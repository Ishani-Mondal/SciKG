{"title": [], "abstractContent": [{"text": "Despite the popularity of stochastic parsers, symbolic parsing still has some advantages, but is not practical without an effective mechanism for selecting among alternative analyses.", "labels": [], "entities": [{"text": "symbolic parsing", "start_pos": 46, "end_pos": 62, "type": "TASK", "confidence": 0.6988391280174255}]}, {"text": "This paper describes the symbolic preference system of a hybrid parser that combines a shallow parser with an overlay parser that builds on the chunks.", "labels": [], "entities": []}, {"text": "The hybrid currently equals or exceeds most sto-chastic parsers in speed and is approaching them inaccuracy.", "labels": [], "entities": [{"text": "speed", "start_pos": 67, "end_pos": 72, "type": "METRIC", "confidence": 0.9780229926109314}]}, {"text": "The preference system is novel in using a simple, three-valued scoring method (-1, 0, or +1) for assigning preferences to constituents viewed in the context of their containing constituents.", "labels": [], "entities": []}, {"text": "The approach addresses problems associated with earlier preference systems, and has considerably facilitated development.", "labels": [], "entities": []}, {"text": "It is ultimately based on viewing preference scoring as an engineering mechanism, and only indirectly related to cognitive principles or corpus-based frequencies.", "labels": [], "entities": []}], "introductionContent": [{"text": "Despite the popularity of stochastic parsers, symbolic parsing still has some advantages, but is not practical without an effective mechanism for selecting among alternative analyses.", "labels": [], "entities": [{"text": "symbolic parsing", "start_pos": 46, "end_pos": 62, "type": "TASK", "confidence": 0.6988391280174255}]}, {"text": "Without it, accept/fail grammar rules must either be overly strong or admit very large numbers of parses.", "labels": [], "entities": []}, {"text": "Symbolic parsers have recently been augmented by stochastic post-processors for output disambiguation, which reduces their independence from corpora.", "labels": [], "entities": []}, {"text": "Both the LFG XLE parser), and the HPSG LinGO ERG parser () have such additions.", "labels": [], "entities": [{"text": "HPSG LinGO ERG parser", "start_pos": 34, "end_pos": 55, "type": "DATASET", "confidence": 0.9091425240039825}]}, {"text": "This paper examines significant aspects of a purely symbolic alternative: the preference and pruning system of the RH (Retro-Hybrid) parser.", "labels": [], "entities": []}, {"text": "The parser combines a preexisting, efficient shallow parser with an overlay parser that builds on the emitted chunks.", "labels": [], "entities": []}, {"text": "The overlay parser is \"retro\" in that the grammar is related to ATNs (Augmented Transition Networks) originated by.", "labels": [], "entities": []}, {"text": "RH delivers single \"best\" parses providing syntactic categories, syntactic functions, head features, and other information).", "labels": [], "entities": [{"text": "RH", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.7182638645172119}]}, {"text": "The parenthesized numbers following the category labels in the figure are preference scores, and are explained further on.", "labels": [], "entities": []}, {"text": "While the parses are not quite as detailed as those obtained using \"deep\" grammars, the missing information, mostly relating to long distance dependencies, can be added at far less cost in a post-parse phase that operates only on a single best parse.", "labels": [], "entities": []}, {"text": "Methods for doing so, for stochastic parser output, are described by Johnson (2002) and.", "labels": [], "entities": []}, {"text": "The hybrid parser exceeds most stochastic parsers in speed, and approaches them inaccuracy, even based on limited manual \"training\" on a particular idiom, so the preference system is a successful one (see Section 6), and continues to improve.", "labels": [], "entities": [{"text": "speed", "start_pos": 53, "end_pos": 58, "type": "METRIC", "confidence": 0.9927064776420593}]}, {"text": "The RH preference system builds on earlier methods.", "labels": [], "entities": []}, {"text": "The major difference is afar simpler scoring system, which has considerably facilitated overlay parser development.", "labels": [], "entities": [{"text": "overlay parser development", "start_pos": 88, "end_pos": 114, "type": "TASK", "confidence": 0.7400030295054117}]}, {"text": "Also, the architecture allows the use of large numbers of preference tests without impacting parser speed.", "labels": [], "entities": []}, {"text": "Finally, the treatment of coordination exploits the lookaheads afforded by the shallow parser to license or bar alternative appositive readings.", "labels": [], "entities": []}, {"text": "Section 2 below discusses symbolic preference systems in general, and section 3 provides an overview of RH parser structure.", "labels": [], "entities": [{"text": "RH parser structure", "start_pos": 104, "end_pos": 123, "type": "TASK", "confidence": 0.8867445190747579}]}, {"text": "Section 4 describes the organization of the RH preference system and the simplified scoring mechanism.", "labels": [], "entities": [{"text": "RH preference", "start_pos": 44, "end_pos": 57, "type": "TASK", "confidence": 0.5294029712677002}]}, {"text": "Section 5 discusses the training approach and Section 6 provides some experimental results.", "labels": [], "entities": []}, {"text": "Section 7 summarizes, and indicates directions for further work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The second extrapolation is to the LFG XLE parser () for English, consisting of a highly developed symbolic parser and grammar, an OT-based preference component, and a stochastic back end to select among remaining alternative parser outputs.", "labels": [], "entities": [{"text": "LFG XLE parser", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.6924169858296713}]}, {"text": "Two sets of values are given for XLE, one obtained using the full English grammar, and one obtained using a reduced grammar ignoring less-frequently applicable rules.", "labels": [], "entities": []}, {"text": "The extrapolation indicates that the coverage of RH is quite good fora symbolic parser with limited training on an idiom.", "labels": [], "entities": []}, {"text": "While the most important factor in RH parser speed is the enormous speed of the shallow parser, the preference and pruning approach of the overlay parser make contributions to both speed and coverage.", "labels": [], "entities": [{"text": "RH parser", "start_pos": 35, "end_pos": 44, "type": "TASK", "confidence": 0.7814399898052216}, {"text": "overlay parser", "start_pos": 139, "end_pos": 153, "type": "TASK", "confidence": 0.7002370357513428}, {"text": "speed", "start_pos": 181, "end_pos": 186, "type": "METRIC", "confidence": 0.9782242178916931}, {"text": "coverage", "start_pos": 191, "end_pos": 199, "type": "METRIC", "confidence": 0.9579916596412659}]}, {"text": "This can be seen in by the difference between RH parser results with and without pruning.", "labels": [], "entities": [{"text": "RH parser", "start_pos": 46, "end_pos": 55, "type": "TASK", "confidence": 0.7724000811576843}]}, {"text": "Pruning increases coverage because without it more parses exceed imposed resource limits..", "labels": [], "entities": [{"text": "coverage", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9913215041160583}]}, {"text": "Highest Scoring Parses per Input 100-sentence sample from section 23, and compared using a different unlabeled bracketing standard.", "labels": [], "entities": []}, {"text": "For nonparsed sentences the chunks are bracketed.", "labels": [], "entities": []}, {"text": "Accuracy is not extrapolated to XLE because available measurements give f-scores (all \u2264 80%) for dependency relations rather than for bracketed constituents.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.993665337562561}]}, {"text": "As a partial indication of the role and effectiveness of the RH preference system, if non-parsed sentences are ignored, the percentage of fully accurate bracketings shown in rises to approximately 46/89 = 51.6% (it is actually larger because coverage is higher on the 100-sentence sample).", "labels": [], "entities": []}, {"text": "As further indication, compares, for section 23, the average and median number of parses per sentence obtained by the base grammar alone (RH Base), and the base grammar plus the preference system (RH Pref).", "labels": [], "entities": [{"text": "RH Base)", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9188553690910339}, {"text": "RH Pref)", "start_pos": 197, "end_pos": 205, "type": "METRIC", "confidence": 0.9132177035013834}]}, {"text": "The table demonstrates that the preference system is a crucial parser component.", "labels": [], "entities": []}, {"text": "Also, the median of 2 parses per sentence obtained using the preference system explains why the fallback low-attach strategy is successful in many cases.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3 compares accuracy. The values for  Collins and Sagae/Lavie are based on comparison  with treebank data for the entire section 23. How- ever, because RH does not produce treebank-style  tags, the RH values are based only on a random", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9995822310447693}, {"text": "Collins and Sagae/Lavie", "start_pos": 44, "end_pos": 67, "type": "DATASET", "confidence": 0.6359288394451141}, {"text": "RH", "start_pos": 204, "end_pos": 206, "type": "METRIC", "confidence": 0.8696427345275879}]}, {"text": " Table 4. Highest Scoring Parses per Input", "labels": [], "entities": []}]}