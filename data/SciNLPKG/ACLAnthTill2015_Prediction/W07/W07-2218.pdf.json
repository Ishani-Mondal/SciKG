{"title": [{"text": "A Latent Variable Model for Generative Dependency Parsing", "labels": [], "entities": [{"text": "Generative Dependency Parsing", "start_pos": 28, "end_pos": 57, "type": "TASK", "confidence": 0.5955981512864431}]}], "abstractContent": [{"text": "We propose a generative dependency parsing model which uses binary latent variables to induce conditioning features.", "labels": [], "entities": [{"text": "generative dependency parsing", "start_pos": 13, "end_pos": 42, "type": "TASK", "confidence": 0.9167541265487671}]}, {"text": "To define this model we use a recently proposed class of Bayesian Networks for structured prediction , Incremental Sigmoid Belief Networks.", "labels": [], "entities": [{"text": "structured prediction", "start_pos": 79, "end_pos": 100, "type": "TASK", "confidence": 0.6878492385149002}]}, {"text": "We demonstrate that the proposed model achieves state-of-the-art results on three different languages.", "labels": [], "entities": []}, {"text": "We also demonstrate that the features induced by the ISBN's latent variables are crucial to this success, and show that the proposed model is particularly good on long dependencies.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dependency parsing has been a topic of active research in natural language processing during the last several years.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9007793068885803}, {"text": "natural language processing", "start_pos": 58, "end_pos": 85, "type": "TASK", "confidence": 0.6507914165655772}]}, {"text": "The CoNLL-X shared task) made a wide selection of standardized treebanks for different languages available for the research community and allowed for easy comparison between various statistical methods on a standardized benchmark.", "labels": [], "entities": []}, {"text": "One of the surprising things discovered by this evaluation is that the best results are achieved by methods which are quite different from state-of-the-art models for constituent parsing, e.g. the deterministic parsing method of () and the minimum spanning tree parser of).", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 167, "end_pos": 186, "type": "TASK", "confidence": 0.7040344178676605}]}, {"text": "All the most accurate dependency parsing models are fully discriminative, unlike constituent parsing where all the state of the art methods have a generative component).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.7756022214889526}, {"text": "constituent parsing", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.720772385597229}]}, {"text": "Another surprising thing is the lack of latent variable models among the methods used in the shared task.", "labels": [], "entities": []}, {"text": "Latent variable models would allow complex features to be induced automatically, which would be highly desirable in multilingual parsing, where manual feature selection might be very difficult and time consuming, especially for languages unknown to the parser developer.", "labels": [], "entities": [{"text": "multilingual parsing", "start_pos": 116, "end_pos": 136, "type": "TASK", "confidence": 0.5544511079788208}]}, {"text": "In this paper we propose a generative latent variable model for dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.8798822462558746}]}, {"text": "It is based on Incremental Sigmoid Belief Networks (ISBNs), a class of directed graphical model for structure prediction problems recently proposed in, where they were demonstrated to achieve competitive results on the constituent parsing task.", "labels": [], "entities": [{"text": "structure prediction", "start_pos": 100, "end_pos": 120, "type": "TASK", "confidence": 0.7647386193275452}, {"text": "constituent parsing task", "start_pos": 219, "end_pos": 243, "type": "TASK", "confidence": 0.7479449907938639}]}, {"text": "As discussed in, computing the conditional probabilities which we need for parsing is in general intractable with ISBNs, but they can be approximated efficiently in several ways.", "labels": [], "entities": []}, {"text": "In particular, the neural network constituent parsers in and) can be regarded as coarse approximations to their corresponding ISBN model.", "labels": [], "entities": []}, {"text": "ISBNs use history-based probability models.", "labels": [], "entities": []}, {"text": "The most common approach to handling the unbounded nature of the parse histories in these models is to choose a pre-defined set of features which can be unambiguously derived from the history (e.g.).", "labels": [], "entities": []}, {"text": "Decision probabilities are then assumed to be independent of all information not represented by this finite set of features.", "labels": [], "entities": []}, {"text": "ISBNs instead use a vector of binary latent variables to encode the information about the parser history.", "labels": [], "entities": []}, {"text": "This history vector is similar to the hidden state of a Hidden Markov Model.", "labels": [], "entities": []}, {"text": "But unlike the graphical model for an HMM, which specifies conditional dependency edges only between adjacent states in the sequence, the ISBN graphical model can specify conditional dependency edges between states which are arbitrarily far apart in the parse history.", "labels": [], "entities": []}, {"text": "The source state of such an edge is determined by the partial output structure built at the time of the destination state, thereby allowing the conditional dependency edges to be appropriate for the structural nature of the problem being modeled.", "labels": [], "entities": []}, {"text": "This structure sensitivity is possible because ISBNs area constrained form of switching model), where each output decision switches the model structure used for the remaining decisions.", "labels": [], "entities": []}, {"text": "We build an ISBN model of dependency parsing using the parsing order proposed in ().", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.8233213722705841}]}, {"text": "However, instead of performing deterministic parsing as in (), we use this ordering to define a generative history-based model, by integrating word prediction operations into the set of parser actions.", "labels": [], "entities": []}, {"text": "Then we propose a simple, language independent set of relations which determine how latent variable vectors are interconnected by conditional dependency edges in the ISBN model.", "labels": [], "entities": []}, {"text": "ISBNs also condition the latent variable vectors on a set of explicit features, which we vary in the experiments.", "labels": [], "entities": [{"text": "ISBNs", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9143528938293457}]}, {"text": "In experiments we evaluate both the performance of the ISBN dependency parser compared to previous work, and the ability of the ISBN model to induce complex history features.", "labels": [], "entities": [{"text": "ISBN dependency parser", "start_pos": 55, "end_pos": 77, "type": "TASK", "confidence": 0.5300191144148508}]}, {"text": "Our model achieves state-of-the-art performance on the languages we test, significantly outperforming the model of () on two languages out of three and demonstrating about the same results on the third.", "labels": [], "entities": []}, {"text": "In order to test the model's feature induction abilities, we train models with two different sets of explicit conditioning features: the feature set individually tuned by) for each considered language, and a minimal set of local features.", "labels": [], "entities": []}, {"text": "These models achieve comparable accuracy, unlike with the discriminative SVM-based approach of), where careful feature selection appears to be crucial.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9992544054985046}]}, {"text": "We also conduct a controlled experiment where we used the tuned features of () but disable the feature induction abilities of our model by elimination of the edges connecting latent state vectors.", "labels": [], "entities": []}, {"text": "This restricted model achieves far worse results, showing that it is exactly the capacity of ISBNs to induce history features which is the key to its success.", "labels": [], "entities": []}, {"text": "It also motivates further research into how feature induction techniques can be exploited in discriminative parsing methods.", "labels": [], "entities": [{"text": "feature induction", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.7348005771636963}]}, {"text": "We analyze how the relation accuracy changes with the length of the head-dependent relation, demonstrating that our model very significantly outperforms the state-of-the-art baseline of) on long dependencies.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9915762543678284}]}, {"text": "Additional experiments suggest that both feature induction abilities and use of the beam search contribute to this improvement.", "labels": [], "entities": []}, {"text": "The fact that our model defines a probability model over parse trees, unlike the previous state-ofthe-art methods), makes it easier to use this model in applications which require probability estimates, e.g. in language processing pipelines.", "labels": [], "entities": []}, {"text": "Also, as with any generative model, it maybe easy to improve the parser's accuracy by using discriminative retraining techniques) or data-defined kernels, with or even without introduction of any additional linguistic features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9987275004386902}]}, {"text": "In addition, there are some applications, such as language modeling, which require generative models.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.7691906690597534}]}, {"text": "Another advantage of generative models is that they do not suffer from the label bias problems, which is a potential problem for conditional or deterministic history-based models, such as ().", "labels": [], "entities": [{"text": "generative", "start_pos": 21, "end_pos": 31, "type": "TASK", "confidence": 0.9631708264350891}]}, {"text": "In the remainder of this paper, we will first review general ISBNs and how they can be approximated.", "labels": [], "entities": [{"text": "ISBNs", "start_pos": 61, "end_pos": 66, "type": "METRIC", "confidence": 0.903891921043396}]}, {"text": "Then we will define the generative parsing model, based on the algorithm of (), and propose an ISBN for this model.", "labels": [], "entities": [{"text": "generative parsing", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.9239098727703094}, {"text": "ISBN", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.9936297535896301}]}, {"text": "The empirical part of the paper then evaluates both the overall accuracy of this method and the importance of the model's capacity to induce features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9992672801017761}]}, {"text": "Additional related work will be discussed in the last section before concluding.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we evaluate the ISBN model for dependency parsing on three treebanks from the CoNLL-X shared task.", "labels": [], "entities": [{"text": "ISBN", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.9329455494880676}, {"text": "dependency parsing", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.7745864987373352}, {"text": "CoNLL-X shared task", "start_pos": 94, "end_pos": 113, "type": "DATASET", "confidence": 0.7812205155690511}]}, {"text": "We compare our generative models with the best parsers from the CoNLL-X task, including the SVM-based parser of) (the MALT parser), which uses the same parsing algorithm.", "labels": [], "entities": []}, {"text": "To test the feature induction abilities of our model we compare results with two feature sets, the feature set tuned individually for each language by), and another feature set which includes only obvious local features.", "labels": [], "entities": []}, {"text": "This simple feature set comprises only features of the word on top of the stack Sand the front word of the queue I.", "labels": [], "entities": []}, {"text": "We compare the gain from using tuned features with the similar gain obtained by the MALT parser.", "labels": [], "entities": [{"text": "MALT parser", "start_pos": 84, "end_pos": 95, "type": "DATASET", "confidence": 0.6989427208900452}]}, {"text": "To obtain these results we train the MALT parser with the same two feature sets.", "labels": [], "entities": [{"text": "MALT parser", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.6310475766658783}]}, {"text": "In order to distinguish the contribution of ISBN's feature induction abilities from the contribution of our estimation method and search, we perform another experiment.", "labels": [], "entities": []}, {"text": "We use the tuned feature set and disable the feature induction abilities of the model by removing all the edges between latent variables vectors.", "labels": [], "entities": []}, {"text": "Comparison of this restricted model with the full ISBN model shows how important the feature induction is.", "labels": [], "entities": []}, {"text": "Also, comparison of this restricted model with the MALT parser, which uses the same set of features, indicates whether our generative estimation method and use of beam search is beneficial.", "labels": [], "entities": [{"text": "generative estimation", "start_pos": 123, "end_pos": 144, "type": "TASK", "confidence": 0.9145687818527222}]}, {"text": "We used the CoNLL-X distributions of Danish DDT treebank, Dutch Alpino treebank (van der) and Slovene SDT treebank ().", "labels": [], "entities": [{"text": "Danish DDT treebank", "start_pos": 37, "end_pos": 56, "type": "DATASET", "confidence": 0.8708991805712382}, {"text": "Dutch Alpino treebank", "start_pos": 58, "end_pos": 79, "type": "DATASET", "confidence": 0.6171960532665253}, {"text": "Slovene SDT treebank", "start_pos": 94, "end_pos": 114, "type": "DATASET", "confidence": 0.7502294977506002}]}, {"text": "The choice of these treebanks was motivated by the fact that they all are freely distributed and have very different sizes of their training sets: 195,069 tokens for Dutch, 94,386 tokens for Danish and only 28,750 tokens for Slovene.", "labels": [], "entities": []}, {"text": "As it is generally believed that discriminative models win over generative models with a large amount of training data, so we expected to see similar trend in our results.", "labels": [], "entities": []}, {"text": "Test sets are about equal and contain about 5,000 scoring tokens.", "labels": [], "entities": []}, {"text": "We followed the experimental setup of the shared task and used all the information provided for the languages: gold standard part-of-speech tags and coarse part-of-speech tags, word form, word lemma (lemma information was not available for Danish) and a set of fine-grain word features.", "labels": [], "entities": []}, {"text": "As we explained in section 3, we treated these sets of finegrain features as anatomic value when predicting a word.", "labels": [], "entities": [{"text": "predicting a word", "start_pos": 97, "end_pos": 114, "type": "TASK", "confidence": 0.8548097411791483}]}, {"text": "However, when conditioning on words, we treated each component of this composite feature individually, as it proved to be useful on the development set.", "labels": [], "entities": []}, {"text": "We used frequency cutoffs: we ignored any property (e.g., word form, feature or even partof-speech tag 4 ) which occurs in the training set less than 5 times.", "labels": [], "entities": []}, {"text": "Following (), we used pseudo-projective transformation they proposed to cast non-projective parsing tasks as projective.", "labels": [], "entities": []}, {"text": "ISBN models were trained using a small development set taken out from the training set, which was used for tuning learning parameters and for early stopping.", "labels": [], "entities": [{"text": "early stopping", "start_pos": 142, "end_pos": 156, "type": "TASK", "confidence": 0.7902462780475616}]}, {"text": "The sizes of the development sets were: 4,988 tokens for larger Dutch corpus, 2,504 tokens for Danish and 2,033 tokens for Slovene.", "labels": [], "entities": []}, {"text": "The MALT parser was trained always using the entire training set.", "labels": [], "entities": [{"text": "MALT parser", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.575656846165657}]}, {"text": "We expect that the mean field approximation should demonstrate better results than feed-forward approximation on this task as it is theoretically expected and confirmed on the constituent parsing task.", "labels": [], "entities": [{"text": "constituent parsing task", "start_pos": 176, "end_pos": 200, "type": "TASK", "confidence": 0.7638484040896097}]}, {"text": "However, the sizes of testing sets would not allow us to perform any conclusive analysis, so we decided not to perform these comparisons here.", "labels": [], "entities": []}, {"text": "Instead we used the mean field approximation for the smaller two corpora and used the feed-forward approximation for the larger one.", "labels": [], "entities": []}, {"text": "Training the mean field approximations on the larger Dutch treebank is feasible, but would significantly reduce the possibilities for tuning the learning parameters on the development set and, thus, would increase the randomness of model comparisons.", "labels": [], "entities": [{"text": "Dutch treebank", "start_pos": 53, "end_pos": 67, "type": "DATASET", "confidence": 0.9811258018016815}]}, {"text": "All model selection was performed on the development set and a single model of each type was applied to the testing set.", "labels": [], "entities": []}, {"text": "We used a state variable vector consisting of 80 binary variables, as it proved sufficient on the preliminary experiments.", "labels": [], "entities": []}, {"text": "For the MALT parser we replicated the parameters from () as described in detail on their website.", "labels": [], "entities": [{"text": "MALT parser", "start_pos": 8, "end_pos": 19, "type": "TASK", "confidence": 0.4703051745891571}]}, {"text": "The labeled attachment scores for the ISBN with tuned features (TF) and local features (LF) and ISBN with tuned features and no edges connecting latent variable vectors (TF-NA) are presented in table 1, along with results for the MALT parser both with tuned and local feature, the MST parser (), and the average score (Aver) across all systems in the CoNLL-X shared task.", "labels": [], "entities": [{"text": "MALT parser", "start_pos": 230, "end_pos": 241, "type": "TASK", "confidence": 0.5594015121459961}, {"text": "average score (Aver)", "start_pos": 304, "end_pos": 324, "type": "METRIC", "confidence": 0.8019647479057312}, {"text": "CoNLL-X shared task", "start_pos": 351, "end_pos": 370, "type": "DATASET", "confidence": 0.7787954211235046}]}, {"text": "The MST parser is included because it demonstrated the best overall result in the task, non significantly outperforming the MALT parser, which, in turn, achieved the second best overall result.", "labels": [], "entities": [{"text": "MST parser", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.7071244716644287}]}, {"text": "The labeled attachment score is computed using the same method as in the CoNLL-X shared task, i.e. ignoring punctuation.", "labels": [], "entities": []}, {"text": "Note, that though we tried to completely replicate training of the MALT parser with the tuned features, we obtained slightly different results.", "labels": [], "entities": [{"text": "MALT parser", "start_pos": 67, "end_pos": 78, "type": "DATASET", "confidence": 0.6831614077091217}]}, {"text": "The original published results for the MALT parser with tuned features were 84.8% for Danish, 78.6% for Dutch and 70.3% for Slovene.", "labels": [], "entities": [{"text": "MALT parser", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.6530616879463196}]}], "tableCaptions": [{"text": " Table 1: Labeled attachment score on the testing sets  of Danish, Dutch and Slovene treebanks.", "labels": [], "entities": [{"text": "Labeled attachment score", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.7667128841082255}, {"text": "Danish, Dutch and Slovene treebanks", "start_pos": 59, "end_pos": 94, "type": "DATASET", "confidence": 0.6256494621435801}]}, {"text": " Table 2: F 1 score of labeled attachment as a function  of dependency length on the testing sets of Danish,  Dutch and Slovene.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.97547713915507}]}]}