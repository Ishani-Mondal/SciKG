{"title": [{"text": "Annotating Expressions of Appraisal in English", "labels": [], "entities": [{"text": "Annotating Expressions of Appraisal", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6246501058340073}]}], "abstractContent": [{"text": "The Appraisal framework is a theory of the language of evaluation, developed within the tradition of systemic functional linguistics.", "labels": [], "entities": [{"text": "Appraisal", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.8137623071670532}]}, {"text": "The framework describes a taxonomy of the types of language used to convey evaluation and position oneself with respect to the evaluations of other people.", "labels": [], "entities": []}, {"text": "Accurate automatic recognition of these types of language can inform an analysis of document sentiment.", "labels": [], "entities": [{"text": "analysis of document sentiment", "start_pos": 72, "end_pos": 102, "type": "TASK", "confidence": 0.6861996129155159}]}, {"text": "This paper describes the preparation of test data for algorithms for automatic Appraisal analysis.", "labels": [], "entities": [{"text": "Appraisal analysis", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.9293479025363922}]}, {"text": "The difficulty of the task is assessed byway of an inter-annotator agreement study, based on measures analogous to those used in the MUC-7 evaluation.", "labels": [], "entities": [{"text": "MUC-7 evaluation", "start_pos": 133, "end_pos": 149, "type": "DATASET", "confidence": 0.7475654780864716}]}], "introductionContent": [{"text": "The Appraisal framework) describes a taxonomy of the language employed in communicating evaluation, explaining how users of English convey attitude (emotion, judgement of people and appreciation of objects), engagement (assessment of the evaluations of other people) and how writers may modify the strength of their attitude/engagement.", "labels": [], "entities": []}, {"text": "Accurate automatic analysis of these aspects of language will augment existing research in the fields of sentiment () and subjectivity analysis (), but assessing the usefulness of analysis algorithms leveraging the Appraisal framework will require test data.", "labels": [], "entities": [{"text": "subjectivity analysis", "start_pos": 122, "end_pos": 143, "type": "TASK", "confidence": 0.71895931661129}, {"text": "Appraisal framework", "start_pos": 215, "end_pos": 234, "type": "DATASET", "confidence": 0.8244133293628693}]}, {"text": "At present there are no machine-readable Appraisal-annotated texts publicly available.", "labels": [], "entities": []}, {"text": "Realworld instances of Appraisal in use are limited to example extracts that demonstrate the theory, coming from a wide variety of genres as disparate as news reporting) and poetry).", "labels": [], "entities": [{"text": "Appraisal", "start_pos": 23, "end_pos": 32, "type": "TASK", "confidence": 0.9074450135231018}]}, {"text": "These examples, while useful in demonstrating the various aspects of Appraisal, can only be employed in a qualitative analysis and would bring about inconsistencies if analysed collectively -one can expect the writing style to depend upon the genre, resulting in significantly different syntactic constructions and lexical choices.", "labels": [], "entities": [{"text": "Appraisal", "start_pos": 69, "end_pos": 78, "type": "TASK", "confidence": 0.7913253903388977}]}, {"text": "We therefore need to examine Appraisal across documents in the same genre and investigate patterns within that particular register.", "labels": [], "entities": [{"text": "Appraisal", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.731864333152771}]}, {"text": "This paper discusses the methodology of an Appraisal annotation study and an analysis of the inter-annotator agreement exhibited by two human judges.", "labels": [], "entities": [{"text": "Appraisal annotation", "start_pos": 43, "end_pos": 63, "type": "TASK", "confidence": 0.5562230050563812}]}, {"text": "The output of this study has the additional benefit of bringing a set of machine-readable annotations of Appraisal into the public domain for further research.", "labels": [], "entities": []}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "The next section offers an overview of the Appraisal framework.", "labels": [], "entities": [{"text": "Appraisal framework", "start_pos": 43, "end_pos": 62, "type": "DATASET", "confidence": 0.6210344582796097}]}, {"text": "Section 3 discusses the methodology adopted for the annotation study.", "labels": [], "entities": []}, {"text": "Section 4 discusses the measures employed to assess inter-annotator agreement and reports the results of these measures.", "labels": [], "entities": []}, {"text": "Section 5 offers an analysis of cases of systematic disagreement.", "labels": [], "entities": []}, {"text": "Other computational work utilising the Appraisal framework is reviewed in Section 6.", "labels": [], "entities": [{"text": "Appraisal framework", "start_pos": 39, "end_pos": 58, "type": "DATASET", "confidence": 0.76478111743927}, {"text": "Section 6", "start_pos": 74, "end_pos": 83, "type": "DATASET", "confidence": 0.939574807882309}]}, {"text": "Section 7 summarises the paper and outlines future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Martin and consider the resources by which writers alter the strength of their evaluation as a system of graduation.", "labels": [], "entities": []}, {"text": "Graduation is a general property of both attitude and engagement.", "labels": [], "entities": [{"text": "Graduation", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9493870139122009}]}, {"text": "In attitude it enables authors to convey greater or lesser degrees of positivity or negativity, while graduation of engagements scales authors' conviction in their utterance.", "labels": [], "entities": []}, {"text": "Graduation is divided into two subsystems.", "labels": [], "entities": []}, {"text": "Force alters appraisal propositions in terms of its inten-sity, quantity or temporality, or by means of spatial metaphor.", "labels": [], "entities": []}, {"text": "Focus considers the resolution of semantic categories, for example: They play real jazz.", "labels": [], "entities": [{"text": "resolution of semantic categories", "start_pos": 20, "end_pos": 53, "type": "TASK", "confidence": 0.8125277757644653}]}, {"text": "They play jazz, sort of.", "labels": [], "entities": []}, {"text": "In real terms a musician either plays jazz or they do not, but these examples demonstrate how authors blur the lines of semantic sets and how binary relationships can be turned into scalar ones.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The distribution of the Appraisal types selected by each annotator (%).", "labels": [], "entities": [{"text": "Appraisal", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9856954216957092}]}, {"text": " Table 2: The density of annotations relative to the  number of documents, sentences and words.", "labels": [], "entities": []}, {"text": " Table 3: MUC-7 score definitions (Chinchor 1998).", "labels": [], "entities": [{"text": "MUC-7 score definitions (Chinchor 1998)", "start_pos": 10, "end_pos": 49, "type": "DATASET", "confidence": 0.7019586563110352}]}, {"text": " Table 4: MUC-7 test scores, evaluating the agree- ment in text anchors selected by the annotators. \u00af  x  denotes the average value, calculated using the har- monic mean.", "labels": [], "entities": [{"text": "MUC-7 test", "start_pos": 10, "end_pos": 20, "type": "DATASET", "confidence": 0.7309612035751343}]}]}