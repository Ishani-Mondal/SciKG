{"title": [], "abstractContent": [{"text": "The paper presents two techniques for lemmatization of Polish person names.", "labels": [], "entities": [{"text": "lemmatization of Polish person names", "start_pos": 38, "end_pos": 74, "type": "TASK", "confidence": 0.8581169247627258}]}, {"text": "First, we apply a rule-based approach which relies on linguistic information and heuris-tics.", "labels": [], "entities": []}, {"text": "Then, we investigate an alternative knowledge-poor method which employs string distance measures.", "labels": [], "entities": []}, {"text": "We provide an evaluation of the adopted techniques using a set of newspaper texts.", "labels": [], "entities": []}], "introductionContent": [{"text": "Proper names constitute a significant part of natural language texts (estimated to about 10% in newspaper articles) and are important for NLP applications, such as Information Extraction, which rely on automatic text understanding.", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 164, "end_pos": 186, "type": "TASK", "confidence": 0.8030628263950348}, {"text": "text understanding", "start_pos": 212, "end_pos": 230, "type": "TASK", "confidence": 0.727769136428833}]}, {"text": "In particular, coreference resolution (e.g., identifying several name variants as referring to the same entity) plays a crucial role in such systems.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.9648910462856293}]}, {"text": "Although automatic recognition of proper names in English, French and other major languages has been in the research focus for over a decade now, cf. (,), (, only a few efforts have been reported for Slavic languages, cf. () (Russian and Bulgarian),) (Polish).", "labels": [], "entities": [{"text": "automatic recognition of proper names", "start_pos": 9, "end_pos": 46, "type": "TASK", "confidence": 0.766041922569275}]}, {"text": "Rich inflection and a more relaxed word order make recognition of proper names in Slavic more difficult than for other languages.", "labels": [], "entities": [{"text": "recognition of proper names", "start_pos": 51, "end_pos": 78, "type": "TASK", "confidence": 0.9000274240970612}]}, {"text": "Moreover, inflection of proper names is usually quite different from common nouns, which complicates the lemmatization process necessary for correct coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 149, "end_pos": 171, "type": "TASK", "confidence": 0.8651530742645264}]}, {"text": "In this paper, we focus on lemmatization of Polish person names, the most idiosyncratic class of proper names in this language.", "labels": [], "entities": [{"text": "lemmatization of Polish person names", "start_pos": 27, "end_pos": 63, "type": "TASK", "confidence": 0.7767407298088074}]}, {"text": "First, we report results of a rule-based symbolic approach.", "labels": [], "entities": []}, {"text": "We apply different heuristics, mostly based on the internal (morphological and syntactic) structure of proper names but also on the surrounding context.", "labels": [], "entities": []}, {"text": "Sometimes, however, the required information is not available, even if the entire document is considered, and lemmatization cannot be performed.", "labels": [], "entities": []}, {"text": "Therefore, we experimented with various knowledge-poor methods, namely string distance metrics, in order to test their usefulness for lemmatization of Polish person names as an alternative technique, especially for cases where documentlevel heuristics are insufficient.", "labels": [], "entities": [{"text": "lemmatization of Polish person names", "start_pos": 134, "end_pos": 170, "type": "TASK", "confidence": 0.7892402648925781}]}, {"text": "Lemmatization of proper names in Slavic has not attracted much attention so far but some work has been done for Slovene:) present a machine-learning approach to lemmatization of unknown single-token words, whereas) report on a shallow approach to find base forms.", "labels": [], "entities": [{"text": "Lemmatization of proper names", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.9103357493877411}]}, {"text": "The organization of the paper is as follows.", "labels": [], "entities": []}, {"text": "First, we present a description of phenomena which make lemmatization of Polish person names a difficult task.", "labels": [], "entities": [{"text": "lemmatization of Polish person names", "start_pos": 56, "end_pos": 92, "type": "TASK", "confidence": 0.8775884509086609}]}, {"text": "Next, a rule-based approach and its evaluation are presented.", "labels": [], "entities": []}, {"text": "Then, various string distance metrics are introduced, followed by the results of experiments on newspaper texts.", "labels": [], "entities": []}, {"text": "The final section presents conclusions and perspectives for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our rule-based approach to person name lemmatization exploits existing resources (a dictionary of first names and contextual triggers) and relies on contextual information (heuristics).", "labels": [], "entities": [{"text": "person name lemmatization", "start_pos": 27, "end_pos": 52, "type": "TASK", "confidence": 0.7091607451438904}]}, {"text": "It has been implemented using SProUT, a shallow processing platform, integrated with a Polish morphological anal-yser ().", "labels": [], "entities": []}, {"text": "For first names, all inflected forms of the most frequent Polish first names are stored in a database so a simple gazetteer look-up associates names with the corresponding base form.", "labels": [], "entities": []}, {"text": "We also used a list of ca 30 000 foreign first names (nominative forms).", "labels": [], "entities": []}, {"text": "For last names, we applied several heuristic rules in order to recognize and produce their base forms.", "labels": [], "entities": []}, {"text": "First, we identify most common types of Polish surnames, e.g., capitalized words ending in -skiego, -skim, -skiemu or -icza, -iczem, -iczu (typical last name suffixes), and convert them to the corresponding base forms (i.e., words ending in -ski and -icz, respectively).", "labels": [], "entities": []}, {"text": "In this way, a significant number of names can be lemmatized in a brute-force manner.", "labels": [], "entities": []}, {"text": "For all remaining surnames, more sophisticated rules have to be applied.", "labels": [], "entities": []}, {"text": "2, these rules have to take into account several pieces of information such as part-of-speech and gender of the (common) word which serves as a surname, but also gender of the first name.", "labels": [], "entities": []}, {"text": "The major problem we encountered while applying these rules is that the information necessary to trigger the appropriate rule is often missing.", "labels": [], "entities": []}, {"text": "For example, in sentence (1), inferring gender of the surname/first name could involve a subcategorization frame for the verb powiadomi\u00b4cpowiadomi\u00b4c 'inform', which requires an accusative NP argument.", "labels": [], "entities": []}, {"text": "In this way we might possibly predict that the base form of Putina is Putin, as -a is the typical accusative ending of masculine names.", "labels": [], "entities": []}, {"text": "Since the subcategorization lexicon is not available, such instances are either not covered or different heuristics are employed for guessing the base form.", "labels": [], "entities": []}, {"text": "Additionally, grammar rules may produce variants of recognized full person names.", "labels": [], "entities": []}, {"text": "For example, for the full name CEO dr Jan Kowalski the following variants can be produced: Kowalski, CEO Kowalski, dr Kowalski, etc.", "labels": [], "entities": []}, {"text": "As the grammar rules always return the longest match, a shorter form may not be recognized.", "labels": [], "entities": []}, {"text": "The produced variants are therefore used in the second pass through the text in order to identify 'incomplete' forms.", "labels": [], "entities": []}, {"text": "As no morphological generation is involved, only base forms can be identified in this way.", "labels": [], "entities": []}, {"text": "The system evaluation indicates that 23.8% of the recognized names were identified by this partial coreference resolution mechanism.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 99, "end_pos": 121, "type": "TASK", "confidence": 0.8587938249111176}]}, {"text": "An analysis of incorrectly recognized named entities (NEs) revealed that major problems concerned (a) classical ambiguities, such as a proper name vs. a common word, and (b) person vs. organization name, caused by a specific word order and a structural ambiguity of phrases containing NEs.", "labels": [], "entities": []}, {"text": "Let us consider the following examples to illustrate the problems.", "labels": [], "entities": []}, {"text": "The text fragment Dane Federalnego in (2) is recognized by the grammar as a person name since Dane is a gazetteer entry fora foreign (English) first name.", "labels": [], "entities": []}, {"text": "Consequently, Federalnego Urz\u02db edu Statystycznego could not be recognized as an organization name.", "labels": [], "entities": [{"text": "Federalnego Urz\u02db edu Statystycznego", "start_pos": 14, "end_pos": 49, "type": "DATASET", "confidence": 0.7990998864173889}]}, {"text": "Potentially, heuristics solving such NE overlapping collisions could improve the precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.9989922642707825}]}, {"text": "Similar techniques have been applied to other languages.", "labels": [], "entities": []}, {"text": "In (3) and (4) the names Della 'of Dell' and Austriak\u00f3w 'of Austrians' were erroneously recognized as surnames.", "labels": [], "entities": []}, {"text": "The rule matching a token representing a title followed by a capitalized word, adopted for English person names, is less reliable for Polish due to declension of proper names and lack of prepositions in genitive constructions.", "labels": [], "entities": []}, {"text": "One solution to this problem would involve matching Della and Austriak\u00f3w with their base forms (Dell and Austriacy, resp.), which might appear in the immediate context.", "labels": [], "entities": []}, {"text": "In this way, the name type could be validated.", "labels": [], "entities": []}, {"text": "However, a corpus inspection revealed that quite frequently no base form appears in the same document.", "labels": [], "entities": []}, {"text": "The last example, (5), illustrates another problem, which is even harder to solve.", "labels": [], "entities": []}, {"text": "The phrase prezes sp\u00f3\u0142ki Kruk is structurally ambiguous, i.e., it can be bracketed as [prezes or.", "labels": [], "entities": []}, {"text": "Consequently, the name Kruk might either refer to a company name ('.", "labels": [], "entities": []}, {"text": "said the president of the Kruk company') or to a person name ('.", "labels": [], "entities": [{"text": "Kruk company", "start_pos": 26, "end_pos": 38, "type": "DATASET", "confidence": 0.8931874930858612}]}, {"text": "said Kruk, the president of the company').", "labels": [], "entities": []}, {"text": "Inferring the proper interpretation might not be possible even if we consider the subcategorization frame of the verb powiedzie\u00b4cpowiedzie\u00b4c 'to say'.", "labels": [], "entities": []}, {"text": "For evaluation of recognition and lemmatization of person names, a set of 30 articles on various topics (politics, finance, sports, culture and science) has been randomly chosen from Rzeczpospolita, a leading Polish newspaper.", "labels": [], "entities": []}, {"text": "The total number of person name occurrences in this document set amounts to 858.", "labels": [], "entities": [{"text": "person name occurrences in this document set", "start_pos": 20, "end_pos": 64, "type": "DATASET", "confidence": 0.7164206079074315}]}, {"text": "Evaluation of recognition's precision and recall yielded 88.6% and 82.6%, respectively.", "labels": [], "entities": [{"text": "recognition", "start_pos": 14, "end_pos": 25, "type": "TASK", "confidence": 0.8719449043273926}, {"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.999764621257782}, {"text": "recall", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.999862551689148}]}, {"text": "Precision of lemmatization of first names and surnames achieved 92.2% and 75.6%, respectively.", "labels": [], "entities": []}, {"text": "For 12.4% of the recognized person names more than one output structure was returned.", "labels": [], "entities": []}, {"text": "For instance, in case of the person name Marka Belki, the first name Marka is interpreted by the gazetteer either as an accusative form of the male name Marek or as a nominative form of a foreign female name Marka.", "labels": [], "entities": []}, {"text": "In fact, 10% of the Polish first-name forms in our gazetteer are ambiguous with respect to gender.", "labels": [], "entities": []}, {"text": "As for the last name Belki, it is a genitive form of the common Polish noun belka 'beam', so the base form can be obtained directly.", "labels": [], "entities": []}, {"text": "Nevertheless, as inflection of proper names differs from that of common nouns, various combinations of the regular noun Belka and the special proper name form Belki are possible, which increases ambiguity of the identified form.", "labels": [], "entities": []}, {"text": "All possible lemmatizations are as follows: A good heuristics to reduce such ambiguous lemmatizations is to prioritize rules which refer to morphological information over those which rely solely on orthography and/or token types.", "labels": [], "entities": []}, {"text": "Since knowledge-based lemmatization of Polish NEs is extremely hard, we also explored a possibility of using string distance metrics for matching inflected person names with their base forms (and their variants) in a collection of document, rather than within a single document.", "labels": [], "entities": [{"text": "knowledge-based lemmatization of Polish NEs", "start_pos": 6, "end_pos": 49, "type": "TASK", "confidence": 0.6042604804039001}]}, {"text": "The rest of this section describes our experiments in using different string distance metrics for this task, inspired by the work presented in and).", "labels": [], "entities": []}, {"text": "The problem can be formally defined as follows.", "labels": [], "entities": []}, {"text": "Let A, B and C be three sets of strings over some alphabet \u03a3, with B \u2286 C.", "labels": [], "entities": []}, {"text": "Further, let f : A \u2192 B be a function representing a mapping of inflected forms (A) into their corresponding base forms (B).", "labels": [], "entities": []}, {"text": "Given, A and C (the search space), the task is to construct an approximation off , namely fora \u2208 A, we say that f returns the correct answer fora; otherwise, f is said to return an incorrect answer.", "labels": [], "entities": []}, {"text": "For another task, a multiresult experiment, we construct an approximation f * : A \u2192 \uf732 C , where f * returns the correct answer fora if f (a) \u2208 f * (a).", "labels": [], "entities": []}, {"text": "Since fora given string more than one answer can be returned, we measured the accuracy in three ways.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9997418522834778}]}, {"text": "First, we calculated the accuracy on the assumption that a multi-result answer is incorrect and we defined all-answer accuracy (AA) measure which penalizes multi-result answers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9995517134666443}, {"text": "all-answer accuracy (AA) measure", "start_pos": 107, "end_pos": 139, "type": "METRIC", "confidence": 0.8797461787859598}]}, {"text": "Second, we measured the accuracy of single-result answers (single-result accuracy (SR)) disregarding the multi-result answers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9992314577102661}, {"text": "single-result accuracy (SR))", "start_pos": 59, "end_pos": 87, "type": "METRIC", "confidence": 0.7871512651443482}]}, {"text": "Finally, we used a weaker measure which treats a multi-result answer as correct if one of the results in the answer set is correct (relaxed-all-answer accuracy (RAA)).", "labels": [], "entities": [{"text": "relaxed-all-answer accuracy (RAA))", "start_pos": 132, "end_pos": 166, "type": "METRIC", "confidence": 0.9032143235206604}]}, {"text": "Let s denote the number of strings for which a single result (base form) was returned.", "labels": [], "entities": []}, {"text": "Analogously, m is the number of strings for which more than one result was returned.", "labels": [], "entities": []}, {"text": "Let s c and m c denote, respectively, the number of correct single-result answers returned and the number of multi-result answers containing at least one correct result.", "labels": [], "entities": []}, {"text": "The accuracy metrics are computed as: AA = s c /(s + m), SR = s c /s, and RAA = (s c + m c )/(s + m).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994737505912781}, {"text": "AA", "start_pos": 38, "end_pos": 40, "type": "METRIC", "confidence": 0.9990103244781494}, {"text": "SR", "start_pos": 57, "end_pos": 59, "type": "METRIC", "confidence": 0.9982764720916748}, {"text": "RAA", "start_pos": 74, "end_pos": 77, "type": "METRIC", "confidence": 0.9964148998260498}]}, {"text": "We started our experiments with the PL-F-NAME dataset and applied all but the multi-token strings distance metrics.", "labels": [], "entities": [{"text": "PL-F-NAME dataset", "start_pos": 36, "end_pos": 53, "type": "DATASET", "confidence": 0.8588347733020782}]}, {"text": "The results of the accuracy evaluation are given in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.999544084072113}]}, {"text": "The first three columns give the accuracy figures, whereas the column labeled AV gives an average number of results returned in the answer set.: Results for PL-F-NAMES Interestingly, the simple linguistically-aware common prefix-based measure turned out to work best in the AA category, which is the most relevant one, whereas WLCS metrics is the most accurate in case of single-result answers and the RAA category.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9992042183876038}, {"text": "AV", "start_pos": 78, "end_pos": 80, "type": "METRIC", "confidence": 0.9354526400566101}, {"text": "AA", "start_pos": 274, "end_pos": 276, "type": "METRIC", "confidence": 0.942002534866333}]}, {"text": "Thus, a combination of the two seems to be a reasonable solution to further improve the performance (i.e., if WLCS provides a single answer, return this answer, otherwise return the answer of CP \u03b4\uf732 ).", "labels": [], "entities": [{"text": "answer of CP \u03b4", "start_pos": 182, "end_pos": 196, "type": "METRIC", "confidence": 0.7359454929828644}]}, {"text": "Next, the time-efficient skip grams metrics performed surprisingly well in the AA category.", "labels": [], "entities": [{"text": "AA", "start_pos": 79, "end_pos": 81, "type": "METRIC", "confidence": 0.9553688168525696}]}, {"text": "This result was achieved with {0, 2} gram classes.", "labels": [], "entities": []}, {"text": "Recall that about 10% of the inflected first name forms in Polish are ambiguous, as they are either a male or a female person name, see sec.", "labels": [], "entities": []}, {"text": "2. Clearly, the AA accuracy figures in the experiment run on the PL-F-NAME-2 (with a large search space) was significantly worse.", "labels": [], "entities": [{"text": "AA", "start_pos": 16, "end_pos": 18, "type": "METRIC", "confidence": 0.9994069337844849}, {"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.8877527117729187}, {"text": "PL-F-NAME-2", "start_pos": 65, "end_pos": 76, "type": "DATASET", "confidence": 0.8615788221359253}]}, {"text": "However, the SR accuracy for some of the metrics is still acceptable.", "labels": [], "entities": [{"text": "SR", "start_pos": 13, "end_pos": 15, "type": "METRIC", "confidence": 0.9976425766944885}, {"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.7524798512458801}]}, {"text": "The top ranking metrics with respect to SR and AA accuracy are given in.", "labels": [], "entities": [{"text": "SR", "start_pos": 40, "end_pos": 42, "type": "METRIC", "confidence": 0.9930965304374695}, {"text": "AA", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9892788529396057}, {"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.8312138915061951}]}, {"text": "Metrics which return more than 5 answers on average were excluded from this list.", "labels": [], "entities": []}, {"text": "Also in the case of PL-F-NAME-2 the combination of W LCS and CP \u03b4\uf732 seems to be the best choice.", "labels": [], "entities": [{"text": "W LCS", "start_pos": 51, "end_pos": 56, "type": "METRIC", "confidence": 0.8273889422416687}]}, {"text": "Finally, we have made experiments for full person names, each represented as two tokens.", "labels": [], "entities": []}, {"text": "It is important to note that the order of the first name and the surname in some of the entities in our test datasets is swapped.", "labels": [], "entities": []}, {"text": "This inaccuracy is introduced by full names where the surname may also function as a first name.", "labels": [], "entities": []}, {"text": "Nevertheless, the results of the experiment on PL-FULL-NAMES given in are nearly optimal.", "labels": [], "entities": []}, {"text": "JW M , W LCS, LCS, skip grams and Smith-Waterman were among the 'best' metrics.: Results for PL-FULL-NAMES", "labels": [], "entities": [{"text": "LCS", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.9139444231987}, {"text": "skip grams", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.9430828392505646}, {"text": "PL-FULL-NAMES", "start_pos": 93, "end_pos": 106, "type": "TASK", "confidence": 0.37472373247146606}]}], "tableCaptions": [{"text": " Table 3: Dataset used for the experiments", "labels": [], "entities": []}, {"text": " Table 4. The first three columns  give the accuracy figures, whereas the column la- beled AV gives an average number of results re- turned in the answer set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9997199177742004}, {"text": "AV", "start_pos": 91, "end_pos": 93, "type": "METRIC", "confidence": 0.6759323477745056}]}, {"text": " Table 4: Results for PL-F-NAMES", "labels": [], "entities": [{"text": "PL-F-NAMES", "start_pos": 22, "end_pos": 32, "type": "TASK", "confidence": 0.5174832344055176}]}, {"text": " Table 5. Metrics which return  more than 5 answers on average were excluded from  this list. Also in the case of PL-F-NAME-2 the com- bination of W LCS and CP \u03b4\uf732 seems to be the best  choice.", "labels": [], "entities": []}, {"text": " Table 5: Top results for PL-F-NAMES-2", "labels": [], "entities": [{"text": "PL-F-NAMES-2", "start_pos": 26, "end_pos": 38, "type": "TASK", "confidence": 0.4711073040962219}]}, {"text": " Table 6: Results for PL-FULL-NAMES", "labels": [], "entities": [{"text": "PL-FULL-NAMES", "start_pos": 22, "end_pos": 35, "type": "TASK", "confidence": 0.4703427851200104}]}, {"text": " Table 7. The  JW M metric seems to be the best choice as an in- ternal metric, whereas W LCS, CP \u03b4\uf732 and Jaro per- form slightly worse.", "labels": [], "entities": [{"text": "JW M metric", "start_pos": 15, "end_pos": 26, "type": "METRIC", "confidence": 0.49880219499270123}]}, {"text": " Table 7: AA accuracy for PL-FULL-NAMES-2", "labels": [], "entities": [{"text": "AA", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9994999170303345}, {"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9517065286636353}, {"text": "PL-FULL-NAMES-2", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.36194753646850586}]}, {"text": " Table 8. JW M  and W LCS turned out to achieve the best scores.", "labels": [], "entities": []}, {"text": " Table 8: Results for PL-FULL-NAMES-3", "labels": [], "entities": [{"text": "PL-FULL-NAMES-3", "start_pos": 22, "end_pos": 37, "type": "TASK", "confidence": 0.46564844250679016}]}]}