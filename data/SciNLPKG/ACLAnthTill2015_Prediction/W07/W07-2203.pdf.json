{"title": [{"text": "Semi-supervised Training of a Statistical Parser from Unlabeled Partially-bracketed Data", "labels": [], "entities": []}], "abstractContent": [{"text": "We compare the accuracy of a statistical parse ranking model trained from a fully-annotated portion of the Susanne treebank with one trained from unla-beled partially-bracketed sentences derived from this treebank and from the Penn Treebank.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9995288848876953}, {"text": "Susanne treebank", "start_pos": 107, "end_pos": 123, "type": "DATASET", "confidence": 0.9654415547847748}, {"text": "Penn Treebank", "start_pos": 227, "end_pos": 240, "type": "DATASET", "confidence": 0.9971290826797485}]}, {"text": "We demonstrate that confidence-based semi-supervised techniques similar to self-training outperform expectation maximization when both are constrained by partial bracketing.", "labels": [], "entities": []}, {"text": "Both methods based on partially-bracketed training data outperform the fully supervised technique, and both can, in principle, be applied to any statistical parser whose output is consistent with such partial-bracketing.", "labels": [], "entities": []}, {"text": "We also explore tuning the model to a different domain and the effect of in-domain data in the semi-supervised training processes.", "labels": [], "entities": []}], "introductionContent": [{"text": "Extant statistical parsers require extensive and detailed treebanks, as many of their lexical and structural parameters are estimated in a fullysupervised fashion from treebank derivations. is a detailed exposition of one such ongoing line of research which utilizes the Wall Street Journal (WSJ) sections of the Penn Treebank (PTB).", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ) sections of the Penn Treebank (PTB)", "start_pos": 271, "end_pos": 332, "type": "DATASET", "confidence": 0.9257670385496957}]}, {"text": "However, there are disadvantages to this approach.", "labels": [], "entities": []}, {"text": "Firstly, treebanks are expensive to create manually.", "labels": [], "entities": []}, {"text": "Secondly, the richer the annotation required, the harder it is to adapt the treebank to train parsers which make different assumptions about the structure of syntactic analyses.", "labels": [], "entities": []}, {"text": "For example, trains a statistical parser based on Combinatory Categorial Grammar (CCG) on the WSJ PTB, but first maps the treebank to CCG derivations semi-automatically.", "labels": [], "entities": [{"text": "WSJ PTB", "start_pos": 94, "end_pos": 101, "type": "DATASET", "confidence": 0.9741090536117554}]}, {"text": "Thirdly, many (lexical) parameter estimates do not generalize well between domains.", "labels": [], "entities": []}, {"text": "For instance, reports that WSJ-derived bilexical parameters in Collins' (1999) Model 1 parser contribute about 1% to parse selection accuracy when test data is in the same domain, but yield no improvement for test data selected from the Brown Corpus.", "labels": [], "entities": [{"text": "parse selection", "start_pos": 117, "end_pos": 132, "type": "TASK", "confidence": 0.8986079692840576}, {"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.8639380931854248}, {"text": "Brown Corpus", "start_pos": 237, "end_pos": 249, "type": "DATASET", "confidence": 0.9523800313472748}]}, {"text": "adapt a statistical parser trained on the WSJ PTB to the biomedical domain by retraining on the Genia Corpus, augmented with manually corrected derivations in the same format.", "labels": [], "entities": [{"text": "WSJ PTB", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.9715963304042816}, {"text": "Genia Corpus", "start_pos": 96, "end_pos": 108, "type": "DATASET", "confidence": 0.8340461850166321}]}, {"text": "To make statistical parsing more viable fora range of applications, we need to make more effective and flexible use of extant training data and minimize the cost of annotation for new data created to tune a system to anew domain.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.8513286709785461}]}, {"text": "Unsupervised methods for training parsers have been relatively unsuccessful to date, including expectation maximization (EM) such as the inside-outside algorithm (IOA) over PCFGs ().", "labels": [], "entities": [{"text": "expectation maximization (EM", "start_pos": 95, "end_pos": 123, "type": "METRIC", "confidence": 0.7542674243450165}]}, {"text": "However, adapted the IOA to apply over semi-supervised data (unlabeled bracketings) extracted from the PTB.", "labels": [], "entities": [{"text": "IOA", "start_pos": 21, "end_pos": 24, "type": "DATASET", "confidence": 0.7520542144775391}, {"text": "PTB", "start_pos": 103, "end_pos": 106, "type": "DATASET", "confidence": 0.9698918461799622}]}, {"text": "They constrain the training data (parses) considered within the IOA to those consistent with the constituent boundaries defined by the bracketing.", "labels": [], "entities": []}, {"text": "One advantage of this approach is that, although less information is derived from the treebank, it gen-eralizes better to parsers which make different representational assumptions, and it is easier, as Pereira and Schabes did, to map unlabeled bracketings to a format more consistent with the target grammar.", "labels": [], "entities": []}, {"text": "Another is that the cost of annotation with unlabeled brackets should be lower than that of developing a representationally richer treebank.", "labels": [], "entities": []}, {"text": "More recently, both have successfully trained maximum entropy parsing models utilizing all derivations in the model consistent with the annotation of the WSJ PTB, weighting counts by the normalized probability of the associated derivation.", "labels": [], "entities": [{"text": "maximum entropy parsing", "start_pos": 46, "end_pos": 69, "type": "TASK", "confidence": 0.6253397663434347}, {"text": "WSJ PTB", "start_pos": 154, "end_pos": 161, "type": "DATASET", "confidence": 0.9579672515392303}]}, {"text": "In this paper, we extend this line of investigation by utilizing only unlabeled and partial bracketing.", "labels": [], "entities": []}, {"text": "We compare the performance of a statistical parsing model trained from a detailed treebank with that of the same model trained with semi-supervised techniques that require only unlabeled partially-bracketed data.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.6190735995769501}]}, {"text": "We contrast an IOA-based EM method for training a PGLR parser (), similar to the method applied by Pereira and Schabes to PCFGs, to a range of confidence-based semi-supervised methods described below.", "labels": [], "entities": []}, {"text": "The IOA is a generalization of the Baum-Welch or Forward-Backward algorithm, another instance of EM, which can be used to train Hidden Markov Models (HMMs). and demonstrated that Baum-Welch does not necessarily improve the performance of an HMM part-ofspeech tagger when deployed in an unsupervised or semi-supervised setting.", "labels": [], "entities": [{"text": "IOA", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.7226529717445374}]}, {"text": "These somewhat negative results, in contrast to those of, suggest that EM techniques require fairly determinate training data to yield useful models.", "labels": [], "entities": []}, {"text": "Another motivation to explore alternative non-iterative methods is that the derivation space over partiallybracketed data can remain large (>1K) while the confidence-based methods we explore have a total processing overhead equivalent to one iteration of an IOA-based EM algorithm.", "labels": [], "entities": []}, {"text": "As we utilize an initial model to annotate additional training data, our methods are closely related to self-training methods described in the literature (e.g.).", "labels": [], "entities": []}, {"text": "However these methods have been applied to fully-annotated training data to create the initial model, which is then used to annotate further training data derived from unannotated text.", "labels": [], "entities": []}, {"text": "Instead, we train entirely from partially-bracketed data, starting from the small proportion of 'unambiguous' data whereby a single parse is consistent with the annotation.", "labels": [], "entities": []}, {"text": "Therefore, our methods are better described as semi-supervised and the main focus of this work is the flexible re-use of existing treebanks to train a wider variety of statistical parsing models.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 168, "end_pos": 187, "type": "TASK", "confidence": 0.6363195776939392}]}, {"text": "While many statistical parsers extract a context-free grammar in parallel with a statistical parse selection model, we demonstrate that existing treebanks can be utilized to train parsers that deploy grammars that make other representational assumptions.", "labels": [], "entities": []}, {"text": "As a result, our methods can be applied by a range of parsers to minimize the manual effort required to train a parser or adapt to anew domain.", "labels": [], "entities": []}, {"text": "\u00a72 gives details of the parsing system that are relevant to this work.", "labels": [], "entities": [{"text": "parsing", "start_pos": 24, "end_pos": 31, "type": "TASK", "confidence": 0.9718741178512573}]}, {"text": "\u00a73 and \u00a74 describe our data and evaluation schemes, respectively.", "labels": [], "entities": []}, {"text": "\u00a75 describes our semi-supervised training methods.", "labels": [], "entities": []}, {"text": "\u00a76 explores the problem of tuning a parser to anew domain.", "labels": [], "entities": []}, {"text": "Finally, \u00a77 gives conclusions and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The parser's output is evaluated using a relational dependency evaluation scheme) with standard measures: precision, recall and F 1 . Relations are organized into a hierarchy with the root node specifying an unlabeled dependency.", "labels": [], "entities": [{"text": "precision", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.999570906162262}, {"text": "recall", "start_pos": 117, "end_pos": 123, "type": "METRIC", "confidence": 0.9986188411712646}, {"text": "F 1", "start_pos": 128, "end_pos": 131, "type": "METRIC", "confidence": 0.9941608607769012}]}, {"text": "The microaveraged precision, recall and F 1 scores are calculated from the counts for all relations in the hierarchy which subsume the parser output.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.8896238803863525}, {"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.999333918094635}, {"text": "F 1 scores", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9850533803304037}]}, {"text": "The microaveraged F 1 score for the baseline system using this evaluation scheme is 75.61%, which -over similar sets of relational dependencies -is broadly comparable to recent evaluation results published by King and collaborators with their state-of-theart parsing system ().", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9072418212890625}]}], "tableCaptions": [{"text": " Table 1: Corpus split for S, W and SW .", "labels": [], "entities": [{"text": "Corpus split", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.6985526829957962}]}, {"text": " Table 2: Performance of all models on DepBank.   \u2021 represents the statistical significance of the sys- tem against the baseline model.", "labels": [], "entities": [{"text": "DepBank", "start_pos": 39, "end_pos": 46, "type": "DATASET", "confidence": 0.9539496898651123}]}]}