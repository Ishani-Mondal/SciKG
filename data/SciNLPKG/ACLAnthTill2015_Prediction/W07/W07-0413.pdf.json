{"title": [{"text": "Proceedings of SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Three models for discriminative machine translation using Global Lexical Selection and Sentence Reconstruction", "labels": [], "entities": [{"text": "SSST, NAACL-HLT 2007 / AMTA Workshop", "start_pos": 15, "end_pos": 51, "type": "TASK", "confidence": 0.5879616354193006}, {"text": "Syntax and Structure", "start_pos": 55, "end_pos": 75, "type": "TASK", "confidence": 0.6929889520009359}, {"text": "discriminative machine translation", "start_pos": 108, "end_pos": 142, "type": "TASK", "confidence": 0.6927552421887716}]}], "abstractContent": [{"text": "Machine translation of a source language sentence involves selecting appropriate target language words and ordering the selected words to form a well-formed target language sentence.", "labels": [], "entities": [{"text": "Machine translation of a source language sentence", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.841415456363133}]}, {"text": "Most of the previous work on statistical machine translation relies on (local) associations of target words/phrases with source words/phrases for lexical selection.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 29, "end_pos": 60, "type": "TASK", "confidence": 0.6424178580443064}]}, {"text": "In contrast, in this paper, we present a novel approach to lexical selection where the target words are associated with the entire source sentence (global) without the need for local associations.", "labels": [], "entities": [{"text": "lexical selection", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.7196862399578094}]}, {"text": "This technique is used by three models (Bag-of-words model, sequential model and hierarchical model) which predict the target language words given a source sentence and then order the words appropriately.", "labels": [], "entities": []}, {"text": "We show that a hierarchical model performs best when compared to the other two models.", "labels": [], "entities": []}], "introductionContent": [{"text": "The problem of machine translation can be viewed as consisting of two subproblems: (a) lexical selection, where appropriate target language lexical items are chosen for each source language lexical item and (b) lexical reordering, where the chosen target language lexical items are rearranged to produce a meaningful target language string.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.8012006878852844}]}, {"text": "Most of the previous work on statistical machine translation, as exemplified in, employs word-alignment algorithm (such as GIZA++ () that provides local associations between source words and target words.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 29, "end_pos": 60, "type": "TASK", "confidence": 0.6678078273932139}]}, {"text": "The source-to-target word-alignments are sometimes augmented with target-to-source word alignments in order to improve the precision of these local associations.", "labels": [], "entities": [{"text": "precision", "start_pos": 123, "end_pos": 132, "type": "METRIC", "confidence": 0.9977788329124451}]}, {"text": "Further, the word-level alignments are extended to phrase-level alignments in order to increase the extent of local associations.", "labels": [], "entities": []}, {"text": "The phrasal associations compile some amount of (local) lexical reordering of the target words-those permitted by the size of the phrase.", "labels": [], "entities": []}, {"text": "Most of the state-of-the-art machine translation systems use these phrase-level associations in conjunction with a target language model to produce the target sentence.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7514494359493256}]}, {"text": "There is relatively little emphasis on (global) lexical reordering other than the local re-orderings permitted within the phrasal alignments.", "labels": [], "entities": []}, {"text": "A few exceptions are the hierarchical (possibly syntax-based) transduction models;) and the string transduction models (.", "labels": [], "entities": []}, {"text": "In this paper, we present three models for doing discriminative machine translation using global lexical selection and lexical reordering.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.7197546064853668}]}, {"text": "1. Bag-of-Words model : Given a source sentence, each of the target words are chosen by looking at the entire source sentence.", "labels": [], "entities": []}, {"text": "The target language words are then permuted in various ways and then, the best permutation is chosen using the language model on the target side.", "labels": [], "entities": []}, {"text": "The size of the search space of these permutations can beset by a parameter called the permutation window.", "labels": [], "entities": []}, {"text": "This model does not allow long distance re-orderings of target words unless a very large permutation window chosen which is very expensive.", "labels": [], "entities": []}, {"text": "2. Sequential Lexical Choice model : Given a source sentence, the target words are predicted in an order which is faithful to the or-der of words in the source sentence.", "labels": [], "entities": []}, {"text": "Now, the number of permutations that need to be examined to obtain the best target language strings are much less when compared to the Bag-of-Words model.", "labels": [], "entities": []}, {"text": "This model is expected to give good results for language pairs such as English-French for which only local word order variations exist between sentences.", "labels": [], "entities": []}, {"text": "3. Hierarchical lexical association and reordering model : For language pairs such as English-Hindi or English-Japanese where there is a high degree of global reordering), it is necessary to be able to handle long distance movement of words/phrases.", "labels": [], "entities": []}, {"text": "In this approach, the target words predicted through global lexical selection are associated with various nodes of the source dependency tree and then, hierarchical reordering is done to obtain the order of words in the target sentence.", "labels": [], "entities": []}, {"text": "Hierarchical reordering allows phrases to distort to longer distances than the previous two models.", "labels": [], "entities": []}, {"text": "The outline of the paper is as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we talk about the global lexical selection.", "labels": [], "entities": [{"text": "global lexical selection", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.6260798176129659}]}, {"text": "Section 3 describes three models for global lexical selection and reordering.", "labels": [], "entities": [{"text": "global lexical selection", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.661793053150177}]}, {"text": "In Section 4, we report the results of the translation models on English-Hindi language pair and contrast the strengths and limitations of the models.", "labels": [], "entities": []}], "datasetContent": [{"text": "The language pair that we considered for our experiments are English-Hindi.", "labels": [], "entities": []}, {"text": "The training set consists of 37967 sentence pairs, the development set contains 819 sentence pairs and the test set has 699 sentence pairs.", "labels": [], "entities": []}, {"text": "The dataset is from the newspaper domain with topics ranging from politics to tourism.", "labels": [], "entities": [{"text": "newspaper domain", "start_pos": 24, "end_pos": 40, "type": "DATASET", "confidence": 0.9213460981845856}]}, {"text": "The sentence pairs have a maximum source sentence length of 30 words.", "labels": [], "entities": []}, {"text": "The average length of English sentences is 18 while that of Hindi sentences is 20.", "labels": [], "entities": []}, {"text": "The source language vocabulary is 41017 and target sentence vocabulary is 48576.", "labels": [], "entities": []}, {"text": "The token/type ratio of English in the dataset is 16.70 and that of Hindi is 15.64.", "labels": [], "entities": []}, {"text": "This dataset is relatively sparse.", "labels": [], "entities": []}, {"text": "So, the translation accuracies on this dataset would be relatively less when compared to those on much larger datasets.", "labels": [], "entities": []}, {"text": "In the target side of the development corpus, the percentage of unseen tokens is 13.48%(3.87% types) while in the source side, the percentage of unseen tokens is 10.77%(3.20% types).", "labels": [], "entities": []}, {"text": "On furthur inspection of a small portion of the dataset, we found that the maximum percentage of the unseen words on the target side are the named entities.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Summary of the results", "labels": [], "entities": []}]}