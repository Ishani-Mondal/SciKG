{"title": [{"text": "Deep Grammars in a Tree Labeling Approach to Syntax-based Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 58, "end_pos": 89, "type": "TASK", "confidence": 0.7288638850053152}]}], "abstractContent": [{"text": "In this paper, we propose anew syntax-based machine translation (MT) approach based on reducing the MT task to a tree-labeling task, which is further decomposed into a sequence of simple decisions for which discriminative classifiers can be trained.", "labels": [], "entities": [{"text": "syntax-based machine translation (MT)", "start_pos": 31, "end_pos": 68, "type": "TASK", "confidence": 0.8065473337968191}]}, {"text": "The approach is very flexible and we believe that it is particularly well-suited for exploiting the linguistic knowledge encoded in deep grammars whenever possible , while at the same time taking advantage of data-based techniques that have proven a powerful basis for MT, as recent advances in statistical MT show.", "labels": [], "entities": [{"text": "MT", "start_pos": 269, "end_pos": 271, "type": "TASK", "confidence": 0.9967445135116577}, {"text": "MT", "start_pos": 307, "end_pos": 309, "type": "TASK", "confidence": 0.8569527268409729}]}, {"text": "A full system using the Lexical-Functional Grammar (LFG) parsing system XLE and the grammars from the Parallel Grammar development project (ParGram; (Butt et al., 2002)) has been implemented, and we present preliminary results on English-to-German translation with a tree-labeling system trained on a small subsection of the Eu-roparl corpus.", "labels": [], "entities": [{"text": "Lexical-Functional Grammar (LFG) parsing", "start_pos": 24, "end_pos": 64, "type": "TASK", "confidence": 0.6188753942648569}, {"text": "Eu-roparl corpus", "start_pos": 325, "end_pos": 341, "type": "DATASET", "confidence": 0.8527871072292328}]}, {"text": "1 Motivation Machine translation (MT) is probably the oldest application of what we call deep linguistic processing techniques today.", "labels": [], "entities": [{"text": "1 Motivation Machine translation (MT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7370410178388868}]}, {"text": "But from its inception, there have been alternative considerations of approaching the task with data-based statistical techniques (cf. War-ren Weaver's well-known memo from 1949).", "labels": [], "entities": []}, {"text": "Only with fairly recent advances in computer technology have researchers been able to build effective statistical MT prototypes, but in the last few years, the statistical approach has received enormous research interest and made significant progress.", "labels": [], "entities": [{"text": "MT", "start_pos": 114, "end_pos": 116, "type": "TASK", "confidence": 0.771807074546814}]}, {"text": "The most successful statistical MT paradigm has been, fora while now, the so-call phrase-based MT approach (Och and Ney, 2003).", "labels": [], "entities": [{"text": "MT", "start_pos": 32, "end_pos": 34, "type": "TASK", "confidence": 0.8865844011306763}, {"text": "MT", "start_pos": 95, "end_pos": 97, "type": "TASK", "confidence": 0.8036307692527771}]}, {"text": "In this paradigm, sentences are translated from a source language to a target language through the repeated substitution of contiguous word sequences (\"phrases\") from the source language for word sequences in the target language.", "labels": [], "entities": []}, {"text": "Training of the phrase translation model builds on top of a standard statistical word alignment over the training corpus of parallel text (Brown et al., 1993) for identifying corresponding word blocks, assuming no further linguistic analysis of the source or target language.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.8248183727264404}]}, {"text": "In decoding, i.e. the application of the acquired translation model to unseen source sentences, these systems then typically rely on n-gram language models and simple statistical reordering models to shuffle the phrases into an order that is coherent in the target language.", "labels": [], "entities": []}, {"text": "An obvious advantage of statistical MT approaches is that they can adopt (often very idiomatic) translations of mid-to high-frequency constructions without requiring any language-pair specific engineering work.", "labels": [], "entities": [{"text": "MT", "start_pos": 36, "end_pos": 38, "type": "TASK", "confidence": 0.8451260328292847}]}, {"text": "At the same time it is clear that a linguistics-free approach is limited in what it can ultimately achieve: only linguistically informed systems can detect certain generalizations from lower-frequency constructions in the data and successfully apply them in a similar but different linguistic context.", "labels": [], "entities": []}, {"text": "Hence, the idea of \"hybrid\" MT, exploiting both linguistic and statistical information is fairly old.", "labels": [], "entities": [{"text": "MT", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.9041840434074402}]}, {"text": "Here we will not consider classical, rule-based systems with some added data-based resource acquisition (although they maybe among the best candidates for high-quality special-purpose translation but adaption to new language pairs and sub-languages is very costly for these systems).", "labels": [], "entities": [{"text": "special-purpose translation", "start_pos": 168, "end_pos": 195, "type": "TASK", "confidence": 0.6986181139945984}]}, {"text": "The other form of hybridization-a statistical MT model that is based on a deeper analysis of the syntactic 33", "labels": [], "entities": [{"text": "hybridization-a statistical MT", "start_pos": 18, "end_pos": 48, "type": "TASK", "confidence": 0.6715855995814005}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}