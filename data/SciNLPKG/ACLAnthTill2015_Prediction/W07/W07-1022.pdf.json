{"title": [{"text": "BaseNPs that contain gene names: domain specificity and genericity", "labels": [], "entities": [{"text": "genericity", "start_pos": 56, "end_pos": 66, "type": "TASK", "confidence": 0.6098623871803284}]}], "abstractContent": [{"text": "The names of named entities very often occur as constituents of larger noun phrases which denote different types of entity.", "labels": [], "entities": []}, {"text": "Understanding the structure of the embedding phrase can bean enormously beneficial first step to enhancing whatever processing is intended to follow the named entity recognition in the first place.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 153, "end_pos": 177, "type": "TASK", "confidence": 0.7424688537915548}]}, {"text": "In this paper, we examine the integration of general purpose linguistic processors together with domain specific named entity recognition in order to carryout the task of baseNP detection.", "labels": [], "entities": [{"text": "domain specific named entity recognition", "start_pos": 97, "end_pos": 137, "type": "TASK", "confidence": 0.646262776851654}, {"text": "baseNP detection", "start_pos": 171, "end_pos": 187, "type": "TASK", "confidence": 0.7526251077651978}]}, {"text": "We report a best F-score of 87.17% on this task.", "labels": [], "entities": [{"text": "F-score", "start_pos": 17, "end_pos": 24, "type": "METRIC", "confidence": 0.9995641112327576}]}, {"text": "We also report an inter-annotator agreement score of 98.8 Kappa on the task of baseNP annotation of anew data set.", "labels": [], "entities": [{"text": "anew data set", "start_pos": 100, "end_pos": 113, "type": "DATASET", "confidence": 0.786373903354009}]}], "introductionContent": [{"text": "Base noun phrases (baseNPs), broadly \"the initial portions of non-recursive noun phrases up to the head\", are valuable pieces of linguistic structure which minimally extend beyond the scope of named entities.", "labels": [], "entities": []}, {"text": "In this paper, we explore the integration of different techniques for detecting baseNPs that contain a named entity, using a domain-trained named entity recognition (NER) system but in combination with other linguistic components that are \"general purpose\".", "labels": [], "entities": [{"text": "domain-trained named entity recognition (NER)", "start_pos": 125, "end_pos": 170, "type": "TASK", "confidence": 0.7752739105905805}]}, {"text": "The rationale is simply that domain-trained NER is clearly a necessity for the task; but one might expect to be able to secure good coverage at the higher syntactic level by intelligent integration of general purpose syntactic processing without having to undergo a further round of domain specific annotation and training.", "labels": [], "entities": [{"text": "NER", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.8568535447120667}]}, {"text": "We present a number of experiments exploring different ways of integrating NER into general purpose linguistic processing.", "labels": [], "entities": [{"text": "NER", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.9536424279212952}, {"text": "general purpose linguistic processing", "start_pos": 84, "end_pos": 121, "type": "TASK", "confidence": 0.5823553949594498}]}, {"text": "Of course, good results can also be used subsequently to help reduce the effort required in data annotation for use in dedicated domain-specific machine learning systems for baseNP detection.", "labels": [], "entities": [{"text": "baseNP detection", "start_pos": 174, "end_pos": 190, "type": "TASK", "confidence": 0.796924352645874}]}, {"text": "First, however, we motivate the task itself.", "labels": [], "entities": []}, {"text": "Enormous effort has been directed in recent years to the automatic tagging of named entities in bio-medical texts and with considerable success.", "labels": [], "entities": [{"text": "automatic tagging of named entities in bio-medical texts", "start_pos": 57, "end_pos": 113, "type": "TASK", "confidence": 0.8142280541360378}]}, {"text": "For example, iHOP reports gene name precision as being between 87% and 99% (depending on the organism)).", "labels": [], "entities": [{"text": "iHOP", "start_pos": 13, "end_pos": 17, "type": "DATASET", "confidence": 0.929824709892273}, {"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9310033917427063}]}, {"text": "Named entities are of course only sometimes identical in scope with noun phrases.", "labels": [], "entities": []}, {"text": "Often they are embedded within highly complex noun phrases.", "labels": [], "entities": []}, {"text": "Nevertheless, the simple detection of a name by itself can be valuable.", "labels": [], "entities": [{"text": "detection of a name", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.8090835809707642}]}, {"text": "This depends in part on the intended application.", "labels": [], "entities": []}, {"text": "Thus, iHOP uses gene and protein names to hyperlink sentences from Medline and this then supports a browser over those sentences with additional navigation facilities.", "labels": [], "entities": [{"text": "Medline", "start_pos": 67, "end_pos": 74, "type": "DATASET", "confidence": 0.9295681715011597}]}, {"text": "Clicking on Dpp whilst viewing a page of information about hedgehog leads to a page of information about Dpp in which sentences that relate both Dpp and hedgehog are prioritized.", "labels": [], "entities": []}, {"text": "One of the application advantages of iHOP is that the discovered gene names are presented to the user in their original context and this enables users to compensate for problems in reliability and/or contextual relevance.", "labels": [], "entities": []}, {"text": "In many Information Extraction (IE) systems, relations between entities are detected and extracted into a table.", "labels": [], "entities": [{"text": "Information Extraction (IE)", "start_pos": 8, "end_pos": 35, "type": "TASK", "confidence": 0.8473695993423462}]}, {"text": "In this case, since the im-mediate surrounding context of the gene name maybe simply lost, the reliability of the original identification becomes much more important.", "labels": [], "entities": [{"text": "reliability", "start_pos": 95, "end_pos": 106, "type": "METRIC", "confidence": 0.9849309921264648}]}, {"text": "In section 2 below, we explain our own application background in which our objective is to increase the productivity of human curators whose task is to read particular scientific papers and fill in fields of a database of information about genes.", "labels": [], "entities": []}, {"text": "Directing curators' attention to sentences which contain gene names is clearly one step.", "labels": [], "entities": [{"text": "Directing curators' attention to sentences which contain gene names", "start_pos": 0, "end_pos": 67, "type": "TASK", "confidence": 0.7300620741314359}]}, {"text": "Curators additionally report that an index into the paper that uses the gene name and its embedding baseNP is even more valuable (reference omitted for anonymity).", "labels": [], "entities": []}, {"text": "This often enables them to predict the possible relevance of the name occurrence to the curation task and thus begin ordering their exploration of the paper.", "labels": [], "entities": []}, {"text": "Consequently, our technical goal of baseNP detection is linked directly to a valuable application task.", "labels": [], "entities": [{"text": "baseNP detection", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.8091581165790558}]}, {"text": "We also use the baseNP identification in order to type the occurrence semantically and use this information in an anaphora resolution process).", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 114, "end_pos": 133, "type": "TASK", "confidence": 0.747740626335144}]}, {"text": "The detection of baseNPs that contain a named entity is a super-task of NER, as well as a sub-task of NP-chunking.", "labels": [], "entities": [{"text": "NER", "start_pos": 72, "end_pos": 75, "type": "DATASET", "confidence": 0.601563572883606}]}, {"text": "Given that NER is clearly a domain specific task, it is an interesting question what performance levels are achievable using domain trained NER in combination with general purpose linguistic processing modules.", "labels": [], "entities": [{"text": "NER", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9596415758132935}]}, {"text": "There is a further motivation for the task.", "labels": [], "entities": []}, {"text": "The distinction between a named entity and an embedding noun phrase is one with critical importance even for the sub-task of NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 125, "end_pos": 128, "type": "TASK", "confidence": 0.9141160249710083}]}, {"text": "conclude, from their analysis of a multi-feature maximum entropy NER module, that increases in performance of biomedical NER systems will depend as much upon qualitative improvements in annotated data as in the technology underlying the systems.", "labels": [], "entities": []}, {"text": "The claim is that quality problems are partly due to confusion over what lies in the scope of a named entity and what lies at higher syntactic levels.", "labels": [], "entities": []}, {"text": "Current biomedical annotations are often inconsistent partly because annotators are left with little guidance on how to handle complexities in noun phrases, especially with respect to premodifiers and conjunctions.", "labels": [], "entities": []}, {"text": "For example, which premodifiers are part of the named entity and which are \"merely\" part of the embedding noun phrase?", "labels": [], "entities": []}, {"text": "Is human part of the named entity in the regulation of human interleukin-2 gene expression, By focussing attention instead on the baseNPs that contain a named entity, one can clearly sidestep this issue to some extent.", "labels": [], "entities": []}, {"text": "After all, increasing the accuracy of an NER module with respect to premodifier inclusion is unlikely to affect the overall accuracy of detection of the embedding noun phrases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9991351962089539}, {"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9988619089126587}]}], "datasetContent": [{"text": "POS tagging errors naturally affect the performance of both shallow and full parsing systems, though not necessarily equally.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.844216525554657}]}, {"text": "For example, the tagger in the shallow system tags ectopic as a verb in vnd-expression leads to ectopic Nk6 expression and this is not corrected by the retagging module because ectopic is not part of the gene name.", "labels": [], "entities": []}, {"text": "Consequently the baseNP spotter is led into a left boundary error.", "labels": [], "entities": [{"text": "baseNP spotter", "start_pos": 17, "end_pos": 31, "type": "TASK", "confidence": 0.5430085510015488}]}, {"text": "Nevertheless, the distribution of baseNPs from the two systems do appear to be complementary in a rather deeper fashion.", "labels": [], "entities": []}, {"text": "Analysis of the results indicates that parentheticals in pre-modifier positions appears to throw the shallow parser severely off course.", "labels": [], "entities": []}, {"text": "For example, it generates the analysis indicates the advantages to be gained in nbest selection.", "labels": [], "entities": []}, {"text": "The entries for full and retag+full are repeated from: Effects of n-best selection for full+sel and retag+full+sel show the effect of adding n-best selection.", "labels": [], "entities": []}, {"text": "The entries for full+oracle and retag+full+oracle show the maximum achievable performance by replacing the actual selection policy with an oracle that always chooses the correct hypothesis, if it is available.", "labels": [], "entities": []}, {"text": "The results are that, regardless of whether a retagging policy is adopted, an oracle which selects the best analysis can achieve an error reduction of well over 25%.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 132, "end_pos": 147, "type": "METRIC", "confidence": 0.9780034124851227}]}, {"text": "Furthermore, the simple selection policy outlined before succeeds in achieving almost half the possible error reduction available.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 104, "end_pos": 119, "type": "METRIC", "confidence": 0.9609711170196533}]}, {"text": "This result is particularly interesting because it demonstrates that the extra knowledge source available in this baseNP detection task (namely NER) can profitably be brought to bear at more than one stage in the overall processing pipeline.", "labels": [], "entities": [{"text": "baseNP detection task", "start_pos": 114, "end_pos": 135, "type": "TASK", "confidence": 0.7705429196357727}]}, {"text": "Even when NER has been used to improve the sequence of POS tags given to the parser, it can profitably be exploited again when selecting between parses.", "labels": [], "entities": []}, {"text": "The complementary nature of the two systems is revealed in which shows the effects of integrating the two parsers.", "labels": [], "entities": []}, {"text": "baseNPs from the shallow parser are accepted whenever it hypothesizes one and there is no competing overlapping baseNP from the full parser.", "labels": [], "entities": []}, {"text": "Note that this is rather different from the standard method of simply selecting between an analysis from the one parser and one from another.", "labels": [], "entities": []}, {"text": "The success of this policy reflects the fact that there remain several cases where the full parser fails to deliver \"apparently\" simple baseNPs either because the tagger has failed to generate a suitable hypothesis, or because parsing itself fails to find a good enough analysis in the time available to it.", "labels": [], "entities": []}, {"text": "Overall, the best results (87.17% F-score) are obtained by applying NER results both before parsing through the update of POS tags and after it in se-: Combining shallow and full parsing lection from n-best lists; and by combining the results of both full parsing in order to improve analysis of more complex structures and shallow parsing as a back-off strategy.", "labels": [], "entities": [{"text": "F-score", "start_pos": 34, "end_pos": 41, "type": "METRIC", "confidence": 0.9990270137786865}]}, {"text": "The same strategy applied using our automated gene name recognizer results in a F-score of 73.6% F-score, which is considerably less of course, although the gene name recognizer itself operates at 82.5% F-Score, with similar precision and recall figures.", "labels": [], "entities": [{"text": "gene name recognizer", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.6740657687187195}, {"text": "F-score", "start_pos": 80, "end_pos": 87, "type": "METRIC", "confidence": 0.9995168447494507}, {"text": "F-score", "start_pos": 97, "end_pos": 104, "type": "METRIC", "confidence": 0.9985669255256653}, {"text": "gene name recognizer", "start_pos": 157, "end_pos": 177, "type": "TASK", "confidence": 0.6778286894162496}, {"text": "F-Score", "start_pos": 203, "end_pos": 210, "type": "METRIC", "confidence": 0.9934004545211792}, {"text": "precision", "start_pos": 225, "end_pos": 234, "type": "METRIC", "confidence": 0.9995054006576538}, {"text": "recall", "start_pos": 239, "end_pos": 245, "type": "METRIC", "confidence": 0.999279797077179}]}, {"text": "This naturally limits the possible performance of our baseNP recognition task.", "labels": [], "entities": [{"text": "baseNP recognition task", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.7754447758197784}]}, {"text": "Encouragingly, the \"lost\" performance (just under 11%) is actually less in this scenario than when gene name recognition is perfect.", "labels": [], "entities": [{"text": "gene name recognition", "start_pos": 99, "end_pos": 120, "type": "TASK", "confidence": 0.6687787572542826}]}], "tableCaptions": [{"text": " Table 1: Generic shallow parsing", "labels": [], "entities": [{"text": "Generic shallow parsing", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.6962804992993673}]}, {"text": " Table 3: F-scores for baseNP detection for various \u03bb", "labels": [], "entities": [{"text": "F-scores", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9948746562004089}, {"text": "baseNP detection", "start_pos": 23, "end_pos": 39, "type": "TASK", "confidence": 0.7012432962656021}]}, {"text": " Table 4: Effects of n-best selection", "labels": [], "entities": []}, {"text": " Table 5: Combining shallow and full parsing", "labels": [], "entities": [{"text": "parsing", "start_pos": 37, "end_pos": 44, "type": "TASK", "confidence": 0.6869459748268127}]}]}