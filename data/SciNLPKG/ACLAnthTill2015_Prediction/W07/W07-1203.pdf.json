{"title": [{"text": "Filling Statistics with Linguistics - Property Design for the Disambiguation of German LFG Parses", "labels": [], "entities": [{"text": "German LFG Parses", "start_pos": 80, "end_pos": 97, "type": "DATASET", "confidence": 0.5779947936534882}]}], "abstractContent": [{"text": "We present a log-linear model for the disam-biguation of the analyses produced by a Ger-man broad-coverage LFG, focussing on the properties (or features) this model is based on.", "labels": [], "entities": []}, {"text": "We compare this model to an initial model based only on apart of the properties provided to the final model and observe that the performance of a log-linear model for parse selection depends heavily on the types of properties that it is based on.", "labels": [], "entities": [{"text": "parse selection", "start_pos": 167, "end_pos": 182, "type": "TASK", "confidence": 0.9486876726150513}]}, {"text": "In our case, the error reduction achieved with the log-linear model based on the extended set of properties is 51.0% and thus compares very favorably to the error reduction of 34.5% achieved with the initial model.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 17, "end_pos": 32, "type": "METRIC", "confidence": 0.978805273771286}, {"text": "error reduction", "start_pos": 157, "end_pos": 172, "type": "METRIC", "confidence": 0.9082822799682617}]}], "introductionContent": [{"text": "In the development of stochastic disambiguation modules for 'deep' grammars, relatively much work has gone into the definition of suitable probability models and the corresponding learning algorithms.", "labels": [], "entities": []}, {"text": "Property design, on the contrary, has rather been underemphasized, and the properties used in stochastic disambiguation modules are most often presented only superficially.", "labels": [], "entities": [{"text": "Property design", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7710640132427216}]}, {"text": "This paper's aim is to draw more attention to property design by presenting linguistically motivated properties that are used for the disambiguation of the analyses produced by a German broad-coverage LFG and by showing that property design is of crucial importance for the quality of stochastic models for parse selection.", "labels": [], "entities": [{"text": "property design", "start_pos": 46, "end_pos": 61, "type": "TASK", "confidence": 0.7057301551103592}, {"text": "parse selection", "start_pos": 307, "end_pos": 322, "type": "TASK", "confidence": 0.956410825252533}]}, {"text": "We present, in Section 2, the system that the disambiguation module was developed for as well as the initially used properties.", "labels": [], "entities": []}, {"text": "In Section 3, we then present a selection of the properties that were expressly designed for the resolution of frequent ambiguities in German LFG parses.", "labels": [], "entities": [{"text": "resolution of frequent ambiguities in German LFG parses", "start_pos": 97, "end_pos": 152, "type": "TASK", "confidence": 0.6556534320116043}]}, {"text": "Section 4 describes experiments that we carried outwith log-linear models based on the initial set of properties and on an extended one.", "labels": [], "entities": []}], "datasetContent": [{"text": "The overall results in terms of F-score and error reduction, defined as , that the four resulting systems achieve on our test set of 1,497 TiGer DB structures are shown in.", "labels": [], "entities": [{"text": "F-score", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.9985777139663696}, {"text": "error reduction", "start_pos": 44, "end_pos": 59, "type": "METRIC", "confidence": 0.9438841342926025}]}, {"text": "In order to give the reader an idea of the size of the different models, we also indicate the number of properties that they are based on.", "labels": [], "entities": []}, {"text": "All of the F-scores were calculated by means of the evaluation software by . We observe that the models obtained using property selection and regularization, in addition to being much more compact than their unregularized counterparts, perform significantly better than these.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9841459393501282}]}, {"text": "More importantly though, we can see that the most important improvement, namely from an error reduction of 32.5% to one of 42.0% or from 34.8% to 51.0% respectively, is achieved by adding more informative properties to the model.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 88, "end_pos": 103, "type": "METRIC", "confidence": 0.9791572093963623}]}, {"text": "then shows results broken down according to individual dependencies that are achieved with, on the one hand, the best-performing model based on both the XLE template-based and the newly in-: Overall F-score and corresponding error reduction achieved by the four different systems on the 1,497 TiGer DB structures of our test set troduced properties and, on the other hand, the bestperforming model based on XLE template-based properties only.", "labels": [], "entities": [{"text": "F-score", "start_pos": 199, "end_pos": 206, "type": "METRIC", "confidence": 0.9984840750694275}, {"text": "error reduction", "start_pos": 225, "end_pos": 240, "type": "METRIC", "confidence": 0.9456924200057983}]}, {"text": "Furthermore, we indicate the respective upper and lower bound F-scores, determined by the best possible parse selection and by an arbitrary selection respectively.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9937080144882202}]}, {"text": "We observe that the overall F-score is significantly better with a selection based on the model that includes the newly introduced properties than with a selection based on the model that relies on the XLE template-based properties only; overall error reduction increases from 34.5% to 51.0%.", "labels": [], "entities": [{"text": "F-score", "start_pos": 28, "end_pos": 35, "type": "METRIC", "confidence": 0.9987902045249939}, {"text": "error reduction", "start_pos": 246, "end_pos": 261, "type": "METRIC", "confidence": 0.9706391394138336}]}, {"text": "What is particularly interesting is the considerably better error reduction for the core grammatical functions sb (subject) and oa (accusative object).", "labels": [], "entities": [{"text": "error reduction", "start_pos": 60, "end_pos": 75, "type": "METRIC", "confidence": 0.9229666292667389}]}, {"text": "But also for rcs (relative clauses) and mos (modifiers or adjuncts), which are notoriously difficult for disambiguation due to PP and ADVP attachment ambiguities, we observe an improvement in F-score.", "labels": [], "entities": [{"text": "F-score", "start_pos": 192, "end_pos": 199, "type": "METRIC", "confidence": 0.9973044395446777}]}, {"text": "Our error reduction of 51.0% also compares favorably to the 36% error reduction on English LFG parses reported in . However, it is considerably lower than the error reduction of 78% reported for the Dutch Alpino parser), but this maybe due to the fact that our lower bound is calculated on the basis of analyses that have already passed a prefilter and is thus relatively high.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 4, "end_pos": 19, "type": "METRIC", "confidence": 0.9893290996551514}, {"text": "error reduction", "start_pos": 159, "end_pos": 174, "type": "METRIC", "confidence": 0.9655041992664337}]}], "tableCaptions": [{"text": " Table 1: Overall F-score and corresponding error re- duction achieved by the four different systems on the  1,497 TiGer DB structures of our test set", "labels": [], "entities": [{"text": "F-score", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.9981368780136108}, {"text": "error re- duction", "start_pos": 44, "end_pos": 61, "type": "METRIC", "confidence": 0.8311550691723824}, {"text": "TiGer DB structures of our test set", "start_pos": 115, "end_pos": 150, "type": "DATASET", "confidence": 0.8231994083949498}]}]}