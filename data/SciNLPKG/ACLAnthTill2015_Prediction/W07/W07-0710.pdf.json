{"title": [{"text": "Training Non-Parametric Features for Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 37, "end_pos": 68, "type": "TASK", "confidence": 0.8294939200083414}]}], "abstractContent": [{"text": "Modern statistical machine translation systems maybe seen as using two components: feature extraction, that summarizes information about the translation, and a log-linear framework to combine features.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 7, "end_pos": 38, "type": "TASK", "confidence": 0.6365923682848612}, {"text": "feature extraction", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.7013556957244873}]}, {"text": "In this paper , we propose to relax the linearity constraints on the combination, and hence relaxing constraints of monotonicity and independence of feature functions.", "labels": [], "entities": []}, {"text": "We expand features into a non-parametric, non-linear, and high-dimensional space.", "labels": [], "entities": []}, {"text": "We extend empirical Bayes reward training of model parameters to meta parameters of feature generation.", "labels": [], "entities": [{"text": "feature generation", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.7573594152927399}]}, {"text": "In effect, this allows us to trade away some human expert feature design for data.", "labels": [], "entities": []}, {"text": "Preliminary results on a standard task show an encouraging improvement.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, statistical machine translation have experienced a quantum leap in quality thanks to automatic evaluation () and errorbased optimization.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 17, "end_pos": 48, "type": "TASK", "confidence": 0.744783878326416}]}, {"text": "The conditional log-linear feature combination framework) is remarkably simple and effective in practice.", "labels": [], "entities": []}, {"text": "Therefore, recent efforts) have concentrated on feature design -wherein more intelligent features maybe added.", "labels": [], "entities": [{"text": "feature design", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.7777319848537445}]}, {"text": "Because of their simplicity, however, log-linear models impose some constraints on how new information maybe inserted into the system to achieve the best results.", "labels": [], "entities": []}, {"text": "In other words, new information needs to be parameterized carefully into one or more real valued feature functions.", "labels": [], "entities": []}, {"text": "Therefore, that requires some human knowledge and understanding.", "labels": [], "entities": []}, {"text": "When not readily available, this is typically replaced with painstaking experimentation.", "labels": [], "entities": []}, {"text": "We propose to replace that step with automatic training of non-parametric agnostic features instead, hopefully relieving the burden of finding the optimal parameterization.", "labels": [], "entities": []}, {"text": "First, we define the model and the objective function training framework, then we describe our new non-parametric features.", "labels": [], "entities": []}], "datasetContent": [{"text": "The BLEU score () was defined to measure overlap between a hypothesized translation and a set of human references.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9856129884719849}]}, {"text": "n-gram overlap counts {c n } 4 n=1 are computed over the test set sentences, and compared to the total counts of n-grams in the hypothesis: Those quantities are abbreviated ck and a k to simplify the notation.", "labels": [], "entities": []}, {"text": "The precision ratio P n for an ngram order n is: A brevity penalty BP is also taken into account, to avoid favoring overly short sentences: where r is the average length of the shortest sentence 1 , and a is the average length of hypotheses.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9984754920005798}, {"text": "BP", "start_pos": 67, "end_pos": 69, "type": "METRIC", "confidence": 0.9762561917304993}]}, {"text": "The BLEU score the set of hypotheses {e B({e 1 As implemented by NIST mteval-v11b.pl.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.998611569404602}, {"text": "NIST mteval-v11b.pl", "start_pos": 65, "end_pos": 84, "type": "DATASET", "confidence": 0.8445423543453217}]}, {"text": "Oracle BLEU hypothesis: There is no easy way to pick the set hypotheses from an n-best list that will maximize the overall BLEU score.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.9336296319961548}, {"text": "BLEU", "start_pos": 123, "end_pos": 127, "type": "METRIC", "confidence": 0.9981632828712463}]}, {"text": "Instead, to compute oracle BLEU hypotheses, we chose, for each sentence independently, the hypothesis with the highest BLEU score computed fora sentence itself.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.9889649152755737}, {"text": "BLEU score", "start_pos": 119, "end_pos": 129, "type": "METRIC", "confidence": 0.9770892262458801}]}, {"text": "We believe that it is a relatively tight lower bound and equal for practical purposes to the true oracle BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 105, "end_pos": 109, "type": "METRIC", "confidence": 0.9923485517501831}]}, {"text": "For our experiments, we used the standard NIST MT-02 data set to evaluate our system.", "labels": [], "entities": [{"text": "NIST MT-02 data set", "start_pos": 42, "end_pos": 61, "type": "DATASET", "confidence": 0.8992756009101868}]}], "tableCaptions": [{"text": " Table 1: BLEU scores for GMM features vs the lin- ear baseline, using different selection methods and  number of kernels.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9985454082489014}]}]}