{"title": [{"text": "Hunting Elusive Metaphors Using Lexical Resources", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we propose algorithms to automatically classify sentences into metaphoric or normal usages.", "labels": [], "entities": [{"text": "classify sentences into metaphoric or normal usages", "start_pos": 53, "end_pos": 104, "type": "TASK", "confidence": 0.6742663638932365}]}, {"text": "Our algorithms only need the WordNet and bigram counts, and does not require training.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 29, "end_pos": 36, "type": "DATASET", "confidence": 0.9682609438896179}]}, {"text": "We present empirical results on a test set derived from the Master Metaphor List.", "labels": [], "entities": [{"text": "Master Metaphor List", "start_pos": 60, "end_pos": 80, "type": "DATASET", "confidence": 0.8855977654457092}]}, {"text": "We also discuss issues that make classification of metaphors a tough problem in general.", "labels": [], "entities": [{"text": "classification of metaphors", "start_pos": 33, "end_pos": 60, "type": "TASK", "confidence": 0.867253581682841}]}], "introductionContent": [{"text": "Metaphor is an interesting figure of speech which expresses an analogy between two seemingly unrelated concepts.", "labels": [], "entities": []}, {"text": "Metaphoric usages enhance the attributes of the source concept by comparing it with the attributes of the target concept.", "labels": [], "entities": []}, {"text": "Abstractions and enormously complex situations are routinely understood via metaphors).", "labels": [], "entities": []}, {"text": "Metaphors begin their lives as Novel Poetic Creations with marked rhetoric effects whose comprehension requires special imaginative leap.", "labels": [], "entities": []}, {"text": "As time goes by, they become part of general use and their comprehension becomes automatic and idiomatic and rhetoric effect is dulled.", "labels": [], "entities": []}, {"text": "We term such metaphors whose idiomatic effects are dulled because of common usage as dead metaphors while metaphors with novel usages as live metaphors.", "labels": [], "entities": []}, {"text": "In this paper we are interested only in identifying live metaphors.", "labels": [], "entities": [{"text": "identifying live metaphors", "start_pos": 40, "end_pos": 66, "type": "TASK", "confidence": 0.7564358711242676}]}, {"text": "Metaphors have interesting applications in many NLP problems like machine translation, text summarization, information retrieval and question answering.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.8187828660011292}, {"text": "text summarization", "start_pos": 87, "end_pos": 105, "type": "TASK", "confidence": 0.7867767512798309}, {"text": "information retrieval", "start_pos": 107, "end_pos": 128, "type": "TASK", "confidence": 0.8335667252540588}, {"text": "question answering", "start_pos": 133, "end_pos": 151, "type": "TASK", "confidence": 0.9125545024871826}]}, {"text": "Consider the task of summarizing a parable which is a metaphoric story with amoral.", "labels": [], "entities": [{"text": "summarizing a parable", "start_pos": 21, "end_pos": 42, "type": "TASK", "confidence": 0.8598297635714213}]}, {"text": "The best summary of a parable is the moral.", "labels": [], "entities": []}, {"text": "Paraphrasing a metaphoric passage like a parable is difficult without understanding the metaphoric uses.", "labels": [], "entities": [{"text": "Paraphrasing a metaphoric passage", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.874576136469841}]}, {"text": "The performance of the conventional summarizing systems will be ineffective because they cannot identify such metaphoric usages.", "labels": [], "entities": [{"text": "summarizing", "start_pos": 36, "end_pos": 47, "type": "TASK", "confidence": 0.9750372171401978}]}, {"text": "Also it is easy to create novel and interesting uses of metaphors as long as one concept is explained in terms of another concept.", "labels": [], "entities": []}, {"text": "The performance of machine translation systems will be affected in such cases especially if they have not encountered such metaphoric uses before.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.7519591152667999}]}, {"text": "Metaphor identification in text documents is, however, complicated by issues including context sensitiveness, emergence of novel metaphoric forms, and the need for semantic knowledge about the sentences.", "labels": [], "entities": [{"text": "Metaphor identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9557746052742004}]}, {"text": "Metaphoric appeal differs across language or people's prior exposure to such usages.", "labels": [], "entities": [{"text": "Metaphoric appeal", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7746951878070831}]}, {"text": "In addition, as points out, literal and figurative expressions are end points of a single continuum along which metaphoricity and idiomaticity are situated, thereby making clear demarcation of metaphoric and normal usages fuzzy.", "labels": [], "entities": []}, {"text": "We discuss many such issues that make the task of classifying sentences into metaphoric or nonmetaphoric difficult.", "labels": [], "entities": [{"text": "classifying sentences into metaphoric", "start_pos": 50, "end_pos": 87, "type": "TASK", "confidence": 0.8245257437229156}]}, {"text": "We then focuses on a subset of metaphoric usages involving the nouns in a sentence.", "labels": [], "entities": []}, {"text": "In particular, we identify the subjectobject, verb-noun and adjective-noun relationships in sentences and classify them as metaphoric or non-metaphoric.", "labels": [], "entities": []}, {"text": "Extensions to other metaphoric types will be part of future work.", "labels": [], "entities": []}, {"text": "Our algorithms use the hyponym relationship in WordNet, and word bigram counts, to predict the metaphors.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 47, "end_pos": 54, "type": "DATASET", "confidence": 0.9592131972312927}]}, {"text": "In doing so we circumvent two issues: the absence of labeled training data, and the lack of clear features that are indicative of metaphors.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents interesting observations that were made during the initial survey, and presents examples that makes metaphor identification hard.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 119, "end_pos": 142, "type": "TASK", "confidence": 0.9533504247665405}]}, {"text": "Section 3 discusses our main techniques for identifying metaphors in text documents.", "labels": [], "entities": [{"text": "identifying metaphors in text documents", "start_pos": 44, "end_pos": 83, "type": "TASK", "confidence": 0.8896062970161438}]}, {"text": "Section 4 analyzes the effect of the techniques.", "labels": [], "entities": []}, {"text": "Section 5 discusses relevant prior work in the area of metaphor processing and identification.", "labels": [], "entities": [{"text": "metaphor processing and identification", "start_pos": 55, "end_pos": 93, "type": "TASK", "confidence": 0.8331347852945328}]}, {"text": "Finally we conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We experimented with the Berkeley Master Metaphor List ( to compute the performance of our techniques.", "labels": [], "entities": [{"text": "Berkeley Master Metaphor List", "start_pos": 25, "end_pos": 54, "type": "DATASET", "confidence": 0.8456404954195023}]}, {"text": "The Berkeley Master Metaphor List is a collection of nearly 1728 unique sentences and phrases.", "labels": [], "entities": [{"text": "Berkeley Master Metaphor List", "start_pos": 4, "end_pos": 33, "type": "DATASET", "confidence": 0.9004991799592972}]}, {"text": "We corrected some typos and spelling errors in the Master list and expanded phrases to complete sentences.", "labels": [], "entities": [{"text": "Master list", "start_pos": 51, "end_pos": 62, "type": "DATASET", "confidence": 0.9181522727012634}]}, {"text": "The list has many metaphoric uses which has become very common usages in today's standards, and thus no longer have any rhetoric effects.", "labels": [], "entities": []}, {"text": "Therefore, we manually label the sentences in the Master List into 789 'live metaphors' and the remaining ones 'dead metaphors' as the ground truth . shows the initial performance of the Type I algorithm.", "labels": [], "entities": []}, {"text": "There are 129 sentences in the Master List that contain subject-be-object form.", "labels": [], "entities": [{"text": "Master List", "start_pos": 31, "end_pos": 42, "type": "DATASET", "confidence": 0.8824413120746613}]}, {"text": "Our algorithm has a precision of 70% and a recall of 61% with respect to the live/dead labels.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9994722008705139}, {"text": "recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.9996551275253296}]}, {"text": "Note that although the accuracy is 58%, the algorithm is better than a random classification in terms of precision and recall.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.999731719493866}, {"text": "precision", "start_pos": 105, "end_pos": 114, "type": "METRIC", "confidence": 0.9995064735412598}, {"text": "recall", "start_pos": 119, "end_pos": 125, "type": "METRIC", "confidence": 0.998199462890625}]}, {"text": "One thing to note is that our negative examples are (subjectively labeled) dead metaphors.", "labels": [], "entities": []}, {"text": "We thus expect the task to be harder than with random non-metaphoric sentences.", "labels": [], "entities": []}, {"text": "Another point to note here is that the live/dead labels are on sentences and not on particular phrases with type I relations.", "labels": [], "entities": []}, {"text": "A sentence can contain more than one phrases with various types.", "labels": [], "entities": []}, {"text": "Therefore this result does not give a complete picture of our algorithm.", "labels": [], "entities": []}, {"text": "A few interesting metaphors detected by our algorithm are as follows: Lawyers are real sharks.", "labels": [], "entities": []}, {"text": "Smog pollution is an environmental malaise.", "labels": [], "entities": [{"text": "Smog pollution", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9683157205581665}]}, {"text": "Some false negatives are due to phrases qualifying the object of the sentence as in the following example, He is a budding artist.", "labels": [], "entities": []}, {"text": "There is a Type I relation in this sentence because the subject 'He' and the object 'artist' are related by the 'be' form verb 'is'.", "labels": [], "entities": []}, {"text": "In this case, the Type I algorithm compares the hyponyms relation between 'person' and 'artist' and declares it as a normal sentence.", "labels": [], "entities": []}, {"text": "However the adjective 'budding' adds Type III figurative meaning to this sentence.", "labels": [], "entities": []}, {"text": "Therefore although the Type I relation is normal, there are other features in the sentences that make it metaphoric.", "labels": [], "entities": []}, {"text": "We observed that most of false negatives that are wrongly classified because of the above reason have pronoun subject like 'he', 'she' etc.", "labels": [], "entities": []}, {"text": "Another major source of issue is the occurrences of pronoun 'it' which is hard to resolve.", "labels": [], "entities": []}, {"text": "We replaced it by 'entity', which is the root of WordNet, when comparing the hyponyms.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 49, "end_pos": 56, "type": "DATASET", "confidence": 0.9519214630126953}]}, {"text": "'Entity' matches the hyponym relation with any other noun and hence all these sentences with 'it' as the subject are classified as normal sentences.", "labels": [], "entities": []}, {"text": "shows the performance of our Type I algorithm for sentences with non-pronoun subjects.", "labels": [], "entities": []}, {"text": "It clearly shows that the performance in is affected by sentences with pronoun subjects as explained in the earlier paragraphs.", "labels": [], "entities": []}, {"text": "In some cases, prepositional phrases affects the performance of our algorithm.", "labels": [], "entities": []}, {"text": "Consider the following example, He is the child of evil.", "labels": [], "entities": []}, {"text": "Here the phrase 'child of evil' is metaphoric.", "labels": [], "entities": []}, {"text": "But the parser identifies a subject-be-object relationship between 'He' and 'child' and our algorithm compares the hyponym relation between 'person' and 'child' and declares it as a normal sentence.", "labels": [], "entities": []}, {"text": "Our current algorithm does not deal with cases like the following example The customer is a scientist. vs. The customer is king.", "labels": [], "entities": []}, {"text": "Since there is no direct hyponym relation between scientist/king with customer we declare both these sentences as metaphors although only the latter is.", "labels": [], "entities": []}, {"text": "Unlike the algorithm for Type I, there is a threshold T to beset for Type II and III algorithm.", "labels": [], "entities": [{"text": "Type I", "start_pos": 25, "end_pos": 31, "type": "TASK", "confidence": 0.870505303144455}]}, {"text": "By changing T , we are able to plot a precision recall curve.", "labels": [], "entities": [{"text": "T", "start_pos": 12, "end_pos": 13, "type": "METRIC", "confidence": 0.9788329005241394}, {"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9992825388908386}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.8755154609680176}]}, {"text": "show the precision recall graph for Type II and Type III relations respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.9983810186386108}, {"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.7260461449623108}]}, {"text": "shows the overall precision recall graph for all three types put together.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9993599057197571}, {"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.8659864664077759}]}, {"text": "False positives in Type II and Type III were due to very general verbs and adjectives.", "labels": [], "entities": [{"text": "False positives", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.9349858164787292}]}, {"text": "These verbs and adjectives can occur with a large number of nouns, and tend to produce low conditional probabilities even for normal nouns.", "labels": [], "entities": []}, {"text": "Thereby they are often mistakenly classified as metaphoric relations.", "labels": [], "entities": []}, {"text": "We expect the performance to improve if these general verbs and adjectives are handled properly.", "labels": [], "entities": []}, {"text": "Some general verbs include 'gave', 'made', 'has', etc., and similarity general adjectives include 'new', 'good', 'many', 'more', etc.", "labels": [], "entities": []}, {"text": "The plot for Type III is more random.", "labels": [], "entities": [{"text": "Type III", "start_pos": 13, "end_pos": 21, "type": "TASK", "confidence": 0.7687654495239258}]}, {"text": "Most errors can be attributed to some of the following reasons: \u2022 As mentioned in the challenges section, the parser is not very accurate.", "labels": [], "entities": []}, {"text": "For example, They battled each other over the chessboard every week.", "labels": [], "entities": []}, {"text": "Here the parser identifies the verb-object relation as ( battled , week ), which is not correct.", "labels": [], "entities": []}, {"text": "\u2022 Pronoun resolution: As discussed earlier, the pronoun 'it' is not resolved and hence they introduce additional source of errors.", "labels": [], "entities": [{"text": "Pronoun resolution", "start_pos": 2, "end_pos": 20, "type": "TASK", "confidence": 0.8085611462593079}]}, {"text": "\u2022 Manual annotations could be wrong.", "labels": [], "entities": []}, {"text": "In our experiment we have used only two annotators, but having more would have increased the confidence in the labels.", "labels": [], "entities": []}, {"text": "\u2022 Many of the verb-noun forms are most naturally captured by trigrams instead of bigram.", "labels": [], "entities": []}, {"text": "For example, (developed , attachment) most likely occurs in a corpus as 'developed an attachment' or 'developed the attachment'.", "labels": [], "entities": []}, {"text": "Our bigram approach can fail here.", "labels": [], "entities": []}, {"text": "\u2022 Sense disambiguation: We don't disambiguate senses while comparing the WordNet relations.", "labels": [], "entities": [{"text": "Sense disambiguation", "start_pos": 2, "end_pos": 22, "type": "TASK", "confidence": 0.699842095375061}]}, {"text": "This increases our false negatives.", "labels": [], "entities": [{"text": "false negatives", "start_pos": 19, "end_pos": 34, "type": "METRIC", "confidence": 0.9412521421909332}]}, {"text": "\u2022 Also as mentioned earlier, the labels are on sentences and not on the typed relationships.", "labels": [], "entities": []}, {"text": "Therefore even though a sentence has one or more of the noun form types, those maybe normal relationships while the whole sentence maybe metaphoric because of other types.", "labels": [], "entities": []}, {"text": "Note, however, that some of these mismatches are corrected for the 'All types combined' result.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Type I Performance  Predicted as Predicted as  Metaphoric  Normal  Annotated as live  50  32  Annotated as dead  22  25", "labels": [], "entities": []}, {"text": " Table 3: Type I Performance for sentences with non- pronoun subject  Predicted as Predicted as  Metaphoric  Normal  Annotated as live  40  1  Annotated as dead  19  4", "labels": [], "entities": []}]}