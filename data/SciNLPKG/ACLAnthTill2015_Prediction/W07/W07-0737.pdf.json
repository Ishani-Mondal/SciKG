{"title": [], "abstractContent": [{"text": "This paper studies the impact that difficult-to-translate source-language phrases might have on the machine translation process.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 100, "end_pos": 119, "type": "TASK", "confidence": 0.8137056529521942}]}, {"text": "We formulate the notion of difficulty as a measurable quantity; we show that a classifier can be trained to predict whether a phrase might be difficult to translate; and we develop a framework that makes use of the classifier and external resources (such as human translators) to improve the overall translation quality.", "labels": [], "entities": []}, {"text": "Through experimental work, we verify that by isolating difficult-to-translate phrases and processing them as special cases, their negative impact on the translation of the rest of the sentences can be reduced.", "labels": [], "entities": []}], "introductionContent": [{"text": "For translators, not all source sentences are created equal.", "labels": [], "entities": []}, {"text": "Some are straight-forward enough to be automatically translated by a machine, while others may stump even professional human translators.", "labels": [], "entities": []}, {"text": "Similarly, within a single sentence there maybe some phrases that are more difficult to translate than others.", "labels": [], "entities": []}, {"text": "The focus of this paper is on identifying Difficult-to-Translate Phrases (DTPs) within a source sentence and determining their impact on the translation process.", "labels": [], "entities": [{"text": "identifying Difficult-to-Translate Phrases (DTPs) within a source sentence", "start_pos": 30, "end_pos": 104, "type": "TASK", "confidence": 0.7752276122570038}, {"text": "translation process", "start_pos": 141, "end_pos": 160, "type": "TASK", "confidence": 0.8993168473243713}]}, {"text": "We investigate three questions: (1) how should we formalize the notion of difficulty as a measurable quantity over an appropriately defined phrasal unit?", "labels": [], "entities": []}, {"text": "To what level of accuracy can we automatically identify DTPs?", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9989380240440369}]}, {"text": "To what extent do DTPs affect an MT system's performance on other (not-as-difficult) parts of the sentence?", "labels": [], "entities": [{"text": "MT", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.9798643589019775}]}, {"text": "Conversely, would knowing the correct translation for the DTPs improve the system's translation for the rest of the sentence?", "labels": [], "entities": []}, {"text": "In this work, we model difficulty as a measurement with respect to a particular MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 80, "end_pos": 82, "type": "TASK", "confidence": 0.9677483439445496}]}, {"text": "We further assume that the degree of difficulty of a phrase is directly correlated with the quality of the translation produced by the MT system, which can be approximated using an automatic evaluation metric, such as BLEU ().", "labels": [], "entities": [{"text": "MT", "start_pos": 135, "end_pos": 137, "type": "TASK", "confidence": 0.9362432956695557}, {"text": "BLEU", "start_pos": 218, "end_pos": 222, "type": "METRIC", "confidence": 0.9982426166534424}]}, {"text": "Using this formulation of difficulty, we build a framework that augments an off-the-shelf phrasebased MT system with a DTP classifier that we developed.", "labels": [], "entities": []}, {"text": "We explore the three questions in a set of experiments, using the framework as a testbed.", "labels": [], "entities": []}, {"text": "In the first experiment, we verify that our proposed difficulty measurement is sensible.", "labels": [], "entities": []}, {"text": "The second experiment evaluates the classifier's accuracy in predicting whether a source phrase is a DTP.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9989088773727417}, {"text": "predicting whether a source phrase is a DTP", "start_pos": 61, "end_pos": 104, "type": "TASK", "confidence": 0.7623751685023308}]}, {"text": "For that, we train a binary SVM classifier via a series of lexical and system dependent features.", "labels": [], "entities": []}, {"text": "The third is an oracle study in which the DTPs are perfectly identified and human translations are obtained.", "labels": [], "entities": []}, {"text": "These human-translated phrases are then used to constrain the MT system as it translates the rest of the sentence.", "labels": [], "entities": [{"text": "MT", "start_pos": 62, "end_pos": 64, "type": "TASK", "confidence": 0.9782178997993469}]}, {"text": "We evaluate the translation quality of the entire sentence and also the parts that are not translated by humans.", "labels": [], "entities": []}, {"text": "Finally, the framework is evaluated as a whole.", "labels": [], "entities": []}, {"text": "Results from our experiments suggest that improved handling of DTPs will have a positive impact the overall MT output quality.", "labels": [], "entities": [{"text": "MT", "start_pos": 108, "end_pos": 110, "type": "TASK", "confidence": 0.9903073310852051}]}, {"text": "Moreover, we find the SVMtrained DTP classifier to have a promising rate of accuracy, and that the incorporation of DTP information can improve the outputs of the underlying MT system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9993405938148499}, {"text": "MT", "start_pos": 174, "end_pos": 176, "type": "TASK", "confidence": 0.954531192779541}]}, {"text": "Specifically, we achieve an improvement of translation quality for non-difficult seg-ments of a sentence when the DTPs are translated by humans.", "labels": [], "entities": []}], "datasetContent": [{"text": "The goal of these four experiments is to gain a better understanding of the DTPs and their impact on the translation process.", "labels": [], "entities": [{"text": "translation process", "start_pos": 105, "end_pos": 124, "type": "TASK", "confidence": 0.9001995325088501}]}, {"text": "All our studies are conducted for Arabic-to-English MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 52, "end_pos": 54, "type": "TASK", "confidence": 0.681149959564209}]}, {"text": "We formed a one-million word parallel text out of two corpora released by the Linguistic Data Consortium: Ara-bic News Translation Text Part 1 and Arabic English Parallel News Part 1.", "labels": [], "entities": [{"text": "Ara-bic News Translation Text Part", "start_pos": 106, "end_pos": 140, "type": "TASK", "confidence": 0.59686439037323}]}, {"text": "The majority of the data was used to train the underlying phrase-based MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 71, "end_pos": 73, "type": "TASK", "confidence": 0.8486887216567993}]}, {"text": "We reserve 2000 sentences for development and experimentation.", "labels": [], "entities": []}, {"text": "Half of these are used for the training and evaluation of the DTP classifier (Sections 4.1 and 4.2); the other half is used for translation experiments on the rest of the framework (Sections 4.3 and 4.4).", "labels": [], "entities": [{"text": "DTP", "start_pos": 62, "end_pos": 65, "type": "DATASET", "confidence": 0.8033776879310608}, {"text": "translation", "start_pos": 128, "end_pos": 139, "type": "TASK", "confidence": 0.9652175307273865}]}, {"text": "In both cases, translation phrases are extracted from the sentences and assigned \"gold standard\" labels according to the procedure described in Section 3.1.", "labels": [], "entities": [{"text": "translation phrases", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.9017168283462524}]}, {"text": "It is necessary to keep two separate datasets because the later experiments make use of the trained DTP classifier.", "labels": [], "entities": []}, {"text": "For the two translation experiments, we also face a practical obstacle: we do not have an army of human translators at our disposal to translate the identified phrases.", "labels": [], "entities": [{"text": "translation", "start_pos": 12, "end_pos": 23, "type": "TASK", "confidence": 0.9680151343345642}]}, {"text": "To make the studies possible, we rely on a pre-translated parallel corpus to simulate the process of asking a human to translate a phrase.", "labels": [], "entities": []}, {"text": "That is, we use the phrase extraction toolkit to find translation phrases corresponding to each DTP candidate (note that the data used for this experiment is separate from the main parallel corpus used to train the MT system, so the system has no knowledge about these translations).", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.7486665844917297}, {"text": "MT", "start_pos": 215, "end_pos": 217, "type": "TASK", "confidence": 0.9407297968864441}]}, {"text": "BLEU Baseline (no human trans) 24.0 w/ translated DTPs 39.6 w/ translated non-DTPs 33.7 w/ translated phrases (random) 35.1 w/ translated phrases (classifier) 37.0 While it is unsurprising that the inclusion of human translations increases the overall BLEU score, this comparison shows that the boost is sharper when more DTPs are translated.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9246821999549866}, {"text": "BLEU score", "start_pos": 252, "end_pos": 262, "type": "METRIC", "confidence": 0.97584667801857}]}, {"text": "This is consistent with our conjecture that pre-translating difficult phrases maybe helpful.", "labels": [], "entities": []}, {"text": "A more interesting question is whether the human translations still provide any benefit once we factor out their direct contributions to the increase in BLEU scores.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 153, "end_pos": 164, "type": "METRIC", "confidence": 0.9765417277812958}]}, {"text": "To answer this question, we compute the BLEU scores for the outputs again, this time filtering out all 484 identified phrases from the evaluation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9992961883544922}]}, {"text": "In other words in this experiment we focus on the part of the sentence that is not labeled and does include any human translations.", "labels": [], "entities": []}, {"text": "The largest gain (2.4 BLEU increment from baseline) occurs when all and only the DTPs were translated.", "labels": [], "entities": [{"text": "BLEU increment", "start_pos": 22, "end_pos": 36, "type": "METRIC", "confidence": 0.9648457765579224}]}, {"text": "In contrast, replacing phrases from Group II did not improve the BLEU score very much.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 65, "end_pos": 75, "type": "METRIC", "confidence": 0.9834631681442261}]}, {"text": "These results suggest that better handling of DTPs will have a positive effect on the overall MT process.", "labels": [], "entities": [{"text": "MT", "start_pos": 94, "end_pos": 96, "type": "TASK", "confidence": 0.9968029260635376}]}, {"text": "We also note that using our SVM-trained classifier to identify the DTPs, the constrained MT system's outputs obtained a BLEU score that is nearly as high as if a perfect classifier was used.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 120, "end_pos": 130, "type": "METRIC", "confidence": 0.9812963902950287}]}, {"text": "We now perform a local evaluation of the trained DTP classifier for its classification accuracy.", "labels": [], "entities": [{"text": "DTP classifier", "start_pos": 49, "end_pos": 63, "type": "TASK", "confidence": 0.5589365363121033}, {"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.957023561000824}]}, {"text": "The classifier is trained as an SVM using a linear kernel.", "labels": [], "entities": []}, {"text": "The \"gold standard\" phrases from the section 4.1 are split into three groups: 2013 instances are used as training data for the classifier; 100 instances are used for development (e.g., parameter tuning and feature engineering); and 200 instances are used as test instances.", "labels": [], "entities": [{"text": "parameter tuning", "start_pos": 185, "end_pos": 201, "type": "TASK", "confidence": 0.7987774014472961}, {"text": "feature engineering)", "start_pos": 206, "end_pos": 226, "type": "TASK", "confidence": 0.7999042173226675}]}, {"text": "The test set has an equal number of difficult and non-difficult phrases (50% baseline accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9228554368019104}]}, {"text": "In order to optimize the accuracy of classification, we used a development set for feature engineering and trying various SVM kernels and associated parameters.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9983590245246887}, {"text": "feature engineering", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.7515790164470673}]}, {"text": "For the feature engineering part, we used the all-but-one heuristic to test the contribution of each individual feature.", "labels": [], "entities": []}, {"text": "presents the most and least contributing four features that we used in our classification.", "labels": [], "entities": []}, {"text": "Among various features, we observed that the syntactic features are the most contributing sources of information for our classification.", "labels": [], "entities": []}, {"text": "The DTP classifier achieves an average accuracy of 71.5%, using 10 fold cross validation on the test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9993795156478882}]}, {"text": "This final experiment evaluates the complete framework as described in Section 3.", "labels": [], "entities": []}, {"text": "The setup of this study is similar to that of the previous section.", "labels": [], "entities": []}, {"text": "The main difference is that now, we rely on the classifier to predict which phrase would be the most difficult to translate and use human translations for those phrases.", "labels": [], "entities": []}, {"text": "Out of 1000 sentences, 356 have been identified to contain DTPs (that are in the phrase extraction list).", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 81, "end_pos": 98, "type": "TASK", "confidence": 0.7082321047782898}]}, {"text": "In other words, only 356 sentences hold DTPs that we can find their human translations through phrase projection.", "labels": [], "entities": [{"text": "phrase projection", "start_pos": 95, "end_pos": 112, "type": "TASK", "confidence": 0.703681081533432}]}, {"text": "For the remaining sentences, we do not use any human translation.: Evaluation of the subset of 356 sentences: both for the full sentence and for non-DTP parts, with and without human translation replacement of DTPs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Isolated Translation of the selected training  phrases", "labels": [], "entities": [{"text": "Isolated Translation", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.8150506913661957}]}, {"text": " Table 4: BLEU scores for the translation outputs ex- cluding the 484 (DTP and non-DTP) phrases.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9991143345832825}]}, {"text": " Table 5: Entire Corpus level evaluation (1000 sen- tences) when replacing DTPs in the hit list", "labels": [], "entities": [{"text": "Entire Corpus level evaluation", "start_pos": 10, "end_pos": 40, "type": "METRIC", "confidence": 0.8672820925712585}]}, {"text": " Table 6: Evaluation of the subset of 356 sentences: both  for the full sentence and for non-DTP parts, with and  without human translation replacement of DTPs.", "labels": [], "entities": []}]}