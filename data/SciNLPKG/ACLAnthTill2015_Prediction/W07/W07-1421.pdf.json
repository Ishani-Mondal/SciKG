{"title": [{"text": "Hypothesis Transformation and Semantic Variability Rules Used in Recognizing Textual Entailment", "labels": [], "entities": [{"text": "Recognizing Textual Entailment", "start_pos": 65, "end_pos": 95, "type": "TASK", "confidence": 0.8734109799067179}]}], "abstractContent": [{"text": "Based on the core approach of the tree edit distance algorithm, the system central module is designed to target the scope of TE-semantic variability.", "labels": [], "entities": [{"text": "TE-semantic variability", "start_pos": 125, "end_pos": 148, "type": "TASK", "confidence": 0.7515034675598145}]}, {"text": "The main idea is to transform the hypothesis making use of extensive semantic knowledge from sources like DIRT, WordNet, Wikipedia, acronyms database.", "labels": [], "entities": [{"text": "DIRT", "start_pos": 106, "end_pos": 110, "type": "DATASET", "confidence": 0.9357299208641052}, {"text": "WordNet", "start_pos": 112, "end_pos": 119, "type": "DATASET", "confidence": 0.8884113430976868}]}, {"text": "Additionally, we built a system to acquire the extra background knowledge needed and applied complex grammar rules for rephrasing in English.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many NLP applications need to recognize when the meaning of one text can be expressed by, or inferred from, another text.", "labels": [], "entities": []}, {"text": "Information Retrieval (IR), Question Answering (QA), Information Extraction (IE), Text Summarization (SUM) are examples of applications that need to assess such a semantic relationship between text segments.", "labels": [], "entities": [{"text": "Information Retrieval (IR)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8429511308670044}, {"text": "Question Answering (QA)", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.8333985269069671}, {"text": "Information Extraction (IE)", "start_pos": 53, "end_pos": 80, "type": "TASK", "confidence": 0.8285500764846802}, {"text": "Text Summarization (SUM)", "start_pos": 82, "end_pos": 106, "type": "TASK", "confidence": 0.8270283699035644}]}, {"text": "Textual Entailment Recognition (RTE) () has recently been proposed as an application independent task to capture such inferences.", "labels": [], "entities": [{"text": "Textual Entailment Recognition (RTE)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8238333761692047}]}, {"text": "This year our textual entailment system participated for the first time in the RTE 1 competition.", "labels": [], "entities": [{"text": "RTE 1 competition", "start_pos": 79, "end_pos": 96, "type": "DATASET", "confidence": 0.7212890982627869}]}, {"text": "Next chapters present its main parts, the detailed results obtained and some possible future improvements.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Entities extended fitness", "labels": [], "entities": []}, {"text": " Table 3: Test results  To be able to see each component's relevance, the  system was run in turn with each component re- moved. The results in the table below show that the  system part verifying the NEs is the most impor- tant.  System Description Precision Relevance  Without DIRT  0.6876  0.54 %  Without WordNet  0.6800  1.63 %  Without Acronyms  0.6838  1.08 %  Without BK  0.6775  2.00 %  Without Negations  0.6763  2.17 %  Without NEs  0.5758  16.71 %  Table 4: Components relevance", "labels": [], "entities": []}]}