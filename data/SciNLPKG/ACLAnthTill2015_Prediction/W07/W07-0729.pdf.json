{"title": [{"text": "The 'noisier channel': translation from morphologically complex languages", "labels": [], "entities": [{"text": "translation from morphologically complex languages", "start_pos": 23, "end_pos": 73, "type": "TASK", "confidence": 0.8372857928276062}]}], "abstractContent": [{"text": "This paper presents anew paradigm for translation from inflectionally rich languages that was used in the University of Maryland statistical machine translation system for the WMT07 Shared Task.", "labels": [], "entities": [{"text": "translation from inflectionally rich languages", "start_pos": 38, "end_pos": 84, "type": "TASK", "confidence": 0.8255289912223815}, {"text": "statistical machine translation", "start_pos": 129, "end_pos": 160, "type": "TASK", "confidence": 0.6445255180199941}, {"text": "WMT07 Shared Task", "start_pos": 176, "end_pos": 193, "type": "TASK", "confidence": 0.6472844481468201}]}, {"text": "The system is based on a hierarchical phrase-based decoder that has been augmented to translate ambiguous input given in the form of a confusion network (CN), a weighted finite state representation of a set of strings.", "labels": [], "entities": []}, {"text": "By treating morphologically derived forms of the input sequence as possible, albeit more \"costly\" paths that the decoder may select, we find that significant gains (10% BLEU relative) can be attained when translating from Czech, a language with considerable inflectional complexity, into English.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 169, "end_pos": 173, "type": "METRIC", "confidence": 0.9994670748710632}]}], "introductionContent": [{"text": "Morphological analysis occupies a tenuous position statistical machine translation systems.", "labels": [], "entities": [{"text": "Morphological analysis", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9679621756076813}, {"text": "machine translation", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.7221661508083344}]}, {"text": "Conventional translation models are constructed with no consideration of the relationships between lexical items and instead treat different inflected (observed) forms of identical underlying lemmas as completely independent of one another.", "labels": [], "entities": []}, {"text": "While the variously inflected forms of one lemma may express differences in meaning that are crucial to correct translation, the strict independence assumptions normally made exacerbate data sparseness and lead to poorly estimated models and suboptimal translations.", "labels": [], "entities": []}, {"text": "A variety of solutions have been proposed: use of morphological information to improve word reordering before training and after decoding.", "labels": [], "entities": [{"text": "word reordering", "start_pos": 87, "end_pos": 102, "type": "TASK", "confidence": 0.7585181593894958}]}, {"text": "show improvements in a Czech to English word-based translation system when inflectional endings are simplified or removed entirely.", "labels": [], "entities": [{"text": "Czech to English word-based translation", "start_pos": 23, "end_pos": 62, "type": "TASK", "confidence": 0.5423387348651886}]}, {"text": "Their method can, however, actually harm performance since the discarded morphemes carry some information that may have bearing on the translation (cf. Section 3.3).", "labels": [], "entities": []}, {"text": "To avoid this pitfall, use a datadriven approach to cluster source-language morphological variants that are meaningless in the target language, and propose the use of a backoff model that uses morphologically reduced forms only when the translation of the surface form is unavailable.", "labels": [], "entities": []}, {"text": "All of these approaches have in common that the decisions about whether to use morphological information are made in either a pre-or post-processing step.", "labels": [], "entities": []}, {"text": "Recent work in spoken language translation suggests that allowing decisions about the use of morphological information to be made alongside other translation decisions (i.e., inside the decoder), will yield better results.", "labels": [], "entities": [{"text": "spoken language translation", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.7218941648801168}]}, {"text": "At least as early as, it has been shown that when translating the output from automatic speech regonition (ASR) systems, the quality can be improved by considering multiple (rather than only a single best) transcription hypothesis.", "labels": [], "entities": [{"text": "translating the output from automatic speech regonition (ASR)", "start_pos": 50, "end_pos": 111, "type": "TASK", "confidence": 0.7073239177465439}]}, {"text": "Although state-of-the-art statistical machine translation systems have conventionally assumed unambiguous input; recent work has demonstrated the possibility of efficient decoding of am-biguous input (represented as confusion networks or word lattices) within standard phrase-based models as well as hierarchical phrase-based models.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.6466101706027985}]}, {"text": "These hybrid decoders search for the target language sentenc\u00ea e that maximizes the following probability, where G(o) represents the set of weighted transcription hypotheses produced by an ASR decoder: The conditional probability p(e, f |o) that is maximized is modeled directly using a log-linear model), whose parameters can be tuned to optimize either the probability of a development set or some other objective (such as maximizing BLEU).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 435, "end_pos": 439, "type": "METRIC", "confidence": 0.9806818962097168}]}, {"text": "In addition to the standard translation model features, the ASR system's posterior probability is another feature.", "labels": [], "entities": [{"text": "ASR", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.9448268413543701}]}, {"text": "The decoder thus finds a translation hypothesis\u00eahypothesis\u02c6hypothesis\u00ea that maximizes the joint translation/transcription probability, which is not necessarily the one that corresponds to the best single transcription hypothesis.", "labels": [], "entities": []}], "datasetContent": [{"text": "We carried out a series of experiments using different strategies for making use of morphological information on the News Commentary Czech-English data set provided for the WMT07 Shared Task.", "labels": [], "entities": [{"text": "News Commentary Czech-English data set", "start_pos": 117, "end_pos": 155, "type": "DATASET", "confidence": 0.9151385664939881}, {"text": "WMT07 Shared Task", "start_pos": 173, "end_pos": 190, "type": "DATASET", "confidence": 0.7951170404752096}]}, {"text": "Czech was selected because it exhibits a rich inflectional morphology, but its other morphological processes (such as compounding and cliticization) that affect multiple lemmas are relatively limited.", "labels": [], "entities": [{"text": "Czech", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9259070754051208}]}, {"text": "This has the advantage that a morphologically simplified (i.e., lemmatized) form of a Czech sentence has the same number of tokens as the surface form has words, which makes representing G(f ) as a confusion network relatively straightforward.", "labels": [], "entities": []}, {"text": "The relative morphological complexity of Czech, as well as the potential benefits that can be realized by stemming, can be inferred from the corpus statistics given in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Corpus statistics, by language, for the  WMT07 training subset of the News Commentary  corpus.", "labels": [], "entities": [{"text": "WMT07 training subset of the News Commentary  corpus", "start_pos": 51, "end_pos": 103, "type": "DATASET", "confidence": 0.7756951302289963}]}]}