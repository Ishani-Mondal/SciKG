{"title": [{"text": "A Linguistic Investigation into Unsupervised DOP", "labels": [], "entities": [{"text": "DOP", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.7527747750282288}]}], "abstractContent": [{"text": "Unsupervised Data-Oriented Parsing models (U-DOP) represent a class of structure bootstrapping models that have achieved some of the best unsupervised parsing results in the literature.", "labels": [], "entities": []}, {"text": "While U-DOP was originally proposed as an engineering approach to language learning (Bod 2005, 2006a), it turns out that the model has a number of properties that may also be of linguistic and cognitive interest.", "labels": [], "entities": [{"text": "Bod 2005, 2006a", "start_pos": 85, "end_pos": 100, "type": "DATASET", "confidence": 0.9441178888082504}]}, {"text": "In this paper we will focus on the original U-DOP model proposed in Bod (2005) which computes the most probable tree from among the shortest derivations of sentences.", "labels": [], "entities": [{"text": "Bod (2005)", "start_pos": 68, "end_pos": 78, "type": "DATASET", "confidence": 0.9209801256656647}]}, {"text": "We will show that this U-DOP model can learn both rule-based and exemplar-based aspects of language, ranging from agreement and movement phenomena to discontiguous contructions, provided that productive units of arbitrary size are allowed.", "labels": [], "entities": []}, {"text": "We argue that our results suggest a rapprochement between nativism and empiricism.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper investigates a number of linguistic and cognitive aspects of the unsupervised data-oriented parsing framework, known as U-DOP.", "labels": [], "entities": []}, {"text": "U-DOP is a generalization of the DOP model which was originally proposed for supervised language processing.", "labels": [], "entities": []}, {"text": "DOP produces and analyzes new sentences out of largest and most probable subtrees from previously analyzed sentences.", "labels": [], "entities": []}, {"text": "DOP maximizes what has been called the 'structural analogy' between a sentence and a corpus of previous sentence-structures).", "labels": [], "entities": []}, {"text": "While DOP has been successful in some areas, e.g. in ambiguity resolution, there is also a serious shortcoming to the approach: it does not account for the acquisition of initial structures.", "labels": [], "entities": [{"text": "DOP", "start_pos": 6, "end_pos": 9, "type": "TASK", "confidence": 0.9060915112495422}, {"text": "ambiguity resolution", "start_pos": 53, "end_pos": 73, "type": "TASK", "confidence": 0.7240894287824631}]}, {"text": "That is, DOP assumes that the structures of previous linguistic experiences are already given and stored in a corpus.", "labels": [], "entities": [{"text": "DOP", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.688856840133667}]}, {"text": "As such, DOP can at best account for adult language use and has nothing to say about language acquisition.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 85, "end_pos": 105, "type": "TASK", "confidence": 0.7074159234762192}]}, {"text": "In, DOP was extended to unsupervised parsing in a rather straightforward way.", "labels": [], "entities": [{"text": "DOP", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.4939030706882477}]}, {"text": "This new model, termed U-DOP, again starts with the notion of tree.", "labels": [], "entities": []}, {"text": "But since in language learning we do not yet know which trees should be assigned to initial sentences, it is assumed that a language learner will initially allow (implicitly) for all possible trees and let linguistic experience decide which trees are actually learned.", "labels": [], "entities": []}, {"text": "That is, U-DOP generates anew sentence by reconstructing it out of the largest possible and most frequent subtrees from all possible (binary) trees of previous sentences.", "labels": [], "entities": []}, {"text": "This has resulted in state-of-theart performance for English, German and Chinese corpora.", "labels": [], "entities": []}, {"text": "Although we do not claim that U-DOP provides any near-to-complete theory of language acquisition, we intend to show in this paper that it can learn a variety of linguistic phenomena, some of which are exemplar-based, such as idiosyncratic constructions, others of which are typically viewed as rule-based, such as auxiliary fronting and subject-verb agreement.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 76, "end_pos": 96, "type": "TASK", "confidence": 0.7446780800819397}]}, {"text": "We argue that U-DOP can be seen as a rapprochement between nativism and empiricism.", "labels": [], "entities": []}, {"text": "In particular, we argue that there is a fallacy in the argument that for syntactic facets to be learned they must be either innate or in the input data: they can just as well emerge from an analogical process without ever hearing the particular facet and without assuming that it is hard-wired in the mind.", "labels": [], "entities": []}, {"text": "In the following section, we will start by reviewing the original DOP framework in.", "labels": [], "entities": []}, {"text": "In section 3 we will show how DOP can be generalized to language learning, resulting in U-DOP.", "labels": [], "entities": []}, {"text": "Next, in section 4, we show that the approach can learn idiosyncratic constructions.", "labels": [], "entities": []}, {"text": "In section 5 we discuss how U-DOP can learn agreement phenomena, and in section 6 we extend our argument to auxiliary movement.", "labels": [], "entities": []}, {"text": "We end with a conclusion.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}