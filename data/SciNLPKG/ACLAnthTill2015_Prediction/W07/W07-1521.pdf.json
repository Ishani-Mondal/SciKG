{"title": [{"text": "Building Chinese Sense Annotated Corpus with the Help of Software Tools", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents the building procedure of a Chinese sense annotated corpus.", "labels": [], "entities": [{"text": "Chinese sense annotated corpus", "start_pos": 48, "end_pos": 78, "type": "DATASET", "confidence": 0.5720003694295883}]}, {"text": "A set of software tools is designed to help human annotator to accelerate the annotation speed and keep the consistency.", "labels": [], "entities": [{"text": "consistency", "start_pos": 108, "end_pos": 119, "type": "METRIC", "confidence": 0.9828930497169495}]}, {"text": "The software tools include 1) a tagger for word segmentation and POS tagging, 2) an annotating interface responsible for the sense describing in the lexicon and sense annotating in the corpus, 3) a checker for consistency keeping, 4) a transformer responsible for the transforming from text file to XML format, and 5) a counter for sense frequency distribution calculating.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.7729122340679169}, {"text": "POS tagging", "start_pos": 65, "end_pos": 76, "type": "TASK", "confidence": 0.7195819020271301}, {"text": "consistency keeping", "start_pos": 210, "end_pos": 229, "type": "TASK", "confidence": 0.6251787543296814}, {"text": "sense frequency distribution calculating", "start_pos": 332, "end_pos": 372, "type": "TASK", "confidence": 0.5961622297763824}]}], "introductionContent": [{"text": "There is a strong need fora large-scale Chinese corpus annotated with word senses both for word sense disambiguation (WSD) and linguistic research.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 91, "end_pos": 122, "type": "TASK", "confidence": 0.7718975991010666}]}, {"text": "Although much research has been carried out, there is still along way to go for WSD techniques to meet the requirements of practical NLP programs such as machine translation and information retrieval.", "labels": [], "entities": [{"text": "WSD", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.9828304052352905}, {"text": "machine translation", "start_pos": 154, "end_pos": 173, "type": "TASK", "confidence": 0.8281168639659882}, {"text": "information retrieval", "start_pos": 178, "end_pos": 199, "type": "TASK", "confidence": 0.7995520830154419}]}, {"text": "It was argued that no fundamental progress in WSD could be made until largescale lexical resources were built.", "labels": [], "entities": [{"text": "WSD", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.976285457611084}]}, {"text": "In English a word sense annotated corpus SEM-COR (Semantic Concordances) () has been built, which was later trained and tested by many WSD systems and stimulated large amounts of WSD work.", "labels": [], "entities": [{"text": "WSD", "start_pos": 179, "end_pos": 182, "type": "TASK", "confidence": 0.8856587409973145}]}, {"text": "In Japanese the Hinoki Sensebank is constructed ().", "labels": [], "entities": [{"text": "Hinoki Sensebank", "start_pos": 16, "end_pos": 32, "type": "DATASET", "confidence": 0.8941708505153656}]}, {"text": "In the field of Chinese corpus construction, plenty of attention has been paid to POS tagging and syntactic structures bracketing, for instance the Penn Chinese Treebank () and Sinica Corpus (), but very limited work has been done with semantic knowledge annotation.", "labels": [], "entities": [{"text": "Chinese corpus construction", "start_pos": 16, "end_pos": 43, "type": "TASK", "confidence": 0.6334026753902435}, {"text": "POS tagging", "start_pos": 82, "end_pos": 93, "type": "TASK", "confidence": 0.7685065567493439}, {"text": "Penn Chinese Treebank () and Sinica Corpus", "start_pos": 148, "end_pos": 190, "type": "DATASET", "confidence": 0.8429397472313472}]}, {"text": "introduced the Sinica sense-based lexical knowledge base, but as is well known, Chinese pervasive in Taiwan is not the same as mandarin Chinese.", "labels": [], "entities": []}, {"text": "SENSEVAL-3 provides a Chinese word sense annotated corpus, which contains 20 words and 15 sentences per meaning for most words, but obviously the data is too limited to achieve wide coverage, high accuracy WSD systems.", "labels": [], "entities": [{"text": "SENSEVAL-3", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.7964072227478027}]}, {"text": "This paper is devoted to building a large-scale Chinese corpus annotated with word senses.", "labels": [], "entities": []}, {"text": "A small part of the Chinese sense annotated corpus has been adopted as one of the SemEval-2007 tasks namely \"Multilingual Chinese-English Lexical Sample Task\" This paper concentrates on the description of the manually annotating schemes with the help of software tools.", "labels": [], "entities": [{"text": "Multilingual Chinese-English Lexical Sample Task", "start_pos": 109, "end_pos": 157, "type": "TASK", "confidence": 0.6686570942401886}]}, {"text": "The software tools will help human annotators mainly in the two aspects: 1) Reduce the labor time and accelerate the speed; 2) Keep the inter-annotator agreement.", "labels": [], "entities": [{"text": "speed", "start_pos": 117, "end_pos": 122, "type": "METRIC", "confidence": 0.9751687049865723}]}, {"text": "The overall procedure along with the software tools is illustrated in.", "labels": [], "entities": []}, {"text": "This paper is so organized as follows.", "labels": [], "entities": []}, {"text": "In section 2 the preprocessing stage (word segmentation and POS tagging) is discussed.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7789402306079865}, {"text": "POS tagging", "start_pos": 60, "end_pos": 71, "type": "TASK", "confidence": 0.7839504480361938}]}, {"text": "Then in section 3 the annotating scheme and the annotating interface are demonstrated in detail.", "labels": [], "entities": []}, {"text": "The strategy to keep consistency is addressed in section 4.", "labels": [], "entities": [{"text": "consistency", "start_pos": 21, "end_pos": 32, "type": "METRIC", "confidence": 0.9798032641410828}]}, {"text": "And then in section 5 and 6 the two postprocessing stages are respectively presented.", "labels": [], "entities": []}, {"text": "Finally in section 7 conclusions are drawn and future works are presented.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}