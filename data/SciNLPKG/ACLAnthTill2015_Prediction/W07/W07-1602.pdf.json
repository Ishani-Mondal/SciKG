{"title": [], "abstractContent": [{"text": "In order for automated navigation systems to operate effectively, the route instructions they produce must be clear, concise and easily understood by users.", "labels": [], "entities": []}, {"text": "In order to incorporate a landmark within a coherent sentence, it is necessary to first understand how that landmark is conceptualised by travellers-whether it is perceived as point-like, line-like or area-like.", "labels": [], "entities": []}, {"text": "This paper investigates the viability of automatically classifying the conceptualisation of landmarks relative to a given city context.", "labels": [], "entities": [{"text": "classifying the conceptualisation of landmarks relative to a given city context", "start_pos": 55, "end_pos": 134, "type": "TASK", "confidence": 0.6187459284609015}]}, {"text": "We use web data to learn the default conceptualisation of those landmarks , crucially analysing preposition and verb collocations in the classification.", "labels": [], "entities": []}], "introductionContent": [{"text": "At present, many navigation systems produce badlyworded and difficult to follow route instructions, which do not closely correspond with the way people give one another directions ().", "labels": [], "entities": []}, {"text": "Typically, automated navigation systems give turning instructions with street names as reference points, eg turn right at Smith St. By contrast, human-generated route instructions tend to use landmarks in preference to street names as navigational reference points).", "labels": [], "entities": [{"text": "Smith St.", "start_pos": 122, "end_pos": 131, "type": "DATASET", "confidence": 0.9594683647155762}]}, {"text": "According to, landmarks are typically used in route directions in one of two waysas descriptives, providing a static picture of a spatial scene so that the traveller can verify his or her location along a route, eg the City Library is on your left, or to specify or clarify a point on a route at which the traveller must make a choice between multiple pathways, termed choice points or decision points.", "labels": [], "entities": []}, {"text": "Route instructions which identify decision points with respect to landmarks have been found to be significantly easier to follow than standard streetbased or turn-based route instructions).", "labels": [], "entities": []}, {"text": "This paper goes beyond classical approaches to landmarks that focus on salient point-like objects.", "labels": [], "entities": []}, {"text": "Instead, we aim to find appropriate ways of classifying landmarks automatically, based on the way those landmarks are used in spatial sentences on the web: as point-like, linear-like, and area-like objects that structure movement pattern in urban spaces.", "labels": [], "entities": []}, {"text": "In particular, we analyse how different prepositions and verbs with pre-classified semantics co-occur with mentions of the landmarks.", "labels": [], "entities": []}, {"text": "A preposition such as through can be used with reference to a landmark we are conceptualising as an area, but not one we are conceptualising as a point.", "labels": [], "entities": []}, {"text": "presented an analysis of the spatial properties of commonly used English spatial prepositions, such as at, in and to.", "labels": [], "entities": []}, {"text": "This classification used as the basis of a list of prepositions for the present study, grouped according to whether the preposition indicates a point-like, line-like or area-like landmark.", "labels": [], "entities": []}, {"text": "In addition, a shortlist of verbs was compiled based on the verb classes of and similarly divided into the three conceptual classes.", "labels": [], "entities": []}, {"text": "Each of the verbs and prepositions was combined in turn with a list of landmarks in Melbourne, Australia, to produce a series of spatial phrases such as at Flinders St Station.", "labels": [], "entities": [{"text": "Flinders St Station", "start_pos": 156, "end_pos": 175, "type": "DATASET", "confidence": 0.9273725152015686}]}, {"text": "These phrases were then sent to the Google search engine, which determined the approximate number of documents on the web containing that exact phrase.", "labels": [], "entities": []}, {"text": "The document counts were then summed over the conceptual categories the prepositions and verbs appeared in -point, line and area.", "labels": [], "entities": []}, {"text": "The result of this was a probabilistic categorisation of each landmark, according to its usage in spatial contexts on the web.", "labels": [], "entities": []}, {"text": "Evaluation of the baseline was performed based on annotators' independent judgements of the conceptual class of each of the landmarks, gathered from a web-based annotation interface.", "labels": [], "entities": []}, {"text": "It was found that the baseline classification agreed with the gold standard classification 63.8% of the time.", "labels": [], "entities": []}, {"text": "A slight improvement on the baseline was achieved via a supervised neural network classifier, which took the web counts as inputs.", "labels": [], "entities": []}, {"text": "This classifier agreed with the gold standard 68.5% of the time.", "labels": [], "entities": []}, {"text": "As a result of this analysis, a set of systematically ambiguous landmarks was identified, with implications for future landmark classification models.", "labels": [], "entities": [{"text": "landmark classification", "start_pos": 119, "end_pos": 142, "type": "TASK", "confidence": 0.7076457142829895}]}, {"text": "In the remainder of this paper, we describe background research (Section 2) and then outline our research methodology (Section 3).", "labels": [], "entities": []}, {"text": "We then present the results of a series of landmark classification experiments (Section 4), and finally discuss the broader implications of the experiments (Section 5).", "labels": [], "entities": []}], "datasetContent": [{"text": "Experiment 1 involved using only the raw web count data as input into the classifiers.", "labels": [], "entities": []}, {"text": "The accuracy and error rate reduction (E.R.R.) of the classifiers are given in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994300007820129}, {"text": "error rate reduction (E.R.R.)", "start_pos": 17, "end_pos": 46, "type": "METRIC", "confidence": 0.9405263364315033}]}, {"text": "The neural network classifier produced results slightly better than the simple voting classifier, but with 18 landmarks incorrectly classified by the neural network, there is still plently of room for improvement.", "labels": [], "entities": []}, {"text": "The raw web count data used in this experiment was likely to be biased in favour of certain prepositions and verbs, because some of these words (such as at and in, which each occur in over 7 billion documents) are much more common than others (such as beside, which occurs in just over 50 million documents).", "labels": [], "entities": []}, {"text": "This may result in the web counts being unfairly weighted towards one class or another, creating classifier bias.", "labels": [], "entities": []}, {"text": "The simple voting classifier showed a tendency towards point classifications over line or area classifications.", "labels": [], "entities": []}, {"text": "The neural network classifier reversed the bias shown by the simple voting classifier, with the area class showing high recall but low precision, resulting in a low recall for the point class.", "labels": [], "entities": [{"text": "recall", "start_pos": 120, "end_pos": 126, "type": "METRIC", "confidence": 0.9978691339492798}, {"text": "precision", "start_pos": 135, "end_pos": 144, "type": "METRIC", "confidence": 0.9976522326469421}, {"text": "recall", "start_pos": 165, "end_pos": 171, "type": "METRIC", "confidence": 0.9963998794555664}]}, {"text": "Neither of the two line landmarks were classified correctly; in fact, none of the landmarks were classified as lines.", "labels": [], "entities": []}, {"text": "To adjust for the potential bias in preposition and verb use, the web counts were normalised against the prior probabilities of the relevant preposition or verb, by calculating the ratio of the count of each linguistic chunk to the count of its preposition or verb in isolation.", "labels": [], "entities": []}, {"text": "The accuracy and error rate reduction of the classifiers are given in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994718432426453}, {"text": "error rate reduction", "start_pos": 17, "end_pos": 37, "type": "METRIC", "confidence": 0.9727296630541483}]}, {"text": "Normalising the web counts by the prior probabilities of the prepositions and verbs did not improve the accuracy of the classifiers as expected.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9991487264633179}]}, {"text": "ple voting classifier reduced inaccuracy, while the accuracy of the neural net classifier remained unchanged.", "labels": [], "entities": [{"text": "ple voting classifier", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.6052692532539368}, {"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9994823932647705}]}, {"text": "As explained in Section 3.2, the annotators who generated the gold standard were required to choose one of point, line or area for each landmark, even if they were unfamiliar with the landmark.", "labels": [], "entities": []}, {"text": "Some of these annotators may have been forced to guess the appropriate class.", "labels": [], "entities": []}, {"text": "As a result, these annotations may cause the gold standard to lack validity, which could be one of the barriers to classifier improvement.", "labels": [], "entities": [{"text": "validity", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.997173547744751}, {"text": "classifier improvement", "start_pos": 115, "end_pos": 137, "type": "TASK", "confidence": 0.8984315693378448}]}, {"text": "In this experiment, a more sound gold standard was generated by weighting annotators' classifications by their familiarity with the landmark.", "labels": [], "entities": []}, {"text": "The effect of this is that the judgement of an annotator who is very familiar with a landmark outweighs the judgement of an annotator who is less familiar.", "labels": [], "entities": []}, {"text": "Experiments 1 and 2 were conducted again based on this new gold standard.", "labels": [], "entities": []}, {"text": "These repeated experiments are dubbed Experiments 1 and 2 respectively.", "labels": [], "entities": []}, {"text": "The results of each of the repeated experiments are shown in.", "labels": [], "entities": []}, {"text": "The simple voting classifier showed improvement using the weighted gold standard, with the accuracies under Experiments 1 and 2 each exceeding the accuracy of the equivalent experiment using the original gold standard.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.998964786529541}]}, {"text": "Experiment 1 showed the most improvement for the simple voting classifier, giving an accuracy of 67.2% (only one landmark shy of the 70% accuracy achieved by the neural network classifier in experiment 1).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9995508790016174}, {"text": "accuracy", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.9912962913513184}]}, {"text": "While landmarks well-known to all are likely to produce consistently valid classifications, and landmarks poorly known to all are likely to produce consistently invalid classifications, regardless of whether a weighting scheme is used, it is the landmarks which are well-known to some and poorly known to others which should have gained the greatest benefit from annotations weighted by familiarity.", "labels": [], "entities": []}, {"text": "However, the majority of such landmarks were already being classified correctly by the neural network in both Experiments 1 and 2, which explains why the neural network showed no improvement.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Results with simple web counts (Experi- ment 1)", "labels": [], "entities": []}, {"text": " Table 4: Results with normalised web counts (Ex- periment 2)", "labels": [], "entities": []}, {"text": " Table 5: Results weighted according to landmark familiarity (Experiments 1 and 2 )", "labels": [], "entities": []}]}