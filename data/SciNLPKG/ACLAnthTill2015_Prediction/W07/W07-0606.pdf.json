{"title": [{"text": "A Cognitive Model for the Representation and Acquisition of Verb Selectional Preferences", "labels": [], "entities": [{"text": "Representation and Acquisition of Verb Selectional Preferences", "start_pos": 26, "end_pos": 88, "type": "TASK", "confidence": 0.7616181373596191}]}], "abstractContent": [{"text": "We present a cognitive model of inducing verb selectional preferences from individual verb usages.", "labels": [], "entities": []}, {"text": "The selectional preferences for each verb argument are represented as a probability distribution over the set of semantic properties that the argument can possess-a semantic profile.", "labels": [], "entities": []}, {"text": "The semantic profiles yield verb-specific conceptual-izations of the arguments associated with a syntactic position.", "labels": [], "entities": []}, {"text": "The proposed model can learn appropriate verb profiles from a small set of noisy training data, and can use them in simulating human plausibility judgments and analyzing implicit object alternation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Verbs have preferences for the semantic properties of the arguments filling a particular role.", "labels": [], "entities": []}, {"text": "For example, the verb eat expects that the object receiving its theme role will have the property of being edible, among others.", "labels": [], "entities": []}, {"text": "Learning verb selectional preferences is an important aspect of human language acquisition, and the acquired preferences have been shown to guide children's expectations about missing or upcoming arguments in language comprehension (.", "labels": [], "entities": []}, {"text": "Resnik (1996) introduced a statistical approach to learning and use of verb selectional preferences.", "labels": [], "entities": []}, {"text": "In this framework, a semantic class hierarchy for words is used, together with statistical tools, to induce a verb's selectional preferences fora particular argument position in the form of a distribution overall the classes that can occur in that position.", "labels": [], "entities": []}, {"text": "Resnik's model was proposed as a model of human learning of selectional preferences that made minimal representational assumptions; it showed how such preferences could be acquired from usage data and an existing conceptual hierarchy.", "labels": [], "entities": []}, {"text": "However, his and later computational models (see Section 2) have properties that do not match with certain cognitive plausibility criteria fora child language acquisition model.", "labels": [], "entities": []}, {"text": "All these models use the training data in \"batch mode\", and most of them use information theoretic measures that rely on total counts from a corpus.", "labels": [], "entities": []}, {"text": "Therefore, it is not clear how the representation of selectional preferences could be updated incrementally in these models as the person receives more data.", "labels": [], "entities": []}, {"text": "Moreover, the assumption that children have access to a full hierarchical representation of semantic classes maybe too strict.", "labels": [], "entities": []}, {"text": "We propose an alternative view in this paper which is more plausible in the context of child language acquisition.", "labels": [], "entities": [{"text": "child language acquisition", "start_pos": 87, "end_pos": 113, "type": "TASK", "confidence": 0.6173889736334482}]}, {"text": "In previous work, we have proposed a usage-based computational model of early verb learning that uses Bayesian clustering and prediction to model language acquisition and use.", "labels": [], "entities": []}, {"text": "Individual verb usages are incrementally grouped to form emergent classes of linguistic constructions that share semantic and syntactic properties.", "labels": [], "entities": []}, {"text": "We have shown that our Bayesian model can incrementally acquire a general conception of the semantic roles of predicates based only on exposure to individual verb usages).", "labels": [], "entities": []}, {"text": "The model forms probabilistic associations between the semantic properties of arguments, their syntactic positions, and the semantic primitives 41 of verbs.", "labels": [], "entities": []}, {"text": "Our previous experiments demonstrated that, initially, this probability distribution for an argument position yields verb-specific conceptualizations of the role associated with that position.", "labels": [], "entities": []}, {"text": "As the model is exposed to more input, the verb-based roles gradually transform into more abstract representations that reflect the general properties of arguments across the observed verbs.", "labels": [], "entities": []}, {"text": "A shortcoming of the model was that, because the prediction of the semantic roles was based only on the groupings of verbs, it could not make use of verb-specific knowledge in generating expectations about a particular verb's arguments.", "labels": [], "entities": []}, {"text": "That is, once it was exposed to a range of verbs, it no longer had access to the verb-specific information, only to generalizations over clusters of verbs.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew version of our model that, in addition to learning general semantic roles for constructions, can use its verb-specific knowledge to predict intuitive selectional preferences for each verb argument position.", "labels": [], "entities": []}, {"text": "We introduce anew notion, a verb semantic profile, as a probability distribution over the semantic properties of an argument for each verb.", "labels": [], "entities": []}, {"text": "A verb semantic profile is predicted from both the verb-based and the construction-based knowledge that the model has learned through clustering, and reflects the properties of the arguments that are observed for that verb.", "labels": [], "entities": []}, {"text": "Our proposed prediction model makes appropriate generalizations over the observed properties, and captures expectations about previously unseen arguments.", "labels": [], "entities": []}, {"text": "As in other work on selectional preferences, the semantic properties that we use in our representation of arguments are drawn from a standard lexical ontology), but we do not require knowledge of the hierarchical structure of the WordNet concepts.", "labels": [], "entities": []}, {"text": "From the computational point of view, this makes use of an available resource, while from the cognitive view, this avoids ad hoc assumptions about the representation of a conceptual hierarchy.", "labels": [], "entities": []}, {"text": "However, we do require some properties to be more general (i.e., shared by more words) than others, which eventually enables the model to make appropriate generalizations.", "labels": [], "entities": []}, {"text": "Otherwise, the selected semantic properties are not fundamental to the model, and could in the future be replaced with an approach that is deemed more appropriate to child language acquisition.", "labels": [], "entities": [{"text": "child language acquisition", "start_pos": 166, "end_pos": 192, "type": "TASK", "confidence": 0.6529218554496765}]}, {"text": "Each argument contributes to the semantic profile of the verb through its (potentially large) set of semantic properties instead of its membership in a single class.", "labels": [], "entities": []}, {"text": "As input to our model, we use an automatically parsed corpus, which is very noisy.", "labels": [], "entities": []}, {"text": "However, as a result of our novel representation, the model can induce and use selectional preferences using a relatively small set of noisy training data.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the following sections, we first describe the training data for our model.", "labels": [], "entities": []}, {"text": "In accordance with other computational models, we focus hereon the verb preferences for the direct object position.", "labels": [], "entities": []}, {"text": "Next, we provide a qualitative analysis of our model through examination of the semantic profiles fora number of verbs.", "labels": [], "entities": []}, {"text": "We then evaluate our model through two tasks of simulating verb-argument plausibility judgment, and analyzing the implicit object alternation, following.", "labels": [], "entities": [{"text": "verb-argument plausibility judgment", "start_pos": 59, "end_pos": 94, "type": "TASK", "confidence": 0.6646495461463928}]}], "tableCaptions": []}