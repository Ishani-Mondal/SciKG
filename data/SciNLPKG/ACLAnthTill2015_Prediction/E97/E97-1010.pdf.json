{"title": [{"text": "Homonymy and Polysemy in Information Retrieval", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.7765264809131622}]}], "abstractContent": [{"text": "This paper discusses research on distinguishing word meanings in the context of information retrieval systems.", "labels": [], "entities": [{"text": "distinguishing word meanings", "start_pos": 33, "end_pos": 61, "type": "TASK", "confidence": 0.8203667004903158}, {"text": "information retrieval", "start_pos": 80, "end_pos": 101, "type": "TASK", "confidence": 0.6512056291103363}]}, {"text": "We conducted experiments with three sources of evidence for making these distinctions: morphology , part-of-speech, and phrases.", "labels": [], "entities": []}, {"text": "We have focused on the distinction between homonymy and polysemy (unrelated vs. related meanings).", "labels": [], "entities": []}, {"text": "Our results support the need to distinguish homonymy and poly-semy.", "labels": [], "entities": []}, {"text": "We found: 1) grouping morphological variants makes a significant improvement in retrieval performance, 2) that more than half of all words in a dictionary that differ in part-of-speech are related in meaning , and 3) that it is crucial to assign credit to the component words of a phrase.", "labels": [], "entities": []}, {"text": "These experiments provide a better understanding of word-based methods, and suggest where natural language processing can provide further improvements in retrieval performance .", "labels": [], "entities": []}], "introductionContent": [{"text": "Lexical ambiguity is a fundamental problem in natural language processing, but relatively little quantitative information is available about the extent of the problem, or about the impact that it has on specific applications.", "labels": [], "entities": [{"text": "Lexical ambiguity", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8542659878730774}, {"text": "natural language processing", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.6792260011037191}]}, {"text": "We report on our experiments to resolve lexical ambiguity in the context of information retrieval (IR).", "labels": [], "entities": [{"text": "resolve lexical ambiguity", "start_pos": 32, "end_pos": 57, "type": "TASK", "confidence": 0.817112147808075}, {"text": "information retrieval (IR)", "start_pos": 76, "end_pos": 102, "type": "TASK", "confidence": 0.8495293259620667}]}, {"text": "Our approach to disambiguation is to treat the information associated with dictionary This paper is based on work that was done at the Center for Intelligent Information Retrieval at the University of Massachusetts.", "labels": [], "entities": [{"text": "disambiguation", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.9681310653686523}, {"text": "Intelligent Information Retrieval", "start_pos": 146, "end_pos": 179, "type": "TASK", "confidence": 0.6348625123500824}]}, {"text": "It was supported by the National Science Foundation, Library of Congress, and Department of Commerce raider cooperative agreement number EEC-9209623.", "labels": [], "entities": [{"text": "National Science Foundation", "start_pos": 24, "end_pos": 51, "type": "DATASET", "confidence": 0.9217836062113444}]}, {"text": "I am grateful for their support.", "labels": [], "entities": []}, {"text": "senses (morphology. part of speech, and phrases) as multiple sources of evidence.", "labels": [], "entities": []}, {"text": "1 Experiments were designed to test each source of evidence independently, and to identify areas of interaction.", "labels": [], "entities": []}, {"text": "Our hypothesis is: Hypothesis 1 Resolving lexical ambiguity will lead to an improvement in retrieval performance.", "labels": [], "entities": []}, {"text": "There are many issues involved in determining how word senses should be used in information retrieval.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 80, "end_pos": 101, "type": "TASK", "confidence": 0.766220211982727}]}, {"text": "The most basic issue is one of identity --what is a word sense?", "labels": [], "entities": []}, {"text": "In previous work, researchers have usually made distinctions based on their intuition.", "labels": [], "entities": []}, {"text": "This is not satisfactory for two reasons.", "labels": [], "entities": []}, {"text": "First, it is difficult to scale up; researchers have generally focused on only two or three words.", "labels": [], "entities": []}, {"text": "Second, they have used very coarse grained distinctions (e.g., 'river bank' v. 'commercial bank').", "labels": [], "entities": []}, {"text": "In practice it is often difficult to determine how many senses a word should have, and meanings are often related.", "labels": [], "entities": []}, {"text": "A related issue is sense granularity.", "labels": [], "entities": []}, {"text": "Dictionaries often make very fine distinctions between word meanings, and it isn't clear whether these distinctions are important in the context of a particular application.", "labels": [], "entities": []}, {"text": "For example, the sentence They danced across the lvom is ambiguous with respect to the word dance.", "labels": [], "entities": []}, {"text": "It can be paraphrased as They were across the room and they were dancing, or as They crossed the tvom as they danced.", "labels": [], "entities": []}, {"text": "ambiguous in Romance languages, and can only have the former meaning.", "labels": [], "entities": []}, {"text": "Machine translation syst.ems therefore need to be aware of this ambiguity and translate the sentence appropriately.", "labels": [], "entities": []}, {"text": "This is a systematic class of ambiguity, and applies to all \"verbs of translatory motion\" (e.g., The bottle floated ~mder the bridge will exhibit the same distinction (Talmy 85)).", "labels": [], "entities": []}, {"text": "Such distinctions are unlikely to have an impact on information retrieval.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 52, "end_pos": 73, "type": "TASK", "confidence": 0.8210069239139557}]}, {"text": "However, there are 1We used the Longman Dictionary as our source of information about word senses (Procter 78).", "labels": [], "entities": [{"text": "Longman Dictionary", "start_pos": 32, "end_pos": 50, "type": "DATASET", "confidence": 0.975249320268631}]}, {"text": "\"/2 also distinctions that are important in information retrieval that are unlikely to be important in machine translation.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.73843914270401}, {"text": "machine translation", "start_pos": 103, "end_pos": 122, "type": "TASK", "confidence": 0.7905175387859344}]}, {"text": "For example, the word west can be used in the context the East versus the West, or in the context West Germany.", "labels": [], "entities": []}, {"text": "These two senses were found to provide a good separation between relevant and non-relevant documents, but the distinction is probably not important for machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 152, "end_pos": 171, "type": "TASK", "confidence": 0.7807422876358032}]}, {"text": "It is likely that different applications will require different types of distinctions, and the type of distinctions required in information retrieval is an open question.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 128, "end_pos": 149, "type": "TASK", "confidence": 0.7620232999324799}]}, {"text": "Finally, there are questions about how word senses should be used in a retrieval system.", "labels": [], "entities": []}, {"text": "In general, word senses should be used to supplement wordbased indexing rather than indexing on word senses alone.", "labels": [], "entities": []}, {"text": "This is because of the uncertainty involved with sense representation, and the degree to which we can identify a particular sense with the use of a word in context.", "labels": [], "entities": [{"text": "sense representation", "start_pos": 49, "end_pos": 69, "type": "TASK", "confidence": 0.7102502286434174}]}, {"text": "If we replace words with senses, we are making an assertion that we are very certain that the replacement does not lose any of the information important in making relevance judgments, and that the sense we are choosing fora word is in fact correct.", "labels": [], "entities": []}, {"text": "Both of these are problematic.", "labels": [], "entities": []}, {"text": "Until more is learned about sense distinctions, and until very accurate methods are developed for identifying senses, it is probably best to adopt a more conservative approach (i.e., uses senses as a supplement to wordbased indexing).", "labels": [], "entities": []}, {"text": "The following section will provide an overview of lexical ambiguity and information retrieval.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 72, "end_pos": 93, "type": "TASK", "confidence": 0.8434520065784454}]}, {"text": "This will be followed by a discussion of our experiments.", "labels": [], "entities": []}, {"text": "The paper will conclude with a summary of what has been accomplished, and what work remains for the future.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our initial experiments were designed to investigate the following two hypotheses: Hypothesis 2 Word senses provide an effective separation between relevant and non-relevant documents.", "labels": [], "entities": []}, {"text": "As we saw earlier in the paper, it is possible fora query about 'AIDS' the disease to retrieve documents about 'hearing aids'.", "labels": [], "entities": []}, {"text": "But to what extent are such inappropriate matches associated with relevance judgments?", "labels": [], "entities": []}, {"text": "This hypothesis predicts that sense mismatches will be more likely to appear in documents that are not relevant than in those that are relevant.", "labels": [], "entities": []}, {"text": "The next set of experiments were concerned with determining the effectiveness of different sources of evidence for distinguishing word senses.", "labels": [], "entities": [{"text": "distinguishing word senses", "start_pos": 115, "end_pos": 141, "type": "TASK", "confidence": 0.7669248183568319}]}, {"text": "We were also interested in the extent with which a difference inform corresponded to a difference in meaning.", "labels": [], "entities": []}, {"text": "For example, words can differ in morphology (authorize/authorized), or part-of-speech (diabetic [noun]/diabetic), or in their ability to appear in a phrase (database/data base).", "labels": [], "entities": []}, {"text": "They can also exhibit such differences, but represent different concepts, such as author/authorize.", "labels": [], "entities": []}, {"text": "sink[noun]/sink, or stone wall/stonewall.", "labels": [], "entities": []}, {"text": "Our default assumption was that a difference inform is associated with a difference in meaning unless we could establish that the different word forms were related.", "labels": [], "entities": []}, {"text": "We conducted several experiments to determine the impact of grouping morphological variants on retrieval performance.", "labels": [], "entities": []}, {"text": "These experiments are described in detail in (Krovetz 93), so we will only summarize them here.", "labels": [], "entities": [{"text": "Krovetz 93)", "start_pos": 46, "end_pos": 57, "type": "DATASET", "confidence": 0.8321987787882487}]}, {"text": "Our experiments compared a baseline (no stemming) against several different morphology routines: 1) a routine that grouped only inflectional variants (plurals and tensed verb forms), 2) a routine that grouped inflectional as well as derivational variants (e.g.,-ize,-ity), and 3) the Porter stemmer (Porter 80).", "labels": [], "entities": []}, {"text": "These experiments were done with four different test collections which varied in both size and subject area.", "labels": [], "entities": []}, {"text": "We found that there was a significant improvement over the baseline performance from grouping morphological variants.", "labels": [], "entities": []}, {"text": "Earlier experiments with morphology in IR did not report improvements in performance (Harman 91).", "labels": [], "entities": [{"text": "IR", "start_pos": 39, "end_pos": 41, "type": "TASK", "confidence": 0.9478468894958496}]}, {"text": "We attribute these differences to the use of different test collections, and in part to the use of different retrieval systems.", "labels": [], "entities": []}, {"text": "We found that the improvement varies depending on the test collection, and that collections that were made up of shorter documents were more likely to improve.", "labels": [], "entities": []}, {"text": "This is because morphological variants can occur within the same document, but they are less likely to do so in documents that are short.", "labels": [], "entities": []}, {"text": "By grouping morphological variants, we are helping to improve access to the shorter documents.", "labels": [], "entities": []}, {"text": "However, we also found improvements even aExcluding closed class words, such as of and for.", "labels": [], "entities": []}, {"text": "in a collection of legal documents which had an average length of more than 3000 words.", "labels": [], "entities": []}, {"text": "We also found it was very difficult to improve retrieval performance over the performance of the Porter stemmer, which does not use a lexicon.", "labels": [], "entities": [{"text": "Porter stemmer", "start_pos": 97, "end_pos": 111, "type": "DATASET", "confidence": 0.8374028205871582}]}, {"text": "The absence of a lexicon causes the Porter stemmer to make errors by grouping morphological \"false friends\" (e.g.. author/authority, or police/policy).", "labels": [], "entities": []}, {"text": "We found that there were three reasons why the Porter stemmer improves performance despite such groupings.", "labels": [], "entities": []}, {"text": "The first two reasons are associated with the heuristics used by the stemmer: 1) some word forms will be grouped when one of the forms has a combination of endings (e.g., -ization and -ize).", "labels": [], "entities": []}, {"text": "We empirically found that the word forms in these groups are almost always related in meaning.", "labels": [], "entities": []}, {"text": "2) the stemmer uses a constraint on the form of the resulting stem based on a sequence of consonants and vowels; we found that this constraint is surprisingly effective at separating unrelated variants.", "labels": [], "entities": []}, {"text": "The third reason has to do with the nature of morphological variants.", "labels": [], "entities": []}, {"text": "We found that when a word form appears to be a variant, it often is a variant.", "labels": [], "entities": []}, {"text": "For example, consider the grouping of police and policy.", "labels": [], "entities": [{"text": "grouping of police", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.8410056630770365}]}, {"text": "We examined all words in the dictionary in which a word ended in 'y', and in which the 'y' could be replaced by 'e' and still yield a word in the dictionary.", "labels": [], "entities": []}, {"text": "There were 175 such words, but only 39 were clearly unrelated in meaning to the presumed root (i.e., cases like policy/police).", "labels": [], "entities": []}, {"text": "Of the 39 unrelated word pairs, only 14 were grouped by the Porter stemmer because of the consonant/vowel constraints.", "labels": [], "entities": []}, {"text": "We also identified the morphological \"'false friends\" for the 10 most frequent suffixes.", "labels": [], "entities": []}, {"text": "We found that out of 911 incorrect word pairs, only 303 were grouped by the Porter stemmer.", "labels": [], "entities": [{"text": "Porter stemmer", "start_pos": 76, "end_pos": 90, "type": "DATASET", "confidence": 0.8429013192653656}]}, {"text": "Finally, we found that conflating inflectional variants harmed the performance of about a third of the queries.", "labels": [], "entities": []}, {"text": "This is partially a result of the interaction between morphology and part-of-speech (e.g., a query that contains work in the sense of theoretical work will be grouped with all of the variants associated with the the verb-worked, working, works); we note that some instances of works can be related to the singular form work (although not necessarily the right meaning of work), and some can be related to the untensed verb form.", "labels": [], "entities": []}, {"text": "Grouping inflectional variants also harms retrieval performance because of an overlap between inflected forms and uninflected forms (e.g., arms can occur as a reference to weapons, or as an inflected form of arm).", "labels": [], "entities": []}, {"text": "Conflating these forms has the effect of grouping unrelated concepts, and thus increases the net ambiguity.", "labels": [], "entities": []}, {"text": "Our experiments with morphology support our atgument about distinguishing homonymy and polysemy.", "labels": [], "entities": []}, {"text": "Grouping related morphological variants makes a significant improvement in retrieval performance.", "labels": [], "entities": []}, {"text": "Morphological false friends (policy/police) often provide a strong separation between relevant and non-relevant documents (see ().", "labels": [], "entities": [{"text": "Morphological false friends (policy/police)", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.7272464409470558}]}, {"text": "There are no morphology routines that can currently handle the problems we encountered with inflectional variants, and it is likely that separating related from unrelated forms will make further improvements in performance.", "labels": [], "entities": []}, {"text": "Relatively little attention has been paid in IR to the differences in a word's part of speech.", "labels": [], "entities": [{"text": "IR", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.9908131957054138}]}, {"text": "These differences have been used to help identify phrases (Dillon and Gray 83), and as a means of filtering for word sense disambiguation (to only consider the meanings of nouns).", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 112, "end_pos": 137, "type": "TASK", "confidence": 0.6821306347846985}]}, {"text": "To the best of our knowledge the differences have never been examined for distinguishing meanings within the context of IR.", "labels": [], "entities": [{"text": "IR", "start_pos": 120, "end_pos": 122, "type": "TASK", "confidence": 0.9703097343444824}]}, {"text": "The aim of our experiments was to determine how well part of speech differences correlate with differences in word meanings, and to what extent the use of meanings determined by these differences will affect the performance of a retrieval system.", "labels": [], "entities": []}, {"text": "We conducted two sets of experiments, one concerned with homonymy, and one concerned with polysemy.", "labels": [], "entities": []}, {"text": "In the first experiment the Church tagger was used to identify part-of-speech of the words in documents and queries.", "labels": [], "entities": []}, {"text": "The collections were then indexed by the word tagged with the part of speech (i.e., instead of indexing 'book', we indexed 'book/noun' and 'book/verb').", "labels": [], "entities": []}, {"text": "4 A baseline was established in which all variants of a word were present in the query, regardless of part of speech variation; the baseline did not include any morphological variants of the query words because we wanted to test the interaction between morphology and part-of-speech in a separate experiment.", "labels": [], "entities": []}, {"text": "The baseline was then compared against aversion of the query in which all variations were eliminated except for the part of speech that was correct (i.e., if the word was used as a noun ill the original query, all other variants were eliminated).", "labels": [], "entities": []}, {"text": "This constituted the experiment that tested homonymy.", "labels": [], "entities": []}, {"text": "We then identified words that were related in spite of a difference in part of speech; this was based on the data that was produced by tagging the dictionary (see Section 3.2.1).", "labels": [], "entities": []}, {"text": "Another version of the queries was constructed in which part of speech variants were retained if the meaning was related, 4in actuality, we indexed it with whatever tags were used by the tagger; we are just using 'noun' and 'verb' for purposes of illustration. and this was compared to the previous version.", "labels": [], "entities": []}, {"text": "When we ran the experiments, we found that performance decreased compared with the baseline.", "labels": [], "entities": []}, {"text": "However, we found many cases where the tagger was incorrect.", "labels": [], "entities": []}, {"text": "5 We were unable to determine whether the results of the experiment were due to the incorrectness of the hypothesis being tested (that distinctions in part of speech can lead to an improvement in performance), or to the errors made by the tagger.", "labels": [], "entities": []}, {"text": "We also assumed that a difference in part-of-speech would correspond to a difference in meaning.", "labels": [], "entities": []}, {"text": "The data in and shows that many words are related in meaning despite a difference in partof-speech.", "labels": [], "entities": []}, {"text": "Not all errors made by the tagger cause decreases in retrieval performance, and we are in the process of determining the error rate of the tagger on those words in which part-of-speech differences are also associated with a difference in concepts (e.g., novel as a noun and as an adjective).", "labels": [], "entities": [{"text": "error rate", "start_pos": 121, "end_pos": 131, "type": "METRIC", "confidence": 0.9267702400684357}]}, {"text": "6  Phrases are an important and poorly understood area of IR.", "labels": [], "entities": [{"text": "IR", "start_pos": 58, "end_pos": 60, "type": "TASK", "confidence": 0.9937376976013184}]}, {"text": "They generally improve retrieval performance, but the improvements are not consistent.", "labels": [], "entities": []}, {"text": "Most research to date has focused on syntactic phrases, in which words are grouped together because they are in a specific syntactic relationship (Fagan 87), (Smeaton and Van Rijsbergen 88).", "labels": [], "entities": []}, {"text": "The research in this section is concerned with a subset of these phrases, namely those that are lexical.", "labels": [], "entities": []}, {"text": "A lexical phrase is a phrase that might be defined in a dictionary, such as hot line or back end.", "labels": [], "entities": []}, {"text": "Lexical phrases can be distinguished from a phrases such as sanctions against South Africa in that the meaning of a lexical phrase cannot necessarily be determined from the meaning of its parts.", "labels": [], "entities": []}, {"text": "Lexical phrases are generally made up of only two or three words (overwhelmingly just two), and they usually occur in a fixed order.", "labels": [], "entities": []}, {"text": "The literature mentions examples such as blind venetians vs. venetian blinds, or science library vs. library science, but these are primarily just cute examples.", "labels": [], "entities": []}, {"text": "It is very rare that the order could be reversed to produce a different concept.", "labels": [], "entities": []}, {"text": "Although dictionaries contain a large number of phrasal entries, there are many lexical phrases that are missing.", "labels": [], "entities": []}, {"text": "These are typically proper nouns (United States, Great Britain, United Nations) or technical concepts (operating system, specific heat, 5See (Krovetz 95) for more details about these errors.", "labels": [], "entities": []}, {"text": "~There are approximately 4000 words in the Longman dictionary which have more than one part-of-speech.", "labels": [], "entities": [{"text": "Longman dictionary", "start_pos": 43, "end_pos": 61, "type": "DATASET", "confidence": 0.9664174914360046}]}, {"text": "Less than half of those words will be like novel, and we are examining them by hand.", "labels": [], "entities": []}, {"text": "due process, strict liability).", "labels": [], "entities": []}, {"text": "We manually identified the lexical phrases in four different test collections (the phrases were based on our judgement), and we found that 92 out of 120 phrases (77%) were not found in the Longman dictionary.", "labels": [], "entities": [{"text": "Longman dictionary", "start_pos": 189, "end_pos": 207, "type": "DATASET", "confidence": 0.9686665534973145}]}, {"text": "A breakdown of the phrases is given in (h:rovetz 95).", "labels": [], "entities": []}, {"text": "For the phrase experiment we not only had to identify the lexical phrases, we also had to identiL' any related forms, such as database~data base.", "labels": [], "entities": []}, {"text": "This was done via brute force --a program simply concatenated every adjacent word in the database, and if it was also a single word in the collection it prim ted out the pair.", "labels": [], "entities": []}, {"text": "We tested this with the Computer Science and Time collections, and used those results to develop an exception list for filtering the pairs (e.g., do not consider \"special ties/specialties').", "labels": [], "entities": [{"text": "Computer Science and Time collections", "start_pos": 24, "end_pos": 61, "type": "DATASET", "confidence": 0.5956413269042968}]}, {"text": "We represented the phrases using a proximity operator: and tried several experiments to include the related form when it was found in the corpus.", "labels": [], "entities": []}, {"text": "We found that retrieval performance decreased for 118 out of 120 phrases.", "labels": [], "entities": []}, {"text": "A failure analysis indicated that this was due to the need to assign partial credit to individual words of a phrase.", "labels": [], "entities": []}, {"text": "The component words were always related to the meaning of the compound as a whole (e.g., Britain and Great Britain).", "labels": [], "entities": [{"text": "Great Britain", "start_pos": 101, "end_pos": 114, "type": "DATASET", "confidence": 0.8288470208644867}]}, {"text": "Database~data base occurred in about a 50/50 distribution, and the queries in which they occurred were significantly improved when the related form was included.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Distribution of zero-affix morphology within dictionary definitions", "labels": [], "entities": []}]}