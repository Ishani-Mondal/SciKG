{"title": [], "abstractContent": [{"text": "Many current approaches to statistical language modeling rely on independence a.~-sumptions 1)etween the different explanatory variables.", "labels": [], "entities": [{"text": "statistical language modeling", "start_pos": 27, "end_pos": 56, "type": "TASK", "confidence": 0.8031021952629089}]}, {"text": "This results in models which are computationally simple, but which only model the main effects of the explanatory variables oil the response variable.", "labels": [], "entities": []}, {"text": "This paper presents an argmnent in favor of a statistical approach that also models the interactions between the explanatory variables.", "labels": [], "entities": [{"text": "argmnent", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9933443069458008}]}, {"text": "The argument rests on empirical evidence from two series of experiments concerning automatic ambiguity resolution.", "labels": [], "entities": [{"text": "automatic ambiguity resolution", "start_pos": 83, "end_pos": 113, "type": "TASK", "confidence": 0.6152223745981852}]}, {"text": "1 Introduction In this paper, we present an empirical argument in favor of a certain approach to statistical natural language modeling: we advocate statistical natural language models that account for the interactions between the explanatory statistical variables, rather than relying on independence a~ssumptions.", "labels": [], "entities": [{"text": "statistical natural language modeling", "start_pos": 97, "end_pos": 134, "type": "TASK", "confidence": 0.6203950718045235}]}, {"text": "Such models are able to perform prediction on the basis of estimated probability distributions that are properly conditioned on the combinations of the individual values of the explanatory variables.", "labels": [], "entities": []}, {"text": "After describing one type of statistical model that is particularly well-suited to modeling natural language data, called a loglinear model, we present ein-pirical evidence fi'om a series of experiments on different ambiguity resolution tasks that show that the performance of the loglinear models outranks the performance of other models described in the literature that a~ssume independence between the explanatory variables.", "labels": [], "entities": []}, {"text": "2 Statistical Language Modeling By \"statistical language model\", we refer to a mathematical object that \"imitates the properties\" of some respects of naturM language, and in turn makes predictions that are useful from a scientific or engineering point of view.", "labels": [], "entities": [{"text": "Statistical Language Modeling", "start_pos": 2, "end_pos": 31, "type": "TASK", "confidence": 0.8098913033803304}]}, {"text": "Much recent work in this flame-work hm~ used written and spoken natural language data to estimate parameters for statisticM models that were characterized by serious limitations: models were either limited to a single explanatory variable or. if more than one explanatory variable wa~s considered, the variables were assumed to be independent.", "labels": [], "entities": []}, {"text": "In this section, we describe a method for statistical language modeling that transcends these limitations.", "labels": [], "entities": [{"text": "statistical language modeling", "start_pos": 42, "end_pos": 71, "type": "TASK", "confidence": 0.829866866270701}]}], "introductionContent": [{"text": "In this paper, we present an empirical argument in favor of a certain approach to statistical natural language modeling: we advocate statistical natural language models that account for the interactions between the explanatory statistical variables, rather than relying on independence a~ssumptions.", "labels": [], "entities": [{"text": "statistical natural language modeling", "start_pos": 82, "end_pos": 119, "type": "TASK", "confidence": 0.6258459016680717}]}, {"text": "Such models are able to perform prediction on the basis of estimated probability distributions that are properly conditioned on the combinations of the individual values of the explanatory variables.", "labels": [], "entities": []}, {"text": "After describing one type of statistical model that is particularly well-suited to modeling natural language data, called a loglinear model, we present einpirical evidence fi'om a series of experiments on different ambiguity resolution tasks that show that the performance of the loglinear models outranks the performance of other models described in the literature that a~ssume independence between the explanatory variables.", "labels": [], "entities": []}], "datasetContent": [{"text": "Training and evaluation data was prepared from the Penn treebank.", "labels": [], "entities": [{"text": "Penn treebank", "start_pos": 51, "end_pos": 64, "type": "DATASET", "confidence": 0.9924871623516083}]}, {"text": "All 1.1 million words of parsed text in the Brown Corpus, and 2.6 million words of parsed WSJ articles, were used.", "labels": [], "entities": [{"text": "Brown Corpus", "start_pos": 44, "end_pos": 56, "type": "DATASET", "confidence": 0.9879936873912811}, {"text": "WSJ articles", "start_pos": 90, "end_pos": 102, "type": "DATASET", "confidence": 0.8825928568840027}]}, {"text": "All instances of PPs that are attached to VPs and NPs were extracted.", "labels": [], "entities": []}, {"text": "This resulted in 82,000 PP cases from the Brown Corpus, and 89,000 PP cases from the WS.] articles.", "labels": [], "entities": [{"text": "Brown Corpus", "start_pos": 42, "end_pos": 54, "type": "DATASET", "confidence": 0.9192833006381989}, {"text": "WS.] articles", "start_pos": 85, "end_pos": 98, "type": "DATASET", "confidence": 0.8994023601214091}]}, {"text": "Verbs and nouns were lemmatized to their root forms if the root forms were attested in the corpus.", "labels": [], "entities": []}, {"text": "If the root form did not occur in the corpus, then the inflected form was used.", "labels": [], "entities": []}, {"text": "All the PP cases from the Brown Curl)us, and 50,000 of the WSJ cases, were reserved ms training data.", "labels": [], "entities": [{"text": "Brown Curl)us", "start_pos": 26, "end_pos": 39, "type": "DATASET", "confidence": 0.9634480476379395}, {"text": "WSJ cases", "start_pos": 59, "end_pos": 68, "type": "DATASET", "confidence": 0.9631492495536804}]}, {"text": "The remaining 39,00 WSJ PP cases formed the evaluation pool.", "labels": [], "entities": [{"text": "WSJ PP cases", "start_pos": 20, "end_pos": 32, "type": "DATASET", "confidence": 0.7289106845855713}]}, {"text": "In each experiment, performance IMutu',d Information provides an estimate of the magnitude of the ratio t)ctw(.(-n the joint prol)ability P(verb/noun,1)reposition), and the joint probability a.~-suming indcpendcnce P(verb/noun)P(prcl)osition ) -s(:(, (.", "labels": [], "entities": []}, {"text": "Previous work oll automatic PP attachment disambiguation has only considered the pattern of a verb phrase containing an object, and a final PP.", "labels": [], "entities": [{"text": "PP attachment disambiguation", "start_pos": 28, "end_pos": 56, "type": "TASK", "confidence": 0.8231531977653503}]}, {"text": "This lends to two possible attachment sites, the verb and the object of the verb.", "labels": [], "entities": []}, {"text": "The pattern is usually further simplified by considering only the heads of the possible attachment sites, corresponding to the sequence \"Verb Noun1 Preposition Noun2\".", "labels": [], "entities": []}, {"text": "The first set of experiments concerns this pattern.", "labels": [], "entities": []}, {"text": "There are 53,000 such cases in the training data. and 16,000 such cases in the evaluation pool.", "labels": [], "entities": []}, {"text": "A number of methods were evaluated on this pattern according to the 25-sample scheme described above.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "As suggested by, PP attachment for the \"'Verb NP PP\" pattern is relatively easy to predict because the two possible attachment sites differ in syntactic category, and therefore have very different kinds of lexical preferences.", "labels": [], "entities": [{"text": "PP attachment", "start_pos": 17, "end_pos": 30, "type": "TASK", "confidence": 0.8359621167182922}]}, {"text": "For example, most PPs with of attach to nouns, and most PPs with f,o and by attach to verbs.", "labels": [], "entities": []}, {"text": "In actual texts, there are often more than two possible attachment sites fora PP.", "labels": [], "entities": []}, {"text": "Thus, a second, more realistic series of experiments was perforlned that investigated different PP attachment strategies for the pattern \"'Verb Noun1 Noun2 Preposition Noun3\"' that includes more than two possible attachment sites that are not syntactically heterogeneous.", "labels": [], "entities": []}, {"text": "There were 28,000 such cases in the training data. and 8000 ca,~es in the evaluation pool.", "labels": [], "entities": []}], "tableCaptions": []}