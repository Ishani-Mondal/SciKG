{"title": [], "abstractContent": [{"text": "It is challenging to translate names and technical terms across languages with different alphabets and sound inventories.", "labels": [], "entities": [{"text": "translate names and technical terms", "start_pos": 21, "end_pos": 56, "type": "TASK", "confidence": 0.7848356366157532}]}, {"text": "These items are commonly transliterated, i.e., replaced with approximate phonetic equivalents.", "labels": [], "entities": []}, {"text": "For example, computer in English comes out as ~ i/l:::'=-~-(konpyuutaa) in Japanese.", "labels": [], "entities": []}, {"text": "Translating such items from Japanese back to English is even more challenging, and of practical interest, as transliterated items makeup the bulk of text phrases not found in bilingual dictionaries.", "labels": [], "entities": []}, {"text": "We describe and evaluate a method for performing backwards translitera-tions by machine.", "labels": [], "entities": []}, {"text": "This method uses a gen-erative model, incorporating several distinct stages in the transliteration process.", "labels": [], "entities": []}], "introductionContent": [{"text": "Translators must deal with many problems, and one of the most frequent is translating proper names and technical terms.", "labels": [], "entities": [{"text": "translating proper names and technical terms", "start_pos": 74, "end_pos": 118, "type": "TASK", "confidence": 0.8117379446824392}]}, {"text": "For language pairs like Spanish/English, this presents no great challenge: a phrase like Antonio Gil usually gets translated as Antonio Gil.", "labels": [], "entities": []}, {"text": "However, the situation is more complicated for language pairs that employ very different alphabets and sound systems, such as Japanese/English and Arabic/English.", "labels": [], "entities": []}, {"text": "Phonetic translation across these pairs is called transliteration.", "labels": [], "entities": [{"text": "Phonetic translation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8154266178607941}]}, {"text": "We will look at Japanese/English transliteration in this paper.", "labels": [], "entities": [{"text": "Japanese/English transliteration", "start_pos": 16, "end_pos": 48, "type": "TASK", "confidence": 0.5321910381317139}]}, {"text": "Japanese frequently imports vocabulary from other languages, primarily (but not exclusively) from English.", "labels": [], "entities": []}, {"text": "It has a special phonetic alphabet called katakana, which is used primarily (but not exclusively) to write down foreign names and loanwords.", "labels": [], "entities": []}, {"text": "To write a word like golf bag in katakana, some compromises must be made.", "labels": [], "entities": []}, {"text": "For example, Japanese has no distinct Land R sounds: the two English sounds collapse onto the same Japanese sound.", "labels": [], "entities": []}, {"text": "A similar compromise must be struck for English H and F.", "labels": [], "entities": [{"text": "English H", "start_pos": 40, "end_pos": 49, "type": "DATASET", "confidence": 0.8234758079051971}]}, {"text": "Also, Japanese generally uses an alternating consonant-vowel structure, making it impossible to pronounce LFB without intervening vowels.", "labels": [], "entities": []}, {"text": "Katakana writing is a syllabary rather than an alphabet--there is one symbol for ga (~I), another for gi (4e), another for gu (P'), etc.", "labels": [], "entities": []}, {"text": "So the way to write gol]bag in katakana is =~'~ 7 ~ ~, ~, roughly pronounced goruhubaggu.", "labels": [], "entities": []}, {"text": "Here area few more examples: Notice how the transliteration is more phonetic than orthographic; the letter h in Johnson does not produce any katakana.", "labels": [], "entities": []}, {"text": "Also, a dot-separator (.) is used to separate words, but not consistently.", "labels": [], "entities": []}, {"text": "And transliteration is clearly an information-losing operation: aisukuriimu loses the distinction between ice cream and I scream.", "labels": [], "entities": []}, {"text": "Transliteration is not trivial to automate, but we will be concerned with an even more challenging problem--going from katakana back to English, i.e., back-transliteration.", "labels": [], "entities": []}, {"text": "Automating backtransliteration has great practical importance in Japanese/English machine translation.", "labels": [], "entities": [{"text": "Japanese/English machine translation", "start_pos": 65, "end_pos": 101, "type": "TASK", "confidence": 0.5000766038894653}]}, {"text": "Katakana phrases are the largest source of text phrases that do not appear in bilingual dictionaries or training corpora (a.k.a. \"not-found words\").", "labels": [], "entities": []}, {"text": "However, very little computational work has been done in this area; briefly mentions a patternmatching approach, while) discuss a hybrid neural-net/expert-system approach to (forward) transliteration.", "labels": [], "entities": []}, {"text": "The information-losing aspect of transliteration makes it hard to invert.", "labels": [], "entities": []}, {"text": "Here are some problem instances, taken from actual newspaper articles: 1 ITexts used in ARPA Machine Translation evaluations, T--x~--(aasudee) (robaato shyoon renaado) ? \"~':~ ~--:~\" l.--)-~ y I-", "labels": [], "entities": [{"text": "ITexts", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.813139796257019}, {"text": "ARPA Machine Translation evaluations", "start_pos": 88, "end_pos": 124, "type": "TASK", "confidence": 0.7254383265972137}]}], "datasetContent": [{"text": "We have performed two large-scale experiments, one using a full-language P(w) model, and one using a personal name language model.", "labels": [], "entities": []}, {"text": "In the first experiment, we extracted 1449 unique katakana phrases from a corpus of 100 short news articles.", "labels": [], "entities": []}, {"text": "Of these, 222 were missing from an online 100,000-entry bilingual dictionary.", "labels": [], "entities": []}, {"text": "We backtransliterated these 222 phrases.", "labels": [], "entities": []}, {"text": "Many of the translations are perfect: technical program, sez scandal, omaha beach, new york times, ramon diaz.", "labels": [], "entities": []}, {"text": "Others are close: tanya harding, nickel simpson, danger washington, world cap.", "labels": [], "entities": [{"text": "danger washington", "start_pos": 49, "end_pos": 66, "type": "TASK", "confidence": 0.6168520450592041}]}, {"text": "Some miss the mark: nancy care again, plus occur, patriot miss real.", "labels": [], "entities": []}, {"text": "While it is difficult to judge overall accuracy--some of the phases are onomatopoetic, and others are simply too hard even for good human translators--it is easier to identify system weaknesses, and most of these lie in the P(w) model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.998885452747345}]}, {"text": "For example, nancy kerrigan should be preferred over nancy care again.", "labels": [], "entities": []}, {"text": "Ina second experiment, we took katakana versions of the names of 100 U.S. politicians, e.g.: -Jm :/.", "labels": [], "entities": []}, {"text": "7' =--(jyon.buroo), T~/~ . ~'0' I\" (a.rhonsu.dama~;'\u00a2o), and \"~'4 3' \u2022 ~7,f :/ (maiku.de~ain).", "labels": [], "entities": [{"text": "T", "start_pos": 20, "end_pos": 21, "type": "METRIC", "confidence": 0.9918236136436462}]}, {"text": "We back-transliterated these by machine and asked four human subjects to do the same.", "labels": [], "entities": []}, {"text": "These subjects were native English speakers and news-aware: we gave them brief instructions, examples, and hints.", "labels": [], "entities": []}, {"text": "The results were as follows: There is room for improvement on both sides.", "labels": [], "entities": []}, {"text": "Being English speakers, the human subjects were good at English name spelling and U.S. politics, but not at Japanese phonetics.", "labels": [], "entities": [{"text": "English name spelling", "start_pos": 56, "end_pos": 77, "type": "TASK", "confidence": 0.6658414701620737}]}, {"text": "A native Japanese speaker might be expert at the latter but not the former.", "labels": [], "entities": []}, {"text": "People who are expert in all of these areas, however, are rare.", "labels": [], "entities": []}, {"text": "many errors can be corrected.", "labels": [], "entities": []}, {"text": "A first-name/last-name model would rank richard bryan more highly than richard brian.", "labels": [], "entities": []}, {"text": "A bigram model would prefer orren hatch over olin hatch.", "labels": [], "entities": []}, {"text": "Other errors are due to unigram training problems, or more rarely, incorrect or brittle phonetic models.", "labels": [], "entities": []}, {"text": "For example, \"Long\" occurs much more often than \"R.on\" in newspaper text, and our word selection does not exclude phrases like \"Long Island.\"", "labels": [], "entities": [{"text": "Long Island", "start_pos": 128, "end_pos": 139, "type": "DATASET", "confidence": 0.9524541199207306}]}, {"text": "So we get long wyden instead of ton wyden.", "labels": [], "entities": []}, {"text": "Rare errors are due to incorrect or brittle phonetic models.", "labels": [], "entities": []}, {"text": "Still the machine's performance is impressive.", "labels": [], "entities": []}, {"text": "When word separators (,) are removed from the katakana phrases, rendering the task exceedingly difficult for people, the machine's performance is unchanged.", "labels": [], "entities": []}, {"text": "7% of katakana tokens are mis-recognized, affecting 50% of test strings, but accuracy only drops from 64% to 52%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9993639588356018}]}], "tableCaptions": []}