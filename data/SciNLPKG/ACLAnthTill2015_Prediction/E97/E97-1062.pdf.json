{"title": [{"text": "Learning Parse and Translation Decisions From Examples With Rich Context", "labels": [], "entities": [{"text": "Learning Parse and Translation Decisions", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.6747114300727844}]}], "abstractContent": [{"text": "We present a knowledge and context-based system for parsing and translating natural language and evaluate it on sentences from the Wall Street Journal.", "labels": [], "entities": [{"text": "parsing and translating natural language", "start_pos": 52, "end_pos": 92, "type": "TASK", "confidence": 0.8290587067604065}, {"text": "Wall Street Journal", "start_pos": 131, "end_pos": 150, "type": "DATASET", "confidence": 0.9606365362803141}]}, {"text": "Applying machine learning techniques, the system uses parse action examples acquired under supervision to generate a determinis-tic shift-reduce parser in the form of a decision structure.", "labels": [], "entities": []}, {"text": "It relies heavily on context , as encoded in features which describe the morphological, syntactic, semantic and other aspects of a given parse state.", "labels": [], "entities": []}, {"text": "1 Introduction The parsing of unrestricted text, with its enormous lexical and structural ambiguity, still poses a great challenge in natural language processing.", "labels": [], "entities": [{"text": "parsing of unrestricted text", "start_pos": 19, "end_pos": 47, "type": "TASK", "confidence": 0.8477102816104889}]}, {"text": "The traditional approach of trying to master the complexity of parse grammars with hand-coded rules turned out to be much more difficult than expected, if not impossible.", "labels": [], "entities": []}, {"text": "Newer statistical approaches with often only very limited context sensitivity seem to have hit a performance ceiling even when trained on very large corpora.", "labels": [], "entities": []}, {"text": "To cope with the complexity of unrestricted text, parse rules in any kind of formalism will have to consider a complex context with many different morphological , syntactic or semantic features.", "labels": [], "entities": []}, {"text": "This can present a significant problem, because even linguistically trained natural language developers have great difficulties writing and even more so extending explicit parse grammars covering a wide range of natural language.", "labels": [], "entities": []}, {"text": "On the other hand it is much easier for humans to decide how specific sentences should be analyzed.", "labels": [], "entities": []}, {"text": "We therefore propose an approach to parsing based on learning from examples with a very strong emphasis on context, integrating morphological, syntactic, semantic and other aspects relevant to making good parse decisions, thereby also allowing the parsing to be deterministic.", "labels": [], "entities": [{"text": "parsing", "start_pos": 36, "end_pos": 43, "type": "TASK", "confidence": 0.9798685908317566}]}, {"text": "Applying machine learning techniques, the system uses parse action examples acquired under supervision to generate a de-terministic shift-reduce type parser in the form of a decision structure.", "labels": [], "entities": []}, {"text": "The generated parser transforms input sentences into an integrated phrase-structure and case-frame tree, powerful enough to be fed into a transfer and a generation module to complete the full process of machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 203, "end_pos": 222, "type": "TASK", "confidence": 0.708060547709465}]}, {"text": "Balanced by rich context and some background knowledge, our corpus based approach relieves the NL-developer from the hard if not impossible task of writing explicit grammar rules and keeps grammar coverage increases very manageable.", "labels": [], "entities": []}, {"text": "Compared with standard statistical methods, our system relies on deeper analysis and more supervision, but radically fewer examples.", "labels": [], "entities": []}, {"text": "2 Basic Parsing Paradigm As the basic mechanism for parsing text into a shallow semantic representation, we choose a shift-reduce type parser (Marcus, 1980).", "labels": [], "entities": []}, {"text": "It breaks parsing into an ordered sequence of small and manageable parse actions such as shift and reduce.", "labels": [], "entities": []}, {"text": "This ordered 'left-to-right' parsing is much closer to how humans parse a sentence than, for example, chart oriented parsers; it allows a very transparent control structure and makes the parsing process relatively intuitive for humans.", "labels": [], "entities": []}, {"text": "This is very important, because during the training phase, the system is guided by a human supervisor for whom the flow of control needs to be as transparent and intuitive as possible.", "labels": [], "entities": []}, {"text": "The parsing does not have separate phases for part-of-speech selection and syntactic and semantic processing, but rather integrates all of them into a single parsing phase.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9688190817832947}, {"text": "part-of-speech selection", "start_pos": 46, "end_pos": 70, "type": "TASK", "confidence": 0.6811690330505371}, {"text": "syntactic and semantic processing", "start_pos": 75, "end_pos": 108, "type": "TASK", "confidence": 0.6202719956636429}]}, {"text": "Since the system has all morphological , syntactic and semantic context information available at all times, the system can make well-482", "labels": [], "entities": []}], "introductionContent": [{"text": "The parsing of unrestricted text, with its enormous lexical and structural ambiguity, still poses a great challenge in natural language processing.", "labels": [], "entities": [{"text": "parsing of unrestricted text", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.8339361548423767}]}, {"text": "The traditional approach of trying to master the complexity of parse grammars with hand-coded rules turned out to be much more difficult than expected, if not impossible.", "labels": [], "entities": []}, {"text": "Newer statistical approaches with often only very limited context sensitivity seem to have hit a performance ceiling even when trained on very large corpora.", "labels": [], "entities": []}, {"text": "To cope with the complexity of unrestricted text, parse rules in any kind of formalism will have to consider a complex context with many different morphological, syntactic or semantic features.", "labels": [], "entities": []}, {"text": "This can present a significant problem, because even linguistically trained natural language developers have great difficulties writing and even more so extending explicit parse grammars covering a wide range of natural language.", "labels": [], "entities": []}, {"text": "On the other hand it is much easier for humans to decide how specific sentences should be analyzed.", "labels": [], "entities": []}, {"text": "We therefore propose an approach to parsing based on learning from examples with a very strong emphasis on context, integrating morphological, syntactic, semantic and other aspects relevant to making good parse decisions, thereby also allowing the parsing to be deterministic.", "labels": [], "entities": [{"text": "parsing", "start_pos": 36, "end_pos": 43, "type": "TASK", "confidence": 0.9798685908317566}]}, {"text": "Applying machine learning techniques, the system uses parse action examples acquired under supervision to generate a deterministic shift-reduce type parser in the form of a decision structure.", "labels": [], "entities": []}, {"text": "The generated parser transforms input sentences into an integrated phrase-structure and case-frame tree, powerful enough to be fed into a transfer and a generation module to complete the full process of machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 203, "end_pos": 222, "type": "TASK", "confidence": 0.708060547709465}]}, {"text": "Balanced by rich context and some background knowledge, our corpus based approach relieves the NL-developer from the hard if not impossible task of writing explicit grammar rules and keeps grammar coverage increases very manageable.", "labels": [], "entities": []}, {"text": "Compared with standard statistical methods, our system relies on deeper analysis and more supervision, but radically fewer examples.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Evaluation results with varying number of  training sentences; with all 205 features and hybrid  decision structure; Train. = number of training sen- tences; pr/prec. = precision; rec. = recall; I. = la- beled; Tagging = tagging accuracy; Cr/snt = cross- ings per sentence; Ops = correct operations; OpSeq  = Operation Sequence", "labels": [], "entities": [{"text": "precision", "start_pos": 179, "end_pos": 188, "type": "METRIC", "confidence": 0.9943825006484985}, {"text": "recall", "start_pos": 197, "end_pos": 203, "type": "METRIC", "confidence": 0.9851655960083008}, {"text": "accuracy", "start_pos": 239, "end_pos": 247, "type": "METRIC", "confidence": 0.9870737791061401}, {"text": "OpSeq", "start_pos": 310, "end_pos": 315, "type": "METRIC", "confidence": 0.8720999956130981}]}, {"text": " Table 2: Evaluation results with varying number of  features; with 256 training sentences", "labels": [], "entities": []}, {"text": " Table 3: Evaluation results with varying types of  decision structures; with 256 training sentences and  205 features", "labels": [], "entities": []}, {"text": " Table 4: Translation evaluation results (best possi- ble = 1.00, worst possible = 6.00)", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9313788414001465}, {"text": "possi- ble", "start_pos": 47, "end_pos": 57, "type": "METRIC", "confidence": 0.8327956199645996}]}, {"text": " Table 5: Correlation between various parse and  translation metrics. Values near -1.0 or 1.0 indi- cate very strong correlation, whereas values near 0.0  indicate a weak or no correlation. Most correlation  values, incl. for labeled precision are negative, be- cause a higher (better) labeled precision correlates  with a numerically lower (better) translation score  on the 1.0 (best) to 6.0 (worst) translation evalua- tion scale.", "labels": [], "entities": []}, {"text": " Table 6: Comparing our system CONTEX with  Magerman's SPATTER, and Collins' BLD; results for  SPATTER, and BLD are for sentences of up to 40", "labels": [], "entities": [{"text": "CONTEX", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9793054461479187}, {"text": "Collins' BLD", "start_pos": 68, "end_pos": 80, "type": "DATASET", "confidence": 0.714565709233284}, {"text": "BLD", "start_pos": 108, "end_pos": 111, "type": "METRIC", "confidence": 0.9297024011611938}]}]}