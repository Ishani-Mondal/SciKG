{"title": [{"text": "Using Syntactic Dependency as Local Context to Resolve Word Sense Ambiguity", "labels": [], "entities": [{"text": "Resolve Word Sense Ambiguity", "start_pos": 47, "end_pos": 75, "type": "TASK", "confidence": 0.8685395121574402}]}], "abstractContent": [{"text": "Most previous corpus-based algorithms dis-ambiguate a word with a classifier trained from previous usages of the same word.", "labels": [], "entities": []}, {"text": "Separate classifiers have to be trained for different words.", "labels": [], "entities": []}, {"text": "We present an algorithm that uses the same knowledge sources to disambiguate different words.", "labels": [], "entities": []}, {"text": "The algorithm does not require a sense-tagged corpus and exploits the fact that two different words are likely to have similar meanings if they occur in identical local contexts.", "labels": [], "entities": []}, {"text": "1 Introduction Given a word, its context and its possible meanings, the problem of word sense disambiguation (WSD) is to determine the meaning of the word in that context.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 83, "end_pos": 114, "type": "TASK", "confidence": 0.8023736576239268}]}, {"text": "WSD is useful in many natural language tasks, such as choosing the correct word in machine translation and coreference resolution.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.7089081108570099}, {"text": "coreference resolution", "start_pos": 107, "end_pos": 129, "type": "TASK", "confidence": 0.9513446688652039}]}], "introductionContent": [{"text": "Given a word, its context and its possible meanings, the problem of word sense disambiguation (WSD) is to determine the meaning of the word in that context.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 68, "end_pos": 99, "type": "TASK", "confidence": 0.8056148042281469}]}, {"text": "WSD is useful in many natural language tasks, such as choosing the correct word in machine translation and coreference resolution.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.7089081108570099}, {"text": "coreference resolution", "start_pos": 107, "end_pos": 129, "type": "TASK", "confidence": 0.9513441026210785}]}, {"text": "In several recent proposals, statistical and machine learning techniques were used to extract classifiers from hand-tagged corpus.", "labels": [], "entities": []}, {"text": "Yarowsky proposed an unsupervised method that used heuristics to obtain seed classifications and expanded the results to the other parts of the corpus, thus avoided the need to hand-annotate any examples.", "labels": [], "entities": []}, {"text": "Most previous corpus-based WSD algorithms determine the meanings of polysemous words by exploiting their local contexts.", "labels": [], "entities": []}, {"text": "A basic intuition that underlies those algorithms is the following: (i) Two occurrences of the same word have identical meanings if they have similar local contexts.", "labels": [], "entities": []}, {"text": "In other words, most previous corpus-based WSD algorithms learn to disambiguate a polysemous word from previous usages of the same word.", "labels": [], "entities": [{"text": "WSD", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.9327548146247864}]}, {"text": "This has several undesirable consequences.", "labels": [], "entities": []}, {"text": "Firstly, a word must occur thousands of times before a good classifier can be learned.", "labels": [], "entities": []}, {"text": "In Yarowsky's experiment, an average of 3936 examples were used to disambiguate between two senses.", "labels": [], "entities": []}, {"text": "In Ng and Lee's experiment, 192,800 occurrences of 191 words were used as training examples.", "labels": [], "entities": []}, {"text": "There are thousands of polysemous words, e.g., there are 11,562 polysemous nouns in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 84, "end_pos": 91, "type": "DATASET", "confidence": 0.9754164814949036}]}, {"text": "For every polysemous word to occur thousands of times each, the corpus must contain billions of words.", "labels": [], "entities": []}, {"text": "Secondly, learning to disambiguate a word from the previous usages of the same word means that whatever was learned for one word is not used on other words, which obviously missed generality in natural languages.", "labels": [], "entities": []}, {"text": "Thirdly, these algorithms cannot deal with words for which classifiers have not been learned.", "labels": [], "entities": []}, {"text": "In this paper, we present a WSD algorithm that relies on a different intuition: (2) Two different words are likely to have similar meanings if they occur in identical local contexts.", "labels": [], "entities": [{"text": "WSD", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9442178606987}]}, {"text": "Consider the sentence: The new facility will employ 500 of the existing 600 employees The word \"facility\" has 5 possible meanings in WordNet 1.5: (a) installation, (b) proficiency/technique, (c) adeptness, (d) readiness, (e) toilet/bathroom.", "labels": [], "entities": [{"text": "WordNet 1.5", "start_pos": 133, "end_pos": 144, "type": "DATASET", "confidence": 0.9246154427528381}, {"text": "readiness", "start_pos": 210, "end_pos": 219, "type": "METRIC", "confidence": 0.9977274537086487}]}, {"text": "To disambiguate the word, we consider other words that appeared in an identical local context as \"facility\" in (3). is a list of words that have also been used as the subject of \"employ\" in a 25-million-word Wall Street Journal corpus.", "labels": [], "entities": [{"text": "Wall Street Journal corpus", "start_pos": 208, "end_pos": 234, "type": "DATASET", "confidence": 0.9540230333805084}]}, {"text": "The \"freq\" column are the number of times these words were used as the subject of \"employ\".", "labels": [], "entities": [{"text": "freq\" column", "start_pos": 5, "end_pos": 17, "type": "METRIC", "confidence": 0.9741159081459045}]}, {"text": "The logA column are their likelihood ratios).", "labels": [], "entities": [{"text": "likelihood", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.9623916745185852}]}, {"text": "The meaning of \"facility\" in (3) can be determined by choosing one of its 5 senses that is most similar 1 to the meanings of words in.", "labels": [], "entities": []}, {"text": "This way, a polysemous word is disambiguated with past usages of other words.", "labels": [], "entities": []}, {"text": "Whether or not it appears in the corpus is irrelevant.", "labels": [], "entities": []}, {"text": "Our approach offers several advantages: \u2022 The same knowledge sources are used for all words, as opposed to using a separate classifier for each individual word.", "labels": [], "entities": []}, {"text": "\u2022 It requires a much smaller corpus that needs not be sense-tagged.", "labels": [], "entities": []}, {"text": "\u2022 It is able to deal with words that are infrequent or do not even appear in the corpus.", "labels": [], "entities": []}, {"text": "\u2022 The same mechanism can also be used to infer the semantic categories of unknown words.", "labels": [], "entities": []}, {"text": "The required resources of the algorithm include the following: (a) an untagged text corpus, (b) a broad-coverage parser, (c) a concept hierarchy, such as the WordNet) or Roget's Thesaurus, and (d) a similarity measure between concepts.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 158, "end_pos": 165, "type": "DATASET", "confidence": 0.9442185163497925}]}, {"text": "In the next section, we introduce our definition of local contexts and the database of local contexts.", "labels": [], "entities": []}, {"text": "A description of the disambiguation algorithm is presented in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 discusses the evaluation results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used a subset of the SemCor ( to evaluate our algorithm.", "labels": [], "entities": []}, {"text": "General-purpose lexical resources, such as WordNet, Longman Dictionary of Contemporary English (LDOCE), and Roget's Thesaurus, strive to achieve completeness.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 43, "end_pos": 50, "type": "DATASET", "confidence": 0.960224986076355}, {"text": "Longman Dictionary of Contemporary English (LDOCE)", "start_pos": 52, "end_pos": 102, "type": "DATASET", "confidence": 0.9307152330875397}]}, {"text": "They often make subtle distinctions between word senses.", "labels": [], "entities": []}, {"text": "As a result, when the WSD task is defined as choosing a sense out of a list of senses in a general-purpose lexical resource, even humans may frequently disagree with one another on what the correct sense should be.", "labels": [], "entities": [{"text": "WSD task", "start_pos": 22, "end_pos": 30, "type": "TASK", "confidence": 0.9136894941329956}]}, {"text": "The subtle distinctions between different word senses are often unnecessary.", "labels": [], "entities": []}, {"text": "Therefore, we relaxed the correctness criterion.", "labels": [], "entities": []}, {"text": "A selected sense 8answer is correct if it is \"similar enough\" to the sense tag skeu in SemCor.", "labels": [], "entities": []}, {"text": "We experimented with three interpretations of \"similar enough\".", "labels": [], "entities": []}, {"text": "The strictest interpretation is sim(sanswer,Ske~)=l, which is true only when 8answer~Skey.", "labels": [], "entities": []}, {"text": "The most relaxed interpretation is sim(s~nsw~, Skey) >0, which is true if 8answer and 8key are the descendents of the same top-level concepts in WordNet (e.g., entity, group, location, etc.).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 145, "end_pos": 152, "type": "DATASET", "confidence": 0.9386002421379089}]}, {"text": "A compromise between these two is sim(Sans~er, Skew) >_ 0.27, where 0.27 is the average similarity of 50,000 randomly generated pairs in which wand w ~ belong to the same Roget's category.", "labels": [], "entities": []}, {"text": "We use three words \"duty\", \"interest\" and \"line\" as examples to provide a rough idea about what sirn( s~nswer, Skew) >_ 0.27 means.", "labels": [], "entities": []}, {"text": "The word \"duty\" has three senses in WordNet 1.5.", "labels": [], "entities": [{"text": "WordNet 1.5", "start_pos": 36, "end_pos": 47, "type": "DATASET", "confidence": 0.9419746994972229}]}, {"text": "The similarity between the three senses are all below 0.27, although the similarity between Senses 1 (responsibility) and 2 (assignment, chore) is very close (0.26) to the threshold.", "labels": [], "entities": []}, {"text": "The word \"interest\" has 8 senses.", "labels": [], "entities": []}, {"text": "Senses 1 (sake, benefit) and 7 (interestingness) are merged.", "labels": [], "entities": []}, {"text": "2 Senses 3 (fixed charge for borrowing money), 4 (a right or legal share of something), and 5 (financial interest in something) are merged.", "labels": [], "entities": []}, {"text": "The word \"interest\" is reduced to a 5-way ambiguous word.", "labels": [], "entities": []}, {"text": "The other three senses are 2 (curiosity), 6 (interest group) and 8 (pastime, hobby).", "labels": [], "entities": []}, {"text": "The word \"line\" has 27 senses.", "labels": [], "entities": []}, {"text": "The similarity threshold 0.27 reduces the number of senses to 14.", "labels": [], "entities": [{"text": "similarity threshold 0.27", "start_pos": 4, "end_pos": 29, "type": "METRIC", "confidence": 0.9709375699361166}]}, {"text": "The reduced senses are \u2022 Senses 1, 5, 17 and 24: something that is communicated between people or groups.", "labels": [], "entities": []}, {"text": "1: a mark that is long relative to its width 5: a linear string of words expressing some idea ')The similarities between senses of the same word are computed during scoring.", "labels": [], "entities": []}, {"text": "We do not actually change the WordNet hierarchy 17: a mark indicating positions or bounds of the playing area 24: as in \"drop me a line when you get there\" \u2022 Senses 2, 3, 9, 14, 18: group 2: a formation of people or things beside one another 3: a formation of people or things one after another 9: a connected series of events or actions or developments 14: the descendants of one individual 18: common carrier where each group is a reduced sense and the numbers are original WordNet sense numbers.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Subjects of \"employ\" with highest likelihood ratio", "labels": [], "entities": [{"text": "likelihood", "start_pos": 44, "end_pos": 54, "type": "METRIC", "confidence": 0.9107440114021301}]}, {"text": " Table 2: Modifiees of \"new\" with the highest likeli- hood ratios", "labels": [], "entities": [{"text": "likeli- hood ratios", "start_pos": 46, "end_pos": 65, "type": "METRIC", "confidence": 0.8608871549367905}]}]}