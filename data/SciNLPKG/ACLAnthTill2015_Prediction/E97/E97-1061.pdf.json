{"title": [{"text": "Retrieving Collocations by Co-occurrences and Word Order Constraints", "labels": [], "entities": [{"text": "Retrieving Collocations", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9691641628742218}]}], "abstractContent": [{"text": "In this paper, we describe a method for automatically retrieving collocations from large text corpora.", "labels": [], "entities": []}, {"text": "This method retrieve collocations in the following stages: 1) extracting strings of characters as units of collocations 2) extracting recurrent combinations of strings in accordance with their word order in a corpus as collocations.", "labels": [], "entities": []}, {"text": "Through the method, various range of col-locations, especially domain specific collo-cations, are retrieved.", "labels": [], "entities": []}, {"text": "The method is practical because it uses plain texts without any information dependent on a language such as lexical knowledge and parts of speech.", "labels": [], "entities": []}], "introductionContent": [{"text": "A collocation is a recurrent combination of words, ranging from word level to sentence level.", "labels": [], "entities": []}, {"text": "In this paper, we classify collocations into two types according to their structures.", "labels": [], "entities": []}, {"text": "One is an uninterrupted collocation which consists of a sequence of words, the other is an interrupted collocation which consists of words containing one or several gaps filled in by substitutable words or phrases which belong to the same category.", "labels": [], "entities": []}, {"text": "The features of collocations are defined as follows: \u2022 collocations are recurrent \u2022 collocations consist of one or several lexical units \u2022 order of units are rigid in a collocation.", "labels": [], "entities": []}, {"text": "For language processing such as machine translation, a knowledge of domain specific collocations is indispensable because what collocations mean are different from their literal meaning and the usage and meaning of a collocation is totally dependent on each domain.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.747220903635025}]}, {"text": "In addition, new collocations are produced one after another and most of them are technical jargons.", "labels": [], "entities": []}, {"text": "There has been a growing interest in corpus-based approaches which retrieve collocations from large corpora (, ),,,,,.", "labels": [], "entities": []}, {"text": "Although these approaches achieved good results for the task considered, most of them aim to extract fixed collocations, mainly noun phrases, and require the information which is dependent on each language such as dictionaries and parts of speech.", "labels": [], "entities": []}, {"text": "From a practical point of view, however, a more robust and flexible approach is desirable.", "labels": [], "entities": []}, {"text": "We propose a method to retrieve interrupted and uninterrupted collocations by the frequencies of co-occurrences and word order constraints from a monolingual corpus.", "labels": [], "entities": []}, {"text": "The method comprises two stages: the first stage extracts sequences of words (or characters) t from a corpus as units of collocations and the second stage extracts recurrent combinations of units and constructs collocations by arranging them in accordance with word order in the corpus.", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed an experiment for evaluating the algorithm.", "labels": [], "entities": []}, {"text": "The corpus used in the experiment is a computer manual written in English comprising 1,311,522 words (in 120,240 sentences).", "labels": [], "entities": []}, {"text": "In the first stage of this method, 167,387 strings are produced.", "labels": [], "entities": []}, {"text": "Among them, 650, 1950, 6774 strings are extracted over the entropy threshold 2, 1.5, 1 respectively.", "labels": [], "entities": []}, {"text": "For 650 strings whose entropy is greater than 2, 162 strings (24.9%) are complete sentences, 297 strings (45.7%) are regarded as grammatically appropriate units, and 114 strings (17.5%) are regarded as meaningful units even though they are not grammatical.", "labels": [], "entities": []}, {"text": "This told us that the precision of the first stage is 88.1%.", "labels": [], "entities": [{"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.9998071789741516}]}, {"text": "shows top 20 strings in order of entropy value.", "labels": [], "entities": []}, {"text": "They are quite representative of the given domain.", "labels": [], "entities": []}, {"text": "Most of them are technical jargons related to computers and typical expressions used in manual descriptions although they vary in their constructions.", "labels": [], "entities": []}, {"text": "It is interesting to note that the strings which do not belong to the grammatical units also take high entropy value.", "labels": [], "entities": []}, {"text": "Some of them contain punctuation, and some of them terminate in articles.", "labels": [], "entities": []}, {"text": "Punctuation marks and function words in the strings are useful to recognize how the strings are used in a corpus.", "labels": [], "entities": []}, {"text": "illustrates how the entropy is changed with the change of string length.", "labels": [], "entities": []}, {"text": "The third column in the table shows the kinds of adjacent words which follow the strings.", "labels": [], "entities": []}, {"text": "The table shows that the ungrammatical strings such as \"For more information on\" and \"For more information, refer to\" act more cohesively than the grammatical string \"For more information\" in the corpus.", "labels": [], "entities": []}, {"text": "Actually, the former strings are more useful to construct collocations in the second stage.", "labels": [], "entities": []}, {"text": "In the second stage, we extracted collocations from 411 key strings retrieved in the first stage (297 grammatical units and 114 meaningful units).", "labels": [], "entities": []}, {"text": "Necessary thresholds are given by the following set of equations:.", "labels": [], "entities": []}, {"text": "Evaluation is done by human check and 180 collocations are regarded as meaningful.", "labels": [], "entities": []}, {"text": "The precision is 43.8% when the number of meaningful collocation is divided by the number of the key strings and 66.9% when it is divided by the number of the collocations retrieved in the second stage 2.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9993769526481628}]}, {"text": "shows the collocations extracted with the underlined key strings.", "labels": [], "entities": []}, {"text": "The table indicates that arbitrary length of collocations, which are frequently used in computer manuals, are retrieved through the method.", "labels": [], "entities": []}, {"text": "As the method focuses on the cooccurrence of strings, most of the collocations are specific to the given domain.", "labels": [], "entities": []}, {"text": "Common collocations are tend to be ignored because they are not used repeatedly in a single text.", "labels": [], "entities": []}, {"text": "It is not a serious problem, 2Usually the latter ratio is adopted as precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9993896484375}]}, {"text": "however, becausecommon collocations are limited in number and we can efficiently obtain them from dictionaries or by human reflection.", "labels": [], "entities": []}, {"text": "No. 7 and 8 in are the examples of invalid collocations.", "labels": [], "entities": []}, {"text": "They contain unnecessary strings such as \"to a\" and \", the\" in them.", "labels": [], "entities": []}, {"text": "The majority of invalid collocations are of this type.", "labels": [], "entities": []}, {"text": "One possible solution is to eliminate unnecessary strings at the second stage.", "labels": [], "entities": []}, {"text": "Most of the unnecessary strings consist of only punctuation marks and function words.", "labels": [], "entities": []}, {"text": "Therefore, by filtering out these strings, invalid collocations produced by the method should be reduced.", "labels": [], "entities": []}, {"text": "summarizes the result of the evaluation.", "labels": [], "entities": []}, {"text": "In the experiment, 573 strings are retrieved as appropriate units of collocations and 180 combinations of units are retrieved as appropriate collocations.", "labels": [], "entities": []}, {"text": "Precision is 88.1% in the first stage, and 66.9% in the second stage.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9946897029876709}]}, {"text": "Although evaluation of retrieval systems is usually performed with precision and recall, we cannot examine recall rate in the experiment.", "labels": [], "entities": [{"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9995806813240051}, {"text": "recall", "start_pos": 81, "end_pos": 87, "type": "METRIC", "confidence": 0.999114453792572}, {"text": "recall rate", "start_pos": 107, "end_pos": 118, "type": "METRIC", "confidence": 0.9837623834609985}]}, {"text": "It is difficult to recognize how many collocations are in a corpus because the measure differs largely dependent on the domain or the application considered.", "labels": [], "entities": []}, {"text": "As an alternative way to evaluate the algorithm, we are planning to apply the collocations retrieved to a machine translation system and evaluate how they contribute to the quality of translation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Result of the second step", "labels": [], "entities": [{"text": "Result", "start_pos": 10, "end_pos": 16, "type": "TASK", "confidence": 0.6577072143554688}]}, {"text": " Table 2: Result of the third step", "labels": [], "entities": []}, {"text": " Table 3: Top 20 strings extracted at the first stage", "labels": [], "entities": []}]}