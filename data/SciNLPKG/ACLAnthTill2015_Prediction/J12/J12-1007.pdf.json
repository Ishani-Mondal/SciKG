{"title": [{"text": "Book Reviews Graph-Based Natural Language Processing and Information Retrieval", "labels": [], "entities": [{"text": "Graph-Based Natural Language Processing", "start_pos": 13, "end_pos": 52, "type": "TASK", "confidence": 0.7389438450336456}, {"text": "Information Retrieval", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.7296430319547653}]}], "abstractContent": [{"text": "There is hardly any domain in which objects and their relations cannot be intuitively represented as nodes and edges in a graph.", "labels": [], "entities": []}, {"text": "Graph theory is a well-studied sub-discipline of mathematics, with a large body of results and a large number of efficient algorithms that operate on graphs.", "labels": [], "entities": [{"text": "Graph theory", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.8981657922267914}]}, {"text": "Like many other disciplines, the fields of natural language processing (NLP) and information retrieval (IR) also deal with data that can be represented as a graph.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 43, "end_pos": 76, "type": "TASK", "confidence": 0.8241479893525442}, {"text": "information retrieval (IR)", "start_pos": 81, "end_pos": 107, "type": "TASK", "confidence": 0.854317981004715}]}, {"text": "In this light, it is somewhat surprising that only in recent years the applicability of graph-theoretical frameworks to language technology became apparent and increasingly found its way into publications in the field of computational linguistics.", "labels": [], "entities": []}, {"text": "Using algorithms that take the overall graph structure of a problem into account, rather than characteristics of single objects or (unstructured) sets of objects, graph-based methods have been shown to improve a wide range of NLP tasks.", "labels": [], "entities": []}, {"text": "Ina short but comprehensive overview of the field of graph-based methods for NLP and IR, Rada Mihalcea and Dragomir Radev list an extensive number of techniques and examples from a wide range of research papers by a large number of authors.", "labels": [], "entities": [{"text": "IR", "start_pos": 85, "end_pos": 87, "type": "TASK", "confidence": 0.8751738667488098}]}, {"text": "This book provides an excellent review of this research area, and serves both as an introduction and as a survey of current graph-based techniques in NLP and IR.", "labels": [], "entities": [{"text": "IR", "start_pos": 158, "end_pos": 160, "type": "TASK", "confidence": 0.9329153895378113}]}, {"text": "Because the few existing surveys in this field concentrate on particular aspects, such as graph clustering (Lancichinetti and Fortunato 2009) or IR (Liu 2006), a textbook on the topic was very much needed and this book surely fills this gap.", "labels": [], "entities": [{"text": "graph clustering", "start_pos": 90, "end_pos": 106, "type": "TASK", "confidence": 0.787491649389267}, {"text": "IR", "start_pos": 145, "end_pos": 147, "type": "TASK", "confidence": 0.9738735556602478}]}, {"text": "The book is organized in four parts and contains a total of nine chapters.", "labels": [], "entities": []}, {"text": "The first part gives an introduction to notions of graph theory, and the second part covers natural and random networks.", "labels": [], "entities": [{"text": "graph theory", "start_pos": 51, "end_pos": 63, "type": "TASK", "confidence": 0.7638019621372223}]}, {"text": "The third part is devoted to graph-based IR, and part IV covers graph-based NLP.", "labels": [], "entities": [{"text": "IR", "start_pos": 41, "end_pos": 43, "type": "TASK", "confidence": 0.8814608454704285}]}, {"text": "Chapter 1 lays the groundwork for the remainder of the book by introducing all necessary concepts in graph theory, including the notation, graph properties, and graph representations.", "labels": [], "entities": []}, {"text": "In the second chapter, a glimpse is offered into the plethora of graph-based algorithms that have been developed independently of applications in NLP and IR.", "labels": [], "entities": [{"text": "IR", "start_pos": 154, "end_pos": 156, "type": "TASK", "confidence": 0.9356904625892639}]}, {"text": "Sacrificing depth for breadth, this chapter does a great job in touching on a wide variety of methods, including minimum spanning trees, shortest-path algorithms, cuts and flows, subgraph matching, dimensionality reduction, random walks, spreading activation, and more.", "labels": [], "entities": [{"text": "subgraph matching", "start_pos": 179, "end_pos": 196, "type": "TASK", "confidence": 0.8211311399936676}, {"text": "dimensionality reduction", "start_pos": 198, "end_pos": 222, "type": "TASK", "confidence": 0.7197321504354477}, {"text": "spreading activation", "start_pos": 238, "end_pos": 258, "type": "TASK", "confidence": 0.9090837836265564}]}, {"text": "Algorithms are explained concisely, using examples, pseudo-code, and/or illustrations, some of which are very well suited for classroom examples.", "labels": [], "entities": []}, {"text": "Network theory is presented in Chapter 3.", "labels": [], "entities": [{"text": "Network theory", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8494246900081635}]}, {"text": "The term network is here used to refer to naturally occurring relations, as opposed to graphs being generated by an automated process.", "labels": [], "entities": []}, {"text": "After presenting the classical Erd\u02dd os-R\u00e9nyi random graph model and showing its inadequacy to model power-law degree distributions following Zipf's law, scale-free small-world networks are introduced.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}