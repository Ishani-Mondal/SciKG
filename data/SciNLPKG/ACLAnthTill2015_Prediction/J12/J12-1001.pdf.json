{"title": [{"text": "Affirmative Cue Words in Task-Oriented Dialogue", "labels": [], "entities": [{"text": "Affirmative Cue Words in Task-Oriented Dialogue", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.7817050417264303}]}], "abstractContent": [{"text": "We present a series of studies of affirmative cue words-a family of cue words such as \"okay\" or \"alright\" that speakers use frequently in conversation.", "labels": [], "entities": []}, {"text": "These words pose a challenge for spoken dialogue systems because of their ambiguity: They maybe used for agreeing with what the interlocutor has said, indicating continued attention, or for cueing the start of anew topic, among other meanings.", "labels": [], "entities": [{"text": "cueing the start of anew topic", "start_pos": 190, "end_pos": 220, "type": "TASK", "confidence": 0.7593381802241007}]}, {"text": "We describe differences in the acoustic/prosodic realization of such functions in a corpus of spontaneous, task-oriented dialogues in Standard American English.", "labels": [], "entities": []}, {"text": "These results are important both for interpretation and for production in spoken language applications.", "labels": [], "entities": [{"text": "interpretation", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.9749261736869812}]}, {"text": "We also assess the predictive power of computational methods for the automatic disambiguation of these words.", "labels": [], "entities": []}, {"text": "We find that contextual information and final intonation figure as the most salient cues to automatic disambiguation.", "labels": [], "entities": []}], "introductionContent": [{"text": "CUE PHRASES are linguistic expressions that maybe used to convey explicit information about the discourse or dialogue, or to convey a more literal, semantic contribution.", "labels": [], "entities": [{"text": "CUE", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.4120084047317505}, {"text": "PHRASES", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.8364999294281006}]}, {"text": "They aid speakers and writers in organizing the discourse, and listeners and readers in processing it.", "labels": [], "entities": []}, {"text": "In previous literature, these constructions have also been termed discourse markers, pragmatic connectives, discourse operators, and clue words.", "labels": [], "entities": []}, {"text": "Examples of cue phrases include now, well, so, and, but, then, after all, furthermore, however, in consequence, as a matter of fact, in fact, actually, okay, alright, for example, and incidentally.", "labels": [], "entities": []}, {"text": "The ability to correctly determine the function of cue phrases is critical for important natural language processing tasks, including anaphora resolution (, argument understanding, plan recognition (, and discourse segmentation (Litman and Passonneau 1995).", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 134, "end_pos": 153, "type": "TASK", "confidence": 0.7239929437637329}, {"text": "argument understanding", "start_pos": 157, "end_pos": 179, "type": "TASK", "confidence": 0.7659930288791656}, {"text": "plan recognition", "start_pos": 181, "end_pos": 197, "type": "TASK", "confidence": 0.7535018920898438}, {"text": "discourse segmentation", "start_pos": 205, "end_pos": 227, "type": "TASK", "confidence": 0.7447124719619751}]}, {"text": "Furthermore, correctly determining the function of cue phrases using features of the surrounding text can be used to improve the naturalness of synthetic speech in text-tospeech systems.", "labels": [], "entities": []}, {"text": "In this study, we focus on a subclass of cue phrases that we term affirmative cue words, and that include alright, mm-hm, okay, right, and uh-huh, inter alia.", "labels": [], "entities": []}, {"text": "These words are frequent in spontaneous conversation, especially in task-oriented dialogue, and are heavily overloaded: Their possible discourse/pragmatic functions include agreeing with what the interlocutor has said, displaying interest and continued attention, and cueing the start of anew topic.", "labels": [], "entities": []}, {"text": "Some ACWs (e.g., alright, okay) are capable of conveying as many as ten different functions, as described in Section 3.", "labels": [], "entities": []}, {"text": "Whereas ACWs thus form a subset of more general classes of utterances which have been studied in more general studies of cue words, cue phrases, discourse markers, feedback utterances, linguistic feedback, acknowledgments, grounding acts, our focus is on this particular subset of lexical items which may convey an affirmative response-but which may also convey many different meanings.", "labels": [], "entities": []}, {"text": "The disambiguation of these meanings we believe is critical to the success of spoken dialogue systems.", "labels": [], "entities": []}, {"text": "In the studies presented here, our goal is to extend our understanding of ACWs, in particular by finding descriptions of the acoustic/prosodic characteristics of their different functions, and by assessing the predictive power of computational methods for their automatic disambiguation.", "labels": [], "entities": []}, {"text": "This knowledge should be helpful in spoken language generation and understanding tasks, including interactive spoken dialogue systems and applications doing off-line analyses of conversational data, such as meeting segmentation and summarization.", "labels": [], "entities": [{"text": "spoken language generation", "start_pos": 36, "end_pos": 62, "type": "TASK", "confidence": 0.6711109081904093}, {"text": "summarization", "start_pos": 232, "end_pos": 245, "type": "TASK", "confidence": 0.955730140209198}]}, {"text": "For example, spoken dialogue systems lacking a model of the appropriate realization of different uses of these words are likely to have difficulty in understanding and communicating with their users, either by producing cue phrases in away that does not convey the intended meaning or by misunderstanding users' productions.", "labels": [], "entities": []}, {"text": "This article is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews previous literature.", "labels": [], "entities": []}, {"text": "In Section 3 we describe the materials used in the present study from the Columbia Games Corpus.", "labels": [], "entities": [{"text": "Columbia Games Corpus", "start_pos": 74, "end_pos": 95, "type": "DATASET", "confidence": 0.9761379758516947}]}, {"text": "Section 4 presents a statistical description of the acoustic, prosodic, and contextual characteristics of the functions of ACWs in this corpus.", "labels": [], "entities": []}, {"text": "In Section 5 we describe results from a number of machine learning experiments aimed at investigating how accurately ACWs maybe automatically classified into their various functions.", "labels": [], "entities": []}, {"text": "Finally, in Section 6 we summarize and discuss our main findings.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2  Distribution of function over ACW. Rest = {gotcha, huh, yep, yes, yup}.", "labels": [], "entities": [{"text": "ACW", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.8864375948905945}, {"text": "Rest", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.947973906993866}]}, {"text": " Table 3  Distribution of function over ACW, after downsampling. Rest = {gotcha, huh, yep, yes, yup}.", "labels": [], "entities": [{"text": "ACW", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.8842172622680664}, {"text": "Rest", "start_pos": 65, "end_pos": 69, "type": "METRIC", "confidence": 0.9631907343864441}]}, {"text": " Table 10  Error rate of each classifier on the general task using different feature sets; F-measures of  the SVM classifier; and error rate and F-measures of two baselines and human labelers.  For the classifier error rates:  \u2020 Significantly different from full model.  \u00a7 Significantly different  from SVM. (Wilcoxon signed rank sum test, p < 0.05.) Significance was not tested for the  classifier F-measures.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 91, "end_pos": 101, "type": "METRIC", "confidence": 0.9747627973556519}, {"text": "error rate", "start_pos": 130, "end_pos": 140, "type": "METRIC", "confidence": 0.9865347445011139}, {"text": "F-measures", "start_pos": 145, "end_pos": 155, "type": "METRIC", "confidence": 0.9306074380874634}, {"text": "Significance", "start_pos": 351, "end_pos": 363, "type": "METRIC", "confidence": 0.9365401864051819}]}, {"text": " Table 11  Error rate of each classifier on the detection of discourse boundary functions and  acknowledgment functions, using different feature sets.  \u2020 Significantly different from  full model.  \u00a7 Significantly different from SVM. (Wilcoxon signed rank sum test, p < 0.05.)", "labels": [], "entities": []}, {"text": " Table 12  F-measure achieved by our full-model SVM classifier for the different discourse/pragmatic  functions of each lexical item.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9906020164489746}]}, {"text": " Table 13  Error rate of the SVM classifier on online and offline tasks.", "labels": [], "entities": [{"text": "Error rate", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9797127544879913}, {"text": "SVM classifier", "start_pos": 29, "end_pos": 43, "type": "TASK", "confidence": 0.8247679471969604}]}]}