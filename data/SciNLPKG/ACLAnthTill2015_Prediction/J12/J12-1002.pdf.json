{"title": [{"text": "A Context-Theoretic Framework for Compositionality in Distributional Semantics", "labels": [], "entities": []}], "abstractContent": [{"text": "Formalizing \"meaning as context\" mathematically leads to anew, algebraic theory of meaning, in which composition is bilinear and associative.", "labels": [], "entities": []}, {"text": "These properties are shared by other methods that have been proposed in the literature, including the tensor product, vector addition, point-wise multiplication, and matrix multiplication.", "labels": [], "entities": [{"text": "vector addition", "start_pos": 118, "end_pos": 133, "type": "TASK", "confidence": 0.8078636527061462}, {"text": "matrix multiplication", "start_pos": 166, "end_pos": 187, "type": "TASK", "confidence": 0.7887088060379028}]}, {"text": "Entailment can be represented by a vector lattice ordering, inspired by a strengthened form of the distributional hypothesis, and a degree of entailment is defined in the form of a conditional probability.", "labels": [], "entities": []}, {"text": "Approaches to the task of recognizing textual entailment, including the use of subsequence matching, lexical entailment probability, and latent Dirichlet allocation, can be described within our framework.", "labels": [], "entities": []}], "introductionContent": [{"text": "This article presents the thesis that defining meaning as context leads naturally to a model in which meanings of strings are represented as elements of an associative algebra over the real numbers, and entailment is described by a vector lattice ordering.", "labels": [], "entities": []}, {"text": "This model is general enough to encompass several proposed methods of composition in vector-based representations of meaning.", "labels": [], "entities": []}, {"text": "In recent years, the abundance of text corpora and computing power has allowed the development of techniques to analyze statistical properties of words.", "labels": [], "entities": []}, {"text": "For example techniques such as latent semantic analysis) and its variants, and measures of distributional similarity), attempt to derive aspects of the meanings of words by statistical analysis, and statistical information is often used when parsing to determine sentence structure.", "labels": [], "entities": [{"text": "latent semantic analysis", "start_pos": 31, "end_pos": 55, "type": "TASK", "confidence": 0.6260681748390198}]}, {"text": "These techniques have proved useful in many applications within computational linguistics and natural language processing), arguably providing evidence that they capture something about the nature of words that should be included in representations of their meaning.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 94, "end_pos": 121, "type": "TASK", "confidence": 0.6941830515861511}]}, {"text": "However, it is very difficult to reconcile these techniques with existing theories of meaning in language, which revolve around logical and ontological representations.", "labels": [], "entities": []}, {"text": "The new techniques, almost without exception, can be viewed as dealing with vector-based representations of meaning, placing meaning (at least at the word level) within the realm of mathematics and algebra; conversely the older theories of meaning dwell in the realm of logic and ontology.", "labels": [], "entities": []}, {"text": "It seems there is r The theory on its own is not useful when applied to real-world corpora because of the problem of data sparseness.", "labels": [], "entities": []}, {"text": "Instead we examine the mathematical properties of the model, and abstract them to form a framework which contains many of the properties of the model.", "labels": [], "entities": []}, {"text": "Implementations of the framework are called context theories because they can be viewed as theories about the contexts in which strings occur.", "labels": [], "entities": []}, {"text": "By analogy with the term \"model-theoretic\" we use the term \"context-theoretic\" for concepts relating to context theories, thus we call our framework the context-theoretic framework.", "labels": [], "entities": []}, {"text": "r In order to ensure that the framework was practically useful, context theories were developed in parallel with the framework itself.", "labels": [], "entities": []}, {"text": "The aim was to be able to describe existing approaches to representing meaning within the framework as fully as possible.", "labels": [], "entities": []}, {"text": "In developing the framework we were looking for specific properties; namely, we wanted it to: r provide some guidelines describing in what way the representation of a phrase or sentence should relate to the representations of the individual words as vectors; r require information about the probability of a string of words to be incorporated into the representation; r provide away to measure the degree of entailment between strings based on the particular meaning representation; r be general enough to encompass logical representations of meaning; and r be able to incorporate the representation of ambiguity and uncertainty, including statistical information such as the probability of a parse or the probability that a word takes a particular sense.", "labels": [], "entities": []}, {"text": "The framework we present is abstract, and hence does not subscribe to a particular method for obtaining word vectors: They maybe raw frequency counts, or vectors obtained by a method such as latent semantic analysis.", "labels": [], "entities": []}, {"text": "Nor does the framework provide a recipe for how to represent meaning in natural language; instead it provides restrictions on the set of possibilities.", "labels": [], "entities": []}, {"text": "The advantage of the framework is in ensuring that techniques are used in away that is well-founded in a theory of meaning.", "labels": [], "entities": []}, {"text": "For example, given vector representations of words, there is not one single way of combining these to give vector representations of phrases and sentences, but in order to fit within the framework there are certain properties of the representation that need to hold.", "labels": [], "entities": []}, {"text": "Any method of combining these vectors in which these properties hold can be considered within the framework and is thus justified according to the underlying theory; in addition the framework instructs us as to how to measure the degree of entailment between strings according to that particular method.", "labels": [], "entities": []}, {"text": "The contribution of this article is as follows: r We define the context-theoretic framework and introduce the mathematics necessary to understand it.", "labels": [], "entities": []}, {"text": "The description presented here is cleaner than that of, and in addition we provide examples that should provide intuition for the concepts we describe.", "labels": [], "entities": []}, {"text": "r We relate the framework to methods of composition that have been proposed in the literature, namely: vector addition; the tensor product; the multiplicative models of; It is important to note that the purpose of describing related work in terms of our framework is not merely to demonstrate the generality of our framework: In doing so, we identify previously ignored features of this work such as the lattice structure within the vector space.", "labels": [], "entities": [{"text": "vector addition", "start_pos": 103, "end_pos": 118, "type": "TASK", "confidence": 0.7369714975357056}]}, {"text": "This allows anyone of these approaches to be endowed with an entailment property defined by this lattice structure, based on a philosophy of meaning as context.", "labels": [], "entities": []}, {"text": "Although the examples described here show that existing approaches can be described within the framework and show some of its potential, they cannot demonstrate its full power.", "labels": [], "entities": []}, {"text": "The mathematical structures we make use of are extremely general, and we hope that in the future many interesting discoveries will be made by exploring the realm we identify here.", "labels": [], "entities": []}, {"text": "Our approach in defining the framework maybe perceived as overly abstract; however, we believe this approach has many potential benefits, because approaches to composition which may have been considered unrelated (such as the tensor product and vector addition) are now shown to be related.", "labels": [], "entities": [{"text": "vector addition", "start_pos": 245, "end_pos": 260, "type": "TASK", "confidence": 0.7234489321708679}]}, {"text": "This means that when studying such constructions, work can be avoided by considering the general case, for the same reason that class inheritance aids code reuse.", "labels": [], "entities": []}, {"text": "For example, definitions given in terms of the framework can be applied to all instances, such as our definition of a degree of entailment.", "labels": [], "entities": []}, {"text": "We also hope to motivate people to prove theorems in terms of the framework, having demonstrated its wide applicability.", "labels": [], "entities": []}, {"text": "The remainder of the article is as follows: In Section 2 we define our framework, introducing the necessary definitions, and showing how related work fits into the framework.", "labels": [], "entities": []}, {"text": "In Section 3 we introduce our motivating example, showing that a simple mathematical definition of the notions of \"corpus\" and \"context\" leads to an instance of our framework.", "labels": [], "entities": []}, {"text": "In Section 4, we describe specific instances of our framework in application to the task of recognizing textual entailment.", "labels": [], "entities": [{"text": "recognizing textual entailment", "start_pos": 92, "end_pos": 122, "type": "TASK", "confidence": 0.7943786382675171}]}, {"text": "In Section 5 we show how the sophisticated approach of can be described within our framework.", "labels": [], "entities": []}, {"text": "Finally, in Section 6 we present our conclusions and plans for further work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}