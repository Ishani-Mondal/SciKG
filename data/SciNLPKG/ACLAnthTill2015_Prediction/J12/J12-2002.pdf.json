{"title": [{"text": "Are You Sure That This Happened? Assessing the Factuality Degree of Events in Text", "labels": [], "entities": []}], "abstractContent": [{"text": "Identifying the veracity, or factuality, of event mentions in text is fundamental for reasoning about eventualities in discourse.", "labels": [], "entities": []}, {"text": "Inferences derived from events judged as not having happened, or as being only possible, are different from those derived from events evaluated as factual.", "labels": [], "entities": []}, {"text": "Event factuality involves two separate levels of information.", "labels": [], "entities": []}, {"text": "On the one hand, it deals with polarity, which distinguishes between positive and negative instantiations of events.", "labels": [], "entities": []}, {"text": "On the other, it has to do with degrees of certainty (e.g., possible, probable), an information level generally subsumed under the category of epistemic modality.", "labels": [], "entities": []}, {"text": "This article aims at contributing to a better understanding of how event factuality is articulated in natural language.", "labels": [], "entities": []}, {"text": "For that purpose, we put forward a linguistic-oriented computational model which has at its core an algorithm articulating the effect of factuality relations across levels of syntactic embedding.", "labels": [], "entities": []}, {"text": "As a proof of concept, this model has been implemented in De Facto, a factuality profiler for eventualities mentioned in text, and tested against a corpus built specifically for the task, yielding an F 1 of 0.70 (macro-averaging) and 0.80 (micro-averaging).", "labels": [], "entities": [{"text": "F 1", "start_pos": 200, "end_pos": 203, "type": "METRIC", "confidence": 0.9912077784538269}]}, {"text": "These two measures mutually compensate for an over-emphasis present in the other (either on the lesser or greater populated categories), and can therefore be interpreted as the lower and upper bounds of the De Facto's performance.", "labels": [], "entities": [{"text": "De Facto's performance", "start_pos": 207, "end_pos": 229, "type": "DATASET", "confidence": 0.8688228875398636}]}], "introductionContent": [{"text": "When we talk about situations in the world, we often leave pieces of information vague or try to complete the story with approximations, either because we do not know all the details or we are not sure about what we know.", "labels": [], "entities": []}, {"text": "With a lesser or greater degree, this vagueness is pervasive in all types of accounts, regardless of the topic and the degree of proximity of the speaker with the facts being reported: our last family gathering, what we read about the tsunami and its aftermath in Japan, our perspective on a particular topic, or how we feel today.", "labels": [], "entities": []}, {"text": "Even in scientific discourse, findings tend to be expressed with degrees of cautiousness.", "labels": [], "entities": []}, {"text": "The linguistic mechanisms for coping with the vagueness and fuzziness in our knowledge are commonly referred to as speculative language.", "labels": [], "entities": []}, {"text": "This involves different levels of grammatical manifestation, most significantly quantification over entities and events, modality, and hedging devices of a varied nature.", "labels": [], "entities": []}, {"text": "We can be vague or approximate with the temporal and spatial references of situations in the world, when quantifying the frequency of usual events, assessing the number of participants involved, and describing or adscribing them into a class.", "labels": [], "entities": []}, {"text": "We also qualify our statements with approximative language when giving an opinion, or when we are not certain about the degree of veracity of what we are telling.", "labels": [], "entities": []}, {"text": "The present article focuses on a particular kind of speculation in language, specifically, that concerning the factuality status of eventualities mentioned in discourse.", "labels": [], "entities": []}, {"text": "Whenever we talk about situations, we express our degree of certainty about their factual status.", "labels": [], "entities": [{"text": "certainty", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9623406529426575}]}, {"text": "We can characterize them as an unquestionable fact, or qualify them with some degree of uncertainty if we are not sure whether the situation holds, or will hold, in the world.", "labels": [], "entities": []}, {"text": "Identifying the factuality status of event mentions is fundamental for reasoning about eventualities in discourse.", "labels": [], "entities": [{"text": "Identifying the factuality status of event mentions", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.7997064249856132}]}, {"text": "Inferences derived from events judged as not having happened, or as being only possible, are different from those derived from events evaluated as factual.", "labels": [], "entities": []}, {"text": "Event factuality is also essential for any task involving temporal ordering, because the plotting of event mentions into a timeline requires different actions depending on their veracity.", "labels": [], "entities": [{"text": "plotting of event mentions", "start_pos": 89, "end_pos": 115, "type": "TASK", "confidence": 0.8411962538957596}]}, {"text": "discuss its relevance for information extraction, and in the area of textual entailment, factuality-related information (modality, intensional contexts, etc.) has been taken as a basic feature in some systems participating in the PASCAL RTE challenges (e.g.,.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.7945114076137543}, {"text": "PASCAL RTE", "start_pos": 230, "end_pos": 240, "type": "TASK", "confidence": 0.6801056563854218}]}, {"text": "The need for this type of information is also acknowledged in the annotation schemes of corpora devoted to event information, such as the ACE corpus for the Event and Relation recognition task (e.g., ACE 2008), or TimeBank, a corpus annotated with event and temporal information ().", "labels": [], "entities": [{"text": "ACE corpus", "start_pos": 138, "end_pos": 148, "type": "DATASET", "confidence": 0.9530473947525024}, {"text": "Event and Relation recognition task", "start_pos": 157, "end_pos": 192, "type": "TASK", "confidence": 0.6477572798728943}, {"text": "ACE 2008)", "start_pos": 200, "end_pos": 209, "type": "DATASET", "confidence": 0.8854540983835856}]}, {"text": "Significantly, in the past few years this level of information has been at the focus of much research within the NLP area dedicated to the biomedical domain.", "labels": [], "entities": []}, {"text": "Distinguishing between what is reported as a fact versus a possibility in experiment reports or in patient health records is a crucial capability for any robust information extraction tool operating on that domain.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 161, "end_pos": 183, "type": "TASK", "confidence": 0.7671841979026794}]}, {"text": "This interest has resulted in the compilation of domain-specific corpora devoted particularly to that level of information, such as BioScope (, and others that include event factivity as a further attribute in the annotation of biomedical events, such as GENIA.", "labels": [], "entities": [{"text": "BioScope", "start_pos": 132, "end_pos": 140, "type": "DATASET", "confidence": 0.8093640804290771}, {"text": "GENIA", "start_pos": 255, "end_pos": 260, "type": "DATASET", "confidence": 0.95067298412323}]}, {"text": "Furthermore, factuality-related information was the main focus in the CoNLL-2010 shared task on Learning to Detect Hedges and their Scope in Natural Language Text (, and the topic in a subtask of the BioNLP'09 and BioNLP'11 shared task editions on Event Extraction (), 1 dedicated to predict whether the biological event is under negation or speculation.", "labels": [], "entities": [{"text": "Learning to Detect Hedges and their Scope in Natural Language Text", "start_pos": 96, "end_pos": 162, "type": "TASK", "confidence": 0.5768355347893455}, {"text": "Event Extraction", "start_pos": 248, "end_pos": 264, "type": "TASK", "confidence": 0.6664333641529083}]}, {"text": "The overall goal of this article is to contribute to a better understanding of this particular aspect of speculation.", "labels": [], "entities": []}, {"text": "We analyze all the ingredients involved in computing the factuality nature of event mentions in text, and put forward a computational model based on that.", "labels": [], "entities": []}, {"text": "As a proof of concept, the model is implemented into De Facto, a factuality profiler, and its performance tested against FactBank, a corpus annotated with factuality information built specifically for the task and currently available to the community through the Linguistic Data Consortium (Saur\u00ed and Pustejovsky 2009a).", "labels": [], "entities": []}, {"text": "The article begins by defining event factuality and its place in speculative language (Section 2).", "labels": [], "entities": []}, {"text": "The basic components for the model on event factuality are presented in Section 3, and the algorithm integrating these is introduced in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 reports on the experiment resulting from implementing the proposed model into De Facto, and Section 6 relates the present work to other research in the field.", "labels": [], "entities": []}], "datasetContent": [{"text": "Consider each sentence, S, as consisting of one or more evaluation levels, l.", "labels": [], "entities": []}, {"text": "By default, sentences have a root evaluation level, l 0 . Sentences with SIPs have more, corresponding to the levels of embedding created by these predicates.", "labels": [], "entities": []}, {"text": "For example, a sentence with two SIPs, in boldface in Example (25b), has three evaluation levels.", "labels": [], "entities": [{"text": "Example (25b", "start_pos": 54, "end_pos": 66, "type": "DATASET", "confidence": 0.8791552186012268}]}, {"text": "We identify each evaluation level by its embedding depth, expressed in the bracket subindices.", "labels": [], "entities": []}, {"text": "Each evaluation level l n has: A set Sn of relevant sources.", "labels": [], "entities": []}, {"text": "At the root level l 0 , S 0 contains only one relevant source, s 0 , corresponding to the author of the text.", "labels": [], "entities": []}, {"text": "At each higher level l n>0 , anew source is introduced by the SIP triggering it.", "labels": [], "entities": []}, {"text": "A set E n of events (one or more), the factuality of which is evaluated relative to each relevant source s \u2208 Sn . A set F n of contextual factuality values.", "labels": [], "entities": []}, {"text": "At the beginning of each new level, one or more factuality values are set (cf. the value CT+ applying the naive decoder assumption at the top level).", "labels": [], "entities": []}, {"text": "These values are relative to the relevant sources in Sn , because each source may assess the same event differently.", "labels": [], "entities": []}, {"text": "The task of event identification can be carried out by already existing event recognizers.", "labels": [], "entities": [{"text": "event identification", "start_pos": 12, "end_pos": 32, "type": "TASK", "confidence": 0.8765013217926025}, {"text": "event recognizers", "start_pos": 72, "end_pos": 89, "type": "TASK", "confidence": 0.7121641933917999}]}, {"text": "The next sections define the operations for identifying the set of relevant sources Sn and the factuality values these assign to each event in any evaluation level l n .   For developing and evaluating De Facto, we compiled FactBank, a corpus annotated with information concerning the factuality of events (Saur\u00ed and Pustejovsky 2009a).", "labels": [], "entities": []}, {"text": "FactBank consists of 208 documents, which include all those in TimeBank () and a subset of those in the AQUAINT TimeML Corpus.", "labels": [], "entities": [{"text": "FactBank", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9324477910995483}, {"text": "TimeBank", "start_pos": 63, "end_pos": 71, "type": "DATASET", "confidence": 0.9617947340011597}, {"text": "AQUAINT TimeML Corpus", "start_pos": 104, "end_pos": 125, "type": "DATASET", "confidence": 0.8991032640139262}]}, {"text": "The TimeBank part was used for developing De Facto and its associated linguistic resources, and the AQUAINT TimeML part was set as the gold standard for evaluating its performance.", "labels": [], "entities": [{"text": "AQUAINT TimeML part", "start_pos": 100, "end_pos": 119, "type": "DATASET", "confidence": 0.7223430077234904}]}, {"text": "TimeBank contains 183 documents (amounting to 88% of the documents in FactBank) and 7,935 events (83.6% of the events), and the AQUAINT part has 25 documents (12%) and 1,553 events (16.4%).", "labels": [], "entities": [{"text": "TimeBank", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9538407921791077}, {"text": "FactBank", "start_pos": 70, "end_pos": 78, "type": "DATASET", "confidence": 0.9283092617988586}, {"text": "AQUAINT part", "start_pos": 128, "end_pos": 140, "type": "DATASET", "confidence": 0.821262001991272}]}, {"text": "Overall, FactBank contains a total of 9,488 events.", "labels": [], "entities": [{"text": "FactBank", "start_pos": 9, "end_pos": 17, "type": "DATASET", "confidence": 0.9117872714996338}]}, {"text": "Given that each event can have more than one relevant source, FactBank has a total of 13,506 event/source pairs manually annotated with the set of factuality distinctions introduced in.", "labels": [], "entities": [{"text": "FactBank", "start_pos": 62, "end_pos": 70, "type": "DATASET", "confidence": 0.9229781627655029}]}, {"text": "The annotation has applied a battery of discriminatory tests grounded on the linguistic and logical relations at the core of Horn's analysis (refer to Section 3.2).", "labels": [], "entities": []}, {"text": "The inter-annotation agreement from that exercise is \u03ba = 0.81 (over 30% of events in the corpus).", "labels": [], "entities": []}, {"text": "In terms of pairwise F 1 -score (that is, taking one of the annotators as the gold standard), the agreement between annotators yielded: CT+: 0.93, CT\u2212: 0.83, PR+: 0.57, PR\u2212: 0.46, PS+: 0.56, PS\u2212: 0.75, and Uu: 0.88.", "labels": [], "entities": [{"text": "F 1 -score", "start_pos": 21, "end_pos": 31, "type": "METRIC", "confidence": 0.9353660941123962}, {"text": "CT+", "start_pos": 136, "end_pos": 139, "type": "METRIC", "confidence": 0.9696820080280304}, {"text": "CT\u2212: 0.83", "start_pos": 147, "end_pos": 156, "type": "METRIC", "confidence": 0.9501075446605682}, {"text": "PR+: 0.57", "start_pos": 158, "end_pos": 167, "type": "METRIC", "confidence": 0.9111121892929077}, {"text": "PR\u2212: 0.46", "start_pos": 169, "end_pos": 178, "type": "METRIC", "confidence": 0.9110434502363205}]}, {"text": "Overall, these results are highly satisfying considering the difficulty of the task and thus validate the approach on the annotation.", "labels": [], "entities": []}, {"text": "See further details in Saur\u00ed and Pustejovsky (2009b).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 6  Distribution of ESPs in De Facto.", "labels": [], "entities": []}, {"text": " Table 7  Confusion matrix: Gold standard (rows) vs. De Facto output (columns).", "labels": [], "entities": [{"text": "Gold standard", "start_pos": 28, "end_pos": 41, "type": "METRIC", "confidence": 0.8821599185466766}]}, {"text": " Table 8  P&R for each relevant category and for the whole corpus (macro-and micro-average).", "labels": [], "entities": [{"text": "P&R", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9133089582125345}]}, {"text": " Table 9  Baseline performance (F 1 measures).", "labels": [], "entities": [{"text": "F 1 measures", "start_pos": 32, "end_pos": 44, "type": "METRIC", "confidence": 0.9680559833844503}]}, {"text": " Table 10  De Facto performance (F 1 measures).", "labels": [], "entities": [{"text": "F 1 measures", "start_pos": 33, "end_pos": 45, "type": "METRIC", "confidence": 0.9602266947428385}]}]}