{"title": [{"text": "Did It Happen? The Pragmatic Complexity of Veridicality Assessment", "labels": [], "entities": []}], "abstractContent": [{"text": "Natural language understanding depends heavily on assessing veridicality-whether events mentioned in a text are viewed as happening or not-but little consideration is given to this property in current relation and event extraction systems.", "labels": [], "entities": [{"text": "Natural language understanding", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6722355683644613}, {"text": "event extraction", "start_pos": 214, "end_pos": 230, "type": "TASK", "confidence": 0.7302676141262054}]}, {"text": "Furthermore, the work that has been done has generally assumed that veridicality can be captured by lexical semantic properties whereas we show that context and world knowledge play a significant role in shaping veridicality.", "labels": [], "entities": []}, {"text": "We extend the FactBank corpus, which contains semantically driven veridicality annotations, with pragmatically informed ones.", "labels": [], "entities": [{"text": "FactBank corpus", "start_pos": 14, "end_pos": 29, "type": "DATASET", "confidence": 0.9553552865982056}]}, {"text": "Our annotations are more complex than the lexical assumption predicts but systematic enough to be included in computational work on textual understanding.", "labels": [], "entities": [{"text": "textual understanding", "start_pos": 132, "end_pos": 153, "type": "TASK", "confidence": 0.7416170835494995}]}, {"text": "They also indicate that veridicality judgments are not always categorical, and should therefore be modeled as distributions.", "labels": [], "entities": []}, {"text": "We build a classifier to automatically assign event veridicality distributions based on our new annotations.", "labels": [], "entities": []}, {"text": "The classifier relies not only on lexical features like hedges or negations, but also on structural features and approximations of world knowledge, thereby providing a nuanced picture of the diverse factors that shape veridicality.", "labels": [], "entities": []}], "introductionContent": [{"text": "A reader's or listener's understanding of an utterance depends heavily on assessing the extent to which the speaker (author) intends to convey that the events described did (or did not) happen.", "labels": [], "entities": []}, {"text": "An unadorned declarative like The cancer has spread conveys firm speaker commitment, whereas qualified variants such as There are strong indicators that the cancer has spread or The cancer might have spread imbue the claim with uncertainty.", "labels": [], "entities": []}, {"text": "We call this event veridicality, building on logical, linguistic, and computational insights about the relationship between language and reader commitment;.", "labels": [], "entities": []}, {"text": "The central goal of this article is to begin to identify the linguistic and contextual factors that shape readers' veridicality judgments.", "labels": [], "entities": []}, {"text": "There is along tradition of tracing veridicality to fixed properties of lexical items (.", "labels": [], "entities": []}, {"text": "On this view, a lexical item L is veridical if the meaning of L applied to argument p entails the truth of p.", "labels": [], "entities": []}, {"text": "For example, because both true and false things can be believed, one should not infer directly from A believes that S that S is true, making believe non-veridical.", "labels": [], "entities": []}, {"text": "Conversely, realize appears to be veridical, because realizing S entails the truth of S.", "labels": [], "entities": []}, {"text": "The prototypical anti-veridical operator is negation, because not S entails the falsity of S, but anti-veridicality is a characteristic of a wide range of words and constructions (e.g., have yet to, fail, without).", "labels": [], "entities": []}, {"text": "These basic veridicality judgments can be further subdivided using modal or probabilistic notions.", "labels": [], "entities": []}, {"text": "For example, although may is non-veridical by the basic classifications, we might classify may S as possible with regard to S.", "labels": [], "entities": []}, {"text": "Lexical theories of this sort provide a basis for characterizing readers' veridicality judgments, but they do not tell the whole story, because they neglect the pragmatic enrichment that is pervasive inhuman communication.", "labels": [], "entities": []}, {"text": "In the lexical view, say can only be classified as non-veridical (both true and false things can be said), and yet, if a New York Times article contained the sentence United Widget said that its chairman resigned, readers would reliably infer that United Widget's chairman resigned-the sentence is, in this context, veridical (at least to some degree) with respect to the event described by the embedded clause, with United Widget said functioning to mark the source of evidence.", "labels": [], "entities": []}, {"text": "Cognitive authority, as termed in information science, plays a crucial role in how people judge the veridicality of events.", "labels": [], "entities": []}, {"text": "Here, the provenance of the document (the New York Times) and the source (United Widget) combine to reliably lead a reader to infer that the author intended to convey that the event really happened.", "labels": [], "entities": [{"text": "New York Times)", "start_pos": 42, "end_pos": 57, "type": "DATASET", "confidence": 0.819951593875885}]}, {"text": "Conversely, allege is lexically non-veridical, and yet this only begins to address the complex interplay of world knowledge and lexical meaning that will shape people's inferences about the sentence FBI agents alleged in court documents today that Zazi had admitted receiving weapons and explosives training from al Qaeda operatives in Pakistan last year.", "labels": [], "entities": []}, {"text": "We conclude from examples like this that veridicality judgments have an important pragmatic component, and, in turn, that veridicality should be assessed using information from the entire sentence as well as from the context.", "labels": [], "entities": []}, {"text": "Lexical theories have a significant role to play here, but we expect their classifications to be buffeted by other communicative pressures.", "labels": [], "entities": []}, {"text": "For example, the lexical theory can tell us that, as a narrowly semantic fact, X alleges S is non-veridical with regard to S.", "labels": [], "entities": []}, {"text": "Where X is a trustworthy source for S-type information, however, we might fairly confidently conclude that S is true.", "labels": [], "entities": []}, {"text": "Where X is known to spread disinformation, we might tentatively conclude that S is false.", "labels": [], "entities": []}, {"text": "These pragmatic enrichments move us from uncertainty to some degree of 1 Our use of the term \"veridicality\" most closely matches that of, where it is defined so as to be (i) relativized to particular agents or perspectives, (ii) gradable, and (iii) general enough to cover not only facts but also the commitments that arise from using certain referential expressions and aspectual morphology.", "labels": [], "entities": []}, {"text": "The more familiar term \"factuality\" seems at odds with all three of these criteria, so we avoid it.", "labels": [], "entities": []}, {"text": "2 Lexical notions of veridicality must be relativized to specific argument positions, with the other arguments existentially closed for the purposes of checking entailment.", "labels": [], "entities": []}, {"text": "For example, believe is non-veridical on its inner (sentential) argument because \"\u2203x : x believes p\" does not entail p. certainty.", "labels": [], "entities": []}, {"text": "Such enrichments can be central to understanding how a listener (or a reader) understands a speaker's (or author's) message.", "labels": [], "entities": []}, {"text": "Embracing pragmatic enrichment means embracing uncertainty.", "labels": [], "entities": [{"text": "Embracing pragmatic enrichment", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8262538313865662}]}, {"text": "Although listeners can feel reasonably confident about the core lexical semantics of the words of their language, there is no such firm foundation when it comes to this kind of pragmatic enrichment.", "labels": [], "entities": []}, {"text": "The newspaper says, United Widget said that its profits were up in the fourth quarter, but just how trustworthy is United Widget on such matters?", "labels": [], "entities": [{"text": "United Widget", "start_pos": 20, "end_pos": 33, "type": "DATASET", "confidence": 0.9135362803936005}, {"text": "United Widget", "start_pos": 115, "end_pos": 128, "type": "DATASET", "confidence": 0.9198004603385925}]}, {"text": "Speakers are likely to vary in what they intend in such cases, and listeners are thus forced to operate under uncertainty when making the requisite inferences.", "labels": [], "entities": []}, {"text": "Lexical theories allow us to abstract away from these challenges, but a pragmatically informed approach must embrace them.", "labels": [], "entities": []}, {"text": "The FactBank corpus is a leading resource for research on veridicality.", "labels": [], "entities": [{"text": "FactBank corpus", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9733708202838898}]}, {"text": "Its annotations are \"textual-based\": They seek to capture the ways in which lexical meanings and local semantic interactions determine veridicality judgments.", "labels": [], "entities": []}, {"text": "In order to better understand the role of pragmatic enrichment, we had a large group of linguistically naive annotators annotate a portion of the FactBank corpus, given very loose guidelines.", "labels": [], "entities": [{"text": "FactBank corpus", "start_pos": 146, "end_pos": 161, "type": "DATASET", "confidence": 0.9674497842788696}]}, {"text": "Whereas the FactBank annotators were explicitly told to avoid bringing world knowledge to bear on the task, our annotators were encouraged to choose labels that reflected their own natural reading of the texts.", "labels": [], "entities": [{"text": "FactBank", "start_pos": 12, "end_pos": 20, "type": "DATASET", "confidence": 0.8891106843948364}]}, {"text": "Each sentence was annotated by 10 annotators, which increases our confidence in them and also highlights the sort of vagueness and ambiguity that can affect veridicality.", "labels": [], "entities": []}, {"text": "These new annotations help confirm our hypothesis that veridicality judgments are shaped by a variety of other linguistic and contextual factors beyond lexical meanings.", "labels": [], "entities": []}, {"text": "The nature of such cues is central to linguistic pragmatics and fundamental to a range of natural language processing (NLP) tasks, including information extraction, opinion detection, and textual entailment.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 141, "end_pos": 163, "type": "TASK", "confidence": 0.8013786375522614}, {"text": "opinion detection", "start_pos": 165, "end_pos": 182, "type": "TASK", "confidence": 0.8278299868106842}, {"text": "textual entailment", "start_pos": 188, "end_pos": 206, "type": "TASK", "confidence": 0.7149897217750549}]}, {"text": "Veridicality is prominent in BioNLP, where identifying negations (; Morante and Daelemans 2009) and hedges or \"speculations\" () is crucial to proper textual understanding.", "labels": [], "entities": [{"text": "Veridicality", "start_pos": 0, "end_pos": 12, "type": "METRIC", "confidence": 0.9057753086090088}]}, {"text": "Recently, more attention has been devoted to veridicality within NLP, with the 2010 workshop on negation and speculation in natural language processing.", "labels": [], "entities": [{"text": "negation and speculation in natural language processing", "start_pos": 96, "end_pos": 151, "type": "TASK", "confidence": 0.735480010509491}]}, {"text": "Veridicality was also at the heart of the 2010 CoNLL shared task, where the goal was to distinguish uncertain events from the rest.", "labels": [], "entities": [{"text": "Veridicality", "start_pos": 0, "end_pos": 12, "type": "METRIC", "confidence": 0.6916733980178833}, {"text": "CoNLL shared task", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.48826982577641803}]}, {"text": "The centrality of veridicality assessment to tasks like event and relation extraction is arguably still not fully appreciated, however.", "labels": [], "entities": [{"text": "veridicality assessment", "start_pos": 18, "end_pos": 41, "type": "TASK", "confidence": 0.807246208190918}, {"text": "event and relation extraction", "start_pos": 56, "end_pos": 85, "type": "TASK", "confidence": 0.5719887018203735}]}, {"text": "At present the vast majority of information extraction systems work at roughly the clause level and regard any relation they find as true.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.8010938763618469}]}, {"text": "But relations in actual text may not be facts for all sorts of reasons, such as being embedded under an attitude verb like doubt, being the antecedent of a conditional, or being part of the report by an untrustworthy source.", "labels": [], "entities": []}, {"text": "To avoid wrong extractions in these cases, it is essential for NLP systems to assess the veridicality of extracted facts.", "labels": [], "entities": []}, {"text": "In the present article, we argue for three main claims about veridicality.", "labels": [], "entities": []}, {"text": "First and foremost, we aim to show that pragmatically informed veridicality judgments are systematic enough to be included in computational work on textual understanding.", "labels": [], "entities": []}, {"text": "Second, we seek to justify FactBank's seven-point categorization over simpler alternatives (e.g., certain vs. uncertain, as in the CoNLL task).", "labels": [], "entities": [{"text": "FactBank", "start_pos": 27, "end_pos": 35, "type": "DATASET", "confidence": 0.8231006264686584}]}, {"text": "Finally, the inherent uncertainty of pragmatic inference suggests to us that veridicality judgments are not always categorical, and thus are better modeled as probability distributions over veridicality categories.", "labels": [], "entities": []}, {"text": "To substantiate these claims, we analyze in detail the annotations we collected, and we report on experiments that treat veridicality as a distribution-prediction task.", "labels": [], "entities": []}, {"text": "Our feature set includes not only lexical items like hedges, modals, and negations, but also complex structural features and approximations of world knowledge.", "labels": [], "entities": []}, {"text": "Though the resulting classifier has limited ability to assess veridicality in complex real world contexts, it still does a quite good job of capturing human pragmatic judgments of veridicality.", "labels": [], "entities": []}, {"text": "We argue that the model yields insights into the complex pragmatic factors that shape readers' veridicality judgments.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 5  Confusion matrix comparing the FactBank annotations (rows) with our annotations (columns).", "labels": [], "entities": []}, {"text": " Table 7  Precision, recall, and F1 on the subsets of the training data (10-fold cross-validation) and test  data where there is majority vote, as well as F1 for the baseline.", "labels": [], "entities": [{"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9996769428253174}, {"text": "F1", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9996786117553711}, {"text": "F1", "start_pos": 155, "end_pos": 157, "type": "METRIC", "confidence": 0.9993962049484253}]}, {"text": " Table 6. Our results  significantly exceed the baseline (McNemar's test, p < 0.001). 7", "labels": [], "entities": [{"text": "McNemar's test", "start_pos": 58, "end_pos": 72, "type": "METRIC", "confidence": 0.7864377299944559}]}]}