{"title": [{"text": "Finite-State Chart Constraints for Reduced Complexity Context-Free Parsing Pipelines", "labels": [], "entities": []}], "abstractContent": [{"text": "We present methods for reducing the worst-case and typical-case complexity of a context-free parsing pipeline via hard constraints derived from finite-state pre-processing.", "labels": [], "entities": []}, {"text": "We perform O(n) predictions to determine if each word in the input sentence may begin or end a multi-word constituent in chart cells spanning two or more words, or allow single-word constituents in chart cells spanning the word itself.", "labels": [], "entities": [{"text": "O", "start_pos": 11, "end_pos": 12, "type": "METRIC", "confidence": 0.9826188087463379}]}, {"text": "These pre-processing constraints prune the search space for any chart-based parsing algorithm and significantly decrease decoding time.", "labels": [], "entities": []}, {"text": "In many cases cell population is reduced to zero, which we term chart cell \"closing.\"", "labels": [], "entities": []}, {"text": "We present methods for closing a sufficient number of chart cells to ensure provably quadratic or even linear worst-case complexity of context-free inference.", "labels": [], "entities": []}, {"text": "In addition, we apply high precision constraints to achieve large typical-case speedups and combine both high precision and worst-case bound constraints to achieve superior performance on both short and long strings.", "labels": [], "entities": [{"text": "precision", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9857656955718994}, {"text": "precision", "start_pos": 110, "end_pos": 119, "type": "METRIC", "confidence": 0.9862784743309021}]}, {"text": "These bounds on processing are achieved without reducing the parsing accuracy, and in some cases accuracy improves.", "labels": [], "entities": [{"text": "parsing", "start_pos": 61, "end_pos": 68, "type": "TASK", "confidence": 0.9707207679748535}, {"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.8941803574562073}, {"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9991728663444519}]}, {"text": "We demonstrate that our method generalizes across multiple grammars and is complementary to other pruning techniques by presenting empirical results for both exact and approximate inference using the exhaustive CKY algorithm, the Charniak parser, and the Berkeley parser.", "labels": [], "entities": []}, {"text": "We also report results parsing Chinese, where we achieve the best reported results for an individual model on the commonly reported data set.", "labels": [], "entities": [{"text": "parsing Chinese", "start_pos": 23, "end_pos": 38, "type": "TASK", "confidence": 0.8226678967475891}]}], "introductionContent": [{"text": "Although there have been great advances in the statistical modeling of hierarchical syntactic structure over the past 15 years, exact inference with such models remains very costly and most rich syntactic modeling approaches resort to heavy pruning, pipelining, or both.", "labels": [], "entities": []}, {"text": "Pipeline systems make use of simpler models with more efficient inference to reduce the search space of the full model.", "labels": [], "entities": []}, {"text": "For example, the well-known parser used a part-of-speech (POS)-tagger and a finite-state noun phrase (NP) chunker as initial stages of a multi-stage Maximum Entropy parser.", "labels": [], "entities": []}, {"text": "The parser uses a simple probalistic context-free grammar (PCFG) to sparsely populate a chart fora richer model, and added a discriminatively trained reranker to the end of that pipeline.", "labels": [], "entities": []}, {"text": "Finite-state pre-processing for context-free parsing is very common as a means of reducing the amount of search required in the later stage.", "labels": [], "entities": [{"text": "context-free parsing", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.4820560812950134}]}, {"text": "As mentioned earlier, the Ratnaparkhi pipeline used a finite-state POS-tagger and a finite-state NP-chunker to reduce the search space at the parsing stage, and achieved linear observed-time performance.", "labels": [], "entities": []}, {"text": "Other recent examples of the utility of finite-state constraints for parsing pipelines include,, and.", "labels": [], "entities": [{"text": "parsing pipelines", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.9354546666145325}]}, {"text": "Similar hard constraints have been applied for dependency parsing, as will be outlined in Section 2.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.9050082266330719}]}, {"text": "Note that by making use of preprocessing constraints, such approaches are no longer performing full exact inferencethese are approximate inference methods, as are the methods presented in this article.", "labels": [], "entities": []}, {"text": "Using finite-state chunkers early in a syntactic parsing pipeline has shown both an efficiency) and an accuracy benefit for parsing systems.) demonstrated an efficiency gain by explicitly disallowing constituents that cross chunk boundaries.", "labels": [], "entities": [{"text": "syntactic parsing pipeline", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.6747768123944601}, {"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.9992451667785645}]}, {"text": "demonstrated that high-precision constraints on early stages of the pipeline (in the form of base phrase constraints derived either from a chunker or from later stages of an earlier iteration of the same pipeline) achieved significant accuracy improvements, by moving the pipeline search away from unlikely areas of the search space.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 235, "end_pos": 243, "type": "METRIC", "confidence": 0.9976423382759094}]}, {"text": "All of these approaches (as with Ratnaparkhi earlier) achieve improvements by ruling out parts of the search space, and the gain can either be realized in efficiency (same accuracy, less time) and/or accuracy (same time, greater accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 172, "end_pos": 180, "type": "METRIC", "confidence": 0.9891214966773987}, {"text": "accuracy", "start_pos": 200, "end_pos": 208, "type": "METRIC", "confidence": 0.9990134239196777}, {"text": "accuracy", "start_pos": 229, "end_pos": 237, "type": "METRIC", "confidence": 0.9979143738746643}]}, {"text": "Rather than extracting constraints from taggers or chunkers built for different purposes, in this study we have trained prediction models to more directly reduce the number of entries stored in cells of a dynamic programming chart during parsing-even to the point of \"closing\" chart cells to all entries.", "labels": [], "entities": []}, {"text": "We demonstrate results using three finite-state taggers that assign each word position in the sequence with a binary class label.", "labels": [], "entities": []}, {"text": "The first tagger decides if the word can begin a constituent of span greater than one word; the second tagger decides if the word can end a constituent of span greater than one word; and the third tagger decides if a chart cell spanning a single word should contain phrase-level non-terminals, or only POS tags.", "labels": [], "entities": []}, {"text": "Following the prediction of each word, chart cells spanning multiple words can be completely closed as follows: Given a chart cell (b, e) spanning words w b . .", "labels": [], "entities": []}, {"text": "we where b < e, we can \"close\" cell (b, e) if the first tagger decides that w b cannot be the first word of a multi-word constituent (MWC) or if the second tagger decides that we cannot be the last word in a MWC.", "labels": [], "entities": []}, {"text": "Completely closing sufficient chart cells allows us to impose worst-case complexity bounds on the overall pipeline, abound that none of the other previously mentioned methods for finite-state preprocessing can guarantee.", "labels": [], "entities": []}, {"text": "To complement closing multi-word constituent chart cells, our third tagger restricts the population of span-1 chart cells.", "labels": [], "entities": []}, {"text": "We note that all span-1 chart cells must contain at least one POS tag and can therefore never be closed completely.", "labels": [], "entities": []}, {"text": "Instead, our tagger restricts unary productions with POS tags on their right-hand side that span a single word.", "labels": [], "entities": []}, {"text": "We term these single word constituents (SWCs).", "labels": [], "entities": []}, {"text": "Disallowing SWCs alters span-1 cell population from potentially containing all non-terminals to just POS non-terminals.", "labels": [], "entities": [{"text": "SWCs", "start_pos": 12, "end_pos": 16, "type": "TASK", "confidence": 0.9458073973655701}]}, {"text": "In practice, this decreases the number of entries in span-1 chart cells by 70% during exhaustive parsing, significantly reducing the number of allowable constituents in larger spans.", "labels": [], "entities": [{"text": "exhaustive parsing", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.5378364473581314}]}, {"text": "Span-1 chart cells are also the most frequently queried cells in the Cocke-Younger-Kasami (CKY) algorithm.", "labels": [], "entities": []}, {"text": "The search over possible midpoints will always include two cells spanning a single word-one as the first left child and one as the last right child.", "labels": [], "entities": []}, {"text": "It is therefore beneficial to minimize the number of entries in these span-1 cells.", "labels": [], "entities": []}, {"text": "The pre-processing framework we have outlined is straightforward to incorporate into most existing context-free constituent parsers, a task we have already done for several state-of-the art parsers.", "labels": [], "entities": []}, {"text": "In the following sections we formally define our approach to finite-state chart constraints and analyze the accuracy of each of the three taggers and their impact on parsing efficiency and accuracy when used to prune the search space of a constituent parser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.9986833930015564}, {"text": "parsing", "start_pos": 166, "end_pos": 173, "type": "TASK", "confidence": 0.970651388168335}, {"text": "accuracy", "start_pos": 189, "end_pos": 197, "type": "METRIC", "confidence": 0.9972099661827087}]}, {"text": "We apply our methods to exhaustive CYK parsing with simple grammars, as well as to high-accuracy parsing approaches such as the parsing pipeline and the Berkeley parser.", "labels": [], "entities": [{"text": "CYK parsing", "start_pos": 35, "end_pos": 46, "type": "TASK", "confidence": 0.5380465984344482}]}, {"text": "Various methods for applying finite-state chart constraints are investigated, including methods that guarantee quadratic or linear complexity of the context-free parser.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the sections that follow, we present empirical trials to examine the behavior of chart constraints under a variety of conditions.", "labels": [], "entities": []}, {"text": "First, we detail the data, evaluation, and parsers used in these experiments.", "labels": [], "entities": []}, {"text": "For English, all stochastic grammars are induced from the Penn WSJ Treebank (Marcus, Marcinkiewicz, and Santorini 1993).", "labels": [], "entities": [{"text": "Penn WSJ Treebank", "start_pos": 58, "end_pos": 75, "type": "DATASET", "confidence": 0.9674052198727926}]}, {"text": "Sections 2-21 of the treebank are used as training, Section 00 as held-out (for determining stopping criteria during training and some parameter tuning), Section 24 as development, and Section 23 as test set.", "labels": [], "entities": []}, {"text": "For Chinese, we use the Penn Chinese Treebank ().", "labels": [], "entities": [{"text": "Penn Chinese Treebank", "start_pos": 24, "end_pos": 45, "type": "DATASET", "confidence": 0.9866243600845337}]}, {"text": "Articles 1-270 and 400-1151 are used for training, articles 301-325 for both held-out and development, and articles 271-300 for testing.", "labels": [], "entities": []}, {"text": "Supervised class labels are extracted from the non-binarized treebank trees for B, E, and U (as well as their complements).", "labels": [], "entities": []}, {"text": "All results report F-measure labeled bracketing accuracy (harmonic mean of labeled precision and labeled recall) for all sentences in the data set, and timing is reported using an Intel 3.00GHz processor with 6MB of cache and 16GB of memory.", "labels": [], "entities": [{"text": "F-measure labeled bracketing accuracy (harmonic mean of labeled precision", "start_pos": 19, "end_pos": 92, "type": "METRIC", "confidence": 0.6665354251861573}, {"text": "recall", "start_pos": 105, "end_pos": 111, "type": "METRIC", "confidence": 0.8640280961990356}, {"text": "timing", "start_pos": 152, "end_pos": 158, "type": "METRIC", "confidence": 0.9984304308891296}]}, {"text": "Timing results include both the pre-processing time to tag the chart constraints as well as the subsequent context-free inference, but tagging time is relatively negligible as it takes less than three seconds to tag the entire development corpus.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1  Statistics on extracted word classes for English (Sections 2-21 of the Penn WSJ treebank) and  Chinese (articles 1-270 and 400-1151 of the Penn Chinese treebank).", "labels": [], "entities": [{"text": "Penn WSJ treebank", "start_pos": 81, "end_pos": 98, "type": "DATASET", "confidence": 0.9566556811332703}, {"text": "Penn Chinese treebank", "start_pos": 149, "end_pos": 170, "type": "DATASET", "confidence": 0.9677217205365499}]}, {"text": " Table 3  Tagging accuracy on the respective development sets (WSJ Section 24 for English and Penn  Chinese Treebank articles 301-325 for Chinese) for binary classes B, E, and U, for various  Markov orders.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9648684859275818}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9836392998695374}, {"text": "WSJ Section 24", "start_pos": 63, "end_pos": 77, "type": "DATASET", "confidence": 0.9336473941802979}, {"text": "Penn  Chinese Treebank articles 301-325", "start_pos": 94, "end_pos": 133, "type": "DATASET", "confidence": 0.954907214641571}]}, {"text": " Table 4  English development set results (WSJ Section 24) for the CONSTRAINEDCYK algorithm with both  left-and right-binarized Markov order-2 grammars under various individual and combined  constraints.", "labels": [], "entities": [{"text": "WSJ Section 24", "start_pos": 43, "end_pos": 57, "type": "DATASET", "confidence": 0.8197385668754578}]}, {"text": " Table 5  English test set results (WSJ Section 23) for the CONSTRAINEDCYK algorithm with both left-and  right-binarized Markov order-2 grammars.", "labels": [], "entities": [{"text": "WSJ Section 23", "start_pos": 36, "end_pos": 50, "type": "DATASET", "confidence": 0.8391281763712565}]}, {"text": " Table 6  Chinese test set results (PCTB Sections 271-300) for the CONSTRAINEDCYK algorithm with both  left-and right-binarized Markov order-2 grammars.", "labels": [], "entities": [{"text": "Chinese test set", "start_pos": 10, "end_pos": 26, "type": "DATASET", "confidence": 0.8517201940218607}, {"text": "PCTB Sections 271-300", "start_pos": 36, "end_pos": 57, "type": "DATASET", "confidence": 0.8453464110692342}]}, {"text": " Table 7  English test set results (WSJ Section 23) applying sentence-level high precision and unary  constraints to three parsers with parameter settings tuned on development data.", "labels": [], "entities": [{"text": "WSJ Section 23", "start_pos": 36, "end_pos": 50, "type": "DATASET", "confidence": 0.8719112475713094}, {"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.709701657295227}]}, {"text": " Table 8  Chinese test set results (PCTB articles 271-300) applying sentence-level high-precision and unary  constraints to two parsers with parameter settings tuned on development data.", "labels": [], "entities": [{"text": "Chinese test set", "start_pos": 10, "end_pos": 26, "type": "DATASET", "confidence": 0.8874815702438354}, {"text": "PCTB articles 271-300", "start_pos": 36, "end_pos": 57, "type": "DATASET", "confidence": 0.9215105970700582}]}]}