{"title": [], "abstractContent": [{"text": "This article documents a large set of heretofore unpublished details Collins used in his parser, such that, along with Collins' (1999) thesis, this article contains all information necessary to duplicate Collins' benchmark results.", "labels": [], "entities": []}, {"text": "Indeed, these as-yet-unpublished details account for an 11% relative increase in error from an implementation including all details to a clean-room implementation of Collins' model.", "labels": [], "entities": [{"text": "error", "start_pos": 81, "end_pos": 86, "type": "METRIC", "confidence": 0.9822542071342468}]}, {"text": "We also show a cleaner and equally well-performing method for the handling of punctuation and conjunction and reveal certain other probabilistic oddities about Collins' parser.", "labels": [], "entities": [{"text": "handling of punctuation and conjunction", "start_pos": 66, "end_pos": 105, "type": "TASK", "confidence": 0.8605417609214783}]}, {"text": "We not only analyze the effect of the unpublished details, but also reanalyze the effect of certain well-known details, revealing that bilexical dependencies are barely used by the model and that head choice is not nearly as important to overall parsing performance as once thought.", "labels": [], "entities": []}, {"text": "Finally, we perform experiments that show that the true discriminative power of lexicalization appears to lie in the fact that unlexicalized syntactic structures are generated conditioning on the headword and its part of speech.", "labels": [], "entities": []}], "introductionContent": [{"text": "Michael) parsing models have been quite influential in the field of natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 68, "end_pos": 95, "type": "TASK", "confidence": 0.6451612909634908}]}, {"text": "Not only did they achieve new performance benchmarks on parsing the Penn Treebank, and not only did they serve as the basis of Collins' own future work, but they also served as the basis of important work on parser selection, an investigation of corpus variation and the effectiveness of bilexical dependencies, sample selection (Hwa 2001), bootstrapping non-English parsers, and the automatic labeling of semantic roles and predicate-argument extraction, as well as that of other research efforts.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 68, "end_pos": 81, "type": "DATASET", "confidence": 0.907178670167923}, {"text": "parser selection", "start_pos": 208, "end_pos": 224, "type": "TASK", "confidence": 0.9437567293643951}, {"text": "sample selection", "start_pos": 312, "end_pos": 328, "type": "TASK", "confidence": 0.7843371629714966}, {"text": "bootstrapping non-English parsers", "start_pos": 341, "end_pos": 374, "type": "TASK", "confidence": 0.8121035496393839}, {"text": "predicate-argument extraction", "start_pos": 425, "end_pos": 454, "type": "TASK", "confidence": 0.7085039168596268}]}, {"text": "Recently, in order to continue our work combining word sense with parsing and the study of language-dependent and -independent parsing features (Bikel and Chiang 2000), we built a multilingual parsing engine that is capable of instantiating a wide variety of generative statistical parsing models.", "labels": [], "entities": [{"text": "parsing", "start_pos": 66, "end_pos": 73, "type": "TASK", "confidence": 0.9630836844444275}, {"text": "generative statistical parsing", "start_pos": 259, "end_pos": 289, "type": "TASK", "confidence": 0.8744482398033142}]}, {"text": "As an appropriate baseline model, we chose to instantiate the parameters of Collins' Model 2.", "labels": [], "entities": [{"text": "Collins' Model 2", "start_pos": 76, "end_pos": 92, "type": "DATASET", "confidence": 0.9706751704216003}]}, {"text": "This task proved more difficult than it initially appeared.", "labels": [], "entities": []}, {"text": "Starting with Collins' (1999) thesis, we reproduced all the parameters described but did not achieve nearly the same high performance on the well-established development test set of Section 00 of the Penn Treebank.", "labels": [], "entities": [{"text": "Collins' (1999) thesis", "start_pos": 14, "end_pos": 36, "type": "DATASET", "confidence": 0.8058545708656311}, {"text": "development test set of Section 00 of the Penn Treebank", "start_pos": 158, "end_pos": 213, "type": "DATASET", "confidence": 0.8714148879051209}]}, {"text": "Together with Collins' thesis, this article contains all the information necessary to replicate Collins' parsing results.", "labels": [], "entities": [{"text": "Collins' thesis", "start_pos": 14, "end_pos": 29, "type": "DATASET", "confidence": 0.909898042678833}, {"text": "replicate Collins' parsing", "start_pos": 86, "end_pos": 112, "type": "TASK", "confidence": 0.7657069762547811}]}, {"text": "Specifically, this article describes all the as-yet-unpublished details and features of Collins' model and some analysis of the effect of these features with respect to parsing performance, as well as some comparative analysis of the effects of published features.", "labels": [], "entities": []}, {"text": "In particular, implementing Collins' model using only the published details causes an 11% increase in relative error over Collins' own published results.", "labels": [], "entities": [{"text": "relative error", "start_pos": 102, "end_pos": 116, "type": "METRIC", "confidence": 0.7422856986522675}]}, {"text": "That is, taken together, all the unpublished details have a significant effect on overall parsing performance.", "labels": [], "entities": []}, {"text": "In addition to the effects of the unpublished details, we also have new evidence to show that the discriminative power of Collins' model does not lie where once thought: Bilexical dependencies play an extremely small role in Collins' models, and head choice is not nearly as critical as once thought.", "labels": [], "entities": [{"text": "head choice", "start_pos": 246, "end_pos": 257, "type": "TASK", "confidence": 0.8405494391918182}]}, {"text": "This article also discusses the rationale for various parameter choices.", "labels": [], "entities": []}, {"text": "In general, we will limit our discussion to Collins' Model 2, but we make occasional reference to Model 3, as well.", "labels": [], "entities": [{"text": "Collins' Model 2", "start_pos": 44, "end_pos": 60, "type": "DATASET", "confidence": 0.9144802689552307}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 6  Number of times our parsing engine was able to deliver a probability for the various levels of  back-off of the modifier-word generation model, P Mw , when testing on Section 00, having  trained on Sections 02-21. In other words, this table reports how often a context in the  back-off chain of P Mw that was needed during decoding was observed in training.", "labels": [], "entities": []}, {"text": " Table 7  Results on Section 00 with simplified head rules. The baseline model is our engine in its  closest possible emulation of Collins' Model 2. See", "labels": [], "entities": [{"text": "Collins' Model 2", "start_pos": 131, "end_pos": 147, "type": "DATASET", "confidence": 0.9425342082977295}]}, {"text": " Table 8  Parsing performance with various models on Section 00 of the Penn Treebank. P M is the  parameter class for generating partially lexicalized modifying nonterminals (a nonterminal  label and part of speech). P Mw is the parameter class that generates the headword of a  modifying nonterminal. Together, P M and P Mw generate a fully lexicalized modifying  nonterminal. The check marks indicate the inclusion of the headword w h and its part of  speech t h of the lexicalized head nonterminal H(t h , w h ) in the conditioning contexts of P M and  P Mw . See Table 4 for definitions of the remaining column headings.", "labels": [], "entities": [{"text": "Section 00 of the Penn Treebank", "start_pos": 53, "end_pos": 84, "type": "DATASET", "confidence": 0.697843020160993}]}, {"text": " Table 8. Model M tw,tw shows our baseline, and Model M \u03c6,\u03c6 shows  the effect of removing all dependence on the headword and its part of speech, with the  other models illustrating varying degrees of removing elements from the two parame- ter classes' conditioning contexts. Notably, including the headword w h in or removing  it from the P M contexts appears to have a significant effect on overall performance, as  shown by moving from Model M tw,t to Model M t,t and from Model M tw,\u03c6 to Model  M t,\u03c6 . This reinforces the notion that particular headwords have structural preferences,  so that making the P M parameters dependent on headwords would capture such pref- erences. As for effects involving dependence on the head tag t h , observe that moving  from Model M tw,t to Model M tw,\u03c6 results in a small drop in both recall and precision,  whereas making an analogous move from Model M t,t to Model M t,\u03c6 results in a drop  in recall, but a slight gain in precision (the two moves are analogous in that in both  cases, t h is dropped from the context of P Mw ). It is not evident why these two moves  do not produce similar performance losses, but in both cases, the performance drops  are small relative to those observed when eliminating w h from the conditioning con- texts, indicating that headwords matter far more than parts of speech for determining  structural preferences, as one would expect.", "labels": [], "entities": [{"text": "recall", "start_pos": 825, "end_pos": 831, "type": "METRIC", "confidence": 0.9967314004898071}, {"text": "precision", "start_pos": 836, "end_pos": 845, "type": "METRIC", "confidence": 0.9885922074317932}, {"text": "recall", "start_pos": 935, "end_pos": 941, "type": "METRIC", "confidence": 0.9978815913200378}, {"text": "precision", "start_pos": 964, "end_pos": 973, "type": "METRIC", "confidence": 0.9990915060043335}]}]}