{"title": [{"text": "Statistical Machine Translation with Scarce Resources Using Morpho-syntactic Information", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8077959020932516}]}], "abstractContent": [{"text": "RWTH Aachen RWTH Aachen In statistical machine translation, correspondences between the words in the source and the target language are learned from parallel corpora, and often little or no linguistic knowledge is used to structure the underlying models.", "labels": [], "entities": [{"text": "RWTH Aachen RWTH Aachen", "start_pos": 0, "end_pos": 23, "type": "DATASET", "confidence": 0.8268505930900574}, {"text": "statistical machine translation", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.6258483429749807}]}, {"text": "In particular, existing statistical systems for machine translation often treat different inflected forms of the same lemma as if they were independent of one another.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.7872442305088043}]}, {"text": "The bilingual training data can be better exploited by explicitly taking into account the interdependencies of related inflected forms.", "labels": [], "entities": []}, {"text": "We propose the construction of hierarchical lexicon models on the basis of equivalence classes of words.", "labels": [], "entities": []}, {"text": "In addition, we introduce sentence-level restructuring transformations which aim at the assimilation of word order in related sentences.", "labels": [], "entities": []}, {"text": "We have systematically investigated the amount of bilingual training data required to maintain an acceptable quality of machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 120, "end_pos": 139, "type": "TASK", "confidence": 0.7251818180084229}]}, {"text": "The combination of the suggested methods for improving translation quality in frameworks with scarce resources has been successfully tested: We were able to reduce the amount of bilingual training data to less than 10% of the original corpus, while losing only 1.6% in translation quality.", "labels": [], "entities": []}, {"text": "The improvement of the translation results is demonstrated on two German-English corpora taken from the Verbmobil task and the Nespole!", "labels": [], "entities": [{"text": "translation", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.9528392553329468}, {"text": "Nespole!", "start_pos": 127, "end_pos": 135, "type": "DATASET", "confidence": 0.8539251983165741}]}], "introductionContent": [{"text": "The statistical approach to machine translation has proved successful in various comparative evaluations since its revival by the work of the IBM research group more than a decade ago.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.8158775866031647}]}, {"text": "The IBM group dispensed with linguistic analysis, at least in its earliest publications.", "labels": [], "entities": [{"text": "IBM group", "start_pos": 4, "end_pos": 13, "type": "DATASET", "confidence": 0.7880315184593201}, {"text": "linguistic analysis", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7308800965547562}]}, {"text": "Although the IBM group finally made use of morphological and syntactic information to enhance translation quality (), most of today's statistical machine translation systems still consider only surface forms and use no linguistic knowledge about the structure of the languages involved.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 134, "end_pos": 165, "type": "TASK", "confidence": 0.63520947098732}]}, {"text": "In many applications only small amounts of bilingual training data are available for the desired domain and language pair, and it is highly desirable to avoid at least parts of the costly data collection process.", "labels": [], "entities": []}, {"text": "The main objective of the work reported in this article is to introduce morphological knowledge in order to reduce the amount of bilingual data necessary to sufficiently cover the vocabulary expected in testing.", "labels": [], "entities": []}, {"text": "This is achieved by explicitly taking into account the interdependencies of related inflected forms.", "labels": [], "entities": []}, {"text": "In this work, a hierarchy of equivalence classes at different levels of abstraction is proposed.", "labels": [], "entities": []}, {"text": "Features from those hierarchy levels are combined to form hierarchical lexicon models, which can replace the standard probabilistic lexicon used", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3  Resolution of ambiguity on the Verbmobil corpus.", "labels": [], "entities": [{"text": "Resolution", "start_pos": 10, "end_pos": 20, "type": "TASK", "confidence": 0.9606855511665344}, {"text": "Verbmobil corpus", "start_pos": 41, "end_pos": 57, "type": "DATASET", "confidence": 0.9612230658531189}]}, {"text": " Table 5  Statistics of corpora for training: Verbmobil and Nespole! Singletons are types occurring only  once in training.", "labels": [], "entities": [{"text": "Verbmobil", "start_pos": 46, "end_pos": 55, "type": "DATASET", "confidence": 0.7166945934295654}]}, {"text": " Table 6  Conventional dictionary used to complement the  training corpus.", "labels": [], "entities": []}, {"text": " Table 7  The official vocabularies in Verbmobil.", "labels": [], "entities": [{"text": "Verbmobil", "start_pos": 39, "end_pos": 48, "type": "DATASET", "confidence": 0.9316646456718445}]}, {"text": " Table 8  Statistics for the test sets for German to English translation: Verbmobil  Eval-2000 (Test and Develop) and Nespole!", "labels": [], "entities": [{"text": "Nespole!", "start_pos": 118, "end_pos": 126, "type": "DATASET", "confidence": 0.7811824381351471}]}, {"text": " Table 9  Results for hierarchical lexicon models and translation with scarce resources.  \"Restructuring\" entails treatment of question inversion and separated verb prefixes as  well as merging of phrases in both languages. A conventional dictionary is available in  all three setups. The language model is always trained on the full monolingual English  corpus. Task: Verbmobil. Testing on 527 sentences (Test and Develop).", "labels": [], "entities": []}, {"text": " Table 11  Results for hierarchical lexicon model Nespole!  \"Restructuring\" entails treatment of question  inversion and separated verb prefixes as well as  merging of phrases in both languages. The same  conventional dictionary was used as in the  experiments the Verbmobil. The language model  was trained on a combination of the English parts  of the Nespole! corpus and the Verbmobil corpus.", "labels": [], "entities": [{"text": "Verbmobil", "start_pos": 265, "end_pos": 274, "type": "DATASET", "confidence": 0.9241390824317932}, {"text": "Nespole! corpus", "start_pos": 354, "end_pos": 369, "type": "DATASET", "confidence": 0.8743861516316732}, {"text": "Verbmobil corpus", "start_pos": 378, "end_pos": 394, "type": "DATASET", "confidence": 0.9653040170669556}]}]}