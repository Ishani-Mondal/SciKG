{"title": [{"text": "Word Translation Disambiguation Using Bilingual Bootstrapping", "labels": [], "entities": [{"text": "Word Translation Disambiguation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8440955678621928}]}], "abstractContent": [{"text": "This article proposes anew method for word translation disambiguation, one that uses a machine-learning technique called bilingual bootstrapping.", "labels": [], "entities": [{"text": "word translation disambiguation", "start_pos": 38, "end_pos": 69, "type": "TASK", "confidence": 0.8553329110145569}]}, {"text": "In learning to disambiguate words to be translated , bilingual bootstrapping makes use of a small amount of classified data and a large amount of unclassified data in both the source and the target languages.", "labels": [], "entities": []}, {"text": "It repeatedly constructs classi-fiers in the two languages in parallel and boosts the performance of the classifiers by classifying unclassified data in the two languages and by exchanging information regarding classified data between the two languages.", "labels": [], "entities": []}, {"text": "Experimental results indicate that word translation disambiguation based on bilingual bootstrapping consistently and significantly outperforms existing methods that are based on monolingual bootstrapping.", "labels": [], "entities": [{"text": "word translation disambiguation", "start_pos": 35, "end_pos": 66, "type": "TASK", "confidence": 0.8368796110153198}]}], "introductionContent": [{"text": "We address here the problem of word translation disambiguation.", "labels": [], "entities": [{"text": "word translation disambiguation", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.8555110891660055}]}, {"text": "If, for example, we were to attempt to translate the English noun plant, which could refer either to a type of factory or to a form of flora (i.e., in Chinese, either to or to), our goal would be to determine the correct Chinese translation.", "labels": [], "entities": [{"text": "translate the English noun plant, which could refer either to a type of factory or to a form of flora (i.e., in Chinese, either to or to)", "start_pos": 39, "end_pos": 176, "type": "Description", "confidence": 0.7977319918572903}]}, {"text": "That is, word translation disambiguation is essentially a special case of word sense disambiguation (in the above example, gongchang would correspond to the sense of factory and zhiwu to the sense of flora).", "labels": [], "entities": [{"text": "word translation disambiguation", "start_pos": 9, "end_pos": 40, "type": "TASK", "confidence": 0.869871457417806}, {"text": "word sense disambiguation", "start_pos": 74, "end_pos": 99, "type": "TASK", "confidence": 0.6128469506899515}]}, {"text": "We could view word translation disambiguation as a problem of classification.", "labels": [], "entities": [{"text": "word translation disambiguation", "start_pos": 14, "end_pos": 45, "type": "TASK", "confidence": 0.8358002702395121}]}, {"text": "To perform the task, we could employ a supervised learning method, but since to do so would require human labeling of data, which would be expensive, bootstrapping would be a better choice. has proposed a bootstrapping method for word sense disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 230, "end_pos": 255, "type": "TASK", "confidence": 0.7884584665298462}]}, {"text": "When applied to translation from English to Chinese, his method starts learning with a small number of English sentences that contain ambiguous English words and that are labeled with correct Chinese translations of those words.", "labels": [], "entities": []}, {"text": "It then uses these classified sentences as training data to create a classifier (e.g., a decision list), which it uses to classify unclassified sentences containing the same ambiguous words.", "labels": [], "entities": []}, {"text": "The output of this process is then used as additional training data.", "labels": [], "entities": []}, {"text": "It also adopts the one-sense-per-discourse heuristic) in classifying unclassified sentences.", "labels": [], "entities": [{"text": "classifying unclassified sentences", "start_pos": 57, "end_pos": 91, "type": "TASK", "confidence": 0.8396039406458536}]}, {"text": "By repeating the above process, an accurate classifier for word translation disambiguation can be created.", "labels": [], "entities": [{"text": "word translation disambiguation", "start_pos": 59, "end_pos": 90, "type": "TASK", "confidence": 0.8482884565989176}]}, {"text": "Because this method uses data in a single language (i.e., the source language in translation), we refer to it here as monolingual bootstrapping (MB).", "labels": [], "entities": []}, {"text": "In this paper, we propose anew method of bootstrapping, one that we refer to as bilingual bootstrapping (BB).", "labels": [], "entities": []}, {"text": "Instead of using data in one language, BB uses data in two languages.", "labels": [], "entities": []}, {"text": "In translation from English to Chinese, for example, BB makes use of unclassified data from both languages.", "labels": [], "entities": [{"text": "BB", "start_pos": 53, "end_pos": 55, "type": "DATASET", "confidence": 0.45554637908935547}]}, {"text": "It also uses a small number of classified data in English and, optionally, a small number of classified data in Chinese.", "labels": [], "entities": []}, {"text": "The data in the two languages should be from the same domain but are not required to be exactly in parallel.", "labels": [], "entities": []}, {"text": "BB constructs classifiers for English-to-Chinese translation disambiguation by repeating the following two steps: (1) Construct a classifier for each of the languages on the basis of classified data in both languages, and (2) use the constructed classifier for each language to classify unclassified data, which are then added to the classified data of the language.", "labels": [], "entities": [{"text": "English-to-Chinese translation disambiguation", "start_pos": 30, "end_pos": 75, "type": "TASK", "confidence": 0.6987014611562093}]}, {"text": "We can use classified data in both languages in step (1), because words in one language have translations in the other, and we can transform data from one language into the other.", "labels": [], "entities": []}, {"text": "We have experimentally evaluated the performance of BB in word translation disambiguation, and all of our results indicate that BB consistently and significantly outperforms MB.", "labels": [], "entities": [{"text": "BB", "start_pos": 52, "end_pos": 54, "type": "METRIC", "confidence": 0.8840851187705994}, {"text": "word translation disambiguation", "start_pos": 58, "end_pos": 89, "type": "TASK", "confidence": 0.8672762513160706}, {"text": "BB", "start_pos": 128, "end_pos": 130, "type": "METRIC", "confidence": 0.9869533181190491}]}, {"text": "The higher performance of BB can be attributed to its effective use of the asymmetric relationship between the ambiguous words in the two languages.", "labels": [], "entities": [{"text": "BB", "start_pos": 26, "end_pos": 28, "type": "TASK", "confidence": 0.3931073844432831}]}, {"text": "Our study is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we describe related work.", "labels": [], "entities": []}, {"text": "Specifically, we formalize the problem of word translation disambiguation as that of classification based on statistical learning.", "labels": [], "entities": [{"text": "word translation disambiguation", "start_pos": 42, "end_pos": 73, "type": "TASK", "confidence": 0.8445142110188802}]}, {"text": "As examples, we describe two such methods: one using decision lists and the other using naive Bayes.", "labels": [], "entities": []}, {"text": "We also explain the Yarowsky disambiguation method, which is based on Monolingual Bootstrapping.", "labels": [], "entities": []}, {"text": "In Section 3, we describe bilingual bootstrapping, comparing BB with MB, and discussing the relationship between BB and co-training.", "labels": [], "entities": [{"text": "BB", "start_pos": 61, "end_pos": 63, "type": "METRIC", "confidence": 0.9463604092597961}, {"text": "MB", "start_pos": 69, "end_pos": 71, "type": "METRIC", "confidence": 0.9507689476013184}]}, {"text": "In Section 4, we describe our experimental results, and finally, in Section 5, we give some concluding remarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have conducted two experiments on English-Chinese translation disambiguation.", "labels": [], "entities": [{"text": "English-Chinese translation disambiguation", "start_pos": 37, "end_pos": 79, "type": "TASK", "confidence": 0.6514552136262258}]}, {"text": "In this section, we will first describe the experimental settings and then present the results.", "labels": [], "entities": []}, {"text": "We will also discuss the results of several follow-on experiments.", "labels": [], "entities": []}, {"text": "We first applied BB, MB-B, and MB-D to translation disambiguation on the English words line and interest using a benchmark data set.", "labels": [], "entities": [{"text": "BB", "start_pos": 17, "end_pos": 19, "type": "METRIC", "confidence": 0.9950404763221741}, {"text": "translation disambiguation", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.9790302813053131}]}, {"text": "The data set consists mainly of articles from the Wall Street Journal and is prepared for conducting word sense disambiguation (WSD) on the two words (e.g., Pedersen 2000).", "labels": [], "entities": [{"text": "Wall Street Journal", "start_pos": 50, "end_pos": 69, "type": "DATASET", "confidence": 0.9557318091392517}, {"text": "word sense disambiguation (WSD)", "start_pos": 101, "end_pos": 132, "type": "TASK", "confidence": 0.7647998432318369}]}, {"text": "We collected from the HIT dictionary 6 the Chinese words that can be translations of the two English words; these are listed in.", "labels": [], "entities": [{"text": "HIT dictionary", "start_pos": 22, "end_pos": 36, "type": "DATASET", "confidence": 0.9716306030750275}]}, {"text": "One sense of an English word links to one group of Chinese words.", "labels": [], "entities": []}, {"text": "(For the word interest, we used only its four major senses, because the remaining two minor senses occur in only 3.3% of the data.)", "labels": [], "entities": []}, {"text": "For each sense, we selected an English word that is strongly associated with the sense according to our own intuition (cf.).", "labels": [], "entities": []}, {"text": "We refer to this word as a seed word.", "labels": [], "entities": []}, {"text": "For example, for the sense of money paid for the use of money, we selected the word rate.", "labels": [], "entities": []}, {"text": "We viewed the seed word as a classified \"sentence,\" following a similar proposal in.", "labels": [], "entities": []}, {"text": "In this way, for each sense we had a classified instance in English.", "labels": [], "entities": []}, {"text": "As unclassified data in English, we collected sentences in news articles from a Web site (www.news.com), and as unclassified data in Chinese, we collected sentences in news articles from another Web site (news.cn.tom.com).", "labels": [], "entities": []}, {"text": "Note that we need to use only the sentences containing the words in.", "labels": [], "entities": []}, {"text": "We observed that the distribution of the senses in the unclassified data was balanced.", "labels": [], "entities": []}, {"text": "As test data, we used the entire benchmark data set.", "labels": [], "entities": [{"text": "benchmark data set", "start_pos": 33, "end_pos": 51, "type": "DATASET", "confidence": 0.7840008934338888}]}, {"text": "shows the sizes of the data sets.", "labels": [], "entities": []}, {"text": "Note that there are in general more unclassified sentences (and texts) in Chinese than in English, because one English word usually can link to several Chinese words (cf..", "labels": [], "entities": []}, {"text": "As the translation dictionary, we used the HIT dictionary, which contains about 76,000 Chinese words, 60,000 English words, and 118,000 senses (links).", "labels": [], "entities": [{"text": "HIT dictionary", "start_pos": 43, "end_pos": 57, "type": "DATASET", "confidence": 0.9391769170761108}]}, {"text": "We then used the data to conduct translation disambiguation with BB, MB-B, and MB-D, as described in Sections 4.1 and Section 4.2.", "labels": [], "entities": [{"text": "translation disambiguation", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.9650651812553406}, {"text": "BB", "start_pos": 65, "end_pos": 67, "type": "METRIC", "confidence": 0.8254790306091309}]}, {"text": "For both BB and MB-B, we used an ensemble of five naive Bayesian classifiers with window sizes of \u00b11, \u00b13, \u00b15, \u00b17, and \u00b19 words, and we set the parameters \u03b2, b, and \u03b8 to 0.2, 15, and 1.5, respectively.", "labels": [], "entities": []}, {"text": "The parameters were tuned on the basis of our preliminary experimental results on MB-B; they were not tuned, however, for BB.", "labels": [], "entities": [{"text": "BB", "start_pos": 122, "end_pos": 124, "type": "METRIC", "confidence": 0.9910125136375427}]}, {"text": "We set the BB-specific parameter \u03b1 to 0.4, which meant that we weighted information from English and Chinese equally.", "labels": [], "entities": [{"text": "BB-specific parameter \u03b1", "start_pos": 11, "end_pos": 34, "type": "METRIC", "confidence": 0.8117647767066956}]}, {"text": "shows the translation disambiguation accuracies of the three methods as well as that of a baseline method in which we always choose the most frequent sense.", "labels": [], "entities": [{"text": "translation disambiguation", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.8688944578170776}]}, {"text": "show the learning curves of MB-D, MB-B, and BB.", "labels": [], "entities": [{"text": "BB", "start_pos": 44, "end_pos": 46, "type": "METRIC", "confidence": 0.9883397817611694}]}, {"text": "shows the accuracies of BB with different \u03b1 values.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9847493767738342}, {"text": "BB", "start_pos": 24, "end_pos": 26, "type": "METRIC", "confidence": 0.9713665843009949}]}, {"text": "From the results, we see that BB consistently and significantly outperforms both MB-D and MB-B.", "labels": [], "entities": [{"text": "BB", "start_pos": 30, "end_pos": 32, "type": "METRIC", "confidence": 0.9967541098594666}]}, {"text": "The results from the sign test are statistically significant (p-value < 0.001).", "labels": [], "entities": []}, {"text": "(For the sign test method, see, for example, Yang and Liu).", "labels": [], "entities": []}, {"text": "shows the results achieved by some existing supervised learning methods with respect to the benchmark data (cf..", "labels": [], "entities": []}, {"text": "Although BB is a method nearly equivalent to one based on unsupervised learning, it still performs favorably when compared with the supervised methods (note that since the experimental settings are different, the results cannot be directly compared).", "labels": [], "entities": [{"text": "BB", "start_pos": 9, "end_pos": 11, "type": "METRIC", "confidence": 0.8490314483642578}]}, {"text": "We also conducted translation on seven of the twelve English words studied in. lists the words we used.", "labels": [], "entities": [{"text": "translation", "start_pos": 18, "end_pos": 29, "type": "TASK", "confidence": 0.9839752912521362}]}], "tableCaptions": [{"text": " Table 3  Accuracies of disambiguation in Experiment 1.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9963005781173706}]}, {"text": " Table 4  Accuracies of supervised methods.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9878601431846619}]}, {"text": " Table 7  Accuracies of disambiguation in Experiment 2.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9961040019989014}]}, {"text": " Table 8  Top words for interest rate sense of interest.", "labels": [], "entities": []}, {"text": " Table 9  Accuracy of text classification.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9911967515945435}, {"text": "text classification", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.6931260824203491}]}, {"text": " Table 10  Accuracy of disambiguation.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9971953630447388}]}]}