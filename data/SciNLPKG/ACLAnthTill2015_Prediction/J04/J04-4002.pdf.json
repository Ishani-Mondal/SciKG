{"title": [{"text": "The Alignment Template Approach to Statistical Machine Translation", "labels": [], "entities": [{"text": "Alignment Template Approach", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.8410019477208456}, {"text": "Statistical Machine Translation", "start_pos": 35, "end_pos": 66, "type": "TASK", "confidence": 0.8257893522580465}]}], "abstractContent": [{"text": "Google RWTH Aachen A phrase-based statistical machine translation approach-the alignment template approach-is described.", "labels": [], "entities": [{"text": "RWTH Aachen", "start_pos": 7, "end_pos": 18, "type": "DATASET", "confidence": 0.7369917333126068}, {"text": "phrase-based statistical machine translation", "start_pos": 21, "end_pos": 65, "type": "TASK", "confidence": 0.5543055981397629}]}, {"text": "This translation approach allows for general many-to-many relations between words.", "labels": [], "entities": []}, {"text": "Thereby, the context of words is taken into account in the translation model, and local changes in word order from source to target language can be learned explicitly.", "labels": [], "entities": []}, {"text": "The model is described using a log-linear modeling approach, which is a generalization of the often used source-channel approach.", "labels": [], "entities": []}, {"text": "Thereby, the model is easier to extend than classical statistical machine translation systems.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 54, "end_pos": 85, "type": "TASK", "confidence": 0.6879323919614156}]}, {"text": "We describe in detail the process for learning phrasal translations, the feature functions used, and the search algorithm.", "labels": [], "entities": [{"text": "learning phrasal translations", "start_pos": 38, "end_pos": 67, "type": "TASK", "confidence": 0.6610626975695292}]}, {"text": "The evaluation of this approach is performed on three different tasks.", "labels": [], "entities": []}, {"text": "For the German-English speech Verbmobil task, we analyze the effect of various system components.", "labels": [], "entities": [{"text": "German-English speech Verbmobil task", "start_pos": 8, "end_pos": 44, "type": "TASK", "confidence": 0.5788787603378296}]}, {"text": "On the French-English Canadian Hansards task, the alignment template system obtains significantly better results than a single-word-based translation model.", "labels": [], "entities": [{"text": "French-English Canadian Hansards task", "start_pos": 7, "end_pos": 44, "type": "DATASET", "confidence": 0.6110742464661598}]}, {"text": "In the Chinese-English 2002 National Institute of Standards and Technology (NIST) machine translation evaluation it yields statistically significantly better NIST scores than all competing research and commercial translation systems.", "labels": [], "entities": [{"text": "Chinese-English 2002 National Institute of Standards and Technology (NIST) machine translation", "start_pos": 7, "end_pos": 101, "type": "TASK", "confidence": 0.49994752498773426}]}], "introductionContent": [{"text": "Machine translation (MT) is a hard problem, because natural languages are highly complex, many words have various meanings and different possible translations, sentences might have various readings, and the relationships between linguistic entities are often vague.", "labels": [], "entities": [{"text": "Machine translation (MT)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.907417106628418}]}, {"text": "In addition, it is sometimes necessary to take world knowledge into account.", "labels": [], "entities": []}, {"text": "The number of relevant dependencies is much too large and those dependencies are too complex to take them all into account in a machine translation system.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.6750533133745193}]}, {"text": "Given these boundary conditions, a machine translation system has to make decisions (produce translations) given incomplete knowledge.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.7391111552715302}]}, {"text": "In such a case, a principled approach to solving that problem is to use the concepts of statistical decision theory to try to make optimal decisions given incomplete knowledge.", "labels": [], "entities": [{"text": "statistical decision theory", "start_pos": 88, "end_pos": 115, "type": "TASK", "confidence": 0.6290246546268463}]}, {"text": "This is the goal of statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 20, "end_pos": 51, "type": "TASK", "confidence": 0.7435637513796488}]}, {"text": "The use of statistical techniques in machine translation has led to dramatic improvements in the quality of research systems in recent years.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.7491540908813477}]}, {"text": "For example, the statistical approaches of the Verbmobil evaluations (Wahlster 2000) or the U.S. National Institute of Standards and Technology (NIST)/TIDES MT evaluations 2001 through 2003 1 obtain the best results.", "labels": [], "entities": [{"text": "Verbmobil evaluations (Wahlster 2000)", "start_pos": 47, "end_pos": 84, "type": "DATASET", "confidence": 0.881941537062327}, {"text": "U.S. National Institute of Standards and Technology (NIST)/TIDES MT evaluations 2001", "start_pos": 92, "end_pos": 176, "type": "TASK", "confidence": 0.518687537738255}]}, {"text": "In addition, the field of statistical machine translation is rapidly progressing, and the quality of systems is getting better and better.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.760953962802887}]}, {"text": "An important factor in these improvements is definitely the availability of large amounts of data for training statistical models.", "labels": [], "entities": []}, {"text": "Yet the modeling, training, and search methods have also improved since the field of statistical machine translation was pioneered by IBM in the late 1980s and early 1990s (.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 85, "end_pos": 116, "type": "TASK", "confidence": 0.7014933824539185}]}, {"text": "This article focuses on an important improvement, namely, the use of (generalized) phrases instead of just single words as the core elements of the statistical translation model.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 148, "end_pos": 171, "type": "TASK", "confidence": 0.6876658201217651}]}, {"text": "We describe in Section 2 the basics of our statistical translation model.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 43, "end_pos": 66, "type": "TASK", "confidence": 0.7277173399925232}]}, {"text": "We suggest the use of a log-linear model to incorporate the various knowledge sources into an overall translation system and to perform discriminative training of the free model parameters.", "labels": [], "entities": []}, {"text": "This approach can be seen as a generalization of the originally suggested source-channel modeling framework for statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 112, "end_pos": 143, "type": "TASK", "confidence": 0.6857484877109528}]}, {"text": "In Section 3, we describe the statistical alignment models used to obtain a word alignment and techniques for learning phrase translations from word alignments.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 76, "end_pos": 90, "type": "TASK", "confidence": 0.7133274972438812}, {"text": "learning phrase translations from word alignments", "start_pos": 110, "end_pos": 159, "type": "TASK", "confidence": 0.729400098323822}]}, {"text": "Here, the term phrase just refers to a consecutive sequence of words occurring in text and has to be distinguished from the use of the term in a linguistic sense.", "labels": [], "entities": []}, {"text": "The learned bilingual phrases are not constrained by linguistic phrase boundaries.", "labels": [], "entities": []}, {"text": "Compared to the word-based statistical translation models in, this model is based on a (statistical) phrase lexicon instead of a single-word-based lexicon.", "labels": [], "entities": [{"text": "word-based statistical translation", "start_pos": 16, "end_pos": 50, "type": "TASK", "confidence": 0.6230666637420654}]}, {"text": "Looking at the results of the recent machine translation evaluations, this approach seems currently to give the best results, and an increasing number of researchers are working on different methods for learning phrase translation lexica for machine translation purposes.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.7791673541069031}, {"text": "learning phrase translation lexica", "start_pos": 203, "end_pos": 237, "type": "TASK", "confidence": 0.6962362080812454}, {"text": "machine translation", "start_pos": 242, "end_pos": 261, "type": "TASK", "confidence": 0.6901481300592422}]}, {"text": "Our approach to learning a phrase translation lexicon works in two stages: In the first stage, we compute an alignment between words, and in the second stage, we extract the aligned phrase pairs.", "labels": [], "entities": [{"text": "phrase translation lexicon", "start_pos": 27, "end_pos": 53, "type": "TASK", "confidence": 0.7906779944896698}]}, {"text": "In our machine translation system, we then use generalized versions of these phrases, called alignment templates, that also include the word alignment and use word classes instead of the words themselves.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 7, "end_pos": 26, "type": "TASK", "confidence": 0.7009323090314865}]}, {"text": "In Section 4, we describe the various components of the statistical translation model.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.7342839539051056}]}, {"text": "The backbone of the translation model is the alignment template feature function, which requires that a translation of anew sentence be composed of a set of alignment templates that covers the source sentence and the produced translation.", "labels": [], "entities": []}, {"text": "Other feature functions score the well-formedness of the produced target language sentence (i.e., language model feature functions), the number of produced words, or the order of the alignment templates.", "labels": [], "entities": []}, {"text": "Note that all components of our statistical machine translation model are purely data-driven and that there is no need for linguistically annotated corpora.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.6131316324075063}]}, {"text": "This is an important advantage compared to syntax-based translation models) that require a parser for source or target language.", "labels": [], "entities": []}, {"text": "In Section 5, we describe in detail our search algorithm and discuss an efficient implementation.", "labels": [], "entities": []}, {"text": "We use a dynamic-programming-based beam search algorithm that allows a trade-off between efficiency and quality.", "labels": [], "entities": [{"text": "beam search", "start_pos": 35, "end_pos": 46, "type": "TASK", "confidence": 0.7195083051919937}]}, {"text": "We also discuss the use of heuristic functions to reduce the number of search errors fora fixed beam size.", "labels": [], "entities": []}, {"text": "In Section 6, we describe various results obtained on different tasks.", "labels": [], "entities": []}, {"text": "For the German-English Verbmobil task, we analyze the effect of various system compo-", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2  Statistics for Verbmobil task: training corpus (Train), conventional dictionary (Lex),  development corpus (Dev), test corpus (Test) (Words*: words without punctuation marks).", "labels": [], "entities": [{"text": "conventional dictionary (Lex)", "start_pos": 66, "end_pos": 95, "type": "METRIC", "confidence": 0.8575965523719787}]}, {"text": " Table 3  Effect of alignment template length on translation quality.", "labels": [], "entities": [{"text": "translation", "start_pos": 49, "end_pos": 60, "type": "TASK", "confidence": 0.9587288498878479}]}, {"text": " Table 4  Effect of pruning parameter tp and heuristic function on search efficiency for direct-translation  model (Np = 50,000).", "labels": [], "entities": []}, {"text": " Table 5  Effect of pruning parameter tp and heuristic function on error rate for direct-translation model  (Np = 50,000).", "labels": [], "entities": [{"text": "error rate", "start_pos": 67, "end_pos": 77, "type": "METRIC", "confidence": 0.9613921344280243}]}, {"text": " Table 6  Effect of pruning parameter Np and heuristic function on search efficiency for  direct-translation model (tp = 10 \u221212 ).", "labels": [], "entities": []}, {"text": " Table 7  Effect of pruning parameter Np and heuristic function on error rate for direct-translation  model (tp = 10 \u221212 ).", "labels": [], "entities": [{"text": "error rate", "start_pos": 67, "end_pos": 77, "type": "METRIC", "confidence": 0.9550321996212006}]}, {"text": " Table 8  Effect of the length of the language model history (Unigram/Bigram/Trigram: word-based;  CLM: class-based 5-gram).", "labels": [], "entities": []}, {"text": " Table 9  Corpus statistics for Hansards task (Words*: words without punctuation marks).", "labels": [], "entities": [{"text": "Hansards", "start_pos": 32, "end_pos": 40, "type": "DATASET", "confidence": 0.748640775680542}]}, {"text": " Table 10  Translation results on the Hansards task.", "labels": [], "entities": [{"text": "Translation", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.951749861240387}, {"text": "Hansards task", "start_pos": 38, "end_pos": 51, "type": "DATASET", "confidence": 0.8707178235054016}]}, {"text": " Table 11  Corpus statistics for Chinese-English corpora-large data track (Words*: words without  punctuation marks).", "labels": [], "entities": []}]}