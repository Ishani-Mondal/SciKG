{"title": [{"text": "Squibs and Discussions The Kappa Statistic: A Second Look", "labels": [], "entities": [{"text": "Squibs and Discussions The Kappa Statistic", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7290374338626862}]}], "abstractContent": [{"text": "In recent years, the kappa coefficient of agreement has become the de facto standard for evaluating intercoder agreement for tagging tasks.", "labels": [], "entities": [{"text": "kappa coefficient of agreement", "start_pos": 21, "end_pos": 51, "type": "METRIC", "confidence": 0.7180150896310806}, {"text": "tagging tasks", "start_pos": 125, "end_pos": 138, "type": "TASK", "confidence": 0.8984066843986511}]}, {"text": "In this squib, we highlight issues that affect \u03ba and that the community has largely neglected.", "labels": [], "entities": []}, {"text": "First, we discuss the assumptions underlying different computations of the expected agreement component of \u03ba.", "labels": [], "entities": []}, {"text": "Second, we discuss how prevalence and bias affect the \u03ba measure.", "labels": [], "entities": [{"text": "prevalence", "start_pos": 23, "end_pos": 33, "type": "METRIC", "confidence": 0.9958795309066772}]}, {"text": "In the last few years, coded corpora have acquired an increasing importance in every aspect of human-language technology.", "labels": [], "entities": []}, {"text": "Tagging for many phenomena, such as dialogue acts (Carletta et al. 1997; Di Eugenio et al.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9706606864929199}]}, {"text": "2000), requires coders to make subtle distinctions among categories.", "labels": [], "entities": []}, {"text": "The objectivity of these decisions can be assessed by evaluating the reliability of the tagging, namely, whether the coders reach a satisfying level of agreement when they perform the same coding task.", "labels": [], "entities": []}, {"text": "Currently, the de facto standard for assessing intercoder agreement is the \u03ba coefficient, which factors out expected agreement (Cohen 1960; Krippendorff 1980).", "labels": [], "entities": [{"text": "\u03ba coefficient", "start_pos": 75, "end_pos": 88, "type": "METRIC", "confidence": 0.8911406993865967}]}, {"text": "\u03ba had long been used in content analysis and medicine (e.g., in psychiatry to assess how well stu-dents' diagnoses on a set of test cases agree with expert answers) (Grove et al. 1981).", "labels": [], "entities": [{"text": "content analysis", "start_pos": 24, "end_pos": 40, "type": "TASK", "confidence": 0.7182732075452805}]}, {"text": "Carletta (1996) deserves the credit for bringing \u03ba to the attention of computational linguists.", "labels": [], "entities": []}, {"text": "\u03ba is computed as P(A) \u2212 P(E) 1 \u2212 P(E) , where P(A) is the observed agreement among the coders, and P(E) is the expected agreement, that is, P(E) represents the probability that the coders agree by chance.", "labels": [], "entities": []}, {"text": "The values of \u03ba are constrained to the interval [\u22121, 1].", "labels": [], "entities": []}, {"text": "A \u03ba value of one means perfect agreement, a \u03ba value of zero means that agreement is equal to chance, and a \u03ba value of negative one means \"perfect\" disagreement.", "labels": [], "entities": []}, {"text": "This squib addresses two issues that have been neglected in the computational linguistics literature.", "labels": [], "entities": []}, {"text": "First, there are two main ways of computing P(E), the expected agreement, according to whether the distribution of proportions over the categories is taken to be equal for the coders (Scott 1955; Fleiss 1971; Krippendorff 1980; Siegel and Castellan 1988) or not (Cohen 1960).", "labels": [], "entities": []}, {"text": "Clearly, the two approaches reflect different conceptualizations of the problem.", "labels": [], "entities": []}, {"text": "We believe the distinction between the two is often glossed over because in practice the two computations of P(E) produce very similar outcomes inmost cases, especially for the highest values of \u03ba.", "labels": [], "entities": []}, {"text": "However, first, we will show that they can indeed result in different values of \u03ba, that we will call \u03ba Co (Cohen 1960) and \u03ba S&C (Siegel and Castellan 1988).", "labels": [], "entities": []}, {"text": "These different values can lead to contradictory conclusions on intercoder agreement.", "labels": [], "entities": []}, {"text": "Moreover, the assumption of *", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}