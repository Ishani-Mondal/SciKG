{"title": [{"text": "Named Entity Transliteration and Discovery from Multilingual Comparable Corpora", "labels": [], "entities": []}], "abstractContent": [{"text": "Named Entity recognition (NER) is an important part of many natural language processing tasks.", "labels": [], "entities": [{"text": "Named Entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7901738733053207}, {"text": "natural language processing tasks", "start_pos": 60, "end_pos": 93, "type": "TASK", "confidence": 0.7032062113285065}]}, {"text": "Most current approaches employ machine learning techniques and require supervised data.", "labels": [], "entities": []}, {"text": "However, many languages lack such resources.", "labels": [], "entities": []}, {"text": "This paper presents an algorithm to automatically discover Named Entities (NEs) in a resource free language, given a bilingual corpora in which it is weakly temporally aligned with a resource rich language.", "labels": [], "entities": []}, {"text": "We observe that NEs have similar time distributions across such corpora, and that they are often transliterated, and develop an algorithm that exploits both iteratively.", "labels": [], "entities": []}, {"text": "The algorithm makes use of anew, frequency based, metric for time distributions and a resource free discriminative approach to transliteration.", "labels": [], "entities": []}, {"text": "We evaluate the algorithm on an English-Russian corpus, and show high level of NEs discovery in Russian.", "labels": [], "entities": [{"text": "NEs discovery", "start_pos": 79, "end_pos": 92, "type": "TASK", "confidence": 0.8826775550842285}]}], "introductionContent": [{"text": "Named Entity recognition has been getting much attention in NLP research in recent years, since it is seen as a significant component of higher level NLP tasks such as information distillation and question answering, and an enabling technology for better information access.", "labels": [], "entities": [{"text": "Named Entity recognition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7071187297503153}, {"text": "information distillation", "start_pos": 168, "end_pos": 192, "type": "TASK", "confidence": 0.7360457926988602}, {"text": "question answering", "start_pos": 197, "end_pos": 215, "type": "TASK", "confidence": 0.7256316244602203}]}, {"text": "Most successful approaches to NER employ machine learning techniques, which require supervised training data.", "labels": [], "entities": [{"text": "NER", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.9886052012443542}]}, {"text": "However, for many languages, these resources do not exist.", "labels": [], "entities": []}, {"text": "Moreover, it is often difficult to find experts in these languages both for the expensive annotation effort and even for language specific clues.", "labels": [], "entities": []}, {"text": "On the other hand, comparable multilingual data (such as multilingual news streams) are increasingly available (see section 4).", "labels": [], "entities": []}, {"text": "In this work, we make two independent observations about Named Entities encountered in such corpora, and use them to develop an algorithm that extracts pairs of NEs across languages.", "labels": [], "entities": []}, {"text": "Specifically, given a bilingual corpora that is weakly temporally aligned, and a capability to annotate the text in one of the languages with NEs, our algorithm identifies the corresponding NEs in the second language text, and annotates them with the appropriate type, as in the source text.", "labels": [], "entities": []}, {"text": "The first observation is that NEs in one language in such corpora tend to co-occur with their counterparts in the other.", "labels": [], "entities": []}, {"text": "E.g., shows a histogram of the number of occurrences of the word Hussein and its Russian transliteration in our bilingual news corpus spanning years 2001 through late 2005.", "labels": [], "entities": []}, {"text": "One can see several common peaks in the two histograms, largest one being around the time of the beginning of the war in Iraq.", "labels": [], "entities": []}, {"text": "The word Russia, on the other hand, has a distinctly different temporal signature.", "labels": [], "entities": []}, {"text": "We can exploit such weak synchronicity of NEs across languages as away to associate them.", "labels": [], "entities": []}, {"text": "In order to score a pair of entities across languages, we compute the similarity of their time distributions.", "labels": [], "entities": [{"text": "similarity", "start_pos": 70, "end_pos": 80, "type": "METRIC", "confidence": 0.9785943031311035}]}, {"text": "The second observation is that NEs are often transliterated or have a common etymological origin across languages, and thus are phonetically similar.", "labels": [], "entities": []}, {"text": "shows an example list of NEs and their pos- sible Russian transliterations.", "labels": [], "entities": []}, {"text": "Approaches that attempt to use these two characteristics separately to identify NEs across languages would have significant shortcomings.", "labels": [], "entities": []}, {"text": "Transliteration based approaches require a good model, typically handcrafted or trained on a clean set of transliteration pairs.", "labels": [], "entities": []}, {"text": "On the other hand, time sequence similarity based approaches would incorrectly match words which happen to have similar time signatures (e.g. Taliban and Afghanistan in recent news).", "labels": [], "entities": []}, {"text": "We introduce an algorithm we call co-ranking which exploits these observations simultaneously to match NEs on one side of the bilingual corpus to their counterparts on the other.", "labels": [], "entities": []}, {"text": "We use a Discrete Fourier Transform based metric for computing similarity of time distributions, and we score NEs similarity with a linear transliteration model.", "labels": [], "entities": []}, {"text": "For a given NE in one language, the transliteration model chooses atop ranked list of candidates in another language.", "labels": [], "entities": []}, {"text": "Time sequence scoring is then used to re-rank the candidates and choose the one best temporally aligned with the NE.", "labels": [], "entities": [{"text": "Time sequence scoring", "start_pos": 0, "end_pos": 21, "type": "METRIC", "confidence": 0.8836180170377096}]}, {"text": "That is, we attempt to choose a candidate which is both a good transliteration (according to the current model) and is well aligned with the NE.", "labels": [], "entities": [{"text": "NE", "start_pos": 141, "end_pos": 143, "type": "DATASET", "confidence": 0.9006208777427673}]}, {"text": "Finally, pairs of NEs A major challenge inherent in discovering transliterated NEs is the fact that a single entity maybe represented by multiple transliteration strings.", "labels": [], "entities": []}, {"text": "One reason is language morphology.", "labels": [], "entities": []}, {"text": "For example, in Russian, depending on a case being used, the same noun may appear with various endings.", "labels": [], "entities": []}, {"text": "Another reason is the lack of transliteration standards.", "labels": [], "entities": []}, {"text": "Again, in Russian, several possible transliterations of an English entity maybe acceptable, as long as they are phonetically similar to the source.", "labels": [], "entities": []}, {"text": "Thus, in order to rely on the time sequences we obtain, we need to be able to group variants of the same NE into an equivalence class, and collect their aggregate mention counts.", "labels": [], "entities": []}, {"text": "We would then score time sequences of these equivalence classes.", "labels": [], "entities": []}, {"text": "For instance, we would like to count the aggregate number of occurrences of Herzegovina, Hercegovina\u00a1 on the English side in order to map it accurately to the equivalence class of that NE's variants we may see on the Russian side of our corpus (e.g. One of the objectives for this work was to use as little of the knowledge of both languages as possible.", "labels": [], "entities": []}, {"text": "In order to effectively rely on the quality of time sequence scoring, we used a simple, knowledge poor approach to group NE variants for Russian.", "labels": [], "entities": [{"text": "time sequence scoring", "start_pos": 47, "end_pos": 68, "type": "TASK", "confidence": 0.5644426941871643}]}, {"text": "In the rest of the paper, whenever we refer to a Named Entity, we imply an NE equivalence class.", "labels": [], "entities": []}, {"text": "Note that although we expect that better use of language specific knowledge would improve the results, it would defeat one of the goals of this work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We ran experiments using a bilingual comparable English-Russian news corpus we built by crawling a Russian news website (www.lenta.ru).", "labels": [], "entities": []}, {"text": "The site provides loose translations of (and pointers to) the original English texts.", "labels": [], "entities": []}, {"text": "We collected pairs of articles spanning from 1/1/2001 through 12/24/2004.", "labels": [], "entities": [{"text": "1/1/2001 through 12/24/2004", "start_pos": 45, "end_pos": 72, "type": "DATASET", "confidence": 0.7386702949350531}]}, {"text": "The corpus consists of 2,022 documents with 0-8 documents per day.", "labels": [], "entities": []}, {"text": "The corpus is available on our web page at http://L2R.cs.uiuc.edu/U cogcomp/.", "labels": [], "entities": []}, {"text": "The English side was tagged with a publicly available NER system based on the SNoW learning architecture, that is available at the same site.", "labels": [], "entities": []}, {"text": "This set of English NEs was hand-pruned to remove incorrectly classified words to obtain 978 single word NEs.", "labels": [], "entities": []}, {"text": "In order to reduce running time, some limited preprocessing was done on the Russian side.", "labels": [], "entities": [{"text": "preprocessing", "start_pos": 46, "end_pos": 59, "type": "METRIC", "confidence": 0.9773113131523132}]}, {"text": "All classes, whose temporal distributions were close to uniform (i.e. words with a similar likelihood of occurrence throughout the corpus) were deemed common and not considered as NE candidates.", "labels": [], "entities": []}, {"text": "Unique words were grouped into 15,594 equivalence classes, and 1,605 of those classes were discarded using this method.", "labels": [], "entities": []}, {"text": "Insertions/omissions features were not used in the experiments as they provided no tangible benefit for the languages of our corpus.", "labels": [], "entities": [{"text": "Insertions", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9006693959236145}]}, {"text": "Unless mentioned otherwise, the transliteration model was initialized with a subset of 254 pairs of NEs and their transliteration equivalence classes.", "labels": [], "entities": []}, {"text": "Negative examples here and during the rest of the training were pairs of randomly selected non-NE English and Russian words.", "labels": [], "entities": []}, {"text": "In each iteration, we used the current transliter- ation model to find a list of 30 best transliteration equivalence classes for each NE.", "labels": [], "entities": []}, {"text": "We then computed time sequence similarity score between NE and each class from its list to find the one with the best matching time sequence.", "labels": [], "entities": [{"text": "time sequence similarity score", "start_pos": 17, "end_pos": 47, "type": "METRIC", "confidence": 0.8590870946645737}]}, {"text": "If its similarity score surpassed a set threshold, it was added to the list of positive examples for the next round of training.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 7, "end_pos": 23, "type": "METRIC", "confidence": 0.9785102009773254}]}, {"text": "Positive examples were constructed by pairing each English NE with each of the transliterations from the best equivalence class that surpasses the threshold.", "labels": [], "entities": []}, {"text": "We used the same number of positive and negative examples.", "labels": [], "entities": []}, {"text": "For evaluation, random 727 of the total of 978 NE pairs matched by the algorithm were selected and checked by a language expert.", "labels": [], "entities": []}, {"text": "Accuracy was computed as the percentage of those NEs correctly discovered by the algorithm.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9963198900222778}]}, {"text": "shows the proportion of correctly discovered NE transliteration equivalence classes throughout the run of the algorithm.", "labels": [], "entities": []}, {"text": "The figure also shows the accuracy if transliterations are selected according to the current transliteration model (top scoring candidate) and sequence matching alone.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9995080232620239}]}, {"text": "The transliteration model alone achieves an accuracy of about 47%, while the time sequence alone gets about 41%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9996194839477539}]}, {"text": "The combined algorithm achieves about 66%, giving a significant improvement.", "labels": [], "entities": []}], "tableCaptions": []}