{"title": [{"text": "Comparing the Utility of State Features in Spoken Dialogue Using Reinforcement Learning", "labels": [], "entities": []}], "abstractContent": [{"text": "Recent work in designing spoken dialogue systems has focused on using Reinforcement Learning to automatically learn the best action fora system to take at any point in the dialogue to maximize dialogue success.", "labels": [], "entities": []}, {"text": "While policy development is very important, choosing the best features to model the user state is equally important since it impacts the actions a system should make.", "labels": [], "entities": []}, {"text": "In this paper, we compare the relative utility of adding three features to a model of user state in the domain of a spoken dialogue tutoring system.", "labels": [], "entities": []}, {"text": "In addition, we also look at the effects of these features on what type of a question a tutoring system should ask at any state and compare it with our previous work on using feedback as the system action.", "labels": [], "entities": []}], "introductionContent": [{"text": "A host of issues confront spoken dialogue system designers, such as choosing the best system action to perform given any user state, and also selecting the right features to best represent the user state.", "labels": [], "entities": []}, {"text": "While recent work has focused on using Reinforcement Learning (RL) to address the first issue (such as,), (), there has been very little empirical work on the issue of feature selection in prior RL approaches to dialogue systems.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 168, "end_pos": 185, "type": "TASK", "confidence": 0.6993198990821838}]}, {"text": "In this paper, we use a corpus of dialogues of humans interacting with a spoken dialogue tutoring system to show the comparative utility of adding the three features of concept repetition, frustration level, and student performance.", "labels": [], "entities": []}, {"text": "These features are not just unique to the tutoring domain but are important to dialogue systems in general.", "labels": [], "entities": []}, {"text": "Our empirical results show that these features all lead to changes in what action the system should take, with concept repetition and frustration having the largest effects.", "labels": [], "entities": [{"text": "concept repetition", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.7130748629570007}]}, {"text": "This paper extends our previous work) which first presented a methodology for exploring whether adding more complex features to a representation of student state will beneficially alter tutor actions with respect to feedback.", "labels": [], "entities": []}, {"text": "Here we present an empirical method of comparing the effects of each feature while also generalizing our findings to a different action choice of what type of follow-up question should a tutor ask the student (as opposed to what type of feedback should the tutor give).", "labels": [], "entities": []}, {"text": "In complex domains such as tutoring, testing different policies with real or simulated students can be time consuming and costly so it is important to properly choose the best features before testing, which this work allows us to do.", "labels": [], "entities": []}, {"text": "This in turn aids our long-term goal of improving a spoken dialogue system that can effectively adapt to a student to maximize their learning.", "labels": [], "entities": []}], "datasetContent": [{"text": "The goal of this study is to quantify the utility of adding a feature to a baseline state space.", "labels": [], "entities": []}, {"text": "We use the following four step process: (1) establish an action set and reward function to be used as constants throughout the test since the state space is the one MDP parameter that will be changed during the tests; (2) establish a baseline state and policy, and (3) add anew feature to that state and test if adding the feature results in policy changes.", "labels": [], "entities": []}, {"text": "Every time we create anew state, we make sure that the generated V-values converge.", "labels": [], "entities": []}, {"text": "Finally, (4), we evaluate the effects of adding anew feature by using three metrics: (1) number of policy changes (diffs), (2) % policy change, and (3) Expected Cumulative Reward.", "labels": [], "entities": [{"text": "number of policy changes (diffs)", "start_pos": 89, "end_pos": 121, "type": "METRIC", "confidence": 0.8637934412275042}, {"text": "Expected Cumulative Reward", "start_pos": 152, "end_pos": 178, "type": "METRIC", "confidence": 0.8825035889943441}]}, {"text": "These three metrics are discussed in more detail in Section 5.2.", "labels": [], "entities": []}, {"text": "In this section we focus on the first three steps of the methodology.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4. The second and  third columns show the original baseline states and  their policies. The next column shows the new pol- icy when splitting the original state into the three  new states based on certainty (with the policies that  differ from the baseline shown in bold). The final  column shows the size of each new state. So the  first row indicates that if the student is correct and  certain, one should give a combination of a complex  and short answer question; if the student is correct  and neutral, just ask a SAQ; and else if the student is  correct and uncertain, give a Mix. The overall trend  of adding the certainty feature is that if the student  exhibits some emotion (either they are certain or un- certain), the best response is Mix, but for neutral do  something else.", "labels": [], "entities": [{"text": "pol- icy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9022564093271891}, {"text": "Mix", "start_pos": 755, "end_pos": 758, "type": "METRIC", "confidence": 0.992384135723114}]}, {"text": " Table 4: Baseline 2 Policy", "labels": [], "entities": []}, {"text": " Table 6: Question Act Results", "labels": [], "entities": [{"text": "Question Act", "start_pos": 10, "end_pos": 22, "type": "DATASET", "confidence": 0.8030693233013153}]}]}