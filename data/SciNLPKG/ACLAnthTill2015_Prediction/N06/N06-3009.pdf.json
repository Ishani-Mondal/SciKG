{"title": [{"text": "A Hybrid Approach to Biomedical Named Entity Recognition and Semantic Role Labeling", "labels": [], "entities": [{"text": "Biomedical Named Entity Recognition", "start_pos": 21, "end_pos": 56, "type": "TASK", "confidence": 0.7551788240671158}, {"text": "Semantic Role Labeling", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.6437629560629526}]}], "abstractContent": [{"text": "In this paper, we describe our hybrid approach to two key NLP technologies: biomedical named entity recognition (Bio-NER) and (Bio-SRL).", "labels": [], "entities": [{"text": "biomedical named entity recognition", "start_pos": 76, "end_pos": 111, "type": "TASK", "confidence": 0.59690260887146}]}, {"text": "In Bio-NER, our system successfully integrates linguistic features into the CRF framework.", "labels": [], "entities": []}, {"text": "In addition, we employ web lexicons and template-based post-processing to further boost its performance.", "labels": [], "entities": []}, {"text": "Through these broad linguistic features and the nature of CRF, our system outperforms state-of-the-art machine-learning-based systems, especially in the recognition of protein names (F=78.5%).", "labels": [], "entities": [{"text": "recognition of protein names", "start_pos": 153, "end_pos": 181, "type": "TASK", "confidence": 0.8556536138057709}, {"text": "F", "start_pos": 183, "end_pos": 184, "type": "METRIC", "confidence": 0.997677743434906}]}, {"text": "In Bio-SRL, first, we construct a proposition bank on top of the popular biomedical GENIA treebank following the PropBank annotation scheme.", "labels": [], "entities": [{"text": "GENIA treebank", "start_pos": 84, "end_pos": 98, "type": "DATASET", "confidence": 0.8882348835468292}, {"text": "PropBank annotation scheme", "start_pos": 113, "end_pos": 139, "type": "DATASET", "confidence": 0.8834969401359558}]}, {"text": "We only annotate the predicate-argument structures (PAS's) of thirty frequently used biomedical verbs (predicates) and their corresponding arguments.", "labels": [], "entities": []}, {"text": "Second, we use our proposition bank to train a biomedical SRL system, which uses a maximum entropy (ME) machine-learning model.", "labels": [], "entities": [{"text": "SRL", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.7897660136222839}]}, {"text": "Thirdly, we automatically generate argument-type templates, which can be used to improve classification of biomedical argument roles.", "labels": [], "entities": [{"text": "classification of biomedical argument roles", "start_pos": 89, "end_pos": 132, "type": "TASK", "confidence": 0.7947903394699096}]}, {"text": "Our experimental results show that a newswire Eng-lish SRL system that achieves an F-score of 86.29% in the newswire English domain can maintain an F-score of 64.64% when ported to the biomedical domain.", "labels": [], "entities": [{"text": "F-score", "start_pos": 83, "end_pos": 90, "type": "METRIC", "confidence": 0.9990689158439636}, {"text": "F-score", "start_pos": 148, "end_pos": 155, "type": "METRIC", "confidence": 0.9989497065544128}]}, {"text": "By using our annotated biomedical corpus, we can increase that F-score by 22.9%.", "labels": [], "entities": [{"text": "F-score", "start_pos": 63, "end_pos": 70, "type": "METRIC", "confidence": 0.997837245464325}]}, {"text": "Adding automatically generated template features further increases overall F-score by 0.47% and adjunct (AM) F-score by 1.57%, respectively.", "labels": [], "entities": [{"text": "F-score", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.9966422319412231}, {"text": "adjunct (AM) F-score", "start_pos": 96, "end_pos": 116, "type": "METRIC", "confidence": 0.6838954091072083}]}], "introductionContent": [{"text": "The volume of biomedical literature available on the Web has experienced unprecedented growth in recent years, and demand for efficient methods to process this material has increased accordingly.", "labels": [], "entities": []}, {"text": "Lately, there has been a surge of interest in mining biomedical literature.", "labels": [], "entities": []}, {"text": "To this end, more and more information extraction (IE) systems using natural language processing (NLP) technologies have been developed for use in the biomedical field.", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 27, "end_pos": 54, "type": "TASK", "confidence": 0.8624093651771545}]}, {"text": "Key biomedical IE tasks include named entity (NE) recognition (NER), such as the recognition of protein and gene names; and relation extraction, such as the extraction of protein-protein and gene-gene interactions.", "labels": [], "entities": [{"text": "IE", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.7738679647445679}, {"text": "named entity (NE) recognition (NER)", "start_pos": 32, "end_pos": 67, "type": "TASK", "confidence": 0.75649979379442}, {"text": "recognition of protein and gene names", "start_pos": 81, "end_pos": 118, "type": "TASK", "confidence": 0.763632575670878}, {"text": "relation extraction", "start_pos": 124, "end_pos": 143, "type": "TASK", "confidence": 0.8439751267433167}, {"text": "extraction of protein-protein and gene-gene interactions", "start_pos": 157, "end_pos": 213, "type": "TASK", "confidence": 0.7751567562421163}]}, {"text": "NER identifies named entities from natural language texts and classifies them into specific classes according to a defined ontology or classification.", "labels": [], "entities": [{"text": "NER identifies named entities from natural language texts", "start_pos": 0, "end_pos": 57, "type": "TASK", "confidence": 0.8203674703836441}]}, {"text": "In general, biomedical NEs do not follow any nomenclature and may comprise long compound words and short abbreviations.", "labels": [], "entities": [{"text": "biomedical NEs", "start_pos": 12, "end_pos": 26, "type": "TASK", "confidence": 0.7172127068042755}]}, {"text": "Some NEs contain various symbols and other spelling variations.", "labels": [], "entities": []}, {"text": "On average, an NE has five synonyms, and it may belong to multiple categories intrinsically.", "labels": [], "entities": []}, {"text": "Since biomedical language and vo-cabulary are highly complex and evolving rapidly, Bio-NER is a very challenging problem, which raises a number of difficulties.", "labels": [], "entities": []}, {"text": "The other main focus of Bio-IE is relation extraction.", "labels": [], "entities": [{"text": "Bio-IE", "start_pos": 24, "end_pos": 30, "type": "TASK", "confidence": 0.728807806968689}, {"text": "relation extraction", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.9203863143920898}]}, {"text": "Most systems only extract the relation targets (e.g., proteins, genes) and the verbs representing those relations, overlooking the many adverbial and prepositional phrases and words that describe location, manner, timing, condition, and extent.", "labels": [], "entities": []}, {"text": "However, the information in such phrases maybe important for precise definition and clarification of complex biological relations.", "labels": [], "entities": []}, {"text": "This problem can be tackled by using semantic role labeling (SRL) because it not only recognizes main roles, such as agents and objects, but also extracts adjunct roles such as location, manner, timing, condition, and extent.", "labels": [], "entities": [{"text": "semantic role labeling (SRL)", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.7887978752454122}, {"text": "extent", "start_pos": 218, "end_pos": 224, "type": "METRIC", "confidence": 0.9638405442237854}]}, {"text": "() has demonstrated that full-parsing and SRL can improve the performance of relation extraction, resulting in an F-score increase of 15% (from 67% to 82%).", "labels": [], "entities": [{"text": "SRL", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.8279808163642883}, {"text": "relation extraction", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.8730722367763519}, {"text": "F-score increase", "start_pos": 114, "end_pos": 130, "type": "METRIC", "confidence": 0.9853761792182922}]}, {"text": "This significant result leads us to surmise that SRL may also have potential for relation extraction in the biomedical domain.", "labels": [], "entities": [{"text": "SRL", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.972979724407196}, {"text": "relation extraction", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.9000793397426605}]}, {"text": "Unfortunately, no SRL system for the biomedical domain exists.", "labels": [], "entities": [{"text": "SRL", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.9247621297836304}]}, {"text": "In this paper, we tackle the problems of both biomedical SRL and NER.", "labels": [], "entities": [{"text": "biomedical SRL", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.62051922082901}, {"text": "NER", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.9007389545440674}]}, {"text": "Our contributions are (1) employing web lexicons and template-based postprocessing to boost the performance of Bio-NER; (2) constructing a proposition bank on top of the popular biomedical GENIA treebank following the PropBank annotation scheme and developing a Biomedical SRL system.", "labels": [], "entities": [{"text": "GENIA treebank", "start_pos": 189, "end_pos": 203, "type": "DATASET", "confidence": 0.8331089019775391}, {"text": "Biomedical SRL", "start_pos": 262, "end_pos": 276, "type": "TASK", "confidence": 0.5979410111904144}]}, {"text": "We adapt an SRL system trained the World Street Journal (WSJ) corpus to the biomedical domain.", "labels": [], "entities": [{"text": "World Street Journal (WSJ) corpus", "start_pos": 35, "end_pos": 68, "type": "DATASET", "confidence": 0.9779773950576782}]}, {"text": "On adjunct arguments, especially those relevant to the biomedical domain, the performance is unsatisfactory.", "labels": [], "entities": []}, {"text": "We, therefore, develop automatically generated templates for identifying these arguments.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform 10-fold cross validation on the GENIA V3.02 corpus) to compare our CRF-based system with other biomedical NER systems.", "labels": [], "entities": [{"text": "GENIA V3.02 corpus", "start_pos": 43, "end_pos": 61, "type": "DATASET", "confidence": 0.9699605902036031}]}, {"text": "The experimental results are reported in.", "labels": [], "entities": []}, {"text": "Our system outperforms other systems in protein names by an F-score of at least 2.6%.", "labels": [], "entities": [{"text": "F-score", "start_pos": 60, "end_pos": 67, "type": "METRIC", "confidence": 0.9995740056037903}]}, {"text": "For DNA names, our performance is very close to that of the best system.", "labels": [], "entities": []}, {"text": "Our experimental results show that a newswire English SRL system that achieves an F-score of 86.29% can maintain an F-score of 64.64% when ported to the biomedical domain.", "labels": [], "entities": [{"text": "F-score", "start_pos": 82, "end_pos": 89, "type": "METRIC", "confidence": 0.999316930770874}, {"text": "F-score", "start_pos": 116, "end_pos": 123, "type": "METRIC", "confidence": 0.9990288019180298}]}, {"text": "By using SE-ROW, we can increase that F-score by 22.9%.", "labels": [], "entities": [{"text": "SE-ROW", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.9811269640922546}, {"text": "F-score", "start_pos": 38, "end_pos": 45, "type": "METRIC", "confidence": 0.9984331727027893}]}, {"text": "Adding automatically generated template features further increases overall F-score by 0.47% and adjunct (AM) F-score by 1.57%, respectively.", "labels": [], "entities": [{"text": "F-score", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.9966422319412231}, {"text": "adjunct (AM) F-score", "start_pos": 96, "end_pos": 116, "type": "METRIC", "confidence": 0.6838953852653503}]}], "tableCaptions": [{"text": " Table 1. Our system outperforms other  systems in protein names by an F-score of at least  2.6%. For DNA names, our performance is very  close to that of the best system.", "labels": [], "entities": [{"text": "F-score", "start_pos": 71, "end_pos": 78, "type": "METRIC", "confidence": 0.999420166015625}]}, {"text": " Table 1. Performance of protein and DNA name  recognition on the GENIA V3.02 corpus", "labels": [], "entities": [{"text": "protein and DNA name  recognition", "start_pos": 25, "end_pos": 58, "type": "TASK", "confidence": 0.6595109403133392}, {"text": "GENIA V3.02 corpus", "start_pos": 66, "end_pos": 84, "type": "DATASET", "confidence": 0.9692750374476115}]}]}