{"title": [{"text": "Museli: A Multi-Source Evidence Integration Approach to Topic Seg- mentation of Spontaneous Dialogue", "labels": [], "entities": [{"text": "Topic Seg- mentation of Spontaneous Dialogue", "start_pos": 56, "end_pos": 100, "type": "TASK", "confidence": 0.7340893915721348}]}], "abstractContent": [{"text": "We introduce a novel topic segmentation approach that combines evidence of topic shifts from lexical cohesion with linguistic evidence such as syntactically distinct features of segment initial contributions.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.7278822064399719}]}, {"text": "Our evaluation demonstrates that this hybrid approach outperforms state-of-the-art algorithms even when applied to loosely struc-tured, spontaneous dialogue.", "labels": [], "entities": []}], "introductionContent": [{"text": "Use of topic-based models of dialogue has played a role in information retrieval (), information extraction, and summarization.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 59, "end_pos": 80, "type": "TASK", "confidence": 0.7800259292125702}, {"text": "information extraction", "start_pos": 85, "end_pos": 107, "type": "TASK", "confidence": 0.8803580403327942}, {"text": "summarization", "start_pos": 113, "end_pos": 126, "type": "TASK", "confidence": 0.9937815070152283}]}, {"text": "However, previous work on automatic topic segmentation has focused primarily on segmentation of expository text.", "labels": [], "entities": [{"text": "automatic topic segmentation", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.6015712022781372}]}, {"text": "We present Museli, a novel topic segmentation approach for dialogue that integrates evidence of topic shifts from lexical cohesion with linguistic indicators such as syntactically distinct features of segment initial contributions.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.7624693214893341}]}, {"text": "Our evaluation demonstrates that approaches designed for text do not generalize well to dialogue.", "labels": [], "entities": []}, {"text": "We demonstrate a significant advantage of Museli over competing approaches.", "labels": [], "entities": []}, {"text": "We then discuss why models based entirely on lexical cohesion fail on dialogue and how our algorithm compensates with other topic shift indicators.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we evaluate Museli in comparison to the best performing state-of-the-art approaches, demonstrating that our hybrid Museli approach out-performs all of these approaches on two different dialogue corpora by a statistically significant margin (p < .01), in one case reducing the probability of error as measured by Beeferman's P k to only 10% ().", "labels": [], "entities": []}, {"text": "We used two different dialogue corpora for our evaluation.", "labels": [], "entities": []}, {"text": "The first corpus, which we refer to as the Olney & Cai corpus, is a set of dialogues selected randomly from the same corpus Olney and Cai selected their corpus from).", "labels": [], "entities": [{"text": "Olney & Cai corpus", "start_pos": 43, "end_pos": 61, "type": "DATASET", "confidence": 0.8732948303222656}]}, {"text": "The second corpus is a locally collected corpus of thermodynamics tutoring dialogues, which we refer to as the Thermo corpus.", "labels": [], "entities": [{"text": "Thermo corpus", "start_pos": 111, "end_pos": 124, "type": "DATASET", "confidence": 0.7929470539093018}]}, {"text": "This corpus is particularly appropriate for addressing the research question of how to automatically segment dialogue for two reasons: First, the exploratory task that students and tutors engaged in together is more loosely structured than many task oriented domains typically investigated in the dialogue community, such as flight reservation or meeting scheduling.", "labels": [], "entities": [{"text": "flight reservation or meeting scheduling", "start_pos": 325, "end_pos": 365, "type": "TASK", "confidence": 0.6947115242481232}]}, {"text": "Second, because the tutor and student play asymmetric roles in the interaction, this corpus allows us to explore how conversational role affects how speakers mark topic shifts.", "labels": [], "entities": []}, {"text": "presents statistics describing characteristics of these two corpora.", "labels": [], "entities": []}, {"text": "Similar to (, we adopt a flat model of topicsegmentation for our gold standard based on discourse segment purpose, where a shift in topic corresponds to a shift in purpose that is acknowledged and acted upon by both conversational agents.", "labels": [], "entities": []}, {"text": "We evaluated inter-coder reliability over 10% of the Thermo corpus mentioned above.", "labels": [], "entities": [{"text": "Thermo corpus", "start_pos": 53, "end_pos": 66, "type": "DATASET", "confidence": 0.9729028344154358}]}, {"text": "3 annotators were given a 10 page coding manual with explanation of our informal definition of shared discourse segment purpose as well as examples of segmented dialogues.", "labels": [], "entities": []}, {"text": "Pairwise inter-coder agreement was above 0.7 kappa for all pairs of annotators.", "labels": [], "entities": [{"text": "Pairwise inter-coder agreement", "start_pos": 0, "end_pos": 30, "type": "METRIC", "confidence": 0.6886693239212036}]}], "tableCaptions": [{"text": " Table 1: Evaluation Corpora Statistics", "labels": [], "entities": []}, {"text": " Table 2: Results on both corpora", "labels": [], "entities": []}]}