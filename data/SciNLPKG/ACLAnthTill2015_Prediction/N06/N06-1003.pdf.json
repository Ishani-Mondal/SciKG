{"title": [{"text": "Improved Statistical Machine Translation Using Paraphrases", "labels": [], "entities": [{"text": "Improved Statistical Machine Translation", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.8672842085361481}, {"text": "Paraphrases", "start_pos": 47, "end_pos": 58, "type": "TASK", "confidence": 0.4748711884021759}]}], "abstractContent": [{"text": "Parallel corpora are crucial for training SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.947224497795105}]}, {"text": "However, for many language pairs they are available only in very limited quantities.", "labels": [], "entities": []}, {"text": "For these language pairs a huge portion of phrases encountered at run-time will be unknown.", "labels": [], "entities": []}, {"text": "We show how techniques from paraphrasing can be used to deal with these otherwise unknown source language phrases.", "labels": [], "entities": []}, {"text": "Our results show that augmenting a state-of-the-art SMT system with paraphrases leads to significantly improved coverage and translation quality.", "labels": [], "entities": [{"text": "SMT", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.98943030834198}]}, {"text": "For a training corpus with 10,000 sentence pairs we increase the coverage of unique test set un-igrams from 48% to 90%, with more than half of the newly covered items accurately translated, as opposed to none in current approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "As with many other statistical natural language processing tasks, statistical machine translation () produces high quality results when ample training data is available.", "labels": [], "entities": [{"text": "statistical natural language processing", "start_pos": 19, "end_pos": 58, "type": "TASK", "confidence": 0.6204356923699379}, {"text": "statistical machine translation", "start_pos": 66, "end_pos": 97, "type": "TASK", "confidence": 0.6863853732744852}]}, {"text": "This is problematic for so called \"low density\" language pairs which do not have very large parallel corpora.", "labels": [], "entities": []}, {"text": "For example, when words occur infrequently in a parallel corpus parameter estimates for word-level alignments can be inaccurate, which can in turn lead to inaccurate phrase translations.", "labels": [], "entities": [{"text": "phrase translations", "start_pos": 166, "end_pos": 185, "type": "TASK", "confidence": 0.7564831674098969}]}, {"text": "Limited amounts of training data can further lead to a problem of low coverage in that many phrases encountered at run-time are not observed in the training data and therefore their translations will not be learned.", "labels": [], "entities": [{"text": "coverage", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9899078607559204}]}, {"text": "Here we address the problem of unknown phrases.", "labels": [], "entities": []}, {"text": "Specifically we show that upon encountering an unknown source phrase, we can substitute a paraphrase for it and then proceed using the translation of that paraphrase.", "labels": [], "entities": []}, {"text": "We derive these paraphrases from resources that are external to the parallel corpus that the translation model is trained from, and we are able to exploit (potentially more abundant) parallel corpora from other language pairs to do so.", "labels": [], "entities": []}, {"text": "In this paper we: \u2022 Define a method for incorporating paraphrases of unseen source phrases into the statistical machine translation process.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 100, "end_pos": 131, "type": "TASK", "confidence": 0.6318792502085367}]}, {"text": "\u2022 Show that by translating paraphrases we achieve a marked improvement in coverage and translation quality, especially in the case of unknown words which to date have been left untranslated.", "labels": [], "entities": [{"text": "coverage", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9571154713630676}, {"text": "translation", "start_pos": 87, "end_pos": 98, "type": "TASK", "confidence": 0.9434177279472351}]}, {"text": "\u2022 Argue that while we observe an improvement in Bleu score, this metric is particularly poorly suited to measuring the sort of improvements that we achieve.", "labels": [], "entities": [{"text": "Argue", "start_pos": 2, "end_pos": 7, "type": "METRIC", "confidence": 0.9856359958648682}, {"text": "Bleu score", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9761210381984711}]}, {"text": "\u2022 Present an alternative methodology for targeted manual evaluation that maybe useful in other research projects.", "labels": [], "entities": []}], "datasetContent": [{"text": "We examined the application of paraphrases to deal with unknown phrases when translating from Spanish and French into English.", "labels": [], "entities": []}, {"text": "We used the publicly available Europarl multilingual parallel corpus) to create six training corpora for the two language pairs, and used the standard Europarl development and test sets.", "labels": [], "entities": [{"text": "Europarl multilingual parallel corpus", "start_pos": 31, "end_pos": 68, "type": "DATASET", "confidence": 0.8749279081821442}, {"text": "Europarl development and test sets", "start_pos": 151, "end_pos": 185, "type": "DATASET", "confidence": 0.888657557964325}]}, {"text": "We evaluated the efficacy of using paraphrases in three ways: by calculating the Bleu score for the translated output, by measuring the increase in coverage when including paraphrases, and through a targeted manual evaluation of the phrasal translations of unseen phrases to determine how many of the newly covered phrases were accurately translated.", "labels": [], "entities": [{"text": "Bleu score", "start_pos": 81, "end_pos": 91, "type": "METRIC", "confidence": 0.9537736177444458}, {"text": "coverage", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.9685395359992981}]}, {"text": "Although Bleu is currently the standard metric for MT evaluation, we believe that it may not meaningfully measure translation improvements in our setup.", "labels": [], "entities": [{"text": "Bleu", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.9976229071617126}, {"text": "MT evaluation", "start_pos": 51, "end_pos": 64, "type": "TASK", "confidence": 0.9635377526283264}]}, {"text": "By substituting a paraphrase for an unknown source phrase there is a strong chance that its translation may also be a paraphrase of the equivalent target language phrase.", "labels": [], "entities": []}, {"text": "Bleu relies on exact matches of n-grams in a reference translation.", "labels": [], "entities": []}, {"text": "Thus if our translation is a paraphrase of the reference, Bleu will fail to score it correctly.", "labels": [], "entities": [{"text": "Bleu", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.7688863277435303}]}, {"text": "Because Bleu is potentially insensitive to the type of changes that we were making to the translations, we additionally performed a focused manual evaluation).", "labels": [], "entities": [{"text": "Bleu", "start_pos": 8, "end_pos": 12, "type": "DATASET", "confidence": 0.609787106513977}]}, {"text": "To do this, had bilingual speakers create word-level alignments for the first 150 and 250 sentence in the Spanish-English and French-English test corpora, as shown in.", "labels": [], "entities": []}, {"text": "We were able to use these alignments to extract the translations of the Spanish and French words that we were applying our paraphrase method to.", "labels": [], "entities": []}, {"text": "Knowing this correspondence between foreign phrases and their English counterparts allowed us to directly analyze whether translations that were being produced from paraphrases remained faithful to the meaning of the reference translation.", "labels": [], "entities": []}, {"text": "When proThe article combats discrimination and inequality in the treatment of citizens for the reasons listed therein.", "labels": [], "entities": []}, {"text": "The article combats discrimination and the different treatment of citizens for the reasons mentioned in the same.", "labels": [], "entities": []}, {"text": "The article fights against uneven and the treatment of citizens for the reasons enshrined in the same.", "labels": [], "entities": []}, {"text": "The article is countering discrimination and the unequal treatment of citizens for the reasons that in the same.", "labels": [], "entities": []}, {"text": "ducing our translations using the Pharaoh decoder we employed its \"trace\" facility, which tells which source sentence span each target phrase was derived from.", "labels": [], "entities": []}, {"text": "This allowed us to identify which elements in the machine translated output corresponded to the paraphrased foreign phrase.", "labels": [], "entities": []}, {"text": "We asked a monolingual judge whether the phrases in the machine translated output had the same meaning as of the reference phrase.", "labels": [], "entities": []}, {"text": "In addition to judging the accuracy of 100 phrases for each of the translated sets, we measured how much our paraphrase method increased the coverage of the translation system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9989429116249084}]}, {"text": "Because we focus on words that the system was previously unable to translate, the increase in coverage and the translation quality of the newly covered phrases are the two most relevant indicators as to the efficacy of the method.", "labels": [], "entities": [{"text": "coverage", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9928209185600281}]}, {"text": "We performed a manual evaluation by judging the accuracy of phrases for 100 paraphrased translations from each of the sets using the manual word alignments.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9988429546356201}]}, {"text": "1 gives the percentage of time that each of the translations of paraphrases were judged to have the same meaning as the equivalent target phrase.", "labels": [], "entities": []}, {"text": "In the case of the translations of single word paraphrases for the Spanish accuracy ranged from just below 50% to just below 70%.", "labels": [], "entities": [{"text": "translations of single word paraphrases", "start_pos": 19, "end_pos": 58, "type": "TASK", "confidence": 0.8506862998008728}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.995846688747406}]}, {"text": "This number is impressive in light of the fact that none of those items are correctly translated in the baseline model, which simply inserts the foreign language word.", "labels": [], "entities": []}, {"text": "As with the Bleu scores, the translations of multi-word paraphrases were judged to be more accurate than the translations of single word paraphrases.", "labels": [], "entities": [{"text": "Bleu scores", "start_pos": 12, "end_pos": 23, "type": "DATASET", "confidence": 0.878320187330246}]}, {"text": "In performing the manual evaluation we were additionally able to determine how often Bleu was capable of measuring an actual improvement in translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 140, "end_pos": 151, "type": "TASK", "confidence": 0.9556213021278381}]}, {"text": "For those items judged to have the same meaning as the gold standard phrases we could track how many would have contributed to a higher Bleu score (that is, which of them were exactly the same as the reference translation phrase, or had some words in common with the reference translation phrase).", "labels": [], "entities": [{"text": "Bleu score", "start_pos": 136, "end_pos": 146, "type": "METRIC", "confidence": 0.9849909245967865}]}, {"text": "By counting how often a correct phrase would have contributed to an increased Bleu score, and how often it would fail to increase the Bleu score we were able to determine with what frequency Bleu was sensitive to our improvements.", "labels": [], "entities": [{"text": "Bleu score", "start_pos": 78, "end_pos": 88, "type": "METRIC", "confidence": 0.9893191754817963}, {"text": "Bleu score", "start_pos": 134, "end_pos": 144, "type": "METRIC", "confidence": 0.9548768401145935}]}, {"text": "We found that Bleu was insensitive to our translation improvements between 60-75% of the time, thus re-", "labels": [], "entities": [{"text": "Bleu", "start_pos": 14, "end_pos": 18, "type": "DATASET", "confidence": 0.6886054873466492}]}], "tableCaptions": [{"text": " Table 2: Bleu scores for the various training corpora, including baseline results without paraphrasing, results  for only paraphrasing unknown words, and results for paraphrasing any unseen phrase. Corpus size is  measured in sentences.", "labels": [], "entities": [{"text": "Bleu", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9974494576454163}]}, {"text": " Table 3: Bleu scores for the various training corpora, when the paraphrase feature function is not included", "labels": [], "entities": [{"text": "Bleu", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9963611960411072}]}, {"text": " Table 4: Percent of time that the translation of a paraphrase was judged to retain the same meaning as the  corresponding phrase in the gold standard. Starred items had fewer than 100 judgments and should not be  taken as reliable estimates.", "labels": [], "entities": [{"text": "gold standard", "start_pos": 137, "end_pos": 150, "type": "DATASET", "confidence": 0.8995218873023987}]}, {"text": " Table 5: The percent of the unique test set phrases  which have translations in each of the Spanish- English training corpora prior to paraphrasing", "labels": [], "entities": [{"text": "paraphrasing", "start_pos": 136, "end_pos": 148, "type": "TASK", "confidence": 0.6350072026252747}]}]}