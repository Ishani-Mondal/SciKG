{"title": [], "abstractContent": [{"text": "We present a probabilistic bilingual capitalization model for capitalizing machine translation outputs using conditional random fields.", "labels": [], "entities": [{"text": "capitalizing machine translation outputs", "start_pos": 62, "end_pos": 102, "type": "TASK", "confidence": 0.8208199292421341}]}, {"text": "Experiments carried out on three language pairs and a variety of experiment conditions show that our model significantly outperforms a strong mono-lingual capitalization model baseline, especially when working with small datasets and/or European language pairs.", "labels": [], "entities": []}], "introductionContent": [{"text": "Capitalization is the process of recovering case information for texts in lowercase.", "labels": [], "entities": []}, {"text": "It is also called truecasing (.", "labels": [], "entities": []}, {"text": "Usually, capitalization itself tries to improve the legibility of texts.", "labels": [], "entities": []}, {"text": "It, however, can affect the word choice or order when interacting with other models.", "labels": [], "entities": []}, {"text": "In natural language processing, a good capitalization model has been shown useful for tasks like name entity recognition, automatic content extraction, speech recognition, modern word processors, and machine translation (MT).", "labels": [], "entities": [{"text": "name entity recognition", "start_pos": 97, "end_pos": 120, "type": "TASK", "confidence": 0.712591807047526}, {"text": "automatic content extraction", "start_pos": 122, "end_pos": 150, "type": "TASK", "confidence": 0.6581730544567108}, {"text": "speech recognition", "start_pos": 152, "end_pos": 170, "type": "TASK", "confidence": 0.7568479776382446}, {"text": "machine translation (MT)", "start_pos": 200, "end_pos": 224, "type": "TASK", "confidence": 0.8208620429039002}]}, {"text": "Capitalization can be viewed as a sequence labeling process.", "labels": [], "entities": []}, {"text": "The input to this process is a sentence in lowercase.", "labels": [], "entities": []}, {"text": "For each lowercased word in the input sentence, we have several available capitalization tags: initial capital (IU), all uppercase (AU), all lowercase (AL), mixed case (MX), and all having no case (AN).", "labels": [], "entities": [{"text": "initial capital (IU)", "start_pos": 95, "end_pos": 115, "type": "METRIC", "confidence": 0.7667677402496338}, {"text": "case (AN)", "start_pos": 192, "end_pos": 201, "type": "METRIC", "confidence": 0.7033987939357758}]}, {"text": "The output of capitalization is a capitalization tag sequence.", "labels": [], "entities": []}, {"text": "Associating a tag in the output with the corresponding lowercased word in the input results in a surface form of the word.", "labels": [], "entities": []}, {"text": "For example, we can tag the input sentence \"click ok to save your changes to /home/doc.\" into \"click IU ok AU to AL save AL your AL changes AL to AL /home/doc MX . AN\", getting the surface form \"Click OK to save your changes to /home/DOC .\".", "labels": [], "entities": []}, {"text": "A capitalizer is a tagger that recovers the capitalization tag for each input lowercased word, outputting a well-capitalized sentence.", "labels": [], "entities": []}, {"text": "Since each lowercased word can have more than one tag, and associating a tag with a lowercased word can result in more than one surface form (e.g., /home/doc MX can be either /home/DOC or /home/Doc), we need a capitalization model to solve the capitalization ambiguities.", "labels": [], "entities": []}, {"text": "For example, use a trigram language model estimated from a corpus with case information; use a maximum entropy Markov model (MEMM) combining features involving words and their cases.", "labels": [], "entities": []}, {"text": "Capitalization models presented inmost previous approaches are monolingual because the models are estimated only from monolingual texts.", "labels": [], "entities": []}, {"text": "However, for capitalizing machine translation outputs, using only monolingual capitalization models is not enough.", "labels": [], "entities": [{"text": "capitalizing machine translation outputs", "start_pos": 13, "end_pos": 53, "type": "TASK", "confidence": 0.8607631176710129}]}, {"text": "For example, if the sentence \"click ok to save your changes to /home/doc .\" in the above example is the translation of the French sentence \"CLIQUEZ SUR OK POUR ENREGISTRER VOS MODIFI-CATIONS DANS /HOME/DOC .\", the correct capitalization result should probably be \"CLICK OK TO SAVE YOUR CHANGES TO /HOME/DOC .\", where all words are in all upper-case.", "labels": [], "entities": [{"text": "CLIQUEZ SUR OK POUR ENREGISTRER VOS MODIFI-CATIONS DANS", "start_pos": 140, "end_pos": 195, "type": "METRIC", "confidence": 0.7530403472483158}]}, {"text": "Without looking into the case of the MT input, we can hardly get the correct capitalization result.", "labels": [], "entities": [{"text": "MT", "start_pos": 37, "end_pos": 39, "type": "TASK", "confidence": 0.8913896083831787}]}, {"text": "Although monolingual capitalization models in previous work can apply to MT output, a bilingual model is more desirable.", "labels": [], "entities": [{"text": "MT", "start_pos": 73, "end_pos": 75, "type": "TASK", "confidence": 0.9824346899986267}]}, {"text": "This is because MT outputs usually strongly preserve case from the input, and because monolingual capitalization models do not always perform as well on badly translated text as on well-formed syntactic texts.", "labels": [], "entities": [{"text": "MT", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.988466739654541}]}, {"text": "In this paper, we present a bilingual capitalization model for capitalizing machine translation outputs using conditional random fields (CRFs) ().", "labels": [], "entities": [{"text": "capitalizing machine translation outputs", "start_pos": 63, "end_pos": 103, "type": "TASK", "confidence": 0.8321460336446762}]}, {"text": "This model exploits case information from both the input sentence (source) and the output sentence (target) of the MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 115, "end_pos": 117, "type": "TASK", "confidence": 0.9645691514015198}]}, {"text": "We define a series of feature functions to incorporate capitalization knowledge into the model.", "labels": [], "entities": []}, {"text": "Experimental results are shown in terms of BLEU scores of a phrase-based SMT system with the capitalization model incorporated, and in terms of capitalization precision.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9989649057388306}, {"text": "SMT", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.8567229509353638}, {"text": "precision", "start_pos": 159, "end_pos": 168, "type": "METRIC", "confidence": 0.8535224199295044}]}, {"text": "Experiments are performed on both French and English targeted MT systems with large-scale training data.", "labels": [], "entities": [{"text": "MT", "start_pos": 62, "end_pos": 64, "type": "TASK", "confidence": 0.8940860033035278}]}, {"text": "Our experimental results show that the CRF-based bilingual capitalization model performs better than a strong baseline capitalizer that uses a trigram language model.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Impact of CRF-based capitalizer on end-to-end translation performance compared with two LM-based baselines.", "labels": [], "entities": []}, {"text": " Table 4: Impact of CRF-based capitalizer on capitalization precision compared with two LM-based baselines.", "labels": [], "entities": [{"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.947913408279419}]}]}