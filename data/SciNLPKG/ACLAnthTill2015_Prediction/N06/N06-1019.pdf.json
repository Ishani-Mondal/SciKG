{"title": [], "abstractContent": [{"text": "We propose a solution to the annotation bottleneck for statistical parsing, by exploiting the lexicalized nature of Combi-natory Categorial Grammar (CCG).", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.8304158747196198}]}, {"text": "The parsing model uses predicate-argument dependencies for training, which are derived from sequences of CCG lexical categories rather than full derivations.", "labels": [], "entities": []}, {"text": "A simple method is used for extracting dependencies from lexical category sequences, resulting in high precision, yet incomplete and noisy data.", "labels": [], "entities": [{"text": "extracting dependencies from lexical category sequences", "start_pos": 28, "end_pos": 83, "type": "TASK", "confidence": 0.8013259768486023}, {"text": "precision", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.9762871861457825}]}, {"text": "The dependency parsing model of Clark and Curran (2004b) is extended to exploit this partial training data.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7831871509552002}]}, {"text": "Remarkably, the accuracy of the parser trained on data derived from category sequences alone is only 1.3% worse in terms of F-score than the parser trained on complete dependency structures.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9996160268783569}, {"text": "F-score", "start_pos": 124, "end_pos": 131, "type": "METRIC", "confidence": 0.9975658655166626}]}], "introductionContent": [{"text": "State-of-the-art statistical parsers require large amounts of hand-annotated training data, and are typically based on the Penn Treebank, the largest treebank available for English.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 123, "end_pos": 136, "type": "DATASET", "confidence": 0.995739072561264}]}, {"text": "Even robust parsers using linguistically sophisticated formalisms, such as TAG,,) and LFG (), often use training data derived from the Penn Treebank.", "labels": [], "entities": [{"text": "TAG", "start_pos": 75, "end_pos": 78, "type": "METRIC", "confidence": 0.9274155497550964}, {"text": "Penn Treebank", "start_pos": 135, "end_pos": 148, "type": "DATASET", "confidence": 0.994696170091629}]}, {"text": "The labour-intensive nature of the treebank development process, which can take many years, creates a significant barrier for the development of parsers for new domains and languages.", "labels": [], "entities": []}, {"text": "Previous work has attempted parser adaptation without relying on treebank data from the new domain (.", "labels": [], "entities": [{"text": "parser adaptation", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.9688360095024109}]}, {"text": "In this paper we propose the use of annotated data in the new domain, but only partially annotated data, which reduces the annotation effort required).", "labels": [], "entities": []}, {"text": "We develop a parsing model which can be trained using partial data, by exploiting the properties of lexicalized grammar formalisms.", "labels": [], "entities": []}, {"text": "The formalism we use is Combinatory Categorial Grammar, together with a parsing model described in which we adapt for use with partial data.", "labels": [], "entities": [{"text": "Combinatory Categorial Grammar", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.624035656452179}]}, {"text": "Parsing with Combinatory Categorial Grammar (CCG) takes place in two stages: first, CCG lexical categories are assigned to the words in the sentence, and then the categories are combined by the parser).", "labels": [], "entities": [{"text": "Parsing with Combinatory Categorial Grammar (CCG)", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.7597830779850483}]}, {"text": "The lexical categories can bethought of as detailed part of speech tags and typically express subcategorization information.", "labels": [], "entities": []}, {"text": "We exploit the fact that CCG lexical categories contain a lot of syntactic information, and can therefore be used for training a full parser, even though attachment information is not explicitly represented in a category sequence.", "labels": [], "entities": []}, {"text": "Our partial training regime only requires sentences to be annotated with lexical categories, rather than full parse trees; therefore the data can be produced much more quickly fora new domain or language).", "labels": [], "entities": []}, {"text": "The partial training method uses the log-linear dependency model described in, which uses sets of predicate-argument de-pendencies, rather than derivations, for training.", "labels": [], "entities": []}, {"text": "Our novel idea is that, since there is so much information in the lexical category sequence, most of the correct dependencies can be easily inferred from the categories alone.", "labels": [], "entities": []}, {"text": "More specifically, fora given sentence and lexical category sequence, we train on those predicate-argument dependencies which occur in k% of the derivations licenced by the lexical categories.", "labels": [], "entities": []}, {"text": "By setting the k parameter high, we can produce a set of high precision dependencies for training.", "labels": [], "entities": [{"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9695965647697449}]}, {"text": "A similar idea is proposed by for producing high precision data for lexical acquisition.", "labels": [], "entities": [{"text": "lexical acquisition", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.7291733920574188}]}, {"text": "Using this procedure we are able to produce dependency data with over 99% precision and, remarkably, up to 86% recall, when compared against the complete gold-standard dependency data.", "labels": [], "entities": [{"text": "precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9983333945274353}, {"text": "recall", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.9993578791618347}]}, {"text": "The high recall figure results from the significant amount of syntactic information in the lexical categories, which reduces the ambiguity in the possible dependency structures.", "labels": [], "entities": [{"text": "recall", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.9989950060844421}]}, {"text": "Since the recall is not 100%, we require a log-linear training method which works with partial data.", "labels": [], "entities": [{"text": "recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9995269775390625}]}, {"text": "describe a partial training method fora log-linear LFG parsing model in which the \"correct\" LFG derivations fora sentence are those consistent with the less detailed gold standard derivation from the Penn Treebank.", "labels": [], "entities": [{"text": "LFG parsing", "start_pos": 51, "end_pos": 62, "type": "TASK", "confidence": 0.6252391040325165}, {"text": "Penn Treebank", "start_pos": 200, "end_pos": 213, "type": "DATASET", "confidence": 0.9947784543037415}]}, {"text": "We use a similar method hereby treating a CCG derivation as correct if it is consistent with the highprecision partial dependency structure.", "labels": [], "entities": []}, {"text": "Section 3 explains what we mean by consistency in this context.", "labels": [], "entities": []}, {"text": "Surprisingly, the accuracy of the parser trained on partial data approaches that of the parser trained on full data: our best partial-data model is only 1.3% worse in terms of dependency F-score than the fulldata model, despite the fact that the partial data does not contain any explicit attachment information.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9995200634002686}, {"text": "F-score", "start_pos": 187, "end_pos": 194, "type": "METRIC", "confidence": 0.8271245360374451}]}], "datasetContent": [{"text": "The resource used for the experiments is CCGbank, which consists of normalform CCG derivations derived from the phrasestructure trees in the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 141, "end_pos": 154, "type": "DATASET", "confidence": 0.8911808729171753}]}, {"text": "It also contains predicate-argument dependencies which we use for development and final evaluation.", "labels": [], "entities": []}, {"text": "Ina final experiment, we attempted to exploit the high accuracy of the partial-data model by using it to provide new training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.999403715133667}]}, {"text": "For each sentence in Section 2-21, we parsed the gold-standard lexical category sequences and used the best performing partial-data model to assign scores to each dependency in the packed chart.", "labels": [], "entities": []}, {"text": "The score fora dependency was the sum of the probabilities of all derivations producing that dependency, which can be calculated using the inside-outside algorithm.", "labels": [], "entities": []}, {"text": "(This is the score used by the maximum-recall parsing algorithm.)", "labels": [], "entities": [{"text": "maximum-recall parsing", "start_pos": 31, "end_pos": 53, "type": "TASK", "confidence": 0.7145712375640869}]}, {"text": "Partial dependency structures were then created by returning all dependencies whose score was above some threshold k, as before.", "labels": [], "entities": []}, {"text": "gives the accuracy of the data created by this procedure.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9995937943458557}]}, {"text": "Note how these values differ to those reported in.", "labels": [], "entities": []}, {"text": "We then trained the dependency model on this partial data using the same method as before.", "labels": [], "entities": []}, {"text": "However, the peformance of the parser on Section 00 using these new models was below that of the previous best performing partial-data model for all values of k.", "labels": [], "entities": [{"text": "Section 00", "start_pos": 41, "end_pos": 51, "type": "DATASET", "confidence": 0.8430619537830353}]}, {"text": "We report this negative result because we had hypothesised that using a probability model to score the dependencies, rather than simply the number of derivations in which they occur, would lead to improved performance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy of the Partial Dependency Data", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9973551034927368}]}, {"text": " Table 2: Accuracy of the Parser on Section 00", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9986428618431091}]}, {"text": " Table 3: Accuracy of the Parser on Section 23", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9977090358734131}]}, {"text": " Table 4: Accuracy of the Partial Dependency Data  using Inside-Outside Scores", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9927719235420227}]}]}