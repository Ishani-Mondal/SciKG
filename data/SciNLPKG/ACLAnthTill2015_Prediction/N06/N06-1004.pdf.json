{"title": [{"text": "Segment Choice Models: Feature-Rich Models for Global Distortion in Statistical Machine Translation", "labels": [], "entities": [{"text": "Segment Choice", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8981896638870239}, {"text": "Statistical Machine Translation", "start_pos": 68, "end_pos": 99, "type": "TASK", "confidence": 0.6562919219334921}]}], "abstractContent": [{"text": "This paper presents anew approach to distortion (phrase reordering) in phrasebased machine translation (MT).", "labels": [], "entities": [{"text": "phrase reordering)", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.7845447758833567}, {"text": "phrasebased machine translation (MT)", "start_pos": 71, "end_pos": 107, "type": "TASK", "confidence": 0.7552069922288259}]}, {"text": "Distortion is modeled as a sequence of choices during translation.", "labels": [], "entities": []}, {"text": "The approach yields trainable, probabilistic distortion models that are global: they assign a probability to each possible phrase reordering.", "labels": [], "entities": []}, {"text": "These \"segment choice\" models (SCMs) can be trained on \"segment-aligned\" sentence pairs; they can be applied during decoding or rescoring.", "labels": [], "entities": []}, {"text": "The approach yields a metric called \"distortion perplexity\" (\"disperp\") for comparing SCMs offline on test data, analogous to perplexity for language models.", "labels": [], "entities": [{"text": "SCMs offline", "start_pos": 86, "end_pos": 98, "type": "TASK", "confidence": 0.8273458182811737}]}, {"text": "A decision-tree-based SCM is tested on Chinese-to-English translation, and outperforms a baseline distortion penalty approach at the 99% confidence level.", "labels": [], "entities": [{"text": "SCM", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.7213244438171387}]}], "introductionContent": [], "datasetContent": [{"text": "We carried out SCM disperp experiments for the English-Chinese task, in both directions.", "labels": [], "entities": [{"text": "SCM disperp", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.9177980124950409}]}, {"text": "That is, we trained and tested models both for the distortion of English into Chinese-like phrase order, and the distortion of Chinese into English-like phrase order.", "labels": [], "entities": [{"text": "distortion of English into Chinese-like phrase order", "start_pos": 51, "end_pos": 103, "type": "TASK", "confidence": 0.8128583601542881}, {"text": "distortion of Chinese into English-like phrase order", "start_pos": 113, "end_pos": 165, "type": "TASK", "confidence": 0.7699887241636004}]}, {"text": "For reasons of space, details about the \"distorted English\" experiments won't be given here.", "labels": [], "entities": []}, {"text": "Training and development data for the distorted Chinese experiments were taken from the NIST 2005 release of the FBIS corpus of Xinhua news stories.", "labels": [], "entities": [{"text": "NIST 2005 release of the FBIS corpus of Xinhua news stories", "start_pos": 88, "end_pos": 147, "type": "DATASET", "confidence": 0.9648342457684603}]}, {"text": "The training corpus comprised 62,000 FBIS segment alignments, and the development \"dev\" corpus comprised a disjoint set of 2,306 segment alignments from the same FBIS corpus.", "labels": [], "entities": [{"text": "FBIS segment alignments", "start_pos": 37, "end_pos": 60, "type": "TASK", "confidence": 0.7031397422154745}]}, {"text": "All disperp results are obtained by testing on \"dev\" corpus.", "labels": [], "entities": []}, {"text": "shows disperp results for the models described earlier.", "labels": [], "entities": [{"text": "disperp", "start_pos": 6, "end_pos": 13, "type": "METRIC", "confidence": 0.9871829748153687}]}, {"text": "The y axis begins at 1.0 (minimum value of disperp).", "labels": [], "entities": [{"text": "disperp", "start_pos": 43, "end_pos": 50, "type": "METRIC", "confidence": 0.987753689289093}]}, {"text": "The x axis shows number of alignments (DSHs) used to train DTs, on a log scale.", "labels": [], "entities": [{"text": "DTs", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.8501030802726746}]}, {"text": "Models A-D are fixed in advance; Model P's single parameter was optimized once on the entire training set of 62K FBIS alignments (to 0.77) rather than separately for each amount of training data.", "labels": [], "entities": []}, {"text": "Model P, the normalized version of Koehn's distortion penalty, is superior to Models A-D, and the DT-based SCM is superior to Model P. The DT-based SCM had four trees (2-choice, 3-choice, 4-choice, and 5+-choice) with position-based and word-based questions.", "labels": [], "entities": []}, {"text": "The word-based questions involved only the 100 most frequent Chinese words in the training corpus.", "labels": [], "entities": []}, {"text": "The system's disperp drops from 3.1 to 2.8 as the number of alignments goes from 500 to 62K.", "labels": [], "entities": [{"text": "disperp", "start_pos": 13, "end_pos": 20, "type": "METRIC", "confidence": 0.9977259039878845}]}, {"text": "In the \"four-DT\" results above, examples with five or more segments are handled by the same \"5+-choice\" tree.", "labels": [], "entities": []}, {"text": "Increasing the number of trees allows finer modeling of multi-segment cases while spreading the training data more thinly.", "labels": [], "entities": []}, {"text": "Thus, the optimal number of trees depends on the amount of training data.", "labels": [], "entities": []}, {"text": "Fixing this amount to 32K alignments, we varied the number of trees.", "labels": [], "entities": []}, {"text": "shows that this parameter has a significant impact on disperp, and that questions based on the most frequent 100 Chinese words help performance for any number of trees.", "labels": [], "entities": [{"text": "disperp", "start_pos": 54, "end_pos": 61, "type": "TASK", "confidence": 0.9137487411499023}]}, {"text": "In the number of the most frequent Chinese words for questions is varied (for a 13-DT system trained on 32K alignments).", "labels": [], "entities": []}, {"text": "Most of the improvement came from the 8 most frequent words, especially from the most frequent, the comma \",\".", "labels": [], "entities": []}, {"text": "This behaviour seems to be specific to Chinese.", "labels": [], "entities": []}, {"text": "In our \"distorted English\" experiments, questions about the 8 most frequent words also gave a significant improvement, but each of the 8 words had a fairly equal share in the improvement.", "labels": [], "entities": []}, {"text": "Finally, we grew the DT system used for the MT experiments: one with 13 trees and questions about the 25 most frequent Chinese words, grown on 88K alignments.", "labels": [], "entities": [{"text": "MT", "start_pos": 44, "end_pos": 46, "type": "TASK", "confidence": 0.991855263710022}]}, {"text": "Its disperp on the \"dev\" used for the MT experiments (a different \"dev\" from the one above -see Sec.", "labels": [], "entities": [{"text": "MT", "start_pos": 38, "end_pos": 40, "type": "TASK", "confidence": 0.9124230742454529}]}, {"text": "5.2) was 2.42 vs. 3.48 for the baseline Model P system: a 30% drop.", "labels": [], "entities": []}, {"text": "The training corpus for the MT system's phrase tables consists of all parallel text available for the NIST MT05 Chinese-English evaluation, except the Xinhua corpora and part 3 of LDC's \"MultipleTranslation Chinese Corpus\" (MTCCp3).", "labels": [], "entities": [{"text": "MT", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.9586271643638611}, {"text": "NIST MT05 Chinese-English evaluation", "start_pos": 102, "end_pos": 138, "type": "DATASET", "confidence": 0.8327680230140686}]}, {"text": "The English language model was trained on the same corpora, plus 250M words from Gigaword.", "labels": [], "entities": [{"text": "Gigaword", "start_pos": 81, "end_pos": 89, "type": "DATASET", "confidence": 0.9422346949577332}]}, {"text": "The DTbased SCM was trained and tuned on a subset of this same training corpus (above).", "labels": [], "entities": [{"text": "DTbased SCM", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.750067800283432}]}, {"text": "The dev corpus for optimizing component weights is MTCCp3.", "labels": [], "entities": [{"text": "MTCCp3", "start_pos": 51, "end_pos": 57, "type": "DATASET", "confidence": 0.9535692930221558}]}, {"text": "The experimental results below were obtained by testing on the evaluation set for MTeval NIST04.", "labels": [], "entities": [{"text": "MTeval NIST04", "start_pos": 82, "end_pos": 95, "type": "DATASET", "confidence": 0.5602011382579803}]}, {"text": "Phrase tables were learned from the training corpus using the \"diag-and\" method (, and using IBM model 2 to produce initial word alignments (these authors found this worked as well as IBM4).", "labels": [], "entities": [{"text": "IBM4", "start_pos": 184, "end_pos": 188, "type": "DATASET", "confidence": 0.8521950840950012}]}, {"text": "Phrase probabilities were based on unsmoothed relative frequencies.", "labels": [], "entities": [{"text": "Phrase probabilities", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.836429089307785}]}, {"text": "The model used by the decoder was a log-linear combination of a phrase translation model (only in the P(source|target) direction), trigram language model, word penalty (lexical weighting), an optional segmentation model (in the form of a phrase penalty) and distortion model.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.7548416554927826}]}, {"text": "Weights on the components were assigned using the method for max-BLEU training on the development set.", "labels": [], "entities": []}, {"text": "The decoder uses a dynamicprogramming beam-search, like the one in).", "labels": [], "entities": []}, {"text": "Future-cost estimates for all distortion models are assigned using the baseline penalty model.", "labels": [], "entities": []}, {"text": "The \"DP\" systems use the distortion penalty in) with optimized on \"dev\", while \"DT\" systems use the DT-based SCM.", "labels": [], "entities": [{"text": "distortion", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9751714468002319}]}, {"text": "\"1x\" is the default beam width, while \"4x\" is a wider beam (our notation reflects decoding time, so \"4x\" takes four times as long as \"1x\").", "labels": [], "entities": []}, {"text": "\"PP\" denotes presence of the phrase penalty component.", "labels": [], "entities": []}, {"text": "The advantage of DTs as measured by difference between the score of the best DT system and the best DP system is 0.75 BLEU at 1x and 0.5 BLEU at 4x.", "labels": [], "entities": [{"text": "DTs", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.8630629181861877}, {"text": "BLEU", "start_pos": 118, "end_pos": 122, "type": "METRIC", "confidence": 0.9990712404251099}, {"text": "BLEU", "start_pos": 137, "end_pos": 141, "type": "METRIC", "confidence": 0.9977279305458069}]}, {"text": "With a 95% bootstrap confidence interval of \u00b10.7 BLEU (based on 1000-fold resampling), the resolution of these results is too coarse to draw firm conclusions.", "labels": [], "entities": [{"text": "bootstrap confidence interval", "start_pos": 11, "end_pos": 40, "type": "METRIC", "confidence": 0.9389605720837911}, {"text": "BLEU", "start_pos": 49, "end_pos": 53, "type": "METRIC", "confidence": 0.9751332402229309}, {"text": "resolution", "start_pos": 91, "end_pos": 101, "type": "METRIC", "confidence": 0.9749978184700012}]}], "tableCaptions": [{"text": " Table 1. Pairwise comparison for 1x systems", "labels": [], "entities": []}]}