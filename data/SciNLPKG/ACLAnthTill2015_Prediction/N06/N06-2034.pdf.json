{"title": [{"text": "Using Phrasal Patterns to Identify Discourse Relations", "labels": [], "entities": [{"text": "Identify Discourse", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.9058835804462433}]}], "abstractContent": [{"text": "This paper describes a system which identifies discourse relations between two successive sentences in Japanese.", "labels": [], "entities": []}, {"text": "On top of the lexical information previously proposed, we used phrasal pattern information.", "labels": [], "entities": []}, {"text": "Adding phrasal information improves the system's accuracy 12%, from 53% to 65%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.999614953994751}]}], "introductionContent": [{"text": "Identifying discourse relations is important for many applications, such as text/conversation understanding, single/multi-document summarization and question answering.", "labels": [], "entities": [{"text": "Identifying discourse relations", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8678164680798849}, {"text": "text/conversation understanding", "start_pos": 76, "end_pos": 107, "type": "TASK", "confidence": 0.6129563078284264}, {"text": "question answering", "start_pos": 149, "end_pos": 167, "type": "TASK", "confidence": 0.8944358229637146}]}, {"text": "( proposed a method to identify discourse relations between text segments using Na\u00efve Bayes classifiers trained on a huge corpus.", "labels": [], "entities": []}, {"text": "They showed that lexical pair information extracted from massive amounts of data can have a major impact.", "labels": [], "entities": []}, {"text": "We developed a system which identifies the discourse relation between two successive sentences in Japanese.", "labels": [], "entities": []}, {"text": "On top of the lexical information previously proposed, we added phrasal pattern information.", "labels": [], "entities": []}, {"text": "A phrasal pattern includes at least three phrases (bunsetsu segments) from two sentences, where function words are mandatory and content words are optional.", "labels": [], "entities": []}, {"text": "For example, if the first sentence is \"X should have done Y\" and the second sentence is \"A did B\", then we found it very likely that the discourse relation is CONTRAST (89% in our Japanese corpus).", "labels": [], "entities": [{"text": "CONTRAST", "start_pos": 159, "end_pos": 167, "type": "METRIC", "confidence": 0.9972180128097534}]}], "datasetContent": [{"text": "The system identifies one of six discourse relations, described in, fora test sentence pair.", "labels": [], "entities": []}, {"text": "Using the 300 sentence pairs set aside earlier (50 of each discourse relation type), we ran two experiments for comparison purposes: one using only lexical information, the other using phrasal patterns as well.", "labels": [], "entities": []}, {"text": "In the experiment using only lexical information, the system selects the relation maximizing Score 2 (this did better than Score 1 ).", "labels": [], "entities": []}, {"text": "In the other, the system chooses a relation as follows: if one relation maximizes both Score 1 and Score 2 , choose that relation; else, if one relation maximizes both Score and Score 4 , choose that relation; else choose the relation maximizing Score 2 . shows the result.", "labels": [], "entities": []}, {"text": "For all discourse relations, the results using phrasal patterns are better or the same.", "labels": [], "entities": []}, {"text": "When we consider the frequency of discourse relations, i.e. 43% for ELABORATION, 32% for CONTRAST etc., the weighted accuracy was 53% using only lexical information, which is comparable to the similar experiment by (Marcu and Echihabi 2002) of 49.7%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9491079449653625}]}, {"text": "Using phrasal patterns, the accuracy improves 12% to 65%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9997326731681824}]}, {"text": "Note that the baseline accuracy (by always selecting the most frequent relation) is 43%, so the improvement is significant.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9527258276939392}]}], "tableCaptions": [{"text": " Table 3. Accuracy for different agreements", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9991605281829834}]}]}