{"title": [{"text": "Word Domain Disambiguation via Word Sense Disambiguation", "labels": [], "entities": [{"text": "Word Domain Disambiguation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8122128248214722}, {"text": "Word Sense Disambiguation", "start_pos": 31, "end_pos": 56, "type": "TASK", "confidence": 0.7492432792981466}]}], "abstractContent": [{"text": "Word subject domains have been widely used to improve the performance of word sense disambiguation algorithms.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 73, "end_pos": 98, "type": "TASK", "confidence": 0.7311732967694601}]}, {"text": "However, comparatively little effort has been devoted so far to the disambiguation of word subject domains.", "labels": [], "entities": []}, {"text": "The few existing approaches have focused on the development of algorithms specific to word domain dis-ambiguation.", "labels": [], "entities": [{"text": "word domain dis-ambiguation", "start_pos": 86, "end_pos": 113, "type": "TASK", "confidence": 0.6408615012963613}]}, {"text": "In this paper we explore an alternative approach where word domain disambiguation is achieved via word sense disambiguation.", "labels": [], "entities": [{"text": "word domain disambiguation", "start_pos": 55, "end_pos": 81, "type": "TASK", "confidence": 0.6340503493944804}, {"text": "word sense disambiguation", "start_pos": 98, "end_pos": 123, "type": "TASK", "confidence": 0.698733369509379}]}, {"text": "Our study shows that this approach yields very strong results, suggesting that word domain disambiguation can be addressed in terms of word sense disam-biguation with no need for special purpose algorithms.", "labels": [], "entities": [{"text": "word domain disambiguation", "start_pos": 79, "end_pos": 105, "type": "TASK", "confidence": 0.6494004329045614}]}], "introductionContent": [{"text": "Word subject domains have been ubiquitously used in dictionaries to help human readers pinpoint the specific sense of a word by specifying technical usage, e.g. see \"subject field codes\" in.", "labels": [], "entities": []}, {"text": "In computational linguistics, word subject domains have been widely used to improve the performance of machine translation systems.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 103, "end_pos": 122, "type": "TASK", "confidence": 0.7226293683052063}]}, {"text": "For example, in a review of commonly used features in automated translation, reports that most of the machine translation systems surveyed made use of word subject domains.", "labels": [], "entities": [{"text": "automated translation", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.7145152390003204}, {"text": "machine translation", "start_pos": 102, "end_pos": 121, "type": "TASK", "confidence": 0.7188473641872406}]}, {"text": "Word subject domains have also been used in information systems.", "labels": [], "entities": []}, {"text": "For example, Sanfilippo (1998) describes a summarization system where subject domains provide users with useful conceptual parameters to tailor summary requests to a user's interest.", "labels": [], "entities": [{"text": "summarization", "start_pos": 43, "end_pos": 56, "type": "TASK", "confidence": 0.9681192636489868}]}, {"text": "Successful usage of word domains in applications such as machine translation and summarization is strongly dependent on the ability to assign the appropriate subject domain to a word in its context.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.8123021125793457}, {"text": "summarization", "start_pos": 81, "end_pos": 94, "type": "TASK", "confidence": 0.9493022561073303}]}, {"text": "Such an assignment requires a process of Word Domain Disambiguation (WDD) because the same word can often be assigned different subject domains out of context (e.g. the word partner can potentially be related to FINANCE or MARRIAGE).", "labels": [], "entities": [{"text": "Word Domain Disambiguation (WDD)", "start_pos": 41, "end_pos": 73, "type": "TASK", "confidence": 0.7301734338204066}]}, {"text": "Interestingly enough, word subject domains have been widely used to improve the performance of Word Sense Disambiguation (WSD) algorithms).", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 95, "end_pos": 126, "type": "TASK", "confidence": 0.729039470354716}]}, {"text": "However, comparatively little effort has been devoted so far to the word domain disambiguation itself.", "labels": [], "entities": [{"text": "word domain disambiguation", "start_pos": 68, "end_pos": 94, "type": "TASK", "confidence": 0.6290620962778727}]}, {"text": "The most notable exceptions are the work of and.", "labels": [], "entities": []}, {"text": "Both studies propose algorithms specific to the WDD task and have focused on the disambiguation of noun domains.", "labels": [], "entities": [{"text": "WDD task", "start_pos": 48, "end_pos": 56, "type": "TASK", "confidence": 0.906257152557373}]}, {"text": "In this paper we explore an alternative approach where word domain disambiguation is achieved via word sense disambiguation.", "labels": [], "entities": [{"text": "word domain disambiguation", "start_pos": 55, "end_pos": 81, "type": "TASK", "confidence": 0.6340503493944804}, {"text": "word sense disambiguation", "start_pos": 98, "end_pos": 123, "type": "TASK", "confidence": 0.698733369509379}]}, {"text": "Moreover, we extend the treatment of WDD to verbs and adjectives.", "labels": [], "entities": []}, {"text": "Initial results show that this approach yield very strong results, suggesting that WDD can be addressed in terms of word sense disambiguation with no need of special purpose algorithms.", "labels": [], "entities": [{"text": "WDD", "start_pos": 83, "end_pos": 86, "type": "TASK", "confidence": 0.8987598419189453}, {"text": "word sense disambiguation", "start_pos": 116, "end_pos": 141, "type": "TASK", "confidence": 0.6887185275554657}]}], "datasetContent": [{"text": "To evaluate our WDD approach, we used both the SemCor and Senseval3 data sets.", "labels": [], "entities": [{"text": "Senseval3 data sets", "start_pos": 58, "end_pos": 77, "type": "DATASET", "confidence": 0.9051816463470459}]}, {"text": "Both corpora were stripped of their sense annotations and processed with an extension of the WSD algorithm of to assign a WordNet sense to each noun, verb and adjective.", "labels": [], "entities": []}, {"text": "The extension consisted in extending the training data set so as to include a selection of WordNet examples (full sentences containing a main verb) and the Open Mind Word Expert corpus.", "labels": [], "entities": [{"text": "Open Mind Word Expert corpus", "start_pos": 156, "end_pos": 184, "type": "DATASET", "confidence": 0.5684258997440338}]}, {"text": "The original hand-coded word sense annotations of the SemCor and Senseval3 corpora and the word sense annotations assigned by the WSD algorithm used in this study were mapped into subject domain annotations using WordNet Domains, as described in the opening paragraph of section 2 above.", "labels": [], "entities": []}, {"text": "The version of the SemCor and Senseval3 corpora where subject domain annotations were generated from hand-coded word senses served as gold standard.", "labels": [], "entities": []}, {"text": "A baseline for both corpora was obtained by assigning to each lemma the subject domain corresponding to sense 1 of the lemma.", "labels": [], "entities": []}, {"text": "WDD results of a tenfold cross-validation for the SemCor data set are given in.", "labels": [], "entities": [{"text": "WDD", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6573265194892883}, {"text": "SemCor data set", "start_pos": 50, "end_pos": 65, "type": "DATASET", "confidence": 0.9171294967333475}]}, {"text": "Accuracy is high across nouns, verbs and adjectives.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9920315742492676}]}, {"text": "To verify the statistical significance of these results against the baseline, we used a standard proportions comparison test (see.", "labels": [], "entities": []}, {"text": "According to this test, the accuracy of our system is significantly better than the baseline.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9997105002403259}]}, {"text": "The high accuracy of our WDD algorithm is corroborated by the results for the Senseval3 data set in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9995535016059875}, {"text": "Senseval3 data set", "start_pos": 78, "end_pos": 96, "type": "DATASET", "confidence": 0.9571762681007385}]}, {"text": "Such corroboration is important as the Senseval3 corpus was not part of the data set used to train the WSD algorithm which provided the basis for subject domain assign-ment.", "labels": [], "entities": [{"text": "Senseval3 corpus", "start_pos": 39, "end_pos": 55, "type": "DATASET", "confidence": 0.8561575412750244}]}, {"text": "The standard comparison test for the Senseval3 is not as conclusive as with SemCor.", "labels": [], "entities": []}, {"text": "This is probably due to the comparatively smaller size of the Senseval3 corpus.", "labels": [], "entities": [{"text": "Senseval3 corpus", "start_pos": 62, "end_pos": 78, "type": "DATASET", "confidence": 0.96140918135643}]}], "tableCaptions": [{"text": " Table 1: Results for verb sense disambiguation on  Senseval3 data, adapted from Sanfilippo et al. (2006).", "labels": [], "entities": [{"text": "verb sense disambiguation", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.7074245015780131}, {"text": "Senseval3 data", "start_pos": 52, "end_pos": 66, "type": "DATASET", "confidence": 0.8924042582511902}]}, {"text": " Table 3. Such corroboration is impor- tant as the Senseval3 corpus was not part of the  data set used to train the WSD algorithm which  provided the basis for subject domain assign-ment. The standard comparison test for the Sen- seval3 is not as conclusive as with SemCor. This  is probably due to the comparatively smaller size  of the Senseval3 corpus.", "labels": [], "entities": [{"text": "Senseval3 corpus", "start_pos": 51, "end_pos": 67, "type": "DATASET", "confidence": 0.7799942493438721}, {"text": "Senseval3 corpus", "start_pos": 338, "end_pos": 354, "type": "DATASET", "confidence": 0.8351696729660034}]}, {"text": " Table 2: SemCor WDD results.", "labels": [], "entities": [{"text": "SemCor WDD", "start_pos": 10, "end_pos": 20, "type": "TASK", "confidence": 0.5488805174827576}]}, {"text": " Table 3: Senseval3 WDD results.", "labels": [], "entities": [{"text": "Senseval3 WDD", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.7410716414451599}]}]}