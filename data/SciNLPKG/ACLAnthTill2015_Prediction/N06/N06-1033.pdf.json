{"title": [], "abstractContent": [{"text": "Systems based on synchronous grammars and tree transducers promise to improve the quality of statistical machine translation output, but are often very computa-tionally intensive.", "labels": [], "entities": [{"text": "statistical machine translation output", "start_pos": 93, "end_pos": 131, "type": "TASK", "confidence": 0.7242752909660339}]}, {"text": "The complexity is exponential in the size of individual grammar rules due to arbitrary re-orderings between the two languages, and rules extracted from parallel corpora can be quite large.", "labels": [], "entities": []}, {"text": "We devise a linear-time algorithm for factoring syntactic re-orderings by bi-narizing synchronous rules when possible and show that the resulting rule set significantly improves the speed and accuracy of a state-of-the-art syntax-based machine translation system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 192, "end_pos": 200, "type": "METRIC", "confidence": 0.997858464717865}, {"text": "machine translation", "start_pos": 236, "end_pos": 255, "type": "TASK", "confidence": 0.7267877757549286}]}], "introductionContent": [{"text": "Several recent syntax-based models for machine translation) can be seen as instances of the general framework of synchronous grammars and tree transducers.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.7588956952095032}]}, {"text": "In this framework, both alignment (synchronous parsing) and decoding can bethought of as parsing problems, whose complexity is in general exponential in the number of nonterminals on the right hand side of a grammar rule.", "labels": [], "entities": []}, {"text": "To alleviate this problem, we investigate bilingual binarization to factor the synchronous grammar to a smaller branching factor, although it is not guaranteed to be successful for any synchronous rule with arbitrary permutation.", "labels": [], "entities": []}, {"text": "In particular: \u2022 We develop a technique called synchronous binarization and devise a fast binarization algorithm such that the resulting rule set allows efficient algorithms for both synchronous parsing and decoding with integrated n-gram language models.", "labels": [], "entities": []}, {"text": "\u2022 We examine the effect of this binarization method on end-to-end machine translation quality, compared to a more typical baseline method.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.6099336445331573}]}, {"text": "\u2022 We examine cases of non-binarizable rules in a large, empirically-derived rule set, and we investigate the effect on translation quality when excluding such rules.", "labels": [], "entities": []}, {"text": "Melamed (2003) discusses binarization of multitext grammars on a theoretical level, showing the importance and difficulty of binarization for efficient synchronous parsing.", "labels": [], "entities": []}, {"text": "One way around this difficulty is to stipulate that all rules must be binary from the outset, as in inversion-transduction grammar (ITG) () and the binary synchronous context-free grammar (SCFG) employed by the Hiero system) to model the hierarchical phrases.", "labels": [], "entities": []}, {"text": "In contrast, the rule extraction method of aims to incorporate more syntactic information by providing parse trees for the target language and extracting tree transducer rules that apply to the parses.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 17, "end_pos": 32, "type": "TASK", "confidence": 0.7508708834648132}]}, {"text": "This approach results in rules with many nonterminals, making good binarization techniques critical.", "labels": [], "entities": []}, {"text": "Suppose we have the following SCFG, where superscripts indicate reorderings (formal definitions of SCFGs can be found in Section 2): Decoding can be cast as a (monolingual) parsing problem since we only need to parse the sourcelanguage side of the SCFG, as if we were constructing a CFG projected on Chinese out of the SCFG.", "labels": [], "entities": []}, {"text": "The only extra work we need to do for decoding is to build corresponding target-language (English) subtrees in parallel.", "labels": [], "entities": []}, {"text": "In other words, we build synchronous trees when parsing the source-language input, as shown in.", "labels": [], "entities": []}, {"text": "To efficiently decode with CKY, we need to binarize the projected CFG grammar.", "labels": [], "entities": [{"text": "CKY", "start_pos": 27, "end_pos": 30, "type": "DATASET", "confidence": 0.9190168976783752}, {"text": "CFG grammar", "start_pos": 66, "end_pos": 77, "type": "DATASET", "confidence": 0.870031476020813}]}, {"text": "1 Rules can be binarized in different ways.", "labels": [], "entities": []}, {"text": "For example, we could binarize the first rule left to right or right to left: We call those intermediate symbols (e.g. V PP-VP ) virtual nonterminals and corresponding rules virtual rules, whose probabilities are all set to 1.", "labels": [], "entities": []}, {"text": "These two binarizations are no different in the translation-model-only decoding described above, just as in monolingual parsing.", "labels": [], "entities": []}, {"text": "However, in the source-channel approach to machine translation, we need to combine probabilities from the translation model (an SCFG) with the language model (an ngram), which has been shown to be very important for translation quality.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.7863048613071442}]}, {"text": "To do bigram-integrated decoding, we need to augment each chart item (X, i, j) with two target-language 1 Other parsing strategies like the Earley algorithm use an internal binary representation (e.g. dotted-rules) of the original grammar to ensure cubic time complexity.", "labels": [], "entities": []}, {"text": "boundary words u and v to produce a bigram-item like", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we answer two empirical questions.", "labels": [], "entities": []}, {"text": "The solid-line curve represents the distribution of all rules against permutation lengths.", "labels": [], "entities": []}, {"text": "The dashed-line stairs indicate the percentage of non-binarizable rules in our initial rule set while the dotted-line denotes that percentage among all permutations.", "labels": [], "entities": []}], "tableCaptions": []}