{"title": [{"text": "Exploiting Domain Structure for Named Entity Recognition", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.7031482259432474}]}], "abstractContent": [{"text": "Named Entity Recognition (NER) is a fundamental task in text mining and natural language understanding.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7769332428773245}, {"text": "text mining", "start_pos": 56, "end_pos": 67, "type": "TASK", "confidence": 0.811654269695282}, {"text": "natural language understanding", "start_pos": 72, "end_pos": 102, "type": "TASK", "confidence": 0.6507617433865865}]}, {"text": "Current approaches to NER (mostly based on supervised learning) perform well on domains similar to the training domain, but they tend to adapt poorly to slightly different domains.", "labels": [], "entities": [{"text": "NER", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9817313551902771}]}, {"text": "We present several strategies for exploiting the domain structure in the training data to learn a more robust named entity recognizer that can perform well on anew domain.", "labels": [], "entities": []}, {"text": "First, we propose a simple yet effective way to automatically rank features based on their generalizabilities across domains.", "labels": [], "entities": []}, {"text": "We then train a classifier with strong emphasis on the most general-izable features.", "labels": [], "entities": []}, {"text": "This emphasis is imposed by putting a rank-based prior on a logistic regression model.", "labels": [], "entities": []}, {"text": "We further propose a domain-aware cross validation strategy to help choose an appropriate parameter for the rank-based prior.", "labels": [], "entities": []}, {"text": "We evaluated the proposed method with a task of recognizing named entities (genes) in biology text involving three species.", "labels": [], "entities": []}, {"text": "The experiment results show that the new domain-aware approach outperforms a state-of-the-art baseline method in adapting to new domains, especially when there is a great difference between the new domain and the training domain.", "labels": [], "entities": []}], "introductionContent": [{"text": "Named Entity Recognition (NER) is the task of identifying and classifying phrases that denote certain types of named entities (NEs), such as persons, organizations and locations in news articles, and genes, proteins and chemicals in biomedical literature.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER) is the task of identifying and classifying phrases that denote certain types of named entities (NEs), such as persons, organizations and locations in news articles, and genes, proteins and chemicals in biomedical", "start_pos": 0, "end_pos": 243, "type": "Description", "confidence": 0.8047114231369712}]}, {"text": "NER is a fundamental task in many natural language processing applications, such as question answering, machine translation, text mining, and information retrieval).", "labels": [], "entities": [{"text": "NER", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9306011199951172}, {"text": "question answering", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.8884034752845764}, {"text": "machine translation", "start_pos": 104, "end_pos": 123, "type": "TASK", "confidence": 0.7658199369907379}, {"text": "text mining", "start_pos": 125, "end_pos": 136, "type": "TASK", "confidence": 0.7868074774742126}, {"text": "information retrieval", "start_pos": 142, "end_pos": 163, "type": "TASK", "confidence": 0.7801623046398163}]}, {"text": "Existing approaches to NER are mostly based on supervised learning.", "labels": [], "entities": [{"text": "NER", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.9888407588005066}]}, {"text": "They can often achieve high accuracy provided that a large annotated training set similar to the test data is available).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9986522793769836}]}, {"text": "Unfortunately, when the test data has some difference from the training data, these approaches tend to not perform well.", "labels": [], "entities": []}, {"text": "For example, reported a performance degradation of a named entity recognizer trained on Reuters corpus, where the F1 measure dropped from 0.908 when tested on a similar Reuters set to 0.643 when tested on a Wall Street Journal set.", "labels": [], "entities": [{"text": "Reuters corpus", "start_pos": 88, "end_pos": 102, "type": "DATASET", "confidence": 0.9780362844467163}, {"text": "F1 measure", "start_pos": 114, "end_pos": 124, "type": "METRIC", "confidence": 0.9906079471111298}, {"text": "Reuters set", "start_pos": 169, "end_pos": 180, "type": "DATASET", "confidence": 0.8845870196819305}, {"text": "Wall Street Journal set", "start_pos": 207, "end_pos": 230, "type": "DATASET", "confidence": 0.9502866566181183}]}, {"text": "The degradation can be expected to be worse if the training data and the test data are more different.", "labels": [], "entities": []}, {"text": "The performance degradation indicates that existing approaches adapt poorly to new domains.", "labels": [], "entities": []}, {"text": "We believe one reason for this poor adaptability is that these approaches have not considered the fact that, depending on the genre or domain of the text, the entities to be recognized may have different mor-phological properties or occur in different contexts.", "labels": [], "entities": []}, {"text": "Indeed, since most existing learning-based NER approaches explore a large feature space, without regularization, a learned NE recognizer can easily overfit the training domain.", "labels": [], "entities": [{"text": "NE recognizer", "start_pos": 123, "end_pos": 136, "type": "TASK", "confidence": 0.8483054637908936}]}, {"text": "Domain overfitting is a serious problem in NER because we often need to tag entities in completely new domains.", "labels": [], "entities": [{"text": "NER", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.9158775806427002}]}, {"text": "Given any new test domain, it is generally quite expensive to obtain a large amount of labeled entity examples in that domain.", "labels": [], "entities": []}, {"text": "As a result, in many real applications, we must train on data that do not fully resemble the test data.", "labels": [], "entities": []}, {"text": "This problem is especially serious in recognizing entities, in particular gene names, from biomedical literature.", "labels": [], "entities": []}, {"text": "Gene names of one species can be quite different from those of another species syntactically due to their different naming conventions.", "labels": [], "entities": []}, {"text": "For example, some biological species such as yeast use symbolic gene names like tL(CAA)G3, while some other species such as fly use descriptive gene names like wingless.", "labels": [], "entities": []}, {"text": "In this paper, we present several strategies for exploiting the domain structure in the training data to learn a more robust named entity recognizer that can perform well on anew domain.", "labels": [], "entities": []}, {"text": "Our work is motivated by the fact that in many real applications, the training data available to us naturally falls into several domains that are similar in some aspects but different in others.", "labels": [], "entities": []}, {"text": "For example, in biomedical literature, the training data can be naturally grouped by the biological species being discussed, while for news articles, the training data can be divided by the genre, the time, or the news agency of the articles.", "labels": [], "entities": []}, {"text": "Our main idea is to exploit such domain structure in the training data to identify generalizable features which, presumably, are more useful for recognizing named entities in anew domain.", "labels": [], "entities": []}, {"text": "Indeed, named entities across different domains often share certain common features, and it is these common features that are suitable for adaptation to new domains; features that only work fora particular domain would not be as useful as those working for multiple domains.", "labels": [], "entities": []}, {"text": "In biomedical literature, for example, surrounding words such as expression and encode are strong indicators of gene mentions, regardless of the specific biological species being discussed, whereas species-specific name characteristics (e.g., prefix = \"-less\") would clearly not generalize well, and may even hurt the performance on anew domain.", "labels": [], "entities": []}, {"text": "Similarly, in news articles, the part-ofspeeches of surrounding words such as \"followed by a verb\" are more generalizable indicators of name mentions than capitalization, which might be misleading if the genre of the new domain is different; an extreme case is when every letter in the new domain is capitalized.", "labels": [], "entities": []}, {"text": "Based on these intuitions, we regard a feature as generalizable if it is useful for NER in all training domains, and propose a generalizability-based feature ranking method, in which we first rank the features within each training domain, and then combine the rankings to promote the features that are ranked high in all domains.", "labels": [], "entities": [{"text": "NER", "start_pos": 84, "end_pos": 87, "type": "TASK", "confidence": 0.936081051826477}]}, {"text": "We further propose a rankbased prior on logistic regression models, which puts more emphasis on the more generalizable features during the learning stage in a principled way.", "labels": [], "entities": []}, {"text": "Finally, we present a domain-aware validation strategy for setting an appropriate parameter value for the rank-based prior.", "labels": [], "entities": []}, {"text": "We evaluated our method on a biomedical literature data set with annotated gene names from three species, fly, mouse, and yeast, by treating one species as the new domain and the other two as the training domains.", "labels": [], "entities": [{"text": "biomedical literature data set", "start_pos": 29, "end_pos": 59, "type": "DATASET", "confidence": 0.7771111130714417}]}, {"text": "The experiment results show that the proposed method outperforms a baseline method that represents the state-of-the-art NER techniques.", "labels": [], "entities": [{"text": "NER", "start_pos": 120, "end_pos": 123, "type": "TASK", "confidence": 0.9527132511138916}]}, {"text": "The rest of the paper is organized as follows: In Section 2, we introduce a feature ranking method based on the generalizability of features across domains.", "labels": [], "entities": []}, {"text": "In Section 3, we briefly introduce the logistic regression models for NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.8793514370918274}]}, {"text": "We then propose a rankbased prior on logistic regression models and describe the domain-aware validation strategy in Section 4.", "labels": [], "entities": []}, {"text": "The experiment results are presented in Section 5.", "labels": [], "entities": []}, {"text": "Finally we discuss related work in Section 6 and conclude our work in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our domain-aware approach to NER on the problem of gene recognition in biomedical literature.", "labels": [], "entities": [{"text": "NER", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.9911733269691467}, {"text": "gene recognition", "start_pos": 64, "end_pos": 80, "type": "TASK", "confidence": 0.7458819150924683}]}, {"text": "The data we used is from BioCreAtIvE Task 1B ().", "labels": [], "entities": [{"text": "BioCreAtIvE Task 1B", "start_pos": 25, "end_pos": 44, "type": "DATASET", "confidence": 0.7919862469037374}]}, {"text": "We chose this data set because it contains three subsets of MED-LINE abstracts with gene names from three species (fly, mouse, and yeast), while no other existing annotated NER data set has such explicit domain structure.", "labels": [], "entities": [{"text": "NER data set", "start_pos": 173, "end_pos": 185, "type": "DATASET", "confidence": 0.869353731473287}]}, {"text": "The original BioCreAtIvE 1B data was not provided with every gene annotated, but for each abstract, a list of genes that were mentioned in the abstract was given.", "labels": [], "entities": [{"text": "BioCreAtIvE 1B data", "start_pos": 13, "end_pos": 32, "type": "DATASET", "confidence": 0.8287539680798849}]}, {"text": "A gene synonym list was also given for each species.", "labels": [], "entities": []}, {"text": "We used a simple string matching method with slight relaxation to tag the gene mentions in the abstracts.", "labels": [], "entities": [{"text": "string matching", "start_pos": 17, "end_pos": 32, "type": "TASK", "confidence": 0.7326907217502594}]}, {"text": "We took 7500 sentences from each species for our experiments, where half of the sentences contain gene mentions.", "labels": [], "entities": []}, {"text": "We further split the 7500 sentences of each species into two sets, 5000 for training and 2500 for testing.", "labels": [], "entities": []}, {"text": "We conducted three sets of experiments, each combining the 5000-sentence training data of two species as training data, and the 2500-sentence test data of the third species as test data.", "labels": [], "entities": []}, {"text": "The 2500-sentence test data of the training species was used for validation.", "labels": [], "entities": []}, {"text": "We call these three sets of experiments F+M\u21d2Y, F+Y\u21d2M, and M+Y\u21d2F. we use FEX 1 for feature extraction and BBR 2 for logistic regression in our experiments.", "labels": [], "entities": [{"text": "FEX 1", "start_pos": 72, "end_pos": 77, "type": "METRIC", "confidence": 0.9751142263412476}, {"text": "feature extraction", "start_pos": 82, "end_pos": 100, "type": "TASK", "confidence": 0.6560012698173523}, {"text": "BBR", "start_pos": 105, "end_pos": 108, "type": "METRIC", "confidence": 0.996459424495697}]}], "tableCaptions": [{"text": " Table 1: Comparison of the domain-aware method  and the baseline method, where in the domain-aware  method, b = 0.5b 1 + 0.5b 2", "labels": [], "entities": []}]}