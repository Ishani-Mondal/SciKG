{"title": [], "abstractContent": [{"text": "In this paper, we introduce a methodology for analyzing judgment opinions.", "labels": [], "entities": []}, {"text": "We define a judgment opinion as consisting of a valence, a holder, and a topic.", "labels": [], "entities": []}, {"text": "We decompose the task of opinion analysis into four parts: 1) recognizing the opinion; 2) identifying the valence; 3) identifying the holder; and 4) identifying the topic.", "labels": [], "entities": [{"text": "opinion analysis", "start_pos": 25, "end_pos": 41, "type": "TASK", "confidence": 0.7592076659202576}]}, {"text": "In this paper, we address the first three parts and evaluate our methodology using both intrinsic and extrinsic measures.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently, many researchers and companies have explored the area of opinion detection and analysis.", "labels": [], "entities": [{"text": "opinion detection and analysis", "start_pos": 67, "end_pos": 97, "type": "TASK", "confidence": 0.7919196784496307}]}, {"text": "With the increased immersion of Internet users has come a proliferation of opinions available on the web.", "labels": [], "entities": []}, {"text": "Not only do we read more opinions from the web, such as in daily news editorials, but also we post more opinions through mechanisms such as governmental web sites, product review sites, newsgroup message boards and personal blogs.", "labels": [], "entities": []}, {"text": "This phenomenon has opened the door for massive opinion collection, which has potential impact on various applications such as public opinion monitoring and product review summary systems.", "labels": [], "entities": [{"text": "opinion collection", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.7469720244407654}, {"text": "public opinion monitoring", "start_pos": 127, "end_pos": 152, "type": "TASK", "confidence": 0.6786534786224365}]}, {"text": "Although in its infancy, many researchers have worked in various facets of opinion analysis. and classified sentiment polarity of reviews at the document level.", "labels": [], "entities": [{"text": "opinion analysis.", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.7326131016016006}]}, {"text": "classified sentence level subjectivity using syntactic classes such as adjectives, pronouns and modal verbs as features.", "labels": [], "entities": []}, {"text": "extracted subjective expressions from sentences using a bootstrapping pattern learning process.", "labels": [], "entities": []}, {"text": "identified the polarity of opinion sentences using semantically oriented words.", "labels": [], "entities": []}, {"text": "These techniques were applied and examined in different domains, such as customer reviews (Hu and Liu 2004) and news articles . These researchers use lists of opinion-bearing clue words and phrases, and then apply various additional techniques and refinements.", "labels": [], "entities": []}, {"text": "Along with many opinion researchers, we participated in a large pilot study, sponsored by NIST, which concluded that it is very difficult to define what an opinion is in general.", "labels": [], "entities": [{"text": "NIST", "start_pos": 90, "end_pos": 94, "type": "DATASET", "confidence": 0.9325064420700073}]}, {"text": "Moreover, an expression that is considered as an opinion in one domain might not bean opinion in another.", "labels": [], "entities": []}, {"text": "For example, the statement \"The screen is very big\" might be a positive review fora widescreen desktop review, but it could be a mere fact in general newspaper text.", "labels": [], "entities": []}, {"text": "This implies that it is hard to apply opinion bearing words collected from one domain to an application for another domain.", "labels": [], "entities": []}, {"text": "One might therefore need to collect opinion clues within individual domains.", "labels": [], "entities": []}, {"text": "In case we cannot simply find training data from existing sources, such as news article analysis, we need to manually annotate data first.", "labels": [], "entities": [{"text": "news article analysis", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.630500594774882}]}, {"text": "Most opinions are of two kinds: 1) beliefs about the world, with values such as true, false, possible, unlikely, etc.; and 2) judgments about the world, with values such as good, bad, neutral, wise, foolish, virtuous, etc.", "labels": [], "entities": []}, {"text": "Statements like \"I believe that he is smart\" and \"Stock prices will rise soon\" are examples of beliefs whereas \"I like the new policy on social security\" and \"Unfortunately this really was his year: despite a stagnant economy, he still won his re-election\" are examples of judgment opinions.", "labels": [], "entities": []}, {"text": "However, judgment opinions and beliefs are not necessarily mutually exclusive.", "labels": [], "entities": []}, {"text": "For example, \"I think it is an outrage\" or \"I believe that he is smart\" carry both a belief and a judgment.", "labels": [], "entities": []}, {"text": "In the NIST pilot study, it was apparent that human annotators often disagreed on whether a belief statement was or was not an opinion.", "labels": [], "entities": [{"text": "NIST pilot study", "start_pos": 7, "end_pos": 23, "type": "DATASET", "confidence": 0.8984485665957133}]}, {"text": "However, high annotator agreement was seen on judg-1 TREC novelty track ment opinions.", "labels": [], "entities": [{"text": "agreement", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.5255774855613708}, {"text": "judg-1 TREC novelty track ment opinions", "start_pos": 46, "end_pos": 85, "type": "DATASET", "confidence": 0.8860357602437338}]}, {"text": "In this paper, we therefore focus our analysis on judgment opinions only.", "labels": [], "entities": []}, {"text": "We hope that future work yields a more precise definition of belief opinions on which human annotators can agree.", "labels": [], "entities": []}, {"text": "We define a judgment opinion as consisting of three elements: a valence, a holder, and a topic.", "labels": [], "entities": []}, {"text": "The valence, which applies specifically to judgment opinions and not beliefs, is the value of the judgment.", "labels": [], "entities": [{"text": "valence", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9921565055847168}]}, {"text": "In our framework, we consider the following valences: positive, negative, and neutral.", "labels": [], "entities": []}, {"text": "The holder of an opinion is the person, organization or group whose opinion is expressed.", "labels": [], "entities": []}, {"text": "Finally, the topic is the event or entity about which the opinion is held.", "labels": [], "entities": []}, {"text": "In previous work, identify opinion holders (sources) using Conditional Random Fields (CRF) and extraction patterns.", "labels": [], "entities": []}, {"text": "They define the opinion holder identification problem as a sequence tagging task: given a sequence of words ( ) in a sentence, they generate a sequence of labels ( ) indicating whether the word is a holder or not.", "labels": [], "entities": [{"text": "opinion holder identification problem", "start_pos": 16, "end_pos": 53, "type": "TASK", "confidence": 0.734121635556221}, {"text": "sequence tagging", "start_pos": 59, "end_pos": 75, "type": "TASK", "confidence": 0.7597522735595703}]}, {"text": "However, there are many cases where multiple opinions are expressed in a sentence each with its own holder.", "labels": [], "entities": []}, {"text": "In those cases, finding opinion holders for each individual expression is necessary.", "labels": [], "entities": []}, {"text": "In the corpus they used, 48.5% of the sentences which contain an opinion have more than one opinion expression with multiple opinion holders.", "labels": [], "entities": []}, {"text": "This implies that multiple opinion expressions in a sentence occur significantly often.", "labels": [], "entities": []}, {"text": "A major challenge of our work is therefore not only to focus on sentence with only one opinion, but also to identify opinion holders when there is more than one opinion expressed in a sentence.", "labels": [], "entities": [{"text": "identify opinion holders", "start_pos": 108, "end_pos": 132, "type": "TASK", "confidence": 0.615055630604426}]}, {"text": "For example, consider the sentence \"In relation to Bush's axis of evil remarks, the German Foreign Minister also said, Allies are not satellites, and the French Foreign Minister caustically criticized that the United States' unilateral, simplistic worldview poses anew threat to the world\".", "labels": [], "entities": []}, {"text": "Here, \"the German Foreign Minister\" should be the holder for the opinion \"Allies are not satellites\" and \"the French Foreign Minister\" should be the holder for \"caustically criticized\".", "labels": [], "entities": []}, {"text": "In this paper, we introduce a methodology for analyzing judgment opinions.", "labels": [], "entities": []}, {"text": "We decompose the task into four parts: 1) recognizing the opinion; 2) identifying the valence; 3) identifying the holder; and 4) identifying the topic.", "labels": [], "entities": [{"text": "identifying the valence", "start_pos": 70, "end_pos": 93, "type": "TASK", "confidence": 0.8011584281921387}, {"text": "identifying the topic", "start_pos": 129, "end_pos": 150, "type": "TASK", "confidence": 0.8241340517997742}]}, {"text": "For the purposes of this paper, we address the first three parts and leave the last for future work.", "labels": [], "entities": []}, {"text": "Opinions can be extracted from various granularities such as a word, a sentence, a text, or even multiple texts.", "labels": [], "entities": []}, {"text": "Each is important, but we focus our attention on wordlevel opinion detection (Section 2.1) and the detection of opinions in short emails (Section 3).", "labels": [], "entities": [{"text": "wordlevel opinion detection", "start_pos": 49, "end_pos": 76, "type": "TASK", "confidence": 0.616269459327062}, {"text": "detection of opinions in short emails", "start_pos": 99, "end_pos": 136, "type": "TASK", "confidence": 0.8249544004599253}]}, {"text": "We evaluate our methodology using intrinsic and extrinsic measures.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In the next section, we describe our methodology addressing the three steps described above, and in Section 4 we present our experimental results.", "labels": [], "entities": []}, {"text": "We conclude with a discussion of future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate the three systems described in Sections 2 and 3: detecting opinionbearing words and identifying valence, identifying opinion holders, and the German email opinion analysis system.", "labels": [], "entities": [{"text": "detecting opinionbearing words", "start_pos": 78, "end_pos": 108, "type": "TASK", "confidence": 0.8120120565096537}, {"text": "identifying opinion holders", "start_pos": 134, "end_pos": 161, "type": "TASK", "confidence": 0.6962646245956421}, {"text": "German email opinion analysis", "start_pos": 171, "end_pos": 200, "type": "TASK", "confidence": 0.7507127225399017}]}], "tableCaptions": [{"text": " Table 5: Word distribution in our gold standard", "labels": [], "entities": [{"text": "Word distribution", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.800573319196701}]}, {"text": " Table 6: Precision, recall, and F-score on word va- lence categorization for Positive (P), Negative (N)  and Neutral (X) verbs (V) and adjectives (A) (with  95% confidence intervals)", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9986934065818787}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9990068078041077}, {"text": "F-score", "start_pos": 33, "end_pos": 40, "type": "METRIC", "confidence": 0.9989629983901978}]}, {"text": " Table 8: Opinion holder identification results (All  noun phrases as candidates)", "labels": [], "entities": [{"text": "Opinion holder identification", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.7183763384819031}]}, {"text": " Table 9: German email opinion analysis system results", "labels": [], "entities": [{"text": "German email opinion analysis", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.6556321382522583}]}]}