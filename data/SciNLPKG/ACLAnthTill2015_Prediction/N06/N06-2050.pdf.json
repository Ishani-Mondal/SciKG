{"title": [{"text": "Comparing the roles of textual, acoustic and spoken-language features on spontaneous-conversation summarization", "labels": [], "entities": [{"text": "summarization", "start_pos": 98, "end_pos": 111, "type": "TASK", "confidence": 0.5374026298522949}]}], "abstractContent": [{"text": "This paper is concerned with the summarization of spontaneous conversations.", "labels": [], "entities": [{"text": "summarization of spontaneous conversations", "start_pos": 33, "end_pos": 75, "type": "TASK", "confidence": 0.8917006105184555}]}, {"text": "Compared with broadcast news, which has received intensive study, spontaneous conversations have been less addressed in the literature.", "labels": [], "entities": []}, {"text": "Previous work has focused on textual features extracted from transcripts.", "labels": [], "entities": []}, {"text": "This paper explores and compares the effectiveness of both textual features and speech-related features.", "labels": [], "entities": []}, {"text": "The experiments show that these features incrementally improve summarization performance.", "labels": [], "entities": [{"text": "summarization", "start_pos": 63, "end_pos": 76, "type": "TASK", "confidence": 0.9838821887969971}]}, {"text": "We also find that speech disfluencies, which have been removed as noise in previous work, help identify important utterances, while the structural feature is less effective than it is in broadcast news.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spontaneous conversations area very important type of speech data.", "labels": [], "entities": []}, {"text": "Distilling important information from them has commercial and other importance.", "labels": [], "entities": [{"text": "Distilling important information", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8820755283037821}]}, {"text": "Compared with broadcast news, which has received the most intensive studies (), spontaneous conversations have been less addressed in the literature.", "labels": [], "entities": []}, {"text": "Spontaneous conversations are different from broadcast news in several aspects: (1) spontaneous conversations are often less well formed linguistically, e.g., containing more speech disfluencies and false starts; (2) the distribution of important utterances in spontaneous conversations could be different from that in broadcast news, e.g., the beginning part of news often contains important information, but in conversations, information maybe more evenly distributed; conversations often contain discourse clues, e.g., question-answer pairs and speakers' information, which can be utilized to keep the summary coherent; (4) word error rates (WERs) from speech recognition are usually much higher in spontaneous conversations.", "labels": [], "entities": [{"text": "word error rates (WERs)", "start_pos": 627, "end_pos": 650, "type": "METRIC", "confidence": 0.8902381658554077}, {"text": "speech recognition", "start_pos": 656, "end_pos": 674, "type": "TASK", "confidence": 0.7100291401147842}]}, {"text": "Previous work on spontaneous-conversation summarization has mainly focused on textual features), while speech-related features have not been explored for this type of speech source.", "labels": [], "entities": [{"text": "spontaneous-conversation summarization", "start_pos": 17, "end_pos": 55, "type": "TASK", "confidence": 0.5937684178352356}]}, {"text": "This paper explores and compares the effectiveness of both textual features and speech-related features.", "labels": [], "entities": []}, {"text": "The experiments show that these features incrementally improve summarization performance.", "labels": [], "entities": [{"text": "summarization", "start_pos": 63, "end_pos": 76, "type": "TASK", "confidence": 0.9838821887969971}]}, {"text": "We also discuss problems (1) and (2) mentioned above.", "labels": [], "entities": []}, {"text": "For (1), proposes to detect and remove false starts and speech disfluencies from transcripts, in order to make the text-format summary concise and more readable.", "labels": [], "entities": []}, {"text": "Nevertheless, it is not always necessary to remove them.", "labels": [], "entities": []}, {"text": "One reason is that original utterances are often more desired to ensure comprehensibility and naturalness if the summaries are to be delivered as excerpts of audio (see section 2), in order to avoid the impact of WER.", "labels": [], "entities": [{"text": "WER", "start_pos": 213, "end_pos": 216, "type": "METRIC", "confidence": 0.5810458064079285}]}, {"text": "Second, disfluencies are not necessarily noise; instead, they show regularities in a number of dimensions, and correlate with many factors including topic difficulty).", "labels": [], "entities": []}, {"text": "Rather than removing them, we explore the effects of disfluencies on summarization, which, to our knowledge, has not yet been addressed in the literature.", "labels": [], "entities": [{"text": "summarization", "start_pos": 69, "end_pos": 82, "type": "TASK", "confidence": 0.980095624923706}]}, {"text": "Our experiments show that they improve summarization performance.", "labels": [], "entities": [{"text": "summarization", "start_pos": 39, "end_pos": 52, "type": "TASK", "confidence": 0.9908344745635986}]}, {"text": "To discuss problem (2), we explore and compare both textual features and speech-related features, as they are explored in broadcast news).", "labels": [], "entities": []}, {"text": "The experiments show that the structural feature (e.g. utterance position) is less effective for summarizing spontaneous conversations than it is in broadcast news.", "labels": [], "entities": [{"text": "summarizing spontaneous conversations", "start_pos": 97, "end_pos": 134, "type": "TASK", "confidence": 0.9191480080286661}]}, {"text": "MMR and lexical features are the best.", "labels": [], "entities": [{"text": "MMR", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8522527813911438}]}, {"text": "The structural feature is least effective.", "labels": [], "entities": []}, {"text": "We do not discuss problem (3) and (4) in this paper.", "labels": [], "entities": []}, {"text": "For problem (3), a similar idea has been proposed to summarize online blogs and discussions.", "labels": [], "entities": [{"text": "summarize online blogs and discussions", "start_pos": 53, "end_pos": 91, "type": "TASK", "confidence": 0.8887882232666016}]}, {"text": "Problem (4) has been partially addressed by; but it has not been studied together with acoustic features.", "labels": [], "entities": []}], "datasetContent": [{"text": "The data used for our experiments come from SWITCHBOARD.", "labels": [], "entities": []}, {"text": "We randomly select 27 conversations, containing around 3660 utterances.", "labels": [], "entities": []}, {"text": "The important utterances of each conversation are manually annotated.", "labels": [], "entities": []}, {"text": "We use f-score and the ROUGE score as evaluation metrics.", "labels": [], "entities": [{"text": "ROUGE score", "start_pos": 23, "end_pos": 34, "type": "METRIC", "confidence": 0.980459064245224}]}, {"text": "Ten-fold cross validation is applied to obtain the results presented in this section.", "labels": [], "entities": []}, {"text": "The ROUGE-1 scores show similar tendencies to the f-scores: the rich features improve summarization performance over the baseline MMR summarizers.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9789559841156006}, {"text": "summarization", "start_pos": 86, "end_pos": 99, "type": "TASK", "confidence": 0.9736680388450623}]}, {"text": "Other ROUGE scores like ROUGE-L show the same tendency, but are not presented here due to the space limit.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 6, "end_pos": 11, "type": "METRIC", "confidence": 0.9068644046783447}, {"text": "ROUGE-L", "start_pos": 24, "end_pos": 31, "type": "METRIC", "confidence": 0.7097197771072388}]}], "tableCaptions": [{"text": " Table-1 shows the f-score of logistic regression  (LR) based summarizers, under different  compression ratios, and with incremental features  used.", "labels": [], "entities": []}, {"text": " Table 3. ROUGE-1 of LR summarizers using incremental features", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9806194305419922}, {"text": "LR summarizers", "start_pos": 21, "end_pos": 35, "type": "TASK", "confidence": 0.7114201784133911}]}, {"text": " Table 5. Average tf.idf scores of words following filled pauses.", "labels": [], "entities": [{"text": "Average tf.idf scores", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.9205200473467509}]}]}