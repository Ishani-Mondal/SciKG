{"title": [], "abstractContent": [{"text": "We present a PCFG parsing algorithm that uses a multilevel coarse-to-fine (mlctf) scheme to improve the efficiency of search for the best parse.", "labels": [], "entities": [{"text": "PCFG parsing", "start_pos": 13, "end_pos": 25, "type": "TASK", "confidence": 0.760606050491333}]}, {"text": "Our approach requires the user to specify a sequence of nested partitions or equivalence classes of the PCFG non-terminals.", "labels": [], "entities": []}, {"text": "We define a sequence of PCFGs corresponding to each partition , where the nonterminals of each PCFG are clusters of nonterminals of the original source PCFG.", "labels": [], "entities": []}, {"text": "We use the results of parsing at a coarser level (i.e., grammar defined in terms of a coarser partition) to prune the next finer level.", "labels": [], "entities": []}, {"text": "We present experiments showing that with our algorithm the workload (as measured by the total number of constituents processed) is decreased by a factor often with no decrease in parsing accuracy compared to standard CKY parsing with the original PCFG.", "labels": [], "entities": [{"text": "parsing", "start_pos": 179, "end_pos": 186, "type": "TASK", "confidence": 0.962258517742157}, {"text": "accuracy", "start_pos": 187, "end_pos": 195, "type": "METRIC", "confidence": 0.8614636063575745}, {"text": "CKY parsing", "start_pos": 217, "end_pos": 228, "type": "TASK", "confidence": 0.5712487101554871}, {"text": "PCFG", "start_pos": 247, "end_pos": 251, "type": "DATASET", "confidence": 0.9427977204322815}]}, {"text": "We suggest that the search space over mlctf algorithms is almost totally unexplored so that future work should be able to improve significantly on these results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Reasonably accurate constituent-based parsing is fairly quick these days, if fairly quick means about a second per sentence.", "labels": [], "entities": [{"text": "constituent-based parsing", "start_pos": 20, "end_pos": 45, "type": "TASK", "confidence": 0.5733102858066559}]}, {"text": "Unfortunately, this is still too slow for many applications.", "labels": [], "entities": []}, {"text": "In some cases researchers need large quantities of parsed data and do not have the hundreds of machines necessary to parse gigaword corpora in a week or two.", "labels": [], "entities": []}, {"text": "More pressingly, in real-time applications such as speech recognition, a parser would be only apart of a much larger system, and the system builders are not keen on giving the parser one of the ten seconds available to process, say, a thirty-word sentence.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.759505420923233}]}, {"text": "Even worse, some applications require the parsing of multiple candidate strings per sentence) or parsing from a lattice (, and in these applications parsing efficiency is even more important.", "labels": [], "entities": []}, {"text": "We present here a multilevel coarse-to-fine (mlctf) PCFG parsing algorithm that reduces the complexity of the search involved in finding the best parse.", "labels": [], "entities": [{"text": "PCFG parsing", "start_pos": 52, "end_pos": 64, "type": "TASK", "confidence": 0.759075254201889}]}, {"text": "It defines a sequence of increasingly more complex PCFGs, and uses the parse forest produced by one PCFG to prune the search of the next more complex PCFG.", "labels": [], "entities": []}, {"text": "We currently use four levels of grammars in our mlctf algorithm.", "labels": [], "entities": []}, {"text": "The simplest PCFG, which we call the level-0 grammar, contains only one nontrivial nonterminal and is so simple that minimal time is needed to parse a sentence using it.", "labels": [], "entities": []}, {"text": "Nonetheless, we demonstrate that it identifies the locations of correct constituents of the parse tree (the \"gold constituents\") with high recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 139, "end_pos": 145, "type": "METRIC", "confidence": 0.9986996650695801}]}, {"text": "Our level-1 grammar distinguishes only argument from modifier phrases (i.e., it has two nontrivial nonterminals), while our level-2 grammar distinguishes the four major phrasal categories (verbal, nominal, adjectival and prepositional phrases), and level 3 distinguishes all of the standard categories of the Penn treebank.", "labels": [], "entities": [{"text": "Penn treebank", "start_pos": 309, "end_pos": 322, "type": "DATASET", "confidence": 0.9870037138462067}]}, {"text": "The nonterminal categories in these grammars can be regarded as clusters or equivalence classes of the original Penn treebank nonterminal categories.", "labels": [], "entities": [{"text": "Penn treebank nonterminal categories", "start_pos": 112, "end_pos": 148, "type": "DATASET", "confidence": 0.9339272379875183}]}, {"text": "(In fact, we obtain these grammars by relabeling the node labels in the treebank and extracting a PCFG from this relabelled treebank in the standard fashion, but we discuss other approaches below.)", "labels": [], "entities": []}, {"text": "We require that the partition of the nonterminals defined by the equivalence classes at level l + 1 be a refinement of the partition defined at level l.", "labels": [], "entities": []}, {"text": "This means that each nonterminal category at level l+1 is mapped to a unique nonterminal category at level l (although in general the mapping is many to one, i.e., each nonterminal category at level l corresponds to several nonterminal categories at level l + 1).", "labels": [], "entities": []}, {"text": "We use the correspondence between categories at different levels to prune possible constituents.", "labels": [], "entities": []}, {"text": "A constituent is considered at level l + 1 only if the corresponding constituent at level l has a probability exceeding some threshold..", "labels": [], "entities": []}, {"text": "Thus parsing a sentence proceeds as follows.", "labels": [], "entities": []}, {"text": "We first parse the sentence with the level-0 grammar to produce a parse forest using the CKY parsing algorithm.", "labels": [], "entities": [{"text": "CKY parsing", "start_pos": 89, "end_pos": 100, "type": "TASK", "confidence": 0.7685259580612183}]}, {"text": "Then for each level l + 1 we reparse the sentence with the level l + 1 grammar using the level l parse forest to prune as described above.", "labels": [], "entities": []}, {"text": "As we demonstrate, this leads to considerable efficiency improvements.", "labels": [], "entities": []}, {"text": "The paper proceeds as follows.", "labels": [], "entities": []}, {"text": "We next discuss previous work (Section 2).", "labels": [], "entities": []}, {"text": "Section 3 outlines the algorithm in more detail.", "labels": [], "entities": []}, {"text": "Section 4 presents some experiments showing that the workload (as measured by the total number of constituents processed) is decreased by a factor often over standard CKY parsing at the final level.", "labels": [], "entities": [{"text": "CKY parsing", "start_pos": 167, "end_pos": 178, "type": "TASK", "confidence": 0.7353389859199524}]}, {"text": "We also discuss some fine points of the results therein.", "labels": [], "entities": []}, {"text": "Finally in section 5 we suggest that because the search space of mlctf algorithms is, at this point, almost totally unexplored, future work should be able to improve significantly on these results.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}