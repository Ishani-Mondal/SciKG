{"title": [{"text": "Exploiting Semantic Role Labeling, WordNet and Wikipedia for Coreference Resolution", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.6614643136660258}, {"text": "Coreference Resolution", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.975735604763031}]}], "abstractContent": [{"text": "In this paper we present an extension of a machine learning based coreference resolution system which uses features induced from different semantic knowledge sources.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 66, "end_pos": 88, "type": "TASK", "confidence": 0.7672244012355804}]}, {"text": "These features represent knowledge mined from WordNet and Wikipedia, as well as information about semantic role labels.", "labels": [], "entities": []}, {"text": "We show that semantic features indeed improve the performance on different referring expression types such as pronouns and common nouns.", "labels": [], "entities": []}], "introductionContent": [{"text": "The last years have seen a boost of work devoted to the development of machine learning based coreference resolution systems (, inter alia).", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 94, "end_pos": 116, "type": "TASK", "confidence": 0.7346591055393219}]}, {"text": "While machine learning has proved to yield performance rates fully competitive with rule based systems, current coreference resolution systems are mostly relying on rather shallow features, such as the distance between the coreferent expressions, string matching, and linguistic form.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 112, "end_pos": 134, "type": "TASK", "confidence": 0.9169894158840179}, {"text": "string matching", "start_pos": 247, "end_pos": 262, "type": "TASK", "confidence": 0.7134675681591034}]}, {"text": "However, the literature emphasizes since the very beginning the relevance of world knowledge and inference for coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 111, "end_pos": 133, "type": "TASK", "confidence": 0.9729492664337158}]}, {"text": "This paper explores whether coreference resolution can benefit from semantic knowledge sources.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.9833270907402039}]}, {"text": "More specifically, whether a machine learning based approach to coreference resolution can be improved and which phenomena are affected by such information.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 64, "end_pos": 86, "type": "TASK", "confidence": 0.967975527048111}]}, {"text": "We investigate the use of the WordNet and Wikipedia taxonomies for extracting semantic similarity and relatedness measures, as well as semantic parsing information in terms of semantic role labeling, SRL henceforth).", "labels": [], "entities": [{"text": "WordNet and Wikipedia taxonomies", "start_pos": 30, "end_pos": 62, "type": "DATASET", "confidence": 0.7713708430528641}, {"text": "semantic parsing information", "start_pos": 135, "end_pos": 163, "type": "TASK", "confidence": 0.8010457356770834}, {"text": "semantic role labeling", "start_pos": 176, "end_pos": 198, "type": "TASK", "confidence": 0.6491467456022898}]}, {"text": "We believe that the lack of semantics in the current systems leads to a performance bottleneck.", "labels": [], "entities": []}, {"text": "In order to correctly identify the discourse entities which are referred to in a text, it seems essential to reason over the lexical semantic relations, as well as the event representations embedded in the text.", "labels": [], "entities": []}, {"text": "As an example, consider a fragment from the Automatic Content Extraction (ACE) 2003 data.", "labels": [], "entities": [{"text": "Automatic Content Extraction (ACE) 2003 data", "start_pos": 44, "end_pos": 88, "type": "DATASET", "confidence": 0.6834785118699074}]}, {"text": "(1) But frequent visitors say that given the sheer weight of the country's totalitarian ideology and generations of mass indoctrination, changing this country's course will be something akin to turning a huge ship at sea.", "labels": [], "entities": []}, {"text": "Opening North Korea up, even modestly, and exposing people to the idea that Westerners -and South Koreans -are not devils, alone represents an extraordinary change.", "labels": [], "entities": []}, {"text": "as his people begin to get a clearer idea of the deprivation they have suffered, especially relative to their neighbors.", "labels": [], "entities": []}, {"text": "\"This is a society that has been focused most of all on stability,\".", "labels": [], "entities": []}, {"text": "In order to correctly resolve the anaphoric expressions highlighted in bold, it seems that some kind of lexical semantic and encyclopedic knowledge is required.", "labels": [], "entities": []}, {"text": "This includes that North Korea is a country, that countries consist of people and are societies.", "labels": [], "entities": []}, {"text": "The resolution requires an encyclopedia (i.e. Wikipedia) look-up and reasoning on the content relatedness holding between the different expressions (i.e. as a path measure along the links of the WordNet and Wikipedia taxonomies).", "labels": [], "entities": [{"text": "resolution", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9656665325164795}, {"text": "WordNet and Wikipedia taxonomies", "start_pos": 195, "end_pos": 227, "type": "DATASET", "confidence": 0.7742980271577835}]}, {"text": "Event representations seem also to be important for coreference resolution, as shown below: (2) A state commission of inquiry into the sinking of the Kursk will convene in Moscow on Wednesday, the Interfax news agency reported.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.993274599313736}, {"text": "Interfax news agency", "start_pos": 197, "end_pos": 217, "type": "DATASET", "confidence": 0.9770689606666565}]}, {"text": "It said that the diving operation will be completed by the end of next week.", "labels": [], "entities": [{"text": "diving", "start_pos": 17, "end_pos": 23, "type": "TASK", "confidence": 0.9635804891586304}]}, {"text": "In this example, knowing that the Interfax news agency is the AGENT of the report predicate and It being the AGENT of say could trigger the (semantic parallelism based) inference required to correctly link the two expressions, in contrast to anchoring the pronoun to Moscow.", "labels": [], "entities": [{"text": "Interfax news agency", "start_pos": 34, "end_pos": 54, "type": "DATASET", "confidence": 0.9645233949025472}, {"text": "AGENT", "start_pos": 62, "end_pos": 67, "type": "METRIC", "confidence": 0.964673638343811}]}, {"text": "SRL provides the semantic relationships that constituents have with predicates, thus allowing us to include such documentlevel event descriptive information into the relations holding between referring expressions (REs).", "labels": [], "entities": []}, {"text": "Instead of exploring different kinds of data representations, task definitions or machine learning techniques) we focus on a few promising semantic features which we evaluate in a controlled environment.", "labels": [], "entities": []}, {"text": "That way we try to overcome the plateauing in performance in coreference resolution observed by.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.9241383075714111}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Partitions of the ACE 2003 training data corpus", "labels": [], "entities": [{"text": "ACE 2003 training data", "start_pos": 28, "end_pos": 50, "type": "DATASET", "confidence": 0.9567951709032059}]}, {"text": " Table 2: Results on MUC", "labels": [], "entities": [{"text": "MUC", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.6934194564819336}]}, {"text": " Table 3: Results on the ACE 2003 data (BNEWS and NWIRE sections)", "labels": [], "entities": [{"text": "ACE 2003 data", "start_pos": 25, "end_pos": 38, "type": "DATASET", "confidence": 0.9543046156565348}, {"text": "BNEWS", "start_pos": 40, "end_pos": 45, "type": "DATASET", "confidence": 0.8936336636543274}, {"text": "NWIRE", "start_pos": 50, "end_pos": 55, "type": "DATASET", "confidence": 0.68892902135849}]}, {"text": " Table 4: Results ACE (merged BNEWS/NWIRE)", "labels": [], "entities": [{"text": "ACE", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.6123960018157959}, {"text": "BNEWS/NWIRE)", "start_pos": 30, "end_pos": 42, "type": "DATASET", "confidence": 0.7906146198511124}]}]}