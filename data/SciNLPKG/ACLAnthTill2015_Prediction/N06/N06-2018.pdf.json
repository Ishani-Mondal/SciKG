{"title": [{"text": "MMR-based Active Machine Learning for Bio Named Entity Recognition", "labels": [], "entities": [{"text": "MMR-based Active Machine Learning", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8194941729307175}, {"text": "Bio Named Entity Recognition", "start_pos": 38, "end_pos": 66, "type": "TASK", "confidence": 0.6741450875997543}]}], "abstractContent": [{"text": "This paper presents anew active learning paradigm which considers not only the uncertainty of the classifier but also the diversity of the corpus.", "labels": [], "entities": []}, {"text": "The two measures for uncertainty and diversity were combined using the MMR (Maximal Marginal Relevance) method to give the sampling scores in our active learning strategy.", "labels": [], "entities": [{"text": "MMR (Maximal Marginal Relevance)", "start_pos": 71, "end_pos": 103, "type": "METRIC", "confidence": 0.7374790807565054}]}, {"text": "We incorporated MMR-based active machine-learning idea into the biomedical named-entity recognition system.", "labels": [], "entities": [{"text": "biomedical named-entity recognition", "start_pos": 64, "end_pos": 99, "type": "TASK", "confidence": 0.6396919588247935}]}, {"text": "Our experimental results indicated that our strategies for active-learning based sample selection could significantly reduce the human effort .", "labels": [], "entities": []}], "introductionContent": [{"text": "Named-entity recognition is one of the most elementary and core problems in biomedical text mining.", "labels": [], "entities": [{"text": "Named-entity recognition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.752617746591568}, {"text": "biomedical text mining", "start_pos": 76, "end_pos": 98, "type": "TASK", "confidence": 0.6674099663893381}]}, {"text": "To achieve good recognition performance, we use a supervised machine-learning based approach which is a standard in the named-entity recognition task.", "labels": [], "entities": [{"text": "named-entity recognition task", "start_pos": 120, "end_pos": 149, "type": "TASK", "confidence": 0.7940206428368887}]}, {"text": "The obstacle of supervised machine-learning methods is the lack of the annotated training data which is essential for achieving good performance.", "labels": [], "entities": []}, {"text": "Building a training corpus manually is time consuming, labor intensive, and expensive.", "labels": [], "entities": []}, {"text": "Creating training corpora for the biomedical domain is particularly expensive as it requires domain specific expert knowledge.", "labels": [], "entities": []}, {"text": "One way to solve this problem is through active learning method to select the most informative samples for training.", "labels": [], "entities": []}, {"text": "Active selection of the training examples can significantly reduce the necessary number of labeled training examples without degrading the performance.", "labels": [], "entities": []}, {"text": "Existing work for active learning explores two approaches: certainty or uncertainty-based methods () and committee-based methods.", "labels": [], "entities": []}, {"text": "Uncertainty-based systems begin with an initial classifier and the systems assign some uncertainty scores to the un-annotated examples.", "labels": [], "entities": []}, {"text": "The k examples with the highest scores will be annotated by human experts and the classifier will be retrained.", "labels": [], "entities": []}, {"text": "In the committee-based systems, diverse committees of classifiers were generated.", "labels": [], "entities": []}, {"text": "Each committee member will examine the un-annotated examples.", "labels": [], "entities": []}, {"text": "The degree of disagreement among the committee members will be evaluated and the examples with the highest disagreement will be selected for manual annotation.", "labels": [], "entities": []}, {"text": "Our efforts are different from the previous active learning approaches and are devoted to two aspects: we propose an entropy-based measure to quantify the uncertainty that the current classifier holds.", "labels": [], "entities": []}, {"text": "The most uncertain samples are selected for human annotation.", "labels": [], "entities": []}, {"text": "However, we also assume that the selected training samples should give the different aspects of learning features to the classification system.", "labels": [], "entities": []}, {"text": "So, we try to catch the most representative sentences in each sampling.", "labels": [], "entities": []}, {"text": "The divergence measures of the two sentences are for the novelty of the features and their representative levels, and are described by the minimum similarity among the examples.", "labels": [], "entities": []}, {"text": "The two measures for uncertainty and diversity will be combined using the MMR (Maximal Marginal Relevance) method to give the sampling scores in our active learning strategy.", "labels": [], "entities": [{"text": "MMR (Maximal Marginal Relevance)", "start_pos": 74, "end_pos": 106, "type": "METRIC", "confidence": 0.7556380828221639}]}, {"text": "We incorporate MMR-based active machinelearning idea into the POSBIOTM/NER) system which is a trainable biomedical named-entity recognition system using the Conditional Random Fields () machine learning technique to automatically identify different sets of biological entities in the text.", "labels": [], "entities": [{"text": "POSBIOTM/NER)", "start_pos": 62, "end_pos": 75, "type": "DATASET", "confidence": 0.750258207321167}, {"text": "biomedical named-entity recognition", "start_pos": 104, "end_pos": 139, "type": "TASK", "confidence": 0.6700571775436401}]}, {"text": "2 MMR-based Active Learning for Biomedical Named-entity Recognition", "labels": [], "entities": [{"text": "Biomedical Named-entity Recognition", "start_pos": 32, "end_pos": 67, "type": "TASK", "confidence": 0.6232200463612875}]}], "datasetContent": [{"text": "We conducted our active learning experiments using pool-based sample selection (.", "labels": [], "entities": []}, {"text": "The pool-based sample selection, in which the learner chooses the best instances for labeling from a given pool of unlabelled examples, is the most practical approach for problems in which unlabelled data is relatively easily available.", "labels": [], "entities": []}, {"text": "For our empirical evaluation of the active learning methods, we used the training and test data released by JNLPBA ().", "labels": [], "entities": [{"text": "JNLPBA", "start_pos": 108, "end_pos": 114, "type": "DATASET", "confidence": 0.9600077271461487}]}, {"text": "The training corpus contains 2000 MEDLINE abstracts, and the test data contains 404 abstracts from the GENIA corpus.", "labels": [], "entities": [{"text": "GENIA corpus", "start_pos": 103, "end_pos": 115, "type": "DATASET", "confidence": 0.9698847532272339}]}, {"text": "100 abstracts were used to train our initial NER module.", "labels": [], "entities": [{"text": "NER module", "start_pos": 45, "end_pos": 55, "type": "TASK", "confidence": 0.8456850051879883}]}, {"text": "The remaining training data were taken as the pool.", "labels": [], "entities": []}, {"text": "Each time, we chose k examples from the given pool to train the new NER module and the number k varied from 1000 to 17000 with a step size 1000.", "labels": [], "entities": [{"text": "NER module", "start_pos": 68, "end_pos": 78, "type": "DATASET", "confidence": 0.7291276156902313}]}, {"text": "We test 4 different active learning methods: Random selection, Entropy-based uncertainty selection, Entropy combined with Diversity, and Normalized Entropy (equation) combined with Diversity.", "labels": [], "entities": []}, {"text": "When we compute the active learning score using the entropy based method and the combining methods we set the values of parameter N (from equation) to 3 and \u03bb (from equation) to 0.8 empirically.", "labels": [], "entities": []}], "tableCaptions": []}