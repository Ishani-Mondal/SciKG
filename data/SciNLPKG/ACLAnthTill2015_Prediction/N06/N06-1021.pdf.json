{"title": [{"text": "Multilingual Dependency Parsing using Bayes Point Machines", "labels": [], "entities": [{"text": "Multilingual Dependency Parsing", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6364754239718119}]}], "abstractContent": [{"text": "We develop dependency parsers for Ara-bic, English, Chinese, and Czech using Bayes Point Machines, a training algorithm which is as easy to implement as the perceptron yet competitive with large margin methods.", "labels": [], "entities": [{"text": "dependency parsers", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.7119604647159576}]}, {"text": "We achieve results comparable to state-of-the-art in English and Czech, and report the first directed dependency parsing accuracies for Arabic and Chinese.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.6266180127859116}]}, {"text": "Given the multilingual nature of our experiments, we discuss some issues regarding the comparison of dependency parsers for different languages.", "labels": [], "entities": [{"text": "comparison of dependency parsers", "start_pos": 87, "end_pos": 119, "type": "TASK", "confidence": 0.6676527857780457}]}], "introductionContent": [{"text": "Dependency parsing is an alternative to constituency analysis with a venerable tradition going back at least two millenia.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8342826068401337}, {"text": "constituency analysis", "start_pos": 40, "end_pos": 61, "type": "TASK", "confidence": 0.9180608987808228}]}, {"text": "The last century has seen attempts to formalize dependency parsing, particularly in the Prague School approach to linguistics.", "labels": [], "entities": [{"text": "formalize dependency parsing", "start_pos": 38, "end_pos": 66, "type": "TASK", "confidence": 0.7334222197532654}]}, {"text": "Ina dependency analysis of syntax, words directly modify other words.", "labels": [], "entities": []}, {"text": "Unlike constituency analysis, there are no intervening non-lexical nodes.", "labels": [], "entities": [{"text": "constituency analysis", "start_pos": 7, "end_pos": 28, "type": "TASK", "confidence": 0.9168098568916321}]}, {"text": "We use the terms child and parent to denote the dependent term and the governing term respectively.", "labels": [], "entities": []}, {"text": "Parsing has many potential applications, ranging from question answering and information retrieval to grammar checking.", "labels": [], "entities": [{"text": "question answering", "start_pos": 54, "end_pos": 72, "type": "TASK", "confidence": 0.8821422755718231}, {"text": "information retrieval", "start_pos": 77, "end_pos": 98, "type": "TASK", "confidence": 0.8213348686695099}, {"text": "grammar checking", "start_pos": 102, "end_pos": 118, "type": "TASK", "confidence": 0.9021883308887482}]}, {"text": "Our intended application is machine translation in the Microsoft Research Treelet Translation System ( ).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.7803725302219391}, {"text": "Microsoft Research Treelet Translation System", "start_pos": 55, "end_pos": 100, "type": "DATASET", "confidence": 0.8506480813026428}]}, {"text": "This system expects an analysis of the source language in which words are related by directed, unlabeled dependencies.", "labels": [], "entities": []}, {"text": "For the purposes of developing machine translation for several language pairs, we are interested in dependency analyses for multiple languages.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.7539383172988892}]}, {"text": "The contributions of this paper are two-fold: First, we present a training algorithm called Bayes Point Machines (, which is as easy to implement as the perceptron, yet competitive with large margin methods.", "labels": [], "entities": []}, {"text": "This algorithm has implications for anyone interested in implementing discriminative training methods for any application.", "labels": [], "entities": []}, {"text": "Second, we develop parsers for English, Chinese, Czech, and Arabic and probe some linguistic questions regarding dependency analyses in different languages.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, the Arabic and Chinese results are the first reported results to date for directed dependencies.", "labels": [], "entities": []}, {"text": "In the following, we first describe the data (Section 2) and the basic parser architecture (Section 3).", "labels": [], "entities": []}, {"text": "Section 4 introduces the Bayes Point Machine while Section 5 describes the features for each language.", "labels": [], "entities": []}, {"text": "We conclude with experimental results and discussions in Sections 6 and 7.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Summary of data used to train parsers.", "labels": [], "entities": []}, {"text": " Table 2: Bayes Point Machine accuracy measured on blind test set.", "labels": [], "entities": [{"text": "Bayes Point Machine", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.4464563727378845}, {"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.7090836763381958}, {"text": "blind test set", "start_pos": 51, "end_pos": 65, "type": "DATASET", "confidence": 0.7861821055412292}]}, {"text": " Table 3: Comparison to previous best published results reported in (McDonald et al., 2005a).", "labels": [], "entities": []}, {"text": " Table 4: Bayes Point Machine accuracy vs. averaged perceptrons, measured on development test set, ex- cluding punctuation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9418650269508362}]}]}