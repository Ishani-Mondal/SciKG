{"title": [{"text": "A Maximum Entropy Approach to Combining Word Alignments", "labels": [], "entities": [{"text": "Combining Word Alignments", "start_pos": 30, "end_pos": 55, "type": "TASK", "confidence": 0.5971037447452545}]}], "abstractContent": [{"text": "This paper presents anew approach to combining outputs of existing word alignment systems.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 67, "end_pos": 81, "type": "TASK", "confidence": 0.73467056453228}]}, {"text": "Each alignment link is represented with a set of feature functions extracted from linguistic features and input alignments.", "labels": [], "entities": []}, {"text": "These features are used as the basis of alignment decisions made by a maximum entropy approach.", "labels": [], "entities": []}, {"text": "The learning method has been evaluated on three language pairs, yielding significant improvements over input alignments and three heuristic combination methods.", "labels": [], "entities": []}, {"text": "The impact of word alignment on MT quality is investigated, using a phrase-based MT system.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 14, "end_pos": 28, "type": "TASK", "confidence": 0.7620157897472382}, {"text": "MT quality", "start_pos": 32, "end_pos": 42, "type": "TASK", "confidence": 0.9030567109584808}, {"text": "MT", "start_pos": 81, "end_pos": 83, "type": "TASK", "confidence": 0.809160590171814}]}], "introductionContent": [{"text": "Word alignment-detection of corresponding words between two sentences that are translations of each other-is usually an intermediate step of statistical machine translation (MT) (), but also has been shown useful for other applications such as construction of bilingual lexicons, word-sense disambiguation, projection of resources, and crosslanguage information retrieval.", "labels": [], "entities": [{"text": "Word alignment-detection of corresponding words between two sentences", "start_pos": 0, "end_pos": 69, "type": "TASK", "confidence": 0.8592723160982132}, {"text": "statistical machine translation (MT)", "start_pos": 141, "end_pos": 177, "type": "TASK", "confidence": 0.74849733710289}, {"text": "word-sense disambiguation", "start_pos": 280, "end_pos": 305, "type": "TASK", "confidence": 0.7328131794929504}, {"text": "projection of resources", "start_pos": 307, "end_pos": 330, "type": "TASK", "confidence": 0.89864581823349}, {"text": "crosslanguage information retrieval", "start_pos": 336, "end_pos": 371, "type": "TASK", "confidence": 0.7543373505274454}]}, {"text": "Maximum entropy (ME) models have been used in bilingual sense disambiguation, word reordering, and sentence segmentation (, parsing, POS tagging and PP attachment), machine translation ( ), and FrameNet classification (.", "labels": [], "entities": [{"text": "bilingual sense disambiguation", "start_pos": 46, "end_pos": 76, "type": "TASK", "confidence": 0.6273457209269205}, {"text": "word reordering", "start_pos": 78, "end_pos": 93, "type": "TASK", "confidence": 0.7778169214725494}, {"text": "sentence segmentation", "start_pos": 99, "end_pos": 120, "type": "TASK", "confidence": 0.7112925499677658}, {"text": "POS tagging", "start_pos": 133, "end_pos": 144, "type": "TASK", "confidence": 0.7045450061559677}, {"text": "PP attachment", "start_pos": 149, "end_pos": 162, "type": "TASK", "confidence": 0.636973574757576}, {"text": "machine translation", "start_pos": 165, "end_pos": 184, "type": "TASK", "confidence": 0.820930153131485}, {"text": "FrameNet classification", "start_pos": 194, "end_pos": 217, "type": "TASK", "confidence": 0.8128575086593628}]}, {"text": "They have also been used to solve the word alignment problem (), but a sentence-level approach to combining knowledge sources is used rather than a word-level approach.", "labels": [], "entities": [{"text": "word alignment problem", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.8276933431625366}]}, {"text": "This paper describes an approach to combining evidence from alignments generated by existing systems to obtain an alignment that is closer to the true alignment than the individual alignments.", "labels": [], "entities": []}, {"text": "The alignment-combination approach (called ACME) operates at the level of alignment links, rather than at the sentence level (as in previous ME approaches).", "labels": [], "entities": []}, {"text": "ACME uses ME to decide whether to include/exclude a particular alignment link based on feature functions that are extracted from the input alignments and linguistic features of the words.", "labels": [], "entities": []}, {"text": "Since alignment combination relies on evidence from existing alignments, we focus on alignment links that exist in at least one input alignment.", "labels": [], "entities": []}, {"text": "An important challenge in this approach is the selection of appropriate links when two aligners make different alignment choices.", "labels": [], "entities": []}, {"text": "We show that ACME yields a significant relative error reduction over the input alignment systems and heuristic-based combinations on three different language pairs.", "labels": [], "entities": [{"text": "ACME", "start_pos": 13, "end_pos": 17, "type": "TASK", "confidence": 0.9191286563873291}]}, {"text": "Using a higher number of input alignments and partitioning the training data into disjoint subsets yield further error-rate reductions.", "labels": [], "entities": []}, {"text": "The next section briefly overviews ME models.", "labels": [], "entities": [{"text": "ME", "start_pos": 35, "end_pos": 37, "type": "TASK", "confidence": 0.6660971641540527}]}, {"text": "Section 3 presents anew ME approach to combining existing word alignment systems.", "labels": [], "entities": [{"text": "ME", "start_pos": 24, "end_pos": 26, "type": "METRIC", "confidence": 0.6579703688621521}, {"text": "word alignment", "start_pos": 58, "end_pos": 72, "type": "TASK", "confidence": 0.7214604914188385}]}, {"text": "Section 4 describes the evaluation data, input alignments, and evaluation metrics.", "labels": [], "entities": []}, {"text": "Section 5 presents experiments on three language pairs, upper bounds for alignment error rate in alignment combination, and MT evaluation on English-Chinese and English-Arabic.", "labels": [], "entities": [{"text": "alignment error rate", "start_pos": 73, "end_pos": 93, "type": "METRIC", "confidence": 0.6571996410687765}, {"text": "MT", "start_pos": 124, "end_pos": 126, "type": "TASK", "confidence": 0.9450112581253052}]}, {"text": "Section 6 describes previous work on alignment combination and ME models on word alignment.", "labels": [], "entities": [{"text": "alignment combination", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.8734908401966095}, {"text": "word alignment", "start_pos": 76, "end_pos": 90, "type": "TASK", "confidence": 0.7692136764526367}]}], "datasetContent": [{"text": "The alignment combination techniques are evaluated in this paper using data from three language pairs, as shown in.  and SAHMM ().", "labels": [], "entities": [{"text": "alignment combination", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.928124874830246}, {"text": "SAHMM", "start_pos": 121, "end_pos": 126, "type": "DATASET", "confidence": 0.5355649590492249}]}, {"text": "Both systems are run in two different directions with default configurations.", "labels": [], "entities": []}, {"text": "We indicate the two directions using the notation Aligner(en \u2192 f l) and Aligner(f l \u2192 en), where en is English, fl is either Chinese (ch), Arabic (ar), or Romanian (ro).", "labels": [], "entities": []}, {"text": "To train both systems, additional data was used for the three language pairs: 107K English-Chinese sentence pairs (4.1M/3.3M English/Chinese words); 44K English-Arabic sentence pairs (1.4M/1M English/Arabic words); 48K English-Romanian sentence pairs (1M/1M English/Romanian words).", "labels": [], "entities": []}, {"text": "POS tags were generated using the MXPOST tagger.", "labels": [], "entities": [{"text": "MXPOST tagger", "start_pos": 34, "end_pos": 47, "type": "DATASET", "confidence": 0.8696824312210083}]}, {"text": "POS tagger for English was trained on Sections 0-18 of the Penn Treebank Wall Street Journal corpus.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.6295473128557205}, {"text": "Sections 0-18 of the Penn Treebank Wall Street Journal corpus", "start_pos": 38, "end_pos": 99, "type": "DATASET", "confidence": 0.7976838797330856}]}, {"text": "On the FL side, we used POS tagger for only Chinese and it was trained on Sections 16-299 of Chinese Treebank.", "labels": [], "entities": [{"text": "FL", "start_pos": 7, "end_pos": 9, "type": "DATASET", "confidence": 0.8964027762413025}, {"text": "POS tagger", "start_pos": 24, "end_pos": 34, "type": "TASK", "confidence": 0.6061445772647858}, {"text": "Sections 16-299 of Chinese Treebank", "start_pos": 74, "end_pos": 109, "type": "DATASET", "confidence": 0.6478839695453644}]}, {"text": "For comparison purposes, three additional heuristically-induced alignments are generated for each system: (1) Intersection of both directions (Aligner(int)); (2) Union of both directions (Aligner(union)); and (3) The previously bestknown heuristic combination approach called growdiag-final () (Aligner(gdf)).", "labels": [], "entities": []}, {"text": "In our evaluation, we take A to be the set of alignment links fora set of sentences, S to be the set of sure alignment links, and P be the set of probable alignment links (in the gold standard).", "labels": [], "entities": []}, {"text": "Precision (P r), recall (Rc) and alignment error rate (AER) are defined as follows: 6 Our gold standard for each language pair is a manually aligned corpus.", "labels": [], "entities": [{"text": "Precision (P r)", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.9508473038673401}, {"text": "recall (Rc)", "start_pos": 17, "end_pos": 28, "type": "METRIC", "confidence": 0.9696155786514282}, {"text": "alignment error rate (AER)", "start_pos": 33, "end_pos": 59, "type": "METRIC", "confidence": 0.9620278179645538}]}, {"text": "English-Chinese annotations distinguish between sure and probable alignment links (i.e., S \u2282 P ), but there is no such distinction for the other two language pairs (i.e., P = S).", "labels": [], "entities": []}, {"text": "Because of the availability of limited manually annotated data, evaluations are performed using 5-fold cross validation.", "labels": [], "entities": []}, {"text": "Once the alignments are generated for each fold (using one as the test set and the other 4 folds as training set), the results are concatenated to compute precision, recall and error rate on the entire set of sentence pairs for each data set.", "labels": [], "entities": [{"text": "precision", "start_pos": 155, "end_pos": 164, "type": "METRIC", "confidence": 0.9991818070411682}, {"text": "recall", "start_pos": 166, "end_pos": 172, "type": "METRIC", "confidence": 0.9987990856170654}, {"text": "error rate", "start_pos": 177, "end_pos": 187, "type": "METRIC", "confidence": 0.9599271714687347}]}, {"text": "This section presents several experiments and results comparing AER of ACME to those of standard alignment approaches on English-Chinese data.", "labels": [], "entities": [{"text": "AER", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9976882934570312}]}, {"text": "We also present experiments on additional languages, analyses based on precision and recall, an upperbound oracle analysis, and MT evaluations.", "labels": [], "entities": [{"text": "precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9984014630317688}, {"text": "recall", "start_pos": 85, "end_pos": 91, "type": "METRIC", "confidence": 0.9662330150604248}, {"text": "MT", "start_pos": 128, "end_pos": 130, "type": "TASK", "confidence": 0.978640615940094}]}, {"text": "The experiments below test the effects of input alignments, feature set, data partitioning, number of inputs, and size of training data on the performance of ACME.", "labels": [], "entities": [{"text": "ACME", "start_pos": 158, "end_pos": 162, "type": "TASK", "confidence": 0.861511766910553}]}, {"text": "2 Input alignments: shows the AER for GIZA++ and SAHMM (in each direction), three heuristic-based combinations and ACME using 2 uni-directional alignments as input and all features described in Section 3. 8 (We use 'ACME' in this section to refer to ACME applied to two input alignments and ACME in later sections to refer to ACME applied to four input alignments.)", "labels": [], "entities": [{"text": "AER", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.9991788268089294}]}, {"text": "Using 2 GIZA++ uni-directional alignments as input, ACME yields a 22.0% AER-a relative error reduction of 25.9% over GIZA++(gdf).", "labels": [], "entities": [{"text": "ACME", "start_pos": 52, "end_pos": 56, "type": "TASK", "confidence": 0.6378897428512573}, {"text": "AER-a relative error", "start_pos": 72, "end_pos": 92, "type": "METRIC", "confidence": 0.9244976242383321}]}, {"text": "Similarly, using 2 SAHMM uni-directional alignments as input, ACME produces a 20.6% AER-a relative error reduction of 28.0% and 25.4% over SAHMM(gdf) and SAHMM(int), respectively.", "labels": [], "entities": [{"text": "AER-a relative error reduction", "start_pos": 84, "end_pos": 114, "type": "METRIC", "confidence": 0.9399864375591278}]}, {"text": "Because the NIST MTEval data include sentences that maybe related (according to the document in which they appear), the training and test material could potentially be related; however, given the types of features used in our experiments, we do not believe this biases our results.", "labels": [], "entities": [{"text": "NIST MTEval data", "start_pos": 12, "end_pos": 28, "type": "DATASET", "confidence": 0.8883543610572815}]}, {"text": "For ease of readability, in the rest of this paper, we will report precision, recall, and AER in percentages.", "labels": [], "entities": [{"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9984506368637085}, {"text": "recall", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.9997331500053406}, {"text": "AER", "start_pos": 90, "end_pos": 93, "type": "METRIC", "confidence": 0.9997685551643372}]}, {"text": "Partitioning Data: Previous work showed that partitioning the data into disjoint subsets and learning a different model for each partition improves the performance of the alignment systems ().", "labels": [], "entities": []}, {"text": "To test whether this same principle applies to alignment combination with maximum entropy modeling, the training data was partitioned using POS tags for English and the FL, and different weights were learned for each partition.", "labels": [], "entities": []}, {"text": "To determine the contribution of improved alignment in an external application, we examined the improvement in an off-the-shelf phrase-based MT system Pharaoh) on both Chinese and Arabic data.", "labels": [], "entities": []}, {"text": "In these experiments, all components of the MT system were kept the same except for the component that generates a phrase table from a given alignment.", "labels": [], "entities": [{"text": "MT", "start_pos": 44, "end_pos": 46, "type": "TASK", "confidence": 0.9854865074157715}]}, {"text": "The input alignments were generated using GIZA++ and SAHMM on 107K (44K) sentence pairs for Chinese (Arabic).", "labels": [], "entities": [{"text": "SAHMM", "start_pos": 53, "end_pos": 58, "type": "METRIC", "confidence": 0.5792669653892517}]}, {"text": "ACME (with English POS partitioning) combines alignments using model parameters learned from the corresponding manually aligned data.", "labels": [], "entities": [{"text": "ACME", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7241116166114807}]}, {"text": "MT output is evaluated using the standard MT evaluation metric BLEU ().", "labels": [], "entities": [{"text": "MT", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.955934464931488}, {"text": "MT evaluation", "start_pos": 42, "end_pos": 55, "type": "TASK", "confidence": 0.8673213422298431}, {"text": "BLEU", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.8694112300872803}]}, {"text": "10 presents the BLEU scores on MTEval'03 data for 5 different Pharaoh runs, one for each alignment.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.9994505047798157}, {"text": "MTEval'03 data", "start_pos": 31, "end_pos": 45, "type": "DATASET", "confidence": 0.9356334507465363}]}, {"text": "The parameters of the MT system were optimized on MTEval'02 data using minimum error rate training.", "labels": [], "entities": [{"text": "MT", "start_pos": 22, "end_pos": 24, "type": "TASK", "confidence": 0.9804685115814209}, {"text": "MTEval'02 data", "start_pos": 50, "end_pos": 64, "type": "DATASET", "confidence": 0.9453355073928833}]}, {"text": "For the language model, the SRI Language Modeling Toolkit was used to train a trigram model with modified Kneser-Ney smoothing on 155M words of English newswire text, mostly from the Xinhua portion of the Gigaword corpus.", "labels": [], "entities": [{"text": "SRI Language Modeling Toolkit", "start_pos": 28, "end_pos": 57, "type": "DATASET", "confidence": 0.6327982246875763}, {"text": "Gigaword corpus", "start_pos": 205, "end_pos": 220, "type": "DATASET", "confidence": 0.875997394323349}]}, {"text": "During decoding, the number of English phrases per FL phrase was limited to 100 and the distortion of phrases was limited by 4.", "labels": [], "entities": [{"text": "distortion", "start_pos": 88, "end_pos": 98, "type": "METRIC", "confidence": 0.9479248523712158}]}, {"text": "Based on the observations in (, we also limited the phrase length to 3 for computational reasons.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Data Used for Combination Experiments.", "labels": [], "entities": []}, {"text": " Table 3: Comparison of GIZA++ and SAHMM to  ACME[2] (on English-Chinese).", "labels": [], "entities": [{"text": "SAHMM", "start_pos": 35, "end_pos": 40, "type": "DATASET", "confidence": 0.6134926676750183}]}, {"text": " Table 4: Application of ACME[2] on Partitioned  Data (on English-Chinese).", "labels": [], "entities": []}, {"text": " Table 5: Application of ACME to 1, 2 and 4 Input  Alignments (on English-Chinese).", "labels": [], "entities": []}, {"text": " Table 6: AER for Input Alignments, Heuristic-based Alignments, and ACME Using 2 and 4 Input Align- ments (on English-Arabic and English-Romanian).", "labels": [], "entities": [{"text": "AER", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9992417097091675}]}, {"text": " Table 7: Oracle Upper Bounds on AER for Align- ment Combination", "labels": [], "entities": [{"text": "AER", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.9890594482421875}]}, {"text": " Table 8: Evaluation of Pharaoh with Different Initial  Alignments using BLEU (in percentages)", "labels": [], "entities": [{"text": "BLEU", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.9988238215446472}]}]}