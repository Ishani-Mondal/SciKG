{"title": [{"text": "Estimation of Consistent Probabilistic Context-free Grammars", "labels": [], "entities": []}], "abstractContent": [{"text": "We consider several empirical estimators for probabilistic context-free grammars, and show that the estimated grammars have the so-called consistency property, under the most general conditions.", "labels": [], "entities": []}, {"text": "Our estimators include the widely applied expectation maximization method, used to estimate probabilistic context-free grammars on the basis of unannotated corpora.", "labels": [], "entities": []}, {"text": "This solves a problem left open in the literature , since for this method the consistency property has been shown only under restrictive assumptions on the rules of the source grammar.", "labels": [], "entities": [{"text": "consistency", "start_pos": 78, "end_pos": 89, "type": "METRIC", "confidence": 0.9543740153312683}]}], "introductionContent": [{"text": "Probabilistic context-free grammars are one of the most widely used formalisms in current work in statistical natural language parsing and stochastic language modeling.", "labels": [], "entities": [{"text": "statistical natural language parsing", "start_pos": 98, "end_pos": 134, "type": "TASK", "confidence": 0.7042984589934349}, {"text": "stochastic language modeling", "start_pos": 139, "end_pos": 167, "type": "TASK", "confidence": 0.6297646462917328}]}, {"text": "An important property fora probabilistic context-free grammar is that it be consistent, that is, the grammar should assign probability of one to the set of all finite strings or parse trees that it generates.", "labels": [], "entities": []}, {"text": "In other words, the grammar should not lose probability mass with strings or trees of infinite length.", "labels": [], "entities": []}, {"text": "Several methods for the empirical estimation of probabilistic context-free grammars have been proposed in the literature, based on the optimization of some function on the probabilities of the observed data, such as the maximization of the likelihood of a tree bank or a corpus of unannotated sentences.", "labels": [], "entities": []}, {"text": "It has been conjectured in) that these methods always provide probabilistic context-free grammars with the consistency property.", "labels": [], "entities": []}, {"text": "A first result in this direction was presented in (, by showing that a probabilistic contextfree grammar estimated by maximizing the likelihood of a sample of parse trees is always consistent.", "labels": [], "entities": []}, {"text": "In later work by and, the result was independently extended to expectation maximization, which is an unsupervised method exploited to estimate probabilistic context-free grammars by finding local maxima of the likelihood of a sample of unannotated sentences.", "labels": [], "entities": []}, {"text": "The proof in) makes use of spectral analysis of expectation matrices, while the proof in) is based on a simpler counting argument.", "labels": [], "entities": []}, {"text": "Both these proofs assume restrictions on the underlying context-free grammars.", "labels": [], "entities": []}, {"text": "More specifically, in) empty rules and unary rules are not allowed, thus excluding infinite ambiguity, that is, the possibility that some string in the input sample has an infinite number of derivations in the grammar.", "labels": [], "entities": []}, {"text": "The treatment of general form contextfree grammars has been an open problem so far.", "labels": [], "entities": []}, {"text": "In this paper we consider several estimation methods for probabilistic context-free grammars, and we show that the resulting grammars have the consistency property.", "labels": [], "entities": [{"text": "consistency", "start_pos": 143, "end_pos": 154, "type": "METRIC", "confidence": 0.9772368669509888}]}, {"text": "Our proofs are applicable under the most general conditions, and our results also include the expectation maximization method, thus solving the open problem discussed above.", "labels": [], "entities": []}, {"text": "We use an alternative proof technique with respect to pre-vious work, based on an already known renormalization construction for probabilistic context-free grammars, which has been used in the context of language modeling.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 204, "end_pos": 221, "type": "TASK", "confidence": 0.702887162566185}]}, {"text": "The structure of this paper is as follows.", "labels": [], "entities": []}, {"text": "We provide some preliminary definitions in Section 2, followed in Section 3 by a brief overview of the estimation methods we investigate in this paper.", "labels": [], "entities": [{"text": "estimation", "start_pos": 103, "end_pos": 113, "type": "TASK", "confidence": 0.9428636431694031}]}, {"text": "In Section 4 we prove some properties of a renormalization technique for probabilistic context-free grammars, and use this property to show our main results in Section 5.", "labels": [], "entities": []}, {"text": "Section 6 closes with some concluding remarks.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}