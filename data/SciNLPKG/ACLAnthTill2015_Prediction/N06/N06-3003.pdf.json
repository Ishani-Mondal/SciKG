{"title": [{"text": "Can the Internet help improve Machine Translation?", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.8974747955799103}]}], "abstractContent": [{"text": "This paper summarizes a largely automated method that uses online post-editing feedback to automatically improve translation rules.", "labels": [], "entities": [{"text": "translation rules", "start_pos": 113, "end_pos": 130, "type": "TASK", "confidence": 0.9087449610233307}]}, {"text": "As a starting point, bilingual speak-ers' local fixes are collected through an online Translation Correction Tool.", "labels": [], "entities": []}, {"text": "Next, the Rule Refinement Module attacks the problem at its core and uses the local fixes to detect incorrect rules that need to be refined.", "labels": [], "entities": [{"text": "Rule Refinement Module", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.8147895733515421}]}, {"text": "Once the grammar and lexicon have been refined, the Machine Translation system not only produces the correct translation as fixed by the bilingual speaker, but is also able to generalize and correctly translates similar sentences.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.7357058823108673}]}, {"text": "Thus, this work constitutes a novel approach to improving translation quality.", "labels": [], "entities": [{"text": "translation quality", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.8890914916992188}]}, {"text": "Enhanced by the reaching power of the Internet, our approach becomes even more relevant to address the problem of how to automatically improve the quality of Machine Translation output.", "labels": [], "entities": [{"text": "Machine Translation output", "start_pos": 158, "end_pos": 184, "type": "TASK", "confidence": 0.8385624090830485}]}], "introductionContent": [{"text": "Achieving high translation quality remains the biggest challenge Machine Translation (MT) systems currently face.", "labels": [], "entities": [{"text": "translation", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.955351710319519}, {"text": "Machine Translation (MT)", "start_pos": 65, "end_pos": 89, "type": "TASK", "confidence": 0.8480320870876312}]}, {"text": "Researchers have explored a variety of methods to include user feedback in the MT loop.", "labels": [], "entities": [{"text": "MT loop", "start_pos": 79, "end_pos": 86, "type": "TASK", "confidence": 0.8989345729351044}]}, {"text": "Similar to our approach, Phaholphinyo and colleagues proposed adding post-editing rules to their English-Thai MT system with the use of a post-editing tool.", "labels": [], "entities": [{"text": "MT", "start_pos": 110, "end_pos": 112, "type": "TASK", "confidence": 0.8293461799621582}]}, {"text": "However, they use context sensitive pattern-matching rules, which make it impossible to fix errors involving missing words.", "labels": [], "entities": []}, {"text": "Unlike our approach, in their system, the rules are created by experienced linguists and their approach requires a large corpus.", "labels": [], "entities": []}, {"text": "They mention an experiment with 6,000 bilingual sentences but report no results due to data sparseness.", "labels": [], "entities": []}, {"text": "In general, most MT systems have failed to incorporate post-editing efforts beyond the addition of corrected translations to the parallel training data for SMT and EBMT or to a translation memory database.", "labels": [], "entities": [{"text": "MT", "start_pos": 17, "end_pos": 19, "type": "TASK", "confidence": 0.9883913397789001}, {"text": "SMT", "start_pos": 156, "end_pos": 159, "type": "TASK", "confidence": 0.9598568081855774}]}, {"text": "1 Therefore, a largely automated method that uses online post-editing information to automatically improve translation rules constitutes a great advance in the field.", "labels": [], "entities": [{"text": "translation rules", "start_pos": 107, "end_pos": 124, "type": "TASK", "confidence": 0.9046408236026764}]}, {"text": "If an MT-produced translation is incorrect, a bilingual speaker can diagnose the presence of an error reliably using the online Translation Correction Tool (Font).", "labels": [], "entities": [{"text": "MT-produced translation", "start_pos": 6, "end_pos": 29, "type": "TASK", "confidence": 0.9003012180328369}]}, {"text": "An example of an English-Spanish sentence pair generated by our MT system is \"Gaud\u00ed was a great artist -Gaud\u00ed era un artista grande\".", "labels": [], "entities": [{"text": "MT", "start_pos": 64, "end_pos": 66, "type": "TASK", "confidence": 0.837398886680603}]}, {"text": "Using the online tool, bilingual speakers modified the incorrect translation to obtain a correct one: \"Gaud\u00ed era un gran artista\".", "labels": [], "entities": []}, {"text": "Bilingual speakers, however, cannot be expected to diagnose which complex translation rules produced the error, and even less, determine how to improve those rules.", "labels": [], "entities": []}, {"text": "One of the main goals of this research is to automate the Rule Refinement process based on just error-locus and possibly some error-type information from the bilingual speaker, relying on rule blame assignment and on regression testing to evaluate and measure the consequent improvement in MT accuracy.", "labels": [], "entities": [{"text": "Rule Refinement", "start_pos": 58, "end_pos": 73, "type": "TASK", "confidence": 0.8535479605197906}, {"text": "rule blame assignment", "start_pos": 188, "end_pos": 209, "type": "TASK", "confidence": 0.6052464246749878}, {"text": "MT", "start_pos": 290, "end_pos": 292, "type": "TASK", "confidence": 0.9908331036567688}, {"text": "accuracy", "start_pos": 293, "end_pos": 301, "type": "METRIC", "confidence": 0.6630027294158936}]}, {"text": "In this case, our Automatic Rule Refinement system can add the missing sense to the lexicon (great\ud97b\udf59gran) as well as the special case rule for Spanish prenominal adjectives to the grammar.", "labels": [], "entities": [{"text": "Automatic Rule Refinement", "start_pos": 18, "end_pos": 43, "type": "TASK", "confidence": 0.5466170112291971}]}, {"text": "With this system in place, we envision a modified version of the Translation Correction Tool as a game with a purpose, available online through a major web portal.", "labels": [], "entities": [{"text": "Translation Correction", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.8812234103679657}]}, {"text": "This would allow bilingual speakers to correct MT input and get rewards for making good corrections, and compare their scores and speed with other users.", "labels": [], "entities": [{"text": "MT input", "start_pos": 47, "end_pos": 55, "type": "TASK", "confidence": 0.8917502164840698}, {"text": "speed", "start_pos": 130, "end_pos": 135, "type": "METRIC", "confidence": 0.9242649078369141}]}, {"text": "For the MT community this means having a free and easy way to get MT output feedback and potentially improve their systems based on such feedback.", "labels": [], "entities": [{"text": "MT", "start_pos": 8, "end_pos": 10, "type": "TASK", "confidence": 0.967168927192688}, {"text": "MT output", "start_pos": 66, "end_pos": 75, "type": "TASK", "confidence": 0.861987441778183}]}, {"text": "Furthermore, a fully interactive system would be a great opportunity to show users that their corrections have a visible impact on technology, since they would seethe effects their corrections have on other sentences.", "labels": [], "entities": []}, {"text": "Last but not least, this new method is also expected to be particularly useful in resource-poor scenarios, such as the ones the Avenue project is devoted to, where statistical systems are not an option and where there might be no experts with knowledge of the resource-poor language ().", "labels": [], "entities": [{"text": "Avenue project", "start_pos": 128, "end_pos": 142, "type": "DATASET", "confidence": 0.9382565319538116}]}], "datasetContent": [{"text": "We plan to evaluate the RR module on its ability to improve coverage and overall translation quality.", "labels": [], "entities": [{"text": "RR", "start_pos": 24, "end_pos": 26, "type": "TASK", "confidence": 0.9662513732910156}]}, {"text": "This requires identifying sensible evaluation metrics.", "labels": [], "entities": []}, {"text": "Initial experiments have shown that both BLEU and METEOR can automatically distinguish between raw MT output and corrected MT output, even fora small set of sentences.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.9985828399658203}, {"text": "METEOR", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9532659649848938}]}, {"text": "In addition to the presence of the corrected translation in the lattice produced by the refined system, our evaluation metrics will also need to take into account whether the incorrect translation is now prevented from being generated and whether the lattice of alternative translations increased or decreased.", "labels": [], "entities": []}, {"text": "A decrease of lattice size would mean that the refinement also made the grammar tighter, which is the desired effect.", "labels": [], "entities": []}], "tableCaptions": []}