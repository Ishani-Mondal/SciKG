{"title": [{"text": "Extracting Salient Keywords from Instructional Videos Using Joint Text, Audio and Visual Cues", "labels": [], "entities": [{"text": "Extracting Salient Keywords from Instructional Videos", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.8659951587518057}]}], "abstractContent": [{"text": "This paper presents a multi-modal feature-based system for extracting salient keywords from transcripts of instructional videos.", "labels": [], "entities": [{"text": "extracting salient keywords from transcripts of instructional videos", "start_pos": 59, "end_pos": 127, "type": "TASK", "confidence": 0.6835357397794724}]}, {"text": "Specifically , we propose to extract domain-specific keywords for videos by integrating various cues from linguistic and statistical knowledge, as well as derived sound classes and characteristic visual content types.", "labels": [], "entities": []}, {"text": "The acquisition of such salient keywords will facilitate video indexing and browsing, and significantly improve the quality of current video search engines.", "labels": [], "entities": [{"text": "video indexing", "start_pos": 57, "end_pos": 71, "type": "TASK", "confidence": 0.6978912800550461}]}, {"text": "Experiments on four government instructional videos show that 82% of the salient keywords appear in the top 50% of the highly ranked keywords.", "labels": [], "entities": []}, {"text": "In addition, the audiovisual cues improve precision and recall by 1.1% and 1.5% respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9996941089630127}, {"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.999603807926178}]}], "introductionContent": [{"text": "With recent advances in multimedia technology, the number of videos that are available to both general public and particular individuals or organizations is growing rapidly.", "labels": [], "entities": []}, {"text": "This consequently creates a high demand for efficient video searching and categorization as evidenced by the emergence of various offerings for web video searching.", "labels": [], "entities": [{"text": "web video searching", "start_pos": 144, "end_pos": 163, "type": "TASK", "confidence": 0.6618156135082245}]}, {"text": "While videos contain a rich source of audiovisual information, text-based video search is still among the most effective and widely used approaches.", "labels": [], "entities": [{"text": "text-based video search", "start_pos": 63, "end_pos": 86, "type": "TASK", "confidence": 0.7034221688906351}]}, {"text": "However, the quality of such text-based video search engines still lags behind the quality of those that search textual information like web pages.", "labels": [], "entities": []}, {"text": "This is due to the extreme difficulty of tagging domain-specific keywords to videos.", "labels": [], "entities": []}, {"text": "How to effectively extract domain-specific or salient keywords from video transcripts has thus become a critical and challenging issue for both the video indexing and searching communities.", "labels": [], "entities": []}, {"text": "Recently, with the advances in speech recognition and natural language processing technologies, systems are being developed to automatically extract keywords from video transcripts which are either transcribed from speech or obtained from closed captions.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.7292081117630005}]}, {"text": "Most of these systems, however, simply treat all words equally or directly \"transplant\" keyword extraction techniques developed for pure text documents to the video domain without taking specific characteristics of videos into account (M. Smith and T.).", "labels": [], "entities": []}, {"text": "In the traditional information retrieval (IR) field, most existing methods for selecting salient keywords rely primarily on word frequency or other statistical information obtained from a collection of documents.", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 19, "end_pos": 45, "type": "TASK", "confidence": 0.8866524696350098}]}, {"text": "These techniques, however, do notwork well for videos for two reasons: 1) most video transcripts are very short, as compared to atypical text collection; and 2) it is impractical to assume that there is a large video collection on a specific topic, due to the video production costs.", "labels": [], "entities": []}, {"text": "As a result, many keywords extracted from videos using traditional IR techniques are not really content-specific, and consequently, the video search results that are returned based on these keywords are generally unsatisfactory.", "labels": [], "entities": []}, {"text": "In this paper, we propose a system for extracting salient or domain-specific keywords from instructional videos by exploiting joint audio, visual, and text cues.", "labels": [], "entities": []}, {"text": "Specifically, we first apply a text-based keyword extraction system to find a set of keywords from video transcripts.", "labels": [], "entities": [{"text": "text-based keyword extraction", "start_pos": 31, "end_pos": 60, "type": "TASK", "confidence": 0.6521500547726949}]}, {"text": "Then we apply various audiovisual content analysis techniques to identify cue contexts in which domain-specific keywords are more likely to appear.", "labels": [], "entities": []}, {"text": "Finally, we adjust the keyword salience by fusing the audio, visual and text cues together, and \"discover\" a set of salient keywords.", "labels": [], "entities": []}, {"text": "Professionally produced educational or instructional videos are the main focus of this work since they are playing increasingly important roles in people's daily lives.", "labels": [], "entities": []}, {"text": "For the system evaluation, we used training and education videos that are freely downloadable from various DHS (Department of Homeland Security) web sites.", "labels": [], "entities": []}, {"text": "These were selected because 1) DHS has an increasing need for quickly browsing, searching and re-purposing its learning resources across its over twenty diverse agencies; 2) most DHS videos contain closed captions in compliance with federal accessibility requirements such as Section 508.", "labels": [], "entities": []}], "datasetContent": [{"text": "Four DHS videos were used in the experiment, which contain diverse topics ranging from bio-terrorism history, weapons of mass destruction, to school preparation for terrorism.", "labels": [], "entities": [{"text": "DHS videos", "start_pos": 5, "end_pos": 15, "type": "DATASET", "confidence": 0.9660885035991669}]}, {"text": "The video length also varies a lot from 30 minutes to 2 hours.", "labels": [], "entities": []}, {"text": "Each video also contains a variety of sub-topics.", "labels": [], "entities": []}, {"text": "Video transcripts were acquired by extracting the closed captions with our own application.", "labels": [], "entities": []}, {"text": "To evaluate system performance, we compare the keywords generated from our system against the humangenerated gold standard.", "labels": [], "entities": []}, {"text": "Note that for this experiment, we only consider nouns and noun phrases as keywords.", "labels": [], "entities": []}, {"text": "To collect the ground truth, we invited a few human evaluators, showed them the four test videos, and presented them with all candidate keywords extracted by GlossEx.", "labels": [], "entities": []}, {"text": "We then asked them to label all keywords that they considered to be domain-specific, which is guidelined by the following question: \"would you be satisfied if you get this video when you use this keyword as a search term?\".", "labels": [], "entities": []}, {"text": "shows the number of candidate keywords and manually labeled salient keywords for all four test videos.", "labels": [], "entities": []}, {"text": "As we can see, approximately 50% of candidate keywords were judged to be domain-specific by humans.", "labels": [], "entities": []}, {"text": "Based on this observation, we selected the top 50% of highly ranked keywords based on the adjusted salience, and examined their presence in the pool of salient keywords for each video.", "labels": [], "entities": []}, {"text": "As a result, an average of 82% of salient keywords were identified within these top 50% of re-ranked keywords.", "labels": [], "entities": []}, {"text": "In addition, the audiovisual cues improve precision and recall by 1.1% and 1.5% respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9996941089630127}, {"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.999603807926178}]}], "tableCaptions": [{"text": " Table 1: The number of candidate and manually labeled  salient keywords in the four test videos", "labels": [], "entities": []}]}