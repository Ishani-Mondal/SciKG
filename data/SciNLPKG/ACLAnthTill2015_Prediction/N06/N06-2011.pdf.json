{"title": [{"text": "Spectral Clustering for Example Based Machine Translation", "labels": [], "entities": [{"text": "Example Based Machine Translation", "start_pos": 24, "end_pos": 57, "type": "TASK", "confidence": 0.6854617446660995}]}], "abstractContent": [{"text": "Prior work has shown that generalization of data in an Example Based Machine Translation (EBMT) system, reduces the amount of pre-translated text required to achieve a certain level of accuracy (Brown, 2000).", "labels": [], "entities": [{"text": "Example Based Machine Translation (EBMT)", "start_pos": 55, "end_pos": 95, "type": "TASK", "confidence": 0.7765007955687386}, {"text": "accuracy", "start_pos": 185, "end_pos": 193, "type": "METRIC", "confidence": 0.9941405653953552}]}, {"text": "Several word clustering algorithms have been suggested to perform these generalizations, such as k-Means clustering or Group Average Clustering.", "labels": [], "entities": [{"text": "word clustering", "start_pos": 8, "end_pos": 23, "type": "TASK", "confidence": 0.7396524250507355}, {"text": "k-Means clustering", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.7154912650585175}]}, {"text": "The hypothesis is that better con-textual clustering can lead to better translation accuracy with limited training data.", "labels": [], "entities": [{"text": "translation", "start_pos": 72, "end_pos": 83, "type": "TASK", "confidence": 0.9642648696899414}, {"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.8740421533584595}]}, {"text": "In this paper, we use a form of spectral clustering to cluster words, and this is shown to result in as much as 29.08% improvement over the baseline EBMT system .", "labels": [], "entities": []}], "introductionContent": [{"text": "In EBMT, the source sentence to be translated is matched against the source language sentences present in a corpus of source-target sentence pairs.", "labels": [], "entities": []}, {"text": "When a partial match is found, the corresponding target translations are obtained through subsentential alignment.", "labels": [], "entities": []}, {"text": "These partial matches are put together to obtain the final translation by optimizing translation and alignment scores and using a statistical target language model in the decoding process.", "labels": [], "entities": []}, {"text": "Prior work has shown that EBMT requires large amounts of data (in the order of two to three million words)) of pre-translated text, to function reasonably well.", "labels": [], "entities": []}, {"text": "Thus, some modification of the basic EBMT method is required to make it effective when less data is available.", "labels": [], "entities": []}, {"text": "In order to use the available text efficiently, systems such as, and, convert the examples in the corpus into templates against which the new text can be matched.", "labels": [], "entities": []}, {"text": "Thus, source-target sentence pairs are converted to source-target generalized template pairs.", "labels": [], "entities": []}, {"text": "An example of such a pair is shown below: The session opened at 2p.m La s\u00e9ance est ouvert\u00e9ouvert\u00e9 a 2 heures The <event> <verb-past-tense> at <time> La <event> <verb-past-tense> a <time> This single template can be used to translate different source sentences, including for example, The session adjourned at 6p.m The seminar opened at 8a.m if 'session' and 'seminar' are both generalized to '<event>', 'opened' and 'adjourned' are both generalized to '<verb-past-tense>' and finally '6p.m' and '8a.m' are both generalized to '<time>'.", "labels": [], "entities": []}, {"text": "The system used by) performs its generalization using both equivalence classes of words and a production rule grammar.", "labels": [], "entities": []}, {"text": "This paper describes the use of spectral clustering), for automated extraction of equivalence classes.", "labels": [], "entities": [{"text": "spectral clustering", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.7136956751346588}, {"text": "automated extraction of equivalence classes", "start_pos": 58, "end_pos": 101, "type": "TASK", "confidence": 0.747622835636139}]}, {"text": "Spectral clustering is seen to be superior to Group Average Clustering (GAC)) both in terms of semantic similarity of words falling in a single cluster, and overall BLEU score () in a large scale EBMT system.", "labels": [], "entities": [{"text": "Spectral clustering", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9166626632213593}, {"text": "BLEU score", "start_pos": 165, "end_pos": 175, "type": "METRIC", "confidence": 0.9868776202201843}]}, {"text": "The next section explains the term vectors extracted for each word, which are then used to cluster words into equivalence classes and provides an outline of the Standard GAC algorithm.", "labels": [], "entities": []}, {"text": "Section 3 describes the spectral clustering algorithm used.", "labels": [], "entities": [{"text": "spectral clustering", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.7464160919189453}]}, {"text": "Sec-tion 4 lists results obtained in a full evaluation of the algorithm.", "labels": [], "entities": []}, {"text": "Section 5 concludes and discusses directions for future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: % Relative improvement over baseline EBMT", "labels": [], "entities": [{"text": "Relative", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9971117973327637}, {"text": "EBMT", "start_pos": 47, "end_pos": 51, "type": "TASK", "confidence": 0.32970932126045227}]}]}