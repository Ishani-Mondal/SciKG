{"title": [{"text": "Language Model Information Retrieval with Document Expansion", "labels": [], "entities": [{"text": "Language Model Information Retrieval", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.535582110285759}]}], "abstractContent": [{"text": "Language model information retrieval depends on accurate estimation of document models.", "labels": [], "entities": [{"text": "Language model information retrieval", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.5455121695995331}]}, {"text": "In this paper, we propose a document expansion technique to deal with the problem of insufficient sampling of documents.", "labels": [], "entities": [{"text": "document expansion", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.791916161775589}]}, {"text": "We construct a probabilistic neighborhood for each document, and expand the document with its neighborhood information.", "labels": [], "entities": []}, {"text": "The expanded document provides a more accurate estimation of the document model, thus improves retrieval accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9747373461723328}]}, {"text": "Moreover, since document expansion and pseudo feedback exploit different corpus structures, they can be combined to further improve performance.", "labels": [], "entities": [{"text": "document expansion", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.7251206934452057}]}, {"text": "The experiment results on several different data sets demonstrate the effectiveness of the proposed document expansion method.", "labels": [], "entities": [{"text": "document expansion", "start_pos": 100, "end_pos": 118, "type": "TASK", "confidence": 0.7507981061935425}]}], "introductionContent": [{"text": "Information retrieval with statistical language models ( has recently attracted much more attention because of its solid theoretical background as well as its good empirical performance.", "labels": [], "entities": [{"text": "Information retrieval", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8464097678661346}]}, {"text": "In this approach, queries and documents are assumed to be sampled from hidden generative models, and the similarity between a document and a query is then calculated through the similarity between their underlying models.", "labels": [], "entities": []}, {"text": "Clearly, good retrieval performance relies on the accurate estimation of the query and document models.", "labels": [], "entities": []}, {"text": "Indeed, smoothing of document models has been proved to be very critical).", "labels": [], "entities": []}, {"text": "The need for smoothing originated from the zero count problem: when a term does not occur in a document, the maximum likelihood estimator would give it a zero probability.", "labels": [], "entities": []}, {"text": "This is unreasonable because the zero count is often due to insufficient sampling, and a larger sample of the data would likely contain the term.", "labels": [], "entities": []}, {"text": "Smoothing is proposed to address the problem.", "labels": [], "entities": []}, {"text": "While most smoothing methods utilize the global collection information with a simple interpolation (), several recent studies () have shown that local corpus structures can be exploited to improve retrieval performance.", "labels": [], "entities": []}, {"text": "In this paper, we further study the use of local corpus structures for document model estimation and propose to use document expansion to better exploit local corpus structures for estimating document language models.", "labels": [], "entities": [{"text": "document model estimation", "start_pos": 71, "end_pos": 96, "type": "TASK", "confidence": 0.6746019721031189}, {"text": "document expansion", "start_pos": 116, "end_pos": 134, "type": "TASK", "confidence": 0.6817128509283066}, {"text": "estimating document language models", "start_pos": 181, "end_pos": 216, "type": "TASK", "confidence": 0.8115651458501816}]}, {"text": "According to statistical principles, the accuracy of a statistical estimator is largely determined by the sampling size of the observed data; a small data set generally would result in large variances, thus cannot be trusted completely.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9988800883293152}]}, {"text": "Unfortunately, in retrieval, we often have to estimate a model based on a single document.", "labels": [], "entities": []}, {"text": "Since a document is a small sample, our estimate is unlikely to be very accurate.", "labels": [], "entities": []}, {"text": "A natural improvement is to enlarge the data sample, ideally in a document-specific way.", "labels": [], "entities": []}, {"text": "Ideally, the enlarged data sample should come from the same original generative model.", "labels": [], "entities": []}, {"text": "In reality, however, since the underlying model is unknown to us, we would not really be able to obtain such extra data.", "labels": [], "entities": []}, {"text": "The essence of this paper is to use document expansion to obtain high quality extra data to enlarge the sample of a document so as to improve the accuracy of the estimated document language model.", "labels": [], "entities": [{"text": "document expansion", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.6851073056459427}, {"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9988112449645996}]}, {"text": "Document expansion was previously explored in) in the context of the vector space retrieval model, mainly involving selecting more terms from similar documents.", "labels": [], "entities": [{"text": "Document expansion", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9151039123535156}]}, {"text": "Our work differs from this previous work in that we study document expansion in the language modeling framework and implement the idea quite differently.", "labels": [], "entities": [{"text": "document expansion", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.7302152812480927}]}, {"text": "Our main idea is to augment a document probabilistically with potentially all other documents in the collection that are similar to the document.", "labels": [], "entities": []}, {"text": "The probability associated with each neighbor document reflects how likely the neighbor document is from the underlying distribution of the original document, thus we have a \"probabilistic neighborhood\", which can serve as \"extra data\" for the document for estimating the underlying language model.", "labels": [], "entities": []}, {"text": "From the viewpoint of smoothing, our method extends the existing work on using clusters for smoothing () to allow each document to have its own cluster for smoothing.", "labels": [], "entities": []}, {"text": "We evaluated our method using six representative retrieval test sets.", "labels": [], "entities": []}, {"text": "The experiment results show that document expansion smoothing consistently outperforms the baseline smoothing methods in all the data sets.", "labels": [], "entities": [{"text": "document expansion smoothing", "start_pos": 33, "end_pos": 61, "type": "TASK", "confidence": 0.8287635644276937}]}, {"text": "It also outperforms a state-of-the-art clustering smoothing method.", "labels": [], "entities": [{"text": "clustering smoothing", "start_pos": 39, "end_pos": 59, "type": "TASK", "confidence": 0.9118835628032684}]}, {"text": "Analysis shows that the improvement tends to be more significant for short documents, indicating that the improvement indeed comes from the improved estimation of the document language model, since a short document presumably would benefit more from the neighborhood smoothing.", "labels": [], "entities": []}, {"text": "Moreover, since document expansion and pseudo feedback exploit different corpus structures, they can be combined to further improve performance.", "labels": [], "entities": [{"text": "document expansion", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.7251206934452057}]}, {"text": "As document expansion can be done in the indexing stage, it is scalable to large collections.", "labels": [], "entities": [{"text": "document expansion", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.7074037790298462}]}], "datasetContent": [{"text": "We evaluate the proposed method over six representative TREC data sets): AP (Associated Press news 1988-90), LA (LA Times), WSJ (Wall Street Journal 1987-92), SJMN (San Jose Mercury News 1991), DOE (Department of Energy), and TREC8 (the ad hoc data used in TREC8).", "labels": [], "entities": [{"text": "AP (Associated Press news 1988-90)", "start_pos": 73, "end_pos": 107, "type": "DATASET", "confidence": 0.8801402449607849}, {"text": "WSJ (Wall Street Journal 1987-92)", "start_pos": 124, "end_pos": 157, "type": "DATASET", "confidence": 0.8398915103503636}, {"text": "TREC8", "start_pos": 226, "end_pos": 231, "type": "METRIC", "confidence": 0.7378916144371033}]}, {"text": "shows the statistics of these data.", "labels": [], "entities": []}, {"text": "We choose the first four TREC data sets for performance comparison with (: Experiment data sets documents are usually short, and our previous experience shows that it is a relatively difficult data set.", "labels": [], "entities": [{"text": "TREC data sets", "start_pos": 25, "end_pos": 39, "type": "DATASET", "confidence": 0.7956233421961466}]}], "tableCaptions": [{"text": " Table 2: Comparisons with baselines. *,**,*** indicate that we accept the improvement hypothesis by  Wilcoxon test at significance level 0.1, 0.05, 0.01 respectively.", "labels": [], "entities": [{"text": "significance level 0.1", "start_pos": 119, "end_pos": 141, "type": "METRIC", "confidence": 0.9510113000869751}]}, {"text": " Table 3: PR curve on AP data. *,**,*** indicate that  we accept the improvement hypothesis by Wilcoxon  test at significant level 0.1, 0.05, 0.01 respectively.", "labels": [], "entities": [{"text": "PR", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9748778939247131}, {"text": "AP data", "start_pos": 22, "end_pos": 29, "type": "DATASET", "confidence": 0.8925885558128357}]}, {"text": " Table 4: Comparisons with CBDM.", "labels": [], "entities": []}, {"text": " Table 5: Impact on short documents (in MAP)", "labels": [], "entities": []}, {"text": " Table 6:  Combination with pseudo feed- back.*,**,*** indicate that we accept the improve- ment hypothesis by Wilcoxon test at significant  level 0.1, 0.05, 0.01 respectively.", "labels": [], "entities": []}, {"text": " Table 7: Performance of the interpolation algorithm  combined with the pseudo feedback.", "labels": [], "entities": []}]}