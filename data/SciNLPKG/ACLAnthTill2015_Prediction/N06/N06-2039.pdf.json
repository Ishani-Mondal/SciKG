{"title": [{"text": "Unsupervised Induction of Modern Standard Arabic Verb Classes", "labels": [], "entities": [{"text": "Induction of Modern Standard Arabic Verb Classes", "start_pos": 13, "end_pos": 61, "type": "TASK", "confidence": 0.510402249438422}]}], "abstractContent": [{"text": "We exploit the resources in the Ara-bic Treebank (ATB) for the novel task of automatically creating lexical semantic verb classes for Modern Standard Arabic (MSA).", "labels": [], "entities": [{"text": "Ara-bic Treebank (ATB)", "start_pos": 32, "end_pos": 54, "type": "DATASET", "confidence": 0.8588355839252472}, {"text": "Modern Standard Arabic (MSA)", "start_pos": 134, "end_pos": 162, "type": "TASK", "confidence": 0.690400093793869}]}, {"text": "Verbs are clustered into groups that share semantic elements of meaning as they exhibit similar syntactic behavior.", "labels": [], "entities": []}, {"text": "The results of the clustering experiments are compared with a gold standard set of classes, which is approximated by using the noisy English translations provided in the ATB to create Levin-like classes for MSA.", "labels": [], "entities": [{"text": "ATB", "start_pos": 170, "end_pos": 173, "type": "DATASET", "confidence": 0.9587816596031189}]}, {"text": "The quality of the clusters is found to be sensitive to the inclusion of information about lexical heads of the constituents in the syntactic frames, as well as parameters of the clustering algorithm.", "labels": [], "entities": []}, {"text": "The best set of parameters yields an F \u03b2=1 score of 0.501, compared to a random baseline with an F \u03b2=1 score of 0.37.", "labels": [], "entities": [{"text": "F \u03b2=1 score", "start_pos": 37, "end_pos": 48, "type": "METRIC", "confidence": 0.9811016321182251}, {"text": "F \u03b2=1 score", "start_pos": 97, "end_pos": 108, "type": "METRIC", "confidence": 0.9652167797088623}]}], "introductionContent": [{"text": "The creation of the Arabic Treebank (ATB) facilitates corpus based studies of many interesting linguistic phenomena in Modern Standard Arabic (MSA).", "labels": [], "entities": [{"text": "Arabic Treebank (ATB)", "start_pos": 20, "end_pos": 41, "type": "DATASET", "confidence": 0.8531101822853089}, {"text": "Modern Standard Arabic (MSA)", "start_pos": 119, "end_pos": 147, "type": "DATASET", "confidence": 0.6495799273252487}]}, {"text": "The ATB comprises manually annotated morphological and syntactic analyses of newswire text from different Arabic sources.", "labels": [], "entities": []}, {"text": "We exploit the ATB for the novel task of automatically creating lexical semantic verb classes for MSA.", "labels": [], "entities": []}, {"text": "We are interested in the problem of classifying verbs in MSA into groups that share semantic elements of meaning as they exhibit similar syntactic behavior.", "labels": [], "entities": []}, {"text": "This 1 http://www.ldc.org manner of classifying verbs in a language is mainly advocated by.", "labels": [], "entities": []}, {"text": "The Levin Hypothesis (LH) contends that verbs that exhibit similar syntactic behavior share element(s) of meaning.", "labels": [], "entities": []}, {"text": "There exists a relatively extensive classification of English verbs according to different syntactic alternations, and numerous linguistic studies of other languages illustrate that LH holds cross linguistically, in spite of variations in the verb class assignment (.", "labels": [], "entities": []}, {"text": "For MSA, the only test of LH has been the work of, arguing for Middle and Unaccusative alternations in Arabic.", "labels": [], "entities": [{"text": "MSA", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.8246734738349915}, {"text": "LH", "start_pos": 26, "end_pos": 28, "type": "METRIC", "confidence": 0.804728627204895}]}, {"text": "To date, no general study of MSA verbs and alternations exists.", "labels": [], "entities": [{"text": "MSA verbs and alternations", "start_pos": 29, "end_pos": 55, "type": "TASK", "confidence": 0.869298443198204}]}, {"text": "We address this problem by automatically inducing such classes, exploiting explicit syntactic and morphological information in the ATB.", "labels": [], "entities": []}, {"text": "Inducing such classes automatically allows fora large-scale study of different linguistic phenomena within the MSA verb system, as well as crosslinguistic comparison with their English counterparts.", "labels": [], "entities": []}, {"text": "Moreover, drawing on generalizations yielded by such a classification could potentially be useful in several NLP problems such as Information Extraction, Event Detection, Information Retrieval and Word Sense Disambiguation, not to mention the facilitation of lexical resource creation such as MSA WordNets and ontologies.", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 130, "end_pos": 152, "type": "TASK", "confidence": 0.7626000940799713}, {"text": "Event Detection", "start_pos": 154, "end_pos": 169, "type": "TASK", "confidence": 0.7303594946861267}, {"text": "Information Retrieval", "start_pos": 171, "end_pos": 192, "type": "TASK", "confidence": 0.7536137104034424}, {"text": "Word Sense Disambiguation", "start_pos": 197, "end_pos": 222, "type": "TASK", "confidence": 0.6448399126529694}, {"text": "MSA WordNets", "start_pos": 293, "end_pos": 305, "type": "DATASET", "confidence": 0.8239039480686188}]}], "datasetContent": [{"text": "The evaluation metric used here is a variation on an F -score derived for hard clustering).", "labels": [], "entities": [{"text": "F -score", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9822065234184265}]}, {"text": "The result is an F \u03b2 measure, where \u03b2 is the coefficient of the relative strengths of precision and recall.", "labels": [], "entities": [{"text": "F \u03b2 measure", "start_pos": 17, "end_pos": 28, "type": "METRIC", "confidence": 0.9842410087585449}, {"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9992597699165344}, {"text": "recall", "start_pos": 100, "end_pos": 106, "type": "METRIC", "confidence": 0.9975851774215698}]}, {"text": "\u03b2 = 1 for all results we report.", "labels": [], "entities": []}, {"text": "The score measures the maximum overlap between a hypothesized cluster (HYP) and a corresponding gold standard cluster (GOLD), and computes a weighted average across all the HYP clus- Here A is the set of HYP clusters, C is the set of GOLD clusters, and V tot = \ud97b\udf59 A\u2208A \ud97b\udf59A\ud97b\udf59 is the total number of verbs that were clustered into the HYP set.", "labels": [], "entities": []}, {"text": "This can be larger than the number of verbs to be clustered because verbs can be members of more than one cluster.", "labels": [], "entities": []}], "tableCaptions": []}