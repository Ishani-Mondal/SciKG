{"title": [{"text": "Learning to recognize features of valid textual entailments", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper advocates anew architecture for tex-tual inference in which finding a good alignment is separated from evaluating entailment.", "labels": [], "entities": [{"text": "tex-tual inference", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.8131603896617889}]}, {"text": "Current approaches to semantic inference in question answering and textual entailment have approximated the entailment problem as that of computing the best alignment of the hypothesis to the text, using a locally decomposable matching score.", "labels": [], "entities": [{"text": "semantic inference", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.7819854021072388}, {"text": "question answering", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.7883868515491486}, {"text": "textual entailment", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.710977092385292}]}, {"text": "We argue that there are significant weaknesses in this approach, including flawed assumptions of monotonicity and locality.", "labels": [], "entities": []}, {"text": "Instead we propose a pipelined approach where alignment is followed by a classification step, in which we extract features representing high-level characteristics of the entailment problem , and pass the resulting feature vector to a statistical classifier trained on development data.", "labels": [], "entities": []}, {"text": "We report results on data from the 2005 Pascal RTE Challenge which surpass previously reported results for alignment-based systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "During the last five years there has been a surge in work which aims to provide robust textual inference in arbitrary domains about which the system has no expertise.", "labels": [], "entities": []}, {"text": "The best-known such work has occurred within the field of question answering; more recently, such work has continued with greater focus in addressing the PASCAL Recognizing Textual Entailment (RTE) Challenge () and within the U.S. Government AQUAINT program.", "labels": [], "entities": [{"text": "question answering", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.9017180502414703}, {"text": "PASCAL Recognizing Textual Entailment (RTE) Challenge", "start_pos": 154, "end_pos": 207, "type": "TASK", "confidence": 0.7328469641506672}]}, {"text": "Substantive progress on this task is key to many text and natural language applications.", "labels": [], "entities": []}, {"text": "If one could tell that Protestors chanted slogans opposing a free trade agreement was a match for people demonstrating against free trade, then one could offer a form of semantic search not available with current keywordbased search.", "labels": [], "entities": []}, {"text": "Even greater benefits would flow to richer and more semantically complex NLP tasks.", "labels": [], "entities": []}, {"text": "Because full, accurate, open-domain natural language understanding lies far beyond current capabilities, nearly all efforts in this area have sought to extract the maximum mileage from quite limited semantic representations.", "labels": [], "entities": [{"text": "open-domain natural language understanding", "start_pos": 24, "end_pos": 66, "type": "TASK", "confidence": 0.6590994298458099}]}, {"text": "Some have used simple measures of semantic overlap, but the more interesting work has largely converged on a graphalignment approach, operating on semantic graphs derived from syntactic dependency parses, and using a locally-decomposable alignment score as a proxy for strength of entailment.", "labels": [], "entities": []}, {"text": "(Below, we argue that even approaches relying on weighted abduction maybe seen in this light.)", "labels": [], "entities": []}, {"text": "In this paper, we highlight the fundamental semantic limitations of this type of approach, and advocate a multi-stage architecture that addresses these limitations.", "labels": [], "entities": []}, {"text": "The three key limitations are an assumption of monotonicity, an assumption of locality, and a confounding of alignment and evaluation of entailment.", "labels": [], "entities": []}, {"text": "We focus on the PASCAL RTE data, examples from which are shown in table 1.", "labels": [], "entities": [{"text": "PASCAL RTE data", "start_pos": 16, "end_pos": 31, "type": "DATASET", "confidence": 0.6714150607585907}]}, {"text": "This data set contains pairs consisting of a short text followed by a one-sentence hypothesis.", "labels": [], "entities": []}, {"text": "The goal is to say whether the hypothesis follows from the text and general background knowledge, according to the intuitions of an intelligent human reader.", "labels": [], "entities": []}, {"text": "That is, the standard is not whether the hypothesis is logically entailed, but whether it can reasonably be inferred.", "labels": [], "entities": []}], "datasetContent": [{"text": "We present results based on the First PASCAL RTE Challenge, which used a development set containing 567 pairs and a test set containing 800 pairs.", "labels": [], "entities": [{"text": "First PASCAL RTE Challenge", "start_pos": 32, "end_pos": 58, "type": "DATASET", "confidence": 0.7253406420350075}]}, {"text": "The data sets are balanced to contain equal numbers of yes and no answers.", "labels": [], "entities": []}, {"text": "The RTE Challenge recommended two evaluation metrics: raw accuracy and confidence weighted score (CWS).", "labels": [], "entities": [{"text": "RTE Challenge", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.7937489748001099}, {"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9103089570999146}, {"text": "confidence weighted score (CWS)", "start_pos": 71, "end_pos": 102, "type": "METRIC", "confidence": 0.9392410417397817}]}, {"text": "The CWS is computed as follows: for each positive integer k up to the size of the test set, we compute accuracy over the k most confident predictions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.999322772026062}]}, {"text": "The CWS is then the average, over k, of these partial accuracies.", "labels": [], "entities": []}, {"text": "Like raw accuracy, it lies in the interval, but it will exceed raw accuracy to the degree that predictions are well-calibrated.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9400057792663574}, {"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.8614112734794617}]}, {"text": "Several characteristics of the RTE problems should be emphasized.", "labels": [], "entities": [{"text": "RTE", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9284363389015198}]}, {"text": "Examples are derived from abroad variety of sources, including newswire; therefore systems must be domain-independent.", "labels": [], "entities": []}, {"text": "The inferences required are, from a human perspective, fairly superficial: no long chains of reasoning are involved.", "labels": [], "entities": []}, {"text": "However, there are \"trick\" questions expressly designed to foil simplistic techniques.", "labels": [], "entities": []}, {"text": "The definition of entailment is informal and approximate: whether a competent speaker with basic knowledge of the world would typically infer the hypothesis from the text.", "labels": [], "entities": []}, {"text": "Entailments will certainly depend on linguistic knowledge, and may also depend on world knowledge; however, the scope of required  world knowledge is left unspecified.", "labels": [], "entities": []}, {"text": "Despite the informality of the problem definition, human judges exhibit very good agreement on the RTE task, with agreement rate of 91-96% (.", "labels": [], "entities": [{"text": "RTE task", "start_pos": 99, "end_pos": 107, "type": "TASK", "confidence": 0.8648649156093597}, {"text": "agreement rate", "start_pos": 114, "end_pos": 128, "type": "METRIC", "confidence": 0.9850809276103973}]}, {"text": "In principle, then, the upper bound for machine performance is quite high.", "labels": [], "entities": []}, {"text": "In practice, however, the RTE task is exceedingly difficult for computers.", "labels": [], "entities": [{"text": "RTE task", "start_pos": 26, "end_pos": 34, "type": "TASK", "confidence": 0.9236993789672852}]}, {"text": "Participants in the first PASCAL RTE workshop reported accuracy from 49% to 59%, and CWS from 50.0% to 69.0% (.", "labels": [], "entities": [{"text": "PASCAL RTE workshop", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.5738425453503927}, {"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9996154308319092}]}, {"text": "shows results fora range of systems and testing conditions.", "labels": [], "entities": []}, {"text": "We report accuracy and CWS on each RTE data set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9995875954627991}, {"text": "CWS", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.9895379543304443}, {"text": "RTE data set", "start_pos": 35, "end_pos": 47, "type": "DATASET", "confidence": 0.9178474346796671}]}, {"text": "The baseline for all experiments is random guessing, which always attains 50% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.998524010181427}]}, {"text": "We show comparable results from recent systems based on lexical similarity (Jijkoun and de), graph alignment (), weighted abduction (), and a mixed system including theorem proving).", "labels": [], "entities": [{"text": "graph alignment", "start_pos": 93, "end_pos": 108, "type": "TASK", "confidence": 0.6903980225324631}]}, {"text": "We then show results for our system under several different training regimes.", "labels": [], "entities": []}, {"text": "The row labeled \"alignment only\" describes experiments in which all features except the alignment score are turned off.", "labels": [], "entities": []}, {"text": "We predict entailment just in case the alignment score exceeds a threshold which is optimized on development data.", "labels": [], "entities": []}, {"text": "\"Hand-tuning\" describes experiments in which all features are on, but no training occurs; rather, weights are set by hand, according to human intuition.", "labels": [], "entities": []}, {"text": "Finally, \"learning\" describes experiments in which all features are on, and feature weights are trained on the development data.", "labels": [], "entities": []}, {"text": "The Each RTE problem is also tagged as belonging to one of seven tasks.", "labels": [], "entities": [{"text": "RTE problem", "start_pos": 9, "end_pos": 20, "type": "TASK", "confidence": 0.7761195003986359}]}, {"text": "Previous work () has shown that conditioning on task can significantly improve accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9969109892845154}]}, {"text": "In this work, however, we ignore the task variable, and none of the results shown in table 2 reflect optimization by task.", "labels": [], "entities": []}, {"text": "figures reported for development data performance therefore reflect overfitting; while such results are not a fair measure of overall performance, they can help us assess the adequacy of our feature set: if our features have failed to capture relevant aspects of the problem, we should expect poor performance even when overfitting.", "labels": [], "entities": []}, {"text": "It is therefore encouraging to see CWS above 70%.", "labels": [], "entities": [{"text": "CWS", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.3866298198699951}]}, {"text": "Finally, the figures reported for test data performance are the fairest basis for comparison.", "labels": [], "entities": []}, {"text": "These are significantly better than our results for alignment only (Fisher's exact test, p < 0.05), indicating that we gain real value from our features.", "labels": [], "entities": [{"text": "alignment", "start_pos": 52, "end_pos": 61, "type": "TASK", "confidence": 0.9671421647071838}]}, {"text": "However, the gain over comparable results from other teams is not significant at the p < 0.05 level.", "labels": [], "entities": []}, {"text": "A curious observation is that the results for handtuned weights are as good or better than results for learned weights.", "labels": [], "entities": []}, {"text": "A possible explanation runs as follows.", "labels": [], "entities": []}, {"text": "Most of the features represent high-level patterns which arise only occasionally.", "labels": [], "entities": []}, {"text": "Because the training data contains only a few hundred examples, many features are active in just a handful of instances; their learned weights are therefore quite noisy.", "labels": [], "entities": []}, {"text": "Indeed, a feature which is expected to favor entailment may even windup with a negative weight: the modal feature weak yes is an example.", "labels": [], "entities": []}, {"text": "As shown in table 3, the learned weight for this feature was strongly negative -but this resulted from a single training example in which the feature was active but the hypothesis was not entailed.", "labels": [], "entities": []}, {"text": "In such cases, we shouldn't expect good generalization to test data, and human intuition about the \"value\" of specific features maybe more reliable.", "labels": [], "entities": []}, {"text": "shows the values learned for selected feature weights.", "labels": [], "entities": []}, {"text": "As expected, the features added adjunct in all context, modal yes, and text is factive were all found to be strong indicators of entailment, while date insert, date modifier insert, widening from text to hyp all indicate lack of entailment.", "labels": [], "entities": []}, {"text": "Interestingly, text has neg marker and text & hyp diff polarity were also found to disfavor entailment; while this outcome is sensible, it was not anticipated or designed.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Performance on the RTE development and test sets.  CWS stands for confidence weighted score (see text).", "labels": [], "entities": [{"text": "RTE development and test sets", "start_pos": 29, "end_pos": 58, "type": "DATASET", "confidence": 0.8051706433296204}, {"text": "CWS", "start_pos": 61, "end_pos": 64, "type": "METRIC", "confidence": 0.7702906727790833}, {"text": "confidence weighted score", "start_pos": 76, "end_pos": 101, "type": "METRIC", "confidence": 0.9433170159657797}]}, {"text": " Table 3: Learned weights for selected features. Positive weights  favor entailment. Weights near 0 are omitted. Based on training  on the PASCAL RTE development set.", "labels": [], "entities": [{"text": "PASCAL RTE development set", "start_pos": 139, "end_pos": 165, "type": "DATASET", "confidence": 0.8721872717142105}]}]}