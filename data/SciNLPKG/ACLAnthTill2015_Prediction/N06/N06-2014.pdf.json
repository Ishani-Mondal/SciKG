{"title": [{"text": "Agreement/Disagreement Classification: Exploiting Unlabeled Data using Contrast Classifiers", "labels": [], "entities": [{"text": "Agreement/Disagreement Classification", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.6700830832123756}]}], "abstractContent": [{"text": "Several semi-supervised learning methods have been proposed to leverage unlabeled data, but imbalanced class distributions in the data set can hurt the performance of most algorithms.", "labels": [], "entities": []}, {"text": "In this paper, we adapt the new approach of contrast classifiers for semi-supervised learning.", "labels": [], "entities": []}, {"text": "This enables us to exploit large amounts of unlabeled data with a skewed distribution.", "labels": [], "entities": []}, {"text": "In experiments on a speech act (agreement/disagreement) classification problem, we achieve better results than other semi-supervised methods.", "labels": [], "entities": [{"text": "speech act (agreement/disagreement) classification problem", "start_pos": 20, "end_pos": 78, "type": "TASK", "confidence": 0.6891195774078369}]}, {"text": "We also obtain performance comparable to the best results reported so far on this task and outperform systems with equivalent feature sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "In natural language understanding research with data-driven techniques, data labeling is an essential but time-consuming and costly process.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 3, "end_pos": 33, "type": "TASK", "confidence": 0.6404112378756205}, {"text": "data labeling", "start_pos": 72, "end_pos": 85, "type": "TASK", "confidence": 0.7073147594928741}]}, {"text": "To alleviate this effort, various semi-supervised learning algorithms such as self-training, cotraining (), transductive SVM (Joachims, 1999) and many others have been proposed and successfully applied under different assumptions and settings.", "labels": [], "entities": []}, {"text": "They all aim to improve classification accuracy by exploiting more readily available unlabeled data as well as labeled examples.", "labels": [], "entities": [{"text": "classification", "start_pos": 24, "end_pos": 38, "type": "TASK", "confidence": 0.9754197597503662}, {"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9105930328369141}]}, {"text": "However, these iterative training methods have shortcomings when trained on data with imbalanced class distributions.", "labels": [], "entities": []}, {"text": "One reason is that most classifiers underlying these methods assume a balanced training set, and thus when one of the classes has a much larger number of examples than the other classes, the trained classifier will be biased toward the majority class.", "labels": [], "entities": []}, {"text": "The imbalance will propagate through subsequent iterations, resulting in a more skewed data set upon which a further biased classifier will be trained.", "labels": [], "entities": []}, {"text": "To exploit unlabeled data in learning an inherently skewed data distribution, we introduce a semi-supervised classification method using contrast classifiers, first proposed by.", "labels": [], "entities": []}, {"text": "It approximates the posterior class probability given an observation using class-specific contrast classifiers that implicitly model the difference between the distribution of labeled data for that class and the unlabeled data.", "labels": [], "entities": []}, {"text": "In this paper, we will explore the applicability of contrast classifiers to the problem of semisupervised learning for identifying agreements and disagreements in multi-party conversational speech.", "labels": [], "entities": [{"text": "identifying agreements and disagreements in multi-party conversational speech", "start_pos": 119, "end_pos": 196, "type": "TASK", "confidence": 0.7393133863806725}]}, {"text": "These labels represent a simple type of \"speech act\" that can be important for understanding the interaction between speakers, or for automatically summarizing or browsing the contents of a meeting.", "labels": [], "entities": [{"text": "summarizing or browsing the contents of a meeting", "start_pos": 148, "end_pos": 197, "type": "TASK", "confidence": 0.7877736762166023}]}, {"text": "This problem was previously studied), using a subset of ICSI meeting recording corpus (.", "labels": [], "entities": [{"text": "ICSI meeting recording corpus", "start_pos": 56, "end_pos": 85, "type": "DATASET", "confidence": 0.9230147749185562}]}, {"text": "In semisupervised learning, there is a challenge due to an imbalanced class distribution: over 60% of the data are associated with the default class and only 5% are with disagreements.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted experiments to answer the following questions.", "labels": [], "entities": []}, {"text": "First, is the contrast classifier approach applicable to language processing problems, which often involve large amounts of unlabeled data?", "labels": [], "entities": []}, {"text": "Second, does it outperform other semi-supervised learning methods on a skewed data set?", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of 3-way classification accu- racy on lexical (lex) vs. expanded (exp) features  sets.  Accuracy  Hillard-lex 82  Galley-lex 85.0  SVM-lex  86.3  CC-lex  86.7  Galley-exp 86.9", "labels": [], "entities": [{"text": "Accuracy  Hillard-lex 82  Galley-lex 85.0  SVM-lex  86.3  CC-lex  86.7  Galley-exp 86.9", "start_pos": 109, "end_pos": 196, "type": "DATASET", "confidence": 0.7355661744421179}]}, {"text": " Table 2: Comparison of the classification perfor- mance  Method  3-way A/D  A/D  Acc  confusion recovery  unsupervised 79  8  83  cc  81.4  4  82.4  cc-threshold  76.7  6  85.2  cc-meta  86.7  5  81.3  cc-meta-thres 87.1  5  82.4", "labels": [], "entities": [{"text": "Acc  confusion recovery", "start_pos": 82, "end_pos": 105, "type": "METRIC", "confidence": 0.7944170236587524}]}, {"text": " Table 3: Classification performance, training on the  entire ICSI data set. F is defined as 2pr  p+r where p is  macro precision and r is the macro recall.  Method  Acc F  Neg recall  SVM  85.4 72.6 21.1  self-training 80.4 65.3 5.2  cotraining  85.1 73.8 47.4  cc  83.0 75.5 68.5", "labels": [], "entities": [{"text": "ICSI data set", "start_pos": 62, "end_pos": 75, "type": "DATASET", "confidence": 0.9702678918838501}, {"text": "F", "start_pos": 77, "end_pos": 78, "type": "METRIC", "confidence": 0.9986777901649475}, {"text": "precision", "start_pos": 120, "end_pos": 129, "type": "METRIC", "confidence": 0.8424567580223083}, {"text": "recall", "start_pos": 149, "end_pos": 155, "type": "METRIC", "confidence": 0.964722216129303}, {"text": "Acc F  Neg recall", "start_pos": 166, "end_pos": 183, "type": "METRIC", "confidence": 0.6509033739566803}, {"text": "SVM  85.4 72.6 21.1  self-training 80.4 65.3 5.2  cotraining  85.1 73.8 47.4", "start_pos": 185, "end_pos": 261, "type": "DATASET", "confidence": 0.7824936981002489}]}]}