{"title": [{"text": "Evaluating Centering for Sentence Ordering in Two New Domains", "labels": [], "entities": [{"text": "Sentence Ordering", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.8633565604686737}]}], "abstractContent": [{"text": "This paper builds on recent research investigating sentence ordering in text production by evaluating the Centering-based metrics of coherence employed by Karamanis et al.", "labels": [], "entities": [{"text": "sentence ordering in text production", "start_pos": 51, "end_pos": 87, "type": "TASK", "confidence": 0.6517087459564209}]}, {"text": "(2004) using the data of Barzilay and Lapata (2005).", "labels": [], "entities": []}, {"text": "This is the first time that Centering is evaluated empirically as a sentence ordering constraint in several domains, verifying the results reported in Karamanis et al.", "labels": [], "entities": []}], "introductionContent": [{"text": "As most literature in text linguistics argues, a felicitous text should be coherent which means that the content has to be organised in away that makes the text easy to read and comprehend.", "labels": [], "entities": [{"text": "text linguistics", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.7342986762523651}]}, {"text": "The easiest way to demonstrate this claim is by arbitrarily reordering the sentences that an understandable text consists of.", "labels": [], "entities": []}, {"text": "This process very often gives rise to documents that do not make sense although the information content remains the same.", "labels": [], "entities": []}, {"text": "Hence, deciding in which sequence to present a set of preselected information-bearing items is an important problem in automatic text production.", "labels": [], "entities": [{"text": "automatic text production", "start_pos": 119, "end_pos": 144, "type": "TASK", "confidence": 0.6123461524645487}]}, {"text": "Entity coherence, which arises from the way NP referents relate subsequent sentences in the text, is an important aspect of textual felicity.", "labels": [], "entities": []}, {"text": "Centering Theory ( has been an influential framework for modelling entity coherence in computational linguistics in the last two decades. were the first to evaluate Centering-based metrics of coherence for ordering clauses in a subset of the GNOME corpus ( ) consisting of 20 artefact descriptions.", "labels": [], "entities": [{"text": "GNOME corpus", "start_pos": 242, "end_pos": 254, "type": "DATASET", "confidence": 0.9294220507144928}]}, {"text": "They introduced a novel experimental methodology that treats the observed ordering of clauses in a text as the gold standard, which is scored by each metric.", "labels": [], "entities": []}, {"text": "Then, the metric is penalised proportionally to the amount of alternative orderings of the same material that score equally to or better than the gold standard.", "labels": [], "entities": []}, {"text": "This methodology is very similar to the way Barzilay and evaluate automatically another model of coherence called the entity grid using a larger collection of 200 articles from the North American News Corpus (NEWS) and 200 accident narratives from the National Transportation Safety Board database (ACCS).", "labels": [], "entities": [{"text": "North American News Corpus (NEWS)", "start_pos": 181, "end_pos": 214, "type": "DATASET", "confidence": 0.7768543362617493}, {"text": "National Transportation Safety Board database (ACCS)", "start_pos": 252, "end_pos": 304, "type": "DATASET", "confidence": 0.7904318571090698}]}, {"text": "The same data and similar methods were used by to compare their probabilistic approach for ordering sentences with that of.", "labels": [], "entities": []}, {"text": "This paper discusses how the Centering-based metrics of coherence employed by can be evaluated on the data prepared by Barzilay and Lapata.", "labels": [], "entities": []}, {"text": "This is the first time that Centering is evaluated empirically as a sentence ordering constraint in more than one domain, verifying the results reported in Karamanis et al.", "labels": [], "entities": []}, {"text": "The paper also contributes by emphasising the following methodological point: To conduct our experiments, we need to produce several alternative orderings of sentences and compare them with the gold standard.", "labels": [], "entities": []}, {"text": "As the number of possible orderings grows factorially, enumerating them exhaustively (as Barzilay and Lee do) becomes impractical.", "labels": [], "entities": []}, {"text": "In this paper, we make use of the methods of which allow us to explore a: (A) Fragment of the entity grid for example (1); (B) CP (i.e. first member of the CF list), next two referents, CB, transition and violations of CHEAPNESS (denoted with a * ) for the same example.", "labels": [], "entities": [{"text": "CB", "start_pos": 186, "end_pos": 188, "type": "METRIC", "confidence": 0.9293931722640991}, {"text": "transition", "start_pos": 190, "end_pos": 200, "type": "METRIC", "confidence": 0.9526780843734741}, {"text": "violations", "start_pos": 205, "end_pos": 215, "type": "METRIC", "confidence": 0.9672311544418335}]}, {"text": "sufficient number of alternative orderings and return more reliable results than Barzilay and Lapata, who used a sample of just 20 randomly produced orderings (often out of several millions).", "labels": [], "entities": []}], "datasetContent": [{"text": "As already mentioned, previous work assumes that the gold standard ordering (GSO) observed in a text is more coherent than any other ordering of the sentences (or the corresponding CF lists) it consists of.", "labels": [], "entities": [{"text": "gold standard ordering (GSO)", "start_pos": 53, "end_pos": 81, "type": "METRIC", "confidence": 0.6781907230615616}]}, {"text": "If a metric takes a randomly produced ordering to be more coherent than the GSO, it has to be penalised.", "labels": [], "entities": [{"text": "GSO", "start_pos": 76, "end_pos": 79, "type": "DATASET", "confidence": 0.8144780993461609}]}, {"text": "introduce a measure called the classification rate which estimates this penalty as the weighted sum of the percentage of alternative orderings that score equally to or better than the GSO.", "labels": [], "entities": [{"text": "GSO", "start_pos": 184, "end_pos": 187, "type": "DATASET", "confidence": 0.8284698724746704}]}, {"text": "When comparing several metrics with each other, the one with the lowest classification rate is the most appropriate for sentence ordering.", "labels": [], "entities": [{"text": "sentence ordering", "start_pos": 120, "end_pos": 137, "type": "TASK", "confidence": 0.7961690127849579}]}, {"text": "argues that computing the classification rate using a random sample of one million orderings provides reliable results for the entire population of orderings.", "labels": [], "entities": [{"text": "classification", "start_pos": 26, "end_pos": 40, "type": "TASK", "confidence": 0.9596234560012817}]}, {"text": "In our experiments, we used a random sample of that size for GSOs which consisted of more than 10 sentences.", "labels": [], "entities": []}, {"text": "This allows us to explore a sufficient portion of possible orderings (without having to exhaustively enumerate every ordering as Barzilay and Lee do).", "labels": [], "entities": []}, {"text": "Arguably, our experiments also return more reliable results than those of Barzilay and Lapata who used a sample of just a few randomly produced orderings.", "labels": [], "entities": []}, {"text": "Since the Centering-based metrics can be directly deployed on unseen texts without any training, we treated all texts in NEWS and ACCS as testing data.", "labels": [], "entities": [{"text": "NEWS", "start_pos": 121, "end_pos": 125, "type": "DATASET", "confidence": 0.9437404870986938}]}], "tableCaptions": [{"text": " Table 2: Comparing M.NOCB with M.CHEAP,  M.KP and M.BFP in the NEWS corpus.", "labels": [], "entities": [{"text": "NEWS corpus", "start_pos": 64, "end_pos": 75, "type": "DATASET", "confidence": 0.9677611887454987}]}, {"text": " Table 3: Comparing M.NOCB with M.CHEAP,  M.KP and M.BFP in the ACCS corpus.", "labels": [], "entities": [{"text": "ACCS corpus", "start_pos": 64, "end_pos": 75, "type": "DATASET", "confidence": 0.9270345270633698}]}, {"text": " Table 4: Comparing M.NOCB with M.CHEAP,  M.KP and M.BFP in the GNOME corpus.", "labels": [], "entities": [{"text": "GNOME corpus", "start_pos": 64, "end_pos": 76, "type": "DATASET", "confidence": 0.9315039813518524}]}]}