{"title": [{"text": "Generating Training Data for Medical Dictations", "labels": [], "entities": [{"text": "Medical Dictations", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.6515890657901764}]}], "abstractContent": [{"text": "In automatic speech recognition (ASR) enabled applications for medical dictations, corpora of literal transcriptions of speech are critical for training both speaker independent and speaker adapted acoustic models.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 3, "end_pos": 37, "type": "TASK", "confidence": 0.8138694862524668}]}, {"text": "Obtaining these transcriptions is both costly and time consuming.", "labels": [], "entities": []}, {"text": "Non-literal transcriptions, on the other hand, are easy to obtain because they are generated in the normal course of a medical transcription operation.", "labels": [], "entities": []}, {"text": "This paper presents a method of automatically generating texts that can take the place of literal transcriptions for training acoustic and language models.", "labels": [], "entities": []}, {"text": "ATRS 1 is an automatic transcription reconstruction system that can produce near-literal transcriptions with almost no human labor.", "labels": [], "entities": [{"text": "ATRS 1", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.6921002268791199}, {"text": "transcription reconstruction", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.7856951057910919}]}, {"text": "We will show that (i) adapted acoustic models trained on ATRS data perform as well as or better than adapted acoustic models trained on literal transcriptions (as measured by recognition accuracy) and (ii) language models trained on ATRS data have lower perplexity than language models trained on non-literal data.", "labels": [], "entities": [{"text": "ATRS data", "start_pos": 57, "end_pos": 66, "type": "DATASET", "confidence": 0.8828769326210022}, {"text": "ATRS data", "start_pos": 233, "end_pos": 242, "type": "DATASET", "confidence": 0.8826984763145447}]}], "introductionContent": [{"text": "Dictation applications of automatic speech recognition (ASR) require literal transcriptions of speech in order to train both speaker independent and speaker adapted acoustic models.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 26, "end_pos": 60, "type": "TASK", "confidence": 0.8342987795670828}]}, {"text": "Literal transcriptions may also be used to train stochastic language models that need to perform well on spontaneous or disfluent speech.", "labels": [], "entities": []}, {"text": "With the exception of personal desktop systems, however, obtaining these transcriptions is costly and time consuming since they must be produced manually 1 patent pending (Serial No.: 09/487398) by humans educated for the task.", "labels": [], "entities": []}, {"text": "The high cost makes literal transcription unworkable for ASR applications that require adapted acoustic models for thousands of talkers as well as accurate language models for idiosyncratic natural speech.", "labels": [], "entities": [{"text": "literal transcription", "start_pos": 20, "end_pos": 41, "type": "TASK", "confidence": 0.9349680244922638}, {"text": "ASR", "start_pos": 57, "end_pos": 60, "type": "TASK", "confidence": 0.9928036332130432}]}, {"text": "Non-literal transcriptions, on the other hand, are easy to obtain because they are generated in the normal course of a medical transcription operation.", "labels": [], "entities": []}, {"text": "It has been previously shown by that the non-literal transcriptions can be successfully used in acoustic adaptation.", "labels": [], "entities": [{"text": "acoustic adaptation", "start_pos": 96, "end_pos": 115, "type": "TASK", "confidence": 0.7777247130870819}]}, {"text": "However, non-literal transcriptions are incomplete.", "labels": [], "entities": []}, {"text": "They exclude many utterances that commonly occur in medical dictation-filled pauses, repetitions, repairs, ungrammatical phrases, pleasantries, asides to the transcriptionist, etc.", "labels": [], "entities": []}, {"text": "Depending on the talker, such material may constitute a significant portion of the dictation.", "labels": [], "entities": []}, {"text": "We present a method of automatically generating texts that can take the place of literal transcriptions for training acoustic and language models.", "labels": [], "entities": []}, {"text": "ATRS is an automatic transcription reconstruction system that can produce near-literal transcriptions with almost no human labor.", "labels": [], "entities": [{"text": "ATRS", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6714203357696533}, {"text": "transcription reconstruction", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.7940716743469238}]}, {"text": "The following sections will describe ATRS and present experimental results from language and acoustic modeling.", "labels": [], "entities": [{"text": "ATRS", "start_pos": 37, "end_pos": 41, "type": "TASK", "confidence": 0.9251995086669922}]}, {"text": "We will show that (i) adapted acoustic models trained on ATRS data perform as well as or better than adapted acoustic models trained on literal transcriptions (as measured by recognition accuracy) and (ii) language models trained on ATRS data have lower perplexity than language models trained on non-literal data.", "labels": [], "entities": [{"text": "ATRS data", "start_pos": 57, "end_pos": 66, "type": "DATASET", "confidence": 0.8828769326210022}, {"text": "ATRS data", "start_pos": 233, "end_pos": 242, "type": "DATASET", "confidence": 0.8826984763145447}]}, {"text": "Data used in the experiments comes from medical dictations.", "labels": [], "entities": []}, {"text": "All of the dictations are telephone speech.", "labels": [], "entities": []}], "datasetContent": [{"text": "The usefulness of semi-literal transcriptions was evaluated in two ways: acoustic adaptation and language modeling.", "labels": [], "entities": [{"text": "acoustic adaptation", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.7089244872331619}, {"text": "language modeling", "start_pos": 97, "end_pos": 114, "type": "TASK", "confidence": 0.7194565236568451}]}, {"text": "Three speaker adapted acoustic models were trained for each of the 5 talkers in this study using the three types of label files and evaluated on the talker's testing data.", "labels": [], "entities": []}, {"text": "Software licensed from Entropic Laboratory was used for performing recognition, evaluating accuracy and acoustic adaptation.).", "labels": [], "entities": [{"text": "Entropic Laboratory", "start_pos": 23, "end_pos": 42, "type": "DATASET", "confidence": 0.9368507564067841}, {"text": "recognition", "start_pos": 67, "end_pos": 78, "type": "TASK", "confidence": 0.9587342143058777}, {"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9951719641685486}, {"text": "acoustic adaptation.", "start_pos": 104, "end_pos": 124, "type": "TASK", "confidence": 0.7414932698011398}]}, {"text": "Adapted models were trained using MLLR technique () available as part of the Entropic package.", "labels": [], "entities": [{"text": "MLLR", "start_pos": 34, "end_pos": 38, "type": "METRIC", "confidence": 0.8879950046539307}, {"text": "Entropic package", "start_pos": 77, "end_pos": 93, "type": "DATASET", "confidence": 0.9132719933986664}]}, {"text": "Recognition accuracy and correctness reported in this study were calculated according to the following formulas: (1) Acc = hits -insertions / total words (2) Correctness = hits / total words  The following Acoustic Models were trained via adaptation with a general SI model for each talker using all available data (except for the testing data).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9275094866752625}, {"text": "Acc", "start_pos": 117, "end_pos": 120, "type": "METRIC", "confidence": 0.9971801042556763}]}, {"text": "Each model's name reflects the kind of label data that was used for training.", "labels": [], "entities": []}, {"text": "For ASR applications where there are significant discrepancies between an utterance and its formal transcription, the inclusion of literal data in the language model can reduce language model perplexity and improve recognition accuracy.", "labels": [], "entities": [{"text": "ASR", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9911866784095764}, {"text": "accuracy", "start_pos": 227, "end_pos": 235, "type": "METRIC", "confidence": 0.9156638383865356}]}, {"text": "In medical transcription, the non-literal texts typically depart from what has actually been said.", "labels": [], "entities": [{"text": "medical transcription", "start_pos": 3, "end_pos": 24, "type": "TASK", "confidence": 0.7265098094940186}]}, {"text": "Hence if the talker says \"lungs are clear\" or \"lungs sound pretty clear\", the typed transcription is likely to have \"Lungs -clear\".", "labels": [], "entities": [{"text": "Lungs -clear", "start_pos": 117, "end_pos": 129, "type": "METRIC", "confidence": 0.8961210250854492}]}, {"text": "In addition, as we noted earlier, the non-literal transcription will omit disfluencies and asides and will correct grammatical errors.", "labels": [], "entities": []}, {"text": "Literal and semi-literal texts can be added onto language model training data or interpolated into an existing language model.", "labels": [], "entities": []}, {"text": "Below we will present results of a language modeling experiment that compares language models built from literal, semiliteral and non-literal versions of the same training set.", "labels": [], "entities": []}, {"text": "The results substantiate our claim that automatically generated semi-literal transcription can lead to a significant improvement in language model quality.", "labels": [], "entities": []}, {"text": "In order to test the proposed method's suitability for language modeling, we constructed three trigram language models and used perplexity as the measure of the models' goodness.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.7190206944942474}]}], "tableCaptions": [{"text": " Table 1. Recognition results for three adaptation  methods", "labels": [], "entities": [{"text": "Recognition", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.8113114833831787}]}, {"text": " Table 2. Perplexity tests on LLM, NLM, SLM", "labels": [], "entities": [{"text": "SLM", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.4550143778324127}]}]}