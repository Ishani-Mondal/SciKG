{"title": [{"text": "Unsupervised Learning of Name Structure From Coreference Data *", "labels": [], "entities": [{"text": "Unsupervised Learning of Name Structure", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.4908149003982544}]}], "abstractContent": [{"text": "We present two methods for learning the structure of personal names from unlabeled data.", "labels": [], "entities": [{"text": "learning the structure of personal names", "start_pos": 27, "end_pos": 67, "type": "TASK", "confidence": 0.7713000029325485}]}, {"text": "The first simply uses a few implicit constraints governing this structure to gain a toehold on the problem-e.g., descriptors come before first names, which come before middle names, etc.", "labels": [], "entities": []}, {"text": "The second model also uses possible coreference information.", "labels": [], "entities": []}, {"text": "We found that coreference constraints on names improve the performance of the model from 92.6% to 97.0%.", "labels": [], "entities": []}, {"text": "We are interested in this problem in its own right, but also as a possible way to improve named entity recognition (by recognizing the structure of different kinds of names) and as away to improve noun-phrase coreference determination.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 90, "end_pos": 114, "type": "TASK", "confidence": 0.6323001682758331}, {"text": "noun-phrase coreference determination", "start_pos": 197, "end_pos": 234, "type": "TASK", "confidence": 0.8007557392120361}]}], "introductionContent": [{"text": "We present two methods for the unsupervised learning of the structure of personal names as found in Wall Street Journal text.", "labels": [], "entities": [{"text": "learning of the structure of personal names", "start_pos": 44, "end_pos": 87, "type": "TASK", "confidence": 0.6948409335953849}, {"text": "Wall Street Journal text", "start_pos": 100, "end_pos": 124, "type": "DATASET", "confidence": 0.9694012105464935}]}, {"text": "More specifically, we consider a \"name\" to be a sequence of proper nouns from a single noun-phrase (as indicated by Penn treebank-style parse trees).", "labels": [], "entities": [{"text": "Penn treebank-style parse trees", "start_pos": 116, "end_pos": 147, "type": "DATASET", "confidence": 0.9472925066947937}]}, {"text": "For example, \"Defense Secretary George W. Smith\" would be a name and we would analyze it into the components \"Defense Secretary\" (a descriptor), \"George\" (a first name), \"W.\"", "labels": [], "entities": []}, {"text": "(a middle name, we do not distinguish between initials and \"true\" names), and \"Smith\" (a last name).", "labels": [], "entities": []}, {"text": "We consider two unsupervised models for learning this information.", "labels": [], "entities": []}, {"text": "The first simply uses a few implicit constraints governing this structure to gain a toehold on the problem -e.g., descriptors come before first names, which come * This research was supported in part by NSF grant LIS SBR 9720368.", "labels": [], "entities": [{"text": "NSF grant LIS SBR 9720368", "start_pos": 203, "end_pos": 228, "type": "DATASET", "confidence": 0.7406690716743469}]}, {"text": "The author would like to thank Mark Johnson and the rest of the Brown Laboratory for Linguistic Information Processing (BLLIP) for general advice and encouragement.", "labels": [], "entities": [{"text": "Brown Laboratory for Linguistic Information Processing (BLLIP)", "start_pos": 64, "end_pos": 126, "type": "DATASET", "confidence": 0.6159259676933289}]}, {"text": "before middle names, etc.", "labels": [], "entities": []}, {"text": "We henceforth call this the \"name\" model.", "labels": [], "entities": []}, {"text": "The second model also uses possible coreference information.", "labels": [], "entities": []}, {"text": "Typically the same individual is mentioned several times in the same article (e.g., we might later encounter \"Mr. Smith\"), and the pattern of such references, and the mutual constraints among them, could very well help our unsupervised methods determine the correct structure.", "labels": [], "entities": []}, {"text": "We call this the \"coreference\" model.", "labels": [], "entities": []}, {"text": "We were attracted to this second model as it might offer a small example of how semantic information like coreference could help in learning structural information.", "labels": [], "entities": []}, {"text": "To the best of our knowledge there has not been any previous work on learning personal structure.", "labels": [], "entities": [{"text": "learning personal structure", "start_pos": 69, "end_pos": 96, "type": "TASK", "confidence": 0.7481058835983276}]}, {"text": "We are aware of one previous case of unsupervised learning of lexical information from possible coreference, namely that of Ge et. al. where possible pronoun coreference was used to learn the gender of nouns.", "labels": [], "entities": []}, {"text": "In this case a program with an approximately 65% accuracy in determining the correct antecedent was used to collect information on pronouns and their possible antecedents.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9985141158103943}]}, {"text": "The gender of the pronoun was then used to suggest the gender of the noun-phrase that was proposed as the antecedent.", "labels": [], "entities": []}, {"text": "The current work is quite different in both goal and methods, but similar in spirit.", "labels": [], "entities": []}, {"text": "More generally this work is part of a growing body of work on learning language-related information from unlabeled corpora.", "labels": [], "entities": []}], "datasetContent": [{"text": "From the work on named entity recognition we obtained a list of 145,670 names, of which 87,809 were marked as personal names.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 17, "end_pos": 41, "type": "TASK", "confidence": 0.7140872279802958}]}, {"text": "A second program creates an ordered list of names that appear in each article in the corpus.", "labels": [], "entities": []}, {"text": "The two files, names and article-name occurrences, are the input to our procedures.", "labels": [], "entities": []}, {"text": "With one exception, all the probabilities required by the two models are initialized with flat distributions -i.e., if a random variable can taken possible values, each value is 1/n.", "labels": [], "entities": []}, {"text": "The probabilites so set are: 1.", "labels": [], "entities": []}, {"text": "p(N (l) = n(l)) from equation 2 (the probability that label l appears n(l) times), 2.", "labels": [], "entities": []}, {"text": "p(w(i) | l) from equation 2 (the probability of generating w(i) given it has label l), , and p(a | \ud97b\udf59 l(w)) from equation 8, the probabilities that a the label \ud97b\udf59 l(w) will be subtracted, retained, or added when going from the old name to the new name.", "labels": [], "entities": []}, {"text": "We then used the expectation-maximization (EM) algorithm to re-estimate the values.", "labels": [], "entities": []}, {"text": "We initially decided to run EM for 100 iterations as our benchmark.", "labels": [], "entities": []}, {"text": "In practice no change in performance was observed after about 15 iterations.", "labels": [], "entities": []}, {"text": "The one exception to the flat probability distribution rule is the probability distribution p(R), the probability of an antecedent being coreferent, a family relation, or non-coreferent.", "labels": [], "entities": []}, {"text": "This distribution was set at .993, .002, and .005 respectively for the three alternatives and the values were not re-estimated by EM.", "labels": [], "entities": [{"text": "EM", "start_pos": 130, "end_pos": 132, "type": "DATASET", "confidence": 0.9317064881324768}]}, {"text": "1 show some of the probabilities for individual words given the possible labels.", "labels": [], "entities": []}, {"text": "The result shown in are basically correct, with \"Director\" having a high probability as a descriptor, (0.0059), \"Ms.\" having a high probability as honorific (0.058), etc.", "labels": [], "entities": []}, {"text": "Some of the small non-zero probabilities are due to genuine ambiguity (e.g., Fisher does occur as a first name as well as a last name) but more of it is due to small confusions in particular cases (e.g., \"Director\" as a last-name, or \"John\" as descriptor).", "labels": [], "entities": []}, {"text": "After EM training we evaluated the program on 309 personal names from our names list that we had annotated by hand.", "labels": [], "entities": []}, {"text": "These names were obtained by random selection of names labeled as personal names by the name-entity recognizer.", "labels": [], "entities": []}, {"text": "If the named entity recognizer had mistakenly classified something as a personal name it was not used in our test data.", "labels": [], "entities": []}, {"text": "For the name model we straightforwardly used equation 2 to determine the most probable label sequence \ud97b\udf59 l for each name.", "labels": [], "entities": []}, {"text": "Note, however, that the testing data does not itself include any information on whether or not the test name was a first or subsequent occurrence of an individual in the text.", "labels": [], "entities": []}, {"text": "To evaluate the coreference model we looked at the possible coreference data to find if the test-data name was most common as a first occurrence, or if not, which possible antecedent was the most common.", "labels": [], "entities": []}, {"text": "If first occurrence prevailed, \ud97b\udf59 l was determined from equation 2, and otherwise it was determined using equation 3 with \ud97b\udf59 c set to the most common possible coreferent for this name.", "labels": [], "entities": []}, {"text": "We compare the most probable labels \ud97b\udf59 l fora test example with the hand-labeled test data.", "labels": [], "entities": []}, {"text": "We report percentage of words that are given the correct label and percentage of names that are completely correct.", "labels": [], "entities": []}, {"text": "The results of our experiments are as follows:", "labels": [], "entities": []}], "tableCaptions": []}