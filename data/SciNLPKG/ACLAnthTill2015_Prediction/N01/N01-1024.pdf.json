{"title": [], "abstractContent": [{"text": "We propose an algorithm to automatically induce the morphology of inflectional languages using only text corpora and no human input.", "labels": [], "entities": []}, {"text": "Our algorithm combines cues from orthography, semantics, and syntactic distributions to induce morphological relationships in German, Dutch, and English.", "labels": [], "entities": []}, {"text": "Using CELEX as a gold standard for evaluation, we show our algorithm to bean improvement over any knowledge-free algorithm yet proposed.", "labels": [], "entities": [{"text": "CELEX", "start_pos": 6, "end_pos": 11, "type": "DATASET", "confidence": 0.9299908876419067}]}], "introductionContent": [{"text": "Many NLP tasks, such as building machine-readable dictionaries, are dependent on the results of morphological analysis.", "labels": [], "entities": []}, {"text": "While morphological analyzers have existed since the early 1960s, current algorithms require human labor to build rules for morphological structure.", "labels": [], "entities": [{"text": "morphological analyzers", "start_pos": 6, "end_pos": 29, "type": "TASK", "confidence": 0.7520110905170441}]}, {"text": "In an attempt to avoid this labor-intensive process, recent work has focused on machine-learning approaches to induce morphological structure using large corpora.", "labels": [], "entities": []}, {"text": "In this paper, we propose a knowledge-free algorithm to automatically induce the morphology structures of a language.", "labels": [], "entities": []}, {"text": "Our algorithm takes as input a large corpus and produces as output a set of conflation sets indicating the various inflected and derived forms for each word in the language.", "labels": [], "entities": []}, {"text": "As an example, the conflation set of the word \"abuse\" would contain \"abuse\", \"abused\", \"abuses\", \"abusive\", \"abusively\", and so forth.", "labels": [], "entities": []}, {"text": "Our algorithm extends earlier approaches to morphology induction by combining various induced information sources: the semantic relatedness of the affixed forms using a Latent Semantic Analysis approach to corpusbased semantics), affix frequency, syntactic context, and transitive closure.", "labels": [], "entities": [{"text": "morphology induction", "start_pos": 44, "end_pos": 64, "type": "TASK", "confidence": 0.8722177445888519}]}, {"text": "Using the hand-labeled CELEX lexicon as our gold standard, the current version of our algorithm achieves an F-score of 88.1% on the task of identifying conflation sets in English, outperforming earlier algorithms.", "labels": [], "entities": [{"text": "CELEX lexicon", "start_pos": 23, "end_pos": 36, "type": "DATASET", "confidence": 0.8834131360054016}, {"text": "F-score", "start_pos": 108, "end_pos": 115, "type": "METRIC", "confidence": 0.9993446469306946}]}, {"text": "Our algorithm is also applied to German and Dutch and evaluated on its ability to find prefixes, suffixes, and circumfixes in these languages.", "labels": [], "entities": []}, {"text": "To our knowledge, this serves as the first evaluation of complete regular morphological induction of German or Dutch (although researchers such as have evaluated induction algorithms on morphological sub-problems in German).", "labels": [], "entities": []}], "datasetContent": [{"text": "We compare this improved algorithm to our former algorithm) as well as to.", "labels": [], "entities": []}, {"text": "We use as input to our system 6.7 million words of English newswire, 2.3 million of German, and 6.7 million of Dutch.", "labels": [], "entities": []}, {"text": "Our gold standards are the hand-tagged morphologically-analyzed CELEX lexicon in each of these languages.", "labels": [], "entities": []}, {"text": "We apply the algorithms only to those words of our corpora with frequencies of 10 or more.", "labels": [], "entities": []}, {"text": "Obviously this cutoff slightly limits the generality of our results, but it also greatly decreases processing time for all of In making these computations, we disregard any CELEX words absent from our data set and vice versa.", "labels": [], "entities": []}, {"text": "Most capital words are not in CELEX so this process also discards them.", "labels": [], "entities": [{"text": "CELEX", "start_pos": 30, "end_pos": 35, "type": "DATASET", "confidence": 0.9582176208496094}]}, {"text": "Hence, we also make an augmented CELEX to incorporate capitalized forms.", "labels": [], "entities": []}, {"text": "uses the above scoring mechanism to compare the F-Scores (product of precision and recall divided by average of the two ) of our system at a cutoff threshold of 85% to those of our earlier algorithm (\"S/J2000\") at the same threshold; Goldsmith; and a baseline system which performs no analysis (claiming that for any word, its conflation set only consists of itself).", "labels": [], "entities": [{"text": "F-Scores", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9905741810798645}, {"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9878852963447571}, {"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9965932965278625}, {"text": "Goldsmith", "start_pos": 234, "end_pos": 243, "type": "DATASET", "confidence": 0.9010168313980103}]}, {"text": "The \"S\" and \"C\" columns respectively indicate performance of systems when scoring for suffixing and circumfixing (using the unaugmented CELEX).", "labels": [], "entities": [{"text": "CELEX", "start_pos": 136, "end_pos": 141, "type": "DATASET", "confidence": 0.9273774027824402}]}, {"text": "The \"A\" column shows circumfixing performance using the augmented CELEX.", "labels": [], "entities": [{"text": "A", "start_pos": 5, "end_pos": 6, "type": "METRIC", "confidence": 0.9744136333465576}, {"text": "CELEX", "start_pos": 66, "end_pos": 71, "type": "DATASET", "confidence": 0.7903413772583008}]}, {"text": "Space limitations required that we illustrate \"A\" scores for one language only, but performance in the other two language is similarly degraded.", "labels": [], "entities": [{"text": "A\" scores", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9166126449902853}]}, {"text": "Boxes are shaded out for algorithms not designed to produce circumfixes.", "labels": [], "entities": []}, {"text": "Note that each of our additions resulted in an overall improvement which held true across each of the three languages.", "labels": [], "entities": []}, {"text": "Furthermore, using ten-fold cross validation on the English data, we find that Fscore differences of the S column are each statistically significant at least at the 95% level.", "labels": [], "entities": [{"text": "English data", "start_pos": 52, "end_pos": 64, "type": "DATASET", "confidence": 0.8373781740665436}, {"text": "Fscore", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.9971511960029602}]}], "tableCaptions": [{"text": " Table 5: Computation of F-Scores  Algorithms  English  German  Dutch  S  C A S  C  S  C  None  62.8 59.9 51.7 75.8 63.0 74.2 70.0  Goldsmith 81.8  84.0  75.8  S/J2000 85.2  88.3  82.2  +orthogrph 85.7 82.2 76.9 89.3 76.1 84.5 78.9  + syntax 87.5 84.0 79.0 91.6 78.2 85.6 79.4  + transitive  84.5 79.7  78.9  79.6  88.1  92.3  85.8", "labels": [], "entities": [{"text": "F-Scores  Algorithms  English  German  Dutch  S  C A S  C  S  C  None  62.8 59.9 51.7 75.8 63.0 74.2 70.0  Goldsmith 81.8  84.0  75.8  S/J2000 85.2  88.3", "start_pos": 25, "end_pos": 178, "type": "DATASET", "confidence": 0.7218324274852358}]}]}