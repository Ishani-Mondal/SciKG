{"title": [{"text": "Tree-cut and A Lexicon based on Systematic Polysemy", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes a lexicon organized around systematic polysemy: a set of word senses that are related in systematic and predictable ways.", "labels": [], "entities": []}, {"text": "The lexicon is derived by a fully automatic extraction method which utilizes a clustering technique called tree-cut.", "labels": [], "entities": []}, {"text": "We compare our lexicon to WordNet cousins, and the inter-annotator disagreement observed between WordNet Semcor and DSO corpora.", "labels": [], "entities": [{"text": "WordNet Semcor", "start_pos": 97, "end_pos": 111, "type": "DATASET", "confidence": 0.9287509024143219}]}], "introductionContent": [{"text": "In recent years, the granularity of word senses for computational lexicons has been discussed frequently in Lexical Semantics (for example,).", "labels": [], "entities": []}, {"text": "This issue emerged as a prominent problem after previous studies and exercises in Word Sense Disambiguation (WSD) reported that, when ne-grained sense deenitions such as those in WordNet were used, entries became very similar and indistinguishable to human annotators, thereby causing disagreement on correct tags).", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 82, "end_pos": 113, "type": "TASK", "confidence": 0.7720725735028585}]}, {"text": "In addition to WSD, the selection of sense inventories is fundamentally critical in other Natural Language Processing (NLP) tasks such as Information Extraction (IE) and Machine Translation (MT), as well as in Information Retrieval (IR), since the diierence in the correct sense assignments aaects recall, precision and other evaluation measures.", "labels": [], "entities": [{"text": "WSD", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.9826561212539673}, {"text": "Information Extraction (IE)", "start_pos": 138, "end_pos": 165, "type": "TASK", "confidence": 0.8059484243392945}, {"text": "Machine Translation (MT)", "start_pos": 170, "end_pos": 194, "type": "TASK", "confidence": 0.8620837926864624}, {"text": "Information Retrieval (IR)", "start_pos": 210, "end_pos": 236, "type": "TASK", "confidence": 0.8258225679397583}, {"text": "recall", "start_pos": 298, "end_pos": 304, "type": "METRIC", "confidence": 0.9989097118377686}, {"text": "precision", "start_pos": 306, "end_pos": 315, "type": "METRIC", "confidence": 0.9990172386169434}]}, {"text": "In response to this, several approaches have been proposed which group \ud97b\udf59ne-grained word senses in various ways to derive coarse-grained sense groups.", "labels": [], "entities": []}, {"text": "Some approaches utilize an abstraction hierarchy d ened in a dictionary, while others utilize surface syntactic patterns of the functional structures (such as predicate-argument structure for verbs) of words.", "labels": [], "entities": []}, {"text": "Also, the current version of WordNet (1.6) encodes groupings of similar/related word senses (or synsets) by a relation called cousin.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 29, "end_pos": 36, "type": "DATASET", "confidence": 0.9220532178878784}]}, {"text": "Another approach to grouping word senses is to utilize a linguistic phenomenon called systematic polysemy: a set of word senses that are related in systematic and predictable ways.", "labels": [], "entities": []}, {"text": "For example, ANIMAL and MEAT meanings of the word \\chicken\" are related because chicken as meat refers to the esh of ac hicken as a bird that is used for food.", "labels": [], "entities": [{"text": "ANIMAL", "start_pos": 13, "end_pos": 19, "type": "METRIC", "confidence": 0.932861864566803}, {"text": "MEAT", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9594693779945374}]}, {"text": "This relation is systematic, since many ANIMAL words such a s \\duck\" and \\lamb\" have a MEAT meaning.", "labels": [], "entities": [{"text": "MEAT", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.8427547216415405}]}, {"text": "Another example is the relation QUANTITY-PROCESS observed in nouns such as \\increase\" and \\supply\".", "labels": [], "entities": [{"text": "QUANTITY-PROCESS", "start_pos": 32, "end_pos": 48, "type": "METRIC", "confidence": 0.9484134912490845}]}, {"text": "Sense grouping based on systematic polysemy is lexico-semantically motivated in that it expresses general human knowledge about the relatedness of word meanings.", "labels": [], "entities": [{"text": "Sense grouping", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7837960422039032}]}, {"text": "Such sense groupings have advantages compared to other approaches.", "labels": [], "entities": []}, {"text": "First, related senses of a word often exist simultaneously in a discourse (for example the QUANTITY and PROCESS meanings of \\increase\" above).", "labels": [], "entities": [{"text": "QUANTITY", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.8639850616455078}]}, {"text": "Thus, systematic polysemy can be eeectively used in WSD (and WSD evaluation) to accept multiple or alternative sense tags.", "labels": [], "entities": [{"text": "WSD", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.8233978748321533}, {"text": "WSD evaluation", "start_pos": 61, "end_pos": 75, "type": "TASK", "confidence": 0.7311916649341583}]}, {"text": "Second, many systematic relations are observed between senses which belong to diierent semantic categories.", "labels": [], "entities": []}, {"text": "So if a lexicon is deened by a collection of separate trees/hierarchies (such as the case of WordNet), systematic polysemy can express similarity between senses that are not hierarchically proximate.", "labels": [], "entities": []}, {"text": "Third, by explicitly representing (inter-)relations between senses, a lexicon based on systematic polysemy can facilitate semantic inferences.", "labels": [], "entities": []}, {"text": "Thus it is useful in knowledge-intensive NLP tasks such as discourse analysis, IE and MT.", "labels": [], "entities": [{"text": "discourse analysis", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.7836845517158508}, {"text": "IE", "start_pos": 79, "end_pos": 81, "type": "TASK", "confidence": 0.9728813171386719}, {"text": "MT", "start_pos": 86, "end_pos": 88, "type": "TASK", "confidence": 0.969125509262085}]}, {"text": "More recently, () also discusses potential usefulness of systematic polysemy for clustering word senses for IR.", "labels": [], "entities": [{"text": "clustering word senses", "start_pos": 81, "end_pos": 103, "type": "TASK", "confidence": 0.8449531594912211}, {"text": "IR", "start_pos": 108, "end_pos": 110, "type": "TASK", "confidence": 0.9772166013717651}]}, {"text": "However, extracting systematic relations from large sense inventories is a diicult task.", "labels": [], "entities": []}, {"text": "Most often, this procedure is done manually.", "labels": [], "entities": []}, {"text": "For example, WordNet cousin relations were identiied manually by t he W ordNet lexicographers.", "labels": [], "entities": []}, {"text": "A similar eeort was also made in the EuroWordnet project (Vossen et 1 Systematic polysemy (in the sense we use in this paper) is also referred to as regular polysemy or logical polysemy (Pustejovsky, 1 9 9 5 ) . al., 1999).", "labels": [], "entities": [{"text": "EuroWordnet project", "start_pos": 37, "end_pos": 56, "type": "DATASET", "confidence": 0.9822593927383423}]}, {"text": "The problem is not only that manual inspection of a large, complex lexicon is very timeconsuming, it is also prone to inconsistencies.", "labels": [], "entities": []}, {"text": "In this paper, we describes a lexicon organized around systematic polysemy.", "labels": [], "entities": []}, {"text": "The lexicon is derived by a fully automatic extraction method which utilizes a clustering technique called tree-cut ().", "labels": [], "entities": []}, {"text": "In our previous work), we applied this method to a small subset of WordNet nouns and showed potential applicability.", "labels": [], "entities": [{"text": "WordNet nouns", "start_pos": 67, "end_pos": 80, "type": "DATASET", "confidence": 0.9075924754142761}]}, {"text": "In the current work, we applied the method to all nouns and verbs in WordNet, and built a lexicon in which word senses are partitioned by systematic polysemy.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 69, "end_pos": 76, "type": "DATASET", "confidence": 0.9505597352981567}]}, {"text": "We report results of comparing our lexicon with the WordNet cousins as well as the inter-annotator disagreement observed between two semantically annotated corpora: WordNet Semcor ( and.", "labels": [], "entities": [{"text": "WordNet cousins", "start_pos": 52, "end_pos": 67, "type": "DATASET", "confidence": 0.9641574323177338}, {"text": "WordNet Semcor", "start_pos": 165, "end_pos": 179, "type": "DATASET", "confidence": 0.9407998621463776}]}, {"text": "The results are quite promising: our extraction method discovered 89% of the WordNet cousins, and the sense partitions in our lexicon yielded better \ud97b\udf59 values) than arbitrary sense groupings on the agreement data.", "labels": [], "entities": [{"text": "WordNet cousins", "start_pos": 77, "end_pos": 92, "type": "DATASET", "confidence": 0.9683517217636108}]}], "datasetContent": [{"text": "To test our automatic extraction method, we co mpared the cluster pairs derived by our method to WordNet cousins.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 97, "end_pos": 104, "type": "DATASET", "confidence": 0.9425944685935974}]}, {"text": "The cousin relation is relatively new in WordNet, and the coverage is still incomplete.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 41, "end_pos": 48, "type": "DATASET", "confidence": 0.9523875713348389}]}, {"text": "Currently a total of 194 unique relations are encoded.", "labels": [], "entities": []}, {"text": "A cousin relation in WordNet is deened between two synsets, and it indicates that senses of aw ord that appear in both of the (sub)trees rooted by those synsets are related.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 21, "end_pos": 28, "type": "DATASET", "confidence": 0.9396964311599731}]}, {"text": "The cousins were man-8 Note that the relatedness between clusters was determined solely by our subjective judgement.", "labels": [], "entities": []}, {"text": "That is because there is no existing large-scale lexicon which encodes related senses completely for all words in the lexicon.", "labels": [], "entities": []}, {"text": "(Note that WordNet cousin relation is encoded only for some words).", "labels": [], "entities": [{"text": "WordNet cousin relation", "start_pos": 11, "end_pos": 34, "type": "DATASET", "confidence": 0.8571960926055908}]}, {"text": "Although the distinction between related vs. unrelated meanings is sometimes unclear, systematicity of the related senses among words is quite intuitive and has been well studied in Lexical Semantics (for example,).", "labels": [], "entities": [{"text": "Lexical Semantics", "start_pos": 182, "end_pos": 199, "type": "TASK", "confidence": 0.6887403130531311}]}, {"text": "A comparison with WordNet cousin is discussed in the next section 4.", "labels": [], "entities": [{"text": "WordNet cousin", "start_pos": 18, "end_pos": 32, "type": "DATASET", "confidence": 0.9197948276996613}]}, {"text": "Actually, cousin is one of the three relations which indicate the grouping of related senses of a word.", "labels": [], "entities": []}, {"text": "Others are sister and twin.", "labels": [], "entities": []}, {"text": "In this paper, we use cousin to refer to all relations listed in \\cousin.tps\" le (available in a WordNet distribution).", "labels": [], "entities": [{"text": "WordNet distribution", "start_pos": 97, "end_pos": 117, "type": "DATASET", "confidence": 0.9390815794467926}]}, {"text": "ually identiied by the WordNet lexicographers.", "labels": [], "entities": [{"text": "WordNet lexicographers", "start_pos": 23, "end_pos": 45, "type": "DATASET", "confidence": 0.9570229947566986}]}, {"text": "To compare the automatically derived cluster pairs to WordNet cousins, we used the hypernymhyponym relation in the trees, instead of the number or ratio of the overlapping words.", "labels": [], "entities": []}, {"text": "This is because the levels at which the cousin relations are deened diier quite widely, from depth 0 to depth 6, thus the number of polysemous words covered in each cousin relation signiicantly varies.", "labels": [], "entities": []}, {"text": "Therefore, it was diicult to decide on an appropriate threshold value for either criteria.", "labels": [], "entities": []}, {"text": "Using the hypernym-hyponym relation, we checked, for each cousin relation, whether there was at least one cluster pair that subsumed or was subsumed by the cousin.", "labels": [], "entities": []}, {"text": "More speciically, fora cousin relation deened between nodes c1 and c2 in trees T1 and T2 respectively and a cluster pair deened between nodes r1 and r2 in the same trees, wed ecided on the correspondence if c1 i s ah ypernym or hyponym of r1, and c2 i s ah ypernym or hyponym r2 at the same time.", "labels": [], "entities": []}, {"text": "Based on this criteria, we obtained a result indicating that 173 out of the 194 cousin relations had corresponding cluster pairs.", "labels": [], "entities": []}, {"text": "This makes the recall ratio 89%, which we consider to be quite high.", "labels": [], "entities": [{"text": "recall ratio", "start_pos": 15, "end_pos": 27, "type": "METRIC", "confidence": 0.9574064016342163}]}, {"text": "In addition to the WordNet cousins, our automatic extraction method discovered several interesting relations.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 19, "end_pos": 26, "type": "DATASET", "confidence": 0.9464638233184814}, {"text": "automatic extraction", "start_pos": 40, "end_pos": 60, "type": "TASK", "confidence": 0.7291485071182251}]}, {"text": "To test if the sense partitions in our lexicon constitute an appropriate (or useful) level of granularity, we applied it to the inter-annotator disagreement observed in two semantically annotated corpora: WordNet Semcor () and DSO ().", "labels": [], "entities": [{"text": "WordNet Semcor", "start_pos": 205, "end_pos": 219, "type": "DATASET", "confidence": 0.9151009917259216}, {"text": "DSO", "start_pos": 227, "end_pos": 230, "type": "DATASET", "confidence": 0.7307502031326294}]}, {"text": "The agreement be tween those corpora is previously studied in ().", "labels": [], "entities": []}, {"text": "In our current work, we \ud97b\udf59rst re-produced their agreement data, then used our sense partitions to see whether or not they yield a better agreement.", "labels": [], "entities": []}, {"text": "In this experiment, we extracted 28,772 sentences/instances for 191 words (consisting of 121 nouns and 70 verbs) tagged in the intersection of the two corpora.", "labels": [], "entities": []}, {"text": "This constitutes the base data set.", "labels": [], "entities": [{"text": "base data set", "start_pos": 21, "end_pos": 34, "type": "DATASET", "confidence": 0.797338475783666}]}, {"text": "shows the breakdown of the number of instances where tags agreed and disagreed.", "labels": [], "entities": []}, {"text": "As you Note that the numbers reported in) are slightly more than the ones reported in this paper.", "labels": [], "entities": []}, {"text": "For instance, the number of sentences in the intersected corpus reported in) is 30,315.", "labels": [], "entities": []}, {"text": "We speculate the discrepancies are due to the diierent s en tence alignment meth- can see, the agreement i s no t very high: only around 48%.", "labels": [], "entities": []}, {"text": "11 This low agreement ratio is also reeected in a measure called the \ud97b\udf59 statistic).", "labels": [], "entities": [{"text": "agreement ratio", "start_pos": 12, "end_pos": 27, "type": "METRIC", "confidence": 0.9098777770996094}]}, {"text": "\ud97b\udf59 measure takes into account chance agreement, thus better representing the state of disagreement.", "labels": [], "entities": []}, {"text": "A \ud97b\udf59 value is calculated for each word, on a confusion matrix where rows represent the senses assigned by judge 1 (DSO) and columns represent the senses assigned by judge 2 (Semcor).", "labels": [], "entities": []}, {"text": "shows an example matrix for the noun \\table\".", "labels": [], "entities": []}, {"text": "A \ud97b\udf59 value fora word is calculated as follows.", "labels": [], "entities": []}, {"text": "We use the notation and formula used in).", "labels": [], "entities": []}, {"text": "Let n ij denote the number of instances where the judge 1 assigned sense i and the judge 2 assigned sense j to the same instance, and n i+ and n +i denote the marginal totals of rows and columns respectively.", "labels": [], "entities": []}, {"text": "where P ii = nii n++ (i.e., proportion of n ii , the number of instances where both judges agreed on sense i, to the total instances), P i+ = ni+ n++ and P +i = n+i n++ . The \ud97b\udf59 value is 1.0 when the agreement is perfect (i.e., values in the oo-diagonal cells are all 0, that is,.", "labels": [], "entities": []}, {"text": "By using the formula above, the average \ud97b\udf59 for the 191 words was .264, as shown in.", "labels": [], "entities": []}, {"text": "This means the agreement between Semcor and DSO is quite low.", "labels": [], "entities": [{"text": "DSO", "start_pos": 44, "end_pos": 47, "type": "DATASET", "confidence": 0.7872833609580994}]}, {"text": "We selected the same 191 words from our lexicon, and used their sense partitions to reduce the size of the confusion matrices.", "labels": [], "entities": []}, {"text": "For each word, we computed the \ud97b\udf59 for the reduced matrix, and compared it with the \ud97b\udf59 fora random sense grouping of the same partition pattern.", "labels": [], "entities": []}, {"text": "For example, the partition pattern of f(1 4),(2 3 5),(6)g for \\table\" mentioned earlier (where shows its reduced matrix) is a multinomial combination The \ud97b\udf59 value fora random grouping is obtained by generating 5,000 random partitions which ha ve the same pattern as the corresponding sense partition in our lexicon, then taking the mean of their \ud97b\udf59's.", "labels": [], "entities": []}, {"text": "Then we measured the possible increase in \ud97b\udf59 by our lexicon by taking the diierence between the paired \ud97b\udf59 values for all words (i.e., \ud97b\udf59 w by our sense partition -\ud97b\udf59 w by random partition, fora word w), and performed a signiicance)'s result is slightly higher: \ud97b\udf59 = :317.", "labels": [], "entities": []}, {"text": "13 For this comparison, we excluded 23 words whose sense partitions consisted of only 1 sense cover.", "labels": [], "entities": []}, {"text": "This is reeected in the total number of instances in. test, with a null hypothesis that there was no significant increase.", "labels": [], "entities": []}, {"text": "The result showed that the P-values were 4.17 and 2.65 for nouns and verbs respectively, which were both statistically signiicant.", "labels": [], "entities": [{"text": "P-values", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9607294201850891}]}, {"text": "Therefore, the null hypothesis was rejected, and we concluded that there was a signiicant increase in \ud97b\udf59 by using our lexicon.", "labels": [], "entities": []}, {"text": "As a note, the average \ud97b\udf59's for the 191 words from our lexicon and their corresponding random partitions were .260 and .233 respectively.", "labels": [], "entities": []}, {"text": "Those values are in fact lower than that for the original WordNet lexicon.", "labels": [], "entities": [{"text": "WordNet lexicon", "start_pos": 58, "end_pos": 73, "type": "DATASET", "confidence": 0.9682601690292358}]}, {"text": "There are two major reasons for this.", "labels": [], "entities": []}, {"text": "First, in general, combining any arbitrary senses does not always increase \ud97b\udf59.", "labels": [], "entities": []}, {"text": "In the given formula 9, \ud97b\udf59 actually decreases when the increase in P i P ii (i.e., the diagonal sum) in the reduced matrix is less than the increase in P i P i+ P +i (i.e., the marginal product sum) by some factor.", "labels": [], "entities": []}, {"text": "14 This situation typically happens when senses combined are well distinguished in the original matrix, in the sense that, for senses i and j, n ij and n ji are 0 or very small (relative to the total frequency).", "labels": [], "entities": []}, {"text": "Second, some systematic relations are in fact easily distinguishable.", "labels": [], "entities": []}, {"text": "Senses in such relations often denote diierent objects in a context, for instance ANIMAL and MEAT senses of \\chicken\".", "labels": [], "entities": [{"text": "ANIMAL", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.8536567091941833}]}, {"text": "Since our lexicon groups those senses together, the \ud97b\udf59's for the reduce matrices decrease for the reason we mentioned above.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Automatically Extracted Cluster Pairs", "labels": [], "entities": []}, {"text": " Table 3: Extracted Relations for \\table\"", "labels": [], "entities": []}, {"text": " Table 4: WordNet vs. the New Lexicon  Category  WordNet  New  Nouns  Monosemous  82,892 88,977  Polysemous  12,243  6,158  Total words  95,135 95,135  Ave # senses  2.73  2.52  Verbs  Monosemous  5,758  7,987  Polysemous  4,568  2,339  Total words  10,326 10,326  Ave # senses  3.57  2.82  Total  Monosemous  88,650 96,964  Polysemous  16,811  8,497  Total words  105,461 105,461", "labels": [], "entities": []}, {"text": " Table 5: Agreement b e t ween Semcor and DSO", "labels": [], "entities": [{"text": "DSO", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.8496376872062683}]}, {"text": " Table 7: Reduced Matrix for \\table\" (\ud97b\udf59 = :699)", "labels": [], "entities": []}, {"text": " Table 8: Our Lexicon vs. Random Partitions", "labels": [], "entities": []}]}