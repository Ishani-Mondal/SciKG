{"title": [], "abstractContent": [{"text": "We apply Support Vector Machines (SVMs) to identify English base phrases (chunks).", "labels": [], "entities": []}, {"text": "SVMs are known to achieve high generalization performance even with input data of high dimensional feature spaces.", "labels": [], "entities": []}, {"text": "Furthermore, by the Kernel principle , SVMs can carryout training with smaller computational overhead independent of their dimen-sionality.", "labels": [], "entities": []}, {"text": "We apply weighted voting of 8 SVMs-based systems trained with distinct chunk representations.", "labels": [], "entities": []}, {"text": "Experimental results show that our approach achieves higher accuracy than previous approaches .", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.99882572889328}]}], "introductionContent": [{"text": "Chunking is recognized as series of processesfirst identifying proper chunks from a sequence of tokens (such as words), and second classifying these chunks into some grammatical classes.", "labels": [], "entities": []}, {"text": "Various NLP tasks can be seen as a chunking task.", "labels": [], "entities": []}, {"text": "Examples include English base noun phrase identification (base NP chunking), English base phrase identification (chunking), Japanese chunk (bunsetsu) identification and named entity extraction.", "labels": [], "entities": [{"text": "English base noun phrase identification (base NP chunking", "start_pos": 17, "end_pos": 74, "type": "TASK", "confidence": 0.6265812913576762}, {"text": "English base phrase identification", "start_pos": 77, "end_pos": 111, "type": "TASK", "confidence": 0.5299163833260536}, {"text": "Japanese chunk (bunsetsu) identification", "start_pos": 124, "end_pos": 164, "type": "TASK", "confidence": 0.5890258649984995}, {"text": "named entity extraction", "start_pos": 169, "end_pos": 192, "type": "TASK", "confidence": 0.6471447149912516}]}, {"text": "Tokenization and part-of-speech tagging can also be regarded as a chunking task, if we assume each character as a token.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 17, "end_pos": 39, "type": "TASK", "confidence": 0.7075852006673813}]}, {"text": "Machine learning techniques are often applied to chunking, since the task is formulated as estimating an identifying function from the information (features) available in the surrounding context.", "labels": [], "entities": [{"text": "chunking", "start_pos": 49, "end_pos": 57, "type": "TASK", "confidence": 0.9610999226570129}]}, {"text": "Various machine learning approaches have been proposed for chunking).", "labels": [], "entities": [{"text": "chunking", "start_pos": 59, "end_pos": 67, "type": "TASK", "confidence": 0.977899968624115}]}, {"text": "Conventional machine learning techniques, such as Hidden Markov Model (HMM) and Maximum Entropy Model (ME), normally require a careful feature selection in order to achieve high accuracy.", "labels": [], "entities": [{"text": "Maximum Entropy Model (ME", "start_pos": 80, "end_pos": 105, "type": "METRIC", "confidence": 0.7590002417564392}, {"text": "accuracy", "start_pos": 178, "end_pos": 186, "type": "METRIC", "confidence": 0.9715644717216492}]}, {"text": "They do not provide a method for automatic selection of given feature sets.", "labels": [], "entities": []}, {"text": "Usually, heuristics are used for selecting effective features and their combinations.", "labels": [], "entities": []}, {"text": "New statistical learning techniques such as Support Vector Machines (SVMs) and) have been proposed.", "labels": [], "entities": []}, {"text": "These techniques take a strategy that maximizes the margin between critical samples and the separating hyperplane.", "labels": [], "entities": []}, {"text": "In particular, SVMs achieve high generalization even with training data of a very high dimension.", "labels": [], "entities": [{"text": "SVMs", "start_pos": 15, "end_pos": 19, "type": "TASK", "confidence": 0.9706405997276306}]}, {"text": "Furthermore, by introducing the Kernel function, SVMs handle non-linear feature spaces, and carryout the training considering combinations of more than one feature.", "labels": [], "entities": []}, {"text": "In the field of natural language processing, SVMs are applied to text categorization and syntactic dependency structure analysis, and are reported to have achieved higher accuracy than previous approaches..", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 16, "end_pos": 43, "type": "TASK", "confidence": 0.6801239053408304}, {"text": "syntactic dependency structure analysis", "start_pos": 89, "end_pos": 128, "type": "TASK", "confidence": 0.7105546742677689}, {"text": "accuracy", "start_pos": 171, "end_pos": 179, "type": "METRIC", "confidence": 0.9975132942199707}]}, {"text": "In this paper, we apply Support Vector Machines to the chunking task.", "labels": [], "entities": [{"text": "chunking task", "start_pos": 55, "end_pos": 68, "type": "TASK", "confidence": 0.9118444919586182}]}, {"text": "In addition, in order to achieve higher accuracy, we apply weighted voting of 8 SVM-based systems which are trained using distinct chunk representations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9986635446548462}]}, {"text": "For the weighted voting systems, we introduce anew type of weighting strategy which are derived from the theoretical basis of the SVMs.", "labels": [], "entities": [{"text": "SVMs", "start_pos": 130, "end_pos": 134, "type": "DATASET", "confidence": 0.8996593952178955}]}, {"text": "The training samples which lie on either of two dashed lines are called support vectors.", "labels": [], "entities": []}, {"text": "It is known that only the support vectors in given training data matter.", "labels": [], "entities": []}, {"text": "This implies that we can obtain the same decision function even if we remove all training samples except for the extracted support vectors.", "labels": [], "entities": []}, {"text": "In practice, even in the case where we cannot separate training data linearly because of some noise in the training data, etc, we can build the separating linear hyperplane by allowing some misclassifications.", "labels": [], "entities": []}, {"text": "Though we omit the details here, we can build an optimal hyperplane by introducing a soft margin parameter o , which trades off between the training error and the magnitude of the margin.", "labels": [], "entities": []}, {"text": "Furthermore, SVMs have a potential to carryout the non-linear classification.", "labels": [], "entities": []}, {"text": "Though we leave the details to, the optimization problem can be rewritten into a dual form, where all feature vectors appear in their dot products.", "labels": [], "entities": []}, {"text": "By simply substituting every dot product of", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the following three annotated corpora for our experiments.", "labels": [], "entities": []}, {"text": "\u00b0 Base NP standard data set (baseNP-S) This data set was first introduced by, and taken as the standard data set for baseNP identification task 2 . This data set consists of four sections of the Wall Street Journal (WSJ) part of the Penn Treebank for the training data, and one section (20) for the test data.", "labels": [], "entities": [{"text": "baseNP identification task", "start_pos": 117, "end_pos": 143, "type": "TASK", "confidence": 0.7860690057277679}, {"text": "Wall Street Journal (WSJ) part of the Penn Treebank", "start_pos": 195, "end_pos": 246, "type": "DATASET", "confidence": 0.9323223016478799}]}, {"text": "The data has part-ofspeech (POS) tags annotated by the Brill tagger.", "labels": [], "entities": [{"text": "Brill tagger", "start_pos": 55, "end_pos": 67, "type": "DATASET", "confidence": 0.9367595016956329}]}, {"text": "\u00b0 Base NP large data set (baseNP-L) This data set consists of 20 sections (02-21) of the WSJ part of the Penn Treebank for the training data, and one section (00) for the test data.", "labels": [], "entities": [{"text": "WSJ part", "start_pos": 89, "end_pos": 97, "type": "DATASET", "confidence": 0.9411947429180145}, {"text": "Penn Treebank", "start_pos": 105, "end_pos": 118, "type": "DATASET", "confidence": 0.8659284710884094}]}, {"text": "POS tags in this data sets are also annotated by the Brill tagger.", "labels": [], "entities": [{"text": "Brill tagger", "start_pos": 53, "end_pos": 65, "type": "DATASET", "confidence": 0.958267331123352}]}, {"text": "We omit the experiments IOB1 and IOE1 representations for this training data since the data size is too large for our current SVMs learning program.", "labels": [], "entities": []}, {"text": "In case of IOB1 and IOE1, the size of training data for one classifier which estimates the class I and O becomes much larger compared with IOB2 and IOE2 models.", "labels": [], "entities": [{"text": "IOE1", "start_pos": 20, "end_pos": 24, "type": "DATASET", "confidence": 0.7828598022460938}]}, {"text": "In addition, we also omit to estimate the voting weights using cross validation method due to a large amount of training cost.", "labels": [], "entities": []}, {"text": "\u00b0 Chunking data set (chunking) This data set was used for CoNLL-2000 shared task).", "labels": [], "entities": [{"text": "CoNLL-2000", "start_pos": 58, "end_pos": 68, "type": "DATASET", "confidence": 0.8257395625114441}]}, {"text": "In this data set, the total of 10 base phrase classes (NP,VP,PP,ADJP,ADVP,CONJP, INITJ,LST,PTR,SBAR) are annotated.", "labels": [], "entities": [{"text": "INITJ,LST,PTR,SBAR", "start_pos": 81, "end_pos": 99, "type": "METRIC", "confidence": 0.9440036416053772}]}, {"text": "This data set consists of 4 sections of the WSJ part of the Penn Treebank for the training data, and one section (20) for the test data 3 . All the experiments are carried outwith our software package TinySVM 4 , which is designed and optimized to handle large sparse feature vectors and large number of training samples.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 44, "end_pos": 47, "type": "DATASET", "confidence": 0.9129346609115601}, {"text": "Penn Treebank", "start_pos": 60, "end_pos": 73, "type": "DATASET", "confidence": 0.9814345836639404}]}, {"text": "This package can estimate the VC bound and Leave-One-Out bound automatically.", "labels": [], "entities": [{"text": "VC bound", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9805545210838318}]}, {"text": "For the kernel function, we use the 2-nd polynomial function and set the soft margin parameter o to be 1.", "labels": [], "entities": [{"text": "soft margin parameter o", "start_pos": 73, "end_pos": 96, "type": "METRIC", "confidence": 0.7946403175592422}]}, {"text": "In the baseNP identification task, the performance of the systems is usually measured with three rates: precision, recall and . In this paper, we refer to as accuracy.", "labels": [], "entities": [{"text": "baseNP identification task", "start_pos": 7, "end_pos": 33, "type": "TASK", "confidence": 0.8341755867004395}, {"text": "precision", "start_pos": 104, "end_pos": 113, "type": "METRIC", "confidence": 0.9997088313102722}, {"text": "recall", "start_pos": 115, "end_pos": 121, "type": "METRIC", "confidence": 0.9982286095619202}, {"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.9996007084846497}]}, {"text": "shows results of our SVMs based chunking with individual chunk representations.", "labels": [], "entities": []}, {"text": "This table also lists the voting weights estimated by different approaches (B:Cross Validation, C:VC-bound, D:Leave-one-out).", "labels": [], "entities": []}, {"text": "We also show the results of Start/End representation in. shows the results of the weighted voting of four different voting methods: A: Uniform, B: Cross Validation ( shows the precision, recall and \u00b1 \u00b2 h \u00b3 \u00a5 of the best result for each data set.", "labels": [], "entities": [{"text": "precision", "start_pos": 176, "end_pos": 185, "type": "METRIC", "confidence": 0.9995457530021667}, {"text": "recall", "start_pos": 187, "end_pos": 193, "type": "METRIC", "confidence": 0.9990515112876892}]}], "tableCaptions": [{"text": " Table 2: Accuracy of individual representations", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.996701180934906}]}, {"text": " Table 3: Results of weighted voting", "labels": [], "entities": []}, {"text": " Table 4: Best results for each data set", "labels": [], "entities": []}]}