{"title": [{"text": "Using Lexical Semantic Techniques to Classify Free-Responses", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper discusses a case study in which lexical semantic techniques were used to implement a prototype scoring system for short-answer, free-responses to test questions.", "labels": [], "entities": []}, {"text": "Scoring, as it is discussed in this paper, is a kind of clasgification problem.", "labels": [], "entities": [{"text": "Scoring", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9589871764183044}]}, {"text": "Responses are automatically scored by being assigned appropriate classifications.", "labels": [], "entities": []}, {"text": "The ultimate goal is to develop a scoring system which can reliably analyze response content.", "labels": [], "entities": []}, {"text": "For this study, a domain-specific, concept-based lexicon, and a concept grammar were built to represent the response set, using 200 of 378 responses from the original data set.", "labels": [], "entities": []}, {"text": "The lexicon is built, from individual words, and 2-word and 3-word terms from the training data.", "labels": [], "entities": []}, {"text": "The lexicon is best characterized by Bergler's (1995) layered lexicon.", "labels": [], "entities": []}, {"text": "Concept grammar rules are built by mapping concepts from the lexicon onto the concept-structure patterns present in a set of training responses.", "labels": [], "entities": []}, {"text": "Previous attempts to score these responses using lexically-based statistical techniques and structure-independent content grammars were not reliable (Burstein and Kaplan (1995)).", "labels": [], "entities": []}, {"text": "The results discussed in this paper illustrate the reliability of the lexical semantic methods used in the study.", "labels": [], "entities": []}], "introductionContent": [{"text": "There is a movement in testing to augment the conventional multiple-choice items (i.e., test questions) with short-answer free-response items.", "labels": [], "entities": []}, {"text": "Due to the large volume of tests administered yearly by Educational Testing Service (ETS), hand-scoring of these tests with these types of items is costly and time-consuming for practical testing programs.", "labels": [], "entities": []}, {"text": "ETS is currently working on natural language understanding systems which could be used for computer-assisted scoring of short-answer freeresponses (see and)) The overall goal of our current research is to develop a scoring system that can handle short-answer free-response items.", "labels": [], "entities": [{"text": "ETS", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.974147379398346}, {"text": "natural language understanding", "start_pos": 28, "end_pos": 58, "type": "TASK", "confidence": 0.7043809493382772}]}, {"text": "Such a scoring system has to be able to identify the relevant content of a response and assign it to an appropriate content category.", "labels": [], "entities": []}, {"text": "Another consideration in the development of a scoring system is that the data sets that are available to us are relatively small, and the responses in these data sets lack lexico-~syntactic patterning.", "labels": [], "entities": []}, {"text": "The items which we work with are either experimental, or have been administered as paper-and-pencil exams.", "labels": [], "entities": []}, {"text": "In the former case, there is a limited subject pool, and in the latter case, we rely on what has been put into electronic form.", "labels": [], "entities": []}, {"text": "The response sets typically range from 300-700 responses which we have to use for training and testing.", "labels": [], "entities": []}, {"text": "This is quite a different scenario from natural language understanding systems which can be designed using large corpora from full text sources, such as the AP News and the Wall Street Journal.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 40, "end_pos": 70, "type": "TASK", "confidence": 0.712675154209137}, {"text": "AP News and the Wall Street Journal", "start_pos": 157, "end_pos": 192, "type": "DATASET", "confidence": 0.8826995236533028}]}, {"text": "This paper discusses a case study that examined how lexical semantic techniques could be used to build scoring systems, based on small data sets.", "labels": [], "entities": []}, {"text": "Previous attempts to classify these responses using lexically-based statistical techniques and structure-independent content grammars were not reliable ().", "labels": [], "entities": []}, {"text": "The results of this case study illustrate the reliability of lexical semantic methods.", "labels": [], "entities": []}, {"text": "For this study, a concept-based lexicon and a concept grammar were built to represent a response set.", "labels": [], "entities": []}, {"text": "The lexicon can best be characterized by layered lexicon in that the list of lexical entry words and terms can remain constant, while the features associated with each entry are modular, so that they can be replaced as necessary.", "labels": [], "entities": []}, {"text": "Concepts in the concept grammars were linked to the lexicon.", "labels": [], "entities": []}, {"text": "In this paper, concepts are superordinate terms which contain one or more subordinate, metonymic terms.", "labels": [], "entities": []}, {"text": "A prototype was implemented to test our hypothesis that a lexical semantics approach to scoring would yield accurate results.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}