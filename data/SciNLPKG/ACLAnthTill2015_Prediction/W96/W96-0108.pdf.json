{"title": [{"text": "A Statistical Approach to Automatic OCR Error Correction in Context", "labels": [], "entities": [{"text": "OCR Error Correction in Context", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.8786787748336792}]}], "abstractContent": [{"text": "This paper describes an automatic, context-sensitive, word-error correction system based on statistical language modeling (SLM) as applied to optical character recognition (OCR) post-processing.", "labels": [], "entities": [{"text": "word-error correction", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.7856026887893677}, {"text": "statistical language modeling (SLM)", "start_pos": 92, "end_pos": 127, "type": "TASK", "confidence": 0.7018487801154455}, {"text": "optical character recognition (OCR) post-processing", "start_pos": 142, "end_pos": 193, "type": "TASK", "confidence": 0.8099545793873923}]}, {"text": "The system exploits information from multiple sources, including letter n-grams, character confusion probabilities, and word-bigram probabilities.", "labels": [], "entities": []}, {"text": "Letter n-grams are used to index the words in the lexicon.", "labels": [], "entities": []}, {"text": "Given a sentence to be corrected, the system decomposes each string in the sentence into letter n-grams and retrieves word candidates from the lexicon by comparing string n-grams with lexicon-entry n-grams.", "labels": [], "entities": []}, {"text": "The retrieved candidates are ranked by the conditional probability of matches with the string, given character confusion probabilities.", "labels": [], "entities": []}, {"text": "Finally, the wordobigram model and Viterbi algorithm are used to determine the best scoring word sequence for the sentence.", "labels": [], "entities": []}, {"text": "The system can correct non-word errors as well as real-word errors and achieves a 60.2% error reduction rate for real OCR text.", "labels": [], "entities": [{"text": "error reduction rate", "start_pos": 88, "end_pos": 108, "type": "METRIC", "confidence": 0.953805128733317}]}, {"text": "In addition, the system can learn the character confusion probabilities fora specific OCR environment and use them in self-calibration to achieve better performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word errors present problems for various text-or speech-based applications such as optical character recognition (OCR) and voice-input computer interfaces.", "labels": [], "entities": [{"text": "optical character recognition (OCR)", "start_pos": 83, "end_pos": 118, "type": "TASK", "confidence": 0.8038506011168162}]}, {"text": "In particular, though current OCR technology is quite refined and robust, sources such as old books, poor-quality (nth-generation) photocopies, and faxes can still be difficult to process and may cause many OCR errors.", "labels": [], "entities": [{"text": "OCR", "start_pos": 207, "end_pos": 210, "type": "TASK", "confidence": 0.9512216448783875}]}, {"text": "For OCR to be truly useful in a wide range of applications, such as office automation and information retrieval systems, OCR reliability must be improved.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 90, "end_pos": 111, "type": "TASK", "confidence": 0.7762917280197144}]}, {"text": "A method for the automatic correction of OCR errors would be clearly beneficial.", "labels": [], "entities": [{"text": "automatic correction of OCR", "start_pos": 17, "end_pos": 44, "type": "TASK", "confidence": 0.7085628286004066}]}, {"text": "Essentially, there are two types of word errors: non-word errors and real-word errors.", "labels": [], "entities": []}, {"text": "A nonword error occurs when a word in a source text is interpreted (under OCR) as a string that does not correspond to any valid word in a given word list or dictionary.", "labels": [], "entities": []}, {"text": "A real-word error occurs when a source-text word is interpreted as a string that actually does occur in the dictionary, but is not identical with the source-text word.", "labels": [], "entities": []}, {"text": "For example, if the source text \"John found the man\" is rendered as \"John fornd he man\" by an OCR device, then \"fornd\" is a non-word error and \"he\" is a real-word error.", "labels": [], "entities": []}, {"text": "In general, non-word errors will never correspond to any dictionary entries and will include wildly incorrect strings (such as \"#--&&') as well as misrecognized alpha-numeric sequences (such as \"BN234\" for \"8N234\").", "labels": [], "entities": []}, {"text": "However, some non-word errors might become realword errors if the size of the word list or dictionary increases.", "labels": [], "entities": []}, {"text": "(For example, the word \"ruel \"~ might count as a non-word error for the source-text word \"rut\" if a small dictionary is used for reference, but count as a real-word error if an unabridged dictionary is used.)", "labels": [], "entities": []}, {"text": "While non-word errors might be corrected without considering the context in which the error occurs, a real-word error can only be corrected by taking context into account.", "labels": [], "entities": []}, {"text": "The problems of word-error detection and correction have been studied for several decades.", "labels": [], "entities": [{"text": "word-error detection and correction", "start_pos": 16, "end_pos": 51, "type": "TASK", "confidence": 0.8098924309015274}]}, {"text": "A good survey in this area can be found in].", "labels": [], "entities": []}, {"text": "Most traditional word-correction techniques concentrate on non-word error correction and do not consider the context in which the error appears.", "labels": [], "entities": []}, {"text": "Recently, statistical language models (SLMs) and feature-based methods have been used for context-sensitive spelling-error correction.", "labels": [], "entities": [{"text": "spelling-error correction", "start_pos": 108, "end_pos": 133, "type": "TASK", "confidence": 0.7517002820968628}]}, {"text": "For example, Atwell and Elliittm have used a part-of-speech (POS) tagging method to detect the real-word errors in text.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging", "start_pos": 45, "end_pos": 73, "type": "TASK", "confidence": 0.6290175020694733}]}, {"text": "Mays and colleagues have exploited word trigrams to detect and correct both the non-word and real-word errors that were artificially generated from 100 sentences.", "labels": [], "entities": []}, {"text": "Church and Gale have used a Bayesian classifier method to improve the performance for non-word error correction.", "labels": [], "entities": [{"text": "non-word error correction", "start_pos": 86, "end_pos": 111, "type": "TASK", "confidence": 0.7176215052604675}]}, {"text": "Golding has applied a hybrid Bayesian method for real-word error correction and Golding and Schabes have combined a POS trigram and Bayesian methods for the same purpose.", "labels": [], "entities": [{"text": "real-word error correction", "start_pos": 49, "end_pos": 75, "type": "TASK", "confidence": 0.7041439016660055}]}, {"text": "The goal of the work described here is to investigate the effectiveness and efficiency of SLMbased methods applied to the problem of OCR error correction.", "labels": [], "entities": [{"text": "OCR error correction", "start_pos": 133, "end_pos": 153, "type": "TASK", "confidence": 0.9031614263852438}]}, {"text": "Since POS-based methods are not effective in distinguishing among candidates with the same POS tags and since methods based on word-trigram models involve extensive training data and require that huge word-trigram tables be available at run time, we used a word-bigram SLM as the first step in our investigation.", "labels": [], "entities": [{"text": "word-bigram SLM", "start_pos": 257, "end_pos": 272, "type": "TASK", "confidence": 0.5180107802152634}]}, {"text": "In this paper, we describe a system that uses a word-bigram SLM technique to correct OCR errors.", "labels": [], "entities": []}, {"text": "The system takes advantage of information from multiple sources, including letter ngrams, character confusion probabilities, and word bigram probabilities, to effect context-based word error correction.", "labels": [], "entities": [{"text": "context-based word error correction", "start_pos": 166, "end_pos": 201, "type": "TASK", "confidence": 0.4923744574189186}]}, {"text": "It can correct non-word as well as real-word errors.", "labels": [], "entities": []}, {"text": "In addition, the system can learn the character confusion probability table fora specific OCR environment and use it to achieve better performance.", "labels": [], "entities": [{"text": "character confusion", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.8092469871044159}]}], "datasetContent": [{"text": "To test our OCR-error-correction process, we used a set of electronic documents from the Ziff-Davis (ZIFF) news wire?", "labels": [], "entities": [{"text": "ZIFF) news wire", "start_pos": 101, "end_pos": 116, "type": "DATASET", "confidence": 0.6914153024554253}]}, {"text": "The documents in the corpus are business articles in the domain of computer science and computer engineering.", "labels": [], "entities": []}, {"text": "We used 90% of the collection for training and the remaining 10% for testing.", "labels": [], "entities": []}, {"text": "The system created a lexicon and collected word-bigram sequences and statistics from the training data.", "labels": [], "entities": []}, {"text": "Words or word-bigrams with frequency less than three were discarded.", "labels": [], "entities": []}, {"text": "The resulting lexicon contained about 100,000 words; these were indexed using 34,847 letter n-grams.", "labels": [], "entities": []}, {"text": "The resulting word-bigram table had about 1,000,000 entries.", "labels": [], "entities": []}, {"text": "Seventy pages of ZIFF data in the test set were printed in 7-point Times font.", "labels": [], "entities": [{"text": "ZIFF data in the test set", "start_pos": 17, "end_pos": 42, "type": "DATASET", "confidence": 0.8404283424218496}]}, {"text": "We degraded the print quality of the documents by photocopying them on a \"light' setting.", "labels": [], "entities": []}, {"text": "The photocopies were then scanned by a Fujitsu 3097E scanner and the resulting images were processed by Xerox Textbridge OCR software.", "labels": [], "entities": [{"text": "Fujitsu 3097E scanner", "start_pos": 39, "end_pos": 60, "type": "DATASET", "confidence": 0.8932669560114542}, {"text": "Xerox Textbridge OCR", "start_pos": 104, "end_pos": 124, "type": "DATASET", "confidence": 0.8752354979515076}]}, {"text": "The set of documents contained 55,699 strings and the overall word error rate after OCR processing was 22.9% (12,760).", "labels": [], "entities": [{"text": "word error rate", "start_pos": 62, "end_pos": 77, "type": "METRIC", "confidence": 0.7331397732098898}]}, {"text": "For literal words in the source (only letter sequences, not alphanumeric ones), the error rate was lower, 14.7%.", "labels": [], "entities": [{"text": "error rate", "start_pos": 84, "end_pos": 94, "type": "METRIC", "confidence": 0.9941743910312653}]}, {"text": "gives the number of real-word and non-word errors for literal words in the OCR data.", "labels": [], "entities": [{"text": "OCR data", "start_pos": 75, "end_pos": 83, "type": "DATASET", "confidence": 0.8805871307849884}]}], "tableCaptions": [{"text": " Table 1: OCR Errors Originating from Literal Words", "labels": [], "entities": [{"text": "OCR Errors Originating from Literal Words", "start_pos": 10, "end_pos": 51, "type": "TASK", "confidence": 0.8033220867315928}]}, {"text": " Table 2: Results from Isolated-Word Error Correction", "labels": [], "entities": []}, {"text": " Table 3: Results from Context-Dependent Non-Word Error Correction", "labels": [], "entities": [{"text": "Context-Dependent Non-Word Error Correction", "start_pos": 23, "end_pos": 66, "type": "TASK", "confidence": 0.6202386394143105}]}, {"text": " Table 4: Results from Context-Dependent Real-and Non-Word Error Correction", "labels": [], "entities": []}]}