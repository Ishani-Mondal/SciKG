{"title": [{"text": "APPORTIONING DEVELOPMENT EFFORT IN A PROBABILISTIC LR PARSING SYSTEM THROUGH EVALUATION", "labels": [], "entities": [{"text": "APPORTIONING", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.9301953911781311}, {"text": "DEVELOPMENT EFFORT IN A PROBABILISTIC LR PARSING SYSTEM THROUGH EVALUATION", "start_pos": 13, "end_pos": 87, "type": "METRIC", "confidence": 0.646076625585556}]}], "abstractContent": [{"text": "We describe an implemented system for robust domain-independent syntactic parsing of English, using a unification-based grammar of part-of-speech and punctuation labels coupled with a probabilistic LR parser.", "labels": [], "entities": [{"text": "syntactic parsing of English", "start_pos": 64, "end_pos": 92, "type": "TASK", "confidence": 0.8001481369137764}]}, {"text": "We present evaluations of the system's performance along several different dimensions; these enable us to assess the contribution that each individual part is making to the success of the system as a whole, and thus prioritise the effort to be devoted to its further enhancement.", "labels": [], "entities": []}, {"text": "Currently, the system is able to parse around 80% of sentences in a substantial corpus of general text containing a number of distinct genres.", "labels": [], "entities": []}, {"text": "On a random sample of 250 such sentences the system has a mean crossing bracket rate of 0.71 and recall and precision of 83% and 84~0 respectively when evaluated against manually-disambiguated analyses I .", "labels": [], "entities": [{"text": "mean crossing bracket rate", "start_pos": 58, "end_pos": 84, "type": "METRIC", "confidence": 0.8173553720116615}, {"text": "recall", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9996336698532104}, {"text": "precision", "start_pos": 108, "end_pos": 117, "type": "METRIC", "confidence": 0.99628746509552}]}], "introductionContent": [{"text": "This work is part of an effort to develop a robust, domain-independent syntactic parser capable of yielding the unique correct analysis for unrestricted naturally-occurring input.", "labels": [], "entities": []}, {"text": "Our goal is to develop a system with performance comparable to extant part-of-speech taggers, returning a syntactic analysis from which predicate-argument structure can be recovered, and which can support semantic interpretation.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 205, "end_pos": 228, "type": "TASK", "confidence": 0.7266907244920731}]}, {"text": "The requirement fora domain-independent analyser favours statistical 1Some of this work was carried out while the second author was visiting Rank Xerox, Grenoble.", "labels": [], "entities": []}, {"text": "The work was also supported by UK DTI/SALT project 41/5808 'Integrated Language Database', and by SERC/EPSRC Advanced Fellowships to both authors.", "labels": [], "entities": [{"text": "UK DTI/SALT project 41/5808 'Integrated Language Database", "start_pos": 31, "end_pos": 88, "type": "DATASET", "confidence": 0.8417720347642899}, {"text": "SERC/EPSRC Advanced Fellowships", "start_pos": 98, "end_pos": 129, "type": "DATASET", "confidence": 0.7550414323806762}]}, {"text": "Geoff Nunberg provided encouragement and much advice on the analysis of punctuation, and Greg Grefenstette undertook the original corpus tokenisation and segmentation for the punctuation experiments.", "labels": [], "entities": []}, {"text": "Bernie .]ones and Kiku Ribas made helpful comments on an earlier draft.", "labels": [], "entities": []}, {"text": "We are responsible for any mistakes.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Grammar coverage on Susanne and SEC", "labels": [], "entities": [{"text": "coverage", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.4435289204120636}]}, {"text": " Table 2: Grammar coverage and ambiguity during  development", "labels": [], "entities": [{"text": "Grammar coverage", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.5769285559654236}]}, {"text": " Table 3: GEIG evaluation metrics for test set of 250 held-back sentences against Susanne bracketings", "labels": [], "entities": [{"text": "GEIG", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.4871641993522644}, {"text": "Susanne bracketings", "start_pos": 82, "end_pos": 101, "type": "TASK", "confidence": 0.7395150363445282}]}, {"text": " Table 4: GEIG evaluation metrics for test set of 250 held-back sentences against the manually-disambigated  analyses", "labels": [], "entities": [{"text": "GEIG", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.416036456823349}]}]}