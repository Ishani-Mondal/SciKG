{"title": [{"text": "EXPLOITING TEXT STRUCTURE FOR TOPIC IDENTIFICATION", "labels": [], "entities": [{"text": "TEXT STRUCTURE FOR TOPIC IDENTIFICATION", "start_pos": 11, "end_pos": 50, "type": "METRIC", "confidence": 0.7617750287055969}]}], "abstractContent": [{"text": "The paper demonstrates how information on text structure can be used to improve the performance on the identification of topical words in texts, which is based on a probabilistic model of text categorization.", "labels": [], "entities": [{"text": "identification of topical words in texts", "start_pos": 103, "end_pos": 143, "type": "TASK", "confidence": 0.8439621031284332}]}, {"text": "We use texts which are not explicitly structured.", "labels": [], "entities": []}, {"text": "A text structure is identified by measuring the similarity between segments comprising the text and its title.", "labels": [], "entities": []}, {"text": "It is shown that a text structure thus identified gives a good clue to finding out parts of the text most relevant to its content.", "labels": [], "entities": []}, {"text": "The significance of exploiting information on the structure for topic identification is demonstrated by a set of experiments conducted on the 19Mb of Japanese newspaper articles.", "labels": [], "entities": [{"text": "topic identification", "start_pos": 64, "end_pos": 84, "type": "TASK", "confidence": 0.9037303924560547}, {"text": "19Mb of Japanese newspaper articles", "start_pos": 142, "end_pos": 177, "type": "DATASET", "confidence": 0.8563578248023986}]}, {"text": "The paper also brings concepts from the rhetorical structure theory (RST) to the statistical analysis of a text structure.", "labels": [], "entities": [{"text": "rhetorical structure theory (RST)", "start_pos": 40, "end_pos": 73, "type": "TASK", "confidence": 0.8579713801542918}]}, {"text": "Finally, it is shown that information on text structure is more effective for large documents than for small documents.", "labels": [], "entities": []}], "introductionContent": [{"text": "Topic identification concerns a problem of predicting terms in text which indicate its subject or theme.", "labels": [], "entities": [{"text": "Topic identification", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8607711791992188}, {"text": "predicting terms in text which indicate its subject or theme", "start_pos": 43, "end_pos": 103, "type": "TASK", "confidence": 0.7754560351371765}]}, {"text": "In the past, the problem has been addressed mostly by computational linguists in relation to issues like coreference, anaphora resolution (, or discourse center (.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 118, "end_pos": 137, "type": "TASK", "confidence": 0.678200900554657}]}, {"text": "In information retrieval, predicting important terms in document is crucial for an effective retrieval of relevant documents), though they do not necessarily correspond to the subject or the theme.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 3, "end_pos": 24, "type": "TASK", "confidence": 0.7555545270442963}, {"text": "predicting important terms in document", "start_pos": 26, "end_pos": 64, "type": "TASK", "confidence": 0.8538468599319458}]}, {"text": "Predicting important terms involves numerical weighting of terms in document.", "labels": [], "entities": []}, {"text": "Terms with top weights are judged important and representative of document.", "labels": [], "entities": []}, {"text": "A spin-off of information retrieval, known as text categorization, shares a similar research interest.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 14, "end_pos": 35, "type": "TASK", "confidence": 0.7769629955291748}, {"text": "text categorization", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.7785824835300446}]}, {"text": "Text categorization concerns associating documents with their classification terms or categories.", "labels": [], "entities": [{"text": "Text categorization", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7942914664745331}]}, {"text": "Since in text categorization, categories are determined beforehand in such away as to meet the user's specific tastes or needs, they may not serve as a topic or a theme in that they need not have a semantic relevance to the contents of documents.", "labels": [], "entities": []}, {"text": "Technically, however, it is straightforward to move from text categorization to topic identification, provided that we are able to somehow isolate themes in texts and use them as categories to be assigned to texts.", "labels": [], "entities": [{"text": "topic identification", "start_pos": 80, "end_pos": 100, "type": "TASK", "confidence": 0.7173569947481155}]}, {"text": "But the problem with using text categorization for topic identification, is that categories are arbitrarily given by humans, with no regard for documents that are to be classified.", "labels": [], "entities": [{"text": "topic identification", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.8680386543273926}]}, {"text": "There is thus always a danger of misrepresenting documents.", "labels": [], "entities": []}, {"text": "One possible way out is to choose categories not from outside of the documents but from within.", "labels": [], "entities": []}, {"text": "The feasibility of the idea is explored in the paper.", "labels": [], "entities": []}, {"text": "The use of text structure in information retrieval was motivated by the need for dealing with large documents, whose breadth of vocabulary may easily mislead the retrieval system into making a wrong judgement about their relevancy to the query.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.7278474569320679}]}, {"text": "Indeed, anew area of research known as passage retrieval has emerged to explore methods for using information from various levels of a document's structure, e.g. sentences, sections, paragraphs, and other semantically or rhetorically motivated textual units.", "labels": [], "entities": [{"text": "passage retrieval", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.8602025508880615}]}, {"text": "describes weighting methods that combine the similarity measure with various textual categories like abstract, purpose and supplementary, etc.", "labels": [], "entities": []}, {"text": "compares the full-text retrieval with the passage retrieval based on sections and paragraphs, and reports that the latter form of retrieval led to an increased effectiveness.", "labels": [], "entities": []}, {"text": "examines the usefulness of passage for relevance feedback, which concerns deriving or learning useful query terms from retrieved documents. is an interesting attempt to enhance the retrieval performance by using what they calla text tile, a discourse unit determined on the basis of the subject or content of the text.", "labels": [], "entities": []}, {"text": "proposes a hybrid approach of using both passage and document.", "labels": [], "entities": []}, {"text": "Section 2 introduces the idea of bringing an IR technique to the topic identification task.", "labels": [], "entities": [{"text": "IR", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.9887108206748962}, {"text": "topic identification task", "start_pos": 65, "end_pos": 90, "type": "TASK", "confidence": 0.8848669330279032}]}, {"text": "Section 3 discusses a problem that the proposed method shows poor performance on large documents.", "labels": [], "entities": []}, {"text": "Section 4 is a response to the problem: we propose the use of information on text structure to reduce irrelevancy in the document and increase effectiveness.", "labels": [], "entities": []}, {"text": "In Section 5, we conduct a set of experiments to determine whether the use of text structure has a positive effect on the performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have conducted a set of experiments to see how a full-text and \"discard\" model compare in terms of the performance on the topic identification task.", "labels": [], "entities": [{"text": "topic identification task", "start_pos": 125, "end_pos": 150, "type": "TASK", "confidence": 0.8317580024401346}]}, {"text": "Our experiments used the total of 43,253 full-text news articles from Nihon Keizai Shimbun, a Japanese business daily).", "labels": [], "entities": [{"text": "Nihon Keizai Shimbun, a Japanese business daily", "start_pos": 70, "end_pos": 117, "type": "DATASET", "confidence": 0.8674975410103798}]}, {"text": "All of the articles appeared in the first half of the year 1992.", "labels": [], "entities": []}, {"text": "Of these, 40,553 articles, which appeared on May 31, 1992 and earlier, were used for training and the remaining 2,700 articles, which appeared on June 1, 1992 or later, were used for testing.", "labels": [], "entities": []}, {"text": "A training set and a test set were obtained by extracting nouns from the newspaper corpus, which involves as a sub-step tokenizing each article into a set of words.", "labels": [], "entities": [{"text": "newspaper corpus", "start_pos": 73, "end_pos": 89, "type": "DATASET", "confidence": 0.8080705404281616}]}, {"text": "The procedure was carried outwith the tokenizer program JUMAN.", "labels": [], "entities": [{"text": "JUMAN", "start_pos": 56, "end_pos": 61, "type": "DATASET", "confidence": 0.8053601384162903}]}, {"text": "The resultant training set contained some 2.5 million words excluding stop words.", "labels": [], "entities": []}, {"text": "The test set was then divided into nine subsets of news articles according to the length.", "labels": [], "entities": []}, {"text": "Each subset contained 300 articles.", "labels": [], "entities": []}, {"text": "In, the test set 1, for instance, consists of articles, each of which which contains from 100 to 200 characters.", "labels": [], "entities": []}, {"text": "The test set 2, on the other hand, consists of larger articles, which are between 200 and 300 character long.", "labels": [], "entities": []}, {"text": "test set length (in char.) num. of doc.", "labels": [], "entities": []}, {"text": "1 400-500 300 5 500-600 300 6 600-700 300 7 700-800 300 8 800-900 300 9 900-1000 300 In the experiments, we were interested in finding out the effectiveness of a segment model which considers a starting block of the article and ignores everything else.", "labels": [], "entities": []}, {"text": "Here we tried two approaches; one is based on a fixed-length segment and the other on a proportional-length segment.", "labels": [], "entities": []}, {"text": "The fixed-length approach uses the first i words of the text, i being constant across texts, whereas the proportionallength approach uses the first j% of words contained in the text, so that the actual length of segment is  proportional to that of the whole text.", "labels": [], "entities": []}, {"text": "show break even points of experiments using the fixed-length and proportionallength strategies, respectively.", "labels": [], "entities": []}, {"text": "A break even point is a highest point where recall and precision is equal.", "labels": [], "entities": [{"text": "break even point", "start_pos": 2, "end_pos": 18, "type": "METRIC", "confidence": 0.9677092234293619}, {"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9994933605194092}, {"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9987661838531494}]}, {"text": "It is meant as a summary figure of the performance.", "labels": [], "entities": []}, {"text": "Precision and recall are determined for each text in the test set, by the formulae below: the number of words correctly identified as title words Precision = the number of words assigned the number of words correctly identified as title words Recall = the number of actual topics We use a assigning strategy called probabilistic thresholding to decide what words to be assigned to the text as potential title indicators.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9811033010482788}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9985167384147644}, {"text": "Precision", "start_pos": 146, "end_pos": 155, "type": "METRIC", "confidence": 0.9645088911056519}]}, {"text": "Basically, what we do is to pickup a thresholding constant k and assign words whose probability of being a title word is greater thank.", "labels": [], "entities": []}, {"text": "Typically, a large value of k gives high recall and low precision, while the opposite is the case with a small value of k.", "labels": [], "entities": [{"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.999403715133667}, {"text": "precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9993053674697876}]}, {"text": "A break even point is obtained by varying the value of k.", "labels": [], "entities": [{"text": "break even point", "start_pos": 2, "end_pos": 18, "type": "METRIC", "confidence": 0.8961512843767802}]}, {"text": "Returning to, i indicates the size of segment, and I the length of text.", "labels": [], "entities": []}, {"text": "The '+/-' figure next to each break even point indicates the improvement (or drop) as compared to a topic identification task using full texts.", "labels": [], "entities": [{"text": "topic identification task", "start_pos": 100, "end_pos": 125, "type": "TASK", "confidence": 0.813698430856069}]}, {"text": "means that no break even point was found for the associated experiment and the precision at the highest recall is listed instead (the highest recall is given parenthetically).", "labels": [], "entities": [{"text": "precision", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9989755153656006}, {"text": "recall", "start_pos": 104, "end_pos": 110, "type": "METRIC", "confidence": 0.9944223761558533}, {"text": "recall", "start_pos": 142, "end_pos": 148, "type": "METRIC", "confidence": 0.9918729662895203}]}, {"text": "In case that the length of a text is smaller than that of the segment, the whole text is used.", "labels": [], "entities": []}, {"text": "The column labelled \"10\" in is the result of applying a segment model which considers the starting 10-word block from a text.", "labels": [], "entities": []}, {"text": "The table shows that at i = 10, there were no break even points found for texts with more than 400 characters (1 > 400).", "labels": [], "entities": []}, {"text": "Both the FLM and PLM approaches produced an improvement over the full-text model.", "labels": [], "entities": [{"text": "FLM", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.6070656776428223}]}, {"text": "Discarding rear portions of a text turns out to be more effective for large texts (1 > 200) than for short texts (100 < l < 200).", "labels": [], "entities": [{"text": "Discarding rear portions of a text", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8177299002806345}]}, {"text": "However, the effectiveness of the \"discard\" strategy slowly declines as the text length increases.", "labels": [], "entities": []}, {"text": "In, for instance, the effectiveness falls from .42 to .32 at i = 20.", "labels": [], "entities": [{"text": "effectiveness", "start_pos": 22, "end_pos": 35, "type": "METRIC", "confidence": 0.9935498833656311}]}, {"text": "The distribution of similarity measurements for large texts in suggests that the similarity distribution for large texts tend to be less skewed to the left than that for short texts.", "labels": [], "entities": []}, {"text": "This would mean that title-indicating terms are scattered more evenly over the text, and thus it becomes all the more difficult to demarcate between relevant and irrelevant parts of the text.", "labels": [], "entities": []}, {"text": "A problem with the PLM approach is that a segment from which topical words are chosen is too small for short texts.", "labels": [], "entities": [{"text": "PLM", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.901200532913208}]}, {"text": "Thus at 20%, for instance, its performance on 100-200 character texts drops by 17% compared to the full-text approach, but gradually improves as the value of j increases.", "labels": [], "entities": []}, {"text": "Interestingly enough, the situation turns around when l is large and j is small: thus at j = 20, there is a 20 % increase for 500 < l < 600 but a 17 % decrease for 100 < l < 200.", "labels": [], "entities": []}, {"text": "The results of experiments using paragraphs are shown in.", "labels": [], "entities": []}, {"text": "The experiments used the first paragraph of a text as a segment.", "labels": [], "entities": []}, {"text": "Though the use of paragraph achieved better results at some points (300-400 and 500-600) than other approaches, the overall performance is not outstanding compared to either FLM or PLM.", "labels": [], "entities": []}, {"text": "In particular, the 'first paragraph' strategy is outperformed by the full-text method on texts with more than 900 characters.", "labels": [], "entities": []}, {"text": "Two major benefits of using text structure in topic identification are an improvement in effectiveness and a considerable reduction of the text volume necessary for the correct identification of text topics.", "labels": [], "entities": [{"text": "topic identification", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.9372547268867493}]}, {"text": "For instance, a fixed-length model using the first 20-word block requires only about one tenth of the words that are used in a full-text model and still performs significantly and consistently better than the latter.", "labels": [], "entities": []}, {"text": "Contrary to our expectation, the results of the experiments cast some doubt as to the usefulness of paragraphs for topic identification..", "labels": [], "entities": [{"text": "topic identification.", "start_pos": 115, "end_pos": 136, "type": "TASK", "confidence": 0.9127674400806427}]}, {"text": "As a conclusion, let us mention a few points.", "labels": [], "entities": []}, {"text": "The present paper demonstrated that evidence on text structure enhanced the performance on the identification of topical words in texts, which is based on a probabilistic model of text categorization.", "labels": [], "entities": [{"text": "identification of topical words in texts", "start_pos": 95, "end_pos": 135, "type": "TASK", "confidence": 0.8575803935527802}]}, {"text": "Importantly, we used texts which are not explicitly structured.", "labels": [], "entities": []}, {"text": "A text structure is identified by measuring the similarity between segments comprising the text and its title.", "labels": [], "entities": []}, {"text": "It was shown clearly that a text structure thus identified gives a good clue to finding out parts of the text most relevant to its content.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Fixed-LengthModel(FLM): a summary", "labels": [], "entities": []}, {"text": " Table 3: Proportional-Length Model (PLM): a summary", "labels": [], "entities": []}, {"text": " Table 4: Results for using paragraphs. Figures are in break even point.", "labels": [], "entities": [{"text": "break even point", "start_pos": 55, "end_pos": 71, "type": "METRIC", "confidence": 0.9008738795916239}]}]}