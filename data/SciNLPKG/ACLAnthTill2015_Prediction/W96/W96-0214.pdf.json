{"title": [{"text": "Efficient Algorithms for Parsing the DOP Model *", "labels": [], "entities": []}], "abstractContent": [{"text": "Excellent results have been reported for Data-Oriented Parsing (DOP) of natural language texts (Bod, 1993c).", "labels": [], "entities": [{"text": "Data-Oriented Parsing (DOP) of natural language texts", "start_pos": 41, "end_pos": 94, "type": "TASK", "confidence": 0.8353791269991133}, {"text": "Bod, 1993c)", "start_pos": 96, "end_pos": 107, "type": "DATASET", "confidence": 0.9225282818078995}]}, {"text": "Unfortunately, existing algorithms are both computationally intensive and difficult to implement.", "labels": [], "entities": []}, {"text": "Previous algorithms are expensive due to two factors: the exponential number of rules that must be generated and the use of a Monte Carlo parsing algorithm.", "labels": [], "entities": []}, {"text": "In this paper we solve the first problem by a novel reduction of the DOP model to:a small, equivalent probabilistic context-free grammar.", "labels": [], "entities": []}, {"text": "We solve the second problem by a novel deterministic parsing strategy that maximizes the expected number of correct constituents , rather than the probability of a correct parse tree.", "labels": [], "entities": []}, {"text": "Using ithe optimizations, experiments yield a 97% crossing brackets rate and 88% zero crossing brackets rate.", "labels": [], "entities": []}, {"text": "This differs significantly from the results reported by Bod, and is comparable to results from a duplication of Pereira and Schabes's (1992) experiment on the same data.", "labels": [], "entities": [{"text": "Bod", "start_pos": 56, "end_pos": 59, "type": "DATASET", "confidence": 0.9488447904586792}]}, {"text": "We show that Bod's results are at least partially due to an extremely fortuitous choice of test data, and partially due to using cleaner data than other researchers.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Data-Oriented Parsing (DOP) model has a short, interesting, and controversial history.", "labels": [], "entities": [{"text": "Data-Oriented Parsing (DOP)", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.7721594572067261}]}, {"text": "It was introduced by Remko, and was then studied by Rens Bod.", "labels": [], "entities": []}, {"text": "Unfortunately, was notable to find an efficient exact * I would like to acknowledge support from National Science Foundation Grant IRI-9350192 and a National Science Foundation Graduate Student Fellowship.", "labels": [], "entities": [{"text": "National Science Foundation Grant IRI-9350192", "start_pos": 97, "end_pos": 142, "type": "DATASET", "confidence": 0.8803578615188599}, {"text": "National Science Foundation Graduate Student Fellowship", "start_pos": 149, "end_pos": 204, "type": "DATASET", "confidence": 0.9282006323337555}]}, {"text": "I would also like to thank Rens Bod, Stan Chen, Andrew Kehler, David Magerman, Wheeler Rural, Stuart Shieber, and Khalil Sima'an for helpful discussions, and comments on earlier drafts, and the comments of the anonymous reviewers.", "labels": [], "entities": []}, {"text": "algorithm for parsing using the model; however he did discover and implement Monte Carlo approximations.", "labels": [], "entities": [{"text": "parsing", "start_pos": 14, "end_pos": 21, "type": "TASK", "confidence": 0.9712902903556824}]}, {"text": "He tested these algorithms on a cleaned up version of the ATIS corpus, and achieved some very exciting results, reportedly getting 96% of his test set exactly correct, a huge improvement over previous results.", "labels": [], "entities": [{"text": "ATIS corpus", "start_pos": 58, "end_pos": 69, "type": "DATASET", "confidence": 0.972940593957901}]}, {"text": "For instance, Bod (1993b) compares these results to, in which, for short sentences, 30% of the sentences have no crossing brackets (a much easier measure than exact match).", "labels": [], "entities": [{"text": "Bod (1993b)", "start_pos": 14, "end_pos": 25, "type": "DATASET", "confidence": 0.8924254477024078}, {"text": "exact match", "start_pos": 159, "end_pos": 170, "type": "METRIC", "confidence": 0.9268181920051575}]}, {"text": "Thus, Bod achieves an extraordinary &fold error rate reduction.", "labels": [], "entities": [{"text": "Bod", "start_pos": 6, "end_pos": 9, "type": "DATASET", "confidence": 0.8243071436882019}, {"text": "fold error rate", "start_pos": 37, "end_pos": 52, "type": "METRIC", "confidence": 0.849179188410441}]}, {"text": "Not surprisingly, other researchers attempted to duplicate these results, but due to alack of details of the parsing algorithm in his publications, these other researchers were notable to confirm the results (Magerman, Lalferty, personal communication).", "labels": [], "entities": [{"text": "parsing", "start_pos": 109, "end_pos": 116, "type": "TASK", "confidence": 0.9659347534179688}]}, {"text": "Even Bod's thesis) does not contain enough information to replicate his results.", "labels": [], "entities": [{"text": "Bod's thesis", "start_pos": 5, "end_pos": 17, "type": "DATASET", "confidence": 0.9302577376365662}]}, {"text": "Parsing using the DOP model is especially difficult.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.982455849647522}]}, {"text": "The model can be summarized as a special kind of Stochastic Tree Substitution Grammar (STSG): given a bracketed, labelled training corpus, let every subtree of that corpus bean elementary tree, with a probability proportional to the number of occurrences of that subtree in the training corpus.", "labels": [], "entities": [{"text": "Stochastic Tree Substitution Grammar (STSG)", "start_pos": 49, "end_pos": 92, "type": "TASK", "confidence": 0.8094590050833566}]}, {"text": "Unfortunately, the number of trees is in general exponential in the size of the training corpus trees, producing an unwieldy grammar.", "labels": [], "entities": []}, {"text": "In this paper, we introduce a reduction of the DOP model to an exactly equivalent Probabilistic Context Free Grammar (PCFG) that is linear in the number of nodes in the training data.", "labels": [], "entities": []}, {"text": "Next, we present an algorithm for parsing, which returns the parse that is expected to have the largest number of correct constituents.", "labels": [], "entities": [{"text": "parsing", "start_pos": 34, "end_pos": 41, "type": "TASK", "confidence": 0.9843633770942688}]}, {"text": "We use the reduction and algorithm to parse held out test data, comparing these results to a replication of Pereira and This paper contains the first published replication of the full DOP model, i.e. using a parser which sums over derivations.", "labels": [], "entities": []}, {"text": "It also contains algorithms implementing the model with significantly fewer resources than previously needed.", "labels": [], "entities": []}, {"text": "Furthermore, for the first time, the DOP model is compared on the same data to a competing model.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: DOP versus Pereira and Schabes on Minimally Edited ATIS", "labels": [], "entities": [{"text": "DOP", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8176149725914001}, {"text": "ATIS", "start_pos": 61, "end_pos": 65, "type": "TASK", "confidence": 0.31973275542259216}]}, {"text": " Table 2: DOP versus Pereira and Schabes on Bod's Data", "labels": [], "entities": [{"text": "DOP", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9129654765129089}, {"text": "Bod's Data", "start_pos": 44, "end_pos": 54, "type": "DATASET", "confidence": 0.992529292901357}]}, {"text": " Table 3: Transformations from N-ary to Binary Branching Structures", "labels": [], "entities": []}, {"text": " Table 4: Probabilities of Sentences with Unique Productions/Test Data with Ungeneratable Sentences", "labels": [], "entities": []}]}