{"title": [{"text": "A generative perspective on verbs and their readings", "labels": [], "entities": []}], "abstractContent": [{"text": "We sketch the architecture of a sentence generation module that maps a language-neutral \"deep\" representation to a language-specific sentence-semantic specification, which is given to a front-end generator.", "labels": [], "entities": [{"text": "sentence generation module", "start_pos": 32, "end_pos": 58, "type": "TASK", "confidence": 0.7869308590888977}]}, {"text": "Lexicaliza-t, ion is tlm main instrument tbr the mapl~ing step, and we examine the role of verb semantics in the process.", "labels": [], "entities": []}, {"text": "In particular, we propose a set of rules that derive a range of verb alternations from a single base form, which is one source of lexical paraphrasing in the system.", "labels": [], "entities": []}, {"text": "1 Overview This paper examines the role of several aspects of verb semantics for natural language general ,ion.", "labels": [], "entities": []}, {"text": "We assume a scenario of producing sentences in multiple languages from a common underlying representation~although the problems of mul-tilinguality will not bean explicit topic here.", "labels": [], "entities": []}, {"text": "Section 2 briefly describes the architecture of an implemented generator, called MOOSE, and characterizes the two levels of representation involved:, a language-neutral level for representing various kinds of events, and a language-specific level of semantic sentence specification , which largely corresponds to the level of'sentence plans' used in systems based on a linguistic upper model, specifically PENMAN [Bateman et el. 1990].", "labels": [], "entities": []}, {"text": "The lexicon of a target language is the primary vehicle for mapping from one level to the other.", "labels": [], "entities": []}, {"text": "Then, sections 3 and4 discuss our primary topic: verb semantics.", "labels": [], "entities": [{"text": "verb semantics", "start_pos": 49, "end_pos": 63, "type": "TASK", "confidence": 0.7335020303726196}]}, {"text": "First, a treatment of several Aktionsart features is proposed, and the role of valency in the tipper model idea is examined, and improvements suggested.", "labels": [], "entities": []}, {"text": "Section 4 proposes a set of rules for systematically computing alternations (or diatheses) of a verb from a single base form.", "labels": [], "entities": [{"text": "computing alternations (or diatheses) of a verb", "start_pos": 53, "end_pos": 100, "type": "TASK", "confidence": 0.7576227519247267}]}, {"text": "4 *For their helpful comments and suggestions for improving this paper, I thank two anonymous reviewers.", "labels": [], "entities": []}, {"text": "Au-thor's address: TU Berlin, Proiekt KIT-VMll, Sekr.", "labels": [], "entities": [{"text": "TU Berlin", "start_pos": 19, "end_pos": 28, "type": "DATASET", "confidence": 0.7075750827789307}]}, {"text": "28/29, 141 2 Two-step sentence generation The MOOSE sentence generator grew out of experiences with building the TECHDOC system [RSsner, Stede 1994], which produces instructional text in multiple l:mguages from a common representation.", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.7341950833797455}, {"text": "MOOSE sentence generator", "start_pos": 46, "end_pos": 70, "type": "TASK", "confidence": 0.661673386891683}]}, {"text": "Specifically , MOOSE accounts for the fact that events can receive different verbalizations even in closely related languages such as English and German.", "labels": [], "entities": [{"text": "MOOSE", "start_pos": 15, "end_pos": 20, "type": "TASK", "confidence": 0.7139912247657776}]}, {"text": "It is designed as a sentence generation module that pays attention to language-specific lexical idiosyncrasies, and that can be incorporated into a larger-scale text generator.", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.7246292233467102}]}, {"text": "2.1 MOOSE in a nutshell For this brief description of the system architecture , see figure 1.", "labels": [], "entities": [{"text": "MOOSE", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.8107832074165344}]}, {"text": "The generator assumes a language-neutral level of event representation, the situation specification or SitSpec.", "labels": [], "entities": []}, {"text": "Using parts oft, he target lexicon (see section 2.3), the lexical options for verbalizing the SitSpec are determined.", "labels": [], "entities": []}, {"text": "For verbs, the applicable alternations and extensions are computed (see section 4) and added to the set of options.", "labels": [], "entities": []}, {"text": "Then a language-specific semantic specification SemSpec is constructed in accordance with generation parameters pertaining to brevity and stylistic tbatures.", "labels": [], "entities": []}, {"text": "The SemSpec is then handed over to a surface generator: Penman [Pen-man Group 1989] for English, and a variant developed at FAW Uhn for German.", "labels": [], "entities": [{"text": "Penman [Pen-man Group 1989]", "start_pos": 56, "end_pos": 83, "type": "DATASET", "confidence": 0.9078946014245352}, {"text": "FAW Uhn", "start_pos": 124, "end_pos": 131, "type": "DATASET", "confidence": 0.9302213191986084}]}, {"text": "As opposed to the 'tradi-tional' Penman idea, the domain model in which the input SitSpec is represented has been de-coupled from the linguistic upper model, in order to achieve variety in verbalization that would otherwise not be possible [Stede and Grote 1995], MOOSE is implemented in Macintosh Common Lisp and uses MacPenman; a full description of the system is given in [Stede 1996].", "labels": [], "entities": []}, {"text": "2.2 Levels of representation A central assumption of the research reported here is that the \"deepest\" level of representation is in general not a linguistic representation; instead, we assume a domain model of some sort, implemented in a KI=I. language.", "labels": [], "entities": []}, {"text": "Thus, an explicit transition between instan-tinted domain knowledge and a language-specific semantic sentence representation is seen as the central step in generation.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}