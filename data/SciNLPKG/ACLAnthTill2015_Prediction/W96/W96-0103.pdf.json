{"title": [{"text": "Hierarchical Clustering of Words and Application to NLP Tasks", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes a data-driven method for hierarchical clustering of words and clustering of multiword compounds.", "labels": [], "entities": [{"text": "hierarchical clustering of words", "start_pos": 46, "end_pos": 78, "type": "TASK", "confidence": 0.7196470275521278}]}, {"text": "A large vocabulary of English words (70,000 words) is clustered bottom-up, with respect to corpora ranging in size from 5 million to 50 million words, using mutual information as an objective function.", "labels": [], "entities": []}, {"text": "The resulting hierarchical clusters of words are then naturally transformed to a bit-string representation of (i.e. word bits for) all the words in the vocabulary.", "labels": [], "entities": []}, {"text": "Evaluation of the word bits is carried out through the measurement of the error rate of the ATR Decision-Tree Part-Of-Speech Tagger.", "labels": [], "entities": [{"text": "error rate", "start_pos": 74, "end_pos": 84, "type": "METRIC", "confidence": 0.970199853181839}, {"text": "ATR Decision-Tree Part-Of-Speech Tagger", "start_pos": 92, "end_pos": 131, "type": "TASK", "confidence": 0.6911108195781708}]}, {"text": "The same clustering technique is then applied to the classification of multiword compounds.", "labels": [], "entities": [{"text": "classification of multiword compounds", "start_pos": 53, "end_pos": 90, "type": "TASK", "confidence": 0.8174245655536652}]}, {"text": "In order to avoid the explosion of the number of compounds to be handled, compounds in a small subclass are bundled and treated as a single compound.", "labels": [], "entities": []}, {"text": "Another merit of this approach is that we can avoid the data sparseness problem which is ubiquitous in corpus statistics.", "labels": [], "entities": []}, {"text": "The quality of one of the obtained compound classes is examined and compared to a conventional approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the fundamental issues concerning corpus-based NLP is that we can never expect to know from the training data all the necessary quantitative information for the words that might occur in the test data if the vocabulary is large enough to cope with areal world domain.", "labels": [], "entities": []}, {"text": "In view of the effectiveness of class-based n-gram language models against the data sparseness problem, it is expected that classes of words are also useful for NLP tasks in such away that statistics on classes are used whenever statistics on individual words are unavailable or unreliable.", "labels": [], "entities": []}, {"text": "An ideal type of clusters for NLP is the one which guarantees mutual substitutability, in terms of both syntactic and semantic soundness, among words in the same class.", "labels": [], "entities": []}, {"text": "Take, for example, the following sentences.", "labels": [], "entities": []}, {"text": "(a) He went to the house by car.", "labels": [], "entities": []}, {"text": "(b) He went to the apartment by bus.", "labels": [], "entities": []}, {"text": "(c) He went to the ? by ? .", "labels": [], "entities": []}, {"text": "(d) He went to the house by the sea.", "labels": [], "entities": []}, {"text": "Suppose that we want to parse sentences using a statistical parser and that sentences (a) and (b) appeared in the training and test data, respectively.", "labels": [], "entities": []}, {"text": "Since (a) is in the training data, we know that the prepositional phrase by car is attached to the main verb went, not to the noun phrase the house.", "labels": [], "entities": []}, {"text": "Sentence (b) is quite similar to (a) in meaning, and identical to (a) in sentence structure.", "labels": [], "entities": []}, {"text": "Now if the words apartment and bus are unknown to the parsing system *A part of this work is done when the author was at ATR Interpreting Telecommunications Research Laboratories, Kyoto, Japan.", "labels": [], "entities": [{"text": "ATR Interpreting Telecommunications Research Laboratories", "start_pos": 121, "end_pos": 178, "type": "DATASET", "confidence": 0.9123112201690674}]}, {"text": "(i.e. never occurred in the training data), then sentence (b) must look to the system very much like (c), and it will be very hard for the parsing system to tell the difference in sentence structure between (c) and (d).", "labels": [], "entities": []}, {"text": "However, if the system has access to a predefined set of classes of words, and if car and bus are in the same class, and house and apartme.nt are in another class, it will not be hard for the system to detect the similarity between (a) and (b) and assign the correct sentence structure to (b) without confusing it with (d).", "labels": [], "entities": []}, {"text": "The same argument holds for an example-based machine translation system.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7015527933835983}]}, {"text": "In that case, an appropriate translation of (b) is expected to be derived with an example translation of (a) if the system has an access to the classes of words.", "labels": [], "entities": []}, {"text": "Therefore, it is desirable that we build clustering of the vocabulary in terms of mutual substitutability.", "labels": [], "entities": []}, {"text": "Furthermore, clustering is much more useful if the clusters are of variable granularity.", "labels": [], "entities": [{"text": "clustering", "start_pos": 13, "end_pos": 23, "type": "TASK", "confidence": 0.9618688225746155}]}, {"text": "Suppose, for example, that we have two sets of clusters, one is finer than the other, and that word-1 and word-2 are in different finer classes.", "labels": [], "entities": []}, {"text": "With finer clusters alone, the amount of information on the association of the two words that the system can obtain from the clusters is minimal.", "labels": [], "entities": []}, {"text": "However, if the system has a capability of falling back and checking if they belong to the same coarser class, and if that is the case, then the system can take advantage of the class information for the two words.", "labels": [], "entities": []}, {"text": "When we extend this notion of two-level word clustering to many levels, we will have a tree representation of all the words in the vocabulary in which the root node represents the whole vocabulary and a leaf node represents a word in the vocabulary.", "labels": [], "entities": []}, {"text": "Also, any set of nodes in the tree constitutes a partition (or clustering) of the vocabulary if there exists one and only one node in the set along the path from the root node to each leaf node.", "labels": [], "entities": []}, {"text": "In the following sections, we will first describe a method of creating a binary tree representation of the vocabulary and present results of evaluating and comparing the quality of the clusters obtained from texts of very different sizes.", "labels": [], "entities": []}, {"text": "Then we will extend the paradigm of clustering from word-based clustering to compound-based clustering.", "labels": [], "entities": []}, {"text": "In the above examples we looked only at the mutual substitutability of words; however, a lot of information can also be gained if we look at the substitutability of word compounds for either other word compounds or single words.", "labels": [], "entities": []}, {"text": "We will introduce the notion of compound-classes, propose a method for constructing them, and present results of our approach.", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed experiments using plain texts from six years of the Wall Street Journal Corpus to create clusters and word bits.", "labels": [], "entities": [{"text": "Wall Street Journal Corpus", "start_pos": 65, "end_pos": 91, "type": "DATASET", "confidence": 0.9715746343135834}]}, {"text": "The sizes of the texts are 5 million words (MW), 10MW, 20MW, and 50MW.", "labels": [], "entities": []}, {"text": "The vocabulary is selected as the 70,000 most frequently occurring words in the entire corpus.", "labels": [], "entities": []}, {"text": "We set the number C of classes to 500.", "labels": [], "entities": []}, {"text": "The obtained hierarchical clusters are evaluated via the error rate of the ATR Decision-Tree Part-Of-Speech Tagger.", "labels": [], "entities": [{"text": "error rate", "start_pos": 57, "end_pos": 67, "type": "METRIC", "confidence": 0.968062549829483}, {"text": "ATR Decision-Tree Part-Of-Speech Tagger", "start_pos": 75, "end_pos": 114, "type": "TASK", "confidence": 0.6675672084093094}]}, {"text": "Then as an attempt to combine the two types of clustering methods discussed in Section 2, we performed an experiment for incorporating a word-reshuffling process into the word bits construction process.", "labels": [], "entities": [{"text": "word bits construction", "start_pos": 171, "end_pos": 193, "type": "TASK", "confidence": 0.6178864439328512}]}, {"text": "We used plain texts from two years of Wall Street Journal Corpus to create compound clusters.", "labels": [], "entities": [{"text": "Wall Street Journal Corpus", "start_pos": 38, "end_pos": 64, "type": "DATASET", "confidence": 0.9621990621089935}]}, {"text": "The total volume amounts to about 40 MW of text.", "labels": [], "entities": []}, {"text": "The word-classes used in this experiment are taken from the result of MI clustering with the 50MW text followed by five rounds of reshuffling.", "labels": [], "entities": [{"text": "MI clustering", "start_pos": 70, "end_pos": 83, "type": "TASK", "confidence": 0.7902780473232269}]}, {"text": "The quality of the compound clusters depends on the threshold *TH* in equation 3.", "labels": [], "entities": [{"text": "TH", "start_pos": 63, "end_pos": 65, "type": "METRIC", "confidence": 0.9901008605957031}]}, {"text": "We used *TH*=3 following \"a very rough rule of thumb\" used for word-based mutual information in.", "labels": [], "entities": [{"text": "TH*=3", "start_pos": 9, "end_pos": 14, "type": "METRIC", "confidence": 0.9532363613446554}]}, {"text": "Out of the 40MW text, 7621 distinct class chains and 287,656 distinct multiword compounds are extracted.", "labels": [], "entities": []}, {"text": "To construct anew vocabulary, we selected the words and tokens whose frequency in the reduced text is more than four.", "labels": [], "entities": []}, {"text": "The size of the new vocabulary is 60589 and it contains 4685 class chain tokens.", "labels": [], "entities": []}, {"text": "Some of the compound-classes that were obtained are shown in.", "labels": [], "entities": []}, {"text": "The compounds are listed in descending order of frequency in each class, and the lists are truncated at an arbitrary point.", "labels": [], "entities": []}, {"text": "6The conversion of a word-class to a word is not a one-to-one mapping, but with the context in the text the conversion is unique.", "labels": [], "entities": []}, {"text": "In the actual implementation, the text is represented by a series of (word, word-class) pairs and no conversion is actually carried out.", "labels": [], "entities": []}, {"text": "consists of names with title many of which are politicians' names.", "labels": [], "entities": []}, {"text": "Compound-class-179 contains multiword company names.", "labels": [], "entities": []}, {"text": "Compound-class-221 consists of multiword compound nouns from several specific semantic domains including money, surgery and natural environment, but most of the frequent compounds are money-related terms.", "labels": [], "entities": []}, {"text": "Compound-class-256 is worth special attention in the sense that although single words and multiword compounds are mixed almost evenly, most of the single words are abbreviations of organizations, mostly public organizations, and the multiword compounds also ahnost exclusively represent public organizations.", "labels": [], "entities": []}, {"text": "Another point to note here is that the pattern of case is not uniform in this list.", "labels": [], "entities": []}, {"text": "Although both \"Defense Department\" and \"British government\" represent political organizations, the former consists of only capitalized words and the latter doesn't.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Texts for Tagging Experiments", "labels": [], "entities": [{"text": "Tagging Experiments", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.933617115020752}]}]}