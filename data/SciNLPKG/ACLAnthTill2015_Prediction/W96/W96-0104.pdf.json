{"title": [{"text": "Learning similarity-based word sense disambiguation from sparse data", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 26, "end_pos": 51, "type": "TASK", "confidence": 0.7371296584606171}]}], "abstractContent": [{"text": "We describe a method for automatic word sense disambiguation using a text corpus and a machine-readable dictionary (MRD).", "labels": [], "entities": [{"text": "automatic word sense disambiguation", "start_pos": 25, "end_pos": 60, "type": "TASK", "confidence": 0.658335454761982}]}, {"text": "The method is based on word similarity and context similarity measures.", "labels": [], "entities": []}, {"text": "Words are considered similar if they appear in similar contexts; contexts are similar if they contain similar words.", "labels": [], "entities": []}, {"text": "The circularity of this definition is resolved by an iterative, converging process, in which the system learns from the corpus a set of typical usages for each of the senses of the polysemous word listed in the MRD.", "labels": [], "entities": []}, {"text": "A new instance of a polysemous word is assigned the sense associated with the typical usage most similar to its context.", "labels": [], "entities": []}, {"text": "Experiments show that this method performs well, and can learn even from very sparse training data.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word Sense Disambiguation (WSD) is the problem of assigning a sense to an ambiguous word, using its context.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.792300800482432}]}, {"text": "We assume that different senses of a word correspond to different entries in its dictionary definition.", "labels": [], "entities": []}, {"text": "For example, suit has two senses listed in a dictionary: an action in court, and suit of clothes.", "labels": [], "entities": []}, {"text": "Given the sentence The union's lawyers are reviewing the suit, we would like the system to decide automatically that suit is used therein its court-related sense (we assume that the part of speech of the polysemous word is known).", "labels": [], "entities": []}, {"text": "In recent years, text corpora have been the main source of information for learning automatic WSD (see, e.g., ().", "labels": [], "entities": [{"text": "WSD", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.7729580998420715}]}, {"text": "A typical corpus-based algorithm constructs a training set from all contexts of a polysemous word W in the corpus, and uses it to learn a classifier that maps instances of W (each supplied with its context) into the senses.", "labels": [], "entities": []}, {"text": "Because learning requires that the examples in the training set be partitioned into the different senses, and because sense information is not available in the corpus explicitly, this approach depends critically on manuM sense tagging --a laborious and time-consuming process that has to be repeated for every word, in every language, and, more likely than not, for every topic of discourse or source of information.", "labels": [], "entities": [{"text": "manuM sense tagging", "start_pos": 215, "end_pos": 234, "type": "TASK", "confidence": 0.5535914897918701}]}, {"text": "The need for tagged examples creates a problem referred to in previous works as the knowledge acquisition bottleneck: training a disambiguator for W requires that the examples in the corpus be partitioned into senses, which, in turn, requires a fully operational disambiguator.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 84, "end_pos": 105, "type": "TASK", "confidence": 0.7693758010864258}]}, {"text": "The method we propose circumvents this problem by automatically tagging the training set examples for W using other examples, that do not contain W, but do contain related words extracted from its dictionary definition.", "labels": [], "entities": []}, {"text": "For instance, in the training set for suit, we would use, in addition to the contexts of suit, all the contexts of cour'c and of clothes in the corpus, because court and clothes appear in the MRD entry of suit that defines its two senses.", "labels": [], "entities": []}, {"text": "Note that, unfike the contexts of suit, which may discuss either court action or clothing, the contexts of court are not fikely to be especially related to clothing, and, similarly, those of clothes will normally have tittle to do with lawsuits.", "labels": [], "entities": []}, {"text": "We will use this observation to tag the original contexts of suic.", "labels": [], "entities": []}, {"text": "Another problem that affects the corpus-based WSD methods is the sparseness of data: these methods typically rely on the statistics of cooccurrences of words, while many of the possible cooccurrences are not observed even in a very large corpus.", "labels": [], "entities": []}, {"text": "We address this problem in several ways.", "labels": [], "entities": []}, {"text": "First, instead of tallying word statistics for the examples of each sense (which maybe unrefiable when the examples are few), we collect sentence-level statistics, representing each sentence by the set of features it contains.", "labels": [], "entities": []}, {"text": "Second, we define a similarity measure on the feature space, which allows us to pool the statistics of similar features.", "labels": [], "entities": []}, {"text": "Third, in addition to the examples of the polysemous word W in the corpus, we learn also from the examples of all the words in the dictionary definition of W.", "labels": [], "entities": []}, {"text": "In our experiments, this resulted in a training set that could be up to 20 times larger than the set of original examples.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 1 describes the approach we have developed.", "labels": [], "entities": []}, {"text": "In section 2, we report the results of tests we have conducted on the Treebank-2 corpus.", "labels": [], "entities": [{"text": "Treebank-2 corpus", "start_pos": 70, "end_pos": 87, "type": "DATASET", "confidence": 0.985800176858902}]}, {"text": "Section 3 describes related work.", "labels": [], "entities": []}, {"text": "Proofs and other details of our scheme can be found in ().", "labels": [], "entities": []}], "datasetContent": [{"text": "We tested the algorithm on the Treebank-2 corpus, which contains 1 million words from the Wall Street Journal, 1989, and is considered a small corpus for the present task.", "labels": [], "entities": [{"text": "Treebank-2 corpus", "start_pos": 31, "end_pos": 48, "type": "DATASET", "confidence": 0.9151400327682495}, {"text": "Wall Street Journal, 1989", "start_pos": 90, "end_pos": 115, "type": "DATASET", "confidence": 0.8968735337257385}]}, {"text": "As the MRD, we used a combination of the Webster, the Oxford and the WordNet online dictionaries (the latter used as a thesaurus only).", "labels": [], "entities": [{"text": "MRD", "start_pos": 7, "end_pos": 10, "type": "DATASET", "confidence": 0.7224238514900208}, {"text": "Webster", "start_pos": 41, "end_pos": 48, "type": "DATASET", "confidence": 0.956153929233551}, {"text": "Oxford", "start_pos": 54, "end_pos": 60, "type": "DATASET", "confidence": 0.8813827633857727}, {"text": "WordNet online dictionaries", "start_pos": 69, "end_pos": 96, "type": "DATASET", "confidence": 0.9611008365948995}]}, {"text": "During the development and the tuning of the algorithm, we used the method of pseudo-words (, to save the need for manual verification of the resulting sense tags.", "labels": [], "entities": []}, {"text": "The final algorithm was tested on a total of 500 examples of four polysemous words: drug, sentence, suit, and player (see).", "labels": [], "entities": []}, {"text": "The relatively small number of polysemous words we studied was dictated by the size and nature of the corpus (we are currently testing additional words, using texts from the British National Corpus).", "labels": [], "entities": [{"text": "British National Corpus", "start_pos": 174, "end_pos": 197, "type": "DATASET", "confidence": 0.936068574587504}]}, {"text": "The average success rate of our algorithm was 92%.", "labels": [], "entities": []}, {"text": "The original training set (before the addition of the feedback sets) consisted of a few dozen examples, in comparison to thousands of examples needed in other corpus-based methods.", "labels": [], "entities": []}, {"text": "Results on two of the words on which we tested our algorithm (drug and suit) have been also reported in the works of Schutze and Yarowsky.", "labels": [], "entities": []}, {"text": "It is interesting to compare the performance of the different methods on these words.", "labels": [], "entities": []}, {"text": "On the word drug, our algorithm achieved performance of 90.5%, after being trained on 148 examples (contexts).", "labels": [], "entities": []}, {"text": "In comparison, (Yarowsky, 1995) achieved) achieved 957o correct performance, using 8206 contexts.", "labels": [], "entities": [{"text": "correct", "start_pos": 56, "end_pos": 63, "type": "METRIC", "confidence": 0.9298560619354248}]}, {"text": "In summary, our algorithm achieved performance comparable to some of the best reported results, using much less data for training.", "labels": [], "entities": []}, {"text": "This feature of our approach is important, because the size of the available training set is usually severely constrained for most senses of most words ().", "labels": [], "entities": []}, {"text": "Finally, we note that, as inmost corpus-based methods, supplying additional examples is expected to improve the performance.", "labels": [], "entities": []}, {"text": "We now present in detail several of the results obtained with the word drug.", "labels": [], "entities": []}, {"text": "A plot of the improvement in the performance vs. iteration number appears in.", "labels": [], "entities": []}, {"text": "The success rate is plotted for each sense, and for the weighted average of both senses we considered (the weights are proportional to the numb~er of examples of each sense).", "labels": [], "entities": [{"text": "numb~er", "start_pos": 139, "end_pos": 146, "type": "METRIC", "confidence": 0.8649109204610189}]}, {"text": "shows how the similarity values develop with iteration number.", "labels": [], "entities": []}, {"text": "For each example S of the narcotic sense of drug, the value of sims(S, narcotic) increases with n.", "labels": [], "entities": []}, {"text": "Note that after several iterations the similarity values are close to 1, and, because they are bounded by 1, they cannot change significantly with further iterations.", "labels": [], "entities": [{"text": "similarity", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.954984188079834}]}, {"text": "compares the similarities of a narcotic example to the narcotic sense and to the medicine sense, for each iteration.", "labels": [], "entities": []}, {"text": "The medicine sense assignment, made in the first iteration, has been corrected in the following iterations.", "labels": [], "entities": [{"text": "medicine sense assignment", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.5384059349695841}]}, {"text": "shows the most similar words found for the words with the highest weights in the drug example (low-similarity words have been omitted).", "labels": [], "entities": []}, {"text": "Note that the similarity is contextual, and is affected by the polysemous target word.", "labels": [], "entities": []}, {"text": "For example, traJficking was found to be similar to crime, because in drug contexts the expressions drug trajficking and crime are highly related.", "labels": [], "entities": []}, {"text": "In general, traJficking and crime need not be similar, of course.", "labels": [], "entities": [{"text": "traJficking", "start_pos": 12, "end_pos": 23, "type": "TASK", "confidence": 0.9585931897163391}]}], "tableCaptions": [{"text": " Table 1: A summary of the experimental results on four polysemous words.", "labels": [], "entities": []}]}