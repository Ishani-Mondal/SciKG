{"title": [], "abstractContent": [{"text": "This article investigates the effects of different degrees of contextual granularity on language model performance.", "labels": [], "entities": []}, {"text": "It presents anew language model that combines clustering and half-contextualization, a novel representation of contexts.", "labels": [], "entities": []}, {"text": "Half-contextualization is based on the half-context hypothesis that states that the distributional characteristics of a word or bigram are best represented by treating its context distribution to the left and right separately and that only directionally relevant distributional information should be used.", "labels": [], "entities": []}, {"text": "Clustering is achieved using anew clustering algorithm for class-based language models that compares favorably to the exchange algorithm.", "labels": [], "entities": []}, {"text": "When interpolated with a Kneser-Ney model, half-context models are shown to have better perplexity than commonly used interpolated n-gram models and traditional class-based approaches.", "labels": [], "entities": []}, {"text": "A novel, fine-grained, context-specific analysis highlights those contexts in which the model performs well and those which are better treated by existing non-class-based models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Stochastic language models area crucial component of many speech and language technology applications.", "labels": [], "entities": []}, {"text": "The key problem encountered by these models is that sparse data make the accurate estimation of the probability of novel and rare word sequences difficult.", "labels": [], "entities": []}, {"text": "In order to address this, language model researchers have developed a number of strategies.", "labels": [], "entities": []}, {"text": "Of particular interest in this article are the following four:", "labels": [], "entities": []}], "datasetContent": [{"text": "A corpus of, consisting of almost 50 million words, was randomly split into training set (80%), validation set (10%), and test set (10%).", "labels": [], "entities": []}, {"text": "Unigrams, bigrams, and trigrams and their counts were extracted from training, validation, and test sets.", "labels": [], "entities": []}, {"text": "A modified KN model (Chen and Goodman 1998), termed P (KN) , was estimated on the training set count files and applied to the test set using srilm, the SRI language modeling toolkit (Stolcke 2002).", "labels": [], "entities": [{"text": "SRI language modeling", "start_pos": 152, "end_pos": 173, "type": "TASK", "confidence": 0.5924000342686971}]}, {"text": "The same count files were the input to the HC and exemplar-theoretic model estimation and application procedure.", "labels": [], "entities": [{"text": "exemplar-theoretic model estimation", "start_pos": 50, "end_pos": 85, "type": "TASK", "confidence": 0.5769304037094116}]}, {"text": "Vocabulary size was the same for both KN and exemplar-theoretic models: 256,874 (the 256,873 words occurring in the training set and the unknown word).", "labels": [], "entities": [{"text": "Vocabulary size", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.9234263896942139}]}, {"text": "A total of 70.8% of tokens w 3 in the test set occur in a context w 1 w 2 w 3 occurring in the training set; for 22.2% of tokens only w 2 w 3 occurs in the training set; and for 6.7% only w 3 occurs in the training set.", "labels": [], "entities": []}, {"text": "The out-of-vocabulary rate is 0.27%.", "labels": [], "entities": [{"text": "out-of-vocabulary rate", "start_pos": 4, "end_pos": 26, "type": "METRIC", "confidence": 0.9562966525554657}]}, {"text": "All validation and test set words that do not occur in the training set are mapped to the special unknown token UNK.", "labels": [], "entities": []}, {"text": "In all interpolation experiments, the weight of the P (KN) model is 1 \u2212 \u03b1 and the weight of the model with which P (KN) is interpolated is \u03b1.", "labels": [], "entities": []}, {"text": "The validation set was employed to determine the optimum interpolation weight \u03b1 and discount D for each case.", "labels": [], "entities": [{"text": "interpolation weight \u03b1", "start_pos": 57, "end_pos": 79, "type": "METRIC", "confidence": 0.8666277329126993}, {"text": "discount D", "start_pos": 84, "end_pos": 94, "type": "METRIC", "confidence": 0.8294866383075714}]}, {"text": "Total processing time for estimating the HC clusters for S uni and S mixed (lines 13 and 15 in, subsequently) was less than 3.5 hours on an Opteron 8214 processor.", "labels": [], "entities": [{"text": "Opteron 8214 processor", "start_pos": 140, "end_pos": 162, "type": "DATASET", "confidence": 0.9561878641446432}]}, {"text": "In evaluating our model it seems appropriate to compare its performance against other class-based models.", "labels": [], "entities": []}, {"text": "Consequently, the SRI toolkit was also used to construct a class bigram language model, following the incremental version of the algorithm proposed by, which we simply term the P (Brown) model.", "labels": [], "entities": [{"text": "SRI toolkit", "start_pos": 18, "end_pos": 29, "type": "DATASET", "confidence": 0.830157071352005}]}, {"text": "A total of Perplexity results for interpolation of P (Brown) with a bigram model P . \u03b1 = 0 corresponds to P (KN) alone, \u03b1 = 1 corresponds to P Models used in our experiments.", "labels": [], "entities": [{"text": "Perplexity", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9919008016586304}]}, {"text": "modified Kneser-Ney model P exemplar-theoretic Brown model P exemplar-theoretic Half-Context model (Equation 1) P whole-context analogue of Equation 1 P (KN-Brown) interpolation of P (KN) with P (ET-Brown) P interpolation of P (KN) with P (Half) P (KN-Whole) interpolation of P (KN) with P (Whole) 1,024 classes (the same number of classes as the combined left and right context clusters in the 2 \u00d7 512 HC model) were derived from the training data.", "labels": [], "entities": []}, {"text": "1 presents results for the interpolation of P (Brown) with a bigram model P (KN) when applied to the validation set over a number of interpolation weights, followed by results from the test data using the optimum weight for the P (Brown) model (\u03b1 = 0.05) found during the validation phase.", "labels": [], "entities": []}, {"text": "It is clear from that although interpolating a traditional class-based model with a KN bigram model does offer some benefit, this benefit is slight (perplexity = 164.80 for P (KN) alone, versus 164.33 using the optimum interpolation weight on the test set).", "labels": [], "entities": []}, {"text": "It is also clear that the traditional class-based model operating by itself (\u03b1 = 1.0, perplexity = 245.45) performs poorly relative to P . Of course the SRI class-based model employs whole-context classes, not halfcontext distributions which consider behavior to the left and right separately.", "labels": [], "entities": []}, {"text": "The following models, detailed in, were used in our experiments: modified Kneser-Ney (P (KN) ); exemplar-theoretic half-context (P (Half) ); exemplar-theoretic wholecontext (P (Whole) ); exemplar-theoretic Brown (P (ET-Brown) ); and P , P (KN-Whole) , and P , the interpolations of Kneser-Ney with exemplar-theoretic half-context, whole-context, and Brown, respectively.", "labels": [], "entities": []}, {"text": "Perplexity results, for each of these models, from the validation and test sets, are presented in.", "labels": [], "entities": []}, {"text": "Order-2 in implies that only unigrams are clustered in the exemplar-theoretic models and the Kneser-Ney model is a bigram model.", "labels": [], "entities": []}, {"text": "As for order-3, this implies that both unigrams and bigrams are clustered together in the exemplar-theoretic models and that the Kneser-Ney model is a trigram model.", "labels": [], "entities": []}, {"text": "For lines 7-11 and 15-16, the parameters \u03b1 and D that were optimal on the validation set are given.", "labels": [], "entities": []}, {"text": "For lines 2-6 and 13-14, the optimal value of Don the validation set for \u03b1 = 1 (that is, 0 weight for the P (KN) model) was chosen.", "labels": [], "entities": []}, {"text": "The \u03b1 parameter on lines 8-11 and 15-16 indicates that half-and whole-context models are as valuable, or nearly so, as the KN models: The interpolation weight of half/whole-context models is either 0.4 or 0.5.", "labels": [], "entities": []}, {"text": "In contrast, the Brown class model (line 7) receives a lower weight of 0.2, indicating that it is less valuable in the interpolation with KN.", "labels": [], "entities": []}, {"text": "The discount parameter D determines the influence of class-based generalization in the overall model.", "labels": [], "entities": []}, {"text": "Again, the Brown model receives the smallest weight (line 7).", "labels": [], "entities": []}, {"text": "For both D and \u03b1, the lowest half/whole-context model values are those for the KN order-3 interpolations on lines 15-16: D = .5, \u03b1 = .4 (value of \u03b1 tied with KN order-2 interpolation online 9).", "labels": [], "entities": []}, {"text": "This maybe a reflection of the fact that class-based generalization is contributing more to better performance in order-2 models because order-2 models have a much lower baseline performance.", "labels": [], "entities": []}, {"text": "For order-2 the differences between HC and WC models are small (lines 3 vs. 4, 5 vs. 6, 8 vs. 9, 10 vs. 11).", "labels": [], "entities": []}, {"text": "For order-3, exemplar-theoretic half-context is clearly better than exemplar-theoretic whole-context (lines 13 vs. 14), although that difference is reduced in the two interpolated models P and P (KN-Whole) (lines 15 vs. 16).", "labels": [], "entities": []}, {"text": "On this evidence it would appear that the combination of left and right context information into a single context distribution (i.e., a whole-context approach) is redundant, if not harmful.", "labels": [], "entities": []}, {"text": "This is evidence for the half-context hypothesis put forward at the beginning of the article: Outward distributions, present in WC representations but absent in HC representations, do not seem to be helpful in class-based generalization, and are perhaps even harmful in order-3.", "labels": [], "entities": []}, {"text": "One reason why HC models perform better for order-3 than WC models could be that unigrams and bigrams are clustered together for the order-3 models.", "labels": [], "entities": []}, {"text": "Although it makes sense to treat, say, the right contexts of from Mark and Martin as similar, the distributional patterns of the two n-grams are very different if the left context is also taken into account, which is the case for WC models.", "labels": [], "entities": []}, {"text": "We could attempt to extend the exchange algorithm that has most often been used for class-based language modeling to half-context clustering.", "labels": [], "entities": [{"text": "class-based language modeling", "start_pos": 84, "end_pos": 113, "type": "TASK", "confidence": 0.6880864898363749}, {"text": "half-context clustering", "start_pos": 117, "end_pos": 140, "type": "TASK", "confidence": 0.6871860325336456}]}, {"text": "This is beyond the scope of this article, however.", "labels": [], "entities": []}, {"text": "Instead, we compare the order-2 WC experiments directly with the Brown classes.", "labels": [], "entities": []}, {"text": "We do this to make sure that our good results for HC models are not due to the fact that we use a weak WC baseline.", "labels": [], "entities": []}, {"text": "As we will argue now, our WC baseline is at least as good or even better than Brown clustering.", "labels": [], "entities": [{"text": "WC baseline", "start_pos": 26, "end_pos": 37, "type": "DATASET", "confidence": 0.6947035640478134}]}, {"text": "There are two set-ups that can be argued to be directly comparable to the Brown experiments reported here: either 512 left HC classes and 512 right HC classes (lines 2-4, 7-9, and 13-16); or 1,024 left HC classes and 1,024 right HC classes (lines 5-6 and 10-11).", "labels": [], "entities": []}, {"text": "In the Brown experiments (lines 2 and 7), Equation is used in the same way as in the HC/WC experiments except that class membership is based on the classes induced by srilm (corresponding to the experiments in).", "labels": [], "entities": [{"text": "Equation", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9994045495986938}, {"text": "HC/WC experiments", "start_pos": 85, "end_pos": 102, "type": "DATASET", "confidence": 0.7809039652347565}]}, {"text": "The comparisons on lines 2 vs. 4 and 6 and 7 vs. 9 and 11 clearly show that the quality of bisecting k-means whole-context clustering is comparable to, if not better than, Brown-type whole-context clustering.", "labels": [], "entities": []}, {"text": "That is, keeping the representation constant in both cases (i.e., whole-context) enables us to seethe algorithmic benefits of bisecting k-means as it appears to offer more useful clusters than those produced by the exchange algorithm.", "labels": [], "entities": []}, {"text": "Finally, although the exemplar-theoretic models are clearly outperformed by the P (KN) model (lines 1 vs. 3-6, 12 vs., it is important to note that the combination of the P (KN) model and the exemplar-theoretic models outperforms the stand-alone P (KN) model (lines 1 vs. 8-11, 12 vs. 15 and 16).", "labels": [], "entities": []}, {"text": "This is strong evidence that a combined classbased and history-length-interpolated model is superior to history-length interpolation by itself.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2  Perplexity results for interpolation of P (Brown) with a bigram model P", "labels": [], "entities": []}, {"text": " Table 3  Models used in our experiments.", "labels": [], "entities": []}, {"text": " Table 4  Perplexity results for Kneser-Ney, exemplar-theoretic Brown, exemplar-theoretic half-context,  exemplar-theoretic whole-context, and interpolations.", "labels": [], "entities": []}]}