{"title": [], "abstractContent": [{"text": "We describe the application of the graph-theoretic property known as treewidth to the problem of finding efficient parsing algorithms.", "labels": [], "entities": [{"text": "parsing algorithms", "start_pos": 115, "end_pos": 133, "type": "TASK", "confidence": 0.9067084789276123}]}, {"text": "This method, similar to the junction tree algorithm used in graphical models for machine learning, allows automatic discovery of efficient algorithms such as the O(n 4) algorithm for bilexical grammars of Eisner and Satta.", "labels": [], "entities": []}, {"text": "We examine the complexity of applying this method to parsing algorithms for general Linear Context-Free Rewriting Systems.", "labels": [], "entities": [{"text": "parsing", "start_pos": 53, "end_pos": 60, "type": "TASK", "confidence": 0.969851016998291}]}, {"text": "We show that any polynomial-time algorithm for this problem would imply an improved approximation algorithm for the well-studied treewidth problem on general graphs.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this article, we describe meta-algorithms for parsing: algorithms for finding the optimal parsing algorithm fora given grammar, with the constraint that rules in the grammar are considered independently of one another.", "labels": [], "entities": [{"text": "parsing", "start_pos": 49, "end_pos": 56, "type": "TASK", "confidence": 0.9644845128059387}]}, {"text": "In order to have a common representation for our algorithms to work with, we represent parsing algorithms as weighted deduction systems.", "labels": [], "entities": []}, {"text": "Weighted deduction systems consist of axioms and rules for building items or partial results.", "labels": [], "entities": []}, {"text": "Items are identified by square brackets, with their weights written to the left.", "labels": [], "entities": []}, {"text": "shows a rule for deducing anew item when parsing a context free grammar (CFG) with the rule S \u2192 AB.", "labels": [], "entities": [{"text": "parsing a context free grammar (CFG)", "start_pos": 41, "end_pos": 77, "type": "TASK", "confidence": 0.7336916327476501}]}, {"text": "The item below the line, called the consequent, can be derived if the two items above the line, called the antecedents, have been derived.", "labels": [], "entities": []}, {"text": "Items have types, corresponding to grammar nonterminals in this example, and variables, whose values range over positions in the string to be parsed.", "labels": [], "entities": []}, {"text": "We restrict ourselves to items containing position variables directly as arguments; no other functions or operations are allowed to apply to variables.", "labels": [], "entities": []}, {"text": "The consequent's weight is the product of the weights of the two antecedents and the rule weight w 0 . Implicit in the notation is the fact that we take the maximum weight overall derivations of the same item.", "labels": [], "entities": []}, {"text": "Thus, the weighted deduction system corresponds to the Viterbi or max-product algorithm for parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 92, "end_pos": 99, "type": "TASK", "confidence": 0.9617677927017212}]}, {"text": "Applications of the same weighted deduction system with other semirings are also possible).", "labels": [], "entities": []}, {"text": "The computational complexity of parsing depends on the total number of instantiations of variables in the system's deduction rules.", "labels": [], "entities": [{"text": "parsing", "start_pos": 32, "end_pos": 39, "type": "TASK", "confidence": 0.9779926538467407}]}, {"text": "If the total number of instantiations is M, parsing is O(M) if there are no cyclic dependencies among instantiations, or, equivalently, if all instantiations can be sorted topologically.", "labels": [], "entities": [{"text": "parsing", "start_pos": 44, "end_pos": 51, "type": "TASK", "confidence": 0.9589500427246094}, {"text": "O", "start_pos": 55, "end_pos": 56, "type": "METRIC", "confidence": 0.9713767170906067}]}, {"text": "In most parsing algorithms, variables range over positions in the input string.", "labels": [], "entities": []}, {"text": "In order to determine complexity in the length n of the input string, it is sufficient to count the number of unique position variables in each rule.", "labels": [], "entities": []}, {"text": "If all rules have at most k position variables, M = O(n k ), and parsing takes time O(n k ) in the length of the input string.", "labels": [], "entities": [{"text": "O", "start_pos": 52, "end_pos": 53, "type": "METRIC", "confidence": 0.9870721697807312}, {"text": "O", "start_pos": 84, "end_pos": 85, "type": "METRIC", "confidence": 0.9501110911369324}]}, {"text": "In the remainder of this article, we will explore methods for minimizing k, the largest number of position variables in any rule, among equivalent deduction systems.", "labels": [], "entities": []}, {"text": "These methods directly minimize the parsing complexity of the resulting deduction system.", "labels": [], "entities": []}, {"text": "Although we will assume no cyclic dependencies among rule instantiations for the majority of the article, we will discuss the cyclic casein Section 2.2.", "labels": [], "entities": []}, {"text": "It is often possible to improve the computational complexity of a deduction rule by decomposing the computation into two or more new rules, each having a smaller number of variables than the original rule.", "labels": [], "entities": []}, {"text": "We refer to this process as factorization.", "labels": [], "entities": []}, {"text": "One straightforward example of rule factorization is the binarization of a CFG, as shown in.", "labels": [], "entities": [{"text": "CFG", "start_pos": 75, "end_pos": 78, "type": "DATASET", "confidence": 0.882897138595581}]}, {"text": "Given a deduction rule fora CFG rule with r nonterminals on the righthand side, and a total of r + 1 variables, an equivalent set of rules can be produced, each with three variables, storing intermediate results that indicate that a substring of the original rule's righthand side has been recognized.", "labels": [], "entities": [{"text": "CFG", "start_pos": 28, "end_pos": 31, "type": "DATASET", "confidence": 0.886709988117218}]}, {"text": "This type of rule factorization produces an O(n 3 ) parser for any input CFG.", "labels": [], "entities": []}, {"text": "Another well-known instance of rule factorization is the hook trick of, which reduces the complexity of parsing for bilexicalized CFGs from O(n 5 ) to O(n 4 ).", "labels": [], "entities": [{"text": "hook trick", "start_pos": 57, "end_pos": 67, "type": "METRIC", "confidence": 0.9526324570178986}]}, {"text": "The basic rule for bilexicalized parsing combines two CFG constituents marked with lexical heads as shown in.", "labels": [], "entities": [{"text": "bilexicalized parsing", "start_pos": 19, "end_pos": 40, "type": "TASK", "confidence": 0.5831749141216278}]}, {"text": "Here items with type C indicate constituents, with [C, x 0 , h, x 1 ] indicating a constituent extending from position x 0 to position x 1 , headed by the word at position h.", "labels": [], "entities": []}, {"text": "The item is used to indicate the weight assigned by the grammar to a bilexical dependency headed by the word at a) Binarization of the CFG rule S \u2192 AB CD as rule factorization: The deduction rule above can be factored into the three equivalent rule below.", "labels": [], "entities": [{"text": "CFG", "start_pos": 135, "end_pos": 138, "type": "DATASET", "confidence": 0.8408532738685608}]}], "datasetContent": [], "tableCaptions": []}