{"title": [{"text": "ACL Lifetime Achievement Award The Brain as a Statistical Inference Engine-and You Can Too *", "labels": [], "entities": []}], "abstractContent": [{"text": "There are several possible templates for award talks.", "labels": [], "entities": [{"text": "award talks", "start_pos": 41, "end_pos": 52, "type": "TASK", "confidence": 0.9533416330814362}]}, {"text": "1 The most common is an intellectual history-how I came to make all these wonderful discoveries.", "labels": [], "entities": []}, {"text": "However, I am never completely happy with my work, as it seems a pale shadow of what I think it should have been.", "labels": [], "entities": []}, {"text": "Thus I am picking a different model-things we all know but do not say out loud because we have no evidence to support them; and besides, making such bold claims sounds pretentious.", "labels": [], "entities": []}, {"text": "Thus I do not expect to say anything too novel here.", "labels": [], "entities": []}, {"text": "I hope all my readers already know that the brain exploits statistics, and most of them suspect that we in statistical computational linguistics have something to say about how this works out in the case of language.", "labels": [], "entities": []}, {"text": "My goal is therefore not to say anything you do not believe, but to cause you to believe it more passionately.", "labels": [], "entities": []}, {"text": "1. Evidence for Statistics There is a growing body of evidence that our brains do their work via statistics.", "labels": [], "entities": []}, {"text": "Here I present two studies: one classic, one new.", "labels": [], "entities": []}, {"text": "1.1 Lexical Acquisition in Infants The classic work is that of Saffran and Newport (Saffran, Aslin, and Newport 1996) (S&N) on eight-month-olds' acquisition of lexical items.", "labels": [], "entities": [{"text": "Lexical Acquisition", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.8383429050445557}]}, {"text": "As is well known, speech is heard as a mostly unsegmented stream, thus raising the question of how children learn to segment it into words.", "labels": [], "entities": []}, {"text": "What S&N show is that infants use statistical regularities in the input.", "labels": [], "entities": []}, {"text": "When the stream is mid-word, there are fewer possible continuations than between words because of the uncertainty in the next word.", "labels": [], "entities": []}, {"text": "More technically, the per-phoneme entropy is higher between words than within them.", "labels": [], "entities": []}, {"text": "S&N show that eight-month-olds are capable of detecting such differences.", "labels": [], "entities": [{"text": "S&N", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8563926418622335}]}, {"text": "To do this S&N create an artificial \"language\" in which each \"word\" consists of three arbitrary phonemes, for example, bidukapupadotigolabubidaku..", "labels": [], "entities": []}, {"text": ".. So biduka and pupado are words, but the second two syllables of the first plus the first syllable of the second (dukapu) is not.", "labels": [], "entities": []}, {"text": "All the words are played with no emphasis on any syllable and * With apologies to.", "labels": [], "entities": []}, {"text": "1 I have written this paper in the first person to reflect its origins as the Lifetime Achievement Award talk at ACL-2011.", "labels": [], "entities": [{"text": "Lifetime Achievement Award talk at ACL-2011", "start_pos": 78, "end_pos": 121, "type": "DATASET", "confidence": 0.45107385019461316}]}, {"text": "It is not, however, based upon a transcript, since I can write better writing than I can speak.", "labels": [], "entities": []}, {"text": "I also have included a few things I did not have time to say in the original version.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}