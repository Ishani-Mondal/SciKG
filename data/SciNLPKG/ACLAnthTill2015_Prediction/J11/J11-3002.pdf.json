{"title": [{"text": "Controlling User Perceptions of Linguistic Style: Trainable Generation of Personality Traits", "labels": [], "entities": []}], "abstractContent": [{"text": "Recent work in natural language generation has begun to take linguistic variation into account, developing algorithms that are capable of modifying the system's linguistic style based either on the user's linguistic style or other factors, such as personality or politeness.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.6729954878489176}]}, {"text": "While stylistic control has traditionally relied on handcrafted rules, statistical methods are likely to be needed for generation systems to scale to the production of the large range of variation observed inhuman dialogues.", "labels": [], "entities": []}, {"text": "Previous work on statistical natural language generation (SNLG) has shown that the grammaticality and naturalness of generated utterances can be optimized from data; however these data-driven methods have not been shown to produce stylistic variation that is perceived by humans in the way that the system intended.", "labels": [], "entities": [{"text": "statistical natural language generation (SNLG)", "start_pos": 17, "end_pos": 63, "type": "TASK", "confidence": 0.7402068376541138}]}, {"text": "This paper describes PERSONAGE, a highly parameterizable language generator whose parameters are based on psychological findings about the linguistic reflexes of personality.", "labels": [], "entities": [{"text": "PERSONAGE", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9526773691177368}]}, {"text": "We present a novel SNLG method which uses parameter estimation models trained on personality-annotated data to predict the generation decisions required to convey any combination of scalar values along the five main dimensions of personality.", "labels": [], "entities": [{"text": "SNLG", "start_pos": 19, "end_pos": 23, "type": "TASK", "confidence": 0.9432318806648254}]}, {"text": "A human evaluation shows that parameter estimation models produce recognizable stylistic variation along multiple dimensions, on a continuous scale, and without the computational cost incurred by overgeneration techniques.", "labels": [], "entities": [{"text": "parameter estimation", "start_pos": 30, "end_pos": 50, "type": "TASK", "confidence": 0.7189905643463135}]}], "introductionContent": [{"text": "Although language can be seen as simply a method for exchanging information, it also has asocial function).", "labels": [], "entities": []}, {"text": "Speakers use linguistic cues to project social aspects of utterances, such as the speaker's personality, emotions, and social group, and hearers use these cues to infer properties about the speaker.", "labels": [], "entities": []}, {"text": "Although some cues appear to be produced through automatic cognitive processes, speakers may also overload their communicative intentions to try to satisfy multiple goals simultaneously, such as projecting a specific image to the hearer while communicating information and minimizing communicative effort.", "labels": [], "entities": []}, {"text": "The combination of these pragmatic effects results in the large range of linguistic variation observed between individual speakers.", "labels": [], "entities": []}, {"text": "Much of the research on generating utterances that manifest different linguistic styles has focused on text generation applications such as journalistic writing or instruction manuals.", "labels": [], "entities": [{"text": "text generation", "start_pos": 103, "end_pos": 118, "type": "TASK", "confidence": 0.7387522459030151}]}, {"text": "Recent research in language generation for dialogue applications has also begun to take linguistic variation into account, developing algorithms to modify the system's linguistic style based on either the user's linguistic style, or other factors such as the user's emotional state, her personality, or considerations of politeness strategies.", "labels": [], "entities": [{"text": "language generation", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.7797265648841858}]}, {"text": "There is growing evidence that dialogue systems such as intelligent tutoring systems are more effective if they can generate a range of different types of stylistic linguistic variation (Litman and Forbes-; Porayska-Pomsta and Mellish 2004;.", "labels": [], "entities": []}, {"text": "Most of this work uses either templates or handcrafted rules to generate utterances.", "labels": [], "entities": []}, {"text": "This guarantees high quality, natural outputs, which is useful for demonstrating the utility of stylistic variation.", "labels": [], "entities": []}, {"text": "Handcrafted approaches mean that utterances have to be constructed by hand for each new application, however, leading to problems of portability and scalability.", "labels": [], "entities": []}, {"text": "Statistical natural language generation (SNLG) has the potential to address such scalability issues by relying on annotated data rather than manual parameter tuning.", "labels": [], "entities": [{"text": "Statistical natural language generation (SNLG", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.7809755404790243}]}, {"text": "It also offers the promise of techniques for producing continuous stylistic variation over multiple stylistic factors by automatically learning a model of the relation between stylistic factors and properties (parameters) of generated utterances).", "labels": [], "entities": []}, {"text": "It is difficult to produce such continuous variation over multiple factors with a rule-based or template-based approach (but see.", "labels": [], "entities": []}, {"text": "Moreover, to date, no one has shown that humans correctly perceive the generated variation as the system intended, nor has anyone shown that an SNLG approach can produce outputs that are natural enough to be used in dialogue applications such as intelligent tutoring systems, interactive drama systems, and conversational agents, where some types of stylistic variation have already been shown to be useful.", "labels": [], "entities": []}, {"text": "In previous work, we argue that the Big Five model of personality provides a useful framework for modeling some types of stylistic linguistic variation.", "labels": [], "entities": []}, {"text": "This model of human personality has become widely accepted in psychology over the last 50 years.", "labels": [], "entities": []}, {"text": "tabulates each Big Five trait along with some of the important trait adjectives associated with the extremes of each trait.", "labels": [], "entities": []}, {"text": "We believe that these trait adjectives provide an intuitive, meaningful definition of linguistic style.", "labels": [], "entities": []}, {"text": "In previous work we describe a rule-based version of PERSONAGE, which here we will refer to as PERSONAGE-RB (.", "labels": [], "entities": [{"text": "PERSONAGE", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.5433143377304077}]}, {"text": "In PERSONAGE-RB, generation parameters are implemented, and their values are set based on correlations between linguistic cues and the Big Five traits that have been systematically documented in the psychology literature).", "labels": [], "entities": []}, {"text": "For example, parameters for the extraversion utterances; (b) learning utterance reranking models from user feedback rather than corpora; and (c) learning generation parameters directly from data.", "labels": [], "entities": []}, {"text": "The first approach has used SLMs to rerank a large set of candidate utterances, and focused on grammaticality and naturalness).", "labels": [], "entities": []}, {"text": "The seminal work of in this area showed that high quality paraphrases can be generated from an underspecified representation of meaning, by first applying a very underconstrained, rule-based overgeneration phase, whose outputs are then ranked by an SLM scoring phase.", "labels": [], "entities": []}, {"text": "The SLM scoring gives a low score (rank) to any ungrammatical output produced by the rule-based generator.", "labels": [], "entities": []}, {"text": "We will refer to this as the overgenerate and scoring (OS) approach.", "labels": [], "entities": []}, {"text": "Ina novel twist, applied this method to the generation of dialogues in which conversational agents with different personalities discuss movies.", "labels": [], "entities": []}, {"text": "The SLM ranking model blends SLMs from blogs annotated with Big Five personality traits with SLMs from Switchboard, a much larger conversational dialogue corpus.", "labels": [], "entities": []}, {"text": "Their CRAG-2 generator discretizes the blog personality ratings into three groups (low, medium, and high), and models personality with three distinct SLM models for each trait.", "labels": [], "entities": []}, {"text": "Each model estimates the likelihood of the utterance given the personality type.", "labels": [], "entities": []}, {"text": "A cache model based on recently used linguistic forms can also be combined, in order to model recency effects and alignment.", "labels": [], "entities": []}, {"text": "This approach was integrated into a demonstrator, but it does not generate continuous variation (discretization of personality ratings), and to our knowledge it has never been evaluated to test whether the variation produced is perceivable by users.", "labels": [], "entities": []}, {"text": "A second approach to SNLG is a variant of the OS technique that trains the scoring phase to replicate human judgments rather than relying on the probabilities or frequencies of a SLM.", "labels": [], "entities": [{"text": "SNLG", "start_pos": 21, "end_pos": 25, "type": "TASK", "confidence": 0.9769923686981201}, {"text": "replicate human judgments", "start_pos": 92, "end_pos": 117, "type": "TASK", "confidence": 0.8374858697255453}]}, {"text": "This approach typically uses higher-level syntactic, semantic, and discourse features rather than only n-grams, with typical results demonstrating that the performance of the scoring models approaches the gold-standard human ranking with a relatively small training set).", "labels": [], "entities": []}, {"text": "An advantage of this approach is that human judgments can be based on any aspect of the output, such as stylistic differences in politeness or personality.", "labels": [], "entities": []}, {"text": "showed that this technique can be used to model individual preferences in rhetorical structure, syntactic form, and content ordering.", "labels": [], "entities": [{"text": "rhetorical structure", "start_pos": 74, "end_pos": 94, "type": "TASK", "confidence": 0.9398183524608612}]}, {"text": "In previous work, we also applied this method to scoring randomly produced outputs of PERSONAGE (Mairesse 2008).", "labels": [], "entities": [{"text": "PERSONAGE", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.5900924205780029}]}, {"text": "The resulting statistical generator is referred to as PERSONAGE-OS.", "labels": [], "entities": [{"text": "PERSONAGE-OS", "start_pos": 54, "end_pos": 66, "type": "METRIC", "confidence": 0.6013294458389282}]}, {"text": "We randomly varied PERSONAGE's non-deterministic decisions points to generate a large number of paraphrases.", "labels": [], "entities": []}, {"text": "We then computed post hoc features consisting of the actual generation decisions, surface word n-grams, and contentanalysis features from the Linguistic Inquiry and Word Count (LIWC) tool and the MRC psycholinguistic database.", "labels": [], "entities": [{"text": "MRC psycholinguistic database", "start_pos": 196, "end_pos": 225, "type": "DATASET", "confidence": 0.7120226820309957}]}, {"text": "Example content-analysis features include the ratio of words related to positive emotions (e.g., good), social interactions (e.g., pal), or the average frequency of use of each word.", "labels": [], "entities": []}, {"text": "Scoring models trained on personality ratings of random utterances (in-domain data) outperformed the mean value baseline for all Big Five traits, with the best results for agreeableness, extraversion, and emotional stability.", "labels": [], "entities": []}, {"text": "The models for those traits predict the ratings of unseen utterances with correlations of r = .52, r = .37, and r = .29, respectively.", "labels": [], "entities": []}, {"text": "We also trained models on out-of-domain data, that is, 96 personality-annotated conversation extracts (without any generation decision features).", "labels": [], "entities": []}, {"text": "Results show that the out-of-domain models perform worse for all traits, only outperforming the baseline for agreeableness and conscientiousness.", "labels": [], "entities": []}, {"text": "We also explored several hybrid methods for training that mix and blend data from different sources.", "labels": [], "entities": []}, {"text": "Inspired by recent work on domain adaptation, we tested whether the performance of the out-of-domain models can be improved when training includes a small amount of data from the target domain, by applying the method of.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.7755827605724335}]}, {"text": "Whereas adding out-of-domain data improved performance for some traits, we find that adding a single domain feature performs as well as Daume's method.", "labels": [], "entities": []}, {"text": "The results showed that mixing randomly generated in-domain utterances with rule-based in-domain utterances improves performance; the rule-based utterances provide away to incorporate knowledge from the personality psychology literature into an SNLG approach.", "labels": [], "entities": []}, {"text": "Thus, personality scoring models can be effective, although the computational cost of the OS approach remains a major drawback.", "labels": [], "entities": [{"text": "personality scoring", "start_pos": 6, "end_pos": 25, "type": "TASK", "confidence": 0.8222408294677734}]}, {"text": "The third SNLG approach estimates the generation parameters directly from data, without any overgeneration phase.", "labels": [], "entities": [{"text": "SNLG", "start_pos": 10, "end_pos": 14, "type": "TASK", "confidence": 0.8974742889404297}]}, {"text": "If the language generator is constrained to be a generative SLM, the parameters can then be learned through standard maximum-likelihood estimation.", "labels": [], "entities": []}, {"text": "Whereas n-gram SLMs can only model local linguistic phenomena, Belz showed that a context-free grammar (PCFG) can successfully model individual differences in the production of weather reports.", "labels": [], "entities": []}, {"text": "This method provides a principled way to produce utterances matching the linguistic style of a specific corpus (e.g., of an individual author) without any overgeneration phase.", "labels": [], "entities": []}, {"text": "However, standard PCFG generation methods require a treebank-annotated corpus, and they cannot model context-dependent generation decisions, such as the control of sentence length or the generation of referring expressions.", "labels": [], "entities": [{"text": "PCFG generation", "start_pos": 18, "end_pos": 33, "type": "TASK", "confidence": 0.7270757406949997}]}, {"text": "Paiva and Evans (2005) adopt a more general framework by learning a regression model mapping generation decisions to stylistic dimensions extracted from a corpus, independently of the language generation mechanism.", "labels": [], "entities": []}, {"text": "Factors are identified by applying factor analysis to a corpus exhibiting stylistic variation, and expressed as a linear combination of linguistic features.", "labels": [], "entities": []}, {"text": "Textual outputs are generated with a rule-based generator in the target domain that is allowed to randomly vary the generation parameters, while logging the parameter settings corresponding to each output.", "labels": [], "entities": []}, {"text": "Then the same factors found in the original corpus are measured in the random outputs, and linear regression is applied to learn which generation parameters predict the factor measurements.", "labels": [], "entities": []}, {"text": "The generation parameters can then be manipulated to hit multiple stylistic targets on a continuous scale (because factors are measured continuously) by searching for the parameter setting yielding the target stylistic scores according to the linear models.", "labels": [], "entities": []}, {"text": "The generator of Paiva and Evans, trained in this way, can reproduce intended factor levels across several factors, such as sentence length and type of referring expression, thus modeling the stylistic variation as measured in the original corpus.", "labels": [], "entities": []}, {"text": "Again, it has not been shown that humans perceive the stylistic differences that this approach produces.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section first details some of the parameter estimation models trained on the data collected in Section 3.", "labels": [], "entities": []}, {"text": "The models' predictive power is then evaluated by doing a 10-fold cross-validation in Section 4.2.", "labels": [], "entities": []}, {"text": "Finally, Section 4.3 evaluates human perceptions of utterances generated using the models.", "labels": [], "entities": []}, {"text": "Before discussing our quantitative results, we use, and 8 to illustrate how the learned models predict generation parameters from input personality scores.", "labels": [], "entities": []}, {"text": "Note that sometimes the best performing model is non-linear.", "labels": [], "entities": []}, {"text": "For example, given input trait values, the AdaBoost model in outputs the class yielding the largest sum of weights for the rules returning that class.", "labels": [], "entities": []}, {"text": "The first rule of the EXCLAMATION model in shows that an extraversion score above 6.42 out of 7 would increase the weight of the enabled class by 1.81.", "labels": [], "entities": [{"text": "EXCLAMATION", "start_pos": 22, "end_pos": 33, "type": "METRIC", "confidence": 0.8451794385910034}]}, {"text": "The fifth rule indicates that a target agreeableness above 5.13 would further increase the weight by .42.", "labels": [], "entities": [{"text": "weight", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9695876836776733}]}, {"text": "also illustrates how personality traits that do not have an effect on the parameter are removed, i.e., extraversion and agreeableness are the traits that affect the use of exclamation marks.", "labels": [], "entities": []}, {"text": "The STUTTERING model tree in lets us calculate that a low emotional stability (1.0) together with a neutral conscientiousness (4.0) and openness to experience (4.0) yield a parameter value of .62 (see bottom-left linear model), whereas a neutral emotional stability decreases the value down to .17.", "labels": [], "entities": []}, {"text": "The full parameter range obtained when varying both emotional stability and conscientiousness is illustrated in, which shows that the .5 cut-off  The evaluation presented in Section 4.2 measures how well the PE models predict the parameters, using parameter settings in the random sample and expert judge ratings as the predictors.", "labels": [], "entities": []}, {"text": "We relied on a small number of expert judges to minimize rating inconsistencies and facilitate the learning process.", "labels": [], "entities": []}, {"text": "In order to test whether the PE method produces high quality outputs manifesting personality, we ran an experiment with 24 native English speakers (12 male and 12 female graduate students from a range of disciplines from both the U.K. and the U.S.).", "labels": [], "entities": [{"text": "PE", "start_pos": 29, "end_pos": 31, "type": "TASK", "confidence": 0.9670971035957336}]}, {"text": "We produced a set of 50 utterances for this experiment using the best performing models for each generation parameter shown in.", "labels": [], "entities": []}, {"text": "Given this model, we generate 5 utterances for each of 10 input communicative goals.", "labels": [], "entities": []}, {"text": "Each utterance targets an extreme value for two traits (either 1 or 7 out of 7) and neutral values for the remaining three traits (4 out of 7).", "labels": [], "entities": []}, {"text": "The goal is for each utterance to project multiple traits on a continuous scale.", "labels": [], "entities": []}, {"text": "Here, we test whether PE models can convey personality in extreme regions of the Big Five space.", "labels": [], "entities": [{"text": "PE", "start_pos": 22, "end_pos": 24, "type": "TASK", "confidence": 0.9617452025413513}, {"text": "Big Five space", "start_pos": 81, "end_pos": 95, "type": "DATASET", "confidence": 0.8647704323132833}]}, {"text": "In order to generate a range of alternatives for each input communicative goal, all target scores are randomized around their initial value according to a normal probability distribution with a standard deviation of 10% of the full scale (see.", "labels": [], "entities": []}, {"text": "All 50 utterances were evaluated by the 24 naive subjects using the TIPI in (Gosling, Rentfrow, and.", "labels": [], "entities": [{"text": "TIPI", "start_pos": 68, "end_pos": 72, "type": "METRIC", "confidence": 0.7534117102622986}]}, {"text": "As in the training data collection (Section 3.1), the subjects rated one set of five utterances at a time, one for each communicative goal.", "labels": [], "entities": [{"text": "training data collection", "start_pos": 10, "end_pos": 34, "type": "DATASET", "confidence": 0.763582726319631}]}, {"text": "The communicative goals and the utterances were presented in random order.", "labels": [], "entities": []}, {"text": "To limit the experiment's duration, only the two traits with extreme target values are evaluated for each utterance.", "labels": [], "entities": [{"text": "duration", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9651492238044739}]}, {"text": "As a result, 20 utterances are evaluated for each trait, 10 of which were generated to convey the low end of that trait, and 10 of which target the high end of that trait.", "labels": [], "entities": []}, {"text": "Each utterance was also evaluated for its naturalness as before.", "labels": [], "entities": []}, {"text": "Subjects thus answered 5 questions for 50 utterances, two from the TIPI for each extreme trait and one about naturalness (250 judgments in total per subject).", "labels": [], "entities": [{"text": "TIPI", "start_pos": 67, "end_pos": 71, "type": "DATASET", "confidence": 0.685370922088623}]}, {"text": "Subjects were not told that the utterances were intended to manifest extreme trait values.", "labels": [], "entities": []}, {"text": "shows several sample outputs and the mean personality ratings from the naive subjects for two communicative goals.", "labels": [], "entities": []}, {"text": "For example, utterance 1.a projects a high extraversion through the insertion of an exclamation mark based on the model in, whereas utterance 2.a conveys introversion by beginning with the filled pause err.", "labels": [], "entities": []}, {"text": "The same utterance also projects a low agreeableness by focusing on negative propositions, through a low CONTENT POLARITY parameter value produced by the model in.", "labels": [], "entities": [{"text": "CONTENT POLARITY parameter value", "start_pos": 105, "end_pos": 137, "type": "METRIC", "confidence": 0.8670072555541992}]}], "tableCaptions": [{"text": " Table 3  Example outputs of PERSONAGE with random parameter settings (random utterances), and  scalar personality trait values after collection of TIPI judgments. Extra = extraversion, ems =  emotional stability, agree = agreeableness, consc = conscientiousness, and open = openness  to experience.", "labels": [], "entities": [{"text": "open", "start_pos": 268, "end_pos": 272, "type": "METRIC", "confidence": 0.9819688200950623}]}, {"text": " Table 6  Pearson's correlation coefficient between parameter model predictions and continuous  parameter values, for different regression models. Parameters that do not correlate with any  trait are omitted. Results are averaged over a 10-fold cross-validation, and the best result for  each parameter is in bold.", "labels": [], "entities": []}, {"text": " Table 7  F-measure of the enabled class for classification models of binary parameters. Parameters that do  not correlate with any trait are omitted. Results are averaged over a 10-fold cross-validation, and  the best result for each parameter is in bold.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9922229647636414}]}, {"text": " Table 8  Example outputs from PERSONAGE-PE for a comparison (#1) and a recommendation (#2), with  the average judges' personality (Rating) and naturalness (Nat) scores. Ratings are on a scale from  1 to 7, with 1 = very low (e.g., introvert) and 7 = very high (e.g., extravert).", "labels": [], "entities": [{"text": "naturalness (Nat)", "start_pos": 144, "end_pos": 161, "type": "METRIC", "confidence": 0.6712802946567535}]}]}