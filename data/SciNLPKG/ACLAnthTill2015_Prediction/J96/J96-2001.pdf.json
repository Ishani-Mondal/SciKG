{"title": [{"text": "Estimating Lexical Priors for Low-Frequency Morphologically Ambiguous Forms", "labels": [], "entities": [{"text": "Estimating Lexical Priors", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.827042818069458}]}], "abstractContent": [{"text": "Given a form that is previously unseen in a sufficiently large training corpus, and that is morphologically n-ways ambiguous (serves n different lexical functions) what is the best estimator for the lexical prior probabilities for the various functions of the form?", "labels": [], "entities": []}, {"text": "We argue that the best estimator is provided by computing the relative frequencies of the various functions among the hapax legomena-the forms that occur exactly once in a corpus; in particular, a hapax-based estimator is better than one based on the proportion of the various functions among words of all frequency ranges.", "labels": [], "entities": []}, {"text": "As we shall argue, this is because when one computes an overall measure, one is including high-frequency words, and high-frequency words tend to have idiosyncratic properties that are not at all representative of the much larger mass of(productively formed) low-frequency words.", "labels": [], "entities": []}, {"text": "This result has potential importance for various kinds of applications requiring lexical disambiguation, including, in particular, stochastic taggers.", "labels": [], "entities": []}, {"text": "This is especially true when some initial hand-tagging of a corpus is required:for predicting lexical priors for very low-frequer~cy morphologically ambiguous types (most of which would not occur in any given corpus), one should concentrate on tagging a good representative sample of the hapax legomena, rather than extensively tagging words of all frequency ranges.", "labels": [], "entities": [{"text": "predicting lexical priors", "start_pos": 83, "end_pos": 108, "type": "TASK", "confidence": 0.8523092667261759}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 2  Cross-validation statistics for English past participles versus simple past tense verbs.", "labels": [], "entities": []}, {"text": " Table 3  Cross-validation statistics for Dutch verbs in -en versus plural nouns in -en.", "labels": [], "entities": []}, {"text": " Table 4  Results of tenfold cross-validation for Dutch disyllabic -er words. N and N1 are the number of  tokens and number of hapax legomena in the Uit den Boogaart corpus for simplex and  complex adjectives and nouns, and proper names. OMLE and HMLE are, respectively, the  overall and hapax-based MLEs based on N and N1. For each category, the columns headed by  X2(OMLE) and X2(HMLE) list the summed contribution to the X2-measures over ten  cross-validation runs for the overall and hapax-based estimates.", "labels": [], "entities": [{"text": "Uit den Boogaart corpus", "start_pos": 149, "end_pos": 172, "type": "DATASET", "confidence": 0.6049152240157127}]}]}