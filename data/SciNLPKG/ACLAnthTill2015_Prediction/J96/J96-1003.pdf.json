{"title": [{"text": "Error-tolerant Finite-state Recognition with Applications to Morphological Analysis and Spelling Correction", "labels": [], "entities": [{"text": "Finite-state Recognition", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.5567239820957184}, {"text": "Morphological Analysis", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.7759149372577667}, {"text": "Spelling Correction", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.9125013053417206}]}], "abstractContent": [{"text": "This paper presents the notion of error-tolerant recognition with finite-state recognizers along with results from some applications.", "labels": [], "entities": [{"text": "error-tolerant recognition", "start_pos": 34, "end_pos": 60, "type": "TASK", "confidence": 0.6118540316820145}]}, {"text": "Error-tolerant recognition enables the recognition of strings that deviate mildly from any string in the regular set recognized by the underlying finite-state recognizer.", "labels": [], "entities": [{"text": "Error-tolerant recognition", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6207520514726639}]}, {"text": "Such recognition has applications to error-tolerant morphological processing, spelling correction, and approximate string matching in information retrieval.", "labels": [], "entities": [{"text": "error-tolerant morphological processing", "start_pos": 37, "end_pos": 76, "type": "TASK", "confidence": 0.6314643025398254}, {"text": "spelling correction", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.9584341645240784}, {"text": "approximate string matching", "start_pos": 103, "end_pos": 130, "type": "TASK", "confidence": 0.6883031924565634}]}, {"text": "After a description of the concepts and algorithms involved, we give examples from two applications: in the context of morphological analysis, error-tolerant recognition allows misspelled input word forms to be corrected and morphologically analyzed concurrently.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 119, "end_pos": 141, "type": "TASK", "confidence": 0.7566583752632141}]}, {"text": "We present an application of this to error-tolerant analysis of the agglutinative morphology of Turkish words.", "labels": [], "entities": []}, {"text": "The algorithm can be applied to morphological analysis of any language whose morphology has been fully captured by a single (and possibly very large) finite-state transducer, regardless of the word formation processes and morphographemic phenomena involved.", "labels": [], "entities": [{"text": "word formation", "start_pos": 193, "end_pos": 207, "type": "TASK", "confidence": 0.7092092931270599}]}, {"text": "In the context of spelling correction, error-tolerant recognition can be used to enumerate candidate correct forms from a given misspelled string within a certain edit distance.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.9390934407711029}]}, {"text": "Error-tolerant recognition can be applied to spelling correction for any language, if (a) it has a word list comprising all inflected forms, or (b) its morphology has been fully described by a finite-state transducer.", "labels": [], "entities": [{"text": "Error-tolerant recognition", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7469349503517151}, {"text": "spelling correction", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.9212393164634705}]}, {"text": "We present experimental results for spelling correction fora number of languages.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.9593101739883423}]}, {"text": "These results indicate that such recognition works very efficiently for candidate generation in spelling correction for many European languages (English, Dutch, French, German, and Italian, among others) with very large word lists of root and inflected forms (some containing well over 200,000 forms), generating all candidate solutions within 10 to 45 milliseconds (with an edit distance of 1) on a SPARCStation 10/41.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 96, "end_pos": 115, "type": "TASK", "confidence": 0.8601763546466827}, {"text": "SPARCStation 10/41", "start_pos": 400, "end_pos": 418, "type": "DATASET", "confidence": 0.885955810546875}]}, {"text": "For spelling correction in Turkish, error-tolerant recognition operating with a (circular) recognizer of Turkish words (with about 29,000 states and 119,000 transitions) can generate all candidate words in less than 20 milliseconds, with an edit distance of 1.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.9394094347953796}, {"text": "error-tolerant recognition", "start_pos": 36, "end_pos": 62, "type": "TASK", "confidence": 0.6790110915899277}]}], "introductionContent": [{"text": "Error-tolerant finite-state recognition enables the recognition of strings that deviate mildly from any string in the regular set recognized by the underlying finite-state recognizer.", "labels": [], "entities": [{"text": "finite-state recognition", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.7166208624839783}]}, {"text": "For example, suppose we have a recognizer for the regular set over {a, b} described by the regular expression (aba + bab)*, and we would like to recognize inputs that maybe slightly corrupted, for example, abaaaba maybe matched to abaaba (correcting fora spurious a), or babbb maybe matched to babbab (correcting fora deletion), or ababba maybe matched to either abaaba (correcting ab to an a) or to ababab (correcting the reversal of the last two symbols).", "labels": [], "entities": []}, {"text": "Error-tolerant recognition can be used in many applications that are based on finite-state recognition, such as morphological analysis, spelling correction, or even tagging with finite-state models.", "labels": [], "entities": [{"text": "Error-tolerant recognition", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7688829600811005}, {"text": "morphological analysis", "start_pos": 112, "end_pos": 134, "type": "TASK", "confidence": 0.7526946067810059}, {"text": "spelling correction", "start_pos": 136, "end_pos": 155, "type": "TASK", "confidence": 0.9638294875621796}]}, {"text": "The approach presented in this paper uses the finite-state recognizer built to recognize the regular set, but relies on a very efficiently controlled recognition algorithm based on depth-first searching of the state graph of the recognizer.", "labels": [], "entities": []}, {"text": "In morphological analysis, misspelled input word forms can be corrected and morphologically analyzed concurrently.", "labels": [], "entities": []}, {"text": "In the context of spelling correction, error-tolerant recognition can universally be applied to the generation of candidate correct forms for any language, provided it has a word list comprising all inflected forms, or its morphology has been fully described by automata such as two-level finite-state transducers.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.9315860867500305}, {"text": "error-tolerant recognition", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.7148852050304413}]}, {"text": "The algorithm for error-tolerant recognition is very fast and applicable to languages that have productive compounding, or agglutination, or both, as word formation processes.", "labels": [], "entities": [{"text": "error-tolerant recognition", "start_pos": 18, "end_pos": 44, "type": "TASK", "confidence": 0.6827510744333267}, {"text": "word formation", "start_pos": 150, "end_pos": 164, "type": "TASK", "confidence": 0.72905333340168}]}, {"text": "There have been a number of approaches to error-tolerant searching.", "labels": [], "entities": [{"text": "error-tolerant searching", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.6723329722881317}]}, {"text": "Wu and Manber (1991) describe an algorithm for fast searching, allowing for errors.", "labels": [], "entities": []}, {"text": "This algorithm (called agrep) relies on a very efficient pattern matching scheme whose steps can be implemented with arithmetic and logical operations.", "labels": [], "entities": []}, {"text": "It is most efficient when the size of the pattern is limited to 32 to 64 symbols, though it allows for an arbitrary number of insertions, deletions, and substitutions.", "labels": [], "entities": []}, {"text": "It is particularly suitable when the pattern is small and the sequence to be searched is large.", "labels": [], "entities": []}, {"text": "describe algorithms for approximate matching to regular expressions with arbitrary costs, but like the algorithm described in Wu and Manber, these are best suited to applications where the pattern or the regular expression is small and the sequence is large.", "labels": [], "entities": []}, {"text": "present a method for imperfect string recognition using fuzzy logic.", "labels": [], "entities": [{"text": "imperfect string recognition", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.6458940108617147}]}, {"text": "Their method is for context-free grammars (hence, it can be applied to finite state recognition as well), but it relies on introducing new productions to allow for errors; this may increase the size of the grammar substantially.", "labels": [], "entities": [{"text": "finite state recognition", "start_pos": 71, "end_pos": 95, "type": "TASK", "confidence": 0.6999238133430481}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1  Statistics about the word lists used.", "labels": [], "entities": []}, {"text": " Table 2  Correction Statistics for Threshold 1.", "labels": [], "entities": [{"text": "Threshold", "start_pos": 36, "end_pos": 45, "type": "TASK", "confidence": 0.6906459927558899}]}, {"text": " Table 3  Correction Statistics for Threshold 2.", "labels": [], "entities": [{"text": "Threshold", "start_pos": 36, "end_pos": 45, "type": "TASK", "confidence": 0.6847553253173828}]}, {"text": " Table 4  Correction Statistics for Threshold 3.", "labels": [], "entities": [{"text": "Threshold", "start_pos": 36, "end_pos": 45, "type": "TASK", "confidence": 0.7072364091873169}]}]}