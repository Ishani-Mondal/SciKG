{"title": [{"text": "A Statistically Emergent Approach for Language Processing: Application to Modeling Context Effects in Ambiguous Chinese Word Boundary Perception", "labels": [], "entities": [{"text": "Modeling Context Effects in Ambiguous Chinese Word Boundary Perception", "start_pos": 74, "end_pos": 144, "type": "TASK", "confidence": 0.664764834774865}]}], "abstractContent": [{"text": "This paper proposes that the process of language understanding can be modeled as a collective phenomenon that emerges from a myriad of microscopic and diverse activities.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.7374308109283447}]}, {"text": "The process is analogous to the crystallization process in chemistry.", "labels": [], "entities": []}, {"text": "The essential features of this model are: asynchronous parallelism; temperature-controlled randomness; and statistically emergent active symbols.", "labels": [], "entities": []}, {"text": "A computer program that tests this model on the task of capturing the effect of context on the perception of ambiguous word boundaries in Chinese sentences is presented.", "labels": [], "entities": []}, {"text": "The program adopts a holistic approach in which word identification forms an integral component of sentence analysis.", "labels": [], "entities": [{"text": "word identification", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.7447479069232941}, {"text": "sentence analysis", "start_pos": 99, "end_pos": 116, "type": "TASK", "confidence": 0.718168318271637}]}, {"text": "Various types of knowledge, from statistics to linguistics, are seamlessly integrated for the tasks of word boundary disambiguation as well as sentential analysis.", "labels": [], "entities": [{"text": "word boundary disambiguation", "start_pos": 103, "end_pos": 131, "type": "TASK", "confidence": 0.6779313882191976}, {"text": "sentential analysis", "start_pos": 143, "end_pos": 162, "type": "TASK", "confidence": 0.7676970064640045}]}, {"text": "Our experimental results showed that the model is able to address the word boundary ambiguity problems effectively.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper suggests that the language understanding process can be effectively modeled as the statistical outcome of a large number of independent activities occurring in parallel.", "labels": [], "entities": [{"text": "language understanding process", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.8097387949625651}]}, {"text": "There is no global controller deciding which processes to run next.", "labels": [], "entities": []}, {"text": "All processing is done locally by many simple, independent agents that make their decisions stochastically.", "labels": [], "entities": []}, {"text": "The system is self-organizing, with coherent behavior being a statistically emergent property of the system as a whole.", "labels": [], "entities": []}, {"text": "The model, in a nutshell, simulates language understanding as a crystallization process.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.7260658442974091}]}, {"text": "This process consists of a series of hierarchical, structure-building activities in which high-level linguistic structures are formed from their constituents and get properly hooked up to each other as the process converges.", "labels": [], "entities": []}, {"text": "The essential features of the model are: \u2022 The process of sentence analysis is a series of computational activities that determine how various constituents in a sentence can be meaningfully related.", "labels": [], "entities": [{"text": "sentence analysis", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.7326941043138504}]}, {"text": "\u2022 All computational activities are carried out by a large number of procedures known as codelets.", "labels": [], "entities": []}, {"text": "\u2022 A linguistic structure is not built by a single codelet.", "labels": [], "entities": []}, {"text": "Rather, it is constructed by a sequence of codelets.", "labels": [], "entities": []}, {"text": "The execution of this sequence of codelets is interleaved with other codelets that are responsible for building other structures.", "labels": [], "entities": []}, {"text": "\u2022 The order by which structures are built is not explicitly programmed, but is an emergent outcome of chains of codelets working in an asynchronous parallel mode.", "labels": [], "entities": []}, {"text": "\u2022 Computational activities area combination of top-down and bottom-up activities.", "labels": [], "entities": []}, {"text": "\u2022 Computational activities are indirectly guided by a semantic network of linguistic concepts, which ensures that these activities do not operate independently of the system's representation of the context of a sentence.", "labels": [], "entities": []}, {"text": "\u2022 Decision making is stochastic, with the amount of randomness being controlled by a parameter known as the computational temperature.", "labels": [], "entities": [{"text": "Decision making", "start_pos": 2, "end_pos": 17, "type": "TASK", "confidence": 0.8947450816631317}]}, {"text": "We have applied our model to the task of capturing the effect of context on the perception of ambiguous word boundaries in Chinese sentences.", "labels": [], "entities": []}, {"text": "Our ap--proach differs from existing work on Chinese word segmentation primarily in that our system performs sentence interpretation, in addition to word boundary identification.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 45, "end_pos": 70, "type": "TASK", "confidence": 0.6709739863872528}, {"text": "sentence interpretation", "start_pos": 109, "end_pos": 132, "type": "TASK", "confidence": 0.7213496565818787}, {"text": "word boundary identification", "start_pos": 149, "end_pos": 177, "type": "TASK", "confidence": 0.6765468517939249}]}, {"text": "Our system figures out where the word boundaries of a sentence are by determining how various constituents in a sentence can be meaningfully related.", "labels": [], "entities": []}, {"text": "The relations the system builds represent its interpretation of the sentence.", "labels": [], "entities": []}, {"text": "In the initial stage of a run, the system constructs relations between characters of a sentence.", "labels": [], "entities": []}, {"text": "Through a spreading activation mechanism, the system gradually shifts to the construction of words and of relations between words.", "labels": [], "entities": []}, {"text": "Later, the system progresses to identifying and constructing chunks (in other words, phrases), and to establishing connections between chunks.", "labels": [], "entities": []}, {"text": "Note that there is no top-level executive that decides the order of these activities.", "labels": [], "entities": []}, {"text": "At any given time, the system stochastically selects one action to execute.", "labels": [], "entities": []}, {"text": "Therefore, efforts toward building different structures are interleaved, sometimes cooperating and sometimes competing.", "labels": [], "entities": []}, {"text": "The system's high-level behavior, therefore, arises from its low-level stochastic actions.", "labels": [], "entities": []}, {"text": "We will give a detailed description of this application in this paper.", "labels": [], "entities": []}, {"text": "In Section 2, we introduce the problem of ambiguous Chinese word boundary perception, and follow, in Section 3, with a summary of the current practices in Chinese word identification.", "labels": [], "entities": [{"text": "ambiguous Chinese word boundary perception", "start_pos": 42, "end_pos": 84, "type": "TASK", "confidence": 0.6235273659229279}, {"text": "Chinese word identification", "start_pos": 155, "end_pos": 182, "type": "TASK", "confidence": 0.6252345939477285}]}, {"text": "We describe our model in Section 4, showing a sample run of our program in Section 5 to illustrate the behavior of the model.", "labels": [], "entities": []}, {"text": "Finally, some discussions of the model are covered in Section 6.", "labels": [], "entities": []}, {"text": "In Section 7, we compare our model with others, and explore areas for future research in Section 8.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2  Initial state of the coderack.", "labels": [], "entities": []}]}