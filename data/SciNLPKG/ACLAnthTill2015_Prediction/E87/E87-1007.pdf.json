{"title": [{"text": "HOW TO DETECT GRAMMATICAL ERRORS IN A TEXT WITHOUT PARSING IT Checking Grammar in Texts", "labels": [], "entities": [{"text": "TO DETECT GRAMMATICAL ERRORS IN A TEXT WITHOUT PARSING IT", "start_pos": 4, "end_pos": 61, "type": "METRIC", "confidence": 0.7629973709583282}, {"text": "Checking Grammar in Texts", "start_pos": 62, "end_pos": 87, "type": "TASK", "confidence": 0.8435734510421753}]}], "abstractContent": [{"text": "The Constituent Likelihood Automatic Word-tagging System (CLAWS) was originally designed for the low-level grammatical analysis of the million-word LOB Corpus of English text samples.", "labels": [], "entities": [{"text": "LOB Corpus of English text samples", "start_pos": 148, "end_pos": 182, "type": "DATASET", "confidence": 0.684920867284139}]}, {"text": "CLAWS does not attempt a full parse, but uses a firat-order Markov model of language to assign word-class labels to words.", "labels": [], "entities": [{"text": "CLAWS", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9023160934448242}]}, {"text": "CLAWS can be modified to detect grammatical errors, essentially by flagging unlikely word-class transitions in the input text.", "labels": [], "entities": []}, {"text": "This may seem to bean intuitively implausible and theoretically inadequate model of natural language syntax, but nevertheless it can successfully pinpoint most grammatical errors in a text.", "labels": [], "entities": []}, {"text": "Several modifications to CLAWS have been explored.", "labels": [], "entities": [{"text": "CLAWS", "start_pos": 25, "end_pos": 30, "type": "DATASET", "confidence": 0.7410642504692078}]}, {"text": "The resulting system cannot detect all errors in typed documents; but then neither do far more complex systems, which attempt a full parse, requiting much greater computation.", "labels": [], "entities": []}, {"text": "A number of ~rcbers have experimented with ways to cope with grammatically ill-formed English input (for example, [Carboneil and Hayes 83], [Charniak 83], [Granger 83], [Hayes and Mouradian 81], [Heidorn et al 82], [Jensen et al 83], [Kwasny and Sondheimer 81], [Weischedel and Black 80], [Weischedel and Sondheimer 83]).", "labels": [], "entities": []}, {"text": "However, the majority of these systems are designed for Natural Language interfaces to software systems, and so can assume a restricted vocabulary and syntax; for example, the system discussed by [Fass 83] had a vocabulary of less than 50 words.", "labels": [], "entities": [{"text": "Fass 83", "start_pos": 197, "end_pos": 204, "type": "DATASET", "confidence": 0.8576449155807495}]}, {"text": "This maybe justifiable fora NL front-end to a computer system such as a Database Query system, since even an artificial subset of English maybe more acceptable to users than a formal command or query language.", "labels": [], "entities": []}, {"text": "However, for automated text-checking in Word Processing, we cannot reasonably ask the WP user to restrict their English text in this way.", "labels": [], "entities": []}, {"text": "This means that WP text-checking systems must be extremely robust, capable of analysing a very wide range of lexical and syntactic constructs.", "labels": [], "entities": []}, {"text": "Otherwise, the grammar checker is liable to flag many constructs which are in fact acceptable to humans, but happen not to be included in the system's limited grammar.", "labels": [], "entities": []}, {"text": "A system which not only performs syntactic analysis of text, but also pinpoints grammatical errors, must be assessed along two orthogonal scales rather than a single 'accuracy' measure: RECALL-\"number of words/constructs correctly flagged as errors\" \"total number of 'true' errors that should be flagged\" PRECISION = \"number of words/constructs correctly flagged as errors\" \"total number of wordslconstructs flagged by the system\" It is easy to optimise one of these performance measures at the expense of the other, flagging (nearly) ALL words in a text will guarantee optimal recall (i.e. (nearly) all actual errors will be flagged) but at a low precision; and conversely, reducing the number of words flagged to nearly zero should raise the precision but lower the recall.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 167, "end_pos": 175, "type": "METRIC", "confidence": 0.9817997217178345}, {"text": "RECALL", "start_pos": 186, "end_pos": 192, "type": "METRIC", "confidence": 0.9988364577293396}, {"text": "PRECISION", "start_pos": 305, "end_pos": 314, "type": "METRIC", "confidence": 0.9547261595726013}, {"text": "recall", "start_pos": 578, "end_pos": 584, "type": "METRIC", "confidence": 0.9963935017585754}, {"text": "precision", "start_pos": 648, "end_pos": 657, "type": "METRIC", "confidence": 0.9650590419769287}, {"text": "precision", "start_pos": 744, "end_pos": 753, "type": "METRIC", "confidence": 0.9987354874610901}, {"text": "recall", "start_pos": 768, "end_pos": 774, "type": "METRIC", "confidence": 0.9970424771308899}]}, {"text": "The problem is to balance this trade-off to arrive at recall AND precision levels acceptable to WP users.", "labels": [], "entities": [{"text": "recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.999078631401062}, {"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.6415713429450989}]}, {"text": "A system which can accept a limited subset of English (and reject (or flag as erroneous) anything else) may have a reasonable recall rate; that is, most of the 'true' errors will probably be included in the rejected text.", "labels": [], "entities": [{"text": "recall", "start_pos": 126, "end_pos": 132, "type": "METRIC", "confidence": 0.9989332556724548}]}, {"text": "However, the precision rate is liable to be unacceptable to the WP user:, large amounts of the input text will effectively be marked as potentially erroneous, with no indication of where' within this text the actual errors lie.", "labels": [], "entities": [{"text": "precision rate", "start_pos": 13, "end_pos": 27, "type": "METRIC", "confidence": 0.9866810739040375}]}, {"text": "One way to deal with this problem is to increase the size and power of the parser and underlying grammar to deal with something nearer the whole gamut of English syntax; this is the approach taken by IBM's EPISTLE project (see [Heidorn et al 82], [Jensen et al 83]).", "labels": [], "entities": []}, {"text": "Unfortunately, this can lead to a very large and computationally expensive system: [Heidorn et al 82] reported that the EPISTLE system required a 4Mb virtual machine (although a more efficient implementation underdevelopment should require less memory).", "labels": [], "entities": [{"text": "EPISTLE", "start_pos": 120, "end_pos": 127, "type": "DATASET", "confidence": 0.8231495022773743}]}, {"text": "The UNIX Writer's Workbench collection of programs (see [Cherry and Macdonald 83], [Cherry et ai 83]) is probably the most widely-used system for WP text-checking (and also one of the most widely-used NLP systems overall-see [AtweU 86], [Hubert 85]).", "labels": [], "entities": [{"text": "UNIX Writer's Workbench collection", "start_pos": 4, "end_pos": 38, "type": "DATASET", "confidence": 0.6808709919452667}, {"text": "WP text-checking", "start_pos": 146, "end_pos": 162, "type": "TASK", "confidence": 0.8310773372650146}, {"text": "AtweU 86]", "start_pos": 226, "end_pos": 235, "type": "DATASET", "confidence": 0.9671487609545389}]}, {"text": "This system includes a number of separate programs to check for different types of faults, including misspellings, cliches, and cee, ain stylistic infelicities such as overly long (or short) sentences.", "labels": [], "entities": []}, {"text": "However, it lacks a general-purpose grammar checker, the nearest program is a tool to filter out doubled words (as in \"I signed the the contract\").", "labels": [], "entities": []}, {"text": "Although there is a program PARTS which assigns apart of speech tag to each word in the text (as a precursor to the stylistic analysis programs), this program uses a set of localized heuristic rules to disambiguate words according to context; and these roles are based on the underlying assumption that the input sentences are grammatically well-formed.", "labels": [], "entities": []}, {"text": "So, there is no clearway to modify PARTS to flag grammatical errors, unless we introduce a radically different mechanism for disambiguating word*tags according to contexu 38 LOB and CLAWS One such alternative word-tag disambiguation mechanism was developed for the analysis of the Lancaster-Oslo/Bergen (LOB) Corpus.", "labels": [], "entities": [{"text": "Lancaster-Oslo/Bergen (LOB) Corpus", "start_pos": 281, "end_pos": 315, "type": "DATASET", "confidence": 0.8143677881785801}]}, {"text": "The LOB Corpus is a million-word collection of English text samples, used for experimentation and inspiration in computational linguistics and related studies (see for example [Leech et al 83a], [Atwell forthcoming b]).", "labels": [], "entities": [{"text": "LOB Corpus", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.9354600608348846}]}, {"text": "CLAWS, the Constituent-Likelihood Automatic Word-tagging System ([Leech et al 83b], [Atwell et al 84]), was developed to annotate the raw text with basic granmlatical information, to make it more useful for linguistic research; CLAWS did not attempt a full parse of each sentence, but simply marked each word with a grammatical code from a set of 133 WORDTAGS.", "labels": [], "entities": [{"text": "CLAWS", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9021034836769104}]}, {"text": "The word-tagged LOB Corpus is now available to other researchers (see [Johansson et ai 86]).", "labels": [], "entities": [{"text": "LOB Corpus", "start_pos": 16, "end_pos": 26, "type": "DATASET", "confidence": 0.7915960848331451}]}, {"text": "CLAWS was originally implemented in Pascal, but it is currently being recoded in C and in POPLOG Prolog.", "labels": [], "entities": [{"text": "POPLOG Prolog", "start_pos": 90, "end_pos": 103, "type": "DATASET", "confidence": 0.8182222843170166}]}, {"text": "CLAWS can deal with Unrestricted English text input including \"noisy\" or ill-formed sentences, because it is based on Constituent Likelihood Grammar, a novel probabilistic approach to grammatical description and analysis described in [Atwell 83].", "labels": [], "entities": [{"text": "CLAWS", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8602370619773865}, {"text": "grammatical description and analysis", "start_pos": 184, "end_pos": 220, "type": "TASK", "confidence": 0.8185246586799622}, {"text": "Atwell 83]", "start_pos": 235, "end_pos": 245, "type": "DATASET", "confidence": 0.9326820770899454}]}, {"text": "A Constituent Likelihood Grammar is used to calculate likelihoods for competing putative analysis; not only does this tell us which is the 'best' analysis, but it also shows how 'good' this analysis is.", "labels": [], "entities": []}, {"text": "For assigning word-tags to words, a simple Markovian model can be used instead of a probabilistic rewrite-role system (such as a prohabilistic context-free grammar); this greatly simplifies processing.", "labels": [], "entities": []}, {"text": "CLAWS first uses a dictionary, sufflxlist and other default routines to assign a set of putative tags to each word; then, for each sequence of ambiguously-tagged words, the likelihood of every possible combination or 'chain' of tags is evaluated, and the best chain is chosen.", "labels": [], "entities": [{"text": "CLAWS", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8705638647079468}]}, {"text": "The likelihood of each chain of tags is evaluated as a product of all the 'links' (tag-pair-likelihoods) in the sequence; tag-pair likelihood is a function of the frequency of that sequence of two tags in a sample of tagged text, compared to the frequency of each of the two tags individually.", "labels": [], "entities": []}, {"text": "An important advantage of this simple Markovian model is that word-tagging is done without parsing: there is no need to workout higher-level constituent-structure trees before assigning unambiguous word-tags to words.", "labels": [], "entities": []}, {"text": "Despite its simplicity, this technique is surprisingly robust and successful: CLAWS has been used to analyse a wide variety of Unrestricted English, including extracts form newspapers, novels, diaries, learned journals, E.E.C. regulations, etc., with a consistent accuracy of c96%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 264, "end_pos": 272, "type": "METRIC", "confidence": 0.9949480295181274}]}, {"text": "Although the system did not have parse trees available in deciding word-classes, only cA% of words in the LOB Corpus had to have their assigned wordtag corrected by manual editing (see [Atwell 81, 82]).", "labels": [], "entities": [{"text": "LOB Corpus", "start_pos": 106, "end_pos": 116, "type": "DATASET", "confidence": 0.9718954265117645}]}, {"text": "Another important advantage of the simple Markovian model is that it is relatively straightforward to transfer the model from English to other Natural Languages.", "labels": [], "entities": []}, {"text": "The basic statistical model remains, only the dictionary and Markovian tag-pair frequency table need to be replaced.", "labels": [], "entities": []}, {"text": "We are experimenting with the possibility of (partially) automating even this process-see [Atweli 86a, 86b, forthcoming c], [Atwell and Drakos 87].", "labels": [], "entities": [{"text": "Atweli 86a, 86b", "start_pos": 91, "end_pos": 106, "type": "DATASET", "confidence": 0.9132525622844696}, {"text": "Atwell and Drakos 87", "start_pos": 125, "end_pos": 145, "type": "DATASET", "confidence": 0.8995384722948074}]}, {"text": "The general Constituent Likelihood approach to grammatical analysis, and CLAWS in particular, can be used to analyse text including ill-formed syntax.", "labels": [], "entities": [{"text": "grammatical analysis", "start_pos": 47, "end_pos": 67, "type": "TASK", "confidence": 0.7011529952287674}]}, {"text": "More importantly, it can also be adapted to flag syntactic errors in texts; unlike other techniques for error-detection, these modifications of CLAWS lead to only limited increases in processing requirements.", "labels": [], "entities": []}, {"text": "In fact, various different types of modification are possible, yielding varying degrees of success in error-detection.", "labels": [], "entities": []}, {"text": "Several different techniques have been explored.", "labels": [], "entities": []}, {"text": "Error Likelihoods Avery simple adaptation of CLAWS (simple in theory at least) is to augment the tag*pair frequency table with a tag-pair error likelihood table.", "labels": [], "entities": [{"text": "tag-pair error likelihood table", "start_pos": 129, "end_pos": 160, "type": "METRIC", "confidence": 0.7087261378765106}]}, {"text": "As in the original system, CLAWS uses the tag-pair frequency table and the Constituent Likelihood formulae to find the best word-tag for each word.", "labels": [], "entities": [{"text": "CLAWS", "start_pos": 27, "end_pos": 32, "type": "DATASET", "confidence": 0.8721235990524292}]}, {"text": "Having found the best tag for each word, every cooccurring pair of tags in the analysis is reassessed: the ERRO~_-LIKELIHOOD of each tag-pair is checked.", "labels": [], "entities": [{"text": "ERRO~_-LIKELIHOOD", "start_pos": 107, "end_pos": 124, "type": "METRIC", "confidence": 0.787854810555776}]}, {"text": "Error-likelihood is a measure of how frequently a given tag-pair occurs in an error as compared to how frequently it occurs invalid text.", "labels": [], "entities": [{"text": "Error-likelihood", "start_pos": 0, "end_pos": 16, "type": "METRIC", "confidence": 0.9816226959228516}]}, {"text": "For example, if the user types ...", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}