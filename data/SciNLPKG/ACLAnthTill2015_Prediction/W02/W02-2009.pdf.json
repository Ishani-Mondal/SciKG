{"title": [{"text": "Cross-dataset Clustering: Revealing Corresponding Themes Across Multiple Corpora", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a method for identifying corresponding themes across several corpora that are focused on related, but distinct, domains.", "labels": [], "entities": []}, {"text": "This task is approached through simultaneous clustering of keyword sets extracted from the analyzed corpora.", "labels": [], "entities": []}, {"text": "Our algorithm extends the information-bottleneck soft clustering method fora suitable setting consisting of several datasets.", "labels": [], "entities": [{"text": "information-bottleneck soft clustering", "start_pos": 26, "end_pos": 64, "type": "TASK", "confidence": 0.5986538628737131}]}, {"text": "Experimentation with topical corpora reveals similar aspects of three distinct religions.", "labels": [], "entities": []}, {"text": "The evaluation is byway of comparison to clusters constructed manually by an expert.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper addresses the problem of detecting corresponding subtopics, or themes, within related bodies of text.", "labels": [], "entities": []}, {"text": "Such task is typical to comparative research, whether commercial or scientific: a conceivable application would aim at detecting corresponding characteristics regarding, e.g., companies, markets, legal systems or political organizations.", "labels": [], "entities": []}, {"text": "Clustering has often been perceived as a mean for extracting meaningful components from data).", "labels": [], "entities": []}, {"text": "Regarding textual data, clusters of words (Pereira, Tishby and Lee, 1993) or documents () are often interpreted as capturing topics or themes that play prominent role in the analyzed texts.", "labels": [], "entities": []}, {"text": "Our work extends the \"standard\" clustering paradigm, which pertains to a single dataset.", "labels": [], "entities": []}, {"text": "We address a setting in which several datasets, corresponding to related domains, are given.", "labels": [], "entities": []}, {"text": "We focus on the comparative task of detecting those themes that are expressed across several datasets, rather than discovering internal themes within each individual dataset.", "labels": [], "entities": []}, {"text": "More specifically, we address the task of clustering simultaneously multiple datasets such that each cluster includes elements from several datasets, capturing a common theme, which is shared across the sets.", "labels": [], "entities": []}, {"text": "We term this task crossdataset (CD) clustering.", "labels": [], "entities": [{"text": "crossdataset (CD) clustering", "start_pos": 18, "end_pos": 46, "type": "TASK", "confidence": 0.5950780570507049}]}, {"text": "In this article we demonstrate CD clustering through detecting corresponding themes across three different religions.", "labels": [], "entities": [{"text": "CD clustering", "start_pos": 31, "end_pos": 44, "type": "TASK", "confidence": 0.8585982620716095}]}, {"text": "That is: we apply our approach to three sets of religion-related keywords, extracted from three corpora, which include encyclopedic entries and introductory articles regarding Buddhism, Christianity and Islam.", "labels": [], "entities": []}, {"text": "Each one of three representative keyword-sets, which were extracted from the above corpora, presumably encapsulates topics and themes discussed within its source corpus.", "labels": [], "entities": []}, {"text": "Our algorithm succeeds to reveal common themes such as scriptures, rituals and schools through respective keyword clusters consisting of terms such as Sutra, Bible and Quran; Full Moon, Easter and Id al Fitr; Theravada, Protestant and Shiite (see below fora detailed depiction of our results).", "labels": [], "entities": []}, {"text": "The CD clustering algorithm, presented in Section 2.2 below, extends the information bottleneck (IB) soft clustering method.", "labels": [], "entities": [{"text": "CD clustering", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.6656395345926285}, {"text": "information bottleneck (IB) soft clustering", "start_pos": 73, "end_pos": 116, "type": "TASK", "confidence": 0.6154581989560809}]}, {"text": "Our modifications to the IB formulation enable the clustering algorithm to capture characteristic patterns that run across different datasets, rather then being \"trapped\" by unique characteristics of individual datasets.", "labels": [], "entities": []}, {"text": "Like other topic discovery tasks that are approached by clustering, the goal of CD clustering is not defined in precise terms.", "labels": [], "entities": [{"text": "topic discovery tasks", "start_pos": 11, "end_pos": 32, "type": "TASK", "confidence": 0.7985021074612936}, {"text": "CD clustering", "start_pos": 80, "end_pos": 93, "type": "TASK", "confidence": 0.7518081068992615}]}, {"text": "Yet, it is clear that its focus on detecting themes in a comparative manner, within multiple datasets, distinguishes CD clustering substantially from the standard single-dataset clustering paradigm.", "labels": [], "entities": [{"text": "CD clustering", "start_pos": 117, "end_pos": 130, "type": "TASK", "confidence": 0.6528892666101456}]}, {"text": "A related problem, of detecting analogies between different information systems has been addressed in the past within cognitive research.", "labels": [], "entities": [{"text": "detecting analogies between different information systems", "start_pos": 22, "end_pos": 79, "type": "TASK", "confidence": 0.8561918139457703}]}, {"text": "Recently, a related computational method for detecting corresponding themes has been introduced (coupled clustering, ).", "labels": [], "entities": []}, {"text": "The coupled clustering setting, however, being focused on detecting analogies, is limited to two data sets.", "labels": [], "entities": []}, {"text": "Further, it requires similarity values between pairs of data elements as input: this setting does not seem straightforwardly applicable to the multiple dataset setting.", "labels": [], "entities": []}, {"text": "Our method, in distinction, uses a more direct source of information, namely word co-occurrence statistics within the analyzed corpora.", "labels": [], "entities": []}, {"text": "Another difference is that we take the \"soft\" approach to clustering, producing probabilities of assignments into clusters rather than a deterministic 0/1 assignment values.", "labels": [], "entities": []}], "datasetContent": [{"text": "The (soft) CD clustering algorithm receives as input multiple datasets along with their feature vectors.", "labels": [], "entities": []}, {"text": "In the current application, we have three sets extracted from the corresponding corpora -X Buddhism , X Christianity , and X Islam -each of ~150 keywords to be clustered.", "labels": [], "entities": []}, {"text": "A particular keyword might appear in two or more of the datasets, but the CD setting considers it as a distinct element within each dataset, thus keeping the sets of clustered elements disjoint.", "labels": [], "entities": []}, {"text": "Like the IB clustering algorithm, the CD algorithm produces probabilistic assignments of the data elements.", "labels": [], "entities": [{"text": "IB clustering", "start_pos": 9, "end_pos": 22, "type": "TASK", "confidence": 0.8301630020141602}]}, {"text": "The feature set Y consists, in the current work, of about 7000 content words, each occurs in at least two of the examined corpora.", "labels": [], "entities": []}, {"text": "The set of features is used commonly for all datasets, thus it underlies a common representation, which enables the clustering process to compare elements of different sets.", "labels": [], "entities": []}, {"text": "Naively approached, the original IB algorithm could be utilized unaltered to the multipledataset setting, simply by applying it to the unified set X, consisting of the union of the disjoint X i 's.", "labels": [], "entities": []}, {"text": "The problem of this simplistic approach is that each dataset has its own characteristic features and feature combinations, which correspond to prominent topics discussed uniquely in that corpus.", "labels": [], "entities": []}, {"text": "A standard clustering method, such as the IB algorithm, would have a tendency to cluster together elements that originate in the same dataset, producing clusters populated mostly by elements from a single dataset (cf. ). The goal of CD clustering is to neutralize this tendency and to create clusters containing elements that share common features across different datasets.", "labels": [], "entities": []}, {"text": "To accomplish this goal, we change the criterion by which elements are assigned into clusters.", "labels": [], "entities": []}, {"text": "Recall that the assignment of an element x to a cluster c is determined by the similarity of their characterizing feature distributions, p(y|x) and p(y|c) (step IB3).", "labels": [], "entities": []}, {"text": "The problem lies in using the p(y|c) distribution, which is determined by summing p(y|x) values overall cluster elements, to characterize a cluster without taking into account dataset boundaries.", "labels": [], "entities": []}, {"text": "Thus, fora certain y, p(y|c) might be high despite of being characteristic only for cluster elements originating in a single dataset.", "labels": [], "entities": []}, {"text": "This results in the tendency discussed above to favor clusters consisting of elements of a single dataset.", "labels": [], "entities": []}, {"text": "Therefore, we define a biased probability distribution, p ~ c (y), to be used by the CD clustering algorithm for characterizing a cluster c.", "labels": [], "entities": []}, {"text": "It is designed to call attention to y's that are typical for cluster members in all, or most, different datasets.", "labels": [], "entities": []}, {"text": "Consequently, an element x would be assigned to a cluster c (as in step IB3) in accordance to the degree of similarity between its own characteristic features and those characterizing other cluster members from all datasets.", "labels": [], "entities": []}, {"text": "The resulting clusters would thus contain representatives of all datasets.", "labels": [], "entities": []}, {"text": "The definition of p ~ c (y) is based on the joint probability p(y,c,X i ).", "labels": [], "entities": []}, {"text": "First, compute the geometric mean of p(y,c,X i ) overall X i , weighted by p(X i ): (see Appendix below for the details of how p(X i ) and p(y,c,X i ) are calculated).", "labels": [], "entities": []}, {"text": "\u03c1 is not a probability measure, but just a function of y and c into.", "labels": [], "entities": []}, {"text": "However, since a geometric mean reflects \"uniformity\" of the averaged values, \u03c1 captures the degree to which p(y,c,X i ) values are high across all datasets.", "labels": [], "entities": []}, {"text": "The CD clustering algorithm, starting at t = 0, iterates, in correspondence to the IB algorithm, the following steps: CD1: Calculate for each cluster c its marginal probability (same as IB1):", "labels": [], "entities": []}], "tableCaptions": []}