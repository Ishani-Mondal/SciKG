{"title": [{"text": "From Words to Corpora: Recognizing Translation", "labels": [], "entities": [{"text": "Recognizing Translation", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.7427175343036652}]}], "abstractContent": [{"text": "This paper presents a technique for discovering translationally equivalent texts.", "labels": [], "entities": [{"text": "discovering translationally equivalent texts", "start_pos": 36, "end_pos": 80, "type": "TASK", "confidence": 0.7453844398260117}]}, {"text": "It is comprised of the application of a matching algorithm at two different levels of analysis and a well-founded similarity score.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 114, "end_pos": 130, "type": "METRIC", "confidence": 0.9644505679607391}]}, {"text": "This approach can be applied to any multilingual corpus using any kind of translation lexicon; it is therefore adaptable to varying levels of multilingual resource availability.", "labels": [], "entities": []}, {"text": "Experimental results are shown on two tasks: a search for matching thirty-word segments in a corpus where some segments are mutual translations, and classification of candidate pairs of web pages that mayor may not be translations of each other.", "labels": [], "entities": []}, {"text": "The latter results compare competitively with previous , document-structure-based approaches to the same problem.", "labels": [], "entities": []}], "introductionContent": [{"text": "As inmost areas of natural language processing, recent approaches to machine translation have turned increasingly to statistical modeling of the phenomenon (translation models).", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.7213017741839091}, {"text": "machine translation", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.7575916945934296}]}, {"text": "Such models are learned automatically from data, typically parallel corpora: texts in two or more languages that are mutual translations.", "labels": [], "entities": []}, {"text": "As computational resources have become more powerful and less expensive, the task of training translation models has become feasible), as has the task of translating (or \"decoding\") text using such models ().", "labels": [], "entities": []}, {"text": "However, the success of the statistical approach to translation (and also to other multilingual applications that utilize parallel text) hangs crucially on the quality, quantity, and diversity of data used in parameter estimation.", "labels": [], "entities": [{"text": "translation", "start_pos": 52, "end_pos": 63, "type": "TASK", "confidence": 0.9773882031440735}, {"text": "parameter estimation", "start_pos": 209, "end_pos": 229, "type": "TASK", "confidence": 0.6890232861042023}]}, {"text": "If translation is a generative process, then one might consider its reverse process of recognition: Given two documents, might it be determined fully automatically whether they are translations of each other?", "labels": [], "entities": [{"text": "translation", "start_pos": 3, "end_pos": 14, "type": "TASK", "confidence": 0.9648767709732056}]}, {"text": "The ability to detect translations of a document has numerous applications.", "labels": [], "entities": []}, {"text": "The most obvious is as a means to build a parallel corpus from a set of multilingual documents that contains some translation pairs.", "labels": [], "entities": []}, {"text": "Examples include mining the World-Wide Web for parallel text) and building parallel corpora from comparable corpora such as multilingual collections of news reports.", "labels": [], "entities": []}, {"text": "Another use of translation detection might be as an aid in alignment tasks at any level.", "labels": [], "entities": [{"text": "translation detection", "start_pos": 15, "end_pos": 36, "type": "TASK", "confidence": 0.9902400076389313}, {"text": "alignment tasks", "start_pos": 59, "end_pos": 74, "type": "TASK", "confidence": 0.9180857539176941}]}, {"text": "For example, consider the task of aligning NP chunks (and perhaps also the extra-NP material) in an NP-bracketed parallel corpus; a chunk-level similarity score () built from a word-level model could be incorporated into a framework that involves bootstrapping more complex models of translation from simpler ones.", "labels": [], "entities": []}, {"text": "Finally, reliable cross-lingual duplicate detection might improve performance in nbest multilingual information retrieval systems; at the same time, by detecting the existence of a translation in a multilingual corpus, the cost of translating a document of interest is eliminated.", "labels": [], "entities": [{"text": "cross-lingual duplicate detection", "start_pos": 18, "end_pos": 51, "type": "TASK", "confidence": 0.7669170300165812}]}, {"text": "I present here an algorithm for classifying document pairs as either translationally equivalent or not, which can be built upon any kind of word-to-word translation lexicon (automatically learned or hand-crafted).", "labels": [], "entities": []}, {"text": "I propose a score of translational similarity, then describe an evaluation task involving a constrained search for texts (of arbitrary size) that are translation pairs, in a noisy space, and present precision/recall results.", "labels": [], "entities": [{"text": "translational similarity", "start_pos": 21, "end_pos": 45, "type": "TASK", "confidence": 0.7386970818042755}, {"text": "precision", "start_pos": 199, "end_pos": 208, "type": "METRIC", "confidence": 0.9980294108390808}, {"text": "recall", "start_pos": 209, "end_pos": 215, "type": "METRIC", "confidence": 0.8705158829689026}]}], "datasetContent": [{"text": "This experiment used the Hong Kong Hansard English-Chinese parallel corpus.", "labels": [], "entities": [{"text": "Hong Kong Hansard English-Chinese parallel corpus", "start_pos": 25, "end_pos": 74, "type": "DATASET", "confidence": 0.9209367334842682}]}, {"text": "The training corpus is aligned at the sentence level, with segment lengths averaging fifteen words (in each language).", "labels": [], "entities": []}, {"text": "The test corpus is aligned at the twosentence level, with segment lengths averaging thirty words.", "labels": [], "entities": []}, {"text": "The first experiment involved tenfold cross-validation with (for each fold) a training corpus of 9,400 sentence pairs and a test corpus of 1,000 two-sentence pairs.", "labels": [], "entities": []}, {"text": "The corpus was randomly divided into folds, and no noise was introduced (i.e., k = n).", "labels": [], "entities": []}, {"text": "An important application of translation recognition is the construction of parallel text corpora.", "labels": [], "entities": [{"text": "translation recognition", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.988185703754425}]}, {"text": "One source of raw text in this task is the World-Wide Web, for which several parallel text search systems currently exist).", "labels": [], "entities": []}, {"text": "These systems propose candidate pairs of pages, which are then classified as either translationally equivalent or not.", "labels": [], "entities": []}, {"text": "The STRAND system, for example, uses structural markup information from the pages, without looking at their content, to attempt to align them.", "labels": [], "entities": [{"text": "STRAND", "start_pos": 4, "end_pos": 10, "type": "DATASET", "confidence": 0.5288555026054382}]}, {"text": "If the tsim technique can provide a classifier that rivals or complements the structural one, using as it does an entirely orthogonal set of features, then perhaps a combined classifier could provide even greater reliability.", "labels": [], "entities": []}, {"text": "In addition, custom-quality parallel corpora could be generated from comparable corpora that lack Figure 2: (a.)", "labels": [], "entities": []}, {"text": "Precision and recall with no noise.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9759987592697144}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9988179802894592}]}, {"text": "This plot shows precision and recall averaged overall ten folds.", "labels": [], "entities": [{"text": "precision", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9997420907020569}, {"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9996434450149536}]}, {"text": "Each point corresponds to a threshold value; the threshold becomes less strict from left to right.", "labels": [], "entities": []}, {"text": "Shown are curves for each of UTL, TMTL, and DICT under both algorithms (MWBM, CL); the maximum F scores are marked (see).", "labels": [], "entities": [{"text": "F", "start_pos": 95, "end_pos": 96, "type": "METRIC", "confidence": 0.9599288702011108}]}, {"text": "Precision-recall curves at varying levels of noise.", "labels": [], "entities": [{"text": "Precision-recall", "start_pos": 0, "end_pos": 16, "type": "METRIC", "confidence": 0.9644621014595032}]}, {"text": "k = 300 in all cases; the circles and dashed line show precision and recall for the top 300 pairs in the matching (i.e., if k were known, it would not make sense to use a lower threshold, so the only reasonable thresholds are to the left), and the squares and dotted line show precision and recall at each condition's maximum F -score-the values are shown in.", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9994102716445923}, {"text": "recall", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.9980944991111755}, {"text": "precision", "start_pos": 277, "end_pos": 286, "type": "METRIC", "confidence": 0.9991773962974548}, {"text": "recall", "start_pos": 291, "end_pos": 297, "type": "METRIC", "confidence": 0.9989042282104492}, {"text": "F -score-the", "start_pos": 326, "end_pos": 338, "type": "METRIC", "confidence": 0.9890942772229513}]}, {"text": "(Note that the curves \"stop\" before reaching a point where recall is 1.0, since a point is eventually reached where no more matches are possible (because of filtering).) structural features.", "labels": [], "entities": [{"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9970977306365967}]}, {"text": "This experiment also shows that tsim is scalable to larger texts.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of translation lexicons and  matching algorithms at their maximal F -scores.  Note that thresholds, and tsim scores in general, are  comparable only for a given translation lexicon. The  STR translation lexicon offered a boost only when  used to supplement TMTL \u222a DICT; when added to  each alone it had little or no effect.", "labels": [], "entities": [{"text": "F -scores", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9648493727048238}, {"text": "STR translation lexicon", "start_pos": 208, "end_pos": 231, "type": "DATASET", "confidence": 0.6407190362612406}]}, {"text": " Table 2: Precision and recall when the top k (300)  pairs are taken (i.e., k is known; in the case of n =  300, the matching contained only 293 pairs), and at  maximal F -scores for various levels of noise.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.995252251625061}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9993237257003784}, {"text": "F -scores", "start_pos": 169, "end_pos": 178, "type": "METRIC", "confidence": 0.9815481901168823}]}, {"text": " Table 3: Comparison with STRAND. The test set is  294 of the 326 pairs in Resnik's (1999) test set. The  STRAND \u03ba scores are similar to those published by", "labels": [], "entities": [{"text": "STRAND", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.7997546195983887}, {"text": "Resnik's (1999) test set", "start_pos": 75, "end_pos": 99, "type": "DATASET", "confidence": 0.7160030603408813}, {"text": "STRAND \u03ba scores", "start_pos": 106, "end_pos": 121, "type": "METRIC", "confidence": 0.9065585335095724}]}]}