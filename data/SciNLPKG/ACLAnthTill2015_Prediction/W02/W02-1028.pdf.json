{"title": [{"text": "A Bootstrapping Method for Learning Semantic Lexicons using Extraction Pattern Contexts", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes a bootstrapping algorithm called Basilisk that learns high-quality semantic lexicons for multiple categories.", "labels": [], "entities": []}, {"text": "Basilisk begins with an unannotated corpus and seed words for each semantic category, which are then bootstrapped to learn new words for each category.", "labels": [], "entities": []}, {"text": "Basilisk hypothesizes the semantic class of a word based on collective information over a large body of extraction pattern contexts.", "labels": [], "entities": []}, {"text": "We evaluate Basilisk on six semantic categories.", "labels": [], "entities": []}, {"text": "The semantic lexicons produced by Basilisk have higher precision than those produced by previous techniques, with several categories showing substantial improvement.", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9969598054885864}]}], "introductionContent": [{"text": "In recent years, several algorithms have been developed to acquire semantic lexicons automatically or semi-automatically using corpus-based techniques.", "labels": [], "entities": []}, {"text": "For our purposes, the term semantic lexicon will refer to a dictionary of words labeled with semantic classes (e.g., \"bird\" is an animal and \"truck\" is a vehicle).", "labels": [], "entities": []}, {"text": "Semantic class information has proven to be useful for many natural language processing tasks, including information extraction (, anaphora resolution (, question answering (), and prepositional phrase attachment (.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 105, "end_pos": 127, "type": "TASK", "confidence": 0.8168670237064362}, {"text": "anaphora resolution", "start_pos": 131, "end_pos": 150, "type": "TASK", "confidence": 0.7139084041118622}, {"text": "question answering", "start_pos": 154, "end_pos": 172, "type": "TASK", "confidence": 0.803642749786377}, {"text": "prepositional phrase attachment", "start_pos": 181, "end_pos": 212, "type": "TASK", "confidence": 0.6059323648611704}]}, {"text": "Although some semantic dictionaries do exist (e.g., WordNet), these resources often do not contain the specialized vocabulary and jargon that is needed for specific domains.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 52, "end_pos": 59, "type": "DATASET", "confidence": 0.9493417739868164}]}, {"text": "Even for relatively general texts, such as the Wall Street Journal ( or terrorism articles, reported that 3 of every 5 terms generated by their semantic lexicon learner were not present in WordNet.", "labels": [], "entities": [{"text": "Wall Street Journal", "start_pos": 47, "end_pos": 66, "type": "DATASET", "confidence": 0.9590430657068888}, {"text": "WordNet", "start_pos": 189, "end_pos": 196, "type": "DATASET", "confidence": 0.9412348866462708}]}, {"text": "These results suggest that automatic semantic lexicon acquisition could be used to enhance existing resources such as WordNet, or to produce semantic lexicons for specialized domains.", "labels": [], "entities": [{"text": "semantic lexicon acquisition", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.6940915286540985}, {"text": "WordNet", "start_pos": 118, "end_pos": 125, "type": "DATASET", "confidence": 0.943505048751831}]}, {"text": "We have developed a weakly supervised bootstrapping algorithm called Basilisk that automatically generates semantic lexicons.", "labels": [], "entities": []}, {"text": "Basilisk hypothesizes the semantic class of a word by gathering collective evidence about semantic associations from extraction pattern contexts.", "labels": [], "entities": []}, {"text": "Basilisk also learns multiple semantic classes simultaneously, which helps constrain the bootstrapping process.", "labels": [], "entities": []}, {"text": "First, we present Basilisk's bootstrapping algorithm and explain how it differs from previous work on semantic lexicon induction.", "labels": [], "entities": [{"text": "semantic lexicon induction", "start_pos": 102, "end_pos": 128, "type": "TASK", "confidence": 0.7122972011566162}]}, {"text": "Second, we present empirical results showing that Basilisk outperforms a previous algorithm.", "labels": [], "entities": []}, {"text": "Third, we explore the idea of learning multiple semantic categories simultaneously by adding this capability to Basilisk as well as another bootstrapping algorithm.", "labels": [], "entities": []}, {"text": "Finally, we present results showing that learning multiple semantic categories simultaneously improves performance.", "labels": [], "entities": []}, {"text": "The nouns extracted by these patterns become candidates for the lexicon and are placed in a candidate word pool.", "labels": [], "entities": []}, {"text": "Basilisk scores each candidate word by gathering all patterns that extract it and measuring how strongly those contexts are associated with words that belong to the semantic category.", "labels": [], "entities": []}, {"text": "The five best candidate words are added to the lexicon, and the process starts over again.", "labels": [], "entities": []}, {"text": "In this section, we describe Basilisk's bootstrapping algorithm in more detail and discuss related work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Breakdown of semantic categories", "labels": [], "entities": [{"text": "Breakdown of semantic categories", "start_pos": 10, "end_pos": 42, "type": "TASK", "confidence": 0.8646371364593506}]}, {"text": " Table 1. The recall results  range from 40-60%, which indicates that a good per- centage of the category words are being found, al- though there are clearly more category words lurking  in the corpus.", "labels": [], "entities": [{"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9993764758110046}]}]}