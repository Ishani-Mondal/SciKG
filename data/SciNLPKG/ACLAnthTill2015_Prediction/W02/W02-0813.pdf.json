{"title": [{"text": "Combining Contextual Features for Word Sense Disambiguation", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 34, "end_pos": 59, "type": "TASK", "confidence": 0.6392615636189779}]}], "abstractContent": [{"text": "In this paper we present a maximum en-tropy Word Sense Disambiguation system we developed which performs competitively on SENSEVAL-2 test data for En-glish verbs.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 44, "end_pos": 69, "type": "TASK", "confidence": 0.5915157198905945}, {"text": "SENSEVAL-2 test data", "start_pos": 122, "end_pos": 142, "type": "DATASET", "confidence": 0.6603864928086599}]}, {"text": "We demonstrate that using richer linguistic contextual features significantly improves tagging accuracy, and compare the system's performance with human annotator performance in light of both fine-grained and coarse-grained sense distinctions made by the sense inventory .", "labels": [], "entities": [{"text": "tagging", "start_pos": 87, "end_pos": 94, "type": "TASK", "confidence": 0.9697161316871643}, {"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9410470128059387}]}], "introductionContent": [{"text": "Highly ambiguous words pose continuing problems for Natural Language Processing (NLP) applications.", "labels": [], "entities": []}, {"text": "They can lead to irrelevant document retrieval in IR systems, and inaccurate translations in Machine Translation systems ().", "labels": [], "entities": [{"text": "document retrieval", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.7131904512643814}, {"text": "Machine Translation", "start_pos": 93, "end_pos": 112, "type": "TASK", "confidence": 0.738449215888977}]}, {"text": "While homonyms like bank are fairly tractable, polysemous words like run, with related but subtly distinct meanings, present the greatest hurdle for Word Sense Disambiguation (WSD).", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 149, "end_pos": 180, "type": "TASK", "confidence": 0.7611956844727198}]}, {"text": "SENSEVAL-1 and SENSEVAL-2 have attempted to provide a framework for evaluating automatic systems by creating corpora tagged with fixed sense inventories, which also enables the training of supervised WSD systems.", "labels": [], "entities": [{"text": "SENSEVAL-1", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.8669693470001221}]}, {"text": "In this paper we describe a maximum entropy WSD system that combines information from many different sources, using as much linguistic knowledge as can be gathered automatically by current NLP tools.", "labels": [], "entities": []}, {"text": "Maximum entropy models have been applied to a wide range of classification tasks in NLP.", "labels": [], "entities": []}, {"text": "Our maximum entropy system performed competitively with the best performing systems on the English verb lexical sample task in SENSEVAL-1 and SENSEVAL-2.", "labels": [], "entities": []}, {"text": "We compared the system performance with human annotator performance in light of both fine-grained and coarse-grained sense distinctions made by WordNet in SENSEVAL-2, and found that many of the system's errors on fine-grained senses stemmed from the same sources that caused disagreements between human annotators.", "labels": [], "entities": [{"text": "WordNet in SENSEVAL-2", "start_pos": 144, "end_pos": 165, "type": "DATASET", "confidence": 0.8366459012031555}]}, {"text": "These differences were partially resolved by backing off to more coarse-grained sense-groups, which are sometimes necessary when even human annotators cannot make the fine-grained sense distinctions specified in the dictionary.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Accuracy of different variants of maximum entropy models on SENSEVAL-1 verbs. Only local in- formation was used, unless indicated by \"+topic,\" in which case the topical keyword features were included  in the model; \"wn\" indicates that WordNet class features were used, while \"lex\" indicates only lexical and  named entity tag features were used for the noun complements; \"+trans\" indicates that an attempt was made  to undo passivization transformations.", "labels": [], "entities": []}, {"text": " Table 2: Accuracy of maximum entropy system using different subsets of features for SENSEVAL-2 verbs.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9611109495162964}]}, {"text": " Table 3: Number of senses and sense groups in training data for each SENSEVAL-2 verb; fine-grained  accuracy of top three competitors (JHU, SMULS, KUNLP) in SENSEVAL-2 English verbs lexical sample  task; fine-grained (MX) and coarse-grained accuracy (MX-c) of maximum entropy system; inter-tagger  agreement for fine-grained senses (ITA) and sense groups (ITA-c). *No inter-tagger agreement figures were  available for \"play\" and \"work\".", "labels": [], "entities": [{"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9149503707885742}, {"text": "accuracy (MX-c)", "start_pos": 242, "end_pos": 257, "type": "METRIC", "confidence": 0.8585717529058456}]}]}