{"title": [], "abstractContent": [{"text": "Named entity (NE) recognition is an important task for many natural language applications , such as Internet search engines, document indexing, information extraction and machine translation.", "labels": [], "entities": [{"text": "Named entity (NE) recognition", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6007513701915741}, {"text": "document indexing", "start_pos": 125, "end_pos": 142, "type": "TASK", "confidence": 0.7476186752319336}, {"text": "information extraction", "start_pos": 144, "end_pos": 166, "type": "TASK", "confidence": 0.8012917935848236}, {"text": "machine translation", "start_pos": 171, "end_pos": 190, "type": "TASK", "confidence": 0.7738856971263885}]}, {"text": "Moreover, in oriental languages (such as Chinese, Japanese and Korean), NE recognition is even more important because it significantly affects the performance of word segmentation, the most fundamental task for understanding the texts in oriental languages.", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 72, "end_pos": 86, "type": "TASK", "confidence": 0.9830307364463806}, {"text": "word segmentation", "start_pos": 162, "end_pos": 179, "type": "TASK", "confidence": 0.7356375604867935}]}, {"text": "In this paper, a prob-abilistic verification model is designed for verifying the correctness of a named entity candidate.", "labels": [], "entities": []}, {"text": "This model assesses the confidence level of a candidate not only according to the candidate's structure but also according to its context.", "labels": [], "entities": []}, {"text": "In our design, the clues for confidence measurement are collected from both positive and negative examples in the training data in a statistical manner.", "labels": [], "entities": []}, {"text": "Experimental results show that the proposed method significantly improves the F-measure of Chinese personal name recognition from 86.5% to 94.4%.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9983506202697754}, {"text": "Chinese personal name recognition", "start_pos": 91, "end_pos": 124, "type": "TASK", "confidence": 0.6246222332119942}]}], "introductionContent": [{"text": "Named entity (NE) recognition (or proper name recognition) is a task to find the entities of person, location, organization, date, time, percentage and monetary value in text documents.", "labels": [], "entities": [{"text": "Named entity (NE) recognition (or proper name recognition) is a task to find the entities of person, location, organization, date, time, percentage and monetary value in text documents", "start_pos": 0, "end_pos": 184, "type": "Description", "confidence": 0.7485520702761572}]}, {"text": "It is an important task for many natural language applications, such as Internet search engines, document indexing, information extraction and machine translation.", "labels": [], "entities": [{"text": "document indexing", "start_pos": 97, "end_pos": 114, "type": "TASK", "confidence": 0.7745477557182312}, {"text": "information extraction", "start_pos": 116, "end_pos": 138, "type": "TASK", "confidence": 0.8314383029937744}, {"text": "machine translation", "start_pos": 143, "end_pos": 162, "type": "TASK", "confidence": 0.7929209470748901}]}, {"text": "Moreover, in oriental languages (such as Chinese, Japanese and Korean), NE recognition is even more important because it significantly affects the performance of word segmentation, the most fundamental task for understanding the texts in oriental languages.", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 72, "end_pos": 86, "type": "TASK", "confidence": 0.9830307364463806}, {"text": "word segmentation", "start_pos": 162, "end_pos": 179, "type": "TASK", "confidence": 0.7356375604867935}]}, {"text": "Therefore, a high-accuracy NE recognition method is highly demanded for most natural language applications in various languages.", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 27, "end_pos": 41, "type": "TASK", "confidence": 0.9808580577373505}]}, {"text": "There are two major approaches to NE recognition: the handcrafted approach) and the statistical approach).", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.9863599240779877}]}, {"text": "In the first approach, a system usually relies on a large number of handcrafted rules.", "labels": [], "entities": []}, {"text": "This kind of systems can be rapid prototyped but are hard to scale up.", "labels": [], "entities": []}, {"text": "In fact, there will be numerous exceptions for most handcrafted rules.", "labels": [], "entities": []}, {"text": "It is generally expensive and impossible to code for every exception we can imagine, not to mention those exceptions we are notable to think of.", "labels": [], "entities": []}, {"text": "Another serious problem with the handcrafted approach is that systems are hard to be ported across different domains and different languages.", "labels": [], "entities": []}, {"text": "Porting a handcrafted system usually means rewriting all its rules.", "labels": [], "entities": [{"text": "Porting", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.947687029838562}]}, {"text": "Therefore, the statistical approach is becoming more and more popular because of its costeffectiveness in scaling up and porting systems.", "labels": [], "entities": []}, {"text": "In general, the statistical approach to NE recognition can be viewed as a two-stage process.", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 40, "end_pos": 54, "type": "TASK", "confidence": 0.9901590347290039}]}, {"text": "First, according to dictionaries and/or pattern matching rules, the input text is tokenized into tokens.", "labels": [], "entities": []}, {"text": "Each token maybe a word or an NE candidate which can consist of more than one word.", "labels": [], "entities": []}, {"text": "Then, the most likely token sequence is selected according to a statistical model, such as Markov model or maximum entropy model.", "labels": [], "entities": []}, {"text": "Although, the statistical NE recognition is much more scalable and portable, its performance is still not satisfactory.", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 26, "end_pos": 40, "type": "TASK", "confidence": 0.8484784662723541}]}, {"text": "The insufficient coverage/precision of pattern matching rules and unknown words are the major sources of errors.", "labels": [], "entities": [{"text": "coverage", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9635776281356812}, {"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9876012802124023}, {"text": "pattern matching rules", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.7512225608030955}]}, {"text": "Furthermore, the role of the statistical model is to assess the relative possibilities of all possible token sequences and select the most probable one.", "labels": [], "entities": []}, {"text": "The scores obtained from the statistical model can be used fora comparison of competing token sequences, but not for an assessment of the probability that a spotted named entity is correct.", "labels": [], "entities": []}, {"text": "To reduce the recognition errors, we propose a probabilistic verification model to verify the correctness of a named entity.", "labels": [], "entities": []}, {"text": "This model assesses the confidence level of a named entity candidate not only according to the candidate's structure but also according to its contexts.", "labels": [], "entities": []}, {"text": "In our design, the clues for confidence measurement are collected from both positive and negative examples in the training data.", "labels": [], "entities": []}, {"text": "Therefore, the confidence measure has strong discriminant power for judging the correctness of a named entity.", "labels": [], "entities": []}, {"text": "In the experiments of Chinese personal name recognition, the proposed verification model increases the F-measure from 86.5% to 94.4%, which corresponds to 58.5% error reduction rate, where \"error rate\" is defined as \"100% F-measure \u2212 \".", "labels": [], "entities": [{"text": "Chinese personal name recognition", "start_pos": 22, "end_pos": 55, "type": "TASK", "confidence": 0.5967202186584473}, {"text": "F-measure", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.9984466433525085}, {"text": "error reduction rate", "start_pos": 161, "end_pos": 181, "type": "METRIC", "confidence": 0.9698387980461121}, {"text": "error rate", "start_pos": 190, "end_pos": 200, "type": "METRIC", "confidence": 0.9687074720859528}, {"text": "F-measure", "start_pos": 222, "end_pos": 231, "type": "METRIC", "confidence": 0.9509879946708679}]}], "datasetContent": [{"text": "The proposed named entity verification method is used to recognize Chinese personal names from news.", "labels": [], "entities": []}, {"text": "In Chinese, most of the personal names consist of three Chinese characters.", "labels": [], "entities": []}, {"text": "The first character is a surname.", "labels": [], "entities": []}, {"text": "The last two characters area given name.", "labels": [], "entities": []}, {"text": "Therefore, our preliminary experiments are focused on recognizing the personal names of three Chinese characters.", "labels": [], "entities": [{"text": "recognizing the personal names", "start_pos": 54, "end_pos": 84, "type": "TASK", "confidence": 0.817683607339859}]}, {"text": "In our experiments, the training corpus consists of about 14,339,000 Chinese characters collected from economy and industry news.", "labels": [], "entities": []}, {"text": "This corpus should be annotated to estimate the probabilistic parameters of the scoring functions methods that can be bootstrapped from a little seed data or a few seed rules) are highly demanded to automatically annotate the training data.", "labels": [], "entities": []}, {"text": "In the following section, we propose an EM-style bootstrapping procedure) for annotating the training data automatically.", "labels": [], "entities": []}, {"text": "Both the baseline model and the proposed name entity verification model (named NEV model) are tested on the same testing corpus.", "labels": [], "entities": []}, {"text": "The testing corpus, also collected from economy and industry news, consists of about 737,000 characters.", "labels": [], "entities": []}, {"text": "This corpus is annotated manually and contains totally 2,545 Chinese personal names.", "labels": [], "entities": []}, {"text": "The F-measure of the baseline model is 86.5% (as indicated by the dashed line in).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9989017248153687}]}, {"text": "The precision and recall rates of the baseline model are 79.1% and 95.5% respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9998286962509155}, {"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9996089339256287}]}, {"text": "Although the recall rate of the baseline model is high, the precision rate is pretty low.", "labels": [], "entities": [{"text": "recall rate", "start_pos": 13, "end_pos": 24, "type": "METRIC", "confidence": 0.9877218902111053}, {"text": "precision rate", "start_pos": 60, "end_pos": 74, "type": "METRIC", "confidence": 0.9930645227432251}]}, {"text": "Over 20% of the name candidates proposed by the baseline model are incorrect.", "labels": [], "entities": []}, {"text": "In our experiments, the sizes of the leftand right-context windows of the NEV model are set to 2.", "labels": [], "entities": []}, {"text": "In, the solid line with triangle markers depicts the F-measure of the NEV model versus the iteration number of bootstrapping.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9987725615501404}]}, {"text": "The F-measure saturates after 3 iterations.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9755668044090271}]}, {"text": "After 4 iterations, the F-measure of the NEV model reaches 94.4%.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9988478422164917}]}, {"text": "The corresponding precision and recall rates are 96.4% and 92.5% respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.999765932559967}, {"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9990146160125732}]}, {"text": "Compared with the baseline model, the precision rate is greatly improved from 79.1% to 96.4% with a little sacrifice in recall rate.", "labels": [], "entities": [{"text": "precision rate", "start_pos": 38, "end_pos": 52, "type": "METRIC", "confidence": 0.9647822380065918}, {"text": "recall rate", "start_pos": 120, "end_pos": 131, "type": "METRIC", "confidence": 0.9764525294303894}]}, {"text": "The F-measure is improved from 86.5% to 94.4%, which corresponds to 58.5% error reduction rate, where \"error rate\" is defined as \"100% F-measure \u2212 \".", "labels": [], "entities": [{"text": "F-measure", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9985692501068115}, {"text": "error reduction rate", "start_pos": 74, "end_pos": 94, "type": "METRIC", "confidence": 0.9475558201471964}, {"text": "error rate\"", "start_pos": 103, "end_pos": 114, "type": "METRIC", "confidence": 0.9698017835617065}, {"text": "F-measure", "start_pos": 135, "end_pos": 144, "type": "METRIC", "confidence": 0.9623851180076599}]}, {"text": "lists three examples of the misrecognized names made by the baseline model.", "labels": [], "entities": []}, {"text": "These examples clearly show that the baseline model tends to incorrectly group consecutive single characters, either from unknown words or single-character words, into names.", "labels": [], "entities": []}, {"text": "In the first two examples, the single characters come from the unknown location name \",(ga luo lai na; Carolina) and the unknown company name \"(luo ji; Logitech)\".", "labels": [], "entities": []}, {"text": "The single characters in the last example are single-character words \"\ud97b\udf59(gi; quarter)\", \"\ud97b\udf59(quan; all)\" and \"Z (mei; USA)\".", "labels": [], "entities": []}, {"text": "Without the inadequate strong tendency of grouping single characters, the NEV model is able to avoid the misrecognition errors made by the baseline model.", "labels": [], "entities": []}, {"text": "The NEV model assesses the confidence measure of each name candidate according to the context around the candidate.", "labels": [], "entities": [{"text": "NEV", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.691253125667572}]}, {"text": "In, the name candidates in the shaded boxes are rejected by the NEV model because   To sum up, the experimental results demonstrate that the contextual information, either from positive examples or from negative examples, is very helpful for named entity verification.", "labels": [], "entities": [{"text": "named entity verification", "start_pos": 242, "end_pos": 267, "type": "TASK", "confidence": 0.6464898884296417}]}, {"text": "Besides, the superiority of the NEV model also shows that the proposed probabilistic score functions NE ( ) S \u22c5 and anti-NE ( ) S \u22c5 are effective in providing the scores to produce a reliable confidence measure.", "labels": [], "entities": []}, {"text": "Especially, the proposed named entity verification approach does not require any dictionary in advance.", "labels": [], "entities": [{"text": "named entity verification", "start_pos": 25, "end_pos": 50, "type": "TASK", "confidence": 0.6157180666923523}]}], "tableCaptions": [{"text": " Table 1: Number of distinct names in  the name corpus and total frequency  of names in the annotated news dur- ing the bootstrapping iteration.", "labels": [], "entities": []}]}