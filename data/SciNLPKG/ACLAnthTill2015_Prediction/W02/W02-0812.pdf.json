{"title": [{"text": "Evaluating the Effectiveness of Ensembles of Decision Trees in Disambiguating Senseval Lexical Samples", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents an evaluation of an ensemble-based system that participated in the English and Spanish lexical sample tasks of SENSEVAL-2.", "labels": [], "entities": []}, {"text": "The system combines decision trees of unigrams, bigrams, and co-occurrences into a single classi-fier.", "labels": [], "entities": []}, {"text": "The analysis is extended to include the SENSEVAL-1 data.", "labels": [], "entities": [{"text": "SENSEVAL-1 data", "start_pos": 40, "end_pos": 55, "type": "DATASET", "confidence": 0.7253710329532623}]}], "introductionContent": [{"text": "There were eight Duluth systems that participated in the English and Spanish lexical sample tasks of SENSEVAL-2.", "labels": [], "entities": []}, {"text": "These systems were all based on the combination of lexical features with standard machine learning algorithms.", "labels": [], "entities": []}, {"text": "The most accurate of these systems proved to be Duluth3 for English and Duluth8 for Spanish.", "labels": [], "entities": []}, {"text": "These only differ with respect to minor language specific issues, so we refer to them generically as Duluth38, except when the language distinction is important.", "labels": [], "entities": [{"text": "Duluth38", "start_pos": 101, "end_pos": 109, "type": "DATASET", "confidence": 0.9438794851303101}]}, {"text": "Duluth38 is an ensemble approach that assigns a sense to an instance of an ambiguous word by taking a vote among three bagged decision trees.", "labels": [], "entities": [{"text": "Duluth38", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9472531676292419}]}, {"text": "Each tree is learned from a different view of the training examples associated with the target word.", "labels": [], "entities": []}, {"text": "Each view of the training examples is based on one of the following three types of lexical features: single words, two word sequences that occur anywhere within the context of the word being disambiguated, and two word sequences made up of this target word and another word within one or two positions.", "labels": [], "entities": []}, {"text": "These features are referred to as unigrams, bigrams, and cooccurrences.", "labels": [], "entities": []}, {"text": "The focus of this paper is on determining if the member classifiers in the Duluth38 ensemble are complementary or redundant with each other and with other participating systems.", "labels": [], "entities": [{"text": "Duluth38 ensemble", "start_pos": 75, "end_pos": 92, "type": "DATASET", "confidence": 0.9254172146320343}]}, {"text": "Two classifiers are complementary if they disagree on a substantial number of disambiguation decisions and yet attain comparable levels of overall accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.9952567219734192}]}, {"text": "Classifiers are redundant if they arrive at the same disambiguation decisions for most instances of the ambiguous word.", "labels": [], "entities": []}, {"text": "There is little advantage in creating an ensemble of redundant classifiers, since they will make the same disambiguation decisions collectively as they would individually.", "labels": [], "entities": []}, {"text": "An ensemble can only improve upon the accuracy of its member classifiers if they are complementary to each other, and the errors of one classifier are offset by the correct judgments of others.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9975428581237793}]}, {"text": "This paper continues with a description of the lexical features that makeup the Duluth38 system, and then profiles the SENSEVAL-1 and SENSEVAL-2 lexical sample data that is used in this evaluation.", "labels": [], "entities": [{"text": "Duluth38 system", "start_pos": 80, "end_pos": 95, "type": "DATASET", "confidence": 0.9612494111061096}, {"text": "SENSEVAL-1", "start_pos": 119, "end_pos": 129, "type": "METRIC", "confidence": 0.7874467968940735}, {"text": "SENSEVAL-2 lexical sample data", "start_pos": 134, "end_pos": 164, "type": "DATASET", "confidence": 0.7159839197993279}]}, {"text": "There are two types of analysis presented.", "labels": [], "entities": []}, {"text": "First, the accuracy of the member classifiers in the Duluth38 ensemble are evaluated individually and in pairwise combinations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.998944103717804}, {"text": "Duluth38 ensemble", "start_pos": 53, "end_pos": 70, "type": "DATASET", "confidence": 0.9473413825035095}]}, {"text": "Second, the agreement between Duluth38 and the top two participating systems in SENSEVAL-1 and SENSEVAL-2 is compared.", "labels": [], "entities": [{"text": "SENSEVAL-2", "start_pos": 95, "end_pos": 105, "type": "DATASET", "confidence": 0.8220136165618896}]}, {"text": "This paper concludes with a review of the origins of our approach.", "labels": [], "entities": []}, {"text": "Since the focus here is on analysis, implementation level details are not extensively discussed.", "labels": [], "entities": []}, {"text": "Such descriptions can be found in or).", "labels": [], "entities": []}], "datasetContent": [{"text": "The English lexical sample for SENSEVAL-1 is made up of 35 words, six of which are used in multiple parts of speech.", "labels": [], "entities": [{"text": "SENSEVAL-1", "start_pos": 31, "end_pos": 41, "type": "TASK", "confidence": 0.7669138312339783}]}, {"text": "The training examples have been manually annotated based on the HECTOR sense inventory.", "labels": [], "entities": [{"text": "HECTOR sense inventory", "start_pos": 64, "end_pos": 86, "type": "DATASET", "confidence": 0.7926420172055563}]}, {"text": "There are 12,465 training examples, and 7,448 test instances.", "labels": [], "entities": []}, {"text": "This corresponds to what is known as the trainable lexical sample in the SENSEVAL-1 official results.", "labels": [], "entities": []}, {"text": "The English lexical sample for SENSEVAL-2 consists of 73 word types, each of which is associated with a single part of speech.", "labels": [], "entities": [{"text": "SENSEVAL-2", "start_pos": 31, "end_pos": 41, "type": "TASK", "confidence": 0.8089058995246887}]}, {"text": "There are 8,611 sense-tagged examples provided for training, where each instance has been manually assigned a WordNet sense.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 110, "end_pos": 117, "type": "DATASET", "confidence": 0.9231565594673157}]}, {"text": "The evaluation data for the English lexical sample consists of 4,328 held out test instances.", "labels": [], "entities": [{"text": "English lexical sample", "start_pos": 28, "end_pos": 50, "type": "DATASET", "confidence": 0.7666775186856588}]}, {"text": "The Spanish lexical sample for SENSEVAL-2 consists of 39 word types.", "labels": [], "entities": [{"text": "SENSEVAL-2", "start_pos": 31, "end_pos": 41, "type": "TASK", "confidence": 0.6607365012168884}]}, {"text": "There are 4,480 training examples that have been manually tagged with senses from Euro-WordNet.", "labels": [], "entities": [{"text": "Euro-WordNet", "start_pos": 82, "end_pos": 94, "type": "DATASET", "confidence": 0.9863189458847046}]}, {"text": "The evaluation data consists of 2,225 test instances.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy in Lexical Sample Tasks  system  accuracy correct", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9925803542137146}, {"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9965347051620483}]}, {"text": " Table 2: System Pairwise Agreement  system pair  both  one  zero", "labels": [], "entities": []}]}