{"title": [{"text": "Combining Outputs of Multiple Japanese Named Entity Chunkers by Stacking", "labels": [], "entities": [{"text": "Stacking", "start_pos": 64, "end_pos": 72, "type": "TASK", "confidence": 0.6813324093818665}]}], "abstractContent": [{"text": "In this paper, we propose a method for learning a classifier which combines outputs of more than one Japanese named entity extractors.", "labels": [], "entities": []}, {"text": "The proposed combination method belongs to the family of stacked generalizers, which is in principle a technique of combining outputs of several classifiers at the first stage by learning a second stage classifier to combine those outputs at the first stage.", "labels": [], "entities": []}, {"text": "Individual models to be combined are based on maximum entropy models, one of which always considers surrounding contexts of a fixed length, while the other considers those of variable lengths according to the number of constituent morphemes of named entities.", "labels": [], "entities": []}, {"text": "As an algorithm for learning the second stage classifier, we employ a decision list learning method.", "labels": [], "entities": []}, {"text": "Experimental evaluation shows that the proposed method achieves improvement over the best known results with Japanese named entity extractors based on maximum en-tropy models.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the recent corpus-based NLP research, system combination techniques have been successfully applied to several tasks such as parts-of-speech tagging), base noun phrase chunking), and parsing ().", "labels": [], "entities": [{"text": "parts-of-speech tagging", "start_pos": 127, "end_pos": 150, "type": "TASK", "confidence": 0.7150609791278839}, {"text": "base noun phrase chunking", "start_pos": 153, "end_pos": 178, "type": "TASK", "confidence": 0.5948807299137115}, {"text": "parsing", "start_pos": 185, "end_pos": 192, "type": "TASK", "confidence": 0.9765823483467102}]}, {"text": "The aim of system combination is to combine portions of the individual systems' outputs which are partial but can be regarded as highly accurate.", "labels": [], "entities": []}, {"text": "The process of system combination can be decomposed into the following two sub-processes: 1.", "labels": [], "entities": []}, {"text": "Collect systems which behave as differently as possible: it would help a lot if at least the collected systems tend to make errors of different types, because simple voting technique can identify correct outputs.", "labels": [], "entities": []}, {"text": "Previously studied techniques for collecting such systems include: i) using several existing real systems), ii) bagging/boosting techniques), and iii) switching the data expression and obtaining several models).", "labels": [], "entities": []}, {"text": "2. Combine the outputs of the several systems: previously studied techniques include: i) voting techniques), ii) switching among several systems according to confidence values they provide), iii) stacking techniques which train a second stage classifier for combining outputs of classifiers at the first stage).", "labels": [], "entities": []}, {"text": "In this paper, we propose a method for combining outputs of (Japanese) named entity chunkers, which belongs to the family of stacking techniques.", "labels": [], "entities": []}, {"text": "In the sub-process 1, we focus on models which differ in the lengths of preceding/subsequent contexts to be incorporated in the models.", "labels": [], "entities": []}, {"text": "As the base model for supervised learning of Japanese named entity chunking, we employ a model based on the maximum entropy model (), which performed the best in IREX (Information Retrieval and Extraction Exercise) Workshop (IREX Committee, 1999) among those based on machine learning techniques.", "labels": [], "entities": [{"text": "supervised learning of Japanese named entity chunking", "start_pos": 22, "end_pos": 75, "type": "TASK", "confidence": 0.5921403169631958}, {"text": "IREX", "start_pos": 162, "end_pos": 166, "type": "METRIC", "confidence": 0.7214483022689819}, {"text": "Information Retrieval and Extraction Exercise) Workshop (IREX Committee, 1999)", "start_pos": 168, "end_pos": 246, "type": "TASK", "confidence": 0.7451031804084778}]}, {"text": "reported that the optimal number of preceding/subsequent contexts to be incorporated in the model is two morphemes to both left and right from the current position.", "labels": [], "entities": []}, {"text": "In this paper, we train several maximum entropy models which differ in the lengths of preceding/subsequent contexts, and then combine their outputs.", "labels": [], "entities": []}, {"text": "As the sub-process 2, we propose to apply a stacking technique which learns a classifier for combining outputs of several named entity chunkers.", "labels": [], "entities": []}, {"text": "This second stage classifier learns rules for accepting/rejecting outputs of several individual named entity chunkers.", "labels": [], "entities": []}, {"text": "The proposed method can be applied to the cases where the number of constituent systems is quite small (e.g., two).", "labels": [], "entities": []}, {"text": "Actually, in the experimental evaluation, we show that the results of combining the best performing model of with the one which performs poorly but extracts named entities quite different from those of the best performing model can help improve the performance of the best model.", "labels": [], "entities": []}], "datasetContent": [{"text": "We experimentally evaluate the performance of the proposed system combination method using the IREX workshop's training and test data.", "labels": [], "entities": [{"text": "IREX workshop's training and test data", "start_pos": 95, "end_pos": 133, "type": "DATASET", "confidence": 0.8970028502600533}]}], "tableCaptions": [{"text": " Table 1: Statistics of NE Types of IREX", "labels": [], "entities": [{"text": "IREX", "start_pos": 36, "end_pos": 40, "type": "TASK", "confidence": 0.3770931363105774}]}, {"text": " Table 3: Performance of Individual Models against  T s (F-measure (\u03b2 = 1) (%))", "labels": [], "entities": [{"text": "F-measure", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9942818880081177}]}, {"text": " Table 4: Difference between 5-gram model and  Other Individual Models (Recall of the Union /  Overlap Rate of Over-generated Entities) (%)", "labels": [], "entities": [{"text": "Recall of the Union /  Overlap Rate of Over-generated Entities)", "start_pos": 72, "end_pos": 135, "type": "METRIC", "confidence": 0.7349655546925284}]}, {"text": " Table 5: Performance of Combining 5-gram model  and Other Individual Models (against T s, F-measure  (\u03b2 = 1) (%))", "labels": [], "entities": [{"text": "F-measure", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9829995036125183}]}, {"text": " Table 6: Evaluation Results of Combining System Outputs, per # of constituent morphemes  (T rI = T rC = D CRL , F-measure (\u03b2 = 1) / Recall / Precision (%))", "labels": [], "entities": [{"text": "T rI = T rC = D CRL", "start_pos": 91, "end_pos": 110, "type": "METRIC", "confidence": 0.7212846353650093}, {"text": "F-measure", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.9776750206947327}, {"text": "Recall", "start_pos": 133, "end_pos": 139, "type": "METRIC", "confidence": 0.9877510070800781}, {"text": "Precision", "start_pos": 142, "end_pos": 151, "type": "METRIC", "confidence": 0.9162262082099915}]}, {"text": " Table 7: Evaluation Results of Combining System Outputs, per NE type  (T rI = T rC = D CRL , F-measure (\u03b2 = 1) (Recall, Precision) (%))", "labels": [], "entities": [{"text": "T rI = T rC = D CRL", "start_pos": 72, "end_pos": 91, "type": "METRIC", "confidence": 0.7670941576361656}, {"text": "F-measure", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9824032783508301}, {"text": "Recall", "start_pos": 113, "end_pos": 119, "type": "METRIC", "confidence": 0.9251199960708618}, {"text": "Precision", "start_pos": 121, "end_pos": 130, "type": "METRIC", "confidence": 0.8849440813064575}]}]}