{"title": [{"text": "Using the Web to Overcome Data Sparseness", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper shows that the web can be employed to obtain frequencies for bigrams that are unseen in a given corpus.", "labels": [], "entities": []}, {"text": "We describe a method for retrieving counts for adjective-noun, noun-noun, and verb-object bigrams from the web by querying a search engine.", "labels": [], "entities": []}, {"text": "We evaluate this method by demonstrating that web frequencies and correlate with frequencies obtained from a carefully edited, balanced corpus.", "labels": [], "entities": []}, {"text": "We also perform a task-based evaluation, showing that web frequencies can reliably predict human plausibility judgments.", "labels": [], "entities": []}], "introductionContent": [{"text": "In two recent papers, criticize the fact that current NLP algorithms are typically optimized, tested, and compared on fairly small data sets (corpora with millions of words), even though data sets several orders of magnitude larger are available, at least for some tasks.", "labels": [], "entities": []}, {"text": "Banko and Brill goon to demonstrate that learning algorithms typically used for NLP tasks benefit significantly from larger training sets, and their performance shows no sign of reaching an asymptote as the size of the training set increases.", "labels": [], "entities": []}, {"text": "Arguably, the largest data set that is available for NLP is the web, which currently consists of at least 968 million pages.", "labels": [], "entities": []}, {"text": "Data retrieved from the web therefore provides enormous potential for training NLP algorithms, if Banko and Brill's findings generalize.", "labels": [], "entities": []}, {"text": "There is a small body of existing research that tries to harness the potential of the web for NLP. and use the web to generate corpora for languages where electronic resources are scarce, while Resnik (1999) describes a method for mining the web for bilingual texts. and use the web for word sense disambiguation, and proposes a method for resolving PP attachment ambiguities based on web data.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 287, "end_pos": 312, "type": "TASK", "confidence": 0.7406138777732849}, {"text": "PP attachment ambiguities", "start_pos": 350, "end_pos": 375, "type": "TASK", "confidence": 0.8177008430163065}]}, {"text": "A particularly interesting application is proposed by, who uses the web for example-based machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.732467383146286}]}, {"text": "His task is to translate compounds from French into English, with corpus evidence serving as a filter for candidate translations.", "labels": [], "entities": []}, {"text": "As an example consider the French compound groupe de travail.", "labels": [], "entities": []}, {"text": "There are five translation of groupe and three translations for travail (in the dictionary that Grefenstette (1998) is using), resulting in 15 possible candidate translations.", "labels": [], "entities": []}, {"text": "Only one of them, viz., work group has a high corpus frequency, which makes it likely that this is the correct translation into English.", "labels": [], "entities": []}, {"text": "observes that this approach suffers from an acute data sparseness problem if the corpus counts are obtained from a conventional corpus such as the British National Corpus (BNC).", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 147, "end_pos": 176, "type": "DATASET", "confidence": 0.9737277030944824}]}, {"text": "However, as demonstrates, this problem can be overcome by obtaining counts through web searches, instead of relying on the BNC.", "labels": [], "entities": [{"text": "BNC", "start_pos": 123, "end_pos": 126, "type": "DATASET", "confidence": 0.9095799922943115}]}, {"text": "therefore effectively uses the web as away of obtaining counts for compounds that are sparse in the BNC.", "labels": [], "entities": [{"text": "BNC", "start_pos": 100, "end_pos": 103, "type": "DATASET", "confidence": 0.9394071698188782}]}, {"text": "While this is an important initial result, it raises the question of the generality of the proposed approach to overcoming data sparseness.", "labels": [], "entities": []}, {"text": "It remains to be shown that web counts are generally useful for approximating data that is sparse or unseen in a given corpus.", "labels": [], "entities": []}, {"text": "It seems possible, for instance, that results are limited to his particular task (filtering potential translations) or to his particular linguistic phenomenon (noun-noun compounds).", "labels": [], "entities": [{"text": "filtering potential translations)", "start_pos": 82, "end_pos": 115, "type": "TASK", "confidence": 0.7972300201654434}]}, {"text": "Another potential problem is the fact that web counts are far more noisy than counts obtained from a well-edited, carefully balanced corpus such as the BNC.", "labels": [], "entities": [{"text": "BNC", "start_pos": 152, "end_pos": 155, "type": "DATASET", "confidence": 0.9513533711433411}]}, {"text": "The effect of this noise on the usefulness of the web counts is largely unexplored.", "labels": [], "entities": []}, {"text": "The aim of the present paper is to generalize findings by testing the hypothesis that the web can be employed to obtain frequencies for bigrams that are unseen in a given corpus.", "labels": [], "entities": []}, {"text": "Instead of having a particular task in mind (which would introduce a sampling bias), we rely on sets of bigrams that are randomly selected from the corpus.", "labels": [], "entities": []}, {"text": "We use a web-based approach not only for nounnoun bigrams, but also for adjective-noun and verbobject bigrams, so as to explore whether this approach generalizes to different predicate-argument combinations.", "labels": [], "entities": []}, {"text": "We evaluate our web counts in two different ways: (a) comparison with actual corpus frequencies, and (b) task-based evaluation (predicting human plausibility judgments).", "labels": [], "entities": []}], "datasetContent": [{"text": "While the procedure for obtaining web counts described in Section 2.2 is very straightforward, it also has obvious limitations.", "labels": [], "entities": []}, {"text": "Most importantly, it is based on bigrams formed by adjacent words, and fails to take syntactic variants into account (other than intervening determiners for verb-object bigrams).", "labels": [], "entities": []}, {"text": "In the case of Google, there is also the problem that the counts are based on the number of matching pages, not the number of matching words.", "labels": [], "entities": []}, {"text": "Finally, there is the problem that web data is very noisy and unbalanced compared to a carefully edited corpus like the BNC.", "labels": [], "entities": [{"text": "BNC", "start_pos": 120, "end_pos": 123, "type": "DATASET", "confidence": 0.9398216009140015}]}, {"text": "Given these limitations, it is necessary to explore if there is a reliable relationship between web counts and BNC counts.", "labels": [], "entities": []}, {"text": "Once this is assured, we can explore the usefulness of web counts for overcoming data sparseness.", "labels": [], "entities": []}, {"text": "We carried out a correlation analysis to determine if there is a linear relationship between the BNC counts and Altavista and Google counts.", "labels": [], "entities": [{"text": "BNC counts", "start_pos": 97, "end_pos": 107, "type": "DATASET", "confidence": 0.5985763370990753}]}, {"text": "The results of this analysis are listed in Table 5.", "labels": [], "entities": []}, {"text": "All correlation coefficients reported in this paper refer to Pearson's rand were computed on logtransformed counts.", "labels": [], "entities": [{"text": "correlation", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9566616415977478}, {"text": "Pearson's rand", "start_pos": 61, "end_pos": 75, "type": "DATASET", "confidence": 0.8529476324717203}]}, {"text": "A  heuristics (see (1)-) are sufficient to obtain useful frequencies from the web.", "labels": [], "entities": []}, {"text": "It seems that the large amount of data available for web counts outweighs the associated problems (noisy, unbalanced, etc.).", "labels": [], "entities": []}, {"text": "Note that the highest coefficients were obtained for adjective-noun bigrams, which probably indicates that this type of predicate-argument relationship is least subject to syntactic variation and thus least affected by the simplifications of our search heuristics.", "labels": [], "entities": []}, {"text": "Previous work has demonstrated that corpus counts correlate with human plausibility judgments for adjective-noun bigrams.", "labels": [], "entities": []}, {"text": "This results holds for both seen bigrams () and for unseen bigrams whose counts were recreated using smoothing techniques ().", "labels": [], "entities": []}, {"text": "Based on these findings, we decided to evaluate our web counts on the task of predicting plausibility ratings.", "labels": [], "entities": [{"text": "predicting plausibility ratings", "start_pos": 78, "end_pos": 109, "type": "TASK", "confidence": 0.863524854183197}]}, {"text": "If the web counts for bigrams correlate with plausibility judgments, then this indicates that the counts are valid, in the sense of being useful for predicting intuitive plausibility. and collected plausibility ratings for 90 seen and 90 unseen adjective-noun bigrams (see Section 2.1) using magnitude estimation.", "labels": [], "entities": []}, {"text": "Magnitude estimation is an experimental technique standardly used in psychophysics to measure judgments of sensory stimuli, which and have applied to the elicitation of linguistic judgments.", "labels": [], "entities": [{"text": "Magnitude estimation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8097095489501953}]}, {"text": "Magnitude estimation requires subjects to assign numbers to a series of linguistic stimuli in a proportional fashion.", "labels": [], "entities": [{"text": "Magnitude estimation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9654466807842255}]}, {"text": "Subjects are first exposed to a modulus item, which they assign an arbitrary number.", "labels": [], "entities": []}, {"text": "All other stimuli are rated proportional to the modulus.", "labels": [], "entities": []}, {"text": "In the experiments conducted by and, native speakers of English were presented with adjectivenoun bigrams and were asked to rate the degree of adjective-noun fit proportional to the modulus item.", "labels": [], "entities": []}, {"text": "The resulting judgments were normalized by dividing them by the modulus value and by logtransforming them.", "labels": [], "entities": []}, {"text": "report a correlation of .570 between mean plausibility judgments and BNC counts for the seen adjectivenoun bigrams.", "labels": [], "entities": [{"text": "BNC counts", "start_pos": 69, "end_pos": 79, "type": "METRIC", "confidence": 0.9817796647548676}]}, {"text": "For unseen adjective-noun bigrams, found a correlation of .356 between mean judgments and frequencies recreated using class-based smoothing.", "labels": [], "entities": []}, {"text": "In the present study, we used the plausibility judgments collected by and for adjective-noun bigrams and conducted additional experiments to obtain nounnoun and verb-object judgments for the materials described in Section 2.1.", "labels": [], "entities": []}, {"text": "We used the same experimental procedure as the original study (see and for details).", "labels": [], "entities": []}, {"text": "Four experiments were carried out, one each for seen and unseen noun-noun bigrams, and for seen and unseen verb-object bigrams.", "labels": [], "entities": []}, {"text": "Unlike the adjective-noun and the noun-noun bigrams, the verb-object bigrams were not presented to subjects in isolation, but embedded in a minimal sentence context involving a proper name as the subject (e.g., Paul fulfilled the obligation).", "labels": [], "entities": []}, {"text": "The experiments were conducted over the web using the WebExp software package (.", "labels": [], "entities": []}, {"text": "A series of previous studies has shown that data obtained using WebExp closely replicates results obtained in a controlled laboratory setting; this was demonstrated for acceptability judgments), co-reference judgments (, and sentence completions ().", "labels": [], "entities": [{"text": "sentence completions", "start_pos": 225, "end_pos": 245, "type": "TASK", "confidence": 0.7155644446611404}]}, {"text": "These references also provide a detailed discussion of the WebExp experimental setup.", "labels": [], "entities": [{"text": "WebExp experimental setup", "start_pos": 59, "end_pos": 84, "type": "DATASET", "confidence": 0.9266911943753561}]}, {"text": "lists the descriptive statistics for all six judgment experiments: the original experiments by and for adjective-noun bigrams, and our new ones for nounnoun and verb-object bigrams.", "labels": [], "entities": []}, {"text": "We used correlation analysis to compare web counts with plausibility judgments for seen adjective-noun, noun-noun, and verb-object bigrams.: Descriptive statistics for plausibility judgments (log-transformed); N is the number of subjects used in each experiment ing log-transformed web and BNC counts with log-transformed plausibility judgments.", "labels": [], "entities": [{"text": "BNC", "start_pos": 290, "end_pos": 293, "type": "METRIC", "confidence": 0.9878458380699158}]}, {"text": "The results show that both Altavista and Google counts correlate with plausibility judgments for seen bigrams.", "labels": [], "entities": []}, {"text": "Google slightly outperforms Altavista: the correlation coefficient for Google ranges from .624 to .693, while for Altavista, it ranges from .638 to .685.", "labels": [], "entities": [{"text": "correlation coefficient", "start_pos": 43, "end_pos": 66, "type": "METRIC", "confidence": 0.9741292893886566}]}, {"text": "A surprising result is that the web counts consistently achieve a higher correlation with the judgments than the BNC counts, which range from .488 to .569.", "labels": [], "entities": [{"text": "BNC counts", "start_pos": 113, "end_pos": 123, "type": "DATASET", "confidence": 0.7938637435436249}]}, {"text": "We carried out a series of one-tailed t-tests to determine if the differences between the correlation coefficients for the web counts and the correlation coefficients for the BNC counts were significant.", "labels": [], "entities": [{"text": "BNC counts", "start_pos": 175, "end_pos": 185, "type": "DATASET", "confidence": 0.8627903759479523}]}, {"text": "For the adjective-noun bigrams, the difference between the BNC coefficient and the Altavista coefficient failed to reach significance (t(87) = 1.46, p > .05), while the Google coefficient was significantly higher than the BNC coefficient (t(87) = 1.78, p < .05).", "labels": [], "entities": [{"text": "BNC coefficient", "start_pos": 59, "end_pos": 74, "type": "DATASET", "confidence": 0.7701242566108704}, {"text": "significance", "start_pos": 121, "end_pos": 133, "type": "METRIC", "confidence": 0.9684015512466431}, {"text": "BNC coefficient", "start_pos": 222, "end_pos": 237, "type": "DATASET", "confidence": 0.8206898272037506}]}, {"text": "For the noun-noun bigrams, both the Altavista and the Google coefficients were significantly higher than the BNC coefficient (t(87) = 2.94, p < .01 and t(87) = 3.06, p < .01).", "labels": [], "entities": [{"text": "BNC coefficient", "start_pos": 109, "end_pos": 124, "type": "DATASET", "confidence": 0.6326136291027069}]}, {"text": "Also for the verb-object bigrams, both the Altavista coefficient and the Google coefficient were significantly higher than the BNC coefficient (t(87) = 2.21, p < .05 and t(87) = 2.25, p < .05).", "labels": [], "entities": [{"text": "Google coefficient", "start_pos": 73, "end_pos": 91, "type": "METRIC", "confidence": 0.5573334395885468}, {"text": "BNC coefficient", "start_pos": 127, "end_pos": 142, "type": "DATASET", "confidence": 0.6669699251651764}]}, {"text": "In sum, for all three types of bigrams, the correlation coefficients achieved with Google were significantly higher than the ones achieved with the BNC.", "labels": [], "entities": [{"text": "correlation", "start_pos": 44, "end_pos": 55, "type": "METRIC", "confidence": 0.9823212623596191}, {"text": "BNC", "start_pos": 148, "end_pos": 151, "type": "DATASET", "confidence": 0.966113269329071}]}, {"text": "For Altavista, the noun-noun and the verbobject coefficients were higher than the coefficients obtained from the BNC.", "labels": [], "entities": [{"text": "BNC", "start_pos": 113, "end_pos": 116, "type": "DATASET", "confidence": 0.8716232776641846}]}, {"text": "(bottom half) lists the correlations coefficients obtained by comparing log-transformed judgments with log-transformed web counts for unseen adjective-noun, noun-noun, and verb-object bigrams.", "labels": [], "entities": []}, {"text": "We observe that the web counts consistently show a significant correlation with the judgments, the coefficient ranging from .466 to .588 for Al-  Note that a small number of bigrams produced zero counts even in our web queries; these frequencies were set to one for the correlation analysis (see Section 2.2).", "labels": [], "entities": []}, {"text": "To conclude, this evaluation demonstrated that web counts reliably predict human plausibility judgments, both for seen and for unseen predicateargument bigrams.", "labels": [], "entities": []}, {"text": "In the case of Google counts for seen bigrams, we were also able to show that web counts area better predictor of human judgments than BNC counts.", "labels": [], "entities": []}, {"text": "These results show that our heuristic method yields useful frequencies; the simplifications we made in obtaining the counts, as well as the fact that web data are noisy, seem to be outweighed by the fact that the web is up to three orders of magnitude larger than the BNC (see our estimate in Section 2.2).", "labels": [], "entities": [{"text": "BNC", "start_pos": 268, "end_pos": 271, "type": "DATASET", "confidence": 0.9054284691810608}]}], "tableCaptions": [{"text": " Table 2: Number of zero counts returned by the  queries to search engines (unseen bigrams)", "labels": [], "entities": [{"text": "Number of zero counts", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.8991183042526245}]}, {"text": " Table 1: Example stimuli for seen and unseen noun-noun and verb-object bigrams (with log-transformed  BNC counts)", "labels": [], "entities": [{"text": "BNC counts", "start_pos": 103, "end_pos": 113, "type": "METRIC", "confidence": 0.9097852408885956}]}, {"text": " Table 3: Descriptive statistics for web counts and BNC counts (log-transformed)", "labels": [], "entities": []}, {"text": " Table 4: Average factor by which the web counts are  larger than the BNC counts (seen bigrams)", "labels": [], "entities": [{"text": "Average", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9926468133926392}]}, {"text": " Table 6: Descriptive statistics for plausibility judgments (log-transformed); N is the number of subjects used  in each experiment", "labels": [], "entities": []}]}