{"title": [{"text": "Improving a general-purpose Statistical Translation Engine by Terminological lexicons", "labels": [], "entities": [{"text": "Improving", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9835366606712341}, {"text": "Statistical Translation Engine", "start_pos": 28, "end_pos": 58, "type": "TASK", "confidence": 0.8513742287953695}]}], "abstractContent": [{"text": "The past decade has witnessed exciting work in the field of Statistical Machine Translation (SMT).", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 60, "end_pos": 97, "type": "TASK", "confidence": 0.9052929480870565}]}, {"text": "However, accurate evaluation of its potential in real-life contexts is still a questionable issue.", "labels": [], "entities": []}, {"text": "In this study, we investigate the behavior of an SMT engine faced with a corpus far different from the one it has been trained on.", "labels": [], "entities": [{"text": "SMT engine", "start_pos": 49, "end_pos": 59, "type": "TASK", "confidence": 0.9291752576828003}]}, {"text": "We show that terminological databases are obvious resources that should be used to boost the performance of a statistical engine.", "labels": [], "entities": []}, {"text": "We propose and evaluate away of integrating terminology into a SMT engine which yields a significant reduction in word error rate.", "labels": [], "entities": [{"text": "SMT", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.9909521341323853}, {"text": "word error rate", "start_pos": 114, "end_pos": 129, "type": "METRIC", "confidence": 0.6399681270122528}]}], "introductionContent": [{"text": "SMT mainly became known to the linguistic community as a result of the seminal work of.", "labels": [], "entities": [{"text": "SMT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9847381114959717}]}, {"text": "Since then, many researchers have invested effort into designing better models than the ones proposed in the aforementioned article and several new exciting ways have been suggested to attack the problem.", "labels": [], "entities": []}, {"text": "For instance, succeeded in overcoming the independence assumption made by IBM models by introducing order-1 Hidden Markov alignment models.", "labels": [], "entities": []}, {"text": "described an elegant way of integrating automatically acquired probabilistic templates into the translation process, and did the same for morphological information.", "labels": [], "entities": []}, {"text": "Radically different statistical models have also been proposed.) investigated maximum entropy models as an alternative to the so-called noisy-channel approach.", "labels": [], "entities": []}, {"text": "Very recently, described a model in which the noisy-channel takes as input a parsed sentence rather than simple words.", "labels": [], "entities": []}, {"text": "While many of these studies include intensive evaluation sections, it is not always easy to determine exactly how well statistical translation can do on a given task.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 119, "end_pos": 142, "type": "TASK", "confidence": 0.7688280344009399}]}, {"text": "We know that on a specific task of spoken language translation, provided evidence that SMT compared favorably to a symbolic translation system; but as mentioned by the author, the comparison was not totally fair.", "labels": [], "entities": [{"text": "spoken language translation", "start_pos": 35, "end_pos": 62, "type": "TASK", "confidence": 0.7428395549456278}, {"text": "SMT", "start_pos": 87, "end_pos": 90, "type": "TASK", "confidence": 0.989504337310791}]}, {"text": "We do not know of any studies that describe extensive experiments evaluating the adequacy of SMT in areal translation environment.", "labels": [], "entities": [{"text": "SMT", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.9937759637832642}]}, {"text": "We prefer not to commit ourselves to defining what areal translation task is; instead, we adopt the conservative point of view that a viable translation engine (statistical or not) is one that copes with texts that maybe very different in nature from those used to train it.", "labels": [], "entities": []}, {"text": "This fairly general definition suggests that adaptativity is a cornerstone of a successful SMT engine.", "labels": [], "entities": [{"text": "SMT", "start_pos": 91, "end_pos": 94, "type": "TASK", "confidence": 0.9953108429908752}]}, {"text": "Curiously enough, we are not aware of much work on adaptative SMT, despite the tremendous amount of work done on adaptative statistical language modeling.", "labels": [], "entities": [{"text": "adaptative SMT", "start_pos": 51, "end_pos": 65, "type": "TASK", "confidence": 0.6063665747642517}, {"text": "adaptative statistical language modeling", "start_pos": 113, "end_pos": 153, "type": "TASK", "confidence": 0.6241824626922607}]}, {"text": "In this paper, we propose to evaluate how a statistical engine behaves when translating a very domain specific text which is far different from the corpus used to trained both our translation and language models.", "labels": [], "entities": []}, {"text": "We first describe our translation engine.", "labels": [], "entities": [{"text": "translation", "start_pos": 22, "end_pos": 33, "type": "TASK", "confidence": 0.9724928736686707}]}, {"text": "In section 3, we quantify and analyse the performance deterioration of an SMT engine trained on a broad-based corpus (the Hansard) when used to translate a domain specific text (in this study, a manual for military snipers).", "labels": [], "entities": [{"text": "SMT", "start_pos": 74, "end_pos": 77, "type": "TASK", "confidence": 0.9913519620895386}, {"text": "Hansard", "start_pos": 122, "end_pos": 129, "type": "DATASET", "confidence": 0.9376258254051208}]}, {"text": "In section 4, We then suggest a simple but natural way of improving a broad-based SMT engine; that is, by opening the engine to available terminological resources.", "labels": [], "entities": [{"text": "SMT", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.9080145359039307}]}, {"text": "In section 5, we report on the improvement we observed by implementing our proposed approach.", "labels": [], "entities": []}, {"text": "Finally, in section 6 we discuss other approaches we feel can lead to more robust translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 82, "end_pos": 93, "type": "TASK", "confidence": 0.96507328748703}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Main characteristics of our test cor- pora and global performance of our statistical  translator without any adjustments. |length|  reports the average length (counted in words)  of the source sentences and the standard de- viation; nbs is the number of sentences in the  corpus.", "labels": [], "entities": [{"text": "length", "start_pos": 133, "end_pos": 139, "type": "METRIC", "confidence": 0.9888818860054016}]}, {"text": " Table 3: Translation performance with differ- ent terminological lexicons. nb is the number of  entries in the lexicon and coverage reports the  number of different source entries from the lex- icon belonging to the text to translate and the  total number of their occurrences.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9591463804244995}]}]}