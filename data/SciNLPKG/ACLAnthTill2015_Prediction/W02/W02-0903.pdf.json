{"title": [{"text": "Boosting automatic lexical acquisition with morphological information", "labels": [], "entities": [{"text": "Boosting automatic lexical acquisition", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.7163489237427711}]}], "abstractContent": [{"text": "In this paper we investigate the impact of morphological features on the task of automatically extending a dictionary.", "labels": [], "entities": []}, {"text": "We approach the problem as a pattern classification task and compare the performance of several models in classifying nouns that are unknown to abroad coverage dictionary.", "labels": [], "entities": [{"text": "pattern classification", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.7501237690448761}]}, {"text": "We used a boosting clas-sifier to compare the performance of models that use different sets of features.", "labels": [], "entities": []}, {"text": "We show how adding simple morphological features to a model greatly improves the classification performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "The incompleteness of the available lexical resources is a major bottleneck in natural language processing (NLP).", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 79, "end_pos": 112, "type": "TASK", "confidence": 0.7711345255374908}]}, {"text": "The development of methods for the automatic extension of these resources might affect many NLP tasks.", "labels": [], "entities": []}, {"text": "Further, from a more general computational perspective, modeling lexical meaning is a necessary step toward semantic modeling of larger linguistic units.", "labels": [], "entities": []}, {"text": "We approach the problem of lexical acquisition as a classification task.", "labels": [], "entities": [{"text": "lexical acquisition", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.7349695414304733}]}, {"text": "The goal of the classifier is to insert new words into an existing dictionary.", "labels": [], "entities": []}, {"text": "A dictionary 1 in this context simply associates lexical \u00a1 I would like to thank for their input everybody in the Brown Laboratory for Linguistic Information Processing (BLLIP) and Information Retrieval and Machine Learning Group at Brown (IRML), and particularly Mark Johnson and Thomas Hofmann.", "labels": [], "entities": [{"text": "Information Retrieval and Machine Learning Group at Brown (IRML)", "start_pos": 181, "end_pos": 245, "type": "TASK", "confidence": 0.7578519257632169}]}, {"text": "I also thank Brian Roark and Jesse Hochstadt.", "labels": [], "entities": []}, {"text": "1 Or lexicon, we use the two terms interchangeably.", "labels": [], "entities": []}, {"text": "forms with class labels; e.g., \u00a2 \u00a4 \u00a3 \u00a6 \u00a5 \u00a8 \u00a7 \u00a9 \u00a9 , where the arrow can be interpreted as the ISA relation.", "labels": [], "entities": [{"text": "\u00a5 \u00a8 \u00a7 \u00a9 \u00a9", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.6477094352245331}]}, {"text": "In this study we use a simplified version of Wordnet as our base lexicon and we ignore other relevant semantic relations (like hyponymy) and the problem of word sense ambiguity.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 45, "end_pos": 52, "type": "DATASET", "confidence": 0.95210200548172}, {"text": "word sense ambiguity", "start_pos": 156, "end_pos": 176, "type": "TASK", "confidence": 0.7025958100954691}]}, {"text": "We focus on finding features that are useful for associating unknown words with class labels from the dictionary.", "labels": [], "entities": []}, {"text": "In this paper we report the following preliminary findings.", "labels": [], "entities": []}, {"text": "First of all we found that the task is difficult.", "labels": [], "entities": []}, {"text": "We developed several models, based on nearest neighbor (NN), naive Bayes (NB) and boosting classifiers.", "labels": [], "entities": []}, {"text": "Unfortunately, the error rate of these models is much higher than what is found in text categorization tasks 2 with comparable numbers of classes.", "labels": [], "entities": [{"text": "error rate", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.9742644727230072}]}, {"text": "Secondly, it seems obvious that information that is potentially useful for word classification can be of very diverse types, e.g., semantic and syntactic, morphological and topical.", "labels": [], "entities": [{"text": "word classification", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.7628714740276337}]}, {"text": "Therefore methods that allow flexible feature combination and selection are desirable.", "labels": [], "entities": []}, {"text": "We experimented with a multiclass boosting algorithm, which proved successful in this respect.", "labels": [], "entities": []}, {"text": "In this context boosting combines two sources of information: words co-occurring near the new word, which we refer to as collocations, and morphological properties of the new word.", "labels": [], "entities": []}, {"text": "This classifier shows improved performance over models that use only collocations.", "labels": [], "entities": []}, {"text": "In particular, we found that even rudimentary morphological information greatly im- proves classification performance and should therefore be part of any word classification model.", "labels": [], "entities": [{"text": "word classification", "start_pos": 154, "end_pos": 173, "type": "TASK", "confidence": 0.7925782203674316}]}, {"text": "The outline of the paper is as follows.", "labels": [], "entities": []}, {"text": "In section 2 we introduce the dictionary we used for our tests, a simplified version of Wordnet.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 88, "end_pos": 95, "type": "DATASET", "confidence": 0.9833124279975891}]}, {"text": "In section 3 we describe more formally the task, a few simple models, and the test methods.", "labels": [], "entities": []}, {"text": "In section 4 we describe the boosting model and the set of morphological features.", "labels": [], "entities": []}, {"text": "In section 5 we summarize the results of our experiments.", "labels": [], "entities": []}, {"text": "In section 6 we describe related work, and then in section 7 we present our conclusions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}