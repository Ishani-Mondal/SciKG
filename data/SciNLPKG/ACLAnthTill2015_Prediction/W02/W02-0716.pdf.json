{"title": [{"text": "Towards a Speech-to-Speech Machine Translation Quality Metric", "labels": [], "entities": [{"text": "Speech-to-Speech Machine Translation Quality Metric", "start_pos": 10, "end_pos": 61, "type": "TASK", "confidence": 0.7174480080604553}]}], "abstractContent": [{"text": "General characteristics of a pragmatic metric for the production evaluation of speech-to-speech translations are discussed.", "labels": [], "entities": [{"text": "speech-to-speech translations", "start_pos": 79, "end_pos": 108, "type": "TASK", "confidence": 0.6787237524986267}]}, {"text": "While these characteristics constrain the space of allowable metrics, infinite definition space remains from which to select and define any particular metric.", "labels": [], "entities": []}, {"text": "The recommended characteistics are drawn from the author's experience as primary developer of a text-based translation quality metric used in a production environment.", "labels": [], "entities": []}, {"text": "The primary contribution is that of strict category ordering and two metarules that reduce the variance in assignment of errors to categories.", "labels": [], "entities": []}], "introductionContent": [{"text": "When we consider speech-to-speech (S2S) translation systems, several abstract models are possible.", "labels": [], "entities": [{"text": "speech-to-speech (S2S) translation", "start_pos": 17, "end_pos": 51, "type": "TASK", "confidence": 0.6391750514507294}]}, {"text": "In Model 1 () we treat the entire software system as a \"black box,\" just recognizing that the input is a source language utterance (SLU) and the output is a target language utterance (TLU).", "labels": [], "entities": []}, {"text": "In Model 2 () we break the previous black box into several traditional components, reflecting typical language processing modules.", "labels": [], "entities": []}, {"text": "The source language utterance is transformed to a source language text (SLT) by an automatic speech recognition (ASR) system.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 83, "end_pos": 117, "type": "TASK", "confidence": 0.7803423007329305}]}, {"text": "The SLT is then translated by a machine translation (MT) system to a target language text (TLT), which is in turn converted to the target language utterance by a text-to-speech (TTS) system.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.8368824243545532}]}, {"text": "Model 3 () illustrates how the source language text and MT component maybe replaced by a natural language generation (NLG) system, given a rich enough semantic representation.", "labels": [], "entities": []}, {"text": "Other models are certainly possible, depending upon how the various processing tasks are subdivided.", "labels": [], "entities": []}, {"text": "module; that is, one metric for the mapping SLU to SLT, another metric for SLT to TLT, and a third from TLT to TLU.", "labels": [], "entities": []}, {"text": "Each metric would be used to study the effectiveness of the system module of interest.", "labels": [], "entities": []}, {"text": "However, since the only guaranteed inputoutput pair regardless of the particular combination of technologies used would be SLU to TLU, and since all systems can be abstracted into Model 1 above, let us focus on an abstract metric which we will call the utterance-to-utterance (U2U) Metric.", "labels": [], "entities": []}, {"text": "What do we require of our abstract U2U metric?", "labels": [], "entities": [{"text": "U2U metric", "start_pos": 35, "end_pos": 45, "type": "DATASET", "confidence": 0.8044969737529755}]}], "datasetContent": [], "tableCaptions": []}