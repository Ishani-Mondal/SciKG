{"title": [{"text": "Feature Selection fora Rich HPSG Grammar Using Decision Trees", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper examines feature selection for log linear models over rich constraint-based grammar (HPSG) representations by building decision trees over features in corresponding probabilistic context free grammars (PCFGs).", "labels": [], "entities": []}, {"text": "We show that single decision trees do not make optimal use of the available information ; constructed ensembles of decision trees based on different feature subspaces show significant performance gains (14% parse selection error reduction).", "labels": [], "entities": [{"text": "parse selection error reduction", "start_pos": 207, "end_pos": 238, "type": "METRIC", "confidence": 0.707949310541153}]}, {"text": "We compare the performance of the learned PCFG grammars and log linear models over the same features.", "labels": [], "entities": []}], "introductionContent": [{"text": "Hand-built NLP grammars frequently have a depth of linguistic representation and constraints not present in current treebanks, giving them potential importance for tasks requiring deeper processing.", "labels": [], "entities": []}, {"text": "On the other hand, these manually built grammars need to solve the disambiguation problem to be practically usable.", "labels": [], "entities": []}, {"text": "This paper presents work on the problem of probabilistic parse selection from among a set of alternatives licensed by a hand-built grammar in the context of the newly developed Redwoods HPSG treebank ().", "labels": [], "entities": [{"text": "probabilistic parse selection", "start_pos": 43, "end_pos": 72, "type": "TASK", "confidence": 0.6404254833857218}, {"text": "Redwoods HPSG treebank", "start_pos": 177, "end_pos": 199, "type": "DATASET", "confidence": 0.9085718194643656}]}, {"text": "HPSG (Head-driven Phrase Structure Grammar) is a modern constraintbased lexicalist (unification) grammar, described in.", "labels": [], "entities": []}, {"text": "The Redwoods treebank makes available syntactic and semantic analyses of much greater depth than, for example, the Penn Treebank.", "labels": [], "entities": [{"text": "Redwoods treebank", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.9683803021907806}, {"text": "Penn Treebank", "start_pos": 115, "end_pos": 128, "type": "DATASET", "confidence": 0.9956239461898804}]}, {"text": "Therefore there area large number of features available that could be used by stochastic models for disambiguation.", "labels": [], "entities": []}, {"text": "Other researchers have worked on extracting features useful for disambiguation from unification grammar analyses and have built log linear models a.k.a.", "labels": [], "entities": []}, {"text": "Stochastic Unification Based Grammars (;).", "labels": [], "entities": []}, {"text": "Here we also use log linear models to estimate conditional probabilities of sentence analyses.", "labels": [], "entities": []}, {"text": "Since feature selection is almost prohibitive for these models, because of high computational costs, we use PCFG models to select features for log linear models.", "labels": [], "entities": []}, {"text": "Even though this method maybe expected to be suboptimal, it proves to be useful.", "labels": [], "entities": []}, {"text": "We select features for PCFGs using decision trees and use the same features in a conditional log linear model.", "labels": [], "entities": []}, {"text": "We compare the performance of the two models using equivalent features.", "labels": [], "entities": []}, {"text": "Our PCFG models are comparable to branching process models for parsing the Penn Treebank, in which the next state of the model depends on a history of features.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 75, "end_pos": 88, "type": "DATASET", "confidence": 0.9192698895931244}]}, {"text": "In most recent parsing work the history consists of a small number of manually selected features).", "labels": [], "entities": [{"text": "parsing", "start_pos": 15, "end_pos": 22, "type": "TASK", "confidence": 0.9675911664962769}]}, {"text": "Other researchers have proposed automatically selecting the conditioning information for various states of the model, thus potentially increasing greatly the space of possible features and selectively choosing the best predictors for each situation.", "labels": [], "entities": []}, {"text": "Decision trees have been applied for feature selection for statistical parsing models by and.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.7061653137207031}, {"text": "statistical parsing", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.7724571824073792}]}, {"text": "Another example of automatic feature selection for parsing is in the context of a deterministic parsing model that chooses parse actions based on automatically induced decision structures over a very rich feature set.", "labels": [], "entities": [{"text": "parsing", "start_pos": 51, "end_pos": 58, "type": "TASK", "confidence": 0.9689775109291077}]}, {"text": "Our experiments in feature selection using decision trees suggest that single decision trees may not be able to make optimal use of a large number of relevant features.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.7001053988933563}]}, {"text": "This maybe due to the greedy search procedures or to the fact that trees combine information from different features only through partitioning of the space.", "labels": [], "entities": []}, {"text": "For example they have difficulty in weighing evidence from different features without fully partitioning the space.", "labels": [], "entities": []}, {"text": "A common approach to overcoming some of the problems with decision trees -such as reducing their variance or increasing their representational power -has been building ensembles of decision trees by, for example, bagging or boosting.", "labels": [], "entities": []}, {"text": "have experimented with boosting decision trees, reporting significant gains.", "labels": [], "entities": []}, {"text": "Our approach is to build separate decision trees using different (although not disjoint) subsets of the feature space and then to combine their estimates by using the average of their predictions.", "labels": [], "entities": []}, {"text": "A similar method based on random feature subspaces has been proposed by, who found that the random feature subspace method outperformed bagging and boosting for datasets with a large number of relevant features where there is redundancy in the features.", "labels": [], "entities": []}, {"text": "Other examples of ensemble combination based on different feature subspaces include Zheng (1998) who learns combinations of Naive Bayes classifiers and who create ensembles of kNN classifiers.", "labels": [], "entities": []}, {"text": "We begin by describing the information our HPSG corpus makes available and the subset we have attempted to use in our models.", "labels": [], "entities": [{"text": "HPSG corpus", "start_pos": 43, "end_pos": 54, "type": "DATASET", "confidence": 0.9343144297599792}]}, {"text": "Next we describe our ensembles of decision trees for learning parameterizations of branching process models.", "labels": [], "entities": []}, {"text": "Finally, we report parse disambiguation results for these models and corresponding conditional log linear models.", "labels": [], "entities": []}], "datasetContent": [{"text": "We present experimental results comparing the parse ranking performance of different models.", "labels": [], "entities": [{"text": "parse ranking", "start_pos": 46, "end_pos": 59, "type": "TASK", "confidence": 0.9214929044246674}]}, {"text": "The accuracy results are averaged over a ten-fold crossvalidation on the data set summarized in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9993630051612854}]}, {"text": "The sentences in this data set have exactly one preferred parse selected by a human annotator.", "labels": [], "entities": []}, {"text": "At this early stage, the treebank is expected to be noisy because all annotation was done by a single annotator.", "labels": [], "entities": []}, {"text": "Accuracy results denote the percentage of test sentences for which the highest ranked analysis was the correct one.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9964382648468018}]}, {"text": "This measure scores whole sentence accuracy and is therefore more strict than the labelled precision/recall measures and more appropriate for the task of parse ranking.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9904114603996277}, {"text": "precision", "start_pos": 91, "end_pos": 100, "type": "METRIC", "confidence": 0.9684739708900452}, {"text": "recall", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.9253693222999573}, {"text": "parse ranking", "start_pos": 154, "end_pos": 167, "type": "TASK", "confidence": 0.9596182703971863}]}, {"text": "When a model ranks a set of m parses highest with equal scores and one of those parses is the preferred parse in the treebank, we compute the accuracy on this sentence as 1/m.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.999337375164032}]}, {"text": "To give an idea about the difficulty of the task on the corpus we have used, we also show a baseline which is the expected accuracy of choosing a parse sentences length lex ambig struct ambig 7.0 4.1 7.3: Parse ranking accuracy of syntactic models: single decision tree compared to simpler models at random and accuracy results from simpler models that have been used broadly in NLP.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9972702860832214}, {"text": "accuracy", "start_pos": 219, "end_pos": 227, "type": "METRIC", "confidence": 0.5151810646057129}, {"text": "accuracy", "start_pos": 311, "end_pos": 319, "type": "METRIC", "confidence": 0.9992313385009766}]}, {"text": "PCFG-S is a simple PCFG model where we only have the node label (feature 0) in the history, and PCFG-GP has only the node and its parent's labels (features 0 and 1) as in PCFG grammars with grandparent annotation.", "labels": [], "entities": [{"text": "PCFG-S", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9539822340011597}]}, {"text": "shows the accuracy of parse selection of the three simple models mentioned above defined over derivation trees and the accuracy achieved by a single decision tree (PCFG-DTAll) using all features in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.998731791973114}, {"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9992225170135498}]}, {"text": "The third column contains accuracy results for log linear models using the same features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9994081258773804}]}, {"text": "We can note from that the generative models greatly benefit from the addition of more conditioning information, while the log linear model performs very well even with only simple rule features, and its accuracy does not increase so sharply with the addition of more complex features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 203, "end_pos": 211, "type": "METRIC", "confidence": 0.9991951584815979}]}, {"text": "The error reduction from PCFG-S to PCFG-DTAll is 25.36%, while the corresponding error reduction for the log linear model is 12%.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 4, "end_pos": 19, "type": "METRIC", "confidence": 0.988357812166214}, {"text": "PCFG-S", "start_pos": 25, "end_pos": 31, "type": "DATASET", "confidence": 0.8955378532409668}, {"text": "PCFG-DTAll", "start_pos": 35, "end_pos": 45, "type": "DATASET", "confidence": 0.8881630897521973}, {"text": "error reduction", "start_pos": 81, "end_pos": 96, "type": "METRIC", "confidence": 0.966147392988205}]}, {"text": "The error reduction for the log linear model from PCFG-GP to PCFGDTAll is very small which suggests an overfitting effect.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 4, "end_pos": 19, "type": "METRIC", "confidence": 0.9806495606899261}, {"text": "PCFG-GP", "start_pos": 50, "end_pos": 57, "type": "DATASET", "confidence": 0.9562250971794128}, {"text": "PCFGDTAll", "start_pos": 61, "end_pos": 70, "type": "DATASET", "confidence": 0.9254364967346191}]}, {"text": "PCFG-S is doing much worse than the log linear model with the same features, and this is true for the training data as well as for the test data.", "labels": [], "entities": [{"text": "PCFG-S", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9677455425262451}]}, {"text": "A partial explanation for this is the fact that PCFG-S tries to maximize the likelihood of the correct parses under strong independence assumptions, whereas the log linear model need only worry about making the correct parses more probable than the incorrect ones.", "labels": [], "entities": [{"text": "PCFG-S", "start_pos": 48, "end_pos": 54, "type": "DATASET", "confidence": 0.8781834840774536}]}, {"text": "Next we show results comparing the single deci-: Parse ranking accuracy: single decision trees and ensembles sion tree model (PCFG-DTAll) to an ensemble of 11 decision trees based on different feature subspaces.", "labels": [], "entities": [{"text": "Parse ranking accuracy", "start_pos": 49, "end_pos": 71, "type": "METRIC", "confidence": 0.7759547034899393}]}, {"text": "The decision trees in the ensemble are used to rank the possible parses of a sentence individually and then their votes are combined using a simple majority vote.", "labels": [], "entities": []}, {"text": "The sets of features in each decision tree are obtained by removing two features from the whole space.", "labels": [], "entities": []}, {"text": "The left preterminal features (features with numbers 7 and 8) participate in only one decision tree.", "labels": [], "entities": []}, {"text": "Also, features 2, 3, and 5 participate in all decision trees since they have very few possible values and should not partition the space too quickly.", "labels": [], "entities": []}, {"text": "The feature space of each of the 10 decision trees not containing the left preterminal features was formed by removing two of the features from among those with numbers {0, 1, 4, 6, and 9} from the initial feature space (minus features 7 and 8).", "labels": [], "entities": []}, {"text": "This method for constructing feature subspaces is heuristic, but is based on the intuition of removing the features that have the largest numbers of possible values.", "labels": [], "entities": []}, {"text": "1 shows the accuracy results for models based on derivation trees, semantic dependency trees, and a combined model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.999609649181366}]}, {"text": "The first row shows parse ranking accuracy using derivation trees of generative and log linear models over the same features.", "labels": [], "entities": [{"text": "parse ranking", "start_pos": 20, "end_pos": 33, "type": "TASK", "confidence": 0.9251762628555298}, {"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9114370942115784}]}, {"text": "Results are shown for features selected by a a single decision tree, and an ensemble of 11 decision tree models based on different feature subspaces as described above.", "labels": [], "entities": []}, {"text": "The relative improvement inaccuracy of the log linear model from single to multiple decision trees is fairly small.", "labels": [], "entities": []}, {"text": "The second row shows corresponding models for the semantic dependency trees.", "labels": [], "entities": []}, {"text": "Since there area small number of features used for this task, the performance gain from using feature subspaces is not so large.", "labels": [], "entities": []}, {"text": "It should be noted that there is a 90.9% upper bound on parse ranking accuracy using semantic trees only.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9715988636016846}]}, {"text": "This is because for many sentences there are several analyses with the same semantic dependency structure.", "labels": [], "entities": []}, {"text": "Interestingly, for semantic trees the difference between the log linear and generative models is not so large.", "labels": [], "entities": []}, {"text": "Finally, the last row shows the combination of models over derivation trees and semantic trees.", "labels": [], "entities": []}, {"text": "The feature subspace ensemble of 11 decision tree models for the derivation trees is combined with the ensemble of 5 feature subspace models over semantic dependencies to yield a larger ensemble that ranks possible sentence analyses based on weighted majority vote (with smaller weights for the semantic models).", "labels": [], "entities": []}, {"text": "The improvement for PCFG models from combining the syntactic and semantic models is about 5.4% error reduction from the error rate of the better (syntactic) models.", "labels": [], "entities": [{"text": "error", "start_pos": 95, "end_pos": 100, "type": "METRIC", "confidence": 0.9788088202476501}]}, {"text": "The corresponding log linear model contains all features from the syntactic and semantic decision trees in the ensemble.", "labels": [], "entities": []}, {"text": "The error reduction due to the addition of semantics is 6.1% for the log linear model.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 4, "end_pos": 19, "type": "METRIC", "confidence": 0.9822659194469452}]}, {"text": "Overall the gains from using semantic information are not as good as we expected.", "labels": [], "entities": []}, {"text": "Further research remains to be done in this area.", "labels": [], "entities": []}, {"text": "The results show that decision trees and ensembles of decision trees can be used to greatly improve the performance of generative models over derivation trees and dependency trees.", "labels": [], "entities": []}, {"text": "The performance of generative models using a lot of conditioning information approaches the performance of log linear models although the latter remain clearly superior.", "labels": [], "entities": []}, {"text": "The corresponding improvement in log linear models when adding more complex features is not as large as the improvement in generative models.", "labels": [], "entities": []}, {"text": "On the other hand, there might be better ways to incorporate the information from additional history in log linear models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Features over derivation trees", "labels": [], "entities": []}, {"text": " Table 2: Features over semantic dependency trees", "labels": [], "entities": []}, {"text": " Table 3: Annotated corpus used in experiments: The", "labels": [], "entities": []}, {"text": " Table 4: Parse ranking accuracy of syntactic mod- els: single decision tree compared to simpler mod- els", "labels": [], "entities": [{"text": "Parse", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9579810500144958}, {"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.7993948459625244}]}, {"text": " Table 5: Parse ranking accuracy: single decision trees and ensembles", "labels": [], "entities": [{"text": "Parse ranking", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.697565108537674}, {"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9259650111198425}]}]}