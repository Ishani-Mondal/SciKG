{"title": [{"text": "Toward balancing conciseness, readability and salience: an integrated architecture", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we present an architecture for generating texts that vary in the emphasis put on conciseness, readability and the marking of particularly salient items.", "labels": [], "entities": []}, {"text": "We abandon the traditional pipeline architecture , and use an integrated approach which makes the search for an optimum text explicit, taking into account both inter-sentential and intra-sentential features.", "labels": [], "entities": []}, {"text": "We describe a context sensitive scoring system which can relate surface properties to a deeper representational level.", "labels": [], "entities": []}, {"text": "We show how this approach can be used in generating paragraph length texts, optimised against various criteria.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "A small-scale evaluation of the scoring system with respect to the readability of paraphrases was performed.", "labels": [], "entities": []}, {"text": "We compared the system's assessment of texts' readability with that of human judges.", "labels": [], "entities": []}, {"text": "Baselines were established by comparing other readability measures with the judges' assessments.", "labels": [], "entities": []}, {"text": "The results were inconclusive, but provide a basis for future work.", "labels": [], "entities": []}, {"text": "17 sets of input data were chosen, and divided randomly between \"training\" and \"test\" portions, containing 5 and 12 input sets respectively.", "labels": [], "entities": []}, {"text": "We then \"trained\" the parameters of the scoring system by hand, by modifying the scoring tables associated with the elementary trees in the grammar.", "labels": [], "entities": []}, {"text": "At the end of the training procedure, the context sensitive scoring system's assessment of the texts approximately matched our intuitions about their readability.", "labels": [], "entities": []}, {"text": "The test phase was carried out in a procedure similar to that used by ().", "labels": [], "entities": []}, {"text": "Human subjects were asked to read short paragraphs.", "labels": [], "entities": []}, {"text": "For each, they answered two questions on a 7 point scale.", "labels": [], "entities": []}, {"text": "\u00a4 Understandability: \"How easy is this paragraph to understand?\"", "labels": [], "entities": []}, {"text": "The options were labelled \"Difficult\" (=1), \"Fairly easy\" (=4), \"Very easy\" (=7).", "labels": [], "entities": [{"text": "Difficult", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9952560067176819}]}, {"text": "Intermediate values were possible but unlabelled.", "labels": [], "entities": []}, {"text": "\u00a4 Quality: \"How well-written is this paragraph?\".", "labels": [], "entities": [{"text": "Quality", "start_pos": 2, "end_pos": 9, "type": "METRIC", "confidence": 0.9984890222549438}]}, {"text": "The options were labelled \"Horrible\" (=1), \"Alright\" (=4), \"Very well-written\" (=7).", "labels": [], "entities": [{"text": "Alright", "start_pos": 44, "end_pos": 51, "type": "METRIC", "confidence": 0.9869658946990967}]}, {"text": "Again, intermediate values were possible but unlabelled.", "labels": [], "entities": []}, {"text": "There were 10 subjects, who were staff and students of the Department of Computing at HeriotWatt University.", "labels": [], "entities": [{"text": "HeriotWatt University", "start_pos": 86, "end_pos": 107, "type": "DATASET", "confidence": 0.8834047615528107}]}, {"text": "These were selected according to the following scheme.", "labels": [], "entities": []}, {"text": "For each of the 12 test input data sets, a collection of paragraphs was generated.", "labels": [], "entities": []}, {"text": "(The texts in each collection are paraphrases of the same information).", "labels": [], "entities": []}, {"text": "For each collection of paraphrases, the best, worst, and two (in two cases, three) intermediate texts were selected, the judgment of quality being made by the (trained) scoring system.", "labels": [], "entities": []}, {"text": "Each subject judged 20 paragraphs, and hence each paragraph was judged by 4 subjects.", "labels": [], "entities": []}, {"text": "The data was normalised 1 to correct for the variation between subjects.", "labels": [], "entities": []}, {"text": "The final score fora text's understandability was the mean of the normalised judgments for understandability for that text.", "labels": [], "entities": []}, {"text": "Similarly, the final score fora text's quality was the mean of the normalised judgments for quality for that text.", "labels": [], "entities": []}, {"text": "It was expected that there would be strong correlation between the normalised quality and understandability judgments.", "labels": [], "entities": []}, {"text": "The data confirmed this: the correlation co-efficient between the mean normalised understandability scores and the mean normalised quality scores was 0.92 (8 ) . The subjects' judgments were then compared with various readability metrics: Our main hypothesis was that the scoring system would correlate better with understandability and quality than our baseline metrics.", "labels": [], "entities": []}, {"text": "The correlations of the scores with normalised readability and quality were , where are the number of syllables, words and sentences respectively, in the paragraph.", "labels": [], "entities": [{"text": "quality", "start_pos": 63, "end_pos": 70, "type": "METRIC", "confidence": 0.9561218619346619}]}, {"text": "Although the non-confirmation of our hypothesis is a blow for the context-sensitive scoring system, it is not the end.", "labels": [], "entities": []}, {"text": "The training of the parameters for the present evaluation was unsatisfactory.", "labels": [], "entities": []}, {"text": "This is primarily due the labouriousness of hand training.", "labels": [], "entities": []}, {"text": "Because of this, only a small quantity of training data could be used and hence the resultant parameters lacked generality.", "labels": [], "entities": []}, {"text": "Of course, the following question remains open.", "labels": [], "entities": []}, {"text": "Could any training of the context sensitive scoring system yield a metric sufficiently general to perform well in the evaluation above?", "labels": [], "entities": []}, {"text": "We believe it could, but that the successful procedure could not be carried out by hand.", "labels": [], "entities": []}], "tableCaptions": []}