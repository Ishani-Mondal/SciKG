{"title": [{"text": "A Character-net Based Chinese Text Segmentation Method", "labels": [], "entities": [{"text": "Character-net Based Chinese Text Segmentation", "start_pos": 2, "end_pos": 47, "type": "TASK", "confidence": 0.5713928461074829}]}], "abstractContent": [{"text": "The segmentation of Chinese texts is a key process in Chinese information processing.", "labels": [], "entities": [{"text": "segmentation of Chinese texts", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.8977954536676407}, {"text": "Chinese information processing", "start_pos": 54, "end_pos": 84, "type": "TASK", "confidence": 0.6493721206982931}]}, {"text": "The difficulties in segmentation are the process of ambiguous character string and unknown Chinese words.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 20, "end_pos": 32, "type": "TASK", "confidence": 0.9794312119483948}]}, {"text": "In order to obtain the correct result, the first is identification of all possible candidates of Chinese words in a text.", "labels": [], "entities": []}, {"text": "In this paper, a data structure Chinese-character-net is put forward, then, based on this character-net, anew algorithm is presented to obtain all possible candidate of Chinese words in a text.", "labels": [], "entities": []}, {"text": "This paper gives the experiment result.", "labels": [], "entities": []}, {"text": "Finally the characteristics of the algorithm are analysed.", "labels": [], "entities": []}], "introductionContent": [{"text": "The segmentation of Chinese texts is a key problem in Chinese information processing.", "labels": [], "entities": [{"text": "segmentation of Chinese texts", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.8892098516225815}, {"text": "Chinese information processing", "start_pos": 54, "end_pos": 84, "type": "TASK", "confidence": 0.6605347295602163}]}, {"text": "In the process of segmentation, the ambiguity processing, unknown Chinese words (not included in the lexicon) recognition (such as person names, organization names etc) are very difficult.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 18, "end_pos": 30, "type": "TASK", "confidence": 0.9763903617858887}]}, {"text": "As for those problems, many algorithms are put forward.", "labels": [], "entities": []}, {"text": "But the existing algorithms haven't a universal data structure, each algorithm can resolve a problem, and correspond to a concrete data structure specifically.", "labels": [], "entities": []}, {"text": "In process of the difficulties, the first step is identification of all possible candidates of Chinese words segmentation.", "labels": [], "entities": [{"text": "Chinese words segmentation", "start_pos": 95, "end_pos": 121, "type": "TASK", "confidence": 0.6006005704402924}]}, {"text": "For examples: The ambiguous string is ( .There are some methods to resolve this problem: the one is the method forward maximum matching, backward maximum matching and minimum matching are used to find out the possible word strings from the character string.", "labels": [], "entities": [{"text": "backward maximum matching", "start_pos": 137, "end_pos": 162, "type": "METRIC", "confidence": 0.8265330990155538}]}, {"text": "The second is The words finding automaton based on the Aho-Corasick Algorithm.", "labels": [], "entities": [{"text": "words finding automaton", "start_pos": 18, "end_pos": 41, "type": "TASK", "confidence": 0.7873013615608215}]}, {"text": "The former requires three scans of the input character string.", "labels": [], "entities": []}, {"text": "In addition, during each scan, backtracking has to be performed in cases where a dictionary search fails.", "labels": [], "entities": []}, {"text": "After that, the word recognition is built based on the candidates.", "labels": [], "entities": [{"text": "word recognition", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.7613183557987213}]}, {"text": "The second requires building up a state chart, is difficult to combine with other algorithms.", "labels": [], "entities": []}, {"text": "In this paper, an algorithm is put forward to solve this problem, which uses the connection information between Chinese characters to recognize all possible candidates of segmentation words in a Chinese text.", "labels": [], "entities": []}, {"text": "In the method, at first establish a Chinese character-net , try to establish a universal data structure, which is easy to combine with other algorithms in Chinese text segmentation, and can use different kinds of information in a Chinese text, then identify all possible candidates of words segmentation easily.", "labels": [], "entities": [{"text": "Chinese text segmentation", "start_pos": 155, "end_pos": 180, "type": "TASK", "confidence": 0.6993855237960815}, {"text": "words segmentation", "start_pos": 285, "end_pos": 303, "type": "TASK", "confidence": 0.7068469524383545}]}], "datasetContent": [{"text": "Based on a basic Chinese word dictation obtained from Beijing University, which has 61135 Chinese words, we obtain the connections between each two characters, establish a Chinese character net which has 76259 connections.", "labels": [], "entities": [{"text": "Beijing University", "start_pos": 54, "end_pos": 72, "type": "DATASET", "confidence": 0.9073383510112762}]}, {"text": "The records increase 24.7% ((76259-61135)/ 61135).", "labels": [], "entities": []}, {"text": "In the character net, there are 2857 connections which have same char1 and same char2.", "labels": [], "entities": []}, {"text": "Ina general Chinese machine readable lexicon, there are about only 12% of words whose length are longer than three Chinese characters, about 70% of words whose length equal 4, and about 15% of words whose length equal 6.", "labels": [], "entities": []}, {"text": "So, in the algorithm in this paper, the structure of the character-net is fine and the confliction maybe processed seldom in the selection of the connections between same char1 and same char2.", "labels": [], "entities": []}, {"text": "About 1500 Chinese characters can be processed per second.", "labels": [], "entities": []}], "tableCaptions": []}