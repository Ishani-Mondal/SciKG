{"title": [{"text": "Improving Translation Quality of Rule-based Machine Translation", "labels": [], "entities": [{"text": "Improving Translation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8711656928062439}, {"text": "Machine Translation", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7173220962285995}]}], "abstractContent": [{"text": "This paper proposes machine learning techniques, which help disambiguate word meaning.", "labels": [], "entities": []}, {"text": "These methods focus on considering the relationship between a word and its surroundings, described as context information in the paper.", "labels": [], "entities": []}, {"text": "Context information is produced from rule-based translation such as part-of-speech tags, semantic concept, case relations and soon.", "labels": [], "entities": []}, {"text": "To automatically extract the context information, we apply machine learning algorithms which are C4.5, C4.5rule and RIPPER.", "labels": [], "entities": [{"text": "RIPPER", "start_pos": 116, "end_pos": 122, "type": "METRIC", "confidence": 0.839251697063446}]}, {"text": "In this paper, we test on ParSit, which is an interlingual-based machine translation for English to Thai.", "labels": [], "entities": [{"text": "ParSit", "start_pos": 26, "end_pos": 32, "type": "DATASET", "confidence": 0.8060715794563293}, {"text": "interlingual-based machine translation", "start_pos": 46, "end_pos": 84, "type": "TASK", "confidence": 0.6830150087674459}]}, {"text": "To evaluate our approach, an verb-to-be is selected because it has increased in frequency and it is quite difficult to be translated into Thai by using only linguistic rules.", "labels": [], "entities": []}, {"text": "The result shows that the accuracy of C4.5, C4.5rule and RIPPER are 77.7%, 73.1% and 76.1% respectively whereas ParSit give accuracy only 48%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9997259974479675}, {"text": "RIPPER", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9959728121757507}, {"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9994331002235413}]}], "introductionContent": [{"text": "Machine translation has been developed for many decades.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7726161479949951}]}, {"text": "Many approaches have been proposed such as rule-based, statistic-based, and example-based approaches.", "labels": [], "entities": []}, {"text": "However, there is no machine learning technique that meets human's requirement.", "labels": [], "entities": []}, {"text": "Each technique has its own advantages and disadvantages.", "labels": [], "entities": []}, {"text": "Statistic-based, example-based and corpus-based approaches were recently proposed.", "labels": [], "entities": []}, {"text": "A rulebased approach is the first strategy pursued by research in the field of machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.7778871655464172}]}, {"text": "Rules are written from linguistic knowledge by human.", "labels": [], "entities": []}, {"text": "The strength is that it can deeply analyze in both syntax and semantic levels.", "labels": [], "entities": []}, {"text": "However, the weak points of this model are 1) it requires much linguistic knowledge.", "labels": [], "entities": []}, {"text": "2) it is impossible to write rules that coverall a language.", "labels": [], "entities": []}, {"text": "In many years ago, a statistic-based and an example-based were proposed.", "labels": [], "entities": []}, {"text": "These approaches do not require linguistic knowledge, but they need large size of bilingual corpus.", "labels": [], "entities": []}, {"text": "A statistic-based approach uses statistic of bilingual corpus and language model.", "labels": [], "entities": []}, {"text": "The advantage is that it maybe able to produce suitable translations even if a given sentence is not similar to any sentences in a training corpus.", "labels": [], "entities": []}, {"text": "In contrast, an example-based can produce appropriate translations in case of a given sentence must similar to any sentences in a training data.", "labels": [], "entities": []}, {"text": "Nevertheless, a statistic-based approach cannot translate idioms and phrases that reflect long-distance dependency.", "labels": [], "entities": []}, {"text": "To improve quality of a rule-based machine translation, we have to modify/add some generation rules or analysis rules.", "labels": [], "entities": [{"text": "rule-based machine translation", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.6514442066351572}]}, {"text": "This method requires much linguistic knowledge and we cannot guarantee that accuracy will be better.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9996036887168884}]}, {"text": "For example, in case of modifying some rules, it does not only change incorrect sentences to correct sentences furthermore they may effect on correct sentences too.", "labels": [], "entities": []}, {"text": "The common errors of machine translation can be classified into two main groups.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.754530668258667}]}, {"text": "One is choosing incorrect meaning and the other is incorrect ordering.", "labels": [], "entities": []}, {"text": "In our experiments, we select ParSit in evaluation.", "labels": [], "entities": []}, {"text": "ParSit is English-to-Thai machine translation by using an interlingual-based approach.", "labels": [], "entities": [{"text": "ParSit", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8410049676895142}, {"text": "English-to-Thai machine translation", "start_pos": 10, "end_pos": 45, "type": "TASK", "confidence": 0.617693285147349}]}, {"text": "An interlingual-based approach is a kind of rulebased machine translation.", "labels": [], "entities": [{"text": "rulebased machine translation", "start_pos": 44, "end_pos": 73, "type": "TASK", "confidence": 0.6669162511825562}]}, {"text": "The statistics of incorrect meaning and incorrect ordering in ParSit are 81.74% and 18.26% respectively.", "labels": [], "entities": []}, {"text": "Therefore, in this paper, we address on choosing a correct meaning.", "labels": [], "entities": []}, {"text": "We use context information, words and part-of-speech tags, in classifying the correct meaning.", "labels": [], "entities": []}, {"text": "This paper, we apply machine learning algorithms, C4.5, C4.5rule, and RIPPER, to automatically extract words and part-of-speech tags.", "labels": [], "entities": [{"text": "RIPPER", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.9672174453735352}]}, {"text": "We develop a computer system for sentence translation In this section, we will briefly describe a rulebased machine translation.", "labels": [], "entities": [{"text": "sentence translation", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.7811729907989502}, {"text": "rulebased machine translation", "start_pos": 98, "end_pos": 127, "type": "TASK", "confidence": 0.7022441228230795}]}, {"text": "Each rule-based machine translation has its own mythology in translation.", "labels": [], "entities": [{"text": "rule-based machine translation", "start_pos": 5, "end_pos": 35, "type": "TASK", "confidence": 0.6489683588345846}]}, {"text": "Hence in this paper, we select ParSit as a case study.", "labels": [], "entities": [{"text": "ParSit", "start_pos": 31, "end_pos": 37, "type": "DATASET", "confidence": 0.8505486845970154}]}, {"text": "ParSit is English to Thai machine translation using an interlingual-based approach.", "labels": [], "entities": [{"text": "ParSit", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8585463166236877}, {"text": "Thai machine translation", "start_pos": 21, "end_pos": 45, "type": "TASK", "confidence": 0.533636212348938}]}, {"text": "ParSit consists of four modules that area syntax analysis module, a semantic analysis module, a semantic generation module, and a syntax generation module.", "labels": [], "entities": [{"text": "ParSit", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8522548079490662}]}, {"text": "An example of ParSit translation is shown in.", "labels": [], "entities": [{"text": "ParSit translation", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.7100736498832703}]}, {"text": "In, the English sentence, \"We develop a computer system for sentence translation.\", input into ParSit.", "labels": [], "entities": [{"text": "sentence translation.", "start_pos": 60, "end_pos": 81, "type": "TASK", "confidence": 0.7288251221179962}, {"text": "ParSit", "start_pos": 95, "end_pos": 101, "type": "DATASET", "confidence": 0.8840866088867188}]}, {"text": "Both syntax and semantic analysis modules analyze the sentence and then transform into the interlingual tree which is shown in.", "labels": [], "entities": []}, {"text": "In the interlingual tree shows the relationship between words such as 1) \"We\" is an agent of \"develop\" 2) \"system\" is an object of \"develop\" 3) \"computer\" is modifier of \"system\" and soon.", "labels": [], "entities": []}, {"text": "Finally, Thai sentence, \u0e1e\u0e27\u0e01\u0e40\u0e23\u0e32\u0e1e\u0e31 \u0e12\u0e19\u0e32\u0e23\u0e30\u0e1a\u0e1a\u0e04\u0e2d\u0e21\u0e1e\u0e34 \u0e27\u0e40\u0e15\u0e2d\u0e23\uf70e \u0e40\u0e1e\u0e37 \u0e48 \u0e2d\u0e01\u0e32\u0e23\u0e41\u0e1b\u0e25 \u0e1b\u0e23\u0e30\u0e42\u0e22\u0e04, is generated from the interlingual tree by the syntax and semantic generation modules.", "labels": [], "entities": []}, {"text": "The errors of translation from ParSit can be classified into two main groups.", "labels": [], "entities": []}, {"text": "One is incorrect meaning and the other is incorrect ordering.", "labels": [], "entities": []}, {"text": "The incorrect meaning also can be reclassified into three categories; 1).", "labels": [], "entities": []}, {"text": "missing some words 2).", "labels": [], "entities": []}, {"text": "generating over words 3).", "labels": [], "entities": []}, {"text": "using incorrect word The examples of errors are shown below.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our approach, we should test on a word, which frequently occurred in normal text and has several meanings.", "labels": [], "entities": []}, {"text": "According to the statistics of word usage from 100M-word British National Corpus, verb-to-be occurred more than thee million times, and translation of verb-to-be into Thai is quite difficult by using only linguistic rules.", "labels": [], "entities": [{"text": "British National Corpus", "start_pos": 57, "end_pos": 80, "type": "DATASET", "confidence": 0.9367114702860514}]}, {"text": "Therefore our experiment, we test our approach on verb-to-be.", "labels": [], "entities": []}, {"text": "\u2208 As , where A n is a nominal attribute and v is a legal value for A n ; or Ac is a continuous variable and \u03b8 is some value for Ac that occurs in the training data; or As is a set-value attribute and v is a value that is an element of As . In fact, a condition can include negation.", "labels": [], "entities": []}, {"text": "A set-valued attribute is an attribute whose value is a set of strings.", "labels": [], "entities": []}, {"text": "The primitive tests on a set-valued attribute As are of the form \"v \u2208 As \".", "labels": [], "entities": []}, {"text": "When constructing a rule, RIPPER finds the test that maximizes information gain fora set of examples S efficiently, making only a single pass over S for each attribute.", "labels": [], "entities": []}, {"text": "All symbols v, that appear as elements of attribute A for some training examples, are considered by RIPPER.", "labels": [], "entities": [{"text": "RIPPER", "start_pos": 100, "end_pos": 106, "type": "DATASET", "confidence": 0.6139860153198242}]}, {"text": "In the experiment, we use 3,200 English sentences from Japan Electronic Dictionary Research Institute (EDR).", "labels": [], "entities": [{"text": "Japan Electronic Dictionary Research Institute (EDR)", "start_pos": 55, "end_pos": 107, "type": "DATASET", "confidence": 0.9238455891609192}]}, {"text": "EDR corpus is collected from news, novel and journal.", "labels": [], "entities": [{"text": "EDR corpus", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9399145245552063}]}, {"text": "Then our linguists manually assigned the suitable meaning of verb-to-be in Thai.", "labels": [], "entities": []}, {"text": "In training and testing steps, we divided data into two groups.", "labels": [], "entities": []}, {"text": "The first is 700 sentences for testing and the other is for training.", "labels": [], "entities": []}, {"text": "We use various sizes of a training data set and different sizes of context information., 3 and 4 are the result from C4.5, C4.5rule and RIPPER respectively.", "labels": [], "entities": [{"text": "RIPPER", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.9103540778160095}]}, {"text": "The series in columns represent the number of training sentences.", "labels": [], "entities": []}, {"text": "The row headers show the types of context information that Pos\u00b1n, Word\u00b1n and P&W\u00b1n mean part-of-speech tags, words and part-of-speech tags and words with the window size is n.", "labels": [], "entities": []}, {"text": "According to the result from C4.5 in, with data size is not more than 500 sentences, C4.5 makes good accuracy by using only part-of-speech tags with any window sizes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9989808201789856}]}, {"text": "In case of a training data set is equal or more than 1000 sentences, considering only words give the best accuracy and the suitable window size is depend on the size of training data set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9990680813789368}]}, {"text": "In, RIPPER produces high accuracies by investigating only one word and one part-of-speech tag before and after verb-tobe words.", "labels": [], "entities": [{"text": "RIPPER", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.5359898805618286}, {"text": "accuracies", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.989170253276825}]}], "tableCaptions": [{"text": " Table 1. Statistics of ParSit Error  Incorrect meaning errors  M (%) G (%) U (%)", "labels": [], "entities": [{"text": "ParSit Error  Incorrect meaning errors  M (%) G (%) U (%)", "start_pos": 24, "end_pos": 81, "type": "METRIC", "confidence": 0.7245226068930193}]}, {"text": " Table 2. The results from C4.5", "labels": [], "entities": [{"text": "C4.5", "start_pos": 27, "end_pos": 31, "type": "DATASET", "confidence": 0.7583597898483276}]}, {"text": " Table 3: The results from C4.5rule", "labels": [], "entities": [{"text": "C4.5rule", "start_pos": 27, "end_pos": 35, "type": "DATASET", "confidence": 0.773650586605072}]}, {"text": " Table 4: The results from RIPPER.", "labels": [], "entities": [{"text": "RIPPER", "start_pos": 27, "end_pos": 33, "type": "DATASET", "confidence": 0.41977670788764954}]}]}