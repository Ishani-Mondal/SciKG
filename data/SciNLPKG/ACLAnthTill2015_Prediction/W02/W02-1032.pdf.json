{"title": [{"text": "Exploiting Headword Dependency and Predictive Clustering for Language Modeling", "labels": [], "entities": [{"text": "Language Modeling", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.7187816798686981}]}], "abstractContent": [{"text": "This paper presents several practical ways of incorporating linguistic structure into language models.", "labels": [], "entities": []}, {"text": "A headword detector is first applied to detect the headword of each phrase in a sentence.", "labels": [], "entities": []}, {"text": "A permuted headword trigram model (PHTM) is then generated from the annotated corpus.", "labels": [], "entities": []}, {"text": "Finally, PHTM is extended to a cluster PHTM (C-PHTM) by defining clusters for similar words in the corpus.", "labels": [], "entities": []}, {"text": "We evaluated the proposed models on the realistic application of Japanese Kana-Kanji conversion.", "labels": [], "entities": [{"text": "Kana-Kanji conversion", "start_pos": 74, "end_pos": 95, "type": "TASK", "confidence": 0.7586758732795715}]}, {"text": "Experiments show that C-PHTM achieves 15% error rate reduction over the word trigram model.", "labels": [], "entities": [{"text": "error rate reduction", "start_pos": 42, "end_pos": 62, "type": "METRIC", "confidence": 0.9703564246495565}]}, {"text": "This demonstrates that the use of simple methods such as the headword trigram and predictive clustering can effectively capture long distance word dependency, and substantially outperform a word trigram model.", "labels": [], "entities": [{"text": "predictive clustering", "start_pos": 82, "end_pos": 103, "type": "TASK", "confidence": 0.870891809463501}]}], "introductionContent": [{"text": "In spite of its deficiencies, trigram-based language modeling still dominates the statistical language modeling community, and is widely applied to tasks such as speech recognition and Asian language text input.", "labels": [], "entities": [{"text": "trigram-based language modeling", "start_pos": 30, "end_pos": 61, "type": "TASK", "confidence": 0.6636728743712107}, {"text": "statistical language modeling", "start_pos": 82, "end_pos": 111, "type": "TASK", "confidence": 0.7381301919619242}, {"text": "speech recognition", "start_pos": 162, "end_pos": 180, "type": "TASK", "confidence": 0.7680474519729614}, {"text": "Asian language text input", "start_pos": 185, "end_pos": 210, "type": "TASK", "confidence": 0.682020902633667}]}, {"text": "Word trigram models are deficient because they can only capture local dependency relations, taking no advantage of richer linguistic structure.", "labels": [], "entities": []}, {"text": "Many proposals have been made that try to incorporate linguistic structure into language models (LMs), but little improvement has been achieved so far in realistic applications because (1) capturing longer distance word dependency leads to higher-order n-gram models, where the number of parameters is usually too large to estimate; (2) capturing deeper linguistic relations in a LM requires a large amount of annotated training corpus and a decoder that assigns linguistic structure, which are not always available.", "labels": [], "entities": []}, {"text": "This paper presents several practical ways of incorporating long distance word dependency and linguistic structure into LMs.", "labels": [], "entities": []}, {"text": "A headword detector is first applied to detect the headwords in each phrase in a sentence.", "labels": [], "entities": []}, {"text": "A permuted headword trigram model (PHTM) is then generated from the annotated corpus.", "labels": [], "entities": []}, {"text": "Finally, PHTM is extended to a cluster model (C-PHTM), which clusters similar words in the corpus.", "labels": [], "entities": []}, {"text": "Our models are motivated by three assumptions about language: (1) Headwords depend on previous headwords, as well as immediately preceding words; (2) The order of headwords in a sentence can freely change in some cases; and (3) Word clusters help us make a more accurate estimate of the probability of word strings.", "labels": [], "entities": []}, {"text": "We evaluated the proposed models on the realistic application of Japanese Kana-Kanji conversion, which converts phonetic Kana strings into proper Japanese orthography.", "labels": [], "entities": [{"text": "Kana-Kanji conversion", "start_pos": 74, "end_pos": 95, "type": "TASK", "confidence": 0.6957436501979828}]}, {"text": "Results show that C-PHTM achieves a 15% error rate reduction over the word trigram model.", "labels": [], "entities": [{"text": "error rate reduction", "start_pos": 40, "end_pos": 60, "type": "METRIC", "confidence": 0.9730565746625265}]}, {"text": "This demonstrates that the use of simple methods can effectively capture long distance word dependency, and substantially outperform the word trigram model.", "labels": [], "entities": []}, {"text": "Although the techniques in this paper are described in the context of Japanese Kana-Kanji conversion, we believe that they can be extended to other languages and applications.", "labels": [], "entities": [{"text": "Kana-Kanji conversion", "start_pos": 79, "end_pos": 100, "type": "TASK", "confidence": 0.778137594461441}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Sections 2 and 3 describe the techniques of using headword dependency and clustering for language modeling.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 89, "end_pos": 106, "type": "TASK", "confidence": 0.7197615057229996}]}, {"text": "Section 4 reviews related work.", "labels": [], "entities": []}, {"text": "Section 5 introduces the evaluation methodology, and Section 6 presents the results of our main experiments.", "labels": [], "entities": []}, {"text": "Section 7 concludes our discussion.", "labels": [], "entities": []}], "datasetContent": [{"text": "The most common metric for evaluating a language model is perplexity.", "labels": [], "entities": []}, {"text": "Perplexity can be roughly interpreted as the expected branching factor of the test document when presented to a language model.", "labels": [], "entities": []}, {"text": "Perplexity is widely used due to its simplicity and efficiency.", "labels": [], "entities": []}, {"text": "However, the ultimate quality of a language model must be measured by its effect on the specific task to which it is applied, such as speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 134, "end_pos": 152, "type": "TASK", "confidence": 0.8086357414722443}]}, {"text": "Lower perplexities usually result in lower error rates, but there are numerous counterexamples to this in the literature.", "labels": [], "entities": [{"text": "error rates", "start_pos": 43, "end_pos": 54, "type": "METRIC", "confidence": 0.9672073721885681}]}, {"text": "In this study, we evaluated our language models on the application of Japanese Kana-Kanji conversion, which is the standard method of inputting Japanese text by converting the text of syllabary-based Kana string into the appropriate combination of ideographic Kanji and Kana.", "labels": [], "entities": [{"text": "Kana-Kanji conversion", "start_pos": 79, "end_pos": 100, "type": "TASK", "confidence": 0.6674909591674805}]}, {"text": "This is a similar problem to speech recognition, except that it does not include acoustic ambiguity.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.8104086518287659}]}, {"text": "Performance on this task is generally measured in terms of the character error rate (CER), which is the number of characters wrongly converted from the phonetic string divided by the number of characters in the correct transcript.", "labels": [], "entities": [{"text": "character error rate (CER)", "start_pos": 63, "end_pos": 89, "type": "METRIC", "confidence": 0.8572456041971842}]}, {"text": "The role of the language model is to select the word string (in a combination of Kanji and Kana) with the highest probability among the candidate strings that match the typed phonetic (Kana) string.", "labels": [], "entities": []}, {"text": "Current products make about 5-10% errors in conversion of real data in a wide variety of domains.", "labels": [], "entities": []}, {"text": "For our experiments, we used two newspaper corpora: Nikkei and Yomiuri Newspapers.", "labels": [], "entities": [{"text": "Nikkei", "start_pos": 52, "end_pos": 58, "type": "DATASET", "confidence": 0.9804551005363464}, {"text": "Yomiuri Newspapers", "start_pos": 63, "end_pos": 81, "type": "DATASET", "confidence": 0.8272356986999512}]}, {"text": "Both corpora have been word-segmented.", "labels": [], "entities": []}, {"text": "We built language models from a 36-million-word subset of the Nikkei Newspaper corpus.", "labels": [], "entities": [{"text": "Nikkei Newspaper corpus", "start_pos": 62, "end_pos": 85, "type": "DATASET", "confidence": 0.9799903631210327}]}, {"text": "We performed parameter optimization on a 100,000-word subset of the Yomiuri Newspaper (held-out data).", "labels": [], "entities": [{"text": "100,000-word subset of the Yomiuri Newspaper", "start_pos": 41, "end_pos": 85, "type": "DATASET", "confidence": 0.7328238934278488}]}, {"text": "We tested our models on another 100,000-word subset of the Yomiuri Newspaper corpus.", "labels": [], "entities": [{"text": "Yomiuri Newspaper corpus", "start_pos": 59, "end_pos": 83, "type": "DATASET", "confidence": 0.9545000592867533}]}, {"text": "The lexicon we used contains 167,107 entries.", "labels": [], "entities": []}, {"text": "In our experiments, we used the so-called \"N-best rescoring\" method.", "labels": [], "entities": []}, {"text": "In this method, a list of hypotheses is generated by the baseline language model (a word trigram model in this study 4 ), which is then rescored using a more sophisticated LM.", "labels": [], "entities": []}, {"text": "Due to the limited number of hypotheses in the N-best list, the second pass maybe constrained by the first pass.", "labels": [], "entities": []}, {"text": "In this study, we used the 100-best list.", "labels": [], "entities": []}, {"text": "The \"oracle\" CER (i.e., the CER among the hypotheses with the minimum number of errors) is presented in.", "labels": [], "entities": []}, {"text": "This is the upper bound on performance in our experiments.", "labels": [], "entities": []}, {"text": "The performance of the conversion using the baseline trigram model is much better than the state-of-the-art performance currently available in the marketplace.", "labels": [], "entities": []}, {"text": "This maybe due to the large amount of training data we used, and to the similarity between the training and the test data.", "labels": [], "entities": []}, {"text": "We also notice that the \"oracle\" CER is relatively high due to the high out-of-vocabulary rate, which is 1.14%.", "labels": [], "entities": [{"text": "CER", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.9789397120475769}, {"text": "out-of-vocabulary rate", "start_pos": 72, "end_pos": 94, "type": "METRIC", "confidence": 0.8240779638290405}]}, {"text": "Because we have only limited room for improvement, the reported results of our experiments in this study maybe underestimated.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Comparison of CER results", "labels": [], "entities": []}]}