{"title": [{"text": "Using eigenvectors of the bigram graph to infer morpheme identity", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes the results of some experiments exploring statistical methods to infer syntactic categories from a raw corpus in an unsupervised fashion.", "labels": [], "entities": []}, {"text": "It shares certain points in common with Brown et at (1992) and work that has grown out of that: it employs statistical techniques to derive categories based on what words occur adjacent to a given word.", "labels": [], "entities": []}, {"text": "However, we use an eigenvector decomposition of a nearest-neighbor graph to produce a two-dimensional rendering of the words of a corpus in which words of the same syntactic category tend to form clusters and neighborhoods.", "labels": [], "entities": []}, {"text": "We exploit this technique for extending the value of automatic learning of morphology.", "labels": [], "entities": []}, {"text": "In particular, we look at the suffixes derived from a corpus by unsupervised learning of morphology, and we ask which of these suffixes have a consistent syntactic function (e.g., in English,-ed is primarily a mark of verbal past tense, does but-s marks both noun plurals and 3 rd person present on verbs).", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes some results of our efforts to develop statistical techniques for unsupervised learning of syntactic wordbehavior, with two specific goals: (1) the development of visualization tools displaying syntactic behavior of words, and (2) the development of quantitative techniques to test whether a given candidate set of words acts in a syntactically uniform way, in a given corpus.", "labels": [], "entities": []}, {"text": "In practical terms, this means the development of computational techniques which accept a corpus in an unknown language as input, and produce as output a two-dimensional image, with each word identified as a point on the image, in such a fashion that words with similar syntactic behavior will be placed near to each other on the image.", "labels": [], "entities": []}, {"text": "We approach the problem in two stages: first, a nearest-neighbor analysis, in which a graph is constructed which links words whose distribution is similar, and second, what we might calla planar projection of this graph onto R 2 , that is to say, a two-dimensional region, which is maximally faithful to the relations expressed by the nearest-neighbor graph.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}