{"title": [{"text": "Analyzing the Semantics of Patient Data to Rank Records of Literature Retrieval", "labels": [], "entities": [{"text": "Literature Retrieval", "start_pos": 59, "end_pos": 79, "type": "TASK", "confidence": 0.6410687118768692}]}], "abstractContent": [{"text": "We describe the use of clinical data present in the medical record to determine the relevance of research evidence from literature databases.", "labels": [], "entities": []}, {"text": "We studied the effect of using automated knowledge approaches as compared to physician's selection of articles, when using a traditional information retrieval system.", "labels": [], "entities": []}, {"text": "The first method identified terms and their semantics and relationships in the patient's record to build a map of the record, which was represented in conceptual graph notation.", "labels": [], "entities": []}, {"text": "This approach was applied to data in an individual's medical record and used to score citations retrieved using a graph matching algorithm.", "labels": [], "entities": []}, {"text": "The second method identified associations between terms in the medical record, assigning them semantic types and weights based on the co-occurrence of these associations in citations of biomedical literature.", "labels": [], "entities": []}, {"text": "The method was applied to data in an individual's medical record and used to score citations.", "labels": [], "entities": []}, {"text": "The last method combined the first two.", "labels": [], "entities": []}, {"text": "The results showed that physicians agreed better with each other than with the automated methods.", "labels": [], "entities": []}, {"text": "However, we found a significant positive relation between physicians' selection of abstracts and two of the methods.", "labels": [], "entities": []}, {"text": "We believe the results encourage the use of clinical data to determine the relevance of medical literature to the care of individual patients.", "labels": [], "entities": []}], "introductionContent": [{"text": "The practice of evidence-based medicine, which gained popularity in the last decade, has encouraged clinicians to understand and utilize critically appraised published research evidence.", "labels": [], "entities": []}, {"text": "The tremendous increase of biomedical knowledge resources in electronic form, particularly on the World Wide Web, has generated a great deal of interest.", "labels": [], "entities": []}, {"text": "The increased availability of information does not make it easy for clinicians to filter large amounts of information and incorporate evidence to clinical practice.", "labels": [], "entities": []}, {"text": "Although the number of clinicians and medical students who routinely perform their own searches has increased, they still have difficulty keeping-up-to-date with advances in medical science.", "labels": [], "entities": []}, {"text": "Decision support tools designed to provide relevant and current evidence to clinicians promise to substantially improve healthcare quality) and potentially reduce medical errors.)", "labels": [], "entities": []}, {"text": "Such tools include those that facilitate the access to, extraction of, and summarization of evidence.", "labels": [], "entities": [{"text": "summarization of evidence", "start_pos": 75, "end_pos": 100, "type": "TASK", "confidence": 0.8513406117757162}]}, {"text": "The Evidence and Decision Support track of the 2000 AMIA Spring Symposium examined the challenges in the development and adoption of clinical decision support systems for evidence-based practice.)", "labels": [], "entities": [{"text": "Evidence and Decision Support track of the 2000 AMIA Spring Symposium", "start_pos": 4, "end_pos": 73, "type": "TASK", "confidence": 0.5130890607833862}]}, {"text": "The speakers for the Evidence and Decision Support track described five central areas of activity as essential for the adoption of those systems.", "labels": [], "entities": [{"text": "Evidence and Decision Support", "start_pos": 21, "end_pos": 50, "type": "TASK", "confidence": 0.6465857028961182}]}, {"text": "Two of the areas were a) the capture of both literature-based and practice based research evidence into machine-interpretable form, and b) the establishment of a technical and methodological foundation for applying research evidence to individual patients at the point of care.", "labels": [], "entities": []}, {"text": "Our goal is to improve the way retrieved medical literature is presented by identifying critical information in the individual medical record that is useful for determining the relevance of literature data, also called research evidence.", "labels": [], "entities": []}, {"text": "We describe an automated knowledge based approach that uses case-specific evidence present in patient's medical record to rank research evidence from literature databases.", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed a study in order to assess the effect of using the automated knowledge approach compared to a physicians' selection of articles when using traditional information retrieval systems.", "labels": [], "entities": []}, {"text": "Three patients consented to the use of anonymized versions of the data stored in their electronic medical records.", "labels": [], "entities": []}, {"text": "We randomly selected one admission of each patient to build the clinical cases.", "labels": [], "entities": []}, {"text": "Data from these individuals' medical records were retrieved from the clinical repository as previously described.", "labels": [], "entities": []}, {"text": "Narrative reports were parsed differently depending on the algorithm in evaluation.", "labels": [], "entities": []}, {"text": "The \"maps\" of the three medical records were created.", "labels": [], "entities": []}, {"text": "For each case, four clinical questions were selected from a database of generic questions based on the work of Ely and collaborators.)", "labels": [], "entities": []}, {"text": "Nonclinical questions (e.g., What are the administrative rules/considerations in <situation y?>) were eliminated from the database before the selection.", "labels": [], "entities": []}, {"text": "Each question selected was also eliminated before the next random selection, so that we had a total of 12 unique questions.", "labels": [], "entities": []}, {"text": "A health science librarian generated the search strategy for each question based on the case description.", "labels": [], "entities": []}, {"text": "Two information retrieval systems were searched: PubMED (clinical queries using research methodology filters based largely on the work of Haynes and colleagues) and OVID (Evidence-Based Medicine Reviews) . All search strategies were keyword based with Boolean connectors.", "labels": [], "entities": [{"text": "PubMED", "start_pos": 49, "end_pos": 55, "type": "DATASET", "confidence": 0.8778015971183777}, {"text": "OVID", "start_pos": 165, "end_pos": 169, "type": "METRIC", "confidence": 0.7376522421836853}]}, {"text": "The search was time limited (last 3 years).", "labels": [], "entities": []}, {"text": "In the cases where no citation was retrieved, the time limit was removed.", "labels": [], "entities": [{"text": "time limit", "start_pos": 50, "end_pos": 60, "type": "METRIC", "confidence": 0.9776696860790253}]}, {"text": "The time limit was imposed because the time required by an expert to analyze all citations retrieved without this limitation would have been a disincentive to their participation in the study.", "labels": [], "entities": [{"text": "time", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9795518517494202}]}, {"text": "Subjects were recruited as follows.", "labels": [], "entities": []}, {"text": "Three board-certified internists, one board-certified family physician, and one research physician were selected as experts.", "labels": [], "entities": []}, {"text": "Four of the five physicians actively practice medicine in their fields.", "labels": [], "entities": []}, {"text": "Participants were given instructions and received the following materials: a) cases' description, b) clinical questions selected for each case, and c) citations retrieved to answer each question.", "labels": [], "entities": []}, {"text": "Case descriptions were based on the admission note (chief complaint, history of present illness, past medical and surgery history, and current medications), and the results of laboratory tests performed during the admission.", "labels": [], "entities": []}, {"text": "Subjects were asked to score each citation according to the relevance of the article (citation) to the question asked and to the patient the case referred to.", "labels": [], "entities": []}, {"text": "We asked each to define a relevant citation as providing information that could be used in the care of that particular patient.", "labels": [], "entities": []}, {"text": "The score used by the physicians was: 1 -completely nonrelevant 2 -almost entirely nonrelevant 3 -somewhat relevant 4 -very relevant 5 -completely relevant Each participant analyzed all questions.", "labels": [], "entities": []}, {"text": "The automated methods also scored each citation.", "labels": [], "entities": []}, {"text": "The scores were based on how well the abstract and title in the citation matched the case's summary.", "labels": [], "entities": []}, {"text": "The computer scores are described in the previous section.", "labels": [], "entities": []}, {"text": "We used the inverse chronological order in which the citations were provided by their respective programs as an additional method for comparison (control).", "labels": [], "entities": []}, {"text": "The main outcome measure in my study was the distance of averaged correlation coefficients between subjects and the average of the raters.", "labels": [], "entities": [{"text": "distance of averaged correlation coefficients", "start_pos": 45, "end_pos": 90, "type": "METRIC", "confidence": 0.7994380474090577}]}, {"text": "For each physician, we calculated the average distance from the average of the other 4 physicians, and for each automated method, we calculated the average distance from the average of all 5 physicians.", "labels": [], "entities": []}, {"text": "The null hypotheses were: a) that each subject was no more distant from the average of the physicians than the physicians were from each other and b) that there was no correlation between the average of the physicians' scores and the average of the subjects' scores.", "labels": [], "entities": []}, {"text": "We used bootstrapping to estimate variance directly from the data.", "labels": [], "entities": [{"text": "variance", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9291172027587891}]}, {"text": "We used Pearson's product-moment correlation to calculate the strength of the association between subjects and the average of the raters.", "labels": [], "entities": []}, {"text": "In order to accommodate the fact that questions had a different number of citations associated with them, we calculated a weighted average r_ of correlation coefficients r i given weights w i as follows: where n is the number of citations retrieved in question i.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. A significant  positive correlation was found between the  average of physicians' scores and the scores  given by the graph matching and the combined  algorithms.", "labels": [], "entities": []}, {"text": " Table 2.  Positive numbers imply worse performance  (more unlike the average physician). No  physicians differed significantly from other  physicians. The automated methods did differ  from physicians with significant P values.", "labels": [], "entities": [{"text": "P", "start_pos": 219, "end_pos": 220, "type": "METRIC", "confidence": 0.946406364440918}]}, {"text": " Table 1. Correlation coefficients and significance of  the correlation", "labels": [], "entities": [{"text": "Correlation", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9749387502670288}, {"text": "significance", "start_pos": 39, "end_pos": 51, "type": "METRIC", "confidence": 0.972496509552002}]}, {"text": " Table 2. Average subject correlations minus average  physician correlations", "labels": [], "entities": [{"text": "Average subject correlations", "start_pos": 10, "end_pos": 38, "type": "METRIC", "confidence": 0.7491268912951151}, {"text": "physician correlations", "start_pos": 54, "end_pos": 76, "type": "METRIC", "confidence": 0.6243413984775543}]}]}