{"title": [{"text": "The Influence of Minimum Edit Distance on Reference Resolution", "labels": [], "entities": [{"text": "Reference Resolution", "start_pos": 42, "end_pos": 62, "type": "TASK", "confidence": 0.8293224573135376}]}], "abstractContent": [{"text": "We report on experiments in reference resolution using a decision tree approach.", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.8867542445659637}]}, {"text": "We started with a standard feature set used in previous work, which led to moderate results.", "labels": [], "entities": []}, {"text": "A closer examination of the performance of the features for different forms of anaphoric expressions showed good results for pronouns, moderate results for proper names, and poor results for definite noun phrases.", "labels": [], "entities": []}, {"text": "We then included a cheap, language and domain independent feature based on the minimum edit distance between strings.", "labels": [], "entities": []}, {"text": "This feature yielded a significant improvement for data sets consisting of definite noun phrases and proper names, respectively.", "labels": [], "entities": []}, {"text": "When applied to the whole data set the feature produced a smaller but still significant improvement.", "labels": [], "entities": []}], "introductionContent": [{"text": "For the automatic understanding of written or spoken natural language it is crucial to be able to identify the entities referred to by referring expressions.", "labels": [], "entities": [{"text": "automatic understanding of written or spoken natural language", "start_pos": 8, "end_pos": 69, "type": "TASK", "confidence": 0.7012534514069557}]}, {"text": "The most common and thus most important types of referring expressions are pronouns and definite noun phrases (NPs).", "labels": [], "entities": []}, {"text": "Supervised machine learning algorithms have been used for pronoun resolution) and for the resolution of definite NPs ().", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.7877506613731384}, {"text": "resolution of definite NPs", "start_pos": 90, "end_pos": 116, "type": "TASK", "confidence": 0.8172399401664734}]}, {"text": "An unsupervised approach to the resolution of definite NPs was applied by.", "labels": [], "entities": [{"text": "resolution of definite NPs", "start_pos": 32, "end_pos": 58, "type": "TASK", "confidence": 0.9014008641242981}]}, {"text": "However, though machine learning algorithms may deduce to make best use of a given set of features fora given problem, it is a linguistic question and a non-trivial task to identify a set of features which describe the data sufficiently.", "labels": [], "entities": []}, {"text": "We report on experiments in the resolution of anaphoric expressions in general, including definite noun phrases, proper names, and personal, possessive and demonstrative pronouns.", "labels": [], "entities": [{"text": "resolution of anaphoric expressions", "start_pos": 32, "end_pos": 67, "type": "TASK", "confidence": 0.888477236032486}]}, {"text": "Based on the work mentioned above we started with a feature set including NP-level and coreference-level features.", "labels": [], "entities": []}, {"text": "Applied to the whole data set these features led only to moderate results.", "labels": [], "entities": []}, {"text": "Since the NP form of the anaphor (i.e., whether the anaphoric expression is realized as pronoun, definite NP or proper name) appeared to be the most important feature, we divided the data set into several subsets based on the NP form of the anaphor.", "labels": [], "entities": []}, {"text": "This led to the insight that the moderate performance of our system was caused by the low performance for definite NPs.", "labels": [], "entities": []}, {"text": "We adopted anew feature based on the minimum edit distance) between anaphor and antecedent, which led to a significant improvement on definite NPs and proper names.", "labels": [], "entities": []}, {"text": "When applied to the whole data set the feature yielded a smaller but still significant improvement.", "labels": [], "entities": []}, {"text": "In this paper, we first discuss features that have been found to be relevant for the task of reference resolution (Section 2).", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 93, "end_pos": 113, "type": "TASK", "confidence": 0.9578550457954407}]}, {"text": "Then we describe our corpus, the corpus annotation, and the way we prepared the data for use with a binary machine learning classifier (Section 3).", "labels": [], "entities": []}, {"text": "In Section 4 we first describe the feature set used initially and the results it produced.", "labels": [], "entities": []}, {"text": "We then introduce the minimum edit distance feature and give the results it yielded on different data sets.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 4: Baseline results using features 2-15.", "labels": [], "entities": []}, {"text": " Table 5: Anaphors and their direct antecedents", "labels": [], "entities": []}, {"text": " Table 6: Additional Features (", "labels": [], "entities": []}, {"text": " Table 7: Improved results using features 2-17.", "labels": [], "entities": [{"text": "Improved", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9810416102409363}]}]}