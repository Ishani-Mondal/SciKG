{"title": [{"text": "Unsupervised discovery of morphologically related words based on orthographic and semantic similarity", "labels": [], "entities": []}], "abstractContent": [{"text": "We present an algorithm that takes an unannotated corpus as its input, and returns a ranked list of probable morphologically related pairs as its output.", "labels": [], "entities": []}, {"text": "The algorithm tries to discover morphologically related pairs by looking for pairs that are both orthographically and semantically similar, where orthographic similarity is measured in terms of minimum edit distance, and semantic similarity is measured in terms of mutual information.", "labels": [], "entities": []}, {"text": "The procedure does not rely on a morpheme concatenation model, nor on dis-tributional properties of word substrings (such as affix frequency).", "labels": [], "entities": []}, {"text": "Experiments with German and English input give encouraging results, both in terms of precision (proportion of good pairs found at various cutoff points of the ranked list), and in terms of a qualitative analysis of the types of morphological patterns discovered by the algorithm.", "labels": [], "entities": [{"text": "precision", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9994901418685913}]}], "introductionContent": [{"text": "In recent years, there has been much interest in computational models that learn aspects of the morphology of a natural language from raw or structured data.", "labels": [], "entities": []}, {"text": "Such models are of great practical interest as tools for descriptive linguistic analysis and for minimizing the expert resources needed to develop morphological analyzers and stemmers.", "labels": [], "entities": [{"text": "descriptive linguistic analysis", "start_pos": 57, "end_pos": 88, "type": "TASK", "confidence": 0.7761614123980204}]}, {"text": "From a theoretical point of view, morphological learning algorithms can help answer questions related to human language acquisition.", "labels": [], "entities": [{"text": "human language acquisition", "start_pos": 105, "end_pos": 131, "type": "TASK", "confidence": 0.6870972911516825}]}, {"text": "In this study, we present a system that, given a corpus of raw text from a language, returns a ranked list of probable morphologically related word pairs.", "labels": [], "entities": []}, {"text": "For example, when run with the Brown corpus as its input, our system returned a list with pairs such as pencil/pencils and structured/unstructured at the top.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 31, "end_pos": 43, "type": "DATASET", "confidence": 0.8326197862625122}]}, {"text": "Our algorithm is completely knowledge-free, in the sense that it processes raw corpus data, and it does not require any form of a priori information about the language it is applied to.", "labels": [], "entities": []}, {"text": "The algorithm performs unsupervised learning, in the sense that it does not require a correctly-coded standard to (iteratively) compare its output against.", "labels": [], "entities": []}, {"text": "The algorithm is based on the simple idea that a combination of formal and semantic cues should be exploited to identify morphologically related pairs.", "labels": [], "entities": []}, {"text": "In particular, we use minimum edit distance to measure orthographic similarity, and mutual information to measure semantic similarity.", "labels": [], "entities": []}, {"text": "The algorithm does not rely on the notion of affix, and it does not depend on global distributional properties of substrings (such as affix frequency).", "labels": [], "entities": []}, {"text": "Thus, at least in principle, the algorithm is well-suited to discover pairs that are related by rare and/or nonconcatenative morphological processes.", "labels": [], "entities": []}, {"text": "The algorithm returns a list of related pairs, but it does not attempt to extract the patterns that relate the pairs.", "labels": [], "entities": []}, {"text": "As such, it can be used as a tool to pre-process corpus data for an analysis to be performed by a human morphologist, or as the first step of a fully automated morphological learning program, to be followed, for example, by a rule induction procedure that extracts correspondence patterns from paired forms.", "labels": [], "entities": []}, {"text": "See the last section of this paper for further discussion of possible applications.", "labels": [], "entities": []}, {"text": "We tested our model with German and English input.", "labels": [], "entities": []}, {"text": "Our results indicate that the algorithm is able to identify a number of pairs related by a variety of derivational and inflectional processes with a remarkably high precision rate.", "labels": [], "entities": [{"text": "precision rate", "start_pos": 165, "end_pos": 179, "type": "METRIC", "confidence": 0.9818200767040253}]}, {"text": "The algorithm is also discovering morphological relationships (such as German plural formation with umlaut) that would probably be harder to discover using affix-based approaches.", "labels": [], "entities": [{"text": "German plural formation", "start_pos": 71, "end_pos": 94, "type": "TASK", "confidence": 0.6290265222390493}]}, {"text": "The remainder of the paper is organized as follows: In section 2, we shortly review related work.", "labels": [], "entities": []}, {"text": "In section 3, we present our model.", "labels": [], "entities": []}, {"text": "In section 4, we discuss the results of experiments with German and English input.", "labels": [], "entities": []}, {"text": "Finally, in section 5 we summarize our main results, we sketch possible directions that our current work could take, and we discuss some potential uses for the output of our algorithm.", "labels": [], "entities": []}], "datasetContent": [{"text": "We tested our procedure on the German APA corpus, a corpus of newswire containing over twenty-eight million word tokens, and on the English Brown corpus (, a balanced corpus containing less than one million two hundred thousand word tokens.", "labels": [], "entities": [{"text": "German APA corpus", "start_pos": 31, "end_pos": 48, "type": "DATASET", "confidence": 0.8762235244115194}, {"text": "English Brown corpus", "start_pos": 132, "end_pos": 152, "type": "DATASET", "confidence": 0.9629790186882019}]}, {"text": "Of course, the most important difference between these two corpora is that they represent different languages.", "labels": [], "entities": []}, {"text": "However, observe also that they have very different sizes, and that they are different in terms of the types of texts constituting them.", "labels": [], "entities": []}, {"text": "Besides the high frequency trimming procedure described above, for both languages we removed from the potential content word lists those words that were not recognized by the XEROX morphological analyzer for the relevant language.", "labels": [], "entities": []}, {"text": "The reason for this is that, as we describe below, we use this tool to build the reference sets for evaluation purposes.", "labels": [], "entities": []}, {"text": "Thus, morphologically related pairs composed of words not recognized by the analyzer would unfairly lower the precision of our algorithm.", "labels": [], "entities": [{"text": "precision", "start_pos": 110, "end_pos": 119, "type": "METRIC", "confidence": 0.9992899894714355}]}, {"text": "Moreover, after some preliminary experimentation, we also decided to remove words longer than 9 characters from the German list (this corresponds to trimming words whose length is one standard deviation or more above the average token length).", "labels": [], "entities": [{"text": "German list", "start_pos": 116, "end_pos": 127, "type": "DATASET", "confidence": 0.8945300281047821}, {"text": "trimming words", "start_pos": 149, "end_pos": 163, "type": "TASK", "confidence": 0.8851715326309204}]}, {"text": "This actually lowers the performance of our system, but makes the results easier to analyze -otherwise, the top of the German list would be cluttered by a high number of rather uninteresting morphological pairs formed by inflected forms from the paradigm of very long nominal compounds (such as Wirtschaftsforschungsinstitut 'institute for economic research').", "labels": [], "entities": []}, {"text": "Unlike high frequency trimming, the two operations we just described are meant to facilitate empirical evaluation, and they do not constitute necessary steps of the core algorithm.", "labels": [], "entities": [{"text": "high frequency trimming", "start_pos": 7, "end_pos": 30, "type": "TASK", "confidence": 0.6910771528879801}]}], "tableCaptions": [{"text": " Table 1: German precision at various cutoff points  (5279 = total number of pairs)", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9745705127716064}]}, {"text": " Table 2: English precision at various cutoff points  (8902 = total number of pairs)", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9622756242752075}]}, {"text": " Table 3: The most common German suffixation and  prefixation patterns", "labels": [], "entities": [{"text": "German suffixation and  prefixation", "start_pos": 26, "end_pos": 61, "type": "TASK", "confidence": 0.5968081280589104}]}, {"text": " Table 4: The most common English suffixation and  prefixation patterns", "labels": [], "entities": [{"text": "English suffixation and  prefixation", "start_pos": 26, "end_pos": 62, "type": "TASK", "confidence": 0.68192557990551}]}, {"text": " Table 5: Some German rules involving stem vowel  changes found by the rule extractor", "labels": [], "entities": []}]}