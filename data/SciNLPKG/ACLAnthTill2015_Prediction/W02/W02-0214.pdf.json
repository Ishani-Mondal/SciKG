{"title": [{"text": "Topic Identification In Natural Language Dialogues Using Neural Networks", "labels": [], "entities": [{"text": "Topic Identification", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8938815891742706}]}], "abstractContent": [{"text": "In human-computer interaction systems using natural language, the recognition of the topic from user's utterances is an important task.", "labels": [], "entities": [{"text": "recognition of the topic from user's utterances", "start_pos": 66, "end_pos": 113, "type": "TASK", "confidence": 0.8194562569260597}]}, {"text": "We examine two different perspectives to the problem of topic analysis needed for carrying out a successful dialogue.", "labels": [], "entities": [{"text": "topic analysis", "start_pos": 56, "end_pos": 70, "type": "TASK", "confidence": 0.7970452904701233}]}, {"text": "First, we apply self-organized document maps for mod-eling the broader subject of discourse based on the occurrence of content words in the dialogue context.", "labels": [], "entities": []}, {"text": "On a Finnish corpus of 57 dialogues the method is shown to work well for recognizing subjects of longer dialogue segments, whereas for individual utterances the subject recognition history should perhaps betaken into account.", "labels": [], "entities": [{"text": "Finnish corpus of 57 dialogues", "start_pos": 5, "end_pos": 35, "type": "DATASET", "confidence": 0.8589616537094116}]}, {"text": "Second , we attempt to identify topically relevant words in the utterances and thus locate the old information ('topic words') and new information ('focus words').", "labels": [], "entities": []}, {"text": "For this we define a probabilistic model and compare different methods for model parameter estimation on a corpus of 189 dialogues.", "labels": [], "entities": []}, {"text": "Moreover, the utilization of information regarding the position of the word in the utterance is found to improve the results.", "labels": [], "entities": []}], "introductionContent": [{"text": "The analysis of the topic of a sentence or a document is an important task for many natural language applications.", "labels": [], "entities": [{"text": "analysis of the topic of a sentence or a document", "start_pos": 4, "end_pos": 53, "type": "TASK", "confidence": 0.8700752854347229}]}, {"text": "For example, in interactive dialogue systems that attempt to carryout and answer requests made by customers, the response strategy employed may depend on the topic of the request).", "labels": [], "entities": []}, {"text": "In large vocabulary speech recognition knowledge of the topic can, in general, be utilized for adjusting the language model used (see, e.g.,).", "labels": [], "entities": [{"text": "large vocabulary speech recognition", "start_pos": 3, "end_pos": 38, "type": "TASK", "confidence": 0.7455975711345673}]}, {"text": "We describe two approaches to analyzing the topical information, namely the use of topically ordered document maps for analyzing the overall topic of dialogue segments, and identification of topic and focus words in an utterance for sentence-level analysis and identification of topically relevant specific information in short contexts.", "labels": [], "entities": [{"text": "identification of topically relevant specific information in short contexts", "start_pos": 261, "end_pos": 336, "type": "TASK", "confidence": 0.8648670249515109}]}], "datasetContent": [{"text": "The ordered document map can be utilized in the analysis of dialogue topics as follows: encode a dialogue turn, i.e., an utterance u (or an utterance combined with its recent history) as a document vector.", "labels": [], "entities": []}, {"text": "Locate the bestmatching map unit, or several such units.", "labels": [], "entities": []}, {"text": "Utilize the identities of the best units as a semantic representation of the topic of the u.", "labels": [], "entities": []}, {"text": "In effect, this is a latent semantic representation of the topical content of the utterance.", "labels": [], "entities": []}, {"text": "Evaluation of such a latent representation directly amounts to asking whether the dialogue manager can benefit from the representation, and must therefore be carried out by the dialogue manager.", "labels": [], "entities": []}, {"text": "This direct evaluation has not yet been done.", "labels": [], "entities": []}, {"text": "Instead, we have utilized the following approach for evaluating the ordering of the maps and the generalization to new, unseen dialogues: An intermediate set of named semantic concepts has been defined in an attempt to approximate what is considered to be interesting for the dialogue manager.", "labels": [], "entities": []}, {"text": "The latent semantic representation of the map is then labeled or calibrated to reflect these named concepts.", "labels": [], "entities": []}, {"text": "In effect, each dialogue segment is categorized to a prior topical category.", "labels": [], "entities": []}, {"text": "The organized map is labeled using part of the data ('training data'), and the remaining part is used to evaluate the map ('test data') 1 . 1 Note that even in this case the map is ordered in Furthermore, a statistical model for document classification can be defined on top of the map.", "labels": [], "entities": [{"text": "document classification", "start_pos": 229, "end_pos": 252, "type": "TASK", "confidence": 0.7134865522384644}]}, {"text": "The probability model used for topic estimation is where A i is the topic category, S denotes the text transcription of the spoken sentence and X N is the set of N best map vectors used for the classification.", "labels": [], "entities": [{"text": "topic estimation", "start_pos": 31, "end_pos": 47, "type": "TASK", "confidence": 0.9594555497169495}]}, {"text": "We approximate the probability P (X N |S) to be equal for each map vector in X N . We assume that X N conveys all information about S.", "labels": [], "entities": []}, {"text": "The terms P (A i |X N ) are calculated as the relative frequencies of the topics of the document vectors in the training data that were mapped to the nodes that correspond to X N .  The following experiment was performed using each described method: For each utterance in the test data, n words were tagged as topic, and likewise for the focus category.", "labels": [], "entities": []}, {"text": "Further, n was varied from 1 to 8 to produce the results depicted in.", "labels": [], "entities": []}, {"text": "As can be seen, the Bayesian variational analysis and the maximum likelihood estimation produce nearly identical performances.", "labels": [], "entities": [{"text": "maximum likelihood estimation", "start_pos": 58, "end_pos": 87, "type": "METRIC", "confidence": 0.733157753944397}]}, {"text": "This is perhaps due to the use of very smooth model family, namely first-order polynomials, for taking into account the effect of the position of the word.", "labels": [], "entities": []}, {"text": "For this reason, overlearn- ing is not problem even for the ML estimation.", "labels": [], "entities": [{"text": "overlearn- ing", "start_pos": 17, "end_pos": 31, "type": "METRIC", "confidence": 0.796803613503774}, {"text": "ML estimation", "start_pos": 60, "end_pos": 73, "type": "TASK", "confidence": 0.5764352232217789}]}, {"text": "However, since the nearly identical results were obtained using two completely different implementations of quite similar methods, this can be considered as a validation experiment on either implementation and optimization method.", "labels": [], "entities": []}, {"text": "In total, it seems that the full statistical model designed works rather well especially in focus identification.", "labels": [], "entities": [{"text": "focus identification", "start_pos": 92, "end_pos": 112, "type": "TASK", "confidence": 0.9239685535430908}]}, {"text": "When compared to the full model, disregarding position information altoghether results in inferior performance.", "labels": [], "entities": []}, {"text": "The difference is statistically significant (p \u2264 0.05) in focus identification for all values of n and in topic identification for small values of n.", "labels": [], "entities": [{"text": "focus identification", "start_pos": 58, "end_pos": 78, "type": "TASK", "confidence": 0.7930538952350616}, {"text": "topic identification", "start_pos": 106, "end_pos": 126, "type": "TASK", "confidence": 0.7951102256774902}]}, {"text": "Moreover, the performance of the tf\u00d7idf scheme is clearly inferior in either task.", "labels": [], "entities": []}, {"text": "However, it seems that the tf\u00d7idf definition of word importance corresponds more closely with the definition of 'focus' than that of 'topic'.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Proportions of customer utterances  in each topic category in the data sets.  Training data Test data  Beginnings  0.08  0.11  Endings  0.12  0.14  Timetables  0.49  0.59  Tickets  0.16  0.11  OOD  0.15  0.06", "labels": [], "entities": [{"text": "Training data Test data  Beginnings  0.08  0.11  Endings  0.12  0.14  Timetables  0.49  0.59  Tickets  0.16  0.11  OOD  0.15  0.06", "start_pos": 88, "end_pos": 218, "type": "METRIC", "confidence": 0.58390810615138}]}]}