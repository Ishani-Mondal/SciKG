{"title": [{"text": "An overview of Amalgam: A machine-learned generation module", "labels": [], "entities": [{"text": "Amalgam", "start_pos": 15, "end_pos": 22, "type": "DATASET", "confidence": 0.8084799647331238}]}], "abstractContent": [{"text": "We present an overview of Amalgam, a sentence realization module that combines machine-learned and knowledge-engineered components to produce natural language sentences from logical form inputs.", "labels": [], "entities": [{"text": "sentence realization module", "start_pos": 37, "end_pos": 64, "type": "TASK", "confidence": 0.796159029006958}]}, {"text": "We describe the decomposition of the task of sentence realization into a linguistically informed series of steps, with particular attention to the linguistic issues that arise in German.", "labels": [], "entities": [{"text": "sentence realization", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.7186335027217865}]}, {"text": "We report on the evaluation of component steps and of the overall system.", "labels": [], "entities": []}], "introductionContent": [{"text": "Since the mid 1990s, there has been increasing interest in the application of statistical and machine learning techniques to various aspects of natural language generation, ranging from learning plans for high-level organization of texts and dialogues or ensuring that the macro properties of generated texts such as the distribution of sentence lengths and lexical variety mirror the properties of naturally occurring texts) to sentence planning (.).", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 144, "end_pos": 171, "type": "TASK", "confidence": 0.6492547790209452}, {"text": "sentence planning", "start_pos": 429, "end_pos": 446, "type": "TASK", "confidence": 0.8234611451625824}]}, {"text": "As generation proceeds through successively less abstract stages, nearing the final output string, it would appear that current generation systems are still likely to employ knowledge-engineered approaches.", "labels": [], "entities": []}, {"text": "Indeed, commenting on sentence realization, rather succinctly summarize what is no doubt a widely-held belief, namely that \"This phase is not a planning phase in that it only executes decisions made previously.\"", "labels": [], "entities": [{"text": "sentence realization", "start_pos": 22, "end_pos": 42, "type": "TASK", "confidence": 0.728770300745964}]}, {"text": "Although the kinds and number of decisions to be made during sentence realization will depend on the nature of the prior sentence planning phase and on the linguistic complexity of the domain, myriad encoding decisions must still be made.", "labels": [], "entities": [{"text": "sentence realization", "start_pos": 61, "end_pos": 81, "type": "TASK", "confidence": 0.7359261810779572}]}, {"text": "Machine learning approaches have been successfully applied to such aspects of sentence realization as determining the appropriate form of referring expressions () and the grammatical relations of noun phrases) as well as performing lexical selection ().", "labels": [], "entities": [{"text": "sentence realization", "start_pos": 78, "end_pos": 98, "type": "TASK", "confidence": 0.7501780390739441}]}, {"text": "Traditional knowledge engineering approaches to sentence realization founder on our inadequate understanding of the mapping from propositional content to surface form, a mapping that encompasses such problems as equi-NP deletion, movement operations such as extraposition and left-dislocation, ordering of modifiers within constituents, and voice alternations.", "labels": [], "entities": [{"text": "sentence realization", "start_pos": 48, "end_pos": 68, "type": "TASK", "confidence": 0.7367697656154633}]}, {"text": "Research in knowledge engineered solutions to these problems continues (see for example,).", "labels": [], "entities": []}, {"text": "However, the task of broad-coverage sentence realization would appear to be of comparable complexity to sentence analysis, and equally difficult to adapt to new domains.", "labels": [], "entities": [{"text": "broad-coverage sentence realization", "start_pos": 21, "end_pos": 56, "type": "TASK", "confidence": 0.6881166199843088}, {"text": "sentence analysis", "start_pos": 104, "end_pos": 121, "type": "TASK", "confidence": 0.7459712028503418}]}, {"text": "Sentence realization therefore appears to bean ideal candidate for statistical and machinelearned approaches.", "labels": [], "entities": [{"text": "Sentence realization", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9452981352806091}]}, {"text": "Some recently described systems have attempted to side-step the encoding decisions involved in sentence realization by proposing alternative realizations of an input semantic form and leaving it to a word-level language model to select the most likely candidate sentence for output.", "labels": [], "entities": [{"text": "sentence realization", "start_pos": 95, "end_pos": 115, "type": "TASK", "confidence": 0.7448968887329102}]}, {"text": "The Nitrogen system, for example, uses a rather permissive knowledge-engineered component to propose candidate output sentences that are then scored using word bigrams.", "labels": [], "entities": []}, {"text": "Statistics garnered from actual texts are thus used as a substitute for deeper knowledge.", "labels": [], "entities": []}, {"text": "The addition of syntactic information, either to constrain the range of candidate sentences or to augment the n-gram model, has produced favorable improvements over n-gram models used alone ().", "labels": [], "entities": []}, {"text": "In the current paper we describe an on-going research project code-named Amalgam.", "labels": [], "entities": [{"text": "Amalgam", "start_pos": 73, "end_pos": 80, "type": "DATASET", "confidence": 0.9231157898902893}]}, {"text": "Amalgam is a (predominantly) machine-learned generation module that performs sentence realization and a small degree of lexical selection.", "labels": [], "entities": [{"text": "sentence realization", "start_pos": 77, "end_pos": 97, "type": "TASK", "confidence": 0.7491700053215027}]}, {"text": "Amalgam takes as input a logical form graph.", "labels": [], "entities": []}, {"text": "Proceeding through a series of machine-learned and knowledgeengineered steps, it transforms that graph into a fully articulated tree structure from which an output sentence can be read.", "labels": [], "entities": []}, {"text": "Amalgam has been successfully applied to the realization of non-trivial German sentences in diverse technical domains.", "labels": [], "entities": [{"text": "Amalgam", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.783345639705658}]}, {"text": "An extended description is given in.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1 Accuracy of decision classifiers", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9956890940666199}]}]}