{"title": [{"text": "Bootstrapping Lexical Choice via Multiple-Sequence Alignment", "labels": [], "entities": [{"text": "Multiple-Sequence Alignment", "start_pos": 33, "end_pos": 60, "type": "TASK", "confidence": 0.6938318461179733}]}], "abstractContent": [{"text": "An important component of any generation system is the mapping dictionary, a lexicon of elementary semantic expressions and corresponding natural language realizations.", "labels": [], "entities": []}, {"text": "Typically, labor-intensive knowledge-based methods are used to construct the dictionary.", "labels": [], "entities": []}, {"text": "We instead propose to acquire it automatically via a novel multiple-pass algorithm employing multiple-sequence alignment , a technique commonly used in bioin-formatics.", "labels": [], "entities": [{"text": "multiple-sequence alignment", "start_pos": 93, "end_pos": 120, "type": "TASK", "confidence": 0.6875903904438019}]}, {"text": "Crucially, our method leverages latent information contained in multi-parallel corpora-datasets that supply several verbalizations of the corresponding semantics rather than just one.", "labels": [], "entities": []}, {"text": "We used our techniques to generate natural language versions of computer-generated mathematical proofs, with good results on both a per-component and overall-output basis.", "labels": [], "entities": []}, {"text": "For example, in evaluations involving a dozen human judges, our system produced output whose readability and faith-fulness to the semantic input rivaled that of a traditional generation system.", "labels": [], "entities": []}], "introductionContent": [{"text": "One or two homologous sequences whisper . .", "labels": [], "entities": []}, {"text": "a full multiple alignment shouts out loud).", "labels": [], "entities": []}, {"text": "Today's natural language generation systems typically employ a lexical chooser that translates complex semantic concepts into words.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 8, "end_pos": 35, "type": "TASK", "confidence": 0.7112013498942057}]}, {"text": "The lexical chooser relies on a mapping dictionary that lists possible realizations of elementary semantic concepts; sample entries might be [Parent [sex:female]] \u2192 mother or love(x,y )\u2192 {x loves y, x is in love with y}.", "labels": [], "entities": []}, {"text": "To date, creating these dictionaries has involved human analysis of a domain-relevant corpus comprised of semantic representations and corresponding human verbalizations).", "labels": [], "entities": []}, {"text": "The corpus analysis and knowledge engineering work required in such an approach is substantial, prohibitively so in large domains.", "labels": [], "entities": [{"text": "corpus analysis", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.7039736360311508}]}, {"text": "But, since corpus data is already used in building lexical choosers by hand, an appealing alternative is to have the system learn a mapping dictionary directly from the data.", "labels": [], "entities": []}, {"text": "Clearly, this would greatly reduce the human effort involved and ease porting the system to new domains.", "labels": [], "entities": []}, {"text": "Hence, we address the following problem: given a parallel (but unaligned) corpus consisting of both complex semantic input and corresponding natural language verbalizations, learn a semantics-to-words mapping dictionary automatically.", "labels": [], "entities": []}, {"text": "Now, we could simply apply standard statistical machine translation methods, treating verbalizations as \"translations\" of the semantics.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.668795516093572}]}, {"text": "These methods typically rely on one-parallel corpora consisting of text pairs, one in each \"language\" (but cf.; see Section 5).", "labels": [], "entities": []}, {"text": "However, learning the kind of semantics-to-words mapping that we desire from one-parallel data alone is difficult even for humans.", "labels": [], "entities": []}, {"text": "First, given the same semantic input, different authors may (and do) delete or insert information (see; hence, direct comparison between a semantic text and a single verbalization may not provide enough information regarding their underlying correspondences.", "labels": [], "entities": []}, {"text": "Second, a single verbalization certainly fails to convey the variety of potential linguistic realizations of the concept that an expressive lexical chooser would ideally have access to.", "labels": [], "entities": []}, {"text": "The multiple-sequence idea Our approach is motivated by an analogous situation that arises in computational biology.", "labels": [], "entities": []}, {"text": "In brief, an important bioin-1 Throughout, fonts denote a mapping dictionary's two information types: semantics and realizations..", "labels": [], "entities": []}, {"text": "Note how the three indicated \"sausages\" roughly correspond to the three arguments of show-from(a=0,b=0,a * b=0).", "labels": [], "entities": []}, {"text": "(The phrases \"as in the theorem statement\" and \"their product\" correspond to chains of nodes, but are drawn as single nodes for clarity.", "labels": [], "entities": []}, {"text": "Shading indicates argument-value matches (Section 3.1).", "labels": [], "entities": []}, {"text": "All lattice figures omit punctuation nodes for clarity.)", "labels": [], "entities": []}, {"text": "(1) Given a and b as in the theorem statement, prove that a * b=0.", "labels": [], "entities": []}, {"text": "(2) Suppose that a and bare equal to zero.", "labels": [], "entities": []}, {"text": "Prove that their product is also zero.", "labels": [], "entities": []}, {"text": "(3) Assume that a=0 and b=0.", "labels": [], "entities": []}, {"text": "formatics problem -Gusfield (1997) refers to it as \"The Holy Grail\" -is to determine commonalities within a collection of biological sequences such as proteins or genes.", "labels": [], "entities": []}, {"text": "Because of mutations within individual sequences, such as changes, insertions, or deletions, pair-wise comparison of sequences can fail to reveal which features are conserved across the entire group.", "labels": [], "entities": []}, {"text": "Hence, biologists compare multiple sequences simultaneously to reveal hidden structure characteristic to the group as a whole.", "labels": [], "entities": []}, {"text": "Our work applies multiple-sequence alignment techniques to the mapping-dictionary acquisition problem.", "labels": [], "entities": [{"text": "multiple-sequence alignment", "start_pos": 17, "end_pos": 44, "type": "TASK", "confidence": 0.7374495267868042}, {"text": "mapping-dictionary acquisition", "start_pos": 63, "end_pos": 93, "type": "TASK", "confidence": 0.7638334333896637}]}, {"text": "The main idea is that using a multi-parallel corpus -one that supplies several alternative verbalizations for each semantic expression -can enhance both the accuracy and the expressiveness of the resulting dictionary.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 157, "end_pos": 165, "type": "METRIC", "confidence": 0.9987413287162781}]}, {"text": "In particular, matching a semantic expression against a composite of the common structural features of a set of verbalizations ameliorates the effect of \"mutations\" within individual verbalizations.", "labels": [], "entities": []}, {"text": "Furthermore, the existence of multiple verbalizations helps the system learn several ways to express concepts.", "labels": [], "entities": []}, {"text": "To illustrate, consider a sample semantic expression from the mathematical theorem-proving domain.", "labels": [], "entities": []}, {"text": "The expression show-from(a=0,b=0,a * b=0) means \"assuming the two premises a = 0 and b = 0, show that the goal a * b = 0 holds\".", "labels": [], "entities": []}, {"text": "shows three human verbalizations of this expression.", "labels": [], "entities": []}, {"text": "Even for so formal a domain as mathematics, the verbalizations vary considerably, and none directly matches the entire semantic input.", "labels": [], "entities": []}, {"text": "For instance, it is not obvious without domain knowledge that \"Given a and b as in the theorem statement\" matches \"a=0\" and \"b=0\", nor that \"their product\" and \"a * b\" are equivalent.", "labels": [], "entities": []}, {"text": "Moreover, sentence (3) omits the goal argument entirely.", "labels": [], "entities": []}, {"text": "However, as shows, the combination of these verbalizations, as computed by our multiple-sequence alignment method, exhibits high structural similarity to the semantic input: the indicated \"sausage\" structures correspond closely to the three arguments of show-from.", "labels": [], "entities": []}], "datasetContent": [{"text": "We implemented our system on formal mathematical proofs created by the Nuprl system, which has been used to create thousands of proofs in many mathematical fields.", "labels": [], "entities": [{"text": "Nuprl system", "start_pos": 71, "end_pos": 83, "type": "DATASET", "confidence": 0.9482751786708832}]}, {"text": "Generating natural-language versions of proofs was first addressed several decades ago.", "labels": [], "entities": [{"text": "Generating natural-language versions of proofs", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.8534138321876525}]}, {"text": "But now, large formal-mathematics libraries are available on-line.", "labels": [], "entities": []}, {"text": "6 Unfortunately, they are usually encoded in highly technical languages (see).", "labels": [], "entities": []}, {"text": "Naturallanguage versions of these proofs would make them more widely accessible, both to users lacking familiarity with a specific prover's language, and to search engines which at present cannot search the symbolic language of formal proofs.", "labels": [], "entities": []}, {"text": "Besides these practical benefits, the formal mathematics domain has the further advantage of being particularly suitable for applying statistical generation techniques.", "labels": [], "entities": [{"text": "statistical generation", "start_pos": 134, "end_pos": 156, "type": "TASK", "confidence": 0.831665575504303}]}, {"text": "Training data is available because theorem-prover developers frequently provide verbalizations of system outputs for explanatory purposes.", "labels": [], "entities": []}, {"text": "In our case, a multi-parallel corpus of Nuprl proof verbalizations already exists) and forms the core of our training corpus.", "labels": [], "entities": []}, {"text": "Also, from a research point of view, the examples from show that there is a surprising variety in the data, making the problem quite challenging.", "labels": [], "entities": []}, {"text": "All evaluations reported here involved judgments from graduate students and researchers in computer science.", "labels": [], "entities": []}, {"text": "We authors were not among the judges.", "labels": [], "entities": []}, {"text": "We first evaluated three individual components of our system: paraphrase thesaurus induction, argument-value selection in slotted lattice induction, and template induction.", "labels": [], "entities": [{"text": "paraphrase thesaurus induction", "start_pos": 62, "end_pos": 92, "type": "TASK", "confidence": 0.6627031167348226}]}, {"text": "We also validated the utility of multi-parallel, as opposed to one-parallel, data.", "labels": [], "entities": []}, {"text": "Paraphrase thesaurus We presented two judges with all 71 paraphrase pairs produced by our system.", "labels": [], "entities": []}, {"text": "They identified 87% and 82%, respectively, as being plausible substitutes within a mathematical context.", "labels": [], "entities": []}, {"text": "Argument-value selection We next measured how well our system matches semantic argument values with lattice node sequences.", "labels": [], "entities": []}, {"text": "We randomly selected 20 Nuprl steps and their corresponding verbalizations.", "labels": [], "entities": []}, {"text": "From this sample, a Nuprl expert identified the argument values that appeared in at least one corresponding verbalization; of the 46 such values, our system correctly matched lattice node sequences to 91%.", "labels": [], "entities": []}, {"text": "To study the relative effectiveness of using multi-parallel rather than one-parallel data, we also implemented a baseline system that used only one (randomly-selected) verbalization among the multiple possibilities.", "labels": [], "entities": []}, {"text": "This single-verbalization baseline matched only 44% of the values correctly, indicating the value of a multi-parallel-corpus approach.", "labels": [], "entities": []}, {"text": "Templates Thirdly, we randomly selected 20 induced templates; of these, a Nuprl expert determined that 85% were plausible verbalizations of the corresponding Nuprl.", "labels": [], "entities": []}, {"text": "This was a very large improvement over the single-verbalization baseline's 30%, again validating the multi-parallel-corpus approach.", "labels": [], "entities": []}, {"text": "Finally, we evaluated the quality of the text our system generates by comparing its output against the system of Holland-, which produces accurate and readable Nuprl proof verbalizations.", "labels": [], "entities": []}, {"text": "Their system has a hand-crafted lexical chooser derived via manual analysis of the same corpus that our system was trained on.", "labels": [], "entities": []}, {"text": "To run the experiments, we replaced Holland-Minkley et. al's lexical chooser with the mapping dictionary we induced.", "labels": [], "entities": []}, {"text": "(An alternative evaluation would have been to compare our output with human-authored texts.", "labels": [], "entities": []}, {"text": "But this wouldn't have allowed us to evaluate the performance of the lexical chooser alone, as human proof generation may differ in aspects other than lexical choice.)", "labels": [], "entities": []}, {"text": "The test set serving as input to the two systems consisted of 20 held-out proofs, unseen throughout the entirety of our algorithm development work.", "labels": [], "entities": []}, {"text": "We evaluated the texts on two dimensions: readability and fidelity to the mathematical semantics.", "labels": [], "entities": []}, {"text": "Readability We asked 11 judges to compare the readability of the texts produced from the same Nuprl proof input:(ii) and (iii) show an example text pair.", "labels": [], "entities": []}, {"text": "9 (The judges were not given the original Nuprl proofs.) shows the results.", "labels": [], "entities": []}, {"text": "Good entries are those that are not preferences for the traditional system, since our goal, after all, is to show that MSA-based techniques can produce output as good or better than a hand-crafted system.", "labels": [], "entities": []}, {"text": "We see that for every lemma and for every judge, our system performed quite well.", "labels": [], "entities": []}, {"text": "Furthermore, for more than half of the lemmas, more than half the: Readability results.", "labels": [], "entities": []}, {"text": "\ud97b\udf59: preference for our system.", "labels": [], "entities": []}, {"text": "\ud97b\udf59: preference for hand-crafted system.", "labels": [], "entities": []}, {"text": "\ud97b\udf59: > 50% of the judges preferred the statistical system's output.", "labels": [], "entities": []}, {"text": "judges found our system's output to be distinctly better than the traditional system's.", "labels": [], "entities": []}, {"text": "Fidelity We asked a Nuprl-familiar expert informal logic to determine, given the Nuprl proofs and output texts, whether the texts preserved the main ideas of the formal proofs without introducing ambiguities.", "labels": [], "entities": []}, {"text": "All 20 of our system's proofs were judged correct, while only 17 of the traditional system's proofs were judged to be correct.", "labels": [], "entities": []}], "tableCaptions": []}