{"title": [{"text": "The Importance of Lexicalized Syntax Models for Natural Language Generation Tasks", "labels": [], "entities": [{"text": "Natural Language Generation Tasks", "start_pos": 48, "end_pos": 81, "type": "TASK", "confidence": 0.7625471353530884}]}], "abstractContent": [{"text": "The parsing community has long recognized the importance of lexicalized models of syntax.", "labels": [], "entities": []}, {"text": "By contrast, these models do not appear to have had an impact on the statistical NLG community.", "labels": [], "entities": []}, {"text": "To prove their importance in NLG, we show that a lexicalized model of syntax improves the performance of a statistical text compression system, and show results that suggest it would also improve the performances of an MT application and a pure natural language generation system.", "labels": [], "entities": [{"text": "statistical text compression", "start_pos": 107, "end_pos": 135, "type": "TASK", "confidence": 0.6237316330273946}, {"text": "MT application", "start_pos": 219, "end_pos": 233, "type": "TASK", "confidence": 0.9078478515148163}]}], "introductionContent": [{"text": "We distinguish between three types of language models: -gram language models look only at word sequences to gauge the quality of a sentence.", "labels": [], "entities": []}, {"text": "\u00a2 Non-lexicalized syntax models consider only syntactic structure down to the level of word tags in assessing the grammaticality of a sentence.", "labels": [], "entities": []}, {"text": "A PCFG is an example of such a model.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 2, "end_pos": 6, "type": "DATASET", "confidence": 0.9190214276313782}]}, {"text": "\u00a2 Lexicalized syntax models take into account both sentence syntax and lexical values when determining the quality of a sentence.", "labels": [], "entities": []}, {"text": "The parsing community has long recognized the importance of lexicalized models of syntax for building robust natural language applications.", "labels": [], "entities": []}, {"text": "For example, showed that by using a lexicalized syntax model instead of a nonlexicalized PCFG syntax model trained on Penn . More sophisticated lexicalized models of syntax have increased the performance of syntactic parsers to \u00a7 \u00a7 labeled recall and precision.", "labels": [], "entities": [{"text": "Penn", "start_pos": 118, "end_pos": 122, "type": "DATASET", "confidence": 0.9666196703910828}, {"text": "recall", "start_pos": 240, "end_pos": 246, "type": "METRIC", "confidence": 0.99101722240448}, {"text": "precision", "start_pos": 251, "end_pos": 260, "type": "METRIC", "confidence": 0.9984664916992188}]}, {"text": "Lexicalized models of syntax have been also proven useful in speech recognition) and language modeling.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.8277633190155029}, {"text": "language modeling", "start_pos": 85, "end_pos": 102, "type": "TASK", "confidence": 0.7862008810043335}]}, {"text": "By contrast, lexicalized models of syntax do not appear to have had an impact on the statistical NLG community., for example, use an \u00a3 -gram model to select between different lexical renderings of a meaning representation.", "labels": [], "entities": []}, {"text": "use a combination of bigram and context free probabilities to select between sentence compressions.", "labels": [], "entities": []}, {"text": "To our knowledge, the only NLG work that resonates with the work in parsing, speech recognition, and language modeling is that of, who show that a statistical generation system that uses a lexicalized hierarchical model of syntax outperforms a system that uses a random model.", "labels": [], "entities": [{"text": "parsing", "start_pos": 68, "end_pos": 75, "type": "TASK", "confidence": 0.9738666415214539}, {"text": "speech recognition", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.7184205800294876}, {"text": "language modeling", "start_pos": 101, "end_pos": 118, "type": "TASK", "confidence": 0.7199394702911377}]}, {"text": "Given the small interest in exploiting lexicalized models of syntax in NLG, we may conclude that such models have no role to play in this area.", "labels": [], "entities": []}, {"text": "In this paper, we show that this is not the case.", "labels": [], "entities": []}, {"text": "To prove the importance of lexicalized models of syntax in NLG, we focus on three distinct tasks, each involving a generation component.", "labels": [], "entities": []}, {"text": "First, we show that a lexicalized model of syntax can improve the performance of a statistics-based text compression system.", "labels": [], "entities": []}, {"text": "Second, we show that a lexicalized model of syntax may improve the outputs of a Chinese-toEnglish machine translation system.", "labels": [], "entities": [{"text": "Chinese-toEnglish machine translation", "start_pos": 80, "end_pos": 117, "type": "TASK", "confidence": 0.5390227834383646}]}, {"text": "Finally, we analyze the results of a pure natural language generation system.", "labels": [], "entities": []}, {"text": "In each experiment, we assess the impact that a lexicalized model of syntax may have on improving the quality of existing systems using an off-the-shelf component: the parser built by.", "labels": [], "entities": []}, {"text": "Our use of Charniak's parser provides fora loose coupling of a lexicalized model of syntax with a generation system, which is far from ideal.", "labels": [], "entities": []}, {"text": "Nevertheless, these experiments provide evidence that lexicalized models of syntax can improve the quality of the outputs of statistics-based generators.", "labels": [], "entities": []}, {"text": "Our results motivate work aimed at building generation systems that choose between possible renderings of the same meaning using not only n-gram probabilistic models, but lexicalized models of syntax, such as those proposed by and Charniak (2000).", "labels": [], "entities": []}], "datasetContent": [{"text": "After reranking, we performed the same error analysis as before.", "labels": [], "entities": [{"text": "error analysis", "start_pos": 39, "end_pos": 53, "type": "METRIC", "confidence": 0.955111026763916}]}, {"text": "The results for the new error analysis are summarized in.", "labels": [], "entities": []}, {"text": "We can see from the delta row in (negative numbers are good), that we removed most grammaticality errors.", "labels": [], "entities": []}, {"text": "We saw modest improvement with respect to the dropping of important modifiers; this is to be expected, though, since the syntax model has no idea of \"importance.\"", "labels": [], "entities": []}, {"text": "The same argument explains the minimal change in the missing antecedent problems.", "labels": [], "entities": []}, {"text": "We removed all instances of extra information but added seven additional counts of missing information.", "labels": [], "entities": []}, {"text": "Any summarization system must balance length of summary against informational and grammatical quality.", "labels": [], "entities": [{"text": "summarization", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.9603234529495239}, {"text": "length", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9799861311912537}]}, {"text": "In order to have more documents of higher grammaticality, more words are often nec-  essary, which reduces the amount of information which can be packed into a summary of comparable length.", "labels": [], "entities": []}, {"text": "Here, by removing most of the grammaticality errors, we caused the system to drop some of the important information.", "labels": [], "entities": []}, {"text": "To determine whether the changes in the system are noticeable to a user, we carried out a subjective evaluation.", "labels": [], "entities": []}, {"text": "We presented human judges with the outputs generated by the original text compression system, the results after rescoring, and humangenerated compressions.", "labels": [], "entities": []}, {"text": "These judges were asked to rank outputs on a scale from.", "labels": [], "entities": []}, {"text": "In the Wall Street Journal data, there was a moderate improvement in grammaticality, coherence and quality, as error analysis suggested.", "labels": [], "entities": [{"text": "Wall Street Journal data", "start_pos": 7, "end_pos": 31, "type": "DATASET", "confidence": 0.9780422002077103}]}, {"text": "In the Mitre data, grammaticality and quality went down significantly, while coherence remained steady.", "labels": [], "entities": [{"text": "Mitre data", "start_pos": 7, "end_pos": 17, "type": "DATASET", "confidence": 0.9746099412441254}, {"text": "quality", "start_pos": 38, "end_pos": 45, "type": "METRIC", "confidence": 0.9713219404220581}]}, {"text": "This can be attributed to two factors.", "labels": [], "entities": []}, {"text": "First, there were few errors in the Mitre data to start with and thus less room for improvement; Second, the Mitre data is out of domain for both the document compression system and for the parser, which leads to less reliable statistics.", "labels": [], "entities": [{"text": "Mitre data", "start_pos": 36, "end_pos": 46, "type": "DATASET", "confidence": 0.9306710660457611}, {"text": "Mitre data", "start_pos": 109, "end_pos": 119, "type": "DATASET", "confidence": 0.950584203004837}, {"text": "document compression", "start_pos": 150, "end_pos": 170, "type": "TASK", "confidence": 0.6690718531608582}]}], "tableCaptions": []}