{"title": [{"text": "Spoken Language Parsing Using Phrase-Level Grammars and Trainable Classifiers", "labels": [], "entities": [{"text": "Spoken Language Parsing", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8589255412419637}]}], "abstractContent": [{"text": "In this paper, we describe a novel approach to spoken language analysis for translation, which uses a combination of grammar-based phrase-level parsing and automatic classification.", "labels": [], "entities": [{"text": "spoken language analysis", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.7067054311434428}, {"text": "translation", "start_pos": 76, "end_pos": 87, "type": "TASK", "confidence": 0.8593164086341858}, {"text": "phrase-level parsing", "start_pos": 131, "end_pos": 151, "type": "TASK", "confidence": 0.6719086319208145}]}, {"text": "The job of the analyzer is to produce a shallow semantic interlingua representation for spoken task-oriented utterances.", "labels": [], "entities": []}, {"text": "The goal of our hybrid approach is to provide accurate real-time analyses while improving robustness and portability to new domains and languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "Interlingua-based approaches to Machine Translation (MT) are highly attractive in systems that support a large number of languages.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.8679485559463501}]}, {"text": "For each source language, an analyzer that converts the source language into the interlingua is required.", "labels": [], "entities": []}, {"text": "For each target language, a generator that converts the interlingua into the target language is needed.", "labels": [], "entities": []}, {"text": "Given analyzers and generators for all supported languages, the system simply connects the source language analyzer with the target language generator to perform translation.", "labels": [], "entities": []}, {"text": "Robust and accurate analysis is critical in interlingua-based translation systems.", "labels": [], "entities": [{"text": "interlingua-based translation", "start_pos": 44, "end_pos": 73, "type": "TASK", "confidence": 0.6176023185253143}]}, {"text": "In speech-tospeech translation systems, the analyzer must be robust to speech recognition errors, spontaneous speech, and ungrammatical inputs as described by.", "labels": [], "entities": [{"text": "speech-tospeech translation", "start_pos": 3, "end_pos": 30, "type": "TASK", "confidence": 0.6974921524524689}]}, {"text": "Furthermore, the analyzer should run in (near) real time.", "labels": [], "entities": []}, {"text": "In addition to accuracy, speed, and robustness, the portability of the analyzer with respect to new domains and new languages is an important consideration.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9993745684623718}, {"text": "speed", "start_pos": 25, "end_pos": 30, "type": "METRIC", "confidence": 0.97152179479599}]}, {"text": "Despite continuing improvements in speech recognition and translation technologies, restricted domains of coverage are still necessary in order to achieve reasonably accurate machine translation.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.7933374643325806}, {"text": "translation", "start_pos": 58, "end_pos": 69, "type": "TASK", "confidence": 0.7993540167808533}, {"text": "machine translation", "start_pos": 175, "end_pos": 194, "type": "TASK", "confidence": 0.7269992679357529}]}, {"text": "Porting translation systems to new domains or even expanding the coverage in an existing domain can be very difficult and timeconsuming.", "labels": [], "entities": [{"text": "Porting translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9264023900032043}]}, {"text": "This creates significant challenges in situations where translation is needed fora new domain within relatively short notice.", "labels": [], "entities": []}, {"text": "Likewise, demand can be high for translation systems that can be rapidly expanded to include new languages that were not previously considered important.", "labels": [], "entities": []}, {"text": "Thus, it is important that the analysis approach used in a translation system be portable to new domains and languages.", "labels": [], "entities": []}, {"text": "One approach to analysis in restricted domains is to use semantic grammars, which focus on parsing semantic concepts rather than syntactic structure.", "labels": [], "entities": []}, {"text": "Semantic grammars can be especially useful for parsing spoken language because they are less susceptible to syntactic deviations caused by spontaneous speech effects.", "labels": [], "entities": [{"text": "parsing spoken language", "start_pos": 47, "end_pos": 70, "type": "TASK", "confidence": 0.8911953965822855}]}, {"text": "However, the focus on meaning rather than syntactic structure generally makes porting to anew domain quite difficult.", "labels": [], "entities": [{"text": "porting", "start_pos": 78, "end_pos": 85, "type": "TASK", "confidence": 0.9672490954399109}]}, {"text": "Since semantic grammars do not exploit syntactic similarities across domains, completely new grammars must usually be developed.", "labels": [], "entities": []}, {"text": "While grammar-based parsing can provide very accurate analyses on development data, it is difficult fora grammar to completely cover a domain, a problem that is exacerbated by spoken input.", "labels": [], "entities": []}, {"text": "Furthermore, it generally takes a great deal of effort by human experts to develop a highcoverage grammar.", "labels": [], "entities": []}, {"text": "On the other hand, machine learning approaches can generalize beyond training data and tend to degrade gracefully in the face of noisy input.", "labels": [], "entities": []}, {"text": "Machine learning methods may, however, be less accurate on clearly in-domain input than grammars and may require a large amount of training data.", "labels": [], "entities": []}, {"text": "We describe a prototype version of an analyzer that combines phrase-level parsing and machine learning techniques to take advantage of the benefits of each.", "labels": [], "entities": [{"text": "phrase-level parsing", "start_pos": 61, "end_pos": 81, "type": "TASK", "confidence": 0.7714990675449371}]}, {"text": "Phrase-level semantic grammars and a robust parser are used to extract low-level interlingua arguments from an utterance.", "labels": [], "entities": []}, {"text": "Then, automatic classifiers assign high-level domain actions to semantic segments in the utterance.", "labels": [], "entities": []}], "datasetContent": [{"text": "We present the results from recent experiments to measure the performance of the analyzer components and of end-to-end translation using the analyzer.", "labels": [], "entities": []}, {"text": "We also report the results of an ablation experiment that used earlier versions of the analyzer and IF specification.", "labels": [], "entities": []}, {"text": "Acceptable Perfect SR Hypotheses 66% 56%  The training data contained 6409 SDUinterlingua pairs.", "labels": [], "entities": [{"text": "Acceptable Perfect SR Hypotheses", "start_pos": 0, "end_pos": 32, "type": "METRIC", "confidence": 0.8914787322282791}]}, {"text": "The data were randomly divided into 16 test sets containing 400 examples each.", "labels": [], "entities": []}, {"text": "In each fold, the remaining data were used to create training sets containing 500, 1000, 2000, 3000, 4000, 5000, and 6009 examples.", "labels": [], "entities": []}, {"text": "The performance of the classifiers appears to begin leveling off around 4000 training examples.", "labels": [], "entities": []}, {"text": "These results seem promising with regard to the portability of the DA classifiers since a data set of this size could be constructed in a few weeks.", "labels": [], "entities": [{"text": "DA classifiers", "start_pos": 67, "end_pos": 81, "type": "TASK", "confidence": 0.6476897895336151}]}, {"text": "developed a method for identifying SDU boundaries in a speech-to-speech translation system.", "labels": [], "entities": [{"text": "speech-to-speech translation", "start_pos": 55, "end_pos": 83, "type": "TASK", "confidence": 0.696369856595993}]}, {"text": "Identifying SDU boundaries is also similar to sentence boundary detection.", "labels": [], "entities": [{"text": "Identifying SDU boundaries", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8678991794586182}, {"text": "sentence boundary detection", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.7407687505086263}]}, {"text": "use TiMBL () to identify sentence boundaries in speech recognizer output, and use a statistical approach to identify sentence boundaries in automatic speech recognition transcripts of broadcast speech.", "labels": [], "entities": [{"text": "speech recognizer output", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.7490238845348358}, {"text": "identify sentence boundaries in automatic speech recognition transcripts of broadcast speech", "start_pos": 108, "end_pos": 200, "type": "TASK", "confidence": 0.7148543000221252}]}], "tableCaptions": [{"text": " Table 4. Classifier accuracy on transcription", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9820533990859985}, {"text": "transcription", "start_pos": 33, "end_pos": 46, "type": "TASK", "confidence": 0.7743796110153198}]}, {"text": " Table 5. Frequency of most common DA elements", "labels": [], "entities": [{"text": "Frequency", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9819080233573914}]}]}