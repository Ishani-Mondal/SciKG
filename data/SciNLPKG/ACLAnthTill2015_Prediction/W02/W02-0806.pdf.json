{"title": [{"text": "Assessing System Agreement and Instance Difficulty in the Lexical Sample Tasks of SENSEVAL-2", "labels": [], "entities": [{"text": "Instance Difficulty", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.6499139368534088}, {"text": "SENSEVAL-2", "start_pos": 82, "end_pos": 92, "type": "TASK", "confidence": 0.6191118359565735}]}], "abstractContent": [{"text": "This paper presents a comparative evaluation among the systems that participated in the Spanish and English lexical sample tasks of SENSEVAL-2.", "labels": [], "entities": []}, {"text": "The focus is on pairwise comparisons among systems to assess the degree to which they agree, and on measuring the difficulty of the test instances included in these tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper presents a post-mortem analysis of the English and Spanish lexical sample tasks of SENSEVAL-2.", "labels": [], "entities": []}, {"text": "Two closely related questions are considered.", "labels": [], "entities": []}, {"text": "First, to what extent did the competing systems agree?", "labels": [], "entities": []}, {"text": "Did systems tend to be redundant and have success with many of the same test instances, or were they complementary and able to disambiguate different portions of the instance space?", "labels": [], "entities": []}, {"text": "Second, how much did the difficulty of the test instances vary?", "labels": [], "entities": []}, {"text": "Are there test instances that proved unusually difficult to disambiguate relative to other instances?", "labels": [], "entities": []}, {"text": "We address the first question via a series of pairwise comparisons among the participating systems that measures their agreement via the kappa statistic.", "labels": [], "entities": []}, {"text": "We also introduce a simple measure of the degree to which systems are complementary called optimal combination.", "labels": [], "entities": []}, {"text": "We analyze the second question by rating the difficulty of test instances relative to the number of systems that were able to disambiguate them correctly.", "labels": [], "entities": []}, {"text": "Nearly all systems that received official scores in the Spanish and English lexical sample tasks of SENSEVAL-2 are included in this study.", "labels": [], "entities": []}, {"text": "There are 23 systems included from the English lexical sample task and eight from the Spanish.", "labels": [], "entities": []}, {"text": "lists the systems and shows the number of test instances that each disambiguated correctly, both by part of speech and in total.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Lexical Sample Systems  system  correct instances  name  noun verb adj  total (%)  English  1754 1806 768 4328 (1.00)", "labels": [], "entities": [{"text": "English  1754 1806 768 4328", "start_pos": 93, "end_pos": 120, "type": "DATASET", "confidence": 0.94926837682724}]}]}