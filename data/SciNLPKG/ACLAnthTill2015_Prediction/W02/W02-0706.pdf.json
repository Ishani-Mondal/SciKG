{"title": [{"text": "Architectures for speech-to-speech translation using finite-state models", "labels": [], "entities": [{"text": "speech-to-speech translation", "start_pos": 18, "end_pos": 46, "type": "TASK", "confidence": 0.7259892821311951}]}], "abstractContent": [{"text": "Speech-to-speech translation can be approached using finite state models and several ideas borrowed from automatic speech recognition.", "labels": [], "entities": [{"text": "Speech-to-speech translation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7631692886352539}, {"text": "automatic speech recognition", "start_pos": 105, "end_pos": 133, "type": "TASK", "confidence": 0.7325411637624105}]}, {"text": "The models can be Hidden Markov Models for the accous-tic part, language models for the source language and finite state transducers for the transfer between the source and target language.", "labels": [], "entities": []}, {"text": "A \"serial architecture\" would use the Hidden Markov and the language models for recognizing input utterance and the transducer for finding the translation.", "labels": [], "entities": []}, {"text": "An \"integrated architecture\", on the other hand, would integrate all the models in a single network where the search process takes place.", "labels": [], "entities": []}, {"text": "The output of this search process is the target word sequence associated to the optimal path.", "labels": [], "entities": []}, {"text": "In both architectures, HMMs can be trained from a source-language speech corpus, and the translation model can be learned automatically from a parallel text training corpus.", "labels": [], "entities": []}, {"text": "The experiments presented here correspond to speech-input translations from Spanish to English and from Italian to En-glish, in applications involving the interaction (by telephone) of a customer with the front-desk of a hotel.", "labels": [], "entities": []}], "introductionContent": [{"text": "Present finite-state technology allows us to build speech-to-speech translation (ST) systems using ideas very similar to those of automatic speech recognition (ASR).", "labels": [], "entities": [{"text": "speech-to-speech translation (ST)", "start_pos": 51, "end_pos": 84, "type": "TASK", "confidence": 0.8698841691017151}, {"text": "automatic speech recognition (ASR)", "start_pos": 130, "end_pos": 164, "type": "TASK", "confidence": 0.8340581953525543}]}, {"text": "In ASR the acoustic hidden Markov models (HMMs) can be integrated into the language model, which is typically a finite-state grammar (e.g. a N-gram).", "labels": [], "entities": [{"text": "ASR", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.9784849286079407}]}, {"text": "In ST the same HMMs can be integrated in a translation model which consists in a stochastic finite-state transducer (SFST).", "labels": [], "entities": []}, {"text": "Thanks to this integration, the translation process can be efficiently performed by searching for an optimal path of states through the integrated network by using well-known optimization procedures such as (beam-search accelerated) Viterbi search.", "labels": [], "entities": [{"text": "translation", "start_pos": 32, "end_pos": 43, "type": "TASK", "confidence": 0.9688199758529663}]}, {"text": "This \"integrated architecture\" can be compared with the more conventional \"serial architecture\", where the HMMs, along with a suitable source language model, are used as a front-end to recognize a sequence of source-language words which is then processed by the translation model.", "labels": [], "entities": []}, {"text": "A related approach has been proposed in).", "labels": [], "entities": []}, {"text": "In any case, a pure pattern-recognition approach can be followed to build the required systems.", "labels": [], "entities": []}, {"text": "Acoustic models can be trained from a sufficiently large source-language speech training set, in the very same way as in speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 121, "end_pos": 139, "type": "TASK", "confidence": 0.7493910491466522}]}, {"text": "On the other hand, using adequate learning algorithms), the translation model can also be learned from a sufficiently large training set consisting of source-target parallel text.", "labels": [], "entities": [{"text": "translation", "start_pos": 60, "end_pos": 71, "type": "TASK", "confidence": 0.9754389524459839}]}], "datasetContent": [{"text": "Three sets of speech-to-speech translation prototypes have been implemented for Spanish to English and for Italian to English.", "labels": [], "entities": [{"text": "speech-to-speech translation", "start_pos": 14, "end_pos": 42, "type": "TASK", "confidence": 0.6383025348186493}]}, {"text": "In all of them, the application was the translation of queries, requests and complaints made by telephone to the front desk of a hotel.", "labels": [], "entities": [{"text": "translation of queries, requests and complaints made by telephone to the front desk of a hotel", "start_pos": 40, "end_pos": 134, "type": "TASK", "confidence": 0.7429750772083507}]}, {"text": "Three tasks of different degree of difficulty have been considered.", "labels": [], "entities": []}, {"text": "In the first one (EUTRANS-0), Spanish-to-English translation systems were learned from a big and well controlled training corpus: about 170k different pairs (\u2248 2M running words), with a lexicon of about 700 words.", "labels": [], "entities": [{"text": "Spanish-to-English translation", "start_pos": 30, "end_pos": 60, "type": "TASK", "confidence": 0.5684705525636673}]}, {"text": "In the second one (EUTRANS-I), also from Spanish to English, the systems were learned from a random subset of 10k pairs (\u2248 100k running words) from the previous corpus; this was established as a more realistic training corpus for the kind of application considered.", "labels": [], "entities": []}, {"text": "In the third and most difficult one, from Italian to English (EUTRANS-II), the systems were learned from a small training corpus that was obtained from a transcription of a spontaneous speech corpus: about 3k pairs (\u2248 60k running words), with a lexicon of about 2,500 words.", "labels": [], "entities": []}, {"text": "For the serial architecture, the speech decoding was performed in a conventional way, using the same acoustic models as with the integrated architecture and trigrams of the source language models.", "labels": [], "entities": []}, {"text": "For the integrated architecture, the speech decoding of an utterance is a sub-product of the translation process (the sequence of source words associated to the optimal sequence of transitions that produces the sequence of target words).", "labels": [], "entities": []}, {"text": "The acoustic models of phone units were trained with the HTK Toolkit.", "labels": [], "entities": [{"text": "HTK Toolkit", "start_pos": 57, "end_pos": 68, "type": "DATASET", "confidence": 0.977827787399292}]}, {"text": "For the EUTRANS-0 and EUTRANS-I prototypes, a training speech corpus of 57,000 Spanish running words was used, while the EUTRANS-II Italian acoustic models were trained from another corpus of 52,000 running words Performance was assessed on the base of 336 Spanish sentences in the case of EUTRANS-0 and EUTRANS-I and 278 Italian sentences in EUTRANS-II.", "labels": [], "entities": [{"text": "EUTRANS-I", "start_pos": 304, "end_pos": 313, "type": "DATASET", "confidence": 0.9150699377059937}, {"text": "EUTRANS-II", "start_pos": 343, "end_pos": 353, "type": "DATASET", "confidence": 0.9246664047241211}]}, {"text": "In all the cases, the test sentences (as well as the corresponding speakers) were different from those appearing in the training data.", "labels": [], "entities": []}, {"text": "For the easiest task, EUTRANS-0, (well controlled and a large training set), the best result was achieved with an integrated architecture and a SFST obtained with the OMEGA learning technique.", "labels": [], "entities": [{"text": "EUTRANS-0", "start_pos": 22, "end_pos": 31, "type": "DATASET", "confidence": 0.8154691457748413}, {"text": "SFST", "start_pos": 144, "end_pos": 148, "type": "METRIC", "confidence": 0.8728079795837402}]}, {"text": "A Translation Word Error Rate of 7.6% was achieved, while the corresponding source-language speech decoding Word Error Rate was 8.4%.", "labels": [], "entities": [{"text": "Translation Word Error Rate", "start_pos": 2, "end_pos": 29, "type": "METRIC", "confidence": 0.6589493975043297}, {"text": "Word Error Rate", "start_pos": 108, "end_pos": 123, "type": "METRIC", "confidence": 0.7364428440729777}]}, {"text": "Although these figures may seem strange (and they would certainly be in the case of a serial architecture), they are in fact consistent with the fact that, in this task (corpus), the target language exhibits a significantly lower perplexity than the source language.", "labels": [], "entities": []}, {"text": "For the second, less easy task EUTRANS-I, (well controlled task but a small training set), the best result was achieved with an integrated architecture and a SFST obtained with the MGTI learning technique (10.5% of word error rate corresponding to the speech decoding and 12.6% of translation word error rate).", "labels": [], "entities": [{"text": "EUTRANS-I", "start_pos": 31, "end_pos": 40, "type": "DATASET", "confidence": 0.9065560698509216}, {"text": "SFST", "start_pos": 158, "end_pos": 162, "type": "METRIC", "confidence": 0.8085724115371704}, {"text": "word error rate", "start_pos": 215, "end_pos": 230, "type": "METRIC", "confidence": 0.70637380083402}]}, {"text": "For the most difficult task, EUTRANS-II (spontaneous task and a small training set), the best result was achieved with a serial architecture and a SFST obtained with the MGTI learning technique (22.1% of word error rate corresponding to the speech decoding and 37.9% of translation word error rate).", "labels": [], "entities": [{"text": "EUTRANS-II", "start_pos": 29, "end_pos": 39, "type": "DATASET", "confidence": 0.9148378968238831}, {"text": "SFST", "start_pos": 147, "end_pos": 151, "type": "METRIC", "confidence": 0.8748273253440857}, {"text": "word error rate", "start_pos": 204, "end_pos": 219, "type": "METRIC", "confidence": 0.7132965127627054}]}, {"text": "Several systems have been implemented for speechto-speech translation based on SFSTs.", "labels": [], "entities": [{"text": "speechto-speech translation", "start_pos": 42, "end_pos": 69, "type": "TASK", "confidence": 0.823410838842392}]}, {"text": "Some of them were implemented for translation from Italian to English and the others for translation from Spanish to English.", "labels": [], "entities": [{"text": "translation from Italian to English", "start_pos": 34, "end_pos": 69, "type": "TASK", "confidence": 0.8541765093803406}, {"text": "translation from Spanish to English", "start_pos": 89, "end_pos": 124, "type": "TASK", "confidence": 0.844162118434906}]}, {"text": "All of them support all kinds of finite-state translation models and run on low-cost hardware.", "labels": [], "entities": [{"text": "finite-state translation", "start_pos": 33, "end_pos": 57, "type": "TASK", "confidence": 0.6618134081363678}]}, {"text": "They are currently accessible through standard telephone lines with response times close to or better than real time.", "labels": [], "entities": []}, {"text": "From the results presented, it appears that the integrated architecture allows for the achievement of better results than the results achieved with a serial architecture when enough training data is available to train the SFST.", "labels": [], "entities": [{"text": "SFST", "start_pos": 222, "end_pos": 226, "type": "TASK", "confidence": 0.499941885471344}]}, {"text": "However, when the training data is insufficient, the results obtained by the serial architecture were better than the results obtained by the integrated architecture.", "labels": [], "entities": []}, {"text": "This effect is possible because the source language models for the experiments with the serial architecture were smoothed trigrams.", "labels": [], "entities": []}, {"text": "In the case of sufficient training data, the source language model associated to a SFST learnt by the MGTI or OMEGA is better than trigrams (Section 2.1).", "labels": [], "entities": [{"text": "SFST", "start_pos": 83, "end_pos": 87, "type": "TASK", "confidence": 0.9425017833709717}, {"text": "MGTI", "start_pos": 102, "end_pos": 106, "type": "DATASET", "confidence": 0.859975278377533}, {"text": "OMEGA", "start_pos": 110, "end_pos": 115, "type": "DATASET", "confidence": 0.7323586344718933}]}, {"text": "However, in the other case (not sufficient training data) these source languages were worse than trigrams.", "labels": [], "entities": []}, {"text": "Consequently an important degradation is produced in the implicit decoding of the input utterance.", "labels": [], "entities": []}], "tableCaptions": []}