{"title": [{"text": "Speech Translation Performance of Statistical Dependency Transduction and Semantic Similarity Transduction", "labels": [], "entities": [{"text": "Speech Translation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7297823280096054}, {"text": "Statistical Dependency Transduction", "start_pos": 34, "end_pos": 69, "type": "TASK", "confidence": 0.5616686642169952}, {"text": "Semantic Similarity Transduction", "start_pos": 74, "end_pos": 106, "type": "TASK", "confidence": 0.6767692168553671}]}], "abstractContent": [{"text": "In this paper we compare the performance of two methods for speech translation.", "labels": [], "entities": [{"text": "speech translation", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.7569989264011383}]}, {"text": "One is a statistical dependency transduc-tion model using head transducers, the other a case-based transduction model involving a lexical similarity measure.", "labels": [], "entities": []}, {"text": "Examples of translated utterance transcriptions are used in training both models, though the case-based model also uses semantic labels classifying the source utterances.", "labels": [], "entities": [{"text": "translated utterance transcriptions", "start_pos": 12, "end_pos": 47, "type": "TASK", "confidence": 0.6379058559735616}]}, {"text": "The main conclusion is that while the two methods provide similar translation accuracy under the experimental conditions and accuracy metric used, the statistical dependency transduction method is significantly faster at computing translations .", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.8432237505912781}, {"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9958413243293762}]}], "introductionContent": [{"text": "Machine translation, natural language processing, and more generally other computational problems that are not amenable to closed form solutions, have typically been tackled by one of three broad approaches: rule-based systems, statistical models (including generative models), and case-based systems.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8417177498340607}, {"text": "natural language processing", "start_pos": 21, "end_pos": 48, "type": "TASK", "confidence": 0.7075732549031576}]}, {"text": "Hybrid solutions combining these approaches have also been used in language processing generally) and more specifically in machine translation (for example).", "labels": [], "entities": [{"text": "language processing", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.7327722907066345}, {"text": "machine translation", "start_pos": 123, "end_pos": 142, "type": "TASK", "confidence": 0.8171894550323486}]}, {"text": "In this paper we compare the performance of two methods for speech translation.", "labels": [], "entities": [{"text": "speech translation", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.7569989264011383}]}, {"text": "One is the statistical dependency transduction model), a trainable generative statistical translation model using head transducers.", "labels": [], "entities": [{"text": "statistical dependency transduction", "start_pos": 11, "end_pos": 46, "type": "TASK", "confidence": 0.6916447381178538}, {"text": "generative statistical translation", "start_pos": 67, "end_pos": 101, "type": "TASK", "confidence": 0.7090958654880524}]}, {"text": "The other is a case-based transduction model which makes use of a semantic similarity measure between words.", "labels": [], "entities": []}, {"text": "Both models are trained automatically using examples of translated utterances (the transcription of a spoken utterance and a translation of that transcription).", "labels": [], "entities": []}, {"text": "The casebased model makes use of additional information in the form of labels associated with source language utterances, typically one or two labels per utterance.", "labels": [], "entities": []}, {"text": "This additional information, which was originally provided fora separate monolingual task, is used to construct the lexical similarity measure.", "labels": [], "entities": []}, {"text": "In training these translation methods, as well as their runtime application, no pre-existing bilingual lexicon is needed.", "labels": [], "entities": []}, {"text": "Instead, in both cases, the initial phase of training from the translation data is a statistical hierarchical alignment search applied to the set of bilingual examples.", "labels": [], "entities": []}, {"text": "This training phase produces a bilingual lexicon, used by both methods, as well as synchronized hierarchical alignments used to build the dependency transduction model.", "labels": [], "entities": []}, {"text": "In the experiments comparing the performance of the models we look at accuracy as well as the time taken to translate sentences from English to Japanese.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9996470212936401}]}, {"text": "The source language inputs used in these experiments are naturally spoken utterances from large numbers of real customers calling telephone operator services.", "labels": [], "entities": []}, {"text": "In section 2 we describe the hierarchical alignment algorithm followed by descriptions of the translation methods in sections 3 and 4.", "labels": [], "entities": [{"text": "hierarchical alignment", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.5765126645565033}]}, {"text": "We present the experiments in section 5 and provide concluding remarks in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use two simple string edit-distance evaluation metrics that can be calculated automatically.", "labels": [], "entities": []}, {"text": "These metrics, simple accuracy and translation accuracy, are used to compare the target string produced by the system against the reference human translation from held-out data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9012248516082764}, {"text": "translation", "start_pos": 35, "end_pos": 46, "type": "TASK", "confidence": 0.8268897533416748}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.7515100836753845}]}, {"text": "Simple accuracy (the 'word accuracy' of speech recognition research) is computed by first finding a transformation of one string into another that minimizes the total number of insertions, deletions and substitutions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.7857004404067993}, {"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.6221440434455872}, {"text": "speech recognition", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7256615161895752}]}, {"text": "Since a transposition corresponds to an insertion and a deletion, the values of \u0083 and @ will be different in the expressions for computing the two accuracy metrics.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.9967286586761475}]}, {"text": "The units for string operations in the evaluation metrics are Japanese characters.", "labels": [], "entities": []}, {"text": "The following experimental systems are evaluated here: Word-Word A simple word for word baseline method in which each source word is replaced with the most highly correlated target word in the training corpus.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy for text (%)", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9993526339530945}]}, {"text": " Table 2: Accuracy for speech (%)", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9993395209312439}]}]}