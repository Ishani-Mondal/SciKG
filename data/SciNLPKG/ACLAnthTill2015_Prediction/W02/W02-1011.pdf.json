{"title": [{"text": "Thumbs up? Sentiment Classification using Machine Learning Techniques", "labels": [], "entities": [{"text": "Sentiment Classification", "start_pos": 11, "end_pos": 35, "type": "TASK", "confidence": 0.9802919030189514}]}], "abstractContent": [{"text": "We consider the problem of classifying documents not by topic, but by overall sentiment , e.g., determining whether a review is positive or negative.", "labels": [], "entities": []}, {"text": "Using movie reviews as data, we find that standard machine learning techniques definitively out-perform human-produced baselines.", "labels": [], "entities": []}, {"text": "However , the three machine learning methods we employed (Naive Bayes, maximum en-tropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization.", "labels": [], "entities": [{"text": "maximum en-tropy classification", "start_pos": 71, "end_pos": 102, "type": "TASK", "confidence": 0.7014311750729879}, {"text": "sentiment classification", "start_pos": 159, "end_pos": 183, "type": "TASK", "confidence": 0.9139789342880249}]}, {"text": "We conclude by examining factors that make the sentiment classification problem more challenging.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.9450534284114838}]}], "introductionContent": [{"text": "Today, very large amounts of information are available in on-line documents.", "labels": [], "entities": []}, {"text": "As part of the effort to better organize this information for users, researchers have been actively investigating the problem of automatic text categorization.", "labels": [], "entities": [{"text": "automatic text categorization", "start_pos": 129, "end_pos": 158, "type": "TASK", "confidence": 0.59975865483284}]}, {"text": "The bulk of such work has focused on topical categorization, attempting to sort documents according to their subject matter (e.g., sports vs. politics).", "labels": [], "entities": []}, {"text": "However, recent years have seen rapid growth in on-line discussion groups and review sites (e.g., the New York Times' Books web page) where a crucial characteristic of the posted articles is their sentiment, or overall opinion towards the subject matter -for example, whether a product review is positive or negative.", "labels": [], "entities": [{"text": "Books web page", "start_pos": 118, "end_pos": 132, "type": "DATASET", "confidence": 0.8710281451543173}]}, {"text": "Labeling these articles with their sentiment would provide succinct summaries to readers; indeed, these labels are part of the appeal and value-add of such sites as www.rottentomatoes.com, which both labels movie reviews that do not contain explicit rating indicators and normalizes the different rating schemes that individual reviewers use.", "labels": [], "entities": []}, {"text": "Sentiment classification would also be helpful in business intelligence applications (e.g. MindfulEye's Lexant system 1 ) and recommender systems (e.g.,,), where user input and feedback could be quickly summarized; indeed, in general, free-form survey responses given in natural language format could be processed using sentiment categorization.", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9306279122829437}]}, {"text": "Moreover, there are also potential applications to message filtering; for example, one might be able to use sentiment information to recognize and discard \"flames\".", "labels": [], "entities": [{"text": "message filtering", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.8158509135246277}]}, {"text": "In this paper, we examine the effectiveness of applying machine learning techniques to the sentiment classification problem.", "labels": [], "entities": [{"text": "sentiment classification problem", "start_pos": 91, "end_pos": 123, "type": "TASK", "confidence": 0.9545383453369141}]}, {"text": "A challenging aspect of this problem that seems to distinguish it from traditional topic-based classification is that while topics are often identifiable by keywords alone, sentiment can be expressed in a more subtle manner.", "labels": [], "entities": [{"text": "topic-based classification", "start_pos": 83, "end_pos": 109, "type": "TASK", "confidence": 0.6765223741531372}]}, {"text": "For example, the sentence \"How could anyone sit through this movie?\" contains no single word that is obviously negative.", "labels": [], "entities": []}, {"text": "(See Section 7 for more examples).", "labels": [], "entities": []}, {"text": "Thus, sentiment seems to require more understanding than the usual topic-based classification.", "labels": [], "entities": []}, {"text": "So, apart from presenting our results obtained via machine learning techniques, we also analyze the problem to gain a better understanding of how difficult it is.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used documents from the movie-review corpus described in Section 3.", "labels": [], "entities": []}, {"text": "To create a data set with uniform class distribution (studying the effect of skewed  Figure 3: Average three-fold cross-validation accuracies, in percent.", "labels": [], "entities": []}, {"text": "Boldface: best performance fora given setting (row).", "labels": [], "entities": []}, {"text": "Recall that our baseline results ranged from 50% to 69%.", "labels": [], "entities": []}, {"text": "class distributions was out of the scope of this study), we randomly selected 700 positive-sentiment and 700 negative-sentiment documents.", "labels": [], "entities": []}, {"text": "We then divided this data into three equal-sized folds, maintaining balanced class distributions in each fold.", "labels": [], "entities": []}, {"text": "(We did not use a larger number of folds due to the slowness of the MaxEnt training procedure.)", "labels": [], "entities": []}, {"text": "All results reported below, as well as the baseline results from Section 4, are the average three-fold cross-validation results on this data (of course, the baseline algorithms had no parameters to tune).", "labels": [], "entities": []}, {"text": "To prepare the documents, we automatically removed the rating indicators and extracted the textual information from the original HTML document format, treating punctuation as separate lexical items.", "labels": [], "entities": []}, {"text": "No stemming or stoplists were used.", "labels": [], "entities": []}, {"text": "One unconventional step we took was to attempt to model the potentially important contextual effect of negation: clearly \"good\" and \"not very good\" indicate opposite sentiment orientations.", "labels": [], "entities": [{"text": "negation", "start_pos": 103, "end_pos": 111, "type": "TASK", "confidence": 0.964866578578949}]}, {"text": "Adapting a technique of, we added the tag NOT to every word between a negation word (\"not\", \"isn't\", \"didn't\", etc.) and the first punctuation mark following the negation word.", "labels": [], "entities": [{"text": "NOT", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.9616325497627258}]}, {"text": "(Preliminary experiments indicate that removing the negation tag had a negligible, but on average slightly harmful, effect on performance.)", "labels": [], "entities": []}, {"text": "For this study, we focused on features based on unigrams (with negation tagging) and bigrams.", "labels": [], "entities": []}, {"text": "Because training MaxEnt is expensive in the number of features, we limited consideration to (1) the 16165 unigrams appearing at least four times in our 1400-document corpus (lower count cutoffs did not yield significantly different results), and (2) the 16165 bigrams occurring most often in the same data (the selected bigrams all occurred at least seven times).", "labels": [], "entities": []}, {"text": "Note that we did not add negation tags to the bigrams, since we consider bigrams (and n-grams in general) to bean orthogonal way to incorporate context.", "labels": [], "entities": []}], "tableCaptions": []}