{"title": [{"text": "Augmented Mixture Models for Lexical Disambiguation", "labels": [], "entities": [{"text": "Augmented Mixture", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.843974381685257}, {"text": "Lexical Disambiguation", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.8624165952205658}]}], "abstractContent": [{"text": "This paper investigates several augmented mixture models that are competitive alternatives to standard Bayesian models and prove to be very suitable to word sense disambiguation and related classification tasks.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 152, "end_pos": 177, "type": "TASK", "confidence": 0.7263395587603251}]}, {"text": "We present anew classification correction technique that successfully addresses the problem of underestimation of infrequent classes in the training data.", "labels": [], "entities": [{"text": "classification correction", "start_pos": 16, "end_pos": 41, "type": "TASK", "confidence": 0.9612296521663666}]}, {"text": "We show that the mixture models are boosting-friendly and that both Adaboost and our original correction technique can improve the results of the raw model significantly, achieving state-of-the-art performance on several standard test sets in four languages.", "labels": [], "entities": []}, {"text": "With substantially different output to Na\u00efve Bayes and other statistical methods, the investigated models are also shown to be effective participants in classifier combination.", "labels": [], "entities": []}], "introductionContent": [{"text": "The focus tasks of this paper are two related problems in lexical ambiguity resolution: Word Sense Disambiguation (WSD) and ContextSensitive Spelling Correction (CSSC).", "labels": [], "entities": [{"text": "lexical ambiguity resolution", "start_pos": 58, "end_pos": 86, "type": "TASK", "confidence": 0.6918443739414215}, {"text": "Word Sense Disambiguation (WSD)", "start_pos": 88, "end_pos": 119, "type": "TASK", "confidence": 0.7253056367238363}, {"text": "ContextSensitive Spelling Correction (CSSC)", "start_pos": 124, "end_pos": 167, "type": "TASK", "confidence": 0.7840863168239594}]}, {"text": "Word Sense Disambiguation has along history as a computational task, and the field has recently supported large-scale international system evaluation exercises in multiple languages (SENSEVAL-1,, and SENSEVAL-2,).", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6907594005266825}]}, {"text": "General purpose Spelling Correction is also a long-standing task (e.g., traditionally focusing on resolving typographical errors such as transposition and deletion to find the closest \"valid\" word (in a dictionary or a morphological variant), typically ignoring context.", "labels": [], "entities": [{"text": "General purpose Spelling Correction", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6170434430241585}]}, {"text": "Yet observed that about 25-50% of the spelling errors found in modern documents are either context-inappropriate misuses or substitutions of valid words (such as principal and principle) which are not detected by traditional spelling correctors.", "labels": [], "entities": []}, {"text": "Previous work has addressed the problem of CSSC from a machine learning perspective, including Bayesian and Decision List models, and Transformation-Based Learning (.", "labels": [], "entities": []}, {"text": "Generally, both tasks involve the selection between a relatively small set of alternatives per keyword (e.g. sense id's such as church/BUILDING and church/INSTITUTION or commonly confused spellings such as quiet and quite), and are dependent on local and long-distance collocational and syntactic patterns to resolve between the set of alternatives.", "labels": [], "entities": []}, {"text": "Thus both tasks can share a common feature space, data representation and algorithm infrastructure.", "labels": [], "entities": []}, {"text": "We present a framework of doing so, while investigating the use of mixture models in conjunction with anew error-correction technique as competitive alternatives to Bayesian models.", "labels": [], "entities": []}, {"text": "While several authors have observed the fundamental similarities between CSSC and WSD (e.g., to our knowledge no previous comparative empirical study has tackled these two problems in a single unified framework.", "labels": [], "entities": []}], "datasetContent": [{"text": "We present a comparative study for four languages (English, Swedish, Spanish, and Basque) by performing 5-fold cross-validation on the SENSEVAL-2 lexical-sample training data, using the fine-grained sense inventory.", "labels": [], "entities": [{"text": "SENSEVAL-2 lexical-sample training data", "start_pos": 135, "end_pos": 174, "type": "DATASET", "confidence": 0.6253657713532448}]}, {"text": "For English and Swedish, for which POS-tagged training data was available to us, the fnTBL algorithm) based on Brill (1995) was used to annotate the data, while for Spanish a mildly-supervised POS-tagging system similar to the one presented in Cucerzan and Yarowsky (2000) was employed.", "labels": [], "entities": []}, {"text": "We also present the results obtained by the different algorithms on another WSD standard set, SENSEVAL-1, also by performing 5-fold cross validation on the original training data.", "labels": [], "entities": [{"text": "WSD standard set", "start_pos": 76, "end_pos": 92, "type": "DATASET", "confidence": 0.8972124656041464}]}, {"text": "For CSSC, we tested our system on the identical data from the Brown corpus used by, and.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 62, "end_pos": 74, "type": "DATASET", "confidence": 0.9076051414012909}]}, {"text": "Finally, we present the results obtained by the investigated methods on a single run on the Senseval-1 and Senseval-2 test data.", "labels": [], "entities": [{"text": "Senseval-1 and Senseval-2 test data", "start_pos": 92, "end_pos": 127, "type": "DATASET", "confidence": 0.7484186887741089}]}, {"text": "The described models were initially trained and tested by performing 5-fold cross-validation on the SENSEVAL-2 English lexical-sample-task training data.", "labels": [], "entities": [{"text": "SENSEVAL-2 English lexical-sample-task training data", "start_pos": 100, "end_pos": 152, "type": "DATASET", "confidence": 0.6324812650680542}]}, {"text": "When parameters needed to be estimated, jackknife or a 3-1-1 split (training and/or parameter estimation -testing) were used.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The increase in performance for successive variants", "labels": [], "entities": []}, {"text": " Table 2: Results using 5-fold cross validation on SENSEVAL-", "labels": [], "entities": [{"text": "SENSEVAL", "start_pos": 51, "end_pos": 59, "type": "TASK", "confidence": 0.7868260145187378}]}, {"text": " Table 3. The difference between  MMVC and enhanced Na\u00efve Bayes is statistically  significant (McNemar rejection risk 0.036).", "labels": [], "entities": [{"text": "McNemar rejection risk 0.036", "start_pos": 95, "end_pos": 123, "type": "METRIC", "confidence": 0.8401738852262497}]}, {"text": " Table 3: Results using 5-fold cross validation on SENSEVAL-", "labels": [], "entities": [{"text": "SENSEVAL", "start_pos": 51, "end_pos": 59, "type": "TASK", "confidence": 0.7870930433273315}]}, {"text": " Table 4: Results on the standard 14 CSSC data sets", "labels": [], "entities": [{"text": "CSSC data sets", "start_pos": 37, "end_pos": 51, "type": "DATASET", "confidence": 0.8782347043355306}]}, {"text": " Table 5: The contribution of MMVC in a rank-based classi-", "labels": [], "entities": [{"text": "MMVC", "start_pos": 30, "end_pos": 34, "type": "TASK", "confidence": 0.6031880974769592}]}, {"text": " Table 6: Accuracy on SENSEVAL-1 and SENSEVAL-2 En-", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9986135959625244}]}]}