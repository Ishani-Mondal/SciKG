{"title": [{"text": "A Multi-Perspective Evaluation of the NESPOLE! Speech-to-Speech Translation System", "labels": [], "entities": [{"text": "NESPOLE! Speech-to-Speech Translation", "start_pos": 38, "end_pos": 75, "type": "TASK", "confidence": 0.7183393687009811}]}], "abstractContent": [{"text": "Performance and usability of real-world speech-to-speech translation systems , like the one developed within the Nespole!", "labels": [], "entities": [{"text": "speech-to-speech translation", "start_pos": 40, "end_pos": 68, "type": "TASK", "confidence": 0.7181693613529205}, {"text": "Nespole!", "start_pos": 113, "end_pos": 121, "type": "DATASET", "confidence": 0.892414778470993}]}, {"text": "project, are affected by several aspects that go beyond the pure translation quality provided by the underlying components of the system.", "labels": [], "entities": []}, {"text": "In this paper we describe these aspects as perspectives along which we have evaluated the Nespole!", "labels": [], "entities": [{"text": "Nespole!", "start_pos": 90, "end_pos": 98, "type": "DATASET", "confidence": 0.9256696701049805}]}, {"text": "Four main issues are investigated: (1) assessing system performance under various network traffic conditions; (2) a study on the usage and utility of multi-modality in the context of multilingual communication; (3) a comparison of the features of the individual speech recognition engines, and (4) an end-to-end evaluation of the system.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 262, "end_pos": 280, "type": "TASK", "confidence": 0.7243644297122955}]}], "introductionContent": [{"text": "1 is a speech-to-speech machine translation project designed to provide fully functional speech-to-speech capabilities within realworld settings of common users involved in ecommerce applications.", "labels": [], "entities": [{"text": "speech-to-speech machine translation", "start_pos": 7, "end_pos": 43, "type": "TASK", "confidence": 0.6657928029696146}]}, {"text": "The project is a collaboration between three European research groups (IRST in Trento, Italy; ISL at Universit\u00e4t Karlsruhe (TH); and CLIPS at Universit\u00e9 Joseph Fourier in Grenoble, France), one US research group (ISL at Carnegie Mellon University in Pittsburgh, PA) and two industrial partners (APT; Trento, Italy -the Trentino provincial tourism board, and AETHRA; Ancona, Italya tele-communications company).", "labels": [], "entities": [{"text": "AETHRA", "start_pos": 358, "end_pos": 364, "type": "METRIC", "confidence": 0.6866989731788635}]}, {"text": "The project is funded jointly by the European Commission and the US NSF.", "labels": [], "entities": []}, {"text": "Over the past two years, we have developed a fully functional showcase of the Nespole!", "labels": [], "entities": [{"text": "Nespole!", "start_pos": 78, "end_pos": 86, "type": "DATASET", "confidence": 0.9442955553531647}]}, {"text": "system within the domain of travel and tourism, and have significantly improved system performance and usability based on a series of studies and evaluations with real users.", "labels": [], "entities": []}, {"text": "Our experience has shown that improving translation quality is only one of several important issues that must be addressed in achieving a practical real-world speech-to-speech translation system.", "labels": [], "entities": [{"text": "translation", "start_pos": 40, "end_pos": 51, "type": "TASK", "confidence": 0.958268404006958}, {"text": "speech-to-speech translation", "start_pos": 159, "end_pos": 187, "type": "TASK", "confidence": 0.7282897531986237}]}, {"text": "This paper describes how we tackled these issues and evaluates their effect on system performance and usability.", "labels": [], "entities": []}, {"text": "We focus on four main issues: (1) assessing system performance under various network traffic conditions and architectural configurations; (2) a study on the usage and utility of multi-modality in the context of multi-lingual communication; (3) a comparison of the features of the individual speech recognition engines, and (4) an end-to-end evaluation of the demonstration system.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 291, "end_pos": 309, "type": "TASK", "confidence": 0.7103674709796906}]}], "datasetContent": [{"text": "Several different evaluation experiments have been conducted, targeting different aspects of our system: (1) the impact of network traffic and the consequences of real packet-loss on system performance; (2) the impact and usability of multi-modality; (3) a comparison of the features of the various speech recognition engines, developed independently for different languages with different techniques; and (4) end-to-end performance evaluations.", "labels": [], "entities": []}, {"text": "The data used in the evaluations is part of a database collected during the project ().", "labels": [], "entities": []}, {"text": "The nature of the e-commerce scenario and application in which our system is situated requires that speech-translation be well-integrated with additional modalities of communication and information exchange between the agent and client.", "labels": [], "entities": []}, {"text": "Significant effort has been devoted to this issue within the project.", "labels": [], "entities": []}, {"text": "The main multi-modal component in the current version of our system is the AeWhiteboard -a special whiteboard, which allows users to share maps and web-pages.", "labels": [], "entities": []}, {"text": "The functionalities provided by the AeWhiteboard include: image loading, free-hand drawing, area selecting, color choosing, scrolling the image loaded, zooming the image loaded, URL opening, and Nespole!", "labels": [], "entities": [{"text": "image loading", "start_pos": 58, "end_pos": 71, "type": "TASK", "confidence": 0.8048204481601715}, {"text": "area selecting", "start_pos": 92, "end_pos": 106, "type": "TASK", "confidence": 0.6994675844907761}, {"text": "color choosing", "start_pos": 108, "end_pos": 122, "type": "TASK", "confidence": 0.7346785962581635}, {"text": "URL opening", "start_pos": 178, "end_pos": 189, "type": "TASK", "confidence": 0.7608082294464111}]}, {"text": "The most important feature of the whiteboard is that each gesture performed by a user is mirrored on the whiteboard of the other user.", "labels": [], "entities": []}, {"text": "Both users communicate while viewing the same images and annotated whiteboards.", "labels": [], "entities": []}, {"text": "Typically, the client asks for spatial information regarding locations, distances, and navigation directions (e.g., how to get from a hotel to the ski slopes).", "labels": [], "entities": []}, {"text": "By using the whiteboard, the agent can indicate the locations and draw routes on the map, point at areas, select items, draw connections between different locations using a mouse or an optical pen, and accompany his/her gestures with verbal explanations.", "labels": [], "entities": []}, {"text": "Supporting such combined verbal and gesture interactions has required modifications and extensions of both HLT modules and the IF.", "labels": [], "entities": []}, {"text": "During July 2001, we conducted a detailed study to evaluate the effect of multi-modality on the communication effectiveness and usability of our system.", "labels": [], "entities": []}, {"text": "The goals of the experiment were to test: (1) whether multi-modality increases the probability of successful interaction, especially when spatial information is the focus of the communicative exchange; (2) whether multimodality helps reduce mis-communications and disfluencies; and (3) whether multi-modality supports a faster recovery from recognition and translation errors.", "labels": [], "entities": [{"text": "recovery from recognition and translation errors", "start_pos": 327, "end_pos": 375, "type": "TASK", "confidence": 0.6638261477152506}]}, {"text": "For these purposes, two experimental conditions were devised: a speechonly condition (SO), involving multilingual communication and the sharing of images; and a multi-modal condition (MM), where users could additionally convey spatial information by penbased gestures on shared maps.", "labels": [], "entities": []}, {"text": "The setting for the experiment was the scenario described earlier, involving clients searching for winter tour-package information in the Trentino province.", "labels": [], "entities": []}, {"text": "The client's task was to select an appropriate resort location and hotel within the specified constraints concerning the relevant geographical area, the available budget, etc.", "labels": [], "entities": []}, {"text": "The agent's task was to provide the necessary information.", "labels": [], "entities": []}, {"text": "Novice subjects, previously unfamiliar with the system and task were recruited to play the role of the clients.", "labels": [], "entities": []}, {"text": "Subjects wore a head-mounted microphone, using it in a push-to-talk mode, and drew gestures on maps by means of a table-pen device or a mouse.", "labels": [], "entities": []}, {"text": "Each subject could only hear the translated speech of the other party (original audio was disabled in this experiment).", "labels": [], "entities": []}, {"text": "28 dialogues were collected, with 14 dialogues each for English and for German clients, and Italian agents in all cases.", "labels": [], "entities": []}, {"text": "Each group contained 7 SO and 7 MM dialogues.", "labels": [], "entities": [{"text": "MM dialogues", "start_pos": 32, "end_pos": 44, "type": "TASK", "confidence": 0.841586172580719}]}, {"text": "The dialogue transcriptions include: orthographical transcription, annotations for spontaneous phenomena and disfluencies, turn information and annotations for gestures.", "labels": [], "entities": [{"text": "orthographical transcription", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.7203407287597656}]}, {"text": "Translated turns were classified into successful, partially successful and unsuccessful by comparing the translated turns with the responses they generated.", "labels": [], "entities": []}, {"text": "Repeated turns were also counted.", "labels": [], "entities": []}, {"text": "The average duration of dialogues was 35 minutes (35.8 for SO and 35.5 for MM).", "labels": [], "entities": [{"text": "MM", "start_pos": 75, "end_pos": 77, "type": "TASK", "confidence": 0.8755189776420593}]}, {"text": "On average, a dialogue contained 35 turns, 247 tokens and 97 token types per speaker.", "labels": [], "entities": []}, {"text": "Average values and variance of all measures are very similar for agents and clients and across conditions and Languages.", "labels": [], "entities": [{"text": "variance", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9618326425552368}]}, {"text": "ANOVA tests (p=0.05) on the number of turns and the number of spontaneous phenomena and disfluencies, agents and customers separately, did not produce any evidence that modality or language affected these variables.", "labels": [], "entities": [{"text": "ANOVA", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.5371052026748657}]}, {"text": "Hence the spoken input is homogeneous across groups.", "labels": [], "entities": []}, {"text": "Details on the experimental database collected and the various statistical analyses performed appear in ().", "labels": [], "entities": []}, {"text": "The analysis of the results indicated that both the SO and MM versions of the system were effective for goal completion: 86% of the users were able to complete the task's goal by choosing a hotel meeting the pre-specified budget and location constraints.", "labels": [], "entities": []}, {"text": "In the MM dialogues, there were 7.6 gestures per dialogue on average.", "labels": [], "entities": [{"text": "MM dialogues", "start_pos": 7, "end_pos": 19, "type": "TASK", "confidence": 0.9571648836135864}]}, {"text": "The agents performed almost all gestures (98%), with a clear preference for area selections (61% of total gestures).", "labels": [], "entities": []}, {"text": "Most gestures (79%) followed a dialogue contribution; none of the gestures were performed during speech.", "labels": [], "entities": []}, {"text": "Overall, few or no deictics were used.", "labels": [], "entities": []}, {"text": "We believe that these findings are related to the push-to-talk procedure and to the time needed to transfer gestures across the network: agents often preceded gestures with appropriate verbal cues e.g., \"I'll show you the hotel on the map\", in order to notify the other party of an upcoming gesture.", "labels": [], "entities": []}, {"text": "These verbal cues indicate that gestures were well integrated in the communication.", "labels": [], "entities": []}, {"text": "We found significant differences between the SO and MM dialogues in terms of unsuccessful and repeated turns, particularly so in the spatial segments of the dialogues.", "labels": [], "entities": [{"text": "SO and MM dialogues", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7842873632907867}]}, {"text": "In the English-Italian dialogues the MM dialogues contained 19% unsuccessful turns versus 30% for the SO dialogues.", "labels": [], "entities": [{"text": "MM dialogues", "start_pos": 37, "end_pos": 49, "type": "TASK", "confidence": 0.8736181259155273}, {"text": "SO dialogues", "start_pos": 102, "end_pos": 114, "type": "TASK", "confidence": 0.8937634527683258}]}, {"text": "For German-Italian dialogues we found 18% in MM versus 31% in SO.", "labels": [], "entities": [{"text": "MM", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.7415128350257874}]}, {"text": "English-Italian MM dialogues contained 11% repeated turns versus 17% for SO.", "labels": [], "entities": [{"text": "MM dialogues", "start_pos": 16, "end_pos": 28, "type": "TASK", "confidence": 0.9088926613330841}]}, {"text": "For German-Italian dialogues repeated turns amounted to 18% for MM versus 23% for SO.", "labels": [], "entities": [{"text": "MM", "start_pos": 64, "end_pos": 66, "type": "TASK", "confidence": 0.7356134653091431}]}, {"text": "In addition we found smoother dialogues under MM condition, with fewer returns to already discussed topics for MM (one return every 19 turns in SO versus one return every 31 turns in MM).", "labels": [], "entities": [{"text": "MM", "start_pos": 111, "end_pos": 113, "type": "TASK", "confidence": 0.9546016454696655}]}, {"text": "MM also exhibited a lower number of dialogue segments containing identifiable misunderstandings between the two parties (one such segment in each of 3 of the MM dialogues, versus a total of seven such segments in the SO dialogues -one dialogue with 3 segments, one with two, and a third with a single segment of miscommunication).", "labels": [], "entities": [{"text": "MM", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.7775272130966187}, {"text": "MM dialogues", "start_pos": 158, "end_pos": 170, "type": "TASK", "confidence": 0.732896089553833}, {"text": "SO dialogues", "start_pos": 217, "end_pos": 229, "type": "TASK", "confidence": 0.8623169362545013}]}, {"text": "Furthermore, the misunderstandings in MM conditions were often immediately solved by resorting to MM resources, while in case of SO ambiguous or mis-understood subdialogues often remained unresolved.", "labels": [], "entities": [{"text": "MM", "start_pos": 38, "end_pos": 40, "type": "TASK", "confidence": 0.927758514881134}, {"text": "SO ambiguous or mis-understood subdialogues", "start_pos": 129, "end_pos": 172, "type": "TASK", "confidence": 0.8678961515426635}]}, {"text": "Finally, the experiment subjects, given the choice between the MM and the SO system, expressed a clear preference for the former.", "labels": [], "entities": []}, {"text": "In summary, we found strong supporting evidence that multimodality has a positive effect on the quality of interaction by reducing ambiguity, making it easier to resolve ambiguous utterances and to recover from system errors, improving the flow of the dialogue, and enhancing the mutual comprehension between the parties, in particular when spatial information is involved.", "labels": [], "entities": []}, {"text": "In December 2001, we conducted a large scale multi-lingual end-to-end translation evaluation of the Nespole!", "labels": [], "entities": [{"text": "Nespole!", "start_pos": 100, "end_pos": 108, "type": "DATASET", "confidence": 0.8711145520210266}]}, {"text": "For each of the three language pairs (English-Italian, German-Italian and French-Italian), four previ-    ously unseen test dialogues were used to evaluate the performance of the translation system.", "labels": [], "entities": []}, {"text": "The dialogues included two scenarios: one covering winter ski vacations, the other about summer resorts.", "labels": [], "entities": []}, {"text": "One or two of the dialogues for each language contained multi-modal expressions.", "labels": [], "entities": []}, {"text": "The test data included a mixture of dialogues that were collected mono-lingually prior to system development (both client and agent spoke the same language), and data collected bilingually (during the July 2001 MM experiment), using the actual translation system.", "labels": [], "entities": [{"text": "MM experiment)", "start_pos": 211, "end_pos": 225, "type": "TASK", "confidence": 0.7686219414075216}]}, {"text": "This mixture of data conditions was intended primarily for comprehensiveness and not for comparison of the different conditions.", "labels": [], "entities": []}, {"text": "We performed an extensive suite of evalua- tions on the above data.", "labels": [], "entities": []}, {"text": "The evaluations were all end-to-end, from input to output, not assessing individual modules or components.", "labels": [], "entities": []}, {"text": "We performed both mono-lingual evaluation (where generated output language was the same as the input language), as well as cross-lingual evaluation.", "labels": [], "entities": []}, {"text": "For cross-lingual evaluations, translation from English German and French to Italian was evaluated on client utterances, and translation from Italian to each of the three languages was evaluated on agent utterances.", "labels": [], "entities": []}, {"text": "We evaluated on both manually transcribed input as well as on actual speech-recognition of the original audio.", "labels": [], "entities": []}, {"text": "We also graded the speech recognized output as a \"paraphrase\" of the transcriptions, to measure the levels of semantic loss of information due to recognition errors.", "labels": [], "entities": []}, {"text": "Speech recognition word accuracies and the results of speech graded as a paraphrase appear in.", "labels": [], "entities": [{"text": "Speech recognition word accuracies", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.6915281489491463}]}, {"text": "Translations were graded by multiple human graders at the level of Semantic Dialogue Units (SDUs).", "labels": [], "entities": [{"text": "Translations", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.9501330852508545}]}, {"text": "For each data set, one grader first manually segmented each utterance into SDUs.", "labels": [], "entities": []}, {"text": "All graders then used this segmentation in order to assign scores for each SDU present in the utterance.", "labels": [], "entities": []}, {"text": "We followed the three-point grading scheme previously developed for the C-STAR consortium, as described in ().", "labels": [], "entities": [{"text": "C-STAR consortium", "start_pos": 72, "end_pos": 89, "type": "DATASET", "confidence": 0.8994581401348114}]}, {"text": "Each SDU is graded as either \"Perfect\" (meaning translated correctly and output is fluent), \"OK\" (meaning is translated reasonably correct but output maybe disfluent), or \"Bad\" (meaning not properly translated).", "labels": [], "entities": [{"text": "Perfect", "start_pos": 30, "end_pos": 37, "type": "METRIC", "confidence": 0.9885544180870056}, {"text": "OK", "start_pos": 93, "end_pos": 95, "type": "METRIC", "confidence": 0.9865043759346008}]}, {"text": "We calculate the percent of SDUs that are graded with each of the above categories.", "labels": [], "entities": []}, {"text": "\"Perfect\" and \"OK\" percentages are also summed together into a category of \"Acceptable\" translations.", "labels": [], "entities": [{"text": "Perfect", "start_pos": 1, "end_pos": 8, "type": "METRIC", "confidence": 0.9859776496887207}, {"text": "OK\" percentages", "start_pos": 15, "end_pos": 30, "type": "METRIC", "confidence": 0.890428384145101}, {"text": "Acceptable", "start_pos": 76, "end_pos": 86, "type": "METRIC", "confidence": 0.9967057108879089}]}, {"text": "Average percentages are calculated for each dialogue, each grader, and separately for client and agent utterances.", "labels": [], "entities": []}, {"text": "We then calculated combined averages for all graders and for all dialogues for each language pair.", "labels": [], "entities": []}, {"text": "shows the results of the monolingual end-to-end translation for the four languages, and shows the results of the crosslingual evaluations.", "labels": [], "entities": []}, {"text": "The results indicate acceptable translations in the range of 27-43% of SDUs (interlingua units) with speech recognized inputs.", "labels": [], "entities": []}, {"text": "While this level of translation accuracy cannot be considered impressive, our user studies and system demonstrations indicate that it is already sufficient for achieving effective communication with real users.", "labels": [], "entities": [{"text": "translation", "start_pos": 20, "end_pos": 31, "type": "TASK", "confidence": 0.9673461318016052}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.8911037445068359}]}, {"text": "We expect performance levels to reach a range of 60-70% within the next year of the project.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Features of the Speech Recognition Engines", "labels": [], "entities": [{"text": "Speech Recognition Engines", "start_pos": 26, "end_pos": 52, "type": "TASK", "confidence": 0.8239453037579855}]}, {"text": " Table 2: Speech Recognition Word Accuracy Rates and", "labels": [], "entities": [{"text": "Speech Recognition Word Accuracy Rates", "start_pos": 10, "end_pos": 48, "type": "TASK", "confidence": 0.7736338138580322}]}, {"text": " Table 3: Monolingual End-to-End Translation Results", "labels": [], "entities": [{"text": "Monolingual End-to-End Translation", "start_pos": 10, "end_pos": 44, "type": "TASK", "confidence": 0.7776477734247843}]}]}