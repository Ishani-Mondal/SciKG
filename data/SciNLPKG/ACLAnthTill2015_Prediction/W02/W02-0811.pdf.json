{"title": [{"text": "Combining Heterogeneous Classifiers for Word-Sense Disambiguation", "labels": [], "entities": [{"text": "Word-Sense Disambiguation", "start_pos": 40, "end_pos": 65, "type": "TASK", "confidence": 0.6795616298913956}]}], "abstractContent": [{"text": "This paper discusses ensembles of simple but heterogeneous classifiers for word-sense disambigua-tion, examining the Stanford-CS224N system entered in the SENSEVAL-2 English lexical sample task.", "labels": [], "entities": [{"text": "SENSEVAL-2 English lexical sample task", "start_pos": 155, "end_pos": 193, "type": "TASK", "confidence": 0.6453973889350891}]}, {"text": "First-order classifiers are combined by a second-order classifier, which variously uses majority voting, weighted voting, or a maximum en-tropy model.", "labels": [], "entities": []}, {"text": "While individual first-order classifiers perform comparably to middle-scoring teams' systems , the combination achieves high performance.", "labels": [], "entities": []}, {"text": "We discuss trade-offs and empirical performance.", "labels": [], "entities": []}, {"text": "Finally, we present an analysis of the combination, examining how ensemble performance depends on error independence and task difficulty.", "labels": [], "entities": []}], "introductionContent": [{"text": "The problem of supervised word sense disambiguation (WSD) has been approached using many different classification algorithms, including naive-Bayes, decision trees, decision lists, and memory-based learners.", "labels": [], "entities": [{"text": "supervised word sense disambiguation (WSD)", "start_pos": 15, "end_pos": 57, "type": "TASK", "confidence": 0.7829779556819371}]}, {"text": "While it is unquestionable that certain algorithms are better suited to the WSD problem than others (for a comparison, see), it seems that, given similar input features, various algorithms exhibit roughly similar accuracies.", "labels": [], "entities": [{"text": "WSD problem", "start_pos": 76, "end_pos": 87, "type": "TASK", "confidence": 0.9326902329921722}]}, {"text": "This was supported by the SENSEVAL-2 results, where a This paper is based on work supported in part by the National Science Foundation under Grants IIS-0085896 and IIS-9982226, by an NSF Graduate Fellowship, and by the Research Collaboration between NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation and CSLI, Stanford University.", "labels": [], "entities": [{"text": "SENSEVAL-2", "start_pos": 26, "end_pos": 36, "type": "TASK", "confidence": 0.6946230530738831}, {"text": "NTT Communication Science Laboratories", "start_pos": 250, "end_pos": 288, "type": "DATASET", "confidence": 0.6918323487043381}]}, {"text": "In fact, we have observed that differences between implementations of a single classifier type, such as smoothing or window size, impacted accuracy far more than the choice of classification algorithm.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9985686540603638}]}, {"text": "large fraction of systems had scores clustered in a fairly narrow region).", "labels": [], "entities": []}, {"text": "We began building our system with 23 supervised WSD systems, each submitted by a student taking the natural language processing course (CS224N) at Stanford University in Spring 2000.", "labels": [], "entities": []}, {"text": "Students were free to implement whatever WSD method they chose.", "labels": [], "entities": [{"text": "WSD", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9193665981292725}]}, {"text": "While most implemented variants of naive-Bayes, others implemented a range of other methods, including n-gram models, vector space models, and memory-based learners.", "labels": [], "entities": []}, {"text": "Taken individually, the best of these systems would have turned in an accuracy of 61.2% in the SENSEVAL-2 English lexical sample task (which would have given it 6th place), while others would have produced middling to low performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9994174242019653}, {"text": "SENSEVAL-2 English lexical sample task", "start_pos": 95, "end_pos": 133, "type": "TASK", "confidence": 0.58795046210289}]}, {"text": "In this paper, we investigate how these classifiers behave in combination.", "labels": [], "entities": []}, {"text": "In section 2, we discuss the first-order classifiers and describe our methods of combination.", "labels": [], "entities": []}, {"text": "In section 3, we discuss performance, analyzing what benefit was found from combination, and when.", "labels": [], "entities": []}, {"text": "We also discuss aspects of the component systems which substantially influenced overall performance.", "labels": [], "entities": []}, {"text": "shows the high-level organization of our system.", "labels": [], "entities": []}, {"text": "Individual first-order classifiers each map lists of context word tokens to word-sense predictions, and are self-contained WSD systems.", "labels": [], "entities": []}, {"text": "The firstorder classifiers are combined in a variety of ways with second-order classifiers.", "labels": [], "entities": []}, {"text": "Second-order classifiers are selectors, taking a list of first-order out-  1 Split data into multiple training and held-out parts.", "labels": [], "entities": []}, {"text": "2 Rank first-order classifiers globally (across all words).", "labels": [], "entities": []}, {"text": "3 Rank first-order classifiers locally (per word), breaking ties with global ranks.", "labels": [], "entities": []}, {"text": "4 For each word w 5", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Results by part-of-speech, and overall.", "labels": [], "entities": []}]}