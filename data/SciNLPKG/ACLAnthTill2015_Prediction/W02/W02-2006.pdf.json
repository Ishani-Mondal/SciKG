{"title": [{"text": "Bootstrapping a Multilingual Part-of-speech Tagger in One Person-day", "labels": [], "entities": [{"text": "Bootstrapping a Multilingual Part-of-speech Tagger", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.5115720272064209}]}], "abstractContent": [{"text": "This paper presents a method for bootstrapping a fine-grained, broad-coverage part-of-speech (POS) tagger in anew language using only one person-day of data acquisition effort.", "labels": [], "entities": []}, {"text": "It requires only three resources, which are currently readily available in 60-100 world languages: (1) an online or hardcopy pocket-sized bilingual dictionary, (2) a basic library reference grammar, and (3) access to an existing monolingual text corpus in the language.", "labels": [], "entities": []}, {"text": "The algorithm begins by inducing initial lexical POS distributions from English translations in a bilingual dictionary without POS tags.", "labels": [], "entities": []}, {"text": "It handles irregular, regular and semi-regular morphology through a robust generative model using weighted Levenshtein alignments.", "labels": [], "entities": []}, {"text": "Unsupervised induction of grammatical gender is performed via global modeling of context-window feature agreement.", "labels": [], "entities": [{"text": "induction of grammatical gender", "start_pos": 13, "end_pos": 44, "type": "TASK", "confidence": 0.7412702888250351}]}, {"text": "Using a combination of these and other evidence sources, interactive training of context and lexical prior models are accomplished for fine-grained POS tag spaces.", "labels": [], "entities": [{"text": "POS tag spaces", "start_pos": 148, "end_pos": 162, "type": "TASK", "confidence": 0.7727705836296082}]}, {"text": "Experiments show high accuracy, fine-grained tag resolution with minimal new human effort.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9991326928138733}]}], "introductionContent": [{"text": "Previous work in minimally supervised language learning has defined minimal using several different criteria.", "labels": [], "entities": []}, {"text": "Some have assumed only partially tagged training corpora, while others have begin with small tagged seed wordlists (such as and for named-entity tagging).", "labels": [], "entities": [{"text": "named-entity tagging", "start_pos": 132, "end_pos": 152, "type": "TASK", "confidence": 0.6952033340930939}]}, {"text": "Others have exploited the automatic transfer of some already existing annotated resource in a different medium or language (such as the translingual projection of part-of-speech tags, syntactic bracketing and inflectional morphology in, requiring no direct supervision in the foreign language).", "labels": [], "entities": [{"text": "syntactic bracketing", "start_pos": 184, "end_pos": 204, "type": "TASK", "confidence": 0.7088644504547119}]}, {"text": "observed that an often more practical measure of the degree of supervision is not simply the quantity of annotated words, but the total weighted human labor and resource costs of different modes of supervision (allowing manual rule writing to be compared directly with active learning on a common cost-performance learning curve).", "labels": [], "entities": []}, {"text": "In this paper we observe that another useful measure of (minimal) supervision is the additional cost of obtaining a desired functionality from existing commonly available knowledge sources.", "labels": [], "entities": []}, {"text": "In particular, we note that fora remarkably wide range of languages, academic libraries, many booksellers and websites offer a foundation of linguistic wisdom in reference grammars and dictionaries.", "labels": [], "entities": []}, {"text": "Thus starting from this baseline, what is the marginal cost of distilling from and augmenting this existing knowledge to achieve a desired new task functionality?", "labels": [], "entities": []}], "datasetContent": [{"text": "One problem with minimally supervised learning of foreign languages is that annotated evaluation data are often not available for the features being induced, or are otherwise difficult to obtain.", "labels": [], "entities": []}, {"text": "Thus we have used for initial test languages two languages familiar to the authors (Romanian and Spanish) for which sufficient evaluation resources could be obtained.", "labels": [], "entities": []}, {"text": "However, the monolingual corpora utilized for bootstrapping were quite small (123 thousand words of the book 1984 for Romanian and 3.2 million words of newswire for Spanish), which are easily comparable to the sizes that can be accessed online for 60-100 world languages.", "labels": [], "entities": []}, {"text": "The seed dictionaries were located online (for Spanish -42k entries) and via OCR (for Romanian -7k entries), and small grammar references were obtained at a local bookstore.", "labels": [], "entities": [{"text": "OCR", "start_pos": 77, "end_pos": 80, "type": "DATASET", "confidence": 0.6856908798217773}]}, {"text": "1000 words of test data were annotated with a standardized, finely detailed part-of-speech tag inventory including the full complex distinctions for gender, person, number, case, detailed tense and nominal definiteness (an inventory of 259 and 230 fine-grained tags were used for Spanish and Romanian respectively).", "labels": [], "entities": []}, {"text": "The minimal supervision in this study consisted of an average total of 4 person-hours per language for manually entering the inflectional paradigms and associated parts of speech from a grammar as in Section 3, and an additional average of 3 personhours per language for dictionary extraction and entry parsing.", "labels": [], "entities": [{"text": "dictionary extraction", "start_pos": 271, "end_pos": 292, "type": "TASK", "confidence": 0.7637635171413422}, {"text": "entry parsing", "start_pos": 297, "end_pos": 310, "type": "TASK", "confidence": 0.8547801077365875}]}, {"text": "OCR itself on our high-speed 2-sided scanner with OmniPage Pro took under 30 minutes).", "labels": [], "entities": [{"text": "OCR", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.4889557957649231}, {"text": "OmniPage Pro", "start_pos": 50, "end_pos": 62, "type": "DATASET", "confidence": 0.9302878975868225}]}, {"text": "As would be expected given that data entry was done by computer scientists which were not native speakers of the test languages, significant analysis errors or gaps were introduced when rather blindly transferring from the reference grammar.", "labels": [], "entities": []}, {"text": "Thus to test the relative contributions of limited native speaker help when available, for roughly 4 additional total person hours in a second test condition for Romanian a native speaker corrected and augmented gaps in the patterns previously entered from the grammar book, focusing almost exclusively on the complex inflections of closed-class words.", "labels": [], "entities": []}, {"text": "A summary of the results for these three supervision modes is given in.", "labels": [], "entities": []}, {"text": "Performance is broken down by fine-grained part of speech.", "labels": [], "entities": []}, {"text": "Exactmatch accuracy is measured over both the full finegrained (up to 5-feature) part-of-speech space, as well as the 12-class core POS tag (noun and proper noun, pronoun, verb, adjective, adverb, numeral, determiner, conjunction, preposition, interjection, particle, punctuation).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9804484248161316}, {"text": "POS tag (noun and proper noun, pronoun, verb, adjective, adverb, numeral, determiner, conjunction, preposition, interjection, particle, punctuation", "start_pos": 132, "end_pos": 279, "type": "Description", "confidence": 0.7402619380375435}]}, {"text": "The feature of grammatical gender was specifically isolated because it is rarely salient for cross-language applications such as machine translation (where grammatical gender rarely transfers), and because its induction algorithm in Section 4.1 depends heavily on the size of the monolingual corpus (which is small in these experiments, suggesting size-dependent potential for significant further improvement here).", "labels": [], "entities": [{"text": "grammatical gender", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.8471161127090454}, {"text": "machine translation", "start_pos": 129, "end_pos": 148, "type": "TASK", "confidence": 0.8087489306926727}]}, {"text": "Finally, a post-hoc analysis of the system vs. test data discrepancies showed that a significant number were simply arbitrary differences in annotation convention between the grammar-book analyses and the test data tagging policy.", "labels": [], "entities": []}, {"text": "For example, one such \"error\"/discrepancy is the rather arbitrary distinction of whether the Romanian word oricare (meaning any) should be considered an adjective (as listed in a standard bilingual dictionary) or a determiner.", "labels": [], "entities": []}, {"text": "Another difference is whether proper-name citations of common nouns (e.g. Casa Blanca) should be annotated for gender/number etc. or not.", "labels": [], "entities": [{"text": "proper-name citations of common nouns (e.g. Casa Blanca)", "start_pos": 30, "end_pos": 86, "type": "TASK", "confidence": 0.8563606262207031}]}, {"text": "Yet regardless of exactly how many system-test discrepancies are just policy differences rather than errors, even the raw accuracy here is very promising given the very fined-grained part-of-speech inventory and small monolingual data size used for bootstrapping.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9935339689254761}]}, {"text": "And ultimately the performance is quite: Performance of POS tagger induction based on 1 person-day of supervision, no tagged training corpora and a fine-grained (\ud97b\udf59250 tags) tagset.", "labels": [], "entities": [{"text": "POS tagger induction", "start_pos": 56, "end_pos": 76, "type": "TASK", "confidence": 0.8486977219581604}]}, {"text": "NNS and NN refer to non-native-speaker and native-speaker effort.", "labels": [], "entities": [{"text": "NNS", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8264482617378235}]}, {"text": "remarkable given that it is the result of less than 1 total person day of data collection and supervision, in contrast to the thousands of hours and $100,000-$1,000,000 spent on some annotated training data in a much more limited tagset inventories.", "labels": [], "entities": []}, {"text": "Thus in terms of cost-benefit analysis, the supervision paradigm and associated bootstrapping models presented here offer quite a good value of new functionality per labor invested.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of inducing candidate part-of-speech distributions derived solely from untagged En- glish translation lists. Results are measured by type (all dictionary entries are weighted equally).", "labels": [], "entities": []}, {"text": " Table 3: Performance of POS tagger induction  based on 1 person-day of supervision, no tagged  training corpora and a fine-grained (\ud97b\udf59250 tags)  tagset. NNS and NN refer to non-native-speaker and  native-speaker effort.", "labels": [], "entities": [{"text": "POS tagger induction", "start_pos": 25, "end_pos": 45, "type": "TASK", "confidence": 0.8784265915552775}]}]}