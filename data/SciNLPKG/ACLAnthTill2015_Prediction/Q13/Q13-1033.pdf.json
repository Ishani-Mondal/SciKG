{"title": [{"text": "Training Deterministic Parsers with Non-Deterministic Oracles", "labels": [], "entities": []}], "abstractContent": [{"text": "Greedy transition-based parsers are very fast but tend to suffer from error propagation.", "labels": [], "entities": []}, {"text": "This problem is aggravated by the fact that they are normally trained using oracles that are deter-ministic and incomplete in the sense that they assume a unique canonical path through the transition system and are only valid as long as the parser does not stray from this path.", "labels": [], "entities": []}, {"text": "In this paper, we give a general characterization of oracles that are nondeterministic and complete , present a method for deriving such oracles for transition systems that satisfy a property we call arc decomposition, and instantiate this method for three well-known transition systems from the literature.", "labels": [], "entities": []}, {"text": "We say that these oracles are dynamic, because they allow us to dynamically explore alternative and non-optimal paths during training-in contrast to oracles that statically assume a unique optimal path.", "labels": [], "entities": []}, {"text": "Experimental evaluation on a wide range of data sets clearly shows that using dynamic oracles to train greedy parsers gives substantial improvements inaccuracy.", "labels": [], "entities": []}, {"text": "Moreover, this improvement comes at no cost in terms of efficiency, unlike other techniques like beam search.", "labels": [], "entities": [{"text": "beam search", "start_pos": 97, "end_pos": 108, "type": "TASK", "confidence": 0.9346851110458374}]}], "introductionContent": [{"text": "Greedy transition-based parsers are easy to implement and are very efficient, but they are generally not as accurate as parsers that are based on global search ( or as transition-based parsers that use beam search or dynamic programming ().", "labels": [], "entities": []}, {"text": "This work is part of a line of research trying to push the boundaries of greedy parsing and narrow the accuracy gap of 2-3% between searchbased and greedy parsers, while maintaining the efficiency and incremental nature of greedy parsers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.9988150596618652}]}, {"text": "One reason for the lower accuracy of greedy parsers is error propagation: once the parser makes an error in decoding, more errors are likely to follow.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9983564019203186}, {"text": "error propagation", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.7406211495399475}]}, {"text": "This behavior is closely related to the way in which greedy parsers are normally trained.", "labels": [], "entities": []}, {"text": "Given a treebank oracle, a gold sequence of transitions is derived, and a predictor is trained to predict transitions along this gold sequence, without considering any parser state outside this sequence.", "labels": [], "entities": []}, {"text": "Thus, once the parser strays from the golden path attest time, it ventures into unknown territory and is forced to react to situations it has never been trained for.", "labels": [], "entities": []}, {"text": "In recent work, we introduced the concept of a dynamic oracle, which is non-deterministic and not restricted to a single golden path, but instead provides optimal predictions for any possible state the parser might be in.", "labels": [], "entities": []}, {"text": "Dynamic oracles are non-deterministic in the sense that they return a set of valid transitions fora given parser state and gold tree.", "labels": [], "entities": []}, {"text": "Moreover, they are welldefined and optimal also for states from which the gold tree cannot be derived, in the sense that they return the set of transitions leading to the best tree derivable from each state.", "labels": [], "entities": []}, {"text": "We showed experimentally that, using a dynamic oracle for the arc-eager transition system, a greedy parser can be trained to perform well also after incurring a mistake, thus alleviating the effect of error propagation and resulting in consistently better parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 256, "end_pos": 263, "type": "TASK", "confidence": 0.9501559138298035}, {"text": "accuracy", "start_pos": 264, "end_pos": 272, "type": "METRIC", "confidence": 0.8519976735115051}]}, {"text": "In this paper, we extend the work of by giving a general characterization of dynamic oracles as oracles that are nondeterministic, in that they return sets of transitions, and complete, in that they are defined for all possible states.", "labels": [], "entities": []}, {"text": "We then define a formal property of transition systems which we call arc decomposition, and introduce a framework for deriving dynamic oracles for arc-decomposable systems.", "labels": [], "entities": [{"text": "arc decomposition", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.6884149312973022}]}, {"text": "Using this framework, we derive novel dynamic oracles for the hybrid () and easy-first) transition systems, which are arc-decomposable (as is the arc-eager system).", "labels": [], "entities": []}, {"text": "We also show that the popular arc-standard system) is not arc-decomposable, and so deriving a dynamic oracle for it remains an open research question.", "labels": [], "entities": []}, {"text": "Finally, we perform a set of experiments on the CoNLL 2007 data sets, validating that the use of dynamic oracles for exploring states that result from parsing mistakes during training is beneficial across transition systems.", "labels": [], "entities": [{"text": "CoNLL 2007 data sets", "start_pos": 48, "end_pos": 68, "type": "DATASET", "confidence": 0.9868530929088593}]}], "datasetContent": [{"text": "Setup, data and parameters The goal of our experiments is to evaluate the utility of the dynamic oracles for training, by comparing a training scenario which only sees configurations that can lead to the gold tree (following a static oracle for the left-to-right systems and a non-deterministic but incomplete oracle for the easy-first system), against a training scenario that involves exploration of incorrect states, using the dynamic oracles.", "labels": [], "entities": []}, {"text": "As our training algorithm involves a random component (we shuffle the sentences prior to each iteration, and randomly select whether to follow a corrector incorrect action), we evaluate each setup five times using different random seeds, and report the averaged results.", "labels": [], "entities": []}, {"text": "We perform all of the experiments on the multilingual CoNLL-2007 data sets.", "labels": [], "entities": [{"text": "CoNLL-2007 data sets", "start_pos": 54, "end_pos": 74, "type": "DATASET", "confidence": 0.9583554665247599}]}, {"text": "We use 15 training iterations for the left-to-right parsers, and 20 training iterations for the easy-first parser.", "labels": [], "entities": []}, {"text": "We use the standard perceptron update as our update rule in training, and use the averaged weight vector for prediction in test time.", "labels": [], "entities": []}, {"text": "The feature sets differ by transition system but are kept the same across data sets.", "labels": [], "entities": []}, {"text": "The exact feature-set definitions for the different systems are available in the accompanying software, which is available online at the first author's homepage.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on the CoNLL 2007 data set. UAS, including punctuation. Each number is an average over 5 runs  with different randomization seeds. All experiments used the same exploration parameters of k=1, p=0.9.", "labels": [], "entities": [{"text": "CoNLL 2007 data set", "start_pos": 25, "end_pos": 44, "type": "DATASET", "confidence": 0.9748261421918869}, {"text": "UAS", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.7596043348312378}]}]}