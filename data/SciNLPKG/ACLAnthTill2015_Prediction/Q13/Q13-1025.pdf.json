{"title": [{"text": "Data-driven, PCFG-based and Pseudo-PCFG-based Models for Chinese Dependency Parsing", "labels": [], "entities": [{"text": "Chinese Dependency Parsing", "start_pos": 57, "end_pos": 83, "type": "TASK", "confidence": 0.5510560969511668}]}], "abstractContent": [{"text": "We present a comparative study of transition-, graph-and PCFG-based models aimed at illuminating more precisely the likely contribution of CFGs in improving Chinese dependency parsing accuracy, especially by combining heterogeneous models.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 165, "end_pos": 183, "type": "TASK", "confidence": 0.7051504850387573}, {"text": "accuracy", "start_pos": 184, "end_pos": 192, "type": "METRIC", "confidence": 0.8624817728996277}]}, {"text": "Inspired by the impact of a constituency grammar on dependency parsing, we propose several strategies to acquire pseudo CFGs only from dependency annotations.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.8823042213916779}]}, {"text": "Compared to linguistic grammars learned from rich phrase-structure treebanks, well designed pseudo grammars achieve similar parsing accuracy and have equivalent contributions to parser ensemble.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.8415054678916931}]}, {"text": "Moreover, pseudo grammars increase the diversity of base models; therefore, together with all other models, further improve system combination.", "labels": [], "entities": []}, {"text": "Based on automatic POS tagging, our final model achieves a UAS of 87.23%, resulting in a significant improvement of the state of the art.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 19, "end_pos": 30, "type": "TASK", "confidence": 0.7898536324501038}, {"text": "UAS", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.9994475245475769}]}], "introductionContent": [{"text": "Popular approaches to dependency parsing can be divided into two classes: grammar-free and grammar-based.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.8403283655643463}]}, {"text": "Data-driven, grammar-free approaches make essential use of machine learning from linguistic annotations in order to parse new sentences.", "labels": [], "entities": [{"text": "parse new sentences", "start_pos": 116, "end_pos": 135, "type": "TASK", "confidence": 0.8476457794507345}]}, {"text": "Such approaches, e.g. transition-based and graph-based) have attracted the most attention in recent years.", "labels": [], "entities": []}, {"text": "In contrast, grammarbased approaches rely on linguistic grammars (in either dependency or constituency formalisms) to shape the search space for possible syntactic analysis.", "labels": [], "entities": []}, {"text": "In particular, CFG-based dependency parsing exploits a mapping between dependency and constituency representations and reuses parsing algorithms developed for CFG to produce dependency structures.", "labels": [], "entities": [{"text": "CFG-based dependency parsing", "start_pos": 15, "end_pos": 43, "type": "TASK", "confidence": 0.5755940278371176}]}, {"text": "In previous work, data-driven, discriminative approaches have been widely discussed for Chinese dependency parsing.", "labels": [], "entities": [{"text": "Chinese dependency parsing", "start_pos": 88, "end_pos": 114, "type": "TASK", "confidence": 0.6954160829385122}]}, {"text": "On the other hand, various PCFG-based constituent parsing methods have been applied to obtain phrase-structures as well.", "labels": [], "entities": [{"text": "PCFG-based constituent parsing", "start_pos": 27, "end_pos": 57, "type": "TASK", "confidence": 0.5942707558472952}]}, {"text": "With rich linguistic rules, phrase-structures of Chinese sentences can be well transformed to their corresponding dependency structures.", "labels": [], "entities": []}, {"text": "Therefore, PCFG parsers with such conversion rules can betaken as another type of dependency parser.", "labels": [], "entities": []}, {"text": "We call them PCFG-based parsers, in this paper.", "labels": [], "entities": []}, {"text": "Explicitly defining linguistic rules to express precisely generic grammatical regularities, a constituency grammar can be applied to arrange sentences into a hierarchy of nested phrases, which determines constructions between larger phrases and their smaller component phrases.", "labels": [], "entities": []}, {"text": "This type of information is different from, but highly related to, the information captured by a dependency representation.", "labels": [], "entities": []}, {"text": "A constituency grammar, thus, has great possible contributions to dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.8716251850128174}]}, {"text": "In order to pave the way for new and better methods, we study the impact of CFGs on Chinese dependency parsing.", "labels": [], "entities": [{"text": "Chinese dependency parsing", "start_pos": 84, "end_pos": 110, "type": "TASK", "confidence": 0.6540970404942831}]}, {"text": "A series of empirical analysis of state-ofthe-art graph-, transition-and PCFG-based parsers is presented to illuminate more precisely the properties of heterogeneous models.", "labels": [], "entities": []}, {"text": "We show that CFGs have a great impact on dependency parsing and PCFGbased models have complementary predictive powers to data-driven models.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.8673882782459259}]}, {"text": "System ensemble is an effective and important technique to build more accurate parsers based on multiple, diverse, weaker models.", "labels": [], "entities": []}, {"text": "Exploiting differ-ent data-driven models, e.g. transition-and graphbased models, has received the most attention in dependency parser ensemble).", "labels": [], "entities": []}, {"text": "Only a few works investigate integrating data-driven and PCFG-based models).", "labels": [], "entities": []}, {"text": "We argue that grammars can significantly increase the diversity of base models, which plays a central role in parser ensemble, and therefore lead to better and more promising hybrid systems.", "labels": [], "entities": []}, {"text": "We introduce a general classifier enhancing technique, i.e. bootstrap aggregating (Bagging), to improve dependency parsing accuracy.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 104, "end_pos": 122, "type": "TASK", "confidence": 0.7430936694145203}, {"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.8693524599075317}]}, {"text": "This technique can be applied to enhance a single-view parser, or to combine multiple heterogeneous parsers.", "labels": [], "entities": []}, {"text": "Experiments on the CoNLL 09 shared task data demonstrate its effectiveness: (1) Bagging can improve individual single-view parsers, especially the PCFGbased one; (2) Bagging is more effective than previously introduced ensemble methods to combine multi-view parsers; (3) Integrating data-driven and PCFG-based models is more useful than combining different data-driven models.", "labels": [], "entities": [{"text": "CoNLL 09 shared task data", "start_pos": 19, "end_pos": 44, "type": "DATASET", "confidence": 0.9153345227241516}]}, {"text": "Although PCFG-based models have a big contribution to data-driven dependency parsing, they have a serious limitation: There are no corresponding constituency annotations for some dependency treebanks, e.g. Chinese Dependency Treebank (LDC2012T05).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.7536562979221344}, {"text": "Chinese Dependency Treebank (LDC2012T05)", "start_pos": 206, "end_pos": 246, "type": "DATASET", "confidence": 0.9449242651462555}]}, {"text": "To overcome this limitation, we propose several strategies to acquire pseudo grammars only from dependency annotations.", "labels": [], "entities": []}, {"text": "In particular, dependency trees are converted to pseudo constituency trees and PCFGs can be extracted from such trees.", "labels": [], "entities": []}, {"text": "Another motivation of this study is to increase the diversity of candidate models for parser ensemble.", "labels": [], "entities": []}, {"text": "Experiments show that pseudo-PCFGbased models are very competitive: (1) Pseudo grammars achieve similar or even better parsing results than linguistic grammars learned from rich constituency annotations; (2) Compared to linguistic grammars, well designed, single-view pseudo grammars have an equivalent contribution to parser ensemble; (3) Combining different pseudo grammars even work better for ensemble than linguistic grammars; (4) Pseudo-PCFG-based models increase the diversity of base models, and therefore lead to further improvements for ensemble.", "labels": [], "entities": []}, {"text": "Based on automatic POS tagging, our final model achieves a UAS of 87.23% on the CoNLL data and 84.65% on CTB5, which yield relative error reductions of 18-24% over the best published results in the literature.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 19, "end_pos": 30, "type": "TASK", "confidence": 0.7892874777317047}, {"text": "UAS", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.9996142387390137}, {"text": "CoNLL data", "start_pos": 80, "end_pos": 90, "type": "DATASET", "confidence": 0.9602096974849701}, {"text": "CTB5", "start_pos": 105, "end_pos": 109, "type": "DATASET", "confidence": 0.9153710603713989}, {"text": "error", "start_pos": 132, "end_pos": 137, "type": "METRIC", "confidence": 0.9197595119476318}]}, {"text": "2 Background and related work 2.1 Data-driven dependency parsing The mainstream work on recent dependency parsing focuses on data-driven approaches that automatically learn to produce dependency graphs for sentences solely from a hand-crafted dependency treebank.", "labels": [], "entities": [{"text": "Data-driven dependency parsing", "start_pos": 34, "end_pos": 64, "type": "TASK", "confidence": 0.597542405128479}, {"text": "dependency parsing", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.7533999979496002}]}, {"text": "The advantage of such models is that they are easily ported to any language in which labeled linguistic resources exist.", "labels": [], "entities": []}, {"text": "Practically all statistical models that have been proposed in recent years can be mainly described as either graph-based or transition-based.", "labels": [], "entities": []}, {"text": "Both models have been adopted to learn Chinese dependency structures ().", "labels": [], "entities": []}, {"text": "According to published results, graph-based and transition-based parsers achieve similar accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9974431991577148}]}, {"text": "In the graph-based framework, informative evaluation results have been presented in ().", "labels": [], "entities": []}, {"text": "First, second and third order projective parsing models are well evaluated.", "labels": [], "entities": [{"text": "projective parsing", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.6995398998260498}]}, {"text": "In the transition-based framework, two advanced techniques have been studied.", "labels": [], "entities": []}, {"text": "First, developing features has been shown crucial to advancing parsing accuracy and a very rich feature set is carefully evaluated by.", "labels": [], "entities": [{"text": "parsing", "start_pos": 63, "end_pos": 70, "type": "TASK", "confidence": 0.9839252233505249}, {"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.941602349281311}]}, {"text": "Second, beyond deterministic greedy search, principled dynamic programming strategies can be employed to explore more possible hypotheses.", "labels": [], "entities": []}, {"text": "Both techniques have been examined and shown helpful for Chinese dependency parsing.", "labels": [], "entities": [{"text": "Chinese dependency parsing", "start_pos": 57, "end_pos": 83, "type": "TASK", "confidence": 0.6507014334201813}]}, {"text": "Furthermore, combined both and obtained a state-of-the-art supervised parsing result.", "labels": [], "entities": []}], "datasetContent": [{"text": "Penn Chinese TreeBank (CTB) is a segmented, POS tagged, and fully bracketed corpus in the constituency formalism, and very popular to evaluate fundamental NLP tasks, including word segmentation, POS tagging, constituent parsing as well as dependency parsing.", "labels": [], "entities": [{"text": "Penn Chinese TreeBank (CTB)", "start_pos": 0, "end_pos": 27, "type": "DATASET", "confidence": 0.9701728622118632}, {"text": "word segmentation", "start_pos": 176, "end_pos": 193, "type": "TASK", "confidence": 0.7515786588191986}, {"text": "POS tagging", "start_pos": 195, "end_pos": 206, "type": "TASK", "confidence": 0.8254742622375488}, {"text": "constituent parsing", "start_pos": 208, "end_pos": 227, "type": "TASK", "confidence": 0.730159729719162}, {"text": "dependency parsing", "start_pos": 239, "end_pos": 257, "type": "TASK", "confidence": 0.8388545215129852}]}, {"text": "We use CTB 6 as our main corpus and define the training, development and test sets according to the  a well known implementation of Collins' lexicalized model, for experiments.", "labels": [], "entities": [{"text": "CTB 6", "start_pos": 7, "end_pos": 12, "type": "DATASET", "confidence": 0.916874498128891}]}, {"text": "In data-driven parsing, features consisting of POS tags are very effective, so typically POS tagging is performed as a preprocessing.", "labels": [], "entities": [{"text": "data-driven parsing", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.5864810347557068}, {"text": "POS tagging", "start_pos": 89, "end_pos": 100, "type": "TASK", "confidence": 0.7055656313896179}]}, {"text": "We use the baseline sequential tagger described in) to provide such lexical information to the graph-based parser.", "labels": [], "entities": []}, {"text": "Note that the transition-based parser performs a joint inference to acquire POS and dependency information simultaneously, so there is no need to offer extra tagging results to it.", "labels": [], "entities": []}, {"text": "(Column 2-6) summarizes the overall accuracy of different parsers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9991770386695862}]}, {"text": "Two transition-based parsing results are presented: The first one employ a simple feature set () and a small beam (16); the second one employ rich features (Zhang and Nivre, 2011) and a larger beam (32).", "labels": [], "entities": []}, {"text": "Two graph-based parsing results are reported; the difference between them is whether integrate relation labels into the parsing procedure.", "labels": [], "entities": []}, {"text": "Roughly speaking, currently state-of-the-art data-driven models achieves slightly better precision than unlexicalized PCFG-based models with regard to unlabeled dependency prediction.", "labels": [], "entities": [{"text": "precision", "start_pos": 89, "end_pos": 98, "type": "METRIC", "confidence": 0.9985440969467163}, {"text": "dependency prediction", "start_pos": 161, "end_pos": 182, "type": "TASK", "confidence": 0.7007356137037277}]}, {"text": "Bagging has been applied to enhance discriminative sequence models for Chinese word segmentation (Sun, 2010b) and POS tagging clearly shows that the Bagging model taking both data-driven and PCFG-based models as basic systems outperform the Bagging model taking either model in isolation as basic systems.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 71, "end_pos": 96, "type": "TASK", "confidence": 0.5929569403330485}, {"text": "POS tagging", "start_pos": 114, "end_pos": 125, "type": "TASK", "confidence": 0.7683099508285522}]}, {"text": "The combination of a PCFG-based model and a data-driven model (either graph-based or transition-based) is more effective than the combination of two datadriven models, which has received the most attention in dependency parser ensemble. is the performance of reparsing on the development data.", "labels": [], "entities": []}, {"text": "From this table, we can see by utilizing more parsers, Bagging can enhance reparsing.", "labels": [], "entities": [{"text": "Bagging", "start_pos": 55, "end_pos": 62, "type": "TASK", "confidence": 0.9359195828437805}]}, {"text": "According to's findings, reparsing performs as well as other combination models.", "labels": [], "entities": [{"text": "reparsing", "start_pos": 25, "end_pos": 34, "type": "TASK", "confidence": 0.9723304510116577}]}, {"text": "Our auxiliary experiments confirm this finding: Learning-based stacking cannot achieve better performance.", "labels": [], "entities": [{"text": "Learning-based stacking", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.5343562811613083}]}, {"text": "Limited to the document length, we do not give descriptions of these experiments.", "labels": [], "entities": []}, {"text": "86.37 bagging 86.09 reparse) 85.86: UAS of reparsing and Bagging.", "labels": [], "entities": [{"text": "UAS", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.8434696197509766}, {"text": "Bagging", "start_pos": 57, "end_pos": 64, "type": "TASK", "confidence": 0.8074874877929688}]}], "tableCaptions": [{"text": " Table 1: Accuracy of different parsers. The first block  presents baseline parsers; the last two blocks present  Bagging-enhanced parsers, where m is respectively set to  15 and 8. Z08 and Z11 distinguish different feature sets;  b=16 and b=32 are beam sizes. +/-lab means whether to  incorporate relation labels to a model.", "labels": [], "entities": []}, {"text": " Table 2: UAS of Bagging(5) models with different \u03bb.", "labels": [], "entities": [{"text": "UAS", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.454814612865448}]}, {"text": " Table 4: UAS of pseudo-grammar-based models.", "labels": [], "entities": []}, {"text": " Table 5: UAS of different Bagging(15) models.", "labels": [], "entities": [{"text": "UAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.7834839224815369}]}]}