{"title": [{"text": "Branch and Bound Algorithm for Dependency Parsing with Non-local Features", "labels": [], "entities": [{"text": "Dependency Parsing", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.6308758556842804}]}], "abstractContent": [{"text": "Graph based dependency parsing is inefficient when handling non-local features due to high computational complexity of inference.", "labels": [], "entities": [{"text": "Graph based dependency parsing", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7521900683641434}]}, {"text": "In this paper, we proposed an exact and efficient decoding algorithm based on the Branch and Bound (B&B) framework where non-local features are bounded by a linear combination of local features.", "labels": [], "entities": [{"text": "Branch and Bound (B&B) framework", "start_pos": 82, "end_pos": 114, "type": "DATASET", "confidence": 0.5853686134020487}]}, {"text": "Dynamic programming is used to search the upper bound.", "labels": [], "entities": []}, {"text": "Experiments are conducted on English PTB and Chinese CTB datasets.", "labels": [], "entities": [{"text": "English PTB and Chinese CTB datasets", "start_pos": 29, "end_pos": 65, "type": "DATASET", "confidence": 0.7740427106618881}]}, {"text": "We achieved competitive Unlabeled Attachment Score (UAS) when no additional resources are available: 93.17% for English and 87.25% for Chinese.", "labels": [], "entities": [{"text": "Unlabeled Attachment Score (UAS)", "start_pos": 24, "end_pos": 56, "type": "METRIC", "confidence": 0.8285224139690399}]}, {"text": "Parsing speed is 177 words per second for English and 97 words per second for Chinese.", "labels": [], "entities": [{"text": "Parsing speed", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.9152478575706482}]}, {"text": "Our algorithm is general and can be adapted to non-projective dependency parsing or other graph-ical models.", "labels": [], "entities": []}], "introductionContent": [{"text": "For graph based projective dependency parsing, dynamic programming (DP) is popular for decoding due to its efficiency when handling local features.", "labels": [], "entities": [{"text": "graph based projective dependency parsing", "start_pos": 4, "end_pos": 45, "type": "TASK", "confidence": 0.6953699946403503}]}, {"text": "It performs cubic time parsing for arc-factored models) and biquadratic time for higher order models with richer sibling and grandchild features.", "labels": [], "entities": []}, {"text": "However, for models with general non-local features, DP is inefficient.", "labels": [], "entities": []}, {"text": "There have been numerous studies on global inference algorithms for general higher order parsing.", "labels": [], "entities": [{"text": "general higher order parsing", "start_pos": 68, "end_pos": 96, "type": "TASK", "confidence": 0.6170454397797585}]}, {"text": "One popular approach is reranking.", "labels": [], "entities": []}, {"text": "It typically has two steps: the low level classifier generates the top k hypotheses using local features, then the high level classifier reranks these candidates using global features.", "labels": [], "entities": []}, {"text": "Since the reranking quality is bounded by the oracle performance of candidates, some work has combined candidate generation and reranking steps using cube pruning) to achieve higher oracle performance.", "labels": [], "entities": [{"text": "candidate generation", "start_pos": 103, "end_pos": 123, "type": "TASK", "confidence": 0.7067048698663712}]}, {"text": "They parse a sentence in bottom up order and keep the top k derivations for each span using k best parsing).", "labels": [], "entities": []}, {"text": "After merging the two spans, non-local features are used to rerank top k combinations.", "labels": [], "entities": []}, {"text": "This approach is very efficient and flexible to handle various nonlocal features.", "labels": [], "entities": []}, {"text": "The disadvantage is that it tends to compute non-local features as early as possible so that the decoder can utilize that information at internal spans, hence it may miss long historical features such as long dependency chains.", "labels": [], "entities": []}, {"text": "Smith and Eisner modeled dependency parsing using Markov Random Fields (MRFs) with global constraints and applied loopy belief propagation (LBP) for approximate learning and inference.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.734506368637085}]}, {"text": "Similar work was done for Combinatorial Categorial Grammar (CCG) parsing ().", "labels": [], "entities": [{"text": "Combinatorial Categorial Grammar (CCG) parsing", "start_pos": 26, "end_pos": 72, "type": "TASK", "confidence": 0.7944505981036595}]}, {"text": "They used posterior marginal beliefs for inference to satisfy the tree constraint: for each factor, only legal messages (satisfying global constraints) are considered in the partition function.", "labels": [], "entities": []}, {"text": "A similar line of research investigated the use of integer linear programming (ILP) based parsing ().", "labels": [], "entities": [{"text": "integer linear programming (ILP) based parsing", "start_pos": 51, "end_pos": 97, "type": "TASK", "confidence": 0.6472037956118584}]}, {"text": "This method is very expressive.", "labels": [], "entities": []}, {"text": "It can handle arbitrary non-local features determined or bounded by linear inequalities of local features.", "labels": [], "entities": []}, {"text": "For local models, LP is less efficient than DP.", "labels": [], "entities": [{"text": "LP", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.9693061709403992}]}, {"text": "The reason is that, DP works on a small number of dimensions in each recursion, while for LP, the popular revised simplex method needs to solve am dimensional linear system in each iteration (, where m is the number of constraints, which is quadratic in sentence length for projective dependency parsing ().", "labels": [], "entities": [{"text": "projective dependency parsing", "start_pos": 274, "end_pos": 303, "type": "TASK", "confidence": 0.6771860520044962}]}, {"text": "Dual Decomposition (DD) ( ) is a special case of Lagrangian relaxation.", "labels": [], "entities": []}, {"text": "It relies on standard decoding algorithms as oracle solvers for sub-problems, together with a simple method for forcing agreement between the different oracles.", "labels": [], "entities": []}, {"text": "This method does not need to consider the tree constraint explicitly, as it resorts to dynamic programming which guarantees its satisfaction.", "labels": [], "entities": []}, {"text": "It works well if the sub-problems can be well defined, especially for joint learning tasks.", "labels": [], "entities": []}, {"text": "However, for the task of dependency parsing, using various non-local features may result in many overlapped sub-problems, hence it may take along time to reach a consensus In this paper, we propose a novel Branch and Bound (B&B) algorithm for efficient parsing with various non-local features.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.7993191480636597}]}, {"text": "B&B is generally used for combinatorial optimization problems such as ILP.", "labels": [], "entities": [{"text": "B", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.8719996809959412}]}, {"text": "The difference between our method and ILP is that the sub-problem in ILP is a relaxed LP, which requires a numerical solution, while ours bounds the non-local features by a linear combination of local features and uses DP for decoding as well as calculating the upper bound of the objective function.", "labels": [], "entities": []}, {"text": "An exact solution is achieved if the bound is tight.", "labels": [], "entities": []}, {"text": "Though in the worst case, time complexity is exponential in sentence length, it is practically efficient especially when adopting a pruning strategy.", "labels": [], "entities": []}, {"text": "Experiments are conducted on English PennTree Bank and Chinese Tree Bank 5 (CTB5) with standard train/develop/test split.", "labels": [], "entities": [{"text": "English PennTree Bank", "start_pos": 29, "end_pos": 50, "type": "DATASET", "confidence": 0.8375357786814371}, {"text": "Chinese Tree Bank 5 (CTB5)", "start_pos": 55, "end_pos": 81, "type": "DATASET", "confidence": 0.9686822635786874}]}, {"text": "We achieved 93.17% Unlabeled Attachment Score (UAS) for English at a speed of 177 words per second and 87.25% for Chinese at a speed of 97 words per second.", "labels": [], "entities": [{"text": "Unlabeled Attachment Score (UAS)", "start_pos": 19, "end_pos": 51, "type": "METRIC", "confidence": 0.8549762268861135}]}], "datasetContent": [{"text": "The datasets we used are the English Penn Tree Bank (PTB) and Chinese Tree Bank 5.0 (CTB5).", "labels": [], "entities": [{"text": "English Penn Tree Bank (PTB)", "start_pos": 29, "end_pos": 57, "type": "DATASET", "confidence": 0.8992010865892682}, {"text": "Chinese Tree Bank 5.0 (CTB5)", "start_pos": 62, "end_pos": 90, "type": "DATASET", "confidence": 0.956424960068294}]}, {"text": "We use the standard train/develop/test split as described in.", "labels": [], "entities": []}, {"text": "We extracted dependencies using Joakim Nivre's Penn2Malt tool with standard head rules: Yamada and Matsumoto's (", "labels": [], "entities": [{"text": "Penn2Malt", "start_pos": 47, "end_pos": 56, "type": "DATASET", "confidence": 0.9087464213371277}]}], "tableCaptions": [{"text": " Table 1: Data split in our experiment", "labels": [], "entities": []}, {"text": " Table 2: Comparison between our system and the- state-of-art systems.", "labels": [], "entities": []}, {"text": " Table 3: Trade off between parsing accuracy (UAS)  and speed (words per second) with different pre- pruning settings. k denotes the number of candi- date heads of each word preserved for B&B parsing.   \u2020 Their speed is not directly comparable as they per- forms labeled parsing without pruning.", "labels": [], "entities": [{"text": "parsing", "start_pos": 28, "end_pos": 35, "type": "TASK", "confidence": 0.9467909932136536}, {"text": "accuracy (UAS)", "start_pos": 36, "end_pos": 50, "type": "METRIC", "confidence": 0.8621717989444733}, {"text": "speed", "start_pos": 56, "end_pos": 61, "type": "METRIC", "confidence": 0.9441361427307129}, {"text": "B&B parsing", "start_pos": 188, "end_pos": 199, "type": "TASK", "confidence": 0.619447186589241}]}]}