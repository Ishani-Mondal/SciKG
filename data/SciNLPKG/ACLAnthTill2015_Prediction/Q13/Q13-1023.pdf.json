{"title": [{"text": "Good, Great, Excellent: Global Inference of Semantic Intensities", "labels": [], "entities": []}], "abstractContent": [{"text": "Adjectives like good, great, and excellent are similar in meaning, but differ in intensity.", "labels": [], "entities": []}, {"text": "Intensity order information is very useful for language learners as well as in several NLP tasks, but is missing inmost lexical resources (dictionaries, WordNet, and thesauri).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 153, "end_pos": 160, "type": "DATASET", "confidence": 0.9561523795127869}]}, {"text": "In this paper, we present a primarily unsupervised approach that uses semantics from Web-scale data (e.g., phrases like good but not excellent) to rank words by assigning them positions on a continuous scale.", "labels": [], "entities": []}, {"text": "We rely on Mixed Integer Linear Programming to jointly determine the ranks, such that individual decisions benefit from global information.", "labels": [], "entities": []}, {"text": "When ranking English adjectives, our global algorithm achieves substantial improvements over previous work on both pairwise and rank correlation metrics (specifically, 70% pairwise accuracy as compared to only 56% by previous work).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 181, "end_pos": 189, "type": "METRIC", "confidence": 0.9293310642242432}]}, {"text": "Moreover, our approach can incorporate external synonymy information (increas-ing its pairwise accuracy to 78%) and extends easily to new languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.906944990158081}]}, {"text": "We also make our code and data freely available.", "labels": [], "entities": []}], "introductionContent": [{"text": "Current lexical resources such as dictionaries and thesauri do not provide information about the intensity order of words.", "labels": [], "entities": []}, {"text": "For example, both WordNet and Roget's 21st Century Thesaurus (thesaurus.com) present acceptable, great, and superb as synonyms of the adjective good.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 18, "end_pos": 25, "type": "DATASET", "confidence": 0.9394271373748779}]}, {"text": "However, a native speaker knows that these words represent varying intensity and can in fact generally be ranked by intensity as acceptable < good < great < superb.", "labels": [], "entities": []}, {"text": "Similarly, warm < hot < scorching are identified as synonyms in these resources.", "labels": [], "entities": []}, {"text": "Ranking information, http://demelo.org/gdm/intensity/ however, is crucial because it allows us to differentiate e.g. between various intensities of an emotion, and is hence very useful for humans when learning a language or judging product reviews, as well as for automatic text understanding and generation tasks such as sentiment and subjectivity analysis, recognizing textual entailment, question answering, summarization, and coreference and discourse analysis.", "labels": [], "entities": [{"text": "text understanding and generation", "start_pos": 274, "end_pos": 307, "type": "TASK", "confidence": 0.7515243589878082}, {"text": "sentiment and subjectivity analysis", "start_pos": 322, "end_pos": 357, "type": "TASK", "confidence": 0.7679605185985565}, {"text": "question answering", "start_pos": 391, "end_pos": 409, "type": "TASK", "confidence": 0.8753228187561035}, {"text": "summarization", "start_pos": 411, "end_pos": 424, "type": "TASK", "confidence": 0.9861195087432861}, {"text": "coreference and discourse analysis", "start_pos": 430, "end_pos": 464, "type": "TASK", "confidence": 0.7234870940446854}]}, {"text": "In this work, we attempt to automatically rank sets of related words by intensity, focusing in particular on adjectives.", "labels": [], "entities": []}, {"text": "This is made possible by the vast amounts of world knowledge that are now available.", "labels": [], "entities": []}, {"text": "We use lexico-semantic information extracted from a Web-scale corpus in conjunction with an algorithm based on a Mixed Integer Linear Program (MILP).", "labels": [], "entities": []}, {"text": "Linguistic analyses have identified phrases such as good but not great or hot and almost scorching in a text corpus as sources of evidence about the relative intensities of words.", "labels": [], "entities": []}, {"text": "However, pure information extraction approaches often fail to provide enough coverage for real-world downstream applications (Tandon and de, unless some form of advanced inference is used (.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.747605562210083}]}, {"text": "In our work, we address this sparsity problem by relying on Web-scale data and using an MILP model that extends the pairwise scores to a more complete joint ranking of words on a continuous scale, while maintaining global constraints such as transitivity and giving more weight to the order of word pairs with higher corpus evidence scores.", "labels": [], "entities": []}, {"text": "Instead of considering intensity ranking as a pairwise decision process, we thus exploit the fact that individual decisions may benefit from global information, e.g. about how two words relate to some third word.", "labels": [], "entities": []}, {"text": "Previous work) has also used lexico-semantic patterns to or-der adjectives.", "labels": [], "entities": []}, {"text": "They mainly evaluate their algorithm on a set of pairwise decisions, but also present a partitioning approach that attempts to form scales by placing each adjective to the left or right of pivot words.", "labels": [], "entities": []}, {"text": "Unfortunately, this approach often fails because many pairs lack order-based evidence even on the Web, as explained in more detail in Section 3.", "labels": [], "entities": []}, {"text": "In contrast, our MILP jointly uses information from all relevant word pairs and captures complex interactions and inferences to produce intensity scales.", "labels": [], "entities": []}, {"text": "We can thus obtain an order between two adjectives even when there is no explicit evidence in the corpus (using evidence for related pairs and transitive inference).", "labels": [], "entities": []}, {"text": "Our global MILP is flexible and can also incorporate additional synonymy information if available (which helps the MILP find an even better ranking solution).", "labels": [], "entities": []}, {"text": "Our approach also extends easily to new languages.", "labels": [], "entities": []}, {"text": "We describe two approaches for this multilingual extension: pattern projection and cross-lingual MILPs.", "labels": [], "entities": [{"text": "pattern projection", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.732739046216011}, {"text": "cross-lingual MILPs", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.5227907598018646}]}, {"text": "We evaluate our predicted intensity rankings using both pairwise classification accuracy and ranking correlation coefficients, achieving strong results, significantly better than the previous approach by Sheinman & Tokunaga (32% relative error reduction) and quite close to human-level performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.7931186556816101}, {"text": "relative error reduction", "start_pos": 229, "end_pos": 253, "type": "METRIC", "confidence": 0.8341255585352579}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Main test results", "labels": [], "entities": [{"text": "Main", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.7052513957023621}]}, {"text": " Table 4: Confusion matrix (Web baseline)", "labels": [], "entities": []}, {"text": " Table 5: Confusion matrix (MILP)", "labels": [], "entities": []}]}