{"title": [{"text": "A Novel Feature-based Bayesian Model for Query Focused Multi-document Summarization", "labels": [], "entities": [{"text": "Query Focused Multi-document Summarization", "start_pos": 41, "end_pos": 83, "type": "TASK", "confidence": 0.5691563338041306}]}], "abstractContent": [{"text": "Supervised learning methods and LDA based topic model have been successfully applied in the field of multi-document summarization.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 101, "end_pos": 129, "type": "TASK", "confidence": 0.6699662208557129}]}, {"text": "In this paper, we propose a novel supervised approach that can incorporate rich sentence features into Bayesian topic models in a principled way, thus taking advantages of both topic model and feature based supervised learning methods.", "labels": [], "entities": []}, {"text": "Experimental results on DUC2007, TAC2008 and TAC2009 demonstrate the effectiveness of our approach.", "labels": [], "entities": [{"text": "DUC2007", "start_pos": 24, "end_pos": 31, "type": "DATASET", "confidence": 0.9285471439361572}, {"text": "TAC2008", "start_pos": 33, "end_pos": 40, "type": "METRIC", "confidence": 0.4818101227283478}, {"text": "TAC2009", "start_pos": 45, "end_pos": 52, "type": "DATASET", "confidence": 0.6106696724891663}]}], "introductionContent": [{"text": "Query-focused multi-document summarization (; can facilitate users to grasp the main idea of documents.", "labels": [], "entities": [{"text": "Query-focused multi-document summarization", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.5870145459969839}]}, {"text": "In query-focused summarization, a specific topic description, such as a query, which expresses the most important topic information is proposed before the document collection, and a summary would be generated according to the given topic.", "labels": [], "entities": []}, {"text": "Supervised models have been widely used in summarization).", "labels": [], "entities": [{"text": "summarization", "start_pos": 43, "end_pos": 56, "type": "TASK", "confidence": 0.9922118186950684}]}, {"text": "Supervised models usually regard summarization as a classification or regression problem and use various sentence features to build a classifier based on labeled negative or positive samples.", "labels": [], "entities": [{"text": "summarization", "start_pos": 33, "end_pos": 46, "type": "TASK", "confidence": 0.9786732792854309}]}, {"text": "However, existing supervised approaches seldom exploit the intrinsic structure among sentences.", "labels": [], "entities": []}, {"text": "This disadvantage usually gives rise to serious problems such as unbalance and low recall in summaries.", "labels": [], "entities": [{"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9993457198143005}, {"text": "summaries", "start_pos": 93, "end_pos": 102, "type": "TASK", "confidence": 0.9454514980316162}]}, {"text": "Recently, LDA-based () Bayesian topic models have widely been applied in multidocument summarization in that Bayesian approaches can offer clear and rigorous probabilistic interpretations for summaries;).", "labels": [], "entities": [{"text": "multidocument summarization", "start_pos": 73, "end_pos": 100, "type": "TASK", "confidence": 0.5811903774738312}]}, {"text": "Exiting Bayesian approaches label sentences or words with topics and sentences which are closely related with query or can highly generalize documents are selected into summaries.", "labels": [], "entities": []}, {"text": "However, LDA topic model suffers from the intrinsic disadvantages that it only uses word frequency for topic modeling and cannot use useful text features such as position, word order etc (.", "labels": [], "entities": []}, {"text": "For example, the first sentence in a document maybe more important for summary since it is more likely to give a global generalization about the document.", "labels": [], "entities": []}, {"text": "It is hard for LDA model to consider such information, making useful information lost.", "labels": [], "entities": []}, {"text": "It naturally comes to our minds that we can improve summarization performance by making full use of both useful text features and the latent semantic structures from by LDA topic model.", "labels": [], "entities": [{"text": "summarization", "start_pos": 52, "end_pos": 65, "type": "TASK", "confidence": 0.9911106824874878}]}, {"text": "One related work is from.", "labels": [], "entities": []}, {"text": "They built a hierarchical topic model called Hybhsum based on LDA for topic discovery and assumed this model can produce appropriate scores for sentence evaluation.", "labels": [], "entities": [{"text": "topic discovery", "start_pos": 70, "end_pos": 85, "type": "TASK", "confidence": 0.7705126404762268}]}, {"text": "Then the scores are used for tuning the weights of various features that helpful for summary generation.", "labels": [], "entities": [{"text": "summary generation", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.9073862433433533}]}, {"text": "Their work made a good step of combining topic model with feature based supervised learning.", "labels": [], "entities": []}, {"text": "However, what their approach confuses us is that whether a topic model only based on word frequency is good enough to generate an appropriate sentence score for regression.", "labels": [], "entities": []}, {"text": "Actually, how to incorporate features into LDA topic model has been a open problem.", "labels": [], "entities": []}, {"text": "Supervised topic models such as sLDA give us some inspiration.", "labels": [], "entities": []}, {"text": "In sLDA, each document is associated with a labeled feature and sLDA can integrate such feature into LDA for topic modeling in a prin-cipled way.", "labels": [], "entities": []}, {"text": "With reference to the work of supervised LDA models, in this paper, we propose a novel sentence feature based Bayesian model S-sLDA for multidocument summarization.", "labels": [], "entities": [{"text": "multidocument summarization", "start_pos": 136, "end_pos": 163, "type": "TASK", "confidence": 0.5939785838127136}]}, {"text": "Our approach can naturally combine feature based supervised methods and topic models.", "labels": [], "entities": []}, {"text": "The most important and challenging problem in our model is the tuning of feature weights.", "labels": [], "entities": []}, {"text": "To solve this problem, we transform the problem of finding optimum feature weights into an optimization algorithm and learn these weights in a supervised way.", "labels": [], "entities": []}, {"text": "A set of experiments are conducted based on the benchmark data of DUC2007, TAC2008 and TAC2009, and experimental results show the effectiveness of our model.", "labels": [], "entities": [{"text": "DUC2007", "start_pos": 66, "end_pos": 73, "type": "DATASET", "confidence": 0.93466717004776}, {"text": "TAC2008", "start_pos": 75, "end_pos": 82, "type": "DATASET", "confidence": 0.5231176018714905}, {"text": "TAC2009", "start_pos": 87, "end_pos": 94, "type": "DATASET", "confidence": 0.5961563587188721}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes some background and related works.", "labels": [], "entities": []}, {"text": "Section 3 describes our details of S-sLDA model.", "labels": [], "entities": []}, {"text": "Section 4 demonstrates details of our approaches, including learning, inference and summary generation.", "labels": [], "entities": [{"text": "summary generation", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.7837904095649719}]}, {"text": "Section 5 provides experiments results and Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "The query-focused multi-document summarization task defined in DUC data is used as the test data.", "labels": [], "entities": [{"text": "DUC data", "start_pos": 63, "end_pos": 71, "type": "DATASET", "confidence": 0.9192304015159607}]}, {"text": "Stop-words in both documents and queries are removed using a stop-word list of 598 words, and the remaining words are stemmed by Porter Stemmer . As for the automatic evaluation of summarization, ROUGE (Recall-Oriented Understudy for Gisting Evaluation) measures, including ROUGE-1, ROUGE-2, and ROUGE-SU4 and their corresponding 95% confidence intervals, are used to evaluate the performance of the summaries.", "labels": [], "entities": [{"text": "summarization", "start_pos": 181, "end_pos": 194, "type": "TASK", "confidence": 0.963470458984375}, {"text": "ROUGE", "start_pos": 196, "end_pos": 201, "type": "METRIC", "confidence": 0.9601337313652039}]}, {"text": "In order to obtain a more comprehensive measure of summary quality, we also conduct manual evaluation on TAC data with reference to).", "labels": [], "entities": [{"text": "TAC data", "start_pos": 105, "end_pos": 113, "type": "DATASET", "confidence": 0.6850392371416092}]}, {"text": "In order to obtain a more accurate measure of summary quality for our S-sLDA model and Hybhsum, we performed a simple user study concerning the following aspects: (1) Overall quality: Which summary is better overall?", "labels": [], "entities": [{"text": "Hybhsum", "start_pos": 87, "end_pos": 94, "type": "DATASET", "confidence": 0.9449819922447205}]}, {"text": "(2) Focus: Which summary contains less irrelevant content?   and Hybhsum, as well as the four questions above.", "labels": [], "entities": [{"text": "Hybhsum", "start_pos": 65, "end_pos": 72, "type": "METRIC", "confidence": 0.654056966304779}]}, {"text": "Then they need to answer which summary is better (tie).", "labels": [], "entities": []}, {"text": "We randomly select 20 document collections from TAC 2008 data and randomly assign two summaries for each collection to three different evaluators to judge which model is better in each aspect.", "labels": [], "entities": [{"text": "TAC 2008 data", "start_pos": 48, "end_pos": 61, "type": "DATASET", "confidence": 0.9529707233111063}]}, {"text": "As we can see from  Responsiveness, S-sLDA model outputs Hybhsum based on t-test on 95% confidence level.", "labels": [], "entities": [{"text": "Hybhsum", "start_pos": 57, "end_pos": 64, "type": "METRIC", "confidence": 0.995293915271759}]}, {"text": "shows the example summaries generated respectively by two models for document collection D0803A-A in TAC2008, whose query is \"Describe the coalmine accidents in China and actions taken\".", "labels": [], "entities": [{"text": "TAC2008", "start_pos": 101, "end_pos": 108, "type": "DATASET", "confidence": 0.5159160494804382}]}, {"text": "From table 6, we can see that each sentence in these two summaries is somewhat related to topics of coal mines in China.", "labels": [], "entities": []}, {"text": "We also observe that the summary in(a) is better than that in(b), tending to select shorter sentences and provide more information.", "labels": [], "entities": []}, {"text": "This is because, in S-sLDA model, topic modeling is determined simultaneously by various features including terms and other ones such as sentence length, sentence position and soon, which can contribute to summary quality.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.8061027228832245}, {"text": "soon", "start_pos": 176, "end_pos": 180, "type": "METRIC", "confidence": 0.9590393900871277}]}, {"text": "As we can see, in(b), sentences and provide some unimportant information such as \"somebody said\", though they contain some words which are related to topics about coal mines.", "labels": [], "entities": []}, {"text": "(1)China to close at least 4,000 coal mines this year: official (2)By Oct. 10 this year there had been 43 coalmine accidents that killed 10 or more people, (3)Officials had stakes in coal mines.", "labels": [], "entities": []}, {"text": "(4)All the coal mines will be closed down this year.", "labels": [], "entities": []}, {"text": "(5) In the first eight months, the death toll of coalmine accidents rose 8.5 percent last year.", "labels": [], "entities": [{"text": "the death toll", "start_pos": 31, "end_pos": 45, "type": "METRIC", "confidence": 0.7209020654360453}]}, {"text": "(6) The government has issued a series of regulations and measures to improve the coun.try's coalmine safety situation.The mining safety technology and equipments have been sold to countries.", "labels": [], "entities": [{"text": "coun.try's coalmine safety", "start_pos": 82, "end_pos": 108, "type": "DATASET", "confidence": 0.862997313340505}]}, {"text": "(8)More than 6,000 miners died in accidents in China (1) In the first eight months, the death toll of coalmine accidents across China rose 8.5 percent from the same period last year.", "labels": [], "entities": []}, {"text": "(2)China will close down a number of ill-operated coal mines at the end of this month, said a work safety official here Monday.", "labels": [], "entities": []}, {"text": "(3) Li Yizhong, director of the National Bureau of Production Safety Supervision and Administration, has said the collusion between mine owners and officials is to be condemned.", "labels": [], "entities": [{"text": "National Bureau of Production Safety Supervision and Administration", "start_pos": 32, "end_pos": 99, "type": "TASK", "confidence": 0.7294206768274307}]}, {"text": "(4)from January to September this year, 4,228 people were killed in 2,337 coalmine accidents.", "labels": [], "entities": []}, {"text": "(5) Chen said officials who refused to register their stakes in coal mines within the required time", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Comparison of Bayesian models on TAC2009", "labels": [], "entities": [{"text": "TAC2009", "start_pos": 43, "end_pos": 50, "type": "DATASET", "confidence": 0.7193155288696289}]}, {"text": " Table 3: Comparison with baselines on TAC2008", "labels": [], "entities": [{"text": "TAC2008", "start_pos": 39, "end_pos": 46, "type": "DATASET", "confidence": 0.7511940598487854}]}, {"text": " Table 4: Comparison with baselines on TAC2009", "labels": [], "entities": [{"text": "TAC2009", "start_pos": 39, "end_pos": 46, "type": "DATASET", "confidence": 0.7274339199066162}]}, {"text": " Table 5: Comparison with baselines on TAC2009", "labels": [], "entities": [{"text": "TAC2009", "start_pos": 39, "end_pos": 46, "type": "DATASET", "confidence": 0.7126471400260925}]}]}