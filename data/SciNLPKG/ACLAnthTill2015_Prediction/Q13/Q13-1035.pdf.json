{"title": [{"text": "Measuring Machine Translation Errors in New Domains", "labels": [], "entities": [{"text": "Measuring Machine Translation Errors", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7854468077421188}]}], "abstractContent": [{"text": "We develop two techniques for analyzing the effect of porting a machine translation system to anew domain.", "labels": [], "entities": [{"text": "porting a machine translation", "start_pos": 54, "end_pos": 83, "type": "TASK", "confidence": 0.6278688535094261}]}, {"text": "One is a macro-level analysis that measures how domain shift affects corpus-level evaluation; the second is a micro-level analysis for word-level errors.", "labels": [], "entities": []}, {"text": "We apply these methods to understand what happens when a Parliament-trained phrase-based machine translation system is applied in four very different domains: news, medical texts, scientific articles and movie subtitles.", "labels": [], "entities": [{"text": "Parliament-trained phrase-based machine translation", "start_pos": 57, "end_pos": 108, "type": "TASK", "confidence": 0.8046982437372208}]}, {"text": "We present quantitative and qualitative experiments that highlight opportunities for future research in domain adaptation for machine translation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 104, "end_pos": 121, "type": "TASK", "confidence": 0.7313938438892365}, {"text": "machine translation", "start_pos": 126, "end_pos": 145, "type": "TASK", "confidence": 0.7441449165344238}]}], "introductionContent": [{"text": "When building a statistical machine translation (SMT) system, the expected use case is often limited to a specific domain, genre and register (henceforth \"domain\" refers to this set, in keeping with standard, imprecise, terminology), such as a particular type of legal or medical document.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 16, "end_pos": 53, "type": "TASK", "confidence": 0.7840161373217901}]}, {"text": "Unfortunately, it is expensive to obtain enough parallel data to reliably estimate translation models in anew domain.", "labels": [], "entities": []}, {"text": "Instead, one can hope that large amounts of data from another, \"old domain,\" might be close enough to stand as a proxy.", "labels": [], "entities": []}, {"text": "This is the defacto standard: we train SMT systems on Parliament proceedings, but then use them to translate all sorts of new text.", "labels": [], "entities": [{"text": "SMT", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9876775145530701}]}, {"text": "Unfortunately, this results in significantly degraded translation quality.", "labels": [], "entities": [{"text": "translation", "start_pos": 54, "end_pos": 65, "type": "TASK", "confidence": 0.9608971476554871}]}, {"text": "In this paper, we present two complementary methods for quantifiably measuring the source of translation errors ( \u00a75.1 and \u00a75.2) in a novel taxonomy ( \u00a74).", "labels": [], "entities": []}, {"text": "We show quantitative ( \u00a77.1) and qualitative ( \u00a77.2) results obtained from our methods on Old Domain (Hansard) Inp monsieur le pr\u00e9sidentpr\u00b4pr\u00e9sident, les p \u02c6 echeurs de homard de la r \u00b4 egion de l'atlantique sont dans une situation catastrophique.", "labels": [], "entities": [{"text": "Old Domain (Hansard)", "start_pos": 90, "end_pos": 110, "type": "DATASET", "confidence": 0.8701322078704834}]}, {"text": "Ref mr. speaker, lobster fishers in atlantic canada are facing a disaster.", "labels": [], "entities": [{"text": "Ref mr. speaker", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.7162047823270162}]}, {"text": "Out mr. speaker, the lobster fishers in atlantic canada are in a mess.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct our study on French-English datasets.", "labels": [], "entities": [{"text": "French-English datasets", "start_pos": 24, "end_pos": 47, "type": "DATASET", "confidence": 0.8204101026058197}]}, {"text": "We consider five very different domains for which large corpora are publicly available.", "labels": [], "entities": []}, {"text": "The largest corpus is the Hansard parliamentary proceedings.", "labels": [], "entities": [{"text": "Hansard parliamentary proceedings", "start_pos": 26, "end_pos": 59, "type": "DATASET", "confidence": 0.9638952016830444}]}, {"text": "Corpora in the four other domains are smaller and more specialized, and, thus, more naturally serve as new domains.", "labels": [], "entities": []}, {"text": "For each new domain, we use all available data.", "labels": [], "entities": []}, {"text": "We do not attempt to hold the amount of new domain data constant, as we suspect that such artificial constraints would not be sufficient to control for the very different natures of the domains.", "labels": [], "entities": []}, {"text": "Detailed statistics for the parallel corpora are given in.", "labels": [], "entities": []}, {"text": "Hansard: Canadian parliamentary proceedings, consists of manual transcriptions and translations of meetings of Canada's House of Commons and its committees from 2001 to 2009.", "labels": [], "entities": [{"text": "Hansard", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9671986699104309}]}, {"text": "Discussions cover a wide variety of topics, and speaking styles range from prepared speeches by a single speaker to more interactive discussions.", "labels": [], "entities": []}, {"text": "It is significantly larger than Europarl, the common source of old domain data.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 32, "end_pos": 40, "type": "DATASET", "confidence": 0.9879155158996582}]}, {"text": "EMEA: Documents from the European Medicines Agency, made available with the OPUS corpora collection.", "labels": [], "entities": [{"text": "EMEA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8754755258560181}, {"text": "OPUS corpora collection", "start_pos": 76, "end_pos": 99, "type": "DATASET", "confidence": 0.9438955585161845}]}, {"text": "This corpus primarily consists of drug usage guidelines.", "labels": [], "entities": []}, {"text": "News: News commentary corpus made available for the WMT 2009 evaluation.", "labels": [], "entities": [{"text": "WMT 2009 evaluation", "start_pos": 52, "end_pos": 71, "type": "DATASET", "confidence": 0.8431760867436727}]}, {"text": "It has been commonly used in the domain adaptation literature (, for instance).", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.7158450186252594}]}, {"text": "Science: Parallel abstracts from scientific publications in many disciplines including physics, bio-433 logy, and computer science.", "labels": [], "entities": []}, {"text": "We collected data from two distinct sources: (1) Canadian Science Publishing made available translated abstracts from their journals which span many research disciplines; (2) parallel abstracts from PhD theses in Physics and Computer Science collected from the HAL public repository (.", "labels": [], "entities": [{"text": "Canadian Science Publishing", "start_pos": 49, "end_pos": 76, "type": "DATASET", "confidence": 0.96539439757665}, {"text": "HAL public repository", "start_pos": 261, "end_pos": 282, "type": "DATASET", "confidence": 0.9579988320668539}]}, {"text": "Subs: Translated movie subtitles, available through the OPUS corpora collection.", "labels": [], "entities": [{"text": "OPUS corpora collection", "start_pos": 56, "end_pos": 79, "type": "DATASET", "confidence": 0.9719337224960327}]}, {"text": "In contrast to the other domains considered, subtitles consist of informal noisy text.", "labels": [], "entities": []}, {"text": "In this study, we use the Hansard domain as the OLD domain, and we consider four possible NEW domains: EMEA, News, Science and Subs.", "labels": [], "entities": [{"text": "Hansard domain", "start_pos": 26, "end_pos": 40, "type": "DATASET", "confidence": 0.9636252224445343}, {"text": "EMEA", "start_pos": 103, "end_pos": 107, "type": "DATASET", "confidence": 0.888746976852417}, {"text": "News", "start_pos": 109, "end_pos": 113, "type": "DATASET", "confidence": 0.897935152053833}]}, {"text": "Data sets for all domains were processed consistently.", "labels": [], "entities": []}, {"text": "After tokenization, we paid particular attention to normalization in order to minimize artificial differences when combining data, such as American, British and Canadian spellings.", "labels": [], "entities": []}, {"text": "This proved particularly important for the news domain; the impact of SEEN reduced by more than half after normalization.", "labels": [], "entities": [{"text": "SEEN", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.6263319849967957}]}], "tableCaptions": []}