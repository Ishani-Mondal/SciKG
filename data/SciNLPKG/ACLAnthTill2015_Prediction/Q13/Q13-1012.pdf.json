{"title": [{"text": "Efficient Stacked Dependency Parsing by Forest Reranking", "labels": [], "entities": [{"text": "Efficient Stacked Dependency Parsing", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.4756505861878395}]}], "abstractContent": [{"text": "This paper proposes a discriminative forest reranking algorithm for dependency parsing that can be seen as a form of efficient stacked parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.8309793174266815}]}, {"text": "A dynamic programming shift-reduce parser produces a packed derivation forest which is then scored by a discrim-inative reranker, using the 1-best tree output by the shift-reduce parser as guide features in addition to third-order graph-based features.", "labels": [], "entities": []}, {"text": "To improve efficiency and accuracy, this paper also proposes a novel shift-reduce parser that eliminates the spurious ambiguity of arc-standard transition systems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9980573058128357}]}, {"text": "Testing on the English Penn Treebank data, forest reranking gave a state-of-the-art unlabeled dependency accuracy of 93.12.", "labels": [], "entities": [{"text": "English Penn Treebank data", "start_pos": 15, "end_pos": 41, "type": "DATASET", "confidence": 0.9082715064287186}, {"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.7500903606414795}]}], "introductionContent": [{"text": "There are two main approaches of data-driven dependency parsing -one is graph-based and the other is transition-based.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.7042903900146484}]}, {"text": "In the graph-based approach, global optimization algorithms find the highest-scoring tree with locally factored models ().", "labels": [], "entities": [{"text": "global optimization", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.6898749768733978}]}, {"text": "While third-order graph-based models achieve stateof-the-art accuracy, it has O(n 4 ) time complexity fora sentence of length n.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9962825179100037}, {"text": "O(n 4 ) time complexity", "start_pos": 78, "end_pos": 101, "type": "METRIC", "confidence": 0.8870460646493095}]}, {"text": "Recently, some pruning techniques have been proposed to improve the efficiency of third-order models.", "labels": [], "entities": []}, {"text": "The transition-based approach usually employs the shift-reduce parsing algorithm with linear-time complexity.", "labels": [], "entities": []}, {"text": "It greedily chooses the transition with the highest score and the resulting transition sequence is not always globally optimal.", "labels": [], "entities": []}, {"text": "The beam search algorithm improves parsing flexibility in deterministic parsing, and dynamic programming makes beam search more efficient.", "labels": [], "entities": [{"text": "beam search", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.8693288564682007}, {"text": "parsing", "start_pos": 35, "end_pos": 42, "type": "TASK", "confidence": 0.9791816473007202}, {"text": "beam search", "start_pos": 111, "end_pos": 122, "type": "TASK", "confidence": 0.8644503355026245}]}, {"text": "There is also an alternative approach that integrates graph-based and transition-based models.", "labels": [], "entities": []}, {"text": "formulated their approach as stacking of parsers where the output of the first-stage parser is provided to the second as guide features.", "labels": [], "entities": []}, {"text": "In particular, they used a transition-based parser for the first stage and a graph-based parser for the second stage.", "labels": [], "entities": []}, {"text": "The main drawback of this approach is that the efficiency of the transition-based parser is sacrificed because the second-stage employs full parsing.", "labels": [], "entities": []}, {"text": "This paper proposes an efficient stacked parsing method through discriminative reranking with higher-order graph-based features, which works on the forests output by the first-stage dynamic programming shift-reduce parser and integrates nonlocal features efficiently with cube-pruning.", "labels": [], "entities": [{"text": "stacked parsing", "start_pos": 33, "end_pos": 48, "type": "TASK", "confidence": 0.5832262635231018}]}, {"text": "The advantages of our method are as follows: \u2022 Unlike the conventional stacking approach, the first-stage shift-reduce parser prunes the search space of the second-stage graph-based parser.", "labels": [], "entities": []}, {"text": "The arc-standard transition-based dependency parsing system with dynamic programming: means \"take anything\".", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.6693345010280609}]}, {"text": "a \u21b7 b denotes that a tree b is attached to a tree a. rated in standard graph-based models.", "labels": [], "entities": []}, {"text": "\u2022 In contrast to joint transition-based/graphbased approaches) which require a large beam size and make dynamic programming impractical, our two-stage approach can integrate both models with little loss of efficiency.", "labels": [], "entities": []}, {"text": "In addition, the elimination of spurious ambiguity from the arc-standard shift-reduce parser improves the efficiency and accuracy of our approach.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9992052912712097}]}], "datasetContent": [{"text": "Non-Spurious Ambiguity) We conducted experiments on the English Penn Treebank (PTB) data to compare spurious and nonspurious shift-reduce parsers.", "labels": [], "entities": [{"text": "English Penn Treebank (PTB) data", "start_pos": 56, "end_pos": 88, "type": "DATASET", "confidence": 0.9713280711855207}]}, {"text": "We split the WSJ part of PTB into sections 02-21 for training, section 22 for development, and section 23 for test.", "labels": [], "entities": [{"text": "WSJ part of PTB", "start_pos": 13, "end_pos": 28, "type": "DATASET", "confidence": 0.753355473279953}]}, {"text": "We used the head rules ( to convert phrase structure to dependency structure.", "labels": [], "entities": []}, {"text": "141 axiom(c 0 ) : The dynamic programming arc-standard transition-based deductive system without spurious ambiguity: the symbol represents that the root node of the topmost element on the stack has not been scanned yet.: Unlabeled accuracy scores (UAS) and parsing times (+forest dumping times, second per sentence) for parsing development (WSJ22) and test (WSJ23) data with spurious shift-reduce and proposed shift-reduce parser (non-sp.) using several beam sizes.", "labels": [], "entities": [{"text": "accuracy scores (UAS)", "start_pos": 231, "end_pos": 252, "type": "METRIC", "confidence": 0.9146038293838501}, {"text": "parsing development", "start_pos": 320, "end_pos": 339, "type": "TASK", "confidence": 0.9170958995819092}, {"text": "WSJ22", "start_pos": 341, "end_pos": 346, "type": "DATASET", "confidence": 0.9060524702072144}, {"text": "WSJ23", "start_pos": 358, "end_pos": 363, "type": "DATASET", "confidence": 0.9306169152259827}]}, {"text": "We used an early update version of the averaged perceptron algorithm () to train two shift-reduce dependency parsers with beam size of 12.", "labels": [], "entities": []}, {"text": "shows experimental results of parsing the development and test datasets with each of the spurious and non-spurious shift-reduce parsers using several beam sizes.", "labels": [], "entities": [{"text": "parsing", "start_pos": 30, "end_pos": 37, "type": "TASK", "confidence": 0.9759206771850586}]}, {"text": "Parsing accuracies were evaluated by unlabeled accuracy scores (UAS) with and without punctuations.", "labels": [], "entities": [{"text": "accuracy scores (UAS)", "start_pos": 47, "end_pos": 68, "type": "METRIC", "confidence": 0.926391315460205}]}, {"text": "The parsing times were measured on an Intel Core i7 2.8GHz.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9700224995613098}]}, {"text": "parser without loss of efficiency.", "labels": [], "entities": []}, {"text": "shows oracle unlabeled accuracies of spurious k-best lists, non-spurious k-best lists, spurious forests, and non-spurious forests.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 23, "end_pos": 33, "type": "METRIC", "confidence": 0.9389317631721497}]}, {"text": "We extract an oracle tree from each packed forest using the for- est oracle algorithm.", "labels": [], "entities": []}, {"text": "Both forests produce much better results than the k-best lists, and non-spurious forests have almost the same oracle accuracies as spurious forests.", "labels": [], "entities": []}, {"text": "However, as shown in, spurious forests encode a number of non-unique dependency trees while all dependency trees in non-spurious forests are distinct from each other.", "labels": [], "entities": []}, {"text": "Following, the training set (WSJ02-21) is split into 20 folds, and each fold is parsed by each of the spurious and non-spurious shift-reduce parsers using beam size 12 with the model trained on sentences from the remaining 19 folds, dumping the outputs as packed forests.", "labels": [], "entities": [{"text": "WSJ02-21", "start_pos": 29, "end_pos": 37, "type": "DATASET", "confidence": 0.9459365606307983}]}, {"text": "The reranker is modeled by either equation or (4).", "labels": [], "entities": []}, {"text": "By our preliminary experiments using development data (WSJ22), we modeled the reranker with equation (1) when training, and with equation (4) when testing 5 (i.e., the scores of the first-stage parser are not considered during training of the reranking model).", "labels": [], "entities": [{"text": "WSJ22", "start_pos": 55, "end_pos": 60, "type": "DATASET", "confidence": 0.9391298890113831}]}, {"text": "This prevents the discriminative reranking features from under-training (.", "labels": [], "entities": []}, {"text": "A discriminative reranking model is trained on the packed forests by using the averaged perceptron algorithm with 5 iterations.", "labels": [], "entities": []}, {"text": "When training nonlocal reranking models, we set k-best size of cubepruning to 5.", "labels": [], "entities": []}, {"text": "For dumping packed forests for test data, spurious and non-spurious shift-reduce parsers are trained by the averaged perceptron algorithm.", "labels": [], "entities": []}, {"text": "In all experiments on English data, we fixed beam size to 12 for training both parsers.", "labels": [], "entities": [{"text": "English data", "start_pos": 22, "end_pos": 34, "type": "DATASET", "confidence": 0.834167093038559}]}, {"text": "We also experiment on the Penn Chinese Treebank (CTB5).", "labels": [], "entities": [{"text": "Penn Chinese Treebank (CTB5)", "start_pos": 26, "end_pos": 54, "type": "DATASET", "confidence": 0.9780054291089376}]}, {"text": "Following Huang and Sagae (2010), we split it into training (secs 001-815 and 1001-1136), development (secs 886-931 and 1148-1151), and test (secs 816-885 and 1137-1147) sets, and use the head rules of.", "labels": [], "entities": []}, {"text": "The training set is split into 10 folds to dump packed forests for training of reranking models.", "labels": [], "entities": []}, {"text": "We set the beam size of both spurious and nonspurious parsers to 12, and the number of perceptron training iterations to 25 for the parsers and to 8 for both rerankers.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Unlabeled accuracy scores (UAS) and parsing times (+forest dumping times, second per sentence) for parsing  development (WSJ22) and test (WSJ23) data with spurious shift-reduce and proposed shift-reduce parser (non-sp.)  using several beam sizes.", "labels": [], "entities": [{"text": "accuracy scores (UAS)", "start_pos": 20, "end_pos": 41, "type": "METRIC", "confidence": 0.897180187702179}, {"text": "parsing  development", "start_pos": 109, "end_pos": 129, "type": "TASK", "confidence": 0.9175240397453308}, {"text": "WSJ22", "start_pos": 131, "end_pos": 136, "type": "DATASET", "confidence": 0.8606173992156982}, {"text": "WSJ23", "start_pos": 148, "end_pos": 153, "type": "DATASET", "confidence": 0.914402425289154}]}, {"text": " Table 7: Unlabeled accuracy scores and cpu times per sentence (parsing+reranking) when parsing and reranking test  data (WSJ23) with gold POS tags: shift-reduce parser is denoted as sr (beam size, k: k-best size of cube pruning).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.8942140936851501}, {"text": "WSJ23", "start_pos": 122, "end_pos": 127, "type": "DATASET", "confidence": 0.8768358826637268}]}, {"text": " Table 4: Comparison of spurious (sp.) and non-spurious  (non-sp.) forests: each forest is produced by baseline  and proposed shift-reduce parsers using beam size 12 for  39832 training sentences with gold POS tags.", "labels": [], "entities": []}, {"text": " Table 7. Each spu- rious and non-spurious shift-reduce parser produces", "labels": [], "entities": []}, {"text": " Table 6: Comparison of spurious (sp.) and non-spurious  (non-sp.) forests: each forest is produced by baseline and  proposed shift-reduce parsers using beam size 12 for test  data (WSJ23) with gold POS tags.", "labels": [], "entities": []}, {"text": " Table 8: Comparison with other systems: the results were  evaluated on testing data (WSJ23) with automatic POS  tags: label means labeled dependency parsing and the cpu  times of our systems were taken on Intel Core i7 2.8GHz.", "labels": [], "entities": [{"text": "WSJ23", "start_pos": 86, "end_pos": 91, "type": "DATASET", "confidence": 0.7727619409561157}, {"text": "dependency parsing", "start_pos": 139, "end_pos": 157, "type": "TASK", "confidence": 0.6810834109783173}]}, {"text": " Table 9: Accuracy and the number of non-zero weighted  features of the local reranking models with and without  guide features: the first-and second-order features are  named for MSTParser.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9993155002593994}, {"text": "MSTParser", "start_pos": 180, "end_pos": 189, "type": "DATASET", "confidence": 0.9677139520645142}]}, {"text": " Table 10: Accuracy and the number of non-zero weighted  features of the non-local reranking models with and with- out guide features: the first-and second-order features are  named for MSTParser.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9993805885314941}, {"text": "MSTParser", "start_pos": 186, "end_pos": 195, "type": "DATASET", "confidence": 0.9681923389434814}]}, {"text": " Table 11: Unlabeled accuracy, root correct rate, and sen- tence complete rate: these scores are measured on test  data (WSJ23) without punctuations.", "labels": [], "entities": [{"text": "Unlabeled", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.9307522773742676}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.90410315990448}, {"text": "root correct rate", "start_pos": 31, "end_pos": 48, "type": "METRIC", "confidence": 0.8163031140963236}, {"text": "sen- tence complete rate", "start_pos": 54, "end_pos": 78, "type": "METRIC", "confidence": 0.9237059950828552}, {"text": "WSJ23", "start_pos": 121, "end_pos": 126, "type": "DATASET", "confidence": 0.8383045792579651}]}, {"text": " Table 12: Head correct rate, recall, precision, F-measure,  and complete rate of coordination strutures: these are  measured on test data (WSJ23).", "labels": [], "entities": [{"text": "Head correct rate", "start_pos": 11, "end_pos": 28, "type": "METRIC", "confidence": 0.8235795497894287}, {"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9992181062698364}, {"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9996949434280396}, {"text": "F-measure", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9981182813644409}, {"text": "complete rate", "start_pos": 65, "end_pos": 78, "type": "METRIC", "confidence": 0.9610426723957062}, {"text": "WSJ23", "start_pos": 140, "end_pos": 145, "type": "DATASET", "confidence": 0.8455648422241211}]}, {"text": " Table 13: Recall, precision, and F-measure of grand-child  structures whose grand parent is an artificial root symbol:  these are measured on test data (WSJ23).", "labels": [], "entities": [{"text": "Recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9770441651344299}, {"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9990617632865906}, {"text": "F-measure", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9996029734611511}, {"text": "WSJ23", "start_pos": 154, "end_pos": 159, "type": "DATASET", "confidence": 0.8984734416007996}]}, {"text": " Table 14: Results on Chinese Treebank data (CTB5):  evaluations are performed without punctuations.", "labels": [], "entities": [{"text": "Chinese Treebank data (CTB5)", "start_pos": 22, "end_pos": 50, "type": "DATASET", "confidence": 0.9684932231903076}]}]}