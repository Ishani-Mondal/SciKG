{"title": [{"text": "Distributional Semantics Beyond Words: Supervised Learning of Analogy and Paraphrase", "labels": [], "entities": []}], "abstractContent": [{"text": "There have been several efforts to extend distributional semantics beyond individual words, to measure the similarity of word pairs, phrases, and sentences (briefly, tuples; ordered sets of words, contiguous or noncontiguous).", "labels": [], "entities": []}, {"text": "One way to extend beyond words is to compare two tuples using a function that combines pairwise similarities between the component words in the tuples.", "labels": [], "entities": []}, {"text": "A strength of this approach is that it works with both rela-tional similarity (analogy) and compositional similarity (paraphrase).", "labels": [], "entities": []}, {"text": "However, past work required hand-coding the combination function for different tasks.", "labels": [], "entities": []}, {"text": "The main contribution of this paper is that combination functions are generated by supervised learning.", "labels": [], "entities": []}, {"text": "We achieve state-of-the-art results in measuring relational similarity between word pairs (SAT analogies and SemEval 2012 Task 2) and measuring compositional similarity between noun-modifier phrases and unigrams (multiple-choice paraphrase questions).", "labels": [], "entities": [{"text": "SemEval 2012 Task", "start_pos": 109, "end_pos": 126, "type": "TASK", "confidence": 0.7081299821535746}]}], "introductionContent": [{"text": "Harris and hypothesized that words that appear in similar contexts tend to have similar meanings.", "labels": [], "entities": []}, {"text": "This hypothesis is the foundation for distributional semantics, in which words are represented by context vectors.", "labels": [], "entities": []}, {"text": "The similarity of two words is calculated by comparing the two corresponding context vectors (.", "labels": [], "entities": []}, {"text": "Distributional semantics is highly effective for measuring the semantic similarity between individual words.", "labels": [], "entities": []}, {"text": "On a set of eighty multiple-choice synonym questions from the test of English as a foreign language (TOEFL), a distributional approach recently achieved 100% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.9986222982406616}]}, {"text": "However, it has been difficult to extend distributional semantics beyond individual words, to word pairs, phrases, and sentences.", "labels": [], "entities": []}, {"text": "Moving beyond individual words, there are various types of semantic similarity to consider.", "labels": [], "entities": []}, {"text": "Here we focus on paraphrase and analogy.", "labels": [], "entities": []}, {"text": "Paraphrase is similarity in the meaning of two pieces of text.", "labels": [], "entities": [{"text": "Paraphrase", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9722116589546204}]}, {"text": "Analogy is similarity in the semantic relations of two sets of words.", "labels": [], "entities": []}, {"text": "It is common to study paraphrase at the sentence level), but we prefer to concentrate on the simplest type of paraphrase, where a bigram paraphrases a unigram.", "labels": [], "entities": []}, {"text": "For example, doghouse is a paraphrase of kennel.", "labels": [], "entities": []}, {"text": "In our experiments, we concentrate on noun-modifier bigrams and noun unigrams.", "labels": [], "entities": []}, {"text": "Analogies map terms in one domain to terms in another domain.", "labels": [], "entities": []}, {"text": "The familiar analogy between the solar system and the RutherfordBohr atomic model involves several terms from the domain of the solar system and the domain of the atomic model.", "labels": [], "entities": [{"text": "RutherfordBohr atomic model", "start_pos": 54, "end_pos": 81, "type": "DATASET", "confidence": 0.9300908446311951}]}, {"text": "The simplest type of analogy is proportional analogy, which involves two pairs of words).", "labels": [], "entities": [{"text": "proportional analogy", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.7122936844825745}]}, {"text": "For example, the pair cook, raw is analogous to the pair decorate, plain.", "labels": [], "entities": []}, {"text": "If we cook a thing, it is no longer raw; if we decorate a thing, it is no longer plain.", "labels": [], "entities": []}, {"text": "The semantic relations between cook and raw are similar to the semantic relations between decorate and plain.", "labels": [], "entities": []}, {"text": "In the following experiments, we focus on proportional analogies.", "labels": [], "entities": []}, {"text": "distinguished four approaches to extend distributional semantics beyond words: In the first, a single vector space representation fora phrase or sentence is computed from the representations of the individual words.", "labels": [], "entities": []}, {"text": "In the second, two phrases or sentences are compared by combining multiple pairwise similarity values.", "labels": [], "entities": []}, {"text": "Third, weighted inference rules integrate distributional similarity and formal logic ().", "labels": [], "entities": []}, {"text": "Fourth, a single space integrates formal logic and vectors.", "labels": [], "entities": []}, {"text": "Taking the second approach, Turney (2012) introduced a dual-space model, with one space for measuring domain similarity (similarity of topic or field) and another for function similarity (similarity of role or usage).", "labels": [], "entities": []}, {"text": "Similarities beyond individual words are calculated by functions that combine domain and function similarities of component words.", "labels": [], "entities": []}, {"text": "The dual-space model has been applied to measuring compositional similarity (paraphrase recognition) and relational similarity (analogy recognition).", "labels": [], "entities": [{"text": "paraphrase recognition", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.7402993738651276}, {"text": "analogy recognition", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.7097311615943909}]}, {"text": "In experiments that tested for sensitivity to word order, the dual-space model performed significantly better than competing approaches . A limitation of past work with the dual-space model is that the combination functions were handcoded.", "labels": [], "entities": []}, {"text": "Our main contribution is to show how handcoding can be eliminated with supervised learning.", "labels": [], "entities": []}, {"text": "For ease of reference, we will call our approach SuperSim (supervised similarity).", "labels": [], "entities": []}, {"text": "With no modification of SuperSim for the specific task (relational similarity or compositional similarity), we achieve better results than previous hand-coded models.", "labels": [], "entities": []}, {"text": "Compositional similarity (paraphrase) compares two contiguous phrases or sentences (n-grams), whereas relational similarity (analogy) does not require contiguity.", "labels": [], "entities": []}, {"text": "We use tuple to refer to both contiguous and noncontiguous word sequences.", "labels": [], "entities": []}, {"text": "We approach analogy as a problem of supervised tuple classification.", "labels": [], "entities": [{"text": "supervised tuple classification", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.7107439637184143}]}, {"text": "To measure the relational similarity between two word pairs, we train SuperSim with quadruples that are labeled as positive and negative examples of analogies.", "labels": [], "entities": []}, {"text": "For example, the proportional analogy cook, raw, decorate, plain is labeled as a positive example.", "labels": [], "entities": []}, {"text": "A quadruple is represented by a feature vector, composed of domain and function similarities from the dual-space model and other features based on corpus frequencies.", "labels": [], "entities": []}, {"text": "SuperSim uses a support vector machine to learn the probability that a quadruple a, b, c, d consists of a word pair a, band an analogous word pair c, d.", "labels": [], "entities": []}, {"text": "The probability can be interpreted as the degree of relational similarity between the two given word pairs.", "labels": [], "entities": []}, {"text": "We also approach paraphrase as supervised tuple classification.", "labels": [], "entities": [{"text": "supervised tuple classification", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.6836816569169363}]}, {"text": "To measure the compositional similarity beween an m-gram and an n-gram, we train the learning algorithm with (m + n)-tuples that are positive and negative examples of paraphrases.", "labels": [], "entities": []}, {"text": "SuperSim learns to estimate the probability that a triple a, b, c consists of a compositional bigram ab and a synonymous unigram c.", "labels": [], "entities": []}, {"text": "For instance, the phrase fish tank is synonymous with aquarium; that is, fish tank and aquarium have high compositional similarity.", "labels": [], "entities": []}, {"text": "The triple fish, tank, aquarium is represented using the same features that we used for analogy.", "labels": [], "entities": []}, {"text": "The probability of the triple can be interpreted as the degree of compositional similarity between the given bigram and unigram.", "labels": [], "entities": []}, {"text": "We review related work in Section 2.", "labels": [], "entities": []}, {"text": "The general feature space for learning relations and compositions is presented in Section 3.", "labels": [], "entities": []}, {"text": "The experiments with relational similarity are described in Section 4, and Section 5 reports the results with compositional similarity.", "labels": [], "entities": []}, {"text": "Section 6 discusses the implications of the results.", "labels": [], "entities": []}, {"text": "We consider future work in Section 7 and conclude in Section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "Since the PPMI features play an important role in answering the noun-modifier questions, let us take The results for SuperSim are new but the other results in   a closer look at them.", "labels": [], "entities": []}, {"text": "From, we see that there are twelve PPMI features for the triple a, b, c, where ab is a noun-modifier bigram and c is a noun unigram.", "labels": [], "entities": []}, {"text": "We can split the twelve features into three subsets, one subset for each pair of words, a, b, a, c, and b, c.", "labels": [], "entities": []}, {"text": "For example, the subset fora, b is the four features PPMI(a, b, left), PPMI(b, a, left), PPMI(a, b, right), and PPMI(b, a, right).", "labels": [], "entities": []}, {"text": "shows the effects of ablating these subsets.", "labels": [], "entities": []}, {"text": "The results in indicate that all three PPMI subsets contribute to the performance of SuperSim, but the a, b subset contributes more than the other two subsets.", "labels": [], "entities": []}, {"text": "Thea, b features help to increase the sensitivity of SuperSim to the order of the words in the noun-modifier bigram; for example, they make it easier to distinguish fantasy world from world fantasy.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Number of features for various tuple sizes.", "labels": [], "entities": []}, {"text": " Table 4: The top ten results on five-choice SAT questions.", "labels": [], "entities": []}, {"text": " Table 5: Feature ablation with ten-choice SAT questions.", "labels": [], "entities": []}, {"text": " Table 6: Spearman correlations for SemEval 2012 Task 2.", "labels": [], "entities": [{"text": "SemEval 2012 Task 2", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.8851358294487}]}, {"text": " Table 8: Results for the two noun-modifier datasets.", "labels": [], "entities": []}, {"text": " Table 9: Ablation with fourteen-choice questions.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.8014922738075256}]}, {"text": " Table 10: PPMI subset ablation with fourteen-choices.", "labels": [], "entities": []}, {"text": " Table 11: A question based on holistic vectors.", "labels": [], "entities": []}]}