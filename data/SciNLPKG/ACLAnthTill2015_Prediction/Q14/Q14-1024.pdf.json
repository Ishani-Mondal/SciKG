{"title": [{"text": "Exploiting Social Network Structure for Person-to-Person Sentiment Analysis", "labels": [], "entities": [{"text": "Person-to-Person Sentiment Analysis", "start_pos": 40, "end_pos": 75, "type": "TASK", "confidence": 0.7282713850339254}]}], "abstractContent": [{"text": "Person-to-person evaluations are prevalent in all kinds of discourse and important for establishing reputations, building social bonds, and shaping public opinion.", "labels": [], "entities": []}, {"text": "Such evaluations can be analyzed separately using signed social networks and textual sentiment analysis, but this misses the rich interactions between language and social context.", "labels": [], "entities": [{"text": "textual sentiment analysis", "start_pos": 77, "end_pos": 103, "type": "TASK", "confidence": 0.7379550635814667}]}, {"text": "To capture such interactions, we develop a model that predicts individual A's opinion of individual B by synthesizing information from the signed social network in which A and B are embedded with sentiment analysis of the evaluative texts relating A to B.", "labels": [], "entities": []}, {"text": "We prove that this problem is NP-hard but can be relaxed to an efficiently solvable hinge-loss Markov random field, and we show that this implementation outperforms text-only and network-only versions in two very different datasets involving community-level decision-making: the Wiki-pedia Requests for Adminship corpus and the Convote U.S. Congressional speech corpus.", "labels": [], "entities": [{"text": "Convote U.S. Congressional speech corpus", "start_pos": 328, "end_pos": 368, "type": "DATASET", "confidence": 0.8379256844520568}]}], "introductionContent": [{"text": "People's evaluations of one another are prevalent in all kinds of discourse, public and private, across ages, genders, cultures, and social classes).", "labels": [], "entities": []}, {"text": "Such opinions matter for establishing reputations and reinforcing social bonds, and they are especially consequential in political contexts, where they take the form of endorsements, accusations, and assessments intended to sway public opinion.", "labels": [], "entities": []}, {"text": "The significance of such person-to-person evaluations means that there is a pressing need for computational models and technologies that can analyze them.", "labels": [], "entities": []}, {"text": "Research on signed social networks suggests one path forward: how one person will evaluate another can often be predicted from the network they are embedded in.", "labels": [], "entities": []}, {"text": "Linguistic sentiment analysis suggests another path forward: one could leverage textual features to predict the valence of evaluative texts describing people.", "labels": [], "entities": [{"text": "Linguistic sentiment analysis", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8427285949389139}]}, {"text": "Such independent efforts have been successful, but they generally neglect the ways in which social and linguistic features complement each other.", "labels": [], "entities": []}, {"text": "In some settings, textual data is sparse but the network structure is largely observed; in others, text is abundant but the network is partly or unreliably recorded.", "labels": [], "entities": []}, {"text": "In addition, we often see rich interactions between the two kinds of informationpolitical allies might tease each other with negative language to enhance social bonds, and opponents often use sarcastically positive language in their criticisms.", "labels": [], "entities": []}, {"text": "Separate sentiment or signed-network models will miss or misread these signals.", "labels": [], "entities": []}, {"text": "We develop 3) a graphical model that synthesizes network and linguistic information to make more and better predictions about both.", "labels": [], "entities": []}, {"text": "The objective of the model is to predict A's opinion of B using a synthesis of the structural context around A and B inside the social network and sentiment analysis of the evaluative texts relating A to B.", "labels": [], "entities": []}, {"text": "We prove that the problem is NP-hard but that it can be relaxed to an efficiently solvable hinge-loss Markov random field, and we show that this implementation outperforms text-only and networkonly versions in two very different datasets involving community-level decision-making: the Wikipedia Requests for Adminship corpus, in which Wikipedia editors discuss and vote on who should be promoted within the Wikipedia hierarchy, and the Convote U.S. Congressional speech corpus (), in which elected officials discuss political topics (Sec. 5).", "labels": [], "entities": [{"text": "Convote U.S. Congressional speech corpus", "start_pos": 436, "end_pos": 476, "type": "DATASET", "confidence": 0.571448290348053}]}, {"text": "These corpora differ dramatically in size, in the style and quality of their textual data, and in the structure and observability of their networks.", "labels": [], "entities": []}, {"text": "Together, they provide a clear picture of how joint models of text and network structure can excel where their component parts cannot.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our first set of experiments is conducted on the Wikipedia Requests for Adminship corpus, which allows us to evaluate our model's ability to predict person-to-person evaluations in Web texts that are informal but pertain to important social outcomes.", "labels": [], "entities": [{"text": "Wikipedia Requests for Adminship corpus", "start_pos": 49, "end_pos": 88, "type": "DATASET", "confidence": 0.7091681718826294}]}, {"text": "The 'Convote' corpus of Congressional speeches () consists of 3,857 speech segments drawn from 53 debates from the U.S. House of Representatives in 2005.", "labels": [], "entities": [{"text": "Convote' corpus of Congressional speeches", "start_pos": 5, "end_pos": 46, "type": "DATASET", "confidence": 0.7913195093472799}]}, {"text": "There is a mean of 72.8 speech segments per debate and 32.1 speakers per debate.", "labels": [], "entities": []}, {"text": "Segments are annotated with the speaker, their party affiliation, the bill discussed, and how the speaker voted on that bill (positive or negative). and others represent this corpus as a bipartite person-item graph with signed edges from Congresspeople to the bills (items) they spoke about, and they add additional person-person edges encoding who mentioned whom in the speech segments.", "labels": [], "entities": []}, {"text": "We take a different perspective, extracting from it a dense, undirected person-person graph by linking two Congresspeople if they ever voted on the same bill, labeling the edge as positive if they cast the same vote at least half of the time.", "labels": [], "entities": []}, {"text": "We directly use the sentiment model trained by Thomas et al.", "labels": [], "entities": []}, {"text": "The resulting graph has 276 nodes, 14,690 edges (54% positive), and 506,327 triangles.", "labels": [], "entities": []}, {"text": "We split the network G = (V, E) into 5 folds using the 'random sampling' technique described in Sec.", "labels": [], "entities": []}, {"text": "3.4 and: the set of nodes V is fixed across all folds, and the set of edges E is partitioned randomly so that each fold has 20% of all edges.", "labels": [], "entities": []}, {"text": "In the full graph, there is one clique per debate, so each fold contains the overlay of several subgraphs, one per debate and each 20% complete on average.", "labels": [], "entities": []}, {"text": "Here, random sampling was used because the alternative ('BFS sampling' in) would produce nearly complete subgraphs, on which we found the prediction task to be overly easy (since the problem becomes more constrained; Sec. 5.3).", "labels": [], "entities": []}, {"text": "We compare the three models also used on the Wikipedia dataset (Sec. 4.2).", "labels": [], "entities": [{"text": "Wikipedia dataset", "start_pos": 45, "end_pos": 62, "type": "DATASET", "confidence": 0.9709078967571259}]}, {"text": "Our sentiment model comes right out of the box with the Convote corpus: distribute the text-level scores from their SVM classifier with the corpus, so we simply work with those, after transforming them into probabilities via logistic regression (a standard technique called Platt scaling).", "labels": [], "entities": [{"text": "Convote corpus", "start_pos": 56, "end_pos": 70, "type": "DATASET", "confidence": 0.8926940262317657}]}, {"text": "Thus, let q u and q v be the probabilistic sentiment predictions for u and v on a given bill.", "labels": [], "entities": []}, {"text": "The probability that u and v agree on the bill is q u q v + (1 \u2212 q u )(1 \u2212 q v ), and we define the probability p e of a positive sign on the edge e = {u, v} as the average agreement probability overall bills that u and v co-voted on.", "labels": [], "entities": []}, {"text": "For instance, the speech containing the sentence, 'Mr. Speaker, I do rise today in strong support of H.R.", "labels": [], "entities": []}, {"text": "810,' receives a probability of 98% of expressing a positive opinion on H.R.", "labels": [], "entities": []}, {"text": "(i.e., House of Representatives) bill 810, whereas the prediction for the speech containing the words, 'Therefore, I urge my colleagues to vote against both H.R.", "labels": [], "entities": []}, {"text": "810 and H.R. 2520,' is only 1%.", "labels": [], "entities": [{"text": "H.R. 2520", "start_pos": 8, "end_pos": 17, "type": "DATASET", "confidence": 0.9164387285709381}]}, {"text": "Hence, the edge between the two respective speakers has a probability of 98% \u00d7 1% + 2% \u00d7 99% = 3% of being positive.", "labels": [], "entities": []}, {"text": "As in the Wikipedia experiments, we report AUCs as a function of the evidence ratio.", "labels": [], "entities": []}, {"text": "The sentiment model alone (yellow) achieves an AUC/ROC (AUC/negPR) of 0.65 (0.62), well above the random baselines at 0.5 (0.46).", "labels": [], "entities": [{"text": "AUC/ROC (AUC/negPR)", "start_pos": 47, "end_pos": 66, "type": "METRIC", "confidence": 0.8520292192697525}]}, {"text": "The network-only model (blue) performs much worse at the start, but it surpasses the sentiment model even with just 12.5% of the edges as evidence, a reflection of the dense, high-quality network structure with many triangles.", "labels": [], "entities": []}, {"text": "When we combine the sentiment and network models (black), we consistently seethe best results, with the largest gains in the realistic scenario where there is little evidence.", "labels": [], "entities": []}, {"text": "We now evaluate our model in a setting in which the linguistic person-to-person evaluations are less direct and reliable than in the RfA corpus but the signed network is considerably denser.", "labels": [], "entities": [{"text": "RfA corpus", "start_pos": 133, "end_pos": 143, "type": "DATASET", "confidence": 0.8735171258449554}]}], "tableCaptions": []}