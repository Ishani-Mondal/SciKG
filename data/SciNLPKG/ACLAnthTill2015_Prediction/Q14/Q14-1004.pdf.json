{"title": [{"text": "A Crossing-Sensitive Third-Order Factorization for Dependency Parsing", "labels": [], "entities": [{"text": "Dependency Parsing", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.803091436624527}]}], "abstractContent": [{"text": "Parsers that parametrize over wider scopes are generally more accurate than edge-factored models.", "labels": [], "entities": []}, {"text": "For graph-based non-projective parsers, wider factorizations have so far implied large increases in the computational complexity of the parsing problem.", "labels": [], "entities": [{"text": "parsing problem", "start_pos": 136, "end_pos": 151, "type": "TASK", "confidence": 0.928732305765152}]}, {"text": "This paper introduces a \"crossing-sensitive\" generalization of a third-order factorization that trades off complexity in the model structure (i.e., scoring with features over multiple edges) with complexity in the output structure (i.e., producing crossing edges).", "labels": [], "entities": []}, {"text": "Under this model, the optimal 1-Endpoint-Crossing tree can be found in O(n 4) time, matching the asymp-totic run-time of both the third-order projec-tive parser and the edge-factored 1-Endpoint-Crossing parser.", "labels": [], "entities": []}, {"text": "The crossing-sensitive third-order parser is significantly more accurate than the third-order projective parser under many experimental settings and significantly less accurate on none.", "labels": [], "entities": []}], "introductionContent": [{"text": "Conditioning on wider syntactic contexts than simply individual head-modifier relationships improves parsing accuracy in a wide variety of parsers and frameworks.", "labels": [], "entities": [{"text": "parsing", "start_pos": 101, "end_pos": 108, "type": "TASK", "confidence": 0.9710918664932251}, {"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9556694030761719}]}, {"text": "This paper proposes anew graphbased dependency parser that efficiently produces * The majority of this work was done while at the University of Pennsylvania.", "labels": [], "entities": []}, {"text": "the globally optimal dependency tree according to a third-order model (that includes features over grandparents and siblings in the tree) in the class of 1-Endpoint-Crossing trees (that includes all projective trees and the vast majority of non-projective structures seen in dependency treebanks).", "labels": [], "entities": []}, {"text": "Within graph-based projective parsing, the thirdorder parser of  has a runtime of O(n 4 ), just one factor of n more expensive than the edge-factored model of.", "labels": [], "entities": [{"text": "graph-based projective parsing", "start_pos": 7, "end_pos": 37, "type": "TASK", "confidence": 0.6428742607434591}, {"text": "O", "start_pos": 82, "end_pos": 83, "type": "METRIC", "confidence": 0.9843237996101379}]}, {"text": "Incorporating richer features and producing trees with crossing edges has traditionally been a challenge, however, for graph-based dependency parsers.", "labels": [], "entities": []}, {"text": "If parsing is posed as the problem of finding the optimal scoring directed spanning tree, then the problem becomes NP-hard when trees are scored with a grandparent and/or sibling factorization.", "labels": [], "entities": [{"text": "parsing", "start_pos": 3, "end_pos": 10, "type": "TASK", "confidence": 0.9827178120613098}]}, {"text": "For various definitions of mildly non-projective trees, even edge-factored versions are expensive, with edge-factored running times between O(n 4 ) and O(n 7 ) ().", "labels": [], "entities": []}, {"text": "The third-order projective parser of  and the edge-factored 1-EndpointCrossing parser described in have some similarities: both use O(n 4 ) time and O(n 3 ) space, using sub-problems over intervals with one exterior vertex, which are constructed using one free split point.", "labels": [], "entities": []}, {"text": "The two parsers differ in how the exterior vertex is used:  use the exterior vertex to store a grandparent index, while use the exterior vertex to introduce crossed edges between the point and  the interval.", "labels": [], "entities": []}, {"text": "This paper proposes merging the two parsers to achieve the best of both worlds -producing the best tree in the wider range of 1-EndpointCrossing trees while incorporating the identity of the grandparent and/or sibling of the child in the score of an edge whenever the local neighborhood of the edge does not contain crossing edges.", "labels": [], "entities": []}, {"text": "The crossing-sensitive grandparent-sibling 1-EndpointCrossing parser proposed here takes O(n 4 ) time, matching the runtime of both the third-order projective parser and of the edge-factored 1-EndpointCrossing parser (see).", "labels": [], "entities": [{"text": "O", "start_pos": 89, "end_pos": 90, "type": "METRIC", "confidence": 0.9777238965034485}]}, {"text": "The parsing algorithms of  and are reviewed in Section 2.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9726072549819946}]}, {"text": "The proposed crossing-sensitive factorization is defined in Section 3.", "labels": [], "entities": []}, {"text": "The parsing algorithm that finds the optimal 1-Endpoint-Crossing tree according to this factorization is described in Section 4.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9658496379852295}]}, {"text": "The implemented parser is significantly more accurate than the third-order projective parser in a variety of languages and treebank representations (Section 5).", "labels": [], "entities": []}, {"text": "Section 6 discusses the proposed approach in the context of prior work on non-projective parsing.", "labels": [], "entities": [{"text": "non-projective parsing", "start_pos": 74, "end_pos": 96, "type": "TASK", "confidence": 0.6528281420469284}]}], "datasetContent": [{"text": "The crossing-sensitive third-order parser was implemented as an alternative parsing algorithm within dpo3 ( . To ensure a fair comparison, all code relating to input/output, features, learning, etc. was re-used from the original projective implementation, and so the only substantive differences between the projective and 1-Endpoint-Crossing parsers are the dynamic programming charts, the parsing algorithms, and the routines that extract the maximum scoring tree from the completed chart.", "labels": [], "entities": []}, {"text": "The treebanks used to prepare the CoNLL shared task data () vary widely in their conventions for representing conjunctions, modal verbs, determiners, and other decisions (.", "labels": [], "entities": [{"text": "CoNLL shared task data", "start_pos": 34, "end_pos": 56, "type": "DATASET", "confidence": 0.7787773907184601}]}, {"text": "The experiments use the newly released HamleDT software () that normalizes these treebanks into one standard format and also provides built-in transformations to other conjunction styles.", "labels": [], "entities": [{"text": "HamleDT", "start_pos": 39, "end_pos": 46, "type": "DATASET", "confidence": 0.8887466788291931}]}, {"text": "The unnormalized treebanks input to HamleDT were from the CoNLL 2006 Shared Task () for Danish, Dutch, Portuguese, and Swedish and from the) for Czech.", "labels": [], "entities": [{"text": "HamleDT", "start_pos": 36, "end_pos": 43, "type": "DATASET", "confidence": 0.8561100363731384}, {"text": "CoNLL 2006 Shared Task", "start_pos": 58, "end_pos": 80, "type": "DATASET", "confidence": 0.88198122382164}]}, {"text": "The experiments include the default Prague style), Mel'\u02c7 cukian style, and Stanford style) for conjunctions.", "labels": [], "entities": []}, {"text": "Under the grandparent-sibling factorization, the two words being conjoined would never appear in the same scope for the Prague style (as they are siblings on different sides of the conjunct head).", "labels": [], "entities": []}, {"text": "In the Mel'\u02c7 cukian style, the two conjuncts are in a grandparent relationship and in the Stanford style the two conjuncts are in a sibling relationship, and so we would expect to see larger gains for including grandparents and siblings under the latter two representations.", "labels": [], "entities": []}, {"text": "The experiments also include a nearly projective dataset, the English Penn Treebank (, converted to dependencies with PennConverter.", "labels": [], "entities": [{"text": "English Penn Treebank", "start_pos": 62, "end_pos": 83, "type": "DATASET", "confidence": 0.8844982385635376}, {"text": "PennConverter", "start_pos": 118, "end_pos": 131, "type": "DATASET", "confidence": 0.9898486733436584}]}, {"text": "The experiments use marginal-based pruning based on an edge-factored directed spanning tree model).", "labels": [], "entities": []}, {"text": "Each word's set of potential parents is limited to those with a marginal probability of at least .1 times the probability of the most probable parent, and cutoff this list at a maximum of 20 potential parents per word.", "labels": [], "entities": []}, {"text": "To ensure that there is always at least one projective and/or 1-Endpoint-Crossing tree achievable, the artificial root is always included as an option.", "labels": [], "entities": []}, {"text": "The pruning parameters were chosen to keep 99.9% of the true edges on the English development set.", "labels": [], "entities": [{"text": "English development set", "start_pos": 74, "end_pos": 97, "type": "DATASET", "confidence": 0.9105377197265625}]}, {"text": "Following and , before training the training set trees are transformed to be the best achievable within the model class (i.e., the closest projective tree or 1-Endpoint-Crossing tree).", "labels": [], "entities": []}, {"text": "All models are trained for five iterations of averaged structured perceptron training.", "labels": [], "entities": []}, {"text": "For English, the model after the iteration that performs best on the development set is used; for all other languages, the model after the fifth iteration is used.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Overall Unlabeled Attachment Scores (UAS) for  all words. 3 CS-GSib is the proposed crossing-sensitive  grandparent-sibling factorization. For each data set, we  bold the most accurate model and those not significantly  different from the most accurate (sign test, p < .05). Lan- guages are sorted in increasing order of projectivity.", "labels": [], "entities": [{"text": "Overall Unlabeled Attachment Scores (UAS)", "start_pos": 10, "end_pos": 51, "type": "METRIC", "confidence": 0.6957139202526638}]}, {"text": " Table 6: The proportion of edges in the predicted output  trees from the CS-GSib 1-Endpoint-Crossing parser that  would have used each of the five part types for scoring.", "labels": [], "entities": []}]}