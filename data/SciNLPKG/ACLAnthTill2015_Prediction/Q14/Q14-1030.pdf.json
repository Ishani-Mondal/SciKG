{"title": [{"text": "Large-scale Semantic Parsing without Question-Answer Pairs", "labels": [], "entities": [{"text": "Semantic Parsing without Question-Answer Pairs", "start_pos": 12, "end_pos": 58, "type": "TASK", "confidence": 0.8193104147911072}]}], "abstractContent": [{"text": "In this paper we introduce a novel semantic parsing approach to query Freebase in natural language without requiring manual annotations or question-answer pairs.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 35, "end_pos": 51, "type": "TASK", "confidence": 0.7557346522808075}]}, {"text": "Our key insight is to represent natural language via semantic graphs whose topology shares many commonalities with Freebase.", "labels": [], "entities": []}, {"text": "Given this representation , we conceptualize semantic parsing as a graph matching problem.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 45, "end_pos": 61, "type": "TASK", "confidence": 0.7718347907066345}]}, {"text": "Our model converts sentences to semantic graphs using CCG and subsequently grounds them to Free-base guided by denotations as a form of weak supervision.", "labels": [], "entities": []}, {"text": "Evaluation experiments on a subset of the FREE917 and WEBQUESTIONS benchmark datasets show our semantic parser improves over the state of the art.", "labels": [], "entities": [{"text": "FREE917", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.5390287041664124}, {"text": "WEBQUESTIONS benchmark datasets", "start_pos": 54, "end_pos": 85, "type": "DATASET", "confidence": 0.8605082233746847}]}], "introductionContent": [{"text": "Querying a database to retrieve an answer, telling a robot to perform an action, or teaching a computer to play a game are tasks requiring communication with machines in a language interpretable by them.", "labels": [], "entities": []}, {"text": "Semantic parsing addresses the specific task of learning to map natural language (NL) to machine interpretable formal meaning representations.", "labels": [], "entities": [{"text": "Semantic parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8334302008152008}, {"text": "map natural language (NL) to machine interpretable formal meaning representations", "start_pos": 60, "end_pos": 141, "type": "TASK", "confidence": 0.7000388726592064}]}, {"text": "Traditionally, sentences are converted into logical form grounded in the symbols of some fixed ontology or relational database.", "labels": [], "entities": []}, {"text": "Approaches for learning semantic parsers have been for the most part supervised, using annotated training data consisting of sentences and their corresponding logical forms (.", "labels": [], "entities": [{"text": "learning semantic parsers", "start_pos": 15, "end_pos": 40, "type": "TASK", "confidence": 0.6567038794358572}]}, {"text": "More recently, alternative forms of supervision have been proposed to alleviate the annotation burden, e.g., by learning from conversational logs (, from sentences paired with system behavior ( What is the capital of Texas?", "labels": [], "entities": []}, {"text": "Logical Form \u03bbx. city(x) \u2227 capital(x, Texas) Answer {Austin}: An example question with annotated logical query, and its answer.", "labels": [], "entities": [{"text": "Answer", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9453771114349365}]}, {"text": "2011;, via distant supervision (, from questions (, and questionanswer pairs.", "labels": [], "entities": []}, {"text": "Indeed, methods which learn from question-answer pairs have been gaining momentum as a means of scaling semantic parsers to large, open-domain problems ().", "labels": [], "entities": []}, {"text": "shows an example of a question, its annotated logical form, and answer (or denotation).", "labels": [], "entities": [{"text": "answer", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9660653471946716}]}, {"text": "In this paper, we build a semantic parser that does not require example annotations or question-answer pairs but instead learns from a large knowledge base (KB) and web-scale corpora.", "labels": [], "entities": []}, {"text": "Specifically, we exploit Freebase, a large community-authored knowledge base that spans many sub-domains and stores real world facts in graphical format, and parsed sentences from a large corpus.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 25, "end_pos": 33, "type": "DATASET", "confidence": 0.9469148516654968}]}, {"text": "We formulate semantic parsing as a graph matching problem.", "labels": [], "entities": [{"text": "formulate semantic parsing", "start_pos": 3, "end_pos": 29, "type": "TASK", "confidence": 0.920861820379893}]}, {"text": "We convert the output of an open-domain combinatory categorial grammar (CCG) parser) into a graphical representation and subsequently map it onto Freebase.", "labels": [], "entities": []}, {"text": "The parser's graphs (also called ungrounded graphs) are mapped to all possible Freebase subgraphs (also called grounded graphs) by replacing edges and nodes with relations and types in Freebase.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 185, "end_pos": 193, "type": "DATASET", "confidence": 0.9450334906578064}]}, {"text": "Each grounded graph corresponds to a unique grounded logical query.", "labels": [], "entities": []}, {"text": "During learning, our semantic parser is trained to identify which KB subgraph best corresponds to the NL graph.", "labels": [], "entities": []}, {"text": "Problem-capital(Austin) \u2227 UNIQUE(Austin) \u2227 capital.of.arg1(e, Austin) \u2227 capital.of.arg2(e, Texas) (a) Semantic parse of the sentence Austin is the capital of Texas.", "labels": [], "entities": []}, {"text": "atically, ungrounded graphs may give rise to many grounded graphs.", "labels": [], "entities": []}, {"text": "Since we do not make use of manual annotations of sentences or question-answer pairs, we do not know which grounded graphs are correct.", "labels": [], "entities": []}, {"text": "To overcome this, we rely on comparisons between denotations of natural language queries and related Freebase queries as a form of weak supervision in order to learn the mapping between NL and KB graphs.", "labels": [], "entities": []}, {"text": "illustrates our approach for the sentence Austin is the capital of Texas.", "labels": [], "entities": []}, {"text": "From the CCG syntactic derivation (which we omit here for the sake of brevity) we obtain a semantic parse) and convert it to an ungrounded graph).", "labels": [], "entities": []}, {"text": "Next, we select an entity from the graph and replace it with a variable x, creating a graph corresponding to the query What is the capital of Texas?).", "labels": [], "entities": []}, {"text": "The math function UNIQUE on Austin in indicates Austin is the only value of x which can satisfy the query graph in.", "labels": [], "entities": [{"text": "UNIQUE", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.8530650734901428}]}, {"text": "Therefore, the denotation 1 of the NL query graph is {AUSTIN}.", "labels": [], "entities": [{"text": "AUSTIN", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9598966836929321}]}, {"text": "shows two different groundings of the query graph in the Freebase KB.", "labels": [], "entities": [{"text": "Freebase KB", "start_pos": 57, "end_pos": 68, "type": "DATASET", "confidence": 0.9783238768577576}]}, {"text": "We obtain these by replacing edges and nodes in the query graph with Freebase relations and types.", "labels": [], "entities": []}, {"text": "We use the denotation of the NL query as a form of weak supervision to select the best grounded graph.", "labels": [], "entities": []}, {"text": "Under the constraint that the denotation of a Freebase query should be the same as the denotation of the NL query, the graph on the left hand-side of is chosen as the correct grounding.", "labels": [], "entities": []}, {"text": "Experimental results on two benchmark datasets consisting of questions to Freebase -FREE917) and WEBQUESTIONS -show that our semantic parser improves over state-of-the-art approaches.", "labels": [], "entities": [{"text": "Freebase -FREE917", "start_pos": 74, "end_pos": 91, "type": "DATASET", "confidence": 0.6596597830454508}, {"text": "WEBQUESTIONS -", "start_pos": 97, "end_pos": 111, "type": "METRIC", "confidence": 0.9436902105808258}]}, {"text": "Our contributions include: a novel graph-based method to convert natural language sentences to grounded semantic parses which exploits the similarities in the topology of knowledge graphs and linguistic structure, together with the ability to train using a wide range of features; a proposal to learn from a large scale web corpus, without question-answer pairs, based on denotations of queries from natural language statements as weak supervision; and the development of a scalable semantic parser which besides Freebase uses CLUEWEB09 for training, a corpus of 503.9 million webpages.", "labels": [], "entities": [{"text": "convert natural language sentences to grounded semantic parses", "start_pos": 57, "end_pos": 119, "type": "TASK", "confidence": 0.6757990084588528}]}, {"text": "Our semantic parser can be downloaded from http://sivareddy.in/ downloads.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present our experimental set-up for assessing the performance of the semantic parser described above.", "labels": [], "entities": []}, {"text": "We present the datasets on which our model was trained and tested, discuss implementation details, and briefly introduce the models used for comparison with our approach.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Domain-specific Freebase statistics (*some  relations/types/triples are shared across domains);  number of training CLUEWEB09 sentences; number  of test questions in FREE917 and WEBQUESTIONS.", "labels": [], "entities": [{"text": "FREE917", "start_pos": 176, "end_pos": 183, "type": "DATASET", "confidence": 0.8561975359916687}, {"text": "WEBQUESTIONS", "start_pos": 188, "end_pos": 200, "type": "DATASET", "confidence": 0.8716158866882324}]}, {"text": " Table 2: Experimental results on FREE917.", "labels": [], "entities": [{"text": "FREE917", "start_pos": 34, "end_pos": 41, "type": "METRIC", "confidence": 0.720953106880188}]}, {"text": " Table 3: GRAPHPARSER ablation results on  FREE917 and WEBQUESTIONS development set.", "labels": [], "entities": [{"text": "GRAPHPARSER ablation", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.8339658081531525}, {"text": "FREE917", "start_pos": 43, "end_pos": 50, "type": "DATASET", "confidence": 0.7900314927101135}, {"text": "WEBQUESTIONS development set", "start_pos": 55, "end_pos": 83, "type": "DATASET", "confidence": 0.8392009139060974}]}, {"text": " Table 4: Experimental results on WEBQUESTIONS.", "labels": [], "entities": [{"text": "WEBQUESTIONS", "start_pos": 34, "end_pos": 46, "type": "DATASET", "confidence": 0.5183817744255066}]}]}