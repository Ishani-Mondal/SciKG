{"title": [{"text": "The Language Demographics of Amazon Mechanical Turk", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a large scale study of the languages spoken by bilingual workers on Mechanical Turk (MTurk).", "labels": [], "entities": [{"text": "Mechanical Turk (MTurk)", "start_pos": 79, "end_pos": 102, "type": "DATASET", "confidence": 0.9416040778160095}]}, {"text": "We establish a methodology for determining the language skills of anonymous crowd workers that is more robust than simple surveying.", "labels": [], "entities": []}, {"text": "We validate workers' self-reported language skill claims by measuring their ability to correctly translate words, and by geolocating workers to see if they reside in countries where the languages are likely to bespoken.", "labels": [], "entities": []}, {"text": "Rather than posting a one-off survey, we posted paid tasks consisting of 1,000 assignments to translate a total of 10,000 words in each of 100 languages.", "labels": [], "entities": []}, {"text": "Our study ran for several months, and was highly visible on the MTurk crowdsourcing platform, increasing the chances that bilingual workers would complete it.", "labels": [], "entities": [{"text": "MTurk crowdsourcing platform", "start_pos": 64, "end_pos": 92, "type": "DATASET", "confidence": 0.8782204389572144}]}, {"text": "Our study was useful both to create bilingual dictionaries and to act as census of the bilingual speakers on MTurk.", "labels": [], "entities": [{"text": "MTurk", "start_pos": 109, "end_pos": 114, "type": "DATASET", "confidence": 0.9454278945922852}]}, {"text": "We use this data to recommend languages with the largest speaker populations as good candidates for other researchers who want to develop crowdsourced, multilingual technologies.", "labels": [], "entities": []}, {"text": "To further demonstrate the value of creating data via crowdsourcing, we hire workers to create bilingual parallel corpora in six Indian languages , and use them to train statistical machine translation systems.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 170, "end_pos": 201, "type": "TASK", "confidence": 0.6385473310947418}]}], "introductionContent": [], "datasetContent": [{"text": "The central task in this study was to investigate Mechanical Turk's bilingual population.", "labels": [], "entities": [{"text": "Mechanical Turk's bilingual population", "start_pos": 50, "end_pos": 88, "type": "DATASET", "confidence": 0.5848402321338654}]}, {"text": "We accomplished this through self-reported surveys combined with a HIT to translate individual words for 100 languages.", "labels": [], "entities": []}, {"text": "We evaluate the accuracy of the workers' translations against known translations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9991152882575989}]}, {"text": "In cases where these were not exact matches, we used a second pass monolingual HIT, which asked English speakers to evaluate if a worker-provided translation was a synonym of the known translation.", "labels": [], "entities": [{"text": "HIT", "start_pos": 79, "end_pos": 82, "type": "METRIC", "confidence": 0.9221591353416443}]}, {"text": "Demographic questionnaire At the start of each HIT, Turkers were asked to complete a brief survey about their language abilities.", "labels": [], "entities": []}, {"text": "The survey asked the following questions: \u2022 Is [language] your native language?", "labels": [], "entities": []}, {"text": "\u2022 How many years have you spoken?", "labels": [], "entities": []}, {"text": "\u2022 Is English your native language?", "labels": [], "entities": []}, {"text": "\u2022 How many years have you spoken English?", "labels": [], "entities": []}, {"text": "\u2022 What country do you live in?", "labels": [], "entities": []}, {"text": "We automatically collected each worker's current location by geolocating their IP address.", "labels": [], "entities": []}, {"text": "A total of 5,281 unique workers completed our HITs.", "labels": [], "entities": [{"text": "HITs", "start_pos": 46, "end_pos": 50, "type": "TASK", "confidence": 0.7558165788650513}]}, {"text": "Of these, 3,625 provided answers to our survey questions, and we were able to geolocate 5,043.", "labels": [], "entities": []}, {"text": "plots the location of workers across 106 countries.", "labels": [], "entities": []}, {"text": "gives the most common self-reported native languages.", "labels": [], "entities": []}, {"text": "Selection of languages We drew our data from the different language versions of Wikipedia.", "labels": [], "entities": []}, {"text": "We selected the 100 languages with the largest number of articles 1 (.", "labels": [], "entities": []}, {"text": "For each language, we chose the 1,000 most viewed articles over a 1 year period, 2 and extracted the 10,000 most frequent words from them.", "labels": [], "entities": []}, {"text": "The resulting vocabularies served as the input to our translation HIT.", "labels": [], "entities": [{"text": "translation HIT", "start_pos": 54, "end_pos": 69, "type": "TASK", "confidence": 0.7853563129901886}]}, {"text": "Translation HIT For the translation task, we asked Turkers to translate individual words.", "labels": [], "entities": [{"text": "Translation HIT", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8433588743209839}, {"text": "translation task", "start_pos": 24, "end_pos": 40, "type": "TASK", "confidence": 0.9211204051971436}]}, {"text": "We showed each word in the context of three sentences that were drawn from Wikipedia.", "labels": [], "entities": []}, {"text": "Turkers were allowed to mark that they were unable to translate a word.", "labels": [], "entities": []}, {"text": "Each task contained 10 words, 8 of which were words with unknown translations, and 2 of which were quality control words with known translations.", "labels": [], "entities": []}, {"text": "We gave special instruction for translating names of people and places, giving examples of how to handle 'Barack Obama' and 'Australia' using their interlanguage links.", "labels": [], "entities": [{"text": "translating names of people and places", "start_pos": 32, "end_pos": 70, "type": "TASK", "confidence": 0.8703586657842001}]}, {"text": "For languages with non-Latin alphabets, names were transliterated.", "labels": [], "entities": []}, {"text": "The task paid $0.15 for the translation of 10 words.", "labels": [], "entities": [{"text": "translation of 10 words", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.8481390327215195}]}, {"text": "Each set of 10 words was independently translated by three separate workers.", "labels": [], "entities": []}, {"text": "5,281 workers completed 256,604 translation assignments, totaling more than 3 million words, over a period of three and a half months.", "labels": [], "entities": [{"text": "translation assignments", "start_pos": 32, "end_pos": 55, "type": "TASK", "confidence": 0.912832111120224}]}, {"text": "Gold standard translations A set of gold standard translations were automatically harvested from 1 http://meta.wikimedia.org/wiki/List_of_ Wikipedias 2 http://dumps.wikimedia.org/other/ pagecounts-raw/ 500K+ ARTICLES: German (de), English (en), Spanish (es), French (fr), Italian (it), Japanese (ja), Dutch (nl), Polish (pl), Portuguese (pt), Russian (ru) 100K-500K ARTICLES: Arabic (ar), Bulgarian (bg), Catalan (ca), Czech (cs), Danish (da), Esperanto (eo), Basque (eu), Persian (fa), Finnish (fi), Hebrew (he), Hindi (hi), Croatian (hr), Hungarian (hu), Indonesian (id), Korean (ko), Lithuanian (lt), Malay (ms), Norwegian (Bokmal) (no), Romanian (ro), Slovak (sk), Slovenian (sl), Serbian (sr), Swedish (sv), Turkish (tr), UKrainian (UK), Vietnamese (vi), Waray-Waray (war), Chinese (zh) 10K-100K ARTICLES: Afrikaans (af) Amharic (am) Asturian (ast) Azerbaijani (az) Belarusian (be) Bengali (bn) Bishnupriya Manipuri (bpy) Breton (br) Bosnian (bs) Cebuano (ceb) Welsh (cy) Zazaki (diq) Greek (el) West Frisian (fy) Irish (ga) Galician (gl) Gujarati (gu) Haitian (ht) Armenian (hy) Icelandic (is) Javanese (jv) Geor- Wikipedia for every language to use as embedded controls.", "labels": [], "entities": [{"text": "UKrainian", "start_pos": 727, "end_pos": 736, "type": "DATASET", "confidence": 0.9261236786842346}]}, {"text": "We used Wikipedia's inter-language links to pair titles of English articles with their corresponding foreign article's title.", "labels": [], "entities": []}, {"text": "To get a more translatable set of pairs, we excluded any pairs where: (1) the English word was not present in the WordNet ontology, (2) either article title was longer than a single word, (3) the English Wikipedia page was a subcategory of person or place, or (4) the English and the foreign titles were identical or a substring of the other.", "labels": [], "entities": []}, {"text": "We counted all translations that exactly matched the gold standard translation as correct.", "labels": [], "entities": []}, {"text": "For nonexact matches we created a second-pass quality assurance HIT.", "labels": [], "entities": []}, {"text": "Turkers were shown a pair of English words, one of which was a Turker's translation of the foreign word used for quality control, and the other of which was the gold-standard translation of the foreign word.", "labels": [], "entities": []}, {"text": "Evaluators were asked whether the two words had the same meaning, and chose between three answers: 'Yes', 'No', or 'Re- We checked Turkers who were working on this task by embedding pairs of words which were ei- ther known to be synonyms (drawn from WordNet) or unrelated (randomly chosen from a corpus).", "labels": [], "entities": [{"text": "Re", "start_pos": 116, "end_pos": 118, "type": "METRIC", "confidence": 0.9511418342590332}]}, {"text": "Automating approval/rejections for the second-pass evaluation allowed the whole pipeline to be run automatically.", "labels": [], "entities": []}, {"text": "Caching judgments meant that we ultimately needed only 20,952 synonym tasks to judge all of the submitted translations (a total of 74,572 non-matching word pairs).", "labels": [], "entities": []}, {"text": "These were completed by an additional 1,005 workers.", "labels": [], "entities": []}, {"text": "Each of these assignments included 10 word pairs and paid $0.10.", "labels": [], "entities": []}, {"text": "Full sentence translations To demonstrate the feasibility of using crowdsourcing to create multilingual technologies, we hire Turkers to construct bilingual parallel corpora from scratch for six Indian languages.", "labels": [], "entities": []}, {"text": "attempted to build a Tamil-English translation system from scratch by hiring professional translators, but found the cost prohibitive.", "labels": [], "entities": [{"text": "Tamil-English translation", "start_pos": 21, "end_pos": 46, "type": "TASK", "confidence": 0.7296755313873291}]}, {"text": "We created parallel corpora by translating the 100 most viewed Wikipedia pages in Bengali, Malyalam, Hindi, Tamil, Telugu, and Urdu into English.", "labels": [], "entities": []}, {"text": "We collected four translations from different Turkers for each source sentence.", "labels": [], "entities": []}, {"text": "Workers were paid $0.70 per HIT to translate 10 sentences.", "labels": [], "entities": [{"text": "HIT", "start_pos": 28, "end_pos": 31, "type": "DATASET", "confidence": 0.7916713356971741}, {"text": "translate 10 sentences", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.8410402536392212}]}, {"text": "We accepted or rejected translations based on a manual review of each worker's submissions, which included a comparison of the translations to a monotonic gloss (produced with a dictionary), and metadata such as the amount of time the worker took to complete the HIT and their geographic location.", "labels": [], "entities": []}, {"text": "shows an example of the translations we obtained.", "labels": [], "entities": []}, {"text": "The lack of a professionally translated reference sentences prevented us from doing a systematic comparison between the quality of profes-", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 5: BLEU scores for translating into English  using bilingual parallel corpora by themselves, and  with the addition of single-word dictionaries. Scores  are calculated using four reference translations and  represent the mean of three MERT runs.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9987964630126953}, {"text": "MERT", "start_pos": 242, "end_pos": 246, "type": "METRIC", "confidence": 0.9023375511169434}]}]}