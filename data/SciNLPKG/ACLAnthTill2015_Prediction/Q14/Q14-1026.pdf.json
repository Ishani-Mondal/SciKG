{"title": [{"text": "Improved CCG Parsing with Semi-supervised Supertagging", "labels": [], "entities": [{"text": "Improved CCG Parsing", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.714418868223826}, {"text": "Supertagging", "start_pos": 42, "end_pos": 54, "type": "TASK", "confidence": 0.8052878379821777}]}], "abstractContent": [{"text": "Current supervised parsers are limited by the size of their labelled training data, making improving them with unlabelled data an important goal.", "labels": [], "entities": []}, {"text": "We show how a state-of-the-art CCG parser can be enhanced, by predicting lexical categories using unsupervised vector-space embeddings of words.", "labels": [], "entities": []}, {"text": "The use of word embeddings enables our model to better generalize from the labelled data, and allows us to accurately assign lexical categories without depending on a POS-tagger.", "labels": [], "entities": []}, {"text": "Our approach leads to substantial improvements in dependency parsing results over the standard supervised CCG parser when evaluated on Wall Street Journal (0.8%), Wikipedia (1.8%) and biomedical (3.4%) text.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.8298136591911316}, {"text": "Wall Street Journal", "start_pos": 135, "end_pos": 154, "type": "DATASET", "confidence": 0.9582488338152567}]}, {"text": "We compare the performance of two recently proposed approaches for classification using a wide variety of word embeddings.", "labels": [], "entities": []}, {"text": "We also give a detailed error analysis demonstrating where using embeddings outperforms traditional feature sets, and showing how including POS features can decrease accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 166, "end_pos": 174, "type": "METRIC", "confidence": 0.9968351721763611}]}], "introductionContent": [{"text": "Combinatory Categorial Grammar (CCG) is widely used in natural language semantics, largely because of its direct linkage of syntax and semantics.", "labels": [], "entities": [{"text": "Combinatory Categorial Grammar (CCG)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7745955934127172}]}, {"text": "However, this connection means that performance on semantic applications is highly dependent on the quality of the syntactic parse.", "labels": [], "entities": []}, {"text": "Although CCG parsers perform at state-of-the-art levels (, fullsentence accuracy is just 25.6% on Wikipedia text, which gives a low upper bound on logical inference approaches to question-answering and textual entailment.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.8258916735649109}, {"text": "textual entailment", "start_pos": 202, "end_pos": 220, "type": "TASK", "confidence": 0.6919243931770325}]}, {"text": "Supertags are rich lexical categories that go beyond POS tags by encoding information about predicate-argument structure.", "labels": [], "entities": []}, {"text": "Supertagging is \"almost parsing\", and is used by parsers based on strongly lexicalized formalisms such as CCG and TAG to improve accuracy and efficiency, by delegating many of the parsing decisions to finite-state models (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.9971181154251099}]}, {"text": "A disadvantage of this approach is that larger sets of lexical categories mean increased sparsity, decreasing tagging accuracy.", "labels": [], "entities": [{"text": "tagging", "start_pos": 110, "end_pos": 117, "type": "TASK", "confidence": 0.9448444843292236}, {"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.8849279284477234}]}, {"text": "As large amounts of labelled data are unlikely to be made available, recent work has explored using unlabelled data to improve parser lexicons ().", "labels": [], "entities": []}, {"text": "However, existing work has failed to improve the overall accuracy of state-of-the-art supervised parsers in-domain.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9988634586334229}]}, {"text": "Another strand of recent work has explored using unsupervised word embeddings as features in supervised models (, largely motivated as a simpler and more general alternative to standard feature sets.", "labels": [], "entities": []}, {"text": "We apply similar techniques to CCG supertagging, hypothesising that words which are close in the embedding space will have similar supertags.", "labels": [], "entities": []}, {"text": "Most existing work has focused on flat tagging tasks, and has not produced state-of-the-art results on structured prediction tasks like parsing).", "labels": [], "entities": [{"text": "flat tagging tasks", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.7448721528053284}]}, {"text": "CCG's lexicalized nature provides a simple and elegant solution to treating parsing as a flat tagging task, as the lexical categories encode information about hierarchical structure.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Embeddings used in our experiments. Dimensionality is the set of dimensions of the word em- bedding space that we experimented with, and Training Words refers to the size of the unlabelled corpus the  embeddings were trained on.", "labels": [], "entities": []}, {"text": " Table 2: Comparison of different embeddings and  context windows on Section 00 of CCGBank. Ab- breviations such as Turian-50 refer to the Turian em- beddings with a 50-dimensional embedding space.", "labels": [], "entities": [{"text": "Section 00 of CCGBank", "start_pos": 69, "end_pos": 90, "type": "DATASET", "confidence": 0.7336833626031876}]}, {"text": " Table 4: Parsing F1-scores for labelled dependencies across a range of domains, using the C&C parser with  different supertaggers. Embeddings models used a context window of 7 words, and no additional hidden  layer. Following previous CCG parsing work, we report F1-scores on the subset of sentences where the  parser is able to produce a parse (F1-cov), and the parser's coverage (COV). Where available we also report  overall scores (F1-all), including parser failures, which we believe gives a more realistic assessment.", "labels": [], "entities": [{"text": "CCG parsing", "start_pos": 236, "end_pos": 247, "type": "TASK", "confidence": 0.5507604628801346}, {"text": "coverage (COV)", "start_pos": 373, "end_pos": 387, "type": "METRIC", "confidence": 0.8681880235671997}, {"text": "F1-all", "start_pos": 437, "end_pos": 443, "type": "METRIC", "confidence": 0.9773525595664978}]}]}