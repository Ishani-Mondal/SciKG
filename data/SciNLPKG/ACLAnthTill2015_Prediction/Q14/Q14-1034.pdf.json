{"title": [{"text": "Extracting Lexically Divergent Paraphrases from Twitter", "labels": [], "entities": [{"text": "Extracting Lexically Divergent Paraphrases", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.890480250120163}]}], "abstractContent": [{"text": "We present MULTIP (Multi-instance Learning Paraphrase Model), anew model suited to identify paraphrases within the short messages on Twitter.", "labels": [], "entities": [{"text": "MULTIP", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.8409541249275208}]}, {"text": "We jointly model paraphrase relations between word and sentence pairs and assume only sentence-level annotations during learning.", "labels": [], "entities": []}, {"text": "Using this principled latent variable model alone, we achieve the performance competitive with a state-of-the-art method which combines a latent space model with a feature-based supervised classifier.", "labels": [], "entities": []}, {"text": "Our model also captures lexically divergent paraphrases that differ from yet complement previous methods; combining our model with previous work significantly outperforms the state-of-the-art.", "labels": [], "entities": []}, {"text": "In addition, we present a novel annotation methodology that has allowed us to crowdsource a paraphrase corpus from Twit-ter.", "labels": [], "entities": []}, {"text": "We make this new dataset available to the research community.", "labels": [], "entities": []}], "introductionContent": [{"text": "Paraphrases are alternative linguistic expressions of the same or similar meaning.", "labels": [], "entities": []}, {"text": "Twitter engages millions of users, who naturally talk about the same topics simultaneously and frequently convey similar meaning using diverse linguistic expressions.", "labels": [], "entities": []}, {"text": "The unique characteristics of this user-generated text presents new challenges and opportunities for paraphrase research (;).", "labels": [], "entities": [{"text": "paraphrase research", "start_pos": 101, "end_pos": 120, "type": "TASK", "confidence": 0.9607512950897217}]}, {"text": "For many applications, like automatic summarization, first story detection) and search, it is crucial to resolve redundancy in tweets (e.g. oscar nom'd doc \u2194 Oscar-nominated documentary).", "labels": [], "entities": [{"text": "summarization", "start_pos": 38, "end_pos": 51, "type": "TASK", "confidence": 0.8525611758232117}, {"text": "first story detection", "start_pos": 53, "end_pos": 74, "type": "TASK", "confidence": 0.6991438070933024}]}, {"text": "In this paper, we investigate the task of determining whether two tweets are paraphrases.", "labels": [], "entities": []}, {"text": "Previous work has exploited a pair of shared named entities to locate semantically equivalent patterns from related news articles (.", "labels": [], "entities": []}, {"text": "But short sentences in Twitter do not often mention two named entities () and require nontrivial generalization from named entities to other words.", "labels": [], "entities": []}, {"text": "For example, consider the following two sentences about basketball player Brook Lopez from Twitter: \u2022 That boy Brook Lopez with a deep 3 \u2022 brook lopez hit a 3 and i missed it Although these sentences do not have many words in common, the identical word \"3\" is a strong indicator that the two sentences are paraphrases.", "labels": [], "entities": []}, {"text": "We therefore propose a novel joint word-sentence approach, incorporating a multi-instance learning assumption () that two sentences under the same topic (we highlight topics in bold) are paraphrases if they contain at least one word pair (we call it an anchor and highlight with underscores; the words in the anchor pair need not be identical) that is indicative of sentential paraphrase.", "labels": [], "entities": []}, {"text": "This at-least-one-anchor assumption might be ineffective for long or randomly paired sentences, but holds up better for short sentences that are temporally and topically related on Twitter.", "labels": [], "entities": []}, {"text": "Moreover, our model design (see) allows exploitation of arbitrary features and linguistic resources, such as part-of-speech features and a normalization lex- Figure 1: (a) a plate representation of the MULTIP model (b) an example instantiation of MULTIP for the pair of sentences \"Manti bout to be the next Junior Seau\" and \"Teo is the little new Junior Seau\", in which anew American football player Manti Te'o was being compared to a famous former player Junior Seau.", "labels": [], "entities": [{"text": "MULTIP", "start_pos": 202, "end_pos": 208, "type": "DATASET", "confidence": 0.783730149269104}, {"text": "MULTIP", "start_pos": 247, "end_pos": 253, "type": "DATASET", "confidence": 0.8790275454521179}]}, {"text": "Only 4 out of the total 6 \u00d7 5 word pairs, z 1 -z 30 , are shown here.", "labels": [], "entities": []}, {"text": "icon, to discriminatively determine word pairs as paraphrastic anchors or not.", "labels": [], "entities": []}, {"text": "Our graphical model is a major departure from popular surface-or latent-similarity methods (.", "labels": [], "entities": []}, {"text": "Our approach to extract paraphrases from Twitter is general and can be combined with various topic detecting solutions.", "labels": [], "entities": [{"text": "topic detecting", "start_pos": 93, "end_pos": 108, "type": "TASK", "confidence": 0.753059595823288}]}, {"text": "As a demonstration, we use Twitter's own trending topic service to collect data and conduct experiments.", "labels": [], "entities": []}, {"text": "While having a principled and extensible design, our model alone achieves performance on par with a state-of-the-art ensemble approach that involves both latent semantic modeling and supervised classification.", "labels": [], "entities": []}, {"text": "The proposed model also captures radically different paraphrases from previous approaches; a combined system shows significant improvement over the state-of-the-art.", "labels": [], "entities": []}, {"text": "This paper makes the following contributions: 1) We present a novel latent variable model for paraphrase identification, that specifically accommodates the very short context and divergent wording in Twitter data.", "labels": [], "entities": [{"text": "paraphrase identification", "start_pos": 94, "end_pos": 119, "type": "TASK", "confidence": 0.9717707931995392}]}, {"text": "We experimentally compare several representative approaches and show that our proposed method More information about Twitter's trends: https://support.twitter.com/articles/ 101125-faqs-about-twitter-s-trends yields state-of-the-art results and identifies paraphrases that are complementary to previous methods.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Performance of different paraphrase identification approaches on Twitter data. *An enhanced  version that uses additional 1.6 million sentences from Twitter. ** Reimplementation of a strong baseline  used by Das and Smith (2009).", "labels": [], "entities": [{"text": "paraphrase identification", "start_pos": 35, "end_pos": 60, "type": "TASK", "confidence": 0.725903794169426}]}, {"text": " Table 3: Feature ablation by removing each individ- ual feature group from the full set.", "labels": [], "entities": [{"text": "Feature ablation", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.7903355658054352}]}, {"text": " Table 4: Example system outputs; rank is the position in the list of all candidate paraphrase pairs in the test  set ordered by model score. MULTIP discovers lexically divergent paraphrases while LEXLATENT prefers  more overall sentence similarity. Underline marks the word pair(s) with highest estimated probability as  paraphrastic anchor(s) for each sentence pair.", "labels": [], "entities": [{"text": "LEXLATENT", "start_pos": 197, "end_pos": 206, "type": "METRIC", "confidence": 0.9294915199279785}]}]}