{"title": [{"text": "Crosslingual and Multilingual Construction of Syntax-Based Vector Space Models", "labels": [], "entities": []}], "abstractContent": [{"text": "Syntax-based distributional models of lexical semantics provide a flexible and linguistically adequate representation of co-occurrence information.", "labels": [], "entities": []}, {"text": "However, their construction requires large, accurately parsed corpora, which are unavailable for most languages.", "labels": [], "entities": []}, {"text": "In this paper, we develop a number of methods to overcome this obstacle.", "labels": [], "entities": []}, {"text": "We describe (a) a crosslingual approach that constructs a syntax-based model fora new language requiring only an English resource and a translation lexicon; and (b) multilingual approaches that combine crosslingual with monolingual information , subject to availability.", "labels": [], "entities": []}, {"text": "We evaluate on two lexical semantic benchmarks in Ger-man and Croatian.", "labels": [], "entities": []}, {"text": "We find that the models exhibit complementary profiles: crosslingual models yield higher accuracies while monolin-gual models provide better coverage.", "labels": [], "entities": []}, {"text": "In addition , we show that simple multilingual models can successfully combine their strengths.", "labels": [], "entities": []}], "introductionContent": [{"text": "Building on the Distributional Hypothesis, which states that words occurring in similar contexts are similar in meaning, distributional semantic models (DSMs) represent a word's meaning via its occurrence in context in large corpora.", "labels": [], "entities": []}, {"text": "Vector spaces, the most widely used type of DSMs, represent words as vectors in a highdimensional space whose dimensions correspond to features of the words' contexts.", "labels": [], "entities": []}, {"text": "Word spaces represent the simplest case of DSMs in which the dimensions are simply the context words.", "labels": [], "entities": []}, {"text": "A notable subclass of DSMs are syntax-based models) which use (lexicalized) syntactic relations as dimensions.", "labels": [], "entities": []}, {"text": "They are able to model more fine-grained distinctions than word spaces and have been found to be useful for tasks such as selectional preference learning, verb class induction (Schulte im), analogical reasoning), and alternation discovery).", "labels": [], "entities": [{"text": "selectional preference learning", "start_pos": 122, "end_pos": 153, "type": "TASK", "confidence": 0.6961835026741028}, {"text": "verb class induction", "start_pos": 155, "end_pos": 175, "type": "TASK", "confidence": 0.6803213953971863}, {"text": "alternation discovery", "start_pos": 217, "end_pos": 238, "type": "TASK", "confidence": 0.9471113383769989}]}, {"text": "Despite their flexibility and usefulness, syntax-based DSMs are used less often than word-based spaces.", "labels": [], "entities": []}, {"text": "An important reason is that their construction requires accurate parsers, which are unavailable for many languages.", "labels": [], "entities": []}, {"text": "In addition, syntax-based DSMs are inherently more sparse than word spaces, which calls fora large corpus of well parsable data.", "labels": [], "entities": []}, {"text": "It is thus not surprising that besides English (, only few other languages possess large-scale syntax-based DSMs (.", "labels": [], "entities": []}, {"text": "This paper develops methods that take advantage of the resource gradient between English and other languages, exploiting the higher-quality resources of the former to induce resources for target languages among the latter, by translating the word-link-word co-occurrences that underlie syntax-based DSMs.", "labels": [], "entities": []}, {"text": "This directly provides a crosslingual method to construct syntax-based DSMs for target languages without any target language data, requiring only an English syntax-based DSM and a translation lexicon.", "labels": [], "entities": []}, {"text": "Such lexicons are available for many language pairs, and we outline a method to reduce ambiguity inherent in such dictionaries.", "labels": [], "entities": []}, {"text": "We describe a set of multilingual methods that can combine corpus evidence from English and the target language to further improve the performance of the obtained DSM.", "labels": [], "entities": []}, {"text": "We consider two target languages, German and Croatian, as examples of one close and one more remote target language.", "labels": [], "entities": []}, {"text": "For evaluation, we use two  tasks, namely synonym choice and semantic similarity prediction.", "labels": [], "entities": [{"text": "synonym choice", "start_pos": 42, "end_pos": 56, "type": "TASK", "confidence": 0.9378172755241394}, {"text": "semantic similarity prediction", "start_pos": 61, "end_pos": 91, "type": "TASK", "confidence": 0.7657393415768942}]}, {"text": "For both languages and tasks, monolingually constructed DSMs can provide strong baselines.", "labels": [], "entities": []}, {"text": "We find similar patterns across tasks and target languages: the crosslingually constructed DSM can be parametrized so that it becomes superior to an existing monolingual DSM in quality, even if inferior in coverage.", "labels": [], "entities": [{"text": "coverage", "start_pos": 206, "end_pos": 214, "type": "METRIC", "confidence": 0.9594014286994934}]}, {"text": "A simple multilingual backoff can combine the crosslingual model's high quality with the monolingual model's high coverage.", "labels": [], "entities": []}, {"text": "We begin by sketching the structure of Distributional Memory, a general framework for syntax-based semantic spaces, in Section 2.", "labels": [], "entities": []}, {"text": "Our main contributions follow in Sections 3 and 4, namely, a family of models for the crosslingual and multilingual construction of DSMs.", "labels": [], "entities": []}, {"text": "The second part of the paper is concerned with evaluation.", "labels": [], "entities": []}, {"text": "Section 5 describes our experimental setup after which we discuss our results for German (Section 6) and Croatian (Section 7).", "labels": [], "entities": []}, {"text": "The paper concludes with related work (Section 8) and a general discussion (Section 9).", "labels": [], "entities": []}], "datasetContent": [{"text": "To show the benefits of our crosslingual methods, we perform experiments for the language pairs EnglishGerman and English-Croatian.", "labels": [], "entities": []}, {"text": "These languages exemplify variability on the resource gradient: The resource situation is best for English, still relatively good for German, and most difficult for Croatian.", "labels": [], "entities": []}, {"text": "This section outlines the experiments for German; Section 7 focuses on Croatian.", "labels": [], "entities": []}, {"text": "We evaluate our models on two standard tasks from lexical semantics: synonym choice and the prediction of human relatedness judgments.", "labels": [], "entities": [{"text": "synonym choice", "start_pos": 69, "end_pos": 83, "type": "TASK", "confidence": 0.9105500876903534}, {"text": "prediction of human relatedness judgments", "start_pos": 92, "end_pos": 133, "type": "TASK", "confidence": 0.8614890813827515}]}, {"text": "Even though these two tasks are in-vitro, they are widely used for model selection in distributional space models and we can compare the results of our models against previous work.", "labels": [], "entities": [{"text": "model selection", "start_pos": 67, "end_pos": 82, "type": "TASK", "confidence": 0.6890264451503754}]}, {"text": "The two tasks test how well the models can account for two different aspects of lexical semantics, namely a specific lexical relation (synonymy) and general semantic relatedness.", "labels": [], "entities": []}, {"text": "Our first task is synonym detection, where models have to identify the true synonym fora target word from four candidates.", "labels": [], "entities": [{"text": "synonym detection", "start_pos": 18, "end_pos": 35, "type": "TASK", "confidence": 0.977929562330246}]}, {"text": "We use the German Reader's Digest Word Power (RDWP) dataset (Wallace and), but can contain short phrases among the candidates (cf. example in).", "labels": [], "entities": [{"text": "German Reader's Digest Word Power (RDWP) dataset", "start_pos": 11, "end_pos": 59, "type": "DATASET", "confidence": 0.9161746561527252}]}, {"text": "Our second evaluation tests how well the models predict similarities for German word pairs including closely related, somewhat related, and unrelated word pairs (cf).", "labels": [], "entities": []}, {"text": "We use the Gur350 dataset which contains 350 word pairs scored for relatedness by native German taggers on a five-point Likert scale between 0 (unrelated) and 4 (synonymous).", "labels": [], "entities": [{"text": "Gur350 dataset", "start_pos": 11, "end_pos": 25, "type": "DATASET", "confidence": 0.9657909572124481}]}, {"text": "Both datasets contain nouns, verbs and adjectives.", "labels": [], "entities": []}, {"text": "The experimental results for the two experiments are shown in, structured by model type.", "labels": [], "entities": []}, {"text": "We observe similar patterns for the two experiments.", "labels": [], "entities": []}, {"text": "In both cases, uninformed baselines (random and frequency) perform badly.", "labels": [], "entities": []}, {"text": "(In Exp. 1, the frequency baseline predicts the most frequent item as synonym; in Exp. 2, it predicts min(f (w 1 ), f (w 2 )).)", "labels": [], "entities": []}, {"text": "In contrast, wordbased DSMs perform quite well, particularly the dimensionality-reduced model (BOW PCA).", "labels": [], "entities": [{"text": "BOW", "start_pos": 95, "end_pos": 98, "type": "METRIC", "confidence": 0.945205807685852}]}, {"text": "We see a consistent quality versus coverage tradeoff among the different classes of syntax-based DSMs.", "labels": [], "entities": []}, {"text": "The monolingual DM.DE model is significantly outperformed by the BOW model on Exp.", "labels": [], "entities": [{"text": "BOW", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.8147425651550293}, {"text": "Exp.", "start_pos": 78, "end_pos": 82, "type": "DATASET", "confidence": 0.9688584208488464}]}, {"text": "1 (p<0.01), but numerically outperforms it on Exp.", "labels": [], "entities": [{"text": "Exp.", "start_pos": 46, "end_pos": 50, "type": "DATASET", "confidence": 0.9707646667957306}]}, {"text": "2 (difference not significant).", "labels": [], "entities": [{"text": "difference", "start_pos": 3, "end_pos": 13, "type": "METRIC", "confidence": 0.9608985781669617}]}, {"text": "In both tasks, the crosslingual DM.XL models outperform both DM.DE and BOW PCA in terms of quality: They achieve the numerically highest accuracy (and correlation, respectively) among all syntaxbased models.", "labels": [], "entities": [{"text": "BOW", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.9576303362846375}, {"text": "accuracy", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.9974709749221802}, {"text": "correlation", "start_pos": 151, "end_pos": 162, "type": "METRIC", "confidence": 0.996029257774353}]}, {"text": "This high quality comes at a low coverage, matching our intuitions about the profile of the crosslingual model.", "labels": [], "entities": []}, {"text": "Filtering leads to a significant improvement in Exp.", "labels": [], "entities": [{"text": "Exp", "start_pos": 48, "end_pos": 51, "type": "DATASET", "confidence": 0.7787598967552185}]}, {"text": "2 (p<0.05) but not in Exp.", "labels": [], "entities": [{"text": "Exp.", "start_pos": 22, "end_pos": 26, "type": "DATASET", "confidence": 0.9543687105178833}]}, {"text": "1. The multilingual models (DM.MULTI) perform even better.", "labels": [], "entities": []}, {"text": "They nearly retain the quality of the crosslingual models (accuracy of .59 vs. .63 for Exp. 1, correlation of .47 vs. .49 for Exp. 2) but attain higher coverage (89% in Exp.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9994868040084839}, {"text": "correlation", "start_pos": 95, "end_pos": 106, "type": "METRIC", "confidence": 0.9912469983100891}, {"text": "coverage", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.9942506551742554}, {"text": "Exp", "start_pos": 169, "end_pos": 172, "type": "DATASET", "confidence": 0.9142873287200928}]}, {"text": "1 and 69% in Exp.", "labels": [], "entities": [{"text": "Exp", "start_pos": 13, "end_pos": 16, "type": "DATASET", "confidence": 0.9140211343765259}]}, {"text": "2) Notably, the coverage is even higher than that of the DM.DE models, attesting to the complementarity of mono-and crosslingual information.", "labels": [], "entities": [{"text": "coverage", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9856576323509216}]}, {"text": "The differences among the DM.MULTI models are small, but MaxSim does a little better and performs best overall.", "labels": [], "entities": []}, {"text": "1, it does significantly better in the all-items evaluation than all other syntax-based models (p<0.01).", "labels": [], "entities": []}, {"text": "2 are only significant at p<0.05 for the model pair 6-8; we attribute this to the smaller size of the dataset.", "labels": [], "entities": []}, {"text": "In sum, we can construct crosslingual DMs without any use of target language corpora that mirror or even exceed the performance of monolingual DMs.", "labels": [], "entities": []}, {"text": "If monolingual data is available, the combination of corpus evidence provides a substantial advantage over both monolingual and crosslingual models, even for German, a language with large, relatively reliably parsed corpora.", "labels": [], "entities": []}, {"text": "Users can choose among different models with different coverage/quality tradeoffs.", "labels": [], "entities": []}, {"text": "Comparison to models from the literature.", "labels": [], "entities": []}, {"text": "Models from the literature are shown at the bottom of the two tables.", "labels": [], "entities": []}, {"text": "They generally obtain the highest accuracy (or correlation, respectively), but only cover a relatively small part of the datasets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9991508722305298}, {"text": "correlation", "start_pos": 47, "end_pos": 58, "type": "METRIC", "confidence": 0.9991022348403931}]}, {"text": "In particular, the models with a quality higher than the DM variants (11 in Exp.", "labels": [], "entities": [{"text": "Exp", "start_pos": 76, "end_pos": 79, "type": "DATASET", "confidence": 0.9563705325126648}]}, {"text": "1 and 10 and 11 in Exp.", "labels": [], "entities": [{"text": "Exp.", "start_pos": 19, "end_pos": 23, "type": "DATASET", "confidence": 0.9251079857349396}]}, {"text": "2) exhibit a coverage of less than half than that of the DM.MULTI models.", "labels": [], "entities": [{"text": "coverage", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9961236119270325}]}, {"text": "This appears to show the usual trade-off between hand-constructed knowledge and automatically acquired knowledge ().", "labels": [], "entities": []}, {"text": "However, we can similarly bias our DMs towards accuracy with the aid of a simple frequency filter that only permits predictions for items where all involved lemmas occur more frequently in the German corpus than some threshold.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9991576671600342}, {"text": "German corpus", "start_pos": 193, "end_pos": 206, "type": "DATASET", "confidence": 0.7748427987098694}]}, {"text": "Setting these thresholds to match the coverage figures of the best ontology-based models, DM.MULTI MaxSim almost reaches the ontology-based results: On Exp.", "labels": [], "entities": [{"text": "DM.MULTI MaxSim", "start_pos": 90, "end_pos": 105, "type": "DATASET", "confidence": 0.7197421789169312}]}, {"text": "1, fora coverage of .22 we obtain an accuracy of .68 (ontology-based model: .77), and on Exp.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9995973706245422}]}, {"text": "2, we ob-  Our third experiment considers a language that is more different from English than German, namely Croatian, a Slavic language.", "labels": [], "entities": []}, {"text": "Available resources for Croatian are more limited than for English or German.", "labels": [], "entities": []}, {"text": "Since syntactic analysis used to be a bottleneck, the first syntax-based DSM for Croatian, DM.HR, became available only last year.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.7667971849441528}]}, {"text": "As for evaluation datasets, there are no human similarity judgments, but there is a synonym choice dataset (CroSyn -see for details).", "labels": [], "entities": []}, {"text": "Thus, our Croatian evaluation is a synonym choice task parallel to Exp.", "labels": [], "entities": []}, {"text": "We take DM.HR as the monolingual model which was built from a dependency-parsed Croatian web corpus of 1.2B tokens.", "labels": [], "entities": []}, {"text": "We construct a crosslingual model by starting from Baroni and Lenci's English TypeDM and using Taktika Nova's freely available English-Croatian dictionary 11 with 105K translation pairs.", "labels": [], "entities": [{"text": "Taktika Nova's freely available English-Croatian dictionary 11", "start_pos": 95, "end_pos": 157, "type": "DATASET", "confidence": 0.7758438177406788}]}, {"text": "After removing entries with more than one word per language, we were left with 95K pairs, considerably fewer than for English-German.", "labels": [], "entities": []}, {"text": "We apply the methods from Section 3 for edge translation and filtering.", "labels": [], "entities": [{"text": "edge translation", "start_pos": 40, "end_pos": 56, "type": "TASK", "confidence": 0.799700915813446}]}, {"text": "The resulting filtered Croatian DM.XL has 47K nodes and 315M edges, about one order of magnitude smaller than the German crosslingual resource.", "labels": [], "entities": [{"text": "Croatian DM.XL", "start_pos": 23, "end_pos": 37, "type": "DATASET", "confidence": 0.9045698642730713}]}, {"text": "Finally, we combined DM.HR with the crosslingual DM (as in Section 4) to obtain multilingual Croatian DMs.", "labels": [], "entities": []}, {"text": "shows the results which correspond closely to those for Exp.", "labels": [], "entities": [{"text": "Exp.", "start_pos": 56, "end_pos": 60, "type": "DATASET", "confidence": 0.8558370471000671}]}, {"text": "1. A dimensionality-reduced BOW space performs competitively with the monolingual DM.HR.", "labels": [], "entities": []}, {"text": "The crosslingual DM is again able to improve accuracy over DM.HR (by 6%) but drops in coverage.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9993521571159363}, {"text": "coverage", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9959055185317993}]}, {"text": "Again, the multilingual models perform best: DM.MULTI MaxSim loses only 1% accuracy compared to the crosslingual model but achieves almost perfect coverage.", "labels": [], "entities": [{"text": "DM.MULTI MaxSim", "start_pos": 45, "end_pos": 60, "type": "DATASET", "confidence": 0.640887439250946}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9993663430213928}, {"text": "coverage", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.9527989625930786}]}, {"text": "The differences to DM.HR and DM.XL are both significant (p<0.01).", "labels": [], "entities": [{"text": "DM.HR", "start_pos": 19, "end_pos": 24, "type": "DATASET", "confidence": 0.9043997526168823}]}, {"text": "The two major differences to the German synonym choice task (Exp.", "labels": [], "entities": [{"text": "German synonym choice task", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.6757510602474213}]}, {"text": "1) are that (a) filtering plays an essential role for Croatian (increase inaccuracy by 15%) and (b) DM.MULTI clearly outperforms the BOW model.", "labels": [], "entities": [{"text": "DM.MULTI", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9177826642990112}]}, {"text": "We attribute the difference to the semiautomatic construction of the Croatian dataset from machine-readable dictionaries.", "labels": [], "entities": [{"text": "Croatian dataset", "start_pos": 69, "end_pos": 85, "type": "DATASET", "confidence": 0.8200100660324097}]}, {"text": "Overall, the results for Croatian are encouraging.", "labels": [], "entities": []}, {"text": "They demonstrate that languages where parsing technology is still developing can in particular profit from cross-and multilingual methods.", "labels": [], "entities": [{"text": "parsing", "start_pos": 38, "end_pos": 45, "type": "TASK", "confidence": 0.9661180377006531}]}, {"text": "This is true even for relatively small translation dictionaries, matching previous results from the literature (Peirsman and Pad\u00f3, 2011).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Coverage and Correlation (Pearson's r)  for predicting word similarity, contrasting link types  (all links vs. selectional preference links)", "labels": [], "entities": [{"text": "Pearson's r)", "start_pos": 36, "end_pos": 48, "type": "METRIC", "confidence": 0.6799185648560524}, {"text": "predicting word similarity", "start_pos": 54, "end_pos": 80, "type": "TASK", "confidence": 0.8442192077636719}]}, {"text": " Table 4: Sizes of various DM resources", "labels": [], "entities": [{"text": "Sizes", "start_pos": 10, "end_pos": 15, "type": "TASK", "confidence": 0.9796240329742432}]}, {"text": " Table 5: Exp. 1: Accuracy and Coverage for synonym  choice on the Reader's Digest Word Choice dataset.  MGHZ07: Mohammad et al. (2007). Best results for  each model class in bold.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9910209774971008}, {"text": "synonym  choice", "start_pos": 44, "end_pos": 59, "type": "TASK", "confidence": 0.8375604748725891}, {"text": "Reader's Digest Word Choice dataset.  MGHZ07: Mohammad et al", "start_pos": 67, "end_pos": 127, "type": "DATASET", "confidence": 0.8613383620977402}]}, {"text": " Table 6: Exp. 2: Coverage and correlation (Pear- son's r) for predicting word similarity on the Gur350  dataset. MGHZ07: Mohammad et al. (2007) 8 ,  ZGM07: Zesch et al. (2007) 9 , PU12: Pad\u00f3 and Utt  (2012). Best results for each model class in bold.", "labels": [], "entities": [{"text": "correlation", "start_pos": 31, "end_pos": 42, "type": "METRIC", "confidence": 0.9573277235031128}, {"text": "Pear- son's r)", "start_pos": 44, "end_pos": 58, "type": "METRIC", "confidence": 0.6499546815951666}, {"text": "predicting word similarity", "start_pos": 63, "end_pos": 89, "type": "TASK", "confidence": 0.7823640505472819}, {"text": "Gur350  dataset", "start_pos": 97, "end_pos": 112, "type": "DATASET", "confidence": 0.9845995008945465}, {"text": "MGHZ07", "start_pos": 114, "end_pos": 120, "type": "DATASET", "confidence": 0.9457034468650818}]}, {"text": " Table 8: Experiment 3: Accuracy and Coverage for  synonym choice on the CroSyn dataset. SPA13: \u0160na- jder et al. (2013). In boldface: best results.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9694079756736755}, {"text": "synonym choice", "start_pos": 51, "end_pos": 65, "type": "TASK", "confidence": 0.8832010328769684}, {"text": "CroSyn dataset", "start_pos": 73, "end_pos": 87, "type": "DATASET", "confidence": 0.9536219239234924}, {"text": "SPA13: \u0160na- jder et al. (2013)", "start_pos": 89, "end_pos": 119, "type": "DATASET", "confidence": 0.885638724673878}]}]}