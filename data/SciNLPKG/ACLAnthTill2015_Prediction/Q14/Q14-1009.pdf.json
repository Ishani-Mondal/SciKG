{"title": [], "abstractContent": [{"text": "We propose anew method for unsupervised tagging that finds minimal models which are then further improved by Expectation Max-imization training.", "labels": [], "entities": []}, {"text": "In contrast to previous approaches that rely on manually specified and multi-step heuristics for model minimization , our approach is a simple greedy approximation algorithm DMLC (DISTRIBUTED-MINIMUM-LABEL-COVER) that solves this objective in a single step.", "labels": [], "entities": [{"text": "model minimization", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.7806571125984192}]}, {"text": "We extend the method and show how to efficiently parallelize the algorithm on modern parallel computing platforms while preserving approximation guarantees.", "labels": [], "entities": []}, {"text": "The new method easily scales to large data and grammar sizes, overcoming the memory bottleneck in previous approaches.", "labels": [], "entities": []}, {"text": "We demonstrate the power of the new algorithm by evaluating on various sequence labeling tasks: Part-of-Speech tagging for multiple languages (including low-resource languages), with complete and incomplete dictionaries, and supertagging, a complex sequence labeling task, where the grammar size alone can grow to millions of entries.", "labels": [], "entities": [{"text": "Part-of-Speech tagging", "start_pos": 96, "end_pos": 118, "type": "TASK", "confidence": 0.7550700306892395}]}, {"text": "Our results show that for all of these settings, our method achieves state-of-the-art scalable performance that yields high quality tagging outputs.", "labels": [], "entities": []}], "introductionContent": [{"text": "Supervised sequence labeling with large labeled training datasets is considered a solved problem.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.6352715641260147}]}, {"text": "For * * The research described herein was conducted while the author was working at Google.", "labels": [], "entities": []}, {"text": "instance, state of the art systems obtain tagging accuracies over 97% for part-of-speech (POS) tagging on the English Penn Treebank.", "labels": [], "entities": [{"text": "English Penn Treebank", "start_pos": 110, "end_pos": 131, "type": "DATASET", "confidence": 0.9308193922042847}]}, {"text": "However, learning accurate taggers without labeled data remains a challenge.", "labels": [], "entities": []}, {"text": "The accuracies quickly drop when faced with data from a different domain, language, or when there is very little labeled information available for training ().", "labels": [], "entities": [{"text": "accuracies", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.996619701385498}]}, {"text": "Recently, there has been an increasing amount of research tackling this problem using unsupervised methods.", "labels": [], "entities": []}, {"text": "A popular approach is to learn from POS-tag dictionaries, where we are given a raw word sequence and a dictionary of legal tags for each word type.", "labels": [], "entities": []}, {"text": "Learning from POStag dictionaries is still challenging.", "labels": [], "entities": [{"text": "POStag dictionaries", "start_pos": 14, "end_pos": 33, "type": "DATASET", "confidence": 0.8064197301864624}]}, {"text": "Complete wordtag dictionaries may not always be available for use and in every setting.", "labels": [], "entities": []}, {"text": "When they are available, the dictionaries are often noisy, resulting in high tagging ambiguity.", "labels": [], "entities": []}, {"text": "Furthermore, when applying taggers in new domains or different datasets, we may encounter new words that are missing from the dictionary.", "labels": [], "entities": []}, {"text": "There have been some efforts to learn POS taggers from incomplete dictionaries by extending the dictionary to include these words using some heuristics or using other methods such as type-supervision (.", "labels": [], "entities": [{"text": "POS taggers from incomplete dictionaries", "start_pos": 38, "end_pos": 78, "type": "TASK", "confidence": 0.8813868641853333}]}, {"text": "In this work, we tackle the problem of unsupervised sequence labeling using tag dictionaries.", "labels": [], "entities": []}, {"text": "The first reported work on this problem was on POS tagging from.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 47, "end_pos": 58, "type": "TASK", "confidence": 0.7832514345645905}]}, {"text": "The approach involved training a standard Hidden Markov Model (HMM) using the Expectation Maximization (EM) algorithm, though EM does not perform well on this task.", "labels": [], "entities": []}, {"text": "More recent methods have yielded better performance than EM (see) for an overview).", "labels": [], "entities": []}, {"text": "One interesting line of research introduced by explores the idea of performing model minimization followed by EM training to learn taggers.", "labels": [], "entities": [{"text": "model minimization", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.718471884727478}]}, {"text": "Their idea is closely related to the classic Minimum Description Length principle for model selection ().", "labels": [], "entities": [{"text": "model selection", "start_pos": 86, "end_pos": 101, "type": "TASK", "confidence": 0.7342644333839417}]}, {"text": "They (1) formulate an objective function to find the smallest model that explains the text (model minimization step), and then, (2) fit the minimized model to the data (EM step).", "labels": [], "entities": []}, {"text": "For POS tagging, this method () yields the best performance to date; 91.6% tagging accuracy on a standard test dataset from the English Penn Treebank.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.8466696739196777}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9928123354911804}, {"text": "English Penn Treebank", "start_pos": 128, "end_pos": 149, "type": "DATASET", "confidence": 0.9245441953341166}]}, {"text": "The original work from) uses an integer linear programming (ILP) formulation to find minimal models, an approach which does not scale to large datasets.", "labels": [], "entities": []}, {"text": "introduced a two-step greedy approximation to the original objective function (called the MIN-GREEDY algorithm) that runs much faster while maintaining the high tagging performance.", "labels": [], "entities": []}, {"text": "showed how to use several heuristics to further improve this algorithm (for instance, better choice of tag bigrams when breaking ties) and stack other techniques on top, such as careful initialization of HMM emission models which results in further performance gains.", "labels": [], "entities": []}, {"text": "Their method also works under incomplete dictionary scenarios and can be applied to certain low-resource scenarios ( by combining model minimization with supervised training.", "labels": [], "entities": []}, {"text": "In this work, we propose anew scalable algorithm for performing model minimization for this task.", "labels": [], "entities": [{"text": "model minimization", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.7668366432189941}]}, {"text": "By making an assumption on the structure of the solution, we prove that a variant of the greedy set cover algorithm always finds an approximately optimal label set.", "labels": [], "entities": []}, {"text": "This is in contrast to previous methods that employ heuristic approaches with no guarantee on the quality of the solution.", "labels": [], "entities": []}, {"text": "In addition, we do not have to rely on ad hoc tie-breaking procedures or careful initializations for unknown words.", "labels": [], "entities": []}, {"text": "Finally, not only is the proposed method approximately optimal, it is also easy to distribute, allowing it to easily scale to very large datasets.", "labels": [], "entities": []}, {"text": "We show empirically that our method, combined with an EM training step outperforms existing state of the art systems.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this Section, we describe the experimental setup for various tasks, settings and compare empirical performance of our method against several existing baselines.", "labels": [], "entities": []}, {"text": "The performance results for all systems (on all tasks) are measured in terms of tagging accuracy, i.e. % of tokens from the test corpus that were labeled correctly by the system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.868255615234375}]}], "tableCaptions": [{"text": " Table 1: Results for unsupervised part-of-speech tagging on English Penn Treebank dataset. Tagging accuracies for  different methods are shown on multiple datasets. te shows the size (number of tokens) in the test data, tr represents  the size of the raw text used to perform model minimization.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.7226628363132477}, {"text": "English Penn Treebank dataset", "start_pos": 61, "end_pos": 90, "type": "DATASET", "confidence": 0.955439567565918}]}, {"text": " Table 2: Part-of-Speech tagging accuracy using PTB sections 00-15 and TUT to build the tag dictionary. For compar- ison, we also include the results for the previously reported state-of-the-art system (method 3) for the same task.", "labels": [], "entities": [{"text": "Part-of-Speech tagging", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.713296502828598}, {"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.970612645149231}, {"text": "PTB sections 00-15", "start_pos": 48, "end_pos": 66, "type": "DATASET", "confidence": 0.8124919136365255}, {"text": "TUT", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.9835978150367737}]}, {"text": " Table 4: Results for unsupervised supertagging with a dictionary. Here, we report the total accuracy as well as  accuracy on just the ambiguous tokens (i.e., tokens which have more than one tagging possibility).  *  The baseline  method 2 requires several pre-processing steps in order to run feasibly for this task (described in Section 6.2). In  contrast, the new approach (DMLC) runs fast and also permits efficient parallelization.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9990604519844055}, {"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9994286894798279}]}]}