{"title": [{"text": "Entity Linking meets Word Sense Disambiguation: a Unified Approach", "labels": [], "entities": [{"text": "Entity Linking", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8152818381786346}, {"text": "Word Sense Disambiguation", "start_pos": 21, "end_pos": 46, "type": "TASK", "confidence": 0.62045090397199}]}], "abstractContent": [{"text": "Entity Linking (EL) and Word Sense Disam-biguation (WSD) both address the lexical ambiguity of language.", "labels": [], "entities": [{"text": "Entity Linking (EL)", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7902555108070374}, {"text": "Word Sense Disam-biguation (WSD)", "start_pos": 24, "end_pos": 56, "type": "TASK", "confidence": 0.6030872017145157}]}, {"text": "But while the two tasks are pretty similar, they differ in a fundamental respect: in EL the textual mention can be linked to a named entity which mayor may not contain the exact mention, while in WSD there is a perfect match between the word form (bet-ter, its lemma) and a suitable word sense.", "labels": [], "entities": []}, {"text": "In this paper we present Babelfy, a unified graph-based approach to EL and WSD based on a loose identification of candidate meanings coupled with a densest subgraph heuris-tic which selects high-coherence semantic interpretations.", "labels": [], "entities": [{"text": "EL and WSD", "start_pos": 68, "end_pos": 78, "type": "TASK", "confidence": 0.5825870831807455}]}, {"text": "Our experiments show state-of-the-art performances on both tasks on 6 different datasets, including a multilingual setting.", "labels": [], "entities": []}, {"text": "Babelfy is online at http://babelfy.org", "labels": [], "entities": [{"text": "Babelfy", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9328092336654663}]}], "introductionContent": [{"text": "The automatic understanding of the meaning of text has been a major goal of research in computational linguistics and related areas for several decades, with ambitious challenges, such as Machine Reading () and the quest for knowledge).", "labels": [], "entities": [{"text": "automatic understanding of the meaning of text", "start_pos": 4, "end_pos": 50, "type": "TASK", "confidence": 0.8328011376517159}, {"text": "Machine Reading", "start_pos": 188, "end_pos": 203, "type": "TASK", "confidence": 0.8684912621974945}]}, {"text": "Word Sense Disambiguation (WSD)) is a historical task aimed at assigning meanings to single-word and multi-word occurrences within text, a task which is more alive than ever in the research community.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD))", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7706807454427084}, {"text": "assigning meanings to single-word and multi-word occurrences within text", "start_pos": 63, "end_pos": 135, "type": "TASK", "confidence": 0.785198708375295}]}, {"text": "Recently, the collaborative creation of large semistructured resources, such as Wikipedia, and knowledge resources built from them (), such as BabelNet (),) and YAGO2, has favoured the emergence of new tasks, such as Entity Linking (EL) (, and opened up new possibilities for tasks such as Named Entity Disambiguation (NED) and Wikification.", "labels": [], "entities": [{"text": "Named Entity Disambiguation (NED)", "start_pos": 290, "end_pos": 323, "type": "TASK", "confidence": 0.7757830619812012}]}, {"text": "The aim of EL is to discover mentions of entities within a text and to link them to the most suitable entry in a reference knowledge base.", "labels": [], "entities": []}, {"text": "However, in contrast to WSD, a mention maybe partial while still being unambiguous thanks to the context.", "labels": [], "entities": [{"text": "WSD", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.5964164733886719}]}, {"text": "For instance, consider the following sentence: (1) Thomas and Mario are strikers playing in Munich.", "labels": [], "entities": []}, {"text": "This example makes it clear how intertwined the two tasks of WSD and EL are.", "labels": [], "entities": [{"text": "WSD", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.6995490789413452}]}, {"text": "In fact, on the one hand, striker and play are polysemous words which can be disambiguated by selecting the game/soccer playing senses of the two words in a dictionary; on the other hand, Thomas and Mario are partial mentions which have to be linked to the appropriate entries of a knowledge base, that is, Thomas M\u00fcller and Mario Gomez, two well-known soccer players.", "labels": [], "entities": []}, {"text": "The two main differences between WSD and EL lie, on the one hand, in the kind of inventory used, i.e., dictionary vs. encyclopedia, and, on the other hand, in the assumption that the mention is complete or potentially partial.", "labels": [], "entities": [{"text": "WSD and EL", "start_pos": 33, "end_pos": 43, "type": "TASK", "confidence": 0.5921202301979065}]}, {"text": "Notwithstanding these differences, the tasks are similar in nature, in that they both involve the disambiguation of textual fragments according to a reference inventory.", "labels": [], "entities": []}, {"text": "However, the research community has so far tackled the two tasks separately, often duplicating efforts and solutions.", "labels": [], "entities": []}, {"text": "In contrast to this trend, research in knowledge acquisition is now heading towards the seamless in-tegration of encyclopedic and lexicographic knowledge into structured language resources (, and the main representative of this new direction is undoubtedly BabelNet (.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 39, "end_pos": 60, "type": "TASK", "confidence": 0.7164748311042786}]}, {"text": "Given such structured language resources it seems natural to suppose that they might provide a common ground for the two tasks of WSD and EL.", "labels": [], "entities": [{"text": "WSD", "start_pos": 130, "end_pos": 133, "type": "TASK", "confidence": 0.7069249749183655}]}, {"text": "More precisely, in this paper we explore the hypothesis that the lexicographic knowledge used in WSD is also useful for tackling the EL task, and, vice versa, that the encyclopedic information utilized in EL helps disambiguate nominal mentions in a WSD setting.", "labels": [], "entities": [{"text": "WSD", "start_pos": 97, "end_pos": 100, "type": "TASK", "confidence": 0.9565103054046631}, {"text": "WSD setting", "start_pos": 249, "end_pos": 260, "type": "TASK", "confidence": 0.8580957353115082}]}, {"text": "We propose Babelfy, a novel, unified graph-based approach to WSD and EL, which performs two main steps: i) it exploits random walks with restart, and triangles as a support for reweighting the edges of a large semantic network; ii) it uses a densest subgraph heuristic on the available semantic interpretations of the input text to perform a joint disambiguation with both concepts and named entities.", "labels": [], "entities": [{"text": "WSD", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.8913687467575073}]}, {"text": "Our experiments show the benefits of our synergistic approach on six gold-standard datasets.", "labels": [], "entities": []}], "datasetContent": [{"text": "We carried out our experiments on six datasets, four for WSD and two for EL: \u2022 The SemEval-2013 task 12 dataset for multilingual WSD ( , which consists of 13 documents in different domains, available in 5 languages.", "labels": [], "entities": [{"text": "SemEval-2013 task 12 dataset", "start_pos": 83, "end_pos": 111, "type": "DATASET", "confidence": 0.724602460861206}]}, {"text": "For each language, all noun occurrences were annotated using BabelNet, thereby providing Wikipedia and WordNet annotations wherever applicable.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 89, "end_pos": 98, "type": "DATASET", "confidence": 0.9012247323989868}]}, {"text": "The number of mentions to be disambiguated roughly ranges from 1K to 2K per language in the different setups.", "labels": [], "entities": []}, {"text": "\u2022 The SemEval-2007 task 7 dataset for coarsegrained English all-words WSD (.", "labels": [], "entities": [{"text": "SemEval-2007 task 7 dataset", "start_pos": 6, "end_pos": 33, "type": "DATASET", "confidence": 0.7404945492744446}, {"text": "coarsegrained English all-words WSD", "start_pos": 38, "end_pos": 73, "type": "TASK", "confidence": 0.3922479636967182}]}, {"text": "We take into account only nominal mentions obtaining a dataset containing 1107 nouns to be disambiguated using WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 111, "end_pos": 118, "type": "DATASET", "confidence": 0.9784069657325745}]}, {"text": "\u2022 The SemEval-2007 task 17 dataset for finegrained English all-words WSD (.", "labels": [], "entities": [{"text": "SemEval-2007 task 17 dataset", "start_pos": 6, "end_pos": 34, "type": "DATASET", "confidence": 0.7616750150918961}]}, {"text": "We considered only nominal mentions resulting in 158 nouns annotated with WordNet synsets.", "labels": [], "entities": [{"text": "WordNet synsets", "start_pos": 74, "end_pos": 89, "type": "DATASET", "confidence": 0.941029280424118}]}, {"text": "\u2022 The Senseval-3 dataset for English all-words WSD (), which contains 899 nouns to be disambiguated using WordNet.", "labels": [], "entities": [{"text": "Senseval-3 dataset", "start_pos": 6, "end_pos": 24, "type": "DATASET", "confidence": 0.7628111243247986}, {"text": "WordNet", "start_pos": 106, "end_pos": 113, "type": "DATASET", "confidence": 0.9732620716094971}]}, {"text": "\u2022 KORE50 (, which consists of 50 short English sentences (mean length of 14 words) with a total number of 144 mentions manually annotated using YAGO2, for which a Wikipedia mapping is available.", "labels": [], "entities": [{"text": "KORE50", "start_pos": 2, "end_pos": 8, "type": "METRIC", "confidence": 0.5523685812950134}, {"text": "YAGO2", "start_pos": 144, "end_pos": 149, "type": "DATASET", "confidence": 0.7107362747192383}]}, {"text": "This dataset was built with the idea of testing against a high level of ambiguity for the EL task.", "labels": [], "entities": [{"text": "EL task", "start_pos": 90, "end_pos": 97, "type": "TASK", "confidence": 0.6761252880096436}]}, {"text": "We fixed the parameters of RWR (Section 5) to the values \u03b1 = .85, \u03b7 = 100 and n = 1M which maximize F1 on a manually created tuning set made up of 10 gold-standard semantic signatures.", "labels": [], "entities": [{"text": "RWR (Section 5)", "start_pos": 27, "end_pos": 42, "type": "DATASET", "confidence": 0.8582131385803222}, {"text": "F1", "start_pos": 100, "end_pos": 102, "type": "METRIC", "confidence": 0.9995530247688293}]}, {"text": "We tuned our two disambiguation parameters \u00b5 = 10 and \u03b8 = 0.8 by optimizing F 1 on the trial dataset of the SemEval-2013 task on multilingual WSD ( . We used the same parameters on all the other WSD datasets.", "labels": [], "entities": [{"text": "F 1", "start_pos": 76, "end_pos": 79, "type": "METRIC", "confidence": 0.9905549585819244}, {"text": "WSD datasets", "start_pos": 195, "end_pos": 207, "type": "DATASET", "confidence": 0.8222992420196533}]}, {"text": "As for EL, we used the training part of AIDA-CoNLL) to set \u00b5 = 5 and \u03b8 = 0.0.", "labels": [], "entities": [{"text": "AIDA-CoNLL", "start_pos": 40, "end_pos": 50, "type": "DATASET", "confidence": 0.8087367415428162}, {"text": "\u00b5", "start_pos": 59, "end_pos": 60, "type": "METRIC", "confidence": 0.9730557799339294}, {"text": "\u03b8", "start_pos": 69, "end_pos": 70, "type": "METRIC", "confidence": 0.9596691131591797}]}], "tableCaptions": [{"text": " Table 1: F1 scores (percentages) of the participating systems of SemEval-2013 task 12 together with MFS, UKB w2w,  IMS, our system and its ablated versions on the Senseval-3, SemEval-2007 task 17 and SemEval-2013 datasets. The  first system which has a statistically significant difference from the top system is marked with (\u03c7 2 , p < 0.05).", "labels": [], "entities": [{"text": "F1 scores (percentages)", "start_pos": 10, "end_pos": 33, "type": "METRIC", "confidence": 0.9366184115409851}, {"text": "MFS", "start_pos": 101, "end_pos": 104, "type": "DATASET", "confidence": 0.89301997423172}, {"text": "UKB w2w", "start_pos": 106, "end_pos": 113, "type": "DATASET", "confidence": 0.9275765717029572}, {"text": "IMS", "start_pos": 116, "end_pos": 119, "type": "DATASET", "confidence": 0.8147856593132019}, {"text": "SemEval-2013 datasets", "start_pos": 201, "end_pos": 222, "type": "DATASET", "confidence": 0.828670084476471}]}, {"text": " Table 2: F1 score (percentages) on the SemEval-2007  task 7. The first system which has a statistically signifi- cant difference from the top system is marked with (\u03c7 2 ,  p < 0.05).", "labels": [], "entities": [{"text": "F1 score (percentages)", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.9251225590705872}, {"text": "SemEval-2007  task 7", "start_pos": 40, "end_pos": 60, "type": "DATASET", "confidence": 0.6110570629437765}]}, {"text": " Table 3: Accuracy (percentages) of state-of-the-art EL  systems and our system on KORE50 and AIDA-CoNLL.  The first system with a statistically significant difference  from the top system is marked with (\u03c7 2 , p < 0.05).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.981069028377533}, {"text": "KORE50", "start_pos": 83, "end_pos": 89, "type": "DATASET", "confidence": 0.9634284377098083}, {"text": "AIDA-CoNLL", "start_pos": 94, "end_pos": 104, "type": "DATASET", "confidence": 0.7799063324928284}]}]}