{"title": [{"text": "Exploring Compositional Architectures and Word Vector Representations for Prepositional Phrase Attachment", "labels": [], "entities": [{"text": "Exploring Compositional Architectures", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.788163979848226}, {"text": "Prepositional Phrase Attachment", "start_pos": 74, "end_pos": 105, "type": "TASK", "confidence": 0.7167547543843588}]}], "abstractContent": [{"text": "Prepositional phrase (PP) attachment disam-biguation is a known challenge in syntactic parsing.", "labels": [], "entities": [{"text": "Prepositional phrase (PP) attachment disam-biguation", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.7403815133231026}, {"text": "syntactic parsing", "start_pos": 77, "end_pos": 94, "type": "TASK", "confidence": 0.8056236207485199}]}, {"text": "The lexical sparsity associated with PP attachments motivates research in word representations that can capture pertinent syntactic and semantic features of the word.", "labels": [], "entities": []}, {"text": "One promising solution is to use word vectors induced from large amounts of raw text.", "labels": [], "entities": []}, {"text": "However , state-of-the-art systems that employ such representations yield modest gains in PP attachment accuracy.", "labels": [], "entities": [{"text": "PP attachment", "start_pos": 90, "end_pos": 103, "type": "TASK", "confidence": 0.8925950825214386}, {"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.8943883776664734}]}, {"text": "In this paper, we show that word vector representations can yield significant PP attachment performance gains.", "labels": [], "entities": [{"text": "PP attachment", "start_pos": 78, "end_pos": 91, "type": "TASK", "confidence": 0.8248791396617889}]}, {"text": "This is achieved via a non-linear architecture that is discriminatively trained to maximize PP attachment accuracy.", "labels": [], "entities": [{"text": "PP attachment", "start_pos": 92, "end_pos": 105, "type": "TASK", "confidence": 0.8175457119941711}, {"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.8243955373764038}]}, {"text": "The architecture is initialized with word vectors trained from unlabeled data, and relearns those to maximize attachment accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9602354168891907}]}, {"text": "We obtain additional performance gains with alternative representations such as dependency-based word vectors.", "labels": [], "entities": []}, {"text": "When tested on both En-glish and Arabic datasets, our method outper-forms both a strong SVM classifier and state-of-the-art parsers.", "labels": [], "entities": []}, {"text": "For instance, we achieve 82.6% PP attachment accuracy on Arabic, while the Turbo and Charniak self-trained parsers obtain 76.7% and 80.8% respectively.", "labels": [], "entities": [{"text": "PP attachment", "start_pos": 31, "end_pos": 44, "type": "TASK", "confidence": 0.5769348740577698}, {"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.7891643047332764}]}], "introductionContent": [{"text": "The problem of prepositional phrase (PP) attachment disambiguation has been under investigation The code and data for this work are available at http: //groups.csail.mit.edu/rbg/code/pp.", "labels": [], "entities": [{"text": "prepositional phrase (PP) attachment disambiguation", "start_pos": 15, "end_pos": 66, "type": "TASK", "confidence": 0.7055250406265259}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 5: PP attachment accuracy of our HPCD  model compared to other systems. HPCD (full) uses  syntactic vectors with enriching and relearning. The  last row is a modified RBG parser with a feature for  the PP predictions of our model.", "labels": [], "entities": [{"text": "PP attachment", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.7719985544681549}, {"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.7626104354858398}, {"text": "HPCD", "start_pos": 79, "end_pos": 83, "type": "DATASET", "confidence": 0.9435080289840698}]}, {"text": " Table 6: Parsing performance (UAS) of the RBG  parser, with predicted and oracle PPs.", "labels": [], "entities": [{"text": "Parsing performance (UAS)", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.8005476832389832}]}, {"text": " Table 7: PP attachment accuracy when enriching  word vectors with part-of-speech tags of the candi- date head (POS) and the following word (NextPOS),  and with WordNet and VerbNet features.", "labels": [], "entities": [{"text": "PP attachment", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.918921023607254}, {"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.974454939365387}, {"text": "WordNet", "start_pos": 161, "end_pos": 168, "type": "DATASET", "confidence": 0.9573583006858826}]}, {"text": " Table 8: PP attachment accuracy of linear (standard)  and syntactic (dependency-based) word vectors.", "labels": [], "entities": [{"text": "PP attachment", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.9166049957275391}, {"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9161630868911743}]}]}