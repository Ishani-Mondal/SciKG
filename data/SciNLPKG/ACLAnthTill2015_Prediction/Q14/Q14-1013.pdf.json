{"title": [{"text": "Senti-LSSVM: Sentiment-Oriented Multi-Relation Extraction with Latent Structural SVM", "labels": [], "entities": [{"text": "Sentiment-Oriented Multi-Relation Extraction", "start_pos": 13, "end_pos": 57, "type": "TASK", "confidence": 0.6415445705254873}]}], "abstractContent": [{"text": "Extracting instances of sentiment-oriented relations from user-generated web documents is important for online marketing analysis.", "labels": [], "entities": [{"text": "Extracting instances of sentiment-oriented relations from user-generated web documents", "start_pos": 0, "end_pos": 86, "type": "TASK", "confidence": 0.8661382330788506}, {"text": "online marketing analysis", "start_pos": 104, "end_pos": 129, "type": "TASK", "confidence": 0.6993312935034434}]}, {"text": "Unlike previous work, we formulate this extraction task as a structured prediction problem and design the corresponding inference as an integer linear program.", "labels": [], "entities": []}, {"text": "Our latent structural SVM based model can learn from training corpora that do not contain explicit annotations of sentiment-bearing expressions, and it can simultaneously recognize instances of both binary (polarity) and ternary (comparative) relations with regard to entity mentions of interest.", "labels": [], "entities": []}, {"text": "The empirical evaluation shows that our approach significantly outperforms state-of-the-art systems across domains (cameras and movies) and across genres (reviews and forum posts).", "labels": [], "entities": []}, {"text": "The gold standard corpus that we built will also be a valuable resource for the community.", "labels": [], "entities": [{"text": "gold standard corpus", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.8233120640118917}]}], "introductionContent": [{"text": "Sentiment-oriented relation extraction () is concerned with recognizing sentiment polarities and comparative relations between entities from natural language text.", "labels": [], "entities": [{"text": "Sentiment-oriented relation extraction", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.8407739400863647}, {"text": "recognizing sentiment polarities", "start_pos": 60, "end_pos": 92, "type": "TASK", "confidence": 0.7560742100079855}]}, {"text": "Identifying such relations often requires syntactic and semantic analysis at both sentence and phrase level.", "labels": [], "entities": []}, {"text": "Most prior work on sentiment analysis consider either i) subjective sentence detection (, ii) polarity classification (), or iii) comparative relation identification (; Ganapathibhotla and . In practice, however, different types of sentiment-oriented relations frequently coexist in documents.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.9550707638263702}, {"text": "subjective sentence detection", "start_pos": 57, "end_pos": 86, "type": "TASK", "confidence": 0.6324229935805002}, {"text": "polarity classification", "start_pos": 94, "end_pos": 117, "type": "TASK", "confidence": 0.7407431304454803}, {"text": "comparative relation identification", "start_pos": 130, "end_pos": 165, "type": "TASK", "confidence": 0.6125666002432505}]}, {"text": "In particular, we found that more than 38% of the sentences in our test corpus contain more than one type of relations.", "labels": [], "entities": []}, {"text": "The isolated analysis approach is inappropriate because i) it sacrifices acuracy by ignoring the intricate interplay among different types of relations; ii) it could lead to conflicting predictions such as estimating a relation candidate as both negative and comparative.", "labels": [], "entities": []}, {"text": "Therefore, in this paper, we identify instances of both sentiment polarities and comparative relations for entities of interest simultaneously.", "labels": [], "entities": []}, {"text": "We assume that all the mentions of entities and attributes are given, and entities are disambiguated.", "labels": [], "entities": []}, {"text": "It is a widely used assumption when evaluating a module in a pipeline system that the outputs of preceding modules are error-free.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, the only existing system capable of extracting both comparisons and sentiment polarities is a rule-based system proposed by.", "labels": [], "entities": []}, {"text": "We argue that it is better to tackle the task by using a unified model with structured outputs.", "labels": [], "entities": []}, {"text": "It allows us to consider a set of correlated relation instances jointly and characterize their interaction through a set of soft and hard constraints.", "labels": [], "entities": []}, {"text": "For example, we can encode constraints to discourage an attribute to participate in a polarity relation and a comparative relation at the same time.", "labels": [], "entities": []}, {"text": "As a result, the system extracts a set of correlated instances of sentiment-oriented relations from a given sentence.", "labels": [], "entities": []}, {"text": "For example, with the sentence about the camera Canon 7D, \"The sensor is great, but the price is higher than Nikon D7000.\" the expected output is positive and preferred(Nikon D7000, Canon 7D, textitprice).", "labels": [], "entities": []}, {"text": "However, constructing a fully annotated training corpus for this task is labor-intensive and requires strong linguistic background.", "labels": [], "entities": []}, {"text": "We minimize this overhead by applying a simplified annotation scheme, in which annotators mark mentions of entities and attributes, disambiguate the entities, and label instances of relations for each sentence.", "labels": [], "entities": []}, {"text": "Based on the new scheme, we have created a small Sentiment Relation Graph (SRG) corpus for the domains of cameras and movies, which significantly differs from the corpora used in prior work) in the following ways: i) both sentiment polarities and comparative relations are annotated; ii) all mentioned entities are disambiguated; and iii) no subjective expressions are annotated, unless they are part of entity mentions.", "labels": [], "entities": []}, {"text": "The new annotation scheme raises anew challenge for learning algorithms in that they need to automatically find textual evidences for each annotated relation during training.", "labels": [], "entities": []}, {"text": "For example, with the sentence \"I like the Rebel a little better, but that is another price jump\", simply assigning a sentimentbearing expression to the nearest relation candidate is insufficient, especially when the sentiment is not explicitly expressed.", "labels": [], "entities": []}, {"text": "In this paper, we propose SENTI-LSSVM, a latent structural SVM based model for sentiment-oriented relation extraction.", "labels": [], "entities": [{"text": "SENTI-LSSVM", "start_pos": 26, "end_pos": 37, "type": "METRIC", "confidence": 0.6776742339134216}, {"text": "sentiment-oriented relation extraction", "start_pos": 79, "end_pos": 117, "type": "TASK", "confidence": 0.8463679552078247}]}, {"text": "SENTI-LSSVM is applied to find the most likely set of the relation instances expressed in a given sentence, where the latent variables are used to assign the most appropriate textual evidences to the respective instances.", "labels": [], "entities": [{"text": "SENTI-LSSVM", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.7574439644813538}]}, {"text": "In summary, the contributions of this paper are the following: \u2022 We propose SENTI-LSSVM: the first unified statistical model with the capability of extracting instances of both binary and ternary sentimentoriented relations.", "labels": [], "entities": [{"text": "SENTI-LSSVM", "start_pos": 76, "end_pos": 87, "type": "METRIC", "confidence": 0.8594052195549011}]}, {"text": "\u2022 We design a task-specific integer linear programming (ILP) formulation for inference.", "labels": [], "entities": []}, {"text": "\u2022 We construct anew SRG corpus as a valuable asset for the evaluation of sentiment relation extraction.", "labels": [], "entities": [{"text": "sentiment relation extraction", "start_pos": 73, "end_pos": 102, "type": "TASK", "confidence": 0.8789686957995096}]}, {"text": "\u2022 We conduct extensive experiments with online reviews and forum posts, showing that SENTI-LSSVM model can effectively learn from a training corpus without explicitly annotated subjective expressions and that its performance significantly outperforms state-of-the-art systems.", "labels": [], "entities": [{"text": "SENTI-LSSVM", "start_pos": 85, "end_pos": 96, "type": "TASK", "confidence": 0.6956212520599365}]}], "datasetContent": [{"text": "This section describes the empirical evaluation of SENTI-LSSVM together with two competitive baselines on the SRG corpus.", "labels": [], "entities": [{"text": "SENTI-LSSVM", "start_pos": 51, "end_pos": 62, "type": "TASK", "confidence": 0.7468598484992981}, {"text": "SRG corpus", "start_pos": 110, "end_pos": 120, "type": "DATASET", "confidence": 0.80516716837883}]}, {"text": "We implemented a rule-based baseline (DING-RULE) and a structural SVM () baseline (SENTI-SSVM) for comparison.", "labels": [], "entities": [{"text": "SENTI-SSVM", "start_pos": 83, "end_pos": 93, "type": "METRIC", "confidence": 0.9195082783699036}]}, {"text": "The former system extends the work of, which designed several linguisticallymotivated rules based on a sentiment polarity lexicon for relation identification and assumes there is only one type of sentiment relation in a sentence.", "labels": [], "entities": [{"text": "relation identification", "start_pos": 134, "end_pos": 157, "type": "TASK", "confidence": 0.8280288279056549}]}, {"text": "In our implementation, we keep all the rules of () and add one phrase-level rule when there are more than one mention in a sentence.", "labels": [], "entities": []}, {"text": "The additional rule assigns sentiment-bearing words and negators to its nearest relation candidates based on the absolute surface distance between the words and the corresponding mentions.", "labels": [], "entities": []}, {"text": "In this case, the phraselevel sentiment-oriented relations depend only on the assigned sentiment words and negators.", "labels": [], "entities": []}, {"text": "The latter system is based on a structural SVM and does not consider the assignment of textual evidences to relation instances during inference.", "labels": [], "entities": []}, {"text": "The textual features of a relation candidate are all lexical and sentiment predictor features within a surface distance of four words from the mentions of the candidate.", "labels": [], "entities": [{"text": "sentiment predictor", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.6584510654211044}]}, {"text": "Thus, this baseline does not need the inference constraints of SENTI-LSSVM for the selection of textual evidences.", "labels": [], "entities": [{"text": "SENTI-LSSVM", "start_pos": 63, "end_pos": 74, "type": "METRIC", "confidence": 0.5319541096687317}]}, {"text": "To gain more insights into the model, we also evaluate the contribution of individual features of In addition, to show if identifying sentiment polarities and comparative relations jointly works better than tackling each task on its own, we train SENTI-LSSVM for each task separately and combine their predictions according to compatibility rules and the corresponding graph scores.", "labels": [], "entities": [{"text": "SENTI-LSSVM", "start_pos": 247, "end_pos": 258, "type": "METRIC", "confidence": 0.7644693851470947}]}, {"text": "For each domain and text genre, we withheld 15% documents for development and use the remaining for cross validation.", "labels": [], "entities": []}, {"text": "The hyperparameters of all systems are tuned on the development datasets.", "labels": [], "entities": []}, {"text": "For all experiments of SENTI-LSSVM, we use \u03c1 = 0.0001 for the L1 regularizer in Eq.(4) and \u03d5 = 0.05 for the loss function; and for SENTI-SSVM, \u03c1 = 0.0001 and \u03d5 = 0.01.", "labels": [], "entities": []}, {"text": "Since the relation type of off-topic sentences is certainly other, we evaluate all systems with 5-fold cross-validation only on the on-topic sentences in the evaluation dataset.", "labels": [], "entities": []}, {"text": "Since the same sSoR can have several equivalent MRGs and the relation type other is not of our interest, we evaluate the sSoRs in terms of precision, recall and F-measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 139, "end_pos": 148, "type": "METRIC", "confidence": 0.9996590614318848}, {"text": "recall", "start_pos": 150, "end_pos": 156, "type": "METRIC", "confidence": 0.9995461106300354}, {"text": "F-measure", "start_pos": 161, "end_pos": 170, "type": "METRIC", "confidence": 0.9966908693313599}]}, {"text": "All reported numbers are averages over the 5 folds.", "labels": [], "entities": []}, {"text": "shows the complete results of all systems.", "labels": [], "entities": []}, {"text": "Here our model SENTI-LSSVM outperformed all baselines in terms of the average F-measure scores and recalls by a large margin.", "labels": [], "entities": [{"text": "SENTI-LSSVM", "start_pos": 15, "end_pos": 26, "type": "METRIC", "confidence": 0.6671528220176697}, {"text": "F-measure scores", "start_pos": 78, "end_pos": 94, "type": "METRIC", "confidence": 0.9257601797580719}, {"text": "recalls", "start_pos": 99, "end_pos": 106, "type": "METRIC", "confidence": 0.9114333391189575}]}, {"text": "The F-measure on movie reviews is about 14% over the best baseline.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9990191459655762}]}, {"text": "The rule-based system has higher precision than recall inmost cases.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9992747902870178}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9988516569137573}]}, {"text": "However, simply increasing the coverage of the domain independent sentiment polarity lexicon might lead to worse performance) because many sentiment oriented relations are conveyed by domain dependent expressions and factual expressions implying evaluations, such as \"This camera does not have manual control.\"", "labels": [], "entities": []}, {"text": "Compared to DING-RULE, SENTI-SSVM performs better in the camera domain but worse for the movies due to many misclassification of negative relation instances as other.", "labels": [], "entities": [{"text": "SENTI-SSVM", "start_pos": 23, "end_pos": 33, "type": "METRIC", "confidence": 0.8436258435249329}]}, {"text": "It also wrongly predicted more positive instances as other than SENTI-LSSVM.", "labels": [], "entities": [{"text": "SENTI-LSSVM", "start_pos": 64, "end_pos": 75, "type": "DATASET", "confidence": 0.4544871747493744}]}, {"text": "We found that the recalls of these instances are low because they often have overly similar features with the instances of the type other linking to the same mentions.", "labels": [], "entities": [{"text": "recalls", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.9991900324821472}]}, {"text": "The problem gets worse in the movie domain since i) many sentences contain no explicit sentiment-bearing words; ii) the prior polarity of the sentiment-bearing words do not agree with their contextual polarity in the sentences.", "labels": [], "entities": []}, {"text": "Consider the following example from a forum post about the movie \"Superman Returns\": \"Have a look at Superman: the Animated Series or Justice League Unlimited . .", "labels": [], "entities": [{"text": "Superman Returns\"", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.7948785722255707}]}, {"text": ". that is how the characters of Superman and Lex Luthor should be.\".", "labels": [], "entities": []}, {"text": "In contrast, our model minimizes the overlapping features by assigning them to the most likely relation candidates.", "labels": [], "entities": []}, {"text": "This leads to significantly better performance.", "labels": [], "entities": []}, {"text": "Although SENTI-SSVM has low recall for both positive and negative relations, it achieves the highest recall for the comparative relation among all systems in the movie domain and camera reviews.", "labels": [], "entities": [{"text": "SENTI-SSVM", "start_pos": 9, "end_pos": 19, "type": "METRIC", "confidence": 0.638545036315918}, {"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9989368319511414}, {"text": "recall", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.9992076754570007}]}, {"text": "Since less than 1% of all instances are for comparative relations in these document sets and all models are trained to optimize the overall accuracy, SENTI-LSSVM intends to trade off the minority class for the overall better performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 140, "end_pos": 148, "type": "METRIC", "confidence": 0.9981503486633301}, {"text": "SENTI-LSSVM", "start_pos": 150, "end_pos": 161, "type": "TASK", "confidence": 0.5337404608726501}]}, {"text": "This advantage disappears on the camera forum posts, where the number of instances of comparative relation is 12 times more than that in the other data sets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Distribution of relation instances in SRG corpus.", "labels": [], "entities": [{"text": "SRG corpus", "start_pos": 48, "end_pos": 58, "type": "DATASET", "confidence": 0.8374026417732239}]}, {"text": " Table 2: Evaluation results for DING-RULE, SENTI-SSVM and SENTI-LSSVM. Boldface figures are statistically  significantly better than all others in the same comparison group under t-test with p = 0.05.", "labels": [], "entities": [{"text": "DING-RULE", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9619652032852173}, {"text": "SENTI-SSVM", "start_pos": 44, "end_pos": 54, "type": "METRIC", "confidence": 0.9257665872573853}, {"text": "SENTI-LSSVM", "start_pos": 59, "end_pos": 70, "type": "METRIC", "confidence": 0.5666796565055847}]}, {"text": " Table 3: Micro-average F-measure of SENTI-LSSVM", "labels": [], "entities": [{"text": "Micro-average", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9855450987815857}, {"text": "F-measure", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.88505619764328}, {"text": "SENTI-LSSVM", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.49479347467422485}]}]}