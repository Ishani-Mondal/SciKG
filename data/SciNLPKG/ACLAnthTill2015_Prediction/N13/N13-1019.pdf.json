{"title": [{"text": "Topic Segmentation with a Structured Topic Model", "labels": [], "entities": [{"text": "Topic Segmentation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8904513716697693}]}], "abstractContent": [{"text": "We present anew hierarchical Bayesian model for unsupervised topic segmentation.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 61, "end_pos": 79, "type": "TASK", "confidence": 0.7180056422948837}]}, {"text": "This new model integrates a point-wise boundary sampling algorithm used in Bayesian segmenta-tion into a structured topic model that can capture a simple hierarchical topic structure latent in documents.", "labels": [], "entities": []}, {"text": "We develop an MCMC inference algorithm to split/merge segment(s).", "labels": [], "entities": []}, {"text": "Experimental results show that our model out-performs previous unsupervised segmentation methods using only lexical information on Choi's datasets and two meeting transcripts and has performance comparable to those previous methods on two written datasets.", "labels": [], "entities": [{"text": "Choi's datasets", "start_pos": 131, "end_pos": 146, "type": "DATASET", "confidence": 0.8747169772783915}]}], "introductionContent": [{"text": "Documents are usually comprised of topically coherent text segments, each of which contains some number of text passages (e.g., sentences or paragraphs) (.", "labels": [], "entities": []}, {"text": "Within each topically coherent segment, one would expect that the word usage demonstrates more consistent lexical distributions (known as lexical cohesion) than that across segments.", "labels": [], "entities": []}, {"text": "A linear partition of texts into topic segments may reveal information about, for example, themes of segments and the overall thematic structure of the text, and can subsequently be useful for text analysis tasks, such as information retrieval (e.g., passage retrieval (), document summarisation and discourse analysis (.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 222, "end_pos": 243, "type": "TASK", "confidence": 0.7297280579805374}, {"text": "passage retrieval", "start_pos": 251, "end_pos": 268, "type": "TASK", "confidence": 0.8725396394729614}, {"text": "document summarisation", "start_pos": 273, "end_pos": 295, "type": "TASK", "confidence": 0.7243289947509766}, {"text": "discourse analysis", "start_pos": 300, "end_pos": 318, "type": "TASK", "confidence": 0.7602397501468658}]}, {"text": "In this paper we consider how to automatically find a topic segmentation.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 54, "end_pos": 72, "type": "TASK", "confidence": 0.7227682024240494}]}, {"text": "It involves identifying the most prominent topic changes in a sequence of text passages, and splits those passages into a sequence of topically coherent segments).", "labels": [], "entities": []}, {"text": "This task can be cast as an unsupervised machine learning problem: placing topic boundaries in unannotated text.", "labels": [], "entities": []}, {"text": "Although a variety of cues in text can be used for topic segmentation, such as cue phases) and discourse information (, in this paper, we focus on lexical cohesion and use it as the primary cue in developing an unsupervised segmentation model.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.7151640504598618}]}, {"text": "The effectiveness of lexical cohesion has been demonstrated by), c99), MinCut (), PLDA),, TopicTiling (, etc.", "labels": [], "entities": []}, {"text": "Our work uses recent progress in hierarchical topic modelling with non-parametric Bayesian methods (, and is based on Bayesian segmentation methods () using topic models.", "labels": [], "entities": [{"text": "hierarchical topic modelling", "start_pos": 33, "end_pos": 61, "type": "TASK", "confidence": 0.6043170889218649}]}, {"text": "This can also be viewed as a multi-topic extension of hierarchical Bayesian segmentation), although our use of hierarchies is used to improve the performance of linear segmentation, rather than develop hierarchical segmentation.", "labels": [], "entities": []}, {"text": "Recently, topic models are increasingly used in various text analysis tasks including topic segmentation.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.8297696709632874}]}, {"text": "Previous work has shown that using topic assignments or topic distributions instead of word frequency can significantly improve segmentation performance.", "labels": [], "entities": []}, {"text": "Here we consider more advanced topic models that model dependencies between (sub-)sections in a document, such as structured topic models (STMs) presented in (.", "labels": [], "entities": []}, {"text": "STMs treat each text as a sequence of segments, each of which is a set of text passages (e.g., a paragraph or sentence).", "labels": [], "entities": [{"text": "STMs treat each text as a sequence of segments, each of which is a set of text passages (e.g., a paragraph or sentence)", "start_pos": 0, "end_pos": 119, "type": "Description", "confidence": 0.7166527796674658}]}, {"text": "Text passages in a segment share the same prior distribution on their topics.", "labels": [], "entities": []}, {"text": "The topic distributions of segments in a single document are then encouraged to be similar via a hierarchical prior.", "labels": [], "entities": []}, {"text": "This gives a substantial improvement in modelling accuracy.", "labels": [], "entities": [{"text": "modelling", "start_pos": 40, "end_pos": 49, "type": "TASK", "confidence": 0.9453684687614441}, {"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9734233617782593}]}, {"text": "However, instead of explicitly learning the segmentation, STMs just leverage the existing structure of documents from the given segmentation.", "labels": [], "entities": [{"text": "STMs", "start_pos": 58, "end_pos": 62, "type": "TASK", "confidence": 0.9471719861030579}]}, {"text": "Given a sequence of text passages, how can we automatically learn the segmentation?", "labels": [], "entities": []}, {"text": "The word boundary sampling algorithm introduced in) uses point-wise sampling of word boundaries after phonemes in an utterance.", "labels": [], "entities": [{"text": "word boundary sampling", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.7439504067103068}]}, {"text": "Similarly, the segmentation method of PLDA () samples segment boundaries, but also jointly samples a topic model.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 15, "end_pos": 27, "type": "TASK", "confidence": 0.960709273815155}]}, {"text": "This is different to other topic modelling approaches that run LDA as a precursor to a separate segmentation step ().", "labels": [], "entities": []}, {"text": "While conceptually similar to PLDA, our non-parametric approach built on STM required new methods to implement, but the resulting improvement by the standard segmentation scores is substantial.", "labels": [], "entities": []}, {"text": "This paper presents anew hierarchical Bayesian unsupervised topic segmentation model, integrating a point-wise boundary sampling algorithm with a structured topic model.", "labels": [], "entities": [{"text": "Bayesian unsupervised topic segmentation", "start_pos": 38, "end_pos": 78, "type": "TASK", "confidence": 0.6120119616389275}]}, {"text": "This new model takes advantage of the high modelling accuracy of structured topic models () to produce a topic segmentation based on the distribution of latent topics.", "labels": [], "entities": []}, {"text": "We show that this model provides high quality segmentation performance on Choi's dataset, as well as two sets of meeting transcripts and written texts.", "labels": [], "entities": [{"text": "Choi's dataset", "start_pos": 74, "end_pos": 88, "type": "DATASET", "confidence": 0.9009467760721842}]}, {"text": "In the following sections we describe our topic segmentation model and an MCMC inference algorithm for the non-parametric split/merge process.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.720227837562561}]}, {"text": "The rest of the paper is organised as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we review recent related work in the topic segmentation literature.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.7063342183828354}]}, {"text": "Section 3 presents the new topic segmentation model, followed by the derivation of a sampling algorithm in Section 4.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.7694258391857147}]}, {"text": "We report the experimental results by comparing several related topic segmentation methods in Section 5.", "labels": [], "entities": []}, {"text": "Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "To demonstrate the effectiveness of our model (denoted by TSM) in topic segmentation tasks, we evaluate it on three different kinds of corpora 4 : a set of synthetic documents, two meeting transcripts and two sets of text books (see; and compare TSM with the following methods: two baselines (the Random algorithm that places topic boundaries uniformly at random, and the Even algorithm that places a boundary after every m th text passage, where m is the average gold-standard segment length), C99, MinCut, Bayesseg, APS (Kazantseva and Szpakowicz, 2011), and PLDA.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.7445933222770691}, {"text": "PLDA", "start_pos": 561, "end_pos": 565, "type": "DATASET", "confidence": 0.6633848547935486}]}, {"text": "Metrics: We evaluated the segmentation performance with PK (Beeferman et al., 1999) and WindowDiff (WD r ) (), which are two common metrics used in topic segmentation.", "labels": [], "entities": [{"text": "WindowDiff (WD r )", "start_pos": 88, "end_pos": 106, "type": "METRIC", "confidence": 0.6598509788513184}, {"text": "topic segmentation", "start_pos": 148, "end_pos": 166, "type": "TASK", "confidence": 0.7265743613243103}]}, {"text": "Both move a sliding window of fixed size k over the document, and compare the inferred segmentation with the gold-standard segmentation for each window.", "labels": [], "entities": []}, {"text": "The window size is usually set to the half of the average gold-standard segment size).", "labels": [], "entities": []}, {"text": "In addition, we also used an extended WindowDiff proposed by, denoted by WD e . One problem of WD r is that errors near the two ends of a text are penalised less than those in the middle.", "labels": [], "entities": []}, {"text": "To solve the problem WD e adds k fictive text passages at the beginning and the end of the text when computing the score.", "labels": [], "entities": []}, {"text": "We evaluated all the methods with the same Java code for the three metrics.", "labels": [], "entities": []}, {"text": "Parameter Settings: In order to make all the methods comparable, we chose for each method the parameter settings that give the gold-standard number of segments 5 . Specifically, we used a 11 \u00d7 11 rank mask for C99, as suggested by, the configurations included in the code (http://groups.csail.mit.edu/rbg/code) for Bayesseg and manually tuned parameters for MinCut.", "labels": [], "entities": [{"text": "MinCut", "start_pos": 358, "end_pos": 364, "type": "DATASET", "confidence": 0.9524126648902893}]}, {"text": "For APS, a greedy approach was used to search parameter settings that can approximately give the gold-standard number of segments.", "labels": [], "entities": [{"text": "APS", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9601294994354248}]}, {"text": "For PLDA, two randomly initialised Gibbs chains were used.", "labels": [], "entities": [{"text": "PLDA", "start_pos": 4, "end_pos": 8, "type": "TASK", "confidence": 0.8507682085037231}]}, {"text": "Each chain ran for 75,000 burn-in iterations, then 1000 samples were drawn at a lag of 25 from each chain.", "labels": [], "entities": []}, {"text": "For TSM, 10 randomly initialised  Gibbs chains were used.", "labels": [], "entities": [{"text": "TSM", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9346349835395813}]}, {"text": "Each chain ran for 30,000 iterations with 25,000 for burn-in, then 200 samples were drawn.", "labels": [], "entities": []}, {"text": "The concentration parameter bin TSM was sampled using the Adaptive-Reject sampling scheme introduced in (), the discount parameter a = 0.2, and \u03bb 0 = \u03bb 1 = 0.1.", "labels": [], "entities": []}, {"text": "To derive the final segmentation for PLDA and TSM, we first estimated the marginal probabilities of placing boundaries after text passages from the total of 2000 samples.", "labels": [], "entities": []}, {"text": "These probabilities were then thresholded to give the gold-standard number of segments.", "labels": [], "entities": []}, {"text": "Precisely, we apply a small amount of Gaussian smoothing to the marginal probabilities (except for Choi's dataset), like does.", "labels": [], "entities": [{"text": "Choi's dataset", "start_pos": 99, "end_pos": 113, "type": "DATASET", "confidence": 0.6936682462692261}]}, {"text": "Finally, we used asymmetric Dirichlet prior in PLDA and STM, the one on topic distributions is \u03b1 = 0.1, the other on word distributions \u03b3 = 0.01.", "labels": [], "entities": []}, {"text": "Choi's dataset) is commonly used in evaluating topic segmentation methods.", "labels": [], "entities": [{"text": "Choi's dataset", "start_pos": 0, "end_pos": 14, "type": "DATASET", "confidence": 0.874090830485026}, {"text": "topic segmentation", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.7178500294685364}]}, {"text": "It consists of 700 documents, each being a concatenation of 10 segments.", "labels": [], "entities": []}, {"text": "Each segment is the first n sentences of a randomly selected document from the Brown corpus, s.t.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 79, "end_pos": 91, "type": "DATASET", "confidence": 0.966985434293747}]}, {"text": "3 \u2264 n \u2264 11.", "labels": [], "entities": []}, {"text": "Those documents are divided into 4 subsets with different range of n, as shown in.", "labels": [], "entities": []}, {"text": "We ran PLDA and STM with 50 topics.", "labels": [], "entities": [{"text": "PLDA", "start_pos": 7, "end_pos": 11, "type": "DATASET", "confidence": 0.54337477684021}, {"text": "STM", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.8182671666145325}]}, {"text": "Results in show that our model significantly outperforms all the other methods on the four subsets overall the metrics.", "labels": [], "entities": []}, {"text": "Furthermore, comparing to other published results, this also outperforms (Misra et al., 2009) (see their table 2), and (Riedl and Biemann, 2012) (they report an average of 1.04 and 1.06 in, whereas TSM averages 0.93).", "labels": [], "entities": [{"text": "TSM", "start_pos": 198, "end_pos": 201, "type": "METRIC", "confidence": 0.868544340133667}]}, {"text": "This gives TSM the best reported results to date.", "labels": [], "entities": [{"text": "TSM", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.49652040004730225}]}, {"text": "Note the lexical transitions in these concatenated documents are very sharp).", "labels": [], "entities": []}, {"text": "The sharp transitions lead to significant change in segment level topic distributions, which further implies the variance of these distributions is large.", "labels": [], "entities": []}, {"text": "In TSM, a large variance causes a small concentration parameter b.", "labels": [], "entities": [{"text": "TSM", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.8827064037322998}]}, {"text": "We observed that the sampled b's (about 0.1) are indeed small for the four subsets, which shows there is no topic sharing among segments.", "labels": [], "entities": []}, {"text": "Therefore, TSM is able to recognise the segments are unrelated text.", "labels": [], "entities": [{"text": "TSM", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.7230609059333801}]}, {"text": "We applied our model to segmenting the two meeting transcripts, which are the ICSI meeting transcripts () and the 2008 presidential election debates).", "labels": [], "entities": [{"text": "ICSI meeting transcripts", "start_pos": 78, "end_pos": 102, "type": "DATASET", "confidence": 0.9193913737932841}]}, {"text": "The ICSI meeting has 75 transcripts, we used the 25 annotated transcripts provided by for evaluation.", "labels": [], "entities": [{"text": "ICSI meeting", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9390097260475159}]}, {"text": "For the election debates, we used the four annotated debates used in.", "labels": [], "entities": []}, {"text": "The statistics are shown in.", "labels": [], "entities": []}, {"text": "PLDA and TSM were trained with 10 topics on the ICSI and 50 on the Election.", "labels": [], "entities": [{"text": "PLDA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.942571759223938}, {"text": "TSM", "start_pos": 9, "end_pos": 12, "type": "DATASET", "confidence": 0.5995927453041077}, {"text": "ICSI", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.7128318548202515}]}, {"text": "In this set of experiments, we show that our model is robust to meeting transcripts.", "labels": [], "entities": []}, {"text": "As shown in, topic modelling based methods (i.e., Bayesseg, PLDA and TSM) outperform those using either TF or TF-IDF, which is consistent with previously reported results (.", "labels": [], "entities": []}, {"text": "Among the topic model based methods, TSM achieves the best results on all the three metrics.", "labels": [], "entities": [{"text": "TSM", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.8738248944282532}]}, {"text": "On the ICSI transcripts, TSM performs 6.8%, 9.7% and 3.4% better than Bayesseg on the WD r , WD e and PK metrics respectively.", "labels": [], "entities": [{"text": "ICSI transcripts", "start_pos": 7, "end_pos": 23, "type": "DATASET", "confidence": 0.8393133282661438}, {"text": "TSM", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.6959676742553711}, {"text": "WD r , WD e", "start_pos": 86, "end_pos": 97, "type": "METRIC", "confidence": 0.5900383770465851}]}, {"text": "shows an example of how the inferred topic boundary probabilities at utterances compare with the gold-standard boundaries on one ICSI meeting transcript.", "labels": [], "entities": [{"text": "ICSI meeting transcript", "start_pos": 129, "end_pos": 152, "type": "DATASET", "confidence": 0.8750461141268412}]}, {"text": "The gold-standard segmentation is  Although TSM still performs the best on the debates, all the methods have relatively worse performance than on the ICSI meeting transcripts.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 18, "end_pos": 30, "type": "TASK", "confidence": 0.9567713737487793}, {"text": "TSM", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.6227381825447083}, {"text": "ICSI meeting transcripts", "start_pos": 150, "end_pos": 174, "type": "DATASET", "confidence": 0.9456039071083069}]}, {"text": "pointed out that the ICSI meetings are characterised by pragmatic topic changes, in contrast, the debates are characterised by strategic topic changes with strong rewards for setting the agenda, dodging a question, etc.", "labels": [], "entities": [{"text": "ICSI", "start_pos": 21, "end_pos": 25, "type": "DATASET", "confidence": 0.6920321583747864}]}, {"text": "Thus, considering the properties of debates might further improve the segmentation performance.", "labels": [], "entities": []}, {"text": "We further tested TSM on two written text datasets, Clinical and Fiction (.", "labels": [], "entities": [{"text": "TSM", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.8813737034797668}]}, {"text": "The statistics are shown in.", "labels": [], "entities": []}, {"text": "Each document in the Clinical dataset is a chapter of a medical textbook.", "labels": [], "entities": [{"text": "Clinical dataset", "start_pos": 21, "end_pos": 37, "type": "DATASET", "confidence": 0.7682558000087738}]}, {"text": "Section breaks are selected to be the true topic boundaries.", "labels": [], "entities": []}, {"text": "For the Fiction dataset, each document is a fiction downloaded from Project Gutenberg, the true topic boundaries are chapter breaks.", "labels": [], "entities": [{"text": "Fiction dataset", "start_pos": 8, "end_pos": 23, "type": "DATASET", "confidence": 0.8967147171497345}]}, {"text": "We trained PLDA and TSM with 25 topics on the Fiction and 50 on the Clinical.", "labels": [], "entities": [{"text": "PLDA", "start_pos": 11, "end_pos": 15, "type": "DATASET", "confidence": 0.7435386776924133}, {"text": "TSM", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.6938479542732239}]}, {"text": "TSM compares favourably with Bayesseg and outperforms the other methods on the Clinical dataset, but it does not perform as well as Bayesseg on the Fiction dataset.", "labels": [], "entities": [{"text": "TSM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.48509857058525085}, {"text": "Clinical dataset", "start_pos": 79, "end_pos": 95, "type": "DATASET", "confidence": 0.9869019389152527}, {"text": "Fiction dataset", "start_pos": 148, "end_pos": 163, "type": "DATASET", "confidence": 0.9353334009647369}]}, {"text": "In fiction books, the topic boundaries between sections are usually blurred by the authors for reasons of continuity).", "labels": [], "entities": []}, {"text": "We observed that the sampled concentration (or inverse variance) parameter bin TSM is about 18.4 on Fiction, but 4.8 on Clinical, as shown in.", "labels": [], "entities": [{"text": "sampled concentration (or inverse variance) parameter bin TSM", "start_pos": 21, "end_pos": 82, "type": "METRIC", "confidence": 0.7655484557151795}, {"text": "Fiction", "start_pos": 100, "end_pos": 107, "type": "DATASET", "confidence": 0.9529101252555847}, {"text": "Clinical", "start_pos": 120, "end_pos": 128, "type": "DATASET", "confidence": 0.7610224485397339}]}, {"text": "This means the variance of segment level topic distributions \u03bd learnt by TSM is not large for the fiction, so chapter breaks may not necessarily indicate topic changes.", "labels": [], "entities": []}, {"text": "For example, there is a document in the Fiction dataset where gold-standard topic boundaries are placed after each block of text.", "labels": [], "entities": [{"text": "Fiction dataset", "start_pos": 40, "end_pos": 55, "type": "DATASET", "confidence": 0.9180842936038971}]}, {"text": "In contrast, Bayesseg assumes each segment has its own distribution over words, i.e., one topic per segment, which means topics are not shared among segments.", "labels": [], "entities": []}, {"text": "We hypothesize that for certain kinds of documents where the change in topic distribution is subtle, such as fiction, assuming one topic per segment can capture subtle changes in word usage.", "labels": [], "entities": []}, {"text": "This is an area for future investigation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: The Choi's dataset", "labels": [], "entities": [{"text": "The Choi's dataset", "start_pos": 10, "end_pos": 28, "type": "DATASET", "confidence": 0.7817603275179863}]}, {"text": " Table 3: Real dataset statistics", "labels": [], "entities": []}, {"text": " Table 4: Comparison on Choi's datasets with WD and PK (%)  3-11  3-5  6-8  9-11  WD r WD e PK WD r WD e PK WD r WD e PK WD r WD e PK  Random  51.7  49.1 48.7 51.4  50.0 48.4 52.5  49.9 49.2 52.4  48.9 49.2  Even  49.1  46.7 49.0 46.3  45.8 46.3 38.8  37.3 38.8 30.0  28.6 30.0  MinCut  30.4  29.8 26.7 41.6  41.5 37.3 28.2  27.4 25.5 23.6  22.7 21.6  APS  40.7  38.8 38.4 32.0  30.6 31.8 34.4  32.6 32.7 34.5  32.2 33.2  C99  13.5  12.3 12.3 11.3  10.2 10.8 10.2  9.3  9.8  8.9  8.1  8.6  Bayesseg 11.6  10.9 10.9 11.8  11.5 11.1  7.7  7.2  7.3  6.1  5.7  5.7  PLDA  2.4  2.2  1.8  4.0  3.9  3.3  3.6  3.5  2.7  3.0  2.8  2.0  TSM  0.8  0.8  0.6  1.3  1.3  1.0  1.4  1.4  0.9  1.9  1.8  1.2", "labels": [], "entities": [{"text": "Choi's datasets", "start_pos": 24, "end_pos": 39, "type": "DATASET", "confidence": 0.782301108042399}, {"text": "APS  40.7  38.8 38.4 32.0  30.6 31.8 34.4  32.6 32.7 34.5  32.2 33.2  C99  13.5  12.3 12.3 11.3  10.2 10.8 10.2  9.3  9.8  8.9  8.1  8.6  Bayesseg 11.6  10.9 10.9 11.8  11.5 11.1  7.7  7.2  7.3", "start_pos": 352, "end_pos": 545, "type": "TASK", "confidence": 0.6238181052936448}]}, {"text": " Table 5: Comparison on the meeting transcripts and written texts with WD and PK (%)  ICSI  Election  Fiction  Clinical  WD r WD e PK WD r WD e PK  WD r WD e PK WD r WD e PK  Random  46.3  41.7 44.1 51.0  49.7 45.1  51.0  48.7 47.5 45.9  38.5 44.1  Even  48.3  43.0 46.4 56.0  55.1 51.2  48.1  45.9 46.3 49.2  42.0 48.8  C99  42.9  37.4 39.9 43.1  41.5 37.0  48.1  45.1 42.1 39.7  31.9 38.7  MinCut  40.6  36.9 36.9 43.6  43.3 39.0  40.5  39.7 37.1 38.2  36.2 36.8  APS  58.2  49.7 54.6 47.7  36.8 40.6  48.0  45.8 45.1 39.9  32.8 39.6  Bayesseg 32.4  29.7 26.7 41.1  41.3 34.1  33.7  32.8 27.8 35.0  28.8 34.0  PLDA  32.6  28.8 29.4 40.6  41.1 32.0  43.0  41.3 36.1 37.3  32.1 32.4  TSM  30.2  26.8 25.8 38.1  38.9 31.3  40.8  38.7 32.5 34.5  29.1 30.6", "labels": [], "entities": [{"text": "ICSI  Election  Fiction  Clinical", "start_pos": 86, "end_pos": 119, "type": "DATASET", "confidence": 0.8888491839170456}]}, {"text": " Table 6: Sampled concentration parameters", "labels": [], "entities": []}, {"text": " Table 6. This means the vari- ance of segment level topic distributions \u03bd learnt by  TSM is not large for the fiction, so chapter breaks  may not necessarily indicate topic changes. For ex- ample, there is a document in the Fiction dataset  where gold-standard topic boundaries are placed af- ter each block of text. In contrast, Bayesseg assumes", "labels": [], "entities": [{"text": "Fiction dataset", "start_pos": 225, "end_pos": 240, "type": "DATASET", "confidence": 0.9499374330043793}]}]}