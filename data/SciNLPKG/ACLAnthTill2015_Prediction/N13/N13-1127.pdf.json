{"title": [{"text": "Emergence of Gricean Maxims from Multi-Agent Decision Theory", "labels": [], "entities": [{"text": "Multi-Agent Decision Theory", "start_pos": 33, "end_pos": 60, "type": "TASK", "confidence": 0.6631612976392111}]}], "abstractContent": [{"text": "Grice characterized communication in terms of the cooperative principle, which enjoins speakers to make only contributions that serve the evolving conversational goals.", "labels": [], "entities": []}, {"text": "We show that the cooperative principle and the associated maxims of relevance, quality, and quantity emerge from multi-agent decision theory.", "labels": [], "entities": [{"text": "multi-agent decision theory", "start_pos": 113, "end_pos": 140, "type": "TASK", "confidence": 0.6996844013532003}]}, {"text": "We utilize the Decentralized Partially Observable Markov Decision Process (Dec-POMDP) model of multi-agent decision making which relies only on basic definitions of rationality and the ability of agents to reason about each other's beliefs in maximizing joint utility.", "labels": [], "entities": [{"text": "multi-agent decision making", "start_pos": 95, "end_pos": 122, "type": "TASK", "confidence": 0.6978438099225363}]}, {"text": "Our model uses cognitively-inspired heuristics to simplify the otherwise intractable task of reasoning jointly about actions, the environment, and the nested beliefs of other actors.", "labels": [], "entities": []}, {"text": "Our experiments on a cooperative language task show that reasoning about others' belief states, and the resulting emergent Gricean communicative behavior, leads to significantly improved task performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "famously characterized communication among rational agents in terms of an overarching cooperative principle and a set of more specific maxims, which enjoin speakers to make contributions that are truthful, informative, relevant, clear, and concise.", "labels": [], "entities": []}, {"text": "Since then, there have been many attempts to derive the maxims (or perhaps just their effects) from more basic cognitive principles concerning how people make decisions, formulate plans, and collaborate to achieve goals.", "labels": [], "entities": []}, {"text": "This research traces to early work by on signaling systems.", "labels": [], "entities": []}, {"text": "It has recently been the subject of extensive theoretical discussion and has been tested experimentally using one-step games in which the speaker produces a message and the hearer ventures a guess as to its intended referent ().", "labels": [], "entities": []}, {"text": "To date, however, these theoretical models and experiments have not been extended to multi-step interactions extending overtime and involving both language and action together, which leaves this work relatively disconnected from research on planning and goal-orientation in artificial agents.", "labels": [], "entities": []}, {"text": "We attribute this in large part to the complexity of Gricean reasoning itself, which requires agents to model each other's belief states.", "labels": [], "entities": []}, {"text": "Tracking these as they evolve overtime in response to experiences is extremely demanding.", "labels": [], "entities": []}, {"text": "Our approach complements slot-filling dialog systems, where the focus is on managing speech recognition uncertainty ( ).", "labels": [], "entities": [{"text": "speech recognition uncertainty", "start_pos": 85, "end_pos": 115, "type": "TASK", "confidence": 0.7188044985135397}]}, {"text": "However, recent years have seen significant advances in multi-agent decision-theoretic models and their efficient implementation.", "labels": [], "entities": []}, {"text": "With the current paper, we seek to show that the Decentralized Par-tially Observable Markov Decision Process (Dec-POMDP) provides a robust, flexible foundation for implementing agents that communicate in a Gricean manner.", "labels": [], "entities": []}, {"text": "Dec-POMDPs are multi-agent, partiallyobservable models in which agents maintain belief distributions over the underlying, hidden world state, including the beliefs of the other players, and speech actions change those beliefs.", "labels": [], "entities": []}, {"text": "In this setting, informative, relevant communication emerges as the best way to maximize joint utility.", "labels": [], "entities": []}, {"text": "The complexity of pragmatic reasoning is still forbidding, though.", "labels": [], "entities": []}, {"text": "Correspondingly, optimal decision making in Dec-POMDPs is NEXP complete ().", "labels": [], "entities": [{"text": "decision making", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.7456440031528473}]}, {"text": "To manage this issue, we introduce several cognitively-plausible approximations which allow us to simplify the Dec-POMDP to a single-agent POMDP, for which relatively efficient solvers exist).", "labels": [], "entities": []}, {"text": "We demonstrate our algorithms on a variation of the Cards task, a partially-observable collaborative search problem.", "labels": [], "entities": []}, {"text": "Spatial language comprises the bulk of communication in the Cards task, and we discuss a model of spatial semantics in Section 3.", "labels": [], "entities": []}, {"text": "Using this task and a model of the meaning of spatial language, we next discuss two agents that play the game: ListenerBot (Section 4) makes decisions using a single-agent POMDP that does not take into account the beliefs or actions of its partner, whereas DialogBot (Section 5) maintains a model of its partner's beliefs.", "labels": [], "entities": []}, {"text": "As a result of the cooperative structure of the underlying model and the effects of communication within it, DialogBot's contributions are relevant, truthful, and informative, which leads to significantly improved task performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "We now experimentally evaluate our semantic classifiers and the agents' task performance.", "labels": [], "entities": []}, {"text": "We evaluated our ListenerBot and DialogBot agents in the Cards task.", "labels": [], "entities": []}, {"text": "Using 500 randomly generated initial player and card locations, we tested each combination of ListenerBot and DialogBot partners.", "labels": [], "entities": []}, {"text": "Agents succeeded at a given initial position if they both reached the card within 50 moves.", "labels": [], "entities": []}, {"text": "shows how many trials each dyad won and how many high-level actions they took to do so.", "labels": [], "entities": []}, {"text": "Collaborating DialogBots performed the best, completing more trials and using fewer moves than the ListenerBots.", "labels": [], "entities": []}, {"text": "The DialogBots initially explore the space in a similar manner to the ListenerBots, but then share card location information.", "labels": [], "entities": []}, {"text": "This leads to shorter interactions, as once the DialogBot finds the card, the other player can find it more quickly.", "labels": [], "entities": []}, {"text": "In the combination of ListenerBot and DialogBot, we see about half of the improvement over two ListenerBots.", "labels": [], "entities": []}, {"text": "Roughly 50% of the time, the ListenerBot finds the card first, which doesn't help the DialogBot find the card any faster.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: The evaluation for each combination of  agents. LB = ListenerBot; DB = DialogBot.", "labels": [], "entities": []}]}