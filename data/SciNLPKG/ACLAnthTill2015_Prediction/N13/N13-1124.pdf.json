{"title": [{"text": "Identifying Intention Posts in Discussion Forums", "labels": [], "entities": [{"text": "Identifying Intention Posts in Discussion Forums", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.9098826746145884}]}], "abstractContent": [{"text": "This paper proposes to study the problem of identifying intention posts in online discussion forums.", "labels": [], "entities": [{"text": "identifying intention posts in online discussion forums", "start_pos": 44, "end_pos": 99, "type": "TASK", "confidence": 0.7088188060692379}]}, {"text": "For example, in a discussion forum , a user wrote \"I plan to buy a camera,\" which indicates a buying intention.", "labels": [], "entities": []}, {"text": "This intention can be easily exploited by advertisers.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, there is still no reported study of this problem.", "labels": [], "entities": []}, {"text": "Our research found that this problem is particularly suited to transfer learning because in different domains , people express the same intention in similar ways.", "labels": [], "entities": [{"text": "transfer learning", "start_pos": 63, "end_pos": 80, "type": "TASK", "confidence": 0.9522769153118134}]}, {"text": "We then propose anew transfer learning method which, unlike a general transfer learning algorithm, exploits several special characteristics of the problem.", "labels": [], "entities": []}, {"text": "Experimental results show that the proposed method outperforms several strong baselines, including supervised learning in the target domain and a recent transfer learning method .", "labels": [], "entities": []}], "introductionContent": [{"text": "Social media content is increasingly regarded as an information goldmine.", "labels": [], "entities": []}, {"text": "Researchers have studied many problems in social media, e.g., sentiment analysis and social network analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.9582625329494476}, {"text": "social network analysis", "start_pos": 85, "end_pos": 108, "type": "TASK", "confidence": 0.6197949647903442}]}, {"text": "In this paper, we study a novel problem which is also of great value, namely, intention identification, which aims to identify discussion posts expressing certain user intentions that can be exploited by businesses or other interested parties.", "labels": [], "entities": [{"text": "intention identification", "start_pos": 78, "end_pos": 102, "type": "TASK", "confidence": 0.6896001994609833}]}, {"text": "For example, one user wrote, \"I am looking fora brand new car to replace my old Ford Focus\".", "labels": [], "entities": []}, {"text": "Identifying such intention automatically can help social media sites to decide what ads to display so that the ads are more likely to be clicked.", "labels": [], "entities": []}, {"text": "This work focuses on identifying user posts with explicit intentions.", "labels": [], "entities": []}, {"text": "By explicit we mean that the intention is explicitly stated in the text, no need to deduce (hidden or implicit intention).", "labels": [], "entities": []}, {"text": "For example, in the above sentence, the author clearly expressed that he/she wanted to buy a car.", "labels": [], "entities": []}, {"text": "On the other hand, an example of an implicit sentence is \"Anyone knows the battery life of iPhone?\"", "labels": [], "entities": []}, {"text": "The person mayor may not be thinking about buying an iPhone.", "labels": [], "entities": []}, {"text": "To our knowledge, there is no reported study of this problem in the context of text documents.", "labels": [], "entities": []}, {"text": "The main related work is in Web search, where user (or query) intent classification is a major issue (.", "labels": [], "entities": [{"text": "user (or query) intent classification", "start_pos": 46, "end_pos": 83, "type": "TASK", "confidence": 0.6891417418207441}]}, {"text": "Its task is to determine what the user is searching for based on his/her keyword queries (2 to 3 words) and his/her click data.", "labels": [], "entities": []}, {"text": "We will discuss this and other related work in Section 2.", "labels": [], "entities": []}, {"text": "We formulate the proposed problem as a twoclass classification problem since an application may only be interested in a particular intention.", "labels": [], "entities": [{"text": "twoclass classification problem", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.7723508874575297}]}, {"text": "We define intention posts (positive class) as the posts that explicitly express a particular intention of interest, e.g., the intention to buy a product.", "labels": [], "entities": []}, {"text": "The other posts are non-intention posts (negative class).", "labels": [], "entities": []}, {"text": "Note that we do not exploit intention specific knowledge since our aim is to propose a generic method applicable to different types of intentions.", "labels": [], "entities": []}, {"text": "There is an important feature about this problem which makes it amenable to transfer learning so that we do not need to label data in every domain.", "labels": [], "entities": []}, {"text": "That is, fora particular kind of intention such as buying, the ways to express the intention in different domains are often very similar.", "labels": [], "entities": []}, {"text": "This fact can be exploited to build a classifier based on labeled data in some domains and apply it to a new/target domain without labeling any training data in the target domain.", "labels": [], "entities": []}, {"text": "However, this problem also has some special difficulties that existing general transfer learning methods do not deal with.", "labels": [], "entities": []}, {"text": "The two special difficulties of the proposed problem are as follows: 1.", "labels": [], "entities": []}, {"text": "In an intention post, the intention is typically expressed in only one or two sentences while most sentences do not express intention, which provide very noisy data for classifiers.", "labels": [], "entities": []}, {"text": "Furthermore, words/phrases used for expressing intention are quite limited compared to other types of expressions.", "labels": [], "entities": []}, {"text": "These mean that the set of shared (or common) features in different domains is very small.", "labels": [], "entities": []}, {"text": "Most of the existing advanced transfer learning methods all try to extract and exploit these shared features.", "labels": [], "entities": []}, {"text": "The small number of such features in our task makes it hard for the existing methods to find them accurately, which in turn learn poorer classifiers.", "labels": [], "entities": []}, {"text": "2. As mentioned above, in different domains, the ways to express the same intention are often similar.", "labels": [], "entities": []}, {"text": "This means that only the positive (intention) features are shared among different domains, while features indicating the negative class in different domains are very diverse.", "labels": [], "entities": []}, {"text": "We then have an imbalance problem, i.e., the shared features are almost exclusively features indicating the positive class.", "labels": [], "entities": []}, {"text": "To our knowledge, none of the existing transfer learning methods deals with this imbalance problem of shared features, which also results in inaccurate classifiers.", "labels": [], "entities": []}, {"text": "We thus propose anew transfer learning (or domain adaptation) method, called Co-Class, which, unlike a general transfer learning method, is able to deal with these difficulties in solving the problem.", "labels": [], "entities": [{"text": "transfer learning (or domain adaptation)", "start_pos": 21, "end_pos": 61, "type": "TASK", "confidence": 0.6549873266901288}]}, {"text": "Co-Class works as follows: we first build a classifier using the labeled data from existing domains, called the source data, and then apply the classifier to classify the target (domain) data (which is unlabeled).", "labels": [], "entities": []}, {"text": "Based on the target data labeled by , we perform a feature selection on the target data.", "labels": [], "entities": []}, {"text": "The selected set of features is used to build two classifiers, one ( ) from the labeled source data and one ( ) from the target data which has been labeled by . The two classifiers ( and ) then work together to perform classification of the target data.", "labels": [], "entities": []}, {"text": "The process then runs iteratively until the labels assigned to the target data stabilize.", "labels": [], "entities": []}, {"text": "Note that in each iteration both classifiers are built using the same set of features selected from the target domain in order to focus on the target domain.", "labels": [], "entities": []}, {"text": "The proposed Co-Class explicitly deals with the difficulties mentioned above (see Section 3).", "labels": [], "entities": []}, {"text": "Our experiments using four real-life data sets extracted from four forum discussion sites show that Co-Class outperforms several strong baselines.", "labels": [], "entities": []}, {"text": "What is also interesting is that it works even better than fully supervised learning in the target domain itself, i.e., using both training and test data in the target domain.", "labels": [], "entities": []}, {"text": "It also outperforms a recent state-of-the-art transfer learning method (, which has been successfully applied to the NLP task of sentiment classification.", "labels": [], "entities": [{"text": "NLP task of sentiment classification", "start_pos": 117, "end_pos": 153, "type": "TASK", "confidence": 0.7082806646823883}]}, {"text": "In summary, this paper makes two main contributions: 1.", "labels": [], "entities": []}, {"text": "It proposes to study the novel problem of intention identification.", "labels": [], "entities": [{"text": "intention identification", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.7121364921331406}]}, {"text": "User intention is an important type of information in social media with many applications.", "labels": [], "entities": []}, {"text": "To our knowledge, there is still no reported study of this problem.", "labels": [], "entities": []}, {"text": "2. It proposes anew transfer learning method CoClass which is able to exploit the above two key issues/characteristics of the problem in building cross-domain classifiers.", "labels": [], "entities": []}, {"text": "Our experimental results demonstrate its effectiveness.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have conducted a comprehensive set of experiments to compare the proposed Co-Class method with several strong baselines, including a state-ofthe-art transfer learning method. and); 3 repeat 4 for each document in do 5  ; // predict the class of using 6 end 7 Produce data based on predicted class of ; 8 Select anew feature set from ; 9 Learn anew classifier on based on the new feature set ; 10 until the predicted classes of stabilize 11 Return the classifier from the last iteration.", "labels": [], "entities": []}, {"text": "Input: Labeled data and unlabeled data 1 Select a feature set based on IG from ; 2 Learn an initial na\u00ef ve Bayes classifier from based on (using Equations and  For our experiments, we are interested in the intention to buy, which is our intention or positive class.", "labels": [], "entities": []}, {"text": "For each dataset, we manually labeled 1000 posts.", "labels": [], "entities": []}, {"text": "Labeling: We initially labeled about one fifth of posts by two human annotators.", "labels": [], "entities": []}, {"text": "We found their labels highly agreed.", "labels": [], "entities": []}, {"text": "We then used only one annotator to complete the remaining labeling.", "labels": [], "entities": []}, {"text": "The reason for the strong labeling agreement is that we are interested in only explicit buying intentions, which are clearly expressed in each post, e.g., \"I am in the market fora new smartphone.\"", "labels": [], "entities": []}, {"text": "There is little ambiguity or subjectivity in labeling.", "labels": [], "entities": []}, {"text": "To ensure that the task is realistic, for all datasets we keep their original class distributions as they are extracted from their respective websites to reflect the real-life situation.", "labels": [], "entities": []}, {"text": "The intention class is always the minority class, which makes it much harder to predict due to the imbalanced class distribution.", "labels": [], "entities": []}, {"text": "gives the statistics of each dataset.", "labels": [], "entities": []}, {"text": "On average, each post contains about 7.5 sentences and 122 words.", "labels": [], "entities": []}, {"text": "We have made the datasets used in this paper publically available at the websites of the first two authors.", "labels": [], "entities": []}, {"text": "For all experiments, we use precision, recall and F1-score as the evaluation measures.", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.999748170375824}, {"text": "recall", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.9994962215423584}, {"text": "F1-score", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9989331364631653}]}, {"text": "They are suitable because our objective is to identify intention posts.", "labels": [], "entities": []}, {"text": "We now compare Co-Class with the baseline methods listed below.", "labels": [], "entities": []}, {"text": "Note that for this set of experiments, the source data all contain labeled posts from three domains and the target data contain unlabeled posts in one domain.", "labels": [], "entities": []}, {"text": "That is, for each target domain, we merge three other domains for training and the target domain for testing.", "labels": [], "entities": []}, {"text": "For example, for the target of \"Cellphone\", the model is built using the data from the other three domains (i.e., \"Electronics\", \"Camera\" and \"TV\").", "labels": [], "entities": []}, {"text": "The results are the classification of the model on the target domain \"Cellphone\".", "labels": [], "entities": []}, {"text": "Several strong baselines are described as follows: 3TR-1TE: Use labeled data from three domains to train and then classify the target (test) domain.", "labels": [], "entities": [{"text": "3TR-1TE", "start_pos": 51, "end_pos": 58, "type": "METRIC", "confidence": 0.461842805147171}]}, {"text": "This method was used in.", "labels": [], "entities": []}, {"text": "EM: This is the algorithm in Section 3.1.", "labels": [], "entities": [{"text": "EM", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.6203005909919739}]}, {"text": "The combined data from three domains are used as the labeled source data.", "labels": [], "entities": []}, {"text": "The data of the remaining one domain are used as the unlabeled target data, which is also used as the test data (since it is unlabeled).", "labels": [], "entities": []}, {"text": "ANB: This is a recent transfer learning method (.", "labels": [], "entities": [{"text": "ANB", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.45187026262283325}]}, {"text": "ANB uses frequently cooccurring entropy (FCE) to pick out generalizable (or shared) features that occur frequently in both the source and target domains.", "labels": [], "entities": []}, {"text": "Then, a weighted transfer version of na\u00ef ve Bayes classifier is applied.", "labels": [], "entities": []}, {"text": "We chose this method for comparison as it is a recent method, also based on na\u00ef ve Bayes, and has been applied to the NLP task of sentiment Unigrams, 59   classification, which to some extend is related to the proposed task of intention classification.", "labels": [], "entities": [{"text": "NLP task of sentiment Unigrams, 59   classification", "start_pos": 118, "end_pos": 169, "type": "TASK", "confidence": 0.5035177730023861}, {"text": "intention classification", "start_pos": 227, "end_pos": 251, "type": "TASK", "confidence": 0.7116791605949402}]}, {"text": "ANB was also shown to perform better than EM and na\u00ef ve Bayes transfer learning method.", "labels": [], "entities": [{"text": "ANB", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.4800035357475281}]}, {"text": "We look at the results of 3TR-1TE first, which are shown in.", "labels": [], "entities": [{"text": "3TR-1TE", "start_pos": 26, "end_pos": 33, "type": "DATASET", "confidence": 0.7637759447097778}]}, {"text": "Due to space limitations, we only show the trigrams F1-scores as they perform the best on average.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9547735452651978}]}, {"text": "gives the number of features with trigrams.", "labels": [], "entities": []}, {"text": "We can observe that on average using 3000 features gives the best F1-score results.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9994064569473267}]}, {"text": "It has 1000 more features than one domain learning because we now combine three domains (3000 posts) for training and thus more useful features.", "labels": [], "entities": []}, {"text": "From, we observe that the F1-score results of 3TR-1TE are worse than those of one domain learning, which is intuitive because no training data are used from the target domain.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.999290943145752}, {"text": "3TR-1TE", "start_pos": 46, "end_pos": 53, "type": "DATASET", "confidence": 0.7428897619247437}]}, {"text": "But the results are not dramatically worse which indicate that there are some common features in different domains, meaning people expressing the same intention in similar ways.", "labels": [], "entities": []}, {"text": "Since we found that trigrams with 3000 features perform the best on average, we run EM, FS-EM1, FS-EM2 and Co-Class based on trigrams with 3000 features.", "labels": [], "entities": [{"text": "FS-EM1", "start_pos": 88, "end_pos": 94, "type": "METRIC", "confidence": 0.7774726748466492}, {"text": "FS-EM2", "start_pos": 96, "end_pos": 102, "type": "DATASET", "confidence": 0.6429422497749329}]}, {"text": "For the baseline ANB, we tuned the parameters using a development set (1/10 of the training data).", "labels": [], "entities": [{"text": "ANB", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.738694965839386}]}, {"text": "We found that selecting 2000 generalizable/shared features gives the best results (the default is 500 in ().", "labels": [], "entities": []}, {"text": "We kept ANB's other original parameter values.", "labels": [], "entities": [{"text": "ANB", "start_pos": 8, "end_pos": 11, "type": "DATASET", "confidence": 0.5165597200393677}]}, {"text": "The F1-scores (averages overall 4 datasets) with the number of iterations are shown in.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.998648464679718}]}, {"text": "Iteration 0 is the result of 3TR-1TE.", "labels": [], "entities": [{"text": "3TR-1TE", "start_pos": 29, "end_pos": 36, "type": "DATASET", "confidence": 0.8203607797622681}]}, {"text": "From, we can make the following observations: 1.", "labels": [], "entities": []}, {"text": "EM makes a little improvement in iteration 1.", "labels": [], "entities": [{"text": "EM", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.9589579105377197}]}, {"text": "After that, the results deteriorate.", "labels": [], "entities": []}, {"text": "The gain of iteration 1 shows that incorporating the target domain data (unlabeled) is helpful.", "labels": [], "entities": []}, {"text": "However, the selected features from source domains can only fit the labeled source data but not the target data, which was explained in Section 3.1. 2. ANB improves slightly from iteration 1 to iteration 6, but the results are all worse than those of Co-Class.", "labels": [], "entities": []}, {"text": "We checked the generalizable/shared features of ANB and found that they were not suitable for our problem since they were mainly adjectives, nouns and sentiment verbs, which do not have strong correlation with intentions.", "labels": [], "entities": []}, {"text": "This shows that it is hard to find the truly shared features indicating intentions.", "labels": [], "entities": []}, {"text": "Furthermore, ANB's results are almost the same as those of EM.", "labels": [], "entities": [{"text": "ANB", "start_pos": 13, "end_pos": 16, "type": "METRIC", "confidence": 0.6176949143409729}, {"text": "EM", "start_pos": 59, "end_pos": 61, "type": "DATASET", "confidence": 0.6272972822189331}]}, {"text": "3. FS-EM2 behaves similarly to FS-EM1.", "labels": [], "entities": [{"text": "FS-EM2", "start_pos": 3, "end_pos": 9, "type": "DATASET", "confidence": 0.69419926404953}, {"text": "FS-EM1", "start_pos": 31, "end_pos": 37, "type": "DATASET", "confidence": 0.8758620023727417}]}, {"text": "After two iterations, the results start to deteriorate.", "labels": [], "entities": []}, {"text": "Selecting features only from the target domain makes sense since it can reflect target domain data well.", "labels": [], "entities": []}, {"text": "However, it also becomes worse with the increased number of iterations, due to strong positive features.", "labels": [], "entities": []}, {"text": "With increased iterations, positive features get stronger due to the imbalanced feature problem discussed in Section 1. 4. Co-Class performs much better than all other methods.", "labels": [], "entities": []}, {"text": "With the increased number of iterations, the results actually improve.", "labels": [], "entities": []}, {"text": "Starting from iteration 7, the results stabilize.", "labels": [], "entities": []}, {"text": "Co-Class solves the problem of strong positive features by requiring strong conditions for positive classification and focusing on features in the target domain only.", "labels": [], "entities": []}, {"text": "Although the detailed results of precision and recall are not shown, the Co-Class model actually improves the F1-score by improving both the precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9995965361595154}, {"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.998846173286438}, {"text": "F1-score", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9987353682518005}, {"text": "precision", "start_pos": 141, "end_pos": 150, "type": "METRIC", "confidence": 0.99956876039505}, {"text": "recall", "start_pos": 155, "end_pos": 161, "type": "METRIC", "confidence": 0.9973576664924622}]}, {"text": "Significance of improvement: We now discuss the significance of improvements by comparing the results of Co-Class with other models.", "labels": [], "entities": []}, {"text": "summarizes the results among the models.", "labels": [], "entities": []}, {"text": "For Co-Class, we use the converged models at iteration 7.", "labels": [], "entities": []}, {"text": "We also include the One Domain learning results which are from fully supervised classification in the target domains with trigrams and 1500 features.", "labels": [], "entities": []}, {"text": "The results of 3TR-1TE, EM, ANB, FS-EM1, and FS-EM2 are obtained based on their settings which give the best results in.", "labels": [], "entities": [{"text": "3TR-1TE", "start_pos": 15, "end_pos": 22, "type": "DATASET", "confidence": 0.737372100353241}, {"text": "ANB", "start_pos": 28, "end_pos": 31, "type": "METRIC", "confidence": 0.8732977509498596}, {"text": "FS-EM1", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9596930742263794}, {"text": "FS-EM2", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.8391324281692505}]}, {"text": "It is clear from that Co-Class is the best method in general.", "labels": [], "entities": []}, {"text": "It is even better than the fully supervised One-Domain learning, although their results are not strictly comparable because OneDomain learning uses training and test data from the same domain via 10-fold cross validation, while all other methods use one domain as the test data (the labeled data are from the other three domains).", "labels": [], "entities": []}, {"text": "One possible reason is that the labeled data are much bigger than those in One-Domain learning, which contain more expressions of buying intention.", "labels": [], "entities": []}, {"text": "Note that FS-EM1 and FS-EM2 work slightly better than Co-Class in domain \"Camera\" because it is the least noisy domain with very short posts while other domains (as source data) are quite noisy.", "labels": [], "entities": [{"text": "FS-EM1", "start_pos": 10, "end_pos": 16, "type": "DATASET", "confidence": 0.6303734183311462}, {"text": "FS-EM2", "start_pos": 21, "end_pos": 27, "type": "DATASET", "confidence": 0.8355619311332703}]}, {"text": "With good quality data, FS-EM1 and FS-EM2 (also proposed in this paper) can do slightly better than Co-Class.", "labels": [], "entities": [{"text": "FS-EM1", "start_pos": 24, "end_pos": 30, "type": "DATASET", "confidence": 0.6589502096176147}, {"text": "FS-EM2", "start_pos": 35, "end_pos": 41, "type": "DATASET", "confidence": 0.7695764303207397}]}, {"text": "Statistical paired t-test shows that Co-Class performs significantly better than baseline methods 3TR-1TE, EM, ANB and FS-EM1 at the confidence level of 95%, and better than FS-EM2 at the confidence level of 94%.", "labels": [], "entities": [{"text": "3TR-1TE", "start_pos": 98, "end_pos": 105, "type": "DATASET", "confidence": 0.7502435445785522}, {"text": "ANB", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.7977012395858765}, {"text": "FS-EM1", "start_pos": 119, "end_pos": 125, "type": "METRIC", "confidence": 0.9138202667236328}, {"text": "FS-EM2", "start_pos": 174, "end_pos": 180, "type": "DATASET", "confidence": 0.6225546598434448}]}], "tableCaptions": [{"text": " Table 1: Datasets statistics with the buy intention", "labels": [], "entities": []}, {"text": " Table 2: One-domain learning using na\u00ef ve Bayes with n-grams (with best no. of features)", "labels": [], "entities": []}, {"text": " Table 3: F1-scores of 3TR-1TE with trigrams and different no. of features", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.997808039188385}]}, {"text": " Table 4: F1-score results of One-Domain, 3TR-1TE, EM, ANB, FS-EM1, FS-EM2, and Co-Class", "labels": [], "entities": [{"text": "F1-score", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9993058443069458}, {"text": "ANB", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.8665521740913391}, {"text": "FS-EM1", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9164077043533325}, {"text": "FS-EM2", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.5572589039802551}]}]}