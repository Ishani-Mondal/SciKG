{"title": [{"text": "Supervised Learning of Complete Morphological Paradigms", "labels": [], "entities": [{"text": "Supervised Learning of Complete Morphological Paradigms", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.7399682998657227}]}], "abstractContent": [{"text": "We describe a supervised approach to predicting the set of all inflected forms of a lexical item.", "labels": [], "entities": [{"text": "predicting the set of all inflected forms of a lexical item", "start_pos": 37, "end_pos": 96, "type": "TASK", "confidence": 0.5918269401246851}]}, {"text": "Our system automatically acquires the orthographic transformation rules of morphological paradigms from labeled examples, and then learns the contexts in which those transformations apply using a discriminative sequence model.", "labels": [], "entities": []}, {"text": "Because our approach is completely data-driven and the model is trained on examples extracted from Wiktionary, our method can extend to new languages without change.", "labels": [], "entities": []}, {"text": "Our end-to-end system is able to predict complete paradigms with 86.1% accuracy and individual inflected forms with 94.9% accuracy , averaged across three languages and two parts of speech.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9959600567817688}, {"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.997657299041748}]}], "introductionContent": [{"text": "For natural languages with rich morphology, knowledge of how to inflect base forms is critical for both text generation and analysis.", "labels": [], "entities": [{"text": "text generation", "start_pos": 104, "end_pos": 119, "type": "TASK", "confidence": 0.759956419467926}]}, {"text": "Hand-engineered, rulebased methods for predicting inflections can offer extremely high accuracy, but they are laborious to construct and do not exist with full lexical coverage in all languages.", "labels": [], "entities": [{"text": "predicting inflections", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.9002271592617035}, {"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.996250569820404}]}, {"text": "By contrast, a large number of example inflections are freely available in a semistructured format on the Web.", "labels": [], "entities": []}, {"text": "The English Wiktionary 1 is a crowd-sourced lexical resource that includes complete inflection tables for many lexical items in many languages.", "labels": [], "entities": [{"text": "English Wiktionary 1", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.8345454931259155}]}, {"text": "We present a supervised system that, given only data from Wiktionary, automatically discovers and learns to apply the orthographic transformations governing a language's inflectional morphology.", "labels": [], "entities": []}, {"text": "Our data-driven approach is designed to extend to any language for which we have a substantial number of example inflection tables.", "labels": [], "entities": []}, {"text": "The design of our model is guided by three structural assumptions: 1.", "labels": [], "entities": []}, {"text": "The inflections of many lexical items are governed by a few repeated morphological paradigms.", "labels": [], "entities": []}, {"text": "2. A morphological paradigm can be decomposed into independent orthographic transformation rules (including prefix, suffix, and stem changes), which are triggered by orthographic context.", "labels": [], "entities": []}, {"text": "3. A base form is transformed in consistent, correlated ways to produce its inflected variants.", "labels": [], "entities": []}, {"text": "Learning proceeds in two stages that both utilize the same training set of labeled inflection tables.", "labels": [], "entities": []}, {"text": "First, an inventory of interpretable transformation rules is generated by aligning each base form to all of its inflected forms.", "labels": [], "entities": []}, {"text": "Second, a semi-Markov conditional random field (CRF) () is trained to apply these rules correctly to unseen base forms.", "labels": [], "entities": []}, {"text": "As we demonstrate experimentally, the CRF is most effective when jointly predicting all inflected forms of a lexical item together, forcing the system to adopt a single consistent analysis of each base form.", "labels": [], "entities": []}, {"text": "Previous work has also described supervised and semi-supervised approaches to predicting inflectional morphology.", "labels": [], "entities": [{"text": "predicting inflectional morphology", "start_pos": 78, "end_pos": 112, "type": "TASK", "confidence": 0.9170519113540649}]}, {"text": "Our approach differs primarily in its use of automatically extracted morphological rules and our discriminative prediction method which jointly models entire inflection tables.", "labels": [], "entities": []}, {"text": "These modeling choices are directly inspired by the data setting: Wiktionary contains complete inflection tables for many lexical items in each of a large number of languages, so it is natural to make full use of this information with a joint model of all inflected forms.", "labels": [], "entities": []}, {"text": "We evaluate our predictions on held-out Wiktionary inflection tables for three languages and two parts of speech.", "labels": [], "entities": []}, {"text": "Our language-independent method predicts inflections for unseen base forms with accuracies ranging from 88.9% (German nouns) to 99.7% (Spanish verbs).", "labels": [], "entities": []}, {"text": "For comparability with previous work, we also evaluate our approach on German verb forms in the CELEX lexical database (.", "labels": [], "entities": [{"text": "CELEX lexical database", "start_pos": 96, "end_pos": 118, "type": "DATASET", "confidence": 0.9757566253344218}]}, {"text": "Our approach outperforms the semi-supervised hierarchical Bayesian model of, while employing scalable exact inference and interpretable transformation rules.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our model under two experimental conditions.", "labels": [], "entities": []}, {"text": "First, we use the German verb lexicon in the CELEX lexical database ( with the same train/test splits as.", "labels": [], "entities": [{"text": "CELEX lexical database", "start_pos": 45, "end_pos": 67, "type": "DATASET", "confidence": 0.9723509152730306}]}, {"text": "Second, we train on our Wiktionary data described in Section 5 and evaluate on held-out forms from this same dataset.", "labels": [], "entities": [{"text": "Wiktionary data", "start_pos": 24, "end_pos": 39, "type": "DATASET", "confidence": 0.7360540628433228}]}, {"text": "In each case, we evaluate two variants of our model in order to examine the importance of jointly modeling the production of the entire inflection table.", "labels": [], "entities": []}, {"text": "Our JOINT model is exactly as defined in Section 4.", "labels": [], "entities": [{"text": "JOINT", "start_pos": 4, "end_pos": 9, "type": "TASK", "confidence": 0.4570499062538147}]}, {"text": "For our FACTORED model, the dictionary of rules is extracted separately for each setting of the attributes a; i.e., we run the entire procedure in Section 3 with only one inflected format a time and forego the UNIONSPANS step.", "labels": [], "entities": []}, {"text": "A separate prediction model is trained for each a and so features are not shared across multiple predictions as they are in the JOINT case.", "labels": [], "entities": [{"text": "JOINT", "start_pos": 128, "end_pos": 133, "type": "TASK", "confidence": 0.6098926663398743}]}, {"text": "Note that this FACTORED approach, with blank results unreported in that work.", "labels": [], "entities": [{"text": "FACTORED", "start_pos": 15, "end_pos": 23, "type": "DATASET", "confidence": 0.40819329023361206}]}, {"text": "Our FACTORED model is able to do approximately as well as the DE11 baseline method, and our JOINT model performs better yet, performing comparably to DE11+CORPUS, which uses additional monolingual text.", "labels": [], "entities": []}, {"text": "All models substantially outperform the NA\u00a8IVENA\u00a8IVE suffixing baseline.", "labels": [], "entities": [{"text": "NA\u00a8IVENA\u00a8IVE suffixing", "start_pos": 40, "end_pos": 62, "type": "METRIC", "confidence": 0.7883773843447367}]}, {"text": "The relatively low ORACLE accuracy indicates that some errors arise from failing to apply rules that are not attested in these small training sets.", "labels": [], "entities": [{"text": "ORACLE", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9944593906402588}, {"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.7668538093566895}]}, {"text": "can produce inflection tables that the JOINT model cannot, due to its ability to \"mix and match\" orthographic changes in the same inflection table.", "labels": [], "entities": []}, {"text": "We also evaluate a NA\u00a8IVENA\u00a8IVE method for applying the joint rules which selects the most common suffix rule available after pruning.", "labels": [], "entities": [{"text": "NA\u00a8IVENA\u00a8IVE", "start_pos": 19, "end_pos": 31, "type": "METRIC", "confidence": 0.9071189761161804}]}, {"text": "Finally, we report the ORACLE accuracy attainable with the morphological rule dictionary of the JOINT model.", "labels": [], "entities": [{"text": "ORACLE", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.9987969398498535}, {"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.8960968255996704}, {"text": "JOINT", "start_pos": 96, "end_pos": 101, "type": "DATASET", "confidence": 0.7568243741989136}]}, {"text": "For our conditional likelihood objective, we use \u03b3 = 0.0002; this parameter and the feature set were tuned on a small development set and held fixed for all experiments.", "labels": [], "entities": []}, {"text": "Dreyer and Eisner (2011) construct ten train/test splits of the 5615 German verb forms in the CELEX lexical database, keeping 200 forms for training in each case, which they further subsample.", "labels": [], "entities": [{"text": "CELEX lexical database", "start_pos": 94, "end_pos": 116, "type": "DATASET", "confidence": 0.9700316389401754}]}, {"text": "These random splits serve to control for instability due to the small training set sizes.", "labels": [], "entities": []}, {"text": "Each infinitive verb form has 22 corresponding inflected forms capturing variation such as person, number, mood, and tense.", "labels": [], "entities": []}, {"text": "shows our results compared to those of.", "labels": [], "entities": []}, {"text": "The FACTORED model performs on par with the DE11 baseline model, but the stronger performance of the JOINT model indicates that making joint predictions is important.", "labels": [], "entities": [{"text": "FACTORED", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.8794647455215454}, {"text": "DE11 baseline", "start_pos": 44, "end_pos": 57, "type": "DATASET", "confidence": 0.9284125864505768}]}, {"text": "With 100 training examples, our model is able to equal the performance of DE11+CORPUS, which additionally uses ten million tokens of monolingual German text.", "labels": [], "entities": [{"text": "DE11+CORPUS", "start_pos": 74, "end_pos": 85, "type": "DATASET", "confidence": 0.7853323817253113}]}, {"text": "We emphasize that this is not the data condition for which our model was designed.", "labels": [], "entities": []}, {"text": "It is unfavorable for two reasons: first, feature-rich models can be learned more stably on larger training sets, and second, the train/test splits are chosen randomly, and therefore the test sets may contain completely irregular verbs using morphological rules that we have never observed.", "labels": [], "entities": []}, {"text": "As can be seen from the ORA-CLE results in, a substantial fraction of the missed test examples cannot be produced using our extracted rules simply because we have not seen the relevant examples; in many cases, even a human could not generalize correctly from the given examples without exploiting external knowledge of the German language.", "labels": [], "entities": [{"text": "ORA-CLE", "start_pos": 24, "end_pos": 31, "type": "METRIC", "confidence": 0.9951550960540771}]}], "tableCaptions": [{"text": " Table 3: Number of full morphology tables extracted  from Wiktionary for each language and part of speech  pair that we considered, as well as the number of inflected  forms associated with each base form.", "labels": [], "entities": []}, {"text": " Table 4: Accuracies on reconstructing individual in- flected forms in CELEX, averaged over the 5415 inflec- tion tables in each of 10 test sets. Three training set  sizes are reported. DE11 indicates a reported result from  Dreyer and Eisner", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9948004484176636}, {"text": "CELEX", "start_pos": 71, "end_pos": 76, "type": "DATASET", "confidence": 0.939002513885498}, {"text": "DE11", "start_pos": 186, "end_pos": 190, "type": "METRIC", "confidence": 0.8890604376792908}]}, {"text": " Table 5: Accuracies on reconstructing complete inflection tables and individual inflected forms for held-out base forms  in our Wiktionary dataset. Results are shown for our fully JOINT model, a FACTORED model that predicts individual  inflected forms independently, a NA\u00a8IVENA\u00a8IVE baseline that picks the most common applicable suffix rule, and an ORACLE  that selects the best inflection table within our model's capacity. For each language and part of speech, regardless of  training set size, evaluation is based on a blind test set of 200 held-out forms.", "labels": [], "entities": [{"text": "Wiktionary dataset", "start_pos": 129, "end_pos": 147, "type": "DATASET", "confidence": 0.8974269032478333}, {"text": "NA\u00a8IVENA\u00a8IVE baseline", "start_pos": 270, "end_pos": 291, "type": "METRIC", "confidence": 0.8283670842647552}, {"text": "ORACLE", "start_pos": 350, "end_pos": 356, "type": "METRIC", "confidence": 0.9973374009132385}]}, {"text": " Table 6: Breakdown of errors by morphological rule be- ing applied by the JOINT model on the DE-NOUNS devel- opment set. We show the rule itself, treating the nomina- tive singular as the base form, an example of a German  word using that rule, and then the model's accuracy at  predicting applications of that rule. Errors are spread out  over many rules, but it generally appears that common  rules are to blame for the errors that are made, due in  large part to gender confusion in this case.", "labels": [], "entities": [{"text": "DE-NOUNS devel- opment set", "start_pos": 94, "end_pos": 120, "type": "DATASET", "confidence": 0.6749042630195617}, {"text": "accuracy", "start_pos": 267, "end_pos": 275, "type": "METRIC", "confidence": 0.9986839890480042}]}]}