{"title": [{"text": "Using Semantic Unification to Generate Regular Expressions from Natural Language", "labels": [], "entities": []}], "abstractContent": [{"text": "We consider the problem of translating natural language text queries into regular expressions which represent their meaning.", "labels": [], "entities": [{"text": "translating natural language text queries", "start_pos": 27, "end_pos": 68, "type": "TASK", "confidence": 0.8292057633399963}]}, {"text": "The mis-match in the level of abstraction between the natural language representation and the regular expression representation make this a novel and challenging problem.", "labels": [], "entities": []}, {"text": "However, a given regular expression can be written in many semantically equivalent forms, and we exploit this flexibility to facilitate translation by finding a form which more directly corresponds to the natural language.", "labels": [], "entities": [{"text": "translation", "start_pos": 136, "end_pos": 147, "type": "TASK", "confidence": 0.9646573066711426}]}, {"text": "We evaluate our technique on a set of natural language queries and their associated regular expressions which we gathered from Amazon Mechanical Turk.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 127, "end_pos": 149, "type": "DATASET", "confidence": 0.944508413473765}]}, {"text": "Our model substantially outperforms a state-of-the-art semantic parsing baseline, yielding a 29% absolute improvement inaccuracy.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 55, "end_pos": 71, "type": "TASK", "confidence": 0.7211333364248276}]}], "introductionContent": [{"text": "Regular expressions (regexps) have proven themselves to bean extremely powerful and versatile formalism that has made its way into everything from spreadsheets to databases.", "labels": [], "entities": []}, {"text": "However, despite their usefulness and wide availability, they are still considered a dark art that even many programmers do not fully understand).", "labels": [], "entities": []}, {"text": "Thus, the ability to automatically generate regular expressions from natural language would be useful in many contexts.", "labels": [], "entities": []}, {"text": "Our goal is to learn to generate regexps from natural language, using a training set of natural language and regular expression pairs such as the one in.", "labels": [], "entities": []}, {"text": "We do not assume that the data includes an alignment between fragments of the natural language and fragments of the regular expression.", "labels": [], "entities": []}, {"text": "In- The dataset used in this work is available at http://groups.csail.mit.edu/rbg/code/regexp/ Text Description Regular Expression three letter word starting with 'X' \\bX[A-Za-z]{2}\\b Figure 1: An example text description and its associated regular expression.", "labels": [], "entities": []}, {"text": "ducing such an alignment during learning is particularly challenging because oftentimes even humans are unable to perform a fragment-by-fragment alignment.", "labels": [], "entities": [{"text": "ducing", "start_pos": 0, "end_pos": 6, "type": "TASK", "confidence": 0.9798301458358765}]}, {"text": "We can think of this task as an instance of grounded semantic parsing, similar to the work done in the domain of database queries.", "labels": [], "entities": [{"text": "grounded semantic parsing", "start_pos": 44, "end_pos": 69, "type": "TASK", "confidence": 0.7048176129659017}]}, {"text": "However, the current success in semantic parsing relies on two important properties of the data.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.8576535582542419}]}, {"text": "First, while the past work did not assume the alignment was given, they did assume that finding a fine grained fragmentby-fragment alignment was possible.", "labels": [], "entities": []}, {"text": "Secondly, the semantic domains considered in the past were strongly typed.", "labels": [], "entities": []}, {"text": "This typing provides constraints which significantly reduce the space of possible parses, thereby greatly reducing the ambiguity.", "labels": [], "entities": []}, {"text": "However, in many interesting domains these two properties may not hold.", "labels": [], "entities": []}, {"text": "In our domain, the alignment between the natural language and the regular expressions often happens at the level of the whole phrase, making fragment-by-fragment alignment impossible.", "labels": [], "entities": []}, {"text": "For example, in no fragment of the regexp maps clearly to the phrase \"three letter\".", "labels": [], "entities": []}, {"text": "Instead, the regexp explicitly represents the fact that there is only two characters after X, which is not stated explicitly by the text description and must be inferred.", "labels": [], "entities": []}, {"text": "Furthermore, regular expressions have relatively few type constraints.", "labels": [], "entities": []}, {"text": "The key idea of our work is to utilize semantic unification in the logical domain to disambiguate the meaning of the natural language.", "labels": [], "entities": [{"text": "semantic unification", "start_pos": 39, "end_pos": 59, "type": "TASK", "confidence": 0.7654160261154175}]}, {"text": "Semantic unification utilizes an inference engine to determine the semantic equality of two syntactically divergent expressions.", "labels": [], "entities": [{"text": "Semantic unification", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8587793111801147}]}, {"text": "This is a departure from past work on semantic parsing which has largely focused on the syntactic interface between the natural language and the logical form, and on example-based semantic equality, neither of which utilize the inference power inherent in many symbolic domains.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 38, "end_pos": 54, "type": "TASK", "confidence": 0.7322983294725418}]}, {"text": "To see how we can take advantage of semantic unification, consider the regular expression in.", "labels": [], "entities": [{"text": "semantic unification", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.7767857313156128}]}, {"text": "This regular expression is semantically equivalent to the regular expression in.", "labels": [], "entities": []}, {"text": "Furthermore, it admits a fragment-by-fragment mapping as can be seen in(b).", "labels": [], "entities": []}, {"text": "In contrast, as we noted earlier, the regexp in does not admit such a mapping.", "labels": [], "entities": []}, {"text": "In fact, learning can be quite difficult if our training data contains only the regexp in.", "labels": [], "entities": []}, {"text": "We can, nonetheless, use the regexp in as a stepping-stone for learning if we can use semantic inference to determine the equivalence between the two regular expressions.", "labels": [], "entities": []}, {"text": "More generally, whenever the regexp in the training data does not factorize in away that facilitates a direct mapping to the natural language description, we must find a regexp which does factorize and be able to compute its equivalence to the regexp we see in the training data.", "labels": [], "entities": []}, {"text": "We compute this equivalence by converting each regexp to a minimal deterministic finite automaton (DFA) and leveraging the fact that minimal DFAs are guaranteed to be the same for semantically equivalent regexps.", "labels": [], "entities": []}, {"text": "We handle the additional ambiguity stemming from the weak typing in our domain through the use of a more effective parsing algorithm.", "labels": [], "entities": []}, {"text": "The state of the art semantic parsers) utilize a pruned chart parsing algorithm which fails to represent many of the top parses and is prohibitively slow in the face of weak typing.", "labels": [], "entities": []}, {"text": "In contrast, we use an n-best parser which always represents the most likely parses, and can be made very efficient through the use of the parsing algorithm from.", "labels": [], "entities": []}, {"text": "Our approach works by inducing a combinatory categorial grammar (CCG)).", "labels": [], "entities": []}, {"text": "This grammar consists of a lexicon which pairs words or phrases with regular expression functions.", "labels": [], "entities": []}, {"text": "The learning process initializes the lexicon by pairing each sentence in the training data with the full regular expression associated with it.", "labels": [], "entities": []}, {"text": "These lexical entries are iteratively refined by considering all possible ways to split the regular expression and all possible ways to split the phrase.", "labels": [], "entities": []}, {"text": "At each iteration we find the n-best parses with the current lexicon, and find the subset of these parses which are correct using DFA equivalence.", "labels": [], "entities": []}, {"text": "We update the weights of a log-linear model based on these parses and the calculated DFA equivalence.", "labels": [], "entities": []}, {"text": "We evaluate our technique using a dataset of sentence/regular expression pairs which we generated using Amazon Mechanical Turk.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 104, "end_pos": 126, "type": "DATASET", "confidence": 0.9504121939341227}]}, {"text": "We find that our model generates the correct regexp for 66% of sentences, while the state-of-the-art semantic parsing technique from generates correct regexps for only 37% of sentences.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 101, "end_pos": 117, "type": "TASK", "confidence": 0.7603683769702911}]}, {"text": "The results confirm our hypothesis that leveraging the inference capabilities of the semantic domain can help disambiguate natural language meaning.", "labels": [], "entities": []}], "datasetContent": [{"text": "Dataset Our dataset consists of 824 natural language and regular expression pairs gathered using Amazon Mechanical Turk and oDesk.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 97, "end_pos": 119, "type": "DATASET", "confidence": 0.9488929907480875}, {"text": "oDesk", "start_pos": 124, "end_pos": 129, "type": "DATASET", "confidence": 0.8657827377319336}]}, {"text": "On Mechanical Turk we asked workers to generate their own original natural language queries to capture a subset of the lines in a file (similar to UNIX grep).", "labels": [], "entities": []}, {"text": "In order to compare to example based techniques we also ask the Mechanical Turk workers to generate 5 positive and 5 negative examples for each query.", "labels": [], "entities": []}, {"text": "On oDesk we hired a set of programmers to generate regular expressions for each of these natural language queries.", "labels": [], "entities": [{"text": "oDesk", "start_pos": 3, "end_pos": 8, "type": "DATASET", "confidence": 0.9295663833618164}]}, {"text": "We split our data into 3 sets of 275 queries each and tested using 3-fold cross validation.", "labels": [], "entities": []}, {"text": "We tuned our parameters separately on each development set but ended up with the same values in each case.", "labels": [], "entities": []}, {"text": "We evaluate by comparing the generated regular expression for each sentence with the correct regular expression using our DFA equivalence technique.", "labels": [], "entities": []}, {"text": "As discussed in \u00a73.1 this metric is exact, indicating whether the generated regular expression is semantically equivalent to the correct regular expression.", "labels": [], "entities": []}, {"text": "Additionally, as discussed in \u00a76, our identity lexical entries ensure we generate a valid parse for every sentence, so we report only accuracy instead of precision and recall.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 134, "end_pos": 142, "type": "METRIC", "confidence": 0.9993108510971069}, {"text": "precision", "start_pos": 154, "end_pos": 163, "type": "METRIC", "confidence": 0.9994494318962097}, {"text": "recall", "start_pos": 168, "end_pos": 174, "type": "METRIC", "confidence": 0.9978265166282654}]}, {"text": "Baselines We compared against six different baselines.", "labels": [], "entities": []}, {"text": "The UBL baseline uses the published code from after configuring it to handle the lambda calculus format of our regular expressions.", "labels": [], "entities": [{"text": "UBL baseline", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.8908290565013885}]}, {"text": "7 The other baselines are ablated and/or modified versions of our model.", "labels": [], "entities": []}, {"text": "The BeamParse baselines replace the N-BEST procedure from Algorithm 1 with the beam search algorithm used for parsing by past CCG parsers.", "labels": [], "entities": [{"text": "BeamParse baselines", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.7687165141105652}, {"text": "parsing by past CCG parsers", "start_pos": 110, "end_pos": 137, "type": "TASK", "confidence": 0.7565803527832031}]}, {"text": "The StringUnify baseline replaces the DFA-EQUAL procedure from Algorithm 1 with exact regular expression string equality.", "labels": [], "entities": []}, {"text": "The HeuristicUnify baselines strengthen this by replacing DFA-EQUAL with a smart heuristic form of semantic unification.", "labels": [], "entities": [{"text": "HeuristicUnify baselines", "start_pos": 4, "end_pos": 28, "type": "DATASET", "confidence": 0.7939277291297913}, {"text": "semantic unification", "start_pos": 99, "end_pos": 119, "type": "TASK", "confidence": 0.7539476156234741}]}, {"text": "Our heuristic unification procedure first flattens the regexp trees by merging all children into the parent node if they are both of the same type and of type or, and, or cons.", "labels": [], "entities": [{"text": "heuristic unification", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.6523885130882263}]}, {"text": "It then sorts all children of the and and or operators.", "labels": [], "entities": []}, {"text": "Finally, it converts both regexps back to a flat string and compares these strings for equivalence.", "labels": [], "entities": []}, {"text": "This process should more effective than any", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy of our model and the baselines.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9973552227020264}]}, {"text": " Table 2: Results for varying amounts of training data.", "labels": [], "entities": []}]}