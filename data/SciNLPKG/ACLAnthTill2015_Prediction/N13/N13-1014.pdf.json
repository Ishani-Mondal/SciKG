{"title": [{"text": "Learning a Part-of-Speech Tagger from Two Hours of Annotation", "labels": [], "entities": [{"text": "Part-of-Speech Tagger from Two Hours of Annotation", "start_pos": 11, "end_pos": 61, "type": "TASK", "confidence": 0.8224313599722726}]}], "abstractContent": [{"text": "Most work on weakly-supervised learning for part-of-speech taggers has been based on un-realistic assumptions about the amount and quality of training data.", "labels": [], "entities": [{"text": "part-of-speech taggers", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.7299821078777313}]}, {"text": "For this paper, we attempt to create true low-resource scenarios by allowing a linguist just two hours to annotate data and evaluating on the languages Kin-yarwanda and Malagasy.", "labels": [], "entities": []}, {"text": "Given these severely limited amounts of either type supervision (tag dictionaries) or token supervision (labeled sentences), we are able to dramatically improve the learning of a hidden Markov model through our method of automatically generalizing the annotations, reducing noise, and inducing word-tag frequency information.", "labels": [], "entities": []}], "introductionContent": [{"text": "The high performance achieved by part-of-speech (POS) taggers trained on plentiful amounts of labeled word tokens is a success story of computational linguistics.", "labels": [], "entities": [{"text": "computational linguistics", "start_pos": 136, "end_pos": 161, "type": "TASK", "confidence": 0.7370123267173767}]}, {"text": "However, research on learning taggers using type supervision (e.g. tag dictionaries or morphological transducers) has had a more checkered history.", "labels": [], "entities": [{"text": "learning taggers", "start_pos": 21, "end_pos": 37, "type": "TASK", "confidence": 0.6271752417087555}]}, {"text": "The setting is a seductive one: by labeling the possible parts-ofspeech for high frequency words, one might learn accurate taggers by incorporating the type information as constraints to a semi-supervised generative learning model like a hidden Markov model (HMM).", "labels": [], "entities": []}, {"text": "Early work showed much promise for this strategy, but successive efforts in recent years have continued to peel away and address layers of unrealistic assumptions about the size, coverage, and quality of the tag dictionaries that had been used (.", "labels": [], "entities": []}, {"text": "This paper attempts to strip away further layers so we can build better intuitions about the effectiveness of type-supervised and token-supervised strategies in a realistic setting of POS-tagging for low-resource languages.", "labels": [], "entities": []}, {"text": "In most previous work, tag dictionaries are extracted from a corpus of annotated tokens.", "labels": [], "entities": []}, {"text": "To explore the type-supervised scenario, these have been used as a proxy for dictionaries produced by linguists.", "labels": [], "entities": []}, {"text": "However, this overstates their effectiveness.", "labels": [], "entities": []}, {"text": "Researchers have often manually pruned tag dictionaries by removing low-frequency word/tag pairs; this violates the assumption that frequency information is not available.", "labels": [], "entities": []}, {"text": "Others have also created tag dictionaries by extracting every word/tag pair in a large, labeled corpus, including the test data-even though actual applications would never have such complete lexical knowledge.", "labels": [], "entities": []}, {"text": "Dictionaries extracted from corpora are also biased towards including only the most likely tag for each word type, resulting in a cleaner dictionary than one would find in real scenario.", "labels": [], "entities": []}, {"text": "Finally, tag dictionaries extracted from annotated tokens benefit from the annotation process of labeling and review and refinement over an extended collaboration period.", "labels": [], "entities": []}, {"text": "Such high quality annotations are simply not available for most low-resource languages.", "labels": [], "entities": []}, {"text": "This paper describes an approach to learning a POS-tagger that can be applied in a truly lowresource scenario.", "labels": [], "entities": []}, {"text": "Specifically, we discuss techniques that allow us to learn a tagger given only the amount of labeled data that a human annotator could provide in two hours.", "labels": [], "entities": []}, {"text": "Here, we evaluate on the languages Malagasy and Kinyarwanda, as well as English as a control language.", "labels": [], "entities": []}, {"text": "Furthermore, we are interested in whether type-supervision or tokensupervision is more effective, given the strict time constraint; accordingly, we had annotators produce both a tag dictionary and a set of labeled sentences.", "labels": [], "entities": []}, {"text": "The data produced under our conditions differs in several ways from the labeled data used in previous work.", "labels": [], "entities": []}, {"text": "Most obviously, there is less of it.", "labels": [], "entities": []}, {"text": "Instead of using hundreds of thousands of labeled tokens to construct a tag dictionary (and hundreds of thousands more as unlabeled (raw) data for training), we only use the 1k-2k labeled tokens or types provided by our annotators within the timeframe.", "labels": [], "entities": []}, {"text": "Our training data is also much noisier than the data from atypical corpus: the annotations were produced by a single non-native-speaker working alone for two hours.", "labels": [], "entities": []}, {"text": "Therefore, dealing with the size and quality of training data were core challenges to our task.", "labels": [], "entities": []}, {"text": "To learn a POS-tagger from so little labeled data, we developed an approach that starts by generalizing the initial annotations to the entire raw corpus.", "labels": [], "entities": []}, {"text": "Our approach uses label propagation (LP)) to infer tag distributions on unlabeled tokens.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 18, "end_pos": 35, "type": "TASK", "confidence": 0.6906856596469879}]}, {"text": "We then apply a novel weighted variant of the model minimization procedure originally developed by to estimate sequence and word-tag frequency information from an unlabeled corpus by approximating the minimal set of tag bigrams needed to explain the data.", "labels": [], "entities": []}, {"text": "This combination of techniques turns a tiny, unweighted, initial tag dictionary into a weighted tag dictionary that covers the entire corpus's vocabulary.", "labels": [], "entities": []}, {"text": "This weighted information limits the potential damage of tag dictionary noise and bootstraps frequency information to approximate a good starting point for the learning of an HMM using expectation-maximization (EM), and far outperforms just using EM on the raw annotations themselves.", "labels": [], "entities": []}], "datasetContent": [{"text": "Experimental results are shown in.", "labels": [], "entities": []}, {"text": "Each experiment starts with an initial data set provided by annotator A or B.", "labels": [], "entities": []}, {"text": "Experiment (1) simply uses EM with the initial small tag dictionary to learn a tagger from the raw corpus.", "labels": [], "entities": []}, {"text": "(2) uses LP to infer an expanded tag dictionary and tag distributions over raw corpus tokens, but then takes the highest-weighted tag from each token for use as noisily-labeled training data to initialize EM.", "labels": [], "entities": [{"text": "initialize EM", "start_pos": 194, "end_pos": 207, "type": "TASK", "confidence": 0.6627706289291382}]}, {"text": "(3) performs greedy modelminimization on the LP output to derive that noisilylabeled corpus.", "labels": [], "entities": []}, {"text": "Finally, is the same as (3), but additionally uses external dictionary nodes in the LP graph.", "labels": [], "entities": []}, {"text": "In the case of token-supervision, we also include (0), in which we simply used the tagged sentences as supervised data for an HMM without EM (followed by MEMM training).", "labels": [], "entities": []}, {"text": "The results show that performance improves with our LP and minimization techniques compared to basic EM-HMM training.", "labels": [], "entities": [{"text": "LP", "start_pos": 52, "end_pos": 54, "type": "METRIC", "confidence": 0.9954631924629211}]}, {"text": "LP gives large across-theboard improvements over EM training with only the original tag dictionary (compare columns.", "labels": [], "entities": [{"text": "EM training", "start_pos": 49, "end_pos": 60, "type": "TASK", "confidence": 0.8944394588470459}]}, {"text": "Weighted model minimization further improves results for type-supervision settings, but not for token supervision.", "labels": [], "entities": []}, {"text": "Using an external dictionary in the LP graph has little effect for KIN, probably due to the available dictionary's very small size.", "labels": [], "entities": []}, {"text": "However, MLG with its larger dictionary obtains an improvement in both scenarios.", "labels": [], "entities": [{"text": "MLG", "start_pos": 9, "end_pos": 12, "type": "DATASET", "confidence": 0.8814607262611389}]}, {"text": "Results on ENG are mixed; this maybe because the PTB tagset has 45 tags (far more than the dictionary) so the external dictionary nodes in the LP graph may consequently serve to collapse distinctions (e.g. singular and plural) in the larger set.", "labels": [], "entities": [{"text": "PTB tagset", "start_pos": 49, "end_pos": 59, "type": "DATASET", "confidence": 0.9488111734390259}]}, {"text": "Our results show differences between token-and type-supervised annotations.", "labels": [], "entities": []}, {"text": "Tag dictionary expansion is helpful no matter what the annotations look like: in both cases, the initial dictionary is too small for effective EM learning, so expansion is necessary.", "labels": [], "entities": [{"text": "Tag dictionary expansion", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.5554576416810354}, {"text": "EM learning", "start_pos": 143, "end_pos": 154, "type": "TASK", "confidence": 0.8973985314369202}]}, {"text": "However, model minimization only benefits the type-supervised scenarios, leaving tokensupervised performance unchanged.", "labels": [], "entities": [{"text": "model minimization", "start_pos": 9, "end_pos": 27, "type": "TASK", "confidence": 0.704587385058403}]}, {"text": "This suggests  , and English (ENG).", "labels": [], "entities": [{"text": "ENG", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.5600873231887817}]}, {"text": "The letters A and B refer to the annotator.", "labels": [], "entities": []}, {"text": "LP(ed) refers to label propagation including nodes from an external dictionary.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.7133556008338928}]}, {"text": "Each result given as percentages for Total (T), Known (K), and Unknown (U).", "labels": [], "entities": [{"text": "Total (T)", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9239352941513062}, {"text": "Unknown (U)", "start_pos": 63, "end_pos": 74, "type": "METRIC", "confidence": 0.962320938706398}]}], "tableCaptions": [{"text": " Table 1: Statistics for Kinyarwanda, Malagasy, and  English data annotated by annotators A and B.", "labels": [], "entities": [{"text": "Malagasy, and  English data", "start_pos": 38, "end_pos": 65, "type": "DATASET", "confidence": 0.5135016024112702}]}, {"text": " Table 2: Experimental results. Three languages are shown: Kinyarwanda (KIN), Malagasy (MLG)", "labels": [], "entities": []}, {"text": " Table 5: Tag assignments in different scenarios. A  star indicates an entry in the human-provided TD.", "labels": [], "entities": [{"text": "Tag assignments", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.7553799450397491}]}]}