{"title": [{"text": "Discriminative Joint Modeling of Lexical Variation and Acoustic Confusion for Automated Narrative Retelling Assessment", "labels": [], "entities": [{"text": "Automated Narrative Retelling Assessment", "start_pos": 78, "end_pos": 118, "type": "TASK", "confidence": 0.6900847926735878}]}], "abstractContent": [{"text": "Automatically assessing the fidelity of a retelling to the original narrative-a task of growing clinical importance-is challenging, given extensive paraphrasing during retelling along with cascading automatic speech recognition (ASR) errors.", "labels": [], "entities": [{"text": "cascading automatic speech recognition (ASR)", "start_pos": 189, "end_pos": 233, "type": "TASK", "confidence": 0.7563306944710868}]}, {"text": "We present a word tagging approach using conditional random fields (CRFs) that allows a diversity of features to be considered during inference, including some capturing acoustic confusions encoded in word confusion networks.", "labels": [], "entities": [{"text": "word tagging", "start_pos": 13, "end_pos": 25, "type": "TASK", "confidence": 0.7962962985038757}]}, {"text": "We evaluate the approach under several scenarios, including both supervised and unsupervised training, the latter achieved by training on the output of a baseline automatic word-alignment model.", "labels": [], "entities": []}, {"text": "We also adapt the ASR models to the domain, and evaluate the impact of error rate on performance.", "labels": [], "entities": [{"text": "ASR", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.9652841687202454}, {"text": "error rate", "start_pos": 71, "end_pos": 81, "type": "METRIC", "confidence": 0.9445540308952332}]}, {"text": "We find strong robustness to ASR errors, even using just the 1-best system output.", "labels": [], "entities": [{"text": "ASR", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.9839694499969482}]}, {"text": "A hybrid approach making use of both automatic alignment and CRFs trained tagging models achieves the best performance, yielding strong improvements over using either approach alone.", "labels": [], "entities": [{"text": "CRFs trained tagging", "start_pos": 61, "end_pos": 81, "type": "TASK", "confidence": 0.5773282647132874}]}], "introductionContent": [{"text": "Narrative production tasks are an essential component of many standard neuropsychological test batteries.", "labels": [], "entities": [{"text": "Narrative production", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.86484095454216}]}, {"text": "For example, narration of a wordless picture book is part of the Autism Diagnostic Observation Schedule (ADOS) () and retelling of previously narrated stories is part of both the Developmental Neuropsychological Assessment (NEPSY) () and the Wechsler Logical Memory (WLM) test.", "labels": [], "entities": [{"text": "narration of a wordless picture book", "start_pos": 13, "end_pos": 49, "type": "TASK", "confidence": 0.7992419004440308}]}, {"text": "Such tests also arise in reading comprehension, second language learning and other computer-based tutoring systems.", "labels": [], "entities": []}, {"text": "The accuracy of automated scoring of a narrative retelling depends on correctly identifying which of the source narrative's propositions or events (what we will call 'story elements') have been included in the retelling.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9985276460647583}]}, {"text": "Speakers may choose to relate these elements using diverse words or phrases, and an automated method of identifying these elements needs to model the permissible variants and paraphrasings.", "labels": [], "entities": []}, {"text": "In previous work (, we developed models based on automatic word-alignment methods, as described briefly in Section 3.", "labels": [], "entities": []}, {"text": "Such alignments are learned in an unsupervised manner from a parallel corpus of manual or ASR transcripts of retellings and the original source narrative, much as in machine translation training.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 166, "end_pos": 185, "type": "TASK", "confidence": 0.7581042647361755}]}, {"text": "Relying on manual transcripts to train the alignment models limits the ability of these methods to handle ASR errors.", "labels": [], "entities": [{"text": "ASR", "start_pos": 106, "end_pos": 109, "type": "TASK", "confidence": 0.9927162528038025}]}, {"text": "By instead training on ASR transcripts, these methods can automatically capture some regularities of lexical variants and their common realizations by the recognizer.", "labels": [], "entities": [{"text": "ASR transcripts", "start_pos": 23, "end_pos": 38, "type": "TASK", "confidence": 0.88654825091362}]}, {"text": "Additionally, evidence of acoustic confusability is available in word lattice output from the recognizer, which can be exploited to yield more robust automatic scoring, particularly in high error-rate scenarios.", "labels": [], "entities": []}, {"text": "In this paper, we present and evaluate the use of word tagging models for this task, in contrast to just using automatic (unsupervised) word-alignment methods.", "labels": [], "entities": [{"text": "word tagging", "start_pos": 50, "end_pos": 62, "type": "TASK", "confidence": 0.7324665933847427}]}, {"text": "The approach is general enough to al-low tagging of word confusion networks derived from lattices, thus allowing us to explore the utility of such representations to achieve robustness.", "labels": [], "entities": []}, {"text": "We present results under a range of experimental conditions, including: variously adapting the ASR models to the domain; using maximum entropy models rather than CRFs; differing tagsets (BIO versus IO); and with varying degrees of supervision.", "labels": [], "entities": [{"text": "ASR", "start_pos": 95, "end_pos": 98, "type": "TASK", "confidence": 0.9267280697822571}]}, {"text": "Finally, we demonstrate improved utility in terms of using the automatic scores to classify elderly individuals as having Mild Cognitive Impairment.", "labels": [], "entities": [{"text": "Mild Cognitive Impairment", "start_pos": 122, "end_pos": 147, "type": "METRIC", "confidence": 0.5760559439659119}]}, {"text": "Ultimately we find that hybrid approaches, making use of both word-alignment and tagging models, yield strong improvements over either used independently.", "labels": [], "entities": []}], "datasetContent": [{"text": "Corpus: Our models were trained on immediate and delayed retellings from 144 subjects with a mean age of 85.4, of whom 36 were clinically diagnosed with MCI (training set).", "labels": [], "entities": [{"text": "Corpus", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8529245853424072}]}, {"text": "We evaluated our models on a set of retellings from 70 non-overlapping subjects with a mean age of 88.5, half of whom had received a diagnosis of MCI (test set).", "labels": [], "entities": []}, {"text": "In contrast to the unsupervised word-alignment based method, the method outlined here required manual story element labels of the retellings.", "labels": [], "entities": []}, {"text": "The training and test sets from this paper are therefore different from the sets used in previous work (, and the results are not directly comparable.", "labels": [], "entities": []}, {"text": "The recordings were sometimes made in an informal setting, such as the subject's home or a senior center.", "labels": [], "entities": []}, {"text": "For this reason, there are often extraneous noises in the recordings such as music, footsteps, and clocks striking the hour.", "labels": [], "entities": []}, {"text": "Although this presents a challenge for ASR, part of the goal of our work is to demonstrate the robustness of our methods to noisy audio.", "labels": [], "entities": [{"text": "ASR", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9937217831611633}]}], "tableCaptions": [{"text": " Table 3: Improvement in ASR word error-rate by adapting the", "labels": [], "entities": [{"text": "ASR word error-rate", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.7763784726460775}]}, {"text": " Table 4: Story element F-score achieved by baseline word-alignment model and log-linear models (MaxEnt and CRF) using", "labels": [], "entities": [{"text": "F-score", "start_pos": 24, "end_pos": 31, "type": "METRIC", "confidence": 0.710727334022522}]}, {"text": " Table 5: Story element F-score achieved by log-linear models (MaxEnt and CRF) when adding context dependent features (CD)", "labels": [], "entities": [{"text": "F-score", "start_pos": 24, "end_pos": 31, "type": "METRIC", "confidence": 0.6020660996437073}]}, {"text": " Table 6: Classification performance (AUC) for the baseline word-alignment model and the best performing log-linear models of", "labels": [], "entities": [{"text": "AUC)", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.866743266582489}]}]}