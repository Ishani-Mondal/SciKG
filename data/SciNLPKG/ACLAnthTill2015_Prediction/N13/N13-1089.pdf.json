{"title": [{"text": "Improving Lexical Semantics for Sentential Semantics: Modeling Selectional Preference and Similar Words in a Latent Variable Model", "labels": [], "entities": [{"text": "Improving Lexical Semantics", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8868810335795084}]}], "abstractContent": [{"text": "Sentence Similarity [SS] computes a similarity score between two sentences.", "labels": [], "entities": [{"text": "Sentence Similarity [SS", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8683480024337769}]}, {"text": "The SS task differs from document level semantics tasks in that it features the sparsity of words in a data unit, i.e. a sentence.", "labels": [], "entities": []}, {"text": "Accordingly it is crucial to robustly model each word in a sentence to capture the complete semantic picture of the sentence.", "labels": [], "entities": []}, {"text": "In this paper, we hypothesize that by better modeling lexical semantics we can obtain better sentential semantics.", "labels": [], "entities": []}, {"text": "We incorporate both corpus-based (selectional preference information) and knowledge-based (similar words extracted in a dictionary) lexical semantics into a latent variable model.", "labels": [], "entities": []}, {"text": "The experiments show state-of-the-art performance among unsupervised systems on two SS datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentence Similarity is emerging as a crucial step in many NLP tasks that focus on sentence level semantics such as word sense disambiguation, summarization (), text coherence (Lapata and), tweet clustering (), etc.", "labels": [], "entities": [{"text": "Sentence Similarity", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9012754559516907}, {"text": "word sense disambiguation", "start_pos": 115, "end_pos": 140, "type": "TASK", "confidence": 0.6938120126724243}, {"text": "summarization", "start_pos": 142, "end_pos": 155, "type": "TASK", "confidence": 0.971586287021637}, {"text": "tweet clustering", "start_pos": 189, "end_pos": 205, "type": "TASK", "confidence": 0.7724741101264954}]}, {"text": "SS operates in a very small context, on average 11 words per sentence in Semeval-2012 dataset (, resulting in inadequate evidence to generalize to robust sentential semantics.", "labels": [], "entities": [{"text": "SS", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9401713013648987}, {"text": "Semeval-2012 dataset", "start_pos": 73, "end_pos": 93, "type": "DATASET", "confidence": 0.839319497346878}]}, {"text": "Weighted Textual Matrix Factorization [WTMF] () is a latent variable model that outperforms Latent Semantic Analysis) and Latent Dirichelet Allocation () models by a large margin in the SS task, yielding state-of-the-art performance on the LI06 () SS dataset.", "labels": [], "entities": [{"text": "LI06 () SS dataset", "start_pos": 240, "end_pos": 258, "type": "DATASET", "confidence": 0.7482272833585739}]}, {"text": "However, all of these models make harsh simplifying assumptions on how a token is generated: (1) in LSA/WTMF, a token is generated by the inner product of the word latent vector and the document latent vector; (2) in LDA, all the tokens in a document are sampled from the same document level topic distribution.", "labels": [], "entities": []}, {"text": "Under this framework, they ignore rich linguistic phenomena such as inter-word dependency, semantic scope of words, etc.", "labels": [], "entities": []}, {"text": "This is a result of simply using document IDs as features to represent a word.", "labels": [], "entities": []}, {"text": "Modeling quality lexical semantics in latent variable models does not draw enough attention in the community, since people usually apply dimension reduction techniques for documents, which have abundant words for extracting the document level semantics.", "labels": [], "entities": []}, {"text": "However, in the SS setting, it is crucial to make good use of each word, given the limited number of words in a sentence.", "labels": [], "entities": [{"text": "SS", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.9398011565208435}]}, {"text": "We believe a reasonable word generation story will avoid introducing noise in sentential semantics, encouraging robust lexical semantics which can further boost the sentential semantics.", "labels": [], "entities": [{"text": "word generation", "start_pos": 24, "end_pos": 39, "type": "TASK", "confidence": 0.7324866354465485}]}, {"text": "In this paper, we explicitly encode lexical semantics, both corpus-based and knowledge-based information, in the WTMF model, by which we are able to achieve even better results in SS task.", "labels": [], "entities": [{"text": "SS task", "start_pos": 180, "end_pos": 187, "type": "TASK", "confidence": 0.8943780660629272}]}, {"text": "The additional corpus-based information we exploit is selectional preference semantics, a feature already existing in the data yet ignored by most latent variable models.", "labels": [], "entities": []}, {"text": "Selectional preference focuses on the admissible arguments fora word, thus capturing more nuanced semantics than the sentence IDs (when applied to a corpus of sentences as opposed to documents).", "labels": [], "entities": []}, {"text": "Consider the following example: In WTMF/LSA/LDA, a word will receive semantics from all the other words in a sentence, hence, the word oil, in the above example, will be assigned the incorrect finance topic that reflects the sentence level semantics.", "labels": [], "entities": [{"text": "WTMF/LSA/LDA", "start_pos": 35, "end_pos": 47, "type": "DATASET", "confidence": 0.7749937772750854}]}, {"text": "Moreover, the problem worsens for adjectives, adverbs and verbs, which have a much narrower semantic scope than the whole sentence.", "labels": [], "entities": []}, {"text": "For example, the verb say should only be associated with analyst (only receiving semantics from analyst), as it is not related to other words in the sentence.", "labels": [], "entities": []}, {"text": "In contrast, oil, according to its selectional preference, should be associated with crude indicating the resource topic.", "labels": [], "entities": []}, {"text": "We believe modeling selectional preference capturing local evidence completes the semantic picture for words, hence further rendering better sentential semantics.", "labels": [], "entities": []}, {"text": "To our best knowledge, this is the first work to model selectional preference for sentence/document semantics.", "labels": [], "entities": []}, {"text": "We also integrate knowledge-based semantics in the WTMF framework.", "labels": [], "entities": [{"text": "WTMF framework", "start_pos": 51, "end_pos": 65, "type": "DATASET", "confidence": 0.8734164535999298}]}, {"text": "Knowledge-based semantics, a human-annotated clean resource, is an important complement to corpus-based noisy cooccurrence information.", "labels": [], "entities": []}, {"text": "We extract similar word pairs from Wordnet.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 35, "end_pos": 42, "type": "DATASET", "confidence": 0.9807704091072083}]}, {"text": "Leveraging these pairs, an infrequent word such as purchase can exploit robust latent vectors from its synonyms such as buy.", "labels": [], "entities": []}, {"text": "Similar words pairs can be seamlessly modeled in WTMF, since in the matrix factorization framework a latent vector profile is explicitly created for each word, while in LDA all the data structures are designed for documents/sentences.", "labels": [], "entities": []}, {"text": "We construct a graph to connect words according to the extracted similar word pairs, to encourage similar words to share similar latent vector profiles.", "labels": [], "entities": []}, {"text": "We will refer to our proposed novel model as WTMF+PK.", "labels": [], "entities": [{"text": "WTMF+PK", "start_pos": 45, "end_pos": 52, "type": "DATASET", "confidence": 0.7500004768371582}]}], "datasetContent": [{"text": "We build the model WTMF+PK on the same corpora as used in our previous work are used as the tuning set for setting the parameters of our models.", "labels": [], "entities": [{"text": "WTMF+PK", "start_pos": 19, "end_pos": 26, "type": "DATASET", "confidence": 0.752007524172465}]}, {"text": "This data comprises msrpar, msr-vid, smt-eur.", "labels": [], "entities": []}, {"text": "Once the models are tuned, we evaluate them on the STS12 test data that comprises 3150 sentence pairs from msr-par, msr-vid, smt-eur, smt-news, On-WN.", "labels": [], "entities": [{"text": "STS12 test data", "start_pos": 51, "end_pos": 66, "type": "DATASET", "confidence": 0.8738869825998942}, {"text": "On-WN", "start_pos": 144, "end_pos": 149, "type": "DATASET", "confidence": 0.967538058757782}]}, {"text": "It is worth noting that smt-news and On-WN are not part of the tuning data.", "labels": [], "entities": [{"text": "On-WN", "start_pos": 37, "end_pos": 42, "type": "DATASET", "confidence": 0.9399464130401611}]}, {"text": "We use cosine similarity to measure the similarity scores between two sentences.", "labels": [], "entities": []}, {"text": "Pearson correlation between the system's answer and gold standard similarity scores is used as the evaluation metric.", "labels": [], "entities": [{"text": "gold standard similarity scores", "start_pos": 52, "end_pos": 83, "type": "METRIC", "confidence": 0.5818297192454338}]}, {"text": "We include three baselines LSA, LDA and WTMF using the setting described in).", "labels": [], "entities": [{"text": "WTMF", "start_pos": 40, "end_pos": 44, "type": "DATASET", "confidence": 0.7050996422767639}]}, {"text": "We run Gibbs Sampling based LDA for 2000 iterations and average the model over the last 10 iterations.", "labels": [], "entities": []}, {"text": "For WTMF, we run 20 iterations and fix the missing words weight at w m = 0.01 with a regularization coefficient set at \u03bb = 20, which is the best condition found in ().", "labels": [], "entities": [{"text": "WTMF", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.6940785050392151}]}, {"text": "summarizes the results at dimension K = 100 (the dimension of latent vectors).", "labels": [], "entities": []}, {"text": "To remove randomness, each reported number is the averaged results of 10 runs.", "labels": [], "entities": []}, {"text": "Based on the STS tuning set, we experiment with different values for the selectional preference weight (\u03b3 = {0, 1, 2}), and likewise for the similar word pairs weight varying the \u03b4 value as follows \u03b4 = {0, 0.1, 0.3, 0.5, 0.7}.", "labels": [], "entities": [{"text": "STS tuning set", "start_pos": 13, "end_pos": 27, "type": "DATASET", "confidence": 0.7301368912061056}]}, {"text": "The performance on STS12 tuning and test dataset as well as on the LI06 dataset are illustrated in.", "labels": [], "entities": [{"text": "STS12 tuning and test dataset", "start_pos": 19, "end_pos": 48, "type": "DATASET", "confidence": 0.6128312826156617}, {"text": "LI06 dataset", "start_pos": 67, "end_pos": 79, "type": "DATASET", "confidence": 0.935596376657486}]}, {"text": "The parameters of model 6 in (\u03b3 = 2, \u03b4 = 0.3) are the chosen values based on tuning set performance.", "labels": [], "entities": []}, {"text": "shows WTMF is already a very strong baseline: it outperforms LSA and LDA by a large margin.", "labels": [], "entities": [{"text": "WTMF", "start_pos": 6, "end_pos": 10, "type": "DATASET", "confidence": 0.6134054660797119}]}, {"text": "Same as in), LSA performance degrades dramatically when trained on a corpus of sentence sized documents, yielding results worse than the surface words baseline 31% (Agirre et al., 2012).", "labels": [], "entities": [{"text": "LSA", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.7990543842315674}]}, {"text": "Using corpus-based selectional preference semantics alone (model 4 WTMF+P in) boosts the performance of WTMF by +1.17% on the test set, while using knowledge-based semantics alone (model 5 WTMF+K) improves the over the WTMF results by an absolute +2.31%.", "labels": [], "entities": []}, {"text": "Combining them (model 6 WTMF+PK) yields the best results, with an absolute increase of +3.39%, which suggests that the two sources of semantic evidence are useful, but more importantly, they are complementary for each other.", "labels": [], "entities": []}, {"text": "also presents the performance on each individual dataset.", "labels": [], "entities": []}, {"text": "The gain on each individual source is not as much as the overall gain, which suggests part of the overall gain comes from the correct ranking of intra-source pairs.", "labels": [], "entities": []}, {"text": "Note that WTMF+PK improves all individual datasets except smt-eur.", "labels": [], "entities": []}, {"text": "This maybe caused by too many overlapping words in the sentence pairs in smt-eur, while our approach focuses on extracting similarity between different words.", "labels": [], "entities": []}, {"text": "Observing the performance using different values of weights in and 3b, we can conclude that the selectional preference and similar word pairs yield very promising results.", "labels": [], "entities": []}, {"text": "The trends hold in different parameter conditions with a consistent improvement.", "labels": [], "entities": []}, {"text": "illustrates the impact of dimension K = {50, 75, 100, 125, 150} on WTMF and WTMF+PK.", "labels": [], "entities": [{"text": "WTMF", "start_pos": 67, "end_pos": 71, "type": "DATASET", "confidence": 0.9036099910736084}, {"text": "WTMF+PK", "start_pos": 76, "end_pos": 83, "type": "DATASET", "confidence": 0.8641665975252787}]}, {"text": "Generally a larger K leads to a higher Pearson correlation, but the improvement is tiny when K \u2265 100 (0.1% increase).", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 39, "end_pos": 58, "type": "METRIC", "confidence": 0.9172215163707733}]}, {"text": "Compared to all the unsupervised systems that participated in Semeval STS 2012 task, WTMF+PK yields state-of-the-art performance (70.70%).", "labels": [], "entities": [{"text": "Semeval STS 2012 task", "start_pos": 62, "end_pos": 83, "type": "TASK", "confidence": 0.6666189283132553}, {"text": "WTMF+PK", "start_pos": 85, "end_pos": 92, "type": "METRIC", "confidence": 0.5456963082154592}]}, {"text": "In (Guo and Diab, 2012c) we also apply WTMF (K = 100) on STS12, achieving a correlation of 69.5%.", "labels": [], "entities": [{"text": "WTMF", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9886653423309326}]}, {"text": "However, additional data is incorporated in the training corpora: (1) STS12 tuning set; (2) for WordNet and Wiktionary data, the target words are also included in the definitions (hence synonym pairs were used); (3) the usage examples of target words were also appended to the definitions.", "labels": [], "entities": [{"text": "STS12 tuning set", "start_pos": 70, "end_pos": 86, "type": "DATASET", "confidence": 0.5995474060376486}, {"text": "WordNet and Wiktionary data", "start_pos": 96, "end_pos": 123, "type": "DATASET", "confidence": 0.710906870663166}]}, {"text": "While trained with this experimental setting, our model WTMF+PK (\u03b3 = 2, \u03b4 = 0.3, K = 100) is able to reach an even higher correlation of 72.0%.", "labels": [], "entities": []}, {"text": "show that WTMF is the state-of-the-art model on LI06.", "labels": [], "entities": [{"text": "WTMF", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.7168301343917847}, {"text": "LI06", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.9582723379135132}]}, {"text": "With lexical semantics explicitly modeled, WTMF+PK yields better results than WTMF (see).", "labels": [], "entities": []}, {"text": "It should be noted that LI06 prefers a smaller similar word pair weight ( a \u03b4 = 0.1 yields the best performance around of 90.75%), yet in almost all conditions WTMF+PK outperforms WTMF as shown in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation Results using Pearson Correlation on STS12 and LI06", "labels": [], "entities": [{"text": "Pearson Correlation", "start_pos": 35, "end_pos": 54, "type": "METRIC", "confidence": 0.9385972917079926}, {"text": "STS12", "start_pos": 58, "end_pos": 63, "type": "DATASET", "confidence": 0.7396724224090576}]}]}