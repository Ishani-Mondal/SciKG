{"title": [{"text": "Unsupervised Domain Tuning to Improve Word Sense Disambiguation", "labels": [], "entities": [{"text": "Improve Word Sense Disambiguation", "start_pos": 30, "end_pos": 63, "type": "TASK", "confidence": 0.6726298928260803}]}], "abstractContent": [{"text": "The topic of a document can prove to be useful information for Word Sense Disambigua-tion (WSD) since certain meanings tend to be associated with particular topics.", "labels": [], "entities": [{"text": "Word Sense Disambigua-tion (WSD)", "start_pos": 63, "end_pos": 95, "type": "TASK", "confidence": 0.7083251426617304}]}, {"text": "This paper presents an LDA-based approach for WSD, which is trained using any available WSD system to establish a sense per (Latent Dirich-let allocation based) topic.", "labels": [], "entities": [{"text": "WSD", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9810309410095215}]}, {"text": "The technique is tested using three unsupervised and one supervised WSD algorithms within the SPORT and FINANCE domains giving a performance increase each time, suggesting that the technique maybe useful to improve the performance of any available WSD system.", "labels": [], "entities": [{"text": "FINANCE", "start_pos": 104, "end_pos": 111, "type": "METRIC", "confidence": 0.884502649307251}]}], "introductionContent": [{"text": "Assigning each word its most frequent sense (MFS) is commonly used as a baseline in Word Sense Disambiguation (WSD).", "labels": [], "entities": [{"text": "Assigning each word its most frequent sense (MFS)", "start_pos": 0, "end_pos": 49, "type": "METRIC", "confidence": 0.6759666919708252}, {"text": "Word Sense Disambiguation (WSD)", "start_pos": 84, "end_pos": 115, "type": "TASK", "confidence": 0.7503374467293421}]}, {"text": "This baseline can be difficult to beat, particularly for unsupervised systems which do not have access to the annotated training data used to determine the MFS.", "labels": [], "entities": [{"text": "MFS", "start_pos": 156, "end_pos": 159, "type": "TASK", "confidence": 0.5814546942710876}]}, {"text": "However, it has also been shown that unsupervised methods can be used to identify the most likely sense for each ambiguous word type and this approach can be effective for disambiguation ().", "labels": [], "entities": []}, {"text": "Knowledge of the domain of a document has been shown to be useful information for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.9771965742111206}]}, {"text": "For example, improve the performance of a graph-based WSD system using a small number of hand-tagged examples, but further examples would be required for each new domain.", "labels": [], "entities": []}, {"text": "automatically construct a thesaurus from texts in a domain which they use for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.8736409544944763}]}, {"text": "Unfortunately, performance drops when the thesaurus is combined with information from local context.", "labels": [], "entities": []}, {"text": "showed that performance of an unsupervised WSD algorithm can be improved by supplementing the context with domain information.", "labels": [], "entities": [{"text": "WSD", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.9366263151168823}]}, {"text": "use LDA to create an additional feature fora supervised WSD algorithm, by inferring topics for labeled training data.", "labels": [], "entities": [{"text": "WSD", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.9225288033485413}]}, {"text": "integrate a topic model with WordNet and use it to carryout disambiguation and learn topics simultaneously.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 29, "end_pos": 36, "type": "DATASET", "confidence": 0.9529852867126465}]}, {"text": "use sense paraphrases to estimate probabilities of senses and carryout WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.8540247678756714}]}, {"text": "showed that automatically acquiring the predominant sense of a word from a corpus from the same domain increases performance (over using a predominant sense acquired from a balanced corpus), but their work requires a separate thesaurus to be built for each domain under investigation.", "labels": [], "entities": []}, {"text": "extracted relevant terms from texts in a domain and used them to initialize a random walkover the WordNet graph.", "labels": [], "entities": [{"text": "WordNet graph", "start_pos": 98, "end_pos": 111, "type": "DATASET", "confidence": 0.9561244547367096}]}, {"text": "Our approaches rely on a one sense per topic hypothesis (, making use of topics induced using LDA -we present three novel techniques for exploiting domain information that are employable with any WSD algorithm (unsupervised or supervised).", "labels": [], "entities": []}, {"text": "Using any WSD algorithm, we create a sense per topic distribution for each LDA topic, and the classification of anew document into a topic determines the sense distribution of the words within.", "labels": [], "entities": []}, {"text": "Once a sense per topic distribution is obtained, no further WSD annotation of new texts is required.", "labels": [], "entities": [{"text": "WSD annotation of new texts", "start_pos": 60, "end_pos": 87, "type": "TASK", "confidence": 0.8551183462142944}]}, {"text": "Instead of fixing domains, our technique allows these to be dynamically created (using LDA) and we using four existing publicly available WSD algorithms (three unsupervised and one supervised) to show that our technique increases their performance with no changes to the original algorithm.", "labels": [], "entities": []}, {"text": "Section 2 briefly introduces LDA, while Section 3 describes our three techniques for adding domain information to a WSD algorithm.", "labels": [], "entities": [{"text": "WSD algorithm", "start_pos": 116, "end_pos": 129, "type": "TASK", "confidence": 0.7971796691417694}]}, {"text": "The WSD algorithms employed in the evaluation of our techniques are described in Section 4 with experiments and results in Section 5.", "labels": [], "entities": [{"text": "WSD", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9069201946258545}]}, {"text": "Section 6 draws our conclusions and presents avenues for future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Summary of results based on 150 topics", "labels": [], "entities": []}]}