{"title": [{"text": "Modeling Syntactic and Semantic Structures in Hierarchical Phrase-based Translation", "labels": [], "entities": [{"text": "Hierarchical Phrase-based Translation", "start_pos": 46, "end_pos": 83, "type": "TASK", "confidence": 0.5918253858884176}]}], "abstractContent": [{"text": "Incorporating semantic structure into a linguistics-free translation model is challenging , since semantic structures are closely tied to syntax.", "labels": [], "entities": []}, {"text": "In this paper, we propose a two-level approach to exploiting predicate-argument structure reordering in a hierarchical phrase-based translation model.", "labels": [], "entities": []}, {"text": "First, we introduce linguistically motivated constraints into a hierarchical model, guiding translation phrase choices in favor of those that respect syntactic boundaries.", "labels": [], "entities": []}, {"text": "Second, based on such translation phrases, we propose a predicate-argument structure reordering model that predicts reordering not only between an argument and its predicate, but also between two arguments.", "labels": [], "entities": []}, {"text": "Experiments on Chinese-to-English translation demonstrate that both advances significantly improve translation accuracy.", "labels": [], "entities": [{"text": "Chinese-to-English translation", "start_pos": 15, "end_pos": 45, "type": "TASK", "confidence": 0.6893229782581329}, {"text": "translation", "start_pos": 99, "end_pos": 110, "type": "TASK", "confidence": 0.9419665932655334}, {"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.789937436580658}]}], "introductionContent": [{"text": "Hierarchical phrase-based (HPB) translation models () that utilize synchronous context free grammars (SCFG) have been widely adopted in statistical machine translation (SMT).", "labels": [], "entities": [{"text": "Hierarchical phrase-based (HPB) translation", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.568316454688708}, {"text": "statistical machine translation (SMT)", "start_pos": 136, "end_pos": 173, "type": "TASK", "confidence": 0.7957881540060043}]}, {"text": "Although formally syntactic, such models rarely respect linguistically-motivated syntax, and have no formal notion of semantics.", "labels": [], "entities": []}, {"text": "As a result, they tend to produce translations containing both grammatical errors and semantic role confusions.", "labels": [], "entities": []}, {"text": "Our goal is to take advantage of syntactic and semantic parsing to improve translation quality of HPB translation models.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 47, "end_pos": 63, "type": "TASK", "confidence": 0.7504679262638092}, {"text": "HPB translation", "start_pos": 98, "end_pos": 113, "type": "TASK", "confidence": 0.6933777630329132}]}, {"text": "Rather than introducing semantic structure into the HPB model directly, we construct an improved translation model by incorporating linguistically motivated syntactic constraints into a standard HPB model.", "labels": [], "entities": []}, {"text": "Once the translation phrases are linguistically constrained, we are able to propose a predicate-argument reordering model.", "labels": [], "entities": []}, {"text": "This reordering model aims to solve two problems: ensure that arguments are ordered properly after translation, and to ensure that the proper argument structures even exist, for instance in the case of PRO-drop languages.", "labels": [], "entities": []}, {"text": "Experimental results on Chinese-to-English translation show that both the hard syntactic constraints and the predicateargument reordering model obtain significant improvements over the syntactically and semantically uninformed baseline.", "labels": [], "entities": [{"text": "Chinese-to-English translation", "start_pos": 24, "end_pos": 54, "type": "TASK", "confidence": 0.6472476720809937}]}, {"text": "In principle, semantic frames (or, more specifically, predicate-argument structures: PAS) seem to be a promising avenue for translational modeling.", "labels": [], "entities": [{"text": "translational modeling", "start_pos": 124, "end_pos": 146, "type": "TASK", "confidence": 0.9626903831958771}]}, {"text": "While languages might diverge syntactically, they are less likely to diverge semantically.", "labels": [], "entities": []}, {"text": "This has previously been recognized by, who report that approximately 84% of semantic role mappings remained consistent across translations between English and Chinese.", "labels": [], "entities": []}, {"text": "Subsequently, took advantage of this consistency to jointly model semantic frames on Chinese/English bitexts, yielding improved frame recognition accuracy on both languages.", "labels": [], "entities": [{"text": "frame recognition", "start_pos": 128, "end_pos": 145, "type": "TASK", "confidence": 0.6669472604990005}, {"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.8994236588478088}]}, {"text": "While there has been some encouraging work on integrating syntactic knowledge into Chiang's HPB model, modeling semantic structure in a linguistically naive translation model is a challenge, because the semantic structures themselves are syntactically motivated.", "labels": [], "entities": []}, {"text": "In previous work, model the reordering/deletion of source-side semantic roles in a tree-to-string translation model.", "labels": [], "entities": []}, {"text": "While it is natural to include semantic structures in a treebased translation model, the effect of semantic structures is presumably limited, since tree templates themselves have already encoded semantics to some extent.", "labels": [], "entities": []}, {"text": "For example, template (VP (VBG giving) NP#1 NP#2) entails NP#1 as receiver and NP#2 as thing given.", "labels": [], "entities": []}, {"text": "model the reordering between predicates and their arguments by assuming arguments are translated as a unit.", "labels": [], "entities": []}, {"text": "However, they only considered the reordering between arguments and their predicates.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have presented our two-level approach to incorporating syntactic and semantic structures in a HPB system.", "labels": [], "entities": []}, {"text": "In this section, we test the effect of such structural information on a Chinese-to-English translation task.", "labels": [], "entities": [{"text": "Chinese-to-English translation task", "start_pos": 72, "end_pos": 107, "type": "TASK", "confidence": 0.7264948983987173}]}, {"text": "The baseline system is a reproduction of Chiang's (2007) HPB system.", "labels": [], "entities": [{"text": "Chiang's (2007) HPB system", "start_pos": 41, "end_pos": 67, "type": "DATASET", "confidence": 0.88909912109375}]}, {"text": "The bilingual training data contains 1.5M sentence pairs with 39.4M Chinese words and 46.6M English words.", "labels": [], "entities": []}, {"text": "We obtain the word alignments by running GIZA++) on the corpus in both directions and applying \"grow-diag-final-and\" refinement (.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 14, "end_pos": 29, "type": "TASK", "confidence": 0.6980655789375305}]}, {"text": "We use the SRI language modeling toolkit to train a 5-gram language model on the Xinhua portion of the Gigaword corpus and standard MERT to tune the feature weights on the development data.", "labels": [], "entities": [{"text": "SRI language modeling", "start_pos": 11, "end_pos": 32, "type": "TASK", "confidence": 0.6931560039520264}, {"text": "Gigaword corpus", "start_pos": 103, "end_pos": 118, "type": "DATASET", "confidence": 0.8076908588409424}, {"text": "MERT", "start_pos": 132, "end_pos": 136, "type": "METRIC", "confidence": 0.9739795327186584}]}, {"text": "To obtain syntactic parse trees for instantiating syntactic constraints and predicate-argument structures for integrating the PAS reordering model, we first parse the source sentences with the Berkeley Parser () is used to calculate the NIST BLEU scores, which measures caseinsensitive matching of n-grams with n up to 4.", "labels": [], "entities": [{"text": "NIST", "start_pos": 237, "end_pos": 241, "type": "DATASET", "confidence": 0.6289650201797485}, {"text": "BLEU scores", "start_pos": 242, "end_pos": 253, "type": "METRIC", "confidence": 0.9542978405952454}]}, {"text": "To test whether a performance difference is statistically significant, we conduct significance tests following the paired bootstrapping approach).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Effects of hard constraints. Here max-phrase-length is for maximum initial phrase length in training and  max-char-span for maximum phrase length can be covered by non-terminal X in decoding.", "labels": [], "entities": []}, {"text": " Table 3: Experimental results over different sentence  length on the three test sets. +/++: significant over base  HPB at 0.05/0.01.", "labels": [], "entities": []}]}