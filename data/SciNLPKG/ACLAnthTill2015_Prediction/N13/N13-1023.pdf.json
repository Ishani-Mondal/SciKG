{"title": [{"text": "Segmentation Strategies for Streaming Speech Translation", "labels": [], "entities": [{"text": "Streaming Speech Translation", "start_pos": 28, "end_pos": 56, "type": "TASK", "confidence": 0.7288012504577637}]}], "abstractContent": [{"text": "The study presented in this work is a first effort at real-time speech translation of TED talks, a compendium of public talks with different speakers addressing a variety of topics.", "labels": [], "entities": [{"text": "real-time speech translation of TED talks", "start_pos": 54, "end_pos": 95, "type": "TASK", "confidence": 0.7980524698893229}]}, {"text": "We address the goal of achieving a system that balances translation accuracy and la-tency.", "labels": [], "entities": [{"text": "translation", "start_pos": 56, "end_pos": 67, "type": "TASK", "confidence": 0.9275496602058411}, {"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.8938052654266357}]}, {"text": "In order to improve ASR performance for our diverse data set, adaptation techniques such as constrained model adaptation and vocal tract length normalization are found to be useful.", "labels": [], "entities": [{"text": "ASR", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9965337514877319}, {"text": "vocal tract length normalization", "start_pos": 125, "end_pos": 157, "type": "TASK", "confidence": 0.5330926552414894}]}, {"text": "In order to improve machine translation (MT) performance, techniques that could be employed in real-time such as monotonic and partial translation retention are found to be of use.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.8518547117710114}]}, {"text": "We also experiment with inserting text segmenters of various types between ASR and MT in a series of real-time translation experiments.", "labels": [], "entities": [{"text": "inserting text segmenters", "start_pos": 24, "end_pos": 49, "type": "TASK", "confidence": 0.7351305882136027}, {"text": "ASR", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.8134828805923462}]}, {"text": "Among other results, our experiments demonstrate that a good segmentation is useful, and a novel conjunction-based seg-mentation strategy improves translation quality nearly as much as other strategies such as comma-based segmentation.", "labels": [], "entities": []}, {"text": "It was also found to be important to synchronize various pipeline components in order to minimize la-tency.", "labels": [], "entities": []}], "introductionContent": [{"text": "The quality of automatic speech-to-text and speechto-speech (S2S) translation has improved so significantly over the last several decades that such systems are now widely deployed and used by an increasing number of consumers.", "labels": [], "entities": [{"text": "speechto-speech (S2S) translation", "start_pos": 44, "end_pos": 77, "type": "TASK", "confidence": 0.6699031233787537}]}, {"text": "Under the hood, the individual components such as automatic speech recognition (ASR), machine translation (MT) and text-tospeech synthesis (TTS) that constitute a S2S system are still loosely coupled and typically trained on disparate data and domains.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 50, "end_pos": 84, "type": "TASK", "confidence": 0.8071835041046143}, {"text": "machine translation (MT)", "start_pos": 86, "end_pos": 110, "type": "TASK", "confidence": 0.8271207392215729}, {"text": "text-tospeech synthesis (TTS)", "start_pos": 115, "end_pos": 144, "type": "TASK", "confidence": 0.7541978240013123}]}, {"text": "Nevertheless, the models as well as the pipeline have been optimized in several ways to achieve tasks such as high quality offline speech translation), on-demand web based speech and text translation, low-latency real-time translation), etc.", "labels": [], "entities": [{"text": "offline speech translation", "start_pos": 123, "end_pos": 149, "type": "TASK", "confidence": 0.764411191145579}, {"text": "web based speech and text translation", "start_pos": 162, "end_pos": 199, "type": "TASK", "confidence": 0.7125332802534103}, {"text": "low-latency real-time translation", "start_pos": 201, "end_pos": 234, "type": "TASK", "confidence": 0.7411424517631531}]}, {"text": "The design of a S2S translation system is highly dependent on the nature of the audio stimuli.", "labels": [], "entities": [{"text": "S2S translation", "start_pos": 16, "end_pos": 31, "type": "TASK", "confidence": 0.8655040264129639}]}, {"text": "For example, talks, lectures and audio broadcasts are typically long and require appropriate segmentation strategies to chunk the input signal to ensure high quality translation.", "labels": [], "entities": []}, {"text": "In contrast, single utterance translation in several consumer applications (apps) are typically short and can be processed without the need for additional chunking.", "labels": [], "entities": [{"text": "single utterance translation", "start_pos": 13, "end_pos": 41, "type": "TASK", "confidence": 0.6793313423792521}]}, {"text": "Another key parameter in designing a S2S translation system for any task is latency.", "labels": [], "entities": [{"text": "S2S translation", "start_pos": 37, "end_pos": 52, "type": "TASK", "confidence": 0.8513529598712921}, {"text": "latency", "start_pos": 76, "end_pos": 83, "type": "METRIC", "confidence": 0.9657897353172302}]}, {"text": "In offline scenarios where high latencies are permitted, several adaptation strategies (speaker, language model, translation model), denser data structures (Nbest lists, word sausages, lattices) and rescoring procedures can be utilized to improve the quality of end-to-end translation.", "labels": [], "entities": []}, {"text": "On the other hand, realtime speech-to-text or speech-to-speech translation demand the best possible accuracy at low latencies such that communication is not hindered due to potential delay in processing.", "labels": [], "entities": [{"text": "speech-to-speech translation", "start_pos": 46, "end_pos": 74, "type": "TASK", "confidence": 0.7501007616519928}, {"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9982241988182068}]}, {"text": "In this work, we focus on the speech translation of talks.", "labels": [], "entities": [{"text": "speech translation of talks", "start_pos": 30, "end_pos": 57, "type": "TASK", "confidence": 0.8303502723574638}]}, {"text": "We investigate the tradeoff between accuracy and latency for both offline and real-time translation of talks.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9990193843841553}, {"text": "latency", "start_pos": 49, "end_pos": 56, "type": "METRIC", "confidence": 0.9471640586853027}]}, {"text": "In both these scenarios, appropriate segmentation of the audio signal as well as the ASR hypothesis that is fed into machine translation is critical for maximizing the overall translation quality of the talk.", "labels": [], "entities": [{"text": "ASR", "start_pos": 85, "end_pos": 88, "type": "TASK", "confidence": 0.8003714084625244}, {"text": "machine translation", "start_pos": 117, "end_pos": 136, "type": "TASK", "confidence": 0.6819885075092316}]}, {"text": "Ideally, one would like to train the models on entire talks.", "labels": [], "entities": []}, {"text": "However, such corpora are not available in large amounts.", "labels": [], "entities": []}, {"text": "Hence, it is necessary to con-form to appropriately sized segments that are similar to the sentence units used in training the language and translation models.", "labels": [], "entities": []}, {"text": "We propose several nonlinguistic and linguistic segmentation strategies for the segmentation of text (reference or ASR hypotheses) for machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 135, "end_pos": 154, "type": "TASK", "confidence": 0.773385614156723}]}, {"text": "We address the problem of latency in real-time translation as a function of the segmentation strategy; i.e., we ask the question \"what is the segmentation strategy that maximizes the number of segments while still maximizing translation accuracy?\".", "labels": [], "entities": [{"text": "accuracy", "start_pos": 237, "end_pos": 245, "type": "METRIC", "confidence": 0.9405080080032349}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Statistics of the data used for training the speech translation models.", "labels": [], "entities": [{"text": "speech translation", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.7800552546977997}]}, {"text": " Table 2: ASR word accuracies on the IWSLT data  sets. 3", "labels": [], "entities": [{"text": "ASR word accuracies", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7160657644271851}, {"text": "IWSLT data  sets", "start_pos": 37, "end_pos": 53, "type": "DATASET", "confidence": 0.9846564133961996}]}, {"text": " Table 3: BLEU scores at the talk level for reference text and ASR 1-best for various segmentation strategies.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9989803433418274}, {"text": "ASR 1-best", "start_pos": 63, "end_pos": 73, "type": "METRIC", "confidence": 0.9760698080062866}]}]}