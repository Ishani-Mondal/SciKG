{"title": [{"text": "Enforcing Subcategorization Constraints in a Parser Using Sub-parses Recombining", "labels": [], "entities": [{"text": "Enforcing Subcategorization Constraints", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.8133171002070109}, {"text": "Recombining", "start_pos": 69, "end_pos": 80, "type": "TASK", "confidence": 0.9239190816879272}]}], "abstractContent": [{"text": "Treebanks are not large enough to adequately model subcategorization frames of predica-tive lexemes, which is an important source of lexico-syntactic constraints for parsing.", "labels": [], "entities": []}, {"text": "As a consequence, parsers trained on such tree-banks usually make mistakes when selecting the arguments of predicative lexemes.", "labels": [], "entities": []}, {"text": "In this paper, we propose an original way to correct subcategorization errors by combining sub-parses of a sentence S that appear in the list of the n-best parses of S.", "labels": [], "entities": []}, {"text": "The subcatego-rization information comes from three different resources, the first one is extracted from a treebank, the second one is computed on a large corpora and the third one is an existing syntactic lexicon.", "labels": [], "entities": []}, {"text": "Experiments on the French Treebank showed a 15.24% reduction of erroneous subcategorization frames (SF) selections for verbs as well as a relative decrease of the error rate of 4% Labeled Accuracy Score on the state of the art parser on this treebank.", "labels": [], "entities": [{"text": "French Treebank", "start_pos": 19, "end_pos": 34, "type": "DATASET", "confidence": 0.9952126145362854}, {"text": "error rate", "start_pos": 163, "end_pos": 173, "type": "METRIC", "confidence": 0.9821309447288513}, {"text": "Labeled Accuracy Score", "start_pos": 180, "end_pos": 202, "type": "METRIC", "confidence": 0.7513173222541809}]}], "introductionContent": [{"text": "Automatic syntactic parsing of natural languages has witnessed many important changes in the last fifteen years.", "labels": [], "entities": [{"text": "syntactic parsing of natural languages", "start_pos": 10, "end_pos": 48, "type": "TASK", "confidence": 0.8559176087379455}]}, {"text": "Among these changes, two have modified the nature of the task itself.", "labels": [], "entities": []}, {"text": "The first one is the availability of treebanks such as the Penn Treebank ( or the French Treebank (, which have been used in the parsing community to train stochastic parsers, such as.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 59, "end_pos": 72, "type": "DATASET", "confidence": 0.9953067302703857}, {"text": "French Treebank", "start_pos": 82, "end_pos": 97, "type": "DATASET", "confidence": 0.9813297092914581}]}, {"text": "Such work remained rooted in the classical language theoretic tradition of parsing, generally based on variants of generative context free grammars.", "labels": [], "entities": []}, {"text": "The second change occurred with the use of discriminative machine learning techniques, first to rerank the output of a stochastic parser) and then in the parser itself).", "labels": [], "entities": []}, {"text": "Such parsers clearly depart from classical parsers in the sense that they do not rely anymore on a generative grammar: given a sentence S, all possible parses for S 1 are considered as possible parses of S.", "labels": [], "entities": []}, {"text": "A parse tree is seen as a set of lexico-syntactic features which are associated to weights.", "labels": [], "entities": []}, {"text": "The score of a parse is computed as the sum of the weights of its features.", "labels": [], "entities": []}, {"text": "This new generation of parsers allows to reach high accuracy but possess their own limitations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9971856474876404}]}, {"text": "We will focus in this paper on one kind of weakness of such parser which is their inability to properly take into account subcategorization frames (SF) of predicative lexemes , an important source of lexicosyntactic constraints.", "labels": [], "entities": []}, {"text": "The proper treatment of SF is actually confronted to two kinds of problems: (1) the acquisition of correct SF for verbs and (2) the integration of such constraints in the parser.", "labels": [], "entities": []}, {"text": "The first problem is a consequence of the use of treebanks for training parsers.", "labels": [], "entities": []}, {"text": "Such treebanks are composed of a few thousands sentences and only a small subpart of acceptable SF fora verb actually Another important aspect of the new parsing paradigm is the use of dependency trees as a means to represent syntactic structure.", "labels": [], "entities": []}, {"text": "In dependency syntax, the number of possible syntactic trees associated to a sentence is bounded, and only depends on the length of the sentence, which is not the case with syntagmatic derivation trees.", "labels": [], "entities": []}, {"text": "We will concentrate in this paper on verbal SF.", "labels": [], "entities": [{"text": "verbal SF", "start_pos": 37, "end_pos": 46, "type": "TASK", "confidence": 0.7308162152767181}]}, {"text": "The second problem is a consequence of the parsing models.", "labels": [], "entities": [{"text": "parsing", "start_pos": 43, "end_pos": 50, "type": "TASK", "confidence": 0.971448540687561}]}, {"text": "For algorithmic complexity as well as data sparseness reasons, the parser only considers lexico-syntactic configurations of limited domain of locality (in the parser used in the current work, this domain of locality is limited to configurations made of one or two dependencies).", "labels": [], "entities": []}, {"text": "As described in more details in section 2, SF often exceed in scope such domains of locality and are therefore not easy to integrate in the parser.", "labels": [], "entities": [{"text": "SF", "start_pos": 43, "end_pos": 45, "type": "METRIC", "confidence": 0.8583097457885742}]}, {"text": "A popular method for introducing higher order constraints in a parser consist in reranking then best output of a parser as in).", "labels": [], "entities": []}, {"text": "The reranker search space is restricted by the output of the parser and high order features can be used.", "labels": [], "entities": []}, {"text": "One drawback of the reranking approach is that correct SF for the predicates of a sentence can actually appear in different parse trees.", "labels": [], "entities": []}, {"text": "Selecting complete trees can therefore lead to sub-optimal solutions.", "labels": [], "entities": []}, {"text": "The method proposed in this paper merges parts of different trees that appear in an n best list in order to build anew parse.", "labels": [], "entities": []}, {"text": "Taking into account SF in a parser has been a major issue in the design of syntactic formalisms in the eighties and nineties.", "labels": [], "entities": []}, {"text": "Unification grammars, such as Lexical Functional Grammars, Generalized Phrase Structure Grammars ( and Head-driven Phrase Structure Grammars, made SF part of the grammar.", "labels": [], "entities": []}, {"text": "Tree Adjoining Grammars ( proposed to extend the domain of locality of Context Free Grammars partly in order to be able to represent SF in a generative grammar.", "labels": [], "entities": []}, {"text": "More recently, proposed away to introduce SF in a probabilistic context free grammar and (Arun and) used the same technique for French., used subcategorization probabilities for ranking trees generated by unification-based phrasal grammar and showed that using frame frequency in a dependency parser can lead to a significant improvement of the performance of the parser.", "labels": [], "entities": []}, {"text": "The main novelties of the work presented here is (1) the way anew parse is built by combining subparses that appear in then best parse list and (2) the use of three very different resources that list the possible SF for verbs.", "labels": [], "entities": []}, {"text": "The organization of the paper is the following: in section 2, we will briefly describe the parsing model that we will be using for this work and give accuracy results on a French corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.9990319013595581}, {"text": "French corpus", "start_pos": 172, "end_pos": 185, "type": "DATASET", "confidence": 0.9231368899345398}]}, {"text": "Section 3 will describe three different resources that we have been using to correct SF errors made by the parser and give coverage results for these resources on a development corpus.", "labels": [], "entities": [{"text": "coverage", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.954763650894165}]}, {"text": "Section 4 will propose three different ways to take into account, in the parser, the resources described in section 3 and give accuracy results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.9992474317550659}]}, {"text": "Section 5 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Size and decomposition of the French Treebank", "labels": [], "entities": [{"text": "Size", "start_pos": 10, "end_pos": 14, "type": "TASK", "confidence": 0.9689810872077942}, {"text": "French Treebank", "start_pos": 40, "end_pos": 55, "type": "DATASET", "confidence": 0.986372321844101}]}, {"text": " Table 2: Subcategorization Frame Accuracy, Labeled and  Unlabeled Accuracy Score on TEST and DEV.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9258748888969421}, {"text": "Accuracy Score", "start_pos": 67, "end_pos": 81, "type": "METRIC", "confidence": 0.8758322298526764}, {"text": "TEST", "start_pos": 85, "end_pos": 89, "type": "DATASET", "confidence": 0.7839176654815674}, {"text": "DEV", "start_pos": 94, "end_pos": 97, "type": "DATASET", "confidence": 0.5644671320915222}]}, {"text": " Table 4: sizes of the corpora used to collect SF", "labels": [], "entities": []}, {"text": " Table 5: Lexical and syntactic coverage of the three re- sources on DEV", "labels": [], "entities": [{"text": "DEV", "start_pos": 69, "end_pos": 72, "type": "DATASET", "confidence": 0.9253228902816772}]}, {"text": " Table 6: LAS and UAS on TEST using PP", "labels": [], "entities": [{"text": "LAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.819144070148468}, {"text": "UAS", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.3637402653694153}]}, {"text": " Table 8: LAS and UAS on TEST using DP", "labels": [], "entities": [{"text": "LAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.800464928150177}, {"text": "UAS", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.5723249912261963}, {"text": "DP", "start_pos": 36, "end_pos": 38, "type": "DATASET", "confidence": 0.5539827346801758}]}, {"text": " Table 9: LAS and UAS on TEST using PP with resource  combination", "labels": [], "entities": [{"text": "LAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8021873831748962}, {"text": "UAS", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.489725798368454}]}, {"text": " Table 10: LAS and UAS on TEST using DP with resource  combination", "labels": [], "entities": [{"text": "LAS", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.733361542224884}, {"text": "UAS", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.5495700836181641}]}]}