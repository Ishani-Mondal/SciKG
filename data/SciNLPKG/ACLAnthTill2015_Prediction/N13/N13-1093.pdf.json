{"title": [{"text": "Exploiting the Scope of Negations and Heterogeneous Features for Relation Extraction: A Case Study for Drug-Drug Interaction Extraction", "labels": [], "entities": [{"text": "Relation Extraction", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.9560348391532898}, {"text": "Drug-Drug Interaction Extraction", "start_pos": 103, "end_pos": 135, "type": "TASK", "confidence": 0.6413506468137106}]}], "abstractContent": [{"text": "This paper presents an approach that exploits the scope of negation cues for relation extraction (RE) without the need of using any specifically annotated dataset for building a separate negation scope detection classifier.", "labels": [], "entities": [{"text": "relation extraction (RE)", "start_pos": 77, "end_pos": 101, "type": "TASK", "confidence": 0.8490074276924133}, {"text": "negation scope detection classifier", "start_pos": 187, "end_pos": 222, "type": "TASK", "confidence": 0.7523990571498871}]}, {"text": "New features are proposed which are used in two different stages.", "labels": [], "entities": []}, {"text": "These also include non-target entity specific features.", "labels": [], "entities": []}, {"text": "The proposed RE approach outperforms the previous state of the art for drug-drug interaction (DDI) extraction.", "labels": [], "entities": [{"text": "RE", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.9289576411247253}, {"text": "drug-drug interaction (DDI) extraction", "start_pos": 71, "end_pos": 109, "type": "TASK", "confidence": 0.737438827753067}]}], "introductionContent": [{"text": "Negation is a linguistic phenomenon where a negation cue (e.g. not) can alter the meaning of a particular text segment or of a fact.", "labels": [], "entities": []}, {"text": "This text segment (or fact) is said to be inside the scope of that negation (cue).", "labels": [], "entities": []}, {"text": "In the context of RE, there is not much work that aims to exploit the scope of negations.", "labels": [], "entities": [{"text": "RE", "start_pos": 18, "end_pos": 20, "type": "TASK", "confidence": 0.9743544459342957}]}, {"text": "The only work on RE that we are aware of is where they used various heuristics to extract negative protein interaction.", "labels": [], "entities": [{"text": "RE", "start_pos": 17, "end_pos": 19, "type": "TASK", "confidence": 0.9718034267425537}]}, {"text": "Despite the recent interest on automatically detecting the scope of negation 2 till now there seems to be no empirical evidence supporting its exploitation for the purpose of RE.", "labels": [], "entities": [{"text": "negation 2", "start_pos": 68, "end_pos": 78, "type": "TASK", "confidence": 0.8388517796993256}, {"text": "RE", "start_pos": 175, "end_pos": 177, "type": "TASK", "confidence": 0.9187924265861511}]}, {"text": "Even if we could manage to obtain highly accurate automatically detected In the context of event extraction (a closely related task of RE), there have been efforts in BioNLP shared tasks of 2009 and 2011 for (non-mandatory sub-task of) event negation detection (3 participants in 2009; 2 in 2011) ().", "labels": [], "entities": [{"text": "event extraction", "start_pos": 91, "end_pos": 107, "type": "TASK", "confidence": 0.7838426828384399}, {"text": "event negation detection", "start_pos": 236, "end_pos": 260, "type": "TASK", "confidence": 0.7508086363474528}]}, {"text": "The participants approached the sub-task using either pre-defined patterns or some heuristics.", "labels": [], "entities": []}, {"text": "This task is popularized by various recently held shared tasks negation scopes, it is not clear how to feed this information inside the RE approach.", "labels": [], "entities": [{"text": "RE", "start_pos": 136, "end_pos": 138, "type": "TASK", "confidence": 0.8918312788009644}]}, {"text": "Simply considering whether a pair of candidate mentions falls under the scope of a negation cue might not be helpful.", "labels": [], "entities": []}, {"text": "In this paper, we propose that the scope of negations can be exploited at two different levels.", "labels": [], "entities": []}, {"text": "Firstly, the system would check whether all the target entity 3 mentions inside a sentence along with possible relation clues (or trigger words), if any, fall (directly or indirectly) under the scope of a negation cue.", "labels": [], "entities": []}, {"text": "If such a sentence is found, then it should be discarded (i.e. candidate mention pairs 4 inside that sentence would not be considered).", "labels": [], "entities": []}, {"text": "Secondly, for each of the remaining pairs of candidate mentions, the system should exploit features related to the scope of negation (rather than simply adding a feature for negation cue, approach adopted in various RE systems) that can provide indication (if any such evidence exists) that the corresponding relation of interest actually does not hold in that particular context.", "labels": [], "entities": []}, {"text": "In the subsequent sections, we describe our approach.", "labels": [], "entities": []}, {"text": "The RE task considered is drug-drug interaction (DDI) extraction.", "labels": [], "entities": [{"text": "RE", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.9472048282623291}, {"text": "drug-drug interaction (DDI) extraction", "start_pos": 26, "end_pos": 64, "type": "TASK", "confidence": 0.7023398578166962}]}, {"text": "The task has significant importance for public health safety.", "labels": [], "entities": [{"text": "public health safety", "start_pos": 40, "end_pos": 60, "type": "TASK", "confidence": 0.7565216422080994}]}, {"text": "We used The target entities, for example, for DDI extraction and for EMP-ORG relation extraction would be {DRUG} and {PER, GPE, ORG} respectively.", "labels": [], "entities": [{"text": "DDI extraction", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.7590857744216919}, {"text": "EMP-ORG relation extraction", "start_pos": 69, "end_pos": 96, "type": "TASK", "confidence": 0.6629539231459299}, {"text": "PER", "start_pos": 118, "end_pos": 121, "type": "METRIC", "confidence": 0.9206984639167786}]}, {"text": "Any entity other than the target entities (w.r.t. the particular RE task) belongs to non-target entities.", "labels": [], "entities": []}, {"text": "Candidate mention pairs for RE are taken from target entity mentions.", "labels": [], "entities": [{"text": "RE", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.6371082663536072}]}, {"text": "After the death of pop star Michael Jackson, allegedly due to DDI, it was reported that about 2.2 million people in USA, age 57 to 85, were taking potentially dangerous combinations of drugs).", "labels": [], "entities": []}, {"text": "An earlier report mentioned that deaths from accidental drug interactions rose 68 percent between.", "labels": [], "entities": []}, {"text": "the DDIExtraction-2011 challenge corpus).", "labels": [], "entities": [{"text": "DDIExtraction-2011 challenge corpus", "start_pos": 4, "end_pos": 39, "type": "DATASET", "confidence": 0.9205696185429891}]}, {"text": "The official training and test data of the corpus contain 4,267 and 1,539 sentences, and 2,402 and 755 DDI annotations respectively.", "labels": [], "entities": []}, {"text": "2 Proposed Approach 2.1 Stage 1: Exploiting scope of negation to filter out sentences We propose a two stage RE approach.", "labels": [], "entities": [{"text": "RE", "start_pos": 109, "end_pos": 111, "type": "TASK", "confidence": 0.9392074346542358}]}, {"text": "In the first stage, our goal is to exploit the scope of negations to reduce the number of candidate mention pairs by discarding sentences.", "labels": [], "entities": []}, {"text": "For this purpose, we propose the following features to train a binary classifier: \u2022 has2TM: If the sentence has exactly 2 target entity mentions (i.e. drug mentions for DDI extraction).", "labels": [], "entities": [{"text": "DDI extraction", "start_pos": 169, "end_pos": 183, "type": "TASK", "confidence": 0.8224910795688629}]}, {"text": "\u2022 has3OrMoreTM: Whether the sentence has more than 2 target entity mentions.", "labels": [], "entities": []}, {"text": "\u2022 allTMonRight: Whether all target entity mentions inside the sentence appear after the negation cue.", "labels": [], "entities": [{"text": "allTMonRight", "start_pos": 2, "end_pos": 14, "type": "METRIC", "confidence": 0.9545682072639465}]}, {"text": "\u2022 neitherAllTMonLeftOrRight: Whether some but not all target entity mentions appear after the negation cue.", "labels": [], "entities": []}, {"text": "\u2022 negCue: The negation cue itself.", "labels": [], "entities": []}, {"text": "\u2022 immediateGovernor: The word on which the cue is directly syntactically dependent.", "labels": [], "entities": []}, {"text": "\u2022 nearestVerbGovernor: The nearest verb in the dependency graph on which the cue is syntactically dependent.", "labels": [], "entities": []}, {"text": "\u2022 isVerbGovernorRoot: Whether the nearestVerbGovernor is root of the dependency graph of the sentence.", "labels": [], "entities": []}, {"text": "\u2022 allTMdependentOnNVG: Whether all target entity mentions are syntactically dependent (directly/indirectly) on the nearestVerbGovernor.", "labels": [], "entities": [{"text": "allTMdependentOnNVG", "start_pos": 2, "end_pos": 21, "type": "METRIC", "confidence": 0.9748796224594116}]}, {"text": "\u2022 allButOneTMdependentOnNVG: Whether all but one target entity mentions are syntactically dependent on the nearestVerbGovernor.", "labels": [], "entities": []}, {"text": "\u2022 although*PrecedeCue: Whether the syntactic clause containing the negation cue begins with \"although / though / despite / in spite\".", "labels": [], "entities": [{"text": "PrecedeCue", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.7477898001670837}]}, {"text": "\u2022 commaBeforeNextTM: Whether there is a comma in the text between the negation cue and the next target entity mention after the cue.", "labels": [], "entities": []}, {"text": "\u2022 commaAfterPrevTM: Whether there is a comma in the text between the previous target entity mention before the negation cue and the cue itself.", "labels": [], "entities": []}, {"text": "\u2022 sentHasBut: Whether the sentence contains the word \"but\".", "labels": [], "entities": []}, {"text": "The objective of the classifier is to decide whether all of the target entity mentions (i.e. drugs) as well as any possible evidence of the relation of interest (for which we assume the immediate and the nearest verb governors of the negation cue would be good candidates) inside the corresponding sentence fall under the scope of a negation cue in such away that the sentence is unlikely to contain a DDI.", "labels": [], "entities": []}, {"text": "In the Stage 1, any sentence that contains at least one DDI is considered by the classifier as a positive (training/test) instance.", "labels": [], "entities": []}, {"text": "Other sentences are considered as negative instances.", "labels": [], "entities": []}, {"text": "We rule out any sentence (i.e. we do not consider as training/test instance for the classifier that filters less informative sentences) during both training and testing if any of the following conditions holds: \u2022 The sentence contains less than two target entity mentions (such sentence would not contain the relation of interest anyway).", "labels": [], "entities": []}, {"text": "\u2022 It has any of the following phrases -\"not recommended\", \"should not be\" or \"must not be\".", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: 5-fold cross-validation results on training data.", "labels": [], "entities": []}, {"text": " Table 2: Results obtained on the official test set of the  2011 DDI Extraction challenge. LII filtering refers to the  techniques proposed in Chowdhury and Lavelli (2012b)  for reducing skewness in RE data distribution. stat. sig. in- dicates that the improvement of F-score, due to usage of  Stage 1 classifier, is statistically significant (verified using  Approximate Randomization Procedure (", "labels": [], "entities": [{"text": "official test set of the  2011 DDI Extraction challenge", "start_pos": 34, "end_pos": 89, "type": "DATASET", "confidence": 0.7427485717667474}, {"text": "LII filtering", "start_pos": 91, "end_pos": 104, "type": "TASK", "confidence": 0.6733059585094452}, {"text": "RE data distribution. stat. sig. in", "start_pos": 199, "end_pos": 234, "type": "DATASET", "confidence": 0.8054344994681222}, {"text": "F-score", "start_pos": 268, "end_pos": 275, "type": "METRIC", "confidence": 0.9962146878242493}, {"text": "Approximate", "start_pos": 360, "end_pos": 371, "type": "METRIC", "confidence": 0.9675795435905457}]}]}