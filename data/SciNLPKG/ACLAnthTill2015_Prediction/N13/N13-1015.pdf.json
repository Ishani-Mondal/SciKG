{"title": [{"text": "Experiments with Spectral Learning of Latent-Variable PCFGs", "labels": [], "entities": []}], "abstractContent": [{"text": "Latent-variable PCFGs (L-PCFGs) area highly successful model for natural language parsing.", "labels": [], "entities": [{"text": "natural language parsing", "start_pos": 65, "end_pos": 89, "type": "TASK", "confidence": 0.6453130145867666}]}, {"text": "Recent work (Cohen et al., 2012) has introduced a spectral algorithm for parameter estimation of L-PCFGs, which-unlike the EM algorithm-is guaranteed to give consistent parameter estimates (it has PAC-style guarantees of sample complexity).", "labels": [], "entities": []}, {"text": "This paper describes experiments using the spectral algorithm.", "labels": [], "entities": []}, {"text": "We show that the algorithm provides models with the same accuracy as EM, but is an order of magnitude more efficient.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9986943602561951}]}, {"text": "We describe a number of key steps used to obtain this level of performance; these should be relevant to other work on the application of spectral learning algorithms.", "labels": [], "entities": []}, {"text": "We view our results as strong empirical evidence for the viability of spectral methods as an alternative to EM.", "labels": [], "entities": []}], "introductionContent": [{"text": "Latent-variable PCFGS (L-PCFGs) area highly successful model for natural language parsing).", "labels": [], "entities": [{"text": "natural language parsing", "start_pos": 65, "end_pos": 89, "type": "TASK", "confidence": 0.6594570378462473}]}, {"text": "Recent work () has introduced a spectral learning algorithm for L-PCFGs.", "labels": [], "entities": []}, {"text": "A crucial property of the algorithm is that it is guaranteed to provide consistent parameter estimates-in fact it has PAC-style guarantees of sample complexity.", "labels": [], "entities": []}, {"text": "1 This is in contrast to the EM algorithm, the usual method for parameter estimation in L-PCFGs, which has the weaker guarantee of reaching a local maximum of the likelihood function.", "labels": [], "entities": [{"text": "parameter estimation", "start_pos": 64, "end_pos": 84, "type": "TASK", "confidence": 0.6940109729766846}]}, {"text": "The spectral algorithm is relatively simple and efficient, relying on a singular value decomposition of the training examples, followed by a single pass over the data where parameter values are calculated.", "labels": [], "entities": []}, {"text": "describe the algorithm, and the theory behind it, but as yet no experimental results have been reported for the method.", "labels": [], "entities": []}, {"text": "This paper describes experiments on natural language parsing using the spectral algorithm for parameter estimation.", "labels": [], "entities": [{"text": "natural language parsing", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.6423325141270956}]}, {"text": "The algorithm provides models with slightly higher accuracy than EM (88.05% F-measure on test data for the spectral algorithm, vs 87.76% for EM), but is an order of magnitude more efficient (9h52m for training, compared to 187h12m, a speed-up of 19 times).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9979512095451355}, {"text": "F-measure", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9968600273132324}]}, {"text": "We describe a number of key steps in obtaining this level of performance.", "labels": [], "entities": []}, {"text": "A simple backed-off smoothing method is used to estimate the large number of parameters in the model.", "labels": [], "entities": []}, {"text": "The spectral algorithm requires functions mapping inside and outside trees to feature vectors-we make use of features corresponding to single level rules, and larger tree fragments composed of two or three levels of rules.", "labels": [], "entities": []}, {"text": "We show that it is important to scale features by their inverse variance, in a manner that is closely related to methods used in canonical correlation analysis.", "labels": [], "entities": [{"text": "canonical correlation analysis", "start_pos": 129, "end_pos": 159, "type": "TASK", "confidence": 0.697746733824412}]}, {"text": "Negative values can cause issues in spectral algorithms, but we describe a solution to these problems.", "labels": [], "entities": []}, {"text": "In recent work there has been a series of results in spectral learning algorithms for latent-variable models ().", "labels": [], "entities": []}, {"text": "Most of these results are theoretical (although see for empirical results of spectral learning for dependency parsing).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 99, "end_pos": 117, "type": "TASK", "confidence": 0.8131261765956879}]}, {"text": "While the focus of our experiments is on parsing, our findings should be relevant to the application of spectral methods to other latent-variable models.", "labels": [], "entities": [{"text": "parsing", "start_pos": 41, "end_pos": 48, "type": "TASK", "confidence": 0.974946916103363}]}, {"text": "We view our results as strong empirical evidence for the viability of spectral methods as an alternative to EM.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Results on the development data (section 22,  with machine-generated POS tags) and test data (section  23, with machine-generated POS tags).", "labels": [], "entities": []}, {"text": " Table 1: Results on section 22 for the EM algorithm, varying the number of iterations used. Best results in each row  are in boldface.", "labels": [], "entities": [{"text": "EM algorithm", "start_pos": 40, "end_pos": 52, "type": "TASK", "confidence": 0.8328944742679596}]}, {"text": " Table 3: Running time for the EM algorithm and the various stages in the spectral algorithm. For EM we show the  time for a single iteration, and the time to train the optimal model (time for 30 iterations of training for m = 8, 16, 24,  time for 20 iterations of training for m = 32).", "labels": [], "entities": []}]}