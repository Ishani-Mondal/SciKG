{"title": [{"text": "An Analysis of Frequency-and Memory-Based Processing Costs", "labels": [], "entities": [{"text": "Frequency-and Memory-Based Processing Costs", "start_pos": 15, "end_pos": 58, "type": "TASK", "confidence": 0.5212301537394524}]}], "abstractContent": [{"text": "The frequency of words and syntactic constructions has been observed to have a substantial effect on language processing.", "labels": [], "entities": []}, {"text": "This begs the question of what causes certain constructions to be more or less frequent.", "labels": [], "entities": []}, {"text": "A theory of grounding (Phillips, 2010) would suggest that cognitive limitations might cause languages to develop frequent constructions in such away as to avoid processing costs.", "labels": [], "entities": []}, {"text": "This paper studies how current theories of working memory fit into theories of language processing and what influence memory limitations may have over reading times.", "labels": [], "entities": []}, {"text": "Measures of such limitations are evaluated on eye-tracking data and the results are compared with predictions made by different theories of processing.", "labels": [], "entities": []}], "introductionContent": [{"text": "Frequency effects in language have been isolated and observed in many studies.", "labels": [], "entities": [{"text": "Frequency", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9704540967941284}]}, {"text": "These effects are important because they illuminate the ontogeny of language (how individual speakers have acquired language), but they do not answer questions about the phylogeny of language (how the language came to its current form). has hypothesized that grammar rule probabilities maybe grounded in memory limitations.", "labels": [], "entities": []}, {"text": "Increased delays in processing centerembedded sentences as the number of embeddings increases, for example, are often explained in terms of a complexity cost associated with maintaining incomplete dependencies in working memory;).", "labels": [], "entities": []}, {"text": "Other studies have shown a link between processing delays and the low frequency of center-embedded constructions like object relatives), but they have not explored the source of this low frequency.", "labels": [], "entities": []}, {"text": "A grounding hypothesis would claim that the low probability of generating such a structure may arise from an associated memory load.", "labels": [], "entities": []}, {"text": "In this account, while these complexity costs may involve languagespecific concepts such as referent or argument linking, the underlying explanation would be one of memory limitations) or neural activation (.", "labels": [], "entities": []}, {"text": "This paper seeks to explore the different predictions made by these theories on a broad-coverage corpus of eye-tracking data (.", "labels": [], "entities": []}, {"text": "In addition, the current experiment seeks to isolate memory effects from frequency effects in the same task.", "labels": [], "entities": []}, {"text": "The results show that memory load measures area significant factor even when frequency measures are residualized out.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows: Sections 2 and 3 describe several frequency and memory measures.", "labels": [], "entities": []}, {"text": "Section 4 describes a probabilistic hierarchic sequence model that allows all of these measures to be directly computed.", "labels": [], "entities": []}, {"text": "Section 5 describes how these measures were used to predict reading time durations on the Dundee eye-tracking corpus.", "labels": [], "entities": [{"text": "Dundee eye-tracking corpus", "start_pos": 90, "end_pos": 116, "type": "DATASET", "confidence": 0.8971812725067139}]}, {"text": "Sections 6 and 7 present results and discuss.", "labels": [], "entities": []}], "datasetContent": [{"text": "The measures presented in this paper were evaluated on the Dundee eye-tracking corpus (.", "labels": [], "entities": [{"text": "Dundee eye-tracking corpus", "start_pos": 59, "end_pos": 85, "type": "DATASET", "confidence": 0.8694203694661459}]}, {"text": "The corpus consists of 2388 sentences of naturally occurring news text written in standard British English.", "labels": [], "entities": []}, {"text": "The corpus also includes eye-tracking data from 10 native English speakers, which provides a test corpus of 260,124 subject-duration pairs of reading time data.", "labels": [], "entities": []}, {"text": "Of this, any fixated words appearing fewer than 5 times in the training data were considered unknown and were filtered out to obtain accurate predictions.", "labels": [], "entities": []}, {"text": "Fixations on the first or last words of a line were also filtered out to avoid any 'wrap-up' effects resulting from preparing to saccade to the beginning of the next line or resulting from orienting to anew line.", "labels": [], "entities": []}, {"text": "Additionally, following, any fixations that skip more than 4 words were attributed to track loss by the eyetracker or lack of attention of the reader and so were excluded from the analysis.", "labels": [], "entities": []}, {"text": "This left the final evaluation corpus with 151,331 subject-duration pairs.", "labels": [], "entities": []}, {"text": "The evaluation consisted of fitting a linear mixedeffects model ( ) to reading time durations using the lmer function of the lme4 R package (.", "labels": [], "entities": []}, {"text": "This allowed by-subject and by-item variation to be included in the initial regression as random intercepts in addition to several baseline predictors.", "labels": [], "entities": []}, {"text": "Before fitting, the durations extracted from Each fixed effect was centered to reduce collinearity.", "labels": [], "entities": [{"text": "durations", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9560314416885376}]}, {"text": "the corpus were log-transformed, producing more normally distributed data to obey the assumptions of linear mixed effects models.", "labels": [], "entities": []}, {"text": "Included among the fixed effects were the position in the sentence that initiated the go-past region (SENTPOS) and the number of characters in the initiating word (NRCHAR).", "labels": [], "entities": [{"text": "SENTPOS)", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9274016618728638}]}, {"text": "The difficulty of integrating a word maybe seen in whether the immediately following word was fixated (NEXTISFIX), and similarly if the immediately previous word was fixated (PREVISFIX) the current word probably need not be fixated for as long.", "labels": [], "entities": []}, {"text": "Finally, unigram (LOGPROB) and bigram probabilities are included.", "labels": [], "entities": [{"text": "unigram (LOGPROB)", "start_pos": 9, "end_pos": 26, "type": "METRIC", "confidence": 0.7224338054656982}]}, {"text": "The bigram probabilities are those of the current word given the previous word (LOGFWPROB) and the current word given the following word (LOGBWPROB).", "labels": [], "entities": [{"text": "LOGFWPROB", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.840779185295105}]}, {"text": "showed that for n-gram probabilities to be effective predictors on the Dundee corpus, they must be calculated from a wide variety of texts, so following them, this study used the Brown corpus, the WSJ Sections 02-21 (, the written text portion of the British National Corpus, and the Dundee corpus (.", "labels": [], "entities": [{"text": "Dundee corpus", "start_pos": 71, "end_pos": 84, "type": "DATASET", "confidence": 0.986351877450943}, {"text": "Brown corpus", "start_pos": 179, "end_pos": 191, "type": "DATASET", "confidence": 0.9711255431175232}, {"text": "WSJ Sections 02-21", "start_pos": 197, "end_pos": 215, "type": "DATASET", "confidence": 0.9368000030517578}, {"text": "British National Corpus", "start_pos": 251, "end_pos": 274, "type": "DATASET", "confidence": 0.9280480941136678}, {"text": "Dundee corpus", "start_pos": 284, "end_pos": 297, "type": "DATASET", "confidence": 0.9948877096176147}]}, {"text": "This amounted to an n-gram training corpus of roughly 87 million words.", "labels": [], "entities": []}, {"text": "These statistics were smoothed using the SRILM) implementation of modified Kneser-Ney smoothing).", "labels": [], "entities": []}, {"text": "Finally, total surprisal (SURP) was included to account for frequency effects in the baseline.", "labels": [], "entities": [{"text": "total surprisal (SURP)", "start_pos": 9, "end_pos": 31, "type": "METRIC", "confidence": 0.8742286682128906}]}, {"text": "The preceding measures are commonly used in baseline models to fit reading time data) and were calculated from the final word of each go-past region.", "labels": [], "entities": []}, {"text": "The following measures create a more sophisticated baseline by accumulating over the entire go-past region to capture what must be integrated into the discourse to continue the parse.", "labels": [], "entities": []}, {"text": "One factor (CWDELTA) simply counts the number of words in each go-past region.", "labels": [], "entities": []}, {"text": "Cumula-tive total surprisal (CUMUSURP) and cumulative entropy reduction (ENTRED) give the surprisal) and entropy reduction summed over the go-past region.", "labels": [], "entities": [{"text": "cumulative entropy reduction (ENTRED)", "start_pos": 43, "end_pos": 80, "type": "METRIC", "confidence": 0.8507771094640096}]}, {"text": "To avoid convergence issues, each of the cumulative measures is residualized from the next simpler model in the following order: CWDELTA from the standard baseline, CU-MUSURP from the baseline with CWDELTA, and EN-TRED from the baseline with all other effects.", "labels": [], "entities": [{"text": "EN-TRED", "start_pos": 211, "end_pos": 218, "type": "METRIC", "confidence": 0.8708731532096863}]}, {"text": "Residualization was accomplished by using the simpler mixed-effects model to fit the measure of interest.", "labels": [], "entities": []}, {"text": "The residuals from that model fit were then used in place of the factor of interest.", "labels": [], "entities": []}, {"text": "All joint interactions were included in the baseline model as well.", "labels": [], "entities": []}, {"text": "Finally, to account for spillover effects where processing from a previous region contributes to the following duration, the above baseline predictors from the previous go-past region were included as factors for the current region.", "labels": [], "entities": [{"text": "duration", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9624944925308228}]}, {"text": "Having SURP as a predictor with CUMUSURP may seem redundant, but initial analyses showed SURP was a significant predictor over CUMUSURP when CWDELTA was a separate factor in the baseline (current: p = 2.2 \u00b7 10 \u221216 spillover: p = 2 \u00b7 10 \u221215 ) and vice versa (current: p = 2.2 \u00b7 10 \u221216 spillover: p = 6 \u00b7 10 \u22125 ).", "labels": [], "entities": []}, {"text": "One reason for this could be that go-past durations conflate complexity experienced when initially fixating on a region with the difficulty experienced during regressions.", "labels": [], "entities": []}, {"text": "By including both versions of surprisal, the model is able to account for frequency effects occurring in both conditions.", "labels": [], "entities": []}, {"text": "This study is only interested in how well the proposed memory-based measures fit the data over the baseline, so to avoid fitting to the test data or weakening the baseline by overfitting to training data, the full baseline was used in the final evaluation.", "labels": [], "entities": []}, {"text": "Each measure proposed in this paper was summed over go-past regions to make it cumulative and was residualized from all non-spillover factors before being included on top of the full baseline as a main effect.", "labels": [], "entities": []}, {"text": "Likewise, the spillover version of each proposed measure was residualized from the other spillover factors before being included as a main effect.", "labels": [], "entities": []}, {"text": "Only a single proposed measure (or its spillover corrollary) was included in each model.", "labels": [], "entities": []}, {"text": "The results shown in reflect the probability of the full model fit being obtained by the model lacking each factor of interest.", "labels": [], "entities": []}, {"text": "This was found via posterior sam-: Significance of each of the structure generation outcomes at predicting log-transformed durations when added to the baseline as a main effect after being residualized from it.", "labels": [], "entities": []}, {"text": "The sign of the t-score indicates the direction of the correlation between the residualized factor and go-past durations.", "labels": [], "entities": []}, {"text": "Note that these factors are all based on the current go-past region; the spillover corollaries of these were not significant predictors of reading times.", "labels": [], "entities": []}, {"text": "pling of each factor using the Markov chain Monte Carlo implementation of the languageR R package . The results indicate that the F+L-and F-L+ measures were both significant predictors of duration as expected.", "labels": [], "entities": [{"text": "languageR R package", "start_pos": 78, "end_pos": 97, "type": "DATASET", "confidence": 0.8710665305455526}, {"text": "F+L-and F-L+ measures", "start_pos": 130, "end_pos": 151, "type": "METRIC", "confidence": 0.8541862765947977}, {"text": "duration", "start_pos": 188, "end_pos": 196, "type": "METRIC", "confidence": 0.9935861229896545}]}, {"text": "Further, F-L-and F+L+, which both simply reflect sequential cueing, were not significant predictors of go-past duration, also as expected.", "labels": [], "entities": [{"text": "F-L-and F+L+", "start_pos": 9, "end_pos": 21, "type": "METRIC", "confidence": 0.8636488318443298}, {"text": "duration", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.648270308971405}]}], "tableCaptions": [{"text": " Table 3: Significance of each of the structure generation  outcomes at predicting log-transformed durations when  added to the baseline as a main effect after being residu- alized from it. The sign of the t-score indicates the direc- tion of the correlation between the residualized factor and  go-past durations. Note that these factors are all based  on the current go-past region; the spillover corollaries of  these were not significant predictors of reading times.", "labels": [], "entities": []}]}