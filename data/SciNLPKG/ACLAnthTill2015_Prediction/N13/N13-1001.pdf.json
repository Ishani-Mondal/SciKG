{"title": [{"text": "Model With Minimal Translation Units, But Decode With Phrases", "labels": [], "entities": []}], "abstractContent": [{"text": "N-gram-based models co-exist with their phrase-based counterparts as an alternative SMT framework.", "labels": [], "entities": [{"text": "SMT", "start_pos": 84, "end_pos": 87, "type": "TASK", "confidence": 0.9859492182731628}]}, {"text": "Both techniques have pros and cons.", "labels": [], "entities": []}, {"text": "While the N-gram-based framework provides a better model that captures both source and target contexts and avoids spurious phrasal segmentation, the ability to memorize and produce larger translation units gives an edge to the phrase-based systems during decoding, in terms of better search performance and superior selection of translation units.", "labels": [], "entities": []}, {"text": "In this paper we combine N-gram-based modeling with phrase-based decoding, and obtain the benefits of both approaches.", "labels": [], "entities": []}, {"text": "Our experiments show that using this combination not only improves the search accuracy of the N-gram model but that it also improves the BLEU scores.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9585132598876953}, {"text": "BLEU", "start_pos": 137, "end_pos": 141, "type": "METRIC", "confidence": 0.9993258714675903}]}, {"text": "Our system outperforms state-of-the-art phrase-based systems (Moses and Phrasal) and N-gram-based systems by a significant margin on German, French and Spanish to English translation tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical Machine Translation advanced from word-based models) towards more sophisticated models that take contextual information into account.", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7752540111541748}]}, {"text": "Phrase-based () and N-gram-based ) models are two instances of such frameworks.", "labels": [], "entities": []}, {"text": "While the two models have some common properties, they are substantially different.", "labels": [], "entities": []}, {"text": "* Much of the work presented here was carried out while the first author was at the University of Stuttgart.", "labels": [], "entities": []}, {"text": "Phrase-based systems employ a simple and effective machinery by learning larger chunks of translation called phrases . Memorizing larger units enables the phrase-based model to learn local dependencies such as short reorderings, idioms, insertions and deletions, etc.", "labels": [], "entities": []}, {"text": "The model however, has the following drawbacks: i) it makes independence assumptions over phrases ignoring the contextual information outside of phrases ii) it has issues handling long-distance reordering iii) it has the spurious phrasal segmentation problem which allows multiple derivations of a bilingual sentence pair having different model scores for each segmentation.", "labels": [], "entities": []}, {"text": "Modeling with minimal translation units helps address some of these issues.", "labels": [], "entities": []}, {"text": "The N-gram-based SMT framework is based on tuples.", "labels": [], "entities": [{"text": "SMT", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.8856092095375061}]}, {"text": "Tuples are minimal translation units composed of source and target cepts 2 . N-gram-based models are Markov models over sequences of tuples ) or operations encapsulating tuples.", "labels": [], "entities": []}, {"text": "This mechanism has several useful properties.", "labels": [], "entities": []}, {"text": "Firstly, no phrasal independence assumption is made.", "labels": [], "entities": []}, {"text": "The model has access to both source and target context outside of phrases.", "labels": [], "entities": []}, {"text": "Secondly the model learns a unique derivation of a bilingual sentence given its alignment, thus avoiding the spurious segmentation problem.", "labels": [], "entities": []}, {"text": "Using minimal translation units, however, results in a higher number of search errors because of i) poor translation selection, ii) inaccurate future-cost estimates and iii) incorrect early pruning of hypotheses that would produce better model scores if allowed to continue.", "labels": [], "entities": []}, {"text": "In order to deal with these problems, search is carried out only on a graph of pre-calculated orderings, and ad-hoc reordering limits are imposed to constrain the search space (), or a higher beam size is used in decoding).", "labels": [], "entities": []}, {"text": "The ability to memorize and produce larger translation chunks during decoding, on the other hand, gives a distinct advantage to the phrase-based system during search.", "labels": [], "entities": []}, {"text": "Phrase-based systems i) have access to uncommon translations, ii) do not require higher beam sizes, iii) have more accurate future-cost estimates because of the availability of phrase-internal language model context before search is started.", "labels": [], "entities": []}, {"text": "To illustrate this consider the German-English phrase-pair \"scho\u00df ein Torscored a goal\", composed from the tuples (ceptpairs) \"scho\u00df -scored\", \"ein -a\" and \"Tor -goal\".", "labels": [], "entities": [{"text": "Tor -goal", "start_pos": 157, "end_pos": 166, "type": "METRIC", "confidence": 0.9056132237116495}]}, {"text": "It is likely that the N-gram system does not have the tuple \"scho\u00df -scored\" in its n-best translation options because \"scored\" is an uncommon translation for \"scho\u00df\" outside the sports domain.", "labels": [], "entities": []}, {"text": "Even if \"scho\u00df -scored\" is hypothesized, it will be ranked quite low in the stack until \"ein\" and \"Tor\" are generated in the next steps.", "labels": [], "entities": []}, {"text": "A higher beam is required to prevent it from getting pruned.", "labels": [], "entities": []}, {"text": "Phrase-based systems, on the other hand, are likely to have access to the phrasal unit \"scho\u00df ein Tor -scored a goal\" and can generate it in a single step.", "labels": [], "entities": []}, {"text": "Moreover, a more accurate future-cost estimate can be computed because of the available context internal to the phrase.", "labels": [], "entities": []}, {"text": "In this work, we extend the N-gram model, based on operation sequences), to use phrases during decoding.", "labels": [], "entities": []}, {"text": "The main idea is to study whether a combination of modeling with minimal translation units and using phrasal information during decoding helps to solve the above-mentioned problems.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "The next two sections review phrase-based and N-gram-based SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.7393585443496704}]}, {"text": "Section 2 provides a comparison of phrase-based and N-gram-based SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.7473609447479248}]}, {"text": "Section 3 summarizes the operation sequence model (OSM), the main baseline for this work.", "labels": [], "entities": []}, {"text": "Section 4 analyzes the search problem when decoding with: Different Segmentations of a Bilingual Sentence Pair minimal units.", "labels": [], "entities": []}, {"text": "Section 5 discusses how information available in phrases can be used to improve search performance.", "labels": [], "entities": []}, {"text": "Section 6 presents the results of this work.", "labels": [], "entities": []}, {"text": "We conducted experiments on the German-toEnglish and French-to-English translation tasks and found that using phrases in decoding improves both search accuracy and BLEU scores.", "labels": [], "entities": [{"text": "French-to-English translation tasks", "start_pos": 53, "end_pos": 88, "type": "TASK", "confidence": 0.7107710440953573}, {"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.9752520322799683}, {"text": "BLEU", "start_pos": 164, "end_pos": 168, "type": "METRIC", "confidence": 0.9997296929359436}]}, {"text": "Finally we compare our system with two state-of-the-art phrasebased systems (Moses and Phrasal) and two stateof-the-art N-gram-based systems (Ncode and OSM) on standard translation tasks.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our modifications we apply a simple strategy.", "labels": [], "entities": []}, {"text": "We hold the model constant and change the search to use the baseline decoder, which uses minimal translation units, or the modified decoders that use phrasal information during decoding.", "labels": [], "entities": []}, {"text": "The model parameters are optimized by running MERT (minimum error rate training) for the baseline decoder on the dev set.", "labels": [], "entities": [{"text": "MERT", "start_pos": 46, "end_pos": 50, "type": "METRIC", "confidence": 0.992274820804596}]}, {"text": "After we have the optimized weights, we run the baseline decoder and our modifications on the test.", "labels": [], "entities": []}, {"text": "Note that because all the decoding runs use the same feature vector, the model stays constant, only search changes.", "labels": [], "entities": []}, {"text": "This allows us to compare different decoding runs, obtained using the same parameters, but different search strategies, in terms of model scores.", "labels": [], "entities": []}, {"text": "We compute a search accuracy and translation quality for each run.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.959763765335083}, {"text": "translation", "start_pos": 33, "end_pos": 44, "type": "TASK", "confidence": 0.9171659350395203}]}, {"text": "Search accuracy is computed by comparing translation hypotheses from the different decoding runs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.9953866600990295}]}, {"text": "We form a collection of the best scoring hypotheses by traversing through all the runs and selecting the sentences with highest model score.", "labels": [], "entities": []}, {"text": "For each input sentence we select a single best scoring hypothesis.", "labels": [], "entities": []}, {"text": "The best scoring hypothesis can be contributed from several runs.", "labels": [], "entities": []}, {"text": "In this case all these runs will be given a credit for that particular sentence when computing the search accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9757291674613953}]}, {"text": "The search accuracy of a decoding run is defined as the percentage of hypotheses that were contributed from this run, when forming a list of best scoring hypotheses.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9633288383483887}]}, {"text": "For example, fora test set of 1000 sentences, the accuracy of a decoding run would be 30% if it was able to produce the best scoring hypothesis for 300 sentences in the test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9994901418685913}]}, {"text": "Translation quality is measured through BLEU ().", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9357194900512695}, {"text": "BLEU", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9970353841781616}]}, {"text": "We initially experimented with two language pairs: German-to-English (G-E) and French-to-English (F-E).", "labels": [], "entities": []}, {"text": "We trained our system and the baseline systems on most of the data 6 made available for the translation task of the Fourth Workshop on Statistical Machine Translation.", "labels": [], "entities": [{"text": "translation task", "start_pos": 92, "end_pos": 108, "type": "TASK", "confidence": 0.9175313115119934}, {"text": "Statistical Machine Translation", "start_pos": 135, "end_pos": 166, "type": "TASK", "confidence": 0.6437726219495138}]}, {"text": "We used 1M bilingual sentences, for the estimation of the translation model and 2M sentences from the monolingual corpus (news commentary) which also contains the English part of the bilingual corpus.", "labels": [], "entities": []}, {"text": "Word alignments are obtained by running GIZA++) with the grow-diag-final-and () symmetrization heuristic.", "labels": [], "entities": [{"text": "Word alignments", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6526787728071213}]}, {"text": "We follow the training steps described in, consisting of i) post-processing the alignments to remove discontinuous and unaligned target cepts, ii) conversion of bilingual alignments into operation sequences, iii) estimation of the n-gram language models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Search Accuracies (Acc.) and BLEU scores of  the Baseline and Our Decoders with different Stack Sizes  (fc = Future Cost Estimated from Phrases, t = Cept Trans- lation Options enriched from Phrases)", "labels": [], "entities": [{"text": "Search Accuracies (Acc.)", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.6944270431995392}, {"text": "BLEU", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9987767338752747}]}]}