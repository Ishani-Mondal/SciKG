{"title": [{"text": "Beyond Left-to-Right: Multiple Decomposition Structures for SMT", "labels": [], "entities": [{"text": "SMT", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.9862865805625916}]}], "abstractContent": [{"text": "Standard phrase-based translation models do not explicitly model context dependence between translation units.", "labels": [], "entities": []}, {"text": "As a result, they rely on large phrase pairs and target language models to recover contextual effects in translation.", "labels": [], "entities": []}, {"text": "In this work, we explore n-gram models over Minimal Translation Units (MTUs) to explicitly capture contextual dependencies across phrase boundaries in the channel model.", "labels": [], "entities": []}, {"text": "As there is no single best direction in which con-textual information should flow, we explore multiple decomposition structures as well as dynamic bidirectional decomposition.", "labels": [], "entities": []}, {"text": "The resulting models are evaluated in an intrinsic task of lexical selection for MT as well as a full MT system, through n-best rerank-ing.", "labels": [], "entities": [{"text": "MT", "start_pos": 81, "end_pos": 83, "type": "TASK", "confidence": 0.9200314879417419}, {"text": "MT", "start_pos": 102, "end_pos": 104, "type": "TASK", "confidence": 0.9431986808776855}]}, {"text": "These experiments demonstrate that additional contextual modeling does indeed benefit a phrase-based system and that the direction of conditioning is important.", "labels": [], "entities": []}, {"text": "Integrating multiple conditioning orders provides consistent benefit, and the most important directions differ by language pair.", "labels": [], "entities": []}], "introductionContent": [{"text": "The translation procedure of a classical phrasebased translation model () first divides the input sentence into a sequence of phrases, translates each phrase, explores reorderings of these translations, and then scores the resulting candidates with a linear combination of models.", "labels": [], "entities": []}, {"text": "Conventional models include phrase-based channel models that effectively model each phrase as a large unigram, reordering models, and target language models.", "labels": [], "entities": []}, {"text": "Of these models, only the target language model * This research was conducted during the author's internship at Microsoft Research (and, to some weak extent, the lexicalized reordering model) captures some lexical dependencies that span phrase boundaries, though it is notable to model information from the source side.", "labels": [], "entities": []}, {"text": "Larger phrases capture more contextual dependencies within a phrase, but individual phrases are still translated almost independently.", "labels": [], "entities": []}, {"text": "To address this limitation, several researchers have proposed bilingual n-gram Markov models () to capture contextual dependencies between phrase pairs.", "labels": [], "entities": []}, {"text": "Much of their work is limited by the requirement \"that the source and target side of a tuple of words are synchronized, i.e. that they occur in the same order in their respective languages\").", "labels": [], "entities": []}, {"text": "For language pairs with significant typological divergences, such as Chinese-English, it is quite difficult to extract a synchronized sequence of units; in the limit, the smallest synchronized unit maybe the whole sentence.", "labels": [], "entities": []}, {"text": "Other approaches explore incorporation into syntax-based MT systems or replacing the phrasal translation system altogether.", "labels": [], "entities": [{"text": "MT", "start_pos": 57, "end_pos": 59, "type": "TASK", "confidence": 0.9258068203926086}]}, {"text": "We investigate the addition of MTUs to a phrasal translation system to improve modeling of context and to provide more robust estimation of long phrases.", "labels": [], "entities": [{"text": "MTUs", "start_pos": 31, "end_pos": 35, "type": "TASK", "confidence": 0.9258880615234375}]}, {"text": "However, in a phrase-based system there is no single synchronized traversal order; instead, we may consider the translation units in many possible orders: left-to-right or right-to-left according to either the source or the target are natural choices.", "labels": [], "entities": []}, {"text": "Alternatively we consider translating a particularly unambiguous unit in the middle of the sentence and building outwards from there.", "labels": [], "entities": []}, {"text": "We investigate both consistent and dynamic decomposition orders in several language pairs, looking at distinct orders in isolation and combination.", "labels": [], "entities": []}, {"text": "proposed a translation model using a Markov model of bilingual n-grams, demonstrating state-of-the-art performance compared to conventional phrase-based models.", "labels": [], "entities": [{"text": "translation", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.9754434823989868}]}, {"text": "further explored factorized n-gram approaches, though both models considered rather large n-grams; this paper focuses on small units with asynchronous orders in source and target.", "labels": [], "entities": []}, {"text": "developed a joint model that captures translation of contiguous and gapped units as well as reordering.", "labels": [], "entities": []}, {"text": "Two prior approaches explored similar models in syntax based systems.", "labels": [], "entities": []}, {"text": "MTUs have been used in dependency translation models) to augment syntax directed translation systems.", "labels": [], "entities": [{"text": "dependency translation", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.784048855304718}]}, {"text": "Likewise in target language syntax systems, one can consider Markov models over minimal rules, where the translation probability of each rule is adjusted to include context information from parent rules).", "labels": [], "entities": []}], "datasetContent": [{"text": "We report experimental results on the lexical selection task and the reranking task on three language pairs.", "labels": [], "entities": []}, {"text": "The datasets used for the different languages are described in detail in Section 6.2.", "labels": [], "entities": []}, {"text": "The data used for the lexical selection experiments consists of the training portion of the datasets used for MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 110, "end_pos": 112, "type": "TASK", "confidence": 0.9935775995254517}]}, {"text": "These training sets are split into three sections: lex-train, for training MTU Markov models and extracting possible translations for each source MTU, lex-dev for tuning combination weights for systems using several MTU MMs, and lex-test, for final evaluation results.", "labels": [], "entities": []}, {"text": "The possible translations for each source MTU are defined as the most frequent 100 translations seen in lex-train.", "labels": [], "entities": [{"text": "MTU", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.5440802574157715}]}, {"text": "The lex-dev sets contain 200 sentence pairs each and the lex-test sets contains 1000 sentence pairs each.", "labels": [], "entities": []}, {"text": "These development and test sets consist of equally spaced sentences taken from the full MT training sets.", "labels": [], "entities": [{"text": "MT training", "start_pos": 88, "end_pos": 99, "type": "TASK", "confidence": 0.8765601217746735}]}, {"text": "We start by reporting BLEU scores of the six individual MTU MMs on the three language pairs in.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9967628717422485}, {"text": "MTU MMs", "start_pos": 56, "end_pos": 63, "type": "TASK", "confidence": 0.8812380135059357}]}, {"text": "The baseline predicts the most frequent target MTU for each source MTU (unigram MM not using context).", "labels": [], "entities": []}, {"text": "The oracle looks at the correct translation and always chooses the correct target MTU if it is in the vocabulary of available MTUs.", "labels": [], "entities": []}, {"text": "We can see that there is a large difference between the baseline and oracle performance, underscoring the importance of modeling context for accurate prediction.", "labels": [], "entities": []}, {"text": "The best decomposition order varies from language to language: right-to-left in source order is best for Chinese-English, right-to-left in target order is best for German-English and left-to-right or rightto-left in target order are best in English-Bulgarian.", "labels": [], "entities": []}, {"text": "We computed statistical significance tests, testing the difference between the L2RT model (the standard in prior work) and models achieving higher test set performance.", "labels": [], "entities": []}, {"text": "The models that are significantly better at significance \u03b1 < 0.01 are marked with a star in the table.", "labels": [], "entities": [{"text": "significance \u03b1", "start_pos": 44, "end_pos": 58, "type": "METRIC", "confidence": 0.9442858099937439}]}, {"text": "We used a paired bootstrap test with 10,000 trials).", "labels": [], "entities": []}, {"text": "Next we evaluate the methods for combining decomposition orders introduced in Sections 4.1 and 4.2.", "labels": [], "entities": []}, {"text": "The results are reported in  We can see that the product models TgtProduct (a product of the three target-order MTU MMs) and AllProduct (a product of all six MTU MMs) are consistently best.", "labels": [], "entities": [{"text": "AllProduct", "start_pos": 125, "end_pos": 135, "type": "METRIC", "confidence": 0.8371216654777527}]}, {"text": "The dynamic decomposition models TgtDynamic achieve slight but not significant gains over the baseline.", "labels": [], "entities": []}, {"text": "The combination models that are statistically significantly better than corresponding baselines (\u03b1 < 0.01) are marked with a star.", "labels": [], "entities": []}, {"text": "Our takeaway from these experiments is that multiple decomposition orders are good, and thus taking a product (which encourages agreement among the models) is a good choice for this task.", "labels": [], "entities": []}, {"text": "The dynamic decomposition method shows some promise, but it does not outperform the simpler product approach.", "labels": [], "entities": []}, {"text": "Perhaps a lager space of decompositions would achieve better results, especially given a larger parameter set to trade off decompositions and better tuning for those parameters.", "labels": [], "entities": []}, {"text": "For Chinese-English, the training corpus consists of 1 million sentence pairs from the FBIS and HongKong portions of the LDC data for the NIST MT evaluation.", "labels": [], "entities": [{"text": "FBIS", "start_pos": 87, "end_pos": 91, "type": "DATASET", "confidence": 0.9322499632835388}, {"text": "LDC data", "start_pos": 121, "end_pos": 129, "type": "DATASET", "confidence": 0.7518333792686462}, {"text": "NIST MT evaluation", "start_pos": 138, "end_pos": 156, "type": "DATASET", "confidence": 0.7666822274525961}]}, {"text": "We used the union of the NIST 2002 and 2003 test sets as the development set and the NIST 2005 test set as our test set.", "labels": [], "entities": [{"text": "NIST 2002 and 2003 test sets", "start_pos": 25, "end_pos": 53, "type": "DATASET", "confidence": 0.9391001562277476}, {"text": "NIST 2005 test set", "start_pos": 85, "end_pos": 103, "type": "DATASET", "confidence": 0.978367879986763}]}, {"text": "The baseline phrasal system uses a 5-gram language model with modified Kneser-Ney smoothing, trained on the Xinhua portion of the English Gigaword corpus (238M English words).", "labels": [], "entities": [{"text": "English Gigaword corpus", "start_pos": 130, "end_pos": 153, "type": "DATASET", "confidence": 0.8275759220123291}]}, {"text": "For German-English we used the dataset from  For English-Bulgarian we used a dataset containing sentences from several data sources: JRCAcquis (), TAUS 4 , and webscraped data.", "labels": [], "entities": [{"text": "JRCAcquis", "start_pos": 133, "end_pos": 142, "type": "DATASET", "confidence": 0.845569908618927}]}, {"text": "The development set consists of 1,497 sentences, the English side from WMT 2009 news test data, and the Bulgarian side a human translation thereof.", "labels": [], "entities": [{"text": "WMT 2009 news test data", "start_pos": 71, "end_pos": 94, "type": "DATASET", "confidence": 0.9666775465011597}]}, {"text": "The test set comes from the same mixture of sources as the training set.", "labels": [], "entities": []}, {"text": "For this system we used a single four-gram target language model trained on the target side of the parallel corpus.", "labels": [], "entities": []}, {"text": "All systems used phrase tables with a maximum length of seven words on either side and lexicalized reordering models.", "labels": [], "entities": []}, {"text": "For the Chinese-English system we used GIZA++ alignments, and for the other two we used alignments by an HMM model augmented with word-based distortion.", "labels": [], "entities": []}, {"text": "The alignments were symmetrized and then combined with the heuristics \"grow-diag-final-and\".", "labels": [], "entities": []}, {"text": "We tune parameters using MERT) with random restarts on the development set.", "labels": [], "entities": [{"text": "MERT", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9106119275093079}]}, {"text": "Case-insensitive BLEU-4 is our evaluation metric ().", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.9931029081344604}]}, {"text": "We first report detailed experiments on ChineseEnglish, and then verify our main conclusions on the other language pairs.", "labels": [], "entities": []}, {"text": "looks at the impact of individual 3-gram and 5-gram MTU Markov models and their combination.", "labels": [], "entities": []}, {"text": "Amongst the decomposition orders tested (L2RT, R2LT, L2RS, and R2LS), each of the individual MTU MMs was able to achieve significant improvement over the baseline, around 1 BLEU point.", "labels": [], "entities": [{"text": "MTU MMs", "start_pos": 93, "end_pos": 100, "type": "TASK", "confidence": 0.7994264960289001}, {"text": "BLEU", "start_pos": 173, "end_pos": 177, "type": "METRIC", "confidence": 0.9988173842430115}]}, {"text": "The results achieved by the individual models differ, and the combination of four directions is better than the best individual direction, but the difference is not statistically significant.", "labels": [], "entities": []}, {"text": "We ran an additional experiment to test whether MTU MMs make effective use of context across phrase boundaries, or whether they simply provide better smoothed estimates of phrasal translation probabilities.", "labels": [], "entities": [{"text": "MTU MMs", "start_pos": 48, "end_pos": 55, "type": "TASK", "confidence": 0.8942270576953888}]}, {"text": "The last row of the table reports the results achieved by a combination of MTU MMs that do not use context across the phrasal boundaries.", "labels": [], "entities": [{"text": "MTU MMs", "start_pos": 75, "end_pos": 82, "type": "TASK", "confidence": 0.8734593391418457}]}, {"text": "Since an MTU MM limited to look only inside phrases can provide improved smoothing compared to whole phrase relative frequency counts, it is conceivable it could provide a large improvement.", "labels": [], "entities": [{"text": "MTU MM", "start_pos": 9, "end_pos": 15, "type": "TASK", "confidence": 0.6257267892360687}]}, {"text": "However, there is no improvement in practice for this language pair; the additional improvements from MTU MMs stem from modeling cross-phrase context.", "labels": [], "entities": [{"text": "MTU MMs", "start_pos": 102, "end_pos": 109, "type": "TASK", "confidence": 0.8632921278476715}]}, {"text": "www.tausdata.org The combination heuristic was further refined to disallow crossing one-to-many alignments, which would result in the extraction of larger minimum translation units.", "labels": [], "entities": []}, {"text": "We found that this further refinement on the combination heuristic consistently improved the BLEU scores by between 0.3 and 0.7.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 93, "end_pos": 97, "type": "METRIC", "confidence": 0.999512791633606}]}, {"text": "Here again we calla difference significant if the paired bootstrap p-value is less than 0.01.", "labels": [], "entities": []}, {"text": "shows the test set results of individual 3-gram MTU Markov models and the combination of 3-gram and 5-gram models on the English-Bulgarian and German-English datasets.", "labels": [], "entities": [{"text": "German-English datasets", "start_pos": 143, "end_pos": 166, "type": "DATASET", "confidence": 0.6675814390182495}]}, {"text": "For English-Bulgarian all individual 3-gram Markov models achieve significant improvements of close to one point; their combination is better than the best individual model (but not significantly).", "labels": [], "entities": []}, {"text": "The individual 5-gram models and their combination bring much larger improvement, fora total increase of 2.82 points over the baseline.", "labels": [], "entities": []}, {"text": "We believe the 5-gram models were more effective in this setting because the larger training set allowed for successful training of models of larger capacity.", "labels": [], "entities": []}, {"text": "Also the increased context size helps to resolve ambiguity in the forms of morphologically-rich Bulgarian words.", "labels": [], "entities": []}, {"text": "For German-English we see a similar pattern, with the combination of models outperforming the individual ones, and the 5-gram models being better than the 3-gram.", "labels": [], "entities": []}, {"text": "Here the individual 3-gram models are better than the baseline at significance level 0.02 and their combination is better than the baseline at our earlier defined threshold of 0.01.", "labels": [], "entities": []}, {"text": "The withinphrase MTU MMs (results shown in the last two rows) improve upon the baseline slightly, but here again the improvements mostly stem from the use of context across phrase boundaries.", "labels": [], "entities": [{"text": "MTU MMs", "start_pos": 17, "end_pos": 24, "type": "TASK", "confidence": 0.8130574524402618}]}, {"text": "Our final results on German-English are better than the best result of 27.30 from the shared task ().", "labels": [], "entities": []}, {"text": "Thanks to the reviewers for referring us to recent work by) that pointed out problems with significance tests for machine translation, where the randomness and local optima in the MERT weight tuning method lead to a large variance in development and test set performance across different runs of optimization (using a different random seed or starting point).) proposed a stratified approximate randomization statistical significance test, which controls for optimizer instability.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 114, "end_pos": 133, "type": "TASK", "confidence": 0.8182452321052551}]}, {"text": "Using this test, for the English-Bulgarian system, we confirmed that the combination of four 3-gram MMs and the combination of 5-gram MMs is better than the baseline (p = .0001 for both, using five runs of parameter tuning).", "labels": [], "entities": []}, {"text": "We have not run the test for the other language pairs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Lexical selection results for individual MTU  Markov models.", "labels": [], "entities": [{"text": "Lexical selection", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.8534296452999115}]}, {"text": " Table 2: Lexical selection results for combinations of  MTU Markov models.", "labels": [], "entities": [{"text": "Lexical selection", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.8419658839702606}]}, {"text": " Table 3: Data sets for different language pairs.", "labels": [], "entities": []}, {"text": " Table 4: Reranking with 3-gram and 5-gram MTU trans- lation models on Chinese-English. Starred results on the  test set indicate significantly better performance than the  baseline.", "labels": [], "entities": []}]}