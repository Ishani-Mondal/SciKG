{"title": [{"text": "Unsupervised Metaphor Identification Using Hierarchical Graph Factorization Clustering", "labels": [], "entities": [{"text": "Unsupervised Metaphor Identification", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.5538894534111023}]}], "abstractContent": [{"text": "We present a novel approach to automatic metaphor identification, that discovers both metaphorical associations and metaphorical expressions in unrestricted text.", "labels": [], "entities": [{"text": "automatic metaphor identification", "start_pos": 31, "end_pos": 64, "type": "TASK", "confidence": 0.7415976524353027}]}, {"text": "Our system first performs hierarchical graph factor-ization clustering (HGFC) of nouns and then searches the resulting graph for metaphorical connections between concepts.", "labels": [], "entities": [{"text": "hierarchical graph factor-ization clustering (HGFC) of nouns", "start_pos": 26, "end_pos": 86, "type": "TASK", "confidence": 0.7829391890101962}]}, {"text": "It then makes use of the salient features of the metaphori-cally connected clusters to identify the actual metaphorical expressions.", "labels": [], "entities": []}, {"text": "In contrast to previous work, our method is fully unsupervised.", "labels": [], "entities": []}, {"text": "Despite this fact, it operates with an encouraging precision (0.69) and recall (0.61).", "labels": [], "entities": [{"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9990780353546143}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9998149275779724}]}, {"text": "Our approach is also the first one in NLP to exploit the cognitive findings on the differences in organisation of abstract and concrete concepts in the human brain.", "labels": [], "entities": []}], "introductionContent": [{"text": "Metaphor has traditionally been viewed as a form of linguistic creativity, that gives our expression more vividness, distinction and artistism.", "labels": [], "entities": []}, {"text": "While this is true on the surface, the mechanisms of metaphor have a much deeper origin in our reasoning.", "labels": [], "entities": []}, {"text": "Today metaphor is widely understood as a cognitive phenomenon operating at the level of mental processes, whereby one concept or domain is systematically viewed in terms of the properties of another (.", "labels": [], "entities": []}, {"text": "Consider the examples (1) \"He shot down all of my arguments\" and (2) \"He attacked every weak point in my argument\".", "labels": [], "entities": []}, {"text": "They demonstrate a metaphorical mapping of the concept of argument to that of war.", "labels": [], "entities": []}, {"text": "The argument, which is the target concept, is viewed in terms of a battle (or a war), the source concept.", "labels": [], "entities": []}, {"text": "The existence of such a link allows us to systematically describe arguments using the war terminology, thus leading to a number of metaphorical expressions.", "labels": [], "entities": []}, {"text": "Lakoff and Johnson call such generalisations a source-target domain mapping, or conceptual metaphor.", "labels": [], "entities": []}, {"text": "The ubiquity of metaphor in language has been established in a number of corpus studies and the role it plays inhuman reasoning has been confirmed in psychological experiments ().", "labels": [], "entities": []}, {"text": "This makes metaphor an important research area for computational and cognitive linguistics, and its automatic processing indispensable for any semanticsoriented NLP application.", "labels": [], "entities": [{"text": "computational and cognitive linguistics", "start_pos": 51, "end_pos": 90, "type": "TASK", "confidence": 0.7040773183107376}]}, {"text": "The problem of metaphor modeling is gaining interest within NLP, with a growing number of approaches exploiting statistical techniques).", "labels": [], "entities": [{"text": "metaphor modeling", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.9198732376098633}]}, {"text": "Compared to more traditional approaches based on hand-coded knowledge), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust.", "labels": [], "entities": []}, {"text": "However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of phenomena;, and only addressed one of the metaphor processing subtasks: identification of metaphorical mappings) or identification of metaphorical expressions (.", "labels": [], "entities": [{"text": "statistical metaphor processing", "start_pos": 18, "end_pos": 49, "type": "TASK", "confidence": 0.7603691319624583}, {"text": "identification of metaphorical mappings", "start_pos": 189, "end_pos": 228, "type": "TASK", "confidence": 0.8548983931541443}, {"text": "identification of metaphorical expressions", "start_pos": 233, "end_pos": 275, "type": "TASK", "confidence": 0.8712222576141357}]}, {"text": "In this paper, we present the first computational method that identifies the generalisations that govern the production of metaphorical expressions, i.e. conceptual metaphors, and then uses these generalisations to identify metaphorical expressions in unrestricted text.", "labels": [], "entities": []}, {"text": "As opposed to previous works on statistical metaphor processing that were supervised or semi-supervised, and thus required training data, our method is fully unsupervised.", "labels": [], "entities": [{"text": "statistical metaphor processing", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.8370439410209656}]}, {"text": "It relies on building a hierarchical graph of concepts connected by their association strength (using hierarchical clustering) and then searching for metaphorical links in this graph.", "labels": [], "entities": []}, {"text": "introduced the hypothesis of \"clustering by association\" and claimed that in the course of distributional noun clustering, abstract concepts tend to cluster together if they are associated with the same source domain, while concrete concepts cluster by meaning similarity.", "labels": [], "entities": [{"text": "distributional noun clustering", "start_pos": 91, "end_pos": 121, "type": "TASK", "confidence": 0.6381243964036306}]}, {"text": "We share this intuition, but take this idea a significant step further.", "labels": [], "entities": []}, {"text": "Our approach is theoretically grounded in the cognitive science findings suggesting that abstract and concrete concepts are organised differently in the human brain.", "labels": [], "entities": []}, {"text": "According to, these differences emerge from their general patterns of relation with other concepts.", "labels": [], "entities": []}, {"text": "However, most NLP systems to date treat abstract and concrete concepts as identical.", "labels": [], "entities": []}, {"text": "In contrast, we incorporate this distinction into our model by creating a network (or a graph) of concepts, and automatically learning the different patterns of association of abstract and concrete concepts with other concepts.", "labels": [], "entities": []}, {"text": "We expect that, while concrete concepts would tend to naturally organise into a tree-like structure (with more specific terms descending from the more general terms), abstract concepts would exhibit a more complex pattern of associations.", "labels": [], "entities": []}, {"text": "The figure schematically shows a small portion of the graph describing the concepts of mechanism (concrete), political system and relationship (abstract) at two levels of generality.", "labels": [], "entities": []}, {"text": "One can see from this graph that if concrete concepts, such as bike or engine tend to be connected to only one concept at the higher level in the hierarchy (mechanism), abstract concepts may have multiple higher-level associates: the literal ones and the metaphorical ones.", "labels": [], "entities": []}, {"text": "For example, the abstract concept of democracy is literally associated with a more general concept of political system, as well as metaphorically associated with the concept of mechanism.", "labels": [], "entities": []}, {"text": "Such multiple associations are due to the fact that political systems are metaphorically viewed as mechanisms, they can function, break, they can be oiled etc.", "labels": [], "entities": []}, {"text": "We often discuss them using mechanism terminology, and thus a corpus-based distributional learning approach would learn that they share features with political systems (from their literal uses), as well as with mechanisms (from their metaphorical uses, as shown next to the respective graph edges in the figure).", "labels": [], "entities": []}, {"text": "Our system discovers such association patterns within the graph and uses them to identify metaphorical connections between the concepts.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, our method is the first one to use a hierarchical clustering model for the metaphor processing task.", "labels": [], "entities": [{"text": "metaphor processing task", "start_pos": 105, "end_pos": 129, "type": "TASK", "confidence": 0.90622345606486}]}, {"text": "The original graph of concepts is built using hierarchical graph factorization clustering (HGFC) () of nouns, yielding a network of clusters with different levels of generality.", "labels": [], "entities": []}, {"text": "The weights on the edges of the graph indicate association between the clusters (concepts).", "labels": [], "entities": []}, {"text": "HGFC has not been previously employed for noun clustering in NLP, but showed successful results in the verb clustering task (.", "labels": [], "entities": [{"text": "noun clustering", "start_pos": 42, "end_pos": 57, "type": "TASK", "confidence": 0.7888183295726776}, {"text": "verb clustering task", "start_pos": 103, "end_pos": 123, "type": "TASK", "confidence": 0.7943498094876608}]}, {"text": "In summary, our system (1) builds a graph of concepts using HGFC, (2) traverses it to find metaphorical associations between clusters using weights on the edges of the graph, (3) generates lists of salient features for the metaphorically connected clusters and (4) searches the British National Corpus (BNC)) for metaphorical expressions describing the target domain concepts using the verbs from the set of salient features.", "labels": [], "entities": [{"text": "British National Corpus (BNC))", "start_pos": 278, "end_pos": 308, "type": "DATASET", "confidence": 0.9733788073062897}]}, {"text": "We evaluated the performance of the system with the aid of human judges in precision-and recall-oriented settings.", "labels": [], "entities": [{"text": "precision-and", "start_pos": 75, "end_pos": 88, "type": "METRIC", "confidence": 0.9981020092964172}, {"text": "recall-oriented", "start_pos": 89, "end_pos": 104, "type": "METRIC", "confidence": 0.822318971157074}]}, {"text": "In addition, we compared its performance to that of two baselines, an unsupervised baseline using agglomerative clustering (AGG) and a supervised baseline built upon WordNet) (WN).", "labels": [], "entities": []}], "datasetContent": [{"text": "Our noun dataset used for clustering contains 2000 most frequent nouns in the BNC.", "labels": [], "entities": [{"text": "clustering", "start_pos": 26, "end_pos": 36, "type": "TASK", "confidence": 0.9639143347740173}, {"text": "BNC", "start_pos": 78, "end_pos": 81, "type": "DATASET", "confidence": 0.947199821472168}]}, {"text": "Following previous semantic noun classification experiments (, we use the grammatical relations (GRs) as features for clustering.", "labels": [], "entities": [{"text": "semantic noun classification", "start_pos": 19, "end_pos": 47, "type": "TASK", "confidence": 0.6030184924602509}]}, {"text": "We extracted the features from the Gigaword corpus (, which was first parsed using the RASP parser ().", "labels": [], "entities": [{"text": "Gigaword corpus", "start_pos": 35, "end_pos": 50, "type": "DATASET", "confidence": 0.9481881856918335}]}, {"text": "The verb lemmas in VERB-SUBJECT, VERB-DIRECT OBJECT and VERB-INDIRECT OBJECT relations with the nouns in the dataset were then extracted from the GR output of the parser.", "labels": [], "entities": [{"text": "VERB-SUBJECT", "start_pos": 19, "end_pos": 31, "type": "DATASET", "confidence": 0.8400264382362366}, {"text": "VERB-DIRECT", "start_pos": 33, "end_pos": 44, "type": "DATASET", "confidence": 0.6761360168457031}, {"text": "OBJECT", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.5222015380859375}]}, {"text": "The feature values were the relative frequencies of the features.", "labels": [], "entities": []}, {"text": "To create our dataset, we extracted 10 common source concepts that map to multiple targets from the Master Metaphor List ( and linguistic analyses of metaphor.", "labels": [], "entities": []}, {"text": "These included FIRE, CHILD, SPEED, WAR, DISEASE, BREAKDOWN, CONSTRUCTION, VEHICLE, SYS-TEM, BUSINESS.", "labels": [], "entities": [{"text": "FIRE", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.9928393363952637}, {"text": "CHILD", "start_pos": 21, "end_pos": 26, "type": "METRIC", "confidence": 0.9654802680015564}, {"text": "SPEED", "start_pos": 28, "end_pos": 33, "type": "METRIC", "confidence": 0.9816995859146118}, {"text": "WAR", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.7491763234138489}, {"text": "DISEASE", "start_pos": 40, "end_pos": 47, "type": "METRIC", "confidence": 0.8544885516166687}, {"text": "BREAKDOWN", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9900528788566589}, {"text": "CONSTRUCTION", "start_pos": 60, "end_pos": 72, "type": "METRIC", "confidence": 0.7723095417022705}, {"text": "VEHICLE", "start_pos": 74, "end_pos": 81, "type": "METRIC", "confidence": 0.8940821886062622}, {"text": "BUSINESS", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.8977780342102051}]}, {"text": "Each of the three systems identified 50 source-target domain mappings for the given source domains, resulting in a set of 150 conceptual metaphors (each representing a number of submappings since all the target concepts are clusters or synsets).", "labels": [], "entities": []}, {"text": "These were then evaluated against human judgements in two different experimental settings.", "labels": [], "entities": []}, {"text": "Setting 1: The judges were presented with a set of conceptual metaphors identified by the three systems, randomized.", "labels": [], "entities": []}, {"text": "They were asked to annotate the mappings they considered valid.", "labels": [], "entities": []}, {"text": "In all our experiments, the judges were encouraged to rely on their own intuition of metaphor, but they also reviewed the metaphor annotation guidelines of.", "labels": [], "entities": []}, {"text": "Two independent judges, both na-tive speakers of English, participated in this experiment.", "labels": [], "entities": []}, {"text": "Their agreement on the task was \u03ba = 0.60 (n = 2, N = 150, k = 2) ().", "labels": [], "entities": []}, {"text": "The main differences in the annotators' judgements stem from the fact that some metaphorical associations are less obvious and common than others, and thus need more context (or imaginative effort) to establish.", "labels": [], "entities": []}, {"text": "Such examples, where the judges disagreed included metaphorical mappings such as INTENSITY is SPEED, GOAL is a CHILD, COLLEC-TION is a SYSTEM, ILLNESS is a BREAKDOWN.", "labels": [], "entities": [{"text": "INTENSITY", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.7777913212776184}, {"text": "SPEED", "start_pos": 94, "end_pos": 99, "type": "METRIC", "confidence": 0.8888083696365356}, {"text": "GOAL", "start_pos": 101, "end_pos": 105, "type": "METRIC", "confidence": 0.9844204783439636}, {"text": "CHILD", "start_pos": 111, "end_pos": 116, "type": "METRIC", "confidence": 0.48962756991386414}, {"text": "ILLNESS", "start_pos": 143, "end_pos": 150, "type": "METRIC", "confidence": 0.859559178352356}, {"text": "BREAKDOWN", "start_pos": 156, "end_pos": 165, "type": "METRIC", "confidence": 0.7747291922569275}]}, {"text": "The system performance was then evaluated against these judgements in terms of precision (P ), i.e. the proportion of the valid metaphorical mappings among those identified.", "labels": [], "entities": [{"text": "precision (P )", "start_pos": 79, "end_pos": 93, "type": "METRIC", "confidence": 0.9591714143753052}]}, {"text": "We calculated system precision (in all experiments) as an average over both annotations.", "labels": [], "entities": [{"text": "precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9623510241508484}]}, {"text": "HGFC operates with a precision of P = 0.69, whereas the baselines attain P = 0.36 (AGG) and P = 0.29 (WN).", "labels": [], "entities": [{"text": "HGFC", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9404469132423401}, {"text": "precision", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.9980685114860535}, {"text": "P", "start_pos": 73, "end_pos": 74, "type": "METRIC", "confidence": 0.9656068086624146}, {"text": "AGG)", "start_pos": 83, "end_pos": 87, "type": "METRIC", "confidence": 0.91362664103508}]}, {"text": "The precision of annotator judgements against each other (the human ceiling) is P = 0.80, suggesting that this is a challenging task.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9993374943733215}, {"text": "P", "start_pos": 80, "end_pos": 81, "type": "METRIC", "confidence": 0.9748672842979431}]}, {"text": "Setting 2: To measure recall, R, of the systems we asked two annotators (both native speakers with a background in metaphor, different from Setting 1) to write down up to 5 target concepts they strongly associated with each of the 10 source concepts.", "labels": [], "entities": [{"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9988757967948914}, {"text": "R", "start_pos": 30, "end_pos": 31, "type": "METRIC", "confidence": 0.7571792602539062}]}, {"text": "Their annotations were then aggregated into a single metaphor association gold standard, consisting of 63 mappings in total.", "labels": [], "entities": []}, {"text": "The recall of the systems was measured against this gold standard, resulting in HGFC R = 0.61, AGG R = 0.11 and WN R = 0.03.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9993589520454407}, {"text": "HGFC R = 0.61", "start_pos": 80, "end_pos": 93, "type": "METRIC", "confidence": 0.9104498326778412}, {"text": "AGG R = 0.11", "start_pos": 95, "end_pos": 107, "type": "METRIC", "confidence": 0.958918422460556}, {"text": "WN R = 0.03", "start_pos": 112, "end_pos": 123, "type": "METRIC", "confidence": 0.8785895854234695}]}, {"text": "As expected, HGFC outperforms both AGG and WN baselines in both settings.", "labels": [], "entities": [{"text": "HGFC", "start_pos": 13, "end_pos": 17, "type": "DATASET", "confidence": 0.6232689023017883}, {"text": "AGG", "start_pos": 35, "end_pos": 38, "type": "DATASET", "confidence": 0.7204532027244568}]}, {"text": "AGG has been previously shown to be less accurate than HGFC in the verb clustering task (.", "labels": [], "entities": [{"text": "verb clustering task", "start_pos": 67, "end_pos": 87, "type": "TASK", "confidence": 0.7980758349100748}]}, {"text": "Our analysis of the noun clusters indicated that HGFC tends to produce more pure and complete clusters than AGG.", "labels": [], "entities": []}, {"text": "Another important reason AGG fails is that it by definition organises all concepts into tree and optimises its solution locally, taking into account a small number of clusters at a time.", "labels": [], "entities": [{"text": "AGG", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.628535270690918}]}, {"text": "However, being able to discover connections between more distant domains and optimising globally overall concepts is crucial for metaphor identification.", "labels": [], "entities": [{"text": "metaphor identification", "start_pos": 129, "end_pos": 152, "type": "TASK", "confidence": 0.9422236084938049}]}, {"text": "This makes AGG less suitable for the task, as demonstrated by our results.", "labels": [], "entities": [{"text": "AGG", "start_pos": 11, "end_pos": 14, "type": "DATASET", "confidence": 0.5024665594100952}]}, {"text": "However, AGG identified a number of interesting mappings missed by HGFC, e.g. CAREER IS A CHILD, LANGUAGE IS A SYS-TEM, CORRUPTION IS A VEHICLE, EMPIRE IS A CONSTRUCTION, as well as a number of mappings in common with HGFC, e.g. DEBATE IS A WAR, DE-STRUCTION IS A DISEASE.", "labels": [], "entities": [{"text": "AGG", "start_pos": 9, "end_pos": 12, "type": "DATASET", "confidence": 0.8677021861076355}, {"text": "CAREER IS A CHILD", "start_pos": 78, "end_pos": 95, "type": "METRIC", "confidence": 0.8373225331306458}, {"text": "VEHICLE", "start_pos": 136, "end_pos": 143, "type": "METRIC", "confidence": 0.7266849279403687}, {"text": "HGFC", "start_pos": 218, "end_pos": 222, "type": "DATASET", "confidence": 0.914483368396759}]}, {"text": "The WN system also identified a few interesting metaphorical mappings (e.g. COGNITION IS FIRE, EDUCATION IS CON-STRUCTION), but its output is largely dominated by the concepts similar to the source noun and contains some unrelated concepts.", "labels": [], "entities": [{"text": "FIRE", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.909878671169281}]}, {"text": "The comparison of HGFC to WN shows that HGFC identifies meaningful properties and relations of abstract concepts that cannot be captured in a tree-like classification (even an accurate, manually created one).", "labels": [], "entities": []}, {"text": "The latter is more appropriate for concrete concepts, and a more flexible representation is needed to model abstract concepts.", "labels": [], "entities": []}, {"text": "The fact that both baselines identified some valid metaphorical associations, relying on less suitable conceptual graphs, suggests that our way of traversing the graph is a viable approach in principle.", "labels": [], "entities": []}, {"text": "HGFC identifies valid metaphorical associations fora range of source concepts.", "labels": [], "entities": []}, {"text": "On of them (CRIME IS A VIRUS) happened to have been already validated in psychological experiments ().", "labels": [], "entities": [{"text": "CRIME IS A VIRUS", "start_pos": 12, "end_pos": 28, "type": "METRIC", "confidence": 0.6345672756433487}]}, {"text": "The most frequent type of error of HGFC is the presence of target clusters similar or closely related to the source noun (e.g. the parent cluster for child).", "labels": [], "entities": []}, {"text": "The clusters from the same domain can, however, be filtered out if their nouns frequently occur in the same documents with the source noun (in a large corpus), i.e. by topical similarity.", "labels": [], "entities": []}, {"text": "The latter is less likely for the metaphorically connected nouns.", "labels": [], "entities": []}, {"text": "We intend to implement this improvement in the future version of the system.", "labels": [], "entities": []}, {"text": "For each of the identified conceptual metaphors, the three systems extracted a number of metaphorical expressions from the corpus (average of 430 for HGFC, 148 for AGG, and 855 for WN).", "labels": [], "entities": [{"text": "HGFC", "start_pos": 150, "end_pos": 154, "type": "DATASET", "confidence": 0.8632601499557495}, {"text": "AGG", "start_pos": 164, "end_pos": 167, "type": "DATASET", "confidence": 0.8276323080062866}]}, {"text": "The expressions were also evaluated against human judgements.", "labels": [], "entities": []}, {"text": "The judges were presented with a set of randomly sampled sentences containing metaphorical expressions as annotated by the system and by the baselines (200 each), randomized.", "labels": [], "entities": []}, {"text": "They were asked to mark the tagged expressions that were metaphorical in their judgement as correct.", "labels": [], "entities": []}, {"text": "Their agreement on the task was \u03ba = 0.56 (n = 2, N = 600, k = 2), HLJ 26 [..]", "labels": [], "entities": [{"text": "HLJ 26", "start_pos": 66, "end_pos": 72, "type": "DATASET", "confidence": 0.833963930606842}]}, {"text": "\"effective action\" was needed to eradicate terrorism, drug-trafficking and corruption.", "labels": [], "entities": [{"text": "eradicate terrorism", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.9272294640541077}]}, {"text": "EG0 275 In the 1930s the words \"means test\" was a curse, fuelling the resistance against it both among the unemployed and some of its administrators.", "labels": [], "entities": [{"text": "EG0 275", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9438671767711639}]}, {"text": "CRX 1054 [..] if the rehabilitative approach were demonstrably successful in curing crime.", "labels": [], "entities": [{"text": "CRX 1054", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9747528433799744}, {"text": "curing crime", "start_pos": 77, "end_pos": 89, "type": "TASK", "confidence": 0.8864653408527374}]}, {"text": "whereby the main source of disagreement was the presence of lexicalized metaphors, e.g. verbs such as impose, decline etc.", "labels": [], "entities": []}, {"text": "The system performance against these annotations is P = 0.65 (HGFC), P = 0.47 (AGG) and P = 0.12 (WN).", "labels": [], "entities": [{"text": "HGFC", "start_pos": 62, "end_pos": 66, "type": "DATASET", "confidence": 0.7735021710395813}, {"text": "AGG)", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.8339544236660004}]}, {"text": "The human ceiling for this task was measured at P = 0.79.", "labels": [], "entities": [{"text": "P", "start_pos": 48, "end_pos": 49, "type": "METRIC", "confidence": 0.9878178238868713}]}, {"text": "shows example sentences annotated by HGFC.", "labels": [], "entities": [{"text": "HGFC", "start_pos": 37, "end_pos": 41, "type": "DATASET", "confidence": 0.9540342092514038}]}, {"text": "The performance of our unsupervised approach is close to the previous supervised systems of Mason (accuracy of 0.73) and  (precision of 0.79), however, the results are not directly comparable due to different experimental settings.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9978311657905579}, {"text": "precision", "start_pos": 123, "end_pos": 132, "type": "METRIC", "confidence": 0.9965386390686035}]}, {"text": "The system errors in this task stem from multiple word senses of the salient features or the source and target sharing some physical properties (e.g. one can \"die from crime\" and \"die from a disease\").", "labels": [], "entities": []}, {"text": "Some identified expressions invoke a chain of mappings (e.g. ABUSE IS A DISEASE, DISEASE IS AN ENEMY for \"combat abuse\"), however, such chains are not yet incorporated into the system.", "labels": [], "entities": [{"text": "ABUSE IS A DISEASE", "start_pos": 61, "end_pos": 79, "type": "METRIC", "confidence": 0.8994596600532532}, {"text": "DISEASE IS AN ENEMY", "start_pos": 81, "end_pos": 100, "type": "METRIC", "confidence": 0.7954136282205582}]}, {"text": "The performance of AGG is higher than in the mappings identification task, since it outputs only few expressions for the incorrect mappings.", "labels": [], "entities": [{"text": "mappings identification task", "start_pos": 45, "end_pos": 73, "type": "TASK", "confidence": 0.9332484205563863}]}, {"text": "In contrast, WN tagged a large number of literal expressions due to the incorrect prior identification of the underlying associations.", "labels": [], "entities": [{"text": "WN tagged", "start_pos": 13, "end_pos": 22, "type": "TASK", "confidence": 0.6822827458381653}]}, {"text": "Since there is no large metaphor-annotated corpus available, it was impossible for us to reliably evaluate the recall of metaphorical expressions.", "labels": [], "entities": []}, {"text": "However, we estimated it as a recall of salient features.", "labels": [], "entities": [{"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9809181690216064}]}, {"text": "We manually compiled sets of typical features for the 10 source domains, and measured their recall among the top 50 HGFC features at R = 0.70.", "labels": [], "entities": [{"text": "recall", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.9992150068283081}, {"text": "R", "start_pos": 133, "end_pos": 134, "type": "METRIC", "confidence": 0.9842259287834167}]}, {"text": "However, in practice the coverage in this task would directly depend on that of the metaphorical associations.", "labels": [], "entities": [{"text": "coverage", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9838901162147522}]}], "tableCaptions": []}