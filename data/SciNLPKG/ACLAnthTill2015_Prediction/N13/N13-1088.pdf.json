{"title": [{"text": "More than meets the eye: Study of Human Cognition in Sense Annotation", "labels": [], "entities": []}], "abstractContent": [{"text": "Word Sense Disambiguation (WSD) approaches have reported good accuracies in recent years.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7754272123177847}, {"text": "accuracies", "start_pos": 62, "end_pos": 72, "type": "METRIC", "confidence": 0.9752665758132935}]}, {"text": "However, these approaches can be classified as weak AI systems.", "labels": [], "entities": []}, {"text": "According to the classical definition, a strong AI based WSD system should perform the task of sense disambiguation in the same manner and with similar accuracy as human beings.", "labels": [], "entities": [{"text": "WSD", "start_pos": 57, "end_pos": 60, "type": "TASK", "confidence": 0.9518433809280396}, {"text": "sense disambiguation", "start_pos": 95, "end_pos": 115, "type": "TASK", "confidence": 0.7111165970563889}, {"text": "accuracy", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.9975122213363647}]}, {"text": "In order to accomplish this, a detailed understanding of the human techniques employed for sense disambiguation is necessary.", "labels": [], "entities": [{"text": "sense disambiguation", "start_pos": 91, "end_pos": 111, "type": "TASK", "confidence": 0.8138984441757202}]}, {"text": "Instead of building yet another WSD system that uses contextual evidence for sense disambiguation, as has been done before, we have taken a step back-we have endeavored to discover the cognitive faculties that lie at the very core of the human sense disambiguation technique.", "labels": [], "entities": [{"text": "WSD", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.958181619644165}, {"text": "sense disambiguation", "start_pos": 77, "end_pos": 97, "type": "TASK", "confidence": 0.6947267800569534}, {"text": "sense disambiguation", "start_pos": 244, "end_pos": 264, "type": "TASK", "confidence": 0.7403407990932465}]}, {"text": "In this paper, we present a hypothesis regarding the cognitive sub-processes involved in the task of WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 101, "end_pos": 104, "type": "TASK", "confidence": 0.928267240524292}]}, {"text": "We support our hypothesis using the experiments conducted through the means of an eye-tracking device.", "labels": [], "entities": []}, {"text": "We also strive to find the levels of difficulties in annotating various classes of words, with senses.", "labels": [], "entities": []}, {"text": "We believe, once such an in-depth analysis is performed, numerous insights can be gained to develop a robust WSD system that conforms to the principle of strong AI.", "labels": [], "entities": [{"text": "WSD", "start_pos": 109, "end_pos": 112, "type": "TASK", "confidence": 0.9657997488975525}]}], "introductionContent": [{"text": "Word Sense Disambiguation (WSD) is formally defined as the task of computationally identifying senses of a word in a context.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7896928588549296}]}, {"text": "The phrase 'in a context' is not defined explicitly in the literature.", "labels": [], "entities": []}, {"text": "NLP researchers define it according to their convenience.", "labels": [], "entities": []}, {"text": "In our current work, we strive to unravel the appropriate meaning of contextual evidence used for the human annotation process.", "labels": [], "entities": []}, {"text": "showed that the contextual evidence is the predominant parameter for the human sense annotation process.", "labels": [], "entities": [{"text": "human sense annotation process", "start_pos": 73, "end_pos": 103, "type": "TASK", "confidence": 0.6687631085515022}]}, {"text": "They also state that WSD is successful as a weak AI system, and further analysis into human cognitive activities lying at the heart of sense annotation can aid in development of a WSD system built upon the principles of strong AI.", "labels": [], "entities": [{"text": "WSD", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9094983339309692}, {"text": "WSD", "start_pos": 180, "end_pos": 183, "type": "TASK", "confidence": 0.9309471249580383}]}, {"text": "Knowledge based approaches, which can be considered to be closest form of WSD conforming to the principles of strong AI, typically achieve low accuracy.", "labels": [], "entities": [{"text": "WSD", "start_pos": 74, "end_pos": 77, "type": "TASK", "confidence": 0.974746823310852}, {"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9976657629013062}]}, {"text": "Recent developments in domain-specific knowledge based approaches have reported higher accuracies.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 87, "end_pos": 97, "type": "METRIC", "confidence": 0.98322993516922}]}, {"text": "A domain-specific approach due to beats supervised WSD done in generic domains.", "labels": [], "entities": [{"text": "WSD", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.9695309996604919}]}, {"text": "present a knowledge based approach which rivals the supervised approaches by using the semantic relations automatically extracted from Wikipedia.", "labels": [], "entities": []}, {"text": "They reported approximately 7% gain over the closet supervised approach.", "labels": [], "entities": []}, {"text": "In this paper, we delve deep into the cognitive roles associated with sense disambiguation through the means of an eye-tracking device capturing the gaze patterns of lexicographers, during the annotation process.", "labels": [], "entities": [{"text": "sense disambiguation", "start_pos": 70, "end_pos": 90, "type": "TASK", "confidence": 0.750470757484436}]}, {"text": "In-depth discussions with trained lexicographers indicate that there are multiple cognitive sub-processes driving the sense disambiguation task.", "labels": [], "entities": [{"text": "sense disambiguation task", "start_pos": 118, "end_pos": 143, "type": "TASK", "confidence": 0.7861452202002207}]}, {"text": "The eye movement paths available from the screen recordings done during sense annotation conform to this theory.", "labels": [], "entities": [{"text": "sense annotation", "start_pos": 72, "end_pos": 88, "type": "TASK", "confidence": 0.7641025483608246}]}, {"text": "points out that the accuracy of various WSD algorithms is poor on certain Part-of-speech (POS) categories, particularly, verbs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9993956089019775}, {"text": "WSD", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.9853001236915588}]}, {"text": "It is also a general observation for lexicographers involved in sense annotation that there are different levels of difficulties associated with various classes of words.", "labels": [], "entities": [{"text": "sense annotation", "start_pos": 64, "end_pos": 80, "type": "TASK", "confidence": 0.7118280977010727}]}, {"text": "This fact is also reflected in our analysis on sense annotation.", "labels": [], "entities": [{"text": "sense annotation", "start_pos": 47, "end_pos": 63, "type": "TASK", "confidence": 0.8342625498771667}]}, {"text": "The data available after the eye-tracking experiments gave us the fixation times and saccades pertaining to different classes of words.", "labels": [], "entities": []}, {"text": "From the analysis of this data we draw conclusive remarks regarding the reasons behind this phenomenon.", "labels": [], "entities": []}, {"text": "In our case, we classified words based on their POS categories.", "labels": [], "entities": []}, {"text": "In this paper, we establish that contextual evidence is the prime parameter for the human annotation.", "labels": [], "entities": []}, {"text": "Further, we probe into the implication of context used as a clue for sense disambiguation, and the manner of its usage.", "labels": [], "entities": [{"text": "sense disambiguation", "start_pos": 69, "end_pos": 89, "type": "TASK", "confidence": 0.7041223347187042}]}, {"text": "In this work, we address the following questions: \u2022 What are the cognitive sub-processes associated with the human sense annotation task?", "labels": [], "entities": []}, {"text": "\u2022 Which classes of words are more difficult to disambiguate and why?", "labels": [], "entities": []}, {"text": "By providing relevant answers to these questions we intend to present a comprehensive understanding of sense annotation as a complex cognitive process and the factors involved in it.", "labels": [], "entities": [{"text": "sense annotation", "start_pos": 103, "end_pos": 119, "type": "TASK", "confidence": 0.7081384509801865}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 contains related work.", "labels": [], "entities": []}, {"text": "In section 3 we present the experimental setup.", "labels": [], "entities": []}, {"text": "Section 4 displays the results.", "labels": [], "entities": []}, {"text": "We summarize our findings in section 5.", "labels": [], "entities": []}, {"text": "Finally, we conclude the paper in section 6 presenting the future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used a generic domain (viz., News) corpus in Hindi language for experimental purposes.", "labels": [], "entities": [{"text": "News) corpus", "start_pos": 32, "end_pos": 44, "type": "DATASET", "confidence": 0.8359640041987101}]}, {"text": "To identify the levels of difficulties associated with human annotation, across various POS categories, we conducted experiments on around 2000 words (including function words and stop words).", "labels": [], "entities": []}, {"text": "The analysis was done only for open class words.", "labels": [], "entities": []}, {"text": "The statistics pertaining to the our experiment are illustrated in table 1.", "labels": [], "entities": []}, {"text": "For statistical significance of our experiments, we collected the data with the help of 3 skilled lexicographers and 3 unskilled lexicographers.", "labels": [], "entities": []}, {"text": "For our experiments we used a Sense Annotation Tool, designed at IIT Bombay and an eye-tracking device.", "labels": [], "entities": [{"text": "IIT Bombay", "start_pos": 65, "end_pos": 75, "type": "DATASET", "confidence": 0.8124921917915344}]}, {"text": "The details of the tools and their purposes are explained below:", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of words (tokens) and average degree  of corpus polysemy (senses) of words per POS category  (taken from Hindi News domain) used for experiments", "labels": [], "entities": [{"text": "average degree  of corpus polysemy (senses)", "start_pos": 39, "end_pos": 82, "type": "METRIC", "confidence": 0.7603714689612389}, {"text": "Hindi News domain)", "start_pos": 122, "end_pos": 140, "type": "DATASET", "confidence": 0.9496191143989563}]}, {"text": " Table 2: Comparison of time taken across different cognitive stages of sense annotation by lexicographers for verbs", "labels": [], "entities": []}, {"text": " Table 3: Pairwise correlation between annotation time taken by lexicographers", "labels": [], "entities": []}]}