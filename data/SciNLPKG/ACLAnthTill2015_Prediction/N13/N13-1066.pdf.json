{"title": [], "abstractContent": [{"text": "In cases in which there is no standard or-thography fora language or language variant , written texts will display a variety of or-thographic choices.", "labels": [], "entities": []}, {"text": "This is problematic for natural language processing (NLP) because it creates spurious data sparseness.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 24, "end_pos": 57, "type": "TASK", "confidence": 0.7978553473949432}]}, {"text": "We study the transformation of spontaneously spelled Egyptian Arabic into a conventionalized or-thography which we have previously proposed for NLP purposes.", "labels": [], "entities": []}, {"text": "We show that a two-stage process can reduce divergences from this standard by 69%, making subsequent processing of Egyptian Arabic easier.", "labels": [], "entities": [{"text": "processing of Egyptian Arabic", "start_pos": 101, "end_pos": 130, "type": "TASK", "confidence": 0.7459478378295898}]}], "introductionContent": [{"text": "In areas with diglossia, vernacular spoken variants (\"low\") of a language family co-exist with a largely written variant (\"high\"), which is often not spoken as a native language.", "labels": [], "entities": []}, {"text": "Traditionally, the low variants have not been written: written language is reserved for formal occasions and in those formal occasions only the high variant is used.", "labels": [], "entities": []}, {"text": "Prototypical examples of diglossia are the German speaking parts of Switzerland, and the Arab world.", "labels": [], "entities": []}, {"text": "The advent of the internet has changed linguistic behavior: it is now common to find written informal conversations, in the form of email exchanges, text messages, Twitter exchanges, and interactions on blogs and in web forums.", "labels": [], "entities": []}, {"text": "These written conversations are typically written in the low variants (or in a mixture of low and high), since conversations in the high variant seem unnatural to the discourse participants.", "labels": [], "entities": []}, {"text": "For natural language processing (NLP), this poses many challenges, one of which is the fact that the low variants have not been written much in the past and do not have a standard orthography which is generally agreed on by the linguistic community (and perhaps sanctioned by an authoritative institution).", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 4, "end_pos": 37, "type": "TASK", "confidence": 0.8231694002946218}]}, {"text": "Instead, each discourse participant devises a spontaneous orthography, in which she chooses among conventions from the high variant to render the spoken language.", "labels": [], "entities": []}, {"text": "We are thus faced with a large number of ways to spell the same word, none of which can be assumed as \"standard\" since there is no standard.", "labels": [], "entities": []}, {"text": "As a result, the increased data sparseness adds to the challenges of NLP tasks such as machine translation, compared to languages for which orthography is standardized.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.7938942015171051}]}, {"text": "In this paper, we work on Egyptian Arabic (EGY).", "labels": [], "entities": [{"text": "Egyptian Arabic (EGY)", "start_pos": 26, "end_pos": 47, "type": "DATASET", "confidence": 0.6415308833122253}]}, {"text": "We follow the conventions which we have previously proposed for the normalized orthography for EGY (, called CODA (Conventional Orthography for Dialectal Arabic).", "labels": [], "entities": [{"text": "EGY", "start_pos": 95, "end_pos": 98, "type": "DATASET", "confidence": 0.8899758458137512}]}, {"text": "In this paper, we investigate how easy it is to convert spontaneous orthography of EGY written in Arabic script into CODA orthography automatically.", "labels": [], "entities": []}, {"text": "We will refer to this process as \"normalization\" or \"codafication\".", "labels": [], "entities": []}, {"text": "We present a freely available system called CODAFY, which we propose as a preprocessor for NLP modules for EGY.", "labels": [], "entities": [{"text": "EGY", "start_pos": 107, "end_pos": 110, "type": "DATASET", "confidence": 0.8532711863517761}]}, {"text": "We show that a \"do nothing\" baseline achieves a normalization performance of 75.5%, and CODAFY achieves a normalization performance of 92.4%, an error reduction of 69.2% over this baseline on an unseen test set.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 145, "end_pos": 160, "type": "METRIC", "confidence": 0.9721358120441437}]}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "We first review relevant linguistic facts in Section 2 and then present the conventionalized orthography we use in this paper.", "labels": [], "entities": []}, {"text": "After reviewing related work in Section 4, we present our data (Section 5), our approach (Section 6), and our results (Section 7).", "labels": [], "entities": []}, {"text": "We conclude with a discussion of future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The different codafication approaches, discussed in the previous section, are tested against the development set, which was not used as part of our training.", "labels": [], "entities": []}, {"text": "The evaluation metric we use is a word accuracy metric, i.e., we evaluate how well we can correctly predict the CODA form of the input spontaneous orthography.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.723100483417511}]}, {"text": "lists the effects of using the different codafication approaches.", "labels": [], "entities": []}, {"text": "For each approach, two numbers are reported; exact and normalized.", "labels": [], "entities": [{"text": "exact", "start_pos": 45, "end_pos": 50, "type": "METRIC", "confidence": 0.9680427312850952}]}, {"text": "In the exact evaluation, the output of the codafication approach is exactly matched against the correct CODA orthography, while in the normalized evaluation, the match is relaxed for the (/ / / A/\u00c2/ \u02c7 A/ \u00af A) and / y/\u00fd alternations, i.e., these differences do not count as errors.", "labels": [], "entities": []}, {"text": "In many NLP applications (such as machine translation), the input is normalized for these two phenomena, so that the normalized evaluation gives a sense of the relevance of codafication to downstream processes which normalize.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.8081267774105072}]}, {"text": "In this evaluation we compare our different codafication techniques, CEC, MLE, CEC+MLE and MLE+CEC, against the baseline.", "labels": [], "entities": []}, {"text": "We also show the effect of using MADA ARZ as a codafication system.", "labels": [], "entities": [{"text": "MADA ARZ", "start_pos": 33, "end_pos": 41, "type": "DATASET", "confidence": 0.6724988222122192}]}, {"text": "We see that MLE on its own outperforms CEC.", "labels": [], "entities": [{"text": "MLE", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.3784470856189728}, {"text": "CEC", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.9409864544868469}]}, {"text": "Running CEC first and then MLE gives us our best result using surface techniques, namely 91.5%, for an error reduction of 63.4% against the baseline.", "labels": [], "entities": [{"text": "CEC", "start_pos": 8, "end_pos": 11, "type": "METRIC", "confidence": 0.834614098072052}, {"text": "MLE", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9778769612312317}, {"text": "error reduction", "start_pos": 103, "end_pos": 118, "type": "METRIC", "confidence": 0.9817916750907898}]}, {"text": "This configuration also gives the highest normalized accuracy of 95.2%, for an error reduction of 49.5% against the baseline.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.92537921667099}, {"text": "error reduction", "start_pos": 79, "end_pos": 94, "type": "METRIC", "confidence": 0.9827582836151123}]}, {"text": "We now turn to deep modeling techniques.", "labels": [], "entities": []}, {"text": "The performance of MADA ARZ on its own as a codafication system is close to the performance of CEC+MLE, by which it is outperformed in the exact-match accuracy by 0.4%.", "labels": [], "entities": [{"text": "MADA ARZ", "start_pos": 19, "end_pos": 27, "type": "DATASET", "confidence": 0.6099770069122314}, {"text": "MLE", "start_pos": 99, "end_pos": 102, "type": "METRIC", "confidence": 0.5736490488052368}, {"text": "exact-match", "start_pos": 139, "end_pos": 150, "type": "METRIC", "confidence": 0.905771791934967}, {"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.7546729445457458}]}, {"text": "The best deep modeling (and the best overall) performance is achieved when running MADA ARZ on top of MLE.", "labels": [], "entities": [{"text": "MADA ARZ", "start_pos": 83, "end_pos": 91, "type": "DATASET", "confidence": 0.7666530013084412}, {"text": "MLE", "start_pos": 102, "end_pos": 105, "type": "DATASET", "confidence": 0.7128092646598816}]}, {"text": "This gives the highest accuracy of 92.6% (exact) and 95.8% (normalized), for error reductions of 68.1% (exact) and 55.8% (normalized) against the baseline, respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.999569833278656}, {"text": "error reductions", "start_pos": 77, "end_pos": 93, "type": "METRIC", "confidence": 0.9706992506980896}]}, {"text": "Note that the non-contextual modeling techniques CEC (5,584 words/sec) and MLE (6,698 words/sec) area lot faster than the deep modeling technique MADA ARZ (53 words/sec), while their combination CEC+MLE+MADA ARZ is the slowest among all the approaches, operating at a rate of 52 words/sec.", "labels": [], "entities": [{"text": "MLE", "start_pos": 75, "end_pos": 78, "type": "METRIC", "confidence": 0.8063820600509644}]}, {"text": "Thus, a small drop inaccuracy results in a large increase in speed.", "labels": [], "entities": [{"text": "speed", "start_pos": 61, "end_pos": 66, "type": "METRIC", "confidence": 0.9827082753181458}]}, {"text": "We also evaluated using MADA M SA (v 3.2) (Morphological Analysis and Disambiguation for MSA)).", "labels": [], "entities": [{"text": "MADA M SA", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.839678148428599}]}, {"text": "MADA M SA is able to do some codafication, but it performs far worse than our codafication approaches.", "labels": [], "entities": [{"text": "MADA M SA", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.6184048056602478}]}, {"text": "lists the results of the best performing codafication surface approach, CEC+MLE, and deep approach, MLE+MADA ARZ , when applied on the test set, which was not used as part of our training or development, i.e., a completely blind test.", "labels": [], "entities": [{"text": "MLE+MADA ARZ", "start_pos": 100, "end_pos": 112, "type": "METRIC", "confidence": 0.7845403999090195}]}, {"text": "We see that on the test set, the addition of MADA ARZ improves results relatively more as compared to the development set.: Comparison of the performance of the different codafication approaches on the test corpus.", "labels": [], "entities": [{"text": "MADA ARZ", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.8720805048942566}]}, {"text": "Acc stands for Accuracy; ER is error reduction against the Baseline.", "labels": [], "entities": [{"text": "Acc", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9874773025512695}, {"text": "Accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9984436631202698}, {"text": "ER", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.9876513481140137}]}, {"text": "Morphological Analysis We tested the effect of codafication on morphological tagging, specifically full POS and lemma determination in context by the morphological tagger MADA ARZ . Here, we are evaluating MADA ARZ not on its conversion to CODA (as above), but on its core functionality, namely morphological tagging.", "labels": [], "entities": [{"text": "Morphological Analysis", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7896440923213959}, {"text": "morphological tagging", "start_pos": 63, "end_pos": 84, "type": "TASK", "confidence": 0.6441926807165146}, {"text": "POS", "start_pos": 104, "end_pos": 107, "type": "METRIC", "confidence": 0.9923134446144104}, {"text": "MADA ARZ", "start_pos": 171, "end_pos": 179, "type": "DATASET", "confidence": 0.7520257532596588}, {"text": "morphological tagging", "start_pos": 295, "end_pos": 316, "type": "TASK", "confidence": 0.7358289361000061}]}, {"text": "We compare the performance of MADA ARZ against running CEC+MLE+MADA ARZ . When tested on the development set, the initial CEC+MLE codafication step helps MADA ARZ improve the identification of the complete Arabic (Buckwalter) POS tag from 84% to 85.3%, for an error reduction of 8.1%, while the correct lemma choice increases from 85.2% to 85.7%, for an error reduction of 3.4%.", "labels": [], "entities": [{"text": "MADA ARZ", "start_pos": 63, "end_pos": 71, "type": "DATASET", "confidence": 0.8419536650180817}, {"text": "error reduction", "start_pos": 354, "end_pos": 369, "type": "METRIC", "confidence": 0.9260233938694}]}, {"text": "When tested on the test set, we get improvements on the choice of the complete Buckwalter POS tag and lemma from 84.5% to 85.4% (5.8% error reduction) and from 86.3% to 86.7% (2.9% error reduction), respectively.", "labels": [], "entities": [{"text": "Buckwalter POS tag", "start_pos": 79, "end_pos": 97, "type": "DATASET", "confidence": 0.8509670297304789}, {"text": "error reduction", "start_pos": 134, "end_pos": 149, "type": "METRIC", "confidence": 0.9533412754535675}, {"text": "error reduction)", "start_pos": 181, "end_pos": 197, "type": "METRIC", "confidence": 0.9264838695526123}]}, {"text": "Arabic to English MT The goal of this experiment is to test the effect of codafication on machine translation from dialectal Arabic to English.", "labels": [], "entities": [{"text": "MT", "start_pos": 18, "end_pos": 20, "type": "TASK", "confidence": 0.6008523106575012}, {"text": "machine translation", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.6758459210395813}]}, {"text": "We use the open-source Moses toolkit () to build a phrase-based SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.7688376307487488}]}, {"text": "We use MGIZA++ for word alignment (.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.7866961359977722}]}, {"text": "Phrase translations of up to 8 words are extracted in the phrase table.", "labels": [], "entities": [{"text": "Phrase translations", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7648672163486481}]}, {"text": "We use SRILM) with modified Kneser-Ney smoothing to build two 4-gram language models.", "labels": [], "entities": []}, {"text": "The first model is trained on the English side of the bitext, while the other is trained on the English Gigaword data.", "labels": [], "entities": [{"text": "English Gigaword data", "start_pos": 96, "end_pos": 117, "type": "DATASET", "confidence": 0.8262742956479391}]}, {"text": "Feature weights are tuned to maximize BLEU () on a development set using MERT.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9948038458824158}]}, {"text": "We perform case-insensitive evaluation in terms of the BLEU metric.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.9969011545181274}]}, {"text": "We train the system on dialectal Arabic-English parallel data, obtained from several LDC corpora, which amounts to \u223c500k sentences with 3.8M untokenized words on the Arabic side.", "labels": [], "entities": []}, {"text": "The development set, used for tuning the parameters of the MT system, has 1,547 sentences with 15,585 untokenized Arabic words.", "labels": [], "entities": [{"text": "MT", "start_pos": 59, "end_pos": 61, "type": "TASK", "confidence": 0.9536312818527222}]}, {"text": "The test set has 1,065 sentences with 12,116 untokenized Arabic words.", "labels": [], "entities": []}, {"text": "Both development and test sets have two reference translations each.", "labels": [], "entities": []}, {"text": "The English data is lower-cased and tokenized using simple punctuation-based rules.", "labels": [], "entities": []}, {"text": "We build two systems which vary in preprocessing of the Arabic text.", "labels": [], "entities": []}, {"text": "The baseline system applies only simple punctuation-based rules.", "labels": [], "entities": []}, {"text": "The second system applies our codafication in addition to punctuation separation.", "labels": [], "entities": [{"text": "punctuation separation", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.6761539131402969}]}, {"text": "The Arabic text is Alif/Ya normalized and is kept untokenized in both settings.", "labels": [], "entities": []}, {"text": "The baseline system achieves a BLEU score of 22.1%.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.9836516380310059}]}, {"text": "The system using codafication obtains a BLEU score of 22.6%, and outperforms the baseline by 0.5% absolute BLEU points.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.9859849512577057}, {"text": "BLEU", "start_pos": 107, "end_pos": 111, "type": "METRIC", "confidence": 0.9867384433746338}]}, {"text": "This result shows that improvements observed in intrinsic evaluation of codafication carry onto the extrinsic task of machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 118, "end_pos": 137, "type": "TASK", "confidence": 0.7736373245716095}]}], "tableCaptions": [{"text": " Table 1: Spontaneous to CODA character substitu- tion transformations", "labels": [], "entities": [{"text": "CODA character substitu- tion", "start_pos": 25, "end_pos": 54, "type": "TASK", "confidence": 0.6135003328323364}]}, {"text": " Table 2: Spontaneous to CODA character addi- tion/deletion transformations", "labels": [], "entities": []}, {"text": " Table 3: Comparison of the performance of the different codafication approaches on the development corpus.  Acc stands for Accuracy; ER is error reduction against the Baseline. w/s is speed (words/sec).", "labels": [], "entities": [{"text": "Acc", "start_pos": 109, "end_pos": 112, "type": "METRIC", "confidence": 0.9943903088569641}, {"text": "Accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9650099873542786}, {"text": "speed", "start_pos": 185, "end_pos": 190, "type": "METRIC", "confidence": 0.992094099521637}]}, {"text": " Table 4: Comparison of the performance of the  different codafication approaches on the test cor- pus. Acc stands for Accuracy; ER is error reduction  against the Baseline.", "labels": [], "entities": [{"text": "Acc", "start_pos": 104, "end_pos": 107, "type": "METRIC", "confidence": 0.9961689114570618}, {"text": "Accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9968666434288025}, {"text": "ER", "start_pos": 129, "end_pos": 131, "type": "METRIC", "confidence": 0.960546612739563}]}]}