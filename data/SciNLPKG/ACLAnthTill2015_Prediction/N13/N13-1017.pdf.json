{"title": [{"text": "Drug Extraction from the Web: Summarizing Drug Experiences with Multi-Dimensional Topic Models", "labels": [], "entities": [{"text": "Drug Extraction from the Web", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7924030065536499}, {"text": "Summarizing Drug Experiences", "start_pos": 30, "end_pos": 58, "type": "TASK", "confidence": 0.8969067732493082}]}], "abstractContent": [{"text": "Multi-dimensional latent text models, such as factorial LDA (f-LDA), capture multiple factors of corpora, creating structured output for researchers to better understand the contents of a corpus.", "labels": [], "entities": []}, {"text": "We consider such models for clinical research of new recreational drugs and trends, an important application for mining current information for healthcare workers.", "labels": [], "entities": []}, {"text": "We use a \"three-dimensional\" f-LDA variant to jointly model combinations of drug (mari-juana, salvia, etc.), aspect (effects, chemistry, etc.) and route of administration (smoking, oral, etc.)", "labels": [], "entities": []}, {"text": "Since a purely unsupervised topic model is unlikely to discover these specific factors of interest, we develop a novel method of incorporating prior knowledge by leverag-ing user generated tags as priors in our model.", "labels": [], "entities": []}, {"text": "We demonstrate that this model can be used as an exploratory tool for learning about these drugs from the Web by applying it to the task of extractive summarization.", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 140, "end_pos": 164, "type": "TASK", "confidence": 0.6726385354995728}]}, {"text": "In addition to providing useful output for this important public health task, our prior-enriched model provides a framework for the application of f-LDA to other tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Topic models aid exploration of the main thematic elements of large text corpora by revealing latent structure and producing a high level semantic view ().", "labels": [], "entities": []}, {"text": "Topic models have been used for understanding the contents of a corpus and identifying interesting aspects of a collection for more indepth analysis.", "labels": [], "entities": []}, {"text": "While standard topic models assume a flat semantic structure, there are potentially many dimensions of a corpus that contribute to word choice, such as sentiment, perspective and ideology).", "labels": [], "entities": []}, {"text": "Rather than studying these factors in isolation, multi-dimensional topic models can consider multiple factors jointly.", "labels": [], "entities": []}, {"text": "Paul and Dredze (2012b) introduced factorial LDA (f-LDA), a general framework for multidimensional text models that capture an arbitrary number of factors (explained in \u00a73).", "labels": [], "entities": []}, {"text": "While a standard topic model learns distributions over \"topics\" in documents, f-LDA learns distributions over combinations of multiple factors (e.g. topic, perspective) called tuples (e.g. (HEALTHCARE,LIBERAL)).", "labels": [], "entities": []}, {"text": "While f-LDA can model factors without supervision, it has not been used in situations where the user has prior information about the factors.", "labels": [], "entities": []}, {"text": "In this paper we consider a setting where the user has prior knowledge about the end application: mining recreational drug trends from user forums, an important clinical research problem ( \u00a72).", "labels": [], "entities": []}, {"text": "We show how to incorporate available information from these forums into f-LDA as a novel hierarchical prior over the model parameters, guiding the model toward the desired output ( \u00a73.1).", "labels": [], "entities": []}, {"text": "We then demonstrate the model's utility in exploring a corpus in a targeted manner by using it to automatically extract interesting sentences from the text, a simple form of extractive multi-document summarization ().", "labels": [], "entities": []}, {"text": "In the same way that topic models can be used for aspectspecific summarization, we use f-LDA to extract snippets corresponding to fine-grained information patterns.", "labels": [], "entities": []}, {"text": "Our results demonstrate that our multi-dimensional modeling approach targets more informative text than a simpler model ( \u00a74).", "labels": [], "entities": []}], "datasetContent": [{"text": "Our corpus consists of messages from drugs-forum.com ( \u00a72.1).", "labels": [], "entities": []}, {"text": "The site categorizes threads into many forums and subforums, including some on specific drugs, which are categorized hierarchically.", "labels": [], "entities": []}, {"text": "We treated higher-level categories with pharmacologically similar drugs as a single drug type (e.g. OPIOIDS, AMPHETAMINES); for others we took the finest-granularity subforum as the drug type.", "labels": [], "entities": [{"text": "OPIOIDS", "start_pos": 100, "end_pos": 107, "type": "METRIC", "confidence": 0.7623476982116699}, {"text": "AMPHETAMINES", "start_pos": 109, "end_pos": 121, "type": "METRIC", "confidence": 0.6722151041030884}]}, {"text": "We selected 22 popular drugs and from these forums we crawled 410K messages.", "labels": [], "entities": []}, {"text": "We selected a subset of tags to form components for the route and aspect factors.", "labels": [], "entities": []}, {"text": "(Some tags were too general or infrequent to be useful.)", "labels": [], "entities": []}, {"text": "A list of the tags and drugs used appears in.", "labels": [], "entities": []}, {"text": "We also included a GENERAL component in the latter two factors to model word usage which does not pertain to a particular route or aspect; the prior parameters \u03b7 for these components were simply set to 0.", "labels": [], "entities": [{"text": "GENERAL", "start_pos": 19, "end_pos": 26, "type": "METRIC", "confidence": 0.944513201713562}]}, {"text": "We wish to demonstrate that our modified f-LDA model can be used to discover useful information in the text.", "labels": [], "entities": []}, {"text": "One way to demonstrate this is by using the model to extract relevant snippets of text from the forums, which will form the basis of our evaluation experiments.", "labels": [], "entities": []}, {"text": "Our goal is not to build a complete summarization system, but rather to use the model to direct researchers to interesting messages.", "labels": [], "entities": []}, {"text": "While we model all 22 drugs, our summarization experiments will focus on five drugs which have been studied only relatively recently: mephedrone and MDPV (\u03b2-ketones), BromoDragonfly (synthetic phenethylamines), Spice/K2 (synthetic cannabinoids), and salvia divinorum.", "labels": [], "entities": [{"text": "summarization", "start_pos": 33, "end_pos": 46, "type": "TASK", "confidence": 0.957798182964325}]}, {"text": "We will consider these drugs in particular because these are the five drugs for which technical reports were created by the EU Psychonaut Project (), an online database of novel and emerging drugs, whose information is collected by reading drug websites, including Drugs-Forum.", "labels": [], "entities": []}, {"text": "Extensive technical reports were written about these five popular drugs, and we can use these reports to produce reference summaries for our experiments ( \u00a74.2).", "labels": [], "entities": []}, {"text": "Of these five drugs, only salvia has its own subforum; the others belong to subforums representing the broader categories shown in parentheses.", "labels": [], "entities": []}, {"text": "We simply model the drug type as a proxy for the specific drug, as most of the drugs in each category have similar effects and properties.", "labels": [], "entities": []}, {"text": "The first two drugs are both in the same subforum, so for the purpose of our model we treat mephedrone and MDPV as the single drug type, \u03b2-ketones.", "labels": [], "entities": []}, {"text": "These two drugs are grouped together during summarization ( \u00a74.2), but the corresponding reference summaries incorporate excepts from the technical reports on both drugs.", "labels": [], "entities": [{"text": "summarization", "start_pos": 44, "end_pos": 57, "type": "TASK", "confidence": 0.9258449673652649}]}, {"text": "Recall that the reports used as reference summaries were themselves created by reading web forums.", "labels": [], "entities": []}, {"text": "Our hypothesis is that f-LDA could be used as an exploratory tool to expedite the creation of these reports.", "labels": [], "entities": []}, {"text": "Thus in our evaluation we want to measure how useful the extracted snippets would be in informing the writing of such reports.", "labels": [], "entities": []}, {"text": "We performed both human and automatic evaluation on the summaries generated by f-LDA (variants 1 and 2) as well as our baseline.", "labels": [], "entities": []}, {"text": "We also included randomly selected snippets as a control (five per reference).", "labels": [], "entities": []}, {"text": "Example output is shown in.", "labels": [], "entities": []}, {"text": "The human judgments effectively measured a form of precision, as the quality of snippets were judged by their correspondence to the reference text, without regard to how much of the reference text was covered by all snippets.", "labels": [], "entities": [{"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9976304769515991}]}, {"text": "We also used the automatic evaluation metric ROUGE) as a rough estimate of summary recall: this metric computes the percentage of n-grams in the reference text that appeared in the generated summaries.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 45, "end_pos": 50, "type": "METRIC", "confidence": 0.8091747760772705}, {"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9633854031562805}]}, {"text": "We computed ROUGE for both 1-grams and 2-grams.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 12, "end_pos": 17, "type": "METRIC", "confidence": 0.9979884624481201}]}, {"text": "When computing n-gram counts, we applied Porter's stemmer to all tokens.", "labels": [], "entities": []}, {"text": "We excluded stop words from 1-gram counts but included them in 2-gram counts where we care about longer phrases.", "labels": [], "entities": []}, {"text": "We find that f-LDA-1 has the highest score for both 1-and 2-grams, suggesting that it is extracting a more diverse set of relevant snippets.", "labels": [], "entities": []}, {"text": "When performing a paired t-test across the 12 reference summaries, we find that f-LDA is better than the baseline with p-values 0.14 and 0.10 for 1-gram and 2-gram recall, respectively.", "labels": [], "entities": [{"text": "f-LDA", "start_pos": 80, "end_pos": 85, "type": "METRIC", "confidence": 0.9234897494316101}, {"text": "recall", "start_pos": 164, "end_pos": 170, "type": "METRIC", "confidence": 0.9944338202476501}]}, {"text": "f-LDA's recall advantage may come from the fact that it learns from a larger amount of data and it may learn more diverse word distributions by directly modeling triples.", "labels": [], "entities": [{"text": "recall", "start_pos": 8, "end_pos": 14, "type": "METRIC", "confidence": 0.9970661997795105}]}, {"text": "f-LDA-1 had slightly better recall (under ROUGE), while f-LDA-2 was slightly better according to the human annotators.", "labels": [], "entities": [{"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.999688982963562}, {"text": "ROUGE", "start_pos": 42, "end_pos": 47, "type": "METRIC", "confidence": 0.9971603155136108}]}], "tableCaptions": [{"text": " Table 2: Summary quality evaluation across four systems.", "labels": [], "entities": [{"text": "Summary quality evaluation", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.850305994351705}]}]}