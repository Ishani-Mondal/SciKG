{"title": [{"text": "On Quality Ratings for Spoken Dialogue Systems -Experts vs. Users", "labels": [], "entities": []}], "abstractContent": [{"text": "In the field of Intelligent User Interfaces, Spoken Dialogue Systems (SDSs) play a key role as speech represents a true intuitive means of human communication.", "labels": [], "entities": []}, {"text": "Deriving information about its quality can help rendering SDSs more user-adaptive.", "labels": [], "entities": []}, {"text": "Work on automatic estimation of subjective quality usually relies on statistical models.", "labels": [], "entities": []}, {"text": "To create those, manual data annotation is required, which maybe performed by actual users or by experts.", "labels": [], "entities": []}, {"text": "Here, both variants have their advantages and drawbacks.", "labels": [], "entities": []}, {"text": "In this paper, we analyze the relationship between user and expert ratings by investigating models which combine the advantages of both types of ratings.", "labels": [], "entities": []}, {"text": "We explore two novel approaches using statistical classification methods and evaluate those with a pre-existing corpus providing user and expert ratings.", "labels": [], "entities": [{"text": "statistical classification", "start_pos": 38, "end_pos": 64, "type": "TASK", "confidence": 0.6815021187067032}]}, {"text": "After analyzing the results, we eventually recommend to use expert ratings instead of user ratings in general.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "For measuring the performance of the classification algorithms, we rely on Unweighted Average Recall (UAR), Cohen's Kappa and Spearman's Rho.", "labels": [], "entities": [{"text": "Unweighted Average Recall (UAR)", "start_pos": 75, "end_pos": 106, "type": "METRIC", "confidence": 0.9713562528292338}]}, {"text": "The latter two also represent a measure for similarity of paired data.", "labels": [], "entities": [{"text": "similarity", "start_pos": 44, "end_pos": 54, "type": "METRIC", "confidence": 0.9420067667961121}]}, {"text": "All measures will be briefly described in the following: Unweighted Average Recall The Unweighted Average Recall (UAR) is defined as the sum of all class-wise recalls r c divided by the number of classes |C|: Recall r c for class c is defined as where \u03b4 is the Kronecker-delta, hi and r i represent the corresponding hypothesis-referencepair of rating i, and |R c | the total number of all ratings of class c.", "labels": [], "entities": [{"text": "Unweighted Average Recall", "start_pos": 57, "end_pos": 82, "type": "METRIC", "confidence": 0.7489837209383646}, {"text": "Unweighted Average Recall (UAR)", "start_pos": 87, "end_pos": 118, "type": "METRIC", "confidence": 0.9080216586589813}]}, {"text": "In other words, UAR for multi-class classification problems is the accuracy corrected by the effects of unbalanced data.", "labels": [], "entities": [{"text": "UAR", "start_pos": 16, "end_pos": 19, "type": "METRIC", "confidence": 0.9813228845596313}, {"text": "multi-class classification", "start_pos": 24, "end_pos": 50, "type": "TASK", "confidence": 0.7039482593536377}, {"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.9992515444755554}]}, {"text": "Cohen's Kappa To measure the relative agreement between two corresponding sets of ratings, the number of label agreements corrected by the chance level of agreement divided by the maximum proportion of times the labelers could agree is computed.", "labels": [], "entities": []}, {"text": "\u03ba is defined as where p 0 is the rate of agreement and p c is the chance agreement.", "labels": [], "entities": [{"text": "chance agreement", "start_pos": 66, "end_pos": 82, "type": "METRIC", "confidence": 0.9271443784236908}]}, {"text": "As US and IQ are on an ordinal scale, a weighting factor w is introduced reducing the discount of disagreements the smaller the difference is between two ratings: Here, r 1 and r 2 denote the rating pair and r max and r min the maximal and minimal rating.", "labels": [], "entities": [{"text": "IQ", "start_pos": 10, "end_pos": 12, "type": "DATASET", "confidence": 0.6658545136451721}, {"text": "discount", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9626092314720154}]}, {"text": "This results in w = 0 for agreement and w = 1 if the ratings have maximal difference.", "labels": [], "entities": [{"text": "agreement", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9020034074783325}]}, {"text": "Spearman's Rho The correlation of two variables describes the degree by that one variable can be expressed by the other.", "labels": [], "entities": []}, {"text": "Spearman's Rank Correlation Coefficient is a non-parametric method assuming a monotonic function between the two variables.", "labels": [], "entities": []}, {"text": "It is defined by where xi and y i are corresponding ranked ratings and \u00af x and \u00af y the mean ranks.", "labels": [], "entities": []}, {"text": "Thus, two sets of ratings can have total correlation even if they never agree.", "labels": [], "entities": []}, {"text": "This would happen if all ratings are shifted by the same value, for example.", "labels": [], "entities": []}, {"text": "For evaluating Belief-Based Sequential Recognition, not only the absolute performance is of interest but also how this performance is influenced by the characteristics of the observation probability, i.e., the performance of the applied statistical classification approach and the variance of their confidence scores.", "labels": [], "entities": [{"text": "Belief-Based Sequential Recognition", "start_pos": 15, "end_pos": 50, "type": "TASK", "confidence": 0.690256933371226}]}, {"text": "In order to obtain different confidence characteristics, multiple classification algorithms, or algorithm variants respectively, are needed.", "labels": [], "entities": []}, {"text": "Hence, five statistical classifiers have been chosen arbitrarily to produce the observation probabilities for Belief-Based Sequential Recognition: \u2022 SVM 3 with cubic kernel \u2022 SVM with RBF-kernel", "labels": [], "entities": [{"text": "Sequential Recognition", "start_pos": 123, "end_pos": 145, "type": "TASK", "confidence": 0.7432423830032349}]}], "tableCaptions": [{"text": " Table 1: Results (UAR, Cohen's Kappa, and Spearman's  Rho) of 10-fold cross-validation for US recognition of US  recognition using models trained on US  Classifier  UAR  \u03ba  \u03c1  SVM (cubic Kernel)  0.39 0.33 0.48  SVM (RBF-Kernel)  0.39 0.42 0.55  Naive Bayes  0.36 0.40 0.55  Naive Bayes (Kernel) 0.42 0.44 0.59  Rule Induction  0.50 0.51 0.61", "labels": [], "entities": [{"text": "UAR", "start_pos": 19, "end_pos": 22, "type": "DATASET", "confidence": 0.6792522668838501}, {"text": "US recognition of US  recognition", "start_pos": 92, "end_pos": 125, "type": "TASK", "confidence": 0.7024277329444886}, {"text": "US  Classifier  UAR  \u03ba  \u03c1  SVM", "start_pos": 150, "end_pos": 180, "type": "DATASET", "confidence": 0.7995675404866537}, {"text": "Rule Induction  0.50 0.51 0.61", "start_pos": 313, "end_pos": 343, "type": "METRIC", "confidence": 0.8745352149009704}]}, {"text": " Table 2: Results (UAR, Cohen's Kappa, and Spearman's  Rho) of 10-fold cross-validation for US recognition of the  Model Exchange approach (trained on IQ, evaluated on  US)  Classifier  UAR  \u03ba  \u03c1  SVM (cubic Kernel)  0.34 0.42 0.55  SVM (RBF-Kernel)  0.34 0.42 0.58  Naive Bayes  0.35 0.40 0.57  Naive Bayes (Kernel) 0.34 0.37 0.60  Rule Induction  0.34 0.42 0.59", "labels": [], "entities": [{"text": "US recognition", "start_pos": 92, "end_pos": 106, "type": "TASK", "confidence": 0.5918715596199036}]}, {"text": " Table 1.  Using the same feature set, these classification al- gorithms are also applied for the evaluation of the  Model Exchange approach using 10-fold cross val- idation. Note that the parameters of the classifiers  also remained the same. The data was partitioned  randomly on exchange level, i.e., without regarding  their belonging to a specific dialogue. The measured  results of the Model Exchange approach for the five  classification methods can be seen in", "labels": [], "entities": []}, {"text": " Table 3: Results (UAR, Cohen's Kappa, and Spearman's  Rho) of 10-fold cross-validation for US recognition of  action-independent Belief-Based Sequential Recognition  Classifier  UAR  \u03ba  \u03c1  SVM (cubic Kernel)  0.28 0.36 0.48  SVM (RBF-Kernel)  0.30 0.40 0.54  Naive Bayes  0.32 0.39 0.54  Naive Bayes (Kernel) 0.33 0.45 0.61  Rule Induction  0.33 0.47 0.63", "labels": [], "entities": []}, {"text": " Table 4: Results (UAR, Cohen's Kappa, and Spearman's  Rho) of 10-fold cross-validation for US recognition of  action-dependent Belief-Based Sequential Recognition  Classifier  UAR  \u03ba  \u03c1  SVM (cubic Kernel)  0.28 0.35 0.48  SVM (RBF-Kernel)  0.29 0.40 0.54  Naive Bayes  0.32 0.40 0.55  Naive Bayes (Kernel) 0.34 0.44 0.60  Rule Induction  0.35 0.47 0.62", "labels": [], "entities": []}, {"text": " Table 5: Recognition performance and variance of confi- dence distributions for IQ recognition  Classifier  \u03c3 2  UAR  \u03ba  \u03c1  SVM (cubic Kernel) 0.03 0.38 0.54 0.69  SVM (RBF-Kernel)  0.05 0.48 0.65 0.77  Naive Bayes  0.13 0.49 0.57 0.71  Naive Bayes (Kernel) 0.12 0.52 0.59 0.73  Rule Induction  0.13 0.55 0.68 0.79", "labels": [], "entities": [{"text": "IQ recognition", "start_pos": 81, "end_pos": 95, "type": "TASK", "confidence": 0.9695949554443359}, {"text": "UAR", "start_pos": 114, "end_pos": 117, "type": "METRIC", "confidence": 0.9803446531295776}]}]}