{"title": [{"text": "Generating Expressions that Refer to Visible Objects", "labels": [], "entities": [{"text": "Generating Expressions that Refer to Visible Objects", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.7044503050191062}]}], "abstractContent": [{"text": "We introduce a novel algorithm for generating referring expressions, informed by human and computer vision and designed to refer to visible objects.", "labels": [], "entities": []}, {"text": "Our method separates absolute properties like color from relative properties like size to stochastically generate a diverse set of outputs.", "labels": [], "entities": []}, {"text": "Expressions generated using this method are often overspecified and maybe underspecified, akin to expressions produced by people.", "labels": [], "entities": []}, {"text": "We call such expressions identifying descriptions.", "labels": [], "entities": []}, {"text": "The algorithm out-performs the well-known Incremental Algorithm (Dale and Reiter, 1995) and the Graph-Based Algorithm (Krahmer et al., 2003; Vi-ethen et al., 2008) across a variety of images in two domains.", "labels": [], "entities": []}, {"text": "We additionally motivate an evaluation method for referring expression generation that takes the proposed algorithm's non-determinism into account.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 50, "end_pos": 81, "type": "TASK", "confidence": 0.6430759032567342}]}], "introductionContent": [{"text": "Referring expression generation (REG) is the task of generating an expression that can identify a referent to a listener.", "labels": [], "entities": [{"text": "Referring expression generation (REG)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.9205543498198191}]}, {"text": "These expressions generally take the form of a definite noun phrase such as \"the large orange plate\" or \"the furry running dog\".", "labels": [], "entities": []}, {"text": "Research in REG primarily focuses on the subtask of selecting a set of properties that maybe used to construct the final surface expression, e.g., color:orange, size:large, type:plate.", "labels": [], "entities": [{"text": "REG", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9416216611862183}]}, {"text": "This property selection task is optimized to meet different goals: for example, to be identical to those a person would generate in the same situation, or to be unique to the intended referent and no other item in the discourse.", "labels": [], "entities": []}, {"text": "We focus on the task of generating referring expressions for visible objects, specifically with the goal of generating descriptive, human-like referring expressions.", "labels": [], "entities": []}, {"text": "We are motivated by the desire to connect this algorithm to input from a computer vision system, and discuss how this may work throughout the paper.", "labels": [], "entities": []}, {"text": "Computer vision does not yet reliably provide features for some of the most frequent properties that people use in visual description (in particular, size-based features), and so we use a gold-standard visual input, evaluating purely on REG.", "labels": [], "entities": []}, {"text": "The proposed algorithm, which we call the Visible Objects Algorithm, is designed to approximate human variation identifying an object in a group of visible, real world objects.", "labels": [], "entities": [{"text": "human variation identifying an object in a group of visible, real world objects", "start_pos": 96, "end_pos": 175, "type": "TASK", "confidence": 0.7073404001338142}]}, {"text": "Our primary contributions are the following.", "labels": [], "entities": []}, {"text": "Background for each issue is provided in Section 2: 1.", "labels": [], "entities": []}, {"text": "An approach accounting for overspecification, underspecification, and some of the known effects of vision on reference.", "labels": [], "entities": []}, {"text": "2. A function to approximate the stochastic nature of reference.", "labels": [], "entities": []}, {"text": "This reflects that people will produce different references to the same object.", "labels": [], "entities": []}, {"text": "3. A separation between absolute properties like color, which maybe detected directly by CV, from relative properties like size and location, which require reasoning over visual features to determine an appropriate form (e.g., height/width and distance features between pixels are available from a visual input; saying an object is \"tall\" requires further reasoning).", "labels": [], "entities": []}, {"text": "4. An evaluation method for non-deterministic REG that aligns generated and observed data and calculates accuracy over alignments.", "labels": [], "entities": [{"text": "REG", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9275854825973511}, {"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9989055395126343}]}], "datasetContent": [{"text": "Previous evaluation of REG algorithms have used measurements such as Uniqueness, Minimality, Dice , and Accuracy (.", "labels": [], "entities": [{"text": "REG", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.939304769039154}, {"text": "Minimality", "start_pos": 81, "end_pos": 91, "type": "METRIC", "confidence": 0.8562045097351074}, {"text": "Dice", "start_pos": 93, "end_pos": 97, "type": "METRIC", "confidence": 0.8835932612419128}, {"text": "Accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9944764971733093}]}, {"text": "Uniqueness is the proportion of outputs that identify the referent uniquely, and Minimality is the proportion of outputs that are both minimal and unique.", "labels": [], "entities": [{"text": "Minimality", "start_pos": 81, "end_pos": 91, "type": "METRIC", "confidence": 0.9821422696113586}]}, {"text": "As our goal is to mimic human reference, these metrics are not as useful for the evaluations as the others.", "labels": [], "entities": []}, {"text": "The Dice metric provides a value for the similarity between a generated description and a humanproduced description, and therefore serves as a reasonable objective measure for how human-like the produced sets are.", "labels": [], "entities": []}, {"text": "Given the generated property set (D S ) and the human-produced property set (D H ), Dice is calculated as: For each input domain, we evaluate over boolean values (included or excluded) for the attributes D (see).", "labels": [], "entities": []}, {"text": "Note that this means the specific values for the attributes are not compared.", "labels": [], "entities": []}, {"text": "In this formulation based on boolean values, |D S |=|D H |=|D| and Dice reduces to: Calculating Dice over the same number of attributes for both the observed and generated data has the nice mathematical property of making Dice equal to other common metrics for evaluating a model, including Accuracy, Precision, and Recall.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 291, "end_pos": 299, "type": "METRIC", "confidence": 0.9984158277511597}, {"text": "Precision", "start_pos": 301, "end_pos": 310, "type": "METRIC", "confidence": 0.9945185780525208}, {"text": "Recall", "start_pos": 316, "end_pos": 322, "type": "METRIC", "confidence": 0.9872564077377319}]}, {"text": "Since the proposed algorithm is stochastic, this introduces a problem in using a metric that compares single expressions.", "labels": [], "entities": []}, {"text": "We therefore seek to find the best alignment between the set of expressions produced by the algorithm and the set of expressions produced by people.", "labels": [], "entities": []}, {"text": "We formulate this alignment as an assignment problem weighted by Dice.", "labels": [], "entities": []}, {"text": "For the corpus of observed property sets H and the corpus of generated property sets S, we find the best align-Example Corresponding Evaluated Expression Property Set Property Set the red ball color:red, type:ball type:1 color:1 size:0 loc:0 with D={type, color, size, and location}.", "labels": [], "entities": []}, {"text": "ment x out of all possible alignments X between the corpora: arg max x\u2208X This maybe solved in polynomial time using the Hungarian method.", "labels": [], "entities": []}, {"text": "Note that because IA and GB are deterministic, finding an optimal alignment is trivial.", "labels": [], "entities": []}, {"text": "We call this method ALIGNED DICE.", "labels": [], "entities": [{"text": "ALIGNED DICE", "start_pos": 20, "end_pos": 32, "type": "METRIC", "confidence": 0.8035145998001099}]}, {"text": "It is an open question whether an alignment-based evaluation is fair: the proposed algorithm has more than one chance to match the human descriptions.", "labels": [], "entities": []}, {"text": "In the second evaluation method (MAJORITY) we address this issue, comparing how often the most frequent generated set compares with the most frequent observed set.", "labels": [], "entities": []}, {"text": "We run the proposed algorithm 1,000 times, and the generated property sets are ordered by frequency.", "labels": [], "entities": []}, {"text": "The most frequent generated set is compared against the most frequent humanproduced set.", "labels": [], "entities": []}, {"text": "The majority score is the percentage of folds where these two sets match.", "labels": [], "entities": [{"text": "folds", "start_pos": 40, "end_pos": 45, "type": "METRIC", "confidence": 0.8180571794509888}]}, {"text": "For IA and FB, the most frequent generated set is the only generated set.", "labels": [], "entities": []}, {"text": "This is a simple way to fairly compare the output of deterministic and non-deterministic algorithms.", "labels": [], "entities": []}, {"text": "There are no ties in the generated sets, but in the case of a tie in the observed data, we count a match if any match the most frequent generated set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: GRE3D3: Results (in %).", "labels": [], "entities": [{"text": "GRE3D3", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.540110170841217}]}, {"text": " Table 3: TUNA: Results (in %).", "labels": [], "entities": [{"text": "TUNA", "start_pos": 10, "end_pos": 14, "type": "DATASET", "confidence": 0.4067224860191345}]}]}