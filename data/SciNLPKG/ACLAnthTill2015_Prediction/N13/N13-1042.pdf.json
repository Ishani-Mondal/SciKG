{"title": [{"text": "Focused training sets to reduce noise in NER feature models", "labels": [], "entities": []}], "abstractContent": [{"text": "Feature and context aggregation play a large role in current NER systems, allowing significant opportunities for research into optimizing these features to cater to different domains.", "labels": [], "entities": [{"text": "Feature and context aggregation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.5717040002346039}]}, {"text": "This work strives to reduce the noise introduced into aggregated features from dis-parate and generic training data in order to allow for contextual features that more closely model the entities in the target data.", "labels": [], "entities": []}, {"text": "The proposed approach trains models based on only apart of the training set that is more similar to the target domain.", "labels": [], "entities": []}, {"text": "To this end, models are trained for an existing NER system using the top documents from the training set that are similar to the target document in order to demonstrate that this technique can be applied to improve any pre-built NER system.", "labels": [], "entities": []}, {"text": "Initial results show an improvement over the University of Illinois NE tagger with a weighted average F1 score of 91.67 compared to the Illinois tagger's score of 91.32.", "labels": [], "entities": [{"text": "University of Illinois NE tagger", "start_pos": 45, "end_pos": 77, "type": "DATASET", "confidence": 0.618958193063736}, {"text": "F1 score", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9701663553714752}]}, {"text": "This research serves as a proof-of-concept for future planned work to cluster the training documents to produce a number of more focused models from a given training set, thereby reducing noise and extracting a more representative feature set.", "labels": [], "entities": []}], "introductionContent": [{"text": "Though research in the area of named entity recognition (NER) is fairly extensive, current stateof-the-art solutions are generic, succeeding only for domains similar to their training data, and still fail to adequately provide functionality that is adaptable to abroad range of domains (.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 31, "end_pos": 61, "type": "TASK", "confidence": 0.7974411050478617}]}, {"text": "This leaves room for improvement in designing a system that can more easily adapt to previously unseen data.", "labels": [], "entities": []}, {"text": "In particular, the increasingly popular feature set produced by feature and context aggregation provides many opportunities for different types of optimization given the strong correlation between the training input and the feature values that are produced.", "labels": [], "entities": []}, {"text": "This is due to the fact that aggregation looks at features at a document or corpus level, rather than at the token level, and therefore will be sensitive to changes in the training set.", "labels": [], "entities": []}, {"text": "This research looks to exploit this aspect of feature and context aggregation by identifying portions of a training set that are more similar to the target data and will thus provide feature values that are likely more representative of the entities within that data.", "labels": [], "entities": [{"text": "feature and context aggregation", "start_pos": 46, "end_pos": 77, "type": "TASK", "confidence": 0.6629614904522896}]}, {"text": "Rather than train a model with a full training set, this approach extracts portions of the training data that are most similar to the target data and trains a model using only those documents.", "labels": [], "entities": []}, {"text": "This initial work tailors a model to a given target document to demonstrate that less, but more appropriate, training data is preferable to a full generic training set.", "labels": [], "entities": []}, {"text": "Similar to that of, in which they use passage retrieval to expand their feature set, cosine similarity is used to retrieve documents containing similar entity instances in an effort to achieve a more relevant feature set that will result in more likely output label predictions.", "labels": [], "entities": []}, {"text": "However, the proposed approach conducts document similarity above the tagger level, without modifying the underlying tagging system.", "labels": [], "entities": []}, {"text": "This allows for domain adaptation improvements using any available NER tagger.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.8080537021160126}]}, {"text": "This approach is able to be implemented with any pre-existing NER tagger in order to improve the performance of the tagger for out-ofdomain data.", "labels": [], "entities": [{"text": "NER tagger", "start_pos": 62, "end_pos": 72, "type": "TASK", "confidence": 0.6890097558498383}]}, {"text": "Initial results show an improvement over the standard NE tagger from the University of Illinois at Urbana-Champaign using a smaller training set and no additional external data sources.", "labels": [], "entities": [{"text": "NE tagger", "start_pos": 54, "end_pos": 63, "type": "TASK", "confidence": 0.8525887131690979}]}], "datasetContent": [], "tableCaptions": []}