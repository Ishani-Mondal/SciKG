{"title": [{"text": "Automatic Morphological Enrichment of a Morphologically Underspecified Treebank", "labels": [], "entities": [{"text": "Morphological Enrichment", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.7398233711719513}]}], "abstractContent": [{"text": "In this paper, we study the problem of automatic enrichment of a morphologically under-specified treebank for Arabic, a morphologically rich language.", "labels": [], "entities": []}, {"text": "We show that we can map from a tagset of size six to one with 485 tags at an accuracy rate of 94%-95%.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 77, "end_pos": 90, "type": "METRIC", "confidence": 0.9786009192466736}]}, {"text": "We can also identify the unspecified lemmas in the treebank with an accuracy over 97%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9994194507598877}]}, {"text": "Furthermore , we demonstrate that using our automatic annotations improves the performance of a state-of-the-art Arabic morphological tag-ger.", "labels": [], "entities": []}, {"text": "Our approach combines a variety of techniques from corpus-based statistical models to linguistic rules that target specific phenomena.", "labels": [], "entities": []}, {"text": "These results suggest that the cost of treebank-ing can be reduced by designing underspec-ified treebanks that can be subsequently enriched automatically.", "labels": [], "entities": []}], "introductionContent": [{"text": "Collections of manually-annotated morphological and syntactic analyses of sentences, or treebanks, are an important resource for building statistical parsing models or for syntax-aware approaches to applications such as machine translation.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 138, "end_pos": 157, "type": "TASK", "confidence": 0.698642909526825}, {"text": "machine translation", "start_pos": 220, "end_pos": 239, "type": "TASK", "confidence": 0.8192661106586456}]}, {"text": "Rich treebank annotations have also been used fora variety of natural language processing (NLP) applications such as tokenization, diacritization, part-of-speech (POS) tagging, morphological disambiguation, base phrase chunking, and semantic role labeling.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 117, "end_pos": 129, "type": "TASK", "confidence": 0.9664902687072754}, {"text": "part-of-speech (POS) tagging", "start_pos": 147, "end_pos": 175, "type": "TASK", "confidence": 0.6244624376296997}, {"text": "base phrase chunking", "start_pos": 207, "end_pos": 227, "type": "TASK", "confidence": 0.6472877860069275}, {"text": "semantic role labeling", "start_pos": 233, "end_pos": 255, "type": "TASK", "confidence": 0.6631011863549551}]}, {"text": "The development of a treebank with rich annotations is demanding in time and money, especially for morphologically complex languages.", "labels": [], "entities": []}, {"text": "Consequently, the richer the annotation, the slower the annotation process and the smaller the size of the treebank.", "labels": [], "entities": []}, {"text": "As such, a tradeoff is usually made between the size of the treebank and the richness of its annotations.", "labels": [], "entities": []}, {"text": "In this paper, we investigate the possibility of automatically enriching the morphologically underspecified Columbia Arabic Treebank (CATiB) ) with the more complex POS tags and lemmas used in the Penn Arabic Treebank (PATB) ().", "labels": [], "entities": [{"text": "Columbia Arabic Treebank (CATiB)", "start_pos": 108, "end_pos": 140, "type": "DATASET", "confidence": 0.9421998163064321}, {"text": "Penn Arabic Treebank (PATB)", "start_pos": 197, "end_pos": 224, "type": "DATASET", "confidence": 0.972407470146815}]}, {"text": "We employ a variety of techniques that range from corpus-based statistical models to handwritten rules based on linguistic observations.", "labels": [], "entities": []}, {"text": "Our best method reaches accuracy rates of 94%-95% on full POS tag identification.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9995331764221191}, {"text": "POS tag identification", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.6714405218760172}]}, {"text": "We can also identify the unspecified lemmas in CATiB with an accuracy over 97%.", "labels": [], "entities": [{"text": "CATiB", "start_pos": 47, "end_pos": 52, "type": "DATASET", "confidence": 0.858478844165802}, {"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9993333220481873}]}, {"text": "37% of our POS tag errors are due to gold tree or gold POS errors.", "labels": [], "entities": []}, {"text": "A learning curve experiment to evaluate the dependence of our method on annotated data shows that while the quality of some components may reduce sharply with less data (12% absolute reduction inaccuracy when using 32 of the data or some 10K annotated words), the overall effect is a lot smaller (2% absolute drop).", "labels": [], "entities": []}, {"text": "These results suggest that the cost of treebanking can be reduced by designing underspecified treebanks that can be subsequently enriched automatically.", "labels": [], "entities": []}, {"text": "The rest of this paper is structured as follows: Section 2 presents related work; Section 3 details various language background facts about Arabic and its treebanking; Section 4 explains our approach; and Section 5 presents and discusses our results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use a CATiB version of the PATB part 3v3.1 and part 2v3.0 released by the Linguistic Data Consortium (LDC) ().", "labels": [], "entities": [{"text": "PATB part 3v3.1", "start_pos": 30, "end_pos": 45, "type": "DATASET", "confidence": 0.7393738528092703}, {"text": "Linguistic Data Consortium (LDC)", "start_pos": 77, "end_pos": 109, "type": "DATASET", "confidence": 0.8017305185397466}]}, {"text": "We use the train/development/test (80/10/10) splits of for PATB part 3v3.1 (16.6K sentences; 400K tokens): we use their train as our training data, their development as the tuning data for TADA and their test as our development set.", "labels": [], "entities": [{"text": "PATB part 3v3.1", "start_pos": 59, "end_pos": 74, "type": "DATASET", "confidence": 0.8139558037122091}, {"text": "TADA", "start_pos": 189, "end_pos": 193, "type": "DATASET", "confidence": 0.6935972571372986}]}, {"text": "For our blind test, we use the first 1000 sentences in PATB part 2v3.0 (38K tokens).", "labels": [], "entities": [{"text": "PATB part 2v3.0", "start_pos": 55, "end_pos": 70, "type": "DATASET", "confidence": 0.9013428489367167}]}, {"text": "We report all results in terms of token accuracy on the full Buckwalter tag, reduced Buckwalter tag and the lemma.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.985345721244812}, {"text": "Buckwalter tag", "start_pos": 61, "end_pos": 75, "type": "DATASET", "confidence": 0.9218488931655884}, {"text": "Buckwalter tag", "start_pos": 85, "end_pos": 99, "type": "DATASET", "confidence": 0.7806011438369751}]}, {"text": "The reduced Buckwalter tag is the Buckwalter tag without case, state, and mood.", "labels": [], "entities": []}, {"text": "The number of tags is reduced to 220 tags (compared to 485 tags for the full Buckwalter tagset).", "labels": [], "entities": [{"text": "Buckwalter tagset", "start_pos": 77, "end_pos": 94, "type": "DATASET", "confidence": 0.9750470817089081}]}, {"text": "In cases of gold full Buckwalter tags that are underspecified for case, state or mood, we do not penalize our systems if our more specific predicted  tag otherwise matches the gold tag.", "labels": [], "entities": []}, {"text": "Words whose lemmas are unknown (nolemma, TBupdate) or has the lemma DEFAULT (including digits and punctuation) are excluded from the evaluation, but not training: in the development set, 4,498 out of 25,446 words were excluded (\u223c18%).", "labels": [], "entities": [{"text": "TBupdate", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.872722864151001}, {"text": "DEFAULT", "start_pos": 68, "end_pos": 75, "type": "METRIC", "confidence": 0.9935944676399231}]}, {"text": "shows the results of our experiments on the development set.", "labels": [], "entities": []}, {"text": "Considering the baseline systems, we see that using both the CATiB POS tag and the word form in MLE Baseline 2 gives us a 20.5% absolute increase above MLE Baseline 1.", "labels": [], "entities": [{"text": "CATiB POS tag", "start_pos": 61, "end_pos": 74, "type": "DATASET", "confidence": 0.7265058159828186}]}, {"text": "Using TADA improves the performance significantly (adding 8.46% absolute over MLE Baseline 2).", "labels": [], "entities": [{"text": "TADA", "start_pos": 6, "end_pos": 10, "type": "METRIC", "confidence": 0.863572895526886}]}, {"text": "Every additional morphological filter has a positive impact and the improvement of the accuracy for full Buckwalter with each new filter ranged between 0.22% and 1.18% absolute except for the case filter, which adds almost 5%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9995973706245422}, {"text": "Buckwalter", "start_pos": 105, "end_pos": 115, "type": "DATASET", "confidence": 0.9177106022834778}]}, {"text": "Adding the MLE override has a positive impact on the accuracy of the full and reduced Buckwalter tags and the lemma.", "labels": [], "entities": [{"text": "MLE", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.8182178139686584}, {"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9995238780975342}, {"text": "Buckwalter tags", "start_pos": 86, "end_pos": 101, "type": "DATASET", "confidence": 0.8880516290664673}]}, {"text": "We applied our automatic enrichment to the underspecified CATiB treebank (as opposed to the parts of PATB, which we used throughout the paper to simulate CATiB).", "labels": [], "entities": [{"text": "CATiB treebank", "start_pos": 58, "end_pos": 72, "type": "DATASET", "confidence": 0.9149715006351471}]}, {"text": "We evaluate the added value of these annotations by using them to extend the training data for the morphological tagger MADA), which is used on untokenized text.", "labels": [], "entities": [{"text": "morphological tagger MADA", "start_pos": 99, "end_pos": 124, "type": "TASK", "confidence": 0.61068328221639}]}, {"text": "We train anew set of MADA classifier models using a combination of the original MADA (v 3.2) training data (578K words taken from PATBs 1, 2 and 3) and the enriched CATiB data (218K words).", "labels": [], "entities": [{"text": "MADA classifier", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.8301112651824951}, {"text": "MADA (v 3.2) training data", "start_pos": 80, "end_pos": 106, "type": "DATASET", "confidence": 0.8296425342559814}, {"text": "CATiB data", "start_pos": 165, "end_pos": 175, "type": "DATASET", "confidence": 0.7960264086723328}]}, {"text": "We apply the new MADA system to our development set and evaluate on several metrics.", "labels": [], "entities": []}, {"text": "As a baseline, we process the same development set using MADA (v 3.2).", "labels": [], "entities": [{"text": "MADA", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.7562836408615112}]}, {"text": "Other than the training data used to construct the classifier models, there are no differences between the two systems.", "labels": [], "entities": []}, {"text": "The CATiB-enriched system results in a Buckwalter POS tag accuracy of 85.6% (a 2.2% error reduction over the baseline).", "labels": [], "entities": [{"text": "Buckwalter POS tag", "start_pos": 39, "end_pos": 57, "type": "DATASET", "confidence": 0.5556316177050272}, {"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.5714895129203796}]}, {"text": "When evaluating on the set of 14 MADA morphological features, the new system results in a 85.7% accuracy (2.4% error reduction).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9985911250114441}, {"text": "error reduction", "start_pos": 111, "end_pos": 126, "type": "METRIC", "confidence": 0.9625628292560577}]}, {"text": "The new system also improves PATB segmentation accuracy (99.2%, a 5.4% error reduction).", "labels": [], "entities": [{"text": "PATB segmentation", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.7166932225227356}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9773310422897339}, {"text": "error reduction", "start_pos": 71, "end_pos": 86, "type": "METRIC", "confidence": 0.9748069643974304}]}, {"text": "In the future, we will evaluate the contribution of the additional annotations in the context of other applications, such as syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 125, "end_pos": 142, "type": "TASK", "confidence": 0.7887192964553833}]}], "tableCaptions": [{"text": " Table 1: Accuracy of enriching CATiB trees with Buck- walter (BW) tags and lemmas on the development set.  Reduced Buckwalter is similar to Buckwalter, but ignores  case, mood and state. The Difference between the two  metrics highlights the errors from case, mood and state.", "labels": [], "entities": [{"text": "Difference", "start_pos": 192, "end_pos": 202, "type": "METRIC", "confidence": 0.9810978174209595}]}, {"text": " Table 2: Accuracy of enriching CATiB trees with Buck- walter (BW) tags and lemmas on the blind test set.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9876464605331421}]}, {"text": " Table 3: Accuracy of enriching CATiB trees with Buck- walter (BW) tags and lemmas using TADA only for dif- ferent training sizes on the development set.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9782049059867859}, {"text": "TADA", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.9224559664726257}]}, {"text": " Table 4: Accuracy of enriching CATiB trees with Buck- walter (BW) tags and lemmas using our best performing  system for different training sizes on the development set.", "labels": [], "entities": []}]}