{"title": [{"text": "Relation Extraction with Matrix Factorization and Universal Schemas", "labels": [], "entities": [{"text": "Relation Extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9821643829345703}]}], "abstractContent": [{"text": "Traditional relation extraction predicts relations within some fixed and finite target schema.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.7814796566963196}]}, {"text": "Machine learning approaches to this task require either manual annotation or, in the case of distant supervision, existing struc-tured sources of the same schema.", "labels": [], "entities": []}, {"text": "The need for existing datasets can be avoided by using a universal schema: the union of all involved schemas (surface form predicates as in OpenIE, and relations in the schemas of pre-existing databases).", "labels": [], "entities": []}, {"text": "This schema has an almost unlimited set of relations (due to surface forms), and supports integration with existing structured data (through the relation types of existing databases).", "labels": [], "entities": []}, {"text": "To populate a database of such schema we present matrix factorization models that learn latent feature vectors for entity tuples and relations.", "labels": [], "entities": []}, {"text": "We show that such latent models achieve substantially higher accuracy than a traditional classification approach.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9985989928245544}]}, {"text": "More importantly, by operating simultaneously on relations observed in text and in pre-existing structured DBs such as Freebase, we are able to reason about unstructured and structured data in mutually-supporting ways.", "labels": [], "entities": []}, {"text": "By doing so our approach outperforms state-of-the-art distant supervision.", "labels": [], "entities": []}], "introductionContent": [{"text": "Most previous work in relation extraction uses a predefined, finite and fixed schema of relation types (such as born-in or employed-by).", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.9245698750019073}]}, {"text": "Usually some textual data is labeled according to this schema, and this labeling is then used in supervised training of an automated relation extractor, e.g..", "labels": [], "entities": [{"text": "relation extractor", "start_pos": 133, "end_pos": 151, "type": "TASK", "confidence": 0.6975124478340149}]}, {"text": "However, labeling textual relations is time-consuming and difficult, leading to significant recent interest in distantly-supervised learning.", "labels": [], "entities": [{"text": "labeling textual relations", "start_pos": 9, "end_pos": 35, "type": "TASK", "confidence": 0.878213107585907}]}, {"text": "Here one aligns existing database records with the sentences in which these records have been \"rendered\"--effectively labeling the text-and from this labeling we can train a machine learning system as before.", "labels": [], "entities": []}, {"text": "However, this method relies on the availability of a large database that has the desired schema.", "labels": [], "entities": []}, {"text": "The need for pre-existing datasets can be avoided by using language itself as the source of the schema.", "labels": [], "entities": []}, {"text": "This is the approach taken by.", "labels": [], "entities": []}, {"text": "Here surface patterns between mentions of concepts serve as relations.", "labels": [], "entities": []}, {"text": "This approach requires no supervision and has tremendous flexibility, but lacks the ability to generalize.", "labels": [], "entities": []}, {"text": "For example, OpenIE may find FERGUSON-historian-at-HARVARD but does not know FERGUSON-is-a-professor-at-HARVARD.", "labels": [], "entities": [{"text": "OpenIE", "start_pos": 13, "end_pos": 19, "type": "DATASET", "confidence": 0.9172818660736084}, {"text": "FERGUSON-historian-at-HARVARD", "start_pos": 29, "end_pos": 58, "type": "METRIC", "confidence": 0.7716302871704102}]}, {"text": "OpenIE has traditionally relied on a large diversity of textual expressions to provide good coverage.", "labels": [], "entities": [{"text": "OpenIE", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8606842160224915}]}, {"text": "But this diversity is not always available, and, in any case, the lack of generalization greatly inhibits the ability to support reasoning.", "labels": [], "entities": []}, {"text": "One way to gain generalization is to cluster textual surface forms that have similar meaning).", "labels": [], "entities": []}, {"text": "While the clusters discovered by all these methods usually contain semantically related items, closer inspection invariably shows that they do not provide reliable implicature.", "labels": [], "entities": []}, {"text": "For example, atypical representative cluster may include historian-at, professor-at, scientistat, worked-at.", "labels": [], "entities": []}, {"text": "Although these relation types are indeed semantically related, note that scientist-at does not necessarily imply professor-at, and worked-at certainly does not imply scientist-at.", "labels": [], "entities": []}, {"text": "In fact, we contend that any relational schema would inherently be brittle and ill-defined--having ambiguities, problematic boundary cases, and incompleteness.", "labels": [], "entities": []}, {"text": "For example, Freebase, in spite of its extensive effort towards high coverage, has no critized nor scientist-at relation.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 13, "end_pos": 21, "type": "DATASET", "confidence": 0.968176543712616}]}, {"text": "In response to this problem, we present anew approach: implicature with universal schemas.", "labels": [], "entities": []}, {"text": "Here we embrace the diversity and ambiguity of original inputs; we avoid forcing textual meaning into predefined boxes.", "labels": [], "entities": []}, {"text": "This is accomplished by defining our schema to be the union of all source schemas: original input forms, e.g. variants of surface patterns similarly to OpenIE, as well as relations in the schemas of many available pre-existing structured databases.", "labels": [], "entities": []}, {"text": "But then, unlike OpenIE, our focus lies on learning asymmetric implicature among relations.", "labels": [], "entities": [{"text": "OpenIE", "start_pos": 17, "end_pos": 23, "type": "DATASET", "confidence": 0.8961811661720276}]}, {"text": "This allows us to probabilistically \"fill in\" inferred unobserved entity-entity relations in this union.", "labels": [], "entities": []}, {"text": "For example, after observing FERGU-SON-historian-at-HARVARD our system infers that FERGUSON-professor-at-HARVARD, but not vice versa.", "labels": [], "entities": [{"text": "FERGU-SON-historian-at-HARVARD", "start_pos": 29, "end_pos": 59, "type": "METRIC", "confidence": 0.6493899822235107}, {"text": "FERGUSON-professor-at-HARVARD", "start_pos": 83, "end_pos": 112, "type": "METRIC", "confidence": 0.7170222401618958}]}, {"text": "At the heart of our approach is the hypothesis that we should concentrate on predicting source data--a relatively well defined task that can be evaluated and optimized--as opposed to modeling semantic equivalence, which we believe will always be illusive.", "labels": [], "entities": []}, {"text": "Note that by operating simultaneously on relations observed in text and in pre-existing structured databases such as Freebase, we are able to reason about unstructured and structured data in mutuallysupporting ways.", "labels": [], "entities": []}, {"text": "For example, we can predict surface pattern relations that effectively serve as additional features when predicting Freebase relations, hence improving generalization.", "labels": [], "entities": []}, {"text": "Also notice that users of our system will not have to study and understand the complexities of a particular schema in order to issue queries; they can ask in whatever form naturally occurs to them, and our system will likely already have that relation in our universal schema.", "labels": [], "entities": []}, {"text": "Our technical approach is based on extensions to probabilistic models of matrix factorization and collaborative filtering ().", "labels": [], "entities": []}, {"text": "We represent the probabilistic knowledge base as a matrix with entityentity pairs in the rows and relations in the columns (see).", "labels": [], "entities": []}, {"text": "The rows come from running crossdocument entity resolution across pre-existing structured databases and textual corpora.", "labels": [], "entities": [{"text": "crossdocument entity resolution", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.6419126292069753}]}, {"text": "The columns come from the union of surface forms and DB relations.", "labels": [], "entities": []}, {"text": "We present a series of models that learn lower dimensional manifolds for tuples, relations and entities, and a set of weights that capture direct correlations between relations.", "labels": [], "entities": []}, {"text": "Weights and lower dimensional representations act, through dot products, as the natural parameters of a single log-linear model to derive per-cell probabilities.", "labels": [], "entities": []}, {"text": "In experiments we show that our models can accurately predict surface patterns relationships which do not appear explicitly in text, and that learning latent representations of entities, tuples and relations substantially improves results over a traditional classifier approach.", "labels": [], "entities": []}, {"text": "Moreover, we can improve accuracy by simultaneously operating on relations observed in the New York Times corpus and in Freebase.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9987308382987976}, {"text": "New York Times corpus", "start_pos": 91, "end_pos": 112, "type": "DATASET", "confidence": 0.82463039457798}]}, {"text": "In particular, our model outperforms the current state-of-the-art distant supervision method (Surdeanu et al., 2012) by 10% points Mean Average Precision through joint implicature among surface patterns and Freebase relations.", "labels": [], "entities": [{"text": "Precision", "start_pos": 144, "end_pos": 153, "type": "METRIC", "confidence": 0.891350269317627}]}], "datasetContent": [{"text": "How accurately can we fill a database of Universal Schema, and does reasoning jointly across a universal schema help to improve over more isolated approaches?", "labels": [], "entities": []}, {"text": "In the following we seek to answer this question empirically.", "labels": [], "entities": []}, {"text": "To this end we train our models on observed facts in a newswire corpus and Freebase, and then manually evaluate ranked predictions: first for structured relations and then for surface form relations.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 75, "end_pos": 83, "type": "DATASET", "confidence": 0.9206249117851257}]}, {"text": "For evaluation we use collections of relations: surface patterns in one experiment and Freebase relations in the other.", "labels": [], "entities": []}, {"text": "In either case we compare the competing systems with respect to their ranked results for each relation in the collection.", "labels": [], "entities": []}, {"text": "Given this ranking task, our evaluation is inspired by the TREC competitions and work in information retrieval (.", "labels": [], "entities": [{"text": "TREC", "start_pos": 59, "end_pos": 63, "type": "DATASET", "confidence": 0.6416930556297302}, {"text": "information retrieval", "start_pos": 89, "end_pos": 110, "type": "TASK", "confidence": 0.7931342720985413}]}, {"text": "That is, we treat each relation as query and receive the top 1000 (run depth) entity pairs from each system.", "labels": [], "entities": []}, {"text": "Then we pool the top 100 (pool depth) answers from each system and manually judge their relevance or \"truth.\"", "labels": [], "entities": []}, {"text": "This gives a set of relevant results that we can use to calculate recall and precision measures.", "labels": [], "entities": [{"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9983586668968201}, {"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9977068901062012}]}, {"text": "In particular, we can use these annotations to measure an average precision across the precision-recall curve, and an aggregate mean average precision (MAP) across all relations.", "labels": [], "entities": [{"text": "precision", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.7724929451942444}, {"text": "precision-recall", "start_pos": 87, "end_pos": 103, "type": "METRIC", "confidence": 0.9897947907447815}, {"text": "aggregate mean average precision (MAP)", "start_pos": 118, "end_pos": 156, "type": "METRIC", "confidence": 0.8711423533303397}]}, {"text": "This metric has shown to be very robust and stable).", "labels": [], "entities": []}, {"text": "In addition we also present a weighted version of MAP (weighted MAP) in which the average precision for each re-  lation is weighted by the relation's number of true facts.", "labels": [], "entities": [{"text": "precision", "start_pos": 90, "end_pos": 99, "type": "METRIC", "confidence": 0.9848885536193848}]}, {"text": "Notice that we deviate from previous work in distant supervision that (a) combines the results from several relations in a single precision recall curve, and (b) uses held-out evaluation to measure how well the predictions match existing Freebase facts.", "labels": [], "entities": [{"text": "precision recall curve", "start_pos": 130, "end_pos": 152, "type": "METRIC", "confidence": 0.8580194314320883}]}, {"text": "First, when aggregating across relations results are often dominated by a few very frequent relations, such as containedby, providing little information about how the models perform across the board.", "labels": [], "entities": []}, {"text": "Second, evaluating with Freebase held-out data is biased.", "labels": [], "entities": [{"text": "Freebase held-out data", "start_pos": 24, "end_pos": 46, "type": "DATASET", "confidence": 0.9357949296633402}]}, {"text": "For example, we find that frequently mentioned entity pairs are more likely to have relations in Freebase.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 97, "end_pos": 105, "type": "DATASET", "confidence": 0.960184633731842}]}, {"text": "Systems that rank such tuples higher receives higher precision than those that do not have such bias, regardless of how correct their predictions are.", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9980461597442627}]}, {"text": "Third, we can aggregate per-relation comparisons to establish statistical significance, for example via the sign test.", "labels": [], "entities": []}, {"text": "Also note that while we run our models on the complete training and test set, evaluation is restricted to the subsampled test set.", "labels": [], "entities": []}, {"text": "shows our results for Freebase relations, omitting those for which none of the systems can find any relevant facts.", "labels": [], "entities": []}, {"text": "Our first baseline is MI09, a distantly supervised classifier based on the work of.", "labels": [], "entities": [{"text": "MI09", "start_pos": 22, "end_pos": 26, "type": "DATASET", "confidence": 0.5490606427192688}]}, {"text": "This classifier only learns from observed pattern-relation pairs in the training set (of which we only have about 8k).", "labels": [], "entities": []}, {"text": "By contrast, our latent feature models can learn pattern-pattern correlations both on the unlabeled training and test set (comparable to bootstrapping).", "labels": [], "entities": []}, {"text": "We hence also compare against YA11, aversion of MI09 that uses preprocessed cluster features according to.", "labels": [], "entities": [{"text": "MI09", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.9229247570037842}]}, {"text": "The third baseline is SU12, the state-of-theart Multi-Instance Multi-Label system by.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Average and (weighted) Mean Average Precisions for Freebase relations based on pooled results. The #  column shows the number of true facts in the pool. NFE is statistically different to all but NF and F according to the  sign test. Bold faced are winners per relation, italics indicate ties.", "labels": [], "entities": [{"text": "Average", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9757328033447266}, {"text": "Mean Average Precisions", "start_pos": 33, "end_pos": 56, "type": "METRIC", "confidence": 0.9304061730702718}]}, {"text": " Table 2: Average and (weighted) Mean Average Preci- sions for surface patterns. 2", "labels": [], "entities": [{"text": "Average", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9857287406921387}, {"text": "Mean Average Preci-", "start_pos": 33, "end_pos": 52, "type": "METRIC", "confidence": 0.9654959142208099}]}]}