{"title": [{"text": "Improved Reordering for Phrase-Based Translation using Sparse Features", "labels": [], "entities": [{"text": "Improved Reordering", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8425274789333344}, {"text": "Phrase-Based Translation", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.9252274930477142}]}], "abstractContent": [{"text": "There have been many recent investigations into methods to tune SMT systems using large numbers of sparse features.", "labels": [], "entities": [{"text": "SMT", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.8953365683555603}]}, {"text": "However, there have not been nearly so many examples of helpful sparse features, especially for phrase-based systems.", "labels": [], "entities": []}, {"text": "We use sparse features to address reordering, which is often considered a weak point of phrase-based translation.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 88, "end_pos": 112, "type": "TASK", "confidence": 0.7351826429367065}]}, {"text": "Using a hierarchical reordering model as our base-line, we show that simple features coupling phrase orientation to frequent words or word-clusters can improve translation quality, with boosts of up to 1.2 BLEU points in Chinese-English and 1.8 in Arabic-English.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 206, "end_pos": 210, "type": "METRIC", "confidence": 0.9989410042762756}]}, {"text": "We compare this solution to a more traditional maximum entropy approach, where a probability model with similar features is trained on word-aligned bitext.", "labels": [], "entities": []}, {"text": "We show that sparse decoder features outperform maximum entropy handily , indicating that there are major advantages to optimizing reordering features directly for BLEU with the decoder in the loop.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 164, "end_pos": 168, "type": "METRIC", "confidence": 0.9716284871101379}]}], "introductionContent": [{"text": "With the growing adoption of tuning algorithms that can handle thousands of features (), SMT system designers now face a choice when incorporating new ideas into their translation models.", "labels": [], "entities": [{"text": "SMT", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.9939562678337097}]}, {"text": "Maximum likelihood models can be estimated from large wordaligned bitexts, creating a small number of highly informative decoder features; or the same ideas can be incorporated into the decoder's linear model directly.", "labels": [], "entities": []}, {"text": "There are trade-offs to each approach.", "labels": [], "entities": []}, {"text": "Maximum likelihood models can be estimated from millions of sentences of bitext, but optimize a mismatched objective, predicting events observed in word aligned bitext instead of optimizing translation quality.", "labels": [], "entities": []}, {"text": "Sparse decoder features have the opposite problem; with the decoder in the loop, we can only tune on small development sets, 1 but a translation error metric directly informs training.", "labels": [], "entities": []}, {"text": "We investigate this trade-off in the context of reordering models for phrase-based decoding.", "labels": [], "entities": []}, {"text": "Starting with the intuition that most lexicalized reordering models do not smooth their orientation distributions intelligently for low-frequency phrase-pairs, we design features that track the first and last words (or clusters) of the phrases in a pair.", "labels": [], "entities": []}, {"text": "These features are incorporated into a maximum entropy reordering model, as well as sparse decoder features, to see which approach best complements the now-standard relative-frequency lexicalized reordering model.", "labels": [], "entities": []}, {"text": "We also view our work as an example of strong sparse features for phrase-based translation.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 66, "end_pos": 90, "type": "TASK", "confidence": 0.8008729517459869}]}, {"text": "Features from hierarchical and syntax-based translation () do not easily transfer to the phrase-based paradigm, and most work that has looked at large feature counts in the context of phrase-based translation has focused on the learning method, and not the features themselves).", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 184, "end_pos": 208, "type": "TASK", "confidence": 0.706958681344986}]}, {"text": "We show that by targeting reordering, large gains can be made with relatively simple features.", "labels": [], "entities": []}], "datasetContent": [{"text": "We  evaluation; the Arabic system is summarized in and the Chinese in.", "labels": [], "entities": []}, {"text": "The Arabic system's development set is the NIST mt06 test set, and its test sets are mt08 and mt09.", "labels": [], "entities": [{"text": "NIST mt06 test set", "start_pos": 43, "end_pos": 61, "type": "DATASET", "confidence": 0.952987477183342}]}, {"text": "The Chinese system's development set is taken from the NIST mt05 evaluation set, augmented with some material reserved from our NIST training corpora in order to better cover newsgroup and weblog domains.", "labels": [], "entities": [{"text": "NIST mt05 evaluation set", "start_pos": 55, "end_pos": 79, "type": "DATASET", "confidence": 0.9710594564676285}, {"text": "NIST training corpora", "start_pos": 128, "end_pos": 149, "type": "DATASET", "confidence": 0.9196938077608744}]}, {"text": "Its test sets are mt06 and mt08.", "labels": [], "entities": []}, {"text": "We report lower-cased BLEU (), evaluated using the same English tokenization used in training.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9980949759483337}]}, {"text": "For our primary results, we perform random replications of parameter tuning, as suggested by.", "labels": [], "entities": []}, {"text": "Each replication uses a different random seed to determine the order in which MIRA visits tuning sentences.", "labels": [], "entities": [{"text": "MIRA visits tuning sentences", "start_pos": 78, "end_pos": 106, "type": "TASK", "confidence": 0.7479757964611053}]}, {"text": "We test for significance using Clark et al.'s MultEval tool, which uses a stratified approximate randomization test to account for multiple replications.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Arabic-English Corpus. For English dev and test  sets, word counts are averaged across 4 references.", "labels": [], "entities": []}, {"text": " Table 5: Comparing reordering methods according to BLEU score. n indicates the number of tuning replications,  while standard deviations (std) indicate optimizer stability. Test scores that are significantly higher (p < 0.01) than  the HRM baseline are highlighted in bold.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.968885749578476}, {"text": "HRM baseline", "start_pos": 237, "end_pos": 249, "type": "DATASET", "confidence": 0.8257043659687042}]}, {"text": " Table 7: Arabic-English BLEU scores with each system's  original feature set versus the intersection of the two fea- ture sets, with and without the relative frequency HRM.  BLEU is averaged across mt08 and mt09.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9917860627174377}, {"text": "HRM", "start_pos": 169, "end_pos": 172, "type": "METRIC", "confidence": 0.6367889642715454}, {"text": "BLEU", "start_pos": 175, "end_pos": 179, "type": "METRIC", "confidence": 0.9990741014480591}]}, {"text": " Table 9: The effect of Sparse HRMs on complex systems.", "labels": [], "entities": []}]}