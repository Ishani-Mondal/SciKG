{"title": [{"text": "Combining Heterogeneous Models for Measuring Relational Similarity", "labels": [], "entities": [{"text": "Similarity", "start_pos": 56, "end_pos": 66, "type": "TASK", "confidence": 0.7988744974136353}]}], "abstractContent": [{"text": "In this work, we study the problem of measuring relational similarity between two word pairs (e.g., silverware:fork and clothing:shirt).", "labels": [], "entities": []}, {"text": "Due to the large number of possible relations, we argue that it is important to combine multiple models based on heterogeneous information sources.", "labels": [], "entities": []}, {"text": "Our overall system consists of two novel general-purpose relational similarity models and three specific word relation models.", "labels": [], "entities": []}, {"text": "When evaluated in the setting of a recently proposed SemEval-2012 task, our approach outperforms the previous best system substantially, achieving a 54.1% relative increase in Spearman's rank correlation.", "labels": [], "entities": [{"text": "SemEval-2012 task", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.7831183969974518}, {"text": "Spearman's rank correlation", "start_pos": 176, "end_pos": 203, "type": "METRIC", "confidence": 0.7805950343608856}]}], "introductionContent": [{"text": "The problem of measuring relational similarity is to determine the degree of correspondence between two word pairs.", "labels": [], "entities": []}, {"text": "For instance, the analogous word pairs silverware:fork and clothing:shirt both exemplify well a Class-Inclusion:Singular Collective relation and thus have high relational similarity.", "labels": [], "entities": []}, {"text": "Unlike the problem of attributional similarity, which measures whether two words share similar attributes and is addressed in extensive research work, measuring relational similarity is a relatively new research direction pioneered by, but with many potential applications.", "labels": [], "entities": []}, {"text": "For instance, problems of identifying specific relations between words, such as synonyms, * Work conducted while interning at Microsoft Research.", "labels": [], "entities": []}, {"text": "antonyms or associations, can be reduced to measuring relational similarity compared to prototypical word pairs with the desired relation.", "labels": [], "entities": []}, {"text": "In scenarios like information extraction or question answering, where identifying the existence of certain relations is often the core problem, measuring relational similarity provides a more flexible solution rather than creating relational classifiers for predefined or task-specific categories of relations).", "labels": [], "entities": [{"text": "information extraction", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.8254585862159729}, {"text": "question answering", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.8589654266834259}]}, {"text": "In order to promote this research direction, Jurgens et al.", "labels": [], "entities": []}, {"text": "(2012) proposed anew shared task of measuring relational similarity in SemEval-2012 recently.", "labels": [], "entities": []}, {"text": "In this task, each submitted system is required to judge the degree of a target word pair having a particular relation, measured by its relational similarity compared to a few prototypical example word pairs.", "labels": [], "entities": []}, {"text": "The system performance is evaluated by its correlation with the human judgments using two evaluation metrics, Spearman's rank correlation and MaxDiff accuracy (more details of the task and evaluation metrics will be given in Sec. 3).", "labels": [], "entities": [{"text": "Spearman's rank correlation", "start_pos": 110, "end_pos": 137, "type": "METRIC", "confidence": 0.7783919721841812}, {"text": "MaxDiff accuracy", "start_pos": 142, "end_pos": 158, "type": "METRIC", "confidence": 0.6936047375202179}]}, {"text": "Although participating systems incorporated substantial amounts of information from lexical resources (e.g., WordNet) and contextual patterns from large corpora, only one system () is able to outperform a simple baseline that uses PMI (pointwise mutual information) scoring, which demonstrates the difficulty of this task.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 109, "end_pos": 116, "type": "DATASET", "confidence": 0.9334213137626648}]}, {"text": "In this paper, we explore the problem of measuring relational similarity in the same task setting.", "labels": [], "entities": []}, {"text": "We argue that due to the large number of possible relations, building an ensemble of relational simi-larity models based on heterogeneous information sources is the key to advance the state-of-the-art on this problem.", "labels": [], "entities": []}, {"text": "By combining two general-purpose relational similarity models with three specific wordrelation models covering relations like IsA and synonymy/antonymy, we improve the previous stateof-the-art substantially -having a relative gain of 54.1% in Spearman's rank correlation and 14.7% in the MaxDiff accuracy!", "labels": [], "entities": [{"text": "MaxDiff", "start_pos": 288, "end_pos": 295, "type": "DATASET", "confidence": 0.5892534255981445}, {"text": "accuracy", "start_pos": 296, "end_pos": 304, "type": "METRIC", "confidence": 0.666787326335907}]}, {"text": "Our main contributions are threefold.", "labels": [], "entities": []}, {"text": "First, we propose a novel directional similarity method based on the vector representation of words learned from a recurrent neural network language model.", "labels": [], "entities": []}, {"text": "The relation of two words is captured by their vector offset in the latent semantic space.", "labels": [], "entities": []}, {"text": "Similarity of relations can then be naturally measured by a distance function in the vector space.", "labels": [], "entities": []}, {"text": "This method alone already performs better than all existing systems.", "labels": [], "entities": []}, {"text": "Second, unlike the previous finding, where SVMs learn a much poorer model than naive, we show that using a highlyregularized log-linear model on simple contextual pattern features collected from a document collection of 20GB, a discriminative approach can learn a strong model as well.", "labels": [], "entities": []}, {"text": "Third, we demonstrate that by augmenting existing word-relation models, which cover only a small number of relations, the overall system can be further improved.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "We first survey the related work in Sec.", "labels": [], "entities": []}, {"text": "2 and formally define the problem in Sec.", "labels": [], "entities": []}, {"text": "3. We describe the individual models in detail in Sec.", "labels": [], "entities": []}, {"text": "4. The combination approach is depicted in Sec.", "labels": [], "entities": []}, {"text": "5, along with experimental comparisons to individual models and existing systems.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results of measuring relational similarity using  the directional similarity method, evaluated on the train- ing set. The 1600-dimensional RNNLM vector space  achieves the highest Spearman's \u03c1 and MaxDiff accuracy.", "labels": [], "entities": [{"text": "RNNLM vector space", "start_pos": 149, "end_pos": 167, "type": "DATASET", "confidence": 0.8788109421730042}, {"text": "Spearman's \u03c1", "start_pos": 190, "end_pos": 202, "type": "METRIC", "confidence": 0.6576631665229797}, {"text": "MaxDiff accuracy", "start_pos": 207, "end_pos": 223, "type": "METRIC", "confidence": 0.7211943864822388}]}, {"text": " Table 2: Average Spearman's \u03c1 (Top) and MaxDiff accuracy (%) (Bottom) of each major relation group and all 69  testing relations. The best result in each row is highlighted in boldface font. Statistical significance tests are conducted  by comparing each of our systems with the previous best performing system, UTD N B .  \u2020 and  \u2021 indicate the difference  in the average results is statistically significant with 95% or 99% confidence level, respectively.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.6456944346427917}, {"text": "UTD N B", "start_pos": 313, "end_pos": 320, "type": "DATASET", "confidence": 0.7678593595822653}]}, {"text": " Table 3: Average Spearman's \u03c1 and MaxDiff accuracy results of different model combinations. Com indicates combin- ing all models, where other columns show the results when the specified model is removed. The best result in each row  is highlighted in boldface font. Statistical significance tests are conducted by comparing each ablation configuration  with Com.  \u2021 indicates the difference in the average results is statistically significant with 99% confidence level.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.7973476052284241}]}]}