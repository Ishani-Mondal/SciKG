{"title": [{"text": "Supervised All-Words Lexical Substitution using Delexicalized Features", "labels": [], "entities": [{"text": "All-Words Lexical Substitution", "start_pos": 11, "end_pos": 41, "type": "TASK", "confidence": 0.6278194685777029}]}], "abstractContent": [{"text": "We propose a supervised lexical substitution system that does not use separate clas-sifiers per word and is therefore applicable to any word in the vocabulary.", "labels": [], "entities": []}, {"text": "Instead of learning word-specific substitution patterns, a global model for lexical substitution is trained on delexicalized (i.e., non lexical) features, which allows to exploit the power of supervised methods while being able to generalize beyond target words in the training set.", "labels": [], "entities": []}, {"text": "This way, our approach remains technically straightforward, provides better performance and similar coverage in comparison to unsu-pervised approaches.", "labels": [], "entities": [{"text": "coverage", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9933189153671265}]}, {"text": "Using features from lexical resources, as well as a variety of features computed from large corpora (n-gram counts, distributional similarity) and a ranking method based on the posterior probabilities obtained from a Maximum Entropy classifier, we improve over the state of the art in the LexSub Best-Precision metric and the Generalized Average Precision measure.", "labels": [], "entities": [{"text": "LexSub Best-Precision metric", "start_pos": 289, "end_pos": 317, "type": "DATASET", "confidence": 0.8251913984616598}, {"text": "Generalized Average Precision measure", "start_pos": 326, "end_pos": 363, "type": "METRIC", "confidence": 0.7933159023523331}]}, {"text": "Robustness of our approach is demonstrated by evaluating it successfully on two different datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, the task of automatically providing lexical substitutions in context) received much attention.", "labels": [], "entities": []}, {"text": "The premise to be able to replace words in a sentence without changing its meaning gave rise to applications like linguistic steganography (, semantic text similarity (, and plagiarism detection ().", "labels": [], "entities": [{"text": "semantic text similarity", "start_pos": 142, "end_pos": 166, "type": "TASK", "confidence": 0.6737112601598104}, {"text": "plagiarism detection", "start_pos": 174, "end_pos": 194, "type": "TASK", "confidence": 0.7512845098972321}]}, {"text": "Lexical substitution, a special form of contextual paraphrasing where only a single word is replaced, is closely related to word sense disambiguation (WSD): polysemous words have possible substitutions reflecting several senses, and the correct sense has to be picked to avoid spurious system behavior.", "labels": [], "entities": [{"text": "Lexical substitution", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8303563296794891}, {"text": "word sense disambiguation (WSD)", "start_pos": 124, "end_pos": 155, "type": "TASK", "confidence": 0.7847907245159149}]}, {"text": "However, no explicit word sense inventory is required for lexical substitution).", "labels": [], "entities": [{"text": "lexical substitution", "start_pos": 58, "end_pos": 78, "type": "TASK", "confidence": 0.7245689332485199}]}, {"text": "The prominent tasks in a lexical substitution system are generation and ranking, i.e. to generate a set of possible substitutions for the target word and then to rank this set of possible substitutions according to their contextual fitness.", "labels": [], "entities": []}, {"text": "The task to generate a high quality set of possible substitutions is challenging in itself, for two reasons.", "labels": [], "entities": []}, {"text": "First, the available lexical resources are seldom complete in listing synonyms.", "labels": [], "entities": []}, {"text": "Second, manually annotated substitutions show that not all synonyms of a word are appropriate in a given context, and many good substitutions have other lexical relation than synonymy to the original word.", "labels": [], "entities": []}, {"text": "In this work, we present a supervised lexical substitution system that, unlike the usual lexical sample supervised approaches, can produce substitutions for targets that are not contained in the training material.", "labels": [], "entities": []}, {"text": "We reach this by using non-lexical features from heterogeneous evidence, including lexical-semantic resources and distributional similarity, n-gram and shallow syntactic features based on large, unannotated background corpora.", "labels": [], "entities": []}, {"text": "In light of the existence of lexical resources such as WordNet or machine readable dictionaries that can serve as the source for lexical information, and with the ever-increasing availability of large unannotated corpora for many languages and domains, our proposal enables us to leverage the quality gain of supervised machine learning while generalizing over a large vocabulary through the avoidance of lexicalized features.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 55, "end_pos": 62, "type": "DATASET", "confidence": 0.961105227470398}]}, {"text": "Using a single classifier for all substitution targets in this way results in an all-words substitution system.", "labels": [], "entities": []}, {"text": "As our results demonstrate, our model improves over the state of the art in lexical substitution with practically no open parameters that have to be optimized and selected carefully according to the dataset at hand.", "labels": [], "entities": [{"text": "lexical substitution", "start_pos": 76, "end_pos": 96, "type": "TASK", "confidence": 0.6893385797739029}]}], "datasetContent": [{"text": "In our work, we use two major freely available datasets that contain human-annotated substitutions for single words in their full-sentence context.", "labels": [], "entities": []}, {"text": "This dataset was introduced in the Lexical Substitution task at Semeval 2007 1 . It consists of 2002 sentences fora total of 201 words (10 sentences per word, but 8 sentences does not have gold standard labels).", "labels": [], "entities": [{"text": "Lexical Substitution task at Semeval 2007", "start_pos": 35, "end_pos": 76, "type": "TASK", "confidence": 0.7627751628557841}]}, {"text": "Each sentence was assigned to 5 native speaker annotators, who entered as many paraphrases or substitutions as they found appropriate for the word in context.", "labels": [], "entities": []}, {"text": "Paraphrases are assigned a weight (or frequency) that denotes how many annotators suggested that particular word as a substitute.", "labels": [], "entities": []}, {"text": "We follow previous works in lexical substitution and evaluate our models using the Generalized Average Precision (GAP) () measure which assesses the quality of the entire ranked list.", "labels": [], "entities": [{"text": "lexical substitution", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.7302858829498291}, {"text": "Generalized Average Precision (GAP)", "start_pos": 83, "end_pos": 118, "type": "METRIC", "confidence": 0.9268423318862915}]}, {"text": "In addition, we also provide the precision of our system at the first rank (P@1), i.e. the percentage of correct paraphrases at rank 1.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9995643496513367}]}, {"text": "This is a realistic evaluation criterion for many applications, such as paraphrasing for linguistic steganography: it is the highestranked candidate that can be used to replace the original word (the manipulated text should preserve the original meaning) and there is no straightforward way to exploit multiple correct answers.", "labels": [], "entities": [{"text": "linguistic steganography", "start_pos": 89, "end_pos": 113, "type": "TASK", "confidence": 0.6209824532270432}]}, {"text": "In addition, we also provide the Semeval 2007 best precision 4 metric ( for the LexSub dataset for comparison to Semeval 2007 participants.", "labels": [], "entities": [{"text": "Semeval 2007 best precision 4 metric", "start_pos": 33, "end_pos": 69, "type": "METRIC", "confidence": 0.6440033266941706}, {"text": "LexSub dataset", "start_pos": 80, "end_pos": 94, "type": "DATASET", "confidence": 0.9946011006832123}]}, {"text": "This metric also evaluates the first guess of a system (per context), but gives less credit to easier contexts, where several good options exist.", "labels": [], "entities": []}, {"text": "This fact motivates us to use P@1 rather than the best precision metric in all other experiments.", "labels": [], "entities": [{"text": "P@1", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.9447093804677328}, {"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9968104958534241}]}], "tableCaptions": [{"text": " Table 1: Details of the datasets: WN=WordNet", "labels": [], "entities": [{"text": "WordNet", "start_pos": 38, "end_pos": 45, "type": "DATASET", "confidence": 0.9478150606155396}]}, {"text": " Table 2: Comparison to the baseline on LexSub 2007.", "labels": [], "entities": [{"text": "LexSub 2007", "start_pos": 40, "end_pos": 51, "type": "DATASET", "confidence": 0.9857424795627594}]}, {"text": " Table 3: Comparison to the baseline on the TWSI dataset.", "labels": [], "entities": [{"text": "TWSI dataset", "start_pos": 44, "end_pos": 56, "type": "DATASET", "confidence": 0.9693516790866852}]}, {"text": " Table 4: Feature ablation experiment (on LexSub dataset,  with candidates from Gold Standard).", "labels": [], "entities": [{"text": "LexSub dataset", "start_pos": 42, "end_pos": 56, "type": "DATASET", "confidence": 0.9963309466838837}, {"text": "Gold Standard", "start_pos": 80, "end_pos": 93, "type": "DATASET", "confidence": 0.9555200338363647}]}, {"text": " Table 5: Comparison to previous works (LexSub dataset).", "labels": [], "entities": [{"text": "LexSub dataset", "start_pos": 40, "end_pos": 54, "type": "DATASET", "confidence": 0.9912055134773254}]}]}