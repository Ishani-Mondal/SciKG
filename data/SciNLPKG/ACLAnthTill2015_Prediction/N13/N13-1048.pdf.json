{"title": [{"text": "Training MRF-Based Phrase Translation Models using Gradient Ascent", "labels": [], "entities": [{"text": "MRF-Based Phrase Translation", "start_pos": 9, "end_pos": 37, "type": "TASK", "confidence": 0.8648040294647217}]}], "abstractContent": [{"text": "This paper presents a general, statistical framework for modeling phrase translation via Markov random fields.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.821619987487793}]}, {"text": "The model allows for arbituary features extracted from a phrase pair to be incorporated as evidence.", "labels": [], "entities": []}, {"text": "The parameters of the model are estimated using a large-scale discriminative training approach that is based on stochastic gradient ascent and an N-best list based expected BLEU as the objective function.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 173, "end_pos": 177, "type": "METRIC", "confidence": 0.9985373020172119}]}, {"text": "The model is easy to be incoporated into a standard phrase-based statistical machine translation system, requiring no code change in the runtime engine.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 52, "end_pos": 96, "type": "TASK", "confidence": 0.5618042051792145}]}, {"text": "Evaluation is performed on two Europarl translation tasks, German-English and French-English.", "labels": [], "entities": [{"text": "Europarl translation tasks", "start_pos": 31, "end_pos": 57, "type": "DATASET", "confidence": 0.8247529665629069}]}, {"text": "Results show that incoporating the Markov random field model significantly improves the performance of a state-of-the-art phrase-based machine translation system, leading to again of 0.8-1.3 BLEU points.", "labels": [], "entities": [{"text": "phrase-based machine translation", "start_pos": 122, "end_pos": 154, "type": "TASK", "confidence": 0.6207817991574606}, {"text": "BLEU", "start_pos": 191, "end_pos": 195, "type": "METRIC", "confidence": 0.9991164803504944}]}], "introductionContent": [{"text": "The phrase translation model, also known as the phrase table, is one of the core components of a phrase-based statistical machine translation (SMT) system.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.8448375463485718}, {"text": "phrase-based statistical machine translation (SMT)", "start_pos": 97, "end_pos": 147, "type": "TASK", "confidence": 0.7294002813952309}]}, {"text": "The most common method of constructing the phrase table takes a two-phase approach.", "labels": [], "entities": []}, {"text": "First, the bilingual phrase pairs are extracted heuristically from an automatically word-aligned training data.", "labels": [], "entities": []}, {"text": "The second phase is parameter estimation, where each phrase pair is assigned with some scores that are estimated based on counting of words or phrases on the same word-aligned training data.", "labels": [], "entities": [{"text": "parameter estimation", "start_pos": 20, "end_pos": 40, "type": "TASK", "confidence": 0.6565874814987183}]}, {"text": "There has been a lot of research on improving the quality of the phrase table using more principled methods for phrase extraction (e.g., Lamber and Banchs 2005), parameter estimation (e.g.,; He and Deng 2012), or both (e.g.,).", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 112, "end_pos": 129, "type": "TASK", "confidence": 0.8483606576919556}]}, {"text": "The focus of this paper is on the parameter estimation phase.", "labels": [], "entities": []}, {"text": "We revisit the problem of scoring a phrase translation pair by developing anew phrase translation model based on Markov random fields (MRFs) and large-scale discriminative training.", "labels": [], "entities": [{"text": "phrase translation pair", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.7743005057175955}, {"text": "phrase translation", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.7856731712818146}]}, {"text": "We strive to address the following three primary concerns.", "labels": [], "entities": []}, {"text": "First of all, instead of parameterizing a phrase translation pair using a set of scoring functions that are learned independently (e.g., phrase translation probabilities and lexical weights) we use a general, statistical framework in which arbitrary features extracted from a phrase pair can be incorporated to model the translation in a unified way.", "labels": [], "entities": [{"text": "phrase translation pair", "start_pos": 42, "end_pos": 65, "type": "TASK", "confidence": 0.7627553045749664}, {"text": "phrase translation", "start_pos": 137, "end_pos": 155, "type": "TASK", "confidence": 0.7289451360702515}]}, {"text": "To this end, we propose the use of a MRF model.", "labels": [], "entities": [{"text": "MRF", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.7822961807250977}]}, {"text": "Second, because the phrase model has to work with other component models in an SMT system in order to produce good translations and the quality of translation is measured via BLEU score, it is desirable to optimize the parameters of the phrase model jointly with other component models with respect to an objective function that is closely related to the evaluation metric under consideration, i.e., BLEU in this paper.", "labels": [], "entities": [{"text": "SMT", "start_pos": 79, "end_pos": 82, "type": "TASK", "confidence": 0.9789133667945862}, {"text": "BLEU score", "start_pos": 175, "end_pos": 185, "type": "METRIC", "confidence": 0.9741052389144897}, {"text": "BLEU", "start_pos": 400, "end_pos": 404, "type": "METRIC", "confidence": 0.9983443021774292}]}, {"text": "To this end, we resort to a large-scale discriminative training approach, following the pioneering work of.", "labels": [], "entities": []}, {"text": "Although there are established methods of tuning a handful of features on small training sets, such as the MERT method, the development of discriminative training methods for millions of features on millions of sentence pairs is still an ongoing area of research.", "labels": [], "entities": []}, {"text": "A recent survey is due to.", "labels": [], "entities": []}, {"text": "In this paper we show that by using stochastic gradient ascent and an N-best list based expected BLEU as the objective function, largescale discriminative training can lead to significant improvements.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.992251455783844}]}, {"text": "The third primary concern is the ease of adoption of the proposed method.", "labels": [], "entities": []}, {"text": "To this end, we use a simple and well-established learning method, ensuring that the results can be easily reproduced.", "labels": [], "entities": []}, {"text": "We also develop the features for the MRF model in such away that the resulting model is of the same format as that of a traditional phrase table.", "labels": [], "entities": [{"text": "MRF", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.8591843843460083}]}, {"text": "Thus, the model can be easily incorporated into a standard phrase-based SMT system, requiring no code change in the runtime engine.", "labels": [], "entities": [{"text": "SMT", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.8762966990470886}]}, {"text": "In the rest of the paper, Section 2 presents the MRF model for phrase translation.", "labels": [], "entities": [{"text": "MRF", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.6817961931228638}, {"text": "phrase translation", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.9122524261474609}]}, {"text": "Section 3 describes the way the model parameters are estimated.", "labels": [], "entities": []}, {"text": "Section 4 presents the experimental results on two Europarl translation tasks.", "labels": [], "entities": [{"text": "Europarl translation tasks", "start_pos": 51, "end_pos": 77, "type": "TASK", "confidence": 0.7358946800231934}]}, {"text": "Section 5 reviews previous work that lays the foundation of this study.", "labels": [], "entities": []}, {"text": "Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted our experiments on two Europarl translation tasks, German-to-English (DE-EN) and French-to-English (FR-EN).", "labels": [], "entities": [{"text": "Europarl translation tasks", "start_pos": 36, "end_pos": 62, "type": "TASK", "confidence": 0.6445145606994629}, {"text": "FR-EN", "start_pos": 113, "end_pos": 118, "type": "METRIC", "confidence": 0.7309621572494507}]}, {"text": "The data sets are published for the shared task in NAACL 2006 Workshop on Statistical Machine Translation (WMT06)).", "labels": [], "entities": [{"text": "NAACL 2006 Workshop on Statistical Machine Translation (WMT06))", "start_pos": 51, "end_pos": 114, "type": "TASK", "confidence": 0.8305225789546966}]}, {"text": "For DE-EN, the training set contains 751K sentence pairs, with 21 words per sentence on average.", "labels": [], "entities": []}, {"text": "The official development set used for the shared task contains 2000 sentences.", "labels": [], "entities": []}, {"text": "In our experiments, we used the first 1000 sentences as a development set for MERT training and optimizing parameters for discriminative training, such as learning rate and the number of iterations.", "labels": [], "entities": [{"text": "MERT training", "start_pos": 78, "end_pos": 91, "type": "TASK", "confidence": 0.8755607008934021}]}, {"text": "We used the rest 1000 sentences as the first test set (TEST1).", "labels": [], "entities": [{"text": "TEST1", "start_pos": 55, "end_pos": 60, "type": "METRIC", "confidence": 0.9398871064186096}]}, {"text": "We used the WMT06 test data as the second test set (TEST2), which contains 2000 sentences.", "labels": [], "entities": [{"text": "WMT06 test data", "start_pos": 12, "end_pos": 27, "type": "DATASET", "confidence": 0.960909922917684}, {"text": "TEST2", "start_pos": 52, "end_pos": 57, "type": "METRIC", "confidence": 0.8778573274612427}]}, {"text": "For FR-EN, the training set contains 688K sentence pairs, with 21 words per sentence on average.", "labels": [], "entities": [{"text": "FR-EN", "start_pos": 4, "end_pos": 9, "type": "TASK", "confidence": 0.45616990327835083}]}, {"text": "The development set contains 2000 sentences.", "labels": [], "entities": []}, {"text": "We used 2000 sentences from the WMT05 shared task as TEST1, and the 2000 sentences from the WMT06 shared task as TEST2.", "labels": [], "entities": [{"text": "WMT05 shared task", "start_pos": 32, "end_pos": 49, "type": "DATASET", "confidence": 0.8551450570424398}, {"text": "TEST1", "start_pos": 53, "end_pos": 58, "type": "METRIC", "confidence": 0.9281771779060364}, {"text": "WMT06 shared task", "start_pos": 92, "end_pos": 109, "type": "DATASET", "confidence": 0.8919090231259664}]}, {"text": "Two baseline phrase-based SMT systems, each for one language pair, are developed as follows.", "labels": [], "entities": [{"text": "SMT", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.8518359661102295}]}, {"text": "These baseline systems are used in our experiments both for comparison purpose and for generating N-best lists for discriminative training.", "labels": [], "entities": []}, {"text": "First, we performed word alignment on the training set using a hidden Markov model with lexicalized distortion (He 2007), then extracted the phrase table from the word aligned bilingual texts ().", "labels": [], "entities": [{"text": "word alignment", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.7840011417865753}]}, {"text": "The maximum phrase length is set to four.", "labels": [], "entities": []}, {"text": "Other models used in a baseline system include a lexicalized reordering model, word count and phrase count, and a trigram language model trained on the English training data provided by the WMT06 shared task.", "labels": [], "entities": [{"text": "WMT06 shared task", "start_pos": 190, "end_pos": 207, "type": "DATASET", "confidence": 0.8310176134109497}]}, {"text": "A fast beam-search phrasebased decoder) is used and the distortion limit is set to four.", "labels": [], "entities": []}, {"text": "The decoder is modified so as to output the Viterbi derivation for each translation hypothesis.", "labels": [], "entities": []}, {"text": "The metric used for evaluation is case insensitive BLEU score (.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 51, "end_pos": 61, "type": "METRIC", "confidence": 0.9675584733486176}]}, {"text": "We also performed a significance test using the paired ttest.", "labels": [], "entities": [{"text": "significance", "start_pos": 20, "end_pos": 32, "type": "METRIC", "confidence": 0.9370445013046265}]}, {"text": "Differences are considered statistically significant when the p-value is less than 0.05.", "labels": [], "entities": []}, {"text": "The official results are accessible at http://www.statmt.org/wmt06/shared-task/results.html  presents the baseline results.", "labels": [], "entities": []}, {"text": "The performance of our phrase-based SMT systems compares favorably to the top-ranked systems, thus providing a fair baseline for our research.", "labels": [], "entities": [{"text": "SMT", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.8518633842468262}]}, {"text": "shows the main results measured in BLEU evaluated on TEST1 and TEST2.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.9960015416145325}, {"text": "TEST1", "start_pos": 53, "end_pos": 58, "type": "DATASET", "confidence": 0.6398063898086548}, {"text": "TEST2", "start_pos": 63, "end_pos": 68, "type": "DATASET", "confidence": 0.9106348752975464}]}, {"text": "Row 1 is the baseline system.", "labels": [], "entities": []}, {"text": "Rows 2 to 5 are the systems enhanced by integrating different versions of the MRF-based phrase translation model.", "labels": [], "entities": [{"text": "MRF-based phrase translation", "start_pos": 78, "end_pos": 106, "type": "TASK", "confidence": 0.7534049352010092}]}, {"text": "These versions, labeled as MRF f , are trained using the method described in Section 3, and differ in the feature classes (which are specified by the subscript f) incorporated in the MRF-based model.", "labels": [], "entities": []}, {"text": "In this study we focused on three classes of features, as described in Section 2, phrase-pair features (p), word-pair features (t) and triplet features (tp).", "labels": [], "entities": []}, {"text": "The statistics for these features are given in. shows that all the MRF models lead to a substantial improvement over the baseline system across all test sets, with a statistically significant margin from 0.8 to 1.3 BLEU points.", "labels": [], "entities": [{"text": "MRF", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.7744603157043457}, {"text": "BLEU", "start_pos": 215, "end_pos": 219, "type": "METRIC", "confidence": 0.9978766441345215}]}, {"text": "As expected, the best phrase model incorporates all of the three classes of features (MRF p+t+tp in Row 2).", "labels": [], "entities": [{"text": "MRF", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.5520128011703491}]}, {"text": "We also find that both MRF p and MRF t , although using only one class of features, perform quite well.", "labels": [], "entities": [{"text": "MRF", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.7053579092025757}]}, {"text": "In TEST2 of DE-EN and TEST1 of FR-EN, they are in a near statistical tie with MRF p+t and MRF p+t+tp .", "labels": [], "entities": [{"text": "TEST2", "start_pos": 3, "end_pos": 8, "type": "METRIC", "confidence": 0.965119481086731}, {"text": "TEST1", "start_pos": 22, "end_pos": 27, "type": "METRIC", "confidence": 0.7965849041938782}, {"text": "FR-EN", "start_pos": 31, "end_pos": 36, "type": "METRIC", "confidence": 0.6038182377815247}]}], "tableCaptions": [{"text": " Table 1: Baseline results in BLEU. The results of  top ranked systems are reported in Koehn and  Monz (2006) 2 .", "labels": [], "entities": [{"text": "BLEU", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.9180733561515808}]}, {"text": " Table 2: Main results (BLEU scores) of MRF- based phrase translation models with different  feature classes. The superscripts \u03b1 and \u03b2 indicate  statistically significant difference (p < 0.05)  from Baseline and MRF p+t+tp , respectively.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9989857077598572}, {"text": "MRF- based phrase translation", "start_pos": 40, "end_pos": 69, "type": "TASK", "confidence": 0.812354326248169}]}, {"text": " Table 4: BLEU scores of MRF-based phrase trans- lation models trained using different objective  functions. The MRF models use phrase-pair and  word-pair features. The superscript \u03b1 indicates  statistically significant difference (p < 0.05) from", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9991563558578491}, {"text": "MRF-based phrase trans- lation", "start_pos": 25, "end_pos": 55, "type": "TASK", "confidence": 0.810025942325592}]}]}