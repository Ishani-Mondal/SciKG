{"title": [{"text": "Open Information Extraction with Tree Kernels", "labels": [], "entities": [{"text": "Open Information Extraction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.703659733136495}]}], "abstractContent": [{"text": "Traditional relation extraction seeks to identify pre-specified semantic relations within natural language text, while open Information Extraction (Open IE) takes a more general approach , and looks fora variety of relations without restriction to a fixed relation set.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.8031720817089081}, {"text": "open Information Extraction (Open IE)", "start_pos": 119, "end_pos": 156, "type": "TASK", "confidence": 0.7607601540429252}]}, {"text": "With this generalization comes the question, what is a relation?", "labels": [], "entities": []}, {"text": "For example, should the more general task be restricted to relations mediated by verbs, nouns, or both?", "labels": [], "entities": []}, {"text": "To help answer this question, we propose two levels of sub-tasks for Open IE.", "labels": [], "entities": [{"text": "Open IE", "start_pos": 69, "end_pos": 76, "type": "TASK", "confidence": 0.5226701945066452}]}, {"text": "One task is to determine if a sentence potentially contains a relation between two entities?", "labels": [], "entities": []}, {"text": "The other task looks to confirm explicit relation words for two entities.", "labels": [], "entities": []}, {"text": "We propose multiple SVM models with dependency tree kernels for both tasks.", "labels": [], "entities": []}, {"text": "For explicit relation extraction, our system can extract both noun and verb relations.", "labels": [], "entities": [{"text": "explicit relation extraction", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.6040888130664825}]}, {"text": "Our results on three datasets show that our system is superior when compared to state-of-the-art systems like REVERB and OLLIE for both tasks.", "labels": [], "entities": [{"text": "REVERB", "start_pos": 110, "end_pos": 116, "type": "METRIC", "confidence": 0.9849648475646973}, {"text": "OLLIE", "start_pos": 121, "end_pos": 126, "type": "METRIC", "confidence": 0.9162542223930359}]}, {"text": "For example, in some experiments our system achieves 33% improvement on nominal relation extraction over OLLIE.", "labels": [], "entities": [{"text": "nominal relation extraction", "start_pos": 72, "end_pos": 99, "type": "TASK", "confidence": 0.6711343030134836}, {"text": "OLLIE", "start_pos": 105, "end_pos": 110, "type": "METRIC", "confidence": 0.7076607346534729}]}, {"text": "In addition we propose an unsupervised rule-based approach which can serve as a strong baseline for Open IE systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Relation Extraction (RE) systems are designed to discover various semantic relations (e.g. <Obama, president, the United States>) from natural language text.", "labels": [], "entities": [{"text": "Relation Extraction (RE)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8463710665702819}]}, {"text": "Traditional RE systems extract specific relations for prespecified name-entity types ().", "labels": [], "entities": [{"text": "RE", "start_pos": 12, "end_pos": 14, "type": "TASK", "confidence": 0.9638880491256714}]}, {"text": "To train such systems, every relation needs manually annotated training examples, which supports limited scope and is difficult to extend.", "labels": [], "entities": []}, {"text": "For this reason, proposed Open Information Extraction (Open IE), whose goal is to extract general relations for two entities.", "labels": [], "entities": [{"text": "Open Information Extraction (Open IE)", "start_pos": 26, "end_pos": 63, "type": "TASK", "confidence": 0.760757395199367}]}, {"text": "The idea is to avoid the need for specific training examples, and to extract a diverse range of relations.", "labels": [], "entities": []}, {"text": "This generalized form has received significant attention, e.g., (.", "labels": [], "entities": []}, {"text": "Because Open IE is not guided by or not restricted to a prespecified list of relations, the immediate challenge is determining about what counts as a relation?", "labels": [], "entities": [{"text": "Open IE", "start_pos": 8, "end_pos": 15, "type": "TASK", "confidence": 0.6494551301002502}]}, {"text": "Most recent Open IE systems have targeted verbal relations (, claiming that these are the majority.", "labels": [], "entities": []}, {"text": "However, show that only 20% of relations in the ACE programs Relation Detection and Characterization (RDC) are verbal.", "labels": [], "entities": [{"text": "Relation Detection and Characterization (RDC)", "start_pos": 61, "end_pos": 106, "type": "TASK", "confidence": 0.8677637491907392}]}, {"text": "Our manually extracted relation triple set from the Penn Treebank shows that there are more nominal relations than verbal ones, 3 to 2.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 52, "end_pos": 65, "type": "DATASET", "confidence": 0.9940162003040314}]}, {"text": "This difference arises because of the ambiguity of what constitutes a relation in Open IE.", "labels": [], "entities": []}, {"text": "It is often difficult even for humans to agree on what constitutes a relation, and which words in the sentence establish a relation between a pair of entities.", "labels": [], "entities": []}, {"text": "For example, in the sentence \"Olivetti broke Cocom rules\" is there a relation between Olivetti and Cocom?", "labels": [], "entities": []}, {"text": "This ambiguity in the problem definition leads to significant challenges and confusion when evaluating and comparing the performance of different methods and systems.", "labels": [], "entities": []}, {"text": "An example are the results in and, REVERB \"is reported\" as superior to WOE parse , a system proposed in; while in, it is reported the opposite.", "labels": [], "entities": [{"text": "REVERB", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9987308382987976}, {"text": "WOE parse", "start_pos": 71, "end_pos": 80, "type": "TASK", "confidence": 0.6100399047136307}]}, {"text": "To better answer the question, what counts as a relation?", "labels": [], "entities": []}, {"text": "we propose two tasks for Open IE.", "labels": [], "entities": [{"text": "Open IE", "start_pos": 25, "end_pos": 32, "type": "TASK", "confidence": 0.5926168411970139}]}, {"text": "The first task seeks to determine whether there is a relation between two entities (called \"Binary task\").", "labels": [], "entities": []}, {"text": "The other is to confirm whether the relation words extracted for the two entities are appropriate (the \"Triple task\").", "labels": [], "entities": []}, {"text": "The Binary task does not restrict relation word forms, whether they are mediated by nouns, verbs, prepositions, or even implicit relations.", "labels": [], "entities": []}, {"text": "The Triple task requires an abstract representation of relation word forms, which we develop here.", "labels": [], "entities": []}, {"text": "We assume that relation words are nouns or verbs; in our data, these two types comprise 71% of explicit relations.", "labels": [], "entities": []}, {"text": "We adapt an SVM dependency tree kernel model) for both tasks.", "labels": [], "entities": []}, {"text": "The input to our tasks is a dependency parse, created by Stanford Parser.", "labels": [], "entities": []}, {"text": "Selecting relevant features from a parse tree for semantic tasks is difficult.", "labels": [], "entities": []}, {"text": "SVM tree kernels avoid extracting explicit features from parse trees by calculating the inner product of the two trees.", "labels": [], "entities": []}, {"text": "For the Binary task, our dependency path is the path between two entities.", "labels": [], "entities": []}, {"text": "For the Triple task, the path is among entities and relation words (i.e. relation triples).", "labels": [], "entities": []}, {"text": "Tree kernels have been used in traditional RE and have helped achieve state of the art performance (.", "labels": [], "entities": [{"text": "RE", "start_pos": 43, "end_pos": 45, "type": "TASK", "confidence": 0.8908324837684631}]}, {"text": "But one challenge of using tree kernels on Open IE is that the lexicon of relations is much larger than those of traditional RE, making it difficult to include the lexical information as features.", "labels": [], "entities": []}, {"text": "Here we proposed an unlexicalized tree structure for Open IE.", "labels": [], "entities": []}, {"text": "As far as we know, this is the first time an SVM tree kernel has been applied in Open IE.", "labels": [], "entities": []}, {"text": "Experimental results on multiple datasets show our system outperforms state-of-the-art systems REVERB and OLLIE.", "labels": [], "entities": [{"text": "REVERB", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.978346049785614}, {"text": "OLLIE", "start_pos": 106, "end_pos": 111, "type": "METRIC", "confidence": 0.9526398181915283}]}, {"text": "Typically an Open IE system is tested on one dataset.", "labels": [], "entities": []}, {"text": "However, because the definition of relation is ambiguous, we believe that is necessary to test with multiple datasets.", "labels": [], "entities": []}, {"text": "In addition to the supervised model, we also propose an unsupervised model which relies on several heuristic rules.", "labels": [], "entities": []}, {"text": "Results with this approach show that this simple unsupervised model provides a robust strong baseline for other approaches.", "labels": [], "entities": []}, {"text": "In summary, our main contributions are: \u2022 Use SVM tree kernels for Open IE.", "labels": [], "entities": []}, {"text": "Our system is robust comparing with other Open IE systems, achieving superior scores in two test sets and comparative scores in another set.", "labels": [], "entities": []}, {"text": "\u2022 Extend beyond verbal relations, which are prevalent in current systems.", "labels": [], "entities": [{"text": "Extend", "start_pos": 2, "end_pos": 8, "type": "TASK", "confidence": 0.948150634765625}]}, {"text": "Analyze implicit relation problem in Open IE, which is ignored by other work.", "labels": [], "entities": []}, {"text": "\u2022 Propose an unsupervised model for Open IE, which can be a strong baseline for other approaches.", "labels": [], "entities": [{"text": "Open IE", "start_pos": 36, "end_pos": 43, "type": "TASK", "confidence": 0.6332280933856964}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 provides the problem description and system structure, before summarizing previous work in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 defines our representation of relation word patterns crucial to our task two, and Section 5 describes tree kernels for SVM.", "labels": [], "entities": []}, {"text": "Section 6 describes the unsupervised model, and Section 7 explains our experiment design and results.", "labels": [], "entities": []}, {"text": "Section 8 concludes with a summary, and anticipation of future work.", "labels": [], "entities": [{"text": "summary", "start_pos": 27, "end_pos": 34, "type": "METRIC", "confidence": 0.9111462235450745}]}], "datasetContent": [{"text": "We compared the unsupervised heuristic rule method and the supervised SVM method discussed above against REVERB) and OL-LIE (), using three datasets.", "labels": [], "entities": [{"text": "REVERB", "start_pos": 105, "end_pos": 111, "type": "METRIC", "confidence": 0.9766951203346252}, {"text": "OL-LIE", "start_pos": 117, "end_pos": 123, "type": "METRIC", "confidence": 0.7328794598579407}]}, {"text": "One dataset consists of sentences from the Penn Treebank, and the other two are the experiment datasets of each of the two systems being compared.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 43, "end_pos": 56, "type": "DATASET", "confidence": 0.9955569505691528}]}, {"text": "E feature F1 the dependency link label between two entities, null if none.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.7073262929916382}]}], "tableCaptions": [{"text": " Table 2: Relation extraction results on Treebank set  (Binary)", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7745123505592346}]}, {"text": " Table 3: Relation extraction results on Treebank set  (Triple)", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.8641244471073151}, {"text": "Treebank set", "start_pos": 41, "end_pos": 53, "type": "DATASET", "confidence": 0.9301813542842865}]}, {"text": " Table 4: Relation extraction results on REVERB set  (Triple).", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.8237371146678925}, {"text": "REVERB set", "start_pos": 41, "end_pos": 51, "type": "METRIC", "confidence": 0.9662196040153503}]}, {"text": " Table 5: Relation extraction results on OLLIE set  (Triple).", "labels": [], "entities": [{"text": "Relation extraction", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.8927723467350006}, {"text": "OLLIE", "start_pos": 41, "end_pos": 46, "type": "METRIC", "confidence": 0.9905939102172852}]}]}