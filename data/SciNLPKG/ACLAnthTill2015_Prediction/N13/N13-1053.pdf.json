{"title": [], "abstractContent": [{"text": "The rising influence of user-generated online reviews (Cone, 2011) has led to growing incentive for businesses to solicit and manufacture DECEPTIVE OPINION SPAM-fictitious reviews that have been deliberately written to sound authentic and deceive the reader.", "labels": [], "entities": []}, {"text": "Recently , Ott et al.", "labels": [], "entities": []}, {"text": "(2011) have introduced an opinion spam dataset containing gold standard deceptive positive hotel reviews.", "labels": [], "entities": []}, {"text": "However, the complementary problem of negative deceptive opinion spam, intended to slander competitive offerings, remains largely unstudied.", "labels": [], "entities": []}, {"text": "Following an approach similar to Ott et al.", "labels": [], "entities": []}, {"text": "(2011), in this work we create and study the first dataset of deceptive opinion spam with negative sentiment reviews.", "labels": [], "entities": []}, {"text": "Based on this dataset, we find that standard n-gram text categorization techniques can detect negative deceptive opinion spam with performance far surpassing that of human judges.", "labels": [], "entities": []}, {"text": "Finally, in conjunction with the aforementioned positive review dataset, we consider the possible interactions between sentiment and deception, and present initial results that encourage further exploration of this relationship.", "labels": [], "entities": []}], "introductionContent": [{"text": "Consumer's purchase decisions are increasingly influenced by user-generated online reviews of products and services.", "labels": [], "entities": []}, {"text": "Accordingly, there is a growing incentive for businesses to solicit and manufacture DECEPTIVE OPINION SPAMfictitious reviews that have been deliberately written to sound authentic and deceive the reader).", "labels": [], "entities": []}, {"text": "For example, has estimated that between 1% and 6% of positive hotel reviews appear to be deceptive, suggesting that some hotels maybe posting fake positive reviews in order to hype their own offerings.", "labels": [], "entities": []}, {"text": "In this work we distinguish between two kinds of deceptive opinion spam, depending on the sentiment expressed in the review.", "labels": [], "entities": []}, {"text": "In particular, reviews intended to promote or hype an offering, and which therefore express a positive sentiment towards the offering, are called positive deceptive opinion spam.", "labels": [], "entities": []}, {"text": "In contrast, reviews intended to disparage or slander competitive offerings, and which therefore express a negative sentiment towards the offering, are called negative deceptive opinion spam.", "labels": [], "entities": []}, {"text": "While previous related work) has explored characteristics of positive deceptive opinion spam, the complementary problem of negative deceptive opinion spam remains largely unstudied.", "labels": [], "entities": []}, {"text": "Following the framework of, we use Amazon's Mechanical Turk service to produce the first publicly available 1 dataset of negative deceptive opinion spam, containing 400 gold standard deceptive negative reviews of 20 popular Chicago hotels.", "labels": [], "entities": []}, {"text": "To validate the credibility of our deceptive reviews, we show that human deception detection performance on the negative reviews is low, in agreement with decades of traditional deception detection research).", "labels": [], "entities": [{"text": "human deception detection", "start_pos": 67, "end_pos": 92, "type": "TASK", "confidence": 0.6249514023462931}, {"text": "deception detection", "start_pos": 178, "end_pos": 197, "type": "TASK", "confidence": 0.7567555010318756}]}, {"text": "We then show that standard n-gram text categorization techniques can be used to detect negative deceptive opinion spam with approximately 86% accuracy -far surpassing that of the human judges.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 142, "end_pos": 150, "type": "METRIC", "confidence": 0.9972196817398071}]}, {"text": "In conjunction with Ott et al.", "labels": [], "entities": []}, {"text": "(2011)'s positive deceptive opinion spam dataset, we then explore the interaction between sentiment and deception with respect to three types of language features: (1) changes in first-person singular use, often attributed to psychological distancing (, (2) decreased spatial awareness and more narrative form, consistent with theories of reality monitoring and imaginative writing (), and (3) increased negative emotion terms, often attributed to leakage cues, but perhaps better explained in our case as an exaggeration of the underlying review sentiment.", "labels": [], "entities": []}], "datasetContent": [{"text": "One of the biggest challenges facing studies of deception is obtaining labeled data.", "labels": [], "entities": []}, {"text": "have proposed an approach for generating positive deceptive opinion spam using Amazon's popular Mechanical Turk crowdsourcing service.", "labels": [], "entities": [{"text": "generating positive deceptive opinion spam", "start_pos": 30, "end_pos": 72, "type": "TASK", "confidence": 0.6312291383743286}]}, {"text": "In this section we discuss our efforts to extend's dataset to additionally include negative deceptive opinion spam.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Deception detection performance, incl. (P)recision, (R)ecall, and (F)1-score, for three human judges and two  meta-judges on a set of 160 negative reviews. The largest value in each column is indicated with boldface.", "labels": [], "entities": [{"text": "Deception detection", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.8860924243927002}, {"text": "recision", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.5379201173782349}, {"text": "R)ecall", "start_pos": 63, "end_pos": 70, "type": "METRIC", "confidence": 0.6754820744196574}, {"text": "F)1-score", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.8416427572568258}]}, {"text": " Table 2: Automated classifier performance for different train and test sets, incl. (P)recision, (R)ecall and (F)1-score.", "labels": [], "entities": [{"text": "recision", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.5631300806999207}, {"text": "R)ecall", "start_pos": 98, "end_pos": 105, "type": "METRIC", "confidence": 0.6734829743703207}]}]}