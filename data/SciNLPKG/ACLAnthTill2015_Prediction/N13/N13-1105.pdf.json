{"title": [{"text": "A Quantum-Theoretic Approach to Distributional Semantics", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we explore the potential of quantum theory as a formal framework for capturing lexical meaning.", "labels": [], "entities": []}, {"text": "We present a novel semantic space model that is syntactically aware, takes word order into account, and features key quantum aspects such as superposition and entanglement.", "labels": [], "entities": []}, {"text": "We define a dependency-based Hilbert space and show how to represent the meaning of words by density matrices that encode dependency neighborhoods.", "labels": [], "entities": []}, {"text": "Experiments on word similarity and association reveal that our model achieves results competitive with a variety of classical models.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 15, "end_pos": 30, "type": "TASK", "confidence": 0.7548623383045197}]}], "introductionContent": [{"text": "The fields of cognitive science and natural language processing have recently produced an ensemble of semantic models which have an impressive track record of replicating human behavior and enabling real-world applications.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 36, "end_pos": 63, "type": "TASK", "confidence": 0.7195330262184143}]}, {"text": "Examples include simulations of word association Denh\u00ec ere and, semantic priming (, categorization, numerous studies of lexicon acquisition, word sense discrimination, and paraphrase recognition).", "labels": [], "entities": [{"text": "word sense discrimination", "start_pos": 141, "end_pos": 166, "type": "TASK", "confidence": 0.6719988187154134}, {"text": "paraphrase recognition", "start_pos": 172, "end_pos": 194, "type": "TASK", "confidence": 0.8076187372207642}]}, {"text": "The term \"semantic\" derives from the intuition that words seen in the context of a given word contribute to its meaning.", "labels": [], "entities": []}, {"text": "Although the specific details of the individual models differ, they all process a corpus of text as input and represent words (or concepts) in a (reduced) highdimensional space.", "labels": [], "entities": []}, {"text": "In this paper, we explore the potential of quantum theory as a formal framework for capturing lexical meaning and modeling semantic processes such as word similarity and association (see for an overview of related research in this area).", "labels": [], "entities": [{"text": "word similarity and association", "start_pos": 150, "end_pos": 181, "type": "TASK", "confidence": 0.7100921273231506}]}, {"text": "We use the term quantum theory to refer to the abstract mathematical foundation of quantum mechanics which is not specifically tied to physics.", "labels": [], "entities": []}, {"text": "Quantum theory is in principle applicable in any discipline where there is a need to formalize uncertainty.", "labels": [], "entities": [{"text": "Quantum theory", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7910923063755035}]}, {"text": "Indeed, researchers have been pursuing applications in areas as diverse as economics, information theory, psychology, and cognitive science.", "labels": [], "entities": [{"text": "information theory", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.8128828406333923}]}, {"text": "But what are the features of quantum theory which make it a promising framework for modeling meaning?", "labels": [], "entities": []}, {"text": "Superposition, entanglement, incompatibility, and interference are all related aspects of quantum theory, which endow it with a unique character.", "labels": [], "entities": []}, {"text": "Superposition is away of modeling uncertainty, more so than in classical probability theory.", "labels": [], "entities": []}, {"text": "It contains information about the potentialities of a system's state.", "labels": [], "entities": []}, {"text": "An electron whose location in an atom is uncertain can be modeled as being in a superposition of locations.", "labels": [], "entities": []}, {"text": "Analogously, words in natural language can have multiple meanings.", "labels": [], "entities": []}, {"text": "In isolation, the word pen may refer to a writing implement, an enclosure for confining livestock, a playpen, a penitentiary or a female swan.", "labels": [], "entities": []}, {"text": "However, when observed in the context of the word ink the ambiguity resolves into the sense of the word dealing with writing.", "labels": [], "entities": []}, {"text": "The meanings of words in a semantic space are superposed in away which is intuitively similar to the atom's electron.", "labels": [], "entities": []}, {"text": "Entanglement concerns the relationship between systems for which it is impossible to specify a joint probability distribution from the probability distributions of their constituent parts.", "labels": [], "entities": []}, {"text": "With regard to word meanings, entanglement encodes (hidden) relationships between concepts.", "labels": [], "entities": []}, {"text": "The different senses of a word \"exist in parallel\" until it is observed in some context.", "labels": [], "entities": []}, {"text": "This reduction of ambiguity has effects on other concepts connected via entanglement.", "labels": [], "entities": []}, {"text": "The notion of incompatibility is fundamental to quantum systems.", "labels": [], "entities": []}, {"text": "In classical systems, it is assumed by default that measurements are compatible, that is, independent, and as a result the order in which these take place does not matter.", "labels": [], "entities": []}, {"text": "By contrast in quantum theory, measurements may share (hidden) order-sensitive inter-dependencies and the outcome of the first measurement can change the outcome of the second measurement.", "labels": [], "entities": []}, {"text": "Interference is a feature of quantum probability that can cause classical assumptions such as the law of total probability to be violated.", "labels": [], "entities": [{"text": "Interference", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.9443264603614807}]}, {"text": "When concepts interact their joint representation can exhibit nonclassical behavior, e.g., with regard to conjunction and disjunction).", "labels": [], "entities": []}, {"text": "An often cited example is the \"guppy effect\".", "labels": [], "entities": []}, {"text": "Although guppy is an example of a pet-fish it is neither a very typical pet nor fish.", "labels": [], "entities": []}, {"text": "In the following we use the rich mathematical framework of quantum theory to model semantic information.", "labels": [], "entities": []}, {"text": "Specifically, we show how word meanings can be expressed as quantum states.", "labels": [], "entities": []}, {"text": "A word brings with it its own subspace which is spanned by vectors representing its potential usages.", "labels": [], "entities": []}, {"text": "We present a specific implementation of a semantic space that is syntactically aware, takes word order into account, and features key aspects of quantum theory.", "labels": [], "entities": []}, {"text": "We empirically evaluate our model on word similarity and association and show that it achieves results competitive with a variety of classical models.", "labels": [], "entities": [{"text": "word similarity and association", "start_pos": 37, "end_pos": 68, "type": "TASK", "confidence": 0.7372334748506546}]}, {"text": "We begin by introducing some of the mathematical background needed for describing our approach (Section 2).", "labels": [], "entities": []}, {"text": "Next, we present our semantic space model (Section 3) and our evaluation experiments (Sections 4 and 5).", "labels": [], "entities": []}, {"text": "We conclude by discussing related work (Section 6).", "labels": [], "entities": []}], "datasetContent": [{"text": "Data All our experiments used a dependency parsed and lemmatized version of the British National Corpus (BNC).", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 80, "end_pos": 109, "type": "DATASET", "confidence": 0.9791919191678365}]}, {"text": "As mentioned in Section 3, we obtained dependencies from the output of the Stanford parser).", "labels": [], "entities": []}, {"text": "The BNC comprises 4,049 texts totalling approximately 100 million words.", "labels": [], "entities": [{"text": "BNC", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.6457465291023254}]}, {"text": "Evaluation Tasks We evaluated our model on word similarity and association.", "labels": [], "entities": []}, {"text": "Both tasks are employed routinely to assess how well semantic models predict human judgments of word relatedness.", "labels": [], "entities": []}, {"text": "We used the WordSim353 test collection () which consists of similarity judgments for word pairs.", "labels": [], "entities": [{"text": "WordSim353 test collection", "start_pos": 12, "end_pos": 38, "type": "DATASET", "confidence": 0.9641709725062052}]}, {"text": "Participants gave each pair a similarity rating using a 0 to 10 scale (e.g., tiger-cat are very similar, whereas delay-racism are not).", "labels": [], "entities": []}, {"text": "The average rating for each pair represents an estimate of the perceived similarity of the two words.", "labels": [], "entities": []}, {"text": "The collection contains ratings for 437 unique words (353 pairs) all of which appeared in our corpus.", "labels": [], "entities": []}, {"text": "Word association is a slightly different task: Participants are given a cue word (e.g., rice) and asked to name an associate in response (e.g., Chinese, wedding, food, white).", "labels": [], "entities": [{"text": "Word association", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7642115950584412}]}, {"text": "We used the norms collected by.", "labels": [], "entities": []}, {"text": "We estimated the strength of association between a cue and its associate, as the relative frequency with which it was named.", "labels": [], "entities": []}, {"text": "The norms contain 9,968 unique words (70,739 pairs) out of which 9,862 were found in our corpus, excluding multiword expressions.", "labels": [], "entities": []}, {"text": "For both tasks, we used correlation analysis to examine the degree of linear relationship between human ratings and model similarity values.", "labels": [], "entities": []}, {"text": "We report correlation coefficients using Spearman's rank correlation coefficient.", "labels": [], "entities": [{"text": "correlation", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9544841647148132}, {"text": "Spearman's rank correlation coefficient", "start_pos": 41, "end_pos": 80, "type": "METRIC", "confidence": 0.5633523821830749}]}, {"text": "Quantum Model Parameters The quantum framework presented in Section 3 is quite flexible.", "labels": [], "entities": []}, {"text": "Depending on the choice of dependency relations Rel, dependency clusters RC j , and complex values \u03b1 j = e i\u03b8 j , different classes of models can be derived.", "labels": [], "entities": []}, {"text": "To explore these parameters, we partitioned the WordSim353 dataset and norms into a development and test set following a 70-30 split.", "labels": [], "entities": [{"text": "WordSim353 dataset", "start_pos": 48, "end_pos": 66, "type": "DATASET", "confidence": 0.9832557439804077}]}, {"text": "We tested 9 different intuitively chosen relation partitions {RC 1 , ..., RC n Part }, creating models that considered only neighboring heads, models that considered only neighboring dependents, and models that considered both.", "labels": [], "entities": []}, {"text": "For the latter two we experimented with partitions of one, two or three clusters.", "labels": [], "entities": []}, {"text": "In addition to these more coarse grained clusters, for models that included both heads and dependents we explored a partition with twelve clusters broadly corresponding to objects, subjects, modifiers, auxiliaries, determiners and soon.", "labels": [], "entities": []}, {"text": "In all cases stopwords were not taken into account in the construction of the semantic space.", "labels": [], "entities": []}, {"text": "For each model variant we performed a grid search over the possible phases \u03b8 j = k\u03c0 with range k = 0 4 , 1 4 , ..., 7 4 for the complex-valued \u03b1 j assigned to the respective relation cluster RC j (see Section 3.2 for details).", "labels": [], "entities": []}, {"text": "In general, we observed that the choice of dependency relations and their clustering as well as the phases assigned to each cluster greatly influenced the semantic space.", "labels": [], "entities": []}, {"text": "On both tasks, the best performing model had the relation partition described in Section 3.1.", "labels": [], "entities": []}, {"text": "Section 5 reports our results on the test set using this model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of distributional models on Word- Sim353 dataset and Nelson et al.'s (1998) norms (test  set). Correlation coefficients are all statistically signifi- cant (p < 0.01).", "labels": [], "entities": [{"text": "Word- Sim353 dataset", "start_pos": 50, "end_pos": 70, "type": "DATASET", "confidence": 0.9438175708055496}]}]}