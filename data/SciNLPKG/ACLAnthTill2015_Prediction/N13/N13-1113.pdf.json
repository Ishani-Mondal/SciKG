{"title": [{"text": "Improved Information Structure Analysis of Scientific Documents Through Discourse and Lexical Constraints", "labels": [], "entities": [{"text": "Improved Information Structure Analysis of Scientific Documents", "start_pos": 0, "end_pos": 63, "type": "TASK", "confidence": 0.8985292996679034}]}], "abstractContent": [{"text": "Inferring the information structure of scientific documents is useful for many downstream applications.", "labels": [], "entities": []}, {"text": "Existing feature-based machine learning approaches to this task require substantial training data and suffer from limited performance.", "labels": [], "entities": []}, {"text": "Our idea is to guide feature-based models with declarative domain knowledge encoded as posterior distribution constraints.", "labels": [], "entities": []}, {"text": "We explore a rich set of discourse and lexical constraints which we incorporate through the Generalized Expectation (GE) criterion.", "labels": [], "entities": [{"text": "Generalized Expectation (GE)", "start_pos": 92, "end_pos": 120, "type": "METRIC", "confidence": 0.7881659030914306}]}, {"text": "Our constrained model improves the performance of existing fully and lightly supervised models.", "labels": [], "entities": []}, {"text": "Even a fully unsupervised version of this model outperforms lightly supervised feature-based models, showing that our approach can be useful even when no labeled data is available.", "labels": [], "entities": []}], "introductionContent": [{"text": "Techniques that enable automatic analysis of the information structure of scientific articles can help scientists identify information of interest in the growing volume of scientific literature.", "labels": [], "entities": [{"text": "automatic analysis of the information structure of scientific articles", "start_pos": 23, "end_pos": 93, "type": "TASK", "confidence": 0.6095889939202203}]}, {"text": "For example, classification of sentences according to argumentative zones (AZ) -an information structure scheme that is applicable across scientific domains () -can support information retrieval, information extraction and summarization.", "labels": [], "entities": [{"text": "classification of sentences according to argumentative zones (AZ)", "start_pos": 13, "end_pos": 78, "type": "TASK", "confidence": 0.802301037311554}, {"text": "information retrieval", "start_pos": 173, "end_pos": 194, "type": "TASK", "confidence": 0.7595496773719788}, {"text": "information extraction", "start_pos": 196, "end_pos": 218, "type": "TASK", "confidence": 0.8559202551841736}, {"text": "summarization", "start_pos": 223, "end_pos": 236, "type": "TASK", "confidence": 0.9900742173194885}]}, {"text": "Previous work on sentence-based classification of scientific literature according to categories of information structure has mostly used feature-based machine learning, such as Support Vector Machines (SVM) and Conditional Random Fields (CRF) (e.g. ().", "labels": [], "entities": [{"text": "sentence-based classification of scientific literature according to categories of information structure", "start_pos": 17, "end_pos": 120, "type": "TASK", "confidence": 0.7946007414297624}]}, {"text": "Unfortunately, the performance of these methods is rather limited, as indicated e.g. by the relatively low numbers reported by in biochemistry and chemistry with per-class F-scores ranging from .18 to .76.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 172, "end_pos": 180, "type": "METRIC", "confidence": 0.9069977402687073}]}, {"text": "We propose a novel approach to this task in which traditional feature-based models are augmented with explicit declarative expert and domain knowledge, and apply it to sentence-based AZ.", "labels": [], "entities": []}, {"text": "We explore two sources of declarative knowledge for our task -discourse and lexical.", "labels": [], "entities": []}, {"text": "One way to utilize discourse knowledge is to guide the model predictions by encoding a desired predicted class (i.e. information category) distribution in a given position in the document.", "labels": [], "entities": []}, {"text": "Consider, for example, sentence (1) from the first paragraph of the Discussion section in a paper: (1) In time, this will prove to be most suitable for detailed analysis of the role of these hormones in mammary cancer development.", "labels": [], "entities": [{"text": "mammary cancer development", "start_pos": 203, "end_pos": 229, "type": "TASK", "confidence": 0.7356489698092142}]}, {"text": "Although the future tense and cue phrases such as \"in time\" can indicate that authors are discussing future work (i.e. the \"Future work\" class in the AZ scheme), in this case they refer to their own contribution (i.e. the \"Conclusion\" class in AZ).", "labels": [], "entities": []}, {"text": "As most authors discuss their own contribution in the beginning of the Discussion section and future directions in the end, encoding the desired class distribution as a function of the position in this section can guide the model to the right decision.", "labels": [], "entities": []}, {"text": "Likewise, lexical knowledge can guide the model through predicted class distributions for sentences that contain specific vocabulary.", "labels": [], "entities": []}, {"text": "Consider, for example, sentence (2): (2) The values calculated for lungs include the presumed DNA adduct of BA and might thus be slightly overestimated.", "labels": [], "entities": [{"text": "presumed DNA adduct of", "start_pos": 85, "end_pos": 107, "type": "METRIC", "confidence": 0.773113489151001}, {"text": "BA", "start_pos": 108, "end_pos": 110, "type": "METRIC", "confidence": 0.6543435454368591}]}, {"text": "The verb \"calculated\" usually indicates the \"Method\" class, but, when accompanied by the modal verb \"might\", it is more likely to imply that authors are interpreting their own results (i.e. the \"Conclusion\" class in AZ).", "labels": [], "entities": []}, {"text": "This can be explicitly encoded in the model through a target distribution for sentences containing certain modal verbs.", "labels": [], "entities": []}, {"text": "Recent work has shown that explicit declaration of domain and expert knowledge can be highly useful for structured NLP tasks such as parsing, POS tagging and information extraction (.", "labels": [], "entities": [{"text": "parsing", "start_pos": 133, "end_pos": 140, "type": "TASK", "confidence": 0.9773971438407898}, {"text": "POS tagging", "start_pos": 142, "end_pos": 153, "type": "TASK", "confidence": 0.8648815453052521}, {"text": "information extraction", "start_pos": 158, "end_pos": 180, "type": "TASK", "confidence": 0.7938992977142334}]}, {"text": "These works have encoded expert knowledge through constraints, with different frameworks differing in the type of constraints and the inference and learning algorithms used.", "labels": [], "entities": []}, {"text": "We build on the Generalized Expectation (GE) framework) which encodes expert knowledge through a preference (i.e. soft) constraints for parameter settings for which the predicted label distribution matches a target distribution.", "labels": [], "entities": [{"text": "Generalized Expectation (GE)", "start_pos": 16, "end_pos": 44, "type": "TASK", "confidence": 0.5758104860782624}]}, {"text": "In order to integrate domain knowledge with a features-based model, we develop a simple taxonomy of constraints (i.e. desired class distributions) and employ a top-down classification algorithm on top of a Maximum Entropy Model augmented with GE constraints.", "labels": [], "entities": []}, {"text": "This algorithm enables us to break the multi-class prediction into a pipeline of consecutive, simpler predictions which can be better assisted by the encoded knowledge.", "labels": [], "entities": []}, {"text": "We experiment in the biological domain with the eight-category AZ scheme) adapted from () and described in).", "labels": [], "entities": []}, {"text": "The results show that our constrained model substantially outperforms a baseline unconstrained Maximum Entropy Model.", "labels": [], "entities": []}, {"text": "While this type of constrained models have previously improved the feature-based model performance mostly in the weakly supervised and domain adaptation scenarios (e.g. (), we demonstrate substantial gains both when the Maximum En- work inconsistent with the current work Future work (FUT) the potential future direction of the research tropy Model is fully trained and when its training data is sparse.", "labels": [], "entities": [{"text": "Maximum En- work", "start_pos": 220, "end_pos": 236, "type": "METRIC", "confidence": 0.7367161884903908}, {"text": "FUT", "start_pos": 285, "end_pos": 288, "type": "METRIC", "confidence": 0.7328246831893921}]}, {"text": "This demonstrates the importance of expert knowledge for our task and supports our modeling decision that combines feature-based methods with domain knowledge encoded via constraints..", "labels": [], "entities": []}, {"text": "Because manual annotation is prohibitively expensive, approaches based on light supervision are now emerging for the task, including those based on active learning and self-training (Guo et al., 2011) and unsupervised methods (.", "labels": [], "entities": []}, {"text": "Unfortunately, these approaches do not reach the performance level of fully supervised models, let alone exceed it.", "labels": [], "entities": []}, {"text": "Our novel method addresses this problem.", "labels": [], "entities": []}, {"text": "Declarative knowledge and constraints Previous work has shown that incorporating declarative constraints into feature-based machine learning models works well in many NLP tasks.", "labels": [], "entities": []}, {"text": "Such constraints can be used in a semi-supervised or unsupervised fashion.", "labels": [], "entities": []}, {"text": "For example, shows that using CRF in conjunction with auxiliary constraints on unlabeled data significantly outperforms traditional CRF in information extraction, and shows that using declarative constraints alone for unsupervised learning achieves good results in text classification.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 139, "end_pos": 161, "type": "TASK", "confidence": 0.7938320934772491}, {"text": "text classification", "start_pos": 265, "end_pos": 284, "type": "TASK", "confidence": 0.8400384783744812}]}, {"text": "We show that declarative constraints can be highly useful for the identification of information structure of scientific documents.", "labels": [], "entities": [{"text": "identification of information structure of scientific documents", "start_pos": 66, "end_pos": 129, "type": "TASK", "confidence": 0.8276779225894383}]}, {"text": "In contrast with most previous works, we show that such constraints can improve the performance of a fully supervised model.", "labels": [], "entities": []}, {"text": "The constraints are particularly helpful for identifying low-frequency information categories, but still yield high performance on high-frequency categories.", "labels": [], "entities": []}], "datasetContent": [{"text": "Data We used the full paper corpus used by which contains 8171 sentences from 50 biomedical journal articles.", "labels": [], "entities": []}, {"text": "The corpus is annotated according to the AZ scheme described in.", "labels": [], "entities": [{"text": "AZ", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.8589409589767456}]}, {"text": "AZ describes the logical structure, scientific argumentation and intellectual attribution of a scientific paper.", "labels": [], "entities": [{"text": "AZ", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.5107259154319763}]}, {"text": "It was originally introduced by and applied to computational linguistics papers, and later adapted to other domains such as biology () -which we used in this work -and chemistry.", "labels": [], "entities": []}, {"text": "shows the AZ class distribution in full articles as well as in individual sections.", "labels": [], "entities": [{"text": "AZ", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.8732962012290955}]}, {"text": "Since section names vary across scientific articles, we grouped similar sections before calculating the statistics (e.g. Discussion and Conclusions sections were grouped under Discussion).", "labels": [], "entities": []}, {"text": "We can see that although there is a major category in each section (e.g. CON in Discussion), up to 36.5% of the sentences in each section still belong to other categories.", "labels": [], "entities": []}, {"text": "Features We extracted the following features from each sentence and used them in the featurebased classifiers: (1) Discourse features: location in the article/section/paragraph.", "labels": [], "entities": []}, {"text": "For this feature each text batch was divided to ten equal size parts and the corresponding feature value identifies the relevant part; (2) Lexical features: number of citations and references to tables and figures (0, 1, or more), word, bi-gram, verb, and verb class (obtained by spectral clustering); (3) Syntactic features: tense and voice (POS tags of main and auxiliary verbs), grammatical relation, subject and object.", "labels": [], "entities": []}, {"text": "The lexical and the syntactic features were extracted for the represented sentence as well as for its surrounding sentences.", "labels": [], "entities": []}, {"text": "We used the C&C POS tagger and parser) for extracting the lexical and the syntactic features.", "labels": [], "entities": []}, {"text": "Note that all the information encoded into our constraints is also encoded in the features and is thus available to the feature-based model.", "labels": [], "entities": []}, {"text": "This enables us to properly evaluate the impact of our modeling decision which augments a feature-based model with constraints.", "labels": [], "entities": []}, {"text": "Baselines We compared our model against four baselines, two with full supervision: Support Vector Machines (SVM) and Maximum Entropy Models (MaxEnt), and two with light supervision: Trans-  ductive SVM (TSVM) and semi-supervised MaxEnt based on Entropy Regularization (ER)).", "labels": [], "entities": []}, {"text": "SVM and MaxEnt have proved successful in information structure analysis (e.g. () but, to the best of our knowledge, their semi-supervised versions have not been used for AZ of full articles.", "labels": [], "entities": [{"text": "SVM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8887016773223877}, {"text": "information structure analysis", "start_pos": 41, "end_pos": 71, "type": "TASK", "confidence": 0.8234384854634603}, {"text": "AZ", "start_pos": 170, "end_pos": 172, "type": "METRIC", "confidence": 0.8721773028373718}]}, {"text": "Parameter tuning The boundaries of the reference probabilities (a k and bk in Equation) were defined and optimized on the development data which consists of one third of the corpus.", "labels": [], "entities": []}, {"text": "We con- Evaluation We evaluated the precision, recall and F-score for each category, using a standard ten-fold cross-validation scheme.", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9997310042381287}, {"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9992050528526306}, {"text": "F-score", "start_pos": 58, "end_pos": 65, "type": "METRIC", "confidence": 0.9984198808670044}]}, {"text": "The models were tested on each of the ten folds and trained on the rest of them, and the results were averaged across the ten folds.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Class distribution (shown in percentages) in articles", "labels": [], "entities": []}, {"text": " Table 5: Performance of baselines on the Discussion section.", "labels": [], "entities": []}, {"text": " Table 6: Discussion section performance of MaxEnt, MaxEnt+GE and a MaxEnt+GE model that does not include our top-down", "labels": [], "entities": [{"text": "MaxEnt+GE", "start_pos": 52, "end_pos": 61, "type": "DATASET", "confidence": 0.6025746862093607}]}, {"text": " Table 7: Discussion section performance of the MaxEnt, Max-", "labels": [], "entities": [{"text": "MaxEnt", "start_pos": 48, "end_pos": 54, "type": "DATASET", "confidence": 0.9301222562789917}]}, {"text": " Table 8: Analysis of the impact of the different constraint types", "labels": [], "entities": []}]}