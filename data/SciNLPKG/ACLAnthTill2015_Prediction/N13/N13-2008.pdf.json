{"title": [{"text": "Statistical Machine Translation in Low Resource Settings", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8014408747355143}]}], "abstractContent": [{"text": "My thesis will explore ways to improve the performance of statistical machine translation (SMT) in low resource conditions.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 58, "end_pos": 95, "type": "TASK", "confidence": 0.8179596463839213}]}, {"text": "Specifically , it aims to reduce the dependence of modern SMT systems on expensive parallel data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.9942619800567627}]}, {"text": "We define low resource settings as having only small amounts of parallel data available , which is the case for many language pairs.", "labels": [], "entities": []}, {"text": "All current SMT models use parallel data during training for extracting translation rules and estimating translation probabilities.", "labels": [], "entities": [{"text": "SMT", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9924255609512329}, {"text": "extracting translation rules", "start_pos": 61, "end_pos": 89, "type": "TASK", "confidence": 0.8479951421419779}]}, {"text": "The theme of our approach is the integration of information from alternate data sources, other than parallel corpora, into the statistical model.", "labels": [], "entities": []}, {"text": "In particular, we focus on making use of large monolingual and comparable corpora.", "labels": [], "entities": []}, {"text": "By augmenting components of the SMT framework, we hope to extend its applicability beyond the small handful of language pairs with large amounts of available parallel text.", "labels": [], "entities": [{"text": "SMT", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.9896066784858704}]}], "introductionContent": [{"text": "Statistical machine translation (SMT) systems are heavily dependent on parallel data.", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8085847049951553}]}, {"text": "SMT doesn't work well when fewer than several million lines of bitext are available (.", "labels": [], "entities": [{"text": "SMT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9277394413948059}]}, {"text": "When the available bitext is small, statistical models perform poorly due to the sparse word and phrase counts that define their parameters.", "labels": [], "entities": []}, {"text": "gives a learning curve that shows this effect.", "labels": [], "entities": []}, {"text": "As the amount of bitext approaches zero, performance drops drastically.", "labels": [], "entities": []}, {"text": "In this thesis, we seek to modify the SMT model to reduce its dependence on parallel data and, thus, enable it to apply to new language pairs.", "labels": [], "entities": [{"text": "SMT", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.99111008644104}]}, {"text": "Specifically, we plan to address the following challenges that arise when using SMT systems in low resource conditions: \u2022 Translating unknown words.", "labels": [], "entities": [{"text": "SMT", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.9920458793640137}, {"text": "Translating unknown words", "start_pos": 122, "end_pos": 147, "type": "TASK", "confidence": 0.8936381141344706}]}, {"text": "In the context of SMT, unknown words (or out-of-vocabulary, OOV) are defined as having never appeared in the source side of the training parallel corpus.", "labels": [], "entities": [{"text": "SMT", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.996145486831665}]}, {"text": "When the training corpus is small, the percent of words which are unknown can be high.", "labels": [], "entities": []}, {"text": "In high resource conditions, a word aligned bitext is used to extract a list of phrase pairs or translation rules which are used to translate new sentences.", "labels": [], "entities": []}, {"text": "With more parallel data, this list is increasingly comprehensive.", "labels": [], "entities": []}, {"text": "Using multi-word phrases instead of individual words as the basic translation unit has been shown to increase translation performance (.", "labels": [], "entities": [{"text": "translation", "start_pos": 110, "end_pos": 121, "type": "TASK", "confidence": 0.9678614139556885}]}, {"text": "However, when the parallel corpus is small, so is the number of phrase pairs that can be extracted.", "labels": [], "entities": []}, {"text": "In the standard SMT pipeline, translation probabilities are estimated using relative frequency counts over the training bitext.", "labels": [], "entities": [{"text": "SMT", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9949665665626526}, {"text": "translation", "start_pos": 30, "end_pos": 41, "type": "TASK", "confidence": 0.9534360766410828}]}, {"text": "However, when the bitext counts are sparse, probability esti- mates are likely to be noisy.", "labels": [], "entities": []}, {"text": "My thesis focuses on translating into English.", "labels": [], "entities": [{"text": "translating into English", "start_pos": 21, "end_pos": 45, "type": "TASK", "confidence": 0.8859309156735738}]}, {"text": "We assume access to a small amount of parallel data, which is realistic, especially considering the recent success of crowdsourcing translations).", "labels": [], "entities": []}, {"text": "Additionally, we assume access to larger monolingual corpora.", "labels": [], "entities": []}, {"text": "lists the 22 languages for which we plan to perform translation experiments, along with the total amount of monolingual data that we will use for each.", "labels": [], "entities": []}, {"text": "We use web crawled time-stamped news articles and Wikipedia for each language.", "labels": [], "entities": []}, {"text": "We have extracted the Wikipedia pages which are inter-lingually linked to English pages.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Millions of monolingual web crawl and", "labels": [], "entities": []}, {"text": " Table 2: Top-10 Accuracy on test set. Performance", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9868805408477783}]}, {"text": " Table 3: Information about datasets released by", "labels": [], "entities": []}, {"text": " Table 4: BLEU performance gains that target coverage and accuracy separately and together. We add the top-K", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9977066516876221}, {"text": "coverage", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9804691672325134}, {"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9989492297172546}]}]}