{"title": [{"text": "Large-Scale Paraphrasing for Natural Language Understanding", "labels": [], "entities": []}], "abstractContent": [{"text": "We examine the application of data-driven paraphrasing to natural language understanding.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 58, "end_pos": 88, "type": "TASK", "confidence": 0.658948282400767}]}, {"text": "We leverage bilingual parallel corpora to extract a large collection of syntactic paraphrase pairs, and introduce an adaptation scheme that allows us to tackle a variety of text transformation tasks via paraphrasing.", "labels": [], "entities": [{"text": "text transformation", "start_pos": 173, "end_pos": 192, "type": "TASK", "confidence": 0.7205597460269928}]}, {"text": "We evaluate our system on the sentence compression task.", "labels": [], "entities": [{"text": "sentence compression task", "start_pos": 30, "end_pos": 55, "type": "TASK", "confidence": 0.7943700949350992}]}, {"text": "Further, we use distributional similarity measures based on context vectors derived from large monolingual corpora to annotate our paraphrases with an orthogonal source of information.", "labels": [], "entities": []}, {"text": "This yields significant improvements in our compression system's output quality, achieving state-of-the-art performance.", "labels": [], "entities": []}, {"text": "Finally, we propose a refinement of our paraphrases by classifying them into natural logic entailment relations.", "labels": [], "entities": []}, {"text": "By extending the synchronous parsing paradigm towards these entailment relations, we will enable our system to perform recognition of textual en-tailment.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this work, we propose an extension of current paraphrasing methods to tackle natural language understanding problems.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 80, "end_pos": 110, "type": "TASK", "confidence": 0.6656248966852824}]}, {"text": "We create a large set of paraphrase pairs in a data-driven fashion, rank them based on a variety of similarity metrics, and attach an entailment relation to each pair, facilitating natural logic inference.", "labels": [], "entities": []}, {"text": "The resulting resource has potential applications to a variety of NLP applications, including summarization, query expansion, question answering, and recognizing textual entailment.", "labels": [], "entities": [{"text": "summarization", "start_pos": 94, "end_pos": 107, "type": "TASK", "confidence": 0.9841931462287903}, {"text": "query expansion", "start_pos": 109, "end_pos": 124, "type": "TASK", "confidence": 0.6922347396612167}, {"text": "question answering", "start_pos": 126, "end_pos": 144, "type": "TASK", "confidence": 0.8942635953426361}, {"text": "recognizing textual entailment", "start_pos": 150, "end_pos": 180, "type": "TASK", "confidence": 0.8437155485153198}]}, {"text": "Specifically, we build on Callison-Burch (2007)'s pivot-based paraphrase extraction method, which uses bilingual parallel data to learn English phrase pairs that share the same meaning.", "labels": [], "entities": [{"text": "paraphrase extraction", "start_pos": 62, "end_pos": 83, "type": "TASK", "confidence": 0.670220136642456}]}, {"text": "Our approach extends the pivot method to learn meaning-preserving syntactic transformations in English.", "labels": [], "entities": []}, {"text": "We represent these using synchronous context-free grammars (SCFGs).", "labels": [], "entities": []}, {"text": "This representation allows us to re-use a lot of machine translation machinery to perform monolingual text-to-text generation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.7434690594673157}, {"text": "text-to-text generation", "start_pos": 102, "end_pos": 125, "type": "TASK", "confidence": 0.7050462812185287}]}, {"text": "We demonstrate the method on a sentence compression task ().", "labels": [], "entities": [{"text": "sentence compression task", "start_pos": 31, "end_pos": 56, "type": "TASK", "confidence": 0.7824694613615671}]}, {"text": "To improve the system, we then incorporate features based on monolingual distributional similarity.", "labels": [], "entities": []}, {"text": "This orthogonal source of signal allows us to re-scores the bilingually-extracted paraphrases using information drawn from large monolingual corpora.", "labels": [], "entities": []}, {"text": "We show that the monolingual distributional scores yield significant improvements over a baseline that scores paraphrases only with bilinguallyextracted features ().", "labels": [], "entities": []}, {"text": "Further, we propose a semantics for paraphrasing by classifying each paraphrase pair with one of the entailment relation types defined by natural logic.", "labels": [], "entities": []}, {"text": "Natural logic is used to perform inference over pairs of natural language phrases, like our paraphrase pairs.", "labels": [], "entities": []}, {"text": "It defines a set of relations including, equivalence (\u2261), forward-and backward-entailments (, ), antonyms (\u2227), and others.", "labels": [], "entities": []}, {"text": "We will build a classifier for our paraphrases that uses features extracted from annotated resources like WordNet and distributional information gathered overlarge text corpora to assign one or more entailment relations to each paraphrase pair.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 106, "end_pos": 113, "type": "DATASET", "confidence": 0.9543845653533936}]}, {"text": "We will evaluate the entailment assignments by applying this enhanced paraphrasing system to the task of recognizing textual entailment (RTE).", "labels": [], "entities": [{"text": "recognizing textual entailment (RTE)", "start_pos": 105, "end_pos": 141, "type": "TASK", "confidence": 0.6847544610500336}]}], "datasetContent": [{"text": "We propose evaluating the resulting system on textual entailment recognition.", "labels": [], "entities": [{"text": "textual entailment recognition", "start_pos": 46, "end_pos": 76, "type": "TASK", "confidence": 0.8129152059555054}]}, {"text": "To do this, we cast the RTE task as asynchronous parsing problem, as illustrated in.", "labels": [], "entities": [{"text": "RTE task", "start_pos": 24, "end_pos": 32, "type": "TASK", "confidence": 0.8387123048305511}]}, {"text": "We will extend the notion of synchronous parsing towards resolving entailments, and define and implement a compositional join operator to compute entailment relations over synchronous derivations from the individual rule entailments.", "labels": [], "entities": [{"text": "synchronous parsing", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.6917046010494232}]}, {"text": "While the assumption of asynchronous parse structure is likely to be valid for translations and paraphrases, we do not expect it to straightforwardly hold for entailment recognition.", "labels": [], "entities": [{"text": "translations and paraphrases", "start_pos": 79, "end_pos": 107, "type": "TASK", "confidence": 0.8282270828882853}, {"text": "entailment recognition", "start_pos": 159, "end_pos": 181, "type": "TASK", "confidence": 0.8911340832710266}]}, {"text": "We will thus investigate the limits of the synchronous assumption over RTE data.", "labels": [], "entities": []}, {"text": "Furthermore, to expand the system's coverage in a first step, we propose a simple relaxation of the synchronousness requirement via entailment-less \"glue rules.\"", "labels": [], "entities": []}, {"text": "These rules, similar to out-of-vocabulary rules in translation, will allow us to include potentially unrelated or unrecognized portions of the input into the synchronous parse.", "labels": [], "entities": []}, {"text": "For evaluation, we follow the task-based approach taken in Section 2 and apply the similarity-scored paraphrases to sentence compression.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 116, "end_pos": 136, "type": "TASK", "confidence": 0.7284664809703827}]}, {"text": "The distributional similarity scores are incorporated into the paraphrasing system as additional rule features into the log-linear model.", "labels": [], "entities": []}, {"text": "The task-targeted parameter tuning thus results in a reranking of the rules that takes into consideration, the distributional information, bilingual alignment-based paraphrase probabilities, and compression-centric features.", "labels": [], "entities": []}, {"text": "shows comparison of the bilingual baseline paraphrase grammar (PP), the reranked grammars based on signatures extracted from the Google n-grams (n-gram), the richer signatures drawn from Annotated Gigaword (Syntax), and Clarke and Lapata (2008)'s compression system (ILP).", "labels": [], "entities": []}, {"text": "In both cases, the inclusion of distributional similarity information results in significantly better output grammaticality and meaning retention.", "labels": [], "entities": []}, {"text": "Despite its lower coverage (12 versus 200 million phrases), the syntactic distributional similarity outperforms the simpler Google n-gram signatures.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results of the human evaluation on longer com-", "labels": [], "entities": [{"text": "longer com-", "start_pos": 45, "end_pos": 56, "type": "DATASET", "confidence": 0.9524049162864685}]}]}