{"title": [], "abstractContent": [{"text": "Topics generated automatically, e.g. using LDA, are now widely used in Computational Linguistics.", "labels": [], "entities": [{"text": "Computational Linguistics", "start_pos": 71, "end_pos": 96, "type": "TASK", "confidence": 0.7723598778247833}]}, {"text": "Topics are normally represented as a set of keywords, often then terms in a topic with the highest marginal probabilities.", "labels": [], "entities": []}, {"text": "We introduce an alternative approach in which topics are represented using images.", "labels": [], "entities": []}, {"text": "Candidate images for each topic are retrieved from the web by querying a search engine using the top n terms.", "labels": [], "entities": []}, {"text": "The most suitable image is selected from this set using a graph-based algorithm which makes use of textual information from the metadata associated with each image and features extracted from the images themselves.", "labels": [], "entities": []}, {"text": "We show that the proposed approach significantly outperforms several base-lines and can provide images that are useful to represent a topic.", "labels": [], "entities": []}], "introductionContent": [{"text": "Topic models are statistical methods for summarising the content of a document collection using latent variables known as topics).", "labels": [], "entities": [{"text": "summarising the content of a document collection", "start_pos": 41, "end_pos": 89, "type": "TASK", "confidence": 0.8185461418969291}]}, {"text": "Within a model, each topic is a multinomial distribution over words in the collection while documents are represented as distributions over topics.", "labels": [], "entities": []}, {"text": "Topic modelling is now widely used in Natural Language Processing (NLP) and has been applied to a range of tasks including word sense disambiguation, multi-document summarisation, information retrieval (), image labelling) and visualisation of document collections.", "labels": [], "entities": [{"text": "Topic modelling", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8028891682624817}, {"text": "word sense disambiguation", "start_pos": 123, "end_pos": 148, "type": "TASK", "confidence": 0.6840136647224426}, {"text": "multi-document summarisation", "start_pos": 150, "end_pos": 178, "type": "TASK", "confidence": 0.6425244212150574}, {"text": "information retrieval", "start_pos": 180, "end_pos": 201, "type": "TASK", "confidence": 0.7864862382411957}]}, {"text": "Topics are often represented by using then terms with the highest marginal probabilities in the topic to generate a set of keywords.", "labels": [], "entities": []}, {"text": "For example, wine, bottle, grape, flavour, dry.", "labels": [], "entities": []}, {"text": "Interpreting such lists may not be straightforward, particularly since there maybe no access to the source collection used to train the model.", "labels": [], "entities": []}, {"text": "Therefore, researchers have recently begun developing automatic methods to generate meaningful and representative labels for topics.", "labels": [], "entities": []}, {"text": "These techniques have focussed on the creation of textual labels ().", "labels": [], "entities": []}, {"text": "An alternative approach is to represent a topic using an illustrative image (or set of images).", "labels": [], "entities": []}, {"text": "Images have the advantage that they can be understood quickly and are language independent.", "labels": [], "entities": []}, {"text": "This is particularly important for applications in which the topics are used to provide an overview of a collection with many topics being shown simultaneously.", "labels": [], "entities": []}, {"text": "This paper explores the problem of selecting images to illustrate automatically generated topics.", "labels": [], "entities": []}, {"text": "Our approach generates a set of candidate images for each topic by querying an image search engine with the top n topic terms.", "labels": [], "entities": []}, {"text": "The most suitable image is selected using a graph-based method that makes use of both textual and visual information.", "labels": [], "entities": []}, {"text": "Textual information is obtained from the metadata associated with each image while visual features are extracted from the images themselves.", "labels": [], "entities": []}, {"text": "Our approach is evaluated using a data set created for this study that was annotated by crowdsourcing.", "labels": [], "entities": []}, {"text": "Results of the evaluation show that the proposed method significantly outperforms three baselines.", "labels": [], "entities": []}, {"text": "The contributions of this paper are as follows: (1) introduces the problem of labelling topics using images; (2) describes an approach to this problem that makes use of multimodal information to select images from a set of candidates; (3) introduces a data set to evaluate image labelling; and (4) evaluates the proposed approach using this data set.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section discusses the experimental design for evaluating the proposed approaches to labelling topics with images.", "labels": [], "entities": [{"text": "labelling topics with images", "start_pos": 89, "end_pos": 117, "type": "TASK", "confidence": 0.8699690401554108}]}, {"text": "To our knowledge no data set for evaluating these approaches is currently available and consequently we developed one for this study . Human judgements about the suitability of images are obtained through crowdsourcing.", "labels": [], "entities": []}, {"text": "Evaluation of the topic labelling methods is carried out using a similar approach to the framework proposed by for labelling topics using textual labels.", "labels": [], "entities": []}, {"text": "Top-1 average rating is the average human rating assigned to the top-ranked label proposed by the system.", "labels": [], "entities": [{"text": "Top-1 average rating", "start_pos": 0, "end_pos": 20, "type": "METRIC", "confidence": 0.7899235288302103}]}, {"text": "This provides an indication of the overall quality of the image the system judges as the best one.", "labels": [], "entities": []}, {"text": "The highest possible score averaged across all topics is 2.68, since for many topics the average score obtained from the human judgements is lower than 3.", "labels": [], "entities": []}, {"text": "The second evaluation measure is the normalized discounted cumulative gain (nDCG)) which compares the label ranking proposed by the system to the optimal ranking provided by humans.", "labels": [], "entities": [{"text": "normalized discounted cumulative gain (nDCG))", "start_pos": 37, "end_pos": 82, "type": "METRIC", "confidence": 0.7982682159968785}]}, {"text": "The discounted cumulative gain at position p (DCG p ) is computed using the following equation: where rel i is the relevance of the label to the topic in position i.", "labels": [], "entities": []}, {"text": "Then nDCG is computed as: where IDCG p is the optimal ranking of the image labels, in our experiments this is the ranking provided by the scores in the human annotated data set.", "labels": [], "entities": []}, {"text": "We follow in computing nDCG-1, nDCG-3 and nDCG-5 for the top 1, 3 and 5 ranked system image labels respectively.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results for various approaches to topic labelling.", "labels": [], "entities": [{"text": "topic labelling", "start_pos": 44, "end_pos": 59, "type": "TASK", "confidence": 0.6732032597064972}]}]}