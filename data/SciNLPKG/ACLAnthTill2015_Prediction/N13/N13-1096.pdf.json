{"title": [{"text": "Measuring the Structural Importance through Rhetorical Structure Index", "labels": [], "entities": [{"text": "Structural Importance", "start_pos": 14, "end_pos": 35, "type": "TASK", "confidence": 0.9127835929393768}]}], "abstractContent": [{"text": "In this paper, we propose a novel Rhetorical Structure Index (RSI) to measure the structural importance of a word or a phrase.", "labels": [], "entities": [{"text": "Rhetorical Structure Index (RSI)", "start_pos": 34, "end_pos": 66, "type": "METRIC", "confidence": 0.75069959461689}]}, {"text": "Unlike TF-IDF and other content-driven measurements , RSI identifies words or phrases that are structural cues in an unstructured document.", "labels": [], "entities": [{"text": "RSI identifies words or phrases that are structural cues in an unstructured document", "start_pos": 54, "end_pos": 138, "type": "TASK", "confidence": 0.6382787663203019}]}, {"text": "We show structurally motivated features with high RSI values are more useful than content-driven features for applications such as segmenting unstructured lecture transcripts into meaningful segments.", "labels": [], "entities": [{"text": "segmenting unstructured lecture transcripts into meaningful segments", "start_pos": 131, "end_pos": 199, "type": "TASK", "confidence": 0.7898600442068917}]}, {"text": "Experiments show that using RSI significantly improves the segmentation accuracy compared to TF-IDF, a traditional content-based feature weighting scheme.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 59, "end_pos": 71, "type": "TASK", "confidence": 0.9642943739891052}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9240936636924744}]}], "introductionContent": [{"text": "Online learning, anew trend in distance learning, provides numerous lectures to students allover the world.", "labels": [], "entities": []}, {"text": "More than 19,000 colleges offer thousands of free online lectures . Starting from video recordings of lectures which sometimes also come with the presentation material, a set of processes can be applied to extract information from the unstructured data to assist students in browsing, searching and understanding the content of the lecture.", "labels": [], "entities": []}, {"text": "These processes include automatic speech recognition (ASR) which converts the audio to text, lecture segmentation which inserts paragraph boundaries and adds section titles to the lecture transcriptions, automatic summarization that generates a short summary from the full lecture, and lecture translation that translates the lecture from the original language to the native language of the student.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 24, "end_pos": 58, "type": "TASK", "confidence": 0.7873236835002899}, {"text": "lecture segmentation", "start_pos": 93, "end_pos": 113, "type": "TASK", "confidence": 0.7228492796421051}, {"text": "lecture translation", "start_pos": 286, "end_pos": 305, "type": "TASK", "confidence": 0.7023112326860428}]}, {"text": "The transcription of a lecture generated by the ASR system is a sequence of words which does not contain any structural information such as paragraph, section boundaries and section titles.", "labels": [], "entities": [{"text": "ASR", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.9437621235847473}]}, {"text": "used acoustic and linguistic features for rhetorical structure detection and summarization.", "labels": [], "entities": [{"text": "rhetorical structure detection", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.9626034498214722}, {"text": "summarization", "start_pos": 77, "end_pos": 90, "type": "TASK", "confidence": 0.9722601175308228}]}, {"text": "They showed that linguistic features such as TF-IDF are the most influential in segmentation and summarization and that knowing the structure of a lecture can significantly improve the performance of lecture summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 97, "end_pos": 110, "type": "TASK", "confidence": 0.9833500385284424}]}, {"text": "Our experiments with a real-time lecture translation system also show that displaying the rolling translation results of a live lecture with proper paragraphing and inserted section titles makes it easier for students to grasp the key points during a lecture.", "labels": [], "entities": [{"text": "real-time lecture translation", "start_pos": 23, "end_pos": 52, "type": "TASK", "confidence": 0.750964899857839}]}, {"text": "In this paper, we apply existing algorithms, namely the Hidden Markov Model (HMM) ( to unstructured lecture transcription to infer the underlying structure for better lecture segmentation and summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 192, "end_pos": 205, "type": "TASK", "confidence": 0.9666750431060791}]}, {"text": "HMM has been successfully applied in early) for text segmentation, event tracking and boundary detection.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.8322597444057465}, {"text": "event tracking", "start_pos": 67, "end_pos": 81, "type": "TASK", "confidence": 0.7620943784713745}, {"text": "boundary detection", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.7580271661281586}]}, {"text": "The focus of this work is to identify cue words and phrases that are good indicators of lecture structure.", "labels": [], "entities": []}, {"text": "Intuitively, words and phrases such as \"last week we talked about\", \"this is an outline of my talk\", \"now I am going to talk about\", \"in conclusion\", and \"any questions\" should be important features to recognize lecture structure.", "labels": [], "entities": []}, {"text": "These words/phrases, however, may not be so important content-wise.", "labels": [], "entities": []}, {"text": "Thus, content-driven metrics such as the TF-IDF score usually do not assign higher weights to these structurally important words/phrases.", "labels": [], "entities": [{"text": "TF-IDF score", "start_pos": 41, "end_pos": 53, "type": "METRIC", "confidence": 0.6697236001491547}]}, {"text": "We propose a novel metric called Rhetorical Structural Index (RSI) to weigh words/phrases based on their structural importance.", "labels": [], "entities": [{"text": "Rhetorical Structural Index (RSI)", "start_pos": 33, "end_pos": 66, "type": "METRIC", "confidence": 0.7281971474488577}]}], "datasetContent": [{"text": "We evaluated segmentation on three different data sets: college lectures recorded by Karlsruhe Institute of Technology (KIT), Microsoft research (MSR) lectures 2 and scientific papers 3 . Both college and Microsoft research lectures are manually transcribed.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 13, "end_pos": 25, "type": "TASK", "confidence": 0.9737564325332642}]}, {"text": "The reason why we do not include experiments on ASR output is that current ASR quality of lecture data is still quite poor.", "labels": [], "entities": [{"text": "ASR output", "start_pos": 48, "end_pos": 58, "type": "TASK", "confidence": 0.8711775243282318}, {"text": "ASR", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.9797914624214172}]}, {"text": "Word-Error-Rates (WER) of ASR output range from 24.37 to 30.80 for KIT lectures.", "labels": [], "entities": [{"text": "Word-Error-Rates (WER)", "start_pos": 0, "end_pos": 22, "type": "METRIC", "confidence": 0.8644417524337769}, {"text": "ASR", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9441054463386536}, {"text": "KIT lectures", "start_pos": 67, "end_pos": 79, "type": "DATASET", "confidence": 0.8111024796962738}]}, {"text": "Roughly speaking, everyone out of 3 or 4 words is mis-recognized.", "labels": [], "entities": []}, {"text": "For evaluation, human annotators annotated a few lectures to create test/reference sets.", "labels": [], "entities": []}, {"text": "The test data from KIT is annotated by one human annotator and MSR lectures are annotated by four annotators.", "labels": [], "entities": [{"text": "KIT", "start_pos": 19, "end_pos": 22, "type": "DATASET", "confidence": 0.8562378287315369}]}, {"text": "The segmentation gold standard is created based on the agreed annotations.", "labels": [], "entities": [{"text": "segmentation gold standard", "start_pos": 4, "end_pos": 30, "type": "DATASET", "confidence": 0.8159303863843282}]}, {"text": "Since the number of annotated lectures is small and human annotation is subjective, we also used ACL papers as an additional data set.", "labels": [], "entities": [{"text": "ACL papers", "start_pos": 97, "end_pos": 107, "type": "DATASET", "confidence": 0.8071321547031403}]}, {"text": "ACL papers are in away \"lectures in written form\" and have titles for section and subsections which can be used to identify the segments and annotate the data set automatically.", "labels": [], "entities": [{"text": "ACL papers", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9234370589256287}]}, {"text": "The statistics of each data set are listed in.: Statistics of three data sets used in the experiments: our own lecture data (KIT), Microsoft research talks (MSR) and conference proceedings from ACL anthology archive.", "labels": [], "entities": [{"text": "ACL anthology archive", "start_pos": 194, "end_pos": 215, "type": "DATASET", "confidence": 0.962553342183431}]}, {"text": "We removed equations, short titles such as \"Abstract\" and \"Conclusion\", when extracting text from PDF files from the ACL anthology, which results in a relatively small number of words per paper.", "labels": [], "entities": [{"text": "ACL anthology", "start_pos": 117, "end_pos": 130, "type": "DATASET", "confidence": 0.8304923474788666}]}, {"text": "Words are simply tokenized without case normalization or stemming, which results in relatively large vocabulary sizes.", "labels": [], "entities": [{"text": "case normalization", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.6650162190198898}]}], "tableCaptions": [{"text": " Table 1: Examples of n-grams with high RSI values  which are likely to be structural cues.", "labels": [], "entities": []}, {"text": " Table 2: Statistics of three data sets used in the exper- iments: our own lecture data (KIT), Microsoft research  talks (MSR) and conference proceedings from ACL an- thology archive. We removed equations, short titles such  as \"Abstract\" and \"Conclusion\", when extracting text  from PDF files from the ACL anthology, which results  in a relatively small number of words per paper. Words  are simply tokenized without case normalization or stem- ming, which results in relatively large vocabulary sizes.", "labels": [], "entities": [{"text": "ACL an- thology archive", "start_pos": 159, "end_pos": 182, "type": "DATASET", "confidence": 0.6134611427783966}]}, {"text": " Table 3: Segmentation results measured by P k (the  smaller the better), Precision, Recall and F-Measure  scores (the higher the better) for three data sets compar- ing HMM using TF-IDF*-filtered word tokens as emis- sion and RSI-filtered words as emissions.", "labels": [], "entities": [{"text": "Precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9991089701652527}, {"text": "Recall", "start_pos": 85, "end_pos": 91, "type": "METRIC", "confidence": 0.9933783411979675}, {"text": "F-Measure", "start_pos": 96, "end_pos": 105, "type": "METRIC", "confidence": 0.9919732809066772}]}]}