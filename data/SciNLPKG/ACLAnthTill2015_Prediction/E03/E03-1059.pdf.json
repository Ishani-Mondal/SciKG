{"title": [{"text": "A Comparison of Event Models for Naive Bayes Anti-Spam E-Mail Filtering", "labels": [], "entities": [{"text": "Naive Bayes Anti-Spam E-Mail Filtering", "start_pos": 33, "end_pos": 71, "type": "TASK", "confidence": 0.7781667947769165}]}], "abstractContent": [{"text": "We describe experiments with a Naive Bayes text classifier in the context of anti-spam E-mail filtering, using two different statistical event models: a mul-ti-variate Bernoulli model and a multi-nomial model.", "labels": [], "entities": [{"text": "anti-spam E-mail filtering", "start_pos": 77, "end_pos": 103, "type": "TASK", "confidence": 0.6099067330360413}]}, {"text": "We introduce a family of feature ranking functions for feature selection in the multinomial event model that take account of the word frequency information.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.7031797468662262}]}, {"text": "We present evaluation results on two publicly available corpora of legitimate and spam E-mails.", "labels": [], "entities": []}, {"text": "We find that the multinomial model is less biased towards one class and achieves slightly higher accuracy than the multi-variate Bernoulli model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9991304278373718}]}], "introductionContent": [{"text": "Text categorization is the task of assigning a text document to one of several predefined categories.", "labels": [], "entities": [{"text": "Text categorization", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7973297238349915}]}, {"text": "Text categorization plays an important role in natural language processing (NLP) and information retrieval (IR) applications.", "labels": [], "entities": [{"text": "Text categorization", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7705942094326019}, {"text": "natural language processing (NLP)", "start_pos": 47, "end_pos": 80, "type": "TASK", "confidence": 0.7873257001241049}, {"text": "information retrieval (IR)", "start_pos": 85, "end_pos": 111, "type": "TASK", "confidence": 0.8256011843681336}]}, {"text": "One particular application of text categorization is anti-spam E-mail filtering, where the goal is to block unsolicited messages with commercial or pornographic content (UCE, spam) from a user's E-mail stream, while letting other (legitimate) messages pass.", "labels": [], "entities": [{"text": "text categorization", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.704778328537941}, {"text": "anti-spam E-mail filtering", "start_pos": 53, "end_pos": 79, "type": "TASK", "confidence": 0.6082244614760081}]}, {"text": "Here, the task is to assign a message to one of two categories, legitimate and spam, based on the message's content.", "labels": [], "entities": []}, {"text": "In recent years, a growing body of research has applied machine learning techniques to text categorization and (anti-spam) E-mail filtering, including rule learning, Naive Bayes (, memory based learning (), decision trees, support vector machines () or combinations of different learners ().", "labels": [], "entities": [{"text": "text categorization", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.7305850684642792}, {"text": "E-mail filtering", "start_pos": 123, "end_pos": 139, "type": "TASK", "confidence": 0.7196067571640015}, {"text": "rule learning", "start_pos": 151, "end_pos": 164, "type": "TASK", "confidence": 0.7849348485469818}]}, {"text": "In these approaches a classifier is learned from training data rather than constructed by hand, which results in better and more robust classifiers.", "labels": [], "entities": []}, {"text": "The Naive Bayes classifier has been found particularly attractive for the task of text categorization because it performs surprisingly well in many application areas despite its simplicity.", "labels": [], "entities": [{"text": "Naive Bayes classifier", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.6388901670773824}, {"text": "text categorization", "start_pos": 82, "end_pos": 101, "type": "TASK", "confidence": 0.7619324326515198}]}, {"text": "Bayesian classifiers are based on a probabilistic model of text generation.", "labels": [], "entities": [{"text": "text generation", "start_pos": 59, "end_pos": 74, "type": "TASK", "confidence": 0.7235213667154312}]}, {"text": "A text is generated by first choosing a class according to some prior probability and then generating a text according to a class-specific distribution.", "labels": [], "entities": []}, {"text": "The model parameters are estimated from training examples that have been annotated with their correct class.", "labels": [], "entities": []}, {"text": "Given anew document, the classifier outputs the class which is most likely to have generated the document.", "labels": [], "entities": []}, {"text": "From a linguistic point of view, a document is made up of words, and the semantics of the document is determined by the meaning of the words and the linguistic structure of the document.", "labels": [], "entities": []}, {"text": "The Naive Bayesian classifier makes the simplifying assumption that the probability that a document is generated in some class depends only on the probabilities of the words given the context of the class, and that the words in a document are independent of each other.", "labels": [], "entities": []}, {"text": "This is called the Naive Bayes assumption.", "labels": [], "entities": []}, {"text": "The generative model underlying the Naive Bayes classifier can be characterized with respect to the amount of information it captures about the words in a document.", "labels": [], "entities": [{"text": "Naive Bayes classifier", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.7517378528912863}]}, {"text": "In information retrieval and text categorization, two types of models have been used.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 3, "end_pos": 24, "type": "TASK", "confidence": 0.8591202795505524}, {"text": "text categorization", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7928444445133209}]}, {"text": "Both assume that there is a fixed vocabulary.", "labels": [], "entities": []}, {"text": "In the first model, a document is generated by first choosing a subset of the vocabulary and then using the selected words any number of times, at least once, in any order.", "labels": [], "entities": []}, {"text": "This model is called multi-variate Bernoulli model.", "labels": [], "entities": []}, {"text": "It captures the information of which words are used in a document, but not the number of times each words is used, nor the order of the words in the document.", "labels": [], "entities": []}, {"text": "In the second model, a document is generated by choosing a set of word occurrences and arranging them in any order.", "labels": [], "entities": []}, {"text": "This model is called multinomial model.", "labels": [], "entities": []}, {"text": "In addition to the multi-variate Bernoulli model, it also captures the information about how many times a word is used in a document.", "labels": [], "entities": []}, {"text": "Note that in both models, a document can contain additional words that are not in the vocabulary, which are considered noise and are not used for classification.", "labels": [], "entities": []}, {"text": "Despite the fact that the multi-variate Bernoulli model captures less information about a document (compared to the multinomial model), it performs quite well in text categorization tasks, particularly when the set of words used for classification is small.", "labels": [], "entities": []}, {"text": "However, have shown that the multinomial model outperforms the multi-variate Bernoulli model on larger vocabulary sizes or when the vocabulary size is chosen optimal for both models.", "labels": [], "entities": []}, {"text": "Most text categorization approaches to antispam E-mail filtering have used the multi-variate Bernoulli model (.", "labels": [], "entities": [{"text": "antispam E-mail filtering", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.6968397796154022}]}, {"text": "used a multinomial model but did not compare it to the multi-variate model.", "labels": [], "entities": []}, {"text": "used a multinomial model in a different context.", "labels": [], "entities": []}, {"text": "In this paper we present results of experiments in which we evaluated the performance of a Naive Bayes classifier on two publicly available E-mail corpora, using both the multi-variate Bernoulli and the multinomial model.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "2 we describe the Naive Bayes classifier and the two generative models in more detail.", "labels": [], "entities": []}, {"text": "3 we introduce feature selection methods that take into account the extra information contained in the multinomial model.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.6810546666383743}]}, {"text": "4 we describe our experiments and discuss the results.", "labels": [], "entities": []}, {"text": "5 we draw some conclusions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Precision/recall breakeven points for Ling-Spam. Rows printed in italic show the point of  maximum accuracy in cases where precision and recall were different for all vocabulary sizes. Values  that are no more than 0.5% below the highest value in a column are printed in bold.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9457900524139404}, {"text": "recall breakeven points", "start_pos": 20, "end_pos": 43, "type": "METRIC", "confidence": 0.9131179451942444}, {"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9809710383415222}, {"text": "precision", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.9972967505455017}, {"text": "recall", "start_pos": 147, "end_pos": 153, "type": "METRIC", "confidence": 0.9956436157226562}]}, {"text": " Table 3: Precision/recall breakeven points for PUL", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9837610125541687}, {"text": "recall", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.9508267045021057}, {"text": "PUL", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.5409278273582458}]}]}