{"title": [{"text": "A Shallow Model of Backchannel Continuers in Spoken Dialogue", "labels": [], "entities": []}], "abstractContent": [{"text": "Spoken dialogue systems would be more acceptable if they were able to produce backchannel continuers such as mm-hmm in naturalistic locations during the user's utterances.", "labels": [], "entities": []}, {"text": "Using the HCRC Map Task Corpus as our data source, we describe models for predicting these locations using only limited processing and features of the user's speech that are commonly available, and which therefore could be used as a low-cost improvement for current systems.", "labels": [], "entities": [{"text": "HCRC Map Task Corpus", "start_pos": 10, "end_pos": 30, "type": "DATASET", "confidence": 0.9785198867321014}]}, {"text": "The baseline model inserts continuers after a predetermined number of words.", "labels": [], "entities": []}, {"text": "One further model correlates back-channel contin-uers with pause duration, while a second predicts their occurrence using trigram POS frequencies.", "labels": [], "entities": []}, {"text": "Combining these two models gives the best results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Ina spoken dialogue between people, the participants use simple utterances such as yeah, a totty wee bit aye and mm-hnint to signal that communication is working.", "labels": [], "entities": []}, {"text": "Without this feedback, the partner may assume that he has not been understood and reformulate his utterance.", "labels": [], "entities": []}, {"text": "Following, we will use the term backchannel for such utterances.", "labels": [], "entities": []}, {"text": "Although these can be substantive because they can repeat material from the partner's utterance, e.g., Right, okay, I'm below the fiat rocks, we will adopt)'s terminology of continuer.", "labels": [], "entities": [{"text": "continuer", "start_pos": 174, "end_pos": 183, "type": "METRIC", "confidence": 0.9796314835548401}]}, {"text": "We will take this to refer to the class of backchannel utterances, with minimal content, used to clearly signal that the speaker should continue with her current turn.", "labels": [], "entities": []}, {"text": "( point out that users of speech interface systems need feedback, too, especially since the system's silence could mean either of two very different things: that it is waiting for user input, in which case the user should speak, or that it is still processing information, in which case the user should not.", "labels": [], "entities": []}, {"text": "However, any feedback must come at the right time or else it risks disrupting the speaker and ultimately, delaying task completion ().", "labels": [], "entities": []}, {"text": "Most of our data, including the examples given above, are drawn from the HCRC Map Task Corpus, described in more detail in Section 3.", "labels": [], "entities": [{"text": "HCRC Map Task Corpus", "start_pos": 73, "end_pos": 93, "type": "DATASET", "confidence": 0.9828703254461288}]}, {"text": "Clearly these dialogues are significantly more complex than the kind of interactions supported by current commercial spoken dialogue systems, where the length of user utterances is severely constrained.", "labels": [], "entities": []}, {"text": "What kind of system would involve potentially lengthy user instructions comparable to those found in the Map Task?,, and describe work on building spoken dialogue systems for conversing with mobile robots, and this is a setting where complex instructions naturally arise.", "labels": [], "entities": []}, {"text": "For example, in one scenario, 1 users attempt to teach routes and route segments to a robot.", "labels": [], "entities": []}, {"text": "(1) is a portion of such an instruction.", "labels": [], "entities": []}, {"text": "(1) okay go to the end of the road and turn left and erm ... and then carry on down that road and then turn ...", "labels": [], "entities": []}, {"text": "take your second left where the trees are on the corner We describe a shallow model, based on human dialogue data, for predicting whereto place backchannel feedback.", "labels": [], "entities": []}, {"text": "The model deliberately requires only simple processing on information that spoken dialogue systems already keep as history, and is intended to support a low-cost improvement to existing technology.", "labels": [], "entities": []}, {"text": "'For details, seethe description of the IBL Project presented on http: //www. ltg. ed. ac . uk/dsea/.", "labels": [], "entities": [{"text": "IBL Project", "start_pos": 40, "end_pos": 51, "type": "DATASET", "confidence": 0.72324138879776}]}], "datasetContent": [{"text": "The best possible evaluation method, given our aim of low-cost technological improvement, would be to test the acceptability of a dialogue system before and after our models have been incorporated.", "labels": [], "entities": []}, {"text": "A potential second best option, having humans judge the naturalness of the models' results independent from a dialogue system, is problematic.", "labels": [], "entities": []}, {"text": "Conversational naturalness must be judged in a reasonable amount of left and righthand context.", "labels": [], "entities": []}, {"text": "We could doctor a conversation by excising the real follower's backchannel continuers and re-inserting randomly selected ones where each model predicts, but the results would be judged unnatural because of the knock-on effects on subsequent utterances.", "labels": [], "entities": []}, {"text": "A speaker's timings differ depending on whether or not his partner produces a backchannel, and it is difficult to test system insertion of a backchannel where the follower actually produces a more substantive utterance.", "labels": [], "entities": [{"text": "timings", "start_pos": 12, "end_pos": 19, "type": "METRIC", "confidence": 0.9630712866783142}]}, {"text": "Thus we have chosen the less explanatory but time-honoured evaluation method of comparing the be- Precision 39% Recall 36% F-measure 37%: Results of the best model on high backchannel rate data haviour of our models to what the humans in the corpus do.", "labels": [], "entities": [{"text": "Recall", "start_pos": 112, "end_pos": 118, "type": "METRIC", "confidence": 0.6494826674461365}, {"text": "F-measure", "start_pos": 123, "end_pos": 132, "type": "METRIC", "confidence": 0.7682836055755615}]}, {"text": "One difficulty with evaluating a model such as ours is that human speakers differ markedly in their own backchanneling behaviour.", "labels": [], "entities": []}, {"text": "As Ward and Tsukahara (2000) remark, \"a rule can predict opportunities, but respondents do not choose to produce back-channel feedback at every opportunity\".", "labels": [], "entities": []}, {"text": "Because we cannot identify the opportunities that humans pass up, we do the second best thing: cite results both in general and fora relatively high level of backchannel in the corpus.", "labels": [], "entities": []}, {"text": "Our reasoning here is that the more backchannels an individual produces, the fewer opportunities they are likely to have passed up.", "labels": [], "entities": []}, {"text": "The models were run on previously unseen test data, the results of which can be seen in.", "labels": [], "entities": []}, {"text": "All models improved on the training models.", "labels": [], "entities": []}, {"text": "The baseline model was the worst performer with an F-measure of only 7%.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9997106194496155}]}, {"text": "The trigram part-of-speech model and the pause duration models had very similar results, with the pause duration model proving to be a slightly better predictor.", "labels": [], "entities": []}, {"text": "The combined model improved the F-measure and importantly the precision.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.985321581363678}, {"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9995798468589783}]}, {"text": "The best model was a five-fold improvement over the baseline.", "labels": [], "entities": []}, {"text": "If we now modify our test set so that it reproduces the behaviour of a speaker with a higher rate of backchannel, we see signficantly improved results.", "labels": [], "entities": []}, {"text": "Thus, running the model on the dialogue containing eighty backchannel continuers gives a much higher precision rate, improving upon the best model by 10% as can be seen in.", "labels": [], "entities": [{"text": "precision", "start_pos": 101, "end_pos": 110, "type": "METRIC", "confidence": 0.9994182586669922}]}], "tableCaptions": [{"text": " Table 1: Frequency of Acknowledgements", "labels": [], "entities": [{"text": "Frequency of Acknowledgements", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.6406044960021973}]}, {"text": " Table 2: Highest Performing Pause Duration Models", "labels": [], "entities": [{"text": "Pause Duration", "start_pos": 29, "end_pos": 43, "type": "TASK", "confidence": 0.5980743169784546}]}, {"text": " Table 3: Discounted Trigram Frequencies in the CMU- Cambridge Language Model", "labels": [], "entities": [{"text": "CMU- Cambridge Language Model", "start_pos": 48, "end_pos": 77, "type": "DATASET", "confidence": 0.932394015789032}]}, {"text": " Table 5: Results of the Models on the Test Data", "labels": [], "entities": []}]}