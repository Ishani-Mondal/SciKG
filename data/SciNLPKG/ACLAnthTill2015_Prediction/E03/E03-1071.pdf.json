{"title": [{"text": "Investigating GIS and Smoothing for Maximum Entropy Taggers", "labels": [], "entities": [{"text": "Smoothing for Maximum Entropy Taggers", "start_pos": 22, "end_pos": 59, "type": "TASK", "confidence": 0.7245965957641601}]}], "abstractContent": [{"text": "This paper investigates two elements of Maximum Entropy tagging: the use of a correction feature in the Gener-alised Iterative Scaling (Gis) estimation algorithm, and techniques for model smoothing.", "labels": [], "entities": [{"text": "Maximum Entropy tagging", "start_pos": 40, "end_pos": 63, "type": "TASK", "confidence": 0.6389675736427307}, {"text": "model smoothing", "start_pos": 182, "end_pos": 197, "type": "TASK", "confidence": 0.7280408143997192}]}, {"text": "We show analytically and empirically that the correction feature, assumed to be required for the correct-ness of GIS, is unnecessary.", "labels": [], "entities": [{"text": "correction", "start_pos": 46, "end_pos": 56, "type": "METRIC", "confidence": 0.990420401096344}]}, {"text": "We also explore the use of a Gaussian prior and a simple cutoff for smoothing.", "labels": [], "entities": []}, {"text": "The experiments are performed with two tagsets: the standard Penn Treebank POS tagset and the larger set of lexical types from Combinatory Categorial Grammar.", "labels": [], "entities": [{"text": "Penn Treebank POS tagset", "start_pos": 61, "end_pos": 85, "type": "DATASET", "confidence": 0.9830589890480042}]}], "introductionContent": [{"text": "The use of maximum entropy (ME) models has become popular in Statistical NLP; some example applications include part-of-speech (Pos) tagging, parsing) and language modelling.", "labels": [], "entities": [{"text": "Statistical NLP", "start_pos": 61, "end_pos": 76, "type": "TASK", "confidence": 0.8494778275489807}, {"text": "part-of-speech (Pos) tagging", "start_pos": 112, "end_pos": 140, "type": "TASK", "confidence": 0.6449240565299987}, {"text": "language modelling", "start_pos": 155, "end_pos": 173, "type": "TASK", "confidence": 0.7899107933044434}]}, {"text": "Many tagging problems have been successfully modelled in the ME framework, including POS tagging, with state of the art performance), \"supertagging\") and chunking.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 85, "end_pos": 96, "type": "TASK", "confidence": 0.7358679473400116}]}, {"text": "Generalised Iterative Scaling (GIs) is a very simple algorithm for estimating the parameters of a ME model.", "labels": [], "entities": [{"text": "Generalised Iterative Scaling (GIs)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7386970619360606}]}, {"text": "The original formulation of GIS required the sum of the feature values for each event to be constant.", "labels": [], "entities": []}, {"text": "Since this is not the case for many applications, the standard method is to add a \"correction\", or \"slack\", feature to each event Improved Iterative Scaling (us)) eliminated the correction feature to improve the convergence rate of the algorithm.", "labels": [], "entities": []}, {"text": "However, the extra bookkeeping required for us means that GIS is often faster in practice).", "labels": [], "entities": [{"text": "GIS", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.5399819016456604}]}, {"text": "This paper shows, by a simple adaptation of Berger's proof for the convergence of HS, that GIS does not require a correction feature.", "labels": [], "entities": []}, {"text": "We also investigate how the use of a correction feature affects the performance of ME taggers.", "labels": [], "entities": [{"text": "ME taggers", "start_pos": 83, "end_pos": 93, "type": "TASK", "confidence": 0.825546383857727}]}, {"text": "GIS and HS obtain a maximum likelihood estimate (mLE) of the parameters, and, like other MLE methods, are susceptible to overfitting.", "labels": [], "entities": [{"text": "maximum likelihood estimate (mLE)", "start_pos": 20, "end_pos": 53, "type": "METRIC", "confidence": 0.8424743811289469}]}, {"text": "A simple technique used to avoid overfitting is a frequency cutoff, in which only frequently occurring features are included in the model.", "labels": [], "entities": []}, {"text": "However, more sophisticated smoothing techniques exist, such as the use of a Gaussian prior on the parameters of the model).", "labels": [], "entities": []}, {"text": "This technique has been applied to language modelling), text classification () and parsing), but to our knowledge it has not been compared with the use of a feature cutoff.", "labels": [], "entities": [{"text": "language modelling", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.7778736352920532}, {"text": "text classification", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.8555476665496826}, {"text": "parsing", "start_pos": 83, "end_pos": 90, "type": "TASK", "confidence": 0.9694241881370544}]}, {"text": "We explore the combination of Gaussian smoothing and a simple cutoff for two tagging tasks.", "labels": [], "entities": []}, {"text": "The two taggers used for the experiments area POS tagger, trained on the WSJ Penn Treebank, and a \"supertagger\", which assigns tags from the much larger set of lexical types from Combinatory Categorial Grammar (ccG)).", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 46, "end_pos": 56, "type": "TASK", "confidence": 0.6727700233459473}, {"text": "WSJ Penn Treebank", "start_pos": 73, "end_pos": 90, "type": "DATASET", "confidence": 0.9516439835230509}]}, {"text": "Elimination of the correction feature and use of appropriate smoothing methods result instate of the art performance for both tagging tasks.", "labels": [], "entities": [{"text": "tagging", "start_pos": 126, "end_pos": 133, "type": "TASK", "confidence": 0.960448682308197}]}], "datasetContent": [{"text": "We develop and test our improved POS tagger (c &c) using the standard parser development methodology on the Penn Treebank WSJ corpus.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 33, "end_pos": 43, "type": "TASK", "confidence": 0.6144995987415314}, {"text": "Penn Treebank WSJ corpus", "start_pos": 108, "end_pos": 132, "type": "DATASET", "confidence": 0.9827721118927002}]}, {"text": "shows the number of sentences and words in the training, development and test datasets.", "labels": [], "entities": []}, {"text": "As well as evaluating the overall accuracy of the taggers (Acc), we also calculate the accuracy on previously unseen words (UwoRD), previously unseen word-tag pairs (UTAG) and ambiguous words (AmB), that is, those with more than one tag over the testing, training and development datasets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9988541603088379}, {"text": "Acc", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.9806138277053833}, {"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9994358420372009}]}, {"text": "Note that the unseen word-tag pairs do not include the previously unseen words.", "labels": [], "entities": []}, {"text": "We first replicated the results of the MXPOST tagger.", "labels": [], "entities": [{"text": "MXPOST tagger", "start_pos": 39, "end_pos": 52, "type": "TASK", "confidence": 0.600174605846405}]}, {"text": "In doing so, we discovered a number of minor variations from Ratnaparkhi (1998): \u2022 MXPOST adds a default contextual predicate which is true for every context; \u2022 MXPOST does not use the cutoff values described in.", "labels": [], "entities": []}, {"text": "MXPOST uses a cutoff of 1 for the current word feature and 5 for other features.", "labels": [], "entities": [{"text": "MXPOST", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9468330144882202}]}, {"text": "However, the current word must have appeared at least 5 times with any tag for the current word feature to be included; otherwise the word is considered rare and morphological features are included instead.", "labels": [], "entities": []}, {"text": "nor improvement in performance when the correction feature is removed.", "labels": [], "entities": []}, {"text": "We also experimented with the default contextual predicate but found it had little impact on the performance.", "labels": [], "entities": []}, {"text": "For the remainder of the experiments we use neither the correction nor the default features.", "labels": [], "entities": [{"text": "correction", "start_pos": 56, "end_pos": 66, "type": "METRIC", "confidence": 0.9905959367752075}]}, {"text": "The rest of this section considers various combinations of feature cutoffs and Gaussian smoothing.", "labels": [], "entities": []}, {"text": "We report optimal results with respect to the smoothing parameter a, where a = No-2 and N is the number of training instances.", "labels": [], "entities": []}, {"text": "We found that using a 2 gave the most benefit to our basic tagger, improving performance by about 0.15% on the development set.", "labels": [], "entities": []}, {"text": "This result is shown in the first row of.", "labels": [], "entities": []}, {"text": "The lexical categories for the supertagging experiments were extracted from CCGbank, a CCG version of the Penn Treebank ().", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 106, "end_pos": 119, "type": "DATASET", "confidence": 0.9943486452102661}]}, {"text": "Following, all categories that occurred at least 10 times in the training data were used, resulting in a tagset of 398 categories.", "labels": [], "entities": []}, {"text": "Sections 02-21, section 00, and section 23 were used for training, development and testing, as before.", "labels": [], "entities": []}, {"text": "Our supertagger used the same configuration as our best performing POS tagger, except that the a parameter was again optimised on the development set.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 67, "end_pos": 77, "type": "TASK", "confidence": 0.6013850718736649}]}, {"text": "The results on section 00 and section 23 are given in. c&c outperforms Clark's supertagger by 0.43% on the test set, a reduction in error rate of 4.9%.", "labels": [], "entities": [{"text": "Clark's supertagger", "start_pos": 71, "end_pos": 90, "type": "METRIC", "confidence": 0.8639988501866659}, {"text": "error rate", "start_pos": 132, "end_pos": 142, "type": "METRIC", "confidence": 0.987667977809906}]}, {"text": "Supertagging has the potential to benefit more The results in Clark", "labels": [], "entities": [{"text": "Supertagging", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.8645041584968567}]}], "tableCaptions": [{"text": " Table 3: WSJ training, testing and development", "labels": [], "entities": [{"text": "WSJ", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.7996912598609924}]}, {"text": " Table 4: Basic tagger performance on WSJ 00", "labels": [], "entities": [{"text": "WSJ", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.9070066809654236}]}, {"text": " Table 5: WSJ 00 results with varying current and  previous word feature cutoffs", "labels": [], "entities": [{"text": "WSJ", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.5033223628997803}]}, {"text": " Table 6: WSJ 00 results with varying cutoffs", "labels": [], "entities": [{"text": "WSJ", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.42928898334503174}]}, {"text": " Table 7: Tagger performance on WSJ 23", "labels": [], "entities": [{"text": "Tagger", "start_pos": 10, "end_pos": 16, "type": "TASK", "confidence": 0.9738302826881409}, {"text": "WSJ 23", "start_pos": 32, "end_pos": 38, "type": "DATASET", "confidence": 0.9775215685367584}]}, {"text": " Table 9: 10-fold cross-validation results", "labels": [], "entities": []}, {"text": " Table 10: Comparison with other taggers", "labels": [], "entities": []}, {"text": " Table 11: Supertagger WSJ 00 results", "labels": [], "entities": [{"text": "Supertagger WSJ 00", "start_pos": 11, "end_pos": 29, "type": "DATASET", "confidence": 0.6058344642321268}]}, {"text": " Table 12: Supertagger WSJ 23 results", "labels": [], "entities": [{"text": "Supertagger WSJ 23", "start_pos": 11, "end_pos": 29, "type": "DATASET", "confidence": 0.6559510131676992}]}]}