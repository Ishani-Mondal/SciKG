{"title": [{"text": "Word classification based on combined measures of distributional and semantic similarity", "labels": [], "entities": [{"text": "Word classification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7708897590637207}]}], "abstractContent": [{"text": "The paper addresses the problem of automatic enrichment of a thesaurus by classifying new words into its classes.", "labels": [], "entities": []}, {"text": "The proposed classification method makes use of both the distributional data about anew word and the strength of the semantic relatedness of its target class to other likely candidate classes.", "labels": [], "entities": []}], "introductionContent": [{"text": "Today, many NLP applications make active use of thesauri like WordNet, which serve as background lexical knowledge for processing the semantics of words and documents.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 62, "end_pos": 69, "type": "DATASET", "confidence": 0.954953134059906}]}, {"text": "However, maintaining a thesaurus so that it sufficiently covers the lexicon of novel text data requires a lot of time and effort, which maybe prohibitive in many settings.", "labels": [], "entities": []}, {"text": "One possibility to (semi-) automatically enrich a thesaurus with new items is to exploit the distributional hypothesis.", "labels": [], "entities": []}, {"text": "According to this approach, the meaning of anew word is first represented as the totality of textual contexts where it occurs and then assigned to that semantic class which members exhibit similar occurrence patterns.", "labels": [], "entities": []}, {"text": "The distributional approach was shown to be quite effective for tasks where new words need to be assigned to a limited number of classes (up to 5; e.g.,.", "labels": [], "entities": []}, {"text": "However, its application to numerous classes, as would be the case with a thesaurus of a realistic size, proves to be much more challenging.", "labels": [], "entities": []}, {"text": "For example, attain the learning accuracy' of 38% when assigning new words to 46 WordNet concepts.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9059925675392151}]}, {"text": "In the present paper we propose a method that is particularly effective for the task of classifying words into numerous classes forming a hierarchy.", "labels": [], "entities": []}, {"text": "The position of a class inside the hierarchy reflects the degree of its semantic similarity to other classes.", "labels": [], "entities": []}, {"text": "Besides distributional data, our method integrates this semantic information: the classification decision is a function of both (1) the distributional similarity of the new word to the target class and (2) the strength of the semantic relatedness of the target class to other likely candidates.", "labels": [], "entities": []}, {"text": "Thus, using the thesaurus as background knowledge we aim to makeup for possible insufficient quality of the distributional data.", "labels": [], "entities": []}], "datasetContent": [{"text": "The proposed method was tested on the distributional data on nouns obtained from two corpora: the British National Corpus (BNC) and the Associated Press 1988 corpus (AP)5 . The BNC data consisted of over 1.34 million verb-object cooccurrence pairs, whereby the objects were both direct and prepositional; only those pairs extracted from the corpus were retained that appeared more than once and which involved nouns appearing with at least 5 different verbs.", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 98, "end_pos": 127, "type": "DATASET", "confidence": 0.9716440141201019}, {"text": "Associated Press 1988 corpus (AP)5", "start_pos": 136, "end_pos": 170, "type": "DATASET", "confidence": 0.906630665063858}, {"text": "BNC data", "start_pos": 177, "end_pos": 185, "type": "DATASET", "confidence": 0.9207295775413513}]}, {"text": "The AP dataset contained 0.73 million verbs-direct objects pairs, which involved 1000 most frequent nouns in the corpus.", "labels": [], "entities": [{"text": "AP dataset", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.8614079356193542}]}, {"text": "The semantic classes used in the experiments were constructed from WordNet noun synsets as follows.", "labels": [], "entities": []}, {"text": "Each synset positioned seven edges below the top-most level formed a class by subsuming all its hyponym synsets.", "labels": [], "entities": []}, {"text": "Then all classes that contained less than 5 nouns were discarded.", "labels": [], "entities": []}, {"text": "Thus the BNC nouns formed 233 classes with 1807 unique nouns and the AP nouns formed 137 classes with 816 unique nouns.", "labels": [], "entities": [{"text": "BNC nouns", "start_pos": 9, "end_pos": 18, "type": "DATASET", "confidence": 0.8980732560157776}]}, {"text": "For both datasets, presence of a noun in multiple classes was allowed.", "labels": [], "entities": []}, {"text": "The experiments were conducted using tenfold cross-validation.", "labels": [], "entities": []}, {"text": "The nouns present in the constructed classes were divided into a training set and a test set.", "labels": [], "entities": []}, {"text": "After that the ability of the cla ssifiers to recover the original class of a test noun was tested.", "labels": [], "entities": []}, {"text": "Their performance was evaluated in terms of precision and in terms of learning accuracy ().", "labels": [], "entities": [{"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9996535778045654}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.917116641998291}]}, {"text": "The latter is a measure designed specifically to evaluate the quality of classifying instances into a hierarchy of classes.", "labels": [], "entities": []}, {"text": "It describes the semantic similarity between the assigned class and the correct class (Equation 2) averaged overall test instances.", "labels": [], "entities": []}, {"text": "The experiments were conducted with k = 1, 3, 5, 7, 10, 15, 20, 30, 50, 70 and 100.", "labels": [], "entities": []}, {"text": "We first corn-pared the following three versions of KNN.", "labels": [], "entities": [{"text": "KNN", "start_pos": 52, "end_pos": 55, "type": "DATASET", "confidence": 0.8207632303237915}]}, {"text": "The first was the one that determines the score fora class by simply counting its members among the nearest neighbors (\"baseline\").", "labels": [], "entities": []}, {"text": "The second was the distance-weighted version of KNN: each neighbor voted for its class or classes with a weight proportional to its distributional similarity to the test word (\"distributional similarity weighting\").", "labels": [], "entities": []}, {"text": "The weight in the third version was determined according to Equation 3, whereby A (c) was just the number of votes for the class (i.e., without considering the distributional similarity values, \"semantic similarity weighting\").", "labels": [], "entities": [{"text": "A (c)", "start_pos": 80, "end_pos": 85, "type": "METRIC", "confidence": 0.9115849137306213}]}, {"text": "describes the precision demonstrated by these three weighting possibilities on the BNC data (for \"semantic similarity weighting\", the parameter 13 was tuned to 5).", "labels": [], "entities": [{"text": "precision", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9993990659713745}, {"text": "BNC data", "start_pos": 83, "end_pos": 91, "type": "DATASET", "confidence": 0.9638938009738922}]}, {"text": "describes the learning accuracy of these three versions of KINN (fi was set to 1).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.8178580403327942}, {"text": "KINN", "start_pos": 59, "end_pos": 63, "type": "DATASET", "confidence": 0.5170172452926636}]}, {"text": "compares them on the data of the two corpora (the number in parentheses specifies the k for which the evaluation score was achieved As seen from these results, both the distributional and semantic weighting schemas exhibit better performance than the non-weighted version of KNN.", "labels": [], "entities": []}, {"text": "The semantic weighting schema performs not as well as the distributional one in terms of precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 89, "end_pos": 98, "type": "METRIC", "confidence": 0.9981814622879028}]}, {"text": "In terms of learning accuracy, however, it surpasses it at greater values of k.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9865548610687256}]}, {"text": "This can be explained by the fact that one is more likely to obtain valuable semantic information about a class, when one estimates its relatedness in the thesaurus to a bigger number of classes.", "labels": [], "entities": []}, {"text": "At a certain point, however, the increase of the num-  ber of classes taken into account harms its performance (see the decreasing curve for k>30,).", "labels": [], "entities": []}, {"text": "We thus saw that both distributional and mantic weighting provide useful evidence about the class fora new word.", "labels": [], "entities": []}, {"text": "In the next step, we tested their combination: in Equation 3, A (c) was the sum of neighbors' votes, each weighted by the distributional similarity of the neighbor to the test word.", "labels": [], "entities": [{"text": "A", "start_pos": 62, "end_pos": 63, "type": "METRIC", "confidence": 0.9925451874732971}]}, {"text": "compares the precision and learning accuracy of the combined weighting schema to the distributional weighting.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9995216131210327}, {"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.8225089907646179}]}, {"text": "The combined weighting schema thus showed relative improvement on the distributional one: 1.5% (BNC) and 2.3% (AP) in terms of precision and 9.2% (BNC) and 4.5% (AP) in terms of learning accuracy.", "labels": [], "entities": [{"text": "BNC", "start_pos": 96, "end_pos": 99, "type": "METRIC", "confidence": 0.7746541500091553}, {"text": "AP", "start_pos": 111, "end_pos": 113, "type": "METRIC", "confidence": 0.980646014213562}, {"text": "precision", "start_pos": 127, "end_pos": 136, "type": "METRIC", "confidence": 0.9988896250724792}, {"text": "AP", "start_pos": 162, "end_pos": 164, "type": "METRIC", "confidence": 0.9815981388092041}, {"text": "accuracy", "start_pos": 187, "end_pos": 195, "type": "METRIC", "confidence": 0.9320238828659058}]}], "tableCaptions": []}