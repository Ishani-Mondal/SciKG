{"title": [{"text": "The adaptation of a machine-learned sentence realization system to French", "labels": [], "entities": [{"text": "sentence realization", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.772500067949295}]}], "abstractContent": [{"text": "We describe the adaptation to French of a machine-learned sentence realization system called Amalgam that was originally developed to be as language independent as possible and was first implemented for German.", "labels": [], "entities": []}, {"text": "We discuss the development of the French implementation with particular attention to the degree to which the original system could be re-used, and we present the results of a human evaluation of the quality of sentence realization using the new French system.", "labels": [], "entities": [{"text": "sentence realization", "start_pos": 210, "end_pos": 230, "type": "TASK", "confidence": 0.7605909705162048}]}], "introductionContent": [{"text": "Recently, statistical and machine-learned approaches have been applied to the sentence realization phase of natural language generation.", "labels": [], "entities": [{"text": "sentence realization phase of natural language generation", "start_pos": 78, "end_pos": 135, "type": "TASK", "confidence": 0.6934555513518197}]}, {"text": "The Nitrogen system, for example, uses a word bigram language model to score and rank a large set of alternative sentence realizations ().", "labels": [], "entities": []}, {"text": "Other recent approaches use syntactic representations.", "labels": [], "entities": []}, {"text": "FERGUS), Halogen ( and Amalgam) use syntactic trees as an intermediate representation to determine the optimal string output.", "labels": [], "entities": [{"text": "FERGUS", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8237016201019287}]}, {"text": "The Amalgam system discussed here is a sentence realization system which maps a semantic representation to a surface syntactic tree via intermediate syntactic representations.", "labels": [], "entities": [{"text": "sentence realization", "start_pos": 39, "end_pos": 59, "type": "TASK", "confidence": 0.73487788438797}]}, {"text": "The mappings are performed with linguistic operations, the context for which is primarily machine-learned.", "labels": [], "entities": []}, {"text": "The resulting syntactic tree contains all the necessary information on its leaf nodes from which a surface string can be read.", "labels": [], "entities": []}, {"text": "The promise of machine-learned approaches to sentence realization is that they can easily be adapted to new domains and ideally to new languages merely by retraining The architecture of Amalgam was intended to be languageindependent, although the system has previously only been applied to German sentence realization.", "labels": [], "entities": [{"text": "sentence realization", "start_pos": 45, "end_pos": 65, "type": "TASK", "confidence": 0.7237336039543152}, {"text": "German sentence realization", "start_pos": 290, "end_pos": 317, "type": "TASK", "confidence": 0.6623821059862772}]}, {"text": "Adapting this system to French allows us to assess which aspects of the system are truly language-independent and what must be added in order to account for French.", "labels": [], "entities": []}, {"text": "The purpose of this paper is to focus on the adaptation of Amalgam to French.", "labels": [], "entities": [{"text": "adaptation of Amalgam to French", "start_pos": 45, "end_pos": 76, "type": "TASK", "confidence": 0.6862223625183106}]}, {"text": "Discussions about the general architecture of the system can be found in and.", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed a human evaluation of French generation.", "labels": [], "entities": [{"text": "French generation", "start_pos": 35, "end_pos": 52, "type": "DATASET", "confidence": 0.9237407445907593}]}, {"text": "This was the first formal evaluation of the French generation system.", "labels": [], "entities": [{"text": "French generation system", "start_pos": 44, "end_pos": 68, "type": "DATASET", "confidence": 0.9161154429117838}]}, {"text": "For this evaluation, 545 test sentences from a blind software manual corpus were analyzed with our NLPWin analysis system, producing a logical form for each sentence.", "labels": [], "entities": []}, {"text": "From each logical form, our sentence realization system then generated a hypothesis sentence.", "labels": [], "entities": []}, {"text": "We did not control for noise introduced into the data by the analysis phase (about 15% of the sentences did not have a spanning parse).", "labels": [], "entities": []}, {"text": "Nevertheless, this experiment gives us a good indication of the performance of French Amalgam.", "labels": [], "entities": [{"text": "French Amalgam", "start_pos": 79, "end_pos": 93, "type": "DATASET", "confidence": 0.9691032469272614}]}, {"text": "Five evaluators were asked to evaluate the same set of sentences independently.", "labels": [], "entities": []}, {"text": "Each generated sentence was evaluated in isolation; i.e., discourse context was not taken into account.", "labels": [], "entities": []}, {"text": "For each sentence, raters were presented with the original French sentence as a reference and the hypothesis sentence from French Amalgam.", "labels": [], "entities": [{"text": "French Amalgam", "start_pos": 123, "end_pos": 137, "type": "DATASET", "confidence": 0.9053878784179688}]}, {"text": "All the raters assigned an integer score comparing each sentence to the reference.", "labels": [], "entities": []}, {"text": "The scores were 1 \"Unacceptable\", 2 \"Possibly acceptable\", 3 \"Acceptable\" and 4 \"Ideal\".", "labels": [], "entities": [{"text": "Unacceptable", "start_pos": 19, "end_pos": 31, "type": "METRIC", "confidence": 0.9437172412872314}, {"text": "Acceptable", "start_pos": 62, "end_pos": 72, "type": "METRIC", "confidence": 0.9993613362312317}, {"text": "Ideal", "start_pos": 81, "end_pos": 86, "type": "METRIC", "confidence": 0.9795368909835815}]}, {"text": "The score of a sentence is the average of the scores from the five raters.", "labels": [], "entities": []}, {"text": "The system score is the average of the scores of all sentences.", "labels": [], "entities": []}, {"text": "The average score was 2.92 with a standard deviation of 0.19.", "labels": [], "entities": []}, {"text": "The maximum score was 4, and 99/545 sentences (18.2%) received that score.", "labels": [], "entities": []}, {"text": "For 45 of those sentences, the score was assigned automatically, because the sentences were completely identical.", "labels": [], "entities": [{"text": "the score", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9249904453754425}]}, {"text": "The other sentences with score 4 (54 sentences in total) differed in someway from the original but had been assigned that score by all 5 evaluators, who had judged them equivalent to the reference sentence.", "labels": [], "entities": []}], "tableCaptions": []}