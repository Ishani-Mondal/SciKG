{"title": [{"text": "Producing Contextually Appropriate Intonation in an Information-State Based Dialogue System", "labels": [], "entities": []}], "abstractContent": [{"text": "Our goal is to improve the contextual appropriateness of spoken output in a dialogue system.", "labels": [], "entities": []}, {"text": "We explore the use of the information state to determine the information structure of system utterances.", "labels": [], "entities": []}, {"text": "We concentrate on the realization of information structure by intonation.", "labels": [], "entities": []}, {"text": "We present the results of evaluating the contextual appropriateness of varied system output produced with a text-to-speech synthesis system that supports intonation annotation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Most commercial spoken dialogue systems use carefully scripted dialogues.", "labels": [], "entities": []}, {"text": "This has the advantage that the system output can be pre-recorded and have high quality.", "labels": [], "entities": []}, {"text": "The disadvantage is limited dialogue flexibility, as user-initiative must be restricted to ensure the dialogue adheres to the script.", "labels": [], "entities": []}, {"text": "More flexible dialogues need dynamically produced output.", "labels": [], "entities": []}, {"text": "As the range of possible system utterances grows pre-recording becomes infeasible, and speech synthesis becomes necessary.", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 87, "end_pos": 103, "type": "TASK", "confidence": 0.7384133338928223}]}, {"text": "One challenge for systems using synthesized speech is the generation of contextually appropriate intonation.", "labels": [], "entities": []}, {"text": "With dynamically produced output, the same sequence of words may appear in different contexts, possibly needing different intonation.", "labels": [], "entities": []}, {"text": "For example, the intonation of an answer needs to correspond to the respective question: whereas in (1S) the nuclear intonation center has a \"default\" placement, in (2S) it does not.", "labels": [], "entities": []}, {"text": "I (1) U: What is the status of the stove?", "labels": [], "entities": [{"text": "U", "start_pos": 6, "end_pos": 7, "type": "METRIC", "confidence": 0.9460508227348328}]}, {"text": "S: The stove is switched ON.", "labels": [], "entities": [{"text": "ON", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.9903585314750671}]}], "datasetContent": [{"text": "To evaluate the impact of controlling intonation through IS on the acceptability of system turns, we conducted two experiments with the German output of Mary.", "labels": [], "entities": [{"text": "German output of Mary", "start_pos": 136, "end_pos": 157, "type": "DATASET", "confidence": 0.8920994699001312}]}, {"text": "We tested whether there are differences in acceptability between (i) default output and (ii) the controlled intontation, in general and for various IS patterns.", "labels": [], "entities": []}, {"text": "First, we compared contextual appropriateness of output produced with (i) the default intonation and controlled intonation, using either (ii) GToBI or (iii) SABLE intonation markup.", "labels": [], "entities": []}, {"text": "Second, we carried out a more detailed comparison of contextual appropriateness for (i) the default intonation and (ii) the controlled intonation using GToBI.", "labels": [], "entities": [{"text": "GToBI", "start_pos": 152, "end_pos": 157, "type": "DATASET", "confidence": 0.9225193858146667}]}, {"text": "For each experiment, we prepared 3-5 turn dialogues from the travel agency and home-device domains handled in GoDIS.", "labels": [], "entities": [{"text": "GoDIS", "start_pos": 110, "end_pos": 115, "type": "DATASET", "confidence": 0.9092772006988525}]}, {"text": "The last turn was the evaluated system utterance.", "labels": [], "entities": [{"text": "evaluated system utterance", "start_pos": 22, "end_pos": 48, "type": "TASK", "confidence": 0.5555080672105154}]}, {"text": "The turns were constructed so that the context supported different IS patterns in the target: Marked or unmarked Theme before or after Rheme.", "labels": [], "entities": [{"text": "Rheme", "start_pos": 135, "end_pos": 140, "type": "METRIC", "confidence": 0.8578013777732849}]}, {"text": "Intonation annotation was assigned as described in \u00a75 and \u00a76.", "labels": [], "entities": [{"text": "Intonation annotation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.867572009563446}]}, {"text": "The dialogues were presented on a web page 7 with the targets highlighted in bold.", "labels": [], "entities": []}, {"text": "The subjects were asked to go through the dialogues one by one, read a dialogue, listen to the target audio, and judge the contextual appropriateness of its intonation on a scale from 1 (worst) to 5 (best).", "labels": [], "entities": []}, {"text": "In the first experiment, 22 subjects judged 10 utterances in different intonation versions, in the second one it was 20 subjects and 16 utterances.", "labels": [], "entities": []}, {"text": "The default was generally judged worse than SABLE output and that was judged worse than GToBI output (Tab. 2, Ex.1).", "labels": [], "entities": []}, {"text": "This was also the case for utterances with unmarked Theme, irrespective of Theme-Rheme order (Tab.", "labels": [], "entities": []}, {"text": "For marked Theme, SABLE shows a slight improvement over the default (Tab.", "labels": [], "entities": [{"text": "SABLE", "start_pos": 18, "end_pos": 23, "type": "METRIC", "confidence": 0.9150851964950562}]}, {"text": "However, this is due to slight differences in pronunciation not due to the intonation annotation.", "labels": [], "entities": []}, {"text": "More detailed analysis revealed a few exceptions when SABLE was judged better than GToBI.", "labels": [], "entities": [{"text": "SABLE", "start_pos": 54, "end_pos": 59, "type": "METRIC", "confidence": 0.8785405158996582}, {"text": "GToBI", "start_pos": 83, "end_pos": 88, "type": "DATASET", "confidence": 0.820098340511322}]}, {"text": "A possible source is that SABLE annotated input is additionally processed and possibly modified by applying Mary defaults in ways we cannot control.", "labels": [], "entities": []}, {"text": "Thus, Mary may sometimes \"improve\" the SABLE intonation specification (towards default).", "labels": [], "entities": [{"text": "SABLE intonation", "start_pos": 39, "end_pos": 55, "type": "TASK", "confidence": 0.6599553525447845}]}, {"text": "With GToBT we give specific annotations that prevent the application of Mary defaults, but may sometimes result in less smooth output.", "labels": [], "entities": []}, {"text": "In the second experiment we restricted the comparison to the default and GToBI output, and we varied the IS patterns systematically.", "labels": [], "entities": []}, {"text": "The second experiment confirms the tendency that GToBI outputs get better acceptability judgements than Mary defaults both overall (Tab. 2, Ex. 2) and per IS pattern (Tab. 3-6, Ex.2).", "labels": [], "entities": []}, {"text": "Comparing average absolute judgements can be problematic, if the subjects place their judgements differently on the scale.", "labels": [], "entities": []}, {"text": "However, the average differences between individual subjects' judgements of the GToBI and default version of each target were small and confirmed that GToBI output is judged better than the default.", "labels": [], "entities": []}, {"text": "After the first experiment, we also realized that the setup we use cannot ensure the subjects actually take the context into account.", "labels": [], "entities": []}, {"text": "We considered presenting the dialogues spoken (recorded human-user turns and synthesized system turns), but then the quality and intonation of turns other than the target could influence the judgements.", "labels": [], "entities": []}, {"text": "Instead, we included evaluation of the targets with default intonation in isolation before their The subjects were mostly computational linguistics students.", "labels": [], "entities": []}, {"text": "Some had previous knowledge of phonetics or experience with speech synthesis.", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 60, "end_pos": 76, "type": "TASK", "confidence": 0.718720555305481}]}, {"text": "evaluation in context in the second experiment.", "labels": [], "entities": []}, {"text": "9 We did not include the non-default versions in the eval-raises the issue of a suitable semantic representation.", "labels": [], "entities": []}, {"text": "The semantics close to database contents we use now obscures many aspects of meaning important for more subtle dialoge modelling.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Unmarked Theme, Theme before Rheme", "labels": [], "entities": [{"text": "Rheme", "start_pos": 39, "end_pos": 44, "type": "TASK", "confidence": 0.34220537543296814}]}, {"text": " Table 4: Unmarked Theme, Rheme before Theme", "labels": [], "entities": [{"text": "Rheme", "start_pos": 26, "end_pos": 31, "type": "METRIC", "confidence": 0.9853969216346741}]}, {"text": " Table 5: Marked Theme, Theme before Rheme", "labels": [], "entities": [{"text": "Rheme", "start_pos": 37, "end_pos": 42, "type": "TASK", "confidence": 0.339590847492218}]}, {"text": " Table 6: Marked Theme, Rheme before Theme", "labels": [], "entities": [{"text": "Rheme", "start_pos": 24, "end_pos": 29, "type": "METRIC", "confidence": 0.9767381548881531}]}, {"text": " Table 7: Default vs. GToBI judgment differences", "labels": [], "entities": []}]}