{"title": [{"text": "Automatic Construction of Machine Translation Knowledge Using Translation Literalness", "labels": [], "entities": [{"text": "Automatic Construction of Machine Translation Knowledge", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.7377052307128906}]}], "abstractContent": [{"text": "When machine translation (MT) knowledge is automatically constructed from bilingual corpora, redundant rules are acquired due to translation variety.", "labels": [], "entities": [{"text": "machine translation (MT) knowledge", "start_pos": 5, "end_pos": 39, "type": "TASK", "confidence": 0.8532133350769678}]}, {"text": "These rules increase ambiguity or cause incorrect MT results.", "labels": [], "entities": [{"text": "MT", "start_pos": 50, "end_pos": 52, "type": "TASK", "confidence": 0.9891977906227112}]}, {"text": "To overcome this problem, we constrain the sentences used for knowledge extraction to \"the appropriate bilingual sentences for the MT.\"", "labels": [], "entities": [{"text": "knowledge extraction", "start_pos": 62, "end_pos": 82, "type": "TASK", "confidence": 0.7539187669754028}, {"text": "MT", "start_pos": 131, "end_pos": 133, "type": "TASK", "confidence": 0.9627745151519775}]}, {"text": "In this paper, we propose a method using translation literalness to select appropriate sentences or phrases.", "labels": [], "entities": []}, {"text": "The translation correspondence rate (TCR) is defined as the literalness measure.", "labels": [], "entities": [{"text": "translation correspondence rate (TCR)", "start_pos": 4, "end_pos": 41, "type": "METRIC", "confidence": 0.895844171444575}]}, {"text": "Based on the TCR, two automatic construction methods are tested.", "labels": [], "entities": [{"text": "TCR", "start_pos": 13, "end_pos": 16, "type": "DATASET", "confidence": 0.7873818278312683}]}, {"text": "One is to filter the corpus before rule acquisition.", "labels": [], "entities": [{"text": "rule acquisition", "start_pos": 35, "end_pos": 51, "type": "TASK", "confidence": 0.7616553902626038}]}, {"text": "The other is to split the acquisition process into two phases, where a bilingual sentence is divided into literal parts and the other parts before different generalizations are applied.", "labels": [], "entities": []}, {"text": "The effects are evaluated by the MT quality, and about 4.9% of MT results were improved by the latter method.", "labels": [], "entities": [{"text": "MT", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.9424268007278442}, {"text": "MT", "start_pos": 63, "end_pos": 65, "type": "TASK", "confidence": 0.958248496055603}]}], "introductionContent": [{"text": "Along with the efforts made to accumulate bilingual corpora for many language pairs, quite a few machine translation (MT) systems that automatically construct their knowledge from corpora have been proposed).", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 97, "end_pos": 121, "type": "TASK", "confidence": 0.8482048869132995}]}, {"text": "However, if we use corpora without any restriction, redundant rules are acquired due to translation varieties.", "labels": [], "entities": []}, {"text": "Such rules increase ambiguity and may cause inappropriate MT results.", "labels": [], "entities": [{"text": "MT", "start_pos": 58, "end_pos": 60, "type": "TASK", "confidence": 0.991703987121582}]}, {"text": "Translation variety increases with corpus size.", "labels": [], "entities": []}, {"text": "For instance, large corpora usually contain multiple translations of the same source sentences.", "labels": [], "entities": []}, {"text": "Moreover, peculiar translations that depend on context or situation proliferate in large corpora.", "labels": [], "entities": []}, {"text": "Our targets are corpora that contain over one hundred thousand sentences.", "labels": [], "entities": []}, {"text": "To reduce the influence of translation variety, we attempt to control the bilingual sentences that are appropriate for machine translation (here called \"controlled translation\").", "labels": [], "entities": [{"text": "machine translation", "start_pos": 119, "end_pos": 138, "type": "TASK", "confidence": 0.7248349785804749}]}, {"text": "Among the measures that can be used for controlled translation, we focus on translation literalness in this paper.", "labels": [], "entities": [{"text": "controlled translation", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.6317148208618164}, {"text": "translation literalness", "start_pos": 76, "end_pos": 99, "type": "TASK", "confidence": 0.8573518693447113}]}, {"text": "By restricting bilingual sentences during MT knowledge construction, the MT quality will be improved.", "labels": [], "entities": [{"text": "MT knowledge construction", "start_pos": 42, "end_pos": 67, "type": "TASK", "confidence": 0.9341908693313599}, {"text": "MT", "start_pos": 73, "end_pos": 75, "type": "TASK", "confidence": 0.9813609719276428}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the problems caused by translation varieties.", "labels": [], "entities": []}, {"text": "Section 3 discusses the kinds of translations that are appropriate for MTs.", "labels": [], "entities": [{"text": "MTs", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.9890376925468445}]}, {"text": "Section 4 introduces the concept of translation literalness and how to measure it.", "labels": [], "entities": [{"text": "translation literalness", "start_pos": 36, "end_pos": 59, "type": "TASK", "confidence": 0.9320888221263885}]}, {"text": "Section 5 describes construction methods using literalness, and Section 6 evaluates the construction methods.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate the effect of literalness in MT knowledge construction, we constructed knowledge by using the methods described in Section 5 and evaluated the MT quality of the resulting English-to-Japanese translation.", "labels": [], "entities": [{"text": "MT knowledge construction", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.9386458198229471}, {"text": "MT", "start_pos": 164, "end_pos": 166, "type": "TASK", "confidence": 0.9357423186302185}]}, {"text": "Bilingual Corpus We used as the training set 149,882 bilingual sentences from the Basic Travel Expression Corpus ().", "labels": [], "entities": [{"text": "Basic Travel Expression Corpus", "start_pos": 82, "end_pos": 112, "type": "DATASET", "confidence": 0.5337078869342804}]}, {"text": "This corpus is a collection of Japanese sentences and their English translations based on expressions that are usually found in phrasebooks for foreign tourists.", "labels": [], "entities": []}, {"text": "There are many bilingual sentences in which the source sentences are the same but the targets are not.", "labels": [], "entities": []}, {"text": "About 13% of different English sentences have multiple Japanese translations.", "labels": [], "entities": []}, {"text": "Translation Dictionary: Extraction of Word Correspondence For word correspondences that occur more than nine times in the corpus, statistical word alignment was carried out by a similar method to.", "labels": [], "entities": [{"text": "Extraction of Word Correspondence", "start_pos": 24, "end_pos": 57, "type": "TASK", "confidence": 0.7625842094421387}, {"text": "word alignment", "start_pos": 142, "end_pos": 156, "type": "TASK", "confidence": 0.6882398277521133}]}, {"text": "When words for which the correspondence could not be found remain, a thesaurus ( was used to create correspondences to the words of the same group.", "labels": [], "entities": []}, {"text": "A translation dictionary was constructed as a collection of the word correspondences.", "labels": [], "entities": []}, {"text": "The accuracy of this word aligner is about 90% for precision and 73% for recall by a closed test of content words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.999731719493866}, {"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9996065497398376}, {"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9988595247268677}]}, {"text": "Evaluation for MT Quality We used the following two methods to evaluate MT quality.", "labels": [], "entities": [{"text": "MT", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.9766800403594971}, {"text": "MT", "start_pos": 72, "end_pos": 74, "type": "TASK", "confidence": 0.9928511381149292}]}, {"text": "We used BLUE () with 10,150 sentences that were reserved for the test set.", "labels": [], "entities": [{"text": "BLUE", "start_pos": 8, "end_pos": 12, "type": "METRIC", "confidence": 0.996048629283905}]}, {"text": "The number of references was one for each sentence, and a range from uni-gram to fourgram was used.", "labels": [], "entities": []}, {"text": "From the above-mentioned test set, 510 sentences were evaluated by paired comparison.", "labels": [], "entities": []}, {"text": "In detail, the source sentences were translated using the base rule set created from the entire corpus, and the same sources were translated using the rules constructed with literalness.", "labels": [], "entities": []}, {"text": "One by one, a Japanese native speaker judged which MT result was better or that they were of the same quality.", "labels": [], "entities": [{"text": "MT", "start_pos": 51, "end_pos": 53, "type": "TASK", "confidence": 0.9662670493125916}]}, {"text": "Subjective quality is represented by the following equation, where I denotes the number of improved sentences and D denotes the number of degraded sentences.", "labels": [], "entities": []}, {"text": "The level of MT quality achieved by each of the construction methods is compared in.", "labels": [], "entities": [{"text": "MT", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.9834970235824585}]}, {"text": "Coverage of exact rules denotes the portion of sentences that were translated by using only the rules that require the source example to exactly match the input sentence.", "labels": [], "entities": []}, {"text": "In addition, the threshold TCR > 0.4 was used for filtering because it was experimentally shown to be the best value.", "labels": [], "entities": [{"text": "TCR", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9425424337387085}]}, {"text": "In the case of split construction, we used the extracted corpus after filtering based on the group maximum, and phrases that were TCR > 0.8 were judged to be literal phrases.", "labels": [], "entities": [{"text": "split construction", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.9030048549175262}, {"text": "TCR", "start_pos": 130, "end_pos": 133, "type": "METRIC", "confidence": 0.9896579384803772}]}], "tableCaptions": [{"text": " Table 1: Comparison of TDMT Training Translations and Original Translations", "labels": [], "entities": [{"text": "TDMT Training Translations", "start_pos": 24, "end_pos": 50, "type": "TASK", "confidence": 0.6413476665814718}]}, {"text": " Table 2: MT Quality vs. Construction Methods", "labels": [], "entities": [{"text": "MT", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.9858503937721252}]}]}