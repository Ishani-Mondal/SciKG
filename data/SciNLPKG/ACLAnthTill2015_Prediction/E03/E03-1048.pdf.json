{"title": [{"text": "A Corpus-Centered Approach to Spoken Language Translation", "labels": [], "entities": [{"text": "Spoken Language Translation", "start_pos": 30, "end_pos": 57, "type": "TASK", "confidence": 0.8835193713506063}]}], "abstractContent": [{"text": "This paper reports the latest performance of components and features of a project named Corpus-Centered Computation (C'3), which targets a translation technology suitable for spoken language translation.", "labels": [], "entities": [{"text": "spoken language translation", "start_pos": 175, "end_pos": 202, "type": "TASK", "confidence": 0.6935962637265524}]}, {"text": "C3 places corpora at the center of the technology.", "labels": [], "entities": []}, {"text": "Translation knowledge is extracted from corpora by both EBMT and SMT methods, translation quality is gauged by referring to corpora , the best translation among multiple-engine outputs is selected based on corpora and the corpora themselves are paraphrased or filtered by automated processes.", "labels": [], "entities": [{"text": "Translation knowledge", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8703286647796631}, {"text": "SMT", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.9087291955947876}]}], "introductionContent": [{"text": "Our project, named Corpus-Centered Computation (( 3 ), proposes solutions for efficiently constructing a high-quality translation subsystem fora speechto-speech translation system.", "labels": [], "entities": [{"text": "speechto-speech translation", "start_pos": 145, "end_pos": 172, "type": "TASK", "confidence": 0.7368560433387756}]}, {"text": "This paper introduces recent progress in C3 . Sections 2 and 3 demonstrate a competition between multiple machine translation systems developed in our project, and Sections 4 and 5 explain the features that differentiate our project from other corpus-based projects.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 106, "end_pos": 125, "type": "TASK", "confidence": 0.7564021646976471}]}], "datasetContent": [{"text": "We used the measures below.", "labels": [], "entities": []}, {"text": "The BLEU score and the RED rank are measured by referring to the test corpus, i.e., a set of input sentences and their multiple reference translations; the HUMAN rank and the estimated TOEIC score are judged by bilingual translators.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9782097637653351}, {"text": "RED rank", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9771643579006195}, {"text": "HUMAN rank", "start_pos": 156, "end_pos": 166, "type": "METRIC", "confidence": 0.9316898882389069}, {"text": "TOEIC score", "start_pos": 185, "end_pos": 196, "type": "METRIC", "confidence": 0.8614454567432404}]}, {"text": "(1) Average of Ranks2 : (2) BLEU score: The MT translations are scored based on the precision of N-grams in an entire set of multiple reference translations ().", "labels": [], "entities": [{"text": "Average of Ranks2", "start_pos": 4, "end_pos": 21, "type": "METRIC", "confidence": 0.9612619678179423}, {"text": "BLEU score", "start_pos": 28, "end_pos": 38, "type": "METRIC", "confidence": 0.984336793422699}, {"text": "MT translations", "start_pos": 44, "end_pos": 59, "type": "TASK", "confidence": 0.9456957280635834}, {"text": "precision", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.9933987855911255}]}, {"text": "It ranges from 1.0 (best) down to 0.0 (worst).", "labels": [], "entities": []}, {"text": "(3) Estimated TOEIC score: It is important to interpret MT performance from the viewpoint of a language proficiency test such as TOEIC . A translator compared MT translations with human ones, then, MT's proficiency is estimated by regression analysis ().", "labels": [], "entities": [{"text": "Estimated TOEIC score", "start_pos": 4, "end_pos": 25, "type": "METRIC", "confidence": 0.81104975938797}, {"text": "MT", "start_pos": 56, "end_pos": 58, "type": "TASK", "confidence": 0.9178471565246582}, {"text": "TOEIC", "start_pos": 129, "end_pos": 134, "type": "DATASET", "confidence": 0.7735695242881775}, {"text": "MT translations", "start_pos": 159, "end_pos": 174, "type": "TASK", "confidence": 0.9036025404930115}, {"text": "MT", "start_pos": 198, "end_pos": 200, "type": "TASK", "confidence": 0.9644345045089722}]}, {"text": "It ranges from 10 (lowest) to 990 points (perfect).", "labels": [], "entities": []}, {"text": "So far, SMT has been applied mainly to language pairs of similar European languages.", "labels": [], "entities": [{"text": "SMT", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9939847588539124}]}, {"text": "Skeptical opinions dominate about the effectiveness or applicability of SMT to dissimilar language pairs.", "labels": [], "entities": [{"text": "SMT", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.9928188920021057}]}, {"text": "However, we implemented SMT for translation between Japanese and English.", "labels": [], "entities": [{"text": "SMT", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9684514403343201}, {"text": "translation between Japanese and English", "start_pos": 32, "end_pos": 72, "type": "TASK", "confidence": 0.8258159518241882}]}, {"text": "They are dissimilar in many points, such as word order and lexical systems.", "labels": [], "entities": []}, {"text": "We found that SAT, which is an SMT, worked in both J-to-E and Eto-J directions.", "labels": [], "entities": [{"text": "SAT", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.586672842502594}, {"text": "SMT", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9821236729621887}]}], "tableCaptions": [{"text": " Table 1 Quality Evaluation of Three MTs5", "labels": [], "entities": [{"text": "Quality Evaluation", "start_pos": 9, "end_pos": 27, "type": "METRIC", "confidence": 0.9201040863990784}, {"text": "MTs5", "start_pos": 37, "end_pos": 41, "type": "TASK", "confidence": 0.9196973443031311}]}]}