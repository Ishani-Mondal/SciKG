{"title": [{"text": "Development of Corpora within the CLaRK System The BulTreeBank Project Experience", "labels": [], "entities": []}], "abstractContent": [{"text": "CLaRK is an XML-based software system for corpora development.", "labels": [], "entities": [{"text": "CLaRK", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8916906118392944}, {"text": "corpora development", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.7424067556858063}]}, {"text": "It incorporates several technologies: XML technology; Un i code ; Regular Cascaded Grammars; Constraints over XML Documents.", "labels": [], "entities": []}, {"text": "The basic components of the system are: a tagger, a concordancer, an extractor, a grammar processor, a constraint engine.", "labels": [], "entities": []}], "introductionContent": [{"text": "The CLaRK System is an XML-based system for corpora development -see).", "labels": [], "entities": []}, {"text": "The main aim behind the design of the system is the minimization of human intervention during the creation of language resources.", "labels": [], "entities": []}, {"text": "It incorporates the following technologies: XML technology; Unicode; Regular Cascaded Grammars; Constraints over XML Documents.", "labels": [], "entities": []}, {"text": "For document management, storing and querying, we chose the XML technology because of its popularity and its ease of understanding.", "labels": [], "entities": [{"text": "document management", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7989710569381714}]}, {"text": "The core of CLaRK is an Unicode XML Editor, which is the main interface to the system.", "labels": [], "entities": []}, {"text": "Besides the XML language itself, we implemented an XPath language for navigation in documents and an XSLT engine for transformation of XML documents.", "labels": [], "entities": []}, {"text": "The XSL transformations can be applied locally to an XML element and its content.", "labels": [], "entities": []}, {"text": "For multilingual processing tasks, CLaRK is based on an Unicode encoding of the text inside the system.", "labels": [], "entities": []}, {"text": "There is a mechanism for the creation of a hierarchy of tokenisers.", "labels": [], "entities": []}, {"text": "They can be attached to the elements in the DTDs and in this way there are different tokenisers for different parts of the documents.", "labels": [], "entities": []}, {"text": "The basic mechanism of CLaRK for linguistic processing of text corpora is the cascaded regular grammar processor.", "labels": [], "entities": []}, {"text": "The main challenge to the grammars in question is how to apply them on XML encoding of the linguistic information.", "labels": [], "entities": []}, {"text": "The system offers a solution using the XPath language for constructing the input word to the grammar and an XML encoding of the categories of the recognised words.", "labels": [], "entities": []}, {"text": "Several mechanisms for imposing constraints over XML documents are available.", "labels": [], "entities": []}, {"text": "The constraints cannot be stated within the standard XML technology.", "labels": [], "entities": []}, {"text": "The constraints are used in two modes: checking the validity of a document regarding a set of constraints; supporting the linguist in his/her work during the building of a corpus.", "labels": [], "entities": []}, {"text": "The first mode allows the creation of constraints for the validation of a corpus according to given requirements.", "labels": [], "entities": []}, {"text": "The second mode helps the underlying strategy for minimisation of the human labour.", "labels": [], "entities": [{"text": "minimisation", "start_pos": 50, "end_pos": 62, "type": "TASK", "confidence": 0.9705786108970642}]}, {"text": "We envisage several uses for our system: Corpora markup.", "labels": [], "entities": [{"text": "Corpora markup", "start_pos": 41, "end_pos": 55, "type": "TASK", "confidence": 0.6886512935161591}]}, {"text": "Here users work with the XML tools of the system in order to mark-up texts with respect to an XML DTD.", "labels": [], "entities": []}, {"text": "This task usually requires an enormous human effort and handles both -the mark-up itself and its validation afterwards.", "labels": [], "entities": []}, {"text": "Using the available grammar resources, such as morphological analyzers or partial parsing, the system can state local constraints reflecting the characteristics of a particular kind of texts or mark-up.", "labels": [], "entities": []}, {"text": "Dictionary compilation for human users.", "labels": [], "entities": [{"text": "Dictionary compilation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.693102091550827}]}, {"text": "The system supports the creation of actual lexical entries, whose structure can be defined via an appropriate DTD.", "labels": [], "entities": []}, {"text": "The XML tools can be used also for corpus investigation that provides appropriate examples of the word usage in the available corpora.", "labels": [], "entities": [{"text": "corpus investigation", "start_pos": 35, "end_pos": 55, "type": "TASK", "confidence": 0.7188106030225754}]}, {"text": "The constraints, incorporated in the system, can be used for writing a grammar over the sublanguages of the definitions, for imposing constraints over elements of lexical entries and the dictionary as a whole.", "labels": [], "entities": []}, {"text": "The CLaRK System offers a rich set of tools for searching over tokens and mark-up in XML corpora, including cascaded grammars, XPath language.", "labels": [], "entities": []}, {"text": "Their combinations are used for tasks, such as: extraction of elements from a corpus -for example, extraction of all NPs in the corpus; concordance -for example, viewing all NPs in the context of their use.", "labels": [], "entities": []}, {"text": "The first version of the CLaRK System was released on 20.05.2002 and it is freely available at the site of the BulTreeBank Projectl . It is actively used within the BulTreeBank Project for maintenance of language resources of different kindstext archive, morphologically annotated corpora, syntactic trees and lexicons.", "labels": [], "entities": [{"text": "BulTreeBank Projectl", "start_pos": 111, "end_pos": 131, "type": "DATASET", "confidence": 0.965128093957901}]}, {"text": "It is implemented in Java and was tested under MS Windows and Linux.", "labels": [], "entities": []}, {"text": "The paper describes three applications of the CLaRK system, related to corpora development.", "labels": [], "entities": [{"text": "corpora development", "start_pos": 71, "end_pos": 90, "type": "TASK", "confidence": 0.8040818572044373}]}, {"text": "These includes: chunk grammars, disambiguation and evaluation (precision and recall).", "labels": [], "entities": [{"text": "precision", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.9984266757965088}, {"text": "recall", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.9141780138015747}]}, {"text": "This paper does not discuss related work due to space limitations.", "labels": [], "entities": []}], "datasetContent": [{"text": "At the moment the CLaRK system does not have a separate tool for comparing two XML documents, which to be used for calculation of the two measures -precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 148, "end_pos": 157, "type": "METRIC", "confidence": 0.9982659220695496}, {"text": "recall", "start_pos": 162, "end_pos": 168, "type": "METRIC", "confidence": 0.995941698551178}]}, {"text": "However, one could simulate it by using the present tools of the system.", "labels": [], "entities": []}, {"text": "Let us have developed an NP chunk grammar and additionally, a manually annotated corpus.", "labels": [], "entities": []}, {"text": "Let the NPs in the corpus have an attribute type with value \" m\" . In addition, we run the NP chunk grammar over a clean version of the corpus and the NPs in the result have the attribute type with value \" g \" . In order to evaluate the precision and recall of the grammar over the annotated corpus, we have to do the following: 1.", "labels": [], "entities": [{"text": "precision", "start_pos": 237, "end_pos": 246, "type": "METRIC", "confidence": 0.9990746974945068}, {"text": "recall", "start_pos": 251, "end_pos": 257, "type": "METRIC", "confidence": 0.9969731569290161}]}, {"text": "First, we extract the NPs, which are presented within the corpus and in the output from the application of the grammar.", "labels": [], "entities": []}, {"text": "Then we join the two sets of NPs in one XML document.", "labels": [], "entities": []}, {"text": "With a perfect grammar, for each NP marked with value \"m\" there should be one NP marked with value \" g \" and vice versa, but usually this is not the case.", "labels": [], "entities": []}, {"text": "2. In order to find the discrepancies, we remove the NPs in pairs on the basis of the equal content.", "labels": [], "entities": []}, {"text": "The only difference is that one NP in the pair has value \"m\" and the other one has value \" g \" for the attribute type.", "labels": [], "entities": []}, {"text": "In the end, within the document, the NPs with attribute t ype= \" g \" are those NPs that are recognized by the grammar, but there is no corresponding NPs in the corpus and similarly, the NPs with attribute t ype= \"m\" are those NPs that are in the corpus, but they are not recognized by the grammar.", "labels": [], "entities": []}, {"text": "3. Then we count the two kinds of NPs, which have left unmatched in the document.", "labels": [], "entities": []}, {"text": "We use the figures (together with the number of all NPs in the corpus) in order to calculate the precision and recall for the grammar.", "labels": [], "entities": [{"text": "precision", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9995311498641968}, {"text": "recall", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.9991210103034973}]}, {"text": "Although this procedure is precise with respect to the internal structure of the compared sub-trees, it is not sensitive to the context of appearance of these sub-trees4 . For example, one NP in the corpus can match a NP in the grammar result even if they are in quite different contexts.", "labels": [], "entities": []}, {"text": "In order to solve the problem, we add to each leaf element in the XML documents unique identifiers that are the same for the corpus and the result from the application of the grammar.", "labels": [], "entities": []}, {"text": "In this way we compare the NPs (in our case) on the basis of their content and also their position in the linear order of the words in the sentences.", "labels": [], "entities": []}], "tableCaptions": []}