{"title": [{"text": "Named Entity Recognition for Catalan Using Spanish Resources", "labels": [], "entities": [{"text": "Entity Recognition", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.6747048646211624}]}], "abstractContent": [{"text": "This work studies Named Entity Recognition (NER) for Catalan without making use of annotated resources of this language.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 18, "end_pos": 48, "type": "TASK", "confidence": 0.7765485296646754}]}, {"text": "The approach presented is based on machine learning techniques and exploits Spanish resources, either by first training models for Spanish and then translating them into Catalan, or by directly training bilingual models.", "labels": [], "entities": []}, {"text": "The resulting models are retrained on unla-belled Catalan data using bootstrapping techniques.", "labels": [], "entities": []}, {"text": "Exhaustive experimentation has been conducted on real data, showing competitive results for the obtained NER systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "A Named Entity (NE) is a lexical unit consisting of a sequence of contiguous words which refers to a concrete entity -such as a person, a location, an organization or an artifact.", "labels": [], "entities": [{"text": "Named Entity (NE) is a lexical unit consisting of a sequence of contiguous words which refers to a concrete entity -such as a person, a location, an organization or an artifact", "start_pos": 2, "end_pos": 178, "type": "Description", "confidence": 0.7537073964873949}]}, {"text": "contains an example sentence, extracted from the Spanish corpus referred in section 2 and translated into Catalan, including several entities.", "labels": [], "entities": []}, {"text": "There is a wide consensus about that Named Entity Recognition and Classification (NERC) are Natural Language Processing tasks which may improve the performance of many applications, such as Information Extraction, Machine Translation, Question Answering, Topic Detection and Tracking, etc.", "labels": [], "entities": [{"text": "Named Entity Recognition and Classification (NERC)", "start_pos": 37, "end_pos": 87, "type": "TASK", "confidence": 0.8225312680006027}, {"text": "Information Extraction", "start_pos": 190, "end_pos": 212, "type": "TASK", "confidence": 0.8284812569618225}, {"text": "Machine Translation", "start_pos": 214, "end_pos": 233, "type": "TASK", "confidence": 0.8357564508914948}, {"text": "Question Answering", "start_pos": 235, "end_pos": 253, "type": "TASK", "confidence": 0.8561093509197235}, {"text": "Topic Detection and Tracking", "start_pos": 255, "end_pos": 283, "type": "TASK", "confidence": 0.9032102972269058}]}, {"text": "Thus, interest on detecting and classifying those units in a text has kept on growing during the last years.", "labels": [], "entities": []}, {"text": "Named Entity processing consists of two steps, which are usually approached sequentially.", "labels": [], "entities": [{"text": "Entity processing", "start_pos": 6, "end_pos": 23, "type": "TASK", "confidence": 0.739412933588028}]}, {"text": "First, NEs are detected in the text, and their boundaries delimited (Named Entity Recognition, NER).", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 69, "end_pos": 93, "type": "TASK", "confidence": 0.546803226073583}]}, {"text": "Second, entities are classified in a predefined set of classes, which usually contain labels such as person, organization, location, etc.", "labels": [], "entities": []}, {"text": "(Named Entity Classification, NEC).", "labels": [], "entities": [{"text": "Named Entity Classification, NEC)", "start_pos": 1, "end_pos": 34, "type": "TASK", "confidence": 0.5613556752602259}]}, {"text": "In this paper we will focus on the first of these stages, that is, Named Entity boundary detection.", "labels": [], "entities": [{"text": "Named Entity boundary detection", "start_pos": 67, "end_pos": 98, "type": "TASK", "confidence": 0.6423236355185509}]}, {"text": "Previous work in this topic is mainly framed in the Message Understanding Conferences (MUC), devoted to Information Extraction, which included a NERC task.", "labels": [], "entities": [{"text": "Message Understanding Conferences (MUC)", "start_pos": 52, "end_pos": 91, "type": "TASK", "confidence": 0.8051553865273794}, {"text": "Information Extraction", "start_pos": 104, "end_pos": 126, "type": "TASK", "confidence": 0.8454359769821167}, {"text": "NERC task", "start_pos": 145, "end_pos": 154, "type": "TASK", "confidence": 0.7485800385475159}]}, {"text": "Some MUC systems rely on data-driven approaches, such as Nymble () which uses Hidden Markov Models, or ALEMBIC (, based on Error Driven Transformation Based Learning.", "labels": [], "entities": [{"text": "MUC", "start_pos": 5, "end_pos": 8, "type": "TASK", "confidence": 0.9556289911270142}, {"text": "ALEMBIC", "start_pos": 103, "end_pos": 110, "type": "METRIC", "confidence": 0.8540971875190735}]}, {"text": "Others use only hand-coded knowledge, such as FACILE () which relies on handwritten unification context rules with certainty factors, or FASTUS (, PLUM and NetOwl Extractor () which are based on cascaded finite state transducers or pattern matching.", "labels": [], "entities": [{"text": "FACILE", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.8436177968978882}, {"text": "FASTUS", "start_pos": 137, "end_pos": 143, "type": "METRIC", "confidence": 0.8211987614631653}]}, {"text": "There are also hybrid systems combining corpus evidence and gazetteer information (), or combining hand-written rules with Maximum Entropy models to solve correference ().", "labels": [], "entities": []}, {"text": "More recent approaches can be found in the proceedings of the shared task at the 2002 edition of the Conference on Natural Language Learning, CoNLL'02, where several machine-learning systems were compared at the NERC task.", "labels": [], "entities": [{"text": "shared task at the 2002 edition of the Conference on Natural Language Learning, CoNLL'02", "start_pos": 62, "end_pos": 150, "type": "TASK", "confidence": 0.668327780564626}, {"text": "NERC task", "start_pos": 212, "end_pos": 221, "type": "TASK", "confidence": 0.5691331923007965}]}, {"text": "Usually, machine learning (ML) systems rely on algorithms that take as input a set of labelled examples for the target task and produce as output a model (which may take different forms, depending on the used algorithm) that can be applied to new examples to obtain a prediction.", "labels": [], "entities": [{"text": "machine learning (ML)", "start_pos": 9, "end_pos": 30, "type": "TASK", "confidence": 0.7533222913742066}]}, {"text": "CoNLL'02 participants used different state-of-the-art ML algorithms, such as Support Vector Machines (), AdaBoost), Transformation-Based methods), Memory-based techniques) or Hidden Markov Models), among others.", "labels": [], "entities": [{"text": "CoNLL'02", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9036003351211548}]}, {"text": "One remarkable aspect of most widely used ML algorithms is that they are supervised, that is, they require a set of labelled data to be trained on.", "labels": [], "entities": [{"text": "ML", "start_pos": 42, "end_pos": 44, "type": "TASK", "confidence": 0.9849217534065247}]}, {"text": "This may cause a severe bottleneck when such data is not available or is expensive to obtain, which is usually the case for minority languages with few pre-existing linguistic resources and/or limited funding possibilities.", "labels": [], "entities": []}, {"text": "Our goal in this paper is to develop a low-cost Named Entity recognition system for Catalan.", "labels": [], "entities": [{"text": "Named Entity recognition", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.7087421218554179}]}, {"text": "To achieve this, we take advantage of the facts that Spanish and Catalan are two Romance languages with similar syntactic structure, and that -since Spanish and Catalan social and cultural environments greatly overlap-many Named Entities appear in both languages corpora.", "labels": [], "entities": []}, {"text": "Relying on this structural and content similarity, we will build our Catalan NE recognizer on the following assumptions: (a) Named Entities appear in the same contexts in both languages, and (b) Named Entities are composed by similar patterns in both languages.", "labels": [], "entities": []}, {"text": "The work departs from the use of existing annotated Spanish corpora and machine learning techniques to obtain Spanish NER models.", "labels": [], "entities": []}, {"text": "We first build low-cost resources (about 10 person-hours each), namely a small Catalan training corpus and translation dictionaries from Spanish to Catalan.", "labels": [], "entities": [{"text": "translation dictionaries from Spanish to Catalan", "start_pos": 107, "end_pos": 155, "type": "TASK", "confidence": 0.816368043422699}]}, {"text": "We then present and evaluate several strategies to obtain a low-cost Catalan system.", "labels": [], "entities": []}, {"text": "Simple naive strategies consist of learning from the large Spanish corpus a model which makes no use of lexical information, or learning a model for Catalan using the small Catalan corpus.", "labels": [], "entities": []}, {"text": "More sophisticated strategies are translating a Spanish model into Catalan, or directly learning a bilingual model applicable to both languages.", "labels": [], "entities": []}, {"text": "Experimentation shows that the latter strategies, specially the bilingual models, provide very good performance, somewhat better than the former techniques.", "labels": [], "entities": []}, {"text": "We also study the evolution of these models within a bootstrapping process, observing no significant improvement.", "labels": [], "entities": []}, {"text": "Next section of the paper describes the used corpora and evaluation measures.", "labels": [], "entities": []}, {"text": "Section 3 describes the NER learning system.", "labels": [], "entities": [{"text": "NER learning", "start_pos": 24, "end_pos": 36, "type": "TASK", "confidence": 0.8461841344833374}]}, {"text": "Section 4 presents the strategies to obtain a low-cost Catalan NER system and provides results.", "labels": [], "entities": [{"text": "NER", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.8402495384216309}]}, {"text": "Bootstrapping is studied in section 5, and, finally, section 6 concludes.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experimentation of this work has been carried on two corpora, one for each language.", "labels": [], "entities": []}, {"text": "In both cases, the corpora consist of sentences extracted from news articles of same year, namely year 2,000.", "labels": [], "entities": []}, {"text": "The Spanish data corresponds to the CoNLL 2002 Shared Task Spanish data, the original source being the EFE Spanish Newswire Agency.", "labels": [], "entities": [{"text": "CoNLL 2002 Shared Task Spanish data", "start_pos": 36, "end_pos": 71, "type": "DATASET", "confidence": 0.9227800369262695}, {"text": "EFE Spanish Newswire Agency", "start_pos": 103, "end_pos": 130, "type": "DATASET", "confidence": 0.9717822819948196}]}, {"text": "It consists of three files: a training set, a development set and a test set.", "labels": [], "entities": []}, {"text": "The first two are used respectively to train and tune a system, and the latter is used to evaluate and compare systems.", "labels": [], "entities": []}, {"text": "available a large amount of news articles extracted from the Catalan edition of the daily newspaper El PeriOdic\u00b0 de Catalunya (also from year 2,000).", "labels": [], "entities": []}, {"text": "From this corpus, we selected two sets for manual annotation: a training set, to train a system, and a test set, to perform the evaluation.", "labels": [], "entities": []}, {"text": "The remaining data was left as unlabelled data.", "labels": [], "entities": []}, {"text": "As evaluation method we use the common measures for recognition tasks: precision, recall and F1 . Precision is the percentage of NEs predicted by a system which are correct.", "labels": [], "entities": [{"text": "precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9996582269668579}, {"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.998824417591095}, {"text": "F1", "start_pos": 93, "end_pos": 95, "type": "METRIC", "confidence": 0.9996577501296997}, {"text": "Precision", "start_pos": 98, "end_pos": 107, "type": "METRIC", "confidence": 0.9976600408554077}]}, {"text": "Recall is the percentage of NEs in the data that a system correctly recognizes.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9849488139152527}]}, {"text": "Finally, the F1 measure computes the harmonic mean of precision (p) and recall (r) as 2 p \u2022 Op + r).", "labels": [], "entities": [{"text": "F1 measure", "start_pos": 13, "end_pos": 23, "type": "METRIC", "confidence": 0.9703773260116577}, {"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9906381368637085}, {"text": "recall (r)", "start_pos": 72, "end_pos": 82, "type": "METRIC", "confidence": 0.9476079940795898}]}], "tableCaptions": [{"text": " Table 1: Sizes of Spanish and Catalan data sets", "labels": [], "entities": [{"text": "Sizes", "start_pos": 10, "end_pos": 15, "type": "TASK", "confidence": 0.9839361906051636}, {"text": "Spanish and Catalan data sets", "start_pos": 19, "end_pos": 48, "type": "DATASET", "confidence": 0.7082406222820282}]}, {"text": " Table 2: Evaluation of the learned models on the test datasets for Spanish (es) and Catalan (ca). The \"es\"  and \"ca train\" columns indicate the training material used in each model. The \"dim\" column specifies  the dicctionary (either manual or automatic) used for translating models. The NO_LEX model learns  without making use of lexical information. The LEx.ca model is a baseline standard model developed on  Catalan. The LEx.es2ca is a translated model from Spanish to Catalan. The X-LING models are bilingual  models using cross-linguistic features.", "labels": [], "entities": [{"text": "NO_LEX", "start_pos": 289, "end_pos": 295, "type": "METRIC", "confidence": 0.5471900105476379}]}]}