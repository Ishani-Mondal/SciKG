{"title": [], "abstractContent": [{"text": "This paper presents an unsupervised algorithm which automatically discovers word senses from text.", "labels": [], "entities": []}, {"text": "The algorithm is based on a graph model representing words and relationships between them.", "labels": [], "entities": []}, {"text": "Sense clusters are iteratively computed by clustering the local graph of similar words around an ambiguous word.", "labels": [], "entities": []}, {"text": "Discrimination against previously extracted sense clusters enables us to discover new senses.", "labels": [], "entities": []}, {"text": "We use the same data for both recognising and resolving ambiguity .", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes an algorithm which automatically discovers word senses from free text and maps them to the appropriate entries of existing dictionaries or taxonomies.", "labels": [], "entities": []}, {"text": "Automatic word sense discovery has applications of many kinds.", "labels": [], "entities": [{"text": "Automatic word sense discovery", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7070308402180672}]}, {"text": "It can greatly facilitate a lexicographer's work and can be used to automatically construct corpus-based taxonomies or to tune existing ones.", "labels": [], "entities": []}, {"text": "The same corpus evidence which supports a clustering of an ambiguous word into distinct senses can be used to decide which sense is referred to in a given context.", "labels": [], "entities": []}, {"text": "This paper is organised as follows.", "labels": [], "entities": []}, {"text": "In section 2, we present the graph model from which we discover word senses.", "labels": [], "entities": []}, {"text": "Section 3 describes the way we divide graphs surrounding ambiguous words into different areas corresponding to different senses, using Markov clustering).", "labels": [], "entities": []}, {"text": "The quality of the Markov clustering depends strongly on several parameters such as a granularity factor and the size of the local graph.", "labels": [], "entities": []}, {"text": "In section 4, we outline a word sense discovery algorithm which bypasses the problem of parameter tuning.", "labels": [], "entities": [{"text": "word sense discovery", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.7854663928349813}, {"text": "parameter tuning", "start_pos": 88, "end_pos": 104, "type": "TASK", "confidence": 0.7484404444694519}]}, {"text": "We conducted a pilot experiment to examine the performance of our algorithm on a set of words with varying degree of ambiguity.", "labels": [], "entities": []}, {"text": "Section 5 describes the experiment and presents a sample of the results.", "labels": [], "entities": []}, {"text": "Finally, section 6 sketches applications of the algorithm and discusses future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe an initial evaluation experiment and present the results.", "labels": [], "entities": []}, {"text": "We will soon carryout and report on a more thorough analysis of our algorithm.", "labels": [], "entities": []}, {"text": "We used the simple graph model based on cooccurrences of nouns in lists (cf. section 2) for our experiment.", "labels": [], "entities": []}, {"text": "We gathered a list of nouns with varying degree of ambiguity, from homonymy (e.g. arms) to systematic polysemy (e.g. cherry).", "labels": [], "entities": []}, {"text": "Our algorithm was applied to each word in the list (with parameters Iii = 20, n2 = 10, r = 2.0, k = 2.0) in order to extract the top two sense clusters only.", "labels": [], "entities": [{"text": "Iii", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.9799889326095581}]}, {"text": "We then determined the WordNet synsets which most adequately characterized the sense clusters.", "labels": [], "entities": [{"text": "WordNet synsets", "start_pos": 23, "end_pos": 38, "type": "DATASET", "confidence": 0.9269762933254242}]}, {"text": "An extract of the results is listed in table 1.", "labels": [], "entities": []}], "tableCaptions": []}