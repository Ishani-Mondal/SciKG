{"title": [{"text": "Learning Translations of Named-Entity Phrases from Parallel Corpora", "labels": [], "entities": [{"text": "Learning Translations of Named-Entity Phrases from Parallel Corpora", "start_pos": 0, "end_pos": 67, "type": "TASK", "confidence": 0.8450872972607613}]}], "abstractContent": [{"text": "We develop anew approach to learning phrase translations from parallel corpora , and show that it performs with very high coverage and accuracy in choosing French translations of English named-entity phrases in a test corpus of software manuals.", "labels": [], "entities": [{"text": "learning phrase translations from parallel corpora", "start_pos": 28, "end_pos": 78, "type": "TASK", "confidence": 0.7721121360858282}, {"text": "coverage", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9552270174026489}, {"text": "accuracy", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.9962054491043091}]}, {"text": "Analysis of a subset of our results suggests that the method should also perform well on more general phrase translation tasks.", "labels": [], "entities": [{"text": "phrase translation tasks", "start_pos": 102, "end_pos": 126, "type": "TASK", "confidence": 0.85060187180837}]}], "introductionContent": [{"text": "Machine translation can benefit greatly from augmenting knowledge of word translations with knowledge of phrase translations.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7157699465751648}, {"text": "phrase translations", "start_pos": 105, "end_pos": 124, "type": "TASK", "confidence": 0.723698079586029}]}, {"text": "Multiword phrases may have nonliteral translations, or one of several equally valid literal translations maybe strongly preferred in practice.", "labels": [], "entities": []}, {"text": "Automatically learning translations of single words from parallel corpora has been much studied over the past ten years or so, and references), but learning translations of multiword phrases has received less attention.", "labels": [], "entities": [{"text": "Automatically learning translations of single words from parallel corpora", "start_pos": 0, "end_pos": 73, "type": "TASK", "confidence": 0.754308690627416}]}, {"text": "(See Section 5 fora review of prior work in this area.)", "labels": [], "entities": []}, {"text": "In this paper, we develop anew approach to learning phrase translations from parallel corpora, and show that it performs with very high coverage and accuracy on a named-entity phrase translation task.", "labels": [], "entities": [{"text": "learning phrase translations from parallel corpora", "start_pos": 43, "end_pos": 93, "type": "TASK", "confidence": 0.7715586274862289}, {"text": "coverage", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.9676498770713806}, {"text": "accuracy", "start_pos": 149, "end_pos": 157, "type": "METRIC", "confidence": 0.9964780211448669}, {"text": "phrase translation task", "start_pos": 176, "end_pos": 199, "type": "TASK", "confidence": 0.7818087339401245}]}, {"text": "Moreover, analysis of a subset of our evaluation results suggests that the method should also perform well on more general phrase translation tasks.", "labels": [], "entities": [{"text": "phrase translation tasks", "start_pos": 123, "end_pos": 147, "type": "TASK", "confidence": 0.8474921186765035}]}, {"text": "In our approach, we are given a sentencealigned parallel corpus annotated with a set of phrases in one of the two languages (the source language), and our goal is identify the corresponding phrases in the corpus in the other language (the target language), ranking the translation pairs in order of confidence.", "labels": [], "entities": []}, {"text": "Certain segments of the target language corpus maybe annotated as constituting lexical compounds, which mayor may not include the translations of the source language phrases of interest.", "labels": [], "entities": []}, {"text": "Otherwise there is no annotation of the target language text, except for its being divided into words and sentences.", "labels": [], "entities": []}, {"text": "Below we describe the issues in named-entity phrase translation motivating this research, we explain our algorithm, and we present the results of our evaluation on a named-entity phrase translation task.", "labels": [], "entities": [{"text": "named-entity phrase translation", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.6147432823975881}, {"text": "named-entity phrase translation task", "start_pos": 166, "end_pos": 202, "type": "TASK", "confidence": 0.7384674847126007}]}, {"text": "We pay particular attention to the subset of the data that lacks the special characteristics of the named-entity task that we take advantage of to optimize our performance, to suggest how the algorithm might perform on more general tasks.", "labels": [], "entities": []}, {"text": "Finally we compare our approach and results to previous work on learning phrase translations.", "labels": [], "entities": [{"text": "learning phrase translations", "start_pos": 64, "end_pos": 92, "type": "TASK", "confidence": 0.6042663156986237}]}], "datasetContent": [{"text": "The algorithm was developed using EnglishSpanish parallel data, and independently tested on 192,711 English-French parallel sentence pairs consisting mainly of computer software manuals.", "labels": [], "entities": [{"text": "EnglishSpanish parallel data", "start_pos": 34, "end_pos": 62, "type": "DATASET", "confidence": 0.7664892872174581}]}, {"text": "73,108 occurrences of 12,301 unique multiword named-entity phrases were hypothesized in the English data by a hand-built rule-based tagger, mainly using capitalization clues.", "labels": [], "entities": []}, {"text": "We evaluated the performance of our algorithm in finding translations for the hypothesized named-entity phrases using a random sample of 1195 of the proposed translations.", "labels": [], "entities": []}, {"text": "The correctness of the correspondence between the English phrases and their hypothesized translations was judged by a fluent French-English bilingual, with the aid of the sentence pair for which each hypothesized translation received the highest score, according to Model 1.", "labels": [], "entities": []}, {"text": "(In preliminary work, we found that it was very difficult to judge correctness without seeing relevant examples from the data.)", "labels": [], "entities": []}, {"text": "In some cases, the existence of words in the French not corresponding to anything in the English led to multiple equally valid phrase correspondences, any of which was judged correct.", "labels": [], "entities": []}, {"text": "Clear cases of partial matches, however, were always counted as incorrect.", "labels": [], "entities": []}, {"text": "The results of the evaluation are shown in Table 2.", "labels": [], "entities": []}, {"text": "\"Cumulative Coverage\" means the proportion of the unique phrases for which at least one translation is proposed, proceeding in order of strength of association from highest to lowest.", "labels": [], "entities": []}, {"text": "\"Cumulative Accuracy\" is the estimated accuracy of the translations proposed for the top scoring fraction of translations corresponding to \"Cumulative Coverage\".", "labels": [], "entities": [{"text": "Accuracy\"", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.8968025147914886}, {"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9966025352478027}]}, {"text": "2 \"Good Input' Cumulative Accuracy\" is the same as \"Cumulative Accuracy\", but removing 157 cases (13% of the test data) where it was impossible choose a correct French translation for the English phrase, within the assumptions of the task.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.793154239654541}]}, {"text": "the proportion of the English test phrases that had only a single occurrence in the data.", "labels": [], "entities": []}, {"text": "These results show accuracy over 80% up to 99% coverage, with accuracy over 91% at 99% coverage when only data free of tokenization errors and missing translations is considered.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9994864463806152}, {"text": "coverage", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9899924397468567}, {"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.999521017074585}, {"text": "coverage", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9160827398300171}]}, {"text": "Moreover, at this level 62% of the English test phrases had only a single occurrence in the data.", "labels": [], "entities": []}, {"text": "This level of performance is very high compared to previous work on phrase translation, but this task does have several properties that probably make it easier than a more general phrase translation task would be.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.8955441117286682}, {"text": "phrase translation task", "start_pos": 180, "end_pos": 203, "type": "TASK", "confidence": 0.8169680237770081}]}, {"text": "First, 17% of the English phrases were repeated exactly in the French corpus.", "labels": [], "entities": [{"text": "French corpus", "start_pos": 63, "end_pos": 76, "type": "DATASET", "confidence": 0.8125466108322144}]}, {"text": "Second, 80% of the French translations began with a capital letter.", "labels": [], "entities": []}, {"text": "Finally, 16% of the French translations were already identified as complete lexical compounds.", "labels": [], "entities": []}, {"text": "To test the robustness of our technique to phrase cies) in identification of lexical compounds in English and/or French that made it impossible to correctly identify the correct French translation of an English phrase.", "labels": [], "entities": [{"text": "identification of lexical compounds in English and/or French", "start_pos": 59, "end_pos": 119, "type": "TASK", "confidence": 0.8388754189014435}]}, {"text": "(Smadja et al. similarly report the performance of their collocationtranslation learner, removing errors due to mistakes in identifying the source language collocations.)", "labels": [], "entities": []}, {"text": "These included cases where English words were inconectly included in or omitted from the phrase so that there was no single corresponding French phrase, or where an incorrect identification of a French lexical compound connected words in the translation of the English phrase with words not in the translation.", "labels": [], "entities": []}, {"text": "The remaining 15% of the cases excluded from \"good input\" were cases where the French sentence simply did not contain any phrase corresponding to the English phrase, either because of free translation or because of errors in sentence alignment.", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 225, "end_pos": 243, "type": "TASK", "confidence": 0.7036634385585785}]}, {"text": "translation learning tasks where these advantages are lacking, we analyzed our evaluation data to find all cases where the tokenizations were correct, but the correct translation of the English phrase began with a lowercase letter, and the translation itself was not identified as a lexical compound in preprocessing.", "labels": [], "entities": []}, {"text": "(This also guaranteed that none of the translations was identical to the English phrase, since all the English test phrases began with a capital letter.)", "labels": [], "entities": []}, {"text": "There were 240 such cases out of our sample of 1195 hypothesized translation pairs.", "labels": [], "entities": []}, {"text": "The performance of the algorithm on this \"hard\" subset of the data is shown in the last column of.", "labels": [], "entities": []}, {"text": "Compared with the results in the third column on all the \"good input\" data, the error rates go up by a factor of 2-3, but accuracy is still a quite respectable 84% at 99% coverage.", "labels": [], "entities": [{"text": "error", "start_pos": 80, "end_pos": 85, "type": "METRIC", "confidence": 0.9821488261222839}, {"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9995755553245544}, {"text": "coverage", "start_pos": 171, "end_pos": 179, "type": "METRIC", "confidence": 0.9807162284851074}]}], "tableCaptions": [{"text": " Table 2: Performance of phrase translation learning algorithm.", "labels": [], "entities": [{"text": "phrase translation learning", "start_pos": 25, "end_pos": 52, "type": "TASK", "confidence": 0.9181000590324402}]}]}