{"title": [{"text": "Using POS Information for Statistical Machine Translation into Morphologically Rich Languages", "labels": [], "entities": [{"text": "Statistical Machine Translation into Morphologically Rich Languages", "start_pos": 26, "end_pos": 93, "type": "TASK", "confidence": 0.8090496148381915}]}], "abstractContent": [{"text": "When translating from languages with hardly any inflectional morphology like English into morphologically rich languages , the English word forms often do not contain enough information for producing the correct fullform in the target language.", "labels": [], "entities": []}, {"text": "We investigate methods for improving the quality of such translations by making use of part-of-speech information and maximum en-tropy modeling.", "labels": [], "entities": []}, {"text": "Results for translations from English into Spanish and Catalan are presented on the LC-STAR corpus which consists of spontaneously spoken dialogues in the domain of appointment scheduling and travel planning.", "labels": [], "entities": [{"text": "LC-STAR corpus", "start_pos": 84, "end_pos": 98, "type": "DATASET", "confidence": 0.9255447089672089}, {"text": "appointment scheduling", "start_pos": 165, "end_pos": 187, "type": "TASK", "confidence": 0.7007412761449814}]}], "introductionContent": [{"text": "In this paper, we address the question of how partof-speech (POS) information can help improving the quality of Statistical Machine Translation (SMT).", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 112, "end_pos": 149, "type": "TASK", "confidence": 0.8285947342713674}]}, {"text": "One of the main problems when translating from a language with hardly any inflectional morphology (which is English in our experiments) into one with richer morphology (here: Spanish and Catalan) is the production of the correct inflected form in the target language.", "labels": [], "entities": []}, {"text": "We introduce transformations to the English string that are based on the part-of-speech information and show how this knowledge source can help SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 144, "end_pos": 147, "type": "TASK", "confidence": 0.9968225955963135}]}, {"text": "Systematic evaluations will show that the quality of the generated translations is improved.", "labels": [], "entities": []}, {"text": "The transformations we apply are the following: Treatment of verbs In Catalan and Spanish, the pronoun before a verb is often omitted and instead, the person is expressed via the ending of the verb.", "labels": [], "entities": []}, {"text": "The same holds for future tense and for the modes expressed through 'would' and 'should' in English.", "labels": [], "entities": []}, {"text": "Since this makes it hard to generate the correct translation of a given English verb, we propose a method resulting in English word forms containing sufficient information.", "labels": [], "entities": []}, {"text": "Question inversion In English, interrogative phrases have a word order that is different from declarative sentences: Either an auxiliary 'do' is inserted or the order of verb and pronoun is inverted.", "labels": [], "entities": [{"text": "Question inversion", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7601158022880554}]}, {"text": "Since this is different in Spanish and Catalan, we modify the word order in English to make it more similar to the Spanish/Catalan one and to help the verb treatment mentioned above.", "labels": [], "entities": []}, {"text": "The paper is organized as follows: Related work is treated in Section 2.", "labels": [], "entities": []}, {"text": "In Section 3, we shortly review the statistical approach to machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.8245947062969208}]}, {"text": "Then, we introduce the transformations that we apply to the less inflected language of the two under consideration (namely English) in Section 4.", "labels": [], "entities": []}, {"text": "After describing the maximum entropy approach and the training procedure we use for the statistical lexicon in Section 5, we present results on the trilingual LC-STAR corpus in Section 6.", "labels": [], "entities": [{"text": "LC-STAR corpus", "start_pos": 159, "end_pos": 173, "type": "DATASET", "confidence": 0.8350161015987396}]}, {"text": "Then, we conclude and present ideas about future work in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "The quality of the output of our machine translation system is measured automatically by comparing the generated translation to a given reference translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.6969631165266037}]}, {"text": "The two following criteria are used: \u2022 WER (word error rate): The word error rate is based on the Levenshtein distance.", "labels": [], "entities": [{"text": "WER", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.9985464215278625}, {"text": "word error rate)", "start_pos": 44, "end_pos": 60, "type": "METRIC", "confidence": 0.7553343921899796}, {"text": "word error rate", "start_pos": 66, "end_pos": 81, "type": "METRIC", "confidence": 0.7726869185765585}]}, {"text": "It is computed as the minimum number of substitution, insertion and deletion operations that have to be performed to convert the generated string into the reference string.", "labels": [], "entities": []}, {"text": "Since some sentences in the develop and test set occur several times with different reference translations (which holds especially for short sentences like 'okay, good-bye'), we calculate the minimal distance to this set of references as proposed in ( ).", "labels": [], "entities": []}, {"text": "\u2022 BLEU (bilingual evaluation understudy):) have proposed a method of automatic machine translation evaluation, which they call \"BLEU\".", "labels": [], "entities": [{"text": "BLEU", "start_pos": 2, "end_pos": 6, "type": "METRIC", "confidence": 0.9950501322746277}, {"text": "machine translation evaluation", "start_pos": 79, "end_pos": 109, "type": "TASK", "confidence": 0.7866497536500295}, {"text": "BLEU", "start_pos": 128, "end_pos": 132, "type": "METRIC", "confidence": 0.9935430288314819}]}, {"text": "It is based on the notion of modified n-gram precision, for which all candidate n-gram counts in the translation are collected and clipped against their corresponding maximum reference counts.", "labels": [], "entities": [{"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9167265295982361}]}, {"text": "These clipped candidate counts are summed and normalized by the total number of candidate n-grams.", "labels": [], "entities": []}, {"text": "Since BLEU expresses quality, we determine 100-BLEU to transform it into an error measure.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 6, "end_pos": 10, "type": "METRIC", "confidence": 0.9969546794891357}]}, {"text": "Although these measures are only approximations, they seem to be sufficient at the present level of performance of machine translation systems.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 115, "end_pos": 134, "type": "TASK", "confidence": 0.7565658390522003}]}, {"text": "We compared the two statistical lexica obtained from the baseline system and from the maximum entropy training on the transformed corpus.", "labels": [], "entities": []}, {"text": "For the baseline lexicon, we observed an average of 5.82 Catalan translation candidates per English word and 6.16 Spanish translation candidates.", "labels": [], "entities": []}, {"text": "These numbers are significantly reduced in the lexicon which was trained on the transformed corpus using maximum entropy: there, we have an average of 4.20 for Catalan and 4.46 for Spanish.", "labels": [], "entities": []}, {"text": "Especially for (nominative) English pronouns (which have many verbs as translation candidates in the baseline lexicon), the number of translation candidates was substantially scaled down by a factor around 4.", "labels": [], "entities": []}, {"text": "This shows that our method was successful in producing a more focused lexicon probability distribution.", "labels": [], "entities": []}, {"text": "We performed translation experiments with an implementation of the IBM-4 translation model (.", "labels": [], "entities": [{"text": "translation", "start_pos": 13, "end_pos": 24, "type": "TASK", "confidence": 0.9695362448692322}]}, {"text": "A description of the system can be found in ().", "labels": [], "entities": []}, {"text": "presents an assessment of translation quality for both the language pairs English-Catalan and English-Spanish.", "labels": [], "entities": []}, {"text": "We see that there is a significant decrease in error rate for the translation into Catalan.", "labels": [], "entities": [{"text": "error rate", "start_pos": 47, "end_pos": 57, "type": "METRIC", "confidence": 0.9877564311027527}]}, {"text": "This change is consistent across both error rates, the WER and 100-BLEU.", "labels": [], "entities": [{"text": "WER", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.9631310105323792}]}, {"text": "For translations from English into Spanish, the improvement is less substantial.", "labels": [], "entities": [{"text": "translations from English into Spanish", "start_pos": 4, "end_pos": 42, "type": "TASK", "confidence": 0.8791880369186401}]}, {"text": "A reason for this might be that the Spanish vocabulary contains more entries and the ratio between fullforms and baseforms is higher: 1.57 for Spanish versus 1.53 for Catalan4 . This makes it more difficult for the system to choose the correct inflection when generating a Spanish sentence.", "labels": [], "entities": []}, {"text": "We assume that the extension of our approach to other word classes than verbs will yield a quality gain for translations into Spanish.", "labels": [], "entities": []}, {"text": "shows several sentences from the English LC-STAR develop and test corpus that were trans- lated into Catalan.", "labels": [], "entities": []}, {"text": "We see that it is easier for the system to generate the correct verb inflection in Catalan if the verb is enriched with the pronoun.", "labels": [], "entities": []}, {"text": "In the baseline system, it happens that words are inserted -like 'far' as translation of 'will' in the second example which is incorrect.", "labels": [], "entities": []}, {"text": "This can be avoided by the splicing of words.", "labels": [], "entities": []}, {"text": "In the last example, we see that the baseline system generates one word each for the English 'I prefer' and does not find the correct translation, whereas transformations yield an accurate translation of this expression, because the spliced word contains sufficient information.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Statistics of the training, develop and test set of the English-Spanish-Catalan LC-STAR corpus  (*number of words without punctuation marks)  English  Spanish  Catalan  Original  Transformed  Training  Sentences  Words  Words\"", "labels": [], "entities": [{"text": "English-Spanish-Catalan LC-STAR corpus", "start_pos": 66, "end_pos": 104, "type": "DATASET", "confidence": 0.6557755569616953}, {"text": "English  Spanish  Catalan  Original  Transformed  Training  Sentences  Words  Words", "start_pos": 152, "end_pos": 235, "type": "TASK", "confidence": 0.5551582972208658}]}, {"text": " Table 5: Translation error rates [%] for English-Catalan and for English-Spanish", "labels": [], "entities": [{"text": "Translation error rates", "start_pos": 10, "end_pos": 33, "type": "METRIC", "confidence": 0.7870453198750814}]}]}