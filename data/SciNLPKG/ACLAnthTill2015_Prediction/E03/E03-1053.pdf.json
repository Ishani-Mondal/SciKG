{"title": [{"text": "Language Independent Authorship Attribution using Character Level Language Models", "labels": [], "entities": [{"text": "Language Independent Authorship Attribution", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.5334124937653542}]}], "abstractContent": [{"text": "We present a method for computer-assisted authorship attribution based on character-level n-gram language models.", "labels": [], "entities": [{"text": "computer-assisted authorship attribution", "start_pos": 24, "end_pos": 64, "type": "TASK", "confidence": 0.6281820436318716}]}, {"text": "Our approach is based on simple information theoretic principles, and achieves improved performance across a variety of languages without requiring extensive pre-processing or feature selection.", "labels": [], "entities": []}, {"text": "To demonstrate the effectiveness and language independence of our approach, we present experimental results on Greek, English, and Chi-nese data.", "labels": [], "entities": []}, {"text": "We show that our approach achieves state of the art performance in each of these cases.", "labels": [], "entities": []}, {"text": "In particular, we obtain a 18% accuracy improvement over the best published results fora Greek data set, while using afar simpler technique than previous investigations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9994367957115173}, {"text": "Greek data set", "start_pos": 89, "end_pos": 103, "type": "DATASET", "confidence": 0.8543931841850281}]}], "introductionContent": [{"text": "Automated authorship attribution is the problem of identifying the author of an anonymous text, or text whose authorship is in doubt.", "labels": [], "entities": [{"text": "Automated authorship attribution", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7018816073735555}]}, {"text": "A famous example is the Federalist Papers, of which twelve are claimed to have been written both by Alexander Hamilton and James Madison.", "labels": [], "entities": [{"text": "Federalist Papers", "start_pos": 24, "end_pos": 41, "type": "DATASET", "confidence": 0.7335450202226639}]}, {"text": "Recently, vast repositories of electronic text have become available on the Internet, making the problem of managing large text collections increasingly important.", "labels": [], "entities": []}, {"text": "Automated text categorization (TC) is a useful way to organize a large document collection by imposing a desired categorization scheme.", "labels": [], "entities": [{"text": "Automated text categorization (TC)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7855320076147715}]}, {"text": "For example, categorizing documents by their author is an important case that has become increasingly useful, but also increasingly difficult in the age of web-documents that can be easily copied, translated and edited.", "labels": [], "entities": [{"text": "categorizing documents by their author", "start_pos": 13, "end_pos": 51, "type": "TASK", "confidence": 0.8465104222297668}]}, {"text": "Author attribution is becoming an important application in web information management, and is beginning to play a role in areas such as information retrieval, information extraction and question answering.", "labels": [], "entities": [{"text": "Author attribution", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.64699387550354}, {"text": "web information management", "start_pos": 59, "end_pos": 85, "type": "TASK", "confidence": 0.6271835962931315}, {"text": "information retrieval", "start_pos": 136, "end_pos": 157, "type": "TASK", "confidence": 0.7779878377914429}, {"text": "information extraction", "start_pos": 159, "end_pos": 181, "type": "TASK", "confidence": 0.8083588480949402}, {"text": "question answering", "start_pos": 186, "end_pos": 204, "type": "TASK", "confidence": 0.9061006009578705}]}, {"text": "Many algorithms have been invented for assessing the authorship of given text.", "labels": [], "entities": [{"text": "assessing the authorship of given text", "start_pos": 39, "end_pos": 77, "type": "TASK", "confidence": 0.6953049500783285}]}, {"text": "These algorithms rely on the fact that authors use linguistic devices at every level-semantic, syntactic, lexicographic, orthographic and morphological)-to produce their text.", "labels": [], "entities": []}, {"text": "Typically, such devices are applied unconsciously by the author, and thus provide a useful basis for unambiguously determining authorship.", "labels": [], "entities": []}, {"text": "The most common approach to determining authorship is to use a stylistic analysis that proceeds in two steps: first, specific style markers are extracted, and second, a classification procedure is applied to the resulting description.", "labels": [], "entities": []}, {"text": "These methods are usually based on calculating lexical measures that represent the richness of the author's vocabulary and the frequency of common word use ().", "labels": [], "entities": []}, {"text": "Style marker extraction is usually accomplished by some form of non-trivial NLP analysis, such as tagging, parsing and morphological analysis.", "labels": [], "entities": [{"text": "Style marker extraction", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8439009388287863}]}, {"text": "A classifier is then constructed, usually by first performing a non-trivial feature selection step that employs mutual information or Chi-square testing to determine relevant features.", "labels": [], "entities": []}, {"text": "There are several problems with this standard approach however.", "labels": [], "entities": []}, {"text": "First, techniques used for style marker extraction are almost always language dependent, and in fact differ dramatically from language to language.", "labels": [], "entities": [{"text": "style marker extraction", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.7885569930076599}]}, {"text": "For example, an English parser usually cannot be applied to German or Chinese.", "labels": [], "entities": []}, {"text": "Second, feature selection is not a trivial process, and usually involves setting thresholds to eliminate uninformative features).", "labels": [], "entities": [{"text": "feature selection", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.8118555545806885}]}, {"text": "These decisions can be extremely subtle, because although rare features contribute less signal than common features, they can still have an important cumulative effect).", "labels": [], "entities": []}, {"text": "Third, current authorship attribution systems invariably perform their analysis at the word level.", "labels": [], "entities": []}, {"text": "However, although word level analysis seems to be intuitive, it ignores the fact that morphological features can also play an important role, and moreover that many Asian languages such as Chinese and Japanese do not have word boundaries explicitly identified in text.", "labels": [], "entities": []}, {"text": "In fact, word segmentation itself is a difficult problem in Asian languages, which creates an extra level of difficulty in coping with the errors this process introduces.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.7549368739128113}]}, {"text": "In this paper, we propose a simple method that avoids each of these problems.", "labels": [], "entities": []}, {"text": "Our approach is based on building a character-level'n-gram model of an author's writing, using techniques from statistical language modeling.", "labels": [], "entities": []}, {"text": "Language modeling is concerned with capturing regularities of natural language-for example, semantic, syntactic, lexicographic and morphological patterns-that can be used to make predictions.", "labels": [], "entities": [{"text": "Language modeling", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7004736065864563}]}, {"text": "Many of the features considered in language modeling coincide with those used in authorship attribution, and it is therefore natural to apply language modeling concepts to this problem.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.712803915143013}]}, {"text": "To perform authorship attribution, we build a character-level'n-gram language model for each author.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.8054478764533997}]}, {"text": "This approach exploits morphological features while avoiding the need for explicitly segmented words.", "labels": [], "entities": []}, {"text": "By considering all possible character n-grams as potential features, we also avoid the need to run sophisticated NLP tools, such as parsers and taggers, to produce candidate features.", "labels": [], "entities": []}, {"text": "Finally, we avoid feature selection entirely by including every feature in the model, but use estimation methods from sta-268 tistical language modeling to avoid over-fitting a sparse set of training data.", "labels": [], "entities": []}, {"text": "The result is a surprisingly simple, effective approach to authorship attribution that is completely language independent.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 59, "end_pos": 81, "type": "TASK", "confidence": 0.8628579676151276}]}], "datasetContent": [{"text": "In this section, we present experimental results for our approach on three different languages.", "labels": [], "entities": []}, {"text": "We first describe the performance measures used in our experiments, and then present results on Greek data, English data and Chinese data, in Sections 4.2, 4.3 and 4.4 respectively.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Authors in two Greek data sets, A and B.", "labels": [], "entities": [{"text": "Greek data sets", "start_pos": 25, "end_pos": 40, "type": "DATASET", "confidence": 0.8389883836110433}]}, {"text": " Table 2: Experimental results on the Greek data sets.", "labels": [], "entities": [{"text": "Greek data sets", "start_pos": 38, "end_pos": 53, "type": "DATASET", "confidence": 0.8719302217165629}]}, {"text": " Table 3: Authors appearing in the English data set.", "labels": [], "entities": [{"text": "English data set", "start_pos": 35, "end_pos": 51, "type": "DATASET", "confidence": 0.9385839303334554}]}]}