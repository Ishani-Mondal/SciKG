{"title": [{"text": "A General Feature Space for Automatic Verb Classification", "labels": [], "entities": [{"text": "Automatic Verb Classification", "start_pos": 28, "end_pos": 57, "type": "TASK", "confidence": 0.5961271723111471}]}], "abstractContent": [{"text": "We develop a general feature space for automatic classification of verbs into lexical semantic classes.", "labels": [], "entities": [{"text": "automatic classification of verbs into lexical semantic classes", "start_pos": 39, "end_pos": 102, "type": "TASK", "confidence": 0.7953300662338734}]}, {"text": "Previous work was limited in scope by the need for manual selection of discriminating features , through a linguistic analysis of the target verb classes (Merlo and Steven-son, 2001).", "labels": [], "entities": []}, {"text": "We instead analyze the classification structure at a higher level, using the possible defining characteristics of classes as the basis for our feature space.", "labels": [], "entities": []}, {"text": "The general feature space achieves reductions in error rates of 42-69%, on a wider range of classes than investigated previously, with comparable performance to feature sets manually selected for the particular classification tasks.", "labels": [], "entities": [{"text": "error rates", "start_pos": 49, "end_pos": 60, "type": "METRIC", "confidence": 0.9811794459819794}]}, {"text": "Our results show that the approach is generally applicable, and avoids the need for resource-intensive linguistic analysis for each new task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Wide-coverage language processing systems require large amounts of knowledge about individual words, leading to a lexical acquisition bottleneck.", "labels": [], "entities": []}, {"text": "Because verbs play a central role in the syntactic and semantic interpretation of a sentence, much research has focused on automatically learning properties of verbs from text corpora, such as their subcategorization, argument roles (), selectional preferences, and lexical semantic classification ().", "labels": [], "entities": [{"text": "syntactic and semantic interpretation of a sentence", "start_pos": 41, "end_pos": 92, "type": "TASK", "confidence": 0.7939437542642865}, {"text": "lexical semantic classification", "start_pos": 266, "end_pos": 297, "type": "TASK", "confidence": 0.6596592962741852}]}, {"text": "Our work aims to extend the applicability of the latter, by developing a general feature space for automatic verb classification.", "labels": [], "entities": [{"text": "automatic verb classification", "start_pos": 99, "end_pos": 128, "type": "TASK", "confidence": 0.6199473838011423}]}, {"text": "Specifically, showed that verbs could be automatically classified into one of three lexical semantic classes on the basis of five simple statistical features.", "labels": [], "entities": []}, {"text": "This work demonstrated the feasibility of verb classification from noisy, easily extractable corpus statistics.", "labels": [], "entities": [{"text": "verb classification", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.7217399775981903}]}, {"text": "However, the approach was limited in scope by the need for manual determination of a discriminating set of features, through a linguistic analysis of the target verb classes.", "labels": [], "entities": []}, {"text": "Our work overcomes this limitation by developing a general feature space that avoids the need for individual development of features for specific classes.", "labels": [], "entities": []}, {"text": "The central idea of our approach is as follows.", "labels": [], "entities": []}, {"text": "We focus on lexical semantic classes as in, which group together verbs sharing both a common semantics (such as manner of motion or change of state), and a set of syntactic alternations.", "labels": [], "entities": []}, {"text": "An alternation refers to the alternative mappings of the semantic arguments of a verb to syntactic positions, as in: la.", "labels": [], "entities": []}, {"text": "I loaded the truck b.", "labels": [], "entities": []}, {"text": "I loaded hay onto the truck.", "labels": [], "entities": []}, {"text": "In (hereafter MS01), the differences between the specific semantic arguments and their possible alternations for the three target classes were analyzed to determine a small set of discriminating features.", "labels": [], "entities": []}, {"text": "Here, we perform the linguistic analysis at a higher level, by analyzing the range of possible alternations and distinctions among arguments that verbs can exhibit.", "labels": [], "entities": []}], "datasetContent": [{"text": "For the experimental investigation of our feature space, we selected a number of verb classes that would be non-trivial test cases for evaluating the method.", "labels": [], "entities": []}, {"text": "Both for practical reasons and to make the results of general interest, the classes could neither be too small nor contain mostly infrequent verbs.", "labels": [], "entities": []}, {"text": "Pairs or triples of verb classes were selected to form the test pairs/triples for each of a number of separate classification tasks.", "labels": [], "entities": []}, {"text": "To illustrate the range of applicability of the feature space, we picked some pairs/triples of classes that were closely related and some that were more dissimilar.", "labels": [], "entities": []}, {"text": "These dative alternation verbs differ in the preposition and the semantic role of its object.", "labels": [], "entities": []}, {"text": "These psychological state verbs differ in that the Experiencer argument is the subject of Admire verbs, and the object of Amuse verbs.", "labels": [], "entities": []}, {"text": "Run versus Sound Emission verbs.", "labels": [], "entities": []}, {"text": "The kids ran in the room./*The room ran with kids.", "labels": [], "entities": []}, {"text": "Birds sang in the trees./The trees sang with birds.", "labels": [], "entities": []}, {"text": "These intransitive activity verbs differ in the prepositional alternations they allow.", "labels": [], "entities": []}, {"text": "Cheat versus Steal and Remove verbs.", "labels": [], "entities": []}, {"text": "Jane of her money/*the money from Jane.", "labels": [], "entities": []}, {"text": "*Jane of her money/the money from Jane.", "labels": [], "entities": [{"text": "Jane of her money", "start_pos": 1, "end_pos": 18, "type": "DATASET", "confidence": 0.8883664011955261}]}, {"text": "These semantically related classes differ in the prepositional alternants they allow.", "labels": [], "entities": []}, {"text": "These three classes also differ in prepositional altemants.", "labels": [], "entities": []}, {"text": "Note, however, that the options for Spray/Load verbs overlap with both of the other two types of verbs.", "labels": [], "entities": []}, {"text": "Optionally Intransitive: Run versus Change of State versus \"Object Drop\".", "labels": [], "entities": []}, {"text": "These are the three classes of MS01, which we investigate here for comparison to their results.", "labels": [], "entities": [{"text": "MS01", "start_pos": 31, "end_pos": 35, "type": "DATASET", "confidence": 0.8253414630889893}]}, {"text": "All are optionally intransitive but assign different semantic roles to their arguments.", "labels": [], "entities": []}, {"text": "(Note that the Object Drop verbs area superset of the Benefactives above.)", "labels": [], "entities": []}, {"text": "The classification tasks we chose vary in difficulty.", "labels": [], "entities": []}, {"text": "For many tasks, knowing exactly what PP arguments each verb takes maybe sufficient to perform the classification (cf..", "labels": [], "entities": []}, {"text": "However, we do not have access to such perfect knowledge, since PP arguments and adjuncts cannot be distinguished with high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9877810478210449}]}, {"text": "Using our simple extraction tools, for example, the PP/or argument in I admired Jane for her honesty is not distinguished from the for adjunct in I amused Jane for the money.", "labels": [], "entities": [{"text": "honesty", "start_pos": 93, "end_pos": 100, "type": "METRIC", "confidence": 0.9670454859733582}]}, {"text": "Furthermore, PP arguments differ in frequency, so that a highly distinguishing but rarely used alternant will likely not be useful.", "labels": [], "entities": []}, {"text": "Differences in PP usage are thus noisy indicators that we expect to be useful but not definitive.", "labels": [], "entities": []}, {"text": "Finally, one of the pairs, Wipe versus Steal and Remove verbs, are not distinguishable by even perfect information about syntactic frames: there is no frame or slot which is allowed by all verbs in one class and no verbs in the other.", "labels": [], "entities": []}, {"text": "One might therefore expect this task to be one of the hardest we consider.", "labels": [], "entities": []}, {"text": "We performed ten classification tasks, shown in the first column of.", "labels": [], "entities": [{"text": "classification tasks", "start_pos": 17, "end_pos": 37, "type": "TASK", "confidence": 0.8801234662532806}]}, {"text": "The 2-and 3-way tasks, and their motivation, were described earlier in Section 3.", "labels": [], "entities": []}, {"text": "We added three multiway tasks to explore how much we can expect our feature space to scale to multiple class distinctions: The 6-way task involves the Cheat, Steal-Remove, Wipe, Spray/Load, Fill, and \"Other Verbs of Putting\" classes, all of which undergo similar alternations of locative arguments.", "labels": [], "entities": []}, {"text": "To these 6, the 8-way task adds the Run and Sound Emission verbs, which also undergo locative alternations.", "labels": [], "entities": [{"text": "Run", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.9323861002922058}]}, {"text": "The 13-way task includes all our classes (except Benefactive, which is a subset of Object Drop).", "labels": [], "entities": []}, {"text": "Note that we do not create one classifier which is applied to different test data sets; rather, a separate classifier is defined for each task using only the training data for the verb classes under investigation.", "labels": [], "entities": []}, {"text": "In all cases, the training data is balanced, with 20 verbs in each class, so the baseline (chance) performance is 1/k fora task discriminating k classes.", "labels": [], "entities": []}, {"text": "This baseline is shown in the second column of, while the third column gives the number of test verbs for each task.", "labels": [], "entities": []}, {"text": "Our first set of experiments uses all our features (as listed in; the results are shown in columns 4 and 5 of.", "labels": [], "entities": []}, {"text": "In all cases, test performance shows a substantial increase of 22-47 percentage points above the baseline, with a reduction in error rate ranging from 42-69%.", "labels": [], "entities": [{"text": "error rate", "start_pos": 127, "end_pos": 137, "type": "METRIC", "confidence": 0.9914048612117767}]}, {"text": "Indeed, it is worth noting that what we predicted to be the most difficult task (the Wipe/Steal-Remove case) had the best overall performance, of 84.6% (line 5 of the table).", "labels": [], "entities": []}, {"text": "In only two of our 2-and 3-way tasks did test performance decrease by more than 5% compared to training performance, indicating good generalizability of the classifiers.", "labels": [], "entities": []}, {"text": "The 6-and 8-way tasks had very good performance, and even the 13-way task far exceeded the baseline, although in each case, test performance was substantially less than results on training data.", "labels": [], "entities": []}, {"text": "For these complex multiway tasks, it seems, more training verbs would be desirable.", "labels": [], "entities": []}, {"text": "Ideally, we would also like to compare our results to features developed by linguistic experts, such as those in MS01.", "labels": [], "entities": [{"text": "MS01", "start_pos": 113, "end_pos": 117, "type": "DATASET", "confidence": 0.931544840335846}]}, {"text": "On our new test verbs in the optionally intransitive task of MS01, our feature space outperformed their hand-crafted features, 72.1% (line 7 of the table) versus 64.2%.", "labels": [], "entities": [{"text": "MS01", "start_pos": 61, "end_pos": 65, "type": "DATASET", "confidence": 0.9296956658363342}]}, {"text": "For the other tasks, however, no manually derived feature space exists.", "labels": [], "entities": []}, {"text": "We instead compare the general feature space to subsets of our own features (called the Levin-derived subsets) which are hand-selected through an analysis of the classes in Levin.", "labels": [], "entities": []}, {"text": "For each class, we have systematically identified the subset of features indicated by the class description given in Levin.", "labels": [], "entities": []}, {"text": "For each task, then, the Levin-derived subset is the union of these subsets for all the classes in the task.", "labels": [], "entities": []}, {"text": "The results for these feature sets are given in columns 6 and 7 of.", "labels": [], "entities": []}, {"text": "Comparing columns 5 and 7, we see that the general feature space performs as well as or better than the Levin-derived subset on most tasks.", "labels": [], "entities": []}, {"text": "For only 3 of the 10 tasks does the subset of features outperform the full feature space by 5% or more.", "labels": [], "entities": []}, {"text": "These results taken together support the hypothesis that our general feature space can be used successfully for automatic verb classification, and can eliminate the need for time-consuming expert analysis for each new task.", "labels": [], "entities": [{"text": "automatic verb classification", "start_pos": 112, "end_pos": 141, "type": "TASK", "confidence": 0.5850653151671091}]}, {"text": "showed that perfect knowledge of the allowable syntactic frames fora verb enabled an accuracy of 98% in assigning verbs to Levin classes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9996885061264038}]}, {"text": "We adopt the approach of MS01, which instead approximates such knowledge through statistical corpus analysis, allowing for easier extensibility to new classes.", "labels": [], "entities": []}, {"text": "Furthermore, rather than using a class-by-class analysis as in, our features are determined through an analysis of the possible alternations for verbs independent of their class assignment, leading to a more general set of features.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Feature categories with number of fea- tures of each type.", "labels": [], "entities": []}, {"text": " Table 2: Verb classes (see Section 3), their Levin  class numbers, and the number of experimental  verbs in each (see Section 4.2).", "labels": [], "entities": []}, {"text": " Table 3: Experimental Results. Acc is % accuracy; SE is % standard error; # is number of test items  correctly classified.", "labels": [], "entities": [{"text": "Acc", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.9996246099472046}, {"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9915784597396851}, {"text": "SE", "start_pos": 51, "end_pos": 53, "type": "METRIC", "confidence": 0.9986182451248169}, {"text": "standard error", "start_pos": 59, "end_pos": 73, "type": "METRIC", "confidence": 0.9221301376819611}]}]}