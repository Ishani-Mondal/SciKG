{"title": [], "abstractContent": [{"text": "We present some preliminary results of a Czech-English translation system based on dependency trees.", "labels": [], "entities": []}, {"text": "The fully automated process includes: morphological tagging, analytical and tectogrammat-ical parsing of Czech, tectogrammati-cal transfer based on lexical substitution using word-to-word translation dictionaries enhanced by the information from the English-Czech parallel corpus of WSJ, and a simple rule-based system for generation from English tectogram-matical representation.", "labels": [], "entities": [{"text": "morphological tagging", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.6783845275640488}, {"text": "tectogrammat-ical parsing of Czech", "start_pos": 76, "end_pos": 110, "type": "TASK", "confidence": 0.7503930479288101}, {"text": "tectogrammati-cal transfer", "start_pos": 112, "end_pos": 138, "type": "TASK", "confidence": 0.7287401407957077}, {"text": "English-Czech parallel corpus of WSJ", "start_pos": 250, "end_pos": 286, "type": "DATASET", "confidence": 0.7200673818588257}]}, {"text": "In the evaluation part, we compare results of the fully automated and the manually annotated processes of building the tectogrammat-ical representation.'", "labels": [], "entities": []}], "introductionContent": [{"text": "The experiment described in this paper is an attempt to develop a full MT system based on dependency trees (DBMT).", "labels": [], "entities": [{"text": "MT", "start_pos": 71, "end_pos": 73, "type": "TASK", "confidence": 0.9905213117599487}]}, {"text": "Dependency trees represent the sentence structure as concentrated around the verb and its valency.", "labels": [], "entities": []}, {"text": "We use tectogrammatical dependency trees capturing the linguistic meaning of the sentence.", "labels": [], "entities": []}, {"text": "Ina tectogrammatical dependency tree, only autosemantic (lexical) words are represented as nodes, dependencies (edges) are labeled by tectogrammatical functors denoting the semantic roles, the information conveyed by auxiliary words is stored in attributes of the nodes.", "labels": [], "entities": []}, {"text": "For details about the tectogrammatical representation see, an example of a tectogrammatical tree can be found in.", "labels": [], "entities": []}, {"text": "MAGENTA () is an experimental framework for machine translation implemented during 2002 NLP Workshop at CLSP, Johns Hopkins University in Baltimore.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7720521092414856}]}, {"text": "Modules for parsing of Czech, lexical transfer, a prototype of a statistical tree-to-tree transducer for structural transformations used during transfer and generation, and a language model for English based on dependency syntax are integrated in one pipeline.", "labels": [], "entities": [{"text": "parsing of Czech", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.879235565662384}, {"text": "lexical transfer", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.7539755403995514}, {"text": "transfer and generation", "start_pos": 144, "end_pos": 167, "type": "TASK", "confidence": 0.6632066369056702}]}, {"text": "For processing the Czech part of the data, we reuse some modules of the MAGENTA system, but instead of MAGENTA's statistical treeto-tree transducing module and subsequent language model, we implement a rule-based method for generating English output directly from the tectogrammatical representation.", "labels": [], "entities": [{"text": "MAGENTA system", "start_pos": 72, "end_pos": 86, "type": "DATASET", "confidence": 0.8868829607963562}]}, {"text": "First, we summarize resources available for the experiments (Section 2).", "labels": [], "entities": []}, {"text": "Section 3 describes the automatic procedures used for the preparation of both training and testing data, including morphological tagging, and analytical and tectogrammatical parsing of Czech input.", "labels": [], "entities": [{"text": "morphological tagging", "start_pos": 115, "end_pos": 136, "type": "TASK", "confidence": 0.6924405097961426}, {"text": "analytical and tectogrammatical parsing of Czech input", "start_pos": 142, "end_pos": 196, "type": "TASK", "confidence": 0.7488204751695905}]}, {"text": "In Section 4 we describe the process of the filtering of dictionaries used in the transfer procedure (for its characterization, see Section 5).", "labels": [], "entities": []}, {"text": "The generation process consisting mainly of word reordering and lexical insertions is explained in Section 6, an example illustrating the generation steps is presented in Sec-tion 7.", "labels": [], "entities": [{"text": "word reordering", "start_pos": 44, "end_pos": 59, "type": "TASK", "confidence": 0.7118715047836304}]}, {"text": "For the evaluation of the results we use the BLEU score ().", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 45, "end_pos": 55, "type": "METRIC", "confidence": 0.9684821665287018}]}, {"text": "Section 8 compares translations generated from automatically built and manually annotated tectogrammatical representations.", "labels": [], "entities": []}, {"text": "We also compare the results with the output generated by the statistical translation system GIZA++/ISI ReWrite Decoder), trained on the same parallel corpus.", "labels": [], "entities": [{"text": "GIZA++/ISI ReWrite Decoder", "start_pos": 92, "end_pos": 118, "type": "DATASET", "confidence": 0.8564458608627319}]}], "datasetContent": [{"text": "We evaluated our translations with IBM's BLEU evaluation metric (), using the same evaluation method and reference retranslations that were used for evaluation at HLT Workshop 2002 at CLSP ().", "labels": [], "entities": [{"text": "BLEU evaluation metric", "start_pos": 41, "end_pos": 63, "type": "METRIC", "confidence": 0.9025246898333231}, {"text": "HLT Workshop 2002 at CLSP", "start_pos": 163, "end_pos": 188, "type": "DATASET", "confidence": 0.8006670594215393}]}, {"text": "We used four reference retranslations of 490 sentences selected from the WSJ sections 22, 23, and 24, which were themselves used as the fifth reference.", "labels": [], "entities": [{"text": "WSJ sections 22", "start_pos": 73, "end_pos": 88, "type": "DATASET", "confidence": 0.9340973695119222}]}, {"text": "The evaluation method used is to holdout each reference in turn and evaluate it against the remaining four, averaging the five BLEU scores.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 127, "end_pos": 131, "type": "METRIC", "confidence": 0.999079704284668}]}, {"text": "shows final results of our system compared with GIZA++ and MAGENTA's results.", "labels": [], "entities": [{"text": "GIZA++", "start_pos": 48, "end_pos": 54, "type": "DATASET", "confidence": 0.6376760601997375}]}, {"text": "The DBMT with parser I and parser II experiments represent a fully automated translation, while the DBMT experiment on manually annotated trees generates from the Czech tectogrammatical trees prepared by human annotators.", "labels": [], "entities": [{"text": "DBMT", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.8170397877693176}]}, {"text": "For the purposes of comparison, GIZA++ statistical machine translation toolkit with the ReWrite decoder were customized to translate from Czech to English and two experiments with different configurations were performed.", "labels": [], "entities": [{"text": "GIZA++ statistical machine translation", "start_pos": 32, "end_pos": 70, "type": "TASK", "confidence": 0.6419565558433533}, {"text": "ReWrite decoder", "start_pos": 88, "end_pos": 103, "type": "DATASET", "confidence": 0.94669970870018}]}, {"text": "The first one takes the Czech plain text as the input, the second one translates from lemmatized Czech.", "labels": [], "entities": []}, {"text": "In addition, the word-to-word dictionary described in Section 4 was added to the training data (every entry-translation pair as one sentence pair).", "labels": [], "entities": []}, {"text": "The language model was trained on a large monolingual corpus of Wall Street Journal containing about 52M words.", "labels": [], "entities": [{"text": "Wall Street Journal", "start_pos": 64, "end_pos": 83, "type": "DATASET", "confidence": 0.9012815554936727}]}, {"text": "The corpus was selected from the corpus mentioned in Section 2.3.", "labels": [], "entities": []}, {"text": "We also present the score reached by the MA-GENTA system.", "labels": [], "entities": [{"text": "MA-GENTA", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9361282587051392}]}, {"text": "All systems were evaluated against the same sets of references.", "labels": [], "entities": []}, {"text": "Both our experiments show a considerable improvement over MAGENTA's performance, they also score better than GIZA++/ReWrite trained on word forms.", "labels": [], "entities": []}, {"text": "We were still outperformed by GIZA++/ReWrite trained on lemmas, but it makes use of a large language model.", "labels": [], "entities": [{"text": "GIZA++/ReWrite", "start_pos": 30, "end_pos": 44, "type": "DATASET", "confidence": 0.7238134741783142}]}], "tableCaptions": [{"text": " Table 2: Dictionary parameters and weights", "labels": [], "entities": []}]}