{"title": [{"text": "Parsed Corpus Parsed Corpus 2 Participants Transcription Format : XML Xerox / XRCE Grenoble Constitution of a heterogeneous PEAS, the first instantiation of a comparative framework for evaluating parsers of French", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents PEAS, the first comparative evaluation framework for parsers of French whose annotation formalism allows the annotation of both constituents and functional relations.", "labels": [], "entities": [{"text": "PEAS", "start_pos": 20, "end_pos": 24, "type": "METRIC", "confidence": 0.6178144216537476}]}, {"text": "A test corpus containing an assortment of different text types has been built and part of it has been manually annotated.", "labels": [], "entities": []}, {"text": "Precision/Recall and crossing brackets metrics will be adapted to our formalism and applied to the parses produced by one parser from academia and another one from industry in order to validate the framework.", "labels": [], "entities": [{"text": "Precision/Recall", "start_pos": 0, "end_pos": 16, "type": "METRIC", "confidence": 0.8024341265360514}]}], "introductionContent": [{"text": "In natural language understanding, many complex applications use a syntactic parser as a basic functionality.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 3, "end_pos": 33, "type": "TASK", "confidence": 0.6731898784637451}]}, {"text": "Today, in particular for the French language, the developers face the great diversity of the offer in the domain.", "labels": [], "entities": []}, {"text": "Therefore, the need fora complete comparative evaluation framework -including a pivot annotation formalism, a reference treebank, evaluation metrics and the associated software -is increasing.", "labels": [], "entities": []}, {"text": "It is worth noting that most of the recently developed parsers use a robust approach.", "labels": [], "entities": []}, {"text": "Consequently, they do not always produce a complete parse of the sentence, but they are able to produce a result, whatever the size, the particularities and the grammaticality of the input.", "labels": [], "entities": []}, {"text": "For this reason, it is essential to be able to compare in a fairway the parses they produce against those produced by other parsers whatever their characteristics.", "labels": [], "entities": []}, {"text": "One possible solution is to offer a common reference annotation formalism along with a fully parsed reference corpus and a set of robust metrics, allowing for both complete and selective evaluation over an assortment of different text types and syntactic phenomena.", "labels": [], "entities": []}, {"text": "The aim of our research is to build such evaluation framework, which to date is missing for French.", "labels": [], "entities": []}, {"text": "presents the different modules of our evaluation protocol as it stands today.", "labels": [], "entities": []}], "datasetContent": [{"text": "The first proposals for parser evaluation were made in. gave a survey and proposed anew evaluation scheme.", "labels": [], "entities": [{"text": "parser evaluation", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.9559130966663361}]}, {"text": "Since, two orientations have emerged.", "labels": [], "entities": []}, {"text": "The first, inspired by Parseval, is based on phrase boundaries and uses recall plus crossing-bracket measures.", "labels": [], "entities": [{"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9963144659996033}]}, {"text": "Although it has been criticized (, it is still in use nowadays.", "labels": [], "entities": []}, {"text": "The second one is based on dependency relations, (on which recall and precision can also be computed) and seems to be more and more in favor (see the workshop Beyond Parseval 2002).", "labels": [], "entities": [{"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9980402588844299}, {"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9902458190917969}]}, {"text": "Since our annotation formalism has both constituents and functional relations, there is no reason to dismiss either approaches.", "labels": [], "entities": []}, {"text": "Nevertheless, we have to outline that the transcription of the parses will be more systematic for the relations than for the constituents.", "labels": [], "entities": []}, {"text": "Indeed, in our formalism, relations can associate words, chunks or words and chunks, but it is always possible to match any relation argument with the reference parse, because we always know to which chunk a word belongs.", "labels": [], "entities": []}, {"text": "On the other hand, for the segmentation, the chunk boundaries may vary a lot from one parse to another.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 27, "end_pos": 39, "type": "TASK", "confidence": 0.9687139987945557}]}, {"text": "So we have to foresee either an important set of matching rules, or flexible evaluation methods.", "labels": [], "entities": []}], "tableCaptions": []}