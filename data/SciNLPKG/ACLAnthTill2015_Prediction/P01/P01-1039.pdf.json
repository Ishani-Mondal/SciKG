{"title": [], "abstractContent": [{"text": "In this paper we address the problem of extracting key pieces of information from voicemail messages, such as the identity and phone number of the caller.", "labels": [], "entities": [{"text": "extracting key pieces of information from voicemail messages", "start_pos": 40, "end_pos": 100, "type": "TASK", "confidence": 0.7195280939340591}]}, {"text": "This task differs from the named entity task in that the information we are interested in is a subset of the named entities in the message, and consequently, the need to pick the correct subset makes the problem more difficult.", "labels": [], "entities": []}, {"text": "Also, the caller's identity may include information that is not typically associated with a named entity.", "labels": [], "entities": []}, {"text": "In this work, we present three information extraction methods, one based on hand-crafted rules, one based on maximum entropy tagging, and one based on probabilistic transducer induction.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 31, "end_pos": 53, "type": "TASK", "confidence": 0.8392432630062103}]}, {"text": "We evaluate their performance on both manually transcribed messages and on the output of a speech recognition system.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 91, "end_pos": 109, "type": "TASK", "confidence": 0.7279475927352905}]}], "introductionContent": [{"text": "In recent years, the task of automatically extracting information from data has grown in importance, as a result of an increase in the number of publicly available archives and a realization of the commercial value of the available data.", "labels": [], "entities": [{"text": "automatically extracting information from data", "start_pos": 29, "end_pos": 75, "type": "TASK", "confidence": 0.8016302108764648}]}, {"text": "One aspect of information extraction (IE) is the retrieval of documents.", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 14, "end_pos": 41, "type": "TASK", "confidence": 0.8660662949085236}]}, {"text": "Another aspect is that of identifying words from a stream of text that belong in predefined categories, for instance, \"named entities\" such as proper names, organizations, or numerics.", "labels": [], "entities": [{"text": "identifying words from a stream of text that belong in predefined categories, for instance, \"named entities\" such as proper names, organizations, or numerics", "start_pos": 26, "end_pos": 183, "type": "Description", "confidence": 0.7044240256835674}]}, {"text": "Though most of the earlier IE work was done in the context of text sources, recently a great deal of work has also focused on extracting information from speech sources.", "labels": [], "entities": [{"text": "IE", "start_pos": 27, "end_pos": 29, "type": "TASK", "confidence": 0.9898269176483154}, {"text": "extracting information from speech sources", "start_pos": 126, "end_pos": 168, "type": "TASK", "confidence": 0.8229665279388427}]}, {"text": "Examples of this are the Spoken Document Retrieval (SDR) task, named entity (NE) extraction).", "labels": [], "entities": [{"text": "Spoken Document Retrieval (SDR) task", "start_pos": 25, "end_pos": 61, "type": "TASK", "confidence": 0.8267667463847569}, {"text": "named entity (NE) extraction", "start_pos": 63, "end_pos": 91, "type": "TASK", "confidence": 0.6791080037752787}]}, {"text": "The SDR task focused on Broadcast News and the NE task focused on both Broadcast News and telephone conversations.", "labels": [], "entities": [{"text": "NE", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.5492925047874451}]}, {"text": "In this paper, we focus on a source of conversational speech data, voicemail, that is found in relatively large volumes in the real-world, and that could benefit greatly from the use of IE techniques.", "labels": [], "entities": [{"text": "IE", "start_pos": 186, "end_pos": 188, "type": "TASK", "confidence": 0.9677212238311768}]}, {"text": "The goal here is to query one's personal voicemail for items of information, without having to listen to the entire message.", "labels": [], "entities": []}, {"text": "For instance, \"who called today?\", or \"what is X's phone number?\".", "labels": [], "entities": []}, {"text": "Because of the importance of these key pieces of information, in this paper, we focus precisely on extracting the identity and the phone number of the caller.", "labels": [], "entities": []}, {"text": "Other attempts at summarizing voicemail have been made in the past), however the goal there was to compress a voicemail message by summarizing it, and not to extract the answers to specific questions.", "labels": [], "entities": [{"text": "summarizing voicemail", "start_pos": 18, "end_pos": 39, "type": "TASK", "confidence": 0.9101654291152954}, {"text": "summarizing it", "start_pos": 131, "end_pos": 145, "type": "TASK", "confidence": 0.8999536037445068}]}, {"text": "An interesting aspect of this research is that because a transcription of the voicemail is not available, speech recognition algorithms have to be used to convert the speech to text and the subsequent IE algorithms must operate on the transcription.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 106, "end_pos": 124, "type": "TASK", "confidence": 0.7056968361139297}]}, {"text": "One of the complications that we have to deal with is the fact that the state-of-the-art accuracy of speech recognition algorithms on this type of data 1 is only in the neighborhood of 60-70% ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9992067217826843}, {"text": "speech recognition", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.7566121816635132}]}, {"text": "The task that is most similar to our work is named entity extraction from speech data.", "labels": [], "entities": [{"text": "entity extraction from speech data", "start_pos": 51, "end_pos": 85, "type": "TASK", "confidence": 0.8478315591812133}]}, {"text": "Although the goal of the named entity task is similar -to identify the names of persons, locations, organizations, and temporal and numeric expressions -our task is different, and in some ways more difficult.", "labels": [], "entities": []}, {"text": "There are two main reasons for this: first, caller and number information constitute a small fraction of all named entities.", "labels": [], "entities": []}, {"text": "Not all person-names belong to callers, and not all digit strings specify phone-numbers.", "labels": [], "entities": []}, {"text": "In this sense, the algorithms we use must be more precise than those for named entity detection.", "labels": [], "entities": [{"text": "named entity detection", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.648543655872345}]}, {"text": "Second, the caller's identity may include information that is not typically found in a named entity, for example, \"Joe on the third floor\", rather than simply \"Joe\".", "labels": [], "entities": []}, {"text": "We discuss our definitions of \"caller\" and \"number\" in Section 2.", "labels": [], "entities": []}, {"text": "To extract caller information from transcribed speech text, we implemented three different systems, spanning both statistical and non-statistical approaches.", "labels": [], "entities": []}, {"text": "We evaluate these systems on manual voicemail transcriptions as well as the output of a speech recognizer.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 88, "end_pos": 105, "type": "TASK", "confidence": 0.7186521291732788}]}, {"text": "The first system is a simple rule-based system that uses trigger phrases to identify the information-bearing words.", "labels": [], "entities": []}, {"text": "The second system is a maximum entropy model that tags the words in the transcription as belonging to one of the categories, \"caller's identity\", \"phone number\" or \"other\".", "labels": [], "entities": []}, {"text": "The third system is a novel technique based on automatic stochastictransducer induction.", "labels": [], "entities": []}, {"text": "It aims to learn rules automatically from training data instead of requiring hand-crafted rules from experts.", "labels": [], "entities": []}, {"text": "Although the results with this system are not yet as good as the other two, we consider it highly interesting because the technology is new and still open to significant advances.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: Section 2 describes the database we are using; Section 3 contains a description of the baseline system; Section 4 describes the maximum entropy model and the associated features; Section The large word error rate is due to the fact that the speech is spontaneous, and characterized by poor grammar, false starts, pauses, hesitations, etc.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 244, "end_pos": 259, "type": "METRIC", "confidence": 0.6122340361277262}]}, {"text": "While this does not pose a problem fora human listener, it causes significant problems for speech recognition algorithms.", "labels": [], "entities": [{"text": "speech recognition algorithms", "start_pos": 91, "end_pos": 120, "type": "TASK", "confidence": 0.8337652285893759}]}, {"text": "5 discusses the transducer induction technique; Section 6 contains our experimental results and Section 7 concludes our discussions.", "labels": [], "entities": [{"text": "transducer induction", "start_pos": 16, "end_pos": 36, "type": "TASK", "confidence": 0.8262242078781128}]}], "datasetContent": [{"text": "To evaluate the performance of different systems, we use the conventional precision, recall and their F-measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9995142221450806}, {"text": "recall", "start_pos": 85, "end_pos": 91, "type": "METRIC", "confidence": 0.9995550513267517}, {"text": "F-measure", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.9965009689331055}]}, {"text": "Significantly, we insist on exact matches for an answer to be counted as correct.", "labels": [], "entities": []}, {"text": "The reason for this is that any error is liable to render the information useless, or detrimental.", "labels": [], "entities": []}, {"text": "For example, an incorrect phone number can result in unwanted phone charges, and unpleasant conversations.", "labels": [], "entities": []}, {"text": "This is different from typical named entity evaluation, where partial matches are given partial credit.", "labels": [], "entities": []}, {"text": "Therefore, it should be understood that the precision and recall rates computed with this strict criterion cannot be compared to those from named entity detection tasks.", "labels": [], "entities": [{"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.999388575553894}, {"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9921743869781494}]}, {"text": "A summary of our results is presented in Tables: Precision and recall rates for different systems on decoded voicemail messages.", "labels": [], "entities": [{"text": "Precision", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9986812472343445}, {"text": "recall", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.9988810420036316}]}, {"text": "presents precision and recall rates when manual word transcriptions are used; presents these numbers when speech recognition transcripts are used.", "labels": [], "entities": [{"text": "precision", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.9995012283325195}, {"text": "recall", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.9928649663925171}]}, {"text": "On the heading line, P refers to precision, R to recall, F to F-measure, C to caller-identity, and N to phone number.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9994151592254639}, {"text": "recall", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9553669095039368}, {"text": "F-measure", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.8173869252204895}]}, {"text": "Thus P/C denotes \"precision on caller identity\".", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9992470741271973}]}, {"text": "In these tables, the maximum entropy model is referred to as ME.", "labels": [], "entities": [{"text": "ME", "start_pos": 61, "end_pos": 63, "type": "METRIC", "confidence": 0.9052428007125854}]}, {"text": "ME1-U uses unigram lexical features only; ME1-B uses bigram lexical features only.", "labels": [], "entities": [{"text": "ME1-U", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9140971899032593}]}, {"text": "ME1-B performs somewhat better than ME1-U, but uses more than double number of features.", "labels": [], "entities": [{"text": "ME1-B", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8880629539489746}]}, {"text": "ME2-U-f1 uses unigram lexical features and number dictionary features.", "labels": [], "entities": [{"text": "ME2-U-f1", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8313863277435303}]}, {"text": "It improves the recall of phone number by upon ME1-U.", "labels": [], "entities": [{"text": "recall", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.9986951947212219}, {"text": "ME1-U", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.8131843209266663}]}, {"text": "ME2-U-f12 adds the trigger phrase dictionary features to ME2-U-f1, and it improves the recall of caller and phone numbers but degrades on the precision of both.", "labels": [], "entities": [{"text": "recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9975778460502625}, {"text": "precision", "start_pos": 142, "end_pos": 151, "type": "METRIC", "confidence": 0.998620867729187}]}, {"text": "Overall it improves a little on the F-meansures.", "labels": [], "entities": [{"text": "F-meansures", "start_pos": 36, "end_pos": 47, "type": "METRIC", "confidence": 0.9675137400627136}]}, {"text": "ME2-B-f12 uses bigram lexical features, number dictionary features and trigger phrase dictionary features.", "labels": [], "entities": []}, {"text": "It has the best recall of caller, again with over two times number of features of ME2-U-f12.", "labels": [], "entities": [{"text": "recall", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.9996627569198608}]}, {"text": "The above variants of ME features are chosen using simple count cutoff method.", "labels": [], "entities": []}, {"text": "When the incremental feature selection is used, ME2-U-f12-I reduces the number of features from with minor performance loss; ME2-B-f12-I re-: Precision and recall rates for different systems on replaced decoded voicemail messages.  with minor performance loss.", "labels": [], "entities": [{"text": "Precision", "start_pos": 142, "end_pos": 151, "type": "METRIC", "confidence": 0.9877786040306091}, {"text": "recall", "start_pos": 156, "end_pos": 162, "type": "METRIC", "confidence": 0.9965997338294983}]}, {"text": "This shows that the main power of the maxent model comes from a a very small subset of the possible features.", "labels": [], "entities": []}, {"text": "Thus, if memory and speed are concerned, the incremental feature selection is highly recommended.", "labels": [], "entities": []}, {"text": "There are several observations that can be made from these results.", "labels": [], "entities": []}, {"text": "First, the maximum entropy approach systematically beats the baseline in terms of precision, and secondly it is better on recall of the caller's identity.", "labels": [], "entities": [{"text": "precision", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.9993292093276978}, {"text": "recall", "start_pos": 122, "end_pos": 128, "type": "METRIC", "confidence": 0.9976094961166382}]}, {"text": "We believe this is because the baseline has an imperfect set of rules for determining the end of a \"caller identity\" description.", "labels": [], "entities": []}, {"text": "On the other hand, the baseline system has higher recall for phone numbers.", "labels": [], "entities": [{"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9996243715286255}]}, {"text": "The results of structure induction are worse than the other two methods, however as this is a novel approach in a developmental stage, we expect the performance will improve in the future.", "labels": [], "entities": [{"text": "structure induction", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.8249579071998596}]}, {"text": "Another important point is that there is a significant difference in performance between manual and decoded transcriptions.", "labels": [], "entities": []}, {"text": "As expected, the precision and recall numbers are worse in the presence of transcription errors (the recognizer had a word error rate of about 35%).", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9995834231376648}, {"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9987323880195618}, {"text": "word error rate", "start_pos": 118, "end_pos": 133, "type": "METRIC", "confidence": 0.8040045698483785}]}, {"text": "The degradation due to transcription errors could be caused by either: (i) corruption of words in the context surrounding the names and numbers; or (ii) corruption of the information itself.", "labels": [], "entities": []}, {"text": "To investigate this, we did the following experiment: we replaced the regions of decoded text that correspond to the correct caller identity and phone number with the correct manual transcription, and redid the test.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "Compared to the results on the manual transcription, the recall numbers for the maximum-entropy tagger are just slightly (o 8 pr q f s ) worse, and precision is still high.", "labels": [], "entities": [{"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9992496371269226}, {"text": "precision", "start_pos": 148, "end_pos": 157, "type": "METRIC", "confidence": 0.9996956586837769}]}, {"text": "This indicates that the corruption of the information content due to transcription errors is much more important than the corruption of the context.", "labels": [], "entities": []}, {"text": "If measured by the string error rate, none of our systems can be used to extract exact caller and phone number information directly from decoded voicemail.", "labels": [], "entities": [{"text": "string error rate", "start_pos": 19, "end_pos": 36, "type": "METRIC", "confidence": 0.7158834536870321}]}, {"text": "However, they can be used to locate the information in the message and highlight those positions.", "labels": [], "entities": []}, {"text": "To evaluate the effectiveness of this approach, we computed precision and recall numbers in terms of the temporal overlap of the identified and true information bearing segments.", "labels": [], "entities": [{"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9990009665489197}, {"text": "recall", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9972829818725586}]}, {"text": "shows that the temporal location of phone numbers can be reliably determined, with an F-measure of 80%.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.999643087387085}]}], "tableCaptions": [{"text": " Table 3: Precision and recall rates for different  systems on manual voicemail transcriptions.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9984684586524963}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9977720379829407}]}, {"text": " Table 4: Precision and recall rates for different  systems on decoded voicemail messages.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9982386827468872}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9988961219787598}]}, {"text": " Table 5: Precision and recall rates for differ- ent systems on replaced decoded voicemail mes- sages.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9981202483177185}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9989525079727173}]}, {"text": " Table 6: Precision and recall of time-overlap  for different systems on decoded voicemail mes- sages.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9926122426986694}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9990360736846924}]}]}