{"title": [{"text": "What is the Minimal Set of Fragments that Achieves Maximal Parse Accuracy?", "labels": [], "entities": [{"text": "Maximal Parse Accuracy", "start_pos": 51, "end_pos": 73, "type": "METRIC", "confidence": 0.5811882515748342}]}], "abstractContent": [{"text": "We aim at finding the minimal set of fragments which achieves maximal parse accuracy in Data Oriented Parsing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.8749274015426636}, {"text": "Data Oriented Parsing", "start_pos": 88, "end_pos": 109, "type": "TASK", "confidence": 0.6342600584030151}]}, {"text": "Experiments with the Penn Wall Street Journal treebank show that counts of almost arbitrary fragments within parse trees are important, leading to improved parse accuracy over previous models tested on this treebank (a precision of 90.8% and a recall of 90.6%).", "labels": [], "entities": [{"text": "Penn Wall Street Journal treebank", "start_pos": 21, "end_pos": 54, "type": "DATASET", "confidence": 0.9670386910438538}, {"text": "accuracy", "start_pos": 162, "end_pos": 170, "type": "METRIC", "confidence": 0.9419113397598267}, {"text": "precision", "start_pos": 219, "end_pos": 228, "type": "METRIC", "confidence": 0.9983687996864319}, {"text": "recall", "start_pos": 244, "end_pos": 250, "type": "METRIC", "confidence": 0.9996654987335205}]}, {"text": "We isolate some dependency relations which previous models neglect but which contribute to higher parse accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9054166078567505}]}], "introductionContent": [{"text": "One of the goals in statistical natural language parsing is to find the minimal set of statistical dependencies (between words and syntactic structures) that achieves maximal parse accuracy.", "labels": [], "entities": [{"text": "statistical natural language parsing", "start_pos": 20, "end_pos": 56, "type": "TASK", "confidence": 0.7233171761035919}, {"text": "accuracy", "start_pos": 181, "end_pos": 189, "type": "METRIC", "confidence": 0.895137369632721}]}, {"text": "Many stochastic parsing models use linguistic intuitions to find this minimal set, for example by restricting the statistical dependencies to the locality of headwords of constituents, leaving it as an open question whether there exist important statistical dependencies that go beyond linguistically motivated dependencies.", "labels": [], "entities": []}, {"text": "The Data Oriented Parsing (DOP) model, on the other hand, takes a rather extreme view on this issue: given an annotated corpus, all fragments (i.e. subtrees) seen in that corpus, regardless of size and lexicalization, are in principle taken to form a grammar (see).", "labels": [], "entities": [{"text": "Data Oriented Parsing (DOP)", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.820433646440506}]}, {"text": "The set of subtrees that is used is thus very large and extremely redundant.", "labels": [], "entities": []}, {"text": "Both from a theoretical and from a computational perspective we may wonder whether it is possible to impose constraints on the subtrees that are used, in such away that the accuracy of the model does not deteriorate or perhaps even improves.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.9989544153213501}]}, {"text": "That is the main question addressed in this paper.", "labels": [], "entities": []}, {"text": "We report on experiments carried outwith the Penn Wall Street Journal (WSJ) treebank to investigate several strategies for constraining the set of subtrees.", "labels": [], "entities": [{"text": "Penn Wall Street Journal (WSJ) treebank", "start_pos": 45, "end_pos": 84, "type": "DATASET", "confidence": 0.9715964645147324}]}, {"text": "We found that the only constraints that do not decrease the parse accuracy consist in an upper bound of the number of words in the subtree frontiers and an upper bound on the depth of unlexicalized subtrees.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9254360795021057}]}, {"text": "We also found that counts of subtrees with several nonheadwords are important, resulting in improved parse accuracy over previous parsers tested on the WSJ.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9710361957550049}, {"text": "WSJ", "start_pos": 152, "end_pos": 155, "type": "DATASET", "confidence": 0.9815801978111267}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Parsing results with the base line subtree  set compared to previous parsers", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9504621624946594}]}, {"text": " Table 2. Parsing results for different subtree  depths (for test sentences \u2264 40 words)", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.908697247505188}]}, {"text": " Table 3. Parsing results for different subtree  lexicalizations (for test sentences \u2264 40 words)", "labels": [], "entities": []}, {"text": " Table 4. Parsing results for different structural  context (for test sentences \u2264 40 words)", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9060186147689819}]}, {"text": " Table 5. Parsing results for different number of  nonheadwords (for test sentences \u2264 40 words)", "labels": [], "entities": []}]}