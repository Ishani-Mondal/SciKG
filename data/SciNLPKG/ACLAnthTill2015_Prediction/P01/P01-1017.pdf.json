{"title": [{"text": "Immediate-Head Parsing for Language Models \u00a3", "labels": [], "entities": [{"text": "Immediate-Head Parsing", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7324430346488953}]}], "abstractContent": [{"text": "We present two language models based upon an \"immediate-head\" parser-our name fora parser that conditions all events below a constituent c upon the head of c.", "labels": [], "entities": []}, {"text": "While all of the most accurate statistical parsers are of the immediate-head variety, no previous grammatical language model uses this technology.", "labels": [], "entities": []}, {"text": "The perplexity for both of these models significantly improve upon the trigram model base-line as well as the best previous grammar-based language model.", "labels": [], "entities": []}, {"text": "For the better of our two models these improvements are 24% and 14% respectively.", "labels": [], "entities": []}, {"text": "We also suggest that improvement of the underlying parser should significantly improve the model's perplexity and that even in the near term there is a lot of potential for improvement in immediate-head language models.", "labels": [], "entities": []}], "introductionContent": [{"text": "All of the most accurate statistical parsers are lexicalized in that they condition probabilities on the lexical content of the sentences being parsed.", "labels": [], "entities": []}, {"text": "Furthermore, all of these \u00a3 This research was supported in part by NSF grant LIS SBR 9720368 and by NSF grant 00100203 IIS0085980.", "labels": [], "entities": [{"text": "NSF grant LIS SBR 9720368", "start_pos": 67, "end_pos": 92, "type": "DATASET", "confidence": 0.8626907706260681}, {"text": "NSF grant 00100203 IIS0085980", "start_pos": 100, "end_pos": 129, "type": "DATASET", "confidence": 0.8729716837406158}]}, {"text": "The author would like to thank the members of the Brown Laboratory for Linguistic Information Processing (BLLIP) and particularly Brian Roark who gave very useful tips on conducting this research.", "labels": [], "entities": [{"text": "Brown Laboratory for Linguistic Information Processing (BLLIP)", "start_pos": 50, "end_pos": 112, "type": "DATASET", "confidence": 0.6039453579319848}]}, {"text": "Thanks also to Fred Jelinek and Ciprian Chelba for the use of their data and for detailed comments on earlier drafts of this paper.", "labels": [], "entities": []}, {"text": "parsers are what we will call immediate-head parsers in that all of the properties of the immediate descendants of a constituent care assigned probabilities that are conditioned on the lexical head of c.", "labels": [], "entities": []}, {"text": "For example, in the probability that the vp expands into v np pp is conditioned on the head of the vp, \"put\", as are the choices of the sub-heads under the vp, i.e., \"ball\" (the head of the np) and \"in\" (the head of the pp).", "labels": [], "entities": []}, {"text": "It is the experience of the statistical parsing community that immediate-head parsers are the most accurate we can design.", "labels": [], "entities": [{"text": "statistical parsing community", "start_pos": 28, "end_pos": 57, "type": "TASK", "confidence": 0.827652633190155}]}, {"text": "It is also worthy of note that many of these parsers are generative -that is, fora sentence s they try to find the parse \ud97b\udf59 defined by Equation 1: arg max \ud97b\udf59 p(\ud97b\udf59 \ud97b\udf59 s) = arg max \ud97b\udf59 p(\ud97b\udf59, s) (1) This is interesting because insofar as they compute p(\ud97b\udf59, s) these parsers define a language-model in that they can (in principle) assign a probability to all possible sentences in the language by computing the sum in Equation 2: where p(\ud97b\udf59, s) is zero if the yield of \ud97b\udf59 \ud97b\udf59 = s.", "labels": [], "entities": []}, {"text": "Language models, of course, are of interest because speech-recognition systems require them.", "labels": [], "entities": []}, {"text": "These systems determine the words that were spoken by solving  Virtually all current speech recognition systems use the so-called trigram language model in which the probability of a string is broken down into conditional probabilities on each word given the two previous words.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.7655325531959534}]}, {"text": "E.g., On the other hand, in the last few years there has been interest in designing language models based upon parsing and Equation 2.", "labels": [], "entities": []}, {"text": "We now turn to this previous research.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Perplexity results for two previous  grammar-based language models", "labels": [], "entities": []}, {"text": " Table 2: Perplexity results for the immediate- bihead model", "labels": [], "entities": [{"text": "Perplexity", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9512919783592224}]}, {"text": " Table 3: Perplexity results for the immediate- trihead model", "labels": [], "entities": [{"text": "Perplexity", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9521212577819824}]}, {"text": " Table 4: Precision/recall for sentences in which  trigram/grammar models performed best", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9698806405067444}, {"text": "recall", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.9641294479370117}]}, {"text": " Table 4. We see there that, for  example, sentences for which the grammar model  has the superior perplexity have average recall 5.9", "labels": [], "entities": [{"text": "recall 5.9", "start_pos": 123, "end_pos": 133, "type": "METRIC", "confidence": 0.8880610466003418}]}]}