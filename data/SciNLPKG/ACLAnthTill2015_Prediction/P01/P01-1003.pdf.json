{"title": [{"text": "Improvement of a Whole Sentence Maximum Entropy Language Model Using Grammatical Features", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we propose adding long-term grammatical information in a Whole Sentence Maximun Entropy Language Model (WSME) in order to improve the performance of the model.", "labels": [], "entities": [{"text": "Whole Sentence Maximun Entropy Language Model (WSME)", "start_pos": 72, "end_pos": 124, "type": "TASK", "confidence": 0.7189207838641273}]}, {"text": "The grammatical information was added to the WSME model as features and were obtained from a Stochas-tic Context-Free grammar.", "labels": [], "entities": [{"text": "WSME", "start_pos": 45, "end_pos": 49, "type": "DATASET", "confidence": 0.7059609889984131}]}, {"text": "Finally, experiments using apart of the Penn Tree-bank corpus were carried out and significant improvements were acheived.", "labels": [], "entities": [{"text": "Penn Tree-bank corpus", "start_pos": 40, "end_pos": 61, "type": "DATASET", "confidence": 0.9557915131251017}]}], "introductionContent": [{"text": "Language modeling is an important component in computational applications such as speech recognition, automatic translation, optical character recognition, information retrieval etc..", "labels": [], "entities": [{"text": "Language modeling", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7141313403844833}, {"text": "speech recognition", "start_pos": 82, "end_pos": 100, "type": "TASK", "confidence": 0.8113178014755249}, {"text": "automatic translation", "start_pos": 102, "end_pos": 123, "type": "TASK", "confidence": 0.748724639415741}, {"text": "optical character recognition", "start_pos": 125, "end_pos": 154, "type": "TASK", "confidence": 0.6484849552313486}, {"text": "information retrieval", "start_pos": 156, "end_pos": 177, "type": "TASK", "confidence": 0.8311202824115753}]}, {"text": "Statistical language models have gained considerable acceptance due to the efficiency demonstrated in the fields in which they have been applied ().", "labels": [], "entities": []}, {"text": "Traditional statistical language models calculate the probability of a sentence \u00a4 using the chain rule: Although we can incorporate local information (like n-grams) and some kinds of long-distance information (like triggers) within the conditional ME model, the global information contained in the sentence is poorly encoded in the ME model, as happens with the other conditional models.", "labels": [], "entities": []}, {"text": "There is a language model which is able to take advantage of the local information and at the same time allows for the use of the global properties of the sentence: the Whole Sentence Maximum Entropy model (WSME).", "labels": [], "entities": []}, {"text": "We can include classical information such us n-grams, distance n-grams or triggers and global properties of the sentence, as features into the WSME framework.", "labels": [], "entities": [{"text": "WSME framework", "start_pos": 143, "end_pos": 157, "type": "DATASET", "confidence": 0.8534208536148071}]}, {"text": "Besides the fact that the WSME model training procedure is less expensive than the conditional ME model, the most important training step is based on well-developed statistical sampling techniques.", "labels": [], "entities": []}, {"text": "In recent works), WSME models have been successfully trained using features of n-grams and distance n-grams.", "labels": [], "entities": [{"text": "WSME", "start_pos": 18, "end_pos": 22, "type": "TASK", "confidence": 0.7626904249191284}]}, {"text": "In this work, we propose adding information to the WSME model which is provided by the grammatical structure of the sentence.", "labels": [], "entities": [{"text": "WSME", "start_pos": 51, "end_pos": 55, "type": "TASK", "confidence": 0.6664106845855713}]}, {"text": "The information is added in the form of features by means of a Stochastic Context-Free Grammar (SCFG).", "labels": [], "entities": []}, {"text": "The grammatical information is combined with features of n-grams and triggers.", "labels": [], "entities": []}, {"text": "In section 2, we describe the WSME model and the training procedure in order to estimate the parameters of the model.", "labels": [], "entities": [{"text": "WSME model", "start_pos": 30, "end_pos": 40, "type": "DATASET", "confidence": 0.722989946603775}]}, {"text": "In section 3, we define the grammatical features and the way of obtaining them from the SCFG.", "labels": [], "entities": []}, {"text": "Finally, section 4 presents the experiments carried out using apart of the Wall Street Journal in order evalute the behavior of this proposal.", "labels": [], "entities": [{"text": "apart of the Wall Street Journal", "start_pos": 62, "end_pos": 94, "type": "DATASET", "confidence": 0.9243309696515402}]}], "datasetContent": [{"text": "A part of the Wall Street Journal (WSJ) which had been processed in the Penn Treebanck Project () was used in the experiments.", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ)", "start_pos": 14, "end_pos": 39, "type": "DATASET", "confidence": 0.9221493303775787}, {"text": "Penn Treebanck Project", "start_pos": 72, "end_pos": 94, "type": "DATASET", "confidence": 0.9855897823969523}]}, {"text": "This corpus was automatically labelled and manually checked.", "labels": [], "entities": []}, {"text": "There were two kinds of labelling: POStag labelling and syntactic labelling.", "labels": [], "entities": [{"text": "POStag labelling", "start_pos": 35, "end_pos": 51, "type": "TASK", "confidence": 0.5685019195079803}]}, {"text": "The POStag vocabulary was composed of 45 labels.", "labels": [], "entities": [{"text": "POStag vocabulary", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.8797693848609924}]}, {"text": "The syntactic labels are 14.", "labels": [], "entities": []}, {"text": "The corpus was divided into sentences according to the bracketing.", "labels": [], "entities": []}, {"text": "We selected 12 sections of the corpus at random.", "labels": [], "entities": []}, {"text": "Six were used as training corpus, three as test set and the other three sections were used as held-out for tuning the smoothing WSME model.", "labels": [], "entities": [{"text": "smoothing WSME", "start_pos": 118, "end_pos": 132, "type": "TASK", "confidence": 0.6545861810445786}]}, {"text": "The sets are described as follow: the training corpus has 11,201 sentences; the test set has 6,350 sentences and the held-out set has 5,796 sentences.", "labels": [], "entities": []}, {"text": "A base-line Katz back-off smoothed trigram model was trained using the CMU-Cambridge statistical Language Modeling Toolkit and used as prior distribution in  . The vocabulary generated by the trigram model was used as vocabulary of the WSME model.", "labels": [], "entities": [{"text": "CMU-Cambridge statistical Language Modeling Toolkit", "start_pos": 71, "end_pos": 122, "type": "DATASET", "confidence": 0.8031978964805603}, {"text": "WSME model", "start_pos": 236, "end_pos": 246, "type": "DATASET", "confidence": 0.7741580903530121}]}, {"text": "The size of the vocabulary was 19,997 words.", "labels": [], "entities": []}, {"text": "The estimation of the word-category probability distribution was computed from the training corpus.", "labels": [], "entities": []}, {"text": "In order to avoid null values, the unseen events were labeled with a special \"unknown\" symbol which did not appear in the vocabulary, so that the probabilitie of the unseen envent were positive for all the categories.", "labels": [], "entities": []}, {"text": "The SCFG had the maximum number of rules which can be composed of 45 terminal symbols (the number of POStags) and 14 non-terminal symbols (the number of syntactic labels).", "labels": [], "entities": []}, {"text": "The initial probabilities were randomly generated and three different seeds were tested.", "labels": [], "entities": []}, {"text": "However, only one of them is here given that the results were very similar.", "labels": [], "entities": []}, {"text": "The size of the sample used in the ISS was estimated by means of an experimental procedure and was set at 10,000 elements.", "labels": [], "entities": []}, {"text": "The procedure used to generate the sample made use of the \"diagnosis of convergence\", a method by means of which an inicial portion of each run of the Markov chain of sufficient length is discarded.", "labels": [], "entities": [{"text": "convergence", "start_pos": 72, "end_pos": 83, "type": "METRIC", "confidence": 0.8685534000396729}]}, {"text": "Thus, the states in the remaining portion come from the desired equilibrium distribution.", "labels": [], "entities": []}, {"text": "In this work, a discarded portion of 3,000 elements was establiched.", "labels": [], "entities": []}, {"text": "Thus in practice, we have to generate 13,000 instances of the Markov chain.", "labels": [], "entities": []}, {"text": "During the IIS, every sample was tagged using the grammar estimated above, and then the grammatical features were extracted, before combining them with other kinds of features.", "labels": [], "entities": [{"text": "IIS", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9021466374397278}]}, {"text": "The adequate number of iterations of the IIS was established experimentally in 13.", "labels": [], "entities": [{"text": "IIS", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.8474578261375427}]}, {"text": "We trained several WSME models using the Perfect Sampling algorithm in the IIS and a different set of features (including the grammatical features) for each model.", "labels": [], "entities": [{"text": "IIS", "start_pos": 75, "end_pos": 78, "type": "DATASET", "confidence": 0.8524243235588074}]}, {"text": "The different sets of features used in the models were: n-grams (1-grams,2-grams,3-grams); triggers; n-grams and grammatical features; triggers and grammatical feautres; n-grams, triggers and grammatical features.", "labels": [], "entities": []}, {"text": "The A -gram features,(N), was selected by means of its frequency in the corpus.", "labels": [], "entities": []}, {"text": "We select all the unigrams, the bigrams with frequency greater than 5 and the trigrams with frequency greater than 10, in order to mantain the proportion of each type of A -gram in the corpus.", "labels": [], "entities": []}, {"text": "The triggers, (T), were generated using a trig-: Comparison of the perplexity between models with grammatical features and models without grammatical features for WSME models over part of the WSJ corpus.", "labels": [], "entities": [{"text": "WSJ corpus", "start_pos": 192, "end_pos": 202, "type": "DATASET", "confidence": 0.9698794782161713}]}, {"text": "N means features of n-grams, T means features of Triggers.", "labels": [], "entities": []}, {"text": "The perplexity of the trained n-gram model was PP=162.049 ger toolkit developed by Adam Berger 5 . The triggers were selected in acordance with de mutual information.", "labels": [], "entities": []}, {"text": "The triggers selected were those with mutual information greater than 0.0001.", "labels": [], "entities": []}, {"text": "The grammatical features, (G), were selected using the parser tree of all the sentences in the training corpus to obtain the sets and, so, we smooth the model.", "labels": [], "entities": []}, {"text": "We smoothed it using a gaussian prior technique.", "labels": [], "entities": []}, {"text": "In the gaussian technique, we assumed that the f & paramters had a gaussian (normal) prior probability distribution) and found the maximum aposteriori parameter distribution.", "labels": [], "entities": []}, {"text": "The prior distribution was , and we used the held-out data to find the \u00c7 & parameters.", "labels": [], "entities": []}, {"text": "shows the experimental results: the first row represents the set of features used.", "labels": [], "entities": []}, {"text": "The second row shows the perplexity of the models without using grammatical features.", "labels": [], "entities": []}, {"text": "The third row shows the perplexity of the models using grammatical features and the fourth row shows the improvement in perplexity of each model using grammatical features over the corresponding model without grammatical features.", "labels": [], "entities": []}, {"text": "As can be seen in, all the WSME models performed better than the A -gram model, however that is natural because, in the worst case, the WSME models perform like the A -gram model.", "labels": [], "entities": [{"text": "WSME", "start_pos": 27, "end_pos": 31, "type": "DATASET", "confidence": 0.6841214299201965}, {"text": "WSME", "start_pos": 136, "end_pos": 140, "type": "DATASET", "confidence": 0.8486045598983765}]}, {"text": "In, we see that all the models using grammatical features perform better than the models that do not use it.", "labels": [], "entities": []}, {"text": "Since the training procedure was the same for all the models described and since the only difference between the two kinds of models compared were the grammatical features, then we conclude that the improvement must be due to the inclusion of such features into the set of features.", "labels": [], "entities": []}, {"text": "The average percentage of improvement was about 13%.", "labels": [], "entities": [{"text": "improvement", "start_pos": 26, "end_pos": 37, "type": "METRIC", "confidence": 0.9754343032836914}]}, {"text": "Also, although the model N+T performs better than the other model without grammatical features (N,T), it behaves worse than all the models with grammatical features ( N+G improved 2.9% and T+G improvd 5.9% over N+T).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of the perplexity between  models with grammatical features and models  without grammatical features for WSME mod- els over part of the WSJ corpus. N means fea- tures of n-grams, T means features of Triggers.  The perplexity of the trained n-gram model was  PP=162.049", "labels": [], "entities": [{"text": "WSME mod- els", "start_pos": 126, "end_pos": 139, "type": "DATASET", "confidence": 0.7751210331916809}, {"text": "WSJ corpus", "start_pos": 157, "end_pos": 167, "type": "DATASET", "confidence": 0.9796657860279083}]}]}