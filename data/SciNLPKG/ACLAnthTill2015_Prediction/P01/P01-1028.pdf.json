{"title": [{"text": "Generating with a Grammar Based on Tree Descriptions: a Constraint-Based Approach", "labels": [], "entities": []}], "abstractContent": [{"text": "While the generative view of language processing builds bigger units out of smaller ones by means of rewriting steps, the axiomatic view eliminates invalid linguistic structures out of a set of possible structures by means of well-formedness principles.", "labels": [], "entities": []}, {"text": "We present a generator based on the axiomatic view and argue that when combined with a TAG-like grammar and a flat semantics , this axiomatic view permits avoiding drawbacks known to hold either of top-down or of bottom-up generators.", "labels": [], "entities": []}], "introductionContent": [{"text": "We take the axiomatic view of language and show that it yields an interestingly new perspective on the tactical generation task i.e. the task of producing from a given semantics a string with semantics . As (Cornell and Rogers, To appear) clearly shows, there has recently been a surge of interest in logic based grammars for natural language.", "labels": [], "entities": [{"text": "tactical generation task", "start_pos": 103, "end_pos": 127, "type": "TASK", "confidence": 0.7771690686543783}]}, {"text": "In this branch of research sometimes referred to as \"Model Theoretic Syntax\", a grammar is viewed as a set of axioms defining the well-formed structures of natural language.", "labels": [], "entities": []}, {"text": "The motivation for model theoretic grammars is initially theoretical: the use of logic should support both a more precise formulation of grammars and a different perspective on the mathematical and computational properties of natural language.", "labels": [], "entities": []}, {"text": "But eventually the question must also be addressed of how such grammars could be put to work.", "labels": [], "entities": []}, {"text": "One obvious answer is to use a model generator.", "labels": [], "entities": []}, {"text": "Given a logical formula , a model generator is a program which builds some of the models satisfying this formula.", "labels": [], "entities": []}, {"text": "Thus for parsing, a model generator can be used to enumerate the (minimal) model(s), that is, the parse trees, satisfying the conjunction of the lexical categories selected on the basis of the input string plus any additional constraints which might be encoded in the grammar.", "labels": [], "entities": [{"text": "parsing", "start_pos": 9, "end_pos": 16, "type": "TASK", "confidence": 0.971333384513855}]}, {"text": "And similarly for generation, a model generator can be used to enumerate the models satisfying the bag of lexical items selected by the lexical lookup phase on the basis of the input semantics.", "labels": [], "entities": []}, {"text": "How can we design model generators which work efficiently on natural language input i.e. on the type of information delivered by logic based grammars?", "labels": [], "entities": []}, {"text": "shows that constraint programming can be used to implement a model generator for tree logic.", "labels": [], "entities": []}, {"text": "Further, shows that this model generator can be used to parse with descriptions based grammars) that is, on logic based grammars where lexical entries are descriptions of trees expressed in some tree logic.", "labels": [], "entities": []}, {"text": "In this paper, we build on) and show that modulo some minor modifications, the same model generator can be used to generate with description based grammars.", "labels": [], "entities": []}, {"text": "We describe the workings of the algorithm and compare it with standard existing top-down and bottom-up generation algorithms.", "labels": [], "entities": []}, {"text": "In specific, we argue that the change of perspective offered by the constraint-based, axiomatic approach to processing presents some interesting differences with the more traditional generative approach usually pursued in tactical generation and further, that the combination of this static view with a TAG-like grammar and a flat semantics results in a system which combines the positive aspects of both topdown and bottom-up generators.", "labels": [], "entities": [{"text": "tactical generation", "start_pos": 222, "end_pos": 241, "type": "TASK", "confidence": 0.7927550375461578}]}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents the grammars we are working with namely, Description Grammars (DG), Section 3 summarises the parsing model presented in) and Section 4 shows that this model can be extended to generate with DGs.", "labels": [], "entities": []}, {"text": "In Section 5, we compare our generator with top-down and bottom-up generators, Section 6 reports on a proof-of-concept implementation and Section 7 concludes with pointers for further research.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}