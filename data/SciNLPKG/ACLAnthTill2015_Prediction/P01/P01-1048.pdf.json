{"title": [{"text": "Predicting User Reactions to System Error", "labels": [], "entities": [{"text": "Predicting User Reactions to System Error", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.8553431828816732}]}], "abstractContent": [{"text": "This paper focuses on the analysis and prediction of so-called aware sites, defined as turns where a user of a spoken dialogue system first becomes aware that the system has made a speech recognition error.", "labels": [], "entities": [{"text": "prediction of so-called aware sites, defined as turns where a user of a spoken dialogue system first becomes aware that the system has made a speech recognition error", "start_pos": 39, "end_pos": 205, "type": "Description", "confidence": 0.7426746867854019}]}, {"text": "We describe statistical comparisons of features of these aware sites in a train timetable spoken dialogue corpus, which reveal significant prosodic differences between such turns, compared with turns that 'correct' speech recognition errors as well as with 'normal' turns that are neither aware sites nor corrections.", "labels": [], "entities": []}, {"text": "We then present machine learning results in which we show how prosodic features in combination with other automatically available features can predict whether or not a user turn was a normal turn, a correction, and/or an aware site.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes new results in our continuing investigation of prosodic information as a potential resource for error recovery in interactions between a user and a spoken dialogue system.", "labels": [], "entities": [{"text": "error recovery", "start_pos": 117, "end_pos": 131, "type": "TASK", "confidence": 0.6805010437965393}]}, {"text": "In human-human interaction, dialogue partners apply sophisticated strategies to detect and correct communication failures so that errors of recognition and understanding rarely lead to a complete breakdown of the interaction).", "labels": [], "entities": []}, {"text": "In particular, various studies have shown that prosody is an important cue in avoiding such breakdown, e.g. ().", "labels": [], "entities": []}, {"text": "Human-machine interactions between a user and a spoken dialogue system (SDS) exhibit more frequent communication breakdowns, due mainly to errors in the Automatic Speech Recognition (ASR) component of these systems.", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 153, "end_pos": 187, "type": "TASK", "confidence": 0.7619437277317047}]}, {"text": "In such interactions, however, there is also evidence showing prosodic information maybe used as a resource for error recovery.", "labels": [], "entities": [{"text": "error recovery", "start_pos": 112, "end_pos": 126, "type": "TASK", "confidence": 0.7491376399993896}]}, {"text": "In previous work, we identified new procedures to detect recognition errors.", "labels": [], "entities": []}, {"text": "In particular, we found that prosodic features, in combination with other information already available to the recognizer, can distinguish user turns that are misrecognized by the system far better than traditional methods used in ASR rejection ( ).", "labels": [], "entities": [{"text": "ASR rejection", "start_pos": 231, "end_pos": 244, "type": "TASK", "confidence": 0.9908221364021301}]}, {"text": "We also found that user corrections of system misrecognitions exhibit certain typical prosodic features, which can be used to identify such turns ().", "labels": [], "entities": []}, {"text": "These findings are consistent with previous research showing that corrections tend to be hyperarticulated -higher, louder, longer ...than other turns ().", "labels": [], "entities": []}, {"text": "In the current study, we focus on another turn category that is potentially useful in error handling.", "labels": [], "entities": [{"text": "error handling", "start_pos": 86, "end_pos": 100, "type": "TASK", "confidence": 0.7618129849433899}]}, {"text": "In particular, we examine what we term aware sites -turns where a user, while interacting with a machine, first becomes aware that the system has misrecognized a previous user turn.", "labels": [], "entities": []}, {"text": "Note that such aware sites mayor may not also be corrections (another type of post-misrecognition turn), since a user may not immediately provide correcting information.", "labels": [], "entities": []}, {"text": "We will refer to turns that are both aware sites and corrections as corrawares, to turns that are only corrections as corrs, to turns that are only aware sites as awares, and to turns that are neither aware sites nor corrections as norm.", "labels": [], "entities": []}, {"text": "We believe that it would be useful for the dialogue manager in an SDS to be able to detect aware sites for several reasons.", "labels": [], "entities": []}, {"text": "First, if aware sites are detectable, they can function as backward-looking error-signaling devices, making it clear to the system that something has gone wrong in the preceding context, so that, for example, the system can reprompt for information.", "labels": [], "entities": []}, {"text": "In this way, they are similar to what others have termed 'go-back' signals ().", "labels": [], "entities": []}, {"text": "Second, aware sites can be used as forwardlooking signals, indicating upcoming corrections or more drastic changes in user behavior, such as complete restarts of the task.", "labels": [], "entities": []}, {"text": "Given that, in current systems, both corrections and restarts often lead to recognition error ( ), aware sites maybe useful in preparing systems to deal with such problems.", "labels": [], "entities": []}, {"text": "In this paper, we investigate whether aware sites share acoustic properties that set them apart from normal turns, from corrections, and from turns which are both aware sites and corrections.", "labels": [], "entities": []}, {"text": "We also want to test whether these different turn categories can be distinguished automatically, via their prosodic features or from other features known to or automatically detectible by a spoken dialogue system.", "labels": [], "entities": []}, {"text": "Our domain is the TOOT spoken dialogue corpus, which we describe in Section 2.", "labels": [], "entities": [{"text": "TOOT spoken dialogue corpus", "start_pos": 18, "end_pos": 45, "type": "DATASET", "confidence": 0.6680791079998016}]}, {"text": "In Section 3, we present some descriptive findings on different turn categories in TOOT.", "labels": [], "entities": [{"text": "TOOT", "start_pos": 83, "end_pos": 87, "type": "DATASET", "confidence": 0.8521137833595276}]}, {"text": "Section 4 presents results of our machine learning experiments on distinguishing the different turn classes.", "labels": [], "entities": []}, {"text": "In Section 5 we summarize our conclusions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Mean Values of Prosodic Features for Turn Categories.", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9901110529899597}]}, {"text": " Table 3: 4-way Classification Performance.", "labels": [], "entities": [{"text": "Classification", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.8177699446678162}]}, {"text": " Table 4: Confusion Matrix, 4-way Classification.", "labels": [], "entities": []}, {"text": " Table 3.  The ruleset for the 3-class predictions is given in", "labels": [], "entities": []}, {"text": " Table 5: 3-way Classification Performance.", "labels": [], "entities": [{"text": "Classification", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.8834878206253052}]}, {"text": " Table 6: 2-way Classification Performance.", "labels": [], "entities": [{"text": "Classification", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.8669677376747131}]}]}