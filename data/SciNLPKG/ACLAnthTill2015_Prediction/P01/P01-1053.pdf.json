{"title": [{"text": "Automatic Detection of Syllable Boundaries Combining the Advantages of Treebank and Bracketed Corpora Training", "labels": [], "entities": [{"text": "Automatic Detection of Syllable Boundaries", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7782327234745026}]}], "abstractContent": [{"text": "An approach to automatic detection of syllable boundaries is presented.", "labels": [], "entities": [{"text": "automatic detection of syllable boundaries", "start_pos": 15, "end_pos": 57, "type": "TASK", "confidence": 0.7973187685012817}]}, {"text": "We demonstrate the use of several manually constructed grammars trained with a novel algorithm combining the advantages of treebank and bracketed corpora training.", "labels": [], "entities": []}, {"text": "We investigate the effect of the training corpus size on the performance of our system.", "labels": [], "entities": []}, {"text": "The evaluation shows that a handwritten grammar performs better on finding syllable boundaries than does a treebank grammar.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper we present an approach to supervised learning and automatic detection of syllable boundaries.", "labels": [], "entities": [{"text": "automatic detection of syllable boundaries", "start_pos": 64, "end_pos": 106, "type": "TASK", "confidence": 0.7768481016159058}]}, {"text": "The primary goal of the paper is to demonstrate that under certain conditions treebank and bracketed corpora training can be combined by exploiting the advantages of the two methods.", "labels": [], "entities": []}, {"text": "Treebank training provides a method of unambiguous analyses whereas bracketed corpora training has the advantage that linguistic knowledge can be used to write linguistically motivated grammars.", "labels": [], "entities": []}, {"text": "In text-to-speech (TTS) systems, like those described in, the correct pronunciation of unknown or novel words is one of the biggest problems.", "labels": [], "entities": []}, {"text": "In many TTS systems large pronunciation dictionaries are used.", "labels": [], "entities": [{"text": "TTS", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9686152338981628}]}, {"text": "However, the lexicons are finite and every natural language has productive word formation processes.", "labels": [], "entities": [{"text": "word formation", "start_pos": 75, "end_pos": 89, "type": "TASK", "confidence": 0.7635717391967773}]}, {"text": "The German language for example is known for its extensive use of compounds.", "labels": [], "entities": []}, {"text": "A TTS system needs a module where the words converted from graphemes to phonemes are syllabified before they can be further processed to speech.", "labels": [], "entities": [{"text": "TTS", "start_pos": 2, "end_pos": 5, "type": "TASK", "confidence": 0.9517135620117188}]}, {"text": "The placement of the correct syllable boundary is essential for the application of phonological rules.", "labels": [], "entities": []}, {"text": "Our approach offers a machine learning algorithm for predicting syllable boundaries.", "labels": [], "entities": [{"text": "predicting syllable boundaries", "start_pos": 53, "end_pos": 83, "type": "TASK", "confidence": 0.8797661463419596}]}, {"text": "Our method builds on two resources.", "labels": [], "entities": []}, {"text": "The first resource is a series of context-free grammars (CFG) which are either constructed manually or extracted automatically (in the case of the treebank grammar) to predict syllable boundaries.", "labels": [], "entities": []}, {"text": "The different grammars are described in section 4.", "labels": [], "entities": []}, {"text": "The second resource is a novel algorithm that aims to combine the advantages of treebank and bracketed corpora training.", "labels": [], "entities": []}, {"text": "The obtained probabilistic context-free grammars are evaluated on a test corpus.", "labels": [], "entities": []}, {"text": "We also investigate the influence of the size of the training corpus on the performance of our system.", "labels": [], "entities": []}, {"text": "The evaluation shows that adding linguistic information to the grammars increases the accuracy of our models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9994677901268005}]}, {"text": "For instance, we coded the knowledge that (i) consonants in the onset and coda are restricted in their distribution, and (ii) the position inside of the word plays an important role.", "labels": [], "entities": []}, {"text": "Furthermore, linguistically motivated grammars only need a small size of training corpus to achieve high accuracy and even out-perform the treebank grammar trained on the largest training corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.997241735458374}]}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 refers to treebank training.", "labels": [], "entities": [{"text": "treebank training", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.7433276772499084}]}, {"text": "In section 3 we introduce the combination of tree- bank and bracketed corpora training.", "labels": [], "entities": []}, {"text": "In section 4 we describe the grammars and experiments for German data.", "labels": [], "entities": [{"text": "German data", "start_pos": 58, "end_pos": 69, "type": "DATASET", "confidence": 0.8124161064624786}]}, {"text": "Section 5 is dedicated to evaluation and in section 6 we discuss our results.", "labels": [], "entities": [{"text": "evaluation", "start_pos": 26, "end_pos": 36, "type": "TASK", "confidence": 0.9610573053359985}]}], "datasetContent": [{"text": "We experimented with a series of grammars: the first grammar, a treebank grammar, was automatically read from the corpus, which describes a syllable consisting of a phoneme sequence.", "labels": [], "entities": []}, {"text": "There are no intermediate levels between the syllable and the phonemes.", "labels": [], "entities": []}, {"text": "The second grammar is a phoneme grammar where only the number of phonemes is important.", "labels": [], "entities": []}, {"text": "The third grammar is a consonant-vowel grammar with the linguistic information that there are consonants and vowels.", "labels": [], "entities": []}, {"text": "The fourth grammar, a syllable structure grammar is enriched with the information that the consonant in the onset and coda are subject to certain restrictions.", "labels": [], "entities": []}, {"text": "The last grammar is a positional syllable structure grammar which expresses that the consonants of the onset and coda are restricted according to the position inside of a word (e.g, initial, medial, final or monosyllabic).", "labels": [], "entities": []}, {"text": "These grammars were trained on different sizes of corpora and then evaluated.", "labels": [], "entities": []}, {"text": "In the following we first introduce the training procedure and then describe the grammars in details.", "labels": [], "entities": []}, {"text": "In section 5 the evaluation of the system is described.", "labels": [], "entities": []}, {"text": "We split our corpus into a 9/10 training and a 1/10 test corpus resulting in an evaluation (test) corpus consisting of 242047 words.", "labels": [], "entities": []}, {"text": "Our test corpus is available on the World Wide Web 2 . There are two different features that characterize our test corpus: (i) the number of unknown words in the test corpus, (ii) and the number of words with a certain number of syllables.", "labels": [], "entities": [{"text": "World Wide Web", "start_pos": 36, "end_pos": 50, "type": "DATASET", "confidence": 0.8489100337028503}]}, {"text": "The proportion of the unknown words is depicted in.", "labels": [], "entities": []}, {"text": "The percentage of unknown words is almost 100% for the smallest training corpus, decreasing to about 5% for the largest training corpus.", "labels": [], "entities": []}, {"text": "The \"slow\" decrease of the number of unknown words of the test corpus is due to both the high amount of test data (242047 items) and the \"slightly\" growing size of the training corpus.", "labels": [], "entities": []}, {"text": "If the training corpus increases, the number of words that have not been seen before (unknown) in the test corpus decreases.", "labels": [], "entities": []}, {"text": "shows the distribution of the number of syllables in the test corpus ranked by the number of syllables, which is a decreasing function.", "labels": [], "entities": []}, {"text": "Almost 50% of the test corpus consists of monosyllabic words.", "labels": [], "entities": []}, {"text": "If the number of syllables increases, the number of words decreases.", "labels": [], "entities": []}, {"text": "The test corpus without syllable boundaries, is processed by a parser () and the probabilistic context-free grammars sustaining the most probable parse (Viterbi parse) of each word.", "labels": [], "entities": []}, {"text": "We compare the results of the parsing step with our test corpus (annotated with syllable boundaries) and compute the accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 30, "end_pos": 37, "type": "TASK", "confidence": 0.9645310044288635}, {"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9990654587745667}]}, {"text": "If the parser correctly predicts all syllable boundaries of 2 http://www.ims.uni-stuttgart.de/phonetik/eval-syl The accuracy curves of all grammars are shown in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9990391731262207}]}, {"text": "Comparing the treebank grammar and the simplest linguistic grammar we see that the accuracy curve of the treebank grammar monotonically increases, whereas the phoneme grammar has almost constant accuracy values (63%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9993417859077454}, {"text": "accuracy", "start_pos": 195, "end_pos": 203, "type": "METRIC", "confidence": 0.9978170394897461}]}, {"text": "The figure also shows that the simplest grammar is better than the treebank grammar until the treebank grammar is trained with a corpus size of 77.800.", "labels": [], "entities": []}, {"text": "The accuracy of both grammars is about 65% at that point.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996108412742615}]}, {"text": "When the corpus size exceeds 77800, the performance of the treebank grammar is better than the simplest linguistic grammar.", "labels": [], "entities": []}, {"text": "The best treebank grammar reaches a accuracy of 94.89%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9996728897094727}]}, {"text": "The low accuracy rates of the treebank grammar trained on small corpora are due to the high number of syllables that have not been seen in the training procedure.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9990198612213135}]}, {"text": "shows that the CV grammar, the syllable structure grammar and the positional syllable structure grammar outperform the treebank grammar by at least 6% with the second largest training corpus of about 1 million words.", "labels": [], "entities": []}, {"text": "When the corpus size is doubled, the accuracy of the treebank grammar is still 1.5% below the positional syllable structure grammar.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9996527433395386}]}, {"text": "Moreover, the positional syllable structure grammar only needs a corpus size of 9600 to outperform the treebank grammar. is a summary of the best results of the different grammars on different corpora sizes.", "labels": [], "entities": []}], "tableCaptions": []}