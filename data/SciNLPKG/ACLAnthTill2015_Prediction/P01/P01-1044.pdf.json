{"title": [{"text": "Parsing with Treebank Grammars: Empirical Bounds, Theoretical Models, and the Structure of the Penn Treebank", "labels": [], "entities": [{"text": "Parsing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.95173579454422}, {"text": "Penn Treebank", "start_pos": 95, "end_pos": 108, "type": "DATASET", "confidence": 0.9903599619865417}]}], "abstractContent": [{"text": "This paper presents empirical studies and closely corresponding theoretical models of the performance of a chart parser exhaustively parsing the Penn Treebank with the Treebank's own CFG grammar.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 145, "end_pos": 158, "type": "DATASET", "confidence": 0.9877151548862457}]}, {"text": "We show how performance is dramatically affected by rule representation and tree transformations, but little by top-down vs. bottom-up strategies.", "labels": [], "entities": [{"text": "rule representation", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.7786009311676025}]}, {"text": "We discuss grammatical saturation, including analysis of the strongly connected components of the phrasal nonterminals in the Treebank, and model how, as sentence length increases, the effective grammar rule size increases as regions of the grammar are unlocked, yielding super-cubic observed time behavior in some configurations.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper originated from examining the empirical performance of an exhaustive active chart parser using an untransformed treebank grammar over the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 149, "end_pos": 162, "type": "DATASET", "confidence": 0.996324896812439}]}, {"text": "Our initial experiments yielded the surprising result that for many configurations empirical parsing speed was super-cubic in the sentence length.", "labels": [], "entities": []}, {"text": "This led us to look more closely at the structure of the treebank grammar.", "labels": [], "entities": []}, {"text": "The resulting analysis builds on the presentation of Charniak (1996), but extends it by elucidating the structure of non-terminal interrelationships in the Penn Treebank grammar.", "labels": [], "entities": [{"text": "Penn Treebank grammar", "start_pos": 156, "end_pos": 177, "type": "DATASET", "confidence": 0.9899917046229044}]}, {"text": "On the basis of these studies, we build simple theoretical models which closely predict observed parser performance, and, in particular, explain the originally observed super-cubic behavior.", "labels": [], "entities": []}, {"text": "We used treebank grammars induced directly from the local trees of the entire WSJ section of the Penn Treebank () (release 3).", "labels": [], "entities": [{"text": "WSJ section of the Penn Treebank", "start_pos": 78, "end_pos": 110, "type": "DATASET", "confidence": 0.8666651050249735}]}, {"text": "For each length and parameter setting, 25 sentences evenly distributed through the treebank were parsed.", "labels": [], "entities": []}, {"text": "Since we were parsing sentences from among those from which our grammar was derived, coverage was never an issue.", "labels": [], "entities": [{"text": "coverage", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.8494797348976135}]}, {"text": "Every sentence parsed had at least one parse -the parse with which it was originally observed.", "labels": [], "entities": []}, {"text": "The sentences were parsed using an implementation of the probabilistic chart-parsing algorithm presented in.", "labels": [], "entities": []}, {"text": "In that paper, we present a theoretical analysis showing an The default settings are shown above in boldface.", "labels": [], "entities": []}, {"text": "We do not discuss all possible combinations of these settings.", "labels": [], "entities": []}, {"text": "Rather, we take the bottom-up parser using an untransformed grammar with trie rule encodings to be the basic form of the parser.", "labels": [], "entities": []}, {"text": "Except where noted, we will discuss how each factor affects this baseline, as most of the effects are orthogonal.", "labels": [], "entities": []}, {"text": "When we name a setting, any omitted parameters are assumed to be the defaults.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}