{"title": [{"text": "A Statistical Model for Domain-Independent Text Segmentation", "labels": [], "entities": [{"text": "Domain-Independent Text Segmentation", "start_pos": 24, "end_pos": 60, "type": "TASK", "confidence": 0.6242513159910837}]}], "abstractContent": [{"text": "We propose a statistical method that finds the maximum-probability seg-mentation of a given text.", "labels": [], "entities": []}, {"text": "This method does not require training data because it estimates probabilities from the given text.", "labels": [], "entities": []}, {"text": "Therefore, it can be applied to any text in any domain.", "labels": [], "entities": []}, {"text": "An experiment showed that the method is more accurate than or at least as accurate as a state-of-the-art text segmentation system .", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 105, "end_pos": 122, "type": "TASK", "confidence": 0.7223117351531982}]}], "introductionContent": [{"text": "Documents usually include various topics.", "labels": [], "entities": []}, {"text": "Identifying and isolating topics by dividing documents, which is called text segmentation, is important for many natural language processing tasks, including information retrieval) and summarization ().", "labels": [], "entities": [{"text": "Identifying and isolating topics", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7458876222372055}, {"text": "text segmentation", "start_pos": 72, "end_pos": 89, "type": "TASK", "confidence": 0.7001019865274429}, {"text": "information retrieval", "start_pos": 158, "end_pos": 179, "type": "TASK", "confidence": 0.7609665393829346}, {"text": "summarization", "start_pos": 185, "end_pos": 198, "type": "TASK", "confidence": 0.9888136982917786}]}, {"text": "In information retrieval, users are often interested in particular topics (parts) of retrieved documents, instead of the documents themselves.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 3, "end_pos": 24, "type": "TASK", "confidence": 0.746972382068634}]}, {"text": "To meet such needs, documents should be segmented into coherent topics.", "labels": [], "entities": []}, {"text": "Summarization is often used fora long document that includes multiple topics.", "labels": [], "entities": [{"text": "Summarization", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9140499234199524}]}, {"text": "A summary of such a document can be composed of summaries of the component topics.", "labels": [], "entities": []}, {"text": "Identification of topics is the task of text segmentation.", "labels": [], "entities": [{"text": "Identification of topics", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9143882791201273}, {"text": "text segmentation", "start_pos": 40, "end_pos": 57, "type": "TASK", "confidence": 0.7210326939821243}]}, {"text": "A lot of research has been done on text segmentation.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.8146816492080688}]}, {"text": "A major characteristic of the methods used in this research is that they do not require training data to segment given texts., for example, used only the similarity of word distributions in a given text to segment the text.", "labels": [], "entities": []}, {"text": "Consequently, these methods can be applied to any text in any domain, even if training data do not exist.", "labels": [], "entities": []}, {"text": "This property is important when text segmentation is applied to information retrieval or summarization, because both tasks deal with domain-independent documents.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.7152431756258011}, {"text": "information retrieval", "start_pos": 64, "end_pos": 85, "type": "TASK", "confidence": 0.7705737352371216}, {"text": "summarization", "start_pos": 89, "end_pos": 102, "type": "TASK", "confidence": 0.9264100790023804}]}, {"text": "Another application of text segmentation is the segmentation of a continuous broadcast news story into individual stories.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7269069254398346}, {"text": "segmentation of a continuous broadcast news story into individual stories", "start_pos": 48, "end_pos": 121, "type": "TASK", "confidence": 0.8160084545612335}]}, {"text": "In this application, systems relying on supervised learning () achieve good performance because there are plenty of training data in the domain.", "labels": [], "entities": []}, {"text": "These systems, however, cannot be applied to domains for which no training data exist.", "labels": [], "entities": []}, {"text": "The text segmentation algorithm described in this paper is intended to be applied to the summarization of documents or speeches.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7039632350206375}, {"text": "summarization of documents or speeches", "start_pos": 89, "end_pos": 127, "type": "TASK", "confidence": 0.909067964553833}]}, {"text": "Therefore, it should be able to handle domain-independent texts.", "labels": [], "entities": []}, {"text": "The algorithm thus does not use any training data.", "labels": [], "entities": []}, {"text": "It requires only the given documents for segmentation.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 41, "end_pos": 53, "type": "TASK", "confidence": 0.9780066013336182}]}, {"text": "It can, however, incorporate training data when they are available, as discussed in Section 5.", "labels": [], "entities": []}, {"text": "The algorithm selects the optimum segmentation in terms of the probability defined by a statistical model.", "labels": [], "entities": []}, {"text": "This is anew approach for domain-independent text segmentation.", "labels": [], "entities": [{"text": "domain-independent text segmentation", "start_pos": 26, "end_pos": 62, "type": "TASK", "confidence": 0.6210904022057852}]}, {"text": "Previous approaches usually used lexical cohesion to segment texts into topics., for example, used cohesion based on the spreading activation on a semantic network.", "labels": [], "entities": []}, {"text": "used the similarity of word distributions as measured by the cosine to gauge cohesion.", "labels": [], "entities": []}, {"text": "used word repetition as a measure of cohesion.", "labels": [], "entities": [{"text": "word repetition", "start_pos": 5, "end_pos": 20, "type": "TASK", "confidence": 0.7171773016452789}]}, {"text": "used the rank of the cosine, rather than the cosine itself, to measure the similarity of sentences.", "labels": [], "entities": []}, {"text": "The statistical model for the algorithm is described in Section 2, and the algorithm for obtaining the maximum-probability segmentation is described in Section 3.", "labels": [], "entities": []}, {"text": "Experimental results are presented in Section 4.", "labels": [], "entities": []}, {"text": "Further discussion and our conclusions are given in Sections 5 and 6, respectively.", "labels": [], "entities": []}], "datasetContent": [{"text": "The sample texts were preprocessed -i.e., punctuation and stop words were removed and the remaining words were stemmed -by a program using the libraries available in Choi's package.", "labels": [], "entities": []}, {"text": "The texts were then segmented by the systems listed in.", "labels": [], "entities": []}, {"text": "The segmentation boundaries were placed at the ends of sentences.", "labels": [], "entities": []}, {"text": "The segmentations were evaluated by applying an evaluation program in Choi's package.", "labels": [], "entities": [{"text": "segmentations", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.9648244976997375}, {"text": "Choi's package", "start_pos": 70, "end_pos": 84, "type": "DATASET", "confidence": 0.8609763383865356}]}, {"text": "The results are listed in 10% 10% 13% prob 7.9E-5 4.9E-3 2.5E-5 7.5E-8 9.7E-12 i s the probability that a randomly chosen pair of words a distance of \u00d6 w ords apart is inconsistently classified; that is, for one of the segmentations the pair lies in the same segment, while for the other the pair spans a segment boundary\"), where \u00d6 is chosen to behalf the average reference segment length (in words).", "labels": [], "entities": [{"text": "\u00d6", "start_pos": 331, "end_pos": 332, "type": "METRIC", "confidence": 0.9649496078491211}]}, {"text": "8 If two segmentations have the same cost, then our systems arbitrarily select one of them; i.e., the systems select the segmentation processed previously.", "labels": [], "entities": []}, {"text": "The results for are slightly different from those listed in of Choi's paper.", "labels": [], "entities": []}, {"text": "This is because the original results in that paper were based on 500 samples, while the results in our were based on 700 samples 2.7E-4 0.080 2.3E-3 1.0E-4 6.8E-9 . This means that our system is more accurate than or at least as accurate as previous domainindependent text segmentation systems, because & \u00ba \u00b4 \u00ba has been shown to be more accurate than previous domain-independent text segmentation systems.", "labels": [], "entities": [{"text": "domainindependent text segmentation", "start_pos": 250, "end_pos": 285, "type": "TASK", "confidence": 0.5884943008422852}, {"text": "\u00ba", "start_pos": 309, "end_pos": 310, "type": "METRIC", "confidence": 0.8238061666488647}, {"text": "domain-independent text segmentation", "start_pos": 360, "end_pos": 396, "type": "TASK", "confidence": 0.699960192044576}]}, {"text": "Evaluation of the output of text segmentation systems is difficult because the required segmentations depend on the application.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.7121216505765915}]}, {"text": "In this paper, we have used an artificial corpus to evaluate our system.", "labels": [], "entities": []}, {"text": "We regard this as appropriate for comparing relative performance among systems.", "labels": [], "entities": []}, {"text": "It is important, however, to assess the performance of systems by using real texts.", "labels": [], "entities": []}, {"text": "These texts should be domain independent.", "labels": [], "entities": []}, {"text": "They should also be multi-lingual if we want to test the mul-where ae X h \u0097 \u00e8 \u00eb h \u0097 \u00ea V \u00a1 \u00ae i . Equation favors segments whose lengths are similar to the average length (in words).", "labels": [], "entities": []}, {"text": "Another major difference from their algorithm is that our algorithm does not require training data to estimate probabilities, while their algorithm does.", "labels": [], "entities": []}, {"text": "Therefore, our algorithm can be applied to domain-independent texts, while their algorithm is restricted to domains for which training data are available.", "labels": [], "entities": []}, {"text": "It would be interesting, however, to compare our algorithm with their algorithm for the case when training data are available.", "labels": [], "entities": []}, {"text": "In such a case, our model should be extended to incorporate various features such as the average segment length, clue words, named entities, and so on).", "labels": [], "entities": []}, {"text": "Our proposed algorithm naturally estimates the probabilities of words in segments.", "labels": [], "entities": []}, {"text": "These probabilities, which are called word densities, have been used to detect important descriptions of words in texts ().", "labels": [], "entities": []}, {"text": "This method is based on the assumption that the density of a word is high in a segment in which the word is discussed (defined and/or explained) in some depth.", "labels": [], "entities": []}, {"text": "It would be interesting to apply our method to this application.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Test corpus statistics. (Choi, 2000)", "labels": [], "entities": []}]}