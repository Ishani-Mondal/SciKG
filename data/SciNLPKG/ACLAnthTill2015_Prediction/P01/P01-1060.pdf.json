{"title": [{"text": "Parse Forest Computation of Expected Governors", "labels": [], "entities": [{"text": "Parse Forest Computation", "start_pos": 0, "end_pos": 24, "type": "DATASET", "confidence": 0.8178032636642456}]}], "abstractContent": [{"text": "Ina headed tree, each terminal word can be uniquely labeled with a governing word and grammatical relation.", "labels": [], "entities": []}, {"text": "This labeling is a summary of a syntactic analysis which eliminates detail, reflects aspects of semantics, and for some grammatical relations (such as subject of finite verb) is nearly un-controversial.", "labels": [], "entities": []}, {"text": "We define a notion of expected governor markup, which sums vectors indexed by governors and scaled by probabilistic tree weights.", "labels": [], "entities": []}, {"text": "The quantity is computed in a parse forest representation of the set of tree analyses fora given sentence, using vector sums and scaling by inside probability and flow.", "labels": [], "entities": []}], "introductionContent": [{"text": "A labeled headed tree is one in which each nonterminal vertex has a distinguished head child, and in the usual way non-terminal nodes are labeled with non-terminal symbols (syntactic categories such as NP) and terminal vertices are labeled with terminal symbols (words such as reads).", "labels": [], "entities": []}, {"text": "We work with syntactic trees in which terminals are in addition labeled with uninflected word forms (lemmas) derived from the lexicon.", "labels": [], "entities": []}, {"text": "By percolating lemmas up the chains of heads, each node in a headed tree maybe labeled with a lexical head. is an example, where lexical heads are written as subscripts.", "labels": [], "entities": []}, {"text": "We use the notation position word governor label: Governor labels for the terminals in the tree of.", "labels": [], "entities": []}, {"text": "For the head of the sentence, special symbols startc and startw are used as the parent category and parent lexical governor. is the tuple . Governor labels for the example tree are given in.", "labels": [], "entities": []}, {"text": "As observed in, grammatical relations such as subject and object maybe reconstructed as ordered pairs of category labels, such as I NP,S P for subject.", "labels": [], "entities": []}, {"text": "So, a governor label encodes a grammatical relation and a governing lexical head.", "labels": [], "entities": []}, {"text": "Given a unique tree structure fora sentence, governor markup maybe read off the tree.", "labels": [], "entities": []}, {"text": "However, in view of the fact that robust broad coverage parsers frequently deliver thousands, millions, or thousands of millions of analyses for sentences of free text, basing annotation on a unique tree (such as the most probable tree analysis generated by a probabilistic grammar) appears arbitrary.", "labels": [], "entities": []}, {"text": "Note that different trees may produce the same governor labels fora given terminal position.", "labels": [], "entities": []}, {"text": "Suppose for instance that the yield of the tree in has a different tree analysis in which the PP is a child of the VP, rather than NP.", "labels": [], "entities": []}, {"text": "In this case, just as in the original tree, the label for the fourth terminal position (with word label paper) is I NP,VP,read P . Supposing that there are only two tree analyses, this label can be assigned to the fourth word with certainty, in the face of syntactic ambiguity.", "labels": [], "entities": []}, {"text": "The algorithm we will define pools governor labels in this way.", "labels": [], "entities": []}, {"text": "as computed with a head-lexicalized weighting of trees.", "labels": [], "entities": []}, {"text": "Values below 0.1 are omitted.", "labels": [], "entities": []}, {"text": "According to the lexicalized model, the PP headed by of probably attaches to VFP (finite verb phrase) rather than NP.", "labels": [], "entities": []}, {"text": "be the governor labels for word position respectively.", "labels": [], "entities": []}, {"text": "We define a scheme which divides a count of 1 among the different governor labels.", "labels": [], "entities": []}, {"text": "For a given governor tuple The definition sums the probabilistic weights of trees with markup v , and normalizes by the sum of the probabilities of all tree analyses of Y . The definition maybe justified as follows.", "labels": [], "entities": []}, {"text": "We work with a markup space is above the cutoff. is an example.", "labels": [], "entities": []}, {"text": "A direct implementation of the above definition using an iteration over trees to compute y would be unusable because in the robust grammar of English we work with, the number of tree analyses fora sentence is frequently large, greater than", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}