{"title": [], "abstractContent": [{"text": "The standard pipeline approach to semantic processing, in which sentences are morphologically and syntactically resolved to a singletree before they are interpreted, is a poor fit for applications such as natural language interfaces.", "labels": [], "entities": [{"text": "semantic processing", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.7863648235797882}]}, {"text": "This is because the environment information, in the form of the objects and events in the application's run-time environment, cannot be used to inform parsing decisions unless the input sentence is semantically analyzed, but this does not occur until after parsing in the single-tree semantic architecture.", "labels": [], "entities": []}, {"text": "This paper describes the computational properties of an alternative architecture , in which semantic analysis is performed on all possible interpretations during parsing, in polynomial time.", "labels": [], "entities": []}], "introductionContent": [{"text": "Shallow semantic processing applications, comparing argument structures to search patterns or filling in simple templates, can achieve respectable results using the standard 'pipeline' approach to semantics, in which sentences are morphologically and syntactically resolved to a singletree before being interpreted.", "labels": [], "entities": []}, {"text": "Putting disambiguation ahead of semantic evaluation is reasonable in these applications because they are primarily run on content like newspaper text or dictated speech, where no machine-readable contextual information is readily available to provide semantic guidance for disambiguation.", "labels": [], "entities": []}, {"text": "This single-tree semantic architecture is a poor fit for applications such as natural language interfaces however, in which a large amount of contextual information is available in the form of the objects and events in the application's run-time environment.", "labels": [], "entities": []}, {"text": "This is because the environment information cannot be used to inform parsing and disambiguation decisions unless the input sentence is semantically analyzed, but this does not occur until after parsing in the single-tree architecture.", "labels": [], "entities": [{"text": "parsing and disambiguation", "start_pos": 69, "end_pos": 95, "type": "TASK", "confidence": 0.7506386041641235}]}, {"text": "Assuming that no current statistical disambiguation technique is so accurate that it could not benefit from this kind of environment-based information (if available), then it is important that the semantic analysis in an interface architecture be efficiently performed during parsing.", "labels": [], "entities": []}, {"text": "This paper describes the computational properties of one such architecture, embedded within a system forgiving various kinds of conditional instructions and behavioral constraints to virtual human agents in a 3-D simulated environment ().", "labels": [], "entities": []}, {"text": "In one application of this system, users direct simulated maintenance personnel to repair a jet engine, in order to ensure that the maintenance procedures do not risk the safety of the people performing them.", "labels": [], "entities": []}, {"text": "Since it is expected to process abroad range of maintenance instructions, the parser is run on a large subset of the Xtag English grammar, which has been annotated with lexical semantic classes () associated with the objects, states, and processes in the maintenance simulation.", "labels": [], "entities": [{"text": "Xtag English grammar", "start_pos": 117, "end_pos": 137, "type": "DATASET", "confidence": 0.8308924237887064}]}, {"text": "Since the grammar has several thousand lexical entries, the parser is exposed to considerable lexical and structural ambiguity as a matter of course.", "labels": [], "entities": []}, {"text": "The environment-based disambiguation architecture described in this paper has much in common with very early environment-based approaches, such as those described by Winograd, in that it uses the actual entities in an environment database to resolve ambiguity in the input.", "labels": [], "entities": []}, {"text": "This research explores two extensions to the basic approach however: resent abroad range of linguistic phenomena in a manner for which their extensions or potential referents in the environment are welldefined in every case.", "labels": [], "entities": []}, {"text": "This is elaborated in Section 2. 2. It adapts the concept of structure sharing, taken from the study of parsing, not only to translate the many possible interpretations of ambiguous sentences into shared logical expressions, but also to evaluate these sets of potential referents, overall possible interpretations, in polynomial time.", "labels": [], "entities": []}, {"text": "This is elaborated in Section 3.", "labels": [], "entities": []}, {"text": "Taken together, these extensions allow interfaced systems to evaluate abroad range of natural language inputs -including those containing NP/VP attachment ambiguity and verb sense ambiguity -in a principled way, simply based on the objects and events in the systems' environments.", "labels": [], "entities": []}, {"text": "For example, such a system would be able to correctly answer 'Did someone stop the test at 3:00?' and resolve the ambiguity in the attachment of 'at 3:00' just from the fact that there aren't any 3:00 tests in the environment, only an event where one stops at 3:00. 1 Because it evaluates instructions before attempting to choose a single interpretation, the interpreter can avoid getting 'stranded' by disambiguation errors in earlier phases of analysis.", "labels": [], "entities": []}, {"text": "The main challenge of this approach is that it requires the efficient calculation of the set of objects, states, or processes in the environment that each possible sub-derivation of an input sentence could refer to.", "labels": [], "entities": []}, {"text": "A semantic interpreter could always be run on an (exponential) enumerated set of possible parse trees as a post-process, to filter out those interpretations which have no environment referents, but recomputing the potential environment referents for every tree would require an enormous amount of time (particularly for broad coverage grammars such as the one employed here).", "labels": [], "entities": []}, {"text": "The primary result of this paper is therefore a method of containing the time complexity of these calculations to lie within the complexity of parsing (i.e. within fora contextfree grammar, where \u00a3 is the number of words in the input sentence), without sacrificing logical correctness, in order to make environmentbased interpretation tractable for interactive applications.", "labels": [], "entities": []}], "datasetContent": [{"text": "An implemented system incorporating this environment-based approach to disambiguation has been tested on a set of manufacturersupplied aircraft maintenance instructions, using a computer-aided design (CAD) model of a portion of the aircraft as the environment.", "labels": [], "entities": []}, {"text": "It contains several hundred three dimensional objects (buttons, handles, sliding couplings, etc), labeled with object type keywords and connected to other objects through joints with varying degrees of freedom (indicating how each object can be rotated and translated with respect to other objects in the environment).", "labels": [], "entities": []}, {"text": "The test sentences were the manufacturer's in-structions for replacing apiece of equipment in this environment.", "labels": [], "entities": []}, {"text": "The baseline grammar was not altered to fit the test sentences or the environment, but the labeled objects in the CAD model were automatically added to the lexicon as common nouns.", "labels": [], "entities": []}, {"text": "In this preliminary accuracy test, forest nodes that correspond to noun phrase or modifier categories are dispreferred if they have no potential entity referents, and forest nodes corresponding to other categories are dispreferred if their arguments have no potential entity referents.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9954397082328796}]}, {"text": "Many of the nodes in the forest correspond to nounnoun modifications, which cannot be ruled out by the grammar because the composition operation that generates them seems to be productive (virtually any 'N2' that is attached to or contained in an 'N1' can bean 'N1 N2').", "labels": [], "entities": []}, {"text": "Potential referents for noun-noun modifications are calculated by a rudimentary spatial proximity threshold, such that any potential referent of the modified noun lying within the threshold distance of a potential referent of the modifier noun in the environment is added to the composed set.", "labels": [], "entities": []}, {"text": "The results are shown below.", "labels": [], "entities": []}, {"text": "The average number of parse trees per sentence in this set was\u00a8before was\u00a8 was\u00a8before disambiguation.", "labels": [], "entities": []}, {"text": "The average ratio of nodes in enumerated tree sets to nodes in shared forests for the instructions in this test set was \u00a1 \u00a2 \u00a4 \u00a3 , a nearly tenfold reduction due to sharing.", "labels": [], "entities": []}, {"text": "Gold standard 'correct' trees were annotated by hand using the same grammar that the parser uses.", "labels": [], "entities": []}, {"text": "The success rate of the parser in this domain (the rate at which the correct tree could be found in the parse forest) was . The retention rate of the environment-based filtering mechanism described above (the rate at which the correct tree was retained in parse forest) was \u00a1 \u00a8 \u00a7 \u00a8 of successfully parsed sentences.", "labels": [], "entities": [{"text": "retention", "start_pos": 128, "end_pos": 137, "type": "METRIC", "confidence": 0.966661274433136}]}, {"text": "The average reduction in number of possible parse trees due to the environment-based filtering mechanism described above was \u00a2 \u00a3 for successfully parsed and filtered forests.", "labels": [], "entities": []}], "tableCaptions": []}