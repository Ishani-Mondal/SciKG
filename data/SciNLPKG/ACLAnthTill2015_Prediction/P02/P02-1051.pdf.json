{"title": [{"text": "Translating Named Entities Using Monolingual and Bilingual Resources", "labels": [], "entities": [{"text": "Translating Named Entities", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.85785045226415}]}], "abstractContent": [{"text": "Named entity phrases are some of the most difficult phrases to translate because new phrases can appear from nowhere, and because many are domain specific, not to be found in bilingual dictionaries.", "labels": [], "entities": []}, {"text": "We present a novel algorithm for translating named entity phrases using easily obtainable monolingual and bilingual resources.", "labels": [], "entities": [{"text": "translating named entity phrases", "start_pos": 33, "end_pos": 65, "type": "TASK", "confidence": 0.890028789639473}]}, {"text": "We report on the application and evaluation of this algorithm in translating Arabic named entities to English.", "labels": [], "entities": [{"text": "translating Arabic named entities to English", "start_pos": 65, "end_pos": 109, "type": "TASK", "confidence": 0.8896835048993429}]}, {"text": "We also compare our results with the results obtained from human translations and a commercial system for the same task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Named entity phrases are being introduced in news stories on a daily basis in the form of personal names, organizations, locations, temporal phrases, and monetary expressions.", "labels": [], "entities": []}, {"text": "While the identification of named entities in text has received significant attention (e.g., and), translation of named entities has not.", "labels": [], "entities": [{"text": "identification of named entities in text", "start_pos": 10, "end_pos": 50, "type": "TASK", "confidence": 0.8511906266212463}, {"text": "translation of named entities", "start_pos": 99, "end_pos": 128, "type": "TASK", "confidence": 0.897591307759285}]}, {"text": "This translation problem is especially challenging because new phrases can appear from nowhere, and because many named-entities are domain specific, not to be found in bilingual dictionaries.", "labels": [], "entities": []}, {"text": "A system that specializes in translating named entities such as the one we describe here would bean important tool for many NLP applications.", "labels": [], "entities": [{"text": "translating named entities", "start_pos": 29, "end_pos": 55, "type": "TASK", "confidence": 0.8975770672162374}]}, {"text": "Statistical machine translation systems can use such a system as a component to handle phrase translation in order to improve overall translation quality.", "labels": [], "entities": [{"text": "Statistical machine translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6236439744631449}, {"text": "phrase translation", "start_pos": 87, "end_pos": 105, "type": "TASK", "confidence": 0.7614710330963135}]}, {"text": "CrossLingual Information Retrieval (CLIR) systems could identify relevant documents based on translations of named entity phrases provided by such a system.", "labels": [], "entities": [{"text": "CrossLingual Information Retrieval (CLIR)", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.7386535505453745}]}, {"text": "Question Answering (QA) systems could benefit substantially from such a tool since the answer to many factoid questions involve named entities (e.g., answers to who questions usually involve Persons/Organizations, where questions involve Locations, and when questions involve Temporal.", "labels": [], "entities": [{"text": "Question Answering (QA)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8587433457374573}]}, {"text": "In this paper, we describe a system for ArabicEnglish named entity translation, though the technique is applicable to any language pair and does not require especially difficult-to-obtain resources.", "labels": [], "entities": [{"text": "ArabicEnglish named entity translation", "start_pos": 40, "end_pos": 78, "type": "TASK", "confidence": 0.5431756749749184}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we give an overview of our approach.", "labels": [], "entities": []}, {"text": "In Section 3, we describe how translation candidates are generated.", "labels": [], "entities": []}, {"text": "In Section 4, we show how monolingual clues are used to help re-rank the translation candidates list.", "labels": [], "entities": []}, {"text": "In Section 5, we describe how the candidates list can be extended using contextual information.", "labels": [], "entities": []}, {"text": "We conclude this paper with the evaluation results of our translation algorithm on a test set.", "labels": [], "entities": []}, {"text": "We also compare our system with human translators and a commercial system.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate human performance at this task, we compared the translations by the original human translators with the correct translations on the goldstandard.", "labels": [], "entities": []}, {"text": "The errors made by the original human translators turned out to be numerous, ranging from simple spelling errors (e.g., Custa Rica vs. Costa Rica) to more serious errors such as transliteration errors (e.g., John Keele vs. Jon Kyl) and other translation errors (e.g., Union Reserve Council vs. Federal Reserve Board).", "labels": [], "entities": [{"text": "Union Reserve Council vs. Federal Reserve Board", "start_pos": 268, "end_pos": 315, "type": "DATASET", "confidence": 0.9094085012163434}]}, {"text": "The Arabic documents were also translated using a commercial Arabic-to-English translation system.", "labels": [], "entities": []}, {"text": "The translation of the named entity phrases are then manually extracted from the translated text.", "labels": [], "entities": []}, {"text": "When compared with the gold-standard, nearly half of the phrases in the development test set and more than a third of the blind test were translated incorrectly by the commercial system.", "labels": [], "entities": []}, {"text": "The errors can be classified into several categories including: poor transliterations (e.g., Koln Baol vs. Colin Powell), translating a name instead of sounding it out (e.g., O'Neill's urine vs. Paul O'Neill), wrong translation (e.g., Joint Corners Organization vs. Joint Chiefs of Staff) or wrong word order (e.g.,the Church of the Orthodox Roman).", "labels": [], "entities": [{"text": "translating a name", "start_pos": 122, "end_pos": 140, "type": "TASK", "confidence": 0.8896196484565735}]}, {"text": "shows a detailed comparison of the translation accuracy between our system, the commercial system, and the human translators.", "labels": [], "entities": [{"text": "translation", "start_pos": 35, "end_pos": 46, "type": "TASK", "confidence": 0.9622634053230286}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.92910236120224}]}, {"text": "The translations obtained by our system show significant improvement over the commercial system.", "labels": [], "entities": []}, {"text": "In fact, in some cases it outperforms the human translator.", "labels": [], "entities": []}, {"text": "When we consider the top-20 translations, our system's overall accuracy (84%) is higher than the human's (75.3%) on the blind test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9996150732040405}]}, {"text": "This means that there is a lot of room for improvement once we consider more effective re-scoring methods.", "labels": [], "entities": []}, {"text": "Also, the top-20 list in itself is often useful in providing phrasal translation candidates for general purpose statistical machine translation systems or other NLP systems.", "labels": [], "entities": [{"text": "phrasal translation", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.7012172341346741}, {"text": "general purpose statistical machine translation", "start_pos": 96, "end_pos": 143, "type": "TASK", "confidence": 0.5423582315444946}]}, {"text": "The strength of our translation system is in translating person names, which indicates the strength of our transliteration module.", "labels": [], "entities": [{"text": "translating person names", "start_pos": 45, "end_pos": 69, "type": "TASK", "confidence": 0.8527673880259196}]}, {"text": "This might also be attributed to the low named entity coverage of our bilingual dictionary.", "labels": [], "entities": []}, {"text": "In some cases, some words that need to be translated (as opposed to transliterated) are not found in our bilingual dictionary which may lead to incorrect location or organization translations but does not affect person names.", "labels": [], "entities": []}, {"text": "The reason word translations are sometimes not found in the dictionary is not necessarily because of the spotty coverage of the dictionary but because of the way we access definitions in the dictionary.", "labels": [], "entities": [{"text": "word translations", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.7423222959041595}]}, {"text": "Only shallow morphological analysis (e.g., removing prefixes and suffixes) is done before accessing the dictionary, whereas a full morphological analysis is necessary, especially for morphologically rich languages such as Arabic.", "labels": [], "entities": []}, {"text": "Another reason for doing poorly on organizations is that acronyms and abbreviations in the Arabic text (e.g., \" \u00a8 C w\u00af as,\" the Saudi Press Agency) are currently not handled by our system.", "labels": [], "entities": [{"text": "Saudi Press Agency", "start_pos": 128, "end_pos": 146, "type": "DATASET", "confidence": 0.8250068227450053}]}, {"text": "The blind test set was selected from the FBIS 2001 Multilingual Corpus.", "labels": [], "entities": [{"text": "FBIS 2001 Multilingual Corpus", "start_pos": 41, "end_pos": 70, "type": "DATASET", "confidence": 0.9435399919748306}]}, {"text": "The FBIS data is collected by the Foreign Broadcast Information Service for the benefit of the US government.", "labels": [], "entities": [{"text": "FBIS data", "start_pos": 4, "end_pos": 13, "type": "DATASET", "confidence": 0.753778874874115}, {"text": "Foreign Broadcast Information Service", "start_pos": 34, "end_pos": 71, "type": "DATASET", "confidence": 0.8888691961765289}]}, {"text": "We suspect that the human translators who translated the documents into English are somewhat familiar with the genre of the articles and hence the named entities: A comparison of translation accuracy for the human translator, commercial system, and our system on the development and blind test sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 191, "end_pos": 199, "type": "METRIC", "confidence": 0.9829565286636353}]}, {"text": "Only a match with the translation in the gold-standard is considered a correct translation.", "labels": [], "entities": []}, {"text": "The human translator results are obtained by comparing the translations provided by the original human translator with the translations in the gold-standard.", "labels": [], "entities": []}, {"text": "The Sakhr results are for the Web version of Sakhr's commercial system.", "labels": [], "entities": [{"text": "Web version of Sakhr's commercial system", "start_pos": 30, "end_pos": 70, "type": "DATASET", "confidence": 0.7100158078329903}]}, {"text": "The Top-1 results of our system considers whether the correct answer is the top candidate or not, while the Top-20 results considers whether the correct answer is among the top-20 candidates.", "labels": [], "entities": []}, {"text": "Overall is a weighted average of the three named entity categories.", "labels": [], "entities": []}, {"text": "Web counts within a given context (we used here title of the document as the contextual information).", "labels": [], "entities": []}, {"text": "In Co-reference, if the phrase to be translated is part of a longer phrase then we use the the ranking of the candidates for the longer phrase to re-rank the candidates of the short one, otherwise we leave the list as is.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The distribution of named entities in the  test sets into the categories PERSON, ORGANI- ZATION , and LOCATION. The numbers shown  are the ratio of each category to the total.", "labels": [], "entities": [{"text": "PERSON", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9935088157653809}, {"text": "ORGANI- ZATION", "start_pos": 91, "end_pos": 105, "type": "METRIC", "confidence": 0.9450550675392151}, {"text": "LOCATION", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.980804979801178}]}, {"text": " Table 2: A comparison of translation accuracy for the human translator, commercial system, and our system  on the development and blind test sets. Only a match with the translation in the gold-standard is considered  a correct translation. The human translator results are obtained by comparing the translations provided  by the original human translator with the translations in the gold-standard. The Sakhr results are for the  Web version of Sakhr's commercial system. The Top-1 results of our system considers whether the correct  answer is the top candidate or not, while the Top-20 results considers whether the correct answer is among  the top-20 candidates. Overall is a weighted average of the three named entity categories.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9546969532966614}]}, {"text": " Table 3: This table shows the accuracy after each translation module. The modules are applied incremen- tally. Straight Web Counts re-score candidates based on their Web counts. Contextual Web Counts uses", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9994339346885681}]}]}