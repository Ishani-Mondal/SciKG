{"title": [{"text": "Word Translation Disambiguation Using Bilingual Bootstrapping", "labels": [], "entities": [{"text": "Word Translation Disambiguation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8440955678621928}]}], "abstractContent": [{"text": "This paper proposes anew method for word translation disambiguation using a machine learning technique called 'Bilingual Bootstrapping'.", "labels": [], "entities": [{"text": "word translation disambiguation", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.863402783870697}]}, {"text": "Bilingual Bootstrapping makes use of \ud97b\udf59 in learning\ud97b\udf59 a small number of classified data and a large number of unclassified data in the source and the target languages in translation.", "labels": [], "entities": []}, {"text": "It constructs classifiers in the two languages in parallel and repeatedly boosts the performances of the classifiers by further classifying data in each of the two languages and by exchanging between the two languages information regarding the classified data.", "labels": [], "entities": []}, {"text": "Experimental results indicate that word translation disambiguation based on Bilingual Bootstrapping consistently and significantly outperforms the existing methods based on 'Monolingual Bootstrapping'.", "labels": [], "entities": [{"text": "word translation", "start_pos": 35, "end_pos": 51, "type": "TASK", "confidence": 0.7916590571403503}]}], "introductionContent": [{"text": "We address here the problem of word translation disambiguation.", "labels": [], "entities": [{"text": "word translation disambiguation", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.8555110891660055}]}, {"text": "For instance, we are concerned with an ambiguous word in English (e.g., 'plant'), which has multiple translations in Chinese (e.g., '\ud97b\udf59\ud97b\udf59 (gongchang)' and '\ud97b\udf59\ud97b\udf59 (zhiwu)').", "labels": [], "entities": []}, {"text": "Our goal is to determine the correct Chinese translation of the ambiguous English word, given an English sentence which contains the word.", "labels": [], "entities": [{"text": "Chinese translation of the ambiguous English word", "start_pos": 37, "end_pos": 86, "type": "TASK", "confidence": 0.7823058579649244}]}, {"text": "Word translation disambiguation is actually a special case of word sense disambiguation (in the example above, 'gongchang' corresponds to the sense of 'factory' and 'zhiwu' corresponds to the sense of 'vegetation').", "labels": [], "entities": [{"text": "Word translation disambiguation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8390606840451559}, {"text": "word sense disambiguation", "start_pos": 62, "end_pos": 87, "type": "TASK", "confidence": 0.619485487540563}]}, {"text": "1 proposes a method for word sense (translation) disambiguation that is based on a bootstrapping technique, which we refer to here as 'Monolingual Bootstrapping (MB)'.", "labels": [], "entities": [{"text": "word sense (translation) disambiguation", "start_pos": 24, "end_pos": 63, "type": "TASK", "confidence": 0.8164560248454412}]}, {"text": "In this paper, we propose anew method for word translation disambiguation using a bootstrapping technique we have developed.", "labels": [], "entities": [{"text": "word translation disambiguation", "start_pos": 42, "end_pos": 73, "type": "TASK", "confidence": 0.8621289134025574}]}, {"text": "We refer to the technique as 'Bilingual Bootstrapping (BB)'.", "labels": [], "entities": [{"text": "Bilingual Bootstrapping (BB)'", "start_pos": 30, "end_pos": 59, "type": "TASK", "confidence": 0.4940794944763184}]}, {"text": "In order to evaluate the performance of BB, we conducted some experiments on word translation disambiguation using the BB technique and the MB technique.", "labels": [], "entities": [{"text": "word translation disambiguation", "start_pos": 77, "end_pos": 108, "type": "TASK", "confidence": 0.8599710861841837}]}, {"text": "All of the results indicate that BB consistently and significantly outperforms MB.", "labels": [], "entities": [{"text": "BB", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9986881613731384}, {"text": "MB", "start_pos": 79, "end_pos": 81, "type": "METRIC", "confidence": 0.99540114402771}]}], "datasetContent": [{"text": "We first applied BB, MB-B, and MB-D to translation of the English words 'line' and 'interest' using a benchmark data 2 . The data mainly consists of articles in the Wall Street Journal and it is designed for conducting Word We adopted from the HIT dictionary 3 the Chinese translations of the two English words, as listed in.", "labels": [], "entities": [{"text": "BB", "start_pos": 17, "end_pos": 19, "type": "METRIC", "confidence": 0.9965750575065613}, {"text": "Wall Street Journal", "start_pos": 165, "end_pos": 184, "type": "DATASET", "confidence": 0.9615779320398966}, {"text": "HIT dictionary", "start_pos": 244, "end_pos": 258, "type": "DATASET", "confidence": 0.9459463953971863}]}, {"text": "One sense of the words corresponds to one group of translations.", "labels": [], "entities": []}, {"text": "We then used the benchmark data as our test data.", "labels": [], "entities": []}, {"text": "(For the word 'interest', we only used its four major senses, because the remaining two minor senses occur in only 3.3% of the data) The dictionary is created by Harbin Institute of Technology.", "labels": [], "entities": [{"text": "Harbin Institute of Technology", "start_pos": 162, "end_pos": 192, "type": "DATASET", "confidence": 0.9394104331731796}]}, {"text": "As classified data in English, we defined a 'seed word' for each group of translations based on our intuition (cf.,).", "labels": [], "entities": []}, {"text": "Each of the seed words was then used as a classified 'sentence'.", "labels": [], "entities": []}, {"text": "This way of creating classified data is similar to that in.", "labels": [], "entities": []}, {"text": "As unclassified data in English, we collected sentences in news articles from a website (www.news.com), and as unclassified data in Chinese, we collected sentences in news articles from another website (news.cn.tom.com).", "labels": [], "entities": []}, {"text": "We observed that the distribution of translations in the unclassified data was balanced.", "labels": [], "entities": []}, {"text": "shows the sizes of the data.", "labels": [], "entities": []}, {"text": "Note that there are in general more unclassified sentences in Chinese than in English because an English word usually has several Chinese words as translations (cf.,).", "labels": [], "entities": []}, {"text": "As a translation dictionary, we used the HIT dictionary, which contains about 76000 Chinese words, 60000 English words, and 118000 links.", "labels": [], "entities": [{"text": "HIT dictionary", "start_pos": 41, "end_pos": 55, "type": "DATASET", "confidence": 0.9601037204265594}]}, {"text": "We then used the data to conduct translation disambiguation with BB, MB-B, and MB-D, as described in Section 5.", "labels": [], "entities": [{"text": "translation disambiguation", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.9663674235343933}, {"text": "BB", "start_pos": 65, "end_pos": 67, "type": "METRIC", "confidence": 0.8605003356933594}]}, {"text": "For both BB and MB-B, we used an ensemble of five Na\u00efve Bayesian Classifiers with the window sizes being \u00b11, \u00b13, \u00b15, \u00b17, \u00b19 words.", "labels": [], "entities": []}, {"text": "For both BB and MB-B, we set the parameters of \u03b2, b, and \u03b8 to 0.2, 15, and 1.5 respectively.", "labels": [], "entities": []}, {"text": "The parameters were tuned based on our preliminary experimental results on MB-B, they were not tuned, however, for BB.", "labels": [], "entities": [{"text": "BB", "start_pos": 115, "end_pos": 117, "type": "METRIC", "confidence": 0.991858184337616}]}, {"text": "For the BB specific parameter \u03b1, we set it to 0.4, which meant that we treated the information from English and that from Chinese equally.", "labels": [], "entities": [{"text": "BB specific parameter \u03b1", "start_pos": 8, "end_pos": 31, "type": "METRIC", "confidence": 0.5667720139026642}]}, {"text": "shows the translation disambiguation accuracies of the three methods as well as that of a baseline method in which we always choose the major translation.", "labels": [], "entities": []}, {"text": "show the learning curves of MB-D, MB-B, and BB.", "labels": [], "entities": [{"text": "BB", "start_pos": 44, "end_pos": 46, "type": "METRIC", "confidence": 0.9883397817611694}]}, {"text": "shows the accuracies of BB with different \u03b1 values.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9847493767738342}, {"text": "BB", "start_pos": 24, "end_pos": 26, "type": "METRIC", "confidence": 0.9713667035102844}]}, {"text": "From the results, we see that BB consistently and significantly outperforms both MB-D and MB-B.", "labels": [], "entities": [{"text": "BB", "start_pos": 30, "end_pos": 32, "type": "METRIC", "confidence": 0.9967541098594666}]}, {"text": "The results from the sign test are statistically significant (p-value < 0.001).", "labels": [], "entities": []}, {"text": "shows the results achieved by some existing supervised learning methods with respect to the benchmark data (cf.,.", "labels": [], "entities": []}, {"text": "Although BB is a method nearly equivalent to one based on unsupervised learning, it still performs favorably well when compared with the supervised methods (note that since the experimental settings are different, the results cannot be directly compared).", "labels": [], "entities": [{"text": "BB", "start_pos": 9, "end_pos": 11, "type": "METRIC", "confidence": 0.8502677083015442}]}, {"text": "We also conducted translation on seven of the twelve English words studied in. shows the list of the words.", "labels": [], "entities": [{"text": "translation", "start_pos": 18, "end_pos": 29, "type": "TASK", "confidence": 0.9814109206199646}]}, {"text": "For each of the words, we extracted about 200 sentences containing the word from the Encarta 4 English corpus and labeled those sentences with Chinese translations ourselves.", "labels": [], "entities": [{"text": "Encarta 4 English corpus", "start_pos": 85, "end_pos": 109, "type": "DATASET", "confidence": 0.8904706537723541}]}, {"text": "We used the labeled sentences as test data and the remaining sentences as unclassified data in English.", "labels": [], "entities": []}, {"text": "We also used the sentences in the Great Encyclopedia Chinese corpus as unclassified data in Chinese.", "labels": [], "entities": [{"text": "Great Encyclopedia Chinese corpus", "start_pos": 34, "end_pos": 67, "type": "DATASET", "confidence": 0.9220814853906631}]}, {"text": "We defined, for each translation, http://encarta.msn.com/default.asp 5 http://www.whlib.ac.cn/sjk/bkqs.htm a seed word in English as a classified example (cf.,).", "labels": [], "entities": []}, {"text": "We did not, however, conduct translation disambiguation on the words 'crane', 'sake', 'poach', 'axes', and 'motion', because the first four words do not frequently occur in the Encarta corpus, and the accuracy of choosing the major translation for the last word has already exceeded 98%.", "labels": [], "entities": [{"text": "translation disambiguation", "start_pos": 29, "end_pos": 55, "type": "TASK", "confidence": 0.9697123765945435}, {"text": "Encarta corpus", "start_pos": 177, "end_pos": 191, "type": "DATASET", "confidence": 0.9370568096637726}, {"text": "accuracy", "start_pos": 201, "end_pos": 209, "type": "METRIC", "confidence": 0.9994993209838867}]}, {"text": "We next applied BB, MB-B, and MB-D to word translation disambiguation.", "labels": [], "entities": [{"text": "BB", "start_pos": 16, "end_pos": 18, "type": "METRIC", "confidence": 0.9960876703262329}, {"text": "word translation disambiguation", "start_pos": 38, "end_pos": 69, "type": "TASK", "confidence": 0.8689165512720743}]}, {"text": "The experiment settings were the same as those in Experiment 1.", "labels": [], "entities": []}, {"text": "From, we see again that BB significantly outperforms MB-D and MB-B.", "labels": [], "entities": [{"text": "BB", "start_pos": 24, "end_pos": 26, "type": "METRIC", "confidence": 0.9928721785545349}]}, {"text": "(We will describe the results in detail in the full version of this paper.)", "labels": [], "entities": []}, {"text": "Note that the results of MB-D here cannot be directly compared with those in, mainly because the data used are different.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Data sizes in Experiment 1  Unclassified sentences  Words  English  Chinese", "labels": [], "entities": []}, {"text": " Table 3: Accuracies in Experiment 1", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9976550340652466}]}, {"text": " Table 4: Accuracies of supervised methods  interest (%)  line (%)  Ensembles of NBC  89  88  Na\u00efve Bayes  74  72  Decision Tree  78  - Neural Network  - 76  Nearest Neighbor  87  -", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9822269678115845}, {"text": "NBC", "start_pos": 81, "end_pos": 84, "type": "DATASET", "confidence": 0.9407199621200562}]}, {"text": " Table 5: Data descriptions and data sizes in Experiment 2  Unclassified sentences  Words  Chinese translations  English  Chinese  Seed words  Test  sentences  bass", "labels": [], "entities": []}, {"text": " Table 6: Accuracies in Experiment 2", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9967222809791565}]}, {"text": " Table 7: Top words for '\ud97b\udf59\ud97b\udf59", "labels": [], "entities": []}]}