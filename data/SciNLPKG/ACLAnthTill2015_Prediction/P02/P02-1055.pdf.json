{"title": [{"text": "Shallow parsing on the basis of words only: A case study", "labels": [], "entities": [{"text": "Shallow parsing", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.5957715213298798}]}], "abstractContent": [{"text": "We describe a case study in which a memory-based learning algorithm is trained to simultaneously chunk sentences and assign grammatical function tags to these chunks.", "labels": [], "entities": []}, {"text": "We compare the algo-rithm's performance on this parsing task with varying training set sizes (yielding learning curves) and different input representations.", "labels": [], "entities": [{"text": "parsing task", "start_pos": 48, "end_pos": 60, "type": "TASK", "confidence": 0.8899984955787659}]}, {"text": "In particular we compare input consisting of words only, a variant that includes word form information for low-frequency words, gold-standard POS only, and combinations of these.", "labels": [], "entities": []}, {"text": "The word-based shallow parser displays an apparently log-linear increase in performance, and surpasses the flatter POS-based curve at about 50,000 sentences of training data.", "labels": [], "entities": [{"text": "word-based shallow parser", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.5984713931878408}]}, {"text": "The low-frequency variant performs even better, and the combinations is best.", "labels": [], "entities": []}, {"text": "Comparative experiments with areal POS tag-ger produce lower results.", "labels": [], "entities": []}, {"text": "We argue that we might not need an explicit intermediate POS-tagging step for parsing when a sufficient amount of training material is available and word form information is used for low-frequency words.", "labels": [], "entities": [{"text": "parsing", "start_pos": 78, "end_pos": 85, "type": "TASK", "confidence": 0.9777737855911255}]}], "introductionContent": [{"text": "It is common in parsing to assign part-of-speech (POS) tags to words as a first analysis step providing information for further steps.", "labels": [], "entities": [{"text": "parsing", "start_pos": 16, "end_pos": 23, "type": "TASK", "confidence": 0.9701794385910034}]}, {"text": "In many early parsers, the POS sequences formed the only input to the parser, i.e. the actual words were not used except in POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 124, "end_pos": 135, "type": "TASK", "confidence": 0.735266923904419}]}, {"text": "Later, with feature-based grammars, information on POS had a more central place in the lexical entry of a word than the identity of the word itself, e.g. MAJOR and other HEAD features in.", "labels": [], "entities": []}, {"text": "In the early days of statistical parsers, POS were explicitly and often exclusively used as symbols to base probabilities on; these probabilities are generally more reliable than lexical probabilities, due to the inherent sparseness of words.", "labels": [], "entities": []}, {"text": "In modern lexicalized parsers, POS tagging is often interleaved with parsing proper instead of being a separate preprocessing module.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 31, "end_pos": 42, "type": "TASK", "confidence": 0.7846026420593262}]}, {"text": "notes that having his generative parser generate the POS of a constituent's head before the head itself increases performance by 2 points.", "labels": [], "entities": [{"text": "generative parser", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.92428058385849}, {"text": "POS", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.8925739526748657}]}, {"text": "He suggests that this is due to the usefulness of POS for estimating back-off probabilities.", "labels": [], "entities": []}, {"text": "chunking parser consists of two modules: a chunker and an attacher.", "labels": [], "entities": []}, {"text": "The chunker divides the sentence into labeled, non-overlapping sequences (chunks) of words, with each chunk containing ahead and (nearly) all of its premodifiers, exluding arguments and postmodifiers.", "labels": [], "entities": []}, {"text": "His chunker works on the basis of POS information alone, whereas the second module, the attacher, also uses lexical information.", "labels": [], "entities": []}, {"text": "Chunks as a separate level have also been used in and.", "labels": [], "entities": []}, {"text": "This brief overview shows that the main reason for the use of POS tags in parsing is that they provide useful generalizations and (thereby) counteract the sparse data problem.", "labels": [], "entities": [{"text": "parsing", "start_pos": 74, "end_pos": 81, "type": "TASK", "confidence": 0.9174286723136902}]}, {"text": "However, there are two objections to this reasoning.", "labels": [], "entities": []}, {"text": "First, as naturally occurring text does not come POS-tagged, we first need a module to assign POS.", "labels": [], "entities": []}, {"text": "This tagger can base its decisions only on the information present in the sentence, i.e. on the words themselves.", "labels": [], "entities": []}, {"text": "The question then arises whether we could use this information directly, and thus save the explicit tagging step.", "labels": [], "entities": []}, {"text": "The second objection is that sparseness of data is tightly coupled to the amount of training material used.", "labels": [], "entities": []}, {"text": "As training material is more abundant now than it was even a few years ago, and today's computers can handle these amounts, we might ask whether there is now enough data to overcome the sparseness problem for certain tasks.", "labels": [], "entities": []}, {"text": "To answer these two questions, we designed the following experiments.", "labels": [], "entities": []}, {"text": "The task to be learned is a shallow parsing task (described below).", "labels": [], "entities": []}, {"text": "In one experiment, it has to be performed on the basis of the \"gold-standard\", assumed-perfect POS taken directly from the training data, the Penn Treebank (, so as to abstract from a particular POS tagger and to provide an upper bound.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 142, "end_pos": 155, "type": "DATASET", "confidence": 0.9933277368545532}]}, {"text": "In another experiment, parsing is done on the basis of the words alone.", "labels": [], "entities": [{"text": "parsing", "start_pos": 23, "end_pos": 30, "type": "TASK", "confidence": 0.9818204045295715}]}, {"text": "Ina third, a special encoding of low-frequency words is used.", "labels": [], "entities": []}, {"text": "Finally, words and POS are combined.", "labels": [], "entities": [{"text": "POS", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.698150098323822}]}, {"text": "In all experiments, we increase the amount of training data stepwise and record parse performance for each step.", "labels": [], "entities": []}, {"text": "This yields four learning curves.", "labels": [], "entities": []}, {"text": "The word-based shallow parser displays an apparently log-linear increase in performance, and surpasses the flatter POS-based curve at about 50,000 sentences of training data.", "labels": [], "entities": [{"text": "word-based shallow parser", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.5984716912110647}]}, {"text": "The lowfrequency variant performs even better, and the combinations is best.", "labels": [], "entities": []}, {"text": "Comparative experiments with areal POS tagger produce lower results.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 35, "end_pos": 45, "type": "TASK", "confidence": 0.7582782506942749}]}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we describe the parsing task, its input representation, how this data was extracted from the Penn Treebank, and how we setup the learning curve experiments using a memory-based learner.", "labels": [], "entities": [{"text": "parsing task", "start_pos": 29, "end_pos": 41, "type": "TASK", "confidence": 0.9070934057235718}, {"text": "Penn Treebank", "start_pos": 106, "end_pos": 119, "type": "DATASET", "confidence": 0.9962246716022491}]}, {"text": "Section 3 provides the experimental learning curve results and analyses them.", "labels": [], "entities": []}, {"text": "Section 4 contains a comparison of the effects with gold-standard and automatically assigned POS.", "labels": [], "entities": [{"text": "POS", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.8217051029205322}]}, {"text": "We review related research in Section 5, and formulate our conclusions in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We chose a shallow parsing task as our benchmark task.", "labels": [], "entities": []}, {"text": "If, to support an application such as information extraction, summarization, or question answering, we are only interested in parts of the parse tree, then a shallow parser forms a viable alternative to a full parser.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.8347811102867126}, {"text": "summarization", "start_pos": 62, "end_pos": 75, "type": "TASK", "confidence": 0.9681149125099182}, {"text": "question answering", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.7971222400665283}]}, {"text": "show that for the chunking task it is specialized in, their shallow parser is more accurate and more robust than a general-purpose, i.e. full, parser.", "labels": [], "entities": [{"text": "chunking task", "start_pos": 18, "end_pos": 31, "type": "TASK", "confidence": 0.9153812527656555}]}, {"text": "Our shallow parsing task is a combination of chunking (finding and labelling non-overlapping syntactically functional sequences) and what we will call function tagging.", "labels": [], "entities": [{"text": "shallow parsing task", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.6280587514241537}, {"text": "function tagging", "start_pos": 151, "end_pos": 167, "type": "TASK", "confidence": 0.733904629945755}]}, {"text": "Our chunks and functions are based on the annotations in the third release of the Penn Treebank (.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 82, "end_pos": 95, "type": "DATASET", "confidence": 0.9896091818809509}]}, {"text": "Below is an example of a tree and the corresponding chunk (subscripts on brackets) and function (superscripts on headwords) annotation: ] . Nodes in the tree are labeled with a syntactic category and up to four function tags that specify grammatical relations (e.g. SBJ for subject), subtypes of adverbials (e.g. TMP for temporal), discrepancies between syntactic form and syntactic function (e.g. NOM for non-nominal constituents functioning nominally) and notions like topicalization.", "labels": [], "entities": []}, {"text": "Our chunks are based on the syntactic part of the constituent label.", "labels": [], "entities": []}, {"text": "The conversion program is the same as used for the CoNLL-2000 shared task).", "labels": [], "entities": [{"text": "CoNLL-2000 shared task", "start_pos": 51, "end_pos": 73, "type": "DATASET", "confidence": 0.7313388387362162}]}, {"text": "Head words of chunks are assigned a function code that is based on the full constituent label of the parent and of ancestors with a different category, as in the case of VP/S-NOM in the example.", "labels": [], "entities": []}, {"text": "To formulate the task as a machine-learnable classification task, we use a representation that encodes the joint task of chunking and function-tagging a sentence in per-word classification instances.", "labels": [], "entities": [{"text": "machine-learnable classification task", "start_pos": 27, "end_pos": 64, "type": "TASK", "confidence": 0.7486249804496765}, {"text": "chunking and function-tagging a sentence in per-word classification instances", "start_pos": 121, "end_pos": 198, "type": "TASK", "confidence": 0.5626039538118575}]}, {"text": "As illustrated in.1, an instance (which corresponds to a row in the table) consists of the values for all features (the columns) and the functionchunk code for the focus word.", "labels": [], "entities": []}, {"text": "The features describe the focus word and its local context.", "labels": [], "entities": []}, {"text": "For the chunk part of the code, we adopt the \"Inside\", \"Outside\", and \"Between\" (IOB) encoding originating from.", "labels": [], "entities": [{"text": "Between\" (IOB) encoding", "start_pos": 71, "end_pos": 94, "type": "METRIC", "confidence": 0.8509201804796854}]}, {"text": "For the function part of the code, the value is either the function for the head of a chunk, or the dummy value NOFUNC for all non-heads.", "labels": [], "entities": [{"text": "NOFUNC", "start_pos": 112, "end_pos": 118, "type": "METRIC", "confidence": 0.8169727325439453}]}, {"text": "For creating the POS-based task, all words are replaced by the goldstandard POS tags associated with them in the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 113, "end_pos": 126, "type": "DATASET", "confidence": 0.9961714744567871}]}, {"text": "For the combined task, both types of features are used simultaneously.", "labels": [], "entities": []}, {"text": "When the learner is presented with new instances from heldout material, its task is thus to assign the combined function-chunk codes to either words or POS in context.", "labels": [], "entities": []}, {"text": "From the sequence of predicted function-chunk codes, the complete chunking and function assignment can be reconstructed.", "labels": [], "entities": []}, {"text": "However, predictions can be inconsistent, blocking a straightforward reconstruction of the complete shallow parse.", "labels": [], "entities": []}, {"text": "We employed the following four rules to resolve such problems: (1) When an O chunk code is followed by a B chunk code, or when an I chunk code is followed by a B chunk code with a different chunk type, the B is converted to an I.", "labels": [], "entities": []}, {"text": "(2) When more than one word in a chunk is given a function code, the function code of the rightmost word is taken as the chunk's function code.", "labels": [], "entities": []}, {"text": "(3) If all words of the chunk receive NOFUNC tags, a prior function code is assigned to the rightmost word of the chunk.", "labels": [], "entities": []}, {"text": "This prior, estimated on the training set, represents the most frequent function code for that type of chunk.", "labels": [], "entities": []}, {"text": "To measure the success of our learner, we compute the precision, recall and their harmonic mean, the F-score 1 with 0 =1).", "labels": [], "entities": [{"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9996926784515381}, {"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9995384216308594}, {"text": "F-score", "start_pos": 101, "end_pos": 108, "type": "METRIC", "confidence": 0.9957244396209717}]}, {"text": "In the combined function-chunking evaluation, a chunk is only counted as correct when its boundaries, its type and its function are identified correctly.", "labels": [], "entities": []}, {"text": "We report the learning curve results in three paragraphs.", "labels": [], "entities": []}, {"text": "In the first, we compare the performance of a plain words input representation with that of a gold-standard POS one.", "labels": [], "entities": []}, {"text": "In the second we introduce a variant of the word-based task that deals with low-frequency words.", "labels": [], "entities": []}, {"text": "The last paragraph describes results with input consisting of words and POS tags.", "labels": [], "entities": []}, {"text": "Words only versus POS tags only As illustrated in, the learning curves of both the word-based and the POS-based representation are upward with more training data.", "labels": [], "entities": []}, {"text": "The word-based curve starts much lower but flattens less; in the tested range it has an approximately log-linear growth.", "labels": [], "entities": []}, {"text": "Given the measured results, the word-based curve surpasses the POS-based curve at a training set size between 20,000 and 50,000 sentences.", "labels": [], "entities": [{"text": "POS-based", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.7859225273132324}]}, {"text": "This proves two points: First, experiments with a fixed training set size might present a misleading snapshot.", "labels": [], "entities": []}, {"text": "Second, the amount of training material available today is already enough to make words more valuable input than (gold-standard!)", "labels": [], "entities": []}, {"text": "Low-frequency word encoding variant If TRIBL encounters an unknown word in the test material, it stops already at the decision tree stage and returns the default class without even using the information provided by the context.", "labels": [], "entities": [{"text": "word encoding", "start_pos": 14, "end_pos": 27, "type": "TASK", "confidence": 0.7002560645341873}]}, {"text": "This is clearly disadvantageous and specific to this choice of al- gorithm.", "labels": [], "entities": []}, {"text": "A more general shortcoming is that the word form of an unknown word often contains useful information that is not available in the present setup.", "labels": [], "entities": []}, {"text": "To overcome these two problems, we applied what Eisner (1997) calls \"attenuation\" to all words occurring ten times or less in training material.", "labels": [], "entities": []}, {"text": "If such a word ends in a digit, it is converted to the string \"MORPH-NUM\"; if the word is six characters or longer it becomes \"MORPH-XX\" where XX are the final two letters, else it becomes \"MORPH-SHORT\".", "labels": [], "entities": [{"text": "MORPH-NUM", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.9281875491142273}, {"text": "MORPH-XX", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.9273556470870972}, {"text": "MORPH-SHORT", "start_pos": 190, "end_pos": 201, "type": "METRIC", "confidence": 0.7762964367866516}]}, {"text": "If the first letter is capitalised, the attenuated form is \"MORPH-CAP\".", "labels": [], "entities": [{"text": "MORPH-CAP", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9837357401847839}]}, {"text": "This produces sequences such as A number of MORPH-ts were MORPHly MORPH-ed by traders . (A number of developments were negatively interpreted by traders ).", "labels": [], "entities": [{"text": "MORPH-ts", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9571705460548401}, {"text": "MORPHly MORPH-ed", "start_pos": 58, "end_pos": 74, "type": "METRIC", "confidence": 0.7446036338806152}]}, {"text": "We applied this attenuation method to all training sets.", "labels": [], "entities": []}, {"text": "All words in test material that did not occur as words in the attenuated training material were also attenuated following the same procedure.", "labels": [], "entities": []}, {"text": "The curve resulting from the attenuated wordbased experiment is also displayed in.", "labels": [], "entities": []}, {"text": "The curve illustrates that the attenuated representation performs better than the pure word-based one at all reasonable training set sizes.", "labels": [], "entities": []}, {"text": "However the effect clearly diminuishes with more training data, so we cannot exclude that the two curves will meet with yet more training data.", "labels": [], "entities": []}, {"text": "Combining words with POS tags Although the word-based curve, and especially its attenuated variant, end higher than the POS-based curve, POS might still be useful in addition to words.", "labels": [], "entities": []}, {"text": "We therefore also tested a representation with both types of features.", "labels": [], "entities": []}, {"text": "As shown in, the \"attenuated word + gold-standard POS\" curve starts close to the goldstandard POS curve, attains break-even with this curve at about 500 sentences, and ends close to but higher than all other curves, including the \"attenuated word\" curve.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Average precision, recall, and F-scores on the chunking-function-tagging task, with standard devi- ation, using the input features words, attenuated words, gold-standard POS, and MBT POS, and combina- tions, on the maximal training set size.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9976092576980591}, {"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9991932511329651}, {"text": "F-scores", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.998795747756958}]}]}