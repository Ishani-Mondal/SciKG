{"title": [], "abstractContent": [{"text": "Context is used in many NLP systems as an indicator of a term's syntactic and semantic function.", "labels": [], "entities": []}, {"text": "The accuracy of the system is dependent on the quality and quantity of contextual information available to describe each term.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.999196469783783}]}, {"text": "However, the quantity variable is no longer fixed by limited corpus resources.", "labels": [], "entities": []}, {"text": "Given fixed training time and computational resources, it makes sense for systems to invest time in extracting high quality contextual information from a fixed corpus.", "labels": [], "entities": []}, {"text": "However, with an effectively limitless quantity of text available, extraction rate and representation size need to be considered.", "labels": [], "entities": []}, {"text": "We use thesaurus extraction with a range of context extracting tools to demonstrate the interaction between context quantity, time and size on a corpus of 300 million words.", "labels": [], "entities": [{"text": "thesaurus extraction", "start_pos": 7, "end_pos": 27, "type": "TASK", "confidence": 0.733856588602066}, {"text": "context extracting", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.7217155992984772}]}], "introductionContent": [{"text": "Context plays an important role in many natural language tasks.", "labels": [], "entities": []}, {"text": "For example, the accuracy of part of speech taggers or word sense disambiguation systems depends on the quality and quantity of contextual information these systems can extract from the training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9988129138946533}, {"text": "speech taggers or word sense disambiguation", "start_pos": 37, "end_pos": 80, "type": "TASK", "confidence": 0.6256919205188751}]}, {"text": "When predicting the sense of a word, for instance, the immediately preceding word is likely to be more important than the tenth previous word; similar observations can be made about POS taggers or chunkers.", "labels": [], "entities": [{"text": "predicting the sense of a word", "start_pos": 5, "end_pos": 35, "type": "TASK", "confidence": 0.8666308025519053}, {"text": "POS taggers", "start_pos": 182, "end_pos": 193, "type": "TASK", "confidence": 0.7465583682060242}]}, {"text": "A crucial part of training these systems lies in extracting from the data high-quality contextual information, in the sense of defining contexts that are both accurate and correlated with the information (the POS tags, the word senses, the chunks) the system is trying to extract.", "labels": [], "entities": []}, {"text": "The quality of contextual information is often determined by the size of the training corpus: with less data available, extracting context information for any given phenomenon becomes less reliable.", "labels": [], "entities": []}, {"text": "However, corpus size is no longer a limiting factor: whereas up to now people have typically worked with corpora of around one million words, it has become feasible to build much larger document collections; for example, report on experiments with a one billion word corpus.", "labels": [], "entities": []}, {"text": "When using a much larger corpus and scaling the context space, there are, however, other trade-offs to take into consideration: the size of the corpus may make it unfeasible to train some systems because of efficiency issues or hardware costs; it may also result in an unmanageable expansion of the extracted context information, reducing the performance of the systems that have to make use of this information.", "labels": [], "entities": []}, {"text": "This paper reports on experiments that try to establish some of the trade-offs between corpus size, processing time, hardware costs and the performance of the resulting systems.", "labels": [], "entities": []}, {"text": "We report on experiments with a large corpus (around 300 million words).", "labels": [], "entities": []}, {"text": "We trained a thesaurus extraction system with a range of context-extracting front-ends to demonstrate the interaction between context quality, extraction time and representation size.", "labels": [], "entities": []}], "datasetContent": [{"text": "Vector-space thesaurus extraction can be separated into two independent processes.", "labels": [], "entities": [{"text": "Vector-space thesaurus extraction", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8516224225362142}]}, {"text": "The first step extracts the contexts from raw text and compiles them into a vector-space statistical description of the contexts each potential thesaurus term appears in.", "labels": [], "entities": []}, {"text": "We define a context relation as a tuple (w, r, w \ud97b\udf59 ) where w is a thesaurus term, occurring in relation type r, with another word w \ud97b\udf59 in the sentence.", "labels": [], "entities": []}, {"text": "The type can be grammatical or the position of w \ud97b\udf59 in a context window: the relation indicates that the term dog, was the direct object of the verb walk.", "labels": [], "entities": []}, {"text": "Often we treat the tuple (r, w \ud97b\udf59 ) as a single unit and refer to it as an attribute of w.", "labels": [], "entities": []}, {"text": "The context extraction systems used for these experiments are described in the following section.", "labels": [], "entities": [{"text": "context extraction", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7430912554264069}]}, {"text": "The second step in thesaurus extraction performs clustering or nearest-neighbour analysis to determine which terms are similar based on their context vectors.", "labels": [], "entities": [{"text": "thesaurus extraction", "start_pos": 19, "end_pos": 39, "type": "TASK", "confidence": 0.8083011507987976}]}, {"text": "Our second component is similar to Grefenstette's SEXTANT system, which performs nearestneighbour calculations for each pair of potential thesaurus terms.", "labels": [], "entities": []}, {"text": "For nearest-neighbour measurements we must define a function to judge the similarity between two context vectors (e.g. the cosine measure) and a function to combine the raw instance frequencies for each context relation into weighted vector components.", "labels": [], "entities": []}, {"text": "SEXTANT uses a generalisation of the Jaccard measure to measure similarity.", "labels": [], "entities": [{"text": "SEXTANT", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.6290147304534912}]}, {"text": "The Jaccard measure is the cardinality ratio of the intersection and union of attribute sets (atts(w n ) is the attribute set for w n ): The generalised Jaccard measure allows each relation to have a significance weight (based on word, attribute and relation frequencies) associated with it: Grefenstette originally used the weighting function: where f (w i , a j ) is the frequency of the relation and n(a j ) is the number of different words a j appears in relations with.", "labels": [], "entities": []}, {"text": "For the purposes of evaluation, we selected 70 single word noun terms for thesaurus extraction.", "labels": [], "entities": [{"text": "thesaurus extraction", "start_pos": 74, "end_pos": 94, "type": "TASK", "confidence": 0.7639386355876923}]}, {"text": "To avoid sample bias, the words were randomly selected from Wordnet such that they covered a range of values for the following word properties: occurrence frequency based on frequency counts from the Penn Treebank, BNC and Reuters; number of senses based on the number of Wordnet synsets and Macquarie Thesaurus entries; generality/specificity based on depth of the term in the Wordnet hierarchy; abstractness/concreteness based on even distribution across all Wordnet subtrees.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 60, "end_pos": 67, "type": "DATASET", "confidence": 0.9779892563819885}, {"text": "Penn Treebank", "start_pos": 200, "end_pos": 213, "type": "DATASET", "confidence": 0.9930165708065033}, {"text": "BNC", "start_pos": 215, "end_pos": 218, "type": "DATASET", "confidence": 0.8567650318145752}]}, {"text": "shows some of the selected terms with frequency and synonym set data.", "labels": [], "entities": []}, {"text": "For each term we extracted a thesaurus entry with 200 potential synonyms and their weighted Jaccard scores.", "labels": [], "entities": []}, {"text": "The most difficult aspect of thesaurus extraction is evaluating the quality of the result.", "labels": [], "entities": [{"text": "thesaurus extraction", "start_pos": 29, "end_pos": 49, "type": "TASK", "confidence": 0.824015349149704}]}, {"text": "The simplest method of evaluation is direct comparison of the extracted thesaurus with a manually created gold standard.", "labels": [], "entities": []}, {"text": "However on smaller corpora direct matching alone is often too coarsegrained and thesaurus coverage is a problem.", "labels": [], "entities": [{"text": "coverage", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.6311573386192322}]}, {"text": "Our experiments use a combination of three thesauri available in electronic form: The Macquarie Thesaurus), Roget's Thesaurus, and the Moby Thesaurus.", "labels": [], "entities": [{"text": "Macquarie Thesaurus", "start_pos": 86, "end_pos": 105, "type": "DATASET", "confidence": 0.975138932466507}, {"text": "Roget's Thesaurus", "start_pos": 108, "end_pos": 125, "type": "DATASET", "confidence": 0.5819645126660665}, {"text": "Moby Thesaurus", "start_pos": 135, "end_pos": 149, "type": "DATASET", "confidence": 0.9744481146335602}]}, {"text": "Each thesaurus is structured differently: Roget's and Macquarie are topic ordered and the Moby thesaurus is head term ordered.", "labels": [], "entities": [{"text": "Macquarie", "start_pos": 54, "end_pos": 63, "type": "DATASET", "confidence": 0.48966312408447266}, {"text": "Moby thesaurus", "start_pos": 90, "end_pos": 104, "type": "DATASET", "confidence": 0.9602223336696625}]}, {"text": "Roget's is quite dated and has low coverage, and contains a deep hierarchy (depth up to seven) with terms grouped in 8696 small synonym sets at the leaves of the hierarchy.", "labels": [], "entities": []}, {"text": "The Macquarie consists of 812 large topics (often in antonym related pairs), each of which is separated into 21174 small synonym sets.", "labels": [], "entities": [{"text": "The Macquarie consists of 812 large topics", "start_pos": 0, "end_pos": 42, "type": "DATASET", "confidence": 0.9222176841327122}]}, {"text": "Roget's and the Macquarie provide sense distinctions by placing terms in multiple synonym sets.", "labels": [], "entities": [{"text": "Macquarie", "start_pos": 16, "end_pos": 25, "type": "DATASET", "confidence": 0.9244591593742371}]}, {"text": "The Moby thesaurus consists of 30259 head terms and large synonym lists which conflate all the head term senses.", "labels": [], "entities": [{"text": "Moby thesaurus", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.9308024644851685}]}, {"text": "The extracted thesaurus does not distinguish between different head senses.", "labels": [], "entities": []}, {"text": "Therefore, we convert the Roget's and Macquarie thesaurus into head term ordered format by combining each small sense set that the head term appears in.", "labels": [], "entities": [{"text": "Macquarie thesaurus", "start_pos": 38, "end_pos": 57, "type": "DATASET", "confidence": 0.9313518106937408}]}, {"text": "We create a gold standard thesaurus containing the union of the synonym lists from each thesaurus, giving a total of 23207 synonyms for the 70 terms.", "labels": [], "entities": []}, {"text": "With these gold standard resources in place, it is possible to use precision and recall measures to calculate the performance of the thesaurus extraction systems.", "labels": [], "entities": [{"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9994716048240662}, {"text": "recall", "start_pos": 81, "end_pos": 87, "type": "METRIC", "confidence": 0.9977594614028931}, {"text": "thesaurus extraction", "start_pos": 133, "end_pos": 153, "type": "TASK", "confidence": 0.735625684261322}]}, {"text": "To help overcome the problems of coarsegrained direct comparisons we use three different types of measure to evaluate thesaurus quality: 2.", "labels": [], "entities": []}, {"text": "Precision of then top ranked synonyms (P(n))", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.6515268087387085}]}], "tableCaptions": [{"text": " Table 2: Training Corpora Statistics", "labels": [], "entities": [{"text": "Training Corpora Statistics", "start_pos": 10, "end_pos": 37, "type": "DATASET", "confidence": 0.8747460047403971}]}, {"text": " Table 2. The sentences  were randomly shuffled together to produce a sin- gle homogeneous corpus. This corpus was split into  two 150M word corpora over which the main experi- mental results are averaged. We then created smaller  corpora of size 1  2 down to 1  64 th of each 150M corpus.  The next section describes the method of evaluating  each thesaurus created by the combination of a given  context extraction system and corpus size.", "labels": [], "entities": []}, {"text": " Table 3: Examples of the 70 thesaurus evaluation terms with distribution information", "labels": [], "entities": []}, {"text": " Table 4: Effect of morphological analysis on SEXTANT thesaurus quality", "labels": [], "entities": [{"text": "SEXTANT thesaurus", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.5032766759395599}]}, {"text": " Table 5: Average thesaurus quality results for different extraction systems", "labels": [], "entities": []}, {"text": " Table 6: Average SEXTANT thesaurus quality results for different corpus sizes", "labels": [], "entities": [{"text": "SEXTANT thesaurus quality", "start_pos": 18, "end_pos": 43, "type": "METRIC", "confidence": 0.8442659179369608}]}, {"text": " Table 7: Thesaurus quality with relation filtering", "labels": [], "entities": []}]}