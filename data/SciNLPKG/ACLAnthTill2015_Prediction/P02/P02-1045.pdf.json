{"title": [], "abstractContent": [{"text": "In this paper, we investigate the practical applicability of Co-Training for the task of building a classifier for reference resolution.", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 115, "end_pos": 135, "type": "TASK", "confidence": 0.8834642171859741}]}, {"text": "We are concerned with the question if Co-Training can significantly reduce the amount of manual labeling work and still produce a classifier with an acceptable performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "A major obstacle for natural language processing systems which analyze natural language texts or utterances is the need to identify the entities referred to by means of referring expressions.", "labels": [], "entities": []}, {"text": "Among referring expressions, pronouns and definite noun phrases (NPs) are the most prominent.", "labels": [], "entities": []}, {"text": "Supervised machine learning algorithms were used for pronoun resolution with good results, and for definite NPs with fairly good results ().", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.7835673689842224}]}, {"text": "However, the deficiency of supervised machine learning approaches is the need for an unknown amount of annotated training data for optimal performance.", "labels": [], "entities": []}, {"text": "So, researchers in NLP began to experiment with weakly supervised machine learning algorithms such as).", "labels": [], "entities": []}, {"text": "Among others Co-Training was applied to document classification, namedentity recognition), noun phrase bracketing), and statistical parsing.", "labels": [], "entities": [{"text": "document classification", "start_pos": 40, "end_pos": 63, "type": "TASK", "confidence": 0.7946634888648987}, {"text": "namedentity recognition", "start_pos": 65, "end_pos": 88, "type": "TASK", "confidence": 0.6526589393615723}, {"text": "noun phrase bracketing", "start_pos": 91, "end_pos": 113, "type": "TASK", "confidence": 0.7541954318682352}, {"text": "statistical parsing", "start_pos": 120, "end_pos": 139, "type": "TASK", "confidence": 0.888058990240097}]}, {"text": "In this paper we apply Co-Training to the problem of reference resolution in German texts from the tourism domain in order to provide answers to the following questions: Does Co-Training work at all for this task (when compared to conventional C4.5 decision tree learning)?", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 53, "end_pos": 73, "type": "TASK", "confidence": 0.8618200123310089}]}, {"text": "How much labeled training data is required for achieving a reasonable performance?", "labels": [], "entities": []}, {"text": "First, we discuss features that have been found to be relevant for the task of reference resolution, and describe the feature set that we are using (Section 2).", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 79, "end_pos": 99, "type": "TASK", "confidence": 0.9123088121414185}]}, {"text": "Then we briefly introduce the Co-Training paradigm (Section 3), which is followed by a description of the corpus we use, the corpus annotation, and the way we prepared the data for using a binary classifier in the Co-Training algorithm (Section 4).", "labels": [], "entities": []}, {"text": "In Section 5 we specify the experimental setup and report on the results.", "labels": [], "entities": []}], "datasetContent": [{"text": "For our experiments we implemented the standard Co-Training algorithm (as described in Section 3) in Java using the Weka machine learning library . In contrast to other Co-Training approaches, we did not use Naive Bayes as base classifiers, but J48 decision trees, which area Weka re-implementation of C4.5.", "labels": [], "entities": []}, {"text": "The use of decision tree classifiers was motivated by the observation that they appeared to perform better on the task at hand.", "labels": [], "entities": []}, {"text": "We conducted a number of experiments to investigate the question if Co-Training is beneficial for the task of training a classifier for coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 136, "end_pos": 158, "type": "TASK", "confidence": 0.9539321660995483}]}, {"text": "In previous work) we obtained quite different results for different types of anaphora, i.e. if we split the data according to the ana np feature into personal and possessive pronouns (PPER PPOS), proper names (NE), and definite NPs (def NP).", "labels": [], "entities": []}, {"text": "Therefore we performed CoTraining experiments on subsets of our data defined by these NP forms, and on the whole data set.", "labels": [], "entities": []}, {"text": "We determined the features for the two different views with the following procedure: We trained classifiers on each feature separately and chose the best one, adding the feature which produced it as the first feature of view 1.", "labels": [], "entities": []}, {"text": "We then trained classifiers on all remaining features separately, again choosing the best one and adding its feature as the first feature of view 2.", "labels": [], "entities": []}, {"text": "In the next step, we enhanced the first classifier by combining it with all remaining features separately.", "labels": [], "entities": []}, {"text": "The classifier with the best performance was X X X X 17.", "labels": [], "entities": []}, {"text": "ana med X X X X: Views used for the experiments For Co-Training, we committed ourselves to fixed parameter settings in order to reduce the complexity of the experiments.", "labels": [], "entities": []}, {"text": "Settings are given in the relevant subsections, where the following abbreviations are used: L=size of labeled training set, P/N=number of positive/negative instances added per iteration.", "labels": [], "entities": []}, {"text": "All reported Co-Training results are averaged over 5 runs utilizing randomized sequences of unlabeled instances.", "labels": [], "entities": []}, {"text": "We compare the results we obtained with CoTraining with the initial result before the CoTraining process started (zero iterations, both views combined; denoted as XX 0its in the plots).", "labels": [], "entities": []}, {"text": "For this, we used a conventional C4.5 decision tree classifier (J48 implementation, default settings) on labeled training data sets of the same size used for the respective Co-Training experiment.", "labels": [], "entities": []}, {"text": "We did this in order to verify the quality of the training data and for obtaining reference values for comparison with the Co-Training classifiers.", "labels": [], "entities": []}, {"text": "\"20\" using 2:9 \"20_0its\" using 2:6 \"100\" using 2:9 \"100_0its\" using 2:6 \"200\" using 2:9 \"200_0its\" using 2:6 Figure 1: F for PPER PPOS over iterations, baselines PPER PPOS.", "labels": [], "entities": [{"text": "F", "start_pos": 119, "end_pos": 120, "type": "METRIC", "confidence": 0.9832514524459839}]}, {"text": "In, three curves and three baselines are plotted: For 20 (L=20), 20 0its is the baseline, i.e. the initial result obtained by just combining the two initial classifiers.", "labels": [], "entities": []}, {"text": "For 100, L=100, and for 200, L=200.", "labels": [], "entities": [{"text": "L", "start_pos": 9, "end_pos": 10, "type": "METRIC", "confidence": 0.9814879894256592}, {"text": "L", "start_pos": 29, "end_pos": 30, "type": "METRIC", "confidence": 0.9825477004051208}]}, {"text": "The other settings were: P=1, N=1, Pool=10.", "labels": [], "entities": []}, {"text": "As can be seen, the baselines slightly outperform the Co-Training curves (except for 100).", "labels": [], "entities": []}, {"text": "\"200\" using 2:9 \"200_0its\" using 2:6 \"1000\" using 2:9 \"1000_0its\" using 2:6 \"2000\" using 2:9 \"2000_0its\" using 2:6 Figure 2: F for NE over iterations, baselines NE.", "labels": [], "entities": [{"text": "F", "start_pos": 125, "end_pos": 126, "type": "METRIC", "confidence": 0.9511991143226624}]}, {"text": "Then we ran the Co-Training experiment with the NP form NE (i.e. proper names).", "labels": [], "entities": []}, {"text": "Since the distribution of positive and negative examples in the labeled training data was quite different from the previous experiment, we used P=1, N=33, Pool=120.", "labels": [], "entities": [{"text": "P", "start_pos": 144, "end_pos": 145, "type": "METRIC", "confidence": 0.9558752179145813}]}, {"text": "Since all results with Lf 200 were equally poor, we started with L=200, where the results were closer to ones of classifiers using the whole data set.", "labels": [], "entities": []}, {"text": "The resulting Co-Training curve degrades substantially.", "labels": [], "entities": []}, {"text": "However, with a training size of 1000 and 2000 the Co-Training curves are above their baselines.", "labels": [], "entities": []}, {"text": "\"500\" using 2:9 \"500_0its\" using 2:6 \"1000\" using 2:9 \"1000_0its\" using 2:6 \"2000\" using 2:9 \"2000_0its\" using 2:6 Figure 3: F for def NP over iterations, baselines def NP.", "labels": [], "entities": []}, {"text": "In the next experiment we tested the NP form def NP, a concept which can be expected to be far more difficult to learn than the previous two NP forms.", "labels": [], "entities": []}, {"text": "Used settings were P=1, N=30, Pool=120.", "labels": [], "entities": [{"text": "P", "start_pos": 19, "end_pos": 20, "type": "METRIC", "confidence": 0.9917565584182739}, {"text": "N", "start_pos": 24, "end_pos": 25, "type": "METRIC", "confidence": 0.9664301872253418}, {"text": "Pool", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.9830831289291382}]}, {"text": "For Lf 500, F-measure was near 0.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9995656609535217}]}, {"text": "With L=500 the Co-Training curve is way below the baseline.", "labels": [], "entities": [{"text": "L", "start_pos": 5, "end_pos": 6, "type": "METRIC", "confidence": 0.9800227880477905}]}, {"text": "However, with L=1000 and L=2000 Co-Training does show some improvement.", "labels": [], "entities": [{"text": "L", "start_pos": 14, "end_pos": 15, "type": "METRIC", "confidence": 0.9732924103736877}]}, {"text": "\"200\" using 2:9 \"200_0its\" using 2:6 \"1000\" using 2:9 \"1000_0its\" using 2:6 \"2000\" using 2:9 \"2000_0its\" using 2:6 Figure 4: F for All over iterations, baselines All.", "labels": [], "entities": [{"text": "F", "start_pos": 125, "end_pos": 126, "type": "METRIC", "confidence": 0.9754353165626526}]}, {"text": "In the last experiment we trained our classifier on all NP forms, using P=1, N=33, Pool=120.", "labels": [], "entities": []}, {"text": "With L=200 the baseline clearly outperforms CoTraining.", "labels": [], "entities": [{"text": "L", "start_pos": 5, "end_pos": 6, "type": "METRIC", "confidence": 0.9692471027374268}, {"text": "CoTraining", "start_pos": 44, "end_pos": 54, "type": "DATASET", "confidence": 0.8522091507911682}]}, {"text": "Co-Training with L=1000 initially rises above the baselines, but then decreases after about 15 to 20 iterations.", "labels": [], "entities": [{"text": "L=1000", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.9380689462025961}]}, {"text": "With L=2000 the Co-Training curve approximates its baseline and then degenerates.", "labels": [], "entities": []}], "tableCaptions": []}