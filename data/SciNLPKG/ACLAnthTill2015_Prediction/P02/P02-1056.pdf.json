{"title": [{"text": "An Integrated Architecture for Shallow and Deep Processing", "labels": [], "entities": []}], "abstractContent": [{"text": "We present an architecture for the integration of shallow and deep NLP components which is aimed at flexible combination of different language technologies fora range of practical current and future applications.", "labels": [], "entities": []}, {"text": "In particular, we describe the integration of a high-level HPSG parsing system with different high-performance shallow components, ranging from named entity recognition to chunk parsing and shallow clause recognition.", "labels": [], "entities": [{"text": "HPSG parsing", "start_pos": 59, "end_pos": 71, "type": "TASK", "confidence": 0.7229981124401093}, {"text": "named entity recognition", "start_pos": 144, "end_pos": 168, "type": "TASK", "confidence": 0.6818970243136088}, {"text": "chunk parsing", "start_pos": 172, "end_pos": 185, "type": "TASK", "confidence": 0.7633123397827148}, {"text": "shallow clause recognition", "start_pos": 190, "end_pos": 216, "type": "TASK", "confidence": 0.673040489355723}]}, {"text": "The NLP components enrich a representation of natural language text with layers of new XML meta-information using a single shared data structure, called the text chart.", "labels": [], "entities": []}, {"text": "We describe details of the integration methods, and show how information extraction and language checking applications for real-world German text benefit from a deep grammatical analysis.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.8051496148109436}, {"text": "language checking", "start_pos": 88, "end_pos": 105, "type": "TASK", "confidence": 0.7259060889482498}]}], "introductionContent": [{"text": "Over the last ten years or so, the trend in applicationoriented natural language processing (e.g., in the area of term, information, and answer extraction) has been to argue that for many purposes, shallow natural language processing (SNLP) of texts can provide sufficient information for highly accurate and useful tasks to be carried out.", "labels": [], "entities": [{"text": "applicationoriented natural language processing", "start_pos": 44, "end_pos": 91, "type": "TASK", "confidence": 0.5912688970565796}, {"text": "term, information, and answer extraction)", "start_pos": 114, "end_pos": 155, "type": "TASK", "confidence": 0.5764846317470074}, {"text": "shallow natural language processing (SNLP) of texts", "start_pos": 198, "end_pos": 249, "type": "TASK", "confidence": 0.7443477511405945}]}, {"text": "Since the emergence of shallow techniques and the proof of their utility, the focus has been to exploit these technologies to the maximum, often ignoring certain complex issues, e.g. those which are typically well handled by deep NLP systems.", "labels": [], "entities": []}, {"text": "Up to now, deep natural language processing (DNLP) has not played a significant role in the area of industrial NLP applications, since this technology often suffers from insufficient robustness and throughput, when confronted with large quantities of unrestricted text.", "labels": [], "entities": [{"text": "deep natural language processing (DNLP)", "start_pos": 11, "end_pos": 50, "type": "TASK", "confidence": 0.7364451970372882}]}, {"text": "Current information extractions (IE) systems therefore do not attempt an exhaustive DNLP analysis of all aspects of a text, but rather try to analyse or \"understand\" only those text passages that contain relevant information, thereby warranting speed and robustness wrt.", "labels": [], "entities": [{"text": "information extractions (IE)", "start_pos": 8, "end_pos": 36, "type": "TASK", "confidence": 0.8622976183891297}, {"text": "speed", "start_pos": 245, "end_pos": 250, "type": "METRIC", "confidence": 0.9807233214378357}]}, {"text": "What exactly counts as relevant is explicitly defined by means of highly detailed domain-specific lexical entries and/or rules, which perform the required mappings from NL utterances to corresponding domain knowledge.", "labels": [], "entities": []}, {"text": "However, this \"fine-tuning\" wrt.", "labels": [], "entities": []}, {"text": "a particular application appears to be the major obstacle when adapting a given shallow IE system to another domain or when dealing with the extraction of complex \"scenario-based\" relational structures.", "labels": [], "entities": []}, {"text": "In fact, have shown that the current IE technology seems to have an upper performance level of less than 60% in such cases.", "labels": [], "entities": [{"text": "IE", "start_pos": 37, "end_pos": 39, "type": "TASK", "confidence": 0.9723948240280151}]}, {"text": "It seems reasonable to assume that if a more accurate analysis of structural linguistic relationships could be provided (e.g., grammatical functions, referential relationships), this barrier might be overcome.", "labels": [], "entities": []}, {"text": "Actually, the growing market needs in the wide area of intelligent information management systems seem to request such a break-through.", "labels": [], "entities": []}, {"text": "In this paper we will argue that the quality of cur-rent SNLP-based applications can be improved by integrating DNLP on demand in a focussed manner, and we will present a system that combines the finegrained anaysis provided by HPSG parsing with a high-performance SNLP system into a generic and flexible NLP architecture.", "labels": [], "entities": [{"text": "HPSG parsing", "start_pos": 228, "end_pos": 240, "type": "TASK", "confidence": 0.7853899896144867}]}], "datasetContent": [{"text": "An evaluation has been started using the NEGRA corpus, which contains about 20,000 newspaper sentences.", "labels": [], "entities": [{"text": "NEGRA corpus", "start_pos": 41, "end_pos": 53, "type": "DATASET", "confidence": 0.9342128038406372}]}, {"text": "The main objectives are to evaluate the syntactic coverage of the German HPSG on newspaper text and the benefits of integrating deep and shallow analysis.", "labels": [], "entities": [{"text": "German HPSG", "start_pos": 66, "end_pos": 77, "type": "DATASET", "confidence": 0.8814573884010315}]}, {"text": "The sentences of the corpus were used in their original form without stripping, e.g. parenthesized insertions.", "labels": [], "entities": []}, {"text": "We extended the HPSG lexicon semiautomatically from about 10,000 to 35,000 stems, which roughly corresponds to 350,000 full forms.", "labels": [], "entities": [{"text": "HPSG lexicon", "start_pos": 16, "end_pos": 28, "type": "DATASET", "confidence": 0.9188605844974518}]}, {"text": "Then, we checked the lexical coverage of the deep system on the whole corpus, which resulted in 28.6% of the sentences being fully lexically analyzed.", "labels": [], "entities": []}, {"text": "The corresponding experiment with the integrated system yielded an improved lexical coverage of 71.4%, due to the techniques described in section 3.", "labels": [], "entities": [{"text": "coverage", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.6286237239837646}]}, {"text": "This increase is not achieved by manual extension, but only through synergy between the deep and shallow components.", "labels": [], "entities": []}, {"text": "To test the syntactic coverage, we processed the subset of the corpus that was fully covered lexically (5878 sentences) with deep analysis only.", "labels": [], "entities": []}, {"text": "The results are shown in table 4 in the second column.", "labels": [], "entities": []}, {"text": "In order to evaluate the integrated system we processed 20,568 sentences from the corpus without further extension of the HPSG lexicon (see: Evaluation of German HPSG About 10% of the sentences that were successfully parsed by deep analysis only could not be parsed by the integrated system, and the number of analyses per sentence dropped from 16.2% to 8.6%, which indicates a problem in the morphology interface of the integrated system.", "labels": [], "entities": [{"text": "HPSG lexicon", "start_pos": 122, "end_pos": 134, "type": "DATASET", "confidence": 0.9470240473747253}, {"text": "German HPSG", "start_pos": 155, "end_pos": 166, "type": "DATASET", "confidence": 0.8021769523620605}]}, {"text": "We expect better overall results once this problem is removed.", "labels": [], "entities": []}], "tableCaptions": []}