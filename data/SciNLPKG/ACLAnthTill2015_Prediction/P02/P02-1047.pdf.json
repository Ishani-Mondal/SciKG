{"title": [{"text": "An Unsupervised Approach to Recognizing Discourse Relations", "labels": [], "entities": [{"text": "Recognizing Discourse", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.9212491512298584}]}], "abstractContent": [{"text": "We present an unsupervised approach to recognizing discourse relations of CONTRAST , EXPLANATION-EVIDENCE, CONDITION and ELABORATION that hold between arbitrary spans of texts.", "labels": [], "entities": []}, {"text": "We show that discourse relation classifiers trained on examples that are automatically extracted from massive amounts of text can be used to distinguish between some of these relations with accuracies as high as 93%, even when the relations are not explicitly marked by cue phrases.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 190, "end_pos": 200, "type": "METRIC", "confidence": 0.9669920802116394}]}], "introductionContent": [{"text": "In the field of discourse research, it is now widely agreed that sentences/clauses are usually not understood in isolation, but in relation to other sentences/clauses.", "labels": [], "entities": []}, {"text": "Given the high level of interest in explaining the nature of these relations and in providing definitions for them (, it is surprising that there are no robust programs capable of identifying discourse relations that hold between arbitrary spans of text.", "labels": [], "entities": []}, {"text": "Consider, for example, the sentence/clause pairs below. a. Such standards would preclude arms sales to states like Libya, which is also currently subject to a U.N. embargo. b. But states like Rwanda before its present crisis would still be able to legally buy arms.", "labels": [], "entities": []}, {"text": "South Africa can afford to forgo sales of guns and grenades b. because it actually makes most of its profits from the sale of expensive, high-technology systems like laser-designated missiles, aircraft electronic warfare systems, tactical radios, anti-radiation bombs and battlefield mobility systems.", "labels": [], "entities": []}, {"text": "(2) In these examples, the discourse markers But and because help us figure out that a CONTRAST relation holds between the text spans in (1) and an EXPLANATION-EVIDENCE relation holds between the spans in (2).", "labels": [], "entities": [{"text": "CONTRAST", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9662646055221558}]}, {"text": "Unfortunately, cue phrases do not signal all relations in a text.", "labels": [], "entities": []}, {"text": "In the corpus of Rhetorical Structure trees (www.isi.edu/\u00a2 marcu/discourse/) built by, for example, we have observed that only 61 of 238 CONTRAST relations and 79 out of 307 EXPLANATION-EVIDENCE relations that hold between two adjacent clauses were marked by a cue phrase.", "labels": [], "entities": []}, {"text": "So what shall we do when no discourse markers are used?", "labels": [], "entities": []}, {"text": "If we had access to robust semantic interpreters, we could, for example, infer from sentence 1.a that \"cannot buy arms legally(libya)\", infer from sentence 1.b that \"can buy arms legally(rwanda)\", use our background knowledge in order to infer that \"similar(libya,rwanda)\", and apply definitions of discourse relations to arrive at the conclusion that a CONTRAST relation holds between the sentences in (1).", "labels": [], "entities": [{"text": "CONTRAST", "start_pos": 354, "end_pos": 362, "type": "METRIC", "confidence": 0.8918461799621582}]}, {"text": "Unfortunately, the state of the art in NLP does not provide us access to semantic interpreters and general purpose knowledge bases that would support these kinds of inferences.", "labels": [], "entities": []}, {"text": "The discourse relation definitions proposed by others ( are not easier to apply either because they assume the ability to automatically derive, in addition to the semantics of the text spans, the intentions and illocutions associated with them as well.", "labels": [], "entities": []}, {"text": "In spite of the difficulty of determining the discourse relations that hold between arbitrary text spans, it is clear that such an ability is important in many applications.", "labels": [], "entities": []}, {"text": "First, a discourse relation recognizer would enable the development of improved discourse parsers and, consequently, of high performance single document summarizers).", "labels": [], "entities": [{"text": "discourse relation recognizer", "start_pos": 9, "end_pos": 38, "type": "TASK", "confidence": 0.6218120555082957}]}, {"text": "In multidocument summarization, it would enable the development of summarization programs capable of identifying contradictory statements both within and across documents and of producing summaries that reflect not only the similarities between various documents, but also their differences.", "labels": [], "entities": [{"text": "multidocument summarization", "start_pos": 3, "end_pos": 30, "type": "TASK", "confidence": 0.6118108630180359}]}, {"text": "In question-answering, it would enable the development of systems capable of answering sophisticated, non-factoid queries, such as \"what were the causes of X?\" or \"what contradicts Y?\", which are beyond the state of the art of current systems.", "labels": [], "entities": []}, {"text": "In this paper, we describe experiments aimed at building robust discourse-relation classification systems.", "labels": [], "entities": [{"text": "discourse-relation classification", "start_pos": 64, "end_pos": 97, "type": "TASK", "confidence": 0.712966650724411}]}, {"text": "To build such systems, we train a family of Naive Bayes classifiers on a large set of examples that are generated automatically from two corpora: a corpus of 41,147,805 English sentences that have no annotations, and BLIPP, a corpus of 1,796,386 automatically parsed English sentences, which is available from the Linguistic Data Consortium (www.ldc.upenn.edu).", "labels": [], "entities": [{"text": "BLIPP", "start_pos": 217, "end_pos": 222, "type": "METRIC", "confidence": 0.9713550806045532}, {"text": "Linguistic Data Consortium", "start_pos": 314, "end_pos": 340, "type": "DATASET", "confidence": 0.7960068384806315}]}, {"text": "We study empirically the adequacy of various features for the task of discourse relation classification and we show that some discourse relations can be correctly recognized with accuracies as high as 93%.", "labels": [], "entities": [{"text": "discourse relation classification", "start_pos": 70, "end_pos": 103, "type": "TASK", "confidence": 0.685521811246872}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Performances of classifiers trained on the Raw corpus. The baseline in all cases is 50%.", "labels": [], "entities": [{"text": "Raw corpus", "start_pos": 53, "end_pos": 63, "type": "DATASET", "confidence": 0.9767090678215027}, {"text": "baseline", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.8686581254005432}]}, {"text": " Table 4: Performances of classifiers trained on the BLIPP corpus. The baseline in all cases is 50%.", "labels": [], "entities": [{"text": "BLIPP corpus", "start_pos": 53, "end_pos": 65, "type": "DATASET", "confidence": 0.9614102840423584}, {"text": "baseline", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.8174278140068054}]}, {"text": " Table 5: Performances of Raw-trained classifiers on  manually labeled RST relations that hold between  elementary discourse units. Performance results are  shown in bold; baselines are shown in normal fonts.", "labels": [], "entities": []}]}