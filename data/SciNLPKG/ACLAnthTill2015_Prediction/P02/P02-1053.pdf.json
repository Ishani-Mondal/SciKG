{"title": [{"text": "Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews", "labels": [], "entities": [{"text": "Unsupervised Classification of Reviews", "start_pos": 58, "end_pos": 96, "type": "TASK", "confidence": 0.7197756320238113}]}], "abstractContent": [{"text": "This paper presents a simple unsupervised learning algorithm for classifying reviews as recommended (thumbs up) or not recommended (thumbs down).", "labels": [], "entities": []}, {"text": "The classification of a review is predicted by the average semantic orientation of the phrases in the review that contain adjectives or adverbs.", "labels": [], "entities": []}, {"text": "A phrase has a positive semantic orientation when it has good associations (e.g., \"subtle nuances\") and a negative semantic orientation when it has bad associations (e.g., \"very cavalier\").", "labels": [], "entities": []}, {"text": "In this paper, the semantic orientation of a phrase is calculated as the mutual information between the given phrase and the word \"excellent\" minus the mutual information between the given phrase and the word \"poor\".", "labels": [], "entities": []}, {"text": "A review is classified as recommended if the average semantic orientation of its phrases is positive.", "labels": [], "entities": []}, {"text": "The algorithm achieves an average accuracy of 74% when evaluated on 410 reviews from Epinions, sampled from four different domains (reviews of automobiles, banks, movies, and travel destinations).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9993388056755066}]}, {"text": "The accuracy ranges from 84% for automobile reviews to 66% for movie reviews.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995501637458801}]}], "introductionContent": [{"text": "If you are considering a vacation in Akumal, Mexico, you might go to a search engine and enter the query \"Akumal travel review\".", "labels": [], "entities": [{"text": "Akumal travel review", "start_pos": 106, "end_pos": 126, "type": "DATASET", "confidence": 0.8522477348645529}]}, {"text": "However, in this case, Google 1 reports about 5,000 matches.", "labels": [], "entities": [{"text": "Google 1", "start_pos": 23, "end_pos": 31, "type": "DATASET", "confidence": 0.9054336249828339}]}, {"text": "It would be useful to know what fraction of these matches recommend Akumal as a travel destination.", "labels": [], "entities": [{"text": "Akumal", "start_pos": 68, "end_pos": 74, "type": "DATASET", "confidence": 0.900088906288147}]}, {"text": "With an algorithm for automatically classifying a review as \"thumbs up\" or \"thumbs down\", it would be possible fora search engine to report such summary statistics.", "labels": [], "entities": []}, {"text": "This is the motivation for the research described here.", "labels": [], "entities": []}, {"text": "Other potential applications include recognizing \"flames\" (abusive newsgroup messages) and developing new kinds of search tools.", "labels": [], "entities": [{"text": "recognizing \"flames\" (abusive newsgroup messages)", "start_pos": 37, "end_pos": 86, "type": "TASK", "confidence": 0.8645046949386597}]}, {"text": "In this paper, I present a simple unsupervised learning algorithm for classifying a review as recommended or not recommended.", "labels": [], "entities": []}, {"text": "The algorithm takes a written review as input and produces a classification as output.", "labels": [], "entities": []}, {"text": "The first step is to use a part-of-speech tagger to identify phrases in the input text that contain adjectives or adverbs.", "labels": [], "entities": []}, {"text": "The second step is to estimate the semantic orientation of each extracted phrase.", "labels": [], "entities": []}, {"text": "A phrase has a positive semantic orientation when it has good associations (e.g., \"romantic ambience\") and a negative semantic orientation when it has bad associations (e.g., \"horrific events\").", "labels": [], "entities": []}, {"text": "The third step is to assign the given review to a class, recommended or not recommended, based on the average semantic orientation of the phrases extracted from the review.", "labels": [], "entities": []}, {"text": "If the average is positive, the prediction is that the review recommends the item it discusses.", "labels": [], "entities": []}, {"text": "Otherwise, the prediction is that the item is not recommended.", "labels": [], "entities": []}, {"text": "The PMI-IR algorithm is employed to estimate the semantic orientation of a phrase.", "labels": [], "entities": []}, {"text": "PMI-IR uses Pointwise Mutual Information (PMI) and Information Retrieval (IR) to measure the similarity of pairs of words or phrases.", "labels": [], "entities": [{"text": "Information Retrieval (IR", "start_pos": 51, "end_pos": 76, "type": "TASK", "confidence": 0.5595058798789978}]}, {"text": "The se-mantic orientation of a given phrase is calculated by comparing its similarity to a positive reference word (\"excellent\") with its similarity to a negative reference word (\"poor\").", "labels": [], "entities": []}, {"text": "More specifically, a phrase is assigned a numerical rating by taking the mutual information between the given phrase and the word \"excellent\" and subtracting the mutual information between the given phrase and the word \"poor\".", "labels": [], "entities": []}, {"text": "In addition to determining the direction of the phrase's semantic orientation (positive or negative, based on the sign of the rating), this numerical rating also indicates the strength of the semantic orientation (based on the magnitude of the number).", "labels": [], "entities": []}, {"text": "The algorithm is presented in Section 2.", "labels": [], "entities": []}, {"text": "have also developed an algorithm for predicting semantic orientation.", "labels": [], "entities": [{"text": "predicting semantic orientation", "start_pos": 37, "end_pos": 68, "type": "TASK", "confidence": 0.9202841917673746}]}, {"text": "Their algorithm performs well, but it is designed for isolated adjectives, rather than phrases containing adjectives or adverbs.", "labels": [], "entities": []}, {"text": "This is discussed in more detail in Section 3, along with other related work.", "labels": [], "entities": []}, {"text": "The classification algorithm is evaluated on 410 reviews from Epinions 2 , randomly sampled from four different domains: reviews of automobiles, banks, movies, and travel destinations.", "labels": [], "entities": []}, {"text": "Reviews at Epinions are not written by professional writers; any person with a Web browser can become a member of Epinions and contribute a review.", "labels": [], "entities": []}, {"text": "Each of these 410 reviews was written by a different author.", "labels": [], "entities": []}, {"text": "Of these reviews, 170 are not recommended and the remaining 240 are recommended (these classifications are given by the authors).", "labels": [], "entities": []}, {"text": "Always guessing the majority class would yield an accuracy of 59%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9997455477714539}]}, {"text": "The algorithm achieves an average accuracy of 74%, ranging from 84% for automobile reviews to 66% for movie reviews.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9964175224304199}]}, {"text": "The experimental results are given in Section 4.", "labels": [], "entities": []}, {"text": "The interpretation of the experimental results, the limitations of this work, and future work are discussed in Section 5.", "labels": [], "entities": []}, {"text": "Potential applications are outlined in Section 6.", "labels": [], "entities": []}, {"text": "Finally, conclusions are presented in Section 7.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 4. A summary of the corpus of reviews.", "labels": [], "entities": []}, {"text": " Table 5. The accuracy of the classification and the cor- relation of the semantic orientation with the star rating.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.999738872051239}, {"text": "cor- relation", "start_pos": 53, "end_pos": 66, "type": "METRIC", "confidence": 0.9000979860623678}]}]}