{"title": [{"text": "Supervised Ranking in Open-Domain Text Summarization", "labels": [], "entities": [{"text": "Open-Domain Text Summarization", "start_pos": 22, "end_pos": 52, "type": "TASK", "confidence": 0.5997272829214731}]}], "abstractContent": [{"text": "The paper proposes and empirically motivates an integration of supervised learning with unsupervised learning to deal with human biases in summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 139, "end_pos": 152, "type": "TASK", "confidence": 0.979874312877655}]}, {"text": "In particular , we explore the use of probabilistic decision tree within the clustering framework to account for the variation as well as regularity inhuman created summaries.", "labels": [], "entities": []}, {"text": "The corpus of human created extracts is created from a newspaper corpus and used as a test set.", "labels": [], "entities": []}, {"text": "We build probabilistic decision trees of different flavors and integrate each of them with the clustering framework.", "labels": [], "entities": []}, {"text": "Experiments with the corpus demonstrate that the mixture of the two paradigms generally gives a significant boost in performance compared to cases where either of the two is considered alone.", "labels": [], "entities": []}], "introductionContent": [{"text": "have recently made an interesting observation that an unsupervised method based on clustering sometimes better approximates human created extracts than a supervised approach.", "labels": [], "entities": []}, {"text": "That appears somewhat contradictory given that a supervised approach should be able to exploit human supplied information about which sentence to include in an extract and which not to, whereas an unsupervised approach blindly chooses sentences according to some selection scheme.", "labels": [], "entities": []}, {"text": "An interesting question is, why this should be the case.", "labels": [], "entities": []}, {"text": "The reason may have to do with the variation inhuman judgments on sentence selection fora summary.", "labels": [], "entities": []}, {"text": "Ina study to be described later, we asked students to select 10% of a text which they find most important for making a summary.", "labels": [], "entities": []}, {"text": "If they agree perfectly on their judgments, then we will have only 10% of a text selected as most important.", "labels": [], "entities": []}, {"text": "However, what we found was that about half of a text were marked as important, indicating that judgments can vary widely among humans.", "labels": [], "entities": []}, {"text": "Curiously, however, Nomoto and Matsumoto (2001a) also found that a supervised system fares much better when tested on data exhibiting high agreement among humans than an unsupervised system.", "labels": [], "entities": []}, {"text": "Their finding suggests that there are indeed some regularities (or biases) to be found.", "labels": [], "entities": []}, {"text": "So we might conclude that there are two aspects to human judgments in summarization; they can vary but may exhibit some biases which could be usefully exploited.", "labels": [], "entities": [{"text": "summarization", "start_pos": 70, "end_pos": 83, "type": "TASK", "confidence": 0.9889140725135803}]}, {"text": "The issue is then how we might model them in some coherent framework.", "labels": [], "entities": []}, {"text": "The goal of the paper is to explore a possible integration of supervised and unsupervised paradigms as away of responding to the issue.", "labels": [], "entities": []}, {"text": "Taking a decision tree and clustering as representing the respective paradigm, we will show how coupling them provides a summarizer that better approximates human judgments than either of the two considered alone.", "labels": [], "entities": []}, {"text": "To our knowledge, none of the prior work on summarization (e.g.,) explicitly addressed the issue of the variability inherent inhuman judgments in summarization tasks.", "labels": [], "entities": [{"text": "summarization", "start_pos": 44, "end_pos": 57, "type": "TASK", "confidence": 0.9909845590591431}, {"text": "summarization tasks", "start_pos": 146, "end_pos": 165, "type": "TASK", "confidence": 0.923768550157547}]}, {"text": "y , \u03b8 3 n )", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Test Data. N denotes the total number of  sentences in the test data. K \u2265 n means that a wis  (positive) sentence gets at least n votes.  K  N  positive negative  \u2265 1 1424  707  717  \u2265 2 1424  392  1032  \u2265 3 1424  236  1188  \u2265 4 1424  150  1274  \u2265 5 1424  72  1352", "labels": [], "entities": []}, {"text": " Table 4: Performance at varying compression rates for K \u2265 1. MDL-DT denotes a summarizer based  on C4.5 with the MDL extension. DBS (=Z/V) denotes the diversity based summarizer. Z represents the  Z-model summarizer. Performance figures are in F-measure. 'V' indicates that the relevant classifier is  diversity-enabled. Note that DBS =Z/V.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 245, "end_pos": 254, "type": "METRIC", "confidence": 0.9322505593299866}]}]}