{"title": [{"text": "Improving Language Model Size Reduction using Better Pruning Criteria", "labels": [], "entities": [{"text": "Improving Language Model Size Reduction", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.9274182200431824}]}], "abstractContent": [{"text": "Reducing language model (LM) size is a critical issue when applying a LM to realistic applications which have memory constraints.", "labels": [], "entities": [{"text": "Reducing language model (LM) size", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7417023863111224}]}, {"text": "In this paper, three measures are studied for the purpose of LM pruning.", "labels": [], "entities": [{"text": "LM pruning", "start_pos": 61, "end_pos": 71, "type": "TASK", "confidence": 0.8589762449264526}]}, {"text": "They are probability, rank, and entropy.", "labels": [], "entities": []}, {"text": "We evaluated the performance of the three pruning criteria in areal application of Chinese text input in terms of character error rate (CER).", "labels": [], "entities": [{"text": "character error rate (CER)", "start_pos": 114, "end_pos": 140, "type": "METRIC", "confidence": 0.8454798062642416}]}, {"text": "We first present an empirical comparison, showing that rank performs the best inmost cases.", "labels": [], "entities": []}, {"text": "We also show that the high-performance of rank lies in its strong correlation with error rate.", "labels": [], "entities": [{"text": "error rate", "start_pos": 83, "end_pos": 93, "type": "METRIC", "confidence": 0.9897045791149139}]}, {"text": "We then present a novel method of combining two criteria in model pruning.", "labels": [], "entities": []}, {"text": "Experimental results show that the combined criterion consistently leads to smaller models than the models pruned using either of the criteria separately, at the same CER.", "labels": [], "entities": [{"text": "CER", "start_pos": 167, "end_pos": 170, "type": "DATASET", "confidence": 0.8976629972457886}]}], "introductionContent": [{"text": "Backoff n-gram models for applications such as large vocabulary speech recognition are typically trained on very large text corpora.", "labels": [], "entities": [{"text": "large vocabulary speech recognition", "start_pos": 47, "end_pos": 82, "type": "TASK", "confidence": 0.6544954776763916}]}, {"text": "An uncompressed LM is usually too large for practical use since all realistic applications have memory constraints.", "labels": [], "entities": []}, {"text": "Therefore, LM pruning techniques are used to produce the smallest model while keeping the performance loss as small as possible.", "labels": [], "entities": []}, {"text": "Research on backoff n-gram model pruning has been focused on the development of the pruning criterion, which is used to estimate the performance loss of the pruned model.", "labels": [], "entities": []}, {"text": "The traditional count cutoff method) used a pruning criterion based on absolute frequency while recent research has shown that better pruning criteria can be developed based on more sophisticated measures such as perplexity.", "labels": [], "entities": []}, {"text": "In this paper, we study three measures for pruning backoff n-gram models.", "labels": [], "entities": []}, {"text": "They are probability, rank and entropy.", "labels": [], "entities": []}, {"text": "We evaluated the performance of the three pruning criteria in areal application of Chinese text input () through CER.", "labels": [], "entities": [{"text": "CER", "start_pos": 113, "end_pos": 116, "type": "DATASET", "confidence": 0.8958038091659546}]}, {"text": "We first present an empirical comparison, showing that rank performs the best inmost cases.", "labels": [], "entities": []}, {"text": "We also show that the high-performance of rank lies in its strong correlation with error rate.", "labels": [], "entities": [{"text": "error rate", "start_pos": 83, "end_pos": 93, "type": "METRIC", "confidence": 0.9897045791149139}]}, {"text": "We then present a novel method of combining two pruning criteria in model pruning.", "labels": [], "entities": []}, {"text": "Our results show that the combined criterion consistently leads to smaller models than the models pruned using either of the criteria separately.", "labels": [], "entities": []}, {"text": "In particular, the combination of rank and entropy achieves the smallest models at a given CER.", "labels": [], "entities": [{"text": "CER", "start_pos": 91, "end_pos": 94, "type": "DATASET", "confidence": 0.8657316565513611}]}, {"text": "The rest of the paper is structured as follows: Section 2 discusses briefly the related work on backoff n-gram pruning.", "labels": [], "entities": []}, {"text": "Section 3 describes in detail several pruning criteria.", "labels": [], "entities": []}, {"text": "Section 4 presents an empirical comparison of pruning criteria using a Chinese text input system.", "labels": [], "entities": []}, {"text": "Section 5 proposes our method of combining two criteria in model pruning.", "labels": [], "entities": []}, {"text": "Section 6 presents conclusions and our future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: LM size comparison at CER 13.8%", "labels": [], "entities": [{"text": "CER 13.8", "start_pos": 32, "end_pos": 40, "type": "DATASET", "confidence": 0.9110603034496307}]}, {"text": " Table 2: Correlation of LM evaluation measures  with word error rates (Clarkson and Robinson,  2001)", "labels": [], "entities": [{"text": "LM evaluation", "start_pos": 25, "end_pos": 38, "type": "TASK", "confidence": 0.8627030253410339}, {"text": "word error rates", "start_pos": 54, "end_pos": 70, "type": "METRIC", "confidence": 0.7589302261670431}]}, {"text": " Table 3: Sample optimal parameter settings for  combination of criteria based on rank and entropy  # bigrams", "labels": [], "entities": []}, {"text": " Table 4. As we expected, in all three  cases, using a combination of two pruning criteria  achieves consistently better performance than using  either of the criteria separately. In particular, using  the combination of rank and entropy, we obtained  the best models over a wide large of CER values. It  corresponds to a significant size reduction of  15-54% over the probability-based LM pruning at  the same CER. An example of the detailed  comparison results is shown in", "labels": [], "entities": []}, {"text": " Table 5: LM size comparison at CER 13.8%", "labels": [], "entities": [{"text": "CER 13.8", "start_pos": 32, "end_pos": 40, "type": "DATASET", "confidence": 0.9173585772514343}]}]}