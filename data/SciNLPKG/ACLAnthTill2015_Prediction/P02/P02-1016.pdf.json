{"title": [{"text": "Active Learning for Statistical Natural Language Parsing", "labels": [], "entities": [{"text": "Statistical Natural Language Parsing", "start_pos": 20, "end_pos": 56, "type": "TASK", "confidence": 0.6472556740045547}]}], "abstractContent": [{"text": "It is necessary to have a (large) annotated corpus to build a statistical parser.", "labels": [], "entities": []}, {"text": "Acquisition of such a corpus is costly and time-consuming.", "labels": [], "entities": []}, {"text": "This paper presents a method to reduce this demand using active learning, which selects what samples to annotate, instead of annotating blindly the whole training corpus.", "labels": [], "entities": []}, {"text": "Sample selection for annotation is based upon \"representativeness\" and \"usefulness\".", "labels": [], "entities": [{"text": "Sample selection", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7946257889270782}]}, {"text": "A model-based distance is proposed to measure the difference of two sentences and their most likely parse trees.", "labels": [], "entities": []}, {"text": "Based on this distance, the active learning process analyzes the sample distribution by clustering and calculates the density of each sample to quantify its representativeness.", "labels": [], "entities": []}, {"text": "Further more, a sentence is deemed as useful if the existing model is highly uncertain about its parses, where uncertainty is measured by various entropy-based scores.", "labels": [], "entities": []}, {"text": "Experiments are carried out in the shallow semantic parser of an air travel dialog system.", "labels": [], "entities": [{"text": "shallow semantic parser", "start_pos": 35, "end_pos": 58, "type": "TASK", "confidence": 0.682150661945343}]}, {"text": "Our result shows that for about the same parsing accuracy, we only need to annotate a third of the samples as compared to the usual random selection method.", "labels": [], "entities": [{"text": "parsing", "start_pos": 41, "end_pos": 48, "type": "TASK", "confidence": 0.9557515978813171}, {"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9325626492500305}]}], "introductionContent": [{"text": "A prerequisite for building statistical parsers is the availability of a (large) corpus of parsed sentences.", "labels": [], "entities": []}, {"text": "Acquiring such a corpus is expensive and timeconsuming and is often the bottleneck to build a parser fora new application or domain.", "labels": [], "entities": []}, {"text": "The goal of this study is to reduce the amount of annotated sentences (and hence the development time) required fora statistical parser to achieve a satisfactory performance using active learning.", "labels": [], "entities": []}, {"text": "Active learning has been studied in the context of many natural language processing (NLP) applications such as information extraction), text classification) and natural language parsing(), to name a few.", "labels": [], "entities": [{"text": "Active learning", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7741191387176514}, {"text": "information extraction", "start_pos": 111, "end_pos": 133, "type": "TASK", "confidence": 0.7988911271095276}, {"text": "text classification", "start_pos": 136, "end_pos": 155, "type": "TASK", "confidence": 0.8128563761711121}, {"text": "natural language parsing", "start_pos": 161, "end_pos": 185, "type": "TASK", "confidence": 0.6398458580176035}]}, {"text": "The basic idea is to couple tightly knowledge acquisition, e.g., annotating sentences for parsing, with model-training, as opposed to treating them separately.", "labels": [], "entities": []}, {"text": "In our setup, we assume that a small amount of annotated sentences is initially available, which is used to build a statistical parser.", "labels": [], "entities": []}, {"text": "We also assume that there is a large corpus of unannotated sentences at our disposalthis corpus is called active training set.", "labels": [], "entities": []}, {"text": "A batch of samples 1 is selected using algorithms developed here, and are annotated by human beings and are then added to training data to rebuild the model.", "labels": [], "entities": []}, {"text": "The procedure is iterated until the model reaches a certain accuracy level.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9979730248451233}]}, {"text": "Our efforts are devoted to two aspects: first, we believe that the selected samples should reflect the underlying distribution of the training corpus.", "labels": [], "entities": []}, {"text": "In other words, the selected samples need to be representative.", "labels": [], "entities": []}, {"text": "To this end, a model-based structural distance is defined to quantify how \"far\" two sentences are apart, and with the help of this distance, the active training set is clustered so that we can define and compute the \"density\" of a sample; second, we propose and test several entropy-based measures to quantify the uncertainty of a sample in the active training set using an existing model, as it makes sense to ask human beings to annotate the portion of data for which the existing model is not doing well.", "labels": [], "entities": []}, {"text": "Samples are selected from the clusters based on uncertainty scores.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, a structural distance is first defined based on the sequential representation of a parse tree.", "labels": [], "entities": []}, {"text": "It is then straightforward to employ a k-means algorithm to cluster sentences in the active training set.", "labels": [], "entities": []}, {"text": "Section 3 is devoted to confidence measures, where three uncertainty measures are proposed.", "labels": [], "entities": []}, {"text": "Active learning results on the shallow semantic parser of an air travel dialog system are presented 1 A sample means a sentence in this paper.", "labels": [], "entities": []}, {"text": "A summary of related work is given in Section 5.", "labels": [], "entities": []}, {"text": "The paper closes with conclusions and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "All experiments are done with a shallow semantic parser (a.k.a. classer) of the natural language understanding part in DARPA Communicator).", "labels": [], "entities": []}, {"text": "We built an initial model using 1000 sentences.", "labels": [], "entities": []}, {"text": "We have 20951 unlabeled sentences for the active learner to select samples.", "labels": [], "entities": []}, {"text": "An independent test set consists of 4254 sentences.", "labels": [], "entities": []}, {"text": "A fixed batch size is used throughout our experiments.", "labels": [], "entities": []}, {"text": "Exact match is used to compute the accuracy, i.e., the accuracy is the number of sentences whose decoding trees are exactly the same as human annotation divided by the number of sentences in the test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9994874000549316}, {"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9989951252937317}]}, {"text": "The effectiveness of active learning is measured by comparing learning curves (i.e., test accuracy vs. number of training sentences ) of active learning and random selection.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Weighting effect  Weighting  none density performance  Test Accuracy(%) 79.8  84.3  80.7", "labels": [], "entities": [{"text": "Weighting effect  Weighting  none density performance  Test", "start_pos": 10, "end_pos": 69, "type": "METRIC", "confidence": 0.7133310607501439}, {"text": "Accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.5842330455780029}]}]}