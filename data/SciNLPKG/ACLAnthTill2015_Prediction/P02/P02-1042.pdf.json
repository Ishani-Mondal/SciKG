{"title": [{"text": "Building Deep Dependency Structures with a Wide-Coverage CCG Parser", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes a wide-coverage statistical parser that uses Combinatory Categorial Grammar (CCG) to derive dependency structures.", "labels": [], "entities": []}, {"text": "The parser differs from most existing wide-coverage tree-bank parsers in capturing the long-range dependencies inherent in constructions such as coordination, extraction, raising and control, as well as the standard local predicate-argument dependencies.", "labels": [], "entities": [{"text": "coordination, extraction, raising and control", "start_pos": 145, "end_pos": 190, "type": "TASK", "confidence": 0.6756442742688316}]}, {"text": "A set of dependency structures used for training and testing the parser is obtained from a treebank of CCG normal-form derivations , which have been derived (semi-) automatically from the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 188, "end_pos": 201, "type": "DATASET", "confidence": 0.9952780604362488}]}, {"text": "The parser correctly recovers over 80% of labelled dependencies, and around 90% of unlabelled dependencies.", "labels": [], "entities": []}], "introductionContent": [{"text": "Most recent wide-coverage statistical parsers have used models based on lexical dependencies (e.g.,).", "labels": [], "entities": []}, {"text": "However, the dependencies are typically derived from a context-free phrase structure tree using simple head percolation heuristics.", "labels": [], "entities": []}, {"text": "This approach does notwork well for the long-range dependencies involved in raising, control, extraction and coordination, all of which are common in text such as the Wall Street Journal.", "labels": [], "entities": [{"text": "raising, control, extraction and coordination", "start_pos": 76, "end_pos": 121, "type": "TASK", "confidence": 0.7098051990781512}, {"text": "Wall Street Journal", "start_pos": 167, "end_pos": 186, "type": "DATASET", "confidence": 0.9661951065063477}]}, {"text": "Chiang (2000) uses Tree Adjoining Grammar as an alternative to context-free grammar, and here we use another \"mildly context-sensitive\" formalism, Combinatory Categorial Grammar), which arguably provides the most linguistically satisfactory account of the dependencies inherent in coordinate constructions and extraction phenomena.", "labels": [], "entities": []}, {"text": "The potential advantage from using such an expressive grammar is to facilitate recovery of such unbounded dependencies.", "labels": [], "entities": []}, {"text": "As well as having a potential impact on the accuracy of the parser, recovering such dependencies may make the output more useful.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9987455606460571}]}, {"text": "CCG is unlike other formalisms in that the standard predicate-argument relations relevant to interpretation can be derived via extremely non-standard surface derivations.", "labels": [], "entities": []}, {"text": "This impacts on how best to define a probability model for CCG, since the \"spurious ambiguity\" of CCG derivations may lead to an exponential number of derivations fora given constituent.", "labels": [], "entities": []}, {"text": "In addition, some of the spurious derivations may not be present in the training data.", "labels": [], "entities": []}, {"text": "One solution is to consider only the normal-form) derivation, which is the route taken in.", "labels": [], "entities": []}, {"text": "Another problem with the non-standard surface derivations is that the standard PARSEVAL performance measures over such derivations are uninformative).", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.6678538918495178}]}, {"text": "Such measures have been criticised by and, who propose recovery of headdependencies characterising predicate-argument relations as a more meaningful measure.", "labels": [], "entities": []}, {"text": "If the end-result of parsing is interpretable predicate-argument structure or the related dependency structure, then the question arises: why build derivation structure at all?", "labels": [], "entities": []}, {"text": "A CCG parser can directly build derived structures, including long-1 Another, more speculative, possibility is to treat the alternative derivations as hidden and apply the EM algorithm.", "labels": [], "entities": []}, {"text": "These derived structures can be of any form we like-for example, they could in principle be standard Penn Treebank structures.", "labels": [], "entities": [{"text": "Penn Treebank structures", "start_pos": 101, "end_pos": 125, "type": "DATASET", "confidence": 0.9844416379928589}]}, {"text": "Since we are interested in dependency-based parser evaluation, our parser currently builds dependency structures.", "labels": [], "entities": [{"text": "dependency-based parser evaluation", "start_pos": 27, "end_pos": 61, "type": "TASK", "confidence": 0.6554559568564097}]}, {"text": "Furthermore, since we want to model the dependencies in such structures, the probability model is defined over these structures rather than the derivation.", "labels": [], "entities": []}, {"text": "The training and testing material for this CCG parser is a treebank of dependency structures, which have been derived from a set of CCG derivations developed for use with another (normal-form) CCG parser).", "labels": [], "entities": []}, {"text": "The treebank of derivations, which we call CCGbank), was in turn derived (semi-)automatically from the handannotated Penn Treebank.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 43, "end_pos": 50, "type": "DATASET", "confidence": 0.9315133094787598}, {"text": "Penn Treebank", "start_pos": 117, "end_pos": 130, "type": "DATASET", "confidence": 0.9129763543605804}]}], "datasetContent": [{"text": "Sections 02-21 of the CCGbank were used for training (39 161 sentences); section 00 for development (1 901 sentences); and section 23 for testing (2 379 sentences).", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 22, "end_pos": 29, "type": "DATASET", "confidence": 0.7907533645629883}]}, {"text": "8 Sections 02-21 were also used to obtain the category set, by including all categories that appear at least 10 times, which resulted in a set of 398 category types.", "labels": [], "entities": []}, {"text": "The word-category sequences needed for estimating the probabilities in equation 8 can be read directly from the CCGbank.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 112, "end_pos": 119, "type": "DATASET", "confidence": 0.9838539361953735}]}, {"text": "To obtain dependencies 7 These rules are currently applied deterministically.", "labels": [], "entities": []}, {"text": "In future work we will investigate approaches which integrate the rule applications with the statistical model.", "labels": [], "entities": []}, {"text": "for estimating P\u00a2 D 4 C S\u00a4 , we ran the parser over the trees, tracing out the combinatory rules applied during the derivation, and outputting the dependencies.", "labels": [], "entities": []}, {"text": "This method was also applied to the trees in section 23 to provide the gold standard test set.", "labels": [], "entities": [{"text": "gold standard test set", "start_pos": 71, "end_pos": 93, "type": "DATASET", "confidence": 0.8700831383466721}]}, {"text": "Not all trees produced dependency structures, since not all categories and type-changing rules in the CCGbank are encoded in the parser.", "labels": [], "entities": []}, {"text": "We obtained dependency structures for roughly 95% of the trees in the data.", "labels": [], "entities": []}, {"text": "For evaluation purposes, we increased the coverage on section 23 to 99 1 0% (2 352 sentences) by identifying the cause of the parse failures and adding the additional rules and categories when creating the gold-standard; so the final test set consisted of gold-standard dependency structures from 2 352 sentences.", "labels": [], "entities": [{"text": "coverage", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9835706949234009}]}, {"text": "The coverage was increased to ensure the test set was representative of the full section.", "labels": [], "entities": [{"text": "coverage", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9970882534980774}]}, {"text": "We emphasise that these additional rules and categories were not made available to the parser during testing, or used for training.", "labels": [], "entities": []}, {"text": "Initially the parser was run with \u03b2 for the parser.", "labels": [], "entities": []}, {"text": "A time-out was applied so that the parser was stopped if any sentence took longer than 2 CPU minutes to parse.", "labels": [], "entities": []}, {"text": "With these parameters, 2 098 of the 2 352 sentences received some analysis, with 206 timing out and 48 failing to parse.", "labels": [], "entities": []}, {"text": "To deal with the 48 no-analysis cases, the cut-off for the category-dictionary, K, was increased to 100.", "labels": [], "entities": []}, {"text": "Of the 48 cases, 23 sentences then received an analysis.", "labels": [], "entities": []}, {"text": "To deal with the 206 time-out cases, \u03b2 was increased to 0 1 05, which resulted in 181 of the 206 sentences then receiving an analysis, with 18 failing to parse, and 7 timing out.", "labels": [], "entities": [{"text": "\u03b2", "start_pos": 37, "end_pos": 38, "type": "METRIC", "confidence": 0.970373809337616}]}, {"text": "So overall, almost 98% of the 2 352 unseen sentences were given some analysis.", "labels": [], "entities": []}, {"text": "To return a single dependency structure, we chose the most probable structure from the S \u00a7 d cl\u00a8categoriescl\u00a8categories spanning the whole sentence.", "labels": [], "entities": []}, {"text": "If there was no such category, all categories spanning the whole string were considered.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results for section 00 by dependency relation", "labels": [], "entities": []}]}