{"title": [{"text": "A Noisy-Channel Model for Document Compression", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a document compression system that uses a hierarchical noisy-channel model of text production.", "labels": [], "entities": [{"text": "document compression", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.7475778460502625}]}, {"text": "Our compression system first automatically derives the syntactic structure of each sentence and the overall discourse structure of the text given as input.", "labels": [], "entities": []}, {"text": "The system then uses a statistical hierarchical model of text production in order to drop non-important syntactic and discourse constituents so as to generate coherent, grammatical document compressions of arbitrary length.", "labels": [], "entities": []}, {"text": "The system outperforms both a baseline and a sentence-based compression system that operates by simplifying sequentially all sentences in a text.", "labels": [], "entities": []}, {"text": "Our results support the claim that discourse knowledge plays an important role in document summariza-tion.", "labels": [], "entities": []}], "introductionContent": [{"text": "Single document summarization systems proposed to date fall within one of the following three classes: Extractive summarizers simply select and present to the user the most important sentences in a text -see () for comprehensive overviews of the methods and algorithms used to accomplish this.", "labels": [], "entities": [{"text": "Single document summarization", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6163378655910492}, {"text": "Extractive summarizers", "start_pos": 103, "end_pos": 125, "type": "TASK", "confidence": 0.7674509882926941}]}, {"text": "Headline generators are noisy-channel probabilistic systems that are trained on large corpora of \u00a2 H eadline, Text\u00a3 pairs ().", "labels": [], "entities": []}, {"text": "These systems produce short sequences of words that are indicative of the content of the text given as input.", "labels": [], "entities": []}, {"text": "Sentence simplification systems) are capable of compressing long sentences by deleting unimportant words and phrases.", "labels": [], "entities": [{"text": "Sentence simplification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.838695228099823}]}, {"text": "Extraction-based summarizers often produce outputs that contain non-important sentence fragments.", "labels": [], "entities": [{"text": "Extraction-based summarizers", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7000586688518524}]}, {"text": "For example, the hypothetical extractive summary of Text (1), which is shown in, can be compacted further by deleting the clause \"which is already almost enough to win\".", "labels": [], "entities": []}, {"text": "Headline-based summaries, such as that shown in, are usually indicative of a text's content but not informative, grammatical, or coherent.", "labels": [], "entities": []}, {"text": "By repeatedly applying a sentence-simplification algorithm one sentence at a time, one can compress a text; yet, the outputs generated in this way are likely to be incoherent and to contain unimportant information.", "labels": [], "entities": []}, {"text": "When summarizing text, some sentences should be dropped altogether.", "labels": [], "entities": [{"text": "summarizing text", "start_pos": 5, "end_pos": 21, "type": "TASK", "confidence": 0.8864060342311859}]}, {"text": "Ideally, we would like to build systems that have the strengths of all these three classes of approaches.", "labels": [], "entities": []}, {"text": "The \"Document Compression\" entry in shows a grammatical, coherent summary of Text (1), which was generated by a hypothetical document compression system that preserves the most important information in a text while deleting sentences, phrases, and words that are subsidiary to the main message of the text.", "labels": [], "entities": []}, {"text": "Obviously, generating coherent, grammatical summaries such as that produced by the hypothetical document compression system in is not trivial because of many conflicting  The deletion of certain sentences may result in incoherence and information loss.", "labels": [], "entities": []}, {"text": "The deletion of certain words and phrases may also lead to ungrammaticality and information loss.", "labels": [], "entities": []}, {"text": "The mayor is now looking for re-election.", "labels": [], "entities": []}, {"text": "John Doe has already secured the vote of most democrats in his constituency, which is already almost enough to win.", "labels": [], "entities": []}, {"text": "But without the support of the governer, he is still on shaky grounds.", "labels": [], "entities": []}, {"text": "(1) In this paper, we present a document compression system that uses hierarchical models of discourse and syntax in order to simultaneously manage all these conflicting goals.", "labels": [], "entities": [{"text": "document compression", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.7199613451957703}]}, {"text": "Our compression system first automatically derives the syntactic structure of each sentence and the overall discourse structure of the text given as input.", "labels": [], "entities": []}, {"text": "The system then uses a statistical hierarchical model of text production in order to drop non-important syntactic and discourse units so as to generate coherent, grammatical document compressions of arbitrary length.", "labels": [], "entities": []}, {"text": "The system outperforms both a baseline and a sentence-based compression system that operates by simplifying sequentially all sentences in a text.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}