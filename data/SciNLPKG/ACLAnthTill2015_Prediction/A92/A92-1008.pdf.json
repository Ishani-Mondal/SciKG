{"title": [{"text": "Generating Spatial Descriptions for Cross-modal References", "labels": [], "entities": [{"text": "Generating Spatial Descriptions", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6386233568191528}, {"text": "Cross-modal References", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.7506047189235687}]}], "abstractContent": [{"text": "We present a localisation component that supports the generation of cross-modal deictic expressions in the knowledge-based presentation system WIP.", "labels": [], "entities": [{"text": "WIP", "start_pos": 143, "end_pos": 146, "type": "DATASET", "confidence": 0.9041386246681213}]}, {"text": "We deal with relative localisations (e.g., \"The object to the left, of object X.\"), absolute localisations (e.g., \"The object in the upl)er left part of the l)icture.\") and corner lo-calisations (e.g., \"The object in the lower right corner of the l)icture\").", "labels": [], "entities": []}, {"text": "In addition, we distinguish two localisation granularities, one less detailed (e.g., \"the object to the left. of object X.\") and one more detailed (e.g., \"the object above and to the left. of object X.\").", "labels": [], "entities": []}, {"text": "We consider corner localisations to be similar to absolute local-isations and in turn absolute localisations to be specialisations of relative localisations.", "labels": [], "entities": []}, {"text": "This allows us to compute all three localisation types with one generic localisation procedure.", "labels": [], "entities": []}, {"text": "As elementary localisations are derived from previously computed composite localisations, we can cope with both localisation granularities in a computationally efficient way.", "labels": [], "entities": []}, {"text": "Based on these l)rimary localisation l)rocedures, we discuss how objects can be localised among several other objects.", "labels": [], "entities": []}, {"text": "Finally we introduce group local-isations (e.g., \"The object to left, of the group of or, her objects.\") and show how to deal with thern.", "labels": [], "entities": []}], "introductionContent": [{"text": "The increasing amount of information to be communicated to users of complex technical systems nowadays makes it necessary to find new ways to present information.", "labels": [], "entities": []}, {"text": "Neither the variety of all possible l)resentation situations can be anticipated nor it is fiLrther adequate to present the required information in a single communication mode, such as either text or graphics.", "labels": [], "entities": []}, {"text": "Therefore, the automatic generation of nmltimodal presentations tailored to the individual user has become necessary.", "labels": [], "entities": []}, {"text": "Current research projects in artificial intelligence like SAGE (), FN/ANDD (), COMET () and WIP () reflect the growing interest in this topic.", "labels": [], "entities": [{"text": "FN/ANDD", "start_pos": 67, "end_pos": 74, "type": "DATASET", "confidence": 0.7459989388783773}]}, {"text": "For the knowledge-based presentation system WIP, the task is the generation of a multimodal document according to the formal description of the communicative intent of the planned presentation and a set of generation parameters.", "labels": [], "entities": []}, {"text": "The current scenario for WIP is the generation of instructions for using an espresso-machine.", "labels": [], "entities": [{"text": "WIP", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9335768222808838}]}, {"text": "A typical fragment of an instruction manual for an espresso machine is shown in", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}