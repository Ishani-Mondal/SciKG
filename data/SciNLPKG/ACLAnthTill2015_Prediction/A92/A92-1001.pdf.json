{"title": [{"text": "Deriving Database Queries from Logical Forms by Abductive Definition Expansion", "labels": [], "entities": [{"text": "Deriving Database Queries from Logical Forms", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.8499652445316315}]}], "abstractContent": [{"text": "The paper describes a principled approach to the problem of deriving database queries from logical forms produced by a general NL interface.", "labels": [], "entities": []}, {"text": "Our method attempts to construct a database query and a set of plausible assumptions , such that the logical form is equivalent to the query given the assumptions.", "labels": [], "entities": []}, {"text": "The domain information needed is provided as declarative meaning postulates, including \"defini-tional equivalences\".", "labels": [], "entities": []}, {"text": "The technical basis for the approach is that a \"definition\" of the form Head A Conditions ~ Body can be read procedurally as \"Expand Head to Body if it occurs in an environment where Conditions can be inferred\".", "labels": [], "entities": []}, {"text": "The \"environment\" is provided by the other conjuncts occurring together with Head in the original logical form, together with other meaning postulates and the contents of the database.", "labels": [], "entities": []}, {"text": "The method has been implemented in CLARE, a language and reasoning system whose linguistic component is the SRI Core Language Engine.", "labels": [], "entities": [{"text": "SRI Core Language Engine", "start_pos": 108, "end_pos": 132, "type": "DATASET", "confidence": 0.8904878199100494}]}, {"text": "1 Introduction The basic question addressed in this paper is that of how to connect a general NL interface and a back-end application in a principled way.", "labels": [], "entities": []}, {"text": "We will assume here that the interface takes input in a natural language and produces a representation in some kind of enriched first-order logic, and that the application is some kind of rela-tional database; this is a common and important situation , and it is well-known that the problems involved are non-trivial.", "labels": [], "entities": []}, {"text": "The techniques used apply equally well to other NLP applications which involve mapping linguistic concepts to knowledge base predicates.", "labels": [], "entities": []}, {"text": "Concrete examples in the paper will betaken from the SRI CLARE system, working in the domain of project resource management.", "labels": [], "entities": [{"text": "SRI CLARE system", "start_pos": 53, "end_pos": 69, "type": "DATASET", "confidence": 0.8815388679504395}]}, {"text": "CLARE is a combined natural language and *CLARE is being developed as part of a collaborative project involving BP Research, British Aerospace, British Telecom, Cambridge University, SRI International and the UK Defence Research Agency.", "labels": [], "entities": [{"text": "BP Research", "start_pos": 112, "end_pos": 123, "type": "DATASET", "confidence": 0.9027925133705139}, {"text": "British", "start_pos": 125, "end_pos": 132, "type": "DATASET", "confidence": 0.8910384178161621}, {"text": "British", "start_pos": 144, "end_pos": 151, "type": "DATASET", "confidence": 0.8900048136711121}, {"text": "UK Defence Research Agency", "start_pos": 209, "end_pos": 235, "type": "DATASET", "confidence": 0.7431052029132843}]}, {"text": "The project is funded in part by the UK Department of Trade and Industry.", "labels": [], "entities": [{"text": "UK Department of Trade and Industry", "start_pos": 37, "end_pos": 72, "type": "DATASET", "confidence": 0.9204405049482981}]}, {"text": "reasoning system which includes the Core Language Engine (or CLE, Alshawi 1992) as its language component.", "labels": [], "entities": [{"text": "Core Language Engine (or CLE, Alshawi 1992)", "start_pos": 36, "end_pos": 79, "type": "DATASET", "confidence": 0.6369682788848877}]}, {"text": "The CLE produces semantic interpretations of sentences in a notation called Quasi Logical Form.", "labels": [], "entities": []}, {"text": "For database interface applications, the semantic interpretations are converted into fairly conventional logical forms before query derivation takes place.", "labels": [], "entities": []}, {"text": "A NL interface like CLARE which is general (rather than being tailored to the application) will produce logical forms that essentially mirror the linguistic content of the input.", "labels": [], "entities": []}, {"text": "It will thus normally contain what might be called \"linguistic\" predicates (i.e. word senses): for example, the logical form fora query like ($1) List all payments made to BT during 1990.", "labels": [], "entities": [{"text": "BT during 1990", "start_pos": 172, "end_pos": 186, "type": "DATASET", "confidence": 0.9223875006039938}]}, {"text": "would be expected to contain predicates corresponding directly to payment, make and during.", "labels": [], "entities": []}, {"text": "An appropriate database query, on the other hand, might be a command to search for \"transaction\" tuples where the \"payee\" field was filled by \"BT\", and the \"date\" field by a date constrained to be between 1st January and 31st December, 1990.", "labels": [], "entities": [{"text": "BT", "start_pos": 143, "end_pos": 145, "type": "METRIC", "confidence": 0.9240903854370117}, {"text": "1st January and 31st December", "start_pos": 205, "end_pos": 234, "type": "DATASET", "confidence": 0.8226048827171326}]}, {"text": "The differing nature of the two representations can lead to several possible kinds of difficulties, depending on how the \"linguistic\" and \"database\" representations are connected.", "labels": [], "entities": []}, {"text": "There are three in particular that we will devote most of our attention to in what follows: 1.", "labels": [], "entities": []}, {"text": "A query can be conceptually outside the database's domain.", "labels": [], "entities": []}, {"text": "For example, if \"payments\" in (S1) is replaced by \"phone-calls\", the interface should be able to indicate to the user that it is unable to relate the query to the information contained in the database.", "labels": [], "entities": []}, {"text": "2. A query can be contingently outside the database's domain.", "labels": [], "entities": []}, {"text": "Thus if \"1990\" is replaced by \"1985\", it maybe possible to derive a query; however, if the database only contains records going back to 1989, the result will bean empty list.", "labels": [], "entities": []}, {"text": "Presenting this to the user without explanation is seriously misleading.", "labels": [], "entities": []}, {"text": "3. A query may need additional implicit assumptions to be translatable into database form.", "labels": [], "entities": []}, {"text": "Asking (S1) in the context of our example Project Resource Management domain, it is implicitly understood that all payments referred to have been made by SRI.", "labels": [], "entities": [{"text": "SRI", "start_pos": 154, "end_pos": 157, "type": "DATASET", "confidence": 0.9099619388580322}]}, {"text": "If the user receives no feedback describing the assumptions that have been made to perform the translation, it is again possible for misunderstandings to arise.", "labels": [], "entities": [{"text": "translation", "start_pos": 95, "end_pos": 106, "type": "TASK", "confidence": 0.9621332287788391}]}], "introductionContent": [{"text": "The basic question addressed in this paper is that of how to connect a general NL interface and a back-end application in a principled way.", "labels": [], "entities": []}, {"text": "We will assume here that the interface takes input in a natural language and produces a representation in some kind of enriched firstorder logic, and that the application is some kind of relational database; this is a common and important situation, and it is well-known that the problems involved are non-trivial.", "labels": [], "entities": []}, {"text": "The techniques used apply equally well to other NLP applications which involve mapping linguistic concepts to knowledge base predicates.", "labels": [], "entities": []}, {"text": "Concrete examples in the paper will betaken from the SRI CLARE system, working in the domain of project resource management.", "labels": [], "entities": [{"text": "SRI CLARE system", "start_pos": 53, "end_pos": 69, "type": "DATASET", "confidence": 0.8815388679504395}]}, {"text": "CLARE is a combined natural language and *CLARE is being developed as part of a collaborative project involving BP Research, British Aerospace, British Telecom, Cambridge University, SRI International and the UK Defence Research Agency.", "labels": [], "entities": [{"text": "BP Research", "start_pos": 112, "end_pos": 123, "type": "DATASET", "confidence": 0.9027925133705139}, {"text": "British", "start_pos": 125, "end_pos": 132, "type": "DATASET", "confidence": 0.8910384178161621}, {"text": "British", "start_pos": 144, "end_pos": 151, "type": "DATASET", "confidence": 0.8900048136711121}, {"text": "UK Defence Research Agency", "start_pos": 209, "end_pos": 235, "type": "DATASET", "confidence": 0.7431052029132843}]}, {"text": "The project is funded in part by the UK Department of Trade and Industry.", "labels": [], "entities": [{"text": "UK Department of Trade and Industry", "start_pos": 37, "end_pos": 72, "type": "DATASET", "confidence": 0.9204405049482981}]}, {"text": "reasoning system which includes the Core Language Engine (or CLE, Alshawi 1992) as its language component.", "labels": [], "entities": [{"text": "Core Language Engine (or CLE, Alshawi 1992)", "start_pos": 36, "end_pos": 79, "type": "DATASET", "confidence": 0.6369682788848877}]}, {"text": "The CLE produces semantic interpretations of sentences in a notation called Quasi Logical Form.", "labels": [], "entities": []}, {"text": "For database interface applications, the semantic interpretations are converted into fairly conventional logical forms before query derivation takes place.", "labels": [], "entities": []}, {"text": "A NL interface like CLARE which is general (rather than being tailored to the application) will produce logical forms that essentially mirror the linguistic content of the input.", "labels": [], "entities": []}, {"text": "It will thus normally contain what might be called \"linguistic\" predicates (i.e. word senses): for example, the logical form fora query like ($1) List all payments made to BT during 1990.", "labels": [], "entities": [{"text": "BT during 1990", "start_pos": 172, "end_pos": 186, "type": "DATASET", "confidence": 0.9223875006039938}]}, {"text": "would be expected to contain predicates corresponding directly to payment, make and during.", "labels": [], "entities": []}, {"text": "An appropriate database query, on the other hand, might be a command to search for \"transaction\" tuples where the \"payee\" field was filled by \"BT\", and the \"date\" field by a date constrained to be between 1st January and 31st December, 1990.", "labels": [], "entities": [{"text": "BT", "start_pos": 143, "end_pos": 145, "type": "METRIC", "confidence": 0.9240903854370117}, {"text": "1st January and 31st December", "start_pos": 205, "end_pos": 234, "type": "DATASET", "confidence": 0.8226048827171326}]}, {"text": "The differing nature of the two representations can lead to several possible kinds of difficulties, depending on how the \"linguistic\" and \"database\" representations are connected.", "labels": [], "entities": []}, {"text": "There are three in particular that we will devote most of our attention to in what follows: 1.", "labels": [], "entities": []}, {"text": "A query can be conceptually outside the database's domain.", "labels": [], "entities": []}, {"text": "For example, if \"payments\" in (S1) is replaced by \"phone-calls\", the interface should be able to indicate to the user that it is unable to relate the query to the information contained in the database.", "labels": [], "entities": []}, {"text": "2. A query can be contingently outside the database's domain.", "labels": [], "entities": []}, {"text": "Thus if \"1990\" is replaced by \"1985\", it maybe possible to derive a query; however, if the database only contains records going back to 1989, the result will bean empty list.", "labels": [], "entities": []}, {"text": "Presenting this to the user without explanation is seriously misleading.", "labels": [], "entities": []}, {"text": "3. A query may need additional implicit assumptions to be translatable into database form.", "labels": [], "entities": []}, {"text": "Asking (S1) in the context of our example Project Resource Management domain, it is implicitly understood that all payments referred to have been made by SRI.", "labels": [], "entities": [{"text": "SRI", "start_pos": 154, "end_pos": 157, "type": "DATASET", "confidence": 0.9099619388580322}]}, {"text": "If the user receives no feedback describing the assumptions that have been made to perform the translation, it is again possible for misunderstandings to arise.", "labels": [], "entities": [{"text": "translation", "start_pos": 95, "end_pos": 106, "type": "TASK", "confidence": 0.9621332287788391}]}, {"text": "One attractive way to attempt to effect the connection between LF and database query is to encode the database as a set of unit clauses, and to build an interpreter for the logical forms, which encodes the relations between linguistic and database predicates as \"rules\" or \"meaning postulates\" written in Horn-clause form (cf. e.g..", "labels": [], "entities": []}, {"text": "Anyone who has experimented with this scheme will, however, know that it tends to suffer from all three of the types of problem listed above.", "labels": [], "entities": []}, {"text": "This is hardly surprising, when one considers that Hornclauses are \"if\" rules; they give conditions for the LF's being true, but (as pointed out in Konolige 1981), they lack the \"only if\" half that says when they are false.", "labels": [], "entities": []}, {"text": "It is of course possible to invoke the Closed World Assumption (CWA); in this interpretation, finite failure is regarded as equivalent to negation.", "labels": [], "entities": [{"text": "Closed World Assumption (CWA)", "start_pos": 39, "end_pos": 68, "type": "TASK", "confidence": 0.6563683748245239}]}, {"text": "Unfortunately, experience also shows that it is extremely difficult to write meaning postulates for non-trivial domains that are valid under this strict interpretation.", "labels": [], "entities": []}, {"text": "For these reasons, argues that approaches which express the connection between LF and database query in terms of first-order logic formulas are unpromising.", "labels": [], "entities": []}, {"text": "Instead, previous approaches to query derivation which attempt to justify equivalence between queries and semantic represenations have been limited (at least in implemented systems) to employing restricted forms of inference.", "labels": [], "entities": [{"text": "query derivation", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.7209518849849701}]}, {"text": "Examples are the type inference used in PHLIQA ( and Stallard's 'recursive terminological simplification' In this paper we will show how a more general deductive approach can betaken.", "labels": [], "entities": [{"text": "PHLIQA", "start_pos": 40, "end_pos": 46, "type": "DATASET", "confidence": 0.7109354138374329}]}, {"text": "This depends on coding the relationship between LF and database forms not as Horn-clauses but as \"definitional equivalences\", explicit if-and-only-if rules of a particular form.", "labels": [], "entities": []}, {"text": "Our approach retains computational tractability by limiting the way in which the equivalences can take part in deductions, roughly speaking by only using them to perform directed expansions of definitions.", "labels": [], "entities": []}, {"text": "However we still permit nontrivial goal-directed domain reasoning in justifying query derivation, allowing, for example, the translation of an LF conjuct to be influenced by any other LF conjuncts, in contrast to the basically local translation in PHLIQA.", "labels": [], "entities": []}, {"text": "This approach deals with the first two points above without recourse to the CWA and simultaneously allows a clean integration of the \"abductive\" reasoning needed to take care of point 3.", "labels": [], "entities": [{"text": "CWA", "start_pos": 76, "end_pos": 79, "type": "DATASET", "confidence": 0.8896071314811707}]}, {"text": "The main technical problems to be solved are caused by the fact that the left-hand sides of the equivalences are generally not atomic.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "The main concepts are introduced in sections 2 and 3, followed by a simple example in section 4.", "labels": [], "entities": []}, {"text": "Section 5 discusses the role of existential quantification in equivalences.", "labels": [], "entities": []}, {"text": "In section 6 we introduce abductive reasoning, and relate this to the problems discussed above.", "labels": [], "entities": []}, {"text": "Section 8 then briefly describes issues related to implementing efficient search strategies to support the various kinds of inference used, and in section 9 we present an extended example showing how an LF can be successively reduced by equivalences into DB query form.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}