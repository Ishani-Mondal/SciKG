{"title": [], "abstractContent": [{"text": "The real difficulty in development of practical NLP systems comes from the fact that we do not have effective means for gathering \"knowl-edge\".", "labels": [], "entities": []}, {"text": "In this paper, we propose an algorithm which acquires automatically knowledge of semantic collocations among \"words\" from sample corpora.", "labels": [], "entities": []}, {"text": "The algorithm proposed in this paper tries to discover semantic collocations which will be useful for disambiguating structurally ambiguous sentences, by a statistical approach.", "labels": [], "entities": [{"text": "disambiguating structurally ambiguous sentences", "start_pos": 102, "end_pos": 149, "type": "TASK", "confidence": 0.801860436797142}]}, {"text": "The algorithm requires a corpus and minimum linguistic knowledge (parts-of-speech of words, simple inflection rules, and a small number of general syntactic rules).", "labels": [], "entities": []}, {"text": "We conducted two experiments of applying the algorithm to different corpora to extract different types of semantic collocations.", "labels": [], "entities": []}, {"text": "Though there are some unsolved problems, the results showed the effectiveness of the proposed algorithm .", "labels": [], "entities": []}], "introductionContent": [{"text": "Quite a few grammatical formalisms have been proposed by computational linguists, which are claimed to be \"good\" (declarative, highly modular, etc.) for practical application systems in NLP.", "labels": [], "entities": []}, {"text": "It has also been claimed that extra-linguistic, domain specific knowledge is indispensable inmost NLP applications, and computational frameworks for representing and using such domain knowledge have also been developed.", "labels": [], "entities": []}, {"text": "However, the real difficulty in developing practical NLP systems is due to the fact that we do not have effective means for gathering the \"knowledge\", whether lin-*SEKINE is now a visitor at C.C.L., U.M.I.S.T. s ekine @ ccl.", "labels": [], "entities": [{"text": "SEKINE", "start_pos": 164, "end_pos": 170, "type": "METRIC", "confidence": 0.9703978300094604}]}, {"text": "umist, ac. uk guistic or extra-linguistic.", "labels": [], "entities": []}, {"text": "In particular, it has been reported that not only extra-linguistic, domain knowledge but also linguistic knowledge required for application systems varies, depending on text-type (technical reports, scientific papers, manuals, etc.), subject domain, type of application (MT, automatic abstraction, etc.) etc.", "labels": [], "entities": [{"text": "MT, automatic abstraction", "start_pos": 271, "end_pos": 296, "type": "TASK", "confidence": 0.657490573823452}]}, {"text": "This means that we have to have effective and efficient methods either for adapting already existing knowledge fora specific \"sublanguage\" or for acquiring knowledge automatically, for example from sample corpora of given applications.", "labels": [], "entities": []}, {"text": "In this paper, we propose an algorithm which automatically acquires knowledge of semantic collocations among \"words\".", "labels": [], "entities": []}, {"text": "\"Semantic\" here means that the collocations the algorithm discovers are not collocations among words in the sense of traditional linguistics but collocations that reflect ontological relations among entities in given subject domains.", "labels": [], "entities": []}, {"text": "We expect that the knowledge to be extracted will not only be useful for disambiguating sentences but also will contribute to discovering ontological classes in given subject domains.", "labels": [], "entities": []}, {"text": "Though several studies with similar objectives have been reported,,,,,, they require that sample corpora be correctly analyzed or tagged in advance.", "labels": [], "entities": []}, {"text": "It must be a training corpus, which is tagged or parsed by human or it needs correspondence between two language corpora.", "labels": [], "entities": []}, {"text": "Because their preparation needs a lot of manual assistance or an unerring tagger or parser, this requirement makes their algorithm~, troublesome in actual application environments.", "labels": [], "entities": []}, {"text": "On the other hand, the algorithm in this paper has no such requirement, it requires only a minimum of linguistic knowledge, including parts-of-speech of words, simple inflection rules, and a small number of general syntactic rules which lexicon based syntactic theories like HPSG CC etc.", "labels": [], "entities": [{"text": "HPSG CC", "start_pos": 275, "end_pos": 282, "type": "DATASET", "confidence": 0.936911940574646}]}, {"text": "The parser is not a deterministic parser, but a parser which produces all possible analyses.", "labels": [], "entities": []}, {"text": "All of the results are used for calculation ant the system assumes that there is a correct answer among them.", "labels": [], "entities": []}, {"text": "The algorithm builds correct structural descriptions of sentences and discovers semantic collocations at the same time.", "labels": [], "entities": []}, {"text": "It works as a relaxation process.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted two experiments to show the effectiveness of our algorithm.", "labels": [], "entities": []}, {"text": "The first one uses a small, artificial corpus to show how the algorithm works.", "labels": [], "entities": []}, {"text": "The second one is areal experiment in which we use data from areal corpus (computer manuals).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Plausibility values with similar hypothesis effect", "labels": [], "entities": []}, {"text": " Table 3: Plausibility values after the fifth cycle", "labels": [], "entities": [{"text": "Plausibility", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.9317547082901001}]}, {"text": " Table 1: Plausibility values after the first cycle", "labels": [], "entities": [{"text": "Plausibility", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.9321532249450684}]}, {"text": " Table 4: Distances between words in the 5th cycle", "labels": [], "entities": []}, {"text": " Table 5: Number of compound nouns", "labels": [], "entities": []}, {"text": " Table 6: Results of experiment with compound nouns", "labels": [], "entities": []}]}