{"title": [{"text": "Detecting and Correcting Morpho-syntactic Errors in Real Texts", "labels": [], "entities": [{"text": "Detecting and Correcting Morpho-syntactic Errors in Real Texts", "start_pos": 0, "end_pos": 62, "type": "TASK", "confidence": 0.6695544570684433}]}], "abstractContent": [{"text": "This paper presents a system which detects and corrects morpho-syntactic errors in Dutch texts.", "labels": [], "entities": []}, {"text": "It includes a spelling corrector and a shift-reduce parser for Augmented Context-free Grammars.", "labels": [], "entities": [{"text": "spelling corrector", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.8410490155220032}]}, {"text": "The spelling corrector is based on trigram and triphone analysis.", "labels": [], "entities": [{"text": "spelling corrector", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7716268599033356}]}, {"text": "The parser is an extension of the well-known Tomita algorithm (Tomita, 1986).", "labels": [], "entities": []}, {"text": "The parser interacts with the spelling corrector and handles certain types of structural errors.", "labels": [], "entities": [{"text": "spelling corrector", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.7091873586177826}]}, {"text": "Both modules have been integrated with a compound analyzer and a dictionary of 275,000 word forms into a program for stand-alone proofreading of Dutch texts on a large scale.", "labels": [], "entities": [{"text": "proofreading of Dutch texts", "start_pos": 129, "end_pos": 156, "type": "TASK", "confidence": 0.7745579779148102}]}, {"text": "The system is in its final testing phase and will be commercially available as from 1992.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the most widely used applications of natural language processing is spell, grammar and style checking.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 44, "end_pos": 71, "type": "TASK", "confidence": 0.6604065299034119}, {"text": "spell, grammar and style checking", "start_pos": 75, "end_pos": 108, "type": "TASK", "confidence": 0.5959493617216746}]}, {"text": "Although most probably semantic analysis is required to obtain entirely satisfactory results, it is never used --for obvious reasons.", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.8081978559494019}]}, {"text": "Even worse, most language checkers today even restrain from syntactic analysis.", "labels": [], "entities": [{"text": "language checkers", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.7895247042179108}, {"text": "syntactic analysis", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.7608637809753418}]}, {"text": "This denies them the possibility to find morpho-syntactic errors, which form a large and frequently occurring class of spelling errors.", "labels": [], "entities": []}, {"text": "One of the best known systems for English, which does perform syntactic analysis, is Critique.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.744691014289856}]}, {"text": "In order to detect and correct morpho-syntactic errors a system needs (I) modules for word-level spell checking and correction, (2) a parser which contains a comprehensive grammar and an efficient parsing algorithm, and (3) a mechanism to detect and correct grammatical errors as well as to assist in correcting spelling errors.", "labels": [], "entities": [{"text": "word-level spell checking and correction", "start_pos": 86, "end_pos": 126, "type": "TASK", "confidence": 0.7141921103000641}]}, {"text": "I will first define the domain of morpho-syntactic errors and motivate the *The author's current address is: Experimental Psychology Unit, Leiden University, P.O. Box 9555, 2300 RB Leiden, The Netherlands.", "labels": [], "entities": [{"text": "P.O. Box 9555, 2300 RB Leiden, The Netherlands", "start_pos": 158, "end_pos": 204, "type": "DATASET", "confidence": 0.7770147114992142}]}, {"text": "After a brief overview of the system and a discussion of the word-level modules, I will describe the grammar formalism, the parser, its mechanism for error detection, and a pre-processor for word lattices.", "labels": [], "entities": [{"text": "error detection", "start_pos": 150, "end_pos": 165, "type": "TASK", "confidence": 0.7134652584791183}]}, {"text": "Finally, after looking at the integration of the modules and at some useful heuristics, I will give a summary of the results obtained by a non-interactive Dutch grammar-driven spellchecker.", "labels": [], "entities": []}], "datasetContent": [{"text": "The system described in this paper has been built as a practical writing aid that operates non-interactively, because the first phase (determining word types, compound analysis, initial spelling correction, and cross-checking corrections for the entire text) takes too long.", "labels": [], "entities": [{"text": "compound analysis", "start_pos": 159, "end_pos": 176, "type": "TASK", "confidence": 0.6743467748165131}, {"text": "initial spelling correction", "start_pos": 178, "end_pos": 205, "type": "TASK", "confidence": 0.5763716002305349}]}, {"text": "Nevertheless, it can easily process more than 25 words per second 6 fora large text, which may easily take up half an hour or more.", "labels": [], "entities": []}, {"text": "As an example of the performance in the word level checking phase, I presented the system with a 6I have written the system in the programming language C.", "labels": [], "entities": [{"text": "word level checking phase", "start_pos": 40, "end_pos": 65, "type": "TASK", "confidence": 0.8265158087015152}]}, {"text": "The results reported below were obtained with the program running on a DECstation 3100.", "labels": [], "entities": []}, {"text": "Part of the speed derives from the frequent repetition of many words in large texts.", "labels": [], "entities": [{"text": "speed", "start_pos": 12, "end_pos": 17, "type": "METRIC", "confidence": 0.9884710311889648}]}, {"text": "random sample of 1000 lines from two large texts 7.", "labels": [], "entities": []}, {"text": "The sample contained nearly 6000 words, with 30 true spelling errors.", "labels": [], "entities": []}, {"text": "Of these, 14 were corrected appropriately, and 14 were found but substituted by an incorrect alternative or not corrected at all.", "labels": [], "entities": []}, {"text": "Of the 14 appropriately corrected errors, 9 were errors in diacritics only.", "labels": [], "entities": []}, {"text": "The system only missed 2 errors, which it assumed to be proper names (both reported at the end of the file (cf. section 5)).", "labels": [], "entities": []}, {"text": "It also produced 18 false alarms, 11 of which were caused by very infrequent jargon or inflected word forms missing from the dictionary.", "labels": [], "entities": []}, {"text": "Comparison with other spell checkers is hardly possible.", "labels": [], "entities": [{"text": "spell checkers", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.7407658696174622}]}, {"text": "For Dutch, only elementary spell checkers based on simple word lookup are available.", "labels": [], "entities": [{"text": "spell checkers", "start_pos": 27, "end_pos": 41, "type": "TASK", "confidence": 0.7485263049602509}]}, {"text": "If this method is applied to the sample text with the same dictionary as used in the full system, the result is entirely different.", "labels": [], "entities": []}, {"text": "Such a simple spellchecker marks 217 words as misspelled.", "labels": [], "entities": []}, {"text": "Among these are not only the 21 true errors and the 9 errors wrongly placed diacritics, but also 37 abbreviations and proper names, and 150 compounds.", "labels": [], "entities": []}, {"text": "This amounts to a total of 187 false alarms!", "labels": [], "entities": []}, {"text": "The sentence level requires considerably more time.", "labels": [], "entities": []}, {"text": "Error-free short sentences can be parsed at a speed of four or more words per second, but long sentences containing one or more errors may require several seconds per word (including correction, which is also rather time consuming).", "labels": [], "entities": [{"text": "correction", "start_pos": 183, "end_pos": 193, "type": "METRIC", "confidence": 0.9601779580116272}]}, {"text": "For the texts mentioned in footnote 7 (110,000 words in total), the CPU time required for parsing was approximately 7 hours.", "labels": [], "entities": [{"text": "parsing", "start_pos": 90, "end_pos": 97, "type": "TASK", "confidence": 0.9695079922676086}]}, {"text": "But what counts is not only speed; quality is at least equally important.", "labels": [], "entities": [{"text": "speed", "start_pos": 28, "end_pos": 33, "type": "METRIC", "confidence": 0.9928184747695923}, {"text": "quality", "start_pos": 35, "end_pos": 42, "type": "METRIC", "confidence": 0.9772831797599792}]}, {"text": "Preliminary tests have shown satisfactory results.", "labels": [], "entities": []}, {"text": "A 150 sentence spelling test for secretaries and typists, with an average sentence length between six and seven, was performed within nine minutes (elapsed time) leaving only three errors undetected, correcting the other 72 errors appropriately and producing no false alarms.", "labels": [], "entities": [{"text": "150 sentence spelling", "start_pos": 2, "end_pos": 23, "type": "TASK", "confidence": 0.6181489030520121}]}, {"text": "(Human subjects passed the test if they could complete it within ten minutes making at most ten mistakes.)", "labels": [], "entities": []}, {"text": "The three undetected errors involved semantic factors, and were therefore beyond the scope of the system.", "labels": [], "entities": []}, {"text": "The rightly corrected errors were typographical and (mainly) orthographical errors, agreement errors and errors in idiomatic expressions.", "labels": [], "entities": []}, {"text": "7These manuscripts are representative for texts submitted to the system by a publisher who has access to it.", "labels": [], "entities": [{"text": "7These manuscripts", "start_pos": 0, "end_pos": 18, "type": "DATASET", "confidence": 0.9601843059062958}]}, {"text": "A typical example is a text concerning employment legislation and collective wage legislation of over 660,000 characters (a total of 92,000 words) of plain text with mark-up instructions.", "labels": [], "entities": [{"text": "collective wage legislation", "start_pos": 66, "end_pos": 93, "type": "TASK", "confidence": 0.6119987368583679}]}, {"text": "Checking the words and correcting misspelled words took 16 CPU minutes, which results in a speed of nearly 100 words per CPU second.", "labels": [], "entities": []}, {"text": "A smaller text in the same content domain (150,000 characters in 27,500 words) was checked and corrected at word level in 4.5 minutes of CPU time, which is over 100 words per CPU second.", "labels": [], "entities": []}, {"text": "Other spelling exercises also showed good results (most errors detected and most corrected properly, very few false alarms, if any).", "labels": [], "entities": []}, {"text": "A typical text was chosen from a textbook with correction exercises for pupils.", "labels": [], "entities": []}, {"text": "In contrast with the spelling test described in the previous paragraph, most sentences in this test contained more than one spelling error.", "labels": [], "entities": []}, {"text": "The errors varied from superfluous or missing diaeresis to split compounds and d/t-errors.", "labels": [], "entities": []}, {"text": "On a total of 30 sentences, the system discovered 75 errors, of which 62 were corrected properly, 12 miscorrected and one was given no correction at all; it missed 7 errors, while producing one false alarm.", "labels": [], "entities": []}, {"text": "Although the total number of words was only half the number of words in the previous test (457 to be precise), the system took almost three times as much time to process it.", "labels": [], "entities": []}, {"text": "This was partly due to the greater average sentence length (over 15 words per sentence) and the occurrence of more than one error per sentence (up to four per sentence).", "labels": [], "entities": []}, {"text": "The number of errors that could not have been detected without a parser was 18.", "labels": [], "entities": []}, {"text": "Of these, 10 were corrected and 1 was detected but substituted by a wrong alternative, while the parser missed the 7 errors mentioned earlier.", "labels": [], "entities": []}, {"text": "On large real texts, i.e. not constructed for the purpose of testing one's knowledge of spelling, the system performed less well due to parsing problems.", "labels": [], "entities": []}, {"text": "As an example of a well written text, I took the first 1000 lines of a text mentioned in footnote 7.", "labels": [], "entities": []}, {"text": "This sample consisted of 7443 words in 468 sentences (an average of nearly 16 words per sentence).", "labels": [], "entities": []}, {"text": "At word level it performed quite satisfactorily.", "labels": [], "entities": []}, {"text": "It caused 12 false alarms 8, while detecting 11 true errors, of which only 4 were properly corrected.", "labels": [], "entities": []}, {"text": "The compound analysis functioned almost flawlessly.", "labels": [], "entities": []}, {"text": "However, it caused 6 of the 12 false alarms, because one single word, which was not in the dictionary, appeared in 4 different compounds.", "labels": [], "entities": []}, {"text": "The heuristics for suspicious words cooperated very well with the spelling correcter (6 correct guesses, 2 wrong).", "labels": [], "entities": [{"text": "spelling correcter", "start_pos": 66, "end_pos": 84, "type": "METRIC", "confidence": 0.9050442278385162}]}, {"text": "The parser's performance however degraded considerably.", "labels": [], "entities": []}, {"text": "One reason was the great length of many sentences (up to 86 words).", "labels": [], "entities": []}, {"text": "This sometimes caused the parser to exceed its built-in time limit, so that it could not give a correct error message 9.", "labels": [], "entities": []}, {"text": "Long sentences are also highly ambiguous.", "labels": [], "entities": []}, {"text": "This increases the probability of finding a very awkward but errorfree parse, thereby overlooking real errors.", "labels": [], "entities": []}, {"text": "Another reason for the performance degradation was the abundant use of interjections, names (between quotes, dashes or parentheses) and colloquial (ungrammatical) expressions.", "labels": [], "entities": []}, {"text": "Although the parser has some provisions for simply skipping such con8In 4 cases, the false alarm was caused byword contraction.", "labels": [], "entities": []}, {"text": "E.g. the word echtgeno(o)t(e), which is supposed to mean echtgenoot of echtgenote (husband or wife), was marked incorrect and substituted by echtgenoot.", "labels": [], "entities": []}, {"text": "9Unfortunately, the program does not keep track of this, so no data can be specified.", "labels": [], "entities": [{"text": "9Unfortunately", "start_pos": 0, "end_pos": 14, "type": "DATASET", "confidence": 0.9472981095314026}]}, {"text": "structions, they more often than not interfere with error detection.", "labels": [], "entities": [{"text": "error detection", "start_pos": 52, "end_pos": 67, "type": "TASK", "confidence": 0.7117026895284653}]}, {"text": "Fortunately, subject-verb agreement errors indicating d/t-errors were spotted quite reliably, although their number (two in this sample, which were both corrected) is too small to draw any firm conclusion.", "labels": [], "entities": []}, {"text": "The detection of punctuation errors and split compounds still needs improvement.", "labels": [], "entities": []}, {"text": "Whether the results justify the 30 minutes CPU time it took to parse the 468 sentences remains to be seen.", "labels": [], "entities": [{"text": "parse the 468 sentences", "start_pos": 63, "end_pos": 86, "type": "TASK", "confidence": 0.8652532547712326}]}], "tableCaptions": []}