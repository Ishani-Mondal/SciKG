{"title": [{"text": "Complementing WordNet with Roget's and Corpus-based Thesauri for Information Retrieval", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 65, "end_pos": 86, "type": "TASK", "confidence": 0.7234734445810318}]}], "abstractContent": [{"text": "This paper proposes a method to overcome the drawbacks of WordNet when applied to information retrieval by complementing it with Roget's thesaurus and corpus-derived thesauri.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 82, "end_pos": 103, "type": "TASK", "confidence": 0.7031459510326385}]}, {"text": "Words and relations which are not included in WordNet can be found in the corpus-derived the-sauri.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 46, "end_pos": 53, "type": "DATASET", "confidence": 0.9600296020507812}]}, {"text": "Effects of polysemy can be minimized with weighting method considering all query terms and all of the the-sauri.", "labels": [], "entities": []}, {"text": "Experimental results show that our method enhances information retrieval performance significantly.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 51, "end_pos": 72, "type": "TASK", "confidence": 0.8392943441867828}]}], "introductionContent": [{"text": "Information retrieval (IR) systems can be viewed basically as a form of comparison between documents and queries.", "labels": [], "entities": [{"text": "Information retrieval (IR)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8378365159034729}]}, {"text": "In traditional IR methods, this comparison is done based on the use of common index terms in the document and the query.", "labels": [], "entities": [{"text": "IR", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.9673975706100464}]}, {"text": "The drawback of such methods is that if semantically relevant documents do not contain the same terms as the query, then they will be judged irrelevant by the IR system.", "labels": [], "entities": []}, {"text": "This occurs because the vocabulary that the user uses is often not the same as the one used in documents (.", "labels": [], "entities": []}, {"text": "To avoid the above problem, several researchers have suggested the addition of terms which have similar or related meaning to the query, increasing the chances of matching words in relevant documents.", "labels": [], "entities": []}, {"text": "This method is called query expansion.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 22, "end_pos": 37, "type": "TASK", "confidence": 0.807565301656723}]}, {"text": "A thesaurus contains information pertaining to paradigmatic semantic relations such as term synonymy, hypernymy, and hyponymy.", "labels": [], "entities": []}, {"text": "It is thus natural to use a thesaurus as a source for query expansion.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 54, "end_pos": 69, "type": "TASK", "confidence": 0.7641341984272003}]}, {"text": "Many researchers have used WordNet in information retrieval as a tool for query \u2022 Interrelated words may have different parts of speech.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.7034097760915756}]}, {"text": "\u2022 Most domain-specific relationships between words are not found in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 68, "end_pos": 75, "type": "DATASET", "confidence": 0.9725315570831299}]}, {"text": "\u2022 Some kinds of words are not included in WordNet, such as proper names.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.9702244400978088}]}, {"text": "To overcome all the above problems, we propose a method to enrich WordNet with Roget's Thesaurus and corpus-based thesauri.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 66, "end_pos": 73, "type": "DATASET", "confidence": 0.9198679327964783}]}, {"text": "The idea underlying this method is that the automatically constructed thesauri can counter all the above drawbacks of WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 118, "end_pos": 125, "type": "DATASET", "confidence": 0.9533114433288574}]}, {"text": "For example, as we stated earlier, proper names and their interrelations are not found in WordNet, but if proper names bear some strong relationship with other terms, they often cooccur in documents, as can be modelled by a corpus-based thesaurus.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 90, "end_pos": 97, "type": "DATASET", "confidence": 0.9350956082344055}]}, {"text": "Polysemous words degrade the precision of information retrieval since all senses of the original query term are considered for expansion.", "labels": [], "entities": [{"text": "precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9972997307777405}]}, {"text": "To overcome the problem of polysemous words, we apply a restriction in that queries are expanded by adding those terms that are most similar to the entirety of the query, rather than selecting terms that are similar to a single term in the query.", "labels": [], "entities": []}, {"text": "In the next section we describe the details of our method.", "labels": [], "entities": []}], "datasetContent": [{"text": "Experiments were carried out on the TREC-7 Collection, which consists of 528,155 documents and 50 topics (Voorhees and Harman, to appear 1999).", "labels": [], "entities": [{"text": "TREC-7 Collection", "start_pos": 36, "end_pos": 53, "type": "DATASET", "confidence": 0.9269254803657532}]}, {"text": "TREC is currently de facto standard test collection in information retrieval community.", "labels": [], "entities": [{"text": "TREC", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.4243675470352173}]}, {"text": "shows topic-length statistics, shows document statistics, and shows an example topic.", "labels": [], "entities": []}, {"text": "We use the title, description, and combined title+description+narrative of these topics.", "labels": [], "entities": []}, {"text": "Note that in the TREC-7 collection the description contains all terms in the title section.", "labels": [], "entities": [{"text": "TREC-7 collection", "start_pos": 17, "end_pos": 34, "type": "DATASET", "confidence": 0.9183657765388489}]}, {"text": "For our baseline, we used SMART version 11.0 (Salton, 1971) as information retrieval engine with the Inc.ltc weighting method.", "labels": [], "entities": [{"text": "SMART version 11.0 (Salton, 1971)", "start_pos": 26, "end_pos": 59, "type": "DATASET", "confidence": 0.6656214520335197}, {"text": "information retrieval", "start_pos": 63, "end_pos": 84, "type": "TASK", "confidence": 0.8726794719696045}]}, {"text": "SMART is an information retrieval engine based on the vector space model in which term weights are calculated based on term frequency, inverse document frequency and document length normalization.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 12, "end_pos": 33, "type": "TASK", "confidence": 0.7981860041618347}, {"text": "inverse document frequency", "start_pos": 135, "end_pos": 161, "type": "METRIC", "confidence": 0.7452028095722198}]}, {"text": "Automatic indexing of a text in SMART system involves the following steps : \u2022 Tokenization : The text is first tokenized into individual words and other tokens.", "labels": [], "entities": [{"text": "SMART", "start_pos": 32, "end_pos": 37, "type": "TASK", "confidence": 0.7758106589317322}]}, {"text": "\u2022 Stop word removal : Common function words (like the, of, an, etc.) also called stop words, are removed from this list of tokens.", "labels": [], "entities": [{"text": "Stop word removal", "start_pos": 2, "end_pos": 19, "type": "TASK", "confidence": 0.5829883913199106}]}, {"text": "The SMART system uses a predefined list of 571 stop words.", "labels": [], "entities": [{"text": "SMART", "start_pos": 4, "end_pos": 9, "type": "TASK", "confidence": 0.8955268859863281}]}, {"text": "\u2022 Stemming: Various morphological variants of a word are normalized to the same stem.", "labels": [], "entities": []}, {"text": "SMART system uses the variant of Lovin method to apply simple rules for suffix stripping.", "labels": [], "entities": [{"text": "SMART", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7440902590751648}, {"text": "suffix stripping", "start_pos": 72, "end_pos": 88, "type": "TASK", "confidence": 0.8581207096576691}]}, {"text": "\u2022 Weighting : The term (word and phrase) vector thus created fora text, is weighted using t f, idf, and length normalization considerations.", "labels": [], "entities": []}, {"text": "gives the average of non-interpolated precision using SMART without expansion (baseline), expansion using only WordNet, expansion using only the corpus-based syntactic-relationbased thesaurus, expansion using only the corpusbased co-occurrence-based thesaurus, and expansion using combined thesauri.", "labels": [], "entities": [{"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9860623478889465}, {"text": "WordNet", "start_pos": 111, "end_pos": 118, "type": "DATASET", "confidence": 0.9718037247657776}]}, {"text": "For each method we also give the relative improvement over the baseline.", "labels": [], "entities": []}, {"text": "We can see that the combined method outperform the isolated use of each type of thesaurus significantly.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1:TREC-7 Topic length statistics", "labels": [], "entities": [{"text": "TREC-7", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.8948648571968079}, {"text": "Topic length", "start_pos": 16, "end_pos": 28, "type": "TASK", "confidence": 0.7149643003940582}]}, {"text": " Table 3: Average non-interpolated precision for expansion using single or combined thesauri.", "labels": [], "entities": [{"text": "precision", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9974938631057739}]}]}