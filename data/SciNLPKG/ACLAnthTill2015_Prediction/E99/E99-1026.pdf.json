{"title": [{"text": "Japanese Dependency Structure Analysis Based on Maximum Entropy Models", "labels": [], "entities": [{"text": "Dependency Structure Analysis", "start_pos": 9, "end_pos": 38, "type": "TASK", "confidence": 0.6333380738894144}]}], "abstractContent": [{"text": "This paper describes a dependency structure analysis of Japanese sentences based on the maximum entropy models.", "labels": [], "entities": []}, {"text": "Our model is created by learning the weights of some features from a training corpus to predict the dependency between bunsetsus or phrasal units.", "labels": [], "entities": []}, {"text": "The dependency accuracy of our system is 87.2% using the Kyoto University corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9759430289268494}, {"text": "Kyoto University corpus", "start_pos": 57, "end_pos": 80, "type": "DATASET", "confidence": 0.9855480392773946}]}, {"text": "We discuss the contribution of each feature set and the relationship between the number of training data and the accuracy .", "labels": [], "entities": [{"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9987989664077759}]}], "introductionContent": [{"text": "Dependency structure analysis is one of the basic techniques in Japanese sentence analysis.", "labels": [], "entities": [{"text": "Dependency structure analysis", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8695395986239115}, {"text": "Japanese sentence analysis", "start_pos": 64, "end_pos": 90, "type": "TASK", "confidence": 0.6302565733591715}]}, {"text": "The Japanese dependency structure is usually represented by the relationship between phrasal units called 'bunsetsu.'", "labels": [], "entities": []}, {"text": "The analysis has two conceptual steps.", "labels": [], "entities": []}, {"text": "In the first step, a dependency matrix is prepared.", "labels": [], "entities": []}, {"text": "Each element of the matrix represents how likely one bunsetsu is to depend on the other.", "labels": [], "entities": []}, {"text": "In the second step, an optimal set of dependencies for the entire sentence is found.", "labels": [], "entities": []}, {"text": "In this paper, we will mainly discuss the first step, a model for estimating dependency likelihood.", "labels": [], "entities": [{"text": "estimating dependency likelihood", "start_pos": 66, "end_pos": 98, "type": "TASK", "confidence": 0.7201562523841858}]}, {"text": "So far there have been two different approaches to estimating the dependency likelihood, One is the rule-based approach, in which the rules are created by experts and likelihoods are calculated by some means, including semiautomatic corpusbased methods but also by manual assignment of scores for rules.", "labels": [], "entities": []}, {"text": "However, hand-crafted rules have the following problems.", "labels": [], "entities": []}, {"text": "\u2022 They have a problem with their coverage.", "labels": [], "entities": []}, {"text": "Because there are many features to find correct dependencies, it is difficult to find them manually.", "labels": [], "entities": []}, {"text": "\u2022 They also have a problem with their consistency, since many of the features compete with each other and humans cannot create consistent rules or assign consistent scores.", "labels": [], "entities": [{"text": "consistency", "start_pos": 38, "end_pos": 49, "type": "METRIC", "confidence": 0.9916894435882568}]}, {"text": "\u2022 As syntactic characteristics differ across different domains, the rules have to be changed when the target domain changes.", "labels": [], "entities": []}, {"text": "It is costly to create anew hand-made rule for each domain.", "labels": [], "entities": []}, {"text": "At/other approach is a fully automatic corpusbased approach.", "labels": [], "entities": []}, {"text": "This approach has the potential to overcome the problems of the rule-based approach.", "labels": [], "entities": []}, {"text": "It automatically learns the likelihoods of dependencies from a tagged corpus and calculates the best dependencies for an input sentence.", "labels": [], "entities": []}, {"text": "This approach is taken by some other systems).", "labels": [], "entities": []}, {"text": "The parser proposed by) is considered to be one of the most accurate parsers in English.", "labels": [], "entities": []}, {"text": "Its probability estimation is based on the maximum entropy models.", "labels": [], "entities": []}, {"text": "We also use the maximum entropy model.", "labels": [], "entities": []}, {"text": "This model learns the weights of given features from a training corpus.", "labels": [], "entities": []}, {"text": "The weights are calculated based on the frequencies of the features in the training data.", "labels": [], "entities": []}, {"text": "The set of features is defined by a human.", "labels": [], "entities": []}, {"text": "In our model, we use features of bunsetsu, such as character strings, parts of speech, and inflection types of bunsetsu, as well as information between bunsetsus, such as the existence of punctuation, and the distance between bunsetsus.", "labels": [], "entities": []}, {"text": "The probabilities of dependencies are estimated from the model by using those features in input sentences.", "labels": [], "entities": []}, {"text": "We assume that the overall dependencies in a whole sentence can be determined as the product of the probabilities of all the dependencies in the sentence.", "labels": [], "entities": []}, {"text": "Now, we briefly describe the algorithm of dependency analysis.", "labels": [], "entities": [{"text": "dependency analysis", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.9117982089519501}]}, {"text": "It is said that Japanese dependencies have the following characteristics.", "labels": [], "entities": []}, {"text": "(1) Dependencies are directed from left to right (2) Dependencies do not cross (3) A bunsetsu, except for the rightmost one, depends on only one bunsetsu (4) In many cases, the left context is not necessary to determine a dependency 1 The analysis method proposed in this paper is designed to utilize these features.", "labels": [], "entities": []}, {"text": "Based on these properties, we detect the dependencies in a sentence by analyzing it backwards (from right to left).", "labels": [], "entities": []}, {"text": "In the past, such a backward algorithm has been used with rule-based parsers (e.g.,).", "labels": [], "entities": []}, {"text": "We applied it to our statistically based approach.", "labels": [], "entities": []}, {"text": "Because of the statistical property, we can incorporate abeam search, an effective way of limiting the search space in a backward analysis.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiment, we used the Kyoto University text corpus (version 2)), a tagged corpus of the Mainichi newspaper.", "labels": [], "entities": [{"text": "Kyoto University text corpus", "start_pos": 31, "end_pos": 59, "type": "DATASET", "confidence": 0.9579790830612183}, {"text": "Mainichi newspaper", "start_pos": 97, "end_pos": 115, "type": "DATASET", "confidence": 0.9705018103122711}]}, {"text": "For training we used 7,958 sentences from newspaper articles appearing from January 1st to January 8th, and for testing we used 1,246 sentences from articles appearing on January 9th.", "labels": [], "entities": []}, {"text": "The input sentences were morphologically analyzed and their bunsetsus were identified.", "labels": [], "entities": []}, {"text": "We assumed that this preprocessing was done correctly before parsing input sentences.", "labels": [], "entities": [{"text": "parsing input sentences", "start_pos": 61, "end_pos": 84, "type": "TASK", "confidence": 0.8371586203575134}]}, {"text": "If we used automatic morphological analysis and bunsetsu identification, the parsing accuracy would not decrease so much because the rightmost element in a bunsetsu is usually a case marker, a verb ending, or a adjective ending, and each of these is easily recognized.", "labels": [], "entities": [{"text": "bunsetsu identification", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.6878922581672668}, {"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9830449819564819}]}, {"text": "The automatic preprocessing by using public domain tools, for example, can achieve 97% for morphological analysis () and 99% for bunsetsu identification ().", "labels": [], "entities": [{"text": "bunsetsu identification", "start_pos": 129, "end_pos": 152, "type": "TASK", "confidence": 0.7348310053348541}]}, {"text": "We employed the Maximum Entropy tool made by, which requires one to specify the number of iterations for learning.", "labels": [], "entities": []}, {"text": "We set this number to 400 in all our experiments.", "labels": [], "entities": []}, {"text": "In the following sections, we show the features used in our experiments and the results.", "labels": [], "entities": []}, {"text": "Then we describe some interesting statistics that we found in our experiments.", "labels": [], "entities": []}, {"text": "Finally, we compare our work with some related systems.", "labels": [], "entities": []}, {"text": "The features used in our experiments are listed in.", "labels": [], "entities": []}, {"text": "Each row in contains a feature type, feature values, and an experimental result that will be explained later.", "labels": [], "entities": []}, {"text": "Each feature consists of a type and a value.", "labels": [], "entities": []}, {"text": "The features are basically some attributes of a bunsetsu itself or those between bunsetsus.", "labels": [], "entities": []}, {"text": "We call them 'basic features.'", "labels": [], "entities": []}, {"text": "The list is expanded from tIaruno's list ().", "labels": [], "entities": [{"text": "tIaruno's list", "start_pos": 26, "end_pos": 40, "type": "DATASET", "confidence": 0.9315265615781149}]}, {"text": "The features in the list are classified into five categories that are related to the \"Head\" part of the anterior bunsetsu (category \"a\"), the '~rype\" part of the anterior bunsetsu (category \"b\"), the \"Head\" part of the posterior bunsetsu (category \"c\"), the '~l~ype \" part of the posterior bunsetsu (category \"d\"), and the features between bunsetsus (category \"e\") respectively.", "labels": [], "entities": []}, {"text": "The term \"Head\" basically means a rightmost content word in a bunsetsu, and the term \"Type\" basically means a function word following a \"Head\" word or an inflection type of a \"Head\" word.", "labels": [], "entities": []}, {"text": "The terms are defined in the following paragraph.", "labels": [], "entities": []}, {"text": "The features in are combinations of basic features ('combined features').", "labels": [], "entities": []}, {"text": "They are represented by the corresponding category name of basic features, and each feature set is represented by the feature numbers of the corresponding basic features.", "labels": [], "entities": []}, {"text": "They are classified into nine categories we constructed manually.", "labels": [], "entities": []}, {"text": "For example, twin features are combinations of the features related to the categories %\" and \"c.\"", "labels": [], "entities": []}, {"text": "Triplet, quadruplet and quintuplet features basically consist of the twin features plus the features of the remainder categories \"a,\" \"d\" and \"e.\"", "labels": [], "entities": []}, {"text": "The total number of features is about 600,000.", "labels": [], "entities": []}, {"text": "Among them, 40,893 were observed in the training corpus, and we used them in our experiment.", "labels": [], "entities": []}, {"text": "The terms used in the table are the following: Anterior: left bunsetsu of the dependency Posterior: right bunsetsu of the dependency Head: the rightmost word in a bunsetsu other than those whose major part-of-speech 2 category is \"~ (special marks),\" \"1~ (postpositional particles),\" or \"~ (suffix)\" 2Part-of-speech categories follow those of JU-MAN().", "labels": [], "entities": [{"text": "JU-MAN", "start_pos": 343, "end_pos": 349, "type": "DATASET", "confidence": 0.9226401448249817}]}, {"text": "BW-IDto-Anterior-Type means if there is a bunsetsu whose type is identical to that of the anterior bunsetsu between bunsetsus BW-IDto-Anterior-Type-Head-P OS: the part-of-speech category of the headword of the bunsetsu of \"BW-IDto-Anterior-Type\" BW-IDto-Posterior-Head: if there is between bunsetsus a bunsetsu whose head is identical to that of the posterior bunsetsu BW-IDto-Posterior-Head-Type(String): the lexical information of the bunsetsu \"BWIDto-Posterior-Head\" The results of our experiment are listed in Table 3.", "labels": [], "entities": []}, {"text": "The dependency accuracy means the percentage of correct dependencies out of all dependencies.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9499250650405884}]}, {"text": "The sentence accuracy means the percentage of sentences in which all dependencies were analyzed correctly.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.980627715587616}]}, {"text": "We used input sentences that had already been morphologically analyzed and for which bunsetsus had been identified.", "labels": [], "entities": []}, {"text": "The first line in Table 3 (deterministic) shows the accuracy achieved when the test sentences were analyzed deterministically (beam width k = 1).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9995551705360413}]}, {"text": "The second line in (best beam search) shows the best accuracy among the experiments when changing the beam breadth k from 1 to 20.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.999502420425415}, {"text": "beam breadth k", "start_pos": 102, "end_pos": 116, "type": "METRIC", "confidence": 0.7263755202293396}]}, {"text": "The best accuracy was achieved when k = 11, although the variation inaccuracy was very small.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9994516968727112}]}], "tableCaptions": [{"text": " Table 1: Features (basic features)", "labels": [], "entities": []}, {"text": " Table 2: Features (combined features)", "labels": [], "entities": []}, {"text": " Table 3: Results of dependency analysis", "labels": [], "entities": [{"text": "dependency analysis", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.8362502455711365}]}]}