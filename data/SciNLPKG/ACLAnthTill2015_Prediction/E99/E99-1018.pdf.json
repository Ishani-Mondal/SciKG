{"title": [{"text": "POS Disambiguation and Unknown Word Guessing with Decision Trees", "labels": [], "entities": [{"text": "POS Disambiguation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7744145691394806}, {"text": "Unknown Word Guessing", "start_pos": 23, "end_pos": 44, "type": "TASK", "confidence": 0.5674862464269003}]}], "abstractContent": [{"text": "This paper presents a decision-tree approach to the problems of part-of-speech disambiguation and unknown word guessing as they appear in Modem Greek, a highly inflectional language.", "labels": [], "entities": [{"text": "part-of-speech disambiguation", "start_pos": 64, "end_pos": 93, "type": "TASK", "confidence": 0.7312362790107727}, {"text": "unknown word guessing", "start_pos": 98, "end_pos": 119, "type": "TASK", "confidence": 0.647256334622701}]}, {"text": "The learning procedure is tag-set independent and reflects the linguistic reasoning on the specific problems.", "labels": [], "entities": []}, {"text": "The decision trees induced are combined with a high-coverage lexicon to form a tagger that achieves 93,5% overall disambiguation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.9912381768226624}]}], "introductionContent": [{"text": "Part-of-speech (POS) taggers are software devices that aim to assign unambiguous morphosyntactic tags to words of electronic texts.", "labels": [], "entities": [{"text": "Part-of-speech (POS) taggers", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6135652184486389}]}, {"text": "Although the hardest part of the tagging process is performed by a computational lexicon, a POS tagger cannot solely consist of a lexicon due to: (i) morphosyntactic ambiguity (e.g., 'love' as verb or noun) and (ii) the existence of unknown words (e.g., proper nouns, place names, compounds, etc.).", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 92, "end_pos": 102, "type": "TASK", "confidence": 0.7779287993907928}]}, {"text": "When the lexicon can assure high coverage, unknown word guessing can be viewed as a decision taken upon the POS of open-class words (i.e., Noun, Verb, Adjective, Adverb or Participle).", "labels": [], "entities": [{"text": "unknown word guessing", "start_pos": 43, "end_pos": 64, "type": "TASK", "confidence": 0.6487371126810709}]}, {"text": "Towards the disambiguation of POS tags, two main approaches have been followed.", "labels": [], "entities": []}, {"text": "On one hand, according to the linguistic approach, experts encode handcrafted rules or constraints based on abstractions derived from language paradigms (usually with the aid of corpora)).", "labels": [], "entities": []}, {"text": "On the other hand, according to the data-driven approach, a frequency-based language model is acquired from corpora and has the forms of ngrams, rules, decision trees or neural networks.", "labels": [], "entities": []}, {"text": "In order to increase their robusmess, most POS taggers include a guesser, which tries to extract the POS of words not present in the lexicon.", "labels": [], "entities": [{"text": "robusmess", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9161900877952576}, {"text": "POS taggers", "start_pos": 43, "end_pos": 54, "type": "TASK", "confidence": 0.7912775576114655}]}, {"text": "As a common strategy, POS guessers examine the endings of unknown words) along with their capitalization, or consider the distribution of unknown words over specific parts-of-speech.", "labels": [], "entities": [{"text": "POS guessers", "start_pos": 22, "end_pos": 34, "type": "TASK", "confidence": 0.9310540854930878}]}, {"text": "More sophisticated guessers further examine the prefixes of unknown words and the categories of contextual tokens.", "labels": [], "entities": []}, {"text": "This paper presents a POS tagger for Modem Greek (M. Greek), a highly inflectional language, and focuses on a data-driven approach for the induction of decision trees used as disambiguation/guessing devices.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 22, "end_pos": 32, "type": "TASK", "confidence": 0.7220848202705383}, {"text": "Modem Greek (M. Greek)", "start_pos": 37, "end_pos": 59, "type": "DATASET", "confidence": 0.6746773570775986}]}, {"text": "Based on a high-coverage 1 lexicon, we prepared a tagged corpus capable of showing off the behavior of all POS ambiguity schemes present in M.", "labels": [], "entities": []}, {"text": "Greek (e.g., Pronoun-Clitic-Article, Pronoun-Clitic, Adjective-Adverb, Verb-Noun, etc.), as well as the characteristics of unknown words.", "labels": [], "entities": []}, {"text": "Consequently, we used the corpus for the induction of decision trees, which, along with 1 At present, the lexicon is capable of assigning full morphosyntactic attributes (i.e., POS, Number, Gender, Case, Person, Tense, Voice, Mood) to -870.000 Greek word-forms.", "labels": [], "entities": []}, {"text": "the lexicon, are integrated into a robust POS tagger for M.", "labels": [], "entities": []}, {"text": "The disambiguating methodology followed is highly influenced by the Memory-Based Tagger (MBT) presented in.", "labels": [], "entities": [{"text": "Memory-Based Tagger (MBT)", "start_pos": 68, "end_pos": 93, "type": "TASK", "confidence": 0.6421019315719605}]}, {"text": "Our main contribution is the successful application of the decision-tree methodology to M.", "labels": [], "entities": [{"text": "M", "start_pos": 88, "end_pos": 89, "type": "TASK", "confidence": 0.9527403116226196}]}, {"text": "Greek with three improvements/customizations: (i) injection of linguistic bias to the learning procedure, (ii) formation of tag-set independent training patterns, and (iii) handling of set-valued features.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our approach, we first partitioned the datasets described in Section 3 into training and testing sets according to the 10-fold crossvalidation methodL Then, (a) we found the most frequent POS in each training set and (b) we induced a decision tree from each training set.", "labels": [], "entities": []}, {"text": "Consequently, we resolved the ambiguity of the testing sets with two methods: (a) we assigned the most frequent POS acquired from the corresponding training sets and (b) we used the induced decision trees.", "labels": [], "entities": [{"text": "POS", "start_pos": 112, "end_pos": 115, "type": "METRIC", "confidence": 0.9697256684303284}]}, {"text": "concentrates the results of our experiments.", "labels": [], "entities": []}, {"text": "In detail: Column (1) shows in what percentage the ambiguity schemes and the unknown words occur in the corpus.", "labels": [], "entities": []}, {"text": "The total problematic word-tokens in the corpus are 23,38%.", "labels": [], "entities": []}, {"text": "Column (2) shows in what percentage each ambiguity scheme contributes to the total POS ambiguity.", "labels": [], "entities": []}, {"text": "Column (3) shows the error rates of method (a).", "labels": [], "entities": []}, {"text": "Column (4) shows the error rates of method (b).", "labels": [], "entities": []}, {"text": "To compute the total POS disambiguation error rates of the two methods (24,1% and 5,48% respectively) we used the contribution percentages shown in column (2).", "labels": [], "entities": [{"text": "POS disambiguation error rates", "start_pos": 21, "end_pos": 51, "type": "METRIC", "confidence": 0.7269802987575531}]}], "tableCaptions": [{"text": " Table 1. An example-sentence from the tagged corpus", "labels": [], "entities": []}, {"text": " Table 3. Statistics and Evaluation Measurements", "labels": [], "entities": []}]}