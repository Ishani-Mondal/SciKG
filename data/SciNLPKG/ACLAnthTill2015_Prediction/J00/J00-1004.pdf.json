{"title": [{"text": "Learning Dependency Translation Models as Collections of Finite-State Head Transducers", "labels": [], "entities": [{"text": "Learning Dependency Translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.5689581036567688}]}], "abstractContent": [{"text": "The paper defines weighted head transducers,finite-state machines that perform middle-out string transduction.", "labels": [], "entities": [{"text": "middle-out string transduction", "start_pos": 79, "end_pos": 109, "type": "TASK", "confidence": 0.7022998332977295}]}, {"text": "These transducers are strictly more expressive than the special case of standard left-to-right finite-state transducers.", "labels": [], "entities": []}, {"text": "Dependency transduction models are then defined as collections of weighted head transducers that are applied hierarchically.", "labels": [], "entities": [{"text": "Dependency transduction", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.7580283880233765}]}, {"text": "A dynamic programming search algorithm is described for finding the optimal transduction of an input string with respect to a dependency transduction model.", "labels": [], "entities": []}, {"text": "A method for automatically training a dependency transduc-tion model from a set of input-output example strings is presented.", "labels": [], "entities": []}, {"text": "The method first searches for hierarchical alignments of the training examples guided by correlation statistics, and then constructs the transitions of head transducers that are consistent with these alignments.", "labels": [], "entities": []}, {"text": "Experimental results are given for applying the training method to translation from English to Spanish and Japanese.", "labels": [], "entities": [{"text": "translation from English to Spanish", "start_pos": 67, "end_pos": 102, "type": "TASK", "confidence": 0.8320945024490356}]}], "introductionContent": [{"text": "We will define a dependency transduction model in terms of a collection of weighted head transducers.", "labels": [], "entities": []}, {"text": "Each head transducer is a finite-state machine that differs from \"standard\" finite-state transducers in that, instead of consuming the input string left to right, it consumes it \"middle out\" from a symbol in the string.", "labels": [], "entities": []}, {"text": "Similarly, the output of ahead transducer is built up middle out at positions relative to a symbol in the output string.", "labels": [], "entities": []}, {"text": "The resulting finite-state machines are more expressive than standard left-to-right transducers.", "labels": [], "entities": []}, {"text": "In particular, they allow long-distance movement with fewer states than a traditional finite-state transducer, a useful property for the translation task to which we apply them in this paper.", "labels": [], "entities": [{"text": "translation task", "start_pos": 137, "end_pos": 153, "type": "TASK", "confidence": 0.8939114809036255}]}, {"text": "(In fact, finite-state head transducers are capable of unbounded movement with a finite number of states.)", "labels": [], "entities": []}, {"text": "In Section 2, we introduce head transducers and explain how input-output positions on state transitions result in middle-out transduction.", "labels": [], "entities": []}, {"text": "When applied to the problem of translation, the head transducers forming the dependency transduction model operate on input and output strings that are sequences of dependents of corresponding headwords in the source and target languages.", "labels": [], "entities": []}, {"text": "The dependency transduction model produces synchronized dependency trees in which each local tree is produced by ahead transducer.", "labels": [], "entities": []}, {"text": "In other words, the dependency model applies the head transducers recursively, imposing a recursive decomposition of the source and target strings.", "labels": [], "entities": []}, {"text": "A dynamic programming search algorithm finds optimal (lowest total weight) derivations of target strings from input strings or word lattices produced by a speech recognizer.", "labels": [], "entities": []}, {"text": "Section 3 defines dependency transduction models and describes the search algorithm.", "labels": [], "entities": []}, {"text": "We construct the dependency transduction models for translation automatically from a set of unannotated examples, each example comprising a source string and a corresponding target string.", "labels": [], "entities": []}, {"text": "The recursive decomposition of the training examples results from an algorithm for computing hierarchical alignments of the examples, described in Section 4.2.", "labels": [], "entities": []}, {"text": "This alignment algorithm uses dynamic programming search guided by source-target word correlation statistics as described in Section 4.1.", "labels": [], "entities": []}, {"text": "Having constructed a hierarchical alignment for the training examples, a set of head transducer transitions are constructed from each example as described in Section 4.3.", "labels": [], "entities": []}, {"text": "Finally, the dependency transduction model is constructed by aggregating the resulting head transducers and assigning transition weights, which are log probabilities computed from the training counts by simple maximum likelihood estimation.", "labels": [], "entities": [{"text": "dependency transduction", "start_pos": 13, "end_pos": 36, "type": "TASK", "confidence": 0.7667142450809479}]}, {"text": "We have applied this method of training statistical dependency transduction models in experiments on English-to-Spanish and English-to-Japanese translations of transcribed spoken utterances.", "labels": [], "entities": []}, {"text": "The results of these experiments are described in Section 5; our concluding remarks are in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to reduce the time required to carryout training evaluation experiments, we have chosen two simple, string-based evaluation metrics that can be calculated automatically.", "labels": [], "entities": []}, {"text": "These metrics, simple accuracy and translation accuracy, are used to compare the target string produced by the system against a reference human translation from held-out data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9031108021736145}, {"text": "translation", "start_pos": 35, "end_pos": 46, "type": "TASK", "confidence": 0.8350910544395447}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.7509246468544006}]}, {"text": "Simple accuracy is computed by first finding a transformation of one string into another that minimizes the total weight of insertions, deletions, and substitutions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.9921735525131226}]}, {"text": "(We use the same weights for these operations as in the NIST ASR evaluation software [National Institute of.)", "labels": [], "entities": [{"text": "NIST ASR evaluation software", "start_pos": 56, "end_pos": 84, "type": "DATASET", "confidence": 0.8388195484876633}, {"text": "National Institute", "start_pos": 86, "end_pos": 104, "type": "DATASET", "confidence": 0.7849805355072021}]}, {"text": "Translation accuracy includes transpositions (i.e., movement) of words as well as insertions, deletions, and substitutions.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9269828200340271}, {"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.8175702095031738}]}, {"text": "We regard the latter metric as more appropriate for evaluation of translation systems because the simple metric would count a transposition as two errors: an insertion plus a deletion.", "labels": [], "entities": []}, {"text": "(This issue does not arise for speech recognizers because these systems do not normally make transposition errors.)", "labels": [], "entities": [{"text": "speech recognizers", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.6971375644207001}]}, {"text": "For the lowest edit-distance transformation between the reference translation and system output, if we write I for the number of insertions, D for deletions, S for substitutions, and R for number of words in the reference translation string, we can express simple accuracy as simple accuracy Similarly, if T is the number of transpositions in the lowest weight transformation including transpositions, we can express translation accuracy as Since a transposition corresponds to an insertion and a deletion, the values of I ~ and D ~ for translation accuracy will, in general, be different from I and D in the computation of simple accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 264, "end_pos": 272, "type": "METRIC", "confidence": 0.7015104293823242}, {"text": "accuracy", "start_pos": 283, "end_pos": 291, "type": "METRIC", "confidence": 0.7731078267097473}, {"text": "accuracy", "start_pos": 429, "end_pos": 437, "type": "METRIC", "confidence": 0.8948217034339905}, {"text": "accuracy", "start_pos": 549, "end_pos": 557, "type": "METRIC", "confidence": 0.7488741874694824}]}, {"text": "For Spanish, the units for string operations in the evaluation metrics are words, whereas for Japanese they are Japanese characters.", "labels": [], "entities": []}, {"text": "The vocabularies in these English-Spanish and English-Japanese experiments are only a few thousand words; the utterances are fairly short (an average of 7.3 words per utterance) and often contain errors typical of spoken language.", "labels": [], "entities": []}, {"text": "So while the domains maybe representative of task-oriented dialogue settings, further experimentation would be needed to assess the effectiveness of our method in situations such as translating newspaper articles.", "labels": [], "entities": [{"text": "translating newspaper articles", "start_pos": 182, "end_pos": 212, "type": "TASK", "confidence": 0.8884801268577576}]}, {"text": "In terms of the training data required, provide indirect empirical evidence suggesting accuracy can be further improved by increasing the size of our training sets, though also suggesting that the learning curve is relatively shallow beyond the current size of corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9991948008537292}]}], "tableCaptions": [{"text": " Table 1  Simple accuracy/translation accuracy (percent) for the trained  English-to-Spanish model (e2s) against the word-for-word baseline", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9943776726722717}, {"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.8970593214035034}]}]}