{"title": [{"text": "Learning Hybrid Representations to Retrieve Semantically Equivalent Questions", "labels": [], "entities": []}], "abstractContent": [{"text": "Retrieving similar questions in online Q&A community sites is a difficult task because different users may formulate the same question in a variety of ways, using different vocabulary and structure.", "labels": [], "entities": [{"text": "Retrieving similar questions in online Q&A community", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.8920057945781283}]}, {"text": "In this work, we propose anew neural network architecture to perform the task of semantically equivalent question retrieval.", "labels": [], "entities": [{"text": "semantically equivalent question retrieval", "start_pos": 81, "end_pos": 123, "type": "TASK", "confidence": 0.574763298034668}]}, {"text": "The proposed architecture, which we call BOW-CNN, combines a bag-of-words (BOW) representation with a distributed vector representation created by a convolutional neural network (CNN).", "labels": [], "entities": []}, {"text": "We perform experiments using data collected from two Stack Exchange communities.", "labels": [], "entities": []}, {"text": "Our experimental results evidence that: (1) BOW-CNN is more effective than BOW based information retrieval methods such as TFIDF; (2) BOW-CNN is more robust than the pure CNN for long texts.", "labels": [], "entities": [{"text": "BOW-CNN", "start_pos": 44, "end_pos": 51, "type": "METRIC", "confidence": 0.7164186239242554}, {"text": "BOW-CNN", "start_pos": 134, "end_pos": 141, "type": "METRIC", "confidence": 0.794638991355896}]}], "introductionContent": [{"text": "Most Question-answering (Q&A) community sites advise users before posting anew question to search for similar questions.", "labels": [], "entities": [{"text": "Question-answering (Q&A) community", "start_pos": 5, "end_pos": 39, "type": "TASK", "confidence": 0.7873577305248806}]}, {"text": "This is not always an easy task because different users may formulate the same question in a variety of ways.", "labels": [], "entities": []}, {"text": "We define two questions as semantically equivalent if they can be adequately answered by the exact same answer.", "labels": [], "entities": []}, {"text": "Here is an example of a pair of such questions from Ask Ubuntu community, which is part of the Stack Exchange Q&A community site: (q 1 )\"I have downloaded ISO files recently.", "labels": [], "entities": [{"text": "Ask Ubuntu community", "start_pos": 52, "end_pos": 72, "type": "DATASET", "confidence": 0.854063073794047}, {"text": "Stack Exchange Q&A community site", "start_pos": 95, "end_pos": 128, "type": "DATASET", "confidence": 0.681139383997236}]}, {"text": "How do I burn it to a CD or DVD or mount it?\" and (q 2 )\"I need to copy the iso file for Ubuntu 12.04 to a CD-R in Win8.", "labels": [], "entities": []}, {"text": "How do I do so?\".", "labels": [], "entities": []}, {"text": "Retrieving semantically equivalent questions is a challenging task due to two main factors: (1) the same question can be rephrased in many different ways; and (2) two questions maybe different but may refer implicitly to a common problem with the same answer.", "labels": [], "entities": [{"text": "Retrieving semantically equivalent questions", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.9023985117673874}]}, {"text": "Therefore, traditional similarity measures based on word overlap such as shingling and Jaccard coefficient and its variations ( are notable to capture many cases of semantic equivalence.", "labels": [], "entities": []}, {"text": "To capture the semantic relationship between pair of questions, different strategies have been used such as machine translation, knowledge graphs () and topic modelling.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.745306670665741}, {"text": "topic modelling", "start_pos": 153, "end_pos": 168, "type": "TASK", "confidence": 0.8336435854434967}]}, {"text": "Recent papers) have shown the effectiveness of convolutional neural networks (CNN) for sentence-level analysis of short texts in a variety of different natural language processing and information retrieval tasks.", "labels": [], "entities": [{"text": "sentence-level analysis of short texts", "start_pos": 87, "end_pos": 125, "type": "TASK", "confidence": 0.743048119544983}, {"text": "information retrieval", "start_pos": 184, "end_pos": 205, "type": "TASK", "confidence": 0.6877816021442413}]}, {"text": "This motivated us to investigate CNNs for the task of semantically equivalent question retrieval.", "labels": [], "entities": [{"text": "semantically equivalent question retrieval", "start_pos": 54, "end_pos": 96, "type": "TASK", "confidence": 0.5860972851514816}]}, {"text": "However, given the fact that the size of a question in an online community may vary from a single sentence to a detailed problem description with several sentences, it was not clear that the CNN representation would be the most adequate.", "labels": [], "entities": []}, {"text": "In this paper, we propose a hybrid neural network architecture, which we call BOW-CNN.", "labels": [], "entities": [{"text": "BOW-CNN", "start_pos": 78, "end_pos": 85, "type": "METRIC", "confidence": 0.4766608774662018}]}, {"text": "It combines a traditional bag-of-words (BOW) representation with a distributed vector representation created by a CNN, to retrieve semantically equivalent questions.", "labels": [], "entities": []}, {"text": "Using a ranking loss function in the training, BOW-CNN learns to represent questions while learning to rank them according to their semantic similarity.", "labels": [], "entities": []}, {"text": "We evaluate BOW-CNN over two different Q&A communities in the Stack Exchange site, comparing it against CNN and 6 well-established information retrieval algorithms based on BOW.", "labels": [], "entities": [{"text": "Stack Exchange site", "start_pos": 62, "end_pos": 81, "type": "DATASET", "confidence": 0.8664537469546}, {"text": "CNN", "start_pos": 104, "end_pos": 107, "type": "DATASET", "confidence": 0.9114745259284973}]}, {"text": "The results show that our proposed solution outperforms BOW-based information retrieval methods such as the term frequency -inverse document frequency (TFIDF) in all evalu- ated scenarios.", "labels": [], "entities": [{"text": "BOW-based information retrieval", "start_pos": 56, "end_pos": 87, "type": "TASK", "confidence": 0.5861345827579498}, {"text": "frequency -inverse document frequency (TFIDF)", "start_pos": 113, "end_pos": 158, "type": "METRIC", "confidence": 0.7967647463083267}]}, {"text": "Moreover, we were able to show that for short texts (title of the questions), an approach using only CNN obtains the best results, whereas for long texts (title and body of the questions), our hybrid approach (BOW-CNN) is more effective.", "labels": [], "entities": [{"text": "BOW-CNN", "start_pos": 210, "end_pos": 217, "type": "METRIC", "confidence": 0.8247354626655579}]}], "datasetContent": [{"text": "In, we present the question retrieval performance (Accuracy@k) of different algorithms over the AskUbuntu and English datasets for the title and all settings, respectively.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9968308806419373}, {"text": "AskUbuntu and English datasets", "start_pos": 96, "end_pos": 126, "type": "DATASET", "confidence": 0.6902050003409386}]}, {"text": "For both datasets, BOW-CNN outperforms the six IR algorithms for both title and all settings.", "labels": [], "entities": [{"text": "BOW-CNN", "start_pos": 19, "end_pos": 26, "type": "METRIC", "confidence": 0.9768834114074707}]}, {"text": "For the AskUbuntu all, BOW-CNN is four absolute points larger than the   best IR baseline (LMJ) in terms of Accuracy@1, which represents an improvement of 21.9%.", "labels": [], "entities": [{"text": "BOW-CNN", "start_pos": 23, "end_pos": 30, "type": "METRIC", "confidence": 0.9903978109359741}, {"text": "IR baseline (LMJ)", "start_pos": 78, "end_pos": 95, "type": "METRIC", "confidence": 0.9295756697654725}, {"text": "Accuracy@1", "start_pos": 108, "end_pos": 118, "type": "METRIC", "confidence": 0.9601624608039856}]}, {"text": "Since the BOW representation we use is closely related to TFIDF, an important comparison is the performance of BOW-CNN vs. TFIDF.", "labels": [], "entities": []}, {"text": "In, we can see that BOW-CNN consistently outperforms the TFIDF model in the two datasets for both cases title and all.", "labels": [], "entities": [{"text": "BOW-CNN", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.8125460743904114}, {"text": "TFIDF", "start_pos": 57, "end_pos": 62, "type": "METRIC", "confidence": 0.8576800227165222}]}, {"text": "These findings suggest that BOW-CNN is indeed combining the strong semantic representation power conveyed by the convolutional-based representation to, jointly with the BOW representation, construct a more effective model.", "labels": [], "entities": []}, {"text": "Another interesting finding is that CNN outperforms BOW-CNN for short texts and, conversely, BOW-CNN outperforms CNN for long texts).", "labels": [], "entities": [{"text": "BOW-CNN", "start_pos": 52, "end_pos": 59, "type": "METRIC", "confidence": 0.6428145170211792}, {"text": "BOW-CNN", "start_pos": 93, "end_pos": 100, "type": "METRIC", "confidence": 0.8581157922744751}]}, {"text": "This demonstrates that, when dealing with large input texts, BOW-CNN is an effective approach to combine the strengths of convolutional-based representation and BOW.", "labels": [], "entities": []}, {"text": "Impact of Initialization of BOW Weights.", "labels": [], "entities": [{"text": "Initialization of BOW Weights", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.6069892197847366}]}, {"text": "In the BOW-CNN experiments whose results are presented in tables 3 and 4 we initialize the elements of the BOW weight vector t with the IDF of each word in V computed over the question set Q.", "labels": [], "entities": [{"text": "IDF", "start_pos": 136, "end_pos": 139, "type": "METRIC", "confidence": 0.9965289235115051}]}, {"text": "In this section we show some experimental results that indicate the contribution of this initialization.", "labels": [], "entities": []}, {"text": "In, we present the performance of BOW-CNN for the English dataset when different configurations of the BOW weight vector tare used.", "labels": [], "entities": [{"text": "English dataset", "start_pos": 50, "end_pos": 65, "type": "DATASET", "confidence": 0.8485386669635773}]}, {"text": "The first column of indicates the type of initialization, where ones means that t is initialized with the value 1 (one) in all positions.", "labels": [], "entities": []}, {"text": "The second column informs whether t is allowed to be updated (Yes) by the network or not (No).", "labels": [], "entities": []}, {"text": "The numbers suggest that letting BOW weights free to be updated by the network produces better results than fixing them to IDF values.", "labels": [], "entities": [{"text": "IDF", "start_pos": 123, "end_pos": 126, "type": "METRIC", "confidence": 0.9576325416564941}]}, {"text": "In addition, using IDF to initialize the BOW weight vector is better than using the same weight (ones) to initialize it.", "labels": [], "entities": [{"text": "IDF", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.966718852519989}, {"text": "BOW weight vector", "start_pos": 41, "end_pos": 58, "type": "DATASET", "confidence": 0.5671450793743134}]}, {"text": "This is expected, since we are injecting a prior knowledge known to be helpful in IR tasks.", "labels": [], "entities": [{"text": "IR tasks", "start_pos": 82, "end_pos": 90, "type": "TASK", "confidence": 0.9378780126571655}]}], "tableCaptions": [{"text": " Table 1: Partition of training, validation and test  sets for the experiments.", "labels": [], "entities": []}, {"text": " Table 2: Neural Network Hyper-Parameters", "labels": [], "entities": []}, {"text": " Table 3: Question title retrieval performance (Ac- curacy@k) for different algorithms.", "labels": [], "entities": [{"text": "Question title retrieval", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.6239978969097137}, {"text": "Ac- curacy@k)", "start_pos": 48, "end_pos": 61, "type": "METRIC", "confidence": 0.9041397869586945}]}, {"text": " Table 4: Question title + body (all) retrieval per- formance for different algorithms.", "labels": [], "entities": []}, {"text": " Table 5: BOW-CNN performance using different  methods to initialize the BOW weight vector t.", "labels": [], "entities": []}]}