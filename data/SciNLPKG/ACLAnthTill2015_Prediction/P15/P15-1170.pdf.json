{"title": [], "abstractContent": [{"text": "Tracking topics on social media streams is non-trivial as the number of topics mentioned grows without bound.", "labels": [], "entities": [{"text": "Tracking topics on social media streams", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.8558660248915354}]}, {"text": "This complexity is compounded when we want to track such topics against other fast moving streams.", "labels": [], "entities": []}, {"text": "We go beyond traditional small scale topic tracking and consider a stream of topics against another document stream.", "labels": [], "entities": [{"text": "topic tracking", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.7220523059368134}]}, {"text": "We introduce two tracking approaches which are fully applicable to true streaming environments.", "labels": [], "entities": []}, {"text": "When tracking 4.4 million topics against 52 million documents inconstant time and space, we demonstrate that counter to expectations, simple single-pass clustering can outper-form locality sensitive hashing for nearest neighbour search on streams.", "labels": [], "entities": []}], "introductionContent": [{"text": "The emergence of massive social media streams has sparked a growing need for systems able to process them.", "labels": [], "entities": []}, {"text": "While previous research;; Petrovic 2013) has focused on detecting new topics in unbounded textual streams, less attention was paid to following (tracking) the steadily growing set of topics.", "labels": [], "entities": [{"text": "detecting new topics in unbounded textual streams", "start_pos": 56, "end_pos": 105, "type": "TASK", "confidence": 0.8196755136762347}]}, {"text": "Standard topic tracking) deals with helping human analysts follow and monitor ongoing events on massive data streams.", "labels": [], "entities": [{"text": "topic tracking", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.7276805639266968}]}, {"text": "By pairing topics with relevant documents, topic tracking splits a noisy stream of documents into sub-streams grouped by their target topics.", "labels": [], "entities": [{"text": "topic tracking", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.884806752204895}]}, {"text": "This is a crucial task for financial and security analysts who are interested in pulling together relevant information from unstructured and noisy data streams.", "labels": [], "entities": []}, {"text": "Other fields like summarization or topic modeling benefit from topic tracking as a mean to generate their data sources.", "labels": [], "entities": [{"text": "summarization", "start_pos": 18, "end_pos": 31, "type": "TASK", "confidence": 0.9909921884536743}, {"text": "topic modeling", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.8274616003036499}, {"text": "topic tracking", "start_pos": 63, "end_pos": 77, "type": "TASK", "confidence": 0.760094165802002}]}, {"text": "In todays data streams however, new topics emerge on a continual basis and we are interested in following all instead of just a small fraction of newly detected topics.", "labels": [], "entities": []}, {"text": "Since its introduction), standard topic tracking typically operates on a small scale and against a static set of predefined target topics.", "labels": [], "entities": [{"text": "topic tracking", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.8448376953601837}]}, {"text": "We go beyond such approaches and deal for the first time with massive, unbounded topic streams.", "labels": [], "entities": []}, {"text": "Examples of unbounded topic streams include all events reported by news agencies each day across the world; popular examples of unbounded document streams include social media services such as Twitter.", "labels": [], "entities": []}, {"text": "Tracking streams of topics allows research tasks like topic-modeling or summarization to be applied to millions of topics, a scale that is several orders of magnitude larger than those of current publications.", "labels": [], "entities": [{"text": "Tracking streams of topics", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8354123830795288}, {"text": "summarization", "start_pos": 72, "end_pos": 85, "type": "TASK", "confidence": 0.9583762884140015}]}, {"text": "We present two massive scale topic tracking systems capable of tracking unbounded topic streams.", "labels": [], "entities": [{"text": "topic tracking", "start_pos": 29, "end_pos": 43, "type": "TASK", "confidence": 0.9235569834709167}]}, {"text": "One is based on locality sensitive hashing (LSH) and the other on clustering.", "labels": [], "entities": []}, {"text": "Since we operate on two unbounded data sources we are subject to the streaming model of computation, which requires instant and single-pass decision making inconstant time and space.", "labels": [], "entities": []}, {"text": "Contrary to expectations, we find that nearest neighbour search on a stream based on clustering performs faster than LSH for the same level of accuracy.", "labels": [], "entities": [{"text": "LSH", "start_pos": 117, "end_pos": 120, "type": "METRIC", "confidence": 0.9301825165748596}, {"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9974943399429321}]}, {"text": "This is surprising as LSH is widely believed to be the fastest way of nearest neighbour search.", "labels": [], "entities": [{"text": "nearest neighbour search", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.6048308511575063}]}, {"text": "Our experiments reveal how simple single-pass clustering outperforms LSH in terms of effectiveness and efficiency.", "labels": [], "entities": []}, {"text": "Our results are general and apply to any setting where we have massive or infinite numbers of topics, matched against unboundedly large document streams.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the three algorithms in terms of effectiveness and efficiency.", "labels": [], "entities": []}, {"text": "Starting outwith tracking a small set of topics using the traditional approach, we evaluate various similarity metrics to ensure high effectiveness.", "labels": [], "entities": []}, {"text": "We then conduct scaling experiments on massive streams in bounded and unbounded space.", "labels": [], "entities": []}, {"text": "We evaluate effectiveness by recall and precision and combine them using F1 scores.", "labels": [], "entities": [{"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9995900988578796}, {"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.999152421951294}, {"text": "F1", "start_pos": 73, "end_pos": 75, "type": "METRIC", "confidence": 0.999444305896759}]}, {"text": "Efficiency is evaluated using two different metrics.", "labels": [], "entities": [{"text": "Efficiency", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.7358288764953613}]}, {"text": "We provide a theoretical upper bound by computing the number of dot products required for tracking (.", "labels": [], "entities": []}, {"text": "They therefore indicate performance without system-or implementation-dependent distortions.", "labels": [], "entities": []}, {"text": "Equations 2 and 3 represent the cost to identify the candidate set for the LSH-and cluster-based algorithm plus the cost resulting from exhaustively comparing the candidate sets with the documents (Equation 4).", "labels": [], "entities": []}, {"text": "Because we compute the dot products fora worst case scenario, we also provide the runtime in seconds.", "labels": [], "entities": []}, {"text": "All run-times are averaged over 5 runs, measured on the same idle machine.", "labels": [], "entities": []}, {"text": "To ensure fair comparison, all algorithms are implemented in C using the same libraries, compiler, compiler optimizations and run as a single process using 4 GB of memory.", "labels": [], "entities": []}, {"text": "Because the runtime of the traditional approach (\u223c171 days) exceeds our limits, we estimate it based on extrapolating 50 runs using up to 25,000 topics.", "labels": [], "entities": []}, {"text": "Note that this extrapolation favours the efficiency of the baseline system as it ignores hardware dependent slowdowns when scaling up the number of topics.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Comparing the effectiveness of similarity mea- sures when matching 30 Wikipedia articles against 52 million  tweets", "labels": [], "entities": []}, {"text": " Table 5: Effectiveness and efficiency of LSH-and cluster-based tracking to the traditional approach", "labels": [], "entities": [{"text": "LSH-and cluster-based tracking", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.5705360968907675}]}, {"text": " Table 6: Effectiveness and efficiency for tracking in bounded and unbounded space", "labels": [], "entities": []}]}