{"title": [{"text": "Knowledge Portability with Semantic Expansion of Ontology Labels", "labels": [], "entities": []}], "abstractContent": [{"text": "Our research focuses on the multilingual enhancement of ontologies that, often represented only in English, need to be translated in different languages to enable knowledge access across languages.", "labels": [], "entities": []}, {"text": "Ontology translation is a rather different task then the classic document translation, because ontologies contain highly specific vocabulary and they lack contextual information.", "labels": [], "entities": [{"text": "Ontology translation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8933454751968384}, {"text": "document translation", "start_pos": 65, "end_pos": 85, "type": "TASK", "confidence": 0.7603815197944641}]}, {"text": "For these reasons, to improve automatic ontology translations, we first focus on identifying relevant unambigu-ous and domain-specific sentences from a large set of generic parallel corpora.", "labels": [], "entities": [{"text": "ontology translations", "start_pos": 40, "end_pos": 61, "type": "TASK", "confidence": 0.7604959905147552}]}, {"text": "Then, we leverage Linked Open Data resources, such as DBPedia, to isolate ontology-specific bilingual lexical knowledge.", "labels": [], "entities": [{"text": "DBPedia", "start_pos": 54, "end_pos": 61, "type": "DATASET", "confidence": 0.9367166757583618}]}, {"text": "In both cases, we take advantage of the semantic information of the labels to select relevant bilingual data with the aim of building an ontology-specific statistical machine translation system.", "labels": [], "entities": [{"text": "ontology-specific statistical machine translation", "start_pos": 137, "end_pos": 186, "type": "TASK", "confidence": 0.5860502198338509}]}, {"text": "We evaluate our approach on the translation of a medical ontology, translating from English into German.", "labels": [], "entities": [{"text": "translation of a medical ontology", "start_pos": 32, "end_pos": 65, "type": "TASK", "confidence": 0.8070010066032409}]}, {"text": "Our experiment shows a significant improvement of around 3 BLEU points compared to a generic as well as a domain-specific translation approach.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.9993222951889038}]}], "introductionContent": [{"text": "Currently, most of the semantically structured data, i.e. ontologies or taxonomies, has labels expressed in English only.", "labels": [], "entities": []}, {"text": "On the one hand, the increasing amount of ontologies offers an excellent opportunity to link this knowledge together ().", "labels": [], "entities": []}, {"text": "On the other hand, non-English users may encounter difficulties when using the ontological knowledge represented only in English.", "labels": [], "entities": []}, {"text": "Furthermore, applications in information retrieval, question answering or knowledge management, that use monolingual ontologies are therefore limited to the language in which the ontology labels are stored.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.7677987813949585}, {"text": "question answering or knowledge management", "start_pos": 52, "end_pos": 94, "type": "TASK", "confidence": 0.7152119934558868}]}, {"text": "To make the ontological knowledge language-independent and accessible beyond language borders, these monolingual resources need to be transformed into multilingual knowledge bases.", "labels": [], "entities": []}, {"text": "This multilingual enhancement can enable queries on documents beyond English, e.g. for cross-lingual business intelligence in the financial domain (O'), providing information related to an ontology label, e.g. other intangible assets, 2 in Spanish, German or Italian.", "labels": [], "entities": []}, {"text": "The main challenge involved in building multilingual knowledge bases is, however, to bridge the gap between language-specific information and the language-independent semantic content of ontologies or taxonomies (.", "labels": [], "entities": []}, {"text": "Since manual multilingual enhancement of ontologies is a very time consuming and expensive process, we engage an ontology-specific statistical machine translation (SMT) system to automatically translate the ontology labels.", "labels": [], "entities": [{"text": "ontology-specific statistical machine translation (SMT)", "start_pos": 113, "end_pos": 168, "type": "TASK", "confidence": 0.7601181098393032}]}, {"text": "Due to the fact that ontology labels are usually highly domainspecific and stored only in knowledge representations (), the labels appear infrequent in parallel corpora, which are needed to build a domain-specific translation system with accurate translation candidates.", "labels": [], "entities": []}, {"text": "Additionally, ambiguous labels built out of only a few words do often not express enough semantic or contextual information to guide the SMT system to translate a label into the targeted domain.", "labels": [], "entities": [{"text": "SMT", "start_pos": 137, "end_pos": 140, "type": "TASK", "confidence": 0.9898151159286499}]}, {"text": "This can be observed by domain-unadapted SMT systems, e.g. Google Translate, where ambiguous expressions, such as vessel stored in an medical ontology, are often translated into a generic do-main as Schiff 3 in German (meaning ship or boat), but not into the targeted medical domain as Gef\u00e4\u00df.", "labels": [], "entities": [{"text": "SMT", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9176040887832642}]}, {"text": "Since ontologies may changeover time, keeping up with these changes can be challenging fora human translator.", "labels": [], "entities": []}, {"text": "Having in place an SMT system adapted to an ontology can therefore be very beneficial.", "labels": [], "entities": [{"text": "SMT", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9861478805541992}]}, {"text": "In this work, we propose an approach to select the most relevant (parallel) sentences from a pool of generic sentences based on the lexical and semantic overlap with the ontology labels.", "labels": [], "entities": []}, {"text": "The goal is to identify sentences that are domain-specific in respect of the target domain and contain as much as possible relevant words that can allow the SMT system to learn the translations of the monolingual ontology labels.", "labels": [], "entities": [{"text": "SMT", "start_pos": 157, "end_pos": 160, "type": "TASK", "confidence": 0.9913612008094788}]}, {"text": "For instance, with the sentence selection we aim to retain only parallel sentences where the English word injection is translated into the German language as Impfung in the medical domain, but not into Eind\u00fcsung, belonging to the technical domain.", "labels": [], "entities": []}, {"text": "This selection process aims to reduce the semantic noise in the translation process, since we try to avoid learning translation candidates that do not belong to the targeted domain.", "labels": [], "entities": [{"text": "translation process", "start_pos": 64, "end_pos": 83, "type": "TASK", "confidence": 0.9137298464775085}]}, {"text": "Nonetheless, some of the domain-specific ontology labels may not be automatically translatable with SMT, due to the fact that the bilingual information is missing and cannot be learned from the parallel sentences.", "labels": [], "entities": [{"text": "SMT", "start_pos": 100, "end_pos": 103, "type": "TASK", "confidence": 0.9683541655540466}]}, {"text": "Therefore we use the information contained in the DBpedia knowledge base ( to improve the translation of expressions which are not known to the SMT system.", "labels": [], "entities": [{"text": "DBpedia knowledge base", "start_pos": 50, "end_pos": 72, "type": "DATASET", "confidence": 0.9691072305043539}, {"text": "SMT", "start_pos": 144, "end_pos": 147, "type": "TASK", "confidence": 0.9600754380226135}]}, {"text": "We tested our approach on the medical domain translating from English to German, showing improvements of around 3 BLEU points compared to a generic as well as a domain-specific translation model.", "labels": [], "entities": [{"text": "medical domain translating from English to German", "start_pos": 30, "end_pos": 79, "type": "TASK", "confidence": 0.6938101777008602}, {"text": "BLEU", "start_pos": 114, "end_pos": 118, "type": "METRIC", "confidence": 0.9994714856147766}]}, {"text": "The remainder of this paper is organized as follows: Section 2 gives an overview of the related work done in the field of ontology translation within SMT.", "labels": [], "entities": [{"text": "ontology translation", "start_pos": 122, "end_pos": 142, "type": "TASK", "confidence": 0.8972441554069519}, {"text": "SMT", "start_pos": 150, "end_pos": 153, "type": "TASK", "confidence": 0.8651726245880127}]}, {"text": "In Section 3, we present the methodology of parallel data selection and terminology identification to improve ontology label translation.", "labels": [], "entities": [{"text": "parallel data selection", "start_pos": 44, "end_pos": 67, "type": "TASK", "confidence": 0.6722628275553385}, {"text": "terminology identification", "start_pos": 72, "end_pos": 98, "type": "TASK", "confidence": 0.9078198373317719}, {"text": "ontology label translation", "start_pos": 110, "end_pos": 136, "type": "TASK", "confidence": 0.8330538074175516}]}, {"text": "Furthermore we show different methods of embedding domain-specific knowledge into SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.9684081673622131}]}, {"text": "In Experimental Setting, Section 4, we describe the ontology to be translated along the training data needed for SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 113, "end_pos": 116, "type": "TASK", "confidence": 0.9962537288665771}]}, {"text": "Moreover we introduce existing approaches and give a description of metrics for automatic translation evaluation.", "labels": [], "entities": [{"text": "automatic translation evaluation", "start_pos": 80, "end_pos": 112, "type": "TASK", "confidence": 0.6830764214197794}]}, {"text": "Section 5 Translation performed on presents the automatic and manual evaluation of the translated labels.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9589430093765259}]}, {"text": "Finally, conclusions and future work are shown in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this Section, we give an overview on the dataset and the translation toolkit used in our experiment.", "labels": [], "entities": []}, {"text": "Furthermore, we describe the existing approaches and give insights into the SMT evaluation techniques, considering the translation direction from English to German.", "labels": [], "entities": [{"text": "SMT evaluation", "start_pos": 76, "end_pos": 90, "type": "TASK", "confidence": 0.9150402545928955}]}, {"text": "Evaluation Dataset For our experiments we used the International Classification of Diseases (ICD) ontology as the gold standard, 7 whereby the considered translation direction is from English to German.", "labels": [], "entities": [{"text": "Evaluation Dataset", "start_pos": 0, "end_pos": 18, "type": "DATASET", "confidence": 0.7971638739109039}, {"text": "International Classification of Diseases (ICD) ontology", "start_pos": 51, "end_pos": 106, "type": "DATASET", "confidence": 0.8355615884065628}]}, {"text": "The ICD ontology, translated into 43 languages, is used to monitor diseases and to report the general health situation of the population in a country.", "labels": [], "entities": [{"text": "ICD ontology", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.7069605886936188}]}, {"text": "This stored information also provides an overview of the national mortality rate and appearance of diseases of WHO member countries.", "labels": [], "entities": []}, {"text": "For our experiment we used 2000 English labels from the ICD-10 dataset, which were aligned to their German equivalents.", "labels": [], "entities": [{"text": "ICD-10 dataset", "start_pos": 56, "end_pos": 70, "type": "DATASET", "confidence": 0.9795441627502441}]}, {"text": "To identify the best set of sentences we experiment with different values of \u03c4 , which is the percentage of all the sentences that are considered relevant (domainspecific) by the sentence extraction approach.", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 179, "end_pos": 198, "type": "TASK", "confidence": 0.7205690741539001}]}, {"text": "The value that allows the SMT system to achieve the best performance on the development dataset 1 is used on the evaluation set, which is used for the translation evaluation of ontology labels reported in this paper.", "labels": [], "entities": [{"text": "SMT", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.9918164610862732}, {"text": "translation evaluation of ontology labels", "start_pos": 151, "end_pos": 192, "type": "TASK", "confidence": 0.8112425327301025}]}, {"text": "The parameters within the SMT system are optimized on the development dataset 2.", "labels": [], "entities": [{"text": "SMT", "start_pos": 26, "end_pos": 29, "type": "TASK", "confidence": 0.980701208114624}]}, {"text": "Statistical Machine Translation and Training Dataset For our translation task, we use the statistical translation toolkit Moses (, where the word alignments were built with the GIZA++ toolkit.", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.5866846640904745}, {"text": "translation", "start_pos": 61, "end_pos": 72, "type": "TASK", "confidence": 0.9619379639625549}, {"text": "statistical translation", "start_pos": 90, "end_pos": 113, "type": "TASK", "confidence": 0.6803032159805298}]}, {"text": "The SRILM toolkit) was used to build the 5-gram language model.", "labels": [], "entities": [{"text": "SRILM toolkit", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.7723110318183899}]}, {"text": "For a broader domain coverage of the generic training dataset necessary for the SMT system, we merged parts of JRC-Acquis 3.0  We additionally compare our results to an SMT system built on an existing domain-specific parallel dataset, i.e. EMEA 12, which holds specific medical parallel data extracted from the European Medicines Agency documents and websites.", "labels": [], "entities": [{"text": "SMT", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.9948786497116089}, {"text": "JRC-Acquis", "start_pos": 111, "end_pos": 121, "type": "DATASET", "confidence": 0.9069139957427979}, {"text": "SMT", "start_pos": 169, "end_pos": 172, "type": "TASK", "confidence": 0.9847260117530823}, {"text": "EMEA 12", "start_pos": 240, "end_pos": 247, "type": "DATASET", "confidence": 0.8668231070041656}]}, {"text": "Comparison to Existing Approaches We compare our approach on knowledge expansion for sentence selection with similar methods that distinguish between more important sentences and less important ones.", "labels": [], "entities": [{"text": "knowledge expansion", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.7202971428632736}, {"text": "sentence selection", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.7261314988136292}]}, {"text": "First, we sort 1.9M sentences from the generic corpus based on the perplexity of the ontology vocabulary.", "labels": [], "entities": []}, {"text": "The perplexity score gives a notion of how well the probability model based on the ontology vocabulary predicts a sample, which is in our case each sentence in the generic corpus.", "labels": [], "entities": []}, {"text": "Second, we use the method shown in), where the authors use a method based on tf-idf 13 to select the most relevant sentences.", "labels": [], "entities": []}, {"text": "This widely-used method in information retrieval tells us how important a word is to a document, whereby each sentence from the generic corpus is treated as a document.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 27, "end_pos": 48, "type": "TASK", "confidence": 0.7313660830259323}]}, {"text": "Finally, we compare our approach with the infrequent n-gram recovery method, described in (.", "labels": [], "entities": [{"text": "n-gram recovery", "start_pos": 53, "end_pos": 68, "type": "TASK", "confidence": 0.703342854976654}]}, {"text": "Their technique consists of selection of relevant sentences from the generic corpus, which contain infrequent n-grams based on their test data.", "labels": [], "entities": []}, {"text": "They consider an n-gram as infrequent if it appears in the generic corpus less times than an infrequent threshold t.", "labels": [], "entities": []}, {"text": "Furthermore we enrich and evaluate our proposed ontology-specific SMT system with the lexical information coming from the terminological database IATE 14 (Inter-Active Terminology for Europe).", "labels": [], "entities": [{"text": "SMT", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.8851922750473022}]}, {"text": "IATE is the institutional terminology database of the EU and is used for the collection, dissemination and shared management of specific terminology and contains approximately 1.4 million multilingual entries.", "labels": [], "entities": [{"text": "IATE", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.5828583836555481}]}, {"text": "The automatic translation evaluation is based on the correspondence between the SMT output and reference translation (gold standard).", "labels": [], "entities": [{"text": "SMT", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.9908906817436218}]}, {"text": "For the automatic evaluation we used the BLEU () and METEOR) algorithms.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.9987838864326477}, {"text": "METEOR", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.986328661441803}]}, {"text": "BLEU (Bilingual Evaluation Understudy) is calculated for individual translated segments (ngrams) by comparing them with a dataset of reference translations.", "labels": [], "entities": [{"text": "BLEU (Bilingual Evaluation Understudy)", "start_pos": 0, "end_pos": 38, "type": "METRIC", "confidence": 0.7251826077699661}]}, {"text": "Considering the shortness of the labels, we report scores based on the bi-gram overlap (BLEU-2) and the standard four-gram overlap.", "labels": [], "entities": [{"text": "BLEU-2)", "start_pos": 88, "end_pos": 95, "type": "METRIC", "confidence": 0.9534780979156494}]}, {"text": "Those scores, between 0 and 100 (perfect translation), are then averaged over the whole evaluation dataset to reach an estimate of the translation's overall quality.", "labels": [], "entities": []}, {"text": "METEOR (Metric for Evaluation of Translation with Explicit ORdering) is based on the harmonic mean of precision and recall, whereby recall is weighted higher than precision.", "labels": [], "entities": [{"text": "METEOR", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.7357102632522583}, {"text": "Evaluation of Translation", "start_pos": 19, "end_pos": 44, "type": "TASK", "confidence": 0.58854212363561}, {"text": "precision", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.9989174604415894}, {"text": "recall", "start_pos": 116, "end_pos": 122, "type": "METRIC", "confidence": 0.9972401857376099}, {"text": "recall", "start_pos": 132, "end_pos": 138, "type": "METRIC", "confidence": 0.9979817867279053}, {"text": "precision", "start_pos": 163, "end_pos": 172, "type": "METRIC", "confidence": 0.9959795475006104}]}, {"text": "Along with standard exact word (or phrase) matching it has additional features, i.e. stemming, paraphrasing and synonymy matching.", "labels": [], "entities": [{"text": "exact word (or phrase) matching", "start_pos": 20, "end_pos": 51, "type": "TASK", "confidence": 0.6527864634990692}, {"text": "synonymy matching", "start_pos": 112, "end_pos": 129, "type": "TASK", "confidence": 0.7058067321777344}]}, {"text": "Differently to BLEU, the metric produces good correlation with human judgement at the sentence or segment level.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.9966520667076111}]}, {"text": "The approximate randomization approach in) is used to test whether differences among system performances are statistically significant with a p-value < 0.05.", "labels": [], "entities": []}, {"text": "In this Section, we report the translation quality of ontology labels based on translation systems learned from different sentence selection methods.", "labels": [], "entities": []}, {"text": "Additionally, we perform experiments training an SMT system on the combination of in-and outdomain knowledge.", "labels": [], "entities": [{"text": "SMT", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.9945211410522461}]}, {"text": "The final approach enhances a domain-specific translation system with lexical knowledge identified in IATE or DBpedia.", "labels": [], "entities": [{"text": "IATE", "start_pos": 102, "end_pos": 106, "type": "DATASET", "confidence": 0.6343880891799927}, {"text": "DBpedia", "start_pos": 110, "end_pos": 117, "type": "DATASET", "confidence": 0.6171671748161316}]}, {"text": "We report the automatic evaluation based on BLEU and METEOR for the sentence selection techniques, the combination of in-and out-domain data and the lexical enhancement of SMT.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9981653094291687}, {"text": "METEOR", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9545936584472656}, {"text": "sentence selection", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.7686974406242371}, {"text": "SMT", "start_pos": 172, "end_pos": 175, "type": "TASK", "confidence": 0.9794634580612183}]}, {"text": "Sentence Selection Techniques As a first evaluation, we automatically compare the quality of the ICD labels translated with different SMT systems trained on specific sentences by the aforementioned selection techniques.", "labels": [], "entities": [{"text": "SMT", "start_pos": 134, "end_pos": 137, "type": "TASK", "confidence": 0.9798277616500854}]}, {"text": "Due to the in-domain bilingual knowledge, the translation system trained using the EMEA dataset performs slightly better compared to the large generic baseline system.", "labels": [], "entities": [{"text": "EMEA dataset", "start_pos": 83, "end_pos": 95, "type": "DATASET", "confidence": 0.9731986820697784}]}, {"text": "Among the different sentence selection approaches, the infrequent n-gram recovery method (infreq.", "labels": [], "entities": [{"text": "sentence selection", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.7474374175071716}, {"text": "n-gram recovery", "start_pos": 66, "end_pos": 81, "type": "TASK", "confidence": 0.6950540840625763}]}, {"text": "in) outperforms the baselines and all the other techniques.", "labels": [], "entities": []}, {"text": "This is due to the very strict criteria of selecting relevant sentences that allows the infrequent n-gram recovery method to identify a limited number (20,000) of highly ontology-specific bilingual sentences.", "labels": [], "entities": []}, {"text": "The related words and the n-gram overlap models perform slightly better than the baseline, with a usage of 81,000 and 59,000 relevant sentences, and perform similarly to the in-domain EMEA translation system.", "labels": [], "entities": [{"text": "EMEA translation", "start_pos": 184, "end_pos": 200, "type": "TASK", "confidence": 0.673337385058403}]}, {"text": "Further translation quality improvement is possible, if sentence selection methods are combined together (last four rows in).", "labels": [], "entities": [{"text": "translation", "start_pos": 8, "end_pos": 19, "type": "TASK", "confidence": 0.9576795101165771}, {"text": "sentence selection", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.7127288579940796}]}, {"text": "The cosine similarities of the methods are combined together, whereby new thresholds \u03c4 are computed on the development dataset 1 and applied on the ICD evaluation dataset.", "labels": [], "entities": [{"text": "ICD evaluation dataset", "start_pos": 148, "end_pos": 170, "type": "DATASET", "confidence": 0.9157232840855917}]}, {"text": "Each combined method showed improvement compared to the stand-alone method.", "labels": [], "entities": []}, {"text": "The best overall performance is obtained  when combining the n-gram overlap, the semantic related words and infrequent n-gram recovery methods.", "labels": [], "entities": []}, {"text": "With this combination, we reduce the amount of parallel sentences by 98% compared to the generic corpus and significantly outperform the baseline by 2.3 BLEU score points.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 153, "end_pos": 163, "type": "METRIC", "confidence": 0.9796763956546783}]}, {"text": "These two factors confirm the capability of the combined approach of selecting only few ontology-specific bilingual sentences (30,000) that allows the SMT system to identify the correct translations in the target ontology domain.", "labels": [], "entities": [{"text": "SMT", "start_pos": 151, "end_pos": 154, "type": "TASK", "confidence": 0.9938502311706543}]}, {"text": "This is due to the fact that the three combined methods are quite complementary.", "labels": [], "entities": []}, {"text": "In fact, the n-gram overlap method selects a relatively large amount of bilingual sentences with few words in common with the label, the related words approach identifies bilingual sentences in the ontology target domain, and the infrequent ngram recovery technique selects few bilingual sentences with only specific n-grams in common with the labels balancing the effect of the n-gram overlap method.", "labels": [], "entities": []}, {"text": "Combining In-and Out-Domain Data Considering the relatively small amount of parallel data extracted with the sentence selecting methods for the SMT community, we evaluate different approaches that combine a large generic translation model with domain-specific data.", "labels": [], "entities": [{"text": "SMT community", "start_pos": 144, "end_pos": 157, "type": "TASK", "confidence": 0.9055303335189819}]}, {"text": "For this purpose, we use the sentences selected by the best approach () does not show any statistical significant differences between the approaches.", "labels": [], "entities": []}, {"text": "We conclude that the generic corpus is too large compared to the selected in-domain corpus, nullifying the influence of the extracted domain-specific parallel knowledge.", "labels": [], "entities": []}, {"text": "Lexical enhancement for SMT Since the outof-vocabulary problem can be only mitigated with sentence selection, we accessed lexical resources IATE and DBpedia to further improve the translations of the medical labels.", "labels": [], "entities": [{"text": "Lexical enhancement", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8423325419425964}, {"text": "SMT", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9918564558029175}, {"text": "IATE", "start_pos": 140, "end_pos": 144, "type": "DATASET", "confidence": 0.5743309855461121}]}, {"text": "Based on the word overlap between labels and entries in IATE we extracted 11,641 English lexical entries with its equivalent in German.", "labels": [], "entities": [{"text": "IATE", "start_pos": 56, "end_pos": 60, "type": "DATASET", "confidence": 0.831401526927948}]}, {"text": "The DBpedia approach, which disambiguates DBpedia entries based on the (Wikipedia article) categories (Arcan et al., 2012), identified 7,911 English-German expression for the targeted domain, while the abstract based disambiguation approach, marked as DBpedia in identified 3,791 bilingual entries.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 252, "end_pos": 259, "type": "DATASET", "confidence": 0.9516927003860474}]}, {"text": "The lexical enhanced models further improved the translations of the medical labels (last three rows in) due to the additional bilingual information from the lexical resources, which is missing in the standalone sentence selection model.", "labels": [], "entities": []}, {"text": "Comparing the ICD evaluation dataset and the translations generated with the DBpedia (2) lexical enhanced model we observed that more than 80 labels benefit from the additional lexical knowledge, e.g. correcting the mistranslated \"adrenal gland\" into \"Nebenniere\".", "labels": [], "entities": [{"text": "ICD evaluation dataset", "start_pos": 14, "end_pos": 36, "type": "DATASET", "confidence": 0.8829445242881775}]}, {"text": "The lexical extraction and disambiguation of bilingual knowledge based on the abstract of the article compared to the article categories further improves the lexical choice, helping SMT systems to improve the translation of ontology labels.", "labels": [], "entities": [{"text": "lexical extraction", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.7695436179637909}, {"text": "SMT", "start_pos": 182, "end_pos": 185, "type": "TASK", "confidence": 0.993413507938385}]}, {"text": "Since ontologies store specific vocabulary about a domain, this vocabulary is adapted to a concrete language and culture community (.", "labels": [], "entities": []}, {"text": "In order to investigate to what extent the automatically generated translations differ from a translator's adapted point of view, we manually inspected the translations produced by the sentence selection approaches described in Section 5.1.", "labels": [], "entities": [{"text": "sentence selection", "start_pos": 185, "end_pos": 203, "type": "TASK", "confidence": 0.6969995051622391}]}, {"text": "While analysing the English and German part of the ICD ontology gold standard we noticed significant differences in the translations of the medical labels.", "labels": [], "entities": [{"text": "ICD ontology gold standard", "start_pos": 51, "end_pos": 77, "type": "DATASET", "confidence": 0.8703679442405701}]}, {"text": "As a result of the language and cultural adaptation, many labels in the ICD ontology were not always translated literally, i.e. parts of a label were semantically merged, omitted or new information was added while crossing the language border.", "labels": [], "entities": [{"text": "ICD ontology", "start_pos": 72, "end_pos": 84, "type": "DATASET", "confidence": 0.7689438462257385}]}, {"text": "For example, the ICD label \"acute kidney failure and chronic kidney disease\" is stored in the German part of the ontology as \"Niereninsuffizienz\".", "labels": [], "entities": [{"text": "ICD", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.40640711784362793}]}, {"text": "Although none of the translation systems can generate the compounded medical expression for German, the SMT system generated nevertheless an acceptable translation, i.e. \"akutes Nierenversagen und chronischer Nierenerkrankungen\".", "labels": [], "entities": [{"text": "SMT", "start_pos": 104, "end_pos": 107, "type": "TASK", "confidence": 0.969956636428833}]}, {"text": "17 A more extreme example is the English label \"slipping, tripping, stumbling and falls\", in the German ICD ontology represented as \"sonstige St\u00fcrze auf gleicher Ebene\".", "labels": [], "entities": []}, {"text": "The language and cultural adaptation is very active for this example, where the whole English label is semantically merged into the word \"St\u00fcrze\", meaning \"falls\".", "labels": [], "entities": []}, {"text": "Additionally, the German part holds more information within the label, i.e. \"auf gleicher Ebene\" (en.", "labels": [], "entities": []}, {"text": "\"at the same level\"), which is not represented on the English side.", "labels": [], "entities": [{"text": "English side", "start_pos": 54, "end_pos": 66, "type": "DATASET", "confidence": 0.9751142859458923}]}, {"text": "Since the SMT system will always try to translate every phrase (word or word segments) into the target language, an automatic translation evaluation cannot reflect the overall SMT performance.", "labels": [], "entities": [{"text": "SMT", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9913267493247986}, {"text": "SMT", "start_pos": 176, "end_pos": 179, "type": "TASK", "confidence": 0.9882219433784485}]}, {"text": "Further we detected a large error class caused by compounding, a common linguistic feature of German.", "labels": [], "entities": []}, {"text": "Although the phrase \"heart diseases\" with its reference translation \"Herzkrankheiten\" appears frequent in the generic training dataset, the SMT system prefers to translate it word byword into \"Herz Krankheiten\".", "labels": [], "entities": [{"text": "SMT", "start_pos": 140, "end_pos": 143, "type": "TASK", "confidence": 0.9731023907661438}]}, {"text": "Similar observations were made with \"upper arm\" (German \"Oberarm\") with the SMT word to word translation \"oberen Arm\".", "labels": [], "entities": [{"text": "SMT word to word translation", "start_pos": 76, "end_pos": 104, "type": "TASK", "confidence": 0.8925862073898315}]}, {"text": "Finally, we analysed the impact of the semantically enriched sentence selection with related words coming from Word2Vec compared to the surface based sentence selection, e.g. preplexity, infrequent n-gram recovery or n-gram overlap.", "labels": [], "entities": [{"text": "Word2Vec", "start_pos": 111, "end_pos": 119, "type": "DATASET", "confidence": 0.9380879998207092}]}, {"text": "Since semantically enriched selection stored the most relevant sentences, we observed the correct translation of the label \"blood vessels\" into \"Blutgef\u00e4\u00dfe\".", "labels": [], "entities": []}, {"text": "The generic and other surface based selections translated the expression individually into \"Blut Schiffe\", where \"Schiffe\" refers to the more common English word \"ship\", but not to 'part of the system transporting blood throughout our body'.", "labels": [], "entities": []}, {"text": "The last example illustrates further the semantic mismatch between the training domain and the test domain.", "labels": [], "entities": []}, {"text": "Using the generic model, built mainly out of European laws and parliament discussions (JRC-Acquis/Europarl) the word \"head\" inside the label \"injury of head\" is wrongly translated into the word \"Leiter\", meaning \"leader\" in the legal domain.", "labels": [], "entities": [{"text": "JRC-Acquis/Europarl", "start_pos": 87, "end_pos": 106, "type": "DATASET", "confidence": 0.7912041942278544}]}, {"text": "Nevertheless, the additional semantic information prevents storing wrong parallel sentences and guides the SMT to the correct translation, i.e. \"Sch\u00e4digung des Kopfes\".", "labels": [], "entities": [{"text": "SMT", "start_pos": 107, "end_pos": 110, "type": "TASK", "confidence": 0.9891229271888733}]}, {"text": "20 sonstige\u2190other, St\u00fcrze\u2190falls, auf\u2190on, gleicher\u2190same, Ebene\u2190level Herz\u2190heart, Krankheiten\u2190diseases Sch\u00e4digung\u2190injury, des\u2190of, Kopfes\u2190head", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics for the bilingual training, de- velopment and evaluation datasets. ('Vocabulary'  denotes the number of unique words in the dataset)", "labels": [], "entities": []}, {"text": " Table 2: Automatic translation evaluation on the  evaluation dataset of the ICD ontology (Size =  amount of selected sentences from the generic par- allel corpus. bold results = best performance; *sta- tistically significant compared to baseline)", "labels": [], "entities": [{"text": "ICD ontology", "start_pos": 77, "end_pos": 89, "type": "DATASET", "confidence": 0.9295933842658997}]}]}