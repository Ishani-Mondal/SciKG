{"title": [{"text": "Plug Latent Structures and Play Coreference Resolution", "labels": [], "entities": [{"text": "Play Coreference Resolution", "start_pos": 27, "end_pos": 54, "type": "TASK", "confidence": 0.629537413517634}]}], "abstractContent": [{"text": "We present cort, a modular toolkit for devising , implementing, comparing and analyzing approaches to coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 102, "end_pos": 124, "type": "TASK", "confidence": 0.9444804489612579}]}, {"text": "The toolkit allows fora unified representation of popular coreference resolution approaches by making explicit the structures they operate on.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.9040983021259308}]}, {"text": "Several of the implemented approaches achieve state-of-the-art performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Coreference resolution is the task of determining which mentions in a text refer to the same entity.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9178739488124847}]}, {"text": "Machine learning approaches to coreference resolution range from simple binary classification models on mention pairs () to complex structured prediction approaches.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 31, "end_pos": 53, "type": "TASK", "confidence": 0.9679432809352875}]}, {"text": "In this paper, we present a toolkit that implements a framework that unifies these approaches: in the framework, we obtain a unified representation of many coreference approaches by making explicit the latent structures they operate on.", "labels": [], "entities": []}, {"text": "Our toolkit provides an interface for defining structures for coreference resolution, which we use to implement several popular approaches.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 62, "end_pos": 84, "type": "TASK", "confidence": 0.9686271846294403}]}, {"text": "An evaluation of the approaches on CoNLL shared task data ( shows that they obtain state-of-the-art results.", "labels": [], "entities": [{"text": "CoNLL shared task data", "start_pos": 35, "end_pos": 57, "type": "DATASET", "confidence": 0.7729325741529465}]}, {"text": "The toolkit also can perform end-to-end coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.8760824203491211}]}, {"text": "We implemented this functionality on top of the coreference resolution error analysis toolkit cort.", "labels": [], "entities": [{"text": "coreference resolution error analysis", "start_pos": 48, "end_pos": 85, "type": "TASK", "confidence": 0.900176465511322}]}, {"text": "Hence, this toolkit now provides functionality for devising, implementing, comparing and analyzing approaches to coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 113, "end_pos": 135, "type": "TASK", "confidence": 0.9560278058052063}]}, {"text": "cort is released as open source and is available from the Python Package Index 2 .", "labels": [], "entities": [{"text": "Python Package Index 2", "start_pos": 58, "end_pos": 80, "type": "DATASET", "confidence": 0.8692429959774017}]}], "datasetContent": [{"text": "We implemented a mention pair model with bestfirst clustering, the mention ranking model with closest) and latent () antecedents, and antecedent trees).", "labels": [], "entities": []}, {"text": "Only slight modifications of the source code displayed in Listings 1 and 2 were necessary to implement these approaches.", "labels": [], "entities": []}, {"text": "For the ranking models and antecedent trees we use the cost function described in Listing 3.", "labels": [], "entities": []}, {"text": "We evaluate the models on the English test data of the CoNLL-2012 shared task on multilingual coreference resolution ().", "labels": [], "entities": [{"text": "English test data of the CoNLL-2012 shared task", "start_pos": 30, "end_pos": 77, "type": "DATASET", "confidence": 0.7048531509935856}, {"text": "multilingual coreference resolution", "start_pos": 81, "end_pos": 116, "type": "TASK", "confidence": 0.587846169869105}]}, {"text": "The models are trained on the concatenation of training and development data.", "labels": [], "entities": []}, {"text": "The evaluation of the models is shown in.", "labels": [], "entities": []}, {"text": "To put the numbers into context, we compare with, the winning system of the CoNLL-2012 shared task, and the state-ofthe-art system of.", "labels": [], "entities": [{"text": "CoNLL-2012 shared task", "start_pos": 76, "end_pos": 98, "type": "DATASET", "confidence": 0.7508163054784139}]}, {"text": "The mention pair model performs decently, while the antecedent tree model exhibits performance comparable to, who use a very similar model.", "labels": [], "entities": []}, {"text": "The ranking models outperform, obtaining state-of-the-art performance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of different systems and models on CoNLL-2012 English test data. Models below the  dashed lines are implemented in our toolkit.", "labels": [], "entities": [{"text": "CoNLL-2012 English test data", "start_pos": 53, "end_pos": 81, "type": "DATASET", "confidence": 0.9616241306066513}]}]}