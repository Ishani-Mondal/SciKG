{"title": [{"text": "Multi-Pass Decoding With Complex Feature Guidance for Statistical Machine Translation", "labels": [], "entities": [{"text": "Multi-Pass Decoding", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7345665991306305}, {"text": "Statistical Machine Translation", "start_pos": 54, "end_pos": 85, "type": "TASK", "confidence": 0.8410949110984802}]}], "abstractContent": [{"text": "In Statistical Machine Translation, some complex features are still difficult to integrate during decoding and usually used through the reranking of the k-best hypotheses produced by the decoder.", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.8504045804341634}]}, {"text": "We propose a translation table partitioning method that exploits the result of this reranking to iteratively guide the decoder in order to produce anew k-best list more relevant to some complex features.", "labels": [], "entities": [{"text": "translation table partitioning", "start_pos": 13, "end_pos": 43, "type": "TASK", "confidence": 0.8833632270495096}]}, {"text": "We report experiments on two translation domains and two translations directions which yield improvements of up to 1.4 BLEU over the reranking baseline using the same set of complex features.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 119, "end_pos": 123, "type": "METRIC", "confidence": 0.999291181564331}]}, {"text": "On a practical viewpoint, our approach allows SMT system developers to easily integrate complex features into decoding rather than being limited to their use in one-time k-best list reranking.", "labels": [], "entities": [{"text": "SMT", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9958892464637756}]}], "introductionContent": [{"text": "State-of-the-art Phrase-Based Statistical Machine Translation (PBSMT) systems can use a large number of feature functions decomposable into local scores to efficiently evaluate the partial hypotheses built during decoding.", "labels": [], "entities": [{"text": "Phrase-Based Statistical Machine Translation (PBSMT)", "start_pos": 17, "end_pos": 69, "type": "TASK", "confidence": 0.7489351630210876}]}, {"text": "However, some feature functions are difficult to integrate into the decoder mainly because they are not easily decomposable, very costly to compute and/or only available after complete hypotheses have been posited.", "labels": [], "entities": []}, {"text": "Usually such complex features are used through the rescoring and reranking of the k-best translation hypotheses produced by the decoder.", "labels": [], "entities": []}, {"text": "Although this reranking pass is performed over the best part of the decoder search space, it is limited by the actual diversity expressed in the k-best list.", "labels": [], "entities": []}, {"text": "Additionally, reranking being performed on a list generated by a simpler set of features, it may not have access to hypotheses that can best exploit the potential of the complex features used.", "labels": [], "entities": []}, {"text": "We describe a translation table partitioning approach that exploits the result of such a reranking to iteratively guide the decoder to produce new hypotheses that are more relevant to the complex features used.", "labels": [], "entities": [{"text": "translation table partitioning", "start_pos": 14, "end_pos": 44, "type": "TASK", "confidence": 0.9071786403656006}]}, {"text": "To this end, we focus in this work on the simple exploitation of the disagreement between hypotheses ranked best according to the decoder and to our featurerich decoder.", "labels": [], "entities": []}, {"text": "In particular, we seek to provide the next-pass decoder with separate translation tables that either contain bi-phrases that are unique to the decoder's one-best or to the reranker's onebest, in the hope that it will tend, in a soft manner, to exploit the preferences expressed by the complex features, and to otherwise explore alternative translation choices.", "labels": [], "entities": []}, {"text": "Such a comparison is then iteratively repeated, until convergence on a development set between the new pass of the decoder and a reranker trained on the full set of hypotheses generated thus far.", "labels": [], "entities": []}, {"text": "On the test data, this procedure thus produces after each iteration anew decoder n-best, as well as an iteration-specific new reranker best hypothesis.", "labels": [], "entities": []}, {"text": "We report consistent improvements of translation quality over a strong reranking baseline using the same features on 2 different domains and 2 translation directions.", "labels": [], "entities": [{"text": "translation", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.9434758424758911}]}, {"text": "The remainder of this article is organized as follows: we first briefly review related work (Section 2), then introduce our approach (Section 3), describe our experiments (Section 4), and finally discuss our results and present our future work (Section 5).", "labels": [], "entities": []}, {"text": "expand the k-best list of the decoder using three methods.", "labels": [], "entities": []}, {"text": "One of them involves re-decodings using models trained on the decoder k-best list to integrate posterior knowledge during the next re-decoding.", "labels": [], "entities": []}, {"text": "The new k-best list produced by the decoder is concatenated to the original one and then reranked with complex features, which yields improvements over a reranking performed on the original k-best list.", "labels": [], "entities": []}, {"text": "The reranking pass is done out of the loop and the redecodings do not exploit the reranking result that used the complex features.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Data used in our experiments.", "labels": [], "entities": []}, {"text": " Table 2: Reranking results for each set of features  added individually; Rerank uses the full set.", "labels": [], "entities": []}]}