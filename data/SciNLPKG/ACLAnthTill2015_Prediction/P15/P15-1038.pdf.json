{"title": [{"text": "It Depends: Dependency Parser Comparison Using A Web-based Evaluation Tool", "labels": [], "entities": []}], "abstractContent": [{"text": "The last few years have seen a surge in the number of accurate, fast, publicly available dependency parsers.", "labels": [], "entities": []}, {"text": "At the same time, the use of dependency parsing in NLP applications has increased.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.8518136739730835}]}, {"text": "It can be difficult fora non-expert to select a good \"off-the-shelf\" parser.", "labels": [], "entities": []}, {"text": "We present a comparative analysis often leading statistical dependency parsers on a multi-genre corpus of English.", "labels": [], "entities": [{"text": "statistical dependency parsers", "start_pos": 48, "end_pos": 78, "type": "TASK", "confidence": 0.6410856346289316}]}, {"text": "For our analysis, we developed anew web-based tool that gives a convenient way of comparing dependency parser outputs.", "labels": [], "entities": [{"text": "comparing dependency parser", "start_pos": 82, "end_pos": 109, "type": "TASK", "confidence": 0.6525652507940928}]}, {"text": "Our analysis will help practitioners choose a parser to optimize their desired speed/accuracy trade-off, and our tool will help practitioners examine and compare parser output.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.8963042497634888}]}], "introductionContent": [{"text": "Dependency parsing is a valuable form of syntactic processing for NLP applications due to its transparent lexicalized representation and robustness with respect to flexible word order languages.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8408884406089783}, {"text": "syntactic processing", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.762273520231247}]}, {"text": "Thanks to over a decade of research on statistical dependency parsing, many dependency parsers are now publicly available.", "labels": [], "entities": [{"text": "statistical dependency parsing", "start_pos": 39, "end_pos": 69, "type": "TASK", "confidence": 0.7205919226010641}, {"text": "dependency parsers", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.7150883674621582}]}, {"text": "In this paper, we report on a comparative analysis of leading statistical dependency parsers using a multi-genre corpus.", "labels": [], "entities": [{"text": "statistical dependency parsers", "start_pos": 62, "end_pos": 92, "type": "TASK", "confidence": 0.6329726974169413}]}, {"text": "Our purpose is not to introduce anew parsing algorithm but to assess the performance of existing systems across different genres of language use and to provide tools and recommendations that practitioners can use to choose a dependency parser.", "labels": [], "entities": [{"text": "dependency parser", "start_pos": 225, "end_pos": 242, "type": "TASK", "confidence": 0.7227605879306793}]}, {"text": "The contributions of this work include: \u2022 A comparison of the accuracy and speed often state-of-the-art dependency parsers, covering a range of approaches, on a large multigenre corpus of English.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9989973902702332}]}, {"text": "\u2022 A new web-based tool, DEPENDABLE, for side-by-side comparison and visualization of the output from multiple dependency parsers.", "labels": [], "entities": [{"text": "DEPENDABLE", "start_pos": 24, "end_pos": 34, "type": "METRIC", "confidence": 0.8930389881134033}]}, {"text": "\u2022 A detailed error analysis for these parsers using DEPENDABLE, with recommendations for parser choice for different factors.", "labels": [], "entities": [{"text": "DEPENDABLE", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.8822062611579895}]}, {"text": "\u2022 The release of the set of dependencies used in our experiments, the test outputs from all parsers, and the parser-specific models.", "labels": [], "entities": []}], "datasetContent": [{"text": "There are several very useful tools for evaluating the output of dependency parsers, including the venerable eval.pl 18 script used in the CoNLL shared tasks, and newer Java-based tools that support visualization of and search over parse trees such as TedEval (Tsarfaty et al., 2011), MaltEval (Nilsson and Nivre, 2008) and \"What's wrong with my NLP?\".", "labels": [], "entities": []}, {"text": "Recently, there is momentum towards web-based tools for annotation and visualization of NLP pipelines (Stenetorp and others, 2012).", "labels": [], "entities": []}, {"text": "For this work, we used anew webbased tool, DEPENDABLE, developed by the first author of this paper.", "labels": [], "entities": [{"text": "DEPENDABLE", "start_pos": 43, "end_pos": 53, "type": "METRIC", "confidence": 0.9162101149559021}]}, {"text": "It requires no installation and so provides a convenient way to evaluate and compare dependency parsers.", "labels": [], "entities": []}, {"text": "The following are key features of DEPENDABLE: Figure 1: Screenshot of our evaluation tool.", "labels": [], "entities": [{"text": "DEPENDABLE", "start_pos": 34, "end_pos": 44, "type": "DATASET", "confidence": 0.38666006922721863}]}, {"text": "\u2022 It reads any type of Tab Separated Value (TSV) format, including the CoNLL formats.", "labels": [], "entities": [{"text": "Tab Separated Value (TSV) format", "start_pos": 23, "end_pos": 55, "type": "TASK", "confidence": 0.6927435312952314}, {"text": "CoNLL formats", "start_pos": 71, "end_pos": 84, "type": "DATASET", "confidence": 0.9019796550273895}]}, {"text": "\u2022 It computes LAS, UAS and LS for parse outputs from multiple parsers against gold (manual) parses.", "labels": [], "entities": [{"text": "LAS", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.9551763534545898}, {"text": "UAS", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9083573222160339}, {"text": "LS", "start_pos": 27, "end_pos": 29, "type": "METRIC", "confidence": 0.9641537070274353}]}, {"text": "\u2022 It computes exact match scores for multiple parsers, and \"oracle ensemble\" output, the upper bound performance obtainable by combining all parser outputs.", "labels": [], "entities": []}, {"text": "\u2022 It allows the user to exclude symbol tokens, projective trees, or non-projective trees.", "labels": [], "entities": []}, {"text": "\u2022 It produces detailed analyses by POS tags, dependency labels, sentence lengths, and dependency distances.", "labels": [], "entities": []}, {"text": "\u2022 It reports statistical significance values for all parse outputs (using McNemar's test).", "labels": [], "entities": [{"text": "McNemar's test", "start_pos": 74, "end_pos": 88, "type": "DATASET", "confidence": 0.8153704206148783}]}, {"text": "DEPENDABLE can be also used for visualizing and comparing multiple dependency trees together (.", "labels": [], "entities": [{"text": "DEPENDABLE", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.5326402187347412}]}, {"text": "A key feature is that the user may select parse trees by specifying a range of accuracy scores; this enabled us to perform the error analyses in Section 6.5.", "labels": [], "entities": [{"text": "accuracy scores", "start_pos": 79, "end_pos": 94, "type": "METRIC", "confidence": 0.9742917716503143}, {"text": "Section 6.5", "start_pos": 145, "end_pos": 156, "type": "DATASET", "confidence": 0.9016915857791901}]}, {"text": "DEPENDABLE allows one to filter trees by sentence length and highlights arc and label errors.", "labels": [], "entities": [{"text": "DEPENDABLE", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.5137313008308411}]}, {"text": "The evaluation and comparison tools are publicly available at http://nlp.mathcs.emory.edu/ clearnlp/dependable.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Dependency converters. The \"secondary\"  row shows how many types of secondary depen- dencies that can be produced by each converter.", "labels": [], "entities": [{"text": "Dependency converters", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.6943541169166565}]}, {"text": " Table 3: Dependency parsers used in our experiments.", "labels": [], "entities": [{"text": "Dependency parsers", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.7676512598991394}]}, {"text": " Table 4: Overall parsing accuracy. The top 6 rows and the bottom 7 rows show accuracies for greedy and  non-greedy parsers, respectively.", "labels": [], "entities": [{"text": "parsing", "start_pos": 18, "end_pos": 25, "type": "TASK", "confidence": 0.9582107663154602}, {"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9874624609947205}]}, {"text": " Table 5: Overall parsing speed.", "labels": [], "entities": [{"text": "parsing", "start_pos": 18, "end_pos": 25, "type": "TASK", "confidence": 0.9205753803253174}]}, {"text": " Table 6: Accuracy for proj. and non-proj. trees.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9986677169799805}]}, {"text": " Table 8: Oracle ensemble performance.", "labels": [], "entities": []}, {"text": " Table 9: Differential parsing accuracies.", "labels": [], "entities": [{"text": "Differential parsing", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.7999733090400696}]}]}