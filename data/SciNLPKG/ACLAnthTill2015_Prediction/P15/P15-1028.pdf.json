{"title": [{"text": "A Generalisation of Lexical Functions for Composition in Distributional Semantics", "labels": [], "entities": []}], "abstractContent": [{"text": "Over the last two decades, numerous algorithms have been developed that successfully capture something of the semantics of single words by looking at their distribution in text and comparing these distributions in a vector space model.", "labels": [], "entities": []}, {"text": "However , it is not straightforward to construct meaning representations beyond the level of individual words-i.e. the combination of words into larger units-using dis-tributional methods.", "labels": [], "entities": []}, {"text": "First of all, we carryout a large-scale evaluation, comparing different composition methods within the distributional framework for the cases of both adjective-noun and noun-noun composition, making use of a newly developed dataset.", "labels": [], "entities": []}, {"text": "Secondly , we propose a novel method for composition, which generalises the approach by Baroni and Zamparelli (2010).", "labels": [], "entities": []}, {"text": "The performance of our novel method is also evaluated on our new dataset and proves competitive with the best methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the course of the last two decades, there has been a growing interest in distributional methods for lexical semantics.", "labels": [], "entities": [{"text": "lexical semantics", "start_pos": 103, "end_pos": 120, "type": "TASK", "confidence": 0.6955232620239258}]}, {"text": "These methods are based on the distributional hypothesis, according to which words that appear in the same contexts tend to be similar in meaning.", "labels": [], "entities": []}, {"text": "Inspired by Harris' hypothesis, numerous researchers have developed algorithms that try to capture the semantics of individual words by looking at their distribution in a large corpus.", "labels": [], "entities": []}, {"text": "Compared to manual studies common to formal semantics, distributional semantics offers substantially larger coverage since it is able to analyze massive amounts of empirical data.", "labels": [], "entities": []}, {"text": "However, it is not trivial to combine the algebraic objects created by distributional semantics to get a sensible distributional representation for more complex expressions, consisting of several words.", "labels": [], "entities": []}, {"text": "On the other hand, the formalism of the \u03bb -calculus provides us with general, advanced and efficient methods for composition that can model meaning composition not only of simple phrases, but also more complex phenomena such as coercion or composition with fine-grained types.", "labels": [], "entities": []}, {"text": "Despite continued efforts to find a general method for composition and various approaches for the composition of specific syntactic structures (e.g. adjective-noun composition, or the composition of transitive verbs and direct objects (), the modeling of compositionality is still an important challenge for distributional semantics.", "labels": [], "entities": []}, {"text": "Moreover, the validation of proposed methods for composition has used relatively small datasets of human similarity judgements.", "labels": [], "entities": []}, {"text": "Although such studies comparing similarity judgements have their merits, it would be interesting to have studies that evaluate methods for composition on a larger scale, using a larger test set of different specific compositions.", "labels": [], "entities": []}, {"text": "Such an evaluation would allow us to evaluate more thoroughly the different methods of composition that have been proposed.", "labels": [], "entities": []}, {"text": "This is one of the goals of this paper.", "labels": [], "entities": []}, {"text": "To achieve this goal, we make use of two different resources.", "labels": [], "entities": []}, {"text": "We have constructed a dataset for French containing a large number of pairs of a compositional expression (adjective-noun) and a single noun that is semantically close or identical to the composed expression.", "labels": [], "entities": []}, {"text": "These pairs have been extracted semi-automatically from the French Wiktionary.", "labels": [], "entities": [{"text": "French Wiktionary", "start_pos": 60, "end_pos": 77, "type": "DATASET", "confidence": 0.9382071793079376}]}, {"text": "We have also used the Semeval 2013 dataset of phrasal similarity judgements for English with similar pairs extracted semi-automatically from the English Wiktionary to construct a dataset for English for both adjective-noun and noun-noun composition.", "labels": [], "entities": [{"text": "Semeval 2013 dataset", "start_pos": 22, "end_pos": 42, "type": "DATASET", "confidence": 0.6191799938678741}]}, {"text": "This affords us a cross-linguistic comparison of the methods.", "labels": [], "entities": []}, {"text": "These data sets provide a substantial evaluation of the performance of different compositional methods.", "labels": [], "entities": []}, {"text": "We have tested three different methods of composition proposed in the literature, viz.", "labels": [], "entities": []}, {"text": "the additive and multiplicative model, as well as the lexical function approach (.", "labels": [], "entities": []}, {"text": "The two first methods are entirely general, and take as input automatically constructed vectors for adjectives and nouns.", "labels": [], "entities": []}, {"text": "The method by Baroni and Zamparelli, on the other hand, requires the acquisition of a particular function for each adjective, represented by a matrix.", "labels": [], "entities": []}, {"text": "The second goal of our paper is to generalise the functional approach in order to eliminate the need for an individual function for each adjective.", "labels": [], "entities": []}, {"text": "To this goal, we automatically learn a generalised lexical function, based on Baroni and Zamparelli's approach.", "labels": [], "entities": []}, {"text": "This generalised function combines with an adjective vector and a noun vector in a generalised way.", "labels": [], "entities": []}, {"text": "The performance of our novel generalised lexical function approach is evaluated on our test sets and proves competitive with the best, extant methods.", "labels": [], "entities": []}, {"text": "Our paper is organized as follows.", "labels": [], "entities": []}, {"text": "First, we discuss the different compositional models that we have evaluated in our study, briefly revisiting the different existing methods for composition, followed by a description of our generalisation of the lexical function approach.", "labels": [], "entities": []}, {"text": "Next, we report on our evaluation method and its results.", "labels": [], "entities": []}, {"text": "The results section is followed by a section that discusses work related to ours.", "labels": [], "entities": []}, {"text": "Lastly, we draw conclusions and layout some avenues for future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Percentage of correctly classified pairs for (adjective noun1, noun2) for both French and English  spaces.", "labels": [], "entities": [{"text": "Percentage", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9645534157752991}]}, {"text": " Table 3: Percentage of correctly classified pairs for (noun2 noun1, noun3) with negative examples from  existing pairs. Only the English space is tested.", "labels": [], "entities": []}]}