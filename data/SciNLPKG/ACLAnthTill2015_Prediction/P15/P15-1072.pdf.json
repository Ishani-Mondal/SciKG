{"title": [{"text": "A Unified Multilingual Semantic Representation of Concepts", "labels": [], "entities": [{"text": "Semantic Representation of Concepts", "start_pos": 23, "end_pos": 58, "type": "TASK", "confidence": 0.8028683066368103}]}], "abstractContent": [{"text": "Semantic representation lies at the core of several applications in Natural Language Processing.", "labels": [], "entities": [{"text": "Semantic representation", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.850913941860199}]}, {"text": "However, most existing semantic representation techniques cannot be used effectively for the representation of individual word senses.", "labels": [], "entities": []}, {"text": "We put forward a novel multilingual concept representation , called MUFFIN, which not only enables accurate representation of word senses in different languages, but also provides multiple advantages over existing approaches.", "labels": [], "entities": []}, {"text": "MUFFIN represents a given concept in a unified semantic space irrespective of the language of interest, enabling cross-lingual comparison of different concepts.", "labels": [], "entities": []}, {"text": "We evaluate our approach in two different evaluation benchmarks, semantic similarity and Word Sense Disam-biguation, reporting state-of-the-art performance on several standard datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic representation, i.e., the task of representing a linguistic item (such as a word or a word sense) in a mathematical or machine-interpretable form, is a fundamental problem in Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Semantic representation, i.e., the task of representing a linguistic item (such as a word or a word sense) in a mathematical or machine-interpretable form", "start_pos": 0, "end_pos": 154, "type": "Description", "confidence": 0.8351791394608361}, {"text": "Natural Language Processing (NLP)", "start_pos": 184, "end_pos": 217, "type": "TASK", "confidence": 0.7034315566221873}]}, {"text": "The Vector Space Model (VSM) is a prominent approach for semantic representation, with widespread popularity in numerous NLP applications.", "labels": [], "entities": [{"text": "semantic representation", "start_pos": 57, "end_pos": 80, "type": "TASK", "confidence": 0.8479701578617096}]}, {"text": "The prevailing methods for the computation of a vector space representation are based on distributional semantics).", "labels": [], "entities": []}, {"text": "However, these approaches, whether in their conventional co-occurrence based form (), or in their newer predictive branch), suffer from a major drawback: they are unable to model individual word senses or concepts, as they conflate different meanings of a word into a single vectorial representation.", "labels": [], "entities": []}, {"text": "This hinders the functionality of this group of vector space models in tasks such as Word Sense Disambiguation (WSD) that require the representation of individual word senses.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 85, "end_pos": 116, "type": "TASK", "confidence": 0.75374502936999}]}, {"text": "There have been several efforts to adapt and apply distributional approaches to the representation of word senses).", "labels": [], "entities": []}, {"text": "However, none of these techniques provides representations that are already linked to a standard sense inventory, and consequently such mapping has to be carried out either manually, or with the help of sense-annotated data.", "labels": [], "entities": []}, {"text": "addressed this issue and obtained vectors for individual word senses by leveraging WordNet glosses.", "labels": [], "entities": [{"text": "WordNet glosses", "start_pos": 83, "end_pos": 98, "type": "DATASET", "confidence": 0.9117589592933655}]}, {"text": "NASARI) is another approach that obtains accurate sense-specific representations by combining the complementary knowledge from WordNet and Wikipedia.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 127, "end_pos": 134, "type": "DATASET", "confidence": 0.9489135146141052}]}, {"text": "Graph-based approaches have also been successfully utilized to model individual words, or concepts (), drawing on the structural properties of semantic networks.", "labels": [], "entities": []}, {"text": "The applicability of all these techniques, however, is usually either constrained to a single language (usually English), or to a specific task.", "labels": [], "entities": []}, {"text": "We put forward MUFFIN (Multilingual, UniFied and Flexible INterpretation), a novel method that exploits both structural knowledge derived from semantic networks and distributional statistics from text corpora, to produce effective representations of individual word senses or concepts.", "labels": [], "entities": [{"text": "MUFFIN", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.7938500046730042}]}, {"text": "Our approach provides multiple advantages in comparison to the previous VSM techniques: 1.", "labels": [], "entities": [{"text": "VSM", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.8443942666053772}]}, {"text": "Multilingual: it enables sense representation in dozens of languages; 2.", "labels": [], "entities": [{"text": "sense representation", "start_pos": 25, "end_pos": 45, "type": "TASK", "confidence": 0.7247421443462372}]}, {"text": "Unified: it represents a linguistic item, irrespective of its language, in a unified seman- tic space having concepts as its dimensions, permitting direct comparison of different representations across languages, and hence enabling cross-lingual applications; 3.", "labels": [], "entities": []}, {"text": "Flexible: it can be readily applied to different NLP tasks with minimal adaptation.", "labels": [], "entities": [{"text": "Flexible", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9427569508552551}]}, {"text": "We evaluate our semantic representation on two different tasks in lexical semantics: semantic similarity and Word Sense Disambiguation.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 109, "end_pos": 134, "type": "TASK", "confidence": 0.6285383303960165}]}, {"text": "To assess the multilingual capability of our approach, we also perform experiments on languages other than English on both tasks, and across languages for semantic similarity.", "labels": [], "entities": []}, {"text": "We report state-of-the-art performance on multiple datasets and settings in both frameworks, which confirms the reliability and flexibility of our representations.", "labels": [], "entities": []}], "datasetContent": [{"text": "We assess the reliability of MUFFIN in two standard evaluation benchmarks: semantic similarity (Section 4.1) and Word Sense Disambiguation (Section 4.2).", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 113, "end_pos": 138, "type": "TASK", "confidence": 0.5674042999744415}]}, {"text": "We picked the RG-65 dataset as our monolingual word similarity dataset.", "labels": [], "entities": [{"text": "RG-65 dataset", "start_pos": 14, "end_pos": 27, "type": "DATASET", "confidence": 0.9122729003429413}]}, {"text": "The dataset comprises 65 English word pairs which have been manually annotated by several annotators according to their similarity on a scale of 0 to 4.", "labels": [], "entities": []}, {"text": "We also perform evaluations on the French (Joubarne and Inkpen, 2011) and German ( adaptations of this dataset.", "labels": [], "entities": []}, {"text": "Hassan and Mihalcea (2009) developed two sets of cross-lingual datasets based on the English MC-30 and WordSim-353 () datasets, for four different languages: English, German, Romanian, and Arabic.", "labels": [], "entities": [{"text": "WordSim-353 () datasets", "start_pos": 103, "end_pos": 126, "type": "DATASET", "confidence": 0.811478873093923}]}, {"text": "However, the construction procedure they adopted, consisting of translating the pairs to other languages while preserving the original similarity scores, has led to inconsistencies in the datasets.", "labels": [], "entities": []}, {"text": "For instance, the Spanish dataset contains the identical pair mediodiamediodia with a similarity score of 3.42 (in the scale).", "labels": [], "entities": [{"text": "Spanish dataset", "start_pos": 18, "end_pos": 33, "type": "DATASET", "confidence": 0.9013575911521912}]}, {"text": "Additionally, the datasets contain several orthographic errors, such as despliege and grua (instead of despliegue and gr\u00faa) and incorrect translations (e.g., the English noun implement translated into the Spanish verb implementar).", "labels": [], "entities": []}, {"text": "Kennedy and Hirst (2012) proposed a more reliable procedure that leverages two existing aligned monolingual word similarity datasets for the construction of anew cross-lingual dataset.", "labels": [], "entities": []}, {"text": "To this end, for each two word pairs a-b and a'-b' in the two datasets, if the difference in the corresponding scores is greater than one, the pairs are discarded.", "labels": [], "entities": []}, {"text": "Otherwise, two new pairs a-b' and a'-b are created with a score equal to the average of the two original pairs' scores.", "labels": [], "entities": []}, {"text": "In the case of repeated pairs, we merge them into a single pair with a similarity equal to their average scores.", "labels": [], "entities": [{"text": "similarity", "start_pos": 71, "end_pos": 81, "type": "METRIC", "confidence": 0.9585021138191223}]}, {"text": "Using this procedure as a basis, created an English-French dataset consisting of 100 pairs.", "labels": [], "entities": []}, {"text": "We followed the same procedure and built two datasets for English-German (consisting of 125 pairs) and German-French (comprising 96 pairs) language pairs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Spearman (\u03c1) and Pearson (r) correlation performance of different systems on the English,  German and French RG-65 datasets.", "labels": [], "entities": [{"text": "Spearman (\u03c1)", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.9765179008245468}, {"text": "Pearson (r) correlation", "start_pos": 27, "end_pos": 50, "type": "METRIC", "confidence": 0.9235780954360961}, {"text": "English,  German and French RG-65 datasets", "start_pos": 91, "end_pos": 133, "type": "DATASET", "confidence": 0.6351902570043292}]}, {"text": " Table 3: Pearson correlation performance of dif- ferent similarity measures on the three cross- lingual RG-65 datasets.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.8263672292232513}, {"text": "RG-65 datasets", "start_pos": 105, "end_pos": 119, "type": "DATASET", "confidence": 0.9142062067985535}]}, {"text": " Table 4: F1 percentage performance on the SemEval-2013 Multilingual WSD datasets using Wikipedia  as sense inventory.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9991570711135864}, {"text": "SemEval-2013 Multilingual WSD datasets", "start_pos": 43, "end_pos": 81, "type": "DATASET", "confidence": 0.6197731494903564}]}]}