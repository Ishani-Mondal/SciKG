{"title": [{"text": "NEED4Tweet: A Twitterbot for Tweets Named Entity Extraction and Disambiguation", "labels": [], "entities": [{"text": "NEED4Tweet", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.948513925075531}]}], "abstractContent": [{"text": "In this demo paper, we present NEED4Tweet, a Twitterbot for named entity extraction (NEE) and disambiguation (NED) for Tweets.", "labels": [], "entities": [{"text": "named entity extraction (NEE)", "start_pos": 60, "end_pos": 89, "type": "TASK", "confidence": 0.7797331213951111}]}, {"text": "The straightforward application of state-of-the-art extraction and disambiguation approaches on informal text widely used in Tweets, typically results in significantly degraded performance due to the lack of formal structure; the lack of sufficient context required; and the seldom entities involved.", "labels": [], "entities": [{"text": "state-of-the-art extraction", "start_pos": 35, "end_pos": 62, "type": "TASK", "confidence": 0.7778532803058624}]}, {"text": "In this paper, we introduce a novel framework that copes with the introduced challenges.", "labels": [], "entities": []}, {"text": "We rely on contextual and semantic features more than syntactic features which are less informative.", "labels": [], "entities": []}, {"text": "We believe that disambiguation can help to improve the extraction process.", "labels": [], "entities": []}, {"text": "This mimics the way humans understand language.", "labels": [], "entities": []}], "introductionContent": [{"text": "Twitter is an important source for continuously and instantly updated information.", "labels": [], "entities": []}, {"text": "It contains a large amount of unstructured information about users, locations, events, etc.", "labels": [], "entities": []}, {"text": "Shortness and informality of Tweets are challenges for Natural Language Processing (NLP) tasks.", "labels": [], "entities": [{"text": "Shortness", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9090624451637268}]}, {"text": "Information Extraction (IE) is the NLP field of research that is concerned with obtaining structured information from unstructured text.", "labels": [], "entities": [{"text": "Information Extraction (IE)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8467282891273499}]}, {"text": "IE systems attempt to interpret human language text in order to extract information about different types of events, entities, or relationships.", "labels": [], "entities": [{"text": "IE", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.94044029712677}]}, {"text": "Named entity extraction (NEE) is a subtask of IE that aims to locate phrases (mentions) in the text that represent names of persons, organizations, or locations regardless of their type.", "labels": [], "entities": [{"text": "Named entity extraction (NEE)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7611292749643326}, {"text": "IE that aims to locate phrases (mentions) in the text that represent names of persons, organizations, or locations regardless of their type", "start_pos": 46, "end_pos": 185, "type": "Description", "confidence": 0.7022648579799212}]}, {"text": "Named entity disambiguation (NED) is the task of determining which concrete person, place, event, etc. is referred to by a mention.", "labels": [], "entities": [{"text": "Named entity disambiguation (NED) is the task of determining which concrete person, place, event, etc. is referred to by a mention", "start_pos": 0, "end_pos": 130, "type": "Description", "confidence": 0.7818845292696586}]}, {"text": "Wikipedia articles are widely used as an entity's reference.", "labels": [], "entities": []}, {"text": "Challenges: NEE and NED in informal text are challenging.", "labels": [], "entities": []}, {"text": "Here we summarize the challenges of NEE and NED for Tweets: \u2022 The informal language widely used in Tweets makes the extraction process more difficult.", "labels": [], "entities": []}, {"text": "Proper capitalization is a key feature that the state-of-the-art NEE approaches have relied on.", "labels": [], "entities": [{"text": "NEE", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.9386904239654541}]}, {"text": "However, this feature gets less attention from Twitter users when they write their Tweets.", "labels": [], "entities": []}, {"text": "\u2022 The limited length (140 characters) of Tweets forces the senders to provide dense information by using acronyms and informal language.", "labels": [], "entities": []}, {"text": "This makes both the extraction and the disambiguation processes more complex.", "labels": [], "entities": []}, {"text": "\u2022 The limited coverage of a Knowledge Base (KB) is another challenge facing NED for tweets.", "labels": [], "entities": []}, {"text": "According to), 5 million out of 15 million mentions on the Web cannot be linked to Wikipedia.", "labels": [], "entities": []}, {"text": "This means that relying only on a KB for NED leads to around 33% loss in the disambiguated entities.", "labels": [], "entities": []}, {"text": "This percentage is higher on Twitter because of its social nature where users also discuss information about seldom entities.", "labels": [], "entities": []}, {"text": "\u2022 The processes of NEE and NED involve degrees of uncertainty.", "labels": [], "entities": []}, {"text": "For example, in the tweet \"history should show that bush jr should be in jail or at least never should have been president\", for some NEE systems, it maybe uncertain whether the word 'jr' should be part of the mention bush or not.", "labels": [], "entities": []}, {"text": "This motivates us to fundamentally consider sets of possible alternatives in an early stage of the extraction and the disambiguation processes and do a later filtration instead of making hard decisions from the beginning.", "labels": [], "entities": []}, {"text": "\u2022 Named entity (NE) representation in KBs poses another NED challenge.", "labels": [], "entities": []}, {"text": "The YAGO KB () uses the Wikipedia anchor text as a possible mention representation for named entities.", "labels": [], "entities": [{"text": "YAGO KB", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.891827791929245}, {"text": "Wikipedia anchor text", "start_pos": 24, "end_pos": 45, "type": "DATASET", "confidence": 0.8936726252237955}]}, {"text": "However, there maybe more representations that do not appear in the Wikipedia anchor text, but are meant to refer to the entity because of a spelling mistake or because of anew abbreviation for the entity.", "labels": [], "entities": [{"text": "Wikipedia anchor text", "start_pos": 68, "end_pos": 89, "type": "DATASET", "confidence": 0.864911675453186}]}, {"text": "In this demo, we introduce NEED4Tweet, a Twitterbot fora combined system for NEE and NED in Tweets that uses their interdependency and mimics how humans exploit it in language understanding.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 167, "end_pos": 189, "type": "TASK", "confidence": 0.7221739143133163}]}, {"text": "The system is based on our work.", "labels": [], "entities": []}, {"text": "We use a generic open world approach for NED in Tweets for any named entity even though it has no Wikipedia article.", "labels": [], "entities": []}, {"text": "Mentions are disambiguated by assigning them to either a Wikipedia article or a homepage.", "labels": [], "entities": []}, {"text": "We handle the uncertainty involved in the extraction process by considering possible alternatives in an early stage then evaluate these alternatives later based on disambiguation outcomes.", "labels": [], "entities": []}, {"text": "The proposed approach is shown to be robust against the coverage of KBs and the informality of the used language.", "labels": [], "entities": []}, {"text": "2012) focus on the task of filtering Tweets containing a given a mention of topic-centric entity, depending whether the Tweet is actually related to the entity or not.", "labels": [], "entities": []}, {"text": "They develop a set of features (co-occurrence, Web-based features, collectionbased features) to find keywords for positive and negative cases.", "labels": [], "entities": []}, {"text": "Similar to our problem discussed in Section 3.2, is the problem of entity homepage finding, which was part of the TREC Web and entity tracks.", "labels": [], "entities": [{"text": "entity homepage finding", "start_pos": 67, "end_pos": 90, "type": "TASK", "confidence": 0.670755555232366}, {"text": "TREC Web", "start_pos": 114, "end_pos": 122, "type": "DATASET", "confidence": 0.8470456302165985}]}, {"text": "One of the proposed approaches for this task was ().", "labels": [], "entities": []}, {"text": "The authors combine content information with other sources as diverse as inlinks, URLs and anchors to find an entry page.", "labels": [], "entities": []}, {"text": "Although the TREC problem looks similar to ours, the Tweets' short informal nature makes it more tricky to find an entity reference page.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this experiment, we compare the performance of NEED4Tweet against two competitors: AIDA and DBpedia Spotlight.", "labels": [], "entities": [{"text": "DBpedia Spotlight", "start_pos": 95, "end_pos": 112, "type": "DATASET", "confidence": 0.8964477777481079}]}, {"text": "AIDA is a disambiguation system although it uses Stanford NER for automatic NE extraction.", "labels": [], "entities": [{"text": "AIDA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8917397856712341}, {"text": "Stanford NER", "start_pos": 49, "end_pos": 61, "type": "DATASET", "confidence": 0.8963821530342102}, {"text": "NE extraction", "start_pos": 76, "end_pos": 89, "type": "TASK", "confidence": 0.9102894067764282}]}, {"text": "We consider the combination of Stanford NER and the AIDA disambiguation system as one competitor to our extraction and disambiguation system.", "labels": [], "entities": [{"text": "Stanford NER", "start_pos": 31, "end_pos": 43, "type": "DATASET", "confidence": 0.9295818209648132}, {"text": "AIDA disambiguation system", "start_pos": 52, "end_pos": 78, "type": "DATASET", "confidence": 0.8665733138720194}]}, {"text": "DBpedia Spotlight) is a tool for automatically annotating mentions of DBpedia resources in text.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8782814145088196}]}, {"text": "We used DBpedia Spotlight through its Annotate Web Service endpoint.", "labels": [], "entities": [{"text": "DBpedia Spotlight", "start_pos": 8, "end_pos": 25, "type": "DATASET", "confidence": 0.9251866936683655}, {"text": "Annotate Web Service endpoint", "start_pos": 38, "end_pos": 67, "type": "DATASET", "confidence": 0.8350151926279068}]}, {"text": "We used the NESpotter implementation for the extraction configuration.", "labels": [], "entities": []}, {"text": "The results in show the superiority of NEED4Tweet over DBpedia Spotlight and the combined Stanford and AIDA system.", "labels": [], "entities": [{"text": "NEED4Tweet", "start_pos": 39, "end_pos": 49, "type": "DATASET", "confidence": 0.8524469137191772}, {"text": "DBpedia Spotlight", "start_pos": 55, "end_pos": 72, "type": "DATASET", "confidence": 0.9139750003814697}]}, {"text": "More experimental results and analysis can be found in).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Combined evaluation of NEE and NED.", "labels": [], "entities": [{"text": "NEE", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.4073786437511444}]}]}