{"title": [{"text": "Improving Named Entity Recognition in Tweets via Detecting Non-Standard Words", "labels": [], "entities": [{"text": "Improving Named Entity Recognition", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8765842914581299}, {"text": "Detecting Non-Standard Words", "start_pos": 49, "end_pos": 77, "type": "TASK", "confidence": 0.7809802293777466}]}], "abstractContent": [{"text": "Most previous work of text normalization on informal text made a strong assumption that the system has already known which tokens are non-standard words (NSW) and thus need normalization.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.7668775916099548}]}, {"text": "However, this is not realistic.", "labels": [], "entities": []}, {"text": "In this paper, we propose a method for NSW detection.", "labels": [], "entities": [{"text": "NSW detection", "start_pos": 39, "end_pos": 52, "type": "TASK", "confidence": 0.9722304344177246}]}, {"text": "In addition to the information based on the dictionary , e.g., whether a word is out-of-vocabulary (OOV), we leverage novel information derived from the normalization results for OOV words to help make decisions.", "labels": [], "entities": []}, {"text": "Second, this paper investigates two methods using NSW detection results for named entity recognition (NER) in social media data.", "labels": [], "entities": [{"text": "NSW detection", "start_pos": 50, "end_pos": 63, "type": "TASK", "confidence": 0.786147952079773}, {"text": "named entity recognition (NER) in social media", "start_pos": 76, "end_pos": 122, "type": "TASK", "confidence": 0.8287902209493849}]}, {"text": "One adopts a pipeline strategy , and the other uses a joint decoding fashion.", "labels": [], "entities": []}, {"text": "We also create anew data set with newly added normalization annotation beyond the existing named entity labels.", "labels": [], "entities": []}, {"text": "This is the first data set with such annotation and we release it for research purpose.", "labels": [], "entities": []}, {"text": "Our experiment results demonstrate the effectiveness of our NSW detection method and the benefit of NSW detection for NER.", "labels": [], "entities": [{"text": "NSW detection", "start_pos": 60, "end_pos": 73, "type": "TASK", "confidence": 0.7529680728912354}, {"text": "NSW detection", "start_pos": 100, "end_pos": 113, "type": "TASK", "confidence": 0.726315051317215}, {"text": "NER", "start_pos": 118, "end_pos": 121, "type": "TASK", "confidence": 0.9470134377479553}]}, {"text": "Our proposed methods perform better than the state-of-the-art NER system.", "labels": [], "entities": [{"text": "NER", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.7759447693824768}]}], "introductionContent": [{"text": "Short text messages or comments from social media websites such as Facebook and Twitter have become one of the most popular communication forms in recent years.", "labels": [], "entities": []}, {"text": "However, abbreviations, misspelled words and many other non-standard words are very common in short texts for various reasons (e.g., length limitation, need to convey much information, writing style).", "labels": [], "entities": []}, {"text": "They post problems to many NLP techniques in this domain.", "labels": [], "entities": []}, {"text": "There are many ways to improve language processing performance on the social media data.", "labels": [], "entities": []}, {"text": "One is to leverage normalization techniques to automatically convert the non-standard words into the corresponding standard words (.", "labels": [], "entities": []}, {"text": "Intuitively this will ease subsequent language processing modules.", "labels": [], "entities": []}, {"text": "For example, if '2mr' is converted to 'tomorrow', a text-to-speech system will know how to pronounce it, a part-ofspeech (POS) tagger can label it correctly, and an information extraction system can identify it as a time expression.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 165, "end_pos": 187, "type": "TASK", "confidence": 0.7021959275007248}]}, {"text": "This normalization task has received an increasing attention in social media language processing.", "labels": [], "entities": [{"text": "social media language processing", "start_pos": 64, "end_pos": 96, "type": "TASK", "confidence": 0.6283912509679794}]}, {"text": "However, most of previous work on normalization assumed that they already knew which tokens are NSW that need normalization.", "labels": [], "entities": [{"text": "normalization", "start_pos": 34, "end_pos": 47, "type": "TASK", "confidence": 0.9764837026596069}]}, {"text": "Then different methods are applied only to these tokens.", "labels": [], "entities": []}, {"text": "To our knowledge, Han and Baldwin (2011) is the only previous work which made a pilot research on NSW detection.", "labels": [], "entities": [{"text": "NSW detection", "start_pos": 98, "end_pos": 111, "type": "TASK", "confidence": 0.8917383551597595}]}, {"text": "One straightforward method to do this is to use a dictionary to classify a token into in-vocabulary (IV) words and out-of-vocabulary (OOV) words, and just treat all the OOV words as NSW.", "labels": [], "entities": []}, {"text": "The shortcoming of this method is obvious.", "labels": [], "entities": []}, {"text": "For example, tokens like 'iPhone', 'PES'(a game name) and 'Xbox' will be considered as NSW, however, these words do not need normalization.", "labels": [], "entities": [{"text": "NSW", "start_pos": 87, "end_pos": 90, "type": "METRIC", "confidence": 0.9183672666549683}]}, {"text": "Han and Baldwin (2011) called these OOV words correct-OOV, and named those OOV words that do need normalization as ill-OOV.", "labels": [], "entities": []}, {"text": "We will follow their naming convention and use these two terms in our study.", "labels": [], "entities": []}, {"text": "In this paper, we propose two methods to classify tokens in informal text into three classes: IV, correct-OOV, and ill-OOV.", "labels": [], "entities": []}, {"text": "In the following, we call this task the NSW detection task, and these three labels NSW labels or classes.", "labels": [], "entities": [{"text": "NSW detection task", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.8937230507532755}]}, {"text": "The novelty of our work is that we incorporate a token's normalization information to assist this clas-sification process.", "labels": [], "entities": []}, {"text": "Our experiment results demonstrate that our proposed system gives a significant performance improvement on NSW detection compared with the dictionary baseline system.", "labels": [], "entities": [{"text": "NSW detection", "start_pos": 107, "end_pos": 120, "type": "TASK", "confidence": 0.8689046204090118}]}, {"text": "On the other hand, the impact of normalization or NSW detection on NER has not been well studied in social media domain.", "labels": [], "entities": [{"text": "NSW detection", "start_pos": 50, "end_pos": 63, "type": "TASK", "confidence": 0.9237438142299652}, {"text": "NER", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.9841518402099609}]}, {"text": "In this paper, we propose two methods to incorporate the NSW detection information: one is a pipeline system that just uses the predicted NSW labels as additional features in an NER system; the other one uses joint decoding, where we can simultaneously decide a token's NSW and NER labels.", "labels": [], "entities": [{"text": "NSW detection", "start_pos": 57, "end_pos": 70, "type": "TASK", "confidence": 0.8547810018062592}]}, {"text": "Our experiment results show that our proposed joint decoding performs better than the pipeline method, and it outperforms the state-of-the-art NER system.", "labels": [], "entities": []}, {"text": "Our contributions in this paper are as follows: (1) We proposed a NSW detection model by leveraging normalization information of the OOV tokens.", "labels": [], "entities": [{"text": "NSW detection", "start_pos": 66, "end_pos": 79, "type": "TASK", "confidence": 0.8945189416408539}]}, {"text": "(2) We created a data set with new NSW and normalization information, in addition to the existing NER labels.", "labels": [], "entities": [{"text": "NSW and normalization", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.49859094619750977}]}, {"text": "(3) It is the first time to our knowledge that an effective and joint approach is proposed to combine the NSW detection and NER techniques to improve the performance of these two tasks at the same time on social media data.", "labels": [], "entities": [{"text": "NSW detection", "start_pos": 106, "end_pos": 119, "type": "TASK", "confidence": 0.8496005237102509}, {"text": "NER", "start_pos": 124, "end_pos": 127, "type": "TASK", "confidence": 0.9481368660926819}]}, {"text": "(4) We demonstrate the effectiveness of our proposed method.", "labels": [], "entities": []}, {"text": "Our proposed NER system outperforms the state-of-the-art system.", "labels": [], "entities": [{"text": "NER", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9378121495246887}]}], "datasetContent": [{"text": "The NSW detection model is trained using the data released by.", "labels": [], "entities": [{"text": "NSW detection", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.7451053857803345}]}, {"text": "It has 2,577 Twitter messages (selected from the Edinburgh Twitter corpus (), in which there are 2,333 unique pairs of NSW and their standard words.", "labels": [], "entities": [{"text": "Edinburgh Twitter corpus", "start_pos": 49, "end_pos": 73, "type": "DATASET", "confidence": 0.9874375065167745}]}, {"text": "This data is used for training the different normalization models.", "labels": [], "entities": []}, {"text": "We labeled this data set using the given dictionary for NSW detection.", "labels": [], "entities": [{"text": "NSW detection", "start_pos": 56, "end_pos": 69, "type": "TASK", "confidence": 0.8607251048088074}]}, {"text": "4,121 tokens are labeled as ill-OOV, 1,455 as correct-OOV, and the rest 33,740 tokens are IV words.", "labels": [], "entities": [{"text": "correct-OOV", "start_pos": 46, "end_pos": 57, "type": "METRIC", "confidence": 0.9456819295883179}]}, {"text": "We have two test sets for evaluating the NSW detection system.", "labels": [], "entities": [{"text": "NSW detection", "start_pos": 41, "end_pos": 54, "type": "TASK", "confidence": 0.7212954759597778}]}, {"text": "One is from (Han and Baldwin, 2011), which includes 549 tweets.", "labels": [], "entities": []}, {"text": "Each tweet contains at least one ill-OOV and the corresponding correct word.", "labels": [], "entities": []}, {"text": "We call it Test set 1 in the following.", "labels": [], "entities": [{"text": "Test set 1", "start_pos": 11, "end_pos": 21, "type": "DATASET", "confidence": 0.9248501658439636}]}, {"text": "The other is from (, who further processed the tweets data from).", "labels": [], "entities": []}, {"text": "Briefly, released 2,347 tweets with their designed POS tags for social media text, and then further annotated this data with normalization information for each token.", "labels": [], "entities": []}, {"text": "The released data by) contains 798 tweets with ill-OOV.", "labels": [], "entities": []}, {"text": "We use these 798 tweets as the second data set for NSW detection, and call it Test set 2 in the following.", "labels": [], "entities": [{"text": "NSW detection", "start_pos": 51, "end_pos": 64, "type": "TASK", "confidence": 0.8169576525688171}]}, {"text": "In addition, we use all of these 2,347 tweets to train a POS model which then is used to predict tokens' POS tags for NER (see Section 3.2 about the POS tags).", "labels": [], "entities": []}, {"text": "The CRF model is implemented using the pocket-CRF toolkit . The SRILM toolkit) is used to build the character-level language model (LM) for generating the LM features in NSW detection system.", "labels": [], "entities": [{"text": "NSW detection", "start_pos": 170, "end_pos": 183, "type": "TASK", "confidence": 0.7968921065330505}]}, {"text": "The data with the NER labels are from) who annotated 2,396 tweets (34K tokens) with named entities, but there is no information on the tweets' ill-OOV words.", "labels": [], "entities": []}, {"text": "In order to evaluate the impact of ill-OOV on NER, we ask six annotators to annotate the ill-OOV words and the corresponding standard words in this data.", "labels": [], "entities": [{"text": "NER", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.6530731916427612}]}, {"text": "There are only 1,012 sentences with ill-OOV words.", "labels": [], "entities": []}, {"text": "We use all the sentences (2,396) for the NER experiments.", "labels": [], "entities": [{"text": "NER", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.5791841745376587}]}, {"text": "This data set, to our knowledge, is the first one having both ill-OOV and NER annotation in social media domain.", "labels": [], "entities": []}, {"text": "For joint decoding, the parameters \u03b1 and \u03b2 are empirically set as 0.95 and 0.5.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: NSW detection results.", "labels": [], "entities": [{"text": "NSW detection", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.883928507566452}]}, {"text": " Table 4: Feature impact on NSW detection on Test  Set 1. The feature number corresponds to that in  Table 1.", "labels": [], "entities": [{"text": "NSW detection", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.7450162172317505}, {"text": "Test  Set 1", "start_pos": 45, "end_pos": 56, "type": "DATASET", "confidence": 0.8774865468343099}]}, {"text": " Table 6: NSW detection results on the data from  (Ritter et al., 2011) with our new NSW annotation.", "labels": [], "entities": [{"text": "NSW detection", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.7861884534358978}]}, {"text": " Table 7: NER results from different systems on  data from (Ritter et al., 2011).", "labels": [], "entities": [{"text": "NER", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.9645060300827026}]}, {"text": " Table 8: Pipeline NER performance using differ- ent features. The feature number corresponds to  that in", "labels": [], "entities": [{"text": "Pipeline NER", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.8292821049690247}]}]}