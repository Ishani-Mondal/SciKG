{"title": [{"text": "Cross-lingual Transfer of Named Entity Recognizers without Parallel Corpora", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose an approach to cross-lingual named entity recognition model transfer without the use of parallel corpora.", "labels": [], "entities": [{"text": "cross-lingual named entity recognition model transfer", "start_pos": 26, "end_pos": 79, "type": "TASK", "confidence": 0.7408162752787272}]}, {"text": "In addition to global de-lexicalized features, we introduce multilingual gazetteers that are generated using graph propagation, and cross-lingual word representation map-pings without the use of parallel data.", "labels": [], "entities": []}, {"text": "We target the e-commerce domain, which is challenging due to its unstructured and noisy nature.", "labels": [], "entities": []}, {"text": "The experiments have shown that our approaches beat the strong MT baseline, where the English model is transferred to two languages: Spanish and Chi-nese.", "labels": [], "entities": [{"text": "MT", "start_pos": 63, "end_pos": 65, "type": "TASK", "confidence": 0.9370429515838623}]}], "introductionContent": [{"text": "Named Entity Recognition (NER) is usually solved by a supervised learning approach, where sequential labeling models are trained from a large amount of manually annotated corpora.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7958830992380778}]}, {"text": "However, such rich annotated data only exist for resourcerich languages such as English, and building NER systems for the majority of resource-poor languages, or specific domains in any languages, still poses a great challenge.", "labels": [], "entities": []}, {"text": "Annotation projection through parallel text (), ( , () has been traditionally used to overcome this issue, where the annotated tags in the source (resource-rich) language are projected via word-aligned bilingual parallel text (bitext) and used to train sequential labeling models in the (resource-poor) target language.", "labels": [], "entities": [{"text": "Annotation projection", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9014564752578735}]}, {"text": "However, this could lead to two issues: firstly, word alignment and projected tags are potentially noisy, making the trained models sub-optimal.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 49, "end_pos": 63, "type": "TASK", "confidence": 0.808239221572876}]}, {"text": "Instead of projecting noisy labels explicitly, project posterior marginals expectations as soft constraints.", "labels": [], "entities": []}, {"text": "projected POS tags from source language types to target language trigarms using graph propagation and used the projected label distribution to train robust POS taggers.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 156, "end_pos": 167, "type": "TASK", "confidence": 0.7627908885478973}]}, {"text": "Secondly, the availability of such bitext is limited especially for resourcepoor languages and domains, where it is often the case that available resources are moderately-sized monolingual/comparable corpora and small bilingual dictionaries.", "labels": [], "entities": []}, {"text": "Instead, we seek a direct transfer approach) to cross-lingual NER (also classified as transductive transfer learning and closely related to domain adaptation).", "labels": [], "entities": []}, {"text": "Specifically, we only assume the availability of comparable corpora and small-sized bilingual dictionaries, and use the same sequential tagging model trained on the source corpus for tagging the target corpus.", "labels": [], "entities": []}, {"text": "Direct transfer approaches are extensively studied for cross-lingual dependency parser transfer.", "labels": [], "entities": [{"text": "cross-lingual dependency parser transfer", "start_pos": 55, "end_pos": 95, "type": "TASK", "confidence": 0.7541508078575134}]}, {"text": "For example, built a constituent parser using direct transfer between closely related languages, namely, Danish and Swedish.", "labels": [], "entities": []}, {"text": "trained de-lexicalized dependency parsers in English and then \"re-lexicalized\" the parser.", "labels": [], "entities": []}, {"text": "However, crosslingual transfer of named entity taggers have not been studied enough, and this paper, to the best of the authors' knowledge, is the first to apply direct transfer learning to NER.", "labels": [], "entities": [{"text": "crosslingual transfer of named entity taggers", "start_pos": 9, "end_pos": 54, "type": "TASK", "confidence": 0.8437794794638952}, {"text": "NER", "start_pos": 190, "end_pos": 193, "type": "TASK", "confidence": 0.9242531061172485}]}, {"text": "Transfer of NER taggers poses a difficult challenge that is different from syntax transfer: most of the past work deals with de-lexicalized parsers, yet one of the most important clues for NER, gazetteers, is inherently lexicalized.", "labels": [], "entities": [{"text": "Transfer of NER taggers", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6988756507635117}, {"text": "syntax transfer", "start_pos": 75, "end_pos": 90, "type": "TASK", "confidence": 0.738137423992157}]}, {"text": "Also, various features used for dependency parsing (Universal POS tags, unsupervised clustering, etc.) are yet to 390: System Framework be proven useful for direct transfer of NER.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.8060259222984314}]}, {"text": "Therefore, the contributions of this paper is as follows: 1.", "labels": [], "entities": []}, {"text": "We show that direct transfer approach for multilingual NER actually works and performs better than the strong MT baseline (), where the system's output in the source language is simply machine translated into the target language.", "labels": [], "entities": []}, {"text": "2. We explore various non-lexical features, namely, Universal POS tags and Brown cluster mapping, which are deemed effective for multilingual NER transfer.", "labels": [], "entities": [{"text": "NER transfer", "start_pos": 142, "end_pos": 154, "type": "TASK", "confidence": 0.9005407094955444}]}, {"text": "Although brown cluster mapping), Universal POS Tagset ( , and re-lexicalization and self training) are shown to be effective for direct transfer of dependency parsers, there have been no studies exploring these features for NER transfer.", "labels": [], "entities": [{"text": "POS Tagset", "start_pos": 43, "end_pos": 53, "type": "TASK", "confidence": 0.5250410288572311}, {"text": "NER transfer", "start_pos": 224, "end_pos": 236, "type": "TASK", "confidence": 0.9840067625045776}]}, {"text": "3. We show that gazetteers can actually be generated only from the source language gazetteers and a comparable corpus, through a technique which we call gazetteer expansion based on semi-supervised graph propagation (", "labels": [], "entities": [{"text": "gazetteer expansion", "start_pos": 153, "end_pos": 172, "type": "TASK", "confidence": 0.7753109037876129}]}], "datasetContent": [{"text": "The targeted dataset contains a list of products (titles and descriptions).", "labels": [], "entities": []}, {"text": "The titles of products are \u2248 10 words long and poorly structured, adding more difficulties to our task.", "labels": [], "entities": []}, {"text": "On the other hand,: Language-Tags Numbers Stats the length of product descriptions ranges from 12-130 words.", "labels": [], "entities": []}, {"text": "The e-commerce genre poses the need to introduce new NE tagset as opposed to the conventional ones, thus we introduce 6 tag types: 1) Color; 2) Brand names; 3) Size; 4) Type: e.g. \"camera,\" \"shirt\"; 5) Material: e.g. \"plastic\", \"cotton\"; 6) Model: the model number of a product: e.g., \"A1533.\".", "labels": [], "entities": [{"text": "A1533.", "start_pos": 286, "end_pos": 292, "type": "DATASET", "confidence": 0.7288174629211426}]}, {"text": "For the rest of the experiments, English (EN) is the source language, whereas we experiment with Spanish (ES) and Chinese (ZH) as target languages.", "labels": [], "entities": []}, {"text": "The datasets used are: i) Training data: 1800 annotated English products from Rakuten.com shopping; ii) Test data: 300 ES products from Rakuten Spain (Rakuten, 2013b) and 500 products from Rakuten Taiwan (Rakuten, 2013c); iii) Brown clustering: English: Rakuten shopping 2013 dump (19m unique products with 607m tokens); Spanish: Rakuten Spain 2013 dump (700K unique products that contains 41m tokens) in addition to Spanish Wikipedia dump (Al-Rfou', 2013); Chinese: Wikipedia Chinese 2014 dump (147m tokens) plus 16k products crawled from Rakuten Taiwan.", "labels": [], "entities": []}, {"text": "shows the numbers of tags per category for each language.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Language-Tags Numbers Stats", "labels": [], "entities": []}]}