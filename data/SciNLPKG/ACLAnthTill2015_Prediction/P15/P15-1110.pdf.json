{"title": [{"text": "Feature Optimization for Constituent Parsing via Neural Networks", "labels": [], "entities": [{"text": "Constituent Parsing via Neural Networks", "start_pos": 25, "end_pos": 64, "type": "TASK", "confidence": 0.7436586499214173}]}], "abstractContent": [{"text": "The performance of discriminative constituent parsing relies crucially on feature engineering, and effective features usually have to be carefully selected through a painful manual process.", "labels": [], "entities": [{"text": "discriminative constituent parsing", "start_pos": 19, "end_pos": 53, "type": "TASK", "confidence": 0.6781774361928304}]}, {"text": "In this paper, we propose to automatically learn a set of effective features via neural networks.", "labels": [], "entities": []}, {"text": "Specifically, we build a feedforward neu-ral network model, which takes as input a few primitive units (words, POS tags and certain contextual tokens) from the local context, induces the feature representation in the hidden layer and makes parsing predictions in the output layer.", "labels": [], "entities": []}, {"text": "The network simultaneously learns the feature representation and the prediction model parameters using aback propagation algorithm.", "labels": [], "entities": []}, {"text": "By pre-training the model on a large amount of automatically parsed data, and then fine-tuning on the manually annotated Treebank data, our parser achieves the highest F 1 score at 86.6% on Chi-nese Treebank 5.1, and a competitive F 1 score at 90.7% on English Treebank.", "labels": [], "entities": [{"text": "Treebank data", "start_pos": 121, "end_pos": 134, "type": "DATASET", "confidence": 0.9188248217105865}, {"text": "F 1 score", "start_pos": 168, "end_pos": 177, "type": "METRIC", "confidence": 0.9925161401430765}, {"text": "Chi-nese Treebank 5.1", "start_pos": 190, "end_pos": 211, "type": "DATASET", "confidence": 0.8268325527509054}, {"text": "F 1 score", "start_pos": 231, "end_pos": 240, "type": "METRIC", "confidence": 0.9901207486788431}, {"text": "English Treebank", "start_pos": 253, "end_pos": 269, "type": "DATASET", "confidence": 0.9929784536361694}]}, {"text": "More importantly, our parser generalizes well on cross-domain test sets, where we significantly outperform Berkeley parser by 3.4 points on average for Chinese and 2.5 points for English.", "labels": [], "entities": []}], "introductionContent": [{"text": "Constituent parsing seeks to uncover the phrase structure representation of sentences that can be used in a variety of natural language applications such as machine translation, information extraction and question answering.", "labels": [], "entities": [{"text": "Constituent parsing", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9154559969902039}, {"text": "machine translation", "start_pos": 157, "end_pos": 176, "type": "TASK", "confidence": 0.7800266444683075}, {"text": "information extraction", "start_pos": 178, "end_pos": 200, "type": "TASK", "confidence": 0.8244499564170837}, {"text": "question answering", "start_pos": 205, "end_pos": 223, "type": "TASK", "confidence": 0.9014541804790497}]}, {"text": "One of the major challenges for this task is that constituent parsers require an inference algorithm of high computational complexity in order to search over their large structural space, which makes it very hard to efficiently train discriminative models.", "labels": [], "entities": []}, {"text": "So, fora longtime, the task was mainly solved with generative models).", "labels": [], "entities": []}, {"text": "In the last few years, however, with the use of effective parsing strategies, approximate inference algorithms, and more efficient training methods, discriminative models began to surpass the generative models.", "labels": [], "entities": []}, {"text": "Just like other NLP tasks, the performance of discriminative constituent parsing crucially relies on feature engineering.", "labels": [], "entities": [{"text": "discriminative constituent parsing", "start_pos": 46, "end_pos": 80, "type": "TASK", "confidence": 0.6901176969210306}]}, {"text": "If the feature set is too small, it might underfit the model and leads to low performance.", "labels": [], "entities": []}, {"text": "On the other hand, too many features may result in an overfitting problem.", "labels": [], "entities": []}, {"text": "Usually, an effective set of features have to be designed manually and selected through repeated experiments (;.", "labels": [], "entities": []}, {"text": "Not only does this procedure require a lot of expertise, but it is also tedious and time-consuming.", "labels": [], "entities": []}, {"text": "Even after this painstaking process, it is still hard to say whether the selected feature set is complete or optimal to obtain the best possible results.", "labels": [], "entities": []}, {"text": "A more desirable alternative is to learn features automatically with machine learning algorithms.", "labels": [], "entities": []}, {"text": "proposed to learn features by representing the cross-products of some primitive units with low-rank tensors for dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.8380128741264343}]}, {"text": "However, to achieve competitive performance, they had to combine the learned features with the traditional hand-crafted features.", "labels": [], "entities": []}, {"text": "For constituent parsing, employed a recurrent neural network to induce features from an unbounded parsing history.", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.6703004539012909}]}, {"text": "However, the final performance was below the state of the art.", "labels": [], "entities": []}, {"text": "In this work, we design a much simpler neural network to automatically induce features from just the local context for constituent parsing.", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 119, "end_pos": 138, "type": "TASK", "confidence": 0.6756592988967896}]}, {"text": "Con-cretely, we choose the shift-reduce parsing strategy to build the constituent structure of a sentence, and train a feedforward neural network model to jointly learn feature representations and make parsing predictions.", "labels": [], "entities": [{"text": "parsing predictions", "start_pos": 202, "end_pos": 221, "type": "TASK", "confidence": 0.8873535096645355}]}, {"text": "The input layer of the network takes as input a few primitive units (words, POS tags and certain contextual tokens) from the local context, the hidden layer aims to induce a distributed feature representation by combining all the primitive units with different weights, and the output layer attempts to make parsing predictions based on the feature representation.", "labels": [], "entities": []}, {"text": "During the training process, the model simultaneously learns the feature representation and prediction model parameters using a backpropagation algorithm.", "labels": [], "entities": []}, {"text": "Theoretically, the learned feature representation is optimal (or at least locally optimal) for the parsing predictions.", "labels": [], "entities": [{"text": "parsing predictions", "start_pos": 99, "end_pos": 118, "type": "TASK", "confidence": 0.8950949907302856}]}, {"text": "In practice, however, our model does notwork well if it is only trained on the manually annotated Treebank data sets.", "labels": [], "entities": [{"text": "Treebank data sets", "start_pos": 98, "end_pos": 116, "type": "DATASET", "confidence": 0.9558890263239542}]}, {"text": "However, when pre-trained on a large amount of automatically parsed data and then fine-tuned on the Treebank data sets, our model achieves a fairly large improvement in performance.", "labels": [], "entities": [{"text": "Treebank data sets", "start_pos": 100, "end_pos": 118, "type": "DATASET", "confidence": 0.9783278703689575}]}, {"text": "We evaluated our model on both Chinese and English.", "labels": [], "entities": []}, {"text": "On standard data sets, our model reaches F 1 = 86.6% for Chinese and outperforms all the state-of-theart systems, and for English our final performance is F 1 = 90.7% and this result surpasses that of all the previous neural network based models and is comparable to the state-of-the-art systems.", "labels": [], "entities": [{"text": "F 1", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.9881583750247955}, {"text": "F 1", "start_pos": 155, "end_pos": 158, "type": "METRIC", "confidence": 0.9826724231243134}]}, {"text": "On cross-domain data sets, our model outperforms the Berkeley Parser 1 by 3.4 percentage points for Chinese and 2.5 percentage points for English.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows: Section 2 introduces the shift-reduce constituent parsing approach.", "labels": [], "entities": [{"text": "shift-reduce constituent parsing", "start_pos": 78, "end_pos": 110, "type": "TASK", "confidence": 0.6490185856819153}]}, {"text": "Section 3 describes our feature optimization model and some parameter estimation techniques.", "labels": [], "entities": [{"text": "feature optimization", "start_pos": 24, "end_pos": 44, "type": "TASK", "confidence": 0.7636560499668121}]}, {"text": "We discuss and analyze our experimental results in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 discusses related work.", "labels": [], "entities": []}, {"text": "Finally, we conclude this paper in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted experiments on the Penn Chinese Treebank (CTB) version 5.1 ( We also utilized some unlabeled corpora and used the word2vec 2 toolkit to train word embeddings.", "labels": [], "entities": [{"text": "Penn Chinese Treebank (CTB) version 5.1", "start_pos": 32, "end_pos": 71, "type": "DATASET", "confidence": 0.9772180020809174}]}, {"text": "For Chinese, we used the unlabeled Chinese Gigaword (LDC2003T09) and performed Chinese word segmentation using our in-house segmenter.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 79, "end_pos": 104, "type": "TASK", "confidence": 0.6034874121348063}]}, {"text": "For English, we randomly selected 9 million sentences from our in-house newswire corpus, which has no overlap with our training, testing and development sets.", "labels": [], "entities": []}, {"text": "We use Evalb 3 toolkit to evaluate parsing performance.", "labels": [], "entities": [{"text": "parsing", "start_pos": 35, "end_pos": 42, "type": "TASK", "confidence": 0.9717641472816467}]}, {"text": "In this subsection, we examined the robustness of our model by evaluating it on data sets from various domains.", "labels": [], "entities": []}, {"text": "We use the Berkeley Parser as our baseline parser, and trained it on our training set.", "labels": [], "entities": [{"text": "Berkeley Parser", "start_pos": 11, "end_pos": 26, "type": "DATASET", "confidence": 0.9425430297851562}]}, {"text": "For Chinese, we performed our experiments on the cross domain data sets from Chinese Treebank 8.0 ( . It consists of six domains: newswire (nw), magazine articles (mz), broadcast news (bn), broadcast conversation (bc), weblogs (wb) and discussion forums (df).", "labels": [], "entities": [{"text": "Chinese Treebank 8.0", "start_pos": 77, "end_pos": 97, "type": "DATASET", "confidence": 0.8702281713485718}]}, {"text": "Since all of the mz domain data is already included in our training set, we only selected sample sentences from the other five domains as the test sets 5 , and made sure these test sets had no overlap with our treebank training, development and test sets.", "labels": [], "entities": []}, {"text": "Note that we did not use any data from these five domains for training or development.", "labels": [], "entities": []}, {"text": "The models are still the ones described in the previous subsection.", "labels": [], "entities": []}, {"text": "The results are presented in.", "labels": [], "entities": []}, {"text": "Although our \"Supervised\" model got slightly worse performance than the Berkeley Parser (), as shown in, it outperformed the Berkeley Parser on the cross-domain data sets.", "labels": [], "entities": []}, {"text": "This suggests that the learned features can better adapt to cross-domain situations.", "labels": [], "entities": []}, {"text": "Compared with the Berkeley Parser, on average our \"Pretrain-Finetune\" model is 3.4 percentage points better in terms of parsing accuracy, and 3.2 percentage points better in terms of POS tagging accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 120, "end_pos": 127, "type": "TASK", "confidence": 0.9603407382965088}, {"text": "accuracy", "start_pos": 128, "end_pos": 136, "type": "METRIC", "confidence": 0.924708902835846}, {"text": "POS tagging", "start_pos": 183, "end_pos": 194, "type": "TASK", "confidence": 0.7026055753231049}, {"text": "accuracy", "start_pos": 195, "end_pos": 203, "type": "METRIC", "confidence": 0.7624601125717163}]}, {"text": "We also presented the performance of our pre-trained model (\"Only-Pretrain\").", "labels": [], "entities": []}, {"text": "We found the \"Only-Pretrain\" model performs poorly on this cross-domain data sets.", "labels": [], "entities": []}, {"text": "But even pretraining based on this less than competitive model, our \"Pretrain-Finetune\" model achieves significant improvement over the \"Supervised\" model.", "labels": [], "entities": []}, {"text": "So the Pre-Train strategy is crucial to our model.", "labels": [], "entities": []}, {"text": "For English, we performed our experiments on the cross-domain data sets from OntoNote 5.0 (, which consists of nw, mz, bn, bc, wb, df and telephone conversations (tc).", "labels": [], "entities": [{"text": "cross-domain data sets from OntoNote 5.0", "start_pos": 49, "end_pos": 89, "type": "DATASET", "confidence": 0.6967289944489797}]}, {"text": "We also performed experiments on the SMS domain, using data annotated by the LDC for the DARPA BOLT Program.", "labels": [], "entities": [{"text": "DARPA", "start_pos": 89, "end_pos": 94, "type": "DATASET", "confidence": 0.6396843791007996}, {"text": "BOLT", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.7395966053009033}]}, {"text": "We randomly selected 300 sentences for each domain as the test sets .) when evaluated on the standard Penn TreeBank test set), our parser is 2.5 percentage points better on average on the cross domain data sets.", "labels": [], "entities": [{"text": "Penn TreeBank test set", "start_pos": 102, "end_pos": 124, "type": "DATASET", "confidence": 0.9936544895172119}]}, {"text": "So our parser is also very robust for English on crossdomain data sets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Influence of primitive units.", "labels": [], "entities": []}, {"text": " Table 3: Semi-supervised training for Chinese.", "labels": [], "entities": []}, {"text": " Table 4: Semi-supervised training for English.", "labels": [], "entities": []}, {"text": " Table 5: Comparison with the state-of-the-art sys- tems on Chinese test set. * marks neural network  based systems.  \u2021 marks shift-reduce parsing sys- tems.", "labels": [], "entities": [{"text": "Chinese test set", "start_pos": 60, "end_pos": 76, "type": "DATASET", "confidence": 0.9408568541208903}]}, {"text": " Table 6: Comparing with the state-of-the-art sys- tems on English test set. * marks neural network  based systems.  \u2021 marks shift-reduce parsing sys- tems.", "labels": [], "entities": [{"text": "English test set", "start_pos": 59, "end_pos": 75, "type": "DATASET", "confidence": 0.9342322746912638}]}, {"text": " Table 7: Cross-domain performance for Chinese. The \"Only-Pretrain\" model cannot successfully parse  some sentences in bn domain, so we didn't give the numbers.", "labels": [], "entities": []}, {"text": " Table 8: Cross-domain performance for English.", "labels": [], "entities": []}]}