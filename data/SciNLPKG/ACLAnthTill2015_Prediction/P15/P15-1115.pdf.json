{"title": [{"text": "Semantic Role Labeling Improves Incremental Parsing", "labels": [], "entities": [{"text": "Semantic Role Labeling Improves Incremental Parsing", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.8429757555325826}]}], "abstractContent": [{"text": "Incremental parsing is the task of assigning a syntactic structure to an input sentence as it unfolds word byword.", "labels": [], "entities": [{"text": "Incremental parsing", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8553227186203003}]}, {"text": "Incre-mental parsing is more difficult than full-sentence parsing, as incomplete input increases ambiguity.", "labels": [], "entities": [{"text": "Incre-mental parsing", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8678674101829529}, {"text": "full-sentence parsing", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.7033825665712357}]}, {"text": "Intuitively, an incre-mental parser that has access to semantic information should be able to reduce ambiguity by ruling out semantically implausible analyses, even for incomplete input.", "labels": [], "entities": []}, {"text": "In this paper, we test this hypothesis by combining an incremental TAG parser with an incremental semantic role labeler in a discriminative framework.", "labels": [], "entities": []}, {"text": "We show a substantial improvement in parsing performance compared to the baseline parser, both in full-sentence F-score and in incre-mental F-score.", "labels": [], "entities": [{"text": "parsing", "start_pos": 37, "end_pos": 44, "type": "TASK", "confidence": 0.9662469029426575}, {"text": "F-score", "start_pos": 112, "end_pos": 119, "type": "METRIC", "confidence": 0.9322726726531982}, {"text": "F-score", "start_pos": 140, "end_pos": 147, "type": "METRIC", "confidence": 0.7580623626708984}]}], "introductionContent": [{"text": "When humans listen to speech, the input becomes available gradually as the speech signal unfolds.", "labels": [], "entities": []}, {"text": "Reading happens in a similarly gradual manner when the eyes scan a text.", "labels": [], "entities": [{"text": "Reading", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9332865476608276}]}, {"text": "There is good evidence that the human language processor is adapted to this and works incrementally, i.e., computes an interpretation for an incoming sentence on a wordby-word basis ().", "labels": [], "entities": []}, {"text": "Also language processing systems often deal with speech as it is spoken, or text as it is typed.", "labels": [], "entities": []}, {"text": "A dialogue system should start interpreting a sentence while it is spoken, and an information retrieval system should start retrieving results while the user is typing.", "labels": [], "entities": []}, {"text": "Incremental processing is therefore essential both for realistic models of human language processing and for NLP applications that react to user input in real time.", "labels": [], "entities": [{"text": "Incremental processing", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.856767475605011}]}, {"text": "In response to this, a number of incremental parsers have been developed, which use context-free grammar, dependency grammar, or tree-substitution grammars.", "labels": [], "entities": []}, {"text": "Typical applications of incremental parsers include speech recognition), machine translation (), reading time modeling, or dialogue systems ().", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.757989913225174}, {"text": "machine translation", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.806168407201767}, {"text": "reading time modeling", "start_pos": 97, "end_pos": 118, "type": "TASK", "confidence": 0.7716184258460999}]}, {"text": "Incremental parsing, however, is considerably harder than full-sentence parsing: when processing the n-th word in a sentence, an , the parser only has access to the left context (words a 1 . .", "labels": [], "entities": [{"text": "Incremental parsing", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8773014545440674}, {"text": "full-sentence parsing", "start_pos": 58, "end_pos": 79, "type": "TASK", "confidence": 0.7149531990289688}]}, {"text": "a n\u22121 ); the right context (words a n+1 . .", "labels": [], "entities": []}, {"text": "a N ) is not known yet.", "labels": [], "entities": []}, {"text": "This can lead to local ambiguity, i.e., produce additional syntactic analyses that are valid for the sentence prefix, but become invalid as the right context is processed.", "labels": [], "entities": []}, {"text": "As an example consider the sentence prefix in (1): (1) The athlete realized her goals . .", "labels": [], "entities": []}, {"text": ". a. at the competition b. were out of reach The prefix could continue as in (1-a), i.e., as a main clause structure.", "labels": [], "entities": []}, {"text": "Or the next words could be as in, in which case her goals is part of a subordinate clause.", "labels": [], "entities": []}, {"text": "Intuitively, an incremental parser that has access to semantic information would be able to decide which of these two analyses is likely to be correct, even without knowing the rest of the sentence.", "labels": [], "entities": []}, {"text": "If the NP her goals is a likely ARG1 of realized the parser should prefer the main clause structure.", "labels": [], "entities": [{"text": "ARG1", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.9140070676803589}]}, {"text": "On the other hand, if the NP is a likely ARG0 of an (as yet unseen) embedded verb, then the parser should go for the subordinate clause structure.", "labels": [], "entities": []}, {"text": "Note that the preference can easily be reversed: if the prefix was the athlete realized her shoes, then her shoes is very likely to bean ARG0 rather than an ARG1.", "labels": [], "entities": [{"text": "ARG0", "start_pos": 137, "end_pos": 141, "type": "METRIC", "confidence": 0.952565610408783}, {"text": "ARG1", "start_pos": 157, "end_pos": 161, "type": "DATASET", "confidence": 0.6949881315231323}]}, {"text": "The basis of this paper is the hypothesis that semantic information can aid incremental parsing.", "labels": [], "entities": []}, {"text": "To test this hypothesis, we combine an incremental TAG parser with an incremental semantic role labeling (iSRL) system.", "labels": [], "entities": []}, {"text": "The iSRL system takes prefix trees and computes their most likely semantic role assignments.", "labels": [], "entities": []}, {"text": "We show that these role assignments can be used to re-rank the output of the incremental parser, leading to substantial improvements in parsing performance compared to the baseline parser, both in full-sentence F-score and in incremental F-score.", "labels": [], "entities": [{"text": "F-score", "start_pos": 211, "end_pos": 218, "type": "METRIC", "confidence": 0.9093032479286194}, {"text": "F-score", "start_pos": 238, "end_pos": 245, "type": "METRIC", "confidence": 0.873777449131012}]}], "datasetContent": [{"text": "In addition to standard full-sentence labeled bracket score, we evaluate our model incrementally, by scoring the prefix trees generated for each sentence prefix).", "labels": [], "entities": []}, {"text": "For each prefix of the input sentence (two words or more), we compute the labeled bracket score for the minimal structure spanning that prefix.", "labels": [], "entities": []}, {"text": "The minimal structure is defined as the subtree rooted in the lowest common ancestor of the prefix nodes, while removing any leftover intermediate nodes on the right edge of the subtree that do not have a word in the prefix as their yield.", "labels": [], "entities": []}, {"text": "Although not the main focus of this paper, we also report full-sentence combined SRL accuracy (counting verb-predicates only).", "labels": [], "entities": [{"text": "SRL", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.7606651186943054}, {"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.8771008849143982}]}, {"text": "This score is obtained by re-applying the iSRL system to the syn-: Full-sentence parsing results 2 , area under the curve (AUC) for the incremental parsing results of, and combined SRL score across different groups of features.", "labels": [], "entities": [{"text": "Full-sentence parsing", "start_pos": 67, "end_pos": 88, "type": "TASK", "confidence": 0.6593252271413803}, {"text": "area under the curve (AUC)", "start_pos": 101, "end_pos": 127, "type": "METRIC", "confidence": 0.8607638818877084}, {"text": "SRL score", "start_pos": 181, "end_pos": 190, "type": "METRIC", "confidence": 0.8407803475856781}]}, {"text": "tactic parses output by our re-ranker.", "labels": [], "entities": []}, {"text": "(In contrast, work with gold-standard syntactic parses.)", "labels": [], "entities": []}, {"text": "We evaluate four variants of our model (see Section 4 for an explanation of the different groups of features): TREE is the model that uses tree features only; this essentially simulates standard parse reranking approaches such as the one of.", "labels": [], "entities": [{"text": "TREE", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.9966756105422974}]}, {"text": "SRL uses only features based on iSRL triples; it provides a proof-of-concept, demonstrating that the semantic information encoded in SRL triples can help the parser building better syntactic trees.", "labels": [], "entities": [{"text": "SRL", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6173673868179321}]}, {"text": "TREE+PLTAG adds PLTAG Features to the TREE model, taking advantage of local information specific to elementary PLTAG trees; TREE+PLTAG essentially provides a strong syntax-only baseline.", "labels": [], "entities": []}, {"text": "TREE+PLTAG+SRL combines SRL features and syntactic features.", "labels": [], "entities": [{"text": "TREE", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.6354883909225464}]}, {"text": "Finally, our baseline is the PLTAG parser of, using the original probability model without any re-ranking.", "labels": [], "entities": [{"text": "PLTAG parser", "start_pos": 29, "end_pos": 41, "type": "TASK", "confidence": 0.4709218442440033}]}, {"text": "A comparison with other incremental parsers would be desirable, but is not trivial to achieve.", "labels": [], "entities": []}, {"text": "This is because the PLTAG parser is trained and evaluated on aversion of the Penn Treebank that was converted to PLTAG format.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 77, "end_pos": 90, "type": "DATASET", "confidence": 0.9950244128704071}]}, {"text": "This renders our results not directly comparable to parsers that reproduce the Penn Treebank bracketing.", "labels": [], "entities": [{"text": "Penn Treebank bracketing", "start_pos": 79, "end_pos": 103, "type": "DATASET", "confidence": 0.9831564625104269}]}, {"text": "For example, the PLTAG parser produces deeper tree structures informed by Propbank and the noun phrase annotation of. gives the results of evaluating incremental parsing performance.", "labels": [], "entities": [{"text": "PLTAG parser", "start_pos": 17, "end_pos": 29, "type": "TASK", "confidence": 0.6410037875175476}, {"text": "Propbank", "start_pos": 74, "end_pos": 82, "type": "DATASET", "confidence": 0.951778769493103}]}, {"text": "The x-axis shows prefix length, and the y-axis shows incremental F-score computed as suggested by.", "labels": [], "entities": [{"text": "prefix length", "start_pos": 17, "end_pos": 30, "type": "METRIC", "confidence": 0.6472500860691071}, {"text": "F-score", "start_pos": 65, "end_pos": 72, "type": "METRIC", "confidence": 0.9876406788825989}]}, {"text": "Each point is averaged overall prefixes of a given length in the test set.", "labels": [], "entities": []}, {"text": "To quantify the trends shown in this figure, we also compute the area under the curve (AUC) for each feature combination; this is given in.", "labels": [], "entities": [{"text": "AUC)", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.9466651380062103}]}], "tableCaptions": [{"text": " Table 1: Full-sentence parsing results 2 , area under  the curve (AUC) for the incremental parsing re- sults of", "labels": [], "entities": [{"text": "Full-sentence parsing", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.7348875403404236}, {"text": "area under  the curve (AUC)", "start_pos": 44, "end_pos": 71, "type": "METRIC", "confidence": 0.7916390725544521}]}]}