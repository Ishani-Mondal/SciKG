{"title": [{"text": "Addressing the Rare Word Problem in Neural Machine Translation", "labels": [], "entities": [{"text": "Neural Machine Translation", "start_pos": 36, "end_pos": 62, "type": "TASK", "confidence": 0.6841667592525482}]}], "abstractContent": [{"text": "Neural Machine Translation (NMT) is anew approach to machine translation that has shown promising results that are comparable to traditional approaches.", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7869353840748469}, {"text": "machine translation", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.7640552818775177}]}, {"text": "A significant weakness in conventional NMT systems is their inability to correctly translate very rare words: end-to-end NMTs tend to have relatively small vocabularies with a single unk symbol that represents every possible out-of-vocabulary (OOV) word.", "labels": [], "entities": []}, {"text": "In this paper, we propose and implement an effective technique to address this problem.", "labels": [], "entities": []}, {"text": "We train an NMT system on data that is augmented by the output of a word alignment algorithm, allowing the NMT system to emit, for each OOV word in the target sentence, the position of its corresponding word in the source sentence.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 68, "end_pos": 82, "type": "TASK", "confidence": 0.7127201706171036}]}, {"text": "This information is later utilized in a post-processing step that translates every OOV word using a dictionary.", "labels": [], "entities": []}, {"text": "Our experiments on the WMT'14 English to French translation task show that this method provides a substantial improvement of up to 2.8 BLEU points over an equivalent NMT system that does not use this technique.", "labels": [], "entities": [{"text": "WMT'14 English to French translation task", "start_pos": 23, "end_pos": 64, "type": "TASK", "confidence": 0.7287191351254781}, {"text": "BLEU", "start_pos": 135, "end_pos": 139, "type": "METRIC", "confidence": 0.9990179538726807}]}, {"text": "With 37.5 BLEU points, our NMT system is the first to surpass the best result achieved on a WMT'14 contest task.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9992417097091675}, {"text": "NMT", "start_pos": 27, "end_pos": 30, "type": "DATASET", "confidence": 0.7092846035957336}, {"text": "WMT'14 contest task", "start_pos": 92, "end_pos": 111, "type": "DATASET", "confidence": 0.7042945822079977}]}], "introductionContent": [{"text": "Neural Machine Translation (NMT) is a novel approach to MT that has achieved promising results).", "labels": [], "entities": [{"text": "Neural Machine Translation (NMT)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7888132135073344}, {"text": "MT", "start_pos": 56, "end_pos": 58, "type": "TASK", "confidence": 0.9969450831413269}]}, {"text": "An NMT system is a conceptually simple large neural network that reads the en- * Work done while the authors were in Google.", "labels": [], "entities": []}, {"text": "tire source sentence and produces an output translation one word at a time.", "labels": [], "entities": []}, {"text": "NMT systems are appealing because they use minimal domain knowledge which makes them well-suited to any problem that can be formulated as mapping an input sequence to an output sequence).", "labels": [], "entities": []}, {"text": "In addition, the natural ability of neural networks to generalize implies that NMT systems will also generalize to novel word phrases and sentences that do not occur in the training set.", "labels": [], "entities": []}, {"text": "In addition, NMT systems potentially remove the need to store explicit phrase tables and language models which are used in conventional systems.", "labels": [], "entities": []}, {"text": "Finally, the decoder of an NMT system is easy to implement, unlike the highly intricate decoders used by phrase-based systems (.", "labels": [], "entities": []}, {"text": "Despite these advantages, conventional NMT systems are incapable of translating rare words because they have a fixed modest-sized vocabulary which forces them to use the unk symbol to represent the large number of out-of-vocabulary (OOV) words, as illustrated in.", "labels": [], "entities": []}, {"text": "Unsurprisingly, both and have observed that sentences with many rare words tend to be translated much more poorly than sentences containing mainly frequent words.", "labels": [], "entities": []}, {"text": "Standard phrase-based systems (), on the other hand, do not suffer from the rare word problem to the same extent because they can support a much larger vocabulary, and because their use of explicit alignments and phrase tables allows them to memorize the translations of even extremely rare words.", "labels": [], "entities": []}, {"text": "Motivated by the strengths of standard phrase-1 Due to the computationally intensive nature of the softmax, NMT systems often limit their vocabularies to be the top 30K-80K most frequent words in each language.", "labels": [], "entities": []}, {"text": "However, has very recently proposed an efficient approximation to the softmax that allows for training NTMs with very large vocabularies.", "labels": [], "entities": []}, {"text": "As discussed in Section 2, this technique is complementary to ours.", "labels": [], "entities": []}, {"text": "en: The ecotax portico in Pont-de-Buis , . .", "labels": [], "entities": [{"text": "Pont-de-Buis", "start_pos": 26, "end_pos": 38, "type": "DATASET", "confidence": 0.8084641098976135}]}, {"text": ", was taken down on Thursday morning fr: Le portiqu\u00e9 ecotaxe de Pont-de-Buis , . .", "labels": [], "entities": []}, {"text": ", a \u00b4 et\u00e9 d\u00e9mont\u00e9 jeudi matin nn: Le unk de unk\u00e0unk`unk\u00e0 unk , . .", "labels": [], "entities": []}, {"text": ", a \u00b4 et\u00e9 pris le jeudi matin: Example of the rare word problem -An English source sentence (en), a human translation to French (fr), and a translation produced by one of our neural network systems (nn) before handling OOV words.", "labels": [], "entities": []}, {"text": "We highlight words that are unknown to our model.", "labels": [], "entities": []}, {"text": "The token unk indicates an OOV word.", "labels": [], "entities": []}, {"text": "We also show a few important alignments between the pair of sentences.", "labels": [], "entities": []}, {"text": "based system, we propose and implement a novel approach to address the rare word problem of NMTs.", "labels": [], "entities": []}, {"text": "Our approach annotates the training corpus with explicit alignment information that enables the NMT system to emit, for each OOV word, a \"pointer\" to its corresponding word in the source sentence.", "labels": [], "entities": []}, {"text": "This information is later utilized in a post-processing step that translates the OOV words using a dictionary or with the identity translation, if no translation is found.", "labels": [], "entities": []}, {"text": "Our experiments confirm that this approach is effective.", "labels": [], "entities": []}, {"text": "On the English to French WMT'14 translation task, this approach provides an improvement of up to 2.8 (if the vocabulary is relatively small) BLEU points over an equivalent NMT system that does not use this technique.", "labels": [], "entities": [{"text": "English to French WMT'14 translation task", "start_pos": 7, "end_pos": 48, "type": "TASK", "confidence": 0.6224742780129114}, {"text": "BLEU", "start_pos": 141, "end_pos": 145, "type": "METRIC", "confidence": 0.9992758631706238}]}, {"text": "Moreover, our system is the first NMT that outperforms the winner of a WMT'14 task.", "labels": [], "entities": [{"text": "WMT'14 task", "start_pos": 71, "end_pos": 82, "type": "TASK", "confidence": 0.5493432283401489}]}], "datasetContent": [{"text": "We evaluate the effectiveness of our OOV models on the WMT'14 English-to-French translation task.", "labels": [], "entities": [{"text": "WMT'14 English-to-French translation task", "start_pos": 55, "end_pos": 96, "type": "TASK", "confidence": 0.7878203988075256}]}, {"text": "Translation quality is measured with the BLEU metric () on the newstest2014 test set (which has 3003 sentences).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.9977130889892578}, {"text": "newstest2014 test set", "start_pos": 63, "end_pos": 84, "type": "DATASET", "confidence": 0.9762563308080038}]}], "tableCaptions": []}