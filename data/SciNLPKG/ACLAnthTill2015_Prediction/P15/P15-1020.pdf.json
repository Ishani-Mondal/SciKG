{"title": [{"text": "Syntax-based Simultaneous Translation through Prediction of Unseen Syntactic Constituents", "labels": [], "entities": [{"text": "Simultaneous Translation", "start_pos": 13, "end_pos": 37, "type": "TASK", "confidence": 0.8323112428188324}]}], "abstractContent": [{"text": "Simultaneous translation is a method to reduce the latency of communication through machine translation (MT) by dividing the input into short segments before performing translation.", "labels": [], "entities": [{"text": "Simultaneous translation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7214168608188629}, {"text": "machine translation (MT)", "start_pos": 84, "end_pos": 108, "type": "TASK", "confidence": 0.8346381545066833}]}, {"text": "However, short segments pose problems for syntax-based translation methods, as it is difficult to generate accurate parse trees for sub-sentential segments.", "labels": [], "entities": []}, {"text": "In this paper, we perform the first experiments applying syntax-based SMT to simultaneous translation , and propose two methods to prevent degradations in accuracy: a method to predict unseen syntactic constituents that help generate complete parse trees, and a method that waits for more input when the current utterance is not enough to generate a fluent translation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.8716841340065002}, {"text": "accuracy", "start_pos": 155, "end_pos": 163, "type": "METRIC", "confidence": 0.9980870485305786}]}, {"text": "Experiments on English-Japanese translation show that the proposed methods allow for improvements inaccuracy, particularly with regards to word order of the target sentences.", "labels": [], "entities": [{"text": "English-Japanese translation", "start_pos": 15, "end_pos": 43, "type": "TASK", "confidence": 0.7139538824558258}]}], "introductionContent": [{"text": "Speech translation is an application of machine translation (MT) that converts utterances from the speaker's language into the listener's language.", "labels": [], "entities": [{"text": "Speech translation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7411166876554489}, {"text": "machine translation (MT)", "start_pos": 40, "end_pos": 64, "type": "TASK", "confidence": 0.8597213864326477}]}, {"text": "One of the most identifying features of speech translation is the fact that it must be performed in real time while the speaker is speaking, and thus it is necessary to split a constant stream of words into translatable segments before starting the translation process.", "labels": [], "entities": [{"text": "speech translation", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7282406538724899}]}, {"text": "Traditionally, speech translation assumes that each segment corresponds to a sentence, and thus performs sentence boundary detection before translation ().", "labels": [], "entities": [{"text": "speech translation", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.742891252040863}, {"text": "sentence boundary detection", "start_pos": 105, "end_pos": 132, "type": "TASK", "confidence": 0.6463491221268972}]}, {"text": "However, full sentences can belong, particularly informal speech such as lectures, and if translation does not start until explicit ends of sentences, listeners maybe forced to wait a considerable time until receiving the result of translation.", "labels": [], "entities": []}, {"text": "For example, when the speaker continues to talk for 10 seconds, listeners must wait at least 10 seconds to obtain the result of translation.", "labels": [], "entities": []}, {"text": "This is the major factor limiting simultaneity in traditional speech translation systems.", "labels": [], "entities": [{"text": "speech translation", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.7444230020046234}]}, {"text": "Simultaneous translation (Section 2) avoids this problem by starting to translate before observing the whole sentence, as shown in.", "labels": [], "entities": []}, {"text": "However, as translation starts before the whole sentence is observed, translation units are often not syntactically or semantically complete, and the performance may suffer accordingly.", "labels": [], "entities": []}, {"text": "The deleterious effect of this missing information is less worrying in largely monotonic language pairs (e.g. English-French), but cannot be discounted in syntactically distant language pairs (e.g. EnglishJapanese) that often require long-distance reordering beyond translation units.", "labels": [], "entities": []}, {"text": "One way to avoid this problem of missing information is to explicitly predict information needed to translate the content accurately.", "labels": [], "entities": []}, {"text": "An ambitious first step in this direction was recently proposed by, who describe a method that predicts sentence-final verbs using reinforcement learning (e.g. (b)).", "labels": [], "entities": []}, {"text": "This approach has the potential to greatly decrease the delay in translation from verb-final languages to verbinitial languages (such as German-English), but is also limited to only this particular case.", "labels": [], "entities": []}, {"text": "In this paper, we propose a more general method that focuses on a different variety of information: unseen syntactic constituents.", "labels": [], "entities": []}, {"text": "This method is motivated by our desire to apply translation models that use source-side parsing, such as tree-to-string (T2S) translation) or syntactic pre-ordering (, which have been shown to greatly improve translation accuracy over syntactically divergent language pairs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 221, "end_pos": 229, "type": "METRIC", "confidence": 0.8908522725105286}]}, {"text": "However, conventional methods for parsing are not directly applicable to the partial sentences that arise in simultaneous MT.", "labels": [], "entities": [{"text": "parsing", "start_pos": 34, "end_pos": 41, "type": "TASK", "confidence": 0.9673237204551697}, {"text": "MT", "start_pos": 122, "end_pos": 124, "type": "TASK", "confidence": 0.9302458167076111}]}, {"text": "The reason for this, as explained in detail in Section 3, is that parsing methods generally assume that they are given input that forms a complete syntactic phrase.", "labels": [], "entities": []}, {"text": "Looking at the example in, after the speaker has spoken the words \"I think\" we have a partial sentence that will only be complete once we observe the following SBAR.", "labels": [], "entities": []}, {"text": "Our method attempts to predict exactly this information, as shown in, guessing the remaining syntactic constituents that will allow us to acquire a proper parse tree.", "labels": [], "entities": []}, {"text": "Specifically the method consists of two parts: First, we propose a method that trains a statistical model to predict future syntactic constituents based on features of the input segment (Section 4).", "labels": [], "entities": []}, {"text": "Second, we demonstrate how to apply this syntactic prediction to MT, including the proposal of a heuristic method that examines whether a future constituent has the potential to cause a reordering problem during translation, and wait for more input in these cases (Section 5).", "labels": [], "entities": [{"text": "MT", "start_pos": 65, "end_pos": 67, "type": "TASK", "confidence": 0.9852020144462585}]}, {"text": "Based on the proposed method, we perform experiments in simultaneous translation of EnglishJapanese talks (Section 6).", "labels": [], "entities": [{"text": "translation of EnglishJapanese talks", "start_pos": 69, "end_pos": 105, "type": "TASK", "confidence": 0.7716800272464752}]}, {"text": "As this is the first work applying T2S translation to simultaneous MT, we first compare T2S to more traditional phrase-based techniques.", "labels": [], "entities": [{"text": "T2S translation", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.8144146800041199}, {"text": "MT", "start_pos": 67, "end_pos": 69, "type": "TASK", "confidence": 0.8917526006698608}]}, {"text": "We find that T2S translation is effective with longer segments, but drops off quickly with shorter segments, justifying the need for techniques to handle translation when full context is not available.", "labels": [], "entities": [{"text": "T2S translation", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.83971306681633}]}, {"text": "We then compare the proposed method of predicting syntactic constituents, and find that it improves translation results, particularly with respect to word ordering in the output sentences.", "labels": [], "entities": [{"text": "predicting syntactic constituents", "start_pos": 39, "end_pos": 72, "type": "TASK", "confidence": 0.8668821056683859}]}], "datasetContent": [{"text": "We perform 2 types of experiments to evaluate the effectiveness of the proposed methods.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Performance of syntactic constituent pre- diction.  Target  P %  R %  F %  L  (ordered)  31.93  7.27 11.85  (unordered) 51.21 11.66 19.00  R  (ordered)  51.12 33.78 40.68  (unordered) 52.77 34.87 42.00", "labels": [], "entities": [{"text": "Target  P %  R %  F %  L", "start_pos": 62, "end_pos": 86, "type": "METRIC", "confidence": 0.7278347536921501}]}]}