{"title": [{"text": "Efficient Top-Down BTG Parsing for Machine Translation Preordering", "labels": [], "entities": [{"text": "BTG Parsing", "start_pos": 19, "end_pos": 30, "type": "TASK", "confidence": 0.5164239853620529}, {"text": "Machine Translation Preordering", "start_pos": 35, "end_pos": 66, "type": "TASK", "confidence": 0.8414475123087565}]}], "abstractContent": [{"text": "We present an efficient incremental top-down parsing method for preordering based on Bracketing Transduction Grammar (BTG).", "labels": [], "entities": [{"text": "Bracketing Transduction Grammar (BTG)", "start_pos": 85, "end_pos": 122, "type": "TASK", "confidence": 0.7120346426963806}]}, {"text": "The BTG-based preordering framework (Neubig et al., 2012) can be applied to any language using only parallel text, but has the problem of computational efficiency.", "labels": [], "entities": []}, {"text": "Our top-down parsing algorithm allows us to use the early update technique easily for the latent variable structured Perceptron algorithm with beam search, and solves the problem.", "labels": [], "entities": []}, {"text": "Experimental results showed that the top-down method is more than 10 times faster than a method using the CYK algorithm.", "labels": [], "entities": []}, {"text": "A phrase-based machine translation system with the top-down method had statistically significantly higher BLEU scores for 7 language pairs without relying on supervised syntactic parsers, compared to baseline systems using existing preorder-ing methods.", "labels": [], "entities": [{"text": "phrase-based machine translation", "start_pos": 2, "end_pos": 34, "type": "TASK", "confidence": 0.6355639199415842}, {"text": "BLEU", "start_pos": 106, "end_pos": 110, "type": "METRIC", "confidence": 0.9991763234138489}]}], "introductionContent": [{"text": "The difference of the word order between source and target languages is one of major problems in phrase-based statistical machine translation.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 97, "end_pos": 141, "type": "TASK", "confidence": 0.6108873635530472}]}, {"text": "In order to cope with the issue, many approaches have been studied.", "labels": [], "entities": []}, {"text": "Distortion models consider word reordering in decoding time using such as distance ( and lexical information).", "labels": [], "entities": [{"text": "word reordering", "start_pos": 27, "end_pos": 42, "type": "TASK", "confidence": 0.7071604877710342}]}, {"text": "Another direction is to use more complex translation models such as hierarchical models.", "labels": [], "entities": []}, {"text": "However, these approaches suffer from the long-distance reordering issue and computational complexity.", "labels": [], "entities": []}, {"text": "Preordering (reordering-as-preprocessing) () is another approach for tackling the problem, which modifies the word order of an input sentence in a source language to have the word order in a target language).", "labels": [], "entities": [{"text": "Preordering", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.8101306557655334}]}, {"text": "Various methods for preordering have been studied, and a method based on Bracketing Transduction Grammar (BTG) was proposed by.", "labels": [], "entities": [{"text": "Bracketing Transduction Grammar (BTG)", "start_pos": 73, "end_pos": 110, "type": "TASK", "confidence": 0.8060582876205444}]}, {"text": "It reorders source sentences by handling sentence structures as latent variables.", "labels": [], "entities": []}, {"text": "The method can be applied to any language using only parallel text.", "labels": [], "entities": []}, {"text": "However, the method has the problem of computational efficiency.", "labels": [], "entities": []}, {"text": "In this paper, we propose an efficient incremental top-down BTG parsing method which can be applied to preordering.", "labels": [], "entities": [{"text": "BTG parsing", "start_pos": 60, "end_pos": 71, "type": "TASK", "confidence": 0.6758944690227509}]}, {"text": "Model parameters can be learned using latent variable Perceptron with the early update technique (), since the parsing method provides an easy way for checking the reachability of each parser state to valid final states.", "labels": [], "entities": []}, {"text": "We also try to use forced-decoding instead of word alignment based on Expectation Maximization (EM) algorithms in order to create better training data for preordering.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.7626562714576721}]}, {"text": "In experiments, preordering using the topdown parsing algorithm was faster and gave higher BLEU scores than BTG-based preordering using the CYK algorithm.", "labels": [], "entities": [{"text": "topdown parsing", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.45976217091083527}, {"text": "BLEU", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.9994925260543823}]}, {"text": "Compared to existing preordering methods, our method had better or comparable BLEU scores without using supervised parsers.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.9991969466209412}]}], "datasetContent": [{"text": "We conduct experiments for 12 language pairs: Dutch (nl)-English (en), en-nl, en-French (fr), enJapanese (ja), en-Spanish (es), fr-en, Hindi (hi)-en, ja-en, Korean (ko)-en, Turkish (tr)-en, Urdu (ur)-en and Welsh (cy)-en.", "labels": [], "entities": []}, {"text": "We use a phrase-based statistical machine translation system which is similar to ().", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 9, "end_pos": 53, "type": "TASK", "confidence": 0.5825004056096077}]}, {"text": "The decoder adopts the regular distance distortion model, and also incorporates a maximum entropy based lexicalized phrase reordering model ().", "labels": [], "entities": []}, {"text": "The distortion limit is set to 5 words.", "labels": [], "entities": [{"text": "distortion", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9923592209815979}]}, {"text": "Word alignments are learned using 3 iterations of IBM Model-1 () and 3 iterations of the HMM alignment model (.", "labels": [], "entities": [{"text": "Word alignments", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6873138397932053}, {"text": "IBM Model-1", "start_pos": 50, "end_pos": 61, "type": "DATASET", "confidence": 0.8847334384918213}]}, {"text": "Lattice-based minimum error rate training (MERT) () is applied to optimize feature weights.", "labels": [], "entities": [{"text": "Lattice-based minimum error rate training (MERT)", "start_pos": 0, "end_pos": 48, "type": "METRIC", "confidence": 0.7724026814103127}]}, {"text": "5-gram language models trained on sentences collected from various sources are used.", "labels": [], "entities": []}, {"text": "The translation system is trained with parallel sentences automatically collected from the Web.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9655731320381165}]}, {"text": "The parallel data for each language pair consists of around 400 million source and target words.", "labels": [], "entities": []}, {"text": "In order to make the development data for MERT and test data (3,000 and 5,000 sentences respectively for each language), we created parallel sentences by randomly collecting English sentences from the Web, and translating them by humans into each language.", "labels": [], "entities": [{"text": "MERT", "start_pos": 42, "end_pos": 46, "type": "DATASET", "confidence": 0.4518488347530365}]}, {"text": "As an evaluation metric for translation quality, BLEU () is used.", "labels": [], "entities": [{"text": "translation", "start_pos": 28, "end_pos": 39, "type": "TASK", "confidence": 0.9705241322517395}, {"text": "BLEU", "start_pos": 49, "end_pos": 53, "type": "METRIC", "confidence": 0.9985262155532837}]}, {"text": "As intrinsic evaluation metrics for preordering, Fuzzy Reordering Score (FRS)) and) are used.", "labels": [], "entities": [{"text": "Fuzzy Reordering Score (FRS))", "start_pos": 49, "end_pos": 78, "type": "METRIC", "confidence": 0.9303419987360636}]}, {"text": "Let \u03c1 i denote the position in the input sentence of the (i+1)-th token in a preordered word sequence excluding unaligned words in the gold-standard evaluation data.", "labels": [], "entities": []}, {"text": "For: Performance of preordering for various training data.", "labels": [], "entities": [{"text": "preordering", "start_pos": 20, "end_pos": 31, "type": "METRIC", "confidence": 0.8860631585121155}]}, {"text": "Bold BLEU scores indicate no statistically significant difference at p < 0.05 from the best system).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 5, "end_pos": 9, "type": "METRIC", "confidence": 0.999362051486969}]}, {"text": "example, the preordering result \"New York Ito went\" for the gold-standard data in has \u03c1 = 3, 4, 2, 1.", "labels": [], "entities": [{"text": "New York Ito went", "start_pos": 33, "end_pos": 50, "type": "DATASET", "confidence": 0.8909672200679779}, {"text": "gold-standard data", "start_pos": 60, "end_pos": 78, "type": "DATASET", "confidence": 0.8182449638843536}]}, {"text": "Then FRS and \u03c4 are calculated as follows: where \u03b4(X) is the Kronecker's delta function which returns 1 if X is true or 0 otherwise.", "labels": [], "entities": [{"text": "FRS", "start_pos": 5, "end_pos": 8, "type": "METRIC", "confidence": 0.991880476474762}]}, {"text": "These scores are calculated for each sentence, and are averaged overall sentences in test data.", "labels": [], "entities": []}, {"text": "As above, FRS can be calculated as the precision of word bigrams (B is the number of the word bigrams which exist both in the system output and the gold standard data).", "labels": [], "entities": [{"text": "FRS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9981521964073181}, {"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9988824725151062}]}, {"text": "This formulation is equivalent to the original formulation based on chunk fragmentation by.", "labels": [], "entities": []}, {"text": "Equation (6) takes into account the positions of the beginning and the ending words ().", "labels": [], "entities": []}, {"text": "Kendall's \u03c4 is equivalent to the (normalized) crossing alignment link score used by.", "labels": [], "entities": [{"text": "crossing alignment link score", "start_pos": 46, "end_pos": 75, "type": "METRIC", "confidence": 0.6369282379746437}]}, {"text": "We prepared three types of training data for learning model parameters of BTG-based preordering: Manual-8k Manually word-aligned 8,000 sentence pairs.", "labels": [], "entities": [{"text": "BTG-based", "start_pos": 74, "end_pos": 83, "type": "DATASET", "confidence": 0.7789554595947266}]}, {"text": "EM-10k, EM-100k These are the data obtained with the EM-based word alignment learning.", "labels": [], "entities": [{"text": "EM-10k", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9399471282958984}, {"text": "EM-based word alignment learning", "start_pos": 53, "end_pos": 85, "type": "TASK", "confidence": 0.7756753042340279}]}, {"text": "From the word alignment result for phrase translation extraction described above, 10,000 and 100,000 sentence pairs were randomly sampled.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.727362185716629}, {"text": "phrase translation extraction", "start_pos": 35, "end_pos": 64, "type": "TASK", "confidence": 0.9126538832982382}]}, {"text": "Before the sampling, the data filtering procedure 1 and 3 in Section 3.4 were applied, and also sentences were removed if more than half of source words do not have aligned target words.", "labels": [], "entities": []}, {"text": "Word alignment was obtained by symmetrizing source-to-target and target-tosource word alignment with the INTERSEC-TION heuristic.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7479850947856903}]}, {"text": "Forced-10k, Forced-100k These are 10,000 and 100,000 word-aligned sentence pairs obtained with forced-decoding as described in Section 3.4.", "labels": [], "entities": []}, {"text": "As test data for intrinsic evaluation of preordering, we manually word-aligned 2,000 sentence pairs for en-ja and ja-en.", "labels": [], "entities": []}, {"text": "Several preordering systems were prepared in order to compare the following six systems: No-Preordering This is a system without preordering.", "labels": [], "entities": []}, {"text": "Manual-Rules This system uses the preordering method based on manually created rules (Xu).", "labels": [], "entities": []}, {"text": "We made 43 precedence rules for en-ja, and 24 for ja-en.", "labels": [], "entities": []}, {"text": "Auto-Rules This system uses the rule-based preordering method which automatically learns the rules from word-aligned data using the Variant 1 learning algorithm described in.", "labels": [], "entities": []}, {"text": "27 to 36 rules were automatically learned for each language pair.", "labels": [], "entities": []}, {"text": "Classifier This system uses the preordering method based on statistical classifiers (, and the 2-step algorithm was implemented.", "labels": [], "entities": []}, {"text": "Lader This system uses Latent Derivation Reorderer (, which is a BTG-based preordering system using the CYK algorithm.", "labels": [], "entities": []}, {"text": "The basic feature templates in are obtained by using Brown clusters () (the number of classes is set to 256).", "labels": [], "entities": []}, {"text": "For both Lader and TopDown, the beam width is set to 20, and the number of training iterations of online learning is set to 20.", "labels": [], "entities": [{"text": "TopDown", "start_pos": 19, "end_pos": 26, "type": "DATASET", "confidence": 0.8398488759994507}, {"text": "beam width", "start_pos": 32, "end_pos": 42, "type": "METRIC", "confidence": 0.7976270020008087}]}, {"text": "The CPU time shown in this paper is measured using Intel Xeon 3.20GHz with 32GB RAM.", "labels": [], "entities": []}, {"text": "shows the training time and preordering speed together with the intrinsic evaluation metrics.", "labels": [], "entities": []}, {"text": "In this experiment, both Top-Down and Lader were trained using the EM-100k data.", "labels": [], "entities": [{"text": "EM-100k data", "start_pos": 67, "end_pos": 79, "type": "DATASET", "confidence": 0.934238851070404}]}, {"text": "Compared to Lader, Top-Down was faster: more than 20 times in training, and more than 10 times in preordering.", "labels": [], "entities": [{"text": "preordering", "start_pos": 98, "end_pos": 109, "type": "METRIC", "confidence": 0.9868564009666443}]}, {"text": "Top-down had higher preordering accuracy in FRS and \u03c4 for en-ja.", "labels": [], "entities": [{"text": "preordering", "start_pos": 20, "end_pos": 31, "type": "METRIC", "confidence": 0.9519894123077393}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.8817267417907715}, {"text": "FRS", "start_pos": 44, "end_pos": 47, "type": "METRIC", "confidence": 0.8669685125350952}, {"text": "\u03c4", "start_pos": 52, "end_pos": 53, "type": "METRIC", "confidence": 0.9833469986915588}]}, {"text": "Although Lader uses sophisticated loss functions, Top-Down uses a larger number of features.", "labels": [], "entities": []}, {"text": "Manual-Rules performed the best for en-ja, but it needs manually created rules and is difficult to be applied to many language pairs.", "labels": [], "entities": []}, {"text": "AutoRules and Classifier had higher scores than NoPreordering except for fr-en, but cannot be applied to the languages with no available dependency parsers.", "labels": [], "entities": []}, {"text": "Top-Down (Forced-100k) can be applied to any language, and had statistically significantly better BLEU scores than No-Preordering, ManualRules, Auto-Rules, Classifier and Lader for 7 language pairs (en-fr, fr-en, hi-en, ja-en, ko-en, tr-en and ur-en), and similar performance for other language pairs except for en-ja, without dependency parsers trained with manually annotated data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.9992988109588623}]}, {"text": "In all the experiments so far, the decoder was allowed to reorder even after preordering was carried out.", "labels": [], "entities": []}, {"text": "In order to seethe performance without reordering after preordering, we conducted experiments by setting the distortion limit to 0.", "labels": [], "entities": []}, {"text": "The effect of the distortion limits varies for language pairs and preordering methods.", "labels": [], "entities": []}, {"text": "The BLEU scores of Top-Down were not affected largely even when relying only on preordering.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.998286783695221}]}], "tableCaptions": [{"text": " Table 3: Speed and accuracy of preordering.", "labels": [], "entities": [{"text": "Speed", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9961557984352112}, {"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9993599057197571}]}, {"text": " Table 4: Performance of preordering for various training data. Bold BLEU scores indicate no statistically  significant difference at p < 0.05 from the best system", "labels": [], "entities": [{"text": "preordering", "start_pos": 25, "end_pos": 36, "type": "METRIC", "confidence": 0.9351909756660461}, {"text": "BLEU", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9982724189758301}]}, {"text": " Table 5: BLEU score comparison.", "labels": [], "entities": [{"text": "BLEU score comparison", "start_pos": 10, "end_pos": 31, "type": "METRIC", "confidence": 0.8707332213719686}]}, {"text": " Table 6: BLEU scores for different distortion limits.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.999354898929596}, {"text": "distortion", "start_pos": 36, "end_pos": 46, "type": "METRIC", "confidence": 0.9517279267311096}]}]}