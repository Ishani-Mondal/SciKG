{"title": [{"text": "Optimal Shift-Reduce Constituent Parsing with Structured Perceptron", "labels": [], "entities": [{"text": "Optimal Shift-Reduce Constituent Parsing", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.6232810318470001}]}], "abstractContent": [{"text": "We present a constituent shift-reduce parser with a structured perceptron that finds the optimal parse in a practical run-time.", "labels": [], "entities": []}, {"text": "The key ideas are new feature templates that facilitate state merging of dynamic programming and A* search.", "labels": [], "entities": []}, {"text": "Our system achieves 91.1 F1 on a standard English experiment, a level which cannot be reached by other beam-based systems even with large beam sizes.", "labels": [], "entities": [{"text": "91.1", "start_pos": 20, "end_pos": 24, "type": "METRIC", "confidence": 0.9292399883270264}, {"text": "F1", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.9476349949836731}]}], "introductionContent": [{"text": "A parsing system comprises two components: a scoring model fora tree and a search algorithm.", "labels": [], "entities": [{"text": "parsing", "start_pos": 2, "end_pos": 9, "type": "TASK", "confidence": 0.9625139236450195}]}, {"text": "In shift-reduce parsing, the focus of most previous studies has been the former, typically by enriching feature templates, while the search quality has often been taken less seriously.", "labels": [], "entities": [{"text": "shift-reduce parsing", "start_pos": 3, "end_pos": 23, "type": "TASK", "confidence": 0.659670040011406}]}, {"text": "For example, the current state-of-the-art parsers for constituency () and dependency () both employ beam search with a constant beam size, which may suffer from severe search errors.", "labels": [], "entities": []}, {"text": "This is contrary to ordinary PCFG parsing which, while it often uses some approximations, has nearly optimal quality.", "labels": [], "entities": [{"text": "PCFG parsing", "start_pos": 29, "end_pos": 41, "type": "TASK", "confidence": 0.6843526512384415}]}, {"text": "In this paper, we instead investigate the question of whether we can obtain a practical shift-reduce parser with state-of-the-art accuracy by focusing on optimal search quality like PCFG parsing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.9982298016548157}, {"text": "PCFG parsing", "start_pos": 182, "end_pos": 194, "type": "TASK", "confidence": 0.7592554092407227}]}, {"text": "We base our system on best-first search for shiftreduce parsing formulated in, but it differs from their approach in two points.", "labels": [], "entities": [{"text": "shiftreduce parsing", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.650883749127388}]}, {"text": "First, we focus on constituent parsing while they use dependency grammar.", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.7039523720741272}]}, {"text": "Second, and more crucially, they use a locally trained MaxEnt model, which is simple but not strong, while we explore a structured perceptron, the current state-of-the-art in shift-reduce parsing (.", "labels": [], "entities": []}, {"text": "As we will see, this model change makes search quite hard, which motivates us to invent new feature templates as well as to improve the search algorithm.", "labels": [], "entities": []}, {"text": "In existing parsers, features are commonly exploited from the parsing history, such as the top k elements on the stack.", "labels": [], "entities": []}, {"text": "However, such features are expensive in terms of search efficiency.", "labels": [], "entities": []}, {"text": "Instead of relying on features primarily from the stack, our features mostly come from the span of the top few nodes, an idea inspired by the recent empirical success in CRF parsing ().", "labels": [], "entities": [{"text": "CRF parsing", "start_pos": 170, "end_pos": 181, "type": "TASK", "confidence": 0.8680894076824188}]}, {"text": "We show that these span features also fit quite well in the shift-reduce system and lead to state-of-the-art accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9978731870651245}]}, {"text": "We further improve search with new A* heuristics that make optimal search for shift-reduce parsers with a structured perceptron tractable for the first time.", "labels": [], "entities": []}, {"text": "The primary contribution of this paper is to demonstrate the effectiveness and the practicality of optimal search for shift-reduce parsing, especially when combined with appropriate features and efficient search.", "labels": [], "entities": [{"text": "shift-reduce parsing", "start_pos": 118, "end_pos": 138, "type": "TASK", "confidence": 0.508938804268837}]}, {"text": "In English Penn Treebank experiments, our parser achieves an F1 score of 91.1 on test set at a speed of 13.6 sentences per second.", "labels": [], "entities": [{"text": "English Penn Treebank", "start_pos": 3, "end_pos": 24, "type": "DATASET", "confidence": 0.879957894484202}, {"text": "F1 score", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9888819754123688}]}, {"text": "This score is in excess of that of a beam-based system with larger beam size and same speed.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section evaluates the empirical performance of our best-first constituent parser that we builtin the previous section.", "labels": [], "entities": []}, {"text": "As mentioned in Section 2.2, the previous empirical success of best-first shiftreduce parsers might be due to the sparsity property of the MaxEnt model, which may not hold true in the structured perceptron.", "labels": [], "entities": []}, {"text": "We investigate the validity of this assumption by comparing two systems, a locally trained MaxEnt model and a globally trained structured perceptron.", "labels": [], "entities": []}, {"text": "Setting We follow the standard practice and train each model on section 2-21 of the WSJ Penn Treebank (, which is binarized using the algorithm in with the head rule of Collins (1999).", "labels": [], "entities": [{"text": "WSJ Penn Treebank", "start_pos": 84, "end_pos": 101, "type": "DATASET", "confidence": 0.9333238005638123}]}, {"text": "We report the F1 scores for the development set of section 22.", "labels": [], "entities": [{"text": "F1", "start_pos": 14, "end_pos": 16, "type": "METRIC", "confidence": 0.9988638162612915}]}, {"text": "The Stanford POS tagger is used for part-ofspeech tagging.", "labels": [], "entities": [{"text": "Stanford POS tagger", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.7991547187169393}, {"text": "part-ofspeech tagging", "start_pos": 36, "end_pos": 57, "type": "TASK", "confidence": 0.7584051489830017}]}, {"text": "We used the EVALB program to evaluate parsing performance.", "labels": [], "entities": [{"text": "parsing", "start_pos": 38, "end_pos": 45, "type": "TASK", "confidence": 0.9783642888069153}]}, {"text": "7 Every experiment reported here was performed on hardware Feature We borrow the feature templates from.", "labels": [], "entities": []}, {"text": "However, we found the full feature templates make training and decoding of the structured perceptron much slower, and instead developed simplified templates by removing some, e.g., that access to the child information on the second top node on the stack.", "labels": [], "entities": []}, {"text": "8 Result summarizes the results that indicate our assumption is true.", "labels": [], "entities": []}, {"text": "The structured perceptron has the best score even though we restrict the features.", "labels": [], "entities": []}, {"text": "However, its parsing speed is much slower than that of the local MaxEnt model.", "labels": [], "entities": [{"text": "parsing", "start_pos": 13, "end_pos": 20, "type": "TASK", "confidence": 0.9728195071220398}]}, {"text": "To seethe difference in search behaviors between the two models, plots the number of processed (popped) states during search.", "labels": [], "entities": []}, {"text": "Discussion This result may seem somewhat depressing.", "labels": [], "entities": []}, {"text": "We have devised anew method that enables optimal search for the structured perceptron, but it cannot handle even modestly large feature templates.", "labels": [], "entities": []}, {"text": "As we will see below, the time complexity of the system depends on the used features.", "labels": [], "entities": []}, {"text": "We have tried features from Sagae and Lavie (2006), but their features are no longer state-ofthe-art.", "labels": [], "entities": [{"text": "Sagae and Lavie (2006)", "start_pos": 28, "end_pos": 50, "type": "DATASET", "confidence": 0.7685857315858206}]}, {"text": "For example, report higher scores by using beam search with much richer feature templates, though, as we have examined, it seems implausible to apply such features to our system.", "labels": [], "entities": []}, {"text": "In the following, we find a practical solution for improving both parse accuracy and search efficiency in our system.", "labels": [], "entities": [{"text": "parse", "start_pos": 66, "end_pos": 71, "type": "TASK", "confidence": 0.9516165256500244}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.852361261844635}]}, {"text": "We will see that our new features not only make BFS tractable, but also lead to comparable or even superior accuracy relative to the current mainstream features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.998889148235321}]}, {"text": "When 2: A snippet of the hypergraph for the system that simulates a simple PCFG.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 75, "end_pos": 79, "type": "DATASET", "confidence": 0.8605998754501343}]}, {"text": "p is the popped state, which is being expanded with a state of its left states L(p) using a reduce rule.", "labels": [], "entities": []}, {"text": "it is combined with A* search, the speed reaches a practical level.", "labels": [], "entities": [{"text": "A* search", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.8730301260948181}, {"text": "speed", "start_pos": 35, "end_pos": 40, "type": "METRIC", "confidence": 0.9923856258392334}]}, {"text": "We build our final system by combining the ideas in Section 5 and the system in Section 3.", "labels": [], "entities": []}, {"text": "We also build beam-based systems with or without dynamic programming (DP) and with the ordinary or the new span features.", "labels": [], "entities": []}, {"text": "All systems are trained with the structured perceptron.", "labels": [], "entities": []}, {"text": "We use the early update for training beam-based systems.", "labels": [], "entities": []}, {"text": "Effect of A* heuristics shows the effects of A* heuristics.", "labels": [], "entities": []}, {"text": "In terms of search quality, the LF is better; it prunes 92.5% of states compared to naive BFS, while the GP prunes 75%.", "labels": [], "entities": []}, {"text": "However, the LF takes more time to calculate: Results for the Penn Treebank development set.", "labels": [], "entities": [{"text": "Penn Treebank development set", "start_pos": 62, "end_pos": 91, "type": "DATASET", "confidence": 0.9947718977928162}]}, {"text": "Z&C = feature set of.", "labels": [], "entities": []}, {"text": "The speeds of non-DP and DP are the same, so we omit them from the comparison.", "labels": [], "entities": [{"text": "DP", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.7211645841598511}]}, {"text": "The HP combines the advantages of both, achieving the best result.", "labels": [], "entities": []}, {"text": "Accuracy and Speed The F1 scores for the development set are summarized in.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9944273233413696}, {"text": "Speed", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.9768610000610352}, {"text": "F1", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.9933342933654785}]}, {"text": "We can see that the systems with our new feature (span) perform surprisingly well, at a competitive level with the more expensive features of.", "labels": [], "entities": []}, {"text": "This is particularly true with DP; it sometimes outperforms Z&C, probably because our simple features facilitate state merging of DP, which expands search space.", "labels": [], "entities": []}, {"text": "However, our main result that the system with optimal search gets a much higher score (90.7 F1) than beambased systems with a larger beam size (90.2 F1) indicates that ordinary beam-based systems suffer from severe search errors even with the help of DP.", "labels": [], "entities": [{"text": "F1", "start_pos": 92, "end_pos": 94, "type": "METRIC", "confidence": 0.9691928029060364}]}, {"text": "Though our naive BFS is slow (1.12 sent./s.), A* search considerably improves parsing speed (13.6 sent./s.), and is faster than the beam-based system with abeam size of 64 ().", "labels": [], "entities": [{"text": "parsing", "start_pos": 78, "end_pos": 85, "type": "TASK", "confidence": 0.9599508047103882}]}, {"text": "Unary Merging We have not mentioned the effect of our unary merging (Section 3), but the result indicates it has almost the same effect as the previously proposed padding method (Zhu et al.,   Final Experiment compares our parsing system with those of previous studies.", "labels": [], "entities": []}, {"text": "When we look at closed settings, where no external resource other than the training Penn Treebank is used, our system outperforms all other systems including the Berkeley parser and the Stanford parser () in terms of F1.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 84, "end_pos": 97, "type": "DATASET", "confidence": 0.847856879234314}, {"text": "F1", "start_pos": 217, "end_pos": 219, "type": "METRIC", "confidence": 0.9959567189216614}]}, {"text": "The parsing systems with external features or reranking outperform our system.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9759514331817627}]}, {"text": "However, it should be noted that our system could also be improved by external features.", "labels": [], "entities": []}, {"text": "For example, the feature of type-level distributional similarity, such as Brown clustering, can be incorporated with our system without changing the theoretical runtime.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of BFS systems with dynamic  programming for the Penn Treebank development  set with different models and features. SP = the  structured perceptron; ME = the MaxEnt.", "labels": [], "entities": [{"text": "Penn Treebank development  set", "start_pos": 67, "end_pos": 97, "type": "DATASET", "confidence": 0.9911653846502304}]}, {"text": " Table 3: Example of our feature projection. \u03b8 GP is  a weight vector with the GP, which collapses every  c. \u03b8 LF is with the LF, which collapses all elements  in", "labels": [], "entities": []}, {"text": " Table 5: Results for the Penn Treebank develop- ment set. Z&C = feature set of", "labels": [], "entities": [{"text": "Penn Treebank develop- ment set", "start_pos": 26, "end_pos": 57, "type": "DATASET", "confidence": 0.9613375663757324}]}, {"text": " Table 6: The final results for section 23 of the  Penn Treebank. The systems with  \u2020 are re- ported by authors running on different hardware.  We divide baseline state-of-the-art systems into  three categories: shift-reduce systems (Sagae and  Lavie, 2005; Sagae and Lavie, 2006; Zhu et  al., 2013), other chart-based systems (Petrov and  Klein, 2007; Socher et al., 2013), and the systems  with external semi supervised features or rerank- ing (Charniak and Johnson, 2005; McClosky et al.,  2006; Zhu et al., 2013).", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 51, "end_pos": 64, "type": "DATASET", "confidence": 0.9939661622047424}]}]}