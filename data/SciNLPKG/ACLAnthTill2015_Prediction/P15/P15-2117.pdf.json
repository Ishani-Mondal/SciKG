{"title": [{"text": "Answer Sequence Learning with Neural Networks for Answer Selection in Community Question Answering", "labels": [], "entities": [{"text": "Answer Sequence Learning", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9180063207944235}, {"text": "Answer Selection in Community Question Answering", "start_pos": 50, "end_pos": 98, "type": "TASK", "confidence": 0.692404309908549}]}], "abstractContent": [{"text": "In this paper, the answer selection problem in community question answering (CQA) is regarded as an answer sequence labeling task, and a novel approach is proposed based on the recurrent architecture for this problem.", "labels": [], "entities": [{"text": "answer selection problem in community question answering (CQA)", "start_pos": 19, "end_pos": 81, "type": "TASK", "confidence": 0.7668785393238068}, {"text": "answer sequence labeling task", "start_pos": 100, "end_pos": 129, "type": "TASK", "confidence": 0.7041561082005501}]}, {"text": "Our approach applies convo-lution neural networks (CNNs) to learning the joint representation of question-answer pair firstly, and then uses the joint representation as input of the long short-term memory (LSTM) to learn the answer sequence of a question for labeling the matching quality of each answer.", "labels": [], "entities": []}, {"text": "Experiments conducted on the SemEval 2015 C-QA dataset shows the effectiveness of our approach.", "labels": [], "entities": [{"text": "SemEval 2015 C-QA dataset", "start_pos": 29, "end_pos": 54, "type": "DATASET", "confidence": 0.7423383221030235}]}], "introductionContent": [{"text": "Answer selection in community question answering (CQA), which recognizes high-quality responses to obtain useful question-answer pairs, is greatly valuable for knowledge base construction and information retrieval systems.", "labels": [], "entities": [{"text": "Answer selection in community question answering (CQA)", "start_pos": 0, "end_pos": 54, "type": "TASK", "confidence": 0.8246844410896301}, {"text": "knowledge base construction", "start_pos": 160, "end_pos": 187, "type": "TASK", "confidence": 0.7160279154777527}, {"text": "information retrieval", "start_pos": 192, "end_pos": 213, "type": "TASK", "confidence": 0.7753821611404419}]}, {"text": "To recognize matching answers fora question, typical approaches model semantic matching between question and answer by exploring various features (.", "labels": [], "entities": [{"text": "semantic matching between question and answer", "start_pos": 70, "end_pos": 115, "type": "TASK", "confidence": 0.8029864629109701}]}, {"text": "Some studies exploit syntactic tree structures ( to measure the semantic matching between question and answer.", "labels": [], "entities": []}, {"text": "However, these approaches require high-quality data and various external resources which maybe quite difficult to obtain.", "labels": [], "entities": []}, {"text": "To take advantage of a large quantity of raw data, deep learning based approaches () are proposed to learn the distributed representation of question-answer pair directly.", "labels": [], "entities": []}, {"text": "One disadvantage of these approaches lies in that * semantic correlations embedded in the answer sequence of a question are ignored, while they are very important for answer selection. is a example to show the relationship of answers in the sequence fora given question.", "labels": [], "entities": [{"text": "answer selection.", "start_pos": 167, "end_pos": 184, "type": "TASK", "confidence": 0.8393995463848114}]}, {"text": "Intuitively, other answers of the question are beneficial to judge the quality of the current answer.", "labels": [], "entities": []}], "datasetContent": [{"text": "Experimental Dataset: We conduct experiments on the public dataset of the answer selection challenge in SemEval 2015.", "labels": [], "entities": [{"text": "answer selection challenge in SemEval 2015", "start_pos": 74, "end_pos": 116, "type": "TASK", "confidence": 0.7641933659712473}]}, {"text": "This dataset consists of three subsets: training, development, and test sets, and contains 3,229 questions with 21,062 answers.", "labels": [], "entities": []}, {"text": "The answers falls into three classes: Good, Bad, and Potential, accounting for 51%, 39%, and 10% respectively.", "labels": [], "entities": []}, {"text": "The statistics of the dataset are summarized in For the LSTM unit, the size of input gate is set to 200, the sizes of forget gate, output gate, and memory cell are all set to 360.", "labels": [], "entities": []}, {"text": "Stochastic gradient descent (SGD) algorithm via back-propagation through time is used to train the model.", "labels": [], "entities": [{"text": "Stochastic gradient descent (SGD", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7137107193470001}]}, {"text": "To prevent serious overfitting, early stopping and dropout  during the training procedure.", "labels": [], "entities": []}, {"text": "The learning rate \u03bb is initialized to be 0.01 and is updated dynamically according to the gradient descent using the ADADELTA method.", "labels": [], "entities": [{"text": "ADADELTA", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9640321731567383}]}, {"text": "The activation functions (\u03c3, \u03b3) in our model adopt the rectified linear unit (ReLU) ().", "labels": [], "entities": [{"text": "rectified linear unit (ReLU)", "start_pos": 55, "end_pos": 83, "type": "METRIC", "confidence": 0.9514658947785696}]}, {"text": "In addition, the word embeddings for encoding sentences are pre-trained with the unsupervised neural language model () on the Qatar Living data 2 . summarizes the Macro-averaged results.", "labels": [], "entities": [{"text": "Qatar Living data", "start_pos": 126, "end_pos": 143, "type": "DATASET", "confidence": 0.9750991662343343}]}, {"text": "The F1 scores of the individual classes are presented in.", "labels": [], "entities": [{"text": "F1", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9990898370742798}]}], "tableCaptions": [{"text": " Table 1: Statistics of experimental dataset", "labels": [], "entities": []}]}