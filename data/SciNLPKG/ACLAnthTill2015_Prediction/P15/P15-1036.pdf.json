{"title": [{"text": "A Knowledge-Intensive Model for Prepositional Phrase Attachment", "labels": [], "entities": [{"text": "Prepositional Phrase Attachment", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.7813009818394979}]}], "abstractContent": [{"text": "Prepositional phrases (PPs) express crucial information that knowledge base construction methods need to extract.", "labels": [], "entities": []}, {"text": "However , PPs area major source of syntactic ambiguity and still pose problems in parsing.", "labels": [], "entities": []}, {"text": "We present a method for resolving ambiguities arising from PPs, making extensive use of semantic knowledge from various resources.", "labels": [], "entities": [{"text": "resolving ambiguities arising from PPs", "start_pos": 24, "end_pos": 62, "type": "TASK", "confidence": 0.7577319622039795}]}, {"text": "As training data, we use both labeled and unlabeled data, utilizing an expectation maximization algorithm for parameter estimation.", "labels": [], "entities": []}, {"text": "Experiments show that our method yields improvements over existing methods including a state of the art dependency parser.", "labels": [], "entities": []}], "introductionContent": [{"text": "Machine reading and information extraction (IE) projects have produced large resources with many millions of facts (.", "labels": [], "entities": [{"text": "Machine reading and information extraction (IE)", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.800983190536499}]}, {"text": "This wealth of knowledge creates a positive feedback loop for automatic knowledge base construction efforts: the accumulated knowledge can be leveraged to improve machine reading; in turn, improved reading methods can be used to better extract knowledge expressed using complex and potentially ambiguous language.", "labels": [], "entities": [{"text": "automatic knowledge base construction", "start_pos": 62, "end_pos": 99, "type": "TASK", "confidence": 0.638270303606987}, {"text": "machine reading", "start_pos": 163, "end_pos": 178, "type": "TASK", "confidence": 0.710770770907402}]}, {"text": "For example, prepositional phrases (PPs) express crucial information that IE methods need to extract.", "labels": [], "entities": [{"text": "IE", "start_pos": 74, "end_pos": 76, "type": "TASK", "confidence": 0.9532520174980164}]}, {"text": "However, PPs area major source of syntactic ambiguity.", "labels": [], "entities": []}, {"text": "In this paper, we propose to use semantic knowledge to improve PP attachment disambiguation.", "labels": [], "entities": [{"text": "PP attachment disambiguation", "start_pos": 63, "end_pos": 91, "type": "TASK", "confidence": 0.9239723285039266}]}, {"text": "PPs such as \"in\", \"at\", and \"for\" express details about the where, when, and why of relations and events.", "labels": [], "entities": []}, {"text": "PPs also state attributes of nouns.", "labels": [], "entities": []}, {"text": "As an example, consider the following sentences: S1.)", "labels": [], "entities": []}, {"text": "Alice caught the butterfly with the spots.", "labels": [], "entities": []}, {"text": "Alice caught the butterfly with the net.", "labels": [], "entities": []}, {"text": "Specifically, S1 and S2 differ in where their PPs attach.", "labels": [], "entities": []}, {"text": "In S1, the butterfly has spots and therefore the PP, \"with the spots\", attaches to the noun.", "labels": [], "entities": []}, {"text": "For relation extraction, we obtain a binary relation of the form: Alice caught butterfly with spots.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.8896455466747284}]}, {"text": "However, in S2, the net is the instrument used for catching and therefore the PP, \"with the net\", attaches to the verb.", "labels": [], "entities": [{"text": "catching", "start_pos": 51, "end_pos": 59, "type": "TASK", "confidence": 0.961678683757782}]}, {"text": "For relation extraction, we get a ternary extraction of the form: Alice caught butterfly with net.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.9567701518535614}]}, {"text": "The PP attachment problem is often defined as follows: given a PP occurring within a sentence where there are multiple possible attachment sites for the PP, choose the most plausible attachment site.", "labels": [], "entities": [{"text": "PP attachment problem", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.8508038322130839}]}, {"text": "In the literature, prior work going as far back as ( has focused on the language pattern that causes most PP ambiguities, which is the 4-word sequence: {v, n1, p, n2} (e.g., {caught, butterfly, with, spots}).", "labels": [], "entities": []}, {"text": "The task is to determine if the prepositional phrase (p, n2) attaches to the verb v or to the first noun n1.", "labels": [], "entities": []}, {"text": "Following common practice, we focus on PPs occurring as {v, n1, p, n2} quadruples -we shall refer to these as PP quads.", "labels": [], "entities": []}, {"text": "The approach we present here differs from prior work in two main ways.", "labels": [], "entities": []}, {"text": "First, we make extensive use of semantic knowledge about nouns, verbs, prepositions, pairs of nouns, and the discourse context in which a PP quad occurs.", "labels": [], "entities": []}, {"text": "summarizes the types of knowledge we considered in our work.", "labels": [], "entities": []}, {"text": "Second, in training our model, we rely on both labeled and unlabeled data, employing an expectation maximization (EM) algorithm.", "labels": [], "entities": []}, {"text": "In summary, our main contributions are: 1) Semantic Knowledge: Previous methods largely rely on corpus statistics.", "labels": [], "entities": []}, {"text": "Our approach draws upon diverse sources of background knowledge, leading to performance improvements.", "labels": [], "entities": []}, {"text": "2) Unlabeled Data: In addition to training on labeled data, we also make use of a large amount of unlabeled data.", "labels": [], "entities": []}, {"text": "This enhances our method's ability to generalize to diverse data sets.", "labels": [], "entities": []}, {"text": "3) Datasets: In addition to the standard Wall Street Journal corpus (WSJ) (, we labeled two new datasets for testing purposes, one from Wikipedia (WKP), and another from the New York Times Corpus (NYTC).", "labels": [], "entities": [{"text": "Wall Street Journal corpus (WSJ)", "start_pos": 41, "end_pos": 73, "type": "DATASET", "confidence": 0.9484208311353411}, {"text": "Times Corpus (NYTC)", "start_pos": 183, "end_pos": 202, "type": "DATASET", "confidence": 0.8888717412948608}]}, {"text": "We make these datasets freely available for fu- ture research.", "labels": [], "entities": []}, {"text": "In addition, we have applied our model to over 4 million 5-tuples of the form {n0, v, n1, p, n2}, and we also make this dataset available 1 for research into ternary relation extraction beyond spatial and temporal scoping.", "labels": [], "entities": [{"text": "ternary relation extraction", "start_pos": 158, "end_pos": 185, "type": "TASK", "confidence": 0.8029537200927734}]}], "datasetContent": [{"text": "We evaluated our method on several datasets containing PP quads of the form {v, n1, p, n2}.", "labels": [], "entities": []}, {"text": "The task is to predict if the PP (p, n2) attaches to the verb v or to the first noun n1.", "labels": [], "entities": []}, {"text": "Wall Street Journal (WSJ) dataset.", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ) dataset", "start_pos": 0, "end_pos": 33, "type": "DATASET", "confidence": 0.966042731489454}]}, {"text": "For the unlabeled training data, we extracted PP quads from Wikipedia (WKP) and randomly selected 100, 000 which we found to be a sufficient amount of unlabeled data.", "labels": [], "entities": [{"text": "PP quads from Wikipedia (WKP)", "start_pos": 46, "end_pos": 75, "type": "DATASET", "confidence": 0.6335528748376029}]}, {"text": "The largest labeled test dataset is WSJ but it is also made up of a large fraction, of \"of\" PP quads, 30% , which trivially attach to the noun, as already seen in.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 36, "end_pos": 39, "type": "DATASET", "confidence": 0.8757941126823425}]}, {"text": "The New York Times (NYTC) and Wikipedia (WKP) datasets are smaller but contain fewer proportions of \"of\" PP quads, 15%, and 14%, respectively.", "labels": [], "entities": [{"text": "New York Times (NYTC)", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.6665581613779068}, {"text": "Wikipedia (WKP) datasets", "start_pos": 30, "end_pos": 54, "type": "DATASET", "confidence": 0.811238706111908}]}, {"text": "Additionally, we applied our model to over 4 million unlabeled 5-tuples from Wikipedia.", "labels": [], "entities": []}, {"text": "We make this data available for download, along with our manually labeled NYTC and WKP datasets.", "labels": [], "entities": [{"text": "NYTC and WKP datasets", "start_pos": 74, "end_pos": 95, "type": "DATASET", "confidence": 0.7935303449630737}]}, {"text": "For the WKP & NYTC corpora, each quad has a preceding noun, n0, as context, resulting in PP 5-tuples of the form: {n0, v, n1, p, n2}.", "labels": [], "entities": [{"text": "WKP & NYTC corpora", "start_pos": 8, "end_pos": 26, "type": "DATASET", "confidence": 0.842356488108635}]}, {"text": "The WSJ dataset was only available to us in the form of PP quads with no other sentence information.", "labels": [], "entities": [{"text": "WSJ dataset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9608076810836792}]}, {"text": "1) PPAD (Prepositional Phrase Attachment Disambiguator) is our proposed method.", "labels": [], "entities": [{"text": "Prepositional Phrase Attachment Disambiguator)", "start_pos": 9, "end_pos": 55, "type": "TASK", "confidence": 0.6522826254367828}]}, {"text": "It uses diverse types of semantic knowledge, a mixture of labeled and unlabeled data for training data, a logistic regression classi- fier, and expectation maximization (EM) for parameter estimation 2) Collins is the established baseline among PP attachment algorithms.", "labels": [], "entities": [{"text": "expectation maximization (EM)", "start_pos": 144, "end_pos": 173, "type": "METRIC", "confidence": 0.8059839487075806}, {"text": "PP attachment", "start_pos": 244, "end_pos": 257, "type": "TASK", "confidence": 0.9241686165332794}]}, {"text": "3) Stanford Parser is a stateof-the-art dependency parser, the 2014 online version.", "labels": [], "entities": []}, {"text": "4) PPAD Naive Bayes(NB) is the same as PPAD but uses a generative model, as opposed to the discriminative model used in PPAD.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Training and test datasets used in our ex- periments.", "labels": [], "entities": []}, {"text": " Table 4: PPAD vs. baselines.", "labels": [], "entities": [{"text": "PPAD", "start_pos": 10, "end_pos": 14, "type": "TASK", "confidence": 0.549934446811676}]}]}