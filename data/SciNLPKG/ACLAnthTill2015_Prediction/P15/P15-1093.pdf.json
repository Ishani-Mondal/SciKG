{"title": [{"text": "Joint Case Argument Identification for Japanese Predicate Argument Structure Analysis", "labels": [], "entities": [{"text": "Joint Case Argument Identification", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.5363917872309685}, {"text": "Japanese Predicate Argument Structure Analysis", "start_pos": 39, "end_pos": 85, "type": "TASK", "confidence": 0.7509751856327057}]}], "abstractContent": [{"text": "Existing methods for Japanese predicate argument structure (PAS) analysis identify case arguments of each predicate without considering interactions between the target PAS and others in a sentence.", "labels": [], "entities": [{"text": "Japanese predicate argument structure (PAS) analysis", "start_pos": 21, "end_pos": 73, "type": "TASK", "confidence": 0.8054018467664719}]}, {"text": "However , the argument structures of the predicates in a sentence are semantically related to each other.", "labels": [], "entities": []}, {"text": "This paper proposes new methods for Japanese PAS analysis to jointly identify case arguments of all predicates in a sentence by (1) modeling multiple PAS interactions with a bipar-tite graph and (2) approximately searching optimal PAS combinations.", "labels": [], "entities": [{"text": "PAS analysis", "start_pos": 45, "end_pos": 57, "type": "TASK", "confidence": 0.9016202390193939}]}, {"text": "Performing experiments on the NAIST Text Corpus , we demonstrate that our joint analysis methods substantially outperform a strong baseline and are comparable to previous work.", "labels": [], "entities": [{"text": "NAIST Text Corpus", "start_pos": 30, "end_pos": 47, "type": "DATASET", "confidence": 0.9806657234827677}]}], "introductionContent": [{"text": "Predicate argument structure (PAS) analysis is a shallow semantic parsing task that identifies basic semantic units of a sentence, such as who does what to whom, which is similar to semantic role labeling (SRL) . In Japanese PAS analysis, one of the most problematic issues is that arguments are often omitted in the surface form, resulting in so-called zeropronouns.", "labels": [], "entities": [{"text": "Predicate argument structure (PAS) analysis", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.8008038103580475}, {"text": "semantic parsing task", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.8114627599716187}, {"text": "semantic role labeling (SRL)", "start_pos": 182, "end_pos": 210, "type": "TASK", "confidence": 0.8303531507651011}]}, {"text": "\"NOM\" and \"ACC\" represents the nominative and accusative arguments, respectively.", "labels": [], "entities": [{"text": "ACC", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9175235033035278}]}, {"text": "\"\u03d5 i \" is a zeropronoun, referring to the antecedent \"watashi i \".", "labels": [], "entities": []}, {"text": "The case role label \"NOM\" and \"ACC\" respectively represents the nominative and accusative roles, and \u03d5 i represents a zero-pronoun.", "labels": [], "entities": [{"text": "ACC", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.8679338693618774}]}, {"text": "There are two predicates \"hiita (caught)\" and \"yasunda (skipped)\".", "labels": [], "entities": []}, {"text": "For the predicate \"yasunda (skipped)\", \"watashi i -wa (I i )\" is the \"skipper\", and \"gakko-wo (school)\" is the \"entity skipped\".", "labels": [], "entities": []}, {"text": "It is easy to identify these arguments, since syntactic dependency between an argument and its predicate is a strong clue.", "labels": [], "entities": []}, {"text": "On the other hand, the nominative argument of the predicate \"hiita (caught)\" is \"watashi i -wa (I i )\", and this identification is more difficult because of the lack of the direct syntactic dependency with \"hiita (caught)\".", "labels": [], "entities": []}, {"text": "The original nominative argument appears as a zero-pronoun, so that we have to explore the antecedent, an element referred to by a zero-pronoun, as the argument.", "labels": [], "entities": []}, {"text": "As the example sentence shows, we cannot use effective syntactic information for identifying such arguments.", "labels": [], "entities": []}, {"text": "This type of arguments is known as implicit arguments, a very problematic language 961 phenomenon for PAS analysis.", "labels": [], "entities": [{"text": "PAS analysis", "start_pos": 102, "end_pos": 114, "type": "TASK", "confidence": 0.9498260617256165}]}, {"text": "Previous work on Japanese PAS analysis attempted to solve this problem by identifying arguments per predicate without considering interactions between multiple predicates and arguments.", "labels": [], "entities": [{"text": "PAS analysis", "start_pos": 26, "end_pos": 38, "type": "TASK", "confidence": 0.8172922432422638}]}, {"text": "However, implicit arguments are likely to be shared by semantically-related predicates.", "labels": [], "entities": []}, {"text": "In the above example), the implicit argument of the predicate \"hiita (caught)\" is shared by the other predicate \"yasunda (skipped)\" as its nominative argument \"watashi i (I i )\".", "labels": [], "entities": []}, {"text": "Based on this intuition, we propose methods to jointly identify optimal case arguments of all predicates in a sentence taking their interactions into account.", "labels": [], "entities": []}, {"text": "We represent the interactions as a bipartite graph that covers all predicates and candidate arguments in a sentence, and factorize the whole relation into the second-order relations.", "labels": [], "entities": []}, {"text": "This interaction modeling results in a hard combinatorial problem because it is required to select the optimal PAS combination from all possible PAS combinations in a sentence.", "labels": [], "entities": []}, {"text": "To solve this issue, we extend the randomized hill-climbing algorithm () to search all possible PAS in the space of bipartite graphs.", "labels": [], "entities": []}, {"text": "We perform experiments on the NAIST Text Corpus (), a standard benchmark for Japanese PAS analysis.", "labels": [], "entities": [{"text": "NAIST Text Corpus", "start_pos": 30, "end_pos": 47, "type": "DATASET", "confidence": 0.9568958679835001}, {"text": "PAS analysis", "start_pos": 86, "end_pos": 98, "type": "TASK", "confidence": 0.8440607190132141}]}, {"text": "Experimental results show that compared with a strong baseline, our methods achieve an improvement of 1.0-1.2 points in F-measure for total case argument identification, and especially improve performance for implicit argument identification by 2.0-2.5 points.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 120, "end_pos": 129, "type": "METRIC", "confidence": 0.9839960932731628}, {"text": "total case argument identification", "start_pos": 134, "end_pos": 168, "type": "TASK", "confidence": 0.5965482145547867}, {"text": "implicit argument identification", "start_pos": 209, "end_pos": 241, "type": "TASK", "confidence": 0.6103756427764893}]}, {"text": "In addition, although we exploit no external resources, we get comparable results to previous work exploiting large-scale external resources ().", "labels": [], "entities": []}, {"text": "These results suggest that there is potential for more improvement by adding external resources.", "labels": [], "entities": []}, {"text": "The main contributions of this work are: (1) We present new methods to jointly identify case arguments of all predicates in a sentence.", "labels": [], "entities": []}, {"text": "(2) We propose global feature templates that capture interactions over multiple PAS.", "labels": [], "entities": []}, {"text": "(3) Performing experiments on the NAIST Text Corpus, we demonstrate our methods are superior to a strong baseline and comparable to the methods of representative previous work.", "labels": [], "entities": [{"text": "NAIST Text Corpus", "start_pos": 34, "end_pos": 51, "type": "DATASET", "confidence": 0.9779097437858582}]}], "datasetContent": [{"text": "Data Set We evaluate our proposed methods on the NAIST Text Corpus 1.5, which consists of 40,000 sentences of Japanese newspaper text (.", "labels": [], "entities": [{"text": "NAIST Text Corpus 1.5", "start_pos": 49, "end_pos": 70, "type": "DATASET", "confidence": 0.9854007512331009}]}, {"text": "While previous work has adopted the version 1.4 beta, we adopt the latest version.", "labels": [], "entities": []}, {"text": "The major difference between version 1.4 beta and 1.5 is revision of dative case (corresponding to Japanese case particle \"ni\").", "labels": [], "entities": []}, {"text": "In 1.4 beta, most of adjunct usages of \"ni\" are mixed up with the argument usages of \"ni\", making the identification of dative cases seemingly easy.", "labels": [], "entities": [{"text": "identification of dative cases", "start_pos": 102, "end_pos": 132, "type": "TASK", "confidence": 0.827965572476387}]}, {"text": "Therefore, our results are not directly comparable with previous work.", "labels": [], "entities": []}, {"text": "We adopt standard train/dev/test split ( as follows: Train Articles: Jan 1-11, Editorials: Jan-Aug Dev Articles: Jan 12-13, Editorials: Sept Test Articles: Jan 14-17, Editorials: Oct-Dec We exclude inter-sentential arguments (InterZero) in our experiments.", "labels": [], "entities": []}, {"text": "Our features make use of the annotated POS tags, phrase boundaries, and dependency relations annotated in the NAIST Text Corpus.", "labels": [], "entities": [{"text": "NAIST Text Corpus", "start_pos": 110, "end_pos": 127, "type": "DATASET", "confidence": 0.981925884882609}]}, {"text": "We do not use any external resources.", "labels": [], "entities": []}, {"text": "Baseline We adopt the pointwise method (using only local features) proposed by as the baseline.", "labels": [], "entities": []}, {"text": "They built three distinct models corresponding to the three case roles.", "labels": [], "entities": []}, {"text": "By using each model, they estimate the likelihood that each candidate argument plays a case role of the target predicate as a score, and independently select the highest scoring one per predicate.: Global vs Local features on the development sets in F-measures.", "labels": [], "entities": []}, {"text": "\"PC Joint\" denotes the Per-Case Joint Model, and \"AC Joint\" denotes the All-Cases Joint Model.", "labels": [], "entities": []}, {"text": "Features The baseline utilizes the Baseline Features used in and Grammatical features used in, as the \"Local Features\".", "labels": [], "entities": []}, {"text": "In addition, the joint models utilize the \"Global Features\" in.", "labels": [], "entities": []}, {"text": "Implementation Details For our joint models with hill-climbing, we report the average performance across ten independent runs with 10 restarts, which almost reaches convergence 3 . We train the baseline and our joint models for 20 iterations with averaged perceptron.", "labels": [], "entities": [{"text": "Implementation", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.9208328723907471}]}, {"text": "shows the effectiveness of the global features on the development sets.", "labels": [], "entities": []}, {"text": "We incrementally add the global features to the both models that utilize only the local features.", "labels": [], "entities": []}, {"text": "The results show that the global features improve the performance by about 1.0 point in F-measures in total.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 88, "end_pos": 98, "type": "METRIC", "confidence": 0.9906405210494995}]}, {"text": "For and are particularly beneficial to the implicit (Zero) argument identification (an improvement of 1.99 points in Per-Case Joint Model and 3.12 points in All-Cases Joint Model)..", "labels": [], "entities": [{"text": "argument identification", "start_pos": 59, "end_pos": 82, "type": "TASK", "confidence": 0.7047636657953262}]}, {"text": "Their results are not directly comparable to ours since they use external resources and the NAIST Text Corpus 1.4 beta.", "labels": [], "entities": [{"text": "NAIST Text Corpus 1.4 beta", "start_pos": 92, "end_pos": 118, "type": "DATASET", "confidence": 0.9733005404472351}]}, {"text": "the implicit arguments (Zero), one of the problematic issues in Japanese PAS analysis.", "labels": [], "entities": [{"text": "PAS analysis", "start_pos": 73, "end_pos": 85, "type": "TASK", "confidence": 0.8951762914657593}]}], "tableCaptions": [{"text": " Table 2: Global vs Local features on the develop- ment sets in F-measures. \"PC Joint\" denotes the  Per-Case Joint Model, and \"AC Joint\" denotes the  All-Cases Joint Model.", "labels": [], "entities": []}, {"text": " Table 3: F-measures of the three methods in the test sets. The bold values denote the highest F-measures  among all the three methods. Statistical significance with p < 0.05 is marked with  \u2020 compared with  Baseline,  \u2021 compared with PC Joint, and \u22c6 compared with AC Joint.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9828969836235046}, {"text": "F-measures", "start_pos": 95, "end_pos": 105, "type": "METRIC", "confidence": 0.9796810150146484}]}, {"text": " Table 4: Comparison with previous work using the NAIST Text Corpus in F-measure. TA08 is Taira et  al. (2008), IM09 is Imamura et al. (2009), and S&K11 is", "labels": [], "entities": [{"text": "NAIST Text Corpus", "start_pos": 50, "end_pos": 67, "type": "DATASET", "confidence": 0.9863769809405009}, {"text": "TA08", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.9971006512641907}, {"text": "IM09", "start_pos": 112, "end_pos": 116, "type": "METRIC", "confidence": 0.8668476939201355}]}]}