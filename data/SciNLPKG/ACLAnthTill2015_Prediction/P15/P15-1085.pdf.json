{"title": [{"text": "Language to Code: Learning Semantic Parsers for If-This-Then-That Recipes", "labels": [], "entities": []}], "abstractContent": [{"text": "Using natural language to write programs is a touchstone problem for computational linguistics.", "labels": [], "entities": [{"text": "computational linguistics", "start_pos": 69, "end_pos": 94, "type": "TASK", "confidence": 0.7359529733657837}]}, {"text": "We present an approach that learns to map natural-language descriptions of simple \"if-then\" rules to executable code.", "labels": [], "entities": []}, {"text": "By training and testing on a large corpus of naturally-occurring programs (called \"recipes\") and their natural language descriptions , we demonstrate the ability to effectively map language to code.", "labels": [], "entities": []}, {"text": "We compare a number of semantic parsing approaches on the highly noisy training data collected from ordinary users, and find that loosely synchronous systems perform best.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 23, "end_pos": 39, "type": "TASK", "confidence": 0.7353755980730057}]}], "introductionContent": [{"text": "The ability to program computers using natural language would clearly allow novice users to more effectively utilize modern information technology.", "labels": [], "entities": []}, {"text": "Work in semantic parsing has explored mapping natural language to some formal domain-specific programming languages such as database queries), commands to robots), operating systems (, smartphones (, and spreadsheets).", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 8, "end_pos": 24, "type": "TASK", "confidence": 0.7588056027889252}]}, {"text": "Developing such languageto-code translators has generally required specific dedicated efforts to manually construct parsers or large corpora of suitable training examples.", "labels": [], "entities": []}, {"text": "An interesting subset of the possible program space is if-then \"recipes,\" simple rules that allow users to control many aspects of their digital life including smart devices.", "labels": [], "entities": []}, {"text": "Automatically parsing * Work performed while visiting Microsoft Research.", "labels": [], "entities": []}, {"text": "these recipes represents a step toward complex natural language programming, moving beyond single commands toward compositional statements with control flow.", "labels": [], "entities": []}, {"text": "Several services, such as Tasker and IFTTT, allow users to create simple programs with \"triggers\" and \"actions.\"", "labels": [], "entities": [{"text": "IFTTT", "start_pos": 37, "end_pos": 42, "type": "DATASET", "confidence": 0.7832766175270081}]}, {"text": "For example, one can program their Phillips Hue light bulbs to flash red and blue when the Cubs hit a home run.", "labels": [], "entities": [{"text": "Phillips Hue light bulbs", "start_pos": 35, "end_pos": 59, "type": "DATASET", "confidence": 0.9614061415195465}]}, {"text": "A somewhat complicated GUI allows users to construct these recipes based on a set of information \"channels.\"", "labels": [], "entities": []}, {"text": "These channels represent many types of information.", "labels": [], "entities": []}, {"text": "Weather, news, and financial services have provided constant updates through web services.", "labels": [], "entities": []}, {"text": "Home automation sensors and controllers such as motion detectors, thermostats, location sensors, garage door openers, etc. are also available.", "labels": [], "entities": []}, {"text": "Users can then describe the recipes they have constructed in natural language and publish them.", "labels": [], "entities": []}, {"text": "Our goal is to build semantic parsers that allow users to describe recipes in natural language and have them automatically mapped to executable code.", "labels": [], "entities": []}, {"text": "We have collected 114,408 recipedescription pairs from the http://ifttt.com website.", "labels": [], "entities": []}, {"text": "Because users often provided short or incomplete English descriptions, the resulting data is extremely noisy for the task of training a semantic parser.", "labels": [], "entities": []}, {"text": "Therefore, we have constructed semantic-parser learners that utilize and adapt ideas from several previous approaches;) to learn an effective interpreter from such noisy training data.", "labels": [], "entities": []}, {"text": "We present results on our collected IFTTT corpus demonstrating that our best approach produces more accurate programs than several competing baselines.", "labels": [], "entities": [{"text": "IFTTT corpus", "start_pos": 36, "end_pos": 48, "type": "DATASET", "confidence": 0.9244415760040283}]}, {"text": "By exploiting such \"found data\" on the web, semantic parsers for natural-language programming can potentially be developed with minimal effort.", "labels": [], "entities": []}], "datasetContent": [{"text": "Next we evaluate the accuracy of these approaches.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9995338916778564}]}, {"text": "The 114,408 recipes described in Section 3 were first cleaned and tokenized.", "labels": [], "entities": []}, {"text": "We kept only one recipe per unique description, after mapping to lowercase and normalizing punctuation.", "labels": [], "entities": []}, {"text": "Finally the recipes were split by author, randomly assigning each to training, development, or test, to prevent overfitting to the linguistic style of a particular author.", "labels": [], "entities": []}, {"text": "presents summary statistics for the resulting data.", "labels": [], "entities": []}, {"text": "Although certain trigger-action pairs occur much more often than others, the recipes in this data are quite diverse.", "labels": [], "entities": []}, {"text": "The top 10 trigger-action pairs account for 14% of the recipes; the top 100 account for 37%; the top 1000 account for 72%.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the data after cleaning and separating  into training, development, and test sets. In each case, the  number of recipes, tokens (including punctuation, etc.) and  vocabulary size are included.", "labels": [], "entities": []}, {"text": " Table 2: Annotator agreement as measured by Krippendorff's  \u03b1 coefficient", "labels": [], "entities": []}, {"text": " Table 3: Evaluation results. The first column measures how  often the channels are selected correctly for both trigger and  action (e.g. Android Phone Call and Google Drive in Fig- ure 1). The next column measures how often both the channel  and function are correctly selected for both trigger and ac- tion (e.g. Android Phone Call::Any phone call missed and  Google Drive::Add row to spreadsheet). The last column  shows balanced F-measure against the gold tree over all pro- ductions in the proposed derivation, from the root production  down to the lowest parameter. We show results on (a) the  full test data; (b) omitting descriptions marked as non-English  by a majority of the crowdsourced workers; (c) omitting de- scriptions marked as either non-English or unintelligible by  the crowd; and (d) only recipes where at least three of five  workers agreed with the gold standard.", "labels": [], "entities": [{"text": "Android Phone Call", "start_pos": 138, "end_pos": 156, "type": "DATASET", "confidence": 0.8871859113375345}, {"text": "Google Drive in Fig- ure 1", "start_pos": 161, "end_pos": 187, "type": "DATASET", "confidence": 0.7627227476664952}, {"text": "F-measure", "start_pos": 433, "end_pos": 442, "type": "METRIC", "confidence": 0.9977630376815796}]}]}