{"title": [{"text": "Synthetic Word Parsing Improves Chinese Word Segmentation", "labels": [], "entities": [{"text": "Synthetic Word Parsing Improves Chinese Word Segmentation", "start_pos": 0, "end_pos": 57, "type": "TASK", "confidence": 0.9187986935888018}]}], "abstractContent": [{"text": "We present a novel solution to improve the performance of Chinese word seg-mentation (CWS) using a synthetic word parser.", "labels": [], "entities": []}, {"text": "The parser analyses the internal structure of words, and attempts to convert out-of-vocabulary words (OOVs) into in-vocabulary fine-grained sub-words.", "labels": [], "entities": []}, {"text": "We propose a pipeline CWS system that first predicts this fine-grained segmenta-tion, then chunks the output to reconstruct the original word segmentation standard.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 137, "end_pos": 154, "type": "TASK", "confidence": 0.7411469519138336}]}, {"text": "We achieve competitive results on the PKU and MSR datasets, with substantial improvements in OOV recall.", "labels": [], "entities": [{"text": "PKU", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.8639715313911438}, {"text": "MSR datasets", "start_pos": 46, "end_pos": 58, "type": "DATASET", "confidence": 0.8249465823173523}, {"text": "OOV", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.974521815776825}, {"text": "recall", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.8673612475395203}]}], "introductionContent": [{"text": "Since Chinese has no spaces between words to indicate word boundaries, Chinese word segmentation is a task to determine word boundaries between characters.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 71, "end_pos": 96, "type": "TASK", "confidence": 0.655049741268158}]}, {"text": "In recent years, research in Chinese word segmentation has progressed significantly, with state-of-the-art performing at around 96% in precision and recall.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 29, "end_pos": 54, "type": "TASK", "confidence": 0.588223397731781}, {"text": "precision", "start_pos": 135, "end_pos": 144, "type": "METRIC", "confidence": 0.9994783997535706}, {"text": "recall", "start_pos": 149, "end_pos": 155, "type": "METRIC", "confidence": 0.9891390204429626}]}, {"text": "However, frequent OOVs are still a crucial issue that causes low accuracy in word segmentation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9976906776428223}, {"text": "word segmentation", "start_pos": 77, "end_pos": 94, "type": "TASK", "confidence": 0.7423667907714844}]}, {"text": "Li and Zhou (2012) defined those words that are OOVs but consisting of frequent internal parts as pseudo-OOV words and estimated that over 60% of OOVs are pseudo-OOVs in five common Chinese corpora.", "labels": [], "entities": []}, {"text": "For instance, PKU corpus does not contain the word \u9648\u5217\u5ba4 (exhibition room), even though the word \u9648\u5217 (exhibit) and \u5ba4 (room) appear hundreds of times.", "labels": [], "entities": [{"text": "PKU corpus", "start_pos": 14, "end_pos": 24, "type": "DATASET", "confidence": 0.9464747607707977}]}, {"text": "also claimed that most OOVs are proper nouns taking the form of Chinese synthetic words.", "labels": [], "entities": []}, {"text": "These previous works suggest that by analysing the internal structure of the synthetic words, we can transform pseudo-OOVs into in-vocabulary words.", "labels": [], "entities": []}, {"text": "By running a synthetic word parser on each of the words in a CWS training set, we can generate a fine-grained segmentation standard that contains more IVs.", "labels": [], "entities": []}, {"text": "Since the current conditional random field (CRF) word segmenters () perform well on IVs, this transforming process can conceivably improve the handling of pseudo-OOV words, as long as we can recover the original word segmentation standard from the fine-grained sub-word segmentation.", "labels": [], "entities": [{"text": "conditional random field (CRF) word segmenters", "start_pos": 18, "end_pos": 64, "type": "TASK", "confidence": 0.6997675001621246}]}, {"text": "In recent years, some related works about improving OOV problem in CWS have been ongoing.", "labels": [], "entities": [{"text": "OOV problem", "start_pos": 52, "end_pos": 63, "type": "METRIC", "confidence": 0.6836355030536652}]}, {"text": "presented a joint model for Chinese word segmentation and OOVs detection.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.5941420296827952}, {"text": "OOVs detection", "start_pos": 58, "end_pos": 72, "type": "TASK", "confidence": 0.8815396428108215}]}, {"text": "Their models achieved fast training speed, high accuracies and increase on OOV recall.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 48, "end_pos": 58, "type": "METRIC", "confidence": 0.9967729449272156}, {"text": "OOV", "start_pos": 75, "end_pos": 78, "type": "METRIC", "confidence": 0.9953243732452393}, {"text": "recall", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.7180228233337402}]}, {"text": "Sun (2011) proposed a similar sub-word structure which is generated by merging the segmentations provided by different segmenters (a word-based segmenter, a character-based segmenter and a local character classifier).", "labels": [], "entities": []}, {"text": "However, her models does not predict the sub-words of all the synthetic words, but those words with different segmented results of the three segmenters.", "labels": [], "entities": []}, {"text": "Her work maximizes the agreement of different models to improve CWS performance.", "labels": [], "entities": [{"text": "CWS", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9590029716491699}]}, {"text": "Different from her work, we aim to provide an unified way to incorporate morphological information of the synthetic words into the CWS task.", "labels": [], "entities": [{"text": "CWS task", "start_pos": 131, "end_pos": 139, "type": "TASK", "confidence": 0.9262157678604126}]}, {"text": "In this paper, we propose a pipeline word segmentation system to address the pseudo-OOV problem.", "labels": [], "entities": [{"text": "pipeline word segmentation", "start_pos": 28, "end_pos": 54, "type": "TASK", "confidence": 0.6755224764347076}]}, {"text": "Our word segmentation system first converts the original training data into a fine-grained standard by parsing all words with a synthetic word parser (Section 2.1), then trains a CRFbased sub-word segmenter (Section 2.2).", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7539063096046448}, {"text": "CRFbased sub-word segmenter", "start_pos": 179, "end_pos": 206, "type": "TASK", "confidence": 0.5505232314268748}]}, {"text": "A second CRF chunker is trained to recover the original word segmentation given the fine-grained results of the first CRF.", "labels": [], "entities": [{"text": "CRF chunker", "start_pos": 9, "end_pos": 20, "type": "TASK", "confidence": 0.8120668828487396}, {"text": "word segmentation", "start_pos": 56, "end_pos": 73, "type": "TASK", "confidence": 0.7168893665075302}]}, {"text": "The intuition is that finegrained sub-word segmentations resolve pseudoOOVs into IVs, which are easier to predict correctly by the first CRF.", "labels": [], "entities": []}, {"text": "Secondly, by training an-other CRF that predicts the original word segmentation given the fine-grained segmentation as input, we can recover the fine-grained output into original word segmentation standard (Section 2.3).", "labels": [], "entities": []}, {"text": "The flowchart of our word segmentation system is shown in.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.7130255699157715}]}], "datasetContent": [{"text": "We conducted additional experiments to evaluate the performance of the synthetic word parser and CRF-based chunking model.", "labels": [], "entities": [{"text": "CRF-based chunking", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.5586741119623184}]}, {"text": "First, we are interested in how much parsing accuracy is needed for good results.", "labels": [], "entities": [{"text": "parsing", "start_pos": 37, "end_pos": 44, "type": "TASK", "confidence": 0.9794313311576843}, {"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9462787508964539}]}, {"text": "displays the OOV recall results of our word segmentation system when the synthetic word parser is trained with amounts of labeled synthetic words data.", "labels": [], "entities": [{"text": "OOV", "start_pos": 13, "end_pos": 16, "type": "METRIC", "confidence": 0.9295663833618164}, {"text": "recall", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.6942643523216248}, {"text": "word segmentation", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.7133056074380875}]}, {"text": "As the data size increases, our word segmen-    tation system obtains consistent gains on OOV recall on both corpora.", "labels": [], "entities": [{"text": "OOV", "start_pos": 90, "end_pos": 93, "type": "METRIC", "confidence": 0.9448158740997314}, {"text": "recall", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.7176051139831543}]}, {"text": "On the whole 38K words training data, our system reaches the highest OOV recall.", "labels": [], "entities": [{"text": "OOV", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.9984757304191589}, {"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.8438044786453247}]}, {"text": "An interesting observation is that the OOV recall on MSR is more sensitive on data size changing.", "labels": [], "entities": [{"text": "OOV", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.9909177422523499}, {"text": "recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.7060134410858154}]}, {"text": "The main reason is the different annotation standard of the two corpus.", "labels": [], "entities": []}, {"text": "PKU is a correspondingly fine-grained annotated corpus with shorter average word length than MSR.", "labels": [], "entities": [{"text": "PKU", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9073552489280701}]}, {"text": "Our synthetic word parser reaches high parsing accuracy on short length words (three-character and fourcharacter words) even with a small training data size.", "labels": [], "entities": [{"text": "synthetic word parser", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.6972381273905436}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.985957682132721}]}, {"text": "With the increase of word length, the parser needs more training data.", "labels": [], "entities": []}, {"text": "These factors cause that our system reaches high OOV recall on PKU starting from a small training data size and obtains more OOV recall gains on MSR when increasing the training data size.", "labels": [], "entities": [{"text": "OOV", "start_pos": 49, "end_pos": 52, "type": "METRIC", "confidence": 0.9935818910598755}, {"text": "recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.730780839920044}, {"text": "OOV", "start_pos": 125, "end_pos": 128, "type": "METRIC", "confidence": 0.9675997495651245}, {"text": "recall", "start_pos": 129, "end_pos": 135, "type": "METRIC", "confidence": 0.5559467077255249}]}, {"text": "Our pipeline system adopts a chunking model to recover the original standard from the finegrained standard.", "labels": [], "entities": []}, {"text": "One question is how difficult is this task.", "labels": [], "entities": []}, {"text": "Unfortunately, we do not have the gold fine-grained input to evaluate the performance of our chunking model directly; i.e. it is not clear whether a segmentation error is due to mis-predictions in the first or second CRF.", "labels": [], "entities": []}, {"text": "Therefore, we use the synthetic word parser to parse all the words in the gold testing data and generate an artificial gold fine-grained input for the chunking model.", "labels": [], "entities": []}, {"text": "This data keeps the original word bound-  aries and can be used to observe the chunking performance.", "labels": [], "entities": []}, {"text": "shows that the chunking model on the artificial data obtains a 0.822 to 0.847 improvement in OOV recall.", "labels": [], "entities": [{"text": "OOV", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.9721388220787048}, {"text": "recall", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.8533562421798706}]}, {"text": "We can interpret this to mean that 0.025 improvement is possible if the first CRF was perfect; on the other hand, the gap between 0.847 and 1.0 shows that potentially the second CRF is a harder task.", "labels": [], "entities": []}, {"text": "However, the real gap is less for the lose of the parsing step and the existence of non-pseudo OOVs.: The Word Segmentation evaluation of the Chunking Model.", "labels": [], "entities": [{"text": "parsing", "start_pos": 50, "end_pos": 57, "type": "TASK", "confidence": 0.966088593006134}, {"text": "Word Segmentation", "start_pos": 106, "end_pos": 123, "type": "TASK", "confidence": 0.7712814211845398}]}, {"text": "\"Artificial gold\" denotes the word segmentation result when the chunking model runs on the artificial gold input.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.6384749859571457}]}], "tableCaptions": [{"text": " Table 1: Comparison of the Proposed Method to the Baseline and Previous works on PKU and MSR  Corpora. Here, \"R pseudo \" denotes the recall of pseudo-OOV words. \"Bakeoff-2005\" denotes the best  results of the second international Chinese word segmentation bakeoff-2005 on two corpora. Since  we use extra resources and our proposed method replies on the synthetic word parser trained on an  dictionary with internal structure annotated, the results cannot be directly compared with the state-of- the-art systems.", "labels": [], "entities": [{"text": "PKU", "start_pos": 82, "end_pos": 85, "type": "DATASET", "confidence": 0.9505266547203064}, {"text": "recall", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.9902224540710449}, {"text": "international Chinese word segmentation bakeoff-2005", "start_pos": 217, "end_pos": 269, "type": "TASK", "confidence": 0.6862686276435852}]}, {"text": " Table 2: The Statistical Significance Test of the Word Segmentation Results on PKU and MSR Corpora.", "labels": [], "entities": [{"text": "Word Segmentation", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.6804433017969131}, {"text": "PKU and MSR Corpora", "start_pos": 80, "end_pos": 99, "type": "DATASET", "confidence": 0.7432023882865906}]}, {"text": " Table 3: The Word Segmentation evaluation of  the Chunking Model. \"Artificial gold\" denotes  the word segmentation result when the chunking  model runs on the artificial gold input.", "labels": [], "entities": [{"text": "Word Segmentation", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.7497349083423615}, {"text": "word segmentation", "start_pos": 98, "end_pos": 115, "type": "TASK", "confidence": 0.6806070953607559}]}]}