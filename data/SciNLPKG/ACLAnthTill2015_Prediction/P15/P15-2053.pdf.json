{"title": [{"text": "Chinese Zero Pronoun Resolution: A Joint Unsupervised Discourse-Aware Model Rivaling State-of-the-Art Resolvers", "labels": [], "entities": [{"text": "Chinese Zero Pronoun Resolution", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7495908141136169}]}], "abstractContent": [{"text": "We propose an unsupervised probabilistic model for zero pronoun resolution.", "labels": [], "entities": [{"text": "zero pronoun resolution", "start_pos": 51, "end_pos": 74, "type": "TASK", "confidence": 0.6355966428915659}]}, {"text": "To our knowledge, this is the first such model that (1) is trained on zero pronouns in an unsu-pervised manner; (2) jointly identifies and resolves anaphoric zero pronouns; and (3) exploits discourse information provided by a salience model.", "labels": [], "entities": []}, {"text": "Experiments demonstrate that our unsupervised model significantly outperforms its state-of-the-art un-supervised counterpart when resolving the Chinese zero pronouns in the OntoNotes corpus.", "labels": [], "entities": [{"text": "OntoNotes corpus", "start_pos": 173, "end_pos": 189, "type": "DATASET", "confidence": 0.9072642922401428}]}], "introductionContent": [{"text": "A zero pronoun (ZP) is a gap in a sentence that is found when a phonetically null form is used to refer to a real-world entity.", "labels": [], "entities": []}, {"text": "An anaphoric zero pronoun (AZP) is a ZP that corefers with one or more preceding mentions in the associated text.", "labels": [], "entities": []}, {"text": "Below is an example taken from the Chinese TreeBank (CTB), where the ZP (denoted as *pro*) refers to \u4fc4\u7f57\u65af (Russia).", "labels": [], "entities": [{"text": "Chinese TreeBank (CTB)", "start_pos": 35, "end_pos": 57, "type": "DATASET", "confidence": 0.9317677021026611}]}, {"text": "[\u4fc4\u7f57\u65af] \u4f5c\u4e3a\u7c73\u6d1b\u820d\u592b\u7ef4\u5947\u4e00\u8d2f\u7684\u652f\u6301\u8005\uff0c *pro* \u66fe\u7ecf\u63d0\u51fa\u8c03\u505c\u8fd9\u573a\u653f\u6cbb\u5371\u673a\u3002", "labels": [], "entities": []}, {"text": "( is a consistent supporter of Milo\u0161evi\u0107, *pro* has proposed to mediate the political crisis.)", "labels": [], "entities": []}, {"text": "As we can see, ZPs lack grammatical attributes that are useful for overt pronoun resolution such as number and gender.", "labels": [], "entities": [{"text": "overt pronoun resolution", "start_pos": 67, "end_pos": 91, "type": "TASK", "confidence": 0.832105795542399}]}, {"text": "This makes ZP resolution more challenging than overt pronoun resolution.", "labels": [], "entities": [{"text": "ZP resolution", "start_pos": 11, "end_pos": 24, "type": "TASK", "confidence": 0.7951128780841827}, {"text": "overt pronoun resolution", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.7802431384722391}]}, {"text": "Automatic ZP resolution is typically composed of two steps.", "labels": [], "entities": [{"text": "ZP resolution", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.8163741230964661}]}, {"text": "The first step, AZP identification, involves extracting ZPs that are anaphoric.", "labels": [], "entities": [{"text": "AZP identification", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.857732355594635}]}, {"text": "The second step, AZP resolution, aims to identify an antecedent of an AZP.", "labels": [], "entities": [{"text": "AZP resolution", "start_pos": 17, "end_pos": 31, "type": "TASK", "confidence": 0.834565281867981}]}, {"text": "State-of-the-art ZP resolvers have tackled both of these steps in a supervised manner, training one classifier for AZP identification and another for AZP resolution (e.g.,,).", "labels": [], "entities": [{"text": "ZP resolvers", "start_pos": 17, "end_pos": 29, "type": "TASK", "confidence": 0.83883997797966}, {"text": "AZP identification", "start_pos": 115, "end_pos": 133, "type": "TASK", "confidence": 0.7094950675964355}, {"text": "AZP resolution", "start_pos": 150, "end_pos": 164, "type": "TASK", "confidence": 0.6795625984668732}]}, {"text": "More recently, we have proposed an unsupervised AZP resolution model (henceforth the CN14 model) that rivals its supervised counterparts in performance).", "labels": [], "entities": [{"text": "AZP resolution", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.6721717715263367}]}, {"text": "The idea is to resolve AZPs by using a probabilistic pronoun resolution model trained on overt pronouns in an unsupervised manner.", "labels": [], "entities": [{"text": "resolve AZPs", "start_pos": 15, "end_pos": 27, "type": "TASK", "confidence": 0.7088730335235596}, {"text": "probabilistic pronoun resolution", "start_pos": 39, "end_pos": 71, "type": "TASK", "confidence": 0.743186354637146}]}, {"text": "This is an appealing approach, as its language-independent generative process enables it to be applied to languages where data annotated with ZP links are not available.", "labels": [], "entities": []}, {"text": "In light of the advantages of unsupervised models, we examine in this paper the possibility of advancing the state of the art in unsupervised AZP resolution.", "labels": [], "entities": [{"text": "AZP resolution", "start_pos": 142, "end_pos": 156, "type": "TASK", "confidence": 0.7168834507465363}]}, {"text": "The design of our unsupervised model is motivated by a key question: can we resolve AZPs by using a probabilistic model trained on zero pronouns in an unsupervised manner?", "labels": [], "entities": []}, {"text": "As mentioned above, the CN14 model was trained on overt pronouns, but it is not clear how much this helped its resolution performance.", "labels": [], "entities": []}, {"text": "In particular, the contexts in which overt and zero pronouns occur may not statistically resemble each other.", "labels": [], "entities": []}, {"text": "For example, a ZP is likely to be closer to its antecedent than its overt counterpart.", "labels": [], "entities": []}, {"text": "As another example, the verbs governing a ZP and its antecedent are more likely to be identical than the verbs governing an overt pronoun and its antecedent.", "labels": [], "entities": []}, {"text": "Given such differences, it is not clear whether the knowledge learned from overt pronouns is always applicable to the resolution of AZPs.", "labels": [], "entities": [{"text": "resolution of AZPs", "start_pos": 118, "end_pos": 136, "type": "TASK", "confidence": 0.8516210516293844}]}, {"text": "For this reason, we propose to train an unsupervised AZP resolution model directly on zero pronouns.", "labels": [], "entities": [{"text": "AZP resolution", "start_pos": 53, "end_pos": 67, "type": "TASK", "confidence": 0.7903371155261993}]}, {"text": "Moreover, while we previously employed a pipeline architecture where we (1) used a set of heuristic rules for AZP identification, and then (2) applied their probabilistic model to all and only those ZPs that were determined to be anaphoric, in this work we identify and resolve AZPs in a joint fashion.", "labels": [], "entities": [{"text": "AZP identification", "start_pos": 110, "end_pos": 128, "type": "TASK", "confidence": 0.7564098536968231}]}, {"text": "To our knowledge, the model we are proposing here is the first unsupervised model for joint AZP identification and resolution.", "labels": [], "entities": [{"text": "AZP identification and resolution", "start_pos": 92, "end_pos": 125, "type": "TASK", "confidence": 0.7446597665548325}]}, {"text": "In addition, motivated by work on overt pronoun resolution, we hypothesize that AZP resolution can be improved by exploiting discourse information.", "labels": [], "entities": [{"text": "overt pronoun resolution", "start_pos": 34, "end_pos": 58, "type": "TASK", "confidence": 0.7596846222877502}, {"text": "AZP resolution", "start_pos": 80, "end_pos": 94, "type": "TASK", "confidence": 0.7994894683361053}]}, {"text": "Specifically, we design a model of salience and incorporate salience information into our model as a feature.", "labels": [], "entities": []}, {"text": "Inspired by traditional work on discoursebased anaphora resolution (e.g.,), we compute salience based on the coreference clusters constructed so far using a rule-based coreference resolver.", "labels": [], "entities": [{"text": "discoursebased anaphora resolution", "start_pos": 32, "end_pos": 66, "type": "TASK", "confidence": 0.6174007852872213}]}, {"text": "While ZPs have been exploited to improve coreference resolution (, we are the first to improve AZP resolution using coreference information.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.9507418572902679}, {"text": "AZP resolution", "start_pos": 95, "end_pos": 109, "type": "TASK", "confidence": 0.7770008146762848}]}, {"text": "When evaluated on the Chinese portion of the OntoNotes corpus, our AZP resolver outperforms the CN14 model, achieving state-of-the-art results.", "labels": [], "entities": [{"text": "OntoNotes corpus", "start_pos": 45, "end_pos": 61, "type": "DATASET", "confidence": 0.7975021600723267}, {"text": "AZP", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.9031493067741394}]}], "datasetContent": [{"text": "We employ the Chinese portion of the OntoNotes 5.0 corpus that was used in the official CoNLL-2012 shared task ().", "labels": [], "entities": [{"text": "OntoNotes 5.0 corpus", "start_pos": 37, "end_pos": 57, "type": "DATASET", "confidence": 0.7966722846031189}]}, {"text": "In the CoNLL-2012 data, the training set and development set contain ZP coreference annotations, but the test set does not.", "labels": [], "entities": [{"text": "CoNLL-2012 data", "start_pos": 7, "end_pos": 22, "type": "DATASET", "confidence": 0.9641441106796265}]}, {"text": "Therefore, we train our models on the training set and perform evaluation on the development set.", "labels": [], "entities": []}, {"text": "Statistics on the datasets are shown in.", "labels": [], "entities": []}, {"text": "The documents in these datasets come from six sources, namely Broadcast News (BN), Newswires (NW), Broadcast Conversations (BC), Telephone Conversations (TC), Web Blogs (WB), and Magazines (MZ).", "labels": [], "entities": []}, {"text": "We express results in terms of recall (R), precision (P), and F-score (F) on resolving AZPs, considering an AZP z correctly resolved if it is resolved to any NP in the same coreference chain as z.", "labels": [], "entities": [{"text": "recall (R)", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.9511749446392059}, {"text": "precision (P)", "start_pos": 43, "end_pos": 56, "type": "METRIC", "confidence": 0.9535533934831619}, {"text": "F-score (F)", "start_pos": 62, "end_pos": 73, "type": "METRIC", "confidence": 0.9614336937665939}]}, {"text": "Following, we evaluate our model in three settings.", "labels": [], "entities": []}, {"text": "In Setting 1, we assume the availability of gold syntactic parse trees and gold AZPs.", "labels": [], "entities": [{"text": "AZPs", "start_pos": 80, "end_pos": 84, "type": "METRIC", "confidence": 0.860028088092804}]}, {"text": "In Setting 2, we employ gold syntactic parse trees and system (i.e., automatically identified) AZPs.", "labels": [], "entities": []}, {"text": "Finally, in Setting 3 (the end-to-end setting), we employ system syntactic parse trees and system AZPs.", "labels": [], "entities": []}, {"text": "The gold and system syntactic parse trees, as well as the gold AZPs, are obtained from the CoNLL-2012 shared task dataset, while the system AZPs are identified by our generative model.", "labels": [], "entities": [{"text": "CoNLL-2012 shared task dataset", "start_pos": 91, "end_pos": 121, "type": "DATASET", "confidence": 0.858833372592926}]}], "tableCaptions": [{"text": " Table 1: Statistics on the training and test sets.", "labels": [], "entities": []}, {"text": " Table 2: AZP resolution results of the baseline and our model on the test set.", "labels": [], "entities": [{"text": "AZP resolution", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.8054381012916565}]}]}