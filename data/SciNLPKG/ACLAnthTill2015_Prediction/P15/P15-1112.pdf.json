{"title": [{"text": "A Re-ranking Model for Dependency Parser with Recursive Convolutional Neural Network", "labels": [], "entities": []}], "abstractContent": [{"text": "In this work, we address the problem to model all the nodes (words or phrases) in a dependency tree with the dense representations.", "labels": [], "entities": []}, {"text": "We propose a recursive convolutional neural network (RCNN) architecture to capture syntactic and compositional-semantic representations of phrases and words in a dependency tree.", "labels": [], "entities": []}, {"text": "Different with the original re-cursive neural network, we introduce the convolution and pooling layers, which can model a variety of compositions by the feature maps and choose the most informative compositions by the pooling layers.", "labels": [], "entities": []}, {"text": "Based on RCNN, we use a discrimina-tive model to re-rank a k-best list of candidate dependency parsing trees.", "labels": [], "entities": [{"text": "RCNN", "start_pos": 9, "end_pos": 13, "type": "DATASET", "confidence": 0.9261972308158875}]}, {"text": "The experiments show that RCNN is very effective to improve the state-of-the-art dependency parsing on both English and Chi-nese datasets.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.7035802006721497}]}], "introductionContent": [{"text": "Feature-based discriminative supervised models have achieved much progress in dependency parsing), which typically use millions of discrete binary features generated from a limited size training data.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 78, "end_pos": 96, "type": "TASK", "confidence": 0.8250436186790466}]}, {"text": "However, the ability of these models is restricted by the design of features.", "labels": [], "entities": []}, {"text": "The number of features could be so large that the result models are too complicated for practical use and prone to overfit on training corpus due to data sparseness.", "labels": [], "entities": []}, {"text": "Recently, many methods are proposed to learn various distributed representations on both syntax and semantics levels.", "labels": [], "entities": []}, {"text": "These distributed representations have been extensively applied on many * Corresponding author.", "labels": [], "entities": []}, {"text": "natural language processing (NLP) tasks, such as syntax () and semantics (.", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7211078008015951}]}, {"text": "Distributed representations are to represent words (or phrase) by the dense, low-dimensional and real-valued vectors, which help address the curse of dimensionality and have better generalization than discrete representations.", "labels": [], "entities": []}, {"text": "For dependency parsing,  and used the dense vectors (embeddings) to represent words or features and found these representations are complementary to the traditional discrete feature representation.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.8309928178787231}]}, {"text": "However, these two methods only focus on the dense representations (embeddings) of words or features.", "labels": [], "entities": []}, {"text": "These embeddings are pre-trained and keep unchanged in the training phase of parsing model, which cannot be optimized for the specific tasks.", "labels": [], "entities": [{"text": "parsing", "start_pos": 77, "end_pos": 84, "type": "TASK", "confidence": 0.975893497467041}]}, {"text": "Besides, it is also important to represent the (unseen) phrases with dense vector in dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.8182738423347473}]}, {"text": "Since the dependency tree is also in recursive structure, it is intuitive to use the recursive neural network (RNN), which is used for constituent parsing).", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 135, "end_pos": 154, "type": "TASK", "confidence": 0.6629689335823059}]}, {"text": "However, recursive neural network can only process the binary combination and is not suitable for dependency parsing, since a parent node may have two or more child nodes in dependency tree.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.873595803976059}]}, {"text": "In this work, we address the problem to rep-resent all level nodes (words or phrases) with dense representations in a dependency tree.", "labels": [], "entities": []}, {"text": "We propose a recursive convolutional neural network (RCNN) architecture to capture syntactic and compositional-semantic representations of phrases and words.", "labels": [], "entities": []}, {"text": "RCNN is a general architecture and can deal with k-ary parsing tree, therefore it is very suitable for dependency parsing.", "labels": [], "entities": [{"text": "RCNN", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8461777567863464}, {"text": "dependency parsing", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.8328275978565216}]}, {"text": "For each node in a given dependency tree, we first use a RCNN unit to model the interactions between it and each of its children and choose the most informative features by a pooling layer.", "labels": [], "entities": []}, {"text": "Thus, we can apply the RCNN unit recursively to get the vector representation of the whole dependency tree.", "labels": [], "entities": []}, {"text": "The output of each RCNN unit is used as the input of the RCNN unit of its parent node, until it outputs a single fixed-length vector at root node.", "labels": [], "entities": []}, {"text": "illustrates an example how a RCNN unit represents the phrases \"a red bike\" as continuous vectors.", "labels": [], "entities": []}, {"text": "The contributions of this paper can be summarized as follows.", "labels": [], "entities": []}, {"text": "\u2022 RCNN is a general architecture to model the distributed representations of a phrase or sentence with its dependency tree.", "labels": [], "entities": []}, {"text": "Although RCNN is just used for the re-ranking of the dependency parser in this paper, it can be regarded as semantic modelling of text sequences and handle the input sequences of varying length into a fixed-length vector.", "labels": [], "entities": []}, {"text": "The parameters in RCNN can be learned jointly with some other NLP tasks, such as text classification.", "labels": [], "entities": [{"text": "text classification", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.8547090291976929}]}, {"text": "\u2022 Each RCNN unit can model the complicated interactions of the headword and its children.", "labels": [], "entities": []}, {"text": "Combined with a specific task, RCNN can capture the most useful semantic and structure information by the convolution and pooling layers.", "labels": [], "entities": []}, {"text": "\u2022 When applied to the re-ranking model for parsing, RCNN improve the accuracy of base parser to make accurate parsing decisions.", "labels": [], "entities": [{"text": "parsing", "start_pos": 43, "end_pos": 50, "type": "TASK", "confidence": 0.9864596128463745}, {"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9993265867233276}]}, {"text": "The experiments on two benchmark datasets show that RCNN outperforms the state-ofthe-art models.", "labels": [], "entities": []}], "datasetContent": [{"text": "To empirically demonstrate the effectiveness of our approach, we use two datasets in different languages (English and Chinese) in our experimental evaluation and compare our model against the other state-of-the-art methods using the unlabeled attachment score (UAS) metric ignoring punctuation.", "labels": [], "entities": [{"text": "unlabeled attachment score (UAS) metric", "start_pos": 233, "end_pos": 272, "type": "METRIC", "confidence": 0.7942662494523185}]}, {"text": "English For English dataset, we follow the standard splits of Penn Treebank (PTB), using sections 2-21 for training, section 22 as development set and section 23 as test set.", "labels": [], "entities": [{"text": "English dataset", "start_pos": 12, "end_pos": 27, "type": "DATASET", "confidence": 0.6772876232862473}, {"text": "Penn Treebank (PTB)", "start_pos": 62, "end_pos": 81, "type": "DATASET", "confidence": 0.9777742862701416}]}, {"text": "We tag the development and test sets using an automatic POS tagger (at 97.2% accuracy), and tag the training set using four-way jackknifing similar to).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9983108043670654}]}, {"text": "Chinese For Chinese dataset, we follow the same split of the Penn Chinese Treeban (CTB5) as described in and use sections 001-815, 1001-1136 as training set, sections 886-931, 1148-1151 as development set, and sections 816-885, 1137-1147 as test set.", "labels": [], "entities": [{"text": "Chinese For Chinese dataset", "start_pos": 0, "end_pos": 27, "type": "DATASET", "confidence": 0.6779301390051842}, {"text": "Penn Chinese Treeban (CTB5)", "start_pos": 61, "end_pos": 88, "type": "DATASET", "confidence": 0.9820643663406372}]}, {"text": "Dependencies are converted by using the Penn2Malt tool with the head-finding rules of.", "labels": [], "entities": [{"text": "Penn2Malt", "start_pos": 40, "end_pos": 49, "type": "DATASET", "confidence": 0.9689607620239258}]}, {"text": "And following () (Zhang and Nivre, 2011), we use gold segmentation and POS tags for the input.", "labels": [], "entities": []}, {"text": "We use the linear-time incremental parser ( as our base parser and calculate the 64-best parses at the top cell of the chart.", "labels": [], "entities": []}, {"text": "Note that we optimize the training settings for base parser and the results are slightly improved on.", "labels": [], "entities": []}, {"text": "Then we use max-margin criterion to train RCNN.", "labels": [], "entities": [{"text": "max-margin", "start_pos": 12, "end_pos": 22, "type": "METRIC", "confidence": 0.9655868411064148}, {"text": "RCNN", "start_pos": 42, "end_pos": 46, "type": "DATASET", "confidence": 0.909256637096405}]}, {"text": "Finally, we use the mixture strategy to re-rank the top 64-best parses.", "labels": [], "entities": []}, {"text": "For initialization of parameters, we train word2vec embeddings () on Wikipedia corpus for English and Chinese respectively.", "labels": [], "entities": []}, {"text": "For the combination matrices and score vectors, we use the random initialization within (0.01, 0.01).", "labels": [], "entities": []}, {"text": "The parameters which achieve the best unlabeled attachment score on the development set will be chosen for the final evaluation.", "labels": [], "entities": []}, {"text": "We first evaluate the performances of the RCNN and re-ranker (Eq.) on the development set.", "labels": [], "entities": [{"text": "RCNN", "start_pos": 42, "end_pos": 46, "type": "DATASET", "confidence": 0.9162710309028625}, {"text": "re-ranker (Eq.)", "start_pos": 51, "end_pos": 66, "type": "METRIC", "confidence": 0.7907569706439972}]}, {"text": "shows UASs of different models with varying k.", "labels": [], "entities": []}, {"text": "The base parser achieves 92.45%.", "labels": [], "entities": []}, {"text": "When k = 64, the oracle best of base parser achieves 97.34%, while the oracle worst achieves 73.30% (-19.15%) . RCNN achieves the maximum improvement of 93.00%(+0.55%) when k = 6.", "labels": [], "entities": []}, {"text": "When k > 6, the performance of RCNN declines with the increase of k but is still higher than baseline (92.45%).", "labels": [], "entities": []}, {"text": "The reason behind this is that RCNN could require more negative samples to avoid overfitting when k is large.", "labels": [], "entities": []}, {"text": "Since the negative samples are limited in the k-best outputs of abase parser, the learnt parameters could easily overfits to the training set.", "labels": [], "entities": []}, {"text": "The mixture re-ranker achieves the maximum improvement of 93.50%(+1.05%) when k = 64.", "labels": [], "entities": []}, {"text": "In mixture re-ranker, \u03b1 is optimised by searching with the step-size 0.005.", "labels": [], "entities": []}, {"text": "Therefore, we use the mixture re-ranker in the following experiments since it can take the advantages of both the RCNN and base models.", "labels": [], "entities": [{"text": "RCNN", "start_pos": 114, "end_pos": 118, "type": "DATASET", "confidence": 0.8955419063568115}]}, {"text": "shows the accuracies on the top ten POS tags of the modifier words with the largest improvements.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.970014750957489}]}, {"text": "We can see that our re-ranker can improve the accuracies of CC and IN, and therefore may indirectly result in rising the the well-known coordinating conjunction and PPattachment problems.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 46, "end_pos": 56, "type": "METRIC", "confidence": 0.985281765460968}, {"text": "IN", "start_pos": 67, "end_pos": 69, "type": "METRIC", "confidence": 0.9919795989990234}]}, {"text": "The final experimental results on test set are shown in.", "labels": [], "entities": []}, {"text": "The hyperparameters of our model are set as in.", "labels": [], "entities": []}, {"text": "Our re-ranker achieves the maximum improvement of 93.83%(+1.48%) on test set.", "labels": [], "entities": []}, {"text": "Our system performs slightly better than many state-of-the-art systems such as and.", "labels": [], "entities": []}, {"text": "It outperforms and, which also use the mixture reranking strategy.", "labels": [], "entities": []}, {"text": "Since the result of ranker is conditioned to kbest results of base parser, we also do an experiment to avoid this limitation by adding the oracle to k-best candidates.", "labels": [], "entities": []}, {"text": "With including oracle, the re-ranker can achieve 94.16% on UAS, which is shown in the last line (\"our re-ranker (with oracle)\") of.", "labels": [], "entities": [{"text": "UAS", "start_pos": 59, "end_pos": 62, "type": "DATASET", "confidence": 0.7483202219009399}]}, {"text": "Base Paser Re-ranker: Accuracies on the top ten POS tags of the modifier words with the largest improvements on the development set.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 22, "end_pos": 32, "type": "METRIC", "confidence": 0.9763720631599426}]}, {"text": "We also make experiments on the Penn Chinese Treebank (CTB5).", "labels": [], "entities": [{"text": "Penn Chinese Treebank (CTB5)", "start_pos": 32, "end_pos": 60, "type": "DATASET", "confidence": 0.9778794646263123}]}, {"text": "The hyperparameters is the same as the previous experiment on English except that \u03b1 is optimised by searching with the step-size 0.005.", "labels": [], "entities": []}, {"text": "The final experimental results on the test set are shown in.", "labels": [], "entities": []}, {"text": "Our re-ranker achieves the performance of 85.71%(+0.25%) on the test set, which also outperforms the previous state-of-theart methods.", "labels": [], "entities": []}, {"text": "With adding oracle, the re-ranker can achieve 87.43% on UAS, which is shown in the last line (\"our re-ranker (with oracle)\") of.", "labels": [], "entities": [{"text": "UAS", "start_pos": 56, "end_pos": 59, "type": "DATASET", "confidence": 0.7326339483261108}]}], "tableCaptions": [{"text": " Table 1: Accuracy on English test set. Our base- line is the result of base parser; our re-ranker uses  the mixture strategy on the 64-best outputs of base  parser; our re-ranker(with oracle) is to add the or- acle to k-best outputs of base parser.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9888125658035278}, {"text": "English test set", "start_pos": 22, "end_pos": 38, "type": "DATASET", "confidence": 0.8480119903882345}]}, {"text": " Table 2: Hyperparameters of our model", "labels": [], "entities": []}, {"text": " Table 3: Accuracy on Chinese test set.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.998052716255188}, {"text": "Chinese test set", "start_pos": 22, "end_pos": 38, "type": "DATASET", "confidence": 0.9677196741104126}]}]}