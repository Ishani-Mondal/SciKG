{"title": [{"text": "Predicting Valence-Arousal Ratings of Words Using a Weighted Graph Method", "labels": [], "entities": [{"text": "Predicting Valence-Arousal Ratings of Words", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.8980729818344116}]}], "abstractContent": [{"text": "Compared to the categorical approach that represents affective states as several discrete classes (e.g., positive and negative), the dimensional approach represents affective states as continuous numerical values on multiple dimensions, such as the valence-arousal (VA) space, thus allowing for more fine-grained sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 313, "end_pos": 331, "type": "TASK", "confidence": 0.822561115026474}]}, {"text": "In building dimensional sentiment applications, affective lexicons with valence-arousal ratings are useful resources but are still very rare.", "labels": [], "entities": [{"text": "building dimensional sentiment", "start_pos": 3, "end_pos": 33, "type": "TASK", "confidence": 0.767305056254069}]}, {"text": "Therefore , this study proposes a weighted graph model that considers both the relations of multiple nodes and their similarities as weights to automatically determine the VA ratings of affective words.", "labels": [], "entities": [{"text": "VA", "start_pos": 172, "end_pos": 174, "type": "METRIC", "confidence": 0.8191130757331848}]}, {"text": "Experiments on both English and Chi-nese affective lexicons show that the proposed method yielded a smaller error rate on VA prediction than the linear regression , kernel method, and pagerank algorithm used in previous studies.", "labels": [], "entities": [{"text": "error rate", "start_pos": 108, "end_pos": 118, "type": "METRIC", "confidence": 0.9642024040222168}, {"text": "VA prediction", "start_pos": 122, "end_pos": 135, "type": "TASK", "confidence": 0.8011507391929626}]}], "introductionContent": [{"text": "Thanks to the vigorous development of online social network services, anyone can now easily publish and disseminate articles expressing their thoughts and opinions.", "labels": [], "entities": []}, {"text": "Sentiment analysis thus has become a useful technique to automatically identify affective information from texts (.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.954452782869339}]}, {"text": "In sentiment analysis, representation of affective states is an essential issue and can be generally divided into categorical and dimensional approaches.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.9695972502231598}]}, {"text": "The categorical approach represents affective states as several discrete classes such as binary (positive and negative) and Ekman's six basic emotions (e.g., anger, happiness, fear, sadness, disgust and surprise).", "labels": [], "entities": []}, {"text": "Based on this representation, various techniques have been investigated to develop useful applications such as deceptive opinion spam detection (), aspect extraction (Mukherjee and Liu, 2012), cross-lingual portability (, personalized sentiment analysis) and viewpoint identification (.", "labels": [], "entities": [{"text": "deceptive opinion spam detection", "start_pos": 111, "end_pos": 143, "type": "TASK", "confidence": 0.6643151715397835}, {"text": "aspect extraction", "start_pos": 148, "end_pos": 165, "type": "TASK", "confidence": 0.8228688538074493}, {"text": "cross-lingual portability", "start_pos": 193, "end_pos": 218, "type": "TASK", "confidence": 0.7590664923191071}, {"text": "personalized sentiment analysis", "start_pos": 222, "end_pos": 253, "type": "TASK", "confidence": 0.6752068301041921}, {"text": "viewpoint identification", "start_pos": 259, "end_pos": 283, "type": "TASK", "confidence": 0.9380201101303101}]}, {"text": "In addition to identifying sentiment classes, an extension has been made to further determine their sentiment strength in terms of a multi-point scale).", "labels": [], "entities": []}, {"text": "The dimensional approach has drawn considerable attention in recent years as it can provide a more fine-grained sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.8468689620494843}]}, {"text": "It represents affective states as continuous numerical values on multiple dimensions, such as valencearousal (VA) space, as shown in.", "labels": [], "entities": []}, {"text": "The valence represents the degree of pleasant and unpleasant (or positive and negative) feelings, and the arousal represents the degree of excitement and calm.", "labels": [], "entities": []}, {"text": "Based on such a twodimensional representation, a common research goal is to determine the degrees of valence and arousal of given texts such that any affective state can be represented as a point in the VA coordinate plane.", "labels": [], "entities": []}, {"text": "To accomplish this goal, affective lexicons with valence-arousal ratings are useful resources but few exist.", "labels": [], "entities": []}, {"text": "Most existing applications rely on a handcrafted lexicon ANEW (Af-fective Norms for English Words)) which provides 1,034 English words with ratings in the dimensions of pleasure, arousal and dominance to predict the VA ratings of short and long texts (.", "labels": [], "entities": [{"text": "ANEW", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.9126720428466797}, {"text": "VA", "start_pos": 216, "end_pos": 218, "type": "METRIC", "confidence": 0.9943391680717468}]}, {"text": "Accordingly, the automatic prediction of VA ratings of affective words is a critical task in building a VA lexicon.", "labels": [], "entities": [{"text": "prediction of VA ratings of affective words", "start_pos": 27, "end_pos": 70, "type": "TASK", "confidence": 0.683625842843737}]}, {"text": "Few studies have sought to predict the VA rating of words using regression-based methods).", "labels": [], "entities": [{"text": "VA rating", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9819243848323822}]}, {"text": "This kind of method usually starts from a set of words with labeled VA ratings (called seeds).", "labels": [], "entities": [{"text": "VA", "start_pos": 68, "end_pos": 70, "type": "METRIC", "confidence": 0.9652552604675293}]}, {"text": "The VA rating of an unseen word is then estimated from semantically similar seeds.", "labels": [], "entities": [{"text": "VA rating", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9834546446800232}]}, {"text": "For instance, trained a linear regression model for each seed cluster, and then predicted the VA rating of an unseen word using the model of the cluster to which the unseen word belongs.", "labels": [], "entities": [{"text": "VA rating", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9877946376800537}]}, {"text": "used a kernel function to combine the similarity between seeds and unseen words into a linear regression model.", "labels": [], "entities": []}, {"text": "Instead of estimating VA ratings of words, another direction is to determine the polarity (i.e., positive and negative) of words by applying the label propagation () and pagerank () on a graph.", "labels": [], "entities": [{"text": "VA", "start_pos": 22, "end_pos": 24, "type": "METRIC", "confidence": 0.9058353900909424}]}, {"text": "Based on these methods, the polarity of an unseen word can be determined/ranked through its neighbor nodes (seeds).", "labels": [], "entities": []}, {"text": "Although the pagerank algorithm has been used for polarity ranking, it can still be extended for VA prediction.", "labels": [], "entities": [{"text": "polarity ranking", "start_pos": 50, "end_pos": 66, "type": "TASK", "confidence": 0.8846845030784607}, {"text": "VA prediction", "start_pos": 97, "end_pos": 110, "type": "TASK", "confidence": 0.9626336693763733}]}, {"text": "Therefore, this study extends the idea of pagerank in two aspects.", "labels": [], "entities": []}, {"text": "First, we implement pagerank for VA prediction by transforming ranking scores into VA ratings.", "labels": [], "entities": [{"text": "VA prediction", "start_pos": 33, "end_pos": 46, "type": "TASK", "confidence": 0.9128910303115845}]}, {"text": "Second, whereas pagerank assigns an equal weight to the edges connected between an unseen word and its neighbor nodes, we consider their similarities as weights to construct a weighted graph such that neighbor nodes more similar to the unseen word may contribute more to estimate its VA ratings.", "labels": [], "entities": [{"text": "VA", "start_pos": 284, "end_pos": 286, "type": "METRIC", "confidence": 0.992544949054718}]}, {"text": "That is, the proposed weighted graph model considers both the relations of multiple nodes and the similarity weights among them.", "labels": [], "entities": []}, {"text": "In experiments, we evaluate the performance of the proposed method against the linear regression, kernel method, and pagerank algorithm on both English and Chinese affective lexicons for VA prediction.", "labels": [], "entities": [{"text": "VA prediction", "start_pos": 187, "end_pos": 200, "type": "TASK", "confidence": 0.9855932593345642}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the proposed weighted graph model.", "labels": [], "entities": []}, {"text": "Section 3 summarizes the comparative results of different methods for VA prediction.", "labels": [], "entities": [{"text": "VA prediction", "start_pos": 70, "end_pos": 83, "type": "TASK", "confidence": 0.9895752966403961}]}, {"text": "Conclusions are finally drawn in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "This experiment used two affective lexicons with VA ratings: 1) ANEW which contains 1,034 English affective words) and 2) 162 Chinese affective words (CAW) taken from).", "labels": [], "entities": [{"text": "VA", "start_pos": 49, "end_pos": 51, "type": "METRIC", "confidence": 0.9979541301727295}, {"text": "ANEW", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.981128454208374}]}, {"text": "Both lexicons were used for 5-fold cross-validation.", "labels": [], "entities": []}, {"text": "That is, for each run, 80% of the words in the lexicons were considered as seeds and the remaining 20% were used as unseen words.", "labels": [], "entities": []}, {"text": "The similarities between English words and between Chinese words were calculated using the word2vec toolkit trained with the respective English and Chinese wiki corpora (https://dumps.wikimedia.org/).", "labels": [], "entities": []}, {"text": "Two regression-based methods were used for comparison: linear regression () and the kernel method (Malandrakis et al., 2011), along with two graphbased methods: pagerank () and the proposed weighted graph model.", "labels": [], "entities": []}, {"text": "For both regression-based methods, the similarities and VA ratings of the seed words were used for training, and the VA ratings of an unseen word were predicted by taking as input its similarity to the seeds.", "labels": [], "entities": [{"text": "VA", "start_pos": 56, "end_pos": 58, "type": "METRIC", "confidence": 0.997235119342804}, {"text": "VA", "start_pos": 117, "end_pos": 119, "type": "METRIC", "confidence": 0.9950927495956421}]}, {"text": "In addition, for the kernel method, the linear similarity function was chosen because it yielded top performance.", "labels": [], "entities": []}, {"text": "Both graph-based methods used an iterative procedure for VA prediction and required no training.", "labels": [], "entities": [{"text": "VA prediction", "start_pos": 57, "end_pos": 70, "type": "TASK", "confidence": 0.9248938858509064}]}, {"text": "For pagerank, the iterative procedure was implemented using the algorithm presented in (, which estimates the VA ratings of an unseen word by assigning an equal weight to the edges connected to its neighbor seeds.", "labels": [], "entities": [{"text": "VA", "start_pos": 110, "end_pos": 112, "type": "METRIC", "confidence": 0.9847166538238525}]}, {"text": "For the proposed method, the iterative procedure was implemented by considering the word similarity as weights.", "labels": [], "entities": []}, {"text": "Iterative Results of the Graph-based Methods.", "labels": [], "entities": []}, {"text": "uses RMSE as an example to show the iterative results of the pagerank and proposed methods.", "labels": [], "entities": [{"text": "RMSE", "start_pos": 5, "end_pos": 9, "type": "DATASET", "confidence": 0.7696429491043091}]}, {"text": "The results show that the performance of both methods stabilized after around 10 iterations, indicating its efficiency for VA prediction.", "labels": [], "entities": [{"text": "VA prediction", "start_pos": 123, "end_pos": 136, "type": "TASK", "confidence": 0.9553729891777039}]}, {"text": "Another observation is that the ultimate converging result of each word is unrelated to the decay factor and the initial random assignment.", "labels": [], "entities": []}, {"text": "compares the results of the regression-based methods (Linear Regression and Kernel) and graph-based methods (PageRank and Weighted Graph).", "labels": [], "entities": []}, {"text": "The performance of PageRank and Weighted Graph was taken from results of the 50th iteration.", "labels": [], "entities": [{"text": "PageRank", "start_pos": 19, "end_pos": 27, "type": "DATASET", "confidence": 0.9374526739120483}]}, {"text": "The results show that both graph-based methods outperformed the regression-based methods for all metrics.", "labels": [], "entities": []}, {"text": "For the graph-based methods, the proposed Weighted Graph yielded better MAPE performance than PageRank (around 4%), Kernel (around 8%) and Linear Regression (around 7%) on both the ANEW and CAW corpora.", "labels": [], "entities": [{"text": "MAPE", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.7953248023986816}, {"text": "ANEW and CAW corpora", "start_pos": 181, "end_pos": 201, "type": "DATASET", "confidence": 0.7197213843464851}]}, {"text": "The weighted graph model achieved better performance because it predicted VA ratings by considering both the relations of multiple nodes and the weights between them.", "labels": [], "entities": [{"text": "VA", "start_pos": 74, "end_pos": 76, "type": "METRIC", "confidence": 0.9866940975189209}]}, {"text": "For the regressionbased methods, both Linear Regression and Kernel achieved similar results.", "labels": [], "entities": []}, {"text": "Another observation is that the arousal prediction error is greater than that for the valence prediction, indicating that the arousal dimension is more difficult to predict.", "labels": [], "entities": [{"text": "valence prediction", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.6405642181634903}]}], "tableCaptions": [{"text": " Table 1. Comparative results of different methods in VA prediction.", "labels": [], "entities": [{"text": "VA prediction", "start_pos": 54, "end_pos": 67, "type": "TASK", "confidence": 0.9890366196632385}]}]}