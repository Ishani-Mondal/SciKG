{"title": [{"text": "I do not disagree: Leveraging monolingual alignment to detect disagreement in dialogue", "labels": [], "entities": []}], "abstractContent": [{"text": "A wide array of natural dialogue discourse can be found on the internet.", "labels": [], "entities": []}, {"text": "Previous attempts to automatically determine disagreement between interlocutors in such dialogue have mostly relied on n-gram and grammatical dependency features taken from respondent text.", "labels": [], "entities": []}, {"text": "Agreement-disagreement classifiers built upon these baseline features tend to do poorly, yet have proven difficult to improve upon.", "labels": [], "entities": []}, {"text": "Using the Internet Argument Corpus, which comprises quote and response post pairs taken from an online debate forum with human-annotated agreement scoring, we introduce semantic environment features derived by comparing quote and response sentences which align well.", "labels": [], "entities": [{"text": "Internet Argument Corpus", "start_pos": 10, "end_pos": 34, "type": "DATASET", "confidence": 0.7105021675427755}]}, {"text": "We show that this method improves classifier accuracy relative to the baseline method namely in the retrieval of disagreeing pairs, which improves from 69% to 77%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9534016251564026}]}], "introductionContent": [{"text": "To achieve robust text understanding, natural language processing systems need to automatically extract information that is expressed indirectly.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.7494304478168488}]}, {"text": "Here we focus on identifying agreement and disagreement in online debate posts.", "labels": [], "entities": [{"text": "identifying agreement and disagreement in online debate posts", "start_pos": 17, "end_pos": 78, "type": "TASK", "confidence": 0.6210901476442814}]}, {"text": "Previous work on this task has used very shallow linguistic analysis: features are surface-level ones, such as ngrams, post initial unigrams, bigrams and trigrams (which aim at learning the discourse functions of discourse markers, e.g., well, really, you know), repeated sequential use of punctuation signs (e.g., !!, ?!).", "labels": [], "entities": []}, {"text": "When automatically detecting (dis)agreement, these features fall short, reaching around 65% accuracy on a balanced dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9989380240440369}]}, {"text": "Adding extra-linguistic features, such as the structure of the post threads and stance of the post's author on other subjects, boosts performance to 75%.", "labels": [], "entities": []}, {"text": "In this work, we leverage richer linguistic models to increase performance.", "labels": [], "entities": []}, {"text": "In example (1) in, the response-initial bigram I agree is a strong cue of agreement that surface features can learn, but there are more complex examples that surface features cannot capture.", "labels": [], "entities": []}, {"text": "In example (2), the response-initial word Yes is not indicating agreement, despite being in general a good cue for it.", "labels": [], "entities": []}, {"text": "Instead it is necessary to capture the polarity mismatch between the first sentence in the quote and the first sentence in the response (God doesn't takeaway sinful desires vs. Yes, God does takeaway sinful desires) to infer that the response disagrees with the quote.", "labels": [], "entities": []}, {"text": "There may also be mismatches of modality, as demonstrated in the third example (saw vs. may have believed).", "labels": [], "entities": []}, {"text": "Here we also see an example of an explicit agreement word which is negated (that does not make it true) in away that most surface features fail to capture.", "labels": [], "entities": []}, {"text": "Some discourse-level parsing () has been utilized in agreement detection, but most previous work does not take discourse structure into account: the response post is simply taken as a whole as the reply to the quote.", "labels": [], "entities": [{"text": "discourse-level parsing", "start_pos": 5, "end_pos": 28, "type": "TASK", "confidence": 0.66963991522789}, {"text": "agreement detection", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.9084677994251251}]}, {"text": "To overcome this issue, we take advantage of the considerable progress in monolingual alignment (e.g.,) which allows us to align sentences of the quote to sentences in the response.", "labels": [], "entities": []}, {"text": "This approach is reminiscent of the one used for Recognizing Textual Entailment (RTE,) where, given two short passages, systems identify whether the second passage follows from the first one according to the intuitions of an intelligent human reader.", "labels": [], "entities": [{"text": "Recognizing Textual Entailment (RTE", "start_pos": 49, "end_pos": 84, "type": "TASK", "confidence": 0.7718037068843842}]}, {"text": "One common approach used in RTE was to align the two passages, and reason based on the alignment obtained.", "labels": [], "entities": [{"text": "RTE", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9793741703033447}]}, {"text": "2 God doesn't takeaway sinful desires.", "labels": [], "entities": []}, {"text": "You've never had sinful desires?", "labels": [], "entities": []}, {"text": "People assume that when you become a Christian some manner of shield gets put up around you and shields you from \"worldly\" things.", "labels": [], "entities": []}, {"text": "I believe that's wrong, I actually believe that life as a Christian is very hard.", "labels": [], "entities": []}, {"text": "We often pawn it off as the end of our troubles to \"convert\" people.", "labels": [], "entities": []}, {"text": "I don't believe it.", "labels": [], "entities": []}, {"text": "Yes, God does takeaway sinful desires.", "labels": [], "entities": []}, {"text": "(If you ask Him.)", "labels": [], "entities": []}, {"text": "I'm not saying that it doesn't take any work on your part, though.", "labels": [], "entities": []}, {"text": "When you have a sinful desire, you allow a thought to become more than just astray idea.", "labels": [], "entities": []}, {"text": "You foster and encourage the thought and it becomes a desire.", "labels": [], "entities": []}, {"text": "God takes away the desires, helps you deal with your \"stray thoughts\", and shows you how to keep them from becoming desires.", "labels": [], "entities": []}, {"text": "-1.7 3 Your idea about science is a philosophy of science.", "labels": [], "entities": []}, {"text": "The Apostles saw Jesus walk on water.", "labels": [], "entities": []}, {"text": "There was no 'measure' by your version of science, but what they saw remains true.", "labels": [], "entities": []}, {"text": "Many people once believed that the earth is flat: perhaps some still do.", "labels": [], "entities": []}, {"text": "The apostles may have believed that Jesus walked on water: that does NOT make it true.", "labels": [], "entities": []}, {"text": "-2 4 does life end here?", "labels": [], "entities": []}, {"text": "if \"here\" = \"death\", then yes! by definition, yes!", "labels": [], "entities": []}, {"text": "-1.4 5 Is even 'channel' sufficiently ateleological a verb?", "labels": [], "entities": []}, {"text": "It describes an action without ascribing its form to its end result, outcome, whatever but strictly to a cause's force's inaction.", "labels": [], "entities": []}, {"text": "But since it is understood that mechanical forces can also 'channel', unintentional, out of simple mechanics, the word channel cannot be called teleological.", "labels": [], "entities": []}, {"text": "In the same way, 'sorting' can be considered non-teleological, hence mechanical, and thus suited to your glossary, because things can be sorted by mechanical forces alone.", "labels": [], "entities": []}, {"text": "2.8: QR pairs from the Internet Argument Corpus.", "labels": [], "entities": [{"text": "Internet Argument Corpus", "start_pos": 23, "end_pos": 47, "type": "DATASET", "confidence": 0.6629361708958944}]}, {"text": "Here, similarly, once we have identified sentences in the response which align well with sentences in the quote, it becomes easier to extract deep semantic features such as polarity and modality mismatch between sentences as well as embeddings under modality, negation, or attitude verbs.", "labels": [], "entities": []}, {"text": "For instance, in example (2) in, the first sentence in the quote gets aligned with high probability to the first sentence in the response, which enables us to identify the polarity mismatch (doesn't vs. does).", "labels": [], "entities": []}, {"text": "In example (3), the italicized sentences are the most well-aligned, enabling us to identify that the response's author embeds under modality the event of Jesus walking on water and thus does not take it as a fact, whereas the quote's author does take it as a fact.", "labels": [], "entities": []}, {"text": "Our experiments demonstrate that our linguistic model based on alignment significantly outperforms a baseline bag-of-words model in the recall of disagreeing quote-response (QR) pairs.", "labels": [], "entities": []}, {"text": "Such linguistic models will transfer more easily to any debate dialogue, independent of the structural information of post threads and author's stance which might not always be recoverable.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Category counts in the training set.", "labels": [], "entities": []}, {"text": " Table 3: Accuracy, precision (P), recall (R) and F1 scores for both categories (agreement and disagree- ment) on the test set.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9995724558830261}, {"text": "precision (P)", "start_pos": 20, "end_pos": 33, "type": "METRIC", "confidence": 0.9553057700395584}, {"text": "recall (R)", "start_pos": 35, "end_pos": 45, "type": "METRIC", "confidence": 0.9640967547893524}, {"text": "F1", "start_pos": 50, "end_pos": 52, "type": "METRIC", "confidence": 0.9994524121284485}]}]}