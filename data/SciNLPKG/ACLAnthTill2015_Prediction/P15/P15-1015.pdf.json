{"title": [{"text": "Learning Dynamic Feature Selection for Fast Sequential Prediction", "labels": [], "entities": [{"text": "Sequential Prediction", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.6578575372695923}]}], "abstractContent": [{"text": "We present paired learning and inference algorithms for significantly reducing computation and increasing speed of the vector dot products in the classifiers that are at the heart of many NLP components.", "labels": [], "entities": []}, {"text": "This is accomplished by partitioning the features into a sequence of templates which are ordered such that high confidence can often be reached using only a small fraction of all features.", "labels": [], "entities": []}, {"text": "Parameter estimation is arranged to maximize accuracy and early confidence in this sequence.", "labels": [], "entities": [{"text": "Parameter estimation", "start_pos": 0, "end_pos": 20, "type": "METRIC", "confidence": 0.8102810084819794}, {"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9994175434112549}, {"text": "early confidence", "start_pos": 58, "end_pos": 74, "type": "METRIC", "confidence": 0.9254082441329956}]}, {"text": "Our approach is simpler and better suited to NLP than other related cascade methods.", "labels": [], "entities": []}, {"text": "We present experiments in left-to-right part-of-speech tagging, named entity recognition, and transition-based dependency parsing.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.7138374745845795}, {"text": "named entity recognition", "start_pos": 64, "end_pos": 88, "type": "TASK", "confidence": 0.6675817966461182}, {"text": "transition-based dependency parsing", "start_pos": 94, "end_pos": 129, "type": "TASK", "confidence": 0.6028376619021097}]}, {"text": "On the typical benchmarking datasets we can preserve POS tagging accuracy above 97% and parsing LAS above 88.5% both with over a five-fold reduction in run-time, and NER F1 above 88 with more than 2x increase in speed.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 53, "end_pos": 64, "type": "TASK", "confidence": 0.6510998159646988}, {"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9528270959854126}, {"text": "parsing", "start_pos": 88, "end_pos": 95, "type": "TASK", "confidence": 0.9500526785850525}, {"text": "LAS", "start_pos": 96, "end_pos": 99, "type": "METRIC", "confidence": 0.6126997470855713}, {"text": "NER F1", "start_pos": 166, "end_pos": 172, "type": "METRIC", "confidence": 0.7570822834968567}]}], "introductionContent": [{"text": "Many NLP tasks such as part-of-speech tagging, parsing and named entity recognition have become sufficiently accurate that they are no longer solely an object of research, but are also widely deployed in production systems.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.7006537765264511}, {"text": "parsing", "start_pos": 47, "end_pos": 54, "type": "TASK", "confidence": 0.9574522972106934}, {"text": "named entity recognition", "start_pos": 59, "end_pos": 83, "type": "TASK", "confidence": 0.6411468585332235}]}, {"text": "These systems can be run on billions of documents, making the efficiency of inference a significant concern-impacting not only wall-clock running time but also computer hardware budgets and the carbon footprint of data centers.", "labels": [], "entities": []}, {"text": "This paper describes a paired learning and inference approach for significantly reducing computation and increasing speed while preserving accuracy in the linear classifiers typically used in many NLP tasks.", "labels": [], "entities": [{"text": "speed", "start_pos": 116, "end_pos": 121, "type": "METRIC", "confidence": 0.9774301052093506}, {"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9982611536979675}]}, {"text": "The heart of the prediction computation in these models is a dot-product between a dense parameter vector and a sparse feature vector.", "labels": [], "entities": []}, {"text": "The bottleneck in these models is then often a combination of feature extraction and numerical operations, each of which scale linearly in the size of the feature vector.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.7284157276153564}]}, {"text": "Feature extraction can be even more expensive than the dot products, involving, for example, walking sub-graphs, lexicon lookup, string concatenation and string hashing.", "labels": [], "entities": [{"text": "Feature extraction", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7923822104930878}]}, {"text": "We note, however, that in many cases not all of these features are necessary for accurate prediction.", "labels": [], "entities": [{"text": "accurate prediction", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.5578452199697495}]}, {"text": "For example, in part-of-speech tagging if we seethe word \"the,\" there is no need to perform a large dot product or many string operations; we can accurately label the word a DETERMINER using the word identity feature alone.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 16, "end_pos": 38, "type": "TASK", "confidence": 0.718800276517868}, {"text": "DETERMINER", "start_pos": 174, "end_pos": 184, "type": "METRIC", "confidence": 0.9792525172233582}]}, {"text": "In other cases two features are sufficient: when we seethe word \"hits\" preceded by a CARDINAL (e.g. \"two hits\") we can be confident that it is a NOUN.", "labels": [], "entities": [{"text": "CARDINAL", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9789272546768188}]}, {"text": "We present a simple yet novel approach to improve processing speed by dynamically determining on a per-instance basis how many features are necessary fora high-confidence prediction.", "labels": [], "entities": []}, {"text": "Our features are divided into a set of feature templates, such as current-token or previous-tag in the case of POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 111, "end_pos": 122, "type": "TASK", "confidence": 0.6052391529083252}]}, {"text": "At training time, we determine an ordering on the templates such that we can approximate model scores attest time by incrementally calculating the dot product in template ordering.", "labels": [], "entities": []}, {"text": "We then use a running confidence estimate for the label prediction to determine how many terms of the sum to compute fora given instance, and predict once confidence reaches a certain threshold.", "labels": [], "entities": [{"text": "label prediction", "start_pos": 50, "end_pos": 66, "type": "TASK", "confidence": 0.7070761173963547}]}, {"text": "In similar work, cascades of increasingly complex and high-recall models have been used for both structured and unstructured prediction.", "labels": [], "entities": []}, {"text": "use a cascade of boosted models to perform face detection.", "labels": [], "entities": [{"text": "face detection", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.8732852339744568}]}, {"text": "add increasingly higher-order dependencies to a graphical model while filtering the out-put domain to maintain tractable inference.", "labels": [], "entities": []}, {"text": "While most traditional cascades pass instances down to layers with increasingly higher recall, we use a single model and accumulate the scores from each additional template until a label is predicted with sufficient confidence, in a stagewise approximation of the full model score.", "labels": [], "entities": [{"text": "recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9982004165649414}]}, {"text": "Our technique applies to any linear classifier-based model over feature templates without changing the model structure or decreasing prediction speed.", "labels": [], "entities": []}, {"text": "Most similarly to our work, improve performance for several structured vision tasks by dynamically selecting features at runtime.", "labels": [], "entities": []}, {"text": "However, they use a reinforcement learning approach whose computational tradeoffs are better suited to vision problems with expensive features.", "labels": [], "entities": []}, {"text": "Obtaining a speedup on tasks with comparatively cheap features, such as part-of-speech tagging or transition-based parsing, requires an approach with less overhead.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.7054040729999542}, {"text": "transition-based parsing", "start_pos": 98, "end_pos": 122, "type": "TASK", "confidence": 0.5703986883163452}]}, {"text": "In fact, the most attractive aspect of our approach is that it speeds up methods that are already among the fastest in NLP.", "labels": [], "entities": []}, {"text": "We apply our method to left-to-right part-ofspeech tagging in which we achieve accuracy above 97% on the Penn Treebank WSJ corpus while running more than five times faster than our 97.2% baseline.", "labels": [], "entities": [{"text": "part-ofspeech tagging", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.6350038796663284}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9993917942047119}, {"text": "Penn Treebank WSJ corpus", "start_pos": 105, "end_pos": 129, "type": "DATASET", "confidence": 0.9812469929456711}]}, {"text": "We also achieve a five-fold increase in transition-based dependency parsing on the WSJ corpus while achieving an LAS just 1.5% lower than our 90.3% baseline.", "labels": [], "entities": [{"text": "transition-based dependency parsing", "start_pos": 40, "end_pos": 75, "type": "TASK", "confidence": 0.6059311131636301}, {"text": "WSJ corpus", "start_pos": 83, "end_pos": 93, "type": "DATASET", "confidence": 0.8668331503868103}, {"text": "LAS", "start_pos": 113, "end_pos": 116, "type": "METRIC", "confidence": 0.9981271624565125}]}, {"text": "Named entity recognition also shows significant speed increases.", "labels": [], "entities": [{"text": "Named entity recognition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7710022926330566}, {"text": "speed", "start_pos": 48, "end_pos": 53, "type": "METRIC", "confidence": 0.9698804020881653}]}, {"text": "We further demonstrate that our method can be tuned for 2.5 \ud97b\udf59 3.5x multiplicative speedups with nearly no loss inaccuracy.", "labels": [], "entities": []}], "datasetContent": [{"text": "We present experiments on three NLP tasks for which greedy sequence labeling has been a successful solution: part-of-speech tagging, transition-based dependency parsing and named entity recognition.", "labels": [], "entities": [{"text": "greedy sequence labeling", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.6516133944193522}, {"text": "part-of-speech tagging", "start_pos": 109, "end_pos": 131, "type": "TASK", "confidence": 0.8024529218673706}, {"text": "transition-based dependency parsing", "start_pos": 133, "end_pos": 168, "type": "TASK", "confidence": 0.5957740048567454}, {"text": "named entity recognition", "start_pos": 173, "end_pos": 197, "type": "TASK", "confidence": 0.6657089193662008}]}, {"text": "In all cases our method achieves multiplicative speedups attest time with little loss inaccuracy.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of our models using differ- ent margins m, with speeds measured relative to  the baseline. We train a model as accurate as the  baseline while tagging 3.4x tokens/sec, and in an- other model maintain > 97% accuracy while tag- ging 5.2x, and > 96% accuracy with a speedup of  10.3x.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 227, "end_pos": 235, "type": "METRIC", "confidence": 0.9973247051239014}, {"text": "accuracy", "start_pos": 268, "end_pos": 276, "type": "METRIC", "confidence": 0.9991471767425537}]}, {"text": " Table 2: Comparison of our baseline and tem- plated models using varying margins m and num- bers of templates.", "labels": [], "entities": []}, {"text": " Table 3: Comparison of our baseline and tem- plated NER models using varying margin m and  number of templates.", "labels": [], "entities": []}]}