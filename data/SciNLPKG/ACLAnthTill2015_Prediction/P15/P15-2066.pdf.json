{"title": [{"text": "Painless Labeling with Application to Text Mining", "labels": [], "entities": [{"text": "Painless Labeling", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.5489697903394699}]}], "abstractContent": [{"text": "Labeled data is not readily available for many natural language domains, and it typically requires expensive human effort with considerable domain knowledge to produce a set of labeled data.", "labels": [], "entities": []}, {"text": "In this paper, we propose a simple unsupervised system that helps us create a labeled resource for categorical data (e.g., a document set) using only fifteen minutes of human input.", "labels": [], "entities": []}, {"text": "We utilize the labeled resources to discover important insights about the data.", "labels": [], "entities": []}, {"text": "The entire process is domain independent, and demands no prior annotation samples, or rules specific to an annotation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Consider the following two scenarios: Scenario 1: We start processing anew language and we want to get an initial idea of the language before embarking on the expensive process of creating hand annotated resources.", "labels": [], "entities": []}, {"text": "For instance, we may want to know how people express opinion in a language of interest, what characterizes the subjective content of the language and how expressions of opinion differ along opinion types.", "labels": [], "entities": []}, {"text": "The question is how to acquire such first-hand insights of an unknown language in quick time and with minimal human effort?", "labels": [], "entities": []}, {"text": "Scenario 2: We have a set of blog articles and we are interested in learning how blogging differs across gender.", "labels": [], "entities": []}, {"text": "In particular, we seek to learn the writing styles or other indicative patterns -topics of interest, word choices etc.", "labels": [], "entities": []}, {"text": "-that can potentially distinguish writings across gender.", "labels": [], "entities": []}, {"text": "A traditional NLP approach would be to collect a set of articles that are tagged with gender information, which we can then input to a learning system to learn patterns that can differentiate gender.", "labels": [], "entities": []}, {"text": "What if no such annotation is available, as the bloggers don't reveal their gender information?", "labels": [], "entities": []}, {"text": "Could we arrange a human annotation task to annotate the articles along gender?", "labels": [], "entities": []}, {"text": "Often the articles contain explicit patterns (e.g., \"my boyfriend\", \"as a woman\" etc.) which help the annotators to annotate the articles.", "labels": [], "entities": []}, {"text": "Often there are no indicative patterns in the written text, and it becomes impossible to annotate the articles reliably.", "labels": [], "entities": []}, {"text": "The above scenarios depict the cases when we are resource constrained and creating anew resource is nontrivial and time consuming.", "labels": [], "entities": []}, {"text": "Given such difficulties, it would be helpful if we could design a system that requires less human input to create a labeled resource.", "labels": [], "entities": []}, {"text": "In this paper, we present a simple unsupervised system that helps us create a labeled resource with minimal human effort.", "labels": [], "entities": []}, {"text": "The key to our method is that instead of labeling the entire set of unlabeled instances the system labels a subset of data instances for which it is confident to achieve high level of accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 184, "end_pos": 192, "type": "METRIC", "confidence": 0.9942680597305298}]}, {"text": "We experiment with several document labeling tasks and show that a high-quality labeled resource can be produced by a clustering-based labeling system that requires a mere fifteen minutes of human input.", "labels": [], "entities": []}, {"text": "It achieves 85% and 78% accuracy for the task of sentiment and gender classification, showing its effectiveness on two nontrivial labeling tasks with distinct characteristics (see Section 3).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9991844296455383}, {"text": "sentiment and gender classification", "start_pos": 49, "end_pos": 84, "type": "TASK", "confidence": 0.6535954847931862}]}, {"text": "We also utilize the labeled resources created by our system to learn discriminative patterns that help us gain insights into a dataset.", "labels": [], "entities": []}, {"text": "For instance, we learn how users generally express opinion in a language of interest, and how writing varies across gender.", "labels": [], "entities": []}, {"text": "The next section describes the details of our main algorithm.", "labels": [], "entities": []}, {"text": "We present experimental results in Section 3 and 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use three text classification tasks for evaluation: Gender Classification: Here we classify blog articles according to whether an article is written by a male or female.", "labels": [], "entities": [{"text": "text classification", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7430843114852905}, {"text": "Gender Classification", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.7207415252923965}]}, {"text": "We employ the blog dataset as introduced by for this task.", "labels": [], "entities": []}, {"text": "The dataset contains 19320 blog articles, out of which we randomly selected 5000 blog articles as our dataset.", "labels": [], "entities": []}, {"text": "Spam Classification: Here the goal is to determine whether an email is Spam or Ham (i.e., not spam).", "labels": [], "entities": [{"text": "Spam Classification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8031743466854095}]}, {"text": "We use the Enron spam dataset as introduced by  To preprocess a document, we first tokenize and downcase it, remove stop words, and represent it as a vector of unigrams, using frequency as presence.", "labels": [], "entities": [{"text": "Enron spam dataset", "start_pos": 11, "end_pos": 29, "type": "DATASET", "confidence": 0.8844103217124939}]}, {"text": "For spectral clustering, we use dot product as a measure of similarity between two documents vectors.: Description of the datasets.", "labels": [], "entities": [{"text": "spectral clustering", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.753641277551651}]}], "tableCaptions": [{"text": " Table 2: Accuracy of automatically labeled data for each dataset. We also report 5-fold supervised  classification result for each dataset.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9908159971237183}]}, {"text": " Table 3: Description of the datasets.", "labels": [], "entities": []}]}