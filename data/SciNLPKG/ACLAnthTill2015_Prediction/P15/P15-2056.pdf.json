{"title": [{"text": "Learning to Mine Query Subtopics from Query Log", "labels": [], "entities": []}], "abstractContent": [{"text": "Many queries in web search are ambiguous or multifaceted.", "labels": [], "entities": []}, {"text": "Identifying the major senses or facets of queries is very important for web search.", "labels": [], "entities": [{"text": "Identifying the major senses or facets of queries", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.7543546035885811}]}, {"text": "In this paper, we represent the major senses or facets of queries as subtopics and refer to indentifying senses or facets of queries as query subtopic mining, where query subtop-ic are represented as a number of clusters of queries.", "labels": [], "entities": []}, {"text": "Then the challenges of query subtopic mining are how to measure the similarity between queries and group them semantically.", "labels": [], "entities": [{"text": "query subtopic mining", "start_pos": 23, "end_pos": 44, "type": "TASK", "confidence": 0.7420005599657694}]}, {"text": "This paper proposes an approach for mining subtopics from query log, which jointly learns a similarity measure and groups queries by explicitly modeling the structure among them.", "labels": [], "entities": []}, {"text": "Compared with previous approaches using manually defined similarity measures, our approach produces more desirable query subtop-ics by learning a similarity measure.", "labels": [], "entities": []}, {"text": "Experimental results on real queries collected from a search engine log confirm the effectiveness of the proposed approach in mining query sub-topics.", "labels": [], "entities": []}], "introductionContent": [{"text": "Understanding the search intents of queries is essential for satisfying users' information needs and is very important for many search tasks such as personalized search, query suggestion, and search result presentation.", "labels": [], "entities": [{"text": "search result presentation", "start_pos": 192, "end_pos": 218, "type": "TASK", "confidence": 0.6084060768286387}]}, {"text": "However, it is not a trivial task because the underlying intents of the same query maybe different for different users.", "labels": [], "entities": []}, {"text": "Two well-known types of such queries are ambiguous queries and multifaceted queries.", "labels": [], "entities": []}, {"text": "For example, the ambiguous query 'michael jordon' may refer to a basketball player or a professor of statistics in Berkeley.", "labels": [], "entities": []}, {"text": "The multifaceted query 'harry potter' may refer to different search intents such as films, books, or games and soon.", "labels": [], "entities": []}, {"text": "Many approaches have been proposed to identify the search intents of a query which are represented by search goals, topics, or subtopics.", "labels": [], "entities": []}, {"text": "For example, classified query intents into three search goals: informational, navigational, and transactional. and represented query intents by topics.", "labels": [], "entities": []}, {"text": "represented query intents by subtopics which denote different senses or multiple facets of queries.", "labels": [], "entities": []}, {"text": "Previous work on query subtopic mining is mostly based on clustering framework by manually defining a similarity measure with few factors.", "labels": [], "entities": [{"text": "query subtopic mining", "start_pos": 17, "end_pos": 38, "type": "TASK", "confidence": 0.7131824890772501}]}, {"text": "employed an agglomerative clustering algorithm with a similarity measure combining string similarities, click similarities, and keyword similarities linearly.", "labels": [], "entities": []}, {"text": "applied affinity propagation algorithm) with a sense-based similarity.", "labels": [], "entities": [{"text": "affinity propagation", "start_pos": 8, "end_pos": 28, "type": "TASK", "confidence": 0.6974923610687256}]}, {"text": "used a hierarchical clustering algorithm with the similarity measure based on search results.", "labels": [], "entities": []}, {"text": "In this paper, we argue that the similarity between queries is affected by many different factors and it could produce more desirable query subtopics by learning a similarity measure.", "labels": [], "entities": []}, {"text": "To learn a similarity measure for query subtopic mining, a natural approach is to use a binary classifier, that is, the classifier targets pairs of queries and makes predictions about whether they belong to the same subtopic.", "labels": [], "entities": [{"text": "query subtopic mining", "start_pos": 34, "end_pos": 55, "type": "TASK", "confidence": 0.6724275350570679}]}, {"text": "However, because such pairwise classifiers assume that pairs are independent, they might make inconsistent predictions: e.g., predicting queries qi and qj, qj and qk to belong to the same subtopic, but qi and qk to belong to different subtopics.", "labels": [], "entities": []}, {"text": "For example, given three queries, 'luxury car', 'sport car' and 'XJ sport', for the query 'jaguar', a lexiconsimilarity-based classifier is easy to learn that 'luxury car' and 'sport car', and 'sport car' and 'XJ sport' belong to the same subtopic; but difficult to learn that 'luxury car' and 'XJ sport' belong to the same subtopic.", "labels": [], "entities": []}, {"text": "From this example, we can see that a learner should exploit these transitive dependencies among queries to learn a more effective similarity measure.", "labels": [], "entities": []}, {"text": "Hence, in this paper, our first contribution is that we learn a similarity measure by explicitly modeling the dependencies among queries in the same subtopic.", "labels": [], "entities": []}, {"text": "The second contribution is that we analyze the performance of the proposed approach with different dependencies among queries.", "labels": [], "entities": []}, {"text": "The third contribution is that we conduct experiments on real-world data and the experimental results confirm the effectiveness of the proposed approach in mining query subtopics.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the performance of our approach, we employ the measures in (), which are computed as follows, where R ' is the predicted partition and R is the ground-truth partition; \u03c0(A, B) is a similarity measure between set A and B, which is Jaccard coefficient in this paper; and g(.) is the optimal mapping between R ' and R. Based on p and r, fmeasure can be calculated as, The higher the f-measure score is, the better performance an approach achieves.", "labels": [], "entities": []}, {"text": "We used the following approaches as baselines: \uf0b7 K-means: we perform the standard k-means clustering algorithm with different manually defined similarity measures to mine query subtopics.", "labels": [], "entities": []}, {"text": "COS, JAC, EUC, EDIT refer to cosine similarity, Jaccard similarity, Euclidean distance, and edit distance, respectively.", "labels": [], "entities": [{"text": "COS", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.4804978370666504}, {"text": "JAC", "start_pos": 5, "end_pos": 8, "type": "METRIC", "confidence": 0.6199378371238708}, {"text": "EUC", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.5169486403465271}, {"text": "EDIT", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.9466844797134399}, {"text": "cosine similarity", "start_pos": 29, "end_pos": 46, "type": "METRIC", "confidence": 0.7268669605255127}, {"text": "Jaccard similarity", "start_pos": 48, "end_pos": 66, "type": "METRIC", "confidence": 0.695739209651947}, {"text": "Euclidean distance", "start_pos": 68, "end_pos": 86, "type": "METRIC", "confidence": 0.8992303907871246}, {"text": "edit distance", "start_pos": 92, "end_pos": 105, "type": "METRIC", "confidence": 0.8984628319740295}]}, {"text": "\uf0b7 Binary Classification Cluster with the allconnection structure (BCC-AC): BCC-AC uses a SVM classifier to learn the weight wand clusters with correlation clustering method.", "labels": [], "entities": []}, {"text": "\uf0b7 Binary Classification Cluster with the strongconnection structure (BCC-SC): BCC-SC uses a SVM classifier to learn the weight wand clusters with the method presented in Algorithm 1.", "labels": [], "entities": []}, {"text": "For the proposed methods, we denote the method with the all-connection structure as AC and the method with the strong-connection structure as SC.", "labels": [], "entities": []}, {"text": "The parameter C in Eq. is picked from10 -2 to 10 4 using a 10-fold cross validation procedure.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: the features and their weights learned by  the different methods.", "labels": [], "entities": []}]}