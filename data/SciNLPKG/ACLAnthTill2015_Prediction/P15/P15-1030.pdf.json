{"title": [], "abstractContent": [{"text": "This paper describes a parsing model that combines the exact dynamic programming of CRF parsing with the rich nonlinear fea-turization of neural net approaches.", "labels": [], "entities": [{"text": "parsing", "start_pos": 23, "end_pos": 30, "type": "TASK", "confidence": 0.9793114066123962}, {"text": "CRF parsing", "start_pos": 84, "end_pos": 95, "type": "TASK", "confidence": 0.7920387089252472}]}, {"text": "Our model is structurally a CRF that factors over anchored rule productions, but instead of linear potential functions based on sparse features, we use nonlinear potentials computed via a feedforward neu-ral network.", "labels": [], "entities": []}, {"text": "Because potentials are still local to anchored rules, structured inference (CKY) is unchanged from the sparse case.", "labels": [], "entities": []}, {"text": "Computing gradients during learning involves backpropagating an error signal formed from standard CRF sufficient statistics (expected rule counts).", "labels": [], "entities": []}, {"text": "Using only dense features, our neural CRF already exceeds a strong baseline CRF model (Hall et al., 2014).", "labels": [], "entities": []}, {"text": "In combination with sparse features, our system 1 achieves 91.1 F 1 on section 23 of the Penn Tree-bank, and more generally outperforms the best prior single parser results on a range of languages.", "labels": [], "entities": [{"text": "91.1 F 1", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.8255008061726888}, {"text": "Penn Tree-bank", "start_pos": 89, "end_pos": 103, "type": "DATASET", "confidence": 0.9945450723171234}]}], "introductionContent": [{"text": "Neural network-based approaches to structured NLP tasks have both strengths and weaknesses when compared to more conventional models, such conditional random fields (CRFs).", "labels": [], "entities": []}, {"text": "A key strength of neural approaches is their ability to learn nonlinear interactions between underlying features.", "labels": [], "entities": []}, {"text": "In the case of unstructured output spaces, this capability has led to gains in problems ranging from syntax () to lexical semantics.", "labels": [], "entities": []}, {"text": "Neural methods are also powerful tools in the case of structured System available at http://nlp.cs.berkeley.edu output spaces.", "labels": [], "entities": []}, {"text": "Here, past work has often relied on recurrent architectures), which can propagate information through structure via realvalued hidden state, but as a result do not admit efficient dynamic programming).", "labels": [], "entities": []}, {"text": "However, there is a natural marriage of nonlinear induced features and efficient structured inference, as explored by for the case of sequence modeling: feedforward neural networks can be used to score local decisions which are then \"reconciled\" in a discrete structured modeling framework, allowing inference via dynamic programming.", "labels": [], "entities": [{"text": "sequence modeling", "start_pos": 134, "end_pos": 151, "type": "TASK", "confidence": 0.7146705240011215}]}, {"text": "In this work, we present a CRF constituency parser based on these principles, where individual anchored rule productions are scored based on nonlinear features computed with a feedforward neural network.", "labels": [], "entities": [{"text": "CRF constituency parser", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.7410161892573038}]}, {"text": "A separate, identicallyparameterized replicate of the network exists for each possible span and split point.", "labels": [], "entities": []}, {"text": "As input, it takes vector representations of words at the split point and span boundaries; it then outputs scores for anchored rules applied to that span and split point.", "labels": [], "entities": []}, {"text": "These scores can bethought of as nonlinear potentials analogous to linear potentials in conventional CRFs.", "labels": [], "entities": []}, {"text": "Crucially, while the network replicates are connected in a unified model, their computations factor along the same substructures as in standard CRFs.", "labels": [], "entities": []}, {"text": "Prior work on parsing using neural network models has often sidestepped the problem of structured inference by making sequential decisions or by doing reranking; by contrast, our framework permits exact inference via CKY, since the model's structured interactions are purely discrete and do not involve continuous hidden state.", "labels": [], "entities": [{"text": "parsing", "start_pos": 14, "end_pos": 21, "type": "TASK", "confidence": 0.9664000868797302}]}, {"text": "Therefore, we can exploit a neural net's capacity to learn nonlinear features without modifying Figure 1: Neural CRF model.", "labels": [], "entities": []}, {"text": "On the right, each anchored rule (r, s) in the tree is independently scored by a function \u03c6, so we can perform inference with CKY to compute marginals or the Viterbi tree.", "labels": [], "entities": [{"text": "Viterbi tree", "start_pos": 158, "end_pos": 170, "type": "DATASET", "confidence": 0.9035866260528564}]}, {"text": "On the left, we show the process for scoring an anchored rule with neural features: words inf w (see) are embedded, then fed through a neural network with one hidden layer to compute dense intermediate features, whose conjunctions with sparse rule indicator features f o are scored according to parameters W . our core inference mechanism, allowing us to use tricks like coarse pruning that make inference efficient in the purely sparse model.", "labels": [], "entities": []}, {"text": "Our model can be trained by gradient descent exactly as in a conventional CRF, with the gradient of the network parameters naturally computed by backpropagating a difference of expected anchored rule counts through the network for each span and split point.", "labels": [], "entities": []}, {"text": "Using dense learned features alone, the neural CRF model obtains high performance, outperforming the CRF parser of.", "labels": [], "entities": []}, {"text": "When sparse indicators are used in addition, the resulting model gets 91.1 F 1 on section 23 of the Penn Treebank, outperforming the parser of as well as the Berkeley Parser ( and matching the discriminative parser of . The model also obtains the best single parser results on nine other languages, again outperforming the system of. shows our neural CRF model.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 100, "end_pos": 113, "type": "DATASET", "confidence": 0.9789219796657562}]}, {"text": "The model decomposes over anchored rules, and it scores each of these with a potential function; in a standard CRF, these potentials are typically linear functions of sparse indicator features, whereas reflected the flip side of the Stoltzman personality .", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results of our sparse CRF, neural CRF,  and combined parsing models on section 22 of  the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 100, "end_pos": 113, "type": "DATASET", "confidence": 0.9735245108604431}]}, {"text": " Table 2: Exploration of other implementation  choices in the feedforward neural network on sen- tences of length \u2264 40 from section 22 of the Penn  Treebank. Rectified linear units perform better  than tanh or cubic units, a network with one hid- den layer performs best, and embedding the output  feature vector gives worse performance.", "labels": [], "entities": [{"text": "Penn  Treebank", "start_pos": 142, "end_pos": 156, "type": "DATASET", "confidence": 0.9966093599796295}]}, {"text": " Table 3: Results for the nine treebanks in the SPMRL 2013/2014 Shared Tasks; all values are F-scores  for sentences of all lengths using the version of evalb distributed with the shared task. Our parser  substantially outperforms the strongest single parser results on this dataset (Hall et al., 2014; Crabb\u00e9 and  Seddah, 2014). Berkeley-Tags is an improved version of the Berkeley parser designed for the shared task  (Seddah et al., 2013). 2014 Best is a reranked ensemble of modified Berkeley parsers and constitutes the  best published numbers on this dataset (", "labels": [], "entities": [{"text": "SPMRL 2013/2014 Shared Tasks", "start_pos": 48, "end_pos": 76, "type": "TASK", "confidence": 0.5614031553268433}]}]}