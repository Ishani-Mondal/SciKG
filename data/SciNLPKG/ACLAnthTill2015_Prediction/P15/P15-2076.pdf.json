{"title": [], "abstractContent": [{"text": "Data-driven representation learning for words is a technique of central importance in NLP.", "labels": [], "entities": [{"text": "Data-driven representation learning", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7165963351726532}]}, {"text": "While indisputably useful as a source of features in downstream tasks, such vectors tend to consist of uninter-pretable components whose relationship to the categories of traditional lexical semantic theories is tenuous at best.", "labels": [], "entities": []}, {"text": "We present a method for constructing interpretable word vectors from hand-crafted linguistic resources like WordNet, FrameNet etc.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 108, "end_pos": 115, "type": "DATASET", "confidence": 0.9640265107154846}]}, {"text": "These vectors are binary (i.e, contain only 0 and 1) and are 99.9% sparse.", "labels": [], "entities": []}, {"text": "We analyze their performance on state-of-the-art evaluation methods for distributional models of word vectors and find they are competitive to standard distributional approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "Distributed representations of words have been shown to benefit a diverse set of NLP tasks including syntactic parsing (), named entity recognition () and sentiment analysis.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 101, "end_pos": 118, "type": "TASK", "confidence": 0.728130578994751}, {"text": "named entity recognition", "start_pos": 123, "end_pos": 147, "type": "TASK", "confidence": 0.6057155032952627}, {"text": "sentiment analysis", "start_pos": 155, "end_pos": 173, "type": "TASK", "confidence": 0.9576165676116943}]}, {"text": "Additionally, because they can be induced directly from unannotated corpora, they are likewise available in domains and languages where traditional linguistic resources do not exhaust.", "labels": [], "entities": []}, {"text": "Intrinsic evaluations on various tasks are helping refine vector learning methods to discover representations that captures many facts about lexical semantics).", "labels": [], "entities": []}, {"text": "Yet induced word vectors do not look anything like the representations described inmost lexical semantic theories, which focus on identifying classes of words.", "labels": [], "entities": []}, {"text": "Though expensive to construct, conceptualizing word meanings symbolically is important for theoretical understanding and interpretability is desired in computational models.", "labels": [], "entities": []}, {"text": "Our contribution to this discussion is anew technique that constructs task-independent word vector representations using linguistic knowledge derived from pre-constructed linguistic resources like WordNet, FrameNet (), Penn Treebank ( etc.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 197, "end_pos": 204, "type": "DATASET", "confidence": 0.9607694745063782}, {"text": "Penn Treebank", "start_pos": 219, "end_pos": 232, "type": "DATASET", "confidence": 0.9897731244564056}]}, {"text": "In such word vectors every dimension is a linguistic feature and 1/0 indicates the presence or absence of that feature in a word, thus the vector representations are binary while being highly sparse (\u2248 99.9%).", "labels": [], "entities": []}, {"text": "Since these vectors do not encode any word cooccurrence information, they are non-distributional.", "labels": [], "entities": []}, {"text": "An additional benefit of constructing such vectors is that they are fully interpretable i.e, every dimension of these vectors maps to a linguistic feature unlike distributional word vectors where the vector dimensions have no interpretability.", "labels": [], "entities": []}, {"text": "Of course, engineering feature vectors from linguistic resources is established practice in many applications of discriminative learning; e.g., parsing ( or part of speech tagging).", "labels": [], "entities": [{"text": "parsing", "start_pos": 144, "end_pos": 151, "type": "TASK", "confidence": 0.9786237478256226}, {"text": "speech tagging", "start_pos": 165, "end_pos": 179, "type": "TASK", "confidence": 0.6535817384719849}]}, {"text": "However, despite a certain common inventories of features that re-appear across many tasks, feature engineering tends to be seen as a task-specific problem, and engineered feature vectors are not typically evaluated independently of the tasks they are designed for.", "labels": [], "entities": []}, {"text": "We evaluate the quality of our linguistic vectors on a number of tasks that have been proposed for evaluating distributional word vectors.", "labels": [], "entities": []}, {"text": "We show that linguistic word vectors are comparable to current state-ofthe-art distributional word vectors trained on billions of words as evaluated on a battery of semantic and syntactic evaluation benchmarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "We first briefly describe the evaluation tasks and then present results.", "labels": [], "entities": []}, {"text": "We evaluate our word representations on three different benchmarks to measure word similarity.", "labels": [], "entities": []}, {"text": "The first one is the widely used WS-353 dataset (), which contains 353 pairs of English words that have been assigned similarity ratings by humans.", "labels": [], "entities": [{"text": "WS-353 dataset", "start_pos": 33, "end_pos": 47, "type": "DATASET", "confidence": 0.9348907470703125}]}, {"text": "The second is the RG-65 dataset of 65 words pairs.", "labels": [], "entities": [{"text": "RG-65 dataset", "start_pos": 18, "end_pos": 31, "type": "DATASET", "confidence": 0.9034371674060822}]}, {"text": "The third dataset is SimLex () which has been constructed to overcome the shortcomings of WS-353 and contains 999 pairs of adjectives, nouns and verbs.", "labels": [], "entities": [{"text": "WS-353", "start_pos": 90, "end_pos": 96, "type": "DATASET", "confidence": 0.9027308821678162}]}, {"text": "Word similarity is computed using cosine similarity between two words and Spearman's rank correlation is reported between the rankings produced by vector model against the human rankings.", "labels": [], "entities": []}, {"text": "created a treebank containing sentences annotated with fine-grained sentiment labels on phrases and sentences from movie review excerpts.", "labels": [], "entities": []}, {"text": "The coarse-grained treebank of positive and negative classes has been split into training, development, and test datasets containing 6,920, 872, and 1,821 sentences, respectively.", "labels": [], "entities": []}, {"text": "We use average of the word vectors of a given sentence as features in an 2 -regularized logistic regression for classification.", "labels": [], "entities": []}, {"text": "The classifier is tuned on the dev set and accuracy is reported on the test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9995834231376648}]}, {"text": "constructed a dataset from the Penn TreeBank of noun phrases (NP) of length three words, where the first can bean adjective or a noun and the other two are nouns.", "labels": [], "entities": [{"text": "Penn TreeBank", "start_pos": 31, "end_pos": 44, "type": "DATASET", "confidence": 0.9920974671840668}]}, {"text": "The task is to predict the correct bracketing in the parse tree fora given noun phrase.", "labels": [], "entities": []}, {"text": "For example, local (phone company) and (blood pressure) medicine exhibit left and right bracketing respectively.", "labels": [], "entities": []}, {"text": "We append the word vectors of the three words in the NP in order and use them as features in an 2 -regularized logistic regression classifier.", "labels": [], "entities": []}, {"text": "The dataset contains 2,227 noun phrases split into 10 folds.", "labels": [], "entities": []}, {"text": "The classifier is tuned on the first fold and cross-validation accuracy is reported on the remaining nine folds.: Performance of different type of word vectors on evaluation tasks reported by Spearman's correlation (first 3 columns) and Accuracy (last 2 columns).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.8239958882331848}, {"text": "Spearman's correlation", "start_pos": 192, "end_pos": 214, "type": "METRIC", "confidence": 0.5202920039494833}, {"text": "Accuracy", "start_pos": 237, "end_pos": 245, "type": "METRIC", "confidence": 0.9994339346885681}]}, {"text": "Bold shows the best performance fora task.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Sizes of vocabualry and features induced  from different linguistic resources.", "labels": [], "entities": []}, {"text": " Table 3: Performance of different type of word vectors on evaluation tasks reported by Spearman's  correlation (first 3 columns) and Accuracy (last 2 columns). Bold shows the best performance for a task.", "labels": [], "entities": [{"text": "Spearman's  correlation", "start_pos": 88, "end_pos": 111, "type": "METRIC", "confidence": 0.5221874713897705}, {"text": "Accuracy", "start_pos": 134, "end_pos": 142, "type": "METRIC", "confidence": 0.9995291233062744}]}]}