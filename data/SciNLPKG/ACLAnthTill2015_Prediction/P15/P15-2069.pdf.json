{"title": [{"text": "TR9856: A Multi-word Term Relatedness Benchmark", "labels": [], "entities": [{"text": "Multi-word Term Relatedness Benchmark", "start_pos": 10, "end_pos": 47, "type": "TASK", "confidence": 0.7195805013179779}]}], "abstractContent": [{"text": "Measuring word relatedness is an important ingredient of many NLP applications.", "labels": [], "entities": [{"text": "word relatedness", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.7026656717061996}]}, {"text": "Several datasets have been developed in order to evaluate such measures.", "labels": [], "entities": []}, {"text": "The main drawback of existing datasets is the focus on single words, although natural language contains a large proportion of multi-word terms.", "labels": [], "entities": []}, {"text": "We propose the new TR9856 dataset which focuses on multi-word terms and is significantly larger than existing datasets.", "labels": [], "entities": [{"text": "TR9856 dataset", "start_pos": 19, "end_pos": 33, "type": "DATASET", "confidence": 0.9319896399974823}]}, {"text": "The new dataset includes many real world terms such as acronyms and named entities, and further handles term ambiguity by providing topical context for all term pairs.", "labels": [], "entities": []}, {"text": "We report baseline results for common relatedness methods over the new data, and exploit its magnitude to demonstrate that a combination of these methods outperforms each individual method.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many NLP applications share the need to determine whether two terms are semantically related, or to quantify their degree of \"relatedness\".", "labels": [], "entities": []}, {"text": "Developing methods to automatically quantify term relatedness naturally requires benchmark data of term pairs with corresponding human relatedness scores.", "labels": [], "entities": []}, {"text": "Here, we propose a novel benchmark data for term relatedness, that addresses several challenges which have not been addressed by previously available data.", "labels": [], "entities": [{"text": "term relatedness", "start_pos": 44, "end_pos": 60, "type": "TASK", "confidence": 0.7104189395904541}]}, {"text": "The new benchmark data is the first to consider relatedness between multiword terms, allowing to gain better insights regarding the performance of relatedness assessment methods when considering such terms.", "labels": [], "entities": []}, {"text": "Second, in contrast to most previous data, the new data provides a context for each pair of terms, allowing to disambiguate terms as needed.", "labels": [], "entities": []}, {"text": "Third, we use a simple systematic process to ensure that the constructed data is enriched with \"related\" pairs, beyond what one would expect to obtain by random sampling.", "labels": [], "entities": []}, {"text": "In contrast to previous work, our enrichment process does not rely on a particular relatedness algorithm or resource such as Wordnet, hence the constructed data is less biased in favor of a specific method.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 125, "end_pos": 132, "type": "DATASET", "confidence": 0.9670146107673645}]}, {"text": "Finally, the new data triples the size of the largest previously available data, consisting of 9, 856 pairs of terms.", "labels": [], "entities": []}, {"text": "Correspondingly, it is denoted henceforth as TR9856.", "labels": [], "entities": [{"text": "TR9856", "start_pos": 45, "end_pos": 51, "type": "DATASET", "confidence": 0.5845845341682434}]}, {"text": "Each term pair was annotated by 10 human annotators, answering a binary questionrelated/unrelated.", "labels": [], "entities": []}, {"text": "The relatedness score is given as the mean answer of annotators where related = 1 and unrelated = 0.", "labels": [], "entities": []}, {"text": "We report various consistency measures that indicate the validity of TR9856.", "labels": [], "entities": [{"text": "consistency", "start_pos": 18, "end_pos": 29, "type": "METRIC", "confidence": 0.9906784296035767}, {"text": "validity", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9966216087341309}, {"text": "TR9856", "start_pos": 69, "end_pos": 75, "type": "METRIC", "confidence": 0.5809010863304138}]}, {"text": "In addition, we report baseline results over TR9856 for several methods, commonly used to assess termrelatedness.", "labels": [], "entities": [{"text": "TR9856", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.4772404432296753}]}, {"text": "Furthermore, we demonstrate how the new data can be exploited to train an ensemblebased method, that relies on these methods as underlying features.", "labels": [], "entities": []}, {"text": "We believe that the new TR9856 benchmark, which is freely available for research purposes, 1 along with the reported results, will contribute to the development of novel term relatedness methods.", "labels": [], "entities": [{"text": "TR9856 benchmark", "start_pos": 24, "end_pos": 40, "type": "DATASET", "confidence": 0.6293152272701263}]}], "datasetContent": [{"text": "In constructing the TR9856 data we aimed to address the following issues: (i) include terms that involve more than a single word; (ii) disambiguate terms, as needed; (iii) have a relatively high fraction of \"related\" term pairs; (iv) focus on terms that are relatively common as opposed to esoteric terms; (v) generate a relatively large benchmark data.", "labels": [], "entities": [{"text": "TR9856 data", "start_pos": 20, "end_pos": 31, "type": "DATASET", "confidence": 0.9294287264347076}]}, {"text": "To achieve these goals we defined and followed a systematic and reproducible protocol, which is described next.", "labels": [], "entities": []}, {"text": "The complete details are included in the data release notes.", "labels": [], "entities": []}, {"text": "Previous experiments on WS353 and other datasets reported Spearman Correlation (\u03c1) between the algorithm predicted scores and the ground-truth relatedness scores.", "labels": [], "entities": [{"text": "WS353", "start_pos": 24, "end_pos": 29, "type": "DATASET", "confidence": 0.9328439831733704}, {"text": "Spearman Correlation (\u03c1)", "start_pos": 58, "end_pos": 82, "type": "METRIC", "confidence": 0.9749529957771301}]}, {"text": "Here, we also report Pearson Correlation (r) results and demonstrate that the top performing algorithm becomes the worst performing algorithm when switching between these two correlation measures.", "labels": [], "entities": [{"text": "Pearson Correlation (r)", "start_pos": 21, "end_pos": 44, "type": "METRIC", "confidence": 0.9444371104240418}]}, {"text": "In addition, we note that a correlation measure gives equal weight to all pairs in the dataset.", "labels": [], "entities": [{"text": "correlation", "start_pos": 28, "end_pos": 39, "type": "METRIC", "confidence": 0.9505980014801025}]}, {"text": "However, in some NLP applications it is more important to properly distinguish related pairs from unrelated ones.", "labels": [], "entities": []}, {"text": "Correspondingly, we also report results when considering the problem as a binary classification problem, aiming to distinguish pairs with a relatedness score \u2265 0.8 from pairs with a relatedness score \u2264 0.2.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Baseline results for common methods.", "labels": [], "entities": []}, {"text": " Table 3: Mean results over 10-fold cross valida- tion.", "labels": [], "entities": []}, {"text": " Table 4. Ex- cept for the Pearson correlation results of ESA, for  all methods we observe lower performance over  the MWP subset, suggesting that assessing term- relatedness is indeed more difficult when MWTs  are involved.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 27, "end_pos": 46, "type": "METRIC", "confidence": 0.8541254103183746}, {"text": "ESA", "start_pos": 58, "end_pos": 61, "type": "DATASET", "confidence": 0.7905676960945129}]}, {"text": " Table 4: Baseline results for SWP vs. MWP.", "labels": [], "entities": [{"text": "SWP", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.8593378663063049}]}, {"text": " Table 5: Binary classification results.", "labels": [], "entities": [{"text": "Binary classification", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.9870384931564331}]}]}