{"title": [{"text": "Non-projective Dependency-based Pre-Reordering with Recurrent Neural Network for Machine Translation", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 81, "end_pos": 100, "type": "TASK", "confidence": 0.7383321821689606}]}], "abstractContent": [{"text": "The quality of statistical machine translation performed with phrase based approaches can be increased by permuting the words in the source sentences in an order which resembles that of the target language.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 15, "end_pos": 46, "type": "TASK", "confidence": 0.6302607158819834}]}, {"text": "We propose a class of recurrent neu-ral models which exploit source-side dependency syntax features to reorder the words into a target-like order.", "labels": [], "entities": []}, {"text": "We evaluate these models on the German-to-English and Italian-to-English language pairs, showing significant improvements over a phrase-based Moses baseline.", "labels": [], "entities": []}, {"text": "We also compare with state of the art German-to-English pre-reordering rules, showing that our method obtains similar or better results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical machine translation is typically performed using phrase-based systems ().", "labels": [], "entities": [{"text": "Statistical machine translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7411190470059713}]}, {"text": "These systems can usually produce accurate local reordering but they have difficulties dealing with the long-distance reordering that tends to occur between certain language pairs ().", "labels": [], "entities": []}, {"text": "The quality of phrase-based machine translation can be improved by reordering the words in each sentence of source-side of the parallel training corpus in a \"target-like\" order and then applying the same transformation as a pre-processing step to input strings during execution.", "labels": [], "entities": [{"text": "phrase-based machine translation", "start_pos": 15, "end_pos": 47, "type": "TASK", "confidence": 0.6292305688063303}]}, {"text": "When the source-side sentences can be accurately parsed, pre-reordering can be performed using hand-coded rules.", "labels": [], "entities": []}, {"text": "This approach has been successfully applied to German-to-English () and other languages.", "labels": [], "entities": []}, {"text": "The main issue with it is that these rules must be designed for each specific language pair, which requires considerable linguistic expertise.", "labels": [], "entities": []}, {"text": "Fully statistical approaches, on the other hand, learn the reordering relation from word alignments.", "labels": [], "entities": []}, {"text": "Some of them learn reordering rules on the constituency) () or projective dependency,) parse trees of source sentences.", "labels": [], "entities": []}, {"text": "The permutations that these methods can learn can be generally non-local (i.e. high distance) on the sentences but local (parent-child or sibling-sibling swaps) on the parse trees.", "labels": [], "entities": []}, {"text": "Moreover, constituency or projective dependency trees may not be the ideal way of representing the syntax of nonanalytic languages such as German or Italian, which could be better described using non-projective dependency trees ().", "labels": [], "entities": []}, {"text": "Other methods, based on recasting reordering as a combinatorial optimization problem,, can learn to generate in principle arbitrary permutations, but they can only make use of minimal syntactic information (part-of-speech tags) and therefore can't exploit the potentially valuable structural syntactic information provided by a parser.", "labels": [], "entities": []}, {"text": "In this work we propose a class of reordering models which attempt to close this gap by exploiting rich dependency syntax features and at the same time being able to process non-projective dependency parse trees and generate permutations which maybe nonlocal both on the sentences and on the parse trees.", "labels": [], "entities": []}, {"text": "We represent these problems as sequence prediction machine learning tasks, which we address using recurrent neural networks.", "labels": [], "entities": [{"text": "sequence prediction machine learning tasks", "start_pos": 31, "end_pos": 73, "type": "TASK", "confidence": 0.8335415005683899}]}, {"text": "We applied our model to reorder German sentences into an English-like word order as a pre-processing step for phrase-based machine translation, obtaining significant improvements over the unreordered baseline system and quality comparable to the handcoded rules introduced by.", "labels": [], "entities": [{"text": "phrase-based machine translation", "start_pos": 110, "end_pos": 142, "type": "TASK", "confidence": 0.6456781625747681}]}, {"text": "We also applied our model to Italianto-English pre-reordering, obtaining a considerable improvement over the unreordered baseline.", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed German-to-English prereordering experiments with Base RNN-RM (both unlexicalized and lexicalized), Fragment RNN-RM and Base GRU-RM.", "labels": [], "entities": []}, {"text": "In order to validate the experimental results on a different language pair, we additionally performed an Italian-to-English prereordering experiment with the Base GRU-RM, after assessing that this was the model that obtained the largest improvement on German-to-English.", "labels": [], "entities": []}], "tableCaptions": []}