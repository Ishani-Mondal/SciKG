{"title": [{"text": "Transferring Coreference Resolvers with Posterior Regularization", "labels": [], "entities": [{"text": "Transferring Coreference Resolvers", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.9223694403966268}, {"text": "Regularization", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.3746255934238434}]}], "abstractContent": [{"text": "We propose a cross-lingual framework for learning coreference resolvers for resource-poor target languages, given a re-solver in a source language.", "labels": [], "entities": [{"text": "coreference resolvers", "start_pos": 50, "end_pos": 71, "type": "TASK", "confidence": 0.7015393823385239}]}, {"text": "Our method uses word-aligned bitext to project information from the source to the target.", "labels": [], "entities": []}, {"text": "To handle task-specific costs, we propose a softmax-margin variant of posterior regu-larization, and we use it to achieve robust-ness to projection errors.", "labels": [], "entities": []}, {"text": "We show empirically that this strategy outperforms competitive cross-lingual methods, such as delexicalized transfer with bilingual word embeddings, bitext direct projection, and vanilla posterior regularization.", "labels": [], "entities": [{"text": "bitext direct projection", "start_pos": 149, "end_pos": 173, "type": "TASK", "confidence": 0.5760253568490347}]}], "introductionContent": [{"text": "The goal of coreference resolution is to find the mentions in text that refer to the same discourse entity.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.9615153670310974}]}, {"text": "While early work focused primarily on English (), efforts have been made toward multilingual systems, this being addressed in recent shared tasks.", "labels": [], "entities": []}, {"text": "However, the lack of annotated data hinders rapid system deployment for new languages.", "labels": [], "entities": []}, {"text": "Unsupervised methods ( and rule-based approaches ( avoid this data annotation bottleneck, but they often require complex generative models or expert linguistic knowledge.", "labels": [], "entities": []}, {"text": "We propose cross-lingual coreference resolution as away of transferring information from a rich-resource language to build coreference resolvers for languages with scarcer resources; as a testbed, we transfer from English to Spanish and to Brazilian Portuguese.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.8067261576652527}, {"text": "coreference resolvers", "start_pos": 123, "end_pos": 144, "type": "TASK", "confidence": 0.7611095011234283}]}, {"text": "We build upon the recent successes of cross-lingual learning in NLP, which proved quite effective in several structured prediction tasks, such as POS tagging), named entity recognition (), dependency parsing), semantic role labeling, and fine-grained opinion mining (.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 146, "end_pos": 157, "type": "TASK", "confidence": 0.7859680652618408}, {"text": "named entity recognition", "start_pos": 160, "end_pos": 184, "type": "TASK", "confidence": 0.610912432273229}, {"text": "dependency parsing", "start_pos": 189, "end_pos": 207, "type": "TASK", "confidence": 0.7835544049739838}, {"text": "semantic role labeling", "start_pos": 210, "end_pos": 232, "type": "TASK", "confidence": 0.7103788256645203}, {"text": "opinion mining", "start_pos": 251, "end_pos": 265, "type": "TASK", "confidence": 0.7079232186079025}]}, {"text": "The potential of these techniques, however, has never been fully exploited in coreference resolution (despite some existing work, reviewed in \u00a76, but none resulting in an endto-end coreference resolver).", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.9791450500488281}, {"text": "coreference resolver", "start_pos": 181, "end_pos": 201, "type": "TASK", "confidence": 0.7503280937671661}]}, {"text": "We bridge this gap by proposing a simple learning-based method with weak supervision, based on posterior regularization ().", "labels": [], "entities": []}, {"text": "We adapt this framework to handle softmax-margin objective functions (, leading to softmax-margin posterior regularization ( \u00a74).", "labels": [], "entities": []}, {"text": "This step, while fairly simple, opens the door for incorporating taskspecific cost functions, which are important to manage the precision/recall trade-offs in coreference resolution systems.", "labels": [], "entities": [{"text": "precision", "start_pos": 128, "end_pos": 137, "type": "METRIC", "confidence": 0.9896700978279114}, {"text": "recall", "start_pos": 138, "end_pos": 144, "type": "METRIC", "confidence": 0.7891247272491455}, {"text": "coreference resolution", "start_pos": 159, "end_pos": 181, "type": "TASK", "confidence": 0.9174484610557556}]}, {"text": "We show that the resulting problem involves optimizing the difference of two cost-augmented log-partition functions, making abridge with supervised systems based on latent coreference trees, reviewed in \u00a73.", "labels": [], "entities": []}, {"text": "Inspired by this idea, we consider a simple penalized variant of posterior regularization that tunes the Lagrange multipliers directly, bypassing the saddle-point problem of existing EM and alternating stochastic gradient algorithms (.", "labels": [], "entities": []}, {"text": "show that the proposed method outperforms commonly used cross-lingual approaches, such as delexicalized transfer with bilingual embeddings, direct projection, and \"vanilla\" posterior regularization.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our methodology, outlined as Algorithm 1, is inspired by the recent work of on cross-lingual learning of sequence models.", "labels": [], "entities": []}, {"text": "For simplicity, we call the source and tar-: Excerpt of a bitext document with automatic coreference annotations (from FAPESP).", "labels": [], "entities": [{"text": "FAPESP", "start_pos": 119, "end_pos": 125, "type": "DATASET", "confidence": 0.9349454045295715}]}, {"text": "The English side had its coreferences resolved by a state-of-the-art system . The predicted coreference chains {The pulmonary alveoli, the alveoli, their} and {The pulmonary surfactant} are then projected to the Portuguese side, via word alignments.", "labels": [], "entities": []}, {"text": "We now present experiments using the setup in \u00a72.", "labels": [], "entities": []}, {"text": "We compare our coreference resolvers trained with softmax-margin PR ( \u00a75.5) with three other weakly-supervised baselines: delexicalized transfer with cross-lingual embeddings ( \u00a75.2), bitext projection ( \u00a75.3), and vanilla PR ( \u00a75.4).", "labels": [], "entities": [{"text": "coreference resolvers", "start_pos": 15, "end_pos": 36, "type": "TASK", "confidence": 0.838164210319519}]}, {"text": "We also run fully supervised systems ( \u00a75.1), to obtain upper bounds for the level of performance we expect to achieve with the weakly-supervised systems.", "labels": [], "entities": []}, {"text": "An important step in coreference resolution systems is mention prediction.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.9624676406383514}, {"text": "mention prediction", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.8000890612602234}]}, {"text": "For English, mention spans were predicted from the noun phrases given by the Berkeley parser (, the same procedure as . For Spanish and Portuguese, this prediction relied on the output of the dependency parser, using a simple heuristic: besides pronouns, each maximal span formed by contiguous descendants of a noun becomes a candidate mention.", "labels": [], "entities": []}, {"text": "This heuristic is quite effective, as shown by. shows the performance of supervised systems for English, Spanish and Portuguese.", "labels": [], "entities": []}, {"text": "4 appended with an extra regularization term \u03b3 2 w 2 , by running 20 epochs of stochastic gradient descent (SGD; we set \u03b3 = 1.0 and selected the best epoch using the dev-set).", "labels": [], "entities": []}, {"text": "All lexicalized systems use the same features as the SUR-FACE model of , plus features for gender and number.", "labels": [], "entities": []}, {"text": "We collected a list of pronouns for all languages along with their gender, number, and person information.", "labels": [], "entities": []}, {"text": "For English, we trained on the WSJ portion of the OntoNotes dataset, and for Spanish and Portuguese we trained on the monolingual datasets described in \u00a72.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 31, "end_pos": 34, "type": "DATASET", "confidence": 0.7688113451004028}, {"text": "OntoNotes dataset", "start_pos": 50, "end_pos": 67, "type": "DATASET", "confidence": 0.8655487895011902}]}], "tableCaptions": [{"text": " Table 1: Corpus statistics. EN, ES, and PT denote English,  Spanish, and Portuguese, respectively.", "labels": [], "entities": [{"text": "EN", "start_pos": 29, "end_pos": 31, "type": "METRIC", "confidence": 0.7494396567344666}, {"text": "ES", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.7219047546386719}, {"text": "PT", "start_pos": 41, "end_pos": 43, "type": "METRIC", "confidence": 0.9938480257987976}]}, {"text": " Table 2: Results for the supervised systems. We show also the performance of delexicalized English systems, with and without  cross-lingual embeddings. Shown are MUC (Vilain et al., 1995), B 3 (Bagga and Baldwin, 1998), and CEAFe (Luo, 2005), as  well their averaged F1 scores, all computed using the reference implementation of the CoNLL scorer (Pradhan et al., 2014).", "labels": [], "entities": [{"text": "MUC", "start_pos": 163, "end_pos": 166, "type": "METRIC", "confidence": 0.6206316947937012}, {"text": "CEAFe", "start_pos": 225, "end_pos": 230, "type": "DATASET", "confidence": 0.5248430967330933}, {"text": "F1", "start_pos": 268, "end_pos": 270, "type": "METRIC", "confidence": 0.9943857192993164}, {"text": "CoNLL scorer", "start_pos": 334, "end_pos": 346, "type": "DATASET", "confidence": 0.7863011658191681}]}, {"text": " Table 3: Results for all the cross-lingual systems. Bold indicates the overall highest scores. As a lower bound, we show a simple  deterministic baseline that, for pronominal mentions, selects the closest non-pronominal antecedent, and, for non-pronominal  mentions, selects the closest non-pronominal mention that is a superstring of the current mention.", "labels": [], "entities": []}, {"text": " Table 4: Recall/precision scores for mention prediction,  MUC, B 3 and CEAFe, all computed in the Spanish dev set.", "labels": [], "entities": [{"text": "Recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9792615175247192}, {"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9598807692527771}, {"text": "mention prediction", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.7340980768203735}, {"text": "MUC", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.82982337474823}, {"text": "B 3", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9786534011363983}, {"text": "CEAFe", "start_pos": 72, "end_pos": 77, "type": "METRIC", "confidence": 0.942371129989624}, {"text": "Spanish dev set", "start_pos": 99, "end_pos": 114, "type": "DATASET", "confidence": 0.8995321790377299}]}]}