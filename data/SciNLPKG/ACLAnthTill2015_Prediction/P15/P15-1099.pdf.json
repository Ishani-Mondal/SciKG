{"title": [], "abstractContent": [{"text": "Central to many sentiment analysis tasks are sentiment lexicons (SLs).", "labels": [], "entities": [{"text": "sentiment analysis tasks", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.9116722146670023}, {"text": "sentiment lexicons (SLs)", "start_pos": 45, "end_pos": 69, "type": "TASK", "confidence": 0.6330224335193634}]}, {"text": "Previous work studied the problem of checking the consistency of an SL for the case when the entries have categorical labels (positive, negative or neutral) and showed that it is NP-hard.", "labels": [], "entities": [{"text": "consistency", "start_pos": 50, "end_pos": 61, "type": "METRIC", "confidence": 0.9691545367240906}]}, {"text": "In this paper, we address the more general problem, in which polarity tags take the form of a continuous distribution in the interval [0, 1].", "labels": [], "entities": []}, {"text": "We show that this problem is polynomial.", "labels": [], "entities": []}, {"text": "We develop a general framework for addressing the consistency problem using linear programming (LP) theory.", "labels": [], "entities": []}, {"text": "LP tools allow us to uncover inconsistencies efficiently, paving the way to building SL debugging tools.", "labels": [], "entities": []}, {"text": "We show that previous work corresponds to 0-1 integer programming, a particular case of LP.", "labels": [], "entities": []}, {"text": "Our experimental studies show a strong correlation between polarity consistency in SLs and the accuracy of sentiment tagging in practice.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9992456436157227}, {"text": "sentiment tagging", "start_pos": 107, "end_pos": 124, "type": "TASK", "confidence": 0.8879843354225159}]}], "introductionContent": [{"text": "Many sentiment analysis algorithms rely on sentiment lexicons (SLs), where word forms or word senses 1 are tagged as conveying positive, negative or neutral sentiments.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 5, "end_pos": 23, "type": "TASK", "confidence": 0.9428848028182983}]}, {"text": "SLs are constructed by one of three methods: (1) Manual tagging by human annotators is generally reliable, but because it is labor-intensive, slow, and costly, this method has produced small-sized SLs comprising a few thousand words, e.g., Opinion Finder (OF) (), Appraisal Lexicon (AL) (), General Inquirer (GI) (, and MicroWNOp (.", "labels": [], "entities": [{"text": "MicroWNOp", "start_pos": 320, "end_pos": 329, "type": "DATASET", "confidence": 0.9245052337646484}]}, {"text": "(2) Dictionary-based acquisition relies on a set of seed words to expand its coverage to similar words.", "labels": [], "entities": [{"text": "Dictionary-based acquisition", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.7498109340667725}]}, {"text": "There are over thirty dictionary-based techniques), most of them based on WordNet, such as SentiWordNet (SWN)( and Q-WordNet (QWN).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 74, "end_pos": 81, "type": "DATASET", "confidence": 0.9412223100662231}]}, {"text": "Corpus-based acquisition expands a set of seed words with the use of a large document corpus;.", "labels": [], "entities": [{"text": "Corpus-based acquisition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6992893666028976}]}, {"text": "Method (1) generally produces the most reliable annotations, however the considerable effort required to yield substantial lexicons makes it less useful in practice.", "labels": [], "entities": []}, {"text": "The appeals of (2) and (3) lie in the formalism of their models and their capability of producing large-sized SLs.", "labels": [], "entities": []}, {"text": "SLs are either word or sense/synset oriented.", "labels": [], "entities": []}, {"text": "We refer to the former as Sentiment Word Lexicons (SWLs), e.g., GI, OF, and AL, and to the latter as Sentiment Sense Lexions (SSLs), e.g., SWN, QWN, and Micro-WNOp.", "labels": [], "entities": []}, {"text": "Besides the method of compilation, SLs may also vary with regard to sentiment annotation.", "labels": [], "entities": [{"text": "sentiment annotation", "start_pos": 68, "end_pos": 88, "type": "TASK", "confidence": 0.812841385602951}]}, {"text": "Polarity disagreements are noted across SLs that do (SWN, Q-WordNet) and do not (AL, GI) reference WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 99, "end_pos": 106, "type": "DATASET", "confidence": 0.9355300664901733}]}, {"text": "For instance, the adjectives panicky and terrified, have negative and positive polarities in OF, respectively.", "labels": [], "entities": [{"text": "OF", "start_pos": 93, "end_pos": 95, "type": "METRIC", "confidence": 0.9974679946899414}]}, {"text": "They each have only one synset which they share in WordNet: \"thrown into a state of intense fear or desperation\".", "labels": [], "entities": [{"text": "WordNet", "start_pos": 51, "end_pos": 58, "type": "DATASET", "confidence": 0.9714730978012085}]}, {"text": "Assuming that there is an intrinsic re-lationship between the sentiments of a word and its meanings, a single synset polarity assignment to this synset cannot agree with both positive and negative at the word level.", "labels": [], "entities": []}, {"text": "If the information given in WordNet is accurate (the Oxford and Cambridge dictionaries give only this meaning for both words) then there must bean annotation inconsistency in OF, called a polarity inconsistency.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 28, "end_pos": 35, "type": "DATASET", "confidence": 0.9536672830581665}, {"text": "Oxford and Cambridge dictionaries", "start_pos": 53, "end_pos": 86, "type": "DATASET", "confidence": 0.8919545859098434}, {"text": "OF", "start_pos": 175, "end_pos": 177, "type": "METRIC", "confidence": 0.9574326872825623}]}, {"text": "While some inconsistencies are easy to detect, manual consistency checking of an entire SL is an impractical endeavor, primarily because of the sheer size (SWN has over 206,000 word-sense pairs).", "labels": [], "entities": []}, {"text": "Additionally, WordNet's complex network structure renders manual checking virtually impossible; an instance of a polarity inconsistency may entail an entire sub-network of words and senses.", "labels": [], "entities": []}, {"text": "In this paper we develop a rigorous formal method based on linear programming (LP) for polarity consistency checking of SLs with accompanying methods to unearth mislabeled words and synsets when consistency is not satisfied.", "labels": [], "entities": [{"text": "polarity consistency checking of SLs", "start_pos": 87, "end_pos": 123, "type": "TASK", "confidence": 0.7516538083553315}]}, {"text": "We translate the polarity consistency problem (PCP) into a form of the LP problem, suitable as the input to a standard LP solver, and utilize the functionality available in modern LP software (e.g., identifying an irreducible infeasible subset) to pinpoint the sources of inconsistencies when they occur.", "labels": [], "entities": [{"text": "polarity consistency problem (PCP)", "start_pos": 17, "end_pos": 51, "type": "TASK", "confidence": 0.5983405609925588}]}, {"text": "In our experimentation we are able to quickly uncover numerous intra-and inter-lexicon inconsistencies in all of the input SLs tested and to suggest lexicon entries fora linguist to focus on in \"debugging\" the lexicon.", "labels": [], "entities": []}], "datasetContent": [{"text": "The purpose of our experimental work is manifold, we show that: (1) inconsistencies exist in and between SLs, (2) our algorithm is effective at uncovering them in the various types of SLs proposed in the literature, (3) fractional polarity representation is more flexible than discrete, giving orders of magnitude fewer inconsistencies, and (4) sentiment analysis is significantly improved when the inconsistencies of a basis SL are corrected.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 345, "end_pos": 363, "type": "TASK", "confidence": 0.9360235631465912}]}, {"text": "Experiment Setup: We use four SWLs: GI, AL, OF and their union, denoted UN, and three SSLs: QWN, SWN and MicroWN-Op.", "labels": [], "entities": [{"text": "OF", "start_pos": 44, "end_pos": 46, "type": "METRIC", "confidence": 0.9507603645324707}, {"text": "MicroWN-Op", "start_pos": 105, "end_pos": 115, "type": "DATASET", "confidence": 0.8759075999259949}]}, {"text": "The distribution of their entries is given in.", "labels": [], "entities": []}, {"text": "The MAJORITY model (Equation 3) is used in all trials.", "labels": [], "entities": [{"text": "MAJORITY", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.8915310502052307}, {"text": "Equation", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.948635995388031}]}, {"text": "This allows for direct comparison with.", "labels": [], "entities": []}, {"text": "We implemented our algorithm in Java interfacing with the GUROBI LP solver 2 , and ran the tests on a 4 \u00d7 1.70GHz core computer with 6GB of main memory.", "labels": [], "entities": [{"text": "GUROBI LP solver 2", "start_pos": 58, "end_pos": 76, "type": "DATASET", "confidence": 0.8175956457853317}]}], "tableCaptions": [{"text": " Table 1: Counts of words/synsets in each SL", "labels": [], "entities": [{"text": "Counts", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9672068357467651}]}, {"text": " Table 3: SentiWordNet paired with SWLs", "labels": [], "entities": [{"text": "SWLs", "start_pos": 35, "end_pos": 39, "type": "TASK", "confidence": 0.41265782713890076}]}, {"text": " Table 5: Micro-WNOp -SWD Inconsistencies", "labels": [], "entities": []}]}