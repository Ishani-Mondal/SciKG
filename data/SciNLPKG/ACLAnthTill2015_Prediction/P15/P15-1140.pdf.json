{"title": [{"text": "KB-LDA: Jointly Learning a Knowledge Base of Hierarchy, Relations, and Facts", "labels": [], "entities": [{"text": "KB-LDA", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.7887222170829773}]}], "abstractContent": [{"text": "Many existing knowledge bases (KBs), including Freebase, Yago, and NELL, rely on a fixed ontology, given as an input to the system, which defines the data to be cataloged in the KB, i.e., a hierarchy of categories and relations between them.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 47, "end_pos": 55, "type": "DATASET", "confidence": 0.9713927507400513}, {"text": "Yago", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.7373083233833313}]}, {"text": "The system then extracts facts that match the predefined ontology.", "labels": [], "entities": []}, {"text": "We propose an unsupervised model that jointly learns a latent ontological structure of an input corpus, and identifies facts from the corpus that match the learned structure.", "labels": [], "entities": []}, {"text": "Our approach combines mixed membership stochastic block models and topic models to infer a structure by jointly mod-eling text, a latent concept hierarchy, and latent semantic relationships among the entities mentioned in the text.", "labels": [], "entities": []}, {"text": "As a case study, we apply the model to a corpus of Web documents from the software domain , and evaluate the accuracy of the various components of the learned ontology.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9991217255592346}]}], "introductionContent": [{"text": "Knowledge base (KB) construction methods can be broadly categorized along several dimensions.", "labels": [], "entities": [{"text": "Knowledge base (KB) construction", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6274741341670355}]}, {"text": "One dimension is ontology-guided construction, where the list of categories and relations that define the schema of the KB are explicit, versus open IE methods, where they are not.", "labels": [], "entities": [{"text": "ontology-guided construction", "start_pos": 17, "end_pos": 45, "type": "TASK", "confidence": 0.6908202618360519}]}, {"text": "Another dimension is the type of relations and types included in the KB: some KBs, like WordNet, are hierarchical, in that they contain mainly concept types, supertypes and instances, while other KBs contain many types of relationships between concepts.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 88, "end_pos": 95, "type": "DATASET", "confidence": 0.9432475566864014}]}, {"text": "Hierarchical knowledge can be learned by methods including distributional clustering (, as well as Hearst patterns and similar techniques ().", "labels": [], "entities": []}, {"text": "Reverb) and) are open methods for learning multirelation KBs.", "labels": [], "entities": [{"text": "Reverb", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9673736691474915}]}, {"text": "Finally, NELL, FreeBase (Google, 2011) and) are ontology-guided methods for extracting KBs containing both hierarchies and relations.", "labels": [], "entities": [{"text": "FreeBase (Google, 2011)", "start_pos": 15, "end_pos": 38, "type": "DATASET", "confidence": 0.8639783759911855}]}, {"text": "One advantage of ontology-guided methods is that the extracted knowledge is easier to reason with.", "labels": [], "entities": []}, {"text": "An advantage of open IE methods is that ontologies maybe incomplete, and are expensive to construct fora new domain.", "labels": [], "entities": []}, {"text": "Ontology design involves assembling a set of categories, organized in a meaningful hierarchical structure, often providing seeds, i.e., representative examples for each category, and finally, defining inter-category relations.", "labels": [], "entities": [{"text": "Ontology design", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8934958279132843}]}, {"text": "This process is often done manually) leading to a rigid set of categories.", "labels": [], "entities": []}, {"text": "Redesigning anew ontology fora specialized domain represents an additional challenge as it requires extensive knowledge of the domain.", "labels": [], "entities": []}, {"text": "In this paper, we propose an unsupervised model that learns a latent hierarchical structure of categories from an input corpus, learns latent semantic relations between categories, and also identifies facts from the corpus that match the learned structure.", "labels": [], "entities": []}, {"text": "In other words, the model learns both the schema fora KB, and a set of facts that are related to that schema, thus combining the processes of KB population and ontology construction.", "labels": [], "entities": [{"text": "ontology construction", "start_pos": 160, "end_pos": 181, "type": "TASK", "confidence": 0.7247448563575745}]}, {"text": "The intent is to build systems that extract facts which can be interpreted relative to a meaningful ontology without requiring the effort of manual ontology construction.", "labels": [], "entities": []}, {"text": "The input to the learning method is a corpus of documents, plus two sets of resources extracted from the same corpus: a set of hypernymhyponym pairs (e.g., \"animal\", \"horse\") extracted using Hearst patterns, and a set of subject-verbobject triples (e.g., \"horse\", \"eats\", \"hay\") extracted from parsed sentences.", "labels": [], "entities": []}, {"text": "These resources are analogous to the output of open IE systems for hierarchies and relations, and as we demonstrate, our method can be used to highlight domainspecific data from open IE repositories.", "labels": [], "entities": []}, {"text": "Our approach combines mixed membership stochastic block models and topic models to infer a structure by jointly modeling text documents, and links that indicate hierarchy and relation among the entities mentioned in the text.", "labels": [], "entities": []}, {"text": "Joint modeling allows information on topics of nouns (referred to as instances) and verbs (referred to as relations) to be shared between text documents and an ontological structure, resulting in a set of compelling topics.", "labels": [], "entities": []}, {"text": "This model offers a complete solution for KB construction based on an input corpus, and we therefore name it KB-LDA.", "labels": [], "entities": [{"text": "KB construction", "start_pos": 42, "end_pos": 57, "type": "TASK", "confidence": 0.9319992363452911}]}, {"text": "We additionally propose a method for recovering meaningful names for concepts in the learned hierarchy.", "labels": [], "entities": []}, {"text": "These are equivalent to category names in other KBs, however, following our method we extract from the data a set of potential alternative concepts describing each category, including probabilities for their strength of association.", "labels": [], "entities": []}, {"text": "To show the effectiveness of our method, we apply the model to a dataset of Web based documents from the software domain, and learn a software KB.", "labels": [], "entities": []}, {"text": "This is an example of a specialized domain in which, to our knowledge, no broad-coverage ontology exists.", "labels": [], "entities": []}, {"text": "We evaluate the model on the induced categories, relations, and facts, and we compare the proposed categories with an independent set of human-provided labels for documents.", "labels": [], "entities": []}, {"text": "Finally, we use KB-LDA to retrieve domain-specific relations from an open IE resource.", "labels": [], "entities": []}, {"text": "We provide the learned software KB as supplemental material.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the KB-LDA model on a corpus of 5.5M documents from the software domain; thereby we are using the model to construct a software domain knowledge base.", "labels": [], "entities": []}, {"text": "Our evaluation explores the following questions: \u2022 Can KB-LDA learn categories, relations, a hierarchy and topic concepts with high precision?", "labels": [], "entities": [{"text": "precision", "start_pos": 132, "end_pos": 141, "type": "METRIC", "confidence": 0.98142009973526}]}, {"text": "\u2022 How well do KB-LDA topics correspond with human-provided document labels?", "labels": [], "entities": []}, {"text": "\u2022 Is KB-LDA useful in extracting facts from existing open IE resources?", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Top 20 instance topics learned with KB-LDA. For each topic we show the top 2 concepts  recovered for the topic, and top 10 tokens. In italics are words marked as out-of-topic by expert labelers.", "labels": [], "entities": []}, {"text": " Table 4: Precision of topic concepts, relations, and subsumptions. For items extracted from the model  (KB-LDA), and randomly (Random), we show the number of items marked as correct, and precision in  parentheses (p), as labeled by 1, 2, or 3 non-expert workers, and the average precision by experts.", "labels": [], "entities": [{"text": "precision", "start_pos": 188, "end_pos": 197, "type": "METRIC", "confidence": 0.9993341565132141}, {"text": "precision", "start_pos": 280, "end_pos": 289, "type": "METRIC", "confidence": 0.9976024031639099}]}, {"text": " Table 6: Docs and Tag overlap of human-provided  tags with KB-LDA topics, and frequent tokens.", "labels": [], "entities": []}]}