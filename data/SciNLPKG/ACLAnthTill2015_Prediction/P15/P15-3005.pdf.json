{"title": [{"text": "Disease Event Detection based on Deep Modality Analysis", "labels": [], "entities": [{"text": "Disease Event Detection", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.5942230125268301}, {"text": "Deep Modality Analysis", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.6579659680525461}]}], "abstractContent": [{"text": "Social media has attracted attention because of its potential for extraction of information of various types.", "labels": [], "entities": []}, {"text": "For example , information collected from Twitter enables us to build useful applications such as predicting an epidemic of influenza.", "labels": [], "entities": [{"text": "predicting an epidemic of influenza", "start_pos": 97, "end_pos": 132, "type": "TASK", "confidence": 0.8578234672546386}]}, {"text": "However, using text information from social media poses challenges for event detection because of the unreliable nature of user-generated texts, which often include counter-factual statements.", "labels": [], "entities": [{"text": "event detection", "start_pos": 71, "end_pos": 86, "type": "TASK", "confidence": 0.758455902338028}]}, {"text": "Consequently, this study proposes the use of modality features to improve disease event detection from Twitter messages, or \"tweets\".", "labels": [], "entities": [{"text": "disease event detection from Twitter messages", "start_pos": 74, "end_pos": 119, "type": "TASK", "confidence": 0.7583855787913004}]}, {"text": "Experimental results demonstrate that the combination of a modality dictionary and a modality analyzer improves the F1-score by 3.5 points.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9989915490150452}]}], "introductionContent": [{"text": "The rapidly increasing popularity of Social Networking Services (SNSs) such as Twitter and Facebook has greatly eased the dissemination of information.", "labels": [], "entities": []}, {"text": "Such data can serve as a valuable information resource for various applications.", "labels": [], "entities": []}, {"text": "For instance, investigated actual linked structures of human networks, mapped out retweeting as a conversational practice, and detected earthquakes using SNSs.", "labels": [], "entities": []}, {"text": "An important and widespread application of SNS mining is in the public health field such as infection detection.", "labels": [], "entities": [{"text": "SNS mining", "start_pos": 43, "end_pos": 53, "type": "TASK", "confidence": 0.9889509975910187}, {"text": "infection detection", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.855522632598877}]}, {"text": "Among various infectious diseases, influenza is one of the most important diseases worldwide.", "labels": [], "entities": []}, {"text": "However, it is difficult to estimate the precise number of influenza-infected patients based on na\u00efve textual features because SNS messages that contain the word \"flu\" might not necessarily refer to being infected with influenza.", "labels": [], "entities": []}, {"text": "The following tweets are examples of such cases: (1) I might have the flu.", "labels": [], "entities": []}, {"text": "(2) If I had the flu, I would be forced to rest.", "labels": [], "entities": []}, {"text": "\"might\" in example (1) suggests that there is only a suspicion of having influenza.", "labels": [], "entities": [{"text": "might", "start_pos": 1, "end_pos": 6, "type": "METRIC", "confidence": 0.9483945965766907}]}, {"text": "Similarly, \"if\" in example shows that the person is not actually infected.", "labels": [], "entities": []}, {"text": "To filter these instances, we propose to integrate two modalities of information into factuality analysis: shallow modality analysis based on a surface string match and deep modality analysis based on predicate-argument structure analysis.", "labels": [], "entities": []}, {"text": "The main contribution of this paper is two-fold: \u2022 We annotate anew dataset extracted from Twitter for flu detection and prediction task, and extend the na\u00efve bag-of-words model of and propose several Twitter-specific features for disease event detection tasks.", "labels": [], "entities": [{"text": "flu detection and prediction task", "start_pos": 103, "end_pos": 136, "type": "TASK", "confidence": 0.8627363562583923}, {"text": "disease event detection tasks", "start_pos": 231, "end_pos": 260, "type": "TASK", "confidence": 0.7232327237725258}]}, {"text": "\u2022 We show that modality information contributes to the factuality analysis in influenzarelated tweets, which demonstrates the basic feasibility of the proposed approach.", "labels": [], "entities": []}, {"text": "All features presented in this paper increase recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9985675811767578}]}], "datasetContent": [{"text": "Considering our purpose of disease event detection, it is important to estimate the number of positive instances for flu correctly.", "labels": [], "entities": [{"text": "disease event detection", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.6485471129417419}]}, {"text": "In contrast, it is   less important to predict the number of negative instances, although our system has high accuracy (about 91%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9993911981582642}]}, {"text": "Therefore, we computed the precision, recall, and F1-score as the evaluation metrics and conducted five-fold cross-validation.", "labels": [], "entities": [{"text": "precision", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9996826648712158}, {"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.996898889541626}, {"text": "F1-score", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9995293617248535}]}, {"text": "We used Classias (ver.1.1) with its default setting to train the model.", "labels": [], "entities": []}, {"text": "We applied L2-regularized logistic regression as a training algorithm.", "labels": [], "entities": []}, {"text": "We used MeCab (ver.0.996) with IPADic (ver.2.7.0) as a morphological analyzer.", "labels": [], "entities": [{"text": "MeCab", "start_pos": 8, "end_pos": 13, "type": "DATASET", "confidence": 0.8649188280105591}]}, {"text": "The result of disease event detection is shown in.", "labels": [], "entities": [{"text": "disease event detection", "start_pos": 14, "end_pos": 37, "type": "TASK", "confidence": 0.6979931791623434}]}, {"text": "Overall, they seem to have low recall and F1-Score.", "labels": [], "entities": [{"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9997572302818298}, {"text": "F1-Score", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9990365505218506}]}, {"text": "However, it turns out to be difficult to achieve high recall because the percentage of positive cases is extremely low (about 12.6%).", "labels": [], "entities": [{"text": "recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9971964359283447}]}, {"text": "As shown, N-gram and Season features improve F1-score.", "labels": [], "entities": [{"text": "Season", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9191096425056458}, {"text": "F1-score", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9988104104995728}]}, {"text": "Although the shallow modality feature boosts both precision and recall, the deep modality feature only improves recall in compensation with precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.99934321641922}, {"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9992423057556152}, {"text": "recall", "start_pos": 112, "end_pos": 118, "type": "METRIC", "confidence": 0.9990948438644409}, {"text": "precision", "start_pos": 140, "end_pos": 149, "type": "METRIC", "confidence": 0.996982753276825}]}, {"text": "The highest recall for the F1-score is achieved when using both shallow and deep modality features from Tsutsuji and Zunda (in the case of \"All\").", "labels": [], "entities": [{"text": "recall", "start_pos": 12, "end_pos": 18, "type": "METRIC", "confidence": 0.9995545744895935}, {"text": "F1-score", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9987249970436096}]}, {"text": "This result underscores the utility of the modality features for classifying a post by its factuality.", "labels": [], "entities": []}, {"text": "In addition, to judge the performance with respect to the amount of data, we plot a learning curve in.", "labels": [], "entities": []}, {"text": "Although the decision changes only slightly, recall tends to improve by increasing the amount of data.", "labels": [], "entities": [{"text": "recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9989261031150818}]}], "tableCaptions": [{"text": " Table 3: Extended modality feature based on Zunda.  tweet  extended modality", "labels": [], "entities": []}, {"text": " Table 4: Result of binary classification for disease  event detection.  feature  Prec. Rec. F1-score  BoW  74.0 30.5  43.2  BoW+URL  69.9 31.3  43.2  BoW+Atmark  74.0 30.5  43.2  BoW+N-gram  70.7 34.5  46.4  BoW+Season  72.4 33.3  45.6  BoW+Tsutsuji  76.4 32.1  45.2  BoW+Zunda  69.9 31.3  43.2  baseline  69.7 39.2  50.2  baseline+Tsutsuji 70.2 42.0  52.6  baseline+Zunda  67.9 41.2  51.3  All  68.9 44.0  53.7", "labels": [], "entities": [{"text": "disease  event detection", "start_pos": 46, "end_pos": 70, "type": "TASK", "confidence": 0.6919903755187988}, {"text": "F1-score", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9906627535820007}, {"text": "BoW  74.0 30.5  43.2  BoW+URL  69.9 31.3  43.2  BoW+Atmark  74.0", "start_pos": 103, "end_pos": 167, "type": "DATASET", "confidence": 0.7331583244459969}]}, {"text": " Table 7: Contribution and error analysis of deep modality features.", "labels": [], "entities": []}, {"text": " Table 4. Overall, they seem to have low recall and  F1-Score. However, it turns out to be difficult to  achieve high recall because the percentage of pos- itive cases is extremely low (about 12.6%).  As shown, N-gram and Season features improve  F1-score. Although the shallow modality feature  boosts both precision and recall, the deep modal- ity feature only improves recall in compensation  with precision. The highest recall for the F1-score  is achieved when using both shallow and deep  modality features from Tsutsuji and Zunda (in the  case of \"All\"). This result underscores the utility", "labels": [], "entities": [{"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9989967942237854}, {"text": "F1-Score", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9961155652999878}, {"text": "recall", "start_pos": 118, "end_pos": 124, "type": "METRIC", "confidence": 0.9972803592681885}, {"text": "F1-score", "start_pos": 247, "end_pos": 255, "type": "METRIC", "confidence": 0.9960934519767761}, {"text": "precision", "start_pos": 308, "end_pos": 317, "type": "METRIC", "confidence": 0.9984896183013916}, {"text": "recall", "start_pos": 322, "end_pos": 328, "type": "METRIC", "confidence": 0.9953621029853821}, {"text": "recall", "start_pos": 372, "end_pos": 378, "type": "METRIC", "confidence": 0.9955469369888306}, {"text": "precision", "start_pos": 401, "end_pos": 410, "type": "METRIC", "confidence": 0.994851291179657}, {"text": "recall", "start_pos": 424, "end_pos": 430, "type": "METRIC", "confidence": 0.9984644651412964}, {"text": "F1-score", "start_pos": 439, "end_pos": 447, "type": "METRIC", "confidence": 0.9940396547317505}]}]}