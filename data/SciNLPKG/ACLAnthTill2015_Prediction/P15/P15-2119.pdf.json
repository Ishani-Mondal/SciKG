{"title": [{"text": "How Well Do Distributional Models Capture Different Types of Semantic Knowledge?", "labels": [], "entities": [{"text": "Distributional Models Capture Different Types of Semantic Knowledge", "start_pos": 12, "end_pos": 79, "type": "TASK", "confidence": 0.8174283616244793}]}], "abstractContent": [{"text": "In recent years, distributional models (DMs) have shown great success in representing lexical semantics.", "labels": [], "entities": []}, {"text": "In this work we show that the extent to which DMs represent semantic knowledge is highly dependent on the type of knowledge.", "labels": [], "entities": []}, {"text": "We pose the task of predicting properties of concrete nouns in a supervised setting, and compare between learning taxonomic properties (e.g., animacy) and attributive properties (e.g., size, color).", "labels": [], "entities": [{"text": "predicting properties of concrete nouns", "start_pos": 20, "end_pos": 59, "type": "TASK", "confidence": 0.8460904240608216}]}, {"text": "We employ four state-of-the-art DMs as sources of feature representation for this task, and show that they all yield poor results when tested on attributive properties, achieving no more than an average F-score of 0.37 in the binary property prediction task, compared to 0.73 on taxonomic properties.", "labels": [], "entities": [{"text": "F-score", "start_pos": 203, "end_pos": 210, "type": "METRIC", "confidence": 0.9985613226890564}, {"text": "binary property prediction task", "start_pos": 226, "end_pos": 257, "type": "TASK", "confidence": 0.7246198505163193}]}, {"text": "Our results suggest that the distributional hypothesis may not be equally applicable to all types of semantic information.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Distributional Hypothesis states that the meaning of words can be inferred from their linguistic environment.", "labels": [], "entities": []}, {"text": "This hypothesis lies at the heart of distributional models (DMs), which approximate the meaning of words by considering the statistics of their co-occurrence with other words in the lexicon.", "labels": [], "entities": []}, {"text": "DMs have shown impressive results in many semantic tasks, such as predicting the similarity of two words, grouping words into semantic categories, and solving analogy questions (see fora recent survey).", "labels": [], "entities": [{"text": "predicting the similarity of two words", "start_pos": 66, "end_pos": 104, "type": "TASK", "confidence": 0.8435535530249277}, {"text": "grouping words into semantic categories", "start_pos": 106, "end_pos": 145, "type": "TASK", "confidence": 0.7697306632995605}, {"text": "solving analogy questions", "start_pos": 151, "end_pos": 176, "type": "TASK", "confidence": 0.8966555794080099}]}, {"text": "They are also used as a source of semantic information by many downstream applications, including syntactic parsing, image annotation (, and semantic frame identification ().", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 98, "end_pos": 115, "type": "TASK", "confidence": 0.7293606549501419}, {"text": "semantic frame identification", "start_pos": 141, "end_pos": 170, "type": "TASK", "confidence": 0.6975638469060262}]}, {"text": "However, the empirical success of DMs may not be uniform across the full range of semantic knowledge.", "labels": [], "entities": [{"text": "DMs", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9616920351982117}]}, {"text": "It has been argued that DMs can never grasp the full meaning of words, as many aspects of meaning are grounded in the physical world.", "labels": [], "entities": [{"text": "DMs", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9700877666473389}]}, {"text": "This claim relies chiefly on cognitive theory, and is somewhat supported in empirical findings (.", "labels": [], "entities": []}, {"text": "Moreover, a recent study by) has shown that DMs may not model word similarity as well as previously believed.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 62, "end_pos": 77, "type": "TASK", "confidence": 0.6795575022697449}]}, {"text": "In this work, we seek to further study the capabilities of DMs in capturing semantic information.", "labels": [], "entities": []}, {"text": "For our purposes, we assume that the meaning of a word referring to a concrete object (henceforth concept) is comprised of a list of properties (Baroni and.", "labels": [], "entities": []}, {"text": "For example, the meaning of the concept an apple is comprised of such properties as red, round, edible, a fruit, etc.", "labels": [], "entities": []}, {"text": "We distinguish between taxonomic properties (Wu and, which define the conceptual category that a concept belongs to (e.g. an apple is a fruit), and all other types of properties (henceforth referred to as attributive properties).", "labels": [], "entities": []}, {"text": "In this paper we employ DMs in the task of learning properties of concepts, and show a very large discrepancy in performance between learning taxonomic and attributive properties.", "labels": [], "entities": []}, {"text": "Several previous works addressed semantic property learning, but mostly in terms of automatically extracting salient properties of concepts from raw text. is the only work we are aware of that addressed different property types, while utilizing a DM for property extraction.", "labels": [], "entities": [{"text": "semantic property learning", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.6421681841214498}, {"text": "property extraction", "start_pos": 254, "end_pos": 273, "type": "TASK", "confidence": 0.7989287972450256}]}, {"text": "However, their approach is simple, and includes defining the properties of a concept to be the 10 neighboring words of that concept in the DM space.", "labels": [], "entities": []}, {"text": "In order to determine to what extent properties of concepts are captured by DMs, we define the following task.", "labels": [], "entities": []}, {"text": "The goal is to predict, fora given concept, whether it holds a specific property or not (e.g., whether or not the concept elephant is considered large) . We model this task as a learning problem, in which concepts have a feature representation based on a state-of-the-art DM.", "labels": [], "entities": []}, {"text": "A property-predictor is then trained to predict, for any given concept, whether the property applies to it or not (in a binary classification setup), or the strength of affiliation between the property and the concept (in a regression setup).", "labels": [], "entities": []}, {"text": "By evaluating the performance of these predictors, we assess the degree to which the property is captured by the DM.", "labels": [], "entities": []}, {"text": "We experiment with four state-of-the-art DMs ().", "labels": [], "entities": []}, {"text": "Our results show that all DMs, quite successful in many semantic tasks, fail when it comes to predicting attributive properties of concepts.", "labels": [], "entities": [{"text": "predicting attributive properties of concepts", "start_pos": 94, "end_pos": 139, "type": "TASK", "confidence": 0.8314459204673768}]}, {"text": "For example, in the classification task, the best performing DM achieves an averaged F-score of only 0.37, contrasted with an average F-score of 0.73 achieved by the same model for taxonomic properties.", "labels": [], "entities": [{"text": "classification task", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.9007852077484131}, {"text": "F-score", "start_pos": 85, "end_pos": 92, "type": "METRIC", "confidence": 0.9969135522842407}, {"text": "F-score", "start_pos": 134, "end_pos": 141, "type": "METRIC", "confidence": 0.9965284466743469}]}, {"text": "This result, which maybe attributed to an essential difference between taxonomic and attributive properties, demonstrates possible limitations of the distributional hypothesis, at least in terms of the information captured by current stateof-the-art DMs.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments, we consider properties which have at least 25 positive instances in the dataset.", "labels": [], "entities": []}, {"text": "We then discard attributive properties that clearly correspond to a taxonomic property.", "labels": [], "entities": []}, {"text": "For example, the property has feathers is no different from the bird category, or the property lives in water is identical to the fish category.", "labels": [], "entities": []}, {"text": "The final list consists of 7 taxonomic and 13 attributive properties.", "labels": [], "entities": []}, {"text": "For each property, we learn both a linear SVM classifier in the binary setup, and a linear SVM regressor in the regression setup.", "labels": [], "entities": []}, {"text": "For both setups we use the lib-svm package ( and follow a 5-fold cross-validation protocol.", "labels": [], "entities": []}, {"text": "In the binary setup, we report F-scores only, as accuracy measures tend to be misleading due to an unbalanced label distribution.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9766659140586853}, {"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9985937476158142}]}, {"text": "In the regression setup, we report Pearson's correlation scores between predicted values and gold standard values.", "labels": [], "entities": [{"text": "Pearson's correlation scores", "start_pos": 35, "end_pos": 63, "type": "METRIC", "confidence": 0.9499977082014084}]}, {"text": "shows our results in the binary setup (left side) and in the regression setup (right side) for all models.", "labels": [], "entities": []}, {"text": "We display average scores separately for taxonomic and attributive properties.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results for the Property Learning Task. On the left: F-scores for the binary classification task.  On the right: Pearson correlation scores for the regression task.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9891830086708069}, {"text": "Pearson correlation scores", "start_pos": 123, "end_pos": 149, "type": "METRIC", "confidence": 0.9191569487253824}]}]}