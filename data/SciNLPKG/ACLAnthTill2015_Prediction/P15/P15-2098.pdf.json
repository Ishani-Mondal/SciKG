{"title": [{"text": "Radical Embedding: Delving Deeper to Chinese Radicals", "labels": [], "entities": [{"text": "Radical Embedding: Delving Deeper to Chinese Radicals", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.6613387502729893}]}], "abstractContent": [{"text": "Languages using Chinese characters are mostly processed at word level.", "labels": [], "entities": []}, {"text": "Inspired by recent success of deep learning , we delve deeper to character and radical levels for Chinese language processing.", "labels": [], "entities": [{"text": "Chinese language processing", "start_pos": 98, "end_pos": 125, "type": "TASK", "confidence": 0.6240399777889252}]}, {"text": "We propose anew deep learning technique, called \"radical embed-ding\", with justifications based on Chi-nese linguistics, and validate its feasibility and utility through a set of three experiments: two in-house standard experiments on short-text catego-rization (STC) and Chinese word seg-mentation (CWS), and one in-field experiment on search ranking.", "labels": [], "entities": []}, {"text": "We show that radical embedding achieves comparable , and sometimes even better, results than competing methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "Chinese is one of the oldest written languages in the world, but it does not attract much attention in top NLP research forums, probably because of its peculiarities and drastic differences from English.", "labels": [], "entities": []}, {"text": "There are sentences, words, characters in Chinese, as illustrated in.", "labels": [], "entities": []}, {"text": "The top row is a Chinese sentence, whose English translation is at the bottom.", "labels": [], "entities": []}, {"text": "In between is the pronunciation of the sentence in Chinese, called PinYin, which is a form of Romanian phonetic representation of Chinese, similar to the International Phonetic Alphabet (IPA) for English.", "labels": [], "entities": []}, {"text": "Each squared symbol is a distinct Chinese character, and there are no separators between characters calls for Chinese Word Segmentation (CWS) techniques to group adjacent characters into words.", "labels": [], "entities": [{"text": "Chinese Word Segmentation (CWS)", "start_pos": 110, "end_pos": 141, "type": "TASK", "confidence": 0.730023389061292}]}, {"text": "In most current applications (e.g., categorization and recommendation etc.), Chinese is English: It is a nice day today.", "labels": [], "entities": []}, {"text": "Pinyin: j\u012bn ti\u0101n/ ti\u0101n q\u00ec/ zh\u0113n/ h\u01ceo!", "labels": [], "entities": []}, {"text": "a word a character: Illustration of Chinese Language represented at the word level.", "labels": [], "entities": []}, {"text": "Inspired by recent success of delving deep (), an interesting question arises then: can we delve deeper than word level representation for better Chinese language processing?", "labels": [], "entities": []}, {"text": "If the answer is yes, how deep can it be done for fun and for profit?", "labels": [], "entities": []}, {"text": "Intuitively, the answer should be positive.", "labels": [], "entities": []}, {"text": "Nevertheless, each Chinese character is semantically meaningful, thanks to its pictographic root from ancient Chinese as depicted in.", "labels": [], "entities": []}, {"text": "We could delve deeper by decomposing each character into character radicals.", "labels": [], "entities": []}, {"text": "The right part of illustrates the decomposition.", "labels": [], "entities": []}, {"text": "This Chinese character (meaning \"morning\") is decomposed into 4 radicals that consists of 12 strokes in total.", "labels": [], "entities": []}, {"text": "In Chinese linguistics, each Chinese character can be decomposed into no more than four radicals based on a set of preset rules 1 . As depicted by the pictograms in the right part of, the 1st radical (and the 3rd that happens to be the same) means \"grass\", and the 2nd and the 4th mean the \"sun\" and the \"moon\", respectively.", "labels": [], "entities": []}, {"text": "These four radicals altogether convey the meaning that \"the moment when sun arises from the grass while the moon wanes away\", which is exactly \"morning\".", "labels": [], "entities": []}, {"text": "On the other hand, it is hard to decipher the semantics of strokes, and radicals are the minimum semantic unit for Chinese.", "labels": [], "entities": []}, {"text": "Building deep mod- Figure 2: Decomposition of Chinese Character els from radicals could lead to interesting results.", "labels": [], "entities": [{"text": "Decomposition of Chinese Character els", "start_pos": 29, "end_pos": 67, "type": "TASK", "confidence": 0.6751962721347808}]}, {"text": "In sum, this paper makes the following three-fold contributions: (1) we propose anew deep learning technique, called \"radical embedding\", for Chinese language processing with proper justifications based on Chinese linguistics; (2) we validate the feasibility and utility of radical embedding through a set of three experiments, which include not only two in-house standard experiments on short-text categorization (STC) and Chinese word segmentation (CWS), but an in-field experiment on search ranking as well; (3) this initial success of radical embedding could shed some light on new approaches to better language processing for Chinese and other languages alike.", "labels": [], "entities": [{"text": "Chinese language processing", "start_pos": 142, "end_pos": 169, "type": "TASK", "confidence": 0.6273503204186758}, {"text": "Chinese word segmentation (CWS)", "start_pos": 424, "end_pos": 455, "type": "TASK", "confidence": 0.7534381647904714}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents the radical embedding technique and the accompanying deep neural network components, which are combined and stacked to solve three application problems.", "labels": [], "entities": []}, {"text": "Section 3 elaborates on the three applications and reports on the experiment results.", "labels": [], "entities": []}, {"text": "With related work briefly discussed in Section 4, Section 5 concludes this study.", "labels": [], "entities": []}, {"text": "For clarity, we limit the study to Simplified Chinese in this paper.", "labels": [], "entities": [{"text": "Simplified Chinese", "start_pos": 35, "end_pos": 53, "type": "DATASET", "confidence": 0.824011355638504}]}], "datasetContent": [{"text": "In this section, we explain how to stack the components in to solve three problems: short-text categorization, Chinese word segmentation and search ranking, respectively.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 111, "end_pos": 136, "type": "TASK", "confidence": 0.6247849563757578}, {"text": "search ranking", "start_pos": 141, "end_pos": 155, "type": "TASK", "confidence": 0.6499486714601517}]}], "tableCaptions": [{"text": " Table 2: Short Text Categorization Results", "labels": [], "entities": []}, {"text": " Table 3: CWS Result Comparison", "labels": [], "entities": [{"text": "CWS Result Comparison", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.7305014729499817}]}]}