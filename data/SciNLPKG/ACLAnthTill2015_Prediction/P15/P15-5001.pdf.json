{"title": [{"text": "Successful Data Mining Methods for NLP", "labels": [], "entities": [{"text": "Data Mining", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.7639256119728088}, {"text": "NLP", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.7892303466796875}]}], "abstractContent": [{"text": "Historically Natural Language Processing (NLP) focuses on unstructured data (speech and text) understanding while Data Mining (DM) mainly focuses on massive, structured or semi-structured datasets.", "labels": [], "entities": [{"text": "unstructured data (speech and text) understanding", "start_pos": 58, "end_pos": 107, "type": "TASK", "confidence": 0.8003463372588158}, {"text": "Data Mining (DM)", "start_pos": 114, "end_pos": 130, "type": "TASK", "confidence": 0.806283688545227}]}, {"text": "The general research directions of these two fields also have followed different philosophies and principles.", "labels": [], "entities": []}, {"text": "For example, NLP aims at deep understanding of individual words, phrases and sentences (\"micro-level\"), whereas DM aims to conduct a high-level understanding, discovery and synthesis of the most salient information from a large set of documents when working on text data (\"macro-level\").", "labels": [], "entities": []}, {"text": "But they share the same goal of distilling knowledge from data.", "labels": [], "entities": []}, {"text": "In the past five years, these two areas have had intensive interactions and thus mutually enhanced each other through many successful text mining tasks.", "labels": [], "entities": [{"text": "text mining", "start_pos": 134, "end_pos": 145, "type": "TASK", "confidence": 0.8762937188148499}]}, {"text": "This positive progress mainly benefits from some innovative intermediate representations such as \"heterogeneous information net-works\" [Han et al., 2010, Sun et al., 2012b].", "labels": [], "entities": []}, {"text": "However, successful collaborations between any two fields require substantial mutual understanding , patience and passion among researchers.", "labels": [], "entities": []}, {"text": "Similar to the applications of machine learning techniques in NLP, there is usually a gap of at least several years between the creation of anew DM approach and its first successful application in NLP.", "labels": [], "entities": []}, {"text": "More importantly, many DM approaches such as gSpan [Yan and Han, 2002] and RankClus [Sun et al., 2009a] have demonstrated their power on structured data.", "labels": [], "entities": []}, {"text": "But they remain relatively unknown in the NLP community , even though there are many obvious potential applications.", "labels": [], "entities": []}, {"text": "On the other hand, compared to DM, the NLP community has paid more attention to developing large-scale data annotations, resources, shared tasks which cover a wide range of multiple genres and multiple domains.", "labels": [], "entities": []}, {"text": "NLP can also provide the basic building blocks for many DM tasks such as text cube construction [Tao et al., 2014].", "labels": [], "entities": [{"text": "DM tasks", "start_pos": 56, "end_pos": 64, "type": "TASK", "confidence": 0.9152398407459259}, {"text": "text cube construction", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.6799234946568807}]}, {"text": "Therefore in many scenarios, for the same approach the NLP experiment setting is often much closer to real-world applications than its DM counterpart.", "labels": [], "entities": []}, {"text": "We would like to share the experiences and lessons from our extensive inter-disciplinary collaborations in the past five years.", "labels": [], "entities": []}, {"text": "The primary goal of this tutorial is to bridge the knowledge gap between these two fields and speedup the transition process.", "labels": [], "entities": []}, {"text": "We will introduce two types of DM methods: (1).", "labels": [], "entities": [{"text": "DM", "start_pos": 31, "end_pos": 33, "type": "TASK", "confidence": 0.9545987248420715}]}, {"text": "those state-of-the-art DM methods that have already been proven effective for NLP; and (2).", "labels": [], "entities": [{"text": "DM", "start_pos": 23, "end_pos": 25, "type": "TASK", "confidence": 0.9742496609687805}, {"text": "NLP", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.9277129769325256}]}, {"text": "some newly developed DM methods that we believe will fit into some specific NLP problems.", "labels": [], "entities": [{"text": "DM", "start_pos": 21, "end_pos": 23, "type": "TASK", "confidence": 0.9640309810638428}]}, {"text": "In addition, we aim to suggest some new research directions in order to better marry these two areas and lead to more fruitful outcomes.", "labels": [], "entities": []}, {"text": "The tutorial will thus be useful for researchers from both communities.", "labels": [], "entities": []}, {"text": "We will try to provide a concise roadmap of recent perspectives and results, as well as point to the related DM software and resources, and NLP data sets that are available to both research communities.", "labels": [], "entities": [{"text": "NLP data sets", "start_pos": 140, "end_pos": 153, "type": "DATASET", "confidence": 0.7900511225064596}]}, {"text": "2 Outline We will focus on the following three perspectives.", "labels": [], "entities": []}, {"text": "2.1 Where do NLP and DM Meet We will first pickup the tasks shown in Table 1 that have attracted interests from both NLP and DM, and give an overview of different solutions to these problems.", "labels": [], "entities": []}, {"text": "We will compare their fundamental differences in terms of goals, theories, principles and methodologies.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}