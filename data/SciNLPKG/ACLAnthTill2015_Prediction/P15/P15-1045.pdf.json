{"title": [], "abstractContent": [{"text": "We propose an event-driven model for headline generation.", "labels": [], "entities": [{"text": "headline generation", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.9505131244659424}]}, {"text": "Given an input document, the system identifies a key event chain by extracting a set of structural events that describe them.", "labels": [], "entities": []}, {"text": "Then a novel multi-sentence compression algorithm is used to fuse the extracted events, generating a headline for the document.", "labels": [], "entities": [{"text": "multi-sentence compression", "start_pos": 13, "end_pos": 39, "type": "TASK", "confidence": 0.7745884656906128}]}, {"text": "Our model can be viewed as a novel combination of extractive and abstractive headline generation, combining the advantages of both methods using event structures.", "labels": [], "entities": [{"text": "headline generation", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.6884680986404419}]}, {"text": "Standard evaluation shows that our model achieves the best performance compared with previous state-of-the-art systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Headline generation (HG) is a text summarization task, which aims to describe an article (or a set of related paragraphs) using a single short sentence.", "labels": [], "entities": [{"text": "Headline generation (HG)", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8758270740509033}, {"text": "text summarization task", "start_pos": 30, "end_pos": 53, "type": "TASK", "confidence": 0.7543849349021912}]}, {"text": "The task is useful in a number of practical scenarios, such as compressing text for mobile device users), generating table of contents (, and email summarization ().", "labels": [], "entities": [{"text": "email summarization", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.6489428281784058}]}, {"text": "This task is challenging in not only informativeness and readability, which are challenges to common summarization tasks, but also the length reduction, which is unique for headline generation.", "labels": [], "entities": [{"text": "summarization tasks", "start_pos": 101, "end_pos": 120, "type": "TASK", "confidence": 0.902157187461853}, {"text": "headline generation", "start_pos": 173, "end_pos": 192, "type": "TASK", "confidence": 0.8428299725055695}]}, {"text": "Previous headline generation models fall into two main categories, namely extractive HG and abstractive HG (.", "labels": [], "entities": []}, {"text": "Both consist of two steps: candidate extraction and headline generation.", "labels": [], "entities": [{"text": "candidate extraction", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.8144852817058563}, {"text": "headline generation", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.7580573558807373}]}, {"text": "Extractive models choose a set of salient sentences in candidate extraction, and then exploit sentence compression techniques to achieve headline generation (: System framework.).", "labels": [], "entities": [{"text": "candidate extraction", "start_pos": 55, "end_pos": 75, "type": "TASK", "confidence": 0.7945526242256165}, {"text": "sentence compression", "start_pos": 94, "end_pos": 114, "type": "TASK", "confidence": 0.7178763896226883}, {"text": "headline generation", "start_pos": 137, "end_pos": 156, "type": "TASK", "confidence": 0.7755564153194427}]}, {"text": "Abstractive models choose a set of informative phrases for candidate extraction, and then exploit sentence synthesis techniques for headline generation.", "labels": [], "entities": [{"text": "candidate extraction", "start_pos": 59, "end_pos": 79, "type": "TASK", "confidence": 0.7271160334348679}, {"text": "sentence synthesis", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.705923855304718}, {"text": "headline generation", "start_pos": 132, "end_pos": 151, "type": "TASK", "confidence": 0.8519208431243896}]}, {"text": "Extractive HG and abstractive HG have their respective advantages and disadvantages.", "labels": [], "entities": []}, {"text": "Extractive models can generate more readable headlines, because the final title is derived by tailoring human-written sentences.", "labels": [], "entities": []}, {"text": "However, extractive models give less informative titles (, because sentences are very sparse, making high-recall candidate extraction difficult.", "labels": [], "entities": [{"text": "high-recall candidate extraction", "start_pos": 101, "end_pos": 133, "type": "TASK", "confidence": 0.7645243207613627}]}, {"text": "In contrast, abstractive models use phrases as the basic processing units, which are much less sparse.", "labels": [], "entities": []}, {"text": "However, it is more difficult for abstractive HG to ensure the grammaticality of the generated titles, given that sentence synthesis is still very inaccurate based on a set of phrases with little grammatical information.", "labels": [], "entities": [{"text": "sentence synthesis", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.7150313705205917}]}, {"text": "In this paper, we propose an event-driven model for headline generation, which alleviates the disadvantages of both extractive and abstractive HG.", "labels": [], "entities": [{"text": "headline generation", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.935536801815033}]}, {"text": "The framework of the proposed model is shown in.", "labels": [], "entities": []}, {"text": "In particular, we use events as the basic processing units for candidate extraction.", "labels": [], "entities": [{"text": "candidate extraction", "start_pos": 63, "end_pos": 83, "type": "TASK", "confidence": 0.779922753572464}]}, {"text": "We use structured tuples to represent the subject, predicate and object of an event.", "labels": [], "entities": []}, {"text": "This form of event representation is widely used in open information extraction.", "labels": [], "entities": [{"text": "event representation", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.7621923387050629}, {"text": "open information extraction", "start_pos": 52, "end_pos": 79, "type": "TASK", "confidence": 0.6927755872408549}]}, {"text": "Intuitively, events can be regarded as a trade-off between sentences and phrases.", "labels": [], "entities": []}, {"text": "Events are meaningful structures, containing necessary grammatical information, and yet are much less sparse than sentences.", "labels": [], "entities": []}, {"text": "We use salience measures of both sentences and phrases for event extraction, and thus our model can be regarded as a combination of extractive and abstractive HG.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 59, "end_pos": 75, "type": "TASK", "confidence": 0.7209555059671402}]}, {"text": "During the headline generation step, A graphbased multi-sentence compression (MSC) model is proposed to generate a final title, given multiple events.", "labels": [], "entities": [{"text": "headline generation", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.8180911540985107}, {"text": "graphbased multi-sentence compression (MSC)", "start_pos": 39, "end_pos": 82, "type": "TASK", "confidence": 0.7445614337921143}]}, {"text": "First a directed acyclic word graph is constructed based on the extracted events, and then a beam-search algorithm is used to find the best title based on path scoring.", "labels": [], "entities": []}, {"text": "We conduct experiments on standard datasets for headline generation.", "labels": [], "entities": [{"text": "headline generation", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.9190089702606201}]}, {"text": "The results show that headline generation can benefit not only from exploiting events as the basic processing units, but also from the proposed graph-based MSC model.", "labels": [], "entities": [{"text": "headline generation", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.9419524371623993}]}, {"text": "Both our candidate extraction and headline generation methods outperform competitive baseline methods, and our model achieves the best results compared with previous state-of-the-art systems.", "labels": [], "entities": [{"text": "candidate extraction", "start_pos": 9, "end_pos": 29, "type": "TASK", "confidence": 0.7471085786819458}, {"text": "headline generation", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.7840618789196014}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance comparison for automatic  evaluation. The mark  \u2021 denotes that the result is  significantly better with a p-value below 0.01.", "labels": [], "entities": []}, {"text": " Table 2: Results from the manual evaluation. The  mark  \u2021 denotes the result is significantly better  with a p-value below 0.01.", "labels": [], "entities": []}]}