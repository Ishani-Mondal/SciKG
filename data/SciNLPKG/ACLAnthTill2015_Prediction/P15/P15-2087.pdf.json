{"title": [{"text": "MT Quality Estimation for Computer-assisted Translation: Does it Really Help?", "labels": [], "entities": [{"text": "MT Quality Estimation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.5728879769643148}, {"text": "Computer-assisted Translation", "start_pos": 26, "end_pos": 55, "type": "TASK", "confidence": 0.6020022034645081}]}], "abstractContent": [{"text": "The usefulness of translation quality estimation (QE) to increase productivity in a computer-assisted translation (CAT) framework is a widely held assumption (Specia, 2011; Huang et al., 2014).", "labels": [], "entities": [{"text": "translation quality estimation (QE)", "start_pos": 18, "end_pos": 53, "type": "TASK", "confidence": 0.8520658314228058}, {"text": "computer-assisted translation (CAT) framework", "start_pos": 84, "end_pos": 129, "type": "TASK", "confidence": 0.8397938907146454}]}, {"text": "So far, however, the validity of this assumption has not been yet demonstrated through sound evaluations in realistic settings.", "labels": [], "entities": []}, {"text": "To this aim, we report on an evaluation involving professional translators operating with a CAT tool in controlled but natural conditions.", "labels": [], "entities": []}, {"text": "Contrastive experiments are carried out by measuring post-editing time differences when: i) translation suggestions are presented together with binary quality estimates, and ii) the same suggestions are presented without quality indicators.", "labels": [], "entities": []}, {"text": "Translators' productivity in the two conditions is analysed in a principled way, accounting for the main factors (e.g. differences in translators' behaviour, quality of the suggestions) that directly impact on time measurements.", "labels": [], "entities": []}, {"text": "While the general assumption about the usefulness of QE is verified, significance testing results reveal that real productivity gains can be observed only under specific conditions.", "labels": [], "entities": [{"text": "QE", "start_pos": 53, "end_pos": 55, "type": "TASK", "confidence": 0.7927501201629639}]}], "introductionContent": [{"text": "Machine translation (MT) quality estimation aims to automatically predict the expected time (e.g. in seconds) or effort (e.g. number of editing operations) required to correct machine-translated sentences into publishable translations (.", "labels": [], "entities": [{"text": "Machine translation (MT) quality estimation", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.878101280757359}]}, {"text": "In principle, the task has a number of practical applications.", "labels": [], "entities": []}, {"text": "An intuitive one is speeding-up the work of human translators operating with a CAT tool, a software designed to support and facilitate the translation process by proposing suggestions that can be edited by the user.", "labels": [], "entities": []}, {"text": "The idea is that, since the suggestions can be useful (good, hence post-editable) or useless (poor, hence requiring complete re-writing), reliable quality indicators could help to reduce the time spent by the user to decide which action to take (to corrector re-translate).", "labels": [], "entities": []}, {"text": "So far, despite the potential practical benefits, the progress in QE research has not been followed by conclusive results that demonstrate whether the use of quality labels can actually lead to noticeable productivity gains in the CAT framework.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, most prior works limit the analysis to the intrinsic evaluation of QE performance on gold-standard data).", "labels": [], "entities": []}, {"text": "On-field evaluation is indeed a complex task, as it requires: i) the availability of a CAT tool capable to integrate MT QE functionalities, ii) professional translators used to MT post-editing, iii) a sound evaluation protocol to perform betweensubject comparisons, 1 and iv) robust analysis techniques to measure statistical significance under variable conditions (e.g. differences in users' postediting behavior).", "labels": [], "entities": [{"text": "On-field evaluation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6186057329177856}, {"text": "MT QE functionalities", "start_pos": 117, "end_pos": 138, "type": "TASK", "confidence": 0.59299303094546}, {"text": "MT post-editing", "start_pos": 177, "end_pos": 192, "type": "TASK", "confidence": 0.8805774450302124}]}, {"text": "To bypass these issues, the works more closely related to our investigation resort to controlled and simplified evaluation protocols.", "labels": [], "entities": []}, {"text": "For instance, in) the impact of QE predictions on translators' productivity is analysed by measuring the number of words that can be post-edited in a fixed amount of time.", "labels": [], "entities": []}, {"text": "The evaluation, however, only concentrates on the use of QE to rank MT outputs, and the gains in translation speed are measured against the contrastive condition in which no QE-based ranking mechanism is used.", "labels": [], "entities": [{"text": "MT outputs", "start_pos": 68, "end_pos": 78, "type": "TASK", "confidence": 0.8782742023468018}]}, {"text": "In this artificial scenario, the analysis disregards the relation between the usefulness of QE and the intrinsic features of the top-ranked translations (e.g. sentence length, quality of the MT).", "labels": [], "entities": [{"text": "MT", "start_pos": 191, "end_pos": 193, "type": "TASK", "confidence": 0.8593622446060181}]}, {"text": "More recently, claimed a 10% productivity increase when translation is supported by the estimates of an adaptive QE model.", "labels": [], "entities": [{"text": "translation", "start_pos": 56, "end_pos": 67, "type": "TASK", "confidence": 0.9649088978767395}]}, {"text": "Their analysis, however, compares a condition in which MT suggestions are presented with confidence labels (the two factors are not decoupled) against the contrastive condition in which no MT suggestion is presented at all.", "labels": [], "entities": [{"text": "MT suggestions", "start_pos": 55, "end_pos": 69, "type": "TASK", "confidence": 0.9072507619857788}]}, {"text": "Significance testing, moreover, is not performed.", "labels": [], "entities": [{"text": "Significance testing", "start_pos": 0, "end_pos": 20, "type": "METRIC", "confidence": 0.8649108111858368}]}, {"text": "The remainder of this work describes our on-field evaluation addressing (through objective measurements and robust significance tests) the two key questions: \u2022 Does QE really help in the CAT scenario?", "labels": [], "entities": [{"text": "QE", "start_pos": 165, "end_pos": 167, "type": "TASK", "confidence": 0.6980288624763489}, {"text": "CAT", "start_pos": 187, "end_pos": 190, "type": "TASK", "confidence": 0.9905754327774048}]}, {"text": "\u2022 If yes, under what conditions?", "labels": [], "entities": []}], "datasetContent": [{"text": "One of the key questions in utilising QE in the CAT scenario is how to relay QE information to the user.", "labels": [], "entities": [{"text": "CAT", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.9504629373550415}]}, {"text": "In our experiments, we evaluate away of visualising MT quality estimates that is based on a color-coded binary classification (green vs. red) as an alternative to real-valued quality labels.", "labels": [], "entities": [{"text": "MT", "start_pos": 52, "end_pos": 54, "type": "TASK", "confidence": 0.9761952757835388}]}, {"text": "In our context, 'green' means that post-editing the translation is expected to be faster than translation from scratch, while 'red' means that post-editing the translation is expected to take longer than translating from scratch.", "labels": [], "entities": []}, {"text": "This decision rests on the assumption that the two-color scheme is more immediate than realvalued scores, which require some interpretation by the user.", "labels": [], "entities": []}, {"text": "Analysing the difference between alternative visualisation schemes, however, is certainly an aspect that we want to explore in the future.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison (Avg. PET and ranking) be- tween the two testing conditions (with and without  QE labels).", "labels": [], "entities": [{"text": "Avg.", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9296905398368835}, {"text": "PET", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.5003764033317566}]}]}