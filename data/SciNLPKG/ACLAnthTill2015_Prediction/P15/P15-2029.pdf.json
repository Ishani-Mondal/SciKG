{"title": [{"text": "Dependency-based Convolutional Neural Networks for Sentence Embedding *", "labels": [], "entities": []}], "abstractContent": [{"text": "In sentence modeling and classification, convolutional neural network approaches have recently achieved state-of-the-art results , but all such efforts process word vectors sequentially and neglect long-distance dependencies.", "labels": [], "entities": [{"text": "sentence modeling and classification", "start_pos": 3, "end_pos": 39, "type": "TASK", "confidence": 0.7457460910081863}]}, {"text": "To combine deep learning with linguistic structures, we propose a dependency-based convolution approach , making use of tree-based n-grams rather than surface ones, thus utlizing non-local interactions between words.", "labels": [], "entities": []}, {"text": "Our model improves sequential baselines on all four sentiment and question classification tasks, and achieves the highest published accuracy on TREC.", "labels": [], "entities": [{"text": "sentiment and question classification tasks", "start_pos": 52, "end_pos": 95, "type": "TASK", "confidence": 0.8670578956604004}, {"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9961291551589966}, {"text": "TREC", "start_pos": 144, "end_pos": 148, "type": "DATASET", "confidence": 0.7704553008079529}]}], "introductionContent": [{"text": "Convolutional neural networks (CNNs), originally invented in computer vision (, has recently attracted much attention in natural language processing (NLP) on problems such as sequence labeling), semantic parsing), and search query retrieval).", "labels": [], "entities": [{"text": "Convolutional neural networks (CNNs)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.6381884266932806}, {"text": "semantic parsing", "start_pos": 195, "end_pos": 211, "type": "TASK", "confidence": 0.7098434865474701}, {"text": "search query retrieval", "start_pos": 218, "end_pos": 240, "type": "TASK", "confidence": 0.6439566413561503}]}, {"text": "In particular, recent work on CNN-based sentence modeling) has achieved excellent, often state-of-the-art, results on various classification tasks such as sentiment, subjectivity, and question-type classification.", "labels": [], "entities": [{"text": "CNN-based sentence modeling", "start_pos": 30, "end_pos": 57, "type": "TASK", "confidence": 0.591208795706431}, {"text": "question-type classification", "start_pos": 184, "end_pos": 212, "type": "TASK", "confidence": 0.682668149471283}]}, {"text": "However, despite their celebrated success, there remains a major limitation from the linguistics perspective: CNNs, being invented on pixel matrices in image processing, only consider sequential n-grams that are consecutive on the surface string and neglect longdistance dependencies, while the latter play an important role in many linguistic phenomena such as negation, subordination, and wh-extraction, all of which might dully affect the sentiment, subjectivity, or other categorization of the sentence.", "labels": [], "entities": []}, {"text": "* This work was done at both IBM and CUNY, and was supported in part by DARPA FA8750-13-2-0041 (DEFT), and NSF IIS-1449278.", "labels": [], "entities": [{"text": "DARPA FA8750-13-2-0041 (DEFT)", "start_pos": 72, "end_pos": 101, "type": "DATASET", "confidence": 0.6930819988250733}, {"text": "NSF IIS-1449278", "start_pos": 107, "end_pos": 122, "type": "DATASET", "confidence": 0.8875373601913452}]}, {"text": "We thank Yoon Kim for sharing his code, and James Cross and Kai Zhao for discussions.", "labels": [], "entities": []}, {"text": "Indeed, in the sentiment analysis literature, researchers have incorporated long-distance information from syntactic parse trees, but the results are somewhat inconsistent: some reported small improvements), while some otherwise ().", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.9536389708518982}]}, {"text": "As a result, syntactic features have yet to become popular in the sentiment analysis community.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.9652689695358276}]}, {"text": "We suspect one of the reasons for this is data sparsity (according to our experiments, tree n-grams are significantly sparser than surface n-grams), but this problem has largely been alleviated by the recent advances in word embedding.", "labels": [], "entities": []}, {"text": "Can we combine the advantages of both worlds?", "labels": [], "entities": []}, {"text": "So we propose a very simple dependency-based convolutional neural networks (DCNNs).", "labels": [], "entities": []}, {"text": "Our model is similar to, but while his sequential CNNs put a word in its sequential context, ours considers a word and its parent, grandparent, great-grand-parent, and siblings on the dependency tree.", "labels": [], "entities": []}, {"text": "This way we incorporate longdistance information that are otherwise unavailable on the surface string.", "labels": [], "entities": []}, {"text": "Experiments on three classification tasks demonstrate the superior performance of our DCNNs over the baseline sequential CNNs.", "labels": [], "entities": []}, {"text": "In particular, our accuracy on the TREC dataset outperforms all previously published results in the literature, including those with heavy hand-engineered features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9996581077575684}, {"text": "TREC dataset", "start_pos": 35, "end_pos": 47, "type": "DATASET", "confidence": 0.7882830202579498}]}, {"text": "Independently of this work, reported related efforts; see Sec.", "labels": [], "entities": []}], "datasetContent": [{"text": "For all datasets, we first obtain the dependency parse tree from Stanford parser ().", "labels": [], "entities": []}, {"text": "1 Different window size for different choice of convolution are shown in.", "labels": [], "entities": []}, {"text": "For the dataset without a development set (MR), we randomly choose 10% of the training data to indicate early stopping.", "labels": [], "entities": []}, {"text": "In order to have a fare comparison with baseline CNN, we also use 3 to 5 as our window size.", "labels": [], "entities": []}, {"text": "Most of our results are generated by GPU due to its efficiency, however CPU could potentially get better results.", "labels": [], "entities": []}, {"text": "Our implementation, on top of Kim (2014)'s code, 3 will be released.", "labels": [], "entities": [{"text": "Kim (2014)'s code", "start_pos": 30, "end_pos": 47, "type": "DATASET", "confidence": 0.8737190067768097}]}], "tableCaptions": [{"text": " Table 1: Tree-based convolution patterns. Word concatenation always starts with m, while h, g, and g 2  denote parent, grand parent, and great-grand parent, etc., and \" \" denotes words excluded in convolution.", "labels": [], "entities": []}, {"text": " Table 1: Results on Movie Review (MR), Stanford Sentiment Treebank (SST-1), and TREC datasets.  TREC-2 is TREC with fine grained labels.  \u2020 Results generated by GPU (all others generated by CPU).   *  Results generated from Kim (2014)'s implementation.", "labels": [], "entities": [{"text": "Stanford Sentiment Treebank", "start_pos": 40, "end_pos": 67, "type": "DATASET", "confidence": 0.7564327120780945}, {"text": "TREC datasets", "start_pos": 81, "end_pos": 94, "type": "DATASET", "confidence": 0.9094827175140381}]}, {"text": " Table 2: Results on Movie Review (MR), Stanford Sentiment Treeba  TREC-2 is TREC with fine grained labels.  \u2020 Results generated by GPU   *  Results generated from Kim (2014)'s implementation.", "labels": [], "entities": [{"text": "Movie Review (MR)", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.6113177120685578}, {"text": "Stanford Sentiment Treeba", "start_pos": 40, "end_pos": 65, "type": "DATASET", "confidence": 0.8972324331601461}, {"text": "TREC-2", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.5141323208808899}, {"text": "TREC", "start_pos": 77, "end_pos": 81, "type": "METRIC", "confidence": 0.9405725002288818}, {"text": "GPU", "start_pos": 132, "end_pos": 135, "type": "DATASET", "confidence": 0.9334832429885864}]}]}