{"title": [{"text": "Why discourse affects speakers' choice of referring expressions", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a language production model that uses dynamic discourse information to account for speakers' choices of referring expressions.", "labels": [], "entities": []}, {"text": "Our model extends previous rational speech act models (Frank and Goodman, 2012) to more naturally distributed linguistic data, instead of assuming a controlled experimental setting.", "labels": [], "entities": []}, {"text": "Simulations show a close match between speakers' utterances and model predictions, indicating that speakers' behavior can be modeled in a principled way by considering the probabilities of referents in the discourse and the information conveyed by each word.", "labels": [], "entities": []}], "introductionContent": [{"text": "Discourse information plays an important role in various aspects of linguistic processing, such as predictions about upcoming words) and scalar implicature processing ().", "labels": [], "entities": [{"text": "scalar implicature processing", "start_pos": 137, "end_pos": 166, "type": "TASK", "confidence": 0.7572980324427286}]}, {"text": "The relationship between discourse information and speakers' choices of referring expression is one of the most studied problems.", "labels": [], "entities": []}, {"text": "Speakers' choices of referring expressions have long been thought to depend on the salience of entities in the discourse.", "labels": [], "entities": []}, {"text": "For example, speakers normally do not choose a pronoun to refer to anew entity in the discourse, but are more likely to use pronouns for referents that have been referred to earlier in the discourse.", "labels": [], "entities": []}, {"text": "A number of grammatical, semantic, and distributional factors related to salience have been found to influence choices of referring expressions.", "labels": [], "entities": []}, {"text": "While the relationship between discourse salience and speakers' choices of referring expressions is well known, there is not yet a formal account of why this relationship exists.", "labels": [], "entities": []}, {"text": "In recent years, a number of formal models have been proposed to capture inferences between speakers and listeners in the context of Gricean pragmatics).", "labels": [], "entities": []}, {"text": "These models take a game theoretic approach in which speakers optimize productions to convey information for listeners, and listeners infer meaning based on speakers' likely productions.", "labels": [], "entities": []}, {"text": "These models have been argued to account for human communication, and studies report that they robustly predict various linguistic phenomena in experimental settings).", "labels": [], "entities": [{"text": "human communication", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7377571165561676}]}, {"text": "However, these models have not yet been applied to language produced outside of the laboratory, nor have they incorporated measures of discourse salience that can be computed over corpora.", "labels": [], "entities": []}, {"text": "In this paper, we propose a probabilistic model to explain speakers' choices of referring expressions based on discourse salience.", "labels": [], "entities": []}, {"text": "Our model extends the rational speech act model from to incorporate updates to listeners' beliefs as discourse proceeds.", "labels": [], "entities": []}, {"text": "The model predicts that a speaker's choice of referring expressions should depend directly on the amount of information that each word carries in the discourse.", "labels": [], "entities": []}, {"text": "Simulations probe the contribution of each model component and show that the model can predict speakers' pronominalization in a corpus.", "labels": [], "entities": []}, {"text": "These results suggest that this model formalizes underlying principles that account for speakers' choices of referring expressions.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews relevant studies on choices of referring expressions.", "labels": [], "entities": []}, {"text": "Section 3 describes the details of our model.", "labels": [], "entities": []}, {"text": "Section 4 describes the data, preprocessing and annotation procedure.", "labels": [], "entities": []}, {"text": "Section 5 presents simulation results.", "labels": [], "entities": []}, {"text": "Section 6 summarizes this study and discusses implications and future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments are designed to quantify the contributions of the various components of the complete model described in Section 3.2 that incorporates discourse salience, cost, and unseen referents.", "labels": [], "entities": []}, {"text": "We contrast the complete model with three impoverished models that lack precisely one of these components.", "labels": [], "entities": []}, {"text": "The comparison model without discourse uses a uniform discourse salience distribution.", "labels": [], "entities": []}, {"text": "The model without cost uses constant speech cost.", "labels": [], "entities": []}, {"text": "The model without good estimates of unseen referents always assigns probability 1 V \u00b7 \u03b1 \u00b7 1 C\u00b7 to unseen referents in the denominator of, regardless of whether the word is a proper name or pronoun.", "labels": [], "entities": []}, {"text": "In other words, this model does not have good estimates of unseen referents like the complete model does.", "labels": [], "entities": []}, {"text": "We use the adult-and child-directed corpora to examine to what extent each model captures speakers' referring expressions.", "labels": [], "entities": []}, {"text": "We selected pronouns and proper names in each corpus according to several criteria.", "labels": [], "entities": []}, {"text": "First, the referring expression had to be in a coreference chain that had at least one proper name, in order to facilitate computing the cost of the proper name alternative.", "labels": [], "entities": []}, {"text": "Second, pronouns were only included if they were third person pronouns in subject or object position, and indexicals and reflexives were excluded.", "labels": [], "entities": []}, {"text": "Finally, for the CHILDES corpus, children's utterances were excluded.", "labels": [], "entities": [{"text": "CHILDES corpus", "start_pos": 17, "end_pos": 31, "type": "DATASET", "confidence": 0.8487712144851685}]}, {"text": "After filtering pronouns and proper names according to these criteria, 553 pronouns and 1,332 proper names (total 1,885 items) in the OntoNotes corpus, and 165 pronouns and 149 proper names (total 314 items) in the CHILDES Gleason corpus remained for use in the analysis.", "labels": [], "entities": [{"text": "OntoNotes corpus", "start_pos": 134, "end_pos": 150, "type": "DATASET", "confidence": 0.9333167672157288}, {"text": "CHILDES Gleason corpus", "start_pos": 215, "end_pos": 237, "type": "DATASET", "confidence": 0.9296894272168478}]}, {"text": "Each model chooses referring expressions given information extracted from each corpus as described in Section 4.1.", "labels": [], "entities": []}, {"text": "For evaluation, we computed accuracies (total, pronoun, and proper name) and model log likelihood (summing log PS (w|r) for the words in the corpus) for each model.", "labels": [], "entities": [{"text": "model log likelihood (summing log PS (w|r)", "start_pos": 77, "end_pos": 119, "type": "METRIC", "confidence": 0.7854481488466263}]}, {"text": "summarizes the results of each model with the OntoNotes and CHILDES datasets.", "labels": [], "entities": [{"text": "OntoNotes", "start_pos": 46, "end_pos": 55, "type": "DATASET", "confidence": 0.8212182521820068}, {"text": "CHILDES datasets", "start_pos": 60, "end_pos": 76, "type": "DATASET", "confidence": 0.8285609185695648}]}, {"text": "The new referent hyperparameter \u03b1 and the decay parameter for discourse recency salience were fixed at 0.1 and 3.0, respectively.", "labels": [], "entities": [{"text": "discourse recency salience", "start_pos": 62, "end_pos": 88, "type": "TASK", "confidence": 0.6511232654253641}]}], "tableCaptions": []}