{"title": [{"text": "One Tense per Scene: Predicting Tense in Chinese Conversations", "labels": [], "entities": [{"text": "Predicting Tense in Chinese Conversations", "start_pos": 21, "end_pos": 62, "type": "TASK", "confidence": 0.9142361998558044}]}], "abstractContent": [{"text": "We study the problem of predicting tense in Chinese conversations.", "labels": [], "entities": [{"text": "predicting tense in Chinese conversations", "start_pos": 24, "end_pos": 65, "type": "TASK", "confidence": 0.9126787662506104}]}, {"text": "The unique challenges include: (1) Chinese verbs do not have explicit lexical or grammatical forms to indicate tense; (2) Tense information is often implicitly hidden outside of the target sentence.", "labels": [], "entities": []}, {"text": "To tackle these challenges, we first propose a set of novel sentence-level (local) features using rich linguistic resources and then propose anew hypothesis of \"One tense per scene\" to incorporate scene-level (global) evidence to enhance the performance.", "labels": [], "entities": []}, {"text": "Experimental results demonstrate the power of this hybrid approach, which can serve as anew and promising benchmark.", "labels": [], "entities": []}], "introductionContent": [{"text": "In natural languages, tense is important to indicate the time at which an action or event takes place.", "labels": [], "entities": []}, {"text": "In some languages such as Chinese, verbs do not have explicit morphological or grammatical forms to indicate their tense information.", "labels": [], "entities": []}, {"text": "Therefore, automatic tense prediction is important for both human's deep understanding of these languages as well as downstream natural language processing tasks (e.g., machine translation (.", "labels": [], "entities": [{"text": "automatic tense prediction", "start_pos": 11, "end_pos": 37, "type": "TASK", "confidence": 0.6052743295828501}, {"text": "machine translation", "start_pos": 169, "end_pos": 188, "type": "TASK", "confidence": 0.7817930281162262}]}, {"text": "In this paper, we concern \"semantic\" tense (time of the event relative to speech time) as opposed to morphosyntactic tense systems found in many languages.", "labels": [], "entities": []}, {"text": "Our goal is to predict the tense (past, present or future) of the main predicate 1 of each sentence in a Chinese conversation, which has never been thoroughly studied before but is extremely important for conversation understanding.", "labels": [], "entities": [{"text": "predict the tense (past, present or future) of the main predicate 1 of each sentence in a Chinese conversation", "start_pos": 15, "end_pos": 125, "type": "TASK", "confidence": 0.6561565764925696}, {"text": "conversation understanding", "start_pos": 205, "end_pos": 231, "type": "TASK", "confidence": 0.7633280456066132}]}, {"text": "Some recent work () on Chinese The main predicate of a sentence can be considered equal to the root of a dependency parse tense prediction found that tense in written language can be effectively predicted by some features in local contexts such as aspectual markers (e.g. \u7740 (zhe), \u4e86 (le), \u8fc7 (guo)) and time expressions (e.g., \u6628\u5929 (yesterday)).", "labels": [], "entities": [{"text": "dependency parse tense prediction", "start_pos": 105, "end_pos": 138, "type": "TASK", "confidence": 0.8414059281349182}]}, {"text": "However, it is much more challenging to predict tense in Chinese conversations and there has not been an effective set of rules to predict Chinese tense so far due to the complexity of language-specific phenomena.", "labels": [], "entities": []}, {"text": "Let's look at the examples shown in.", "labels": [], "entities": []}, {"text": "In general, there are three unique challenges for tense prediction in Chinese conversations: (1) Informal verbal expressions: sentences in a conversation are often grammatically incorrect, which makes aspectual marker based evidence unreliable.", "labels": [], "entities": [{"text": "tense prediction", "start_pos": 50, "end_pos": 66, "type": "TASK", "confidence": 0.7402430176734924}]}, {"text": "Moreover, sentences in a conversation often omit important sentence components.", "labels": [], "entities": []}, {"text": "For example, in conversation 1 in, \"\u5982\u679c(if)\" which is a very important cue to predict tense of verb \"\u5e9f(destroy)\" is omitted.", "labels": [], "entities": []}, {"text": "(2) Effects of interactions on tense: In contrast to other genres, conversations are interactive, which may have an effect on tense: in some cases, tense can only be inferred by understanding the interactions.", "labels": [], "entities": []}, {"text": "For example, we can see from conversations 2, 3 and 4 in that when the second person (\u4f60(you)) is used as the object of the predicate \"\u544a \u8bc9(tell)\", the predicate describes the action during the conversation and thus its tense is present.", "labels": [], "entities": []}, {"text": "In contrast, when the third person is used in a sentence, it is unlikely that the tense of the predicate is present because it does not describe an action during the conversation.", "labels": [], "entities": []}, {"text": "This challenge is unique to Chinese conversations.", "labels": [], "entities": []}, {"text": "(3) Tense ambiguity in a single sentence: Sentence-level analysis is often inadequate to disambiguate tense.", "labels": [], "entities": [{"text": "Tense ambiguity", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.8536263108253479}]}, {"text": "For example, it is impossible to determine whether \"\u544a\u8bc9(tell)\" in conversations 3 and 4 in is a past action (the speaker already told) or a future action (the speaker hasn't told yet) only based on sentence-level contexts.", "labels": [], "entities": []}, {"text": "In fact, the sentence in conversation 3 omits \"\u521a \u624d(just now)\" which indicates past tense and the sentence in the conversation 4 omits \"\u8981(will)\" which indicates future tense.", "labels": [], "entities": []}, {"text": "If we add the omitted word back to the original sentence, there will not be tense ambiguity.", "labels": [], "entities": []}, {"text": "To tackle the above challenges, we propose to predict tense in Chinese conversations from two views -sentence-level (local) and scenelevel (global).", "labels": [], "entities": []}, {"text": "We first develop a local classifier with linguistic knowledge and new conversationspecific features (Section 2.1).", "labels": [], "entities": []}, {"text": "Then we propose a novel framework to exploit the global contexts of the entire scene to infer tense, based on anew \"One tense per scene\" hypothesis (Section 2.2).", "labels": [], "entities": []}, {"text": "We created anew a benchmark data set 2 , which contains 294 conversations (1,857 sentences) and demonstrated the effectiveness of our approach.", "labels": [], "entities": []}], "datasetContent": [{"text": "We compare our approach with the following baselines: \u2022 Majority: We label every instance with the majority tense (present tense).", "labels": [], "entities": []}, {"text": "\u2022 Local predictor with basic features (Local(b)) \u2022 Local predictor with basic features + dependency parsing features (Local(b+p)) \u2022 Local predictor with basic features + dependency parsing features + linguistic knowledge features (Local(b+p+l)) \u2022 Local predictor + all features introduced in Section 2.1 (Local(all)) \u2022 Conditional Random Fields (CRFs): We model a conversation as a sequence of sentences and predict tense using CRFs).", "labels": [], "entities": []}, {"text": "We implement CRFs using CRFsuite) with all features introduced in Section 2.1.", "labels": [], "entities": []}, {"text": "Among the baselines, Local(b+p) is the most similar model to the approaches in previous work on Chinese tense prediction in written languages ().", "labels": [], "entities": [{"text": "Chinese tense prediction", "start_pos": 96, "end_pos": 120, "type": "TASK", "confidence": 0.670346756776174}]}, {"text": "Recent work ) used eventuality and modality labels as features that derived from a classifier trained on an annotated corpus.", "labels": [], "entities": []}, {"text": "However, the annotated corpus for training the eventuality and modality classifier is not publicly available, we cannot duplicate their approaches.", "labels": [], "entities": []}, {"text": "shows the results of various models.", "labels": [], "entities": []}, {"text": "For our global predictor, the optimal \u03bb (0.4) is tuned on the development set and used on the test set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Tense prediction accuracy.", "labels": [], "entities": [{"text": "Tense prediction", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.9662371277809143}, {"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9716642498970032}]}]}