{"title": [{"text": "Entity Retrieval via Entity Factoid Hierarchy *", "labels": [], "entities": [{"text": "Entity Retrieval", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7104845941066742}]}], "abstractContent": [{"text": "We propose that entity queries are generated via a two-step process: users first select entity facts that can distinguish target entities from the others; and then choose words to describe each selected fact.", "labels": [], "entities": []}, {"text": "Based on this query generation paradigm, we propose anew entity representation model named as entity fac-toid hierarchy.", "labels": [], "entities": []}, {"text": "An entity factoid hierarchy is a tree structure composed of fac-toid nodes.", "labels": [], "entities": []}, {"text": "A factoid node describes one or more facts about the entity in different information granularities.", "labels": [], "entities": []}, {"text": "The entity fac-toid hierarchy is constructed via a factor graph model, and the inference on the factor graph is achieved by a modified variant of Multiple-try Metropolis algorithm.", "labels": [], "entities": []}, {"text": "Entity retrieval is performed by decomposing entity queries and computing the query likelihood on the entity factoid hierarchy.", "labels": [], "entities": [{"text": "Entity retrieval", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8388850688934326}]}, {"text": "Using an array of benchmark datasets, we demonstrate that our proposed framework significantly improves the retrieval performance over existing models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Entity retrieval, which aims at returning specific entities to directly answer a user's query, has drawn much attention these years.", "labels": [], "entities": [{"text": "Entity retrieval", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8120919764041901}]}, {"text": "Various entity retrieval tasks have been proposed, such as TREC Entity () and INEX-LD ( ;).", "labels": [], "entities": [{"text": "entity retrieval", "start_pos": 8, "end_pos": 24, "type": "TASK", "confidence": 0.696893647313118}, {"text": "TREC Entity", "start_pos": 59, "end_pos": 70, "type": "METRIC", "confidence": 0.7171559929847717}, {"text": "INEX-LD", "start_pos": 78, "end_pos": 85, "type": "METRIC", "confidence": 0.7622398138046265}]}, {"text": "Many existing entity retrieval models follow the document retrieval assumption: when issuing queries, users choose the words that may * The work described in this paper is substantially supported by grants from the Research Grant Council of the Hong Kong Special Administrative Region, China (Project Codes: 413510 and 14203414) and the Direct Grant of the Faculty of Engineering, CUHK appear in the \"entity pseudo-document\".", "labels": [], "entities": [{"text": "CUHK", "start_pos": 381, "end_pos": 385, "type": "DATASET", "confidence": 0.9499973058700562}]}, {"text": "Based on the assumption, these models construct internal entity representations by combining various entity descriptions, and use these representations to compute the rank of the candidate entities fora given entity query.", "labels": [], "entities": []}, {"text": "These models include fielded versions of BM25 and Mixture of Language Models (), Entity Language Model (), Hierarchical Expert Model (), Structured Positional Entity Language Model (.", "labels": [], "entities": [{"text": "BM25", "start_pos": 41, "end_pos": 45, "type": "DATASET", "confidence": 0.8610333800315857}]}, {"text": "However, a closer examination of entity queries reveals that most of them are not simple uniform word samples from the \"entity pseudo-document\".", "labels": [], "entities": []}, {"text": "Instead, they can be decomposed into multiple parts, where each part describes a fact about target entities.", "labels": [], "entities": []}, {"text": "For example, the query \"National capitals situated on islands\" describes two facts regarding a target entity: it is a national capital; it is located on an island.", "labels": [], "entities": []}, {"text": "Compared to the assumption in document retrieval models, where query terms are assumed to be generated from a single document, these query terms can be regarded to be independently generated from two underlying documents.", "labels": [], "entities": []}, {"text": "According to this observation, we propose that an entity query is generated via a two-step process: users first select facts that can distinguish target entities from the others; and then choose words that describe the selected facts.", "labels": [], "entities": []}, {"text": "Based on the proposed query generation paradigm, we design anew entity retrieval framework.", "labels": [], "entities": [{"text": "query generation", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.7219208329916}]}, {"text": "On one hand, an entity is modeled to have multiple internal representations, each regarding one or more closely related facts.", "labels": [], "entities": []}, {"text": "On the other hand, an entity query is decomposed into one or more subqueries, each describing a fact about target entities.", "labels": [], "entities": []}, {"text": "In this way, entity retrieval can be performed by combining the probabilities of subqueries being satisfied for each candidate entity.", "labels": [], "entities": [{"text": "entity retrieval", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.7450435757637024}]}, {"text": "One of the central components of our proposed: An example of entity factoid hierarchy containing two factoids about Barack Obama retrieval framework is a novel entity representation known as entity factoid hierarchy.", "labels": [], "entities": []}, {"text": "An entity factoid hierarchy is a tree structure composed of factoid nodes, which is automatically constructed from a collection of entity descriptions.", "labels": [], "entities": []}, {"text": "We abuse the term \"factoid\" to denote a single piece of information regarding an entity.", "labels": [], "entities": []}, {"text": "A factoid node in the hierarchy describes one or more factoids.", "labels": [], "entities": []}, {"text": "Factoid nodes in different levels capture the information of different levels of detail (referred to as information granularities hereafter), where lower level nodes contain more detailed information and higher level nodes abstract the details away.", "labels": [], "entities": []}, {"text": "The entity factoid hierarchy is constructed via a factor graph model, and the inference on the factor graph is achieved by a modified variant of Multiple-try Metropolis algorithm.", "labels": [], "entities": []}, {"text": "Each factoid node is indexed separately as a pseudo-document.", "labels": [], "entities": []}, {"text": "During retrieval, the query likelihood fora candidate entity are computed by transversing the factoid hierarchy.", "labels": [], "entities": []}, {"text": "Compared to exiting entity retrieval models, our proposed framework exhibits two advantages: \u2022 By organizing entity descriptions in a hierarchical structure, detailed entity information is preserved and we can return finer confidence value.", "labels": [], "entities": []}, {"text": "Suppose that the entity \"Barack Obama\" is only described by one sentence: \"born in 1961\".", "labels": [], "entities": []}, {"text": "Traditional entity models, which model an entity as a pseudo-document, would return high confidence value for the query \"who is born in 1961\".", "labels": [], "entities": []}, {"text": "However, as we add more and more sentences to describe \"Barack Obama\", the confidence value returned for the query decreases due to the longer entity pseudo-document.", "labels": [], "entities": []}, {"text": "This result is not desirable for entity retrieval, since adding more descriptions about other facts should not affect the confidence of existing facts.", "labels": [], "entities": [{"text": "entity retrieval", "start_pos": 33, "end_pos": 49, "type": "TASK", "confidence": 0.794318288564682}]}, {"text": "Our factoid hierarchy avoids this problem by preserving all the entity descriptions in a hierarchical structure.", "labels": [], "entities": []}, {"text": "When performing retrieval, entity factoid hierarchy can be traversed to locate the best supporting description for the query.", "labels": [], "entities": []}, {"text": "\u2022 By separating entity facts in different factoid nodes, our model prevent ambiguity caused by mixing terms describing different facts.", "labels": [], "entities": []}, {"text": "Suppose \"Barack Obama\" is described by two sentences: \"Barack Obama is a president of United States\" and \"Barack Obama is a graduate of Harvard Law School\", and our query is \"Who is a president of Harvard Law School\".", "labels": [], "entities": []}, {"text": "A traditional document retrieval model with a bag-of-word entity pseudo-document would return \"Barack Obama\" with high confidence, since all the query terms appear in the entity descriptions.", "labels": [], "entities": []}, {"text": "But obviously, this result is not correct.", "labels": [], "entities": []}, {"text": "In our factoid hierarchy, these two facts are separated in lower level factoid nodes.", "labels": [], "entities": []}, {"text": "While higher level nodes are still mixed with terms from child nodes, they are penalized to avoid giving high confidence value.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform entity retrieval experiments using the DBpedia-Entity dataset used in ().", "labels": [], "entities": [{"text": "entity retrieval", "start_pos": 11, "end_pos": 27, "type": "TASK", "confidence": 0.7861325740814209}, {"text": "DBpedia-Entity dataset", "start_pos": 50, "end_pos": 72, "type": "DATASET", "confidence": 0.9724420011043549}]}, {"text": "The dataset is a mixture of multiple entity retrieval datasets, covering entity queries of various styles such as keyword queries like \"vietnam war movies\" and verbose queries like \"What is the capital of Canada\".", "labels": [], "entities": []}, {"text": "Some query statistics are shown in  The data corpus we use are DBpedia 3.9 and the corresponding English Wikipedia data dump on April 4, 2013.", "labels": [], "entities": [{"text": "DBpedia 3.9", "start_pos": 63, "end_pos": 74, "type": "DATASET", "confidence": 0.8924978375434875}, {"text": "English Wikipedia data dump on April 4", "start_pos": 97, "end_pos": 135, "type": "DATASET", "confidence": 0.898168010371072}]}, {"text": "It should be noted that the original DBpedia-Entity benchmark only uses DBpedia for entity modeling (.", "labels": [], "entities": [{"text": "DBpedia-Entity benchmark", "start_pos": 37, "end_pos": 61, "type": "DATASET", "confidence": 0.8962058424949646}]}, {"text": "In our experiments, we also conducted another set of experiments which include full-text Wikipedia articles as additional entity descriptions, to evaluate the capacity of different models on handling free texts as information sources.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: DBpedia-Entity dataset statistics", "labels": [], "entities": [{"text": "DBpedia-Entity dataset", "start_pos": 10, "end_pos": 32, "type": "DATASET", "confidence": 0.9866922497749329}]}]}