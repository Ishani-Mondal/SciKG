{"title": [{"text": "Co-Simmate: Quick Retrieving All Pairwise Co-Simrank Scores", "labels": [], "entities": [{"text": "Quick Retrieving All Pairwise Co-Simrank Scores", "start_pos": 12, "end_pos": 59, "type": "METRIC", "confidence": 0.7515067408482233}]}], "abstractContent": [{"text": "Co-Simrank is a useful Simrank-like measure of similarity based on graph structure.", "labels": [], "entities": []}, {"text": "The existing method iteratively computes each pair of Co-Simrank score from a dot product of two Pagerank vectors, entailing O(log(1/\u01eb)n 3) time to compute all pairs of Co-Simranks in a graph with n nodes, to attain a desired accuracy \u01eb.", "labels": [], "entities": [{"text": "O", "start_pos": 125, "end_pos": 126, "type": "METRIC", "confidence": 0.9973874688148499}, {"text": "accuracy", "start_pos": 226, "end_pos": 234, "type": "METRIC", "confidence": 0.9993164539337158}]}, {"text": "In this study, we devise a model, Co-Simmate, to speedup the retrieval of all pairs of Co-Simranks to O(log 2 (log(1/\u01eb))n 3) time.", "labels": [], "entities": []}, {"text": "Moreover, we show the optimality of Co-Simmate among other hop-(u k) variations, and integrate it with a matrix decomposition based method on singular graphs to attain higher efficiency.", "labels": [], "entities": []}, {"text": "The viable experiments verify the superiority of Co-Simmate to others.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many NLP applications require a pairwise graphbased similarity measure.", "labels": [], "entities": []}, {"text": "Examples are bilingual lexicon extraction (, sentiment analysis (, synonym extraction (), named entity disambiguation), acronym expansion (.", "labels": [], "entities": [{"text": "bilingual lexicon extraction", "start_pos": 13, "end_pos": 41, "type": "TASK", "confidence": 0.6373023788134257}, {"text": "sentiment analysis", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.8757569193840027}, {"text": "synonym extraction", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.6918079555034637}, {"text": "acronym expansion", "start_pos": 120, "end_pos": 137, "type": "TASK", "confidence": 0.8291302025318146}]}, {"text": "Recently, Co-Simrank ( becomes an appealing graph-theoretical similarity measure that integrates both features of Simrank () and Pagerank.", "labels": [], "entities": []}, {"text": "Co-Simrank works by weighing all the number of connections between two nodes to evaluate how similar two nodes are.", "labels": [], "entities": []}, {"text": "The intuition behind Co-Simrank is that \"more similar nodes are likely to be pointed to by other similar nodes\".", "labels": [], "entities": []}, {"text": "Co-Simrank is defined in a recursive style: where S is the exact Co-Simrank matrix, A is the column-normalised adjacency matrix of the graph, c is a decay factor, and I is an identity matrix.", "labels": [], "entities": []}, {"text": "The best-known method by) computes a single element of S iteratively from a dot product * , * of two Pagerank vectors: where pk (a) is a Pagerank vector, defined asp k (a) = A T p k\u22121 (a) with p 0 (a) = I( * , a) (3) This method is highly efficient when only a small fraction of pairs of Co-Simranks need computing because there is no need to access the entire graph for computing only a single pair score.", "labels": [], "entities": []}, {"text": "However, partial pairs retrieval is insufficient for many realworld applications () which require all-pairs scores.", "labels": [], "entities": []}, {"text": "Let us look at two examples.", "labels": [], "entities": []}, {"text": "Ina co-citation network, one wants to retrieve the relevance between any two given documents at any moment based on their references.", "labels": [], "entities": []}, {"text": "To answer such an ad-hoc query, quantifying scores of all document-pairs provides a comprehensive way to show where low and high relevance of pairwise documents may exist ().", "labels": [], "entities": []}, {"text": "b) Water Burst Localization.", "labels": [], "entities": [{"text": "Water Burst Localization", "start_pos": 3, "end_pos": 27, "type": "TASK", "confidence": 0.7292739152908325}]}, {"text": "Ina water network, nodes denote deployed pressure sensor locations, and edges are pipe sections that connect the nodes.", "labels": [], "entities": []}, {"text": "To determine the burst location, one needs to evaluate \"proximities\" of all pairs of sensor nodes first, and then compare all these \"proximities\" with the difference in the arrival times of the burst transient at sensor locations, to find the sensor node nearest to the burst event.", "labels": [], "entities": []}, {"text": "( Hence, the retrieval of all pairwise Co-Simranks is very useful in many applications.", "labels": [], "entities": []}, {"text": "Unfortunately, when it comes to all pairs computation of S( * , * ), the way of (2) has no advantage over the naive way as both entail O(log(1/\u01eb)n 3 ) time to compute all pairs of Co-Simranks to attain desired accuracy \u01eb.", "labels": [], "entities": [{"text": "O", "start_pos": 135, "end_pos": 136, "type": "METRIC", "confidence": 0.9867866039276123}, {"text": "accuracy", "start_pos": 210, "end_pos": 218, "type": "METRIC", "confidence": 0.9978899359703064}]}, {"text": "The complexity O(log(1/\u01eb)n 3 ) has two parts: The first part O(n 3 ) is for matrix multiplications (A T S k\u22121 A) at each step.", "labels": [], "entities": [{"text": "O", "start_pos": 15, "end_pos": 16, "type": "METRIC", "confidence": 0.8462936282157898}]}, {"text": "A careful implementation, e.g., partial sums memoisation ( or fast matrix multiplications (), 1 can optimise this part further to O(dn 2 ) or O(n log 2 7 ), with d the average graph degree.", "labels": [], "entities": [{"text": "partial sums memoisation", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.5037918388843536}, {"text": "O", "start_pos": 130, "end_pos": 131, "type": "METRIC", "confidence": 0.9662480354309082}]}, {"text": "The second part O(log(1/\u01eb)) is the total number of steps required to guarantee a given accuracy \u01eb, because, as implied by, To the best of our knowledge, there is a paucity of work on optimising the second part O(log(1/\u01eb)).", "labels": [], "entities": [{"text": "O(log(1/\u01eb))", "start_pos": 16, "end_pos": 27, "type": "METRIC", "confidence": 0.9597602412104607}, {"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9986053109169006}, {"text": "O(log(1/\u01eb))", "start_pos": 210, "end_pos": 221, "type": "METRIC", "confidence": 0.9036645740270615}]}, {"text": "used a successive over-relaxation (SOR) method to reduce the number of steps for Simrank, which is also applicable to Co-Simrank.", "labels": [], "entities": []}, {"text": "However, this method requires a judicious choice of an internal parameter (i.e., relaxation factor \u03c9), which is hard to determine a-priori.", "labels": [], "entities": [{"text": "relaxation factor \u03c9)", "start_pos": 81, "end_pos": 101, "type": "METRIC", "confidence": 0.8586671650409698}]}, {"text": "Most recently,  propose an exponential model to speedup the convergence of Simrank: However, \u00af Sand S do not produce the same results.", "labels": [], "entities": []}, {"text": "Thus, this exponential model, if used to compute Co-Simrank, will lose some ranking accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.953895092010498}]}, {"text": "In this paper, we propose an efficient method, Co-Simmate, that computes all pairs of Co-Simranks in just O(log 2 (log(1/\u01eb))n 3 ) time, without any compromise inaccuracy.", "labels": [], "entities": []}, {"text": "In addition, Co-Simmate is parameter-free, and easy to implement.", "labels": [], "entities": []}, {"text": "It can also integrate the best-of-breed matrix decomposition based method by to achieve even higher efficiency.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use both real and synthetic datasets.", "labels": [], "entities": []}, {"text": "Three real graphs (Twitter, Email, Facebook) are taken from SNAP ().", "labels": [], "entities": []}, {"text": "1) Twitter is a who-follows-whom social graph crawled from the entire Twitter site.", "labels": [], "entities": []}, {"text": "Each node is a user, and each edge represents asocial relation.", "labels": [], "entities": []}, {"text": "2) Email is an Email communication network from Enron.", "labels": [], "entities": []}, {"text": "If an address i sent at least one email to address j, there is a link from i to j.", "labels": [], "entities": []}, {"text": "3) FB contains 'circles' (or 'friends lists') from Facebook.", "labels": [], "entities": [{"text": "FB", "start_pos": 3, "end_pos": 5, "type": "DATASET", "confidence": 0.7405158877372742}]}, {"text": "This dataset is collected from the survey participants using the Facebook app, including node features (profiles), circles, and ego networks.", "labels": [], "entities": []}, {"text": "To build synthetic data, we use Boost toolkit ().We control the number of nodes n and edges m to follow densification power laws ().", "labels": [], "entities": [{"text": "Boost toolkit", "start_pos": 32, "end_pos": 45, "type": "DATASET", "confidence": 0.8315723538398743}]}, {"text": "We compare our Co-Simmate with 1) Ite-Mat (), a Co-Simrank method using the dot product of Pagerank vectors.", "labels": [], "entities": []}, {"text": "2) K-Sim (), a linearized method modified to Co-Simrank.", "labels": [], "entities": []}, {"text": "3) Sig-SR (), a SVD Co-Simrank method.", "labels": [], "entities": []}, {"text": "All experiments are on 64bit Ubuntu 14.04 with Intel Xeon E2650 2.0GHz CPU and 16GB RAM.", "labels": [], "entities": []}, {"text": "We compare the number of steps k needed for Co-Simmate and CoSimrank (Ite-Mat) to attain a desired accuracy \u01eb on Twitter, Email, FB.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9989608526229858}, {"text": "Email", "start_pos": 122, "end_pos": 127, "type": "DATASET", "confidence": 0.9352715015411377}, {"text": "FB", "start_pos": 129, "end_pos": 131, "type": "DATASET", "confidence": 0.8567925095558167}]}, {"text": "The results on all the datasets are similar.", "labels": [], "entities": []}, {"text": "Due to space limits,(a) only reports the result on FB.", "labels": [], "entities": [{"text": "FB", "start_pos": 51, "end_pos": 53, "type": "DATASET", "confidence": 0.6439376473426819}]}, {"text": "We can discern that, when \u01eb varies from 0.01 to 1, k increases from 1 to 5 for Co-Simmate, but from 1 to 20 for Co-Simrank.", "labels": [], "entities": [{"text": "\u01eb", "start_pos": 26, "end_pos": 27, "type": "METRIC", "confidence": 0.9779550433158875}]}, {"text": "The fast convergence rate of Co-Simmate is due to our model that twice reuses R k\u22121 of the last step.", "labels": [], "entities": [{"text": "convergence", "start_pos": 9, "end_pos": 20, "type": "METRIC", "confidence": 0.9647680521011353}]}, {"text": "Total Computational Time.(b) compares the total computational time of CoSimmate with 3 best-known methods on real data.", "labels": [], "entities": []}, {"text": "The result shows Co-Simmate runs 10x, 5.6x, 4.3x faster than K-Sim, Ite-Mat, Sig-SR, respectively.", "labels": [], "entities": []}, {"text": "This is because 1) K-Sim is efficient only when a fraction pair of scores are computed, whereas CoSimmate can efficiently handle all pairs scores, by twice sharing R k\u22121 and repeated squaring A 2 k\u22121 . 2) Co-Simmate grasps exponential new terms of S per step, but Ite-Mat grasps just 1 new term of S.", "labels": [], "entities": []}, {"text": "3) Sig-SR does not adopt association tricks in the subspace, unlike our methods that integrate (9).", "labels": [], "entities": []}, {"text": "Effect of Damping Factor c.", "labels": [], "entities": [{"text": "Damping", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.8767300248146057}]}, {"text": "Using real datasets (Twitter, Email, FB), we next evaluate the effect of damping factor con the number of iterations k to guarantee a given accuracy \u01eb.", "labels": [], "entities": [{"text": "FB", "start_pos": 37, "end_pos": 39, "type": "DATASET", "confidence": 0.597184419631958}, {"text": "accuracy", "start_pos": 140, "end_pos": 148, "type": "METRIC", "confidence": 0.9989883303642273}]}, {"text": "We vary \u01eb from 0.1 to 0.00001 and c from 0.6 to 0.8, the results of k on all the datasets are similar.", "labels": [], "entities": []}, {"text": "For the interests of space,(c) tabularises only the results on FB, where 'SM' columns list the number of iterations required for Co-Simmate, and 'SR' columns lists that for Co-Simrank.", "labels": [], "entities": [{"text": "FB", "start_pos": 63, "end_pos": 65, "type": "DATASET", "confidence": 0.8766832947731018}]}, {"text": "From the results, we can see that, for any given \u01eb and c, the number of iterations for Co-Simmate is consistently smaller than that for Co-Simrank.", "labels": [], "entities": []}, {"text": "Their gap is more pronounced when \u01eb becomes smaller orc is increased.", "labels": [], "entities": [{"text": "\u01eb", "start_pos": 34, "end_pos": 35, "type": "METRIC", "confidence": 0.9943496584892273}]}, {"text": "This is because, at each iteration, Co-Simmate can grasp far more first terms of S than Co-Simrank.", "labels": [], "entities": []}, {"text": "Thus, fora fixed accuracy, CoSimmate requires less iterations than Co-Simrank.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9990400671958923}]}, {"text": "This is consistent with our analysis in Theorem 2.", "labels": [], "entities": []}, {"text": "By using synthetic datasets, we fix \u01eb = 0.0001 and vary n from 4,000 to 10,000.(d) depicts the total time of CoSimmate and Ite-Mat.", "labels": [], "entities": [{"text": "\u01eb", "start_pos": 36, "end_pos": 37, "type": "METRIC", "confidence": 0.9917974472045898}]}, {"text": "We can notice that, as n grows, the time of Co-Simmate does not increase so fast as Co-Simrank.", "labels": [], "entities": []}, {"text": "The reason is that the number of steps of Co-Simmate is greatly cut down by twice R k\u22121 sharing and A 2 k\u22121 memoisation.", "labels": [], "entities": []}, {"text": "Exp-V. Effect of Hop-u k . Finally, we test the impact of u on the total time of our hop-(u k ) CoSimmate variations on real datasets.", "labels": [], "entities": []}, {"text": "Due to similar results,(e) merely reports the results on FB.", "labels": [], "entities": [{"text": "FB", "start_pos": 57, "end_pos": 59, "type": "DATASET", "confidence": 0.5714018940925598}]}, {"text": "It can be observed that, as u grows from 2 to 6, the total number of steps for hop-(u k ) CoSimmate decreases, but their total time still grows.", "labels": [], "entities": []}, {"text": "This is because, in each step, the cost of hop-(u k ) Co-Simmate is increasing with u.", "labels": [], "entities": []}, {"text": "Thus, the lowest cost is Co-Simmate when u = 2.", "labels": [], "entities": []}], "tableCaptions": []}