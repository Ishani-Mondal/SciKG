{"title": [{"text": "Accurate Linear-Time Chinese Word Segmentation via Embedding Matching", "labels": [], "entities": [{"text": "Accurate Linear-Time Chinese Word Segmentation", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.5966848075389862}, {"text": "Embedding Matching", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.6622489392757416}]}], "abstractContent": [{"text": "This paper proposes an embedding matching approach to Chinese word segmenta-tion, which generalizes the traditional sequence labeling framework and takes advantage of distributed representations.", "labels": [], "entities": []}, {"text": "The training and prediction algorithms have linear-time complexity.", "labels": [], "entities": []}, {"text": "Based on the proposed model, a greedy segmenter is developed and evaluated on benchmark corpora.", "labels": [], "entities": []}, {"text": "Experiments show that our greedy segmenter achieves improved results over previous neural network-based word seg-menters, and its performance is competitive with state-of-the-art methods, despite its simple feature set and the absence of external resources for training.", "labels": [], "entities": []}], "introductionContent": [{"text": "Chinese sentences are written as character sequences without word delimiters, which makes word segmentation a prerequisite of Chinese language processing.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 90, "end_pos": 107, "type": "TASK", "confidence": 0.7064589560031891}, {"text": "Chinese language processing", "start_pos": 126, "end_pos": 153, "type": "TASK", "confidence": 0.6257528066635132}]}, {"text": "Since, most work has formulated Chinese word segmentation (CWS) as sequence labeling) with character position tags, which has lent itself to structured discriminative learning with the benefit of allowing rich features of segmentation configurations, including (i) context of character/word ngrams within local windows, (ii) segmentation history of previous characters, or the combinations of both.", "labels": [], "entities": [{"text": "Chinese word segmentation (CWS)", "start_pos": 32, "end_pos": 63, "type": "TASK", "confidence": 0.7748999247948328}]}, {"text": "These feature-based models still form the backbone of most state-of-the art systems.", "labels": [], "entities": []}, {"text": "Nevertheless, many feature weights in such models are inevitably poorly estimated because the number of parameters is so large with respect to the limited amount of training data.", "labels": [], "entities": []}, {"text": "This has motivated the introduction of low-dimensional, realvalued vectors, known as embeddings, as a tool to deal with the sparseness of the input.", "labels": [], "entities": []}, {"text": "Embeddings allow linguistic units appearing in similar contexts to share similar vectors.", "labels": [], "entities": []}, {"text": "The success of embeddings has been observed in many NLP tasks.", "labels": [], "entities": []}, {"text": "For CWS, and uses character embeddings in local windows as input fora two-layer network.", "labels": [], "entities": []}, {"text": "The network predicts individual character position tags, the transitions of which are learned separately.", "labels": [], "entities": []}, {"text": "also developed a similar architecture, which labels individual characters and uses character bigram embeddings as additional features to compensate the absence of sentence-level modeling.", "labels": [], "entities": []}, {"text": "improved upon by capturing the combinations of context and history via a tensor neural network.", "labels": [], "entities": []}, {"text": "Despite their differences, these CWS approaches are all sequence labeling models.", "labels": [], "entities": []}, {"text": "In such models, the target character can only influence the prediction as features.", "labels": [], "entities": []}, {"text": "Consider the the segmentation configuration in (1), where the dot appears before the target character in consideration and the box (2) represents any character that can occur in the configuration.", "labels": [], "entities": []}, {"text": "In that example, the known history is that the first two characters \u4e2d\u56fd 'China' are joined together, which is denoted by the underline.", "labels": [], "entities": []}, {"text": "(1) \u4e2d\u56fd\u00b72 \u683c\u5916 (where 2 \u2208 {\u98ce, \u89c4, ...}) (2) \u4e2d\u56fd\u98ce \u683c\u5916 'China-style especially' (3) \u4e2d\u56fd \u89c4\u683c \u5916 'besides Chinese spec.'", "labels": [], "entities": []}, {"text": "For possible target characters, \u98ce 'wind' and \u89c4 'rule', the correct segmentation decisions for them are opposite, as shown in (2) and (3), respectively.", "labels": [], "entities": []}, {"text": "In order to correctly predict both, current models can set higher weights for target character-specific features.", "labels": [], "entities": []}, {"text": "However, in general, \u98ce is more likely to start anew word instead of joining the existing one as in this example.", "labels": [], "entities": []}, {"text": "Given such conflicting evidence, models can rarely find optimal feature weights, if they exist at all.", "labels": [], "entities": []}, {"text": "The crux of this conflicting evidence problem is that similar configurations can suggest opposite decisions, depending on the target character and vice versa.", "labels": [], "entities": []}, {"text": "Thus it might be useful to treat segmentation decisions for distinct characters separately.", "labels": [], "entities": []}, {"text": "And instead of predicting general segmentation decisions given configurations, it could be beneficial to model the matching between configurations and character-specific decisions.", "labels": [], "entities": [{"text": "predicting general segmentation", "start_pos": 15, "end_pos": 46, "type": "TASK", "confidence": 0.7896788914998373}]}, {"text": "To this end, this paper proposes an embedding matching approach (Section 2) to CWS, in which embeddings for both input and output are learned and used as representations to counteract sparsities.", "labels": [], "entities": []}, {"text": "Thanks to embeddings of characterspecific decisions (actions) serving as both input features and output, our hidden-layer-free architecture (Section 2.2) is capable of capturing prediction histories in similar ways as the hidden layers in recurrent neural networks.", "labels": [], "entities": []}, {"text": "We evaluate the effectiveness of the model via a linear-time greedy segmenter (Section 3) implementation.", "labels": [], "entities": []}, {"text": "The segmenter outperforms previous embedding-based models (Section 4.2) and achieves state-of-the-art results (Section 4.3) on a benchmark dataset.", "labels": [], "entities": []}, {"text": "The main contributions of this paper are: \u2022 A novel embedding matching model for Chinese word segmentation.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 81, "end_pos": 106, "type": "TASK", "confidence": 0.6035538415114085}]}, {"text": "\u2022 Developing a greedy word segmenter, which is based on the matching model and achieves competitive results.", "labels": [], "entities": [{"text": "word segmenter", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.7392964065074921}]}, {"text": "\u2022 Introducing the idea of character-specific segmentation action embeddings as both feature and output, which are cornerstones of the model and the segmenter.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the experiments, we use two widely used and freely available 1 manually word-segmented corpora, namely, PKU and MSR, from the second SIGHAN international Chinese word segmentation bakeoff.", "labels": [], "entities": [{"text": "SIGHAN international Chinese word segmentation bakeoff", "start_pos": 136, "end_pos": 190, "type": "TASK", "confidence": 0.7384433547655741}]}, {"text": "Character types 5 \u00d7 10 3 5 \u00d7 10 3 Character tokens 1.8 \u00d7 10 6 4.1 \u00d7 10 6 The segmentation accuracy is evaluated by precision (P ), recall (R), F-score and R oov , the recall for out-of-vocabulary words.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 77, "end_pos": 89, "type": "TASK", "confidence": 0.9450702667236328}, {"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9162223935127258}, {"text": "precision (P )", "start_pos": 115, "end_pos": 129, "type": "METRIC", "confidence": 0.9520544856786728}, {"text": "recall (R)", "start_pos": 131, "end_pos": 141, "type": "METRIC", "confidence": 0.9572808742523193}, {"text": "F-score", "start_pos": 143, "end_pos": 150, "type": "METRIC", "confidence": 0.9848345518112183}, {"text": "R oov", "start_pos": 155, "end_pos": 160, "type": "METRIC", "confidence": 0.9218047261238098}, {"text": "recall", "start_pos": 167, "end_pos": 173, "type": "METRIC", "confidence": 0.9960745573043823}]}, {"text": "Precision is defined as the number of correctly segmented words divided by the total number of words in the segmentation result.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9660996794700623}]}, {"text": "Recall is defined as the number of correctly segmented words divided by the total number of words in the gold standard segmentation.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9472188353538513}]}, {"text": "In particular, R oov reflects the model generalization ability.", "labels": [], "entities": [{"text": "R oov", "start_pos": 15, "end_pos": 20, "type": "METRIC", "confidence": 0.9352298378944397}]}, {"text": "The metric for overall performance, the evenly-weighted F-score is calculated as in: To comply with CWS evaluation conventions and make comparisons fair, we distinguish the following two settings: \u2022 closed-set: no extra resource other than training corpora is used.", "labels": [], "entities": [{"text": "F-score", "start_pos": 56, "end_pos": 63, "type": "METRIC", "confidence": 0.9769946336746216}]}, {"text": "\u2022 open-set: additional lexicon, raw corpora, etc are used.", "labels": [], "entities": []}, {"text": "We will report the final results of our model 3 on PKU and MSR corpora in comparison with previous embedding based models (Section 4.2) and state-of-the-art systems (Section 4.3), before going into detailed experiments for model analyses (Section 4.5).", "labels": [], "entities": [{"text": "PKU and MSR corpora", "start_pos": 51, "end_pos": 70, "type": "DATASET", "confidence": 0.6972436010837555}]}, {"text": "shows the results of our greedy segmenter on the PKU and MSR datasets, which are compared with embedding-based segmenters in previous studies.", "labels": [], "entities": [{"text": "PKU", "start_pos": 49, "end_pos": 52, "type": "DATASET", "confidence": 0.9360188245773315}, {"text": "MSR datasets", "start_pos": 57, "end_pos": 69, "type": "DATASET", "confidence": 0.8943929672241211}]}, {"text": "In the table, results for both closedset and open-set setting are shown for previous models.", "labels": [], "entities": []}, {"text": "In the open-set evaluations, all three previous work use pre-training to train character ngram embeddings from large unsegmented corpora to initialize the embeddings, which will be later trained with the manually word-segmented training data.", "labels": [], "entities": []}, {"text": "For our model, we report the closeset results only, as pre-training does not significant improve the results in our experiments (Section 4.5).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Corpus details of PKU and MSR", "labels": [], "entities": [{"text": "PKU", "start_pos": 28, "end_pos": 31, "type": "DATASET", "confidence": 0.8941124677658081}, {"text": "MSR", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.6051207780838013}]}, {"text": " Table 3: Comparison with previous embedding based models. Numbers in percentage. Results with  \u2020  used extra corpora for (pre-)training.", "labels": [], "entities": [{"text": "Numbers", "start_pos": 59, "end_pos": 66, "type": "METRIC", "confidence": 0.9694812297821045}]}, {"text": " Table 4: Significance test of closed-set results of  Pei et al (2014) and our model.", "labels": [], "entities": []}, {"text": " Table 5: Comparison with the state-of-the-art sys- tems. Results with  \u2020 used extra lexicon/raw cor- pora for training, i.e. in open-set setting. Best05  refers to the best closed-set results in 2nd SIGHAN  bakeoff.", "labels": [], "entities": [{"text": "2nd SIGHAN  bakeoff", "start_pos": 196, "end_pos": 215, "type": "DATASET", "confidence": 0.68057448665301}]}, {"text": " Table 6: The influence of features. F-score in per- centage on the PKU corpus.", "labels": [], "entities": [{"text": "F-score", "start_pos": 37, "end_pos": 44, "type": "METRIC", "confidence": 0.9979655742645264}, {"text": "PKU corpus", "start_pos": 68, "end_pos": 78, "type": "DATASET", "confidence": 0.9393717348575592}]}]}