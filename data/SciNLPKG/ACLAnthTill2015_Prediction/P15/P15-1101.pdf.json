{"title": [{"text": "Sentence-level Emotion Classification with Label and Context Dependence \uf020", "labels": [], "entities": [{"text": "Sentence-level Emotion Classification", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7138831317424774}]}], "abstractContent": [{"text": "Predicting emotion categories, such as anger, joy, and anxiety, expressed by a sentence is challenging due to its inherent multi-label classification difficulty and data sparseness.", "labels": [], "entities": []}, {"text": "In this paper, we address above two challenges by incorporating the label dependence among the emotion labels and the context dependence among the contextual instances into a factor graph model.", "labels": [], "entities": []}, {"text": "Specifically, we recast sentence-level emotion classification as a factor graph inferring problem in which the label and context dependence are modeled as various factor functions.", "labels": [], "entities": [{"text": "sentence-level emotion classification", "start_pos": 24, "end_pos": 61, "type": "TASK", "confidence": 0.68286860982577}]}, {"text": "Empirical evaluation demonstrates the great potential and effectiveness of our proposed approach to sentence-level emotion classification.", "labels": [], "entities": [{"text": "sentence-level emotion classification", "start_pos": 100, "end_pos": 137, "type": "TASK", "confidence": 0.6673292915026346}]}], "introductionContent": [{"text": "Predicting emotion categories, such as anger, joy, and anxiety, expressed by apiece of text encompasses a variety of applications, such as online chatting (, news classification () and stock marketing).", "labels": [], "entities": [{"text": "news classification", "start_pos": 158, "end_pos": 177, "type": "TASK", "confidence": 0.7391654998064041}]}, {"text": "Over the past decade, there has been a substantial body of research on emotion classification, where a considerable amount of work has focused on document-level emotion classification.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 71, "end_pos": 93, "type": "TASK", "confidence": 0.7445822656154633}, {"text": "document-level emotion classification", "start_pos": 146, "end_pos": 183, "type": "TASK", "confidence": 0.6458922525246938}]}, {"text": "Recently, the research community has become increasingly aware of the need on sentence-level emotion classification due to its wide potential applications, e.g. the massively growing importance of analyzing short text in social media).", "labels": [], "entities": [{"text": "sentence-level emotion classification", "start_pos": 78, "end_pos": 115, "type": "TASK", "confidence": 0.6343375146389008}]}, {"text": "In general, sentence-level emotion classification exhibits two challenges.", "labels": [], "entities": [{"text": "sentence-level emotion classification", "start_pos": 12, "end_pos": 49, "type": "TASK", "confidence": 0.6972813407580057}]}], "datasetContent": [{"text": "We have systematically evaluated our DFG approach to sentence-level emotion classification.", "labels": [], "entities": [{"text": "sentence-level emotion classification", "start_pos": 53, "end_pos": 90, "type": "TASK", "confidence": 0.6510122021039327}]}, {"text": "In our study, we employ three evaluation metrics to measure the performances of different approaches to sentence-level emotion classification.", "labels": [], "entities": [{"text": "sentence-level emotion classification", "start_pos": 104, "end_pos": 141, "type": "TASK", "confidence": 0.6684601803620657}]}, {"text": "These metrics have been popularly used in some multi-label classification problems ().", "labels": [], "entities": [{"text": "multi-label classification", "start_pos": 47, "end_pos": 73, "type": "TASK", "confidence": 0.7973493933677673}]}, {"text": "In this section, we compare following approaches which only consider the label dependence among pseudo instances: \uf0d8 Baseline: As a baseline, this approach applies a maximum entropy (ME) classifier with only textual features, ignoring both the label and context dependence.", "labels": [], "entities": []}, {"text": "\uf0d8 LabelD: As the state-of-the-art approach to handling multi-label classification, this approach incorporates label dependence, as described in ().", "labels": [], "entities": [{"text": "multi-label classification", "start_pos": 55, "end_pos": 81, "type": "TASK", "confidence": 0.7387838363647461}]}, {"text": "Specifically, this approach first utilizes a Bayesian network to infer the relationship among the labels and then employ them in the classifier.", "labels": [], "entities": []}, {"text": "\uf0d8 DFG-label: Our DFG approach with the label dependence.", "labels": [], "entities": [{"text": "\uf0d8", "start_pos": 0, "end_pos": 1, "type": "DATASET", "confidence": 0.8787384629249573}, {"text": "DFG-label", "start_pos": 2, "end_pos": 11, "type": "DATASET", "confidence": 0.5378533601760864}]}, {"text": "compares the performance of different approaches to sentence-level emotion classification with the label dependence.", "labels": [], "entities": [{"text": "sentence-level emotion classification", "start_pos": 52, "end_pos": 89, "type": "TASK", "confidence": 0.6746354003747305}]}, {"text": "From this figure, we can see that our DFG approach improves the baseline approach with an impressive improvement in all three kinds of evaluation metrics, i.e., 23.5% reduction in Hloss, 25.6% increase in Accuracy, and 11.8% increase in F1.", "labels": [], "entities": [{"text": "Hloss", "start_pos": 180, "end_pos": 185, "type": "METRIC", "confidence": 0.9939576387405396}, {"text": "Accuracy", "start_pos": 205, "end_pos": 213, "type": "METRIC", "confidence": 0.9988262057304382}, {"text": "F1", "start_pos": 237, "end_pos": 239, "type": "METRIC", "confidence": 0.9997170567512512}]}, {"text": "This result verifies the effectiveness of incorporating the label dependence in sentence-level emotion classification.", "labels": [], "entities": [{"text": "sentence-level emotion classification", "start_pos": 80, "end_pos": 117, "type": "TASK", "confidence": 0.6602723598480225}]}, {"text": "Compared to the state-of-the-art LabelD approach, our DFG approach is much superior.", "labels": [], "entities": []}, {"text": "Significant test show that our DFG approach significantly outperforms both the baseline approach and LabelD (p-value<0.01).", "labels": [], "entities": []}, {"text": "One reason that LabelD performs worse than our approach is possibly due to their separating learning on textual features and label relationships.", "labels": [], "entities": []}, {"text": "Also, different from ours, their approach could not capture the information between two conflict emotion labels, such as \"happy\" and \"sad\" (they are not possibly appearing together).", "labels": [], "entities": []}, {"text": "In this section, we compare following approaches which only consider the context dependence among pseudo instances: \uf0d8 Baseline: same as the one in Section 5.2, which applies a maximum entropy (ME) classifier with only textual features, ignoring both the label and context dependence.", "labels": [], "entities": []}, {"text": "\uf0d8 Transfer: As the state-of-the-art approach to incorporating contextual information in sentence-level emotion classification (, this approach utilizes the label transformation probability to refine the classification results.", "labels": [], "entities": [{"text": "\uf0d8 Transfer", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.8338893055915833}, {"text": "sentence-level emotion classification", "start_pos": 88, "end_pos": 125, "type": "TASK", "confidence": 0.6604078809420267}]}, {"text": "\uf0d8 DFG-label (Neighbor): Our DFG approach with the context dependence only.", "labels": [], "entities": [{"text": "\uf0d8", "start_pos": 0, "end_pos": 1, "type": "DATASET", "confidence": 0.8572343587875366}, {"text": "DFG-label", "start_pos": 2, "end_pos": 11, "type": "DATASET", "confidence": 0.5441519021987915}]}, {"text": "Specifically, the neighboring instances are considered as context.", "labels": [], "entities": []}, {"text": "\uf0d8 DFG-label (Paragraph): Our DFG approach with the context dependence only.", "labels": [], "entities": [{"text": "\uf0d8", "start_pos": 0, "end_pos": 1, "type": "DATASET", "confidence": 0.8658387064933777}, {"text": "DFG-label", "start_pos": 2, "end_pos": 11, "type": "DATASET", "confidence": 0.5475318431854248}]}, {"text": "Specifically, the instances in the same paragraph are considered as context.", "labels": [], "entities": []}, {"text": "\uf0d8 DFG-label (Document): Our DFG approach with the context dependence only.", "labels": [], "entities": [{"text": "\uf0d8", "start_pos": 0, "end_pos": 1, "type": "DATASET", "confidence": 0.8137227296829224}, {"text": "DFG-label", "start_pos": 2, "end_pos": 11, "type": "DATASET", "confidence": 0.47592893242836}]}, {"text": "Specifically, the instances in the same document are considered as context.", "labels": [], "entities": []}, {"text": "compares the performance of different approaches to sentence-level emotion classification with the context dependence only.", "labels": [], "entities": [{"text": "sentence-level emotion classification", "start_pos": 52, "end_pos": 89, "type": "TASK", "confidence": 0.6783778170744578}]}, {"text": "From this figure, we can see that our DFG approach consistently improves the state-of-the-art in all three kinds of evaluation metrics, i.e., 6.1% reduction in Hloss, 6.5% increase in Accuracy, and 3.1% increase in F1 when the neighboring instances are considered as context.", "labels": [], "entities": [{"text": "Hloss", "start_pos": 160, "end_pos": 165, "type": "METRIC", "confidence": 0.953416109085083}, {"text": "Accuracy", "start_pos": 184, "end_pos": 192, "type": "METRIC", "confidence": 0.998457670211792}, {"text": "F1", "start_pos": 215, "end_pos": 217, "type": "METRIC", "confidence": 0.9996515512466431}]}, {"text": "Among the three kinds of context, the neighboring setting performs best.", "labels": [], "entities": []}, {"text": "We also find that using the whole document as the context is not helpful and it performs even worse than the baseline approach.", "labels": [], "entities": []}, {"text": "Compared to the stateof-the-art Transfer approach, our DFG approach with the neighboring context dependence is much superior.", "labels": [], "entities": []}, {"text": "Significant test show that our DFG approach with the neighboring context dependence significantly outperforms the baseline approach and the state-of-the-art LabelD approach (pvalue<0.01).", "labels": [], "entities": []}, {"text": "shows the performance of our DFG approach with both label and context dependence, denoted as DGF-both.", "labels": [], "entities": []}, {"text": "From this table, we can see that using both label and context dependence further improves the performance.", "labels": [], "entities": []}, {"text": "shows the performance of our DGFboth approach when different sizes of training data are used to train the model.", "labels": [], "entities": []}, {"text": "From this figure, we can see that incorporating both the label and context dependence consistently improves the performance with a large margin, irrespective of the amount of training data available.: Performance of our DGF-both approach when different sizes of training data are used", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The numbers of the sentences in each  emotion category", "labels": [], "entities": []}, {"text": " Table 2: The numbers of the sentences  grouped by the emotion labels they contain", "labels": [], "entities": []}, {"text": " Table 3: Performance of our DFG approach  with both label and context dependence", "labels": [], "entities": []}]}