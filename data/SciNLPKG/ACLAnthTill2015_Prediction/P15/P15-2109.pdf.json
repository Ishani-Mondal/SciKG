{"title": [{"text": "The Discovery of Natural Typing Annotations: User-produced Potential Chinese Word Delimiters", "labels": [], "entities": []}], "abstractContent": [{"text": "Human labeled corpus is indispensable for the training of supervised word segmenters.", "labels": [], "entities": [{"text": "word segmenters", "start_pos": 69, "end_pos": 84, "type": "TASK", "confidence": 0.7314773797988892}]}, {"text": "However, it is time-consuming and labor-intensive to label corpus manually.", "labels": [], "entities": []}, {"text": "During the process of typing Chinese text by Pingyin, people usually need to type \"space\" or numeric keys to choose the words due to homo-phones, which can be viewed as a cue for segmentation.", "labels": [], "entities": []}, {"text": "We argue that such a process can be used to build a labeled corpus in a more natural way.", "labels": [], "entities": []}, {"text": "Thus, in this paper, we investigate Natural Typing Annotations (NTAs) that are potential word delimiters produced by users while typing Chinese.", "labels": [], "entities": []}, {"text": "A detailed analysis on over three hundred user-produced texts containing NTAs reveals that high-quality NTAs mostly agree with gold seg-mentation and, consequently, can be used for improving the performance of supervised word segmentation model in out-of-domain.", "labels": [], "entities": [{"text": "supervised word segmentation", "start_pos": 210, "end_pos": 238, "type": "TASK", "confidence": 0.6453849673271179}]}, {"text": "Experiments show that a classification model combined with a voting mechanism can reliably identify the high-quality NTAs texts that are more readily available labeled corpus.", "labels": [], "entities": []}, {"text": "Furthermore, the NTAs might be particularly useful to deal with out-of-vocabulary (OOV) words such as proper names and neo-logisms.", "labels": [], "entities": []}], "introductionContent": [{"text": "Unlike English text in which sentences are sequences of words delimited by white spaces, in Chinese text, sentences are usually represented and stored as strings of Chinese characters without similar natural delimiters.", "labels": [], "entities": []}, {"text": "To find the basic language units, i.e. words, segmentation is a necessary initial step for Chinese language processing.", "labels": [], "entities": [{"text": "Chinese language processing", "start_pos": 91, "end_pos": 118, "type": "TASK", "confidence": 0.6892085274060568}]}, {"text": "Currently most of state-of-the-art methods for Chinese word segmentation (CWS) are based on supervised learning, which depend on large scale annotated corpus.", "labels": [], "entities": [{"text": "Chinese word segmentation (CWS)", "start_pos": 47, "end_pos": 78, "type": "TASK", "confidence": 0.7731589078903198}]}, {"text": "These supervised methods obtain high accuracies on newswire).", "labels": [], "entities": [{"text": "accuracies", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.9817081689834595}]}, {"text": "However, manually annotated training data mostly come from the news domain, and the performance can drop severely when the test data shift from newswire to blogs, computer forums, and Internet literature (.Supervised approaches often have a high requirement on the quality and quantity of annotated corpus, which is always not easy to build.", "labels": [], "entities": []}, {"text": "As a result, many previous methods utilize the information of free data which contain limited but useful segmentation information over the Internet, including large-scale unlabeled data, domain-specific lexicons and semi-annotated web pages such as Wikipedia.", "labels": [], "entities": []}, {"text": "There has been work on making use of both unlabeled data () and Wikipedia () to improve segmentation.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 64, "end_pos": 73, "type": "DATASET", "confidence": 0.9287017583847046}, {"text": "segmentation", "start_pos": 88, "end_pos": 100, "type": "TASK", "confidence": 0.9616860747337341}]}, {"text": "But none of them notice the segmentation information produced by users while typing Chinese.", "labels": [], "entities": []}, {"text": "Chinese is unique due to its logographic writing system.", "labels": [], "entities": []}, {"text": "Chinese users cannot directly type in Chinese words using a QWERTY keyboard.", "labels": [], "entities": []}, {"text": "Input methods have been proposed to assist users to type in Chinese words.", "labels": [], "entities": []}, {"text": "Substantial information has been produced, but not recorded and stored during text typing process.", "labels": [], "entities": []}, {"text": "The typical way to type in Chinese words is in a sequential manner ().", "labels": [], "entities": [{"text": "type in Chinese words", "start_pos": 19, "end_pos": 40, "type": "TASK", "confidence": 0.8449207097291946}]}, {"text": "iRearch showed that Pinyin input methods have the biggest share of Chinese speakers.", "labels": [], "entities": [{"text": "iRearch", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9508325457572937}]}, {"text": "We take one of them for example.", "labels": [], "entities": []}, {"text": "Suppose users want to type in Chinese word \" \u4eca\u5929(today)\".", "labels": [], "entities": []}, {"text": "Firstly, they mentally generate and physically type in corresponding Pinyin \"jintian\".", "labels": [], "entities": []}, {"text": "Then, a Chinese Pinyin input method displays a list of Chinese homophones, as shown in.", "labels": [], "entities": []}, {"text": "Finally, users visually search the target word from candidates and select numeric key, e.g. '1'-'9'(<NUM#1>-<NUM#9>) or space key (<SPACE>, a shortcut for numeric key '1') to get the target word).", "labels": [], "entities": []}, {"text": "Other Chinese input methods, like Wubi, also take these three steps.", "labels": [], "entities": []}, {"text": "Typing English words does not involve the last two steps, which indicates that it is on one side more complicated for Chinese users to type in Chinese words than English, but on the other side more convenient for us to obtain additional information produced by users in typing process.", "labels": [], "entities": [{"text": "Typing English words", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8788902958234152}]}, {"text": "We define numeric keys and the space key as selection keys for choosing the target word.", "labels": [], "entities": []}, {"text": "For sentence \"\u4eca\u5929\u5929 \u6c14\u4e0d\u9519\u3002(Nice weather today.)\"\uff0cone general sequence with selection keys is like \" \u4eca\u5929 (today)<SPACE>\u5929\u6c14(weather)<NUM#2>\u4e0d\u9519 (not bad)<SPACE>\u3002\" or \"\u4eca\u5929 (today) <SPA-CE>\u5929\u6c14\u4e0d\u9519 (weather is not bad) <SPACE>\u3002\"", "labels": [], "entities": []}, {"text": "Ina certain sense, these user-produced selection keys play a role of word delimiters in a very natural way.", "labels": [], "entities": []}, {"text": "In this paper, we propose the concept of Natural Typing Annotations (NTAs) that are potential word delimiters produced by users while typing Chinese words, and verify that it is plausible to automatically generate labeled data for CWS by exploiting NTAs.", "labels": [], "entities": []}, {"text": "According to the principle of statistical sampling, texts with NTAs are gathered from 384 users.", "labels": [], "entities": []}, {"text": "Specifically, since the ultimate goal is to exploit NTAs to automatically generate labeled data for word segmentation, the main task is to select high-quality NTAs, which largely overlap with gold segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 100, "end_pos": 117, "type": "TASK", "confidence": 0.7480738759040833}]}, {"text": "We do this by 1) training a classifier to distinguish acceptable-quality NTAs from low-quality ones, and then 2) using a voting mechanism to further locate the high-quality NTAs among those identified by the classifier in the first step.", "labels": [], "entities": []}, {"text": "Experiments show that Support Vector Machine (SVM) and voting mechanism are effective for this work and the high-quality NTAs texts can be used as the training data for improving the performance of supervised word segmentation model in outof-domain.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 209, "end_pos": 226, "type": "TASK", "confidence": 0.704118400812149}]}, {"text": "In addition, some evidence is provided that user-produced NTAs might be particularly useful to deal with out-of-vocabulary (OOV) words.", "labels": [], "entities": []}, {"text": "In the rest of the paper, we briefly introduce the gold standard and baseline segmenter of our work in section 2, then describe the definition and characteristic of natural typing annotations (NTAs) in section 3, and finally elaborate on the strategy of locating high-quality NTAs texts in section 4.After giving the experimental results and analysis in section 5, we come to the conclusion and the implication of future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We randomly select 32 NTAs texts that contain 1,089 sentences, and then manually label them to form training set.", "labels": [], "entities": []}, {"text": "Taking 1 S mentioned in 4.1 as an example, the manual-labeled training data are shown in table 1.", "labels": [], "entities": []}, {"text": "The label 1 and 0 represent acceptable-quality and low-quality NTAs sentence separately.", "labels": [], "entities": []}, {"text": "According to voting mechanism in section 4.3, every acceptable-quality NTAs text can get a score to rank itself.", "labels": [], "entities": []}, {"text": "Table3 shows top three highquality NTAs texts with their user-produced word segmentation results compared with that of CRF+MSR.", "labels": [], "entities": []}, {"text": "Because CRF+MSR is a general-purpose segmenter and test data does not come from news wire, its performance drops significantly in out-of-domain.", "labels": [], "entities": [{"text": "CRF+MSR", "start_pos": 8, "end_pos": 15, "type": "DATASET", "confidence": 0.7091275652249655}]}, {"text": "suggests that high-quality NTAs texts are very close to gold standard of word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 73, "end_pos": 90, "type": "TASK", "confidence": 0.7093566954135895}]}, {"text": "To discover the causes of errors, we manually inspected these three texts and found the major error is adhesive phenomenon between simple words.", "labels": [], "entities": []}, {"text": "For example, gold segmentation \"|\u8fd9|\u51e0|\u6b3e|\" is formed as \"|\u8fd9\u51e0\u6b3e|\" by users.", "labels": [], "entities": [{"text": "gold segmentation", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.6652984619140625}]}, {"text": "This is an error in word segmentation competition, but in some application scenarios, like machine translation, \"|\u8fd9\u51e0\u6b3e|\"is better than \"|\u8fd9|\u51e0 |\u6b3e|\".", "labels": [], "entities": [{"text": "word segmentation competition", "start_pos": 20, "end_pos": 49, "type": "TASK", "confidence": 0.8509909311930338}, {"text": "machine translation", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.7898666858673096}]}, {"text": "Similar phenomena shed light on understanding what a \"word\" really is.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: examples of training data for classifier.  Package of libSVM (Chang and Lin, 2011) is  used here. Radial basis function is adopted as the  kernel function where gamma value is set to  1/num_features and cost value is 1.  10-fold cross validation is used to validate the  results. The 1,089 sentences are partitioned into  ten parts randomly. Ten runs are performed with  each run using a different part as the testing set.  It is conducted ten times and every part should  be testing set once. Classification accuracy of the  experiment is listed in the table 2.", "labels": [], "entities": [{"text": "Radial basis function", "start_pos": 108, "end_pos": 129, "type": "METRIC", "confidence": 0.9457673033078512}, {"text": "accuracy", "start_pos": 519, "end_pos": 527, "type": "METRIC", "confidence": 0.8336865305900574}]}, {"text": " Table 2: 10-fold cross validation results.  Since the results indicate the validity of our  classification approach, we use this classifier to  handle collected NTAs texts. If 85% of sentences  in a text are acceptable-quality, we select this  text as acceptable-quality NTAs text. Finally, we  obtain 211 acceptable-quality NTAs texts from  all 384 collected ones.", "labels": [], "entities": []}, {"text": " Table 3: Test text word segmentation results  from general-purpose segmenter and top 3 texts.", "labels": [], "entities": [{"text": "Test text word segmentation", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.590679332613945}]}, {"text": " Table 4: Segmenters' results on test data.  We also find out that the NTAs might be par- ticularly useful to identify OOV words, such as  proper names and neo-logisms. If users frequent- ly put some characters in one segment, this seg- ment may be some new word or the new internet  slang, such as \"\u767d\u5bcc\u7f8e(white, rich and pretty) \",  \" \u840c\u840c\u54d2(very cute)\", \" \u5341 \u52a8 \u7136 \u62d2 (someone is  moved but refuses to become girl/boyfriend)\",  etc.", "labels": [], "entities": []}]}