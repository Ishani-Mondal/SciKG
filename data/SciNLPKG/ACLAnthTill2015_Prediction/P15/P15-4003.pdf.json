{"title": [{"text": "In-tool Learning for Selective Manual Annotation in Large Corpora", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a novel approach to the selective annotation of large corpora through the use of machine learning.", "labels": [], "entities": []}, {"text": "Linguistic search engines used to locate potential instances of an infrequent phenomenon do not support ranking the search results.", "labels": [], "entities": []}, {"text": "This favors the use of high-precision queries that return only a few results over broader queries that have a higher recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 117, "end_pos": 123, "type": "METRIC", "confidence": 0.9983104467391968}]}, {"text": "Our approach introduces a classifier used to rank the search results and thus helping the annotator focus on those results with the highest potential of being an instance of the phenomenon in question, even in low-precision queries.", "labels": [], "entities": []}, {"text": "The clas-sifier is trained in an in-tool fashion, except for preprocessing relying only on the manual annotations done by the users in the querying tool itself.", "labels": [], "entities": []}, {"text": "To implement this approach, we build upon CSniper 1 , a web-based multiuser search and annotation tool.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the rapidly growing body of digitally available language data, it becomes possible to investigate phenomena of the language system that manifest themselves infrequently in corpus data, e.g. non-canonical constructions.", "labels": [], "entities": []}, {"text": "To pinpoint occurrences of such phenomena and to annotate them requires anew kind of annotation tool, since manual, sequential annotation is not feasible anymore for large amounts of texts.", "labels": [], "entities": []}, {"text": "An annotation-by-query approach to identify such phenomena in large corpora is implemented To enable a selective manual annotation process, a linguistic search engine is used, allowing the creation of queries which single out potential instances of the phenomenon in question.", "labels": [], "entities": []}, {"text": "Those potential instances are then displayed to the user, who annotates each one as being an instance of the phenomenon or not.", "labels": [], "entities": []}, {"text": "This process of searching and annotating can be performed by multiple users concurrently; the annotations are stored for each user separately.", "labels": [], "entities": []}, {"text": "Ina subsequent evaluation step, a user can review the annotations of all users, e.g. to discard a query if it yields unsatisfying results.", "labels": [], "entities": []}, {"text": "Finally, the annotations of multiple users can be merged into a gold standard.", "labels": [], "entities": []}, {"text": "This approach relieves the annotator from having to read through the corpus from the beginning to the end to look for instances of a phenomenon.", "labels": [], "entities": []}, {"text": "However, the search may yield many results that may superficially appear to bean instance of the desired phenomenon, but due to ambiguities or due to a broadly defined query only a small subset maybe actual instances.", "labels": [], "entities": []}, {"text": "This still leaves the annotator with the tedious task of clicking through the search results to mark the true instances.", "labels": [], "entities": []}, {"text": "To reduce the time and effort required, we present an extension of the annotation-by-query approach) that introduces a ranking of the query results (Section 2) by means of machine learning; we order the results by confidence of the used classifier.", "labels": [], "entities": []}, {"text": "To obtain a model for the classifier, we employ an in-tool learning approach, where we learn from the annotations that are made by users in the tool itself.", "labels": [], "entities": []}, {"text": "This makes our ranking approach useful for highly specific tasks, since no pre-trained models are needed.", "labels": [], "entities": []}, {"text": "Finally we demonstrate the viability of our concept by the example task of finding non-canonical constructions in Section 3.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Precision for various NCC queries (Baseline) and for using the SVM with 10%, 50% and 90%  training data.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9972230195999146}]}]}