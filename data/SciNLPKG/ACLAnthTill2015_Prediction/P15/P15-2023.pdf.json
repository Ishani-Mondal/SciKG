{"title": [{"text": "Discriminative Preordering Meets Kendall's \u03c4 Maximization", "labels": [], "entities": [{"text": "Kendall's \u03c4", "start_pos": 33, "end_pos": 44, "type": "DATASET", "confidence": 0.7803014914194742}, {"text": "Maximization", "start_pos": 45, "end_pos": 57, "type": "TASK", "confidence": 0.5655038952827454}]}], "abstractContent": [{"text": "This paper explores a simple discrimina-tive preordering model for statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 67, "end_pos": 98, "type": "TASK", "confidence": 0.7239774068196615}]}, {"text": "Our model traverses binary constituent trees, and classifies whether children of each node should be reordered.", "labels": [], "entities": []}, {"text": "The model itself is not extremely novel, but herein we introduce anew procedure to determine oracle labels so as to maximize Kendall's \u03c4.", "labels": [], "entities": [{"text": "maximize Kendall's \u03c4", "start_pos": 116, "end_pos": 136, "type": "METRIC", "confidence": 0.6441364139318466}]}, {"text": "Experiments in Japanese-to-English translation revealed that our simple method is comparable with, or superior to, state-of-the-art methods in translation accuracy.", "labels": [], "entities": [{"text": "Japanese-to-English translation", "start_pos": 15, "end_pos": 46, "type": "TASK", "confidence": 0.6582344472408295}, {"text": "translation", "start_pos": 143, "end_pos": 154, "type": "TASK", "confidence": 0.9528809189796448}, {"text": "accuracy", "start_pos": 155, "end_pos": 163, "type": "METRIC", "confidence": 0.8696309328079224}]}], "introductionContent": [{"text": "Current statistical machine translation systems suffer from major accuracy degradation in distant languages, primarily because they utilize exceptionally dissimilar word orders.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 8, "end_pos": 39, "type": "TASK", "confidence": 0.6321946084499359}, {"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9976096153259277}]}, {"text": "One promising solution to this problem is preordering, in which source sentences are reordered to resemble the target language word orders, after which statistical machine translation is applied to reordered sentences ().", "labels": [], "entities": []}, {"text": "This is particularly effective for distant language pairs such as English and Japanese ().", "labels": [], "entities": []}, {"text": "Among such preordering, one of the simplest and straightforward model is a discriminative preordering model (, which classifies whether children of each constituent node should be reordered, given binary trees.", "labels": [], "entities": []}, {"text": "This simple model has, however, difficulty to find oracle labels.", "labels": [], "entities": []}, {"text": "proposed a method to approximate oracle labels along dependency trees.", "labels": [], "entities": []}, {"text": "The present paper proposes anew procedure to find oracle labels.", "labels": [], "entities": []}, {"text": "The main idea is simple: we It is also possible to use n-ary trees (), but we keep this binary model for simplicity.", "labels": [], "entities": []}, {"text": "determine reordering decisions in away that maximizes Kendall's \u03c4 of word alignments.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 69, "end_pos": 84, "type": "TASK", "confidence": 0.6294860392808914}]}, {"text": "We prove that our procedure guarantees the optimal solution for word alignments given as an integer list; in away that local decisions on each node reach global maximization of Kendall's \u03c4 in total.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 64, "end_pos": 79, "type": "TASK", "confidence": 0.766130656003952}]}, {"text": "Any reordering methods that utilize word alignments along constituency benefit from this proof.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 36, "end_pos": 51, "type": "TASK", "confidence": 0.7229778319597244}]}, {"text": "Empirical study in Japanese-to-English translation demonstrate that our simple method outperforms a rule-based preordering method, and is comparable with, or superior to, state-of-the-art methods that rely on language-specific heuristics.", "labels": [], "entities": []}, {"text": "Our contributions are summarized as follows: \u2022 We define a method for obtaining oracle labels in discriminative preordering as the maximization of Kendall's \u03c4 . \u2022 We give a theoretical background to Kendall's \u03c4 based reordering for binary constituent trees.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform experiments over the NTCIR patent corpus) that consists of more than 3 million sentences in English and Japanese.", "labels": [], "entities": [{"text": "NTCIR patent corpus", "start_pos": 32, "end_pos": 51, "type": "DATASET", "confidence": 0.9639676213264465}]}, {"text": "Following conventional literature settings (), we used all 3 million sentences from the NTCIR-7 and NTCIR-: Comparison with previous systems in Japanese-to-English translation, of which scores are retrieved from their papers.", "labels": [], "entities": [{"text": "NTCIR-7", "start_pos": 88, "end_pos": 95, "type": "DATASET", "confidence": 0.9792919754981995}, {"text": "NTCIR", "start_pos": 100, "end_pos": 105, "type": "DATASET", "confidence": 0.8054513931274414}]}, {"text": "Boldfaces indicate the highest scores and differences.", "labels": [], "entities": []}, {"text": "8 training sets, used the first 1000 sentences in NTCIR-8 development set, and then fetched both the NTCIR-9 and NTCIR-10 testing sets.", "labels": [], "entities": [{"text": "NTCIR-8 development set", "start_pos": 50, "end_pos": 73, "type": "DATASET", "confidence": 0.9308168490727743}, {"text": "NTCIR-9", "start_pos": 101, "end_pos": 108, "type": "DATASET", "confidence": 0.9759008884429932}, {"text": "NTCIR-10 testing sets", "start_pos": 113, "end_pos": 134, "type": "DATASET", "confidence": 0.9204713900883993}]}, {"text": "We explore two types of word alignment data for training our preordering model.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 24, "end_pos": 38, "type": "TASK", "confidence": 0.7591556310653687}]}, {"text": "The first data (Giza) is created by running an unsupervised aligner Giza ( on the training data (3 million sentences).", "labels": [], "entities": []}, {"text": "The second data (Nile) is developed by training a supervised aligner Nile () with manually annotated 8,000 sentences, then applied the trained alignment model to remaining training data.", "labels": [], "entities": []}, {"text": "In the evaluation on manually annotated 1,000 sentences 4 , Giza achieved F1 50.1 score, while Nile achieved F1 86.9 score, for word alignment task.", "labels": [], "entities": [{"text": "F1 50.1 score", "start_pos": 74, "end_pos": 87, "type": "METRIC", "confidence": 0.9749537507692972}, {"text": "F1 86.9 score", "start_pos": 109, "end_pos": 122, "type": "METRIC", "confidence": 0.9744441111882528}, {"text": "word alignment task", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.8274365464846293}]}, {"text": "shows the performance of our method, which indicates that our preordering significantly improved translation accuracy in both RIBES and BLEU scores, from the baseline result attained by Moses without preordering.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.950596272945404}, {"text": "RIBES", "start_pos": 126, "end_pos": 131, "type": "METRIC", "confidence": 0.9877625703811646}, {"text": "BLEU", "start_pos": 136, "end_pos": 140, "type": "METRIC", "confidence": 0.9730422496795654}]}, {"text": "In particular, the preordering model trained with the Giza data revealed a substantial improvement, while the use of the Nile data further improves accuracy.", "labels": [], "entities": [{"text": "Giza data", "start_pos": 54, "end_pos": 63, "type": "DATASET", "confidence": 0.7510477900505066}, {"text": "Nile data", "start_pos": 121, "end_pos": 130, "type": "DATASET", "confidence": 0.7318369746208191}, {"text": "accuracy", "start_pos": 148, "end_pos": 156, "type": "METRIC", "confidence": 0.9976626634597778}]}, {"text": "This suggests that our method is particularly effective when high-accuracy word alignments are given.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 75, "end_pos": 90, "type": "TASK", "confidence": 0.7021799087524414}]}, {"text": "In addition, we achieved modest improvements even with DL=0 (no distortion allowed), which indicates the monotonicity of our reordered sentences.", "labels": [], "entities": [{"text": "DL", "start_pos": 55, "end_pos": 57, "type": "METRIC", "confidence": 0.9946861267089844}]}, {"text": "shows a comparison of the proposed method with a rule-based preordering method () and two postordering methods (.", "labels": [], "entities": []}, {"text": "One complication is that each work reports different baseline accuracy, although Moses is shared as a baseline, because these systems differ in various settings in data preprocessing, tokenization criteria, etc.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9731665253639221}]}, {"text": "Since this makes a fair comparison difficult, we additionally put a score difference (\u2206) of each system from its own baseline.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Examples in v(2, 2, 4) from Figure 1.", "labels": [], "entities": []}, {"text": " Table 3: Ablation tests on binary classification ac- curacy (%).", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9901736974716187}]}, {"text": " Table 4: Results in Japanese-to-English transla- tion. Boldfaces denote the highest scores and the  insignificant difference (p < 0.01) from the high- est scores in bootstrap resampling", "labels": [], "entities": []}, {"text": " Table 5: Comparison with previous systems in Japanese-to-English translation, of which scores are  retrieved from their papers. Boldfaces indicate the highest scores and differences.", "labels": [], "entities": []}]}