{"title": [{"text": "Feature Selection in Kernel Space: A Case Study on Dependency Parsing", "labels": [], "entities": [{"text": "Dependency Parsing", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.745390921831131}]}], "abstractContent": [{"text": "Given a set of basic binary features, we propose anew L 1 norm SVM based feature selection method that explicitly selects the features in their polynomial or tree kernel spaces.", "labels": [], "entities": []}, {"text": "The efficiency comes from the anti-monotone property of the subgradients: the subgradient with respect to a combined feature can be bounded by the subgradient with respect to each of its component features, and a feature can be pruned safely without further consideration if its corresponding subgradient is not steep enough.", "labels": [], "entities": []}, {"text": "We conduct experiments on the English dependency parsing task with a third order graph-based parser.", "labels": [], "entities": [{"text": "English dependency parsing task", "start_pos": 30, "end_pos": 61, "type": "TASK", "confidence": 0.6455087959766388}]}, {"text": "Benefiting from the rich features selected in the tree kernel space, our model achieved the best reported unlabeled attachment score of 93.72 without using any additional resource.", "labels": [], "entities": []}], "introductionContent": [{"text": "In Natural Language Processing (NLP) domain, existing linear models typically adopt exhaustive search to generate tons of features such that the important features are included.", "labels": [], "entities": []}, {"text": "However, the brute-force approach will guickly run out of memory when the feature space is extremely large.", "labels": [], "entities": []}, {"text": "Unlike linear models, kernel methods provide a powerful and unified framework for learning a large or even infinite number of features implicitly using limited memory.", "labels": [], "entities": []}, {"text": "However, many kernel methods scale quadratically in the number of training samples, and can hardly reap the benefits of learning a large dataset.", "labels": [], "entities": []}, {"text": "For example, the popular Penn Tree Bank (PTB) corpus for training an English part of speech (POS) tagger has approximately 1M words, thus it takes 1M 2 time to compute the kernel matrix, which is unacceptable using current hardwares.", "labels": [], "entities": [{"text": "Penn Tree Bank (PTB) corpus", "start_pos": 25, "end_pos": 52, "type": "DATASET", "confidence": 0.9749564954212734}, {"text": "training an English part of speech (POS) tagger", "start_pos": 57, "end_pos": 104, "type": "TASK", "confidence": 0.5575645864009857}]}, {"text": "In this paper, we propose anew feature selection method that can efficiently select representative features in the kernel space to improve the quality of linear models.", "labels": [], "entities": []}, {"text": "Specifically, given a limited number of basic features such as the commonly used unigrams and bigrams, our method performs feature selection in the space of their combinations, e.g, the concatenation of these n-grams.", "labels": [], "entities": []}, {"text": "A sparse discriminative model is produced by training L 1 norm SVMs using subgradient methods.", "labels": [], "entities": []}, {"text": "Different from traditional training procedures, we divide the feature vector into a number of segments, and sort them in a coarse-to-fine order: the first segment includes the basic features, the second segment includes the combined features composed of two basic features, and soon.", "labels": [], "entities": []}, {"text": "In each iteration, we calculate the subgradient segment by segment.", "labels": [], "entities": []}, {"text": "A combined feature and all its further combinations in the following segments can be safely pruned if the absolute value of its corresponding subgradient is not sufficiently large.", "labels": [], "entities": []}, {"text": "The algorithm stops until all features are pruned.", "labels": [], "entities": []}, {"text": "Besides, two simple yet effective pruning strategies are proposed to filter the combinations.", "labels": [], "entities": []}, {"text": "We conduct experiments on English dependency parsing task.", "labels": [], "entities": [{"text": "English dependency parsing", "start_pos": 26, "end_pos": 52, "type": "TASK", "confidence": 0.6085609793663025}]}, {"text": "Millions of deep, high order features derived by concatenating contextual words, POS tags, directions and distances of dependencies are selected in the polynomial kernel and tree kernel spaces.", "labels": [], "entities": []}, {"text": "The result is promising: these features significantly improved a state-of-the-art third order dependency parser, yielding the best reported unlabeled attachment score of 93.72 without using any additional resource.", "labels": [], "entities": []}], "datasetContent": [{"text": "Now we looked at the impact of our system on non-English treebanks.", "labels": [], "entities": []}, {"text": "We evaluate our system on six other languages from the CoNLL 2009 sharedtask.", "labels": [], "entities": [{"text": "CoNLL 2009 sharedtask", "start_pos": 55, "end_pos": 76, "type": "DATASET", "confidence": 0.9354558785756429}]}, {"text": "We used the best setting in the previous experiment: reranking model is trained using the features selected in the dependency tree kernel space.", "labels": [], "entities": []}, {"text": "For POS tag features we used the predicted tags.", "labels": [], "entities": []}, {"text": "As the third order parser cannot handle non-projective parse trees, we used the graph transformation techniques to produce nonprojective structures).", "labels": [], "entities": []}, {"text": "First, the training data for the parser is projectivized by applying a number of lifting operations () and encoding information about these lifts in arc labels.", "labels": [], "entities": []}, {"text": "We used the path encoding scheme where the label of each arc is concatenated with two binary tags, one indicates if the arc is lifted, the other indicates if the arc is along the lifting path from the syntactic to the linear head.", "labels": [], "entities": []}, {"text": "Then we train a projective  parser on the transformed data without arc label information and a classifier to predict the arc labels based on the projectivized gold parse tree structure.", "labels": [], "entities": []}, {"text": "During testing, we run the parser and the classifier in a pipeline to generate a labeled parse tree.", "labels": [], "entities": []}, {"text": "Labeled syntactic accuracy is reported for comparison.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9959491491317749}]}, {"text": "Comparison results are listed in.", "labels": [], "entities": [{"text": "Comparison", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9379017353057861}]}, {"text": "We achieved the best reported results on three languages, Japanese, Spanish and Czech.", "labels": [], "entities": []}, {"text": "Note that CoNLL 2009 also provide the semantic labeling annotation which we did not used in our system.", "labels": [], "entities": [{"text": "CoNLL 2009", "start_pos": 10, "end_pos": 20, "type": "DATASET", "confidence": 0.9318299889564514}]}, {"text": "While some official systems benefit from jointly learning parsing and semantic role labeling models.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 70, "end_pos": 92, "type": "TASK", "confidence": 0.6338882545630137}]}], "tableCaptions": [{"text": " Table 2: Comparison between our system and the  state-of-art systems on English dataset. LM is  short for Linear Model, hrs, mins are short for  hours and minutes respectively", "labels": [], "entities": [{"text": "English dataset", "start_pos": 73, "end_pos": 88, "type": "DATASET", "confidence": 0.8813373446464539}]}, {"text": " Table 3: Feature selection in dependency kernel  space with different threshold C.", "labels": [], "entities": [{"text": "Feature selection", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.732806384563446}]}, {"text": " Table 4: Experimental Results on CoNLL 2009  non-English datasets.", "labels": [], "entities": [{"text": "CoNLL 2009  non-English datasets", "start_pos": 34, "end_pos": 66, "type": "DATASET", "confidence": 0.938647910952568}]}]}