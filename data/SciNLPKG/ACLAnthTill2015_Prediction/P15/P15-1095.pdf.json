{"title": [{"text": "Robust Subgraph Generation Improves Abstract Meaning Representation Parsing", "labels": [], "entities": [{"text": "Robust Subgraph Generation Improves Abstract Meaning Representation Parsing", "start_pos": 0, "end_pos": 75, "type": "TASK", "confidence": 0.8790119774639606}]}], "abstractContent": [{"text": "The Abstract Meaning Representation (AMR) is a representation for open-domain rich semantics, with potential use in fields like event extraction and machine translation.", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR)", "start_pos": 4, "end_pos": 41, "type": "TASK", "confidence": 0.8143287052710851}, {"text": "event extraction", "start_pos": 128, "end_pos": 144, "type": "TASK", "confidence": 0.7382184416055679}, {"text": "machine translation", "start_pos": 149, "end_pos": 168, "type": "TASK", "confidence": 0.8147354423999786}]}, {"text": "Node generation, typically done using a simple dictionary lookup, is currently an important limiting factor in AMR parsing.", "labels": [], "entities": [{"text": "Node generation", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9118718504905701}, {"text": "AMR parsing", "start_pos": 111, "end_pos": 122, "type": "TASK", "confidence": 0.9663113653659821}]}, {"text": "We propose a small set of actions that derive AMR subgraphs by transformations on spans of text, which allows for more robust learning of this stage.", "labels": [], "entities": [{"text": "AMR subgraphs", "start_pos": 46, "end_pos": 59, "type": "TASK", "confidence": 0.8340035378932953}]}, {"text": "Our set of construction actions generalize better than the previous approach , and can be learned with a simple classifier.", "labels": [], "entities": []}, {"text": "We improve on the previous state-of-the-art result for AMR parsing , boosting end-to-end performance by 3 F 1 on both the LDC2013E117 and LDC2014T12 datasets.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 55, "end_pos": 66, "type": "TASK", "confidence": 0.8817324340343475}, {"text": "LDC2014T12 datasets", "start_pos": 138, "end_pos": 157, "type": "DATASET", "confidence": 0.8820744752883911}]}], "introductionContent": [{"text": "The Abstract Meaning Representation (AMR) () is a rich, graph-based language for expressing semantics over abroad domain.", "labels": [], "entities": [{"text": "Abstract Meaning Representation (AMR)", "start_pos": 4, "end_pos": 41, "type": "TASK", "confidence": 0.8108410984277725}]}, {"text": "The formalism is backed by a large datalabeling effort, and it holds promise for enabling anew breed of natural language applications ranging from semantically aware MT to rich broaddomain QA over text-based knowledge bases.", "labels": [], "entities": []}, {"text": "shows an example AMR for \"he gleefully ran to his dog Rover,\" and we give a brief introduction to AMR in Section 2.", "labels": [], "entities": [{"text": "AMR", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.8226146697998047}]}, {"text": "This paper focuses on AMR parsing, the task of mapping a natural language sentence into an AMR graph.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 22, "end_pos": 33, "type": "TASK", "confidence": 0.9844286441802979}]}, {"text": "We follow previous work) in dividing AMR parsing into two steps.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.892257571220398}]}, {"text": "The first step is concept identification, which generates AMR nodes from text, and which we'll refer to as NER++ (Section 3.1).", "labels": [], "entities": [{"text": "concept identification", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.7269854992628098}, {"text": "NER", "start_pos": 107, "end_pos": 110, "type": "DATASET", "confidence": 0.8036991953849792}]}, {"text": "The second step is relation identification, which adds arcs to link these nodes into a fully connected AMR graph, which we'll call SRL++ (Section 3.2).", "labels": [], "entities": [{"text": "relation identification", "start_pos": 19, "end_pos": 42, "type": "TASK", "confidence": 0.9067340791225433}, {"text": "SRL++", "start_pos": 131, "end_pos": 136, "type": "DATASET", "confidence": 0.787106841802597}]}, {"text": "We observe that SRL++ is not the hard part of AMR parsing; rather, much of the difficulty in AMR is generating high accuracy concept subgraphs from the NER++ component.", "labels": [], "entities": [{"text": "AMR parsing", "start_pos": 46, "end_pos": 57, "type": "TASK", "confidence": 0.8979101479053497}, {"text": "AMR", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.6075490117073059}, {"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9582741260528564}]}, {"text": "For example, when the existing AMR parser JAMR () is given a gold NER++ output, and must only perform SRL++ over given subgraphs it scores 80 F 1 -nearly the inter-annotator agreement of 83 F 1 , and far higher than its end to end accuracy of 59 F 1 . SRL++ within AMR is relatively easy given a perfect NER++ output, because so much pressure is put on the output of NER++ to carry meaningful information.", "labels": [], "entities": [{"text": "AMR parser JAMR", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.4895147482554118}, {"text": "F 1", "start_pos": 142, "end_pos": 145, "type": "METRIC", "confidence": 0.9667441546916962}, {"text": "accuracy", "start_pos": 231, "end_pos": 239, "type": "METRIC", "confidence": 0.963499903678894}, {"text": "SRL++", "start_pos": 252, "end_pos": 257, "type": "TASK", "confidence": 0.8990244567394257}]}, {"text": "For example, there's a strong typecheck feature for the existence and type of any arc just by looking at its end-points, and syntactic dependency features are very informative for removing any remaining ambiguity.", "labels": [], "entities": []}, {"text": "If a system is con-: A graphical explanation of our method.", "labels": [], "entities": []}, {"text": "We represent the derivation process for He gleefully ran to his dog Rover.", "labels": [], "entities": []}, {"text": "First the tokens in the sentence are labeled with derivation actions, then these actions are used to generate AMR subgraphs, which are then stitched together to form a coherent whole.", "labels": [], "entities": []}, {"text": "sidering how to link the node run-01 in, the verb-sense frame for \"run-01\" leaves very little uncertainty for what we could assign as an ARG0 arc.", "labels": [], "entities": [{"text": "ARG0", "start_pos": 137, "end_pos": 141, "type": "DATASET", "confidence": 0.8614659905433655}]}, {"text": "It must be a noun, which leaves either he or dog, and this is easily decided in favor of he by looking for an nsubj arc in the dependency parse.", "labels": [], "entities": []}, {"text": "The primary contribution of this paper is a novel approach to the NER++ task, illustrated in Figure 2.", "labels": [], "entities": [{"text": "NER++ task", "start_pos": 66, "end_pos": 76, "type": "TASK", "confidence": 0.872412919998169}]}, {"text": "We notice that the subgraphs aligned to lexical items can often be generated from a small set of generative actions which generalize across tokens.", "labels": [], "entities": []}, {"text": "For example, most verbs generate an AMR node corresponding to the verb sense of the appropriate PropBank frame -e.g., run generates run-01 in.", "labels": [], "entities": []}, {"text": "This allows us to frame the NER++ task as the task of classifying one of a small number of actions for each token, rather than choosing a specific AMR subgraph for every token in the sentence.", "labels": [], "entities": [{"text": "NER++ task", "start_pos": 28, "end_pos": 38, "type": "TASK", "confidence": 0.5423257350921631}]}, {"text": "Our approach to the end-to-end AMR parsing task is therefore as follows: we define an action space for generating AMR concepts, and create a classifier for classifying lexical items into one of these actions (Section 4).", "labels": [], "entities": [{"text": "AMR parsing task", "start_pos": 31, "end_pos": 47, "type": "TASK", "confidence": 0.9443041483561198}]}, {"text": "This classifier is trained from automatically generated alignments between the gold AMR trees and their associated sentences (Section 5), using an objective which favors alignment mistakes which are least harmful to the NER++ component.", "labels": [], "entities": []}, {"text": "Finally, the concept subgraphs are combined into a coherent AMR parse using the maximum spanning connected subgraph algorithm of.", "labels": [], "entities": [{"text": "AMR parse", "start_pos": 60, "end_pos": 69, "type": "TASK", "confidence": 0.7574575841426849}]}, {"text": "We show that our approach provides a large boost to recall over previous approaches, and that end to end performance is improved from 59 to 62 smatch (an F 1 measure of correct AMR arcs; see) when incorporated into the SRL++ parser of.", "labels": [], "entities": [{"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9980164766311646}, {"text": "correct AMR arcs", "start_pos": 169, "end_pos": 185, "type": "METRIC", "confidence": 0.7449173529942831}]}, {"text": "When evaluating the performance of our action classifier in isolation, we obtain an action classification accuracy of 84.1%.", "labels": [], "entities": [{"text": "action classification", "start_pos": 84, "end_pos": 105, "type": "TASK", "confidence": 0.6386730670928955}, {"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.8786143064498901}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Distribution of action types in the  proxy section of the newswire section of the  LDC2014T12 dataset, generated from automati- cally aligned data.", "labels": [], "entities": [{"text": "LDC2014T12 dataset", "start_pos": 93, "end_pos": 111, "type": "DATASET", "confidence": 0.973317414522171}]}, {"text": " Table 3: Results on two AMR datasets for JAMR  and our NER++ embedded in the JAMR SRL++  component. Note that recall is consistently higher  across both datasets, with only a small loss in pre- cision.", "labels": [], "entities": [{"text": "AMR datasets", "start_pos": 25, "end_pos": 37, "type": "DATASET", "confidence": 0.8130776882171631}, {"text": "JAMR", "start_pos": 42, "end_pos": 46, "type": "DATASET", "confidence": 0.8950375914573669}, {"text": "JAMR SRL++  component", "start_pos": 78, "end_pos": 99, "type": "DATASET", "confidence": 0.9144642502069473}, {"text": "recall", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.9997180104255676}]}]}