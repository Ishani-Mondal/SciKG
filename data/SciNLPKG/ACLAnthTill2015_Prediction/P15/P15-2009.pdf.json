{"title": [{"text": "Using Tweets to Help Sentence Compression for News Highlights Generation", "labels": [], "entities": []}], "abstractContent": [{"text": "We explore using relevant tweets of a given news article to help sentence compression for generating compressive news highlights.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 65, "end_pos": 85, "type": "TASK", "confidence": 0.7181745767593384}]}, {"text": "We extend an unsupervised dependency-tree based sentence compression approach by incorporating tweet information to weight the tree edge in terms of informativeness and syntactic importance.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 48, "end_pos": 68, "type": "TASK", "confidence": 0.7201340347528458}]}, {"text": "The experimental results on a public corpus that contains both news articles and relevant tweets show that our proposed tweets guided sentence compression method can improve the summariza-tion performance significantly compared to the baseline generic sentence compression method.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 134, "end_pos": 154, "type": "TASK", "confidence": 0.7383334338665009}, {"text": "generic sentence compression", "start_pos": 244, "end_pos": 272, "type": "TASK", "confidence": 0.7467779517173767}]}], "introductionContent": [{"text": "\"Story highlights\" of news articles are provided by only a few news websites such as CNN.com.", "labels": [], "entities": [{"text": "CNN.com", "start_pos": 85, "end_pos": 92, "type": "DATASET", "confidence": 0.9366121888160706}]}, {"text": "The highlights typically consist of three or four succinct itemized sentences for readers to quickly capture the gist of the document, and can dramatically reduce reader's information load.", "labels": [], "entities": []}, {"text": "A highlight sentence is usually much shorter than its original corresponding news sentence; therefore applying extractive summarization methods directly to sentences in a news article is not enough to generate high quality highlights.", "labels": [], "entities": []}, {"text": "Sentence compression aims to retain the most important information of an original sentence in a shorter form while being grammatical at the same time.", "labels": [], "entities": [{"text": "Sentence compression", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9471186995506287}]}, {"text": "Previous research has shown the effectiveness of sentence compression for automatic document summarization).", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 49, "end_pos": 69, "type": "TASK", "confidence": 0.7070136219263077}, {"text": "document summarization", "start_pos": 84, "end_pos": 106, "type": "TASK", "confidence": 0.5240063220262527}]}, {"text": "The compressed summaries can be generated through a pipeline approach that combines a generic sentence compression model with a summary sentence pre-selection or post-selection step.", "labels": [], "entities": []}, {"text": "Prior studies have mostly used the generic sentence compression approaches, however, a generic compression system may not be the best fit for the summarization purpose because it does not take into account the summarization task in the compression module.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 43, "end_pos": 63, "type": "TASK", "confidence": 0.722454845905304}]}, {"text": "thus proposed a summary guided compression method to address this problem and showed the effectiveness of their method.", "labels": [], "entities": []}, {"text": "But this approach relied heavily on the training data, thus has the limitation of domain generalization.", "labels": [], "entities": [{"text": "domain generalization", "start_pos": 82, "end_pos": 103, "type": "TASK", "confidence": 0.6974975168704987}]}, {"text": "Instead of using a manually generated corpus, we investigate using existing external sources to guide sentence compression for the purpose of compressive news highlights generation.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 102, "end_pos": 122, "type": "TASK", "confidence": 0.73985555768013}, {"text": "compressive news highlights generation", "start_pos": 142, "end_pos": 180, "type": "TASK", "confidence": 0.6114312335848808}]}, {"text": "Nowadays it becomes more and more common that users share interesting news content via Twitter together with their comments.", "labels": [], "entities": []}, {"text": "The availability of cross-media information provides new opportunities for traditional tasks of Natural Language Processing (.", "labels": [], "entities": []}, {"text": "In this paper, we propose to use relevant tweets of a news article to guide the sentence compression process in a pipeline framework for generating compressive news highlights.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 80, "end_pos": 100, "type": "TASK", "confidence": 0.7320219576358795}]}, {"text": "This is a pioneer study for using such parallel data to guide sentence compression for document summarization.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 62, "end_pos": 82, "type": "TASK", "confidence": 0.7202311903238297}, {"text": "document summarization", "start_pos": 87, "end_pos": 109, "type": "TASK", "confidence": 0.6291587054729462}]}, {"text": "Our work shares some similar ideas with.", "labels": [], "entities": []}, {"text": "They also attempted to use tweets to help news highlights generation.", "labels": [], "entities": [{"text": "news highlights generation", "start_pos": 42, "end_pos": 68, "type": "TASK", "confidence": 0.6225452125072479}]}, {"text": "derived external features based on the relevant tweet collection to assist the ranking of the original sentences for extractive summarization in a fashion of supervised machine learning.", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 117, "end_pos": 141, "type": "TASK", "confidence": 0.5860128402709961}]}, {"text": "proposed a graph-based approach to simultaneously rank the original news sentences and relevant tweets in an unsupervised way.", "labels": [], "entities": []}, {"text": "Both of them focused on using tweets to help sentence extraction while we leverage tweet information to guide sentence compression for compressive summary generation.", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7701540291309357}, {"text": "sentence compression", "start_pos": 110, "end_pos": 130, "type": "TASK", "confidence": 0.7308998703956604}, {"text": "compressive summary generation", "start_pos": 135, "end_pos": 165, "type": "TASK", "confidence": 0.6735659937063853}]}, {"text": "We extend an unsupervised dependency-tree based sentence compression approach to incorporate tweet information from the aspects of both informativeness and syntactic importance to weight the tree edge.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 48, "end_pos": 68, "type": "TASK", "confidence": 0.7298752516508102}]}, {"text": "We evaluate our method on a public corpus that contains both news articles and relevant tweets.", "labels": [], "entities": []}, {"text": "The result shows that generic compression hurts the performance of highlights generation, while sentence compression guided by relevant tweets of the news article can improve the performance.", "labels": [], "entities": [{"text": "generic compression", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.8181774020195007}, {"text": "highlights generation", "start_pos": 67, "end_pos": 88, "type": "TASK", "confidence": 0.8196140825748444}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Distribution of documents, highlights and tweets with respect to different events", "labels": [], "entities": []}]}