{"title": [{"text": "Unsupervised Learning and Modeling of Knowledge and Intent for Spoken Dialogue Systems", "labels": [], "entities": []}], "abstractContent": [{"text": "Spoken dialogue systems (SDS) are rapidly appearing in various smart devices (smartphone, smart-TV, in-car navigating system, etc).", "labels": [], "entities": [{"text": "Spoken dialogue systems (SDS)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7155157426993052}]}, {"text": "The key role in a successful SDS is a spoken language understanding (SLU) component, which parses user utterances into semantic concepts in order to understand users' intentions.", "labels": [], "entities": [{"text": "SDS", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.9750271439552307}, {"text": "spoken language understanding (SLU)", "start_pos": 38, "end_pos": 73, "type": "TASK", "confidence": 0.782831052939097}]}, {"text": "However, such semantic concepts and their structure are manually created by experts, and the annotation process results in extremely high cost and poor scalability in system development.", "labels": [], "entities": []}, {"text": "Therefore, the dissertation focuses on improving SDS generalization and scalability by automatically inferring domain knowledge and learning structures from unlabeled conversations through a matrix factorization (MF) technique.", "labels": [], "entities": [{"text": "SDS generalization", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.9813900291919708}]}, {"text": "With the automatically acquired semantic concepts and structures, we further investigate whether such information can be utilized to effectively understand user utterances and then show the feasibility of reducing human effort during SDS development.", "labels": [], "entities": [{"text": "SDS development", "start_pos": 234, "end_pos": 249, "type": "TASK", "confidence": 0.9030815958976746}]}], "introductionContent": [{"text": "Various smart devices (e.g. smartphone, smart-TV, in-car navigating system) are incorporating spoken language interfaces, a.k.a. spoken dialogue systems (SDS), in order to help users finish tasks more efficiently.", "labels": [], "entities": []}, {"text": "The key role in a successful SDS is a spoken language understanding (SLU) component; in order to capture the language variation from dialogue participants, the SLU component must create a mapping between the natural language inputs and semantic representations that correspond to users' intentions.", "labels": [], "entities": [{"text": "SDS", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.971925675868988}, {"text": "spoken language understanding (SLU)", "start_pos": 38, "end_pos": 73, "type": "TASK", "confidence": 0.7954404751459757}]}, {"text": "The semantic representation must include \"concepts' and a \"structure\": concepts are the domainspecific topics, and the structure describes the relations between concepts and conveys intentions.", "labels": [], "entities": []}, {"text": "However, most prior work focused on learning the mapping between utterances and semantic representations, where such knowledge still remains predefined.", "labels": [], "entities": []}, {"text": "The need of annotations results in extremely high cost and poor scalability in system development.", "labels": [], "entities": []}, {"text": "Therefore, current technology usually limits conversational interactions to a few narrow predefined domains/topics.", "labels": [], "entities": []}, {"text": "With the increasing conversational interactions, this dissertation focuses on improving generalization and scalability of building SDSs with little human effort.", "labels": [], "entities": []}, {"text": "In order to achieve the goal, two questions need to be addressed: 1) Given unlabelled conversations, how can a system automatically induce and organize the domain-specific concepts?", "labels": [], "entities": []}, {"text": "2) With the automatically acquired knowledge, how can a system understand user utterances and intents?", "labels": [], "entities": []}, {"text": "To tackle the above problems, we propose to acquire the domain knowledge that captures human's semantics, intents, and behaviors.", "labels": [], "entities": []}, {"text": "Then based on the acquired knowledge, we build an SLU component to understand users and to offer better interactions in dialogues.", "labels": [], "entities": []}, {"text": "The dissertation shows the feasibility of building a dialogue learning system that is able to understand how particular domains work based on unlabeled conversations.", "labels": [], "entities": []}, {"text": "As a result, an initial SDS can be automatically built according to the learned knowledge, and its performance can be quickly improved by interacting with users for practical usage, presenting the potential of reducing human effort for SDS development.", "labels": [], "entities": [{"text": "SDS", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9577087163925171}, {"text": "SDS development", "start_pos": 236, "end_pos": 251, "type": "TASK", "confidence": 0.9521338045597076}]}, {"text": "Our MF method completes a partially-missing matrix for semantic decoding/behavior prediction.", "labels": [], "entities": [{"text": "semantic decoding/behavior prediction", "start_pos": 55, "end_pos": 92, "type": "TASK", "confidence": 0.631535679101944}]}, {"text": "Dark circles are observed facts, shaded circles are inferred facts.", "labels": [], "entities": []}, {"text": "The ontology induction maps observed feature patterns to semantic concepts.", "labels": [], "entities": []}, {"text": "The feature relation model constructs correlations between observed feature patterns.", "labels": [], "entities": []}, {"text": "The concept relation model learns the high-level semantic correlations for inferring hidden semantic slots or predicting subsequent behaviors.", "labels": [], "entities": []}, {"text": "Reasoning with matrix factorization incorporates these models jointly, and produces a coherent and domain-specific SLU model.", "labels": [], "entities": []}, {"text": "the intent detection problem in SLU, showing that results obtained from the unsupervised training process align well with the performance of traditional supervised learning.", "labels": [], "entities": [{"text": "intent detection", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.7774032950401306}, {"text": "SLU", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.8641390204429626}]}, {"text": "Following their success of unsupervised SLU, recent studies have also obtained interesting results on the tasks of relation detection), entity extraction (, and extending domain coverage.", "labels": [], "entities": [{"text": "relation detection", "start_pos": 115, "end_pos": 133, "type": "TASK", "confidence": 0.8439841866493225}, {"text": "entity extraction", "start_pos": 136, "end_pos": 153, "type": "TASK", "confidence": 0.8742804229259491}]}, {"text": "However, most studies above do not explicitly learn latent factor representations from the data-while we hypothesize that the better robustness can be achieved by explicitly modeling the measurement errors (usually produced by automatic speech recognizers (ASR)) using latent variable models and taking additional local and global semantic constraints into account.", "labels": [], "entities": [{"text": "automatic speech recognizers (ASR))", "start_pos": 227, "end_pos": 262, "type": "TASK", "confidence": 0.7739087045192719}]}, {"text": "Latent Variable Modeling in SLU Early studies on latent variable modeling in speech included the classic hidden Markov model for statistical speech recognition.", "labels": [], "entities": [{"text": "Latent Variable Modeling", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.5730823973814646}, {"text": "latent variable modeling", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.7165634433428446}, {"text": "statistical speech recognition", "start_pos": 129, "end_pos": 159, "type": "TASK", "confidence": 0.6636543969313303}]}, {"text": "Recently, were the first to study the intent detection problem using query logs and a discrete Bayesian latent variable model.", "labels": [], "entities": [{"text": "intent detection problem", "start_pos": 38, "end_pos": 62, "type": "TASK", "confidence": 0.8506655693054199}]}, {"text": "In the field of dialogue modeling, the partially observable Markov decision process (POMDP) () model is a popular technique for dialogue management, reducing the cost of handcrafted dialogue managers while producing robustness against speech recognition errors.", "labels": [], "entities": [{"text": "dialogue modeling", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.8555838167667389}, {"text": "dialogue management", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.8439209461212158}]}, {"text": "More recently,  used a semi-supervised LDA model to show improvement on the slot filling task.", "labels": [], "entities": [{"text": "slot filling task", "start_pos": 76, "end_pos": 93, "type": "TASK", "confidence": 0.8837640484174093}]}, {"text": "Also, proposed an unsupervised model for connecting words with latent states in HMMs using topic models, obtaining interesting qualitative and quantitative results.", "labels": [], "entities": []}, {"text": "However, for unsupervised SLU, it is not obvious how to incorporate additional information in the HMMs.", "labels": [], "entities": []}, {"text": "With increasing works about learn-ing the feature matrices for language representations (, matrix factorization (MF) has become very popular for both implicit and explicit feedback (.", "labels": [], "entities": []}, {"text": "This thesis proposal is the first to propose a framework about unsupervised SLU modeling, which is able to simultaneously consider various local and global knowledge automatically learned from unlabelled data using a matrix factorization (MF) technique.", "labels": [], "entities": [{"text": "SLU modeling", "start_pos": 76, "end_pos": 88, "type": "TASK", "confidence": 0.9300153851509094}]}], "datasetContent": [], "tableCaptions": []}