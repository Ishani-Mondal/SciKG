{"title": [{"text": "Learning Semantic Representations of Users and Products for Document Level Sentiment Classification", "labels": [], "entities": [{"text": "Document Level Sentiment Classification", "start_pos": 60, "end_pos": 99, "type": "TASK", "confidence": 0.7661975920200348}]}], "abstractContent": [{"text": "Neural network methods have achieved promising results for sentiment classification of text.", "labels": [], "entities": [{"text": "sentiment classification of text", "start_pos": 59, "end_pos": 91, "type": "TASK", "confidence": 0.9470371305942535}]}, {"text": "However, these models only use semantics of texts, while ignoring users who express the sentiment and products which are evaluated, both of which have great influences on interpreting the sentiment of text.", "labels": [], "entities": []}, {"text": "In this paper, we address this issue by incorporating user-and product-level information into a neural network approach for document level sentiment classification.", "labels": [], "entities": [{"text": "document level sentiment classification", "start_pos": 124, "end_pos": 163, "type": "TASK", "confidence": 0.762920007109642}]}, {"text": "Users and products are modeled using vector space models , the representations of which capture important global clues such as individual preferences of users or overall qualities of products.", "labels": [], "entities": []}, {"text": "Such global evidence in turn facilitates embedding learning procedure at document level, yielding better text representations.", "labels": [], "entities": []}, {"text": "By combining evidence at user-, product-and document-level in a unified neural framework, the proposed model achieves state-of-the-art performances on IMDB and Yelp dataset-s 1 .", "labels": [], "entities": [{"text": "Yelp dataset-s 1", "start_pos": 160, "end_pos": 176, "type": "DATASET", "confidence": 0.8783695101737976}]}], "introductionContent": [{"text": "Document-level sentiment classification is a fundamental problem in the field of sentiment analysis and opinion mining.", "labels": [], "entities": [{"text": "Document-level sentiment classification", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.874338686466217}, {"text": "sentiment analysis", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.9240244626998901}, {"text": "opinion mining", "start_pos": 104, "end_pos": 118, "type": "TASK", "confidence": 0.7320286929607391}]}, {"text": "The task is to infer the sentiment polarity or intensity (e.g. 1-5 or 1-10 stars on review sites) of a document.", "labels": [], "entities": []}, {"text": "Dominating studies follow and regard this problem as a multi-class classification task.", "labels": [], "entities": [{"text": "Dominating", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9439716935157776}, {"text": "multi-class classification task", "start_pos": 55, "end_pos": 86, "type": "TASK", "confidence": 0.7421173453330994}]}, {"text": "They usually use machine learning algorithms, and build sentiment classifier from documents with accompanying sentiment labels.", "labels": [], "entities": [{"text": "sentiment classifier from documents with accompanying sentiment labels", "start_pos": 56, "end_pos": 126, "type": "TASK", "confidence": 0.8025039061903954}]}, {"text": "Since the performance of a machine learner is heavily dependent on the choice of data representations, many works focus on designing effective features () or learning discriminative features from data with neural networks).", "labels": [], "entities": []}, {"text": "Despite the apparent success of neural network methods, they typically only use text information while ignoring the important influences of users and products.", "labels": [], "entities": []}, {"text": "Let us take reviews with respect to 1-5 rating scales as an example.", "labels": [], "entities": []}, {"text": "A critical user might write a review \"it works great\" and mark 4 stars, while a lenient user might give 5 stars even if he posts an (almost) identical review.", "labels": [], "entities": []}, {"text": "In this case, user preference affects the sentiment rating of a review.", "labels": [], "entities": []}, {"text": "Product quality also has an impact on review sentiment rating.", "labels": [], "entities": [{"text": "review sentiment rating", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.6341990033785502}]}, {"text": "Reviews towards high-quality products (e.g. Macbook) tend to receive higher ratings than those towards low-quality products.", "labels": [], "entities": [{"text": "Macbook", "start_pos": 44, "end_pos": 51, "type": "DATASET", "confidence": 0.9298585057258606}]}, {"text": "Therefore, it is feasible to leverage individual preferences of users and overall qualities of products to build a smarter sentiment classifier and achieve better performance . In this paper, we propose anew model dubbed User Product Neural Network (UPNN) to capture user-and product-level information for sentiment classification of documents (e.g. reviews).", "labels": [], "entities": [{"text": "sentiment classification of documents (e.g. reviews)", "start_pos": 306, "end_pos": 358, "type": "TASK", "confidence": 0.851673886179924}]}, {"text": "UPNN takes as input a variable-sized document as well as the user who writes the review and the product which is evaluated.", "labels": [], "entities": [{"text": "UPNN", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8832228779792786}]}, {"text": "It outputs sentiment polarity label of a document.", "labels": [], "entities": []}, {"text": "Users and products are encoded in continuous vector spaces, the representations of which capture important global clues such as user preferences and product qualities.", "labels": [], "entities": []}, {"text": "These representations are further integrated with continuous text representation in a unified neural framework for sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 115, "end_pos": 139, "type": "TASK", "confidence": 0.9531081914901733}]}, {"text": "We apply UPNN to three datasets derived from IMDB and Yelp Dataset Challenge.", "labels": [], "entities": [{"text": "IMDB", "start_pos": 45, "end_pos": 49, "type": "DATASET", "confidence": 0.9506940841674805}, {"text": "Yelp Dataset Challenge", "start_pos": 54, "end_pos": 76, "type": "DATASET", "confidence": 0.9503021240234375}]}, {"text": "We compare to several neural network models including recursive neural networks, paragraph vector (, sentimentspecific word embedding (, and a state-of-the-art recommendation algorithm JMARS ().", "labels": [], "entities": [{"text": "JMARS", "start_pos": 185, "end_pos": 190, "type": "DATASET", "confidence": 0.8425618410110474}]}, {"text": "Experimental results show that: (1) UPNN outperforms baseline methods for sentiment classification of documents; (2) incorporating representations of users and products significantly improves classification accuracy.", "labels": [], "entities": [{"text": "sentiment classification of documents", "start_pos": 74, "end_pos": 111, "type": "TASK", "confidence": 0.9284837990999222}, {"text": "accuracy", "start_pos": 207, "end_pos": 215, "type": "METRIC", "confidence": 0.8801494240760803}]}, {"text": "The main contributions of this work are as follows: \u2022 We present anew neural network method (UPNN) by leveraging users and products for document-level sentiment classification.", "labels": [], "entities": [{"text": "document-level sentiment classification", "start_pos": 136, "end_pos": 175, "type": "TASK", "confidence": 0.6906949877738953}]}, {"text": "\u2022 We validate the influences of users and products in terms of sentiment and text on massive IMDB and Yelp reviews.", "labels": [], "entities": []}, {"text": "\u2022 We report empirical results on three datasets, and show that UPNN outperforms state-of-the-art methods for sentiment classification.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 109, "end_pos": 133, "type": "TASK", "confidence": 0.9570027589797974}]}], "datasetContent": [{"text": "We conduct experiments to evaluate UPNN by applying it to sentiment classification of documents.", "labels": [], "entities": [{"text": "UPNN", "start_pos": 35, "end_pos": 39, "type": "TASK", "confidence": 0.7504211664199829}, {"text": "sentiment classification of documents", "start_pos": 58, "end_pos": 95, "type": "TASK", "confidence": 0.9253834038972855}]}, {"text": "Existing benchmark datasets for sentiment classification such as Stanford Sentiment Treebank () typically only have text information, but do not contain users who express the sentiment or products which are evaluated.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.916213721036911}, {"text": "Stanford Sentiment Treebank", "start_pos": 65, "end_pos": 92, "type": "DATASET", "confidence": 0.9336561759312948}]}, {"text": "Therefore, we build the datasets by ourselves.", "labels": [], "entities": []}, {"text": "In order to obtain large scale corpora without manual annotation, we derive three datasets from IMDB (Diao.", "labels": [], "entities": [{"text": "IMDB", "start_pos": 96, "end_pos": 100, "type": "DATASET", "confidence": 0.9660662412643433}]}, {"text": "We split each corpus into training, development and testing sets with a 80/10/10 split, and conduct tokenization and sentence splitting with Stanford CoreNLP ( ).", "labels": [], "entities": [{"text": "tokenization", "start_pos": 100, "end_pos": 112, "type": "TASK", "confidence": 0.9723889827728271}, {"text": "sentence splitting", "start_pos": 117, "end_pos": 135, "type": "TASK", "confidence": 0.706378385424614}, {"text": "Stanford CoreNLP", "start_pos": 141, "end_pos": 157, "type": "DATASET", "confidence": 0.9420710206031799}]}, {"text": "We use standard accuracy () to measure the overall sentiment classification performance, and use M AE and RM SE to measure the divergences between predicted sentiment ratings (pr) and ground truth ratings (gd).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.7299107909202576}, {"text": "sentiment classification", "start_pos": 51, "end_pos": 75, "type": "TASK", "confidence": 0.8913814425468445}, {"text": "M AE", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.8459553718566895}, {"text": "RM SE", "start_pos": 106, "end_pos": 111, "type": "METRIC", "confidence": 0.8837135434150696}]}], "tableCaptions": [{"text": " Table 1: Statistical information of IMDB, Yelp 2014 and Yelp 2013 datasets used for sentiment classifi- cation. The rating scale of IMDB dataset is 1-10. The rating scale of Yelp 2014 and Yelp 2013 datasets is  1-5. |V | is the vocabulary size of words in each dataset. #users is the number of users, #docs/user means  the average number of documents per user posts in the corpus.", "labels": [], "entities": [{"text": "IMDB", "start_pos": 37, "end_pos": 41, "type": "DATASET", "confidence": 0.9280543327331543}, {"text": "Yelp 2013 datasets", "start_pos": 57, "end_pos": 75, "type": "DATASET", "confidence": 0.8553200562795004}, {"text": "sentiment classifi- cation", "start_pos": 85, "end_pos": 111, "type": "TASK", "confidence": 0.8854041546583176}, {"text": "IMDB dataset", "start_pos": 133, "end_pos": 145, "type": "DATASET", "confidence": 0.9717716872692108}, {"text": "Yelp 2013 datasets", "start_pos": 189, "end_pos": 207, "type": "DATASET", "confidence": 0.8145929972330729}]}, {"text": " Table 1.  We split each corpus into training, development  and testing sets with a 80/10/10 split, and conduct  tokenization and sentence splitting with Stanford  CoreNLP (", "labels": [], "entities": [{"text": "tokenization", "start_pos": 113, "end_pos": 125, "type": "TASK", "confidence": 0.9653523564338684}, {"text": "sentence splitting", "start_pos": 130, "end_pos": 148, "type": "TASK", "confidence": 0.693617433309555}, {"text": "Stanford  CoreNLP", "start_pos": 154, "end_pos": 171, "type": "DATASET", "confidence": 0.935977429151535}]}, {"text": " Table 2: Sentiment classification on IMDB, Yelp 2014 and Yelp 2013 datasets. Evaluation metrics are  accuracy (Acc, higher is better), MAE (lower is better) and RMSE (lower is better). Our full model is  UPNN (full).", "labels": [], "entities": [{"text": "Sentiment classification", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.9408644139766693}, {"text": "IMDB", "start_pos": 38, "end_pos": 42, "type": "DATASET", "confidence": 0.9543282389640808}, {"text": "Yelp 2014 and Yelp 2013 datasets", "start_pos": 44, "end_pos": 76, "type": "DATASET", "confidence": 0.7920089264710745}, {"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9991199374198914}, {"text": "Acc", "start_pos": 112, "end_pos": 115, "type": "METRIC", "confidence": 0.9384661316871643}, {"text": "MAE", "start_pos": 136, "end_pos": 139, "type": "METRIC", "confidence": 0.9978023171424866}, {"text": "RMSE", "start_pos": 162, "end_pos": 166, "type": "METRIC", "confidence": 0.9902952909469604}]}, {"text": " Table 3: Influence of user and product representations. For user k and product j, u k and p j are their  continuous vector representations, U k and P j are their continuous matrix representations (see", "labels": [], "entities": []}]}