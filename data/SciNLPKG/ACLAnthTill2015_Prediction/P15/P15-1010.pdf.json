{"title": [{"text": "SENSEMBED: Learning Sense Embeddings for Word and Relational Similarity", "labels": [], "entities": []}], "abstractContent": [{"text": "Word embeddings have recently gained considerable popularity for modeling words in different Natural Language Processing (NLP) tasks including semantic similarity measurement.", "labels": [], "entities": [{"text": "semantic similarity measurement", "start_pos": 143, "end_pos": 174, "type": "TASK", "confidence": 0.7768123348553976}]}, {"text": "However, notwithstanding their success, word embeddings are by their very nature unable to capture polysemy, as different meanings of a word are conflated into a single representation.", "labels": [], "entities": []}, {"text": "In addition, their learning process usually relies on massive corpora only, preventing them from taking advantage of structured knowledge.", "labels": [], "entities": []}, {"text": "We address both issues by proposing a multi-faceted approach that transforms word embeddings to the sense level and leverages knowledge from a large semantic network for effective semantic similarity measurement.", "labels": [], "entities": [{"text": "semantic similarity measurement", "start_pos": 180, "end_pos": 211, "type": "TASK", "confidence": 0.7237032651901245}]}, {"text": "We evaluate our approach on word similarity and relational similarity frameworks, reporting state-of-the-art performance on multiple datasets.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.7451243102550507}]}], "introductionContent": [{"text": "The much celebrated word embeddings represent anew branch of corpus-based distributional semantic model which leverages neural networks to model the context in which a word is expected to appear.", "labels": [], "entities": []}, {"text": "Thanks to their high coverage and their ability to capture both syntactic and semantic information, word embeddings have been successfully applied to a variety of NLP tasks, such as Word Sense Disambiguation (), Machine Translation (), Relational Similarity (), Semantic Relatedness ( ) and Knowledge Representation (.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 182, "end_pos": 207, "type": "TASK", "confidence": 0.7001399795214335}, {"text": "Machine Translation", "start_pos": 212, "end_pos": 231, "type": "TASK", "confidence": 0.836870551109314}, {"text": "Semantic Relatedness", "start_pos": 262, "end_pos": 282, "type": "TASK", "confidence": 0.8091962933540344}, {"text": "Knowledge Representation", "start_pos": 291, "end_pos": 315, "type": "TASK", "confidence": 0.7705654799938202}]}, {"text": "However, word embeddings inherit two important limitations from their antecedent corpusbased distributional models: (1) they are unable to model distinct meanings of a word as they conflate the contextual evidence of different meanings of a word into a single vector; and (2) they base their representations solely on the distributional statistics obtained from corpora, ignoring the wealth of information provided by existing semantic resources.", "labels": [], "entities": []}, {"text": "Several research works have tried to address these problems.", "labels": [], "entities": []}, {"text": "For instance, basing their work on the original sense discrimination approach of, applied K-means clustering to decompose word embeddings into multiple prototypes, each denoting a distinct meaning of the target word.", "labels": [], "entities": []}, {"text": "However, the sense representations obtained are not linked to any sense inventory, a mapping that consequently has to be carried out either manually, or with the help of sense-annotated data.", "labels": [], "entities": []}, {"text": "Another line of research investigates the possibility of taking advantage of existing semantic resources in word embeddings.", "labels": [], "entities": []}, {"text": "A good example is the Relation Constrained Model ().", "labels": [], "entities": []}, {"text": "When computing word embeddings, this model replaces the original co-occurrence clues from text corpora with the relationship information derived from the Paraphrase Database 1 (, an automatically extracted dataset of paraphrase pairs.", "labels": [], "entities": []}, {"text": "However, none of these techniques have simultaneously solved both above-mentioned issues, i.e., inability to model polysemy and reliance on text corpora as the only source of knowledge.", "labels": [], "entities": []}, {"text": "We propose a novel approach, called SENSEMBED, which addresses both drawbacks by exploiting semantic knowledge for modeling arbitrary word senses in a large sense inventory.", "labels": [], "entities": [{"text": "SENSEMBED", "start_pos": 36, "end_pos": 45, "type": "TASK", "confidence": 0.8035209774971008}]}, {"text": "We evaluate our representation on multiple datasets in two standard tasks: word-level semantic similarity and relational similarity.", "labels": [], "entities": [{"text": "word-level semantic similarity", "start_pos": 75, "end_pos": 105, "type": "TASK", "confidence": 0.6097756425539652}]}, {"text": "Experimental results show that moving from words to senses, while making use of lexical-semantic knowledge bases, makes embeddings significantly more powerful, resulting in consistent performance improvement across tasks.", "labels": [], "entities": []}, {"text": "Our contributions are twofold: (1) we propose a knowledge-based approach for obtaining continuous representations for individual word senses; and (2) by leveraging these representations and lexical-semantic knowledge, we put forward a semantic similarity measure with state-of-the-art performance on multiple datasets.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our sense-enhanced semantic representation on multiple word similarity and relatedness datasets (Section 4.1), as well as the relational similarity framework (Section 4.2).", "labels": [], "entities": []}, {"text": "Word similarity measurement is one of the most popular evaluation methods in lexical semantics, and semantic similarity in particular, with numerous evaluation benchmarks and datasets.", "labels": [], "entities": [{"text": "Word similarity measurement", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.7632254163424174}]}, {"text": "Given a set of word pairs, a system's task is to provide similarity judgments for each pair, and these judgements should ideally be as close as possible to those given by humans.", "labels": [], "entities": []}, {"text": "We evaluate SENSEMBED on standard word similarity and relatedness datasets: the RG-65 and the WordSim-353 (, WS-353) datasets.", "labels": [], "entities": [{"text": "SENSEMBED", "start_pos": 12, "end_pos": 21, "type": "TASK", "confidence": 0.9212191700935364}, {"text": "RG-65", "start_pos": 80, "end_pos": 85, "type": "DATASET", "confidence": 0.9326856136322021}, {"text": "WordSim-353", "start_pos": 94, "end_pos": 105, "type": "DATASET", "confidence": 0.9643834829330444}, {"text": "WS-353) datasets", "start_pos": 109, "end_pos": 125, "type": "DATASET", "confidence": 0.7153998414675394}]}, {"text": "suggested that the original WS-353 dataset conflates similarity and relatedness and divided the dataset into two subsets, each containing pairs for just one type of association measure: similarity (the WS-Sim dataset) and relatedness (the WS-Rel dataset).", "labels": [], "entities": [{"text": "WS-353 dataset", "start_pos": 28, "end_pos": 42, "type": "DATASET", "confidence": 0.9407546818256378}, {"text": "WS-Sim dataset", "start_pos": 202, "end_pos": 216, "type": "DATASET", "confidence": 0.9757407903671265}, {"text": "WS-Rel dataset", "start_pos": 239, "end_pos": 253, "type": "DATASET", "confidence": 0.9845902919769287}]}, {"text": "We also evaluate our approach on the YP-130 dataset, which was created by specifically for measuring verb similarity, and also on the Stanford's Contextual Word Similarities (SCWS), a dataset for measuring wordin-context similarity).", "labels": [], "entities": [{"text": "YP-130 dataset", "start_pos": 37, "end_pos": 51, "type": "DATASET", "confidence": 0.9309910535812378}]}, {"text": "In the SCWS dataset each word is provided with the sentence containing it, which helps in pointing out the intended sense of the corresponding target word.", "labels": [], "entities": [{"text": "SCWS dataset", "start_pos": 7, "end_pos": 19, "type": "DATASET", "confidence": 0.8808296322822571}]}, {"text": "Finally, we also report results on the MEN dataset which was recently introduced by.", "labels": [], "entities": [{"text": "MEN dataset", "start_pos": 39, "end_pos": 50, "type": "DATASET", "confidence": 0.9674672484397888}]}, {"text": "MEN contains two sets of English word pairs, together with human-assigned similarity judgments, obtained by crowdsourcing using Amazon Mechanical Turk.", "labels": [], "entities": []}, {"text": "We take as our benchmark the SemEval-2012 task on Measuring Degrees of Relational Similarity (Jurgens et al., 2012).", "labels": [], "entities": [{"text": "Measuring Degrees of Relational Similarity", "start_pos": 50, "end_pos": 92, "type": "TASK", "confidence": 0.8127778530120849}]}, {"text": "The task provides a dataset comprising 79 graded word relations, 10 of which are used for training and the rest for test.", "labels": [], "entities": []}, {"text": "The task evaluated the participating systems in terms of the Spearman correlation and the MaxDiff score.).", "labels": [], "entities": [{"text": "Spearman correlation", "start_pos": 61, "end_pos": 81, "type": "METRIC", "confidence": 0.7868503928184509}]}, {"text": "We also report results for UTD-NB and UTD-SVM (, which rely on lexical pattern classification based on Na\u00a8\u0131veNa\u00a8\u0131ve Bayes and Support Vector Machine classifiers, respectively.", "labels": [], "entities": [{"text": "UTD-NB", "start_pos": 27, "end_pos": 33, "type": "DATASET", "confidence": 0.9110113382339478}, {"text": "UTD-SVM", "start_pos": 38, "end_pos": 45, "type": "DATASET", "confidence": 0.9073863625526428}, {"text": "Na\u00a8\u0131veNa\u00a8\u0131ve Bayes", "start_pos": 103, "end_pos": 121, "type": "METRIC", "confidence": 0.6469799230496088}]}, {"text": "UTD-LDA (Rink and Harabagiu, 2013) is another system presented by the same authors that casts the task as a selectional preferences one.", "labels": [], "entities": [{"text": "UTD-LDA (Rink and Harabagiu, 2013)", "start_pos": 0, "end_pos": 34, "type": "DATASET", "confidence": 0.7709849029779434}]}, {"text": "Finally, we show the performance of Com (Zhila et al., 2013), a system that combines Word2vec, lexical patterns, and knowledge base information.", "labels": [], "entities": []}, {"text": "Similarly to the word similarity experiments, we also report a baseline based on word embeddings (Word2vec) trained on the same corpus and with the same settings as SENSEMBED.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 17, "end_pos": 32, "type": "TASK", "confidence": 0.7385389804840088}]}, {"text": "shows the performance of different systems in the task of relational similarity in terms of the Spearman correlation and MaxDiff score.", "labels": [], "entities": [{"text": "Spearman correlation", "start_pos": 96, "end_pos": 116, "type": "METRIC", "confidence": 0.691968709230423}]}, {"text": "A comparison of the results for Word2vec and SENSEMBED shows the advantage gained by moving from the word to the sense level.", "labels": [], "entities": [{"text": "Word2vec", "start_pos": 32, "end_pos": 40, "type": "DATASET", "confidence": 0.9466506838798523}]}, {"text": "Among the comparison systems, Com attains the closest performance.", "labels": [], "entities": []}, {"text": "However, we note that the system is a combination of several methods, whereas SENSEMBED is based on a single approach.", "labels": [], "entities": [{"text": "SENSEMBED", "start_pos": 78, "end_pos": 87, "type": "TASK", "confidence": 0.50676029920578}]}], "tableCaptions": [{"text": " Table 3: Spearman correlation performance on five word similarity and relatedness datasets.", "labels": [], "entities": []}, {"text": " Table 4: Spearman correlation performance of the  multi-prototype and semantically-enhanced ap- proaches on the WordSim-353 and the Stanford's  Contextual Word Similarities datasets.", "labels": [], "entities": [{"text": "correlation", "start_pos": 19, "end_pos": 30, "type": "METRIC", "confidence": 0.5597479343414307}, {"text": "WordSim-353", "start_pos": 113, "end_pos": 124, "type": "DATASET", "confidence": 0.9568396806716919}]}, {"text": " Table 6: Spearman correlation performance of word embeddings (Word2vec) and SENSEMBED on dif- ferent semantic similarity and relatedness datasets.", "labels": [], "entities": [{"text": "Word2vec", "start_pos": 63, "end_pos": 71, "type": "DATASET", "confidence": 0.943092942237854}, {"text": "SENSEMBED", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9004649519920349}]}, {"text": " Table 5: Spearman correlation performance of dif- ferent systems on the SemEval-2012 Task on Re- lational Similarity.", "labels": [], "entities": [{"text": "SemEval-2012 Task on Re- lational Similarity", "start_pos": 73, "end_pos": 117, "type": "TASK", "confidence": 0.6635935349123818}]}]}