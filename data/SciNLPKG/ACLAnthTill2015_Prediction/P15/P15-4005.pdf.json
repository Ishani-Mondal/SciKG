{"title": [{"text": "Multi-modal Visualization and Search for Text and Prosody Annotations", "labels": [], "entities": []}], "abstractContent": [{"text": "We present ICARUS for intonation, an interactive tool to browse and search automatically derived descriptions of fundamental frequency contours.", "labels": [], "entities": []}, {"text": "It offers access to tonal features in combination with other annotation layers like part-of-speech, syntax or coreference and visualizes them in a highly customizable graphi-cal interface with various playback functions.", "labels": [], "entities": []}, {"text": "The built-in search allows multi-level queries, the construction of which can be done graphically or textually, and includes the ability to search F 0 contours based on various similarity measures.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper we present ICARUS for intonation, anew module for the query and visualization tool ICARUS by.", "labels": [], "entities": [{"text": "ICARUS", "start_pos": 97, "end_pos": 103, "type": "DATASET", "confidence": 0.846107006072998}]}, {"text": "So far, ICARUS included modules for the handling of dependency treebanks) and coreference data), thus supporting typical annotation layers from the processing of written data.", "labels": [], "entities": [{"text": "ICARUS", "start_pos": 8, "end_pos": 14, "type": "DATASET", "confidence": 0.7717264890670776}]}, {"text": "However, the graphical query builder and the intuitive example-based search could prove just as expedient for other types of data, such as speech corpora, transcribed and annotated for sub word features.", "labels": [], "entities": []}, {"text": "This also allows combined research on speech and text data, e.g. the analysis of different tonal realizations of a certain syntactic structure.", "labels": [], "entities": []}, {"text": "ICARUS for intonation allows to import syllable-based prosodic features into ICARUS, which can then be visualized and queried either individually or in a combined search with e.g. syntactic features or coreference information.", "labels": [], "entities": []}, {"text": "The latter targets several user groups: speech data experts can adjust fine-grained settings on pitch accent shapes in their queries and can easily add constraints on part-of-speech or syntax information, while an expert user of dependency treebanks can get a simple visualization of the intonation contour of a sentence.", "labels": [], "entities": []}, {"text": "Furthermore ICARUS focuses on automatic annotations to allow for search on large data sets.", "labels": [], "entities": [{"text": "ICARUS", "start_pos": 12, "end_pos": 18, "type": "DATASET", "confidence": 0.7112502455711365}]}, {"text": "Thus ICARUS for intonation's main features for prosodic search are based on PaIntE, a parametric intonation model.", "labels": [], "entities": [{"text": "prosodic search", "start_pos": 47, "end_pos": 62, "type": "TASK", "confidence": 0.8080593049526215}]}, {"text": "So far, most data in intonation research is manually annotated, which is a very time consuming task: the time for annotating speech data is many times higher than the real time of the audio recording.", "labels": [], "entities": []}, {"text": "For example the Tones and Break Indices (ToBI) system for American English) takes experienced annotators about 100-200 times the real time ().", "labels": [], "entities": [{"text": "Break Indices (ToBI)", "start_pos": 26, "end_pos": 46, "type": "METRIC", "confidence": 0.8692789316177368}]}, {"text": "While manual annotations for pitch accents and prosodic phrase boundaries can also be imported, our main goal with this module is to provide intonation researchers with a customizable tool to conduct thorough studies on very large sets of only automatically annotated speech data.", "labels": [], "entities": []}, {"text": "In Sections 2 and 3 we introduce the PaIntE model and describe the current input format for the data importer.", "labels": [], "entities": []}, {"text": "Section 4 demonstrates several visualization functionalities, and Section 5 discusses the search facilities, including dependency and intonation as well as coreference and intonation queries.", "labels": [], "entities": []}, {"text": "After discussing some related work in Section 6 we conclude in Section 7.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}