{"title": [{"text": "Inducing Word and Part-of-Speech with Pitman-Yor Hidden Semi-Markov Models", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a nonparametric Bayesian model for joint unsupervised word seg-mentation and part-of-speech tagging from raw strings.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 88, "end_pos": 110, "type": "TASK", "confidence": 0.677831694483757}]}, {"text": "Extending a previous model for word segmentation, our model is called a Pitman-Yor Hidden Semi-Markov Model (PYHSMM) and considered as a method to build a class n-gram language model directly from strings, while integrating character and word level information.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.753283828496933}]}, {"text": "Experimental results on standard datasets on Japanese, Chinese and Thai revealed it outperforms previous results to yield the state-of-the-art accuracies.", "labels": [], "entities": []}, {"text": "This model will also serve to analyze a structure of a language whose words are not identified a priori.", "labels": [], "entities": []}], "introductionContent": [{"text": "Morphological analysis is a staple of natural language processing for broad languages.", "labels": [], "entities": [{"text": "Morphological analysis", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9268928170204163}, {"text": "natural language processing", "start_pos": 38, "end_pos": 65, "type": "TASK", "confidence": 0.6930798888206482}]}, {"text": "Especially for some East Asian languages such as Japanese, Chinese or Thai, word boundaries are not explicitly written, thus morphological analysis is a crucial first step for further processing.", "labels": [], "entities": []}, {"text": "Note that also in Latin and old English, scripts were originally written with no word indications (scripta continua), but people felt no difficulty reading them.", "labels": [], "entities": []}, {"text": "Here, morphological analysis means word segmentation and part-of-speech (POS) tagging.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.7344814240932465}, {"text": "part-of-speech (POS) tagging", "start_pos": 57, "end_pos": 85, "type": "TASK", "confidence": 0.7004059195518494}]}, {"text": "For this purpose, supervised methods have often been employed for training.", "labels": [], "entities": []}, {"text": "However, to train such supervised classifiers, we have to prepare a large amount of training data with correct annotations, in this case, word segmentation and POS tags.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 138, "end_pos": 155, "type": "TASK", "confidence": 0.6769939512014389}]}, {"text": "Creating and maintaining these data is not only costly but also very difficult, because generally there are no clear criteria for either \"correct\" segmentation or POS tags.", "labels": [], "entities": []}, {"text": "In fact, since there are different standards for Chinese word segmentation, widely used SIGHAN Bakeoff dataset) consists of multiple parts employing different annotation schemes.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 49, "end_pos": 74, "type": "TASK", "confidence": 0.6101037760575613}, {"text": "SIGHAN Bakeoff dataset", "start_pos": 88, "end_pos": 110, "type": "DATASET", "confidence": 0.8494890530904134}]}, {"text": "Lately, this situation has become increasingly important because there are strong demands for processing huge amounts of text in consumer generated media such as Twitter, Weibo or Facebook ().", "labels": [], "entities": []}, {"text": "They contain a plethora of colloquial expressions and newly coined words, including sentiment expressions such as emoticons that cannot be covered by fixed supervised data.", "labels": [], "entities": []}, {"text": "To automatically recognize such linguistic phenomena beyond small \"correct\" supervised data, we have to extract linguistic knowledge from the statistics of strings themselves in an unsupervised fashion.", "labels": [], "entities": []}, {"text": "Needless to say, such methods will also contribute to analyzing speech transcripts, classic texts, or even unknown languages.", "labels": [], "entities": [{"text": "analyzing speech transcripts", "start_pos": 54, "end_pos": 82, "type": "TASK", "confidence": 0.7903777559598287}]}, {"text": "From a scientific point of view, it is worthwhile to find \"words\" and their part-of-speech purely from a collection of strings without any preconceived assumptions.", "labels": [], "entities": []}, {"text": "To achieve that goal, there have been two kinds of approaches: heuristic methods and statistical generative models.", "labels": [], "entities": []}, {"text": "Heuristic methods are based on basic observations such that word boundaries will often occur at the place where predictive entropy of characters is large (i.e. the next character cannot be predicted without assuming the next word).", "labels": [], "entities": []}, {"text": "By formulating such ideas as search or MDL problems of given coding length 1 , word boundaries are found in an algorithmic fashion (.", "labels": [], "entities": []}, {"text": "However, such methods have difficulty incorporating higher-order statistics beyond simple heuristics, such as word transitions, word spelling formation, or word length distribution.", "labels": [], "entities": [{"text": "word transitions", "start_pos": 110, "end_pos": 126, "type": "TASK", "confidence": 0.7121619582176208}, {"text": "word spelling formation", "start_pos": 128, "end_pos": 151, "type": "TASK", "confidence": 0.7654818495114645}]}, {"text": "Moreover, they usually depends on tuning parameters like thresholds that cannot be learned without human intervention.", "labels": [], "entities": []}, {"text": "In contrast, statistical models are ready to incorporate all such phenomena within a consistent statistical generative model of a string, and often prove to work better than heuristic methods).", "labels": [], "entities": []}, {"text": "In fact, the statistical methods often include the criteria of heuristic methods at least in a conceptual level, which is noted in ( and also explained later in this paper.", "labels": [], "entities": []}, {"text": "Ina statistical model, each word segmentation w of a string sis regarded as a hidden stochastic variable, and the unsupervised learning of word segmentation is formulated as a maximization of a probability of w given s: argmax w p(w|s) . This means that we want the most \"natural\" segmentation w that have a high probability in a language model p(w|s).", "labels": [], "entities": [{"text": "word segmentation w", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.7889487743377686}, {"text": "word segmentation", "start_pos": 139, "end_pos": 156, "type": "TASK", "confidence": 0.7214852422475815}]}, {"text": "Lately, proposed an intermediate model between heuristic and statistical models as a product of character and word HMMs.", "labels": [], "entities": []}, {"text": "However, these two models do not have information shared between the models, which is not the case with generative models.", "labels": [], "entities": []}, {"text": "So far, these approaches only find word segmentation, leaving part-of-speech information behind.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.7334472388029099}]}, {"text": "These two problems are not actually independent but interrelated, because knowing the part-of-speech of some infrequent or unknown word will give contextual clues to word segmentation, and vice versa.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 166, "end_pos": 183, "type": "TASK", "confidence": 0.7208431959152222}]}, {"text": "For example, in Japanese can be segmented into not only /// (plum/too/peach/too), but also into // (plum/peach/peach), which is ungrammatical.", "labels": [], "entities": []}, {"text": "However, we could exclude the latter case 1 For example, defined a coding length using character n-grams plus MDL penalty.", "labels": [], "entities": []}, {"text": "Since this can be interpreted as a crude \"likelihood\" and a prior, its essence is similar but driven by a quite simplistic model.: NPYLM represented in a hierarchical Chinese restaurant process.", "labels": [], "entities": []}, {"text": "Here, a character \u221e-gram HPYLM is embedded in a word n-gram HPYLM and learned jointly during inference.", "labels": [], "entities": []}], "datasetContent": [{"text": "To validate our model, we conducted experiments on several corpora of East Asian languages with no word boundaries.", "labels": [], "entities": []}, {"text": "Datasets For East Asian languages, we used standard datasets in Japanese, Chinese and Thai as shown in.", "labels": [], "entities": []}, {"text": "The Kyoto corpus is a collection of sentences from Japanese newspaper () with both word segmentation and part-of-speech annotations.", "labels": [], "entities": [{"text": "Kyoto corpus", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9674143493175507}, {"text": "word segmentation", "start_pos": 83, "end_pos": 100, "type": "TASK", "confidence": 0.6990162134170532}]}, {"text": "BC-CWJ (Balanced Corpus of Contemporary Written Japanese) is a balanced corpus of written Japanese from the National Institute of Japanese Language and Linguistics, also with both word segmentation and part-ofspeech annotations from slightly different criteria.", "labels": [], "entities": [{"text": "BC-CWJ (Balanced Corpus of Contemporary Written Japanese)", "start_pos": 0, "end_pos": 57, "type": "DATASET", "confidence": 0.8193823496500651}]}, {"text": "For experiments on colloquial texts, we used a random subset of \"OC\" register from this corpus that is comprised of Yahoo!Japan Answers from users.", "labels": [], "entities": [{"text": "Yahoo!Japan Answers", "start_pos": 116, "end_pos": 135, "type": "DATASET", "confidence": 0.8614172786474228}]}, {"text": "For Chinese, experiments are conducted on standard datasets of; for comparison we used MSR and PKU datasets for simplified Chinese, and the CITYU dataset for traditional Chinese.", "labels": [], "entities": [{"text": "PKU datasets", "start_pos": 95, "end_pos": 107, "type": "DATASET", "confidence": 0.7918099462985992}, {"text": "CITYU dataset", "start_pos": 140, "end_pos": 153, "type": "DATASET", "confidence": 0.8968289196491241}]}, {"text": "SIGHAN datasets have word boundaries only, and we conformed to original training/test splits provided with the data.", "labels": [], "entities": [{"text": "SIGHAN datasets", "start_pos": 0, "end_pos": 15, "type": "DATASET", "confidence": 0.9115839600563049}]}, {"text": "InterBEST is a dataset in Thai used in the InterBEST 2009 word segmentation contest.", "labels": [], "entities": [{"text": "InterBEST is a dataset", "start_pos": 0, "end_pos": 22, "type": "DATASET", "confidence": 0.7819991111755371}, {"text": "InterBEST 2009 word segmentation contest", "start_pos": 43, "end_pos": 83, "type": "TASK", "confidence": 0.7738440990447998}]}, {"text": "For contrastive purposes, we used a \"Novel\" subset of it with a random sampling without replacement for training and test data.", "labels": [], "entities": []}, {"text": "Accuracies are measured in token F -measures computed as follows: R = # of correct words # of words in gold standard . Unsupervised word segmentation In, we show the accuracies of unsupervised word segmentation with previous figures.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9928520321846008}, {"text": "F -measures", "start_pos": 33, "end_pos": 44, "type": "METRIC", "confidence": 0.9186272819836935}, {"text": "R", "start_pos": 66, "end_pos": 67, "type": "METRIC", "confidence": 0.9512268304824829}, {"text": "Unsupervised word segmentation", "start_pos": 119, "end_pos": 149, "type": "TASK", "confidence": 0.6166252990563711}, {"text": "word segmentation", "start_pos": 193, "end_pos": 210, "type": "TASK", "confidence": 0.7632129788398743}]}, {"text": "We used bigram PYHSMM and set L = 4 for Chinese, L = 5, 8, 10, 21 for Japanese with different types of contiguous characters, and L = 6 for Thai.", "labels": [], "entities": []}, {"text": "The number of hidden states are K = 10 (Chinese and Thai), K = 20 (Kyoto) and K = 30 (BCCWJ).", "labels": [], "entities": [{"text": "BCCWJ", "start_pos": 86, "end_pos": 91, "type": "METRIC", "confidence": 0.4960986077785492}]}, {"text": "We can see that our PYHSMM outperforms on all the datasets.", "labels": [], "entities": [{"text": "PYHSMM", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.8579433560371399}]}, {"text": "reports that the maximum possible accuracy in unsupervised Chinese word segmentation is 84.8%, derived through the inconsistency between different segmentation standards of the SIGHAN dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9993032217025757}, {"text": "Chinese word segmentation", "start_pos": 59, "end_pos": 84, "type": "TASK", "confidence": 0.6335612336794535}, {"text": "SIGHAN dataset", "start_pos": 177, "end_pos": 191, "type": "DATASET", "confidence": 0.9390381276607513}]}, {"text": "Our PYHSMM performs nearer to this best possible accuracy, leveraging both word and character knowledge in a consistent Bayesian fashion.", "labels": [], "entities": [{"text": "PYHSMM", "start_pos": 4, "end_pos": 10, "type": "DATASET", "confidence": 0.71779865026474}, {"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9984495639801025}]}, {"text": "Further note that in Thai, quite high performance is achieved with a very small data compared to previous work.", "labels": [], "entities": []}, {"text": "have part-of-speech annotations as well.", "labels": [], "entities": []}, {"text": "For these data, we also evaluated the precision of part-ofspeech induction on the output of unsupervised word segmentation above.", "labels": [], "entities": [{"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9991115927696228}, {"text": "word segmentation", "start_pos": 105, "end_pos": 122, "type": "TASK", "confidence": 0.7547000646591187}]}, {"text": "Note that the precision is measured only over correct word segmentation that the system has output.", "labels": [], "entities": [{"text": "precision", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9994888305664062}]}, {"text": "shows the precisions; to the best of our knowledge, there are no previous work on joint unsupervised learning of words and tags, thus we only compared with Bayesian HMM (Goldwater and Griffiths, 2007) on both NPYLM segmentation and gold segmentation.", "labels": [], "entities": [{"text": "precisions", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9971047043800354}, {"text": "NPYLM segmentation", "start_pos": 209, "end_pos": 227, "type": "TASK", "confidence": 0.7272524684667587}]}, {"text": "In this evaluation, we associated each tag of supervised data with a latent state that cooccurred most frequently with that tag.", "labels": [], "entities": []}, {"text": "We can see that the precision of joint POS tagging is better than NPYLM+HMM, and even better than HMM that is run over the gold segmentation.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9995514750480652}, {"text": "POS tagging", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.6999380141496658}]}, {"text": "For colloquial Chinese, we also conducted an experiment on the Leiden Weibo Corpus (LWC), a corpus of Chinese equivalent of Twitter . We used random 20,000 sentences from this corpus, and results are shown in.", "labels": [], "entities": [{"text": "Leiden Weibo Corpus (LWC)", "start_pos": 63, "end_pos": 88, "type": "DATASET", "confidence": 0.9609391291936239}]}, {"text": "In many cases plausible words are found, and assigned to syntactically consistent states.", "labels": [], "entities": []}, {"text": "States that are not shown here are either just not used or consists of a mixture of different syntactic categories.", "labels": [], "entities": []}, {"text": "Guiding our model to induce more accurate latent states is a common problem to all unsupervised part-of-speech induction, but we show some semi-supervised results next.", "labels": [], "entities": [{"text": "part-of-speech induction", "start_pos": 96, "end_pos": 120, "type": "TASK", "confidence": 0.7605889439582825}]}, {"text": "Semi-supervised experiments Because our PYHSMM is a generative model, it is easily amenable to semi-supervised segmentation and tagging.", "labels": [], "entities": []}, {"text": "We used random 10,000 sentences from supervised data on Kyoto, BCCWJ, and LWC datasets along with unsupervised datasets in.", "labels": [], "entities": [{"text": "Kyoto, BCCWJ, and LWC datasets", "start_pos": 56, "end_pos": 86, "type": "DATASET", "confidence": 0.7070529844079699}]}, {"text": "Results are shown in: segmentation accuracies came close to 90% but do not go beyond.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 22, "end_pos": 34, "type": "TASK", "confidence": 0.9738255143165588}, {"text": "accuracies", "start_pos": 35, "end_pos": 45, "type": "METRIC", "confidence": 0.903935968875885}]}, {"text": "By inspecting the segmentation and POS that PYHSMM has output, we found that this is not necessarily a fault of our model, but it came from the often inconsistet or incorrect tagging of the dataset.", "labels": [], "entities": [{"text": "POS", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.9609764814376831}]}, {"text": "In many cases PYHSMM found more \"natural\" segmentations, but it does not always conform to the gold annotations.", "labels": [], "entities": [{"text": "PYHSMM", "start_pos": 14, "end_pos": 20, "type": "DATASET", "confidence": 0.7449912428855896}]}, {"text": "On the other hand, it often oversegments emotional expressions (sequence of the same character, for example) and this is one of the major sources of errors.", "labels": [], "entities": []}, {"text": "Finally, we note that our proposed model for unsupervised learning is most effective for the language which we do not know its syntactic behavior but only know raw strings as its data.", "labels": [], "entities": []}, {"text": "In, we show an excerpt of results to model a Japanese local dialect (Mikawa-ben around Nagoya district) collected from a specific Twitter.", "labels": [], "entities": []}, {"text": "Even from the surface appearance of characters, we can see that similar words are assigned to the same state including some emoticons, and in fact we can identify a state of postpositions specific to that dialect (state 3).", "labels": [], "entities": []}, {"text": "Notice that the words themselves are not trivial before this analysis.", "labels": [], "entities": []}, {"text": "There are also some name of local places (state 41) and general Japanese postpositions (2) or nouns.", "labels": [], "entities": []}, {"text": "Because of the sparsity promoting prior (7) over the hidden states, actually used states are sparse and the results can be considered quite satisfactory.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Datasets used for evaluation. Abbrevi- ations: Ja=Japanese, Zh=Chinese, Th=Thai lan- guage.", "labels": [], "entities": []}, {"text": " Table 4: Accuracies of unsupervised word seg- mentation. BE is a Branching Entropy method of  Zhikov et al. (2010), and HMM 2 is a product of  word and character HMMs of Chen et al. (2014).   *  is the accuracy decoded with L = 3: it becomes  81.7 with L = 4 as MSR and PKU.", "labels": [], "entities": [{"text": "BE", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.9986995458602905}, {"text": "accuracy", "start_pos": 203, "end_pos": 211, "type": "METRIC", "confidence": 0.9985412359237671}]}, {"text": " Table 5: Precision of POS tagging on correctly  segmented words.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9883490800857544}, {"text": "POS tagging", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.8215547502040863}]}, {"text": " Table 6: Semi-supervised segmentation and POS  tagging accuracies. POS is measured by precision.", "labels": [], "entities": [{"text": "POS  tagging", "start_pos": 43, "end_pos": 55, "type": "TASK", "confidence": 0.7624854445457458}, {"text": "POS", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.884518027305603}, {"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9991303086280823}]}]}