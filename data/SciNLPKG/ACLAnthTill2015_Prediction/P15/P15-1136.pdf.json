{"title": [{"text": "Entity-Centric Coreference Resolution with Model Stacking", "labels": [], "entities": [{"text": "Entity-Centric Coreference Resolution", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.6491583387056986}]}], "abstractContent": [{"text": "Mention pair models that predict whether or not two mentions are coreferent have historically been very effective for coref-erence resolution, but do not make use of entity-level information.", "labels": [], "entities": [{"text": "coref-erence resolution", "start_pos": 118, "end_pos": 141, "type": "TASK", "confidence": 0.8662555515766144}]}, {"text": "However, we show that the scores produced by such models can be aggregated to define powerful entity-level features between clusters of mentions.", "labels": [], "entities": []}, {"text": "Using these features, we train an entity-centric coreference system that learns an effective policy for building up coreference chains incrementally.", "labels": [], "entities": []}, {"text": "The mention pair scores are also used to prune the search space the system works in, allowing for efficient training with an exact loss function.", "labels": [], "entities": []}, {"text": "We evaluate our system on the English portion of the 2012 CoNLL Shared Task dataset and show that it improves over the current state of the art.", "labels": [], "entities": [{"text": "English portion of the 2012 CoNLL Shared Task dataset", "start_pos": 30, "end_pos": 83, "type": "DATASET", "confidence": 0.6970638268523746}]}], "introductionContent": [{"text": "Coreference resolution, the task of identifying mentions in a text that refer to the same real world entity, is an important aspect of text understanding and has numerous applications.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9212619662284851}, {"text": "text understanding", "start_pos": 135, "end_pos": 153, "type": "TASK", "confidence": 0.8181914389133453}]}, {"text": "Many approaches to coreference resolution learn a scoring function defined over mention pairs to guide the coreference decisions (.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.9700256884098053}]}, {"text": "However, such systems do not make use of entity-level information, i.e., features between clusters of mentions instead of pairs.", "labels": [], "entities": []}, {"text": "Using entity-level information is valuable because it allows early coreference decisions to inform later ones.", "labels": [], "entities": []}, {"text": "For example, finding that Clinton and she corefer makes it more likely that Clinton corefers with Hillary Clinton than Bill Clinton due to gender agreement constraints.", "labels": [], "entities": []}, {"text": "Such information has been incorporated successfully into entity-centric coreference systems that buildup coreference clusters incrementally, using the information from the partially completed coreference chains produced so far to guide later decisions ().", "labels": [], "entities": []}, {"text": "However, defining useful features between clusters of mentions and learning an effective policy for incrementally building up clusters can be challenging, and many recent state-of-the-art systems work entirely or almost entirely over pairs of mentions (.", "labels": [], "entities": []}, {"text": "In this paper we introduce a novel coreference system that combines the advantages of mention pair and entity-centric systems with model stacking.", "labels": [], "entities": []}, {"text": "We first propose two mention pair models designed to capture different linguistic phenomena in coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 95, "end_pos": 117, "type": "TASK", "confidence": 0.9623515009880066}]}, {"text": "We then describe how the probabilities produced by these models can be used to generate expressive features between clusters of mentions.", "labels": [], "entities": []}, {"text": "Using these features, we train an entity-centric incremental coreference system.", "labels": [], "entities": []}, {"text": "The entity-centric system builds up coreference chains with agglomerative clustering: each mention starts in its own cluster and then pairs of clusters are merged each step.", "labels": [], "entities": []}, {"text": "We train an agent to determine whether it is desirable to merge a particular pair of clusters using an imitation learning algorithm based on DAgger ().", "labels": [], "entities": []}, {"text": "Previous incremental coreference systems heuristically define which actions are beneficial for the agent to perform, but we instead propose away of assigning exact costs to actions based on coreference evaluation metrics, adding a concept of the severity of a mistake.", "labels": [], "entities": []}, {"text": "Furthermore, rather than considering all pairs of clusters as candidate merges, we use the scores of the pairwise models to reduce the search space, first by providing an ordering over which merges are considered and secondly by discarding merges that are not likely to be good.", "labels": [], "entities": []}, {"text": "This greatly reduces the time it takes to run the agent, making learning computationally feasible.", "labels": [], "entities": []}, {"text": "Imitation learning is challenging because it is a non-i.i.d. learning problem; the distribution of states seen by the agent depends on the agent's parameters.", "labels": [], "entities": [{"text": "Imitation learning", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9848768711090088}]}, {"text": "Model stacking offers away of decomposing the learning problem by training pairwise models with many parameters in a straightforward supervised learning setting and using their outputs for training a much simpler model in the more difficult imitation learning setting.", "labels": [], "entities": [{"text": "Model stacking", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7738447785377502}]}, {"text": "Furthermore, mention pair scores can produce powerful features for training the agent because the scores indicate which mention pairs between the clusters in question are relevant; high scoring and low scoring pairs can indicate when a merge should be forced or disallowed while other mention pairs may provide little useful information.", "labels": [], "entities": []}, {"text": "We run experiments on the English portion of the 2012 CoNLL Shared Task dataset.", "labels": [], "entities": [{"text": "2012 CoNLL Shared Task dataset", "start_pos": 49, "end_pos": 79, "type": "DATASET", "confidence": 0.7885777354240417}]}, {"text": "The entitycentric clustering algorithm greatly outperforms commonly used heuristic methods for coordinating pairwise scores to produce a coreference partition.", "labels": [], "entities": [{"text": "entitycentric clustering", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.7528004944324493}]}, {"text": "We also show that combining the scores of different pairwise models designed to capture different aspects coreference results in significant gains inaccuracy.", "labels": [], "entities": []}, {"text": "Our final system gets a combined score of 63.02 on the dataset, substantially outperforming other state of the art systems.", "labels": [], "entities": []}], "datasetContent": [{"text": "We apply our model to the English portion of the CoNLL 2012 Shared Task data, which is derived from the OntoNotes corpus ().", "labels": [], "entities": [{"text": "CoNLL 2012 Shared Task data", "start_pos": 49, "end_pos": 76, "type": "DATASET", "confidence": 0.9237588286399842}, {"text": "OntoNotes corpus", "start_pos": 104, "end_pos": 120, "type": "DATASET", "confidence": 0.9248947203159332}]}, {"text": "The data is split into a training set of 2802 documents, development set of 343 documents, and a test set of 345 documents.", "labels": [], "entities": []}, {"text": "We use the provided preprocessing for parse trees, named entity tags, etc.", "labels": [], "entities": []}, {"text": "The models are evaluated using three of the most popular metrics for coreference resolution: MUC, B 3 , and Entity-based CEAFE (CEAF \u03c6 4 ).", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 69, "end_pos": 91, "type": "TASK", "confidence": 0.9531669318675995}, {"text": "B 3", "start_pos": 98, "end_pos": 101, "type": "METRIC", "confidence": 0.9577502012252808}, {"text": "Entity-based CEAFE (CEAF \u03c6 4 )", "start_pos": 108, "end_pos": 138, "type": "METRIC", "confidence": 0.8833948033196586}]}, {"text": "We also include the average F 1 score (CoNLL F 1 ) of these three metrics, as is commonly done in CoNLL Shared Tasks.", "labels": [], "entities": [{"text": "F 1 score (CoNLL F 1 )", "start_pos": 28, "end_pos": 50, "type": "METRIC", "confidence": 0.8425018489360809}]}, {"text": "We used the most recent version of the CoNLL scorer (version 8.01), which implements the original definitions of these metrics.", "labels": [], "entities": [{"text": "CoNLL scorer", "start_pos": 39, "end_pos": 51, "type": "DATASET", "confidence": 0.8348239660263062}]}], "tableCaptions": [{"text": " Table 1: Metric scores on the development set  for the classification and ranking pairwise mod- els when using best-first clustering (B.F.) or the  entity-centric model (E.C.).", "labels": [], "entities": []}, {"text": " Table 3: Comparison of this work with other state-of-the-art approaches on the test set.", "labels": [], "entities": []}]}