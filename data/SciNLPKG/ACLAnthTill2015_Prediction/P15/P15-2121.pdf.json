{"title": [{"text": "Constrained Semantic Forests for Improved Discriminative Semantic Parsing", "labels": [], "entities": [{"text": "Improved Discriminative Semantic Parsing", "start_pos": 33, "end_pos": 73, "type": "TASK", "confidence": 0.5267245322465897}]}], "abstractContent": [{"text": "In this paper, we present a model for improved discriminative semantic parsing.", "labels": [], "entities": [{"text": "discriminative semantic parsing", "start_pos": 47, "end_pos": 78, "type": "TASK", "confidence": 0.6480622589588165}]}, {"text": "The model addresses an important limitation associated with our previous state-of-the-art discriminative semantic parsing model-the relaxed hybrid tree model by introducing our constrained semantic forests.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 105, "end_pos": 121, "type": "TASK", "confidence": 0.7786641418933868}]}, {"text": "We show that our model is able to yield new state-of-the-art results on standard datasets even with simpler features.", "labels": [], "entities": []}, {"text": "Our system is available for download from http://statnlp.org/research/sp/.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper addresses the problem of parsing natural language sentences into their corresponding semantic representations in the form of formal logical representations.", "labels": [], "entities": [{"text": "parsing natural language sentences into their corresponding semantic representations", "start_pos": 36, "end_pos": 120, "type": "TASK", "confidence": 0.8139259219169617}]}, {"text": "Such a task is also known as semantic parsing.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.7527881860733032}]}, {"text": "One state-of-the-art model for semantic parsing is our recently introduced relaxed hybrid tree model, which performs integrated lexicon acquisition and semantic parsing within a single framework utilizing efficient algorithms for training and inference.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 31, "end_pos": 47, "type": "TASK", "confidence": 0.8166870772838593}, {"text": "semantic parsing", "start_pos": 152, "end_pos": 168, "type": "TASK", "confidence": 0.7292466163635254}]}, {"text": "The model allows natural language phrases to be recursively mapped to semantic units, where certain long-distance dependencies can be captured.", "labels": [], "entities": []}, {"text": "It relies on representations called relaxed hybrid trees that can jointly represent both the sentences and semantics.", "labels": [], "entities": []}, {"text": "The model is essentially discriminative, and allows rich features to be incorporated.", "labels": [], "entities": []}, {"text": "Unfortunately, the relaxed hybrid tree model has an important limitation: it essentially does not allow certain sentence-semantics pairs to be jointly encoded using the proposed relaxed hybrid tree representations.", "labels": [], "entities": []}, {"text": "Thus, the model is unable to identify joint representations for certain sentence-semantics pairs during the training process, and is unable to produce desired outputs for certain inputs during the evaluation process.", "labels": [], "entities": []}, {"text": "In this work, we propose a solution addressing the above limitation, which makes our model more robust.", "labels": [], "entities": []}, {"text": "Through experiments, we demonstrate that our improved discriminative model for semantic parsing, even when simpler features are used, is able to obtain new state-of-the-art results on standard datasets.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 79, "end_pos": 95, "type": "TASK", "confidence": 0.7844532430171967}]}], "datasetContent": [{"text": "Our experiments were conducted on the publicly available multilingual GeoQuery dataset.", "labels": [], "entities": [{"text": "GeoQuery dataset", "start_pos": 70, "end_pos": 86, "type": "DATASET", "confidence": 0.8649330139160156}]}, {"text": "Various previous works on semantic parsing used this dataset for evaluations).", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 26, "end_pos": 42, "type": "TASK", "confidence": 0.7616804242134094}]}, {"text": "The dataset consists of 880 natural language sentences where each sentence is coupled with a formal tree-structured semantic representation.", "labels": [], "entities": []}, {"text": "The early version of this dataset was annotated with English only (), and released aversion that is annotated with three additional languages: German, Greek and Thai.", "labels": [], "entities": []}, {"text": "To make our system directly comparable to previous works, we used the same train/test split used in those works () for evaluation.", "labels": [], "entities": []}, {"text": "We also followed the standard approach for evaluating the correctness of an output semantic representation from our system.", "labels": [], "entities": []}, {"text": "Specifically, we used a standard script to construct Prolog queries based on the outputs, and used the queries to retrieve answers from the GeoQuery database.", "labels": [], "entities": [{"text": "GeoQuery database", "start_pos": 140, "end_pos": 157, "type": "DATASET", "confidence": 0.943413108587265}]}, {"text": "Following previous works, we regarded an output semantic representation as correct if and only if it returned the same answers as the gold standard (.", "labels": [], "entities": []}, {"text": "The results of our system as well as those of several previous systems are given in.", "labels": [], "entities": []}, {"text": "We compared our system's performance against those of several previous works.", "labels": [], "entities": []}, {"text": "The WASP system () is based on statistical machine translation technique while the HY-BRIDTREE+ system () is based on the generative hybrid tree model augmented with a discriminative re-ranking stage where certain global features are used.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.6155255138874054}]}, {"text": "UBL-S () is a CCG-based semantic parsing system.", "labels": [], "entities": [{"text": "UBL-S", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8252583146095276}, {"text": "CCG-based semantic parsing", "start_pos": 14, "end_pos": 40, "type": "TASK", "confidence": 0.5335678358872732}]}, {"text": "TREETRANS () is the system based on tree transducers.", "labels": [], "entities": [{"text": "TREETRANS", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.8435164093971252}]}, {"text": "RHT) is the discriminative semantic parsing system based on relaxed hybrid trees.", "labels": [], "entities": [{"text": "discriminative semantic parsing", "start_pos": 12, "end_pos": 43, "type": "TASK", "confidence": 0.7036314010620117}]}, {"text": "In practice, we set c (the maximum height of a semantic representation) to 20 in our experi- ments, which we determined based on the heights of the semantic trees that appear in the training data.", "labels": [], "entities": []}, {"text": "Results showed that our system consistently yielded higher results than all the previous systems, including our state-of-the-art relaxed hybrid tree system (the full model, when all the features are used), in terms of both accuracy score and F 1 -measure.", "labels": [], "entities": [{"text": "accuracy score", "start_pos": 223, "end_pos": 237, "type": "METRIC", "confidence": 0.9865680634975433}, {"text": "F 1 -measure", "start_pos": 242, "end_pos": 254, "type": "METRIC", "confidence": 0.9854594618082047}]}, {"text": "We would like to highlight two potential advantages of our new model over the old RHT model.", "labels": [], "entities": []}, {"text": "First, our model is able to handle certain sentence-semantics pairs which could not be handled by RHT during both training and evaluation as discussed in Section 3.1.", "labels": [], "entities": []}, {"text": "Second, our model considers the additional pattern X and therefore has the capability to capture more accurate dependencies between the words and semantic units.", "labels": [], "entities": []}, {"text": "We note that in our experiments we used a small subset of the features used by our relaxed hybrid tree work.", "labels": [], "entities": []}, {"text": "Specifically, we did not use any long-distance features, and also did not use any character-level features.", "labels": [], "entities": []}, {"text": "As we have mentioned in, although the RHT model is able to capture unbounded long-distance dependencies, for certain languages such as German such longdistance features appeared to be detrimental to the performance of the system (Lu, 2014,).", "labels": [], "entities": []}, {"text": "Here in this work, we only used simple unigram features (concatenation of a semantic unit and an individual word that appears directly below that unit in the joint representation), pattern features (concatenation of a semantic unit and the pattern below that unit) as well as transition features (concatenation of two semantic units that form a parent-child relationship) described in.", "labels": [], "entities": []}, {"text": "While additional features could potentially lead to better results, using simpler features would make our model more compact and more interpretable.", "labels": [], "entities": []}, {"text": "We summarized in the number of features used in both the previous RHT system and our system across four different languages.", "labels": [], "entities": []}, {"text": "It can be seen that our system only required about 2-3% of the: Number of features involved for both the RHT system and our new system using constrained semantic forests, across four different languages.", "labels": [], "entities": []}, {"text": "features used in the previous system.", "labels": [], "entities": []}, {"text": "We also note that the training time for our model is longer than that of the relaxed hybrid tree model since the space for H (n, m ) is now much larger than the space for H(n, m ).", "labels": [], "entities": []}, {"text": "In practice, to make the overall training process faster, we implemented a parallel version of the original RHT algorithm.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Performance of various works across four different languages. Acc.: accuracy percentage, F:  F 1 -measure percentage.", "labels": [], "entities": [{"text": "Acc.", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.9981042146682739}, {"text": "accuracy percentage", "start_pos": 78, "end_pos": 97, "type": "METRIC", "confidence": 0.9869843125343323}, {"text": "F:  F 1 -measure percentage", "start_pos": 99, "end_pos": 126, "type": "METRIC", "confidence": 0.8968278425080436}]}, {"text": " Table 3: Number of features involved for both  the RHT system and our new system using con- strained semantic forests, across four different lan- guages.", "labels": [], "entities": [{"text": "RHT system", "start_pos": 52, "end_pos": 62, "type": "DATASET", "confidence": 0.7749687135219574}]}]}