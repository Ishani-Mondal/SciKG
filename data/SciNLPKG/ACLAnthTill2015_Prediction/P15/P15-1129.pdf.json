{"title": [], "abstractContent": [{"text": "How do we build a semantic parser in anew domain starting with zero training ex-amples?", "labels": [], "entities": []}, {"text": "We introduce anew methodology for this setting: First, we use a simple grammar to generate logical forms paired with canonical utterances.", "labels": [], "entities": []}, {"text": "The logical forms are meant to cover the desired set of compositional operators, and the canon-ical utterances are meant to capture the meaning of the logical forms (although clumsily).", "labels": [], "entities": []}, {"text": "We then use crowdsourcing to paraphrase these canonical utterances into natural utterances.", "labels": [], "entities": []}, {"text": "The resulting data is used to train the semantic parser.", "labels": [], "entities": []}, {"text": "We further study the role of compositionality in the resulting paraphrases.", "labels": [], "entities": []}, {"text": "Finally, we test our methodology on seven domains and show that we can build an adequate semantic parser in just a few hours.", "labels": [], "entities": []}], "introductionContent": [{"text": "By mapping natural language utterances to executable logical forms, semantic parsers have been useful fora variety of applications requiring precise language understanding (.", "labels": [], "entities": []}, {"text": "Previous work has focused on how to train a semantic parser given input utterances, but suppose we wanted to build a semantic parser fora new domain-for example, a natural language interface into a publications database.", "labels": [], "entities": []}, {"text": "Since no such interface exists, we do not even have a naturally occurring source of input utterances that we can annotate.", "labels": [], "entities": []}, {"text": "So where do we start?", "labels": [], "entities": []}, {"text": "In this paper, we advocate a functionalitydriven process for rapidly building a semantic * Both authors equally contributed to the paper.", "labels": [], "entities": []}, {"text": "Paraphrases what is the newest published article?", "labels": [], "entities": []}, {"text": "who has published the most articles?", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our functionality-driven process on the seven domains described in Section 5 and one new domain we describe in Section 7.3.", "labels": [], "entities": []}, {"text": "For each domain, we held out a random 20% of the examples as the test set, and performed development on the remaining 80%, further splitting it to a training and development set (80%/20%).", "labels": [], "entities": []}, {"text": "We created a database for each domain by randomly generating facts using entities and properties in the domain (with type-checking).", "labels": [], "entities": []}, {"text": "We evaluated using accuracy, which is the fraction of examples that yield the correct denotation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9995943903923035}]}, {"text": "To verify the title of this paper, we attempted to create a semantic parser fora new domain (RECIPES) exactly 24 hours before the submission deadline.", "labels": [], "entities": [{"text": "RECIPES", "start_pos": 93, "end_pos": 100, "type": "METRIC", "confidence": 0.9161495566368103}]}, {"text": "Starting at midnight, we created a seed lexicon in less than 30 minutes.", "labels": [], "entities": []}, {"text": "Then we generated canonical utterances and allowed AMT workers to provide paraphrases overnight.", "labels": [], "entities": [{"text": "AMT", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.9353344440460205}]}, {"text": "In the morning, we trained our parser and obtained an accuracy of 70.8% on the test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9996992349624634}]}], "tableCaptions": [{"text": " Table 5: Test set results on all domains and baselines.", "labels": [], "entities": []}]}