{"title": [{"text": "Implicit Role Linking on Chinese Discourse: Exploiting Explicit Roles and Frame-to-Frame Relations", "labels": [], "entities": [{"text": "Implicit Role Linking", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9148724675178528}]}], "abstractContent": [{"text": "There is a growing interest in researching null instantiations, which are those implicit semantic arguments.", "labels": [], "entities": []}, {"text": "Many of these implicit arguments can be linked to referents in context, and their discoveries are of great benefits to semantic processing.", "labels": [], "entities": [{"text": "semantic processing", "start_pos": 119, "end_pos": 138, "type": "TASK", "confidence": 0.7739764451980591}]}, {"text": "We address the issue of automatically identifying and resolving implicit arguments in Chinese discourse.", "labels": [], "entities": [{"text": "automatically identifying and resolving implicit arguments in Chinese discourse", "start_pos": 24, "end_pos": 103, "type": "TASK", "confidence": 0.7785739269521501}]}, {"text": "For their resolutions, we present an approach that combines the information about overtly labeled arguments and frame-to-frame relations defined by FrameNet.", "labels": [], "entities": [{"text": "FrameNet", "start_pos": 148, "end_pos": 156, "type": "DATASET", "confidence": 0.8899292945861816}]}, {"text": "Experimental results on our created corpus demonstrate the effectiveness of our approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "In natural discourse, only a small proportion of the theoretically possible semantic arguments of predicates tend to be locally instantiated.", "labels": [], "entities": []}, {"text": "Other locally unrealized semantic roles are called null instantiations (NIs).", "labels": [], "entities": []}, {"text": "Nevertheless, many of these implicit roles, while linguistically unexpressed, can often be bound to antecedent referents in the discourse context.", "labels": [], "entities": []}, {"text": "What's more, capturing such implicit semantic roles and linking them to their antecedents can dramatically help text understanding.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.881079912185669}]}, {"text": "Example shows an analyzed result by employing Chinese FrameNet (, which is a lexical semantic knowledge base based on the frame semantics of and takes Berkeley's FrameNet Project () as the reference.", "labels": [], "entities": [{"text": "Chinese FrameNet", "start_pos": 46, "end_pos": 62, "type": "DATASET", "confidence": 0.8109346926212311}]}, {"text": "In Chinese FrameNet, the predicates, called lexical units (LU), evoke frames which roughly correspond to different events or scenarios.", "labels": [], "entities": []}, {"text": "Each frame defines a set of arguments called Frame Elements (FE).", "labels": [], "entities": [{"text": "Frame Elements (FE", "start_pos": 45, "end_pos": 63, "type": "METRIC", "confidence": 0.4512175917625427}]}, {"text": "The set of FEs is further split into core FEs and non-core FEs.", "labels": [], "entities": [{"text": "FEs", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.4136400520801544}]}, {"text": "Particularly, the core FEs are the essential components of a frame and can be defined by themselves.", "labels": [], "entities": []}, {"text": "However, not all core FEs of a frame can be realized simultaneously in a sentence.", "labels": [], "entities": []}, {"text": "These non-instantiated FEs are considered as null instantiations of the frame elements.", "labels": [], "entities": [{"text": "FEs", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.8198826313018799}]}, {"text": "Depending on the interpretation type of the omission, Chinese FrameNet divides the NIs into two categories: 1) Indefinite Null Instantiations (INIs), the missing element which can be understood given interpretational conventions and do not need resolution, and 2) Definite Null Instantiations (DNIs), the missing element which is something that can be understood in the linguistic or discourse context, and the fillers need to be inferred from the context through resolutions.", "labels": [], "entities": [{"text": "Chinese FrameNet", "start_pos": 54, "end_pos": 70, "type": "DATASET", "confidence": 0.8234552145004272}]}, {"text": "The purpose is different, specially used for storing the urn; due to the different heights, generally launched Cause_motion into [the orbit over 3000 kilometers away from the surface of earth] Goal . Particularly, in example (1), lexical unit (or target) launched/u evokes the semantic frame Cause_motion, which has nine core FEs, namely Agent, Theme, Source, Path, Goal, Area, Cause, Result, Initial_State, but only one of them is instantiated, i.e. Goal, whose filler is [the orbit over 3000 kilometers away from the surface of earth/\u00e5/\u00a5L\u00a13000 \u00f5\u00fap?\u201a\u00a5;\u00fe].", "labels": [], "entities": [{"text": "FEs", "start_pos": 326, "end_pos": 329, "type": "METRIC", "confidence": 0.8845434784889221}]}, {"text": "For another core FE Theme, it is filled by [The celestial burial satellite/U:\u00a5(] that occurs in the previous sentence.", "labels": [], "entities": [{"text": "FE Theme", "start_pos": 17, "end_pos": 25, "type": "TASK", "confidence": 0.5261150747537613}]}, {"text": "Clearly, human beings have no problem to infer these uninstantiated roles and find the corresponding fillers based on the relevant context information, but this is beyond the capacity of state-of-the-art semantic role labeling systems.", "labels": [], "entities": []}, {"text": "Next, we formalize the problem as follows: given a discourse D = {S 1 , S 2 , ..., Sn }, where S k (k \u2208) is the k-th sentence in D.", "labels": [], "entities": []}, {"text": "The lexical unit set in S k is T k = {T k1 , T k2 , ..., T kp }, and F k = {F k1 , F k2 , ..., F kp } is relevant frame set.", "labels": [], "entities": []}, {"text": "For a particular frame F ki (i \u2208), its core FE set is E ki = {e 1 , e 2 , ..., em }, but it is possible that only part of core FEs C ki appears in S k , i.e. C ki \u2286 E ki . Apparently the set E ki \u2212 C ki includes the uninstantiated core FEs.", "labels": [], "entities": []}, {"text": "Thus, we need to determine which elements in E ki \u2212 C ki are null instantiations.", "labels": [], "entities": []}, {"text": "If em (e m \u2208 E ki \u2212 C ki ) has been identified as a null instantiated FE, we should determine whether em is a DNI.", "labels": [], "entities": [{"text": "FE", "start_pos": 70, "end_pos": 72, "type": "METRIC", "confidence": 0.9709115624427795}]}, {"text": "If so, we need to find the corresponding antecedent d min context.", "labels": [], "entities": []}, {"text": "The major contributions of this paper can be summarized as follows: (i) We have created a null instantiation (NI) annotations corpus, consisting of 164 Chinese discourses across different fields.", "labels": [], "entities": []}, {"text": "(ii) We use frame-to-frame relations to find antecedents from those explicit semantic roles.", "labels": [], "entities": []}], "datasetContent": [{"text": "Data: Experimental data set comes from Semantic Computing and Chinese FrameNet Research Centor of Shanxi University . Because of the current low performance of CFN automatic semantic analysis systems, all discourses are labeled semantic roles manually, and the process is similar with the FrameNet annotation.", "labels": [], "entities": [{"text": "Chinese FrameNet Research Centor", "start_pos": 62, "end_pos": 94, "type": "DATASET", "confidence": 0.8165487945079803}, {"text": "CFN automatic semantic analysis", "start_pos": 160, "end_pos": 191, "type": "TASK", "confidence": 0.680089108645916}]}, {"text": "First, the ICTCLAS are used for part-of-speech tagging (omitted in examples), and we treat verbs, adjectives and nouns in each sentence as potential targets.", "labels": [], "entities": [{"text": "ICTCLAS", "start_pos": 11, "end_pos": 18, "type": "DATASET", "confidence": 0.6579461097717285}, {"text": "part-of-speech tagging", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.6814223229885101}]}, {"text": "As not all potential targets can be annotated, it is necessary to identify those targets which can evoke frames.", "labels": [], "entities": []}, {"text": "Then, we choose corresponding frames for those targets.", "labels": [], "entities": []}, {"text": "For one verb target launched/u in example (1), we find its evoked frame Cause_motion.", "labels": [], "entities": []}, {"text": "Then annotate semantic roles for those constituents which share syntactical relations with this target, so the span [the orbit over 3000 kilometers away from the surface of earth/\u00e5/\u00a5L\u00a13000 \u00f5\u00fap?\u201a\u00a5;\u00fe] is annotated as role Goal, which is, however, the only one instantiated, out of nine Cause_motion's core frame elements.", "labels": [], "entities": []}, {"text": "So according to the context and frame element relations, we need to determine whether each missing frame element should be annotated as DNI or INI.", "labels": [], "entities": []}, {"text": "Next, we generate the XML format for our annotated corpus, which is similar to the data format in SemEval-10 Task 10.", "labels": [], "entities": [{"text": "SemEval-10 Task 10", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.640615979830424}]}, {"text": "Our 164 discourses had been annotated by one person (to make it consistent), and they consist of 57 discourses from People's Daily and 107 discourses from Chinese reading comprehension, which cover technology, healthcare, social, geography and other fields.", "labels": [], "entities": [{"text": "People's Daily", "start_pos": 116, "end_pos": 130, "type": "DATASET", "confidence": 0.8913718660672506}]}, {"text": "Each discourse contains 10 sentences in average.", "labels": [], "entities": []}, {"text": "The data set contains about 37526 words in 1618 sentences; it has 175 frame types, including 2283 annotated frame instances.", "labels": [], "entities": []}, {"text": "shows the detailed statistics of our data set.", "labels": [], "entities": []}, {"text": "we'll share our data in the website(http://sccfn.sxu.edu.cn/  Definite Null Instantiation identification and resolution model: Our maximum entropy classification model uses the toolkit from with the default parameter values.", "labels": [], "entities": [{"text": "Null Instantiation identification and resolution", "start_pos": 71, "end_pos": 119, "type": "TASK", "confidence": 0.5946465194225311}, {"text": "maximum entropy classification", "start_pos": 131, "end_pos": 161, "type": "TASK", "confidence": 0.6697014470895132}]}, {"text": "The SVM classifier for comparison was trained via SVM toolkit LIBSVM with the default parameter values too.", "labels": [], "entities": [{"text": "SVM toolkit LIBSVM", "start_pos": 50, "end_pos": 68, "type": "DATASET", "confidence": 0.8992405533790588}]}, {"text": "Based on the experimental methods described in the previous section, we have systematically evaluated our approach on the constructed Chinese null instantiation corpus.", "labels": [], "entities": [{"text": "Chinese null instantiation corpus", "start_pos": 134, "end_pos": 167, "type": "DATASET", "confidence": 0.6903784573078156}]}, {"text": "Note all the performances are achieved using 5-fold cross validation.", "labels": [], "entities": []}, {"text": "Null Instantiation Detection gives the performance of NI detection, which achieves 72.71%, 86.12% and 78.84% in precision, recall and F-score, respectively.", "labels": [], "entities": [{"text": "Null Instantiation Detection", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7619077066580454}, {"text": "NI detection", "start_pos": 54, "end_pos": 66, "type": "TASK", "confidence": 0.7771629989147186}, {"text": "precision", "start_pos": 112, "end_pos": 121, "type": "METRIC", "confidence": 0.9997126460075378}, {"text": "recall", "start_pos": 123, "end_pos": 129, "type": "METRIC", "confidence": 0.9979217648506165}, {"text": "F-score", "start_pos": 134, "end_pos": 141, "type": "METRIC", "confidence": 0.9976713061332703}]}, {"text": "Here, the relatively lower precision is mainly due to the heuristic rules used to detect NIs.", "labels": [], "entities": [{"text": "precision", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.999251663684845}]}, {"text": "However, it is worth to point out that lower precision and higher recall is highly beneficial, as higher recall means less filtering of true NIs.", "labels": [], "entities": [{"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9988622665405273}, {"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9991853833198547}, {"text": "recall", "start_pos": 105, "end_pos": 111, "type": "METRIC", "confidence": 0.9983121156692505}]}, {"text": "To illustrate the effectiveness of our method, we compare it with the Lei et al.'s method on our data, as shown in the.", "labels": [], "entities": []}, {"text": "The F-score of our method is 78.84%, which is 9% higher than that of Lei et al.'s method.", "labels": [], "entities": [{"text": "F-score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9991768002510071}]}, {"text": "Clearly, these experimental results further prove that our secondlevel identification is very effective.", "labels": [], "entities": [{"text": "secondlevel identification", "start_pos": 59, "end_pos": 85, "type": "TASK", "confidence": 0.6514147967100143}]}, {"text": "Definite Null Instantiation Identification provides the performance of DNI identification on our automatic NI detection results.", "labels": [], "entities": [{"text": "Null Instantiation Identification", "start_pos": 9, "end_pos": 42, "type": "TASK", "confidence": 0.7554010053475698}, {"text": "DNI identification", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.8976073265075684}, {"text": "NI detection", "start_pos": 107, "end_pos": 119, "type": "TASK", "confidence": 0.8196714222431183}]}, {"text": "It shows that DNI identification based on maximum entropy model achieves the performance of 67.86%, 69.93% and 68.88% in terms of precision, recall and F-score respectively, which are better than the results using SVM classifier, as well as the results employing Lei et al.'s method on our data.", "labels": [], "entities": [{"text": "DNI identification", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.9105361104011536}, {"text": "precision", "start_pos": 130, "end_pos": 139, "type": "METRIC", "confidence": 0.9996411800384521}, {"text": "recall", "start_pos": 141, "end_pos": 147, "type": "METRIC", "confidence": 0.9986403584480286}, {"text": "F-score", "start_pos": 152, "end_pos": 159, "type": "METRIC", "confidence": 0.9976825714111328}]}], "tableCaptions": [{"text": " Table 5: Performance of NI Detection", "labels": [], "entities": [{"text": "NI Detection", "start_pos": 25, "end_pos": 37, "type": "TASK", "confidence": 0.7872419953346252}]}, {"text": " Table 6: Performance of DNI Identification", "labels": [], "entities": [{"text": "DNI Identification", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.7720345258712769}]}, {"text": " Table 7: Results on golden DNI", "labels": [], "entities": [{"text": "golden", "start_pos": 21, "end_pos": 27, "type": "DATASET", "confidence": 0.8605148792266846}, {"text": "DNI", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.6697595715522766}]}, {"text": " Table 8: Performance of NI resolution for our models", "labels": [], "entities": []}]}