{"title": [], "abstractContent": [{"text": "Traditional approaches to word sense dis-ambiguation (WSD) rest on the assumption that there exists a single, unambigu-ous communicative intention underlying every word in a document.", "labels": [], "entities": [{"text": "word sense dis-ambiguation (WSD)", "start_pos": 26, "end_pos": 58, "type": "TASK", "confidence": 0.8334839940071106}]}, {"text": "However, writers sometimes intend fora word to be interpreted as simultaneously carrying multiple distinct meanings.", "labels": [], "entities": []}, {"text": "This deliberate use of lexical ambiguity-i.e., punning-is a particularly common source of humour.", "labels": [], "entities": []}, {"text": "In this paper we describe how traditional, language-agnostic WSD approaches can be adapted to \"disambiguate\" puns, or rather to identify their double meanings.", "labels": [], "entities": [{"text": "WSD", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.8704976439476013}]}, {"text": "We evaluate several such approaches on a manually sense-annotated collection of English puns and observe performance exceeding that of some knowledge-based and supervised baselines.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word sense disambiguation, or WSD, is the task of identifying a word's meaning in context.", "labels": [], "entities": [{"text": "Word sense disambiguation, or WSD", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.6292839199304581}, {"text": "identifying a word's meaning in context", "start_pos": 50, "end_pos": 89, "type": "TASK", "confidence": 0.5950481253010886}]}, {"text": "No matter whether it is performed by a human or a machine, WSD usually rests on the assumption that there is a single unambiguous communicative intention underlying each word in the document.", "labels": [], "entities": [{"text": "WSD", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.9934771656990051}]}, {"text": "However, there exists a class of language constructs known Under this assumption, lexical ambiguity arises due to there being a plurality of words with the same surface form but different meanings, and the task of the interpreter is to select correctly among them.", "labels": [], "entities": []}, {"text": "An alternative view is that each word is a single lexical entry whose specific meaning is underspecified until it is activated by the context.", "labels": [], "entities": []}, {"text": "In the case of systematically polysemous terms (i.e., words that have several related senses shared in a systematic way by a group of similar words), it may not be necessary to disambiguate them at all in order to interpret the communication.", "labels": [], "entities": []}, {"text": "While there has been some research in modelling intentional lexical-semantic underspecification, it is intended for closely related senses such as those of systematically polysemous terms, not those of coarser-grained homonyms which are the subject of this paper.", "labels": [], "entities": []}, {"text": "as paronomasia and syllepsis, or more generally as puns, in which homonymic (i.e., coarse-grained) lexical-semantic ambiguity is a deliberate effect of the communication act.", "labels": [], "entities": []}, {"text": "That is, the writer intends fora certain word or other lexical item to be interpreted as simultaneously carrying two or more separate meanings, or alternatively for it to be unclear which meaning is the intended one.", "labels": [], "entities": []}, {"text": "There area variety of motivations writers have for employing such constructions, and in turn for why such uses are worthy of scholarly investigation.", "labels": [], "entities": []}, {"text": "Perhaps surprisingly, this sort of intentional lexical ambiguity has attracted little attention in the fields of computational linguistics and natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 143, "end_pos": 170, "type": "TASK", "confidence": 0.6489183306694031}]}, {"text": "What little research has been done is confined largely to computational mechanisms for pun generation (in the context of natural language generation for computational humour) and to computational analysis of phonological properties of puns.", "labels": [], "entities": [{"text": "pun generation", "start_pos": 87, "end_pos": 101, "type": "TASK", "confidence": 0.7945492267608643}, {"text": "natural language generation", "start_pos": 121, "end_pos": 148, "type": "TASK", "confidence": 0.7628160913785299}]}, {"text": "A fundamental problem which has not yet been as widely studied is the automatic detection and identification of intentional lexical ambiguity-that is, given a text, does it contain any lexical items which are used in a deliberately ambiguous manner, and if so, what are the intended meanings?", "labels": [], "entities": [{"text": "automatic detection and identification of intentional lexical ambiguity-that", "start_pos": 70, "end_pos": 146, "type": "TASK", "confidence": 0.7083510346710682}]}, {"text": "We consider these to be important research questions with a number of real-world applications.", "labels": [], "entities": []}, {"text": "For instance, puns are particularly common in advertising, where they are used not only to create humour but also to induce in the audience a valenced attitude toward the target (.", "labels": [], "entities": []}, {"text": "Recognizing instances of such lexical ambiguity and understanding their affective connotations would be of benefit to systems performing sentiment analysis on persuasive texts.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 137, "end_pos": 155, "type": "TASK", "confidence": 0.9171527326107025}]}, {"text": "Wordplay is also a perennial topic of scholarship in literary criticism and analysis.", "labels": [], "entities": [{"text": "literary criticism and analysis", "start_pos": 53, "end_pos": 84, "type": "TASK", "confidence": 0.8089769929647446}]}, {"text": "To give just one example, puns are one of the most intensively studied aspects of Shakespeare's rhetoric, and laborious manual counts have shown their frequency in certain of his plays to range from 17 to 85 instances per thousand lines.", "labels": [], "entities": [{"text": "frequency", "start_pos": 151, "end_pos": 160, "type": "METRIC", "confidence": 0.9527312517166138}]}, {"text": "It is not hard to image how computer-assisted detection, classification, and analysis of puns could help scholars in the digital humanities.", "labels": [], "entities": [{"text": "computer-assisted detection, classification", "start_pos": 28, "end_pos": 71, "type": "TASK", "confidence": 0.7125737443566322}]}, {"text": "Finally, computational pun detection and understanding hold tremendous potential for machine-assisted translation.", "labels": [], "entities": [{"text": "computational pun detection", "start_pos": 9, "end_pos": 36, "type": "TASK", "confidence": 0.7643358111381531}, {"text": "machine-assisted translation", "start_pos": 85, "end_pos": 113, "type": "TASK", "confidence": 0.679176390171051}]}, {"text": "Some of the most widely disseminated and translated popular discourses-particularly television shows and movies-feature puns and other forms of wordplay as a recurrent and expected feature).", "labels": [], "entities": []}, {"text": "These pose particular challenges for translators, who need not only to recognize and comprehend each instance of humour-provoking ambiguity, but also to select and implement an appropriate translation strategy.", "labels": [], "entities": [{"text": "translators", "start_pos": 37, "end_pos": 48, "type": "TASK", "confidence": 0.9613378643989563}]}, {"text": "2 NLP systems could assist translators in flagging intentionally ambiguous words for special attention, and where they are not directly translatable (as is usually the case), the systems maybe able to propose ambiguity-preserving alternatives which best match the original pun's double meaning.", "labels": [], "entities": []}, {"text": "In the present work, we discuss the adaptation of automatic word sense disambiguation techniques to intentionally ambiguous text and evaluate these adaptations in a controlled setting.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 60, "end_pos": 85, "type": "TASK", "confidence": 0.6889885167280833}]}, {"text": "We focus on humorous puns, as these are by far the most commonly encountered and more readily available in (and extractable from) existing text corpora.", "labels": [], "entities": []}, {"text": "The remainder of this paper is structured as follows: In the following section we give a brief introduction to puns, WSD, and related previous work on computational detection and comprehension of humour.", "labels": [], "entities": [{"text": "WSD", "start_pos": 117, "end_pos": 120, "type": "TASK", "confidence": 0.87965989112854}, {"text": "computational detection and comprehension of humour", "start_pos": 151, "end_pos": 202, "type": "TASK", "confidence": 0.8306690106789271}]}, {"text": "In \u00a73 we describe the data set produced for our experiments.", "labels": [], "entities": []}, {"text": "In \u00a7 \u00a74 and 5 we describe how disambiguation algorithms, evaluation metrics, and baselines from traditional WSD can be adapted to the task of pun identification, and in \u00a76 we report and discuss the performance of our adapted systems.", "labels": [], "entities": [{"text": "pun identification", "start_pos": 142, "end_pos": 160, "type": "TASK", "confidence": 0.8763537406921387}]}, {"text": "Finally, we conclude in \u00a77 with a review of our research contributions and an outline of our plans for future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Coverage, precision, recall, and F 1 for  various pun diasmbiguation algorithms.", "labels": [], "entities": [{"text": "Coverage", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9353200793266296}, {"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9991437196731567}, {"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9992805123329163}, {"text": "F 1", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.99090376496315}]}, {"text": " Table 2: Coverage, precision, and recall for  SEL+cluster, and random baseline recall, accord- ing to part of speech.", "labels": [], "entities": [{"text": "Coverage", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9199896454811096}, {"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9991051554679871}, {"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9993854761123657}, {"text": "SEL+cluster", "start_pos": 47, "end_pos": 58, "type": "TASK", "confidence": 0.6725389957427979}, {"text": "recall", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.7426239252090454}]}]}