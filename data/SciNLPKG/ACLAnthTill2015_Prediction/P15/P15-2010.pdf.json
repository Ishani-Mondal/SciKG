{"title": [], "abstractContent": [{"text": "The validity of applying paraphrase rules depends on the domain of the text that they are being applied to.", "labels": [], "entities": []}, {"text": "We develop a novel method for extracting domain-specific paraphrases.", "labels": [], "entities": []}, {"text": "We adapt the bilingual pivoting paraphrase method to bias the training data to be more like our target domain of biology.", "labels": [], "entities": []}, {"text": "Our best model results in higher precision while retaining complete recall, giving a 10% relative improvement in AUC.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.999603807926178}, {"text": "recall", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.9486160278320312}, {"text": "AUC", "start_pos": 113, "end_pos": 116, "type": "METRIC", "confidence": 0.9928640127182007}]}], "introductionContent": [{"text": "Many data-driven paraphrase extraction algorithms have been developed in recent years (.", "labels": [], "entities": [{"text": "paraphrase extraction", "start_pos": 17, "end_pos": 38, "type": "TASK", "confidence": 0.8197286427021027}]}, {"text": "These algorithms attempt to learn paraphrase rules, where one phrase can be replaced with another phrase which has equivalent meaning in at least some context.", "labels": [], "entities": []}, {"text": "Determining whether a paraphrase is appropriate fora specific context is a difficult problem, encompassing issues of syntax, word sense (, and style (.", "labels": [], "entities": []}, {"text": "To date, the question of how domain effects paraphrase has been left unexplored.", "labels": [], "entities": []}, {"text": "Although most paraphrase extraction algorithms attempt to estimate a confidence with which a paraphrase rule might apply, these scores are not differentiated by domain, and instead correspond to the general domain represented by the model's training data.", "labels": [], "entities": [{"text": "paraphrase extraction", "start_pos": 14, "end_pos": 35, "type": "TASK", "confidence": 0.8892362713813782}]}, {"text": "As illustrated by Table 1, paraphrases that are highly probable in the general domain (e.g. hot = sexy) can be extremely improbable in more specialized domains like biology.", "labels": [], "entities": []}, {"text": "Dominant word senses change depending on * Incubated by the Allen Institute for Artificial Intelligence.", "labels": [], "entities": []}], "datasetContent": [{"text": "What is the effect of subsampling?", "labels": [], "entities": []}, {"text": "compares the precision and recall of the different subsampling methods against the baseline of training on everything, when they are evaluated on manually labeled test paraphrases from the biology domain.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.999530553817749}, {"text": "recall", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9979973435401917}]}, {"text": "All of subsampled models have a higher precision than the baseline General model, except for the largest of the subsampled models (which was trained on sentence pairs with 166M words -many of which are more like the general domain than the biology domain).", "labels": [], "entities": [{"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9982526898384094}]}, {"text": "The subsampled models have reduced recall since many of the paraphrases that occur in the full 10 9 word bilingual training corpus do not occur in the subsamples.", "labels": [], "entities": [{"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9990942478179932}]}, {"text": "As we increase \u03c4 we improve recall at the expense of precision, since we are including training data that is less and less like our target domain.", "labels": [], "entities": [{"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9995341300964355}, {"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9997076392173767}]}, {"text": "The highest precision model based on the vanilla M-L method is M-L Change Point, which sets the subsample size to include exactly those sentence pairs that look more like the target domain than the general domain.", "labels": [], "entities": []}, {"text": "Our novel extension of the M-L model (M-L Weighted) provides further improvements.", "labels": [], "entities": []}, {"text": "Here, we weight each sentence pair in the bilingual training corpus proportional to \u03c3 i when computing the paraphrase scores.", "labels": [], "entities": []}, {"text": "Specifically, we weight the counting during the bilingual pivoting so that rather than each occurrence counting as 1, each occurrence counts as the ratio of the sentence's cross-entropies:", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Top paraphrase under the general and the best  domain-specific model, General+M-L Weighted.", "labels": [], "entities": []}, {"text": " Table 3: AUC (\u00d7 100) for each model in the biology domain  from", "labels": [], "entities": [{"text": "AUC", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9721333980560303}]}]}