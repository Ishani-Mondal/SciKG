{"title": [{"text": "Probing the Linguistic Strengths and Limitations of Unsupervised Grammar Induction", "labels": [], "entities": [{"text": "Probing the Linguistic Strengths and Limitations of Unsupervised Grammar Induction", "start_pos": 0, "end_pos": 82, "type": "TASK", "confidence": 0.5490405142307282}]}], "abstractContent": [{"text": "Work in grammar induction should help shed light on the amount of syntactic structure that is discoverable from raw word or tag sequences.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.7244031578302383}]}, {"text": "But since most current grammar induction algorithms produce unlabeled dependencies, it is difficult to analyze what types of constructions these algorithms can or cannot capture, and, therefore, to identify where additional supervision maybe necessary.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.6936465501785278}]}, {"text": "This paper provides an in-depth analysis of the errors made by unsupervised CCG parsers by evaluating them against the labeled dependencies in CCGbank, hinting at new research directions necessary for progress in grammar induction.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 213, "end_pos": 230, "type": "TASK", "confidence": 0.7872271835803986}]}], "introductionContent": [{"text": "Grammar induction aims to develop algorithms that can automatically discover the latent syntactic structure of language from raw or part-of-speech tagged text.", "labels": [], "entities": [{"text": "Grammar induction", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8165909945964813}]}, {"text": "While such algorithms would have the greatest utility for low-resource languages for which no treebank is available to train supervised parsers, most work in this area has focused on languages where existing treebanks can be used to measure and compare the performance of the resultant parsers.", "labels": [], "entities": []}, {"text": "Despite significant progress in the last decade (, there has been little analysis performed on the types of errors these induction systems make, and our understanding of what kinds of constructions these parsers can or cannot recover is still rather limited.", "labels": [], "entities": []}, {"text": "One likely reason for this lack of analysis is the fact that most of the work in this domain has focused on parsers that return unlabeled dependencies, which cannot easily be assigned a linguistic interpretation.", "labels": [], "entities": []}, {"text": "This paper shows that approaches that are based on categorial grammar are amenable to more stringent evaluation metrics, which enable detailed analyses of the constructions they capture, while the commonly used unlabeled directed attachment scores hide linguistically important errors.", "labels": [], "entities": []}, {"text": "Any categorial grammar based system, whether deriving its grammar from seed knowledge distinguishing nouns and verbs, from a lexicon constructed from a simple questionnaire for linguists), or from sections of a treebank (, will attach linguistically expressive categories to individual words, and can therefore produce labeled dependencies.", "labels": [], "entities": []}, {"text": "We provide a simple proof of concept for how these labeled dependencies can be used to isolate problem areas in CCG induction algorithms.", "labels": [], "entities": [{"text": "CCG induction", "start_pos": 112, "end_pos": 125, "type": "TASK", "confidence": 0.7761094868183136}]}, {"text": "We illustrate how they make the linguistic assumptions and mistakes of the model transparent, and are easily comparable to a treebank where available.", "labels": [], "entities": []}, {"text": "They also allow us to identify linguistic phenomena that require additional supervision or training signal to master.", "labels": [], "entities": []}, {"text": "Our analysis will be based on extensions of our earlier system, since it requires less supervision than the CCG-based approaches of or.", "labels": [], "entities": []}, {"text": "Our aim in presenting this analysis is to initiate a broader conversation and classification of the impact of various types of supervision provided to these approaches.", "labels": [], "entities": []}, {"text": "We will see that most of the constructions that our system cannot capture, even when they are included in the model's search space, involve precisely the kinds of non-local dependencies that elude even supervised dependency parsers (since they require dependency graphs, instead of trees), and that have motivated the use of categorial grammarbased approaches for supervised parsing.", "labels": [], "entities": [{"text": "supervised parsing", "start_pos": 364, "end_pos": 382, "type": "TASK", "confidence": 0.6906033158302307}]}, {"text": "First, we provide a brief introduction to CCG.", "labels": [], "entities": []}, {"text": "Next, we define a labeled evaluation metric that allows us to compare the labeled dependencies produced by's unsupervised parser with those in CCGbank.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 143, "end_pos": 150, "type": "DATASET", "confidence": 0.9572696089744568}]}, {"text": "Third, we extend their induction algorithm to allow it to induce more complex categories, and refine their probability model to handle punctuation and lexicalization, which we show to be necessary when handling the larger grammars induced by our variant of their algorithm.", "labels": [], "entities": []}, {"text": "While we also perform a traditional dependency evaluation for comparison to the non-CCG based literature, we focus on our CCG-based labeled evaluation metrics to perform a comparative analysis of's parser and our extensions.", "labels": [], "entities": []}], "datasetContent": [{"text": "In languages with treebanks, labeled evaluation can make this style of analysis even simpler.", "labels": [], "entities": []}, {"text": "Fortunately, approaches using CCG can produce labeled output but unfortunately there are mismatches between the basic set of categories and those used in treebanks.", "labels": [], "entities": []}, {"text": "We will focus on the English CCGbank but these details apply with only minor changes to German and Chinese as well.", "labels": [], "entities": [{"text": "English CCGbank", "start_pos": 21, "end_pos": 36, "type": "DATASET", "confidence": 0.9239175319671631}]}, {"text": "We have just seen that labeled evaluation can expose many linguistically important mistakes.", "labels": [], "entities": []}, {"text": "In order to enable a fair and informative comparison of unsupervised CCG parsers against the lexical categories and labeled dependencies in CCGbank, we define a simplification of CCGbank's lexical categories that does not alter the number or direction of dependencies, but makes the categories and dependency labels directly comparable to those produced by an unsupervised parser.", "labels": [], "entities": []}, {"text": "We also do not alter the derivations themselves, although these may contain type-changing rules (which allow e.g. participial verb phrases S[ng]\\NP to be used as NP modifiers NP\\NP) that are beyond the scope of our induction algorithm.", "labels": [], "entities": []}, {"text": "Although the CCG derivations and dependencies that CCG-based parsers return should in principle be amenable to a quantitative labeled evaluation when a gold-standard CCG corpus is available, there maybe minor systematic differences between the sets of categories assumed by the induced parser and those in the treebank.", "labels": [], "entities": []}, {"text": "In particular, the lexical categories in the English CCGbank are augmented with morphosyntactic features that indicate e.g. whether sentences are declarative (S[dcl]), or verb phrases are infinitival (S[to]\\NP).", "labels": [], "entities": [{"text": "English CCGbank", "start_pos": 45, "end_pos": 60, "type": "DATASET", "confidence": 0.8184037208557129}]}, {"text": "Prior work on supervised parsing with CCG found that many of these features can be recovered with proper modeling of latent state splitting.", "labels": [], "entities": [{"text": "latent state splitting", "start_pos": 117, "end_pos": 139, "type": "TASK", "confidence": 0.6454774141311646}]}, {"text": "Since we wish to evaluate a system that does not aim to induce such features, we remove them.", "labels": [], "entities": []}, {"text": "With these three simplifications we eliminate much of the detailed knowledge required to construct the precise CCGbankstyle categories, and dramatically reduce the set of categories without losing expressive power.", "labels": [], "entities": []}, {"text": "One distinction that we do not conflate, even though it is currently beyond the scope of the induction algorithm, is the distinction between PP arguments (requiring prepositions to have the category PP/NP) and adjuncts (requiring prepositions to be (NP\\NP)/NP or ((S\\NP)\\(S\\NP))/NP).", "labels": [], "entities": []}, {"text": "This simplification is consistent with the most basic components of CCG and can therefore be easily used for the evaluation and analysis of any weakly or fully supervised CCG system, not just that of.", "labels": [], "entities": []}, {"text": "An example simplification is present in, and the reduction in the set of categories can be seen in.", "labels": [], "entities": []}, {"text": "Similar simplifications should also be possible for CCGbanks in other languages.", "labels": [], "entities": []}, {"text": "For our experiments we will follow the standard practice in supervised parsing of using WSJ Sections 02-21 for training, Section 22 for development and error analysis, and a final evaluation of the best models on Section 23.", "labels": [], "entities": [{"text": "parsing", "start_pos": 71, "end_pos": 78, "type": "TASK", "confidence": 0.8405463695526123}, {"text": "WSJ Sections 02-21", "start_pos": 88, "end_pos": 106, "type": "DATASET", "confidence": 0.9137216607729594}]}, {"text": "Because the induced lexicons are overly general, the memory footprint grows rapidly as the complexity of the grammar increases.", "labels": [], "entities": []}, {"text": "For this reason, we only train on sentences that contain up to 20 words (as well as an arbitrary number of punctuation marks).", "labels": [], "entities": []}, {"text": "All analyses and evaluation are performed with sentences of all lengths unless otherwise indicated.", "labels": [], "entities": []}, {"text": "Finally, Bisk and Hockenmaier (2013) followed insetting the values of the hyperparameters \u03b1 to powers (eg. the square) of the number of observed outcomes in the distribution.", "labels": [], "entities": []}, {"text": "But when the output consists of words rather than POS tags, the concentration parameter \u03b1 = V 2 is too large to allow the model to learn.", "labels": [], "entities": []}, {"text": "For this reason, experiments will be reported with all hyperparameters set to a constant of 2500.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 6: Unlabeled predicate argument structures for two sentences, both of whom result in DAGs, not  trees, as the subject is shared by multiple verbs.", "labels": [], "entities": []}, {"text": " Table 8: Common categories that the algorithm  cannot induce, and their corpus probability (given  their most frequent tag in Sec. 02-21)", "labels": [], "entities": []}, {"text": " Table 9: Overall performance of the final systems  discussed in this paper (Section 23)", "labels": [], "entities": []}, {"text": " Table 10: Performance on CCGbank and CoNLL- style dependencies (Sections 02-21) for a compar- ison with Naseem et al. (2010).", "labels": [], "entities": []}, {"text": " Table 6: Unlabeled predicate argument structures for two sentences, both of whom result in DAGs, not  trees, as the subject is shared by multiple verbs.", "labels": [], "entities": []}, {"text": " Table 8: Common categories that the algorithm  cannot induce, and their corpus probability (given  their most frequent tag in Sec. 02-21)", "labels": [], "entities": []}, {"text": " Table 9: Overall performance of the final systems  discussed in this paper (Section 23)", "labels": [], "entities": []}, {"text": " Table 10: Performance on CCGbank and CoNLL- style dependencies (Sections 02-21) for a compar- ison with Naseem et al. (2010).", "labels": [], "entities": []}, {"text": " Table 1: Category types in CCGbank 02-21", "labels": [], "entities": [{"text": "CCGbank 02-21", "start_pos": 28, "end_pos": 41, "type": "DATASET", "confidence": 0.9656382203102112}]}, {"text": " Table 2: The impact of our changes to Bisk and Hockenmaier's (2013) model (henceforth: B 1 , top left)  on CCGbank dependencies (LF1, Section 22, all sentences). The best overall model (B 3", "labels": [], "entities": []}, {"text": " Table 3: Test set performance of the final systems  discussed in this paper", "labels": [], "entities": []}, {"text": " Table 4: Performance on CCGbank and CoNLL- style dependencies (Sections 02-21) for a compar- ison with Naseem et al. (2010).", "labels": [], "entities": []}, {"text": " Table 7: LF1 scores of B 1 , B C  1 and B 3", "labels": [], "entities": []}, {"text": " Table 8: Common categories that the algorithm  cannot induce", "labels": [], "entities": []}, {"text": " Table 9: Size, ambiguity, coverage and precision  (evaluated on Section 22) of the induced lexicons.", "labels": [], "entities": [{"text": "coverage", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9856561422348022}, {"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9994245767593384}]}]}