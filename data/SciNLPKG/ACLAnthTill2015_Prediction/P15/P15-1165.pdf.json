{"title": [], "abstractContent": [{"text": "We present a novel, count-based approach to obtaining inter-lingual word representations based on inverted indexing of Wikipedia.", "labels": [], "entities": []}, {"text": "We present experiments applying these representations to 17 datasets in document classification, POS tagging, dependency parsing, and word alignment.", "labels": [], "entities": [{"text": "document classification", "start_pos": 72, "end_pos": 95, "type": "TASK", "confidence": 0.7562012076377869}, {"text": "POS tagging", "start_pos": 97, "end_pos": 108, "type": "TASK", "confidence": 0.9104016423225403}, {"text": "dependency parsing", "start_pos": 110, "end_pos": 128, "type": "TASK", "confidence": 0.8478347957134247}, {"text": "word alignment", "start_pos": 134, "end_pos": 148, "type": "TASK", "confidence": 0.8110375106334686}]}, {"text": "Our approach has the advantage that it is simple, computationally efficient and almost parameter-free, and, more importantly , it enables multi-source cross-lingual learning.", "labels": [], "entities": []}, {"text": "In 14/17 cases, we improve over using state-of-the-art bilingual embeddings.", "labels": [], "entities": []}], "introductionContent": [{"text": "Linguistic resources are hard to come by and unevenly distributed across the world's languages.", "labels": [], "entities": []}, {"text": "Consequently, transferring linguistic resources or knowledge from one language to another has been identified as an important research problem.", "labels": [], "entities": []}, {"text": "Most work on cross-lingual transfer has used English as the source language.", "labels": [], "entities": [{"text": "cross-lingual transfer", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.8268487453460693}]}, {"text": "There are two reasons for this; namely, the availability of English resources and the availability of parallel data for (and translations between) English and most other languages.", "labels": [], "entities": []}, {"text": "In cross-lingual syntactic parsing, for example, two approaches to cross-lingual learning have been explored, namely annotation projection and delexicalized transfer.", "labels": [], "entities": [{"text": "cross-lingual syntactic parsing", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.7408990263938904}, {"text": "annotation projection", "start_pos": 117, "end_pos": 138, "type": "TASK", "confidence": 0.7079781591892242}]}, {"text": "Annotation projection () uses word-alignments inhuman translations to project predicted sourceside analyses to the target language, producing a noisy syntactically annotated resource for the target language.", "labels": [], "entities": [{"text": "Annotation projection", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.801214724779129}]}, {"text": "On the other hand, delexicalized transfer () simply removes lexical features from mono-lingual parsing models, but assumes reliable POS tagging for the target language.", "labels": [], "entities": [{"text": "delexicalized transfer", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.651650920510292}, {"text": "POS tagging", "start_pos": 132, "end_pos": 143, "type": "TASK", "confidence": 0.7203553318977356}]}, {"text": "Delexicalized transfer works particularly well when resources from several source languages are used for training; learning from multiple other languages prevents over-fitting to the peculiarities of the source language.", "labels": [], "entities": []}, {"text": "Some authors have also combined annotation projection and delexicalized transfer, e.g.,.", "labels": [], "entities": [{"text": "annotation projection", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.6966297179460526}]}, {"text": "Others have tried to augment delexicalized transfer models with bilingual word representations.", "labels": [], "entities": []}, {"text": "In cross-lingual POS tagging, mostly annotation projection has been explored, since all features in POS tagging models are typically lexical.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 17, "end_pos": 28, "type": "TASK", "confidence": 0.8082744181156158}, {"text": "POS tagging", "start_pos": 100, "end_pos": 111, "type": "TASK", "confidence": 0.7653296589851379}]}, {"text": "However, using bilingual word representations was recently explored as an alternative to projectionbased approaches.", "labels": [], "entities": []}, {"text": "The major drawback of using bi-lexical representations is that it limits us to using a single source language.", "labels": [], "entities": []}, {"text": "obtained significant improvements using bilingual word clusters over a single source delexicalized transfer model, for example, but even better results were obtained with delexicalized transfer in by simply using several source languages.", "labels": [], "entities": []}, {"text": "This paper introduces a simple method for obtaining truly inter-lingual word representations in order to train models with lexical features on several source languages at the same time.", "labels": [], "entities": []}, {"text": "Briefly put, we represent words by their occurrence in clusters of Wikipedia articles linking to the same concept.", "labels": [], "entities": []}, {"text": "Our representations are competitive with state-of-the-art neural net word embeddings when using only a single source language, but also enable us to exploit the availability of resources in multiple languages.", "labels": [], "entities": []}, {"text": "This also makes it possible to explore multi-source transfer for POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 65, "end_pos": 76, "type": "TASK", "confidence": 0.7383655607700348}]}, {"text": "We evaluate the method across POS tagging and dependency parsing datasets in four languages in the Google Universal Treebanks v.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 30, "end_pos": 41, "type": "TASK", "confidence": 0.7166727781295776}, {"text": "dependency parsing", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.6979383230209351}, {"text": "Google Universal Treebanks v", "start_pos": 99, "end_pos": 127, "type": "DATASET", "confidence": 0.8269445896148682}]}, {"text": "1.0 (see \u00a73.2.1), as well as two document classification datasets and four word alignment problems using a handaligned text.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 75, "end_pos": 89, "type": "TASK", "confidence": 0.6986803859472275}]}, {"text": "Finally, we also directly compare our results to on parsing data for four languages from CoNLL 2006 and 2007.", "labels": [], "entities": [{"text": "CoNLL 2006", "start_pos": 89, "end_pos": 99, "type": "DATASET", "confidence": 0.9351914525032043}]}], "datasetContent": [{"text": "The data set characteristics are found in.3.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Characteristics of the data sets. Embeddings coverage (token-level) for KLEMENTIEV, CHAN- DAR and INVERTED on the test sets. We use the common vocabulary on WORD ALIGNMENT.", "labels": [], "entities": [{"text": "Embeddings coverage", "start_pos": 44, "end_pos": 63, "type": "METRIC", "confidence": 0.9112359881401062}, {"text": "KLEMENTIEV", "start_pos": 82, "end_pos": 92, "type": "METRIC", "confidence": 0.9881895780563354}, {"text": "CHAN- DAR", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9467177391052246}, {"text": "INVERTED", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.9689610600471497}]}, {"text": " Table 4: POS tagging (accuracies), K12: KLEMENTIEV, C14: CHANDAR. Parameters tuned on devel- opment data: \u03c3 = 0.01, \u03b4 = 160. Iterations not tuned (i = 10). Averages do not include Swedish, for  comparability.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.6130291521549225}, {"text": "KLEMENTIEV", "start_pos": 41, "end_pos": 51, "type": "METRIC", "confidence": 0.9826095104217529}, {"text": "CHANDAR", "start_pos": 58, "end_pos": 65, "type": "METRIC", "confidence": 0.9455317258834839}, {"text": "Parameters", "start_pos": 67, "end_pos": 77, "type": "METRIC", "confidence": 0.9511367678642273}]}, {"text": " Table 3: Document classification results (F 1 - scores)", "labels": [], "entities": [{"text": "Document classification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.9248494505882263}, {"text": "F 1 - scores", "start_pos": 43, "end_pos": 55, "type": "METRIC", "confidence": 0.8239997327327728}]}, {"text": " Table 6: Dependency parsing for CoNLL  2006/2007 datasets. Parameters same as on the  Google Universal Treebanks.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.7256741374731064}, {"text": "CoNLL  2006/2007 datasets", "start_pos": 33, "end_pos": 58, "type": "DATASET", "confidence": 0.9632311820983886}, {"text": "Parameters", "start_pos": 60, "end_pos": 70, "type": "METRIC", "confidence": 0.9786466956138611}, {"text": "Google Universal Treebanks", "start_pos": 87, "end_pos": 113, "type": "DATASET", "confidence": 0.7989005446434021}]}, {"text": " Table 5: Dependency parsing results on the Universal Treebanks (unlabeled and labeled attachment  scores). Parameters tuned on development data: \u03c3 = 0.005, \u03b4 = 20, i = 3.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.6838312745094299}, {"text": "Universal Treebanks", "start_pos": 44, "end_pos": 63, "type": "DATASET", "confidence": 0.7857532799243927}, {"text": "Parameters", "start_pos": 108, "end_pos": 118, "type": "METRIC", "confidence": 0.965175986289978}]}, {"text": " Table 7: Word alignment results (P @1). S=sure (certain) alignments. P=possible alignments.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.6160892993211746}]}]}