{"title": [{"text": "Seed-Based Event Trigger Labeling: How far can event descriptions get us?", "labels": [], "entities": [{"text": "Seed-Based Event Trigger Labeling", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7989337593317032}]}], "abstractContent": [{"text": "The task of event trigger labeling is typically addressed in the standard supervised setting: triggers for each target event type are annotated as training data, based on annotation guidelines.", "labels": [], "entities": [{"text": "event trigger labeling", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.7347128589948019}]}, {"text": "We propose an alternative approach, which takes the example trigger terms mentioned in the guidelines as seeds, and then applies an event-independent similarity-based classifier for trigger labeling.", "labels": [], "entities": []}, {"text": "This way we can skip manual annotation for new event types, while requiring only minimal annotated training data for few example events at system setup.", "labels": [], "entities": []}, {"text": "Our method is evaluated on the ACE-2005 dataset, achieving 5.7% F 1 improvement over a state-of-the-art supervised system which uses the full training data.", "labels": [], "entities": [{"text": "ACE-2005 dataset", "start_pos": 31, "end_pos": 47, "type": "DATASET", "confidence": 0.9895595908164978}, {"text": "F 1", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9896798431873322}]}], "introductionContent": [{"text": "Event trigger labeling is the task of identifying the main word tokens that express mentions of prespecified event types in running text.", "labels": [], "entities": [{"text": "Event trigger labeling", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6887620091438293}]}, {"text": "For example, in \"20 people were wounded in Tuesday's airport blast\", \"wounded\" is a trigger of an Injure event and \"blast\" is a trigger of an Attack.", "labels": [], "entities": []}, {"text": "The task both detects trigger tokens and classifies them to appropriate event types.", "labels": [], "entities": []}, {"text": "While this task is often a component within the broader event extraction task, labeling both triggers and arguments, this paper focuses on trigger labeling.", "labels": [], "entities": [{"text": "event extraction task", "start_pos": 56, "end_pos": 77, "type": "TASK", "confidence": 0.795061190923055}, {"text": "trigger labeling", "start_pos": 139, "end_pos": 155, "type": "TASK", "confidence": 0.7165836989879608}]}, {"text": "Most state-of-the-art event trigger labeling approaches ( follow the standard supervised learning paradigm.", "labels": [], "entities": [{"text": "event trigger labeling", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.6535201470057169}]}, {"text": "For each event type, experts first write annotation guidelines.", "labels": [], "entities": []}, {"text": "Then, annotators follow them to label event triggers in a large dataset.", "labels": [], "entities": []}, {"text": "Finally, a classifier is trained over the annotated triggers to label the target events.", "labels": [], "entities": []}, {"text": "The supervised paradigm requires major human efforts both in producing high-quality guidelines and in dataset annotation for each new event type.", "labels": [], "entities": []}, {"text": "Given the rich information embedded in the guidelines, we raise in this paper the following research question: how well can we perform by leveraging only the lexical knowledge already available in quality guidelines for new event types, without requiring annotated training data for them?", "labels": [], "entities": []}, {"text": "To address this question, we propose a seedbased approach for the trigger labeling task (Section 2).", "labels": [], "entities": [{"text": "trigger labeling task", "start_pos": 66, "end_pos": 87, "type": "TASK", "confidence": 0.8339366912841797}]}, {"text": "Given the description fora new event type, which contains some examples of triggers, we first collect these triggers into a list of seeds.", "labels": [], "entities": []}, {"text": "Then, at the labeling phase, we consider each text token as a candidate fora trigger and assess its similarity to the seed list.", "labels": [], "entities": []}, {"text": "In the above example, given seeds such as \"explosion\" and \"fire\" for the Attack event type, we identify that the candidate token \"blast\" is a hyponym of \"explosion\" and synonym of \"fire\" and infer that \"blast\" is a likely Attack trigger.", "labels": [], "entities": []}, {"text": "In our method, such similarity indicators are encoded as a small set of event-independent classification features, based on lexical matches and external resources like WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 168, "end_pos": 175, "type": "DATASET", "confidence": 0.9825088977813721}]}, {"text": "Using eventindependent features allows us to train the system only once, at system setup phase, requiring annotated triggers in a training set for just a few preselected event types.", "labels": [], "entities": []}, {"text": "Then, whenever anew event type is introduced for labeling, we only need to collect a seed list for it from its description, and provide it as input to the system.", "labels": [], "entities": []}, {"text": "We developed a seed-based system (Section 3), based on a state-of-the-art fully-supervised event extraction system (.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 91, "end_pos": 107, "type": "TASK", "confidence": 0.7451032996177673}]}, {"text": "When evaluated on the ACE-2005 dataset, 1 our system outperforms the fully-supervised one (Section 4), even though we don't utilize any annotated triggers of the test events during the labeling phase, and only", "labels": [], "entities": [{"text": "ACE-2005 dataset", "start_pos": 22, "end_pos": 38, "type": "DATASET", "confidence": 0.9764569401741028}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Seed-based performance compared to  fully-supervised systems, plus average F 1 vari- ance (%) over the 10 test runs per test event type.", "labels": [], "entities": [{"text": "F 1 vari- ance", "start_pos": 85, "end_pos": 99, "type": "METRIC", "confidence": 0.9564753532409668}]}]}