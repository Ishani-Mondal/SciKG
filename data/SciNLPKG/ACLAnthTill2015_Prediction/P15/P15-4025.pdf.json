{"title": [{"text": "NiuParser: A Chinese Syntactic and Semantic Parsing Toolkit", "labels": [], "entities": []}], "abstractContent": [{"text": "We present anew toolkit-NiuParser-for Chinese syntactic and semantic analysis.", "labels": [], "entities": [{"text": "Chinese syntactic and semantic analysis", "start_pos": 38, "end_pos": 77, "type": "TASK", "confidence": 0.563309109210968}]}, {"text": "It can handle a wide range of Natural Language Processing (NLP) tasks in Chi-nese, including word segmentation, part-of-speech tagging, named entity recognition , chunking, constituent parsing, dependency parsing, and semantic role labeling.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 93, "end_pos": 110, "type": "TASK", "confidence": 0.7533625662326813}, {"text": "part-of-speech tagging", "start_pos": 112, "end_pos": 134, "type": "TASK", "confidence": 0.7077443450689316}, {"text": "named entity recognition", "start_pos": 136, "end_pos": 160, "type": "TASK", "confidence": 0.6140183806419373}, {"text": "constituent parsing", "start_pos": 173, "end_pos": 192, "type": "TASK", "confidence": 0.7151734083890915}, {"text": "dependency parsing", "start_pos": 194, "end_pos": 212, "type": "TASK", "confidence": 0.8119618892669678}, {"text": "semantic role labeling", "start_pos": 218, "end_pos": 240, "type": "TASK", "confidence": 0.663459300994873}]}, {"text": "The NiuParser system runs fast and shows state-of-the-art performance on several benchmarks.", "labels": [], "entities": []}, {"text": "Moreover, it is very easy to use for both research and industrial purposes.", "labels": [], "entities": []}, {"text": "Advanced features include the Software Development Kit (SDK) interfaces and a multi-thread implementation for system speed-up.", "labels": [], "entities": []}], "introductionContent": [{"text": "Chinese has been one of the most popular world languages for years.", "labels": [], "entities": []}, {"text": "Due to its complexity and diverse underlying structures, processing this language is a challenging issue and has been clearly an important part of Natural Language Processing (NLP).", "labels": [], "entities": []}, {"text": "Many tasks are proposed to analyze and understand Chinese, ranging from word segmentation to syntactic and/or semantic parsing, which can benefit a wide range of natural language applications.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 72, "end_pos": 89, "type": "TASK", "confidence": 0.7351413369178772}, {"text": "semantic parsing", "start_pos": 110, "end_pos": 126, "type": "TASK", "confidence": 0.7059217542409897}]}, {"text": "To date, several systems have been developed for Chinese word segmentation, partof-speech tagging and syntactic parsing (examples include Stanford CoreNLP 1 , FudanNLP 2 , LT-P and etc.) though some of them are not optimized for Chinese.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 49, "end_pos": 74, "type": "TASK", "confidence": 0.6192359328269958}, {"text": "partof-speech tagging", "start_pos": 76, "end_pos": 97, "type": "TASK", "confidence": 0.8143600821495056}, {"text": "syntactic parsing", "start_pos": 102, "end_pos": 119, "type": "TASK", "confidence": 0.7311619520187378}]}, {"text": "In this paper we present anew toolkit for Chinese syntactic and semantic analysis (call it NiuParser 4 ).", "labels": [], "entities": [{"text": "Chinese syntactic and semantic analysis", "start_pos": 42, "end_pos": 81, "type": "TASK", "confidence": 0.6103416979312897}]}, {"text": "Unlike previous systems, the NiuParser toolkit can handle most of Chinese parsing-related tasks, including word segmentation, part-of-speech tagging, named entity recognition, chunking, constituent parsing, dependency parsing, and semantic role labeling.", "labels": [], "entities": [{"text": "Chinese parsing-related tasks", "start_pos": 66, "end_pos": 95, "type": "TASK", "confidence": 0.7149142821629842}, {"text": "word segmentation", "start_pos": 107, "end_pos": 124, "type": "TASK", "confidence": 0.7614643573760986}, {"text": "part-of-speech tagging", "start_pos": 126, "end_pos": 148, "type": "TASK", "confidence": 0.7223338186740875}, {"text": "named entity recognition", "start_pos": 150, "end_pos": 174, "type": "TASK", "confidence": 0.6139910817146301}, {"text": "constituent parsing", "start_pos": 186, "end_pos": 205, "type": "TASK", "confidence": 0.7275877594947815}, {"text": "dependency parsing", "start_pos": 207, "end_pos": 225, "type": "TASK", "confidence": 0.8331392407417297}, {"text": "semantic role labeling", "start_pos": 231, "end_pos": 253, "type": "TASK", "confidence": 0.6706048647562662}]}, {"text": "To the best of our knowledge we are the first to report that all seven of these functions are supported in a single NLP package.", "labels": [], "entities": []}, {"text": "All subsystems in NiuParser are based on statistical models and are learned automatically from data.", "labels": [], "entities": [{"text": "NiuParser", "start_pos": 18, "end_pos": 27, "type": "DATASET", "confidence": 0.8904603123664856}]}, {"text": "Also, we optimize these systems for Chinese in several ways, including handcrafted rules used in pre/post-processing, heuristics used in various algorithms, and a number of tuned features.", "labels": [], "entities": []}, {"text": "The systems are implemented with C++ and run fast.", "labels": [], "entities": []}, {"text": "On several benchmarks, we demonstrate state-ofthe-art performance in both accuracy/F1 score and speed.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9997228980064392}, {"text": "F1 score", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9770250022411346}, {"text": "speed", "start_pos": 96, "end_pos": 101, "type": "METRIC", "confidence": 0.989164412021637}]}, {"text": "In addition, NiuParser can befit into large-scale tasks which are common in both research-oriented experiments and industrial applications.", "labels": [], "entities": []}, {"text": "Several useful utilities are distributed with NiuParser, such as the Software Development Kit (SDK) interfaces and a multi-thread implementation for system speed-up.", "labels": [], "entities": []}, {"text": "The rest of the demonstration is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the implementation details of each subsystem, including statistical approaches and some enhancements with handcrafted rules and dictionaries.", "labels": [], "entities": []}, {"text": "Section 3 represents the ways to use the toolkit.", "labels": [], "entities": []}, {"text": "We also show the performance of the system in Section 4 and finally we conclude the demonstration and point out the future work of NiuParser in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We ran our system on several benchmarks.", "labels": [], "entities": []}, {"text": "Specifically, we trained and tested word segmentation, POS tagging, chunking, and constituent parsing on CTB5.1: articles 001-270 and 440-1151 were used for training and articles 271-300 were used for testing.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.7506468296051025}, {"text": "POS tagging", "start_pos": 55, "end_pos": 66, "type": "TASK", "confidence": 0.9001442790031433}, {"text": "constituent parsing", "start_pos": 82, "end_pos": 101, "type": "TASK", "confidence": 0.7100258469581604}, {"text": "CTB5.1", "start_pos": 105, "end_pos": 111, "type": "DATASET", "confidence": 0.961056649684906}]}, {"text": "The performance of named entity recognition was reported on OntoNotes, where 49,011 sentences were used for training and 1,340 sentences were used for testing.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 19, "end_pos": 43, "type": "TASK", "confidence": 0.6681076486905416}, {"text": "OntoNotes", "start_pos": 60, "end_pos": 69, "type": "DATASET", "confidence": 0.9535875916481018}]}, {"text": "For semantic role labeling, we adopted the same data set and splitting as in.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.7416017452875773}]}, {"text": "Finally, the data set and splitting in () were used to evaluate the performance of dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.8406372368335724}]}, {"text": "All results were reported on a machine with a 800MHz CPU and 4GB memory.", "labels": [], "entities": []}, {"text": "See for results of acurracy/F1 scores, memory use, model sizes and speed.", "labels": [], "entities": [{"text": "acurracy/F1 scores", "start_pos": 19, "end_pos": 37, "type": "METRIC", "confidence": 0.855853870511055}, {"text": "speed", "start_pos": 67, "end_pos": 72, "type": "METRIC", "confidence": 0.9798784255981445}]}, {"text": "Note that we evaluated the speed with a single thread and the accuracies were achieved with statistical models only.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 62, "end_pos": 72, "type": "METRIC", "confidence": 0.9923639297485352}]}, {"text": "From the results we can see that most of the subsystems achieve state-of-the-art performance, (the chunking subsystem is an exception, whose accuracy still have some room left for further improvements.).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 141, "end_pos": 149, "type": "METRIC", "confidence": 0.9982105493545532}]}, {"text": "In addition, the memory use of dependency parsing is extremely heavy.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.8646295368671417}]}, {"text": "We will optimize the implementation of dependency parsing in our future work.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.8980143070220947}]}], "tableCaptions": [{"text": " Table 2: Evaluation of NiuParser on various tasks.  \u2020 beam search-based global training method.   \u2021 classification-based method with Neural Networks. characters per second.  *  predicates per second.", "labels": [], "entities": []}]}