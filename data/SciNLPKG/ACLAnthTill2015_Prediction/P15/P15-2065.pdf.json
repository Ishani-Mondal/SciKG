{"title": [{"text": "Robust Multi-Relational Clustering via 1 -Norm Symmetric Nonnegative Matrix Factorization", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we propose an 1-norm Symmetric Nonnegative Matrix Tri-Factorization (1 S-NMTF) framework to cluster multi-type relational data by utilizing their interrelatedness.", "labels": [], "entities": []}, {"text": "Due to introducing the 1-norm distances in our new objective function, the proposed approach is robust against noise and outliers, which are inherent in multi-relational data.", "labels": [], "entities": []}, {"text": "We also derive the solution algorithm and rigorously analyze its correctness and convergence.", "labels": [], "entities": [{"text": "correctness", "start_pos": 65, "end_pos": 76, "type": "METRIC", "confidence": 0.9728044867515564}, {"text": "convergence", "start_pos": 81, "end_pos": 92, "type": "METRIC", "confidence": 0.9348127841949463}]}, {"text": "The promising experimental results of the algorithm applied to text clustering on IMDB dataset validate the proposed approach.", "labels": [], "entities": [{"text": "text clustering", "start_pos": 63, "end_pos": 78, "type": "TASK", "confidence": 0.7711468935012817}, {"text": "IMDB dataset", "start_pos": 82, "end_pos": 94, "type": "DATASET", "confidence": 0.9514615833759308}]}], "introductionContent": [{"text": "Traditional clustering aims to partition data points into several groups, such that the data points in the same group can share some commonalities whilst those from different groups are dissimilar.", "labels": [], "entities": []}, {"text": "With the recent progresses of Internet and computational technologies, data have started to appear in much richer structures.", "labels": [], "entities": []}, {"text": "To be more specific, in many real-world problems a pair of object can be related in several different ways, which inevitably complicates the problem and calls for new clustering algorithms for better understanding to the data.", "labels": [], "entities": []}, {"text": "To address this new challenge,;) proposed nonnegative matrix factorization (NMF) () based computational algorithms that have successfully solved the problems.", "labels": [], "entities": []}, {"text": "Due to its mathematical elegance and its equivalence to K-means clustering and spectral clustering (), NMF () has been broadly studied in recent years and successfully solved a variety of practical problems in data mining and machine learning, such as those in computer vision (), bioinformatics (, natural language understanding (), to name a few.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 299, "end_pos": 329, "type": "TASK", "confidence": 0.6486763854821523}]}, {"text": "Compared to many traditional clustering methods, such as K-means clustering, NMF has better mathematical interpretation, which usually lead to improved accuracy on clustering (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.9990538954734802}]}, {"text": "Traditional clustering algorithms concentrate on dealing with homogeneous data, in which all the data belong to one single type ().", "labels": [], "entities": []}, {"text": "To deal with the richer data structures in modern real-world applications, symmetric Nonnegative Matrix Tri-Factorization (NMTF)() have demonstrated its effectiveness on simultaneous clustering of multi-type relational data by utilizing the interrelatedness among different data types.", "labels": [], "entities": []}, {"text": "Traditional NMF algorithms routinely use the least square error functions, which are notably known to be sensitive against outliers.", "labels": [], "entities": []}, {"text": "However, at the era of big data outliers are inevitable due to the ever increasing data sizes.", "labels": [], "entities": []}, {"text": "As a result, developing a more robust NMF model for multi-relational data clustering has become more and more important.", "labels": [], "entities": [{"text": "multi-relational data clustering", "start_pos": 52, "end_pos": 84, "type": "TASK", "confidence": 0.634297251701355}]}, {"text": "In this paper, we further develop the symmetric NMF clustering model proposed in () by using the 1 -norm distances, such that our new clustering model is more robust against outliers, which is of particular importance in multi-relational data.", "labels": [], "entities": [{"text": "NMF clustering", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.6524421870708466}]}], "datasetContent": [{"text": "In this section, We test our proposed algorithm on IMDB dataset by using its inter-type relationship information.", "labels": [], "entities": [{"text": "IMDB dataset", "start_pos": 51, "end_pos": 63, "type": "DATASET", "confidence": 0.8993646204471588}]}, {"text": "In our experiment, we set the multi-type data as 3 types: author, comment and word.", "labels": [], "entities": []}, {"text": "As it is discussed in the 3rd part, there are three relationships we need to find, which correspond to three matrices we need to construct the multi-type data matrix:comment-author, comment-word and author-word.", "labels": [], "entities": []}, {"text": "By making use of the URL of every comment, we can find the author who posts the corresponding comment, thus we can build the author-comment matrix.Since each comment with content is given by the dataset file, we could therefore construct the matrix of comment-word, and the author-word matrix is the product of authorcomment matrix and comment-word matrix.", "labels": [], "entities": []}, {"text": "We could find the first 1500 authors who post comments most, since the comments from the same person are more likely to have some correlations, such as similar sentence structures, same words and etc.", "labels": [], "entities": []}, {"text": "We also rule out the stop-words since they may disturb the clustering and they are meaningless to the property of comments.", "labels": [], "entities": []}, {"text": "To make our experiments to be more persuasive, we also add some noise to the three relationship matrices with a ratio of 25 percentage(1/5 in amplitude).", "labels": [], "entities": []}, {"text": "By randomly choosing 500 authors from 1500, we could generate many sub-datasets to conduct our experiments.", "labels": [], "entities": []}, {"text": "We compare the performance of our proposed 1 -norm S-NMTF algorithm with other methods such as P-NMF, Frobenius norm S-NMTF, traditional NMF and K-means clustering.", "labels": [], "entities": []}, {"text": "For simplicity, we only compare the clustering accuracy of commentword matrix since its label (positive or negative) is fixed(the grounding label), thus could be compared with the clustering results by using the clustering algorithms.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.8863404393196106}]}, {"text": "shows that when the data is pure, in many cases(more than the listed), 1 -norm S-NMTF approach has better performance than others illustrates the situation when some noise is added to the data, it is easy to find that 1 -norm S-NMTF algorithm is the best in terms of clustering accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 278, "end_pos": 286, "type": "METRIC", "confidence": 0.8717114925384521}]}, {"text": "This meets our analysis in our Motivation part.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Clustering Accuracy with Noise.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.8765645623207092}]}, {"text": " Table 3: Clustering Accuracy Contrast.", "labels": [], "entities": [{"text": "Clustering Accuracy Contrast", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.7463396191596985}]}]}