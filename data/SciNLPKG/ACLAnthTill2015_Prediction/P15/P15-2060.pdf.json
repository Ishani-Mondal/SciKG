{"title": [{"text": "Event Detection and Domain Adaptation with Convolutional Neural Networks", "labels": [], "entities": [{"text": "Event Detection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7438200414180756}, {"text": "Domain Adaptation", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.7366902232170105}]}], "abstractContent": [{"text": "We study the event detection problem using convolutional neural networks (CNNs) that overcome the two fundamental limitations of the traditional feature-based approaches to this task: complicated feature engineering for rich feature sets and error propagation from the preceding stages which generate these features.", "labels": [], "entities": [{"text": "event detection", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.7416594326496124}]}, {"text": "The experimental results show that the CNNs outper-form the best reported feature-based systems in the general setting as well as the domain adaptation setting without resorting to extensive external resources.", "labels": [], "entities": []}], "introductionContent": [{"text": "We address the problem of event detection (ED): identifying instances of specified types of events in text.", "labels": [], "entities": [{"text": "event detection (ED)", "start_pos": 26, "end_pos": 46, "type": "TASK", "confidence": 0.8918064832687378}]}, {"text": "Associated with each event mention is a phrase, the event trigger (most often a single verb or nominalization), which evokes that event.", "labels": [], "entities": []}, {"text": "Our task, more precisely stated, involves identifying event triggers and classifying them into specific types.", "labels": [], "entities": []}, {"text": "For instance, according to the ACE 2005 annotation guideline 1 , in the sentence \"A police officer was killed in New Jersey today\", an event detection system should be able to recognize the word \"killed\" as a trigger for the event \"Die\".", "labels": [], "entities": [{"text": "ACE 2005 annotation guideline 1", "start_pos": 31, "end_pos": 62, "type": "DATASET", "confidence": 0.9372460007667541}, {"text": "event detection", "start_pos": 135, "end_pos": 150, "type": "TASK", "confidence": 0.692622721195221}]}, {"text": "This task is quite challenging, as the same event might appear in the form of various trigger expressions and an expression might represent different events in different contexts.", "labels": [], "entities": []}, {"text": "ED is a crucial component in the overall task of event extraction, which also involves event argument discovery.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 49, "end_pos": 65, "type": "TASK", "confidence": 0.7982677221298218}, {"text": "event argument discovery", "start_pos": 87, "end_pos": 111, "type": "TASK", "confidence": 0.7184727390607198}]}, {"text": "Recent systems for event extraction have employed either a pipeline architecture with separate classifiers for trigger and argument labeling and) or a joint inference architecture that performs the two subtasks at the same time to benefit from their inter-dependencies (;).", "labels": [], "entities": [{"text": "event extraction", "start_pos": 19, "end_pos": 35, "type": "TASK", "confidence": 0.7233012467622757}]}, {"text": "Both approaches have coped with the ED task by elaborately hand-designing a large set of features (feature engineering) and utilizing the existing supervised natural language processing (NLP) toolkits and resources (i.e name tagger, parsers, gazetteers etc) to extract these features to be fed into statistical classifiers.", "labels": [], "entities": [{"text": "ED", "start_pos": 36, "end_pos": 38, "type": "TASK", "confidence": 0.9615607857704163}]}, {"text": "Although this approach has achieved the top performance), it suffers from at least two issues: (i) The choice of features is a manual process and requires linguistic intuition as well as domain expertise, implying additional studies for new application domains and limiting the capacity to quickly adapt to these new domains.", "labels": [], "entities": []}, {"text": "(ii) The supervised NLP toolkits and resources for feature extraction might involve errors (either due to the imperfect nature or the performance loss of the toolkits on new domains), probably propagated to the final event detector.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.7649805843830109}]}, {"text": "This paper presents a convolutional neural network () for the ED task that automatically learns features from sentences, and minimizes the dependence on supervised toolkits and resources for features, thus alleviating the error propagation and improving the performance for this task.", "labels": [], "entities": []}, {"text": "Due to the emerging interest of the NLP community in deep learning recently, CNNs have been studied extensively and applied effectively in various tasks: semantic parsing (), search query retrieval), semantic matching (, sentence modeling and classification; Kim,.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 154, "end_pos": 170, "type": "TASK", "confidence": 0.7308725565671921}, {"text": "search query retrieval", "start_pos": 175, "end_pos": 197, "type": "TASK", "confidence": 0.6090459028879801}, {"text": "semantic matching", "start_pos": 200, "end_pos": 217, "type": "TASK", "confidence": 0.7997866570949554}, {"text": "sentence modeling and classification", "start_pos": 221, "end_pos": 257, "type": "TASK", "confidence": 0.7439295947551727}]}, {"text": "However, to the best of our knowledge, this is the first work on event detection via CNNs so far.", "labels": [], "entities": [{"text": "event detection", "start_pos": 65, "end_pos": 80, "type": "TASK", "confidence": 0.7714499235153198}]}, {"text": "First, we evaluate CNNs for ED in the general setting and show that CNNs, though not requiring complicated feature engineering, can still outperform the state-of-the-art feature-based methods extensively relying on the other supervised modules and manual resources for features.", "labels": [], "entities": [{"text": "ED", "start_pos": 28, "end_pos": 30, "type": "TASK", "confidence": 0.8953954577445984}]}, {"text": "Second, we investigate CNNs in a domain adaptation (DA) setting for ED.", "labels": [], "entities": []}, {"text": "We demonstrate that CNNs significantly outperform the traditional featurebased methods with respect to generalization performance across domains due to: (i) their capacity to mitigate the error propagation from the preprocessing modules for features, and (ii) the use of word embeddings to induce a more general representation for trigger candidates.", "labels": [], "entities": []}, {"text": "We believe that this is also the first research on domain adaptation using CNNs.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.7252180278301239}]}], "datasetContent": [{"text": "As the benefit of multiple window sizes in the convolution layer has been demonstrated in the previous work on sentence modeling, in the experiments below, we use window sizes in the set {2, 3, 4, 5} to generate feature maps.", "labels": [], "entities": [{"text": "sentence modeling", "start_pos": 111, "end_pos": 128, "type": "TASK", "confidence": 0.7662287056446075}]}, {"text": "We utilize 150 feature maps for each window size in this set.", "labels": [], "entities": []}, {"text": "The window size for triggers is set to 31 while the dimensionality of the position embeddings and entity type embeddings is 50 3 .We inherit the values for the other parameters from, i.e, the dropout rate \u03c1 = 0.5, the mini-batch size = 50, the hyperparameter for the l 2 norms = 3.", "labels": [], "entities": [{"text": "dropout rate \u03c1", "start_pos": 192, "end_pos": 206, "type": "METRIC", "confidence": 0.7820051312446594}]}, {"text": "Finally, we employ the pre-trained word embeddings word2vec with 300 dimensions from for initialization.", "labels": [], "entities": []}, {"text": "We evaluate the presented CNN over the ACE 2005 corpus.", "labels": [], "entities": [{"text": "ACE 2005 corpus", "start_pos": 39, "end_pos": 54, "type": "DATASET", "confidence": 0.9672062397003174}]}, {"text": "For comparison purposes, we utilize the same test set with 40 newswire articles (672 sentences), the same development set with 30 other documents (836 sentences) and the same training set with the remaning 529 documents (14,849 sentences) as the previous studies on this dataset ().", "labels": [], "entities": []}, {"text": "The ACE 2005 corpus has 33 event subtypes that, along with one class \"None\" for the non-trigger tokens, constitutes a 34-class classification problem.", "labels": [], "entities": [{"text": "ACE 2005 corpus", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9667900403340658}]}, {"text": "In order to evaluate the effectiveness of the position embeddings and the entity type embeddings, reports the performance of the proposed CNN on the development set when these embeddings are either included or excluded from the systems.", "labels": [], "entities": []}, {"text": "With the large margins of performance, it is very clear from the table that the position embeddings are crucial while the entity embeddings are also very useful for CNNs on ED.", "labels": [], "entities": []}, {"text": "For the experiments below, we examine the CNNs in two scenarios: excluding the entity type embeddings (CNN1) and including the entity type embeddings (CNN2).", "labels": [], "entities": []}, {"text": "We always use position embeddings in these two scenarios.", "labels": [], "entities": []}, {"text": "In this section, we aim to further compare the proposed CNNs with the feature-based systems under the domain adaptation setting for event detection.", "labels": [], "entities": [{"text": "event detection", "start_pos": 132, "end_pos": 147, "type": "TASK", "confidence": 0.7373347580432892}]}, {"text": "The ultimate goal of domain adaptation research is to develop techniques taking training External features are the features generated from the supervised NLP modules and manual resources such as parsers, name tagger, entity mention extractors (either automatic or manual), gazetteers etc.", "labels": [], "entities": [{"text": "domain adaptation research", "start_pos": 21, "end_pos": 47, "type": "TASK", "confidence": 0.8157257239023844}]}, {"text": "We also do the experiments in this part over the ACE 2005 dataset but focus more on the difference between domains.", "labels": [], "entities": [{"text": "ACE 2005 dataset", "start_pos": 49, "end_pos": 65, "type": "DATASET", "confidence": 0.984795331954956}]}, {"text": "The ACE 2005 corpus comes with 6 different domains: broadcast conversation (bc), broadcast news (bn), telephone conversation (cts), newswire (nw), usenet (un) and webblogs (wl).", "labels": [], "entities": [{"text": "ACE 2005 corpus", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.9652159810066223}]}, {"text": "Following the common practice of domain adaptation research on this dataset, we use news (the union of bn and nw) as the source domain and bc, cts, wl as three different target domains.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.7395354509353638}]}, {"text": "We take half of bc as the development set and use the remaining data for testing.", "labels": [], "entities": []}, {"text": "We note that the distribution of event subtypes and the vocabularies of the source and target domains are quite different (Plank and Moschitti, 2013).", "labels": [], "entities": []}, {"text": "The main conclusions from the table include: (i) The baseline systems MaxEnt, Joint+Local, Joint+Local+Global achieve high performance on the source domain, but degrade dramatically on The performance of the feature-based systems MaxEnt, Joint+Local and Joint+Local+Global are obtained from the actual systems in. the target domains due to the domain shifts.", "labels": [], "entities": []}, {"text": "(ii) Comparing CNN1 and the baseline systems, we see that CNN1 performs comparably with the baseline systems on the source domain (in-domain performance) (as expected), substantially outperform the baseline systems on two of the three target domains (i.e, bc and cts), and is only less effective than the joint beam search approach on the wl domain; (iii) Finally and most importantly, we consistently achieve the best adaptation performance across all the target domains with CNN2 by only introducing entity type information into CNN1.", "labels": [], "entities": []}, {"text": "In fact, CNN2 significantly outperforms the feature-based systems with p < 0.05 and large margins of about 5.0% on the domains bc and cts, clearly confirming our argument in Section 3.3 and testifying to the benefits of CNNs on DA for ED.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance on the Development Set.", "labels": [], "entities": [{"text": "Development Set", "start_pos": 29, "end_pos": 44, "type": "DATASET", "confidence": 0.7391892820596695}]}, {"text": " Table 2: Performance with Gold-Standard Entity Mentions", "labels": [], "entities": [{"text": "Gold-Standard Entity Mentions", "start_pos": 27, "end_pos": 56, "type": "METRIC", "confidence": 0.5784368316332499}]}, {"text": " Table 4: In-domain (first column) and Out-of-domain Performance (columns two to four). Cells marked with  \u2020designate", "labels": [], "entities": []}]}