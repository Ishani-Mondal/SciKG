{"title": [{"text": "A Unified Learning Framework of Skip-Grams and Global Vectors", "labels": [], "entities": []}], "abstractContent": [{"text": "Log-bilinear language models such as SkipGram and GloVe have been proven to capture high quality syntactic and semantic relationships between words in a vector space.", "labels": [], "entities": [{"text": "SkipGram", "start_pos": 37, "end_pos": 45, "type": "DATASET", "confidence": 0.9553731679916382}]}, {"text": "We revisit the relationship between SkipGram and GloVe models from a machine learning viewpoint, and show that these two methods are easily merged into a unified form.", "labels": [], "entities": [{"text": "SkipGram", "start_pos": 36, "end_pos": 44, "type": "DATASET", "confidence": 0.9488659501075745}]}, {"text": "Then, by using the unified form, we extract the factors of the configurations that they use differently.", "labels": [], "entities": []}, {"text": "We also empirically investigate which factor is responsible for the performance difference often observed in widely examined word similarity and analogy tasks.", "labels": [], "entities": [{"text": "word similarity and analogy tasks", "start_pos": 125, "end_pos": 158, "type": "TASK", "confidence": 0.7161869525909423}]}], "introductionContent": [{"text": "Neural-network-inspired word embedding methods such as Skip-Gram (SkipGram) have been proven to capture high quality syntactic and semantic relationships between words in a vector space.", "labels": [], "entities": []}, {"text": "A similar embedding method, called 'Global Vector (GloVe)', was recently proposed.", "labels": [], "entities": []}, {"text": "It has demonstrated significant improvements over SkipGram on the widely used 'Word Analogy' and 'Word Similarity' benchmark datasets ().", "labels": [], "entities": [{"text": "SkipGram", "start_pos": 50, "end_pos": 58, "type": "DATASET", "confidence": 0.9524728059768677}, {"text": "Word Similarity' benchmark datasets", "start_pos": 98, "end_pos": 133, "type": "DATASET", "confidence": 0.7177050530910491}]}, {"text": "Unfortunately, a later deep re-evaluation has revealed that GloVe does not consistently outperform SkipGram (; both methods provided basically the same level of performance, and SkipGram even seems 'more robust (not yielding very poor results)' than GloVe.", "labels": [], "entities": [{"text": "SkipGram", "start_pos": 99, "end_pos": 107, "type": "DATASET", "confidence": 0.9516836404800415}]}, {"text": "Moreover, some other papers, i.e.,, and some researchers in the community have discussed a relationship, and/or which is superior, SkipGram or GloVe.", "labels": [], "entities": [{"text": "SkipGram", "start_pos": 131, "end_pos": 139, "type": "DATASET", "confidence": 0.9510660767555237}, {"text": "GloVe", "start_pos": 143, "end_pos": 148, "type": "DATASET", "confidence": 0.7579032182693481}]}, {"text": "From this background, we revisit the relationship between SkipGram and GloVe from a machine learning viewpoint.", "labels": [], "entities": [{"text": "SkipGram", "start_pos": 58, "end_pos": 66, "type": "DATASET", "confidence": 0.9543105363845825}]}, {"text": "We show that it is nat-V : set of vocabulary (set of words) |V| : vocabulary size, or number of words in V i : index of the input vector, where i \u2208 {1, . .", "labels": [], "entities": []}, {"text": ", |V|} j : index of the output vector, where j \u2208 {1, . .", "labels": [], "entities": []}, {"text": ", |V|} ei : input vector of the i-th word in V oj : output vector of the j-th word in V If i = j, then ei and oj are the input and output vectors of the same word in V, respectively.", "labels": [], "entities": []}, {"text": "D : number of dimensions in input and output vectors mi,j : (i, j)-factor of matrix M si,j : dot product of input and output vectors, ci,j : co-occurrence of the i-th and j-th words in DD : (virtual) negative sampling data c i,j : co-occurrence of the i-th and j-th words in D k : hyper-parameter of the negative sampling \u03b2(\u00b7) : 'weighting factor' of loss function \u03a6(\u00b7) : loss function: List of notations used in this paper.", "labels": [], "entities": []}, {"text": "ural to think that these two methods are essentially identical, with the chief difference being their learning configurations.", "labels": [], "entities": []}, {"text": "The final goal of this paper is to provide a unified learning framework that encompasses the configurations used in SkipGram and GloVe to gain a deeper understanding of the behavior of these embedding methods.", "labels": [], "entities": [{"text": "SkipGram", "start_pos": 116, "end_pos": 124, "type": "DATASET", "confidence": 0.950391411781311}]}, {"text": "We also empirically investigate which learning configuration most clearly elucidates the performance difference often observed in word similarity and analogy tasks.", "labels": [], "entities": []}, {"text": "shows the notations used in this paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Following the series of neural word embedding papers, our training data is taken from a Wikipedia dump (Aug. 2014).", "labels": [], "entities": [{"text": "Wikipedia dump", "start_pos": 88, "end_pos": 102, "type": "DATASET", "confidence": 0.9385006129741669}]}, {"text": "We tokenized and lowercased the data yielding about 1.8B tokens.", "labels": [], "entities": []}, {"text": "For the hyper-parameter selection, we mostly followed the suggestion made in (.", "labels": [], "entities": []}, {"text": "summarizes the default values of hyper-parameters used consistently in all our experiments unless otherwise noted.", "labels": [], "entities": []}, {"text": "We prepared eight word similarity benchmark datasets (WSimilarity), namely, R&G shows the training time and performance results gained from our benchmark data.", "labels": [], "entities": []}, {"text": "The column 'time' indicates average elapsed time (second) for model learning.", "labels": [], "entities": [{"text": "time", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.9590079188346863}]}, {"text": "All the results are the average performance often runs.", "labels": [], "entities": []}, {"text": "This is because the comparison methods have some randomized factors, such as initial value (since they are nonconvex optimization problems) and (probabilistic) sampling method, which significantly impact the results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Hyper-parameters in our experiments.", "labels": [], "entities": []}, {"text": " Table 4: Results: the micro averages of Spear- man's rho (WSimilarity) and accuracy (WAnal- ogy) for all benchmark datasets.", "labels": [], "entities": [{"text": "Spear- man's rho (WSimilarity)", "start_pos": 41, "end_pos": 71, "type": "METRIC", "confidence": 0.6540385819971561}, {"text": "accuracy (WAnal- ogy)", "start_pos": 76, "end_pos": 97, "type": "METRIC", "confidence": 0.8936207393805186}]}, {"text": " Table 5: Impact of the context window size, and  harmonic function.", "labels": [], "entities": []}, {"text": " Table 7: Impact of the weighting function.", "labels": [], "entities": []}]}