{"title": [], "abstractContent": [{"text": "We reduce phrase-based parsing to dependency parsing.", "labels": [], "entities": [{"text": "phrase-based parsing", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.6959731876850128}, {"text": "dependency parsing", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.8013092875480652}]}, {"text": "Our reduction is grounded on anew intermediate representation, \"head-ordered dependency trees,\" shown to be isomorphic to constituent trees.", "labels": [], "entities": []}, {"text": "By encoding order information in the dependency labels, we show that any off-the-shelf, trainable dependency parser can be used to produce constituents.", "labels": [], "entities": []}, {"text": "When this parser is non-projective, we can perform discontinuous parsing in a very natural manner.", "labels": [], "entities": []}, {"text": "Despite the simplicity of our approach , experiments show that the resulting parsers are on par with strong base-lines, such as the Berkeley parser for En-glish and the best non-reranking system in the SPMRL-2014 shared task.", "labels": [], "entities": [{"text": "SPMRL-2014 shared task", "start_pos": 202, "end_pos": 224, "type": "TASK", "confidence": 0.6231851975123087}]}, {"text": "Results are particularly striking for discontinuous parsing of German, where we surpass the current state of the art by a wide margin.", "labels": [], "entities": [{"text": "parsing of German", "start_pos": 52, "end_pos": 69, "type": "TASK", "confidence": 0.7643629312515259}]}], "introductionContent": [{"text": "Constituent parsing is a central problem in NLP-one at which statistical models trained on treebanks have excelled.", "labels": [], "entities": [{"text": "Constituent parsing", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8530558347702026}]}, {"text": "However, most existing parsers are slow, since they need to deal with a heavy grammar constant.", "labels": [], "entities": []}, {"text": "Dependency parsers are generally faster, but less informative, since they do not produce constituents, which are often required by downstream applications).", "labels": [], "entities": [{"text": "Dependency parsers", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8173894882202148}]}, {"text": "How to get the best of both worlds?", "labels": [], "entities": []}, {"text": "Coarse-to-fine decoding) and shift-reduce parsing) were a step forward * This research was carried out during an internship at Priberam Labs.", "labels": [], "entities": [{"text": "Priberam Labs", "start_pos": 127, "end_pos": 140, "type": "DATASET", "confidence": 0.908803254365921}]}, {"text": "to accelerate constituent parsing, but typical runtimes still lag those of dependency parsers.", "labels": [], "entities": [{"text": "constituent parsing", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.5563775300979614}]}, {"text": "This is only made worse if discontinuous constituents are allowed-such discontinuities are convenient to represent wh-movement, scrambling, extraposition, and other linguistic phenomena common in free word order languages.", "labels": [], "entities": []}, {"text": "While non-projective dependency parsers, which are able to model such phenomena, have been widely developed in the last decade), discontinuous constituent parsing is still taking its first steps.", "labels": [], "entities": [{"text": "discontinuous constituent parsing", "start_pos": 129, "end_pos": 162, "type": "TASK", "confidence": 0.70916881163915}]}, {"text": "In this paper, we show that an off-the-shelf, trainable, dependency parser is enough to build a highly-competitive constituent parser.", "labels": [], "entities": []}, {"text": "This (surprising) result is based on a reduction 1 of constituent to dependency parsing, followed by a simple post-processing procedure to recover unaries.", "labels": [], "entities": [{"text": "constituent to dependency parsing", "start_pos": 54, "end_pos": 87, "type": "TASK", "confidence": 0.6381047293543816}]}, {"text": "Unlike other constituent parsers, ours does not require estimating a grammar, nor binarizing the treebank.", "labels": [], "entities": []}, {"text": "Moreover, when the dependency parser is non-projective, our method can perform discontinuous constituent parsing in a very natural way.", "labels": [], "entities": []}, {"text": "Key to our approach is the notion of headordered dependency trees (shown in): by endowing dependency trees with this additional layer of structure, we show that they become isomorphic to constituent trees.", "labels": [], "entities": []}, {"text": "We encode this structure as part of the dependency labels, enabling a dependency-to-constituent conversion.", "labels": [], "entities": []}, {"text": "A related conversion was attempted by to parse German, but their complex encoding scheme blows up the number of arc labels, affecting the final parser's quality.", "labels": [], "entities": [{"text": "parse German", "start_pos": 41, "end_pos": 53, "type": "TASK", "confidence": 0.8554787039756775}]}, {"text": "By contrast, our light encoding achieves a 10-fold decrease in the label alphabet, leading to more accurate parsing.", "labels": [], "entities": []}, {"text": "While simple, our reduction-based parsers are on par with the Berkeley parser for English, and with the best single system in the recent SPMRL shared task ( ), for eight morphologically rich languages.", "labels": [], "entities": [{"text": "SPMRL shared task", "start_pos": 137, "end_pos": 154, "type": "TASK", "confidence": 0.6708827416102091}]}, {"text": "For discontinuous parsing, we surpass the current state of the art by a wide margin on two German datasets (TIGER and NEGRA), while achieving fast parsing speeds.", "labels": [], "entities": [{"text": "discontinuous parsing", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.7414653897285461}, {"text": "German datasets", "start_pos": 91, "end_pos": 106, "type": "DATASET", "confidence": 0.7562493085861206}, {"text": "TIGER", "start_pos": 108, "end_pos": 113, "type": "DATASET", "confidence": 0.3556826710700989}]}, {"text": "We provide a free distribution of our parsers along with this paper, as part of the TurboParser toolkit.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the performance of our reductionbased parsers, we conduct experiments in a variety: Results on the English PTB \u00a723.", "labels": [], "entities": [{"text": "English PTB \u00a723", "start_pos": 111, "end_pos": 126, "type": "DATASET", "confidence": 0.9550316333770752}]}, {"text": "All systems reporting runtimes were run on the same machine.", "labels": [], "entities": []}, {"text": "Marked as * are reranking and semi-supervised c-parsers. of treebanks, both continuous and discontinuous.", "labels": [], "entities": []}, {"text": "shows the accuracies and speeds achieved by our system on the English PTB \u00a723, in comparison to state-of-the-art c-parsers.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9740102887153625}, {"text": "English PTB \u00a723", "start_pos": 62, "end_pos": 77, "type": "DATASET", "confidence": 0.9461309760808945}]}, {"text": "We can see that our simple reduction-based c-parser surpasses the three Stanford parsers (, and is on par with the Berkeley parser, while being more than 5 times faster.", "labels": [], "entities": []}, {"text": "The best supervised competitor is the recent shift-reduce parser of, which achieves similar, but slightly better, accuracy and speed.", "labels": [], "entities": [{"text": "shift-reduce parser", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.5403915494680405}, {"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.999194324016571}]}, {"text": "Our technique has the advantage of being flexible: since the time for d-parsing is the dominating factor (see \u00a74.4), plugging a faster d-parser automatically yields a faster c-parser.", "labels": [], "entities": []}, {"text": "While reranking and semi-supervised systems achieve higher accuracies, this aspect is orthogonal, since the same techniques can be applied to our parser.", "labels": [], "entities": []}, {"text": "We experimented with datasets for eight languages, from the SPMRL14 shared task ).", "labels": [], "entities": [{"text": "SPMRL14 shared task", "start_pos": 60, "end_pos": 79, "type": "DATASET", "confidence": 0.7424672444661459}]}, {"text": "We used the official training, development and test sets with the provided predicted POS tags.", "labels": [], "entities": [{"text": "POS tags", "start_pos": 85, "end_pos": 93, "type": "DATASET", "confidence": 0.6805827021598816}]}, {"text": "For French and German, we used the lexicalization rules detailed in and, respectively.", "labels": [], "entities": []}, {"text": "For Basque, Hungarian and Korean, we always took the rightmost modifier as head-child node.", "labels": [], "entities": []}, {"text": "For Hebrew and Polish we used the leftmost modifier instead.", "labels": [], "entities": []}, {"text": "For Swedish we induced head rules from the provided dependency treebank, as.", "labels": [], "entities": []}, {"text": "These choices were based on dev-set experiments.", "labels": [], "entities": []}, {"text": "For all languages ex-cept French, our system outperforms the Berkeley parser, with or without prescribed POS tags.", "labels": [], "entities": []}, {"text": "Our average F 1 -scores are superior to the best non-reranking system participating in the shared task and to the c-parser of, achieving the best results for 4 out of 8 languages.", "labels": [], "entities": [{"text": "F 1 -scores", "start_pos": 12, "end_pos": 23, "type": "METRIC", "confidence": 0.9493970423936844}]}], "tableCaptions": [{"text": " Table 1: Results on English PTB  \u00a722 achieved by various d- parsers and encoding strategies. For dependencies, we report  unlabeled/labeled attachment scores (UAS/LAS), excluding  punctuation. For constituents, we show F1-scores (without  punctuation and root nodes), as provided by EVALB (Black  et al., 1992). We report total parsing speeds in tokens per sec- ond (including time spent on pruning, decoding, and feature  evaluation), measured on a Intel Xeon processor @2.30GHz.", "labels": [], "entities": [{"text": "English PTB  \u00a722", "start_pos": 21, "end_pos": 37, "type": "DATASET", "confidence": 0.8013040274381638}, {"text": "UAS/LAS)", "start_pos": 160, "end_pos": 168, "type": "METRIC", "confidence": 0.6940380930900574}, {"text": "F1-scores", "start_pos": 220, "end_pos": 229, "type": "METRIC", "confidence": 0.9949179887771606}]}, {"text": " Table 2: Impact of direct and delta encodings on the dev sets  of the SPMRL14 shared task. Reported are the number of  labels and the F1-scores yielded by each encoding technique.", "labels": [], "entities": [{"text": "SPMRL14 shared task", "start_pos": 71, "end_pos": 90, "type": "TASK", "confidence": 0.5948120355606079}, {"text": "F1-scores", "start_pos": 135, "end_pos": 144, "type": "METRIC", "confidence": 0.9968549013137817}]}, {"text": " Table 3: Results on the English PTB  \u00a723. All systems report- ing runtimes were run on the same machine. Marked as  *  are  reranking and semi-supervised c-parsers.", "labels": [], "entities": [{"text": "English PTB  \u00a723", "start_pos": 25, "end_pos": 41, "type": "DATASET", "confidence": 0.9398245960474014}]}, {"text": " Table 5: F1 / exact match scores on TIGER and NEGRA test  sets, with gold and predicted POS tags. These scores are com- puted by the DISCO-DOP evaluator ignoring root nodes and,  for TIGER-H&N and NEGRA, punctuation tokens. The base- lines are published results by Hall and Nivre 2008 (HN08),  Maier et al. 2012 (M12), van Cranenburgh 2012 (C12),  Kallmeyer and Maier 2013 (KM13), van Cranenburgh and  Bod 2013 (CB13), and Versley 2014a, 2014b (V14a, V14b).", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9980958104133606}, {"text": "NEGRA test  sets", "start_pos": 47, "end_pos": 63, "type": "DATASET", "confidence": 0.816927969455719}]}, {"text": " Table 4: F1-scores on eight treebanks of the SPMRL14 shared task, computed with the provided EVALB SPMRL tool, which  takes into account all tokens except root nodes. Berkeley Tagged is a version of", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9973328113555908}, {"text": "SPMRL14 shared task", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.6055362224578857}]}]}