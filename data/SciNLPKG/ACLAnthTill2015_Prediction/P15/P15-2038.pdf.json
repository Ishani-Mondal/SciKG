{"title": [], "abstractContent": [{"text": "Multi-modal semantics has relied on feature norms or raw image data for perceptual input.", "labels": [], "entities": []}, {"text": "In this paper we examine grounding semantic representations in ol-factory (smell) data, through the construction of a novel bag of chemical compounds model.", "labels": [], "entities": []}, {"text": "We use standard evaluations for multi-modal semantics, including measuring conceptual similarity and cross-modal zero-shot learning.", "labels": [], "entities": []}, {"text": "To our knowledge, this is the first work to evaluate semantic similarity on representations grounded in ol-factory data.", "labels": [], "entities": []}], "introductionContent": [{"text": "Distributional semantics represents the meanings of words as vectors in a \"semantic space\", relying on the distributional hypothesis: the idea that words that occur in similar contexts tend to have similar meanings.", "labels": [], "entities": []}, {"text": "Although these models have been successful, the fact that the meaning of a word is represented as a distribution over other words implies they suffer from the grounding problem; i.e. they do not account for the fact that human semantic knowledge is grounded in physical reality and sensori-motor experience.", "labels": [], "entities": []}, {"text": "Multi-modal semantics attempts to address this issue and there has been a surge of recent work on perceptually grounded semantic models.", "labels": [], "entities": []}, {"text": "These models learn semantic representations from both textual and perceptual input and outperform language-only models on a range of tasks, including modelling semantic similarity and relatedness, and predicting compositionality).", "labels": [], "entities": [{"text": "predicting compositionality", "start_pos": 201, "end_pos": 228, "type": "TASK", "confidence": 0.9474754929542542}]}, {"text": "Perceptual information is obtained from either feature norms) or raw data sources such as images).", "labels": [], "entities": []}, {"text": "The former are elicited from human annotators and thus tend to be limited in scope and expensive to obtain.", "labels": [], "entities": []}, {"text": "The latter approach has the advantage that images are widely available and easy to obtain, which, combined with the ready availability of computer vision methods, has led to raw visual information becoming the de-facto perceptual modality in multi-modal models.", "labels": [], "entities": []}, {"text": "However, if our objective is to ground semantic representations in perceptual information, why stop at image data?", "labels": [], "entities": []}, {"text": "The meaning of lavender is probably more grounded in its smell than in the visual properties of the flower that produces it.", "labels": [], "entities": []}, {"text": "Olfactory (smell) perception is of particular interest for grounded semantics because it is much more primitive compared to the other perceptual modalities.", "labels": [], "entities": [{"text": "Olfactory (smell) perception", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6580572903156281}]}, {"text": "As a result, natural language speakers might take aspects of olfactory perception \"for granted\", which would imply that text is a relatively poor source of such perceptual information.", "labels": [], "entities": []}, {"text": "A multi-modal approach would overcome this problem, and might prove useful in, for example, metaphor interpretation (the sweet smell of success; rotten politics) and cognitive modelling, as well as in real-world applications such as automatically retrieving smells or even producing smell descriptions.", "labels": [], "entities": [{"text": "metaphor interpretation", "start_pos": 92, "end_pos": 115, "type": "TASK", "confidence": 0.9367530941963196}, {"text": "cognitive modelling", "start_pos": 166, "end_pos": 185, "type": "TASK", "confidence": 0.7018750458955765}]}, {"text": "Here, we explore grounding semantic representations in olfactory perception.", "labels": [], "entities": []}, {"text": "We obtain olfactory representations by constructing a novel bag of chemical compounds (BoCC) model.", "labels": [], "entities": []}, {"text": "Following previous work in multimodal semantics, we evaluate on well known conceptual similarity and relatedness tasks and on zero-shot learning through induced cross-modal mappings.", "labels": [], "entities": []}, {"text": "To our knowledge this is the first work to explore using olfactory perceptual data for grounding linguistic semantic models.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Examples of pairs in the evaluation  datasets where olfactory information is relevant,  together with the gold-standard similarity score.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 130, "end_pos": 146, "type": "METRIC", "confidence": 0.8945057094097137}]}, {"text": " Table 3: Comparison of olfactory representations  on the covered OMEN dataset.", "labels": [], "entities": [{"text": "OMEN dataset", "start_pos": 66, "end_pos": 78, "type": "DATASET", "confidence": 0.9345620274543762}]}, {"text": " Table 4: Comparison of linguistic, olfactory and  multi-modal representations.", "labels": [], "entities": []}, {"text": " Table 5: Zero-shot learning performance for  BoCC-SVD.", "labels": [], "entities": [{"text": "BoCC-SVD", "start_pos": 46, "end_pos": 54, "type": "DATASET", "confidence": 0.867275059223175}]}]}