{"title": [], "abstractContent": [], "introductionContent": [{"text": "In the TACITUS project for using commonsense knowledge in the understanding of texts about mechanical devices and their failures, we have been developing various commonsense theories that are needed to mediate between the way we talk about the behavior of such devices and causal models of their operation.", "labels": [], "entities": []}, {"text": "Of central importance in this effort is the axiomatization of what might be called \"commonsense metaphysics\".", "labels": [], "entities": []}, {"text": "This includes a number of areas that figure in virtually every domain of discourse, such as scalar notions, granularity, time, space, material, physical objects, causality, functionality, force, and shape.", "labels": [], "entities": []}, {"text": "Our approach to lexical semantics is then to construct core theories of each of these areas, and then to define, or at least characterize, a large number of lexical items in terms provided by the core theories.", "labels": [], "entities": [{"text": "lexical semantics", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.8394965529441833}]}, {"text": "In the TACITUS system, processes for solving pragmatics problems posed by a text will use the knowledge base consisting of these theories in conjunction with the logical forms of the sentences in the text to produce an interpretation.", "labels": [], "entities": []}, {"text": "In this paper we do not stress these interpretation processes; this is another, important aspect of the TACITUS project, and it will be described in subsequent papers.", "labels": [], "entities": [{"text": "TACITUS project", "start_pos": 104, "end_pos": 119, "type": "TASK", "confidence": 0.5688037276268005}]}, {"text": "This work represents a convergence of research in lexical semantics in linguistics and efforts in AI to encode commonsense knowledge.", "labels": [], "entities": []}, {"text": "Lexical semanticists over the years have developed formalisms of increasing adequacy for encoding word meaning, progressing from simple sets of features ( to notations for predicateargument structure), but the early attempts still limited access to world knowledge and assumed only very restricted sorts of processing.", "labels": [], "entities": [{"text": "Lexical semanticists", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8221238553524017}, {"text": "encoding word meaning", "start_pos": 89, "end_pos": 110, "type": "TASK", "confidence": 0.7960967024167379}]}, {"text": "Workers in computational linguistics introduced inference) and other complex cognitive processes into our understanding of the role of word meaning.", "labels": [], "entities": []}, {"text": "Recently, linguists have given greater attention to the cognitive processes that would operate on their representations (e.g.,.", "labels": [], "entities": []}, {"text": "Independently, in AI an effort arose to encode large amounts of commonsense knowledge).", "labels": [], "entities": []}, {"text": "The research reported here represents a convergence of these various developments.", "labels": [], "entities": []}, {"text": "By developing core theories of several fundamental phenomena and defining lexical items within these theories, using the full power of predicate calculus, we are able to cope with complexities of word meaning that have hitherto escaped lexical semanticists, within a framework that gives full scope to the planning and reasoning processes that manipulate representations of word meaning.", "labels": [], "entities": []}, {"text": "In constructing the core theories we are attempting to adhere to several methodological principles.", "labels": [], "entities": []}, {"text": "I. One should aim for characterization of concepts, rather than definition.", "labels": [], "entities": []}, {"text": "One cannot generally expect to find necessary and sufficient conditions fora concept.", "labels": [], "entities": []}, {"text": "The most we can hope for is to find a number of necessary conditions and a number of sufficient conditions.", "labels": [], "entities": []}, {"text": "This amounts to saying that a great many predicates are primitive, but primitives that are highly interrelated with the rest of the knowledge base.", "labels": [], "entities": []}, {"text": "2. One should determine the minimal structure necessary fora concept to make sense.", "labels": [], "entities": []}, {"text": "In efforts to axiomatize some area, there are two positions one may take, exemplified by set theory and by group theory.", "labels": [], "entities": []}, {"text": "In axiomatizing set theory, one attempts to capture exactly some concept one has strong intuitions about.", "labels": [], "entities": [{"text": "axiomatizing set theory", "start_pos": 3, "end_pos": 26, "type": "TASK", "confidence": 0.6215266386667887}]}, {"text": "If the axiomatization turns out to have unexpected models, this exposes an inadequacy.", "labels": [], "entities": []}, {"text": "In group theory, by contrast, one characterizes an abstract class of structures.", "labels": [], "entities": []}, {"text": "If there turnout to be unexpected models, this is a serendipitous discovery of anew phenomenon that we can reason about using an old theory.", "labels": [], "entities": []}, {"text": "The pervasive character of metaphor in natural language discourse shows that our commonsense theories of the world ought to be much more like group theory than set theory.", "labels": [], "entities": []}, {"text": "By seeking minimal structures in axiomatizing concepts, we optimize the possibilities of using the theories in metaphorical and analogical contexts.", "labels": [], "entities": []}, {"text": "This principle is illustrated below in the section on regions.", "labels": [], "entities": []}, {"text": "One consequence of this principle is that our approach will seem more syntactic than semantic.", "labels": [], "entities": []}, {"text": "We have concentrated more on specifying axioms than on constructing models.", "labels": [], "entities": []}, {"text": "Our view is that the chief role of models in our effort is for proving the consistency and independence of sets of axioms, and for showing their adequacy.", "labels": [], "entities": []}, {"text": "As an example of the last point, many of the spatial and temporal theories we construct are intended at least to have Euclidean space or the real numbers as one model, and a subclass of graph-theoretical structures as other models.", "labels": [], "entities": []}, {"text": "3. A balance must be struck between attempting to coverall cases and aiming only for the prototypical cases.", "labels": [], "entities": [{"text": "coverall cases", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.9084323048591614}]}, {"text": "In general, we have tried to cover as many cases as possible with an elegant axiomatization, inline with the two previous principles, but where the formalization begins to look baroque, we assume that higher processes will suspend some inferences in the marginal cases.", "labels": [], "entities": []}, {"text": "We assume that inferences will be drawn in a controlled fashion.", "labels": [], "entities": []}, {"text": "Thus, every outr~, highly context-dependent counterexample need not be accounted for, and to a certain extent, definitions can be geared specifically fora prototype.", "labels": [], "entities": []}, {"text": "4. Where competing ontologies suggest themselves in a domain, one should attempt to construct a theory that accommodates both.", "labels": [], "entities": []}, {"text": "Rather than commit oneself to adopting one set of primitives rather than another, one should show how each set of primitives can be characterized in terms of the other.", "labels": [], "entities": []}, {"text": "Generally, each of the ontologies is useful for different purposes, and it is convenient to be able to appeal to both.", "labels": [], "entities": []}, {"text": "Our treatment of time illustrates this.", "labels": [], "entities": []}, {"text": "5. The theories one constructs should be richer in axioms than in theorems.", "labels": [], "entities": []}, {"text": "In mathematics, one expects to state half a dozen axioms and prove dozens of theorems from them.", "labels": [], "entities": []}, {"text": "In encoding commonsense knowledge it seems to be just the opposite.", "labels": [], "entities": [{"text": "encoding commonsense knowledge", "start_pos": 3, "end_pos": 33, "type": "TASK", "confidence": 0.850019117196401}]}, {"text": "The theorems we seek to prove on the basis of these axioms are theorems about specific situations which are to be interpreted, in particular, theorems about a text that the system is attempting to understand.", "labels": [], "entities": []}, {"text": "6. One should avoid falling into \"black holes\".", "labels": [], "entities": []}, {"text": "There area few \"mysterious\" concepts which crop up repeatedly in the formalization of commonsense metaphysics.", "labels": [], "entities": []}, {"text": "Among these are \"relevant\" (that is, relevant to the task at hand) and \"normative\" (or conforming to some norm or pattern).", "labels": [], "entities": []}, {"text": "To insist upon giving a satisfactory analysis of these before using them in analyzing other concepts is to cross the event horizon that separates lexical semantics from philosophy.", "labels": [], "entities": []}, {"text": "On the other hand, our experience suggests that to avoid their use entirely is crippling; the lexical semantics of a wide variety of other terms depends upon them.", "labels": [], "entities": []}, {"text": "Instead, we have decided to leave them minimally analyzed for the moment and use them without scruple in the analysis of other commonsense concepts.", "labels": [], "entities": []}, {"text": "This approach will allow us to accumulate many examples of the use of these mysterious concepts, and in the end, contribute to their successfill analysis.", "labels": [], "entities": [{"text": "successfill analysis", "start_pos": 133, "end_pos": 153, "type": "TASK", "confidence": 0.5882699638605118}]}, {"text": "The use of these concepts appears below in the discussions of the words \"immediately\", \"sample\", and \"operate\".", "labels": [], "entities": []}, {"text": "We chose as an initial target problem to encode the commonsense knowledge that underlies the concept of \"wear\", as in apart of a device wearing out.", "labels": [], "entities": []}, {"text": "Our aim was to define \"wear\" in terms of predicates characterized elsewhere in the knowledge base and to infer consequences of wear.", "labels": [], "entities": []}, {"text": "For something to wear, we decided, is for it to lose imperceptible bits of material from its surface due to abrasive action overtime.", "labels": [], "entities": []}, {"text": "One goal,which we have not yet achieved, is to be able to prove as a theorem that since the shape of apart of a mechanical device is often functional and since loss of material can result in a change of shape, wear of apart of a device can result in the failure of the device as a whole.", "labels": [], "entities": []}, {"text": "In addition, as we have proceded, we have characterized a number of words found in a set of target texts, as it has become possible.", "labels": [], "entities": []}, {"text": "We are encoding the knowledge as axioms in, what is for the most part a first-order logic, described in ttobbs (1985a), although quantification over predicates is sometimes convenient.", "labels": [], "entities": []}, {"text": "In the formalism there is a nominalization operator \" ' \" for reifying events and conditions, as expressed in the following axiom schema: That is, p is true of x if and only if there is a condition e of p being true of z and e exists in the real world.", "labels": [], "entities": []}, {"text": "In our implementation so far, we have been proving simple theorems from our axioms using the CG5 theoremprover developed by Mark Stickel (1982), but we are only now beginning to use the knowledge base in text processing.", "labels": [], "entities": [{"text": "CG5 theoremprover", "start_pos": 93, "end_pos": 110, "type": "DATASET", "confidence": 0.9535270631313324}]}], "datasetContent": [], "tableCaptions": []}