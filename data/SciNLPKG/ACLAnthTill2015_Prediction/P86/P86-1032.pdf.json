{"title": [{"text": "A MODEL OF PLAN INFERENCE THAT DISTINGUISHES BETWEEN THE BELIEFS OF ACTORS AND OBSERVERS", "labels": [], "entities": [{"text": "A MODEL", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.7433503270149231}, {"text": "PLAN", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.7953566908836365}, {"text": "INFERENCE THAT DISTINGUISHES", "start_pos": 16, "end_pos": 44, "type": "METRIC", "confidence": 0.7249714930852255}, {"text": "BETWEEN", "start_pos": 45, "end_pos": 52, "type": "METRIC", "confidence": 0.8034223318099976}, {"text": "BELIEFS", "start_pos": 57, "end_pos": 64, "type": "METRIC", "confidence": 0.712419331073761}, {"text": "ACTORS", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.5950215458869934}, {"text": "OBSERVERS", "start_pos": 79, "end_pos": 88, "type": "TASK", "confidence": 0.5919780731201172}]}], "abstractContent": [{"text": "Existing models of plan inference (PI) in conversation have assumed that the agent whose plan is being inferred (the actor) and the agent drawing the inference (the observer) have identical beliefs about actions in the domain.", "labels": [], "entities": [{"text": "plan inference (PI)", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.7505185961723327}]}, {"text": "I argue that this assumption often results in failure of both the PI process and the communicative process that PI is meant to support.", "labels": [], "entities": []}, {"text": "In particular , it precludes the principled generation of appropriate responses to queries that arise from invalid plans.", "labels": [], "entities": []}, {"text": "I describe a model of P1 that abandons this assumption.", "labels": [], "entities": []}, {"text": "It rests on an analysis of plans as mental phenomena.", "labels": [], "entities": []}, {"text": "Judgements that a plan is invalid are associated with particular discrepancies between the beliefs that the observer ascribes to the actor when the former believes that the latter has some plan, and the beliefs that the observer herself holds.", "labels": [], "entities": []}, {"text": "I show that the content of an appropriate response to a query is affected by the types of any such discrepancies of belief judged to be present in the plan inferred to underlie that query.", "labels": [], "entities": []}, {"text": "The PI model described here has been implemented in SPIRIT, a small demonstration system that answers questions about the domain of computer mail.", "labels": [], "entities": []}], "introductionContent": [{"text": "The importance of plan inference (PI) in models of conversation has been widely noted in the computational-linguistics literature.", "labels": [], "entities": []}, {"text": "Incorporating PI capabilities into systems that answer users' questions has enabled such systems to handle indirect speech acts, supply more information than is actually requested in a query, provide helpful information in response to a yes/no query answered in the negative, disambiguate requests, resolve certain forms of intersentential ellipsis, and handle such discourse phenomena as clarification subdialogues, and correction or \"debugging ~ subdialogues The research reported in this paper has been made possible in part by an IBM Graduate Fellowship, in part by a gift from the Systems Development Foundation, and in part by support from the Defense Advanced Research Projects Agency under Contract N00039-84-K.0078 with the Space and Naval Warfare Command.", "labels": [], "entities": []}, {"text": "The views and conclusions contained in this document are those of the author and should not be interpreted as representative of the official policies, either expressed or implied, of the Defense Advanced Research Projects Agency or the United States Government.", "labels": [], "entities": []}, {"text": "am grateful to Barbara Grosz, James Allen, Phil Cohen, Amy Lansky, Candy Sidner and Bonnie Webber for their comments on an earlier draft.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}