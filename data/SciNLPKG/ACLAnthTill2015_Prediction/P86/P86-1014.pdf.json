{"title": [{"text": "COPYING IN NATURAL LANGUAGES, CONTEXT-FREENESS, AND QUEUE GRAMMARS", "labels": [], "entities": [{"text": "COPYING", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9438411593437195}, {"text": "CONTEXT-FREENESS", "start_pos": 30, "end_pos": 46, "type": "METRIC", "confidence": 0.8809289336204529}, {"text": "QUEUE GRAMMARS", "start_pos": 52, "end_pos": 66, "type": "METRIC", "confidence": 0.7901759147644043}]}], "abstractContent": [{"text": "The documentation of (unbounded-len~h) copying and cross-serial constructions in a few languages in the recent literature is usually taken to mean that natural languages are slightly context-sensitive.", "labels": [], "entities": []}, {"text": "However, this ignores those copying constructions which, while productive, cannot be easily shown to apply to infinite sublanguages.", "labels": [], "entities": []}, {"text": "To allow such finite copying constructions to betaken into account informal modeling, it is necessary to recognize that natural languages cannot be realistically represented by formal languages of the usual sort.", "labels": [], "entities": []}, {"text": "Rather, they must be modeled as families of formal languages or as formal languages with indefinite vocabularies.", "labels": [], "entities": []}, {"text": "Once this is done, we see copying as a truly pervasive and fundamental process inhuman language.", "labels": [], "entities": [{"text": "copying", "start_pos": 26, "end_pos": 33, "type": "TASK", "confidence": 0.9834453463554382}]}, {"text": "Furthermore, the absence of mirror-image constructions inhuman languages means that it is not enough to extend Context-free Grammars in the direction of context-sensitivity.", "labels": [], "entities": []}, {"text": "Instead, a class of grammars must be found which handles (context-sensitive) copying but not (context-free) mirror images.", "labels": [], "entities": []}, {"text": "This suggests that human linguistic processes use queues rather than stacks, making imperative the development of a hierarchy of Queue Grammars as a counterweight to the Chomsky Grammars.", "labels": [], "entities": []}, {"text": "A simple class of Context-free Queue Grammars is introduced and discussed.", "labels": [], "entities": []}], "introductionContent": [{"text": "The claim that at least some human languages cannot be described by a Context-free Grammar no matter how large or complex has had an interesting career.", "labels": [], "entities": []}, {"text": "In the late 1960's it might have seemed, given the arguments of about respectively coordinations in English, about reduplication-cum-incorporation of object noun stems in about English comparative deletion, that this claim was firmly established.", "labels": [], "entities": []}, {"text": "Potentially serious--and at any rate embarrassing--problems with both the formal and the linguistic aspects of these arguments kept popping up, however, and the partial fixes provided by Brandt Corstius (as reported in for the respectively arguments and by for that as well as the Mohawk argument did not deter from claiming that \"it seems reasonable to assume that the natural languages area proper subset of the infinitecardinality CFL's, until such time as they are validly shown not to be\".", "labels": [], "entities": []}, {"text": "Two new arguments, one involving such that relativization and one about sluicing were dismissed on grounds of descriptive inadequacy by, who, however, suggested that the argument about the doubling relativization construction maybe correct (all these arguments deal with English).", "labels": [], "entities": []}, {"text": "Pullum (1984b) likewise heaped scorn on my argument that English reshmuplicative constructions show non-CFness, but he accepted (1984a; 1984b) argument about noun reduplication in one about Swiss German cross-serial constructions of causative and perception verbs and their objects.", "labels": [], "entities": [{"text": "noun reduplication", "start_pos": 158, "end_pos": 176, "type": "TASK", "confidence": 0.7523455917835236}]}, {"text": "also cite these two, as well as an argument by about verb phrase reduplication in Engenni.", "labels": [], "entities": [{"text": "Engenni", "start_pos": 82, "end_pos": 89, "type": "DATASET", "confidence": 0.9142677783966064}]}, {"text": "They also refer to my discovery of the X or no X ...", "labels": [], "entities": []}, {"text": "construction in English I and mention that \"Alexis ManasterRamer ...", "labels": [], "entities": [{"text": "Alexis ManasterRamer", "start_pos": 44, "end_pos": 64, "type": "DATASET", "confidence": 0.8963951170444489}]}, {"text": "in unpublished lectures finds reduplication constructions that appear to have no length bound in Polish, Turkish, and a number of other languages\".", "labels": [], "entities": []}, {"text": "While they do not refer to my 1983 reshmuplication argument, which they presumably still reject, the Turkish construction they allude to was cited in my 1983 paper and is similar to the English reshmuplication inform as well as function (see below).", "labels": [], "entities": []}, {"text": "In any case, the acceptance of even one case of nonCFness in one natural language by the only active advocates of the CF position would seem to suffice to remove the issue from the agenda.", "labels": [], "entities": []}, {"text": "Any additional arguments, such as Kac (to appear), Kac, Manaster-Ramer, and Rounds (to appear), and Manaster-Ramer (to appear a; to appear b) may appear to be no more than flogging of dead horses.", "labels": [], "entities": [{"text": "Rounds", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9707673192024231}]}, {"text": "However, as I argued in and as recent work (ManasterRamer, to appear a; Rounds, Manaster-Ramer, and Friedman, to appear) shows evermore clearly, this conception of the issue (viz., Is there one natural languages that is weakly noncontext-free?) makes very little difference and not much sense.", "labels": [], "entities": []}, {"text": "First of all, if non-CFness is so hard to find, then it is presumably linguistically marginal.", "labels": [], "entities": []}, {"text": "Second, weak generative arguments cannot be made to work for natural languages, because of their high degree of structural ambiguity and the great difficulty in excluding every conceivable interpretation on which an apparently ungrammatical string might turn out-on reflection--to be in the language.", "labels": [], "entities": []}, {"text": "Third, weak generative capacity is in any case not a very interesting property of a formal grammar, especially from a linguistic point of view, since linguistic models are judged by other criteria (e.g., natural languages might well be regular without this making CFGs any the more attractive as models for them).", "labels": [], "entities": [{"text": "generative capacity", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.8674992322921753}]}, {"text": "Fourth, results about the place of natural languages in the Chomsky Hierarchy seem to be should be considered in light of the fact that there is no reason to take the Chomsky Hierarchy as the appropriate formal space in which to look for them.", "labels": [], "entities": []}, {"text": "Fifth, models of natural languages that are actually in use in theoretical, computational, and descriptive linguistics are -and always have been--only remotely related to the Chomsky Grammars, which means that results about the latter maybe of little relevance to linguistic models.", "labels": [], "entities": []}, {"text": "As I argued in 1983, we should go beyond piecemeal debunking of invalid arguments against CFGs and by the same token it seems tome that we must go beyond piecemeal restatements of such arguments.", "labels": [], "entities": []}, {"text": "Rather, we should focus on general issues and ones that have implications for the modeling of human languages.", "labels": [], "entities": []}, {"text": "One such issue is, it seems tome, the kind of context-sensitivity found in natural languages.", "labels": [], "entities": []}, {"text": "It appears that the counterexamples to contextfreeness are all rather similar.", "labels": [], "entities": []}, {"text": "Specifically, they all seem to involve some kind of cross-serial dependency, i.e., a dependency between the nth elements of two or more substrings.", "labels": [], "entities": []}, {"text": "This--unlike the statement that natural languages are noncontext-free--might mean something if we knew what kinds of models were appropriate for cross-serial dependencies.", "labels": [], "entities": []}, {"text": "Given that not every kind of context-sensitive construction is found inhuman languages, it should be clear that there is nothing to be gained by invoking the dubious slogan of context-sensitivity.", "labels": [], "entities": []}, {"text": "Another relevant question is the centrality or peripherality of these constructions in natural languages.", "labels": [], "entities": []}, {"text": "The relevant literature makes it appear that they are somewhat marginal at best.", "labels": [], "entities": []}, {"text": "This would explain the tortured history of the attempts to show that they exist at all.", "labels": [], "entities": []}, {"text": "However, this appears to be wrong, at least when we consider copying constructions.", "labels": [], "entities": []}, {"text": "The requirement of full or near identity of two or more subparts of a sentence (or a discourse) is a very widespread phenomenon.", "labels": [], "entities": []}, {"text": "In this paper, I will focus on the copying constructions precisely because they are so common inhuman languages.", "labels": [], "entities": [{"text": "copying constructions", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.936869740486145}]}, {"text": "In addition to such questions, which appear to focus on the linguistic side of things, there are also the more mathematical and conceptual problems involved in the whole enterprise of modeling human languages informal terms.", "labels": [], "entities": []}, {"text": "My own belief is that both kinds of issues must be solved in tandem, since we cannot know what kind of formal models we want until we know what we are going to model, and we cannot know what human languages are or are not like until we know hot, to represent them and what to compare them to.", "labels": [], "entities": []}, {"text": "This paper is intended as a contribution to this kind of work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}