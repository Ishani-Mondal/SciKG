{"title": [], "abstractContent": [{"text": "This article presents a novel approach for readability assessment through sorting.", "labels": [], "entities": []}, {"text": "A comparator that judges the relative readability between two texts is generated through machine learning, and a given set of texts is sorted by this comparator.", "labels": [], "entities": []}, {"text": "Our proposal is advantageous because it solves the problem of alack of training data, because the construction of the comparator only requires training data annotated with two reading levels.", "labels": [], "entities": []}, {"text": "The proposed method is compared with regression methods and a state-of-the art classification method.", "labels": [], "entities": []}, {"text": "Moreover, we present our application, called Terrace, which retrieves texts with readability similar to that of a given input text.", "labels": [], "entities": []}], "introductionContent": [{"text": "Readability assessment is an important NLP issue with much application in the domain of language education.", "labels": [], "entities": [{"text": "Readability assessment", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8998247981071472}]}, {"text": "The capability to automatically judge the readability of a text would greatly help language teachers and learners, who currently spend a great deal of time skimming through texts looking fora text at an appropriate reading level.", "labels": [], "entities": []}, {"text": "Substantial previous work has been done over the past decades).", "labels": [], "entities": []}, {"text": "Early work generated measures based on simple text statistics by assuming that these reflect the text reading level.", "labels": [], "entities": []}, {"text": "For example, assumed that the lengths of words and sentences represent their respective difficulty.", "labels": [], "entities": []}, {"text": "used a manually constructed list of words assumed to capture the difficulty of vocabulary.", "labels": [], "entities": []}, {"text": "These measures are easy to use but difficult to apply to languages other than English, because some features, such as word length, are specific to alphabetic writing.", "labels": [], "entities": []}, {"text": "Such methods, however, do not compete with recent methods based on more sophisticated handling of language statistics.", "labels": [], "entities": []}, {"text": "Collins- proposed a classification model by constructing different language models for different school grades, and applied a support vector machine (SVM).", "labels": [], "entities": []}, {"text": "Both of these methods outperform classical methods and are less language-dependent.", "labels": [], "entities": []}, {"text": "These new methods, however, have a serious problem when implementation is attempted for multiple languages: the lack of training corpora.", "labels": [], "entities": []}, {"text": "Large amounts of training data annotated with 12 school grades have not been at all easy to obtain on a reasonable scale.", "labels": [], "entities": []}, {"text": "Another possibility might have been to manually construct such training data, Regarding the first type, many researchers have reported how various features affect the readability of text in terms of vocabulary, syntax, and discourse relations.", "labels": [], "entities": []}, {"text": "Recently, presented an impressive verification of the effects of each kind of feature and found that vocabulary and discourse relations are prominent, although other features are not negligible.", "labels": [], "entities": []}, {"text": "The focus of the current work, however, is not on what feature set to consider, so we use the same features throughout the article, as explained further in Section 3.1.", "labels": [], "entities": []}, {"text": "Rather, the focus of this article is on mapping the extracted feature values to a readability norm.", "labels": [], "entities": []}, {"text": "So far, two models have been used for this: regression and classification.", "labels": [], "entities": []}, {"text": "In regression, readability is given by a score based on a linearly weighted sum of feature values.", "labels": [], "entities": []}, {"text": "Early methods, from the Wannetka formula (, to the recent methods of and, are of this kind.", "labels": [], "entities": []}, {"text": "Elaboration of such regression methods in a more modern context could proceed through a generalized linear model based on estimation of the weights by machine learning, although we have not found such an approach within the literature of readability assessment for language learning.", "labels": [], "entities": []}, {"text": "Our proposal is compared with such an enhanced version of regression in Section 8.", "labels": [], "entities": []}, {"text": "In classification, readability is segmented by academic grades, and the assessment is conducted as a classification task.", "labels": [], "entities": [{"text": "classification", "start_pos": 3, "end_pos": 17, "type": "TASK", "confidence": 0.9700247049331665}]}, {"text": "The first is implemented by means of statistical classification modeling, as reported in Collins- and.", "labels": [], "entities": [{"text": "statistical classification modeling", "start_pos": 37, "end_pos": 72, "type": "TASK", "confidence": 0.8585275808970133}, {"text": "Collins- and", "start_pos": 89, "end_pos": 101, "type": "DATASET", "confidence": 0.9260121385256449}]}, {"text": "The authors used a language model (unigrams) and a naive Bayes classifier by presuming different language models for each reading level.", "labels": [], "entities": []}, {"text": "A language model M i is constructed for each level of readability i by using different corpora for each level.", "labels": [], "entities": []}, {"text": "The readability of a given text T is assessed using the formula L(M i |T) = \u03a3 w\u2208T C(w) log Pr(w|M i ), where w denotes a word in text T, C(w) denotes the frequency of w, and Pr(w|M i ) denotes the probability of w under M i . The second is based on an SVM ( and the authors also studied the effect of statistical features, such as n-grams and syntactic features.", "labels": [], "entities": []}, {"text": "In these papers, the readability norms are represented by means of scores and classes of readability.", "labels": [], "entities": []}, {"text": "That is, given a single text, the system assigns a value corresponding to a school grade.", "labels": [], "entities": []}, {"text": "The result is easy to understand, and various applications have been constructed with this type of scoring.", "labels": [], "entities": []}, {"text": "This solution only works, however, when a sufficient amount of training data with annotations regarding multiple levels is provided.", "labels": [], "entities": []}, {"text": "Usually, the availability of training data in readability assessment is limited, even for school grading.", "labels": [], "entities": []}, {"text": "This is due to the inherent difficulty of classifying the readability of a text into 12 grades, making it difficult to uniformly construct a large set of training data.", "labels": [], "entities": []}, {"text": "Moreover, the copyright issue is more serious for academic texts.", "labels": [], "entities": []}, {"text": "1 Given this situation, when readability assessment is modeled by regression or classification, a research team wanting to apply these previous methods faces the problem of assembling training data, as we did for over a year.", "labels": [], "entities": [{"text": "readability assessment", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.8771417737007141}]}, {"text": "In this article, the readability norm is designed in a completely different way: Given two texts, a comparator judges which is more difficult.", "labels": [], "entities": []}, {"text": "By applying this comparator, a set of texts is sorted.", "labels": [], "entities": []}, {"text": "The readability of a text is assessed by searching for its position within the sorted texts.", "labels": [], "entities": []}, {"text": "The norm is thus considered as the location of a text among an ordered set of texts.", "labels": [], "entities": []}, {"text": "Our approach linguistically enhances assessment of the readability of a text as the relative ease compared to other texts, not as the absolute difficulty of the text.", "labels": [], "entities": []}, {"text": "The root of this idea has been presented in two articles of which we are aware.", "labels": [], "entities": []}, {"text": "In Inui and, the readability of sentences for deaf people is judged by a comparator generated by an SVM.", "labels": [], "entities": []}, {"text": "In addition, presented a comparison of texts in terms of difficulty by using an SVM.", "labels": [], "entities": []}, {"text": "Similarly to what we present in Section 3.1, those authors propose constructing a comparator by using an SVM to compare two sentences or texts with multiple features.", "labels": [], "entities": []}, {"text": "However, neither further applied this approach to obtain readability assessment based on sorting.", "labels": [], "entities": []}, {"text": "Our contribution in this study is therefore that we show how a machine learning method can be used as a comparator and applied to sort texts.", "labels": [], "entities": [{"text": "sort texts", "start_pos": 130, "end_pos": 140, "type": "TASK", "confidence": 0.8983020484447479}]}, {"text": "Our method can be situated more generally among machine learning methods for ranking, where the methods learn so that they rank a set of elements given a set of ordered training data.", "labels": [], "entities": []}, {"text": "Various methods have been proposed so far.", "labels": [], "entities": []}, {"text": "In one of the earliest attempts, obtain a function that scores the probability that an element is ranked higher than another, and rank all elements by maximizing the sum of the pairwise probabilities.", "labels": [], "entities": []}, {"text": "In another, applies an SVM to rank elements, by devising the input vector by subtraction of feature values.", "labels": [], "entities": []}, {"text": "In more recent studies, such as, an attempt is made to directly obtain the ranking function for the whole ordered training data, not as a composition of pairwise function application between elements.", "labels": [], "entities": []}, {"text": "Among these methods, our proposal is unique in two ways.", "labels": [], "entities": []}, {"text": "First, none of the previous methods, as far as we know, proposed discretized ranking based on sorting.", "labels": [], "entities": []}, {"text": "Second and most importantly, all previous methods assume the existence of fully ordered training data.", "labels": [], "entities": []}, {"text": "In contrast, as emphasized by our problem described in this section, such training data are difficult to acquire in the readability domain, and we have to devise a method which works even when very limited training data are all that is available.", "labels": [], "entities": []}, {"text": "Our contribution lies in our study of the possibility of using a learning-to-rank method even when learning data are only partially available.", "labels": [], "entities": []}, {"text": "Such an approach can be further considered for learning-to-rank methods in general in future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the rest of this article, the proposed method and the Terrace system are evaluated.", "labels": [], "entities": []}, {"text": "The key question to be considered through the evaluation is whether the comparator can discern slight differences in the readability levels of test data from only two sets of training data that are roughly different.", "labels": [], "entities": []}, {"text": "The proposed method was tested for English and Japanese.", "labels": [], "entities": []}, {"text": "The data is summarized in, where the upper block corresponds to English and the lower to Japanese.", "labels": [], "entities": []}, {"text": "For both languages, there were training data and test data.", "labels": [], "entities": []}, {"text": "The test data consisted of two sorts: TD1: A collection of texts taken from the same kind of data as the training data.", "labels": [], "entities": []}, {"text": "TD2: A collection of texts unrelated to the training data and originally assigned levels or a linear ordering.", "labels": [], "entities": []}, {"text": "These levels and ordering were used as the correct ordering in our work.", "labels": [], "entities": []}, {"text": "TD2 further consisted of two kinds of data in each language: data for learners of their mother tongue (i.e., children and students) and data for learners of a foreign language.", "labels": [], "entities": [{"text": "TD2", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8705893158912659}]}, {"text": "These are labeled as TD2-M and TD2-F, respectively.", "labels": [], "entities": []}, {"text": "For English, the training data were taken from Time (Time 2008) and Time For Kids (TimeForKids 2008).", "labels": [], "entities": [{"text": "Time (Time 2008)", "start_pos": 47, "end_pos": 63, "type": "DATASET", "confidence": 0.8896956086158753}, {"text": "Time For Kids (TimeForKids 2008)", "start_pos": 68, "end_pos": 100, "type": "DATASET", "confidence": 0.7109743910176414}]}, {"text": "We downloaded 600 articles (that is, |L d | = |L e | = 600), of which 100 were used as TD1-E.", "labels": [], "entities": [{"text": "TD1-E", "start_pos": 87, "end_pos": 92, "type": "DATASET", "confidence": 0.9133062362670898}]}, {"text": "The total number of different words in TD1-E is 22,736, which is the dimension of the feature vector of a text when TD2 is used as the text data.", "labels": [], "entities": []}, {"text": "When using subtraction as \u2022, the dimension is doubled (for local and global), and when using concatenation, the dimension is four times this value.", "labels": [], "entities": []}, {"text": "TD2-M-E consisted of the data set called AtoZ, which can be purchased.", "labels": [], "entities": [{"text": "TD2-M-E", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8828667402267456}]}, {"text": "Each of the texts in this data set is labeled by 27 levels and graded by 5 levels.", "labels": [], "entities": []}, {"text": "TD2-F-E consisted of the English textbooks used in Japanese junior high and high schools).", "labels": [], "entities": [{"text": "TD2-F-E", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8604952096939087}]}, {"text": "These texts are classified into five grades and also linearly ordered; that is, the texts become more difficult in their order of appearance in the textbooks.", "labels": [], "entities": []}, {"text": "These levels and orders originally attached to the data were used as the gold standard in this study.", "labels": [], "entities": []}, {"text": "For the global frequency, we used the log frequency of each word as measured from almost 6 terabytes of Web data in English, scanned in the autumn of 2006 (Tanaka-Ishii and Terada 2009).", "labels": [], "entities": []}, {"text": "For Japanese, the training data and TD1-J were taken from Asahi newspapers.", "labels": [], "entities": [{"text": "TD1-J", "start_pos": 36, "end_pos": 41, "type": "DATASET", "confidence": 0.8158221244812012}, {"text": "Asahi newspapers", "start_pos": 58, "end_pos": 74, "type": "DATASET", "confidence": 0.9855686724185944}]}, {"text": "Six hundred (600) articles were acquired, and 100 of these were used as TD1-J.", "labels": [], "entities": [{"text": "TD1-J", "start_pos": 72, "end_pos": 77, "type": "DATASET", "confidence": 0.9282604455947876}]}, {"text": "The total number of different words in this training data is 48,762.", "labels": [], "entities": []}, {"text": "4 TD2-M-J consisted of Japanese junior high and high school textbooks with six grades, which also appeared in a linear order).", "labels": [], "entities": [{"text": "4 TD2-M-J consisted of Japanese junior high and high school textbooks", "start_pos": 0, "end_pos": 69, "type": "DATASET", "confidence": 0.7667248276146975}]}, {"text": "TD2-F-J consisted of the texts used in the Japanese language proficiency test).", "labels": [], "entities": []}, {"text": "The texts in this data set are classified into four levels and not linearly ordered.", "labels": [], "entities": []}, {"text": "For the global frequency, we used the log frequency of each word as measured from almost 2 terabytes of Web data in Japanese, scanned in the autumn of 2006.", "labels": [], "entities": []}, {"text": "The other evaluation settings were as follows.", "labels": [], "entities": []}, {"text": "As the SVM), we used LIBSVM (Chang and Lin 2001).", "labels": [], "entities": [{"text": "LIBSVM", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.7662048935890198}]}, {"text": "The SVM training was done using the parameters of cost = 0.1 and gamma = 0.00001 with a Gaussian kernel.", "labels": [], "entities": [{"text": "SVM", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9277485013008118}, {"text": "gamma", "start_pos": 65, "end_pos": 70, "type": "METRIC", "confidence": 0.9716417789459229}]}, {"text": "The value of K used in robust sorting (Section 3.2) was K = 2.", "labels": [], "entities": [{"text": "robust sorting", "start_pos": 23, "end_pos": 37, "type": "TASK", "confidence": 0.6969067603349686}]}, {"text": "The basic performance was first tested using TD1.", "labels": [], "entities": []}, {"text": "Because |L d | = |L e | = 600, 500 texts were chosen and paired randomly, and 2 \u00d7 500 = 1,000 pairs were used for training.", "labels": [], "entities": []}, {"text": "The factor of 2 is necessary, because a pair can be used twice by exchanging the comparison order V ed and V de . The remaining 100 texts were randomly paired and tested.", "labels": [], "entities": []}, {"text": "The results presented here were produced through six-fold cross-validation, and each fold was further repeated five times by changing the pairing of training and testing (i.e., total execution was done 30 times to obtain one performance value).", "labels": [], "entities": []}, {"text": "shows the accuracy for English (upper block) and Japanese (lower block).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9997617602348328}]}, {"text": "The rows of a block represent the different operators explained in Section 3.1.", "labels": [], "entities": []}, {"text": "Overall, the scores were above 90%.", "labels": [], "entities": []}, {"text": "The comparator performance for TD2 was also investigated.", "labels": [], "entities": []}, {"text": "Here, the training data amount was set to 2 \u00d7 600.", "labels": [], "entities": []}, {"text": "The accuracy was measured for all pairs of texts with different levels.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995633959770203}]}, {"text": "For TD2-M-E, all five levels were considered, whereas for the linearly ordered TD2-F-E and TD2-M-J, the levels were considered by grade (that is, five levels for TD2-F-E and six levels for TD2-M-J).", "labels": [], "entities": []}, {"text": "The accuracy reported here is the average of execution done five times by changing the random pairing for the training data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995014667510986}]}, {"text": "The performance was, in general, lower than that for TD1, but still stayed close to 90%.", "labels": [], "entities": [{"text": "TD1", "start_pos": 53, "end_pos": 56, "type": "DATASET", "confidence": 0.7896251678466797}]}, {"text": "For the operator \u2022, whether concatenation or subtraction was used made no difference.", "labels": [], "entities": []}, {"text": "Therefore, from hereon, the operator \u2022 is set to concatenation.", "labels": [], "entities": []}, {"text": "To evaluate the classification performance in more detail, the accuracy for every two-class combination was determined for TD2-M-E in English, as shown in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9996999502182007}]}, {"text": "Because TD2-M-E has five grades, the columns indicate the 1st to 4th grades, whereas the rows indicate the 2nd to 5th grades.", "labels": [], "entities": [{"text": "TD2-M-E", "start_pos": 8, "end_pos": 15, "type": "DATASET", "confidence": 0.897088885307312}]}, {"text": "The evaluation thus forms a 4 \u00d7 4 table, where each cell indicates the accuracy of distinguishing the two-class pairs for the row and column.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9994366765022278}]}, {"text": "The closer to the diagonal, the more difficult the classification task was, because the levels to be distinguished became closer to each other.", "labels": [], "entities": [{"text": "classification", "start_pos": 51, "end_pos": 65, "type": "TASK", "confidence": 0.9780030846595764}]}, {"text": "The results reflect this tendency, with lower values for cells closer to the diagonal.", "labels": [], "entities": []}, {"text": "In particular, the performance for discerning grades between pairs of the 4th and 5th grades was poor.", "labels": [], "entities": []}, {"text": "Distinction between the 1st/2nd and 2nd/3rd grades was more successful than that between the 3rd/4th and 4th/5th grades, since the lower the grades the easier it is to discern two given successive school levels.", "labels": [], "entities": [{"text": "Distinction", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9383585453033447}]}, {"text": "Before going onto actually sort text using the comparator, we verified how abnormal our generated comparator was.", "labels": [], "entities": []}, {"text": "Ideally, we want a complete ordering of the set, and for this the comparator must obey certain laws in the sense of mathematical sets.", "labels": [], "entities": []}, {"text": "A comparator is considered abnormal if it does not obey two laws: Reversibility: Texts a, bare defined as reversible if b < a and a > b both hold.", "labels": [], "entities": [{"text": "Reversibility", "start_pos": 66, "end_pos": 79, "type": "METRIC", "confidence": 0.9667191505432129}]}, {"text": "This corresponds to the law that when V ab 's value is +1, then V ba 's value must be -1 and vice versa.", "labels": [], "entities": []}, {"text": "Transitivity: If a < band b < c, then a < c.", "labels": [], "entities": []}, {"text": "Especially for transitivity, in an ordered set this law is the primary requirement that must be fulfilled among ordered elements.", "labels": [], "entities": []}, {"text": "If transitivity does not hold in many triples, we have to introduce partial ordering instead of the total ordering considered thus far.", "labels": [], "entities": []}, {"text": "The anomalies were measured by using the four TD2 data sets.", "labels": [], "entities": [{"text": "TD2 data sets", "start_pos": 46, "end_pos": 59, "type": "DATASET", "confidence": 0.9454838434855143}]}, {"text": "For all pairs and triples of TD2, we tested the reversibility and transitivity for all possible pairs and triples by changing the random pairing of test data (TD1) five times.", "labels": [], "entities": [{"text": "reversibility", "start_pos": 48, "end_pos": 61, "type": "METRIC", "confidence": 0.9626369476318359}]}, {"text": "For reversibility, r 10 pairs out of 226,801 for TD2-M-E were non-reversible once, r 1 pair out of 11,628 for TD2-F-E was non-reversible once, and r all pairs for all other data and random pairings of training data were reversible.", "labels": [], "entities": []}, {"text": "Such strong results were obtained because the training was done by reversing the order of the pairs (thus, the SVM learned both V ed as +1 and V de as -1.)", "labels": [], "entities": []}, {"text": "Similarly, for transitivity, r one triple out of 50,803,424 of TD2-M-E was non-transitive once, and r all triples for all other data and random pairings of training data were transitive.", "labels": [], "entities": [{"text": "transitivity", "start_pos": 15, "end_pos": 27, "type": "TASK", "confidence": 0.9566624164581299}]}, {"text": "Such results show how rarely these anomalies occur in our method.", "labels": [], "entities": []}, {"text": "Therefore, our choice of total ordering seems relevant.", "labels": [], "entities": []}, {"text": "Since the basic results have been clarified thus far, we will now report the results for concatenation fora more global evaluation of sorting and searching.", "labels": [], "entities": []}, {"text": "The TD2 data were sorted by the method explained in Section 3.2, and the correlation with the correct order was investigated.", "labels": [], "entities": [{"text": "TD2 data", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.9090530574321747}]}, {"text": "Three methods were used for comparison: r Flesch-Kincaid r Dale-Chall r Support vector regression (SVR) In these three methods, the readability level is obtained as a value, whereas our method presents an order.", "labels": [], "entities": []}, {"text": "Therefore, the results of the three methods were sorted according to the values.", "labels": [], "entities": []}, {"text": "The resulting orders for the three methods and for ours were then compared with the correct order in the test data.", "labels": [], "entities": []}, {"text": "We used the finest annotation for correct ordering; for example, 27 levels for TD2-M-E, linear ordering for TD2-F-E, linear ordering for TD2-M-J, and 4 levels for TD2-F-J.", "labels": [], "entities": []}, {"text": "Here, SVR was trained by labeling the Time/Asahi newspaper texts as +1.0 and the texts of Time/Asahi for children as -1.0, and then using the 600 texts for training.", "labels": [], "entities": [{"text": "SVR", "start_pos": 6, "end_pos": 9, "type": "METRIC", "confidence": 0.5236604809761047}, {"text": "Time/Asahi newspaper texts", "start_pos": 38, "end_pos": 64, "type": "DATASET", "confidence": 0.9466029286384583}, {"text": "Time/Asahi", "start_pos": 90, "end_pos": 100, "type": "DATASET", "confidence": 0.9226554830869039}]}, {"text": "The LIBSVM package was used with the same kernel and parameter settings given in Section 6.", "labels": [], "entities": []}, {"text": "We used Spearman's correlation to evaluate the ordering.", "labels": [], "entities": []}, {"text": "Spearman's basic correlation formula is where n is the number of texts, and d i is the difference in ranking between the correct and obtained results for text i.", "labels": [], "entities": []}, {"text": "This formula has an extended version to cope with multiple elements having the same ranking.", "labels": [], "entities": []}, {"text": "Given x and y as ordered sequences with the same ranking, the correlation is given as follows: where Here, n x and n y are the numbers of the rankings for equivalently ranked elements in x and y, respectively, and ti , t j denote the number of elements with the same ranking as elements which are indexed as i, j, respectively.", "labels": [], "entities": [{"text": "correlation", "start_pos": 62, "end_pos": 73, "type": "METRIC", "confidence": 0.957481324672699}]}, {"text": "For example, given an order x = [1,2,3,3,4], n x = 1, because only 3 had the same ranking, ti = 2 for i = 1, because there are two 3s.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "The horizontal axis represents the four data sets of TD2, and the vertical axis represents the correlation value.", "labels": [], "entities": [{"text": "correlation", "start_pos": 95, "end_pos": 106, "type": "METRIC", "confidence": 0.9772512912750244}]}, {"text": "Note that for the Japanese   The search performance using the algorithm presented in Section 3.2 was evaluated via the average positional error when a text is searched.", "labels": [], "entities": []}, {"text": "The search performance of our method was compared with that of the three methods presented at the beginning of Section 8.", "labels": [], "entities": []}, {"text": "Because the sorting performance already differed among the methods, we evaluated the performance on correctly sorted texts.", "labels": [], "entities": []}, {"text": "One text was removed from the correctly sorted texts, its position was searched for with each method, and the difference between the resulting and correct positions was measured.", "labels": [], "entities": []}, {"text": "This procedure was repeated for all texts of TD2, and the average difference was obtained.", "labels": [], "entities": []}, {"text": "The finest levels for TD2 were used as the correct annotation.", "labels": [], "entities": []}, {"text": "The execution was again performed five times by changing the random pairing within the training data.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "The horizontal axis represents blocks of TD2 data, and the vertical axis represents the average locational error of searching divided by the total number of levels of each data.", "labels": [], "entities": []}, {"text": "Unlike the correlation figures seen so far, the smaller the value of each result, the better the precision of the search results.", "labels": [], "entities": [{"text": "precision", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9994215965270996}]}, {"text": "As was the casein, the heights of bars are comparable within a data block, whereas bars across blocks are not comparable because of the different numbers of levels.", "labels": [], "entities": []}, {"text": "Naturally, the results are reversed from those of.", "labels": [], "entities": []}, {"text": "Methods with higher performance in sorting had smaller errors.", "labels": [], "entities": [{"text": "sorting", "start_pos": 35, "end_pos": 42, "type": "TASK", "confidence": 0.9687859416007996}]}, {"text": "Overall, our method had the smallest errors among all methods.", "labels": [], "entities": []}, {"text": "Because Terrace is different from previous systems based on the absolute scores of Flesch-Kincaid or Dale-Chall, it was presented to several language teachers who originated the Terrace project (as mentioned in Section 5).", "labels": [], "entities": []}, {"text": "They reacted positively to Terrace, even though the system does not show any absolute readability scores.", "labels": [], "entities": []}, {"text": "There are two main reasons for the favorable response.", "labels": [], "entities": []}, {"text": "First, as mentioned, because they need texts rather than scores, teachers liked the fact that Terrace returns texts directly without outputting the values.", "labels": [], "entities": []}, {"text": "With previous systems, teachers themselves had to input one candidate text after another to find one of an appropriate level.", "labels": [], "entities": []}, {"text": "Second, for foreign language teachers, especially of languages other than English, scores are not well standardized, and teachers are often puzzled by some readability scores.", "labels": [], "entities": []}, {"text": "The teaching levels do not necessarily correspond to standard school grades for natives.", "labels": [], "entities": []}, {"text": "Therefore, they prefer that a system outputs texts directly as in Terrace, because this means they do not have to interpret some score which is difficult to assess.", "labels": [], "entities": []}, {"text": "Nevertheless, they found that the graphical indicators are helpful for locating themselves among numerous collections.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2  Training and test data.", "labels": [], "entities": []}, {"text": " Table 5  Classification results between two classes, tested for TD2-M-E in English.", "labels": [], "entities": []}]}