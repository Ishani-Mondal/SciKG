{"title": [{"text": "Commentary and Discussion A Response to Richard Sproat on Random Systems, Writing, and Entropy", "labels": [], "entities": []}], "abstractContent": [{"text": "In his article \"Ancient symbols and computational linguistics\" (Sproat 2010), Professor Sproat raised two concerns over a method that we have proposed for analyzing small data sets of symbols using entropy (Lee, Jonathan, and Ziman 2010): first, that the method is unable to detect random but non-equiprobable systems; and second, that it misclassifies kudurru texts.", "labels": [], "entities": []}, {"text": "We address these concerns in the following response.", "labels": [], "entities": []}, {"text": "1. Random Systems Random systems can contain unigrams drawn from an equiprobable or from a non-equiprobable distribution.", "labels": [], "entities": []}, {"text": "For small data sets, random but equiprobable systems are likely to have a non-equiprobable actual frequency of unigram occurrence due to the sample size.", "labels": [], "entities": []}, {"text": "A method for determining whether a data set is unlikely to be random but equiprobable was given in Lee, Jonathan, and Ziman (2010).", "labels": [], "entities": []}, {"text": "For a given script set, first order entropy (E 1) summarizes the frequencies at which unigrams occur.", "labels": [], "entities": [{"text": "first order entropy (E 1)", "start_pos": 24, "end_pos": 49, "type": "METRIC", "confidence": 0.7939966320991516}]}, {"text": "E 1 is maximized when all unigrams occur with equal probability.", "labels": [], "entities": [{"text": "E 1", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.8797197639942169}]}, {"text": "In written language, unigrams occur with unequal probabilities-for example, the letters e and t occur more frequently in English than the letters x and z, thereby lending some degree of predictability to the occurrence of a particular unigram, and reducing the value of E 1.", "labels": [], "entities": []}, {"text": "Random script sets drawn from a non-equiprobable distribution could have the same actual frequencies of unigram occurrence as a written language script set.", "labels": [], "entities": []}, {"text": "However, whereas there is unigram-to-unigram dependence in a language, there is no such dependency in a random system.", "labels": [], "entities": []}, {"text": "For example, q tends to be followed by u in English.", "labels": [], "entities": []}, {"text": "The digram qu would therefore occur more often than other digrams starting with q.", "labels": [], "entities": []}, {"text": "This second-order dependency is captured in the second-order entropy, E 2.", "labels": [], "entities": []}, {"text": "Thus it is one of the fundamental outcomes of Shannon's theory that the dependency in", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}