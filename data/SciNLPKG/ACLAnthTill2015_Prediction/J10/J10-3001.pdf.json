{"title": [{"text": "Squibs Does GIZA++ Make Search Errors?", "labels": [], "entities": []}], "abstractContent": [{"text": "Word alignment is a critical procedure within statistical machine translation (SMT).", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.726750373840332}, {"text": "statistical machine translation (SMT)", "start_pos": 46, "end_pos": 83, "type": "TASK", "confidence": 0.7954151183366776}]}, {"text": "(1993) have provided the most popular word alignment algorithm to date, one that has been implemented in the GIZA (Al-Onaizan et al.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.7916451990604401}, {"text": "GIZA", "start_pos": 109, "end_pos": 113, "type": "DATASET", "confidence": 0.8315798044204712}]}, {"text": "1999) and GIZA++ (Och and Ney 2003) software and adopted by nearly every SMT project.", "labels": [], "entities": [{"text": "GIZA++ (Och and Ney 2003)", "start_pos": 10, "end_pos": 35, "type": "DATASET", "confidence": 0.7577199637889862}, {"text": "SMT", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.9816758632659912}]}, {"text": "In this article, we investigate whether this algorithm makes search errors when it computes Viterbi alignments, that is, whether it returns alignments that are sub-optimal according to a trained model.", "labels": [], "entities": []}, {"text": "1. Background Word alignment is the problem of annotating a bilingual text with links connecting words that have the same meanings.", "labels": [], "entities": [{"text": "Background Word alignment", "start_pos": 3, "end_pos": 28, "type": "TASK", "confidence": 0.625252902507782}]}, {"text": "(1993) align an English/French sentence pair by positing a probabilistic model by which an English sentence is translated into French.", "labels": [], "entities": []}, {"text": "1 The model provides a set of non-deterministic choices.", "labels": [], "entities": []}, {"text": "When a particular sequence of choices is applied to an English input sentence e 1 ...e l , the result is a particular French output sentence f 1 ...f m.", "labels": [], "entities": []}, {"text": "In the Brown et al. models, a decision sequence also implies a specific word alignment vector a 1 ...a m.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 72, "end_pos": 86, "type": "TASK", "confidence": 0.666673481464386}]}, {"text": "We say a j = i when French word f j was produced by English word e i during the translation.", "labels": [], "entities": []}, {"text": "Here is a sample sentence pair (e, f) and word alignment a: e: NULL 0 Mary 1 did 2 not 3 slap 4 the 5 green 6 witch 7 f : Mary 1 no 2 d\u00ed o 3 una 4 bofetada 5 a 6 la 7 bruja 8 verde 9 a: [ 1 3 4 5 5 0 5 7 6 ] Notice that the English sentence contains a special NULL word (e 0) that generates \"spurious\" target words (in this case, a 6).", "labels": [], "entities": []}, {"text": "(1993) models are many-to-one, meaning that each English word can produce several French children, but each", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "For Chinese/English experiments, we run GIZA++ training on 101,880 sentence pairs.", "labels": [], "entities": []}, {"text": "We evaluate Viterbi alignments on a smaller test set of 1,880 sentence pairs with manual alignments.", "labels": [], "entities": []}, {"text": "For Arabic/English, we train on 300,000 sentence pairs and test on 2,000.", "labels": [], "entities": []}, {"text": "In tests, we compare GIZA++ Viterbi alignments (based on greedy hill-climbing) with optimal ILP alignments.", "labels": [], "entities": [{"text": "GIZA++ Viterbi", "start_pos": 21, "end_pos": 35, "type": "DATASET", "confidence": 0.6249757210413615}]}, {"text": "We use CPLEX to solve our ILP problems.", "labels": [], "entities": [{"text": "CPLEX", "start_pos": 7, "end_pos": 12, "type": "DATASET", "confidence": 0.8141184449195862}]}, {"text": "Illustration of ILP-based optimal alignment of a single sentence pair.", "labels": [], "entities": [{"text": "ILP-based optimal alignment", "start_pos": 16, "end_pos": 43, "type": "TASK", "confidence": 0.6156950195630392}]}, {"text": "Already-trained log probabilities are shown at the top of the In the middle is a schematic of variables introduced for the English/Spanish sentence pair seatbelts / los cinturones de seguridad.", "labels": [], "entities": []}, {"text": "At the bottom is the ILP formulation and its solution.", "labels": [], "entities": []}, {"text": "compares the results from GIZA++ alignment with optimal ILP alignment for different language pairs and alignment directions, and for unions of uni-directional alignments.", "labels": [], "entities": []}, {"text": "We measure the rate at which GIZA++ makes search errors, and we compute alignment F-scores for the various testing conditions.", "labels": [], "entities": [{"text": "alignment F-scores", "start_pos": 72, "end_pos": 90, "type": "METRIC", "confidence": 0.8495652079582214}]}, {"text": "We conclude that although GIZA++ makes search errors on 5-15% of sentence pairs, these errors do not contribute to an overall loss in alignment task accuracy, as measured by F-score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 149, "end_pos": 157, "type": "METRIC", "confidence": 0.9582861661911011}, {"text": "F-score", "start_pos": 174, "end_pos": 181, "type": "METRIC", "confidence": 0.9917574524879456}]}, {"text": "Focusing on sentence pairs where GIZA++ makes a search error, we plot the average difference in log model scores between GIZA++ and ILP Viterbi alignments in.", "labels": [], "entities": []}, {"text": "We notice a positive correlation between sentence length and the search error Average difference in log model scores between GIZA++ and ILP alignments at different English sentence lengths for English/Chinese alignment.", "labels": [], "entities": []}, {"text": "Points in the plot that appear to be on the x-axis actually lie just above it. gap between GIZA++ and ILP scores.", "labels": [], "entities": [{"text": "GIZA", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.9769240021705627}]}, {"text": "As we move to longer sentences, the alignment procedure becomes harder and GIZA++ makes more errors.", "labels": [], "entities": []}, {"text": "Finally, plots the time taken for ILP alignment at different sentence lengths showing a positive correlation as well.", "labels": [], "entities": [{"text": "ILP alignment", "start_pos": 34, "end_pos": 47, "type": "TASK", "confidence": 0.9318515956401825}]}], "tableCaptions": []}