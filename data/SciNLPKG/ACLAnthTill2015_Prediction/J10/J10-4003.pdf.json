{"title": [{"text": "Squibs An Asymptotic Model for the English Hapax/Vocabulary Ratio", "labels": [], "entities": [{"text": "English Hapax/Vocabulary Ratio", "start_pos": 35, "end_pos": 65, "type": "DATASET", "confidence": 0.8873461723327637}]}], "abstractContent": [{"text": "In the known literature, hapax legomena in an English text or a collection of texts roughly account for about 50% of the vocabulary.", "labels": [], "entities": []}, {"text": "This sort of constancy is baffling.", "labels": [], "entities": []}, {"text": "The 100-million-word British National Corpus was used to study this phenomenon.", "labels": [], "entities": [{"text": "British National Corpus", "start_pos": 21, "end_pos": 44, "type": "DATASET", "confidence": 0.942392627398173}]}, {"text": "The result reveals that the hapax/vocabulary ratio follows a U-shaped pattern.", "labels": [], "entities": []}, {"text": "Initially, as the size of text increases, the hapax/vocabulary ratio decreases; however, after the text size reaches about 3,000,000 words, the hapax/vocabulary ratio starts to increase steadily.", "labels": [], "entities": []}, {"text": "A computer simulation shows that as the text size continues to increase, the hapax/vocabulary ratio would approach 1.", "labels": [], "entities": [{"text": "hapax/vocabulary ratio", "start_pos": 77, "end_pos": 99, "type": "METRIC", "confidence": 0.6032182350754738}]}], "introductionContent": [{"text": "Words in English texts have a very peculiar distribution.", "labels": [], "entities": []}, {"text": "On the one hand, between 50-100 top frequency words typically account for about 50% of the words in any text); on the other, generally, about half of the words of the vocabulary of a text occur only once in the text).", "labels": [], "entities": []}, {"text": "These lexical singletons are referred to as hapax legomenon (plural form: hapax legomena), hapax for short.", "labels": [], "entities": []}, {"text": "Hapaxes play a very important role in language studies.", "labels": [], "entities": [{"text": "language studies", "start_pos": 38, "end_pos": 54, "type": "TASK", "confidence": 0.7146416455507278}]}, {"text": "For example, the ratio between the number of hapaxes and vocabulary size (hereinafter referred to as HVR) is widely used in studies such as vocabulary growth, vocabulary richness and author identification, language typology (, the degree of analytism, and soon.", "labels": [], "entities": [{"text": "HVR", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.9748367667198181}, {"text": "vocabulary growth", "start_pos": 140, "end_pos": 157, "type": "TASK", "confidence": 0.7143020033836365}, {"text": "author identification", "start_pos": 183, "end_pos": 204, "type": "TASK", "confidence": 0.7734851241111755}]}, {"text": "The high percentage of the top 50-100 words within a text is understandable, as only two of them, the and a(n) would account for over 5% of the total word tokens of a text.", "labels": [], "entities": []}, {"text": "However, the seemingly constant and high HVR of a text or collection of texts is baffling.", "labels": [], "entities": [{"text": "HVR", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.9960407018661499}]}, {"text": "Intuitively, as the length of a text or collection of texts increases, the HVR would decrease; as text length approaches infinity, all the words in the language would have occurred, and the number of hapaxes would approach zero.", "labels": [], "entities": [{"text": "HVR", "start_pos": 75, "end_pos": 78, "type": "METRIC", "confidence": 0.7058292627334595}]}, {"text": "But the known facts so far do not seem to corroborate this intuition.", "labels": [], "entities": []}, {"text": "For example, in Lewis Carroll's 26,505-word Alice's Adventures in Wonderland, 44% of the vocabulary are hapaxes; in Mark Twain's 71,370-word The Adventures of Tom Sawyer, the percentage is 49.8% (; in the 43-million-word Merc Corpus, this percentage is 56.6%.", "labels": [], "entities": [{"text": "Lewis Carroll's 26,505-word Alice's Adventures in Wonderland", "start_pos": 16, "end_pos": 76, "type": "TASK", "confidence": 0.7147429221206241}, {"text": "Merc Corpus", "start_pos": 221, "end_pos": 232, "type": "DATASET", "confidence": 0.9801534414291382}]}, {"text": "There seems to be no explanation for this strange behavior of hapax legomena in the literature.", "labels": [], "entities": []}, {"text": "The high HVR even in a mega-corpus poses problems for natural language processing; it would suggest at least sparseness of lexical, semantic, syntactic, discoursal, and pragmatic information on roughly half of the vocabulary.", "labels": [], "entities": [{"text": "HVR", "start_pos": 9, "end_pos": 12, "type": "METRIC", "confidence": 0.9471086859703064}]}, {"text": "The following questions ensue: What are the factors behind this enigmatic distribution of HVR?", "labels": [], "entities": []}, {"text": "Is it possible to substantially reduce HVR by increasing the size of a corpus?", "labels": [], "entities": []}, {"text": "If so, how large should such a corpus be?", "labels": [], "entities": []}, {"text": "These questions are the focus of this article.", "labels": [], "entities": []}, {"text": "In this study, the dynamic relationship among the vocabulary size V, number of hapaxes H, and text length N was examined in the 100-million-word British National Corpus (BNC).", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 145, "end_pos": 174, "type": "DATASET", "confidence": 0.9715024729569753}]}, {"text": "In the study, the orthographic word concept is adopted as a working definition, that is, a word (also called word token) is a string of contiguous alphanumeric characters with a space on either side).", "labels": [], "entities": []}, {"text": "The alphanumeric character set \u03a3 is defined as The word \u03c9 is defined as \u03c9 \u2208 \u03a3 + There are 62 characters in \u03a3; however, in this study, all words are case-insensitive (i.e., words such as Language, LANGUAGE, and language are regarded as the same).", "labels": [], "entities": []}, {"text": "So there are actually 36 characters in \u03a3.", "labels": [], "entities": []}, {"text": "Another concept used is lemma, which refers to the set of words having the same stem, the same major part-of-speech, and the same word-sense (.", "labels": [], "entities": []}, {"text": "In this study, the vocabulary of a text or a corpus is the set of different lemmas within the text or corpus.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1  The initial HVRs (HVR i ), the minimum HVRs (HVR m ), the final HVRs (HVR f ), H at HVR m  (H hvrm ), V at HVR m (V hvrm ), and the PORs.", "labels": [], "entities": [{"text": "PORs", "start_pos": 142, "end_pos": 146, "type": "METRIC", "confidence": 0.9931527376174927}]}]}