{"title": [{"text": "A Unified Statistical Model for the Identification of English BaseNP", "labels": [], "entities": [{"text": "Identification of English BaseNP", "start_pos": 36, "end_pos": 68, "type": "TASK", "confidence": 0.9029609709978104}]}], "abstractContent": [{"text": "This paper presents a novel statistical model for automatic identification of English baseNP.", "labels": [], "entities": [{"text": "automatic identification of English baseNP", "start_pos": 50, "end_pos": 92, "type": "TASK", "confidence": 0.6720637202262878}]}, {"text": "It uses two steps: the N-best Part-Of-Speech (POS) tagging and baseNP identification given the N-best POS-sequences.", "labels": [], "entities": [{"text": "N-best Part-Of-Speech (POS) tagging", "start_pos": 23, "end_pos": 58, "type": "TASK", "confidence": 0.503437802195549}, {"text": "baseNP identification", "start_pos": 63, "end_pos": 84, "type": "TASK", "confidence": 0.7109543979167938}]}, {"text": "Unlike the other approaches where the two steps are separated, we integrate them into a unified statistical framework.", "labels": [], "entities": []}, {"text": "Our model also integrates lexical information.", "labels": [], "entities": []}, {"text": "Finally, Viterbi algorithm is applied to make global search in the entire sentence, allowing us to obtain linear complexity for the entire process.", "labels": [], "entities": []}, {"text": "Compared with other methods using the same testing set, our approach achieves 92.3% in precision and 93.2% in recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.999734103679657}, {"text": "recall", "start_pos": 110, "end_pos": 116, "type": "METRIC", "confidence": 0.9987975358963013}]}, {"text": "The result is comparable with or better than the previously reported results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Finding simple and non-recursive base Noun Phrase (baseNP) is an important subtask for many natural language processing applications, such as partial parsing, information retrieval and machine translation.", "labels": [], "entities": [{"text": "partial parsing", "start_pos": 142, "end_pos": 157, "type": "TASK", "confidence": 0.7223314344882965}, {"text": "information retrieval", "start_pos": 159, "end_pos": 180, "type": "TASK", "confidence": 0.8222149014472961}, {"text": "machine translation", "start_pos": 185, "end_pos": 204, "type": "TASK", "confidence": 0.8139930665493011}]}, {"text": "A baseNP is a simple noun phrase that does not contain other noun phrase recursively, for example, the elements within in the following example are baseNPs, where NNS, IN VBG etc are part-of-speech tags [as defined in M...", "labels": [], "entities": [{"text": "IN VBG", "start_pos": 168, "end_pos": 174, "type": "METRIC", "confidence": 0.7219362556934357}]}, {"text": "Recently some researchers have made experiments with the same test corpus extracted from the 20 th section of the Penn Treebank Wall Street Journal (Penn Treebank).", "labels": [], "entities": [{"text": "test corpus extracted from the 20 th section of the Penn Treebank Wall Street Journal (Penn Treebank)", "start_pos": 62, "end_pos": 163, "type": "DATASET", "confidence": 0.8307438430033232}]}, {"text": "applied transformbased error-driven algorithm to learn a set of transformation rules, and using those rules to locally updates the bracket positions.", "labels": [], "entities": []}, {"text": "Argamon, introduced a memory-based sequences learning method, the training examples are stored and generalization is performed at application time by comparing subsequence of the new text to positive and negative evidence.) devised error driven pruning approach trained on Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 273, "end_pos": 286, "type": "DATASET", "confidence": 0.9964029490947723}]}, {"text": "It extracts baseNP rules from the training corpus and prune some bad baseNP by incremental training, and then apply the pruned rules to identify baseNP through maximum length matching (or dynamic program algorithm).", "labels": [], "entities": []}, {"text": "Most of the prior work treats POS tagging and baseNP identification as two separate procedures.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 30, "end_pos": 41, "type": "TASK", "confidence": 0.8390244841575623}, {"text": "baseNP identification", "start_pos": 46, "end_pos": 67, "type": "TASK", "confidence": 0.7027766406536102}]}, {"text": "However, uncertainty is involved in both steps.", "labels": [], "entities": []}, {"text": "Using the result of the first step as if they are certain will lead to more errors in the second step.", "labels": [], "entities": []}, {"text": "A better approach is to consider the two steps together such that the final output takes the uncertainty in both steps together.", "labels": [], "entities": []}, {"text": "The approaches proposed by Ramshaw & Markus and Cardie&Pierce are deterministic and local, while Argamon, Dagan & Krymolowski consider the problem globally and assigned a score to each possible baseNP structures.", "labels": [], "entities": []}, {"text": "However, they did not consider any lexical information.", "labels": [], "entities": []}, {"text": "This paper presents a novel statistical approach to baseNP identification, which considers both steps together within a unified statistical framework.", "labels": [], "entities": [{"text": "baseNP identification", "start_pos": 52, "end_pos": 73, "type": "TASK", "confidence": 0.8563582897186279}]}, {"text": "It also takes lexical information into account.", "labels": [], "entities": []}, {"text": "In addition, in order to make the best choice for the entire sentence, Viterbi algorithm is applied.", "labels": [], "entities": []}, {"text": "Our tests with the Penn Treebank showed that our integrated approach achieves 92.3% in precision and 93.2% in recall.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 19, "end_pos": 32, "type": "DATASET", "confidence": 0.9933611452579498}, {"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9997712969779968}, {"text": "recall", "start_pos": 110, "end_pos": 116, "type": "METRIC", "confidence": 0.9992006421089172}]}, {"text": "The result is comparable or better that the current state of the art.", "labels": [], "entities": []}, {"text": "In the following sections, we will describe the detail for the algorithm, parameter estimation and search algorithms in section 2.", "labels": [], "entities": []}, {"text": "The experiment results are given in section 3.", "labels": [], "entities": []}, {"text": "In section 4 we make further analysis and comparison.", "labels": [], "entities": []}, {"text": "In the final section we give some conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We designed five experiments as shown in.", "labels": [], "entities": []}, {"text": "\"UID\" and \"SID\" mean respectively that an identifier is assigned to each baseNP rule or the same identifier is assigned to all the baseNP rules.", "labels": [], "entities": [{"text": "SID", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.9431732892990112}]}, {"text": "\"+1\" and \"+4\" denote the number of beat POS sequences retained in the first step.", "labels": [], "entities": [{"text": "POS", "start_pos": 40, "end_pos": 43, "type": "METRIC", "confidence": 0.7281321883201599}]}, {"text": "And \"UID+R\" means the POS tagging result of the given sentence is totally correct for the 2nd step.", "labels": [], "entities": [{"text": "UID+R", "start_pos": 5, "end_pos": 10, "type": "METRIC", "confidence": 0.8412465651830038}, {"text": "POS tagging", "start_pos": 22, "end_pos": 33, "type": "TASK", "confidence": 0.7281962335109711}]}, {"text": "This provides an ideal upper bound for the system.", "labels": [], "entities": []}, {"text": "The reason why we choose N=4 for the N-best POS tagging can be explained in, which shows how the precision of POS tagging changes with the number N.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 44, "end_pos": 55, "type": "TASK", "confidence": 0.5278612971305847}, {"text": "precision", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.998712420463562}, {"text": "POS tagging", "start_pos": 110, "end_pos": 121, "type": "TASK", "confidence": 0.7293628752231598}]}, {"text": "Figure 4: POS tagging precision with respect to different number of N-best In the experiments, the training and testing sets are derived from the 25 sections of Wall Street Journal distributed with the Penn Treebank II, and the definition of baseNP is the same as Ramshaw's, Vi t er bi UI D+4", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.5834822654724121}, {"text": "precision", "start_pos": 22, "end_pos": 31, "type": "METRIC", "confidence": 0.8584715723991394}, {"text": "Wall Street Journal distributed with the Penn Treebank II", "start_pos": 161, "end_pos": 218, "type": "DATASET", "confidence": 0.8943597939279344}]}], "tableCaptions": [{"text": " Table  1. \"UID\" and \"SID\" mean respectively that an  identifier is assigned to each baseNP rule or the  same identifier is assigned to all the baseNP  rules. \"+1\" and \"+4\" denote the number of beat  POS sequences retained in the first step. And  \"UID+R\" means the POS tagging result of the  given sentence is totally correct for the 2nd step.  This provides an ideal upper bound for the  system. The reason why we choose N=4 for the  N-best POS tagging can be explained in", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 265, "end_pos": 276, "type": "TASK", "confidence": 0.6782392263412476}]}, {"text": " Table 1 The average performance of the five experiments", "labels": [], "entities": []}, {"text": " Table 2: The comparison of our statistical method with three other approaches", "labels": [], "entities": []}]}