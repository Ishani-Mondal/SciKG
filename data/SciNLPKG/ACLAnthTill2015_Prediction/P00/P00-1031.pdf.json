{"title": [{"text": "A New Statistical Approach to Chinese Pinyin Input", "labels": [], "entities": []}], "abstractContent": [{"text": "Chinese input is one of the key challenges for Chinese PC users.", "labels": [], "entities": []}, {"text": "This paper proposes a statistical approach to Pinyin-based Chinese input.", "labels": [], "entities": []}, {"text": "This approach uses a trigram-based language model and a statistically based segmentation.", "labels": [], "entities": []}, {"text": "Also, to deal with real input, it also includes a typing model which enables spelling correction in sentence-based Pinyin input, and a spelling model for English which enables modeless Pinyin input.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 77, "end_pos": 96, "type": "TASK", "confidence": 0.7119292467832565}]}], "introductionContent": [{"text": "Chinese input method is one of the most difficult problems for Chinese PC users.", "labels": [], "entities": []}, {"text": "There are two main categories of Chinese input method.", "labels": [], "entities": []}, {"text": "One is shape-based input method, such as \"wu bi zi xing\", the other is Pinyin, or pronunciation-based input method, such as \"Chinese CStar\", \"MSPY\", etc.", "labels": [], "entities": []}, {"text": "Because of its facility to learn and to use, Pinyin is the most popular Chinese input method.", "labels": [], "entities": []}, {"text": "Over 97% of the users in China use Pinyin for input.", "labels": [], "entities": []}, {"text": "Although Pinyin input method has so many advantages, it also suffers from several problems, including Pinyin-tocharacters conversion errors, user typing errors, and UI problem such as the need of two separate mode while typing Chinese and English, etc.", "labels": [], "entities": []}, {"text": "Pinyin-based method automatically converts Pinyin to Chinese characters.", "labels": [], "entities": []}, {"text": "But, there are only about 406 syllables; they correspond to over 6000 common Chinese characters.", "labels": [], "entities": []}, {"text": "So it is very difficult for system to select the correct corresponding Chinese characters automatically.", "labels": [], "entities": []}, {"text": "A higher accuracy maybe achieved using a sentence-based input.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9991347193717957}]}, {"text": "Sentence-based input method chooses character by using a language model base on context.", "labels": [], "entities": []}, {"text": "So its accuracy is higher than wordbased input method.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.9995217323303223}]}, {"text": "In this paper, all the technology is based on sentence-based input method, but it can easily adapted to word-input method.", "labels": [], "entities": []}, {"text": "In our approach we use statistical language model to achieve very high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.998362123966217}]}, {"text": "We design a unified approach to Chinese statistical language modelling.", "labels": [], "entities": [{"text": "statistical language modelling", "start_pos": 40, "end_pos": 70, "type": "TASK", "confidence": 0.6881693998972574}]}, {"text": "This unified approach enhances trigram-based statistical language modelling with automatic, maximumlikelihood-based methods to segment words, select the lexicon, and filter the training data.", "labels": [], "entities": [{"text": "statistical language modelling", "start_pos": 45, "end_pos": 75, "type": "TASK", "confidence": 0.6569079756736755}]}, {"text": "Compared to the commercial product, our system is up to 50% lower in error rate at the same memory size, and about 76% better without memory limits at all (Jianfeng etc.", "labels": [], "entities": [{"text": "error rate", "start_pos": 69, "end_pos": 79, "type": "METRIC", "confidence": 0.9778168201446533}]}], "datasetContent": [{"text": "Typing model is trained from the real user input.", "labels": [], "entities": []}, {"text": "We collected actual typing data from 100 users, with about 8 hours of typing data from each user.", "labels": [], "entities": []}, {"text": "90% of this data are used for training and remaining 10% data are used for testing.", "labels": [], "entities": []}, {"text": "The character perplexity for testing corpus is 66.69, and the word perplexity is 653.71.", "labels": [], "entities": [{"text": "word perplexity", "start_pos": 62, "end_pos": 77, "type": "METRIC", "confidence": 0.9294355809688568}]}, {"text": "We first, tested the baseline system without spelling correction.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.6298337578773499}]}, {"text": "There are two groups of input: one with perfect input (which means instead of using user input); the other is actual input, which contains real typing errors.", "labels": [], "entities": []}, {"text": "The error rate of Pinyin to Hanzi conversion is shown as table 3.1.", "labels": [], "entities": [{"text": "error", "start_pos": 4, "end_pos": 9, "type": "METRIC", "confidence": 0.9845823049545288}, {"text": "Pinyin to Hanzi conversion", "start_pos": 18, "end_pos": 44, "type": "TASK", "confidence": 0.5162300243973732}]}, {"text": "Error Rate Perfect Input 6.82% Actual Input 20.84%.1 system without spelling correction In the actual input data, approximately 4.6% Chinese characters are typed incorrectly.", "labels": [], "entities": [{"text": "Error Rate Perfect Input", "start_pos": 0, "end_pos": 24, "type": "METRIC", "confidence": 0.927697166800499}]}, {"text": "This 4.6% error will cause more errors through propagation.", "labels": [], "entities": []}, {"text": "In the whole system, we found that it results in tripling increase of the error rate from table 3.1.", "labels": [], "entities": [{"text": "error rate", "start_pos": 74, "end_pos": 84, "type": "METRIC", "confidence": 0.9823316037654877}]}, {"text": "It shows that error tolerance is very important for typist while using sentence-based input method.", "labels": [], "entities": []}, {"text": "For example, user types the Pinyin like: wisiyigezhonguoren (), system without error tolerance will convert it into Chinese character like: wi\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59u\ud97b\udf59\ud97b\udf59.", "labels": [], "entities": []}, {"text": "Another experiment is carried out to validate the concept of adaptive spelling correction.", "labels": [], "entities": [{"text": "adaptive spelling correction", "start_pos": 61, "end_pos": 89, "type": "TASK", "confidence": 0.6991900205612183}]}, {"text": "The motivation of adaptive spelling correction is that we want to apply more correction to less skilled typists.", "labels": [], "entities": [{"text": "adaptive spelling correction", "start_pos": 18, "end_pos": 46, "type": "TASK", "confidence": 0.6869861284891764}]}, {"text": "This level of correction can be controlled by the \"language model weight\"(LM weight)  As can be seen from.1, different LM weight will affect the system performance.", "labels": [], "entities": []}, {"text": "For a fixed LM weight of 0.5, the error rate of conversion is reduced by approximately 30%.", "labels": [], "entities": [{"text": "error rate", "start_pos": 34, "end_pos": 44, "type": "METRIC", "confidence": 0.9875849187374115}]}, {"text": "For example, the conversion of \"wisiyigezhonguoren\" is now correct.", "labels": [], "entities": []}, {"text": "If we apply adaptive LM weight depending on the typing skill of the user, we can obtain further error reduction.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 96, "end_pos": 111, "type": "METRIC", "confidence": 0.9587276577949524}]}, {"text": "To verify this, we select 3 users from the testing data, adding one ideal user (suppose input including no errors), we test the error rate of system with different LM weight, and result is as.2 user adaptation The average input error rates of User 1,2,3 are 0.77%, 4.41% and 5.73% respectively.", "labels": [], "entities": []}, {"text": "As can be seen from table 3.2, the best weight for each user is different.", "labels": [], "entities": []}, {"text": "Ina real system, skilled typist could be assigned lower LM weight, and the skill of typist can be determined by: 1.", "labels": [], "entities": []}, {"text": "the number of modification during typing.", "labels": [], "entities": []}, {"text": "2. the difficulty of the text typed distribution of typing time can also be estimated.", "labels": [], "entities": [{"text": "difficulty", "start_pos": 7, "end_pos": 17, "type": "METRIC", "confidence": 0.9828107357025146}]}, {"text": "It can be applied to judge the skill of the typist.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3.2 user adaptation  The average input error rates of User 1,2,3 are  0.77%, 4.41% and 5.73% respectively.", "labels": [], "entities": []}, {"text": " Table 4.1  Modeless Pinyin input method  (Only choose 52 English letters into the  English syllable list)", "labels": [], "entities": []}, {"text": " Table 4.2  Modeless Pinyin input method  (1000 frequently used English syllables + 52  English letters + 1 Unknown)", "labels": [], "entities": []}]}