{"title": [{"text": "Lexical transfer using a vector-space model", "labels": [], "entities": [{"text": "Lexical transfer", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9019774496555328}]}], "abstractContent": [{"text": "Building a bilingual dictionary for transfer in a machine translation system is conventionally done by hand and is very time-consuming.", "labels": [], "entities": []}, {"text": "In order to overcome this bottleneck, we propose anew mechanism for lexical transfer, which is simple and suitable for learning from bilingual corpora.", "labels": [], "entities": [{"text": "lexical transfer", "start_pos": 68, "end_pos": 84, "type": "TASK", "confidence": 0.7294354289770126}]}, {"text": "It exploits a vector-space model developed in information retrieval research.", "labels": [], "entities": [{"text": "information retrieval research", "start_pos": 46, "end_pos": 76, "type": "TASK", "confidence": 0.8819861809412638}]}, {"text": "We present a preliminary result from our computational experiment.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many machine translation systems have been developed and commercialized.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 5, "end_pos": 24, "type": "TASK", "confidence": 0.7628261744976044}]}, {"text": "When these systems are faced with unknown domains, however, their performance degrades.", "labels": [], "entities": []}, {"text": "Although there are several reasons behind this poor performance, in this paper, we concentrate on one of the major problems, i.e., building a bilingual dictionary for transfer.", "labels": [], "entities": [{"text": "transfer", "start_pos": 167, "end_pos": 175, "type": "TASK", "confidence": 0.9644728899002075}]}, {"text": "A bilingual dictionary consists of rules that map apart of the representation of a source sentence to a target representation by taking grammatical differences (such as the word order between the source and target languages) into consideration.", "labels": [], "entities": []}, {"text": "These rules usually use case-frames as their base and accompany syntactic and/or semantic constraints on mapping from a source word to a target word.", "labels": [], "entities": []}, {"text": "For many machine translation systems, experienced experts on individual systems compile the bilingual dictionary, because this is a complicated and difficult task.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.7135175168514252}]}, {"text": "In other words, this task is knowledge-intensive and labor-intensive, and therefore, time-consuming.", "labels": [], "entities": []}, {"text": "Typically, the developer of a machine translation system has to spend several years building a general-purpose bilingual dictionary.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.7250244915485382}]}, {"text": "Unfortunately, such a general-purpose dictionary is not almighty, in that (1) when faced with anew domain, unknown source words may emerge and/or some domain-specific usages of known words may appear and (2) the accuracy of the target word selection maybe insufficient due to the handling of many target words simultaneously.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 212, "end_pos": 220, "type": "METRIC", "confidence": 0.9988499879837036}]}, {"text": "Recently, to overcome these bottlenecks in knowledge building and/or tuning, the automation of lexicography has been studied by many researchers: (1) approaches using a decision tree: the ID3 learning algorithm is applied to obtain transfer rules from case-frame representations of simple sentences with a thesaurus for generalization; (2) approaches using structural matching: to obtain transfer rules, several search methods have been proposed for maximal structural matching between trees obtained by parsing bilingual sentences ().", "labels": [], "entities": [{"text": "knowledge building", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.7173824906349182}]}], "datasetContent": [{"text": "To demonstrate the feasibility of our proposal, we conducted a pilot experiment as explained in this section.", "labels": [], "entities": []}, {"text": "For our sentence vectors and code vectors, we used hand-made thesauri of Japanese and English covering our corpus (for a travel arrangement task), whose hierarchy is based on that of the Japanese commercial thesaurus Kadokawa Ruigo Jiten.", "labels": [], "entities": []}, {"text": "We used our English-Japanese phrasebook (a collection of pairs of typical sentences and their translations) for foreign tourists.", "labels": [], "entities": []}, {"text": "The statistics of the corpus are summarized in.", "labels": [], "entities": []}, {"text": "We word-aligned the corpus before generating the sentence vectors.", "labels": [], "entities": []}, {"text": "We focused on the transfer of content words such as nouns, verbs, and adjectives.", "labels": [], "entities": []}, {"text": "We picked out six polysemous words fora preliminary evaluation: \ud97b\udf59bill,\ud97b\udf59 \ud97b\udf59dry,\ud97b\udf59 \ud97b\udf59call\ud97b\udf59 in English and \" \ud97b\udf59 ,\" \" \ud97b\udf59 \ud97b\udf59 ,\" \" \ud97b\udf59 \ud97b\udf59 \" in Japanese.", "labels": [], "entities": []}, {"text": "We confined ourselves to a selection between two major clusters of each source word using the method in subsection 3.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4 Accuracy of the baseline and the VSM systems", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9990092515945435}, {"text": "VSM", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.5114010572433472}]}, {"text": " Table 5 Coverage of the top two clusters", "labels": [], "entities": []}]}