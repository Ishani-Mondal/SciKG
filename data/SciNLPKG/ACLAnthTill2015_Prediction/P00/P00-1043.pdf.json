{"title": [{"text": "Extracting Causal Knowledge from a Medical Database Using Graphical Patterns", "labels": [], "entities": [{"text": "Extracting Causal Knowledge from a Medical Database", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.8810062152998788}]}], "abstractContent": [{"text": "This paper reports the first part of a project that aims to develop a knowledge extraction and knowledge discovery system that extracts causal knowledge from textual databases.", "labels": [], "entities": [{"text": "knowledge extraction", "start_pos": 70, "end_pos": 90, "type": "TASK", "confidence": 0.7311356067657471}, {"text": "knowledge discovery", "start_pos": 95, "end_pos": 114, "type": "TASK", "confidence": 0.6885377913713455}]}, {"text": "In this initial study, we develop a method to identify and extract cause-effect information that is explicitly expressed in medical abstracts in the Medline database.", "labels": [], "entities": [{"text": "Medline database", "start_pos": 149, "end_pos": 165, "type": "DATASET", "confidence": 0.9865110814571381}]}, {"text": "A set of graphical patterns were constructed that indicate the presence of a causal relation in sentences, and which part of the sentence represents the cause and which part represents the effect.", "labels": [], "entities": []}, {"text": "The patterns are matched with the syntactic parse trees of sentences, and the parts of the parse tree that match with the slots in the patterns are extracted as the cause or the effect.", "labels": [], "entities": []}], "introductionContent": [{"text": "Vast amounts of textual documents and databases are now accessible on the Internet and the World Wide Web.", "labels": [], "entities": []}, {"text": "However, it is very difficult to retrieve useful information from this huge disorganized storehouse.", "labels": [], "entities": []}, {"text": "Programs that can identify and extract useful information, and relate and integrate information from multiple sources are increasingly needed.", "labels": [], "entities": []}, {"text": "The World Wide Web presents tremendous opportunities for developing knowledge extraction and knowledge discovery programs that automatically extract and acquire knowledge about a domain by integrating information from multiple sources.", "labels": [], "entities": [{"text": "knowledge extraction", "start_pos": 68, "end_pos": 88, "type": "TASK", "confidence": 0.7567335069179535}, {"text": "knowledge discovery", "start_pos": 93, "end_pos": 112, "type": "TASK", "confidence": 0.7015314251184464}]}, {"text": "New knowledge can be discovered by relating disparate pieces of information and by inferencing from the extracted knowledge.", "labels": [], "entities": []}, {"text": "This paper reports the first phase of a project to develop a knowledge extraction and knowledge discovery system that focuses on causal knowledge.", "labels": [], "entities": [{"text": "knowledge extraction", "start_pos": 61, "end_pos": 81, "type": "TASK", "confidence": 0.7292476296424866}, {"text": "knowledge discovery", "start_pos": 86, "end_pos": 105, "type": "TASK", "confidence": 0.6952138245105743}]}, {"text": "A system is being developed to identify and extract cause-effect information from the Medline database -a database of abstracts of medical journal articles and conference papers.", "labels": [], "entities": [{"text": "Medline database", "start_pos": 86, "end_pos": 102, "type": "DATASET", "confidence": 0.9800450503826141}]}, {"text": "In this initial study, we focus on causeeffect information that is explicitly expressed (i.e. indicated using some linguistic marker) in sentences.", "labels": [], "entities": []}, {"text": "We have selected four medical areas for this study -heart disease, AIDS, depression and schizophrenia.", "labels": [], "entities": []}, {"text": "The medical domain was selected for two reasons: 1.", "labels": [], "entities": []}, {"text": "The causal relation is particular important in medicine, which is concerned with developing treatments and drugs that can effect a cure for some disease 2.", "labels": [], "entities": []}, {"text": "Because of the importance of the causal relation in medicine, the relation is more likely to be explicitly indicated using linguistic means (i.e. using words such as result, effect, cause, etc.).", "labels": [], "entities": []}], "datasetContent": [{"text": "A total of 68 patterns were constructed for the 35 causality identifiers that occurred at least twice in the training abstracts.", "labels": [], "entities": []}, {"text": "The patterns were applied to two sets of new abstracts downloaded from Medline: 100 new abstracts from the original four medical areas (25 abstracts from each area), and 30 abstracts from two new domains (15 each) -digestive system diseases and respiratory tract diseases.", "labels": [], "entities": [{"text": "Medline", "start_pos": 71, "end_pos": 78, "type": "DATASET", "confidence": 0.9798989295959473}]}, {"text": "Each test abstract was analyzed by at least 2 of the authors to identify \"medically relevant\" cause and effect.", "labels": [], "entities": []}, {"text": "A fair number of causal relations in the abstracts are trivial and not medically relevant, and it was felt that it would not be useful for the information extraction system to extract these trivial causal relations.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 143, "end_pos": 165, "type": "TASK", "confidence": 0.7717268168926239}]}, {"text": "Of the causal relations manually identified in the abstracts, about 7% are implicit (i.e. have to be inferred using knowledge-based inferencing) or occur across sentences.", "labels": [], "entities": []}, {"text": "Since the focus of the study is on explicitly expressed cause and effect within a sentence, only these are included in the evaluation.", "labels": [], "entities": []}, {"text": "The evaluation results are presented in.", "labels": [], "entities": []}, {"text": "Recall is the percentage of the slots filled by the human analysts that are correctly filled by the computer program.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9687712788581848}]}, {"text": "Precision is the percentage of slots filled by the computer program that are correct (i.e. the text entered in the slot is the same as that entered by the human analysts).", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9940170049667358}]}, {"text": "If the text entered by the computer program is partially correct, it is scored as 0.5 (i.e. half correct).", "labels": [], "entities": []}, {"text": "The F-measure given in is a combination of recall and precision equally weighted, and is calculated using the formula (MUC-7): 2*precision*recall / (precision + recall) For the 4 medical areas used for building the extraction patterns, the F-measure for the cause and effect slots are 0.508 and 0.578 respectively.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9975479245185852}, {"text": "recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.998710036277771}, {"text": "precision", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9951841235160828}, {"text": "MUC-7", "start_pos": 119, "end_pos": 124, "type": "DATASET", "confidence": 0.6848213076591492}, {"text": "precision", "start_pos": 129, "end_pos": 138, "type": "METRIC", "confidence": 0.9958904385566711}, {"text": "recall", "start_pos": 139, "end_pos": 145, "type": "METRIC", "confidence": 0.9230452179908752}, {"text": "precision", "start_pos": 149, "end_pos": 158, "type": "METRIC", "confidence": 0.9921239018440247}, {"text": "recall", "start_pos": 161, "end_pos": 167, "type": "METRIC", "confidence": 0.5512556433677673}, {"text": "F-measure", "start_pos": 240, "end_pos": 249, "type": "METRIC", "confidence": 0.9967079162597656}]}, {"text": "If implicit causal relations are included in the evaluation, the recall measures for cause and effect are 0.405 and 0.481 respectively, yielding an F-measure of 0.47 for cause and 0.54 for effect.", "labels": [], "entities": [{"text": "recall", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9992815852165222}, {"text": "F-measure", "start_pos": 148, "end_pos": 157, "type": "METRIC", "confidence": 0.998706579208374}]}, {"text": "The results are not very good, but not very bad either for an information extraction task.", "labels": [], "entities": [{"text": "information extraction task", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.9051371614138285}]}, {"text": "For the 2 new medical areas, we can see in that the precision is about the same as for the original 4 medical areas, indicating that the current extraction patterns work equally well in the new areas.", "labels": [], "entities": [{"text": "precision", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9996849298477173}]}, {"text": "The lower recall indicates that new causality identifiers and extraction patterns need to be constructed.", "labels": [], "entities": [{"text": "recall", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9992038607597351}]}, {"text": "The sources of errors were analyzed for the set of 100 test abstracts and are summarized in.", "labels": [], "entities": []}, {"text": "Most of the spurious extractions (information extracted by the program as cause or effect but not identified by human analysts) were actually causal relations that were not medically relevant.", "labels": [], "entities": []}, {"text": "As mentioned earlier, the manual identification of causal relations focused on medically relevant causal relations.", "labels": [], "entities": [{"text": "manual identification of causal relations", "start_pos": 26, "end_pos": 67, "type": "TASK", "confidence": 0.7414694905281067}]}, {"text": "In the cases where the program did not correctly extract cause and effect information identified by the analysts, half were due to incorrect parser output, and in 20% of the cases, causality patterns have not been constructed for the causality identifier found in the sentence.", "labels": [], "entities": []}, {"text": "We also analyzed the instances of implicit causal relations in sentences, and found that many of them can be identified using some amount of semantic analysis.", "labels": [], "entities": []}, {"text": "Some of them involve words like when, after and with that indicate a time sequence, for example: \u2022 The results indicate that changes to 8-OH-DPAT and clonidine-induced responses occur quicker with the combination treatment than with either reboxetine or sertraline treatments alone.", "labels": [], "entities": []}, {"text": "\u2022 There are also no reports of serious adverse events when lithium is added to a monoamine oxidase inhibitor.", "labels": [], "entities": []}, {"text": "\u2022 Four days after flupenthixol administration, the patient developed orolingual dyskinetic movements involving mainly tongue biting and protrusion.", "labels": [], "entities": []}, {"text": "In these cases, a treatment or drug is associated with a treatment response or physiological event.", "labels": [], "entities": []}, {"text": "If noun phrases and clauses in sentences can be classified accurately into treatments and treatment responses (perhaps by using Medline's Medical Subject Headings), then such implicit causal relations can be identified automatically.", "labels": [], "entities": []}, {"text": "Another group of words involved in implicit causal relations are words like receive, get and take, that indicate that the patient received a drug or treatment, for example: \u2022 The nine subjects who received p24-VLP and zidovudine had an augmentation and/or broadening of their CTL response compared with baseline (p = 0.004).", "labels": [], "entities": []}, {"text": "Such causal relations can also be identified by semantic analysis and classifying noun phrases and clauses into treatments and treatment responses.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. The cause-effect template  Level 1  Level 2  Object  State/Event  Cause  Size  Object  State/Event  Effect  Size  Polarity (e.g. \"Increase\", \"Decrease\",  etc.)  Object  State/Event  Size  Duration", "labels": [], "entities": [{"text": "Object  State/Event  Size  Duration", "start_pos": 171, "end_pos": 206, "type": "TASK", "confidence": 0.5872949808835983}]}, {"text": " Table 2. Common causal expressions for  depression & schizophrenia  Expression  No. of  Occurrences  causative verb  69  effect (of) \u2026(on)  51  associate with  35  treatment of  31  have effect on  28  treat with  26  treatment with  22  effective (for)  14  related to  10", "labels": [], "entities": []}, {"text": " Table 3. Common causal expressions for  AIDs & heart disease  Expression  No. of  Occurrences  causative verb  119  have effect on  30  effect (of)\u2026(on)  25  due to  20  associate with  19  treat with  15  causative noun (including  nominalized verbs)", "labels": [], "entities": [{"text": "AIDs", "start_pos": 41, "end_pos": 45, "type": "TASK", "confidence": 0.9697170257568359}]}]}