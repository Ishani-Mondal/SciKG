{"title": [{"text": "An Improved Parser for Data-Oriented Lexical-Functional Analysis", "labels": [], "entities": [{"text": "Data-Oriented Lexical-Functional Analysis", "start_pos": 23, "end_pos": 64, "type": "TASK", "confidence": 0.6330227653185526}]}], "abstractContent": [{"text": "We present an LFG-DOP parser which uses fragments from LFG-annotated sentences to parse new sentences.", "labels": [], "entities": []}, {"text": "Experiments with the Verbmobil and Homecentre corpora show that (1) Viterbi n best search performs about 100 times faster than Monte Carlo search while both achieve the same accuracy; (2) the DOP hypothesis which states that parse accuracy increases with increasing fragment size is confirmed for LFG-DOP; (3) LFG-DOP's relative frequency estimator performs worse than a discounted frequency estimator; and (4) LFG-DOP significantly outperforms Tree-DOP if evaluated on tree structures only.", "labels": [], "entities": [{"text": "Homecentre corpora", "start_pos": 35, "end_pos": 53, "type": "DATASET", "confidence": 0.8747316002845764}, {"text": "accuracy", "start_pos": 174, "end_pos": 182, "type": "METRIC", "confidence": 0.9960113763809204}, {"text": "accuracy", "start_pos": 231, "end_pos": 239, "type": "METRIC", "confidence": 0.8608075380325317}]}], "introductionContent": [{"text": "Data-Oriented Parsing (DOP) models learn how to provide linguistic representations for an unlimited set of utterances by generalizing from a given corpus of properly annotated exemplars.", "labels": [], "entities": []}, {"text": "They operate by decomposing the given representations into (arbitrarily large) fragments and recomposing those pieces to analyze new utterances.", "labels": [], "entities": []}, {"text": "A probability model is used to choose from the collection of different fragments of different sizes those that makeup the most appropriate analysis of an utterance.", "labels": [], "entities": []}, {"text": "DOP models have been shown to achieve state-of-the-art parsing performance on benchmarks such as the Wall Street Journal corpus (see.", "labels": [], "entities": [{"text": "Wall Street Journal corpus", "start_pos": 101, "end_pos": 127, "type": "DATASET", "confidence": 0.9676659256219864}]}, {"text": "The original DOP model in was based on utterance analyses represented as surface trees, and is equivalent to a Stochastic Tree-Substitution Grammar.", "labels": [], "entities": []}, {"text": "But the model has also been applied to several other grammatical frameworks, e.g. Tree-Insertion Grammar (Hoogweg 2000), Tree-Adjoining Grammar,), Head-driven Phrase Structure Grammar, and Montague Grammar ().", "labels": [], "entities": [{"text": "Head-driven Phrase Structure Grammar", "start_pos": 147, "end_pos": 183, "type": "TASK", "confidence": 0.6244402974843979}]}, {"text": "Most probability models for DOP use the relative frequency estimator to estimate fragment probabilities, although trains fragment probabilities by a maximum likelihood reestimation procedure belonging to the class of expectation-maximization algorithms.", "labels": [], "entities": [{"text": "DOP", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9500719308853149}]}, {"text": "The DOP model has also been tested as a model for human sentence processing.", "labels": [], "entities": [{"text": "human sentence processing", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.602312038342158}]}, {"text": "This paper presents ongoing work on DOP models for Lexical-Functional Grammar representations, known as LFG-DOP).", "labels": [], "entities": [{"text": "Lexical-Functional Grammar representations", "start_pos": 51, "end_pos": 93, "type": "TASK", "confidence": 0.7454581459363302}]}, {"text": "We develop a parser which uses fragments from LFG-annotated sentences to parse new sentences, and we derive some experimental properties of LFG-DOP on two LFG-annotated corpora: the Verbmobil and Homecentre corpus.", "labels": [], "entities": [{"text": "Verbmobil", "start_pos": 182, "end_pos": 191, "type": "DATASET", "confidence": 0.9127914309501648}, {"text": "Homecentre corpus", "start_pos": 196, "end_pos": 213, "type": "DATASET", "confidence": 0.8910748958587646}]}, {"text": "The experiments show that the DOP hypothesis, which states that there is an increase in parse accuracy if larger fragments are taken into account, is confirmed for LFG-DOP.", "labels": [], "entities": [{"text": "DOP", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.7708837985992432}, {"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.6295868158340454}]}, {"text": "We report on an improved search technique for estimating the most probable analysis.", "labels": [], "entities": []}, {"text": "While a Monte Carlo search converges provably to the most probable parse, a Viterbi n best search performs as well as Monte Carlo while its processing time is two orders of magnitude faster.", "labels": [], "entities": []}, {"text": "We also show that LFG-DOP outperforms Tree-DOP if evaluated on tree structures only.", "labels": [], "entities": []}], "datasetContent": [{"text": "We derived some experimental properties of LFG-DOP by studying its behavior on the two LFG-annotated corpora that are currently available: the Verbmobil corpus and the Homecentre corpus.", "labels": [], "entities": [{"text": "Verbmobil corpus", "start_pos": 143, "end_pos": 159, "type": "DATASET", "confidence": 0.9234389662742615}, {"text": "Homecentre corpus", "start_pos": 168, "end_pos": 185, "type": "DATASET", "confidence": 0.9831110537052155}]}, {"text": "Both corpora were annotated at Xerox PARC.", "labels": [], "entities": [{"text": "Xerox PARC", "start_pos": 31, "end_pos": 41, "type": "DATASET", "confidence": 0.9331661760807037}]}, {"text": "They contain packed LFGrepresentations of the grammatical parses of each sentence together with an indication which of these parses is the correct one.", "labels": [], "entities": []}, {"text": "For our experiments we only used the correct parses of each sentence resulting in 540 Verbmobil parses and 980 Homecentre parses.", "labels": [], "entities": [{"text": "Homecentre", "start_pos": 111, "end_pos": 121, "type": "DATASET", "confidence": 0.9100382328033447}]}, {"text": "Each corpus was divided into a 90% training set and a 10% test set.", "labels": [], "entities": []}, {"text": "This division was random except for one constraint: that all the words in the test set actually occurred in the training set.", "labels": [], "entities": []}, {"text": "The sentences from the test set were parsed and disambiguated by means of the fragments from the training set.", "labels": [], "entities": []}, {"text": "Due to memory limitations, we restricted the maximum depth of the indexed subtrees to 4.", "labels": [], "entities": []}, {"text": "Because of the small size of the corpora we averaged our results on 10 different training/test set splits.", "labels": [], "entities": []}, {"text": "Besides an exact match accuracy metric, we also used a more fine-grained score based on the well-known PARSEVAL metrics that evaluate phrase-structure trees).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.891563892364502}]}, {"text": "The PARSEVAL metrics compare a proposed parse P with the corresponding correct treebank parse T as follows: A constituent in P is correct if there exists a constituent in T of the same label that spans the same words and that \u03c6-corresponds to the same f-structure unit (see Bod 2000c for some illustrations of these metrics for LFG-DOP).", "labels": [], "entities": [{"text": "Bod 2000c", "start_pos": 274, "end_pos": 283, "type": "DATASET", "confidence": 0.9690649211406708}]}], "tableCaptions": [{"text": " Table 1. Experimental results on the Verbmobil", "labels": [], "entities": [{"text": "Verbmobil", "start_pos": 38, "end_pos": 47, "type": "DATASET", "confidence": 0.7185042500495911}]}, {"text": " Table 2. Experimental results on the Homecentre", "labels": [], "entities": [{"text": "Homecentre", "start_pos": 38, "end_pos": 48, "type": "DATASET", "confidence": 0.973482072353363}]}, {"text": " Table 3. Accuracies on the Verbmobil", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9968294501304626}, {"text": "Verbmobil", "start_pos": 28, "end_pos": 37, "type": "DATASET", "confidence": 0.44637757539749146}]}, {"text": " Table 4. Accuracies on the Homecentre", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9950771927833557}, {"text": "Homecentre", "start_pos": 28, "end_pos": 38, "type": "DATASET", "confidence": 0.9519911408424377}]}, {"text": " Table 5. Tree accuracy on the Verbmobil", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9932262301445007}, {"text": "Verbmobil", "start_pos": 31, "end_pos": 40, "type": "DATASET", "confidence": 0.8326485753059387}]}, {"text": " Table 6. Tree accuracy on the Homecentre", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9898530840873718}, {"text": "Homecentre", "start_pos": 31, "end_pos": 41, "type": "DATASET", "confidence": 0.9723187685012817}]}, {"text": " Table 7. Precision on the Verbmobil", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9806500673294067}, {"text": "Verbmobil", "start_pos": 27, "end_pos": 36, "type": "DATASET", "confidence": 0.6635063290596008}]}, {"text": " Table 8. Precision on the Homecentre", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9290503263473511}, {"text": "Homecentre", "start_pos": 27, "end_pos": 37, "type": "DATASET", "confidence": 0.9723437428474426}]}]}