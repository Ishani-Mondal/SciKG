{"title": [{"text": "An Empirical Study of the Influence of Argument Conciseness on Argument Effectiveness", "labels": [], "entities": []}], "abstractContent": [{"text": "We have developed a system that generates evaluative arguments that are tailored to the user, properly arranged and concise.", "labels": [], "entities": []}, {"text": "We have also developed an evaluation framework in which the effectiveness of evaluative arguments can be measured with real users.", "labels": [], "entities": []}, {"text": "This paper presents the results of a formal experiment we have performed in our framework to verify the influence of argument conciseness on argument effectiveness", "labels": [], "entities": []}], "introductionContent": [{"text": "Empirical methods are critical to gauge the scalability and robustness of proposed approaches, to assess progress and to stimulate new research questions.", "labels": [], "entities": []}, {"text": "In the field of natural language generation, empirical evaluation has only recently become atop research priority (Dale,).", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 16, "end_pos": 43, "type": "TASK", "confidence": 0.6457851926485697}]}, {"text": "Some empirical work has been done to evaluate models for generating descriptions of objects and processes from a knowledge base), text summaries of quantitative data, descriptions of plans (Young to appear) and concise causal arguments (McConachy,).", "labels": [], "entities": []}, {"text": "However, little attention has been paid to the evaluation of systems generating evaluative arguments, communicative acts that attempt to affect the addressee's attitudes (i.e. evaluative tendencies typically phrased in terms of like and dislike or favor and disfavor).", "labels": [], "entities": []}, {"text": "The ability to generate evaluative arguments is critical in an increasing number of online systems that serve as personal assistants, advisors, or shopping assistants . For instance, a shopping assistant may need to compare two similar products and argue why its current user should like one more than the other.", "labels": [], "entities": []}, {"text": "See for instance In the remainder of the paper, we first describe a computational framework for generating evaluative arguments at different levels of conciseness.", "labels": [], "entities": []}, {"text": "Then, we present an evaluation framework in which the effectiveness of evaluative arguments can be measured with real users.", "labels": [], "entities": []}, {"text": "Next, we describe the design of an experiment we ran within the framework to verify the influence of argument conciseness on argument effectiveness.", "labels": [], "entities": []}, {"text": "We conclude with a discussion of the experiment's results.", "labels": [], "entities": []}], "datasetContent": [{"text": "-Measures of behavioral intentions and attitude change: (a) whether or not the user adopts the new proposed alternative, (b) in which position in the Hot List she places it and (c) how much she likes the new alternative and the other objects in the Hot List.", "labels": [], "entities": []}, {"text": "-A measure of the user's confidence that she has selected the best for her in the set of alternatives.", "labels": [], "entities": []}, {"text": "-A measure of argument effectiveness derived by explicitly questioning the user at the end of the interaction about the rationale for her decision (.", "labels": [], "entities": []}, {"text": "This can provide valuable information on what aspects of the argument were more influential (i.e., better understood and accepted by the user).", "labels": [], "entities": []}, {"text": "-An additional measure of argument effectiveness is to explicitly ask the user at the end of the interaction to judge the argument with respect to several dimensions of quality, such as content, organization, writing style and convincigness.", "labels": [], "entities": []}, {"text": "However, evaluations based on To summarize, the evaluation framework just described supports users in performing a realistic task at their own pace by interacting with an IDEA system.", "labels": [], "entities": []}, {"text": "In the context of this task, an evaluative argument is generated and measurements related to its effectiveness can be performed.", "labels": [], "entities": []}, {"text": "We now discuss an experiment that we have performed within the evaluation framework  The argument generator has been designed to facilitate testing the effectiveness of different aspects of the generation process.", "labels": [], "entities": []}, {"text": "The experimenter can easily control whether the generator tailors the argument to the current user, the degree of conciseness of the argument (by varying k as explained in Section 2.3), and what microplanning tasks the generator performs.", "labels": [], "entities": []}, {"text": "In the experiment described here, we focused on studying the influence of argument conciseness on argument effectiveness.", "labels": [], "entities": []}, {"text": "A parallel experiment about the influence of tailoring is described elsewhere.", "labels": [], "entities": []}, {"text": "We followed a between-subjects design with three experimental conditions: No-Argument -subjects are simply informed that anew house came on the market.", "labels": [], "entities": []}, {"text": "Tailored-Concise -subjects are presented with an evaluation of the new house tailored to their preferences and at a level of conciseness that we hypothesize to be optimal.", "labels": [], "entities": []}, {"text": "To start our investigation, we assume that an effective argument (in our domain) should contain slightly more than half of the available evidence.", "labels": [], "entities": []}, {"text": "By running the generator with different values fork on the user models of the pilot subjects, we found that this corresponds to k=-0.3.", "labels": [], "entities": []}, {"text": "In fact, with k=-0.3 the arguments contained on average 10 pieces of evidence out of the 19 available.", "labels": [], "entities": []}, {"text": "Tailored-Verbose -subjects are presented with an evaluation of the new house tailored to their preferences, but at a level of conciseness that we hypothesize to be too low (k=-1, which corresponds on average, in our analysis of the pilot subjects, to 16 pieces of evidence out of the possible 19).", "labels": [], "entities": []}, {"text": "In the three conditions, all the information about the new house is also presented graphically, so that no information is hidden from the subject.", "labels": [], "entities": []}, {"text": "Our hypotheses on the outcomes of the experiment are summarized in.", "labels": [], "entities": []}, {"text": "We expect arguments generated for the TailoredConcise condition to be more effective than arguments generated for the Tailored-Verbose condition.", "labels": [], "entities": []}, {"text": "We also expect the Tailored-Concise condition to be somewhat better than the NoArgument condition, but to a lesser extent, because subjects, in the absence of any argument, may spend more time further exploring the dataset, thus reaching a more informed and balanced decision.", "labels": [], "entities": []}, {"text": "Finally, we do not have strong hypotheses on comparisons of argument effectiveness between the NoArgument and Tailored-Verbose conditions.", "labels": [], "entities": [{"text": "NoArgument", "start_pos": 95, "end_pos": 105, "type": "DATASET", "confidence": 0.9198397397994995}]}, {"text": "The experiment is organized in two phases.", "labels": [], "entities": []}, {"text": "In the first phase, the subject fills out a questionnaire on the Web.", "labels": [], "entities": []}, {"text": "The questionnaire implements a method form decision theory to acquire an AMVF model of the subject's preferences (.", "labels": [], "entities": []}, {"text": "In the second phase of the experiment, to control for possible confounding variables (including subject's argumentativeness, need for cognition), intelligence and self-esteem), the subject is randomly assigned to one of the three conditions.", "labels": [], "entities": []}, {"text": "Then, the subject interacts with the evaluation framework and at the end of the interaction measures of the argument effectiveness are collected, as described in Section 3.1.", "labels": [], "entities": []}, {"text": "After running the experiment with 8 pilot subjects to refine and improve the experimental procedure, we ran a formal experiment involving 30 subjects, 10 in each experimental condition.", "labels": [], "entities": []}], "tableCaptions": []}