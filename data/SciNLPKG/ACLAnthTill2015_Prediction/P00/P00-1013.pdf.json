{"title": [{"text": "Spoken Dialogue Management Using Probabilistic Reasoning", "labels": [], "entities": [{"text": "Spoken Dialogue Management", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.9613975485165914}]}], "abstractContent": [{"text": "Spoken dialogue managers have benefited from using stochastic planners such as Markov Decision Processes (MDPs).", "labels": [], "entities": []}, {"text": "However , so far, MDPs do not handle well noisy and ambiguous speech utterances.", "labels": [], "entities": []}, {"text": "We use a Partially Observable Markov Decision Process (POMDP)-style approach to generate dialogue strategies by inverting the notion of dialogue state; the state represents the user's intentions, rather than the system state.", "labels": [], "entities": []}, {"text": "We demonstrate that under the same noisy conditions , a POMDP dialogue manager makes fewer mistakes than an MDP dialogue manager.", "labels": [], "entities": []}, {"text": "Furthermore, as the quality of speech recognition degrades, the POMDP dialogue manager automatically adjusts the policy.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.7021967321634293}, {"text": "POMDP dialogue manager", "start_pos": 64, "end_pos": 86, "type": "DATASET", "confidence": 0.6471951206525167}]}], "introductionContent": [{"text": "The development of automatic speech recognition has made possible more natural human-computer interaction.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.6745602488517761}]}, {"text": "Speech recognition and speech understanding, however, are not yet at the point where a computer can reliably extract the intended meaning from every human utterance.", "labels": [], "entities": [{"text": "Speech recognition", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8263674080371857}, {"text": "speech understanding", "start_pos": 23, "end_pos": 43, "type": "TASK", "confidence": 0.7914056479930878}]}, {"text": "Human speech can be both noisy and ambiguous, and many real-world systems must also be speaker-independent.", "labels": [], "entities": []}, {"text": "Regardless of these difficulties, any system that manages human-machine dialogues must be able to perform reliably even with noisy and stochastic speech input.", "labels": [], "entities": []}, {"text": "Recent research in dialogue management has shown that Markov Decision Processes (MDPs) can be useful for generating effective dialogue strategies; the system is modelled as a set of states that represent the dialogue as a whole, and a set of actions corresponding to speech productions from the system.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.8303247392177582}]}, {"text": "The goal is to maximise the reward obtained for fulfilling a user's request.", "labels": [], "entities": []}, {"text": "However, the correct way to represent the state of the dialogue is still an open problem (.", "labels": [], "entities": []}, {"text": "A common solution is to restrict the system to a single goal.", "labels": [], "entities": []}, {"text": "For example, in booking a flight in an automated travel agent system, the system state is described in terms of how close the agent is to being able to book the flight.", "labels": [], "entities": []}, {"text": "Such systems suffer from a principal problem.", "labels": [], "entities": []}, {"text": "A conventional MDP-based dialogue manager must know the current state of the system at all times, and therefore the state has to be wholly contained in the system representation.", "labels": [], "entities": []}, {"text": "These systems perform well under certain conditions, but not all.", "labels": [], "entities": []}, {"text": "For example, MDPs have been used successfully for such tasks as retrieving e-mail or making travel arrangements () over the phone, task domains that are generally low in both noise and ambiguity.", "labels": [], "entities": []}, {"text": "However, the issue of reliability in the face of noise is a major concern for our application.", "labels": [], "entities": [{"text": "reliability", "start_pos": 22, "end_pos": 33, "type": "METRIC", "confidence": 0.9746282696723938}]}, {"text": "Our dialogue manager was developed fora mobile robot application that has knowledge from several domains, and must interact with many people overtime.", "labels": [], "entities": []}, {"text": "For speaker-independent systems and systems that must act in a noisy environment, the user's action and intentions cannot always be used to infer the dialogue state; it maybe not be possible to reliably and completely determine the state of the dialogue following each utterance.", "labels": [], "entities": []}, {"text": "The poor reliability of the audio signal on a mobile robot, coupled with the expectations of natural interaction that people have with more anthropomorphic interfaces, increases the demands placed on the dialogue manager.", "labels": [], "entities": []}, {"text": "Most existing dialogue systems do not model confidences on recognition accuracy of the human utterances, and therefore do not account for the reliability of speech recognition when applying a dialogue strategy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9261476397514343}, {"text": "speech recognition", "start_pos": 157, "end_pos": 175, "type": "TASK", "confidence": 0.7506858706474304}]}, {"text": "Some systems douse the log-likelihood values for speech utterances, however these values are only thresholded to indicate whether the utterance needs to be confirmed).", "labels": [], "entities": []}, {"text": "An important concept lying at the heart of this issue is that of observability -the ultimate goal of a dialogue system is to satisfy a user request; however, what the user really wants is at best partially observable.", "labels": [], "entities": []}, {"text": "We handle the problem of partial observability by inverting the conventional notion of state in a dialogue.", "labels": [], "entities": []}, {"text": "The world is viewed as partially unobservable -the underlying state is the intention of the user with respect to the dialogue task.", "labels": [], "entities": []}, {"text": "The only observations about the user's state are the speech utterances given by the speech recognition system, from which some knowledge about the current state can be inferred.", "labels": [], "entities": []}, {"text": "By accepting the partial observability of the world, the dialogue problem becomes one that is addressed by Partially Observable Markov Decision Processes (POMDPs).", "labels": [], "entities": []}, {"text": "Finding an optimal policy fora given POMDP model corresponds to defining an optimal dialogue strategy.", "labels": [], "entities": []}, {"text": "Optimality is attained within the context of a set of rewards that define the relative value of taking various actions.", "labels": [], "entities": []}, {"text": "We will show that conventional MDP solutions are insufficient, and that a more robust methodology is required.", "labels": [], "entities": []}, {"text": "Note that in the limit of perfect sensing, the POMDP policy will be equivalent to an MDP policy.", "labels": [], "entities": []}, {"text": "What the POMDP policy offers is an ability to compensate appropriately for better or worse sensing.", "labels": [], "entities": []}, {"text": "As the speech recognition degrades, the POMDP policy acquires reward more slowly, but makes fewer mistakes and blind guesses compared to a conventional MDP policy.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 7, "end_pos": 25, "type": "TASK", "confidence": 0.7837948501110077}, {"text": "reward", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9516322612762451}]}, {"text": "There are several POMDP algorithms that maybe the natural choice for policy generation).", "labels": [], "entities": [{"text": "policy generation", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.7882331609725952}]}, {"text": "However, solving real world dialogue scenarios is computationally intractable for full-blown POMDP solvers, as the complexity is doubly exponential in the number of states.", "labels": [], "entities": [{"text": "POMDP solvers", "start_pos": 93, "end_pos": 106, "type": "TASK", "confidence": 0.8264357447624207}]}, {"text": "We therefore will use an algorithm for finding approximate solutions to POMDP-style problems and apply it to dialogue management.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 109, "end_pos": 128, "type": "TASK", "confidence": 0.8807315230369568}]}, {"text": "This algorithm, the Augmented MDP, was developed for mobile robot navigation, and operates by augmenting the state description with a compression of the current belief state.", "labels": [], "entities": [{"text": "mobile robot navigation", "start_pos": 53, "end_pos": 76, "type": "TASK", "confidence": 0.6661240259806315}]}, {"text": "By representing the belief state succinctly with its entropy, belief-space planning can be approximated without the expected complexity.", "labels": [], "entities": []}, {"text": "In the first section of this paper, we develop the model of dialogue interaction.", "labels": [], "entities": []}, {"text": "This model allows fora more natural description of dialogue problems, and in particular allows for intuitive handling of noisy and ambiguous dialogues.", "labels": [], "entities": []}, {"text": "Few existing dialogues can handle ambiguous input, typically relying on natural language processing to resolve semantic ambiguities).", "labels": [], "entities": []}, {"text": "Secondly, we present a description of an example problem domain, and finally we present experimental results comparing the performance of the POMDP (approximated by the Augmented MDP) to conventional MDP dialogue strategies.", "labels": [], "entities": []}], "datasetContent": [{"text": "We compared the performance of the three algorithms (conventional MDP, POMDP approximated by the Augmented MDP, and exact POMDP) over the example domain.", "labels": [], "entities": []}, {"text": "The metric used was to look at the total reward accumulated over the course of an extended test.", "labels": [], "entities": []}, {"text": "In order to perform this full test, the observations and states from the underlying MDP were generated stochastically from the model and then given to the policy.", "labels": [], "entities": []}, {"text": "The action taken by the policy was returned to the model, and the policy was rewarded based on the state-action-observation triplet.", "labels": [], "entities": []}, {"text": "The experiments were run fora total of 100 dialogues, where each dialogue is considered to be a cycle of observation-action utterances from the start state request_begun through a sequence of states and back to the start state.", "labels": [], "entities": []}, {"text": "The time was normalised by the length of each dialogue cycle.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: An example dialogue. Note that the robot chooses the correct action in the final two exchanges, even though the  utterance is both noisy and ambiguous.", "labels": [], "entities": []}, {"text": " Table 3: A comparison of the rewards accumulated for the two algorithms (approximate POMDP and conventional MDP)  using the full model.", "labels": [], "entities": []}, {"text": " Table 4: A comparison of the rewards accumulated for the two algorithms using the full model on real users, with results  given as mean +/-std. dev.", "labels": [], "entities": []}]}