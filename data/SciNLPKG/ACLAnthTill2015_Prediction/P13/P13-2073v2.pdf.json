{"title": [{"text": "Language Independent Connectivity Strength Features for Phrase Pivot Statistical Machine Translation", "labels": [], "entities": [{"text": "Phrase Pivot Statistical Machine Translation", "start_pos": 56, "end_pos": 100, "type": "TASK", "confidence": 0.7444461107254028}]}], "abstractContent": [{"text": "An important challenge to statistical machine translation (SMT) is the lack of parallel data for many language pairs.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 26, "end_pos": 63, "type": "TASK", "confidence": 0.8365482042233149}]}, {"text": "One common solution is to pivot through a third language for which there exist parallel corpora with the source and target languages.", "labels": [], "entities": []}, {"text": "Although pivoting is a robust technique, it introduces some low quality translations.", "labels": [], "entities": []}, {"text": "In this paper, we present two language-independent features to improve the quality of phrase-pivot based SMT.", "labels": [], "entities": [{"text": "phrase-pivot based SMT", "start_pos": 86, "end_pos": 108, "type": "TASK", "confidence": 0.472172091404597}]}, {"text": "The features, source connectivity strength and target connectivity strength reflect the quality of projected alignments between the source and target phrases in the pivot phrase table.", "labels": [], "entities": []}, {"text": "We show positive results (0.6 BLEU points) on Persian-Arabic SMT as a case study.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.9990990161895752}, {"text": "SMT", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.6091665029525757}]}], "introductionContent": [{"text": "One of the main issues in statistical machine translation (SMT) is the scarcity of parallel data for many language pairs especially when the source and target languages are morphologically rich.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 26, "end_pos": 63, "type": "TASK", "confidence": 0.8260287344455719}]}, {"text": "A common SMT solution to the lack of parallel data is to pivot the translation through a third language (called pivot or bridge language) for which there exist abundant parallel corpora with the source and target languages.", "labels": [], "entities": [{"text": "SMT", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.993823766708374}]}, {"text": "The literature covers many pivoting techniques.", "labels": [], "entities": []}, {"text": "One of the best performing techniques, phrase pivoting (, builds an induced new phrase table between the source and target.", "labels": [], "entities": [{"text": "phrase pivoting", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.7991074025630951}]}, {"text": "One of the main issues of this technique is that the size of the newly created pivot phrase table is very large.", "labels": [], "entities": []}, {"text": "Moreover, many of the produced phrase pairs are of low quality which affects the translation choices during decoding and the overall translation quality.", "labels": [], "entities": []}, {"text": "In this paper, we introduce language independent features to determine the quality of the pivot phrase pairs between source and target.", "labels": [], "entities": []}, {"text": "We show positive results (0.6 BLEU points) on Persian-Arabic SMT.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.9989514350891113}, {"text": "Persian-Arabic SMT", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.5824322402477264}]}, {"text": "Next, we briefly discuss some related work.", "labels": [], "entities": []}, {"text": "We then review two common pivoting strategies and how we use them in Section 3.", "labels": [], "entities": []}, {"text": "This is followed by our approach to using connectivity strength features in Section 4.", "labels": [], "entities": []}, {"text": "We present our experimental results in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present a set of baseline experiments including a simple filtering technique to overcome the huge expansion of the pivot phrase table.", "labels": [], "entities": []}, {"text": "Then we present our results in using connectivity strength features to improve Persian-Arabic pivot translation quality.", "labels": [], "entities": [{"text": "Persian-Arabic pivot translation", "start_pos": 79, "end_pos": 111, "type": "TASK", "confidence": 0.434258371591568}]}, {"text": "Persian: \"A\u03c2tmAd\"myAn\"dw\"k\u0161wr \" \" \" \" \"' \u202b\u0627%$#\"\u062f\u202c \" \u202b)(\"\u0646\u202c \" \u202b\u062f\u0648\u202c \" \u202b.-,\u0631\u202c '\" \" \" \" \" \" \" \" \" \" \" \" \" \"'trust\"between\"the\"two\"countries'\" English: \"trust\"between\"the\"two\"countries\" Arabic:\" \"Al\u03b8q\u0127\"byn\"Aldwltyn \" \" \" \" \" \"' /012\u202b\u0627\u202c \" 34 \" 3$2\u202b\u062725\u0648\u202c '\" \" \" \" \" \" \" \" \" \" \" \" \" \"'the\"trust\"between\"the\"two\"countries'\" Persian: \"AyjAd\"cnd\"\u0161rkt\"m\u0161trk \" \" \" \" \"' \u202b\u0627$#\"\u062f\u202c \" &'( \" )*+, \" \u202b0/.+\u06a9\u202c '\" \" \" \" \" \" \" \" \" \" \" \" \" \"'Establish\"few\"joint\"companies'\" English: \"joint\"ventures\" Arabic:\" \"b\u03c2D\"\u0161rkAt\"AlmqAwlAt\"fy\"Albld\" \"' 123 \" \u202b,+5\"\u062a\u202c \" \u202b\u062798\"\u06486\u062a\u202c \" :; \" &<=>\u202b\u0627\u202c '\" \" \" \" \" \" \" \" \" \" \" \" \" \"'Some\"construcBon\"companies\"in\"the\"country'\"  In our pivoting experiments, we build two SMT models.", "labels": [], "entities": [{"text": "SMT", "start_pos": 675, "end_pos": 678, "type": "TASK", "confidence": 0.9848321080207825}]}, {"text": "One model to translate from Persian to English and another model to translate from English to Arabic.", "labels": [], "entities": []}, {"text": "The English-Arabic parallel corpus is about 2.8M sentences (\u224860M words) available from LDC 4 and GALE 5 constrained data.", "labels": [], "entities": [{"text": "GALE 5 constrained data", "start_pos": 97, "end_pos": 120, "type": "DATASET", "confidence": 0.8256595730781555}]}, {"text": "We use an in-house Persian-English parallel corpus of about 170K sentences and 4M words.", "labels": [], "entities": []}, {"text": "Word alignment is done using GIZA++.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.718836784362793}]}, {"text": "For Arabic language modeling, we use 200M words from the Arabic Gigaword Corpus together with the Arabic side of our training data.", "labels": [], "entities": [{"text": "Arabic language modeling", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.660781462987264}, {"text": "Arabic Gigaword Corpus", "start_pos": 57, "end_pos": 79, "type": "DATASET", "confidence": 0.7282749017079672}]}, {"text": "We use 5-grams for all language models (LMs) implemented using the SRILM toolkit).", "labels": [], "entities": [{"text": "SRILM toolkit", "start_pos": 67, "end_pos": 80, "type": "DATASET", "confidence": 0.8601061105728149}]}, {"text": "For English language modeling, we use English Gigaword Corpus with 5-gram LM using the KenLM toolkit.", "labels": [], "entities": [{"text": "English language modeling", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.6747593879699707}, {"text": "English Gigaword Corpus", "start_pos": 38, "end_pos": 61, "type": "DATASET", "confidence": 0.7867494424184164}]}, {"text": "All experiments are conducted using the Moses phrase-based SMT system ( optimization.", "labels": [], "entities": [{"text": "SMT", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.926966667175293}]}, {"text": "For Persian-English translation model, weights are optimized using a set 1000 sentences randomly sampled from the parallel corpus while the English-Arabic translation model weights are optimized using a set of 500 sentences from the 2004 NIST MT evaluation test set (MT04).", "labels": [], "entities": [{"text": "Persian-English translation", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.5599988400936127}, {"text": "NIST MT evaluation test set (MT04)", "start_pos": 238, "end_pos": 272, "type": "DATASET", "confidence": 0.8582667857408524}]}, {"text": "The optimized weights are used for ranking and filtering (discussed in Section 3.3).", "labels": [], "entities": [{"text": "ranking", "start_pos": 35, "end_pos": 42, "type": "TASK", "confidence": 0.9645395278930664}]}, {"text": "We use a maximum phrase length of size 8 across all models.", "labels": [], "entities": []}, {"text": "We report results on an inhouse Persian-Arabic evaluation set of 536 sentences with three references.", "labels": [], "entities": []}, {"text": "We evaluate using BLEU-4 () and METEOR.", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9988620281219482}, {"text": "METEOR", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9941890239715576}]}, {"text": "We compare the performance of sentence pivoting against phrase pivoting with different filtering thresholds.", "labels": [], "entities": []}, {"text": "The results are presented in.", "labels": [], "entities": []}, {"text": "In general, the phrase pivoting outperforms the sentence pivoting even when we use a small filtering threshold of size 100.", "labels": [], "entities": []}, {"text": "Moreover, the higher the threshold the better the performance but with a diminishing gain.", "labels": [], "entities": []}, {"text": "We use the best performing setup across the rest of the experiments.", "labels": [], "entities": []}, {"text": "In this experiment, we test the performance of adding the connectivity strength features (+Conn) to the best performing phrase pivoting model (Phrase Pivot F1K).", "labels": [], "entities": []}, {"text": "The results in show that we get a nice improvement of \u22480.6/0.3 (BLEU/METEOR) points by adding the connectivity strength features.", "labels": [], "entities": [{"text": "BLEU/METEOR)", "start_pos": 64, "end_pos": 76, "type": "METRIC", "confidence": 0.8731851726770401}]}, {"text": "The differences in BLEU scores between this setup and all other systems are statistically significant above the 95% level.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9978690147399902}]}, {"text": "Statistical significance is computed using paired bootstrap resampling).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table  Translation Model  Size  # Phrase Pairs  Size  Persian-English  \u22484M words  96,04,103  1.1GB  English-Arabic  \u224860M words  111,702,225  14GB  Pivot Persian-Arabic  N/A  39,199,269,195 \u22482.5TB", "labels": [], "entities": []}, {"text": " Table 2. In  general, the phrase pivoting outperforms the sen- tence pivoting even when we use a small filtering  threshold of size 100. Moreover, the higher the  threshold the better the performance but with a di- minishing gain.", "labels": [], "entities": []}, {"text": " Table 2: Sentence pivoting versus phrase pivoting  with different filtering thresholds (100/500/1000).", "labels": [], "entities": [{"text": "Sentence pivoting", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.8839017748832703}]}, {"text": " Table 3: Connectivity strength features experi- ment result.", "labels": [], "entities": []}]}