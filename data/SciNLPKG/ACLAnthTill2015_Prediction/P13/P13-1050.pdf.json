{"title": [{"text": "Feature-Based Selection of Dependency Paths in Ad Hoc Information Retrieval", "labels": [], "entities": [{"text": "Ad Hoc Information Retrieval", "start_pos": 47, "end_pos": 75, "type": "TASK", "confidence": 0.5711347460746765}]}], "abstractContent": [{"text": "Techniques that compare short text segments using dependency paths (or simply, paths) appear in a wide range of automated language processing applications including question answering (QA).", "labels": [], "entities": [{"text": "question answering (QA)", "start_pos": 165, "end_pos": 188, "type": "TASK", "confidence": 0.8911216497421265}]}, {"text": "However, few models in ad hoc information retrieval (IR) use paths for document ranking due to the prohibitive cost of parsing a retrieval collection.", "labels": [], "entities": [{"text": "ad hoc information retrieval (IR)", "start_pos": 23, "end_pos": 56, "type": "TASK", "confidence": 0.8339240636144366}]}, {"text": "In this paper, we introduce a flexible notion of paths that describe chains of words on a dependency path.", "labels": [], "entities": []}, {"text": "These chains, or catenae, are readily applied in standard IR models.", "labels": [], "entities": [{"text": "IR", "start_pos": 58, "end_pos": 60, "type": "TASK", "confidence": 0.9506163001060486}]}, {"text": "Informative catenae are selected using supervised machine learning with linguistically informed features and compared to both non-linguistic terms and catenae selected heuristically with filters derived from work on paths.", "labels": [], "entities": []}, {"text": "Automatically selected catenae of 1-2 words deliver significant performance gains on three TREC collections.", "labels": [], "entities": [{"text": "TREC collections", "start_pos": 91, "end_pos": 107, "type": "DATASET", "confidence": 0.7366456389427185}]}], "introductionContent": [{"text": "In the past decade, an increasing number of techniques have used complex and effective syntactic and semantic features to determine the similarity, entailment or alignment between short texts.", "labels": [], "entities": [{"text": "determine the similarity, entailment or alignment between short texts", "start_pos": 122, "end_pos": 191, "type": "TASK", "confidence": 0.6868428856134414}]}, {"text": "These approaches are motivated by the idea that sentence meaning can be flexibly captured by the syntactic and semantic relations between words, and encoded in dependency parse tree fragments.", "labels": [], "entities": []}, {"text": "Dependency paths (or simply, paths) are compared using techniques such as tree edit distance, relation probability () and parse tree alignment ().", "labels": [], "entities": [{"text": "parse tree alignment", "start_pos": 122, "end_pos": 142, "type": "TASK", "confidence": 0.6956360538800558}]}, {"text": "Much work on sentence similarity using dependency paths focuses on question answering (QA) where textual inference requires attention to linguistic detail.", "labels": [], "entities": [{"text": "sentence similarity", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7201931029558182}, {"text": "question answering (QA)", "start_pos": 67, "end_pos": 90, "type": "TASK", "confidence": 0.8335020661354064}]}, {"text": "Dependency-based techniques can also be highly effective for ad hoc information retrieval (IR)).", "labels": [], "entities": [{"text": "ad hoc information retrieval (IR))", "start_pos": 61, "end_pos": 95, "type": "TASK", "confidence": 0.8020725420543126}]}, {"text": "However, few path-based methods have been explored for ad hoc IR, largely because parsing large document collections is computationally prohibitive.", "labels": [], "entities": [{"text": "IR", "start_pos": 62, "end_pos": 64, "type": "TASK", "confidence": 0.9248635768890381}, {"text": "parsing large document collections", "start_pos": 82, "end_pos": 116, "type": "TASK", "confidence": 0.8973159343004227}]}, {"text": "In this paper, we explore a flexible application of dependency paths that overcomes this difficulty.", "labels": [], "entities": []}, {"text": "We reduce paths to chains of words called catenae ( ) that capture salient semantic content in an underspecified manner.", "labels": [], "entities": []}, {"text": "Catenae can be used as lexical units in a reformulated query to explicitly indicate important word relationships while retaining efficient and flexible proximity matching.", "labels": [], "entities": []}, {"text": "Crucially, this does not require parsing documents.", "labels": [], "entities": [{"text": "parsing documents", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.8911851942539215}]}, {"text": "Moreover, catenae are compatible with a variety of existing IR models.", "labels": [], "entities": []}, {"text": "We hypothesize that catenae identify most units of salient knowledge in text.", "labels": [], "entities": []}, {"text": "This is because they area condition for ellipsis, in which salient knowledge can be successfully omitted from text ( ).", "labels": [], "entities": []}, {"text": "To our knowledge, this paper is the first time that catenae are proposed as a means for term selection in IR, and where ellipsis is considered as a means for identification of semantic units.", "labels": [], "entities": [{"text": "term selection", "start_pos": 88, "end_pos": 102, "type": "TASK", "confidence": 0.7045687586069107}, {"text": "IR", "start_pos": 106, "end_pos": 108, "type": "TASK", "confidence": 0.6836971044540405}]}, {"text": "We also extend previous work with development of a linguistically informed, supervised machine learning technique for selection of informative catenae.", "labels": [], "entities": []}, {"text": "Previous heuristic filters for dependency paths) can exclude informative relations.", "labels": [], "entities": []}, {"text": "Alternatively, treating all paths as equally informative ( can generate noisy word relations and is computationally intensive.", "labels": [], "entities": []}, {"text": "The challenge of path selection is that no explicit information in text indicates which paths are relevant.", "labels": [], "entities": [{"text": "path selection", "start_pos": 17, "end_pos": 31, "type": "TASK", "confidence": 0.7285225987434387}]}, {"text": "Consider the catenae captured by heuristic filters for the TREC 1 query, 'What role does blood-alcohol level play in automobile accident fatalities' (#358,", "labels": [], "entities": [{"text": "TREC 1 query", "start_pos": 59, "end_pos": 71, "type": "DATASET", "confidence": 0.6151967446009318}]}], "datasetContent": [{"text": "Catenae selection is framed as a supervised classification problem trained on binary human judgments of informativeness: how well catenae represent a query and discriminate between relevant and non-relevant documents in a collection.", "labels": [], "entities": [{"text": "Catenae selection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8078364431858063}]}, {"text": "Kappa for two annotators on catenae in 100 sample queries was 0.63, and test-retest reliability for individual judges was similar (0.62) . Although this is low, human annotations produced consistently better classification accuracy than other labelling methods explored.", "labels": [], "entities": [{"text": "Kappa", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9271891713142395}, {"text": "accuracy", "start_pos": 223, "end_pos": 231, "type": "METRIC", "confidence": 0.8034149408340454}]}, {"text": "We use the Weka () AdaBoost.M1 meta-classifier) with unpruned C4.5 decision trees as base learners to classify catenae as informative or not.", "labels": [], "entities": [{"text": "Weka () AdaBoost.M1 meta-classifier", "start_pos": 11, "end_pos": 46, "type": "DATASET", "confidence": 0.9130269140005112}]}, {"text": "Adaboost.M1 boosts decisions over T weak learners for T features using weighted majority voting.", "labels": [], "entities": []}, {"text": "At each round, predictions of anew learner are focused on incorrectly classified examples from the previous round.", "labels": [], "entities": []}, {"text": "Adaboost.M1 was selected in preference to other algorithms because it performed better in preliminary experiments, leverages many weak features to advantage, and usually does not overfit ().", "labels": [], "entities": []}, {"text": "Predictions are made using 10-fold crossvalidation.", "labels": [], "entities": []}, {"text": "There are roughly three times the number of uninformative catenae compared to informative catenae.", "labels": [], "entities": []}, {"text": "In addition, the number of training examples is small (1295 to 5163 per collection).", "labels": [], "entities": []}, {"text": "To improve classifier accuracy, the training data for each collection is supplemented and balanced by generating examples from queries for isSeq Minimum perplexity of ngrams with length 2, 3, and 4 in a window of up to a 3 words around the site of catenae omission.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9577130675315857}]}, {"text": "This is the area where ungrammaticality maybe introduced.", "labels": [], "entities": []}, {"text": "For the remainder R=`ABCDE&ABE' we compute ppl1 for I&ABE, &AB, ABE, &A, AB, BEJ.", "labels": [], "entities": [{"text": "ABCDE", "start_pos": 21, "end_pos": 26, "type": "METRIC", "confidence": 0.9620875716209412}, {"text": "ABE", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.966999888420105}, {"text": "ABE", "start_pos": 54, "end_pos": 57, "type": "METRIC", "confidence": 0.9859049916267395}, {"text": "ABE", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9463445544242859}, {"text": "BEJ", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.9437782764434814}]}, {"text": "Baselines area unigram query likelihood (QL) model (bag of words) and a highly effective sequential dependence (SD) variant of the Markov random field (MRF) model).", "labels": [], "entities": [{"text": "area unigram query likelihood (QL)", "start_pos": 10, "end_pos": 44, "type": "METRIC", "confidence": 0.680194262947355}]}, {"text": "SD uses a linear combination of three cliques of terms, where each clique is prioritized by a weight \u03bb c . The first clique contains individual words (query likelihood QL), \u03bb 1 = 0.85.", "labels": [], "entities": []}, {"text": "The second clique contains query bigrams that match document bigrams in 2-word ordered windows ('#1'), \u03bb 2 = 0.1.", "labels": [], "entities": []}, {"text": "The third clique uses the same bigrams as clique 2 with an 8-word unordered window ('#uw8'), \u03bb 3 = 0.05.", "labels": [], "entities": []}, {"text": "For example, the query new york city in Indri 4 query language is: #weight( \u03bb1 #combine(new york city) \u03bb2 #combine(#1(new york) #1(york city)) \u03bb3 #combine(#uw8(new york) #uw8(york city))) SD is a competitive baseline in IR ().", "labels": [], "entities": [{"text": "Indri 4 query language", "start_pos": 40, "end_pos": 62, "type": "DATASET", "confidence": 0.8900692462921143}, {"text": "IR", "start_pos": 220, "end_pos": 222, "type": "TASK", "confidence": 0.7773084044456482}]}, {"text": "Our reformulated model uses the same query format as SD, but the second and third cliques contain filtered catenae instead of query bigrams.", "labels": [], "entities": []}, {"text": "In addition, because catenae maybe multi-word units, we adjust the unordered window size to 4 * |c|.", "labels": [], "entities": []}, {"text": "So, if two catenae 'york' and 'new york city' are selected, the last clique has the form: This query representation enables word relations to be explicitly indicated while maintaining efficient and flexible matching of catenae in documents.", "labels": [], "entities": []}, {"text": "Moreover, it does not use dependency relations between words during retrieval, so there is no need to parse a collection.", "labels": [], "entities": []}, {"text": "Experiments compare queries reformulated using catenae selected by baseline filters and our supervised selection method (SFeat) to SD and a bag-of-words model (QL).", "labels": [], "entities": []}, {"text": "We also compare IR effectiveness of all catenae filtered using SFeat with approaches that combine SFeat with baseline filters.", "labels": [], "entities": [{"text": "IR", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.8474560976028442}]}, {"text": "All models are implemented using the Indri retrieval engine version 4.12.", "labels": [], "entities": []}, {"text": "show significant improvement in mean average precision (MAP) of queries using catenae compared to QL.", "labels": [], "entities": [{"text": "mean average precision (MAP)", "start_pos": 32, "end_pos": 60, "type": "METRIC", "confidence": 0.9095652302106222}]}, {"text": "Consistent improvements over SD are also demonstrated for supervised selection applied to all catenae (SFeat) and catenae with only 1-2 words (SF-12) across all collections.", "labels": [], "entities": []}, {"text": "Overall, changes are small and fairly robust, with one half to two thirds of all queries showing less than 10% change in MAP.", "labels": [], "entities": [{"text": "MAP", "start_pos": 121, "end_pos": 124, "type": "METRIC", "confidence": 0.8653153777122498}]}], "tableCaptions": [{"text": " Table 3: Average classifier precision (Pr) and recall  (R) over 10 folds. Pr is % positive predictions  that are correct. R is % positive labeled instances  predicted as positive. A combination of all classes  marginally performs best.", "labels": [], "entities": [{"text": "Average classifier precision (Pr)", "start_pos": 10, "end_pos": 43, "type": "METRIC", "confidence": 0.7816528677940369}, {"text": "recall  (R)", "start_pos": 48, "end_pos": 59, "type": "METRIC", "confidence": 0.9763981699943542}]}, {"text": " Table 4: IR results using filtered catenae consistently improve over non-linguistic methods.  Significance(p < .05) shown compared to QL ( \u2020) and SD ( \u2021).", "labels": [], "entities": [{"text": "IR", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.9587967991828918}, {"text": "Significance", "start_pos": 95, "end_pos": 107, "type": "METRIC", "confidence": 0.9640194177627563}]}, {"text": " Table 5: Results with supervised selection of catenae with specified length (SF-12, SF-123) are more  effective than combinations of SFeat with heuristic NomEnd (SF-NE) or GovDep (SF-GD).", "labels": [], "entities": []}]}