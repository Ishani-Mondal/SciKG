{"title": [{"text": "Iterative Transformation of Annotation Guidelines for Constituency Parsing", "labels": [], "entities": [{"text": "Constituency Parsing", "start_pos": 54, "end_pos": 74, "type": "TASK", "confidence": 0.7136821150779724}]}], "abstractContent": [{"text": "This paper presents an effective algorithm of annotation adaptation for constituency treebanks, which transforms a treebank from one annotation guideline to another with an iterative optimization procedure , thus to build a much larger treebank to train an enhanced parser without increasing model complexity.", "labels": [], "entities": [{"text": "annotation adaptation", "start_pos": 46, "end_pos": 67, "type": "TASK", "confidence": 0.7687375545501709}]}, {"text": "Experiments show that the transformed Tsinghua Chi-nese Treebank as additional training data brings significant improvement over the baseline trained on Penn Chinese Tree-bank only.", "labels": [], "entities": [{"text": "Tsinghua Chi-nese Treebank", "start_pos": 38, "end_pos": 64, "type": "DATASET", "confidence": 0.8439984520276388}, {"text": "Penn Chinese Tree-bank", "start_pos": 153, "end_pos": 175, "type": "DATASET", "confidence": 0.9767558574676514}]}], "introductionContent": [{"text": "Annotated data have become an indispensable resource for many natural language processing (NLP) applications.", "labels": [], "entities": []}, {"text": "On one hand, the amount of existing labeled data is not sufficient; on the other hand, however there exists multiple annotated data with incompatible annotation guidelines for the same NLP task.", "labels": [], "entities": []}, {"text": "For example, the People's Daily corpus () and Chinese Penn Treebank (CTB) () are publicly available for Chinese segmentation.", "labels": [], "entities": [{"text": "People's Daily corpus", "start_pos": 17, "end_pos": 38, "type": "DATASET", "confidence": 0.9382202923297882}, {"text": "Chinese Penn Treebank (CTB)", "start_pos": 46, "end_pos": 73, "type": "DATASET", "confidence": 0.939213752746582}, {"text": "Chinese segmentation", "start_pos": 104, "end_pos": 124, "type": "TASK", "confidence": 0.6350765079259872}]}, {"text": "An available treebank is a major resource for syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.9018823206424713}]}, {"text": "However, it is often a key bottleneck to acquire credible treebanks.", "labels": [], "entities": []}, {"text": "Various treebanks have been constructed based on different annotation guidelines.", "labels": [], "entities": []}, {"text": "In addition to the most popular CTB, Tsinghua Chinese Treebank (TC-T)) is another real large-scale treebank for Chinese constituent parsing.", "labels": [], "entities": [{"text": "Tsinghua Chinese Treebank (TC-T))", "start_pos": 37, "end_pos": 70, "type": "DATASET", "confidence": 0.7867919107278188}, {"text": "Chinese constituent parsing", "start_pos": 112, "end_pos": 139, "type": "TASK", "confidence": 0.6225654681523641}]}, {"text": "illustrates some differences between CTB and TCT in grammar category and syntactic structure.", "labels": [], "entities": []}, {"text": "Unfortunately, these heterogeneous treebanks cannot be directly merged together for training a parsing model.", "labels": [], "entities": []}, {"text": "Such divergences cause a great waste of human effort.", "labels": [], "entities": []}, {"text": "Therefore, it is highly desirable to transform a treebank into another compatible with another annotation guideline.", "labels": [], "entities": []}, {"text": "In this paper, we focus on harmonizing heterogeneous treebanks to improve parsing performance.", "labels": [], "entities": [{"text": "parsing", "start_pos": 74, "end_pos": 81, "type": "TASK", "confidence": 0.9742001891136169}]}, {"text": "We first propose an effective approach to automatic treebank transformation from one annotation guideline to another.", "labels": [], "entities": [{"text": "automatic treebank transformation", "start_pos": 42, "end_pos": 75, "type": "TASK", "confidence": 0.5742859045664469}]}, {"text": "For convenience of reference, a treebank with our desired annotation guideline is named as target treebank, and a treebank with a differtn annotation guideline is named as source treebank.", "labels": [], "entities": []}, {"text": "Our approach proceeds in three steps.", "labels": [], "entities": []}, {"text": "A parser is firstly trained on source treebank.", "labels": [], "entities": []}, {"text": "It is used to relabel the raw sentences of target treebank, to acquire parallel training data with two heterogeneous annotation guidelines.", "labels": [], "entities": []}, {"text": "Then, an annotation transformer is trained on the parallel training data to model the annotation inconsistencies.", "labels": [], "entities": []}, {"text": "In the last step, a parser trained on target treebank is used to generate k-best parse trees with target annotation for source sentences.", "labels": [], "entities": []}, {"text": "Then the optimal parse trees are selected by the annotation transformer.", "labels": [], "entities": []}, {"text": "In this way, the source treebank is transformed to another with our desired annotation guideline.", "labels": [], "entities": []}, {"text": "Then we propose an optimization strategy of iterative training to further improve the transformation performance.", "labels": [], "entities": []}, {"text": "At each iteration, the annotation transformation of sourceto-target and target-to-source are both performed.", "labels": [], "entities": []}, {"text": "The transformed treebank is used to provide better annotation guideline for the parallel training data of next iteration.", "labels": [], "entities": []}, {"text": "As a result, the better parallel training data will bring an improved annotation transformer at next iteration.", "labels": [], "entities": []}, {"text": "We perform treebank transformation from TC- T to CTB, in order to obtain additional treebank to improve a parser.", "labels": [], "entities": []}, {"text": "Experiments on Chinese constituent parsing show that, the iterative training strategy outperforms the basic annotation transformation baseline.", "labels": [], "entities": [{"text": "Chinese constituent parsing", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.5695067246754965}]}, {"text": "With addidional transformed treebank, the improved parser achieves an F-measure of 0.95% absolute improvement over the baseline parser trained on CTB only.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.999580442905426}]}], "datasetContent": [{"text": "We conduct the experiments of treebank transformation from TCT to CTB.", "labels": [], "entities": [{"text": "treebank transformation", "start_pos": 30, "end_pos": 53, "type": "TASK", "confidence": 0.6521907597780228}]}, {"text": "CTB 5.1 is used as the target treebank.", "labels": [], "entities": [{"text": "CTB 5.1", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9735870361328125}]}, {"text": "We follow the conventional corpus splitting of CTB 5.1: articles 001-270 and 400-1151 are used for training, articles 271-300 are used as test data and articles 301-325 are used as developing data.", "labels": [], "entities": [{"text": "CTB 5.1", "start_pos": 47, "end_pos": 54, "type": "DATASET", "confidence": 0.922606885433197}]}, {"text": "We use slightly modified version of CTB 5.1 by deleting all the function tags and empty categories, e.g., *OP*, using Tsurgeon ().", "labels": [], "entities": [{"text": "CTB 5.1", "start_pos": 36, "end_pos": 43, "type": "DATASET", "confidence": 0.9247640073299408}]}, {"text": "The whole TCT 1.0 is taken as the source treebank for training the annotation transformer.", "labels": [], "entities": [{"text": "TCT 1.0", "start_pos": 10, "end_pos": 17, "type": "DATASET", "confidence": 0.7787831723690033}]}, {"text": "The Berkeley parsing model is trained with 5 split-merge iterations.", "labels": [], "entities": [{"text": "Berkeley parsing", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.5010421723127365}]}, {"text": "And we run the Berkeley parser in 100-best mode and construct the 20-fold cross validation training as described in.", "labels": [], "entities": []}, {"text": "In this way, we acquire the parallel parse trees for training the annotation transformer.", "labels": [], "entities": []}, {"text": "In this paper, we use bracketing F 1 as the ParseVal metric provided by EVALB 1 for all experiments.", "labels": [], "entities": [{"text": "bracketing F 1", "start_pos": 22, "end_pos": 36, "type": "METRIC", "confidence": 0.722289502620697}, {"text": "ParseVal metric", "start_pos": 44, "end_pos": 59, "type": "METRIC", "confidence": 0.9740965962409973}, {"text": "EVALB 1", "start_pos": 72, "end_pos": 79, "type": "DATASET", "confidence": 0.8140482306480408}]}], "tableCaptions": [{"text": " Table 1: The performance of treebank annotation transformation using iterative training.", "labels": [], "entities": [{"text": "treebank annotation transformation", "start_pos": 29, "end_pos": 63, "type": "TASK", "confidence": 0.6454991400241852}]}]}