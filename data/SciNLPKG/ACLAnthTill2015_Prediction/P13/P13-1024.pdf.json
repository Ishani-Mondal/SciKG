{"title": [{"text": "Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media", "labels": [], "entities": [{"text": "Linking Tweets to News", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8865586221218109}]}], "abstractContent": [{"text": "Many current Natural Language Processing [NLP] techniques work well assuming a large context of text as input data.", "labels": [], "entities": [{"text": "Natural Language Processing [NLP]", "start_pos": 13, "end_pos": 46, "type": "TASK", "confidence": 0.7266510128974915}]}, {"text": "However they become ineffective when applied to short texts such as Twitter feeds.", "labels": [], "entities": []}, {"text": "To overcome the issue, we want to find a related newswire document to a given tweet to provide contextual support for NLP tasks.", "labels": [], "entities": []}, {"text": "This requires robust model-ing and understanding of the semantics of short texts.", "labels": [], "entities": []}, {"text": "The contribution of the paper is twofold: 1.", "labels": [], "entities": []}, {"text": "we introduce the Linking-Tweets-to-News task as well as a dataset of linked tweet-news pairs, which can benefit many NLP applications; 2.", "labels": [], "entities": []}, {"text": "in contrast to previous research which focuses on lexical features within the short texts (text-to-word information), we propose a graph based latent variable model that models the inter short text correlations (text-to-text information).", "labels": [], "entities": []}, {"text": "This is motivated by the observation that a tweet usually only covers one aspect of an event.", "labels": [], "entities": []}, {"text": "We show that using tweet specific feature (hashtag) and news specific feature (named entities) as well as temporal constraints, we are able to extract text-to-text correlations, and thus completes the semantic picture of a short text.", "labels": [], "entities": []}, {"text": "Our experiments show significant improvement of our new model over base-lines with three evaluation metrics in the new task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently there has been an increasing interest in language understanding of Twitter messages.", "labels": [], "entities": [{"text": "language understanding of Twitter messages", "start_pos": 50, "end_pos": 92, "type": "TASK", "confidence": 0.8369877219200135}]}, {"text": "Researchers were interested in sentiment analysis on Twitter feeds, and opinion mining towards political issues or politicians ().", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.9394560158252716}, {"text": "opinion mining", "start_pos": 72, "end_pos": 86, "type": "TASK", "confidence": 0.7351765334606171}]}, {"text": "Others () summarized tweets using topic models.", "labels": [], "entities": []}, {"text": "Although these NLP techniques are mature, their performance on tweets inevitably degrades, due to the inherent sparsity in short texts.", "labels": [], "entities": []}, {"text": "In the case of sentiment analysis, while people are able to achieve 87.5% accuracy) on a movie review dataset (), the performance drops to 75% ( ) on a sentence level movie review dataset).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.9672017991542816}, {"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9826367497444153}, {"text": "movie review dataset", "start_pos": 89, "end_pos": 109, "type": "DATASET", "confidence": 0.593630443016688}]}, {"text": "The problem worsens when some existing NLP systems cannot produce any results given the short texts.", "labels": [], "entities": []}, {"text": "Considering the following tweet: Pray for Mali...", "labels": [], "entities": []}, {"text": "A typical event extraction/discovery system) fails to discover the war event due to the lack of context information), and thus fails to shed light on the users focus/interests.", "labels": [], "entities": [{"text": "event extraction/discovery", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.8328947424888611}]}, {"text": "To enable the NLP tools to better understand Twitter feeds, we propose the task of linking a tweet to a news article that is relevant to the tweet, thereby augmenting the context of the tweet.", "labels": [], "entities": []}, {"text": "For example, we want to supplement the implicit context of the above tweet with a news article such as the following entitled: State of emergency declared in Mali where abundant evidence can be fed into an offthe-shelf event extraction/discovery system.", "labels": [], "entities": [{"text": "offthe-shelf event extraction/discovery", "start_pos": 206, "end_pos": 245, "type": "TASK", "confidence": 0.8274782061576843}]}, {"text": "To create a gold standard dataset, we download tweets spanning over 18 days, each with a url linking to a news article of CNN or NYTIMES, as well as all the news of CNN and NYTIMES published during the period.", "labels": [], "entities": [{"text": "NYTIMES", "start_pos": 129, "end_pos": 136, "type": "DATASET", "confidence": 0.5668926239013672}]}, {"text": "The goal is to predict the url referred news article based on the text in each tweet.", "labels": [], "entities": []}, {"text": "We believe many NLP tasks will benefit from this task.", "labels": [], "entities": []}, {"text": "In fact, in the topic modeling research, previous work already showed that by incorporating webpages whose urls are contained in tweets, the tweet clustering purity score was boosted from 0.280 to 0.392.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.8168664276599884}, {"text": "tweet clustering purity score", "start_pos": 141, "end_pos": 170, "type": "METRIC", "confidence": 0.6031276509165764}]}, {"text": "Given the few number of words in a tweet (14 words on average in our dataset), the traditional high dimensional surface word matching is lossy and fails to pinpoint the news article.", "labels": [], "entities": []}, {"text": "This constitutes a classic short text semantics impediment (.", "labels": [], "entities": []}, {"text": "Latent variable models are powerful by going beyond the surface word level and mapping short texts into a low dimensional dense vector).", "labels": [], "entities": []}, {"text": "Accordingly, we apply a latent variable model, namely, the Weighted Textual Matrix Factorization () to both the tweets and the news articles.", "labels": [], "entities": []}, {"text": "WTMF is a state-of-the-art unsupervised model that was tested on two short text similarity datasets: () and (, which outperforms Latent Semantic Analysis [LSA] () and Latent Dirichelet Allocation [LDA] () by a large margin.", "labels": [], "entities": [{"text": "WTMF", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9399296641349792}]}, {"text": "We employ it as a strong baseline in this task as it exploits and effectively models the missing words in a tweet, in practice adding thousands of more features for the tweet, by contrast LDA, for example, only leverages observed words (14 features) to infer the latent vector fora tweet.", "labels": [], "entities": []}, {"text": "Apart from the data sparseness, our dataset proposes another challenge: a tweet usually covers only one aspect of an event.", "labels": [], "entities": []}, {"text": "In our previous example, the tweet only contains the location Mali while the event is about French army participated in Mali war.", "labels": [], "entities": []}, {"text": "In this scenario, we would like to find the missing elements of the tweet such as French, war from other short texts, to complete the semantic picture of Pray in Mali tweet.", "labels": [], "entities": [{"text": "Pray in Mali tweet", "start_pos": 154, "end_pos": 172, "type": "DATASET", "confidence": 0.8295548558235168}]}, {"text": "One drawback of WTMF for our purposes is that it simply models the text-to-word information without leveraging the correlation between short texts.", "labels": [], "entities": []}, {"text": "While this is acceptable on standard short text similarity datasets (data points are independently generated), it ignores some valuable information characteristically present in our dataset: (1) The tweet specific features such as hashtags.", "labels": [], "entities": []}, {"text": "Hashtags prove to be a direct indication of the semantics of tweets; (2) The news specific features columbia.edu/ \u02dc weiwei such as named entities in a document.", "labels": [], "entities": []}, {"text": "Named entities acquired from a news document, typically with high accuracy using Named Entity Recognition tools, maybe particularly informative.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9948247671127319}]}, {"text": "If two texts mention the same entities then they might describe the same event; (3) The temporal information in both genres (tweets and news articles).", "labels": [], "entities": []}, {"text": "We note that there is a higher chance of event description overlap between two texts if their time of publication is similar.", "labels": [], "entities": [{"text": "event description overlap", "start_pos": 41, "end_pos": 66, "type": "TASK", "confidence": 0.6339666446050009}]}, {"text": "In this paper, we study the problem of mining and exploiting correlations between texts using these features.", "labels": [], "entities": []}, {"text": "Two texts maybe considered related or complementary if they share a hashtag/NE or satisfies the temporal constraints.", "labels": [], "entities": []}, {"text": "Our proposed latent variable model not only models text-to-word information, but also is aware of the text-to-text information (illustrated in): two linked texts should have similar latent vectors, accordingly the semantic picture of a tweet is completed by receiving semantics from its related tweets.", "labels": [], "entities": []}, {"text": "We incorporate this additional information in the WTMF model.", "labels": [], "entities": [{"text": "WTMF", "start_pos": 50, "end_pos": 54, "type": "DATASET", "confidence": 0.5437222719192505}]}, {"text": "We also show the different impact of the text-to-text relations in the tweet genre and news genre.", "labels": [], "entities": []}, {"text": "We are able to achieve significantly better results than with a text-to-words WTMF model.", "labels": [], "entities": []}, {"text": "This work can be regarded as a short text modeling approach that extends previous work however with a focus on combining the mining of information within short texts coupled with utilizing extra shared information across the short texts.", "labels": [], "entities": [{"text": "short text modeling", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.6326102713743845}]}], "datasetContent": [{"text": "For our task evaluation, ideally, we would like the system to be able to identify the news article specifically referred to by the url within each tweet in the gold standard.", "labels": [], "entities": []}, {"text": "However, this is very difficult given the large number of potential candidates, especially those with slight variations.", "labels": [], "entities": []}, {"text": "Therefore, following the Concept Definition Retrieval task in and we use a metric for evaluating the ranking of the correct news article to evaluate the systems, namely, ATOP t , area under the TOPK t (k) recall curve fora tweet t.", "labels": [], "entities": [{"text": "Concept Definition Retrieval", "start_pos": 25, "end_pos": 53, "type": "TASK", "confidence": 0.6284111241499583}, {"text": "ATOP", "start_pos": 170, "end_pos": 174, "type": "METRIC", "confidence": 0.997018575668335}, {"text": "TOPK t (k) recall curve", "start_pos": 194, "end_pos": 217, "type": "METRIC", "confidence": 0.5916501070771899}]}, {"text": "Basically, it is the normalized ranking \u2208 [0, 1] of the correct news article among all candidate news articles: ATOP t = 1 means the url-referred news article has the highest similarity value with the tweet (a correct NARU); ATOP t = 0.95 means the similarity value with correct news article is larger than 95% of the candidates, i.e. within the top 5% of the candidates.", "labels": [], "entities": [{"text": "ATOP", "start_pos": 112, "end_pos": 116, "type": "METRIC", "confidence": 0.9965564012527466}, {"text": "ATOP", "start_pos": 225, "end_pos": 229, "type": "METRIC", "confidence": 0.992699921131134}]}, {"text": "ATOP t is calculated as follows: where TOPK t (k) = 1 if the url referred news article is in the \"top k\" list, otherwise TOPK t (k) = 0.", "labels": [], "entities": [{"text": "ATOP", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.7902697920799255}, {"text": "TOPK t (k)", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9051040053367615}]}, {"text": "Here k \u2208 [0, 1] is the relative position (when k = 1, it means all the candidates).", "labels": [], "entities": []}, {"text": "We also include other metrics to examine if the system is able to rank the url referred news article in the first few returned results: TOP10 recall hit rate to evaluate whether the correct news is in the top 10 results, and RR, Reciprocal Rank= 1/r (i.e., RR= 1/3 when the correct news article is ranked at the 3rd highest place).", "labels": [], "entities": [{"text": "TOP10", "start_pos": 136, "end_pos": 141, "type": "METRIC", "confidence": 0.9955428242683411}, {"text": "recall hit rate", "start_pos": 142, "end_pos": 157, "type": "METRIC", "confidence": 0.9494893948237101}, {"text": "RR", "start_pos": 225, "end_pos": 227, "type": "METRIC", "confidence": 0.9977879524230957}, {"text": "Reciprocal Rank", "start_pos": 229, "end_pos": 244, "type": "METRIC", "confidence": 0.9848687648773193}, {"text": "RR", "start_pos": 257, "end_pos": 259, "type": "METRIC", "confidence": 0.9928966164588928}]}, {"text": "Corpora: We use the same corpora as in): Brown corpus (each sentence is treated as a document), sense definitions of Wiktionary and Wordnet.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 132, "end_pos": 139, "type": "DATASET", "confidence": 0.9494245052337646}]}, {"text": "The tweets and news articles are also included in the corpus, generating 441,258 short texts and 5,149,122 words.", "labels": [], "entities": []}, {"text": "The data is tokenized, POS-tagged by Stanford POS tagger (, and lemmatized by WordNet::QueryData.pm.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 78, "end_pos": 85, "type": "DATASET", "confidence": 0.9558461308479309}]}, {"text": "The value of each word in matrix X is its TF-IDF value in the short text.", "labels": [], "entities": [{"text": "TF-IDF", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9906443357467651}]}, {"text": "Baselines: We present 4 baselines: 1.", "labels": [], "entities": []}, {"text": "Information Retrieval model, which simply treats a tweet as a document, and performs traditional surface word matching.", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.750476598739624}, {"text": "surface word matching", "start_pos": 97, "end_pos": 118, "type": "TASK", "confidence": 0.7145325541496277}]}, {"text": "2. LDA-\u03b8 with Gibbs Sampling as inference method.", "labels": [], "entities": []}, {"text": "We use the inferred topic distribution \u03b8 as a latent vector to represent the tweet/news.", "labels": [], "entities": []}, {"text": "The problem with LDA-\u03b8 is the inferred topic distribution latent vector is very sparse with only a few non-zero values, resulting in many tweet/news pairs receiving a high similarity value as long as they are in the same topic domain.", "labels": [], "entities": []}, {"text": "Hence following), we first compute the latent vector of a word by P (z|w) (topic distribution per word), then average the word latent vectors weighted by TF-IDF values to represent the short text, which yields much better results.", "labels": [], "entities": []}, {"text": "In these baselines, hashtags and named entities are simply treated as words.", "labels": [], "entities": []}, {"text": "To curtail variation in results due to randomness, each reported number is the average of 10 runs.", "labels": [], "entities": []}, {"text": "For WTMF and WTMF-G, we assign the same initial random values and run 20 iterations.", "labels": [], "entities": [{"text": "WTMF", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.8702341318130493}, {"text": "WTMF-G", "start_pos": 13, "end_pos": 19, "type": "DATASET", "confidence": 0.9380123615264893}]}, {"text": "In both systems we fix the missing words weight as w m = 0.01 and regularization coefficient at \u03bb = 20, which is the best condition of WTMF found in ().", "labels": [], "entities": [{"text": "WTMF", "start_pos": 135, "end_pos": 139, "type": "DATASET", "confidence": 0.5967556834220886}]}, {"text": "For LDA-\u03b8 and LDA-wvec, we run Gibbs Sampling based LDA for 2000 iterations and average the model over the last 10 iterations.", "labels": [], "entities": []}, {"text": "Evaluation: The similarity between a tweet and a news article is measured by cosine similarity.", "labels": [], "entities": []}, {"text": "A news article is represented as the concatenation of its title and its summary, which yields better performance.", "labels": [], "entities": []}, {"text": "As in, for each tweet, we collect the 1,000 news articles published prior to the tweet whose dates of publication are closest to that of the tweet.", "labels": [], "entities": []}, {"text": "The cosine similarity   score between the url referred news article and the tweet is compared against the scores of these 1,000 news articles to calculate the metric scores.", "labels": [], "entities": [{"text": "cosine similarity   score", "start_pos": 4, "end_pos": 29, "type": "METRIC", "confidence": 0.8381791909535726}]}, {"text": "1/10 of the tweet/news pairs are used as development set, based on which all the parameters are tuned.", "labels": [], "entities": []}, {"text": "The metrics ATOP, TOP10 and RR are used to evaluate the performance of systems.", "labels": [], "entities": [{"text": "ATOP", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.9982002973556519}, {"text": "TOP10", "start_pos": 18, "end_pos": 23, "type": "METRIC", "confidence": 0.9912131428718567}, {"text": "RR", "start_pos": 28, "end_pos": 30, "type": "METRIC", "confidence": 0.9956595301628113}]}, {"text": "summarizes the performance of the baselines and WTMF-G at latent dimension D = 100.", "labels": [], "entities": [{"text": "WTMF-G", "start_pos": 48, "end_pos": 54, "type": "DATASET", "confidence": 0.7365322113037109}, {"text": "latent dimension D", "start_pos": 58, "end_pos": 76, "type": "METRIC", "confidence": 0.8253767490386963}]}, {"text": "All the parameters are chosen based on the development set.", "labels": [], "entities": []}, {"text": "For WTMF-G, we try different values of k (the number of neighbors linked to a tweet/news fora hashtag/NE/time constraint) and \u03b4 (the weight of link information).", "labels": [], "entities": [{"text": "WTMF-G", "start_pos": 4, "end_pos": 10, "type": "DATASET", "confidence": 0.7955458164215088}]}, {"text": "We choose to model the links in four subgraphs: (a) hashtags in tweet; (b) named entities in tweet; (c) time in tweet; (d) time in news article.", "labels": [], "entities": []}, {"text": "For LDA we tune the hyperparameter \u03b1 (Dirichlet prior for topic distribution of a document) and \u03b2 (Dirichlet prior for word distribution given a topic).", "labels": [], "entities": []}, {"text": "It is worth noting that ATOP measures the overall ranking in 1000 samples while TOP10/RR focus on whether the aligned news article is in the first few returned results.", "labels": [], "entities": [{"text": "ATOP", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9560514688491821}, {"text": "TOP10", "start_pos": 80, "end_pos": 85, "type": "METRIC", "confidence": 0.9366321563720703}, {"text": "RR", "start_pos": 86, "end_pos": 88, "type": "METRIC", "confidence": 0.9658536314964294}]}], "tableCaptions": [{"text": " Table 1: ATOP Performance (latent dimension D = 100 for LDA/WTMF/WTMF-G)", "labels": [], "entities": [{"text": "ATOP", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.8220025300979614}, {"text": "latent dimension D", "start_pos": 28, "end_pos": 46, "type": "METRIC", "confidence": 0.8962138295173645}]}]}