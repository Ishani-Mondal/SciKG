{"title": [{"text": "Mining Equivalent Relations from Linked Data", "labels": [], "entities": []}], "abstractContent": [{"text": "Linking heterogeneous resources is a major research challenge in the Semantic Web.", "labels": [], "entities": []}, {"text": "This paper studies the task of mining equivalent relations from Linked Data, which was insufficiently addressed before.", "labels": [], "entities": []}, {"text": "We introduce an un-supervised method to measure equivalency of relation pairs and cluster equivalent relations.", "labels": [], "entities": []}, {"text": "Early experiments have shown encouraging results with an average of 0.75~0.87 precision in predicting relation pair equivalency and 0.78~0.98 precision in relation clustering.", "labels": [], "entities": [{"text": "precision", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9985957741737366}, {"text": "predicting relation pair equivalency", "start_pos": 91, "end_pos": 127, "type": "TASK", "confidence": 0.7848059237003326}, {"text": "precision", "start_pos": 142, "end_pos": 151, "type": "METRIC", "confidence": 0.9966872334480286}, {"text": "relation clustering", "start_pos": 155, "end_pos": 174, "type": "TASK", "confidence": 0.8364118933677673}]}], "introductionContent": [{"text": "Linked Data defines best practices for exposing, sharing, and connecting data on the Semantic Web using uniform means such as URIs and RDF.", "labels": [], "entities": []}, {"text": "It constitutes the conjunction between the Web and the Semantic Web, balancing the richness of semantics offered by Semantic Web with the easiness of data publishing.", "labels": [], "entities": []}, {"text": "For the last few years Linked Open Data has grown to a gigantic knowledge base, which, as of 2013, comprised 31 billion triples in 295 datasets . A major research question concerning Linked Data is linking heterogeneous resources, the fact that publishers may describe analogous information using different vocabulary, or may assign different identifiers to the same referents.", "labels": [], "entities": []}, {"text": "Among such work, many study mappings between ontology concepts and data instances (e.g.,).", "labels": [], "entities": []}, {"text": "An insufficiently addressed problem is linking heterogeneous relations, which is also widely found in data and can cause problems in information retrieval ().", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 133, "end_pos": 154, "type": "TASK", "confidence": 0.7773939073085785}]}, {"text": "Existing work in linking relations typically employ string similarity metrics or semantic similarity mea-1 http://lod-cloud.net/state/ sures that require a-priori domain knowledge and are limited in different ways (.", "labels": [], "entities": []}, {"text": "This paper introduces a novel method to discover equivalent groups of relations for Linked Data concepts.", "labels": [], "entities": []}, {"text": "It consists of two components: 1) a measure of equivalency between pairs of relations of a concept and 2) a clustering process to group equivalent relations.", "labels": [], "entities": []}, {"text": "The method is unsupervised; completely data-driven requiring no apriori domain knowledge; and also language independent.", "labels": [], "entities": []}, {"text": "Two types of experiments have been carried out using two major Linked Data sets: 1) evaluating the precision of predicting equivalency of relation pairs and 2) evaluating the precision of clustering equivalent relations.", "labels": [], "entities": [{"text": "precision", "start_pos": 99, "end_pos": 108, "type": "METRIC", "confidence": 0.9983401298522949}, {"text": "precision", "start_pos": 175, "end_pos": 184, "type": "METRIC", "confidence": 0.9965718984603882}]}, {"text": "Preliminary results have shown encouraging results as the method achieves between 0.75~0.85 precision in the first set of experiments while 0.78~0.98 in the latter.", "labels": [], "entities": [{"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9987930059432983}]}], "datasetContent": [{"text": "To our knowledge, there is no publically available gold standard for relation equivalency using Linked Data.", "labels": [], "entities": [{"text": "relation equivalency", "start_pos": 69, "end_pos": 89, "type": "TASK", "confidence": 0.8938584923744202}]}, {"text": "We randomly selected 21 concepts We apply our method to each concept to discover clusters of equivalent relations, using as SPARQL endpoint both DBpedia and Sindice and report results separately.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 145, "end_pos": 152, "type": "DATASET", "confidence": 0.9535237550735474}, {"text": "Sindice", "start_pos": 157, "end_pos": 164, "type": "DATASET", "confidence": 0.8349086046218872}]}, {"text": "This is to study how the method performs in different conditions: on one hand on a smaller and cleaner dataset (DBpedia); on the other hand on a larger and multi-lingual dataset (Sindice) to also test crosslingual capability of our method.", "labels": [], "entities": []}, {"text": "We chose relatively low thresholds, i.e. T minEqvl =0.1, T minTP = 0.01% and T minEqvlRel =0.6, in order to ensure high recall without sacrificing much precision.", "labels": [], "entities": [{"text": "T minEqvl", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9003083407878876}, {"text": "T minTP", "start_pos": 57, "end_pos": 64, "type": "METRIC", "confidence": 0.9185953140258789}, {"text": "recall", "start_pos": 120, "end_pos": 126, "type": "METRIC", "confidence": 0.9986191987991333}, {"text": "precision", "start_pos": 152, "end_pos": 161, "type": "METRIC", "confidence": 0.996198832988739}]}, {"text": "Four human annotators manually annotated the output for each concept.", "labels": [], "entities": []}, {"text": "For this preliminary evaluation, we have limited the amount of annotations to a maximum of 100 top scoring pairs of relations per concept, resulting in 16~100 pairs per concept (avg.", "labels": [], "entities": []}, {"text": "40) for DBpedia experiment and 29~100 pairs for Sindice (avg. 91).", "labels": [], "entities": [{"text": "DBpedia experiment", "start_pos": 8, "end_pos": 26, "type": "DATASET", "confidence": 0.822827935218811}, {"text": "Sindice", "start_pos": 48, "end_pos": 55, "type": "DATASET", "confidence": 0.9142332077026367}]}, {"text": "The annotators were asked to rate each edge in each cluster with -1 (wrong), 1 (correct) or 0 (cannot decide).", "labels": [], "entities": []}, {"text": "Pairs with 0 are ignored in the evaluation (about 12% for DBpedia; and 17% for Sindice mainly due to unreadable encoded URLs for certain languages).", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 58, "end_pos": 65, "type": "DATASET", "confidence": 0.9358023405075073}, {"text": "Sindice", "start_pos": 79, "end_pos": 86, "type": "DATASET", "confidence": 0.8967229127883911}]}, {"text": "To evaluate cross-lingual pairs, we asked annotators to use translation tools.", "labels": [], "entities": []}, {"text": "Inter-Annotator-Agreement (observed IAA) is shown in.", "labels": [], "entities": [{"text": "Inter-Annotator-Agreement (observed IAA)", "start_pos": 0, "end_pos": 40, "type": "METRIC", "confidence": 0.6760076940059662}]}, {"text": "Also using this data, we derived a gold standard for clustering based on edge connectivity and we evaluate (i) the precision of top n% (p@n%) ranked equivalent relation pairs and (ii) the precision of clustering for each concept.", "labels": [], "entities": [{"text": "precision", "start_pos": 115, "end_pos": 124, "type": "METRIC", "confidence": 0.9989701509475708}, {"text": "precision", "start_pos": 188, "end_pos": 197, "type": "METRIC", "confidence": 0.998778760433197}]}, {"text": "So far the output of 13 concepts has been annotated.", "labels": [], "entities": []}, {"text": "This dataset 5 contains \u22481800 relation pairs and is larger than the one by.", "labels": [], "entities": []}, {"text": "Annotation process shows that over 75% of relation pairs in the Sindice experiment contain non-English relations and mostly are crosslingual.", "labels": [], "entities": []}, {"text": "We used this data to report performance, although the method has been applied to all the 21 concepts, and the complete results can be visualized at our demo website link.", "labels": [], "entities": []}, {"text": "Some examples are shown in. shows p@n% for pair equivalency and shows clustering precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 81, "end_pos": 90, "type": "METRIC", "confidence": 0.762628972530365}]}, {"text": "As it is shown in, Linked Data relations are often heterogeneous.", "labels": [], "entities": []}, {"text": "Therefore, finding equivalent relations to improve coverage is important.", "labels": [], "entities": []}, {"text": "Results in show that inmost cases the method identifies equivalent relations with high precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9941533207893372}]}, {"text": "It is effective for both single-and cross-language relation pairs.", "labels": [], "entities": []}, {"text": "The worst performing case for DBpedia is Aircraft (for all n%), mostly due to duplicating numeric valued objects of different relations (e.g., weight, length, capacity).", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 30, "end_pos": 37, "type": "DATASET", "confidence": 0.7041754126548767}]}, {"text": "The decreasing precision with respect to n% suggests the measure effectively ranks correct pairs to the top.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9992751479148865}]}, {"text": "This is a useful feature from IR point of view.", "labels": [], "entities": []}, {"text": "shows that the method effectively clusters equivalent relations with very high precision: 0.8~0.98 inmost cases.", "labels": [], "entities": [{"text": "precision", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9945303797721863}]}, {"text": "Per-concept results are available on our website.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Also using this data,  we derived a gold standard for clustering based  on edge connectivity and we evaluate (i) the pre- cision of top n% (p@n%) ranked equivalent rela- tion pairs and (ii) the precision of clustering for  each concept.", "labels": [], "entities": [{"text": "precision", "start_pos": 204, "end_pos": 213, "type": "METRIC", "confidence": 0.9993409514427185}]}, {"text": " Table 1. IAA on annotating pair equivalency", "labels": [], "entities": [{"text": "IAA", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8196024894714355}]}]}