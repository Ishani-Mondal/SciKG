{"title": [], "abstractContent": [{"text": "We present a generative probabilistic model, inspired by historical printing processes , for transcribing images of documents from the printing press era.", "labels": [], "entities": [{"text": "transcribing images of documents from the printing press era", "start_pos": 93, "end_pos": 153, "type": "TASK", "confidence": 0.8432439698113335}]}, {"text": "By jointly modeling the text of the document and the noisy (but regular) process of rendering glyphs, our unsupervised system is able to decipher font structure and more accurately transcribe images into text.", "labels": [], "entities": []}, {"text": "Overall, our system substantially out-performs state-of-the-art solutions for this task, achieving a 31% relative reduction in word error rate over the leading commercial system for historical transcription, and a 47% relative reduction over Tesser-act, Google's open source OCR system.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 127, "end_pos": 142, "type": "METRIC", "confidence": 0.6497626006603241}, {"text": "historical transcription", "start_pos": 182, "end_pos": 206, "type": "TASK", "confidence": 0.7336500883102417}]}], "introductionContent": [{"text": "Standard techniques for transcribing modern documents do notwork well on historical ones.", "labels": [], "entities": [{"text": "transcribing modern documents", "start_pos": 24, "end_pos": 53, "type": "TASK", "confidence": 0.9031588435173035}]}, {"text": "For example, even state-of-the-art OCR systems produce word error rates of over 50% on the documents shown in.", "labels": [], "entities": [{"text": "word error rates", "start_pos": 55, "end_pos": 71, "type": "METRIC", "confidence": 0.6669452885786692}]}, {"text": "Unsurprisingly, such error rates are too high for many research projects (.", "labels": [], "entities": [{"text": "error rates", "start_pos": 21, "end_pos": 32, "type": "METRIC", "confidence": 0.9719963073730469}]}, {"text": "We present anew, generative model specialized to transcribing printing-press era documents.", "labels": [], "entities": [{"text": "transcribing printing-press era documents", "start_pos": 49, "end_pos": 90, "type": "TASK", "confidence": 0.847880095243454}]}, {"text": "Our model is inspired by the underlying printing processes and is designed to capture the primary sources of variation and noise.", "labels": [], "entities": []}, {"text": "One key challenge is that the fonts used in historical documents are not standard.", "labels": [], "entities": []}, {"text": "The fonts are not irregular like handwriting -each occurrence of a given character type, e.g. a, will use the same underlying glyph.", "labels": [], "entities": []}, {"text": "However, the exact glyphs are unknown.", "labels": [], "entities": []}, {"text": "Some differences between fonts are minor, reflecting small variations in font design.", "labels": [], "entities": []}, {"text": "Others are more severe, like the presence of the archaic long s character before 1804.", "labels": [], "entities": [{"text": "archaic long s character before 1804", "start_pos": 49, "end_pos": 85, "type": "DATASET", "confidence": 0.6030358721812566}]}, {"text": "To address the general problem of unknown fonts, our model learns the font in an unsupervised fashion.", "labels": [], "entities": []}, {"text": "Font shape and character segmentation are tightly coupled, and so they are modeled jointly.", "labels": [], "entities": [{"text": "character segmentation", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.7024290561676025}]}, {"text": "A second challenge with historical data is that the early typesetting process was noisy.", "labels": [], "entities": []}, {"text": "Handcarved blocks were somewhat uneven and often failed to sit evenly on the mechanical baseline.", "labels": [], "entities": []}, {"text": "shows an example of the text's baseline moving up and down, with varying gaps between characters.", "labels": [], "entities": []}, {"text": "To deal with these phenomena, our model incorporates random variables that specifically describe variations in vertical offset and horizontal spacing.", "labels": [], "entities": []}, {"text": "A third challenge is that the actual inking was also noisy.", "labels": [], "entities": [{"text": "inking", "start_pos": 37, "end_pos": 43, "type": "TASK", "confidence": 0.9316203594207764}]}, {"text": "For example, in some characters are thick from over-inking while others are obscured by ink bleeds.", "labels": [], "entities": []}, {"text": "To be robust to such rendering irregularities, our model captures both inking levels and pixel-level noise.", "labels": [], "entities": []}, {"text": "Because the model is generative, we can also treat areas that are obscured by larger ink blotches as unobserved, and let the model predict the obscured text based on visual and linguistic context.", "labels": [], "entities": []}, {"text": "Our system, which we call Ocular, operates by fitting the model to each document in an unsupervised fashion.", "labels": [], "entities": []}, {"text": "The system outperforms state-ofthe-art baselines, giving a 47% relative error reduction over Google's open source Tesseract system, and giving a 31% relative error reduction over ABBYY's commercial FineReader system, which has been used in large-scale historical transcription projects.", "labels": [], "entities": [{"text": "relative error reduction", "start_pos": 63, "end_pos": 87, "type": "METRIC", "confidence": 0.7509625752766927}, {"text": "ABBYY", "start_pos": 179, "end_pos": 184, "type": "DATASET", "confidence": 0.9250648021697998}, {"text": "FineReader", "start_pos": 198, "end_pos": 208, "type": "DATASET", "confidence": 0.8165415525436401}]}], "datasetContent": [{"text": "We evaluate our system by comparing our text recognition accuracy to that of two state-of-the-art systems.", "labels": [], "entities": [{"text": "text recognition", "start_pos": 40, "end_pos": 56, "type": "TASK", "confidence": 0.8282280564308167}, {"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9161731600761414}]}, {"text": "We evaluate the output of our system and the baseline systems using two metrics: character error rate (CER) and word error rate (WER).", "labels": [], "entities": [{"text": "character error rate (CER)", "start_pos": 81, "end_pos": 107, "type": "METRIC", "confidence": 0.9092442790667216}, {"text": "word error rate (WER)", "start_pos": 112, "end_pos": 133, "type": "METRIC", "confidence": 0.9190175433953603}]}, {"text": "Both these metrics are based on edit distance.", "labels": [], "entities": []}, {"text": "CER is the edit distance between the predicted and gold transcriptions of the document, divided by the number of characters in the gold transcription.", "labels": [], "entities": [{"text": "CER", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.906858503818512}, {"text": "edit distance", "start_pos": 11, "end_pos": 24, "type": "METRIC", "confidence": 0.9564551711082458}]}, {"text": "WER is the word-level edit distance (words, instead of characters, are treated as tokens) between predicted and gold transcriptions, divided by the number of words in the gold transcription.", "labels": [], "entities": [{"text": "WER", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.983953595161438}]}, {"text": "When computing WER, text is tokenized into words by splitting on whitespace.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: We evaluate the predicted transcriptions in terms of  both character error rate (CER) and word error rate (WER),  and report macro-averages across documents. We compare  with two baseline systems: Google's open source OCR sys- tem, Tessearact, and a state-of-the-art commercial system,  ABBYY FineReader. We refer to our system as Ocular w/  NYT and Ocular w/ OB, depending on whether NYT or Old  Bailey is used to train the language model.", "labels": [], "entities": [{"text": "character error rate (CER)", "start_pos": 69, "end_pos": 95, "type": "METRIC", "confidence": 0.9020243287086487}, {"text": "word error rate (WER)", "start_pos": 100, "end_pos": 121, "type": "METRIC", "confidence": 0.90782430768013}, {"text": "ABBYY FineReader", "start_pos": 297, "end_pos": 313, "type": "DATASET", "confidence": 0.8975280225276947}, {"text": "NYT", "start_pos": 352, "end_pos": 355, "type": "DATASET", "confidence": 0.8577665686607361}, {"text": "NYT", "start_pos": 395, "end_pos": 398, "type": "DATASET", "confidence": 0.9325194358825684}, {"text": "Old  Bailey", "start_pos": 402, "end_pos": 413, "type": "DATASET", "confidence": 0.8729574382305145}]}]}