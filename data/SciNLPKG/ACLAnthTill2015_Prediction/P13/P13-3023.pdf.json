{"title": [{"text": "Robust Multilingual Statistical Morphological Generation Models", "labels": [], "entities": [{"text": "Robust Multilingual Statistical Morphological Generation", "start_pos": 0, "end_pos": 56, "type": "TASK", "confidence": 0.6462551653385162}]}], "abstractContent": [{"text": "We present a novel method of statistical morphological generation, i.e. the prediction of inflected word forms given lemma, part-of-speech and morphological features, aimed at robustness to unseen inputs.", "labels": [], "entities": [{"text": "statistical morphological generation", "start_pos": 29, "end_pos": 65, "type": "TASK", "confidence": 0.6560737192630768}]}, {"text": "Our system uses a trainable classifier to predict \"edit scripts\" that are then used to transform lemmas into inflected word forms.", "labels": [], "entities": []}, {"text": "Suffixes of lemmas are included as features to achieve robustness.", "labels": [], "entities": []}, {"text": "We evaluate our system on 6 languages with a varying degree of morphological richness.", "labels": [], "entities": []}, {"text": "The results show that the system is able to learn most morphological phenomena and generalize to unseen inputs, producing significantly better results than a dictionary-based baseline.", "labels": [], "entities": []}], "introductionContent": [{"text": "Surface realization is an integral part of all natural language generation (NLG) systems, albeit often implemented in a very simple manner, such as filling words into ready hand-written templates.", "labels": [], "entities": [{"text": "Surface realization", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7593842148780823}, {"text": "natural language generation (NLG)", "start_pos": 47, "end_pos": 80, "type": "TASK", "confidence": 0.8340112169583639}]}, {"text": "More sophisticated methods use hand-written grammars (, possibly in combination with a statistical reranker.", "labels": [], "entities": []}, {"text": "Existing NLG systems are very often applied to languages with little morphology, such as English, where a small set of hand-written rules or the direct use of word forms in the symbolic representation or templates is usually sufficient, and so the main focus of these systems lies on syntax and word order.", "labels": [], "entities": []}, {"text": "However, this approach poses a problem in languages with a complex morphology.", "labels": [], "entities": []}, {"text": "Avoiding inflection, i.e. ensuring that a word lemma will keep its base format all times, often leads to very unnatural results (see.", "labels": [], "entities": []}, {"text": "Some generators use a hand-made morphological dictionary Toto se l\u00edb\u00ed u\u017eivateli Jana Nov\u00e1kov\u00e1.", "labels": [], "entities": []}, {"text": "---------------\u011b \u00e9  The sentences are taken from the Czech translations of Facebook and Doodle, which use simple templates to generate personalized texts.", "labels": [], "entities": [{"text": "Doodle", "start_pos": 88, "end_pos": 94, "type": "DATASET", "confidence": 0.9238024950027466}]}, {"text": "Corrections to make the text fluent are shown in red.", "labels": [], "entities": []}, {"text": "for inflection) or a dictionary learned from automatically tagged data (.", "labels": [], "entities": []}, {"text": "That gives good results, but reaching sufficient coverage with a hand-made dictionary is a very demanding task and even using extreme amounts of automatically annotated data will not generalize beyond the word forms already encountered in the corpus.", "labels": [], "entities": []}, {"text": "Hand-written rules can become overly complex and are not easily adaptable fora different language.", "labels": [], "entities": []}, {"text": "Therefore, the presented method relies on a statistical approach that learns to predict morphological inflection from annotated data.", "labels": [], "entities": []}, {"text": "As a result, such approach is more robust, i.e. capable of generalizing to unseen inputs, and easily portable to different languages.", "labels": [], "entities": []}, {"text": "An attempt to implement statistical morphological generation has already been made by.", "labels": [], "entities": [{"text": "statistical morphological generation", "start_pos": 24, "end_pos": 60, "type": "TASK", "confidence": 0.7758833964665731}]}, {"text": "However, their morphology generation was only a component of a complex generation system.", "labels": [], "entities": [{"text": "morphology generation", "start_pos": 15, "end_pos": 36, "type": "TASK", "confidence": 0.7575731873512268}]}, {"text": "Therefore, no deep analysis of the capabilities of the methods has been performed.", "labels": [], "entities": []}, {"text": "In addition, their method did not attempt to generalize beyond seen inputs.", "labels": [], "entities": []}, {"text": "In this paper, we propose several improvements and provide a detailed evaluation of a statistical morphological inflection system, including more languages into the evaluation and focusing on robustness to unseen inputs.", "labels": [], "entities": []}, {"text": "The paper is structured as follows: first, we explain the problem of morphological generation (Section 2), then give an account of our system (Section 3).", "labels": [], "entities": [{"text": "morphological generation", "start_pos": 69, "end_pos": 93, "type": "TASK", "confidence": 0.736890509724617}]}, {"text": "Section 4 provides a detailed evaluation of the performance of our system in different languages.", "labels": [], "entities": []}, {"text": "We then compare our system to related works in Section 5.", "labels": [], "entities": []}, {"text": "Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our morphological generation setup on all of the languages included in the CoNLL 2009 Shared Task data sets except Chinese (which, as an isolating language, lacks morphology almost altogether): English, German, Spanish, Catalan, Japanese, and Czech.", "labels": [], "entities": [{"text": "CoNLL 2009 Shared Task data sets", "start_pos": 87, "end_pos": 119, "type": "DATASET", "confidence": 0.9368187884489695}]}, {"text": "We use the CoNLL 2009 data sets) with gold-standard morphology annotation for all our experiments (see fora detailed overview).", "labels": [], "entities": [{"text": "CoNLL 2009 data sets", "start_pos": 11, "end_pos": 31, "type": "DATASET", "confidence": 0.9839804321527481}]}, {"text": "We give a discussion of the overall performance of our system in all the languages in Section 4.1.", "labels": [], "entities": []}, {"text": "We focus on Czech in the detailed analysis of the generalization power of our system in Section 4.2 since Czech has the most complicated morphology of all these languages.", "labels": [], "entities": []}, {"text": "In addition, the morphological annotation provided in the CoNLL 2009 Czech data set is more detailed than in the other languages, which eliminates the need for additional syntactic features (cf. Section 3.3).", "labels": [], "entities": [{"text": "CoNLL 2009 Czech data set", "start_pos": 58, "end_pos": 83, "type": "DATASET", "confidence": 0.9697806119918824}]}, {"text": "We also provide a detailed performance overview on English for comparison.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The CoNLL 2009 data sets: Sizes and properties", "labels": [], "entities": [{"text": "CoNLL 2009 data sets", "start_pos": 14, "end_pos": 34, "type": "DATASET", "confidence": 0.9583069533109665}, {"text": "Sizes", "start_pos": 36, "end_pos": 41, "type": "TASK", "confidence": 0.9767715930938721}]}, {"text": " Table 2: The overall performance of our system in different languages.", "labels": [], "entities": []}, {"text": " Table 3: Comparison of our system with a dictionary baseline on different training data sizes.", "labels": [], "entities": []}]}