{"title": [{"text": "Aggregated Word Pair Features for Implicit Discourse Relation Disambiguation", "labels": [], "entities": [{"text": "Implicit Discourse Relation Disambiguation", "start_pos": 34, "end_pos": 76, "type": "TASK", "confidence": 0.806494414806366}]}], "abstractContent": [{"text": "We present a reformulation of the word pair features typically used for the task of disambiguating implicit relations in the Penn Discourse Treebank.", "labels": [], "entities": [{"text": "Penn Discourse Treebank", "start_pos": 125, "end_pos": 148, "type": "DATASET", "confidence": 0.9897655646006266}]}, {"text": "Our word pair features achieve significantly higher performance than the previous formulation when evaluated without additional features.", "labels": [], "entities": []}, {"text": "In addition, we present results fora full system using additional features which achieves close to state of the art performance without resorting to gold syntactic parses or to context outside the relation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Discourse relations such as contrast and causality are part of what makes a text coherent.", "labels": [], "entities": []}, {"text": "Being able to automatically identify these relations is important for many NLP tasks such as generation, question answering and textual entailment.", "labels": [], "entities": [{"text": "question answering", "start_pos": 105, "end_pos": 123, "type": "TASK", "confidence": 0.8668042719364166}, {"text": "textual entailment", "start_pos": 128, "end_pos": 146, "type": "TASK", "confidence": 0.724360466003418}]}, {"text": "In some cases, discourse relations contain an explicit marker such as but or because which makes it easy to identify the relation.", "labels": [], "entities": []}, {"text": "Prior work  showed that where explicit markers exist, the class of the relation can be disambiguated with f-scores higher than 90%.", "labels": [], "entities": []}, {"text": "Predicting the class of implicit discourse relations, however, is much more difficult.", "labels": [], "entities": []}, {"text": "Without an explicit marker to rely on, work on this task initially focused on using lexical cues in the form of word pairs mined from large corpora where they appear around an explicit marker ().", "labels": [], "entities": []}, {"text": "The intuition is that these pairs will tend to represent semantic relationships which are related to the discourse marker (for example, word pairs often appearing around but may tend to be antonyms).", "labels": [], "entities": []}, {"text": "While this approach showed some success and has been used extensively in later work, it has been pointed out by multiple authors that many of the most useful word pairs are pairs of very common functional words, which contradicts the original intuition, and it is hard to explain why these are useful.", "labels": [], "entities": []}, {"text": "In this work we focus on the task of identifying and disambiguating implicit discourse relations which have no explicit marker.", "labels": [], "entities": []}, {"text": "In particular, we present a reformulation of the word pair features that have most often been used for this task in the past, replacing the sparse lexical features with dense aggregated score features.", "labels": [], "entities": []}, {"text": "This is the main contribution of our paper.", "labels": [], "entities": []}, {"text": "We show that our formulation outperforms the original one while requiring less features, and that using a stop list of functional words does not significantly affect performance, suggesting that these features indeed represent semantically related content word pairs.", "labels": [], "entities": []}, {"text": "In addition, we present a system which combines these word pairs with additional features to achieve near state of the art performance without the use of syntactic parse features and of context outside the arguments of the relation.", "labels": [], "entities": []}, {"text": "Previous work has attributed much of the achieved performance to these features, which are easy to get in the experimental setting but would be less reliable or unavailable in other applications.", "labels": [], "entities": []}], "datasetContent": [{"text": "For our main evaluation, we evaluate the performance of word pair features when used with no additional features.", "labels": [], "entities": []}, {"text": "Our word pair features outperform the previous formulation (represented by the results reported by , but used by virtually all previous work on this task).", "labels": [], "entities": []}, {"text": "For most relation classes, tf is significantly better than pmi.", "labels": [], "entities": []}, {"text": "For our secondary evaluation, we present results for each feature category on its own in and for our best system for each of the relation classes in.", "labels": [], "entities": []}, {"text": "We show results for the best systems from ( , ( and) for comparison.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Main evaluation. F-measure (accuracy) for various implementations of the word pairs features", "labels": [], "entities": [{"text": "F-measure", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9982617497444153}, {"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.8152149319648743}]}, {"text": " Table 2: Secondary evaluation. F-measure (accuracy) for the best systems. tf and pmi refer to the word  pair features used (by tf implementation), and the numbers refer to the indeces of Table 3", "labels": [], "entities": [{"text": "F-measure", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9941998720169067}, {"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.6939096450805664}]}, {"text": " Table 3: F-measure for each feature category", "labels": [], "entities": [{"text": "F-measure", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9920646548271179}]}]}