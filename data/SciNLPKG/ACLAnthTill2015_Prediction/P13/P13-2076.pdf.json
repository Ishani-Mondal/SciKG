{"title": [], "abstractContent": [{"text": "Question answering systems have been developed for many languages, but most resources were created for English, which can be a problem when developing a system in another language such as French.", "labels": [], "entities": [{"text": "Question answering", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9020729959011078}]}, {"text": "In particular, for question classification, no labeled question corpus is available for French, so this paper studies the possibility to use existing English corpora and transfer a classification by translating the question and their labels.", "labels": [], "entities": [{"text": "question classification", "start_pos": 19, "end_pos": 42, "type": "TASK", "confidence": 0.8487401306629181}]}, {"text": "By translating the training corpus, we obtain results close to a monolingual setting.", "labels": [], "entities": []}], "introductionContent": [{"text": "In question answering (QA), as inmost Natural Language Processing domains, English is the best resourced language, in terms of corpora, lexicons, or systems.", "labels": [], "entities": [{"text": "question answering (QA)", "start_pos": 3, "end_pos": 26, "type": "TASK", "confidence": 0.8693663835525512}]}, {"text": "Many methods are based on supervised machine learning which is made possible by the great amount of resources for this language.", "labels": [], "entities": []}, {"text": "While developing a question answering system for French, we were thus limited by the lack of resources for this language.", "labels": [], "entities": [{"text": "question answering", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.8289889693260193}]}, {"text": "Some were created, for example for answer validation).", "labels": [], "entities": [{"text": "answer validation", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.8854626715183258}]}, {"text": "Yet, for question classification, although question corpora in French exist, only a small part of them is annotated with question classes, and such an annotation is costly.", "labels": [], "entities": [{"text": "question classification", "start_pos": 9, "end_pos": 32, "type": "TASK", "confidence": 0.8764302730560303}]}, {"text": "We thus wondered if it was possible to use existing English corpora, in this case the data used in (), to create a classification module for French.", "labels": [], "entities": []}, {"text": "Transfering knowledge from one language to another is usually done by exploiting parallel corpora; yet in this case, few such corpora exists (CLEF QA datasets could be used, but question classes are not very precise).", "labels": [], "entities": [{"text": "CLEF QA datasets", "start_pos": 142, "end_pos": 158, "type": "DATASET", "confidence": 0.7086913188298544}]}, {"text": "We thus investigated the possibility of using machine translation to create a parallel corpus, as has been done for spoken language understanding (Jabaian et al., 2011) for example.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.7640121579170227}, {"text": "spoken language understanding", "start_pos": 116, "end_pos": 145, "type": "TASK", "confidence": 0.700789193312327}]}, {"text": "The idea is that using machine translation would enable us to have a large training corpus, either by using the English one and translating the test corpus, or by translating the training corpus.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.7025595903396606}]}, {"text": "One of the questions posed was whether the quality of present machine translation systems would enable to learn the classification properly.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 62, "end_pos": 81, "type": "TASK", "confidence": 0.7281043529510498}]}, {"text": "This paper presents a question classification transfer method, which results are close to those of a monolingual system.", "labels": [], "entities": [{"text": "question classification transfer", "start_pos": 22, "end_pos": 54, "type": "TASK", "confidence": 0.8457394440968832}]}, {"text": "The contributions of the paper are the following: \u2022 comparison of train-on-target and test-onsource strategies for question classification; \u2022 creation of an effective question classification system for French, with minimal annotation effort.", "labels": [], "entities": [{"text": "question classification", "start_pos": 115, "end_pos": 138, "type": "TASK", "confidence": 0.871250182390213}, {"text": "question classification", "start_pos": 167, "end_pos": 190, "type": "TASK", "confidence": 0.6991173774003983}]}, {"text": "This paper is organized as follows: The problem of Question Classification is defined in section 2.", "labels": [], "entities": [{"text": "Question Classification", "start_pos": 51, "end_pos": 74, "type": "TASK", "confidence": 0.8120572566986084}]}, {"text": "The proposed methods are presented in section 3, and the experiments in section 4.", "labels": [], "entities": []}, {"text": "Section 5 details the related works in Question Answering.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.7623598873615265}]}, {"text": "Finally, Section 6 concludes with a summary and a few directions for future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Question classification precision for both  levels of the hierarchy (features = word n-grams,  classifier = libsvm)", "labels": [], "entities": [{"text": "Question classification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.7953517436981201}, {"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9450093507766724}]}, {"text": " Table 2: Question classification precision for both  levels of the hierarchy (features = word n-grams  with abbreviations, classifier = libsvm)", "labels": [], "entities": [{"text": "Question classification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.8023761212825775}, {"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9531087279319763}]}, {"text": " Table 3: Question classification precision for both  levels of the hierarchy (features = word n-grams  with abbreviations, classifier = libsvm)", "labels": [], "entities": [{"text": "Question classification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.8106015920639038}, {"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9559627771377563}]}]}