{"title": [{"text": "Visual Features for Linguists: Basic image analysis techniques for multimodally-curious NLPers", "labels": [], "entities": []}], "abstractContent": [{"text": "Description Features automatically extracted from images constitute anew and rich source of semantic knowledge that can complement information extracted from text.", "labels": [], "entities": []}, {"text": "The convergence between vision-and text-based information can be exploited in scenarios where the two modalities must be combined to solve a target task (e.g., generating verbal descriptions of images, or finding the right images to illustrate a story).", "labels": [], "entities": []}, {"text": "However, the potential applications for integrated visual features go beyond mixed-media scenarios: Because of their complementary nature with respect to language, visual features might provide perceptually grounded semantic information that can be exploited in purely linguistic domains.", "labels": [], "entities": []}, {"text": "The tutorial will first introduce basic techniques to encode image contents in terms of low-level features , such as the widely adopted SIFT descriptors.", "labels": [], "entities": []}, {"text": "We will then show how these low-level descriptors are used to induce more abstract features, focus-ing on the well-established bags-of-visual-words method to represent images, but also briefly introducing more recent developments, that include capturing spatial information with pyramid representations , soft visual word clustering via Fisher encoding and attribute-based image representation.", "labels": [], "entities": [{"text": "soft visual word clustering", "start_pos": 305, "end_pos": 332, "type": "TASK", "confidence": 0.6124598458409309}, {"text": "attribute-based image representation", "start_pos": 357, "end_pos": 393, "type": "TASK", "confidence": 0.6673931976159414}]}, {"text": "Next, we will discuss some example applications , and we will conclude with a brief practical illustration of visual feature extraction using a software package we developed.", "labels": [], "entities": [{"text": "visual feature extraction", "start_pos": 110, "end_pos": 135, "type": "TASK", "confidence": 0.6800320943196615}]}, {"text": "The tutorial is addressed to computational linguists without any background in computer vision.", "labels": [], "entities": []}, {"text": "It provides enough background material to understand the vision-and-language literature and the less technical articles on image analysis.", "labels": [], "entities": [{"text": "image analysis", "start_pos": 123, "end_pos": 137, "type": "TASK", "confidence": 0.8009899854660034}]}, {"text": "After the tutorial, the participants should also be able to autonomously incorporate visual features in their NLP pipelines using off-the-shelf tools.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}