{"title": [], "abstractContent": [{"text": "The English 's possessive construction occurs frequently in text and can encode several different semantic relations; however , it has received limited attention from the computational linguistics community.", "labels": [], "entities": []}, {"text": "This paper describes the creation of a semantic relation inventory covering the use of 's, an inter-annotator agreement study to calculate how well humans can agree on the relations, a large collection of pos-sessives annotated according to the relations , and an accurate automatic annotation system for labeling new examples.", "labels": [], "entities": []}, {"text": "Our 21,938 example dataset is by far the largest annotated possessives dataset we are aware of, and both our automatic classification system, which achieves 87.4% accuracy in our classification experiment, and our annotation data are publicly available .", "labels": [], "entities": [{"text": "accuracy", "start_pos": 163, "end_pos": 171, "type": "METRIC", "confidence": 0.9981787204742432}]}], "introductionContent": [{"text": "The English 's possessive construction occurs frequently in text-approximately 1.8 times for every 100 hundred words in the Penn Treebank-and can encode a number of different semantic relations including ownership (John's car), part-of-whole (John's arm), extent (6 hours' drive), and location (America's rivers).", "labels": [], "entities": [{"text": "Penn Treebank-and", "start_pos": 124, "end_pos": 141, "type": "DATASET", "confidence": 0.9943893253803253}, {"text": "extent", "start_pos": 256, "end_pos": 262, "type": "METRIC", "confidence": 0.9945711493492126}, {"text": "America's rivers", "start_pos": 295, "end_pos": 311, "type": "DATASET", "confidence": 0.907925029595693}]}, {"text": "Accurate automatic possessive interpretation could aid many natural language processing (NLP) applications, especially those that build semantic representations for text understanding, text generation, question answering, or information extraction.", "labels": [], "entities": [{"text": "possessive interpretation", "start_pos": 19, "end_pos": 44, "type": "TASK", "confidence": 0.6843743026256561}, {"text": "text understanding", "start_pos": 165, "end_pos": 183, "type": "TASK", "confidence": 0.726333275437355}, {"text": "text generation", "start_pos": 185, "end_pos": 200, "type": "TASK", "confidence": 0.759566068649292}, {"text": "question answering", "start_pos": 202, "end_pos": 220, "type": "TASK", "confidence": 0.876971960067749}, {"text": "information extraction", "start_pos": 225, "end_pos": 247, "type": "TASK", "confidence": 0.8293481767177582}]}, {"text": "These interpretations could be valuable for machine translation to or from languages that allow different semantic relations to be encoded by \u2020 The authors were affiliated with the USC Information Sciences Institute at the time this work was performed.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7378893792629242}]}, {"text": "This paper presents an inventory of 17 semantic relations expressed by the English 's-construction, a large dataset annotated according to the this inventory, and an accurate automatic classification system.", "labels": [], "entities": []}, {"text": "The final inter-annotator agreement study achieved a strong level of agreement, 0.78 Fleiss' Kappa ( and the dataset is easily the largest manually annotated dataset of possessive constructions created to date.", "labels": [], "entities": [{"text": "agreement", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9913809895515442}, {"text": "Fleiss' Kappa", "start_pos": 85, "end_pos": 98, "type": "METRIC", "confidence": 0.8399413824081421}]}, {"text": "We show that our automatic classication system is highly accurate, achieving 87.4% accuracy on a held-out test set.", "labels": [], "entities": [{"text": "classication", "start_pos": 27, "end_pos": 39, "type": "TASK", "confidence": 0.7839961051940918}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9990350008010864}]}], "datasetContent": [{"text": "We created the dataset used in this work from three different sources, each representing a distinct genre-newswire, non-fiction, and fiction.", "labels": [], "entities": []}, {"text": "Of the 21,938 total examples, 15,330 come from sections 2-21 of the Penn Treebank (.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 68, "end_pos": 81, "type": "DATASET", "confidence": 0.9951129257678986}]}, {"text": "Another 5,266 examples are from The History of the Decline and Fall of the Roman Empire (Gibbon, 1776), a non-fiction work, and 1,342 are from The Jungle Book, a collection of fictional short stories.", "labels": [], "entities": [{"text": "The History of the Decline and Fall of the Roman Empire (Gibbon, 1776)", "start_pos": 32, "end_pos": 102, "type": "TASK", "confidence": 0.6003123912960291}]}, {"text": "For the Penn Treebank, we extracted the examples using the provided gold standard parse trees, whereas, for the latter cases, we used the output of an open source parser (Tratz and Hovy, 2011).", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 8, "end_pos": 21, "type": "DATASET", "confidence": 0.9955756962299347}]}, {"text": "For the automatic classification experiments, we set aside 10% of the data for test purposes, and used the the remaining 90% for training.", "labels": [], "entities": [{"text": "automatic classification", "start_pos": 8, "end_pos": 32, "type": "TASK", "confidence": 0.689913347363472}]}, {"text": "We used 5-fold cross-validation performed using the training data to tweak the included feature templates and optimize training parameters.", "labels": [], "entities": []}, {"text": "To evaluate the importance of the different types of features, the same experiment was re-run multiple times, each time including or excluding exactly one feature template.", "labels": [], "entities": []}, {"text": "Before each variation, the C parameter was retuned using 5-fold cross validation on the training data.", "labels": [], "entities": []}, {"text": "The results for these runs are shown in.", "labels": [], "entities": []}, {"text": "Based upon the leave-one-out and only-one feature evaluation experiment results, it appears that the possessee word is more important to classification than the possessor word.", "labels": [], "entities": []}, {"text": "The possessor word is still valuable though, with it likely being more valuable for certain categories (e.g., and LOCATION) than others (e.g., KINSHIP).", "labels": [], "entities": [{"text": "LOCATION", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9380271434783936}]}, {"text": "Hypernym and gloss term features proved to be about equally valuable.", "labels": [], "entities": []}, {"text": "Curiously, although hypernyms are commonly used as features in NLP classification tasks, gloss terms, which are rarely used for these tasks, are approximately as useful, at least in this particular context.", "labels": [], "entities": [{"text": "NLP classification tasks", "start_pos": 63, "end_pos": 87, "type": "TASK", "confidence": 0.8904876112937927}]}, {"text": "This would bean interesting result to examine in greater detail.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Possessive semantic relations along with examples, counts, and approximate mappings to other  inventories. Q and B represent Quirk et al. (1985) and Badulescu and Moldovan (2009), respectively.  HDFRE, JB, PTB: The History of the Decline and Fall of the Roman Empire, The Jungle Book, and the  Penn Treebank, respectively.", "labels": [], "entities": [{"text": "The Jungle Book", "start_pos": 278, "end_pos": 293, "type": "DATASET", "confidence": 0.8500078121821085}, {"text": "Penn Treebank", "start_pos": 304, "end_pos": 317, "type": "DATASET", "confidence": 0.9929202198982239}]}, {"text": " Table 4: Intermediate results for the possessives refinement work.", "labels": [], "entities": [{"text": "possessives refinement", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.8852610290050507}]}, {"text": " Table 5: Final possessives annotation agreement figures before revisions.", "labels": [], "entities": []}, {"text": " Table 6: Final possessives annotation agreement figures after revisions.", "labels": [], "entities": []}]}