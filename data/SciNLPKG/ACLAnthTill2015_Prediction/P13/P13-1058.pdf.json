{"title": [{"text": "Using subcategorization knowledge to improve case prediction for translation to German", "labels": [], "entities": [{"text": "case prediction", "start_pos": 45, "end_pos": 60, "type": "TASK", "confidence": 0.8329481482505798}, {"text": "translation to German", "start_pos": 65, "end_pos": 86, "type": "TASK", "confidence": 0.906970759232839}]}], "abstractContent": [{"text": "This paper demonstrates the need and impact of subcategorization information for SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 81, "end_pos": 84, "type": "TASK", "confidence": 0.9949325919151306}]}, {"text": "We combine (i) features on source-side syntactic subcategorization and (ii) an external knowledge base with quantitative , dependency-based information about target-side subcategorization frames.", "labels": [], "entities": []}, {"text": "A manual evaluation of an English-to-German translation task shows that the subcategorization information has a positive impact on translation quality through better prediction of case.", "labels": [], "entities": []}], "introductionContent": [{"text": "When translating from a morphologically poor language to a morphologically rich language we are faced with two major problems: (i) the richness of the target-language morphology causes data sparsity problems, and (ii) information about morphological features on the target side is not sufficiently contained in the source language morphology.", "labels": [], "entities": []}, {"text": "We address these two problems using a twostep procedure.", "labels": [], "entities": []}, {"text": "We first replace inflected forms by their stems or lemmas: building a translation system on a stemmed representation of the target side leads to a simpler translation task, and the morphological information contained in the source and target language parts of the translation model is more balanced.", "labels": [], "entities": []}, {"text": "In the second step, the stemmed output of the translation is then inflected: the morphological features are predicted, and the inflected forms are generated using the stem and predicted morphological features.", "labels": [], "entities": []}, {"text": "In this paper, we focus on improving case prediction for noun phrases (NPs) in German translations.", "labels": [], "entities": [{"text": "case prediction for noun phrases (NPs) in German translations", "start_pos": 37, "end_pos": 98, "type": "TASK", "confidence": 0.7445623928850348}]}, {"text": "The NP feature case is extremely difficult to predict in German: while the NP features gender and number are part of the stem or can be derived from the source-side input, respectively, the prediction of case requires information about the subcategorization of the entire clause.", "labels": [], "entities": []}, {"text": "This is due to German being a less configurational language than English, which encodes grammatical relations (e.g. subject-hood, object-hood, etc.) through the position of constituents.", "labels": [], "entities": []}, {"text": "German sentences exhibit a freer constituent order, and thus case is an important indicator of the grammatical functions of noun phrases.", "labels": [], "entities": []}, {"text": "Correct case prediction is a crucial factor for the adequacy of SMT output, cf. the example in table 1 providing an erroneously inflected output (this is taken from a baseline \"simple inflection prediction\" system, cf. section 5.2).", "labels": [], "entities": [{"text": "case prediction", "start_pos": 8, "end_pos": 23, "type": "TASK", "confidence": 0.6398978978395462}, {"text": "SMT", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9957205653190613}]}, {"text": "The translation of the English input sentence in terms of stems is perfectly acceptable; after the inflection step, however, the translation of NP 4 ongoing military actions represents a genitive modifier of the subject NP 2 , instead of a direct object NP of the verb anordnen (to order).", "labels": [], "entities": []}, {"text": "The meaning is thus why the government of the ongoing military actions ordered, which has only one NP and is completely wrong.", "labels": [], "entities": [{"text": "NP", "start_pos": 99, "end_pos": 101, "type": "DATASET", "confidence": 0.8022544384002686}]}, {"text": "The translation in table 1 needs verb subcategorization information.", "labels": [], "entities": []}, {"text": "This is demonstrated by the invented examples (1) and native case), a benefactive (dative case) and a patient (accusative case), zustimmen (to agree) has a strong preference for only selecting an agentive subject (nominative case) and an indirect object theme (dative case).", "labels": [], "entities": []}, {"text": "So in the latter case the NP cannot receive case from the verb and is instead the genitive modifier of the dative NP.", "labels": [], "entities": []}, {"text": "While for examples (1) and (2) knowledge about the syntactic verb subcategorization functions is sufficient to correctly predict the NP cases, examples (3) to (6) require subcategorization information at the syntax-semantic interface.", "labels": [], "entities": []}, {"text": "In all four examples, the verb and the participating noun phrases Mitarbeiter (employee), Kollege (colleague) and Bericht (report) are identical, and the noun phrases are assigned the same case.", "labels": [], "entities": [{"text": "Bericht", "start_pos": 114, "end_pos": 121, "type": "METRIC", "confidence": 0.9559136629104614}]}, {"text": "However, given that the stemmed output of the translation does not tell us anything about case features, in order to predict the appropriate cases of the three noun phrases, we either rely on ordering heuristics (such that the nominative NP is more likely to be in the beginning of the sentence (the German Vorfeld) than the accusative or dative NP, even though all three of these would be grammatical), or we need fine-grained subcategorization information beyond pure syntax.", "labels": [], "entities": []}, {"text": "For example, both Mitarbeiter and Kollege would satisfy the agentive subject role of the verb geben better than Bericht, and Bericht is more likely to be the patient of geben.", "labels": [], "entities": []}, {"text": "The contribution of this paper is to improve the prediction of casein our SMT system by implementing and combining two alternative routes to integrate subcategorization information from the syntax-semantic interface: (i) We regard the translation as a function of the source language input, and project the syntactic functions of the English nouns to their German translations in the SMT output.", "labels": [], "entities": [{"text": "SMT", "start_pos": 74, "end_pos": 77, "type": "TASK", "confidence": 0.988100528717041}, {"text": "SMT", "start_pos": 384, "end_pos": 387, "type": "TASK", "confidence": 0.9305458068847656}]}, {"text": "This subcategorization model is necessary when there are several plausible solutions for the syntactic functions of a noun in combination with a verb.", "labels": [], "entities": []}, {"text": "For example, both Mitarbeiter and Kollege are plausible subjects and direct objects of the verb geben, so the information about these nouns' roles in the input sentence allows for disambiguation.", "labels": [], "entities": []}, {"text": "(ii) The case of an NP is derived from an external knowledge base comprising quantitative, dependency-based information about German verb subcategorization frames and noun modification.", "labels": [], "entities": [{"text": "noun modification", "start_pos": 167, "end_pos": 184, "type": "TASK", "confidence": 0.7105417400598526}]}, {"text": "The verb subcategorization information is not restricted to syntactic noun functions but models association strength for verbnoun pairs with regard to the entire subcategorization frame plus the syntactic functions of the nouns.", "labels": [], "entities": []}, {"text": "For example, the database can tell us that while the verb geben is very likely to subcategorize a ditransitive frame, the verb zustimmen is very likely to subcategorize only a direct object, next to the obligatory subject (subcat frame prediction).", "labels": [], "entities": []}, {"text": "Furthermore, we can retrieve the information that the noun Bericht is less likely to appear as subject of geben than the nouns Mitarbeiter and Kollege (verb-noun subcat case prediction).", "labels": [], "entities": [{"text": "verb-noun subcat case prediction", "start_pos": 152, "end_pos": 184, "type": "TASK", "confidence": 0.6008467599749565}]}, {"text": "And we can lookup that the noun Aktion is very unlikely to be a genitive modification of Regierung (cf. table 1), while Kollege is a plausible genitive modification of Bericht (noun-noun modification case prediction, cf. example (2)).", "labels": [], "entities": [{"text": "Regierung", "start_pos": 89, "end_pos": 98, "type": "DATASET", "confidence": 0.9358534216880798}, {"text": "noun-noun modification case prediction", "start_pos": 177, "end_pos": 215, "type": "TASK", "confidence": 0.7300052419304848}]}, {"text": "In summary, model (i) applies when there are no obvious preferences concerning verb-noun subcategorization or noun-noun modification.", "labels": [], "entities": [{"text": "noun-noun modification", "start_pos": 110, "end_pos": 132, "type": "TASK", "confidence": 0.7079926282167435}]}, {"text": "Model (ii) predicts case relying on the subcategorization and modification preferences.", "labels": [], "entities": []}, {"text": "The combination of our two models approaches a simplified level of semantic role definition but only relies on dependency information that is considerably easier and cheaper to define and obtain than a very high quality semantic parser and/or a corpus annotated with semantic role information.", "labels": [], "entities": [{"text": "semantic role definition", "start_pos": 67, "end_pos": 91, "type": "TASK", "confidence": 0.6528713802496592}]}, {"text": "Integrating semantic role information into SMT has been demonstrated by various researchers to improve translation quality (cf.,,,).", "labels": [], "entities": [{"text": "SMT", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.9805310368537903}]}, {"text": "Our approach is inline with who demonstrated that on the one hand 84% of verb syntactic functions in a 50-sentence test corpus projected from Chinese to English, and that on the other hand about 15% of the subjects were not translated into subjects, but their semantic roles were preserved across language.", "labels": [], "entities": []}, {"text": "These two findings correspond to the expected uses of our models (i) and (ii), respectively.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present experiments using different feature combinations.", "labels": [], "entities": []}, {"text": "We also present a manual evaluation of our best system which shows that the new features improve translation quality.", "labels": [], "entities": [{"text": "translation", "start_pos": 97, "end_pos": 108, "type": "TASK", "confidence": 0.9624403715133667}]}, {"text": "We use the hierarchical translation system that comes with the Moses SMT-package and GIZA++ to compute the word alignment, using the \"growdiag-final-and\" heuristics.", "labels": [], "entities": [{"text": "Moses SMT-package", "start_pos": 63, "end_pos": 80, "type": "DATASET", "confidence": 0.7587414979934692}, {"text": "word alignment", "start_pos": 107, "end_pos": 121, "type": "TASK", "confidence": 0.6910352259874344}]}, {"text": "The rule table was computed with the default parameter setting for GHKM extraction () in the implementation by.", "labels": [], "entities": [{"text": "GHKM extraction", "start_pos": 67, "end_pos": 82, "type": "TASK", "confidence": 0.7952266335487366}]}, {"text": "Our training data contains 1,485,059 parallel sentences ; the German part of the parallel data is used as the target-side language model.", "labels": [], "entities": []}, {"text": "The dev and test sets (1025/1026 lines) are wmt-2009-a/b.", "labels": [], "entities": []}, {"text": "For predicting the grammatical features, we used the Wapiti Toolkit (.", "labels": [], "entities": [{"text": "Wapiti Toolkit", "start_pos": 53, "end_pos": 67, "type": "DATASET", "confidence": 0.8515263497829437}]}, {"text": "We train four CRFs on data prepared as shown in section 3.", "labels": [], "entities": []}, {"text": "The corpora used for the extraction of subcategorization tuples were Europarl and German newspaper data (200 million words).", "labels": [], "entities": [{"text": "Europarl", "start_pos": 69, "end_pos": 77, "type": "DATASET", "confidence": 0.9865710139274597}, {"text": "German newspaper data", "start_pos": 82, "end_pos": 103, "type": "DATASET", "confidence": 0.8400298555692037}]}, {"text": "We choose this particular data combination in order to provide data that matches the training data, as well as to add new data of the test set's domain (news).", "labels": [], "entities": []}, {"text": "The German part of Europarl was dependencyparsed with Bohnet (2010), and subcategorization information was extracted as described in; the newspaper data (HGC -Huge German Corpus) was parsed with, and subcategorization information was extracted as described in Schulte im Walde (2002b).", "labels": [], "entities": [{"text": "Europarl", "start_pos": 19, "end_pos": 27, "type": "DATASET", "confidence": 0.5138305425643921}, {"text": "newspaper data (HGC -Huge German Corpus)", "start_pos": 138, "end_pos": 178, "type": "DATASET", "confidence": 0.9248132374551561}]}, {"text": "In order to provide a better understanding of the impact of the presented features, in particular to see whether there is an improvement inadequacy, we carried out a manual evaluation comparing sys- The numbers in table 5 are artificially high and downplay the difference as they also include cases which are very easy to predict, such as nouns in PPs where only one value for case is possible.", "labels": [], "entities": []}, {"text": "We measure how many case labels were correctly predicted, not correct inflected forms.", "labels": [], "entities": []}, {"text": "tem with the simple prediction system (1).", "labels": [], "entities": []}, {"text": "From the set of different sentences between the simple prediction system and the enriched system (144 of 1026), we evaluated those where the English input sentence was between 8 and 25 words long (46 sentences in total).", "labels": [], "entities": []}, {"text": "We specifically restricted the test set in order to provide sentences which are less difficult to annotate, as longer sentences are often very disfluent and too hard to rate.", "labels": [], "entities": []}, {"text": "Most of the sentences in the evaluation set differ only in the realization of one NP.", "labels": [], "entities": []}, {"text": "For comparing the two systems, the sentences were presented in random order to 3 native speakers of German.", "labels": [], "entities": []}, {"text": "The evaluation consists of two parts: first, the participants were asked to decide which sentence is better without being given the English input (this measures fluency).", "labels": [], "entities": []}, {"text": "In the second part, they should to mark that sentence which better reproduces the content of the English input sentence (this measures adequacy).", "labels": [], "entities": []}, {"text": "The test set is the same for both tasks, the only difference being that the English input is given in the second part.", "labels": [], "entities": []}, {"text": "The results are given in table 6.", "labels": [], "entities": []}, {"text": "Summarizing we can say that the participants prefer the enriched system over the simple system in both parts; there is a high agreement (17 cases) in decisions over those sentences which were rated as enriched better.", "labels": [], "entities": []}, {"text": "When looking at the pairwise inter-annotator agreement for the task of annotating the test-set with the 3 possible labels enriched preferred, simple preferred and no preference, we find that the annotators P1 and P2 have a substantial agreement: Output from the simple system (1) and the enriched system (4).", "labels": [], "entities": []}, {"text": "in terms of Kappa (\u03ba = 0.6184), whereas the agreement of P3 with P1/P2 respectively leads to lower scores (\u03ba = 0.4467 and \u03ba = 0.3596).", "labels": [], "entities": []}, {"text": "However, the annotators tend to agree well on sentences with the label enriched preferred, but largely disagree on sentences labelled as either simple preferred or no preference.", "labels": [], "entities": []}, {"text": "The number of decisions where all three annotators agree on a label when given the English input is listed in table 6(c): for example, only two sentences were given the label baseline is better by all three annotators.", "labels": [], "entities": []}, {"text": "This outcome shows how difficult it is to rate disfluent SMT output.", "labels": [], "entities": [{"text": "SMT", "start_pos": 57, "end_pos": 60, "type": "TASK", "confidence": 0.9197632670402527}]}, {"text": "For evaluating the case prediction system, the distinction between enriched preferred and enriched dispreferred is the most important question to answer.", "labels": [], "entities": [{"text": "case prediction", "start_pos": 19, "end_pos": 34, "type": "TASK", "confidence": 0.8928513526916504}]}, {"text": "Redefining the annotation task to annotating only two values by grouping the labels simple preferred and no preference into one annotation possibility leads to \u03ba = 0.7391, \u03ba = 0.4048 and \u03ba = 0.5652.", "labels": [], "entities": []}, {"text": "shows some examples for output from the simple system and the system using source-side and subcategorization features.", "labels": [], "entities": []}, {"text": "In the first sentence, the subject NP a helicopter was inflected as a direct object in the simple system, but as a subject in the enriched system, which was preferred by all three annotators.", "labels": [], "entities": []}, {"text": "In the second sentence, the NP their trust, i.e. a direct object of put, was incorrectly predicted as genitive-modifier of 38 % (i.e. 38 % of their trust) in the simple system.", "labels": [], "entities": []}, {"text": "The enriched system made use of the preference for accusative for the pair Vertrauen schenken (place trust), correctly inflecting this NP as direct object.", "labels": [], "entities": []}, {"text": "Interestingly, only two annotators preferred the enriched system, whereas one was undecided.", "labels": [], "entities": []}, {"text": "The third sentence illustrates how difficult it is to rate case marking on disfluent SMT output: there are two possibilities to translate enter the money market; the direct equivalent of the English phrase (den Geldmarkt Acc betreten), or via the use of a prepositional phrase (auf den Geldmarkt Acc treten: \"to step into the money market\").", "labels": [], "entities": [{"text": "rate case marking", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.634432464838028}, {"text": "SMT output", "start_pos": 85, "end_pos": 95, "type": "TASK", "confidence": 0.8623229563236237}]}, {"text": "The SMT-output contains a mix of both, i.e. the verb treten (instead of betreten), but without the preposition, which cannot lead to a fully correct inflection.", "labels": [], "entities": [{"text": "SMT-output", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.9521652460098267}]}, {"text": "While the inflection of the simple system (a genitive construction meaning the public sales of the money market) is definitely wrong, the inflection obtained in the enriched system is not useful either, due to the structure of the translation . This difficulty is also reflected by the annotators, who gave twice the label no preference and once the label enriched better.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Overview of the inflection process: the stem markup is highlighted in the SMT output.", "labels": [], "entities": [{"text": "SMT", "start_pos": 84, "end_pos": 87, "type": "TASK", "confidence": 0.9278587102890015}]}, {"text": " Table 3: Number of verb-noun types extracted  from Europarl (EP) and newspaper data (HGC).", "labels": [], "entities": [{"text": "Europarl (EP) and newspaper data (HGC)", "start_pos": 52, "end_pos": 90, "type": "DATASET", "confidence": 0.8523704081773757}]}, {"text": " Table 5: Results of the simple prediction vs. three systems enriched with extra features.", "labels": [], "entities": []}, {"text": " Table 6: Manual evaluation of 46 sentences: with- out (a) and with (b) access to EN input, and the  annotators' agreement in the second part (c).", "labels": [], "entities": []}]}