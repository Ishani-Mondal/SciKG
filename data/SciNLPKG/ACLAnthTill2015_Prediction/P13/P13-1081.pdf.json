{"title": [{"text": "Enlisting the Ghost: Modeling Empty Categories for Machine Translation", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.7521368563175201}]}], "abstractContent": [{"text": "Empty categories (EC) are artificial elements in Penn Treebanks motivated by the government-binding (GB) theory to explain certain language phenomena such as pro-drop.", "labels": [], "entities": [{"text": "Penn Treebanks", "start_pos": 49, "end_pos": 63, "type": "DATASET", "confidence": 0.991632729768753}]}, {"text": "ECs are ubiquitous in languages like Chinese, but they are tacitly ignored inmost machine translation (MT) work because of their elusive nature.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 82, "end_pos": 106, "type": "TASK", "confidence": 0.850570797920227}]}, {"text": "In this paper we present a comprehensive treatment of ECs by first recovering them with a structured MaxEnt model with a rich set of syntactic and lexical features, and then incorporating the predicted ECs into a Chinese-to-English machine translation task through multiple approaches, including the extraction of EC-specific sparse features.", "labels": [], "entities": [{"text": "Chinese-to-English machine translation task", "start_pos": 213, "end_pos": 256, "type": "TASK", "confidence": 0.7322657555341721}]}, {"text": "We show that the recovered empty categories not only improve the word alignment quality, but also lead to significant improvements in a large-scale state-of-the-art syntactic MT system.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 65, "end_pos": 79, "type": "TASK", "confidence": 0.7563746869564056}, {"text": "MT", "start_pos": 175, "end_pos": 177, "type": "TASK", "confidence": 0.8128479719161987}]}], "introductionContent": [{"text": "One of the key challenges in statistical machine translation (SMT) is to effectively model inherent differences between the source and the target language.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 29, "end_pos": 66, "type": "TASK", "confidence": 0.8145585606495539}]}, {"text": "Take the Chinese-English SMT as an example: it is non-trivial to produce correct pronouns on the target side when the source-side pronoun is missing.", "labels": [], "entities": [{"text": "SMT", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.7756322622299194}]}, {"text": "In addition, the pro-drop problem can also degrade the word alignment quality in the training data.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 55, "end_pos": 69, "type": "TASK", "confidence": 0.7252762317657471}]}, {"text": "A sentence pair observed in the real data is shown in along with the word alignment obtained from an automatic word aligner, where the English subject pronoun * This work was done when the author was with IBM.", "labels": [], "entities": []}, {"text": "\"that\" is missing on the Chinese side.", "labels": [], "entities": [{"text": "Chinese side", "start_pos": 25, "end_pos": 37, "type": "DATASET", "confidence": 0.9347248077392578}]}, {"text": "Consequently, \"that\" is incorrectly aligned to the second to the last Chinese word \"De\", due to their high co-occurrence frequency in the training data.", "labels": [], "entities": []}, {"text": "If the dropped pronoun were recovered, \"that\" would have been aligned with the dropped-pro (cf. 3), which is a much more sensible alignment.", "labels": [], "entities": []}, {"text": "In order to account for certain language phenomena such as pro-drop and wh-movement, a set of special tokens, called empty categories (EC), are used in Penn Treebanks ().", "labels": [], "entities": [{"text": "Penn Treebanks", "start_pos": 152, "end_pos": 166, "type": "DATASET", "confidence": 0.9867479503154755}]}, {"text": "Since empty categories do not exist in the surface form of a language, they are often deemed elusive and recovering ECs is even figuratively called \"chasing the ghost\".", "labels": [], "entities": []}, {"text": "In this work we demonstrate that, with the availability of large-scale EC annotations, it is feasible to predict and recover ECs with high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9881860017776489}]}, {"text": "More importantly, with various approaches of modeling the recovered ECs in SMT, we are able to achieve significant improvements . The contributions of this paper include the following: \u2022 Propose a novel structured approach to EC prediction, including the exact word-level lo-cation and EC labels.", "labels": [], "entities": [{"text": "SMT", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.9813778400421143}, {"text": "EC prediction", "start_pos": 226, "end_pos": 239, "type": "TASK", "confidence": 0.9090596139431}]}, {"text": "Our results are significantly higher inaccuracy than that of the state-of-the-art; \u2022 Measure the effect of ECs on automatic word alignment for machine translation after integrating recovered ECs into the MT data; \u2022 Design EC-specific features for phrases and syntactic tree-to-string rules in translation grammar; \u2022 Show significant improvement on top of the state-of-the-art large-scale hierarchical and syntactic machine translation systems.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 124, "end_pos": 138, "type": "TASK", "confidence": 0.7256537526845932}, {"text": "machine translation", "start_pos": 143, "end_pos": 162, "type": "TASK", "confidence": 0.7805757820606232}, {"text": "MT data", "start_pos": 204, "end_pos": 211, "type": "DATASET", "confidence": 0.7287359982728958}, {"text": "translation grammar", "start_pos": 293, "end_pos": 312, "type": "TASK", "confidence": 0.9174477756023407}, {"text": "syntactic machine translation", "start_pos": 405, "end_pos": 434, "type": "TASK", "confidence": 0.7639602621396383}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we present a structured approach to EC prediction.", "labels": [], "entities": [{"text": "EC prediction", "start_pos": 50, "end_pos": 63, "type": "TASK", "confidence": 0.9577851593494415}]}, {"text": "In Section 3, we describe the integration of Chinese ECs in MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 60, "end_pos": 62, "type": "TASK", "confidence": 0.8760126829147339}]}, {"text": "The experimental results for both EC prediction and SMT are reported in Section 4.", "labels": [], "entities": [{"text": "EC prediction", "start_pos": 34, "end_pos": 47, "type": "TASK", "confidence": 0.8851160407066345}, {"text": "SMT", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.9861161708831787}]}, {"text": "A survey on the related work is conducted in Section 5, and Section 6 summarizes the work and introduces some future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: List of features.", "labels": [], "entities": []}, {"text": " Table 3: Example of frequent word pairs used for  sparse features.", "labels": [], "entities": []}, {"text": " Table 4: Prediction accuracy with gold parse trees,  where NULL represents the cases where no ECs  should be produced.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9508029222488403}, {"text": "NULL", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.9860922694206238}]}, {"text": " Table 5: Prediction accuracy with system- generated parse trees.", "labels": [], "entities": [{"text": "Prediction", "start_pos": 10, "end_pos": 20, "type": "TASK", "confidence": 0.845855176448822}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9811286926269531}]}, {"text": " Table 6: Prediction accuracy with system- generated parse trees, modeling * pro * and  * PRO * only.", "labels": [], "entities": [{"text": "Prediction", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.7606262564659119}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9233154654502869}]}, {"text": " Table 7: Comparison with the previous results, us- ing the same training and test data. T: parse trees.  G: gold parse trees. S: system-generated parse  trees. P: precision. R: recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 164, "end_pos": 173, "type": "METRIC", "confidence": 0.9980459213256836}, {"text": "recall", "start_pos": 178, "end_pos": 184, "type": "METRIC", "confidence": 0.9932140111923218}]}, {"text": " Table 8: Word alignment F1 scores with or without  * pro * and * PRO * .", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.6892406642436981}, {"text": "F1", "start_pos": 25, "end_pos": 27, "type": "METRIC", "confidence": 0.9403654336929321}, {"text": "PRO", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.9567216634750366}]}, {"text": " Table 9: Word alignment accuracy for function  words only.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.7400898337364197}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.967452347278595}]}, {"text": " Table 10: BLEU scores in the Hiero system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9985557198524475}, {"text": "Hiero system", "start_pos": 30, "end_pos": 42, "type": "DATASET", "confidence": 0.9244680106639862}]}, {"text": " Table 11: BLEU scores in the tree-to-string system  with Hiero rules as backoff.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9982977509498596}]}]}