{"title": [{"text": "Temporal Signals Help Label Temporal Relations", "labels": [], "entities": [{"text": "Temporal Signals Help Label Temporal Relations", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.8157093326250712}]}], "abstractContent": [{"text": "Automatically determining the temporal order of events and times in a text is difficult, though humans can readily perform this task.", "labels": [], "entities": []}, {"text": "Sometimes events and times are related through use of an explicit coordination which gives information about the temporal relation: expressions like \"before\" and \"as soon as\".", "labels": [], "entities": []}, {"text": "We investigate the r\u00f4le that these coordinating temporal signals have in determining the type of temporal relations in discourse.", "labels": [], "entities": []}, {"text": "Using machine learning, we improve upon prior approaches to the problem, achieving over 80% accuracy at labelling the types of temporal relation between events and times that are related by temporal signals.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9990959167480469}]}], "introductionContent": [{"text": "It is important to understand time in language.", "labels": [], "entities": []}, {"text": "The ability to express and comprehend expressions of time enables us to plan, to tell stories, and to discuss change in the world around us.", "labels": [], "entities": []}, {"text": "When we automatically extract temporal information, we are often concerned with events and times -referred to collectively as temporal intervals.", "labels": [], "entities": []}, {"text": "We might ask, for example, \"Who is the current President of the USA?.\"", "labels": [], "entities": []}, {"text": "In order to extract an answer to this question from a document collection, we need to identify events related to persons becoming president and the times of those events.", "labels": [], "entities": []}, {"text": "Crucially, however, we also need to identify the temporal relations between these events and times, perhaps, for example, by recognizing a temporal relation type from a set such as that of.", "labels": [], "entities": []}, {"text": "This last task, temporal relation typing, is challenging, and is the focus of this paper.", "labels": [], "entities": [{"text": "temporal relation typing", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.7267600695292155}]}, {"text": "Temporal signals are words or phrases that act as discourse markers that co-ordinate a pair of events or times and explicitly state the nature of the temporal relation that holds between them.", "labels": [], "entities": [{"text": "Temporal signals are words or phrases that act as discourse markers that co-ordinate a pair of events or times and explicitly state the nature of the temporal relation that holds between them", "start_pos": 0, "end_pos": 191, "type": "Description", "confidence": 0.8312616171315312}]}, {"text": "For example, in \"The parade reached the town hall before noon\", the word before is a temporal signal, co-ordinating the event reached with the time noon.", "labels": [], "entities": []}, {"text": "Intuitively, these signal words act as discourse contain temporal ordering information that human readers can readily access, and indeed this hypothesis is borne out empirically.", "labels": [], "entities": []}, {"text": "In this paper, we present an in-depth examination into the role temporal signals can play in machine learning for temporal relation typing, within the framework of TimeML ().", "labels": [], "entities": [{"text": "temporal relation typing", "start_pos": 114, "end_pos": 138, "type": "TASK", "confidence": 0.6400447885195414}]}], "datasetContent": [{"text": "We only approach the relation typing task, and we use existing signal annotations -that is, we do not attempt to automatically identify temporal signals.", "labels": [], "entities": [{"text": "relation typing task", "start_pos": 21, "end_pos": 41, "type": "TASK", "confidence": 0.9059801499048868}]}, {"text": "The corpus used is the signal-curated version of TimeBank (.", "labels": [], "entities": [{"text": "TimeBank", "start_pos": 49, "end_pos": 57, "type": "DATASET", "confidence": 0.9449124932289124}]}, {"text": "This corpus, TBsig, 1 adds extra events, times and relations to TimeBank, in an effort to correct signal under-annotation in the original corpus.", "labels": [], "entities": [{"text": "TimeBank", "start_pos": 64, "end_pos": 72, "type": "DATASET", "confidence": 0.9248217940330505}]}, {"text": "Like the original TimeBank corpus, it comprises 183 documents.", "labels": [], "entities": [{"text": "TimeBank corpus", "start_pos": 18, "end_pos": 33, "type": "DATASET", "confidence": 0.9702293276786804}]}, {"text": "In these, we are interested only in the temporal relations that use a signal.", "labels": [], "entities": []}, {"text": "There are 851 signals annotated in the corpus, co-ordinating 886 temporal re-1 See http://derczynski.com/sheffield/resources/tb sig.tar.bz2 lations (13.7% of all).", "labels": [], "entities": []}, {"text": "For comparison, TimeBank has 688 signal annotations which co-ordinate 718 temporal relations (11.2%).", "labels": [], "entities": [{"text": "TimeBank", "start_pos": 16, "end_pos": 24, "type": "DATASET", "confidence": 0.9453533291816711}]}, {"text": "When evaluating classifiers, we performed 10-fold cross-validation, keeping splits at document level.", "labels": [], "entities": []}, {"text": "There are only 14 signalled time-time relations in this corpus, which is not enough to support any generalizations, and so we disregard this interval type pairing.", "labels": [], "entities": []}, {"text": "As is common with statistical approaches to temporal relation typing, we also perform relation folding; that is, to reduce the number of possible classes, we sometimes invert argument order and relation type.", "labels": [], "entities": [{"text": "temporal relation typing", "start_pos": 44, "end_pos": 68, "type": "TASK", "confidence": 0.6454763313134512}, {"text": "relation folding", "start_pos": 86, "end_pos": 102, "type": "TASK", "confidence": 0.8155724704265594}]}, {"text": "For example, A BEFORE B and B AFTER A convey the same temporal relation, and so we can remove all AF-TER-type relations by swapping their argument order and converting them to BEFORE relations.", "labels": [], "entities": [{"text": "BEFORE B", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9729215800762177}, {"text": "BEFORE", "start_pos": 176, "end_pos": 182, "type": "METRIC", "confidence": 0.9503530859947205}]}, {"text": "This lossless process condenses the labels that our classifier has to distinguish between, though classification remains a multi-class problem.", "labels": [], "entities": []}, {"text": "We adopt the base feature set of, which consists mainly of TimeML event and time annotation surface attributes.", "labels": [], "entities": []}, {"text": "These are, for events: class, aspect, modality, tense, polarity, part of speech; and, for times: value, type, function in document, mod, quant.", "labels": [], "entities": []}, {"text": "To these are added same-tense and same-aspect features, as well as the string values of events/times.", "labels": [], "entities": []}, {"text": "The feature groups we use here are: \u2022 Base -The attributes of TimeML annotations involved (includes tense, aspect, polarity and soon as above), as with previous approaches.", "labels": [], "entities": []}, {"text": "\u2022 Argument Ordering -Two features: a boolean set if both arguments are in the same sentence (as in), and the text order of argument intervals (as in).", "labels": [], "entities": []}, {"text": "\u2022 Signal Ordering -Textual ordering is important with temporal signals; compare \"You walk before you run\" and \"Before you walk you run\".", "labels": [], "entities": [{"text": "Signal Ordering", "start_pos": 2, "end_pos": 17, "type": "TASK", "confidence": 0.6932785958051682}, {"text": "Textual ordering", "start_pos": 19, "end_pos": 35, "type": "TASK", "confidence": 0.6469151824712753}]}, {"text": "We add features accounting for relative textual position of signal and arguments as per.", "labels": [], "entities": []}, {"text": "To these we add a feature reporting whether the signal occurs in first, last, or mid-sentence position, and features to indicate whether each interval is in the same sentence as the signal.", "labels": [], "entities": []}, {"text": "\u2022 Syntactic -We add syntactic features: following, the lowest common constituent label between each argument and, the syntactic path from each argument to the signal, using a top-level ROOT node for cross-sentence paths; and three features indicating whether there is a temporal function tag (-TMP between each of the intervals or the signal to the root note.", "labels": [], "entities": []}, {"text": "These features are generated using the Stanford parser () and a function tagger).", "labels": [], "entities": []}, {"text": "\u2022 Signal Text -We add the signal's raw string, as well as its lower-case version and its lemma.", "labels": [], "entities": []}, {"text": "\u2022 DCT -For event-time relations, whether the time expression also functions as the document's creation timestamp.", "labels": [], "entities": []}, {"text": "Collectively, these feature groups comprise the All feature set.", "labels": [], "entities": [{"text": "All feature set", "start_pos": 48, "end_pos": 63, "type": "DATASET", "confidence": 0.7578766047954559}]}, {"text": "For comparison, the feature set we reported in previous work is also included, labeled DG2010.", "labels": [], "entities": [{"text": "DG2010", "start_pos": 87, "end_pos": 93, "type": "DATASET", "confidence": 0.9750164747238159}]}, {"text": "This set contains the base and the signal ordering feature groups only, plus a single signal feature for the signal raw string.", "labels": [], "entities": []}, {"text": "Using these feature representations we trained multinomial na\u00a8\u0131vena\u00a8\u0131ve Bayes (, maximum entropy, adaptive boosting (Freund and Schapire, 1997;), multi-class SVM () and random forest 2) classifiers via Scikit-learn).", "labels": [], "entities": []}, {"text": "We use two baselines: most-common-class and a model trained with no signal features.", "labels": [], "entities": []}, {"text": "We also introduce two measures replicating earlier work: one using the DG2010 features and the classifier used in that work (maximum entropy), and another using the DG2010 features with the best-performing classifier under our All feature set, in order to see if performance changes are due to features or classifier.", "labels": [], "entities": [{"text": "DG2010", "start_pos": 71, "end_pos": 77, "type": "DATASET", "confidence": 0.9761723279953003}, {"text": "DG2010", "start_pos": 165, "end_pos": 171, "type": "DATASET", "confidence": 0.9481740593910217}]}, {"text": "Classifiers were evaluated by determining if the class they output matched the relation type in TB-sig.", "labels": [], "entities": [{"text": "TB-sig", "start_pos": 96, "end_pos": 102, "type": "DATASET", "confidence": 0.9266242384910583}]}, {"text": "For comparison with the general case, i.e. for both signalled and non-signalled temporal relation instances, we list performance with a maximum entropy classifier and the base feature set on TB-sig's temporal relations.", "labels": [], "entities": []}, {"text": "These are split into those that use a signal and those that do not, though no features relaying signal information are included.", "labels": [], "entities": []}, {"text": "In order to assess the adequacy of the dataset in terms of size, we also examined performance using a maximum entropy classifier learned from varying subproportions of the training data.", "labels": [], "entities": []}, {"text": "This was measured over event-event relations, using all features.", "labels": [], "entities": []}, {"text": "That performance appears to stabilise and level off indicates that the training set is of sufficient size for these experiments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Relation typing performance using the base feature set, for relations with and without a temporal signal.", "labels": [], "entities": [{"text": "Relation typing", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.7512641847133636}]}, {"text": " Table 2: Results at temporal relation typing over TB-sig, for relations that use a temporal signal", "labels": [], "entities": [{"text": "temporal relation typing", "start_pos": 21, "end_pos": 45, "type": "TASK", "confidence": 0.6135867536067963}]}, {"text": " Table 3: Relation typing accuracy based on various fea- ture combinations, using random forests. Bold figures  indicate the largest performance change.", "labels": [], "entities": [{"text": "Relation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9492549896240234}, {"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.8509405851364136}]}, {"text": " Table 5: Top ten largest-weighted feature:value pairs.", "labels": [], "entities": []}]}