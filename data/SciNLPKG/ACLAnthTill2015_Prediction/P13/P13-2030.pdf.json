{"title": [{"text": "An Improved MDL-Based Compression Algorithm for Unsupervised Word Segmentation", "labels": [], "entities": [{"text": "Word Segmentation", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.6684509664773941}]}], "abstractContent": [{"text": "We study the mathematical properties of a recently proposed MDL-based unsuper-vised word segmentation algorithm, called regularized compression.", "labels": [], "entities": [{"text": "MDL-based unsuper-vised word segmentation", "start_pos": 60, "end_pos": 101, "type": "TASK", "confidence": 0.5794220939278603}, {"text": "regularized compression", "start_pos": 120, "end_pos": 143, "type": "TASK", "confidence": 0.7359115481376648}]}, {"text": "Our analysis shows that its objective function can be efficiently approximated using the negative empirical pointwise mutual information.", "labels": [], "entities": []}, {"text": "The proposed extension improves the baseline performance in both efficiency and accuracy on a standard benchmark.", "labels": [], "entities": [{"text": "efficiency", "start_pos": 65, "end_pos": 75, "type": "METRIC", "confidence": 0.9852283000946045}, {"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9979472756385803}]}], "introductionContent": [{"text": "Hierarchical Bayes methods have been mainstream in unsupervised word segmentation since the dawn of hierarchical Dirichlet process) and adaptors grammar . Despite this wide recognition, they are also notoriously computational prohibitive and have limited adoption on larger corpora.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.7369387596845627}]}, {"text": "While much effort has been directed to mitigating this issue within the Bayes framework (), many have found minimum description length (MDL) based methods more promising in addressing the scalability problem.", "labels": [], "entities": []}, {"text": "MDL-based methods) rely on underlying search algorithms to segment the text in as many possible ways and use description length to decide which to output.", "labels": [], "entities": []}, {"text": "As different algorithms explore different trajectories in the search space, segmentation accuracy depends largely on the search coverage.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.8843775987625122}]}, {"text": "Early work in this line focused more on existing segmentation algorithm, such as branching entropy) and bootstrap voting experts.", "labels": [], "entities": []}, {"text": "A recent study) on a compression-based algorithm, regularized compression, has achieved comparable performance result to hierarchical Bayes methods.", "labels": [], "entities": [{"text": "regularized compression", "start_pos": 50, "end_pos": 73, "type": "TASK", "confidence": 0.8036726713180542}]}, {"text": "Along this line, in this paper we present a novel extension to the regularized compressor algorithm.", "labels": [], "entities": []}, {"text": "We propose a lower-bound approximate to the original objective and show that, through analysis and experimentation, this amendment improves segmentation performance and runtime efficiency.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 140, "end_pos": 152, "type": "TASK", "confidence": 0.9721135497093201}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: The performance result on the Bernstein- Ratner corpus. Segmentation performance is mea- sured using word-level precision (P), recall (R),  and F-measure (F).", "labels": [], "entities": [{"text": "word-level precision (P)", "start_pos": 111, "end_pos": 135, "type": "METRIC", "confidence": 0.7868915975093842}, {"text": "recall (R)", "start_pos": 137, "end_pos": 147, "type": "METRIC", "confidence": 0.9524285048246384}, {"text": "F-measure (F)", "start_pos": 154, "end_pos": 167, "type": "METRIC", "confidence": 0.9598377346992493}]}, {"text": " Table 3: The performance chart on the Bernstein-Ratner corpus, in descending order of word-level F- measure. We deliberately reproduced the results for adaptors grammar and regularized compression. The  other measurements came directly from the literature.", "labels": [], "entities": [{"text": "word-level F- measure", "start_pos": 87, "end_pos": 108, "type": "METRIC", "confidence": 0.8410486578941345}]}, {"text": " Table 4: The average running time in seconds on  the Bernstein-Ratner corpus for adaptors grammar  (per fold, based on trace output) and regularized  compressors, tested on an Intel Xeon 2.5GHz 8- core machine with 8GB RAM.", "labels": [], "entities": []}]}