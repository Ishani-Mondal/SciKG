{"title": [{"text": "Multigraph Clustering for Unsupervised Coreference Resolution", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.8723879754543304}]}], "abstractContent": [{"text": "We present an unsupervised model for coreference resolution that casts the problem as a clustering task in a directed labeled weighted multigraph.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.974464476108551}]}, {"text": "The model outperforms most systems participating in the English track of the CoNLL'12 shared task.", "labels": [], "entities": [{"text": "CoNLL'12 shared task", "start_pos": 77, "end_pos": 97, "type": "DATASET", "confidence": 0.7671048839886984}]}], "introductionContent": [{"text": "Coreference resolution is the task of determining which mentions in a text refer to the same entity.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9178739488124847}]}, {"text": "With the advent of machine learning and the availability of annotated corpora in the mid 1990s the research focus shifted from rule-based approaches to supervised machine learning techniques.", "labels": [], "entities": []}, {"text": "Quite recently, however, rule-based approaches regained popularity due to Stanford's multi-pass sieve approach which exhibits stateof-the-art performance on many standard coreference data sets and also won the CoNLL-2011 shared task on coreference resolution).", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 236, "end_pos": 258, "type": "TASK", "confidence": 0.8873290121555328}]}, {"text": "These results show that carefully crafted rule-based systems which employ suitable inference schemes can achieve competitive performance.", "labels": [], "entities": []}, {"text": "Such a system can be considered unsupervised in the sense that it does not employ training data for optimizing parameters.", "labels": [], "entities": []}, {"text": "In this paper we present a graph-based approach for coreference resolution that models a document to be processed as a graph.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.9812754690647125}]}, {"text": "The nodes are mentions and the edges correspond to relations between mentions.", "labels": [], "entities": []}, {"text": "Coreference resolution is performed via graph clustering.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9129869043827057}]}, {"text": "Our approach belongs to a class of recently proposed graph models for coreference resolution and is designed to be a simplified version of existing approaches.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 70, "end_pos": 92, "type": "TASK", "confidence": 0.9705986678600311}]}, {"text": "In contrast to previous models belonging to this class we do not learn any edge weights but perform inference on the graph structure only which renders our model unsupervised.", "labels": [], "entities": []}, {"text": "On the English data of the CoNLL'12 shared task the model outperforms most systems which participated in the shared task.", "labels": [], "entities": [{"text": "English data of the CoNLL'12 shared task", "start_pos": 7, "end_pos": 47, "type": "DATASET", "confidence": 0.6908786126545498}]}], "datasetContent": [{"text": "We use the data provided for the English track of the CoNLL'12 shared task on multilingual coreference resolution) which is a subset of the upcoming OntoNotes 5.0 release and comes with various annotation layers provided by state-of-the-art NLP tools.", "labels": [], "entities": [{"text": "CoNLL'12 shared task on multilingual coreference resolution", "start_pos": 54, "end_pos": 113, "type": "TASK", "confidence": 0.6546681949070522}]}, {"text": "We used the official dev/test split for development and evaluation.", "labels": [], "entities": []}, {"text": "We evaluate the model in a setting that corresponds to the shared task's closed track, i.e. we use only WordNet, the number and gender data of and the provided annotation layers.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 104, "end_pos": 111, "type": "DATASET", "confidence": 0.9631602764129639}]}, {"text": "To extract system mentions we employ the mention extractor described in.", "labels": [], "entities": []}, {"text": "We evaluate our system with the coreference resolution evaluation metrics that were used for the CoNLL shared tasks on coreference, which are MUC (, B 3 (Bagga and Baldwin, 1998) and CEAF e ().", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.9185920357704163}, {"text": "MUC", "start_pos": 142, "end_pos": 145, "type": "METRIC", "confidence": 0.5969330072402954}, {"text": "CEAF e", "start_pos": 183, "end_pos": 189, "type": "METRIC", "confidence": 0.6720584034919739}]}, {"text": "We also report the unweighted average of the three scores, which was the official evaluation metric in the shared tasks.", "labels": [], "entities": []}, {"text": "To compute the scores we employed the official scorer supplied by the shared task organizers.: Results of different systems on the CoNLL'12 English data sets.", "labels": [], "entities": [{"text": "CoNLL'12 English data sets", "start_pos": 131, "end_pos": 157, "type": "DATASET", "confidence": 0.9701311886310577}]}], "tableCaptions": [{"text": " Table 1: Results of different systems on the CoNLL'12 English data sets.", "labels": [], "entities": [{"text": "CoNLL'12 English data sets", "start_pos": 46, "end_pos": 72, "type": "DATASET", "confidence": 0.9745975732803345}]}, {"text": " Table 4: Number of recall errors according to  mention type (rows anaphor, columns antecedent).", "labels": [], "entities": [{"text": "recall errors", "start_pos": 20, "end_pos": 33, "type": "METRIC", "confidence": 0.9349601566791534}]}]}