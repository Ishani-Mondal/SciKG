{"title": [{"text": "Transfer Learning Based Cross-lingual Knowledge Extraction for Wikipedia", "labels": [], "entities": [{"text": "Cross-lingual Knowledge Extraction", "start_pos": 24, "end_pos": 58, "type": "TASK", "confidence": 0.632245679696401}]}], "abstractContent": [{"text": "Wikipedia infoboxes area valuable source of structured knowledge for global knowledge sharing.", "labels": [], "entities": [{"text": "Wikipedia infoboxes", "start_pos": 0, "end_pos": 19, "type": "DATASET", "confidence": 0.9643752872943878}, {"text": "global knowledge sharing", "start_pos": 69, "end_pos": 93, "type": "TASK", "confidence": 0.6342093547185262}]}, {"text": "However, infobox information is very incomplete and imbal-anced among the Wikipedias in different languages.", "labels": [], "entities": []}, {"text": "It is a promising but challenging problem to utilize the rich struc-tured knowledge from a source language Wikipedia to help complete the missing in-foboxes fora target language.", "labels": [], "entities": []}, {"text": "In this paper, we formulate the problem of cross-lingual knowledge extraction from multilingual Wikipedia sources, and present a novel framework, called Wiki-CiKE, to solve this problem.", "labels": [], "entities": [{"text": "cross-lingual knowledge extraction from multilingual Wikipedia sources", "start_pos": 43, "end_pos": 113, "type": "TASK", "confidence": 0.7838125910077777}]}, {"text": "An instance-based transfer learning method is utilized to overcome the problems of topic drift and translation errors.", "labels": [], "entities": [{"text": "topic drift", "start_pos": 83, "end_pos": 94, "type": "TASK", "confidence": 0.7220330834388733}]}, {"text": "Our experimental results demonstrate that WikiCiKE out-performs the monolingual knowledge extraction method and the translation-based method.", "labels": [], "entities": [{"text": "knowledge extraction", "start_pos": 80, "end_pos": 100, "type": "TASK", "confidence": 0.7066148072481155}]}], "introductionContent": [{"text": "In recent years, the automatic knowledge extraction using Wikipedia has attracted significant research interest in research fields, such as the semantic web.", "labels": [], "entities": [{"text": "automatic knowledge extraction", "start_pos": 21, "end_pos": 51, "type": "TASK", "confidence": 0.6732435723145803}]}, {"text": "As a valuable source of structured knowledge, Wikipedia infoboxes have been utilized to build linked open data, support next-generation information retrieval), improve question answering (, and other aspects of data exploitation) using semantic web standards, such as RDF ( and OWL;, and their reasoning services.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 136, "end_pos": 157, "type": "TASK", "confidence": 0.7729323506355286}, {"text": "question answering", "start_pos": 168, "end_pos": 186, "type": "TASK", "confidence": 0.8395148515701294}]}, {"text": "However, most infoboxes in different Wikipedia language versions are missing.", "labels": [], "entities": []}, {"text": "shows the statistics of article numbers and infobox information for six major Wikipedias.", "labels": [], "entities": []}, {"text": "Only 32.82% of the articles have infoboxes on average, and the numbers of infoboxes for these Wikipedias vary significantly.", "labels": [], "entities": []}, {"text": "For instance, the English Wikipedia has 13 times more infoboxes than the Chinese Wikipedia and 3.5 times more infoboxes than the second largest Wikipedia of German language.", "labels": [], "entities": []}, {"text": "To solve this problem, KYLIN has been proposed to extract the missing infoboxes from unstructured article texts for the English Wikipedia (.", "labels": [], "entities": [{"text": "English Wikipedia", "start_pos": 120, "end_pos": 137, "type": "DATASET", "confidence": 0.8637329041957855}]}, {"text": "KYLIN performs well when sufficient training data are available, and such techniques as shrinkage and retraining have been used to increase recall from English Wikipedia's long tail of sparse infobox classes ( ).", "labels": [], "entities": [{"text": "KYLIN", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.6769452691078186}, {"text": "recall", "start_pos": 140, "end_pos": 146, "type": "METRIC", "confidence": 0.9982494115829468}]}, {"text": "The extraction performance of KYLIN is limited by the number of available training samples.", "labels": [], "entities": [{"text": "KYLIN", "start_pos": 30, "end_pos": 35, "type": "DATASET", "confidence": 0.5736377835273743}]}, {"text": "Due to the great imbalance between different Wikipedia language versions, it is difficult to gather sufficient training data from a single Wikipedia.", "labels": [], "entities": []}, {"text": "Some translation-based cross-lingual knowledge extraction methods have been proposed; Adafre and de).", "labels": [], "entities": [{"text": "translation-based cross-lingual knowledge extraction", "start_pos": 5, "end_pos": 57, "type": "TASK", "confidence": 0.7108951508998871}, {"text": "Adafre", "start_pos": 86, "end_pos": 92, "type": "DATASET", "confidence": 0.8875217437744141}]}, {"text": "These methods concentrate on translating existing infoboxes from a richer source language version of Wikipedia into the target language.", "labels": [], "entities": []}, {"text": "The recall of new target infoboxes is highly limited by the number of equivalent cross-lingual articles and the number of existing source infoboxes.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.996377170085907}]}, {"text": "Take Chinese-English 1 Wikipedias as an example: current translation-based methods only work for 87,603 Chinese Wikipedia articles, 20.43% of the total 428,777 articles.", "labels": [], "entities": []}, {"text": "Hence, the challenge remains: how could we supplement the missing infoboxes for the rest 79.57% articles?", "labels": [], "entities": []}, {"text": "On the other hand, the numbers of existing infobox attributes in different languages are highly imbalanced.", "labels": [], "entities": []}, {"text": "shows the comparison of the numbers of the articles for the attributes in template PERSON between English and Chinese Wikipedia.", "labels": [], "entities": []}, {"text": "Extracting the missing value for these attributes, such as awards, weight, influences and style, inside the single Chinese Wikipedia is intractable due to the rarity of existing Chinese attribute-value pairs.", "labels": [], "entities": []}, {"text": "In this paper, we have the following hypothesis: one can use the rich English (auxiliary) information to assist the Chinese (target) infobox extraction.", "labels": [], "entities": [{"text": "Chinese (target) infobox extraction", "start_pos": 116, "end_pos": 151, "type": "TASK", "confidence": 0.5257401466369629}]}, {"text": "In general, we address the problem of crosslingual knowledge extraction by using the imbalance between Wikipedias of different languages.", "labels": [], "entities": [{"text": "crosslingual knowledge extraction", "start_pos": 38, "end_pos": 71, "type": "TASK", "confidence": 0.719953735669454}]}, {"text": "For each attribute, we aim to learn an extractor to find the missing value from the unstructured article texts in the target Wikipedia by using the rich information in the source language.", "labels": [], "entities": []}, {"text": "Specifically, we treat this cross-lingual information extraction task as a transfer learning-based binary classification problem.", "labels": [], "entities": [{"text": "cross-lingual information extraction task", "start_pos": 28, "end_pos": 69, "type": "TASK", "confidence": 0.6951327249407768}, {"text": "transfer learning-based binary classification", "start_pos": 75, "end_pos": 120, "type": "TASK", "confidence": 0.6433462277054787}]}, {"text": "The contributions of this paper are as follows: 1.", "labels": [], "entities": []}, {"text": "We propose a transfer learning-based crosslingual knowledge extraction framework called WikiCiKE.", "labels": [], "entities": [{"text": "transfer learning-based crosslingual knowledge extraction", "start_pos": 13, "end_pos": 70, "type": "TASK", "confidence": 0.582357931137085}, {"text": "WikiCiKE", "start_pos": 88, "end_pos": 96, "type": "DATASET", "confidence": 0.9230391979217529}]}, {"text": "The extraction performance for the target Wikipedia is improved by using rich infoboxes and textual information in the source language.", "labels": [], "entities": []}, {"text": "2. We propose the TrAdaBoost-based extractor training method to avoid the problems of topic drift and translation errors of the source Wikipedia.", "labels": [], "entities": [{"text": "TrAdaBoost-based extractor training", "start_pos": 18, "end_pos": 53, "type": "TASK", "confidence": 0.6008831361929575}, {"text": "topic drift", "start_pos": 86, "end_pos": 97, "type": "TASK", "confidence": 0.7506344020366669}]}, {"text": "Meanwhile, some languageindependent features are introduced to make WikiCiKE as general as possible.", "labels": [], "entities": []}, {"text": "3. Chinese-English experiments for four typical attributes demonstrate that WikiCiKE outperforms both the monolingual extraction method and current translation-based method.", "labels": [], "entities": []}, {"text": "The increases of 12.65% for precision and 12.47% for recall in the template named person are achieved when only 30 target training articles are available.", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9996558427810669}, {"text": "recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9995166063308716}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents some basic concepts, the problem formalization and the overview of WikiCiKE.", "labels": [], "entities": []}, {"text": "In Section 3, we propose our detailed approaches.", "labels": [], "entities": []}, {"text": "We present our experiments in Section 4.", "labels": [], "entities": []}, {"text": "Some related work is described in Section 5.", "labels": [], "entities": []}, {"text": "We conclude our work and the future work in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present our experiments to evaluate the effectiveness of WikiCiKE, where we focus on the Chinese-English case; in other words, the target language is Chinese and the source language is English.", "labels": [], "entities": []}, {"text": "It is part of our future work to try other language pairs which two Wikipedias of these languages are imbalanced in infobox information such as English-Dutch.", "labels": [], "entities": []}, {"text": "Following Lavelli's research on evaluation of information extraction, we perform evaluation as follows.", "labels": [], "entities": [{"text": "evaluation of information extraction", "start_pos": 32, "end_pos": 68, "type": "TASK", "confidence": 0.7067613899707794}]}, {"text": "1. We evaluate each attr separately.", "labels": [], "entities": []}, {"text": "2. For each attr, there is exactly one value extracted.", "labels": [], "entities": []}, {"text": "3. No alternative occurrence of real value is available.", "labels": [], "entities": []}, {"text": "4. The overlap ratio is used in this paper rather than \"exactly matching\" and \"containing\".", "labels": [], "entities": [{"text": "overlap ratio", "start_pos": 7, "end_pos": 20, "type": "METRIC", "confidence": 0.987549215555191}]}, {"text": "Given an extracted value v \u2032 = {w \u2032 } and its corresponding real value v = {w}, two measurements for evaluating the overlap ratio are defined: recall: the rate of matched tokens w.r.t. the real value.", "labels": [], "entities": [{"text": "overlap ratio", "start_pos": 116, "end_pos": 129, "type": "METRIC", "confidence": 0.9680818021297455}, {"text": "recall", "start_pos": 143, "end_pos": 149, "type": "METRIC", "confidence": 0.9995552897453308}]}, {"text": "It can be calculated using precision: the rate of matched tokens w.r.t. the extracted value.", "labels": [], "entities": [{"text": "precision", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9988377690315247}]}, {"text": "It can be calculated using We use the average of these two measures to evaluate the performance of our extractor as follows: The recall and precision range from 0 to 1 and are first calculated on a single instance and then averaged over the testing instances.", "labels": [], "entities": [{"text": "recall", "start_pos": 129, "end_pos": 135, "type": "METRIC", "confidence": 0.9996034502983093}, {"text": "precision", "start_pos": 140, "end_pos": 149, "type": "METRIC", "confidence": 0.9913596510887146}]}], "tableCaptions": [{"text": " Table 1: The Numbers of Articles in TEMPLATE  PERSON between English(en) and Chinese(zh).", "labels": [], "entities": []}, {"text": " Table 5: Results for country in TEMPLATE  FILM.", "labels": [], "entities": [{"text": "TEMPLATE", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.8975091576576233}, {"text": "FILM", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.7012037038803101}]}, {"text": " Table 6: Results of WikiCiKE vs. KE-Tr.", "labels": [], "entities": []}, {"text": " Table 7: Results of Significance Test.", "labels": [], "entities": []}]}