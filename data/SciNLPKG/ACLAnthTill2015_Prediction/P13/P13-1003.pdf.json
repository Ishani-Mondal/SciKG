{"title": [{"text": "Training Nondeficient Variants of IBM-3 and IBM-4 for Word Alignment", "labels": [], "entities": [{"text": "IBM-3", "start_pos": 34, "end_pos": 39, "type": "DATASET", "confidence": 0.9239259958267212}, {"text": "Word Alignment", "start_pos": 54, "end_pos": 68, "type": "TASK", "confidence": 0.6967663764953613}]}], "abstractContent": [{"text": "We derive variants of the fertility based models IBM-3 and IBM-4 that, while maintaining their zero and first order parameters , are nondeficient.", "labels": [], "entities": [{"text": "IBM-3", "start_pos": 49, "end_pos": 54, "type": "DATASET", "confidence": 0.9446601867675781}, {"text": "IBM-4", "start_pos": 59, "end_pos": 64, "type": "DATASET", "confidence": 0.9234809279441833}]}, {"text": "Subsequently, we proceed to derive a method to compute a likely alignment and its neighbors as well as give a solution of EM training.", "labels": [], "entities": [{"text": "EM", "start_pos": 122, "end_pos": 124, "type": "TASK", "confidence": 0.8800263404846191}]}, {"text": "The arising M-step energies are non-trivial and handled via projected gradient ascent.", "labels": [], "entities": []}, {"text": "Our evaluation on gold alignments shows substantial improvements (in weighted F-measure) for the IBM-3.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9592325687408447}, {"text": "IBM-3", "start_pos": 97, "end_pos": 102, "type": "DATASET", "confidence": 0.9721975922584534}]}, {"text": "For the IBM-4 there are no consistent improvements.", "labels": [], "entities": [{"text": "IBM-4", "start_pos": 8, "end_pos": 13, "type": "DATASET", "confidence": 0.932666003704071}]}, {"text": "Training the nondeficient IBM-5 in the regular way gives surprisingly good results.", "labels": [], "entities": [{"text": "IBM-5", "start_pos": 26, "end_pos": 31, "type": "DATASET", "confidence": 0.9464735388755798}]}, {"text": "Using the resulting alignments for phrase-based translation systems offers no clear insights w.r.t.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 35, "end_pos": 59, "type": "TASK", "confidence": 0.7958409786224365}]}], "introductionContent": [{"text": "While most people think of the translation and word alignment models IBM-3 and IBM-4 as inherently deficient models (i.e. models that assign non-zero probability mass to impossible events), in this paper we derive nondeficient variants maintaining their zero order (IBM-3) and first order (IBM-4) parameters.", "labels": [], "entities": [{"text": "translation and word alignment", "start_pos": 31, "end_pos": 61, "type": "TASK", "confidence": 0.7956566959619522}]}, {"text": "This is possible as IBM-3 and IBM-4 are very special cases of general loglinear models: they are properly derived by the chain rule of probabilities.", "labels": [], "entities": [{"text": "IBM-3", "start_pos": 20, "end_pos": 25, "type": "DATASET", "confidence": 0.9392427206039429}, {"text": "IBM-4", "start_pos": 30, "end_pos": 35, "type": "DATASET", "confidence": 0.9321638941764832}]}, {"text": "Deficiency is only introduced by ignoring apart of the history to be conditioned on in the individual factors of the chain rule factorization.", "labels": [], "entities": []}, {"text": "While at first glance this seems necessary to obtain zero and first order de-: Plot of the negative log.", "labels": [], "entities": []}, {"text": "likelihoods (the quantity to be minimized) arising in training deficient and nondeficient models (for Europarl German | English, training scheme 1 5 H 5 3 5 4 5 ).", "labels": [], "entities": [{"text": "Europarl German", "start_pos": 102, "end_pos": 117, "type": "DATASET", "confidence": 0.9712737798690796}]}, {"text": "1/3/4=IBM-1/3/4, H=HMM, T=Transfer iteration.", "labels": [], "entities": [{"text": "IBM-1/3/4", "start_pos": 6, "end_pos": 15, "type": "DATASET", "confidence": 0.9081180810928344}, {"text": "T", "start_pos": 24, "end_pos": 25, "type": "METRIC", "confidence": 0.9649599194526672}]}, {"text": "The curves are identical up to iteration 11.", "labels": [], "entities": []}, {"text": "Iteration 11 shows that merely 5.14% of the (HMM) probability mass are covered by the Viterbi alignment and its neighbors.", "labels": [], "entities": [{"text": "Viterbi alignment", "start_pos": 86, "end_pos": 103, "type": "DATASET", "confidence": 0.921154797077179}]}, {"text": "With deficient models (and deficient empty words) the final negative log likelihood is higher than the initial HMM one, with nondeficient models it is lower than for the HMM, as it should be fora better model.", "labels": [], "entities": [{"text": "final negative log likelihood", "start_pos": 54, "end_pos": 83, "type": "METRIC", "confidence": 0.6834172680974007}]}, {"text": "pendencies, we show that with proper renormalization all factors can be made nondeficient.", "labels": [], "entities": []}, {"text": "Having introduced the model variants, we proceed to derive a hillclimbing method to compute a likely alignment (ideally the Viterbi alignment) and its neighbors.", "labels": [], "entities": []}, {"text": "As for the deficient models, this plays an important role in the E-step of the subsequently derived expectation maximization (EM) training scheme.", "labels": [], "entities": [{"text": "E-step", "start_pos": 65, "end_pos": 71, "type": "METRIC", "confidence": 0.9664438366889954}]}, {"text": "As usual, expectations in EM are approximated, but we now also get non-trivial Mstep energies.", "labels": [], "entities": []}, {"text": "We deal with these via projected gradient ascent.", "labels": [], "entities": []}, {"text": "The downside of our method is its resource consumption, but still we present results on corpora with 100.000 sentence pairs.", "labels": [], "entities": []}, {"text": "The source code of this project is available in our word alignment software RegAligner 1 , version 1.2 and later.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 52, "end_pos": 66, "type": "TASK", "confidence": 0.7972438037395477}, {"text": "RegAligner 1", "start_pos": 76, "end_pos": 88, "type": "DATASET", "confidence": 0.8570183515548706}]}, {"text": "gives a first demonstration of how much the proposed variants differ from the standard models by visualizing the resulting negative log likelihoods 2 , the quantity to be minimized in EM-training.", "labels": [], "entities": []}, {"text": "The nondeficient IBM-4 derives a lower negative log likelihood than the HMM, the regular deficient variant only a lower one than the IBM-1.", "labels": [], "entities": [{"text": "IBM-4", "start_pos": 17, "end_pos": 22, "type": "DATASET", "confidence": 0.9057684540748596}, {"text": "negative log likelihood", "start_pos": 39, "end_pos": 62, "type": "METRIC", "confidence": 0.6653793056805929}]}, {"text": "As an aside, the transfer iteration from HMM to IBM3 (iteration 11) reveals that only 5.14% of the probability mass are preserved when using the Viterbi alignment and its neighbors instead of all alignments.", "labels": [], "entities": [{"text": "IBM3", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.8974879384040833}]}, {"text": "Indeed, it is widely recognized that -with proper initialization -fertility based models outperform sequence based ones.", "labels": [], "entities": []}, {"text": "In particular, sequence based models can simply ignore apart of the sentence to be conditioned on, while fertility based models explicitly factor in a probability of words in this sentence to have no aligned words (or any other number of aligned words, called the fertility).", "labels": [], "entities": []}, {"text": "Hence, it is encouraging to see that the nondeficient IBM-4 indeed derives a higher likelihood than the sequence based HMM.", "labels": [], "entities": [{"text": "IBM-4", "start_pos": 54, "end_pos": 59, "type": "DATASET", "confidence": 0.9182888269424438}, {"text": "likelihood", "start_pos": 84, "end_pos": 94, "type": "METRIC", "confidence": 0.9572750329971313}]}, {"text": "Related Work Today's most widely used models for word alignment are still the models IBM 1-5 of and the HMM of, thoroughly evaluated in.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 49, "end_pos": 63, "type": "TASK", "confidence": 0.8364350497722626}]}, {"text": "While it is known that fertilitybased models outperform sequence-based ones, the large bulk of word alignment literature following these publications has mostly ignored fertilitybased models.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 95, "end_pos": 109, "type": "TASK", "confidence": 0.7716071903705597}]}, {"text": "This is different in the present paper which deals exclusively with such models.", "labels": [], "entities": []}, {"text": "One reason for the lack of interest is surely that computing expectations and Viterbi alignments for these models is a hard problem ().", "labels": [], "entities": []}, {"text": "Nevertheless, computing Viterbi align-1 https://github.com/Thomas1205/RegAligner, for the reported results we used a slightly earlier version.", "labels": [], "entities": [{"text": "Thomas1205", "start_pos": 59, "end_pos": 69, "type": "DATASET", "confidence": 0.9436383247375488}, {"text": "RegAligner", "start_pos": 70, "end_pos": 80, "type": "METRIC", "confidence": 0.732884407043457}]}, {"text": "Note that the figure slightly favors IBM-1 and HMM as for them the length J of the foreign sequence is assumed to be known whereas IBM-3 and IBM-4 explicitly predict it.", "labels": [], "entities": [{"text": "IBM-1", "start_pos": 37, "end_pos": 42, "type": "DATASET", "confidence": 0.9177273511886597}]}, {"text": "3 This number regards the corpus probability as in (9) to the power of 1/S, i.e. the objective function in maximum likelihood training.", "labels": [], "entities": []}, {"text": "The number is not entirely fair as alignments where more than half the words align to the empty word are assigned a probability of 0.", "labels": [], "entities": []}, {"text": "Still, this is an issue only for short sentences.", "labels": [], "entities": []}, {"text": "ments for the IBM-3 has been shown to often be practicable.", "labels": [], "entities": [{"text": "ments", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9716467261314392}, {"text": "IBM-3", "start_pos": 14, "end_pos": 19, "type": "DATASET", "confidence": 0.9194586277008057}]}, {"text": "Much work has been spent on HMM-based formulations, focusing on the computationally tractable side ().", "labels": [], "entities": []}, {"text": "In addition, some rather complex models have been proposed that usually aim to replace the fertility based models (.", "labels": [], "entities": []}, {"text": "Another line of models) focuses on joint probabilities to get around the garbage collection effect (i.e. that for conditional models, rare words in the given language align to too many words in the predicted language).", "labels": [], "entities": []}, {"text": "The downside is that these models are computationally harder to handle.", "labels": [], "entities": []}, {"text": "A more recent line of work introduces various forms of regularity terms, often in the form of symmetrization () and recently by using L 0 norms ().", "labels": [], "entities": []}], "datasetContent": [{"text": "We test the proposed methods on subsets of the Europarl corpus for German and English as well as Spanish and English, using lower-cased corpora.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 47, "end_pos": 62, "type": "DATASET", "confidence": 0.9878954887390137}]}, {"text": "We evaluate alignment accuracies on gold alignments 6 in the form of weighted F-measures with \u03b1 = 0.1, which performed well in).", "labels": [], "entities": [{"text": "F-measures", "start_pos": 78, "end_pos": 88, "type": "METRIC", "confidence": 0.9578008055686951}]}, {"text": "In addition we evaluate the effect on phrase-based translation on one of the tasks.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 38, "end_pos": 62, "type": "TASK", "confidence": 0.7479961812496185}]}, {"text": "We implement the proposed methods in our own framework RegAligner rather than GIZA++, which is only rudimentally maintained.", "labels": [], "entities": [{"text": "RegAligner", "start_pos": 55, "end_pos": 65, "type": "DATASET", "confidence": 0.9293546676635742}]}, {"text": "Therefore, we compare to the deficient models in our own software as well as to those in GIZA++.", "labels": [], "entities": []}, {"text": "We run 5 iterations of IBM-1, followed by 5 iterations of HMM, 5 of IBM-3 and finally 5 of IBM-4.", "labels": [], "entities": [{"text": "IBM-1", "start_pos": 23, "end_pos": 28, "type": "DATASET", "confidence": 0.9531029462814331}, {"text": "IBM-3", "start_pos": 68, "end_pos": 73, "type": "DATASET", "confidence": 0.9391351938247681}, {"text": "IBM-4", "start_pos": 91, "end_pos": 96, "type": "DATASET", "confidence": 0.9599851965904236}]}, {"text": "The first iteration of the IBM-3 collects counts from the HMM, and likewise the first iteration of the IBM-4 collects counts from the IBM-3 (in both cases the move and swap matrices are filled with probabilities of the former model, then theses matrices are used as in a regular model iteration).", "labels": [], "entities": [{"text": "IBM-3", "start_pos": 134, "end_pos": 139, "type": "DATASET", "confidence": 0.9315783977508545}]}, {"text": "A nondeficient IBM-4 is always initialized by a nondeficient IBM-3.", "labels": [], "entities": []}, {"text": "We did not set a fertility limit (except for GIZA++).", "labels": [], "entities": [{"text": "fertility limit", "start_pos": 17, "end_pos": 32, "type": "METRIC", "confidence": 0.9458144903182983}]}, {"text": "Experiments were run on a Core i5 with 2.5 GHz and 8 GB of memory.", "labels": [], "entities": []}, {"text": "The latter was the main reason why we did not use still larger corpora . The running times for the entire training were half a day without word classes and a day with word classes.", "labels": [], "entities": []}, {"text": "With 50 instead of 250 PGA iterations in all M-steps we get only half these running times, but the resulting F-measures deteriorate, especially for the IBM-4 with classes.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 109, "end_pos": 119, "type": "METRIC", "confidence": 0.9862820506095886}]}, {"text": "The running times of our implementation of the IBM-5 are much more favorable: the entire training then runs in little more than an hour.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Alignment accuracy (weighted F-measure times 100, \u03b1 = 0.1) on Europarl with 100.000  sentence pairs. Reduced deficiency means renormalization as in", "labels": [], "entities": [{"text": "Alignment", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8500825762748718}, {"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.637234091758728}, {"text": "F-measure", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9073554277420044}, {"text": "Europarl", "start_pos": 72, "end_pos": 80, "type": "DATASET", "confidence": 0.9925109148025513}, {"text": "deficiency", "start_pos": 119, "end_pos": 129, "type": "METRIC", "confidence": 0.9229654669761658}]}, {"text": " Table 2: Evaluation of phrase-based translation  from German to English with the obtained align- ments (for 100.000 sentence pairs). Training is run  in both directions and the resulting alignments are  combined via diag-grow-final-and. The  table shows no clear superiority of any method.", "labels": [], "entities": [{"text": "phrase-based translation  from German to English", "start_pos": 24, "end_pos": 72, "type": "TASK", "confidence": 0.7854897379875183}]}]}