{"title": [{"text": "Random Walk Factoid Annotation for Collective Discourse", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we study the problem of automatically annotating the factoids present in collective discourse.", "labels": [], "entities": []}, {"text": "Factoids are information units that are shared between instances of collective discourse and may have many different ways of being realized in words.", "labels": [], "entities": []}, {"text": "Our approach divides this problem into two steps, using a graph-based approach for each step: (1) factoid discovery , finding groups of words that correspond to the same factoid, and (2) factoid assignment, using these groups of words to mark collective discourse units that contain the respective factoids.", "labels": [], "entities": [{"text": "factoid discovery", "start_pos": 98, "end_pos": 115, "type": "TASK", "confidence": 0.9044509828090668}, {"text": "factoid assignment", "start_pos": 187, "end_pos": 205, "type": "TASK", "confidence": 0.863880455493927}]}, {"text": "We study this on two novel data sets: the New Yorker caption contest data set, and the crossword clues data set.", "labels": [], "entities": [{"text": "New Yorker caption contest data set", "start_pos": 42, "end_pos": 77, "type": "DATASET", "confidence": 0.7206597874561945}, {"text": "crossword clues data set", "start_pos": 87, "end_pos": 111, "type": "DATASET", "confidence": 0.7812858819961548}]}], "introductionContent": [{"text": "Collective discourse tends to contain relatively few factoids, or information units about which the author speaks, but many nuggets, different ways to speak about or refer to a factoid ().", "labels": [], "entities": []}, {"text": "Many natural language applications could be improved with good factoid annotation.", "labels": [], "entities": []}, {"text": "Our approach in this paper divides this problem into two subtasks: discovery of factoids, and assignment of factoids.", "labels": [], "entities": [{"text": "discovery of factoids", "start_pos": 67, "end_pos": 88, "type": "TASK", "confidence": 0.8147854606310526}, {"text": "assignment of factoids", "start_pos": 94, "end_pos": 116, "type": "TASK", "confidence": 0.8796349167823792}]}, {"text": "We take a graph-based approach to the problem, clustering a word graph to discover factoids and using random walks to assign factoids to discourse units.", "labels": [], "entities": []}, {"text": "We also introduce two new datasets in this paper, covered in more detail in section 3.", "labels": [], "entities": []}, {"text": "The New Yorker cartoon caption dataset, provided by Robert Mankoff, the cartoon editor at The New Yorker magazine, is composed of readersubmitted captions fora cartoon published in the magazine.", "labels": [], "entities": [{"text": "New Yorker cartoon caption dataset", "start_pos": 4, "end_pos": 38, "type": "DATASET", "confidence": 0.691126424074173}]}, {"text": "The crossword clue dataset consists * Cartoon Editor, The New Yorker magazine of word-clue pairs used in major American crossword puzzles, with most words having several hundred different clues published for it.", "labels": [], "entities": [{"text": "Cartoon Editor, The New Yorker magazine", "start_pos": 38, "end_pos": 77, "type": "DATASET", "confidence": 0.7218969762325287}]}, {"text": "The term \"factoid\" is used as in, but in a slightly more abstract sense in this paper, denoting a set of related words that should ideally refer to a real-world entity, but may not for some of the less coherent factoids.", "labels": [], "entities": []}, {"text": "The factoids discovered using this method don't necessarily correspond to the factoids that might be chosen by annotators.", "labels": [], "entities": []}, {"text": "For example, given two user-submitted cartoon captions \u2022 \"When they said, 'Take us to your leader,' I don't think they meant your mother's house,\" \u2022 and \"You'd better call your mother and tell her to set a few extra place settings,\" a human may say that they share the factoid called \"mother.\"", "labels": [], "entities": []}, {"text": "The automatic methods however, might say that these captions share factoid3, which is identified by the words \"mother,\" \"in-laws,\" \"family,\" \"house,\" etc.", "labels": [], "entities": []}, {"text": "The layout of this paper is as follows: we review related work in section 2, we introduce the datasets in detail in section 3, we describe our methods in section 4, and report results in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate this task in away similar to pairwise clustering evaluation methods, where every pair of discourse units that should share at least one factoid and does is a true positive instance, every pair that should share a factoid and does not is a false negative, etc.", "labels": [], "entities": []}, {"text": "From this we are able to calculate precision, recall, and F1-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9997550845146179}, {"text": "recall", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9996893405914307}, {"text": "F1-score", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9992382526397705}]}, {"text": "This is a reasonable evaluation method, since the average number of factoids per discourse unit is close to one.", "labels": [], "entities": []}, {"text": "Because the factoids discovered by this method don't necessarily match the factoids chosen by the annotators, it doesn't make sense to try to measure whether two discourse units share the \"correct\" factoid.", "labels": [], "entities": []}, {"text": "show the results of the various methods on the cartoon captions and crossword clues datasets, respectively.", "labels": [], "entities": []}, {"text": "On the crossword clues datasets, the random-walk-based methods are clearly superior to the other methods tested, whereas simple clustering is more effective on the   cartoon captions dataset.", "labels": [], "entities": [{"text": "cartoon captions dataset", "start_pos": 166, "end_pos": 190, "type": "DATASET", "confidence": 0.6646863321463267}]}, {"text": "In some sense, the two datasets in this paper both represent difficult domains, ones in which authors are intentionally obscure.", "labels": [], "entities": []}, {"text": "The good results acheived on the crossword clues dataset indicate that this obscurity can be overcome when discourse units are short.", "labels": [], "entities": []}, {"text": "Future work in this vein includes applying these methods to domains, such as newswire, that are more typical for summarization, and if necessary, investigating how these methods can best be applied to domains with longer sentences.", "labels": [], "entities": [{"text": "summarization", "start_pos": 113, "end_pos": 126, "type": "TASK", "confidence": 0.9886654615402222}]}], "tableCaptions": [{"text": " Table 3: Examples of similar pairs of words as cal- culated on the set of crossword clues for \"tea\".", "labels": [], "entities": []}, {"text": " Table 4: Performance of various methods annotat- ing factoids for cartoon captions.", "labels": [], "entities": [{"text": "cartoon captions", "start_pos": 67, "end_pos": 83, "type": "TASK", "confidence": 0.6724321246147156}]}, {"text": " Table 5: Performance of various methods annotat- ing factoids for crossword clues.", "labels": [], "entities": [{"text": "crossword clues", "start_pos": 67, "end_pos": 82, "type": "TASK", "confidence": 0.8761230111122131}]}]}