{"title": [{"text": "Stem Translation with Affix-Based Rule Selection for Agglutinative Languages", "labels": [], "entities": [{"text": "Stem Translation", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.948979914188385}]}], "abstractContent": [{"text": "Current translation models are mainly designed for languages with limited morphology , which are not readily applicable to agglutinative languages as the difference in the way lexical forms are generated.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel approach for translating agglutinative languages by treating stems and affixes differently.", "labels": [], "entities": [{"text": "translating agglutinative languages", "start_pos": 47, "end_pos": 82, "type": "TASK", "confidence": 0.874602735042572}]}, {"text": "We employ stem as the atomic translation unit to alleviate data spare-ness.", "labels": [], "entities": [{"text": "atomic translation", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.7071946710348129}]}, {"text": "In addition, we associate each stem-granularity translation rule with a distribution of related affixes, and select desirable rules according to the similarity of their affix distributions with given spans to be translated.", "labels": [], "entities": []}, {"text": "Experimental results show that our approach significantly improves the translation performance on tasks of translating from three Turkic languages to Chinese.", "labels": [], "entities": [{"text": "translation", "start_pos": 71, "end_pos": 82, "type": "TASK", "confidence": 0.9714031219482422}]}], "introductionContent": [{"text": "Currently, most methods on statistical machine translation (SMT) are developed for translation of languages with limited morphology (e.g., English, Chinese).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 27, "end_pos": 64, "type": "TASK", "confidence": 0.8104823927084605}]}, {"text": "They assumed that word was the atomic translation unit (ATU), always ignoring the internal morphological structure of word.", "labels": [], "entities": [{"text": "atomic translation unit (ATU)", "start_pos": 31, "end_pos": 60, "type": "TASK", "confidence": 0.6211111396551132}]}, {"text": "This assumption can be traced back to the original IBM word-based models) and several significantly improved models, including phrase-based (, hierarchical) and syntactic (;) models.", "labels": [], "entities": []}, {"text": "These improved models worked well for translating languages like English with large scale parallel corpora available.", "labels": [], "entities": [{"text": "translating languages", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.8928760588169098}]}, {"text": "Different from languages with limited morphology, words of agglutinative languages are formed mainly by concatenation of stems and affixes.", "labels": [], "entities": []}, {"text": "Generally, a stem can attach with several affixes, thus leading to tens of hundreds of possible inflected variants of lexicons fora single stem.", "labels": [], "entities": []}, {"text": "Modeling each lexical form as a separate word will generate high out-of-vocabulary rate for SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 92, "end_pos": 95, "type": "TASK", "confidence": 0.9944692850112915}]}, {"text": "Theoretically, ways like morphological analysis and increasing bilingual corpora could alleviate the problem of data sparsity, but most agglutinative languages are less-studied and suffer from the problem of resource-scarceness.", "labels": [], "entities": []}, {"text": "Therefore, previous research mainly focused on the different inflected variants of the same stem and made various transformation of input by morphological analysis, such as).", "labels": [], "entities": []}, {"text": "These work still assume that the atomic translation unit is word, stem or morpheme, without considering the difference between stems and affixes.", "labels": [], "entities": []}, {"text": "In agglutinative languages, stem is the base part of word not including inflectional affixes.", "labels": [], "entities": []}, {"text": "Affix, especially inflectional affix, indicates different grammatical categories such as tense, person, number and case, etc., which is useful for translation rule disambiguation.", "labels": [], "entities": [{"text": "Affix", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9573190808296204}, {"text": "translation rule disambiguation", "start_pos": 147, "end_pos": 178, "type": "TASK", "confidence": 0.9066328406333923}]}, {"text": "Therefore, we employ stem as the atomic translation unit and use affix information to guide translation rule selection.", "labels": [], "entities": [{"text": "translation rule selection", "start_pos": 92, "end_pos": 118, "type": "TASK", "confidence": 0.8477489550908407}]}, {"text": "Stem-granularity translation rules have much larger coverage and can lower the OOV rate.", "labels": [], "entities": [{"text": "Stem-granularity translation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.777536153793335}, {"text": "OOV rate", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9870382845401764}]}, {"text": "Affix based rule selection takes advantage of auxiliary syntactic roles of affixes to make a better rule selection.", "labels": [], "entities": [{"text": "rule selection", "start_pos": 12, "end_pos": 26, "type": "TASK", "confidence": 0.7545596957206726}]}, {"text": "In this way, we can achieve a balance between rule coverage and matching accuracy, and ultimately improve the translation performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9599218368530273}, {"text": "translation", "start_pos": 110, "end_pos": 121, "type": "TASK", "confidence": 0.9586549997329712}]}, {"text": "We can see that, although the source part of the two translation rules are identical, their affix distributions are quite different.", "labels": [], "entities": []}, {"text": "Affix \"gha\" in the first rule indicates that something is affiliated to a subject, similar to \"of\" in English.", "labels": [], "entities": [{"text": "Affix", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9800196886062622}]}, {"text": "And \"da\" in second rule implies location information.", "labels": [], "entities": []}, {"text": "Therefore, given a span \"zunyi/STM yighin/STM+i/SUF+da/SUF+...\" to be translated, we hope to encourage our model to select the second translation rule.", "labels": [], "entities": []}, {"text": "We can achieve this by calculating similarity between the affix distributions of the translation rule and the span.", "labels": [], "entities": [{"text": "similarity", "start_pos": 35, "end_pos": 45, "type": "METRIC", "confidence": 0.9934881925582886}]}], "datasetContent": [{"text": "In this work, we conduct our experiments on three different agglutinative languages, including Uyghur, Kazakh and Kirghiz.", "labels": [], "entities": []}, {"text": "All of them are derived from Altaic language family, belonging to Turkic languages, and mostly spoken by people in Central Asia.", "labels": [], "entities": []}, {"text": "There are about 24 million people take these languages as mother tongue.", "labels": [], "entities": []}, {"text": "All of the tasks are derived from the evaluation of China Workshop of Machine Translation (CWMT) 2 . shows the statistics of data sets.", "labels": [], "entities": [{"text": "China Workshop of Machine Translation (CWMT)", "start_pos": 52, "end_pos": 96, "type": "TASK", "confidence": 0.7562616840004921}]}, {"text": "For the language model, we use the SRI Language Modeling Toolkit) to train a 5-gram model with the target side of training corpus.", "labels": [], "entities": [{"text": "SRI Language Modeling Toolkit", "start_pos": 35, "end_pos": 64, "type": "DATASET", "confidence": 0.6975834518671036}]}, {"text": "And phrase-based Moses 3 is used as our  word: ATU is surface form, stem: ATU is represented stem, morph: ATU denotes morpheme, affix: stem translation with affix distribution similarity.", "labels": [], "entities": []}, {"text": "BLEU scores in bold means significantly better than the baseline according to) for p-value less than 0.01.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.990886926651001}]}, {"text": "The decoding weights are optimized with MERT to maximum word-level BLEU scores ().", "labels": [], "entities": [{"text": "MERT", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9613472819328308}, {"text": "BLEU scores", "start_pos": 67, "end_pos": 78, "type": "METRIC", "confidence": 0.950772225856781}]}], "tableCaptions": [{"text": " Table 1: Statistics of data sets.  * N means the number of reference, morph is short to morpheme. UY,  KA, KI, CH represent Uyghur, Kazakh, Kirghiz and Chinese respectively.", "labels": [], "entities": []}, {"text": " Table 2: Translation results from Turkic languages  to Chinese.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9812326431274414}]}, {"text": " Table 3: Statistics of training corpus after unsuper- vised(Unsup) and supervised(Sup) morphological  analysis.", "labels": [], "entities": []}]}