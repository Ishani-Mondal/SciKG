{"title": [], "abstractContent": [{"text": "Speaker identification is the task of attributing utterances to characters in a literary narrative.", "labels": [], "entities": [{"text": "Speaker identification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8503139913082123}]}, {"text": "It is challenging to automate because the speakers of the majority of utterances are not explicitly identified in novels.", "labels": [], "entities": []}, {"text": "In this paper, we present a supervised machine learning approach for the task that incorporates several novel features.", "labels": [], "entities": []}, {"text": "The experimental results show that our method is more accurate and general than previous approaches to the problem.", "labels": [], "entities": []}], "introductionContent": [{"text": "Novels are important as social communication documents, in which novelists develop the plot by means of discourse between various characters.", "labels": [], "entities": []}, {"text": "In spite of a frequently expressed opinion that all novels are simply variations of a certain number of basic plots, every novel has a unique plot (or several plots) and a different set of characters.", "labels": [], "entities": []}, {"text": "The interactions among characters, especially in the form of conversations, help the readers construct a mental model of the plot and the changing relationships between characters.", "labels": [], "entities": []}, {"text": "Many of the complexities of interpersonal relationships, such as romantic interests, family ties, and rivalries, are conveyed by utterances.", "labels": [], "entities": []}, {"text": "A precondition for understanding the relationship between characters and plot development in a novel is the identification of speakers behind all utterances.", "labels": [], "entities": [{"text": "identification of speakers behind all utterances", "start_pos": 108, "end_pos": 156, "type": "TASK", "confidence": 0.8334753016630808}]}, {"text": "However, the majority of utterances are not explicitly tagged with speaker names, as is the casein stage plays and film scripts.", "labels": [], "entities": []}, {"text": "In most cases, authors rely instead on the readers' comprehension of the story and of the differences between characters.", "labels": [], "entities": []}, {"text": "Since manual annotation of novels is costly, a system for automatically determining speakers of utterances would facilitate other tasks related to the processing of literary texts.", "labels": [], "entities": []}, {"text": "Speaker identification could also be applied on its own, for instance in generating high quality audio books without human lectors, where each character would be identifiable by a distinct way of speaking.", "labels": [], "entities": [{"text": "Speaker identification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8777005970478058}]}, {"text": "In addition, research on spoken language processing for broadcast and multi-party meetings has demonstrated that the analysis of dialogues is useful for the study of social interactions.", "labels": [], "entities": []}, {"text": "In this paper, we investigate the task of speaker identification in novels.", "labels": [], "entities": [{"text": "speaker identification", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.8731738924980164}]}, {"text": "Departing from previous approaches, we develop a general system that can be trained on relatively small annotated data sets, and subsequently applied to other novels for which no annotation is available.", "labels": [], "entities": []}, {"text": "Since every novel has its own set of characters, speaker identification cannot be formulated as a straightforward tagging problem with a universal set of fixed tags.", "labels": [], "entities": [{"text": "speaker identification", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.9114718437194824}]}, {"text": "Instead, we adopt a ranking approach, which enables our model to be applied to literary texts that are different from the ones it has been trained on.", "labels": [], "entities": []}, {"text": "Our approach is grounded in a variety of features that are easily generalizable across different novels.", "labels": [], "entities": []}, {"text": "Rather than attempt to construct complete semantic models of the interactions, we exploit lexical and syntactic clues in the text itself.", "labels": [], "entities": []}, {"text": "We propose several novel features, including the speaker alternation pattern, the presence of vocatives in utterances, and unsupervised actor-topic features that associate speakers with utterances on the basis of their content.", "labels": [], "entities": []}, {"text": "Experimental evaluation shows that our approach not only outperforms the baseline, but also compares favorably to previous approaches in terms of accuracy and generality, even when tested on novels and authors that are different from those used for training.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9991600513458252}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "After discussing previous work, and defining the terminology, we present our approach and the features that it is based on.", "labels": [], "entities": []}, {"text": "Next, we describe the data, the an-notation details, and the results of our experimental evaluation.", "labels": [], "entities": []}, {"text": "At the end, we discuss an application to extracting a set of family relationships from a novel.", "labels": [], "entities": [{"text": "extracting a set of family relationships from a novel", "start_pos": 41, "end_pos": 94, "type": "TASK", "confidence": 0.8263811204168532}]}], "datasetContent": [{"text": "In this section, we describe experiments conducted to evaluate our speaker identification approach.", "labels": [], "entities": [{"text": "speaker identification", "start_pos": 67, "end_pos": 89, "type": "TASK", "confidence": 0.8707223832607269}]}, {"text": "We refer to our main model as NEIGHBORS, because it incorporates features from the neighboring utterances, as described in Section 4.3.", "labels": [], "entities": [{"text": "NEIGHBORS", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.5483047366142273}]}, {"text": "In contrast, the INDIVIDUAL model relies only on features from the current utterance.", "labels": [], "entities": [{"text": "INDIVIDUAL", "start_pos": 17, "end_pos": 27, "type": "METRIC", "confidence": 0.6446887850761414}]}, {"text": "In an attempt to reproduce the evaluation methodology of EM2010, we also test the ORACLE model, which has access to the gold-standard information about the speakers of eight neighboring utterances in the  range [n \u2212 4, n + 4].", "labels": [], "entities": [{"text": "EM2010", "start_pos": 57, "end_pos": 63, "type": "DATASET", "confidence": 0.9530048370361328}, {"text": "ORACLE", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.9978457689285278}]}, {"text": "Lastly, the BASELINE approach selects the name that is the closest in the narration, which is more accurate than the \"most recent name\" baseline.", "labels": [], "entities": [{"text": "BASELINE", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9568198323249817}, {"text": "accurate", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9777098894119263}]}, {"text": "shows the results of the models trained on annotated utterances from Pride & Prejudice on three test sets.", "labels": [], "entities": []}, {"text": "As expected, the accuracy of all learning models on the test set that comes from the same novel is higher than on unseen novels.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9994668364524841}]}, {"text": "However, in both cases, the drop inaccuracy for the NEIGHBORS model is less than 10%.", "labels": [], "entities": [{"text": "NEIGHBORS", "start_pos": 52, "end_pos": 61, "type": "DATASET", "confidence": 0.6855419278144836}]}, {"text": "Surprisingly, the accuracy is higher on The Steppe than on Emma, even though the different writing style of Chekhov should make the task more difficult for models trained on Austen's prose.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.999541163444519}]}, {"text": "The protagonists of The Steppe are mostly male, and the few female characters rarely speak in the novel.", "labels": [], "entities": [{"text": "The Steppe", "start_pos": 20, "end_pos": 30, "type": "DATASET", "confidence": 0.8594312369823456}]}, {"text": "This renders our gender feature virtually useless, and results in lower accuracy on anaphoric speakers than on explicit speakers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9987032413482666}]}, {"text": "On the other hand, Chekhov prefers to mention speaker names in the dialogues (46% of utterances are in the explicit-speaker category), which makes his prose slightly easier in terms of speaker identification.", "labels": [], "entities": [{"text": "speaker identification", "start_pos": 185, "end_pos": 207, "type": "TASK", "confidence": 0.7231664061546326}]}], "tableCaptions": [{"text": " Table 4: The number of utterances in various  data sets by the type (IS -Implicit Speaker; AS  -Anaphoric Speaker; ES -Explicit Speaker).", "labels": [], "entities": []}, {"text": " Table 5: Speaker identification accuracy (in %) on  Pride & Prejudice, Emma, and The Steppe.", "labels": [], "entities": [{"text": "Speaker identification", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.8390776216983795}, {"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9691605567932129}, {"text": "Pride & Prejudice", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.6063460210959116}, {"text": "Emma", "start_pos": 72, "end_pos": 76, "type": "DATASET", "confidence": 0.8099147081375122}, {"text": "The Steppe", "start_pos": 82, "end_pos": 92, "type": "DATASET", "confidence": 0.8325722515583038}]}, {"text": " Table 6: Speaker identification accuracy (in %) on  Austen's Emma by the type of utterance.", "labels": [], "entities": [{"text": "Speaker identification", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.8472377359867096}, {"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.97974693775177}]}]}