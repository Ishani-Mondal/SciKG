{"title": [{"text": "Is word-to-phone mapping better than phone-phone mapping for handling English words?", "labels": [], "entities": [{"text": "word-to-phone mapping", "start_pos": 3, "end_pos": 24, "type": "TASK", "confidence": 0.6962730288505554}]}], "abstractContent": [{"text": "In this paper, we relook at the problem of pronunciation of English words using native phone set.", "labels": [], "entities": []}, {"text": "Specifically, we investigate methods of pronouncing English words using Telugu phoneset in the context of Telugu Text-to-Speech.", "labels": [], "entities": []}, {"text": "We compare phone-phone substitution and word-phone mapping for pronunciation of En-glish words using Telugu phones.", "labels": [], "entities": [{"text": "phone-phone substitution", "start_pos": 11, "end_pos": 35, "type": "TASK", "confidence": 0.7702569365501404}, {"text": "word-phone mapping", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7303046137094498}]}, {"text": "We are not considering other than native language phoneset in all our experiments.", "labels": [], "entities": []}, {"text": "This differentiates our approach from other works in polyglot speech synthesis.", "labels": [], "entities": [{"text": "polyglot speech synthesis", "start_pos": 53, "end_pos": 78, "type": "TASK", "confidence": 0.6392558614412943}]}], "introductionContent": [{"text": "The objective of a Text-to-Speech (TTS) system is to convert a given text input into a spoken waveform.", "labels": [], "entities": []}, {"text": "Text processing and waveform generation are the two main components of a TTS system.", "labels": [], "entities": [{"text": "Text processing", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8092413246631622}, {"text": "waveform generation", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.9007130861282349}, {"text": "TTS", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.9394993185997009}]}, {"text": "The objective of the text processing component is to convert the given input text into an appropriate sequence of valid phonemic units.", "labels": [], "entities": []}, {"text": "These phonemic units are then realized by the waveform generation component.", "labels": [], "entities": []}, {"text": "For high quality speech synthesis, it is necessary that the text processing unit produce the appropriate sequence of phonemic units, for the given input text.", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 17, "end_pos": 33, "type": "TASK", "confidence": 0.7831584513187408}]}, {"text": "There has been arise in the phenomenon of \"code mixing\".", "labels": [], "entities": [{"text": "code mixing", "start_pos": 43, "end_pos": 54, "type": "TASK", "confidence": 0.7273838520050049}]}, {"text": "This is a phenomenon where lexical items of two languages appear in a single sentence.", "labels": [], "entities": []}, {"text": "Ina multilingual country such as India, we commonly find Indian language text being freely interspersed with English words and phrases.", "labels": [], "entities": []}, {"text": "This is particularly noticeable in the case of text from web sources like blogs, tweets etc.", "labels": [], "entities": []}, {"text": "An informal analysis of a Telugu blog on the web showed that around 20-30% of the text is in English (ASCII) while the remaining is in Telugu (Unicode).", "labels": [], "entities": []}, {"text": "Due to the growth of \"code mixing\" it has become necessary to develop strategies for dealing with such multilingual text in TTS systems.", "labels": [], "entities": [{"text": "TTS", "start_pos": 124, "end_pos": 127, "type": "TASK", "confidence": 0.8835611939430237}]}, {"text": "These multilingual TTS systems should be capable of synthesizing utterances which contain foreign language words or word groups, without sounding unnatural.", "labels": [], "entities": []}, {"text": "The different ways of achieving multilingual TTS synthesis are as follows ().", "labels": [], "entities": [{"text": "TTS synthesis", "start_pos": 45, "end_pos": 58, "type": "TASK", "confidence": 0.9344482123851776}]}], "datasetContent": [{"text": "Once the alignment between the each word and the corresponding phone sequence was complete, we built two phone models using Classification and Regression Trees (CART).", "labels": [], "entities": []}, {"text": "For the first model, we used data from the CMU pronunciation dictionary where each English word had been aligned to a sequence of US English phones (EW-EP mapping).", "labels": [], "entities": [{"text": "CMU pronunciation dictionary", "start_pos": 43, "end_pos": 71, "type": "DATASET", "confidence": 0.8924769560496012}]}, {"text": "Algorithm for Epsilon Scattering : /*Initialize prob(G, P ) the probability of G matching P */ 1.", "labels": [], "entities": [{"text": "Epsilon Scattering", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.668922483921051}]}, {"text": "for each word i in training set count with string alignment all possible G/P association for all possible epsilon positions in the phonetic transcription /* EM loop */ 2.", "labels": [], "entities": []}, {"text": "for each word i in training set alignment path = argmax compute prob new (G, P ) on alignment path 3.", "labels": [], "entities": [{"text": "argmax", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9602479338645935}]}, {"text": "if(prob = prob new ) go to 2 The second model was the EW-TP mapping.", "labels": [], "entities": [{"text": "EW-TP mapping", "start_pos": 54, "end_pos": 67, "type": "DATASET", "confidence": 0.864057719707489}]}, {"text": "Once both the models had been built, they were used to predict the mapped phone sequences for each English word in the test data.", "labels": [], "entities": []}, {"text": "For the purposes of testing, we performed the prediction on both held out test data as well as on test data from a different domain.", "labels": [], "entities": []}, {"text": "The held out test data was prepared by removing every ninth word from the lexicon.", "labels": [], "entities": []}, {"text": "As we knew the correct phone sequence for each word in the test data, aground truth against which to compute the accuracy of prediction was available.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9991312623023987}]}, {"text": "We measured the accuracy of the prediction both at the letter level and at the word level.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.999627947807312}]}, {"text": "At the letter level, the accuracy was computed by counting the number of times the predicted letter to phone mapping matched with the ground truth.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9996402263641357}]}, {"text": "For computing the accuracy at the word level, we counted the number of times the predicted phone sequence of each word in the test data matched with the actual phone sequence for that word (derived from the ground truth).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9993791580200195}]}, {"text": "We also varied the size of the training data and then computed the prediction accuracy for each model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9400314092636108}]}, {"text": "We did so in order to study the effect of training data size on the prediction accuracy.", "labels": [], "entities": [{"text": "prediction", "start_pos": 68, "end_pos": 78, "type": "TASK", "confidence": 0.9499717950820923}, {"text": "accuracy", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9515026211738586}]}, {"text": "show the accuracy of the models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9995900988578796}]}, {"text": "An examination of the results in the two tables shows that incrementally increasing the size of the training data results in an increase of the prediction accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 155, "end_pos": 163, "type": "METRIC", "confidence": 0.9316785335540771}]}, {"text": "The native speakers of Indian languages prefer to speak what is written.", "labels": [], "entities": []}, {"text": "As a result there are fewer variations in word-phone mapping as compared to US English.", "labels": [], "entities": [{"text": "word-phone mapping", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.7459938824176788}]}, {"text": "This is reflected in our results, which show that the word level prediction accuracy is higher for EW-TP mapping as compared to EW-EP mapping.", "labels": [], "entities": [{"text": "word level prediction", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.5457151631514231}, {"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9406670331954956}, {"text": "EW-TP mapping", "start_pos": 99, "end_pos": 112, "type": "TASK", "confidence": 0.6210849285125732}]}, {"text": "To conduct perceptual evaluations of the wordphone mapping rules built from data in 3.2, we incorporated these rules in our Telugu TTS system.", "labels": [], "entities": [{"text": "wordphone mapping", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.7109047770500183}, {"text": "Telugu TTS system", "start_pos": 124, "end_pos": 141, "type": "DATASET", "confidence": 0.8439468940099081}]}, {"text": "This system is henceforth refered to as TA.", "labels": [], "entities": []}, {"text": "A set of 25 bilingual sentences were synthesized by the Telugu TTS, and ten native speakers of Telugu performed perceptual evaluations on the synthesized utterances.", "labels": [], "entities": [{"text": "Telugu TTS", "start_pos": 56, "end_pos": 66, "type": "DATASET", "confidence": 0.8867685794830322}]}, {"text": "As a baseline, we also synthesized the same 25 sentences by incorporating manually written word-phone mapping for the English words, instead of using the automatically generated word-phone mapping rules.", "labels": [], "entities": []}, {"text": "We refer to this system as TM.", "labels": [], "entities": []}, {"text": "The perceptual evaluations were setup both as MOS (mean opinion score) evaluations and as ABX evaluations.", "labels": [], "entities": [{"text": "MOS (mean opinion score", "start_pos": 46, "end_pos": 69, "type": "METRIC", "confidence": 0.8238091588020324}, {"text": "ABX", "start_pos": 90, "end_pos": 93, "type": "METRIC", "confidence": 0.8156158924102783}]}, {"text": "In the MOS evaluations, the listeners were asked to rate the synthesized utterances from all systems on a scale of 1 to 5 (1 being worst and 5 best), and the average scores for each system was calculated.", "labels": [], "entities": [{"text": "MOS", "start_pos": 7, "end_pos": 10, "type": "TASK", "confidence": 0.8063907623291016}]}, {"text": "This average is the MOS score for that system.", "labels": [], "entities": [{"text": "MOS score", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9770374298095703}]}, {"text": "Ina typical ABX evaluation, the listeners are presented with the the same set of utterances synthesized using two systems A and B, and are asked to mark their preference for either A or B.", "labels": [], "entities": []}, {"text": "The listeners also have an option of marking no preference.", "labels": [], "entities": []}, {"text": "In this case, the listeners were asked to mark their preference between TA and TM.", "labels": [], "entities": [{"text": "TA", "start_pos": 72, "end_pos": 74, "type": "METRIC", "confidence": 0.8842408061027527}]}, {"text": "The results of the perceptual evaluations are shown in.", "labels": [], "entities": []}, {"text": "An examination of the results shows that perceptually there is no significant preference for the manual system over the automated system.", "labels": [], "entities": []}, {"text": "The MOS scores also show that there is not much significant difference between the ratings of the manual and the automated system.", "labels": [], "entities": [{"text": "MOS", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9032425880432129}]}], "tableCaptions": [{"text": " Table 3: Accuracy of prediction for English word  -English phone mapping", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9962478280067444}, {"text": "English word  -English phone mapping", "start_pos": 37, "end_pos": 73, "type": "TASK", "confidence": 0.6324852406978607}]}, {"text": " Table 4: Accuracy of prediction for English word- Telugu phone mapping", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9967008233070374}, {"text": "English word- Telugu phone mapping", "start_pos": 37, "end_pos": 71, "type": "TASK", "confidence": 0.6299655139446259}]}, {"text": " Table 5: Perceptual results comparing systems  T M and T A", "labels": [], "entities": []}]}