{"title": [{"text": "Graph-based Semi-Supervised Model for Joint Chinese Word Segmentation and Part-of-Speech Tagging", "labels": [], "entities": [{"text": "Joint Chinese Word Segmentation", "start_pos": 38, "end_pos": 69, "type": "TASK", "confidence": 0.5040847882628441}, {"text": "Part-of-Speech Tagging", "start_pos": 74, "end_pos": 96, "type": "TASK", "confidence": 0.7072649300098419}]}], "abstractContent": [{"text": "This paper introduces a graph-based semi-supervised joint model of Chinese word segmentation and part-of-speech tagging.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 67, "end_pos": 92, "type": "TASK", "confidence": 0.6097373565038046}, {"text": "part-of-speech tagging", "start_pos": 97, "end_pos": 119, "type": "TASK", "confidence": 0.7153443694114685}]}, {"text": "The proposed approach is based on a graph-based label propagation technique.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.7241368740797043}]}, {"text": "One constructs a nearest-neighbor similarity graph overall trigrams of labeled and unlabeled data for propagating syntactic information, i.e., label distributions.", "labels": [], "entities": []}, {"text": "The derived label distributions are regarded as virtual evidences to regular-ize the learning of linear conditional random fields (CRFs) on unlabeled data.", "labels": [], "entities": []}, {"text": "An inductive character-based joint model is obtained eventually.", "labels": [], "entities": []}, {"text": "Empirical results on Chinese tree bank (CTB-7) and Microsoft Research corpora (MSR) reveal that the proposed model can yield better results than the supervised baselines and other competitive semi-supervised CRFs in this task.", "labels": [], "entities": [{"text": "Chinese tree bank (CTB-7)", "start_pos": 21, "end_pos": 46, "type": "DATASET", "confidence": 0.923868199189504}, {"text": "Microsoft Research corpora (MSR)", "start_pos": 51, "end_pos": 83, "type": "DATASET", "confidence": 0.8141132394472758}]}], "introductionContent": [{"text": "Word segmentation and part-of-speech (POS) tagging are two critical and necessary initial procedures with respect to the majority of high-level Chinese language processing tasks such as syntax parsing, information extraction and machine translation.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6914688944816589}, {"text": "part-of-speech (POS) tagging", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.6523742556571961}, {"text": "syntax parsing", "start_pos": 186, "end_pos": 200, "type": "TASK", "confidence": 0.7044119238853455}, {"text": "information extraction", "start_pos": 202, "end_pos": 224, "type": "TASK", "confidence": 0.8531187474727631}, {"text": "machine translation", "start_pos": 229, "end_pos": 248, "type": "TASK", "confidence": 0.7948113679885864}]}, {"text": "The traditional way of segmentation and tagging is performed in a pipeline approach, first segmenting a sentence into words, and then assigning each word a POS tag.", "labels": [], "entities": [{"text": "segmentation and tagging", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.7177073458830515}]}, {"text": "The pipeline approach is very simple to implement, but frequently causes error propagation, given that wrong segmentations in the earlier stage harm the subsequent POS tagging ().", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 164, "end_pos": 175, "type": "TASK", "confidence": 0.6487944573163986}]}, {"text": "The joint approaches of word segmentation and POS tagging (joint S&T) are proposed to resolve these two tasks simultaneously.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.7600050866603851}, {"text": "POS tagging", "start_pos": 46, "end_pos": 57, "type": "TASK", "confidence": 0.7972319722175598}]}, {"text": "They effectively alleviate the error propagation, because segmentation and tagging have strong interaction, given that most segmentation ambiguities cannot be resolved without considering the surrounding grammatical constructions encoded in a POS sequence).", "labels": [], "entities": [{"text": "error propagation", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.6970739960670471}]}, {"text": "In the past years, several proposed supervised joint models () achieved reasonably accurate results, but the outstanding problem among these models is that they rely heavily on a large amount of labeled data, i.e., segmented texts with POS tags.", "labels": [], "entities": []}, {"text": "However, the production of such labeled data is extremely timeconsuming and expensive ().", "labels": [], "entities": []}, {"text": "Therefore, semi-supervised joint S&T appears to be a natural solution for easily incorporating accessible unlabeled data to improve the joint S&T model.", "labels": [], "entities": []}, {"text": "This study focuses on using a graph-based label propagation method to build a semi-supervised joint S&T model.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.742111086845398}]}, {"text": "Graph-based label propagation methods have recently shown they can outperform the state-of-the-art in several natural language processing (NLP) tasks, e.g., POS tagging (, knowledge acquisition, shallow semantic parsing for unknown predicate ().", "labels": [], "entities": [{"text": "label propagation", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.7466680109500885}, {"text": "POS tagging", "start_pos": 157, "end_pos": 168, "type": "TASK", "confidence": 0.891795426607132}, {"text": "knowledge acquisition", "start_pos": 172, "end_pos": 193, "type": "TASK", "confidence": 0.7695657312870026}, {"text": "shallow semantic parsing for unknown predicate", "start_pos": 195, "end_pos": 241, "type": "TASK", "confidence": 0.7618285765250524}]}, {"text": "As far as we know, however, these methods have not yet been applied to resolve the problem of joint Chinese word segmentation (CWS) and POS tagging.", "labels": [], "entities": [{"text": "joint Chinese word segmentation (CWS)", "start_pos": 94, "end_pos": 131, "type": "TASK", "confidence": 0.7154233923980168}, {"text": "POS tagging", "start_pos": 136, "end_pos": 147, "type": "TASK", "confidence": 0.7515941858291626}]}, {"text": "Motivated by the works in (), for structured problems, graph-based label propagation can be employed to infer valuable syntactic information (ngram-level label distributions) from labeled data to unlabeled data.", "labels": [], "entities": [{"text": "graph-based label propagation", "start_pos": 55, "end_pos": 84, "type": "TASK", "confidence": 0.7254665295282999}]}, {"text": "This study extends this intuition to construct a similarity graph for propagating trigram-level label distributions.", "labels": [], "entities": []}, {"text": "The derived label distributions are regarded as prior knowledge to regularize the learning of a sequential model, conditional random fields (CRFs) in this case, on both labeled and unlabeled data to achieve the semisupervised learning.", "labels": [], "entities": []}, {"text": "The approach performs the incorporation of the derived labeled distributions by manipulating a \"virtual evidence\" function as described in.", "labels": [], "entities": []}, {"text": "Experiments on the data from the Chinese tree bank (CTB-7) and show that the proposed model results in significant improvement over other comparative candidates in terms of F-score and out-of-vocabulary (OOV) recall.", "labels": [], "entities": [{"text": "Chinese tree bank (CTB-7)", "start_pos": 33, "end_pos": 58, "type": "DATASET", "confidence": 0.9453752736250559}, {"text": "F-score", "start_pos": 173, "end_pos": 180, "type": "METRIC", "confidence": 0.9954602122306824}, {"text": "recall", "start_pos": 209, "end_pos": 215, "type": "METRIC", "confidence": 0.9186587929725647}]}, {"text": "This paper is structured as follows: Section 2 points out the main differences with the related work of this study.", "labels": [], "entities": []}, {"text": "Section 3 reviews the background, including supervised character-based joint S&T model based on CRFs and graph-based label propagation.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 117, "end_pos": 134, "type": "TASK", "confidence": 0.7025899440050125}]}, {"text": "Section 4 presents the details of the proposed approach.", "labels": [], "entities": []}, {"text": "Section 5 reports the experiment results.", "labels": [], "entities": []}, {"text": "The conclusion is drawn in Section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 3: Training, development and testing data.", "labels": [], "entities": []}, {"text": " Table 4: The performance of segmentation and  POS tagging on testing data.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 29, "end_pos": 41, "type": "TASK", "confidence": 0.969929039478302}, {"text": "POS tagging", "start_pos": 47, "end_pos": 58, "type": "TASK", "confidence": 0.7727745175361633}]}, {"text": " Table 5: The statistics of segmentation error for  named entities (NE) and Chinese numbers (CN)  in test data. #baErr and #gbErr denote the count  of segmentations by Baseline II and our model;  ErrDec% denotes the error reduction.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 28, "end_pos": 40, "type": "TASK", "confidence": 0.9679465293884277}, {"text": "ErrDec", "start_pos": 196, "end_pos": 202, "type": "METRIC", "confidence": 0.9652449488639832}]}, {"text": " Table 6: The statistics of POS tagging error pat- terns in test data. #baErr denote the count of tag- ging error by Baseline II, while \u2193 and \u2191 denotes  the number of error reduced or increased by our  model.", "labels": [], "entities": [{"text": "POS tagging error", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.7382774750391642}]}]}