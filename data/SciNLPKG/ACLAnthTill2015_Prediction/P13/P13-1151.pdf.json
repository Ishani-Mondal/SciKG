{"title": [{"text": "Improving Text Simplification Language Modeling Using Unsimplified Text Data", "labels": [], "entities": [{"text": "Improving Text Simplification Language Modeling", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.9263903498649597}]}], "abstractContent": [{"text": "In this paper we examine language mod-eling for text simplification.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.7795432209968567}]}, {"text": "Unlike some text-to-text translation tasks, text simplification is a monolingual translation task allowing for text in both the input and output domain to be used for training the language model.", "labels": [], "entities": [{"text": "text-to-text translation", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.7756779789924622}, {"text": "text simplification", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7239392995834351}]}, {"text": "We explore the relationship between normal English and simplified English and compare language models trained on varying amounts of text from each.", "labels": [], "entities": []}, {"text": "We evaluate the models intrin-sically with perplexity and extrinsically on the lexical simplification task from Se-mEval 2012.", "labels": [], "entities": []}, {"text": "We find that a combined model using both simplified and normal English data achieves a 23% improvement in perplexity and a 24% improvement on the lexical simplification task over a model trained only on simple data.", "labels": [], "entities": []}, {"text": "Post-hoc analysis shows that the additional unsimplified data provides better coverage for unseen and rare n-grams.", "labels": [], "entities": [{"text": "coverage", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9559659361839294}]}], "introductionContent": [{"text": "An important component of many text-to-text translation systems is the language model which predicts the likelihood of a text sequence being produced in the output language.", "labels": [], "entities": [{"text": "text-to-text translation", "start_pos": 31, "end_pos": 55, "type": "TASK", "confidence": 0.7391155660152435}]}, {"text": "In some problem domains, such as machine translation, the translation is between two distinct languages and the language model can only be trained on data in the output language.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.8126770853996277}]}, {"text": "However, some problem domains (e.g. text compression, text simplification and summarization) can be viewed as monolingual translation tasks, translating between text variations within a single language.", "labels": [], "entities": [{"text": "text compression", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.7659458518028259}, {"text": "text simplification", "start_pos": 54, "end_pos": 73, "type": "TASK", "confidence": 0.7434226870536804}, {"text": "summarization", "start_pos": 78, "end_pos": 91, "type": "TASK", "confidence": 0.9623275399208069}]}, {"text": "In these monolingual problems, text could be used from both the input and output domain to train a language model.", "labels": [], "entities": []}, {"text": "In this paper, we investigate this possibility for text simplification where both simplified English text and normal English text are available for training a simple English language model.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.7794514894485474}]}, {"text": "shows the n-gram overlap proportions in a sentence aligned data set of 137K sentence pairs from aligning Simple English Wikipedia and English Wikipedia articles.", "labels": [], "entities": []}, {"text": "The data highlights two conflicting views: does the benefit of additional data outweigh the problem of the source of the data?", "labels": [], "entities": []}, {"text": "Throughout the rest of this paper we refer to sentences/articles/text from English Wikipedia as normal and sentences/articles/text from Simple English Wikipedia as simple.", "labels": [], "entities": [{"text": "Simple English Wikipedia", "start_pos": 136, "end_pos": 160, "type": "DATASET", "confidence": 0.7921825051307678}]}, {"text": "On the one hand, there is a strong correspondence between the simple and normal data.", "labels": [], "entities": []}, {"text": "At the word level 96% of the simple words are found in the normal corpus and even for n-grams as large as 5, more than half of the n-grams can be found in the normal text.", "labels": [], "entities": []}, {"text": "In addition, the normal text does represent English text and contains many n-grams not seen in the simple corpus.", "labels": [], "entities": []}, {"text": "This extra information may help with data sparsity, providing better estimates for rare and unseen n-grams.", "labels": [], "entities": []}, {"text": "On the other hand, there is still only modest overlap between the sentences for longer n-grams, particularly given that the corpus is sentencealigned and that 27% of the sentence pairs in this aligned data set are identical.", "labels": [], "entities": []}, {"text": "If the word distributions were very similar between simple and normal text, then the overlap proportions between the two languages would be similar regardless of which direction the comparison is made.", "labels": [], "entities": []}, {"text": "Instead, we see that the normal text has more varied language and contains more n-grams.", "labels": [], "entities": []}, {"text": "Previous research has also shown other differences between simple and normal data sources that could impact language model performance including average number of syllables, reading n-gram size:: The proportion of n-grams that overlap in a corpus of 137K sentence-aligned pairs from Simple English Wikipedia and English Wikipedia.", "labels": [], "entities": [{"text": "Simple English Wikipedia", "start_pos": 283, "end_pos": 307, "type": "DATASET", "confidence": 0.8193357388178507}, {"text": "English Wikipedia", "start_pos": 312, "end_pos": 329, "type": "DATASET", "confidence": 0.8811003565788269}]}, {"text": "complexity, and grammatical complexity).", "labels": [], "entities": []}, {"text": "In addition, for some monolingual translation domains, it has been argued that it is not appropriate to train a language model using data from the input domain.", "labels": [], "entities": []}, {"text": "Although this question arises in other monolingual translation domains, text simplification represents an ideal problem area for analysis.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.7428900003433228}]}, {"text": "First, simplified text data is available in reasonable quantities.", "labels": [], "entities": []}, {"text": "Simple English Wikipedia contains more than 60K articles written in simplified English.", "labels": [], "entities": [{"text": "Simple English Wikipedia", "start_pos": 0, "end_pos": 24, "type": "DATASET", "confidence": 0.8976966341336569}]}, {"text": "This is not the case for all monolingual translation tasks (.", "labels": [], "entities": [{"text": "monolingual translation tasks", "start_pos": 29, "end_pos": 58, "type": "TASK", "confidence": 0.6928408940633138}]}, {"text": "Second, the quantity of simple text data available is still limited.", "labels": [], "entities": []}, {"text": "After preprocessing, the 60K articles represents less than half a million sentences which is orders of magnitude smaller than the amount of normal English data available (for example the English Gigaword corpus).", "labels": [], "entities": [{"text": "English Gigaword corpus", "start_pos": 187, "end_pos": 210, "type": "DATASET", "confidence": 0.7588287591934204}]}, {"text": "Finally, many recent text simplification systems have utilized language models trained only on simplified data (; improvements in simple language modeling could translate into improvements for these systems.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.7677924931049347}]}], "datasetContent": [{"text": "To analyze the impact of data source on simple English language modeling, we trained language models on varying amounts of simple data, normal data, and a combination of the two.", "labels": [], "entities": []}, {"text": "For our first task, we evaluated these language models using perplexity based on how well they modeled the simple side of the held-out data.", "labels": [], "entities": []}, {"text": "Examples from the lexical simplification data set from SemEval 2012 consist of three parts: w, the word to be simplified; s 1 , ..., s i\u22121 , w, s i+1 , ..., s n , a sentence containing the word; and, r 1 , r 2 , ..., rm , a list of candidate simplifications for w.", "labels": [], "entities": [{"text": "lexical simplification data set from SemEval 2012", "start_pos": 18, "end_pos": 67, "type": "DATASET", "confidence": 0.7769872844219208}]}, {"text": "The goal of the task is to rank the candidate simplifications according to their simplicity in the context of the sentence.", "labels": [], "entities": [{"text": "simplicity", "start_pos": 81, "end_pos": 91, "type": "METRIC", "confidence": 0.9861792325973511}]}, {"text": "shows an example from the data set.", "labels": [], "entities": []}, {"text": "The data set contains a development set of 300 examples and a test set of 1710 examples.", "labels": [], "entities": []}, {"text": "For our experiments, we evaluated the models on the test set.", "labels": [], "entities": []}, {"text": "Given a language model p(\u00b7) and a lexical simplification example, we ranked the list of candidates based on the probability the language model assigns to the sentence with the candidate simplification inserted in context.", "labels": [], "entities": []}, {"text": "Specifically, we scored each candidate simplification r j by p(s 1 ...", "labels": [], "entities": []}, {"text": "s i\u22121 r j s i+1 ...", "labels": [], "entities": []}, {"text": "s n ) and then ranked them based on this score.", "labels": [], "entities": []}, {"text": "For example, to calculate the ranking for the example in we calculate the probability of each of: With the physical market as constricted as it has been ...", "labels": [], "entities": []}, {"text": "With the physical market as pressurised as it has been ...", "labels": [], "entities": []}, {"text": "With the physical market as low as it has been ...", "labels": [], "entities": []}, {"text": "With the physical market as high-strung as it has been ...", "labels": [], "entities": []}, {"text": "With the physical market as tight as it has been ... with the language model and then rank them by their probability.", "labels": [], "entities": []}, {"text": "We do not suggest this as a com-  plete lexical substitution system, but it was a common feature for many of the submitted systems, it performs well relative to the other systems, and it allows fora concrete comparison between the language models on a simplification task.", "labels": [], "entities": []}, {"text": "To evaluate the rankings, we use the metric from the SemEval 2012 task, the Cohen's kappa coefficient ( between the system ranking and the human ranking, which we denote the \"kappa rank score\".", "labels": [], "entities": [{"text": "SemEval 2012 task", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.6438141862551371}]}, {"text": "See for the full details of how the evaluation metric is calculated.", "labels": [], "entities": []}, {"text": "We use the same setup for training the language models as in the perplexity experiments except the models are open vocabulary instead of closed.", "labels": [], "entities": []}, {"text": "Open vocabulary models allow for the language models to better utilize the varying amounts of data and since the lexical simplification problem only requires a comparison of probabilities within a given model to produce the final ranking, we do not need the closed vocabulary requirement.", "labels": [], "entities": []}, {"text": "shows the kappa rank scores for the simple-only, normal-only and combined models.", "labels": [], "entities": []}, {"text": "As with the perplexity results, for similar amounts of data the simple-only model performs better than the normal-only model.", "labels": [], "entities": []}, {"text": "We also again see that the performance difference between the two models grows as the amount of data increases.", "labels": [], "entities": []}, {"text": "However, unlike the perplexity results, simply appending additional normal data to the entire simple data set does not improve the performance of the lexical simplifier.", "labels": [], "entities": []}, {"text": "Currently, no automated methods exist for evaluating sentence-level or document-level text simplification systems and manual evaluation is timeconsuming, expensive and has not been validated.", "labels": [], "entities": [{"text": "sentence-level or document-level text simplification", "start_pos": 53, "end_pos": 105, "type": "TASK", "confidence": 0.5874045729637146}]}, {"text": "Because of these evaluation challenges, we chose to evaluate the language models extrinsi-Word: With the physical market as tight as it has been in memory, silver could fly at anytime.", "labels": [], "entities": []}, {"text": "Candidates: constricted, pressurised, low, high-strung, tight Human ranking: tight, low, constricted, pressurised, high-strung cally based on the lexical simplification task from SemEval 2012 (.", "labels": [], "entities": [{"text": "SemEval 2012", "start_pos": 179, "end_pos": 191, "type": "DATASET", "confidence": 0.7115634083747864}]}, {"text": "Lexical simplification is a sub-problem of the general text simplification problem); a sentence is simplified by substituting words or phrases in the sentence with \"simpler\" variations.", "labels": [], "entities": [{"text": "Lexical simplification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8679072260856628}, {"text": "text simplification", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.7305271923542023}]}, {"text": "Lexical simplification approaches have been shown to improve the readability of texts), are useful in domains such as medical texts where major content changes are restricted, and they maybe useful as a pre-or post-processing step for general simplification systems.", "labels": [], "entities": [{"text": "Lexical simplification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8439570367336273}]}], "tableCaptions": [{"text": " Table 1: The proportion of n-grams that overlap  in a corpus of 137K sentence-aligned pairs from  Simple English Wikipedia and English Wikipedia.", "labels": [], "entities": [{"text": "Simple English Wikipedia", "start_pos": 99, "end_pos": 123, "type": "DATASET", "confidence": 0.8327662150065104}, {"text": "English Wikipedia", "start_pos": 128, "end_pos": 145, "type": "DATASET", "confidence": 0.8900094628334045}]}, {"text": " Table 3: Proportion of n-grams in the test sets that  occur in the simple and normal training data sets.", "labels": [], "entities": []}, {"text": " Table 4: Proportion of n-grams in the test sets that  occur in the combination of both the simple and  normal data.", "labels": [], "entities": []}]}