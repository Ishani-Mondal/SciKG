{"title": [{"text": "Semantic Frames to Predict Stock Price Movement", "labels": [], "entities": [{"text": "Predict Stock Price", "start_pos": 19, "end_pos": 38, "type": "TASK", "confidence": 0.7764484087626139}]}], "abstractContent": [{"text": "Semantic frames area rich linguistic resource.", "labels": [], "entities": []}, {"text": "There has been much work on semantic frame parsers, but less that applies them to general NLP problems.", "labels": [], "entities": [{"text": "semantic frame parsers", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.6418548822402954}]}, {"text": "We address a task to predict change in stock price from financial news.", "labels": [], "entities": []}, {"text": "Semantic frames help to generalize from specific sentences to scenarios, and to detect the (positive or negative) roles of specific companies.", "labels": [], "entities": []}, {"text": "We introduce a novel tree representation, and use it to train predic-tive models with tree kernels using support vector machines.", "labels": [], "entities": []}, {"text": "Our experiments test multiple text representations on two binary classification tasks, change of price and polarity.", "labels": [], "entities": []}, {"text": "Experiments show that features derived from semantic frame parsing have significantly better performance across years on the polarity task.", "labels": [], "entities": [{"text": "semantic frame parsing", "start_pos": 44, "end_pos": 66, "type": "TASK", "confidence": 0.6463010609149933}]}], "introductionContent": [{"text": "A growing literature evaluates the financial effects of media on the market.", "labels": [], "entities": []}, {"text": "Recent work has applied NLP techniques to various financial media (conventional news, tweets) to detect sentiment in conventional news) or message boards (, or discriminate expert from nonexpert investors in financial tweets ().", "labels": [], "entities": []}, {"text": "With the exception of, these NLP studies have relied on small corpora of hand-labeled data for training or evaluation, and the connection to market events is done indirectly through sentiment detection.", "labels": [], "entities": [{"text": "sentiment detection", "start_pos": 182, "end_pos": 201, "type": "TASK", "confidence": 0.9374992549419403}]}, {"text": "We hypothesize that conventional news can be used to predict changes in the stock price of specific companies, and that the semantic features that best represent relevant aspects of the news vary across  market sectors.", "labels": [], "entities": []}, {"text": "To test this hypothesis, we use price information to label data from six years of financial news.", "labels": [], "entities": []}, {"text": "Our experiments test several document representations for two binary classification tasks, change of price and polarity.", "labels": [], "entities": []}, {"text": "Our main contribution is a novel tree representation based on semantic frame parses that performs significantly better than enriched bag-of-words vectors.", "labels": [], "entities": [{"text": "semantic frame parses", "start_pos": 62, "end_pos": 83, "type": "TASK", "confidence": 0.6704931855201721}]}, {"text": "shows a constructed example based on extracts from financial news about Google in April, 2012.", "labels": [], "entities": []}, {"text": "It illustrates how a series of events reported in the news precedes and potentially predicts a large change in Google's stock price.", "labels": [], "entities": []}, {"text": "Google's early announcement of quarterly earnings possibly presages trouble, and its stock price falls soon after reports of a legal action against Google by Oracle.", "labels": [], "entities": []}, {"text": "To produce a coherent story, the original sentences were edited for, but they are in the style of actual sentences from our dataset.", "labels": [], "entities": []}, {"text": "Accurate detection of events and relations that might have an impact on stock price should benefit from document representation that captures sentiment in lexical items (e.g., aggressive) combined with the conceptual relations captured by.", "labels": [], "entities": []}, {"text": "A frame is a lexical semantic representa-tion of the conceptual roles played by parts of a clause, and relates different lexical items (e.g., report, announce) to the same situation type.", "labels": [], "entities": []}, {"text": "In the figure, some of the words that evoke frames have been underlined, and role fillers are outlined by boxes or ovals.", "labels": [], "entities": [{"text": "role fillers", "start_pos": 77, "end_pos": 89, "type": "TASK", "confidence": 0.8081363439559937}]}, {"text": "Sentiment words are in italics.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this paper is the first to apply semantic frames in this domain.", "labels": [], "entities": []}, {"text": "On the polarity task, the semantic frame features encoded as trees perform significantly better across years and sectors than bag-of-words vectors (BOW), and outperform BOW vectors enhanced with semantic frame features, and a supervised topic modeling approach.", "labels": [], "entities": []}, {"text": "The results on the price change task show the same trend, but are not statistically significant, possibly due to the volatility of the market in 2007 and the following several years.", "labels": [], "entities": []}, {"text": "Yet even modest predictive performance on both tasks could have an impact, as discussed below, if incorporated into financial models such as.", "labels": [], "entities": []}, {"text": "We first discuss the motivation and related work.", "labels": [], "entities": []}, {"text": "Section 4 presents vector-based and tree-based features from semantic frame parses, and section 5 describes our dataset.", "labels": [], "entities": []}, {"text": "The experimental design and results appear in the following section, followed by discussion and conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use publicly available financial news from Reuters from January 2007 through August 2012.", "labels": [], "entities": [{"text": "publicly available financial news from Reuters from January 2007", "start_pos": 7, "end_pos": 71, "type": "DATASET", "confidence": 0.8236365715662638}]}, {"text": "This time frame includes a severe economic downturn in 2007-2010 followed by a modest recovery in 2011-2012.", "labels": [], "entities": []}, {"text": "An information extraction pipeline is used to pre-process the data.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 3, "end_pos": 25, "type": "TASK", "confidence": 0.7674686908721924}]}, {"text": "News full text is extracted from HTML.", "labels": [], "entities": []}, {"text": "The timestamp of the news is extracted fora later alignment with stock price information, which will be discussed in section 6.", "labels": [], "entities": []}, {"text": "The company mentioned is identified by a rule-based matching of a finite list of companies.", "labels": [], "entities": []}, {"text": "There area total of 10 sectors in the Global Industry Classification Standard (GICS), an industry taxonomy used by the S&P 500.", "labels": [], "entities": [{"text": "Global Industry Classification Standard (GICS)", "start_pos": 38, "end_pos": 84, "type": "DATASET", "confidence": 0.699511855840683}, {"text": "S&P 500", "start_pos": 119, "end_pos": 126, "type": "DATASET", "confidence": 0.617266334593296}]}, {"text": "To explore our approach for this domain, we select three sectors for our experiment: Telecommunication Services (TS, the sector with the smallest number of companies), Information Technology (IT), and Consumer Staples (CS), due to our familiarity with the companies in these sectors and an expectation of different characteristics they may exhibit.", "labels": [], "entities": []}, {"text": "In the expectation there would be semantic differences associated with these sectors, experiments are performed independently for each sector.", "labels": [], "entities": []}, {"text": "There are also differences in the number of companies in the sector, and the amount of news.", "labels": [], "entities": []}, {"text": "We bin news articles by sector.", "labels": [], "entities": []}, {"text": "We remove articles that only list stock prices or only show tables of accounting reports.", "labels": [], "entities": []}, {"text": "The first preprocessing step is to extract sentences that mention the  Our current experiments are carried out for each year, training on one year and testing on the next.", "labels": [], "entities": []}, {"text": "The choice to use a coarse time interval with no overlap was an expedience to permit more numerous exploratory experiments, given the computational resources these experiments require.", "labels": [], "entities": []}, {"text": "We test the influence of news to predict (1) a change in stock price (change task), and (2) the polarity of change (increase vs. decrease; polarity task).", "labels": [], "entities": []}, {"text": "Experiments evaluate the FWD and SemTree feature spaces compared to two baselines: bag-of-words (BOW) and supervised latent Dirichlet allocation (sLDA).", "labels": [], "entities": [{"text": "FWD", "start_pos": 25, "end_pos": 28, "type": "DATASET", "confidence": 0.9136458039283752}, {"text": "bag-of-words (BOW)", "start_pos": 83, "end_pos": 101, "type": "METRIC", "confidence": 0.6589069217443466}]}, {"text": "BOW includes features of unigram, bigram and trigram.", "labels": [], "entities": [{"text": "BOW", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8128016591072083}]}, {"text": "sLDA is a statistical model to classify documents based on LDA topic models, using labeled data.", "labels": [], "entities": []}, {"text": "It has been applied to and shown good performance in topical text classification, collaborative filtering, and web page popularity prediction problems.", "labels": [], "entities": [{"text": "topical text classification", "start_pos": 53, "end_pos": 80, "type": "TASK", "confidence": 0.7578654289245605}, {"text": "web page popularity prediction", "start_pos": 111, "end_pos": 141, "type": "TASK", "confidence": 0.6416840329766273}]}, {"text": "We align publicly available daily stock price data from Yahoo Finance with the Reuters news using a method to avoid back-casting.", "labels": [], "entities": [{"text": "Reuters news", "start_pos": 79, "end_pos": 91, "type": "DATASET", "confidence": 0.8931466937065125}]}, {"text": "In particular, we use the daily adjusted closing price -the price quoted at the end of a trading day (4PM US Eastern Time), then adjusted by dividends, stock split, and other corporate actions.", "labels": [], "entities": [{"text": "US Eastern Time)", "start_pos": 106, "end_pos": 122, "type": "DATASET", "confidence": 0.750304214656353}]}, {"text": "We create two types of labels for news documents using the price data, to label the existence of a change and the direction of change.", "labels": [], "entities": []}, {"text": "Both tasks are treated as binary classification problems.", "labels": [], "entities": []}, {"text": "Based on the finding of a one-day delay of the price response to the information embedded in the news by, we use \u2206t = 1 in our experiment.", "labels": [], "entities": []}, {"text": "To constrain the number of parameters, we also use a threshold value (r) of a 2% change, based on the distribution of price changes across our data.", "labels": [], "entities": [{"text": "threshold value (r)", "start_pos": 53, "end_pos": 72, "type": "METRIC", "confidence": 0.7003497004508972}]}, {"text": "In future work, this could be tuned to sector or time.", "labels": [], "entities": []}, {"text": "+1 if p t(0)+\u2206t > p t(\u22121) and change = +1 \u22121 if p t(0)+\u2206t < p t(\u22121) and change = +1 p t(\u22121) is the adjusted closing price at the end of the last trading day, and p t(0)+\u2206t is the price of the end of the trading day after the \u2206t day delay.", "labels": [], "entities": [{"text": "change", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.992879331111908}, {"text": "change", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9810966849327087}]}, {"text": "Only the instances with changes are included in the polarity task.", "labels": [], "entities": []}, {"text": "There is high variance across years in the proportion of positive labels, and often highly skewed classes in one direction or the other.", "labels": [], "entities": []}, {"text": "The average ratios of +/-classes for change and polarity over the six years' data are 0.73 (std=0.35) and 1.12 (std=0.25), respectively.", "labels": [], "entities": []}, {"text": "Because the time frame for our experiments includes an economic crisis followed by a recovery period, we note that the ratio between increase and decrease of price flips between 2007, where it is, where it is 0.71.", "labels": [], "entities": []}, {"text": "Accuracy is very sensitive to skew: when a class has low frequency, accuracy can be high using a baseline that makes prediction on the majority class.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9880490899085999}, {"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9990353584289551}]}, {"text": "Given the high data skew, and the large changes from year to year in positive versus negative skew, we use a more robust evaluation metric.", "labels": [], "entities": []}, {"text": "Our evaluation relies on the Matthews correlation coefficient (MCC, also known as the \u03c6-coefficient) to avoid the bias of accuracy due to data skew, and to produce a robust summary score independent of whether the positive class is skewed to the majority or minority.", "labels": [], "entities": [{"text": "Matthews correlation coefficient (MCC", "start_pos": 29, "end_pos": 66, "type": "METRIC", "confidence": 0.9456148147583008}, {"text": "\u03c6-coefficient)", "start_pos": 86, "end_pos": 100, "type": "METRIC", "confidence": 0.971458226442337}, {"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9987131357192993}]}, {"text": "In contrast to f-measure, which is a classspecific weighted average of precision and recall, and whose weighted version depends on a choice of whether the class-specific weights should come from the training or testing data, MCC is a single summary value that incorporates all 4 cells of a 2 \u00d7 2 confusion matrix (TP, FP, TN and FN for True or False Positive or Negative).", "labels": [], "entities": [{"text": "precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9982101917266846}, {"text": "recall", "start_pos": 85, "end_pos": 91, "type": "METRIC", "confidence": 0.9969378709793091}, {"text": "FP", "start_pos": 318, "end_pos": 320, "type": "METRIC", "confidence": 0.952347457408905}, {"text": "FN", "start_pos": 329, "end_pos": 331, "type": "METRIC", "confidence": 0.9791378974914551}]}, {"text": "We have also observed that MCC has a lower relative standard deviation than f-measure.", "labels": [], "entities": [{"text": "MCC", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9767593741416931}]}, {"text": "For a 2 \u00d7 2 contingency  gested as one of the best methods to summarize into a single value the confusion matrix of a binary classification task (Jurman and Furlanello, 2010;).", "labels": [], "entities": []}, {"text": "Given the confusion matrix All sentences with at least one company mention are used for the experiment.", "labels": [], "entities": []}, {"text": "We remove stop words and use Stanford CoreNLP for partof-speech tagging and named entity recognition.", "labels": [], "entities": [{"text": "Stanford CoreNLP", "start_pos": 29, "end_pos": 45, "type": "DATASET", "confidence": 0.9399040639400482}, {"text": "partof-speech tagging", "start_pos": 50, "end_pos": 71, "type": "TASK", "confidence": 0.8237292170524597}, {"text": "named entity recognition", "start_pos": 76, "end_pos": 100, "type": "TASK", "confidence": 0.640117883682251}]}, {"text": "Models are constructed using linear kernel support vector machines for both classification tasks.", "labels": [], "entities": []}, {"text": "SVM-light with tree kernels 3) is used for both the FWD and SemTree feature spaces.", "labels": [], "entities": [{"text": "FWD", "start_pos": 52, "end_pos": 55, "type": "DATASET", "confidence": 0.9625733494758606}]}, {"text": "shows the mean MCC values for each task, for each sector.", "labels": [], "entities": [{"text": "MCC", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.9568504095077515}]}, {"text": "Separate means are shown for the test years of financial crisis and economic recovery to highlight the differences in performance that might result from market volatility. pos.", "labels": [], "entities": []}, {"text": "1 dow, investors, index, retail, data pos.", "labels": [], "entities": []}, {"text": "2 costs, food, price, prices, named entity 4 neu.", "labels": [], "entities": []}, {"text": "1 q3, q1, nov, q2, apr neu.", "labels": [], "entities": [{"text": "apr", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9736932516098022}]}, {"text": "2 cents, million, share, year, quarter neg.", "labels": [], "entities": []}, {"text": "1 cut, sales, prices, hurt, disappointing neg.", "labels": [], "entities": []}, {"text": "2 percent, call, company, fell, named entity 7: Sample sLDA topics for consumer staples for test year 2010 (train on 2009), polarity task.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Data statistics of mean and standard devi- ation by year from January 2007 to August 2012,  for three sectors, with the number of companies.", "labels": [], "entities": [{"text": "standard devi- ation", "start_pos": 38, "end_pos": 58, "type": "METRIC", "confidence": 0.9000677168369293}]}, {"text": " Table 4: Average MCC for the change and polarity  tasks by feature representation, for 2008-2010; for  2011-2012; for all 5 years and associated p-values  of ANOVAs for comparison to BOW.", "labels": [], "entities": [{"text": "MCC", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.7413576245307922}, {"text": "ANOVAs", "start_pos": 159, "end_pos": 165, "type": "METRIC", "confidence": 0.7303511500358582}, {"text": "BOW", "start_pos": 184, "end_pos": 187, "type": "METRIC", "confidence": 0.6891114115715027}]}]}