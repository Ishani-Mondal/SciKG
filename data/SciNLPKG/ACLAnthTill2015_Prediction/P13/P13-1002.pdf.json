{"title": [{"text": "Integrating Translation Memory into Phrase-Based Machine Translation during Decoding", "labels": [], "entities": [{"text": "Integrating Translation Memory", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.9237195054690043}, {"text": "Phrase-Based Machine Translation", "start_pos": 36, "end_pos": 68, "type": "TASK", "confidence": 0.7252016464869181}]}], "abstractContent": [{"text": "Since statistical machine translation (SMT) and translation memory (TM) complement each other in matched and unmatched regions, integrated models are proposed in this paper to incorporate TM information into phrase-based SMT.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 6, "end_pos": 43, "type": "TASK", "confidence": 0.7775433113177618}, {"text": "phrase-based SMT", "start_pos": 208, "end_pos": 224, "type": "TASK", "confidence": 0.5264954715967178}]}, {"text": "Unlike previous multi-stage pipeline approaches, which directly merge TM result into the final output, the proposed models refer to the corresponding TM information associated with each phrase at SMT decoding.", "labels": [], "entities": [{"text": "SMT decoding", "start_pos": 196, "end_pos": 208, "type": "TASK", "confidence": 0.8972769975662231}]}, {"text": "On a Chinese-English TM database, our experiments show that the proposed integrated Model -III is significantly better than either the SMT or the TM systems when the fuzzy match score is above 0.4.", "labels": [], "entities": [{"text": "Chinese-English TM database", "start_pos": 5, "end_pos": 32, "type": "DATASET", "confidence": 0.6118142108122507}, {"text": "SMT", "start_pos": 135, "end_pos": 138, "type": "TASK", "confidence": 0.8143774271011353}]}, {"text": "Furthermore, integrated Model-III achieves overall 3.48 BLEU points improvement and 2.62 TER points reduction in comparison with the pure SMT system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 56, "end_pos": 60, "type": "METRIC", "confidence": 0.9996364116668701}, {"text": "TER", "start_pos": 89, "end_pos": 92, "type": "METRIC", "confidence": 0.9990962743759155}, {"text": "SMT", "start_pos": 138, "end_pos": 141, "type": "TASK", "confidence": 0.9899583458900452}]}, {"text": "Besides , the proposed models also outperform previous approaches significantly.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical machine translation (SMT), especially the phrase-based model (, has developed very fast in the last decade.", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8456876079241434}]}, {"text": "For certain language pairs and special applications, SMT output has reached an acceptable level, especially in the domains where abundant parallel corpora are available (.", "labels": [], "entities": [{"text": "SMT", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.9939946532249451}]}, {"text": "However, SMT is rarely applied to professional translation because its output quality is still far from satisfactory.", "labels": [], "entities": [{"text": "SMT", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.9939140677452087}, {"text": "professional translation", "start_pos": 34, "end_pos": 58, "type": "TASK", "confidence": 0.6674253642559052}]}, {"text": "Especially, there is no guarantee that a SMT system can produce translations in a consistent manner ).", "labels": [], "entities": [{"text": "SMT", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9914520978927612}]}, {"text": "In contrast, translation memory (TM), which uses the most similar translation sentence (usually above a certain fuzzy match threshold) in the database as the reference for post-editing, has been widely adopted in professional translation field for many years).", "labels": [], "entities": [{"text": "translation memory (TM)", "start_pos": 13, "end_pos": 36, "type": "TASK", "confidence": 0.8952185034751892}]}, {"text": "TM is very useful for repetitive material such as updated product manuals, and can give high quality and consistent translations when the similarity of fuzzy match is high.", "labels": [], "entities": []}, {"text": "Therefore, professional translators trust TM much more than SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.969916820526123}]}, {"text": "However, high-similarity fuzzy matches are available unless the material is very repetitive.", "labels": [], "entities": []}, {"text": "In general, for those matched segments 1 , TM provides more reliable results than SMT does.", "labels": [], "entities": [{"text": "TM", "start_pos": 43, "end_pos": 45, "type": "TASK", "confidence": 0.6038755774497986}, {"text": "SMT", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.9836611151695251}]}, {"text": "One reason is that the results of TM have been revised by human according to the global context, but SMT only utilizes local context.", "labels": [], "entities": [{"text": "TM", "start_pos": 34, "end_pos": 36, "type": "TASK", "confidence": 0.9528951048851013}, {"text": "SMT", "start_pos": 101, "end_pos": 104, "type": "TASK", "confidence": 0.9871750473976135}]}, {"text": "However, for those unmatched segments, SMT is more reliable.", "labels": [], "entities": [{"text": "SMT", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.985824704170227}]}, {"text": "Since TM and SMT complement each other in those matched and unmatched segments, the output quality is expected to be raised significantly if they can be combined to supplement each other.", "labels": [], "entities": [{"text": "SMT", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9664268493652344}]}, {"text": "In recent years, some previous works have incorporated TM matched segments into SMT in a pipelined manner).", "labels": [], "entities": [{"text": "SMT", "start_pos": 80, "end_pos": 83, "type": "TASK", "confidence": 0.9462688565254211}]}, {"text": "All these pipeline approaches translate the sentence in two stages.", "labels": [], "entities": []}, {"text": "They first determine whether the extracted TM sentence pair should be adopted or not.", "labels": [], "entities": []}, {"text": "Most of them use fuzzy match score as the threshold, but  and  use a classifier to make the judgment.", "labels": [], "entities": []}, {"text": "Afterwards, they merge the relevant translations of matched segments into the source sentence, and then force the SMT system to only translate those unmatched segments at decoding.", "labels": [], "entities": [{"text": "SMT", "start_pos": 114, "end_pos": 117, "type": "TASK", "confidence": 0.986134946346283}]}, {"text": "There are three obvious drawbacks for the above pipeline approaches.", "labels": [], "entities": []}, {"text": "Firstly, all of them determine whether those matched segments should be adopted or not at sentence level.", "labels": [], "entities": []}, {"text": "That is, they are either all adopted or all abandoned regardless of their individual quality.", "labels": [], "entities": []}, {"text": "Secondly, as several TM target phrases might be available for one given TM source phrase due to insertions, the incorrect selection made in the merging stage cannot be remedied in the following translation stage.", "labels": [], "entities": []}, {"text": "For example, there are six possible corresponding TM target phrases for the given TM source phrase \"\u5173\u8054 4 \u7684 5 \u5bf9\u8c61 6 \" (as shown in) such as \"object 2 that 3 is 4 associated 5 \", and \"an 1 object 2 that 3 is 4 associated 5 with 6 \", etc.", "labels": [], "entities": []}, {"text": "And it is hard to tell which one should be adopted in the merging stage.", "labels": [], "entities": []}, {"text": "Thirdly, the pipeline approach does not utilize the SMT probabilistic information in deciding whether a matched TM phrase should be adopted or not, and which target phrase should be selected when we have multiple candidates.", "labels": [], "entities": [{"text": "SMT", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.9831612706184387}]}, {"text": "Therefore, the possible improvements resulted from those pipeline approaches are quite limited.", "labels": [], "entities": []}, {"text": "On the other hand, instead of directly merging TM matched phrases into the source sentence, some approaches) simply add the longest matched pairs into SMT phrase table, and then associate them with a fixed large probability value to favor the corresponding TM target phrase at SMT decoding.", "labels": [], "entities": [{"text": "SMT phrase", "start_pos": 151, "end_pos": 161, "type": "TASK", "confidence": 0.8408539891242981}, {"text": "SMT decoding", "start_pos": 277, "end_pos": 289, "type": "TASK", "confidence": 0.915066659450531}]}, {"text": "However, since only one aligned target phrase will be added for each matched source phrase, they share most drawbacks with the pipeline approaches mentioned above and merely achieve similar performance.", "labels": [], "entities": []}, {"text": "To avoid the drawbacks of the pipeline approach (mainly due to making a hard decision before decoding), we propose several integrated models to completely make use of TM information during decoding.", "labels": [], "entities": []}, {"text": "For each TM source phrase, we keep all its possible corresponding target phrases (instead of keeping only one of them).", "labels": [], "entities": []}, {"text": "The integrated models then consider all corresponding TM target phrases and SMT preference during decoding.", "labels": [], "entities": [{"text": "SMT", "start_pos": 76, "end_pos": 79, "type": "TASK", "confidence": 0.9863660335540771}]}, {"text": "Therefore, the proposed integrated models combine SMT and TM at a deep level (versus the surface level at which TM result is directly plugged in under previous pipeline approaches).", "labels": [], "entities": [{"text": "SMT", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.980964720249176}]}, {"text": "On a Chinese-English computer technical documents TM database, our experiments have shown that the proposed Model-III improves the translation quality significantly over either the pure phrase-based SMT or the TM systems when the fuzzy match score is above 0.4.", "labels": [], "entities": [{"text": "Chinese-English computer technical documents TM database", "start_pos": 5, "end_pos": 61, "type": "DATASET", "confidence": 0.6189721077680588}]}, {"text": "Compared with the pure SMT system, the proposed integrated Model-III achieves 3.48 BLEU points improvement and 2.62 TER points reduction overall.", "labels": [], "entities": [{"text": "SMT", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.9931461811065674}, {"text": "BLEU", "start_pos": 83, "end_pos": 87, "type": "METRIC", "confidence": 0.9996553659439087}, {"text": "TER", "start_pos": 116, "end_pos": 119, "type": "METRIC", "confidence": 0.9992135763168335}]}, {"text": "Furthermore, the proposed models significantly outperform previous pipeline approaches.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our TM database consists of computer domain Chinese-English translation sentence-pairs, which contains about 267k sentence-pairs.", "labels": [], "entities": [{"text": "TM database", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.7507317960262299}]}, {"text": "The average length of Chinese sentences is 13.85 words and that of English sentences is 13.86 words.", "labels": [], "entities": []}, {"text": "We randomly selected a development set and a test set, and then the remaining sentence pairs are for training set.", "labels": [], "entities": []}, {"text": "The detailed corpus statistics are shown in.", "labels": [], "entities": []}, {"text": "Furthermore, development set and test set are divided into various intervals according to their best fuzzy match scores.", "labels": [], "entities": []}, {"text": "Corpus statistics for each interval in the test set are shown in.", "labels": [], "entities": []}, {"text": "For the phrase-based SMT system, we adopted the Moses toolkit ().", "labels": [], "entities": [{"text": "SMT", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.8867006301879883}]}, {"text": "The system configurations are as follows: GIZA++) is used to obtain the bidirectional word alignments.", "labels": [], "entities": [{"text": "GIZA", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.8834379315376282}]}, {"text": "Afterwards, \"intersection\" 3 refinement () is adopted to extract phrase-pairs.", "labels": [], "entities": []}, {"text": "We use the SRI Language Model toolkit) to train a 5-gram model with modified Kneser-Ney smoothing) on the target-side (English) training corpus.", "labels": [], "entities": [{"text": "SRI Language Model toolkit", "start_pos": 11, "end_pos": 37, "type": "DATASET", "confidence": 0.839340090751648}]}, {"text": "All the feature weights and the weight for each probability factor (3 factors for Model-III) are tuned on the development set with minimumerror-rate training (MERT).", "labels": [], "entities": [{"text": "minimumerror-rate training (MERT)", "start_pos": 131, "end_pos": 164, "type": "METRIC", "confidence": 0.8884290218353271}]}, {"text": "The maximum phrase length is set to 7 in our experiments.", "labels": [], "entities": []}, {"text": "In this work, the translation performance is measured with case-insensitive BLEU-4 score () and TER score).", "labels": [], "entities": [{"text": "translation", "start_pos": 18, "end_pos": 29, "type": "TASK", "confidence": 0.9698834419250488}, {"text": "BLEU-4 score", "start_pos": 76, "end_pos": 88, "type": "METRIC", "confidence": 0.9797435998916626}, {"text": "TER score", "start_pos": 96, "end_pos": 105, "type": "METRIC", "confidence": 0.9898368716239929}]}, {"text": "Statistical significance testis conducted with re-sampling (1,000 times) approach) in 95% confidence level.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Corpus Statistics for Test-Set", "labels": [], "entities": [{"text": "Corpus", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.972443163394928}]}, {"text": " Table 3: Translation Results (BLEU%). Scores marked by \"*\" are significantly better (p < 0.05) than both TM  and SMT systems, and those marked by \"#\" are significantly better (p < 0.05) than Koehn-10.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.946085512638092}, {"text": "BLEU", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.9990968704223633}]}, {"text": " Table 4: Translation Results (TER%). Scores marked by \"*\" are significantly better (p < 0.05) than both TM and  SMT systems, and those marked by \"#\" are significantly better (p < 0.05) than", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9518338441848755}, {"text": "TER", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.9885363578796387}]}]}