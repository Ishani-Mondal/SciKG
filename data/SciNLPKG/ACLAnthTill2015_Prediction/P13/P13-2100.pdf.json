{"title": [{"text": "Using Integer Linear Programming in Concept-to-Text Generation to Produce More Compact Texts", "labels": [], "entities": [{"text": "Concept-to-Text Generation", "start_pos": 36, "end_pos": 62, "type": "TASK", "confidence": 0.741181343793869}]}], "abstractContent": [{"text": "We present an ILP model of concept-to-text generation.", "labels": [], "entities": [{"text": "concept-to-text generation", "start_pos": 27, "end_pos": 53, "type": "TASK", "confidence": 0.7855164408683777}]}, {"text": "Unlike pipeline archi-tectures, our model jointly considers the choices in content selection, lexicaliza-tion, and aggregation to avoid greedy decisions and produce more compact texts.", "labels": [], "entities": []}], "introductionContent": [{"text": "Concept-to-text natural language generation (NLG) generates texts from formal knowledge representations).", "labels": [], "entities": [{"text": "Concept-to-text natural language generation (NLG) generates texts from formal knowledge representations", "start_pos": 0, "end_pos": 103, "type": "TASK", "confidence": 0.7497374690496005}]}, {"text": "With the emergence of the Semantic Web (, interest in concept-to-text NLG has been revived and several methods have been proposed to express axioms of OWL ontologies () in natural language;).", "labels": [], "entities": []}, {"text": "NLG systems typically employ a pipeline architecture.", "labels": [], "entities": []}, {"text": "They usually start by selecting the logical facts to express.", "labels": [], "entities": []}, {"text": "The next stage, text planning, ranges from simply ordering the selected facts to complex decisions about the rhetorical structure of the text.", "labels": [], "entities": [{"text": "text planning", "start_pos": 16, "end_pos": 29, "type": "TASK", "confidence": 0.8479929268360138}]}, {"text": "Lexicalization then selects the words and syntactic structures that will realize each fact, specifying how each fact can be expressed as a single sentence.", "labels": [], "entities": []}, {"text": "Sentence aggregation then combines sentences into longer ones.", "labels": [], "entities": [{"text": "Sentence aggregation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9218979477882385}]}, {"text": "Another component generates appropriate referring expressions, and surface realization produces the final text.", "labels": [], "entities": []}, {"text": "Each stage of the pipeline is treated as a local optimization problem, where the decisions of the previous stages cannot be modified.", "labels": [], "entities": []}, {"text": "This arrangement produces texts that may not be optimal, since the decisions of the stages have been shown to be co-dependent.", "labels": [], "entities": []}, {"text": "For example, content selection and lexicalization may lead to more or fewer sentence aggregation opportunities.", "labels": [], "entities": [{"text": "content selection", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.7282684743404388}]}, {"text": "We present an Integer Linear Programming (ILP) model that combines content selection, lexicalization, and sentence aggregation.", "labels": [], "entities": [{"text": "content selection", "start_pos": 67, "end_pos": 84, "type": "TASK", "confidence": 0.7268549799919128}]}, {"text": "Our model does not consider text planning, nor referring expression generation, which we hope to include in future work, but it is combined with an external simple text planner and a referring expression generation component; we also do not discuss surface realization.", "labels": [], "entities": [{"text": "text planning", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.7951815724372864}, {"text": "referring expression generation", "start_pos": 47, "end_pos": 78, "type": "TASK", "confidence": 0.643487016359965}]}, {"text": "Unlike pipeline architectures, our model jointly examines the possible choices in the three NLG stages it considers, to avoid greedy local decisions.", "labels": [], "entities": []}, {"text": "Given an individual (entity) or class of an OWL ontology and a set of facts (OWL axioms) about the individual or class, we aim to produce a text that expresses as many of the facts in as few words as possible.", "labels": [], "entities": []}, {"text": "This is important when space is limited or expensive (e.g., product descriptions on smartphones, advertisements in search engines).", "labels": [], "entities": []}, {"text": "Although the search space of our model is very large and ILP problems are in general NP-hard, ILP solvers can be used, they are very fast in practice, and they guarantee finding a global optimum.", "labels": [], "entities": [{"text": "ILP solvers", "start_pos": 94, "end_pos": 105, "type": "TASK", "confidence": 0.828878253698349}]}, {"text": "Experiments show that our ILP model outperforms, in terms of compression, an NLG system that uses the same components, but connected in a pipeline, with no deterioration in fluency and clarity.", "labels": [], "entities": [{"text": "clarity", "start_pos": 185, "end_pos": 192, "type": "METRIC", "confidence": 0.989774227142334}]}], "datasetContent": [{"text": "We used NaturalOWL (), an NLG system for OWL ontologies that relies on a pipeline of content selection, text planning, lexicalization, aggregation, referring expression generation, and surface realization.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 148, "end_pos": 179, "type": "TASK", "confidence": 0.7136252919832865}, {"text": "surface realization", "start_pos": 185, "end_pos": 204, "type": "TASK", "confidence": 0.7757157981395721}]}, {"text": "We modified content selection, lexicalization, and aggregation to use our ILP model, maintaining the aggregation rules of the original system.", "labels": [], "entities": [{"text": "content selection", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.6957262009382248}]}, {"text": "For referring expression generation and surface realization, the new system, called ILPNLG, invokes the corresponding components of NaturalOWL.", "labels": [], "entities": [{"text": "expression generation", "start_pos": 14, "end_pos": 35, "type": "TASK", "confidence": 0.7245464324951172}, {"text": "surface realization", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.762407124042511}]}, {"text": "The original system, called PIPELINE, assumes that each relation has been mapped to a topical section, as in ILPNLG.", "labels": [], "entities": [{"text": "PIPELINE", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9112731218338013}, {"text": "ILPNLG", "start_pos": 109, "end_pos": 115, "type": "DATASET", "confidence": 0.9216437935829163}]}, {"text": "It also assumes that a manually specified order of the sections and the relations of each section is available, which is used by the text planner to order the selected facts (by their relations).", "labels": [], "entities": []}, {"text": "The subsequent components of the pipeline are not allowed to change the order of the facts, and aggregation operates only on sentence plans of adjacent facts from the same section.", "labels": [], "entities": []}, {"text": "In ILPNLG, the manually specified order of sections and relations is used to order the sentences of each subset s j (before aggregating them), the aggregated sentences in each section (each aggregated sentence inherits the minimum order of its constituents), and the sections (with their sentences).", "labels": [], "entities": []}, {"text": "We used the Wine Ontology, which had been used in previous experiments with PIPELINE.", "labels": [], "entities": [{"text": "Wine Ontology", "start_pos": 12, "end_pos": 25, "type": "DATASET", "confidence": 0.9497301280498505}, {"text": "PIPELINE", "start_pos": 76, "end_pos": 84, "type": "DATASET", "confidence": 0.7618920803070068}]}, {"text": "We kept the 2 topical sections, the ordering of sections and relations, and the sentence plans that had been used in the previous experiments, but we added more sentence plans to ensure that 3 sentence plans were available per fact.", "labels": [], "entities": []}, {"text": "We generated texts for the 52 wine individuals of the ontology; we did not experiment with texts describing classes of wines, because we could not think of multiple alternative sentence plans for many of their axioms.", "labels": [], "entities": []}, {"text": "For each individual, there were 5 facts on average and a maximum of 6 facts.", "labels": [], "entities": []}, {"text": "PIPELINE has a parameter M specifying the maximum number of facts it is allowed to report per text.", "labels": [], "entities": [{"text": "PIPELINE", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.6723326444625854}]}, {"text": "When M is smaller than the number of available facts |F | and all the facts are treated as equally important, as in our experiments, it selects randomly M of the available facts.", "labels": [], "entities": []}, {"text": "We repeated the generation of PIPELINE's texts for the 52 individuals for M = 2, 3, 4, 5, 6.", "labels": [], "entities": [{"text": "PIPELINE's texts", "start_pos": 30, "end_pos": 46, "type": "DATASET", "confidence": 0.8787664373715719}, {"text": "M = 2", "start_pos": 74, "end_pos": 79, "type": "METRIC", "confidence": 0.8792575200398763}]}, {"text": "For each M , the texts of PIPELINE for the 52 individuals were generated three times, each time using one of the different alternative sentence plans of each relation.", "labels": [], "entities": [{"text": "PIPELINE", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.8446295261383057}]}, {"text": "We also generated the texts using a variant of PIPELINE, dubbed PIPELINESHORT, which always selects the shortest (in elements) sentence plan among the available ones.", "labels": [], "entities": []}, {"text": "In all cases, PIPELINE and PIPELINESHORT were allowed to form aggregated sentences containing up to B max = 22 distinct elements, which was the number of distinct elements of the longest aggregated sentence in the previous experiments, where PIPELINE was allowed to aggregate up to 3 original sentences.", "labels": [], "entities": []}, {"text": "With ILPNLG, we repeated the generation of the texts of the 52 individuals using different values of \u03bb 1 (\u03bb 2 = 1 \u2212 \u03bb 1 ), which led to texts expressing from zero to all of the available facts.", "labels": [], "entities": [{"text": "ILPNLG", "start_pos": 5, "end_pos": 11, "type": "DATASET", "confidence": 0.9468681812286377}]}, {"text": "We set the maximum number of fact subsets tom = 3, which was the maximum number of aggregated sentences observed in the texts of PIPELINE and PIPELINESHORT.", "labels": [], "entities": []}, {"text": "Again, we set B max = 22.", "labels": [], "entities": [{"text": "B max", "start_pos": 14, "end_pos": 19, "type": "METRIC", "confidence": 0.982393205165863}]}, {"text": "We compared ILPNLG to PIPELINE and PIPELI-NESHORT by measuring the average number of facts they reported divided by the average text length (in words).", "labels": [], "entities": []}, {"text": "shows this ratio as a function of the average number of reported facts, along with 95% confidence intervals (of sample means).", "labels": [], "entities": []}, {"text": "PIPELINESHORT achieved better results than PIPELINE, but the differences were small.", "labels": [], "entities": [{"text": "PIPELINESHORT", "start_pos": 0, "end_pos": 13, "type": "DATASET", "confidence": 0.6469036340713501}]}, {"text": "For \u03bb 1 < 0.2, ILPNLG produces empty texts, See www..org/TR/owl-guide/wine.rdf.", "labels": [], "entities": []}, {"text": "since it focuses on minimizing the number of distinct elements of each text.", "labels": [], "entities": []}, {"text": "For \u03bb 1 \u2265 0.225, it performs better than the other systems.", "labels": [], "entities": []}, {"text": "For \u03bb 1 \u2248 0.3, it obtains the highest fact/words ratio by selecting the facts and sentence plans that lead to the most compressive aggregations.", "labels": [], "entities": []}, {"text": "For greater values of \u03bb 1 , it selects additional facts whose sentence plans do not aggregate that well, which is why the ratio declines.", "labels": [], "entities": []}, {"text": "For small numbers of facts, the two pipeline systems select facts and sentence plans that offer very few aggregation opportunities; as the number of selected facts increases, some more aggregation opportunities arise, which is why the facts/words ratio of the two systems improves.", "labels": [], "entities": []}, {"text": "In all the experiments, the ILP solver was very fast (average: 0.08 sec, worst: 0.14 sec In the first pair, PIPELINE uses different verbs for the grapes and producer, whereas ILPNLG uses the same verb, which leads to a more compressive aggregation; both texts describe the same wine and report 4 facts.", "labels": [], "entities": [{"text": "ILP solver", "start_pos": 28, "end_pos": 38, "type": "TASK", "confidence": 0.6279121339321136}]}, {"text": "In the second pair, ILPNLG has chosen to express the sweetness instead of the producer, and uses the same verb (\"be\") for all the facts, leading to a shorter sentence; again both texts describe the same wine and report 4 facts.", "labels": [], "entities": [{"text": "ILPNLG", "start_pos": 20, "end_pos": 26, "type": "DATASET", "confidence": 0.8921034336090088}]}, {"text": "In both examples, some facts are not aggregated because they belong in different sections.", "labels": [], "entities": []}], "tableCaptions": []}