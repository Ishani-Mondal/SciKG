{"title": [{"text": "An Annotated Corpus of Quoted Opinions in News Articles", "labels": [], "entities": []}], "abstractContent": [{"text": "Quotes are used in news articles as evidence of a person's opinion, and thus area useful target for opinion mining.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 100, "end_pos": 114, "type": "TASK", "confidence": 0.7618366479873657}]}, {"text": "However , labelling each quote with a polarity score directed at a textually-anchored target can ignore the broader issue that the speaker is commenting on.", "labels": [], "entities": []}, {"text": "We address this by instead labelling quotes as supporting or opposing a clear expression of a point of view on a topic, called a position statement.", "labels": [], "entities": []}, {"text": "Using this we construct a corpus covering 7 topics with 2,228 quotes.", "labels": [], "entities": []}], "introductionContent": [{"text": "News articles area useful target for opinion mining as they discuss salient opinions by newsworthy people.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.8652328550815582}]}, {"text": "Rather than asserting what a person's opinion is, journalists typically provide evidence by using reported speech, and in particular, direct quotes.", "labels": [], "entities": []}, {"text": "We focus on direct quotes as expressions of opinion, as they can be accurately extracted and attributed to a speaker (O'.", "labels": [], "entities": []}, {"text": "Characterising the opinions in quotes remains challenging.", "labels": [], "entities": []}, {"text": "In sentiment analysis over product reviews, polarity labels are commonly used because the target, the product, is clearly identified.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.9373505711555481}]}, {"text": "However, for quotes on topics of debate, the target and meaning of polarity labels is less clear.", "labels": [], "entities": []}, {"text": "For example, labelling a quote about abortion as simply positive or negative is uninformative, as a speaker can use either positive or negative language to support or oppose either side of the debate.", "labels": [], "entities": []}, {"text": "Previous work ( has addressed this by giving each expression of opinion a textually-anchored target.", "labels": [], "entities": []}, {"text": "While this makes sense for named entities, it does not apply as obviously for topics, such as abortion, that may not be directly mentioned.", "labels": [], "entities": []}, {"text": "Our solution is to instead define position statements, which are Abortion: Women should have the right to choose an abortion.", "labels": [], "entities": []}, {"text": "Carbon tax: Australia should introduce a taxon carbon or an emissions trading scheme to combat global warming.", "labels": [], "entities": []}, {"text": "Immigration: Immigration into Australia should be maintained or increased because its benefits outweigh any negatives.", "labels": [], "entities": []}, {"text": "Reconciliation: The Australian government should formally apologise to the Aboriginal people for past injustices.", "labels": [], "entities": [{"text": "Reconciliation", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9397280216217041}]}, {"text": "Republic: Australia should cease to be a monarchy with the Queen as head of state and become a republic with an Australian head of state.", "labels": [], "entities": []}, {"text": "Same-sex marriage: Same-sex couples should have the right to attain the legal state of marriage as it is for heterosexual couples.", "labels": [], "entities": []}, {"text": "Work choices: Australia should introduce WorkChoices to give employers more control over wages and conditions.", "labels": [], "entities": []}, {"text": "clear statements of a viewpoint or position on a particular topic.", "labels": [], "entities": []}, {"text": "Quotes related to this topic can then be labelled as supporting, neutral, or opposing the position statement.", "labels": [], "entities": []}, {"text": "This disambiguates the meaning of the polarity labels, and allows us to determine the side of the debate that the speaker is on. shows the topics and position statements used in this work, and some example quotes from the republic topic are given below.", "labels": [], "entities": []}, {"text": "Note that the first example includes no explicit mention of the monarchy or the republic.", "labels": [], "entities": []}, {"text": "Positive: \"I now believe that the time has come.", "labels": [], "entities": []}, {"text": "for us to have a truly Australian constitutional head of state.\"", "labels": [], "entities": []}, {"text": "Neutral: \"The establishment of an Australian republic is essentially a symbolic change, with the main arguments, for and against, turning on national identity.", "labels": [], "entities": []}, {"text": "\" Negative: \"I personally think that the monarchy is a tradition which we want to keep.\"", "labels": [], "entities": []}, {"text": "With this formulation we define an annotation scheme and build a corpus covering 7 topics, with 100 documents per topic.", "labels": [], "entities": []}, {"text": "This corpus includes 3,428 quotes, of which 1,183 were marked invalid, leaving 2,228 that were marked as supporting, neutral, or opposing the relevant topic statement.", "labels": [], "entities": []}, {"text": "All quotes in our corpus were annotated by three annotators, with Fleiss' \u03ba values of between 0.43 and 0.45, which is moderate.", "labels": [], "entities": [{"text": "Fleiss' \u03ba", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9427378177642822}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Average Agreement (AA) and Fleiss' \u03ba  over the valid quotes", "labels": [], "entities": [{"text": "Average Agreement (AA)", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.8983498454093933}, {"text": "Fleiss' \u03ba", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.8097232580184937}]}, {"text": " Table 3: Average Agreement (AA) and Fleiss' \u03ba  when the labels are neutral versus non-neutral", "labels": [], "entities": [{"text": "Average Agreement (AA)", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.925941276550293}, {"text": "Fleiss' \u03ba", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.8772362470626831}]}, {"text": " Table 4: Label distribution for the final corpus.", "labels": [], "entities": []}]}