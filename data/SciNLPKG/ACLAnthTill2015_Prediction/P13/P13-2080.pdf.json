{"title": [], "abstractContent": [{"text": "Textual entailment is an asymmetric relation between two text fragments that describes whether one fragment can be inferred from the other.", "labels": [], "entities": [{"text": "Textual entailment", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7187389433383942}]}, {"text": "It thus cannot capture the notion that the target fragment is \"almost entailed\" by the given text.", "labels": [], "entities": []}, {"text": "The recently suggested idea of partial tex-tual entailment may remedy this problem.", "labels": [], "entities": [{"text": "partial tex-tual entailment", "start_pos": 31, "end_pos": 58, "type": "TASK", "confidence": 0.6242968738079071}]}, {"text": "We investigate partial entailment under the faceted entailment model and the possibility of adapting existing textual entailment methods to this setting.", "labels": [], "entities": []}, {"text": "Indeed, our results show that these methods are useful for recognizing partial entailment.", "labels": [], "entities": [{"text": "recognizing partial entailment", "start_pos": 59, "end_pos": 89, "type": "TASK", "confidence": 0.8614810903867086}]}, {"text": "We also provide a preliminary assessment of how partial entailment maybe used for recognizing (complete) textual entailment.", "labels": [], "entities": [{"text": "recognizing (complete) textual entailment", "start_pos": 82, "end_pos": 123, "type": "TASK", "confidence": 0.7869823475678762}]}], "introductionContent": [{"text": "Approaches for applied semantic inference over texts gained growing attention in recent years, largely triggered by the textual entailment framework (.", "labels": [], "entities": []}, {"text": "Textual entailment is a generic paradigm for semantic inference, where the objective is to recognize whether a textual hypothesis (labeled H) can be inferred from another given text (labeled T ).", "labels": [], "entities": [{"text": "Textual entailment", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7205925136804581}, {"text": "semantic inference", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.7812159657478333}]}, {"text": "The definition of textual entailment is in some sense strict, in that it requires that H's meaning be implied by T in its entirety.", "labels": [], "entities": []}, {"text": "This means that from an entailment perspective, a text that contains the main ideas of a hypothesis, but lacks a minor detail, is indiscernible from an entirely unrelated text.", "labels": [], "entities": []}, {"text": "For example, if T is \"muscles move bones\", and H \"the main job of muscles is to move bones\", then T does not entail H, and we are left with no sense of how close (T, H) were to entailment.", "labels": [], "entities": []}, {"text": "In the related problem of semantic text similarity, gradual measures are already in use.", "labels": [], "entities": [{"text": "semantic text similarity", "start_pos": 26, "end_pos": 50, "type": "TASK", "confidence": 0.689807673295339}]}, {"text": "The semantic text similarity challenge in SemEval 2012) explicitly defined different levels of similarity from 5 (semantic equivalence) to 0 (no relation).", "labels": [], "entities": [{"text": "semantic text similarity", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.6967376867930094}]}, {"text": "For instance, 4 was defined as \"the two sentences are mostly equivalent, but some unimportant details differ\", and 3 meant that \"the two sentences are roughly equivalent, but some important information differs\".", "labels": [], "entities": []}, {"text": "Though this modeling does indeed provide finer-grained notions of similarity, it is not appropriate for semantic inference for two reasons.", "labels": [], "entities": [{"text": "semantic inference", "start_pos": 104, "end_pos": 122, "type": "TASK", "confidence": 0.8044876456260681}]}, {"text": "First, the term \"important information\" is vague; what makes one detail more important than another?", "labels": [], "entities": []}, {"text": "Secondly, similarity is not sufficiently well-defined for sound semantic inference; for example, \"snowdrops bloom in summer\" and \"snowdrops bloom in winter\" maybe similar, but have contradictory meanings.", "labels": [], "entities": [{"text": "sound semantic inference", "start_pos": 58, "end_pos": 82, "type": "TASK", "confidence": 0.7261159221331278}]}, {"text": "All in all, these measures of similarity do not quite capture the gradual relation needed for semantic inference.", "labels": [], "entities": [{"text": "semantic inference", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.7955245673656464}]}, {"text": "An appealing approach to dealing with the rigidity of textual entailment, while preserving the more precise nature of the entailment definition, is by breaking down the hypothesis into components, and attempting to recognize whether each one is individually entailed by T . It is called partial textual entailment, because we are only interested in recognizing whether a single element of the hypothesis is entailed.", "labels": [], "entities": []}, {"text": "To differentiate the two tasks, we will refer to the original textual entailment task as complete textual entailment.", "labels": [], "entities": []}, {"text": "Partial textual entailment was first introduced by, who presented a machine learning approach and showed significant improvement over baseline methods.", "labels": [], "entities": [{"text": "Partial textual entailment", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7577324310938517}]}, {"text": "Recently, a public benchmark has become available through the Joint Student Response Analysis and 8th Recognizing Textual Entailment (RTE) Challenge in SemEval 2013 (), on which we focus in this paper.", "labels": [], "entities": [{"text": "8th Recognizing Textual Entailment (RTE) Challenge in SemEval 2013", "start_pos": 98, "end_pos": 164, "type": "TASK", "confidence": 0.6908661696043882}]}, {"text": "Our goal in this paper is to investigate the idea of partial textual entailment, and assess whether existing complete textual entailment methods can be used to recognize it.", "labels": [], "entities": []}, {"text": "We assume the facet model presented in SemEval 2013, and adapt existing technologies to the task of recognizing partial entailment (Section 3).", "labels": [], "entities": []}, {"text": "Our work further expands upon) by evaluating these adapted methods on the new RTE-8 benchmark (Section 4).", "labels": [], "entities": [{"text": "RTE-8 benchmark", "start_pos": 78, "end_pos": 93, "type": "DATASET", "confidence": 0.9146668314933777}]}, {"text": "Partial entailment may also facilitate an alternative divide and conquer approach to complete textual entailment.", "labels": [], "entities": [{"text": "Partial entailment", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8536165952682495}]}, {"text": "We provide an initial investigation of this approach (Section 5).", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our methods as part of RTE-8.", "labels": [], "entities": [{"text": "RTE-8", "start_pos": 36, "end_pos": 41, "type": "DATASET", "confidence": 0.8400696516036987}]}, {"text": "The challenge focuses on the domain of scholastic quizzes, and attempts to emulate the meticulous marking process that teachers do on a daily basis.", "labels": [], "entities": []}, {"text": "Given a question, a student's response, and a reference answer, the task of student response analysis is to determine whether the student answered correctly.", "labels": [], "entities": [{"text": "student response analysis", "start_pos": 76, "end_pos": 101, "type": "TASK", "confidence": 0.616215725739797}]}, {"text": "This task can be approximated as a special case of textual entailment; by assigning the student's answer as T and the reference answer as H, we are basically asking whether one can infer the correct (reference) answer from the student's response.", "labels": [], "entities": []}, {"text": "Recall the example from Section 2.", "labels": [], "entities": []}, {"text": "In this case, H is a reference answer to the question: Q: What is the main job of muscles?", "labels": [], "entities": []}, {"text": "T is essentially the student answer, though it is also possible to define T as the union of both the question and the student answer.", "labels": [], "entities": []}, {"text": "In this work, we chose to exclude the question.", "labels": [], "entities": []}, {"text": "There were two tracks in the challenge: complete textual entailment (the main task) and partial Unseen Answers Classify new answers to questions seen in training.", "labels": [], "entities": []}, {"text": "Unseen Questions Classify new answers to questions that were not seen in training, but other questions from the same domain were.", "labels": [], "entities": []}, {"text": "Unseen Domains Classify new answers to unseen questions from unseen domains.", "labels": [], "entities": [{"text": "Unseen Domains Classify new answers to unseen questions from unseen domains", "start_pos": 0, "end_pos": 75, "type": "TASK", "confidence": 0.7448593513532118}]}, {"text": "shows the F 1 -measure of each configuration in each scenario.", "labels": [], "entities": [{"text": "F 1 -measure", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.9811688959598541}]}, {"text": "There is some variance between the different scenarios; this maybe attributed to the fact that there are much fewer Unseen Answers and Unseen Questions instances.", "labels": [], "entities": []}, {"text": "In all cases, Majority significantly outperformed the other configurations.", "labels": [], "entities": []}, {"text": "While BaseLex and BaseSyn improve upon the baseline, they seem to make different mistakes, in particular false positives.", "labels": [], "entities": [{"text": "BaseLex", "start_pos": 6, "end_pos": 13, "type": "DATASET", "confidence": 0.6967152953147888}]}, {"text": "Their conjunction is thus a more conservative indicator of entailment, and proves helpful in terms of F 1 . All improvements over the baseline were found to be statistically significant using McNemar's test with p < 0.01 (excluding Disjunction).", "labels": [], "entities": [{"text": "F 1", "start_pos": 102, "end_pos": 105, "type": "METRIC", "confidence": 0.9920987784862518}, {"text": "Disjunction", "start_pos": 232, "end_pos": 243, "type": "METRIC", "confidence": 0.9889089465141296}]}, {"text": "It is also interesting to note that the systems' performance does not degrade in \"harder\" scenarios; this is a result of the mostly unsupervised nature of our modules.", "labels": [], "entities": []}, {"text": "Unfortunately, our system was the only submission in the partial entailment pilot track of RTE-8, so we have no comparisons with other systems.", "labels": [], "entities": [{"text": "RTE-8", "start_pos": 91, "end_pos": 96, "type": "DATASET", "confidence": 0.866375207901001}]}, {"text": "However, the absolute improvement from the exact-match baseline to the more sophisticated Majority is in the same ballpark as that of the best systems in previous recognizing textual entailment challenges.", "labels": [], "entities": []}, {"text": "For instance, in the previous recognizing textual entailment challenge), the best system yielded an F 1 score of 0.48, while the baseline scored 0.374.", "labels": [], "entities": [{"text": "recognizing textual entailment challenge", "start_pos": 30, "end_pos": 70, "type": "TASK", "confidence": 0.7766509354114532}, {"text": "F 1 score", "start_pos": 100, "end_pos": 109, "type": "METRIC", "confidence": 0.9915752212206522}]}, {"text": "We can therefore conclude that existing approaches for recognizing textual entailment can indeed be adapted for recognizing partial entailment.", "labels": [], "entities": [{"text": "recognizing textual entailment", "start_pos": 55, "end_pos": 85, "type": "TASK", "confidence": 0.7938531438509623}, {"text": "recognizing partial entailment", "start_pos": 112, "end_pos": 142, "type": "TASK", "confidence": 0.8199693361918131}]}], "tableCaptions": [{"text": " Table 1: Micro-averaged F 1 on the faceted Sci- EntsBank test set.", "labels": [], "entities": [{"text": "F 1", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.8757702708244324}, {"text": "Sci- EntsBank test set", "start_pos": 44, "end_pos": 66, "type": "DATASET", "confidence": 0.6459433674812317}]}, {"text": " Table 2: Micro-averaged F 1 on the 2-way com- plete entailment SciEntsBank test set.", "labels": [], "entities": [{"text": "F 1", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.8877775967121124}, {"text": "com- plete entailment SciEntsBank test set", "start_pos": 42, "end_pos": 84, "type": "DATASET", "confidence": 0.6114896748747144}]}]}