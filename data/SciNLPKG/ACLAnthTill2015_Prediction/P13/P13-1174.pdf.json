{"title": [{"text": "Connotation Lexicon: A Dash of Sentiment Beneath the Surface Meaning", "labels": [], "entities": []}], "abstractContent": [{"text": "Understanding the connotation of words plays an important role in interpreting subtle shades of sentiment beyond denotative or surface meaning of text, as seemingly objective statements often allude nuanced sentiment of the writer, and even purposefully conjure emotion from the readers' minds.", "labels": [], "entities": [{"text": "interpreting subtle shades of sentiment beyond denotative or surface meaning of text", "start_pos": 66, "end_pos": 150, "type": "TASK", "confidence": 0.654545471072197}]}, {"text": "The focus of this paper is drawing nuanced, connotative sentiments from even those words that are objective on the surface, such as \"intelligence\", \"human\", and \"cheesecake\".", "labels": [], "entities": []}, {"text": "We propose induction algorithms encoding a diverse set of linguistic insights (semantic prosody, distri-butional similarity, semantic parallelism of coordination) and prior knowledge drawn from lexical resources, resulting in the first broad-coverage connotation lexicon.", "labels": [], "entities": []}], "introductionContent": [{"text": "There has been a substantial body of research in sentiment analysis over the last decade, where a considerable amount of work has focused on recognizing sentiment that is generally explicit and pronounced rather than implied and subdued.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.9539499878883362}]}, {"text": "However in many real-world texts, even seemingly objective statements can be opinion-laden in that they often allude nuanced sentiment of the writer (, or purposefully conjure emotion from the readers' minds (.", "labels": [], "entities": []}, {"text": "Although some researchers have explored formal and statistical treatments of those implicit and implied sentiments (e.g.,,,), automatic analysis of them largely remains as a big challenge.", "labels": [], "entities": [{"text": "automatic analysis of them", "start_pos": 126, "end_pos": 152, "type": "TASK", "confidence": 0.7627194747328758}]}, {"text": "In this paper, we concentrate on understanding the connotative sentiments of words, as they play an important role in interpreting subtle shades of sentiment beyond denotative or surface meaning of text.", "labels": [], "entities": [{"text": "interpreting subtle shades of sentiment beyond denotative or surface meaning of text", "start_pos": 118, "end_pos": 202, "type": "TASK", "confidence": 0.7176731874545416}]}, {"text": "For instance, consider the following: Geothermal replaces oil-heating; it helps reducing greenhouse emissions.", "labels": [], "entities": []}, {"text": "1 Although this sentence could be considered as a factual statement from the general standpoint, the subtle effect of this sentence may not be entirely objective: this sentence is likely to have an influence on readers' minds in regard to their opinion toward \"geothermal\".", "labels": [], "entities": []}, {"text": "In order to sense the subtle overtone of sentiments, one needs to know that the word \"emissions\" has generally negative connotation, which geothermal reduces.", "labels": [], "entities": []}, {"text": "In fact, depending on the pragmatic contexts, it could be precisely the intention of the author to transfer his opinion into the readers' minds.", "labels": [], "entities": []}, {"text": "The main contribution of this paper is a broadcoverage connotation lexicon that determines the connotative polarity of even those words with ever so subtle connotation beneath their surface meaning, such as \"Literature\", \"Mediterranean\", and \"wine\".", "labels": [], "entities": []}, {"text": "Although there has been a number of previous work that constructed sentiment lexicons (e.g.,,,,), which seem to be increasingly and inevitably expanding over words with (strongly) connotative sentiments rather than explicit sentiments alone (e.g., \"gun\"), little prior work has directly tackled this problem of learning connotation, and much of the subtle connotation of many seemingly objective words is yet to be determined.", "labels": [], "entities": []}, {"text": "A central premise to our approach is that it is collocational statistics of words that affect and shape the polarity of connotation.", "labels": [], "entities": []}, {"text": "Indeed, the etymology of \"connotation\" is from the Latin \"com-\" (\"together or with\") and \"notare\" (\"to mark\").", "labels": [], "entities": []}, {"text": "It is important to clarify, however, that we do not simply assume that words that collocate share the same polarity of connotation.", "labels": [], "entities": []}, {"text": "Although such an assumption played a key role in previous work for the analogous task of learning sentiment lexicon (, we expect that the same assumption would be less reliable in drawing subtle connotative sentiments of words.", "labels": [], "entities": []}, {"text": "As one example, the predicate \"cure\", which has a positive connotation typically takes arguments with negative connotation, e.g., \"disease\", when used as the \"relieve\" sense.", "labels": [], "entities": [{"text": "predicate \"cure\"", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.7628721594810486}]}, {"text": "Therefore, in order to attain abroad coverage lexicon while maintaining good precision, we guide the induction algorithm with multiple, carefully selected linguistic insights: distributional similarity, semantic parallelism of coordination, selectional preference, and semantic prosody (e.g.,,,,)), and also exploit existing lexical resources as an additional inductive bias.", "labels": [], "entities": [{"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.998625636100769}]}, {"text": "We cast the connotation lexicon induction task as a collective inference problem, and consider approaches based on three distinct types of algorithmic framework that have been shown successful for conventional sentiment lexicon induction: Random walk based on HITS/PageRank (e.g., Label/Graph propagation (e.g., Zhu and Ghahra-(2011) but with practical limitations.", "labels": [], "entities": [{"text": "connotation lexicon induction task", "start_pos": 12, "end_pos": 46, "type": "TASK", "confidence": 0.8058570772409439}, {"text": "sentiment lexicon induction", "start_pos": 210, "end_pos": 237, "type": "TASK", "confidence": 0.6659939090410868}, {"text": "Label/Graph propagation", "start_pos": 281, "end_pos": 304, "type": "TASK", "confidence": 0.6064720824360847}]}, {"text": "See \u00a73 for detailed discussion.", "labels": [], "entities": []}, {"text": "Note that when \"cure\" is used as the \"preserve\" sense, it expects objects with non-negative connotation.", "labels": [], "entities": []}, {"text": "Hence wordsense-disambiguation (WSD) presents a challenge, though not unexpectedly.", "labels": [], "entities": [{"text": "wordsense-disambiguation (WSD)", "start_pos": 6, "end_pos": 36, "type": "TASK", "confidence": 0.5699360966682434}]}, {"text": "In this work, we assume the general connotation of each word over statistically prevailing senses, leaving a more cautious handling of WSD as future work.", "labels": [], "entities": [{"text": "WSD", "start_pos": 135, "end_pos": 138, "type": "TASK", "confidence": 0.893588662147522}]}], "datasetContent": [{"text": "In this section, we present comprehensive intrinsic \u00a75.1 and extrinsic \u00a75.2 evaluations comparing three representative lexicons from \u00a72 & \u00a74: C-LP, OVERLAY, PRED-ARG (CP), and two popular sentiment lexicons: SentiWordNet (Baccianella et al., 2010) and GI+MPQA.", "labels": [], "entities": [{"text": "GI+MPQA", "start_pos": 252, "end_pos": 259, "type": "DATASET", "confidence": 0.6460472941398621}]}, {"text": "14 Note that C-LP is the largest among all connotation lexicons, including \u223c70,000 polar words.", "labels": [], "entities": []}, {"text": "We evaluate 4000 words 16 using Amazon Mechanical Turk (AMT).", "labels": [], "entities": [{"text": "Amazon Mechanical Turk (AMT)", "start_pos": 32, "end_pos": 60, "type": "DATASET", "confidence": 0.8863832056522369}]}, {"text": "Because we expect that judging a connotation can be dependent on one's cultural background, personality and value systems, we gather judgements from 5 people for each word, from which we hope to draw a more general judgement of connotative polarity.", "labels": [], "entities": []}, {"text": "About 300 unique Turkers participated the evaluation tasks.", "labels": [], "entities": []}, {"text": "We gather gold standard only for those words for which more than half of the judges agreed on the same polarity.", "labels": [], "entities": []}, {"text": "Otherwise we treat them as ambiguous cases.", "labels": [], "entities": []}, {"text": "17 shows apart of the AMT task, where Turkers are presented with questions that help judges to determine the subtle connotative polarity of each word, then asked to rate the degree of connotation on a scale from -5 (most negative) and 5 (most positive).", "labels": [], "entities": [{"text": "AMT task", "start_pos": 22, "end_pos": 30, "type": "TASK", "confidence": 0.8414281606674194}]}, {"text": "To draw GI+MPQA is the union of General Inquirer and MPQA.", "labels": [], "entities": [{"text": "General Inquirer", "start_pos": 32, "end_pos": 48, "type": "DATASET", "confidence": 0.9282001256942749}, {"text": "MPQA", "start_pos": 53, "end_pos": 57, "type": "DATASET", "confidence": 0.8041447997093201}]}, {"text": "The GI, we use words in the \"Positiv\" & \"Negativ\" set.", "labels": [], "entities": []}, {"text": "For SentiWordNet, to retrieve the polarity of a given word, we sum over the polarity scores overall senses, where positive (negative) values correspond to positive (negative) polarity.", "labels": [], "entities": []}, {"text": "15 \u223c13k adj, \u223c6k verbs, \u223c28k nouns, \u223c22k proper nouns.", "labels": [], "entities": []}, {"text": "We choose words that are not already in GI+MPQA and obtain most frequent 10,000 words based on the unigram frequency in Google-Ngram, then randomly select 4000 words.", "labels": [], "entities": [{"text": "GI+MPQA", "start_pos": 40, "end_pos": 47, "type": "DATASET", "confidence": 0.6742399334907532}]}, {"text": "We allow Turkers to mark words that can be used with both positive and negative connotation, which results in about 7% of words that are excluded from the gold standard set.", "labels": [], "entities": [{"text": "gold standard set", "start_pos": 155, "end_pos": 172, "type": "DATASET", "confidence": 0.8293219606081644}]}, {"text": "the gold standard, we consider two different voting schemes: \u2022 \u2126 V ote : The judgement of each Turker is mapped to neutral for \u22121 \u2264 score \u2264 1, positive for score \u2265 2, negative for score \u2264 2, then we take the majority vote.", "labels": [], "entities": [{"text": "Turker", "start_pos": 95, "end_pos": 101, "type": "DATASET", "confidence": 0.7494314312934875}]}, {"text": "\u2022 \u2126 Score : Let \u03c3(i) be the sum (weighted vote) of the scores given by 5 judges for word i.", "labels": [], "entities": []}, {"text": "Then we determine the polarity label l(i) of i as: The resulting distribution of judgements is shown in & 6.", "labels": [], "entities": []}, {"text": "Interestingly, we observe that among the relatively frequently used English words, there are overwhelmingly more positively connotative words than negative ones.", "labels": [], "entities": []}, {"text": "In, we show the percentage of words with the same label over the mutual words by the two lexicon.", "labels": [], "entities": []}, {"text": "The highest agreement is 77% by C-LP and the gold standard by AMT V ote . How good is this?", "labels": [], "entities": [{"text": "agreement", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9834293127059937}, {"text": "C-LP", "start_pos": 32, "end_pos": 36, "type": "DATASET", "confidence": 0.8761157989501953}, {"text": "AMT V ote", "start_pos": 62, "end_pos": 71, "type": "DATASET", "confidence": 0.8503702481587728}]}, {"text": "It depends on what is the natural degree of agreement oversubtle connotation among people.", "labels": [], "entities": []}, {"text": "Therefore, we also report the degree of agreement among human judges in, where we compute the agreement of one Turker with respect to the gold standard drawn from the rest of the Turkers, and take the average across overall five Turkers . Interestingly, the performance of In order to draw the gold standard from the 4 remaining Turkers, we consider adjusted versions of \u2126 V ote and \u2126 Score schemes described above.", "labels": [], "entities": []}, {"text": "Turkers is not as good as that of C-LP lexicon.", "labels": [], "entities": [{"text": "Turkers", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9733736515045166}]}, {"text": "We conjecture that this could be due to generally varying perception of different people on the connotative polarity, 19 while the corpus-driven induction algorithms focus on the general connotative polarity corresponding to the most prevalent senses of words in the corpus.", "labels": [], "entities": []}, {"text": "We conduct lexicon-based binary sentiment classification on the following two corpora.", "labels": [], "entities": [{"text": "lexicon-based binary sentiment classification", "start_pos": 11, "end_pos": 56, "type": "TASK", "confidence": 0.7487581819295883}]}, {"text": "SemEval From the SemEval task, we obtain a set of news headlines with annotated scores (ranging from -100 to 87).", "labels": [], "entities": []}, {"text": "The positive/negative scores indicate the degree of positive/negative polarity orientation.", "labels": [], "entities": []}, {"text": "We construct several sets of the positive and negative texts by setting thresholds on the scores as shown in.", "labels": [], "entities": []}, {"text": "\" n\" indicates that the positive set consists of the texts with scores \u2265 n and the negative set consists of the texts with scores \u2264 \u2212n.", "labels": [], "entities": []}, {"text": "Emoticon tweets The sentiment Twitter data consists of tweets containing either a smiley emoticon (positive sentiment) or a frowny emoticon (negative sentiment).", "labels": [], "entities": []}, {"text": "We filter out the tweets with question marks or more than 30 words, and keep the ones with at least two words in the union of all polar words in the five lexicons in, and then randomly select 10000 per class.", "labels": [], "entities": []}, {"text": "We denote the short text (e.g., content of tweets or headline texts from SemEval) by t. w represents the   tive/negative words of the lexicon.", "labels": [], "entities": []}, {"text": "We define the weight of was s(w).", "labels": [], "entities": []}, {"text": "If w is adjective, s(w) = 2; otherwise s(w) = 1.", "labels": [], "entities": []}, {"text": "Then the polarity of each text is determined as follows: As shown in, C-LP generally performs better than the other lexicons on both corpora.", "labels": [], "entities": []}, {"text": "Considering that only very simple classification strategy is applied, the result by the connotation lexicon is quite promising.", "labels": [], "entities": []}, {"text": "Finally, highlights interesting examples of proper nouns with connotative polarity, e.g., \"Mandela\", \"Google\", \"Hawaii\" with positive connotation, and \"Monsanto\", \"Halliburton\", \"Enron\" with negative connotation, suggesting that our algorithms could potentially serve as a proxy to track the general connotation of real world entities.", "labels": [], "entities": []}, {"text": "shows example common nouns with connotative polarity.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Evaluation of Induction Algorithms ( \u00a72) with respect to Sentiment Lexicons (precision%).", "labels": [], "entities": [{"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9989972710609436}]}, {"text": " Table 4: ILP/LP Comparison on MQPA (%).", "labels": [], "entities": [{"text": "MQPA", "start_pos": 31, "end_pos": 35, "type": "DATASET", "confidence": 0.7895169258117676}]}, {"text": " Table 5: Distribution of Answers from AMT.", "labels": [], "entities": [{"text": "Distribution of Answers from AMT", "start_pos": 10, "end_pos": 42, "type": "TASK", "confidence": 0.7211351931095124}]}, {"text": " Table 6: Distribution of Connotative Polarity from  AMT.", "labels": [], "entities": [{"text": "AMT", "start_pos": 53, "end_pos": 56, "type": "DATASET", "confidence": 0.7779160737991333}]}, {"text": " Table 7: Agreement (Accuracy) against AMT- driven Gold Standard.", "labels": [], "entities": [{"text": "Agreement", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9801762104034424}, {"text": "Accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9219198822975159}, {"text": "AMT- driven Gold Standard", "start_pos": 39, "end_pos": 64, "type": "DATASET", "confidence": 0.8500535011291503}]}, {"text": " Table 8: Accuracy on Sentiment Classification  (%).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9965441823005676}, {"text": "Sentiment Classification", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.938320130109787}]}]}