{"title": [{"text": "A Tightly-coupled Unsupervised Clustering and Bilingual Alignment Model for Transliteration", "labels": [], "entities": [{"text": "Bilingual Alignment", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.7012558430433273}, {"text": "Transliteration", "start_pos": 76, "end_pos": 91, "type": "TASK", "confidence": 0.7971755862236023}]}], "abstractContent": [{"text": "Machine Transliteration is an essential task for many NLP applications.", "labels": [], "entities": [{"text": "Machine Transliteration", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8006800413131714}]}, {"text": "However , names and loan words typically originate from various languages, obey different transliteration rules, and therefore may benefit from being modeled independently.", "labels": [], "entities": []}, {"text": "Recently, transliteration models based on Bayesian learning have overcome issues with over-fitting allowing for many-to-many alignment in the training of transliteration models.", "labels": [], "entities": []}, {"text": "We propose a novel coupled Dirichlet process mixture model (cDPMM) that simultaneously clusters and bilingually aligns transliteration data within a single unified model.", "labels": [], "entities": []}, {"text": "The unified model decomposes into two classes of non-parametric Bayesian component models: a Dirichlet process mixture model for clustering, and a set of multino-mial Dirichlet process models that perform bilingual alignment independently for each cluster.", "labels": [], "entities": []}, {"text": "The experimental results show that our method considerably outper-forms conventional alignment models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Machine transliteration methods can be categorized into phonetic-based models (), spelling-based models (, and hybrid models which utilize both phonetic and spelling information ().", "labels": [], "entities": []}, {"text": "Among them, statistical spelling-based models which directly align characters in the training corpus have become popular because they are language-independent, do not require phonetic knowledge, and are capable of achieving stateof-the-art performance (.", "labels": [], "entities": []}, {"text": "A major problem with real-word transliteration corpora is that they are usually not clean, may contain name pairs with various linguistic origins and this can hinder the performance of spelling-based models because names from different origins obey different pronunciation rules, for example: \"Kim Jong-il/\u91d1\u6b63\u6069\" (Korea), \"Kana Gaski/\u91d1\u5d0e\" (Japan), \"Haw King/\u970d\u91d1\" (England), \"Jin yong/\u91d1\u5eb8' (China).", "labels": [], "entities": []}, {"text": "The same Chinese character \"\u91d1\" should be aligned to different romanized character sequences: \"Kim\", \"Kana\", \"King\", \"Jin\".", "labels": [], "entities": []}, {"text": "To address this issue, many name classification methods have been proposed, such as the supervised language model-based approach of (, and the unsupervised approach of () that used a bottom-up clustering algorithm.", "labels": [], "entities": [{"text": "name classification", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.8198978006839752}]}, {"text": "( proposed a supervised transliteration model which classifies names based on their origins and genders using a language model; it switches between transliteration models based on the input.", "labels": [], "entities": []}, {"text": "() tackled the issue by using an unsupervised method based on the EM algorithm to perform a soft classification.", "labels": [], "entities": []}, {"text": "Recently, non-parametric Bayesian models () have attracted much attention in the transliteration field.", "labels": [], "entities": []}, {"text": "In comparison to many of the previous alignment models (), the nonparametric Bayesian models allow unconstrained monotonic many-to-many alignment and are able to overcome the inherent over-fitting problem.", "labels": [], "entities": []}, {"text": "Until now most of the previous work () is either affected by the multi-origins factor, or has issues with overfitting.) took these two factors into consideration, but their approach still operates within an EM framework and model order selection by hand is necessary prior to training.", "labels": [], "entities": []}, {"text": "We propose a simple, elegant, fullyunsupervised solution based on a single generative model able to both cluster and align simultaneously.", "labels": [], "entities": []}, {"text": "The coupled Dirichlet Process Mixture Model (cDPMM) integrates a Dirichlet process mixture model (DPMM) and a Bayesian Bilingual Alignment Model (BBAM) ().", "labels": [], "entities": []}, {"text": "The two component models work synergistically to support one another: the clustering model sorts the data into classes so that self-consistent alignment models can be built using data of the same type, and at the same time the alignment probabilities from the alignment models drive the clustering process.", "labels": [], "entities": []}, {"text": "In summary, the key advantages of our model are as follows: \u2022 it is based on a single, unified generative model; \u2022 it is fully unsupervised; \u2022 it is an infinite mixture model, and does not require model order selection -it is effectively capable of discovering an appropriate number of clusters from the data; \u2022 it is able to handle data from multiple origins; \u2022 it can perform many-to-many alignment without over-fitting.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our proposed model obtained the highest performance on all three datasets for all evaluation metrics by a considerable margin.", "labels": [], "entities": []}, {"text": "Surprisingly, for dataset EO although there is no multi-origin factor, we still observed a respectable improvement in every metric.", "labels": [], "entities": []}, {"text": "This shows that although names may have monolingual origin, there are hidden factors which can allow our model to succeed, possibly related to gender or convention.", "labels": [], "entities": []}, {"text": "Other models based on supervised classification or clustering with fixed classes may fail to capture these characteristics.", "labels": [], "entities": []}, {"text": "To guarantee the reliability of the comparative results, we performed significance testing based on paired bootstrap resampling (.", "labels": [], "entities": [{"text": "reliability", "start_pos": 17, "end_pos": 28, "type": "METRIC", "confidence": 0.9624727368354797}]}, {"text": "We found all differences to be significant (p < 0.05).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics of the experimental corpora.", "labels": [], "entities": []}, {"text": " Table 4: Comparison of different methods using  the Moses phrase-based decoder.", "labels": [], "entities": []}, {"text": " Table 5: Comparison of different methods using  the DirecTL decoder.", "labels": [], "entities": [{"text": "DirecTL decoder", "start_pos": 53, "end_pos": 68, "type": "DATASET", "confidence": 0.9657532274723053}]}]}