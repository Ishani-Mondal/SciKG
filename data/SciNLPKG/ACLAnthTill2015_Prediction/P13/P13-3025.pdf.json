{"title": [{"text": "Deepfix: Statistical Post-editing of Statistical Machine Translation Using Deep Syntactic Analysis", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 37, "end_pos": 68, "type": "TASK", "confidence": 0.7216514150301615}]}], "abstractContent": [{"text": "Deepfix is a statistical post-editing system for improving the quality of statistical machine translation outputs.", "labels": [], "entities": [{"text": "Deepfix", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9187791347503662}, {"text": "statistical machine translation outputs", "start_pos": 74, "end_pos": 113, "type": "TASK", "confidence": 0.6857395023107529}]}, {"text": "It attempts to correct errors in verb-noun va-lency using deep syntactic analysis and a simple probabilistic model of valency.", "labels": [], "entities": []}, {"text": "On the English-to-Czech translation pair, we show that statistical post-editing of statistical machine translation leads to an improvement of the translation quality when helped by deep linguistic knowledge.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 83, "end_pos": 114, "type": "TASK", "confidence": 0.630113035440445}]}], "introductionContent": [{"text": "Statistical machine translation (SMT) is the current state-of-the-art approach to machine translation -see e.g..", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8504372835159302}, {"text": "machine translation", "start_pos": 82, "end_pos": 101, "type": "TASK", "confidence": 0.7814642488956451}]}, {"text": "However, its outputs are still typically significantly worse than human translations, containing various types of errors, both in lexical choices and in grammar.", "labels": [], "entities": []}, {"text": "As shown by many researchers, e.g. Bojar (2011a), incorporating deep linguistic knowledge directly into a translation system is often hard to do, and seldom leads to an improvement of translation output quality.", "labels": [], "entities": []}, {"text": "It has been shown that it is often easier to correct the machine translation outputs in a second-stage post-processing, which is usually referred to as automatic post-editing.", "labels": [], "entities": []}, {"text": "Several types of errors can be fixed by employing rule-based post-editing (), which can be seen as being orthogonal to the statistical methods employed in SMT and thus can capture different linguistic phenomena easily.", "labels": [], "entities": [{"text": "SMT", "start_pos": 155, "end_pos": 158, "type": "TASK", "confidence": 0.9900856018066406}]}, {"text": "But there are still other errors that cannot be corrected with hand-written rules, as there exist many linguistic phenomena that can never be fully described manually -they need to be handled statistically by automatically analyzing large-scale text corpora.", "labels": [], "entities": []}, {"text": "However, to the best of our knowledge,", "labels": [], "entities": []}], "datasetContent": [{"text": "We conclude that this method does not improve English-Czech translation, possibly because our training data is too large for this method to bring any benefit.", "labels": [], "entities": [{"text": "English-Czech translation", "start_pos": 46, "end_pos": 71, "type": "TASK", "confidence": 0.5363001525402069}]}, {"text": "We therefore proceed with a more complex approach which relies on deep linguistic knowledge.", "labels": [], "entities": []}, {"text": "We evaluated our method on three datasets: WMT10 (2489 parallel sentences), WMT11 (3003 parallel sentences), and WMT12 (3003 parallel sentences) by.", "labels": [], "entities": [{"text": "WMT10", "start_pos": 43, "end_pos": 48, "type": "DATASET", "confidence": 0.9557409286499023}, {"text": "WMT11", "start_pos": 76, "end_pos": 81, "type": "DATASET", "confidence": 0.9428478479385376}, {"text": "WMT12", "start_pos": 113, "end_pos": 118, "type": "DATASET", "confidence": 0.948610782623291}]}, {"text": "For evaluation, we used outputs of a state-of-the-art SMT system, Moses (Koehn et al., http://featurama.sourceforge.net/ 2007), tuned for English-to-Czech translation).", "labels": [], "entities": [{"text": "SMT", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9882389307022095}]}, {"text": "We used the WMT10 dataset and its Moses translation as our development data to tune the thresholds.", "labels": [], "entities": [{"text": "WMT10 dataset", "start_pos": 12, "end_pos": 25, "type": "DATASET", "confidence": 0.9773459732532501}]}, {"text": "In, we report the achieved BLEU scores (), NIST scores, and PER).", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 27, "end_pos": 38, "type": "METRIC", "confidence": 0.9790446162223816}, {"text": "NIST scores", "start_pos": 43, "end_pos": 54, "type": "METRIC", "confidence": 0.8543679118156433}, {"text": "PER", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.9991838335990906}]}, {"text": "The improvements in automatic scores are low but consistently positive, which suggests that Deepfix does improve the translation quality.", "labels": [], "entities": []}, {"text": "However, the changes performed by Deepfix are so small that automatic evaluation is unable to reliably assess whether they are positive or negative -it can only betaken as an indication.", "labels": [], "entities": [{"text": "Deepfix", "start_pos": 34, "end_pos": 41, "type": "DATASET", "confidence": 0.8824973702430725}]}, {"text": "To reliably assess the performance of Deepfix, we performed manual evaluation on the WMT12 dataset translated by the Moses system.", "labels": [], "entities": [{"text": "Deepfix", "start_pos": 38, "end_pos": 45, "type": "DATASET", "confidence": 0.904032289981842}, {"text": "WMT12 dataset translated by the Moses system", "start_pos": 85, "end_pos": 129, "type": "DATASET", "confidence": 0.8515308839934213}]}, {"text": "The dataset was evenly split into 4 parts and each of the parts was evaluated by one of two annotators (denoted \"A\" and \"B\").", "labels": [], "entities": []}, {"text": "For each sentence that was modified by Deepfix, the annotator decided whether the Deepfix correction had a positive (\"improvement\") or negative (\"degradation\") effect on the translation quality, or concluded that this cannot be decided (\"indefinite\") -either because both of the sentences are correct variants, or because both are incorrect.", "labels": [], "entities": []}, {"text": "The results in prove that the overall effect of Deepfix is positive: it modifies about 20% of the sentence translations (569 out of 3003 sentences), improving over a half of them while leading to a degradation in only a quarter of the cases.", "labels": [], "entities": []}, {"text": "We measured the inter-annotator agreement on 100 sentences which were annotated by both annotators.", "labels": [], "entities": []}, {"text": "For 60 sentence pairs, both of the annotators were able to select which sentence is better, i.e. none of the annotators used the \"indefinite\" marker.", "labels": [], "entities": []}, {"text": "The inter-annotator agreement on these 60 sentence pairs was 97%.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Results of SPE approach of B\u00e9chara et al.  (2011) evaluated on English-Czech SMT.", "labels": [], "entities": [{"text": "SPE", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9512630105018616}, {"text": "SMT", "start_pos": 87, "end_pos": 90, "type": "TASK", "confidence": 0.7851977944374084}]}, {"text": " Table 5: Automatic evaluation of Deepfix on outputs of the Moses system on WMT10, WMT11 and  WMT12 datasets. *Please note that WMT10 was used as the development dataset.", "labels": [], "entities": [{"text": "WMT10", "start_pos": 76, "end_pos": 81, "type": "DATASET", "confidence": 0.9822409749031067}, {"text": "WMT11", "start_pos": 83, "end_pos": 88, "type": "DATASET", "confidence": 0.8489371538162231}, {"text": "WMT12 datasets", "start_pos": 94, "end_pos": 108, "type": "DATASET", "confidence": 0.9018669426441193}, {"text": "WMT10", "start_pos": 128, "end_pos": 133, "type": "DATASET", "confidence": 0.9637494087219238}]}, {"text": " Table 6: Manual evaluation of Deepfix on outputs of Moses Translate system on WMT12 dataset.", "labels": [], "entities": [{"text": "WMT12 dataset", "start_pos": 79, "end_pos": 92, "type": "DATASET", "confidence": 0.9858144521713257}]}]}