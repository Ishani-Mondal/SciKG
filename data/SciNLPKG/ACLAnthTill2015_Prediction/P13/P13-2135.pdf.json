{"title": [{"text": "Exploiting Qualitative Information from Automatic Word Alignment for Cross-lingual NLP Tasks", "labels": [], "entities": [{"text": "Exploiting Qualitative Information from Automatic Word Alignment", "start_pos": 0, "end_pos": 64, "type": "TASK", "confidence": 0.640000466789518}]}], "abstractContent": [{"text": "The use of automatic word alignment to capture sentence-level semantic relations is common to a number of cross-lingual NLP applications.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 21, "end_pos": 35, "type": "TASK", "confidence": 0.7425128221511841}]}, {"text": "Despite its proved usefulness, however, word alignment information is typically considered from a quantitative point of view (e.g. the number of alignments), disregarding qualitative aspects (the importance of aligned terms).", "labels": [], "entities": [{"text": "word alignment information", "start_pos": 40, "end_pos": 66, "type": "TASK", "confidence": 0.8248778382937113}]}, {"text": "In this paper we demonstrate that integrating qualitative information can bring significant performance improvements with negligible impact on system complexity.", "labels": [], "entities": []}, {"text": "Focusing on the cross-lingual textual en-tailment task, we contribute with a novel method that: i) significantly outperforms the state of the art, and ii) is portable, with limited loss in performance, to language pairs where training data are not available.", "labels": [], "entities": []}], "introductionContent": [{"text": "Meaning representation, comparison and projection across sentences are major challenges fora variety of cross-lingual applications.", "labels": [], "entities": [{"text": "Meaning representation", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8920241594314575}, {"text": "comparison", "start_pos": 24, "end_pos": 34, "type": "TASK", "confidence": 0.9557324647903442}]}, {"text": "So far, despite the relevance of the problem, research on multilingual applications has either circumvented the issue, or proposed partial solutions.", "labels": [], "entities": []}, {"text": "When possible, the typical approach builds on the reduction to a monolingual task, burdening the process with dependencies from machine translation (MT) components.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 128, "end_pos": 152, "type": "TASK", "confidence": 0.8035396099090576}]}, {"text": "For instance, in crosslingual question answering and cross-lingual textual entailment (CLTE), intermediate MT steps are respectively performed to ease answer retrieval/presentation) and semantic inference (.", "labels": [], "entities": [{"text": "crosslingual question answering", "start_pos": 17, "end_pos": 48, "type": "TASK", "confidence": 0.621242473522822}, {"text": "cross-lingual textual entailment (CLTE)", "start_pos": 53, "end_pos": 92, "type": "TASK", "confidence": 0.7587495396534601}, {"text": "MT", "start_pos": 107, "end_pos": 109, "type": "TASK", "confidence": 0.9617903232574463}, {"text": "answer retrieval/presentation", "start_pos": 151, "end_pos": 180, "type": "TASK", "confidence": 0.7642238512635231}]}, {"text": "Direct solutions that avoid such pivoting strategies typically exploit similarity measures that rely on bag-of-words representations.", "labels": [], "entities": []}, {"text": "As an example, most supervised approaches to MT quality estimation () and CLTE include features that consider the amount of equivalent terms that are found in the input sentence pairs.", "labels": [], "entities": [{"text": "MT quality estimation", "start_pos": 45, "end_pos": 66, "type": "TASK", "confidence": 0.9012522498766581}]}, {"text": "Such simplification, however, disregards the fact that semantic equivalence is not only proportional to the number of equivalent terms, but also to their importance.", "labels": [], "entities": []}, {"text": "In other words, instead of checking what of a given sentence can be found in the other, current approaches limit the analysis to the amount of lexical elements they share, under the rough assumption that the more the better.", "labels": [], "entities": []}, {"text": "In this paper we argue that: (1) Considering qualitative aspects of word alignments to identify sentence-level semantic relations can bring significant performance improvements in cross-lingual NLP tasks.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 68, "end_pos": 83, "type": "TASK", "confidence": 0.7174866646528244}]}, {"text": "(2) Shallow linguistic processing techniques (often a constraint in real cross-lingual scenarios due to limited resources availability) can be leveraged to setup portable solutions that still outperform current bag-of-words methods.", "labels": [], "entities": []}, {"text": "To support our claims we experiment with the CLTE task, which allows us to perform exhaustive comparative experiments due to the availability of comparable benchmarks for different language pairs.", "labels": [], "entities": []}, {"text": "In the remainder of the paper, we: (1) Prove the effectiveness of our method over datasets for four language combinations; (2) Assess the portability of our models across languages in different testing conditions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments cover two different scenarios.", "labels": [], "entities": []}, {"text": "First, the typical one, in which the CLTE model is trained on labeled data for the same pair of languages L 1 -L 2 of the test set.", "labels": [], "entities": []}, {"text": "Then, simulating the less favorable situation in which labeled training data for L 1 -L 2 are missing, we investigate the possibility to use existing CLTE models trained on labeled data fora different language pair L 3 -L 4 . The SemEval 2012 CLTE datasets used in our experiments are available for four language pairs: Es-En, De-En, Fr-En, and It-En.", "labels": [], "entities": [{"text": "SemEval 2012 CLTE datasets", "start_pos": 230, "end_pos": 256, "type": "DATASET", "confidence": 0.6184885948896408}]}, {"text": "Each dataset was created with the crowdsourcing-based method described in , and consists of 1000 T 1 -T 2 pairs (500 for training, 500 for test).", "labels": [], "entities": []}, {"text": "To train the word alignment models we used the Europarl parallel corpus ( To build the word alignment models we used the MGIZA++ package (.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.7467193901538849}, {"text": "Europarl parallel corpus", "start_pos": 47, "end_pos": 71, "type": "DATASET", "confidence": 0.9423093994458517}, {"text": "word alignment", "start_pos": 87, "end_pos": 101, "type": "TASK", "confidence": 0.6758873909711838}, {"text": "MGIZA++ package", "start_pos": 121, "end_pos": 136, "type": "DATASET", "confidence": 0.8969760338465372}]}, {"text": "Experiments have been carried outwith the hidden Markov model (HMM) () and IBM models 3 and 4 (.", "labels": [], "entities": []}, {"text": "We also explored three symmetrization techniques ( ): union, intersection, and grow-diagfinal-and.", "labels": [], "entities": []}, {"text": "A greedy feature selection process on training data, with different combinations of word alignment models and symmetrization methods, indicated HMM/intersection as the best performing combination.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 84, "end_pos": 98, "type": "TASK", "confidence": 0.7007114887237549}]}, {"text": "For this reason, all our experiments use this setting.", "labels": [], "entities": []}, {"text": "The SVM implementation of Weka () was used to build the CLTE model.", "labels": [], "entities": []}, {"text": "Two binary classifiers were trained to separately check T 1 \u2192 T 2 and T 1 \u2190 T 2 , merging their output to obtain the 4-class judgments (e.g. yes/yes=bidirectional, yes/no=forward).", "labels": [], "entities": []}, {"text": "shows the accuracy obtained by the different feature groups.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9994699358940125}]}, {"text": "For the sake of comparison, state-of-the-art results achieved for each language combination at SemEval 2012 are also reported.", "labels": [], "entities": [{"text": "SemEval 2012", "start_pos": 95, "end_pos": 107, "type": "DATASET", "confidence": 0.6812502443790436}]}, {"text": "As regards Es-En (63.2% accuracy) and De-En (55.8%), the top scores were obtained by the system described in, where a combination of binary classifiers for each entailment direction is trained with a mix-ture of monolingual (i.e. with the input sentences translated in the same language using Google Translate 7 ) and cross-lingual features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9987888932228088}]}, {"text": "Although such system exploits word-alignment information to some extent, this is only done at quantitative level (e.g. number of unaligned words, percentage of aligned words, length of the longest unaligned subsequence).", "labels": [], "entities": []}, {"text": "As regards It-En, the state of the art (56.6%) is represented by the system described in (, which uses a pure pivoting method (using Google Translate) and adaptive similarity functions based on \"soft\" cardinality for flexible term comparisons.", "labels": [], "entities": []}, {"text": "The two systems obtained the same result on Fr-En (57.0%).", "labels": [], "entities": [{"text": "Fr-En", "start_pos": 44, "end_pos": 49, "type": "DATASET", "confidence": 0.8781168460845947}]}, {"text": "As can be seen in, the combination of all our features outperforms the state of the art for each language pair.", "labels": [], "entities": []}, {"text": "The accuracy improvement ranges from 6.6% for Es-En (from 63.2% to 67.4%) to 14.6% for De-En (from 55.8% to 64%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996131062507629}]}, {"text": "Except for Es-En, that has very competitive stateof-the-art results, the combination of AL with POS or IDF feature groups always outperforms the best systems.", "labels": [], "entities": []}, {"text": "Furthermore, the performance increase with qualitative features (POS and IDF) shows coherent trends across all language pairs.", "labels": [], "entities": [{"text": "IDF", "start_pos": 73, "end_pos": 76, "type": "METRIC", "confidence": 0.9729581475257874}]}, {"text": "It is worth noting that, while we rely on a pure cross-lingual approach, both the state-of-the-art CLTE systems include features from the translation of T 1 into the language of T 2 . For De-En, quantitative features alone achieve lower results compared to the other languages.", "labels": [], "entities": []}, {"text": "This can be motivated by the higher difficulty in aligning De-En pairs (this hypothesis is supported by the fact that the average number of alignments per sentence pair is 18 for De-En, and >22 for the other combinations).", "labels": [], "entities": []}, {"text": "Nevertheless, qualitative features lead to results comparable 7 http://translate.google.com/ with the other language pairs.", "labels": [], "entities": []}, {"text": "The selection of the best performing features for each language pair produces further improvements of varying degrees in Es-En (from 67.4% to 68%), De-En (64% -64.8%) and It-En (63.4% -66.8%), while performance remains stable for Fr-En (63%).", "labels": [], "entities": []}, {"text": "All these configurations include the IDF feature (12) and the proportion of aligned words for each PoS category, proving the effectiveness of qualitative word alignment features.", "labels": [], "entities": [{"text": "IDF", "start_pos": 37, "end_pos": 40, "type": "METRIC", "confidence": 0.9958043694496155}]}, {"text": "The fact that HMM/intersection is the best combination of alignment model and symmetrization method is interesting, since it contradicts the general notion that IBM models 3 and 4 perform better than HMM (.", "labels": [], "entities": []}, {"text": "A possible explanation is that, while word alignment models are usually trained on parallel corpora, the majority of CLTE sentence pairs are not parallel.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.7845432758331299}]}, {"text": "In this setting, where producing reliable alignments is more difficult, IBM models are less effective for at least two reasons.", "labels": [], "entities": []}, {"text": "First, including a word fertility model, IBM 3 and 4 limit (typically to the half of the source sentence length) the number of target words that can be aligned with the null word.", "labels": [], "entities": [{"text": "word fertility", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.7091154456138611}]}, {"text": "Therefore, when such limit is reached, these models tend to force low probability, hence less reliable, word alignments.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 104, "end_pos": 119, "type": "TASK", "confidence": 0.7217246741056442}]}, {"text": "Second, in IBM model 4, the larger distortion limit makes it possible to align distant words.", "labels": [], "entities": []}, {"text": "In the case of non-parallel sentences, this often results in wrong or noisy alignments that affect final results.", "labels": [], "entities": []}, {"text": "For these reasons, CLTE data seem more suitable for the simpler and more conservative HMM model, and a precisionoriented symmetrization method like intersection.", "labels": [], "entities": []}, {"text": "The goal of our second round of experiments is to investigate if, and to what extent, our approach can be considered as language-independent.", "labels": [], "entities": []}, {"text": "Confirming this would allow to reuse models trained fora given language pair in situations where CLTE training data is missing.", "labels": [], "entities": []}, {"text": "This is a rather realistic situation since, while bitexts to train word aligners are easier to find, the availability of labeled CLTE data is far from being guaranteed.", "labels": [], "entities": []}, {"text": "Our experiments have been carried out, over the same SemEval datasets, with two methods that do not use labeled data for the target language combination.", "labels": [], "entities": [{"text": "SemEval datasets", "start_pos": 53, "end_pos": 69, "type": "DATASET", "confidence": 0.7356273382902145}]}, {"text": "The first one (method b in) uses a CLTE model trained fora language pair L 1 -L 2 for which labeled training data are avail-able, and applies this model to a language pair L 3 -L 4 for which only parallel corpora are available.", "labels": [], "entities": []}, {"text": "The second method (c in addresses the same problem, but exploits a combination of CLTE models trained for different language pairs.", "labels": [], "entities": []}, {"text": "For each test set, the models trained for the other three language pairs are used in a voting scheme, in order to check whether they can complement each other to increase final results.", "labels": [], "entities": []}, {"text": "All the experiments have been performed using the best CLTE model for each language pair, comparing results with those presented in Section 3.1.", "labels": [], "entities": []}, {"text": "As shown in, reusing models fora new language pair leads to results that still outperform the state of the art.", "labels": [], "entities": []}, {"text": "Remarkably, when used for other language combinations, the Es-En, It-En, and Fr-En models always lead to results above, or equal to the state of the art.", "labels": [], "entities": []}, {"text": "For similar languages such as Spanish, French, and Italian, the accuracy increase over the state of the art is up to 14.8% (from 56.6% to 65.0%) and 13.4% (from 56.6% to 64.2%) when the Fr-En and Es-En models are respectively used to label the It-En dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9996647834777832}, {"text": "Fr-En", "start_pos": 186, "end_pos": 191, "type": "DATASET", "confidence": 0.8554934859275818}, {"text": "It-En dataset", "start_pos": 244, "end_pos": 257, "type": "DATASET", "confidence": 0.8854441344738007}]}, {"text": "Although not always statistically significant and below the performance obtained in the ideal scenario where CLTE training data are available (full sys.), such improvements suggest that our features can be re-used, at least to some extent, across different language settings.", "labels": [], "entities": []}, {"text": "As expected, the major incompatibilities arise between German and the other languages due to the linguistic differences between this language and the others.", "labels": [], "entities": []}, {"text": "However, it is interesting to note that: i) at least in one case (i.e. when tested on It-En) the De-En model still achieves results above the state of the art, and ii) on the De-En evaluation setting the worst model (Fr-En) still achieves state of the art results.", "labels": [], "entities": []}, {"text": "The results obtained with the voting scheme suggest that our models can complement each other when used on anew language pair.", "labels": [], "entities": []}, {"text": "Although statistically significant only over It-En data, voting results both outperform the state of the art and the results achieved by single models.", "labels": [], "entities": [{"text": "It-En data", "start_pos": 45, "end_pos": 55, "type": "DATASET", "confidence": 0.9213535785675049}]}], "tableCaptions": []}