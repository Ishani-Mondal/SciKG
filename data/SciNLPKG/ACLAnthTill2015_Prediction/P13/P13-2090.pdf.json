{"title": [{"text": "Exploring Sentiment in Social Media: Bootstrapping Subjectivity Clues from Multilingual Twitter Streams", "labels": [], "entities": [{"text": "Exploring Sentiment in Social Media", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8775378346443177}]}], "abstractContent": [{"text": "We study subjective language in social media and create Twitter-specific lexicons via bootstrapping sentiment-bearing terms from multilingual Twitter streams.", "labels": [], "entities": []}, {"text": "Starting with a domain-independent, high-precision sentiment lexicon and a large pool of unlabeled data, we bootstrap Twitter-specific sentiment lexicons, using a small amount of labeled data to guide the process.", "labels": [], "entities": []}, {"text": "Our experiments on English, Spanish and Russian show that the resulting lexicons are effective for sentiment classification for many under-explored languages in social media.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 99, "end_pos": 123, "type": "TASK", "confidence": 0.9742134213447571}]}], "introductionContent": [{"text": "The language that people use to express opinions and sentiment is extremely diverse.", "labels": [], "entities": []}, {"text": "This is true for well-formed data, such as news and reviews, and it is particularly true for data from social media.", "labels": [], "entities": []}, {"text": "Communication in social media is informal, abbreviations and misspellings abound, and the person communicating is often trying to be funny, creative, and entertaining.", "labels": [], "entities": []}, {"text": "Topics change rapidly, and people invent new words and phrases.", "labels": [], "entities": []}, {"text": "The dynamic nature of social media together with the extreme diversity of subjective language has implications for any system with the goal of analyzing sentiment in this domain.", "labels": [], "entities": []}, {"text": "General, domain-independent sentiment lexicons have low coverage.", "labels": [], "entities": []}, {"text": "Even models trained specifically on social media data may degrade somewhat overtime as topics change and new sentiment-bearing terms crop up.", "labels": [], "entities": []}, {"text": "For example, the word \"occupy\" would not have been indicative of sentiment before 2011.", "labels": [], "entities": []}, {"text": "Most of the previous work on sentiment lexicon construction relies on existing natural language processing tools, e.g., syntactic parsers), information extraction (IE) tools ( or rich lexical resources such as WordNet ().", "labels": [], "entities": [{"text": "sentiment lexicon construction", "start_pos": 29, "end_pos": 59, "type": "TASK", "confidence": 0.955628514289856}, {"text": "information extraction (IE)", "start_pos": 140, "end_pos": 167, "type": "TASK", "confidence": 0.8403568148612977}]}, {"text": "However, such tools and lexical resources are not available for many languages spoken in social media.", "labels": [], "entities": []}, {"text": "While English is still the top language in Twitter, it is no longer the majority.", "labels": [], "entities": []}, {"text": "Thus, the applicability of these approaches is limited.", "labels": [], "entities": []}, {"text": "Any method for analyzing sentiment in microblogs or other social media streams must be easily adapted to (1) many low-resource languages, (2) the dynamic nature of social media, and (3) working in a streaming mode with limited or no supervision.", "labels": [], "entities": []}, {"text": "Although bootstrapping has been used for learning sentiment lexicons in other domains), it has not yet been applied to learning sentiment lexicons for microblogs.", "labels": [], "entities": []}, {"text": "In this paper, we present an approach for bootstrapping subjectivity clues from Twitter data, and evaluate our approach on English, Spanish and Russian Twitter streams.", "labels": [], "entities": []}, {"text": "Our approach: \u2022 handles the informality, creativity and the dynamic nature of social media; \u2022 does not rely on language-dependent tools; \u2022 scales to the hundreds of new under-explored languages and dialects in social media; \u2022 classifies sentiment in a streaming mode.", "labels": [], "entities": []}, {"text": "To bootstrap subjectivity clues from Twitter streams we rely on three main assumptions: i. sentiment-bearing terms of similar orientation tend to co-occur at the tweet level); ii. sentiment-bearing terms of opposite orientation do not co-occur at the tweet level (Gamon and Aue, 2005); iii.", "labels": [], "entities": []}, {"text": "the co-occurrence of domain-specific and domain-independent subjective terms serves as a signal of subjectivity.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our bootstrapped sentiment lexicons English L E B , Spanish L S B and Russian L R B by comparing them with existing dictionary-expanded lexicons that have been previously shown to be effective for subjectivity and polarity classification ().", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 226, "end_pos": 249, "type": "TASK", "confidence": 0.7333213686943054}]}, {"text": "For that we perform subjectivity and polarity classification using rule-based classifiers 6 on the test data E-TEST, S-TEST and R-TEST.", "labels": [], "entities": [{"text": "subjectivity and polarity classification", "start_pos": 20, "end_pos": 60, "type": "TASK", "confidence": 0.661237008869648}]}, {"text": "We consider how the various lexicons perform for rule-based classifiers for both subjectivity and polarity.", "labels": [], "entities": []}, {"text": "The subjectivity classifier predicts that a tweet is subjective if it contains a) at least one, or b) at least two subjective terms from the lexicon.", "labels": [], "entities": []}, {"text": "For the polarity classifier, we predict a tweet to be positive (negative) if it contains at least one positive (negative) term taking into account negation.", "labels": [], "entities": []}, {"text": "If the tweet contains both positive and negative terms, we take the majority label.", "labels": [], "entities": []}, {"text": "For English we compare our bootstrapped lexicon L E B against the original lexicon L E I and strongly subjective terms from SentiWordNet 3.0 ().", "labels": [], "entities": []}, {"text": "To make a fair comparison, we automatically expand SentiWordNet with noun plural forms and verb inflectional forms.", "labels": [], "entities": []}, {"text": "In we report precision, recall Similar approach to a rule-based classification using terms from he MPQA lexicon (. and F-measure results.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9954254031181335}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9987253546714783}, {"text": "MPQA lexicon", "start_pos": 99, "end_pos": 111, "type": "DATASET", "confidence": 0.954849123954773}, {"text": "F-measure", "start_pos": 119, "end_pos": 128, "type": "METRIC", "confidence": 0.9795516729354858}]}, {"text": "They show that our bootstrapped lexicon significantly outperforms SentiWordNet for subjectivity classification.", "labels": [], "entities": [{"text": "subjectivity classification", "start_pos": 83, "end_pos": 110, "type": "TASK", "confidence": 0.7314867675304413}]}, {"text": "For polarity classification we get comparable F-measure but much higher recall for 0.72 0.78: Precision (x-axis), recall (y-axis) and F-measure (in the table) for English: L E I = initial lexicon, L E B = bootstrapped lexicon, SW N = strongly subjective terms from SentiWordNet.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.7063216269016266}, {"text": "F-measure", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9890378713607788}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9993651509284973}, {"text": "Precision", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9943903088569641}, {"text": "recall", "start_pos": 114, "end_pos": 120, "type": "METRIC", "confidence": 0.9991031885147095}, {"text": "F-measure", "start_pos": 134, "end_pos": 143, "type": "METRIC", "confidence": 0.994513988494873}]}, {"text": "For Spanish we compare our bootstrapped lexicon L S B against the original L S I lexicon, and the full and medium strength terms from the Spanish sentiment lexicon constructed by.", "labels": [], "entities": []}, {"text": "We report precision, recall and Fmeasure in.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9995158910751343}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9997794032096863}, {"text": "Fmeasure", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9988528490066528}]}, {"text": "We observe that our bootstrapped lexicon yields significantly better performance for subjectivity classification compared to both full and medium strength terms.", "labels": [], "entities": [{"text": "subjectivity classification", "start_pos": 85, "end_pos": 112, "type": "TASK", "confidence": 0.807323694229126}]}, {"text": "However, our bootstrapped lexicon yields lower recall and similar precision for polarity classification.", "labels": [], "entities": [{"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9996886253356934}, {"text": "precision", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9994750618934631}, {"text": "polarity classification", "start_pos": 80, "end_pos": 103, "type": "TASK", "confidence": 0.7470041811466217}]}, {"text": "0.59 0.59 0.55 for Spanish: L S I = initial lexicon, L S B = bootstrapped lexicon, SF = full strength terms; S M = medium strength terms.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Sentiment label distribution in develop- ment DEV and test TEST datasets across languages.", "labels": [], "entities": [{"text": "Sentiment label distribution", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.8800557255744934}]}, {"text": " Table 2: The original and the bootstrapped (high- lighted) lexicon term count (L I \u2282 L B ) with polar- ity across languages (thousands).", "labels": [], "entities": []}]}