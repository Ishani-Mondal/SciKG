{"title": [{"text": "Joint Modeling of News Reader's and Comment Writer's Emotions \uf020", "labels": [], "entities": [{"text": "Joint Modeling of News Reader's and Comment Writer's Emotions", "start_pos": 0, "end_pos": 61, "type": "TASK", "confidence": 0.6093166849829934}]}], "abstractContent": [{"text": "Emotion classification can be generally done from both the writer's and reader's perspectives.", "labels": [], "entities": [{"text": "Emotion classification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9493012130260468}]}, {"text": "In this study, we find that two foundational tasks in emotion classification, i.e., reader's emotion classification on the news and writer's emotion classification on the comments, are strongly related to each other in terms of coarse-grained emotion categories, i.e., negative and positive.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.7386751770973206}, {"text": "reader's emotion classification on the news", "start_pos": 84, "end_pos": 127, "type": "TASK", "confidence": 0.7339308091572353}, {"text": "writer's emotion classification on the comments", "start_pos": 132, "end_pos": 179, "type": "TASK", "confidence": 0.7610489044870649}]}, {"text": "On the basis, we propose a respective way to jointly model these two tasks.", "labels": [], "entities": []}, {"text": "In particular, a co-training algorithm is proposed to improve semi-supervised learning of the two tasks.", "labels": [], "entities": []}, {"text": "Experimental evaluation shows the effectiveness of our joint modeling approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "Emotion classification aims to predict the emotion categories (e.g., happy, angry, or sad) of a given text).", "labels": [], "entities": [{"text": "Emotion classification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9164652824401855}]}, {"text": "With the rapid growth of computer mediated communication applications, such as social websites and miro-blogs, the research on emotion classification has been attracting more and more attentions recently from the natural language processing (NLP) community.", "labels": [], "entities": [{"text": "emotion classification", "start_pos": 127, "end_pos": 149, "type": "TASK", "confidence": 0.783206433057785}]}, {"text": "In general, a single text may possess two kinds of emotions, writer's emotion and reader's emotion, where the former concerns the emotion expressed by the writer when writing the text and the latter concerns the emotion expressed by a reader after reading the text.", "labels": [], "entities": []}, {"text": "For example, consider two short texts drawn from a news and corresponding comments, as shown in.", "labels": [], "entities": []}, {"text": "On * * Corresponding author one hand, for the news text, while its writer just objectively reports the news and thus does not express his emotion in the text, a reader could yield sad or worried emotion.", "labels": [], "entities": []}, {"text": "On the other hand, for the comment text, its writer clearly expresses his sad emotion while the emotion of a reader after reading the comments is not clear (Some may feel sorry but others might feel careless).", "labels": [], "entities": []}], "datasetContent": [{"text": "Data Setting: The data set includes 3495 news articles (1572 positive and 1923 negative) and their comments as described in Section 3.", "labels": [], "entities": []}, {"text": "Although the emotions of the comments are not given in the website, we just set their coarse-grained emotion categories the same as the emotions of their source news due to their close relationship, as described in Section 3.", "labels": [], "entities": []}, {"text": "To make the data balanced, we randomly select 1500 positive and 1500 negative news with their comments for the empirical study.", "labels": [], "entities": []}, {"text": "Among them, we randomly select 400 news with their comments as the test data.", "labels": [], "entities": []}, {"text": "Features: Each news or comment text is treated as a bag-of-words and transformed into a binary vector encoding the presence or absence of word unigrams.", "labels": [], "entities": []}, {"text": "Classification algorithm: the maximum entropy (ME) classifier implemented with the public tool, Mallet Toolkits * .  News reader's emotion classifier: The classifier trained with the news text.", "labels": [], "entities": [{"text": "News reader's emotion classifier", "start_pos": 117, "end_pos": 149, "type": "TASK", "confidence": 0.5479878783226013}]}, {"text": "Comment writer's emotion classifier: The classifier trained with the comment text.", "labels": [], "entities": [{"text": "Comment writer's emotion classifier", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6694502770900727}]}, {"text": "demonstrates the performances of the news reader's and comment writer's emotion classifiers trained with the 10 and 50 initial labeled samples plus automatically labeled data from co-training.", "labels": [], "entities": []}, {"text": "Here, in each iteration, we pick 2 positive and 2 negative most confident samples, i.e, 12 2 nn \uf03d\uf03d . From this figure, we can see that our co-training algorithm is very effective: using only 10 labeled samples in each category achieves a very promising performance on either news reader's or comment writer's emotion classification.", "labels": [], "entities": [{"text": "news reader's or comment writer's emotion classification", "start_pos": 275, "end_pos": 331, "type": "TASK", "confidence": 0.49612880415386623}]}, {"text": "Especially, the performance when using only 10 labeled samples is comparable to that when using more than 1200 labeled samples on supervised learning of comment writer's emotion classification.", "labels": [], "entities": [{"text": "comment writer's emotion classification", "start_pos": 153, "end_pos": 192, "type": "TASK", "confidence": 0.6252043068408966}]}, {"text": "For comparison, we also implement a selftraining algorithm for the news reader's and comment writer's emotion classifiers, each of which automatically labels the samples from the unlabeled data independently.", "labels": [], "entities": [{"text": "news reader's and comment writer's emotion classifiers", "start_pos": 67, "end_pos": 121, "type": "TASK", "confidence": 0.6168790625201331}]}, {"text": "For news reader's emotion classification, the performances of selftraining are 0.783 and 0.79 when 10 and 50 ini-* http://mallet.cs.umass.edu/ tial labeled samples are used.", "labels": [], "entities": [{"text": "news reader's emotion classification", "start_pos": 4, "end_pos": 40, "type": "TASK", "confidence": 0.5553138077259063}]}, {"text": "For comment writer's emotion classification, the performances of self-training are 0.505 and 0.508.", "labels": [], "entities": [{"text": "comment writer's emotion classification", "start_pos": 4, "end_pos": 43, "type": "TASK", "confidence": 0.717731523513794}]}, {"text": "These results are much lower than the performances of our cotraining approach, especially on the comment writer's emotion classification i.e., 0.505 and 0.508 vs. 0.783 and 0.805.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Agreement on annotators and emotions", "labels": [], "entities": []}]}