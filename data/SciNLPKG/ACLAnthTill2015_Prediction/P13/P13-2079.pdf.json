{"title": [{"text": "Modeling Human Inference Process for Textual Entailment Recognition", "labels": [], "entities": [{"text": "Modeling Human Inference Process", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8446410894393921}, {"text": "Textual Entailment Recognition", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.8523054917653402}]}], "abstractContent": [{"text": "This paper aims at understanding what human think in textual entailment (TE) recognition process and modeling their thinking process to deal with this problem.", "labels": [], "entities": [{"text": "textual entailment (TE) recognition process", "start_pos": 53, "end_pos": 96, "type": "TASK", "confidence": 0.7261758616992405}]}, {"text": "We first analyze a labeled RTE-5 test set and find that the negative entailment phenomena are very effective features for TE recognition.", "labels": [], "entities": [{"text": "RTE-5 test set", "start_pos": 27, "end_pos": 41, "type": "DATASET", "confidence": 0.8580435315767924}, {"text": "TE recognition", "start_pos": 122, "end_pos": 136, "type": "TASK", "confidence": 0.9891987144947052}]}, {"text": "Then, a method is proposed to extract this kind of phenomena from text-hypothesis pairs automatically.", "labels": [], "entities": []}, {"text": "We evaluate the performance of using the negative entailment phenomena on both the English RTE-5 dataset and Chinese NTCIR-9 RITE dataset, and conclude the same findings.", "labels": [], "entities": [{"text": "English RTE-5 dataset", "start_pos": 83, "end_pos": 104, "type": "DATASET", "confidence": 0.8704155087471008}, {"text": "Chinese NTCIR-9 RITE dataset", "start_pos": 109, "end_pos": 137, "type": "DATASET", "confidence": 0.761656329035759}]}], "introductionContent": [{"text": "Textual Entailment (TE) is a directional relationship between pairs of text expressions, text (T) and hypothesis (H).", "labels": [], "entities": [{"text": "Textual Entailment (TE)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8265351176261901}]}, {"text": "If human would agree that the meaning of H can be inferred from the meaning of T, we say that T entails H ().", "labels": [], "entities": []}, {"text": "The researches on textual entailment have attracted much attention in recent years due to its potential applications.", "labels": [], "entities": [{"text": "textual entailment", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.8363509178161621}]}, {"text": "Recognizing Textual Entailment (RTE)), a series of evaluations on the developments of English TE recognition technologies, have been held seven times up to 2011.", "labels": [], "entities": [{"text": "Recognizing Textual Entailment (RTE))", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.6905366033315659}, {"text": "TE recognition", "start_pos": 94, "end_pos": 108, "type": "TASK", "confidence": 0.7681082785129547}]}, {"text": "In the meanwhile, TE recognition technologies in other languages are also underway.", "labels": [], "entities": [{"text": "TE recognition", "start_pos": 18, "end_pos": 32, "type": "TASK", "confidence": 0.9878722727298737}]}, {"text": "propose an evaluation metric to examine the characteristics of a TE recognition system.", "labels": [], "entities": [{"text": "TE recognition", "start_pos": 65, "end_pos": 79, "type": "TASK", "confidence": 0.9697092473506927}]}, {"text": "They annotate texthypothesis pairs selected from the RTE-5 test set with a series of linguistic phenomena required in the human inference process.", "labels": [], "entities": [{"text": "RTE-5 test set", "start_pos": 53, "end_pos": 67, "type": "DATASET", "confidence": 0.9192601243654887}]}, {"text": "The RTE systems are evaluated by the new indicators, such as how many T-H pairs annotated with a particular phenomenon can be correctly recognized.", "labels": [], "entities": [{"text": "RTE", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.8967450857162476}]}, {"text": "The indicators can tell developers which systems are better to deal with T-H pairs with the appearance of which phenomenon.", "labels": [], "entities": []}, {"text": "That would give developers a direction to enhance their RTE systems.", "labels": [], "entities": []}, {"text": "Such linguistic phenomena are thought as important in the human inference process by annotators.", "labels": [], "entities": []}, {"text": "In this paper, we use this valuable resource from a different aspect.", "labels": [], "entities": []}, {"text": "We aim at knowing the ultimate performance of TE recognition systems which embody human knowledge in the inference process.", "labels": [], "entities": [{"text": "TE recognition", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.9741984009742737}]}, {"text": "The experiments show five negative entailment phenomena are strong features for TE recognition, and this finding confirms the previous study of.", "labels": [], "entities": [{"text": "TE recognition", "start_pos": 80, "end_pos": 94, "type": "TASK", "confidence": 0.9883760511875153}]}, {"text": "We propose a method to acquire the linguistic phenomena automatically and use them in TE recognition.", "labels": [], "entities": [{"text": "TE recognition", "start_pos": 86, "end_pos": 100, "type": "TASK", "confidence": 0.9765148162841797}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we introduce linguistic phenomena used by annotators in the inference process and point out five significant negative entailment phenomena.", "labels": [], "entities": []}, {"text": "Section 3 proposes a method to extract them from T-H pairs automatically, and discuss their effects on TE recognition.", "labels": [], "entities": [{"text": "TE recognition", "start_pos": 103, "end_pos": 117, "type": "TASK", "confidence": 0.9441789984703064}]}, {"text": "In Section 4, we extend the methodology to the BC (binary class subtask) dataset distributed by NTCIR-9 RITE task) and discuss their effects on TE recognition in Chinese.", "labels": [], "entities": [{"text": "BC", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9504380226135254}, {"text": "NTCIR-9 RITE task", "start_pos": 96, "end_pos": 113, "type": "DATASET", "confidence": 0.808125893274943}, {"text": "TE recognition", "start_pos": 144, "end_pos": 158, "type": "TASK", "confidence": 0.9835976660251617}]}, {"text": "Section 5 concludes the remarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "The following two datasets are used in English TE recognition experiments.", "labels": [], "entities": [{"text": "TE recognition", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.890331357717514}]}, {"text": "(a) 210 pairs from part of RTE-5 test set.", "labels": [], "entities": [{"text": "RTE-5 test set", "start_pos": 27, "end_pos": 41, "type": "DATASET", "confidence": 0.9735900163650513}]}, {"text": "The 210 T-H pairs are annotated with the linguistic phenomena by human annotators.", "labels": [], "entities": []}, {"text": "They are selected from the 600 pairs in RTE-5 test set, including 51% ENTAILMENT and 49% NO EN-TAILMENT.", "labels": [], "entities": [{"text": "RTE-5 test set", "start_pos": 40, "end_pos": 54, "type": "DATASET", "confidence": 0.9442164103190104}, {"text": "ENTAILMENT", "start_pos": 70, "end_pos": 80, "type": "METRIC", "confidence": 0.987163245677948}, {"text": "NO EN-TAILMENT", "start_pos": 89, "end_pos": 103, "type": "METRIC", "confidence": 0.8738361299037933}]}, {"text": "(b) 600 pairs of RTE-5 test set.", "labels": [], "entities": [{"text": "RTE-5 test set", "start_pos": 17, "end_pos": 31, "type": "DATASET", "confidence": 0.8659629027048746}]}, {"text": "The original RTE-5 test set, including 50% ENTAILMENT and 50% NO ENTAILMENT.", "labels": [], "entities": [{"text": "RTE-5 test set", "start_pos": 13, "end_pos": 27, "type": "DATASET", "confidence": 0.9111369649569193}, {"text": "ENTAILMENT", "start_pos": 43, "end_pos": 53, "type": "METRIC", "confidence": 0.9773969650268555}, {"text": "NO ENTAILMENT", "start_pos": 62, "end_pos": 75, "type": "METRIC", "confidence": 0.8229895234107971}]}, {"text": "shows the performances of TE recognition.", "labels": [], "entities": [{"text": "TE recognition", "start_pos": 26, "end_pos": 40, "type": "TASK", "confidence": 0.7290984690189362}]}, {"text": "The \"Machine-annotated\" and the \"Human-annotated\" columns denote that the phenomena annotated by machine and human are used in the evaluation respectively.", "labels": [], "entities": []}, {"text": "Using \"Human-annotated\" phenomena can be seen as the upper-bound of the experiments.", "labels": [], "entities": []}, {"text": "The performance of using machine-annotated features in 210-pair and 600-pair datasets is 52.38% and 59.17% respectively.", "labels": [], "entities": []}, {"text": "Though the performance of using the phenomena extracted automatically by machine is not comparable to that of using the human annotated ones, the accuracy achieved by using only 5 features (59.17%) is just a little lower than the average accuracy of all runs in RTE-5 formal runs (60.36%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9992684721946716}, {"text": "accuracy", "start_pos": 238, "end_pos": 246, "type": "METRIC", "confidence": 0.9924081563949585}]}, {"text": "It shows that the significant phenomena are really effective in dealing with entailment recognition.", "labels": [], "entities": [{"text": "entailment recognition", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.9246052503585815}]}, {"text": "If we can improve the performance of the automatic phenomena extraction, it may make a great progress on the textual entailment.", "labels": [], "entities": [{"text": "automatic phenomena extraction", "start_pos": 41, "end_pos": 71, "type": "TASK", "confidence": 0.7528956333796183}]}, {"text": "To make sure if negative entailment phenomena exist in other languages, we apply the methodologies in Sections 2 and 3 to the RITE dataset in NTCIR-9.", "labels": [], "entities": [{"text": "RITE dataset", "start_pos": 126, "end_pos": 138, "type": "DATASET", "confidence": 0.8376101553440094}, {"text": "NTCIR-9", "start_pos": 142, "end_pos": 149, "type": "DATASET", "confidence": 0.7545678615570068}]}, {"text": "We annotate all the 9 negative entailment phenomena on Chinese T-H pairs according to the definitions by and analyze the effects of various combinations of the phenomena on the new annotated Chinese data.", "labels": [], "entities": []}, {"text": "The accuracy of using all the 9 phenomena as features (i.e., setting) is 91.11%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997698664665222}]}, {"text": "It shows the same tendency as the analyses on English data.", "labels": [], "entities": [{"text": "English data", "start_pos": 46, "end_pos": 58, "type": "DATASET", "confidence": 0.843778520822525}]}, {"text": "The significant negative entailment phenomena on Chinese data, i.e.,, are also identical to those on English data.", "labels": [], "entities": []}, {"text": "The model using only 5 phenomena achieves an accuracy of 90.78%, which is very close to the performance using all phenomena.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.999721348285675}]}, {"text": "We also classify the entailment relation using the phenomena extracted automatically by the similar method shown in Section 3.1, and get a similar result.", "labels": [], "entities": []}, {"text": "The accuracy achieved by using the five automatically extracted phenomena as features is 57.11%, and the average accuracy of all runs in NTCIR-9 RITE task is 59.36%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995610117912292}, {"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9987422823905945}, {"text": "NTCIR-9 RITE task", "start_pos": 137, "end_pos": 154, "type": "DATASET", "confidence": 0.7153526743253072}]}, {"text": "Compared to the other methods using a lot of features, only a small number of binary features are used in our method.", "labels": [], "entities": []}, {"text": "Those observations establish what we can calla useful baseline for TE recognition.", "labels": [], "entities": [{"text": "TE recognition", "start_pos": 67, "end_pos": 81, "type": "TASK", "confidence": 0.9869934916496277}]}], "tableCaptions": [{"text": " Table 1: Accuracy of recognizing binary TE rela- tion with the five aspects as features.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9803271889686584}]}, {"text": " Table 2: Accuracy of recognizing TE relation  with individual negative entailment phenomena.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9735805988311768}, {"text": "TE relation", "start_pos": 34, "end_pos": 45, "type": "TASK", "confidence": 0.7945091724395752}]}, {"text": " Table 3: Accuracy of textual entailment recogni- tion using the extracted phenomena as features.", "labels": [], "entities": []}]}