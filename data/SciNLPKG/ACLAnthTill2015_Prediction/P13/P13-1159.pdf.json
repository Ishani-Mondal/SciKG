{"title": [{"text": "Aid is Out There: Looking for Help from Tweets during a Large Scale Disaster", "labels": [], "entities": []}], "abstractContent": [{"text": "The 2011 Great East Japan Earthquake caused a wide range of problems, and as countermeasures, many aid activities were carried out.", "labels": [], "entities": [{"text": "2011 Great East Japan Earthquake", "start_pos": 4, "end_pos": 36, "type": "DATASET", "confidence": 0.6113971412181854}]}, {"text": "Many of these problems and aid activities were reported via Twitter.", "labels": [], "entities": []}, {"text": "However, most problem reports and corresponding aid messages were not successfully exchanged between victims and local governments or humanitarian organizations , overwhelmed by the vast amount of information.", "labels": [], "entities": []}, {"text": "As a result, victims could not receive necessary aid and humanitarian organizations wasted resources on redundant efforts.", "labels": [], "entities": []}, {"text": "In this paper, we propose a method for discovering matches between problem reports and aid messages.", "labels": [], "entities": []}, {"text": "Our system contributes to problem-solving in a large scale disaster situation by facilitating communication between victims and humanitarian organizations.", "labels": [], "entities": []}], "introductionContent": [{"text": "The 2011 Great East Japan Earthquake in March 11, 2011 killed 15,883 people and destroyed over 260,000 households (National Police Agency of Japan, 2013).", "labels": [], "entities": [{"text": "2011 Great East Japan Earthquake in March 11", "start_pos": 4, "end_pos": 48, "type": "DATASET", "confidence": 0.7169382348656654}, {"text": "National Police Agency of Japan, 2013)", "start_pos": 115, "end_pos": 153, "type": "DATASET", "confidence": 0.9217552095651627}]}, {"text": "Accustomed way of living suddenly became unmanageable and people found themselves in extreme conditions for months.", "labels": [], "entities": []}, {"text": "Just after the disaster, many people used Twitter for posting problem reports and aid messages as it functioned while most communication channels suffered disruptions).", "labels": [], "entities": []}, {"text": "Examples of such problem reports and aid messages, translated from Japanese tweets, are given below (P1, A1).", "labels": [], "entities": [{"text": "A1", "start_pos": 105, "end_pos": 107, "type": "METRIC", "confidence": 0.8812547922134399}]}, {"text": "P1 My friend said infant formula is sold out.", "labels": [], "entities": []}, {"text": "If somebody knows shops in Sendai-city where they still have it in stock, please let us know.", "labels": [], "entities": []}, {"text": "A1 At Jusco supermarket in Sendai, you can still buy water and infant formula.", "labels": [], "entities": [{"text": "Jusco supermarket in Sendai", "start_pos": 6, "end_pos": 33, "type": "DATASET", "confidence": 0.8639582395553589}]}, {"text": "If A1 would have been forwarded to the sender of P1, it could have helped since it would help the \"friend\" to obtain infant formula.", "labels": [], "entities": [{"text": "A1", "start_pos": 3, "end_pos": 5, "type": "METRIC", "confidence": 0.9952729344367981}]}, {"text": "But in reality, the majority of such reports/messages, especially unforeseen ones went unnoticed amongst the mass of information ( ).", "labels": [], "entities": []}, {"text": "In addition, there were cases where many humanitarian organizations responded to the same problems and wasted precious resources.", "labels": [], "entities": []}, {"text": "For instance, many volunteers responded to problems which were heavily reported by public media, leading to oversupply.", "labels": [], "entities": []}, {"text": "Such waste of resources could have been avoided if the organizations would have successfully shared the aid messages for the same problems.", "labels": [], "entities": []}, {"text": "Such observations motivated this work.", "labels": [], "entities": []}, {"text": "We developed methods for recognizing problem reports and aid messages in tweets and finding proper matches between them.", "labels": [], "entities": []}, {"text": "By browsing the discovered matches, victims can be assisted to overcome their problems, and humanitarian organizations can avoid redundant relief efforts.", "labels": [], "entities": []}, {"text": "We define problem reports, aid messages and their successful matches as follows.", "labels": [], "entities": []}, {"text": "Problem report: A tweet that informs about the possibility or emergence of a problem that requires a treatment or countermeasure.", "labels": [], "entities": []}, {"text": "Aid message: A tweet that (1) informs about situations or actions that can be a remedy or solution fora problem, or (2) informs that the problem is solved or is about to be solved.", "labels": [], "entities": []}, {"text": "Problem-aid tweet match: A tweet pair is a problem-aid tweet match (1) if the aid message informs how to overcome the problem, (2) if the aid message informs about the set-tlement of the problem, or (3) if the aid message provides information which contributes to the settlement of the problem.", "labels": [], "entities": []}, {"text": "In this work we excluded direct requests, such as \"Send us food!\", from problem reports.", "labels": [], "entities": []}, {"text": "This is because it is relatively easy to recognize such direct requests by checking mood types (i.e., imperative) and their behavior is quite different from problem reports like \"People in Sendai are starving\".", "labels": [], "entities": []}, {"text": "Problem reports in this work do not directly state which actions are required, only implying the necessity of a countermeasure through claiming the existence of problems.", "labels": [], "entities": []}, {"text": "An underlying assumption of our method is that we can find a noun-predicate dependency relation that works as an indicator of problems and aids in problem reports and aid messages, which we refer to as problem nucleus and aid nucleus.", "labels": [], "entities": []}, {"text": "1 An example of problem nucleus is \"infant formula is sold out\" in P1, and that of aid nucleus is \"(can) buy infant formula\" in A1.", "labels": [], "entities": []}, {"text": "Many problem-aid tweet matches can be recognized through problem and aid nuclei pairs.", "labels": [], "entities": []}, {"text": "We also assume that if the problem and aid nuclei match, they share the same noun.", "labels": [], "entities": []}, {"text": "Then, the semantics of predicates in the nuclei is the main factor that decides whether the nuclei constitute a match.", "labels": [], "entities": []}, {"text": "We introduce a semantic classification of predicates according to the framework of excitation polarities proposed in . Our hypothesis is that excitation polarities along with trouble expressions can characterize problem reports, aid messages and their matches.", "labels": [], "entities": []}, {"text": "We developed a supervised method encoding such information into its features.", "labels": [], "entities": []}, {"text": "An evident alternative to this approach is to use sentiment analysis () assuming that problem reports should include something 'bad' while aid messages describe something 'good'.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.9312842786312103}]}, {"text": "However, we will show that this does notwork well in our experiments.", "labels": [], "entities": []}, {"text": "We think this is due to mismatch between the concepts of problem/aid and sentiment polarity.", "labels": [], "entities": []}, {"text": "Note that previous work on 'demand' recognition also found similar tendencies.", "labels": [], "entities": [{"text": "demand' recognition", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.7003987034161886}]}, {"text": "Another issue in this task is, of course, the context surrounding problem/aid nuclei.", "labels": [], "entities": []}, {"text": "The fol- We found that out of 500 random tweets only 4.5% of problem reports and 9.1% of aid messages did not contain any problem report/aid message nuclei.", "labels": [], "entities": []}, {"text": "lowing (imaginary) tweets exemplify the problems caused by contexts.", "labels": [], "entities": []}, {"text": "FP1 I do not believe infant formula is sold out in Sendai.", "labels": [], "entities": [{"text": "FP1", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7994810938835144}, {"text": "Sendai", "start_pos": 51, "end_pos": 57, "type": "DATASET", "confidence": 0.865807831287384}]}, {"text": "FA1 At Jusco supermarket in Iwaki, you can still buy infant formula.", "labels": [], "entities": [{"text": "FA1", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7579156160354614}, {"text": "Jusco supermarket in Iwaki", "start_pos": 7, "end_pos": 33, "type": "DATASET", "confidence": 0.8462887406349182}]}, {"text": "The problem nuclei of FP1 and P1 are the same but FP1 is not a problem report because of the expression \"I do not believe\".", "labels": [], "entities": [{"text": "FP1", "start_pos": 22, "end_pos": 25, "type": "DATASET", "confidence": 0.6432686448097229}, {"text": "FP1", "start_pos": 50, "end_pos": 53, "type": "DATASET", "confidence": 0.5677639842033386}]}, {"text": "The aid nuclei of FA1 and A1 are the same but FA1 does not constitute a proper match with P1 because FA1 and P1 refer to different cities, \"Iwaki\" and \"Sendai\".", "labels": [], "entities": [{"text": "FA1", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.779090940952301}, {"text": "FA1", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.8883417844772339}]}, {"text": "In this work, the problems concerning the modality and other semantic modifications to problem/aid nuclei by context are dealt with by the introduction of features representing the text surrounding the nuclei in machine learning.", "labels": [], "entities": []}, {"text": "As for the location problem, we apply a location recognizer to all tweets and restrict the matching candidates to the tweet pairs referring to the same location.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our problem report recognizer and problem-aid match recognizer.", "labels": [], "entities": [{"text": "problem report recognizer", "start_pos": 17, "end_pos": 42, "type": "TASK", "confidence": 0.6587423086166382}, {"text": "problem-aid match recognizer", "start_pos": 47, "end_pos": 75, "type": "TASK", "confidence": 0.7176620463530222}]}, {"text": "For the sake of space, we give only the performance figures of the aid message recognizer at the end of Section 5.1.", "labels": [], "entities": [{"text": "aid message recognizer", "start_pos": 67, "end_pos": 89, "type": "TASK", "confidence": 0.5646186470985413}]}, {"text": "We collected tweets posted during and after the 2011 Great East Japan Earthquake, between March 10 and April 4, 2011.", "labels": [], "entities": [{"text": "2011 Great East Japan Earthquake", "start_pos": 48, "end_pos": 80, "type": "DATASET", "confidence": 0.6905254244804382}]}, {"text": "After applying keyword-based filtering with a list of over 300 The original similarity was defined over noun pairs and it was estimated from dependency relations.", "labels": [], "entities": []}, {"text": "Obtaining similarity between template pairs, not noun pairs, is straightforward given the same dependency relations.", "labels": [], "entities": []}, {"text": "We used 600 million Web pages for this similarity estimation.", "labels": [], "entities": [{"text": "similarity estimation", "start_pos": 39, "end_pos": 60, "type": "TASK", "confidence": 0.7748715877532959}]}, {"text": "The precision of the pairs was reported as around 70%.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9996637105941772}]}, {"text": "disaster related keywords, we obtained 55 million tweets.", "labels": [], "entities": []}, {"text": "After dependency parsing , we used them in our evaluation.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.8772186934947968}]}], "tableCaptions": [{"text": " Table 4: Recall (R), precision (P), F-score (F) and  average precision (aP) of the problem report rec- ognizers.", "labels": [], "entities": [{"text": "Recall (R)", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9435152858495712}, {"text": "precision (P)", "start_pos": 22, "end_pos": 35, "type": "METRIC", "confidence": 0.9516510367393494}, {"text": "F-score (F)", "start_pos": 37, "end_pos": 48, "type": "METRIC", "confidence": 0.9668918699026108}, {"text": "average precision (aP)", "start_pos": 54, "end_pos": 76, "type": "METRIC", "confidence": 0.9226389050483703}]}, {"text": " Table 6: Recall (R), precision (P), F-score (F) and  average precision (aP) of the problem-aid match  recognizers.", "labels": [], "entities": [{"text": "Recall (R)", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9448303133249283}, {"text": "precision (P)", "start_pos": 22, "end_pos": 35, "type": "METRIC", "confidence": 0.954811230301857}, {"text": "F-score (F)", "start_pos": 37, "end_pos": 48, "type": "METRIC", "confidence": 0.9682761430740356}, {"text": "average precision (aP)", "start_pos": 54, "end_pos": 76, "type": "METRIC", "confidence": 0.9104995608329773}, {"text": "problem-aid match  recognizers", "start_pos": 84, "end_pos": 114, "type": "TASK", "confidence": 0.6609317064285278}]}]}