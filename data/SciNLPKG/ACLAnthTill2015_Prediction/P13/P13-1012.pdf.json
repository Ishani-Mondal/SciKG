{"title": [{"text": "Decentralized Entity-Level Modeling for Coreference Resolution", "labels": [], "entities": [{"text": "Decentralized Entity-Level Modeling", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6609718799591064}, {"text": "Coreference Resolution", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.9718112945556641}]}], "abstractContent": [{"text": "Efficiently incorporating entity-level information is a challenge for coreference resolution systems due to the difficulty of exact inference over partitions.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 70, "end_pos": 92, "type": "TASK", "confidence": 0.9596581757068634}]}, {"text": "We describe an end-to-end discriminative prob-abilistic model for coreference that, along with standard pairwise features, enforces structural agreement constraints between specified properties of coreferent mentions.", "labels": [], "entities": []}, {"text": "This model can be represented as a factor graph for each document that admits efficient inference via belief propagation.", "labels": [], "entities": [{"text": "belief propagation", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.7117981612682343}]}, {"text": "We show that our method can use entity-level information to outperform a basic pairwise system.", "labels": [], "entities": []}], "introductionContent": [{"text": "The inclusion of entity-level features has been a driving force behind the development of many coreference resolution systems ().", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 95, "end_pos": 117, "type": "TASK", "confidence": 0.9222625494003296}]}, {"text": "There is no polynomial-time dynamic program for inference in a model with arbitrary entity-level features, so systems that use such features typically rely on making decisions in a pipelined manner and sticking with them, operating greedily in a left-to-right fashion or in a multi-pass, sieve-like manner (.", "labels": [], "entities": []}, {"text": "However, such systems maybe locked into bad coreference decisions and are difficult to directly optimize for standard evaluation metrics.", "labels": [], "entities": []}, {"text": "In this work, we present anew structured model of entity-level information designed to allow efficient inference.", "labels": [], "entities": []}, {"text": "We use a log-linear model that can be expressed as a factor graph.", "labels": [], "entities": []}, {"text": "Pairwise features appear in the model as unary factors, adjacent to nodes representing a choice of antecedent (or none) for each mention.", "labels": [], "entities": []}, {"text": "Additional nodes model entity-level properties on a per-mention basis, and structural agreement factors softly drive properties of coreferent mentions to agree with one another.", "labels": [], "entities": []}, {"text": "This is a key feature of our model: mentions manage their partial membership in various coreference chains, so that information about entity-level properties is decentralized and propagated across individual mentions, and we never need to explicitly instantiate entities.", "labels": [], "entities": []}, {"text": "Exact inference in this factor graph is intractable, but efficient approximate inference can be carried outwith belief propagation.", "labels": [], "entities": [{"text": "belief propagation", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.7919611930847168}]}, {"text": "Our model is the first discriminatively-trained model that both makes joint decisions over an entire document and models specific entity-level properties, rather than simply enforcing transitivity of pairwise decisions.", "labels": [], "entities": []}, {"text": "We evaluate our system on the dataset from the CoNLL 2011 shared task using three different types of properties: synthetic oracle properties, entity phi features (number, gender, animacy, and NER type), and properties derived from unsupervised clusters targeting semantic type information.", "labels": [], "entities": [{"text": "CoNLL 2011 shared task", "start_pos": 47, "end_pos": 69, "type": "DATASET", "confidence": 0.8527114987373352}]}, {"text": "In all cases, our transitive model of entity properties equals or outperforms our pairwise system and our reimplementation of a previous entity-level system).", "labels": [], "entities": []}, {"text": "Our final system is competitive with the winner of the CoNLL 2011 shared task ().", "labels": [], "entities": [{"text": "CoNLL 2011 shared task", "start_pos": 55, "end_pos": 77, "type": "DATASET", "confidence": 0.7936329692602158}]}], "datasetContent": [{"text": "We use the datasets, experimental setup, and scoring program from the CoNLL 2011 shared task), based on the OntoNotes corpus ().", "labels": [], "entities": [{"text": "CoNLL 2011 shared task", "start_pos": 70, "end_pos": 92, "type": "DATASET", "confidence": 0.9209682643413544}, {"text": "OntoNotes corpus", "start_pos": 108, "end_pos": 124, "type": "DATASET", "confidence": 0.8974916338920593}]}, {"text": "We use the standard automatic parses and NER tags for each document.", "labels": [], "entities": []}, {"text": "Our mentions are those output by the system of Lee et al.; we also use their postprocessing to remove appositives, predicate nominatives, and singletons before evaluation.", "labels": [], "entities": []}, {"text": "For each experiment, we report MUC (, B 3 (Bagga and Baldwin, 1998), and CEAF e (, as well as their average.", "labels": [], "entities": [{"text": "MUC", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.9752095341682434}, {"text": "CEAF e", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9874757528305054}]}, {"text": "We take the regularization constant \u03bb = 0.001 and the parameters of our surrogate loss (c 1 , c 2 , c 3 ) = (0.15, 2.5, 1) for all models.", "labels": [], "entities": []}, {"text": "All models are trained for 20 iterations.", "labels": [], "entities": []}, {"text": "We take the pruning threshold \u03b3 = \u22122.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: CoNLL metric scores for our four dif- ferent systems incorporating noisy oracle data.  This information helps substantially in all cases.  Both entity-level models outperform the PAIR- PROPERTY model, but we observe that the TRAN- SITIVE model is more effective than the LEFT- TORIGHT model at using this information.", "labels": [], "entities": [{"text": "PAIR", "start_pos": 189, "end_pos": 193, "type": "METRIC", "confidence": 0.7980989217758179}, {"text": "LEFT- TORIGHT", "start_pos": 281, "end_pos": 294, "type": "METRIC", "confidence": 0.7497788468996683}]}, {"text": " Table 2: CoNLL metric scores for our systems in- corporating phi features. Our standard BASIC sys- tem already includes phi features, so no results are  reported for PAIRPROPERTY. Here, our TRAN- SITIVE system does not give substantial improve- ment on the averaged metric. Over a baseline  which does not include phi features, all systems  are able to incorporate them comparably.", "labels": [], "entities": [{"text": "PAIRPROPERTY", "start_pos": 167, "end_pos": 179, "type": "METRIC", "confidence": 0.5132280588150024}]}, {"text": " Table 3: CoNLL metric scores for our systems  incorporating clustering features. These features  are equally effectively incorporated by our PAIR- PROPERTY system and our TRANSITIVE system.", "labels": [], "entities": [{"text": "CoNLL metric scores", "start_pos": 10, "end_pos": 29, "type": "METRIC", "confidence": 0.7209346294403076}, {"text": "PAIR- PROPERTY", "start_pos": 142, "end_pos": 156, "type": "METRIC", "confidence": 0.7727219263712565}]}, {"text": " Table 4: CoNLL metric scores averaged across ten different splits of the training set for each experiment.  We include precision, recall, and F 1 for each metric for completeness. Starred F 1 values on the individual  metrics for the TRANSITIVE system are significantly better than all other results in the same block at the  p = 0.01 level according to a bootstrap resampling test.", "labels": [], "entities": [{"text": "precision", "start_pos": 120, "end_pos": 129, "type": "METRIC", "confidence": 0.9997618794441223}, {"text": "recall", "start_pos": 131, "end_pos": 137, "type": "METRIC", "confidence": 0.9991496801376343}, {"text": "F 1", "start_pos": 143, "end_pos": 146, "type": "METRIC", "confidence": 0.9956968426704407}, {"text": "Starred F 1", "start_pos": 181, "end_pos": 192, "type": "METRIC", "confidence": 0.6449927190939585}]}, {"text": " Table 5: CoNLL metric scores for our best systems (including clustering features) on the CoNLL blind  test set, reported in the same manner as", "labels": [], "entities": [{"text": "CoNLL blind  test set", "start_pos": 90, "end_pos": 111, "type": "DATASET", "confidence": 0.8960432857275009}]}]}