{"title": [{"text": "Linggle: a Web-scale Linguistic Search Engine for Words in Context", "labels": [], "entities": [{"text": "Linggle", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8505803346633911}]}], "abstractContent": [{"text": "In this paper, we introduce a Web-scale linguistics search engine, Linggle, that retrieves lexical bundles in response to a given query.", "labels": [], "entities": []}, {"text": "The query might contain keywords, wildcards, wild parts of speech (PoS), synonyms, and additional regular expression (RE) operators.", "labels": [], "entities": []}, {"text": "In our approach, we incorporate inverted file indexing , PoS information from BNC, and semantic indexing based on Latent Dirichlet Allocation with Google Web 1T.", "labels": [], "entities": []}, {"text": "The method involves parsing the query to transforming it into several keyword retrieval commands.", "labels": [], "entities": []}, {"text": "Word chunks are retrieved with counts, further filtering the chunks with the query as a RE, and finally displaying the results according to the counts, similarities, and topics.", "labels": [], "entities": [{"text": "RE", "start_pos": 88, "end_pos": 90, "type": "METRIC", "confidence": 0.9797358512878418}]}, {"text": "Clusters of synonyms or conceptually related words are also provided.", "labels": [], "entities": []}, {"text": "In addition, Linggle provides example sentences from The New York Times on demand.", "labels": [], "entities": [{"text": "The New York Times", "start_pos": 53, "end_pos": 71, "type": "DATASET", "confidence": 0.9016689211130142}]}, {"text": "The current implementation of Linggle is the most functionally comprehensive , and is in principle language and dataset independent.", "labels": [], "entities": [{"text": "Linggle", "start_pos": 30, "end_pos": 37, "type": "DATASET", "confidence": 0.9444553256034851}]}, {"text": "We plan to extend Linggle to provide fast and convenient access to a wealth of linguistic information embodied in Web scale datasets including Google Web 1T and Google Books Ngram for many major languages in the world.", "labels": [], "entities": [{"text": "Linggle", "start_pos": 18, "end_pos": 25, "type": "DATASET", "confidence": 0.8859562873840332}, {"text": "Google Books Ngram", "start_pos": 161, "end_pos": 179, "type": "DATASET", "confidence": 0.7970012625058492}]}], "introductionContent": [{"text": "As a non-native speaker writing in English, one encounters many problems.", "labels": [], "entities": []}, {"text": "Doubts concerning the usage of a preposition, the mandatory presence of a determiner, the correctness of the association of a verb with an object, or the need for synonyms of a term in a given context are issues that arise frequently.", "labels": [], "entities": []}, {"text": "Printed collocation dictionaries and reference tools based on compiled corpora offer limited coverage of word usage while knowledge of collocations is vital to acquire a good level of linguistic competency.", "labels": [], "entities": []}, {"text": "We propose to address these limitations with a comprehensive system aimed at helping the learners \"know a word by the company it keeps\".", "labels": [], "entities": []}, {"text": "The system based on Web-scaled datasets is designed to be abroad coverage language reference tool for English Second Language learners (ESL).", "labels": [], "entities": []}, {"text": "It is conceived to search information related to word usage in context under various conditions.", "labels": [], "entities": []}, {"text": "First, we build an inverted file index for the Google Web 1T n-grams to support queries with RE-like patterns including PoS and synonym matches.", "labels": [], "entities": [{"text": "Google Web 1T n-grams", "start_pos": 47, "end_pos": 68, "type": "DATASET", "confidence": 0.9044367074966431}]}, {"text": "For example, for the query \"$V $D +important role\", Linggle retrieves 4-grams that start with a verb and a determiner followed by a synonym of important and the keyword role (e.g., play a significant role 202,800).", "labels": [], "entities": []}, {"text": "A natural language interface is also available for users who are less familiar with pattern-based searches.", "labels": [], "entities": []}, {"text": "For example, the question \"How can I describe a beach?\" would retrieve two word chunks such as \"sandy beach 413,300\" and \"rocky beach 16,800\".", "labels": [], "entities": []}, {"text": "The n-gram search implementation is achieved through filtering, re-indexing, populating an HBase database with the Web 1T n-grams and augmenting them with the most frequent PoS for words (without disambiguation) derived from the British National Corpus (BNC).", "labels": [], "entities": [{"text": "HBase database", "start_pos": 91, "end_pos": 105, "type": "DATASET", "confidence": 0.9170230627059937}, {"text": "British National Corpus (BNC)", "start_pos": 229, "end_pos": 258, "type": "DATASET", "confidence": 0.9652951161066691}]}, {"text": "The n-grams returned fora query can then be linked to examples extracted from the New York Times Corpus) in order to provide full sentential context for more effective learning.", "labels": [], "entities": [{"text": "New York Times Corpus", "start_pos": 82, "end_pos": 103, "type": "DATASET", "confidence": 0.7815068513154984}]}, {"text": "In some situations, the user might need to search for words in a specific syntactic relation (e.g., Verb-Object collocation).", "labels": [], "entities": []}, {"text": "The query absorb $N in n-grams display mode returns all the nouns that follow the verb ordered by decreasing ngram counts.", "labels": [], "entities": []}, {"text": "Some of these nouns might not be objects of the verb absorb.", "labels": [], "entities": []}, {"text": "In contrast, the same query in cluster display mode will control that two words have been labeled verb-object by a parser.", "labels": [], "entities": []}, {"text": "Moreover, n-grams grouped by object topic/domain give the learner an overview of the usage of the verb.", "labels": [], "entities": []}, {"text": "For example the verb absorb takes clusters of objects related to the topics liquid, energy, money, knowledge, and population.", "labels": [], "entities": []}, {"text": "This tendency of predicates to prefer certain classes of arguments is defined by as selectional preferences and widely reported in the literature.", "labels": [], "entities": []}, {"text": "extend experiments on selectional preference induction to inverse selectional preference, considering the restriction imposed on predicates.", "labels": [], "entities": [{"text": "selectional preference induction", "start_pos": 22, "end_pos": 54, "type": "TASK", "confidence": 0.7107257843017578}]}, {"text": "Inverse sectional preference is also implemented in linggle (e.g. \"$V apple\").", "labels": [], "entities": []}, {"text": "Linggle presents clusters of synonymous collocates (adjectives, nouns and verbs) of a query keyword.", "labels": [], "entities": [{"text": "Linggle", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9182021021842957}]}, {"text": "We obtained the clusters by building on large-scale repository of dependencies and word similarity scores.", "labels": [], "entities": []}, {"text": "Using the method proposed by we induce selectional preference with a Latent Dirichlet Allocation (LDA) model to seed the clusters.", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation (LDA)", "start_pos": 69, "end_pos": 102, "type": "METRIC", "confidence": 0.8702731927235922}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "We review the related work in the next section.", "labels": [], "entities": []}, {"text": "Then we present the syntax of the queries and the functionalities of the system (Section 3).", "labels": [], "entities": []}, {"text": "We describe the details of implementation including the indexing of the n-grams and the clustering algorithm (Section 4) and draw perspective of development of Web scale search engines (Section 5).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 4: Clustering Algorithm for the object of a giv- en verb", "labels": [], "entities": []}]}