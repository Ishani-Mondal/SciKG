{"title": [{"text": "Argument Inference from Relevant Event Mentions in Chinese Argument Extraction", "labels": [], "entities": [{"text": "Argument Inference from Relevant Event Mentions in Chinese Argument Extraction", "start_pos": 0, "end_pos": 78, "type": "TASK", "confidence": 0.8765585005283356}]}], "abstractContent": [{"text": "As a paratactic language, sentence-level argument extraction in Chinese suffers much from the frequent occurrence of ellipsis with regard to inter-sentence arguments.", "labels": [], "entities": [{"text": "sentence-level argument extraction", "start_pos": 26, "end_pos": 60, "type": "TASK", "confidence": 0.6414559582869211}]}, {"text": "To resolve such problem, this paper proposes a novel global argument inference model to explore specific relationships, such as Coreference, Sequence and Parallel, among relevant event mentions to recover those inter-sentence arguments in the sentence, discourse and document layers which represent the cohesion of an event or a topic.", "labels": [], "entities": []}, {"text": "Evaluation on the ACE 2005 Chinese corpus justifies the effectiveness of our global argument inference model over a state-of-the-art baseline.", "labels": [], "entities": [{"text": "ACE 2005 Chinese corpus", "start_pos": 18, "end_pos": 41, "type": "DATASET", "confidence": 0.9751412719488144}]}], "introductionContent": [{"text": "The task of event extraction is to recognize event mentions of a predefined event type and their arguments (participants and attributes).", "labels": [], "entities": [{"text": "event extraction", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.7552016377449036}]}, {"text": "Generally, it can be divided into two subtasks: trigger extraction, which aims to identify trigger/event mentions and determine their event type, and argument extraction, which aims to extract various arguments of a specific event and assign the roles to them.", "labels": [], "entities": [{"text": "trigger extraction", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.6927073746919632}, {"text": "argument extraction", "start_pos": 150, "end_pos": 169, "type": "TASK", "confidence": 0.7229401171207428}]}, {"text": "In this paper, we focus on argument extraction in Chinese event extraction.", "labels": [], "entities": [{"text": "argument extraction", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.7907855212688446}, {"text": "Chinese event extraction", "start_pos": 50, "end_pos": 74, "type": "TASK", "confidence": 0.6284365753332773}]}, {"text": "While most of previous studies in Chinese event extraction deal with Chinese trigger extraction (e.g.,, there are only a few on Chinese argument extraction (e.g.,.", "labels": [], "entities": [{"text": "Chinese event extraction", "start_pos": 34, "end_pos": 58, "type": "TASK", "confidence": 0.6602792739868164}, {"text": "Chinese trigger extraction", "start_pos": 69, "end_pos": 95, "type": "TASK", "confidence": 0.5803366303443909}, {"text": "Chinese argument extraction", "start_pos": 128, "end_pos": 155, "type": "TASK", "confidence": 0.5819452404975891}]}, {"text": "Following previous studies, we divide argument extraction into two components, argument identification and role determination, where the former recognizes the arguments in a specific event mention and the latter classifies these arguments by roles.", "labels": [], "entities": [{"text": "argument extraction", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7394253015518188}, {"text": "argument identification", "start_pos": 79, "end_pos": 102, "type": "TASK", "confidence": 0.7629302740097046}, {"text": "role determination", "start_pos": 107, "end_pos": 125, "type": "TASK", "confidence": 0.7453099489212036}]}, {"text": "With regard to methodology, most of previous studies on argument extraction recast it as a Semantic Role Labeling (SRL) task and focus on intra-sentence information to identify the arguments and their roles.", "labels": [], "entities": [{"text": "argument extraction", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.7491001784801483}, {"text": "Semantic Role Labeling (SRL) task", "start_pos": 91, "end_pos": 124, "type": "TASK", "confidence": 0.8215632608958653}]}, {"text": "However, argument extraction is much different from SRL in the sense that, while the relationship between a predicate and its arguments in SRL can be mainly decided from the syntactic structure, the relationship between an event trigger and its arguments are more semantics-based, especially in Chinese, as a paratactic (e.g., discourse-driven and pro-drop) language with the widespread of ellipsis and the open flexible sentence structure.", "labels": [], "entities": [{"text": "argument extraction", "start_pos": 9, "end_pos": 28, "type": "TASK", "confidence": 0.7568657100200653}, {"text": "SRL", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.9600318074226379}]}, {"text": "Therefore, some arguments of a specific event mention are faraway from the trigger and how to recover those inter-sentence arguments becomes a challenging issue in Chinese argument extraction.", "labels": [], "entities": [{"text": "Chinese argument extraction", "start_pos": 164, "end_pos": 191, "type": "TASK", "confidence": 0.6647575497627258}]}, {"text": "Consider the following discourse (from ACE 2005 Chinese corpus) as a sample: D1: \u5df4\u52d2\u65af\u5766\u81ea\u6cbb\u653f\u5e9c\u5426\u8ba4\u548c\u52a0\u6c99\u8d70\u5eca 20 \u53f7 \u6e05\u6668\u9020\u6210\u4e24\u540d\u4ee5\u8272\u5217\u4eba\u4e27\u751f(E1)\u7684\u70b8\u5f39\u653b\u51fb (E2)\u4e8b\u4ef6\u6709\u5173\u2026\u8868\u793a\u5c06\u5bf9\u8fd9\u8d77\u653b\u51fb(E3)\u4e8b\u4ef6\u5c55 \u5f00 \u8c03 \u67e5 \u3002 (The Palestinian National Authority denied any involvement in the bomb attack (E2) occurred in the Gaza Strip on the morning of the 20th, which killed (E1) two Israelites.", "labels": [], "entities": [{"text": "ACE 2005 Chinese corpus", "start_pos": 39, "end_pos": 62, "type": "DATASET", "confidence": 0.9089482575654984}]}, {"text": "\u2026 They claimed that they will be investigating this attack (E3).)", "labels": [], "entities": []}, {"text": "-From CBS20001120.1000.0823 In above discourse, there are three event mentions, one kill (E1) and two Attack (E2, E3).", "labels": [], "entities": [{"text": "CBS20001120.1000.0823", "start_pos": 6, "end_pos": 27, "type": "DATASET", "confidence": 0.9350335001945496}, {"text": "Attack", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9890917539596558}]}, {"text": "While it is relatively easy to identify 20 \u53f7\u6e05\u6668 (morning of 20th), \u52a0\u6c99\u8d70\u5eca (Gaza Strip) and \u70b8 \u5f39 (bomb) as the Time, Place and Instrument roles in E2 by a sentence-based argument extractor, it is really challenging to recognize these entities as the arguments of its corefered mention E3 since to reduce redundancy in a Chinese discourse, the later Chinese sentences omit many of these entities already mentioned in previous sentences.", "labels": [], "entities": []}, {"text": "Similarly, it is hard to recognize \u4e24\u540d\u4ee5\u8272\u5217\u4eba (two Israelites) as the Target role for event mention E2 and identify \u70b8 \u5f39 (bomb) as the Instrument role for event mention E1.", "labels": [], "entities": []}, {"text": "An alternative way is to employ various relationships among relevant event mentions in a discourse to infer those intersentence arguments.", "labels": [], "entities": []}, {"text": "The contributions of this paper are: 1) We propose a novel global argument inference model, in which various kinds of event relations are involved to infer more arguments on their semantic relations.", "labels": [], "entities": []}, {"text": "2) Different from and, which only consider document-level consistency, we propose a more fine-gained consistency model to enforce the consistency in the sentence, discourse and document layers.", "labels": [], "entities": []}, {"text": "3) We incorporate argument semantics into our global argument inference model to unify the semantics of the event and its arguments.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 overviews the related work.", "labels": [], "entities": []}, {"text": "Section 3 describes a state-of-the-art Chinese argument extraction system as the baseline.", "labels": [], "entities": [{"text": "Chinese argument extraction", "start_pos": 39, "end_pos": 66, "type": "TASK", "confidence": 0.5790608823299408}]}, {"text": "Section 4 introduces our global model in inferring those inter-sentence arguments.", "labels": [], "entities": []}, {"text": "Section 5 reports experimental results and gives deep analysis.", "labels": [], "entities": []}, {"text": "Finally, we conclude our work in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we first describe the experimental settings and the baseline, and then evaluate our global argument inference model incorporating with relevant event mentions and argument semantics to infer arguments and their roles.", "labels": [], "entities": []}, {"text": "For fair comparison, we adopt the same experimental settings as the state-of-the-art event extraction system () and all the evaluations are experimented on the ACE 2005 Chinese corpus.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 85, "end_pos": 101, "type": "TASK", "confidence": 0.7432519495487213}, {"text": "ACE 2005 Chinese corpus", "start_pos": 160, "end_pos": 183, "type": "DATASET", "confidence": 0.980385035276413}]}, {"text": "We randomly select 567 documents as the training set and the remaining 66 documents as the test set.", "labels": [], "entities": []}, {"text": "Besides, we reserve 33 documents in the training set as the development set and use the ground truth entities, times and values for our training and testing.", "labels": [], "entities": []}, {"text": "As for evaluation, we also follow the standards as defined in.", "labels": [], "entities": []}, {"text": "Finally, all the sentences in the corpus are divided into words using a Chinese word segmentation tool (ICTCLAS) 1 with all entities annotated in the corpus kept.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 72, "end_pos": 97, "type": "TASK", "confidence": 0.5683273375034332}]}, {"text": "We use Berkeley Parser 2 and Stanford Parser 3 to create the constituent and dependency parse trees.", "labels": [], "entities": []}, {"text": "Besides, the ME tool (Maxent) 4 is employed to train individual component classifiers and lp_solver 5 is used to construct our global argument inference model.", "labels": [], "entities": []}, {"text": "Besides, all the experiments on argument extraction are done on the output of the trigger extraction system as described in. shows the performance of the baseline trigger extraction system and Line 1 in illustrates the results of argument identification and role determination based on this system.", "labels": [], "entities": [{"text": "argument extraction", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.7702206373214722}, {"text": "trigger extraction", "start_pos": 82, "end_pos": 100, "type": "TASK", "confidence": 0.690452367067337}, {"text": "argument identification", "start_pos": 230, "end_pos": 253, "type": "TASK", "confidence": 0.7139236927032471}, {"text": "role determination", "start_pos": 258, "end_pos": 276, "type": "TASK", "confidence": 0.7582077980041504}]}], "tableCaptions": [{"text": " Table 4. Performance comparison of argument  extraction on argument identification and role  determination.", "labels": [], "entities": [{"text": "argument  extraction", "start_pos": 36, "end_pos": 56, "type": "TASK", "confidence": 0.7429200708866119}, {"text": "argument identification", "start_pos": 60, "end_pos": 83, "type": "TASK", "confidence": 0.7380403280258179}, {"text": "role  determination", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.7874538898468018}]}, {"text": " Table 5. Contributions of different event  relations on argument identification and role  determination. (Incremental)", "labels": [], "entities": [{"text": "argument identification", "start_pos": 57, "end_pos": 80, "type": "TASK", "confidence": 0.7646569311618805}, {"text": "role  determination", "start_pos": 85, "end_pos": 104, "type": "TASK", "confidence": 0.7440412640571594}]}, {"text": " Table 6. Performance comparison of argument  identification and type determination. (Golden  trigger extraction)", "labels": [], "entities": [{"text": "argument  identification", "start_pos": 36, "end_pos": 60, "type": "TASK", "confidence": 0.7560615837574005}, {"text": "type determination", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.8498161435127258}]}]}