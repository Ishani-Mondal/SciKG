{"title": [{"text": "Automated Collocation Suggestion for Japanese Second Language Learners", "labels": [], "entities": [{"text": "Automated Collocation Suggestion", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7954257527987162}]}], "abstractContent": [{"text": "This study addresses issues of Japanese language learning concerning word combinations (collocations).", "labels": [], "entities": [{"text": "word combinations (collocations)", "start_pos": 69, "end_pos": 101, "type": "TASK", "confidence": 0.7502548098564148}]}, {"text": "Japanese learners maybe able to construct grammatically correct sentences, however, these may sound \"unnatural\".", "labels": [], "entities": []}, {"text": "In this work, we analyze correct word combinations using different collocation measures and word similarity methods.", "labels": [], "entities": []}, {"text": "While other methods use well-formed text, our approach makes use of a large Japanese language learner corpus for generating collocation candidates, in order to build a system that is more sensitive to constructions that are difficult for learners.", "labels": [], "entities": []}, {"text": "Our results show that we get better results compared to other methods that use only well-formed text.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automated grammatical error correction is emerging as an interesting topic of natural language processing (NLP).", "labels": [], "entities": [{"text": "Automated grammatical error correction", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.8358742594718933}, {"text": "natural language processing (NLP)", "start_pos": 78, "end_pos": 111, "type": "TASK", "confidence": 0.803166538476944}]}, {"text": "However, previous research in second language learning are focused on restricted types of learners' errors, such as article and preposition errors.", "labels": [], "entities": []}, {"text": "For example, research for Japanese language mainly focuses on Japanese case particles (.", "labels": [], "entities": []}, {"text": "It is only recently that NLP research has addressed issues of collocation errors.", "labels": [], "entities": []}, {"text": "Collocations are conventional word combinations in a language.", "labels": [], "entities": []}, {"text": "In Japanese, ocha wo ireru \"\u304a\u8336\u3092\u5165\u308c\u308b 1 [to make tea]\" and yume wo miru \" \u5922\u3092\u898b\u308b 2 [to have a dream]\" are examples of collocations.", "labels": [], "entities": []}, {"text": "Even though their accurate use is crucial to make communication precise and to sound like a native speaker, learning them 1 lit.", "labels": [], "entities": []}, {"text": "to put in tea 2 lit.", "labels": [], "entities": []}, {"text": "to see a dream is one of the most difficult tasks for second language learners.", "labels": [], "entities": []}, {"text": "For instance, the Japanese collocation yume wo miru [lit.", "labels": [], "entities": []}, {"text": "to see a dream] is unpredictable, at least, for native speakers of English, because its constituents are different from those in the Japanese language.", "labels": [], "entities": []}, {"text": "A learner might create the unnatural combination yume wo suru, using the verb suru (a general light verb meaning \"do\" in English) instead of miru \"to see\".", "labels": [], "entities": []}, {"text": "In this work, we analyze various Japanese corpora using a number of collocation and word similarity measures to deduce and suggest the best collocations for Japanese second language learners.", "labels": [], "entities": []}, {"text": "In order to build a system that is more sensitive to constructions that are difficult for learners, we use word similarity measures that generate collocation candidates using a large Japanese language learner corpus.", "labels": [], "entities": []}, {"text": "By employing this approach, we could obtain a better result compared to other methods that use only wellformed text.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we introduce related work on collocation error correction.", "labels": [], "entities": [{"text": "collocation error correction", "start_pos": 43, "end_pos": 71, "type": "TASK", "confidence": 0.5587051808834076}]}, {"text": "Section 3 explains our method, based on word similarity and association measures, for suggesting collocations.", "labels": [], "entities": []}, {"text": "In Section 4, we describe different word similarity and association measures, as well as the corpora used in our experiments.", "labels": [], "entities": []}, {"text": "The experimental setup and the results are described in Sections 5 and 6, respectively.", "labels": [], "entities": []}, {"text": "Section 7 points out the future directions for our research.", "labels": [], "entities": []}], "datasetContent": [{"text": "We divided our experiments into two parts: verb suggestion and noun suggestion.", "labels": [], "entities": [{"text": "noun suggestion", "start_pos": 63, "end_pos": 78, "type": "TASK", "confidence": 0.704753115773201}]}, {"text": "For verb suggestion, given the learners' \"noun wo verb\" construction, our focus is to suggest \"noun wo verb\" collocations with alternative verbs other than the learner's written verb.", "labels": [], "entities": [{"text": "verb suggestion", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.7257611304521561}]}, {"text": "For noun suggestion, given the learners' \"noun wo verb\" construction, our focus is to suggest \"noun wo verb\" collocations with alternative nouns other than the learner's written noun.", "labels": [], "entities": [{"text": "noun suggestion", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.8524973690509796}]}, {"text": "We compared the verbs in the confusion set ranked by collocation score suggested by the system with the human correction verb and noun in the Lang-8 data.", "labels": [], "entities": [{"text": "Lang-8 data", "start_pos": 142, "end_pos": 153, "type": "DATASET", "confidence": 0.9038149416446686}]}, {"text": "A match would be counted as a true positive (tp).", "labels": [], "entities": []}, {"text": "A false negative (fn) occurs when the system cannot offer any suggestion.", "labels": [], "entities": [{"text": "false negative (fn)", "start_pos": 2, "end_pos": 21, "type": "METRIC", "confidence": 0.8044098019599915}]}, {"text": "The metrics we used for the evaluation are: precision, recall and the mean reciprocal rank (MRR).", "labels": [], "entities": [{"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9997389912605286}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9995829463005066}, {"text": "mean reciprocal rank (MRR)", "start_pos": 70, "end_pos": 96, "type": "METRIC", "confidence": 0.8940412004788717}]}, {"text": "We report precision at rank k, k=1, 5, computing the rank of the correction when a true positive occurs.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9988622665405273}]}, {"text": "The MRR was used to assess whether the suggestion list contains the correction and how far up it is in the list.", "labels": [], "entities": [{"text": "MRR", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9346044659614563}]}, {"text": "It is calculated as follows: where N is the size of the test set.", "labels": [], "entities": []}, {"text": "If the system did not return the correction fora test instance, shows the ten models derived from combining different word similarity measures and the Weighted Dice measure as association measure, using different corpora.", "labels": [], "entities": []}, {"text": "In this table, for instance, we named M1 the model that uses thesaurus for computing word similarity and uses Mainichi Shimbun corpus when computing collocation scores using the association measure adopted, Weighted Dice.", "labels": [], "entities": [{"text": "Mainichi Shimbun corpus", "start_pos": 110, "end_pos": 133, "type": "DATASET", "confidence": 0.926921010017395}]}, {"text": "M2 uses Mainichi Shimbun corpus for computing both word similarity and collocation scores.", "labels": [], "entities": [{"text": "Mainichi Shimbun corpus", "start_pos": 8, "end_pos": 31, "type": "DATASET", "confidence": 0.9388900001843771}]}, {"text": "M10 computes word similarity using the confusing set from Lang-8 corpus and uses BCCWJ and Lang-8 corpus when computing collocation scores.", "labels": [], "entities": [{"text": "Lang-8 corpus", "start_pos": 58, "end_pos": 71, "type": "DATASET", "confidence": 0.885552316904068}, {"text": "BCCWJ", "start_pos": 81, "end_pos": 86, "type": "DATASET", "confidence": 0.8187917470932007}, {"text": "Lang-8 corpus", "start_pos": 91, "end_pos": 104, "type": "DATASET", "confidence": 0.8973946869373322}]}], "tableCaptions": [{"text": " Table 1 Confusion Set example for the words suru (\u3059\u308b) and biru (\u30d3\u30eb)", "labels": [], "entities": []}, {"text": " Table 2 Context of a particular noun represented  as a co-occurrence vector", "labels": [], "entities": []}, {"text": " Table 3 Context of a particular noun represented  as a co-occurrence vector  rity: 1) thesaurus-based word similarity, 2) dis- tributional similarity and 3) confusion set derived  from learner corpus. The first two measures gen- erate the collocation candidates by finding words  that are analogous to the writer's choice, a com- mon approach used in the related work on  collocation error correction (", "labels": [], "entities": [{"text": "collocation error correction", "start_pos": 373, "end_pos": 401, "type": "TASK", "confidence": 0.6954068144162496}]}, {"text": " Table 4 The precision and recall rate and MRR of the Models of Word Similarity and Association  Strength method combination.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.999646782875061}, {"text": "recall rate", "start_pos": 27, "end_pos": 38, "type": "METRIC", "confidence": 0.9884344637393951}, {"text": "MRR", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.9991745352745056}, {"text": "Word Similarity", "start_pos": 64, "end_pos": 79, "type": "TASK", "confidence": 0.6331714540719986}]}]}