{"title": [{"text": "Meet EDGAR, a tutoring agent at MONSERRATE", "labels": [], "entities": [{"text": "EDGAR", "start_pos": 5, "end_pos": 10, "type": "METRIC", "confidence": 0.989342451095581}, {"text": "MONSERRATE", "start_pos": 32, "end_pos": 42, "type": "DATASET", "confidence": 0.7775393724441528}]}], "abstractContent": [{"text": "In this paper we describe a platform for embodied conversational agents with tutoring goals, which takes as input written and spoken questions and outputs answers in both forms.", "labels": [], "entities": []}, {"text": "The platform is developed within a game environment, and currently allows speech recognition and synthesis in Portuguese, English and Spanish.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.7144261747598648}]}, {"text": "In this paper we focus on its understanding component that supports in-domain interactions , and also small talk.", "labels": [], "entities": []}, {"text": "Most in-domain interactions are answered using different similarity metrics, which compare the perceived utterances with ques-tions/sentences in the agent's knowledge base; small-talk capabilities are mainly due to AIML, a language largely used by the chatbots' community.", "labels": [], "entities": []}, {"text": "In this paper we also introduce EDGAR, the butler of MONSERRATE, which was developed in the aforementioned platform, and that answers tourists' questions about MONSER-RATE.", "labels": [], "entities": [{"text": "EDGAR", "start_pos": 32, "end_pos": 37, "type": "METRIC", "confidence": 0.9796876907348633}, {"text": "MONSERRATE", "start_pos": 53, "end_pos": 63, "type": "DATASET", "confidence": 0.9292576909065247}, {"text": "MONSER-RATE", "start_pos": 160, "end_pos": 171, "type": "DATASET", "confidence": 0.9223586320877075}]}], "introductionContent": [{"text": "Several initiatives have been taking place in the last years, targeting the concept of Edutainment, that is, education through entertainment.", "labels": [], "entities": []}, {"text": "Following this strategy, virtual characters have animated several museums allover the world: the 3D animated Hans Christian Andersen is capable of establishing multimodal conversations about the writer's life and tales), Max is a virtual character employed as guide in the Heinz Nixdorf Museums Forum), and Sergeant Blackwell, installed in the Cooper-Hewitt National Design Museum in New York, is used by the U.S. Army Recruiting Command as a hi-tech attraction and information source (Robinson et al., 2008).", "labels": [], "entities": []}, {"text": "DuARTE Digital ( and EDGAR are also examples of virtual characters for the Portuguese language with the same edutainment goal: DuARTE Digital answers questions about Cust\u00f3dia de Bel\u00e9m, a famous work of the Portuguese jewelry; EDGAR is a virtual butler that answers questions about MONSERRATE.", "labels": [], "entities": [{"text": "DuARTE Digital", "start_pos": 0, "end_pos": 14, "type": "DATASET", "confidence": 0.7809992730617523}, {"text": "MONSERRATE", "start_pos": 281, "end_pos": 291, "type": "DATASET", "confidence": 0.7991868257522583}]}, {"text": "Considering the previous mentioned agents, they all cover a specific domain of knowledge (although a general Question/Answering system was integrated in).", "labels": [], "entities": [{"text": "Question/Answering", "start_pos": 109, "end_pos": 127, "type": "TASK", "confidence": 0.598549465338389}]}, {"text": "However, as expected, people tend also to make small talk when interacting with these agents.", "labels": [], "entities": []}, {"text": "Therefore, it is important that these systems properly deal with it.", "labels": [], "entities": []}, {"text": "Several strategies are envisaged to this end and EDGAR is of no exception.", "labels": [], "entities": [{"text": "EDGAR", "start_pos": 49, "end_pos": 54, "type": "METRIC", "confidence": 0.5703319311141968}]}, {"text": "In this paper, we describe the platform behind EDGAR, which we developed aiming at the fast insertion of in-domain knowledge, and to deal with small talk.", "labels": [], "entities": []}, {"text": "This platform is currently in the process of being industrially applied by a company known for its expertise in building and deploying kiosks.", "labels": [], "entities": []}, {"text": "We will provide the hardware and software required to demonstrate EDGAR, both on a computer and on a tablet.", "labels": [], "entities": [{"text": "EDGAR", "start_pos": 66, "end_pos": 71, "type": "TASK", "confidence": 0.5393736958503723}]}, {"text": "This paper is organized as follows: in Section 2 we present EDGAR's development platform and describe typical interactions, in Section 3 we show how we move from in-domain interactions to small talk, and in Section 4 we present an analysis on collected logs and their initial evaluation results.", "labels": [], "entities": []}, {"text": "Finally, in Section 5 we present some conclusions and point to future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Edgar is more a domain-specific Question Answering (QA) than a task-oriented dialogue system.", "labels": [], "entities": [{"text": "Edgar", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7499276399612427}, {"text": "Question Answering (QA)", "start_pos": 32, "end_pos": 55, "type": "TASK", "confidence": 0.8328648626804351}]}, {"text": "Therefore, we evaluated it with the metrics typically used in QA.", "labels": [], "entities": []}, {"text": "The mapping of the different situations in true/false positives/negatives is explained in the following.", "labels": [], "entities": []}, {"text": "We have manually transcribed 1086 spoken utterances (in Portuguese), which were then labeled with the following tags, some depending on the answer given by EDGAR: \u2022 0: in-domain question incorrectly answered, although there was information in the knowledge sources (excluding Program D) to answer it; \u2022 1: out-of-domain question, incorrectly answered; \u2022 2: question correctly answered by Program D; \u2022 3: question correctly answered by using knowledge sources (excluding Program D); \u2022 4: in-domain question, incorrectly answered.", "labels": [], "entities": [{"text": "EDGAR", "start_pos": 156, "end_pos": 161, "type": "DATASET", "confidence": 0.7405112981796265}]}, {"text": "There is no information in the knowledge source to answer it, but it should be; \u2022 5: multiple questions, partially answered; \u2022 6: multiple questions, unanswered; \u2022 7: question with implicit information (there, him, etc.), unanswered; \u2022 8: question which is not \"ipsis verbis\" in the knowledge source, but has a paraphrase there and was not correctly answered; \u2022 9: question with a single word (garden, palace), unanswered; \u2022 10: question that we do not want the system to answer (some were answered, some were not).", "labels": [], "entities": []}, {"text": "The previous tags were mapped into: \u2022 true positives: questions marked with 2, 3 and 5; \u2022 true negatives: questions marked with 0 and 10 (the ones that were not answered by the system); \u2022 false positives: questions marked with 0 and 10 (the ones that were answered by the system); \u2022 false negatives: questions marked with 4, 6, 7, 8 and 9.", "labels": [], "entities": []}, {"text": "Then, two experiments were conducted: in the first, the NLU module was applied to the manual transcriptions; in the second, directly to the output of the ASR.", "labels": [], "entities": [{"text": "ASR", "start_pos": 154, "end_pos": 157, "type": "TASK", "confidence": 0.682773768901825}]}, {"text": "The ASR Word Error Rate (WER) is of 70%.", "labels": [], "entities": [{"text": "ASR Word Error Rate (WER)", "start_pos": 4, "end_pos": 29, "type": "METRIC", "confidence": 0.8302839015211377}]}, {"text": "However, we detect some problems in the way we were collecting the audio, and in more recent evaluations (by using 363 recent logs where previous problems were corrected), that error decreased to a WER of 52%, including speech from 111 children, 21 nonnative Portuguese speakers (thus, with a different pronunciation), 23 individuals not talking in Portuguese and 27 interactions where multiple speakers overlap.", "labels": [], "entities": [{"text": "error", "start_pos": 177, "end_pos": 182, "type": "METRIC", "confidence": 0.9740116596221924}, {"text": "WER", "start_pos": 198, "end_pos": 201, "type": "METRIC", "confidence": 0.9990418553352356}]}, {"text": "Here, we should refer the work presented in, where an evaluation of two virtual guides in a museum is presented.", "labels": [], "entities": []}, {"text": "They also had to deal with speakers from different ages and with question off-topic, and report a ASR with 57% WER (however they majority of their user are children: 76%).", "labels": [], "entities": [{"text": "ASR", "start_pos": 98, "end_pos": 101, "type": "METRIC", "confidence": 0.9938969016075134}, {"text": "WER", "start_pos": 111, "end_pos": 114, "type": "METRIC", "confidence": 0.9988906979560852}]}, {"text": "We are currently preparing anew corpus for evaluating the NLU module, however, the following results remain: in the best scenario, if transcription is perfect, the NLU module behaves as indicated in (manual transcriptions).", "labels": [], "entities": []}], "tableCaptions": []}