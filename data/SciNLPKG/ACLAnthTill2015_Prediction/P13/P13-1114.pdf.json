{"title": [], "abstractContent": [{"text": "Text normalization is an important first step towards enabling many Natural Language Processing (NLP) tasks over informal text.", "labels": [], "entities": [{"text": "Text normalization", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7987905144691467}]}, {"text": "While many of these tasks, such as parsing, perform the best over fully grammatically correct text, most existing text normalization approaches narrowly define the task in the word-to-word sense; that is, the task is seen as that of mapping all out-of-vocabulary non-standard words to their in-vocabulary standard forms.", "labels": [], "entities": [{"text": "parsing", "start_pos": 35, "end_pos": 42, "type": "TASK", "confidence": 0.9769365191459656}, {"text": "text normalization", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.7606000006198883}]}, {"text": "In this paper, we take a parser-centric view of normalization that aims to convert raw informal text into grammatically correct text.", "labels": [], "entities": []}, {"text": "To understand the real effect of nor-malization on the parser, we tie normal-ization performance directly to parser performance.", "labels": [], "entities": []}, {"text": "Additionally, we design a cus-tomizable framework to address the often overlooked concept of domain adaptability , and illustrate that the system allows for transfer to new domains with a minimal amount of data and effort.", "labels": [], "entities": []}, {"text": "Our experimental study over datasets from three domains demonstrates that our approach outper-forms not only the state-of-the-art word-to-word normalization techniques, but also manual word-to-word annotations.", "labels": [], "entities": [{"text": "word-to-word normalization", "start_pos": 130, "end_pos": 156, "type": "TASK", "confidence": 0.662763923406601}]}], "introductionContent": [{"text": "Text normalization is the task of transforming informal writing into its standard form in the language.", "labels": [], "entities": [{"text": "Text normalization", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7494673728942871}]}, {"text": "It is an important processing step fora wide range of Natural Language Processing (NLP) tasks such as text-to-speech synthesis, speech recognition, information extraction, parsing, and machine translation).", "labels": [], "entities": [{"text": "text-to-speech synthesis", "start_pos": 102, "end_pos": 126, "type": "TASK", "confidence": 0.7263877689838409}, {"text": "speech recognition", "start_pos": 128, "end_pos": 146, "type": "TASK", "confidence": 0.7449342608451843}, {"text": "information extraction, parsing", "start_pos": 148, "end_pos": 179, "type": "TASK", "confidence": 0.6590614765882492}, {"text": "machine translation", "start_pos": 185, "end_pos": 204, "type": "TASK", "confidence": 0.7199341356754303}]}, {"text": "* This work was conducted at IBM.", "labels": [], "entities": [{"text": "IBM", "start_pos": 29, "end_pos": 32, "type": "DATASET", "confidence": 0.8520575761795044}]}, {"text": "The use of normalization in these applications poses multiple challenges.", "labels": [], "entities": []}, {"text": "First, as it is most often conceptualized, normalization is seen as the task of mapping all out-of-vocabulary non-standard word tokens to their in-vocabulary standard forms.", "labels": [], "entities": []}, {"text": "However, the scope of the task can also be seen as much wider, encompassing whatever actions are required to convert the raw text into a fully grammatical sentence.", "labels": [], "entities": []}, {"text": "This broader definition of the normalization task may include modifying punctuation and capitalization, and adding, removing, or reordering words.", "labels": [], "entities": []}, {"text": "Second, as with other NLP techniques, normalization approaches are often focused on one primary domain of interest (e.g., Twitter data).", "labels": [], "entities": [{"text": "normalization", "start_pos": 38, "end_pos": 51, "type": "TASK", "confidence": 0.9692334532737732}]}, {"text": "Because the style of informal writing maybe different in different data sources, tailoring an approach towards a particular data source can improve performance in the desired domain.", "labels": [], "entities": []}, {"text": "However, this is often done at the cost of adaptability.", "labels": [], "entities": []}, {"text": "This work introduces a customizable normalization approach designed with domain transfer in mind.", "labels": [], "entities": [{"text": "domain transfer", "start_pos": 73, "end_pos": 88, "type": "TASK", "confidence": 0.7285090088844299}]}, {"text": "In short, customization is done by providing the normalizer with replacement generators, which we define in Section 3.", "labels": [], "entities": []}, {"text": "We show that the introduction of a small set of domain-specific generators and training data allows our model to outperform a set of competitive baselines, including state-of-the-art word-to-word normalization.", "labels": [], "entities": []}, {"text": "Additionally, the flexibility of the model also allows it to attempt to produce fully grammatical sentences, something not typically handled by word-to-word normalization approaches.", "labels": [], "entities": []}, {"text": "Another potential problem with state-of-the-art normalization is the lack of appropriate evaluation metrics.", "labels": [], "entities": []}, {"text": "The normalization task is most frequently motivated by pointing to the need for clean text for downstream processing applications, such as syntactic parsing.", "labels": [], "entities": [{"text": "normalization", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.9764158129692078}, {"text": "syntactic parsing", "start_pos": 139, "end_pos": 156, "type": "TASK", "confidence": 0.7001408040523529}]}, {"text": "However, most studies of normalization give little insight into whether and to what degree the normalization process improves the performance of the downstream application.", "labels": [], "entities": [{"text": "normalization", "start_pos": 25, "end_pos": 38, "type": "TASK", "confidence": 0.9679782390594482}]}, {"text": "For instance, it is unclear how performance measured by the typical normalization evaluation metrics of word error rate and BLEU score) translates into performance on a parsing task, where a well placed punctuation mark may provide more substantial improvements than changing a non-standard word form.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 104, "end_pos": 119, "type": "METRIC", "confidence": 0.7293637990951538}, {"text": "BLEU score", "start_pos": 124, "end_pos": 134, "type": "METRIC", "confidence": 0.9849842488765717}, {"text": "parsing task", "start_pos": 169, "end_pos": 181, "type": "TASK", "confidence": 0.9163975417613983}]}, {"text": "To address this problem, this work introduces an evaluation metric that ties normalization performance directly to the performance of a downstream dependency parser.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we discuss previous approaches to the normalization problem.", "labels": [], "entities": [{"text": "normalization problem", "start_pos": 51, "end_pos": 72, "type": "TASK", "confidence": 0.9562990069389343}]}, {"text": "Section 3 presents our normalization framework, including the actual normalization and learning procedures.", "labels": [], "entities": []}, {"text": "Our instantiation of this model is presented in Section 4.", "labels": [], "entities": []}, {"text": "In Section 5 we introduce the parser driven evaluation metric, and present experimental results of our model with respect to several baselines in three different domains.", "labels": [], "entities": []}, {"text": "Finally, we discuss our experimental study in Section 6 and conclude in Section 7.", "labels": [], "entities": []}, {"text": "took the first major look at the normalization problem, citing the need for normalized text for downstream applications.", "labels": [], "entities": [{"text": "normalization", "start_pos": 33, "end_pos": 46, "type": "TASK", "confidence": 0.9767839908599854}]}, {"text": "Unlike later works that would primarily focus on specific noisy data sets, their work is notable for attempting to develop normalization as a general process that could be applied to different domains.", "labels": [], "entities": [{"text": "normalization", "start_pos": 123, "end_pos": 136, "type": "TASK", "confidence": 0.9652416110038757}]}, {"text": "The recent rise of heavily informal writing styles such as Twitter and SMS messages set off anew round of interest in the normalization problem.", "labels": [], "entities": [{"text": "normalization problem", "start_pos": 122, "end_pos": 143, "type": "TASK", "confidence": 0.9280563294887543}]}], "datasetContent": [{"text": "In this section, we present an empirical study of our framework.", "labels": [], "entities": []}, {"text": "The study is done over datasets from three different domains.", "labels": [], "entities": []}, {"text": "The goal is to evaluate the framework in two aspects: (1) usefulness for downstream applications (specifically dependency parsing), and (2) domain adaptability.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.7933208644390106}]}, {"text": "A few different metrics have been used to evaluate normalizer performance, including word error rate and BLEU score.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 85, "end_pos": 100, "type": "METRIC", "confidence": 0.8160399993260702}, {"text": "BLEU score", "start_pos": 105, "end_pos": 115, "type": "METRIC", "confidence": 0.9864310622215271}]}, {"text": "While each metric has its pros and cons, they all rely on word-to-word matching and treat each word equally.", "labels": [], "entities": []}, {"text": "In this work, we aim to evaluate the performance of a normalizer based on how it affects the performance of downstream applications.", "labels": [], "entities": []}, {"text": "We find that the conventional metrics are not directly applicable, for several reasons.", "labels": [], "entities": []}, {"text": "To begin with, the assumption that words have equal weights is unlikely to hold.", "labels": [], "entities": []}, {"text": "Additionally, these metrics tend to ignore other important non-word information such as punctuation or capitalization.", "labels": [], "entities": []}, {"text": "They also cannot take into account other aspects that may have an impact on downstream performance, such as the word reordering as seen in the example in.", "labels": [], "entities": [{"text": "word reordering", "start_pos": 112, "end_pos": 127, "type": "TASK", "confidence": 0.6705934852361679}]}, {"text": "Therefore, we propose anew evaluation metric that directly equates normalization performance with the performance of a common downstream application-dependency parsing.", "labels": [], "entities": [{"text": "application-dependency parsing", "start_pos": 137, "end_pos": 167, "type": "TASK", "confidence": 0.6869732439517975}]}, {"text": "To realize our desired metric, we apply the following procedure.", "labels": [], "entities": []}, {"text": "First, we produce gold standard normalized data by manually normalizing sentences to their full grammatically correct form.", "labels": [], "entities": []}, {"text": "In addition to the word-to-word mapping performed in typical normalization gold standard generation, this annotation procedure includes all actions necessary to make the sentence grammatical, such as word reordering, modifying capitalization, and removing emoticons.", "labels": [], "entities": [{"text": "word reordering", "start_pos": 200, "end_pos": 215, "type": "TASK", "confidence": 0.6976852566003799}]}, {"text": "We then run an off-the-shelf dependency parser on the gold standard normalized data to produce our gold standard parses.", "labels": [], "entities": [{"text": "gold standard normalized data", "start_pos": 54, "end_pos": 83, "type": "DATASET", "confidence": 0.7717386335134506}]}, {"text": "Although the parser could still produce mistakes on the grammatical sentences, we feel that this provides a realistic benchmark for comparison, as it represents an upper bound on the possible performance of the parser, and avoids an expensive second round of manual annotation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Performance on Twitter dataset", "labels": [], "entities": [{"text": "Performance", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.947860836982727}, {"text": "Twitter dataset", "start_pos": 25, "end_pos": 40, "type": "DATASET", "confidence": 0.9130399227142334}]}, {"text": " Table 3: Performance on SMS dataset", "labels": [], "entities": [{"text": "Performance", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9516518115997314}, {"text": "SMS dataset", "start_pos": 25, "end_pos": 36, "type": "DATASET", "confidence": 0.8381665050983429}]}, {"text": " Table 4: Performance on call-center dataset", "labels": [], "entities": []}]}