{"title": [{"text": "Integrating Multiple Dependency Corpora for Inducing Wide-coverage Japanese CCG Resources", "labels": [], "entities": [{"text": "Integrating Multiple Dependency Corpora", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.8062200546264648}]}], "abstractContent": [{"text": "This paper describes a method of inducing wide-coverage CCG resources for Japanese.", "labels": [], "entities": []}, {"text": "While deep parsers with corpus-induced grammars have been emerging for some languages, those for Japanese have not been widely studied, mainly because most Japanese syntactic resources are dependency-based.", "labels": [], "entities": []}, {"text": "Our method first integrates multiple dependency-based corpora into phrase structure trees and then converts the trees into CCG derivations.", "labels": [], "entities": []}, {"text": "The method is empirically evaluated in terms of the coverage of the obtained lexicon and the accuracy of parsing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9995842576026917}]}], "introductionContent": [{"text": "Syntactic parsing for Japanese has been dominated by a dependency-based pipeline in which chunk-based dependency parsing is applied and then semantic role labeling is performed on the dependencies ().", "labels": [], "entities": [{"text": "Syntactic parsing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9089293777942657}, {"text": "chunk-based dependency parsing", "start_pos": 90, "end_pos": 120, "type": "TASK", "confidence": 0.6749015053113302}, {"text": "semantic role labeling", "start_pos": 141, "end_pos": 163, "type": "TASK", "confidence": 0.6106662750244141}]}, {"text": "This dominance is mainly because chunkbased dependency analysis looks most appropriate for Japanese syntax due to its morphosyntactic typology, which includes agglutination and scrambling.", "labels": [], "entities": [{"text": "chunkbased dependency analysis", "start_pos": 33, "end_pos": 63, "type": "TASK", "confidence": 0.7953219215075175}]}, {"text": "However, it is also true that this type of analysis has prevented us from deeper syntactic analysis such as deep parsing and logical inference (, both of which have been surpassing shallow parsing-based approaches in languages like English.", "labels": [], "entities": []}, {"text": "In this paper, we present our work on inducing wide-coverage Japanese resources based on combinatory categorial grammar (CCG)).", "labels": [], "entities": []}, {"text": "Our work is basically an extension of a seminal work on CCGbank, in which the phrase structure trees of the Penn Treebank (PTB) are converted into CCG derivations and a wide-coverage CCG lexicon is then extracted from these derivations.", "labels": [], "entities": [{"text": "Penn Treebank (PTB)", "start_pos": 108, "end_pos": 127, "type": "DATASET", "confidence": 0.973976218700409}]}, {"text": "As CCGbank has enabled a variety of outstanding works on wide-coverage deep parsing for English, our resources are expected to significantly contribute to Japanese deep parsing.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 3, "end_pos": 10, "type": "DATASET", "confidence": 0.9716534614562988}, {"text": "wide-coverage deep parsing", "start_pos": 57, "end_pos": 83, "type": "TASK", "confidence": 0.5456486145655314}, {"text": "Japanese deep parsing", "start_pos": 155, "end_pos": 176, "type": "TASK", "confidence": 0.5905020435651144}]}, {"text": "The application of the CCGbank method to Japanese is not trivial, as resources like PTB are not available in Japanese.", "labels": [], "entities": [{"text": "PTB", "start_pos": 84, "end_pos": 87, "type": "DATASET", "confidence": 0.9224357604980469}]}, {"text": "The widely used resources for parsing research are the Kyoto corpus () and the NAIST text corpus (, both of which are based on the dependency structures of chunks.", "labels": [], "entities": [{"text": "parsing", "start_pos": 30, "end_pos": 37, "type": "TASK", "confidence": 0.9710327386856079}, {"text": "Kyoto corpus", "start_pos": 55, "end_pos": 67, "type": "DATASET", "confidence": 0.9686765670776367}, {"text": "NAIST text corpus", "start_pos": 79, "end_pos": 96, "type": "DATASET", "confidence": 0.9609732627868652}]}, {"text": "Moreover, the relation between chunk-based dependency structures and CCG derivations is not obvious.", "labels": [], "entities": []}, {"text": "In this work, we propose a method to integrate multiple dependency-based corpora into phrase structure trees augmented with predicate argument relations.", "labels": [], "entities": []}, {"text": "We can then convert the phrase structure trees into CCG derivations.", "labels": [], "entities": []}, {"text": "In the following, we describe the details of the integration method as well as Japanese-specific issues in the conversion into CCG derivations.", "labels": [], "entities": []}, {"text": "The method is empirically evaluated in terms of the quality of the corpus conversion, the coverage of the obtained lexicon, and the accuracy of parsing with the obtained grammar.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9992929697036743}]}, {"text": "Additionally, we discuss problems that remain in Japanese resources from the viewpoint of developing CCG derivations.", "labels": [], "entities": []}, {"text": "There are three primary contributions of this paper: 1) we show the first comprehensive results for Japanese CCG parsing, 2) we present a methodology for integrating multiple dependency-based re- Figure 2: Combinatory rules (used in the current implementation).", "labels": [], "entities": [{"text": "Japanese CCG parsing", "start_pos": 100, "end_pos": 120, "type": "TASK", "confidence": 0.6122675836086273}]}, {"text": "sources to induce CCG derivations, and 3) we investigate the possibility of further improving CCG analysis by additional resources.", "labels": [], "entities": [{"text": "CCG analysis", "start_pos": 94, "end_pos": 106, "type": "TASK", "confidence": 0.8683964908123016}]}], "datasetContent": [{"text": "We used the following for the implementation of our resources: Kyoto corpus ver.", "labels": [], "entities": [{"text": "Kyoto corpus ver.", "start_pos": 63, "end_pos": 80, "type": "DATASET", "confidence": 0.9789193570613861}]}, {"text": "1.5 3 , and JP corpus ver.", "labels": [], "entities": [{"text": "JP corpus ver.", "start_pos": 12, "end_pos": 26, "type": "DATASET", "confidence": 0.9321889281272888}]}, {"text": "1.0 4 . The integrated corpus is divided into training, development, and final test sets following the standard data split in previous works on Japanese dependency parsing ().", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 153, "end_pos": 171, "type": "TASK", "confidence": 0.6959167122840881}]}, {"text": "The details of these resources are shown in. shows the number of successful conversions performed by our method.", "labels": [], "entities": []}, {"text": "In total, we obtained 22,820 CCG derivations from 24,283 sentences (in the training set), resulting in the total conversion rate of 93.98%.", "labels": [], "entities": []}, {"text": "we lost more sentences in Step 2 than in Step 1.", "labels": [], "entities": []}, {"text": "This is natural because Step 2 imposed more restrictions on resulting structures and therefore detected more discrepancies including compounding errors.", "labels": [], "entities": []}, {"text": "Our conversion rate is about 5.5 points lower than the English counterpart.", "labels": [], "entities": [{"text": "conversion", "start_pos": 4, "end_pos": 14, "type": "TASK", "confidence": 0.8084730505943298}]}, {"text": "Manual investigation of the sampled derivations would be beneficial for the conversion improvement.", "labels": [], "entities": [{"text": "conversion", "start_pos": 76, "end_pos": 86, "type": "TASK", "confidence": 0.964218020439148}]}, {"text": "For the lexicon extraction from the CCGbank, we obtained 699 types of lexical categories from 616,305 word tokens.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 36, "end_pos": 43, "type": "DATASET", "confidence": 0.9780099987983704}]}, {"text": "After lexical reduction, the number of categories decreased to 454, which in turn may produce 5,342 categories by lexical expansion.", "labels": [], "entities": []}, {"text": "The average number of categories fora word type was 11.68 as a result.", "labels": [], "entities": []}, {"text": "Following the evaluation criteria in, we measured the coverage of the grammar on unseen texts.", "labels": [], "entities": []}, {"text": "First, we obtained CCG derivations for evaluation sets by applying our conversion method and then used these derivations as gold standard.", "labels": [], "entities": []}, {"text": "Lexical coverage indicates the number of words to which the grammar assigns a gold standard category.", "labels": [], "entities": []}, {"text": "Sentential coverage indicates the number of sentences in which all words are assigned gold standard categories . shows the evaluation results.", "labels": [], "entities": [{"text": "Sentential coverage", "start_pos": 0, "end_pos": 19, "type": "METRIC", "confidence": 0.9050312936306}]}, {"text": "Lexical coverage was 99.40% with rare word treatment, which is in the same level as the case of the English CCG parser C&C.", "labels": [], "entities": [{"text": "Lexical coverage", "start_pos": 0, "end_pos": 16, "type": "METRIC", "confidence": 0.48914872109889984}, {"text": "English CCG parser C&C", "start_pos": 100, "end_pos": 122, "type": "DATASET", "confidence": 0.8315512537956238}]}, {"text": "We also measured coverage in a \"weak\" sense, which means the number of sentences that are given at least one analysis (not necessarily correct) by the obtained grammar.", "labels": [], "entities": [{"text": "coverage", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9858863353729248}]}, {"text": "This number was 99.12 % and 99.06 % for the development and the test set, respectively, which is sufficiently high for wide-coverage parsing of real-world texts.", "labels": [], "entities": [{"text": "wide-coverage parsing of real-world texts", "start_pos": 119, "end_pos": 160, "type": "TASK", "confidence": 0.7559699833393096}]}, {"text": "Finally, we evaluated the parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 26, "end_pos": 33, "type": "TASK", "confidence": 0.9746872782707214}, {"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9355924725532532}]}, {"text": "We employed the parser and the supertagger of, specifically, its generalized modules for lexicalized grammars.", "labels": [], "entities": []}, {"text": "We trained log-linear models in the same way as) using the training set as training data.", "labels": [], "entities": []}, {"text": "Feature sets were simply borrowed from an English parser; no tuning was performed.", "labels": [], "entities": []}, {"text": "Following conventions in research on Japanese dependency parsing, gold morphological analysis results were input to a parser.", "labels": [], "entities": [{"text": "Japanese dependency parsing", "start_pos": 37, "end_pos": 64, "type": "TASK", "confidence": 0.5975694457689921}]}, {"text": "Following C&C, the evaluation measure was precision and recall over dependencies, where a dependency is defined as a 4-tuple: ahead of a functor, a functor category, an argument slot, and ahead of an argument.", "labels": [], "entities": [{"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9992085099220276}, {"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9971150159835815}]}, {"text": "shows the parsing accuracy on the development and the test sets.", "labels": [], "entities": [{"text": "parsing", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9476132392883301}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9707946181297302}]}, {"text": "The supertagging accuracy is presented in the upper table.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9863124489784241}]}, {"text": "While our coverage was almost the same as C&C, the performance of our supertagger and parser was lower.", "labels": [], "entities": [{"text": "coverage", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9882494211196899}]}, {"text": "To improve the performance, tuning disambiguation models for Japanese is a possible approach.", "labels": [], "entities": []}, {"text": "Comparing the parser's performance with previous works on Japanese dependency parsing is difficult as our figures are not directly comparable to theirs.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.7195744514465332}]}, {"text": "reported the accuracy of their parser as 88.48 and 95.09 Since a gold derivation can logically be obtained if gold categories are assigned to all words in a sentence, sentential coverage means that the obtained lexicon has the ability to produce exactly correct derivations for those sentences.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9995101690292358}]}], "tableCaptions": [{"text": " Table 4: Statistics of input linguistic resources.", "labels": [], "entities": []}, {"text": " Table 5: Statistics of corpus conversion.", "labels": [], "entities": [{"text": "corpus conversion", "start_pos": 24, "end_pos": 41, "type": "TASK", "confidence": 0.732258215546608}]}, {"text": " Table 6: Sentential and lexical coverage.", "labels": [], "entities": []}, {"text": " Table 7: Parsing accuracy. LP, LR and LF refer to  labeled precision, recall, and F-score respectively.  UP, UR, and UF are for unlabeled.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9585994482040405}, {"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9462189674377441}, {"text": "recall", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.995658278465271}, {"text": "F-score", "start_pos": 83, "end_pos": 90, "type": "METRIC", "confidence": 0.9959272742271423}, {"text": "UP", "start_pos": 106, "end_pos": 108, "type": "METRIC", "confidence": 0.988929808139801}, {"text": "UR", "start_pos": 110, "end_pos": 112, "type": "METRIC", "confidence": 0.8198264241218567}]}]}