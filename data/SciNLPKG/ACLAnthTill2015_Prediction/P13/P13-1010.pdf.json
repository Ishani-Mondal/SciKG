{"title": [], "abstractContent": [{"text": "We propose a computationally efficient graph-based approach for local coherence modeling.", "labels": [], "entities": [{"text": "local coherence modeling", "start_pos": 64, "end_pos": 88, "type": "TASK", "confidence": 0.6203535298506418}]}, {"text": "We evaluate our system on three tasks: sentence ordering, summary coherence rating and readability assessment.", "labels": [], "entities": [{"text": "sentence ordering", "start_pos": 39, "end_pos": 56, "type": "TASK", "confidence": 0.7312856763601303}]}, {"text": "The performance is comparable to entity grid based approaches though these rely on a computationally expensive training phase and face data sparsity problems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many NLP applications which processor generate texts rely on information about local coherence, i.e. information about which entities occur in which sentence and how the entities are distributed in the text.", "labels": [], "entities": []}, {"text": "This led to the development of many theories and models accounting for local coherence.", "labels": [], "entities": []}, {"text": "One popular model, the centering model (, uses a ranking of discourse entities realized in particular sentences and computes transitions between adjacent sentences to provide insight in the felicity of texts.", "labels": [], "entities": []}, {"text": "Centering models local coherence rather generally and has been applied to the generation of referring expressions (), to resolve pronouns, to score essays (), to arrange sentences in the correct order (, and to many other tasks.", "labels": [], "entities": []}, {"text": "observe that it is not clear how to set parameters in the centering model so that optimal performance in different tasks and languages can be achieved.", "labels": [], "entities": []}, {"text": "criticize research on centering to be too dependent on manually annotated input.", "labels": [], "entities": []}, {"text": "This led them to propose a local coherence model relying on a more parsimonious representation, the entity grid model.", "labels": [], "entities": []}, {"text": "The entity grid is a two dimensional array where the rows represent sentences and the columns discourse entities.", "labels": [], "entities": []}, {"text": "From this grid derive probabilities of transitions between adjacent sentences which are used as features for machine learning algorithms.", "labels": [], "entities": []}, {"text": "They evaluate this approach successfully on sentence ordering, summary coherence rating, and readability assessment.", "labels": [], "entities": [{"text": "sentence ordering", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.7382073998451233}]}, {"text": "However, their approach has some disadvantages which they point out themselves: data sparsity, domain dependence and computational complexity, especially in terms of feature space issues while building their model (,).", "labels": [], "entities": []}, {"text": "In order to overcome these problems we propose to represent entities in a graph and then model local coherence by applying centrality measures to the nodes in the graph (Section 3).", "labels": [], "entities": []}, {"text": "We claim that a graph is a more powerful representation for local coherence than the entity grid which is restricted to transitions between adjacent sentences.", "labels": [], "entities": []}, {"text": "The graph can easily span the entire text without leading to computational complexity and data sparsity problems.", "labels": [], "entities": []}, {"text": "Similar to the application of graph-based methods in other areas of NLP (e.g. work on word sense disambiguation by; for an overview over graph-based methods in NLP see) we model local coherence by relying only on centrality measures applied to the nodes in the graph.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 86, "end_pos": 111, "type": "TASK", "confidence": 0.6294872065385183}]}, {"text": "We apply our graph-based model to the three tasks handled by to show that it provides the same flexibility over disparate tasks as the entity grid model: sentence ordering (Section 4.1), summary coherence ranking (Section 4.2), and readability assessment (Section 4.3).", "labels": [], "entities": [{"text": "sentence ordering", "start_pos": 154, "end_pos": 171, "type": "TASK", "confidence": 0.740095317363739}, {"text": "readability assessment", "start_pos": 232, "end_pos": 254, "type": "TASK", "confidence": 0.7114993631839752}]}, {"text": "In the The Turkish government fell after mob-tie allegations.", "labels": [], "entities": []}, {"text": "Turkey's constitution mandates a secular republic despite its Muslim majority.", "labels": [], "entities": []}, {"text": "Military and secular leaders pressured President Demirel to keep the Islamic-oriented Virtue Party on the fringe.", "labels": [], "entities": []}, {"text": "Business leaders feared Virtue would alienate the EU.: Excerpt of a manual summary M from DUC2003 experiments sections, we discuss the impact of genre and stylistic properties of documents on the local coherence computation.", "labels": [], "entities": [{"text": "DUC2003 experiments", "start_pos": 90, "end_pos": 109, "type": "DATASET", "confidence": 0.9293729662895203}]}, {"text": "We also show that, though we do not need a computationally expensive learning phase, our model achieves state-ofthe-art performance.", "labels": [], "entities": []}, {"text": "From this we conclude that a graph is an alternative to the entity grid model: it is computationally more tractable for modeling local coherence and does not suffer from data sparsity problems (Section 5).", "labels": [], "entities": []}, {"text": "introduced the entity grid, a method for local coherence modeling that captures the distribution of discourse entities across sentences in a text.", "labels": [], "entities": []}], "datasetContent": [{"text": "We compare our model with the entity grid approach and evaluate the influence of the different weighting schemes used in the projection graphs, either PW or P Acc , where weights are potentially decreased by distance information Dist.", "labels": [], "entities": []}, {"text": "Our baseline corresponds to local coherence computation based on the unweighted projection graph P U . For graph construction, all nouns in a document are considered as discourse entities, even those which do not head NPs as this is beneficial for the entity grid model as described in.", "labels": [], "entities": [{"text": "graph construction", "start_pos": 107, "end_pos": 125, "type": "TASK", "confidence": 0.809099942445755}]}, {"text": "We also propose to use a coreference resolution system and consider coreferent entities to be the same discourse entity.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.8738122880458832}]}, {"text": "To do so, we use one of the top performing systems from the CoNLL 2012 shared task.", "labels": [], "entities": [{"text": "CoNLL 2012 shared task", "start_pos": 60, "end_pos": 82, "type": "DATASET", "confidence": 0.9337252378463745}]}, {"text": "As the coreference resolution system is trained on well-formed textual documents and expects a correct sentence ordering, we use in all our experiments only features that do not rely on sentence order (e.g. alias relations, string matching, etc.).", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 7, "end_pos": 29, "type": "TASK", "confidence": 0.9044425189495087}, {"text": "string matching", "start_pos": 224, "end_pos": 239, "type": "TASK", "confidence": 0.7168935686349869}]}, {"text": "Grammatical information associated with each entity is extracted automatically thanks to the Stanford parser using dependency conversion).", "labels": [], "entities": []}, {"text": "Syntactic weights in the bipartite graph are defined following the linguistic intuition that subjects are more important than objects, which are themselves more important than other syntactic roles.", "labels": [], "entities": []}, {"text": "Preliminary experiments show that as long as weight assignment follows the scheme S > O > X, then more coherent documents are associated with a higher local coherence value than less coherent document in 90% of cases (while this value equals 49% when no restriction is given on syntactic weights order).", "labels": [], "entities": []}, {"text": "Moreover, as the local coherence computation is a linear combination of the syntactic weights, the function is smooth and no large variations of the local coherence values are observed for small changes of weights' values.", "labels": [], "entities": []}, {"text": "For these reasons, weights w(e, s i ) are set as follows: 3 if e is subject in s i , 2 if e is an object and 1 otherwise.", "labels": [], "entities": []}, {"text": "We evaluate the ability of our graph-based model to estimate the local coherence of a textual document with three different experiments.", "labels": [], "entities": []}, {"text": "First, we perfom a sentence ordering task (Section 4.1) as proposed in.", "labels": [], "entities": [{"text": "sentence ordering task", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.789261649052302}]}, {"text": "Then, as the first task uses \"artificial\" documents, we also work on two other tasks that involve \"real\" documents: summary coherence rating (Section 4.2), and readability assessment (Section 4.3).", "labels": [], "entities": [{"text": "summary coherence rating", "start_pos": 116, "end_pos": 140, "type": "METRIC", "confidence": 0.774325450261434}]}, {"text": "In these experiments, distance computation and syntactic weights are the same for all tasks and all corpora.", "labels": [], "entities": []}, {"text": "However, the model is also flexible and can be adaptated to the different tasks by optimizing the parameters on a development data set, which may give better results.", "labels": [], "entities": []}, {"text": "The objective of the readability assessment task is to evaluate how difficult to read a document is.", "labels": [], "entities": []}, {"text": "We perform this task on the data used by, a corpus collected originally by from the Encyclopedia Britannica and its version for children, the Britannica Elementary.", "labels": [], "entities": [{"text": "Encyclopedia Britannica", "start_pos": 84, "end_pos": 107, "type": "DATASET", "confidence": 0.8408012092113495}, {"text": "Britannica Elementary", "start_pos": 142, "end_pos": 163, "type": "DATASET", "confidence": 0.9136156141757965}]}, {"text": "Both versions contain 107 articles.", "labels": [], "entities": []}, {"text": "In Encyclopedia Britannica, documents are composed by an average of 83.1 sentences while they contain 36.6 sentences in Britannica Elementary.", "labels": [], "entities": [{"text": "Britannica Elementary", "start_pos": 120, "end_pos": 141, "type": "DATASET", "confidence": 0.9522096812725067}]}, {"text": "Although these texts are not explicitly annotated with grade levels, they represent two broad readability categories.", "labels": [], "entities": []}, {"text": "In order to estimate the complexity of a document, our model computes the local coherence score for each article in the two categories.", "labels": [], "entities": []}, {"text": "The article associated with the higher score is considered to be the more readable as it is more coherent, needing less interpretation from the reader than a document associated with a lower local coherence score.", "labels": [], "entities": []}, {"text": "Values presented in the following section correspond to accuracy, where the system is correct if it assigns the higher local coherence score to the most \"easy to read\" document, and F-measure.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9996395111083984}, {"text": "F-measure", "start_pos": 182, "end_pos": 191, "type": "METRIC", "confidence": 0.9978353381156921}]}], "tableCaptions": [{"text": " Table 3: Discrimination, reproduced baselines  (B&L: Barzilay and Lapata (2008); E&C Elsner  and Charniak", "labels": [], "entities": []}, {"text": " Table 4: Insertion, reproduced baselines vs. graph- based", "labels": [], "entities": []}, {"text": " Table 5: Summary Coherence Rating, reported re- sults from", "labels": [], "entities": [{"text": "Summary Coherence Rating", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.6540821393330892}]}, {"text": " Table 6: Readability, reported results from Barzi- lay and Lapata (2008) vs. graph-based (S&O:  Schwarm and Ostendorf (2005))", "labels": [], "entities": []}, {"text": " Table 7: Readability, comparison between Ency- clopedia Britannica, Britannica Elementary and  Britannica Student", "labels": [], "entities": [{"text": "Ency- clopedia Britannica", "start_pos": 42, "end_pos": 67, "type": "DATASET", "confidence": 0.8764856606721878}, {"text": "Britannica Elementary", "start_pos": 69, "end_pos": 90, "type": "DATASET", "confidence": 0.7794412672519684}, {"text": "Britannica Student", "start_pos": 96, "end_pos": 114, "type": "DATASET", "confidence": 0.8731051087379456}]}]}