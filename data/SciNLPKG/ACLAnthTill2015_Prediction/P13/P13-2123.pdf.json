{"title": [{"text": "A Lightweight and High Performance Monolingual Word Aligner", "labels": [], "entities": [{"text": "Monolingual Word Aligner", "start_pos": 35, "end_pos": 59, "type": "TASK", "confidence": 0.6045719186464945}]}], "abstractContent": [{"text": "Fast alignment is essential for many natural language tasks.", "labels": [], "entities": [{"text": "Fast alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.5358038246631622}]}, {"text": "But in the setting of monolingual alignment, previous work has not been able to align more than one sentence pair per second.", "labels": [], "entities": [{"text": "monolingual alignment", "start_pos": 22, "end_pos": 43, "type": "TASK", "confidence": 0.691303551197052}]}, {"text": "We describe a dis-criminatively trained monolingual word aligner that uses a Conditional Random Field to globally decode the best alignment with features drawn from source and target sentences.", "labels": [], "entities": []}, {"text": "Using just part-of-speech tags and WordNet as external resources, our aligner gives state-of-the-art result, while being an order-of-magnitude faster than the previous best performing system.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 35, "end_pos": 42, "type": "DATASET", "confidence": 0.9654290080070496}]}], "introductionContent": [{"text": "In statistical machine translation, alignment is typically done as a one-off task during training.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.683376133441925}, {"text": "alignment", "start_pos": 36, "end_pos": 45, "type": "TASK", "confidence": 0.9434022307395935}]}, {"text": "However for monolingual tasks, like recognizing textual entailment or question answering, alignment happens repeatedly: once or multiple times per test item.", "labels": [], "entities": [{"text": "recognizing textual entailment", "start_pos": 36, "end_pos": 66, "type": "TASK", "confidence": 0.830489993095398}, {"text": "question answering", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.7688358426094055}]}, {"text": "Therefore, the efficiency of the aligner is of utmost importance for monolingual alignment tasks.", "labels": [], "entities": []}, {"text": "Monolingual word alignment also has a variety of distinctions than the bilingual case, for example: there is often less training data but more lexical resources available; semantic relatedness maybe cued by distributional word similarities; and, both the source and target sentences share the same grammar.", "labels": [], "entities": [{"text": "Monolingual word alignment", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7593644460042318}]}, {"text": "These distinctions suggest a model design that utilizes arbitrary features (to make use of word similarity measure and lexical resources) and exploits deeper sentence structures (especially in the case of major languages where robust parsers are available).", "labels": [], "entities": []}, {"text": "In this setting the balance between precision and speed becomes an issue: while we might leverage an extensive NLP pipeline fora * Performed while faculty at Johns Hopkins University.", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9993507266044617}, {"text": "speed", "start_pos": 50, "end_pos": 55, "type": "METRIC", "confidence": 0.9748069643974304}]}, {"text": "language like English, such pipelines can be computationally expensive.", "labels": [], "entities": []}, {"text": "One earlier attempt, the MANLI system ( , used roughly 5GB of lexical resources and took 2 seconds per alignment, making it hard to be deployed and run in large scale.", "labels": [], "entities": [{"text": "MANLI system", "start_pos": 25, "end_pos": 37, "type": "DATASET", "confidence": 0.9212737679481506}]}, {"text": "On the other extreme, a simple non-probabilistic Tree Edit Distance (TED) model (c.f.", "labels": [], "entities": []}, {"text": "\u00a74.2) is able to align 10, 000 pairs per second when the sentences are pre-parsed, but with significantly reduced performance.", "labels": [], "entities": []}, {"text": "Trying to embrace the merits of both worlds, we introduce a discriminative aligner that is able to align tens to hundreds of sentence pairs per second, and needs access only to a POS tagger and WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 194, "end_pos": 201, "type": "DATASET", "confidence": 0.974638819694519}]}, {"text": "This aligner gives state-of-the-art performance on the MSR RTE2 alignment dataset, is faster than previous work, and we release it publicly as the first open-source monolingual word aligner: Jacana.Align.", "labels": [], "entities": [{"text": "MSR RTE2 alignment dataset", "start_pos": 55, "end_pos": 81, "type": "DATASET", "confidence": 0.8827578276395798}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results on the 800 pairs of test data. E% stands", "labels": [], "entities": [{"text": "E", "start_pos": 49, "end_pos": 50, "type": "METRIC", "confidence": 0.9922587275505066}]}, {"text": " Table 2: Alignment runtime in seconds per sentence pair on", "labels": [], "entities": [{"text": "Alignment runtime", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7710431814193726}]}, {"text": " Table 3: Performance without POS and/or Word- Net features.", "labels": [], "entities": [{"text": "Word- Net", "start_pos": 41, "end_pos": 50, "type": "DATASET", "confidence": 0.8430529435475668}]}]}