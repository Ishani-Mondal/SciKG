{"title": [{"text": "Stop-probability estimates computed on a large corpus improve Unsupervised Dependency Parsing", "labels": [], "entities": []}], "abstractContent": [{"text": "Even though the quality of unsupervised dependency parsers grows, they often fail in recognition of very basic dependencies.", "labels": [], "entities": []}, {"text": "In this paper, we exploit a prior knowledge of STOP-probabilities (whether a given word has any children in a given direction), which is obtained from a large raw corpus using the reducibility principle.", "labels": [], "entities": []}, {"text": "By incorporating this knowledge into Dependency Model with Valence, we managed to considerably outperform the state-of-the-art results in terms of average attachment score over 20 treebanks from CoNLL 2006 and 2007 shared tasks.", "labels": [], "entities": [{"text": "CoNLL 2006 and 2007 shared tasks", "start_pos": 195, "end_pos": 227, "type": "DATASET", "confidence": 0.8787066638469696}]}], "introductionContent": [{"text": "The task of unsupervised dependency parsing (which strongly relates to the grammar induction task) has become popular in the last decade, and its quality has been greatly increasing during this period.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.6833986639976501}, {"text": "grammar induction task", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.7493244806925455}]}, {"text": "The first implementation of Dependency Model with Valence (DMV) () with a simple inside-outside inference algorithm) achieved 36% attachment score on English and was the first system outperforming the adjacent-word baseline.", "labels": [], "entities": [{"text": "attachment score", "start_pos": 130, "end_pos": 146, "type": "METRIC", "confidence": 0.9803436100482941}]}, {"text": "Current attachment scores of state-of-the-art unsupervised parsers are higher than 50% for many languages (.", "labels": [], "entities": [{"text": "attachment", "start_pos": 8, "end_pos": 18, "type": "METRIC", "confidence": 0.9770912528038025}]}, {"text": "This is still far below the supervised approaches, but their indisputable advantage is the fact that no annotated treebanks are needed and the induced structures are not burdened by any linguistic conventions.", "labels": [], "entities": []}, {"text": "Moreover, The adjacent-word baseline is a dependency tree in which each word is attached to the previous (or the following) word.", "labels": [], "entities": []}, {"text": "The attachment score of 35.9% on all the WSJ test sentences was taken from supervised parsers always only simulate the treebanks they were trained on, whereas unsupervised parsers have an ability to befitted to different particular applications.", "labels": [], "entities": [{"text": "attachment score", "start_pos": 4, "end_pos": 20, "type": "METRIC", "confidence": 0.9610952436923981}, {"text": "WSJ test sentences", "start_pos": 41, "end_pos": 59, "type": "DATASET", "confidence": 0.8972969253857931}]}, {"text": "Some of the current approaches are based on the DMV, a generative model where the grammar is expressed by two probability distributions: P choose (c d |c h , dir ), which generates anew child c d attached to the head ch in the direction dir (left or right), and P stop (STOP |c h , dir , \u00b7 \u00b7 \u00b7 ), which makes a decision whether to generate another child of ch in the direction dir or not.", "labels": [], "entities": []}, {"text": "Such a grammar is then inferred using sampling or variational methods.", "labels": [], "entities": []}, {"text": "Unfortunately, there are still cases where the inferred grammar is very different from the grammar we would expect, e.g. verbs become leaves instead of governing the sentences. and made some efforts to boost the verbocentricity of the inferred structures; however, both of the approaches require manual identification of the POS tags marking the verbs, which renders them useless when unsupervised POS tags are employed.", "labels": [], "entities": []}, {"text": "The main contribution of this paper is a considerable improvement of unsupervised parsing quality by estimating the P stop probabilities externally using a very large corpus, and employing this prior knowledge in the standard inference of DMV.", "labels": [], "entities": []}, {"text": "The estimation is done using the reducibility principle introduced in (Mare\u010dek and\u017dabokrtsk\u00b4yand\u02c7and\u017dabokrtsk\u00b4and\u017dabokrtsk\u00b4y, 2012).", "labels": [], "entities": [{"text": "Mare\u010dek and\u017dabokrtsk\u00b4yand\u02c7and\u017dabokrtsk\u00b4and\u017dabokrtsk\u00b4y, 2012)", "start_pos": 71, "end_pos": 131, "type": "DATASET", "confidence": 0.8811950922012329}]}, {"text": "The reducibility principle postulates that if a word (or a sequence of words) can be removed from a sentence without violating its grammatical correctness, it is a leaf (or a subtree) in its dependency structure.", "labels": [], "entities": []}, {"text": "For the purposes of this paper, we assume the following hypothesis: If a sequence of words can be removed from a sentence without violating its grammatical correctness, no word outside the sequence depends on any word in the sequence.", "labels": [], "entities": []}, {"text": "Our hypothesis is a generalization of the original hypothesis since it allows a reducible sequence to form several adjacent subtrees.", "labels": [], "entities": []}, {"text": "Let's outline the connection between the P stop probabilities and the property of reducibility.", "labels": [], "entities": []}, {"text": "shows an example of a dependency tree.", "labels": [], "entities": []}, {"text": "Sequences of reducible words are marked by thick lines below the sentence.", "labels": [], "entities": []}, {"text": "Consider for example the word \"further\".", "labels": [], "entities": []}, {"text": "It can be removed and thus, according to our hypothesis, no other word depends on it.", "labels": [], "entities": []}, {"text": "Therefore, we can deduce that the P stop probability for such word is high both for the left and for the right direction.", "labels": [], "entities": [{"text": "P stop probability", "start_pos": 34, "end_pos": 52, "type": "METRIC", "confidence": 0.956409215927124}]}, {"text": "The phrase \"for further discussions\" is reducible as well and we can deduce that the P stop of its first word (\"for\") in the left direction is high since it cannot have any left children.", "labels": [], "entities": [{"text": "P stop", "start_pos": 85, "end_pos": 91, "type": "METRIC", "confidence": 0.9602532386779785}]}, {"text": "We do not know anything about its right children, because they can be located within the sequence (and there is really one in).", "labels": [], "entities": []}, {"text": "Similarly, the word \"discussions\", which is the last word in this sequence, cannot have any right children and we can estimate that its right P stop probability is high.", "labels": [], "entities": [{"text": "right P stop probability", "start_pos": 136, "end_pos": 160, "type": "METRIC", "confidence": 0.6841380596160889}]}, {"text": "On the other hand, non-reducible words such, as the verb \"asked\" in our example, can have children, and therefore their P stop can be estimated as low for both directions.", "labels": [], "entities": [{"text": "P stop", "start_pos": 120, "end_pos": 126, "type": "METRIC", "confidence": 0.9541475176811218}]}, {"text": "The most difficult task in this approach is to automatically recognize reducible sequences.", "labels": [], "entities": []}, {"text": "This problem, together with the estimation of the stopprobabilities, is described in Section 3.", "labels": [], "entities": [{"text": "stopprobabilities", "start_pos": 50, "end_pos": 67, "type": "METRIC", "confidence": 0.9489268064498901}]}, {"text": "Our model, not much different from the classic DMV, is introduced in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 describes the inference algorithm based on Gibbs sampling.", "labels": [], "entities": []}, {"text": "Experiments and results are discussed in Section 6.", "labels": [], "entities": [{"text": "Section 6", "start_pos": 41, "end_pos": 50, "type": "DATASET", "confidence": 0.8575424551963806}]}, {"text": "Section 7 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Wikipedia texts statistics: total number of  tokens and number of reducible sequences found  in them.", "labels": [], "entities": []}, {"text": " Table 2: Attachment scores on CoNLL 2006 and 2007 data. Standard deviations are provided in brack- ets. DMV model using standard P dmv  stop probability is compared with DMV with P dmv +est", "labels": [], "entities": [{"text": "Attachment", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9746342897415161}, {"text": "CoNLL 2006 and 2007 data", "start_pos": 31, "end_pos": 55, "type": "DATASET", "confidence": 0.9599470734596253}]}]}