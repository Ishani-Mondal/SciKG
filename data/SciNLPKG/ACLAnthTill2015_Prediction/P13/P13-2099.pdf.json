{"title": [{"text": "Evolutionary Hierarchical Dirichlet Process for Timeline Summarization", "labels": [], "entities": [{"text": "Summarization", "start_pos": 57, "end_pos": 70, "type": "TASK", "confidence": 0.6709308624267578}]}], "abstractContent": [{"text": "Timeline summarization aims at generating concise summaries and giving readers a faster and better access to understand the evolution of news.", "labels": [], "entities": [{"text": "Timeline summarization", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7227105498313904}]}, {"text": "It is anew challenge which combines salience ranking problem with novelty detection.", "labels": [], "entities": [{"text": "salience ranking", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.7941814959049225}, {"text": "novelty detection", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.6695475429296494}]}, {"text": "Previous researches in this field seldom explore the evolutionary pattern of topics such as birth, splitting, merging, developing and death.", "labels": [], "entities": []}, {"text": "In this paper, we develop a novel model called Evolutionary Hierarchical Dirichlet Process(EHDP) to capture the topic evolution pattern in time-line summarization.", "labels": [], "entities": []}, {"text": "In EHDP, time varying information is formulated as a series of HDPs by considering time-dependent information.", "labels": [], "entities": []}, {"text": "Experiments on 6 different datasets which contain 3156 documents demonstrates the good performance of our system with regard to ROUGE scores.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 128, "end_pos": 133, "type": "METRIC", "confidence": 0.9804154634475708}]}], "introductionContent": [{"text": "Faced with thousands of news articles, people usually try to ask the general aspects such as the beginning, the evolutionary pattern and the end.", "labels": [], "entities": []}, {"text": "General search engines simply return the top ranking articles according to query relevance and fail to trace how a specific event goes.", "labels": [], "entities": []}, {"text": "Timeline summarization, which aims at generating a series of concise summaries for news collection published at different epochs can give readers a faster and better access to understand the evolution of news.", "labels": [], "entities": [{"text": "Timeline summarization", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7397677302360535}]}, {"text": "The key of timeline summarization is how to select sentences which can tell readers the evolutionary pattern of topics in the event.", "labels": [], "entities": [{"text": "timeline summarization", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.5866156667470932}]}, {"text": "It is very common that the themes of a corpus evolve overtime, and topics of adjacent epochs usually exhibit strong correlations.", "labels": [], "entities": []}, {"text": "Thus, it is important to model topics across different documents and over different time periods to detect how the events evolve.", "labels": [], "entities": []}, {"text": "The task of timelime summarization is firstly proposed by by extracting clusters of noun phases and name entities.) built a similar system in unit of sentences with interest and burstiness.", "labels": [], "entities": [{"text": "timelime summarization", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.486418679356575}]}, {"text": "However, these methods seldom explored the evolutionary characteristics of news.", "labels": [], "entities": []}, {"text": "Recently, extended the graph based sentence ranking algorithm used in traditional multi-document summarization (MDS) to timeline generation by projecting sentences from different time into one plane.", "labels": [], "entities": [{"text": "sentence ranking", "start_pos": 35, "end_pos": 51, "type": "TASK", "confidence": 0.6988565027713776}, {"text": "multi-document summarization (MDS)", "start_pos": 82, "end_pos": 116, "type": "TASK", "confidence": 0.8459889411926269}, {"text": "timeline generation", "start_pos": 120, "end_pos": 139, "type": "TASK", "confidence": 0.722077950835228}]}, {"text": "They further explored the timeline task from the optimization of a function considering the combination of different respects such as relevance, coverage, coherence and diversity).", "labels": [], "entities": []}, {"text": "However, their approaches just treat timeline generation as a sentence ranking or optimization problem and seldom explore the topic information lied in the corpus.", "labels": [], "entities": [{"text": "timeline generation", "start_pos": 37, "end_pos": 56, "type": "TASK", "confidence": 0.8328901827335358}, {"text": "sentence ranking or optimization", "start_pos": 62, "end_pos": 94, "type": "TASK", "confidence": 0.7277005389332771}]}, {"text": "Recently, topic models have been widely used for capturing the dynamics of topics via time.", "labels": [], "entities": []}, {"text": "Many dynamic approaches based on LDA model ( or Hierarchical Dirichelt Processes(HDP) () have been proposed to discover the evolving patterns in the corpus as well as the snapshot clusters at each time epoch;.", "labels": [], "entities": []}, {"text": "In this paper, we propose EHDP: a evolutionary hierarchical Dirichlet process (HDP) model for timeline summarization.", "labels": [], "entities": [{"text": "timeline summarization", "start_pos": 94, "end_pos": 116, "type": "TASK", "confidence": 0.5918866842985153}]}, {"text": "In EHDP, each HDP is built for multiple corpora at each time epoch, and the time dependencies are incorporated into epochs under the Markovian assumptions.", "labels": [], "entities": []}, {"text": "Topic popularity and topic-word distribution can be inferred from a Chinese Restaurant Process (CRP).", "labels": [], "entities": [{"text": "topic-word distribution", "start_pos": 21, "end_pos": 44, "type": "TASK", "confidence": 0.6979696154594421}]}, {"text": "Sentences are selected into timelines by considering different aspects such as topic relevance, coverage and coherence.", "labels": [], "entities": []}, {"text": "We built the evaluation sys-tems which contain 6 real datasets and performance of different models is evaluated according to the ROUGE metrics.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 129, "end_pos": 134, "type": "METRIC", "confidence": 0.874970555305481}]}, {"text": "Experimental results demonstrate the effectiveness of our model .", "labels": [], "entities": []}], "datasetContent": [{"text": "We downloaded 3156 news articles from selected sources such as BBC, New York Times and CNN with various time spans and built the evaluation systems which contains 6 real datasets.", "labels": [], "entities": []}, {"text": "The news belongs to different categories of Rule of Interpretation (ROI) (.", "labels": [], "entities": [{"text": "Rule of Interpretation (ROI)", "start_pos": 44, "end_pos": 72, "type": "TASK", "confidence": 0.5263445973396301}]}, {"text": "For the space limit, we only report three ROUGE ROUGE-2-F and ROUGE-W-F score.", "labels": [], "entities": [{"text": "ROUGE ROUGE-2-F", "start_pos": 42, "end_pos": 57, "type": "METRIC", "confidence": 0.7841936647891998}, {"text": "ROUGE-W-F score", "start_pos": 62, "end_pos": 77, "type": "METRIC", "confidence": 0.9682031273841858}]}, {"text": "Reference timeline in ROUGE evaluation is manually generated by using Amazon Mechanical Turk 1 . Workers were asked to generate reference timeline for news at each epoch in less than 50 words and we collect 790 timelines in total.", "labels": [], "entities": [{"text": "ROUGE evaluation", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.8944320976734161}, {"text": "Amazon Mechanical Turk 1", "start_pos": 70, "end_pos": 94, "type": "DATASET", "confidence": 0.9655032157897949}]}], "tableCaptions": [{"text": " Table 1: New sources of datasets", "labels": [], "entities": []}, {"text": " Table 2: Detailed information for datasets", "labels": [], "entities": [{"text": "Detailed", "start_pos": 10, "end_pos": 18, "type": "TASK", "confidence": 0.9432114958763123}]}, {"text": " Table 3: Comparison with topic models", "labels": [], "entities": []}, {"text": " Table 4: Comparison with other baselines", "labels": [], "entities": []}]}