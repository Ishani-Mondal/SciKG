{"title": [{"text": "Text Classification from Positive and Unlabeled Data using Misclassified Data Correction", "labels": [], "entities": [{"text": "Text Classification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6098738610744476}]}], "abstractContent": [{"text": "This paper addresses the problem of dealing with a collection of labeled training documents, especially annotating negative training documents and presents a method of text classification from positive and un-labeled data.", "labels": [], "entities": [{"text": "text classification", "start_pos": 168, "end_pos": 187, "type": "TASK", "confidence": 0.692795991897583}]}, {"text": "We applied an error detection and correction technique to the results of positive and negative documents classified by the Support Vector Machines (SVM).", "labels": [], "entities": [{"text": "error detection and correction", "start_pos": 14, "end_pos": 44, "type": "TASK", "confidence": 0.7634371817111969}]}, {"text": "The results using Reuters documents showed that the method was comparable to the current state-of-the-art biased-SVM method as the F-score obtained by our method was 0.627 and biased-SVM was 0.614.", "labels": [], "entities": [{"text": "Reuters documents", "start_pos": 18, "end_pos": 35, "type": "DATASET", "confidence": 0.9374644160270691}, {"text": "F-score", "start_pos": 131, "end_pos": 138, "type": "METRIC", "confidence": 0.9980399012565613}]}], "introductionContent": [{"text": "Text classification using machine learning (ML) techniques with a small number of labeled data has become more important with the rapid increase in volume of online documents.", "labels": [], "entities": [{"text": "Text classification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8519743084907532}]}, {"text": "Quite a lot of learning techniques e.g., semi-supervised learning, selftraining, and active learning have been proposed.", "labels": [], "entities": []}, {"text": "Blum et al. proposed a semi-supervised learning approach called the Graph Mincut algorithm which uses a small number of positive and negative examples and assigns values to unlabeled examples in away that optimizes consistency in a nearest-neighbor sense ().", "labels": [], "entities": []}, {"text": "Cabrera et al. described a method for self-training text categorization using the Web as the corpus).", "labels": [], "entities": []}, {"text": "The method extracts unlabeled documents automatically from the Web and applies an enriched self-training for constructing the classifier.", "labels": [], "entities": []}, {"text": "Several authors have attempted to improve classification accuracy using only positive and unlabeled data ().", "labels": [], "entities": [{"text": "classification", "start_pos": 42, "end_pos": 56, "type": "TASK", "confidence": 0.9766632914543152}, {"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9401006102561951}]}, {"text": "Liu et al. proposed a method called biased-SVM that uses soft-margin SVM as the underlying classifiers ().", "labels": [], "entities": []}, {"text": "Elkan and Noto proposed a theoretically justified method.", "labels": [], "entities": []}, {"text": "They showed that under the assumption that the labeled documents are selected randomly from the positive documents, a classifier trained on positive and unlabeled documents predicts probabilities that differ by only a constant factor from the true conditional probabilities of being positive.", "labels": [], "entities": []}, {"text": "They reported that the results were comparable to the current state-of-the-art biased SVM method.", "labels": [], "entities": []}, {"text": "The methods of a region containing most of the available positive data.", "labels": [], "entities": []}, {"text": "However, these methods are sensitive to the parameter values, especially the small size of labeled data presents special difficulties in tuning the parameters to produce optimal results.", "labels": [], "entities": []}, {"text": "In this paper, we propose a method for eliminating the need for manually collecting training documents, especially annotating negative training documents based on supervised ML techniques.", "labels": [], "entities": []}, {"text": "Our goal is to eliminate the need for manually collecting training documents, and hopefully achieve classification accuracy from positive and unlabeled data as high as that from labeled positive and labeled negative data.", "labels": [], "entities": [{"text": "classification", "start_pos": 100, "end_pos": 114, "type": "TASK", "confidence": 0.928443193435669}, {"text": "accuracy", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.9551830887794495}]}, {"text": "Like much previous work on semi-supervised ML, we apply SVM to the positive and unlabeled data, and add the classification results to the training data.", "labels": [], "entities": [{"text": "ML", "start_pos": 43, "end_pos": 45, "type": "TASK", "confidence": 0.84613436460495}]}, {"text": "The difference is that before adding the classification results, we applied the MisClassified data Detection and Correction (MCDC) technique to the results of SVM learning in order to improve classification accuracy obtained by the final classifiers.", "labels": [], "entities": [{"text": "MisClassified data Detection and Correction (MCDC)", "start_pos": 80, "end_pos": 130, "type": "TASK", "confidence": 0.6387645155191422}, {"text": "accuracy", "start_pos": 207, "end_pos": 215, "type": "METRIC", "confidence": 0.856378436088562}]}], "datasetContent": [{"text": "We chose the 1996 Reuters data) for evaluation.", "labels": [], "entities": [{"text": "1996 Reuters data)", "start_pos": 13, "end_pos": 31, "type": "DATASET", "confidence": 0.8352911323308945}]}, {"text": "After eliminating unlabeled documents, we divided these into three.", "labels": [], "entities": []}, {"text": "The data (20,000 documents) extracted from 20 Aug to 19 Sept is used as training data indicating positive and unlabeled documents.", "labels": [], "entities": []}, {"text": "We set the range of \u03b4 from 0.1 to 0.9 to create a wide range of scenarios, where \u03b4 refers to the ratio of documents from the positive class first selected from a fold as the positive set.", "labels": [], "entities": [{"text": "\u03b4", "start_pos": 20, "end_pos": 21, "type": "METRIC", "confidence": 0.961643636226654}]}, {"text": "The rest of the positive and negative documents are used as unlabeled data.", "labels": [], "entities": []}, {"text": "We used categories assigned to more than 100 documents in the training data as it is necessary to examine a wide range of \u03b4 values.", "labels": [], "entities": []}, {"text": "These categories are 88 in all.", "labels": [], "entities": []}, {"text": "The data from 20 Sept to 19 Nov is used as a test set X, to estimate true output distribution.", "labels": [], "entities": []}, {"text": "The remaining data consisting 607,259 from 20 Nov 1996 to 19 Aug 1997 is used as a test data for text classification.", "labels": [], "entities": [{"text": "text classification", "start_pos": 97, "end_pos": 116, "type": "TASK", "confidence": 0.8827959299087524}]}, {"text": "We obtained a vocabulary of 320,935 unique words after eliminating words which occur only once, stemming by a part-ofspeech tagger, and stop word removal.", "labels": [], "entities": [{"text": "stop word removal", "start_pos": 136, "end_pos": 153, "type": "TASK", "confidence": 0.6680975357691447}]}, {"text": "The number of categories per documents is 3.21 on average.", "labels": [], "entities": []}, {"text": "We used the SVM-Light package . We used a linear kernel and set all parameters to their default values.", "labels": [], "entities": []}, {"text": "We compared our method, MCDC with three baselines: (1) SVM, (2) Positive Example-Based Learning (PEBL) proposed by (), and (3) biased-SVM (.", "labels": [], "entities": []}, {"text": "We chose PEBL because the convergence procedure is very similar to our framework.", "labels": [], "entities": [{"text": "PEBL", "start_pos": 9, "end_pos": 13, "type": "DATASET", "confidence": 0.8406603336334229}]}, {"text": "Biased-SVM is the state-of-the-art SVM method, and often used for comparison.", "labels": [], "entities": []}, {"text": "To make comparisons fair, all methods were based on a linear kernel.", "labels": [], "entities": []}, {"text": "We randomly selected 1,000 positive and 1,000 negative documents classified by SVM and added to the SVM training data in each iteration . For biased-SVM, we used training data and classified test documents directly.", "labels": [], "entities": [{"text": "SVM", "start_pos": 79, "end_pos": 82, "type": "DATASET", "confidence": 0.9252619743347168}, {"text": "SVM training data", "start_pos": 100, "end_pos": 117, "type": "DATASET", "confidence": 0.7361576159795126}]}, {"text": "We empirically selected values of two parameters, \"c\" (trade-off between training error and margin) and \"j\", i.e., cost (cost-factor, by which training errors on positive examples) that optimized the F-score obtained by classification of test documents.", "labels": [], "entities": [{"text": "training error", "start_pos": 73, "end_pos": 87, "type": "METRIC", "confidence": 0.9043843746185303}, {"text": "margin", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.5100780129432678}, {"text": "F-score", "start_pos": 200, "end_pos": 207, "type": "METRIC", "confidence": 0.9967785477638245}]}, {"text": "The positive training data in SVM are assigned to the target category.", "labels": [], "entities": [{"text": "SVM", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.8946607112884521}]}, {"text": "The negative training data are the remaining data except for the documents that were assigned to the target category, i.e., this is the ideal method as we used all the training data with positive/negative labeled documents.", "labels": [], "entities": []}, {"text": "The number of positive training data in other three methods depends on the value of \u03b4, and the rest of the positive and negative documents were used as unlabeled data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Miss-classified data correction results", "labels": [], "entities": [{"text": "Miss-classified data correction", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.6472994685173035}]}]}