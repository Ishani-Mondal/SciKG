{"title": [{"text": "Generating Recommendation Dialogs by Extracting Information from User Reviews", "labels": [], "entities": [{"text": "Generating Recommendation Dialogs", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7770072023073832}]}], "abstractContent": [{"text": "Recommendation dialog systems help users navigate e-commerce listings by asking questions about users' preferences toward relevant domain attributes.", "labels": [], "entities": []}, {"text": "We present a framework for generating and ranking fine-grained, highly relevant questions from user-generated reviews.", "labels": [], "entities": []}, {"text": "We demonstrate our approach on anew dataset just released by Yelp, and release anew sentiment lexicon with 1329 adjectives for the restaurant domain.", "labels": [], "entities": [{"text": "anew dataset just released by Yelp", "start_pos": 31, "end_pos": 65, "type": "DATASET", "confidence": 0.7401701460282007}]}], "introductionContent": [{"text": "Recommendation dialog systems have been developed fora number of tasks ranging from product search to restaurant recommendation (.", "labels": [], "entities": [{"text": "restaurant recommendation", "start_pos": 102, "end_pos": 127, "type": "TASK", "confidence": 0.6678358763456345}]}, {"text": "These systems learn user requirements through spoken or text-based dialog, asking questions about particular attributes to filter the space of relevant documents.", "labels": [], "entities": []}, {"text": "Traditionally, these systems draw questions from a small, fixed set of attributes, such as cuisine or price in the restaurant domain.", "labels": [], "entities": []}, {"text": "However, these systems overlook an important element in users' interactions with online product listings: usergenerated reviews.", "labels": [], "entities": []}, {"text": "show that information extracted from user reviews greatly improves user experience in visual search interfaces.", "labels": [], "entities": []}, {"text": "In this paper, we present a dialog-based interface that takes advantage of review texts.", "labels": [], "entities": []}, {"text": "We demonstrate our system on anew challenge corpus of 11,537 businesses and 229,907 user reviews released by the popular review website Yelp 1 , focusing on the dataset's 4724 restaurants and bars.", "labels": [], "entities": []}, {"text": "This paper makes two main contributions.", "labels": [], "entities": []}, {"text": "First, we describe and qualitatively evaluate a frame-1 https://www.yelp.com/dataset_challenge/ work for generating new, highly-relevant questions from user review texts.", "labels": [], "entities": []}, {"text": "The framework makes use of techniques from topic modeling and sentiment-based aspect extraction to identify finegrained attributes for each business.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.737012505531311}, {"text": "sentiment-based aspect extraction", "start_pos": 62, "end_pos": 95, "type": "TASK", "confidence": 0.6578441659609476}]}, {"text": "These attributes form the basis of anew set of questions that the system can ask the user.", "labels": [], "entities": []}, {"text": "Second, we use a method based on informationgain for dynamically ranking candidate questions during dialog production.", "labels": [], "entities": [{"text": "dialog production", "start_pos": 100, "end_pos": 117, "type": "TASK", "confidence": 0.8158425688743591}]}, {"text": "This allows our system to select the most informative question at each dialog step.", "labels": [], "entities": []}, {"text": "An evaluation based on simulated dialogs shows that both the ranking method and the automatically generated questions improve recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 126, "end_pos": 132, "type": "METRIC", "confidence": 0.9982525706291199}]}], "datasetContent": [{"text": "We follow the standard approach of using the attributes of an individual business as a simulation of a user's preferences.", "labels": [], "entities": []}, {"text": "For every business b \u2208 B we form an information need composed of all of b's attributes: To evaluate a recommendation agent, we use the recall metric, which measures how well an information need is satisfied.", "labels": [], "entities": [{"text": "recall metric", "start_pos": 135, "end_pos": 148, "type": "METRIC", "confidence": 0.9817813634872437}]}, {"text": "For each information need I, let B I be the set of businesses that satisfy the questions of an agent.", "labels": [], "entities": []}, {"text": "We define the recall of the set of businesses with respect to the information need as |B I ||I| We average recall across all information needs, yielding average recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9961562752723694}, {"text": "recall", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.9963459372520447}, {"text": "recall", "start_pos": 161, "end_pos": 167, "type": "METRIC", "confidence": 0.99788898229599}]}, {"text": "We compare against a random agent baseline that selects attributes att \u2208 Att uniformly at random at each time step.", "labels": [], "entities": []}, {"text": "Other recommendation dialog systems such as select questions from a small fixed hierarchy, which is not applicable to our large set of attributes.", "labels": [], "entities": []}, {"text": "shows the average recall for the random agent versus the information gain agent with varying sets of attributes.", "labels": [], "entities": [{"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9990801811218262}]}, {"text": "'Top-level' repeatedly queries the user's top-level category preferences, 'Subtopic' additionally uses our topic modeling subcategories, and 'All' uses these plus the aspects extracted from reviews.", "labels": [], "entities": []}, {"text": "We see that for sufficiently long dialogs, 'All' outperforms the other systems.", "labels": [], "entities": []}, {"text": "The 'Subtopic' and 'Top-level' systems plateau after a few dialog steps once they've asked all useful questions.", "labels": [], "entities": []}, {"text": "For instance, most businesses only have one or two top-level categories, so after the system has identified the top-level category that the user is interested in, it has no more good questions to ask.", "labels": [], "entities": []}, {"text": "Note that the information gain agent starts dialogs with the top-level and appropriate subcategory questions, so it is only for longer dialogs that the fine-grained aspects boost performance.", "labels": [], "entities": []}], "tableCaptions": []}