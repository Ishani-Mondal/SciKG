{"title": [{"text": "Transition-based Dependency Parsing with Selectional Branching", "labels": [], "entities": [{"text": "Dependency Parsing", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.8042133450508118}, {"text": "Selectional Branching", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.9262720346450806}]}], "abstractContent": [{"text": "We present a novel approach, called selec-tional branching, which uses confidence estimates to decide when to employ abeam, providing the accuracy of beam search at speeds close to a greedy transition-based dependency parsing approach.", "labels": [], "entities": [{"text": "selec-tional branching", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.6518362313508987}, {"text": "accuracy", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9995073080062866}]}, {"text": "Selectional branching is guaranteed to perform a fewer number of transitions than beam search yet performs as accurately.", "labels": [], "entities": [{"text": "Selectional branching", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7805953323841095}]}, {"text": "We also present anew transition-based dependency parsing algorithm that gives a complexity of O(n) for projective parsing and an expected linear time speed for non-projective parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.6755820661783218}, {"text": "O", "start_pos": 94, "end_pos": 95, "type": "METRIC", "confidence": 0.9944630265235901}, {"text": "projective parsing", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.6884346306324005}]}, {"text": "With the standard setup, our parser shows an unlabeled attachment score of 92.96% and a parsing speed of 9 milliseconds per sentence, which is faster and more accurate than the current state-of-the-art transition-based parser that uses beam search.", "labels": [], "entities": []}], "introductionContent": [{"text": "Transition-based dependency parsing has gained considerable interest because it runs fast and performs accurately.", "labels": [], "entities": [{"text": "Transition-based dependency parsing", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7015543977419535}]}, {"text": "Transition-based parsing gives complexities as low as O(n) and O(n 2 ) for projective and non-projective parsing, respectively.", "labels": [], "entities": [{"text": "Transition-based parsing", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.5596581101417542}, {"text": "O", "start_pos": 54, "end_pos": 55, "type": "METRIC", "confidence": 0.9887591600418091}, {"text": "O", "start_pos": 63, "end_pos": 64, "type": "METRIC", "confidence": 0.9588503837585449}]}, {"text": "The complexity is lower for projective parsing because a parser can deterministically skip tokens violating projectivity, while this property is not assumed for non-projective parsing.", "labels": [], "entities": [{"text": "projective parsing", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.6499940454959869}]}, {"text": "Nonetheless, it is possible to perform non-projective parsing in expected linear time because the amount of nonprojective dependencies is notably smaller) so a parser can assume projectivity for most cases while recognizing ones for which projectivity should not be assumed).", "labels": [], "entities": []}, {"text": "Greedy transition-based dependency parsing has been widely deployed because of its speed; however, state-of-the-art accuracies have been achieved by globally optimized parsers using beam search ().", "labels": [], "entities": [{"text": "transition-based dependency parsing", "start_pos": 7, "end_pos": 42, "type": "TASK", "confidence": 0.6861076156298319}]}, {"text": "These approaches generate multiple transition sequences given a sentence, and pick one with the highest confidence.", "labels": [], "entities": []}, {"text": "Coupled with dynamic programming, transition-based dependency parsing with beam search can be done very efficiently and gives significant improvement to parsing accuracy.", "labels": [], "entities": [{"text": "transition-based dependency parsing", "start_pos": 34, "end_pos": 69, "type": "TASK", "confidence": 0.6048272848129272}, {"text": "parsing", "start_pos": 153, "end_pos": 160, "type": "TASK", "confidence": 0.9722002148628235}, {"text": "accuracy", "start_pos": 161, "end_pos": 169, "type": "METRIC", "confidence": 0.9333716630935669}]}, {"text": "One downside of beam search is that it always uses a fixed size of beam even when a smaller size of beam is sufficient for good results.", "labels": [], "entities": [{"text": "beam search", "start_pos": 16, "end_pos": 27, "type": "TASK", "confidence": 0.9702432155609131}]}, {"text": "In our experiments, a greedy parser performs as accurately as a parser that uses beam search for about 64% of time.", "labels": [], "entities": []}, {"text": "Thus, it is preferred if the beam size is not fixed but proportional to the number of low confidence predictions that a greedy parser makes, in which case, fewer transition sequences need to be explored to produce the same or similar parse output.", "labels": [], "entities": []}, {"text": "We first present anew transition-based parsing algorithm that gives a complexity of O(n) for projective parsing and an expected linear time speed for non-projective parsing.", "labels": [], "entities": [{"text": "O", "start_pos": 84, "end_pos": 85, "type": "METRIC", "confidence": 0.9951956868171692}, {"text": "projective parsing", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.6783681213855743}]}, {"text": "We then introduce selectional branching that uses confidence estimates to decide when to employ abeam.", "labels": [], "entities": []}, {"text": "With our new approach, we achieve a higher parsing accuracy than the current state-of-the-art transition-based parser that uses beam search and a much faster speed.", "labels": [], "entities": [{"text": "parsing", "start_pos": 43, "end_pos": 50, "type": "TASK", "confidence": 0.9708120226860046}, {"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9589308500289917}]}], "datasetContent": [{"text": "Before parsing, POS tags were assigned to the training set by using 20-way jackknifing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 7, "end_pos": 14, "type": "TASK", "confidence": 0.9736843109130859}]}, {"text": "For the automatic generation of POS tags, we used the domainspecific model of Choi and Palmer (2012a)'s tagger, which gave 97.5% accuracy on the English evaluation set (0.2% higher than Collins (2002)'s tagger).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.9989443421363831}]}, {"text": "shows comparison between past and current state-of-the-art parsers and our approach.", "labels": [], "entities": []}, {"text": "The first block shows results from transition-based dependency parsers using beam search.", "labels": [], "entities": []}, {"text": "The second block shows results from other kinds of parsing approaches (e.g., graph-based parsing, ensemble parsing, linear programming, dual decomposition).", "labels": [], "entities": [{"text": "ensemble parsing", "start_pos": 98, "end_pos": 114, "type": "TASK", "confidence": 0.7413209080696106}, {"text": "dual decomposition", "start_pos": 136, "end_pos": 154, "type": "TASK", "confidence": 0.8636474311351776}]}, {"text": "The third block shows results from parsers using external data.", "labels": [], "entities": []}, {"text": "The last block shows results from our approach.", "labels": [], "entities": []}, {"text": "The Time column show how many seconds per sentence each parser takes.", "labels": [], "entities": [{"text": "Time", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9890994429588318}]}, {"text": "Approach UAS LAS Time 92.1 Huang and Sagae 92.7 93.04 93.06 91.86 93.26 93.8 93.16 93.54 Bohnet and Nivre 93.67 92.68 93.79  For evaluation, we use the model trained with b = 80 and m = 0.88, which is the best setting found during development.", "labels": [], "entities": [{"text": "Approach", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9479228258132935}, {"text": "UAS LAS Time 92.1 Huang and Sagae 92.7 93.04 93.06 91.86 93.26 93.8 93.16 93.54 Bohnet and Nivre 93.67 92.68 93.79", "start_pos": 9, "end_pos": 123, "type": "DATASET", "confidence": 0.8982509999048143}]}, {"text": "Our parser shows higher accuracy than, which is the current state-of-the-art transition-based parser that uses beam search.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9995298385620117}]}, {"text": "Bohnet and Nivre (2012)'s transition-based system jointly performs POS tagging and dependency parsing, which shows higher accuracy than ours.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 67, "end_pos": 78, "type": "TASK", "confidence": 0.796301931142807}, {"text": "dependency parsing", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.8010611236095428}, {"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9989136457443237}]}, {"text": "Our parser gives a comparative accuracy to that is a 3rd-order graph-based parsing approach.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9975634813308716}]}, {"text": "In terms of speed, our parser outperforms all other transitionbased parsers; it takes about 9 milliseconds per  sentence using the beam size of 80.", "labels": [], "entities": []}, {"text": "Our parser is implemented in Java and tested on an Intel Xeon 2.57GHz.", "labels": [], "entities": []}, {"text": "Note that we do not include input/output time for our speed comparison.", "labels": [], "entities": []}, {"text": "For a proof of concept, we run the same model, trained with b t = 80, but decode with different beam sizes using the same margin.", "labels": [], "entities": []}, {"text": "Surprisingly, our parser gives the same accuracy (0.01% higher for labeled attachment score) on this data even with b d = 16.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9986587762832642}]}, {"text": "More importantly, b d = 16 shows about the same parsing speed as b d = 80, which indicates that selectional branching automatically reduced down the beam size by estimating low confidence predictions, so even if we assigned a larger beam size for decoding, it would have performed as efficiently.", "labels": [], "entities": []}, {"text": "This implies that we no longer need to be so conscious about the beam size during decoding.", "labels": [], "entities": []}, {"text": "Another interesting part is that (b t = 80, b d = 1) shows higher accuracy than (b t = 1, b d = 1); this implies that our training method of bootstrapping transition sequences can improve even a greedy parser.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9990947246551514}]}, {"text": "Notice that our greedy parser shows higher accuracy than many other greedy parsers ( because it uses the non-local features of and the bootstrapping technique of Choi and Palmer (2011) that had not been used for most other greedy parsing approaches.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9986144304275513}]}, {"text": "shows comparison between state-of-the-art parsers and our approach for four languages with non-projective dependencies.", "labels": [], "entities": []}, {"text": "uses a pseudo-projective transition-based parsing approach.", "labels": [], "entities": []}, {"text": "uses a 2nd-order maximum spanning tree approach. and use different non-projective transition-based parsing approaches.", "labels": [], "entities": []}, {"text": "uses an ensemble model between transition-based and graph-based parsing approaches.", "labels": [], "entities": []}, {"text": "uses integer linear programming for the optimization of their parsing model.", "labels": [], "entities": []}, {"text": "Some of these approaches use greedy parsers, so we include our results from models using (b t = 80, b d = 1, m = 0.88), which finds only the one-best sequences during decoding although it is trained on multiple transition sequences (see Section 4.4).", "labels": [], "entities": []}, {"text": "Our parser shows higher accuracies for most languages except for unlabeled attachment scores in Danish and Slovene.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 24, "end_pos": 34, "type": "METRIC", "confidence": 0.997040331363678}]}, {"text": "Our greedy approach outperforms both and who use different nonprojective parsing algorithms.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Parsing accuracies and speeds on the En- glish evaluation set, excluding tokens containing  only punctuation. b t and b d indicate the beam sizes  used during training and decoding, respectively.  UAS: unlabeled attachment score, LAS: labeled  attachment score, Time: seconds per sentence.", "labels": [], "entities": [{"text": "UAS", "start_pos": 207, "end_pos": 210, "type": "METRIC", "confidence": 0.5225692987442017}, {"text": "LAS: labeled  attachment score", "start_pos": 240, "end_pos": 270, "type": "METRIC", "confidence": 0.6979121267795563}, {"text": "Time", "start_pos": 272, "end_pos": 276, "type": "METRIC", "confidence": 0.9670606255531311}]}, {"text": " Table 5: Parsing accuracies on four languages with non-projective dependencies, excluding punctuation.", "labels": [], "entities": []}]}