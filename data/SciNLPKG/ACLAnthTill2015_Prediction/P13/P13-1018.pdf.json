{"title": [], "abstractContent": [{"text": "In the ever-expanding sea of microblog data, there is a surprising amount of naturally occurring parallel text: some users create post multilingual messages targeting international audiences while others \"retweet\" translations.", "labels": [], "entities": []}, {"text": "We present an efficient method for detecting these messages and extracting parallel segments from them.", "labels": [], "entities": []}, {"text": "We have been able to extract over 1M Chinese-English parallel segments from Sina Weibo (the Chinese counterpart of Twitter) using only their public APIs.", "labels": [], "entities": []}, {"text": "As a supplement to existing parallel training data, our automatically extracted parallel data yields substantial translation quality improvements in translating microblog text and modest improvements in translating edited news commentary.", "labels": [], "entities": [{"text": "translating edited news commentary", "start_pos": 203, "end_pos": 237, "type": "TASK", "confidence": 0.9186777174472809}]}, {"text": "The resources in described in this paper are available at", "labels": [], "entities": []}], "introductionContent": [{"text": "Microblogs such as Twitter and Facebook have gained tremendous popularity in the past 10 years.", "labels": [], "entities": []}, {"text": "In addition to being an important form of communication for many people, they often contain extremely current, even breaking, information about world events.", "labels": [], "entities": []}, {"text": "However, the writing style of microblogs tends to be quite colloquial, with frequent orthographic innovation (R U still with me or what?) and nonstandard abbreviations (idk!", "labels": [], "entities": []}, {"text": "shm)-quite unlike the style found in more traditional, edited genres.", "labels": [], "entities": []}, {"text": "This poses considerable problems for traditional NLP tools, which were developed with other domains in mind, which often make strong assumptions about orthographic uniformity (i.e., there is just one way to spell you).", "labels": [], "entities": []}, {"text": "One approach to cope with this problem is to annotate in-domain data).", "labels": [], "entities": []}, {"text": "Machine translation suffers acutely from the domain-mismatch problem caused by microblog text.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.801131010055542}]}, {"text": "On one hand, standard models are probably suboptimal since they (like many models) assume orthographic uniformity in the input.", "labels": [], "entities": []}, {"text": "However, more acutely, the data used to develop these systems and train their models is drawn from formal and carefully edited domains, such as parallel web pages and translated legal documents.", "labels": [], "entities": []}, {"text": "MT training data seldom looks anything like microblog text.", "labels": [], "entities": [{"text": "MT training", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.8972951173782349}]}, {"text": "This paper introduces a method for finding naturally occurring parallel microblog text, which helps address the domain-mismatch problem.", "labels": [], "entities": []}, {"text": "Our method is inspired by the perhaps surprising observation that a reasonable number of microblog users tweet \"in parallel\" in two or more languages.", "labels": [], "entities": []}, {"text": "For instance, the American entertainer Snoop Dogg regularly posts parallel messages on Sina Weibo (Mainland China's equivalent of Twitter), for example, watup Kenny Mayne!!", "labels": [], "entities": [{"text": "watup Kenny Mayne!!", "start_pos": 153, "end_pos": 172, "type": "DATASET", "confidence": 0.7467449009418488}]}, {"text": "-Kenny Mayne, where an English message and its Chinese translation are in the same post, separated by a dash.", "labels": [], "entities": []}, {"text": "Our method is able to identify and extract such translations.", "labels": [], "entities": []}, {"text": "Briefly, this requires determining if a tweet contains more than one language, if these multilingual utterances contain translated material (or are due to something else, such as code switching), and what the translated spans are.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the related work in parallel data extraction.", "labels": [], "entities": [{"text": "parallel data extraction", "start_pos": 40, "end_pos": 64, "type": "TASK", "confidence": 0.6340792576471964}]}, {"text": "Section 3 presents our model to extract parallel data within the same document.", "labels": [], "entities": []}, {"text": "Section 4 describes our extraction pipeline.", "labels": [], "entities": []}, {"text": "Section 5 describes the data we gathered from both Sina Weibo (Chinese-English) and Twitter (Chinese-English and Arabic-English).", "labels": [], "entities": [{"text": "Sina Weibo", "start_pos": 51, "end_pos": 61, "type": "DATASET", "confidence": 0.8885840773582458}]}, {"text": "We then present experiments showing that our harvested data not only substantially improves translations of microblog text with existing (and arguably inappropriate) translation models, but that it improves the translation of more traditional MT genres, like newswire.", "labels": [], "entities": [{"text": "translations of microblog text", "start_pos": 92, "end_pos": 122, "type": "TASK", "confidence": 0.8428617268800735}, {"text": "MT genres", "start_pos": 243, "end_pos": 252, "type": "TASK", "confidence": 0.879200667142868}]}, {"text": "We conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our method in two ways.", "labels": [], "entities": []}, {"text": "First, intrinsically, by observing how well our method identifies tweets containing parallel data, the language pair and what their spans are.", "labels": [], "entities": []}, {"text": "Second, extrinsically, by looking at how well the data improves a translation task.", "labels": [], "entities": [{"text": "translation task", "start_pos": 66, "end_pos": 82, "type": "TASK", "confidence": 0.8828622102737427}]}, {"text": "This methodology is similar to that of.", "labels": [], "entities": []}, {"text": "We report on machine translation experiments using our harvested data in two domains: edited news and microblogs.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7377471327781677}]}, {"text": "For the news test, we created anew test set from a crawl of the ChineseEnglish documents on the Project Syndicate website 2 , which contains news commentary articles.", "labels": [], "entities": [{"text": "ChineseEnglish documents on the Project Syndicate website 2", "start_pos": 64, "end_pos": 123, "type": "DATASET", "confidence": 0.9669797420501709}]}, {"text": "We chose to use this data set, rather than more standard NIST test sets to ensure that we had recent documents in the test set (the most recent NIST test sets contain documents published in 2007, well before our microblog data was created).", "labels": [], "entities": [{"text": "NIST test sets", "start_pos": 57, "end_pos": 71, "type": "DATASET", "confidence": 0.9632877508799235}, {"text": "NIST test sets", "start_pos": 144, "end_pos": 158, "type": "DATASET", "confidence": 0.9524677793184916}]}, {"text": "We extracted 1386 parallel sentences for tuning and another 1386 sentences for testing, from the manually aligned segments.", "labels": [], "entities": []}, {"text": "For this test set, we used 8 million sentences from the full NIST parallel dataset as the language model training data.", "labels": [], "entities": [{"text": "NIST parallel dataset", "start_pos": 61, "end_pos": 82, "type": "DATASET", "confidence": 0.8890504439671835}]}, {"text": "We shall call this test set Syndicate.", "labels": [], "entities": []}, {"text": "To carryout the microblog translation experiments, we need a high quality parallel test set.", "labels": [], "entities": [{"text": "microblog translation", "start_pos": 16, "end_pos": 37, "type": "TASK", "confidence": 0.6474967449903488}]}, {"text": "Since we are not aware of such a test set, we created one by manually selecting parallel messages from Weibo.", "labels": [], "entities": [{"text": "Weibo", "start_pos": 103, "end_pos": 108, "type": "DATASET", "confidence": 0.9711880683898926}]}, {"text": "Our procedure was as follows.", "labels": [], "entities": []}, {"text": "We selected 2000 candidate Weibo posts from users who have a high number of parallel tweets according to our automatic method (at least 2 in every 5 tweets).", "labels": [], "entities": []}, {"text": "To these, we added another 2000 messages from our targeted Weibo crawl, but these had no requirement on the proportion of parallel tweets they had produced.", "labels": [], "entities": [{"text": "Weibo crawl", "start_pos": 59, "end_pos": 70, "type": "DATASET", "confidence": 0.9581834673881531}]}, {"text": "We identified 2374 parallel segments, of which we used 1187 for development and 1187 for testing.", "labels": [], "entities": []}, {"text": "We refer to this test set as Weibo.", "labels": [], "entities": [{"text": "Weibo", "start_pos": 29, "end_pos": 34, "type": "DATASET", "confidence": 0.9590626955032349}]}, {"text": "Obviously, we removed the development and test sets from our training data.", "labels": [], "entities": []}, {"text": "Furthermore, to ensure that our training data was not too similar to the test set in the Weibo translation task, we filtered the training data to remove near duplicates by computing edit distance between each parallel sentence in the heldout set and each training instance.", "labels": [], "entities": [{"text": "Weibo translation task", "start_pos": 89, "end_pos": 111, "type": "TASK", "confidence": 0.7654276291529337}]}, {"text": "If either the source or the target sides of the a training instance had an edit distance of less than 10%, we removed it.", "labels": [], "entities": [{"text": "edit distance", "start_pos": 75, "end_pos": 88, "type": "METRIC", "confidence": 0.9351231455802917}]}, {"text": "As for the language models, we collected a further 10M tweets from Twitter for the English language model and another 10M tweets from Weibo for the Chinese language model.", "labels": [], "entities": [{"text": "Weibo", "start_pos": 134, "end_pos": 139, "type": "DATASET", "confidence": 0.9627398252487183}]}, {"text": "We acknowledge that self-translated messages are probably not a typically representative sample of all microblog messages.", "labels": [], "entities": []}, {"text": "However, we do not have the resources to produce a carefully curated test set with a more broadly representative distribution.", "labels": [], "entities": []}, {"text": "Still, we believe these results are informative as long as this is kept in mind.", "labels": [], "entities": []}, {"text": "Approximately 150,000 training instances removed.", "labels": [], "entities": []}, {"text": "We use the Moses phrase-based MT system with standard features (.", "labels": [], "entities": [{"text": "MT", "start_pos": 30, "end_pos": 32, "type": "TASK", "confidence": 0.9061562418937683}]}, {"text": "For reordering, we use the MSD reordering model (.", "labels": [], "entities": []}, {"text": "As the language model, we use a 5-gram model with KneserNey smoothing.", "labels": [], "entities": []}, {"text": "The weights were tuned using MERT . Results are presented with BLEU-4 ().", "labels": [], "entities": [{"text": "MERT", "start_pos": 29, "end_pos": 33, "type": "METRIC", "confidence": 0.9220793843269348}, {"text": "BLEU-4", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.9991545677185059}]}], "tableCaptions": [{"text": " Table 2: Examples of English-Mandarin and English-Arabic sentence pairs. The English-Mandarin  sentences were extracted from Sina Weibo and the English-Arabic sentences were extracted from Twitter.  Some messages have been shorted to fit into the table. Some interesting aspects of these sentence pairs  are marked in bold.", "labels": [], "entities": []}, {"text": " Table 3: BLEU scores for different datasets in dif- ferent translation directions (left to right), broken  with different training corpora (top to bottom).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9989697933197021}]}]}