{"title": [{"text": "Multilingual Affect Polarity and Valence Prediction in Metaphor-Rich Texts", "labels": [], "entities": []}], "abstractContent": [{"text": "Metaphor is an important way of conveying the affect of people, hence understanding how people use metaphors to convey affect is important for the communication between individuals and increases cohesion if the perceived affect of the concrete example is the same for the two individuals.", "labels": [], "entities": []}, {"text": "Therefore, building computational models that can automatically identify the affect in metaphor-rich texts like \"The team captain is a rock.\", \"Time is money.\", \"My lawyer is a shark.\" is an important challenging problem, which has been of great interest to the research community.", "labels": [], "entities": []}, {"text": "To solve this task, we have collected and manually annotated the affect of metaphor-rich texts for four languages.", "labels": [], "entities": []}, {"text": "We present novel algorithms that integrate triggers for cognitive, affective, perceptual and social processes with stylistic and lexical information.", "labels": [], "entities": []}, {"text": "By running evaluations on datasets in English, Spanish, Russian and Farsi, we show that the developed affect polarity and valence prediction technology of metaphor-rich texts is portable and works equally well for different languages .", "labels": [], "entities": [{"text": "affect polarity and valence prediction", "start_pos": 102, "end_pos": 140, "type": "TASK", "confidence": 0.6174706935882568}]}], "introductionContent": [{"text": "Metaphor is a figure of speech in which a word or phrase that ordinarily designates one thing is used to designate another, thus making an implicit comparison (.", "labels": [], "entities": []}, {"text": "For instance, in \"My lawyer is a shark\" the speaker may want to communicate that his/her lawyer is strong and aggressive, and that he will attack in court and persist until the goals are achieved.", "labels": [], "entities": []}, {"text": "By using the metaphor, the speaker actually conveys positive affect because having an aggressive lawyer is good if one is being sued.", "labels": [], "entities": []}, {"text": "There has been a substantial body of work on metaphor identification and interpretation.", "labels": [], "entities": [{"text": "metaphor identification and interpretation", "start_pos": 45, "end_pos": 87, "type": "TASK", "confidence": 0.8281164318323135}]}, {"text": "However, in this paper we focus on an equally interesting, challenging and important problem, which concerns the automatic identification of affect carried by metaphors.", "labels": [], "entities": [{"text": "automatic identification of affect carried by metaphors", "start_pos": 113, "end_pos": 168, "type": "TASK", "confidence": 0.7796916876520429}]}, {"text": "Building such computational models is important to understand how people use metaphors to convey affect and how affect is expressed using metaphors.", "labels": [], "entities": []}, {"text": "The existence of such models can be also used to improve the communication between individuals and to make sure that the speakers perceived the affect of the concrete metaphor example in the same way.", "labels": [], "entities": []}, {"text": "The questions we address in this paper are: \"How can we build computational models that can identify the polarity and valence associated with metaphor-rich texts?\" and \"Is it possible to build such automatic models for multiple languages?\".", "labels": [], "entities": []}, {"text": "Our main contributions are: \u2022 We have developed multilingual metaphorrich datasets in English, Spanish, Russian and Farsi that contain annotations of the Positive and Negative polarity and the valence (from \u22123 to +3 scale) corresponding to the intensity of the affect conveyed in the metaphor.", "labels": [], "entities": []}, {"text": "\u2022 We have proposed and developed automated methods for solving the polarity and valence tasks for all four languages.", "labels": [], "entities": []}, {"text": "We model the polarity task as a classification problem, while the valence task as a regression problem.", "labels": [], "entities": []}, {"text": "\u2022 We have studied the influence of different information sources like the metaphor itself, the context in which it resides, the source and target domains of the metaphor, in addition to contextual features and trigger word lists developed by psychologists).", "labels": [], "entities": []}, {"text": "\u2022 We have conducted in depth experimental evaluation and showed that the developed methods significantly outperform baseline methods.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes related work, Section 3 briefly talks about metaphors.", "labels": [], "entities": []}, {"text": "Sections 4 and 5 describe the polarity classification and valence prediction tasks for affect of metaphor-rich texts.", "labels": [], "entities": [{"text": "polarity classification", "start_pos": 30, "end_pos": 53, "type": "TASK", "confidence": 0.7093115448951721}, {"text": "valence prediction", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.6940991282463074}]}, {"text": "Both sections have information on the collected data for English, Spanish, Russian and Farsi, the conducted experiments and obtained results.", "labels": [], "entities": []}, {"text": "Finally, we conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "N-gram features are widely used in a variety of classification tasks, therefore we also use them in our polarity classification task.", "labels": [], "entities": [{"text": "polarity classification task", "start_pos": 104, "end_pos": 132, "type": "TASK", "confidence": 0.7788902719815572}]}, {"text": "We studied the influence of unigrams, bigrams and a combination of the two, and saw that the best performing feature set consists of the combination of unigrams and bigrams.", "labels": [], "entities": []}, {"text": "In this paper, we will refer from now onto n-grams as the combination of unigrams and bigrams.", "labels": [], "entities": []}, {"text": "shows a study of the influence of the different information sources and their combination with n-gram features for English.", "labels": [], "entities": []}, {"text": "For each information source (metaphor, context, source, target and their combinations), we built a separate n-gram feature set and model, which was evaluated on 10-fold cross validation.", "labels": [], "entities": []}, {"text": "The results from this study show that for English, the more information sources one combines, the higher the classification accuracy becomes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9533695578575134}]}, {"text": "The best performances are reached with individual information sources like metaphor, context, source or target instead of their combinations.", "labels": [], "entities": []}, {"text": "The classifiers obtain similar performance for both languages.", "labels": [], "entities": []}, {"text": "LIWC Category Relevance to Metaphor Polarity: We also study the importance and relevance of the LIWC categories for the metaphor polarity task.", "labels": [], "entities": [{"text": "LIWC Category Relevance to Metaphor Polarity", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.6216362913449606}]}, {"text": "We use information gain (IG) to measure the amount of information in bits about the polarity class prediction, if the only information available is the presence of a given LIWC category (feature) and the corresponding polarity class distribution.", "labels": [], "entities": [{"text": "information gain (IG)", "start_pos": 7, "end_pos": 28, "type": "METRIC", "confidence": 0.7960846841335296}, {"text": "polarity class prediction", "start_pos": 84, "end_pos": 109, "type": "TASK", "confidence": 0.6777108907699585}]}, {"text": "IG measures the expected reduction in entropy (uncertainty associated with a random feature).", "labels": [], "entities": [{"text": "IG", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.4670446813106537}, {"text": "entropy", "start_pos": 38, "end_pos": 45, "type": "METRIC", "confidence": 0.9437770247459412}]}, {"text": "illustrates how certain categories occur more with the positive (in red color) vs negative (in green color) class.", "labels": [], "entities": []}, {"text": "With the positive metaphors we observe the LIWC categories for present tense, social, affect and family, while for the negative metaphors we see LIWC categories for past tense, inhibition and anger.", "labels": [], "entities": []}, {"text": "For metaphor texts, these categories are I, conjuntion, anger, discrepancy, swear words among others; for contexts the categories are pronouns like I, you, past tense, friends, affect and soon.", "labels": [], "entities": []}, {"text": "Our study shows that some of the LIWC categories are important across all information sources, but overall different triggers activate depending on the information source and the length of the text used.", "labels": [], "entities": []}, {"text": "shows a comparison of the accuracy of our best performing approach for each language.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9994660019874573}]}, {"text": "For English and Spanish these are the LIWC models, while for Russian and Farsi these are the ngram models.", "labels": [], "entities": []}, {"text": "We compare the performance of the algorithms with a majority baseline, which assigns the majority class to each example.", "labels": [], "entities": []}, {"text": "For instance, in English there are 3529 annotated examples, of which 2086 are positive and 1443 are negative.", "labels": [], "entities": []}, {"text": "Since the positive class is the predominant one for this language and dataset, a majority classifier would have .59 accuracy in returning the positive class as an answer.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9982275366783142}]}, {"text": "Similarly, we compute the majority baseline for the rest of the languages.", "labels": [], "entities": []}, {"text": "As we can see from that all classifiers significantly outperform the majority base-line.", "labels": [], "entities": []}, {"text": "For Farsi the increment is +11.90, while for English the increment is +39.69.", "labels": [], "entities": [{"text": "increment", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9929787516593933}, {"text": "increment", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.9934993982315063}]}, {"text": "This means that the built classifiers perform much better than a random classifier.", "labels": [], "entities": []}, {"text": "For each language and information source we built separate valence prediction regression models.", "labels": [], "entities": [{"text": "valence prediction regression", "start_pos": 59, "end_pos": 88, "type": "TASK", "confidence": 0.7801356514294943}]}, {"text": "We used the same features for the regression task as we have used in the classification task.", "labels": [], "entities": [{"text": "classification task", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.8977943360805511}]}, {"text": "Those include n-grams (unigrams, bigrams and combination of the two), LIWC scores.", "labels": [], "entities": [{"text": "LIWC", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.8228368759155273}]}, {"text": "shows the obtained correlation coefficient (CC) and mean squared error (MSE) results for each one of the four languages (English, Spanish, Russian and Farsi) using the dataset described in.", "labels": [], "entities": [{"text": "correlation coefficient (CC)", "start_pos": 19, "end_pos": 47, "type": "METRIC", "confidence": 0.9820500254631043}, {"text": "mean squared error (MSE)", "start_pos": 52, "end_pos": 76, "type": "METRIC", "confidence": 0.9674702286720276}]}, {"text": "The Farsi and Russian regression models are based only on n-gram features, while the English and Spanish regression models have both n-gram and LIWC features.", "labels": [], "entities": [{"text": "LIWC", "start_pos": 144, "end_pos": 148, "type": "METRIC", "confidence": 0.9305099844932556}]}, {"text": "Overall, the CC for English and Spanish is higher when LIWC features are used.", "labels": [], "entities": [{"text": "CC", "start_pos": 13, "end_pos": 15, "type": "METRIC", "confidence": 0.9806845784187317}]}, {"text": "This means that the LIWC based valence regression model approximates the predicted values better to those of the human annotators.", "labels": [], "entities": []}, {"text": "The better valence prediction happens when the metaphor itself is used by LIWC.", "labels": [], "entities": [{"text": "valence prediction", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.7994770407676697}, {"text": "LIWC", "start_pos": 74, "end_pos": 78, "type": "DATASET", "confidence": 0.9690397381782532}]}, {"text": "The MSE for English and Spanish is the lowest, meaning that the prediction is the closest to those of the human annotators.", "labels": [], "entities": [{"text": "MSE", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.7857256531715393}]}, {"text": "In Russian and Farsi the lowest MSE is when the combined metaphor, source and target information sources are used.", "labels": [], "entities": [{"text": "MSE", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.957512378692627}]}, {"text": "For English and Spanish the smallest MSE or so called prediction error is 1.52 and 1.30 respectively, while for Russian and Farsi is 1.62 and 2.13 respectively.", "labels": [], "entities": [{"text": "prediction error", "start_pos": 54, "end_pos": 70, "type": "METRIC", "confidence": 0.9149011671543121}]}], "tableCaptions": [{"text": " Table 1: Polarity Class Distribution for Four Lan- guages", "labels": [], "entities": []}, {"text": " Table 2: N-gram features, F-scores on 10-fold val- idation for Spanish, Russian and Farsi", "labels": [], "entities": [{"text": "F-scores", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.98316490650177}, {"text": "Farsi", "start_pos": 85, "end_pos": 90, "type": "TASK", "confidence": 0.3887702524662018}]}, {"text": " Table 3: LIWC features, Accuracy and F-scores  on 10-fold validation for English and Spanish", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9995726943016052}, {"text": "F-scores", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9984577894210815}]}, {"text": " Table 4: Valence Score Distribution for Each Lan- guage", "labels": [], "entities": [{"text": "Valence Score Distribution", "start_pos": 10, "end_pos": 36, "type": "METRIC", "confidence": 0.8077072898546854}]}, {"text": " Table 5: Valence Prediction, Correlation Coefficient and Mean Squared Error for English, Spanish, Rus- sian and Farsi", "labels": [], "entities": [{"text": "Valence Prediction", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.8509719967842102}, {"text": "Correlation Coefficient", "start_pos": 30, "end_pos": 53, "type": "METRIC", "confidence": 0.9366053342819214}, {"text": "Mean Squared Error", "start_pos": 58, "end_pos": 76, "type": "METRIC", "confidence": 0.9204434156417847}]}]}