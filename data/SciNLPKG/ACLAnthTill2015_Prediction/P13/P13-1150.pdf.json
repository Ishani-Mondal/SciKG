{"title": [{"text": "Unsupervised Consonant-Vowel Prediction over Hundreds of Languages", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we present a solution to one aspect of the decipherment task: the prediction of consonants and vowels for an unknown language and alphabet.", "labels": [], "entities": [{"text": "prediction of consonants and vowels", "start_pos": 81, "end_pos": 116, "type": "TASK", "confidence": 0.8589453935623169}]}, {"text": "Adopting a classical Bayesian perspective, we performs posterior inference over hundreds of languages, leveraging knowledge of known languages and alphabets to uncover general linguistic patterns of typo-logically coherent language clusters.", "labels": [], "entities": []}, {"text": "We achieve average accuracy in the unsuper-vised consonant/vowel prediction task of 99% across 503 languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9997316002845764}, {"text": "unsuper-vised consonant/vowel prediction", "start_pos": 35, "end_pos": 75, "type": "TASK", "confidence": 0.6498928308486939}]}, {"text": "We further show that our methodology can be used to predict more fine-grained phonetic distinctions.", "labels": [], "entities": []}, {"text": "On a three-way classification task between vowels, nasals, and non-nasal consonants, our model yields unsu-pervised accuracy of 89% across the same set of languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9830927848815918}]}], "introductionContent": [{"text": "Over the past centuries, dozens of lost languages have been deciphered through the painstaking work of scholars, often after decades of slow progress and dead ends.", "labels": [], "entities": []}, {"text": "However, several important writing systems and languages remain undeciphered to this day.", "labels": [], "entities": []}, {"text": "In this paper, we present a successful solution to one aspect of the decipherment puzzle: automatically identifying basic phonetic properties of letters in an unknown alphabetic writing system.", "labels": [], "entities": []}, {"text": "Our key idea is to use knowledge of the phonetic regularities encoded in known language vocabularies to automatically build a universal probabilistic model to successfully decode new languages.", "labels": [], "entities": []}, {"text": "Our approach adopts a classical Bayesian perspective.", "labels": [], "entities": []}, {"text": "We assume that each language has an unobserved set of parameters explaining its observed vocabulary.", "labels": [], "entities": []}, {"text": "We further assume that each language-specific set of parameters was itself drawn from an unobserved common prior, shared across a cluster of typologically related languages.", "labels": [], "entities": []}, {"text": "In turn, each cluster derives its parameters from a universal prior common to all language groups.", "labels": [], "entities": []}, {"text": "This approach allows us to mix together data from languages with various levels of observations and perform joint posterior inference over unobserved variables of interest.", "labels": [], "entities": []}, {"text": "At the bottom layer (see), our model assumes a language-specific data generating HMM over words in the language vocabulary.", "labels": [], "entities": []}, {"text": "Each word is modeled as an emitted sequence of characters, depending on a corresponding Markov sequence of phonetic tags.", "labels": [], "entities": []}, {"text": "Since individual letters are highly constrained in their range of phonetic values, we make the assumption of one-tag-perobservation-type (e.g. a single letter is constrained to be always a consonant or always a vowel across all words in a language).", "labels": [], "entities": []}, {"text": "Going one layer up, we posit that the languagespecific HMM parameters are themselves drawn from informative, non-symmetric distributions representing a typologically coherent language grouping.", "labels": [], "entities": []}, {"text": "By applying the model to a mix of languages with observed and unobserved phonetic sequences, the cluster-level distributions can be inferred and help guide prediction for unknown languages and alphabets.", "labels": [], "entities": []}, {"text": "We apply this approach to two small decipherment tasks: 1.", "labels": [], "entities": []}, {"text": "predicting whether individual characters in an unknown alphabet and language represent vowels or consonants, and 2.", "labels": [], "entities": []}, {"text": "predicting whether individual characters in an unknown alphabet and language represent vowels, nasals, or non-nasal consonants.", "labels": [], "entities": []}, {"text": "For both tasks, our approach yields considerable success.", "labels": [], "entities": []}, {"text": "We experiment with a data set consisting of vocabularies of 503 languages from around the world, written in a mix of Latin, Cyrillic, and Greek alphabets.", "labels": [], "entities": []}, {"text": "In turn for each language, we consider it and its alphabet \"unobserved\" -we hide the graphic and phonetic properties of the symbols -while treating the vocabularies of the remaining languages as fully observed with phonetic tags on each of the letters.", "labels": [], "entities": []}, {"text": "On average, over these 503 leave-one-languageout scenarios, our model predicts consonant/vowel distinctions with 99% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9984293580055237}]}, {"text": "In the more challenging task of vowel/nasal/non-nasal prediction, our model achieves average accuracy over 89%.", "labels": [], "entities": [{"text": "vowel/nasal/non-nasal prediction", "start_pos": 32, "end_pos": 64, "type": "TASK", "confidence": 0.6062600612640381}, {"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9972882270812988}]}], "datasetContent": [{"text": "To test our model, we apply it to a corpus of 503 languages for two decipherment tasks.", "labels": [], "entities": []}, {"text": "In both cases, we will assume no knowledge of our target language or its writing system, other than that it is alphabetic in nature.", "labels": [], "entities": []}, {"text": "At the same time, we will assume basic phonetic knowledge of the writing systems of the other 502 languages.", "labels": [], "entities": []}, {"text": "For our first task, we will predict whether each character type is a consonant or a vowel.", "labels": [], "entities": []}, {"text": "In the second task, we further subdivide the consonants into two major categories: the nasal consonants, and the nonnasal consonants.", "labels": [], "entities": []}, {"text": "Nasal consonants are known to be perceptually very salient and are unique in being high frequency consonants in all known languages.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Language families in our data set. The  Other category includes 9 language isolates and  21 language family singletons.", "labels": [], "entities": []}, {"text": " Table 2: Average accuracy for EM baseline and  model variants across 503 languages. First panel:  results on all languages. Second panel: results for  30 isolate and singleton languages. Third panel:  results for 27 non-Latin alphabet languages (Cyril- lic and Greek). Standard Deviations across lan- guages are about 2%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9986214637756348}, {"text": "Standard", "start_pos": 270, "end_pos": 278, "type": "METRIC", "confidence": 0.9947260022163391}]}, {"text": " Table 3: Plurality language families across 20  clusters. The columns indicate portion of lan- guages in the plurality family, number of lan- guages, and entropy over families.", "labels": [], "entities": []}]}