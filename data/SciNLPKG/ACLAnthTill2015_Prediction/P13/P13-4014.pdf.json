{"title": [{"text": "QuEst -A translation quality estimation framework", "labels": [], "entities": [{"text": "translation quality estimation", "start_pos": 9, "end_pos": 39, "type": "TASK", "confidence": 0.834620992342631}]}], "abstractContent": [{"text": "We describe QUEST, an open source framework for machine translation quality estimation.", "labels": [], "entities": [{"text": "machine translation quality estimation", "start_pos": 48, "end_pos": 86, "type": "TASK", "confidence": 0.8604884147644043}]}, {"text": "The framework allows the extraction of several quality indicators from source segments, their translations, external resources (corpora, language models, topic models, etc.), as well as language tools (parsers, part-of-speech tags, etc.).", "labels": [], "entities": []}, {"text": "It also provides machine learning algorithms to build quality estimation models.", "labels": [], "entities": []}, {"text": "We benchmark the framework on a number of datasets and discuss the efficacy of features and algorithms.", "labels": [], "entities": []}], "introductionContent": [{"text": "As Machine Translation (MT) systems become widely adopted both for gisting purposes and to produce professional quality translations, automatic methods are needed for predicting the quality of a translated segment.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 3, "end_pos": 27, "type": "TASK", "confidence": 0.8462699949741364}]}, {"text": "This is referred to as Quality Estimation (QE).", "labels": [], "entities": [{"text": "Quality Estimation (QE)", "start_pos": 23, "end_pos": 46, "type": "METRIC", "confidence": 0.8557676434516907}]}, {"text": "Different from standard MT evaluation metrics, QE metrics do not have access to reference (human) translations; they are aimed at MT systems in use.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 24, "end_pos": 37, "type": "TASK", "confidence": 0.8895687460899353}, {"text": "MT", "start_pos": 130, "end_pos": 132, "type": "TASK", "confidence": 0.9394869804382324}]}, {"text": "QE has a number of applications, including: \u2022 Deciding which segments need revision by a translator (quality assurance); \u2022 Deciding whether a reader gets a reliable gist of the text; \u2022 Estimating how much effort it will be needed to post-edit a segment; \u2022 Selecting among alternative translations produced by different MT systems; \u2022 Deciding whether the translation can be used for self-training of MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 319, "end_pos": 321, "type": "TASK", "confidence": 0.9017071723937988}]}, {"text": "Work in QE for MT started in the early 2000's, inspired by the confidence scores used in Speech Recognition: mostly the estimation of word posterior probabilities.", "labels": [], "entities": [{"text": "QE", "start_pos": 8, "end_pos": 10, "type": "TASK", "confidence": 0.9132742285728455}, {"text": "MT", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.9755301475524902}, {"text": "Speech Recognition", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.7741177976131439}]}, {"text": "Back then it was called confidence estimation, which we believe is a narrower term.", "labels": [], "entities": [{"text": "confidence estimation", "start_pos": 24, "end_pos": 45, "type": "TASK", "confidence": 0.8017730712890625}]}, {"text": "A 6-week workshop on the topic at John Hopkins University in) had as goal to estimate automatic metrics such as BLEU () and WER.", "labels": [], "entities": [{"text": "John Hopkins University", "start_pos": 34, "end_pos": 57, "type": "DATASET", "confidence": 0.9070997436841329}, {"text": "BLEU", "start_pos": 112, "end_pos": 116, "type": "METRIC", "confidence": 0.9987419247627258}, {"text": "WER", "start_pos": 124, "end_pos": 127, "type": "METRIC", "confidence": 0.982745885848999}]}, {"text": "These metrics are difficult to interpret, particularly at the sentence-level, and results of their very many trials proved unsuccessful.", "labels": [], "entities": []}, {"text": "The overall quality of MT was considerably lower at the time, and therefore pinpointing the very few good quality segments was a hard problem.", "labels": [], "entities": [{"text": "MT", "start_pos": 23, "end_pos": 25, "type": "TASK", "confidence": 0.9866477251052856}]}, {"text": "No software nor datasets were made available after the workshop.", "labels": [], "entities": []}, {"text": "A new surge of interest in the field started recently, motivated by the widespread used of MT systems in the translation industry, as a consequence of better translation quality, more userfriendly tools, and higher demand for translation.", "labels": [], "entities": [{"text": "MT", "start_pos": 91, "end_pos": 93, "type": "TASK", "confidence": 0.9749094247817993}]}, {"text": "In order to make MT maximally useful in this scenario, a quantification of the quality of translated segments similar to \"fuzzy match scores\" from translation memory systems is needed.", "labels": [], "entities": [{"text": "MT", "start_pos": 17, "end_pos": 19, "type": "TASK", "confidence": 0.9938150644302368}]}, {"text": "QE work addresses this problem by using more complex metrics that go beyond matching the source segment with previously translated data.", "labels": [], "entities": []}, {"text": "QE can also be useful for end-users reading translations for gisting, particularly those who cannot read the source language.", "labels": [], "entities": []}, {"text": "QE nowadays focuses on estimating more interpretable metrics.", "labels": [], "entities": [{"text": "QE", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.5279960036277771}]}, {"text": "\"Quality\" is defined according to the application: post-editing, gisting, etc.", "labels": [], "entities": []}, {"text": "A number of positive results have been reported.", "labels": [], "entities": []}, {"text": "Examples include improving post-editing efficiency by filtering out low quality segments which would require more effort or time to correct than translating from scratch (, selecting high quality segments to be published as they are, without post-editing, selecting a translation from either an MT system or a translation memory for postediting (, selecting the best translation from multiple MT systems (, and highlighting sub-segments that need revision (.", "labels": [], "entities": []}, {"text": "QE is generally addressed as a supervised machine learning task using a variety of algorithms to induce models from examples of translations described through a number of features and annotated for quality.", "labels": [], "entities": []}, {"text": "For an overview of various algorithms and features we refer the reader to the WMT12 shared task on QE).", "labels": [], "entities": [{"text": "WMT12 shared task", "start_pos": 78, "end_pos": 95, "type": "DATASET", "confidence": 0.7285884221394857}]}, {"text": "Most of the research work lies on deciding which aspects of quality are more relevant fora given task and designing feature extractors for them.", "labels": [], "entities": []}, {"text": "While simple features such as counts of tokens and language model scores can be easily extracted, feature engineering for more advanced and useful information can be quite labourintensive.", "labels": [], "entities": []}, {"text": "Different language pairs or optimisation against specific quality scores (e.g., post-editing time vs translation adequacy) can benefit from very different feature sets.", "labels": [], "entities": []}, {"text": "QUEST, our framework for quality estimation, provides a wide range of feature extractors from source and translation texts and external resources and tools (Section 2).", "labels": [], "entities": [{"text": "QUEST", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9201602935791016}]}, {"text": "These go from simple, language-independent features, to advanced, linguistically motivated features.", "labels": [], "entities": []}, {"text": "They include features that rely on information from the MT system that generated the translations, and features that are oblivious to the way translations were produced (Section 2.1).", "labels": [], "entities": []}, {"text": "In addition, by integrating a well-known machine learning toolkit, scikit-learn, 1 and algorithms that are known to perform well on this task, QUEST provides a simple and effective way of experimenting with techniques for feature selection and model building, as well as parameter optimisation through grid search (Section 2.2).", "labels": [], "entities": [{"text": "feature selection", "start_pos": 222, "end_pos": 239, "type": "TASK", "confidence": 0.698805496096611}, {"text": "model building", "start_pos": 244, "end_pos": 258, "type": "TASK", "confidence": 0.7072853893041611}]}, {"text": "In Section 3 we present experiments using the framework with nine QE datasets.", "labels": [], "entities": [{"text": "QE datasets", "start_pos": 66, "end_pos": 77, "type": "DATASET", "confidence": 0.9187481999397278}]}, {"text": "In addition to providing a practical platform for quality estimation, by freeing researchers from feature engineering, QUEST will facilitate work on the learning aspect of the problem.", "labels": [], "entities": []}, {"text": "Quality estimation poses several machine learning challenges, such as the fact that it can exploit a large, diverse, but often noisy set of information sources, with a relatively small number of annotated data points, and it relies on human annotations that are often inconsistent due to the subjectivity of the task (quality judgements).", "labels": [], "entities": [{"text": "Quality estimation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8530113697052002}]}, {"text": "Moreover, QE is highly 1 http://scikit-learn.org/ non-linear: unlike many other problems in language processing, considerable improvements can be achieved using non-linear kernel techniques.", "labels": [], "entities": []}, {"text": "Also, different applications for the quality predictions may benefit from different machine learning techniques, an aspect that has been mostly neglected so far.", "labels": [], "entities": []}, {"text": "Finally, the framework will also facilitate research on ways of using quality predictions in novel extrinsic tasks, such as self-training of statistical machine translation systems, and for estimating quality in other text output applications such as text summarisation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 141, "end_pos": 172, "type": "TASK", "confidence": 0.6236516634623209}, {"text": "text summarisation", "start_pos": 251, "end_pos": 269, "type": "TASK", "confidence": 0.7731706202030182}]}], "datasetContent": [{"text": "The statistics of the datasets used in the experiments are shown in.", "labels": [], "entities": []}, {"text": "7 WMT12 English-Spanish sentence translations produced by an SMT system and judged for post-editing effort in 1-5 (worst-best), taking a weighted average of three annotators.", "labels": [], "entities": [{"text": "WMT12 English-Spanish sentence translations", "start_pos": 2, "end_pos": 45, "type": "TASK", "confidence": 0.801597386598587}, {"text": "SMT", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.9109891057014465}]}, {"text": "GALE11 Arabic sentences translated by two SMT systems into English and scored for adequacy in 1-4.", "labels": [], "entities": [{"text": "GALE11 Arabic sentences", "start_pos": 0, "end_pos": 23, "type": "DATASET", "confidence": 0.8978731234868368}]}, {"text": "Systems are denoted by s 1 -s 2 .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of sentences used for training  and testing in our datasets.", "labels": [], "entities": []}, {"text": " Table 2: Results with BB features.", "labels": [], "entities": [{"text": "BB", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.897644579410553}]}, {"text": " Table 3: Results with GB features.", "labels": [], "entities": [{"text": "GB", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.9768093228340149}]}, {"text": " Table 4: Results with BB and GB features.", "labels": [], "entities": [{"text": "BB", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.9950538873672485}, {"text": "GB", "start_pos": 30, "end_pos": 32, "type": "METRIC", "confidence": 0.8964022994041443}]}]}