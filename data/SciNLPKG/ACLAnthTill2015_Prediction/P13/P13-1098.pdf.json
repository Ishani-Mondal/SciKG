{"title": [{"text": "A user-centric model of voting intention from Social Media", "labels": [], "entities": []}], "abstractContent": [{"text": "Social Media contain a multitude of user opinions which can be used to predict real-world phenomena in many domains including politics, finance and health.", "labels": [], "entities": []}, {"text": "Most existing methods treat these problems as linear regression, learning to relate word frequencies and other simple features to a known response variable (e.g., voting intention polls or financial indicators).", "labels": [], "entities": []}, {"text": "These techniques require very careful filtering of the input texts, as most Social Media posts are irrelevant to the task.", "labels": [], "entities": []}, {"text": "In this paper, we present a novel approach which performs high quality filtering automatically , through modelling not just words but also users, framed as a bilin-ear model with a sparse regulariser.", "labels": [], "entities": []}, {"text": "We also consider the problem of modelling groups of related output variables, using a structured multi-task regularisation method.", "labels": [], "entities": []}, {"text": "Our experiments on voting intention prediction demonstrate strong performance over large-scale input from Twitter on two distinct case studies, outperform-ing competitive baselines.", "labels": [], "entities": [{"text": "voting intention prediction", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.8075162967046102}]}], "introductionContent": [{"text": "Web Social Media platforms have ushered anew era inhuman interaction and communication.", "labels": [], "entities": []}, {"text": "The main by-product of this activity is vast amounts of user-generated content, a type of information that has already attracted the interest of both marketeers and scientists because it offers -for the first time at a large-scale -unmediated access to peoples' observations and opinions.", "labels": [], "entities": []}, {"text": "One exciting avenue of research concentrates on mining interesting signals automatically from this stream of text input.", "labels": [], "entities": []}, {"text": "For example, by exploiting Twitter posts, it is possible to infer time series that correlate with financial indicators), track infectious diseases () and, in general, nowcast the magnitude of events emerging in real-life ().", "labels": [], "entities": []}, {"text": "Other studies suggest ways for modelling opinions encapsulated in this content in order to forge branding strategies) or understand various socio-political trends).", "labels": [], "entities": []}, {"text": "The main theme of the aforementioned works is linear regression between word frequencies and a real-world quantity.", "labels": [], "entities": []}, {"text": "They also tend to incorporate hand-crafted lists of search terms to filter irrelevant content and use sentiment analysis lexicons for extracting opinion bias.", "labels": [], "entities": [{"text": "sentiment analysis lexicons", "start_pos": 102, "end_pos": 129, "type": "TASK", "confidence": 0.8404167493184408}, {"text": "extracting opinion bias", "start_pos": 134, "end_pos": 157, "type": "TASK", "confidence": 0.8493308623631796}]}, {"text": "Consequently, they are quite often restricted to a specific application and therefore, generalise poorly to new data sets . In this paper, we propose a generic method that aims to be independent of the characteristics described above (use of search terms or sentiment analysis tools).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 258, "end_pos": 276, "type": "TASK", "confidence": 0.8103136420249939}]}, {"text": "Our approach is able to explore not only word frequencies, but also the space of users by introducing a bilinear formulation for this learning task.", "labels": [], "entities": []}, {"text": "Regularised regression on both spaces allows for an automatic selection of the most important terms and users, performing at the same time an improved noise filtering.", "labels": [], "entities": []}, {"text": "In addition, more advanced regularisation functions enable multi-task learning schemes that can exploit shared structure in the feature space.", "labels": [], "entities": []}, {"text": "The latter property becomes very useful in multi-output regression scenarios, where selected features are expected to have correlated as well as anti-correlated impact on each output (e.g., when inferring voting intentions for competing political parties).", "labels": [], "entities": []}, {"text": "We evaluate our methods on the domain of politics using data from the microblogging service of Twitter to infer voting trends.", "labels": [], "entities": []}, {"text": "Our pro-posed framework is able to successfully predict voting intentions for the top-3 and top-4 parties in the United Kingdom (UK) and Austria respectively.", "labels": [], "entities": []}, {"text": "In both case studies -bound by different characteristics (including language, time-span and number of users) -the average prediction error is smaller than 1.5% for our best model using multi-task learning.", "labels": [], "entities": [{"text": "prediction error", "start_pos": 122, "end_pos": 138, "type": "METRIC", "confidence": 0.8588853180408478}]}, {"text": "Finally, our qualitative analysis shows that the models uncover interesting and semantically interpretable insights from the data.", "labels": [], "entities": []}], "datasetContent": [{"text": "The proposed models are evaluated on C uk and C au which have been introduced in Section 2.", "labels": [], "entities": [{"text": "uk", "start_pos": 39, "end_pos": 41, "type": "METRIC", "confidence": 0.625121533870697}, {"text": "au", "start_pos": 48, "end_pos": 50, "type": "METRIC", "confidence": 0.5047416090965271}]}, {"text": "We measure predictive performance, compare it to the performance of several competitive baselines, and provide a qualitative analysis of the parameters learned by the models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: UK case study -Average RMSEs rep- resenting the error of the inferred voting intention  percentage for the 10-step validation process; \u00b5 \u00b5 \u00b5  denotes the mean RMSE across the three political  parties for each baseline or inference method.", "labels": [], "entities": [{"text": "UK case study", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.9406745036443075}, {"text": "RMSEs rep-", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.7543370723724365}, {"text": "RMSE", "start_pos": 169, "end_pos": 173, "type": "METRIC", "confidence": 0.9844682812690735}]}, {"text": " Table 2: Austrian case study -Average RMSEs  for the 10-step validation process.", "labels": [], "entities": [{"text": "Austrian case study", "start_pos": 10, "end_pos": 29, "type": "DATASET", "confidence": 0.914101759592692}, {"text": "RMSEs", "start_pos": 39, "end_pos": 44, "type": "METRIC", "confidence": 0.9503931403160095}, {"text": "validation process", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.8678901791572571}]}]}