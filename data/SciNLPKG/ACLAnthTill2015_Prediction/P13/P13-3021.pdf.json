{"title": [], "abstractContent": [{"text": "We present experiments using anew unsu-pervised approach to automatic text simplification , which builds on sampling and ranking via a loss function informed by readability research.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.6792051792144775}]}, {"text": "The main idea is that a loss function can distinguish good simplification candidates among randomly sampled sub-sentences of the input sentence.", "labels": [], "entities": []}, {"text": "Our approach is rated as equally grammatical and beginner reader appropriate as a supervised SMT-based baseline system by native speakers, but our setup performs more radical changes that better resembles the variation observed inhuman generated simplifications.", "labels": [], "entities": [{"text": "SMT-based baseline", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.8935959935188293}]}], "introductionContent": [{"text": "As afield of research in NLP, text simplification (TS) has gained increasing attention recently, primarily for English text, but also for Brazilian Portuguese), Dutch (),,, French (Seretan, 2012) and Swedish.", "labels": [], "entities": [{"text": "text simplification (TS)", "start_pos": 30, "end_pos": 54, "type": "TASK", "confidence": 0.8377841114997864}]}, {"text": "Our experiments use Danish text which is similar to English in that it has a deep orthography making it hard to map between letters and sounds.", "labels": [], "entities": []}, {"text": "Danish has a relatively free word order and sparse morfology.", "labels": [], "entities": []}, {"text": "TS can help readers with below average reading skills access information and may supply relevant training material, which is crucial for developing reading skills.", "labels": [], "entities": [{"text": "TS", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.6945710778236389}]}, {"text": "However, manual TS is as expensive as translation, which is a key limiting factor on the availability of easy-to-read material.", "labels": [], "entities": [{"text": "TS", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.8913863897323608}, {"text": "translation", "start_pos": 38, "end_pos": 49, "type": "TASK", "confidence": 0.9805665016174316}]}, {"text": "One of the persistent chalenges of TS is that different interventions are called for depending on the target reader population.", "labels": [], "entities": [{"text": "TS", "start_pos": 35, "end_pos": 37, "type": "TASK", "confidence": 0.9805201888084412}]}, {"text": "Automatic TS is an effective way to counter these limitations.", "labels": [], "entities": [{"text": "TS", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.6748502850532532}]}], "datasetContent": [{"text": "Three system variants were setup to generate simplified output from the original news wire of the development and test partitions of the DSim corpus.", "labels": [], "entities": [{"text": "DSim corpus", "start_pos": 137, "end_pos": 148, "type": "DATASET", "confidence": 0.720374584197998}]}, {"text": "The texts were dependency-parsed using Bohnet's parser trained on the Danish Treebank 3 (Kromann, 2003) with default settings 4 . 1. Split only performed simple sentence splitting.", "labels": [], "entities": [{"text": "Danish Treebank 3 (Kromann, 2003)", "start_pos": 70, "end_pos": 103, "type": "DATASET", "confidence": 0.9617062136530876}, {"text": "sentence splitting", "start_pos": 161, "end_pos": 179, "type": "TASK", "confidence": 0.7394082397222519}]}, {"text": "2. Sample over-generated candidates by sampling the heuristically restricted space of random lexical deletions and ranking candidates with a loss function.", "labels": [], "entities": []}, {"text": "3. Combined is a combination of the two, applying the sampling procedure of Sample to the split sentences from Split.", "labels": [], "entities": []}, {"text": "Sentence Splitting We implemented sentence splitting to extract relative clauses, as marked by the dependency relation rel, coordinated clauses, coord, and conjuncts, conj, when at least a verb and a noun is left in each part of the split.", "labels": [], "entities": [{"text": "Sentence Splitting", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8913130164146423}, {"text": "sentence splitting", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.7284518480300903}]}, {"text": "Only splits resulting in sentences of more than three words were considered.", "labels": [], "entities": []}, {"text": "Where applicable, referred entities were included in the extracted sentence by using the dependency analysis to extract the subtree of the former head of the new sentence . In case of more than one possibility, the split resulting in the most balanced division of the sentence was chosen and the rules were re-applied if anew sentence was still longer than ten tokens.", "labels": [], "entities": []}, {"text": "Structural Heuristics To preserve nodes from later deletion we applied heuristics using simple structural cues from the dependency structures.", "labels": [], "entities": []}, {"text": "We favored nodes headed by a subject relation, subj, and object relations, * obj, and negating modifiers (the Danish word ikke) under the assumption that these were most likely to be important for preserving semantics and generating wellformed candidates under the sampling procedure described below.", "labels": [], "entities": []}, {"text": "The heuristics were applied both to trees, acting by preserving entire subtrees and applied to words, only preserving single tokens.", "labels": [], "entities": []}, {"text": "This serves as away of avoiding relying heavily on possibly faulty dependency analyses and also avoid the risk of insisting on keeping long, complex or superfluous modifiers.", "labels": [], "entities": []}, {"text": "Sampling Candidates for scoring were overgenerated by randomly selecting parts of a (possibly split) input sentence.", "labels": [], "entities": []}, {"text": "Either the selected nodes with their full sub-tree or the single tokens from the flat list of tokens were eliminated, unless they were previously selected for preservation by a heuristic.", "labels": [], "entities": []}, {"text": "Some additional interaction between heuristics and sampling happened when the deletions were performed on trees: deletion of subtrees allow non-continuous deletions when the parses are non-projective, and nodes that were otherwise selected for keeping may nevertheless be removed if they are part of a subtree of anode selected for deletion.", "labels": [], "entities": []}, {"text": "After pruning, all nodes that used to have outgoing obj-relations had the first child node of these relations restored.", "labels": [], "entities": []}, {"text": "Evaluation was performed by a group of proficient Danish speaking volunteers who received written instructions and responded anonymously via an online form.", "labels": [], "entities": []}, {"text": "240 sentences were evaluated: six versions of each of 40 test set sentences.", "labels": [], "entities": []}, {"text": "48 sentences were evaluated by four judges, and the remaining by one judge each.", "labels": [], "entities": []}, {"text": "The judges were asked to rate each sentence in terms of grammaticality and in terms of perceived beginner reader appropriateness, both on a 5-point scale, with one signifying very good and five signifying very bad.", "labels": [], "entities": []}, {"text": "The evaluators had to rate six versions of each sentence: original news wire, a human simplified version, the baseline system, a split sentence version (Split), a sampled only version (Sample), and aversion combining the Split and Sample techniques (Combined).", "labels": [], "entities": []}, {"text": "Below are example outputs for the baseline and the other three automatic systems: BL: Der er hvad der bliver betegnet som abnormt store maengder radioaktivt materiale i havvand naer frygter atomkraftvaerk . Split: Der er m\u00e5lt hvad.", "labels": [], "entities": [{"text": "BL", "start_pos": 82, "end_pos": 84, "type": "METRIC", "confidence": 0.9662066698074341}]}, {"text": "Hvad bliver betegnet som abnormt store maengder af radioaktivt materiale i havvand naer det jordskaelvsramte atomkraftvaerk i Japan . Sample: Der er m\u00e5lt hvad der bliver betegnet som store maengder af radioaktivt materiale i havvand japan . Comb.: Der er m\u00e5lt hvad.", "labels": [], "entities": []}, {"text": "Hvad bliver betegnet som store maengder af radioaktivt materiale det atomkraftvaerk i japan .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3. Significant differences at  p < 0.05 are reported in", "labels": [], "entities": []}, {"text": " Table 1: LIX and PPL scores for reference texts  and system generated output. Medians are re- ported, because distributions are very skewed,  which makes the mean a bad estimator of central  tendency. LIX grade levels in parenthesis.", "labels": [], "entities": [{"text": "LIX grade levels", "start_pos": 202, "end_pos": 218, "type": "METRIC", "confidence": 0.8693941235542297}]}, {"text": " Table 2: Krippendorff's \u03b1 agreement for full-text  and sentence evaluation. Agreement on system  ranks was calculated from the most frequent score  per judge per system.", "labels": [], "entities": [{"text": "\u03b1 agreement", "start_pos": 25, "end_pos": 36, "type": "METRIC", "confidence": 0.8673604428768158}, {"text": "sentence evaluation", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.6240527480840683}, {"text": "Agreement", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9932560920715332}]}, {"text": " Table 3: Human evaluation. Mean (\u00af x), median (\u02dc x)  and most frequent (mode) of assigned ranks by be- ginner reader appropriateness and grammaticality  as assessed by proficient Danish speakers.", "labels": [], "entities": [{"text": "Mean (\u00af x)", "start_pos": 28, "end_pos": 38, "type": "METRIC", "confidence": 0.9380922913551331}, {"text": "median (\u02dc x)", "start_pos": 40, "end_pos": 52, "type": "METRIC", "confidence": 0.909191831946373}]}]}