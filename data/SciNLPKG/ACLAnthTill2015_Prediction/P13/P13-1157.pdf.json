{"title": [{"text": "Machine Translation Detection from Monolingual Web-Text", "labels": [], "entities": [{"text": "Machine Translation Detection", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8344875971476237}]}], "abstractContent": [{"text": "We propose a method for automatically detecting low-quality Web-text translated by statistical machine translation (SMT) systems.", "labels": [], "entities": [{"text": "automatically detecting low-quality Web-text translated by statistical machine translation (SMT)", "start_pos": 24, "end_pos": 120, "type": "TASK", "confidence": 0.730591339369615}]}, {"text": "We focus on the phrase salad phenomenon that is observed in existing SMT results and propose a set of computa-tionally inexpensive features to effectively detect such machine-translated sentences from a large-scale Web-mined text.", "labels": [], "entities": [{"text": "SMT", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.9865263104438782}]}, {"text": "Unlike previous approaches that require bilingual data, our method uses only monolin-gual text as input; therefore it is applicable for refining data produced by a variety of Web-mining activities.", "labels": [], "entities": []}, {"text": "Evaluation results show that the proposed method achieves an accuracy of 95.8% for sentences and 80.6% for text in noisy Web pages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9994513392448425}]}], "introductionContent": [{"text": "The Web provides an extremely large volume of textual content on diverse topics and areas.", "labels": [], "entities": []}, {"text": "Such data is beneficial for constructing a large scale monolingual) and bilingual () corpus that can be used for training statistical models for NLP tools, as well as for building a large-scale knowledge-base ().", "labels": [], "entities": []}, {"text": "With recent advances in statistical machine translation (SMT) systems and their wide adoption in Web services through APIs), a large amount of text in Web pages is translated by SMT systems.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 24, "end_pos": 61, "type": "TASK", "confidence": 0.795982634027799}, {"text": "SMT", "start_pos": 178, "end_pos": 181, "type": "TASK", "confidence": 0.9743130207061768}]}, {"text": "According to, their Web crawler finds that more than 15% of EnglishJapanese parallel documents are machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 99, "end_pos": 118, "type": "TASK", "confidence": 0.7362653315067291}]}, {"text": "Machine-translated sentences are useful if they are of sufficient quality and indistinguishable from human-generated sentences; however, the quality of these machine-translated sentences is generally much lower than sentences generated by native speakers and professional translators.", "labels": [], "entities": []}, {"text": "Therefore, a method to detect and filter such SMT results is desired to best make use of Web-mined data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9905385971069336}]}, {"text": "To solve this problem, we propose a method for automatically detecting Web-text translated by SMT systems . We especially target machinetranslated text produced through the Web APIs that is rapidly increasing.", "labels": [], "entities": [{"text": "SMT", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.6816072463989258}]}, {"text": "We focus on the phrase salad phenomenon (, which characterizes translations by existing SMT systems, i.e., each phrase in a sentence is semantically and syntactically correct but becomes incorrect when combined with other phrases in the sentence.", "labels": [], "entities": [{"text": "SMT", "start_pos": 88, "end_pos": 91, "type": "TASK", "confidence": 0.9716083407402039}]}, {"text": "Based on this trait, we propose features for evaluating the likelihood of machine-translated sentences and use a classifier to determine whether the sentence is generated by the SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 178, "end_pos": 181, "type": "TASK", "confidence": 0.9742001891136169}]}, {"text": "The primary contributions of the proposed method are threefold.", "labels": [], "entities": []}, {"text": "First, unlike previous studies that use parallel text and bilingual features, such as), our method only requires monolingual text as input.", "labels": [], "entities": []}, {"text": "Therefore, our method can be used in monolingual Web data mining where bilingual information is unavailable.", "labels": [], "entities": [{"text": "monolingual Web data mining", "start_pos": 37, "end_pos": 64, "type": "TASK", "confidence": 0.624394953250885}]}, {"text": "Second, the proposed features are designed to be computationally light so that the method is suitable for handling a large-scale Web-mined data.", "labels": [], "entities": []}, {"text": "Our method determines if an input sentence contains phrase salads using a simple yet effective features, i.e., language models (LMs) and automatically obtained non-contiguous phrases that are frequently used by people but difficult for SMT systems to generate.", "labels": [], "entities": [{"text": "SMT", "start_pos": 236, "end_pos": 239, "type": "TASK", "confidence": 0.9854623079299927}]}, {"text": "Third, our method computes features using both human-generated text and SMT results to capture a phrase salad by contrasting these features, which significantly improves detection accuracy.", "labels": [], "entities": [{"text": "SMT", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.9498021602630615}, {"text": "accuracy", "start_pos": 180, "end_pos": 188, "type": "METRIC", "confidence": 0.9339927434921265}]}, {"text": "We evaluate our method using Japanese and English datasets, including a human evaluation to assess its performance.", "labels": [], "entities": []}, {"text": "The results show that our method achieves an accuracy of 95.8% for sentences and 80.6% for noisy Web-text.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9995044469833374}]}], "datasetContent": [{"text": "We evaluate our method using both Japanese and English datasets from various aspects and investigate its characteristics.", "labels": [], "entities": []}, {"text": "In this section, we describe our experiment settings.", "labels": [], "entities": []}, {"text": "For the fluency and grammaticality features, we train 4-gram LMs using the development dataset with the SRI toolkit.", "labels": [], "entities": [{"text": "SRI toolkit", "start_pos": 104, "end_pos": 115, "type": "DATASET", "confidence": 0.9318245053291321}]}, {"text": "To obtain the POS information, we use Mecab () for Japanese and a POS tagger developed by for English.", "labels": [], "entities": []}, {"text": "We evaluate the effect of the sizes of N -grams and development dataset in the experiments.", "labels": [], "entities": []}, {"text": "Using the proposed features, we train an SVM classifier for detecting machine-translated sentences.", "labels": [], "entities": []}, {"text": "We use an implementation of LIB-SVM (Chang and Lin, 2011) with a radial basis function kernel due to the relatively small number of features in the proposed method.", "labels": [], "entities": []}, {"text": "We set appropriate parameters by grid search in a preliminary experiment.", "labels": [], "entities": []}, {"text": "We evaluate the performance of MT detection based on accuracy 6 that is a broadly used evaluation metric for classification problems: where n T P and n TN are the numbers of truepositives and true-negatives, respectively, and n is the total number of exemplars.", "labels": [], "entities": [{"text": "MT detection", "start_pos": 31, "end_pos": 43, "type": "TASK", "confidence": 0.9970717132091522}, {"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9983616471290588}]}, {"text": "The accuracy scores that we report in Sec.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995090961456299}]}, {"text": "5 are all based on 10-fold cross validation.", "labels": [], "entities": []}, {"text": "We evaluate the sentence-level and documentlevel accuracy of our method using the Japanese dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9819626212120056}, {"text": "Japanese dataset", "start_pos": 82, "end_pos": 98, "type": "DATASET", "confidence": 0.9644693732261658}]}, {"text": "Specifically, we evaluate effects of individual features and their combinations, compare with human annotations, and assess performance variations across different sentence lengths and various settings on LM training.", "labels": [], "entities": []}, {"text": "shows the accuracy scores of individual features and comparison methods.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.999526858329773}]}, {"text": "We refer to features for fluency (f w,H , f w,M T ) as Word LMs, grammaticality using POS LMs (f pos,H , f pos,M T ) as POS LMs  and function word LMs (f f w,H , ff w,M T ) as FW LMs, respectively, and for completeness of gappyphrases (f g,H , f g,M T ) as GPs.", "labels": [], "entities": []}, {"text": "The Word LMs show the best accuracy that outperforms CrossEntropy by 3.4% and Lexical Feature by 6.3%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9995087385177612}]}, {"text": "This high accuracy is achieved by contrasting fluency in human-generated and machine-translated text to capture the phrase salad phenomenon.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9990923404693604}]}, {"text": "The accuracy of Word LM trained only on humangenerated sentences is limited to 65.5%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9996115565299988}, {"text": "Word LM", "start_pos": 16, "end_pos": 23, "type": "TASK", "confidence": 0.6430975794792175}]}, {"text": "On the other hand, the accuracy of Word LM trained on machine-translated sentences shows a better performance (84.4%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9995753169059753}]}, {"text": "By combining these into a single feature vector f = (f w,H , f w,M T , f len ), the accuracy is largely improved.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9997352957725525}]}, {"text": "It is interesting that Lexical Feature achieves a high accuracy of 87.8% despite its simplicity.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9991922974586487}]}, {"text": "Since Lexical Feature is a bag-of-words model, it can consider distant words in a sentence.", "labels": [], "entities": []}, {"text": "This is effective for capturing a phrase salad that occurs among distant phrases, which N -gram cannot cover.", "labels": [], "entities": [{"text": "capturing a phrase salad that occurs among distant phrases", "start_pos": 22, "end_pos": 80, "type": "TASK", "confidence": 0.8100459112061394}]}, {"text": "As for Cross-Entropy, a simple subtraction of cross-entropy scores cannot well contrast the fluency in human-generated and machinetranslated text and results in poorer accuracy than Word LMs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 168, "end_pos": 176, "type": "METRIC", "confidence": 0.9980953335762024}]}, {"text": "To investigate the applicability of our method to other languages, we apply the same method to the English dataset.", "labels": [], "entities": [{"text": "English dataset", "start_pos": 99, "end_pos": 114, "type": "DATASET", "confidence": 0.8483105897903442}]}, {"text": "Because English is a configurational language, function words are less flexible than case markers in Japanese.", "labels": [], "entities": []}, {"text": "Therefore, SMT systems may better handle English function words, which potentially decreases the effect of FW LMs in our method.", "labels": [], "entities": [{"text": "SMT", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9864085912704468}]}, {"text": "In addition, because English is a morphologically poor language, the effect of POS LMs maybe reduced.", "labels": [], "entities": []}, {"text": "Nevertheless, in our experiment, all features are shown to be effective even with the English dataset.", "labels": [], "entities": [{"text": "English dataset", "start_pos": 86, "end_pos": 101, "type": "DATASET", "confidence": 0.8477404713630676}]}, {"text": "The combination of all features achieves the best performance, with an accuracy of 93.1%, which outperforms Cross-Entropy by 1.9%, and Lexical Feature by 8.5%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9996353387832642}]}, {"text": "Even though improvements by POS LMs and FW LMs are smaller than Japanese case, their effects are still positive.", "labels": [], "entities": [{"text": "FW LMs", "start_pos": 40, "end_pos": 46, "type": "DATASET", "confidence": 0.8118909597396851}]}, {"text": "We also find that GPs stably contribute to the accuracy.", "labels": [], "entities": [{"text": "GPs", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9366890788078308}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9993243217468262}]}, {"text": "These results show the applicability of our method to other languages.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Accuracy (%) of individual features and compari-", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9991831183433533}]}, {"text": " Table 5: Accuracy (%) of feature combinations; there are", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9987599849700928}]}]}