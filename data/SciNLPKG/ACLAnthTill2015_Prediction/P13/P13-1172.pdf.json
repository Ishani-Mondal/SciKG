{"title": [{"text": "Syntactic Patterns versus Word Alignment: Extracting Opinion Targets from Online Reviews", "labels": [], "entities": [{"text": "Syntactic Patterns", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9084108471870422}, {"text": "Word Alignment", "start_pos": 26, "end_pos": 40, "type": "TASK", "confidence": 0.6891398429870605}]}], "abstractContent": [{"text": "Mining opinion targets is a fundamental and important task for opinion mining from online reviews.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 63, "end_pos": 77, "type": "TASK", "confidence": 0.7476842999458313}]}, {"text": "To this end, there are usually two kinds of methods: syntax based and alignment based methods.", "labels": [], "entities": []}, {"text": "Syntax based methods usually exploited syntactic patterns to extract opinion targets, which were however prone to suffer from parsing errors when dealing with online informal texts.", "labels": [], "entities": []}, {"text": "In contrast, alignment based methods used word alignment model to fulfill this task, which could avoid parsing errors without using parsing.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 42, "end_pos": 56, "type": "TASK", "confidence": 0.7653624415397644}]}, {"text": "However, there is no research fo-cusing on which kind of method is more better when given a certain amount of reviews.", "labels": [], "entities": []}, {"text": "To fill this gap, this paper empirically studies how the performance of these two kinds of methods vary when changing the size, domain and language of the corpus.", "labels": [], "entities": []}, {"text": "We further combine syntactic patterns with alignment model by using a partially supervised framework and investigate whether this combination is useful or not.", "labels": [], "entities": []}, {"text": "In our experiments, we verify that our combination is effective on the corpus with small and medium size.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the rapid development of Web 2.0, huge amount of user reviews are springing upon the Web.", "labels": [], "entities": []}, {"text": "Mining opinions from these reviews become more and more urgent since that customers expect to obtain fine-grained information of products and manufacturers need to obtain immediate feedbacks from customers.", "labels": [], "entities": []}, {"text": "In opinion mining, extracting opinion targets is a basic subtask.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 3, "end_pos": 17, "type": "TASK", "confidence": 0.8852048516273499}]}, {"text": "It is to extract a list of the objects which users express their opinions on and can provide the prior information of targets for opinion mining.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 130, "end_pos": 144, "type": "TASK", "confidence": 0.7430600523948669}]}, {"text": "So this task has attracted many attentions.", "labels": [], "entities": []}, {"text": "To extract opinion targets, pervious approaches usually relied on opinion words which are the words used to express the opinions (;).", "labels": [], "entities": []}, {"text": "Intuitively, opinion words often appear around and modify opinion targets, and there are opinion relations and associations between them.", "labels": [], "entities": []}, {"text": "If we have known some words to be opinion words, the words which those opinion words modify will have high probability to be opinion targets.", "labels": [], "entities": []}, {"text": "Therefore, identifying the aforementioned opinion relations between words is important for extracting opinion targets from reviews.", "labels": [], "entities": [{"text": "extracting opinion targets from reviews", "start_pos": 91, "end_pos": 130, "type": "TASK", "confidence": 0.8814848065376282}]}, {"text": "To fulfill this aim, previous methods exploited the words co-occurrence information to indicate them ().", "labels": [], "entities": []}, {"text": "Obviously, these methods cannot obtain precise extraction because of the diverse expressions by reviewers, like long-span modified relations between words, etc.", "labels": [], "entities": []}, {"text": "To handle this problem, several methods exploited syntactic information, where several heuristic patterns based on syntactic parsing were designed ().", "labels": [], "entities": []}, {"text": "However, the sentences in online reviews usually have informal writing styles including grammar mistakes, typos, improper punctuation etc., which make parsing prone to generate mistakes.", "labels": [], "entities": []}, {"text": "As a result, the syntax-based methods which heavily depended on the parsing performance would suffer from parsing errors ( . To improve the extraction performance, we can only employ some exquisite highprecision patterns.", "labels": [], "entities": []}, {"text": "But this strategy is likely to miss many opinion targets and has lower recall with the increase of corpus size.", "labels": [], "entities": [{"text": "recall", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.999656081199646}]}, {"text": "To resolve these problems, formulated identifying opinion relations between words as an monolingual alignment process.", "labels": [], "entities": []}, {"text": "A word can find its corresponding modifiers by using a word alignment: Mining Opinion Relations between Words using Partially Supervised Alignment Model model (WAM).", "labels": [], "entities": []}, {"text": "Without using syntactic parsing, the noises from parsing errors can be effectively avoided.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.6991363763809204}]}, {"text": "Nevertheless, we notice that the alignment model is a statistical model which needs sufficient data to estimate parameters.", "labels": [], "entities": [{"text": "alignment", "start_pos": 33, "end_pos": 42, "type": "TASK", "confidence": 0.9600037932395935}]}, {"text": "When the data is insufficient, it would suffer from data sparseness and may make the performance decline.", "labels": [], "entities": []}, {"text": "Thus, from the above analysis, we can observe that the size of the corpus has impacts on these two kinds of methods, which arises some important questions: how can we make selection between syntax based methods and alignment based method for opinion target extraction when given a certain amount of reviews?", "labels": [], "entities": [{"text": "opinion target extraction", "start_pos": 242, "end_pos": 267, "type": "TASK", "confidence": 0.6611286699771881}]}, {"text": "And which kind of methods can obtain better extraction performance with the variation of the size of the dataset?", "labels": [], "entities": []}, {"text": "Although () had proved the effectiveness of WAM, they mainly performed experiments on the dataset with medium size.", "labels": [], "entities": [{"text": "WAM", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.9692925810813904}]}, {"text": "We are still curious about that when the size of dataset is larger or smaller, can we obtain the same conclusion?", "labels": [], "entities": []}, {"text": "To our best knowledge, these problems have not been studied before.", "labels": [], "entities": []}, {"text": "Moreover, opinions maybe expressed in different ways with the variation of the domain and language of the corpus.", "labels": [], "entities": []}, {"text": "When the domain or language of the corpus is changed, what conclusions can we obtain?", "labels": [], "entities": []}, {"text": "To answer these questions, in this paper, we adopt a unified framework to extract opinion targets from reviews, in the key component of which we vary the methods between syntactic patterns and alignment model.", "labels": [], "entities": []}, {"text": "Then we run the whole framework on the corpus with different size (from #500 to #1, 000, 000), domain (three domains) and language (Chinese and English) to empirically assess the performance variations and discuss which method is more effective.", "labels": [], "entities": []}, {"text": "Furthermore, this paper naturally addresses another question: is it useful for opinion targets extraction when we combine syntactic patterns and word alignment model into a unified model?", "labels": [], "entities": [{"text": "opinion targets extraction", "start_pos": 79, "end_pos": 105, "type": "TASK", "confidence": 0.6630129416783651}, {"text": "word alignment", "start_pos": 145, "end_pos": 159, "type": "TASK", "confidence": 0.7218609005212784}]}, {"text": "To this end, we employ a partially supervised alignment model (PSWAM) like ().", "labels": [], "entities": []}, {"text": "Based on the exquisitely designed high-precision syntactic patterns, we can obtain some precisely modified relations between words in sentences, which provide a portion of links of the full alignments.", "labels": [], "entities": []}, {"text": "Then, these partial alignment links can be regarded as the constrains fora standard unsupervised word alignment model.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 97, "end_pos": 111, "type": "TASK", "confidence": 0.6956952065229416}]}, {"text": "And each target candidate would find its modifier under the partial supervision.", "labels": [], "entities": []}, {"text": "In this way, the errors generated in standard unsupervised WAM can be corrected.", "labels": [], "entities": [{"text": "WAM", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.9249463081359863}]}, {"text": "For example in, \"kindly\" and \"courteous\" are incorrectly regarded as the modifiers for \"foods\" if the WAM is performed in an whole unsupervised framework.", "labels": [], "entities": [{"text": "WAM", "start_pos": 102, "end_pos": 105, "type": "TASK", "confidence": 0.9652318358421326}]}, {"text": "However, by using some high-precision syntactic patterns, we can assert \"courteous\" should be aligned to \"services\", and \"delicious\" should be aligned to \"foods\".", "labels": [], "entities": []}, {"text": "Through combination under partial supervision, we can see \"kindly\" and \"courteous\" are correctly linked to \"services\".", "labels": [], "entities": []}, {"text": "Thus, it's reasonable to expect to yield better performance than traditional methods.", "labels": [], "entities": []}, {"text": "As mentioned in (, using PSWAM cannot only inherit the advantages of WAM: effectively avoiding noises from syntactic parsing errors when dealing with informal texts, but also can improve the mining performance by using partial supervision.", "labels": [], "entities": []}, {"text": "However, is this kind of combination always useful for opinion target extraction?", "labels": [], "entities": [{"text": "opinion target extraction", "start_pos": 55, "end_pos": 80, "type": "TASK", "confidence": 0.7497382561365763}]}, {"text": "To access this problem, we also make comparison between PSWAM based method and the aforementioned methods in the same corpora with different size, language and domain.", "labels": [], "entities": []}, {"text": "The experimental results show the combination by using PSWAM can be effective on dataset with small and medium size.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, to answer the questions mentioned in the first section, we collect a large collection named as LARGE, which includes reviews from three different domains and different languages.", "labels": [], "entities": [{"text": "LARGE", "start_pos": 112, "end_pos": 117, "type": "METRIC", "confidence": 0.914438009262085}]}, {"text": "This collection was also used in ().", "labels": [], "entities": []}, {"text": "In the experiments, reviews are first segmented into sentences according to punctuation.", "labels": [], "entities": []}, {"text": "The detailed statistical information of the used collection is shown in Table 2, where Restaurant is crawled from the Chinese Web site: www.dianping.com.", "labels": [], "entities": [{"text": "Chinese Web site", "start_pos": 118, "end_pos": 134, "type": "DATASET", "confidence": 0.890483021736145}]}, {"text": "The Hotel and MP3 are used in (), which are respectively crawled from www.tripadvisor.com and www.amazon.com.", "labels": [], "entities": [{"text": "Hotel", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.9540912508964539}]}, {"text": "For each dataset, we perform random sampling to generate testing set with different sizes, where we use sampled subsets with #sentences = 5 \u00d7 10 2 , 10 3 , 5 \u00d7 10 3 , 10 4 , 5 \u00d7 10 4 , 10 5 and 10 6 sentences respectively.", "labels": [], "entities": []}, {"text": "Each , and parsed by using Minipar toolkit.", "labels": [], "entities": [{"text": "Minipar toolkit", "start_pos": 27, "end_pos": 42, "type": "DATASET", "confidence": 0.936720460653305}]}, {"text": "And the method of () is used to identify noun phrases.", "labels": [], "entities": []}, {"text": "We select precision and recall as the metrics.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9995239973068237}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9992782473564148}]}, {"text": "Specifically, to obtain the ground truth, we manually label all opinion targets for each subset.", "labels": [], "entities": []}, {"text": "In this process, three annotators are involved.", "labels": [], "entities": []}, {"text": "First, every noun/noun phrase and its contexts in review sentences are extracted.", "labels": [], "entities": []}, {"text": "Then two annotators were required to judge whether every noun/noun phrase is opinion target or not.", "labels": [], "entities": []}, {"text": "If a conflict happens, a third annotator will make judgment for final results.", "labels": [], "entities": []}, {"text": "The average inter-agreements is 0.74.", "labels": [], "entities": [{"text": "inter-agreements", "start_pos": 12, "end_pos": 28, "type": "METRIC", "confidence": 0.9773176908493042}]}, {"text": "We also perform a significant test, i.e., a t-test with a default significant level of 0.05.", "labels": [], "entities": []}], "tableCaptions": []}