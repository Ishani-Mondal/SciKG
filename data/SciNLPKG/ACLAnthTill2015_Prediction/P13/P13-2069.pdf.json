{"title": [{"text": "Generalized Reordering Rules for Improved SMT", "labels": [], "entities": [{"text": "Generalized Reordering", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.856989711523056}, {"text": "SMT", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.695381224155426}]}], "abstractContent": [{"text": "We present a simple yet effective approach to syntactic reordering for Statistical Machine Translation (SMT).", "labels": [], "entities": [{"text": "syntactic reordering", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.7361450493335724}, {"text": "Statistical Machine Translation (SMT)", "start_pos": 71, "end_pos": 108, "type": "TASK", "confidence": 0.8529493610064188}]}, {"text": "Instead of solely relying on the top-1 best-matching rule for source sentence preordering, we generalize fully lexicalized rules into partially lexicalized and unlexicalized rules to broaden the rule coverage.", "labels": [], "entities": []}, {"text": "Furthermore, , we consider multiple permutations of all the matching rules, and select the final reordering path based on the weighed sum of reordering probabilities of these rules.", "labels": [], "entities": []}, {"text": "Our experiments in English-Chinese and English-Japanese translations demonstrate the effectiveness of the proposed approach: we observe consistent and significant improvement in translation quality across multiple test sets in both language pairs judged by both humans and automatic metric.", "labels": [], "entities": []}], "introductionContent": [{"text": "The proper handling of linguistic structures (such as word order) has been one of the most important yet most challenging tasks in statistical machine translation (SMT).", "labels": [], "entities": [{"text": "handling of linguistic structures (such as word order)", "start_pos": 11, "end_pos": 65, "type": "TASK", "confidence": 0.6932932585477829}, {"text": "statistical machine translation (SMT)", "start_pos": 131, "end_pos": 168, "type": "TASK", "confidence": 0.8035797774791718}]}, {"text": "It is important because it has significant impact on human judgment of Machine Translation (MT) quality: an MT output without structure is just like a bag of words.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 71, "end_pos": 95, "type": "TASK", "confidence": 0.8415186166763305}]}, {"text": "It is also very challenging due to the lack of effective methods to model the structural difference between source and target languages.", "labels": [], "entities": []}, {"text": "A lot of research has been conducted in this area.", "labels": [], "entities": []}, {"text": "Approaches include distance-based penalty function and lexicalized distortion models such as),.", "labels": [], "entities": []}, {"text": "Because these models are relatively easy to compute, they are widely used in phrase-based SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 90, "end_pos": 93, "type": "TASK", "confidence": 0.7881253361701965}]}, {"text": "Hierarchical phrase-based system (Hiero,) utilizes long range reordering information without syntax.", "labels": [], "entities": []}, {"text": "Other models use more syntactic information (string-to-tree, treeto-string, tree-to-tree, string-to-dependency etc.) to capture the structural difference between language pairs, including), (),), and).", "labels": [], "entities": []}, {"text": "These models demonstrate better handling of sentence structures, while the computation is more expensive compared with the distortion-based models.", "labels": [], "entities": []}, {"text": "In the middle of the spectrum, (Xia and McCord 2004),,), and) combined the benefits of the above two strategies: their approaches reorder an input sentence based on a set of reordering rules defined over the source sentence's syntax parse tree.", "labels": [], "entities": []}, {"text": "As a result, the re-ordered source sentence resembles the word order of its target translation.", "labels": [], "entities": []}, {"text": "The reordering rules are either hand-crafted or automatically learned from the training data (source parse trees and bitext word alignments).", "labels": [], "entities": []}, {"text": "These rules can be unlexicalized (only including the constituent labels) or fully lexicalized (including both the constituent labels and their head words).", "labels": [], "entities": []}, {"text": "The unlexicalized reordering rules are more general and can be applied broadly, but sometimes they are not discriminative enough.", "labels": [], "entities": []}, {"text": "In the following English-Chinese reordering rules, 0.44 NP PP \u2192 0 1 0.56 NP PP \u2192 1 0 the NP and PP nodes are reordered with close to random probabilities.", "labels": [], "entities": []}, {"text": "When the constituents are attached with their headwords, the reordering probability is much higher than that of the unlexicalized rules.", "labels": [], "entities": []}, {"text": "Unfortunately, the application of lexicalized reordering rules is constrained by data sparseness: it is unlikely to train the NP:<noun> PP:<prep> reordering rules for every nounpreposition combination.", "labels": [], "entities": []}, {"text": "Even for the learnt lexicalized rules, their counts are also relatively small, thus the reordering probabilities may not be estimated reliably, which could lead to incorrect reordering decisions.", "labels": [], "entities": []}, {"text": "To alleviate this problem, we generalize fully lexicalized rules into partially lexicalized rules, which are further generalized into unlexicalized rules.", "labels": [], "entities": []}, {"text": "Such generalization allows partial match when the fully lexicalized rules cannot be found, thus achieving broader rule coverage.", "labels": [], "entities": []}, {"text": "Given anode of a source parse tree, we find all the matching rules and consider all their possible reorder permutations.", "labels": [], "entities": []}, {"text": "Each permutation has a reordering score, which is the weighted sum of reordering probabilities of all the matching rules.", "labels": [], "entities": []}, {"text": "We reorder the child nodes based on the permutation with the highest reordering score.", "labels": [], "entities": []}, {"text": "Finally we translate the reordered sentence in a phrase-based SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.9075102210044861}]}, {"text": "Our experiments in English to Chinese (EnZh) and English to Japanese (EnJa) translation demonstrate the effectiveness of the proposed approach: we observe consistent improvements across multiple test sets in multiple language pairs and significant gain inhuman judgment of the MT quality.", "labels": [], "entities": [{"text": "English to Japanese (EnJa) translation", "start_pos": 49, "end_pos": 87, "type": "TASK", "confidence": 0.5688743122986385}, {"text": "MT", "start_pos": 277, "end_pos": 279, "type": "TASK", "confidence": 0.9750576019287109}]}, {"text": "This paper is organized as follows: in section 2 we briefly introduce the syntax-based reordering technique.", "labels": [], "entities": []}, {"text": "In section 3, we describe our approach.", "labels": [], "entities": []}, {"text": "In section 4, we show the experiment results, which is followed by conclusion in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We applied the generalized syntax-based reordering on both English-Chinese (EnZh) and English-Japanese (EnJa) translations.", "labels": [], "entities": []}, {"text": "Our English parser is IBM's maximum entropy constituent parser (Ratnaparkhi 1999) trained on Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 93, "end_pos": 106, "type": "DATASET", "confidence": 0.9942367076873779}]}, {"text": "Experiments in) indicated that minimal difference was observed using Berkeley's parser or IBM's parser for reordering.", "labels": [], "entities": []}, {"text": "Our EnZh training data consists of 20 million sentence pairs (~250M words), half of which are from LDC released bilingual corpora and the other half are from technical domains (e.g., software manual).", "labels": [], "entities": [{"text": "EnZh training data", "start_pos": 4, "end_pos": 22, "type": "DATASET", "confidence": 0.7196571429570516}]}, {"text": "We first trained automatic word alignments (HMM alignments in both directions and a MaxEnt alignment), then parsed the English sentences with the IBM parser.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 27, "end_pos": 42, "type": "TASK", "confidence": 0.7239687740802765}]}, {"text": "We extracted different reordering rules from the word alignments and the English parse trees.", "labels": [], "entities": []}, {"text": "After frequency-based pruning, we obtained 12M lexicalized rules, 13M partially lexicalized rules and 600K unlexicalized rules.", "labels": [], "entities": []}, {"text": "Using these rules, we applied preordering on the English sentences and then built an SMT system with the reordered training data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 85, "end_pos": 88, "type": "TASK", "confidence": 0.986302375793457}]}, {"text": "Our decoder is a phrase-based decoder), where various features are combined within the log-linear framework.", "labels": [], "entities": []}, {"text": "These features include source-to-target phrase translation score based on relative frequency, source-to-target and target-to-source word-toword translation scores, a 5-gram language model score, distortion model scores and word count.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7108888626098633}, {"text": "word-toword translation", "start_pos": 132, "end_pos": 155, "type": "TASK", "confidence": 0.679632693529129}]}, {"text": "We selected one tuning set from software manual domain (Tech1), and used PRO tuning (Hopkins and May 2011) to select decoder feature weights.", "labels": [], "entities": [{"text": "PRO tuning", "start_pos": 73, "end_pos": 83, "type": "METRIC", "confidence": 0.8227953910827637}, {"text": "Hopkins and May 2011", "start_pos": 85, "end_pos": 105, "type": "DATASET", "confidence": 0.8837425708770752}]}, {"text": "Our test sets include one from the online technical support domain (Tech2) and one from the news domain: the NIST MT08 English-Chinese evaluation test data.", "labels": [], "entities": [{"text": "NIST MT08 English-Chinese evaluation test data", "start_pos": 109, "end_pos": 155, "type": "DATASET", "confidence": 0.9276057680447897}]}, {"text": "The translation quality is measured by BLEU score).", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9444555640220642}, {"text": "BLEU score", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9687840342521667}]}, {"text": "shows the BLEU score of the baseline phrase-based system (PBMT) that uses lexicalized reordering at decoding time rather than preordering.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9992006421089172}]}, {"text": "Next, shows the translation results with several preordered systems that use unlexicalized (UnLex), fully lexicalized (FullLex) and partially lexicalized (PartLex) rules, respectively.", "labels": [], "entities": []}, {"text": "The lexicalized reordering model is still applicable for preordered systems so that some preordering errors can be recovered at run time.", "labels": [], "entities": []}, {"text": "First we observed that the UnLex preordering model on average does not improve over the typical phrase-based MT baseline due to its limited discriminative power.", "labels": [], "entities": []}, {"text": "When the preordering decision is conditioned on the headword, the FullLex model shows some gains (~0.3 pt) thanks to the richer matching context, while the PartLex model improves further over the FullLex model because of its broader coverage.", "labels": [], "entities": []}, {"text": "Combining all three with multipermutation, multi-level rule matching (MPML) brings the most gains, with consistent (~1.3 Bleu points) improvement over the baseline system on all the test sets.", "labels": [], "entities": [{"text": "Bleu", "start_pos": 121, "end_pos": 125, "type": "METRIC", "confidence": 0.9145060181617737}]}, {"text": "Note that the Bleu scores on the news domain (MT08) are higher than those on the tech domain.", "labels": [], "entities": [{"text": "Bleu", "start_pos": 14, "end_pos": 18, "type": "METRIC", "confidence": 0.9821762442588806}, {"text": "MT08", "start_pos": 46, "end_pos": 50, "type": "DATASET", "confidence": 0.5182619690895081}]}, {"text": "This is because the Tech1 and Tech2 have one reference translation while MT08 has 4 reference translations.", "labels": [], "entities": [{"text": "MT08", "start_pos": 73, "end_pos": 77, "type": "DATASET", "confidence": 0.947208046913147}]}, {"text": "In addition to the automatic MT evaluation, we also used human judgment of quality of the MT translation on a set of randomly selected 125 sentences from the baseline and improved reordering systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 29, "end_pos": 31, "type": "TASK", "confidence": 0.9917402267456055}, {"text": "MT translation", "start_pos": 90, "end_pos": 104, "type": "TASK", "confidence": 0.9501826465129852}]}, {"text": "The human judgment score is 2.82 for the UnLex system output, and 3.04 for the improved MPML reordering output.", "labels": [], "entities": []}, {"text": "The 0.2 point improvement on the 0-5 scale is considered significant.", "labels": [], "entities": []}, {"text": "We also apply the same generalized reordering technique on English-Japanese (EnJa) translation.", "labels": [], "entities": [{"text": "English-Japanese (EnJa) translation", "start_pos": 59, "end_pos": 94, "type": "TASK", "confidence": 0.5637821316719055}]}, {"text": "As there is very limited publicly available English-Japanese parallel data, most our training data (20M sentence pairs) is from the in-house software manual domain.", "labels": [], "entities": []}, {"text": "We use the same English parser and phrase-based decoder as in EnZh experiment.", "labels": [], "entities": []}, {"text": "shows the translation results on technical and news domain test sets.", "labels": [], "entities": [{"text": "translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9608619213104248}]}, {"text": "All the test sets have single reference translation.", "labels": [], "entities": []}, {"text": "First, we observe that the improvement from preordering is larger than that in EnZh MT (1.6-3 pts vs. 1 pt).", "labels": [], "entities": [{"text": "preordering", "start_pos": 44, "end_pos": 55, "type": "METRIC", "confidence": 0.9860061407089233}, {"text": "EnZh MT", "start_pos": 79, "end_pos": 86, "type": "DATASET", "confidence": 0.6067137122154236}]}, {"text": "This is because the word order difference between English and Japanese is larger than that between English and Chinese (Japanese is a SOV language while both English and Chinese are SVO languages).", "labels": [], "entities": []}, {"text": "Without preordering, correct word orders are difficult to obtain given the typical skip-window beam search in the PBMT.", "labels": [], "entities": [{"text": "PBMT", "start_pos": 114, "end_pos": 118, "type": "DATASET", "confidence": 0.9163604378700256}]}, {"text": "Also, as in EnZh, the PartLex model outperforms the UnLex model, both of which being significantly better than the FullLex model due to the limited rule coverage in the later model: only 50% preordering rules are applied in the FullLex model.", "labels": [], "entities": [{"text": "EnZh", "start_pos": 12, "end_pos": 16, "type": "DATASET", "confidence": 0.9113301634788513}]}, {"text": "Tech1 test set is a very close match to the training data thus its BLEU score is much higher.", "labels": [], "entities": [{"text": "Tech1 test set", "start_pos": 0, "end_pos": 14, "type": "DATASET", "confidence": 0.9796334902445475}, {"text": "BLEU score", "start_pos": 67, "end_pos": 77, "type": "METRIC", "confidence": 0.9824348986148834}]}], "tableCaptions": [{"text": " Table 1: MT experiment comparison using different  syntax-based reordering techniques on English- Chinese test sets.", "labels": [], "entities": [{"text": "MT experiment comparison", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.8561919132868449}]}, {"text": " Table 2: MT experiment comparison using  generalized syntax-based reordering techniques on  English-Japanese test sets.", "labels": [], "entities": [{"text": "MT experiment comparison", "start_pos": 10, "end_pos": 34, "type": "TASK", "confidence": 0.866146186987559}]}]}