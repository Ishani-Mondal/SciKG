{"title": [{"text": "Identifying Sentiment Words Using an Optimization-based Model without Seed Words", "labels": [], "entities": [{"text": "Identifying Sentiment Words", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.9402398864428202}]}], "abstractContent": [{"text": "Sentiment Word Identification (SWI) is a basic technique in many sentiment analysis applications.", "labels": [], "entities": [{"text": "Sentiment Word Identification (SWI)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7747985770304998}, {"text": "sentiment analysis", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.9312422871589661}]}, {"text": "Most existing researches exploit seed words, and lead to low ro-bustness.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel optimization-based model for SWI.", "labels": [], "entities": [{"text": "SWI", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.9896441698074341}]}, {"text": "Unlike previous approaches, our model exploits the sentiment labels of documents instead of seed words.", "labels": [], "entities": []}, {"text": "Several experiments on real datasets show that WEED is effective and outperforms the state-of-the-art methods with seed words.", "labels": [], "entities": [{"text": "WEED", "start_pos": 47, "end_pos": 51, "type": "TASK", "confidence": 0.4534417390823364}]}], "introductionContent": [{"text": "In recent years, sentiment analysis () has become a hotspot in opinion mining and attracted much attention.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.9533532559871674}, {"text": "opinion mining", "start_pos": 63, "end_pos": 77, "type": "TASK", "confidence": 0.8527562320232391}]}, {"text": "Sentiment analysis is to classify a text span into different sentiment polarities, i.e. positive, negative or neutral.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9546597301959991}]}, {"text": "Sentiment Word Identification (SWI) is a basic technique in sentiment analysis.", "labels": [], "entities": [{"text": "Sentiment Word Identification (SWI)", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.7758921136458715}, {"text": "sentiment analysis", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.9512011110782623}]}, {"text": "According to ())), SWI can be applied to many fields, such as determining critics opinions about a given product, tweeter classification, summarization of reviews, and message filtering, etc.", "labels": [], "entities": [{"text": "SWI", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9811331629753113}, {"text": "tweeter classification", "start_pos": 114, "end_pos": 136, "type": "TASK", "confidence": 0.7011091262102127}, {"text": "summarization of reviews", "start_pos": 138, "end_pos": 162, "type": "TASK", "confidence": 0.9033879041671753}, {"text": "message filtering", "start_pos": 168, "end_pos": 185, "type": "TASK", "confidence": 0.7674283981323242}]}, {"text": "Thus in this paper, we focus on SWI.", "labels": [], "entities": [{"text": "SWI", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.9878971576690674}]}, {"text": "Here is a simple example of how SWI is applied to comment analysis.", "labels": [], "entities": [{"text": "SWI", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.9731019735336304}, {"text": "comment analysis", "start_pos": 50, "end_pos": 66, "type": "TASK", "confidence": 0.7904141545295715}]}, {"text": "The sentence below is an movie review in IMDB database: \u2022 Bored performers and a lackluster plot and script, do not make a good action movie.", "labels": [], "entities": [{"text": "IMDB database", "start_pos": 41, "end_pos": 54, "type": "DATASET", "confidence": 0.9547354876995087}, {"text": "Bored", "start_pos": 58, "end_pos": 63, "type": "METRIC", "confidence": 0.9645493030548096}]}, {"text": "In order to judge the sentence polarity (thus we can learn about the preference of this user), one must recognize which words are able to express sentiment.", "labels": [], "entities": []}, {"text": "In this sentence, \"bored\" and \"lackluster\" are negative while \"good\" should be positive, yet * Corresponding author its polarity is reversed by \"not\".", "labels": [], "entities": []}, {"text": "By such analysis, we then conclude such movie review is a negative comment.", "labels": [], "entities": []}, {"text": "But how do we recognize sentiment words?", "labels": [], "entities": []}, {"text": "To achieve this, previous supervised approaches need labeled polarity words, also called seed words, usually manually selected.", "labels": [], "entities": []}, {"text": "The words to be classified by their sentiment polarities are called candidate words.", "labels": [], "entities": []}, {"text": "Prior works study the relations between labeled seed words and unlabeled candidate words, and then obtain sentiment polarities of candidate words by these relations.", "labels": [], "entities": []}, {"text": "There are many ways to generate word relations.", "labels": [], "entities": []}, {"text": "The authors of and use statistical measures, such as point wise mutual information (PMI), to compute similarities in words or phrases.", "labels": [], "entities": []}, {"text": "Kanayama and Nasukawa (2006) assume sentiment words successively appear in the text, so one could find sentiment words in the context of seed words).", "labels": [], "entities": []}, {"text": "In and), a Markov random walk model is applied to a large word relatedness graph, constructed according to the synonyms and hypernyms in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 137, "end_pos": 144, "type": "DATASET", "confidence": 0.9566059708595276}]}, {"text": "However, approaches based on seed words has obvious shortcomings.", "labels": [], "entities": []}, {"text": "First, polarities of seed words are not reliable for various domains.", "labels": [], "entities": []}, {"text": "As a simple example, \"rise\" is a neutral word most often, but becomes positive in stock market.", "labels": [], "entities": []}, {"text": "Second, manually selection of seed words can be very subjective even if the application domain is determined.", "labels": [], "entities": []}, {"text": "Third, algorithms using seed words have low robustness.", "labels": [], "entities": []}, {"text": "Any missing keyword in the set of seed words could lead to poor performance.", "labels": [], "entities": []}, {"text": "Therefore, the seed word set of such algorithms demands high completeness (by containing common polarity words as many as possible).", "labels": [], "entities": []}, {"text": "Unlike the previous research work, we identify sentiment words without any seed words in this paper.", "labels": [], "entities": []}, {"text": "Instead, the documents' bag-of-words in-formation and their polarity labels are exploited in the identification process.", "labels": [], "entities": []}, {"text": "Intuitively, polarities of the document and its most component sentiment words are the same.", "labels": [], "entities": []}, {"text": "We call such phenomenon as \"sentiment matching\".", "labels": [], "entities": [{"text": "sentiment matching", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.8841295838356018}]}, {"text": "Moreover, if a word is found mostly in positive documents, it is very likely a positive word, and vice versa.", "labels": [], "entities": []}, {"text": "We present an optimization-based model, called WEED, to exploit the phenomenon of \"sentiment matching\".", "labels": [], "entities": [{"text": "sentiment matching", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.8698161244392395}]}, {"text": "We first measure the importance of the component words in the labeled documents semantically.", "labels": [], "entities": []}, {"text": "Here, the basic assumption is that important words are more sentiment related to the document than those less important.", "labels": [], "entities": []}, {"text": "Then, we estimate the polarity of each document using its component words' importance along with their sentiment values, and compare the estimation to the real polarity.", "labels": [], "entities": [{"text": "estimation", "start_pos": 137, "end_pos": 147, "type": "METRIC", "confidence": 0.9532805681228638}]}, {"text": "After that, we construct an optimization model for the whole corpus to weigh the overall estimation error, which is minimized by the best sentiment values of candidate words.", "labels": [], "entities": []}, {"text": "Finally, several experiments demonstrate the effectiveness of our approach.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this paper is the first work that identifies sentiment words without seed words.", "labels": [], "entities": []}], "datasetContent": [{"text": "We leverage two widely used document datasets.", "labels": [], "entities": []}, {"text": "The first dataset is the Cornell Movie Review Data 1 , containing 1,000 positive and 1,000 negative processed reviews.", "labels": [], "entities": [{"text": "Cornell Movie Review Data 1", "start_pos": 25, "end_pos": 52, "type": "DATASET", "confidence": 0.9764804720878602}]}, {"text": "The other is the Stanford Large Dataset), a collection of 50,000 comments from IMDB, evenly divided into training and test sets.", "labels": [], "entities": [{"text": "Stanford Large Dataset)", "start_pos": 17, "end_pos": 40, "type": "DATASET", "confidence": 0.923119381070137}]}, {"text": "The ground-truth is generated with the help of a sentiment lexicon, MPQA subjective lexicon 3 . We randomly select 20% polarity words as the seed words, and the remaining are candidate ones.", "labels": [], "entities": [{"text": "MPQA subjective lexicon", "start_pos": 68, "end_pos": 91, "type": "DATASET", "confidence": 0.8614415327707926}]}, {"text": "Here, the seed words are provided for the baseline methods but not for ours.", "labels": [], "entities": []}, {"text": "In order to increase the difficulty of our task, several non-polarity words are added to the candidate word set.", "labels": [], "entities": []}, {"text": "shows the word distribution of two datasets.", "labels": [], "entities": []}, {"text": "Word Set pos neg non total  In order to demonstrate the effectiveness of our model, we select two baselines, SO-PMI (Turney and Littman, 2003) and COM ().", "labels": [], "entities": []}, {"text": "Both of them need seed words.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Three rows in the middle shows the fea- ture vectors of three movie reviews, and the last  row shows the word polarity value vector \u20d7  w. For  simplicity, we use TF value to represent the word  importance feature.", "labels": [], "entities": [{"text": "word polarity value vector \u20d7  w", "start_pos": 115, "end_pos": 146, "type": "METRIC", "confidence": 0.8469248513380686}, {"text": "TF value", "start_pos": 172, "end_pos": 180, "type": "METRIC", "confidence": 0.9700871706008911}]}]}