{"title": [{"text": "Discriminative state tracking for spoken dialog systems", "labels": [], "entities": [{"text": "Discriminative state tracking", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6550997296969095}]}], "abstractContent": [{"text": "In spoken dialog systems, statistical state tracking aims to improve robustness to speech recognition errors by tracking a posterior distribution over hidden dialog states.", "labels": [], "entities": [{"text": "statistical state tracking", "start_pos": 26, "end_pos": 52, "type": "TASK", "confidence": 0.656087319056193}]}, {"text": "Current approaches based on gener-ative or discriminative models have different but important shortcomings that limit their accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9940787553787231}]}, {"text": "In this paper we discuss these limitations and introduce anew approach for discriminative state tracking that overcomes them by leveraging the problem structure.", "labels": [], "entities": [{"text": "discriminative state tracking", "start_pos": 75, "end_pos": 104, "type": "TASK", "confidence": 0.7171883781750997}]}, {"text": "An offline evaluation with dialog data collected from real users shows improvements in both state tracking accuracy and the quality of the posterior probabilities.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.8700059652328491}]}, {"text": "Features that encode speech recognition error patterns are particularly helpful, and training requires relatively few dialogs.", "labels": [], "entities": [{"text": "speech recognition error patterns", "start_pos": 21, "end_pos": 54, "type": "TASK", "confidence": 0.8054214864969254}]}], "introductionContent": [{"text": "Spoken dialog systems interact with users via natural language to help them achieve a goal.", "labels": [], "entities": []}, {"text": "As the interaction progresses, the dialog manager maintains a representation of the state of the dialog in a process called dialog state tracking.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 124, "end_pos": 145, "type": "TASK", "confidence": 0.6908350984255472}]}, {"text": "For example, in a bus schedule information system, the dialog state might indicate the user's desired bus route, origin, and destination.", "labels": [], "entities": []}, {"text": "Dialog state tracking is difficult because automatic speech recognition (ASR) and spoken language understanding (SLU) errors are common, and can cause the system to misunderstand the user's needs.", "labels": [], "entities": [{"text": "Dialog state tracking", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9155941605567932}, {"text": "speech recognition (ASR)", "start_pos": 53, "end_pos": 77, "type": "TASK", "confidence": 0.8294480443000793}, {"text": "spoken language understanding (SLU)", "start_pos": 82, "end_pos": 117, "type": "TASK", "confidence": 0.7439331213633219}]}, {"text": "At the same time, state tracking is crucial because the system relies on the estimated dialog state to choose actions -for example, which bus schedule information to present to the user.", "labels": [], "entities": [{"text": "state tracking", "start_pos": 18, "end_pos": 32, "type": "TASK", "confidence": 0.7533156275749207}]}, {"text": "The dialog state tracking problem can be formalized as follows).", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.7931480407714844}]}, {"text": "Each system turn in the dialog is one datapoint.", "labels": [], "entities": []}, {"text": "For each datapoint, the input consists of three items: a set of K features that describes the current dialog context, G dialog state hypotheses, and for each dialog state hypothesis, M features that describe that dialog state hypothesis.", "labels": [], "entities": []}, {"text": "The task is to assign a probability distribution over the G dialog state hypotheses, plus a meta-hypothesis which indicates that none of the G hypotheses is correct.", "labels": [], "entities": []}, {"text": "Note that G varies across turns (datapoints) -for example, in the first turn of, G = 3, and in the second and third turns G = 5.", "labels": [], "entities": [{"text": "G", "start_pos": 10, "end_pos": 11, "type": "METRIC", "confidence": 0.9953681230545044}]}, {"text": "Also note that the dialog state tracker is not predicting the contents of the dialog state hypotheses; the dialog state hypotheses contents are given by some external process, and the task is to predict a probability distribution over them, where the probability assigned to a hypothesis indicates the probability that it is correct.", "labels": [], "entities": [{"text": "dialog state tracker", "start_pos": 19, "end_pos": 39, "type": "TASK", "confidence": 0.6993281841278076}]}, {"text": "It is a requirement that the G hypotheses are disjoint; with the special \"everything else\" meta-hypothesis, exactly one hypothesis is correct by construction.", "labels": [], "entities": []}, {"text": "After the dialog state tracker has output its distribution, this distribution is passed to a separate, downstream process that chooses what action to take next (e.g., how to respond to the user).", "labels": [], "entities": []}, {"text": "Dialog state tracking can be seen an analogous to assigning a probability distribution over items on an ASR N-best list given speech input and the recognition output, including the contents of the N-best list.", "labels": [], "entities": [{"text": "Dialog state tracking", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8887257178624471}]}, {"text": "In this task, the general features describe the recognition overall (such as length of utterance), and the hypothesis-specific features describe each N-best entry (such as decoder cost).", "labels": [], "entities": []}, {"text": "Another analogous task is assigning a probability distribution over a set of URLs given a search query and the URLs.", "labels": [], "entities": []}, {"text": "Here, general features describe the whole set of results, e.g., number of words in the query, and hypothesis-specific features describe each URL, e.g., the fraction of query words contained in page.", "labels": [], "entities": []}, {"text": "For dialog state tracking, most commercial systems use hand-crafted heuristics, selecting the SLU result with the highest confidence score, and discarding alternatives.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.8771002292633057}]}, {"text": "In contrast, statistical approaches compute a posterior distribution over many hypotheses for the dialog state.", "labels": [], "entities": []}, {"text": "The key insight is that dialog is a temporal process in which correlations between turns can be harnessed to overcome SLU errors.", "labels": [], "entities": []}, {"text": "Statistical state tracking has been shown to improve task completion in end-to-end spoken dialog systems; ; ).", "labels": [], "entities": [{"text": "Statistical state tracking", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6056745847066244}]}, {"text": "Two types of statistical state tracking approaches have been proposed.", "labels": [], "entities": [{"text": "statistical state tracking", "start_pos": 13, "end_pos": 39, "type": "TASK", "confidence": 0.665627102057139}]}, {"text": "Generative approaches;; ; ) use generative models that capture how the SLU results are generated from hidden dialog states.", "labels": [], "entities": []}, {"text": "These models can be used to track an arbitrary number of state hypotheses, but cannot easily incorporate large sets of potentially informative features (e.g. from ASR, SLU, dialog history), resulting in poor probability estimates.", "labels": [], "entities": []}, {"text": "As an illustration, in, a generative model might fail to assign the highest score to the correct hypothesis (61C) after the second turn.", "labels": [], "entities": []}, {"text": "In contrast, discriminative approaches use conditional models, trained in a discriminative fashion) to directly estimate the distribution over a set of state hypotheses based on a large set of informative features.", "labels": [], "entities": []}, {"text": "They generally produce more accurate distributions, but in their current form they can only track a handful of state hypotheses.", "labels": [], "entities": []}, {"text": "As a result, the correct hypothesis maybe discarded: for instance, in, a discriminative model might consider only the top 2 SLU results, and thus fail to consider the correct 61C hypothesis at all.", "labels": [], "entities": []}, {"text": "The main contribution of this paper is to develop anew discriminative model for dialog state tracking that can operate over an arbitrary number of hypotheses and still compute accurate probability estimates.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 80, "end_pos": 101, "type": "TASK", "confidence": 0.8599654237429301}]}, {"text": "We also explore the relative importance of different feature sets for this task, and measure the amount of data required to reliably train our model.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use data from the public deployment of two systems in the Spoken Dialog Challenge () which provide bus schedule information for Pittsburgh, USA.", "labels": [], "entities": []}, {"text": "The systems, DS1 and DS2, were fielded by AT&T, and are described in  and Williams (2012).", "labels": [], "entities": [{"text": "AT&T", "start_pos": 42, "end_pos": 46, "type": "DATASET", "confidence": 0.9144563674926758}]}, {"text": "Both systems followed a highly directed flow, separately collecting 5 slots.", "labels": [], "entities": []}, {"text": "All users were asked for their bus route, origin, and destination; then, they were optionally prompted fora date and time.", "labels": [], "entities": []}, {"text": "Each slot was explicitly or implicitly confirmed before collecting the next.", "labels": [], "entities": []}, {"text": "At the end, bus times were presented.", "labels": [], "entities": []}, {"text": "The two systems differed in acoustic models, confidence scoring model, state tracking method and parameters, number of supported routes (8 vs 40, for DS1 and DS2 respectively), presence of minor bugs, and user population.", "labels": [], "entities": []}, {"text": "These differences yield distinctions in the distributions in the two corpora).", "labels": [], "entities": []}, {"text": "In both systems, a dialog state hypothesis consists of a value of the user's goal fora certain slot: for example, a state hypothesis for the origin slot might be \"carnegie mellon university\".", "labels": [], "entities": []}, {"text": "The number G of state hypotheses (e.g. slot values) observed so far depends on the dialog, and turn within that dialog.", "labels": [], "entities": []}, {"text": "For instance, in, G progressively takes values 3, 5 and 5.", "labels": [], "entities": []}, {"text": "Dialog state hypotheses with identical contents (e.g., the same bus route) are merged.", "labels": [], "entities": []}, {"text": "The correctness of the SLU results was manually labeled by professional annotators.", "labels": [], "entities": []}, {"text": "To perform a comparative analysis of various state tracking algorithms, we test them offline, i.e., by re-running state tracking against the SLU results from deployment.", "labels": [], "entities": [{"text": "state tracking", "start_pos": 45, "end_pos": 59, "type": "TASK", "confidence": 0.7303923666477203}]}, {"text": "However, care must be taken: when the improved state-tracker is installed into a dialog system and used to drive action selection, the distribution of the resulting dialog data (which is an input for the state tracker) will change.", "labels": [], "entities": [{"text": "action selection", "start_pos": 113, "end_pos": 129, "type": "TASK", "confidence": 0.649649441242218}]}, {"text": "In other words, it is known a priori that the train and test distributions will be mismatched.", "labels": [], "entities": []}, {"text": "Hence, when conducting offline experiments, if train and test data were drawn from the same matched distribution, this may overstate performance.: Overview of dialog state tracking.", "labels": [], "entities": [{"text": "dialog state tracking", "start_pos": 159, "end_pos": 180, "type": "TASK", "confidence": 0.7959259152412415}]}, {"text": "In this example, the dialog state contains the user's desired bus route.", "labels": [], "entities": []}, {"text": "At each turn, the system produces a spoken output.", "labels": [], "entities": []}, {"text": "The user's spoken response is processed to extract a set of spoken language understanding (SLU) results, each with a local confidence score.", "labels": [], "entities": []}, {"text": "A set of G dialog state hypotheses is formed by considering all SLU results observed so far, including the current turn and all previous turns.", "labels": [], "entities": []}, {"text": "For each state hypothesis, a feature extractor produces a set of M hypothesis-specific features, plus a single set of K general features that describes the current dialog context.", "labels": [], "entities": []}, {"text": "The dialog state tracker uses these features to produce a distribution over the G state hypotheses, plus a meta-hypothesis rest which accounts for the possibility that none of the G hypotheses are correct.", "labels": [], "entities": [{"text": "dialog state tracker", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.6265471378962199}]}, {"text": "To account for this effect, we explicitly study train/test mismatch through three partitions of data from DS1 and DS2 (see): MATCH1 contains matched train/test data from the DS2 dataset; MATCH2 contains matched train/test data from both datasets; finally, MISMATCH contains mismatched train/test data.", "labels": [], "entities": [{"text": "DS2 dataset", "start_pos": 174, "end_pos": 185, "type": "DATASET", "confidence": 0.8656213283538818}, {"text": "MISMATCH", "start_pos": 256, "end_pos": 264, "type": "METRIC", "confidence": 0.4543185532093048}]}, {"text": "While the MISMATCH condition may not identically replicate the mismatch observed from deploying anew state tracker online (since online characteristics depend on user behavior) training on DS1 and testing on DS2 at least ensures the presence of some real-world mismatch.", "labels": [], "entities": [{"text": "MISMATCH", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.7897801399230957}]}, {"text": "We assess performance via two metrics: accuracy and L2 norm.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9996029734611511}, {"text": "L2 norm", "start_pos": 52, "end_pos": 59, "type": "METRIC", "confidence": 0.8592641353607178}]}, {"text": "Accuracy indicates whether the state hypothesis with the highest assigned probability is correct, where rest is correct iff none of the SLU results prior to the current turn include the user's goal.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9900966882705688}]}, {"text": "High accuracy is important as a dialog system must ultimately commit to a single interpretation of the user's needs -e.g., it must commit to a route in order to provide bus timetable information.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 5, "end_pos": 13, "type": "METRIC", "confidence": 0.9991564750671387}]}, {"text": "In addition, the L2 norm (or Brier score,) also captures how well calibrated the output probabilities are, which is crucial to decision theoretic methods for action selection.", "labels": [], "entities": [{"text": "Brier score", "start_pos": 29, "end_pos": 40, "type": "METRIC", "confidence": 0.9839341938495636}]}, {"text": "The L2 norm is computed between the output posterior and the ground-truth vector, which has 1 in the position of the correct item and 0 elsewhere.", "labels": [], "entities": []}, {"text": "Both metrics are computed for each slot in each turn, and reported by averaging across all turns and slots.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Performance of the different algorithms on each dataset using three feature combinations. Base  features are denoted as b, ASR/SLU confusion features as c and history features as h. Performance for  the feature combinations bh is omitted for space; it is between b and bc.", "labels": [], "entities": []}, {"text": " Table 4: Performance per slot on dataset MIS- MATCH using the full feature set bch.", "labels": [], "entities": [{"text": "MIS- MATCH", "start_pos": 42, "end_pos": 52, "type": "METRIC", "confidence": 0.588531881570816}]}]}