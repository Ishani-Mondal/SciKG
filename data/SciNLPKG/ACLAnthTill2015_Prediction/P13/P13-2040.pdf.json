{"title": [], "abstractContent": [{"text": "Ambiguity preserving representations such as lattices are very useful in a number of NLP tasks, including paraphrase generation, paraphrase recognition, and machine translation evaluation.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 106, "end_pos": 127, "type": "TASK", "confidence": 0.8836088478565216}, {"text": "paraphrase recognition", "start_pos": 129, "end_pos": 151, "type": "TASK", "confidence": 0.9299470484256744}, {"text": "machine translation evaluation", "start_pos": 157, "end_pos": 187, "type": "TASK", "confidence": 0.8581516941388448}]}, {"text": "Lattices compactly represent lexical variation, but word order variation leads to a combina-torial explosion of states.", "labels": [], "entities": []}, {"text": "We advocate hypergraphs as compact representations for sets of utterances describing the same event or object.", "labels": [], "entities": []}, {"text": "We present a method to construct hypergraphs from sets of utterances, and evaluate this method on a simple recognition task.", "labels": [], "entities": []}, {"text": "Given a set of utterances that describe a single objector event, we construct such a hypergraph, and demonstrate that it can recognize novel descriptions of the same event with high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 182, "end_pos": 190, "type": "METRIC", "confidence": 0.9893643856048584}]}], "introductionContent": [{"text": "Humans can construct abroad range of descriptions for almost any objector event.", "labels": [], "entities": []}, {"text": "In this paper, we will refer to such objects or events as groundings, in the sense of grounded semantics.", "labels": [], "entities": []}, {"text": "Examples of groundings include pictures (, videos (Chen and Dolan, 2011), translations of a sentence from another language, or even paraphrases of the same sentence (.", "labels": [], "entities": []}, {"text": "One crucial problem is recognizing whether novel utterances are relevant descriptions of those groundings.", "labels": [], "entities": []}, {"text": "In the case of machine translation, this is the evaluation problem; for images and videos, this is recognition and retrieval.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.7583907842636108}]}, {"text": "Generating descriptions of events is also often an interesting task: we might like to find a novel paraphrase fora given sentence, or generate a description of a grounding that meets certain criteria (e.g., brevity, use of a restricted vocabulary).", "labels": [], "entities": [{"text": "Generating descriptions of events", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8797200471162796}]}, {"text": "Much prior work has used lattices to compactly represent a range of lexical choices (.", "labels": [], "entities": []}, {"text": "However, lattices cannot compactly represent alternate word orders, a common occurrence in linguistic descriptions.", "labels": [], "entities": []}, {"text": "Consider the following excerpts from a video description corpus (Chen and Dolan, 2011): \u2022 A man is sliding a cat on the floor.", "labels": [], "entities": []}, {"text": "\u2022 A boy is cleaning the floor with the cat.", "labels": [], "entities": []}, {"text": "\u2022 A cat is being pushed across the floor by a man.", "labels": [], "entities": []}, {"text": "Ideally we would like to recognize that the following utterance is also a valid description of that event: A cat is being pushed across the floor by a boy.", "labels": [], "entities": []}, {"text": "That is difficult with lattice representations.", "labels": [], "entities": []}, {"text": "Consider the following context free grammar: | is cleaning X 4 with X 2 X 2 \u2192 a cat | the cat X 3 \u2192 is being pushed across X 4 by X 0 X 4 \u2192 the floor This grammar compactly captures many lexical and syntactic variants of the input set.", "labels": [], "entities": []}, {"text": "Note how the labels act as a kind of multiple-sequencealignment allowing reordering: spans of tokens covered by the same label are, in a sense, aligned.", "labels": [], "entities": []}, {"text": "This hypergraph or grammar represents a semantic neighborhood: a set of utterances that describe the same entity in a semantic space.", "labels": [], "entities": []}, {"text": "Semantic neighborhoods are defined in terms of a grounding.", "labels": [], "entities": []}, {"text": "Two utterances are neighbors with respect to some grounding (semantic event) if they are both descriptions of that grounding.", "labels": [], "entities": []}, {"text": "Paraphrases, in contrast, maybe defined overall possible groundings.", "labels": [], "entities": []}, {"text": "That is, two words or phrases are considered paraphrases if there exists some grounding that they both describe.", "labels": [], "entities": []}, {"text": "The paraphrase relation is more permissive than the semantic neighbor relation in that regard.", "labels": [], "entities": []}, {"text": "We believe that it is much easier to define and evaluate semantic neighbors.", "labels": [], "entities": []}, {"text": "Human annotators may have difficulty separating paraphrases from unrelated or merely related utterances, and this line may not be consistent between judges.", "labels": [], "entities": []}, {"text": "Annotating whether an utterance clearly describes a grounding is a much easier task.", "labels": [], "entities": [{"text": "Annotating whether an utterance clearly describes a grounding", "start_pos": 0, "end_pos": 61, "type": "TASK", "confidence": 0.6806096434593201}]}, {"text": "This paper describes a simple method for constructing hypergraph-shaped Semantic Neighborhoods from sets of expressions describing the same grounding.", "labels": [], "entities": []}, {"text": "The method is evaluated in a paraphrase recognition task, inspired by a CAPTCHA task).", "labels": [], "entities": [{"text": "paraphrase recognition task", "start_pos": 29, "end_pos": 56, "type": "TASK", "confidence": 0.8359845479329427}]}], "datasetContent": [{"text": "We explore a task in description recognition.", "labels": [], "entities": [{"text": "description recognition", "start_pos": 21, "end_pos": 44, "type": "TASK", "confidence": 0.9501303136348724}]}, {"text": "Given a large set of videos and a number of descriptions for each video, we build a system that can recognize fluent and accurate descriptions of videos.", "labels": [], "entities": []}, {"text": "Such a recognizer has a number of uses.", "labels": [], "entities": []}, {"text": "One example currently in evaluation is a novel CAPTCHAs: to differentiate a human from a bot, a video is presented, and the response must be a reasonably accurate and fluent description of this video.", "labels": [], "entities": []}, {"text": "We split the above data into training and test.", "labels": [], "entities": []}, {"text": "From the training sets, we build a set of recognizers.", "labels": [], "entities": []}, {"text": "Then we present these recognizers with a series of inputs, some of which are from the held outset of correct descriptions of this video, and some of which are from descriptions of other videos.", "labels": [], "entities": []}, {"text": "Based on discussions with authors of CAPTCHA systems, a ratio of actual users to spammers of 2:1 seemed reasonable, so we selected one negative example for every two positives.", "labels": [], "entities": []}, {"text": "This simulates the accuracy of the system when presented with a simple bot that supplies random, well-formed text as CAPTCHA answers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9993577599525452}]}, {"text": "As a baseline, we compare against a simple tfidf approach.", "labels": [], "entities": []}, {"text": "In this baseline we first pool all the training descriptions of the video into a single virtual document.", "labels": [], "entities": []}, {"text": "We gather term frequencies and inverse document frequencies across the whole corpus.", "labels": [], "entities": []}, {"text": "An incoming utterance to be classified is scored by computing the dot product of its counted terms with each document; it is assigned to the document with the highest dot product (cosine similarity).", "labels": [], "entities": []}, {"text": "demonstrates that a baseline tf-idf approach is a reasonable starting point.", "labels": [], "entities": []}, {"text": "An oracle selection from among the top three is the best performance -clearly this is a reasonable approach.", "labels": [], "entities": []}, {"text": "That said, grammar based approach shows improvements over the baseline tf-idf, especially in recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 93, "end_pos": 99, "type": "METRIC", "confidence": 0.9847317934036255}]}, {"text": "Recall is crucial in a CAPTCHA style task: if we fail to recognize utterances provided by humans, we risk frustration or abandonment of the service protected by the CAPTCHA.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.8114707469940186}]}, {"text": "The relative importance of false positives versus false negatives 1 A bot might perform object recognition on the videos and supply a stream of object names.", "labels": [], "entities": [{"text": "object recognition", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.7309874296188354}]}, {"text": "We might simulate this by classifying utterances consisting of appropriate object words but without appropriate syntax or function words.", "labels": [], "entities": []}, {"text": "(a) Input descriptions: \u2022 A cat pops a bunch of little balloons that are on the groung.", "labels": [], "entities": []}, {"text": "\u2022 A dog attacks a bunch of balloons.", "labels": [], "entities": []}, {"text": "\u2022 A dog is biting balloons and popping them.", "labels": [], "entities": []}, {"text": "\u2022 A dog is playing balloons.", "labels": [], "entities": []}, {"text": "\u2022 A dog is playing with balloons.", "labels": [], "entities": []}, {"text": "\u2022 A dog is playing with balls.", "labels": [], "entities": []}, {"text": "\u2022 A dog is popping balloons with its teeth.", "labels": [], "entities": []}, {"text": "\u2022 A dog is popping balloons.", "labels": [], "entities": []}, {"text": "\u2022 A dog is popping balloons.", "labels": [], "entities": []}, {"text": "\u2022 A dog plays with a bunch of balloons.", "labels": [], "entities": []}, {"text": "\u2022 A small dog is attacking balloons.", "labels": [], "entities": []}, {"text": "\u2022 The dog enjoyed popping balloons.", "labels": [], "entities": []}, {"text": "\u2022 The dog popped the balloons.", "labels": [], "entities": []}, {"text": "(b) Top ranked yields from the resulting grammar: Figure 2: Example yields from a small grammar.", "labels": [], "entities": []}, {"text": "The descriptions in (a) were parsed as-is (including the typographical error \"groung\"), and a refined grammar was trained with 4 splits.", "labels": [], "entities": []}, {"text": "The top k yields from this grammar along with the probability of that derivation are listed in (b).", "labels": [], "entities": []}, {"text": "A '+' symbol indicates that the yield was in the training set.", "labels": [], "entities": []}, {"text": "No smoothing or pruning was performed on this grammar.", "labels": [], "entities": []}, {"text": "may vary depending on the underlying resource.", "labels": [], "entities": []}, {"text": "Adjusting the free parameters of this method allows us to achieve different thresholds.", "labels": [], "entities": []}, {"text": "We can see that rule pruning does not have a large impact on overall results, though it does allow yet another means of tradiing off precision vs. recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.9939731955528259}, {"text": "recall", "start_pos": 147, "end_pos": 153, "type": "METRIC", "confidence": 0.9953991770744324}]}], "tableCaptions": [{"text": " Table 2: Experimental results. (a) Comparison of  tf-idf baseline against grammar based approach,  varying several free parameters. An oracle checks  if the correct video is in the top three. For the  grammar variants, the number of splits S and the  smoothing threshold k are varied. (b) Variations  on the rule pruning threshold t and number of  split-merge rounds S. > 0 indicates that all rules  are retained. Here the smoothing threshold k is  fixed at 32.", "labels": [], "entities": []}]}