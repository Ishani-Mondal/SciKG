{"title": [{"text": "Collective Annotation of Linguistic Resources: Basic Principles and a Formal Model", "labels": [], "entities": []}], "abstractContent": [{"text": "Crowdsourcing, which offers new ways of cheaply and quickly gathering large amounts of information contributed by volunteers online, has revolutionised the collection of labelled data.", "labels": [], "entities": []}, {"text": "Yet, to create annotated linguistic resources from this data, we face the challenge of having to combine the judgements of a potentially large group of annotators.", "labels": [], "entities": []}, {"text": "In this paper we investigate how to aggregate individual annotations into a single collective annotation , taking inspiration from the field of social choice theory.", "labels": [], "entities": [{"text": "social choice theory", "start_pos": 144, "end_pos": 164, "type": "TASK", "confidence": 0.6794569691022238}]}, {"text": "We formulate a general formal model for collective annotation and propose several aggregation methods that go beyond the commonly used majority rule.", "labels": [], "entities": []}, {"text": "We test some of our methods on data from a crowdsourcing experiment on textual entailment annotation.", "labels": [], "entities": [{"text": "textual entailment annotation", "start_pos": 71, "end_pos": 100, "type": "TASK", "confidence": 0.6817253629366556}]}], "introductionContent": [{"text": "In recent years, the possibility to undertake largescale annotation projects with hundreds or thousands of annotators has become a reality thanks to online crowdsourcing methods such as Amazon's Mechanical Turk and Games with a Purpose.", "labels": [], "entities": []}, {"text": "Although these techniques open the door to a true revolution for the creation of annotated corpora, within the computational linguistics community there so far is no clear understanding of how the so-called \"wisdom of the crowds\" could or should be used to develop useful annotated linguistic resources.", "labels": [], "entities": []}, {"text": "Those who have looked into this increasingly important issue have mostly concentrated on validating the quality of multiple non-expert annotations in terms of how they compare to expert gold standards; but they have only used simple aggregation methods based on majority voting to combine the judgments of individual annotators.", "labels": [], "entities": []}, {"text": "In this paper, we take a different perspective and instead focus on investigating different aggregation methods for deriving a single collective annotation from a diverse set of judgments.", "labels": [], "entities": []}, {"text": "For this we draw inspiration from the field of social choice theory, a theoretical framework for combining the preferences or choices of several individuals into a collective decision ().", "labels": [], "entities": [{"text": "social choice theory", "start_pos": 47, "end_pos": 67, "type": "TASK", "confidence": 0.7250206271807352}]}, {"text": "Our aim is to explore the parallels between the task of aggregating the preferences of the citizens participating in an election and the task of combining the expertise of speakers taking part in an annotation project.", "labels": [], "entities": []}, {"text": "Our contribution consists in the formulation of a general formal model for collective annotation and, in particular, the introduction of several families of aggregation methods that go beyond the commonly used majority rule.", "labels": [], "entities": [{"text": "collective annotation", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.6959234774112701}]}, {"text": "The remainder of this paper is organised as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we introduce some basic terminology and argue that there are four natural forms of collective annotation.", "labels": [], "entities": []}, {"text": "We then focus on one of them and present a formal model for it in Section 3.", "labels": [], "entities": []}, {"text": "We also formulate some basic principles of aggregation within this model in the same section.", "labels": [], "entities": []}, {"text": "Section 4 introduces three families of aggregation methods: bias-correcting majority rules, greedy methods for identifying (near-)consensual coalitions of annotators, and distance-based aggregators.", "labels": [], "entities": []}, {"text": "We test the former two families of aggregators, as well as the simple majority rule commonly used in similar studies, in a case study on data extracted from a crowdsourcing experiment on textual entailment in Section 5.", "labels": [], "entities": []}, {"text": "Section 6 discusses related work and Section 7 concludes.", "labels": [], "entities": []}, {"text": "() and word similarity rating) involve choosing from amongst a set of categories-acts in a dialogue act taxonomy or values on a scale, respectivelywhich remains fixed for all items in the annotation task.", "labels": [], "entities": [{"text": "word similarity rating", "start_pos": 7, "end_pos": 29, "type": "METRIC", "confidence": 0.6144619981447855}]}, {"text": "In contrast, in tasks such as word sense labelling and PP-attachment annotation ( coders need to choose a category amongst a set of options specific to each item-the possible senses of each word or the possible attachment points in each sentence with a prepositional phrase.", "labels": [], "entities": [{"text": "word sense labelling", "start_pos": 30, "end_pos": 50, "type": "TASK", "confidence": 0.6962210933367411}]}, {"text": "In either case (one set of categories for all items vs. item-specific sets of categories), annotators are typically asked to identify, for each item, the category they consider the best match.", "labels": [], "entities": []}, {"text": "In addition, they maybe given the opportunity to indicate that they cannot judge (the \"don't know\" or \"unclear\" category).", "labels": [], "entities": []}, {"text": "For large-scale annotation projects run over the Internet it is furthermore very likely that an annotator will not be confronted with every single item, and it makes sense to distinguish items not seen by the annotator from items labelled as \"don't know\".", "labels": [], "entities": []}, {"text": "We refer to this form of annotation, i.e., an annotation task where coders have the option to (i) label items with one of the available categories, to (ii) choose \"don't know\", or to (iii) not label an item at all, as plain annotation.", "labels": [], "entities": []}, {"text": "Plain annotation is the most common form of annotation and it is the one we shall focus on in this paper.", "labels": [], "entities": []}, {"text": "However, other, more complex, forms of annotation are also possible and of interest.", "labels": [], "entities": []}, {"text": "For instance, we may ask coders to rank the available categories (resulting in, say, a weak or partial order over the categories); we may ask them to provide a qualitative ratings of the available categories for each item (e.g., excellent match, good match, etc.); or we may ask for quantitative ratings (e.g., numbers from 1 to 100).", "labels": [], "entities": []}, {"text": "We refer to these forms of annotation as complex annotation.", "labels": [], "entities": []}, {"text": "We want to investigate how to aggregate the information available for each item once annotations by multiple annotators have been collected.", "labels": [], "entities": []}, {"text": "In line with the terminology used in social choice theory and particularly judgment aggregation (Ar-1 Some authors have combined qualitative and quantitative ratings; e.g., for the Graded Word Sense dataset of coders were asked to classify each relevant WordNet sense fora given item on a 5-point scale: 1 completely different, 2 mostly different, 3 similar, 4 very similar, 5 identical.), let us call an aggregation method independent if the outcome regarding a given item j only depends on the categories provided by the annotators regarding j itself (but not on, say, the categories assigned to a different item j ).", "labels": [], "entities": [{"text": "social choice theory", "start_pos": 37, "end_pos": 57, "type": "TASK", "confidence": 0.7085370222727457}, {"text": "Ar-1", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.9897394776344299}, {"text": "Word Sense dataset", "start_pos": 188, "end_pos": 206, "type": "DATASET", "confidence": 0.8734187086423238}]}, {"text": "Independent aggregation methods are attractive due to their simplicity.", "labels": [], "entities": []}, {"text": "They also have some conceptual appeal: when deciding on j maybe we should only concern ourselves with what people have to say regarding j?", "labels": [], "entities": []}, {"text": "On the other hand, insisting on independence prevents us from exploiting potentially useful information that cuts across items.", "labels": [], "entities": []}, {"text": "For instance, if a particular annotator almost always chooses category c, then we should maybe give less weight to her selecting c for the item j at hand than when some other annotator chooses c for j.", "labels": [], "entities": []}, {"text": "This would call for methods that do not respect independence, which we shall refer to as general aggregation.", "labels": [], "entities": []}, {"text": "Note that when studying independent aggregation methods, without loss of generality, we may assume that each annotation task consists of just a single item.", "labels": [], "entities": []}, {"text": "In view of our discussion above, there are four classes of approaches to collective annotation: (1) Independent aggregation of plain annotations.", "labels": [], "entities": []}, {"text": "This is the simplest case, resulting in a fairly limited design space.", "labels": [], "entities": []}, {"text": "When, fora given item, each annotator has to choose between k categories (or abstain) and we do not permit ourselves to use any other information, then the only reasonable choice is to implement the plurality rule, under which the winning category is the category chosen by the largest number of annotators.", "labels": [], "entities": []}, {"text": "In case there are exactly two categories available, the plurality rule is also called the majority rule.", "labels": [], "entities": []}, {"text": "The only additional consideration to make here (besides how to deal with ties) is whether or not we may want to declare no winner at all in case the plurality winner does not win by a sufficiently significant margin or does not make a particular quota.", "labels": [], "entities": []}, {"text": "This is the most common approach in the literature (see, e.g.,).", "labels": [], "entities": []}, {"text": "(2) Independent aggregation of complex annotations.", "labels": [], "entities": []}, {"text": "This is a natural generalisation of the first approach, resulting in a wider range of possible methods.", "labels": [], "entities": []}, {"text": "We shall not explore it here, but only point out that in case annotators provide linear orders over categories, there is a close resemblance to classical voting the-ory (; in case only partial orders can be elicited, recent work in computational social choice on the generalisation of classical voting rules may prove helpful (; and in case annotators rate categories using qualitative expressions such as excellent match, the method of majority judgment of should be considered.", "labels": [], "entities": []}, {"text": "(3) General aggregation of plain annotations.", "labels": [], "entities": []}, {"text": "This is the approach we shall discuss below.", "labels": [], "entities": []}, {"text": "It is related to voting in combinatorial domains studied in computational social choice (, and to both binary aggregation) and judgment aggregation).", "labels": [], "entities": []}, {"text": "(4) General aggregation of complex annotations.", "labels": [], "entities": []}, {"text": "While appealing due to its great level of generality, this approach can only be tackled successfully once approaches and are sufficiently well understood.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Observed agreement (and \u03ba) between collective annotations and the gold standard.", "labels": [], "entities": [{"text": "Observed", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9765685796737671}]}]}