{"title": [{"text": "A Novel Translation Framework Based on Rhetorical Structure Theory", "labels": [], "entities": [{"text": "Novel Translation", "start_pos": 2, "end_pos": 19, "type": "TASK", "confidence": 0.6825345754623413}]}], "abstractContent": [{"text": "Rhetorical structure theory (RST) is widely used for discourse understanding, which represents a discourse as a hierarchically semantic structure.", "labels": [], "entities": [{"text": "Rhetorical structure theory (RST)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8235321541627248}, {"text": "discourse understanding", "start_pos": 53, "end_pos": 76, "type": "TASK", "confidence": 0.7231208384037018}]}, {"text": "In this paper, we propose a novel translation framework with the help of RST.", "labels": [], "entities": []}, {"text": "In our framework, the translation process mainly includes three steps: 1) Source RST-tree acquisition: a source sentence is parsed into an RST tree; 2) Rule extraction: translation rules are extracted from the source tree and the target string via bilingual word alignment; 3) RST-based translation: the source RST-tree is translated with translation rules.", "labels": [], "entities": [{"text": "Source RST-tree acquisition", "start_pos": 74, "end_pos": 101, "type": "TASK", "confidence": 0.7114018599192301}, {"text": "Rule extraction", "start_pos": 152, "end_pos": 167, "type": "TASK", "confidence": 0.8067225217819214}, {"text": "RST-based translation", "start_pos": 277, "end_pos": 298, "type": "TASK", "confidence": 0.9805943071842194}]}, {"text": "Experiments on Chinese-to-English show that our RST-based approach achieves improvements of 2.3/0.77/1.43 BLEU points on NIST04/NIST05/CWMT2008 respectively.", "labels": [], "entities": [{"text": "RST-based", "start_pos": 48, "end_pos": 57, "type": "TASK", "confidence": 0.9735828638076782}, {"text": "BLEU", "start_pos": 106, "end_pos": 110, "type": "METRIC", "confidence": 0.9893730282783508}, {"text": "NIST04", "start_pos": 121, "end_pos": 127, "type": "DATASET", "confidence": 0.9689056873321533}, {"text": "NIST05/CWMT2008", "start_pos": 128, "end_pos": 143, "type": "DATASET", "confidence": 0.6756817102432251}]}], "introductionContent": [{"text": "For statistical machine translation (SMT), a crucial issue is how to build a translation model to extract as much accurate and generative translation knowledge as possible.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 4, "end_pos": 41, "type": "TASK", "confidence": 0.8229241867860159}, {"text": "generative translation knowledge", "start_pos": 127, "end_pos": 159, "type": "TASK", "confidence": 0.8907709916432699}]}, {"text": "The existing SMT models have made much progress.", "labels": [], "entities": [{"text": "SMT", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9821344614028931}]}, {"text": "However, they still suffer from the bad performance of unnatural or even unreadable translation, especially when the sentences become complicated.", "labels": [], "entities": []}, {"text": "We think the deep reason is that those models only extract translation information on lexical or syntactic level, but fail to give an overall understanding of source sentences on semantic level of discourse.", "labels": [], "entities": []}, {"text": "In order to solve such problem,) build discourse-based translation models to ensure the lexical coherence or consistency.", "labels": [], "entities": []}, {"text": "Although some lexicons can be translated better by their models, the overall structure still remains unnatural.", "labels": [], "entities": []}, {"text": "design a discourse structure transferring module, but leave much work to do, especially on how to integrate this module into SMT and how to automatically analyze the structures.", "labels": [], "entities": [{"text": "discourse structure transferring module", "start_pos": 9, "end_pos": 48, "type": "TASK", "confidence": 0.745371550321579}, {"text": "SMT", "start_pos": 125, "end_pos": 128, "type": "TASK", "confidence": 0.9660618901252747}]}, {"text": "Those reasons urge us to seek anew translation framework under the idea of \"translation with overall understanding\".", "labels": [], "entities": []}, {"text": "Rhetorical structure theory (RST) ( provides us with a good perspective and inspiration to build such a framework.", "labels": [], "entities": [{"text": "Rhetorical structure theory (RST)", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8230473001797994}]}, {"text": "Generally, an RST tree can explicitly show the minimal spans with semantic functional integrity, which are called elementary discourse units (edus) (), and it also depicts the hierarchical relations among edus.", "labels": [], "entities": [{"text": "RST", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.961462140083313}]}, {"text": "Furthermore, since different languages' edus are usually equivalent on semantic level, it is intuitive to create anew framework based on RST by directly mapping the source edus to target ones.", "labels": [], "entities": []}, {"text": "Taking the Chinese-to-English translation as an example, our translation framework works as the following steps: 1) Source RST-tree acquisition: a source sentence is parsed into an RST-tree; 2) Rule extraction: translation rules are extracted from the source tree and the target string via bilingual word alignment; 3) RST-based translation: the source RSTtree is translated into target sentence with extracted translation rules.", "labels": [], "entities": [{"text": "RST-tree acquisition", "start_pos": 123, "end_pos": 143, "type": "TASK", "confidence": 0.8286491930484772}, {"text": "Rule extraction", "start_pos": 194, "end_pos": 209, "type": "TASK", "confidence": 0.7646288573741913}, {"text": "RST-based translation", "start_pos": 319, "end_pos": 340, "type": "TASK", "confidence": 0.9825174808502197}]}, {"text": "Experiments on Chinese-to-English sentencelevel discourses demonstrate that this method achieves significant improvements.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Segmentation and labeling result.", "labels": [], "entities": [{"text": "Segmentation", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.929104208946228}, {"text": "labeling", "start_pos": 27, "end_pos": 35, "type": "TASK", "confidence": 0.8717377781867981}]}, {"text": " Table 3: Comparison with related models.", "labels": [], "entities": []}]}