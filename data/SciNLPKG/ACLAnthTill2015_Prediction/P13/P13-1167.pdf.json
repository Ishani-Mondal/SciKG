{"title": [{"text": "Evaluating Text Segmentation using Boundary Edit Distance", "labels": [], "entities": [{"text": "Evaluating Text Segmentation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8022540807723999}]}], "abstractContent": [{"text": "This work proposes anew segmentation evaluation metric, named boundary similarity (B), an inter-coder agreement coefficient adaptation, and a confusion-matrix for segmentation that are all based upon an adaptation of the boundary edit distance in Fournier and Inkpen (2012).", "labels": [], "entities": [{"text": "segmentation evaluation", "start_pos": 24, "end_pos": 47, "type": "TASK", "confidence": 0.8875951170921326}, {"text": "boundary similarity (B)", "start_pos": 62, "end_pos": 85, "type": "METRIC", "confidence": 0.8707304954528808}]}, {"text": "Existing seg-mentation metrics such as P k , WindowD-iff, and Segmentation Similarity (S) are all able to award partial credit for near misses between boundaries, but are biased towards segmentations containing few or tightly clustered boundaries.", "labels": [], "entities": []}, {"text": "Despite S's improvements, its normalization also produces cosmetically high values that overestimate agreement & performance, leading this work to propose a solution.", "labels": [], "entities": []}], "introductionContent": [{"text": "Text segmentation is the task of splitting text into segments by placing boundaries within it.", "labels": [], "entities": [{"text": "Text segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7041578441858292}]}, {"text": "Segmentation is performed fora variety of purposes and is often a pre-processing step in a larger task.", "labels": [], "entities": [{"text": "Segmentation", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.9770514369010925}]}, {"text": "E.g., text can be topically segmented to aid video and audio retrieval (, question answering (, subjectivity analysis (, and even summarization (.", "labels": [], "entities": [{"text": "question answering", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.8336212337017059}, {"text": "summarization", "start_pos": 130, "end_pos": 143, "type": "TASK", "confidence": 0.9857721924781799}]}, {"text": "A variety of segmentation granularities, or atomic units, exist, including segmentations at the morpheme (e.g., Sirts and Alum\u00e4e 2012), word (e.g.,), sentence (e.g.,, and paragraph (e.g., Hearst 1997) levels.", "labels": [], "entities": []}, {"text": "Between each atomic unit lies the potential to place a boundary.", "labels": [], "entities": []}, {"text": "Segmentations can also represent the structure of text as being organized linearly (e.g., Hearst 1997), hierarchically (e.g., Eisenstein 2009), etc.", "labels": [], "entities": []}, {"text": "Theoretically, segmentations could also contain varying boundary types, e.g., two boundary types could differentiate between act and scene breaks in a play.", "labels": [], "entities": []}, {"text": "Because of its value to natural language processing, various text segmentation tasks have been automated such as topical segmentationfor which a variety of automatic segmenters exist (e.g.,.", "labels": [], "entities": [{"text": "text segmentation", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.7267887443304062}, {"text": "topical segmentationfor", "start_pos": 113, "end_pos": 136, "type": "TASK", "confidence": 0.7747165262699127}]}, {"text": "This work addresses how to best select an automatic segmenter and which segmentation metrics are most appropriate to do so.", "labels": [], "entities": []}, {"text": "To select an automatic segmenter fora particular task, a variety of segmentation evaluation metrics have been proposed, including P k, WindowDiff (WD;, and most recently Segmentation Similarity (S;.", "labels": [], "entities": [{"text": "Segmentation Similarity", "start_pos": 170, "end_pos": 193, "type": "TASK", "confidence": 0.8344585597515106}]}, {"text": "Each of these metrics have a variety of flaws: P k and WindowDiff both under-penalize errors at the beginning of segmentations ( and have a bias towards favouring segmentations with few or tightly-clustered boundaries, while S produces overly optimistic values due to its normalization (shown later).", "labels": [], "entities": [{"text": "WindowDiff", "start_pos": 55, "end_pos": 65, "type": "DATASET", "confidence": 0.915078341960907}]}, {"text": "To overcome the flaws of existing text segmentation metrics, this work proposes anew series of metrics derived from an adaptation of boundary edit distance.", "labels": [], "entities": [{"text": "text segmentation metrics", "start_pos": 34, "end_pos": 59, "type": "TASK", "confidence": 0.77914959192276}]}, {"text": "This new metric is named boundary similarity (B).", "labels": [], "entities": [{"text": "boundary similarity (B)", "start_pos": 25, "end_pos": 48, "type": "METRIC", "confidence": 0.9266397356987}]}, {"text": "A confusion matrix to interpret segmentation as a classification problem is also proposed, allowing for the computation of information retrieval (IR) metrics such as precision and recall.", "labels": [], "entities": [{"text": "segmentation as a classification problem", "start_pos": 32, "end_pos": 72, "type": "TASK", "confidence": 0.7549661874771119}, {"text": "precision", "start_pos": 166, "end_pos": 175, "type": "METRIC", "confidence": 0.9979357719421387}, {"text": "recall", "start_pos": 180, "end_pos": 186, "type": "METRIC", "confidence": 0.9889342188835144}]}, {"text": "In this work: \u00a72 reviews existing segmentation metrics; \u00a73 proposes an adaptation of boundary edit distance, anew normalization of it, anew confusion matrix for segmentation, and an inter-coder agreement coefficient adaptation; \u00a74 compares existing segmentation metrics to those proposed herein; \u00a75 evaluates Sand B based intercoder agreement; and \u00a76 compares B, S, and WD while evaluating automatic segmenters.", "labels": [], "entities": []}], "datasetContent": [{"text": "Many early studies evaluated automatic segmenters using information retrieval (IR) metrics such as precision, recall, etc.", "labels": [], "entities": [{"text": "precision", "start_pos": 99, "end_pos": 108, "type": "METRIC", "confidence": 0.9988652467727661}, {"text": "recall", "start_pos": 110, "end_pos": 116, "type": "METRIC", "confidence": 0.9860048890113831}]}, {"text": "These metrics looked at segmentation as a binary classification problem and were very harsh in their comparisons-no credit was awarded for nearly missing a boundary.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 24, "end_pos": 36, "type": "TASK", "confidence": 0.977217972278595}]}, {"text": "Near misses occur frequently in segmentationalthough manual coders often agree upon the bulk of where segment lie, they frequently disagree upon the exact position of boundaries.", "labels": [], "entities": [{"text": "Near misses", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.7277674376964569}, {"text": "segmentationalthough manual coders", "start_pos": 32, "end_pos": 66, "type": "TASK", "confidence": 0.8571492632230123}]}, {"text": "To attempt to overcome this issue, both and Hearst (1993) conflated multiple manual segmentations into one that contained only those boundaries which the majority of coders agreed upon.", "labels": [], "entities": []}, {"text": "IR metrics were then used to compare automatic segmenters to this majority solution.", "labels": [], "entities": [{"text": "IR", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.6624894738197327}]}, {"text": "Such a majority solution is unsuitable, however, because it does not contain actual subtopic breaks, but instead the conflation of a collection of potentially disagreeing solutions.", "labels": [], "entities": []}, {"text": "Additionally, the definition of what constitutes a majority is subjective (e.g., Passonneau and Litman,,) each used 4 / 7 , 3 / 7 , and > 50%, respectively).", "labels": [], "entities": []}, {"text": "To address the issue of awarding partial credit for an automatic segmenter nearly missing a boundary-without conflating segmentations,) proposed anew metric named P k .) explain P k well: a window of size k-where k is half of the mean manual segmentation length-is slid across both automatic and manual segmentations.", "labels": [], "entities": []}, {"text": "A penalty is awarded if the window's edges are found to be in differing or the same segments within the manual segmentation and the automatic segmentation disagrees.", "labels": [], "entities": []}, {"text": "P k is the sum of these penalties overall windows.", "labels": [], "entities": []}, {"text": "Measuring the proportion of windows in error allows P k to penalize a fully missed boundary by k windows, whereas a nearly missed boundary is penalized by the distance that it is offset.", "labels": [], "entities": []}, {"text": "P k was not without issue, however.", "labels": [], "entities": []}, {"text": "Pevzner and Hearst) identified that P k : i) penalizes false negatives (FNs) 2 more than false positives (FPs); ii) does not penalize full misses within k units of a reference boundary; iii) penalize near misses too harshly in some situations; and iv) is sensitive to internal segment size variance.", "labels": [], "entities": []}, {"text": "To solve P k 's issues, proposed a modification referred to as WindowDiff (WD).", "labels": [], "entities": []}, {"text": "Its major difference is in how it decides to penalized windows: within a window, if the number of boundaries in the manual segmentation (M ij ) differs from the number of boundaries in the automatic segmentation (A ij ), then a penalty is given.", "labels": [], "entities": []}, {"text": "The ratio of penalties over windows then represents the degree of error between the segmentations, as in Equation 1.", "labels": [], "entities": []}, {"text": "This change better allowed WD to: i) penalize FPs and FNs more equally; 3 ii) Not skip full misses; iii) Less harshly penalize near misses; and iv) Reduce its sensitivity to internal segment size variance.", "labels": [], "entities": [{"text": "WD", "start_pos": 27, "end_pos": 29, "type": "TASK", "confidence": 0.9073358774185181}]}, {"text": "WD did not, however, solve all of the issues related to window-based segmentation comparison.", "labels": [], "entities": [{"text": "WD", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.5052965879440308}, {"text": "window-based segmentation comparison", "start_pos": 56, "end_pos": 92, "type": "TASK", "confidence": 0.6550540328025818}]}, {"text": "WD, and inherently P k : i) Penalize errors less at the beginning and end of segmentations (; ii) Are biased towards favouring automatic segmentations with either few or tightly-clustered boundaries (Niekrasz and Moore, 2010); iii) Calculate window size k inconsistently; 4 iv) Are not symmetric 5 (meaning that they cannot be used to produce a pairwise mean of multiple manual segmentations 6 ).", "labels": [], "entities": [{"text": "Penalize errors", "start_pos": 28, "end_pos": 43, "type": "METRIC", "confidence": 0.9523991346359253}]}, {"text": "Segmentation Similarity (S; Fournier and Inkpen 2012, pp.", "labels": [], "entities": [{"text": "Segmentation Similarity", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9238994717597961}]}, {"text": "154-156) took a different approach to comparing segmentations.", "labels": [], "entities": [{"text": "comparing segmentations", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.7646806538105011}]}, {"text": "Instead of using windows, the work proposes anew restricted edit distance called boundary edit distance which differentiates between full and near misses.", "labels": [], "entities": [{"text": "boundary edit distance", "start_pos": 81, "end_pos": 103, "type": "METRIC", "confidence": 0.719769020875295}]}, {"text": "S then normalizes the counts of full and near misses identified by boundary edit distance, as shown in Equation 2, where s a and s bare the segmentations, n t is the maximum distance that boundaries may span to be considered a near miss, edits(s a , s b , n t ) is the edit distance, and pb(D) is the number of potential boundaries in a document D (pb(D) = |D| \u2212 1).", "labels": [], "entities": []}, {"text": "Boundary edit distance models full misses as the addition/deletion of a boundary, and near misses as n-wise transpositions.", "labels": [], "entities": []}, {"text": "An n-wise transposition is the act of swapping the position of a boundary with an empty position such that it matches a boundary in the segmentation compared against (up to a spanning distance of n t ).", "labels": [], "entities": []}, {"text": "S also scales the severity of a near miss by the distance over which it is transposed, allowing it to scale the penalty of a near misses much like WD.", "labels": [], "entities": [{"text": "severity", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9717438817024231}]}, {"text": "S is also symmetric, allowing it to be used in pairwise means and inter-coder agreement coefficients.", "labels": [], "entities": []}, {"text": "The usage of an edit distance that supported transpositions to compare segmentations was an advancement over window-based methods, but boundary edit distance and its normalization S are not without problems, specifically: i) This edit distance uses string reversals (ABCD =\u21d2 DCBA) to perform transpositions, making it cumbersome to analyse individual pairs of boundaries between segmentations; ii) S is sensitive to variations in the total size of a segmentation, leading it to favour very sparse segmentations with few boundaries; iii) S produces cosmetically high values, making it difficult to interpret and causing over-estimation of inter-coder agreement.", "labels": [], "entities": []}, {"text": "In this work, these deficiencies are demonstrated and anew set of metrics are proposed as replacements.", "labels": [], "entities": []}, {"text": "Having looked at how S, WD, and B perform at a small scale in \u00a74 and on larger data set in \u00a75, this section demonstrates the use of these metrics to evaluate some automatic segmenters.", "labels": [], "entities": []}, {"text": "Three automatic segmenters were trained-or had their parameters estimated upon-The Moonstone data set, including MinCut; (), BayesSeg; (, and APS (.", "labels": [], "entities": [{"text": "Moonstone data set", "start_pos": 83, "end_pos": 101, "type": "DATASET", "confidence": 0.9608370065689087}, {"text": "APS", "start_pos": 142, "end_pos": 145, "type": "DATASET", "confidence": 0.4635947644710541}]}, {"text": "To put this evaluation into context, an upper and lower bound were also created comprised of a random coder from the manual data (Human) and a random segmenter (Random), respectively.", "labels": [], "entities": []}, {"text": "These automatic segmenters, and the upper and lower bounds, were created, trained, and run by another researcher (Anna Kazantseva) with their labels removed during the development of the metrics detailed herein (to improve the impartiality of these analyses).", "labels": [], "entities": []}, {"text": "An ideal segmentation evaluation metric should, in theory, place the three automatic segmenters between the upper and lower bounds in terms of performance if the metrics, and the segmenters, function properly.", "labels": [], "entities": [{"text": "segmentation evaluation", "start_pos": 9, "end_pos": 32, "type": "TASK", "confidence": 0.9111936986446381}]}, {"text": "The mean performance of the upper and lower bounds upon the test set of the Moonstone data set using S, B, and WD are shown in10c along with 95% confidence intervals.", "labels": [], "entities": [{"text": "Moonstone data set", "start_pos": 76, "end_pos": 94, "type": "DATASET", "confidence": 0.9811749656995138}]}, {"text": "Despite the difference in the scale of their values, both Sand WD performed almost identically, placing the three automatic segmenters between the upper and lower bounds as expected.", "labels": [], "entities": [{"text": "Sand WD", "start_pos": 58, "end_pos": 65, "type": "DATASET", "confidence": 0.8622530698776245}]}, {"text": "For S, statistically significant differences 11 (\u03b1 = 0.05) were found between all segmenters except between APS-human and MinCut-BayesSeg, and WD could only find significant differences between the automatic segmenters and the upper and lower bounds.", "labels": [], "entities": []}, {"text": "B, however, shows a marked deviation, and places MinCut and APS statistically significantly below the random baseline with only BayesSeg between the upper and lower bounds-to a significant degree.", "labels": [], "entities": []}, {"text": "Why would pairwise mean B act in such an unexpected manner?", "labels": [], "entities": []}, {"text": "The answer lies in a further analysis using the confusion matrix proposed earlier to calculate B-precision and B-recall (as shown in).", "labels": [], "entities": [{"text": "B-precision", "start_pos": 95, "end_pos": 106, "type": "METRIC", "confidence": 0.9870975613594055}, {"text": "B-recall", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9762517213821411}]}, {"text": "From the values in, all three automatic segmenters appear to have Bprecision above the baseline and below the upper bound, but the B-recall of both APS and MinCut is below that of the random baseline (illustrated).", "labels": [], "entities": [{"text": "Bprecision", "start_pos": 66, "end_pos": 76, "type": "METRIC", "confidence": 0.9970473647117615}, {"text": "B-recall", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9878852963447571}]}, {"text": "These automatic segmenters were developed and performance tuned using WD, thus it would be expected that they would perform as they did according to WD, but the evaluation using B highlights WD's bias towards sparse segmentations (i.e., those with low B-recall)-a failing that S also appears to share.", "labels": [], "entities": []}, {"text": "Mean B shows an unbiased ranking of these automatic segmenters in terms of the upper and lower bounds.", "labels": [], "entities": []}, {"text": "B, then, should be preferred over Sand WD for an unbiased segmentation evaluation that assumes that similarity to a human solution is the best measure of performance fora task.", "labels": [], "entities": [{"text": "B", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9443005323410034}]}], "tableCaptions": [{"text": " Table 1: Correctness of boundary pair", "labels": [], "entities": [{"text": "Correctness", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9890670776367188}]}]}