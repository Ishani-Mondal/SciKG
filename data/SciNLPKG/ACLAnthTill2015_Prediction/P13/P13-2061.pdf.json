{"title": [{"text": "Bilingual Data Cleaning for SMT using Graph-based Random Walk *", "labels": [], "entities": [{"text": "Bilingual Data Cleaning", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6643781761328379}, {"text": "SMT", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9953612685203552}]}], "abstractContent": [{"text": "The quality of bilingual data is a key factor in Statistical Machine Translation (SMT).", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 49, "end_pos": 86, "type": "TASK", "confidence": 0.8765116930007935}]}, {"text": "Low-quality bilingual data tends to produce incorrect translation knowledge and also degrades translation modeling performance.", "labels": [], "entities": [{"text": "translation modeling", "start_pos": 94, "end_pos": 114, "type": "TASK", "confidence": 0.9660504758358002}]}, {"text": "Previous work often used supervised learning methods to filter low-quality data, but a fair amount of human labeled examples are needed which are not easy to obtain.", "labels": [], "entities": []}, {"text": "To reduce the reliance on labeled examples, we propose an unsupervised method to clean bilingual data.", "labels": [], "entities": []}, {"text": "The method leverages the mutual reinforcement between the sentence pairs and the extracted phrase pairs, based on the observation that better sentence pairs often lead to better phrase extraction and vice versa.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 178, "end_pos": 195, "type": "TASK", "confidence": 0.7147193104028702}]}, {"text": "End-to-end experiments show that the proposed method substantially improves the performance in large-scale Chinese-to-English translation tasks.", "labels": [], "entities": [{"text": "Chinese-to-English translation tasks", "start_pos": 107, "end_pos": 143, "type": "TASK", "confidence": 0.7622459630171458}]}], "introductionContent": [{"text": "Statistical machine translation (SMT) depends on the amount of bilingual data and its quality.", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8284023205439249}]}, {"text": "In real-world SMT systems, bilingual data is often mined from the web where low-quality data is inevitable.", "labels": [], "entities": [{"text": "SMT", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.9923394918441772}]}, {"text": "The low-quality bilingual data degrades the quality of word alignment and leads to the incorrect phrase pairs, which will hurt the translation performance of phrase-based SMT systems ().", "labels": [], "entities": [{"text": "word alignment", "start_pos": 55, "end_pos": 69, "type": "TASK", "confidence": 0.7143535166978836}, {"text": "SMT", "start_pos": 171, "end_pos": 174, "type": "TASK", "confidence": 0.8395295143127441}]}, {"text": "Therefore, it is very important to exploit data quality information to improve the translation modeling.", "labels": [], "entities": [{"text": "translation modeling", "start_pos": 83, "end_pos": 103, "type": "TASK", "confidence": 0.9788859188556671}]}, {"text": "Previous work on bilingual data cleaning often involves some supervised learning methods.", "labels": [], "entities": [{"text": "bilingual data cleaning", "start_pos": 17, "end_pos": 40, "type": "TASK", "confidence": 0.6495870451132456}]}, {"text": "Several bilingual data mining systems (Resnik and * This work has been done while the first author was visiting Microsoft Research Asia.;) have a postprocessing step for data cleaning.", "labels": [], "entities": [{"text": "data cleaning", "start_pos": 170, "end_pos": 183, "type": "TASK", "confidence": 0.8639223277568817}]}, {"text": "Maximum entropy or SVM based classifiers are built to filter some non-parallel data or partial-parallel data.", "labels": [], "entities": []}, {"text": "Although these methods can filter some low-quality bilingual data, they need sufficient human labeled training instances to build the model, which may not be easy to acquire.", "labels": [], "entities": []}, {"text": "To this end, we propose an unsupervised approach to clean the bilingual data.", "labels": [], "entities": []}, {"text": "It is intuitive that high-quality parallel data tends to produce better phrase pairs than low-quality data.", "labels": [], "entities": []}, {"text": "Meanwhile, it is also observed that the phrase pairs that appear frequently in the bilingual corpus are more reliable than less frequent ones because they are more reusable, hence most good sentence pairs are prone to contain more frequent phrase pairs.", "labels": [], "entities": []}, {"text": "This kind of mutual reinforcement fits well into the framework of graph-based random walk.", "labels": [], "entities": []}, {"text": "When a phrase pair p is extracted from a sentence pair s, sis considered casting a vote for p.", "labels": [], "entities": []}, {"text": "The higher the number of votes a phrase pair has, the more reliable of the phrase pair.", "labels": [], "entities": []}, {"text": "Similarly, the quality of the sentence pair sis determined by the number of votes casted by the extracted phrase pairs from s.", "labels": [], "entities": []}, {"text": "In this paper, a PageRank-style random walk algorithm) is conducted to iteratively compute the importance score of each sentence pair that indicates its quality: the higher the better.", "labels": [], "entities": []}, {"text": "Unlike other data filtering methods, our proposed method utilizes the importance scores of sentence pairs as fractional counts to calculate the phrase translation probabilities based on Maximum Likelihood Estimation (MLE), thereby none of the bilingual data is filtered out.", "labels": [], "entities": [{"text": "phrase translation probabilities", "start_pos": 144, "end_pos": 176, "type": "TASK", "confidence": 0.7277223765850067}, {"text": "Maximum Likelihood Estimation (MLE)", "start_pos": 186, "end_pos": 221, "type": "METRIC", "confidence": 0.7185853570699692}]}, {"text": "Experimental results show that our proposed approach substantially improves the performance in large-scale Chinese-to-English translation tasks.", "labels": [], "entities": [{"text": "Chinese-to-English translation tasks", "start_pos": 107, "end_pos": 143, "type": "TASK", "confidence": 0.7582024037837982}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: BLEU(%) of Chinese-to-English translation tasks on multiple testing datasets (p < 0.05), where  \"-numberM\" denotes we simply filter number million low scored sentence pairs from the bilingual data  and use others to extract the phrase table. \"CW\" means the corpus weighting feature, which incorporates  sentence scores from random walk as fractional counts to re-estimate the phrase translation probabilities.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9995824694633484}, {"text": "Chinese-to-English translation", "start_pos": 21, "end_pos": 51, "type": "TASK", "confidence": 0.6913746893405914}]}]}