{"title": [], "abstractContent": [{"text": "A new method for keyword extraction from conversations is introduced, which preserves the diversity of topics that are mentioned.", "labels": [], "entities": [{"text": "keyword extraction from conversations", "start_pos": 17, "end_pos": 54, "type": "TASK", "confidence": 0.8648998290300369}]}, {"text": "Inspired from summarization, the method maximizes the coverage of topics that are recognized automatically in transcripts of conversation fragments.", "labels": [], "entities": [{"text": "summarization", "start_pos": 14, "end_pos": 27, "type": "TASK", "confidence": 0.9791169762611389}]}, {"text": "The method is evaluated on excerpts of the Fisher and AMI corpora, using a crowd-sourcing platform to elicit comparative relevance judgments.", "labels": [], "entities": [{"text": "AMI corpora", "start_pos": 54, "end_pos": 65, "type": "DATASET", "confidence": 0.8952734172344208}]}, {"text": "The results demonstrate that the method outperforms two competitive baselines.", "labels": [], "entities": []}], "introductionContent": [{"text": "The goal of keyword extraction from texts is to provide a set of words that are representative of the semantic content of the texts.", "labels": [], "entities": [{"text": "keyword extraction from texts", "start_pos": 12, "end_pos": 41, "type": "TASK", "confidence": 0.8493124395608902}]}, {"text": "In the application intended here, keywords are automatically extracted from transcripts of conversation fragments, and are used to formulate queries to a just-in-time document recommender system.", "labels": [], "entities": []}, {"text": "It is thus important that the keyword set preserves the diversity of topics from the conversation.", "labels": [], "entities": []}, {"text": "While the first keyword extraction methods ignored topicality as they were based on word frequencies, more recent methods have considered topic modeling factors for keyword extraction, but without specifically setting a topic diversity constraint, which is important for naturally-occurring conversations.", "labels": [], "entities": [{"text": "keyword extraction", "start_pos": 16, "end_pos": 34, "type": "TASK", "confidence": 0.8277867138385773}, {"text": "keyword extraction", "start_pos": 165, "end_pos": 183, "type": "TASK", "confidence": 0.7917815148830414}]}, {"text": "In this paper, we propose anew method for keyword extraction that rewards both word similarity, to extract the most representative words, and word diversity, to cover several topics if necessary.", "labels": [], "entities": [{"text": "keyword extraction", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.8172088861465454}, {"text": "word diversity", "start_pos": 142, "end_pos": 156, "type": "TASK", "confidence": 0.6548816859722137}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we review existing methods for keyword extraction.", "labels": [], "entities": [{"text": "keyword extraction", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.8718698918819427}]}, {"text": "In Section 3 we describe our proposal, which relies on topic modeling and a novel topic-aware diverse keyword extraction algorithm.", "labels": [], "entities": [{"text": "topic-aware diverse keyword extraction", "start_pos": 82, "end_pos": 120, "type": "TASK", "confidence": 0.6127975583076477}]}, {"text": "Section 4 presents the data and tasks for comparing sets of keywords.", "labels": [], "entities": []}, {"text": "In Section 5 we show that our method outperforms two existing ones.", "labels": [], "entities": []}], "datasetContent": [{"text": "The proposed keyword extraction method was tested on two conversational corpora, the Fisher) for image (a) and by a topic similarity method (TS) for image (b).", "labels": [], "entities": [{"text": "keyword extraction", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.7810105979442596}]}, {"text": "TS over-represents the topic \"color\" by selecting three words related to it, but misses other topics such as \"remote control\", \"losing a device\" and \"buying a device\" which are also representative of the fragment.", "labels": [], "entities": []}, {"text": "Input : a given text t, a set of topics Z, the number of keywords k Output: a set of keywords SS \u2190 \u2205; while |S| \u2264 k do S \u2190 S \u222a {argmax w\u2208t\\S (h(w)) where h(w) = z\u2208Z p(z|t)[r {w},z + r S,z ] \u03bb }; end return S; Algorithm 1: Diverse keyword extraction.", "labels": [], "entities": [{"text": "Diverse keyword extraction", "start_pos": 222, "end_pos": 248, "type": "TASK", "confidence": 0.8015515208244324}]}, {"text": "Corpus (), and the AMI Meeting Corpus.", "labels": [], "entities": [{"text": "Corpus", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8653249740600586}, {"text": "AMI Meeting Corpus", "start_pos": 19, "end_pos": 37, "type": "DATASET", "confidence": 0.9126549561818441}]}, {"text": "The former corpus contains about 11,000 topic-labeled telephone conversations, on 40 pre-selected topics (one per conversation).", "labels": [], "entities": []}, {"text": "We created a topic model using Mallet over two thirds of the Fisher Corpus, given its large number of single-topic documents, with 40 topics.", "labels": [], "entities": [{"text": "Fisher Corpus", "start_pos": 61, "end_pos": 74, "type": "DATASET", "confidence": 0.9671200811862946}]}, {"text": "The remaining data is used to build 11 artificial \"conversations\" (1-2 minutes long) for testing, by concatenating 11 times three fragments about three different topics.", "labels": [], "entities": []}, {"text": "The AMI Corpus contains 171 half-hour meetings about remote control design, which include several topics each -so they cannot be directly used for learning topic models.", "labels": [], "entities": [{"text": "AMI Corpus", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.9146768748760223}, {"text": "remote control design", "start_pos": 53, "end_pos": 74, "type": "TASK", "confidence": 0.6041616896788279}]}, {"text": "While selecting for testing 8 conversation fragments of 2-3 minutes each, we trained topic models on a subset of the English Wikipedia.", "labels": [], "entities": []}, {"text": "Following several previous studies, the number of topics was set to 100.", "labels": [], "entities": []}, {"text": "To evaluate the relevance (or representativeness) of extracted keywords with respect to a conversation fragment, we designed comparison tasks.", "labels": [], "entities": []}, {"text": "In each task, a fragment is shown, followed by three control questions about its content, and then by two lists of nine keywords each, from two different extraction methods.", "labels": [], "entities": []}, {"text": "To improve readability, the keyword lists are presented to the judges using a word cloud representation generated by Wordle TM (http://www.wordle.net), in which the words ranked higher are emphasized in the word cloud (see example in).", "labels": [], "entities": [{"text": "Wordle TM", "start_pos": 117, "end_pos": 126, "type": "DATASET", "confidence": 0.932730495929718}]}, {"text": "The judges had to read the conversation transcript, answer the control questions, and then decide which word cloud better represents the content of the conversation.", "labels": [], "entities": []}, {"text": "The tasks were crowdsourced via Amazon's Mechanical Turk (AMT) as \"human intelligence tasks\" (HITs).", "labels": [], "entities": []}, {"text": "One of them is exemplified in, without the control questions, and the respective conversation transcript is given in the Appendix.", "labels": [], "entities": []}, {"text": "Ten workers were recruited for each corpus.", "labels": [], "entities": []}, {"text": "An example of judgment counts for each of the 8 AMI HITs comparing two methods is shown in.", "labels": [], "entities": []}, {"text": "After collecting judgments, the comparative relevance values were computed by first applying a qualification control factor to the human judgments, and then averaging results overall judgments.", "labels": [], "entities": []}, {"text": "Moreover, to verify the diversity of the key-  word set, we use the \u03b1-NDCG measure ( proposed for information retrieval, which rewards a mixture of relevance and diversity -with equal weights when \u03b1 = .5 asset here.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 98, "end_pos": 119, "type": "TASK", "confidence": 0.7952223420143127}]}, {"text": "We only apply \u03b1-NDCG to the three-topic conversation fragments from the Fisher Corpus, relevance of a keyword being set to 1 when it belongs to the fragment corresponding to the topic.", "labels": [], "entities": [{"text": "Fisher Corpus", "start_pos": 72, "end_pos": 85, "type": "DATASET", "confidence": 0.8950760662555695}, {"text": "relevance", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9914828538894653}]}, {"text": "A higher value indicates that keywords are more uniformly distributed across the three topics.", "labels": [], "entities": []}, {"text": "We have compared several versions of the diverse keyword extraction method, noted D(\u03bb), for \u03bb \u2208 {.5, .75, 1}, with two other methods.", "labels": [], "entities": [{"text": "keyword extraction", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.7369317710399628}]}, {"text": "The first one uses only word frequency (not including stopwords) and is noted WF.", "labels": [], "entities": [{"text": "WF", "start_pos": 78, "end_pos": 80, "type": "METRIC", "confidence": 0.9707528948783875}]}, {"text": "We did not use TFIDF because it sets low weights on keywords that are repeated in many fragments but which are nevertheless important to extract.", "labels": [], "entities": [{"text": "TFIDF", "start_pos": 15, "end_pos": 20, "type": "METRIC", "confidence": 0.6724513173103333}]}, {"text": "The second method is based on topical similarity (noted TS) but does not specifically enforce diversity.", "labels": [], "entities": [{"text": "TS", "start_pos": 56, "end_pos": 58, "type": "METRIC", "confidence": 0.9071086645126343}]}, {"text": "In fact TS coincides with D(1), so it is noted TS.", "labels": [], "entities": [{"text": "TS", "start_pos": 8, "end_pos": 10, "type": "METRIC", "confidence": 0.9946820139884949}, {"text": "TS", "start_pos": 47, "end_pos": 49, "type": "METRIC", "confidence": 0.9927588701248169}]}, {"text": "As the relevance of keywords for D(.5) was already quite low, we did not test lower values of \u03bb.", "labels": [], "entities": [{"text": "relevance", "start_pos": 7, "end_pos": 16, "type": "METRIC", "confidence": 0.9818427562713623}, {"text": "D", "start_pos": 33, "end_pos": 34, "type": "METRIC", "confidence": 0.8731402158737183}]}, {"text": "Similarly, we did not test additional values of \u03bb above .5 because the resulting word lists were very similar to tested values.", "labels": [], "entities": []}, {"text": "First of all, we compared the four methods with respect to the diversity constraint over the con-   catenated fragments of the Fisher Corpus, by using \u03b1-NDCG to measure how evenly the extracted keywords were distributed across the three topics.", "labels": [], "entities": [{"text": "Fisher Corpus", "start_pos": 127, "end_pos": 140, "type": "DATASET", "confidence": 0.8392095863819122}]}, {"text": "shows results averaged over 11 conversations for various sizes of the keyword set (1-15).", "labels": [], "entities": []}, {"text": "The average \u03b1-NDCG values for D(.75) and D(.5) are similar, and clearly higher than WF and TS for all ranks (except, of course, fora single keyword).", "labels": [], "entities": [{"text": "D(.5)", "start_pos": 41, "end_pos": 46, "type": "METRIC", "confidence": 0.9348793178796768}, {"text": "WF", "start_pos": 84, "end_pos": 86, "type": "METRIC", "confidence": 0.8296254873275757}, {"text": "TS", "start_pos": 91, "end_pos": 93, "type": "METRIC", "confidence": 0.9558246731758118}]}, {"text": "The values for TS are quite low, and only increase fora large number of keywords, demonstrating that TS does not cope well with topic diversity, but on the contrary first selects keywords from the dominant topic.", "labels": [], "entities": [{"text": "TS", "start_pos": 15, "end_pos": 17, "type": "METRIC", "confidence": 0.8678359985351562}]}, {"text": "The values for WF are more uniform as it does not consider topics at all.", "labels": [], "entities": [{"text": "WF", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.6195007562637329}]}, {"text": "To measure the overall representativeness of keywords, we performed binary comparisons between the outputs of each method, using crowdsourcing, over 11 fragments from the Fisher Corpus and 8 fragments from AMI.", "labels": [], "entities": [{"text": "Fisher Corpus", "start_pos": 171, "end_pos": 184, "type": "DATASET", "confidence": 0.919593870639801}, {"text": "AMI", "start_pos": 206, "end_pos": 209, "type": "DATASET", "confidence": 0.9372106790542603}]}, {"text": "The goal is to rank the methods, so we only report hereon the comparisons required for complete ordering.", "labels": [], "entities": []}, {"text": "AMT workers compared two lists of nine keywords each, with four options: X more representative or relevant than Y , or vice-versa, or both relevant, or both irrelevant.", "labels": [], "entities": [{"text": "AMT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.5885746479034424}]}, {"text": "shows the judgments collected when comparing the output of D(.75) with TS on the AMI Corpus.", "labels": [], "entities": [{"text": "D", "start_pos": 59, "end_pos": 60, "type": "METRIC", "confidence": 0.9111685752868652}, {"text": "TS", "start_pos": 71, "end_pos": 73, "type": "METRIC", "confidence": 0.9888398051261902}, {"text": "AMI Corpus", "start_pos": 81, "end_pos": 91, "type": "DATASET", "confidence": 0.9742017984390259}]}, {"text": "Workers disagreed for the first two HITs, but then found that the keywords extracted by D(.75) were more representative compared to TS.", "labels": [], "entities": []}, {"text": "The consolidated rel-evance) is 78% for D(.75) vs. 22% for TS.", "labels": [], "entities": [{"text": "consolidated rel-evance", "start_pos": 4, "end_pos": 27, "type": "METRIC", "confidence": 0.8435631990432739}, {"text": "D", "start_pos": 40, "end_pos": 41, "type": "METRIC", "confidence": 0.9592560529708862}, {"text": "TS", "start_pos": 59, "end_pos": 61, "type": "METRIC", "confidence": 0.5007122755050659}]}, {"text": "The averaged relevance values for all comparisons needed to rank the four methods are shown in separately for the Fisher and AMI Corpora.", "labels": [], "entities": [{"text": "AMI Corpora", "start_pos": 125, "end_pos": 136, "type": "DATASET", "confidence": 0.8634882271289825}]}, {"text": "Although the exact differences vary, the human judgments over the two corpora both indicate the following ranking: D(.75) > TS > WF > D(.5).", "labels": [], "entities": [{"text": "D", "start_pos": 115, "end_pos": 116, "type": "METRIC", "confidence": 0.9899126887321472}, {"text": "TS", "start_pos": 124, "end_pos": 126, "type": "METRIC", "confidence": 0.8161001801490784}]}, {"text": "The optimal value of \u03bb is thus around .75, and with this value, our diversity-aware method extracts more representative keyword sets than TS and WF.", "labels": [], "entities": []}, {"text": "The differences between methods are larger for the Fisher Corpus, due to the artificial fragments that concatenate three topics, but they are still visible on the natural fragments of the AMI Corpus.", "labels": [], "entities": [{"text": "Fisher Corpus", "start_pos": 51, "end_pos": 64, "type": "DATASET", "confidence": 0.9400998055934906}, {"text": "AMI Corpus", "start_pos": 188, "end_pos": 198, "type": "DATASET", "confidence": 0.968803882598877}]}, {"text": "The low scores of D(.5) are found to be due, upon inspection, to the low relevance of keywords.", "labels": [], "entities": [{"text": "D", "start_pos": 18, "end_pos": 19, "type": "METRIC", "confidence": 0.9989326596260071}]}, {"text": "In particular, the comparative relevance of D(.75) vs. D(.5) on the Fisher Corpus is very large (96% vs. 4%).", "labels": [], "entities": [{"text": "D", "start_pos": 44, "end_pos": 45, "type": "METRIC", "confidence": 0.9917340278625488}, {"text": "Fisher Corpus", "start_pos": 68, "end_pos": 81, "type": "DATASET", "confidence": 0.9328307211399078}]}], "tableCaptions": [{"text": " Table 1: Number of answers for each of the four  options of the comparative evaluation task, from  ten human judges. The 8 HITs compare the D(.75)  and TS methods on 8 AMI HITs.", "labels": [], "entities": [{"text": "D(.75)", "start_pos": 141, "end_pos": 147, "type": "METRIC", "confidence": 0.9323605298995972}, {"text": "TS", "start_pos": 153, "end_pos": 155, "type": "METRIC", "confidence": 0.8607714772224426}]}, {"text": " Table 2: Comparative relevance scores of keyword  extraction methods based on human judgments.", "labels": [], "entities": [{"text": "keyword  extraction", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.7408220320940018}]}]}