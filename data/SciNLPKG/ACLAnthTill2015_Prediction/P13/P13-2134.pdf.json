{"title": [{"text": "The Effects of Lexical Resource Quality on Preference Violation Detection", "labels": [], "entities": [{"text": "Preference Violation Detection", "start_pos": 43, "end_pos": 73, "type": "TASK", "confidence": 0.9313785632451376}]}], "abstractContent": [{"text": "Lexical resources such as WordNet and VerbNet are widely used in a multitude of NLP tasks, as are annotated corpora such as treebanks.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 26, "end_pos": 33, "type": "DATASET", "confidence": 0.9515933990478516}, {"text": "VerbNet", "start_pos": 38, "end_pos": 45, "type": "DATASET", "confidence": 0.8105204701423645}]}, {"text": "Often, the resources are used as-is, without question or examination.", "labels": [], "entities": []}, {"text": "This practice risks missing significant performance gains and even entire techniques.", "labels": [], "entities": []}, {"text": "This paper addresses the importance of resource quality through the lens of a challenging NLP task: detecting selec-tional preference violations.", "labels": [], "entities": []}, {"text": "We present DAVID, a simple, lexical resource-based preference violation detector.", "labels": [], "entities": []}, {"text": "With as-is lexical resources, DAVID achieves an F 1-measure of just 28.27%.", "labels": [], "entities": [{"text": "DAVID", "start_pos": 30, "end_pos": 35, "type": "DATASET", "confidence": 0.45887577533721924}, {"text": "F 1-measure", "start_pos": 48, "end_pos": 59, "type": "METRIC", "confidence": 0.9920331537723541}]}, {"text": "When the resource entries and parser outputs fora small sample are corrected, however, the F 1-measure on that sample jumps from 40% to 61.54%, and performance on other examples rises, suggesting that the algorithm becomes practical given refined resources.", "labels": [], "entities": [{"text": "F 1-measure", "start_pos": 91, "end_pos": 102, "type": "METRIC", "confidence": 0.9883396625518799}]}, {"text": "More broadly, this paper shows that resource quality matters tremendously, sometimes even more than algorithmic improvements.", "labels": [], "entities": []}], "introductionContent": [{"text": "A variety of NLP tasks have been addressed using selectional preferences or restrictions, including word sense disambiguation (see), semantic parsing (e.g.,), and metaphor processing (see).", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 100, "end_pos": 125, "type": "TASK", "confidence": 0.7035886645317078}, {"text": "semantic parsing", "start_pos": 133, "end_pos": 149, "type": "TASK", "confidence": 0.7180196195840836}, {"text": "metaphor processing", "start_pos": 163, "end_pos": 182, "type": "TASK", "confidence": 0.9412384331226349}]}, {"text": "These semantic problems are quite challenging; metaphor analysis, for instance, has long been recognized as requiring considerable semantic knowledge.", "labels": [], "entities": [{"text": "metaphor analysis", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.9612590670585632}]}, {"text": "The advent of extensive lexical resources, annotated corpora, and a spectrum of NLP tools presents an opportunity to revisit such challenges from the perspective of selectional preference violations.", "labels": [], "entities": []}, {"text": "Detecting these violations, however, constitutes a severe stress-test for resources designed for other tasks.", "labels": [], "entities": []}, {"text": "As such, it can highlight shortcomings and allow quantifying the potential benefits of improving resources such as WordNet and VerbNet (.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 115, "end_pos": 122, "type": "DATASET", "confidence": 0.9591802954673767}, {"text": "VerbNet", "start_pos": 127, "end_pos": 134, "type": "DATASET", "confidence": 0.8762660622596741}]}, {"text": "In this paper, we present DAVID (Detector of Arguments of Verbs with Incompatible Denotations), a resource-based system for detecting preference violations.", "labels": [], "entities": [{"text": "DAVID", "start_pos": 26, "end_pos": 31, "type": "METRIC", "confidence": 0.9234585762023926}]}, {"text": "DAVID is one component of METAL (Metaphor Extraction via Targeted Analysis of Language), anew system for identifying, interpreting, and cataloguing metaphors.", "labels": [], "entities": [{"text": "Metaphor Extraction via Targeted Analysis of Language)", "start_pos": 33, "end_pos": 87, "type": "TASK", "confidence": 0.7149734571576118}, {"text": "identifying, interpreting, and cataloguing metaphors", "start_pos": 105, "end_pos": 157, "type": "TASK", "confidence": 0.5783734789916447}]}, {"text": "One purpose of DAVID was to explore how far lexical resource-based techniques can take us.", "labels": [], "entities": []}, {"text": "Though our initial results suggested that the answer is \"not very,\" further analysis revealed that the problem lies less in the technique than in the state of existing resources and tools.", "labels": [], "entities": []}, {"text": "Often, it is assumed that the frontier of performance on NLP tasks is shaped entirely by algorithms.", "labels": [], "entities": []}, {"text": "showed that this may not hold for POS tagging -that further improvements may require resource cleanup.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 34, "end_pos": 45, "type": "TASK", "confidence": 0.8326343595981598}]}, {"text": "In the same spirit, we argue that for some semantic tasks, exemplified by preference violation detection, resource quality maybe at least as essential as algorithmic enhancements.", "labels": [], "entities": [{"text": "preference violation detection", "start_pos": 74, "end_pos": 104, "type": "TASK", "confidence": 0.6938947836558024}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 4: Performance on preference violation de- tection task. Column 1 shows the sentence count.", "labels": [], "entities": []}]}