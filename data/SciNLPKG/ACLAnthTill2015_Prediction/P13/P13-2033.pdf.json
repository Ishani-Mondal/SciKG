{"title": [{"text": "Accurate Word Segmentation using Transliteration and Language Model Projection", "labels": [], "entities": [{"text": "Accurate Word Segmentation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.690364807844162}]}], "abstractContent": [{"text": "Transliterated compound nouns not separated by whitespaces pose difficulty on word segmentation (WS).", "labels": [], "entities": [{"text": "word segmentation (WS)", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.8148839592933654}]}, {"text": "Of-fline approaches have been proposed to split them using word statistics, but they rely on static lexicon, limiting their use.", "labels": [], "entities": []}, {"text": "We propose an online approach , integrating source LM, and/or, back-transliteration and English LM.", "labels": [], "entities": []}, {"text": "The experiments on Japanese and Chi-nese WS have shown that the proposed models achieve significant improvement over state-of-the-art, reducing 16% errors in Japanese.", "labels": [], "entities": [{"text": "errors", "start_pos": 148, "end_pos": 154, "type": "METRIC", "confidence": 0.9620420932769775}]}], "introductionContent": [{"text": "Accurate word segmentation (WS) is the key components in successful language processing.", "labels": [], "entities": [{"text": "Accurate word segmentation (WS)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8838091989358267}]}, {"text": "The problem is pronounced in languages such as Japanese and Chinese, where words are not separated by whitespaces.", "labels": [], "entities": []}, {"text": "In particular, compound nouns pose difficulties to WS since they are productive, and often consist of unknown words.", "labels": [], "entities": [{"text": "WS", "start_pos": 51, "end_pos": 53, "type": "TASK", "confidence": 0.9931261539459229}]}, {"text": "In Japanese, transliterated foreign compound words written in Katakana are extremely difficult to split up into components without proper lexical knowledge.", "labels": [], "entities": []}, {"text": "For example, when splitting a compound noun \u30d6 \u30e9\u30ad\u30c3\u30b7\u30e5\u30ec\u30c3\u30c9 burakisshureddo, a traditional word segmenter can easily segment this as \u30d6 \u30e9\u30ad\u30c3/\u30b7\u30e5\u30ec\u30c3\u30c9 \"*blacki shred\" since \u30b7\u30e5\u30ec\u30c3 \u30c9 shureddo \"shred\" is a known, frequent word.", "labels": [], "entities": [{"text": "splitting a compound noun \u30d6 \u30e9\u30ad\u30c3\u30b7\u30e5\u30ec\u30c3\u30c9 burakisshureddo", "start_pos": 18, "end_pos": 70, "type": "TASK", "confidence": 0.8198425258908953}]}, {"text": "It is only the knowledge that \u30d6\u30e9\u30ad\u30c3buraki (*\"blacki\") is not a valid word which prevents this.", "labels": [], "entities": []}, {"text": "Knowing that the back-transliterated unigram \"blacki\" and bigram \"blacki shred\" are unlikely in English can promote the correct WS, \u30d6\u30e9\u30ad\u30c3\u30b7\u30e5/\u30ec\u30c3\u30c9 \"blackish red\".", "labels": [], "entities": [{"text": "WS", "start_pos": 128, "end_pos": 130, "type": "METRIC", "confidence": 0.6811812520027161}]}, {"text": "In Chinese, the problem can be more severe since the language does not have a separate script to represent transliterated words.", "labels": [], "entities": []}, {"text": "tackled Katakana compound splitting using backtransliteration and paraphrasing.", "labels": [], "entities": [{"text": "Katakana compound splitting", "start_pos": 8, "end_pos": 35, "type": "TASK", "confidence": 0.8176328937212626}]}, {"text": "Their approach falls into an offline approach, which focuses on creating dictionaries by extracting new words from large corpora separately before WS.", "labels": [], "entities": []}, {"text": "However, offline approaches have limitation unless the lexicon is constantly updated.", "labels": [], "entities": []}, {"text": "Moreover, they only deal with Katakana, but their method is not directly applicable to Chinese since the language lacks a separate script for transliterated words.", "labels": [], "entities": []}, {"text": "Instead, we adopt an online approach, which deals with unknown words simultaneously as the model analyzes the input.", "labels": [], "entities": []}, {"text": "Our approach is based on semi-Markov discriminative structure prediction, and it incorporates English back-transliteration and English language models (LMs) into WS in a seamless way.", "labels": [], "entities": [{"text": "semi-Markov discriminative structure prediction", "start_pos": 25, "end_pos": 72, "type": "TASK", "confidence": 0.7135468050837517}]}, {"text": "We refer to this process of transliterating unknown words into another language and using the target LM as LM projection.", "labels": [], "entities": []}, {"text": "Since the model employs a general transliteration model and a general English LM, it achieves robust WS for unknown words.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this paper is the first to use transliteration and projected LMs in an online, seamlessly integrated fashion for WS.", "labels": [], "entities": [{"text": "WS", "start_pos": 143, "end_pos": 145, "type": "TASK", "confidence": 0.9871180057525635}]}, {"text": "To show the effectiveness of our approach, we test our models on a Japanese balanced corpus and an electronic commerce domain corpus, and a balanced Chinese corpus.", "labels": [], "entities": []}, {"text": "The results show that we achieved a significant improvement in WS accuracy in both languages.", "labels": [], "entities": [{"text": "WS", "start_pos": 63, "end_pos": 65, "type": "TASK", "confidence": 0.9662481546401978}, {"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9547271728515625}]}], "datasetContent": [{"text": "Corpora For Japanese, we used (1) EC corpus, consists of 1,230 product titles and descriptions randomly sampled from Rakuten).", "labels": [], "entities": [{"text": "EC corpus", "start_pos": 34, "end_pos": 43, "type": "DATASET", "confidence": 0.7075942307710648}, {"text": "Rakuten", "start_pos": 117, "end_pos": 124, "type": "DATASET", "confidence": 0.9429894685745239}]}, {"text": "For Chinese, we used LCMC () (45,697 sentences and 1,001,549 tokens).", "labels": [], "entities": []}, {"text": "As the dictionary, we used CC-CEDICT (MDGB, 2011) . Training and Evaluation We used Averaged Perceptron) (3 iterations) for training, with five-fold cross-validation.", "labels": [], "entities": [{"text": "CC-CEDICT (MDGB, 2011)", "start_pos": 27, "end_pos": 49, "type": "DATASET", "confidence": 0.8500366608301798}, {"text": "Averaged Perceptron)", "start_pos": 84, "end_pos": 104, "type": "METRIC", "confidence": 0.8934576511383057}]}, {"text": "As for the evaluation metrics, we used Precision (Prec.), Recall (Rec.), and F-measure (F).", "labels": [], "entities": [{"text": "Precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.9974109530448914}, {"text": "Recall (Rec.)", "start_pos": 58, "end_pos": 71, "type": "METRIC", "confidence": 0.9357088953256607}, {"text": "F-measure (F)", "start_pos": 77, "end_pos": 90, "type": "METRIC", "confidence": 0.9300700724124908}]}, {"text": "We additionally evaluated the performance limited to Katakana (JA) or proper nouns (ZH) in order to seethe impact of compound splitting.", "labels": [], "entities": [{"text": "compound splitting", "start_pos": 117, "end_pos": 135, "type": "TASK", "confidence": 0.7423169910907745}]}, {"text": "We also used word error rate (WER) to seethe relative change of errors.", "labels": [], "entities": [{"text": "word error rate (WER)", "start_pos": 13, "end_pos": 34, "type": "METRIC", "confidence": 0.8989884952704111}]}], "tableCaptions": [{"text": " Table 2: Japanese WS Performance (%) on BCCWJ -Overall (O) and Katakana (K)", "labels": [], "entities": [{"text": "WS", "start_pos": 19, "end_pos": 21, "type": "TASK", "confidence": 0.7083199620246887}, {"text": "BCCWJ -Overall (O)", "start_pos": 41, "end_pos": 59, "type": "METRIC", "confidence": 0.748582273721695}]}, {"text": " Table 3: Japanese WS Performance (%) on the EC domain corpus", "labels": [], "entities": [{"text": "WS", "start_pos": 19, "end_pos": 21, "type": "TASK", "confidence": 0.6645921468734741}, {"text": "EC domain", "start_pos": 45, "end_pos": 54, "type": "DATASET", "confidence": 0.9755157232284546}]}, {"text": " Table 4: Chinese WS Performance (%) -Overall (O) and Proper Nouns (P)", "labels": [], "entities": [{"text": "Chinese WS", "start_pos": 10, "end_pos": 20, "type": "TASK", "confidence": 0.5570521950721741}, {"text": "Overall (O)", "start_pos": 38, "end_pos": 49, "type": "METRIC", "confidence": 0.9313527643680573}, {"text": "Proper Nouns (P)", "start_pos": 54, "end_pos": 70, "type": "METRIC", "confidence": 0.9039646625518799}]}]}