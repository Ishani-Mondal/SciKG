{"title": [{"text": "Linguistic Models for Analyzing and Detecting Biased Language", "labels": [], "entities": [{"text": "Analyzing and Detecting Biased Language", "start_pos": 22, "end_pos": 61, "type": "TASK", "confidence": 0.7857824206352234}]}], "abstractContent": [{"text": "Unbiased language is a requirement for reference sources like encyclopedias and scientific texts.", "labels": [], "entities": []}, {"text": "Bias is, nonetheless, ubiquitous , making it crucial to understand its nature and linguistic realization and hence detect bias automatically.", "labels": [], "entities": []}, {"text": "To this end we analyze real instances of human edits designed to remove bias from Wikipedia articles.", "labels": [], "entities": []}, {"text": "The analysis uncovers two classes of bias: framing bias, such as praising or perspective-specific words, which we link to the literature on subjectivity; and episte-mological bias, related to whether propositions that are presupposed or entailed in the text are uncontroversially accepted as true.", "labels": [], "entities": []}, {"text": "We identify common linguistic cues for these classes, including factive verbs, implicatives, hedges, and subjective inten-sifiers.", "labels": [], "entities": []}, {"text": "These insights help us develop features fora model to solve anew prediction task of practical importance: given a biased sentence, identify the bias-inducing word.", "labels": [], "entities": []}, {"text": "Our linguistically-informed model performs almost as well as humans tested on the same task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Writers and editors of reference works such as encyclopedias, textbooks, and scientific articles strive to keep their language unbiased.", "labels": [], "entities": []}, {"text": "For example, Wikipedia advocates a policy called neutral point of view (NPOV), according to which articles should represent \"fairly, proportionately, and as far as possible without bias, all significant views that have been published by reliable sources\").", "labels": [], "entities": []}, {"text": "Wikipedia's style guide asks editors to use nonjudgmental language, to indicate the relative prominence of opposing points of view, to avoid presenting uncontroversial facts as mere opinion, and, conversely, to avoid stating opinions or contested assertions as facts.", "labels": [], "entities": []}, {"text": "Understanding the linguistic realization of bias is important for linguistic theory; automatically detecting these biases is equally significant for computational linguistics.", "labels": [], "entities": []}, {"text": "We propose to address both by using a powerful resource: edits in Wikipedia that are specifically designed to remove bias.", "labels": [], "entities": []}, {"text": "Since Wikipedia maintains a complete revision history, the edits associated with NPOV tags allow us to compare the text in its biased (before) and unbiased (after) form, helping us better understand the linguistic realization of bias.", "labels": [], "entities": []}, {"text": "Our work thus shares the intuition of prior NLP work applying Wikipedia's revision history.", "labels": [], "entities": []}, {"text": "The analysis of Wikipedia's edits provides valuable linguistic insights into the nature of biased language.", "labels": [], "entities": []}, {"text": "We find two major classes of bias-driven edits.", "labels": [], "entities": []}, {"text": "The first, framing bias, is realized by subjective words or phrases linked with a particular point of view.", "labels": [], "entities": [{"text": "framing bias", "start_pos": 11, "end_pos": 23, "type": "TASK", "confidence": 0.8539051711559296}]}, {"text": "In (1), the term McMansion, unlike homes, appeals to a negative attitude toward large and pretentious houses.", "labels": [], "entities": [{"text": "McMansion", "start_pos": 17, "end_pos": 26, "type": "DATASET", "confidence": 0.7889727354049683}]}, {"text": "The second class, epistemological bias, is related to linguistic features that subtly (often via presupposition) focus on the believability of a proposition.", "labels": [], "entities": []}, {"text": "In (2), the assertive stated removes the bias introduced by claimed, which casts doubt on Kuypers' statement.", "labels": [], "entities": []}, {"text": "Usually, smaller cottage-style houses have been demolished to make way for these McMansions. b. Usually, smaller cottage-style houses have been demolished to make way for these homes.", "labels": [], "entities": [{"text": "McMansions.", "start_pos": 81, "end_pos": 92, "type": "DATASET", "confidence": 0.8998691439628601}]}, {"text": "Kuypers claimed that the mainstream press in America tends to favor liberal viewpoints. b. Kuypers stated that the mainstream press in America tends to favor liberal viewpoints.", "labels": [], "entities": []}, {"text": "Bias is linked to the lexical and grammatical cues identified by the literature on subjectivity (), sentiment (), and especially stance or \"arguing subjectivity\" ().", "labels": [], "entities": [{"text": "Bias", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.8199598789215088}]}, {"text": "For example, like stance, framing bias is realized when the writer of a text takes a particular position on a controversial topic and uses its metaphors and vocabulary.", "labels": [], "entities": [{"text": "framing bias", "start_pos": 26, "end_pos": 38, "type": "TASK", "confidence": 0.8713162541389465}]}, {"text": "But unlike the product reviews or debate articles that overtly use subjective language, editors in Wikipedia are actively trying to avoid bias, and hence biases may appear more subtly, in the form of covert framing language, or presuppositions and entailments that may not play as important a role in other genres.", "labels": [], "entities": []}, {"text": "Our linguistic analysis identifies common classes of these subtle bias cues, including factive verbs, implicatives and other entailments, hedges, and subjective intensifiers.", "labels": [], "entities": []}, {"text": "Using these cues could help automatically detect and correct instances of bias, by first finding biased phrases, then identifying the word that introduces the bias, and finally rewording to eliminate the bias.", "labels": [], "entities": []}, {"text": "In this paper we propose a solution for the second of these tasks, identifying the bias-inducing word in a biased phrase.", "labels": [], "entities": []}, {"text": "Since, as we show below, this task is quite challenging for humans, our system has the potential to be very useful in improving the neutrality of reference works like Wikipedia.", "labels": [], "entities": []}, {"text": "Tested on a subset of non-neutral sentences from Wikipedia, our model achieves 34% accuracy-and up to 59% if the top three guesses are considered-on this difficult task, outperforming four baselines and nearing humans tested on the same data.", "labels": [], "entities": [{"text": "accuracy-and", "start_pos": 83, "end_pos": 95, "type": "METRIC", "confidence": 0.9994029998779297}]}], "datasetContent": [{"text": "We begin with an empirical analysis based on Wikipedia's bias-driven edits.", "labels": [], "entities": []}, {"text": "This section describes the data, and summarizes our linguistic analysis.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of the NPOV corpus, extracted  from Wikipedia. (Edits refers to bias-driven ed- its, i.e., with an NPOV comment. Sents refers to  sentences with a one-word bias-driven edit.)", "labels": [], "entities": [{"text": "NPOV corpus", "start_pos": 28, "end_pos": 39, "type": "DATASET", "confidence": 0.9096657335758209}]}, {"text": " Table 2: Proportion of the different bias types.", "labels": [], "entities": []}, {"text": " Table 4: Accuracy (%) of the bias detector on the  test set.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9993222951889038}]}]}