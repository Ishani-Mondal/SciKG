{"title": [{"text": "Learning to lemmatise Polish noun phrases", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a novel approach to noun phrase lemmatisation where the main phase is cast as a tagging problem.", "labels": [], "entities": [{"text": "noun phrase lemmatisation", "start_pos": 31, "end_pos": 56, "type": "TASK", "confidence": 0.7367603182792664}]}, {"text": "The idea draws on the observation that the lemmatisation of almost all Polish noun phrases maybe decomposed into transformation of singular words (tokens) that makeup each phrase.", "labels": [], "entities": []}, {"text": "We perform evaluation , which shows results similar to those obtained earlier by a rule-based system , while our approach allows to separate chunking from lemmatisation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Lemmatisation of word forms is the task of finding base forms (lemmas) for each token in running text.", "labels": [], "entities": []}, {"text": "Typically, it is performed along POS tagging and is considered crucial for many NLP applications.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 33, "end_pos": 44, "type": "TASK", "confidence": 0.6916218400001526}]}, {"text": "Similar task maybe defined for whole noun phrases.", "labels": [], "entities": []}, {"text": "By lemmatisation of noun phrases (NPs) we will understand assigning each NP a grammatically correct NP corresponding to the same phrase that could stand as a dictionary entry.", "labels": [], "entities": []}, {"text": "The task of NP lemmatisation is rarely considered, although it carries great practical value.", "labels": [], "entities": [{"text": "NP lemmatisation", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.9102804362773895}]}, {"text": "For instance, any keyword extraction system that works fora morphologically rich language must deal with lemmatisation of NPs.", "labels": [], "entities": [{"text": "keyword extraction", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.7419248819351196}]}, {"text": "This is because keywords are often longer phrases), while the user would be confused to see inflected forms as system output.", "labels": [], "entities": []}, {"text": "Similar situation happens when attempting at terminology extraction from domain corpora: it is usually assumed that domain terms are subclass of NPs.", "labels": [], "entities": [{"text": "terminology extraction from domain corpora", "start_pos": 45, "end_pos": 87, "type": "TASK", "confidence": 0.8683165311813354}]}, {"text": "In (1) we give an example Polish noun phrase ('the main city of the municipality').", "labels": [], "entities": []}, {"text": "Throughout the paper we assume the usage of the tagset of the National Corpus of Polish, henceforth called NCP in short.", "labels": [], "entities": [{"text": "National Corpus of Polish", "start_pos": 62, "end_pos": 87, "type": "DATASET", "confidence": 0.9566259533166885}]}, {"text": "The orthographic form (1a) appears in instrumental case, singular.", "labels": [], "entities": []}, {"text": "Phrase lemma is given as (1b).", "labels": [], "entities": []}, {"text": "Lemmatisation of this phrase consists in reverting case value of the main noun (miasto) as well as its adjective modifier (g\u0142\u00f3wne) to nominative (nom).", "labels": [], "entities": []}, {"text": "Each form in the example is in singular number (sg), miasto has neuter gender (n), gmina is feminine (f).", "labels": [], "entities": []}, {"text": "(1) a. g\u0142\u00f3wnym main According to the lemmatisation principles accompanying the NCP tagset, adjectives are lemmatised as masculine forms (g\u0142\u00f3wny), hence it is not sufficient to take word-level lemma nor the orthographic form to obtain phrase lemmatisation.", "labels": [], "entities": [{"text": "NCP tagset", "start_pos": 79, "end_pos": 89, "type": "DATASET", "confidence": 0.9580289125442505}]}, {"text": "Deg\u00f3rski (2011) discuses some similar cases.", "labels": [], "entities": []}, {"text": "He also notes that this is not an easy task and lemma of a whole NP is rarely a concatenation of lemmas of phrase components.", "labels": [], "entities": []}, {"text": "It is worth stressing that even the task of word-level lemmatisation is non-trivial for inflectional languages due to a large number of inflected forms and even larger number of syncretisms.", "labels": [], "entities": []}, {"text": "According to, \"a typical Polish adjective may have 11 textually different forms (.", "labels": [], "entities": []}, {"text": ") but as many as 70 different tags (2 numbers \u00d7 7 cases \u00d7 5 genders)\", which indicates the scale of the problem.", "labels": [], "entities": []}, {"text": "What is more, several syntactic phenomena typical for Polish complicate NP lemmatisation further.", "labels": [], "entities": [{"text": "NP lemmatisation", "start_pos": 72, "end_pos": 88, "type": "TASK", "confidence": 0.8830732107162476}]}, {"text": "E.g., adjectives may both precede and follow nouns they modify; many English prepositional phrases are realised in Polish using oblique case without any proposition (e.g., there is no standard Polish coun-terpart for the preposition of as genitive case is used for this purpose).", "labels": [], "entities": []}, {"text": "In this paper we present a novel approach to noun phrase lemmatisation where the main phase is cast as a tagging problem and tackled using a method devised for such problems, namely Conditional Random Fields (CRF).", "labels": [], "entities": [{"text": "noun phrase lemmatisation", "start_pos": 45, "end_pos": 70, "type": "TASK", "confidence": 0.7396588524182638}]}], "datasetContent": [{"text": "The performed evaluation assumed training of the CRF on the whole development set annotated with the induced transformations and then applying the trained model to tag the evaluation part with transformations.", "labels": [], "entities": []}, {"text": "Transformations were then applied and the obtained phrase lemmas were compared to the reference annotation.", "labels": [], "entities": []}, {"text": "This procedure includes the influence of deficiencies of the morphological dictionary.", "labels": [], "entities": []}, {"text": "The version of KPWr used here was tagged automatically using the WCRFT tagger, hence tagging errors are also included.", "labels": [], "entities": [{"text": "WCRFT", "start_pos": 65, "end_pos": 70, "type": "DATASET", "confidence": 0.9276450872421265}]}, {"text": "Deg\u00f3rski (2011) reports separate figures for the performance of the entire system (chunker + NP lemmatiser) on the whole test set and performance of the entire system limiting the test set only to those phrases that the system is able to chunk correctly (i.e., to output correct phrase boundaries).", "labels": [], "entities": []}, {"text": "Such a choice is reasonable given that his system is based on rules that intermingle chunking with lemmatisation.", "labels": [], "entities": []}, {"text": "We cannot expect the system to lemmatise correctly those groups which it is unable to capture.", "labels": [], "entities": []}, {"text": "Our approach assumes two-stage operation, where the chunker stage is partially independent from the lemmatisation.", "labels": [], "entities": []}, {"text": "This is why we decided to report performance of the whole system on the whole test set, but also, performance of the lemmatisation module alone on the whole test set.", "labels": [], "entities": []}, {"text": "This seems more appropriate, since the chunker maybe improved or completely replaced independently, while discarding the phrases that are too hard to parse is likely to bias the evaluation of the lemmatisation stage (what is hard to chunk is probably also hard to lemmatise).", "labels": [], "entities": []}, {"text": "For the setting where chunker was used, we used the CRF-based chunker mentioned in the previous section.", "labels": [], "entities": []}, {"text": "The chunker has been trained on the entire KPWr except for the documents that belong to the evaluation set.", "labels": [], "entities": []}, {"text": "Deg\u00f3rski (2011) uses concatenation of wordlevel base forms assigned by the tagger as a baseline.", "labels": [], "entities": []}, {"text": "Observation of the development set suggests that returning the original inflected NPs maybe a better baseline.", "labels": [], "entities": []}, {"text": "As detection of phrase-initial prepositions is apart of our task formulation, we had to implement it in the baseline algorithms as well.", "labels": [], "entities": []}, {"text": "Otherwise, the comparison would be unfair.", "labels": [], "entities": []}, {"text": "We decided to implement both baseline algorithms using the same CRF model but trained on fabricated data.", "labels": [], "entities": []}, {"text": "The training data for the 'take-orthographic-form' baseline was obtained by leaving the 'remove-phrase-initialpreposition' ('p') transformation and replacing all others with '='.", "labels": [], "entities": []}, {"text": "Similarly, for the 'take-lemma' baseline, other transformations were substituted with 'lem'.", "labels": [], "entities": []}, {"text": "The results of the full evaluation are presented in Tab.", "labels": [], "entities": [{"text": "Tab.", "start_pos": 52, "end_pos": 56, "type": "DATASET", "confidence": 0.9629680812358856}]}, {"text": "2. The first conclusion is that the figures are disappointingly low, but comparable with the 58.5% success rate reported in.", "labels": [], "entities": []}, {"text": "The other observation is that the proposed solution significantly outperforms both baseline, out of which the 'take-orthographic-form' (orth baseline) performs slightly better.", "labels": [], "entities": []}, {"text": "Also, it turns out that the variation of the matching procedure using the 'lem' transformation (row labelled CRF lem) performs slightly worse than the procedure without this transformation (row CRF nolem).", "labels": [], "entities": []}, {"text": "This supports the suspicion that relying on wordlevel lemmas may reduce the ability to generalise.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Frequencies of transformations.", "labels": [], "entities": []}, {"text": " Table 2: Performance of NP lemmatisation includ- ing chunking errors.", "labels": [], "entities": []}]}