{"title": [{"text": "Multimodal DBN for Predicting High-Quality Answers in cQA portals", "labels": [], "entities": [{"text": "Predicting High-Quality Answers", "start_pos": 19, "end_pos": 50, "type": "TASK", "confidence": 0.8949304223060608}, {"text": "cQA portals", "start_pos": 54, "end_pos": 65, "type": "DATASET", "confidence": 0.7991493344306946}]}], "abstractContent": [{"text": "In this paper, we address the problem for predicting cQA answer quality as a classification task.", "labels": [], "entities": [{"text": "predicting cQA answer quality", "start_pos": 42, "end_pos": 71, "type": "TASK", "confidence": 0.7365726679563522}]}, {"text": "We propose a multimodal deep belief nets based approach that operates in two stages: First, the joint representation is learned by taking both tex-tual and non-textual features into a deep learning network.", "labels": [], "entities": []}, {"text": "Then, the joint representation learned by the network is used as input features fora linear classifier.", "labels": [], "entities": []}, {"text": "Extensive experimental results conducted on two cQA datasets demonstrate the effectiveness of our proposed approach.", "labels": [], "entities": [{"text": "cQA datasets", "start_pos": 48, "end_pos": 60, "type": "DATASET", "confidence": 0.984175443649292}]}], "introductionContent": [{"text": "Predicting the quality of answers in community based Question Answering (cQA) portals is a challenging task.", "labels": [], "entities": [{"text": "Predicting the quality of answers in community based Question Answering (cQA) portals", "start_pos": 0, "end_pos": 85, "type": "TASK", "confidence": 0.6720557851450784}]}, {"text": "One straightforward approach is to use textual features as a text classification task ().", "labels": [], "entities": [{"text": "text classification task", "start_pos": 61, "end_pos": 85, "type": "TASK", "confidence": 0.7819955746332804}]}, {"text": "However, due to the word over-sparsity and inherent noise of usergenerated content, the classical bag-of-words representation, is not appropriate to estimate the quality of short texts).", "labels": [], "entities": []}, {"text": "Another typical approach is to leverage non-textual features to automatically identify high quality answers;).", "labels": [], "entities": []}, {"text": "However, in this way, the mining of meaningful textual features usually tends to be ignored.", "labels": [], "entities": []}, {"text": "Intuitively, combining both textual and nontextual information extracted from answers is helpful to improve the performance for predicting the answer quality.", "labels": [], "entities": [{"text": "predicting", "start_pos": 128, "end_pos": 138, "type": "TASK", "confidence": 0.9636176824569702}]}, {"text": "However, textual and nontextual features usually have different kinds of representations and the correlations between them are highly non-linear.", "labels": [], "entities": []}, {"text": "Previous study) has shown that it is hard fora shallow model to discover the correlations over multiple sources.", "labels": [], "entities": []}, {"text": "To this end, a deep learning approach, called multimodal deep belief nets (mDBN), is introduced to address the above problems to predict the answer quality.", "labels": [], "entities": []}, {"text": "The approach includes two stages: feature learning and supervised training.", "labels": [], "entities": []}, {"text": "In the former stage, a specially designed deep network is given to learn the unified representation using both textual and non-textual information.", "labels": [], "entities": []}, {"text": "In the latter stage, the outputs of the network are then used as inputs fora linear classifier to make prediction.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows: The related work is surveyed in Section 2.", "labels": [], "entities": []}, {"text": "Then, the proposed approach and experimental results are presented in Section 3 and Section 4 respectively.", "labels": [], "entities": []}, {"text": "Finally, conclusions and future directions are drawn in Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Statistics on experimental datasets.", "labels": [], "entities": []}, {"text": " Table 3: Comparing results on YAHOO", "labels": [], "entities": [{"text": "YAHOO", "start_pos": 31, "end_pos": 36, "type": "TASK", "confidence": 0.6194753050804138}]}, {"text": " Table 4: Comparing results on ZHIDAO", "labels": [], "entities": [{"text": "ZHIDAO", "start_pos": 31, "end_pos": 37, "type": "DATASET", "confidence": 0.8202293515205383}]}]}