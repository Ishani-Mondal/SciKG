{"title": [{"text": "Context-Dependent Multilingual Lexical Lookup for Under-Resourced Languages", "labels": [], "entities": []}], "abstractContent": [{"text": "Current approaches for word sense dis-ambiguation and translation selection typically require lexical resources or large bilingual corpora with rich information fields and annotations, which are often infeasible for under-resourced languages.", "labels": [], "entities": [{"text": "word sense dis-ambiguation", "start_pos": 23, "end_pos": 49, "type": "TASK", "confidence": 0.7626701792081197}, {"text": "translation selection", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.9778044819831848}]}, {"text": "We extract translation context knowledge from a bilingual comparable corpora of a richer-resourced language pair, and inject it into a multilingual lexicon.", "labels": [], "entities": []}, {"text": "The multilingual lexicon can then be used to perform context-dependent lexical lookup on texts of any language, including under-resourced ones.", "labels": [], "entities": []}, {"text": "Evaluations on a prototype lookup tool, trained on a English-Malay bilingual Wikipedia corpus, show a precision score of 0.65 (baseline 0.55) and mean reciprocal rank score of 0.81 (baseline 0.771).", "labels": [], "entities": [{"text": "English-Malay bilingual Wikipedia corpus", "start_pos": 53, "end_pos": 93, "type": "DATASET", "confidence": 0.7436116188764572}, {"text": "precision score", "start_pos": 102, "end_pos": 117, "type": "METRIC", "confidence": 0.9838762283325195}, {"text": "mean reciprocal rank score", "start_pos": 146, "end_pos": 172, "type": "METRIC", "confidence": 0.8576510399580002}]}, {"text": "Based on the early encouraging results, the context-dependent lexical lookup tool maybe developed further into an intelligent reading aid, to help users grasp the gist of a second or foreign language text.", "labels": [], "entities": [{"text": "grasp the gist of a second or foreign language text", "start_pos": 153, "end_pos": 204, "type": "TASK", "confidence": 0.690166512131691}]}], "introductionContent": [{"text": "Word sense disambiguation (WSD) is the task of assigning sense tags to ambiguous lexical items (LIs) in a text.", "labels": [], "entities": [{"text": "Word sense disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8080543726682663}, {"text": "assigning sense tags to ambiguous lexical items (LIs) in a text", "start_pos": 47, "end_pos": 110, "type": "TASK", "confidence": 0.618975219818262}]}, {"text": "Translation selection chooses target language items for translating ambiguous LIs in a text, and can therefore be viewed as a kind of WSD task, with translations as the sense tags.", "labels": [], "entities": [{"text": "Translation selection", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9608302712440491}, {"text": "translating ambiguous LIs in a text", "start_pos": 56, "end_pos": 91, "type": "TASK", "confidence": 0.8380067149798075}, {"text": "WSD task", "start_pos": 134, "end_pos": 142, "type": "TASK", "confidence": 0.87287238240242}]}, {"text": "The translation selection task may also be modified slightly to output a ranked list of translations.", "labels": [], "entities": [{"text": "translation selection task", "start_pos": 4, "end_pos": 30, "type": "TASK", "confidence": 0.9378136793772379}]}, {"text": "This then resembles a dictionary lookup process as performed by a human reader when reading or browsing a text written in a second or foreign language.", "labels": [], "entities": []}, {"text": "For convenience's sake, we will call this task (as performed via computational means) context-dependent lexical lookup.", "labels": [], "entities": []}, {"text": "It can also be viewed as a simplified version of the Cross-Lingual Lexical Substitution ( and Cross-Lingual Word Sense Disambiguation ( tasks, as defined in There is a large body of workaround WSD and translation selection.", "labels": [], "entities": [{"text": "Cross-Lingual Word Sense Disambiguation", "start_pos": 94, "end_pos": 133, "type": "TASK", "confidence": 0.6133977323770523}, {"text": "WSD", "start_pos": 193, "end_pos": 196, "type": "TASK", "confidence": 0.901974081993103}, {"text": "translation selection", "start_pos": 201, "end_pos": 222, "type": "TASK", "confidence": 0.9397991001605988}]}, {"text": "However, many of these approaches require lexical resources or large bilingual corpora with rich information fields and annotations, as reviewed in section 2.", "labels": [], "entities": []}, {"text": "Unfortunately, not all languages have equal amounts of digital resources for developing language technologies, and such requirements are often infeasible for underresourced languages.", "labels": [], "entities": []}, {"text": "We are interested in leveraging richer-resourced language pairs to enable context-dependent lexical lookup for under-resourced languages.", "labels": [], "entities": []}, {"text": "For this purpose, we model translation context knowledge as a second-order co-occurrence bag-of-words model.", "labels": [], "entities": [{"text": "translation context knowledge", "start_pos": 27, "end_pos": 56, "type": "TASK", "confidence": 0.8928420344988505}]}, {"text": "We propose a rapid approach for acquiring them from an untagged, comparable bilingual corpus of a (richer-resourced) language pair in section 3.", "labels": [], "entities": []}, {"text": "This information is then transferred into a multilingual lexicon to perform context-dependent lexical lookup on input texts, including those in an underresourced language (section 4).", "labels": [], "entities": []}, {"text": "Section 5 describes a prototype implementation, where translation context knowledge is extracted from a English-Malay bilingual corpus to enrich a multilingual lexicon with six languages.", "labels": [], "entities": []}, {"text": "Results from a small experiment are presented in 6 and discussed in section 7.", "labels": [], "entities": []}, {"text": "The approach is briefly compared with some related work in section 8, before concluding in section 9.", "labels": [], "entities": []}], "datasetContent": [{"text": "80 input sentences containing LIs with translation ambiguities were randomly selected from the Internet (English, Malay and Chinese) and contributed by a native speaker (Iban).", "labels": [], "entities": []}, {"text": "The test words are: \u2022 English \u00abplant\u00bb (vegetation or factory), \u2022 English \u00abbank\u00bb (financial institution or riverside land), \u2022 Malay \u00abkabinet\u00bb (governmental Cabinet or household furniture), \u2022 Malay \u00abmangga\u00bb (mango or padlock), \u2022 Chinese \u00ab\u8c37\u00bb (g\u00f9, valley or grain) and \u2022 Iban \u00abemperaja\u00bb (rainbow or lover).", "labels": [], "entities": []}, {"text": "Each test sentence was first POS-tagged automatically based on the Penn Treebank tagset.", "labels": [], "entities": [{"text": "Penn Treebank tagset", "start_pos": 67, "end_pos": 87, "type": "DATASET", "confidence": 0.9947996338208517}]}, {"text": "The English test sentences were lemmatised and POStagged with the Stanford Parser.", "labels": [], "entities": [{"text": "English test sentences", "start_pos": 4, "end_pos": 26, "type": "DATASET", "confidence": 0.8845224976539612}, {"text": "POStagged", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9951436519622803}, {"text": "Stanford Parser", "start_pos": 66, "end_pos": 81, "type": "DATASET", "confidence": 0.7869800627231598}]}, {"text": "The Chinese test sentences segmented with the Stanford Chinese Word Segmenter tool.", "labels": [], "entities": [{"text": "Stanford Chinese Word Segmenter tool", "start_pos": 46, "end_pos": 82, "type": "DATASET", "confidence": 0.8872782588005066}]}, {"text": "For Malay POS-tagging, we trained the QTag tagger 6 on a hand-tagged Malay corpus, and applied the trained tagger on our test sentences.", "labels": [], "entities": []}, {"text": "As we lacked a Iban POS-tagger, the Iban test sentences were tagged by hand.", "labels": [], "entities": [{"text": "Iban test sentences", "start_pos": 36, "end_pos": 55, "type": "DATASET", "confidence": 0.8195187250773112}]}, {"text": "LIs of each language and their associated vectors can then be retrieved from the multilingual lexicon.", "labels": [], "entities": []}, {"text": "The prototype tool LEXICALSELECTOR then computes the CSim score and ranks potential translation sets for each LI in the input sentences (ranking strategy wiki-lsi).", "labels": [], "entities": [{"text": "LEXICALSELECTOR", "start_pos": 19, "end_pos": 34, "type": "METRIC", "confidence": 0.8724350929260254}]}, {"text": "The baseline strategy (base-freq) selects the translation set whose members occur most frequently in the bilingual Wikipedia corpus.", "labels": [], "entities": []}, {"text": "As a comparison, the English, Chinese and Malay test sentences were fed to Google Translate and translated into Chinese, Malay and English.", "labels": [], "entities": []}, {"text": "(Google Translate does not support Iban currently.)", "labels": [], "entities": []}, {"text": "The Google Translate interface makes available the ranked list of translation candidates for each word in an input sentence, one language at a time.The translated word for each of the input test word can therefore be noted.", "labels": [], "entities": []}, {"text": "The highest rank of the correct translation for the test words in English/Chinese/Malay are used to evaluate goog-tr.", "labels": [], "entities": []}, {"text": "Two metrics were used in this quick evaluation.", "labels": [], "entities": []}, {"text": "The first metric is by taking the precision of the first translation set returned by each ranking strategy, i.e. whether the top ranked translation set contains the correct translation of the ambiguous item.", "labels": [], "entities": [{"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9990960359573364}]}, {"text": "The precision metric is important for applications like machine translation, where only the top-ranked meaning or translation is considered.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.998609185218811}, {"text": "machine translation", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.8496478796005249}]}, {"text": "The results may also be evaluated similar to a document retrieval task, i.e. as a ranked lexical lookup for human consumption.", "labels": [], "entities": [{"text": "document retrieval task", "start_pos": 47, "end_pos": 70, "type": "TASK", "confidence": 0.7345451811949412}]}, {"text": "This is measured by the mean reciprocal rank (MRR), the average of the reciprocal ranks of the correct translation set for each input sentence in the test set T : The results for the three ranking strategies are summarised in.", "labels": [], "entities": [{"text": "mean reciprocal rank (MRR)", "start_pos": 24, "end_pos": 50, "type": "METRIC", "confidence": 0.8914900819460551}]}, {"text": "For the precision metric, wiki-lsi scored 0.650 when all 80 input sentences are tested, while the base-freq baseline scored 0.550.", "labels": [], "entities": [{"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9991911053657532}]}, {"text": "goog-tr has the highest precision at 0.797.", "labels": [], "entities": [{"text": "goog-tr", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8165377378463745}, {"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9991853833198547}]}, {"text": "However, if only the Chinese and Malay inputs -which has less presence on the Internet and 'less resource-rich' than English -were tested (since goog-tr cannot accept Iban inputs), wiki-lsi and goog-tr actually performs equally well at 0.690 precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 242, "end_pos": 251, "type": "METRIC", "confidence": 0.9969736337661743}]}, {"text": "In our evaluation, the MRR score of wiki-lsi is 0.810, while base-freq scored 0.771.", "labels": [], "entities": [{"text": "MRR", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.9399726986885071}]}, {"text": "wiki-lsi even outperforms goog-tr when only the Chinese and Malay test sentences are considered for the MRR metric, as goog-tr", "labels": [], "entities": [{"text": "MRR", "start_pos": 104, "end_pos": 107, "type": "TASK", "confidence": 0.44898521900177}]}], "tableCaptions": [{"text": " Table 1: Precision and MRR scores of context- dependent lexical lookup", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9522712826728821}, {"text": "MRR", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.7796510457992554}]}]}