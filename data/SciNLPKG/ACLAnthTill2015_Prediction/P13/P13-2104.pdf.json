{"title": [{"text": "Dependency Parser Adaptation with Subtrees from Auto-Parsed Target Domain Data", "labels": [], "entities": [{"text": "Dependency Parser Adaptation", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.738949179649353}]}], "abstractContent": [{"text": "In this paper, we propose a simple and effective approach to domain adaptation for dependency parsing.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.7219872921705246}, {"text": "dependency parsing", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.8472478985786438}]}, {"text": "This is a feature augmentation approach in which the new features are constructed based on sub-tree information extracted from the auto-parsed target domain data.", "labels": [], "entities": []}, {"text": "To demonstrate the effectiveness of the proposed approach , we evaluate it on three pairs of source-target data, compared with several common baseline systems and previous approaches.", "labels": [], "entities": []}, {"text": "Our approach achieves significant improvement on all the three pairs of data sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, several dependency parsing algorithms ( have been proposed and achieved high parsing accuracies on several treebanks of different languages.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.7818493247032166}]}, {"text": "However, the performance of such parsers declines when training and test data come from different domains.", "labels": [], "entities": []}, {"text": "Furthermore, the manually annotated treebanks that these parsers rely on are highly expensive to create.", "labels": [], "entities": []}, {"text": "Therefore, developing dependency parsing algorithms that can be easily ported from one domain to another-say, from a resource-rich domain to a resource-poor domain-is of great importance.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.8028284013271332}]}, {"text": "Several approaches have been proposed for the task of parser adaptation.", "labels": [], "entities": [{"text": "parser adaptation", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.9339796900749207}]}, {"text": "successfully applied self-training to domain adaptation for constituency parsing using the reranking parser of. explored self-training when the amount of the annotated data is small and achieved significant improvement.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7167538851499557}, {"text": "constituency parsing", "start_pos": 60, "end_pos": 80, "type": "TASK", "confidence": 0.8649937510490417}]}, {"text": "enhanced the performance of dependency parser adaptation by utilizing a large-scale hand-crafted HPSG grammar.", "labels": [], "entities": [{"text": "dependency parser adaptation", "start_pos": 28, "end_pos": 56, "type": "TASK", "confidence": 0.9024575352668762}]}, {"text": "proposed a data selection method based on effective measures of domain similarity for dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.8423189222812653}]}, {"text": "There are roughly two varieties of domain adaptation problem-fully supervised casein which there area small amount of labeled data in the target domain, and semi-supervised casein which there are no labeled data in the target domain.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.7155320197343826}]}, {"text": "In this paper, we present a parsing adaptation approach focused on the fully supervised case.", "labels": [], "entities": [{"text": "parsing adaptation", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.9705333113670349}]}, {"text": "It is a feature augmentation approach in which the new features are constructed based on subtree information extracted from the auto-parsed target domain data.", "labels": [], "entities": []}, {"text": "For evaluation, we run experiments on three pairs of source-target domains-WSJBrown, Brown-WSJ, and WSJ-Genia.", "labels": [], "entities": [{"text": "WSJ-Genia", "start_pos": 100, "end_pos": 109, "type": "DATASET", "confidence": 0.9354444146156311}]}, {"text": "Our approach achieves significant improvement on all these data sets.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Results with the first-order parsing model  in the first and second experiments. The super- script indicates the source of labeled data used in  training.", "labels": [], "entities": []}, {"text": " Table 3: Results with the second-order sibling  parsing model in the first and second experiments.", "labels": [], "entities": [{"text": "sibling  parsing", "start_pos": 40, "end_pos": 56, "type": "TASK", "confidence": 0.6217372119426727}]}, {"text": " Table 4: Results with first-order parsing model in  the third experiment. \"Plank (2011)\" refers to the  approach in Plank and van Noord (2011).", "labels": [], "entities": [{"text": "Plank (2011)\"", "start_pos": 76, "end_pos": 89, "type": "DATASET", "confidence": 0.8015294820070267}]}, {"text": " Table 5: The performance (UAS/LAS) of the fi- nal parser in the WSJ-to-Genia experiment when  different training data are used to create the final  parser. The column label and row label indicate  the choice of the labeled data used in Step 1 and 3  of the process described in Section 2.2.", "labels": [], "entities": [{"text": "UAS/LAS)", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9000269025564194}]}]}