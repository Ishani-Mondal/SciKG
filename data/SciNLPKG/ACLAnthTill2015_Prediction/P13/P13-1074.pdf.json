{"title": [], "abstractContent": [{"text": "Punctuations are not available in automatic speech recognition outputs, which could create barriers to many subsequent text processing tasks.", "labels": [], "entities": [{"text": "speech recognition outputs", "start_pos": 44, "end_pos": 70, "type": "TASK", "confidence": 0.7894249757130941}]}, {"text": "This paper proposes a novel method to predict punctuation symbols for the stream of words in transcribed speech texts.", "labels": [], "entities": []}, {"text": "Our method jointly performs parsing and punctuation prediction by integrating a rich set of syntactic features when processing words from left to right.", "labels": [], "entities": [{"text": "parsing", "start_pos": 28, "end_pos": 35, "type": "TASK", "confidence": 0.967456579208374}, {"text": "punctuation prediction", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.8413523435592651}]}, {"text": "It can exploit a global view to capture long-range dependencies for punctuation prediction with linear complexity.", "labels": [], "entities": [{"text": "punctuation prediction", "start_pos": 68, "end_pos": 90, "type": "TASK", "confidence": 0.8208983242511749}]}, {"text": "The experimental results on the test data sets of IWSLT and TDT4 show that our method can achieve high-level performance in punctuation prediction over the stream of words in transcribed speech text.", "labels": [], "entities": [{"text": "IWSLT", "start_pos": 50, "end_pos": 55, "type": "DATASET", "confidence": 0.9029157161712646}, {"text": "TDT4", "start_pos": 60, "end_pos": 64, "type": "DATASET", "confidence": 0.9017929434776306}, {"text": "punctuation prediction", "start_pos": 124, "end_pos": 146, "type": "TASK", "confidence": 0.6942715644836426}]}], "introductionContent": [{"text": "Standard automatic speech recognizers output unstructured streams of words.", "labels": [], "entities": [{"text": "automatic speech recognizers output unstructured streams of words", "start_pos": 9, "end_pos": 74, "type": "TASK", "confidence": 0.7920782417058945}]}, {"text": "They neither perform a proper segmentation of the output into sentences, nor predict punctuation symbols.", "labels": [], "entities": []}, {"text": "The unavailable punctuations and sentence boundaries in transcribed speech texts create barriers to many subsequent processing tasks, such as summarization, information extraction, question answering and machine translation.", "labels": [], "entities": [{"text": "summarization", "start_pos": 142, "end_pos": 155, "type": "TASK", "confidence": 0.9858278036117554}, {"text": "information extraction", "start_pos": 157, "end_pos": 179, "type": "TASK", "confidence": 0.8020862936973572}, {"text": "question answering", "start_pos": 181, "end_pos": 199, "type": "TASK", "confidence": 0.8983421921730042}, {"text": "machine translation", "start_pos": 204, "end_pos": 223, "type": "TASK", "confidence": 0.7833265662193298}]}, {"text": "Thus, the segmentation of long texts is necessary in many real applications.", "labels": [], "entities": [{"text": "segmentation of long texts", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.8717106580734253}]}, {"text": "For example, in speech-to-speech translation, continuously transcribed speech texts need to be segmented before being fed into subsequent machine translation systems (.", "labels": [], "entities": [{"text": "speech-to-speech translation", "start_pos": 16, "end_pos": 44, "type": "TASK", "confidence": 0.7291915714740753}]}, {"text": "This is because current machine translation (MT) systems perform the translation at the sentence level, where various models used in MT are trained over segmented sentences and many algorithms inside MT have an exponential complexity with regard to the length of inputs.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.8523956775665283}, {"text": "MT", "start_pos": 133, "end_pos": 135, "type": "TASK", "confidence": 0.9295265674591064}]}, {"text": "The punctuation prediction problem has attracted research interest in both the speech processing community and the natural language processing community.", "labels": [], "entities": [{"text": "punctuation prediction problem", "start_pos": 4, "end_pos": 34, "type": "TASK", "confidence": 0.9117122292518616}]}, {"text": "Most previous work primarily exploits local features in their statistical models such as lexicons, prosodic cues and hidden event language model (HELM) (.", "labels": [], "entities": []}, {"text": "The word-level models integrating local features have narrow views about the input and could not achieve satisfied performance due to the limited context information access . Naturally, global contexts are required to model the punctuation prediction, especially for long-range dependencies.", "labels": [], "entities": [{"text": "punctuation prediction", "start_pos": 228, "end_pos": 250, "type": "TASK", "confidence": 0.7018862664699554}]}, {"text": "For instance, in English question sentences, the ending question mark is long-range dependent on the initial phrases (, such as \"could you\" in.", "labels": [], "entities": []}, {"text": "There has been some work trying to incorporate syntactic features to broaden the view of hypotheses in the punctuation prediction models.", "labels": [], "entities": [{"text": "punctuation prediction", "start_pos": 107, "end_pos": 129, "type": "TASK", "confidence": 0.7253028303384781}]}, {"text": "In their methods, the punctuation prediction is treated as a separated post-procedure of parsing, which may suffer from the problem of error propagation.", "labels": [], "entities": [{"text": "punctuation prediction", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.7799285054206848}, {"text": "parsing", "start_pos": 89, "end_pos": 96, "type": "TASK", "confidence": 0.9721498489379883}, {"text": "error propagation", "start_pos": 135, "end_pos": 152, "type": "TASK", "confidence": 0.7237082719802856}]}, {"text": "In addition, these approaches are notable to incrementally process inputs and are not efficient for very long inputs, especially in the cases of long transcribed speech texts from presentations where the number of streaming words could be larger than hundreds or thousands.", "labels": [], "entities": []}, {"text": "In this paper, we propose jointly performing punctuation prediction and transition-based dependency parsing over transcribed speech text.", "labels": [], "entities": [{"text": "punctuation prediction", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.811264306306839}, {"text": "transition-based dependency parsing", "start_pos": 72, "end_pos": 107, "type": "TASK", "confidence": 0.6313916544119517}]}, {"text": "When the transition-based parsing consumes the stream of words left to right with the shift-reduce decoding algorithm, punctuation symbols are predicted for each word based on the contexts of the parsing tree.", "labels": [], "entities": []}, {"text": "Two models are proposed to cause the punctuation prediction to interact with the transition actions in parsing.", "labels": [], "entities": []}, {"text": "One is to conduct transition actions of parsing followed by punctuation predictions in a cascaded way.", "labels": [], "entities": [{"text": "parsing", "start_pos": 40, "end_pos": 47, "type": "TASK", "confidence": 0.9667757749557495}]}, {"text": "The other is to associate the conventional transition actions of parsing with punctuation perditions, so that predicted punctuations are directly inferred from the parsing tree.", "labels": [], "entities": []}, {"text": "Our models have linear complexity and are capable of handling streams of words with any length.", "labels": [], "entities": []}, {"text": "In addition, the computation of models use a rich set of syntactic features, which can improve the complicated punctuation predictions from a global view, especially for the long range dependencies.", "labels": [], "entities": []}, {"text": "shows an example of how parsing helps punctuation prediction over the transcribed speech text.", "labels": [], "entities": [{"text": "punctuation prediction", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.8612902164459229}]}, {"text": "As illustrated in(b), two commas are predicted when their preceding words act as the adverbial modifiers (advmod) during parsing.", "labels": [], "entities": []}, {"text": "The period after the word \"menu\" is predicted when the parsing of an adverbial clause modifier (advcl) is completed.", "labels": [], "entities": [{"text": "parsing of an adverbial clause modifier", "start_pos": 55, "end_pos": 94, "type": "TASK", "confidence": 0.7217783729235331}]}, {"text": "The question mark at the end of the input is determined when a direct object modifier (dobj) is identified, together with the long range clue that the auxiliary word occurs before the nominal subject (nsubj).", "labels": [], "entities": []}, {"text": "Eventually, two segmentations are formed according to the punctuation prediction results, shown in(c).", "labels": [], "entities": []}, {"text": "The training data used for our models is adapted from Treebank data by excluding all punctuations but keeping the punctuation contexts, so that it can simulate the unavailable annotated transcribed speech texts.", "labels": [], "entities": [{"text": "Treebank data", "start_pos": 54, "end_pos": 67, "type": "DATASET", "confidence": 0.9448211491107941}]}, {"text": "In decoding, beam search is used to get optimal punctuation prediction results.", "labels": [], "entities": [{"text": "beam search", "start_pos": 13, "end_pos": 24, "type": "TASK", "confidence": 0.8364471793174744}]}, {"text": "We conduct experiments on both IWSLT data and TDT4 test data sets.", "labels": [], "entities": [{"text": "IWSLT data", "start_pos": 31, "end_pos": 41, "type": "DATASET", "confidence": 0.9153348207473755}, {"text": "TDT4 test data sets", "start_pos": 46, "end_pos": 65, "type": "DATASET", "confidence": 0.9568741768598557}]}, {"text": "The experimental results show that our method can achieve higher performance than the CRF-based baseline method.", "labels": [], "entities": []}, {"text": "The paper is structured as follows: Section 2 conducts a survey of related work.", "labels": [], "entities": []}, {"text": "The transitionbased dependency parsing is introduced in Section 3.", "labels": [], "entities": [{"text": "transitionbased dependency parsing", "start_pos": 4, "end_pos": 38, "type": "TASK", "confidence": 0.5704774459203085}]}, {"text": "We explain our approach to predicting punctuations for transcribed speech texts in Section 4.", "labels": [], "entities": [{"text": "predicting punctuations for transcribed speech texts", "start_pos": 27, "end_pos": 79, "type": "TASK", "confidence": 0.8339515924453735}]}, {"text": "Section 5 gives the results of our experiment.", "labels": [], "entities": []}, {"text": "The conclusion and future work are given in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our training data of transition-based dependency trees are converted from phrasal structure trees in English Web Treebank (LDC2012T13) and the English portion of OntoNotes 4.0 (LDC2011T03) by the Stanford Conversion toolkit).", "labels": [], "entities": [{"text": "English Web Treebank (LDC2012T13)", "start_pos": 101, "end_pos": 134, "type": "DATASET", "confidence": 0.9389090041319529}]}, {"text": "It contains around 1.5M words in total and consist of various genres including weblogs, web texts, newsgroups, email, reviews, questionanswer sessions, newswires, broadcast news and broadcast conversations.", "labels": [], "entities": []}, {"text": "To simulate the transcribed speech text, all words in dependency trees are lowercased and punctuations are excluded before model training.", "labels": [], "entities": []}, {"text": "In addition, every ten dependency trees are concatenated sequentially to simulate a parsing result of a stream of words in the model training.", "labels": [], "entities": []}, {"text": "There are two test data sets used in our experiments.", "labels": [], "entities": []}, {"text": "One is the English corpus of the IWSLT09 evaluation campaign) that is the conversional speech text.", "labels": [], "entities": [{"text": "IWSLT09 evaluation campaign", "start_pos": 33, "end_pos": 60, "type": "DATASET", "confidence": 0.8097375631332397}, {"text": "conversional speech text", "start_pos": 74, "end_pos": 98, "type": "TASK", "confidence": 0.9041557908058167}]}, {"text": "The other is a subset of the TDT4 English data (LDC2005T16) which consists of 200 hours of closed-captioned broadcast news.", "labels": [], "entities": [{"text": "TDT4 English data (LDC2005T16)", "start_pos": 29, "end_pos": 59, "type": "DATASET", "confidence": 0.9255185524622599}]}, {"text": "In the decoding, the beam size of both the transition-based parsing and punctuation prediction is set to 5.", "labels": [], "entities": []}, {"text": "The part-of-speech tagger is our re-implementation of the work in).", "labels": [], "entities": [{"text": "part-of-speech tagger", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.7872257232666016}]}, {"text": "The evaluation metrics of our experiments are precision (prec.), recall (rec.) and F1-measure (F1).", "labels": [], "entities": [{"text": "precision", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9994188547134399}, {"text": "recall (rec.)", "start_pos": 65, "end_pos": 78, "type": "METRIC", "confidence": 0.9263143837451935}, {"text": "F1-measure (F1)", "start_pos": 83, "end_pos": 98, "type": "METRIC", "confidence": 0.8513588905334473}]}, {"text": "For the comparison, we also implement a baseline method based on the CRF model.", "labels": [], "entities": []}, {"text": "It incorporates the features of bag of words and POS tags shown in(a), which are commonly used in previous related work.", "labels": [], "entities": []}, {"text": "We test the performance of our method on both the correctly recognized texts and automatically recognized texts.", "labels": [], "entities": []}, {"text": "The former data is used to evaluate the capability of punctuation prediction of our algorithm regardless of the noises from speech data, as our model training data come from formal text instead of transcribed speech data.", "labels": [], "entities": [{"text": "punctuation prediction", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.6939211189746857}]}, {"text": "The usage of the latter test data set aims to evaluate the effectiveness of our method in real applications where lots of substantial recognition errors could be contained.", "labels": [], "entities": []}, {"text": "In addition, we also evaluate the quality of our transition-based parsing, as its performance could have a big influence on the quality of punctuation prediction.", "labels": [], "entities": [{"text": "transition-based parsing", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.5104942321777344}, {"text": "punctuation prediction", "start_pos": 139, "end_pos": 161, "type": "TASK", "confidence": 0.7758149206638336}]}], "tableCaptions": [{"text": " Table 4. Punctuation prediction performance on  correctly recognized text", "labels": [], "entities": [{"text": "Punctuation prediction", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.8432115614414215}]}, {"text": " Table 5. Punctuation prediction performance on  automatically recognized text", "labels": [], "entities": [{"text": "Punctuation prediction", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.8591411113739014}]}, {"text": " Table 6. The performance of our transition-based  parser on written texts. UAS=unlabeled attach- ment score; LAS=labeled attachment score", "labels": [], "entities": [{"text": "UAS", "start_pos": 76, "end_pos": 79, "type": "METRIC", "confidence": 0.9915210008621216}, {"text": "attach- ment score", "start_pos": 90, "end_pos": 108, "type": "METRIC", "confidence": 0.7744639962911606}, {"text": "LAS=labeled attachment score", "start_pos": 110, "end_pos": 138, "type": "METRIC", "confidence": 0.7359422028064728}]}]}