{"title": [{"text": "Co-Regression for Cross-Language Review Rating Prediction", "labels": [], "entities": [{"text": "Cross-Language Review Rating Prediction", "start_pos": 18, "end_pos": 57, "type": "TASK", "confidence": 0.6674834638834}]}], "abstractContent": [{"text": "The task of review rating prediction can be well addressed by using regression algorithms if there is a reliable training set of reviews with human ratings.", "labels": [], "entities": [{"text": "review rating prediction", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.7163156469662985}]}, {"text": "In this paper, we aim to investigate a more challenging task of cross-language review rating prediction, which makes use of only rated reviews in a source language (e.g. English) to predict the rating scores of unrated reviews in a target language (e.g. German).", "labels": [], "entities": [{"text": "cross-language review rating prediction", "start_pos": 64, "end_pos": 103, "type": "TASK", "confidence": 0.6949997022747993}]}, {"text": "We propose anew co-regression algorithm to address this task by leveraging unlabeled reviews.", "labels": [], "entities": []}, {"text": "Evaluation results on several datasets show that our proposed co-regression algorithm can consistently improve the prediction results.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the development of e-commerce, more and more people like to buy products on the web and express their opinions about the products by writing reviews.", "labels": [], "entities": []}, {"text": "These reviews usually contain valuable information for other people's reference when they buy the same or similar products.", "labels": [], "entities": []}, {"text": "In some applications, it is useful to categorize a review into either positive or negative, but in many real-world scenarios, it is important to provide numerical ratings rather than binary decisions.", "labels": [], "entities": []}, {"text": "The task of review rating prediction aims to automatically predict the rating scores of unrated product reviews.", "labels": [], "entities": [{"text": "review rating prediction", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.6206240852673849}]}, {"text": "It is considered as a finergrained task than the binary sentiment classification task.", "labels": [], "entities": [{"text": "binary sentiment classification task", "start_pos": 49, "end_pos": 85, "type": "TASK", "confidence": 0.758824348449707}]}, {"text": "Review rating prediction has been modeled as a multi-class classification or regression task, and the regression based methods have shown better performance than the multi-class classification based methods in recent studies ().", "labels": [], "entities": [{"text": "Review rating prediction", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8144329984982809}]}, {"text": "Therefore, we focus on investigating regression-based methods in this study.", "labels": [], "entities": []}, {"text": "Traditionally, the review rating prediction task has been investigated in a monolingual setting, which means that the training reviews with human ratings and the test reviews are in the same language.", "labels": [], "entities": [{"text": "review rating prediction task", "start_pos": 19, "end_pos": 48, "type": "TASK", "confidence": 0.7061024457216263}]}, {"text": "However, a more challenging task is to predict the rating scores of the reviews in a target language (e.g. German) by making use of the rated reviews in a different source language (e.g. English), which is called Cross-Language Review Rating Prediction.", "labels": [], "entities": [{"text": "Cross-Language Review Rating Prediction", "start_pos": 213, "end_pos": 252, "type": "TASK", "confidence": 0.5597125515341759}]}, {"text": "Considering that the resources (i.e. the rated reviews) for review rating prediction in different languages are imbalanced, it would be very useful to make use of the resources in resource-rich languages to help address the review rating prediction task in resource-poor languages.", "labels": [], "entities": [{"text": "review rating prediction", "start_pos": 60, "end_pos": 84, "type": "TASK", "confidence": 0.695776363213857}, {"text": "review rating prediction", "start_pos": 224, "end_pos": 248, "type": "TASK", "confidence": 0.6682893335819244}]}, {"text": "The task of cross-language review rating prediction can be typically addressed by using machine translation services for review translation, and then applying regression methods based on the monolingual training and test sets.", "labels": [], "entities": [{"text": "cross-language review rating prediction", "start_pos": 12, "end_pos": 51, "type": "TASK", "confidence": 0.7990735620260239}, {"text": "review translation", "start_pos": 121, "end_pos": 139, "type": "TASK", "confidence": 0.717607170343399}]}, {"text": "However, due to the poor quality of machine translation, the reviews translated from one language A to another language B are usually very different from the original reviews in language B, because the words or syntax of the translated reviews maybe erroneous or non-native.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.6827270537614822}]}, {"text": "This phenomenon brings great challenges for existing regression algorithms.", "labels": [], "entities": []}, {"text": "In this study, we propose anew co-regression algorithm to address the above problem by leveraging unlabeled reviews in the target language.", "labels": [], "entities": []}, {"text": "Our algorithm can leverage both views of the reviews in the source language and the target language to collaboratively determine the confidently predicted ones out of the unlabeled reviews, and then use the selected examples to enlarge the training set.", "labels": [], "entities": []}, {"text": "Evaluation results on several datasets show that our proposed coregression algorithm can consistently improve the prediction results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the WEBIS-CLS-10 corpus 3 provided by for evaluation.", "labels": [], "entities": [{"text": "WEBIS-CLS-10 corpus 3", "start_pos": 12, "end_pos": 33, "type": "DATASET", "confidence": 0.9687739809354147}]}, {"text": "It consists of Amazon product reviews for three product categories (i.e. books, dvds and music) written in different languages including English, German, etc.", "labels": [], "entities": []}, {"text": "For each language-category pair there exist three sets of training documents, test documents, and unlabeled documents.", "labels": [], "entities": []}, {"text": "The training and test sets comprise 2000 documents each, whereas the number of unlabeled documents varies from 9000 -170000.", "labels": [], "entities": []}, {"text": "The dataset is provided with the rating score between 1 to 5 assigned by users, which can be used for the review rating prediction task.", "labels": [], "entities": [{"text": "review rating prediction task", "start_pos": 106, "end_pos": 135, "type": "TASK", "confidence": 0.6850908026099205}]}, {"text": "We extracted texts from both the summary field and the text field to represent a review text.", "labels": [], "entities": []}, {"text": "We then extracted the rating score as a review's corresponding real-valued label.", "labels": [], "entities": []}, {"text": "In the cross-language scenario, we regarded English as the source language, and regarded German as the target language.", "labels": [], "entities": []}, {"text": "The experiments were conducted on each product category separately.", "labels": [], "entities": []}, {"text": "Without loss of generality, we sampled and used only 8000 unlabeled documents for each product category.", "labels": [], "entities": []}, {"text": "We use Mean Square Error (MSE) as the evaluation metric, which penalizes more severe errors more heavily.", "labels": [], "entities": [{"text": "Mean Square Error (MSE)", "start_pos": 7, "end_pos": 30, "type": "METRIC", "confidence": 0.9447977840900421}]}, {"text": "In the experiments, our proposed co-regression algorithm (i.e. \"co-regression\") is compared with the COREG algorithm in (Zhou and) and a few other baselines.", "labels": [], "entities": [{"text": "COREG", "start_pos": 101, "end_pos": 106, "type": "METRIC", "confidence": 0.7473549842834473}]}, {"text": "For our proposed coregression algorithm, the growth size m is simply set to 50.", "labels": [], "entities": []}, {"text": "We implemented the COREG algorithm by replacing the KNN regressor with the regression SVM and the pool size is also set to 50.", "labels": [], "entities": [{"text": "COREG", "start_pos": 19, "end_pos": 24, "type": "METRIC", "confidence": 0.8434451222419739}]}, {"text": "The iteration number I varies from 1 to 150.", "labels": [], "entities": [{"text": "iteration number I", "start_pos": 4, "end_pos": 22, "type": "METRIC", "confidence": 0.6717143058776855}]}, {"text": "The comparison results are shown in.", "labels": [], "entities": []}, {"text": "We can see that on all product categories, the MSE values of our co-regression algorithm and the two component regressors tend to decline over a wide range of I, which means that the selected confidently labeled examples at each iteration are indeed helpful to improve the regressors.", "labels": [], "entities": []}, {"text": "Our proposed co-regression algorithm outperforms all the baselines (including COREG) over different iteration members, which verifies the effectiveness of our proposed algorithm.", "labels": [], "entities": [{"text": "COREG", "start_pos": 78, "end_pos": 83, "type": "METRIC", "confidence": 0.8573773503303528}]}, {"text": "We can also see that the COREG algorithm does not perform well for this cross-language regression task.", "labels": [], "entities": [{"text": "COREG", "start_pos": 25, "end_pos": 30, "type": "METRIC", "confidence": 0.865074634552002}]}, {"text": "Overall, our proposed co-regression algorithm can consistently improve the prediction results.", "labels": [], "entities": []}], "tableCaptions": []}