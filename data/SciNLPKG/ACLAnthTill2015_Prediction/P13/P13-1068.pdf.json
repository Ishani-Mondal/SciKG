{"title": [{"text": "Large tagset labeling using Feed Forward Neural Networks. Case study on Romanian Language", "labels": [], "entities": []}], "abstractContent": [{"text": "Standard methods for part-of-speech tagging suffer from data sparseness when used on highly inflectional languages (which require large lexical tagset inventories).", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 21, "end_pos": 43, "type": "TASK", "confidence": 0.7260923683643341}]}, {"text": "For this reason, a number of alternative methods have been proposed over the years.", "labels": [], "entities": []}, {"text": "One of the most successful methods used for this task, FDOOHG7LHUHG7DJJLQJ7XIL, 1999), exploits a reduced set of tags derived by removing several recoverable features from the lexicon morpho-syntactic descriptions.", "labels": [], "entities": [{"text": "FDOOHG7LHUHG7DJJLQJ7XIL", "start_pos": 55, "end_pos": 78, "type": "METRIC", "confidence": 0.7160071134567261}]}, {"text": "A second phase is aimed at recovering the full set of morpho-syntactic features.", "labels": [], "entities": []}, {"text": "In this paper we present an alternative method to Tiered Tagging, based on local optimizations with Neural Networks and we show how, by properly encoding the input sequence in a general Neural Network architecture, we achieve results similar to the Tiered Tagging methodology, significantly faster and without requiring extensive linguistic knowledge as implied by the previously mentioned method.", "labels": [], "entities": [{"text": "Tiered Tagging", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.8923777937889099}, {"text": "Tiered Tagging", "start_pos": 249, "end_pos": 263, "type": "TASK", "confidence": 0.736884206533432}]}], "introductionContent": [{"text": "Part-of-speech tagging is a key process for various tasks such as\u00ecnformation extraction, text-to-speech synthesis, word sense disambiguation and machine translation.", "labels": [], "entities": [{"text": "Part-of-speech tagging", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7767370939254761}, {"text": "text-to-speech synthesis", "start_pos": 89, "end_pos": 113, "type": "TASK", "confidence": 0.7461157441139221}, {"text": "word sense disambiguation", "start_pos": 115, "end_pos": 140, "type": "TASK", "confidence": 0.7025908430417379}, {"text": "machine translation", "start_pos": 145, "end_pos": 164, "type": "TASK", "confidence": 0.7744387090206146}]}, {"text": "It is also known as lexical ambiguity resolution and it represents the process of assigning a uniquely interpretable label to every word inside a sentence.", "labels": [], "entities": [{"text": "lexical ambiguity resolution", "start_pos": 20, "end_pos": 48, "type": "TASK", "confidence": 0.6659515698750814}]}, {"text": "The labels are called POS tags and the entire inventory of POS tags is called a tagset.", "labels": [], "entities": []}, {"text": "There are several approaches to part-of-speech tagging, such as Hidden Markov Models (HMM), Maximum Entropy Classifiers (, Bayesian Networks, Neural Networks ( and Conditional Random Fields (CRF) ().", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.6896333247423172}]}, {"text": "All these methods are primarily intended for English, which uses a relatively small tagset inventory, compared to highly inflectional languages.", "labels": [], "entities": []}, {"text": "For the later mentioned languages, the lexicon tagsets (called morphosyntactic descriptions or MSDs) maybe 10-20 times or even larger than the best known tagsets for English.", "labels": [], "entities": []}, {"text": "For instance Czech MSD tagset requires more than 3000 labels (), Slovene more than 2000 labels, and Romanian more than 1100 labels).", "labels": [], "entities": [{"text": "Czech MSD tagset", "start_pos": 13, "end_pos": 29, "type": "DATASET", "confidence": 0.6992202599843343}]}, {"text": "The standard tagging methods, using such large tagsets, face serious data sparseness problems due to lack of statistical evidence, manifested by the non-robustness of the language models.", "labels": [], "entities": []}, {"text": "When tagging new texts that are not in the same domain as the training data, the accuracy decreases significantly.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.999640703201294}]}, {"text": "Even tagging in-domain texts may not be satisfactorily accurate.", "labels": [], "entities": []}, {"text": "One of the most successful methods used for this taVN FDOOHG 7LHUHG 7DJJLQJ 7XIL, 1999), exploits a reduced set of tags derived by removing several recoverable features from the lexicon morpho-syntactic descriptions.", "labels": [], "entities": [{"text": "FDOOHG 7LHUHG 7DJJLQJ 7XIL, 1999", "start_pos": 54, "end_pos": 86, "type": "DATASET", "confidence": 0.7275493890047073}]}, {"text": "According to the MULTEXT EAST lexical specifications, the Romanian tagset consists of a number of 614 MSD tags (by exploiting the case and gender regular syncretism) for wordforms and 10 punctuation tags (, which is still significantly larger than the tagset of English.", "labels": [], "entities": [{"text": "MULTEXT EAST lexical", "start_pos": 17, "end_pos": 37, "type": "TASK", "confidence": 0.5055713355541229}]}, {"text": "The MULTEX EAST version 4 contains specifications fora total of 16 languages: Bulgarian, Croatian, Czech, Estonian, English, Hungarian, Romanian, In the case of out-of-vocabulary (OOV) words, both approaches use suffix analysis to determine the most probable tags that can be assigned to the current word.", "labels": [], "entities": [{"text": "MULTEX EAST", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.5659838318824768}]}, {"text": "To clarify how these two methods work, if we want to train the network to label the current word, using a context window of 1 (previous tag, current possible tags, and possible tags for the next word) and if we have, say 100 tags in the tagset, the input is areal valued vector of 300 sub-unit elements and the output is a vector which contains 100 elements, also sub-unit real numbers.", "labels": [], "entities": []}, {"text": "As mentioned earlier, each value in the output vector corresponds to a distinct tag from tagset and the tag assigned to the current word is chosen to correspond to the maximum value inside the output vector.", "labels": [], "entities": []}, {"text": "The previously proposed methods still suffer from the same issue of data sparseness when applied to MSD tagging.", "labels": [], "entities": [{"text": "MSD tagging", "start_pos": 100, "end_pos": 111, "type": "TASK", "confidence": 0.887168824672699}]}, {"text": "However, in our approach, we overcome the problem through a different encoding of the input data (see section 2.1).", "labels": [], "entities": []}, {"text": "The power of neural networks results mainly from their ability to attain activation functions over different patterns via their learning algorithm.", "labels": [], "entities": []}, {"text": "By properly encoding the input sequence, the network chooses which input features contribute in determining the output features for MSDs (e.g. patterns composed of part of speech, gender, case, type etc.", "labels": [], "entities": []}, {"text": "contribute independently in selecting the optimal output sequence).", "labels": [], "entities": []}, {"text": "This way, we removed the need for explicit MSD to CTAG conversion and MSD recovery from CTAGs.", "labels": [], "entities": [{"text": "MSD to CTAG conversion", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.5908562391996384}, {"text": "MSD recovery", "start_pos": 70, "end_pos": 82, "type": "TASK", "confidence": 0.8412257730960846}]}], "datasetContent": [], "tableCaptions": []}