{"title": [{"text": "Probabilistic Domain Modelling With Contextualized Distributional Semantic Vectors", "labels": [], "entities": []}], "abstractContent": [{"text": "Generative probabilistic models have been used for content modelling and template induction, and are typically trained on small corpora in the target domain.", "labels": [], "entities": [{"text": "content modelling", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.8389232754707336}, {"text": "template induction", "start_pos": 73, "end_pos": 91, "type": "TASK", "confidence": 0.9213745594024658}]}, {"text": "In contrast, vector space models of distribu-tional semantics are trained on large corpora , but are typically applied to domain-general lexical disambiguation tasks.", "labels": [], "entities": []}, {"text": "We introduce Distributional Semantic Hidden Markov Models, a novel variant of a hidden Markov model that integrates these two approaches by incorporating contex-tualized distributional semantic vectors into a generative model as observed emissions.", "labels": [], "entities": []}, {"text": "Experiments in slot induction show that our approach yields improvements in learning coherent entity clusters in a domain.", "labels": [], "entities": [{"text": "slot induction", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.9622287750244141}]}, {"text": "Ina subsequent extrinsic evaluation , we show that these improvements are also reflected in multi-document summa-rization.", "labels": [], "entities": []}], "introductionContent": [{"text": "Detailed domain knowledge is crucial to many NLP tasks, either as an input for language understanding, or as the goal itself, to acquire such knowledge.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 79, "end_pos": 101, "type": "TASK", "confidence": 0.7611642777919769}]}, {"text": "For example, in information extraction, a list of slots in the target domain is given to the system, and in natural language generation, content models are trained to learn the content structure of texts in the target domain for information structuring and automatic summarization.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 16, "end_pos": 38, "type": "TASK", "confidence": 0.821633905172348}, {"text": "natural language generation", "start_pos": 108, "end_pos": 135, "type": "TASK", "confidence": 0.7322269082069397}, {"text": "information structuring", "start_pos": 229, "end_pos": 252, "type": "TASK", "confidence": 0.7687095403671265}, {"text": "summarization", "start_pos": 267, "end_pos": 280, "type": "TASK", "confidence": 0.8455907106399536}]}, {"text": "Generative probabilistic models have been one popular approach to content modelling.", "labels": [], "entities": [{"text": "content modelling", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.7962773442268372}]}, {"text": "An important advantage of this approach is that the structure of the model can be adapted to fit the assumptions about the structure of the domain and the nature of the end task.", "labels": [], "entities": []}, {"text": "As this field has progressed, the formal structures that are assumed to represent a domain have increased in complexity and become more hierarchical.", "labels": [], "entities": []}, {"text": "Earlier work assumes a flat set of topics (), which are expressed as states of a latent random variable in the model.", "labels": [], "entities": []}, {"text": "Later work organizes topics into a hierarchy from general to specific.", "labels": [], "entities": []}, {"text": "Recently, formalized a domain as a set of frames consisting of prototypical sequences of events, slots, and slot fillers or entities, inspired by classical AI work such as scripts.", "labels": [], "entities": []}, {"text": "We adopt much of this terminology in this work.", "labels": [], "entities": []}, {"text": "For example, in the CRIMINAL INVESTIGATIONS domain, there maybe events such as a murder, an investigation of the crime, an arrest, and atrial.", "labels": [], "entities": []}, {"text": "These would be indicated by event heads such as kill, arrest, charge, plead.", "labels": [], "entities": []}, {"text": "Relevant slots would include VICTIM, SUSPECT, AUTHORITIES, PLEA, etc.", "labels": [], "entities": [{"text": "VICTIM", "start_pos": 29, "end_pos": 35, "type": "DATASET", "confidence": 0.45132067799568176}, {"text": "AUTHORITIES", "start_pos": 46, "end_pos": 57, "type": "METRIC", "confidence": 0.6531776189804077}, {"text": "PLEA", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.9816012382507324}]}, {"text": "One problem faced by this line of work is that, by their nature, these models are typically trained on a small corpus from the target domain, on the order of hundreds of documents.", "labels": [], "entities": []}, {"text": "The small size of the training corpus makes it difficult to estimate reliable statistics, especially for more powerful features such as higher-order N-gram features or syntactic features.", "labels": [], "entities": []}, {"text": "By contrast, distributional semantic models are trained on large, domain-general corpora.", "labels": [], "entities": []}, {"text": "These methods model word meaning using the contexts in the training corpus in which the word appears.", "labels": [], "entities": []}, {"text": "The most popular approach today is a vector space representation, in which each dimension corresponds to some context word, and the value at that dimension corresponds to the strength of the association between the context word and the target word being modelled.", "labels": [], "entities": []}, {"text": "A notion of word similarity arises naturally from these models by comparing the similarity of the word vectors, for example by using a cosine measure.", "labels": [], "entities": []}, {"text": "Recently, these models have been extended by considering how distribu-tional representations can be modified depending on the specific context in which the word appears (, for example).", "labels": [], "entities": []}, {"text": "Contextualization has been found to improve performance in tasks like lexical substitution and word sense disambiguation.", "labels": [], "entities": [{"text": "lexical substitution", "start_pos": 70, "end_pos": 90, "type": "TASK", "confidence": 0.7665082216262817}, {"text": "word sense disambiguation", "start_pos": 95, "end_pos": 120, "type": "TASK", "confidence": 0.7351732651392618}]}, {"text": "In this paper, we propose to inject contextualized distributional semantic vectors into generative probabilistic models, in order to combine their complementary strengths for domain modelling.", "labels": [], "entities": []}, {"text": "There area number of potential advantages that distributional semantic models offer.", "labels": [], "entities": []}, {"text": "First, they provide domain-general representations of word meaning that cannot be reliably estimated from the small target-domain corpora on which probabilistic models are trained.", "labels": [], "entities": []}, {"text": "Second, the contextualization process allows the semantic vectors to implicitly encode disambiguated word sense and syntactic information, without further adding to the complexity of the generative model.", "labels": [], "entities": []}, {"text": "Our model, the Distributional Semantic Hidden Markov Model (DSHMM), incorporates contextualized distributional semantic vectors into a generative probabilistic model as observed emissions.", "labels": [], "entities": []}, {"text": "We demonstrate the effectiveness of our model in two domain modelling tasks.", "labels": [], "entities": []}, {"text": "First, we apply it to slot induction on guided summarization data over five different domains.", "labels": [], "entities": [{"text": "slot induction", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.9721257984638214}, {"text": "summarization", "start_pos": 47, "end_pos": 60, "type": "TASK", "confidence": 0.771314263343811}]}, {"text": "We show that our model outperforms a baseline version of our method that does not use distributional semantic vectors, as well as a recent state-of-the-art template induction method.", "labels": [], "entities": []}, {"text": "Then, we perform an extrinsic evaluation using multi-document summarization, wherein we show that our model is able to learn event and slot topics that are appropriate to include in a summary.", "labels": [], "entities": []}, {"text": "From a modelling perspective, these results show that probabilistic models for content modelling and template induction benefit from distributional semantics trained on a much larger corpus.", "labels": [], "entities": [{"text": "content modelling", "start_pos": 79, "end_pos": 96, "type": "TASK", "confidence": 0.7961977124214172}, {"text": "template induction", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.8201696574687958}]}, {"text": "From the perspective of distributional semantics, this work broadens the variety of problems to which distributional semantics can be applied, and proposes methods to perform inference in a probabilistic setting beyond geometric measures such as cosine similarity.", "labels": [], "entities": []}], "datasetContent": [{"text": "We trained the distributional semantic models using the Annotated Gigaword corpus (, which has been automatically preprocessed and is based on Gigaword 5th edition.", "labels": [], "entities": [{"text": "Annotated Gigaword corpus", "start_pos": 56, "end_pos": 81, "type": "DATASET", "confidence": 0.8184219797452291}, {"text": "Gigaword 5th edition", "start_pos": 143, "end_pos": 163, "type": "DATASET", "confidence": 0.8653964598973592}]}, {"text": "This corpus contains almost ten million news articles and more than 4 billion tokens.", "labels": [], "entities": []}, {"text": "We used those articles marked as \"stories\" -the vast majority of them.", "labels": [], "entities": []}, {"text": "We modelled the 50,000 most common lemmata as target words, and the 3,000 most common lemmata as context words.", "labels": [], "entities": []}, {"text": "We then trained DSHMM and conducted our evaluations on the TAC 2010 guided summarization data set.", "labels": [], "entities": [{"text": "DSHMM", "start_pos": 16, "end_pos": 21, "type": "DATASET", "confidence": 0.9629618525505066}, {"text": "TAC 2010 guided summarization data set", "start_pos": 59, "end_pos": 97, "type": "DATASET", "confidence": 0.9271494646867117}]}, {"text": "Lemmatization and extraction of event heads and arguments are done by preprocessing with the Stanford CoreNLP tool suite ().", "labels": [], "entities": [{"text": "Stanford CoreNLP tool suite", "start_pos": 93, "end_pos": 120, "type": "DATASET", "confidence": 0.9341936111450195}]}, {"text": "This data set contains 46 topic clusters of 20 articles each, grouped into five topic categories or domains.", "labels": [], "entities": []}, {"text": "For example, one topic cluster in the ATTACK category is about the Columbine Massacre.", "labels": [], "entities": [{"text": "ATTACK", "start_pos": 38, "end_pos": 44, "type": "TASK", "confidence": 0.5324491262435913}, {"text": "Columbine Massacre", "start_pos": 67, "end_pos": 85, "type": "DATASET", "confidence": 0.7502608299255371}]}, {"text": "Each topic cluster contains eight human-written \"model\" summaries (\"model\" here meaning a gold standard).", "labels": [], "entities": []}, {"text": "Half of the articles and model summaries in a topic cluster are used in the guided summarization task, and the rest are used in the update summarization task.", "labels": [], "entities": [{"text": "summarization task", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.8301399052143097}, {"text": "update summarization task", "start_pos": 132, "end_pos": 157, "type": "TASK", "confidence": 0.6947356263796488}]}, {"text": "We chose this data set because it allows us to conduct various domain-modelling evaluations.", "labels": [], "entities": []}, {"text": "First, templates for the domains are provided, and the model summaries are annotated with slots from the template, allowing for an intrinsic evaluation of slot induction (Section 5).", "labels": [], "entities": []}, {"text": "Second, it contains multiple domain instances for each of the domains, and each domain instance comes annotated with eight model summaries, allowing for an extrinsic evaluation of our system (Section 6).", "labels": [], "entities": []}, {"text": "We next evaluated our models extrinsically in the setting of extractive, multi-document summarization.", "labels": [], "entities": []}, {"text": "To use the trained DSHMM for extractive summarization, we need a decoding procedure for selecting sentences in the source text to include in the summary.", "labels": [], "entities": [{"text": "DSHMM", "start_pos": 19, "end_pos": 24, "type": "DATASET", "confidence": 0.9656309485435486}, {"text": "extractive summarization", "start_pos": 29, "end_pos": 53, "type": "TASK", "confidence": 0.7013545334339142}]}, {"text": "Inspired by the KLSUM and HI-ERSUM methods of, we develop a criterion based on KullbackLeibler (KL) divergence between distributions estimated from the source text, and those estimated from the summary.", "labels": [], "entities": [{"text": "KLSUM", "start_pos": 16, "end_pos": 21, "type": "DATASET", "confidence": 0.7482458353042603}]}, {"text": "The assumption here is that these distributions should match in a good summary.", "labels": [], "entities": []}, {"text": "We describe two methods to use this criterion: a basic unsupervised method (Section 6.1), and a supervised variant that makes use of indomain summaries to learn the salient slots and events in the domain (Section 6.2).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Slot induction results on the TAC guided  summarization data set. Asterisks (*) indicate  that the model is statistically significantly differ- ent from PROFINDER in terms of F1 at p < 0.05.", "labels": [], "entities": [{"text": "TAC guided  summarization data set", "start_pos": 40, "end_pos": 74, "type": "DATASET", "confidence": 0.6940940082073211}, {"text": "Asterisks", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9693295359611511}, {"text": "F1", "start_pos": 185, "end_pos": 187, "type": "METRIC", "confidence": 0.9991255402565002}]}, {"text": " Table 3: TAC 2010 summarization results by three settings of ROUGE. Asterisks (*) indicate that the  model is statistically significantly better than the HMM model without semantics at a 95% confidence  interval, a caret\u00eendicatescaret\u00eendicates that the value is marginally so.", "labels": [], "entities": [{"text": "TAC 2010", "start_pos": 10, "end_pos": 18, "type": "DATASET", "confidence": 0.7090871334075928}, {"text": "ROUGE", "start_pos": 62, "end_pos": 67, "type": "METRIC", "confidence": 0.9309511184692383}]}]}