{"title": [{"text": "Fast and Robust Compressive Summarization with Dual Decomposition and Multi-Task Learning", "labels": [], "entities": [{"text": "Compressive Summarization", "start_pos": 16, "end_pos": 41, "type": "TASK", "confidence": 0.47400258481502533}]}], "abstractContent": [{"text": "We present a dual decomposition framework for multi-document summarization, using a model that jointly extracts and compresses sentences.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 46, "end_pos": 74, "type": "TASK", "confidence": 0.6133500039577484}]}, {"text": "Compared with previous work based on integer linear programming , our approach does not require external solvers, is significantly faster, and is modular in the three qualities a summary should have: conciseness, informa-tiveness, and grammaticality.", "labels": [], "entities": []}, {"text": "In addition, we propose a multi-task learning framework to take advantage of existing data for extractive summarization and sentence compression.", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 95, "end_pos": 119, "type": "TASK", "confidence": 0.5481400489807129}, {"text": "sentence compression", "start_pos": 124, "end_pos": 144, "type": "TASK", "confidence": 0.7528496384620667}]}, {"text": "Experiments in the TAC-2008 dataset yield the highest published ROUGE scores to date, with runtimes that rival those of extractive summarizers.", "labels": [], "entities": [{"text": "TAC-2008 dataset", "start_pos": 19, "end_pos": 35, "type": "DATASET", "confidence": 0.9703622162342072}, {"text": "ROUGE", "start_pos": 64, "end_pos": 69, "type": "METRIC", "confidence": 0.9641056656837463}]}], "introductionContent": [{"text": "Automatic text summarization is a seminal problem in information retrieval and natural language processing).", "labels": [], "entities": [{"text": "Automatic text summarization", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7113971809546152}, {"text": "information retrieval", "start_pos": 53, "end_pos": 74, "type": "TASK", "confidence": 0.7760253846645355}, {"text": "natural language processing", "start_pos": 79, "end_pos": 106, "type": "TASK", "confidence": 0.667283813158671}]}, {"text": "Today, with the overwhelming amount of information available on the Web, the demand for fast, robust, and scalable summarization systems is stronger than ever.", "labels": [], "entities": [{"text": "summarization", "start_pos": 115, "end_pos": 128, "type": "TASK", "confidence": 0.9393768310546875}]}, {"text": "Up to now, extractive systems have been the most popular in multi-document summarization.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 60, "end_pos": 88, "type": "TASK", "confidence": 0.6271918714046478}]}, {"text": "These systems produce a summary by extracting a representative set of sentences from the original documents (.", "labels": [], "entities": []}, {"text": "This approach has obvious advantages: it reduces the search space by letting decisions be made for each sentence as a whole (avoiding finegrained text generation), and it ensures a grammatical summary, assuming the original sentences are well-formed.", "labels": [], "entities": [{"text": "finegrained text generation", "start_pos": 134, "end_pos": 161, "type": "TASK", "confidence": 0.7147342960039774}]}, {"text": "The typical trade-offs in these models (maximizing relevance, and penalizing redundancy) lead to submodular optimization problems (, which are NP-hard but approximable through greedy algorithms; learning is possible with standard structured prediction algorithms (.", "labels": [], "entities": []}, {"text": "Probabilistic models have also been proposed to capture the problem structure, such as determinantal point processes ().", "labels": [], "entities": []}, {"text": "However, extractive systems are rather limited in the summaries they can produce.", "labels": [], "entities": []}, {"text": "Long, partly relevant sentences tend not to appear in the summary, or to block the inclusion of other sentences.", "labels": [], "entities": []}, {"text": "This has motivated research in compressive summarization), where summaries are formed by compressed sentences, not necessarily extracts.", "labels": [], "entities": [{"text": "compressive summarization", "start_pos": 31, "end_pos": 56, "type": "TASK", "confidence": 0.6464623510837555}]}, {"text": "While promising results have been achieved by models that simultaneously extract and compress, there are still obstacles that need to be surmounted for these systems to enjoy wide adoption.", "labels": [], "entities": []}, {"text": "All approaches above are based on integer linear programming (ILP), suffering from slow runtimes, when compared to extractive systems.", "labels": [], "entities": []}, {"text": "For example, report 55 seconds on average to produce a summary; report substantially faster runtimes, but fewer compressions are allowed.", "labels": [], "entities": []}, {"text": "Having a compressive summarizer which is both fast and expressive remains an open problem.", "labels": [], "entities": []}, {"text": "A second inconvenience of ILP-based approaches is that they do not exploit the modularity of the problem, since the declarative specification required by ILP solvers discards important structural information.", "labels": [], "entities": [{"text": "ILP solvers discards important structural information", "start_pos": 154, "end_pos": 207, "type": "TASK", "confidence": 0.8112250566482544}]}, {"text": "For example, such solvers are unable to take advantage of efficient dynamic programming routines for sentence compression).", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 101, "end_pos": 121, "type": "TASK", "confidence": 0.7664569020271301}]}, {"text": "This paper makes progress in two fronts: \u2022 We derive a dual decomposition framework for extractive and compressive summarization ( \u00a72-3).", "labels": [], "entities": [{"text": "summarization", "start_pos": 115, "end_pos": 128, "type": "TASK", "confidence": 0.759032666683197}]}, {"text": "Not only is this framework orders of magnitude more efficient than the ILP-based approaches, it also allows the three well-known metrics of summaries-conciseness, informativeness, and grammaticality-to be treated separately in a modular fashion (see).", "labels": [], "entities": []}, {"text": "We also contribute with a novel knapsack factor, along with a linear-time algorithm for the corresponding dual decomposition subproblem.", "labels": [], "entities": []}, {"text": "\u2022 We propose multi-task learning ( \u00a74) as a principled way to train compressive summarizers, using auxiliary data for extractive summarization and sentence compression.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 147, "end_pos": 167, "type": "TASK", "confidence": 0.7155058681964874}]}, {"text": "To this end, we adapt the framework of to train structured predictors that share some of their parts.", "labels": [], "entities": []}, {"text": "Experiments on TAC data ( \u00a75) yield state-of-theart results, with runtimes similar to that of extractive systems.", "labels": [], "entities": [{"text": "TAC data", "start_pos": 15, "end_pos": 23, "type": "DATASET", "confidence": 0.7788218557834625}]}, {"text": "To our best knowledge, this had never been achieved by compressive summarizers.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our compressive summarizers on data from the Text Analysis Conference (TAC) evaluations.", "labels": [], "entities": [{"text": "Text Analysis Conference (TAC)", "start_pos": 58, "end_pos": 88, "type": "TASK", "confidence": 0.7600169032812119}]}, {"text": "We use the same splits as previous work: the non-update portions of TAC-2009 for training and TAC-2008 for testing.", "labels": [], "entities": [{"text": "TAC-2009", "start_pos": 68, "end_pos": 76, "type": "DATASET", "confidence": 0.926581084728241}, {"text": "TAC-2008", "start_pos": 94, "end_pos": 102, "type": "DATASET", "confidence": 0.8718532919883728}]}, {"text": "In addition, we reserved TAC-2010 as a devset.", "labels": [], "entities": [{"text": "TAC-2010", "start_pos": 25, "end_pos": 33, "type": "DATASET", "confidence": 0.8429537415504456}]}, {"text": "The test partition contains 48 multi-document summarization problems; each provides 10 related news articles as input, and asks fora summary with up to 100 words, which is evaluated against four manually written abstracts.", "labels": [], "entities": []}, {"text": "We ignored all the query information present in the TAC datasets.", "labels": [], "entities": [{"text": "TAC datasets", "start_pos": 52, "end_pos": 64, "type": "DATASET", "confidence": 0.9300124049186707}]}, {"text": "In the single-task experiments, we trained a compressive summarizer on the dataset disclosed by, which contains manual compressive summaries for the TAC-2009 data.", "labels": [], "entities": [{"text": "TAC-2009 data", "start_pos": 149, "end_pos": 162, "type": "DATASET", "confidence": 0.9552684128284454}]}, {"text": "We trained a structured SVM with stochastic subgradient descent; the cost-augmented inference problems are relaxed and solved with AD 3 , as described in \u00a73.3. 8 We followed the procedure described in to reduce the number of candidate sentences: scores were defined for each sentence (the sum of the scores of the concepts they cover), and the best-scored sentences were greedily selected up to a limit of 1,000 words.", "labels": [], "entities": []}, {"text": "We then tagged and parsed the selected sentences with TurboParser.", "labels": [], "entities": []}, {"text": "Our choice of a dependency parser was motivated by our will fora fast system; in particular, TurboParser attains top accuracies at a rate of 1,200 words per second, keeping parsing times below 1 second for each summarization problem.", "labels": [], "entities": []}, {"text": "For the multi-task experiments, we also used the dataset of, but we augmented the training data with extractive summarization and sentence compression datasets, to help train the We use the AD 3 implementation in http://www.", "labels": [], "entities": []}, {"text": "ark.cs.cmu.edu/AD3, setting the maximum number of iterations to 200 at training time and 1000 attest time.", "labels": [], "entities": [{"text": "ark.cs.cmu.edu/AD3", "start_pos": 0, "end_pos": 18, "type": "DATASET", "confidence": 0.6674052278200785}]}, {"text": "We extended the code to handle the knapsack and budget factors; the modified code will be part of the next release (AD 3 2.1).", "labels": [], "entities": [{"text": "AD 3 2.1", "start_pos": 116, "end_pos": 124, "type": "DATASET", "confidence": 0.9172961115837097}]}, {"text": "9 http://www.ark.cs.cmu.edu/TurboParser compressive summarizer.", "labels": [], "entities": [{"text": "TurboParser compressive summarizer", "start_pos": 28, "end_pos": 62, "type": "TASK", "confidence": 0.6050019065539042}]}, {"text": "For extractive summarization, we used the DUC 2003 and 2004 datasets (a total of 80 multi-document summarization problems).", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.7183930575847626}, {"text": "DUC 2003 and 2004 datasets", "start_pos": 42, "end_pos": 68, "type": "DATASET", "confidence": 0.9590983986854553}]}, {"text": "We generated oracle extracts by maximizing bigram recall with respect to the manual abstracts, as described in.", "labels": [], "entities": [{"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.8783136010169983}]}, {"text": "For sentence compression, we adapted the Simple English Wikipedia dataset of Woodsend and Lapata (2011), containing aligned sentences for 15,000 articles from the English and Simple English Wikipedias.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.8299912810325623}, {"text": "Simple English Wikipedia dataset of Woodsend and Lapata (2011)", "start_pos": 41, "end_pos": 103, "type": "DATASET", "confidence": 0.921932420947335}, {"text": "Simple English Wikipedias", "start_pos": 175, "end_pos": 200, "type": "DATASET", "confidence": 0.8114244143168131}]}, {"text": "We kept only the 4,481 sentence pairs corresponding to deletionbased compressions.", "labels": [], "entities": []}, {"text": "The top rows refer to three strong baselines: the ICSI-1 extractive coverage-based system of Gillick et al. and our compressive summarizer trained as a single task, and in the multi-task setting.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results for compressive summarization.  Shown are the ROUGE-2 and ROUGE SU-4 re- calls with the default options from the ROUGE  toolkit (Lin, 2004); Pyramid scores (Nenkova and  Passonneau, 2004); and linguistic quality scores,  scored between 1 (very bad) to 5 (very good). For  Pyramid, the evaluation was performed by two  annotators, each evaluating half of the problems;  scores marked with  \u2020 were computed by different  annotators and are not directly comparable. Lin- guistic quality was evaluated by two linguists; we  show the average of the reported scores.", "labels": [], "entities": [{"text": "compressive summarization", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.5918682962656021}]}, {"text": " Table 3: Runtimes of several decoders on a Intel  Core i7 processor @2.8 GHz, with 8GB RAM. For  each decoder, we show the average time taken to  solve a summarization problem in TAC-2008. The  reported runtimes of AD 3 and LP-Relax include  the time taken to round the solution ( \u00a73.4), which  is 0.029 seconds on average.", "labels": [], "entities": [{"text": "TAC-2008", "start_pos": 180, "end_pos": 188, "type": "DATASET", "confidence": 0.9044728875160217}]}]}