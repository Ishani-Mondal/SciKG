{"title": [{"text": "Joint Inference for Heterogeneous Dependency Parsing", "labels": [], "entities": [{"text": "Parsing", "start_pos": 45, "end_pos": 52, "type": "TASK", "confidence": 0.804533064365387}]}], "abstractContent": [{"text": "This paper is concerned with the problem of heterogeneous dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.7326485216617584}]}, {"text": "In this paper, we present a novel joint inference scheme, which is able to leverage the consensus information between heterogeneous treebanks in the parsing phase.", "labels": [], "entities": [{"text": "parsing", "start_pos": 149, "end_pos": 156, "type": "TASK", "confidence": 0.9658783674240112}]}, {"text": "Different from stacked learning methods (Nivre and McDonald, 2008; Martins et al., 2008), which process the dependency parsing in a pipelined way (e.g., a second level uses the first level outputs), in our method, multiple dependency parsing models are coordinated to exchange consensus information.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.7093953937292099}, {"text": "dependency parsing", "start_pos": 223, "end_pos": 241, "type": "TASK", "confidence": 0.7198008894920349}]}, {"text": "We conduct experiments on Chinese Dependency Treebank (CDT) and Penn Chinese Treebank (CTB), experimental results show that joint inference can bring significant improvements to all state-of-the-art dependency parsers.", "labels": [], "entities": [{"text": "Chinese Dependency Treebank (CDT)", "start_pos": 26, "end_pos": 59, "type": "DATASET", "confidence": 0.900706926981608}, {"text": "Penn Chinese Treebank (CTB)", "start_pos": 64, "end_pos": 91, "type": "DATASET", "confidence": 0.9682751397291819}]}], "introductionContent": [{"text": "Dependency parsing is the task of building dependency links between words in a sentence, which has recently gained a wide interest in the natural language processing community and has been used for many problems ranging from machine translation () to question answering ().", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8485357463359833}, {"text": "machine translation", "start_pos": 225, "end_pos": 244, "type": "TASK", "confidence": 0.7945579886436462}, {"text": "question answering", "start_pos": 251, "end_pos": 269, "type": "TASK", "confidence": 0.8707726299762726}]}, {"text": "Over the past few years, supervised learning methods have obtained state-of-the-art performance for dependency parsing (;).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 100, "end_pos": 118, "type": "TASK", "confidence": 0.8918389976024628}]}, {"text": "These methods usually rely heavily on the manually annotated treebanks for training the dependency models.", "labels": [], "entities": []}, {"text": "However, annotating syntac-: Different grammar formalisms of syntactic structures between CTB (upper) and CDT (below).", "labels": [], "entities": []}, {"text": "CTB is converted into dependency grammar based on the head rules of).", "labels": [], "entities": [{"text": "CTB", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.747631311416626}]}, {"text": "tic structure, either phrase-based or dependencybased, is both time consuming and labor intensive.", "labels": [], "entities": [{"text": "tic structure", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8606759905815125}]}, {"text": "Making full use of the existing manually annotated treebanks would yield substantial savings in dataannotation costs.", "labels": [], "entities": []}, {"text": "In this paper, we present a joint inference scheme for heterogenous dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.7079178392887115}]}, {"text": "This scheme is able to leverage consensus information between heterogenous treebanks during the inference phase instead of using individual output in a pipelined way, such as stacked learning methods.", "labels": [], "entities": []}, {"text": "The basic idea is very simple: although heterogenous treebanks have different grammar formalisms, they share some consensus information in dependency structures for the same sentence.", "labels": [], "entities": []}, {"text": "For example in, the dependency structures actually share some partial agreements for the same sentence, the two words \"eyes\" and \"Hongkong\" depend on \"cast\" in both Chinese Dependency Treebank (CDT) () and Penn Chinese Treebank (CTB) ().", "labels": [], "entities": [{"text": "Chinese Dependency Treebank (CDT)", "start_pos": 165, "end_pos": 198, "type": "DATASET", "confidence": 0.8843294481436411}, {"text": "Penn Chinese Treebank (CTB)", "start_pos": 206, "end_pos": 233, "type": "DATASET", "confidence": 0.9657575587431589}]}, {"text": "Therefore, we would like to train the dependency parsers on individual heterogenous treebank and jointly parse the same sentences with consensus information exchanged between them.", "labels": [], "entities": [{"text": "dependency parsers", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.6977072507143021}]}, {"text": "The remainder of this paper is divided as fol- lows.", "labels": [], "entities": [{"text": "fol- lows", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9012760718663534}]}, {"text": "Section 2 gives a formal description of the joint inference for heterogeneous dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 78, "end_pos": 96, "type": "TASK", "confidence": 0.6632423549890518}]}, {"text": "In section 3, we present the experimental results.", "labels": [], "entities": []}, {"text": "Finally, we conclude with ideas for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe the experiments to evaluate our proposed approach by using CTB4 () and CDT ().", "labels": [], "entities": []}, {"text": "For the former, we adopt a set of headselection rules to convert the phrase structure syntax of treebank into a dependency tree representation.", "labels": [], "entities": []}, {"text": "The standard data split of CTB4 from is used.", "labels": [], "entities": [{"text": "CTB4", "start_pos": 27, "end_pos": 31, "type": "DATASET", "confidence": 0.9762352705001831}]}, {"text": "For the latter, we randomly select 2,000 sentences for test set, another 2,000 sentences for development set, and others for training set.", "labels": [], "entities": []}, {"text": "We use two baseline parsers, one trained on CTB4, and another trained on CDT in the experiments.", "labels": [], "entities": [{"text": "CTB4", "start_pos": 44, "end_pos": 48, "type": "DATASET", "confidence": 0.9226769804954529}]}, {"text": "We choose the n-best size of 16 and the best iteration time of four on the development set since these settings empirically give the best performance.", "labels": [], "entities": []}, {"text": "CTB4 and CDT use two different POS tag sets and transforming from one tag set to another is difficult ().", "labels": [], "entities": [{"text": "CTB4", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9745998382568359}, {"text": "CDT", "start_pos": 9, "end_pos": 12, "type": "DATASET", "confidence": 0.9161683917045593}]}, {"text": "To overcome this problem, we use Stanford POS Tagger 1 to train a universal POS tagger on the People's Daily corpus, 2 a large-scale Chinese corpus (approximately 300 thousand sentences and 7 million words) annotated with word segmentation and POS tags.", "labels": [], "entities": [{"text": "People's Daily corpus", "start_pos": 94, "end_pos": 115, "type": "DATASET", "confidence": 0.919478565454483}, {"text": "word segmentation", "start_pos": 222, "end_pos": 239, "type": "TASK", "confidence": 0.6929845660924911}]}, {"text": "Then the POS tagger produces a universal layer of POS tags for both the CTB4 and CDT.", "labels": [], "entities": [{"text": "CTB4", "start_pos": 72, "end_pos": 76, "type": "DATASET", "confidence": 0.9402028322219849}, {"text": "CDT", "start_pos": 81, "end_pos": 84, "type": "DATASET", "confidence": 0.5652690529823303}]}, {"text": "Note that the word segmentation standards of these corpora (CTB4, CDT and People's Daily) slightly differs; however, we do not consider this problem and leave it for future research.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.6535860896110535}, {"text": "CTB4", "start_pos": 60, "end_pos": 64, "type": "DATASET", "confidence": 0.9367942214012146}, {"text": "People's Daily", "start_pos": 74, "end_pos": 88, "type": "DATASET", "confidence": 0.8089052438735962}]}, {"text": "The performance of the parsers is evaluated using the following metrics: UAS, DA, and CM, which are defined by).", "labels": [], "entities": [{"text": "UAS", "start_pos": 73, "end_pos": 76, "type": "METRIC", "confidence": 0.9086227416992188}, {"text": "DA", "start_pos": 78, "end_pos": 80, "type": "METRIC", "confidence": 0.8915295004844666}]}, {"text": "All the metrics except CM are calculated as mean scores per word, and punctuation tokens are consistently excluded.", "labels": [], "entities": []}, {"text": "We conduct experiments incrementally to evaluate the joint features used in our first-order and second-order parsers.", "labels": [], "entities": []}, {"text": "Type D = discriminative dependency parsers without using any external resources; C = combined parsers (stacked and ensemble parsers); H = discriminative dependency parsers using external resources derived from heterogeneous treebanks, S = discriminative dependency parsers using external unlabeled data.", "labels": [], "entities": []}, {"text": "\u2020 The results on CTB4 were not directly reported in these papers, we implemented the experiments in this paper.", "labels": [], "entities": [{"text": "CTB4", "start_pos": 17, "end_pos": 21, "type": "DATASET", "confidence": 0.8022840023040771}]}, {"text": "(dep1) only incorporates head-modifier dependency part).", "labels": [], "entities": []}, {"text": "The secondorder parser (dep2) uses the head-modifier and sibling dependency parts (), as well as the grandparent dependency part.", "labels": [], "entities": []}, {"text": "As shown in, we note that adding more joint inference features incrementally, the dependency parsing performance is improved consistently, for both treebanks (CTB4 or CDT).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 82, "end_pos": 100, "type": "TASK", "confidence": 0.76801797747612}]}, {"text": "As a final note, all comparisons between joint models and baseline models in are statistically significant.", "labels": [], "entities": []}, {"text": "Furthermore, we also present a baseline method called \"CTB4 + CDT\" for comparison.", "labels": [], "entities": [{"text": "CTB4 + CDT", "start_pos": 55, "end_pos": 65, "type": "DATASET", "confidence": 0.7491208712259928}]}, {"text": "This method first tags both CTB4 and CDT with the universal POS tagger trained on the People's Daily corpus, then simply concatenates the two corpora and trains a dependency parser, and finally tests on CTB4 and CDT using this single model.", "labels": [], "entities": [{"text": "People's Daily corpus", "start_pos": 86, "end_pos": 107, "type": "DATASET", "confidence": 0.9344398975372314}]}, {"text": "The comparisons in tell us that very limited information is obtained without consensus features by simply taking a union of the dependencies and their contexts from the two treebanks.", "labels": [], "entities": []}, {"text": "To put our results in perspective, we also compare our second-order joint parser with other bestperforming systems.", "labels": [], "entities": []}, {"text": "\"\u2264 40\" refers to the sentence with the length up to 40 and \"Full\" refers to all the sentences in test set.", "labels": [], "entities": []}, {"text": "The results are shown in, our approach significantly outperforms many systems evaluated on this data set. and reported a very high accuracy using subtree-based features and dependency language model based features derived from large-scale data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9992231130599976}]}, {"text": "Our systems did not use such knowledge.", "labels": [], "entities": []}, {"text": "Moreover, their technique is orthogonal to ours, and we suspect that combining their subtree-based features into our systems might get an even better performance.", "labels": [], "entities": []}, {"text": "We do not present the comparison of our proposed approach   with the state-of-the-art methods on CDT because there is little work conducted on this treebank.", "labels": [], "entities": []}, {"text": "Some researchers conducted experiments on CTB5 with a different data split: files 1-815 and files 1,001-1,136 for training, files 886-931 and 1,148-1,151 for development, files 816-885 and files 1,137-1,147 for testing.", "labels": [], "entities": [{"text": "CTB5", "start_pos": 42, "end_pos": 46, "type": "DATASET", "confidence": 0.917091429233551}]}, {"text": "The development and testing sets were also performed using goldstandard assigned POS tags.", "labels": [], "entities": []}, {"text": "We report the experimental results on CTB5 test set in.", "labels": [], "entities": [{"text": "CTB5 test set", "start_pos": 38, "end_pos": 51, "type": "DATASET", "confidence": 0.9627591967582703}]}, {"text": "Our results are better than most systems on this data split, except Zhang and Nivre (2011),  and.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Dependency parsing results on the test set with different joint inference features. Abbreviations:  dep1/dep2 = first-order parser and second-order parser; baseline = dep1 without considering any joint  inference features; +* = the baseline features conjoined with the joint inference features derived from the  heterogeneous treebanks; CTB4 + CDT = we simply concatenate the two corpora and train a dependency  parser, and then test on CTB4 and CDT using this single model. Improvements of joint models over  baseline models are shown in parentheses.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.8446597456932068}, {"text": "CTB4", "start_pos": 447, "end_pos": 451, "type": "DATASET", "confidence": 0.9476694464683533}]}, {"text": " Table 2: Comparison of different approach on  CTB4 test set using UAS metric. MaltParser =  Hall et al. (2006); MST M alt =Nivre and McDon-", "labels": [], "entities": [{"text": "CTB4 test set", "start_pos": 47, "end_pos": 60, "type": "DATASET", "confidence": 0.9673477212587992}]}, {"text": " Table 3: Comparison of different approaches on  CTB5 test set. Abbreviations D, C, H and S are as  in Table 2.", "labels": [], "entities": [{"text": "CTB5 test set", "start_pos": 49, "end_pos": 62, "type": "DATASET", "confidence": 0.9774542848269144}, {"text": "Abbreviations", "start_pos": 64, "end_pos": 77, "type": "METRIC", "confidence": 0.9933690428733826}]}, {"text": " Table 4: Statistics on joint inference output on  CTB4 and CDT development set.", "labels": [], "entities": [{"text": "CTB4 and CDT development set", "start_pos": 51, "end_pos": 79, "type": "DATASET", "confidence": 0.7894856929779053}]}]}