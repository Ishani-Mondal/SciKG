{"title": [{"text": "Addressing Ambiguity in Unsupervised Part-of-Speech Induction with Substitute Vectors", "labels": [], "entities": [{"text": "Addressing Ambiguity in Unsupervised Part-of-Speech Induction", "start_pos": 0, "end_pos": 61, "type": "TASK", "confidence": 0.6915044089158376}]}], "abstractContent": [{"text": "We study substitute vectors to solve the part-of-speech ambiguity problem in an unsupervised setting.", "labels": [], "entities": []}, {"text": "Part-of-speech tagging is a crucial preliminary process in many natural language processing applications.", "labels": [], "entities": [{"text": "Part-of-speech tagging", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7966719269752502}]}, {"text": "Because many words in natural languages have more than one part-of-speech tag, resolving part-of-speech ambiguity is an important task.", "labels": [], "entities": [{"text": "resolving part-of-speech ambiguity", "start_pos": 79, "end_pos": 113, "type": "TASK", "confidence": 0.7717958291371664}]}, {"text": "We claim that part-of-speech ambiguity can be solved using substitute vectors.", "labels": [], "entities": []}, {"text": "A substitute vector is constructed with possible substitutes of a target word.", "labels": [], "entities": []}, {"text": "This study is built on previous work which has proven that word substitutes are very fruitful for part-of-speech induction.", "labels": [], "entities": [{"text": "part-of-speech induction", "start_pos": 98, "end_pos": 122, "type": "TASK", "confidence": 0.7560414969921112}]}, {"text": "Experiments show that our methodology works for words with high ambiguity.", "labels": [], "entities": []}], "introductionContent": [{"text": "Learning syntactic categories of words (i.e. partof-speech or POS tagging) is an important preprocessing step for many natural language processing applications because grammatical rules are not functions of individual words, instead, they are functions of word categories.", "labels": [], "entities": [{"text": "POS tagging)", "start_pos": 62, "end_pos": 74, "type": "TASK", "confidence": 0.7661150197188059}]}, {"text": "Unlike supervised POS tagging systems, POS induction systems make use of unsupervised methods.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 18, "end_pos": 29, "type": "TASK", "confidence": 0.7852578461170197}]}, {"text": "They categorize the words without any help of annotated data.", "labels": [], "entities": []}, {"text": "POS induction is a popular topic and several studies () have been performed.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8729090988636017}]}, {"text": "Token based methods) categorize word occurrences into syntactic groups.", "labels": [], "entities": []}, {"text": "Type based methods) on the other hand, categorize word types and yield the ambiguity problem unlike the token based methods.", "labels": [], "entities": []}, {"text": "Type based methods suffer from POS ambiguity because one POS tag is assigned to each word type.", "labels": [], "entities": []}, {"text": "However, occurrences of many words may have different POS tags.", "labels": [], "entities": []}, {"text": "Two examples below are drawn from the dataset we worked on.", "labels": [], "entities": []}, {"text": "They illustrate a situation where two occurrences of the \"offers\" have different POS tags.", "labels": [], "entities": []}, {"text": "In the first sentence \"offers\" is a noun, whereas, in the second sentence it is a verb.", "labels": [], "entities": []}, {"text": "(1) \"Two rival bidders for Connaught BioSciences extended their offers to acquire the Toronto-based vaccine manufacturer Friday.\"", "labels": [], "entities": []}, {"text": "(2) \"The company currently offers a word-processing package for personal computers called Legend.\"", "labels": [], "entities": [{"text": "Legend", "start_pos": 90, "end_pos": 96, "type": "DATASET", "confidence": 0.9629570841789246}]}, {"text": "In this study, we try to extend the state-of-theart unsupervised POS tagger ( by solving the ambiguity problem it suffers because it has a type based approach.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 65, "end_pos": 75, "type": "TASK", "confidence": 0.6429400593042374}]}, {"text": "The clustering based studies represent the context of a word with a vector using neighbour words.", "labels": [], "entities": []}, {"text": "Similarly, ( proposes to use word context.", "labels": [], "entities": []}, {"text": "They claim that the substitutes of a word have similar syntactic categories and they are determined by the context of the word.", "labels": [], "entities": []}, {"text": "In addition, we suggest that the occurrences with different part-of-speech categories of a word should be seen in different contexts.", "labels": [], "entities": []}, {"text": "In other words, if we categorize the contexts of a word type we can determine different POS tags of the word.", "labels": [], "entities": []}, {"text": "We represent the context of a word by constructing substitute vectors using possible substitutes of the word as () suggests.", "labels": [], "entities": []}, {"text": "illustrates the substitute vector of the occurrence of \"offers\" in (1).", "labels": [], "entities": []}, {"text": "There is a row for each word in the vocabulary.", "labels": [], "entities": []}, {"text": "For instance, probability of occurring \"agreement\" in the position of \"offers\" is 80% in this context.", "labels": [], "entities": []}, {"text": "To resolve ambiguity of a target word, we separate occurrences of the word into different groups depending on the context information represented by substitute vectors.", "labels": [], "entities": []}, {"text": "In the first experiment, for each word type we investigated, we separate all occurences into two categories using substitute vectors.", "labels": [], "entities": []}, {"text": "In the second one we guess the number of the categories we should separate for each word type.", "labels": [], "entities": []}, {"text": "Both experiments achieve better than () for highly ambiguous words.", "labels": [], "entities": []}, {"text": "The level of ambiguity can be measured with perplexity of word's gold tag distribution.", "labels": [], "entities": []}, {"text": "For instance,the gold tag perplexity of word \"offers\" in the Penn Treebank Wall Street Journal corpus we worked on equals to 1.966.", "labels": [], "entities": [{"text": "Penn Treebank Wall Street Journal corpus", "start_pos": 61, "end_pos": 101, "type": "DATASET", "confidence": 0.973733385403951}]}, {"text": "Accordingly, the number of different gold tags of \"offers\" is 2.", "labels": [], "entities": []}, {"text": "Whereas, perplexity of \"board\" equals to 1.019.", "labels": [], "entities": [{"text": "perplexity", "start_pos": 9, "end_pos": 19, "type": "METRIC", "confidence": 0.9901521801948547}]}, {"text": "Although the number of different tags for \"board\" is equal to 2, only a small fraction of the tags of board differs from each other.", "labels": [], "entities": []}, {"text": "We can conclude that \"offers\" is more ambiguous than \"board\".", "labels": [], "entities": []}, {"text": "In this paper we present a method to solve POS ambiguity fora type based POS induction approach.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 73, "end_pos": 86, "type": "TASK", "confidence": 0.7698142230510712}]}, {"text": "For the rest of the paper, we explain our algorithm and the setup of our experiments.", "labels": [], "entities": []}, {"text": "Lastly we present the results and a conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, the setup of each experiment will be presented.", "labels": [], "entities": []}, {"text": "The experiments are conducted on Penn Treebank Wall Street Journal corpus.", "labels": [], "entities": [{"text": "Penn Treebank Wall Street Journal corpus", "start_pos": 33, "end_pos": 73, "type": "DATASET", "confidence": 0.9734059075514475}]}, {"text": "There are 1,173,766 tokens and, 49,206 types.", "labels": [], "entities": []}, {"text": "Out of 49,206 word types, 1183 of them are chosen as target words.", "labels": [], "entities": []}, {"text": "They are fed to the algorithm described above.", "labels": [], "entities": []}, {"text": "Occurrences of these target words correspond to 37.55% of the whole data.", "labels": [], "entities": [{"text": "Occurrences", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9890627264976501}]}, {"text": "These target words are seen in the dataset more than 100 times and less than 4000 times.", "labels": [], "entities": []}, {"text": "This subset is chosen as such because word types occurring more than 4000 times are all with low gold tag perplexity.", "labels": [], "entities": []}, {"text": "They also increase computation time dramatically.", "labels": [], "entities": []}, {"text": "We exclude word types occurring less than 100 times, because the clustering algorithm running on 64-dimension vectors does notwork accurately.", "labels": [], "entities": []}, {"text": "To avoid providing noisy results, the experiments are repeated 10 times.", "labels": [], "entities": []}, {"text": "We report many-toone scores of the experiments.", "labels": [], "entities": []}, {"text": "The many-to-one evaluation assigns each cluster to its most frequent gold-tag.", "labels": [], "entities": []}, {"text": "Overall result demonstrates the percentage of correctly assigned instances and standard deviation in paranthesis.", "labels": [], "entities": []}, {"text": "In the algorithm section, we mention that after dimensionality reduction step, we cluster the vectors to separate tokens of a target word seen in the similar contexts.", "labels": [], "entities": []}, {"text": "In this experiment, we set the number of clusters for each type to 2.", "labels": [], "entities": []}, {"text": "In other words, we assume that the number of different POS tags of each word type is equal to 2.", "labels": [], "entities": []}, {"text": "Nevertheless, separating all the words into 2 clusters results in some inaccuracy in POS induction.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 85, "end_pos": 98, "type": "TASK", "confidence": 0.9155957400798798}]}, {"text": "That is because not all words have POS ambiguity and some have more than 2 different POS tags However, the main purpose of this experiment is to observe whether we can increase the POS induction accuracy for ambiguous types with our approach.", "labels": [], "entities": [{"text": "POS induction accuracy", "start_pos": 181, "end_pos": 203, "type": "METRIC", "confidence": 0.5842362840970358}]}, {"text": "The many-to-one accuracy of this experiment is 63.8%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9930833578109741}]}, {"text": "In the previous experiment, we set the number of clusters for each word type to 2.", "labels": [], "entities": []}, {"text": "However, the number of different POS tags differs for each word type.", "labels": [], "entities": []}, {"text": "More importantly, around 41% of our target tokens belongs to unambiguous word types.", "labels": [], "entities": []}, {"text": "Also, around 36% of our target tokens comes from word types whose gold perplexity is below 1.5.", "labels": [], "entities": [{"text": "gold perplexity", "start_pos": 66, "end_pos": 81, "type": "METRIC", "confidence": 0.9583041965961456}]}, {"text": "That means, the Experiment 1 splits most of our word types that should not be separated.", "labels": [], "entities": []}, {"text": "In this experiment, instead of splitting all types, we guess which types should be splitted.", "labels": [], "entities": []}, {"text": "Also, we guess the number of clusters for each type.", "labels": [], "entities": []}, {"text": "We use gap statistic () on 64-dimensional vectors.", "labels": [], "entities": []}, {"text": "The Gap statistic is a statistical method to guess the number of clusters formed in given data points.", "labels": [], "entities": []}, {"text": "We expect that substitute vectors occurring in the similar context should be closely located in 64-dimensional space.", "labels": [], "entities": []}, {"text": "Thus, gap statistic can provide us the number of groups formed by vectors in 64-dimensional space.", "labels": [], "entities": []}, {"text": "That number is possibly equal to the number of the number of different POS tags of the word types.", "labels": [], "entities": []}, {"text": "The many-to-one accuracy of this experiment is 63.4%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.99305659532547}]}, {"text": "In this experiment, we set the number of clusters for each type to gold number of tags of each type.", "labels": [], "entities": []}, {"text": "The purpose of this experiment is to observe how the accuracy of number of tags given, which is used at step (c), affects the system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9989060163497925}]}, {"text": "The manyto-one accuracy of this experiment is 63.9%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9960758090019226}]}], "tableCaptions": [{"text": " Table 1: Substitute Vector for \"offers\" in above  sentence.", "labels": [], "entities": []}, {"text": " Table 2: Results for the target words correspond- ing to 37.55% of the data.", "labels": [], "entities": []}, {"text": " Table 3: Results for Target Words with gold tag  perplexity \u22641.5 which corresponds to 29.11% of  the data.", "labels": [], "entities": [{"text": "gold tag  perplexity", "start_pos": 40, "end_pos": 60, "type": "METRIC", "confidence": 0.8136911193529764}]}, {"text": " Table 4: Results for Target Words with gold tag  perplexity \u22651.5 which corresponds to 8.44% of  the data..", "labels": [], "entities": []}]}