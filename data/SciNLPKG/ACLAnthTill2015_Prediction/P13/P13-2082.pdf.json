{"title": [{"text": "Leveraging Domain-Independent Information in Semantic Parsing", "labels": [], "entities": []}], "abstractContent": [{"text": "Semantic parsing is a domain-dependent process by nature, as its output is defined over a set of domain symbols.", "labels": [], "entities": [{"text": "Semantic parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8566995859146118}]}, {"text": "Motivated by the observation that interpretation can be decomposed into domain-dependent and independent components, we suggest a novel interpretation model, which augments a domain dependent model with abstract information that can be shared by multiple domains.", "labels": [], "entities": []}, {"text": "Our experiments show that this type of information is useful and can reduce the annotation effort significantly when moving between domains.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural Language (NL) understanding can be intuitively understood as a general capacity, mapping words to entities and their relationships.", "labels": [], "entities": [{"text": "Natural Language (NL) understanding", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6217495948076248}]}, {"text": "However, current work on automated NL understanding (typically referenced as semantic parsing) is restricted to a given output domain 1 (or task) consisting of a closed set of meaning representation symbols, describing domains such as robotic soccer, database queries and flight ordering systems.", "labels": [], "entities": [{"text": "NL understanding", "start_pos": 35, "end_pos": 51, "type": "TASK", "confidence": 0.8216412663459778}, {"text": "semantic parsing)", "start_pos": 77, "end_pos": 94, "type": "TASK", "confidence": 0.8217265407244364}]}, {"text": "In this work, we take a first step towards constructing a semantic interpreter that can leverage information from multiple tasks.", "labels": [], "entities": []}, {"text": "This is not a straightforward objective -the domain specific nature of semantic interpretation, as described in the current literature, does not allow for an easy move between domains.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 71, "end_pos": 94, "type": "TASK", "confidence": 0.8665434122085571}]}, {"text": "For example, a system trained for the task of understanding database queries will not be of any use when it will be given a sentence describing robotic soccer instructions.", "labels": [], "entities": []}, {"text": "In order to understand this difficulty, a closer look at semantic parsing is required.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 57, "end_pos": 73, "type": "TASK", "confidence": 0.7424601316452026}]}, {"text": "Given a sentence, the interpretation process breaks it into a set of interdependent decisions, which rely on an underlying representation mapping words to symbols and syntactic patterns into compositional decisions.", "labels": [], "entities": []}, {"text": "This representation takes into account domain specific information (e.g., a lexicon mapping phrases to a domain predicate) and is therefore of little use when moving to a different domain.", "labels": [], "entities": []}, {"text": "In this work, we attempt to develop a domain independent approach to semantic parsing.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 69, "end_pos": 85, "type": "TASK", "confidence": 0.8263058960437775}]}, {"text": "We do it by developing a layer of representation that is applicable to multiple domains.", "labels": [], "entities": []}, {"text": "Specifically, we add an intermediate layer capturing shallow semantic relations between the input sentence constituents.", "labels": [], "entities": []}, {"text": "Unlike semantic parsing which maps the input to a closed set of symbols, this layer can be used to identify general predicate-argument structures in the input sentence.The following example demonstrates the key idea behind our representationtwo sentences from two different domains have a similar intermediate structure.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 7, "end_pos": 23, "type": "TASK", "confidence": 0.7657361924648285}]}, {"text": "In this case, the constituents of the first sentence (from the Robocup domain), are assigned domainindependent predicate-argument labels (e.g., the word corresponding to a logical function is identified as a P RED).", "labels": [], "entities": [{"text": "Robocup domain", "start_pos": 63, "end_pos": 77, "type": "DATASET", "confidence": 0.9209797382354736}]}, {"text": "Note that it does not use any domain specific information, for example, the P RED label assigned to the word \"kicks\" indicates that this word is the predicate of the sentence, not a specific domain predicate (e.g., pass(\u00b7)).", "labels": [], "entities": [{"text": "P RED label", "start_pos": 76, "end_pos": 87, "type": "METRIC", "confidence": 0.7823063731193542}, {"text": "pass", "start_pos": 215, "end_pos": 219, "type": "METRIC", "confidence": 0.961688756942749}]}, {"text": "The intermediate layer can be reused across domains.", "labels": [], "entities": []}, {"text": "The logical output associated with the second sentence is taken from a different domain, using a different set of output symbols, however it shares the same predicate-argument structure.", "labels": [], "entities": []}, {"text": "Despite the idealized example, in practice, leveraging this information is challenging, as the logical structure is assumed to only weakly correspond to the domain-independent structure, a correspondence which may change in different domains.", "labels": [], "entities": []}, {"text": "The mismatch between the domain independent (linguistic) structure and logical structures typically stems from technical considerations, as the domain logical language is designed according to an application-specific logic and not according to linguistic considerations.", "labels": [], "entities": []}, {"text": "This situation is depicted in the following example, in which one of the domain-independent labels is omitted.", "labels": [], "entities": []}, {"text": "\u2022 In order to overcome this difficulty, we suggest a flexible model that is able to leverage the supervision provided in one domain to learn an abstract intermediate layer, and show empirically that it learns a robust model, improving results significantly in a second domain.", "labels": [], "entities": []}], "datasetContent": [{"text": "Situated Language This dataset, introduced in (, describes situations in a simulated world.", "labels": [], "entities": []}, {"text": "The dataset consists of triplets of the form -(x,u, y), where x is a NL sentence describing a situation (e.g., \"He goes to the kitchen\"), u is a world state consisting of grounded relations (e.g., loc(John, Kitchen)) description, and y is a logical interpretation corresponding to x.", "labels": [], "entities": []}, {"text": "The original dataset was used for concept tagging, which does not include a compositional aspect.", "labels": [], "entities": [{"text": "concept tagging", "start_pos": 34, "end_pos": 49, "type": "TASK", "confidence": 0.729263424873352}]}, {"text": "We automatically generated the full logical structure by mapping the constants to function arguments.", "labels": [], "entities": []}, {"text": "We generated additional function symbols of the same relation, but of different arity when needed 3 . Our new dataset consists of 25 relation symbols (originally 15).", "labels": [], "entities": []}, {"text": "In our experiments we used a set of 5000 of the training triplets.", "labels": [], "entities": []}, {"text": "Robocup The Robocup dataset, originally introduced in, describes robotic soccer events.", "labels": [], "entities": [{"text": "Robocup dataset", "start_pos": 12, "end_pos": 27, "type": "DATASET", "confidence": 0.7618623971939087}]}, {"text": "The dataset was collected for the purpose of constructing semantic parsers from ambiguous supervision and consists of both \"noisy\" and gold labeled data. was constructed by temporally aligning a stream of soccer events occurring during a robotic soccer match with human commentary describing the game.", "labels": [], "entities": []}, {"text": "This dataset consists of pairs (x, {y 0 , y k }), x is a sentence and {y 0 , y k } is a set of events (logical formulas).", "labels": [], "entities": []}, {"text": "One of these events is assumed to correspond to the comment, however this is not guaranteed.", "labels": [], "entities": []}, {"text": "The gold labeled labeled data consists of pairs (x, y).", "labels": [], "entities": []}, {"text": "The data was collected from four Robocup games.", "labels": [], "entities": []}, {"text": "In our experiments we follow other works and use 4-fold cross validation, training over 3 games and testing over the remaining game.", "labels": [], "entities": []}, {"text": "We evaluate the Accuracy of the parser over the test game data.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.999716579914093}]}, {"text": "Due to space considerations, we refer the reader to for further details about this dataset.", "labels": [], "entities": []}, {"text": "Semantic Interpretation Tasks We consider two of the tasks described in (1) Semantic Parsing requires generating the correct logical form given an input sentence.", "labels": [], "entities": [{"text": "Semantic Parsing", "start_pos": 76, "end_pos": 92, "type": "TASK", "confidence": 0.8013450801372528}]}, {"text": "(2) Matching, given a NL sentence and a set of several possible interpretation candidates, the system is required to identify the correct one.", "labels": [], "entities": [{"text": "Matching", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.7905864715576172}]}, {"text": "In all systems, the source for domain-independent information is the Situated domain, and the results are evaluated over the Robocup domain.", "labels": [], "entities": []}, {"text": "Experimental Systems We tested several variations, all solving Eq.", "labels": [], "entities": []}, {"text": "2, however different resources were used to obtain Eq.", "labels": [], "entities": []}, {"text": "2 parameters (see sec. 2.2).", "labels": [], "entities": []}, {"text": "1 describes the different variations.", "labels": [], "entities": []}, {"text": "We used the noisy Robocup dataset to initialize DOM-INIT, a noisy probabilistic model, constructed by taking statistics over the noisy robocup data and computing p(y|x).", "labels": [], "entities": [{"text": "Robocup dataset", "start_pos": 18, "end_pos": 33, "type": "DATASET", "confidence": 0.875616580247879}]}, {"text": "Given the training set {(x, {y 1 , .., y k })}, every word in x is aligned to every symbol in every y that is aligned with it.", "labels": [], "entities": []}, {"text": "The probability of a matching (x, y)is computed as the product: where n is the number of symbols appearing in y, and xi , y i is the word In our model accuracy is equivalent to F-measure.: Results for the matching and parsing tasks.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.9982136487960815}, {"text": "F-measure.", "start_pos": 177, "end_pos": 187, "type": "METRIC", "confidence": 0.9906514883041382}, {"text": "matching and parsing tasks", "start_pos": 205, "end_pos": 231, "type": "TASK", "confidence": 0.6737000420689583}]}, {"text": "Our system performs well on the matching task without any domain information.", "labels": [], "entities": []}, {"text": "Results for both parsing and matching tasks show that using domain-independent information improves results dramatically.", "labels": [], "entities": [{"text": "parsing and matching tasks", "start_pos": 17, "end_pos": 43, "type": "TASK", "confidence": 0.7063236013054848}]}, {"text": "level matching to a logical symbol.", "labels": [], "entities": []}, {"text": "Note that this model uses lexical information only.", "labels": [], "entities": []}, {"text": "We begin by studying the role of domainindependent information when very little domain information is available.", "labels": [], "entities": []}, {"text": "Domain-independent information is learned from the situated domain and domain-specific information (Robocup) available is the simple probabilistic model (DOM-INIT).", "labels": [], "entities": []}, {"text": "This model can be considered as a noisy probabilistic lexicon, without any domain-specific compositional information, which is only available through domain-independent information.", "labels": [], "entities": []}, {"text": "The results, summarized in, show that in both tasks domain-independent information is extremely useful and can makeup for missing domain information.", "labels": [], "entities": []}, {"text": "Most notably, performance for the matching task using only domain independent information (PRED-ARGS) was surprisingly good, with an accuracy of 0.69.", "labels": [], "entities": [{"text": "matching task", "start_pos": 34, "end_pos": 47, "type": "TASK", "confidence": 0.8963298201560974}, {"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.999321460723877}]}, {"text": "Adding domain-specific lexical information (COMBINEDRI+S) pushes this result to over 0.9, currently the highest for this task -achieved without domain specific learning.", "labels": [], "entities": [{"text": "COMBINEDRI+S)", "start_pos": 44, "end_pos": 57, "type": "METRIC", "confidence": 0.9518014937639236}]}, {"text": "The second set of experiments study whether using domain independent information, when relevant (gold) domain-specific training data is available, improves learning.", "labels": [], "entities": []}, {"text": "In this scenario, the domain-independent model is updated according to training data available for the Robocup domain.", "labels": [], "entities": []}, {"text": "We compare two system over varying amounts of training data, the current state-of-the-art for the parsing task over this dataset.", "labels": [], "entities": [{"text": "parsing task", "start_pos": 98, "end_pos": 110, "type": "TASK", "confidence": 0.9029708206653595}]}, {"text": "The system used in) learns from ambiguous training data and achieves this score by using global information.", "labels": [], "entities": []}, {"text": "We hypothesize that it can be used by our model and leave it for future work.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results for the matching and parsing tasks. Our", "labels": [], "entities": [{"text": "matching and parsing tasks", "start_pos": 26, "end_pos": 52, "type": "TASK", "confidence": 0.7434114515781403}]}, {"text": " Table 3: Evaluating our model in a learning settings. The", "labels": [], "entities": []}]}