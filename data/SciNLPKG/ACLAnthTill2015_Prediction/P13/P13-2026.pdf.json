{"title": [{"text": "Automated Pyramid Scoring of Summaries using Distributional Semantics", "labels": [], "entities": [{"text": "Automated Pyramid Scoring of Summaries", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.7317585647106171}]}], "abstractContent": [{"text": "The pyramid method for content evaluation of automated summarizers produces scores that are shown to correlate well with manual scores used in educational assessment of students' summaries.", "labels": [], "entities": []}, {"text": "This motivates the development of a more accurate automated method to compute pyramid scores.", "labels": [], "entities": []}, {"text": "Of three methods tested here, the one that performs best relies on latent semantics.", "labels": [], "entities": []}], "introductionContent": [{"text": "The pyramid method is an annotation and scoring procedure to assess semantic content of summaries in which the content units emerge from the annotation.", "labels": [], "entities": []}, {"text": "Each content unit is weighted by its frequency inhuman reference summaries.", "labels": [], "entities": []}, {"text": "It has been shown to produce reliable rankings of automated summarization systems, based on performance across multiple summarization tasks (.", "labels": [], "entities": [{"text": "summarization", "start_pos": 60, "end_pos": 73, "type": "TASK", "confidence": 0.9254547953605652}]}, {"text": "It has also been applied to assessment of oral narrative skills of children ().", "labels": [], "entities": [{"text": "assessment of oral narrative skills", "start_pos": 28, "end_pos": 63, "type": "TASK", "confidence": 0.6831153988838196}]}, {"text": "Here we show its potential for assessment of the reading comprehension of community college students.", "labels": [], "entities": []}, {"text": "We then present a method to automate pyramid scores based on latent semantics.", "labels": [], "entities": []}, {"text": "The pyramid method depends on two phases of manual annotation, one to identify weighted content units in model summaries written by proficient humans, and one to score target summaries against the models.", "labels": [], "entities": []}, {"text": "The first annotation phase yields Summary Content Units (SCUs), sets of text fragments that express the same basic content.", "labels": [], "entities": []}, {"text": "Each SCU is weighted by the number of model summaries it occurs in. illustrates a Summary Content Unit taken from pyramid annotation of five model summaries of an elementary physics text.", "labels": [], "entities": []}, {"text": "The elements of an SCU are its index; a label, created by the annotator; contributors (Ctr.), or text fragments from the model summaries; and the weight (Wt.), corresponding to the number of contributors from distinct model summaries.", "labels": [], "entities": [{"text": "weight (Wt.)", "start_pos": 146, "end_pos": 158, "type": "METRIC", "confidence": 0.8947671502828598}]}], "datasetContent": [{"text": "The three similarity computations, three methods to compare against SCUs, and five icdf thresholds yield 45 variants, as shown in.", "labels": [], "entities": []}, {"text": "Each variant was evaluated by comparing the unnormalized automated variant, e.g., Lvc, max, 0.64 (its 0.15 icdf) to the human gold scores, using each of the evaluation metrics described in the next subsection.", "labels": [], "entities": []}, {"text": "To compute confidence intervals for the evaluation metrics for each variant, we use bootstrapping with 1000 samples.", "labels": [], "entities": []}, {"text": "To assess the 45 variants, we compared their scores to the manual scores.", "labels": [], "entities": []}, {"text": "We also compared the sets of SCUs retrieved.", "labels": [], "entities": []}, {"text": "By our criterion 1), an automated score that correlates well with manual scores for summaries of a given text could be used  to indicate how well students rank against other students.", "labels": [], "entities": []}, {"text": "We report several types of correlation tests.", "labels": [], "entities": [{"text": "correlation", "start_pos": 27, "end_pos": 38, "type": "METRIC", "confidence": 0.9388077855110168}]}, {"text": "Pearsons tests the strength of a linear correlation between the two sets of scores; it will be high if the same order is produced, with the same distance between pairs of scores.", "labels": [], "entities": []}, {"text": "The Spearman rank correlation is said to be preferable for ordinal comparisons, meaning where the unit interval is less relevant.", "labels": [], "entities": [{"text": "Spearman rank correlation", "start_pos": 4, "end_pos": 29, "type": "METRIC", "confidence": 0.6467168132464091}]}, {"text": "Kendall's tau, an alternative rank correlation, is less sensitive to outliers and more intuitive.", "labels": [], "entities": []}, {"text": "It is the proportion of concordant pairs (pairs in the same order) less the proportion of discordant pairs.", "labels": [], "entities": []}, {"text": "Since correlations can be high when differences are uniform, we use Student's T to test whether differences score means statistically significant.", "labels": [], "entities": [{"text": "Student's T", "start_pos": 68, "end_pos": 79, "type": "METRIC", "confidence": 0.7290945847829183}]}, {"text": "Criterion 2) is met if the correlations are high and the means are not significantly different.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Five variants from the top twelve of all correlations, with confidence interval and rank (P=Pearson's, S=Spearman,", "labels": [], "entities": [{"text": "confidence interval", "start_pos": 70, "end_pos": 89, "type": "METRIC", "confidence": 0.926235556602478}]}]}