{"title": [{"text": "HEADY: News headline abstraction through event pattern clustering", "labels": [], "entities": [{"text": "News headline abstraction", "start_pos": 7, "end_pos": 32, "type": "TASK", "confidence": 0.6478044390678406}, {"text": "event pattern clustering", "start_pos": 41, "end_pos": 65, "type": "TASK", "confidence": 0.658454050620397}]}], "abstractContent": [{"text": "This paper presents HEADY: a novel, ab-stractive approach for headline generation from news collections.", "labels": [], "entities": [{"text": "headline generation from news collections", "start_pos": 62, "end_pos": 103, "type": "TASK", "confidence": 0.8799926042556763}]}, {"text": "From a web-scale corpus of English news, we mine syntactic patterns that a Noisy-OR model generalizes into event descriptions.", "labels": [], "entities": []}, {"text": "At inference time, we query the model with the patterns observed in an unseen news collection, identify the event that better captures the gist of the collection and retrieve the most appropriate pattern to generate a headline.", "labels": [], "entities": []}, {"text": "HEADY improves over a state-of-the-art open-domain title abstraction method, bridging half of the gap that separates it from extractive methods using human-generated titles in manual evaluations, and performs comparably to human-generated headlines as evaluated with ROUGE.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 267, "end_pos": 272, "type": "METRIC", "confidence": 0.8913167715072632}]}], "introductionContent": [{"text": "News events are rarely reported only in one way, from a single point of view.", "labels": [], "entities": []}, {"text": "Different news agencies will interpret the event in different ways; various countries or locations may highlight different aspects of it depending on how they are affected; and opinions and in-depth analyses will be written after the fact.", "labels": [], "entities": []}, {"text": "The variety of contents and styles is both an opportunity and a challenge.", "labels": [], "entities": []}, {"text": "On the positive side, we have the same events described in different ways; this redundancy is useful for summarization, as the information content reported by the majority of news sources most likely represents the central part of the event.", "labels": [], "entities": [{"text": "summarization", "start_pos": 105, "end_pos": 118, "type": "TASK", "confidence": 0.9930474162101746}]}, {"text": "On the other hand, variability and subjectivity can be difficult to isolate.", "labels": [], "entities": []}, {"text": "For some applications it is important to understand, given a collection of related news articles and re- * Work done during an internship at Google Zurich.", "labels": [], "entities": []}, {"text": "\u2022 \u2022 Lala Vasquez on her wedding dress, cake, reality tv show and fianc\u00e9, Carmelo Anthony (video) \u2022 VAZQUEZ MARRIES SPORTS STAR AN-THONY \u2022 Lebron Returns To NYC For Carmelo's Wedding \u2022 Carmelo Anthony's stylist dishes on the wedding \u2022 Paul pitching another Big Three with \"Melo in NYC\" \u2022 Carmelo Anthony and La La Vazquez Get Married at Star-Studded Wedding Ceremony: Headlines observed fora news collection reporting the same wedding event.", "labels": [], "entities": [{"text": "VAZQUEZ MARRIES SPORTS STAR AN-THONY", "start_pos": 99, "end_pos": 135, "type": "METRIC", "confidence": 0.7562352538108825}]}, {"text": "ports, how to formulate in an objective way what has happened.", "labels": [], "entities": []}, {"text": "As a motivating example, shows the different headlines observed in news reporting the wedding between basketball player Carmelo Anthony and actress LaLa Vazquez.", "labels": [], "entities": []}, {"text": "As can be seen, there is a wide variety of ways to report the same event, including different points of view, highlighted aspects, and opinionated statements on the part of the reporter.", "labels": [], "entities": []}, {"text": "When presenting this event to a user in a news-based information retrieval or recommendation system, different event descriptions maybe more appropriate.", "labels": [], "entities": []}, {"text": "For example, a user may only be interested in objective, informative summaries without any interpretation on the part of the reporter.", "labels": [], "entities": []}, {"text": "In this case, Carmelo Anthony, ac-tress LaLa Vazquez wed in NYC would be a good choice.", "labels": [], "entities": []}, {"text": "Our final goal in this research is to build a headline generation system that, given a news collection, is able to describe it with the most compact, objective and informative headline.", "labels": [], "entities": [{"text": "headline generation", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.797533243894577}]}, {"text": "In particular, we want the system to be able to: \u2022 Generate headlines in an open-domain, unsupervised way, so that it does not need to rely on training data which is expensive to produce.", "labels": [], "entities": [{"text": "Generate headlines", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.8840925991535187}]}, {"text": "\u2022 Generalize across synonymous expressions that refer to the same event.", "labels": [], "entities": []}, {"text": "\u2022 Do so in an abstractive fashion, to enforce novelty, objectivity and generality.", "labels": [], "entities": []}, {"text": "In order to advance towards this goal, this paper explores the following questions: \u2022 What is a good way of using syntactic patterns to represent events for generating headlines?", "labels": [], "entities": []}, {"text": "\u2022 Can we have satisfactory readability with an open-domain abstractive approach, not relying on training data nor on manually predefined generation templates?", "labels": [], "entities": []}, {"text": "\u2022 How far can we get in terms of informativeness, compared to the human-produced headlines, i.e., extractive approaches?", "labels": [], "entities": []}, {"text": "In this paper we present HEADY, which is at the same time a novel system for abstractive headline generation, and a smooth clustering of patterns describing the same events.", "labels": [], "entities": [{"text": "HEADY", "start_pos": 25, "end_pos": 30, "type": "METRIC", "confidence": 0.6989730000495911}, {"text": "abstractive headline generation", "start_pos": 77, "end_pos": 108, "type": "TASK", "confidence": 0.6589896182219187}]}, {"text": "HEADY is fully open-domain and can scale to web-sized data.", "labels": [], "entities": [{"text": "HEADY", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8114046454429626}]}, {"text": "By learning to generalize events across the boundaries of a single news story or news collection, HEADY produces compact and effective headlines that objectively convey the relevant information.", "labels": [], "entities": []}, {"text": "When compared to a state-of-the-art opendomain headline abstraction system, the new headlines are statistically significantly better both in terms of readability and informativeness.", "labels": [], "entities": []}, {"text": "Also, automatic evaluations using ROUGE, having objective headlines for the news as references, show that the abstractive headlines are on par with human-produced headlines.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 34, "end_pos": 39, "type": "METRIC", "confidence": 0.9605638384819031}]}], "datasetContent": [{"text": "In our method we use patterns that are fully lexicalized (with the exception of entity placeholders) and enriched with syntactic data.", "labels": [], "entities": []}, {"text": "Under these circumstances, the Noisy-OR can effectively generalize and learn meaningful clusters only if provided with large amounts of data.", "labels": [], "entities": []}, {"text": "To our best knowledge, available data sets for headline generation are not large enough to support this kind of inference.", "labels": [], "entities": [{"text": "headline generation", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.9269901812076569}]}, {"text": "For this reason, we rely on a corpus of news crawled from the web between 2008 and 2012 which have been clustered based on closeness in time and cosine similarity, using the vector-space model and tf.idf weights.", "labels": [], "entities": []}, {"text": "News collections with less than 5 documents are discarded 4 , and those larger than 50 documents are capped, by randomly picking 50 documents from the collection . The total number of news collections after clustering is 1.7 million.", "labels": [], "entities": []}, {"text": "From this set, we have set aside a few hundred collections that will remain unseen until the final evaluation.", "labels": [], "entities": []}, {"text": "As we have no development set, we have done no tuning of the parameters for pattern extraction nor for the Bayesian network training (100,000 latent variables to represent the different events, 40 EM iterations, as mentioned in Section 3.2).", "labels": [], "entities": [{"text": "pattern extraction", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.7954615950584412}]}, {"text": "The EM iterations on the noisy-OR were distributed across 30 machines with 16 GB of memory each.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results from the automatic evaluation,  sorted according to the ROUGE-2 and ROUGE- SU4 scores.", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 74, "end_pos": 81, "type": "METRIC", "confidence": 0.9775444269180298}, {"text": "ROUGE- SU4 scores", "start_pos": 86, "end_pos": 103, "type": "METRIC", "confidence": 0.9248446524143219}]}, {"text": " Table 3: Results from the manual evaluation. At  95% confidence, TopicSum is significantly better  than all others for readability, and only indistin- guishable from the most frequent pattern for in- formativeness. For the rest, 3 means being signifi- cantly better than HEADY,  \u2021 than the most frequent  pattern, and  \u2020 than MSC.", "labels": [], "entities": [{"text": "HEADY", "start_pos": 272, "end_pos": 277, "type": "METRIC", "confidence": 0.8666812777519226}]}]}