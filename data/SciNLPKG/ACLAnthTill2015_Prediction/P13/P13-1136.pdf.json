{"title": [{"text": "A Sentence Compression Based Framework to Query-Focused Multi-Document Summarization", "labels": [], "entities": [{"text": "Query-Focused Multi-Document Summarization", "start_pos": 42, "end_pos": 84, "type": "TASK", "confidence": 0.5972073574860891}]}], "abstractContent": [{"text": "We consider the problem of using sentence compression techniques to facilitate query-focused multi-document summarization.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.7202907055616379}, {"text": "multi-document summarization", "start_pos": 93, "end_pos": 121, "type": "TASK", "confidence": 0.573590561747551}]}, {"text": "We present a sentence-compression-based framework for the task, and design a series of learning-based compression models built on parse trees.", "labels": [], "entities": []}, {"text": "An innovative beam search de-coder is proposed to efficiently find highly probable compressions.", "labels": [], "entities": []}, {"text": "Under this framework , we show how to integrate various indicative metrics such as linguistic motivation and query relevance into the compression process by deriving a novel formulation of a compression scoring function.", "labels": [], "entities": []}, {"text": "Our best model achieves statistically significant improvement over the state-of-the-art systems on several metrics (e.g. 8.0% and 5.4% improvements in ROUGE-2 respectively) for the DUC 2006 and 2007 summarization task.", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 151, "end_pos": 158, "type": "METRIC", "confidence": 0.9889513850212097}, {"text": "DUC 2006", "start_pos": 181, "end_pos": 189, "type": "DATASET", "confidence": 0.8512377142906189}]}], "introductionContent": [{"text": "The explosion of the Internet clearly warrants the development of techniques for organizing and presenting information to users in an effective way.", "labels": [], "entities": []}, {"text": "Query-focused multi-document summarization (MDS) methods have been proposed as one such technique and have attracted significant attention in recent years.", "labels": [], "entities": [{"text": "Query-focused multi-document summarization (MDS)", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.7606690029303232}]}, {"text": "The goal of query-focused MDS is to synthesize a brief (often fixed-length) and well-organized summary from a set of topicrelated documents that answer a complex question or address a topic statement.", "labels": [], "entities": []}, {"text": "The resulting summaries, in turn, can support a number of information analysis applications including openended question answering, recommender systems, and summarization of search engine results.", "labels": [], "entities": [{"text": "openended question answering", "start_pos": 102, "end_pos": 130, "type": "TASK", "confidence": 0.7353091637293497}, {"text": "summarization of search engine results", "start_pos": 157, "end_pos": 195, "type": "TASK", "confidence": 0.8913363218307495}]}, {"text": "As further evidence of its importance, the Document Understanding Conference (DUC) has used queryfocused MDS as its main task since 2004 to foster new research on automatic summarization in the context of users' needs.", "labels": [], "entities": [{"text": "Document Understanding Conference (DUC)", "start_pos": 43, "end_pos": 82, "type": "TASK", "confidence": 0.6875741382439932}]}, {"text": "To date, most top-performing systems for multi-document summarization-whether queryspecific or not-remain largely extractive: their summaries are comprised exclusively of sentences selected directly from the documents to be summarized ().", "labels": [], "entities": [{"text": "multi-document summarization-whether queryspecific", "start_pos": 41, "end_pos": 91, "type": "TASK", "confidence": 0.6502262353897095}]}, {"text": "Despite their simplicity, extractive approaches have some disadvantages.", "labels": [], "entities": []}, {"text": "First, lengthy sentences that are partly relevant are either excluded from the summary or (if selected) can block the selection of other important sentences, due to summary length constraints.", "labels": [], "entities": []}, {"text": "In addition, when people write summaries, they tend to abstract the content and seldom use entire sentences taken verbatim from the original documents.", "labels": [], "entities": []}, {"text": "In news articles, for example, most sentences are lengthy and contain both potentially useful information fora summary as well as unnecessary details that are better omitted.", "labels": [], "entities": []}, {"text": "Consider the following DUC query as input fora MDS system: 1 \"In what ways have stolen artworks been recovered?", "labels": [], "entities": []}, {"text": "How often are suspects arrested or prosecuted for the thefts?\"", "labels": [], "entities": []}, {"text": "One manually generated summary includes the following sentence but removes the bracketed words in gray: In this example, the compressed sentence is rela-1 From DUC 2005, query for topic d422g.", "labels": [], "entities": [{"text": "DUC 2005", "start_pos": 160, "end_pos": 168, "type": "DATASET", "confidence": 0.9356471002101898}]}, {"text": "tively more succinct and readable than the original (e.g. in terms of Flesch-Kincaid Reading Ease Score ().", "labels": [], "entities": [{"text": "Flesch-Kincaid Reading Ease Score", "start_pos": 70, "end_pos": 103, "type": "METRIC", "confidence": 0.8505539000034332}]}, {"text": "Likewise, removing information irrelevant to the query (e.g. \"11 years ago\", \"police said\") is crucial for query-focused MDS.", "labels": [], "entities": [{"text": "query-focused MDS", "start_pos": 107, "end_pos": 124, "type": "TASK", "confidence": 0.5917515903711319}]}, {"text": "Sentence compression techniques are the standard for producing a compact and grammatical version of a sentence while preserving relevance, and prior research (e.g.) has demonstrated their potential usefulness for generic document summarization.", "labels": [], "entities": [{"text": "Sentence compression", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9022256731987}, {"text": "generic document summarization", "start_pos": 213, "end_pos": 243, "type": "TASK", "confidence": 0.9040502111117045}]}, {"text": "Similarly, strides have been made to incorporate sentence compression into query-focused MDS systems ().", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 49, "end_pos": 69, "type": "TASK", "confidence": 0.7400949001312256}]}, {"text": "Most attempts, however, fail to produce better results than those of the best systems built on pure extraction-based approaches that use no sentence compression.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 140, "end_pos": 160, "type": "TASK", "confidence": 0.7448782622814178}]}, {"text": "In this paper we investigate the role of sentence compression techniques for query-focused MDS.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.721273884177208}]}, {"text": "We extend existing work in the area first by investigating the role of learning-based sentence compression techniques.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 86, "end_pos": 106, "type": "TASK", "confidence": 0.7066585272550583}]}, {"text": "In addition, we design three types of approaches to sentence-compressionrule-based, sequence-based and tree-based-and examine them within our compression-based framework for query-specific MDS.", "labels": [], "entities": []}, {"text": "Our topperforming sentence compression algorithm incorporates measures of query relevance, content importance, redundancy and language quality, among others.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 18, "end_pos": 38, "type": "TASK", "confidence": 0.6940172612667084}]}, {"text": "Our tree-based methods rely on a scoring function that allows for easy and flexible tailoring of sentence compression to the summarization task, ultimately resulting in significant improvements for MDS, while at the same time remaining competitive with existing methods in terms of sentence compression, as discussed next.", "labels": [], "entities": [{"text": "summarization task", "start_pos": 125, "end_pos": 143, "type": "TASK", "confidence": 0.9053302109241486}, {"text": "sentence compression", "start_pos": 282, "end_pos": 302, "type": "TASK", "confidence": 0.7404503971338272}]}, {"text": "We evaluate the summarization models on the standard Document Understanding Conference (DUC) 2006 and 2007 corpora 2 for queryfocused MDS and find that all of our compressionbased summarization models achieve statistically significantly better performance than the best DUC 2006 systems.", "labels": [], "entities": [{"text": "standard Document Understanding Conference (DUC) 2006 and 2007 corpora 2", "start_pos": 44, "end_pos": 116, "type": "DATASET", "confidence": 0.6947959711154302}]}, {"text": "Our best-performing system yields an 11.02 ROUGE-2 score (Lin and Hovy, 2003), a 8.0% improvement over the best reported score) on the DUC 2006 dataset, and an 13.49 ROUGE-2, a 5.4% improvement over the best score in DUC).", "labels": [], "entities": [{"text": "ROUGE-2 score", "start_pos": 43, "end_pos": 56, "type": "METRIC", "confidence": 0.9752467572689056}, {"text": "DUC 2006 dataset", "start_pos": 135, "end_pos": 151, "type": "DATASET", "confidence": 0.9696382284164429}, {"text": "ROUGE-2", "start_pos": 166, "end_pos": 173, "type": "METRIC", "confidence": 0.9903312921524048}, {"text": "DUC", "start_pos": 217, "end_pos": 220, "type": "DATASET", "confidence": 0.9414507746696472}]}, {"text": "We also observe substantial improvements over previous systems w.r.t. the manual Pyramid () evaluation measure)); human annotators furthermore rate our system-generated summaries as having less redundancy and comparable quality w.r.t. other linguistic quality metrics.", "labels": [], "entities": []}, {"text": "With these results we believe we are the first to successfully show that sentence compression can provide statistically significant improvements over pure extraction-based approaches for queryfocused MDS.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 73, "end_pos": 93, "type": "TASK", "confidence": 0.7657324075698853}]}], "datasetContent": [{"text": "We evaluate our methods on the, each of which is a collection of newswire articles.", "labels": [], "entities": []}, {"text": "50 complex queries (topics) are provided for DUC 2005 and 2006, 35 are collected for DUC 2007 main task.", "labels": [], "entities": [{"text": "DUC 2005", "start_pos": 45, "end_pos": 53, "type": "DATASET", "confidence": 0.932702898979187}, {"text": "DUC 2007 main task", "start_pos": 85, "end_pos": 103, "type": "DATASET", "confidence": 0.8620310723781586}]}, {"text": "Relevant documents for each query are provided along with 4 to 9 human MDS abstracts.", "labels": [], "entities": []}, {"text": "The task is to generate a summary within 250 words to address the query.", "labels": [], "entities": []}, {"text": "We split DUC 2005 into two parts: 40 topics to train the sentence ranking models, and 10 for ranking algorithm selection and parameter tuning for the multiscorer.", "labels": [], "entities": [{"text": "DUC 2005", "start_pos": 9, "end_pos": 17, "type": "DATASET", "confidence": 0.9330520927906036}, {"text": "sentence ranking", "start_pos": 57, "end_pos": 73, "type": "TASK", "confidence": 0.7198985368013382}, {"text": "ranking algorithm selection", "start_pos": 93, "end_pos": 120, "type": "TASK", "confidence": 0.7915048599243164}]}, {"text": "DUC 2006 and DUC 2007 are reserved as held out test sets.", "labels": [], "entities": [{"text": "DUC 2006", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9766342043876648}, {"text": "DUC 2007", "start_pos": 13, "end_pos": 21, "type": "DATASET", "confidence": 0.8790114521980286}]}, {"text": "The dataset from is used to train the CRF and MaxEnt classifiers (Section 4).", "labels": [], "entities": []}, {"text": "It includes 82 newswire articles with one manually produced compression aligned to each sentence.", "labels": [], "entities": []}, {"text": "Documents are processed by a full NLP pipeline, including token and sentence segmentation, parsing, semantic role labeling, and an information extraction pipeline consisting of mention detection, NP coreference, crossdocument resolution, and relation detection.", "labels": [], "entities": [{"text": "token and sentence segmentation", "start_pos": 58, "end_pos": 89, "type": "TASK", "confidence": 0.6194060668349266}, {"text": "semantic role labeling", "start_pos": 100, "end_pos": 122, "type": "TASK", "confidence": 0.6199711958567301}, {"text": "information extraction", "start_pos": 131, "end_pos": 153, "type": "TASK", "confidence": 0.7076766192913055}, {"text": "mention detection", "start_pos": 177, "end_pos": 194, "type": "TASK", "confidence": 0.7553543448448181}, {"text": "NP coreference", "start_pos": 196, "end_pos": 210, "type": "TASK", "confidence": 0.7713563740253448}, {"text": "crossdocument resolution", "start_pos": 212, "end_pos": 236, "type": "TASK", "confidence": 0.7844140827655792}, {"text": "relation detection", "start_pos": 242, "end_pos": 260, "type": "TASK", "confidence": 0.8801608383655548}]}, {"text": "Learning for Sentence Ranking and Compression.", "labels": [], "entities": [{"text": "Sentence Ranking", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.8751603662967682}]}, {"text": "We use Weka () to train a support vector regressor and experiment with various rankers in RankLib . As LambdaMART has an edge over other rankers on the held-out dataset, we selected it to produce ranked sentences for further processing.", "labels": [], "entities": []}, {"text": "For sequencebased compression using CRFs, we employ Mallet) and integrate the rules during inference.", "labels": [], "entities": [{"text": "sequencebased compression", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.7807515561580658}]}, {"text": "NLTK ( MaxEnt classifiers are used for tree-based compression.", "labels": [], "entities": [{"text": "NLTK", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8782841563224792}]}, {"text": "Beam size is fixed at 2000.", "labels": [], "entities": [{"text": "Beam size", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.8109211027622223}]}, {"text": "Sentence compressions are evaluated by a 5-gram language model trained on Gigaword by SRILM).", "labels": [], "entities": [{"text": "Sentence compressions", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9296509921550751}, {"text": "SRILM", "start_pos": 86, "end_pos": 91, "type": "DATASET", "confidence": 0.8879432678222656}]}], "tableCaptions": [{"text": " Table 5: Query-focused MDS performance comparison: C Rate or compression rate is the proportion of words", "labels": [], "entities": [{"text": "C Rate or compression rate", "start_pos": 52, "end_pos": 78, "type": "METRIC", "confidence": 0.7279969811439514}]}, {"text": " Table 7: Sentence compression comparison. The true c rate is 69.06% for the test set. Tree-based approaches", "labels": [], "entities": [{"text": "Sentence compression", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.8765246570110321}, {"text": "c rate", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.8417465388774872}]}]}