{"title": [{"text": "Named Entity Recognition using Cross-lingual Resources: Arabic as an Example", "labels": [], "entities": [{"text": "Named Entity Recognition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.5952880481878916}]}], "abstractContent": [{"text": "Some languages lack large knowledge bases and good discriminative features for Name Entity Recognition (NER) that can generalize to previously unseen named entities.", "labels": [], "entities": [{"text": "Name Entity Recognition (NER)", "start_pos": 79, "end_pos": 108, "type": "TASK", "confidence": 0.8081296036640803}]}, {"text": "One such language is Arabic, which: a) lacks a capitalization feature; and b) has relatively small knowledge bases, such as Wikipedia.", "labels": [], "entities": []}, {"text": "In this work we address both problems by incorporating cross-lingual features and knowledge bases from English using cross-lingual links.", "labels": [], "entities": []}, {"text": "We show that such features have a dramatic positive effect on recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9967581629753113}]}, {"text": "We show the effectiveness of cross-lingual features and resources on a standard dataset as well as on two new test sets that cover both news and microblogs.", "labels": [], "entities": []}, {"text": "On the standard dataset, we achieved a 4.1% relative improvement in F-measure over the best reported result in the literature.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.9988036155700684}]}, {"text": "The features led to improvements of 17.1% and 20.5% on the new news and mi-croblogs test sets respectively.", "labels": [], "entities": [{"text": "mi-croblogs test sets", "start_pos": 72, "end_pos": 93, "type": "DATASET", "confidence": 0.7925713658332825}]}], "introductionContent": [{"text": "Named Entity Recognition (NER) is essential fora variety of Natural Language Processing (NLP) applications such as information extraction.", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7514004707336426}, {"text": "information extraction", "start_pos": 115, "end_pos": 137, "type": "TASK", "confidence": 0.8639693558216095}]}, {"text": "There has been a fair amount of work on NER fora variety of languages including Arabic.", "labels": [], "entities": []}, {"text": "To train an NER system, some of the following feature types are typically used: -Orthographic features: These features include capitalization, punctuation, existence of digits, etc.", "labels": [], "entities": [{"text": "NER", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.8123006224632263}]}, {"text": "One of the most effective orthographic features is capitalization in English, which helps NER to generalize to new text of different genres.", "labels": [], "entities": [{"text": "NER", "start_pos": 90, "end_pos": 93, "type": "TASK", "confidence": 0.9596912264823914}]}, {"text": "However, capitalization is not very useful in some languages such as German, and nonexistent in other languages such as Arabic.", "labels": [], "entities": []}, {"text": "Further, even in English social media, capitalization maybe inconsistent.", "labels": [], "entities": []}, {"text": "-Contextual features: Certain words are indicative of the existence of named entities.", "labels": [], "entities": []}, {"text": "For example, the word \"said\" is often preceded by a named entity of type \"person\" or \"organization\".", "labels": [], "entities": []}, {"text": "Sequence labeling algorithms (ex. Conditional Random Fields (CRF)) can often identify such indicative words.", "labels": [], "entities": [{"text": "Sequence labeling", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7906202971935272}]}, {"text": "-Character-level features: These features typically include the leading and trailing letters of words.", "labels": [], "entities": []}, {"text": "In some languages, these letters could prefixes and suffixes.", "labels": [], "entities": []}, {"text": "Such features can be indicative or counter-indicative of the existence of named entities.", "labels": [], "entities": []}, {"text": "For example, a word ending with \"ing\" is typically not a named entity, while a word ending in \"berg\" is often a named entity.", "labels": [], "entities": []}, {"text": "-Part-of-speech (POS) tags and morphological features: POS tags indicate (or counter-indicate) the possible presence of a named entity at word level or at word sequence level.", "labels": [], "entities": []}, {"text": "Morphological features can mostly indicate the absence of named entities.", "labels": [], "entities": []}, {"text": "For example, Arabic allows the attachment of pronouns to nouns and verbs.", "labels": [], "entities": []}, {"text": "However, pronouns are rarely ever attached to named entities.", "labels": [], "entities": []}, {"text": "-Gazetteers: This feature checks the presence of a word or a sequence of words in large lists of named entities.", "labels": [], "entities": []}, {"text": "If gazetteers are small, then they would have low coverage, and if they are very large then their entries maybe ambiguous.", "labels": [], "entities": [{"text": "coverage", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.970237672328949}]}, {"text": "For example, \"syntax\" may refer to sentence construction or the music band \"Syntax\".", "labels": [], "entities": [{"text": "sentence construction", "start_pos": 35, "end_pos": 56, "type": "TASK", "confidence": 0.7527442276477814}]}, {"text": "Typically, a subset of these features are available for different languages.", "labels": [], "entities": []}, {"text": "For example, morphological, contextual, and character-level features have been shown to be effective for Arabic NER.", "labels": [], "entities": [{"text": "Arabic NER", "start_pos": 105, "end_pos": 115, "type": "TASK", "confidence": 0.5037524700164795}]}, {"text": "However, Arabic lacks indicative orthographic features that generalize to previously unseen named entities.", "labels": [], "entities": []}, {"text": "Also, although some of the Arabic gazetteers that were used for NER were small , there has been efforts to build larger Arabic gazetteers (.", "labels": [], "entities": [{"text": "NER", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9235291481018066}]}, {"text": "Since training and test parts of standard datasets for Arabic NER are drawn from the same genre in relatively close temporal proximity, a named entity recognizer that simply memorizes named entities in the training set generally performs well on such test sets.", "labels": [], "entities": [{"text": "Arabic NER", "start_pos": 55, "end_pos": 65, "type": "TASK", "confidence": 0.4604480266571045}]}, {"text": "Thus, the results that are reported in the literature are generally high).", "labels": [], "entities": []}, {"text": "We illustrate the limited capacity of existing recognizers to generalize to previously unseen named entities using two new test sets that include microblogs as well as news texts that cover local and international politics, economics, health, sports, entertainment, and science.", "labels": [], "entities": []}, {"text": "As we will show later, recall is well below 50% for all named entity types on the new test sets.", "labels": [], "entities": [{"text": "recall", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.9997860789299011}]}, {"text": "To address this problem, we introduce the use of cross-lingual links between a disadvantaged language, Arabic, and a language with good discriminative features and large resources, English, to improve Arabic NER.", "labels": [], "entities": [{"text": "NER", "start_pos": 208, "end_pos": 211, "type": "TASK", "confidence": 0.6065452694892883}]}, {"text": "We exploit English's orthographic features, particularly capitalization, as well as Arabic and English Wikipedias, including existing annotations from large knowledge sources such as DBpedia.", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 183, "end_pos": 190, "type": "DATASET", "confidence": 0.9508528113365173}]}, {"text": "We also show how to use transliteration mining to improve NER, even when neither language has a capitalization (or similar) feature.", "labels": [], "entities": [{"text": "transliteration mining", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.7184802442789078}, {"text": "NER", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.9139449596405029}]}, {"text": "The intuition is that if the translation of a word is in fact a transliteration, then the word is likely a named entity.", "labels": [], "entities": []}, {"text": "Cross-lingual links are obtained using Wikipedia cross-language links and a large Machine Translation (MT) phrase table that is true cased, where word casing is preserved during training.", "labels": [], "entities": [{"text": "Machine Translation (MT) phrase", "start_pos": 82, "end_pos": 113, "type": "TASK", "confidence": 0.8509705861409506}]}, {"text": "We show the effectiveness of these new features on a standard dataset as well as two new test sets.", "labels": [], "entities": []}, {"text": "The contributions of this paper are as follows: -Using cross-lingual links to exploit orthographic features in other languages.", "labels": [], "entities": []}, {"text": "-Employing transliteration mining to improve NER.", "labels": [], "entities": [{"text": "Employing transliteration mining", "start_pos": 1, "end_pos": 33, "type": "TASK", "confidence": 0.6118791004021963}, {"text": "NER", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9572117924690247}]}, {"text": "-Using cross-lingual links to exploit a large knowledge base, namely English DBpedia, to benefit NER.", "labels": [], "entities": [{"text": "English DBpedia", "start_pos": 69, "end_pos": 84, "type": "DATASET", "confidence": 0.8488110303878784}, {"text": "NER", "start_pos": 97, "end_pos": 100, "type": "TASK", "confidence": 0.6901478171348572}]}, {"text": "-Introducing two new NER test sets for Arabic that include recent news as well as microblogs.", "labels": [], "entities": [{"text": "NER test sets", "start_pos": 21, "end_pos": 34, "type": "DATASET", "confidence": 0.8458252747853597}]}, {"text": "We plan to release these test sets.", "labels": [], "entities": []}, {"text": "-Improving over the best reported results in the literature by 4.1% by strictly adding cross-lingual features.", "labels": [], "entities": []}, {"text": "We also show improvements of 17.1% and 20.5% on the new test sets.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows: Section 2 provides related work; Section 3 describes the baseline system; Section 4 introduces the cross-lingual features and reports on their effectiveness; and Section 5 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: \"Baseline-lit\" Results from (Abdul-Hamid and  Darwish, 2010)", "labels": [], "entities": [{"text": "Abdul-Hamid and  Darwish, 2010)", "start_pos": 39, "end_pos": 70, "type": "DATASET", "confidence": 0.7028493583202362}]}, {"text": " Table 2: Baseline Results for the three test sets", "labels": [], "entities": []}, {"text": " Table 3: Results of using only tokens as features on AN- ERCORP", "labels": [], "entities": [{"text": "AN- ERCORP", "start_pos": 54, "end_pos": 64, "type": "DATASET", "confidence": 0.7341120839118958}]}, {"text": " Table 4: Results with cross-lingual capitalization with  /absolute/relative differences compared to baseline", "labels": [], "entities": []}, {"text": " Table 5: Results with transliteration mining with /abso- lute/relative differences compared to baseline", "labels": [], "entities": []}, {"text": " Table 6: Results using DBpedia with /absolute/relative  differences compared to baseline", "labels": [], "entities": [{"text": "DBpedia", "start_pos": 24, "end_pos": 31, "type": "DATASET", "confidence": 0.6286031603813171}]}, {"text": " Table 7: Results using all the cross-lingual features with  /absolute/relative differences compared to baseline", "labels": [], "entities": []}]}