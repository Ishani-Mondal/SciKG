{"title": [{"text": "TransDoop: A Map-Reduce based Crowdsourced Translation for Complex Domains", "labels": [], "entities": []}], "abstractContent": [{"text": "Large amount of parallel corpora is required for building Statistical Machine Translation (SMT) systems.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 58, "end_pos": 95, "type": "TASK", "confidence": 0.8318859338760376}]}, {"text": "We describe the TransDoop system for gathering translations to create parallel corpora from on-line crowd workforce who have familiarity with multiple languages but are not expert translators.", "labels": [], "entities": []}, {"text": "Our system uses a Map-Reduce-like approach to translation crowdsourcing where sentence translation is decomposed into the following smaller tasks: (a) translation of constituent phrases of the sentence; (b) validation of quality of the phrase translations; and (c) composition of complete sentence translations from phrase translations.", "labels": [], "entities": [{"text": "sentence translation", "start_pos": 78, "end_pos": 98, "type": "TASK", "confidence": 0.7709729373455048}, {"text": "composition of complete sentence translations from phrase translations", "start_pos": 265, "end_pos": 335, "type": "TASK", "confidence": 0.7639449313282967}]}, {"text": "Trans-Doop incorporates quality control mechanisms and easy-to-use worker user interfaces designed to address issues with translation crowdsourcing.", "labels": [], "entities": []}, {"text": "We have evaluated the crowd's output using the METEOR metric.", "labels": [], "entities": [{"text": "METEOR", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9778928160667419}]}, {"text": "For a complex domain like judicial proceedings, the higher scores obtained by the map-reduce based approach compared to complete sentence translation establishes the efficacy of our work.", "labels": [], "entities": [{"text": "complete sentence translation", "start_pos": 120, "end_pos": 149, "type": "TASK", "confidence": 0.752861221631368}]}], "introductionContent": [{"text": "Crowdsourcing is no longer anew term in the domain of Computational Linguistics and Machine Translation research).", "labels": [], "entities": [{"text": "Machine Translation research", "start_pos": 84, "end_pos": 112, "type": "TASK", "confidence": 0.8104161024093628}]}, {"text": "Crowdsourcing -basically where task outsourcing is delegated to a largely unknown Internet audience -is emerging as anew paradigm of human in the loop approaches for developing sophisticated techniques for understanding and generating natural language content.", "labels": [], "entities": [{"text": "understanding and generating natural language content", "start_pos": 206, "end_pos": 259, "type": "TASK", "confidence": 0.6447174449761709}]}, {"text": "Amazon Mechanical Turk(AMT) and CrowdFlower 1 are representative general purpose crowdsourcing platforms whereas Lingotek and Gengo 2 are companies targeted at localization and translation of content typically leveraging freelancers.", "labels": [], "entities": [{"text": "Lingotek", "start_pos": 113, "end_pos": 121, "type": "DATASET", "confidence": 0.9287319779396057}]}, {"text": "Our interest is towards developing a crowdsourcing based system to enable general, nonexpert crowd-workers generate natural language content equivalent in quality to that of expert linguists.", "labels": [], "entities": []}, {"text": "Realization of the potential of attaining great scalability and cost-benefit of crowdsourcing for natural language tasks is limited by the ability of novice multi-lingual workers generate high quality translations.", "labels": [], "entities": []}, {"text": "We have specific interest in Indian languages due to the large linguistic diversity as well as the scarcity of linguistic resources in these languages when compared to European languages.", "labels": [], "entities": []}, {"text": "Crowdsourcing is a promising approach as many Indian languages are spoken by hundreds of Millions of people (approximately, Hindi-Urdu by 500M, Bangla by 200M, Punjabi by over 100M 3 ) coupled with the fact that representation of Indian workers in online crowdsourcing platforms is very high (close to 40% in Amazon Mechanical Turk (AMT)).", "labels": [], "entities": []}, {"text": "However, this is a non-trivial task owing to lack of expertise of novice crowd workers in translation of content.", "labels": [], "entities": [{"text": "translation of content", "start_pos": 90, "end_pos": 112, "type": "TASK", "confidence": 0.91568523645401}]}, {"text": "It is well understood that familiarity with multiple languages might not be good enough for people to generate high quality translations.", "labels": [], "entities": []}, {"text": "This is compounded by lack of sincerity and in certain cases, dishonest intention of earning rewards disproportionate to the effort and time spent for online tasks.", "labels": [], "entities": [{"text": "sincerity", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9765976071357727}]}, {"text": "Common techniques for quality control like gold data based validation and worker reputation are not effective fora subjective task like translation which does not have any task specific measurements.", "labels": [], "entities": [{"text": "translation", "start_pos": 136, "end_pos": 147, "type": "TASK", "confidence": 0.9813639521598816}]}, {"text": "Having expert linguists manually validate crowd generated content defies the purpose of deploying crowdsourcing on a large scale.", "labels": [], "entities": []}, {"text": "In this work, we propose a technique, based on the Divide-and-Conquer principle.", "labels": [], "entities": []}, {"text": "The technique can be considered similar to a Map-Reduce task run on crowd processors, where the translation task is split into simpler tasks distributed to the crowd (the map stage) and the results are later combined in a reduce stage to generate complete translations.", "labels": [], "entities": []}, {"text": "The attempt is to make translation tasks easy and intuitive for novice crowd-workers by providing translations aids to help them generate high quality of translations.", "labels": [], "entities": [{"text": "translation tasks", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.9064688682556152}]}, {"text": "Our contribution in this work is a end-to-end, crowdsourcingplatform-independent, translation crowdsourcing system that completely automates the translation crowdsourcing task by (i) managing the translation pipeline through software components and the crowd; (ii) performing quality control on workers' output; and (iii) interfacing with crowdsourcing service providers.", "labels": [], "entities": []}, {"text": "The multi-stage, Mapreduce approach simplifies the translation task for crowd workers, while novel design of user interface makes the task convenient for the worker and discourages spamming.", "labels": [], "entities": [{"text": "translation task", "start_pos": 51, "end_pos": 67, "type": "TASK", "confidence": 0.8890963494777679}, {"text": "spamming", "start_pos": 181, "end_pos": 189, "type": "TASK", "confidence": 0.9664216041564941}]}, {"text": "The system thus offers the potential to generate high quality parallel corpora on a large scale.", "labels": [], "entities": []}, {"text": "We discuss related work in Section 2 and the multi-staged approach which is central to our system in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 describes the system architecture and workflow, while Section 5 presents important aspects of the user interfaces in the system.", "labels": [], "entities": []}, {"text": "We present our preliminary experiments and observations in Section 6.", "labels": [], "entities": []}, {"text": "Section 7 concludes the paper, pointing to future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Using TransDoop, we conducted a set of smallscale, preliminary translation experiments.", "labels": [], "entities": []}, {"text": "We obtained translations for English-Hindi and EnglishMarathi language pairs for the Judicial and Tourism domains.", "labels": [], "entities": []}, {"text": "For each experiment, 15 sentences were given as input to the pipeline.", "labels": [], "entities": []}, {"text": "For evaluation, we chose METEOR, a well-known translation evaluation metric (.", "labels": [], "entities": [{"text": "METEOR", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9585795402526855}, {"text": "translation evaluation", "start_pos": 46, "end_pos": 68, "type": "TASK", "confidence": 0.9096389412879944}]}, {"text": "We compared the results obtained from the crowdsourcing system with a expert human translation and the output of Google Translate.", "labels": [], "entities": []}, {"text": "We also compared two expert translations using METEOR to establish a skyline for the translation accuracy.", "labels": [], "entities": [{"text": "METEOR", "start_pos": 47, "end_pos": 53, "type": "DATASET", "confidence": 0.6559775471687317}, {"text": "translation", "start_pos": 85, "end_pos": 96, "type": "TASK", "confidence": 0.9444838166236877}, {"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9526202082633972}]}, {"text": "summarizes the results of our experiments.", "labels": [], "entities": []}, {"text": "The translations with Quality Control and multistage pipeline are better than Google translations and translations obtained from the crowd without any quality control, as evaluated by METEOR.", "labels": [], "entities": [{"text": "METEOR", "start_pos": 184, "end_pos": 190, "type": "DATASET", "confidence": 0.8591945767402649}]}, {"text": "Multi-stage translation yields better than complete sentence translation.", "labels": [], "entities": [{"text": "complete sentence translation", "start_pos": 43, "end_pos": 72, "type": "TASK", "confidence": 0.6612666348616282}]}, {"text": "Moreover, the translation quality is comparable to that of expert human translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 14, "end_pos": 25, "type": "TASK", "confidence": 0.9430325031280518}, {"text": "expert human translation", "start_pos": 59, "end_pos": 83, "type": "TASK", "confidence": 0.7334732015927633}]}, {"text": "This behavior is observed across the two language pairs and domains.", "labels": [], "entities": []}, {"text": "This can be seen in some examples of crowdsourced translations obtained through the system which are shown in.", "labels": [], "entities": []}, {"text": "Incorrect splitting of sentences can cause difficulties in translation for the worker.", "labels": [], "entities": [{"text": "translation", "start_pos": 59, "end_pos": 70, "type": "TASK", "confidence": 0.9639982581138611}]}, {"text": "For instance, discontinuous phrases will not be available to the worker as a single translation unit.", "labels": [], "entities": []}, {"text": "In the English interrogative sentence, the noun phrase splits the verb phrase, therefore the auxiliary and main verb could be in different translation units.", "labels": [], "entities": []}, {"text": "e.g. Why did you buy the book?", "labels": [], "entities": []}, {"text": "In addition, the phrase structures of the source and target languages may not map, making translation difficult.", "labels": [], "entities": [{"text": "translation", "start_pos": 90, "end_pos": 101, "type": "TASK", "confidence": 0.9647291898727417}]}, {"text": "For instance, the vaala modifier in Hindi translates to a clause in English.", "labels": [], "entities": []}, {"text": "It does not contain any tense information, therefore the tense of the English clause cannot be determined by the worker.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experimental Results: Comparison of METEOR scores for different techniques, language pairs and domains", "labels": [], "entities": [{"text": "METEOR", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.942812979221344}]}]}