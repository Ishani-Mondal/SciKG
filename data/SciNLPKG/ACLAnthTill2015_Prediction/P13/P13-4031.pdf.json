{"title": [{"text": "tSEARCH: Flexible and Fast Search over Automatic Translations for Improved Quality/Error Analysis", "labels": [], "entities": [{"text": "Improved Quality/Error Analysis", "start_pos": 66, "end_pos": 97, "type": "TASK", "confidence": 0.520320999622345}]}], "abstractContent": [{"text": "This work presents tSEARCH, a web-based application that provides mechanisms for doing complex searches over a collection of translation cases evaluated with a large set of diverse measures.", "labels": [], "entities": []}, {"text": "tSEARCH uses the evaluation results obtained with the ASIYA toolkit for MT evaluation and it is connected to its on-line GUI, which makes possible a graphical visualization and interactive access to the evaluation results.", "labels": [], "entities": [{"text": "tSEARCH", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8668637275695801}, {"text": "MT evaluation", "start_pos": 72, "end_pos": 85, "type": "TASK", "confidence": 0.9659003913402557}]}, {"text": "The search engine offers a flexible query language allowing to find translation examples matching a combination of numerical and structural features associated to the calculation of the quality metrics.", "labels": [], "entities": []}, {"text": "Its database design permits a fast response time for all queries supported on realistic-size test beds.", "labels": [], "entities": []}, {"text": "In summary , tSEARCH, used with ASIYA, offers developers of MT systems and evaluation metrics a powerful tool for helping translation and error analysis.", "labels": [], "entities": [{"text": "MT", "start_pos": 60, "end_pos": 62, "type": "TASK", "confidence": 0.9737221002578735}, {"text": "translation and error analysis", "start_pos": 122, "end_pos": 152, "type": "TASK", "confidence": 0.7713640928268433}]}], "introductionContent": [{"text": "In Machine Translation (MT) system development, a qualitative analysis of the translations is a fundamental step in order to spot the limitations of a system, compare the linguistic abilities of different systems or tune the parameters during system refinement.", "labels": [], "entities": [{"text": "Machine Translation (MT) system development", "start_pos": 3, "end_pos": 46, "type": "TASK", "confidence": 0.8759181840079171}]}, {"text": "This is especially true in statistical MT systems, where usually no special structured knowledge is used other than parallel data and language models, but also on systems that need to reason over linguistic structures.", "labels": [], "entities": [{"text": "MT", "start_pos": 39, "end_pos": 41, "type": "TASK", "confidence": 0.8681938648223877}]}, {"text": "The need for analyzing and comparing automatic translations with respect to evaluation metrics is also paramount for developers of translation quality metrics, who need elements of analysis to better understand the behavior of their evaluation measures.", "labels": [], "entities": []}, {"text": "This paper presents tSEARCH, a web application that aims to alleviate the burden of manual analysis that developers have to conduct to assess the translation quality aspects involved in the above mentioned situations.", "labels": [], "entities": []}, {"text": "As a toy example, consider for instance an evaluation setting with two systems, s 1 and s 2 , and two evaluation metrics m 1 and m 2 . Assume also that m 1 scores s 1 to be better than s 2 in a particular test set, while m 2 predicts just the contrary.", "labels": [], "entities": []}, {"text": "In order to analyze this contradictory evaluation one might be interested in inspecting from the test set the particular translation examples that contribute to these results, i.e., text segments t for which the translation provided by s 1 is scored better by m 1 than the translation provided by s 2 and the opposite behavior regarding metric m 2 . tSEARCH allows to retrieve (visualize and export) these sentences with a simple query in a fast time response.", "labels": [], "entities": []}, {"text": "The search can be further constrained, by requiring certain margins on the differences, by including other systems or metrics, or by requiring some specific syntactic or semantic constructs to appear in the examples.", "labels": [], "entities": []}, {"text": "tSEARCH is build on top of ASIYA (, an open-source toolkit for MT evaluation; and it can be used along with the ASIYA ON-LINE INTERFACE (, which provides an interactive environment to examine the sentences.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 63, "end_pos": 76, "type": "TASK", "confidence": 0.9655539691448212}, {"text": "ON-LINE INTERFACE", "start_pos": 118, "end_pos": 135, "type": "METRIC", "confidence": 0.566986620426178}]}, {"text": "ASIYA allows to analyze a wide range of linguistic aspects of candidate and reference translations using a large set of automatic and heterogeneous evaluation metrics.", "labels": [], "entities": [{"text": "candidate and reference translations", "start_pos": 62, "end_pos": 98, "type": "TASK", "confidence": 0.6441444605588913}]}, {"text": "In particular, it offers a especially rich set of measures that use syntactic and semantic information.", "labels": [], "entities": []}, {"text": "The intermediate structures generated by the parsers, and used to compute the scoring measures, could be priceless for MT developers, who can use them to compare the structures of several translations and see how they affect the performance of the metrics, providing more understanding in order to interpret the actual performance of the automatic translation systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 119, "end_pos": 121, "type": "TASK", "confidence": 0.9765017628669739}]}, {"text": "tSEARCH consists of: 1) a database that stores the resources generated by ASIYA, 2) a query language and a search engine able to look through the information gathered in the database, and 3) a graphical user interface that assists the user to write a query, returns the set of sentences that fulfill the conditions, and allows to export these results in XML format.", "labels": [], "entities": []}, {"text": "The application is publicly accessible on-line 1 , and a brief explanation of its most important features is given in the demonstrative video.", "labels": [], "entities": []}, {"text": "In the following, Section 2 gives an overview of the ASIYA toolkit and the information gathered from the evaluation output.", "labels": [], "entities": [{"text": "ASIYA", "start_pos": 53, "end_pos": 58, "type": "TASK", "confidence": 0.8937852382659912}]}, {"text": "Section 3 and Section 4 describe in depth the tSEARCH application and the on-line interface, respectively.", "labels": [], "entities": []}, {"text": "Finally, Section 5 reviews similar applications in comparison to the functionalities addressed by tSEARCH.", "labels": [], "entities": []}], "datasetContent": [{"text": "Currently, ASIYA contains more than 800 variants of MT metrics to measure the similarity between two translations at several linguistic dimensions.", "labels": [], "entities": [{"text": "MT", "start_pos": 52, "end_pos": 54, "type": "TASK", "confidence": 0.9646217226982117}]}, {"text": "Moreover, the scores can be calculated at three granularity levels: system (entire test-set), document and sentence (or segment).", "labels": [], "entities": []}, {"text": "As shown in, ASIYA requires the user to provide a test suite.", "labels": [], "entities": [{"text": "ASIYA", "start_pos": 13, "end_pos": 18, "type": "TASK", "confidence": 0.8598264455795288}]}, {"text": "Then, the input files are processed in order to calculate the annotations, the parsing trees and the final metric scores.", "labels": [], "entities": []}, {"text": "Several external components are used for both, metric computation and automatic linguistic analysis 2 . The use of these tools depends on the languages supported and the type of measures that one needs to obtain.", "labels": [], "entities": [{"text": "automatic linguistic analysis", "start_pos": 70, "end_pos": 99, "type": "TASK", "confidence": 0.5898256599903107}]}, {"text": "Hence, for instance, lexical-based measures are computed using the last version of most popular metrics, such as BLEU, NIST, METEOR or ROUGE.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 113, "end_pos": 117, "type": "METRIC", "confidence": 0.9969057440757751}, {"text": "NIST", "start_pos": 119, "end_pos": 123, "type": "DATASET", "confidence": 0.8129644393920898}, {"text": "METEOR", "start_pos": 125, "end_pos": 131, "type": "METRIC", "confidence": 0.8344672322273254}, {"text": "ROUGE", "start_pos": 135, "end_pos": 140, "type": "METRIC", "confidence": 0.9018247723579407}]}, {"text": "The syntax-wise measures need the output of taggers, lemmatizers, parsers: ASIYA processes and data files and other analyzers.", "labels": [], "entities": []}, {"text": "In those cases, ASIYA uses the SVMTool (), BIOS (), the CharniakJohnson and Berkeley constituent parsers, and the MALT dependency parser (), among others.", "labels": [], "entities": []}, {"text": "In the tSEARCH platform, the system manages the communication with an instance of the ASIYA toolkit running on the server.", "labels": [], "entities": []}, {"text": "For every test suite, the system maintains a synchronized representation of the input data, the evaluation results and the linguistic information generated.", "labels": [], "entities": []}, {"text": "Then, the system updates a database where the test suites are stored for further analysis using the tSEARCH tool, as described next.", "labels": [], "entities": []}], "tableCaptions": []}