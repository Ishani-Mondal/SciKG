{"title": [{"text": "Statistical Machine Translation Improves Question Retrieval in Community Question Answering via Matrix Factorization", "labels": [], "entities": [{"text": "Statistical Machine Translation Improves Question Retrieval", "start_pos": 0, "end_pos": 59, "type": "TASK", "confidence": 0.849468837181727}, {"text": "Community Question Answering", "start_pos": 63, "end_pos": 91, "type": "TASK", "confidence": 0.6217805743217468}]}], "abstractContent": [{"text": "Community question answering (CQA) has become an increasingly popular research topic.", "labels": [], "entities": [{"text": "Community question answering (CQA)", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7987180550893148}]}, {"text": "In this paper, we focus on the problem of question retrieval.", "labels": [], "entities": [{"text": "question retrieval", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.8189498484134674}]}, {"text": "Question retrieval in CQA can automatically find the most relevant and recent questions that have been solved by other users.", "labels": [], "entities": [{"text": "Question retrieval", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7397456169128418}, {"text": "CQA", "start_pos": 22, "end_pos": 25, "type": "DATASET", "confidence": 0.9214335083961487}]}, {"text": "However, the word ambiguity and word mismatch problems bring about new challenges for question retrieval in CQA.", "labels": [], "entities": [{"text": "question retrieval", "start_pos": 86, "end_pos": 104, "type": "TASK", "confidence": 0.7687307894229889}]}, {"text": "State-of-the-art approaches address these issues by implicitly expanding the queried questions with additional words or phrases using mono-lingual translation models.", "labels": [], "entities": []}, {"text": "While useful , the effectiveness of these models is highly dependent on the availability of quality parallel monolingual corpora (e.g., question-answer pairs) in the absence of which they are troubled by noise issue.", "labels": [], "entities": []}, {"text": "In this work, we propose an alternative way to address the word ambiguity and word mismatch problems by taking advantage of potentially rich semantic information drawn from other languages.", "labels": [], "entities": []}, {"text": "Our proposed method employs statistical machine translation to improve question retrieval and enriches the question representation with the translated words from other languages via matrix factorization.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 28, "end_pos": 59, "type": "TASK", "confidence": 0.6936833461125692}, {"text": "question retrieval", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.8007446825504303}]}, {"text": "Experiments conducted on areal CQA data show that our proposed approach is promising.", "labels": [], "entities": [{"text": "CQA data", "start_pos": 31, "end_pos": 39, "type": "DATASET", "confidence": 0.7655020654201508}]}], "introductionContent": [{"text": "With the development of Web 2.0, community question answering (CQA) services like Yahoo!", "labels": [], "entities": [{"text": "community question answering (CQA)", "start_pos": 33, "end_pos": 67, "type": "TASK", "confidence": 0.7788774420817693}]}, {"text": "Answers, Baidu Zhidao 2 and WkiAnswers have attracted great attention from both academia and industry.", "labels": [], "entities": [{"text": "Answers", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9365795850753784}, {"text": "WkiAnswers", "start_pos": 28, "end_pos": 38, "type": "DATASET", "confidence": 0.9709976315498352}]}, {"text": "In CQA, anyone can ask and answer questions on any topic, and people seeking information are connected to those who know the answers.", "labels": [], "entities": []}, {"text": "As answers are usually explicitly provided by human, they can be helpful in answering real world questions.", "labels": [], "entities": [{"text": "answering real world questions", "start_pos": 76, "end_pos": 106, "type": "TASK", "confidence": 0.8283798843622208}]}, {"text": "In this paper, we focus on the task of question retrieval.", "labels": [], "entities": [{"text": "question retrieval", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.8305913507938385}]}, {"text": "Question retrieval in CQA can automatically find the most relevant and recent questions (historical questions) that have been solved by other users, and then the best answers of these historical questions will be used to answer the users' queried questions.", "labels": [], "entities": [{"text": "Question retrieval", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7287150621414185}, {"text": "CQA", "start_pos": 22, "end_pos": 25, "type": "DATASET", "confidence": 0.9248784780502319}]}, {"text": "However, question retrieval is challenging partly due to the word ambiguity and word mismatch between the queried questions and the historical questions in the archives.", "labels": [], "entities": [{"text": "question retrieval", "start_pos": 9, "end_pos": 27, "type": "TASK", "confidence": 0.8786059319972992}]}, {"text": "Word ambiguity often causes the retrieval models to retrieve many historical questions that do not match the users' intent.", "labels": [], "entities": []}, {"text": "This problem is also amplified by the high diversity of questions and users.", "labels": [], "entities": []}, {"text": "For example, depending on different users, the word \"interest\" may refer to \"curiosity\", or \"a charge for borrowing money\".", "labels": [], "entities": []}, {"text": "Another challenge is word mismatch between the queried questions and the historical questions.", "labels": [], "entities": [{"text": "word mismatch", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.6825463622808456}]}, {"text": "The queried questions may contain words that are different from, but related to, the words in the relevant historical questions.", "labels": [], "entities": []}, {"text": "For example, if a queried question contains the word \"company\" but a relevant historical question instead contains the word \"firm\", then there is a mismatch and the historical question may not be easily distinguished from an irrelevant one.", "labels": [], "entities": []}, {"text": "Researchers have proposed the use of wordbased translation models () to solve the word mismatch problem.", "labels": [], "entities": [{"text": "wordbased translation", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.702856570482254}]}, {"text": "As a principle approach to capture semantic word relations, wordbased translation models are built by using the IBM model 1 ( and have been shown to outperform traditional models (e.g., VSM, BM25, LM) for question retrieval.", "labels": [], "entities": [{"text": "wordbased translation", "start_pos": 60, "end_pos": 81, "type": "TASK", "confidence": 0.6905265152454376}, {"text": "IBM model 1", "start_pos": 112, "end_pos": 123, "type": "DATASET", "confidence": 0.879552443822225}, {"text": "BM25", "start_pos": 191, "end_pos": 195, "type": "DATASET", "confidence": 0.5572100877761841}, {"text": "question retrieval", "start_pos": 205, "end_pos": 223, "type": "TASK", "confidence": 0.8199058771133423}]}, {"text": "Besides, and proposed the phrase-based translation models for question and answer retrieval.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 26, "end_pos": 50, "type": "TASK", "confidence": 0.7014979124069214}, {"text": "question and answer retrieval", "start_pos": 62, "end_pos": 91, "type": "TASK", "confidence": 0.6832340955734253}]}, {"text": "The basic idea is to capture the contextual information in modeling the translation of phrases as a whole, thus the word ambiguity problem is somewhat alleviated.", "labels": [], "entities": []}, {"text": "However, all these existing studies in the literature are basically monolingual approaches which are restricted to the use of original language of questions.", "labels": [], "entities": []}, {"text": "While useful, the effectiveness of these models is highly dependent on the availability of quality parallel monolingual corpora (e.g., question-answer pairs) in the absence of which they are troubled by noise issue.", "labels": [], "entities": []}, {"text": "In this work, we propose an alternative way to address the word ambiguity and word mismatch problems by taking advantage of potentially rich semantic information drawn from other languages.", "labels": [], "entities": []}, {"text": "Through other languages, various ways of adding semantic information to a question could be available, thereby leading to potentially more improvements than using the original language only.", "labels": [], "entities": []}, {"text": "Taking a step toward using other languages, we propose the use of translated representation by alternatively enriching the original questions with the words from other languages.", "labels": [], "entities": []}, {"text": "The idea of improving question retrieval with statistical machine translation is based on the following two observations: (1) Contextual information is exploited during the translation from one language to another.", "labels": [], "entities": [{"text": "question retrieval", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.8335967063903809}, {"text": "statistical machine translation", "start_pos": 46, "end_pos": 77, "type": "TASK", "confidence": 0.6335579256216685}]}, {"text": "For example in, English words \"interest\" and \"bank\" that have multiple meanings under different contexts are correctly addressed by using the state-of-the-art translation tool \u2212\u2212Google Translate.", "labels": [], "entities": []}, {"text": "Thus, word ambiguity based on contextual information is naturally involved when questions are translated.", "labels": [], "entities": []}, {"text": "(2) Multiple words that have similar meanings in one language maybe translated into an unique word or a few words in a foreign language.", "labels": [], "entities": []}, {"text": "For example in, English words such as \"company\" and \"firm\" are translated into \"\u516c\u53f8 (g\u014dngs\u012b)\", \"rheum\" and \"catarrh\" are translated into \"\u611f \u5192(g\u01cenm\u00e0o)\" in Chinese.", "labels": [], "entities": []}, {"text": "Thus, word mismatch problem can be somewhat alleviated by using other languages.", "labels": [], "entities": [{"text": "word mismatch", "start_pos": 6, "end_pos": 19, "type": "TASK", "confidence": 0.7304114103317261}]}, {"text": "Although exploited bilingual translation for question retrieval and obtained the better performance than traditional monolingual translation models.", "labels": [], "entities": [{"text": "question retrieval", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.8280631303787231}]}, {"text": "However, there are two problems with this enrichment: (1) enriching the original questions with the translated words from other languages increases the dimensionality and makes the question representation even more sparse; (2) statistical machine translation may introduce noise, which can harm the performance of question retrieval.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 227, "end_pos": 258, "type": "TASK", "confidence": 0.6326290170351664}, {"text": "question retrieval", "start_pos": 314, "end_pos": 332, "type": "TASK", "confidence": 0.7315051555633545}]}, {"text": "To solve these two problems, we propose to leverage statistical machine translation to improve question retrieval via matrix factorization.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 52, "end_pos": 83, "type": "TASK", "confidence": 0.6717332402865092}, {"text": "question retrieval", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.7637976706027985}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the proposed method by leveraging statistical machine translation to improve question retrieval via matrix factorization.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 54, "end_pos": 85, "type": "TASK", "confidence": 0.6323409577210745}, {"text": "question retrieval", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.7682361900806427}]}, {"text": "Section 3 presents the experimental results.", "labels": [], "entities": []}, {"text": "In section 4, we conclude with ideas for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "We collect the data set from Yahoo!", "labels": [], "entities": [{"text": "data set from Yahoo!", "start_pos": 15, "end_pos": 35, "type": "DATASET", "confidence": 0.7475192189216614}]}, {"text": "Answers and use the getByCategory function provided in Yahoo!", "labels": [], "entities": []}, {"text": "Answers API 6 to obtain CQA threads from the Yahoo!", "labels": [], "entities": []}, {"text": "More specifically, we utilize the resolved questions and the resulting question repository that we use for question retrieval contains 2,288,607 questions.", "labels": [], "entities": [{"text": "question retrieval", "start_pos": 107, "end_pos": 125, "type": "TASK", "confidence": 0.7216804921627045}]}, {"text": "Each resolved question consists of four parts: \"question title\", \"question description\", \"question answers\" and \"question category\".", "labels": [], "entities": []}, {"text": "For question retrieval, we only use the \"question title\" part.", "labels": [], "entities": [{"text": "question retrieval", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.8507656157016754}]}, {"text": "It is assumed that question title already provides enough semantic information for understanding the users' information needs (  at the first level and 1,262 categories at the leaf level.", "labels": [], "entities": []}, {"text": "Each question belongs to a unique leaf category.", "labels": [], "entities": []}, {"text": "shows the distribution across firstlevel categories of the questions in the archives.", "labels": [], "entities": []}, {"text": "We use the same test set in previous work.", "labels": [], "entities": []}, {"text": "This set contains 252 queried questions and can be freely downloaded for research communities.", "labels": [], "entities": []}, {"text": "7 The original language of the above data set is English (l 1 ) and then they are translated into four other languages (Chinese (l 2 ), French (l 3 ), German (l 4 ), Italian (l 5 )), thus the number of language considered is P = 5) by using the state-of-the-art translation tool \u2212\u2212Google Translate.", "labels": [], "entities": []}, {"text": "Evaluation Metrics: We evaluate the performance of question retrieval using the following metrics: Mean Average Precision (MAP) and.", "labels": [], "entities": [{"text": "question retrieval", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.7740004062652588}, {"text": "Mean Average Precision (MAP)", "start_pos": 99, "end_pos": 127, "type": "METRIC", "confidence": 0.9740237891674042}]}, {"text": "MAP rewards methods that return relevant questions early and also rewards correct ranking of the results.", "labels": [], "entities": []}, {"text": "P@N reports the fraction of the top-N questions retrieved that are relevant.", "labels": [], "entities": [{"text": "P", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.8863813877105713}]}, {"text": "We perform a significant test, i.e., attest with a default significant level of 0.05.", "labels": [], "entities": []}, {"text": "We tune the parameters on a small development set of 50 questions.", "labels": [], "entities": []}, {"text": "This development set is also extracted from Yahoo!", "labels": [], "entities": [{"text": "Yahoo!", "start_pos": 44, "end_pos": 50, "type": "DATASET", "confidence": 0.9199988543987274}]}, {"text": "Answers, and it is not included in the test set.", "labels": [], "entities": []}, {"text": "For parameter K, we do an experiment on the development set to determine the optimal values among 50, 100, 150, \u00b7 \u00b7 \u00b7 , 300 in terms of MAP.", "labels": [], "entities": [{"text": "MAP", "start_pos": 136, "end_pos": 139, "type": "METRIC", "confidence": 0.7792463302612305}]}, {"text": "Finally, we set K = 100 in the experiments empirically as this setting yields the best performance.", "labels": [], "entities": [{"text": "K", "start_pos": 16, "end_pos": 17, "type": "METRIC", "confidence": 0.9505898952484131}]}, {"text": "For parameter \u03bb 1 , we set \u03bb 1 = 1 empirically, while for parameter \u03bb i (i \u2208 [2, P ]), we set \u03bb i = 0.25 empirically and ensure that \u2211 i \u03bb i = 1.", "labels": [], "entities": []}, {"text": "presents the main retrieval performance.", "labels": [], "entities": []}, {"text": "Row 1 and row 2 are two baseline systems, which model the relevance score using VSM ( and language model (LM)) in the term space.", "labels": [], "entities": []}, {"text": "Row 3 and row 6 are monolingual translation models to address the word mismatch problem and obtain the state-of-the-art performance in previous work.", "labels": [], "entities": []}, {"text": "Row 3 is the word-based translation model (, and row 4 is the wordbased translation language model, which linearly combines the word-based translation model and language model into a unified framework ().", "labels": [], "entities": [{"text": "word-based translation", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.6235625743865967}]}, {"text": "Row 5 is the phrase-based translation model, which translates a sequence of words as whole ().", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 13, "end_pos": 37, "type": "TASK", "confidence": 0.7136501669883728}]}, {"text": "Row 6 is the entitybased translation model, which extends the wordbased translation model and explores strategies to learn the translation probabilities between words and the concepts using the CQA archives and a popular entity catalog).", "labels": [], "entities": [{"text": "entitybased translation", "start_pos": 13, "end_pos": 36, "type": "TASK", "confidence": 0.6180989146232605}, {"text": "CQA archives", "start_pos": 194, "end_pos": 206, "type": "DATASET", "confidence": 0.9756132066249847}]}, {"text": "Row 7 is the bilingual translation model, which translates the English questions from Yahoo!", "labels": [], "entities": []}, {"text": "Answers into Chinese questions using Google Translate and expands the English words with the translated Chinese words ().", "labels": [], "entities": []}, {"text": "For these previous work, we use the same parameter settings in the original papers.", "labels": [], "entities": []}, {"text": "Row 8 and row 9 are our proposed method, which leverages statistical machine translation to improve question retrieval via matrix factorization.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 57, "end_pos": 88, "type": "TASK", "confidence": 0.6695511738459269}, {"text": "question retrieval", "start_pos": 100, "end_pos": 118, "type": "TASK", "confidence": 0.773767352104187}]}, {"text": "In row 8, we only consider two languages (English and Chinese) and translate English questions into Chinese using Google Translate in order to compare with.", "labels": [], "entities": []}, {"text": "In row 9, we translate English questions into other four languages.", "labels": [], "entities": []}, {"text": "There are some clear trends in the result of (1) Monolingual translation models significantly outperform the VSM and LM (row 1 and row 2 vs. row 3, row 4, row 5 and row 6).", "labels": [], "entities": [{"text": "Monolingual translation", "start_pos": 49, "end_pos": 72, "type": "TASK", "confidence": 0.8075578808784485}]}], "tableCaptions": [{"text": " Table 3: Comparison with different methods for  question retrieval.", "labels": [], "entities": [{"text": "question retrieval", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.8209355473518372}]}, {"text": " Table 4: The impact of matrix factorization.", "labels": [], "entities": []}]}