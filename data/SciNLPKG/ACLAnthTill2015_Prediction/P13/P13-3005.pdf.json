{"title": [{"text": "Survey on parsing three dependency representations for English", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we focus on practical issues of data representation for dependency parsing.", "labels": [], "entities": [{"text": "data representation", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.7255419194698334}, {"text": "dependency parsing", "start_pos": 70, "end_pos": 88, "type": "TASK", "confidence": 0.8629548847675323}]}, {"text": "We carryout an experimental comparison of (a) three syntactic dependency schemes; (b) three data-driven dependency parsers; and (c) the influence of two different approaches to lexical category disambiguation (aka tagging) prior to parsing.", "labels": [], "entities": [{"text": "lexical category disambiguation (aka tagging)", "start_pos": 177, "end_pos": 222, "type": "TASK", "confidence": 0.8100780418940953}]}, {"text": "Comparing parsing accuracies in various setups, we study the interactions of these three aspects and analyze which configurations are easier to learn fora dependency parser.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dependency parsing is one of the mainstream research areas in natural language processing.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9198856055736542}, {"text": "natural language processing", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.6493455767631531}]}, {"text": "Dependency representations are useful fora number of NLP applications, for example, machine translation (), information extraction (), analysis of typologically diverse languages and parser stacking ().", "labels": [], "entities": [{"text": "machine translation", "start_pos": 84, "end_pos": 103, "type": "TASK", "confidence": 0.8520409464836121}, {"text": "information extraction", "start_pos": 108, "end_pos": 130, "type": "TASK", "confidence": 0.8461319208145142}, {"text": "parser stacking", "start_pos": 183, "end_pos": 198, "type": "TASK", "confidence": 0.8603309988975525}]}, {"text": "There were several shared tasks organized on dependency parsing and labeled dependencies) and there were a number of attempts to compare various dependencies intrinsically, e.g. (, and extrinsically, e.g. (. In this paper we focus on practical issues of data representation for dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.7517694234848022}, {"text": "dependency parsing", "start_pos": 278, "end_pos": 296, "type": "TASK", "confidence": 0.7908377349376678}]}, {"text": "The central aspects of our discussion are (a) three dependency formats: two 'classic' representations for dependency parsing, namely, Stanford Basic (SB) and CoNLL Syntactic Dependencies (CD), and bilexical dependencies from the HPSG English Resource Grammar (ERG), so-called DELPH-IN Syntactic Derivation Tree (DT), proposed recently by; (b) three state-of-the art statistical parsers: Malt (), MST) and the parser of Bohnet and Nivre (2012); (c) two approaches to wordcategory disambiguation, e.g. exploiting common PTB tags and using supertags (i.e. specialized ERG lexical types).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 106, "end_pos": 124, "type": "TASK", "confidence": 0.7672134041786194}, {"text": "HPSG English Resource Grammar (ERG)", "start_pos": 229, "end_pos": 264, "type": "DATASET", "confidence": 0.8856733015605381}, {"text": "wordcategory disambiguation", "start_pos": 466, "end_pos": 493, "type": "TASK", "confidence": 0.7365281283855438}]}, {"text": "We parse the formats and compare accuracies in all configurations in order to determine how parsers, dependency representations and grammatical tagging methods interact with each other in application to automatic syntactic analysis.", "labels": [], "entities": [{"text": "automatic syntactic analysis", "start_pos": 203, "end_pos": 231, "type": "TASK", "confidence": 0.6507496237754822}]}, {"text": "SB and CD are derived automatically from phrase structures of Penn Treebank to accommodate the needs of fast and accurate dependency parsing, whereas DT is rooted in the formal grammar theory HPSG and is independent from any specific treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 62, "end_pos": 75, "type": "DATASET", "confidence": 0.9951736927032471}, {"text": "dependency parsing", "start_pos": 122, "end_pos": 140, "type": "TASK", "confidence": 0.7016899734735489}]}, {"text": "For DT we gain more expressivity from the underlying linguistic theory, which challenges parsing with statistical tools.", "labels": [], "entities": [{"text": "DT", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.9486347436904907}]}, {"text": "The structural analysis of the schemes in leads to the hypothesis that CD and DT are more similar to each other than SB to DT.", "labels": [], "entities": []}, {"text": "We recompute similarities on a larger treebank and check whether parsing results reflect them.", "labels": [], "entities": []}, {"text": "The paper has the following structure: an overview of related work is presented in Section 2; treebanks, tagsets, dependency schemes and parsers used in the experiments are introduced in Section 3; analysis of parsing results is discussed in Section 4; conclusions and future work are outlined in Section 5.", "labels": [], "entities": []}, {"text": "investigate which dependency representations of several syntactic structures are easier to parse with supervised versions of the, MST Parser, Malt and the Easy First Non-directional parser.", "labels": [], "entities": [{"text": "MST Parser", "start_pos": 130, "end_pos": 140, "type": "DATASET", "confidence": 0.8859400153160095}]}, {"text": "The results imply that all parsers consistently perform better when (a) coordination has one of the conjuncts as the head rather than the coordinating conjunction; and C: Annotation of coordination structure in SB, CD and DT (left to right) dependency formats (b) the noun phrase is headed by the noun rather than by determiner; (c) prepositions or subordinating conjunctions, rather than their NP or clause arguments, serve as the head in prepositional phrase or subordinated clauses.", "labels": [], "entities": [{"text": "Annotation", "start_pos": 171, "end_pos": 181, "type": "METRIC", "confidence": 0.9764630794525146}]}, {"text": "Therefore we can expect (a) Malt and MST to have fewer errors on coordination structures parsing SB and CD than parsing DT, because SB and CD choose the first conjunct as the head and DT chooses the coordinating conjunction as the head; (b,c) no significant differences for the errors on noun and prepositional phrases, because all three schemes have the noun as the head of the noun phrase and the preposition as the head of the prepositional phrase.", "labels": [], "entities": []}, {"text": "present intristic and extristic (event-extraction task) evaluation of six parsers (GDep, Bikel, Stanford, Charniak-Johnson, C&C and Enju parser) on three dependency formats (Stanford Dependencies, CoNLL-X, and Enju PAS).", "labels": [], "entities": []}, {"text": "Intristic evaluation results show that all parsers have the highest accuracies with the CoNLL-X format.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 68, "end_pos": 78, "type": "METRIC", "confidence": 0.9818999767303467}, {"text": "CoNLL-X format", "start_pos": 88, "end_pos": 102, "type": "DATASET", "confidence": 0.8127410411834717}]}], "datasetContent": [{"text": "In this section we give a detailed analysis of parsing into SB, CD and DT dependencies with Malt, MST and the Bohnet and Nivre (2012) parser.", "labels": [], "entities": [{"text": "parsing", "start_pos": 47, "end_pos": 54, "type": "TASK", "confidence": 0.9711554646492004}, {"text": "MST", "start_pos": 98, "end_pos": 101, "type": "DATASET", "confidence": 0.8050610423088074}]}], "tableCaptions": [{"text": " Table 1: Parsing results of Malt and MST on  Stanford Basic (SB), CoNLL Syntactic De- pendencies (CD) and DELPH-IN Syntactic  Derivation Tree (DT) formats. Punctuation is  excluded from the scoring. Gold PTB tags:  Malt and MST are trained and tested on gold  PTB tags. Gold supertags: Malt and MST  are trained and tested on gold supertags. Gold  PTB tags + gold supertags: Malt and MST are  trained on gold PTB tags and gold supertags.  1 denotes a feature model in which gold PTB  tags function as PoS and gold supertags act  as additional features (in CPOSTAG field); 2  stands for the feature model which exploits  gold supertags as PoS and uses gold PTB tags  as extra features (in CPOSTAG field).", "labels": [], "entities": []}, {"text": " Table 2: Parsing results of the Bohnet  and Nivre (2012) parser on Stanford Ba- sic (SB), CoNLL Syntactic Dependencies  (CD) and DELPH-IN Syntactic Deriva- tion Tree (DT) formats. Parser is trained  on gold-standard data. Punctuation is ex- cluded from the scoring. Predicted PTB:  parser predicts PTB tags during the test  phase. Predicted supertags: parser pre- dicts supertags during the test phase. Pre- dicted PTB + gold supertags: parser re- ceives gold supertags as feature and pre- dicts PTB tags during the test phase. Pre- dicted supertags + gold PTB: parser re- ceives PTB tags as feature and predicts  supertags during test phase.", "labels": [], "entities": [{"text": "Stanford Ba- sic (SB)", "start_pos": 68, "end_pos": 89, "type": "DATASET", "confidence": 0.8830780216625759}, {"text": "CoNLL Syntactic Dependencies  (CD) and DELPH-IN Syntactic Deriva- tion Tree (DT) formats", "start_pos": 91, "end_pos": 179, "type": "DATASET", "confidence": 0.7481484272900749}]}]}