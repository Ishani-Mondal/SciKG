{"title": [{"text": "Building and Evaluating a Distributional Memory for Croatian", "labels": [], "entities": [{"text": "Distributional Memory", "start_pos": 26, "end_pos": 47, "type": "TASK", "confidence": 0.911972165107727}]}], "abstractContent": [{"text": "We report on the first structured dis-tributional semantic model for Croatian, DM.HR.", "labels": [], "entities": []}, {"text": "It is constructed after the model of the English Distributional Memory (Ba-roni and Lenci, 2010), from a dependency-parsed Croatian web corpus, and covers about 2M lemmas.", "labels": [], "entities": []}, {"text": "We give details on the linguistic processing and the design principles.", "labels": [], "entities": []}, {"text": "An evaluation shows state-of-the-art performance on a semantic similarity task with particularly good performance on nouns.", "labels": [], "entities": []}, {"text": "The resource is freely available.", "labels": [], "entities": []}], "introductionContent": [{"text": "Most current work in lexical semantics is based on the Distributional Hypothesis, which posits a correlation between the degree of words' semantic similarity and the similarity of the contexts in which they occur.", "labels": [], "entities": []}, {"text": "Using this hypothesis, word meaning representations can be extracted from large corpora.", "labels": [], "entities": []}, {"text": "Words are typically represented as vectors whose dimensions correspond to context features.", "labels": [], "entities": []}, {"text": "The vector similarities, which are interpreted as semantic similarities, are used in numerous applications.", "labels": [], "entities": []}, {"text": "Most vector spaces in current use are either wordbased (co-occurrence defined by surface window, context words as dimensions) or syntax-based (cooccurrence defined syntactically, syntactic objects as dimensions).", "labels": [], "entities": []}, {"text": "Syntax-based models have several desirable properties.", "labels": [], "entities": []}, {"text": "First, they are model to fine-grained types of semantic similarity such as predicate-argument plausibility.", "labels": [], "entities": []}, {"text": "Second, they are more versatile - have presented a generic framework, the Distributional Memory (DM), which is applicable to a wide range of tasks beyond word similarity.", "labels": [], "entities": [{"text": "word similarity", "start_pos": 154, "end_pos": 169, "type": "TASK", "confidence": 0.7340503036975861}]}, {"text": "Third, they avoid the \"syntactic assumption\" inherent in word-based models, namely that context words are relevant iff they are in an n-word window around the target.", "labels": [], "entities": []}, {"text": "This property is particularly relevant for free word order languages with many long distance dependencies and non-projective structure.", "labels": [], "entities": []}, {"text": "Their obvious problem, of course, is that they require a large parsed corpus.", "labels": [], "entities": []}, {"text": "In this paper, we describe the construction of a Distributional Memory for Croatian (DM.HR), a free word order language.", "labels": [], "entities": []}, {"text": "To do so, we parse hrWaC), a 1.2B-token Croatian web corpus.", "labels": [], "entities": [{"text": "Croatian web corpus", "start_pos": 40, "end_pos": 59, "type": "DATASET", "confidence": 0.7120893001556396}]}, {"text": "We evaluate DM.HR on a synonym choice task, where it outperforms the standard bag-of-word model for nouns and verbs.", "labels": [], "entities": [{"text": "synonym choice task", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.8818997343381246}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Tagging, lemmatization, and parsing accu- racy", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9800149202346802}, {"text": "parsing accu- racy", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.8784335255622864}]}, {"text": " Table 2: Tuple extraction performance on SE- TIMES.HR", "labels": [], "entities": [{"text": "Tuple extraction", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.7854288518428802}, {"text": "SE- TIMES.HR", "start_pos": 42, "end_pos": 54, "type": "METRIC", "confidence": 0.3418237070242564}]}, {"text": " Table 4: Results on synonym choice task", "labels": [], "entities": []}]}