{"title": [{"text": "Improved Lexical Acquisition through DPP-based Verb Clustering", "labels": [], "entities": [{"text": "Improved Lexical Acquisition", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7676864465077718}]}], "abstractContent": [{"text": "Subcategorization frames (SCFs), selec-tional preferences (SPs) and verb classes capture related aspects of the predicate-argument structure.", "labels": [], "entities": []}, {"text": "We present the first unified framework for unsupervised learning of these three types of information.", "labels": [], "entities": []}, {"text": "We show how to utilize Determinantal Point Processes (DPPs), elegant proba-bilistic models that are defined over the possible subsets of a given dataset and give higher probability mass to high quality and diverse subsets, for clustering.", "labels": [], "entities": []}, {"text": "Our novel clustering algorithm constructs a joint SCF-DPP DPP kernel matrix and utilizes the efficient sampling algorithms of DPPs to cluster together verbs with similar SCFs and SPs.", "labels": [], "entities": []}, {"text": "We evaluate the induced clusters in the context of the three tasks and show results that are superior to strong baselines for each 1 .", "labels": [], "entities": []}], "introductionContent": [{"text": "Verb classes (VCs), subcategorization frames (SCFs) and selectional preferences (SPs) capture different aspects of predicate-argument structure.", "labels": [], "entities": []}, {"text": "SCFs describe the syntactic realization of verbal predicate-argument structure, SPs capture the semantic preferences verbs have for their arguments and VCs in the tradition provide a shared level of abstraction for verbs that share many aspects of their syntactic and semantic behavior.", "labels": [], "entities": []}, {"text": "These three of types of information have proved useful for Natural Language Processing (NLP) tasks which require information about predicateargument structure, including parsing), semantic role labeling (, and word sense disambiguation), among many others.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 180, "end_pos": 202, "type": "TASK", "confidence": 0.6684634288152059}, {"text": "word sense disambiguation", "start_pos": 210, "end_pos": 235, "type": "TASK", "confidence": 0.6585962076981863}]}, {"text": "Because lexical information is highly sensitive to domain variation, approaches that can identify VCs, SCFs and SPs in corpora have become increasingly popular, e.g. (O'; Schulte im.", "labels": [], "entities": []}, {"text": "The task of SCF induction involves identifying the arguments of a verb lemma and generalizing about the frames (i.e. SCFs) taken by the verb, where each frame includes a number of arguments and their syntactic types.", "labels": [], "entities": [{"text": "SCF induction", "start_pos": 12, "end_pos": 25, "type": "TASK", "confidence": 0.9845176935195923}]}, {"text": "For example, in (1), the verb \"show\" takes the frame SUBJ-DOBJ-CCOMP (subject, direct object, and clausal complement).", "labels": [], "entities": []}, {"text": "SP induction involves identifying and classifying the lexical items in a given argument slot.", "labels": [], "entities": [{"text": "SP induction", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.9840055704116821}]}, {"text": "In sentence (2), for example, the verb \"show\" takes the frame SUBJ-DOBJ.", "labels": [], "entities": []}, {"text": "The direct object in this frame is likely to be inanimate.", "labels": [], "entities": []}, {"text": "Finally, VC induction involves clustering together verbs with similar meaning, reflected in similar SCFs and SPs.", "labels": [], "entities": [{"text": "VC induction", "start_pos": 9, "end_pos": 21, "type": "TASK", "confidence": 0.9472588300704956}]}, {"text": "For example, \"show\" in the above examples could get clustered together with \"demonstrate\" and \"indicate\".", "labels": [], "entities": []}, {"text": "Because these challenging tasks capture complementary information about predicate argument structure, they should be able to inform and support each other.", "labels": [], "entities": []}, {"text": "Recently, researchers have begun to investigate the benefits of their joint learning.", "labels": [], "entities": []}, {"text": "Schulte im integrated SCF and VC acquisition and used it for WordNet-based SP classification.", "labels": [], "entities": [{"text": "VC acquisition", "start_pos": 30, "end_pos": 44, "type": "TASK", "confidence": 0.6652829349040985}, {"text": "WordNet-based SP classification", "start_pos": 61, "end_pos": 92, "type": "TASK", "confidence": 0.7155513862768809}]}, {"text": "\u00b4 O S\u00e9aghdha (2010) presented a \"dual-topic\" model for SPs that induces also verb clusters.", "labels": [], "entities": [{"text": "\u00b4 O S\u00e9aghdha", "start_pos": 0, "end_pos": 12, "type": "DATASET", "confidence": 0.7199135621388754}, {"text": "SPs", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.9632185697555542}]}, {"text": "Both works reported SP evaluation with promising results.", "labels": [], "entities": [{"text": "SP", "start_pos": 20, "end_pos": 22, "type": "METRIC", "confidence": 0.8429084420204163}]}, {"text": "presented a joint model for inducing simple syntactic frames and VCs.", "labels": [], "entities": []}, {"text": "They reported high accuracy results on VCs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9991981387138367}, {"text": "VCs", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9378468990325928}]}, {"text": "de introduced a joint model for SCF and SP acquisition.", "labels": [], "entities": [{"text": "SCF", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.8403985500335693}, {"text": "SP acquisition", "start_pos": 40, "end_pos": 54, "type": "TASK", "confidence": 0.7860988676548004}]}, {"text": "They evaluated both the SCFs and SPs, obtaining reasonable result on both tasks.", "labels": [], "entities": []}, {"text": "In this paper, we present the first unified framework for unsupervised learning of the three types of information -SCFs, SPs and VCs.", "labels": [], "entities": []}, {"text": "Our framework is based on Determinantal Point Processes), elegant probabilistic models that are defined over the possible subsets of a given dataset and give higher probability mass to high quality and diverse subsets.", "labels": [], "entities": []}, {"text": "We first show how individual-task DPP kernel matrices can be naturally combined to construct a joint kernel.", "labels": [], "entities": []}, {"text": "We use this to construct a joint SCF-SP kernel.", "labels": [], "entities": []}, {"text": "We then introduce a novel clustering algorithm based on iterative DPP sampling which can (contrary to other probabilistic frameworks such as Markov random fields) be performed both accurately and efficiently.", "labels": [], "entities": []}, {"text": "When defined over the joint SCF and SP kernel, this new algorithm can be used to induce VCs that are valuable for both tasks.", "labels": [], "entities": []}, {"text": "We also contribute by evaluating the value of the clusters induced by our model for the acquisition of the three information types.", "labels": [], "entities": []}, {"text": "Our evaluation against a well-known VC gold standard shows that our clustering model outperforms the state-of-theart verb clustering algorithm of, in our setup where no manually created SCF or SP data is available.", "labels": [], "entities": []}, {"text": "Our evaluation against a well-known SCF gold standard and in the context of SP disambiguation tasks shows results that are superior to strong baselines, demonstrating the benefit our approach.", "labels": [], "entities": [{"text": "SP disambiguation tasks", "start_pos": 76, "end_pos": 99, "type": "TASK", "confidence": 0.9389726718266805}]}], "datasetContent": [{"text": "Data sets and gold standards We evaluated the SCFs and verb clusters on gold standard datasets.", "labels": [], "entities": []}, {"text": "We based our set of the largest available joint set for SCFs and VCs -that of (de.", "labels": [], "entities": []}, {"text": "It provides SCF annotations for 183 verbs (an average of 12.3 SCF types per verb) obtained by annotating 250 corpus occurrences per verb with the SCF types of (de).", "labels": [], "entities": []}, {"text": "The verbs represent a range of Levin classes at the top level of the hierarchy in VerbNet).", "labels": [], "entities": []}, {"text": "Where a verb has more than one VerbNet class, we assign it to the one supported by the highest number of member verbs.", "labels": [], "entities": []}, {"text": "To ensure suf-: Performance of the Corpus Statistics SP baseline (non-filtered, NF) as well as for three filtering methods: frequency based (filter-baseline, B), DPP-cluster based (DPP) and AC cluster based (AC).", "labels": [], "entities": [{"text": "Corpus Statistics SP baseline", "start_pos": 35, "end_pos": 64, "type": "DATASET", "confidence": 0.8965263813734055}]}, {"text": "P (method) and R (method) present the precision and recall of the method respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9994799494743347}, {"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.998618483543396}]}, {"text": "The error reduction ratio (ERR) is the ratio between the reduction in precision error achieved by each method and the increase in recall error (each method is compared to the NF baseline).", "labels": [], "entities": [{"text": "error reduction ratio (ERR)", "start_pos": 4, "end_pos": 31, "type": "METRIC", "confidence": 0.9595896601676941}, {"text": "precision error", "start_pos": 70, "end_pos": 85, "type": "METRIC", "confidence": 0.984996885061264}, {"text": "recall error", "start_pos": 130, "end_pos": 142, "type": "METRIC", "confidence": 0.9900675714015961}]}, {"text": "Ratio greater than 1 means that the reduction in precision error is larger than the increase in recall error (see text for exact definition).", "labels": [], "entities": [{"text": "Ratio", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9582939147949219}, {"text": "precision error", "start_pos": 49, "end_pos": 64, "type": "METRIC", "confidence": 0.9855153560638428}, {"text": "recall error", "start_pos": 96, "end_pos": 108, "type": "METRIC", "confidence": 0.9918920695781708}]}, {"text": "DPP based filtering provides substantially better ratio.", "labels": [], "entities": []}, {"text": "ficient representation of each class, we collected from VerbNet the verbs for which at least one of the possible classes is represented in the 183 verbs set by at least one and at most seven verbs.", "labels": [], "entities": [{"text": "VerbNet", "start_pos": 56, "end_pos": 63, "type": "DATASET", "confidence": 0.9430729150772095}]}, {"text": "This yielded 101 additional verbs which we added to the gold standard with the initial 183 verbs.", "labels": [], "entities": []}, {"text": "We parsed the BNC corpus with the RASP parser () and used it for feature extraction.", "labels": [], "entities": [{"text": "BNC corpus", "start_pos": 14, "end_pos": 24, "type": "DATASET", "confidence": 0.9137611389160156}, {"text": "RASP parser", "start_pos": 34, "end_pos": 45, "type": "TASK", "confidence": 0.6407063007354736}, {"text": "feature extraction", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.777417927980423}]}, {"text": "Since 176 out of the 183 initial verbs are represented in this corpus, our final gold standard consists of 34 classes containing 277 verbs, of which 176 have SCF gold standard and has been evaluated for this task.", "labels": [], "entities": [{"text": "SCF gold standard", "start_pos": 158, "end_pos": 175, "type": "METRIC", "confidence": 0.8658893704414368}]}, {"text": "We set the parameters of our algorithm on an held-out data, consisting of different verbs than those used in our experiments, to be M = 10000, K = 20 and T = 10.", "labels": [], "entities": [{"text": "M", "start_pos": 132, "end_pos": 133, "type": "METRIC", "confidence": 0.9527040719985962}, {"text": "T", "start_pos": 154, "end_pos": 155, "type": "METRIC", "confidence": 0.9908095598220825}]}, {"text": "Clustering Evaluation We first evaluate the quality of the clusters induced by our algorithm (DPP-cluster) compared to the gold standard VCs (table 1).", "labels": [], "entities": []}, {"text": "To evaluate the importance of the DPP component, we compare to the performance of aversion of our algorithm where everything is kept fixed except from the sampling which is done from a uniform distribution rather than from the DPP joint kernel (this model is denoted in the table with AC for agglomerative clustering) . We also compare to the state-of-the-art spectral clustering method of where our kernel matrix is used for the distance between data points (SC) . We evaluated the unified cluster set induced in each iteration of our algorithm and of the AC baseline and induced the same number of clusters as in each iteration of our algorithm using the SC baseline.", "labels": [], "entities": []}, {"text": "Since the number of clusters in each iteration is not an argument for our algorithm or for the AC baseline, the number of clusters slightly differ between the two.", "labels": [], "entities": []}, {"text": "The AC and SC baseline results were averaged over 5 and 100 runs respectively.", "labels": [], "entities": []}, {"text": "DPP-cluster has produced identical output across runs.", "labels": [], "entities": [{"text": "DPP-cluster", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.95052570104599}]}, {"text": "The table demonstrates the superiority of the DPP-cluster model.", "labels": [], "entities": []}, {"text": "For four out of five conditions its F-score performance outperforms the baselines by 4.2-8.3%.", "labels": [], "entities": [{"text": "F-score", "start_pos": 36, "end_pos": 43, "type": "METRIC", "confidence": 0.9993904829025269}]}, {"text": "Moreover, in all conditions its recall performances are substantially higher than those of the baselines (by 9.7-26.1%).", "labels": [], "entities": [{"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9995788931846619}]}, {"text": "Note that DPPcluster runs for 17 iterations while the AC baseline performs only 6.", "labels": [], "entities": [{"text": "DPPcluster", "start_pos": 10, "end_pos": 20, "type": "DATASET", "confidence": 0.7303247451782227}]}, {"text": "We therefore evaluated only the last 5 iterations of each model . SCF evaluation For this evaluation, we first built a baseline SCF lexicon based on the parsed Algorithm 1 The DPP-cluster clustering algorithm.", "labels": [], "entities": [{"text": "DPP-cluster clustering", "start_pos": 176, "end_pos": 198, "type": "TASK", "confidence": 0.734323650598526}]}, {"text": "K is the size of the sampled subsets, M is the number of subsets sampled at each iteration, Y is the verb set, T is the number of most probable samples to be used in each iteration Algorithm DPP-cluster : Arguments: topSamples,L Return: SS \u2190 \u2205, topSample \u2190 \u2205 i \u2190 1 while (topSample \u2229 elements(S) = \u2205) do topSample \u2190 topSamples(i) S \u2190 m1M apping(topSample, S) i \u2190 i + 1 if (i > size(topSamples)) then return S end if end while BNC corpus.", "labels": [], "entities": [{"text": "BNC corpus", "start_pos": 426, "end_pos": 436, "type": "DATASET", "confidence": 0.7523066103458405}]}, {"text": "We do this by gathering the GR combinations for each of the verbs in our gold standard, assuming they are frames and gathering their frequencies.", "labels": [], "entities": [{"text": "GR", "start_pos": 28, "end_pos": 30, "type": "METRIC", "confidence": 0.7975755929946899}]}, {"text": "Note that this corpus statistics baseline is a very strong baseline that performs very similarly to, the best unsupervised SCF model we are aware of, when run on their dataset 7 . As shown in table 3 the corpus statistics baseline achieves high recall (84%) at the cost of low precision (52.5%) (similar pattern has been personal communication with the authors. demonstrated for the system of de).", "labels": [], "entities": [{"text": "recall", "start_pos": 245, "end_pos": 251, "type": "METRIC", "confidence": 0.9991480112075806}, {"text": "precision", "start_pos": 277, "end_pos": 286, "type": "METRIC", "confidence": 0.9969109892845154}]}, {"text": "On the other extreme, two other commonly used baselines strongly prefer precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9983633160591125}]}, {"text": "These are the Most Frequent SCF (O') which uniformly assigns to all verbs the two most frequent SCFs in general language, transitive (SUBJ-DOBJ) and intransitive (SUBJ) (and results in poor F-score), and a filtering that removes frames with low corpus frequencies (which results in low recall even when trying to provide the maximum recall fora given precision level).", "labels": [], "entities": [{"text": "F-score", "start_pos": 190, "end_pos": 197, "type": "METRIC", "confidence": 0.995959460735321}, {"text": "recall", "start_pos": 286, "end_pos": 292, "type": "METRIC", "confidence": 0.9965469241142273}, {"text": "recall", "start_pos": 333, "end_pos": 339, "type": "METRIC", "confidence": 0.9706687927246094}, {"text": "precision", "start_pos": 351, "end_pos": 360, "type": "METRIC", "confidence": 0.9575448632240295}]}, {"text": "The task we address is therefore to improve the precision of the corpus statistics baseline in away that does not substantially harm the F-score.", "labels": [], "entities": [{"text": "precision", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9994847774505615}, {"text": "F-score", "start_pos": 137, "end_pos": 144, "type": "METRIC", "confidence": 0.9934093952178955}]}, {"text": "To remedy this imbalance, we apply a cluster based filtering method on top of the maximumrecall frequency filter.", "labels": [], "entities": []}, {"text": "This filter excludes a candidate frame from a verb's lexicon only if it meets the frequency filter criterion and appears in no more than N other members of the cluster of the verb in question.", "labels": [], "entities": []}, {"text": "The filter utilizes the clustering produced by the seventh to last iteration of DPPcluster that contains seven clusters with approximately 30 members each.", "labels": [], "entities": [{"text": "DPPcluster", "start_pos": 80, "end_pos": 90, "type": "DATASET", "confidence": 0.9441590905189514}]}, {"text": "Such clustering should provide a good generalization level for the task.", "labels": [], "entities": []}, {"text": "We report results for moderate as well as aggressive filtering (N = 3 and N = 7 respectively).", "labels": [], "entities": []}, {"text": "clearly demonstrates that cluster based filtering (DPP-cluster and AC) is the only method that provides a good balance between the recall and the precision of the SCF lexicon.", "labels": [], "entities": [{"text": "recall", "start_pos": 131, "end_pos": 137, "type": "METRIC", "confidence": 0.9988439083099365}, {"text": "precision", "start_pos": 146, "end_pos": 155, "type": "METRIC", "confidence": 0.9986500144004822}]}, {"text": "Moreover, the lexicon induced by this method includes a substantially higher number of frames per verb compared to the other filtering methods.", "labels": [], "entities": []}, {"text": "While both AC and DPP-cluster still prefer recall to precision, DPP-cluster does so to a smaller extent 8 . This clearly demonstrates that the clustering serves to provide SCF acquisition with semantic information needed for improved performance.", "labels": [], "entities": [{"text": "recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.9960647225379944}, {"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9950403571128845}, {"text": "SCF acquisition", "start_pos": 172, "end_pos": 187, "type": "TASK", "confidence": 0.9486550390720367}]}, {"text": "SP evaluation We explore a variant of the pseudo-disambiguation task of which has been applied to SP acquisition by a number of recent papers (e.g. (de).", "labels": [], "entities": [{"text": "SP evaluation", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9521481394767761}, {"text": "SP acquisition", "start_pos": 98, "end_pos": 112, "type": "TASK", "confidence": 0.9812282621860504}]}, {"text": "proposed to judge which of two verbs v and\u02dcvand\u02dc and\u02dcv is more likely to take a given noun n as its argument.", "labels": [], "entities": []}, {"text": "In their experiments the model has to choose between a pair (v, n) that Corpus Statistics: [P = 52.5, R = 84, F = 64.6, AF = 12  appears only in the test corpus and a pair (\u02dc v, n) that appears neither in the test nor in the training corpus.", "labels": [], "entities": [{"text": "Corpus Statistics", "start_pos": 72, "end_pos": 89, "type": "DATASET", "confidence": 0.7499539852142334}, {"text": "AF = 12", "start_pos": 120, "end_pos": 127, "type": "METRIC", "confidence": 0.9605274796485901}]}, {"text": "Note, however, that this test only evaluates the capability of a model to distinguish a correct unseen verb-argument pair from an incorrect one, but not its capability to identify erroneous pairs when no alternative pair is presented.", "labels": [], "entities": []}, {"text": "This last property can strongly affect the precision of the model.", "labels": [], "entities": [{"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9993420243263245}]}, {"text": "We therefore propose to measure both aspects of the SP task by computing both the recall and the precision between the list of possible arguments a verb can take according to the model and the corresponding test corpus list . We evaluate the value of our clustering for SP acquisition in the particularly challenging scenario of domain adaptation.", "labels": [], "entities": [{"text": "SP task", "start_pos": 52, "end_pos": 59, "type": "TASK", "confidence": 0.9157127737998962}, {"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.999617338180542}, {"text": "precision", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9991082549095154}, {"text": "SP acquisition", "start_pos": 270, "end_pos": 284, "type": "TASK", "confidence": 0.9434187710285187}, {"text": "domain adaptation", "start_pos": 329, "end_pos": 346, "type": "TASK", "confidence": 0.7219013422727585}]}, {"text": "For each of the verbs in our set we induce a list of possible noun direct objects from the BNC corpus and an equivalent list from the North American News Text (NANT) corpus.) arguments are identified using a parser (RASP in our case).", "labels": [], "entities": [{"text": "BNC corpus", "start_pos": 91, "end_pos": 101, "type": "DATASET", "confidence": 0.9353070855140686}, {"text": "North American News Text (NANT) corpus.", "start_pos": 134, "end_pos": 173, "type": "DATASET", "confidence": 0.7603118531405926}]}, {"text": "Using the verb clusters we create a filtered version of the BNC argument lexicon which includes in the noun argument list of a verb only those nouns that appear in the BNC as arguments of that verb and of one of its cluster members.", "labels": [], "entities": [{"text": "BNC argument lexicon", "start_pos": 60, "end_pos": 80, "type": "DATASET", "confidence": 0.7342798709869385}]}, {"text": "For each verb we then compare the filtered as well as the non-filtered BNC induced lexicon to the NANT lexicon by computing the average recall and precision between the argument lists In principle these measures can take into account the probability assigned by the model to each argument and the corresponding test corpus frequency.", "labels": [], "entities": [{"text": "NANT lexicon", "start_pos": 98, "end_pos": 110, "type": "DATASET", "confidence": 0.9308785796165466}, {"text": "recall", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.9964302182197571}, {"text": "precision", "start_pos": 147, "end_pos": 156, "type": "METRIC", "confidence": 0.9962775111198425}]}, {"text": "In this work we compute probability-ignorant scores and keep more sophisticated evaluations for future research. and then report the average scores across all verbs.", "labels": [], "entities": []}, {"text": "We compare to a baseline which maintains only noun arguments that appear at least twice in BNC . As a final measure of performance we compute the ratio between the reduction in precision error (i.e. p model \u2212p baseline 100\u2212p baseline ) and the increase in recall error ( r baseline \u2212r model 100\u2212r model ).", "labels": [], "entities": [{"text": "precision error", "start_pos": 177, "end_pos": 192, "type": "METRIC", "confidence": 0.9889524281024933}, {"text": "recall error", "start_pos": 256, "end_pos": 268, "type": "METRIC", "confidence": 0.9900843799114227}]}, {"text": "presents the results for verbs with up to 200, 600 and 1000 noun arguments in the training data.", "labels": [], "entities": []}, {"text": "In all cases, the relative error reduction of the DPP cluster filter is substantially higher than that of the frequency baseline.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 27, "end_pos": 42, "type": "METRIC", "confidence": 0.885554850101471}]}, {"text": "Note that for this task the baseline AC clusters are of low quality which is reflects by an error reduction ratio of up to 0.5.", "labels": [], "entities": [{"text": "error reduction ratio", "start_pos": 92, "end_pos": 113, "type": "METRIC", "confidence": 0.9716432293256124}]}], "tableCaptions": [{"text": " Table 1: Verb clustering evaluation for the last five iterations of our DPP-cluster model and the baseline  agglomerative clustering algorithm (AC, see text for its description), and for the spectral clustering (SC)  algorithm of (Sun and Korhonen, 2009) with the same number of clusters induced by DPP-cluster. |C| is  the number of clusters for DPP-cluster and SC (first number) and for AC (second number). The F-score  performance of DPP-cluster is superior in 4 out of 5 cases.", "labels": [], "entities": [{"text": "Verb clustering", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.767498254776001}, {"text": "F-score", "start_pos": 414, "end_pos": 421, "type": "METRIC", "confidence": 0.9953472018241882}]}, {"text": " Table 2: Performance of the Corpus Statistics SP baseline (non-filtered, NF) as well as for three filtering  methods: frequency based (filter-baseline, B), DPP-cluster based (DPP) and AC cluster based (AC). P  (method) and R (method) present the precision and recall of the method respectively. The error reduc- tion ratio (ERR) is the ratio between the reduction in precision error achieved by each method and the  increase in recall error (each method is compared to the NF baseline). Ratio greater than 1 means that  the reduction in precision error is larger than the increase in recall error (see text for exact definition).  DPP based filtering provides substantially better ratio.", "labels": [], "entities": [{"text": "Corpus Statistics SP baseline", "start_pos": 29, "end_pos": 58, "type": "DATASET", "confidence": 0.7974980920553207}, {"text": "precision", "start_pos": 247, "end_pos": 256, "type": "METRIC", "confidence": 0.9985163807868958}, {"text": "recall", "start_pos": 261, "end_pos": 267, "type": "METRIC", "confidence": 0.9923602938652039}, {"text": "error reduc- tion ratio (ERR)", "start_pos": 300, "end_pos": 329, "type": "METRIC", "confidence": 0.8515124171972275}, {"text": "precision error", "start_pos": 368, "end_pos": 383, "type": "METRIC", "confidence": 0.9733649790287018}, {"text": "recall error", "start_pos": 429, "end_pos": 441, "type": "METRIC", "confidence": 0.9902549386024475}, {"text": "precision error", "start_pos": 538, "end_pos": 553, "type": "METRIC", "confidence": 0.9796743392944336}, {"text": "recall error", "start_pos": 585, "end_pos": 597, "type": "METRIC", "confidence": 0.985989511013031}]}, {"text": " Table 3: SCF Results for the DPP-cluster model compared to the Corpus Statistics baseline, Most Fre- quent SCF baseline, maximum-recall frequency thresholding with the maximum threshold values that  keep precision above 80 (threshold = 0.03) and above 90 (threshold = 0.05), and the AC clustering base- line. AF is the average number of frames per verb. All methods except from cluster based filtering  (DPP-cluster and AC) induce lexicons with strong recall/precision imbalance. Cluster based fil- tering keeps a larger number of frames in the lexicon compared to the frequency thresholding  baseline, while keeping similar F-score levels. DPP-cluster provides better recall/precision balance  than AC.", "labels": [], "entities": [{"text": "Corpus Statistics baseline", "start_pos": 64, "end_pos": 90, "type": "DATASET", "confidence": 0.9629281560579935}, {"text": "precision", "start_pos": 205, "end_pos": 214, "type": "METRIC", "confidence": 0.9916715025901794}, {"text": "AF", "start_pos": 310, "end_pos": 312, "type": "METRIC", "confidence": 0.9972800016403198}, {"text": "recall/precision imbalance", "start_pos": 453, "end_pos": 479, "type": "METRIC", "confidence": 0.8027702867984772}, {"text": "F-score", "start_pos": 626, "end_pos": 633, "type": "METRIC", "confidence": 0.9900875687599182}, {"text": "recall/precision balance", "start_pos": 670, "end_pos": 694, "type": "METRIC", "confidence": 0.7588024288415909}]}]}