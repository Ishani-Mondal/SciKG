{"title": [{"text": "Adding Domain Specificity to an MT system", "labels": [], "entities": [{"text": "MT", "start_pos": 32, "end_pos": 34, "type": "TASK", "confidence": 0.9571401476860046}]}], "abstractContent": [{"text": "In the development of a machine translation system, one important issue is being able to adapt to a specific domain without requiring time-consuming lexical work.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.7366848289966583}]}, {"text": "We have experimented with using a statistical word-alignment algorithm to derive word association pairs (French-English) that complement an existing multipurpose bilingual dictionary.", "labels": [], "entities": []}, {"text": "This word association information is added to the system at the time of the automatic creation of our translation pattern database, thereby making this database more domain specific.", "labels": [], "entities": []}, {"text": "This technique significantly improves the overall quality of translation, as measured in an independent blind evaluation.", "labels": [], "entities": [{"text": "translation", "start_pos": 61, "end_pos": 72, "type": "TASK", "confidence": 0.9718529582023621}]}], "introductionContent": [{"text": "The machine translation system described here is a French-English translation system which uses a French broad coverage analyzer, a large multi-purpose French dictionary, a large French-English bilingual lexicon, an application independent English natural language generation component and a transfer component.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.730350524187088}]}, {"text": "The transfer component consists of high-quality transfer patterns automatically acquired from sentence-aligned bilingual corpora using an alignment grammar and algorithm described in detail in (see for an overview of the French-English MT system).", "labels": [], "entities": [{"text": "MT", "start_pos": 236, "end_pos": 238, "type": "TASK", "confidence": 0.826993465423584}]}, {"text": "The transfer component consists only of correspondences learned during the alignment process.", "labels": [], "entities": []}, {"text": "Training takes place on aligned sentences which have been analyzed by the French and English analysis systems to yield dependency structures specific to our system entitled Logical Forms (LF).", "labels": [], "entities": []}, {"text": "The LF structures, when aligned, allow the extraction of lexical and structural translation correspondences which are stored for use at runtime in the transfer database.", "labels": [], "entities": []}, {"text": "The transfer database can also bethought of as an example-base of conceptual structure representations.", "labels": [], "entities": []}, {"text": "See for an illustration of the training process.", "labels": [], "entities": []}, {"text": "The transfer database for French-English was trained on approximately 200,000 pairs of aligned sentences from computer manuals and help files.", "labels": [], "entities": []}, {"text": "In these aligned pairs, the French text was produced by human translators from the original English version.", "labels": [], "entities": []}, {"text": "Sample sentences from the training set are: The French-English lexicon is used during the training period of the transfer component to establish initial, tentative, word correspondences during the alignment process.", "labels": [], "entities": []}, {"text": "The sources for the bilingual dictionary were: Cambridge University Press English-French, Soft-Art English-French, and Langenscheidt FrenchEnglish and English-French dictionaries.", "labels": [], "entities": [{"text": "Cambridge University Press English-French", "start_pos": 47, "end_pos": 88, "type": "DATASET", "confidence": 0.949187770485878}]}, {"text": "The English-French translation data was reversed to create French-English pairs in order to augment the size of the dictionary, with a final translation count of 75,000 pairs.", "labels": [], "entities": []}, {"text": "However, quick examination of the sample sentence above shows that many terms are highly specific to the domain, e.g menu D\u00e9marrer <-> Start menu.", "labels": [], "entities": []}, {"text": "To further add to the specificity of the vocabulary available to the alignment process, we added translation pairs extracted from the actual domain, using statistical word/phrase assignment, as described below.", "labels": [], "entities": [{"text": "statistical word/phrase assignment", "start_pos": 155, "end_pos": 189, "type": "TASK", "confidence": 0.6001145780086518}]}, {"text": "This resulted in one file of automatically created French English translation correspondences, or word associations (WA), and a second file of specialized multi-word translation correspondences which we term Title Associations (TA).", "labels": [], "entities": []}, {"text": "These files, of size 30,000 and 2600 respectively, added to the quality of the alignments and to overall translation quality.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate the relative quality of the translations with and without the word association and title association strategies, we performed several evaluations of machine translation quality.", "labels": [], "entities": []}, {"text": "These evaluations were performed by an independent organization that provides support for NL application development; the evaluators are completely independent of development activities.", "labels": [], "entities": [{"text": "NL application development", "start_pos": 90, "end_pos": 116, "type": "TASK", "confidence": 0.8766918778419495}]}, {"text": "We performed two separate sets of evaluations.", "labels": [], "entities": []}, {"text": "In the first, we evaluated the full version of our system with the Word Association and Title Association components against versions of the system from which we had removed those components.", "labels": [], "entities": [{"text": "Word Association and Title Association", "start_pos": 67, "end_pos": 105, "type": "DATASET", "confidence": 0.7147004008293152}]}, {"text": "We thus expected that versions of the system with the WA and TA components would outperform those without.", "labels": [], "entities": [{"text": "WA", "start_pos": 54, "end_pos": 56, "type": "METRIC", "confidence": 0.5096568465232849}, {"text": "TA", "start_pos": 61, "end_pos": 63, "type": "METRIC", "confidence": 0.7563381195068359}]}, {"text": "In the second evaluation, we tested the versions of our system with and without the WA and TA components against a benchmark system (the latest release of the French-English Systran system, run with settings appropriate for the computer domain) to see whether the addition of the combination of these components would significantly improve our scores with respect to that benchmark.", "labels": [], "entities": [{"text": "WA", "start_pos": 84, "end_pos": 86, "type": "METRIC", "confidence": 0.7865808010101318}, {"text": "TA", "start_pos": 91, "end_pos": 93, "type": "METRIC", "confidence": 0.544106125831604}]}, {"text": "For each condition to be tested, seven evaluators were asked to evaluate the same set of 250 blind test sentences.", "labels": [], "entities": []}, {"text": "For each sentence, raters were presented with a reference sentence, the original English translation from which the human French translation was derived.", "labels": [], "entities": []}, {"text": "In order to maintain consistency among raters who may have different levels of fluency in the source language, raters were not shown the original French sentence (for similar methodologies, see.", "labels": [], "entities": []}, {"text": "Raters were also shown two machine translations, one from the system with the component being tested (System 1), and one from the comparison system (System 2).", "labels": [], "entities": []}, {"text": "Because the order of the two machine translation sentences was randomized on each sentence, evaluators could not determine which sentence was from System 1.", "labels": [], "entities": []}, {"text": "The order of presentation of sentences was also randomized for each rater in order to eliminate any ordering effect.", "labels": [], "entities": []}, {"text": "The raters were asked to make a three-way choice.", "labels": [], "entities": []}, {"text": "For each sentence, the raters were to determine which of the two automatically translated sentences was the better translation of the (unseen) source sentence, assuming that the reference sentence was a perfect translation, with the option of choosing \"neither\" if the differences were negligible.", "labels": [], "entities": []}, {"text": "Raters were instructed to use their best judgment about the relative importance of fluency/style and accuracy/content preservation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9962638020515442}, {"text": "content preservation", "start_pos": 110, "end_pos": 130, "type": "TASK", "confidence": 0.6421800255775452}]}, {"text": "We chose to use this simple three-way scale in order to avoid making any a priori judgments about the relative importance of these parameters for subjective judgments of quality.", "labels": [], "entities": []}, {"text": "The three-way scale also allows sentences to be rated on the same scale, regardless of whether the differences between output from system 1 and system 2 were substantial or relatively small; and regardless of whether either version of the system produced an adequate translation.", "labels": [], "entities": []}, {"text": "The scoring system is similarly simple; each judgment by a rater was represented as 1 (sentence from System 1 judged better), 0 (neither sentence judged better), or -1 (System 2 judged better).", "labels": [], "entities": []}, {"text": "The score for each condition is the mean of the scores of all sentences for all raters.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results with differences only", "labels": [], "entities": []}, {"text": " Table 2: Projected sample sizes", "labels": [], "entities": []}, {"text": " Table 3: Results across whole sample", "labels": [], "entities": []}, {"text": " Table 4: Results against Benchmark system.", "labels": [], "entities": [{"text": "Benchmark", "start_pos": 26, "end_pos": 35, "type": "DATASET", "confidence": 0.8656935095787048}]}, {"text": " Table 5: Increase in patterns kept", "labels": [], "entities": [{"text": "Increase", "start_pos": 10, "end_pos": 18, "type": "TASK", "confidence": 0.9019975662231445}]}]}