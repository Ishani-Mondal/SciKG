{"title": [{"text": "MAYA: A Fast Question-answering System Based On A Predictive Answer Indexer *", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a Question-answering (QA) system in Korean that uses a predictive answer indexer.", "labels": [], "entities": []}, {"text": "The predictive answer indexer, first, extracts all answer candidates in a document in indexing time.", "labels": [], "entities": []}, {"text": "Then, it gives scores to the adjacent content words that are closely related with each answer candidate.", "labels": [], "entities": []}, {"text": "Next, it stores the weighted content words with each candidate into a database.", "labels": [], "entities": []}, {"text": "Using this technique, along with a complementary analysis of questions, the proposed QA system can save response time because it is not necessary for the QA system to extract answer candidates with scores on retrieval time.", "labels": [], "entities": []}, {"text": "If the QA system is combined with a traditional Information Retrieval system, it can improve the document retrieval precision for closed-class questions after minimum loss of retrieval time.", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 48, "end_pos": 69, "type": "TASK", "confidence": 0.6873955279588699}, {"text": "document retrieval", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.6363363862037659}, {"text": "precision", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.8556454181671143}]}], "introductionContent": [], "datasetContent": [{"text": "In order to experiment on MAYA, we collected 14,321 documents (65,752 kilobytes) from two web sites: korea.internet.com (6,452 documents) and www.sogang.ac.kr (7,869 documents).", "labels": [], "entities": [{"text": "MAYA", "start_pos": 26, "end_pos": 30, "type": "DATASET", "confidence": 0.7432675361633301}]}, {"text": "The former gives the members on-line articles on Information Technology (IT).", "labels": [], "entities": []}, {"text": "The latter is a homepage of Sogang University.", "labels": [], "entities": [{"text": "Sogang University", "start_pos": 28, "end_pos": 45, "type": "DATASET", "confidence": 0.9296330213546753}]}, {"text": "The indexing engine created the 14 answer DBs (14 semantic categories).", "labels": [], "entities": []}, {"text": "For the test data, we collected 50 pairs of question-answers from 10 graduate students.", "labels": [], "entities": []}, {"text": "With respect to the total system that combines MAYA with the IR system, we use the Reciprocal Document Rank (RDR) and the Mean Reciprocal Document Rank (MRDR).", "labels": [], "entities": [{"text": "MAYA", "start_pos": 47, "end_pos": 51, "type": "DATASET", "confidence": 0.8019434213638306}, {"text": "Reciprocal Document Rank (RDR)", "start_pos": 83, "end_pos": 113, "type": "METRIC", "confidence": 0.7339171568552653}, {"text": "Mean Reciprocal Document Rank (MRDR)", "start_pos": 122, "end_pos": 158, "type": "METRIC", "confidence": 0.8650997451373509}]}, {"text": "RDR means the reciprocal rank of the first document including the correct answers given by each question.", "labels": [], "entities": [{"text": "RDR", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9792293310165405}]}, {"text": "The performance of MAYA is shown in.", "labels": [], "entities": [{"text": "MAYA", "start_pos": 19, "end_pos": 23, "type": "DATASET", "confidence": 0.7670809626579285}]}, {"text": "We obtained the correct answers for 33 questions out of 50 in Top 1..", "labels": [], "entities": []}, {"text": "The performance of the QA system shows the performance of the total system.", "labels": [], "entities": []}, {"text": "As shown in, the total system significantly improves the document retrieval performance of underlying IR system about the closed-class questions.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. The number of the collected question- answers in each category", "labels": [], "entities": []}, {"text": " Table 2.  We obtained the correct answers for 33  questions out of 50 in Top 1.", "labels": [], "entities": []}, {"text": " Table 2. The performance of the QA system", "labels": [], "entities": []}]}