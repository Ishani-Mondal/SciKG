{"title": [], "abstractContent": [{"text": "This paper reports on the LEARNING COMPUTATIONAL GRAMMARS (LCG) project, a postdoc network devoted to studying the application of machine learning techniques to grammars suitable for computational use.", "labels": [], "entities": [{"text": "LEARNING COMPUTATIONAL GRAMMARS (LCG", "start_pos": 26, "end_pos": 62, "type": "METRIC", "confidence": 0.6192439675331116}]}, {"text": "We were interested in a more systematic survey to understand the relevance of many factors to the success of learning, esp.", "labels": [], "entities": []}, {"text": "the availability of annotated data, the kind of dependencies in the data, and the availability of knowledge bases (gram-mars).", "labels": [], "entities": []}, {"text": "We focused on syntax, esp.", "labels": [], "entities": []}, {"text": "noun phrase (NP) syntax.", "labels": [], "entities": [{"text": "noun phrase (NP) syntax", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.5883478969335556}]}], "introductionContent": [{"text": "This paper reports on the still preliminary, but already satisfying results of the LEARNING COM-PUTATIONAL GRAMMARS (LCG) project, a postdoc network devoted to studying the application of machine learning techniques to grammars suitable for computational use.", "labels": [], "entities": [{"text": "LEARNING COM-PUTATIONAL GRAMMARS (", "start_pos": 83, "end_pos": 117, "type": "METRIC", "confidence": 0.7729248404502869}]}, {"text": "The member institutes are listed with the authors and also included ISSCO at the University of Geneva.", "labels": [], "entities": [{"text": "ISSCO", "start_pos": 68, "end_pos": 73, "type": "DATASET", "confidence": 0.6703850626945496}]}, {"text": "We were impressed by early experiments applying learning to natural language, but dissatisfied with the concentration on a few techniques from the very rich area of machine learning.", "labels": [], "entities": []}, {"text": "We were interested in a more systematic survey to understand the relevance of many factors to the success of learning, esp.", "labels": [], "entities": []}, {"text": "the availability of annotated data, the kind of dependencies in the data, and the availability of knowledge bases (grammars).", "labels": [], "entities": []}, {"text": "We focused on syntax, esp.", "labels": [], "entities": []}, {"text": "noun phrase (NP) syntax from the beginning.", "labels": [], "entities": [{"text": "noun phrase (NP) syntax", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.5898936341206232}]}, {"text": "The industrial partner, Xerox, focused on more immediate applications).", "labels": [], "entities": [{"text": "Xerox", "start_pos": 24, "end_pos": 29, "type": "DATASET", "confidence": 0.8720400929450989}]}, {"text": "The network was focused not only by its scientific goal, the application and evaluation of machine-learning techniques as used to learn natural language syntax, and by the subarea of syntax chosen, NP syntax, but also by the use of shared training and test material, in this case material drawn from the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 304, "end_pos": 317, "type": "DATASET", "confidence": 0.9953953921794891}]}, {"text": "Finally, we were curious about the possibility of combining different techniques, including those from statistical and symbolic machine learning.", "labels": [], "entities": []}, {"text": "The network members played an important role in the organisation of three open workshops in which several external groups participated, sharing data and test materials.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The chunking results for the six systems  associated with the project (shared task CoNLL- 2000). The baseline results have been obtained  by selecting the most frequent chunk tag associ- ated with each part-of-speech tag. The best results  at CoNLL-2000 were obtained by Support Vector  Machines. A majority vote of the six LCG sys- tems does not perform much worse than this best  result. A majority vote of the five best systems  outperforms the best result slightly (0", "labels": [], "entities": [{"text": "CoNLL- 2000", "start_pos": 93, "end_pos": 104, "type": "DATASET", "confidence": 0.796995202700297}]}, {"text": " Table 2: The NP chunking results for six sys- tems associated with the project. The baseline  results have been obtained by selecting the most  frequent chunk tag associated with each part-of- speech tag. The best results for this task have  been obtained with a combination of seven learn- ers, five of which were operated by project mem- bers. The combination of these five performances  is not far off these best results.", "labels": [], "entities": [{"text": "NP chunking", "start_pos": 14, "end_pos": 25, "type": "TASK", "confidence": 0.850109189748764}]}]}