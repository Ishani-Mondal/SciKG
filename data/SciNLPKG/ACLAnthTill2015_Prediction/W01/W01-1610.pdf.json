{"title": [{"text": "Labeling Corrections and Aware Sites in Spoken Dialogue Systems", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper deals with user corrections and aware sites of system errors in the TOOT spoken dialogue system.", "labels": [], "entities": [{"text": "user corrections", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.7376691997051239}, {"text": "TOOT spoken dialogue system", "start_pos": 79, "end_pos": 106, "type": "DATASET", "confidence": 0.731900691986084}]}, {"text": "We \ud97b\udf59rst describe our corpus , and give details on our procedure to label corrections and aware sites.", "labels": [], "entities": []}, {"text": "Then, we show that corrections and aware sites exhibit some prosodic and other properties which set them apart from`normalfrom`normal' utterances.", "labels": [], "entities": []}, {"text": "It appears that some correction types, such as simple repeats, are more likely to be correctly recognized than other types, such a s pa r a-phrases.", "labels": [], "entities": []}, {"text": "We also present evidence that system dialogue strategy aects users' choice of correction type, suggesting that strategy-speciic methods of detecting or coaching users on corrections maybe useful.", "labels": [], "entities": [{"text": "system dialogue strategy aects users' choice of correction", "start_pos": 30, "end_pos": 88, "type": "TASK", "confidence": 0.7383173331618309}]}, {"text": "Aware sites tend to be shorter than other utterances, and are also more dif-\ud97b\udf59cult to recognize correctly for the ASR system.", "labels": [], "entities": [{"text": "ASR", "start_pos": 113, "end_pos": 116, "type": "TASK", "confidence": 0.938465416431427}]}], "introductionContent": [{"text": "Compared to many other systems, spoken dialogue systems (SDS) tend to have more diiculties in correctly interpreting user input.", "labels": [], "entities": [{"text": "spoken dialogue systems (SDS)", "start_pos": 32, "end_pos": 61, "type": "TASK", "confidence": 0.7097491125265757}, {"text": "interpreting user input", "start_pos": 104, "end_pos": 127, "type": "TASK", "confidence": 0.7989414930343628}]}, {"text": "Whereas a car will normally go left if the driver turns the steering wheel in that direction or a vacuum cleaner will start working if one pushes the on-button, interactions between a user and a spoken dialogue system are often hampered by mismatches between the action intended by the user and the action executed by the system.", "labels": [], "entities": []}, {"text": "Such mismatches are mainly due to errors in the Automatic Speech Recognition (ASR) and/or the Natural Language Understanding (NLU) component of these systems.", "labels": [], "entities": [{"text": "Automatic Speech Recognition (ASR)", "start_pos": 48, "end_pos": 82, "type": "TASK", "confidence": 0.7500008394320806}]}, {"text": "To solve these mismatches, users often have to put considerable eeort in trying to make it clear to the system that there was a problem, and trying to correct it by re-entering misrecognized or misinterpreted information.", "labels": [], "entities": []}, {"text": "Previous research has already brought to light t ha ti t is not always easy for users to determine whether their intended actions were carried out correctly or not, in particular when the dialogue system does not give appropriate feedback about its internal representation at the right moment.", "labels": [], "entities": []}, {"text": "In addition, users' corrections may miss their goal, because corrections themselves are more diicult for the system to recognize and interpret correctly, w hi ch ma y lead to so-called cyclic (or spiral) errors.", "labels": [], "entities": []}, {"text": "That corrections are diicult for ASR systems is generally explained by the fact that they tend to be hyperarticulated | higher, louder, longer . .", "labels": [], "entities": [{"text": "ASR", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9902785420417786}]}, {"text": ". than other turns (, where ASR models are not well adapted to handle this special speaking style.", "labels": [], "entities": []}, {"text": "The current paper focuses on user corrections, and looks at places where people \ud97b\udf59rst become aware of a system problem (\\aware sites\").", "labels": [], "entities": [{"text": "user corrections", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.796550840139389}]}, {"text": "In other papers (), we have already given some descriptive statistics on corrections and aware sites and we have beenlooking at methods to automatically predict these two utterance categories.", "labels": [], "entities": []}, {"text": "One of our major \ud97b\udf59ndings is that prosody, which had already been shown to bea good predictor of misrecognitions (), is also useful to correctly classify corrections and aware sites.", "labels": [], "entities": [{"text": "classify corrections", "start_pos": 144, "end_pos": 164, "type": "TASK", "confidence": 0.7668461799621582}]}, {"text": "In this paper, we will elaborate more on the exact labeling scheme we used, and add further descriptive statistics.", "labels": [], "entities": []}, {"text": "More in particular, we address the question whether there is much variance in the way people react to system errors, and if so, to what extent this variance can be explained on the basis of particular properties of the dialogue system.", "labels": [], "entities": []}, {"text": "In the following section we rst provide details on the TOOT corpus that we used for our analyses.", "labels": [], "entities": [{"text": "TOOT corpus", "start_pos": 55, "end_pos": 66, "type": "DATASET", "confidence": 0.9580155313014984}]}, {"text": "Then we give information on the labels for corrections and aware sites, and on the actual labeling procedure.", "labels": [], "entities": []}, {"text": "The next section gives the results of some descriptive statistics on properties of corrections and aware sites and on their distributions.", "labels": [], "entities": []}, {"text": "We will end the paper with a general discussion of our ndings.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Distribution of Correction Types", "labels": [], "entities": [{"text": "Distribution of Correction Types", "start_pos": 10, "end_pos": 42, "type": "TASK", "confidence": 0.8371044993400574}]}, {"text": " Table 2: Averages for diierent prosodic features of diierent Correction Types", "labels": [], "entities": []}, {"text": " Table 4: Distribution of single no utterances  and other turns for aware sites versus other  utterances", "labels": [], "entities": [{"text": "Distribution of single no utterances", "start_pos": 10, "end_pos": 46, "type": "TASK", "confidence": 0.7981483340263367}]}]}