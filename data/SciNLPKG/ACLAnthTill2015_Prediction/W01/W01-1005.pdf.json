{"title": [{"text": "Identification of relevant terms to support the construction of Domain Ontologies", "labels": [], "entities": [{"text": "Identification", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9835132956504822}]}], "abstractContent": [{"text": "Though the utility of domain Ontologies is now widely acknowledged in the IT (Information Technology) community, several barriers must be overcome before Ontologies become practical and useful tools.", "labels": [], "entities": []}, {"text": "One important achievement would be to reduce the cost of identifying and manually entering several thousand-concept descriptions.", "labels": [], "entities": []}, {"text": "This paper describes a text mining technique to aid an Ontology Engineer to identify the important concepts in a Domain Ontology.", "labels": [], "entities": [{"text": "text mining", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.7221041172742844}]}], "introductionContent": [{"text": "In cooperating to work together (or even in interacting in social settings), people and organizations must communicate among themselves.", "labels": [], "entities": []}, {"text": "However, due to different contexts and backgrounds, there can be different viewpoints, assumptions and needs regarding the same domain or the same problem.", "labels": [], "entities": []}, {"text": "They may use different jargon and terminology, sometimes even confused, overlapping, and they may use concepts and evaluation methods that are mismatched or poorly defined.", "labels": [], "entities": []}, {"text": "The consequence is the lack of a shared understanding that leads to a poor communication between people and organizations.", "labels": [], "entities": []}, {"text": "In particular, when IT solutions are involved, this lack of a shared understanding impacts on: \u2022 Effectiveness of people's cooperation \u2022 Flaws in enterprise organization \u2022 The identification of the requirements for the system specification \u2022 The inter-operability among systems and \u2022 The possibility of re-using and sharing of systems components.", "labels": [], "entities": [{"text": "Flaws", "start_pos": 137, "end_pos": 142, "type": "METRIC", "confidence": 0.9828147292137146}]}, {"text": "The goals of an Ontology is to reduce (or eliminate) conceptual and terminological confusion.", "labels": [], "entities": []}, {"text": "This is achieved by identifying and properly defining a set of relevant concepts that characterize a given application domain.", "labels": [], "entities": []}, {"text": "With respect to a Thesaurus: An Ontology aims at describing concepts, whereas a Thesaurus aims at describing terms; An Ontology can be seen as an enriched Thesaurus where, besides the definitions and relationships among terms of a given domain, more conceptual knowledge, by means of richer semantic relationships, is represented.", "labels": [], "entities": []}, {"text": "With respect to a Knowledge Base (KB): An Ontology can be seen as a KB whose goal is the description of the concepts necessary for talking about domains; A KB, in addition, includes the knowledge needed to model and elaborate a problem, derive new knowledge, prove theorems, or answer to intentional queries about a domain.", "labels": [], "entities": []}, {"text": "Though the utility of domain Ontologies is now widely acknowledged in the IT community, several barriers must be overcome before Ontologies become practical and useful tools for shared knowledge management.", "labels": [], "entities": []}, {"text": "In designing SymOntos, we have been working to define innovative solutions concerning the three critical issues listed above.", "labels": [], "entities": []}, {"text": "These solutions are currently being experimented in the context of the European project FETISH 1 , aimed at the definition of an interoperability platform for Small Medium Enterprises in the tourism sector.", "labels": [], "entities": []}, {"text": "Though we will (very) briefly present SymOntos, this paper is concerned with the third issue, that is, the description of text mining methods and tools to automatically enrich the concept Ontology.", "labels": [], "entities": [{"text": "text mining", "start_pos": 122, "end_pos": 133, "type": "TASK", "confidence": 0.7190485000610352}]}, {"text": "In the FETISH Project, we decided to explore the possibility to support the extraction of initial shared/able knowledge from on-line textual documentation accessible from the Web.", "labels": [], "entities": [{"text": "FETISH Project", "start_pos": 7, "end_pos": 21, "type": "DATASET", "confidence": 0.8348162472248077}, {"text": "extraction of initial shared/able knowledge from on-line textual documentation", "start_pos": 76, "end_pos": 154, "type": "TASK", "confidence": 0.7390014366670088}]}], "datasetContent": [{"text": "An obvious problem of any automatic method for concept extraction is to provide objective performance evaluation.", "labels": [], "entities": [{"text": "concept extraction", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.7303435057401657}]}, {"text": "\u2022 Firstly, a \"golden standard\" tourism terminology would be necessary to formally measure the accuracy of the method.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9993367791175842}]}, {"text": "One such standard is not available, and determining this standard is one of the objectives of FETISH.", "labels": [], "entities": [{"text": "FETISH", "start_pos": 94, "end_pos": 100, "type": "DATASET", "confidence": 0.8230152726173401}]}, {"text": "Moreover, the notion of \"term\" is too vague to consider available terminological databases as \"closed\" sets, unless the domain is extremely specific.", "labels": [], "entities": []}, {"text": "\u2022 Secondly, no formal methods to evaluate a terminology are available in literature.", "labels": [], "entities": []}, {"text": "The best way to evaluate a \"basic\" linguistic component (i.e. a module that performs some basic task, such as POS tagging, terminology extraction, etc.) within a larger NLP application (information extraction, document classification, etc.) is to compute the difference in performance with and without the basic component.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 110, "end_pos": 121, "type": "TASK", "confidence": 0.7709523439407349}, {"text": "terminology extraction", "start_pos": 123, "end_pos": 145, "type": "TASK", "confidence": 0.7231423556804657}, {"text": "information extraction", "start_pos": 186, "end_pos": 208, "type": "TASK", "confidence": 0.70980104804039}, {"text": "document classification", "start_pos": 210, "end_pos": 233, "type": "TASK", "confidence": 0.7104337066411972}]}, {"text": "In our case, since Ontology does not perform any measurable task, adopting a similar approach is not straightforward.", "labels": [], "entities": []}, {"text": "As a matter of facts, an Ontology is a basic component itself, therefore it can be formally evaluated only in the context of some specific usage of the Ontology itself.", "labels": [], "entities": []}, {"text": "Having in mind all these inherent difficulties, we performed two sets of experiments.", "labels": [], "entities": []}, {"text": "In the first, we extracted the terminology from a collection of texts in the Tourism domain, and we manually evaluated the results, with the help of other participants in the FETISH project (see the FETISH web site).", "labels": [], "entities": [{"text": "Tourism domain", "start_pos": 77, "end_pos": 91, "type": "DATASET", "confidence": 0.8053773641586304}, {"text": "FETISH project", "start_pos": 175, "end_pos": 189, "type": "DATASET", "confidence": 0.8187106549739838}, {"text": "FETISH web site", "start_pos": 199, "end_pos": 214, "type": "DATASET", "confidence": 0.954433798789978}]}, {"text": "In the second, we attempted to assess the generality of our approach.", "labels": [], "entities": []}, {"text": "We hence extracted the terminology from a financial corpus (the Wall Street journal) and then we both manually evaluated the result, and compared the extracted terminology with an available thesaurus in a (approximately) similar domain.", "labels": [], "entities": [{"text": "Wall Street journal", "start_pos": 64, "end_pos": 83, "type": "DATASET", "confidence": 0.9754856626192728}]}, {"text": "As a reference set of terms we used the Washington Post 5 (WP) dictionary of economic and financial terms.", "labels": [], "entities": [{"text": "Washington Post 5 (WP) dictionary", "start_pos": 40, "end_pos": 73, "type": "DATASET", "confidence": 0.9659412673541478}]}, {"text": "To compute the Domain Relevance, we first collected corpora in several domains: tourism announcements and hotel descriptions, economic prose (Wall Street Journal), medical news (Reuters), sport news (Reuters), a balanced corpus (Brown Corpus) and four novels by Wells.", "labels": [], "entities": [{"text": "Wall Street Journal)", "start_pos": 142, "end_pos": 162, "type": "DATASET", "confidence": 0.9438306540250778}, {"text": "Brown Corpus)", "start_pos": 229, "end_pos": 242, "type": "DATASET", "confidence": 0.9693421920140585}]}, {"text": "Overall, about 3,2 million words were collected.", "labels": [], "entities": []}, {"text": "In the first experiment, we used the Tourism corpus as a \"target\" domain for term extraction.", "labels": [], "entities": [{"text": "Tourism corpus", "start_pos": 37, "end_pos": 51, "type": "DATASET", "confidence": 0.7718150317668915}, {"text": "term extraction", "start_pos": 77, "end_pos": 92, "type": "TASK", "confidence": 0.7498842775821686}]}, {"text": "The Tourism corpus was manually built using the WWW and currently has only about 200,000 words, but it is rapidly growing. is a summary of the experiment.", "labels": [], "entities": [{"text": "Tourism corpus", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.9025225937366486}, {"text": "WWW", "start_pos": 48, "end_pos": 51, "type": "DATASET", "confidence": 0.9845026135444641}]}, {"text": "It is seen that only 2% terms are extracted from the initial list of candidates.", "labels": [], "entities": []}, {"text": "This extremely high filtering rate is due to the small corpus: many candidates are found just onetime in the corpus.", "labels": [], "entities": []}, {"text": "However, candidates are extracted with high precision (over 85%).", "labels": [], "entities": [{"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9980630278587341}]}, {"text": "shows the 15 most highly rated multiword terms, ordered by Consensus (Relevance is 1 for all the terms in the list).", "labels": [], "entities": [{"text": "Consensus", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9916226267814636}, {"text": "Relevance", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9970421195030212}]}, {"text": "compare our method with t with Mutual Information, Dice factor, and pure frequency.", "labels": [], "entities": [{"text": "Dice factor", "start_pos": 51, "end_pos": 62, "type": "METRIC", "confidence": 0.9162896573543549}]}, {"text": "Clearly, these measures are applied on the same set of eligible candidates extracted by the CHAOS chunker.", "labels": [], "entities": [{"text": "CHAOS chunker", "start_pos": 92, "end_pos": 105, "type": "DATASET", "confidence": 0.9367533326148987}]}, {"text": "The results reported in each line are those obtained using the best threshold for each adopted measure 6 . For our method (DR+DC), the threshold is given by the values \u03b1 and \u03b2.", "labels": [], "entities": [{"text": "DR+DC)", "start_pos": 123, "end_pos": 129, "type": "METRIC", "confidence": 0.6987484320998192}]}, {"text": "As remarked in the introduction, a comparison against a golden standard maybe unfair, since, on one side, many terms maybe present in the observed documents, and not present in the terminology.", "labels": [], "entities": []}, {"text": "On the other side, low frequency terms in the reference terminology are difficult to capture using statistical filters.", "labels": [], "entities": []}, {"text": "Due to these problems, the F-measure is in general quite low, though our method outperforms Mutual Information and Dice factor.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9975048899650574}]}, {"text": "As remarked by, the frequency emerges as a reasonable indicator, especially as for the Recall value, which is a rather obvious result.", "labels": [], "entities": [{"text": "Recall value", "start_pos": 87, "end_pos": 99, "type": "METRIC", "confidence": 0.9412331283092499}]}, {"text": "However pure frequency implies the problems outlined in the previous section.", "labels": [], "entities": []}, {"text": "Upon manual inspection, we found that, as obvious, undesired terms increase rapidly in the frequency ranked term list, as the frequency decreases.", "labels": [], "entities": []}, {"text": "Manually inspecting the first 100 highly ranked terms produced a score of 87,5 precision for our method, and 77,5 for the frequency measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.996793806552887}]}, {"text": "For the subsequent 100 terms, the discrepancy gets much higher (18%).", "labels": [], "entities": [{"text": "discrepancy", "start_pos": 34, "end_pos": 45, "type": "METRIC", "confidence": 0.9853502511978149}]}, {"text": "Note that the precision score is inline with that obtained for the Tourism corpus.", "labels": [], "entities": [{"text": "precision score", "start_pos": 14, "end_pos": 29, "type": "METRIC", "confidence": 0.9827605485916138}, {"text": "Tourism corpus", "start_pos": 67, "end_pos": 81, "type": "DATASET", "confidence": 0.9093490242958069}]}, {"text": "Notice also that the values of \u03b1 and \u03b2 are the same in the two experiments.", "labels": [], "entities": []}, {"text": "In practice, we found that the threshold \u03b1=0,35 for the Domain Relevance is a generally \"good\" value, while a little tuning maybe necessary for the Domain Consensus.", "labels": [], "entities": []}, {"text": "In the Tourism domain, where statistical evidence is lower, a lower value for \u03b2 produces higher precision (+1, 2%).", "labels": [], "entities": [{"text": "precision", "start_pos": 96, "end_pos": 105, "type": "METRIC", "confidence": 0.9994338154792786}]}], "tableCaptions": [{"text": " Table 2: The 15 most highly ranked  multiword Tourism terms", "labels": [], "entities": []}, {"text": " Table 3. Terms with high Domain Relevance  and low Domain Consensus  In the second experiment, we used the one- million-word Wall Street journal (WSJ) and  the Washington Post (WP) reference  terminology.  The WP includes 1270 terms, but only 214  occur at least once in the WSJ. We used these", "labels": [], "entities": [{"text": "Wall Street journal (WSJ)", "start_pos": 126, "end_pos": 151, "type": "DATASET", "confidence": 0.9326441685358683}, {"text": "Washington Post (WP) reference  terminology", "start_pos": 161, "end_pos": 204, "type": "DATASET", "confidence": 0.8356929506574359}, {"text": "WSJ", "start_pos": 276, "end_pos": 279, "type": "DATASET", "confidence": 0.9768267273902893}]}, {"text": " Table 4 WSJ/WP experiment on Test 1", "labels": [], "entities": [{"text": "WSJ", "start_pos": 9, "end_pos": 12, "type": "METRIC", "confidence": 0.4884229302406311}, {"text": "WP", "start_pos": 13, "end_pos": 15, "type": "METRIC", "confidence": 0.3049596846103668}]}, {"text": " Table 5 WSJ/WP experiment on Test 5", "labels": [], "entities": [{"text": "WSJ/WP", "start_pos": 9, "end_pos": 15, "type": "TASK", "confidence": 0.41974254449208576}]}]}