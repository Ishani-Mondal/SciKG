{"title": [{"text": "Development of a machine learnable discourse tagging tool", "labels": [], "entities": [{"text": "machine learnable discourse tagging", "start_pos": 17, "end_pos": 52, "type": "TASK", "confidence": 0.663062259554863}]}], "abstractContent": [{"text": "We have developed a discourse level tagging tool for spoken dialogue corpus using machine learning methods.", "labels": [], "entities": [{"text": "discourse level tagging", "start_pos": 20, "end_pos": 43, "type": "TASK", "confidence": 0.6390881538391113}, {"text": "spoken dialogue corpus", "start_pos": 53, "end_pos": 75, "type": "TASK", "confidence": 0.7253121534983317}]}, {"text": "As discourse level information , we focused on dialogue act, relevance and discourse segment.", "labels": [], "entities": []}, {"text": "In dialogue act tagging, we have implemented a transformation-based learning procedure and resulted in 70% accuracy in open test.", "labels": [], "entities": [{"text": "dialogue act tagging", "start_pos": 3, "end_pos": 23, "type": "TASK", "confidence": 0.6954233845074972}, {"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9993622899055481}]}, {"text": "In relevance and discourse segment tagging, we have implemented a decision-tree based learning procedure and resulted in about 75% and 72% accuracy respectively.", "labels": [], "entities": [{"text": "discourse segment tagging", "start_pos": 17, "end_pos": 42, "type": "TASK", "confidence": 0.6868684391180674}, {"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.999377429485321}]}], "introductionContent": [{"text": "In dialogue research communities, the need of dialogue corpora with various level of annotation is recognized.", "labels": [], "entities": []}, {"text": "However, creating annotated dialogue corpora needs considerable cost in recording, transcribing, annotating, and checking the consistency and reliability of the annotated data.", "labels": [], "entities": [{"text": "consistency", "start_pos": 126, "end_pos": 137, "type": "METRIC", "confidence": 0.9679291248321533}]}, {"text": "Considering such situation, we focused on annotation step and developed discourse level tagging tool for spoken dialogue corpus using machine learning methods.", "labels": [], "entities": [{"text": "discourse level tagging", "start_pos": 72, "end_pos": 95, "type": "TASK", "confidence": 0.6689262390136719}]}, {"text": "In this paper, we explain the detail of tagging scheme and describe machine learning algorithm suitable for each level of tagging.", "labels": [], "entities": [{"text": "tagging", "start_pos": 40, "end_pos": 47, "type": "TASK", "confidence": 0.9722855091094971}]}], "datasetContent": [{"text": "We have compared above two dialogue act tagging algorithms in two different tasks: a route direction task and a car troubleshooting task.", "labels": [], "entities": [{"text": "dialogue act tagging", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.6587723791599274}, {"text": "route direction task", "start_pos": 85, "end_pos": 105, "type": "TASK", "confidence": 0.8215723832448324}]}, {"text": "We used 4 dialogues for each task (268 and 184 sentences) as a training data and 2 dialogues as a test data (113 and 63 sentences).", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "We got similar average score for closed test.", "labels": [], "entities": [{"text": "closed test", "start_pos": 33, "end_pos": 44, "type": "DATASET", "confidence": 0.8285648226737976}]}, {"text": "Therefore, we regard the tuning level of parameter of each algorithm as a comparable level.", "labels": [], "entities": []}, {"text": "In open test in the same task, we got 69.7% in TBL and 57.5 % in example-based method.", "labels": [], "entities": [{"text": "TBL", "start_pos": 47, "end_pos": 50, "type": "METRIC", "confidence": 0.9674264788627625}]}, {"text": "As a result, we can conclude TBL is more suitable method for dialogue act tagging learning in limited amount of training data.", "labels": [], "entities": [{"text": "dialogue act tagging learning", "start_pos": 61, "end_pos": 90, "type": "TASK", "confidence": 0.8795702755451202}]}], "tableCaptions": [{"text": " Table 1: Elements for calculating a distance.", "labels": [], "entities": []}, {"text": " Table 2: Comparison of TBL and example- based method.", "labels": [], "entities": []}, {"text": " Table 3: Results of relevance type 2 tagging", "labels": [], "entities": [{"text": "relevance type 2 tagging", "start_pos": 21, "end_pos": 45, "type": "TASK", "confidence": 0.646578960120678}]}, {"text": " Table 4: Results of topic break index tagging", "labels": [], "entities": [{"text": "topic break index tagging", "start_pos": 21, "end_pos": 46, "type": "TASK", "confidence": 0.6084531471133232}]}]}