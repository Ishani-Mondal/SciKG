{"title": [], "abstractContent": [{"text": "This paper presents an overview of a robust, broad-coverage, and application-independent natural language generation system.", "labels": [], "entities": [{"text": "application-independent natural language generation", "start_pos": 65, "end_pos": 116, "type": "TASK", "confidence": 0.6708370447158813}]}, {"text": "It demonstrates how the different language generation components function within a multilingual Machine Translation (MT) system, using the languages that we are currently working on (English, Spanish, Japanese, and Chinese).", "labels": [], "entities": [{"text": "multilingual Machine Translation (MT)", "start_pos": 83, "end_pos": 120, "type": "TASK", "confidence": 0.846563071012497}]}, {"text": "Section 1 provides a system description.", "labels": [], "entities": []}, {"text": "Section 2 focuses on the generation components and their core set of rules.", "labels": [], "entities": []}, {"text": "Section 3 describes an additional layer of generation rules included to address application-specific issues.", "labels": [], "entities": []}, {"text": "Section 4 provides a brief description of the evaluation method and results for the MT system of which our generation components area part.", "labels": [], "entities": [{"text": "MT", "start_pos": 84, "end_pos": 86, "type": "TASK", "confidence": 0.9769290089607239}]}], "introductionContent": [], "datasetContent": [{"text": "The generation components described in the previous sections are part of an MT system that has been run on actual Microsoft technical documentation.", "labels": [], "entities": [{"text": "MT", "start_pos": 76, "end_pos": 78, "type": "TASK", "confidence": 0.9190467000007629}]}, {"text": "The system is frequently evaluated to provide a measure of progress and to yield feedback on its design and development.", "labels": [], "entities": []}, {"text": "In evaluating our progress overtime and comparing our system with others, we have performed several periodic, blind human evaluations.", "labels": [], "entities": []}, {"text": "We focus hereon the evaluation of our Spanish-English and English-Spanish systems.", "labels": [], "entities": []}, {"text": "For each evaluation, several human raters judge the same set of 200-250 sentences randomly extracted from our technical corpora (150K sentences).", "labels": [], "entities": []}, {"text": "The raters are not shown the source language sentence; instead, they are presented with a human translation, along with two machine-generated translations.", "labels": [], "entities": []}, {"text": "Their task is to choose between the alternatives, using the human translation as a reference.", "labels": [], "entities": []}, {"text": "summarizes a comparison of the output of our Spanish-English system with that of Babelfish (http://world.altavista.com/).", "labels": [], "entities": []}, {"text": "does the same for our English-Spanish system and Lernout & Hauspie's EnglishSpanish system (http://officeupdate.lhsl.com/).", "labels": [], "entities": []}, {"text": "In these tables, a rating of 1 means that raters uniformly preferred the translation produced by our system; a rating of 0 means that they did not uniformly prefer either translation; a rating of -1 means that they uniformly preferred the translation produced by the alternative system.", "labels": [], "entities": []}, {"text": "3 Beside each rating is a confidence measure for the mean preference at the .99 level).", "labels": [], "entities": []}], "tableCaptions": []}