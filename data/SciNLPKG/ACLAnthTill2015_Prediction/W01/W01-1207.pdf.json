{"title": [{"text": "Terminological variants for document selection and question/answer matching", "labels": [], "entities": [{"text": "document selection", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.7984362542629242}, {"text": "question/answer matching", "start_pos": 51, "end_pos": 75, "type": "TASK", "confidence": 0.6902442127466202}]}], "abstractContent": [{"text": "Answering precise questions requires applying Natural Language techniques in order to locate the answers inside retrieved documents.", "labels": [], "entities": [{"text": "Answering precise questions", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.862220843633016}]}, {"text": "The QALC system, presented in this paper, participated to the Question Answering track of the TREC8 and TREC9 evaluations.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.7662931680679321}, {"text": "TREC8 and TREC9 evaluations", "start_pos": 94, "end_pos": 121, "type": "DATASET", "confidence": 0.650234654545784}]}, {"text": "QALC exploits an analysis of documents based on the search for multi-word terms and their variations.", "labels": [], "entities": [{"text": "QALC", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8272643685340881}]}, {"text": "These indexes are used to select a minimal number of documents to be processed and to give indices when comparing question and sentence representations.", "labels": [], "entities": []}, {"text": "This comparison also takes advantage of a question analysis module and recognition of numeric and named entities in the documents.", "labels": [], "entities": [{"text": "question analysis", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.7361176013946533}]}], "introductionContent": [{"text": "The Question Answering (QA) track at TREC8 and TREC9 is due to the recent need for more sophisticated paradigms in Information Retrieval (IR).", "labels": [], "entities": [{"text": "Question Answering (QA)", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.7773392617702484}, {"text": "TREC8", "start_pos": 37, "end_pos": 42, "type": "DATASET", "confidence": 0.9385019540786743}, {"text": "TREC9", "start_pos": 47, "end_pos": 52, "type": "DATASET", "confidence": 0.9490673542022705}, {"text": "Information Retrieval (IR)", "start_pos": 115, "end_pos": 141, "type": "TASK", "confidence": 0.8531934380531311}]}, {"text": "Question answering generally refers to encyclopedic or factual questions that require concise answers.", "labels": [], "entities": [{"text": "Question answering", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9274886250495911}]}, {"text": "But current IR techniques do not yet enable a system to give precise answers to precise questions.", "labels": [], "entities": [{"text": "IR", "start_pos": 12, "end_pos": 14, "type": "TASK", "confidence": 0.9872263073921204}]}, {"text": "Question answering is thus an area of IR that calls for Natural Language Processing (NLP) techniques that can provide rich linguistic features as output.", "labels": [], "entities": [{"text": "Question answering", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9319881796836853}, {"text": "IR", "start_pos": 38, "end_pos": 40, "type": "TASK", "confidence": 0.9931683540344238}]}, {"text": "Such NLP modules should be deeply integrated in search and matching components so that answer selection can be performed on such linguistic features and take advantage of them.", "labels": [], "entities": [{"text": "answer selection", "start_pos": 87, "end_pos": 103, "type": "TASK", "confidence": 0.8939104378223419}]}, {"text": "In addition, IR and NLP techniques have to collaborate in the resulting system in order to cope with large-scale and broad coverage text databases while deriving benefit from added knowledge.", "labels": [], "entities": []}, {"text": "We developed a system for question answering, QALC, evaluated in the framework of the QA tracks at TREC8 and TREC9.", "labels": [], "entities": [{"text": "question answering", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.8949743211269379}, {"text": "TREC8", "start_pos": 99, "end_pos": 104, "type": "DATASET", "confidence": 0.9142731428146362}, {"text": "TREC9", "start_pos": 109, "end_pos": 114, "type": "DATASET", "confidence": 0.9367741942405701}]}, {"text": "The QALC system comprises NLP modules for multi-word term and named entity extraction with a specific concern for term conflation through variant recognition.", "labels": [], "entities": [{"text": "multi-word term and named entity extraction", "start_pos": 42, "end_pos": 85, "type": "TASK", "confidence": 0.6192644933859507}, {"text": "term conflation", "start_pos": 114, "end_pos": 129, "type": "TASK", "confidence": 0.6998316794633865}, {"text": "variant recognition", "start_pos": 138, "end_pos": 157, "type": "TASK", "confidence": 0.7207389622926712}]}, {"text": "Since named entity recognition has already been described extensively in other publications (Baluja 1999), we present the contribution of terminological variants to adding knowledge to our system.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 6, "end_pos": 30, "type": "TASK", "confidence": 0.6364797949790955}]}, {"text": "The two main activities involving terminology in NLP are term acquisition and term recognition.", "labels": [], "entities": [{"text": "term acquisition", "start_pos": 57, "end_pos": 73, "type": "TASK", "confidence": 0.8282873630523682}, {"text": "term recognition", "start_pos": 78, "end_pos": 94, "type": "TASK", "confidence": 0.8445647656917572}]}, {"text": "Basically, terms can be viewed as a particular type of lexical data.", "labels": [], "entities": []}, {"text": "Term variation may involve structural, morphological, and semantic transformations of single or multiwords terms.", "labels": [], "entities": [{"text": "Term variation", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.967897355556488}]}, {"text": "In this paper, we describe how QALC uses high level indexes, made of terms and variants, to select among documents the most relevant ones with regard to a question, and then to match candidate answers with this question.", "labels": [], "entities": []}, {"text": "In the selection process, the documents first retrieved by a search engine, are then postfiltered and ranked through a weighting scheme based on high level indexes, in order to retain the top ranked ones.", "labels": [], "entities": []}, {"text": "Similarly, all systems that participated in TREC9 have a search engine component that firstly selects a subset of the provided database of about one million documents.", "labels": [], "entities": [{"text": "TREC9", "start_pos": 44, "end_pos": 49, "type": "TASK", "confidence": 0.4954387843608856}]}, {"text": "Since a search engine produces a ranked list of relevant documents, systems then have to define the highest number of documents to retain.", "labels": [], "entities": []}, {"text": "Indeed, having too many documents leads to a question processing time that is too long, but conversely, having too few documents reduces the possibility of obtaining the correct answer.", "labels": [], "entities": [{"text": "question processing", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7122996747493744}]}, {"text": "For reducing the amount of text to process, one approach consists of keeping one or more relevant text paragraphs from each document retrieved., for instance use an IR engine that retrieves the top 300 sub-documents of about 300-550 words and, on the other hand, the FALCON system (Harabagiu et all 2000) performs a paragraph retrieval stage after the application of a boolean retrieval engine.", "labels": [], "entities": [{"text": "Harabagiu et all 2000", "start_pos": 282, "end_pos": 303, "type": "DATASET", "confidence": 0.8530735224485397}, {"text": "paragraph retrieval", "start_pos": 316, "end_pos": 335, "type": "TASK", "confidence": 0.7150515615940094}]}, {"text": "These systems work on the whole database and apply a bag-of-words technique to select passages whereas QALC first retains a large subset of documents, among which it then selects relevant documents by applying richer criteria based on the use of the linguistic structures of the words.", "labels": [], "entities": [{"text": "QALC", "start_pos": 103, "end_pos": 107, "type": "DATASET", "confidence": 0.8142057657241821}]}, {"text": "QALC indexes, used for document selection, are made of single and multi-word terms retrieved by a 2-step procedure: (1)\u00caautomatic term extraction from questions through part-ofspeech tagging and pattern matching and (2)\u00caautomatic document indexing through term recognition and variant conflation.", "labels": [], "entities": [{"text": "document selection", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.7306423783302307}, {"text": "term extraction from questions", "start_pos": 130, "end_pos": 160, "type": "TASK", "confidence": 0.824996143579483}, {"text": "term recognition", "start_pos": 256, "end_pos": 272, "type": "TASK", "confidence": 0.6993428021669388}]}, {"text": "As a result, linguistic variation is explicitly addressed through the exploitation of word paradigms, contrarily to other approaches like the one taken in COPSY where an approximate matching technique between the query and the documents implicitly takes it into account.", "labels": [], "entities": []}, {"text": "Finally, terms acquired at step\u00ca(1) and indexes from step\u00ca(2) are also used by the matching procedure between a question and the relevant document sentences.", "labels": [], "entities": []}, {"text": "In the next section, we describe the architecture of the QALC system.", "labels": [], "entities": []}, {"text": "Then, we present the question processing for term extraction.", "labels": [], "entities": [{"text": "term extraction", "start_pos": 45, "end_pos": 60, "type": "TASK", "confidence": 0.7405691593885422}]}, {"text": "We continue with the description of FASTR, a transformational shallow parser that recognizes and marks the extracted terms as well as their linguistic variants within the documents.", "labels": [], "entities": [{"text": "FASTR", "start_pos": 36, "end_pos": 41, "type": "METRIC", "confidence": 0.796209990978241}]}, {"text": "The two following sections present the modules of the QALC system where terms and variants are used, namely the document selection and question/answer matching modules.", "labels": [], "entities": [{"text": "document selection", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.6912554204463959}, {"text": "question/answer matching", "start_pos": 135, "end_pos": 159, "type": "TASK", "confidence": 0.5987304225564003}]}, {"text": "Finally, we present the results obtained by the QALC system as well as an evaluation of the contribution of this NLP technique to the QA task through the use of the reference collections for the QA track.", "labels": [], "entities": []}, {"text": "In conclusion, suggestions for more ambitious, but still realistic, developments using NLP are outlined.", "labels": [], "entities": []}], "datasetContent": [{"text": "We sent to TREC9 three runs whose variations concern the searched engine used and the length of the answer (250 or 50 characters).", "labels": [], "entities": [{"text": "TREC9", "start_pos": 11, "end_pos": 16, "type": "DATASET", "confidence": 0.8750438690185547}, {"text": "length", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.9660872220993042}]}, {"text": "Among those runs, the best one obtained a score of 0.407 with 375 correct answers among 682 questions, for answers of 250 characters length.", "labels": [], "entities": []}, {"text": "The score computed by NIST is the reciprocal mean of the rank, from 1 to 5, of the correct answer.", "labels": [], "entities": [{"text": "NIST", "start_pos": 22, "end_pos": 26, "type": "DATASET", "confidence": 0.9008496999740601}]}, {"text": "With this score, the QALC system was ranked 6th among 25 participants at TREC 9 QA task.", "labels": [], "entities": [{"text": "TREC 9 QA task", "start_pos": 73, "end_pos": 87, "type": "DATASET", "confidence": 0.794729545712471}]}, {"text": "Document selection relies on a quantitative measure, i.e. the document weight, whose computation is based on syntactic and semantic indices, i.e. the terms and the terminological variants.", "labels": [], "entities": [{"text": "Document selection", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9411993026733398}]}, {"text": "Those indices allow the system to take into account words as well as group of words and their internal relations within the documents.", "labels": [], "entities": []}, {"text": "Following examples, that we have got from selected documents for TREC9 QA task, show what kind of indices are added to the question words.", "labels": [], "entities": [{"text": "TREC9 QA task", "start_pos": 65, "end_pos": 78, "type": "DATASET", "confidence": 0.7438753048578898}]}, {"text": "For the question 252 When was the first flush toilet invented?", "labels": [], "entities": []}, {"text": ", one multi-word extracted term is flush toilet.", "labels": [], "entities": []}, {"text": "This term is marked by FASTR when recognized in a document, but it is also marked when a variant is found, as for instance low-flush toilet in the following document sentence where low-flush is recognized as equivalent to flush: Santa Barbara , Calif.", "labels": [], "entities": [{"text": "FASTR", "start_pos": 23, "end_pos": 28, "type": "METRIC", "confidence": 0.9919010996818542}]}, {"text": ", is giving $ 80 to anyone who converts to a low-flush toilet.", "labels": [], "entities": []}, {"text": "In the given examples, after the identification number of the term, appears the reference term, made of the lemmatized form of the words and their syntactic category, followed by the variant found in the sentence, with each word, its lemmatized form and its category, and finally its weight.", "labels": [], "entities": []}, {"text": "In the example above, the term found in the sentence is equivalent to the reference term, and thus its weight is 1.00.", "labels": [], "entities": []}, {"text": "The In order to evaluate the efficiency of the selection process, we proceeded to several measures.", "labels": [], "entities": []}, {"text": "We apply our system on the material given for the TREC8 evaluation, onetime with the selection process, and another time without this process.", "labels": [], "entities": [{"text": "TREC8 evaluation", "start_pos": 50, "end_pos": 66, "type": "TASK", "confidence": 0.4975893050432205}]}, {"text": "At each time, 200 documents were returned by the search engine for each of the 200 questions.", "labels": [], "entities": []}, {"text": "When selection was applied, at most 100 documents were selected and subsequently processed by the matching module.", "labels": [], "entities": []}, {"text": "Otherwise, the 200 documents were processed.", "labels": [], "entities": []}, {"text": "The system was scored by 0.463 in the first case, and by 0.452 in the second case.", "labels": [], "entities": []}, {"text": "These results show that the score increases when processing less documents above all because it is just the relevant documents that are selected.", "labels": [], "entities": []}, {"text": "The benefit from performing such a selection is also illustrated by the results given in We see that the selection process discards a lot of documents for 50% of the questions (340 questions are processed from less than 100 documents).", "labels": [], "entities": []}, {"text": "The document set retrieved for those questions had a weighting curve with a sharp slope and a plateau as in.", "labels": [], "entities": []}, {"text": "QALC finds more often the correct answer and in a better position for these 340 questions than for the 342 remaining ones.", "labels": [], "entities": [{"text": "QALC", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6002534627914429}]}, {"text": "The average number of documents selected, when there are less than 100, is 37.", "labels": [], "entities": []}, {"text": "These results are very interesting when applying such time-consuming processes as named entity recognition and question/sentence matching.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 82, "end_pos": 106, "type": "TASK", "confidence": 0.6439180572827657}, {"text": "question/sentence matching", "start_pos": 111, "end_pos": 137, "type": "TASK", "confidence": 0.5874227583408356}]}, {"text": "Document selection will also enable us to apply later on syntactic and semantic sentence analysis.", "labels": [], "entities": [{"text": "Document selection", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8656454086303711}, {"text": "semantic sentence analysis", "start_pos": 71, "end_pos": 97, "type": "TASK", "confidence": 0.6239743332068125}]}], "tableCaptions": [{"text": " Table 1. Evaluation of the ranking process", "labels": [], "entities": []}]}