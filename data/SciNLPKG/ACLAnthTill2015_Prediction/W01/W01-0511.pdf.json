{"title": [{"text": "Classifying the Semantic Relations in Noun Compounds via a Domain-Specific Lexical Hierarchy", "labels": [], "entities": []}], "abstractContent": [{"text": "We are developing corpus-based techniques for identifying semantic relations at an intermediate level of description (more specific than those used in case frames, but more general than those used in traditional knowledge representation systems).", "labels": [], "entities": []}, {"text": "In this paper we describe a classification algorithm for identifying relationships between two-word noun compounds.", "labels": [], "entities": []}, {"text": "We find that a very simple approach using a machine learning algorithm and a domain-specific lexical hierarchy successfully generalizes from training instances, performing better on previously unseen words than a baseline consisting of training on the words themselves.", "labels": [], "entities": []}], "introductionContent": [{"text": "We are exploring empirical methods of determining semantic relationships between constituents in natural language.", "labels": [], "entities": []}, {"text": "Our current project focuses on biomedical text, both because it poses interesting challenges, and because it should be possible to make inferences about propositions that hold between scientific concepts within biomedical texts.", "labels": [], "entities": []}, {"text": "One of the important challenges of biomedical text, along with most other technical text, is the proliferation of noun compounds.", "labels": [], "entities": []}, {"text": "A typical article title is shown below; it consists a cascade of four noun phrases linked by prepositions: Open-labeled long-term study of the efficacy, safety, and tolerability of subcutaneous sumatriptan in acute migraine treatment.", "labels": [], "entities": []}, {"text": "The real concern in analyzing such a title is in determining the relationships that hold between different concepts, rather than on finding the appropriate attachments (which is especially difficult given the lack of a verb).", "labels": [], "entities": []}, {"text": "And before we tackle the prepositional phrase attachment problem, we must find away to analyze the meanings of the noun compounds.", "labels": [], "entities": [{"text": "prepositional phrase attachment", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.6709548433621725}]}, {"text": "Our goal is to extract propositional information from text, and as a step towards this goal, we classify constituents according to which semantic relationships hold between them.", "labels": [], "entities": []}, {"text": "For example, we want to characterize the treatment-for-disease relationship between the words of migraine treatment versus the method-of-treatment relationship between the words of aerosol treatment.", "labels": [], "entities": []}, {"text": "These relations are intended to be combined to produce larger propositions that can then be used in a variety of interpretation paradigms, such as abductive reasoning or inductive logic programming.", "labels": [], "entities": []}, {"text": "Note that because we are concerned with the semantic relations that hold between the concepts, as opposed to the more standard, syntax-driven computational goal of determining left versus right association, this has the fortuitous effect of changing the problem into one of classification, amenable to standard machine learning classification techniques.", "labels": [], "entities": [{"text": "machine learning classification", "start_pos": 311, "end_pos": 342, "type": "TASK", "confidence": 0.741825520992279}]}, {"text": "We have found that we can use such algorithms to classify relationships between two-word noun compounds with a surprising degree of accuracy.", "labels": [], "entities": [{"text": "classify relationships between two-word noun compounds", "start_pos": 49, "end_pos": 103, "type": "TASK", "confidence": 0.8341725865999857}, {"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9972344040870667}]}, {"text": "A one-out-of-eighteen classification using a neural net achieves accuracies as high as 62%.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 65, "end_pos": 75, "type": "METRIC", "confidence": 0.9991397857666016}]}, {"text": "By taking advantage of lexical ontologies, we achieve strong results on noun compounds for which neither word is present in the training set.", "labels": [], "entities": []}, {"text": "Thus, we think this is a promising approach fora variety of semantic labeling tasks.", "labels": [], "entities": [{"text": "semantic labeling tasks", "start_pos": 60, "end_pos": 83, "type": "TASK", "confidence": 0.802306334177653}]}, {"text": "The reminder of this paper is organized as follows: Section 2 describes related work, Section 3 describes the semantic relations and how they were chosen, and Section 4 describes the data collection and ontologies.", "labels": [], "entities": []}, {"text": "In Section 5 we describe the method for automatically assigning semantic relations to noun compounds, and report the results of experiments using this method.", "labels": [], "entities": [{"text": "automatically assigning semantic relations to noun compounds", "start_pos": 40, "end_pos": 100, "type": "TASK", "confidence": 0.7852158333574023}]}, {"text": "Section 6 concludes the paper and discusses future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Different lengths of the MeSH descriptors  for the different models", "labels": [], "entities": [{"text": "MeSH descriptors", "start_pos": 35, "end_pos": 51, "type": "DATASET", "confidence": 0.8138978183269501}]}, {"text": " Table 3: Length of the feature vectors for different  models.", "labels": [], "entities": [{"text": "Length", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.99716717004776}]}, {"text": " Table 4: Test accuracy for each model, where the model", "labels": [], "entities": [{"text": "Test", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.933874785900116}, {"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9144929051399231}]}, {"text": " Table 5: Test accuracy for the four sub-partitions of  the test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9536500573158264}]}]}