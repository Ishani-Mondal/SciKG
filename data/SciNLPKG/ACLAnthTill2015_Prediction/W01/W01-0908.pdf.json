{"title": [{"text": "Using the Distribution of Performance for Studying Statistical NLP Systems and Corpora", "labels": [], "entities": []}], "abstractContent": [{"text": "Statistical NLP systems are frequently evaluated and compared on the basis of their performances on a single split of training and test data.", "labels": [], "entities": []}, {"text": "Results obtained using a single split are, however, subject to sampling noise.", "labels": [], "entities": []}, {"text": "In this paper we argue in favour of reporting a distribution of performance figures, obtained by resampling the training data, rather than a single number.", "labels": [], "entities": []}, {"text": "The additional information from distributions can be used to make statistically quantified statements about differences across parameter settings, systems, and corpora .", "labels": [], "entities": []}], "introductionContent": [{"text": "The common practice in evaluating statistical NLP systems is using a standard corpus (e.g., Penn TreeBank for parsing, Reuters for text categorization) along with a standard split between training and test data.", "labels": [], "entities": [{"text": "Penn TreeBank", "start_pos": 92, "end_pos": 105, "type": "DATASET", "confidence": 0.9867817759513855}]}, {"text": "As systems improve, it becomes harder to achieve additional improvements, and the performance of various state-of-the-art systems is approximately identical.", "labels": [], "entities": []}, {"text": "This makes performance comparisons difficult.", "labels": [], "entities": []}, {"text": "In this paper, we argue in favour of studying the distribution of performance, and present conclusions drawn from studying the recall distribution.", "labels": [], "entities": [{"text": "recall", "start_pos": 127, "end_pos": 133, "type": "METRIC", "confidence": 0.9868337512016296}]}, {"text": "This distribution provides measures for answering the following questions: Q1: Comparing systems on given data: Is classifier A better than classifier B forgiven training and test data?", "labels": [], "entities": []}, {"text": "Q2: Adequacy of training data to test data: Is a system trained on dataset X adequate for analysing dataset Y ? Are features from X indicative in Y ? Q3: Comparing data sets with a given system: If a different training set improves the result of system A on dataset Y 1 , will this be the case on dataset Y 2 as well?", "labels": [], "entities": []}, {"text": "The answers to these questions can provide useful insight into statistical NLP systems.", "labels": [], "entities": []}, {"text": "In particular, about sensitivity to features in the training data, and transferability.", "labels": [], "entities": [{"text": "transferability", "start_pos": 71, "end_pos": 86, "type": "TASK", "confidence": 0.9729481339454651}]}, {"text": "These properties can be different even when similar performance is reported.", "labels": [], "entities": []}, {"text": "A statistical treatment of Question 1 is presented by.", "labels": [], "entities": []}, {"text": "He tests for the significance of performance differences on fixed training and test data sets.", "labels": [], "entities": []}, {"text": "In other related works, provides an overview of significance tests of error differences in small samples, and discusses results of a number of tests.", "labels": [], "entities": []}, {"text": "Questions 2 and 3 have been frequently raised in NLP, but not explicitly addressed, since the prevailing evaluation methods provide no means of addressing them.", "labels": [], "entities": []}, {"text": "In this paper we propose addressing all three questions with a single experimental methodology, which uses the distribution of recall. of a statistical process.", "labels": [], "entities": [{"text": "recall.", "start_pos": 127, "end_pos": 134, "type": "METRIC", "confidence": 0.9655738472938538}]}, {"text": "Therefore, word counts, count ratios, and other data used in creating statistical NLP models are statistical quantities as well, and as such prone to sampling noise.", "labels": [], "entities": []}, {"text": "Sampling noise results from the finiteness of the data, and the particular choice of training and test data.", "labels": [], "entities": [{"text": "Sampling noise", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.906192809343338}]}, {"text": "A model is an approximation or a more abstract representation of training data.", "labels": [], "entities": []}, {"text": "One may look at a model as a collection of estimators analogous, e.g., to the slope calculated by linear regression.", "labels": [], "entities": []}, {"text": "These estimators are statistics with a distribution related to the way they were obtained, which maybe very complicated.", "labels": [], "entities": []}, {"text": "The performance figures, being dependent on these estimators, have a distribution function which maybe difficult to find theoretically.", "labels": [], "entities": []}, {"text": "This distribution gives rise to intrinsic noise.", "labels": [], "entities": []}, {"text": "Performance comparisons based on a single run or a few runs do not take these noises into account.", "labels": [], "entities": []}, {"text": "Because we cannot assign the resulting statements a confidence measure, they are more qualitative than quantitative.", "labels": [], "entities": []}, {"text": "The degree to which we can accept such statements depends on the noise level and more generally, on the distribution of performance.", "labels": [], "entities": []}, {"text": "In this paper, we use recall as a performance measure (cf. Section 4.4 and Section 3.2 in).", "labels": [], "entities": [{"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9989086389541626}]}, {"text": "Recall samples are obtained by resampling from training data and training classifiers on these samples.", "labels": [], "entities": []}, {"text": "The resampling methods used here are cross-validation and bootstrap, cf. Section 3).", "labels": [], "entities": []}, {"text": "Section 4 presents the experimental goals and setup.", "labels": [], "entities": []}, {"text": "Results are presented and discussed in Section 5, and a summary is provided in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "The aim of our experiments is to test whether the recall distribution can be helpful in answering the questions Q1-Q3 mentioned in the introduction of this paper.", "labels": [], "entities": [{"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.9964511394500732}]}, {"text": "The data and learning algorithms are presented in Sections 4.1 and 4.2.", "labels": [], "entities": []}, {"text": "Section 4.3 describes the sampling method in detail.", "labels": [], "entities": []}, {"text": "Section 4.4 motivates the use of recall and describes the experiments.", "labels": [], "entities": [{"text": "recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9981473684310913}]}, {"text": "Sentences Base-NPs Training 8938 \u00b1 48 54763 \u00b1 2 Unique: 5648 \u00b1 34: Sentence and instant counts for the bootstrap samples.", "labels": [], "entities": [{"text": "instant counts", "start_pos": 80, "end_pos": 94, "type": "METRIC", "confidence": 0.9329828917980194}]}, {"text": "The second line refers to unique sentences in the training data.", "labels": [], "entities": []}, {"text": "We used the WSJ15-18 dataset for training.", "labels": [], "entities": [{"text": "WSJ15-18 dataset", "start_pos": 12, "end_pos": 28, "type": "DATASET", "confidence": 0.9884021878242493}]}, {"text": "This dataset contains n 0 = 54760 base-NP instances.", "labels": [], "entities": []}, {"text": "The number of instances in a bootstrap sample depends on the number of instances in the last sampled sentence.", "labels": [], "entities": []}, {"text": "As shows, it is slightly more than n 0 . For k-CV sampling, the data were divided into k random distinct parts, each containing n 0 k \u00b12 instances.", "labels": [], "entities": []}, {"text": "shows the number of recall samples in each experiment (MBSL and SNoW experiments were carried out seperately).", "labels": [], "entities": [{"text": "recall", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.995229959487915}, {"text": "MBSL", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.6364602446556091}]}, {"text": "We trained SNoW and MBSL; the latter using context sizes of c=1 and c=3.", "labels": [], "entities": [{"text": "MBSL", "start_pos": 20, "end_pos": 24, "type": "DATASET", "confidence": 0.7333953976631165}]}, {"text": "Data sets WSJ20, ATIS, WSJ20a, and WSJ20b were used for testing.", "labels": [], "entities": [{"text": "WSJ20", "start_pos": 10, "end_pos": 15, "type": "DATASET", "confidence": 0.9476109147071838}, {"text": "ATIS", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.5419092178344727}, {"text": "WSJ20a", "start_pos": 23, "end_pos": 29, "type": "DATASET", "confidence": 0.8606112599372864}, {"text": "WSJ20b", "start_pos": 35, "end_pos": 41, "type": "DATASET", "confidence": 0.9337125420570374}]}, {"text": "MBSL runs with the two c values were conducted on the same training samples, therefore it is possible to compare their results directly.", "labels": [], "entities": [{"text": "MBSL", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6847687363624573}]}, {"text": "Each run yielded recall and precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.9993354678153992}, {"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9985108971595764}]}, {"text": "Recall maybe viewed as the expected 0-1 lossfunction on the given test sample of instances.", "labels": [], "entities": []}, {"text": "Precision, on the other hand, maybe viewed as the expected 0-1 loss on the sample of instances detected by the learning system.", "labels": [], "entities": []}, {"text": "Care should betaken when discussing the distribution of precision values because this sample varies from run to run.", "labels": [], "entities": [{"text": "precision", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9959398508071899}]}, {"text": "We will therefore only analyse the distribution of recall in this work.", "labels": [], "entities": [{"text": "recall", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.9946959614753723}]}, {"text": "In the following, r 1 and r 3 denote recall samples of MBSL with c = 1 and c = 3, with standard deviations \u03c3 1 and \u03c3 3 . \u03c1 13 denotes the cross-correlation between r 1 and r 3 . SNoW recall and standard deviation will be denoted by r SN and \u03c3 SN . To approach the questions raised in the introduction we made the following measurements: Q1: System comparison was addressed by comparing r 1 and r 3 on the same test data.", "labels": [], "entities": [{"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9571966528892517}, {"text": "recall", "start_pos": 183, "end_pos": 189, "type": "METRIC", "confidence": 0.9078525304794312}]}, {"text": "With samples at hand, we obtained an estimate of P (r 3 > r 1 ).", "labels": [], "entities": [{"text": "P", "start_pos": 49, "end_pos": 50, "type": "METRIC", "confidence": 0.9833483099937439}]}, {"text": "Q2: We studied training and test adequacy through the effect of more specific features on recall, and on its standard deviation.", "labels": [], "entities": [{"text": "recall", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.9986699819564819}]}, {"text": "Setting c = 3 takes into account sequences with context of two and three words in addition to those with c = 1.", "labels": [], "entities": []}, {"text": "Sequences with larger context are more specific, and an improvement in recall implies that they are informative in the test data as well.", "labels": [], "entities": [{"text": "recall", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.999561607837677}]}, {"text": "For particular choices of parameters and test data, the recall spread yields an estimate of the training sampling noise.", "labels": [], "entities": [{"text": "recall spread", "start_pos": 56, "end_pos": 69, "type": "METRIC", "confidence": 0.9867827296257019}]}, {"text": "On inadequate data, where the statistics differ significantly from those in the training data, even small changes in the model can lead to a noticeable difference in recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 166, "end_pos": 172, "type": "METRIC", "confidence": 0.9986369013786316}]}, {"text": "This is because the model relies on statistics which appear relatively rarely in the test data.", "labels": [], "entities": []}, {"text": "Not only do these statistics provide little information about the problem, but even small differences in weighting them are relatively influential.", "labels": [], "entities": []}, {"text": "Therefore, the more training and test data differ from each other, the more spread we can expect in results.", "labels": [], "entities": []}, {"text": "Q3: For comparing test data sets with a system, we used cross-correlations between r 1 , r 3 , or r SN samples obtained on these data sets.", "labels": [], "entities": []}, {"text": "We know that WSJ data are different from ATIS data, and so expect the results on WSJ to correlate with ATIS results less than with other WSJ results.", "labels": [], "entities": [{"text": "WSJ data", "start_pos": 13, "end_pos": 21, "type": "DATASET", "confidence": 0.7647118270397186}, {"text": "ATIS data", "start_pos": 41, "end_pos": 50, "type": "DATASET", "confidence": 0.9576676189899445}, {"text": "WSJ", "start_pos": 81, "end_pos": 84, "type": "DATASET", "confidence": 0.813123345375061}, {"text": "ATIS", "start_pos": 103, "end_pos": 107, "type": "DATASET", "confidence": 0.7258220314979553}]}, {"text": "Both MBSL experiments yielded negligible correlations of ATIS results with any WSJ data set, whether large or small.", "labels": [], "entities": [{"text": "ATIS", "start_pos": 57, "end_pos": 61, "type": "METRIC", "confidence": 0.9278671741485596}, {"text": "WSJ data set", "start_pos": 79, "end_pos": 91, "type": "DATASET", "confidence": 0.9429068168004354}]}, {"text": "These correlations were always weaker than with WSJ20a and WSJ20b, which are about the same size.", "labels": [], "entities": [{"text": "WSJ20a", "start_pos": 48, "end_pos": 54, "type": "DATASET", "confidence": 0.9575059413909912}, {"text": "WSJ20b", "start_pos": 59, "end_pos": 65, "type": "DATASET", "confidence": 0.9397537112236023}]}, {"text": "This is due to ATIS being a different kind of text.", "labels": [], "entities": [{"text": "ATIS", "start_pos": 15, "end_pos": 19, "type": "DATASET", "confidence": 0.7911773920059204}]}, {"text": "The correlation between WSJ20a and WSJ20b results was also weak.", "labels": [], "entities": [{"text": "WSJ20a", "start_pos": 24, "end_pos": 30, "type": "DATASET", "confidence": 0.8269360661506653}, {"text": "WSJ20b", "start_pos": 35, "end_pos": 41, "type": "DATASET", "confidence": 0.8275773525238037}]}, {"text": "This maybe due to their small sizes; these texts might not share enough features to make a significant correlation.", "labels": [], "entities": []}, {"text": "SNoW results were highly correlated for all pairs.", "labels": [], "entities": []}, {"text": "That behaviour is markedly different from the MBSL results, and indicates a high level of noise in the SNoW features.", "labels": [], "entities": []}, {"text": "Indeed, Winnow is able to learn well in the presence of noise, but that noise causes the high correlations observed here.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Recall statistic summary for MBSL with contexts c = 1 and c = 3, and SNoW. The  E(\u00b7) figures were obtained using the full training set. Note the monotonic change of standard  deviation with fold number. The s.d. of the bootstrap samples are closest to those of low-fold  CV samples.", "labels": [], "entities": [{"text": "E", "start_pos": 90, "end_pos": 91, "type": "METRIC", "confidence": 0.9907267093658447}]}, {"text": " Table 5: Cross-correlations between recalls of the three experiments on the test data for five-fold  CV. Correlations of r 1 capture dataset similarity in the best way.", "labels": [], "entities": [{"text": "recalls", "start_pos": 37, "end_pos": 44, "type": "METRIC", "confidence": 0.9726668000221252}]}]}