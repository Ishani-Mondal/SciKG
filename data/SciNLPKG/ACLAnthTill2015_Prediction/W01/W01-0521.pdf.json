{"title": [], "abstractContent": [{"text": "Most work in statistical parsing has focused on a single corpus: the Wall Street Journal portion of the Penn Treebank.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.885481983423233}, {"text": "Wall Street Journal portion of the Penn Treebank", "start_pos": 69, "end_pos": 117, "type": "DATASET", "confidence": 0.9491435065865517}]}, {"text": "While this has allowed for quantitative comparison of parsing techniques, it has left open the question of how other types of text might aaect parser performance, and how portable parsing models are across corpora.", "labels": [], "entities": [{"text": "parsing", "start_pos": 54, "end_pos": 61, "type": "TASK", "confidence": 0.9745082855224609}]}, {"text": "We examine these questions by comparing results for the Brown and WSJ corpora, and also consider which parts of the parser's probability model are particularly tuned to the corpus on which it was trained.", "labels": [], "entities": [{"text": "WSJ corpora", "start_pos": 66, "end_pos": 77, "type": "DATASET", "confidence": 0.9225513935089111}]}, {"text": "This leads us to a technique for pruning parameters to reduce the size of the parsing model.", "labels": [], "entities": [{"text": "parsing", "start_pos": 78, "end_pos": 85, "type": "TASK", "confidence": 0.9642958045005798}]}], "introductionContent": [{"text": "The past several years have seen great progress in the eld of natural language parsing, through the use of statistical methods trained using large corpora of hand-parsed training data.", "labels": [], "entities": [{"text": "natural language parsing", "start_pos": 62, "end_pos": 86, "type": "TASK", "confidence": 0.6356811424096426}]}, {"text": "The techniques of Charniak 1997, achieved roughly comparable results using the same sets of training and test data.", "labels": [], "entities": []}, {"text": "In each case, the corpus used was the Penn Treebank's hand-annotated parses of Wall Street Journal articles.", "labels": [], "entities": [{"text": "Penn Treebank's hand-annotated parses of Wall Street Journal articles", "start_pos": 38, "end_pos": 107, "type": "DATASET", "confidence": 0.9475870251655578}]}, {"text": "Relatively few quantitative parsing results have been reported on other corpora though see Stolcke e t al. for results on Switchboard, as well as for results on Czech and Hwa 1999 for bootstrapping from WSJ to ATIS.", "labels": [], "entities": [{"text": "Switchboard", "start_pos": 122, "end_pos": 133, "type": "DATASET", "confidence": 0.8750478625297546}, {"text": "Czech and Hwa 1999", "start_pos": 161, "end_pos": 179, "type": "DATASET", "confidence": 0.8847998380661011}, {"text": "WSJ", "start_pos": 203, "end_pos": 206, "type": "DATASET", "confidence": 0.7496578097343445}, {"text": "ATIS", "start_pos": 210, "end_pos": 214, "type": "DATASET", "confidence": 0.5200439691543579}]}, {"text": "The inclusion of parses for the Brown corpus in the Penn Treebank allows us to compare parser performance across corpora.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 32, "end_pos": 44, "type": "DATASET", "confidence": 0.8214761316776276}, {"text": "Penn Treebank", "start_pos": 52, "end_pos": 65, "type": "DATASET", "confidence": 0.8284209072589874}]}, {"text": "In this paper we examine the following questions: \ud97b\udf59 To what extent is the performance of statistical parsers on the WSJ task due to its relatively uniform style, and how mi g ht s u ch parsers fare on the more varied Brown corpus?", "labels": [], "entities": [{"text": "WSJ task", "start_pos": 116, "end_pos": 124, "type": "DATASET", "confidence": 0.682062178850174}, {"text": "Brown corpus", "start_pos": 217, "end_pos": 229, "type": "DATASET", "confidence": 0.7190858721733093}]}, {"text": "\ud97b\udf59 Can training data from one corpus be applied to parsing another?", "labels": [], "entities": [{"text": "parsing", "start_pos": 50, "end_pos": 57, "type": "TASK", "confidence": 0.9649863243103027}]}, {"text": "\ud97b\udf59 What aspects of the parser's probability mo d e l are particularly tuned to one corpus, and which are more general?", "labels": [], "entities": []}, {"text": "Our investigation of these questions leads us to a surprising result about parsing the WSJ corpus: over a third of the model's parameters can be eliminated with little impact on performance.", "labels": [], "entities": [{"text": "parsing", "start_pos": 75, "end_pos": 82, "type": "TASK", "confidence": 0.9709005355834961}, {"text": "WSJ corpus", "start_pos": 87, "end_pos": 97, "type": "DATASET", "confidence": 0.7048992961645126}]}, {"text": "Aside from cross-corpus considerations, this is an important nding if a lightweight parser is desired or memory usage is a consideration.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1.  Training Set  Test Set  Corpus Sentences Words Sentences Words  WSJ  39,832 950,028  2245 48,665  Brown  21,818 413,198  2282 38,109", "labels": [], "entities": [{"text": "Training Set  Test Set  Corpus Sentences Words Sentences Words  WSJ  39,832 950,028  2245 48,665  Brown  21,818 413,198  2282 38,109", "start_pos": 11, "end_pos": 143, "type": "DATASET", "confidence": 0.8499622595937628}]}, {"text": " Table 2: Parsing results by training and test corpus", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9416667819023132}]}, {"text": " Table 3: Parsing results by training and test corpus", "labels": [], "entities": [{"text": "Parsing", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9468247890472412}]}, {"text": " Table 4: Parsing results with pruned probability models. The complete parsing model contains 736K pa- rameters in nine distributions. Removing all lexical bigram parameters reducing the size of the model by  43.", "labels": [], "entities": []}]}