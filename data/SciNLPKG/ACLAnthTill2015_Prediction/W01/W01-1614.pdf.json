{"title": [{"text": "Empirical Methods for Evaluating Dialog Systems Empirical Methods for Evaluating Dialog Systems", "labels": [], "entities": [{"text": "Evaluating Dialog Systems", "start_pos": 70, "end_pos": 95, "type": "TASK", "confidence": 0.6151091655095419}]}], "abstractContent": [{"text": "We examine what purpose a dialog metric serves and then propose empirical methods for evaluating systems that meet that purpose.", "labels": [], "entities": []}, {"text": "The methods include a protocol for conducting a wizard-of-oz experiment and a basic set of descriptive statistics for substantiating performance claims using the data collected from the experiment as an ideal benchmark or \"gold standard\" for comparative judgments.", "labels": [], "entities": []}, {"text": "The methods also provide a practical means of optimizing the system through component analysis and cost valuation.", "labels": [], "entities": []}, {"text": "Abstract We examine what purpose a dialog metric serves and then propose empirical methods for evaluating systems that meet that purpose.", "labels": [], "entities": [{"text": "Abstract", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.930237889289856}]}, {"text": "The methods include a protocol for conducting a wizard-of-oz experiment and a basic set of descriptive statistics for substantiating performance claims using the data collected from the experiment as an ideal benchmark or \"gold standard\" for comparative judgments.", "labels": [], "entities": []}, {"text": "The methods also provide a practical means of optimizing the system through component analysis and cost valuation.", "labels": [], "entities": []}], "introductionContent": [{"text": "In evaluating the performance of dialog systems, designers face a number of complicated issues.", "labels": [], "entities": []}, {"text": "On the one hand, dialog systems are ultimately created for the user, so usability factors such as satisfaction or likelihood of future use should be the final criteria.", "labels": [], "entities": []}, {"text": "On the other hand, because usability factors are subjective, they can be erratic and highly dependent on features of the user interface).", "labels": [], "entities": []}, {"text": "So, designers have turned to \"objective\" metrics such as dialog success rate or completion time.", "labels": [], "entities": [{"text": "completion time", "start_pos": 80, "end_pos": 95, "type": "METRIC", "confidence": 0.9325587451457977}]}, {"text": "Unfortunately, due to the interactive nature of dialog, these metrics do not always correspond to the most effective user experience ().", "labels": [], "entities": []}, {"text": "Furthermore, several different metrics may contradict one another), leaving designers with the tricky task of untangling the interactions or correlations between metrics.", "labels": [], "entities": []}, {"text": "Instead of focusing on developing anew metric that circumvents the problems above, we maintain that designers need to make better use of the ones that already exist.", "labels": [], "entities": []}, {"text": "Toward that end, we first examine what purpose a dialog metric serves and then propose empirical methods for evaluating systems that meet that purpose.", "labels": [], "entities": []}, {"text": "The methods include a protocol for conducting a wizard-of-oz experiment and a basic set of descriptive statistics for substantiating performance claims using the data collected from the experiment as an ideal benchmark or \"gold standard\" for comparative judgments.", "labels": [], "entities": []}, {"text": "The methods also provide a practical means of optimizing the system through component analysis and cost valuation.", "labels": [], "entities": []}], "datasetContent": [{"text": "Collecting human performance data for establishing a gold standard requires conducting a carefully controlled wizard-of-oz (WOZ) study.", "labels": [], "entities": []}, {"text": "The general idea is that users communicate with a human \"wizard\" under the illusion that they are interacting with a computational system.", "labels": [], "entities": []}, {"text": "For spoken dialog systems, maintaining the illusion usually involves utilizing a synthetic voice to output wizard responses, often through voice distortion or a text-to-speech (TTS) generator.", "labels": [], "entities": []}, {"text": "The typical use of a WOZ study is to record and analyze user input and wizard output.", "labels": [], "entities": []}, {"text": "This allows designers to know what to expect and what they should try to support.", "labels": [], "entities": []}, {"text": "User input is especially critical for speech recognition systems that rely on the collected data for acoustic training and language modeling.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.8013244271278381}, {"text": "language modeling", "start_pos": 123, "end_pos": 140, "type": "TASK", "confidence": 0.7108163982629776}]}, {"text": "In iterative WOZ studies, previously collected data is used to adjust the system so that as the performance of the system improves, the studies employ less of the wizard and more of the system ().", "labels": [], "entities": []}, {"text": "In the process, design constraints in the interface maybe revealed, in which case, further studies are conducted until acceptable tradeoffs are found.", "labels": [], "entities": []}, {"text": "In contrast to the typical use, a WOZ study for establishing a gold standard prohibits modifications to the interface or experimental \"curtain.\"", "labels": [], "entities": []}, {"text": "As shown in, all input and output through the interface must be carefully controlled.", "labels": [], "entities": []}, {"text": "If designers want to use previously collected performance data as a gold standard, they need to verify that all input and output have remained constant.", "labels": [], "entities": []}, {"text": "The protocol for establishing a gold standard is straightforward: (1) Select a dialog metric to serve as an objective function for evaluation.", "labels": [], "entities": []}, {"text": "To motivate the above protocol, consider how a WOZ study might be used to evaluate spoken dialog systems.", "labels": [], "entities": [{"text": "WOZ study", "start_pos": 47, "end_pos": 56, "type": "DATASET", "confidence": 0.6991772502660751}]}, {"text": "The Achilles' heel of spoken interaction is the fragility of the speech recognizer.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 65, "end_pos": 82, "type": "TASK", "confidence": 0.7144207656383514}]}, {"text": "System performance depends highly on the quality of the recognition.", "labels": [], "entities": []}, {"text": "Suppose a designer is interested in bolstering the robustness of a dialog system by exploiting various repair strategies.", "labels": [], "entities": []}, {"text": "Using task completion rate as an objective function, the designer varies the repair strategies utilized by the system.", "labels": [], "entities": []}, {"text": "To make claims about the robustness of these repair strategies, the designer must keep all other input and output constant.", "labels": [], "entities": []}, {"text": "In particular, the wizard in the experiment must receive utterances through the same speech recognizer as the dialog system.", "labels": [], "entities": []}, {"text": "The performance of the wizard on the same quality of input as the dialog system constitutes the gold standard.", "labels": [], "entities": []}, {"text": "The designer may also wish to keep the set of repair strategies constant while varying the use or disuse of the speech recognizer to estimate how much the recognizer degrades task completion.", "labels": [], "entities": []}, {"text": "A deep intuition underlies the experimental control of the speech recognizer.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.7035272717475891}]}, {"text": "As researchers have observed, people with impaired hearing or non-native language skills still manage to communicate effectively despite noisy or uncertain input.", "labels": [], "entities": []}, {"text": "Unfortunately, the same cannot be said of computers with analogous deficiencies.", "labels": [], "entities": []}, {"text": "People overcome their deficiencies by collaboratively working out the mutual belief that their utterances have been understood sufficiently for current purposes -a process referred to as \"grounding\".", "labels": [], "entities": []}, {"text": "Repair strategies based on grounding indeed show promise for improving the robustness of spoken dialog systems).", "labels": [], "entities": []}], "tableCaptions": []}