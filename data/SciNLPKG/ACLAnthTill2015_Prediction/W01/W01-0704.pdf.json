{"title": [{"text": "Semantic Pattern Learning Through Maximum Entropy-based WSD technique", "labels": [], "entities": [{"text": "Semantic Pattern Learning", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8547501762708029}]}], "abstractContent": [{"text": "This paper describes a Natural Language Learning method that extracts knowledge in the form of semantic patterns with ontology elements associated to syntactic components in the text.", "labels": [], "entities": []}, {"text": "The method combines the use of EuroWord-Net's ontological concepts and the correct sense of each word assigned by a Word Sense Disambiguation(WSD) module to extract three sets of patterns: subject-verb, verb-direct object and verb-indirect object.", "labels": [], "entities": [{"text": "EuroWord-Net", "start_pos": 31, "end_pos": 43, "type": "DATASET", "confidence": 0.9528374075889587}, {"text": "Word Sense Disambiguation(WSD) module", "start_pos": 116, "end_pos": 153, "type": "TASK", "confidence": 0.7546636121613639}]}, {"text": "These sets define the semantic behaviour of the main textual elements based on their syntactic role.", "labels": [], "entities": []}, {"text": "On the one hand, it is shown that Maximum Entropy models applied to WSD tasks provide good results.", "labels": [], "entities": [{"text": "WSD tasks", "start_pos": 68, "end_pos": 77, "type": "TASK", "confidence": 0.9032610654830933}]}, {"text": "The evaluation of the WSD module has revealed a accuracy rate of 64% in a preliminary test.", "labels": [], "entities": [{"text": "WSD", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.8663180470466614}, {"text": "accuracy rate", "start_pos": 48, "end_pos": 61, "type": "METRIC", "confidence": 0.980543464422226}]}, {"text": "On the other hand, we explain how an adequate set of semantic or ontological patterns can improve the success rate of NLP tasks such us pronoun resolution.", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 136, "end_pos": 154, "type": "TASK", "confidence": 0.7683053016662598}]}, {"text": "We have implemented both modules in C++ and although the evaluation has been performed for En-glish, their general features allow the treatment of other languages like Span-ish.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic patterns, as defined in this method, configure a system to add anew information source to Natural Language Processing (NLP) tasks.", "labels": [], "entities": []}, {"text": "To obtain these semantic patterns, it is necessary to count on different tools.", "labels": [], "entities": []}, {"text": "On the one hand, a full parser must make a syntactic analysis of the text.", "labels": [], "entities": []}, {"text": "This parsing will allow the selection of the different syntactic functional elements such as subject, direct object (DObj) and indirect object (IObj).", "labels": [], "entities": []}, {"text": "On the other hand, a WSD tool must provide the correct sense in order to ensure the appropriate selection of the ontological concept associated to each word.", "labels": [], "entities": [{"text": "WSD", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9667684435844421}]}, {"text": "Finally, with the parsing and the correct sense of each word, the pattern extraction method will form and store ontological pairs that define the semantic behaviour of each sentence.", "labels": [], "entities": []}], "datasetContent": [{"text": "Some evaluation results over a few terms of the aforementioned corpus are presented in ).", "labels": [], "entities": []}, {"text": "For each word, the training set is divided in 10 folds, 9 for training and 1 for evaluation; ten tests were accomplished using a different fold for evaluation in each one (10-fold cross-validation).", "labels": [], "entities": []}, {"text": "The accuracy results are the average accuracy on the ten tests fora word.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995217323303223}, {"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9986172914505005}]}, {"text": "Results comparison with previous work is difficult because there is different approaches to the WSD task (knowledge based methods, supervised and unsupervised statistical methods...)) and many of them focus on a different set of words and sense definitions.", "labels": [], "entities": [{"text": "WSD task", "start_pos": 96, "end_pos": 104, "type": "TASK", "confidence": 0.931473970413208}]}, {"text": "Furthermore, the training corpus seems to be critical to the application of the learning to a specific).", "labels": [], "entities": []}, {"text": "In the experiment presented here, the selection of the target words and the corpus used are the same that () where a Boosting method is proposed.", "labels": [], "entities": []}, {"text": "In this paper a comparison between some WSD methods is shown.", "labels": [], "entities": [{"text": "WSD", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.9767779111862183}]}, {"text": "Boosting is the most successful method with a 68.1 % accuracy.", "labels": [], "entities": [{"text": "Boosting", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.6490515470504761}, {"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9985912442207336}]}, {"text": "Our method obtains lower accuracy but this is a first implementation and a better feature selection is expected to improve our results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9990142583847046}]}], "tableCaptions": [{"text": " Table 1: Evaluation results from DSO-WSJ", "labels": [], "entities": [{"text": "DSO-WSJ", "start_pos": 34, "end_pos": 41, "type": "DATASET", "confidence": 0.9305393099784851}]}]}