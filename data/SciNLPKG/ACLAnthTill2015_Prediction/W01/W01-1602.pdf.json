{"title": [{"text": "Variant T ransduction: A Method for Rapid Development of Interactive Sp o ken Interfaces", "labels": [], "entities": [{"text": "Variant T ransduction", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.47030147910118103}]}], "abstractContent": [{"text": "We describe an approach (\\ v ari-ant transduction\") aimed at reducing the eeort and skill involved in building spoken language interfaces.", "labels": [], "entities": []}, {"text": "Applications are created by specifying a relatively small set of example utterance-action pairs grouped into contexts.", "labels": [], "entities": []}, {"text": "No intermediate semantic representations are involved in the speciication, and the connrmation requests used in the dialog are constructed automatically.", "labels": [], "entities": []}, {"text": "These properties of variant transduction arise from combining techniques for paraphrase generation , classiication, and example-matching.", "labels": [], "entities": [{"text": "paraphrase generation", "start_pos": 77, "end_pos": 98, "type": "TASK", "confidence": 0.8587805032730103}]}, {"text": "We describe how a s p o-ken dialog system is constructed with this approach and also provide some experimental results on varying the number of examples used to build a particular application.", "labels": [], "entities": []}], "introductionContent": [{"text": "Developing non-trivial interactive s p o ken language applications currently requires signiicant eort, often several person-months.", "labels": [], "entities": []}, {"text": "A major part of this eort is aimed at coping with variation in the spoken language input by users.", "labels": [], "entities": []}, {"text": "One approach to handling variation is to write a large natural language grammar manually and hope that its coverage is suucient f or multiple applications.", "labels": [], "entities": []}, {"text": "Another approach is to create a simulation of the intended system (typically with a human in the loop) and then record users interacting with the simulation.", "labels": [], "entities": []}, {"text": "The recordings are then transcribed and annotated with semantic information relating to the domainn the transcriptions and annotations can then be used to create a statistical understanding model) or used as guidance for manual grammar development (.", "labels": [], "entities": [{"text": "manual grammar development", "start_pos": 221, "end_pos": 247, "type": "TASK", "confidence": 0.7074757218360901}]}, {"text": "Building mixed initiative s p o ken language systems currently usually involves the design of semantic representations speciic to the application domain.", "labels": [], "entities": []}, {"text": "These representations are used to pass data between the language processing components: understanding, dialog, connrmation generation, and response generation.", "labels": [], "entities": [{"text": "connrmation generation", "start_pos": 111, "end_pos": 133, "type": "TASK", "confidence": 0.6437927037477493}, {"text": "response generation", "start_pos": 139, "end_pos": 158, "type": "TASK", "confidence": 0.6998001784086227}]}, {"text": "However, such representations tend to be domain-speciic, and this makes it diicult to port to new domains or to use machine learning techniques without extensive handlabeling of data with the semantic representations.", "labels": [], "entities": []}, {"text": "Furthermore, the use of intermediate semantic representations still requires anal transduction step from the intermediate representation to the action format expected by the application back-end (e.g. SQL database query or procedure call).", "labels": [], "entities": []}, {"text": "For situations when the eeort and expertise available to build an application is small, the methods mentioned above are impractical, and highly directed dialog systems with little allowance for language variability are constructed.", "labels": [], "entities": []}, {"text": "In this paper, we describe an approach to constructing interactive s p o ken language applications aimed at alleviating these problems.", "labels": [], "entities": []}, {"text": "We rst outline the characteristics of the method (section 2) and what needs to be provided by the application builder (section 3).", "labels": [], "entities": []}, {"text": "In section 4 and section 5 we explain variant expansion and the operation of the system at runtime, and in section 6 we describe how connrmation requests are produced by the system.", "labels": [], "entities": [{"text": "variant expansion", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7035766690969467}]}, {"text": "In section 7 we g iv e some initial experimental results on varying the number of examples used to construct a call-routing application.", "labels": [], "entities": []}], "datasetContent": [{"text": "An important question relating to our method is the eect of the number of examples on system interpretation accuracy.", "labels": [], "entities": [{"text": "eect", "start_pos": 52, "end_pos": 56, "type": "METRIC", "confidence": 0.9946211576461792}, {"text": "system interpretation", "start_pos": 86, "end_pos": 107, "type": "TASK", "confidence": 0.6868885457515717}, {"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.8108775615692139}]}, {"text": "To measure this eeect, we chose the operator services call routing task described by.", "labels": [], "entities": [{"text": "operator services call routing", "start_pos": 36, "end_pos": 66, "type": "TASK", "confidence": 0.6012549698352814}]}, {"text": "We chose this task because a reasonably large data set was available in the form of actual recordings of thousands of real customers calling AT&T's operators, together with transcriptions and manual labeling of the desired call destination.", "labels": [], "entities": []}, {"text": "More speciically, we measure the call routing accuracy for unconstrained caller responses to the initial context prompt AT&T.", "labels": [], "entities": [{"text": "call routing", "start_pos": 33, "end_pos": 45, "type": "TASK", "confidence": 0.7534871399402618}, {"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.802355945110321}]}, {"text": "How may I help you?.", "labels": [], "entities": []}, {"text": "Another advantage of this task was that benchmark call routing accuracy gures were available for systems built with the full data set ().", "labels": [], "entities": [{"text": "benchmark call routing", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.5775558153788248}, {"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.6818123459815979}]}, {"text": "We ha ve no t yet measured interpretation accuracy for the structurally more complex e-mail access application.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9791187644004822}]}, {"text": "In this experiment, the responses to How may I help you? are \\routed\" to fteen destinations, where routing means handing oo the call to another system or human operator, or moving to another example-action context that will interact further with the user to elicit further information so that a subtask (such a s making a collect call) can be completed.", "labels": [], "entities": []}, {"text": "Thus the actions in the initial context are simply the destinations, i.e. a = a 0 , and the matcher is only used to compute e 0 . The fteen destinations include a destination \\other\" which is treated specially in that it is also taken to be the destination when the system rejects the user's input, for example because the conndence in the output of the speech recognizer is too low.", "labels": [], "entities": []}, {"text": "Following previous work on this task, cited above, we present the results for each experimental condition as an ROC curve plotting the routing accuracy (on non-rejected utterances) as a function of the false rejection rate (the percentage of the samples incorrectly rejected)) a classiication by the system of \\other\" is considered equivalent to rejection.", "labels": [], "entities": [{"text": "ROC", "start_pos": 112, "end_pos": 115, "type": "METRIC", "confidence": 0.8709798455238342}, {"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.8192127346992493}]}, {"text": "The dataset consists of 8,844 utterances of which 1000 were held out for testing.", "labels": [], "entities": []}, {"text": "We refer to the remaining 7,884 utterances as the \\full training dataset\".", "labels": [], "entities": []}, {"text": "In the experiments, we vary two conditions: Input uncertainty The input string to the interpretation component is either a human transcription of the spoken utterance or the output of a speech recognizer.", "labels": [], "entities": [{"text": "Input uncertainty", "start_pos": 44, "end_pos": 61, "type": "METRIC", "confidence": 0.9656888544559479}]}, {"text": "The acoustic model used for automatic speech recognition was a general telephone speech HHM model in all cases.", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 28, "end_pos": 56, "type": "TASK", "confidence": 0.6512158513069153}]}, {"text": "(For the full dataset, better results can be achieved by an applicationspeciic acoustic model, as presented by and connrmed by our results below.)", "labels": [], "entities": []}, {"text": "Size of example set We select progressively larger subsets of examples from the full training set, as well as showing results for the full training set itself.", "labels": [], "entities": []}, {"text": "We wish to approximate the situation where an application developer uses typical examples for the initial context without knowing the distribution of call types.", "labels": [], "entities": []}, {"text": "We therefore select k utterances for each destination, with k set to 3, 5, and 10, respectively.", "labels": [], "entities": []}, {"text": "This selection is random, except for the provision that utterances appearing more than once are preferred, to approximate the notion of atypical utterance.", "labels": [], "entities": []}, {"text": "The selected examples are expanded by the addition of variants, as described earlier.", "labels": [], "entities": []}, {"text": "For each value of k, the results shown are for the median of three runs.", "labels": [], "entities": []}, {"text": "shows the routing accuracy ROC curves for transcribed input fork = 3 \ud97b\udf59 5\ud97b\udf59 10 and for the full training dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9440602660179138}, {"text": "ROC", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.7546099424362183}]}, {"text": "These results for transcribed input were obtained with BoosTexter () as the classiier module in our system because we have observed that BoosTexter generally outperforms our Phi classiier (mentioned earlier) for text input.", "labels": [], "entities": []}, {"text": "shows the corresponding four ROC curves for recognition output, and an additional fth graph (the top one) showing the improvement that is obtained with a domain speciic acoustic model coupled with a trigram language model.", "labels": [], "entities": [{"text": "ROC", "start_pos": 29, "end_pos": 32, "type": "METRIC", "confidence": 0.817299485206604}]}, {"text": "These results for recognition output were obtained with the Phi classiier module rather than BoosTexterr the Phi classiier performance is generally the same as, or slightly better than, BoosTexter when applied to recognition output.", "labels": [], "entities": [{"text": "recognition output", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.910278707742691}, {"text": "BoosTexterr", "start_pos": 93, "end_pos": 104, "type": "DATASET", "confidence": 0.7204785943031311}]}, {"text": "The language models used in the experiments for are derived from the example sets fork = 3 \ud97b\udf59 5\ud97b\udf59 10 (lower three graphs) and for the full training set (upper two graphs), respectively.", "labels": [], "entities": []}, {"text": "As described earlier, the language model for restricted numbers of examples is an unweighted one that recognizes sequences of substrings of the examples.", "labels": [], "entities": []}, {"text": "For the full training set, statistical N-gram language models are used (N=3 for the top graph and N=2 for the second to top) since there is suf\ud97b\udf59cient data in the full training set for such language models to be eeective.", "labels": [], "entities": []}, {"text": "Comparing the two gures, it can be seen that the performance shortfall from using small numbers of examples compared to the full training set is greater when speech recog- nition errors are included.", "labels": [], "entities": []}, {"text": "This suggests that it might be advantageous to use the examples to adapt a general statistical language model.", "labels": [], "entities": []}, {"text": "There also seem to be diminishing returns ask is increased from 3 to 5 to 10.", "labels": [], "entities": [{"text": "ask", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.49938148260116577}]}, {"text": "A likely explanation is that expansion of examples by variants is progressively less eeective a st he size of the unexpanded set is increased.", "labels": [], "entities": []}, {"text": "This is to be expected since additional real examples presumably are more faithful to the task than artiicially generated variants.", "labels": [], "entities": []}], "tableCaptions": []}