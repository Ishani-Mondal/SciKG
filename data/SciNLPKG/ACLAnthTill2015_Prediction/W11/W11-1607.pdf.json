{"title": [], "abstractContent": [{"text": "We present a system for fusing sentences which are drawn from the same source document but have different content.", "labels": [], "entities": []}, {"text": "Unlike previous work, our approach is supervised, training on real-world examples of sentences fused by professional journalists in the process of editing news articles.", "labels": [], "entities": []}, {"text": "Like Filippova and Strube (2008), our system merges dependency graphs using Integer Linear Programming.", "labels": [], "entities": []}, {"text": "However, instead of aligning the inputs as a preprocess, we integrate the tasks of finding an alignment and selecting a merged sentence into a joint optimization problem, and learn parameters for this optimization using a structured online algorithm.", "labels": [], "entities": []}, {"text": "Evaluation by human judges shows that our technique produces fused sentences that are both informative and readable.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentence fusion is the process by which content from two or more original sentences is transformed into a single output sentence.", "labels": [], "entities": [{"text": "Sentence fusion", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9103600978851318}]}, {"text": "It is usually studied in the context of multidocument summarization, since fusing similar sentences can avoid repetition of material which is shared by more than one input.", "labels": [], "entities": [{"text": "multidocument summarization", "start_pos": 40, "end_pos": 67, "type": "TASK", "confidence": 0.6417044997215271}]}, {"text": "However, human editors and summarizers do not restrict themselves to combining sentences which share most of their content.", "labels": [], "entities": []}, {"text": "This paper extends previous work on fusion to the casein which the input sentences are drawn from the same document and express fundamentally different content, while still remaining related enough to make fusion sensible 1 . Our data comes from a corpus of news articles for which we have un-edited and edited versions.", "labels": [], "entities": []}, {"text": "We search this corpus for sentences which were fused (or separated) by the editor; these constitute naturally occurring data for our system.", "labels": [], "entities": []}, {"text": "One example from our dataset consists of input sentences (1) and (2) and output (3).", "labels": [], "entities": []}, {"text": "We show corresponding regions of the input and output in boldface.", "labels": [], "entities": []}, {"text": "(1) The bodies showed signs of torture.", "labels": [], "entities": []}, {"text": "(2) They were left on the side of a highway in Chilpancingo, about an hour north of the tourist resort of Acapulco in the southern state of Guerrero, state police said.", "labels": [], "entities": []}, {"text": "(3) The bodies of the men, which showed signs of torture, were left on the side of a highway in Chilpancingo, which is about an hour north of the tourist resort of Acapulco, state police told Reuters.", "labels": [], "entities": []}, {"text": "While the two original sentences are linked by a common topic and reference to a shared entity, they are not paraphrases of one another.", "labels": [], "entities": []}, {"text": "This could create a problem for traditional fusion systems which first find an alignment between similar dependency graphs, then extract a shared structure.", "labels": [], "entities": []}, {"text": "While our system has the same basic framework of alignment and extraction, it performs the two jointly, as parts of a global optimization task.", "labels": [], "entities": [{"text": "alignment and extraction", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.7505082686742147}]}, {"text": "This makes it robust to uncertainty about the hidden correspondences between the sentences.", "labels": [], "entities": []}, {"text": "We use structured online learning to find parameters for the system, allowing it to bitbucket.org/melsner/sentencefusion.", "labels": [], "entities": []}, {"text": "discover good ways to piece together input sentences by examining examples from our corpus.", "labels": [], "entities": []}, {"text": "Sentence fusion is a common strategy in humanauthored summaries of single documents-36% of sentences in the summaries investigated by contain content from multiple sentences in the original document.", "labels": [], "entities": [{"text": "Sentence fusion", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9219125509262085}, {"text": "summaries of single documents-36", "start_pos": 54, "end_pos": 86, "type": "TASK", "confidence": 0.8038283884525299}]}, {"text": "This suggests that a method to fuse dissimilar sentences could be useful for single-document summarization.", "labels": [], "entities": [{"text": "single-document summarization", "start_pos": 77, "end_pos": 106, "type": "TASK", "confidence": 0.617119550704956}]}, {"text": "Our dataset is evidence that editing also involves fusing sentences, and thus that models of this task could contribute to systems for automatic editing.", "labels": [], "entities": [{"text": "automatic editing", "start_pos": 135, "end_pos": 152, "type": "TASK", "confidence": 0.6913306415081024}]}, {"text": "In the remainder of the paper, we first give an overview of related work (Section 2).", "labels": [], "entities": []}, {"text": "We next describe our dataset and preprocessing in more detail (Section 3), describe the optimization we perform (Section 4), and explain how we learn parameters for it (Section 5).", "labels": [], "entities": []}, {"text": "Finally, we discuss our experimental evaluation and give results (Section 6).", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluating sentence fusion is a notoriously difficult task () with no accepted quantitative metrics, so we have to depend on human judges for evaluation.", "labels": [], "entities": [{"text": "sentence fusion", "start_pos": 11, "end_pos": 26, "type": "TASK", "confidence": 0.6976650655269623}]}, {"text": "We compare sentences produced by our system to three alternatives: the editor's fused sentence, a readability upper-bound and a baseline formed by splicing the input sentences together by inserting the word \"and\" between each one.", "labels": [], "entities": []}, {"text": "The readability upper bound is the output of parsing and linearization on the editor's original sentence (; it is designed to measure the loss in grammaticality due to our preprocessing.", "labels": [], "entities": []}, {"text": "Native English speakers rated the fused sentences with respect to readability and content on a scale of 1 to 5 (we give a scoring rubric based on).", "labels": [], "entities": []}, {"text": "12 judges participated in the study, fora total of 1062 evaluations . Each judge saw the each pair of inputs with the retained regions boldfaced, plus a single fusion drawn randomly from among the four systems.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results of human evaluation.", "labels": [], "entities": []}, {"text": " Table 3: Number of times each Content score was as- signed by human judges.", "labels": [], "entities": []}]}