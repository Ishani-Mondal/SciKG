{"title": [{"text": "A Two-Stage Domain Selection Framework for Extensible Multi-Domain Spoken Dialogue Systems", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes a general and effective domain selection framework for multi-domain spoken dialogue systems that employ distributed domain experts.", "labels": [], "entities": []}, {"text": "The framework consists of two processes: deciding if the current domain continues and estimating the probabilities for selecting other domains.", "labels": [], "entities": []}, {"text": "If the current domain does not continue, the domain with the highest activation probability is selected.", "labels": [], "entities": []}, {"text": "Since those processes for each domain expert can be designed independently from other experts and can use a large variety of information , the framework achieves both extensibil-ity and robustness against speech recognition errors.", "labels": [], "entities": [{"text": "speech recognition errors", "start_pos": 205, "end_pos": 230, "type": "TASK", "confidence": 0.7975260019302368}]}, {"text": "The results of an experiment using a corpus of dialogues between humans and a multi-domain dialogue system demonstrate the viability of the proposed framework.", "labels": [], "entities": []}], "introductionContent": [{"text": "As spoken dialogue interfaces are becoming more widely utilized, they will be expected to be able to engage in dialogues in a wide variety of topics.", "labels": [], "entities": []}, {"text": "Particularly, spoken dialogue interfaces for office robots) and multimodal kiosk systems) are expected to deal with people's various requests, unlike automated call center systems that are dedicated to specific tasks.", "labels": [], "entities": []}, {"text": "One effective methodology to build such a system is to integrate systems in small domains by employing distributed multi-domain system architecture.", "labels": [], "entities": []}, {"text": "This architecture has distributed modules * Currently with Panasonic Corporation. that independently manage their own dialogue state and knowledge for speech understanding and utterance generation (e.g.,).", "labels": [], "entities": [{"text": "Panasonic Corporation.", "start_pos": 59, "end_pos": 81, "type": "DATASET", "confidence": 0.9443195760250092}, {"text": "speech understanding", "start_pos": 151, "end_pos": 171, "type": "TASK", "confidence": 0.7155970484018326}, {"text": "utterance generation", "start_pos": 176, "end_pos": 196, "type": "TASK", "confidence": 0.7890582978725433}]}, {"text": "From an engineering viewpoint, such architecture has an advantage in that each domain expert can be designed independently and that it is easy to add new domains.", "labels": [], "entities": []}, {"text": "It enables each domain expert to employ a dialogue strategy very different from those for other domains.", "labels": [], "entities": []}, {"text": "For example, the strategy maybe frame-based mixed-initiative, finite-state-based system-initiative, or plan-based dialogue management ).", "labels": [], "entities": []}, {"text": "One of the crucial issues with distributed multidomain spoken dialogue systems is how to select an appropriate domain for each user utterance so that the system can appropriately understand it and answer it.", "labels": [], "entities": []}, {"text": "So far several methods have been proposed but none of them satisfy two basic requirements at the same time: the ability to be used with a variety of domain experts (extensibility) and being robust against ASR (Automatic Speech Recognition) errors (robustness).", "labels": [], "entities": [{"text": "ASR (Automatic Speech Recognition)", "start_pos": 205, "end_pos": 239, "type": "TASK", "confidence": 0.6993613988161087}]}, {"text": "We suspect that this is one of the main reasons why not many multi-domain spoken dialogue systems have been developed even though their utility is widely recognized.", "labels": [], "entities": []}, {"text": "This paper presents anew general framework for domain selection that satisfies the above two requirements.", "labels": [], "entities": [{"text": "domain selection", "start_pos": 47, "end_pos": 63, "type": "TASK", "confidence": 0.798055499792099}]}, {"text": "In our framework, each expert needs to have two additional submodules: one for estimating the probability that it is newly activated, and one for deciding domain continuation when it is already activated.", "labels": [], "entities": [{"text": "deciding domain continuation", "start_pos": 146, "end_pos": 174, "type": "TASK", "confidence": 0.6179693142573038}]}, {"text": "Since these submodules can be designed independently from those of other experts, there is no restriction on designing experts in our framework, and thus extensibility is achieved.", "labels": [], "entities": []}, {"text": "Robustness is also achieved because those submodules can be designed so that they can utilize domain-dependent information, including information on speech understanding and dialogue history, without detracting from extensibility.", "labels": [], "entities": [{"text": "speech understanding", "start_pos": 149, "end_pos": 169, "type": "TASK", "confidence": 0.7189076244831085}]}, {"text": "Especially the submodule for deciding domain continuation has the ability to utilize dialogue history to avoid erroneous domain shifts that often occur in previous approaches.", "labels": [], "entities": [{"text": "deciding domain continuation", "start_pos": 29, "end_pos": 57, "type": "TASK", "confidence": 0.7901572585105896}]}, {"text": "Note that we do not focus on classifying each utterance without contextual information (e.g.,).", "labels": [], "entities": []}, {"text": "Rather, we try to estimate the user intention with regard to continuing and shifting domains in the course of dialogues.", "labels": [], "entities": []}, {"text": "In what follows, Section 2 explains the distributed multi-domain spoken dialogue system architecture and requirements for domain selection.", "labels": [], "entities": []}, {"text": "Section 3 discusses previous work, and Section 4 presents our proposed framework.", "labels": [], "entities": []}, {"text": "Section 5 describes an example implementation and its evaluation results, and Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Since the proposed framework is an extension of the previous methods, if the activation probability estimator and domain continuation decision maker for each expert are designed well and trained using enough data, it should outperform previous methods that satisfy extensibility.", "labels": [], "entities": []}, {"text": "We believe that this theoretical consideration and an experimental result using a human-system dialogue corpus show the viability of the framework.", "labels": [], "entities": []}, {"text": "Below we explain our implementation and an experiment.", "labels": [], "entities": []}, {"text": "To evaluate the domain selection, we focused on domain shifts rather than the selected domain.", "labels": [], "entities": []}, {"text": "We classified the domain selection results into domain continuations, domain shifts, and OOD utterance detection.", "labels": [], "entities": [{"text": "domain continuations", "start_pos": 48, "end_pos": 68, "type": "TASK", "confidence": 0.7163238078355789}, {"text": "domain shifts", "start_pos": 70, "end_pos": 83, "type": "TASK", "confidence": 0.6485195308923721}, {"text": "OOD utterance detection", "start_pos": 89, "end_pos": 112, "type": "TASK", "confidence": 0.8259137868881226}]}, {"text": "As the evaluation metric, we used the weighted average of F 1 scores for those classes.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 58, "end_pos": 68, "type": "METRIC", "confidence": 0.9601369698842367}]}, {"text": "Here the weight is the ratio of those classes of correct labels.", "labels": [], "entities": []}, {"text": "Note that shifting to an incorrect domain is counted as a false positive when calculating precision for domain shifts.", "labels": [], "entities": [{"text": "precision", "start_pos": 90, "end_pos": 99, "type": "METRIC", "confidence": 0.9978244304656982}]}, {"text": "In addition, the confusion matrices for the three best methods are shown in.", "labels": [], "entities": []}, {"text": "We found FULLIMPL outperforms the other four methods.", "labels": [], "entities": [{"text": "FULLIMPL", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9955358505249023}]}, {"text": "We also found that the differences between the results of the compared methods are all statistically significant (p < .01) by two-tailed binomial tests.", "labels": [], "entities": []}, {"text": "For reference, we also evaluated a classifier-based method that uses features from all the experts.", "labels": [], "entities": []}, {"text": "Note that this method does not satisfy extensibility because it requires training data in the same set of domains as the target system.", "labels": [], "entities": []}, {"text": "We evaluated this just for estimating how well our proposed method works while satisfying extensibility.", "labels": [], "entities": []}, {"text": "It classifies each utterance into one of four categories: the QA expert's domain, the RU expert's domain, the most recently activated IP expert's domain, and OOD.", "labels": [], "entities": [{"text": "OOD", "start_pos": 158, "end_pos": 161, "type": "METRIC", "confidence": 0.7158790230751038}]}, {"text": "If no IP expert has been activated before the utterance, threefold classification was performed.", "labels": [], "entities": []}, {"text": "The training and test data were split depending on whether one of the IP experts has been activated before, and training and testing were separately conducted.", "labels": [], "entities": []}, {"text": "The training data A was used for training SVM classifiers.", "labels": [], "entities": [{"text": "SVM classifiers", "start_pos": 42, "end_pos": 57, "type": "TASK", "confidence": 0.8472554981708527}]}, {"text": "Then feature selection was performed using the training data B.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 5, "end_pos": 22, "type": "TASK", "confidence": 0.7430996894836426}]}, {"text": "The performance of this method is shown as CLASSIFIER in.", "labels": [], "entities": [{"text": "CLASSIFIER", "start_pos": 43, "end_pos": 53, "type": "METRIC", "confidence": 0.8210472464561462}]}, {"text": "Although this method outperforms FULLIMPL, FULLIMPL's performance is close to this method.", "labels": [], "entities": [{"text": "FULLIMPL", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.4845808446407318}, {"text": "FULLIMPL", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.6028310656547546}]}, {"text": "This shows that our method does not degrade its performance very much even though it satisfies extensibility.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of utterances in each domain in the  training and test data.", "labels": [], "entities": []}, {"text": " Table 2: Speech understanding in each expert.", "labels": [], "entities": [{"text": "Speech understanding", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.8170161545276642}]}, {"text": " Table 3: Evaluation results (\"cont.\" means \"continue.\").", "labels": [], "entities": []}, {"text": " Table 4: Confusion matrices for the domain shifts.", "labels": [], "entities": []}]}