{"title": [{"text": "Feature Selection for Sentiment Analysis Based on Content and Syntax Models", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.9874475002288818}]}], "abstractContent": [{"text": "Recent solutions for sentiment analysis have relied on feature selection methods ranging from lexicon-based approaches where the set of features are generated by humans, to approaches that use general statistical measures where features are selected solely on empirical evidence.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.9785465598106384}]}, {"text": "The advantage of statistical approaches is that they are fully automatic, however , they often fail to separate features that carry sentiment from those that do not.", "labels": [], "entities": []}, {"text": "In this paper we propose a set of new feature selection schemes that use a Content and Syntax model to automatically learn a set of features in a review document by separating the entities that are being reviewed from the subjective expressions that describe those entities in terms of polarities.", "labels": [], "entities": []}, {"text": "By focusing only on the subjective expressions and ignoring the entities , we can choose more salient features for document-level sentiment analysis.", "labels": [], "entities": [{"text": "document-level sentiment analysis", "start_pos": 115, "end_pos": 148, "type": "TASK", "confidence": 0.7418006559213003}]}, {"text": "The results obtained from using these features in a maximum entropy classifier are competitive with the state-of-the-art machine learning approaches .", "labels": [], "entities": []}], "introductionContent": [{"text": "As user generated data become more commonplace, we seek to find better approaches to extract and classify relevant content automatically.", "labels": [], "entities": []}, {"text": "This gives users a richer, more informative, and more appropriate set of information in an efficient and organized manner.", "labels": [], "entities": []}, {"text": "One way for organizing such data is text classification, which involves mapping documents into topical categories based on the occurrences of particular features.", "labels": [], "entities": [{"text": "text classification", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.7415545731782913}]}, {"text": "Sentiment Analysis (SA) can be framed as a text classification task where the categories are polarities such as positive and negative.", "labels": [], "entities": [{"text": "Sentiment Analysis (SA)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9332664966583252}, {"text": "text classification task", "start_pos": 43, "end_pos": 67, "type": "TASK", "confidence": 0.7716701726118723}]}, {"text": "However, the similarities end here.", "labels": [], "entities": []}, {"text": "Whereas general text classification is concerned with features that distinguish different topics, sentiment analysis deals with features about subjectivity, affect, emotion, and pointsof-view that describe or modify the related entities.", "labels": [], "entities": [{"text": "general text classification", "start_pos": 8, "end_pos": 35, "type": "TASK", "confidence": 0.6842272679011027}, {"text": "sentiment analysis", "start_pos": 98, "end_pos": 116, "type": "TASK", "confidence": 0.9455593228340149}]}, {"text": "Since user-generated review documents contain both kinds of features, SA solutions ultimately face the challenge of separating the factual content from the subjective content describing it.", "labels": [], "entities": []}, {"text": "For example, taking a segment from a randomly chosen document in Pang et al.'s movie review corpus , we see how entities and modifiers are related to each other: ...", "labels": [], "entities": [{"text": "Pang et al.'s movie review corpus", "start_pos": 65, "end_pos": 98, "type": "DATASET", "confidence": 0.7252513244748116}]}, {"text": "Of course, it helps that Kaye has an actor as talented as Norton to play this part.", "labels": [], "entities": []}, {"text": "It's astonishing how frightening Norton looks with a shaved head and a swastika on his chest.", "labels": [], "entities": []}, {"text": "Visually, the film is very powerful.", "labels": [], "entities": []}, {"text": "Kaye indulges in a lot of interesting artistic choices, and most of them work nicely.", "labels": [], "entities": []}, {"text": "Indeed, most of the information about an entity that relates it to a particular polarity comes from the modifying words.", "labels": [], "entities": []}, {"text": "In the example above, these words are adjectives such as talented, frightening, interesting, and powerful.", "labels": [], "entities": []}, {"text": "They can also be verbs such as work and adverbs such as nicely.", "labels": [], "entities": []}, {"text": "The entities are represented by various nouns and pronouns such as: Kaye, Norton, actor and them.", "labels": [], "entities": []}, {"text": "Therefore, the task of classifying a review document can be explored by taking into account a mixture of entities and their modifiers.", "labels": [], "entities": [{"text": "classifying a review document", "start_pos": 23, "end_pos": 52, "type": "TASK", "confidence": 0.8280421495437622}]}, {"text": "An important characteristic of review documents is that the reviewers tend to discuss the whole set of entities throughout the entire document, whereas the modifiers for those entities tend to be more localized at the sentence or phrase level.", "labels": [], "entities": []}, {"text": "In other words, each entity can be polymorphous within the document, with a long-range semantic relationship between its forms while the modifiers in each case are bound to the entity in a short-range, syntactic relationship.", "labels": [], "entities": []}, {"text": "Generalizing a single entity to all the entities that are found in a document, and taking all their respective modifiers into account, we can start to infer the polarity of the entire document based on the set of all the modifiers.", "labels": [], "entities": []}, {"text": "This reduces to finding all the syntactic words in the document and disregarding the entities.", "labels": [], "entities": []}, {"text": "Taking another look at the example modifiers, we might assume that all of the relevant indicators for SA come from specific parts of speech categories such as adjectives and adverbs, while other parts of speech classes such as nouns are more relevant for general text classification, and can be discarded.", "labels": [], "entities": [{"text": "SA", "start_pos": 102, "end_pos": 104, "type": "TASK", "confidence": 0.964167058467865}, {"text": "general text classification", "start_pos": 255, "end_pos": 282, "type": "TASK", "confidence": 0.6721328397591909}]}, {"text": "However, as demonstrated by,,, and, there are some nouns and verbs that are useful sentiment indicators as well.", "labels": [], "entities": []}, {"text": "Therefore, a clear distinction cannot be made along parts of speech categories.", "labels": [], "entities": []}, {"text": "To address this issue, we propose a feature selection scheme in which we can obtain important sentiment indicators that: 1.", "labels": [], "entities": []}, {"text": "Do not rely on specific parts of speech classes while maintaining the focus on syntax words.", "labels": [], "entities": []}, {"text": "2. Separate semantic words that do not indicate sentiment while keeping nouns that do.", "labels": [], "entities": [{"text": "Separate semantic words", "start_pos": 3, "end_pos": 26, "type": "TASK", "confidence": 0.884641170501709}]}, {"text": "3. Reflect the domain for the set of documents.", "labels": [], "entities": []}, {"text": "By using feature selection schemes that focus on the outlined sentiment indicators as a basis for our machine learning approach, we should achieve competitive accuracy results when classifying document polarities.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 159, "end_pos": 167, "type": "METRIC", "confidence": 0.954237699508667}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses some important work and results for SA and outlines the modelling and classification techniques used by our approach.", "labels": [], "entities": [{"text": "SA", "start_pos": 56, "end_pos": 58, "type": "TASK", "confidence": 0.978302001953125}]}, {"text": "Section 3 provides details about our feature selection methods.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 37, "end_pos": 54, "type": "TASK", "confidence": 0.7763627767562866}]}, {"text": "Our experiments and analyses are given in section 4, and conclusions and future directions are presented in section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section describes the steps taken to generate some experimental results for each scheme described in the previous section.", "labels": [], "entities": []}, {"text": "Before we can analyze these sets of results, we take a look at some baselines.", "labels": [], "entities": []}, {"text": "We use the corpus of 2000 movie reviews () that consists of 1000 positive and 1000 negative documents selected from on-line forums.", "labels": [], "entities": []}, {"text": "In our experiments, we randomize the documents and split the data into 1800 for training / testing purposes and 200 as the validation set.", "labels": [], "entities": []}, {"text": "For the 1800 documents, we run a 3-fold cross validation procedure where we train on 1200 documents and test on 600.", "labels": [], "entities": []}, {"text": "We compare the resultant feature sets after each FS scheme using the OpenNLP 2 Maximum Entropy classifier.", "labels": [], "entities": [{"text": "FS", "start_pos": 49, "end_pos": 51, "type": "TASK", "confidence": 0.8481559157371521}, {"text": "OpenNLP 2 Maximum Entropy classifier", "start_pos": 69, "end_pos": 105, "type": "DATASET", "confidence": 0.8735716819763184}]}, {"text": "Throughout these experiments, we are interested in the classification accuracy.", "labels": [], "entities": [{"text": "classification", "start_pos": 55, "end_pos": 69, "type": "TASK", "confidence": 0.9594095349311829}, {"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.8456012010574341}]}, {"text": "This is evaluated simply by comparing the resultant class from the classifier and the actual class annotated by.", "labels": [], "entities": []}, {"text": "The number of matches is divided by the number of documents in the test set.", "labels": [], "entities": []}, {"text": "Thus, given an annotated test set calculate the accuracy as follows: where I(\u00b7) is the indicator function.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9997779726982117}, {"text": "I", "start_pos": 75, "end_pos": 76, "type": "METRIC", "confidence": 0.9893509745597839}]}], "tableCaptions": [{"text": " Table 1. Next,  we tagged all the words and only selected the words  that were tagged as 'JJ*', 'RB*', and 'VB*' cate- gories (the 'syntactic' categories). The idea is to", "labels": [], "entities": []}, {"text": " Table 1: Baseline results with a different number of iter- ations. Each column represents a different feature selec- tion method.", "labels": [], "entities": []}, {"text": " Table 2: Results for FS Based on Syntactic Classes at 10,  25 and 'eval' iterations.", "labels": [], "entities": [{"text": "FS", "start_pos": 22, "end_pos": 24, "type": "TASK", "confidence": 0.8522198796272278}]}, {"text": " Table 3: Results for FS Based on Syntactic-Semantic  set difference method. Each row represents the accuracy  achieved at a particular \u03b4 value.", "labels": [], "entities": [{"text": "FS", "start_pos": 22, "end_pos": 24, "type": "TASK", "confidence": 0.8812203407287598}, {"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9991794228553772}]}]}