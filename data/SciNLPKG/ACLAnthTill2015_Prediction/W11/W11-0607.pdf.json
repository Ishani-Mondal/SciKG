{"title": [{"text": "Composing and Updating Verb Argument Expectations: A Distributional Semantic Model", "labels": [], "entities": []}], "abstractContent": [{"text": "The aim of this paper is to present a computational model of the dynamic composition and update of verb argument expectations using Distributional Memory, a state-of-the-art framework for distributional semantics.", "labels": [], "entities": []}, {"text": "The experimental results conducted on psycholin-guistic data sets show that the model is able to successfully predict the changes on the patient argument thematic fit produced by different types of verb agents.", "labels": [], "entities": [{"text": "psycholin-guistic data sets", "start_pos": 38, "end_pos": 65, "type": "DATASET", "confidence": 0.7527914245923361}]}], "introductionContent": [{"text": "A number of studies using different experimental paradigms (priming, self-paced reading, etc.) have shown that verbs (eat) activate expectations about nouns occurring as their arguments (cheese), and vice versa ().", "labels": [], "entities": []}, {"text": "Nouns also activate expectations about other nouns occurring as co-arguments in the same event (keydoor)).", "labels": [], "entities": []}, {"text": "These behavioral effects support the hypothesis that in the mental lexicon verbs and their arguments are arranged into a web of mutual expectations.", "labels": [], "entities": []}, {"text": "Verb argument expectations encoded in lexical representations are exploited by subjects to determine the plausibility of a noun as an argument of a particular verb (thematic fit, or selectional preferences in the linguistic literature), which has been proved to have important effects on human sentence processing.", "labels": [], "entities": [{"text": "human sentence processing", "start_pos": 288, "end_pos": 313, "type": "TASK", "confidence": 0.7130349278450012}]}, {"text": "Ina recent work, bring evidence suggesting a more complex view of the organization and on-line use of verb argument expectations.", "labels": [], "entities": []}, {"text": "In fact, the expectations about the likely fillers of a given verb argument (e.g., the patient role) depend on the way another verb argument (e.g., the agent role) is filled.", "labels": [], "entities": []}, {"text": "For instance, if the agent noun is journalist, the most likely patient for the verb check is spelling, while if the agent noun is mechanic, the most likely patient for the same verb is brakes.", "labels": [], "entities": []}, {"text": "As a consequence, thematic fit judgments are also sensitive to the way other roles of the same verb are filled.", "labels": [], "entities": []}, {"text": "show that this fact has clear consequences for sentence processing, and argue that subjects dynamically compute and update verb argument expectations and thematic fit during on-line sentence comprehension, by integrating various types of knowledge about events and their arguments.", "labels": [], "entities": [{"text": "sentence processing", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.7634279429912567}]}, {"text": "The aim of this paper is to present a computational model of the dynamic composition and update of verb argument expectations using Distributional Memory (DM)(, a state-of-the-art Distributional Semantic Model (DSM).", "labels": [], "entities": []}, {"text": "DSMs (aka vector space models) represent word meaning with vectors encoding corpusbased co-occurence statistics, under the assumption of the so-called Distributional Hypothesis): Words occurring in similar contexts are also semantically similar.", "labels": [], "entities": []}, {"text": "Thematic fit judgments have already been successfully modeled with), but to the best of our knowledge the problem of how thematic fit is dynamically updated depending on the way other arguments are filled has not been addressed yet.", "labels": [], "entities": []}, {"text": "The core of our proposal is that Distributional Memory can be used to represent the subject's expectations about the most likely words co-occurring in given syntactic role.", "labels": [], "entities": [{"text": "Distributional Memory", "start_pos": 33, "end_pos": 54, "type": "TASK", "confidence": 0.8248812556266785}]}, {"text": "We will add to the original Distributional Memory framework a model for verb argument expectation composition called ECU, Expectation Composition and Update.", "labels": [], "entities": [{"text": "verb argument expectation composition", "start_pos": 72, "end_pos": 109, "type": "TASK", "confidence": 0.6197668313980103}, {"text": "ECU", "start_pos": 117, "end_pos": 120, "type": "METRIC", "confidence": 0.8434638977050781}]}, {"text": "Specifically, we will show how the expectations of an agent-verb pair about their patient noun argument can be compositionally derived from the DM representation of the verb and the DM representation of its agent.", "labels": [], "entities": []}, {"text": "ECU is evaluated on the data set used in, and the experimental results show that it is able to successfully predict the changes on the patient thematic fit with a verb, depending on different agent fillers.", "labels": [], "entities": [{"text": "ECU", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7229716777801514}]}, {"text": "More generally, we want to argue that the ECU model proposed here can represent a general and viable approach to address compositionality in distributional semantics.", "labels": [], "entities": []}, {"text": "After reviewing some related work in section 2, we present Distributional Memory (section 3) and its use to model verb-argument composition (section 4).", "labels": [], "entities": [{"text": "verb-argument composition", "start_pos": 114, "end_pos": 139, "type": "TASK", "confidence": 0.7263950407505035}]}, {"text": "Experiments and evaluation are reported in section 5.", "labels": [], "entities": []}, {"text": "argues that the information on preferred fillers of one verb argument depends on what the filler is of one of the other arguments.", "labels": [], "entities": []}, {"text": "For instance, the most likely patient of cut is wood, when the agent is lumberjack, but it is meat, when the agent is butcher.", "labels": [], "entities": []}, {"text": "This claim finds an empirical confirmation in the experiments reported by, in which subjects are presented with sentence pairs like the following ones: Each pair contains the same verb and patient argument, while differing for the agent argument.", "labels": [], "entities": []}, {"text": "In the congruent condition, the patient is a preferred argument of the verb, given the agent, e.g. spelling is something which is typically checked by a journalist.", "labels": [], "entities": []}, {"text": "In the incongruent condition, the patient is not a preferred argument of the verb, given its agent, e.g. spelling is not something that is typically checked by a mechanic, who rather checks brakes, engines, etc.", "labels": [], "entities": []}, {"text": "Thematic fit judgments used to determine congruent and incongruent agent-verb-patient tuples were collected in an off-line norming study.", "labels": [], "entities": []}, {"text": "report that self-paced reading times were shorter at the word directly following the patient for the congruent than the incongruent items.", "labels": [], "entities": []}, {"text": "Similar results were obtained in an event-related brain potential (ERP) experiment, in which an N400 effect was observed immediately at the patient noun in the incongruent condition.", "labels": [], "entities": []}, {"text": "In eye-tracking experiments, also demonstrated that the thematic fit of an object depended on the other verb argument fillers.", "labels": [], "entities": []}, {"text": "The conclusion drawn by is that verb argument expectations and thematic fit are not simply stored in the lexicon, but are rather dynamically updated during sentence comprehension, by integrating various types of knowledge.", "labels": [], "entities": []}, {"text": "In fact, if the verb expectations about an argument role depend on the nouns filling its other arguments, the hypothesis that they are compositionally updated is highly plausible, since, \"it is difficult to envision how the potentially unbounded number of contexts that might be relevant could be anticipated and stored in the lexicon\".", "labels": [], "entities": []}], "datasetContent": [{"text": "The ECU model for the compositional update of verb-argument expectations has been evaluated by measuring the thematic fit between an agent-verb pair (\u00ef\u00bf\u00bfn AG , v\u00ef\u00bf\u00bf) and a patient noun argument (n PA ) of the same verb.", "labels": [], "entities": [{"text": "compositional update of verb-argument expectations", "start_pos": 22, "end_pos": 72, "type": "TASK", "confidence": 0.8613864183425903}]}, {"text": "Thematic fit is computed with the verb expectations in EX PA (\u00ef\u00bf\u00bfn AG , v\u00ef\u00bf\u00bf), which in turned have been obtained by composing EX(n AG ) and EX PA (v) with either of the two functions described in section 4.", "labels": [], "entities": [{"text": "EX PA", "start_pos": 55, "end_pos": 60, "type": "METRIC", "confidence": 0.8666672110557556}]}, {"text": "In the following subsections, we illustrate the data sets used for the experiments, the procedure to compute the compositional thematic fit in TypeDM, and the results of the experiments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results of the thematic fit experiments (p-values  computed with a \u03c7 2 test).", "labels": [], "entities": []}]}