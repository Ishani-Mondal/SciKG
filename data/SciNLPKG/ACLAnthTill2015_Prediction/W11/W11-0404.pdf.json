{"title": [{"text": "How Good is the Crowd at \"real\" WSD?", "labels": [], "entities": [{"text": "WSD", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.9338734745979309}]}], "abstractContent": [{"text": "There has been a great deal of excitement recently about using the \"wisdom of the crowd\" to collect data of all kinds, quickly and cheaply (Howe, 2008; von Ahn and Dabbish, 2008).", "labels": [], "entities": [{"text": "Howe, 2008; von Ahn and Dabbish, 2008", "start_pos": 140, "end_pos": 177, "type": "DATASET", "confidence": 0.8328589916229248}]}, {"text": "(Snow et al., 2008) were the first to give a convincing demonstration that at least some kinds of linguistic data can be gathered from workers on the web more cheaply than and as accurately as from local experts, and there has been a steady stream of papers and workshops since then with similar results.", "labels": [], "entities": []}, {"text": "e.g. (Callison-Burch and Dredze, 2010).", "labels": [], "entities": []}, {"text": "Many of the tasks which have been successfully crowdsourced involve judgments which are similar to those performed in everyday life, such as recognizing unclear writing (von Ahn et al., 2008), or, for those tasks that require considerable judgment, the responses are usually binary or from a small set of responses, such as sentiment analysis (Mellebeek et al., 2010) or ratings (Heilman and Smith, 2010).", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 324, "end_pos": 342, "type": "TASK", "confidence": 0.9510217308998108}]}, {"text": "Since the FrameNet process is known to be relatively expensive, we were interested in whether the FrameNet process of fine word sense discrimination and marking of dependents with semantic roles could be performed more cheaply and equally accurately using Amazon's Mechanical Turk (AMT) or similar resources.", "labels": [], "entities": [{"text": "fine word sense discrimination and marking of dependents with semantic roles", "start_pos": 118, "end_pos": 194, "type": "TASK", "confidence": 0.6770481033758684}]}, {"text": "We report on a partial success in this respect and how it was achieved.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Results from Trial 1: Rip.v, high.a and show.v", "labels": [], "entities": [{"text": "Rip.v", "start_pos": 32, "end_pos": 37, "type": "METRIC", "confidence": 0.9008155465126038}]}, {"text": " Table 3: Results from recent trials, including accuracy after filtering on the basis of agreement", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.999502420425415}]}, {"text": " Table 4: Confusion matrix for rip.v (rows=gold standard)", "labels": [], "entities": [{"text": "Confusion", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8881689310073853}, {"text": "rip.v", "start_pos": 31, "end_pos": 36, "type": "TASK", "confidence": 0.485294908285141}]}]}