{"title": [{"text": "Learning English Light Verb Constructions: Contextual or Statistical", "labels": [], "entities": [{"text": "Learning English Light Verb Constructions", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.5357244312763214}]}], "abstractContent": [{"text": "In this paper, we investigate a supervised machine learning framework for automatically learning of English Light Verb Constructions (LVCs).", "labels": [], "entities": [{"text": "automatically learning of English Light Verb Constructions (LVCs)", "start_pos": 74, "end_pos": 139, "type": "TASK", "confidence": 0.5954011827707291}]}, {"text": "Our system achieves an 86.3% accuracy with a baseline (chance) performance of 52.2% when trained with groups of either con-textual or statistical features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9981891512870789}]}, {"text": "In addition, we present an in-depth analysis of these contex-tual and statistical features and show that the system trained by these two types of cosmetically different features reaches similar performance empirically.", "labels": [], "entities": []}, {"text": "However, in the situation where the surface structures of candidate LVCs are identical, the system trained with contextual features which contain information on surrounding words performs 16.7% better.", "labels": [], "entities": []}, {"text": "In this study, we also construct a balanced benchmark dataset with 2,162 sentences from BNC for English LVCs.", "labels": [], "entities": []}, {"text": "And this data set is publicly available and is also a useful computational resource for research on MWEs in general.", "labels": [], "entities": [{"text": "MWEs", "start_pos": 100, "end_pos": 104, "type": "TASK", "confidence": 0.9340970516204834}]}], "introductionContent": [{"text": "Multi-Word Expressions (MWEs) refer to various types of linguistic units or expressions, including idioms, noun compounds, named entities, complex verb phrases and any other habitual collocations.", "labels": [], "entities": [{"text": "Multi-Word Expressions (MWEs) refer to various types of linguistic units or expressions, including idioms, noun compounds, named entities, complex verb phrases and any other habitual collocations", "start_pos": 0, "end_pos": 195, "type": "Description", "confidence": 0.7769866716116667}]}, {"text": "MWEs pose a particular challenge in empirical Natural Language Processing (NLP) because they always have idiosyncratic interpretations which cannot be formulated by directly aggregating the semantics of their constituents ().", "labels": [], "entities": [{"text": "empirical Natural Language Processing (NLP)", "start_pos": 36, "end_pos": 79, "type": "TASK", "confidence": 0.6880334871155875}]}, {"text": "The study in this paper focuses on one special type of MWEs, i.e., the Light Verb Constructions (LVCs), formed from a commonly used verb and usually a noun phrase (NP) in its direct object position, such as have a look and make an offer in English.", "labels": [], "entities": []}, {"text": "These complex verb predicates do not fall clearly into the discrete binary distinction of compositional or non-compositional expressions.", "labels": [], "entities": []}, {"text": "Instead, they stand somewhat in between and are typically semi-compositional.", "labels": [], "entities": []}, {"text": "For example, consider the following three candidate LVCs: take a wallet, take a walk and take awhile.", "labels": [], "entities": []}, {"text": "These three complex verb predicates are cosmetically very similar.", "labels": [], "entities": []}, {"text": "But a closer look at their semantics reveals significant differences and each of them represents a different class of MWEs.", "labels": [], "entities": []}, {"text": "The first expression, take a wallet is a literal combination of a verb and its object noun.", "labels": [], "entities": []}, {"text": "The last expression take awhile is an idiom and its meaning cost along time to do something, cannot be derived by direct integration of the literal meaning of its components.", "labels": [], "entities": []}, {"text": "Only the second expression, take a walk is an LVC whose meaning mainly derives from one of its components, namely its noun object (walk) while the meaning of its main verb is somewhat bleached) and therefore light.", "labels": [], "entities": []}, {"text": "LVCs have already been identified as one of the major sources of problems in various NLP applications, such as automatic word alignment and semantic annotation transference (, and machine translation.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 121, "end_pos": 135, "type": "TASK", "confidence": 0.6861804574728012}, {"text": "semantic annotation transference", "start_pos": 140, "end_pos": 172, "type": "TASK", "confidence": 0.6544900238513947}, {"text": "machine translation", "start_pos": 180, "end_pos": 199, "type": "TASK", "confidence": 0.795562744140625}]}, {"text": "These problems provide empirical grounds for distinguishing between the bleached and full meaning of a verb within a given sentence, a task that is often difficult on the basis of surface structures since they always exhibit identical surface properties.", "labels": [], "entities": []}, {"text": "For example, consider the following sentences: 1.", "labels": [], "entities": []}, {"text": "He had a look of childish bewilderment on his face.", "labels": [], "entities": []}, {"text": "2. I've arranged for you to have a look at his file in our library.", "labels": [], "entities": []}, {"text": "In sentence 1, the verb have in the phrase have a look has its full fledged meaning \"possess, own\" and therefore it is literal instead of light.", "labels": [], "entities": []}, {"text": "However, in sentence 2, have a look only means look and the meaning of the verb have is impoverished and is thus light.", "labels": [], "entities": []}, {"text": "In this paper, we propose an in-depth case study on LVC recognition, in which we investigate machine learning techniques for automatically identifying the impoverished meaning of a verb given a sentence.", "labels": [], "entities": [{"text": "LVC recognition", "start_pos": 52, "end_pos": 67, "type": "TASK", "confidence": 0.9101145267486572}, {"text": "automatically identifying the impoverished meaning of a verb given a sentence", "start_pos": 125, "end_pos": 202, "type": "TASK", "confidence": 0.7793970812450756}]}, {"text": "Unlike the earlier work that has viewed all verbs as possible light verbs (), We focus on a half dozen of broadly documented and most frequently used English light verbs among the small set of them in English.", "labels": [], "entities": []}, {"text": "We construct a token-based data set with a total of 2, 162 sentences extracted from British National Corpus (BNC) and build a learner with L2-loss SVM.", "labels": [], "entities": [{"text": "British National Corpus (BNC)", "start_pos": 84, "end_pos": 113, "type": "DATASET", "confidence": 0.975504865248998}]}, {"text": "Our system achieves a 86.3% accuracy with a baseline (chance) performance of 52.2%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9989243149757385}]}, {"text": "We also extract automatically two groups of features, statistical and contextual features and present a detailed ablation analysis of the interaction of these features.", "labels": [], "entities": []}, {"text": "Interestingly, the results show that the system performs similarly when trained independently with either groups of these features.", "labels": [], "entities": []}, {"text": "And the integration of these two types of features does not improve the performance.", "labels": [], "entities": []}, {"text": "However, when tested with all sentences with the candidate LVCs whose surface structures are identical in both negative and positive examples, for example, the aforementioned sentence 1 (negative) and 2 (positive) with the candidate LVC \"have a look\", the system trained with contextual features which include information on surrounding words performs more robust and significantly better.", "labels": [], "entities": []}, {"text": "This analysis contributes significantly to the understanding of the functionality of both contextual and statistical features and provides empirical evidence to guide the usage of them in NLP applications.", "labels": [], "entities": []}, {"text": "In the rest of the paper, we first present some related work on LVCs in Sec.", "labels": [], "entities": []}, {"text": "2. Then we describe our 1 http://www.natcorp.ox.ac.uk/XMLedition/ model including the learning algorithm and statistical and contextual features in Sec.", "labels": [], "entities": []}, {"text": "3. We present our experiments and analysis in Sec.", "labels": [], "entities": []}, {"text": "4 and conclude our paper in Sec.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we report in detail our experimental settings and provide in-depth analysis on the interactions among features.", "labels": [], "entities": []}, {"text": "First, we present our motivation and methodology to generate the new data set.", "labels": [], "entities": []}, {"text": "Then we describe our experimental results and analysis.", "labels": [], "entities": []}, {"text": "For each experiment, we evaluate the performance with three sets of metrics.", "labels": [], "entities": []}, {"text": "We first report the standard accuracy on the test data set.", "labels": [], "entities": [{"text": "standard", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9806419014930725}, {"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.8838692903518677}, {"text": "test data set", "start_pos": 45, "end_pos": 58, "type": "DATASET", "confidence": 0.8461693723996481}]}, {"text": "Since accuracy is argued not to be a sufficient measure of the evaluation of a binary classifier) and some previous works also report F1 values for the positive classes, we therefore choose to report the precision, recall and F1 value for both positive and negative classes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 6, "end_pos": 14, "type": "METRIC", "confidence": 0.9990044236183167}, {"text": "F1", "start_pos": 134, "end_pos": 136, "type": "METRIC", "confidence": 0.9983295798301697}, {"text": "precision", "start_pos": 204, "end_pos": 213, "type": "METRIC", "confidence": 0.9994101524353027}, {"text": "recall", "start_pos": 215, "end_pos": 221, "type": "METRIC", "confidence": 0.9984416365623474}, {"text": "F1", "start_pos": 226, "end_pos": 228, "type": "METRIC", "confidence": 0.9990542531013489}]}, {"text": "True Class + -Predicted Class + tp fp -fn tn Based on the classic confusion matrix as shown in, we calculate the precision and recall for the positive class in equation 1: And similarly, we use equation 2 for negative class.", "labels": [], "entities": [{"text": "precision", "start_pos": 113, "end_pos": 122, "type": "METRIC", "confidence": 0.9996418952941895}, {"text": "recall", "start_pos": 127, "end_pos": 133, "type": "METRIC", "confidence": 0.9994308352470398}]}, {"text": "And the F1 value is the harmonic mean of the precision and recall of each class.", "labels": [], "entities": [{"text": "F1", "start_pos": 8, "end_pos": 10, "type": "METRIC", "confidence": 0.999238133430481}, {"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.999474823474884}, {"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9979919195175171}]}, {"text": "In our experiments, We aim to build a high performance LVC classifier as well as to analyze the interaction between contextual and statistical features.", "labels": [], "entities": []}, {"text": "We randomly sample 90% sentences for training and the rest for testing.", "labels": [], "entities": []}, {"text": "Our chance baseline is 52.2%, which is the percentage of our majority class in the data set.", "labels": [], "entities": [{"text": "chance baseline", "start_pos": 4, "end_pos": 19, "type": "METRIC", "confidence": 0.9721058011054993}]}, {"text": "As shown in: By using all our contextual features, our classifier achieves overall 86.307% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.981020450592041}]}, {"text": "In order to examine the effectiveness of each individual feature, we conduct an ablation analysis and experiment to use only one of them each time.", "labels": [], "entities": []}, {"text": "It is shown in that LV-NounObj is found to be the most effective contextural feature since it boosts the baseline system up the most, an significant increase of 31.6%.", "labels": [], "entities": []}, {"text": "We then start from this most effective feature, LVNounObj and add one feature each step to observe the change of the system accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9922997355461121}]}, {"text": "The results are listed in  to the object noun.", "labels": [], "entities": []}, {"text": "This observation agrees with previous research that the acceptance of LVCs is closely correlated to the linguistic properties of their components.", "labels": [], "entities": []}, {"text": "The part of speech of the word after the phrase seems to have negative effect on the performance.", "labels": [], "entities": []}, {"text": "However, experiments show that without this feature, the overall performance decreases.", "labels": [], "entities": []}, {"text": "When using statistical features, instead of directly using the value, we discretize each value to a binary feature.", "labels": [], "entities": []}, {"text": "On the one hand, our experiments show that this way of transformation achieves the best performance.", "labels": [], "entities": []}, {"text": "On the other hand, the transformation plays an analogical role as a kernel function which maps one dimensional non-linear separable examples into an infinite or high dimensional space to render the data linearly separable.", "labels": [], "entities": []}, {"text": "In these experiments, we use only numerical features described in section 3.1.", "labels": [], "entities": []}, {"text": "And it is interesting to observe that those features achieve very similar  performance as the contextual features as shown in.", "labels": [], "entities": []}, {"text": "To validate that the similar performance is not incidental.", "labels": [], "entities": []}, {"text": "We then separate our data into 10-fold training and testing sets and learn independently from each fold of these ten split., which shows the comparison of accuracies for each data fold, indicates the comparable results for each fold of the data.", "labels": [], "entities": []}, {"text": "Therefore, we conclude that the similar effect achieved by training with these two groups of features is not accidental.", "labels": [], "entities": []}, {"text": "We also conduct an ablation analysis with statistical features.", "labels": [], "entities": []}, {"text": "Similar to the ablation analyses for contextual features, we first find that the most effective statistical feature is Cpmi, the collocational based point-wise mutual information.", "labels": [], "entities": []}, {"text": "Then we add one feature at each step and show the increasing performance in.", "labels": [], "entities": []}, {"text": "Cpmi is shown to be a good indicator for LVCs and this observation agrees with many previous works on the effectiveness of  point-wise mutual information in MWE identification tasks.", "labels": [], "entities": [{"text": "Cpmi", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.8707268834114075}, {"text": "MWE identification tasks", "start_pos": 157, "end_pos": 181, "type": "TASK", "confidence": 0.9675779143969218}]}], "tableCaptions": [{"text": " Table 2: By using all our contextual features, our classi- fier achieves overall 86.307% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9906761646270752}]}, {"text": " Table 4. Other significant features are fea- tures within the candidate LVCs themselves such as  Determiner, Noun Object and Levin's Class related", "labels": [], "entities": []}, {"text": " Table 4: Ablation analysis for contextual features. Each  feature is added incrementally at each step. Performance  gain is associated with a plus sign otherwise a negative  sign.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9328012466430664}]}, {"text": " Table 5: Best performance achieved with statistical fea- tures. Comparing to Table 2, the performance is similar  to that trained with all contextual features.", "labels": [], "entities": []}, {"text": " Table 6: Ablation analysis for statistical features. Each  feature is added incrementally at each step. Performance  gain is associated with a plus sign.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9765673279762268}]}, {"text": " Table 7. This result indi- cates that these two types of features actually pro- vide similar knowledge to the system and therefore  combining them together does not provide any addi- tional new information. This observation also agrees  with the intuition that point-wise mutual informa- tion basically provides information on word collo- cations", "labels": [], "entities": []}, {"text": " Table 7: The classifier achieves similar performance  trained jointly with Cpmi and LV-NounObj features, com- paring with the performance trained independently.", "labels": [], "entities": []}, {"text": " Table 8: Classifier trained with local contextual features  is more robust and significantly better than the one trained  with statistical features when the test data set consists of  all ambiguous examples.", "labels": [], "entities": []}]}