{"title": [{"text": "The RWTH Aachen Machine Translation System for WMT 2011", "labels": [], "entities": [{"text": "RWTH Aachen Machine Translation", "start_pos": 4, "end_pos": 35, "type": "TASK", "confidence": 0.806936115026474}, {"text": "WMT", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.8735319972038269}]}], "abstractContent": [{"text": "This paper describes the statistical machine translation (SMT) systems developed by RWTH Aachen University for the translation task of the EMNLP 2011 Sixth Workshop on Statistical Machine Translation.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 25, "end_pos": 62, "type": "TASK", "confidence": 0.8190316061178843}, {"text": "translation task of the EMNLP 2011 Sixth Workshop on Statistical Machine Translation", "start_pos": 115, "end_pos": 199, "type": "TASK", "confidence": 0.8023646871248881}]}, {"text": "Both phrase-based and hierarchical SMT systems were trained for the constrained German-English and French-English tasks in all directions.", "labels": [], "entities": [{"text": "SMT", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.9545953869819641}]}, {"text": "Experiments were conducted to compare different training data sets, training methods and optimization criteria, as well as additional models on dependency structure and phrase reordering.", "labels": [], "entities": [{"text": "phrase reordering", "start_pos": 169, "end_pos": 186, "type": "TASK", "confidence": 0.7498565018177032}]}, {"text": "Further, we applied a system combination technique to create a consensus hypothesis from several different systems.", "labels": [], "entities": []}, {"text": "1 Overview We sketch the baseline architecture of RWTH's setups for the WMT 2011 shared translation task by providing an overview of our translation systems in Section 2.", "labels": [], "entities": [{"text": "WMT 2011 shared translation task", "start_pos": 72, "end_pos": 104, "type": "TASK", "confidence": 0.6935973107814789}]}, {"text": "In addition to the baseline features, we adopted several novel methods, which will be presented in Section 3.", "labels": [], "entities": []}, {"text": "Details on the respective setups and translation results for the French-English and German-English language pairs (in both translation directions) are given in Sections 4 and 5.", "labels": [], "entities": []}, {"text": "We finally conclude the paper in Section 6. 2 Translation Systems For the WMT 2011 evaluation we utilized RWTH's state-of-the-art phrase-based and hierarchical translation systems as well as our in-house system combination framework.", "labels": [], "entities": [{"text": "WMT 2011 evaluation", "start_pos": 74, "end_pos": 93, "type": "DATASET", "confidence": 0.7700693607330322}, {"text": "RWTH", "start_pos": 106, "end_pos": 110, "type": "DATASET", "confidence": 0.8672707080841064}]}, {"text": "GIZA++ (Och and Ney, 2003) was employed to train word alignments, language models have been created with the SRILM toolkit (Stolcke, 2002).", "labels": [], "entities": [{"text": "word alignments", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.755581796169281}]}, {"text": "2.1 Phrase-Based System We applied a phrase-based translation (PBT) system similar to the one described in (Zens and Ney, 2008).", "labels": [], "entities": [{"text": "phrase-based translation (PBT)", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.7261449754238128}]}, {"text": "Phrase pairs are extracted from a word-aligned bilingual corpus and their translation probability in both directions is estimated by relative frequencies.", "labels": [], "entities": []}, {"text": "The standard feature set moreover includes an n-gram language model, phrase-level single-word lexicons and word-, phrase-and distortion-penalties.", "labels": [], "entities": []}, {"text": "To lexi-calize reordering, a discriminative reordering model (Zens and Ney, 2006a) is used.", "labels": [], "entities": []}, {"text": "Parameters are optimized with the Downhill-Simplex algorithm (Nelder and Mead, 1965) on the word graph.", "labels": [], "entities": []}, {"text": "2.2 Hierarchical System For the hierarchical setups described in this paper, the open source Jane toolkit (Vilar et al., 2010) was employed.", "labels": [], "entities": []}, {"text": "Jane has been developed at RWTH and implements the hierarchical approach as introduced by Chiang (2007) with some state-of-the-art extensions.", "labels": [], "entities": [{"text": "Jane", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9105281829833984}, {"text": "RWTH", "start_pos": 27, "end_pos": 31, "type": "DATASET", "confidence": 0.9753963947296143}]}, {"text": "In hierarchical phrase-based translation, a weighted synchronous context-free grammar is induced from parallel text.", "labels": [], "entities": [{"text": "hierarchical phrase-based translation", "start_pos": 3, "end_pos": 40, "type": "TASK", "confidence": 0.601676325003306}]}, {"text": "In addition to contiguous lexical phrases, hierarchical phrases with up to two gaps are extracted.", "labels": [], "entities": []}, {"text": "The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007).", "labels": [], "entities": []}, {"text": "The standard models integrated into our Jane systems are: phrase translation probabilities and lexical translation probabilities on phrase level, each for both translation directions, length 405", "labels": [], "entities": [{"text": "phrase translation probabilities", "start_pos": 58, "end_pos": 90, "type": "TASK", "confidence": 0.8080734213193258}]}], "introductionContent": [], "datasetContent": [{"text": "The results for the French\u2192English task are given in.", "labels": [], "entities": []}, {"text": "RWTH's three submissions -one primary and two contrastive -are labeled accordingly in the table.", "labels": [], "entities": [{"text": "RWTH", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8582925200462341}]}, {"text": "The first contrastive submission is a phrasebased system with a standard feature set plus an additional triplet lexicon model (.", "labels": [], "entities": []}, {"text": "The triplet lexicon model was trained on in-domain news commentary data only.", "labels": [], "entities": []}, {"text": "The second contrastive submission is a hierarchical Jane system with three syntax-based extensions: A parse match model (, soft syntactic labels (, and the soft string-to-dependency extension as described in Section 3.3.", "labels": [], "entities": []}, {"text": "The primary submission combines the phrase-based contrastive system, a hierarchical system that is very similar to the Jane contrastive submission but with a slightly worse language model, and an additional PBT system that has been trained with forced alignment) on WMT 2010 data only.", "labels": [], "entities": [{"text": "WMT 2010 data", "start_pos": 266, "end_pos": 279, "type": "DATASET", "confidence": 0.9587008158365885}]}, {"text": "The results for the English\u2192French task are given in.", "labels": [], "entities": []}, {"text": "We likewise submitted two contrastive systems for this translation direction.", "labels": [], "entities": [{"text": "translation direction", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.96314537525177}]}, {"text": "The first contrastive submission is a phrase-based system, enhanced with a triplet lexicon model and a discriminative word lexicon model) -both trained on in-domain news commentary data only -as well as a sentence-level single-word lexicon model and a discriminative reordering model).", "labels": [], "entities": []}, {"text": "The second contrastive submission is a hierarchical Jane system with shallow rules (, a triplet lexicon model, a discriminative word lexicon, the parse match model, and a second phrase table extracted from in-domain data only.", "labels": [], "entities": []}, {"text": "Our primary submission is very similar to the latter Jane setup.", "labels": [], "entities": []}, {"text": "It does not comprise the extended lexicon models and the parse match extension, but instead includes lexical phrases from the full 30 Mio.", "labels": [], "entities": []}, {"text": "sentence corpus as described above.", "labels": [], "entities": []}, {"text": "For the German\u2192English task we conducted experiments comparing the standard phrase extraction with the phrase training technique described in Section 3.2.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 76, "end_pos": 93, "type": "TASK", "confidence": 0.7617434859275818}]}, {"text": "For the latter we applied log-linear phrasetable interpolation as proposed in.", "labels": [], "entities": []}, {"text": "Further experiments included the use of additional language model training data, reranking of nbest lists generated by the phrase-based system, and different optimization criteria.", "labels": [], "entities": []}, {"text": "We also carried out a system combination of several systems, including phrase-based systems on lemmatized German and on source data without compound splitting and two hierarchical systems optimized for different criteria.", "labels": [], "entities": []}, {"text": "The results are given in.", "labels": [], "entities": []}, {"text": "A considerable increase in translation quality can be achieved by application of German compound splitting.", "labels": [], "entities": [{"text": "translation", "start_pos": 27, "end_pos": 38, "type": "TASK", "confidence": 0.9713995456695557}, {"text": "German compound splitting", "start_pos": 81, "end_pos": 106, "type": "TASK", "confidence": 0.5764498213926951}]}, {"text": "The system that operates on German surface forms without compound splitting (SUR) clearly underperforms the baseline system with morphological preprocessing.", "labels": [], "entities": []}, {"text": "The system on lemmatized German (LEM) is at about the same level as the system on surface forms.", "labels": [], "entities": []}, {"text": "In comparison to the standard heuristic phrase extraction technique, performing phrase training (FA) gives an improvement in BLEU on newstest2008 and newstest2009, but a degradation in TER.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 40, "end_pos": 57, "type": "TASK", "confidence": 0.7102488428354263}, {"text": "FA", "start_pos": 97, "end_pos": 99, "type": "METRIC", "confidence": 0.9280956387519836}, {"text": "BLEU", "start_pos": 125, "end_pos": 129, "type": "METRIC", "confidence": 0.9996040463447571}, {"text": "TER", "start_pos": 185, "end_pos": 188, "type": "METRIC", "confidence": 0.9985836744308472}]}, {"text": "The addition of LDC Gigaword corpora (+GW) to the language model training data shows improvements in both BLEU and TER.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 106, "end_pos": 110, "type": "METRIC", "confidence": 0.998396098613739}, {"text": "TER", "start_pos": 115, "end_pos": 118, "type": "METRIC", "confidence": 0.9799844622612}]}, {"text": "Reranking was done on 1000-best lists generated by the the best available system (PBT (FA)+GW).", "labels": [], "entities": [{"text": "Reranking", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.8508529663085938}, {"text": "PBT (FA)+GW)", "start_pos": 82, "end_pos": 94, "type": "METRIC", "confidence": 0.7367351750532786}]}, {"text": "Following models were applied: n-gram posteriors (), sentence length model, a 6-gram LM and singleword lexicon models in both normal and inverse direction.", "labels": [], "entities": []}, {"text": "These models are combined in a log-linear fashion and the scaling factors are tuned in the same manner as the baseline system (using TER\u22124BLEU on newstest2009).", "labels": [], "entities": [{"text": "TER\u22124BLEU", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.9556097984313965}]}, {"text": "The table includes three identical Jane systems which are optimized for different criteria.", "labels": [], "entities": []}, {"text": "The one optimized for TER\u22124BLEU offers the best balance between BLEU and TER, but was not finished in time for submission.", "labels": [], "entities": [{"text": "TER", "start_pos": 22, "end_pos": 25, "type": "METRIC", "confidence": 0.8463954925537109}, {"text": "BLEU", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.9991661310195923}, {"text": "TER", "start_pos": 73, "end_pos": 76, "type": "METRIC", "confidence": 0.9939529299736023}]}, {"text": "As primary submission we chose the reranked PBT system, as secondary the system combination.", "labels": [], "entities": [{"text": "PBT", "start_pos": 44, "end_pos": 47, "type": "DATASET", "confidence": 0.8477961421012878}]}, {"text": "We likewise studied the effect of using BLEU only versus using TER\u22124BLEU as optimization criterion in the English\u2192German translation direction.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9988079071044922}, {"text": "TER\u22124BLEU", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.9493685563405355}]}, {"text": "Moreover, we tested the impact of the discriminative reordering model).", "labels": [], "entities": []}, {"text": "The results can be found in.", "labels": [], "entities": []}, {"text": "For the phrase-based system, optimizing towards TER\u22124BLEU leads to slightly better results both in BLEU and TER than optimizing towards BLEU.", "labels": [], "entities": [{"text": "TER", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9470953345298767}, {"text": "BLEU", "start_pos": 99, "end_pos": 103, "type": "METRIC", "confidence": 0.9980658888816833}, {"text": "TER", "start_pos": 108, "end_pos": 111, "type": "METRIC", "confidence": 0.9604049324989319}, {"text": "BLEU", "start_pos": 136, "end_pos": 140, "type": "METRIC", "confidence": 0.9786738753318787}]}, {"text": "Using the discriminative reordering model yields some improvements both on newstest2008 and newstest2010.", "labels": [], "entities": []}, {"text": "In the case of the hierarchical system, the effect of the optimization criterion is more pronounced than for the phrasebased system.", "labels": [], "entities": []}, {"text": "However, in this case it clearly leads to a tradeoff between BLEU and TER, as the choice of TER\u22124BLEU harms the translation results of test2010 with respect to BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9976752400398254}, {"text": "TER", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.9883588552474976}, {"text": "BLEU", "start_pos": 160, "end_pos": 164, "type": "METRIC", "confidence": 0.9795317649841309}]}], "tableCaptions": [{"text": " Table 1: Corpus statistics of the preprocessed high- quality training data (Europarl, news-commentary, and  selected parts of the 10 9 and UN corpora) for the  RWTH systems for the WMT 2011 French\u2192English and  English\u2192French translation tasks. Numerical quantities  are replaced by a single category symbol.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 77, "end_pos": 85, "type": "DATASET", "confidence": 0.9443051218986511}, {"text": "RWTH", "start_pos": 161, "end_pos": 165, "type": "DATASET", "confidence": 0.7728222012519836}, {"text": "WMT 2011 French\u2192English and  English\u2192French translation tasks", "start_pos": 182, "end_pos": 243, "type": "TASK", "confidence": 0.6776892055164684}]}, {"text": " Table 2: Corpus statistics of the preprocessed full training  data for the RWTH primary system for the WMT 2011  English\u2192French translation task. Numerical quantities  are replaced by a single category symbol.", "labels": [], "entities": [{"text": "RWTH primary system", "start_pos": 76, "end_pos": 95, "type": "DATASET", "confidence": 0.872988243897756}, {"text": "WMT 2011  English\u2192French translation task", "start_pos": 104, "end_pos": 145, "type": "TASK", "confidence": 0.6342918063913073}]}, {"text": " Table 3: RWTH systems for the WMT 2011 French\u2192English translation task (truecase). BLEU and TER results are  in percentage.", "labels": [], "entities": [{"text": "WMT 2011 French\u2192English translation task", "start_pos": 31, "end_pos": 71, "type": "TASK", "confidence": 0.682356229850224}, {"text": "BLEU", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.9991728663444519}, {"text": "TER", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.9951459765434265}]}, {"text": " Table 4: RWTH systems for the WMT 2011 English\u2192French translation task (truecase). BLEU and TER results are  in percentage.", "labels": [], "entities": [{"text": "WMT 2011 English\u2192French translation task", "start_pos": 31, "end_pos": 71, "type": "TASK", "confidence": 0.6712034600121635}, {"text": "BLEU", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.9991534948348999}, {"text": "TER", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.9951329827308655}]}, {"text": " Table 5: Corpus statistics of the preprocessed train- ing data for the WMT 2011 German\u2192English and  English\u2192German translation tasks. Numerical quantities  are replaced by a single category symbol.", "labels": [], "entities": [{"text": "WMT 2011 German\u2192English and  English\u2192German translation tasks", "start_pos": 72, "end_pos": 133, "type": "TASK", "confidence": 0.7855176492170854}]}, {"text": " Table 5. Word alignments were  generated with GIZA++ and symmetrized as for the  French-English setups.  The language models are 4-grams trained on the  bilingual data as well as the provided News crawl  corpus. For the English language model the 10 9  French-English and LDC Gigaword corpora were  used additionally. For the 10 9 French-English and  LDC Gigaword corpora RWTH applied the data se- lection technique described in Section 3.1. We ex- amined two different language models, one with  LDC data and one without.", "labels": [], "entities": [{"text": "Word alignments", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.7220254391431808}, {"text": "News crawl  corpus", "start_pos": 193, "end_pos": 211, "type": "DATASET", "confidence": 0.9506999651590983}, {"text": "RWTH", "start_pos": 373, "end_pos": 377, "type": "DATASET", "confidence": 0.6938847899436951}]}, {"text": " Table 6: RWTH systems for the WMT 2011 German\u2192English translation task (truecase). BLEU and TER results  are in percentage. FA denotes systems with phrase training, +GW the use of LDC data for the language model.  SUR and LEM denote the systems without compound splitting and on the lemmatized source, respectively. The three  hierarchical Jane systems are identical, but used different parameter optimization criterea.", "labels": [], "entities": [{"text": "WMT 2011 German\u2192English translation task", "start_pos": 31, "end_pos": 71, "type": "TASK", "confidence": 0.6565362811088562}, {"text": "BLEU", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.9993699193000793}, {"text": "TER", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.9950947761535645}, {"text": "FA", "start_pos": 125, "end_pos": 127, "type": "METRIC", "confidence": 0.9972033500671387}, {"text": "LEM", "start_pos": 223, "end_pos": 226, "type": "METRIC", "confidence": 0.9024670124053955}]}, {"text": " Table 7: RWTH systems for the WMT 2011 English\u2192German translation task (truecase). BLEU and TER results are  in percentage.", "labels": [], "entities": [{"text": "WMT 2011 English\u2192German translation task", "start_pos": 31, "end_pos": 71, "type": "TASK", "confidence": 0.6623822280338832}, {"text": "BLEU", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.9991340041160583}, {"text": "TER", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.9948418736457825}]}]}