{"title": [{"text": "Challenges in Designing Input Method Editors for Indian Languages: The Role of Word-Origin and Context", "labels": [], "entities": [{"text": "Designing Input Method Editors", "start_pos": 14, "end_pos": 44, "type": "TASK", "confidence": 0.5941343680024147}]}], "abstractContent": [{"text": "Back-transliteration based Input Method Editors are very popular for Indian Languages.", "labels": [], "entities": []}, {"text": "In this paper we evaluate two such Indic language systems to help understand the challenge of designing a back-transliteration based IME.", "labels": [], "entities": []}, {"text": "Through a detailed error-analysis of Hindi, Bang-la and Telugu data, we study the role of phonological features of Indian scripts that are reflected as variations and ambiguity in the transliteration.", "labels": [], "entities": []}, {"text": "The impact of word-origin on back-transliteration is discussed in the context of code-switching.", "labels": [], "entities": []}, {"text": "We also explore the role of word-level context to help overcome some of these challenges.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic Machine Transliteration finds practical use in various Natural Language Processing applications like Machine Translation, Mono lingual and Cross lingual information retrieval.", "labels": [], "entities": [{"text": "Automatic Machine Transliteration", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.6054880619049072}, {"text": "Machine Translation", "start_pos": 111, "end_pos": 130, "type": "TASK", "confidence": 0.8551516234874725}, {"text": "Cross lingual information retrieval", "start_pos": 149, "end_pos": 184, "type": "TASK", "confidence": 0.6762473732233047}]}, {"text": "Backward transliteration -the reverse process of converting a transliterated word into its native script, has been employed as a popular mechanism for multilingual text-input (.", "labels": [], "entities": []}, {"text": "This has given rise to many Input Method Editors (IME)s that allow the use of a normal QWER-TY keyboard to input text in non-Roman scripts like Japanese, Chinese, Arabic and several Indic languages Roman transliteration is widely used for inputting Indian languages in a number of domains.", "labels": [], "entities": []}, {"text": "A lack of standard keyboards, a large number of scripts, as well as familiarity with English and QWERTY keyboards has given rise to a number of transliteration schemes that are used for generating Indian language text in roman transliteration.", "labels": [], "entities": []}, {"text": "Some of these are an attempt to standardise the mapping between the Indian language script and the Roman alphabet, e.g., ITRANS but mostly the users define their own mappings that the readers can understand given their knowledge of the language.", "labels": [], "entities": [{"text": "ITRANS", "start_pos": 121, "end_pos": 127, "type": "DATASET", "confidence": 0.9308017492294312}]}, {"text": "A number of Indian language IMEs exist that employ either standardised mappings or try to account for user variations through rules, statistical methods or a combination of both.", "labels": [], "entities": []}, {"text": "These Machine Transliteration systems maybe used as Input Method Editors (IMEs) for desktop application, e.g., Baraha 1 or as web applications, e.g., Google Transliterate 2 and Quillpad . Microsoft Indic Language Input Tool (MSILIT) 4 supports both a desktop as well as a web-based version.", "labels": [], "entities": []}, {"text": "While all the above systems are popular and seem to serve their purpose adequately, there has not been any systematic evaluation to identify and address common problems that they may face, either specific to the languages concerned or due to the process of back-transliteration.", "labels": [], "entities": []}, {"text": "As point out back-transliteration is \"less forgiving\" than forward transliteration for there maybe many ways to transliterate a word in another script but there is only one way in which a transliterated word can be rendered back in its native form.", "labels": [], "entities": []}, {"text": "For example, \"London\" maybe transliterated as \"\u0932\u0902 \u0926\u0928\" or \"\u0932\u0923\u094d\u0921\u0928\" in Hindi but any back-transliteration can generate only one correct case, that is, \"London\".", "labels": [], "entities": []}, {"text": "One reason for the absence of any meaningful evaluation is the lack of a standard dataset.", "labels": [], "entities": []}, {"text": "The NEWS workshop () made available training and test data in three Indian Languages -Hindi, Tamil and Kannada, but as this was constrained to named entities, it is of limited use for evaluating a general purpose transliteration system.", "labels": [], "entities": [{"text": "NEWS workshop", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9298844337463379}]}, {"text": "describes the creation of a dataset for three Indian languages, viz., Hindi, Bangla and Telugu transliterated into Roman alphabet.", "labels": [], "entities": []}, {"text": "The availability of this dataset has made it possible to evaluate transliteration based Input mechanisms on common grounds and identify areas for improvement.", "labels": [], "entities": []}, {"text": "In this paper, we use the dataset described in () to evaluate two backtransliteration based Indian language IMEs to identify some of the common challenges faced by such systems.", "labels": [], "entities": []}, {"text": "We discuss in some details the errors caused due to a) phonological variation or the variability in transliteration caused by the phonological properties of the source language, and b) word-origin -the transliteration of words or origin other than the source language.", "labels": [], "entities": []}, {"text": "We also discuss how word-level context can help resolve some of these issues.", "labels": [], "entities": []}, {"text": "While the examples presented here are mainly from Hindi, many of the experiments were also repeated for Telugu and Bangla, and can be generalized across these languages.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: The next section presents evaluation data, methodology and a top-level error-analysis.", "labels": [], "entities": []}, {"text": "In Section 3, we discuss the various phonological variations that cause ambiguous transliterations.", "labels": [], "entities": []}, {"text": "In Sec 4, the role of word origin on backtransliteration is discussed.", "labels": [], "entities": []}, {"text": "Section 5 discusses the impact of word-level context on backtransliteration.", "labels": [], "entities": []}, {"text": "Further issues and possible future directions are discussed in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Two of the publicly available systems were chosen for evaluation on the same test data.", "labels": [], "entities": []}, {"text": "Both the systems, as is usual for most Indic language IMEs, take continuous Roman input and convert it automatically into the relevant Indic language string after pause or punctuation.", "labels": [], "entities": []}, {"text": "The user can select from a list of other possible options by a right-click on the relevant word.", "labels": [], "entities": []}, {"text": "The aim of this evaluation was neither competitive nor to discover which system was better but to uncover common issues that plague backtransliteration based IMEs.", "labels": [], "entities": []}, {"text": "The assumption was that an in-depth analysis of the common errors produced would help in a better understanding and ultimately in better systems.", "labels": [], "entities": []}, {"text": "Further, the systems remain a black-box for this study as we do not have access to the internal models and algorithms being used and are therefore labeled as System A and B to mask their identity.", "labels": [], "entities": []}, {"text": "The dataset described above was used for evaluating the two commercial IME systems.", "labels": [], "entities": [{"text": "IME", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.9465523362159729}]}, {"text": "Roman transliterations for all the words for each language were input to obtain the Top-1 result from both the engine.", "labels": [], "entities": []}, {"text": "The output from the systems was analyzed quantitatively as well as manually to identify common patterns of errors.", "labels": [], "entities": []}, {"text": "The accuracies of both the systems were found to be comparable across the number of unique words in the test set (Type), as well as the total number of words counting multiple occurrences of the same type (Token).", "labels": [], "entities": []}, {"text": "Type level accuracies for the systems were around 55%, whereas the Token level accuracies lay between 75-78%.", "labels": [], "entities": [{"text": "Type level accuracies", "start_pos": 0, "end_pos": 21, "type": "METRIC", "confidence": 0.6266558369000753}]}, {"text": "Figure1 shows the cumulative Top-N token accuracy percentages for Hindi.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9086538553237915}]}, {"text": "It shows the percentage of words which the systems got right within Top-N (N varying from 1 to 5).", "labels": [], "entities": []}, {"text": "As mentioned before, the test set had three kinds of data: words collected through speech transcription (speech), by chatting with the users (chat) and through the users writing a few lines on different topics (Topic writing).", "labels": [], "entities": []}, {"text": "It maybe noted that the Scenario data performed better over Chat data and Speech data.", "labels": [], "entities": []}, {"text": "The performance was relatively poorer with Speech and this might be attributed to the noise in speech which made the users enter the wrong words.", "labels": [], "entities": []}, {"text": "Bangla and Telugu showed similar trends.", "labels": [], "entities": [{"text": "Bangla", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9676082134246826}]}], "tableCaptions": [{"text": " Table 1: The classification of errors for Hindi(H),  Bangla (B) and Telugu (T)", "labels": [], "entities": []}, {"text": " Table 2: Spelling variations for retroflex voiceless  stop series in Hindi and Telugu", "labels": [], "entities": []}, {"text": " Table 3: Accuracy improvement using web-search  based LM", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9983800649642944}]}]}