{"title": [{"text": "Identification and Treatment of Multiword Expressions applied to Information Retrieval", "labels": [], "entities": [{"text": "Identification", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9651018977165222}, {"text": "Treatment of Multiword Expressions", "start_pos": 19, "end_pos": 53, "type": "TASK", "confidence": 0.6278447136282921}, {"text": "Information Retrieval", "start_pos": 65, "end_pos": 86, "type": "TASK", "confidence": 0.7986204326152802}]}], "abstractContent": [{"text": "The extensive use of Multiword Expressions (MWE) in natural language texts prompts more detailed studies that aim fora more adequate treatment of these expressions.", "labels": [], "entities": [{"text": "Multiword Expressions (MWE)", "start_pos": 21, "end_pos": 48, "type": "TASK", "confidence": 0.6529080629348755}]}, {"text": "A MWE typically expresses concepts and ideas that usually cannot be expressed by a single word.", "labels": [], "entities": []}, {"text": "Intuitively, with the appropriate treatment of MWEs, the results of an Information Retrieval (IR) system could be improved.", "labels": [], "entities": [{"text": "Information Retrieval (IR)", "start_pos": 71, "end_pos": 97, "type": "TASK", "confidence": 0.7761977314949036}]}, {"text": "The aim of this paper is to apply techniques for the automatic extraction of MWEs from corpora to index them as a single unit.", "labels": [], "entities": [{"text": "automatic extraction of MWEs from corpora", "start_pos": 53, "end_pos": 94, "type": "TASK", "confidence": 0.792167047659556}]}, {"text": "Experimental results show improvements on the retrieval of relevant documents when identifying MWEs and treating them as a single indexing unit.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the motivations of this work is to investigate if the identification and appropriate treatment of Multiword Expressions (MWEs) in an application contributes to improve results and ultimately lead to more precise man-machine interaction.", "labels": [], "entities": []}, {"text": "The term \"multiword expression\" has been used to describe a large set of distinct constructions, for instance support verbs, noun compounds, institutionalized phrases and soon.", "labels": [], "entities": []}, {"text": "defines MWEs as a sequence of words that acts as a single unit at some level of linguistic analysis.", "labels": [], "entities": []}, {"text": "The nature of MWEs can be quite heterogeneous and each of the different classes has specific characteristics, posing a challenge to the implementation of mechanisms that provide unified treatment for them.", "labels": [], "entities": []}, {"text": "For instance, even if a standard system capable of identifying boundaries between words, i.e. a tokenizer, may nevertheless be incapable of recognizing a sequence of words as an MWEs and treating them as a single unit if necessary (e.g. to kick the bucket meaning to die).", "labels": [], "entities": []}, {"text": "For an NLP application to be effective, it requires mechanisms that are able to identify MWEs, handle them and make use of them in a meaningful way (.", "labels": [], "entities": []}, {"text": "It is estimated that the number of MWEs in the lexicon of a native speaker of a language has the same order of magnitude as the number of single words.", "labels": [], "entities": []}, {"text": "However, these ratios are probably underestimated when considering domain-specific language, in which the specialized vocabulary and terminology are composed mostly by MWEs.", "labels": [], "entities": []}, {"text": "In this paper, we perform an application-oriented evaluation of the inclusion of MWE treatment into an Information Retrieval (IR) system.", "labels": [], "entities": [{"text": "MWE treatment", "start_pos": 81, "end_pos": 94, "type": "TASK", "confidence": 0.8891136348247528}, {"text": "Information Retrieval (IR)", "start_pos": 103, "end_pos": 129, "type": "TASK", "confidence": 0.7798845171928406}]}, {"text": "IR systems aim to provide users with quick access to data they are interested).", "labels": [], "entities": [{"text": "IR", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9140315651893616}]}, {"text": "Although language processing is not vital to modern IR systems, it maybe convenient and in this scenario, NLP techniques may contribute in the selection of MWEs for indexing as single units in the IR system.", "labels": [], "entities": [{"text": "IR", "start_pos": 52, "end_pos": 54, "type": "TASK", "confidence": 0.960742712020874}]}, {"text": "The selection of appropriate indexing terms is a key factor for the quality of IR systems.", "labels": [], "entities": [{"text": "IR", "start_pos": 79, "end_pos": 81, "type": "TASK", "confidence": 0.9934946894645691}]}, {"text": "In an ideal system, the index terms should correspond to the concepts found in the documents.", "labels": [], "entities": []}, {"text": "If indexing is performed only with the atomic terms, there maybe a loss of semantic content of the documents.", "labels": [], "entities": []}, {"text": "For example, if the query was pop star meaning celebrity, and the terms were indexed individually, the relevant documents may not be retrieved and the system would return instead irrelevant documents about celestial bodies or carbonated drinks.", "labels": [], "entities": []}, {"text": "In order to investigate the effects of indexing of MWEs for IR, the results of queries are analyzed using IR quality metrics.", "labels": [], "entities": [{"text": "IR", "start_pos": 60, "end_pos": 62, "type": "TASK", "confidence": 0.9517993330955505}]}, {"text": "This paper is structured as follows: in section 2 we discuss briefly MWEs and some of the challenges they represent.", "labels": [], "entities": [{"text": "MWEs", "start_pos": 69, "end_pos": 73, "type": "TASK", "confidence": 0.9243525862693787}]}, {"text": "This is followed in section 3 by a discussion of the materials and methods employed in this paper, and in section 4 of the evaluation performed.", "labels": [], "entities": []}, {"text": "We finish with some conclusions and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the results of the IR system, we need to use metrics that estimate how well a user's query was satisfied by the system.", "labels": [], "entities": [{"text": "IR", "start_pos": 31, "end_pos": 33, "type": "TASK", "confidence": 0.9767528176307678}]}, {"text": "IR evaluation is based on recall and precision.", "labels": [], "entities": [{"text": "IR evaluation", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9735498130321503}, {"text": "recall", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.9996330738067627}, {"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9980546236038208}]}, {"text": "Precision (Eq. 1) is the portion of the retrieved documents which is actually relevant to the query.", "labels": [], "entities": [{"text": "Precision (Eq. 1)", "start_pos": 0, "end_pos": 17, "type": "METRIC", "confidence": 0.9179765701293945}]}, {"text": "Recall (Eq. 2) is the fraction of the relevant documents which is retrieved by the IRS.", "labels": [], "entities": [{"text": "Recall (Eq. 2)", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.9494484782218933}, {"text": "IRS", "start_pos": 83, "end_pos": 86, "type": "DATASET", "confidence": 0.902881383895874}]}, {"text": "P recision(P ) = #Relevant #Retrieved #Retrieved (1) Precision and Recall are set-based measures, therefore, they do not take into consideration the ordering in which the relevant items were retrieved.", "labels": [], "entities": [{"text": "Relevant", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9817023277282715}, {"text": "Recall", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.9222665429115295}]}, {"text": "In order to evaluate ranked retrieval results the most widely used measurement is the average precision (AvP ).", "labels": [], "entities": [{"text": "average precision (AvP )", "start_pos": 86, "end_pos": 110, "type": "METRIC", "confidence": 0.9088611006736755}]}, {"text": "AvP emphasizes returning more relevant documents earlier in the ranking.", "labels": [], "entities": [{"text": "AvP", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6296877264976501}]}, {"text": "For a set of queries, we calculate the Mean Average Precision (MAP) according to. where |Q| is the number of queries, R jk is the set of ranked retrieval results from the top result until document d k , and m j is the number of relevant documents for query j.", "labels": [], "entities": [{"text": "Mean Average Precision (MAP)", "start_pos": 39, "end_pos": 67, "type": "METRIC", "confidence": 0.9718245267868042}]}, {"text": "The experiments performed evaluate the insertion of MWEs in results obtained in the IR system.", "labels": [], "entities": []}, {"text": "The analysis is divided into two evaluations: (A) total set of query topics, where an overview is given of the MWE insertion effects and (B) topics modified by MWEs, where we evaluate only the query topics that contain MWEs.", "labels": [], "entities": [{"text": "MWE insertion", "start_pos": 111, "end_pos": 124, "type": "TASK", "confidence": 0.849633663892746}]}, {"text": "This evaluation investigates the effects of inserting MWEs in documents and queries.", "labels": [], "entities": [{"text": "inserting MWEs in documents and queries", "start_pos": 44, "end_pos": 83, "type": "TASK", "confidence": 0.7665959099928538}]}, {"text": "After each type of index was generated, MWEs were also included in the query topics, in accordance to the dictionaries used for each index (for Baseline BL, the query topics had no modifications).", "labels": [], "entities": [{"text": "Baseline BL", "start_pos": 144, "end_pos": 155, "type": "DATASET", "confidence": 0.712132066488266}]}, {"text": "With eight corpus variations, we obtained individual results for each one of them.", "labels": [], "entities": []}, {"text": "The results presented in were summarized by the absolute number of relevant documents retrieved and the MAP for the entire set of query topics.", "labels": [], "entities": [{"text": "MAP", "start_pos": 104, "end_pos": 107, "type": "METRIC", "confidence": 0.9971930384635925}]}, {"text": "In total, 6,379 relevant documents are returned for the 310 query topics.", "labels": [], "entities": []}, {"text": "It is possible to see a small improvement in the results for the indices M1 and M2 in relation to the baseline (BL).", "labels": [], "entities": [{"text": "baseline (BL)", "start_pos": 102, "end_pos": 115, "type": "METRIC", "confidence": 0.6731305122375488}]}, {"text": "This happens because the choice of candidate MWEs was made from the contents of the document topics and not, as with other indices, from the whole corpus.", "labels": [], "entities": []}, {"text": "Considering the indices built with MWEs extracted from the corpus, the best result is index GS.In second place, comes the CN index, with a subtle improvement over the Baseline.", "labels": [], "entities": []}, {"text": "BL surprisingly got a better result than the Best and Worst CN.", "labels": [], "entities": [{"text": "BL", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.7187942266464233}]}, {"text": "The loss in retrieval quality as a result from MWE identification for BCN was not expected.", "labels": [], "entities": [{"text": "MWE identification", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.9470199644565582}, {"text": "BCN", "start_pos": 70, "end_pos": 73, "type": "DATASET", "confidence": 0.6971221566200256}]}, {"text": "When comparing the gain or loss in MAP of individual query topics, we can see how the index BCN compares to the Baseline: BCN had better MAP in 149 and worse MAP in 108 cases.", "labels": [], "entities": [{"text": "MAP", "start_pos": 137, "end_pos": 140, "type": "METRIC", "confidence": 0.8890751600265503}]}, {"text": "However, the average loss is higher than the average gain, this explains why BL obtains a better result overall.", "labels": [], "entities": [{"text": "BL", "start_pos": 77, "end_pos": 79, "type": "METRIC", "confidence": 0.9899471402168274}]}, {"text": "In order do decide if one run is indeed superior to another, instead of using the absolute MAP value, we chose to calculate a margin of 5%.", "labels": [], "entities": [{"text": "MAP", "start_pos": 91, "end_pos": 94, "type": "METRIC", "confidence": 0.9380524158477783}]}, {"text": "The intuition behind this is that in IR, a difference of less than 5% between the results being compared is not considered significant).", "labels": [], "entities": [{"text": "IR", "start_pos": 37, "end_pos": 39, "type": "TASK", "confidence": 0.9875487089157104}]}, {"text": "To be considered as gain the difference between the values resulting from two different indices for the same query topic should be greater than 5%.", "labels": [], "entities": []}, {"text": "Differences of less than 5% are considered ties.", "labels": [], "entities": []}, {"text": "This way, MAP values of 0.1111 and 0.1122 are considered ties.", "labels": [], "entities": [{"text": "MAP", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9326997399330139}]}, {"text": "Given this margin, we can see in that the indices BCN and WCN are better compared to the baseline.", "labels": [], "entities": [{"text": "BCN", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.6960887908935547}]}, {"text": "In the case of BCN, the gain is almost 20% of cases and the WCN, the difference between gain and loss is less than 2%.", "labels": [], "entities": [{"text": "BCN", "start_pos": 15, "end_pos": 18, "type": "DATASET", "confidence": 0.6069309115409851}, {"text": "WCN", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.5542171597480774}]}, {"text": "Finally, this first experiment guided us toward a deeper evaluation of the query topics that have MWEs, because there is a possibility that the MWE insertions in documents can decrease the accuracy of the system on topics that have no MWE.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 189, "end_pos": 197, "type": "METRIC", "confidence": 0.9985197186470032}]}, {"text": "This evaluation studies in detail the effects on the document retrieval in response to topics in which there were MWEs.", "labels": [], "entities": []}, {"text": "For this purpose, we used the same indices used before and we performed an individual evaluation of the topics, to obtain a better understanding on where the identification of MWEs improves or degrades the results.", "labels": [], "entities": [{"text": "identification of MWEs", "start_pos": 158, "end_pos": 180, "type": "TASK", "confidence": 0.637504905462265}]}, {"text": "As each dictionary was created using a different methodology, the number of expressions contained in each dictionary is also different.", "labels": [], "entities": []}, {"text": "Thus, for each method, the number of query topics considered as having MWEs varies according to the dictionary used.", "labels": [], "entities": []}, {"text": "shows the number of query topics containing MWEs for each dictionary used, and as a consequence, the percentage of modified query topics over the complete set of 310 topics.", "labels": [], "entities": []}, {"text": "First, it is interesting to observe the values of MAP for all topics that have been altered by the identification of MWEs.", "labels": [], "entities": [{"text": "MAP", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.9586035013198853}]}, {"text": "These values are shown in.", "labels": [], "entities": []}, {"text": "As shown in   does not affect the accuracy, which only improves subtly.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9997451901435852}]}, {"text": "But the computational cost for the insertion of these MWEs in the corpus was reduced by half.", "labels": [], "entities": []}, {"text": "In terms of gain percentage, indices M1 and M2 were superior only to WCN, but they are close to other results, including the DT index, which obtained an intermediate result between manual dictionaries and CN.", "labels": [], "entities": []}, {"text": "Analyzing some topics in depth, like topic 141, the best the result among all the indices was obtained by the CN.", "labels": [], "entities": [{"text": "CN", "start_pos": 110, "end_pos": 112, "type": "DATASET", "confidence": 0.937578558921814}]}, {"text": "<TERM ID=\"GH950102-000000-126\" LEMA=\"underworld\" POS=\"NN\"> <WF>underworld</WF> <SYNSET SCORE=\"0.5\" CODE=\"06120171-n\"/> <SYNSET SCORE=\"0.5\" CODE=\"06327598-n\"/> </TERM> Original Topic: -What was the role of the Hubble telescope in proving the existence of black holes?", "labels": [], "entities": [{"text": "TERM ID", "start_pos": 1, "end_pos": 8, "type": "METRIC", "confidence": 0.9248540103435516}, {"text": "LEMA", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.8545806407928467}]}, {"text": "Modified Topic: -what be the role of the hubble telescope in prove the existence of black hole ? black_hole <num>141</num> <title> letterbomb for kiesbauer find information on the explosion of a letterbomb in the studio of the tv channel pro7 presenter arabella kiesbauer . letter_bomb letter_bomb tv_channel </title> shows the top ten scoring documents retrieved for query topic 141 in the baseline.", "labels": [], "entities": []}, {"text": "The relevant document (in bold) is the fourth position in the Baseline.", "labels": [], "entities": [{"text": "Baseline", "start_pos": 62, "end_pos": 70, "type": "DATASET", "confidence": 0.9561440348625183}]}, {"text": "After inserting the expression letterbomb twice (because it occurs twice in the original topic), and tv channel that were in dictionary D1 used by the CN index, the relevant document is scored higher and as a consequence is returned in the first position of the ranking) . The MAP of this topic has increased 75 percentage points, from 0.2500 in Baseline to 1.000 in the CN index.", "labels": [], "entities": [{"text": "CN index", "start_pos": 151, "end_pos": 159, "type": "DATASET", "confidence": 0.8994907438755035}, {"text": "MAP", "start_pos": 277, "end_pos": 280, "type": "METRIC", "confidence": 0.8218181729316711}, {"text": "CN index", "start_pos": 371, "end_pos": 379, "type": "DATASET", "confidence": 0.9437976181507111}]}, {"text": "We see also that the document that was in first position in the Baseline ranking, has its score decreased and was ranked in fourth position in the ranking given by the CN.", "labels": [], "entities": [{"text": "Baseline ranking", "start_pos": 64, "end_pos": 80, "type": "DATASET", "confidence": 0.8795019388198853}, {"text": "CN", "start_pos": 168, "end_pos": 170, "type": "DATASET", "confidence": 0.9509689211845398}]}, {"text": "This document contained information on a \"small bomb located outside the of the Russian embassy\" and has is not relevant to topic 141, being properly relegated to a lower position.", "labels": [], "entities": []}, {"text": "An interesting fact about this topic is that only the MWE letterbomb influences the result.", "labels": [], "entities": [{"text": "MWE letterbomb", "start_pos": 54, "end_pos": 68, "type": "DATASET", "confidence": 0.5645800232887268}]}, {"text": "This was verified as in the index BCN, whose dictionary does not have this MWE, the topic was changed only because of the MWE tv channel and there was no gain or loss for the result.", "labels": [], "entities": [{"text": "BCN", "start_pos": 34, "end_pos": 37, "type": "DATASET", "confidence": 0.9373955130577087}, {"text": "MWE tv channel", "start_pos": 122, "end_pos": 136, "type": "DATASET", "confidence": 0.8724392652511597}]}, {"text": "The second highest gain was of M1 index, in topic 173.", "labels": [], "entities": [{"text": "M1 index", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9704228937625885}]}, {"text": "The gain was of 28 percentage points.", "labels": [], "entities": [{"text": "gain", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9488900899887085}]}, {"text": "On the other hand, we found a downside in M1 and M2 indices, although they improved results on average, they have reached very high values of loss in some topics.", "labels": [], "entities": [{"text": "loss", "start_pos": 142, "end_pos": 146, "type": "METRIC", "confidence": 0.9472285509109497}]}, {"text": "In sum, the MWEs insertion seems to improve retrieval bringing more relevant documents, due to a more precise indexing of specific terms.", "labels": [], "entities": [{"text": "MWEs insertion", "start_pos": 12, "end_pos": 26, "type": "TASK", "confidence": 0.9217638075351715}]}, {"text": "However, the use of these expressions also brought a negative impact for some cases, because some topics require a semantic analysis to return relevant documents (as for example topic 130, which requires relevant documents to mention the causes of the death of Kurt Cobain -documents which mention his death without mentioning the causes were not considered relevant).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results -Evaluation A.", "labels": [], "entities": []}, {"text": " Table 3: BCN x Baseline", "labels": [], "entities": [{"text": "BCN", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.43944239616394043}]}, {"text": " Table 4: WCN x Baseline", "labels": [], "entities": []}, {"text": " Table 5: Topics with MWEs", "labels": [], "entities": [{"text": "MWEs", "start_pos": 22, "end_pos": 26, "type": "TASK", "confidence": 0.6664208173751831}]}, {"text": " Table 6: Results -Evaluation B", "labels": [], "entities": []}, {"text": " Table 7: Ranking for Topic #141 -Baseline", "labels": [], "entities": []}, {"text": " Table 8: Ranking for Topic #141 -CN", "labels": [], "entities": [{"text": "CN", "start_pos": 34, "end_pos": 36, "type": "DATASET", "confidence": 0.41472718119621277}]}]}