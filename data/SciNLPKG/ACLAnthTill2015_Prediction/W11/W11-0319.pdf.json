{"title": [{"text": "Automatically Building Training Examples for Entity Extraction", "labels": [], "entities": [{"text": "Entity Extraction", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.7754076719284058}]}], "abstractContent": [{"text": "In this paper we present methods for automatically acquiring training examples for the task of entity extraction.", "labels": [], "entities": [{"text": "entity extraction", "start_pos": 95, "end_pos": 112, "type": "TASK", "confidence": 0.7785733640193939}]}, {"text": "Experimental evidence show that: (1) our methods compete with a current heavily supervised state-of-the-art system , within 0.04 absolute mean average precision ; and (2) our model significantly out-performs other supervised and unsupervised baselines by between 0.15 and 0.30 in absolute mean average precision.", "labels": [], "entities": [{"text": "absolute mean average precision", "start_pos": 129, "end_pos": 160, "type": "METRIC", "confidence": 0.721858985722065}, {"text": "absolute mean average precision", "start_pos": 280, "end_pos": 311, "type": "METRIC", "confidence": 0.7143881693482399}]}], "introductionContent": [{"text": "Entity extraction is a fundamental task in NLP and related applications.", "labels": [], "entities": [{"text": "Entity extraction", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9016135334968567}]}, {"text": "It is broadly defined as the task of extracting entities of a given semantic class from texts (e.g., lists of actors, musicians, cities).", "labels": [], "entities": []}, {"text": "Search engines such as Bing, Yahoo, and Google collect large sets of entities to better interpret queries), to improve query suggestions and to understand query intents ().", "labels": [], "entities": []}, {"text": "In response, automated techniques for entity extraction have been proposed.", "labels": [], "entities": [{"text": "entity extraction", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.8553120195865631}]}, {"text": "There is mounting evidence that combining knowledge sources and information extraction systems yield significant improvements over applying each in isolation).", "labels": [], "entities": [{"text": "information extraction", "start_pos": 64, "end_pos": 86, "type": "TASK", "confidence": 0.7095229476690292}]}, {"text": "This intuition is explored by the Ensemble Semantics (ES) framework proposed by, which outperforms previous state-of-the-art systems.", "labels": [], "entities": []}, {"text": "A severe limitation of this type of extraction system is its reliance on editorial judgments for building large training sets for each semantic class to be extracted.", "labels": [], "entities": []}, {"text": "This is particularly troublesome for applications such as web search that require large numbers of semantic classes in order to have a sufficient coverage of facts and objects).", "labels": [], "entities": []}, {"text": "Hand-crafting training sets across international markets is often infeasible.", "labels": [], "entities": []}, {"text": "In an exploratory study we estimated that a pool of editors would need roughly 300 working days to complete a basic set of 100 English classes using the ES framework.", "labels": [], "entities": [{"text": "ES framework", "start_pos": 153, "end_pos": 165, "type": "DATASET", "confidence": 0.8643277585506439}]}, {"text": "Critically needed are methods for automatically building training sets that preserve the extraction quality.", "labels": [], "entities": []}, {"text": "In this paper, we propose simple and intuitively appealing solutions to automatically build training sets.", "labels": [], "entities": []}, {"text": "Positive and negative training sets fora target semantic class are acquired by leveraging: i) 'trusted' sources such as structured databases (e.g., IMDB or Wikipedia for acquiring a list of Actors); ii) automatically constructed semantic lexicons; and iii) instances of semantic classes other than the target class.", "labels": [], "entities": []}, {"text": "Our models focus on extracting training sets that are large, balanced, and representative of the unlabeled data.", "labels": [], "entities": []}, {"text": "These models can be used in any extraction setting, where 'trusted' sources of knowledge are available: Today, the popularity of structured and semi-structured sources such as Wikipedia and internet databases, makes this approach widely applicable.", "labels": [], "entities": []}, {"text": "As an example, in this paper we show that our methods can be successfully adapted and used in the ES framework.", "labels": [], "entities": [{"text": "ES framework", "start_pos": 98, "end_pos": 110, "type": "DATASET", "confidence": 0.754778116941452}]}, {"text": "This gives us the possibility to test the methods on a large-scale entity extraction task.", "labels": [], "entities": [{"text": "entity extraction task", "start_pos": 67, "end_pos": 89, "type": "TASK", "confidence": 0.7874880731105804}]}, {"text": "We replace the manually built training data in the the ES model with the training data built by our algorithms.", "labels": [], "entities": []}, {"text": "We show by means of a large empirical study that our algorithms perform nearly as good as the fully supervised ES model, within 4% in absolute mean average precision.", "labels": [], "entities": [{"text": "absolute mean average precision", "start_pos": 134, "end_pos": 165, "type": "METRIC", "confidence": 0.69878089427948}]}, {"text": "Further, we compare the performance of our method against both Pas\u00b8ca and, showing 17% and 15% improvements in absolute mean average precision, respectively.", "labels": [], "entities": [{"text": "absolute mean average", "start_pos": 111, "end_pos": 132, "type": "METRIC", "confidence": 0.8568358421325684}, {"text": "precision", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.6130521297454834}]}, {"text": "The main contributions of this paper are: \u2022 We propose several general methods for automatically acquiring labeled training data; we show that they can be used in a large-scale extraction framework, namely ES; and \u2022 We show empirical evidence on a large-scale entity extraction task that our system using automatically labeled training data performs nearly as well as the fully-supervised ES model, and that it significantly outperforms state-of-the-art systems.", "labels": [], "entities": [{"text": "entity extraction task", "start_pos": 260, "end_pos": 282, "type": "TASK", "confidence": 0.8307159940401713}]}], "datasetContent": [{"text": "In this section, we report experiments comparing the ranking performance of our different methods for acquiring training data presented in Section 3, to three different baselines and a fully supervised upper-bound.", "labels": [], "entities": []}, {"text": "We evaluate over three semantic classes: Actors (movie, tv and stage actors); Athletes (professional and amateur); Musicians (singers, musicians, composers, bands, and orchestras), so to compare with (.", "labels": [], "entities": []}, {"text": "Ranking performance is tested over the test set described in the above paper, composed of 500 instances, randomly selected from the instances extracted by KE pat and KE dis for each of the classes 2 . We experiment with various instantiations of the ES system, each trained on a different training set obtained from our methods.", "labels": [], "entities": [{"text": "KE", "start_pos": 155, "end_pos": 157, "type": "METRIC", "confidence": 0.8715971112251282}]}, {"text": "The different system instantiations (i.e., different training sets) are reported in.", "labels": [], "entities": []}, {"text": "Each training set consists of 500 positive examples, and 500 negative examples.", "labels": [], "entities": []}, {"text": "As an upper bound, we use the ES system, where the training consists of 500 manually annotated instances (P man and N man ), randomly selected from those extracted by the KEs.", "labels": [], "entities": [{"text": "ES", "start_pos": 30, "end_pos": 32, "type": "METRIC", "confidence": 0.6260034441947937}]}, {"text": "This allows us to directly check if our automatically acquired training sets can compete to the human upper-bound.", "labels": [], "entities": []}, {"text": "We also compare to the following baselines.", "labels": [], "entities": []}, {"text": "Baseline 1: An unsupervised rule-based ES system, assigning the lowest score to instances extracted by only one KE, when the KE is untrusted; and assigning the highest score to any other instance.", "labels": [], "entities": []}, {"text": "Baseline 2: An unsupervised rule-based ES system, adopting as KEs the two untrusted extractors KE pat and KE dis , and a rule-based Ranker that assigns scores to instances according to the sum of their normalized confidence scores.", "labels": [], "entities": []}, {"text": "Baseline 3: An instantiation of our ES system, trained on P man and N man . The only difference with the upper-bound is that it uses only two features, namely the confidence score returned by KE dis and KE pat . This instantiation implements the system presented in ().", "labels": [], "entities": [{"text": "confidence score returned", "start_pos": 163, "end_pos": 188, "type": "METRIC", "confidence": 0.9297000567118326}]}, {"text": "For evaluation, we use average precision (AP), a standard information retrieval measure for evaluating ranking algorithms: where L is a ranked list produced by a system, P (i) is the precision of Lat rank i, and corr(i) is 1 if the instance at rank i is correct, and 0 otherwise.", "labels": [], "entities": [{"text": "average precision (AP)", "start_pos": 23, "end_pos": 45, "type": "METRIC", "confidence": 0.9387178421020508}, {"text": "precision", "start_pos": 183, "end_pos": 192, "type": "METRIC", "confidence": 0.9951028823852539}]}, {"text": "In order to accurately compute statistical significance, we divide the test set in 10-folds, and compute the AP mean and variance obtained over the 10-folds.", "labels": [], "entities": [{"text": "AP mean and variance", "start_pos": 109, "end_pos": 129, "type": "METRIC", "confidence": 0.9357880502939224}]}, {"text": "For each configuration, we perform the random sampling of the training set five times, rebuilding the model each time, to estimate the variance when varying the training sampling.: Average precision (AP) results of systems using different training sets, compared to two usupervised Baselines, a supervised Baseline, and a fully supervised upper-bound system.", "labels": [], "entities": [{"text": "Average precision (AP)", "start_pos": 181, "end_pos": 203, "type": "METRIC", "confidence": 0.8777329206466675}]}, {"text": "\u00a7 indicates statistical significance at the 0.95 level wrt all Baselines.", "labels": [], "entities": [{"text": "statistical significance", "start_pos": 12, "end_pos": 36, "type": "METRIC", "confidence": 0.9405418932437897}]}, {"text": "\u2021 indicates statistical significance at the 0.95 level wrt Baseline1 and Baseline 2.", "labels": [], "entities": [{"text": "statistical significance", "start_pos": 12, "end_pos": 36, "type": "METRIC", "confidence": 0.9451194107532501}]}, {"text": "\u2020 indicates statistical significance at the 0.95 level wrt classes; and the mean average precision (MAP) computed across the classes.", "labels": [], "entities": [{"text": "statistical significance", "start_pos": 12, "end_pos": 36, "type": "METRIC", "confidence": 0.8829646706581116}, {"text": "mean average precision (MAP)", "start_pos": 76, "end_pos": 104, "type": "METRIC", "confidence": 0.9457493225733439}]}, {"text": "We report results using P cls as positive training, and varying the negative training composition . Systems S1-S3 use a single method to build the negatives.", "labels": [], "entities": []}, {"text": "Systems S4-S6 combine two methods (250 examples from one method, 250 from the other), and S7 combines all three methods.", "labels": [], "entities": []}, {"text": "reports additional basic results when varying the positive training set composition, and fixing the best performing negative set (namely N cls ).", "labels": [], "entities": []}, {"text": "shows that all systems outperform the baselines in MAP, with 0.95 statistical significance, but S2 which is not significant wrt Baseline 3.", "labels": [], "entities": []}, {"text": "S6 is the best performing system, achieving 0.809 MAP, only 4% below the supervised upper-bound (statistically insignificant at the 0.95 level).", "labels": [], "entities": [{"text": "MAP", "start_pos": 50, "end_pos": 53, "type": "METRIC", "confidence": 0.9920192360877991}]}, {"text": "These results indicate that our methods for automatically acquiring training data are highly effective and competitive with manually crafted training sets.", "labels": [], "entities": []}, {"text": "A class-by-class analysis reveals similar behavior for Actors and Musicians.", "labels": [], "entities": []}, {"text": "For these two classes, the best negative set is N cls (system S3), achieving alone the best AP (respectively 0.842 and 0.770 for Actors and Musicians, 2.1% and 1.6% points below the upper-bound).", "labels": [], "entities": [{"text": "AP", "start_pos": 92, "end_pos": 94, "type": "METRIC", "confidence": 0.9973661303520203}]}, {"text": "N oth and N cbc show a lower accuracy, more than 10% below N cls . This suggest that the most promising strategy for automatically acquiring negative training data is to collect examples from the target class, as they guarantee to be drawn from the same distribution as the instances to be decoded.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9990917444229126}]}, {"text": "The use of near-and far-misses is still valuable (AP results are still better than the baselines), but less effective.", "labels": [], "entities": [{"text": "AP", "start_pos": 50, "end_pos": 52, "type": "METRIC", "confidence": 0.9967597126960754}]}, {"text": "Results for Athletes give different evidence: the best performing negative set is N oth , performing significantly better than N cls . To investigate this contrasting result, we manually picked 20 examples from N cls , N oth and N cbc for each class, and checked their degree of noise, i.e., how many false negatives they contain.", "labels": [], "entities": []}, {"text": "reports the results: these numbers indicate that the N cls is very noisy for the Athletes class, while it is more clean for the other two classes.", "labels": [], "entities": []}, {"text": "This suggests that the learning algorithm, while being robust enough to cope with the small noise in N cls for Actors and Musicians, it starts to diverge when too many false negatives are presented for training, as it happens for Athletes.", "labels": [], "entities": []}, {"text": "False negatives in N cls are correct instances extracted by one untrusted KE alone.", "labels": [], "entities": []}, {"text": "The results in indicates that our untrusted KEs are more accurate in extracting instances for Athletes than for the other classes: accurate enough to make our training set too noisy, thus decreasing the performance of S3 wrt S1 and S2.", "labels": [], "entities": []}, {"text": "This indicates that the effectiveness of N cls decreases when the accuracy of the untrusted KEs is higher.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9992585778236389}]}, {"text": "A good strategy to avoid the above problem is to pair N cls with another negative set, either N cbc or N oth , as in S5 and S6, respectively.", "labels": [], "entities": []}, {"text": "Then, when the above problem is presented, the learning algorithm can rely on the other negative set to compensate some for the noise.", "labels": [], "entities": []}, {"text": "Indeed, when adding N cbc to N cls (system S6) the accuracy over Athletes improves, while the overall performance across all classes (MAP) is kept constant wrt the system using N cls (S3).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9996562004089355}, {"text": "MAP)", "start_pos": 134, "end_pos": 138, "type": "METRIC", "confidence": 0.9408320486545563}]}, {"text": "It is interesting that in, N cbc and N oth also have a few false negatives.", "labels": [], "entities": []}, {"text": "An intrinsic analysis reveals that these are either: (1) Incorrect instances of the other classes that are actual instances of the target class; (2) Correct instances of other classes that are also instances of the target class.", "labels": [], "entities": []}, {"text": "Case (1) is caused by errors of KEs for the other classes (e.g., erroneously extracting 'Matthew Flynt' as a Musician).", "labels": [], "entities": [{"text": "extracting 'Matthew Flynt' as a Musician", "start_pos": 77, "end_pos": 117, "type": "TASK", "confidence": 0.6477772742509842}]}, {"text": "Case (2) covers cases in which instances are ambiguous across classes, for example 'Kerry Taylor' is both an Actor and a Musician.", "labels": [], "entities": []}, {"text": "This observation is still surprising, since Eq.", "labels": [], "entities": []}, {"text": "3 explicitly removes from N cbc and N oth any correct instance of the target class extracted by the KEs.", "labels": [], "entities": []}, {"text": "The presence of false negatives is then due to the low coverage of the KEs for the target class, e.g. the KEs were notable to extract 'Matthew Flynt' and 'Kerry Taylor' as actors.", "labels": [], "entities": []}, {"text": "We computed the Spearman correlation coefficient r among the rankings produced by the different system instantiations, to verify how complementary the information enclosed in the training sets are for building the learning model.", "labels": [], "entities": [{"text": "Spearman correlation coefficient r", "start_pos": 16, "end_pos": 50, "type": "METRIC", "confidence": 0.7641890719532967}]}, {"text": "Among the basic systems S1 \u2212 S3, the highest correlation is between S1 and S2 (r = 0.66 in average across all classes), which is expected, since they both apply the principle of acquiring negative examples from classes other than the target one.", "labels": [], "entities": []}, {"text": "S3 exhibits lower correlation with both S1 and S2, respectively r = 0.57 and r = 0.53, suggesting that it is complementary to them.", "labels": [], "entities": []}, {"text": "Also, the best system S6   has higher correlation with S3 (r = 0.94) than with S2 (r = 0.62), indicating that in the combination of N cls and N cbc , most of the model is built on N cls . Varying the positive training.", "labels": [], "entities": []}, {"text": "reports results when fixing the negative set to the best performing N cls , and exploring the use of other positive sets.", "labels": [], "entities": []}, {"text": "As expected P cls largely outperforms P trs , confirming that removing the constraint in Eq.", "labels": [], "entities": [{"text": "Eq", "start_pos": 89, "end_pos": 91, "type": "DATASET", "confidence": 0.9156418442726135}]}, {"text": "2 and using the simpler Eq.", "labels": [], "entities": []}, {"text": "1 makes the training set unrepresentative of the unlabeled population.", "labels": [], "entities": []}, {"text": "A similar observation stands for P cbc . These results indicate that having a good trusted KE, or even an external resource of positives, is effective only when selecting from the training set examples that are also extracted by the untrusted KEs.", "labels": [], "entities": []}, {"text": "In we report an analysis of the AP achieved by the best performing System (S6), when varying the training size, i.e., changing the cardinality of P cls and N cls + N cbc . The results show that a relatively small-sized training set offers good performance, the plateau being reached already with 500 training examples.", "labels": [], "entities": [{"text": "AP", "start_pos": 32, "end_pos": 34, "type": "METRIC", "confidence": 0.9947388768196106}]}, {"text": "This is an encouraging result, showing that our methods can potentially be applied also in cases where few examples are available, e.g., for rare or not wellrepresented classes.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Average precision (AP) results of systems using different training sets, compared to two usupervised Base- lines, a supervised Baseline, and a fully supervised upper-bound system.  \u00a7 indicates statistical significance at the 0.95  level wrt all Baselines.  \u2021 indicates statistical significance at the 0.95 level wrt Baseline1 and Baseline 2.  \u2020 indicates  statistical significance at the 0.95 level wrt", "labels": [], "entities": [{"text": "Average precision (AP)", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.9058953523635864}]}, {"text": " Table 2: Percentage of false negatives in different types of  negative sets, across the three experimented classes (esti- mations over a random sample of 20 examples per class).", "labels": [], "entities": []}, {"text": " Table 3: Comparative average precision (AP) results for  systems using different positive sets as training data.", "labels": [], "entities": [{"text": "Comparative average precision (AP)", "start_pos": 10, "end_pos": 44, "type": "METRIC", "confidence": 0.8133316536744436}]}]}