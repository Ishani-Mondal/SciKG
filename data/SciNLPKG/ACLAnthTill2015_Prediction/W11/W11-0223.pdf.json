{"title": [{"text": "Self-training and co-training in biomedical word sense disambiguation", "labels": [], "entities": [{"text": "biomedical word sense disambiguation", "start_pos": 33, "end_pos": 69, "type": "TASK", "confidence": 0.7262494713068008}]}], "abstractContent": [{"text": "Word sense disambiguation (WSD) is an intermediate task within information retrieval and information extraction, attempting to select the proper sense of ambiguous words.", "labels": [], "entities": [{"text": "Word sense disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8186261008183161}, {"text": "information retrieval", "start_pos": 63, "end_pos": 84, "type": "TASK", "confidence": 0.7085259109735489}, {"text": "information extraction", "start_pos": 89, "end_pos": 111, "type": "TASK", "confidence": 0.7025354355573654}]}, {"text": "Due to the scarcity of training data, semi-supervised learning, which profits from seed annotated examples and a large set of unlabeled data, are worth researching.", "labels": [], "entities": []}, {"text": "We present preliminary results of two semi-supervised learning algorithms on biomedical word sense disambigua-tion.", "labels": [], "entities": [{"text": "biomedical word sense disambigua-tion", "start_pos": 77, "end_pos": 114, "type": "TASK", "confidence": 0.6405789852142334}]}, {"text": "Both methods add relevant unlabeled examples to the training set, and optimal parameters are similar for each ambiguous word.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word sense disambiguation (WSD) is an intermediate task within information retrieval and information extraction, attempting to select the proper sense of ambiguous words.", "labels": [], "entities": [{"text": "Word sense disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8186261008183161}, {"text": "information retrieval", "start_pos": 63, "end_pos": 84, "type": "TASK", "confidence": 0.7085259109735489}, {"text": "information extraction", "start_pos": 89, "end_pos": 111, "type": "TASK", "confidence": 0.7025354355573654}]}, {"text": "Supervised learning achieves better performance compared to other WSD approaches ().", "labels": [], "entities": [{"text": "WSD", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.9118719100952148}]}, {"text": "Manual annotation requires a large level of human effort whereas there is a large quantity of unlabeled data.", "labels": [], "entities": [{"text": "Manual annotation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.714354395866394}]}, {"text": "Our work follows) but is applied to the biomedical domain; it relies on two semi-supervised learning algorithms.", "labels": [], "entities": []}, {"text": "We have performed experiments of semisupervised learning for word sense disambiguation in the biomedical domain.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 61, "end_pos": 86, "type": "TASK", "confidence": 0.7741307218869528}]}, {"text": "In the following section, we present the evaluated algorithms.", "labels": [], "entities": []}, {"text": "Then, we present preliminary results for self-training and co-training, which show a modest improvement with a common set-up of the algorithms for the evaluated ambiguous words.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}