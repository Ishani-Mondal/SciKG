{"title": [], "abstractContent": [{"text": "This paper describes the development operated into MANY for the 2011 WMT system combination evaluation campaign.", "labels": [], "entities": [{"text": "MANY", "start_pos": 51, "end_pos": 55, "type": "DATASET", "confidence": 0.4747450351715088}, {"text": "WMT system combination evaluation", "start_pos": 69, "end_pos": 102, "type": "TASK", "confidence": 0.7279404252767563}]}, {"text": "Hypotheses from French/English and En-glish/French MT systems were combined with anew version of MANY, an open source system combination software based on confusion networks decoding currently developed at LIUM.", "labels": [], "entities": [{"text": "LIUM", "start_pos": 206, "end_pos": 210, "type": "DATASET", "confidence": 0.9351847171783447}]}, {"text": "MANY has been updated in order to optimize decoder parameters with MERT, which proves to find better weights.", "labels": [], "entities": [{"text": "MANY", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.658039927482605}, {"text": "MERT", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.9423732161521912}]}, {"text": "The system combination yielded significant improvements in BLEU score when applied on system combination data from two languages.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 59, "end_pos": 69, "type": "METRIC", "confidence": 0.9621009528636932}]}], "introductionContent": [{"text": "This year, the LIUM computer science laboratory participated in the French-English system combination task at WMT'11 evaluation campaign.", "labels": [], "entities": [{"text": "WMT'11 evaluation campaign", "start_pos": 110, "end_pos": 136, "type": "DATASET", "confidence": 0.7198151350021362}]}, {"text": "The system used for this task is MANY 1, an open source system combination software based on Confusion Networks (CN).", "labels": [], "entities": []}, {"text": "For this year evaluation, rather more technical than scientific improvements have been added to MANY.", "labels": [], "entities": [{"text": "MANY", "start_pos": 96, "end_pos": 100, "type": "DATASET", "confidence": 0.8396148681640625}]}, {"text": "The tuning process has been improved by using MERT as a replacement of the numerical optimizer Condor).", "labels": [], "entities": [{"text": "MERT", "start_pos": 46, "end_pos": 50, "type": "METRIC", "confidence": 0.8745133876800537}]}, {"text": "The impact of such change is detailed in section 3.", "labels": [], "entities": []}, {"text": "After the evaluation period, some experiments have been performed on the English-French system combination task.", "labels": [], "entities": []}, {"text": "The results are presented in the section 5.", "labels": [], "entities": []}, {"text": "Before that, a quick description of MANY, including recent developments, can be found in section 2. 2 System description MANY is a system combination software) based on the decoding of a lattice made of several Confusion.", "labels": [], "entities": [{"text": "MANY", "start_pos": 36, "end_pos": 40, "type": "DATASET", "confidence": 0.7592246532440186}]}, {"text": "This is a widespread approach in MT system combination ().", "labels": [], "entities": [{"text": "MT system combination", "start_pos": 33, "end_pos": 54, "type": "TASK", "confidence": 0.9114583333333334}]}, {"text": "MANY can be decomposed in two main modules.", "labels": [], "entities": [{"text": "MANY", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8503221869468689}]}, {"text": "The first one is the alignment module which actually is a modified version of TERp (.", "labels": [], "entities": [{"text": "alignment", "start_pos": 21, "end_pos": 30, "type": "TASK", "confidence": 0.9720208644866943}, {"text": "TERp", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.47321465611457825}]}, {"text": "Its role is to incrementally align the hypotheses against a backbone in order to create a confusion network.", "labels": [], "entities": []}, {"text": "Those confusion networks are then connected together to create a lattice.", "labels": [], "entities": []}, {"text": "This module uses different costs (which corresponds to a match, an insertion, a deletion, a substitution, a shift, a synonym and a stem) to compute the best alignment and incrementally build a confusion network.", "labels": [], "entities": []}, {"text": "In the case of confusion network, the match (substitution, synonyms, and stems) costs are considered when the word in the hypothesis matches (is a substitution, a synonyms or a stems of) at least one word of the considered confusion sets in the CN.", "labels": [], "entities": []}, {"text": "The second module is the decoder.", "labels": [], "entities": []}, {"text": "This decoder is based on the token pass algorithm and it accepts as input the lattice previously created.", "labels": [], "entities": []}, {"text": "The probabilities computed in the decoder can be expressed as follow : where t is the hypothesis, the \u03b1 i are the weights of the feature functions hi . The following features are considered for decoding: \u2022 The language model probability: the probability given by a 4-gram language model.", "labels": [], "entities": []}, {"text": "\u2022 The word penalty: penalty depending on the size (in words) of the hypothesis.", "labels": [], "entities": [{"text": "word penalty", "start_pos": 6, "end_pos": 18, "type": "METRIC", "confidence": 0.8099312484264374}]}, {"text": "\u2022 The null-arc penalty: penalty depending on the number of null-arcs crossed in the lattice to obtain the hypothesis.", "labels": [], "entities": []}, {"text": "\u2022 System weights: each word receive a weight corresponding to the sum of the weights of all systems which proposed it.", "labels": [], "entities": []}], "datasetContent": [{"text": "A development corpus, newssyscombtune2011, and a test set, newssyscombtest2011, described in   Choosing the right number of systems to combine: shows the performance of the input systems (ordered by BLEU score computed on newssyscombtune2011) and the result of 3 system combination setups.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 199, "end_pos": 203, "type": "METRIC", "confidence": 0.9984941482543945}]}, {"text": "The difference in these setups only reside on the number of inputs to use for combination (5, 10 and all system outputs).", "labels": [], "entities": []}, {"text": "Notice that the contrastive runs have not been used when combining 5 and 10 systems.", "labels": [], "entities": []}, {"text": "The motivation for this is to benefit from the multi-site systems development which more likely provide varied outputs (i.e. different ngrams and word choice).", "labels": [], "entities": []}, {"text": "The results show that combining 5 systems is slightly better than 10, but give more than 1 BLEU point improvement compared to combining all systems.", "labels": [], "entities": [{"text": "BLEU point", "start_pos": 91, "end_pos": 101, "type": "METRIC", "confidence": 0.9650655686855316}]}, {"text": "Still, the combination always provide an improvement, which was not the casein last year evaluation.", "labels": [], "entities": []}, {"text": "The results obtained by combining 5 and 10 systems are presented in 30.60 51.39: Baseline systems performance on WMT'11 syscomb test data (%BLEU-cased).", "labels": [], "entities": [{"text": "WMT'11 syscomb test data", "start_pos": 113, "end_pos": 137, "type": "DATASET", "confidence": 0.8980108946561813}, {"text": "BLEU-cased", "start_pos": 140, "end_pos": 150, "type": "METRIC", "confidence": 0.9988037347793579}]}, {"text": "Optimizing MANY on newssyscombtune2011 corpus produced the parameter set presented in Table 8.", "labels": [], "entities": [{"text": "newssyscombtune2011 corpus", "start_pos": 19, "end_pos": 45, "type": "DATASET", "confidence": 0.8570450246334076}]}, {"text": "We can see that the weights of all system are not proportional to the BLEU score obtained on the development corpus.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 70, "end_pos": 80, "type": "METRIC", "confidence": 0.9762224853038788}]}, {"text": "This suggest that a better system selection could be found.", "labels": [], "entities": []}, {"text": "This is even more probable since the weight of system Sys2 is positive (which imply a negative impact on each word proposed by this system), which means that when an hypothesis contains a word coming from this system, then its score is decreased.: Parameters obtained after tuning the system parameter using 5 hypotheses.", "labels": [], "entities": []}, {"text": "contains the BLEU scores computed between the outputs of the five systems used during combination.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.998777449131012}]}, {"text": "An interesting observation is that the system which receive the bigger weight is the one which \"distance\" 2 against all other system outputs Sys0 Sys1 Sys2 Sys3 Sys5 mean: Cross-system BLEU scores computed on WMT'11 French-English test corpus outputs (%BLEU-cased).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 185, "end_pos": 189, "type": "METRIC", "confidence": 0.9698503613471985}, {"text": "WMT'11 French-English test corpus outputs", "start_pos": 209, "end_pos": 250, "type": "DATASET", "confidence": 0.9244006037712097}, {"text": "BLEU-cased", "start_pos": 253, "end_pos": 263, "type": "METRIC", "confidence": 0.9978588223457336}]}], "tableCaptions": [{"text": " Table 1: WMT'09 corpora : number of sentences,  words and tokens calculated on the reference.", "labels": [], "entities": [{"text": "WMT'09", "start_pos": 10, "end_pos": 16, "type": "DATASET", "confidence": 0.7389494180679321}]}, {"text": " Table 2:  Baseline systems performance on  WMT'09 data (%BLEU).", "labels": [], "entities": [{"text": "WMT'09 data", "start_pos": 44, "end_pos": 55, "type": "DATASET", "confidence": 0.9571068286895752}, {"text": "BLEU", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9991555213928223}]}, {"text": " Table 3: Parameters obtained with tuning decoder  parameters with MERT.", "labels": [], "entities": [{"text": "MERT", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.7770328521728516}]}, {"text": " Table 4: System Combination results on WMT'09  data (%BLEU-cased).", "labels": [], "entities": [{"text": "WMT'09  data", "start_pos": 40, "end_pos": 52, "type": "DATASET", "confidence": 0.9656124114990234}, {"text": "BLEU-cased", "start_pos": 55, "end_pos": 65, "type": "METRIC", "confidence": 0.9987480640411377}]}, {"text": " Table 5: Description of WMT'11 corpora.", "labels": [], "entities": [{"text": "WMT'11 corpora", "start_pos": 25, "end_pos": 39, "type": "DATASET", "confidence": 0.7811735272407532}]}, {"text": " Table 6: Systems performance on newssyscomb- tune2011 development data (%BLEU-cased). (*  indicate a contrastive run)", "labels": [], "entities": [{"text": "newssyscomb- tune2011 development data", "start_pos": 33, "end_pos": 71, "type": "DATASET", "confidence": 0.8996161103248597}, {"text": "BLEU-cased", "start_pos": 74, "end_pos": 84, "type": "METRIC", "confidence": 0.9987442493438721}]}, {"text": " Table 7:  Baseline systems performance on  WMT'11 syscomb test data (%BLEU-cased).", "labels": [], "entities": [{"text": "WMT'11 syscomb test data", "start_pos": 44, "end_pos": 68, "type": "DATASET", "confidence": 0.9043614566326141}, {"text": "BLEU-cased", "start_pos": 71, "end_pos": 81, "type": "METRIC", "confidence": 0.9987583160400391}]}, {"text": " Table 8: Parameters obtained after tuning the sys- tem parameter using 5 hypotheses.", "labels": [], "entities": []}, {"text": " Table 9: Cross-system BLEU scores computed  on WMT'11 French-English test corpus outputs  (%BLEU-cased).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 23, "end_pos": 27, "type": "METRIC", "confidence": 0.985451340675354}, {"text": "WMT'11 French-English test corpus outputs", "start_pos": 48, "end_pos": 89, "type": "DATASET", "confidence": 0.935518229007721}, {"text": "BLEU-cased", "start_pos": 93, "end_pos": 103, "type": "METRIC", "confidence": 0.9977426528930664}]}, {"text": " Table 10: Description of WMT'11 corpora for  system combination in french.", "labels": [], "entities": [{"text": "system combination", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.6583272516727448}]}, {"text": " Table 11: Systems and combination performance  on WMT'11 french data (%BLEU-cased).", "labels": [], "entities": [{"text": "WMT'11 french data", "start_pos": 51, "end_pos": 69, "type": "DATASET", "confidence": 0.8963597416877747}, {"text": "BLEU-cased", "start_pos": 72, "end_pos": 82, "type": "METRIC", "confidence": 0.9986050724983215}]}]}