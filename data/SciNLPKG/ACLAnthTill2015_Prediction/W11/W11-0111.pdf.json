{"title": [{"text": "Acquiring entailment pairs across languages and domains: A data analysis", "labels": [], "entities": [{"text": "Acquiring entailment", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.7315980792045593}]}], "abstractContent": [{"text": "Entailment pairs are sentence pairs of a premise and a hypothesis, where the premise textually entails the hypothesis.", "labels": [], "entities": []}, {"text": "Such sentence pairs are important for the development of Textual Entailment systems.", "labels": [], "entities": [{"text": "Textual Entailment", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.828884094953537}]}, {"text": "In this paper, we take a closer look at a prominent strategy for their automatic acquisition from newspaper corpora, pairing first sentences of articles with their titles.", "labels": [], "entities": []}, {"text": "We propose a simple logistic regression model that incorporates and extends this heuristic and investigate its robustness across three languages and three domains.", "labels": [], "entities": []}, {"text": "We manage to identify two predictors which predict entailment pairs with a fairly high accuracy across all languages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9965303540229797}]}, {"text": "However, we find that robustness across domains within a language is more difficult to achieve.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic processing has become a major focus of attention in NLP.", "labels": [], "entities": [{"text": "Semantic processing", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8379903733730316}]}, {"text": "However, different applications such as Question Answering, Information Extraction and Machine Translation often adopt very different, task-specific semantic processing strategies.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.8597553968429565}, {"text": "Information Extraction", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.8409773409366608}, {"text": "Machine Translation", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.8136001527309418}]}, {"text": "Textual entailment (TE) was introduced by as a \"meta-task\" that can subsume a large part of the semantic processing requirements of such applications by providing a generic concept of inference that corresponds to \"common sense\" reasoning patterns.", "labels": [], "entities": [{"text": "Textual entailment (TE)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8195284128189086}]}, {"text": "Textual Entailment is defined as a relation between two natural language utterances (a Premise P and a Hypothesis H) that holds if \"a human reading P would infer that H is most likely true\".", "labels": [], "entities": [{"text": "Textual Entailment", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7662643492221832}]}, {"text": "See, e.g., the ACL \"challenge paper\" by for further details.", "labels": [], "entities": [{"text": "ACL \"challenge paper", "start_pos": 15, "end_pos": 35, "type": "DATASET", "confidence": 0.7828587740659714}]}, {"text": "The successive TE workshops that have taken place yearly since 2005 have produced annotation for English which amount to a total of several thousand entailing Premise-Hypothesis sentence pairs, which we will call entailment pairs: (1) P: Swedish bond yields end 21 basis points higher.", "labels": [], "entities": []}, {"text": "H: Swedish bond yields rose further.", "labels": [], "entities": []}, {"text": "From the machine learning perspective assumed by many approaches to TE, this is a very small number of examples, given the complex nature of entailment.", "labels": [], "entities": [{"text": "TE", "start_pos": 68, "end_pos": 70, "type": "TASK", "confidence": 0.9907770156860352}]}, {"text": "Given the problems of manual annotation, therefore, proposed to take advantage of the structural properties of a particular type of discourse -namely newspaper articles -to automatically harvest entailment pairs.", "labels": [], "entities": []}, {"text": "They proposed to pair the title of each article with its first sentence, interpreting the first sentence as Premise and the title as Hypothesis.", "labels": [], "entities": []}, {"text": "Their results were mixed, with an average of 50% actual entailment pairs among all pairs constructed in this manner.", "labels": [], "entities": []}, {"text": "SVMs which identified \"entailment-friendly\" documents based on their bags of words lead to an accuracy of 77%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9996447563171387}]}, {"text": "Building on the same general idea,) applied a simple unsupervised filter which removes all entailment pair candidates that \"did not share an entity (or an NP)\".", "labels": [], "entities": []}, {"text": "They report an accuracy of 91.8% on a manually evaluated sample -considerably better Burger and Ferro.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9997219443321228}]}, {"text": "The article however does not mention the size of the original corpus, and whether \"entity\" is to be understood as named entity, so it is difficult to assess what its recall is, and whether it presupposes a high-quality NER system.", "labels": [], "entities": [{"text": "recall", "start_pos": 166, "end_pos": 172, "type": "METRIC", "confidence": 0.9949493408203125}]}, {"text": "In this paper, we model the task using a logistic regression model that allows us to synchronously analyse the data and predict entailment pairs, and focus on the question of how well these results generalize across domains and languages, for many of which no entailment pairs are available at all.", "labels": [], "entities": []}, {"text": "We make three main contributions: (a), we define an annotation scheme based on semantic and discourse phenomena that can break entailment and annotate two datasets with it; (b), we idenfiy two robust properties of sentence pairs that correlate strongly with entailment and which are robust enough to support high-precision entailment pair extraction; (c), we find that cross-domain differences are actually larger than cross-lingual differences, even for languages as different as German and Hindi.", "labels": [], "entities": [{"text": "entailment pair extraction", "start_pos": 323, "end_pos": 349, "type": "TASK", "confidence": 0.7864739100138346}]}, {"text": "Section 2 defines our annotation scheme.", "labels": [], "entities": []}, {"text": "In Section 3, we sketch the logistic regression framework we use for analysis, and motivate our choice of predictors.", "labels": [], "entities": []}, {"text": "Sections 4 and 5 present the two experiments on language and domain comparisons, respectively.", "labels": [], "entities": [{"text": "language and domain comparisons", "start_pos": 48, "end_pos": 79, "type": "TASK", "confidence": 0.5773775652050972}]}, {"text": "We conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 4: Exp. 1: Precision for the class \"yes\" (entailment) at 30% Recall", "labels": [], "entities": [{"text": "Precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9967544674873352}, {"text": "Recall", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.9846234917640686}]}, {"text": " Table 5: Exp. 2: Distribution of annotation categories on German corpora (in percent)", "labels": [], "entities": []}, {"text": " Table 6: Exp. 2: Predictors in the logreg model (*: p<0.05; **: p<0.01; ***: p<0.001)", "labels": [], "entities": []}, {"text": " Table 7: Exp. 2: Precision for the class \"yes\" at 30% recall", "labels": [], "entities": [{"text": "Precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9975095987319946}]}]}