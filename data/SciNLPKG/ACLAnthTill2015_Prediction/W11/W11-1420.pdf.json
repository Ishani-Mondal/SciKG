{"title": [{"text": "Non-English Response Detection Method for Automated Proficiency Scoring System", "labels": [], "entities": [{"text": "Non-English Response Detection", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6916093528270721}, {"text": "Automated Proficiency Scoring", "start_pos": 42, "end_pos": 71, "type": "TASK", "confidence": 0.7040235797564188}]}], "abstractContent": [{"text": "This paper presents a method for identifying non-English speech, with the aim of supporting an automated speech proficiency scoring system for non-native speakers.", "labels": [], "entities": []}, {"text": "The method uses a popular technique from the language identification domain, a single phone recognizer followed by multiple language-dependent language models.", "labels": [], "entities": []}, {"text": "This method determines the language of a speech sample based on the phonotactic differences among languages.", "labels": [], "entities": []}, {"text": "The method is intended for use with non-native English speakers.", "labels": [], "entities": []}, {"text": "Therefore, the method must be able to distinguish non-English responses from non-native speakers' English responses.", "labels": [], "entities": []}, {"text": "This makes the task more challenging, as the frequent pronunciation errors of non-native speakers may weaken the phonetic and phonotactic distinction between English responses and non-English responses.", "labels": [], "entities": []}, {"text": "In order to address this issue, the speaking rate measure was used to complement the language identification based features in the model.", "labels": [], "entities": []}, {"text": "The accuracy of the method was 98%, and there was 45% relative error reduction over a system based on the conventional language identification technique.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997327923774719}, {"text": "relative error reduction", "start_pos": 54, "end_pos": 78, "type": "METRIC", "confidence": 0.7666824062665304}, {"text": "language identification", "start_pos": 119, "end_pos": 142, "type": "TASK", "confidence": 0.7471745014190674}]}, {"text": "The model using both feature sets furthermore demonstrated an improvement inaccuracy for speakers at all English proficiency levels.", "labels": [], "entities": []}], "introductionContent": [{"text": "We developed a non-English response identification method as a supplementary module for the automated speech proficiency scoring of non-native speakers.", "labels": [], "entities": [{"text": "non-English response identification", "start_pos": 15, "end_pos": 50, "type": "TASK", "confidence": 0.62863161166509}, {"text": "automated speech proficiency scoring", "start_pos": 92, "end_pos": 128, "type": "TASK", "confidence": 0.6435788795351982}]}, {"text": "The method can identify speech samples of test takers who try to game the system by speaking in their native languages.", "labels": [], "entities": []}, {"text": "For the items that elicited spontaneous speech, fluency features such as speaking rate have been one of the most important features in the automated scoring.", "labels": [], "entities": [{"text": "speaking rate", "start_pos": 73, "end_pos": 86, "type": "METRIC", "confidence": 0.6939620971679688}]}, {"text": "By speaking in their native languages, speakers can generate fluent speech, and the automated proficiency scoring system may assign a high score.", "labels": [], "entities": []}, {"text": "This problem has been rarely recognized, and none of research has focused on it as to the authors' knowledge.", "labels": [], "entities": []}, {"text": "In order to address this issue, the automated proficiency scoring system in this study first filters out the responses in non-English languages, and for the remaining responses, it predicts the proficiency score using a scoring model.", "labels": [], "entities": []}, {"text": "Non-English detection is strongly related to language identification; language identification is the process of determining which language a spoken response is in, while non-English detection makes a binary decision whether the spoken response is in English or not.", "labels": [], "entities": [{"text": "Non-English detection", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7862142324447632}, {"text": "language identification", "start_pos": 45, "end_pos": 68, "type": "TASK", "confidence": 0.7313304245471954}, {"text": "language identification", "start_pos": 70, "end_pos": 93, "type": "TASK", "confidence": 0.7375935167074203}]}, {"text": "Due to the strong similarity between the two tasks, the language identification method was used here for non-English response detection.", "labels": [], "entities": [{"text": "language identification", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.7062243223190308}, {"text": "non-English response detection", "start_pos": 105, "end_pos": 135, "type": "TASK", "confidence": 0.6446673572063446}]}, {"text": "In contrast to previous research, the method described here was intended for use with non-native speakers, and the English responses for model training and evaluation were accordingly collected from non-native speakers.", "labels": [], "entities": []}, {"text": "Among other differences, non-native speakers' speech tends to display nonstandard pronunciation characteristics which can make the task of language identification more challenging.", "labels": [], "entities": [{"text": "language identification", "start_pos": 139, "end_pos": 162, "type": "TASK", "confidence": 0.7309784889221191}]}, {"text": "For instance, when native Korean speakers speak English, they may replace some English phonemes not in their language with their native phones, and epenthesize vowels within consonant clusters.", "labels": [], "entities": []}, {"text": "Such processes tend to reduce the phonetic and phonotactic distinction between English and other languages.", "labels": [], "entities": []}, {"text": "The frequency of these pronunciation errors is influenced by speakers' native language and proficiency level, with lowerproficiency speakers likely to exhibit the greatest degree of divergence from standard pronunciation.", "labels": [], "entities": []}, {"text": "Language identification method may not effectively distinguish non-fluent speakers' English responses from non-English responses.", "labels": [], "entities": [{"text": "Language identification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.6522442251443863}]}, {"text": "In order to address these non-native speech characteristics, the model described here includes the speaking rate feature, which has been found to bean indicator of speaking proficiency in previous research.", "labels": [], "entities": []}, {"text": "Non-fluent speakers' English responses can be distinguished from non-English responses by slow speaking rate.", "labels": [], "entities": []}, {"text": "This paper will proceed as follows: we first review previous studies in section 2, then describe the data in section 3, and present the experiment in section 4.", "labels": [], "entities": []}, {"text": "The results and discussion are presented in section 5, and the conclusions are presented in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "First, the accuracy of the PRLM method was evaluated based on multiple forced-choice experiments with two alternatives using OGI data; in addition to non-English responses in EN-detection partition, English responses from the OGI data were used in this experiment.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9993281364440918}, {"text": "PRLM", "start_pos": 27, "end_pos": 31, "type": "TASK", "confidence": 0.9700391888618469}, {"text": "OGI data", "start_pos": 226, "end_pos": 234, "type": "DATASET", "confidence": 0.8256353735923767}]}, {"text": "For each response (in English and one other language), phone hypothesis was generated and two normalized LM scores were calculated using the English LM and the LM for the other language.", "labels": [], "entities": []}, {"text": "The MaxLanguage was hypothesized as the source language of the speech.", "labels": [], "entities": [{"text": "MaxLanguage", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9511921405792236}]}, {"text": "The same experiment was performed for 9 combinations of English and other languages.", "labels": [], "entities": []}, {"text": "Each experiment was comprised of 17 English utterances and 17 non-English utterances . The majority class baseline was thus 0.5.", "labels": [], "entities": []}, {"text": "The mean accuracy of the 9 experiments in this study was 0.943, which is comparable to (1996)'s performance: in his study, the best performing PRLM exhibited an average accuracy of 0.950.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9508635997772217}, {"text": "accuracy", "start_pos": 169, "end_pos": 177, "type": "METRIC", "confidence": 0.992052435874939}]}, {"text": "This initial evaluation used the same data and feature as.", "labels": [], "entities": []}, {"text": "(Of the seven PRLM-based features listed above, only MaxLanguage was used in (1996)'s study.) summarizes the evaluation results of the non-English response detection experiments using three-fold cross-validation within the EN-detection partition.", "labels": [], "entities": [{"text": "response detection", "start_pos": 147, "end_pos": 165, "type": "TASK", "confidence": 0.7162400484085083}]}, {"text": "In order to investigate the impact of different types of features, the features were classified into four sets-MaxLanguage only, PRLM (encompassing all PRLM features), SpeakingRate, and all-and models were trained using each set.", "labels": [], "entities": []}, {"text": "The baseline using majority voting demonstrated an accuracy of 0.95 by classifying all responses as English responses.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9996190071105957}]}, {"text": "All models achieved improvements over baseline.", "labels": [], "entities": []}, {"text": "In particular, the model using all features achieved a 66% relative error reduction over the baseline of 0.95.", "labels": [], "entities": [{"text": "relative error reduction", "start_pos": 59, "end_pos": 83, "type": "METRIC", "confidence": 0.8526895642280579}]}, {"text": "Furthermore, the all-features model outperformed the model based only on PRLM or speaking  rate; the accuracy of the all-features model was approximately 1-2% higher than other models in absolute value and represented approximately a 45-50% relative error reduction over these models.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9995850920677185}]}, {"text": "The PRLM-based model had higher overall accuracy than the speaking rate-based model, and the difference was even more salient by the F-score measure: the PRLM-based model achieved an F-score approximately 24% higher than the speaking ratebased model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9964014291763306}, {"text": "F-score", "start_pos": 133, "end_pos": 140, "type": "METRIC", "confidence": 0.9965795874595642}, {"text": "F-score", "start_pos": 183, "end_pos": 190, "type": "METRIC", "confidence": 0.9961457252502441}]}, {"text": "The model based on all PRLM features did not achieve a higher accuracy than the model based on only MaxLanguage.", "labels": [], "entities": [{"text": "PRLM", "start_pos": 23, "end_pos": 27, "type": "TASK", "confidence": 0.8341394662857056}, {"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9991657733917236}, {"text": "MaxLanguage", "start_pos": 100, "end_pos": 111, "type": "DATASET", "confidence": 0.9515159130096436}]}, {"text": "However, there was a clear improvement in F-score by using the additional features.", "labels": [], "entities": [{"text": "F-score", "start_pos": 42, "end_pos": 49, "type": "METRIC", "confidence": 0.9985944628715515}]}, {"text": "The PRLM-based model achieved an F-score approximately 8% higher than the model based only on MaxLanguage.", "labels": [], "entities": [{"text": "F-score", "start_pos": 33, "end_pos": 40, "type": "METRIC", "confidence": 0.9992091059684753}, {"text": "MaxLanguage", "start_pos": 94, "end_pos": 105, "type": "DATASET", "confidence": 0.9547904133796692}]}, {"text": "In order to investigate the influence of speakers' proficiency on the accuracy of non-English detection, the responses in EN-detection were divided into 4 groups according to proficiency score, and the performance was calculated for each score group; the performance of each score group was calculated using subset comprised of all non-English responses and English responses with the corresponding scores.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9980388283729553}]}, {"text": "A majority class baseline (classifying all responses as English) was again used.", "labels": [], "entities": []}, {"text": "summarizes the results observed, by score level, for the baseline model and for four different models used in.", "labels": [], "entities": []}, {"text": "Note that the baseline is lower in, because the ratio of English to nonEnglish responses is lower for each of the subsets of the EN-detection partitions used for the evaluations: Relationship between proficiency score and MaxDifference at a given score level.", "labels": [], "entities": [{"text": "MaxDifference", "start_pos": 222, "end_pos": 235, "type": "METRIC", "confidence": 0.8386197090148926}]}, {"text": "For all score groups, the model using all features achieved high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.99871826171875}]}, {"text": "The model's accuracy on all data sets except for score group 1 was approximately 0.96 and the F-score approximately 0.85.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9997653365135193}, {"text": "F-score", "start_pos": 94, "end_pos": 101, "type": "METRIC", "confidence": 0.9946643114089966}]}, {"text": "The accuracy on score group 1 was 0.87, relatively lower than other score groups.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997774958610535}]}, {"text": "This is largely due to the smaller number of English responses available at score level 1, and the consequent lower baseline on this data set.", "labels": [], "entities": []}, {"text": "However, the relative error reduction was much larger; it was 74% for score group 1.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 22, "end_pos": 37, "type": "METRIC", "confidence": 0.9011037647724152}]}, {"text": "For all score groups, the PRLM-based models outperformed MaxLanguage based models and speaking rate based models.", "labels": [], "entities": []}, {"text": "Additional PRLM features improved the performance over the models only based on MaxLanguage (conventional language identification method).", "labels": [], "entities": [{"text": "PRLM", "start_pos": 11, "end_pos": 15, "type": "TASK", "confidence": 0.8502918481826782}]}, {"text": "In addition, the combination of both types of features resulted in further improvement.", "labels": [], "entities": []}, {"text": "The consistent improvement of the model using both PRLM and speaking rate features suggests a compensatory relationship between these features.", "labels": [], "entities": [{"text": "PRLM", "start_pos": 51, "end_pos": 55, "type": "TASK", "confidence": 0.8834192156791687}]}, {"text": "In order to investigate this relationship in further detail, two representative features, MaxDifference and AverageDifference were selected, and boxplots were created. and show the relationship between proficiency score and PRLM features.", "labels": [], "entities": [{"text": "AverageDifference", "start_pos": 108, "end_pos": 125, "type": "METRIC", "confidence": 0.9819760322570801}, {"text": "PRLM", "start_pos": 224, "end_pos": 228, "type": "TASK", "confidence": 0.901511013507843}]}, {"text": "In these figures, the label 'NE' is used to indicate the non-English group, while the labels 1, 2, 3, and 4 correspond to each score group.", "labels": [], "entities": []}, {"text": "shows that MaxDifference decreases as: Relationship between proficiency score and AverageDifference the speaker's proficiency decreases, although the feature displays a large variance.", "labels": [], "entities": [{"text": "MaxDifference", "start_pos": 11, "end_pos": 24, "type": "METRIC", "confidence": 0.9652513861656189}, {"text": "AverageDifference", "start_pos": 82, "end_pos": 99, "type": "METRIC", "confidence": 0.9929642677307129}]}, {"text": "The feature mean for non-English responses is lower than for score groups 2, 3, and 4, but the distinction between non-English and English becomes smaller as the proficiency score decreases.", "labels": [], "entities": [{"text": "feature mean", "start_pos": 4, "end_pos": 16, "type": "METRIC", "confidence": 0.9700843989849091}]}, {"text": "The feature mean for score group 1 is even lower than for non-English responses.", "labels": [], "entities": [{"text": "feature mean", "start_pos": 4, "end_pos": 16, "type": "METRIC", "confidence": 0.9794717729091644}]}, {"text": "This obscures the distinction between English responses and non-English responses at lower score levels.", "labels": [], "entities": []}, {"text": "As shows, AverageDifference is relatively stable across score levels, compared to MaxDifference.", "labels": [], "entities": [{"text": "AverageDifference", "start_pos": 10, "end_pos": 27, "type": "METRIC", "confidence": 0.9954257607460022}]}, {"text": "Although the mean feature value decreases as the proficiency score decreases, the decrease is smaller than for MaxDifference.", "labels": [], "entities": [{"text": "MaxDifference", "start_pos": 111, "end_pos": 124, "type": "DATASET", "confidence": 0.912192702293396}]}, {"text": "In addition, the mean feature values of the English groups are consistently higher than those for non-English responses.", "labels": [], "entities": []}, {"text": "shows the relationship between proficiency score and speaking rate.", "labels": [], "entities": []}, {"text": "For the speaking rate feature, the distinction between non-English and English responses increases as speakers' proficiency level decreases, as shown.", "labels": [], "entities": []}, {"text": "The speaking rate of non-English responses is the highest among all groups compared, and the speaking rate decreases for English responses as the speaker's proficiency score decreases.", "labels": [], "entities": [{"text": "speaking rate", "start_pos": 93, "end_pos": 106, "type": "METRIC", "confidence": 0.8894475996494293}]}, {"text": "Thus, the PRLM features tend to display better discrimination between English and non-English responses at the higher end of the proficiency scale, while the SpeakingRate feature provides better discrimination at the lower end of the scale.", "labels": [], "entities": []}, {"text": "By combining both feature classes, we are able to produce a model which outperforms both a PRLM-based model and a model using speaking rate alone.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Performance of non-English response detection", "labels": [], "entities": []}, {"text": " Table 3: Performance of non-English detection according to speakers' proficiency level", "labels": [], "entities": [{"text": "non-English detection", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.7564821541309357}]}]}