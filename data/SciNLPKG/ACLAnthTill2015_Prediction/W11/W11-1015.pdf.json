{"title": [{"text": "A General-Purpose Rule Extractor for SCFG-Based Machine Translation", "labels": [], "entities": [{"text": "General-Purpose Rule Extractor", "start_pos": 2, "end_pos": 32, "type": "TASK", "confidence": 0.6496898333231608}, {"text": "SCFG-Based Machine Translation", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.7957051197687784}]}], "abstractContent": [{"text": "We present a rule extractor for SCFG-based MT that generalizes many of the contraints present in existing SCFG extraction algorithms.", "labels": [], "entities": [{"text": "rule extractor", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.718927651643753}, {"text": "SCFG-based MT", "start_pos": 32, "end_pos": 45, "type": "TASK", "confidence": 0.6640927493572235}, {"text": "SCFG extraction", "start_pos": 106, "end_pos": 121, "type": "TASK", "confidence": 0.8612664639949799}]}, {"text": "Our method's increased rule coverage comes from allowing multiple alignments, virtual nodes, and multiple tree decompositions in the extraction process.", "labels": [], "entities": []}, {"text": "At decoding time, we improve automatic metric scores by significantly increasing the number of phrase pairs that match a given test set, while our experiments with hierarchical grammar filtering indicate that more intelligent filtering schemes will also provide a key to future gains.", "labels": [], "entities": []}], "introductionContent": [{"text": "Syntax-based machine translation systems, regardless of the underlying formalism they use, depend on a method for acquiring bilingual rules in that formalism to build the system's translation model.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7316893041133881}]}, {"text": "In modern syntax-based MT, this formalism is often synchronous context-free grammar (SCFG), and the SCFG rules are obtained automatically from parallel data through a large variety of methods.", "labels": [], "entities": [{"text": "MT", "start_pos": 23, "end_pos": 25, "type": "TASK", "confidence": 0.8836773633956909}]}, {"text": "Some SCFG rule extraction techniques require only Viterbi word alignment links between the source and target sides of the input corpus), while methods based on linguistic constituency structure require the source and/or target side of the input to be parsed.", "labels": [], "entities": [{"text": "SCFG rule extraction", "start_pos": 5, "end_pos": 25, "type": "TASK", "confidence": 0.8528747955958048}]}, {"text": "Among such techniques, most retain the dependency on Viterbi word alignments for each sentence (;) while others make use of a general, corpus-level statistical lexicon instead of individual alignment links (.", "labels": [], "entities": []}, {"text": "Each method may also place constraints on the size, format, or structure of the rules it returns.", "labels": [], "entities": []}, {"text": "This paper describes anew, general-purpose rule extractor intended for cases in which two parse trees and Viterbi word alignment links are provided for each sentence, although compatibility with singleparse-tree extraction methods can be achieved by supplying a flat \"dummy\" parse for the missing tree.", "labels": [], "entities": [{"text": "rule extractor", "start_pos": 43, "end_pos": 57, "type": "TASK", "confidence": 0.7687149941921234}]}, {"text": "Our framework for rule extraction is thus most similar to the Stat-XFER system () and the tree-to-tree situation considered by.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 18, "end_pos": 33, "type": "TASK", "confidence": 0.8462066352367401}]}, {"text": "However, we significantly broaden the scope of allowable rules compared to the Stat-XFER heuristics, and our approach differs from Chiang's system in its respect of the linguistic constituency constraints expressed in the input tree structure.", "labels": [], "entities": []}, {"text": "In summary, we attempt to extract the greatest possible number of syntactically motivated rules while not allowing them to violate explicit constituent boundaries on either the source or target side.", "labels": [], "entities": []}, {"text": "This is achieved by allowing creation of virtual nodes, by allowing multiple decompositions of the same tree pair, and by allowing extraction of SCFG rules beyond the minimial set required to regenerate the tree pair.", "labels": [], "entities": []}, {"text": "After describing our extraction method and comparing it to a number of existing SCFG extraction techniques, we present a series of experiments examining the number of rules that maybe produced from an input corpus.", "labels": [], "entities": [{"text": "SCFG extraction", "start_pos": 80, "end_pos": 95, "type": "TASK", "confidence": 0.8453721702098846}]}, {"text": "We also describe experiments on Chinese-to-English translation that suggest that filtering a very large extracted grammar to a more moderate-sized translation model is an important consideration for obtaining strong results.", "labels": [], "entities": [{"text": "Chinese-to-English translation", "start_pos": 32, "end_pos": 62, "type": "TASK", "confidence": 0.6797752529382706}]}, {"text": "Finally, this paper concludes with some suggestions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted experiments with our rule extractor on the FBIS corpus, made up of approximately 302,000 Chinese-English sentence pairs.", "labels": [], "entities": [{"text": "FBIS corpus", "start_pos": 56, "end_pos": 67, "type": "DATASET", "confidence": 0.9703251123428345}]}, {"text": "We parsed the corpus with the Chinese and English grammars of the Berkeley parser ( and word-aligned it with GIZA++ (.", "labels": [], "entities": []}, {"text": "The parsed and word-aligned FBIS corpus served as the input to our rule extractor, which we ran with a number of different settings.", "labels": [], "entities": [{"text": "FBIS corpus", "start_pos": 28, "end_pos": 39, "type": "DATASET", "confidence": 0.7877835333347321}, {"text": "rule extractor", "start_pos": 67, "end_pos": 81, "type": "TASK", "confidence": 0.7823218703269958}]}, {"text": "First, we acquired a baseline rule extraction (\"xfer-orig\") from our corpus using an implementation of the basic Stat-XFER rule learner (, which decomposes each input tree pair into a single set of minimal SCFG rules 2 using only original nodes in the parse trees.", "labels": [], "entities": []}, {"text": "Next, we tested the effect of allowing multiple decompositions by running our own rule learner, but restricting its rules to also only make use of original nodes (\"compatible\").", "labels": [], "entities": []}, {"text": "Finally, we investigated the total number of extractable rules by allowing the creation of virtual nodes from up to four adjacent sibling nodes and placing two different limits on the length of the right-hand side (\"full-short\" and \"full-long\").", "labels": [], "entities": []}, {"text": "These configurations are summarized in.: Rule sets considered by a Stat-XFER baseline (\"xfer-orig\") and our own rule extractor.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Rule sets considered by a Stat-XFER baseline  (\"xfer-orig\") and our own rule extractor.", "labels": [], "entities": []}, {"text": " Table 3: The number of extracted rule instances (tokens) and unique rules (types) produced by the Stat-XFER system  (\"xfer-orig\") and three configurations of our rule extractor.", "labels": [], "entities": []}, {"text": " Table 4: Automatic metric results using different rule  sets, as well as different grammar filtering methods.", "labels": [], "entities": []}]}