{"title": [{"text": "Features for Phrase-Structure Reranking from Dependency Parses", "labels": [], "entities": [{"text": "Phrase-Structure Reranking from Dependency Parses", "start_pos": 13, "end_pos": 62, "type": "TASK", "confidence": 0.7700003981590271}]}], "abstractContent": [{"text": "Radically different approaches have been proved to be effective for phrase-structure and dependency parsers in the last decade.", "labels": [], "entities": [{"text": "dependency parsers", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.6844766438007355}]}, {"text": "Here, we aim to exploit the divergence in these approaches and show the utility of features extracted from the automatic dependency parses of sentences fora discrimi-native phrase-structure parser.", "labels": [], "entities": []}, {"text": "Our experiments show a significant improvement over the state-of-the-art German discriminative constituent parser.", "labels": [], "entities": []}], "introductionContent": [{"text": "Both phrase-structure and dependency parsers have developed a lot in the last decade.", "labels": [], "entities": [{"text": "dependency parsers", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7543266713619232}]}, {"text": "Different approaches have been proved to be effective for these two parsing tasks which has implicated a divergence between techniques used (and a growing gap between researcher communities).", "labels": [], "entities": [{"text": "parsing tasks", "start_pos": 68, "end_pos": 81, "type": "TASK", "confidence": 0.9252256751060486}]}, {"text": "In this work, we exploit this divergence and show the added value of features extracted from automatic dependency parses of sentences fora discriminative phrase-structure parser.", "labels": [], "entities": []}, {"text": "We report results on German phrase-structure parsing, however, we note that the reverse direction of our approach -i.e. defining features from automatic phrase-structure parses for discriminative dependency parsers -is also manifest which we will address as future work.", "labels": [], "entities": [{"text": "German phrase-structure parsing", "start_pos": 21, "end_pos": 52, "type": "TASK", "confidence": 0.5559359788894653}, {"text": "phrase-structure parses for discriminative dependency parsers", "start_pos": 153, "end_pos": 214, "type": "TASK", "confidence": 0.66938945154349}]}, {"text": "Some generative parsing approaches exploited the difference between phrase-structure and dependency parsers.", "labels": [], "entities": [{"text": "generative parsing", "start_pos": 5, "end_pos": 23, "type": "TASK", "confidence": 0.9588809013366699}]}, {"text": "For instance, introduced an approach where the objective function is the product of the probabilities of a generative phrase-structure and a dependency parsers. is based on the dependencies between pairs of head words.", "labels": [], "entities": []}, {"text": "On the other hand, the related work on this topic for discriminative parsing is sparse, we are only aware of the following works. and introduced frameworks for joint learning of phrase-structure and dependency parsers and showed improvements on both tasks for English.", "labels": [], "entities": [{"text": "discriminative parsing", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.6749170422554016}, {"text": "dependency parsers", "start_pos": 199, "end_pos": 217, "type": "TASK", "confidence": 0.7257536053657532}]}, {"text": "These frameworks require special formulation of -one or both -parsing approaches while our simple approach allows the usage of arbitrary dependency parsers and any feature-based phrase-structure parser.", "labels": [], "entities": []}, {"text": "used automatic dependency parses for pruning the chart of a phrase-structure parser and reported a significant improvement.", "labels": [], "entities": []}, {"text": "One of our feature templates can be regarded as the generalization of this approach.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our approach on the Tiger corpora of the Parsing German Shared Task (PaGe).", "labels": [], "entities": [{"text": "Parsing German Shared Task (PaGe)", "start_pos": 53, "end_pos": 86, "type": "TASK", "confidence": 0.46208615813936504}]}, {"text": "Its training, development, and test datasets consist of 20894, 2611 and 2611 sentences respectively.", "labels": [], "entities": []}, {"text": "We decided to use these corpora to be able to compare our results with other results.", "labels": [], "entities": []}, {"text": "We used the dependency parser of Bohnet (2010) to generate the parses for the feature extraction.", "labels": [], "entities": [{"text": "feature extraction", "start_pos": 78, "end_pos": 96, "type": "TASK", "confidence": 0.7059868574142456}]}, {"text": "We selected the parser since it had top scores for German in the CoNLL Shared Task 2009.", "labels": [], "entities": [{"text": "CoNLL Shared Task 2009", "start_pos": 65, "end_pos": 87, "type": "DATASET", "confidence": 0.8773251324892044}]}, {"text": "The parser is a second order dependency parser that models the interaction between siblings as well as grandchildren.", "labels": [], "entities": []}, {"text": "The parser was after the Shared Task enhanced by a Hash Kernel, which leads to significantly higher accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.997276246547699}]}, {"text": "We generated the dependency structures by 10-fold cross-validation training of the training corpus.", "labels": [], "entities": []}, {"text": "The model for the annotation of the test set and development set was trained on the entire training corpus.", "labels": [], "entities": []}, {"text": "We evaluated the dependency parses themselves inline with PaGe.", "labels": [], "entities": [{"text": "PaGe", "start_pos": 58, "end_pos": 62, "type": "DATASET", "confidence": 0.872848391532898}]}, {"text": "shows the labeled (LAS) and unlabeled attachment scores (UAS) of the dependency parser and compares it with the Malt parser (, which was the only and therefore best dependency parser that participated in the PaGe's dependency parsing track.", "labels": [], "entities": [{"text": "LAS) and unlabeled attachment scores (UAS)", "start_pos": 19, "end_pos": 61, "type": "METRIC", "confidence": 0.7806688215997484}, {"text": "dependency parsing", "start_pos": 215, "end_pos": 233, "type": "TASK", "confidence": 0.6862195432186127}]}, {"text": "Bohnet's parser reaches higher labeled and unlabeled scores.", "labels": [], "entities": []}, {"text": "The last row shows the parsing accuracy with predicted Part-ofSpeech.", "labels": [], "entities": [{"text": "parsing", "start_pos": 23, "end_pos": 30, "type": "TASK", "confidence": 0.9631073474884033}, {"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9353431463241577}]}, {"text": "We used the parses with predicted pos tags for our reranking experiments.", "labels": [], "entities": []}, {"text": "Regarding the phrase-structure parser, our grammar extractor used markovization threshold 1 = 20 and threshold 2 = 10 resulting in a grammar with over fifty thousand of rules.", "labels": [], "entities": []}, {"text": "Our prior experiments found the forest pruning threshold to be optimal at the order of 10 \u22122 which resulted in packed forests with average node number of 108.", "labels": [], "entities": []}, {"text": "The oracle scores were 87.1 and 91.4 for the 100-best lists and packed forests, respectively.", "labels": [], "entities": []}, {"text": "At the second stage, we filtered out rare features (which occurred in less than 5 sentences).", "labels": [], "entities": []}, {"text": "The new dependency parse-based feature set consists of 9240 and 5359 features before and after filtering.", "labels": [], "entities": [{"text": "dependency parse-based", "start_pos": 8, "end_pos": 30, "type": "TASK", "confidence": 0.7491607069969177}]}, {"text": "We employed the ranking MaxEnt implementation of the MALLET package) and the average perceptron training of the Joshua package ().", "labels": [], "entities": [{"text": "MALLET package", "start_pos": 53, "end_pos": 67, "type": "DATASET", "confidence": 0.7848496437072754}]}, {"text": "The update mechanism of the latter one was extended by using the F-score of the candidate full parse against the oracle parse as a loss function (see MIRA) for the motivation).", "labels": [], "entities": [{"text": "F-score", "start_pos": 65, "end_pos": 72, "type": "METRIC", "confidence": 0.9971479773521423}, {"text": "MIRA", "start_pos": 150, "end_pos": 154, "type": "METRIC", "confidence": 0.9372981190681458}]}, {"text": "We used the state-of-the-art feature set of the German phrase-structure parse reranker of Versley and Rehbein (2009) as a baseline feature set.", "labels": [], "entities": [{"text": "phrase-structure parse reranker of Versley and Rehbein (2009)", "start_pos": 55, "end_pos": 116, "type": "TASK", "confidence": 0.6042273253202438}]}, {"text": "This feature set is rich and consists of features constructed from the lexicalized parse tree and its typed dependencies along with features based on external statistical information (like the clustering of unknown words according to their context of occurrences and PP attachment statistics gathered from the automatic POS tagged DE-WaC corpus, a 1.7G words sample of the German-language WWW).", "labels": [], "entities": [{"text": "POS tagged DE-WaC corpus", "start_pos": 320, "end_pos": 344, "type": "DATASET", "confidence": 0.5225242301821709}]}, {"text": "This feature set consists of 1.7 and 0.2 million of features before and after filtering and enables the direct comparison of our results with state-of-theart discriminative results on German.", "labels": [], "entities": []}, {"text": "We use the evalb implementation of PARSEVAL as evaluation metric hereafter on basic constituent labels (noGF) and on the conflation of these labels and grammatical functions (GF).", "labels": [], "entities": []}, {"text": "We have to mention that our F-values are not comparable to the official results of PaGe -which was our original goal -because the evaluation metric there was a special im- plementation for calculating F-value (which differs from evalb for example in handling punctuation marks) and it used gold-standard POS tags in the input (which we thought to be unrealistic).", "labels": [], "entities": [{"text": "F-values", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9554239511489868}, {"text": "PaGe", "start_pos": 83, "end_pos": 87, "type": "DATASET", "confidence": 0.7979610562324524}, {"text": "F-value", "start_pos": 201, "end_pos": 208, "type": "METRIC", "confidence": 0.9359517693519592}]}, {"text": "On the other hand, our results are comparable with results of and.", "labels": [], "entities": []}, {"text": "shows the results achieved by the MaxEnt 100-best list reranker using one out of the three feature templates alone and their union (All) on the development set.", "labels": [], "entities": [{"text": "MaxEnt 100-best list reranker", "start_pos": 34, "end_pos": 63, "type": "DATASET", "confidence": 0.8417787700891495}]}, {"text": "All+Case refers to the enriched feature set incorporating case information for POS tag and grammatical functions for labels.", "labels": [], "entities": []}, {"text": "Baseline here refers to the top parse of Bitpar (the first stage parser).", "labels": [], "entities": []}, {"text": "We note that the inside probability estimation of Bitpar for an edge is always in our feature set.", "labels": [], "entities": []}, {"text": "Each of the three feature templates achieved significant improvements over a strong baselinenote that our first-stage parser is competitive with's two-stage parser -.", "labels": [], "entities": []}, {"text": "On the other hand, as the All results are just slightly better than POSRel (the best individual feature template), the three templates seem to capture similar patterns.", "labels": [], "entities": [{"text": "All", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.9712100028991699}]}, {"text": "The introduction of case information also improved the results, thus we incorporate them into our final feature set.", "labels": [], "entities": []}, {"text": "illustrates the added value of the dependency features (Dep=All+Case) over the reranking feature set of Versley and Rehbein (2009) (RR).", "labels": [], "entities": [{"text": "Dep=All+Case)", "start_pos": 56, "end_pos": 69, "type": "METRIC", "confidence": 0.7892019848028818}]}, {"text": "We also cite here previously published results on the same dataset by (a generative parser) and (a conditional random field-based discriminative parser).", "labels": [], "entities": []}, {"text": "The rows RR, Dep and RR+Dep show the results achieved by the MaxEnt 100-best list parser while the AvgPer row show the results of the forest-based average perceptron approach using the RR+Dep feature set.", "labels": [], "entities": []}, {"text": "We report numbers only at this feature configuration due to the lack of space and because the difference between this and n-best list approaches is similarly moderate at other configurations as well.", "labels": [], "entities": []}, {"text": "The results of show that our simple features constructed from the automatic dependency parse of the sentence are as useful as the stateof-the-art rich feature set for German.", "labels": [], "entities": []}, {"text": "Moreover these two features sets have a certain level of diversity as their union could achieve significantly better results than any of them alone.", "labels": [], "entities": []}, {"text": "This is probably due to fact that most of the RR features are lexicalized while Dep features are unlexicalized.", "labels": [], "entities": []}, {"text": "Regarding the two discriminative approaches, our findings are similar to, i.e. the packed forest-based and n-best list procedures achieved similar results by using only local features.", "labels": [], "entities": []}, {"text": "We found that the improvements by applying the dependency features are similar at the two evaluation metrics (with and without grammatical functions).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Dependency parser accuracy. 1 Gold Part-of- Speech tags; 2 Predicted Part-of-Speech tags.", "labels": [], "entities": [{"text": "Dependency parser", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7870491445064545}, {"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9804062843322754}]}, {"text": " Table 2: Results achieved by dependency feature-based  reranking.  noGF  GF  Baseline  78.48 66.34  outArc  79.19 67.21  POSRel  79.99 68.13  ConstRel 79.67 67.72  All  80.20 68.32  All+Case 80.35 68.48", "labels": [], "entities": [{"text": "noGF  GF  Baseline  78.48 66.34  outArc  79.19 67.21  POSRel  79.99 68.13  ConstRel 79.67 67.72  All  80.20 68.32  All+Case 80.35 68.48", "start_pos": 68, "end_pos": 203, "type": "DATASET", "confidence": 0.8373149362477389}]}, {"text": " Table 3: Results achieved by the enriched feature set.  Develop.  Test  noGF  GF  noGF  GF  Rafferty'08 77.40  - - - Versley'09  78.43 67.90  - - Baseline  78.48 66.29 79.21 66.63  RR  80.51 68.55 80.95 68.67  Dep  80.35 68.48 80.56 68.39  RR+Dep  81.34 69.73 81.49 69.44  AvgPer  81.41 69.67 81.68 69.42", "labels": [], "entities": [{"text": "Rafferty'08 77.40  - - - Versley'09  78.43 67.90  - - Baseline  78.48 66.29 79.21 66.63  RR  80.51 68.55 80.95 68.67  Dep  80.35 68.48 80.56 68.39  RR+Dep  81.34 69.73 81.49 69.44  AvgPer  81.41 69.67 81.68 69.42", "start_pos": 93, "end_pos": 305, "type": "DATASET", "confidence": 0.8182955303707639}]}]}