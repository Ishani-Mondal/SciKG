{"title": [], "abstractContent": [{"text": "This paper addresses context matching in tex-tual inference.", "labels": [], "entities": [{"text": "context matching", "start_pos": 21, "end_pos": 37, "type": "TASK", "confidence": 0.7387111335992813}]}, {"text": "We formulate the task under the Contextual Preferences framework which broadly captures contextual aspects of inference.", "labels": [], "entities": []}, {"text": "We propose a generic classification-based scheme under this framework which coherently attends to context matching in inference and maybe employed in any inference-based task.", "labels": [], "entities": [{"text": "context matching", "start_pos": 98, "end_pos": 114, "type": "TASK", "confidence": 0.7066643983125687}]}, {"text": "As a test bed for our scheme we use the Name-based Text Categorization (TC) task.", "labels": [], "entities": [{"text": "Name-based Text Categorization (TC) task", "start_pos": 40, "end_pos": 80, "type": "TASK", "confidence": 0.7248456137520927}]}, {"text": "We define an integration of Contextual Preferences into the TC setting and present a concrete self-supervised model which instantiates the generic scheme and is applied to address context matching in the TC task.", "labels": [], "entities": [{"text": "TC task", "start_pos": 204, "end_pos": 211, "type": "TASK", "confidence": 0.8619333505630493}]}, {"text": "Experiments on standard TC datasets show that our approach outperforms the state of the art in context mod-eling for Name-based TC.", "labels": [], "entities": [{"text": "TC datasets", "start_pos": 24, "end_pos": 35, "type": "DATASET", "confidence": 0.8477572202682495}]}], "introductionContent": [{"text": "Textual inference is prevalent in text understanding applications.", "labels": [], "entities": [{"text": "Textual inference", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8524397909641266}, {"text": "text understanding", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.8399316072463989}]}, {"text": "For example, in Question Answering (QA) the expected answer should be inferred from retrieved passages, and in Information Extraction (IE) the meaning of the target event is inferred from its mention in the text.", "labels": [], "entities": [{"text": "Question Answering (QA)", "start_pos": 16, "end_pos": 39, "type": "TASK", "confidence": 0.8624743342399597}, {"text": "Information Extraction (IE)", "start_pos": 111, "end_pos": 138, "type": "TASK", "confidence": 0.8131946802139283}]}, {"text": "Lexical inferences make a substantial part of the inference process.", "labels": [], "entities": []}, {"text": "In such cases, a target term is inferred from text expressions based on either one of two types of lexical matches: (i) a direct match of the target term in the text.", "labels": [], "entities": []}, {"text": "For instance, the IE event injure maybe detected by finding the word injure in the text; (ii) an indirect match, through a term that implies the meaning of the target term, e.g. inferring injure from hurt.", "labels": [], "entities": [{"text": "IE event injure", "start_pos": 18, "end_pos": 33, "type": "TASK", "confidence": 0.869498074054718}]}, {"text": "In either case, due to word ambiguity, it is necessary to validate that the context of the match conforms with the intended meaning of the target term before carrying out an inference operation based on this match.", "labels": [], "entities": []}, {"text": "For example, \"You hurt my feelings\" constitutes an invalid context for the injure event as hurt in this text does not refer to a physical injury.", "labels": [], "entities": []}, {"text": "Similarly, inferring the protest-related event demonstrate based on demo is deemed invalid although demo implies the meaning of the word demonstrate in other contexts, e.g., concerning software demonstration.", "labels": [], "entities": []}, {"text": "Although seemingly equivalent, a closer look reveals that the above two examples correspond to two distinct contextual mismatch situations.", "labels": [], "entities": []}, {"text": "While the match of hurt is invalid for injure in the particular given context, an inference based on demo is invalid for the protest demonstrate event in any context.", "labels": [], "entities": []}, {"text": "Thus, several types of context matching are involved in textual inference.", "labels": [], "entities": [{"text": "context matching", "start_pos": 23, "end_pos": 39, "type": "TASK", "confidence": 0.7337883114814758}, {"text": "textual inference", "start_pos": 56, "end_pos": 73, "type": "TASK", "confidence": 0.7221680730581284}]}, {"text": "While most prior work addressed only specific context matching scenarios, presented a broader view, proposing a generic framework for context matching in inference, termed Contextual Preferences (CP).", "labels": [], "entities": [{"text": "context matching", "start_pos": 134, "end_pos": 150, "type": "TASK", "confidence": 0.7072250545024872}]}, {"text": "CP specifies the types of context matching that need to be considered in inference, allowing a model of choice to be applied for validating each type of match.", "labels": [], "entities": []}, {"text": "Szpektor et al. applied CP to an IE task using different models to validate each type of context match.", "labels": [], "entities": [{"text": "IE task", "start_pos": 33, "end_pos": 40, "type": "TASK", "confidence": 0.9324051439762115}]}, {"text": "In this work we adopt CP as our context matching framework and propose a novel classification-based scheme which provides unified modeling for CP.", "labels": [], "entities": [{"text": "context matching", "start_pos": 32, "end_pos": 48, "type": "TASK", "confidence": 0.7043269872665405}]}, {"text": "We represent typical contexts of the textual objects that participate in inference using classifiers; at inference time, each match is assessed by the respective classifiers which determine its contextual validity.", "labels": [], "entities": []}, {"text": "As a test bed we applied our scheme to the task of Name-based Text Categorization.", "labels": [], "entities": [{"text": "Name-based Text Categorization", "start_pos": 51, "end_pos": 81, "type": "TASK", "confidence": 0.7484861016273499}]}, {"text": "This is an unsupervised setting of TC where the only input given is the category name, and in which context validation is of high importance.", "labels": [], "entities": [{"text": "TC", "start_pos": 35, "end_pos": 37, "type": "TASK", "confidence": 0.9282342791557312}]}, {"text": "We instantiate the scheme with a novel self-supervised model and apply it to the TC task.", "labels": [], "entities": [{"text": "TC task", "start_pos": 81, "end_pos": 88, "type": "TASK", "confidence": 0.8793880045413971}]}, {"text": "We suggest a method for integrating any CP-based context matching model into TC and use it to combine the context matching scores generated by our model.", "labels": [], "entities": [{"text": "CP-based context matching", "start_pos": 40, "end_pos": 65, "type": "TASK", "confidence": 0.6320415437221527}]}, {"text": "Results on two standard TC datasets show that our approach outperforms the state of the art context model for this task and suggest applying this scheme to additional inference-based applications.", "labels": [], "entities": [{"text": "TC datasets", "start_pos": 24, "end_pos": 35, "type": "DATASET", "confidence": 0.7456968128681183}]}], "datasetContent": [{"text": "Following ( and ( , we evaluated our method on two standard TC datasets: Reuters-10 and 20-Newsgroups.", "labels": [], "entities": [{"text": "TC datasets", "start_pos": 60, "end_pos": 71, "type": "DATASET", "confidence": 0.8062678873538971}, {"text": "Reuters-10", "start_pos": 73, "end_pos": 83, "type": "DATASET", "confidence": 0.8833231329917908}]}, {"text": "The Reuters-10 (R10, for short) is a sub-corpus of the Reuters-21578 collection 3 , constructed from the ten most frequent categories in the Reuters taxonomy.", "labels": [], "entities": [{"text": "Reuters-10 (R10", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.8947891195615133}, {"text": "Reuters-21578 collection 3", "start_pos": 55, "end_pos": 81, "type": "DATASET", "confidence": 0.9188823302586874}]}, {"text": "We used the Apte split of the Reuters-21578 collection, often used in TC tasks.", "labels": [], "entities": [{"text": "Apte split of the Reuters-21578 collection", "start_pos": 12, "end_pos": 54, "type": "DATASET", "confidence": 0.870441347360611}, {"text": "TC tasks", "start_pos": 70, "end_pos": 78, "type": "TASK", "confidence": 0.9220339059829712}]}, {"text": "The top 10 categories include about 9,000 documents, split into training (70%) and test (30%) sets.", "labels": [], "entities": []}, {"text": "The 20-Newsgroups (20NG) corpus is a collection of newsgroup postings gathered from twenty different categories from the Usenet Newsgroups hierarchy . We used the \"bydate\" version of the corpus, which contains approximately 20,000 documents partitioned (nearly) evenly across the categories and divided in advance to training (60%) and test (40%) sets.", "labels": [], "entities": [{"text": "Usenet Newsgroups hierarchy", "start_pos": 121, "end_pos": 148, "type": "DATASET", "confidence": 0.7920467654863993}]}, {"text": "As in (), we adjusted non-standard category names (e.g. forsale was renamed to sale) and manually specified for each category its relevant WordNet senses.", "labels": [], "entities": []}, {"text": "The sense tagging properly defines the categories, and is expected to accompany such hypotheses.", "labels": [], "entities": [{"text": "sense tagging", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.7140471488237381}]}, {"text": "Other types of information maybe used for this purpose, e.g. words from category descriptions, if such exist.", "labels": [], "entities": []}, {"text": "We applied standard preprocessing (sentence splitting, tokenization, lemmatization and part of speech tagging) to all documents in the datasets.", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.7431218475103378}, {"text": "part of speech tagging", "start_pos": 87, "end_pos": 109, "type": "TASK", "confidence": 0.6468424275517464}]}, {"text": "All terms, including those denoting category names and rules, are represented by their lemma and part of speech.", "labels": [], "entities": []}, {"text": "As sources for lexical entailment rules we used WordNet 3.0 (synonyms, hyponyms, derivations and meronyms) and a Wikipedia-derived rule-base ( ).", "labels": [], "entities": []}, {"text": "Unlike Barak09 we did not limit the rules extracted from WordNet to the most frequent senses and used all rule types from the Wikipedia-based resource.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.9601784944534302}]}], "tableCaptions": [{"text": " Table 2: Ablation tests results.", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9861889481544495}]}]}