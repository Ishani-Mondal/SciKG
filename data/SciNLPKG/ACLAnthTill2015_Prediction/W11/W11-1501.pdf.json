{"title": [{"text": "Extending the tool, or how to annotate historical language varieties", "labels": [], "entities": [{"text": "Extending", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9734154343605042}]}], "abstractContent": [{"text": "We present a general and simple method to adapt an existing NLP tool in order to enable it to deal with historical varieties of languages.", "labels": [], "entities": []}, {"text": "This approach consists basically in expanding the dictionary with the old word variants and in retraining the tagger with a small training corpus.", "labels": [], "entities": []}, {"text": "We implement this approach for Old Spanish.", "labels": [], "entities": []}, {"text": "The results of a thorough evaluation over the extended tool show that using this method an almost state-of-the-art performance is obtained , adequate to carryout quantitative studies in the humanities: 94.5% accuracy for the main part of speech and 92.6% for lemma.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 208, "end_pos": 216, "type": "METRIC", "confidence": 0.9990278482437134}]}, {"text": "To our knowledge, this is the first time that such a strategy is adopted to annotate historical language varieties and we believe that it could be used as well to deal with other non-standard varieties of languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the last few years, there has been a growing interest in all disciplines of the humanities to study historical varieties of languages using quantitative methods (.", "labels": [], "entities": []}, {"text": "Large corpora are necessary to conduct this type of studies, so as to smooth the great data sparseness problem affecting non-standard varieties of languages, and thus guarantee the validity of the generalizations based on these data.", "labels": [], "entities": []}, {"text": "Historical language varieties bear similarities to standard varieties, but they also exhibit remarkable differences in a number of respects, such as their morphology, syntax, and semantics.", "labels": [], "entities": []}, {"text": "In addition, as orthographic rules were not established until later centuries, a great amount of graphemic variation is found in historical texts, such that one word can be written using many different graphemic variants.", "labels": [], "entities": []}, {"text": "This variation increases considerably the number of different words and therefore the lexicon of the corresponding language variety.", "labels": [], "entities": []}, {"text": "For instance, searching for the infinitival verb form haber 'have' in a historical corpus for Spanish can be a difficult task if there are, say, 5 variants of the same word (auer, aver, hauer, haver, haber) and the corpus does not contain any other linguistic information, such as lemma and part of speech.", "labels": [], "entities": []}, {"text": "In this paper we propose a strategy to automatically enrich texts from historical language varieties with linguistic information, namely to expand a preexisting NLP tool for standard varieties of a language.", "labels": [], "entities": []}, {"text": "To our knowledge, it is the first time that such an approach is proposed and evaluated.", "labels": [], "entities": []}, {"text": "In particular, we describe the method followed to extend a library (FreeLing 1 ) for the linguistic analysis of Standard Spanish to enable it to deal with Old Spanish 2 . This general approach has four main advantages over the state-of-the-art strategies (described in section 2).", "labels": [], "entities": []}, {"text": "First, the resulting tool can be reused (with the consequent saving of resources).", "labels": [], "entities": []}, {"text": "Second, the tool can be further improved by other researchers.", "labels": [], "entities": []}, {"text": "Third, it is the tool that is adapted, instead of forc-ing standardisation on the original texts (see section 2).", "labels": [], "entities": []}, {"text": "Also, the strategy can be used to extend other existing tools.", "labels": [], "entities": []}, {"text": "The specific case study in this paper presents additional advantages.", "labels": [], "entities": []}, {"text": "On the one hand, FreeLing is an open source resource that is well documented and actively maintained.", "labels": [], "entities": [{"text": "FreeLing", "start_pos": 17, "end_pos": 25, "type": "DATASET", "confidence": 0.9198397994041443}]}, {"text": "In addition, due to the modularity of this tool, it is relatively easy to adapt.", "labels": [], "entities": []}, {"text": "On the other hand, the result of the extension is a tool for Old Spanish across different centuries, that is to say, the tool can be used to accurately tag not only Spanish from a particular century but also to tag the language over along period of time (from the 12th to the 16th century).", "labels": [], "entities": []}, {"text": "The resulting tool achieves almost state-of-the-art performance for PoS-taggers: a tagging accuracy of 94.5% on the part of speech, 92.6% on lemmas, and 89.9% on the complete morphological tag including detailed information such as gender or number for nouns and tense and person for verbs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9906235337257385}]}, {"text": "In Section 2 we review the state of the art.", "labels": [], "entities": []}, {"text": "In Sections 3 through 5 we describe FreeLing and the data and methodology used for its adaptation to Old Spanish.", "labels": [], "entities": []}, {"text": "Then the results of the evaluation and error analysis are presented (Sections 6 and 7).", "labels": [], "entities": [{"text": "error analysis", "start_pos": 39, "end_pos": 53, "type": "METRIC", "confidence": 0.9483413100242615}]}, {"text": "We conclude with some discussion and suggestions for future work (Section 8).", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we evaluate the dictionary (Section 6.1) and present the overall tagging results (Section 6.2).", "labels": [], "entities": []}, {"text": "The resources for Standard Spanish have been used as a baseline.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Size of the Old Spanish and the Gold Standard Corpus, respectively, in tokens (percentages over the Total  column).", "labels": [], "entities": [{"text": "Gold Standard Corpus", "start_pos": 42, "end_pos": 62, "type": "DATASET", "confidence": 0.9351007342338562}]}, {"text": " Table 2: Text type distribution in the Old Spanish and the Gold Standard Corpus, respectively, in tokens (percentages  over the Total column).", "labels": [], "entities": [{"text": "Gold Standard Corpus", "start_pos": 60, "end_pos": 80, "type": "DATASET", "confidence": 0.9303938349088033}]}, {"text": " Table 3: Distribution of words added to the dictionary.", "labels": [], "entities": []}, {"text": " Table 5: Evaluation of the dictionary.", "labels": [], "entities": []}, {"text": " Table 6: Accuracy obtained for lemma, PoS-1, and PoS-2  in the 5-fold cross-validation for the Old Spanish tagger  on the Gold Standard Corpus (rows C0 to C4) and for  Standard Spanish (row SS).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9982105493545532}, {"text": "PoS-1", "start_pos": 39, "end_pos": 44, "type": "METRIC", "confidence": 0.8801026940345764}, {"text": "Gold Standard Corpus", "start_pos": 123, "end_pos": 143, "type": "DATASET", "confidence": 0.9633786280949911}]}]}