{"title": [{"text": "The Value of Monolingual Crowdsourcing in a Real-World Translation Scenario: Simulation using Haitian Creole Emergency SMS Messages", "labels": [], "entities": [{"text": "Simulation", "start_pos": 77, "end_pos": 87, "type": "TASK", "confidence": 0.9556556940078735}]}], "abstractContent": [{"text": "MonoTrans2 is a translation system that combines machine translation (MT) with human computation using two crowds of monolin-gual source (Haitian Creole) and target (En-glish) speakers.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.8075126767158508}]}, {"text": "We report on its use in the WMT 2011 Haitian Creole to English translation task, showing that MonoTrans2 translated 38% of the sentences well compared to Google Translate's 25%.", "labels": [], "entities": [{"text": "WMT 2011 Haitian Creole to English translation task", "start_pos": 28, "end_pos": 79, "type": "TASK", "confidence": 0.6675442494452}]}], "introductionContent": [{"text": "One of the most remarkable success stories to come out of the January 2010 earthquake in Haiti involved translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 104, "end_pos": 115, "type": "TASK", "confidence": 0.9774532318115234}]}, {"text": "While other forms of emergency response and communication channels were failing, text messages were still getting through, so a number of people came together to create a freephone number for emergency text messages, which allowed earthquake victims to report those who were trapped or in need of medical attention.", "labels": [], "entities": []}, {"text": "The problem, of course, was that most people were texting in Haitian Creole (Kreyol), a language not many of the emergency responders understood, and few, if any, professional translators were available.", "labels": [], "entities": [{"text": "texting in Haitian Creole (Kreyol)", "start_pos": 50, "end_pos": 84, "type": "TASK", "confidence": 0.703616167817797}]}, {"text": "The availability of usable translations literally became a matter of life and death.", "labels": [], "entities": []}, {"text": "In response to this need, Stanford University graduate student Rob Munro coordinated the rapid creation of a crowdsourcing framework, which allowed volunteers -including, for example, Haitian expatriates and French speakers -to translate messages, providing responders with usable information in as little as ten minutes.", "labels": [], "entities": []}, {"text": "Translations may not have been perfect, but to a woman in labor, it had to have made a big difference for English-speaking responders to see Undergoing children delivery Delmas 31 instead of Fanm gen tranche pou f` e yon pitit nan Delmas 31.", "labels": [], "entities": []}, {"text": "What about a scenario, though, in which even amateur bilingual volunteers are hard to find, or too few in number?", "labels": [], "entities": []}, {"text": "What about a scenario, e.g. the March 2011 earthquake and tsunami in Japan, in which there are many people worldwide who wish to help but are not fluent in both the source and target languages?", "labels": [], "entities": []}, {"text": "For the last few years, we have been exploring the idea of monolingual crowdsourcing for translation -that is, technology-assisted collaborative translation involving crowds of participants who know only the source or target language.", "labels": [], "entities": [{"text": "translation", "start_pos": 89, "end_pos": 100, "type": "TASK", "confidence": 0.9625440239906311}]}, {"text": "Our MonoTrans2 framework has previously shown very promising results on children's books: on a test set where Google Translate produced correct translations for only 10% of the input sentences, monolingual German and Spanish speakers using our framework produced translations that were fully correct (as judged by two independent bilinguals) nearly 70% of the time (.", "labels": [], "entities": []}, {"text": "We used the same framework in the WMT 2011 Haitian-English translation task.", "labels": [], "entities": [{"text": "WMT 2011 Haitian-English translation task", "start_pos": 34, "end_pos": 75, "type": "TASK", "confidence": 0.7084710657596588}]}, {"text": "For this experiment, we hired Haitian Creole speakers located in Haiti, and recruited English speakers located in the U.S., to serve as the monolingual crowds.", "labels": [], "entities": []}], "datasetContent": [{"text": "We recruited 26 English speakers and 4 Haitian Creole speakers.", "labels": [], "entities": []}, {"text": "The Haitian Creole speakers were recruited from Haiti and do not speak English.", "labels": [], "entities": []}, {"text": "Five of the 26 English speakers were paid UMD undergraduates; the other 21 were volunteer researchers, graduate students, and staff unrelated to this research.", "labels": [], "entities": []}, {"text": "3 Over a 13 day period, Haitian Creole and English speaker efforts totaled 15 and 29 hours, respectively.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: SMS clean data sets before and after reshuffling", "labels": [], "entities": []}, {"text": " Table 2: Data sets for evaluation and their sizes", "labels": [], "entities": []}, {"text": " Table 3: BLEU and TER results for different levels of com- pletion on the devtest set A", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9992857575416565}, {"text": "TER", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9988956451416016}]}, {"text": " Table 4: BLEU and TER results for different levels of com- pletion on the test set B", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.999392032623291}, {"text": "TER", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9990980625152588}]}, {"text": " Table 5: Number of sentences with maximum possible  adequacy (5) in F ull \u2229 A and F ull \u2229 B, respectively.", "labels": [], "entities": []}]}