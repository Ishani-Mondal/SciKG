{"title": [{"text": "PLCFRS Parsing of English Discontinuous Constituents", "labels": [], "entities": [{"text": "PLCFRS Parsing of English Discontinuous Constituents", "start_pos": 0, "end_pos": 52, "type": "TASK", "confidence": 0.7690984308719635}]}], "abstractContent": [{"text": "This paper proposes a direct parsing of non-local dependencies in English.", "labels": [], "entities": []}, {"text": "To this end, we use probabilistic linear context-free rewriting systems for data-driven parsing, following recent work on parsing German.", "labels": [], "entities": [{"text": "parsing", "start_pos": 122, "end_pos": 129, "type": "TASK", "confidence": 0.964940071105957}]}, {"text": "In order to do so, we first perform a transformation of the Penn Treebank annotation of non-local dependencies into an annotation using crossing branches.", "labels": [], "entities": [{"text": "Penn Treebank annotation", "start_pos": 60, "end_pos": 84, "type": "DATASET", "confidence": 0.9756025473276774}]}, {"text": "The resulting tree-bank can be used for PLCFRS-based parsing.", "labels": [], "entities": [{"text": "PLCFRS-based parsing", "start_pos": 40, "end_pos": 60, "type": "TASK", "confidence": 0.7773920297622681}]}, {"text": "Our evaluation shows that, compared to PCFG parsing with the same techniques, PLCFRS parsing yields slightly better results.", "labels": [], "entities": [{"text": "PCFG parsing", "start_pos": 39, "end_pos": 51, "type": "TASK", "confidence": 0.6384146958589554}, {"text": "PLCFRS parsing", "start_pos": 78, "end_pos": 92, "type": "TASK", "confidence": 0.7462919652462006}]}, {"text": "In particular when evaluating only the parsing results concerning long-distance dependencies , the PLCFRS approach with dis-continuous constituents is able to recognize about 88% of the dependencies of type *T* and *T*-PRN encoded in the Penn Tree-bank.", "labels": [], "entities": [{"text": "Penn Tree-bank", "start_pos": 238, "end_pos": 252, "type": "DATASET", "confidence": 0.9946793615818024}]}, {"text": "Even the evaluation results concerning local dependencies, which can in principle be captured by a PCFG-based model, are better with our PLCFRS model.", "labels": [], "entities": []}, {"text": "This demonstrates that by discarding information on non-local dependencies the PCFG model loses important information on syntactic dependencies in general.", "labels": [], "entities": []}], "introductionContent": [{"text": "Discontinuous constituents as exemplified in (1) are more frequent than generally assumed, even in languages such as English that display a rather rigid word order.", "labels": [], "entities": []}, {"text": "In (1), the NP areas of the factory where the crocidolite was used is separated into two non-adjacent parts.", "labels": [], "entities": []}, {"text": "(1) is an example from the Penn Treebank (PTB).", "labels": [], "entities": [{"text": "Penn Treebank (PTB)", "start_pos": 27, "end_pos": 46, "type": "DATASET", "confidence": 0.974368405342102}]}, {"text": "More generally, all constructions where head-argument or headmodifier dependencies are non-local, such as whmovement, can be seen as instances of discontinuous constituency.", "labels": [], "entities": []}, {"text": "Such instances appear in about 20% of the sentences in the PTB.", "labels": [], "entities": [{"text": "PTB", "start_pos": 59, "end_pos": 62, "type": "DATASET", "confidence": 0.7569082975387573}]}, {"text": "They constitute a particular challenge for parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 43, "end_pos": 50, "type": "TASK", "confidence": 0.9811301827430725}]}, {"text": "(1) Areas of the factory were particularly dusty where the crocidolite was used.", "labels": [], "entities": []}, {"text": "In the past, data-driven parsing has largely been dominated by Probabilistic Context-Free Grammar (PCFG).", "labels": [], "entities": [{"text": "data-driven parsing", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.5154737830162048}]}, {"text": "This is partly due to the annotation formats of treebanks such as the Penn Treebank (PTB), which are used as a data source for grammar extraction.", "labels": [], "entities": [{"text": "Penn Treebank (PTB)", "start_pos": 70, "end_pos": 89, "type": "DATASET", "confidence": 0.9734280228614807}, {"text": "grammar extraction", "start_pos": 127, "end_pos": 145, "type": "TASK", "confidence": 0.7285422086715698}]}, {"text": "Their annotation generally relies on the use of trees without crossing branches, augmented with a mechanism that accounts for non-local dependencies.", "labels": [], "entities": []}, {"text": "In the PTB, e.g., labeling conventions and trace nodes are used which establish additional implicit edges in the tree beyond the overt phrase structure.", "labels": [], "entities": [{"text": "PTB", "start_pos": 7, "end_pos": 10, "type": "DATASET", "confidence": 0.8141869306564331}]}, {"text": "However, given the expressivity restrictions of PCFG, work on data-driven parsing has mostly excluded non-local dependencies.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.9137911200523376}]}, {"text": "When using treebanks with PTB-like annotation, labeling conventions and trace nodes are often discarded.", "labels": [], "entities": []}, {"text": "Some work has however been done towards incorporating non-local information into data-driven parsing.", "labels": [], "entities": []}, {"text": "One general way to do this is (nonprojective) dependency parsing where parsers are not grammar-based and the notion of constituents or phrases is not employed, see e.g. or.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.7238424122333527}]}, {"text": "Within the domain of grammar-based constituent parsing, we can distinguish three approaches): 1.", "labels": [], "entities": [{"text": "grammar-based constituent parsing", "start_pos": 21, "end_pos": 54, "type": "TASK", "confidence": 0.6693009734153748}]}, {"text": "Non-local information can be reconstructed in a post-processing step after PCFG parsing; Jijkoun and de).", "labels": [], "entities": [{"text": "PCFG parsing", "start_pos": 75, "end_pos": 87, "type": "TASK", "confidence": 0.7440251410007477}]}, {"text": "2. Non-local information can be incorpo- rated into the PCFG model) or into complex labels).", "labels": [], "entities": []}, {"text": "3. A formalism can be used which accommodates the direct encoding of non-local information.", "labels": [], "entities": []}, {"text": "This paper pursues the third approach.", "labels": [], "entities": []}, {"text": "Our work is based on recent research in using Linear Context-Free Rewriting Systems (LCFRS) for data driven parsing.", "labels": [], "entities": [{"text": "data driven parsing", "start_pos": 96, "end_pos": 115, "type": "TASK", "confidence": 0.5648313363393148}]}, {"text": "LCFRSs extend CFGs such that nonterminals can span tuples of possibly non-adjacent strings (see).", "labels": [], "entities": []}, {"text": "This enables them to describe discontinuous constituents and non-projective dependencies ().", "labels": [], "entities": []}, {"text": "Furthermore, they are able to capture synchronous derivations, something that is empirically attested in treebanks (.", "labels": [], "entities": []}, {"text": "In order to parse German, a language where discontinuities are particularly frequent, ;  use probabilistic LCFRSs (PLCFRSs).", "labels": [], "entities": [{"text": "parse German", "start_pos": 12, "end_pos": 24, "type": "TASK", "confidence": 0.8568447232246399}]}, {"text": "As a data source, they use the German NEGRA and TIGER treebanks that annotate discontinuous constituents by using crossing branches.", "labels": [], "entities": [{"text": "German NEGRA", "start_pos": 31, "end_pos": 43, "type": "DATASET", "confidence": 0.7112232148647308}, {"text": "TIGER treebanks", "start_pos": 48, "end_pos": 63, "type": "DATASET", "confidence": 0.7720531523227692}]}, {"text": "We adapt this approach for German to English, using the PTB.", "labels": [], "entities": [{"text": "PTB", "start_pos": 56, "end_pos": 59, "type": "DATASET", "confidence": 0.9724975228309631}]}, {"text": "For this, we first need to transform the trace-based annotation of discontinuous constituents into an annotation with crossing branches which requires a careful treatment of the different types of traces that occur in the PTB.", "labels": [], "entities": [{"text": "PTB", "start_pos": 222, "end_pos": 225, "type": "DATASET", "confidence": 0.9243234992027283}]}, {"text": "Then we extract a PLCFRS from the resulting treebank and we use the PLCFRS parser from Kallmeyer and Maier for our parsing experiments.", "labels": [], "entities": []}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces PLCFRS and the parsing algorithm.", "labels": [], "entities": [{"text": "parsing", "start_pos": 36, "end_pos": 43, "type": "TASK", "confidence": 0.9877415895462036}]}, {"text": "The next section explains the transformation of the PTB into an annotation format where nonlocal dependencies are annotated with crossing branches.", "labels": [], "entities": [{"text": "PTB", "start_pos": 52, "end_pos": 55, "type": "DATASET", "confidence": 0.8267053365707397}]}, {"text": "Section 4 describes further transformations we apply to the resulting treebanks, in particular binarization and category splitting.", "labels": [], "entities": [{"text": "category splitting", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.761668473482132}]}, {"text": "Finally, section 5 reports the results or our parsing experiments with a detailed evaluation of the way the different types of long-distance dependencies are captured.", "labels": [], "entities": [{"text": "parsing", "start_pos": 46, "end_pos": 53, "type": "TASK", "confidence": 0.96523517370224}]}], "datasetContent": [{"text": "We use the Wall Street Journal sections 1-22 of the Penn Treebank (version 2.0) as training data and sections 23-24 as test data.", "labels": [], "entities": [{"text": "Wall Street Journal sections 1-22 of the Penn Treebank (version 2.0)", "start_pos": 11, "end_pos": 79, "type": "DATASET", "confidence": 0.9432459015112656}]}, {"text": "Due to time constraints and the complexity of PLCFRS parsing, sentences with more than 25 tokens (not counting null elements) are excluded, resulting in 25801 training sentences and 2233 test sentences.", "labels": [], "entities": [{"text": "PLCFRS parsing", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.7551822364330292}]}, {"text": "After a small number of corrections to the annotation, concerning chiefly wrong indices and missing PRN nodes, we create discontinuous versions of the training and test set by carrying out the reattachment operations described in Section 3 while also keeping context-free versions.", "labels": [], "entities": []}, {"text": "All four sets are then preprocessed by removing all (remaining) indices, null elements and empty constituents.", "labels": [], "entities": []}, {"text": "We call the resulting context-free training and test set Tr and Te, and the resulting discontinuous training and test set Tr \u2032 and Te \u2032 .  Since the structure in Te \u2032 encodes local as well as non-local dependencies, it serves as our primary gold standard.", "labels": [], "entities": []}, {"text": "Ina first step, we use the standard EVALB metric, generalized to trees with discontinuous constituents as in , to measure how much of the structure in the gold standard is captured by different parsers.", "labels": [], "entities": [{"text": "EVALB metric", "start_pos": 36, "end_pos": 48, "type": "METRIC", "confidence": 0.7466766834259033}]}, {"text": "We compare Maier and Kallmeyer's parser trained on Tr \u2032 (resulting in a 3-PLCFRS) with three parsers that do not produce discontinuous structures: the Berkeley parser () trained on Tr using our manual category splits but no automatic splitting/merging/smoothing, the Berkeley parser trained on Tr using its default setting of six iterations of split/merge/smooth, and Maier and Kallmeyer's parser with a grammar extracted from Tr (a 1-PLCFRS, i.e. a PCFG).", "labels": [], "entities": []}, {"text": "The upper half of shows the results.", "labels": [], "entities": []}, {"text": "For comparison, we also evaluated the three context-free parsers on the untransformed context-free test set Te.", "labels": [], "entities": [{"text": "context-free test set Te", "start_pos": 86, "end_pos": 110, "type": "DATASET", "confidence": 0.7466883659362793}]}, {"text": "These figures are given in the lower half of the table.", "labels": [], "entities": []}, {"text": "For Maier and Kallmeyer's parser, the number of rules in the grammar before and after binarizing is also given, as well as the number of items created during parsing as an indicator of parsing complexity.", "labels": [], "entities": []}, {"text": "Across these experiments, the most crucial factor for parsing accuracy seems to be splitting/merging/smoothing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 54, "end_pos": 61, "type": "TASK", "confidence": 0.9875143766403198}, {"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9484624862670898}, {"text": "splitting/merging/smoothing", "start_pos": 83, "end_pos": 110, "type": "TASK", "confidence": 0.7154843986034394}]}, {"text": "As the comparison between the two parsing experiments with the Berkeley parser shows, this technique is key to achieving its state-of-the-art results.", "labels": [], "entities": []}, {"text": "We plan to transfer this technique to discontinuous constituent parsing in future work.", "labels": [], "entities": [{"text": "discontinuous constituent parsing", "start_pos": 38, "end_pos": 71, "type": "TASK", "confidence": 0.651094118754069}]}, {"text": "For now, we must compare discontinuous to context-free constituent parsing on a level below the state of the art.", "labels": [], "entities": [{"text": "context-free constituent parsing", "start_pos": 42, "end_pos": 74, "type": "TASK", "confidence": 0.6287727952003479}]}, {"text": "Comparison between the two experiments with Maier and Kallmeyer's parser shows that it works with about the same accuracy when trained and tested on discontinuous data as when trained and tested on contextfree data, although parsing complexity is considerably higher in the discontinuous experiment as evidenced by the number of items produced.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.998420238494873}]}, {"text": "Note that scores would presumably be lower if sentences with more than 25 tokens were included.", "labels": [], "entities": []}, {"text": "Even when trained on the context-free data, both parsers get most of the structure in Te \u2032 right since only a relatively small fraction of constituents is discontinuous.", "labels": [], "entities": []}, {"text": "However, for those test sentences that do contain discontinuous constituents (Te \u2032 D ), context-free parsers fare much worse than for sentences that do not (Te \u2032 C ).", "labels": [], "entities": []}, {"text": "For Maier and Kallmeyer's parser trained on Tr \u2032 they seem to be only slightly harder to parse.", "labels": [], "entities": []}, {"text": "Although its scores for Te \u2032 D with discontinuous parsing are lower than for Te D with context-free parsing, the former maybe considered a better parse result than the latter since the Te \u2032 D gold standard con-   tains information on non-local dependencies while Te D does not.", "labels": [], "entities": []}, {"text": "In order to assess to what degree this is the case, we perform a dependency evaluation, first used for evaluating discontinuous constituent parser output in.", "labels": [], "entities": []}, {"text": "This method requires a conversion of constituent trees to sets of word-word dependencies.", "labels": [], "entities": []}, {"text": "We use Lin's dependency conversion method, where each phrase is represented by its lexical head.", "labels": [], "entities": [{"text": "dependency conversion", "start_pos": 13, "end_pos": 34, "type": "TASK", "confidence": 0.6603204756975174}]}, {"text": "To determine the head of each phrase, we use the head-finding algorithm of Collins (1999), ordering the children of each node by leftmost dominated terminal.", "labels": [], "entities": []}, {"text": "Under this standard dependency conversion method, the transformation described in Section 3 introduces new word-word (head-argument/headadjunct) dependencies that are relevant to semantic interpretation.", "labels": [], "entities": [{"text": "dependency conversion", "start_pos": 20, "end_pos": 41, "type": "TASK", "confidence": 0.72215935587883}, {"text": "semantic interpretation", "start_pos": 179, "end_pos": 202, "type": "TASK", "confidence": 0.7138642072677612}]}, {"text": "Word-word dependencies lost in the transformation are not normally relevant since they result from attachment of phrases outside of the domains of their heads.", "labels": [], "entities": []}, {"text": "We therefore choose Te \u2032 as the gold standard against which to evaluate both context-free and discontinuous parsing results.", "labels": [], "entities": []}, {"text": "shows that discontinuous parsing as compared to context-free parsing boosts the unlabeled attachment score (i.e. recall on word-word dependencies) slightly for local dependencies and considerably for non-local dependencies.", "labels": [], "entities": [{"text": "recall", "start_pos": 113, "end_pos": 119, "type": "METRIC", "confidence": 0.9847592711448669}]}, {"text": "The lat- Dependency evaluation also allows a direct comparison with state-of-the-art dependency parsers.", "labels": [], "entities": []}, {"text": "In we give results for MSTParser () trained on two dependency versions of Tr \u2032 , converted from constituents to dependencies once without dependency labels and once with dependency labels using the method of.", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 23, "end_pos": 32, "type": "DATASET", "confidence": 0.817944347858429}]}, {"text": "It can be seen that MSTParser recognizes a fair percentage of even the difficult *ICH* and *EXP* type dependencies (cf. Section 5.3) and that it has a considerably better overall score.", "labels": [], "entities": []}, {"text": "We expect that this gap can be bridged by optimizing Maier and Kallmeyer's parser with techniques successfully used for context-free constituent parsing as outlined above, but this remains to be proven experimentally.", "labels": [], "entities": [{"text": "context-free constituent parsing", "start_pos": 120, "end_pos": 152, "type": "TASK", "confidence": 0.6215343077977499}]}], "tableCaptions": [{"text": " Table 1: Reattachment types and gap-degrees of result- ing trees", "labels": [], "entities": []}, {"text": " Table 3: Results of a second discontinuous parsing  experiment where *ICH* and *EXP* transformations  have been omitted in the transformation", "labels": [], "entities": [{"text": "ICH", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.9102983474731445}]}, {"text": " Table 4: Unlabeled attachment scores in dependency evaluation on the dependency-converted Te \u2032", "labels": [], "entities": []}]}