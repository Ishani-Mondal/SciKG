{"title": [{"text": "Automatic linguistic annotation of historical language: ToTrTaLe and XIX century Slovene", "labels": [], "entities": [{"text": "ToTrTaLe", "start_pos": 56, "end_pos": 64, "type": "DATASET", "confidence": 0.9553372263908386}]}], "abstractContent": [{"text": "The paper describes a tool developed to process historical (Slovene) text, which annotates words in a TEI encoded corpus with their modern-day equivalents, mor-phosyntactic tags and lemmas.", "labels": [], "entities": []}, {"text": "Such a tool is useful for developing historical corpora of highly-inflecting languages, enabling full text search in digital libraries of historical texts, for modernising such texts for today's readers and making it simpler to correct OCR transcriptions.", "labels": [], "entities": [{"text": "correct OCR transcriptions", "start_pos": 228, "end_pos": 254, "type": "TASK", "confidence": 0.6790465613206228}]}], "introductionContent": [{"text": "Basic processing of written language, in particular tokenisation, tagging and lemmatisation, is useful in a number of applications, such as enabling fulltext search, corpus-linguistic studies, and adding further layers of annotation.", "labels": [], "entities": [{"text": "fulltext search", "start_pos": 149, "end_pos": 164, "type": "TASK", "confidence": 0.8181236386299133}]}, {"text": "Support for lemmatisation and morphosyntactic tagging is welladvanced for modern-day languages, however, the situation is very different for historical language varieties, where much less -if any -resources exist to train high-quality taggers and lemmatisers.", "labels": [], "entities": []}, {"text": "Historical texts also bring with them a number of challenges not present with modern language: \uf0b7 due to the low print quality, optical character recognition (OCR) produces much worse results than for modern day texts; currently, such texts must be hand-corrected to arrive at acceptable quality levels; \uf0b7 full-text search is difficult, as the texts are not lemmatised and use different orthographic conventions and archaic spellings, typically not familiar to non-specialists; \uf0b7 comprehension can also be limited, esp.", "labels": [], "entities": [{"text": "optical character recognition (OCR)", "start_pos": 127, "end_pos": 162, "type": "TASK", "confidence": 0.7038824607928594}, {"text": "full-text search", "start_pos": 305, "end_pos": 321, "type": "TASK", "confidence": 0.677936002612114}, {"text": "\uf0b7", "start_pos": 477, "end_pos": 478, "type": "METRIC", "confidence": 0.9634186029434204}, {"text": "comprehension", "start_pos": 479, "end_pos": 492, "type": "METRIC", "confidence": 0.5686748623847961}]}, {"text": "when the text uses an alphabet different from the contemporary norm.", "labels": [], "entities": []}, {"text": "This paper describes a tool to help alleviate the above problems.", "labels": [], "entities": []}, {"text": "The tool implements a pipeline, where it first tokenises the text and then attempts to transcribe the archaic words to their modern day equivalents.", "labels": [], "entities": []}, {"text": "For hereon, the text is tagged and lemmatised using the models for modern Slovene.", "labels": [], "entities": []}, {"text": "Such an approach is not new, as it straightforwardly follows from a situation where good language models are available for contemporary language, but not for its historical variants.", "labels": [], "entities": []}, {"text": "The focus of the research in such cases is on the mapping from historical words to modern ones, and such approaches have already been attempted for other languages, e.g. for English (), German (), Spanish () and Icelandic.", "labels": [], "entities": []}, {"text": "These studies have mostly concentrated on mapping historical variants to modern words or evaluating PoS tagging accuracy and have dealt with Germanic and Romance languages.", "labels": [], "entities": [{"text": "PoS tagging", "start_pos": 100, "end_pos": 111, "type": "TASK", "confidence": 0.8646222054958344}, {"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.910331666469574}]}, {"text": "This paper discusses the complete annotation process, including lemmatisation, and treats a Slavic language, which has substantially different morphology; in Slovene, words belong to complex inflectional paradigms, which makes tagging and lemmatisation models quite complex, esp.", "labels": [], "entities": []}, {"text": "The paper also discusses structural annotations supported by the tool, which takes as input a document encoded according to (a subset of) the Text Encoding Initiative Guidelines, TEI P5 ( and also produces output in this format.", "labels": [], "entities": [{"text": "TEI P5", "start_pos": 179, "end_pos": 185, "type": "DATASET", "confidence": 0.7285729348659515}]}, {"text": "An example of the tool input fragment and the corresponding output is given in.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}