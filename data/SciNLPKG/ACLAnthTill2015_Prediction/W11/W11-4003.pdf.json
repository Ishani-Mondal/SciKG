{"title": [{"text": "Extraction of Domain-specific Opinion Words for Similar Domains", "labels": [], "entities": [{"text": "Extraction of Domain-specific Opinion Words", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.8595249772071838}]}], "abstractContent": [{"text": "In this paper we consider anew approach for domain-specific opinion word extraction in Russian.", "labels": [], "entities": [{"text": "domain-specific opinion word extraction", "start_pos": 44, "end_pos": 83, "type": "TASK", "confidence": 0.6147353872656822}]}, {"text": "We suppose that some domains have similar sentiment lexicons and utilize this fact to build an opinion word vocabulary fora group of domains.", "labels": [], "entities": []}, {"text": "We train our model in movie domain and then utilize it to book and game domains.", "labels": [], "entities": []}, {"text": "Obtained word list quality is comparable with quality of initial domain list.", "labels": [], "entities": [{"text": "Obtained word list quality", "start_pos": 0, "end_pos": 26, "type": "METRIC", "confidence": 0.623501792550087}]}], "introductionContent": [{"text": "The web is full of customers' opinions on various products.", "labels": [], "entities": []}, {"text": "Automatic extraction, processing and summarization of such opinions are very useful for future users.", "labels": [], "entities": [{"text": "summarization of such opinions", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.8770109862089157}]}, {"text": "Opinions about products are often expressed using evaluative words and phrases that have a certain positive or negative sentiment.", "labels": [], "entities": []}, {"text": "Therefore, important features in the qualitative classification of opinions about a particular entity are opinion words and expressions used in the domain.", "labels": [], "entities": []}, {"text": "The problem is that it is impossible to compile a list of opinion expressions, which will be equally applicable to all domains, as some opinion phrases are used only in a specific domain while the others are contextoriented.", "labels": [], "entities": []}, {"text": "Indeed, sentiment lexicons adapted to a particular domain or topic have been shown to improve task performance in a number of applications, including opinion retrieval, and expressionlevel sentiment classification.", "labels": [], "entities": [{"text": "opinion retrieval", "start_pos": 150, "end_pos": 167, "type": "TASK", "confidence": 0.8139294385910034}, {"text": "expressionlevel sentiment classification", "start_pos": 173, "end_pos": 213, "type": "TASK", "confidence": 0.8627599676450094}]}, {"text": "In addition there are several studies about context-dependent opinion expressions.", "labels": [], "entities": []}, {"text": "The number of different domains is very large, and recent studies are focused on cross-domain approaches, to bridge the gap between the domains.", "labels": [], "entities": []}, {"text": "On the other side there are different subject fields that has similar sentiment lexicon.", "labels": [], "entities": []}, {"text": "For example: \u00abbreathtaking\u00bb is an opinion word in entertainment (movies, books, games etc.) domain, but non-opinion in the politics domain.", "labels": [], "entities": []}, {"text": "At the opposite side some words (\u00abevil\u00bb, \u00abtreachery\u00bb etc.) have strong sentiment in politics domain, but are neutral in entertainment domain, these words do not express any opinion about a film, game or book.", "labels": [], "entities": []}, {"text": "Thus we suppose that different domains can be separated into clusters (for example: entertainment, digital goods, politics, traveling etc.) where domains of the same cluster have similar sentiment lexicons.", "labels": [], "entities": []}, {"text": "In this paper we focus on the problem of construction of a domain-specific sentiment lexicon in Russian, which can be utilized for various similar domains.", "labels": [], "entities": []}, {"text": "We present anew supervised method for domain-specific opinion word extraction.", "labels": [], "entities": [{"text": "domain-specific opinion word extraction", "start_pos": 38, "end_pos": 77, "type": "TASK", "confidence": 0.6119120717048645}]}, {"text": "We train this method in one domain and then utilize it in two others.", "labels": [], "entities": []}, {"text": "Then we combine extracted word lists to construct a general list of opinion words typical to this domain cluster.", "labels": [], "entities": []}, {"text": "Our approach is based on several text collections, which can be automatically formed for many subject areas.", "labels": [], "entities": []}, {"text": "The set of text collections includes: a collection of product reviews with author evaluation scores, a text collection of product descriptions and a contrast corpus (for example, a general news collection).", "labels": [], "entities": []}, {"text": "For each word in a review collection we calculate various statistical features using aforementioned collections and then apply machine learning algorithms for term classification.", "labels": [], "entities": [{"text": "term classification", "start_pos": 159, "end_pos": 178, "type": "TASK", "confidence": 0.7262162119150162}]}, {"text": "To evaluate the effectiveness of the proposed method we conduct experiments on data sets in three different domains: movies, books and computer games.", "labels": [], "entities": []}, {"text": "The results show that our approach can identify new opinion words specific to the given domain (for example \"fabricated\" in movie domain).", "labels": [], "entities": []}, {"text": "For further evaluation of the lexicon quality, we manually labeled extracted word lists, and our method is proved to be effective in construct-ing a qualitative list of domain-dependent sentiment lexicon.", "labels": [], "entities": []}, {"text": "The results also demonstrate the advantage of combining multiple lists of opinion words over using any single list.", "labels": [], "entities": []}, {"text": "The reminder of this article is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we describe the state-ofthe-art in the opinion words extraction sphere, Section 3 describes our approach in the movie domain, in Section 4 we utilize our approach for two other domains and combine opinion word vocabularies for all three domains.", "labels": [], "entities": [{"text": "opinion words extraction", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.7407066226005554}]}], "datasetContent": [{"text": "To train supervised machine learning algorithms we needed a set of labeled opinion words.", "labels": [], "entities": []}, {"text": "We decided to label the full list often thousand words manually and then to use cross-validation.", "labels": [], "entities": []}, {"text": "We marked up word as opinion one in case we could imagine it in any opinion context in the movie domain.", "labels": [], "entities": []}, {"text": "All words were tagged by two authors.", "labels": [], "entities": []}, {"text": "As a result of our markup we obtained the list of 3200 opinion words (1262 adjectives, 296 adverbs, 857 nouns, 785 verbs).", "labels": [], "entities": []}, {"text": "Our aim in this part of work was to classify words into two classes: opinion or neutral.", "labels": [], "entities": []}, {"text": "For this purpose Weka 1 data mining tool was used.", "labels": [], "entities": [{"text": "Weka 1 data mining", "start_pos": 17, "end_pos": 35, "type": "DATASET", "confidence": 0.8909580260515213}]}, {"text": "We considered the following algorithms: Logistic Regression and LogitBoost.", "labels": [], "entities": [{"text": "Logistic Regression", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.7582826912403107}]}, {"text": "For all experiments 10 fold cross-validation was used.", "labels": [], "entities": []}, {"text": "Using aforementioned algorithms we obtained term lists, ordered by the predicted probability of their opinion orientation.", "labels": [], "entities": []}, {"text": "To measure the quality 1 http://www.cs.waikato.ac.nz/ml/weka/ of these lists we used Precision@n metric.", "labels": [], "entities": []}, {"text": "This metric is very convenient for measuring the quality of list combinations and it can be used with different thresholds.", "labels": [], "entities": []}, {"text": "For the algorithms quality comparison in different domains we chosen = 1000.", "labels": [], "entities": []}, {"text": "This level is not too large for manual labeling and demonstrates the quality in an appropriate way.", "labels": [], "entities": []}, {"text": "The results of classification are in.", "labels": [], "entities": []}, {"text": "For new domains we extracted ten thousand the most frequent words (or all available words with frequency more then 3) and calculated all statistical features, which were described in Section 3.3.", "labels": [], "entities": []}, {"text": "At the next step we applied our model trained in the movie domain to the book and games word lists.", "labels": [], "entities": []}, {"text": "To evaluate the quality of word classification in new domains we manually labeled first thousand of words in each list.", "labels": [], "entities": [{"text": "word classification", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.7147597074508667}]}, {"text": "The results of classification are in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3. Precision@1000 for different feature  sets", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9828147292137146}]}]}