{"title": [{"text": "Handling Outlandish Occurrences: Using Rules and Lexicons for Correcting NLP Articles", "labels": [], "entities": []}], "abstractContent": [{"text": "This article describes the experiments we performed during our participation in the HOO Challenge.", "labels": [], "entities": [{"text": "HOO Challenge", "start_pos": 84, "end_pos": 97, "type": "DATASET", "confidence": 0.6907157301902771}]}, {"text": "We present the adaption we made on two systems, mainly designing new grammatical rules and completing a lexicon.", "labels": [], "entities": []}, {"text": "We focused our work on some of the most common errors in the corpus: missing punctuation and inaccurate prepositions.", "labels": [], "entities": []}, {"text": "Our best experiment achieved a 0.1097 detection score, a 0.0820 recognition score, and a 0.0557 correction score on the test corpus.", "labels": [], "entities": [{"text": "recognition score", "start_pos": 64, "end_pos": 81, "type": "METRIC", "confidence": 0.9668643176555634}, {"text": "correction score", "start_pos": 96, "end_pos": 112, "type": "METRIC", "confidence": 0.95085808634758}]}], "introductionContent": [{"text": "The number of articles written by non-native English speakers makes it necessary to provide the community with tools that can be helpful in checking and improving the linguistic quality of those articles (.", "labels": [], "entities": []}, {"text": "The correction of errors made by English as a Second Language (ESL) writers has been addressed in several recent studies.", "labels": [], "entities": [{"text": "correction of errors made by English as a Second Language (ESL) writers", "start_pos": 4, "end_pos": 75, "type": "TASK", "confidence": 0.6739064476319722}]}, {"text": "Different kinds of errors are targeted, both concerning closed classes of words such as articles, prepositions, modals or auxiliaries and open classes of words, such as nouns and verbs ().", "labels": [], "entities": []}, {"text": "In the case of closed classes and commonly confused words, it is possible to cast the problem as an automatic classification task.", "labels": [], "entities": []}, {"text": "The goal of the classifier is to predict the most likely candidate from a confusion set in the given context.", "labels": [], "entities": []}, {"text": "This requires large training corpora of mostly error-free texts.", "labels": [], "entities": []}, {"text": "Another approach to error correction consists in using manually developed rules to identify and correct erroneous occurrences.", "labels": [], "entities": [{"text": "error correction", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.679786741733551}]}, {"text": "This approach has, for instance, been adopted in the open-source LanguageTool proofreading tool 1.", "labels": [], "entities": [{"text": "LanguageTool proofreading tool 1", "start_pos": 65, "end_pos": 97, "type": "DATASET", "confidence": 0.8727892637252808}]}, {"text": "In this paper, we describe our participation to the HOO2011 challenge.", "labels": [], "entities": [{"text": "HOO2011 challenge", "start_pos": 52, "end_pos": 69, "type": "TASK", "confidence": 0.665823221206665}]}, {"text": "We present our systems and the configurations we used while participating in the test stage of the challenge.", "labels": [], "entities": []}], "datasetContent": [{"text": "The evaluation of our pipeline on the test corpus is given in.", "labels": [], "entities": []}, {"text": "We achieved our best results using the combination of LanguageTool followed by CCAC (run #8); we obtained a 0.1097 detection score, a 0.0833 recognition score, and a 0.0589 correction score, without any bonus).", "labels": [], "entities": [{"text": "CCAC", "start_pos": 79, "end_pos": 83, "type": "DATASET", "confidence": 0.8749122619628906}, {"text": "detection score", "start_pos": 115, "end_pos": 130, "type": "METRIC", "confidence": 0.9304009675979614}, {"text": "recognition score", "start_pos": 141, "end_pos": 158, "type": "METRIC", "confidence": 0.9574042558670044}, {"text": "correction score", "start_pos": 173, "end_pos": 189, "type": "METRIC", "confidence": 0.9601887464523315}]}, {"text": "The CCAC system used independently did not obtain good results (#6).", "labels": [], "entities": [{"text": "CCAC", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.9224728941917419}]}, {"text": "This system has been designed to process very noisy data using basic correction modules (to add or to remove diacritics, to process geminates, and at last to propose corrections based on the Levenshtein distance).", "labels": [], "entities": []}, {"text": "Within the framework of the HOO challenge, the corrections to be made are finer than those of a web corpus.", "labels": [], "entities": [{"text": "HOO challenge", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.5082759261131287}]}, {"text": "While on the training data we achieved our best score using LanguageTool only, 3 on the test corpus, the combination of both LanguageTool and CCAC performed best.", "labels": [], "entities": [{"text": "CCAC", "start_pos": 142, "end_pos": 146, "type": "DATASET", "confidence": 0.8600782155990601}]}, {"text": "This demonstrates the complementarity of both tools when applied on anew corpus for which no specific rules had been designed.", "labels": [], "entities": []}, {"text": "For the time being, our systems only deal with some types of errors (especially punctuation and prepositions), due to time constraints for developing new resources and tools.", "labels": [], "entities": []}, {"text": "Further work is thus needed to process all other kinds of errors.", "labels": [], "entities": []}, {"text": "When improving the LanguageTool resources, we manually designed new rules and added new items in the lexicons.", "labels": [], "entities": []}, {"text": "In order to improve this process, it would be interesting to automatically extract rules and missing words from the annotated corpus in order to reduce human intervention.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Official evaluation on the test corpus (no bonus scores)", "labels": [], "entities": []}]}