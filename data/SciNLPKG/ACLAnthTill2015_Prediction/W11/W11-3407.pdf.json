{"title": [{"text": "Feasibility of Leveraging Crowd Sourcing for the Creation of a Large Scale Annotated Resource for Hindi English Code Switched Data: A Pilot Annotation", "labels": [], "entities": []}], "abstractContent": [{"text": "Linguistic code switching (LCS) occurs when speakers mix multiple languages in the same speech utterance.", "labels": [], "entities": [{"text": "Linguistic code switching (LCS)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7648035486539205}]}, {"text": "We find LCS pervasively in bilingual communities.", "labels": [], "entities": [{"text": "LCS", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9513536095619202}]}, {"text": "LCS poses a serious challenge to Natural Language and Speech Processing.", "labels": [], "entities": [{"text": "LCS", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7123321294784546}, {"text": "Speech Processing", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.7360674738883972}]}, {"text": "With the ubiquity of informal gen-res online, LCS is emerging as a very widespread phenomenon.", "labels": [], "entities": [{"text": "LCS", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9284346699714661}]}, {"text": "This paper presents a first attempt at collecting and annotating a large repository of LCS data.", "labels": [], "entities": [{"text": "LCS data", "start_pos": 87, "end_pos": 95, "type": "DATASET", "confidence": 0.755969911813736}]}, {"text": "We target Hindi English (Hinglish) LCS.", "labels": [], "entities": [{"text": "Hindi English (Hinglish) LCS", "start_pos": 10, "end_pos": 38, "type": "DATASET", "confidence": 0.5702895273764929}]}, {"text": "We investigate the feasibility of leverag-ing crowd sourcing as a means for annotating the data on the word level.", "labels": [], "entities": [{"text": "leverag-ing crowd sourcing", "start_pos": 34, "end_pos": 60, "type": "TASK", "confidence": 0.8813734253247579}]}, {"text": "This paper briefly explains the setup of the experiment and data collection.", "labels": [], "entities": []}, {"text": "It also presents statistics representing agreements among annotators over different possible categories of Hinglish words and analyzes the confidence with which a code switched word can be annotated in the correct category by humans.", "labels": [], "entities": []}], "introductionContent": [{"text": "Linguistic Code switching (LCS) is the term used to describe a common practice among bilingual speakers of a given language pair in which the speakers switchback and forth between their common languages.", "labels": [], "entities": [{"text": "Linguistic Code switching (LCS)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7677995761235555}]}, {"text": "This phenomenon is dominantly observed in inhabitants of countries like India where Hindi is a common first language (L1) and English acts as a second language (L2) among native Hindi speakers.", "labels": [], "entities": []}, {"text": "For example, the following Hindi sentence with code switches to English is a seamless example of North Indian conversation: Uske communication ki wajah se hi project successful hua hai.", "labels": [], "entities": []}, {"text": "(Project has become successful because of his excellent communication.)", "labels": [], "entities": []}, {"text": "LCS occurs both inter-sentential and intra-sentential.", "labels": [], "entities": [{"text": "LCS", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7357206344604492}]}, {"text": "LCS occurs in all genres of communication for such speakers, including spoken conversation, email, online chat rooms, blogs and newsgroups.", "labels": [], "entities": [{"text": "LCS", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8211376667022705}]}, {"text": "Thus, it seriously impacts attempts to process these exchanges computationally, for the purposes of automatic translation, speech recognition, and information extraction, inter alia (.", "labels": [], "entities": [{"text": "automatic translation", "start_pos": 100, "end_pos": 121, "type": "TASK", "confidence": 0.6446764022111893}, {"text": "speech recognition", "start_pos": 123, "end_pos": 141, "type": "TASK", "confidence": 0.8051169216632843}, {"text": "information extraction", "start_pos": 147, "end_pos": 169, "type": "TASK", "confidence": 0.7848207950592041}]}, {"text": "With increasing interest in LCS, there is need for large annotated LCS corpora which can support the needs of computational as well as theoretical research.", "labels": [], "entities": []}, {"text": "This paper presents one experiment where a corpus of code switched sentences is annotated for identifying code switch points using crowd sourcing methods.", "labels": [], "entities": []}, {"text": "The data collection serves as the first attempt at creating a repository for LCS data.", "labels": [], "entities": []}, {"text": "Also the annotations of LCS points will shed light into the nature of this phenomenon and will bean initial building block for the development of interesting analytical and predictive models for automatic LCS processing systems.", "labels": [], "entities": []}, {"text": "It is widely accepted that LCS actually follows a certain pattern and that it does not occur randomly.", "labels": [], "entities": [{"text": "LCS", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.9827515482902527}]}, {"text": "Several studies in sociolinguistics and theoretical linguistics have investigated this issue however on a small scale).", "labels": [], "entities": []}], "datasetContent": [{"text": "Amazon Mechanical Turk (AMT) is a marketplace to host surveys where requesters host some questions which are answered by workers, aka turkers.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk (AMT)", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5659438222646713}]}, {"text": "It has been widely accepted that the use of crowd sourcing techniques for the collection of data annotations is a worthwhile effort (.", "labels": [], "entities": []}, {"text": "The benefit of using crowd sourcing lies in a rapid collection cycle, sometimes at the expense of quality.", "labels": [], "entities": [{"text": "crowd sourcing", "start_pos": 21, "end_pos": 35, "type": "TASK", "confidence": 0.7449967861175537}]}, {"text": "Hence the challenge lies in designing and simplifying the task and presenting it to laypeople in generic terms.", "labels": [], "entities": []}, {"text": "But also setting performance metrics for accepting such annotations.", "labels": [], "entities": []}, {"text": "We carried out our experiments on AMT where we asked the turkers to identify each word in a sentence as one of the following categories: 2 1.", "labels": [], "entities": [{"text": "AMT", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.6123353242874146}]}, {"text": "Hindi-aaya(came),gaya(went),hum(we) 2.", "labels": [], "entities": []}, {"text": "English-usual English words, for example, eat, grin, happy 3.", "labels": [], "entities": [{"text": "grin", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.9743084907531738}]}, {"text": "Foreign Proper Name-John,Stella, IBM 4.", "labels": [], "entities": [{"text": "Foreign Proper Name-John,Stella, IBM 4", "start_pos": 0, "end_pos": 38, "type": "DATASET", "confidence": 0.7701916595300039}]}, {"text": "Indian proper Name-Ramesh,Ganesh, Anjali 5.", "labels": [], "entities": []}, {"text": "Unknown-Any word which cannot be classified into any of the above categories The experiment was setup as a survey with three Hinglish sentences on one page.", "labels": [], "entities": [{"text": "Hinglish", "start_pos": 125, "end_pos": 133, "type": "DATASET", "confidence": 0.9142882227897644}]}, {"text": "Each of such pages is termed a Human Intelligence Task (HIT) and a collection of HITs is termed a task on AMT.", "labels": [], "entities": [{"text": "AMT", "start_pos": 106, "end_pos": 109, "type": "DATASET", "confidence": 0.8219245672225952}]}, {"text": "Our collection of 10500 sentences was divided into 7 tasks, each task containing 500 HITs with 3 sentences each.", "labels": [], "entities": []}, {"text": "Each word in a sentence had a drop down list containing the above options associated with it, with the default option being Hindi.", "labels": [], "entities": []}, {"text": "The AMT turkers then marked each word in the sentence as one of the options above.", "labels": [], "entities": [{"text": "AMT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.6305052042007446}]}, {"text": "A minimum of two turkers were allowed to work on a single HIT or the same set of 3 sentences in order to allow overlap for agreements/disagreements on same set of words.", "labels": [], "entities": []}, {"text": "Accordingly all the data was at least doubly annotated.", "labels": [], "entities": []}, {"text": "A subset of HITs (10% of the corpus size) was gold annotated by a native bilingual speaker of Hindi and English.", "labels": [], "entities": []}, {"text": "We designed the setup of the HITs such that for any given turker at least one sentence in a HIT overlapped with a gold annotation.", "labels": [], "entities": []}, {"text": "Then the turker whose sampled HIT annotations agreed with the gold annotation less than 95% were discarded.", "labels": [], "entities": []}, {"text": "Initially, 136 turkers submitted the results, out of which 85 turkers scored above the set 95% threshold.", "labels": [], "entities": []}, {"text": "The HITs that were rejected were resubmitted to AMT for re-annotation.", "labels": [], "entities": [{"text": "HITs", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.9051218628883362}, {"text": "AMT", "start_pos": 48, "end_pos": 51, "type": "DATASET", "confidence": 0.9033563733100891}]}, {"text": "With resubmission results, 8 more turkers were added as they scored above the 95% threshold bringing the total number of turkers to 93.", "labels": [], "entities": []}, {"text": "Accordingly, the overall data was annotated by 93 turkers, 10% of the overall 10500 sentences is three way annotated with gold annotation and by two turkers.", "labels": [], "entities": []}, {"text": "In this section we present detailed results on the collected annotations.", "labels": [], "entities": []}, {"text": "We calculate inter-turker agreements based on how many times a turker agreed on a category within the same HIT with the other turkers who co-annotated the same HIT.", "labels": [], "entities": []}, {"text": "The results for turkers were then aggregated to find the total number of agreements for each category.", "labels": [], "entities": []}, {"text": "The resulting confusion matrix is shown in  The following detailed statistics show the percentage classification agreement among the coturkers in different categories for the majority annotated class on the word level.", "labels": [], "entities": []}, {"text": "As mentioned above, each HIT was annotated by two turkers.", "labels": [], "entities": []}, {"text": "In our detailed statistics, we observe the number of times two turkers agreed on a category label per  Hence, turkers agreed 98.1% of the time that the label for these 88.16% of the word instances are Hindi, however, some set of the turker pairs confused 1.1% of this Hindi data set as English, while 0.25% of the time pairs of turkers considered these Hindi words as Unknown.", "labels": [], "entities": [{"text": "Hindi data set", "start_pos": 268, "end_pos": 282, "type": "DATASET", "confidence": 0.769903322060903}]}, {"text": "For example, if we compare an individual turker with co-turkers, majority of agreements are Hindi-Hindi, English-English and soon.", "labels": [], "entities": []}, {"text": "Similarly, disagreements are also proportionate to above statistics.", "labels": [], "entities": []}, {"text": "A detailed token level analysis also showed similar trends.", "labels": [], "entities": []}, {"text": "We analyzed a sample of 1304 tokens of which 1005 have a Hindi root and 245 are of English etymology.", "labels": [], "entities": []}, {"text": "27 tokens were Foreign Proper Names and 26 were Indian Proper Names.", "labels": [], "entities": []}, {"text": "The turkers agreed 98.45% times that the tokens are Hindi over the total occurrences of sample Hindi root tokens.", "labels": [], "entities": []}, {"text": "They agreed 79.41% times that the token is English over tokens with English root, 75.74% times agreed that the token is Foreign Proper Name for Foreign Proper Name tokens.", "labels": [], "entities": []}, {"text": "The turkers agreed 74.58% times that the token is an Indian Proper Name for Indian Proper Name tokens.", "labels": [], "entities": []}, {"text": "The turkers were observed to confuse Hindi tokens and Indian Proper Name tokens as 22.63% times, i.e. they mutually agreed that the token is Hindi when it was in fact an Indian Proper Name.", "labels": [], "entities": []}, {"text": "We further analyze the agreement on a complete sentence level, where turkers agreed on the annotation for every token in the sentence, we found only 57 such sentence annotations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Confusion Matrix of the aggregate turk- ers' annotations for the different categories", "labels": [], "entities": []}]}