{"title": [{"text": "Interpreting tractable versus intractable reciprocal sentences", "labels": [], "entities": []}], "abstractContent": [{"text": "In three experiments, we investigated the computational complexity of German reciprocal sentences with different quantificational antecedents.", "labels": [], "entities": []}, {"text": "Building upon the tractable cognition thesis (van Rooij, 2008) and its application to the verification of quantifiers (Szymanik, 2010) we predicted complexity differences among these sentences.", "labels": [], "entities": []}, {"text": "Reciprocals with all-antecedents are expected to preferably receive a strong interpretation (Dalrymple et al., 1998), but reciprocals with proportional or numerical quantifier antecedents should be interpreted weakly.", "labels": [], "entities": []}, {"text": "Experiment 1, where participants completed pictures according to their preferred interpretation, provides evidence for these predictions.", "labels": [], "entities": []}, {"text": "Experiment 2 was a picture verification task.", "labels": [], "entities": [{"text": "picture verification task", "start_pos": 19, "end_pos": 44, "type": "TASK", "confidence": 0.8750543196996053}]}, {"text": "The results show that the strong interpretation was in fact possible for tractable all but one-reciprocals, but not for exactly n.", "labels": [], "entities": []}, {"text": "The last experiment manipulated monotonicity of the quantifier antecedents.", "labels": [], "entities": []}, {"text": "Formal semantics hasn't paid much attention to issues of computational complexity when the meaning of an expression is derived.", "labels": [], "entities": [{"text": "Formal semantics", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8564223647117615}]}, {"text": "However, when it comes to semantic processing in humans (and computers) with limited processing resources, computational tractability becomes one of the most important constraints a cognitively realistic semantics must face.", "labels": [], "entities": [{"text": "semantic processing", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.8130665123462677}]}, {"text": "Two consequences come to mind immediately.", "labels": [], "entities": []}, {"text": "If there is a choice between algorithms, we should choose tractable ones over intractable ones.", "labels": [], "entities": []}, {"text": "And secondly, meanings which cannot be effectively computed shouldn't be posited for natural language expressions.", "labels": [], "entities": []}, {"text": "In this paper we present three psycholinguistic experiments investigating the latter aspect.", "labels": [], "entities": []}, {"text": "Following traditions in computer science, a number of cognitive scientists have defined computational tractability as polynomial-time-computability (for an overview see van Rooij, 2008) leading to the P-Cognition Hypothesis (PCH): cognitive capacities are limited to those functions that can be computed in polynomial time.", "labels": [], "entities": []}, {"text": "These functions are input-output functions in the sense of Marr (1982)'s first level.", "labels": [], "entities": []}, {"text": "One objection against the PCH is that computational complexity is defined in terms of limit behavior as the input increases.", "labels": [], "entities": []}, {"text": "In practice, however, the input maybe rather small.", "labels": [], "entities": []}, {"text": "van Rooij (2008) points out that the input size can be parametrized turning a problem that is intractable fora large input size into a tractable one for small inputs.", "labels": [], "entities": []}, {"text": "We manipulated the input size in an experiment to test this more refined version of the PCH.", "labels": [], "entities": [{"text": "PCH", "start_pos": 88, "end_pos": 91, "type": "DATASET", "confidence": 0.942895770072937}]}, {"text": "An interesting test case for the PCH are quantified sentences containing reciprocal expressions of the form Q of the As R each other.", "labels": [], "entities": []}, {"text": "Consider (1-a)-(1-c).", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "According to the SMH, sentences like (3-a) are preferably interpreted with their strong meaning in (3-b).", "labels": [], "entities": []}, {"text": "All/Most/Four of the dots are connected to each other.", "labels": [], "entities": []}, {"text": "where Q is ALL, MOST or FOUR.", "labels": [], "entities": [{"text": "ALL", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.995818555355072}, {"text": "MOST", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.9961180686950684}, {"text": "FOUR", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.9951320886611938}]}, {"text": "The PCH, on the other hand, predicts differences between the three quantifiers.", "labels": [], "entities": [{"text": "PCH", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.8481944799423218}]}, {"text": "While the strong meaning of reciprocal all can be checked in polynomial time, verifying the strong interpretation of reciprocal most  The second experiment employed a picture verification task using clearly disambiguating pictures for strong vs. intermediate readings.", "labels": [], "entities": []}, {"text": "Unfortunately, the quantifiers we used in the last experiment are all upward monotone in their right argument and therefore their strong interpretation implies the intermediate reading.", "labels": [], "entities": []}, {"text": "Hence, even if the diagrams supporting the strong reading were judged to be true, we still wouldn't know which interpretation subjects had in mind.", "labels": [], "entities": []}, {"text": "Luckily, in sentences that contain nonmonotone quantifiers neither reading entails the other.", "labels": [], "entities": []}, {"text": "We therefore chose the quantifiers all but one, most and exactly n in (6).", "labels": [], "entities": []}, {"text": "All but one and exactly four are clearly non-monotone.", "labels": [], "entities": []}, {"text": "For most, if we take the implicature most, but not all into account, it is possible to construct strong pictures in away that the other readings are ruled out pragmatically.", "labels": [], "entities": []}, {"text": "Crucially, the strong reading of all but one is still PTIME computable, although it is more complex than all.", "labels": [], "entities": [{"text": "PTIME", "start_pos": 54, "end_pos": 59, "type": "METRIC", "confidence": 0.5814245939254761}]}, {"text": "For instance, for verifying a model of size n, only then subsets of size n \u2212 1 have to be considered.", "labels": [], "entities": []}, {"text": "By contrast, verifying the strong meaning of (6-b,c) is intractable.", "labels": [], "entities": []}, {"text": "Sample diagrams are depicted in(a) and 1(b).", "labels": [], "entities": []}, {"text": "For strong pictures, the PCH predicts lower acceptance rates for (6-b,c) than for (6-a).", "labels": [], "entities": [{"text": "acceptance", "start_pos": 44, "end_pos": 54, "type": "METRIC", "confidence": 0.9825921058654785}]}, {"text": "In order to find out whether the strong readings of (6-b,c) are dispreferred or completely unavailable we also paired them with false control diagrams (see).", "labels": [], "entities": []}, {"text": "The wrong pictures differed from the strong ones in that a single line was removed from the completely connected subset.", "labels": [], "entities": []}, {"text": "If the strong reading is available for these two sentences at all, we expect more positive judgments following a strong diagram than following a false control.", "labels": [], "entities": []}, {"text": "Furthermore, we included ambigu- Secondly, as mentioned in the introduction we wanted to investigate whether availability of the strong reading in sentences with counting or proportional quantifiers depends on the size of the model.", "labels": [], "entities": []}, {"text": "The strong meaning of (6-b,c) maybe easy to verify in small universes, but not in larger ones.", "labels": [], "entities": []}, {"text": "To test this possibility we manipulated the number of dots.", "labels": [], "entities": []}, {"text": "Small models always contained four dots and large models six dots.", "labels": [], "entities": []}, {"text": "We chose small models only consisting of four dots because this is the smallest number for which the strong meaning can be distinguished from the intermediate interpretation, so we could be sure that the task would be doable at all 4 . For the more complex six-dot pictures we presented sentences with exactly five instead of exactly three.", "labels": [], "entities": []}, {"text": "Example diagrams are given in   36 German native speakers (mean age 26.9 years; 23 female) read reciprocal quantified sentences on a computer screen in a self-paced fashion.", "labels": [], "entities": []}, {"text": "When they finished reading the sentence, it disappeared from the screen and a dot picture was presented for which a truth value judgment had to be provided within a time limit of 10s 6 . Participants received feedback about how fast they had responded.", "labels": [], "entities": []}, {"text": "This was done to trigger the first interpretation they had in mind.", "labels": [], "entities": []}, {"text": "We collected judgments and judgment times, but because of space limitations will only report the former.", "labels": [], "entities": []}, {"text": "The experiment started with a practice session of 10 trials, followed by the experiment with 138 trials in an individually randomized order.", "labels": [], "entities": []}, {"text": "This main effect was due to an across-the-board preference (7.3% on average) of ambiguous pictures to pictures disambiguating towards an intermediate interpretation.", "labels": [], "entities": []}, {"text": "Lower bound analyses: We computed a logit mixed effects model analysis including quantifier, truth (strong vs. wrong), complexity and their interactions as fixed effects and participants and items as random effects.", "labels": [], "entities": []}, {"text": "The only reliable effect was the fixed effect of quantifier (estimate =3 .31; z =8 .10; p<. 01).", "labels": [], "entities": [{"text": "estimate", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9203833937644958}]}, {"text": "The effect of truth was marginal (estimate =0 .72; z =1 .77; p = .07).", "labels": [], "entities": [{"text": "estimate", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9785470366477966}]}, {"text": "As it turned out, a simpler model taking into account only these two main effects and the random effects accounted for the data with a comparable fit.", "labels": [], "entities": []}, {"text": "This was revealed by a comparison of the log-likelihood of the saturated and the simpler model (\u03c7 2 (8) =1 2 .36; p = .14).", "labels": [], "entities": []}, {"text": "Thus, complexity had no significant influence on the judgments.", "labels": [], "entities": []}, {"text": "The simple model revealed a significant main effect of truth (estimate =0 .67; z =4 .08; p<.", "labels": [], "entities": [{"text": "estimate", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9770625829696655}]}, {"text": "01) which was due to 7.9% more 'true' judgments on average in the strong conditions than in the wrong conditions.", "labels": [], "entities": []}, {"text": "The main effect of quantifier was also significant (most vs. all/exactly: estimate =3 .21; z =1 5 .10; p<. 01).", "labels": [], "entities": []}, {"text": "This was due to more than 60% acceptance for all most conditions but much lower acceptance for the other two quantifiers.", "labels": [], "entities": [{"text": "acceptance", "start_pos": 30, "end_pos": 40, "type": "METRIC", "confidence": 0.9911734461784363}, {"text": "acceptance", "start_pos": 80, "end_pos": 90, "type": "METRIC", "confidence": 0.9929875731468201}]}, {"text": "We analyzed the data by computing separate logit mixed effect models with fixed effects of truth, complexity and their interaction for all three quantifiers and simplified the models when a fixed effect failed to contribute to model fit.", "labels": [], "entities": []}, {"text": "The best model for all but one contained only the fixed effect of truth which was reliable (estimate =1 .04; z =3 .47; p<.", "labels": [], "entities": [{"text": "estimate", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9834350943565369}]}, {"text": "01), but neither complexity nor the interaction enhanced model fit (\u03c7 2 (2) =1.04; p = .60).", "labels": [], "entities": []}, {"text": "Thus, independently of complexity strong pictures were more often accepted than wrong pictures.", "labels": [], "entities": []}, {"text": "The same held for most (fixed effect of truth: estimate =0 .98; z =2 .71; p<. 01).", "labels": [], "entities": [{"text": "fixed effect of truth: estimate", "start_pos": 24, "end_pos": 55, "type": "METRIC", "confidence": 0.8520703415075938}]}, {"text": "Exactly n was different in that the fixed effect of truth and the interaction didn't matter (\u03c7 2 (2) =2.68; p = .26), but complexity was significant (estimate = \u22120.97; z = \u22122.96; p<.01).", "labels": [], "entities": [{"text": "complexity", "start_pos": 122, "end_pos": 132, "type": "METRIC", "confidence": 0.9799606204032898}, {"text": "estimate", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.9809277653694153}]}, {"text": "This effect was due to more errors in complex pictures than in simpler ones.", "labels": [], "entities": []}, {"text": "So far, we have been investigating reciprocal sentences with the upward monotone quantifiers all, most, four (Exp.", "labels": [], "entities": []}, {"text": "1) and the non-monotone quantifiers all but one and exactly n (Exp. 2).", "labels": [], "entities": []}, {"text": "As it looks, only all licenses a strong interpretation easily.", "labels": [], "entities": []}, {"text": "This finding may follow from the monotonicity plus implicatures.", "labels": [], "entities": []}, {"text": "According to's SMH strong readings are preferred in sentences with upward monotone quantificational antecedents.", "labels": [], "entities": [{"text": "SMH", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.9404533505439758}]}, {"text": "For downward monotone quantifiers, on the other hand, intermediate readings should be preferred to strong readings.", "labels": [], "entities": []}, {"text": "The reverse preferences are triggered by opposite entailment patterns.", "labels": [], "entities": []}, {"text": "In the present experiment we compared upward monotone more than n with downward monotone antecedents fewer than n+2.", "labels": [], "entities": []}, {"text": "We paired diagrams like(f) vs. with the two sentences in (7) according to a 2 (monotonicity) \u00d7 2(truth) factorial design.", "labels": [], "entities": []}, {"text": "The diagrams of the first type were identical to the strong pictures of the last experiment.", "labels": [], "entities": []}, {"text": "With monotone increasing quantifiers they were ambiguous between strong and intermediate interpretations while in the monotone decreasing cases they disambiguated towards a strong interpretation.", "labels": [], "entities": []}, {"text": "The second type of pictures disambiguated towards weak readings in monotone increasing quantifiers, but were ambiguous for monotone decreasing quantificational antecedents.", "labels": [], "entities": []}, {"text": "On the basis of the first two experiments we expected high acceptance of both picture types with monotone increasing quantifiers, but much lower acceptance rates for (7-b) with strong than with ambiguous pictures.", "labels": [], "entities": [{"text": "acceptance", "start_pos": 59, "end_pos": 69, "type": "METRIC", "confidence": 0.9541783928871155}, {"text": "acceptance", "start_pos": 145, "end_pos": 155, "type": "METRIC", "confidence": 0.970533549785614}]}, {"text": "We constructed six items and collected three judgments from each participant in each condition.", "labels": [], "entities": []}, {"text": "The experiment was run together with Experiment 2 using the same method.", "labels": [], "entities": []}], "tableCaptions": []}