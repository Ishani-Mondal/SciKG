{"title": [{"text": "Data-Driven Correction of Function Words in Non-Native English", "labels": [], "entities": []}], "abstractContent": [{"text": "We extend the n-gram-based data-driven prediction approach (Elghafari, Meurers and Wunsch, 2010) to identify function word errors in non-native academic texts as part of the Helping Our Own (HOO) Shared Task.", "labels": [], "entities": []}, {"text": "We focus on substitution errors for four categories: prepositions, determiners, conjunctions, and quantifiers.", "labels": [], "entities": []}, {"text": "These error types makeup 12% of the errors annotated in the HOO training data.", "labels": [], "entities": [{"text": "HOO training data", "start_pos": 60, "end_pos": 77, "type": "DATASET", "confidence": 0.8308924436569214}]}, {"text": "In our best submission in terms of the error detection score, we detected 67% of preposition and determiner substitution errors, 40% of conjunction substitution errors, and 33% of quantifier substitution errors.", "labels": [], "entities": [{"text": "error detection", "start_pos": 39, "end_pos": 54, "type": "TASK", "confidence": 0.670742392539978}]}, {"text": "For approximately half of the errors detected, we were also able to provide an appropriate correction.", "labels": [], "entities": [{"text": "correction", "start_pos": 91, "end_pos": 101, "type": "METRIC", "confidence": 0.956745445728302}]}], "introductionContent": [{"text": "We take as a starting point the preposition prediction approach of Elghafari,.", "labels": [], "entities": [{"text": "preposition prediction", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.7890665531158447}]}, {"text": "They explore a surface-based approach for predicting prepositions in English which uses frequency information from web searches to choose the most likely preposition given the context.", "labels": [], "entities": [{"text": "predicting prepositions", "start_pos": 42, "end_pos": 65, "type": "TASK", "confidence": 0.9118403196334839}]}, {"text": "For each preposition found in the text, the prediction algorithm considers three words of context on each side, building a 7-gram with a preposition slot in the middle: rather a question the scales falling For each prediction task, a cohort of queries is constructed with each of the candidate prepositions in the slot to be predicted: 1.", "labels": [], "entities": []}, {"text": "rather a question of the scales falling 2.", "labels": [], "entities": []}, {"text": "rather a question in the scales falling . .", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Function Words with Frequency in Test Data", "labels": [], "entities": []}]}