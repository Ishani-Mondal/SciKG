{"title": [{"text": "Towards semi-automatic methods for improving WordNet", "labels": [], "entities": [{"text": "WordNet", "start_pos": 45, "end_pos": 52, "type": "DATASET", "confidence": 0.70769202709198}]}], "abstractContent": [{"text": "WordNet is extensively used as a major lexical resource in NLP.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9391294121742249}]}, {"text": "However, its quality is far from perfect, and this alters the results of applications using it.", "labels": [], "entities": []}, {"text": "We propose hereto complement previous efforts for \"cleaning up\" the top-level of its taxonomy with semi-automatic methods based on the detection of errors at the lower levels.", "labels": [], "entities": []}, {"text": "The methods we propose test the coherence of two sources of knowledge, exploiting ontological principles and semantic constraints.", "labels": [], "entities": []}], "introductionContent": [{"text": "WordNet (Princeton WordNet, henceforth WN) is a lexical resource widely used in a host of applications in which language or linguistic concepts play a role.", "labels": [], "entities": [{"text": "WordNet (Princeton WordNet", "start_pos": 0, "end_pos": 26, "type": "DATASET", "confidence": 0.8370763957500458}]}, {"text": "For instance, it is a central resource for the quantification of semantic relatedness), in turn often exploited in applications.", "labels": [], "entities": [{"text": "quantification of semantic relatedness", "start_pos": 47, "end_pos": 85, "type": "TASK", "confidence": 0.7715632319450378}]}, {"text": "The quality of this resource therefore is very important for NLP as a whole, and beyond, in several AI applications.", "labels": [], "entities": []}, {"text": "show that the quality of a knowledge resource like WN affects the performance in recognizing textual entailment (RTE) and word-sense disambiguation (WSD) tasks.", "labels": [], "entities": [{"text": "recognizing textual entailment (RTE) and word-sense disambiguation (WSD) tasks", "start_pos": 81, "end_pos": 159, "type": "TASK", "confidence": 0.7442057545368488}]}, {"text": "They observe that the new version of WN induced improvements in recent RTE challenges, but conclude that WN currently is not rich enough to resolve such a task.", "labels": [], "entities": []}, {"text": "What is more, its quality maybe too low to even be useful at all.", "labels": [], "entities": []}, {"text": "discuss the results 1 of 20 \"ablation tests\" on systems submitted to the main RTE-5 task in which WN (alone) was ablated: 11 of these tests demonstrated that the use of this resource has a positive impact (up to 4%) on the performance of the systems but 9 showed a negative (up to 2% improvement when ablated) or null impact.", "labels": [], "entities": [{"text": "WN", "start_pos": 98, "end_pos": 100, "type": "DATASET", "confidence": 0.8282294273376465}]}, {"text": "In the area of automatic recognition of part-whole relations, proposed a learning method relying on WN's taxonomy.", "labels": [], "entities": [{"text": "automatic recognition of part-whole relations", "start_pos": 15, "end_pos": 60, "type": "TASK", "confidence": 0.6985156178474426}, {"text": "WN's taxonomy", "start_pos": 100, "end_pos": 113, "type": "DATASET", "confidence": 0.9103477001190186}]}, {"text": "Analyzing the classification rules obtained, we could see that WN taxonomical errors lead to absurd rules, which can explain wrong recognition results.", "labels": [], "entities": []}, {"text": "For instance, the authors obtain pairs such as shape, physical phenomenon and atmospheric phenomenon, communication as positive constraints for part-whole recognition, while sentences like a curved shape is part of the electromagnetic radiation or rain is part of this document would make no sense.", "labels": [], "entities": [{"text": "part-whole recognition", "start_pos": 144, "end_pos": 166, "type": "TASK", "confidence": 0.6667669415473938}]}, {"text": "Some semantic problems of WN are well-known: confusion between concepts and individuals (in principle solved since WN 2.1), heterogeneous levels of generality, inappropriate use of multiple inheritance, confounding and missing senses, and unclear glosses).", "labels": [], "entities": [{"text": "WN", "start_pos": 26, "end_pos": 28, "type": "TASK", "confidence": 0.9252108931541443}]}, {"text": "Nevertheless, the number of applications where WN is used as an ontology has been increasing.", "labels": [], "entities": []}, {"text": "In fact, apart from the synonymy relation on which synsets are defined, the hyponymy/hypernymy relation is WN's semantic relation most exploited in applications; it generates WN's taxonomy, which can be seen as a lightweight ontology, something it was never designed for, though.", "labels": [], "entities": []}, {"text": "Several works tried to address these shortcomings.", "labels": [], "entities": []}, {"text": "proposed a manual restructuring through the alignment of WN's taxonomy and the foundational ontology DOLCE 2 , but this restructuring just focused on the upper levels of the taxonomy.", "labels": [], "entities": [{"text": "WN's taxonomy", "start_pos": 57, "end_pos": 70, "type": "DATASET", "confidence": 0.8731027046839396}]}, {"text": "Applying formal ontology principles and the OntoClean methodology () have also been suggested for manually \"cleaning up\" the whole resource.", "labels": [], "entities": []}, {"text": "This however is extremely demanding, because the philosophical principles involved require a deep analysis of each concept, and as a result, is unlikely to be achieved in a near future.", "labels": [], "entities": []}, {"text": "also gave some general suggestions as design criteria fora new WN-like knowledge base and recommended that WN should be cleaned up to make it logically correct, but did not provide any practical method for doing so.", "labels": [], "entities": []}, {"text": "Two other more extensive works rely on manual interventions, either the mapping of each synset in WN to a particular concept in the SUMO ontology, or the tagging of each synset in WN with \"features\" from the Top Concept Ontology () to substitute or contrast the original WN taxonomy.", "labels": [], "entities": []}, {"text": "Such approaches are clearly very costly, as each synset needs to be examined.", "labels": [], "entities": []}, {"text": "In addition, the ontological value of these additional resources themselves remains to be proven.", "labels": [], "entities": []}, {"text": "The method used in ( has though helped pointing out a large number of errors in WN 1.6.", "labels": [], "entities": [{"text": "WN 1.6", "start_pos": 80, "end_pos": 86, "type": "DATASET", "confidence": 0.867504745721817}]}, {"text": "Our purpose in this paper is to show that automatic methods to spot errors, especially in the lower levels of WN's taxonomy, can be developed.", "labels": [], "entities": [{"text": "WN's taxonomy", "start_pos": 110, "end_pos": 123, "type": "DATASET", "confidence": 0.7333527406056722}]}, {"text": "Spotting errors can then efficiently direct the manual correction task.", "labels": [], "entities": [{"text": "manual correction", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.6304061263799667}]}, {"text": "Such methods could be used to complement a manual top-level restructuring and could be seen as an alternative to fully manual approaches, which are very demanding and in principle require validation between experts.", "labels": [], "entities": []}, {"text": "Here, we explore methods based on internal coherence checks within WN, or on checking the coherence between WN and annotated corpora such as those of.", "labels": [], "entities": []}, {"text": "The paper is structured as follows: Section 2 presents the data used and the methodology; Section 3 discusses the results; Section 4 concludes, exploring how the method could be extended and applied.", "labels": [], "entities": []}], "datasetContent": [{"text": "We started extracting WN taxonomy from the hypernym relations in the current version of WN (3.0), a network of 117,798 nouns grouped in 82,155 synsets.", "labels": [], "entities": []}, {"text": "We also extracted WN meronymy relations, i.e., 22,187 synset pairs, split into 12,293 \"member\", 9,097 \"part\" and 797 \"substance\", to constitute the first part-whole dataset.", "labels": [], "entities": []}, {"text": "In order to replicate our methodology, we also extracted 89 part-whole relation word pairs annotated with WN senses from the SemEval-2007 Task 4 datasets (.", "labels": [], "entities": [{"text": "SemEval-2007 Task 4 datasets", "start_pos": 125, "end_pos": 153, "type": "DATASET", "confidence": 0.7046709060668945}]}, {"text": "We kept the positive examples from the training and test datasets, 3 excluding redundant pairs, and correcting a couple of errors.", "labels": [], "entities": [{"text": "correcting", "start_pos": 100, "end_pos": 110, "type": "METRIC", "confidence": 0.9523422718048096}]}, {"text": "This data is also annotated with the meronymy sub-relations inspired from the classification of, but five subtypes instead of WN's three, although \"member-collection\" can safely be assumed to correspond to WN's \"member\" meronymy.", "labels": [], "entities": [{"text": "WN", "start_pos": 126, "end_pos": 128, "type": "DATASET", "confidence": 0.9099287986755371}, {"text": "WN", "start_pos": 206, "end_pos": 208, "type": "DATASET", "confidence": 0.9290842413902283}]}, {"text": "We will call this sub-relation Member, be it from WN or from SemEval.", "labels": [], "entities": []}, {"text": "We also tried to get similar datasets from the SemEval-2010 Task 8 but, not being annotated with WN senses, they are useless for our purposes.", "labels": [], "entities": [{"text": "SemEval-2010 Task 8", "start_pos": 47, "end_pos": 66, "type": "DATASET", "confidence": 0.6106472512086233}]}, {"text": "illustrates a WN-extracted meronymy pair from our corpus , encoded in our own xml format.", "labels": [], "entities": []}, {"text": "Synsets are presented with the standard WN sense keys for each word, the recommended reference for stability from one WN release to another.", "labels": [], "entities": []}, {"text": "5 <pair relationOrder=\"(e1, e2)\" comment=\"meronym part\" source=\"WordNet-3.0\"> <e1 synset=\"head%1:06:04\" isInstance=\"No\">", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of pairs extracted by the tests  Error Category Test  WordNet  SemEval  0  349 1.57% 0  0%  Semantic  4  550 4.47% 7 7.87%", "labels": [], "entities": [{"text": "WordNet  SemEval  0", "start_pos": 71, "end_pos": 90, "type": "DATASET", "confidence": 0.6640491088231405}]}]}