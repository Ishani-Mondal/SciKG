{"title": [], "abstractContent": [{"text": "This paper addresses the problem of summarizing decisions in spoken meetings: our goal is to produce a concise decision abstract for each meeting decision.", "labels": [], "entities": [{"text": "summarizing decisions in spoken meetings", "start_pos": 36, "end_pos": 76, "type": "TASK", "confidence": 0.8989065647125244}]}, {"text": "We explore and compare token-level and dialogue act-level automatic summarization methods using both unsupervised and supervised learning frameworks.", "labels": [], "entities": [{"text": "dialogue act-level automatic summarization", "start_pos": 39, "end_pos": 81, "type": "TASK", "confidence": 0.5426241457462311}]}, {"text": "In the supervised summarization setting , and given true clusterings of decision-related utterances, we find that token-level summaries that employ discourse context can approach an upper bound for decision abstracts derived directly from dialogue acts.", "labels": [], "entities": [{"text": "summarization", "start_pos": 18, "end_pos": 31, "type": "TASK", "confidence": 0.8543584942817688}]}, {"text": "In the unsupervised summarization setting,we find that summaries based on unsupervised partitioning of decision-related utterances perform comparably to those based on partitions generated using supervised techniques (0.22 ROUGE-F1 using LDA-based topic models vs. 0.23 using SVMs).", "labels": [], "entities": [{"text": "ROUGE-F1", "start_pos": 223, "end_pos": 231, "type": "METRIC", "confidence": 0.9796675443649292}]}], "introductionContent": [{"text": "Meetings area common way for people to share information and discuss problems.", "labels": [], "entities": []}, {"text": "And an effective meeting always leads to concrete decisions.", "labels": [], "entities": []}, {"text": "As a result, it would be useful to develop automatic methods that summarize not the entire meeting dialogue, but just the important decisions made.", "labels": [], "entities": []}, {"text": "In particular, decision summaries would allow participants to review decisions from previous meetings as they prepare for an upcoming meeting.", "labels": [], "entities": [{"text": "decision summaries", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.7189949750900269}]}, {"text": "For those who did not participate in the earlier meetings, decision summaries might provide one type of efficient overview of the meeting contents.", "labels": [], "entities": []}, {"text": "For managers, decision summaries could act as a concise record of the idea generation process.", "labels": [], "entities": [{"text": "decision summaries", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.6670869439840317}, {"text": "idea generation process", "start_pos": 70, "end_pos": 93, "type": "TASK", "confidence": 0.7786142925421397}]}, {"text": "While there has been some previous work in summarizing meetings and conversations, very little work has focused on decision summarization: and  investigate the use of a semantic parser and machine learning methods for phrase-and token-level decision summarization.", "labels": [], "entities": [{"text": "summarizing meetings and conversations", "start_pos": 43, "end_pos": 81, "type": "TASK", "confidence": 0.9115359783172607}, {"text": "decision summarization", "start_pos": 115, "end_pos": 137, "type": "TASK", "confidence": 0.8257587254047394}, {"text": "phrase-and token-level decision summarization", "start_pos": 218, "end_pos": 263, "type": "TASK", "confidence": 0.572832778096199}]}, {"text": "We believe our work is the first to explore and compare token-level and dialogue act-level approaches -using both unsupervised and supervised learning methods -for summarizing decisions in meetings.", "labels": [], "entities": [{"text": "summarizing decisions in meetings", "start_pos": 164, "end_pos": 197, "type": "TASK", "confidence": 0.8800985515117645}]}, {"text": "DECISION 2: The case will be flat on top and curved on the bottom.", "labels": [], "entities": [{"text": "DECISION", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.7085342407226562}]}, {"text": "DECISION 3: The remote control and its buttons will be made of rubber.", "labels": [], "entities": [{"text": "DECISION 3", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.8292287588119507}]}, {"text": "DECISION 4: The remote will resemble a vegetable and be in bright vegetable colors.: A clip of a meeting from the AMI meeting corpus ( . A, B, C and D refer to distinct speakers; the numbers in parentheses indicate the associated meeting decision: DECISION 1, 2, 3 or 4.", "labels": [], "entities": [{"text": "AMI meeting corpus", "start_pos": 114, "end_pos": 132, "type": "DATASET", "confidence": 0.9202463030815125}]}, {"text": "Also shown is the gold-standard (manual) abstract (summary) for each decision.", "labels": [], "entities": []}, {"text": "Consider the sample dialogue snippet in, which is part of the AMI meeting corpus ).", "labels": [], "entities": [{"text": "AMI meeting corpus", "start_pos": 62, "end_pos": 80, "type": "DATASET", "confidence": 0.9027938842773438}]}, {"text": "The only decision-related dialogue acts (DRDAs) -utterances associated with at least one decision made in the meeting.", "labels": [], "entities": []}, {"text": "The DRDAs are ordered by time; intervening utterances are not shown.", "labels": [], "entities": []}, {"text": "DRDAs are important because they contain critical information for decision summary construction.", "labels": [], "entities": [{"text": "DRDAs", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8438977599143982}, {"text": "decision summary construction", "start_pos": 66, "end_pos": 95, "type": "TASK", "confidence": 0.8392985661824545}]}, {"text": "clearly shows some challenges for decision summarization for spoken meetings beyond the disfluencies, high word error rates, absence of punctuation, interruptions and hesitations due to speech.", "labels": [], "entities": [{"text": "decision summarization", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.8279812932014465}, {"text": "word error rates", "start_pos": 107, "end_pos": 123, "type": "METRIC", "confidence": 0.7423134843508402}]}, {"text": "First, different decisions can be discussed more or less concurrently; as a result, the utterances associated with a single decision are not contiguous in the dialogue.", "labels": [], "entities": []}, {"text": "In, the dialogue acts (henceforth, DAs) concerning DECISION 1, for example, are interleaved with DAs for other decisions.", "labels": [], "entities": [{"text": "DECISION 1", "start_pos": 51, "end_pos": 61, "type": "TASK", "confidence": 0.822750985622406}]}, {"text": "Second, some decision-related DAs contribute more than others to the associated decision.", "labels": [], "entities": []}, {"text": "In composing the summary for DECISION 1, for example, we might safely ignore the first DA for DECISION 1.", "labels": [], "entities": [{"text": "DA", "start_pos": 87, "end_pos": 89, "type": "METRIC", "confidence": 0.8543094396591187}]}, {"text": "Finally, more so than for standard text summarization, purely extract-based summaries are not likely to be easily interpretable: DRDAs often contain text that is irrelevant to the decision and many will only be understandable if analyzed in the context of the surrounding utterances.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.6370582282543182}]}, {"text": "In this paper, we study methods for decision summarization for spoken meetings.", "labels": [], "entities": [{"text": "decision summarization", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.8522115647792816}]}, {"text": "We assume that all decision-related DAs have been identified and aim to produce a summary for the meeting in the form of concise decision abstracts (see), one for each decision made.", "labels": [], "entities": []}, {"text": "In response to the challenges described above, we propose a summarization framework that includes: Clustering of decision-related DAs.", "labels": [], "entities": []}, {"text": "Here we aim to partition the decision-related utterances (DRDAs) according to the decisions each supports.", "labels": [], "entities": []}, {"text": "This step is similar in spirit to many standard text summarization techniques () that begin by grouping sentences according to semantic similarity.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.7380008399486542}]}, {"text": "We select just the important DRDAs in each cluster.", "labels": [], "entities": []}, {"text": "Our goal is to eliminate redundant and less informative utterances.", "labels": [], "entities": []}, {"text": "The selected DRDAs are then concatenated to form the decision summary.", "labels": [], "entities": []}, {"text": "Optional token-level summarization of the selected DRDAs.", "labels": [], "entities": []}, {"text": "Methods are employed to capture concisely the gist of each decision, discarding any distracting text.", "labels": [], "entities": []}, {"text": "Incorporation of the discourse context as needed.", "labels": [], "entities": []}, {"text": "We hypothesize that this will produce more interpretable summaries.", "labels": [], "entities": []}, {"text": "More specifically, we compare both unsupervised (TFIDF () and LDA topic modeling () and (pairwise) supervised clustering procedures (using SVMs and MaxEnt) for partitioning DRDAs according to the decision each supports.", "labels": [], "entities": []}, {"text": "We also investigate unsupervised methods and supervised learning for decision summarization at both the DA and token level, with and without the incorporation of discourse context.", "labels": [], "entities": [{"text": "decision summarization", "start_pos": 69, "end_pos": 91, "type": "TASK", "confidence": 0.8184698820114136}]}, {"text": "During training, the supervised decision summarizers are told which DRDAs for each decision are the most informative for constructing the decision abstract.", "labels": [], "entities": []}, {"text": "Our experiments employ the aforementioned AMI meeting corpus: we compare our decision summaries to the manually generated decision abstracts for each meeting and evaluate performance using the ROUGE-1 () text summarization evaluation metric.", "labels": [], "entities": [{"text": "AMI meeting corpus", "start_pos": 42, "end_pos": 60, "type": "DATASET", "confidence": 0.7972569863001505}]}, {"text": "In the supervised summarization setting, our experiments demonstrate that with true clusterings of decision-related DAs, token-level summaries that employ limited discourse context can approach an upper bound for summaries extracted directly from DRDAs 2 -0.4387 ROUGE-F1 vs. 0.5333.", "labels": [], "entities": [{"text": "summarization", "start_pos": 18, "end_pos": 31, "type": "TASK", "confidence": 0.9061934351921082}, {"text": "ROUGE-F1", "start_pos": 263, "end_pos": 271, "type": "METRIC", "confidence": 0.750981330871582}]}, {"text": "When using system-generated DRDA clusterings, the DAlevel summaries always dominate token-level methods in terms of performance.", "labels": [], "entities": []}, {"text": "For the unsupervised summarization setting, we investigate the use of both unsupervised and supervised methods for the initial DRDA clustering step.", "labels": [], "entities": [{"text": "summarization", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.9587368369102478}, {"text": "DRDA clustering", "start_pos": 127, "end_pos": 142, "type": "TASK", "confidence": 0.6615258455276489}]}, {"text": "We find that summaries based on unsupervised clusterings perform comparably to those generated using supervised techniques (0.2214 ROUGE-F1 using LDA-based topic models vs. 0.2349 using SVMs).", "labels": [], "entities": [{"text": "ROUGE-F1", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9939181804656982}]}, {"text": "As in the supervised summarization setting, we observe that including additional discourse context boosts performance only for token-level summaries.", "labels": [], "entities": [{"text": "summarization", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.8823950886726379}]}], "datasetContent": [{"text": "Experiments based on supervised learning are performed using 3-fold cross-validation.", "labels": [], "entities": []}, {"text": "We train two different types of classifiers for identifying informative DAs or tokens: Conditional Random Fields (CRFs) (via Mallet) and Support Vector Machines (SVMs) (via SVM light ).", "labels": [], "entities": []}, {"text": "We remove function words from DAs before using them as the input of our systems.", "labels": [], "entities": []}, {"text": "The AMI decision abstracts are the gold-standard summaries.", "labels": [], "entities": []}, {"text": "We use the ROUGE (Lin and Hovy, 2003) evaluation measure.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 11, "end_pos": 16, "type": "METRIC", "confidence": 0.9969857335090637}]}, {"text": "ROUGE is a recall-based method that can identify systems producing succinct and descriptive summaries.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.8028944134712219}, {"text": "recall-based", "start_pos": 11, "end_pos": 23, "type": "METRIC", "confidence": 0.9932147264480591}]}, {"text": "Results for the unsupervised and supervised summarization methods are shown in, respectively.", "labels": [], "entities": [{"text": "summarization", "start_pos": 44, "end_pos": 57, "type": "TASK", "confidence": 0.9307016134262085}]}, {"text": "In the tables, TRUE CLUSTERINGS means that we apply our methods on the gold-standard DRDA clusterings.", "labels": [], "entities": [{"text": "TRUE", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.9981179237365723}, {"text": "CLUSTERINGS", "start_pos": 20, "end_pos": 31, "type": "METRIC", "confidence": 0.6626777648925781}, {"text": "DRDA clusterings", "start_pos": 85, "end_pos": 101, "type": "DATASET", "confidence": 0.8238870799541473}]}, {"text": "SYS-TEM CLUSTERINGS use clusterings obtained from the methods introduced in Section 4; we show re-sults only using the best unsupervised (USING LDA) and supervised (USING SVMS) DRDA clustering techniques.", "labels": [], "entities": [{"text": "USING SVMS) DRDA clustering", "start_pos": 165, "end_pos": 192, "type": "DATASET", "confidence": 0.6929362535476684}]}, {"text": "Both and 7 show that some attempt to cluster DRDAs improves the summarization results vs. NO CLUSTERING.", "labels": [], "entities": [{"text": "cluster DRDAs", "start_pos": 37, "end_pos": 50, "type": "TASK", "confidence": 0.5239510983228683}, {"text": "CLUSTERING", "start_pos": 93, "end_pos": 103, "type": "METRIC", "confidence": 0.8347076177597046}]}, {"text": "In, there is no significant difference between the results obtained from the LONGEST DA and PROTOTYPE DA for any experiment setting.", "labels": [], "entities": [{"text": "LONGEST DA", "start_pos": 77, "end_pos": 87, "type": "METRIC", "confidence": 0.770575225353241}]}, {"text": "This is because the longest DA is often selected as the prototype.", "labels": [], "entities": []}, {"text": "An UPPER BOUND result is listed for comparison: for each decision cluster, this system selects all words from the DRDAs that are part of the decision abstract (discarding duplicates).", "labels": [], "entities": [{"text": "UPPER", "start_pos": 3, "end_pos": 8, "type": "METRIC", "confidence": 0.8460118174552917}, {"text": "BOUND", "start_pos": 9, "end_pos": 14, "type": "METRIC", "confidence": 0.8261353373527527}]}, {"text": "presents the results for supervised summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 36, "end_pos": 49, "type": "TASK", "confidence": 0.8232297301292419}]}, {"text": "Rows starting with DA or TOKEN indicate results at the DA-or token-level.", "labels": [], "entities": [{"text": "DA", "start_pos": 19, "end_pos": 21, "type": "METRIC", "confidence": 0.8450424671173096}, {"text": "TOKEN", "start_pos": 25, "end_pos": 30, "type": "METRIC", "confidence": 0.7980084419250488}]}, {"text": "The +CON-TEXT rows show results when discourse context is included.", "labels": [], "entities": []}, {"text": "We see that: (1) SVMs have a superior or comparable summarization performance vs. CRFs on every task.", "labels": [], "entities": []}, {"text": "(2) Token-level summaries perform better than DA-level summaries only using TRUE CLUSTERINGS and the SVM-based summarizer.", "labels": [], "entities": [{"text": "Token-level summaries", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.6308268010616302}]}, {"text": "(3) Discourse context generally improves token-level summaries but not DA-level summaries.", "labels": [], "entities": []}, {"text": "9 (4) DRDA clusterings produced by (unsupervised) LDA lead to summaries that are quite comparable in quality to those generated from DRDA clusterings produced by SVMs (supervised).", "labels": [], "entities": [{"text": "DRDA clusterings", "start_pos": 6, "end_pos": 22, "type": "TASK", "confidence": 0.5623544156551361}]}, {"text": "From, we see that F1 is 0.2214 when choosing longest DAs from LDAgenerated clusterings, which is comparable with the F1s of 0.1935 and 0.2349, attained when employing CRF and SVMs on the same clusterings.", "labels": [], "entities": [{"text": "F1", "start_pos": 18, "end_pos": 20, "type": "METRIC", "confidence": 0.9997897744178772}, {"text": "F1s", "start_pos": 117, "end_pos": 120, "type": "METRIC", "confidence": 0.9957369565963745}]}, {"text": "The results in are achieved by comparing abstracts having function words with systemgenerated summaries without function words.", "labels": [], "entities": []}, {"text": "To reduce the vocabulary difference as much as possible, we also ran experiments that remove function words from the gold-standard abstracts, but no significant difference is observed.", "labels": [], "entities": []}, {"text": "Finally, we considered comparing our systems to the earlier similar work of and ), but found that it would be quite difficult because they employ a different notion from DRDAs which is Decision Dialogue Acts(DDAs).", "labels": [], "entities": [{"text": "Decision Dialogue Acts(DDAs)", "start_pos": 185, "end_pos": 213, "type": "TASK", "confidence": 0.7087545096874237}]}, {"text": "In addition, they manually annotate words from their DDAs as the gold-standard summary, guaranteeing that their decision summaries employ the same vocabulary as the DDAs.", "labels": [], "entities": []}, {"text": "We instead use the actual decision abstracts from the AMI corpus.", "labels": [], "entities": [{"text": "AMI corpus", "start_pos": 54, "end_pos": 64, "type": "DATASET", "confidence": 0.8846264481544495}]}], "tableCaptions": [{"text": " Table 3: Results for Clustering Decision-Related DAs According to the Decision Each Supports", "labels": [], "entities": []}, {"text": " Table 5: Features Used in Token-Level Summarization", "labels": [], "entities": [{"text": "Token-Level Summarization", "start_pos": 27, "end_pos": 52, "type": "TASK", "confidence": 0.8087854981422424}]}, {"text": " Table 6: Results for ROUGE-1: Decision Summary Gen- eration Using Unsupervised Methods", "labels": [], "entities": [{"text": "Decision Summary Gen- eration", "start_pos": 31, "end_pos": 60, "type": "TASK", "confidence": 0.7910227060317994}]}, {"text": " Table 7: Results for ROUGE-1: Summary Generation Using Supervised Learning", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 22, "end_pos": 29, "type": "METRIC", "confidence": 0.6995170712471008}, {"text": "Summary Generation", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.9716899693012238}]}]}