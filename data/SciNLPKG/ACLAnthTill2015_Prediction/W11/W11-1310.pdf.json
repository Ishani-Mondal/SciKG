{"title": [{"text": "Exemplar-based Word-Space Model for Compositionality Detection: Shared task system description", "labels": [], "entities": [{"text": "Compositionality Detection", "start_pos": 36, "end_pos": 62, "type": "TASK", "confidence": 0.901420533657074}]}], "abstractContent": [{"text": "In this paper, we highlight the problems of polysemy in word space models of compo-sitionality detection.", "labels": [], "entities": [{"text": "compo-sitionality detection", "start_pos": 77, "end_pos": 104, "type": "TASK", "confidence": 0.7104790657758713}]}, {"text": "Most models represent each word as a single prototype-based vector without addressing polysemy.", "labels": [], "entities": []}, {"text": "We propose an exemplar-based model which is designed to handle polysemy.", "labels": [], "entities": []}, {"text": "This model is tested for compositionality detection and it is found to outperform existing prototype-based models.", "labels": [], "entities": [{"text": "compositionality detection", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.9638785421848297}]}, {"text": "We have participated in the shared task (Bie-mann and Giesbrecht, 2011) and our best performing exemplar-model is ranked first in two types of evaluations and second in two other evaluations.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the field of computational semantics, to represent the meaning of a compound word, two mechanisms are commonly used.", "labels": [], "entities": []}, {"text": "One is based on the distributional hypothesis and the other is on the principle of semantic compositionality.", "labels": [], "entities": []}, {"text": "The distributional hypothesis (DH) states that words that occur in similar contexts tend to have similar meanings.", "labels": [], "entities": []}, {"text": "Using this hypothesis, distributional models like the Word-space model) represent a target word's meaning as a context vector (location in space).", "labels": [], "entities": []}, {"text": "The similarity between two meanings is the closeness (proximity) between the vectors.", "labels": [], "entities": []}, {"text": "The context vector of a target word is built from its distributional behaviour observed in a corpus.", "labels": [], "entities": []}, {"text": "Similarly, the context vector of a compound word can be built by treating the compound as a single word.", "labels": [], "entities": []}, {"text": "We refer to such a vector as a DH-based vector.", "labels": [], "entities": []}, {"text": "The other mechanism is based on the principle of semantic compositionality (PSC) which states that the meaning of a compound word is a function of, and only of, the meaning of its parts and the way in which the parts are combined.", "labels": [], "entities": [{"text": "semantic compositionality (PSC)", "start_pos": 49, "end_pos": 80, "type": "TASK", "confidence": 0.8264163136482239}]}, {"text": "If the meaning of apart is represented in a WSM using the distributional hypothesis, then the principle can be applied to compose the distributional behaviour of a compound word from its parts without actually using the corpus instances of the compound.", "labels": [], "entities": []}, {"text": "We refer to this as a PSC-based vector.", "labels": [], "entities": []}, {"text": "So a PSC-based is composed of component DH-based vectors.", "labels": [], "entities": []}, {"text": "Both of these two mechanisms are capable of determining the meaning vector of a compound word.", "labels": [], "entities": []}, {"text": "For a given compound, if a DH-based vector and a PSC-based vector of the compound are projected into an identical space, one would expect the vectors to occupy the same location i.e. both the vectors should be nearly the same.", "labels": [], "entities": []}, {"text": "However the principle of semantic compositionality does not hold for noncompositional compounds, which is actually what the existing WSMs of compositionality detection exploit).", "labels": [], "entities": [{"text": "WSMs of compositionality detection", "start_pos": 133, "end_pos": 167, "type": "TASK", "confidence": 0.7992053180932999}]}, {"text": "The DH-based and PSC-based vectors are expected to have high similarity when a compound is compositional and low similarity for non-compositional compounds.", "labels": [], "entities": []}, {"text": "Most methods in WSM (Turney and Pantel, 2010) represent a word as a single context vector built from merging all its corpus instances.", "labels": [], "entities": []}, {"text": "Such a representation is called the prototype-based modelling).", "labels": [], "entities": []}, {"text": "These prototype-based vectors do not distinguish the instances according to the senses of a target word.", "labels": [], "entities": []}, {"text": "Since most compounds are less ambiguous than single words, there is less need for distinguishing instances in a DH-based prototype vector of a compound and we do not address that here but leave ambiguity of compounds for future work.", "labels": [], "entities": []}, {"text": "However the constituent words of the compound are more ambiguous.", "labels": [], "entities": []}, {"text": "When DH-based vectors of the constituent words are used for composing the PSCbased vector of the compound, the resulting vector may contain instances, and therefore contexts, that are not relevant for the given compound.", "labels": [], "entities": []}, {"text": "These noisy contexts effect the similarity between the PSCbased vector and the DH-based vector of the compound.", "labels": [], "entities": []}, {"text": "Basing compositionality judgements on a such a noisy similarity value is no longer reliable.", "labels": [], "entities": []}, {"text": "In this paper, we address this problem of polysemy of constituent words of a compound using an exemplar-based modelling.", "labels": [], "entities": []}, {"text": "In exemplar-based modelling of WSM, each word is represented by all its corpus instances (exemplars) without merging them into a single vector.", "labels": [], "entities": [{"text": "WSM", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.6559402346611023}]}, {"text": "Depending upon the purpose, only relevant exemplars of the target word are activated and then these are merged to form a refined prototype-vector which is less-noisy compared to the original prototype-vector.", "labels": [], "entities": []}, {"text": "Exemplar-based models are more powerful than prototype-based ones because they retain specific instance information.", "labels": [], "entities": []}, {"text": "We have evaluated our models on the validation data released in the shared task).", "labels": [], "entities": []}, {"text": "Based on the validation results, we have chosen three systems for public evaluation and participated in the shared task).", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Average Point Difference (APD) and Av- erage Accuracy (Acc.) of Compositionality Judge- ments", "labels": [], "entities": [{"text": "Average Point Difference (APD)", "start_pos": 10, "end_pos": 40, "type": "METRIC", "confidence": 0.9307370086510977}, {"text": "Av- erage Accuracy (Acc.) of Compositionality Judge- ments", "start_pos": 45, "end_pos": 103, "type": "METRIC", "confidence": 0.8081646511952082}]}, {"text": " Table 3: Average Point Difference Scores", "labels": [], "entities": [{"text": "Average Point Difference Scores", "start_pos": 10, "end_pos": 41, "type": "METRIC", "confidence": 0.8477105498313904}]}, {"text": " Table 4: Coarse Grained Accuracy", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.8615593314170837}]}]}