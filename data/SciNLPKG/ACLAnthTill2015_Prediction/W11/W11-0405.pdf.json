{"title": [{"text": "Consistency Maintenance in Prosodic Labeling for Reliable Prediction of Prosodic Breaks", "labels": [], "entities": [{"text": "Consistency Maintenance", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8491740822792053}, {"text": "Prosodic Labeling", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.8066026568412781}, {"text": "Reliable Prediction of Prosodic Breaks", "start_pos": 49, "end_pos": 87, "type": "TASK", "confidence": 0.7567784070968628}]}], "abstractContent": [{"text": "For the implementation of the prosody prediction model, large scale annotated speech corpora have been widely applied.", "labels": [], "entities": [{"text": "prosody prediction", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.9164006114006042}]}, {"text": "Reliability among transcribers, however, was too low for successful learning of an automatic prosodic prediction.", "labels": [], "entities": [{"text": "Reliability", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9728905558586121}]}, {"text": "This paper reveals our observations on performance deterioration of the learning model due to inconsistent tagging of prosodic breaks in the established corpora.", "labels": [], "entities": []}, {"text": "Then, we suggest a method for consistent prosodic labeling among multiple transcribers.", "labels": [], "entities": [{"text": "prosodic labeling", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.6308825612068176}]}, {"text": "As a result, we obtain a corpus with consistent annotation of prosodic breaks.", "labels": [], "entities": []}, {"text": "The estimated pairwise agreement of annotation of the main corpus is between 0.7477 and 0.7916, and the value of K is between 0.7057 and 0.7569.", "labels": [], "entities": [{"text": "agreement", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9395082592964172}, {"text": "K", "start_pos": 113, "end_pos": 114, "type": "METRIC", "confidence": 0.9884759187698364}]}, {"text": "Considering the estimated K, annotation of the main corpus has reliable consistency among multiple transcribers.", "labels": [], "entities": []}], "introductionContent": [{"text": "The naturalness and comprehensibility of text-tospeech (TTS) synthesis systems are strongly affected by the accuracy of prosody prediction from text input.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.997351884841919}, {"text": "prosody prediction", "start_pos": 120, "end_pos": 138, "type": "TASK", "confidence": 0.634392574429512}]}, {"text": "For the implementation of the prosody prediction model, large annotated speech corpora have been widely applied to both linguistic research and speech processing technologies as in.", "labels": [], "entities": [{"text": "prosody prediction", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.8801615834236145}]}, {"text": "Since an increasing number of annotated speech corpora become available, a number of self-learning or probabilistic models for prosodic prediction have been suggested.", "labels": [], "entities": [{"text": "prosodic prediction", "start_pos": 127, "end_pos": 146, "type": "TASK", "confidence": 0.7486605644226074}]}, {"text": "To obtain reliable results from data-driven models, the corpus must be large scale, noise-free and annotated consistently.", "labels": [], "entities": []}, {"text": "However, due to the limited range of tagged data with prosodic breaks that is used to learn or establish stochastic models at present, reliable results cannot be obtained.", "labels": [], "entities": []}, {"text": "Thus, the reliability among transcribers was too low for successful learning of a prosodic model.", "labels": [], "entities": [{"text": "reliability", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9956477284431458}]}, {"text": "In addition, the performance of ASR systems degrades significantly when training data are limited or noisy as in.", "labels": [], "entities": [{"text": "ASR", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.9908662438392639}]}, {"text": "In this study we propose anew methodology of training transcribers, annotating a corpus by multiple transcribers, and validating the reliability of intertranscriber agreement.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: we review related work on corpus annotation for speech and language processing tasks and method of measuring the reliability of consistency among multiple annotators in Section 2.", "labels": [], "entities": []}, {"text": "Section 3 describes our observations on performance deterioration of the learning model due to inconsistent tagging of prosodic breaks in the established corpora.", "labels": [], "entities": []}, {"text": "In Section 4, we suggest a procedure of constructing a medium-scale corpus, which are aimed at maintaining consistency in prosodic labeling among multiple annotators.", "labels": [], "entities": []}, {"text": "Through a series of experiments during the training phase, the improvement of the agreement of multiple annotators is shown.", "labels": [], "entities": [{"text": "agreement", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.9577421545982361}]}, {"text": "The final experiment is performed in order to guarantee labeling agreement among five annotators.", "labels": [], "entities": []}, {"text": "A brief summary and future work are presented in the final section.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1 Size of Training and Test data", "labels": [], "entities": [{"text": "Size", "start_pos": 9, "end_pos": 13, "type": "TASK", "confidence": 0.9855857491493225}]}, {"text": " Table 2 Experimental Results for Impact Analysis of  Inconsistent Tagging", "labels": [], "entities": [{"text": "Impact Analysis of  Inconsistent Tagging", "start_pos": 34, "end_pos": 74, "type": "TASK", "confidence": 0.8257199645042419}]}, {"text": " Table 4 Data used in intertranscribers training", "labels": [], "entities": []}, {"text": " Table 5 Intertranscriber agreement in training", "labels": [], "entities": []}, {"text": " Table 6 Estimated accuracy of each transcriber", "labels": [], "entities": [{"text": "Estimated", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.9827463626861572}, {"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9005265831947327}]}, {"text": " Table 7 Reliability of intertranscriber agreement", "labels": [], "entities": []}, {"text": " Table 8 Size of resultant corpus", "labels": [], "entities": []}]}