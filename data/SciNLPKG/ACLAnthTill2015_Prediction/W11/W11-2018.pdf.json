{"title": [{"text": "Detecting Levels of Interest from Spoken Dialog with Multistream Prediction Feedback and Similarity Based Hierarchical Fusion Learning", "labels": [], "entities": []}], "abstractContent": [{"text": "Detecting levels of interest from speakers is anew problem in Spoken Dialog Understanding with significant impact on real world business applications.", "labels": [], "entities": [{"text": "Spoken Dialog Understanding", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.9359293182690939}]}, {"text": "Previous work has fo-cused on the analysis of traditional acoustic signals and shallow lexical features.", "labels": [], "entities": []}, {"text": "In this paper, we present a novel hierarchical fusion learning model that takes feedback from previous multistream predictions of prominent seed samples into account and uses a mean cosine similarity measure to learn rules that improve reclassification.", "labels": [], "entities": []}, {"text": "Our method is domain-independent and can be adapted to other speech and language processing areas where domain adaptation is expensive to perform.", "labels": [], "entities": []}, {"text": "Incorporating Discriminative Term Frequency and Inverse Document Frequency (D-TFIDF), lexical affect scoring, and low and high level prosodic and acoustic features, our experiments outperform the published results of all systems participating in the 2010 Inter-speech Paralinguistic Affect Subchallenge.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, there has been growing interest in identifying speakers' emotional state from speech (;).", "labels": [], "entities": [{"text": "identifying speakers' emotional state from speech", "start_pos": 52, "end_pos": 101, "type": "TASK", "confidence": 0.8037767012914022}]}, {"text": "For Spoken Dialog Systems (SDS), the motivation has been to provide users with improved over-the-phone services by recognizing emotions such as anger and frustration and directing users to a human attendant.", "labels": [], "entities": [{"text": "Spoken Dialog Systems (SDS)", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.8476570049921671}]}, {"text": "Other forms of paralinguistic information which researchers have attempted to detect automatically include other classic emotions, charismatic speech (, and deceptive speech ().", "labels": [], "entities": []}, {"text": "More recently, the 2010 Interspeech Paralinguisic Affect Subchallenge sparked interest in detecting a speaker's level of interest (LOI), including both the speaker's interest in the topic and his/her willingness to participating in the dialog (.", "labels": [], "entities": [{"text": "detecting a speaker's level of interest (LOI)", "start_pos": 90, "end_pos": 135, "type": "METRIC", "confidence": 0.5504516631364822}]}, {"text": "Sensing users' LOI in SDS should be useful in sales domains, political polling, or service subscription.", "labels": [], "entities": [{"text": "LOI", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.918332040309906}]}, {"text": "In this paper, we present a similarity-based hierarchical regression approach to predicting speakers' LOI.", "labels": [], "entities": [{"text": "predicting speakers' LOI", "start_pos": 81, "end_pos": 105, "type": "TASK", "confidence": 0.6560625036557516}]}, {"text": "The system has been developed based on the hierarchical fusion learning of lexical and acoustic cues from speech.", "labels": [], "entities": []}, {"text": "We investigate the contribution of a novel source of information, Discriminative TFIDF; lexical affect scoring; and prosodic event features.", "labels": [], "entities": []}, {"text": "Inspired by the successful use of Pseudo Relevance Feedback () techniques in Information Retrieval and the cosine similarity measure) in Data Mining, we design a novel learning model which takes the multistream prediction feedback that is initially returned from seed samples and uses a mean cosine similarity measure to calculate the distance between the new instance and prominent seed data points in the Euclidean Space.", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 77, "end_pos": 98, "type": "TASK", "confidence": 0.7642452716827393}, {"text": "Data Mining", "start_pos": 137, "end_pos": 148, "type": "TASK", "confidence": 0.6888122409582138}]}, {"text": "We then add this similarity measure as anew feature to perform a reclassification.", "labels": [], "entities": []}, {"text": "Our main contributions in this paper are: (1) the novel Discriminative TFIDF approach for lexical modeling and keywords spotting; (2) using lexical affect scoring and language modeling techniques to augment lexical modeling; (3) combin-ing (1) and (2) with additional low-level prosodic features together with voice quality and high-level prosodic event features; and (4) introducing a multistream prediction feedback and mean cosine similarity based fusion learning approach.", "labels": [], "entities": [{"text": "keywords spotting", "start_pos": 111, "end_pos": 128, "type": "TASK", "confidence": 0.7543675899505615}]}, {"text": "We outline related work in Section 2.", "labels": [], "entities": []}, {"text": "The corpus, system features, and machine learning approaches are described in Section 3.", "labels": [], "entities": []}, {"text": "We describe our experimental results in Section 4 and conclude in Section 5. were among the first to study LOI from conversational speech.", "labels": [], "entities": []}, {"text": "They framed this task as either a three-way or binary classification, extracting standard acoustic features and building a bag-of-words vector space model for lexical analysis.", "labels": [], "entities": []}, {"text": "By linearly combining lexical features with acoustic features, they achieved high F-measures when using Support Vector Machine (SVM).", "labels": [], "entities": [{"text": "F-measures", "start_pos": 82, "end_pos": 92, "type": "METRIC", "confidence": 0.998658299446106}]}, {"text": "Since a bag-of-words model is a naive model, there maybe more valuable lexical information that it cannot capture.", "labels": [], "entities": []}, {"text": "Moreover, as lexical and acoustic features are extracted from different domains, a single layer linear combination may not yield the optimal results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conduct our experiments in three parts.", "labels": [], "entities": []}, {"text": "First, we examine how well the Discriminative TFIDF feature performs, compared with standard TFIDF feature.", "labels": [], "entities": []}, {"text": "Secondly, we look at how different feature sets influence our results.", "labels": [], "entities": []}, {"text": "For the first two parts, we evaluate our features using the Subchallenge training vs. development sets only.", "labels": [], "entities": []}, {"text": "Finally, we compare our similarity based multistream fusion feedback approach to other feature-combining approaches.", "labels": [], "entities": []}, {"text": "We examine our final system first comparing training vs. development performance, and then combined training and development sets vs. the test set.", "labels": [], "entities": []}, {"text": "WEKA) and LIBSVM) are used for regression.", "labels": [], "entities": [{"text": "WEKA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7500126957893372}, {"text": "LIBSVM", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.8410686254501343}]}, {"text": "When working with the training and development sets, we are able to access the label and transcriptions of each set to calculate the Discriminative TFIDF scores.", "labels": [], "entities": []}, {"text": "For the testing scenario discussed in in Section 4.3, we do not have these annotations.", "labels": [], "entities": []}, {"text": "So, we redefine the task as a keyword spotting task, where we can use the identified keywords in the training and development sets as keyword features in testing.", "labels": [], "entities": [{"text": "keyword spotting task", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.781125028928121}]}, {"text": "We also sum up the word-level TFIDF scores and use the sentence-level TFIDF as a single feature for the classification experiment.", "labels": [], "entities": []}, {"text": "The regression algorithm we use is Additive Logistic Regression with 50 iterations.", "labels": [], "entities": []}, {"text": "shows how different approaches perform in the experiment.", "labels": [], "entities": []}, {"text": "We see that the Syntactic Discriminative TFIDF approach is much more informative than the standard TFIDF approach.", "labels": [], "entities": [{"text": "Syntactic Discriminative TFIDF", "start_pos": 16, "end_pos": 46, "type": "TASK", "confidence": 0.8086816271146139}]}, {"text": "Note that, after calculating the global IDF score, the standard TFIDF approach selects 732 terms as top-1 level keywords.", "labels": [], "entities": [{"text": "IDF score", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9087126851081848}]}, {"text": "In contrast, our Discriminative TFIDF has stronger discriminative power and picks a total number of 59 truly rare terms as top-1 level keywords.  and prosodic features are the dominating features in this task.", "labels": [], "entities": []}, {"text": "The Prosodic Events feature stream also emerges as anew informative high-level prosodic feature in this task.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Single TFIDF Feature Stream Single Re- gression Results (Train vs. Develop, Additive Logis- tic Regression). D-TFIDF: Discriminative TFIDF. S-D- TFIDF: the POS tagged version of D-TFIDF. CC: Cross  Correlation. MLE: Mean Linear Error.", "labels": [], "entities": [{"text": "MLE", "start_pos": 221, "end_pos": 224, "type": "METRIC", "confidence": 0.9838825464248657}, {"text": "Mean Linear Error", "start_pos": 226, "end_pos": 243, "type": "METRIC", "confidence": 0.926766037940979}]}, {"text": " Table 3: Comparing Contributions of Different Fea- ture Streams in the 2nd-tier Classifier (Training vs. De- velopmen, Random Subspace for the 1st-tier classifier of  Acoustic Stream, and Additive Logistic Regression for  other 1st-tier classifiers. Radial Basis Function (RBF)  Kernel SVM as 2nd-tier Classifier.) S-D-TFIDF: the POS  tagged version of D-TFIDF. VQ: Voice Quality. n: Top-n  Feedback. CC: Cross Correlation. MLE: Mean Linear  Error.", "labels": [], "entities": [{"text": "MLE", "start_pos": 425, "end_pos": 428, "type": "METRIC", "confidence": 0.977610170841217}, {"text": "Mean Linear  Error", "start_pos": 430, "end_pos": 448, "type": "METRIC", "confidence": 0.9262219071388245}]}, {"text": " Table 4: Comparing Different Systems. Above: Train- ing vs. Development. Bottom: Combined Training+ De- velopment vs. Test. CC: Cross Correlation. MLE: Mean  Linear Error.", "labels": [], "entities": [{"text": "Train- ing", "start_pos": 46, "end_pos": 56, "type": "METRIC", "confidence": 0.7443719704945883}, {"text": "Test", "start_pos": 119, "end_pos": 123, "type": "METRIC", "confidence": 0.6426274180412292}, {"text": "MLE", "start_pos": 148, "end_pos": 151, "type": "METRIC", "confidence": 0.9901925325393677}, {"text": "Mean  Linear Error", "start_pos": 153, "end_pos": 171, "type": "METRIC", "confidence": 0.9149235288302103}]}]}