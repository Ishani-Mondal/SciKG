{"title": [{"text": "Morphemes and POS tags for n-gram based evaluation metrics", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose the use of morphemes for automatic evaluation of machine translation output , and systematically investigate a set of F score and BLEU score based metrics calculated on words, morphemes and POS tags along with all corresponding combinations.", "labels": [], "entities": [{"text": "machine translation output", "start_pos": 60, "end_pos": 86, "type": "TASK", "confidence": 0.7750440239906311}, {"text": "F score", "start_pos": 129, "end_pos": 136, "type": "METRIC", "confidence": 0.9898750483989716}, {"text": "BLEU score based metrics", "start_pos": 141, "end_pos": 165, "type": "METRIC", "confidence": 0.9619552493095398}]}, {"text": "Correlations between the new metrics and human judgments are calculated on the data of the third, fourth and fifth shared tasks of the Statistical Machine Translation Workshop.", "labels": [], "entities": [{"text": "Statistical Machine Translation Workshop", "start_pos": 135, "end_pos": 175, "type": "TASK", "confidence": 0.8564121574163437}]}, {"text": "Machine translation outputs in five different European languages are used: English, Spanish, French, German and Czech.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6814010441303253}]}, {"text": "The results show that the F scores which take into account morphemes and POS tags are the most promising metrics.", "labels": [], "entities": [{"text": "F", "start_pos": 26, "end_pos": 27, "type": "METRIC", "confidence": 0.9980074763298035}]}], "introductionContent": [{"text": "Recent investigations have shown that the n-gram based evaluation metrics calculated on Part-ofSpeech (POS) sequences correlate very well with human judgments clearly outperforming the widely used metrics BLEU and TER.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 205, "end_pos": 209, "type": "METRIC", "confidence": 0.9945982694625854}, {"text": "TER", "start_pos": 214, "end_pos": 217, "type": "METRIC", "confidence": 0.9819814562797546}]}, {"text": "The BLEU score measured on morphemes is shown to be useful for evaluation of morphologically rich languages ().", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9678439497947693}]}, {"text": "We propose the use of morphemes fora set of n-gram based automatic evaluation metrics and investigate the correlation of the novel metrics with human judgments.", "labels": [], "entities": []}, {"text": "We carryout a systematic comparison between the F and BLEU based metrics calculated on various combinations of words, morphemes and POS tags.", "labels": [], "entities": [{"text": "F", "start_pos": 48, "end_pos": 49, "type": "METRIC", "confidence": 0.9392085671424866}, {"text": "BLEU", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.9681692719459534}]}, {"text": "The focus of this work is not a comparison of the morpheme and POS based metrics with the standard evaluation metrics 1 as in), but rather a comparison within the proposed set of metrics in order to decide which score(s) should be submitted to the WMT 2011 evaluation task.", "labels": [], "entities": [{"text": "WMT 2011 evaluation task", "start_pos": 248, "end_pos": 272, "type": "TASK", "confidence": 0.6368920356035233}]}, {"text": "There are fifteen evaluation metrics in total, which can be divided in three groups: the metrics calculated on single units, i.e. words, morphemes or POS tags alone, the metrics calculated on pairs, i.e. words and POS tags, words and morphemes as well as morphemes and POS tags, and the metrics which take everything into account -lexical, morphological and syntactic information, i.e. words, morphemes and POS tags.", "labels": [], "entities": []}, {"text": "Spearman's rank correlation coefficients on the document (system) level between all the metrics and the human ranking are computed on the English, French, Spanish, German and Czech texts generated by various translation systems in the framework of the third, fourth) and fifth) shared translation tasks.", "labels": [], "entities": []}], "datasetContent": [{"text": "We carried out a systematic comparison between the following metrics: \u2022 single unit (word/morpheme/POS) metrics: Standard F score: takes into account all word n-grams which have a counterpart both in the corresponding reference and in the hypothesis.", "labels": [], "entities": [{"text": "Standard F score", "start_pos": 113, "end_pos": 129, "type": "METRIC", "confidence": 0.8402312795321146}]}, {"text": "-MORPHF Morpheme F score: takes into account all morpheme n-grams which have a counterpart both in the corresponding reference and in the hypothesis.", "labels": [], "entities": [{"text": "MORPHF Morpheme F score", "start_pos": 1, "end_pos": 24, "type": "METRIC", "confidence": 0.7977539747953415}]}, {"text": "-POSF POS F score: takes into account all POS n-grams which have a counterpart both in the corresponding reference and in the hypothesis.", "labels": [], "entities": [{"text": "POSF POS F score", "start_pos": 1, "end_pos": 17, "type": "METRIC", "confidence": 0.7840811461210251}]}, {"text": "- The standard BLEU score ().", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 15, "end_pos": 25, "type": "METRIC", "confidence": 0.9727143943309784}]}, {"text": "The standard BLEU score calculated on POS tags.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 13, "end_pos": 23, "type": "METRIC", "confidence": 0.9690971076488495}, {"text": "POS tags", "start_pos": 38, "end_pos": 46, "type": "DATASET", "confidence": 0.8033833503723145}]}, {"text": "- The standard BLEU score calculated on morphemes.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 15, "end_pos": 25, "type": "METRIC", "confidence": 0.9790008962154388}]}, {"text": "\u2022 pairwise metrics: -WPF F score of word and POS n-grams.", "labels": [], "entities": [{"text": "WPF", "start_pos": 21, "end_pos": 24, "type": "METRIC", "confidence": 0.9790716767311096}, {"text": "F score", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.901460200548172}]}, {"text": "-WMF F score of word and morpheme n-grams.", "labels": [], "entities": [{"text": "WMF F score", "start_pos": 1, "end_pos": 12, "type": "METRIC", "confidence": 0.8313693404197693}]}, {"text": "-MPF F score of morpheme and POS n-grams.", "labels": [], "entities": [{"text": "F score", "start_pos": 5, "end_pos": 12, "type": "METRIC", "confidence": 0.8620534837245941}]}, {"text": "\u2022 metrics taking everything into account: -WMPF F score on word, morpheme and POS ngrams.", "labels": [], "entities": [{"text": "WMPF", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9027218818664551}, {"text": "F score", "start_pos": 48, "end_pos": 55, "type": "METRIC", "confidence": 0.8888518214225769}]}, {"text": "-WMPBLEU Arithmetic mean of BLEU, MORPHBLEU and POSBLEU scores.", "labels": [], "entities": [{"text": "WMPBLEU Arithmetic mean", "start_pos": 1, "end_pos": 24, "type": "METRIC", "confidence": 0.7629425923029581}, {"text": "BLEU", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.9857760071754456}, {"text": "MORPHBLEU", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9814292192459106}, {"text": "POSBLEU", "start_pos": 48, "end_pos": 55, "type": "METRIC", "confidence": 0.8912161588668823}]}, {"text": "-WMPFBLEU Arithmetic mean of all F and BLEU scores.", "labels": [], "entities": [{"text": "WMPFBLEU Arithmetic mean", "start_pos": 1, "end_pos": 25, "type": "METRIC", "confidence": 0.8161264459292094}, {"text": "F", "start_pos": 33, "end_pos": 34, "type": "METRIC", "confidence": 0.9667373299598694}, {"text": "BLEU", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9202225804328918}]}, {"text": "The prerequisite for POS based metrics is availability of an appropriate POS tagger for the target language.", "labels": [], "entities": []}, {"text": "It should be noted that the POS tags cannot be only basic but must have all details (e.g. verb tenses, cases, number, gender, etc.).", "labels": [], "entities": []}, {"text": "For the morpheme based metrics, a tool for splitting words into morphemes is necessary.", "labels": [], "entities": []}, {"text": "All the F scores and the BLEU scores are based on four-grams (i.e. the value of maximal n is 4).", "labels": [], "entities": [{"text": "F scores", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9684804081916809}, {"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9991872906684875}]}, {"text": "Preliminary experiments on the morpheme based measures showed that there is no improvement by using six-grams, seven-grams or eight-grams.", "labels": [], "entities": []}, {"text": "As for the n-gram averaging, BLEU scores use geometric mean.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 29, "end_pos": 33, "type": "METRIC", "confidence": 0.9980970025062561}]}, {"text": "However, it is also argued not to be optimal because the score becomes equal to zero even if only one of the n-gram counts is equal to zero.", "labels": [], "entities": []}, {"text": "In addition, previous experiments on the syntax-oriented n-gram metrics showed that there is no significant difference between arithmetic and geometric mean in the terms of correlation coefficients.", "labels": [], "entities": []}, {"text": "Therefore, arithmetic averaging without weights is used for all F-scores.", "labels": [], "entities": []}, {"text": "For the WMPF score, an additional experiment with weights is carried out as well.", "labels": [], "entities": [{"text": "WMPF score", "start_pos": 8, "end_pos": 18, "type": "DATASET", "confidence": 0.5080027282238007}]}, {"text": "Experimental set-up The evaluation metrics were compared with human rankings by means of Spearman correlation coefficients \u03c1.", "labels": [], "entities": [{"text": "Spearman correlation coefficients \u03c1", "start_pos": 89, "end_pos": 124, "type": "METRIC", "confidence": 0.7366839125752449}]}, {"text": "Spearman's rank correlation coefficient is equivalent to Pearson correlation on ranks, and its advantage is that it makes fewer assumptions about the data.", "labels": [], "entities": [{"text": "rank correlation coefficient", "start_pos": 11, "end_pos": 39, "type": "METRIC", "confidence": 0.7151325245698293}, {"text": "Pearson correlation", "start_pos": 57, "end_pos": 76, "type": "METRIC", "confidence": 0.9296742379665375}]}, {"text": "The possible values of \u03c1 range between 1 (if all systems are ranked in the same order) and -1 (if all systems are ranked in the reverse order).", "labels": [], "entities": []}, {"text": "Thus the higher the value of \u03c1 for an automatic metric, the more similar is to the human metric.", "labels": [], "entities": []}, {"text": "The scores were calculated for outputs of translations from Spanish, French, German and Czech into English and vice versa.", "labels": [], "entities": []}, {"text": "Spanish, French, German and English POS tags were produced using the TreeTagger 2 , and the Czech texts are tagged using the COMPOST tagger.", "labels": [], "entities": []}, {"text": "In this way, all references and hypotheses were provided with detailed POS tags.", "labels": [], "entities": []}, {"text": "The words of all outputs were split into morphemes using the Morfessor tool).", "labels": [], "entities": []}, {"text": "The tool is corpus-based and languageindependent: it takes a text as input and produces a segmentation of the word forms observed in the text.", "labels": [], "entities": []}, {"text": "The obtained results are not strictly linguistic, however they often resemble a linguistic morpheme segmentation.", "labels": [], "entities": []}, {"text": "Once a morpheme segmentation has been learnt from some text, it can be used for segmenting new texts.", "labels": [], "entities": [{"text": "segmenting new texts", "start_pos": 80, "end_pos": 100, "type": "TASK", "confidence": 0.8598729173342387}]}, {"text": "In our experiments, for each document, first a corresponding reference translation has been split, and then this segmentation is used for splitting all translation hypotheses.", "labels": [], "entities": []}, {"text": "In this way, possible discrepancies between reference and hypothesis segmentation of the same word are avoided.", "labels": [], "entities": []}, {"text": "Effects of the training on the large(r) monolingual corpora have not been investigated yet.", "labels": [], "entities": []}, {"text": "In, an English reference sentence can be seen along with its morpheme and POS equivalents.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Average correlation mean (column 1), rank>  (column 2) and rank\u2265 (column 3) for each evaluation  metric. Bold represents the best value in the particu- lar metric group. The most promising metrics are the  F scores containing POS and morpheme information,  namely WMPF', MPF and POSF, as well as the POSBLEU  score. The standard BLEU score has very low values.", "labels": [], "entities": [{"text": "Average correlation mean", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.7648725907007853}, {"text": "F", "start_pos": 216, "end_pos": 217, "type": "METRIC", "confidence": 0.94901442527771}, {"text": "BLEU", "start_pos": 339, "end_pos": 343, "type": "METRIC", "confidence": 0.9982032775878906}]}]}