{"title": [{"text": "Semantic Mapping Using Automatic Word Alignment and Semantic Role Labeling", "labels": [], "entities": [{"text": "Semantic Mapping", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9045937061309814}, {"text": "Word Alignment", "start_pos": 33, "end_pos": 47, "type": "TASK", "confidence": 0.6597587168216705}, {"text": "Semantic Role Labeling", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.6931879123051962}]}], "abstractContent": [{"text": "To facilitate the application of semantics in statistical machine translation, we propose a broad-coverage predicate-argument structure mapping technique using automated resources.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 46, "end_pos": 77, "type": "TASK", "confidence": 0.6865628262360891}, {"text": "broad-coverage predicate-argument structure mapping", "start_pos": 92, "end_pos": 143, "type": "TASK", "confidence": 0.6269702464342117}]}, {"text": "Our approach utilizes automatic syntactic and semantic parsers to generate Chinese-English predicate-argument structures.", "labels": [], "entities": []}, {"text": "The system produced a many-to-many argument mapping for all PropBank argument types by computing argument similarity based on automatic word alignment, achieving 80.5% F-score on numbered argument mapping and 64.6% F-score on all arguments.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 136, "end_pos": 150, "type": "TASK", "confidence": 0.6972529888153076}, {"text": "F-score", "start_pos": 168, "end_pos": 175, "type": "METRIC", "confidence": 0.9980176687240601}, {"text": "F-score", "start_pos": 215, "end_pos": 222, "type": "METRIC", "confidence": 0.9981482028961182}]}, {"text": "By measuring predicate-argument structure similarity based on the argument mapping, and formulating the predicate-argument structure mapping problem as a linear-assignment problem , the system achieved 84.9% F-score using automatic SRL, only 3.7% F-score lower than using gold standard SRL.", "labels": [], "entities": [{"text": "F-score", "start_pos": 208, "end_pos": 215, "type": "METRIC", "confidence": 0.9995459914207458}, {"text": "SRL", "start_pos": 232, "end_pos": 235, "type": "TASK", "confidence": 0.439909428358078}, {"text": "F-score", "start_pos": 247, "end_pos": 254, "type": "METRIC", "confidence": 0.9989768266677856}]}, {"text": "The mapping output covered 49.6% of the annotated Chinese predicates (which contains predicate-adjectives that often have no parallel annotations in English) and 80.7% of annotated En-glish predicates, suggesting its potential as a valuable resource for improving word alignment and reranking MT output.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 264, "end_pos": 278, "type": "TASK", "confidence": 0.7715011835098267}, {"text": "MT", "start_pos": 293, "end_pos": 295, "type": "TASK", "confidence": 0.8320680260658264}]}], "introductionContent": [{"text": "As the demand for semantically consistent machine translation rises (, the need fora comprehensive semantic mapping tool has become more apparent.", "labels": [], "entities": [{"text": "semantically consistent machine translation", "start_pos": 18, "end_pos": 61, "type": "TASK", "confidence": 0.5814022421836853}]}, {"text": "With the current architecture of machine translation decoders, few ways of incorporating semantics in MT output include using word sense disambiguation to select the correct target translation and reordering/reranking MT output based on semantic consistencies ().", "labels": [], "entities": [{"text": "machine translation decoders", "start_pos": 33, "end_pos": 61, "type": "TASK", "confidence": 0.8242167234420776}, {"text": "MT output", "start_pos": 102, "end_pos": 111, "type": "TASK", "confidence": 0.9250963926315308}]}, {"text": "While a comprehensive semantic mapping tool can supplement or improve the results of such techniques, there are many other exciting ideas we can explore: with automatic SRL, we can improve coverage (and possibly accuracy) of Chinese semantic class generation () by running the system on a large, unannotated parallel corpus.", "labels": [], "entities": [{"text": "SRL", "start_pos": 169, "end_pos": 172, "type": "TASK", "confidence": 0.9756191968917847}, {"text": "accuracy", "start_pos": 212, "end_pos": 220, "type": "METRIC", "confidence": 0.9987756609916687}, {"text": "Chinese semantic class generation", "start_pos": 225, "end_pos": 258, "type": "TASK", "confidence": 0.5316358953714371}]}, {"text": "Using predicate-argument mappings as constraints, it maybe possibly to improve SRL output by performing joint inference of SRL in source and target languages simultaneously, much like what was able to achieve with syntactic parsing.", "labels": [], "entities": [{"text": "SRL output", "start_pos": 79, "end_pos": 89, "type": "TASK", "confidence": 0.8970803618431091}, {"text": "syntactic parsing", "start_pos": 214, "end_pos": 231, "type": "TASK", "confidence": 0.7433769404888153}]}, {"text": "As the foundation of many machine translation decoders, word alignment has continuously played an important role in machine translation.", "labels": [], "entities": [{"text": "machine translation decoders", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.8075530529022217}, {"text": "word alignment", "start_pos": 56, "end_pos": 70, "type": "TASK", "confidence": 0.7939532697200775}, {"text": "machine translation", "start_pos": 116, "end_pos": 135, "type": "TASK", "confidence": 0.8300930857658386}]}, {"text": "There have been several attempts to improve word alignment, most of which have focused on tree-to-tree alignments of syntactic structures (.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 44, "end_pos": 58, "type": "TASK", "confidence": 0.7883338928222656}]}, {"text": "Our hypothesis is that the predicate-argument structure alignments can abstract away from language specific syntactic variation and provide a more robust, semantically coherent alignment across sentences.", "labels": [], "entities": []}, {"text": "We begin by running GIZA++, one of the most popular alignment tools, to obtain automatic word alignments between parallel English/Chinese corpora.", "labels": [], "entities": [{"text": "word alignments between parallel English/Chinese corpora", "start_pos": 89, "end_pos": 145, "type": "TASK", "confidence": 0.8339682295918465}]}, {"text": "To achieve a broader coverage of semantic mappings than just those anno-21 tated in parallel PropBank-ed corpora, we attempt to map automatically generated predicate-argument structures.", "labels": [], "entities": []}, {"text": "For each Chinese and English verb predicate pairs within a parallel sentence, we examine the quality of both the predicate and argument alignment (using GIZA++ word alignment output) and devise a many-to-many argument mapping technique.", "labels": [], "entities": []}, {"text": "From that, we pose predicate-argument mapping as a linear assignment problem (optimizing the total similarity of the mapping) and solve it with the Kuhn-Munkres method.", "labels": [], "entities": []}, {"text": "With this approach, we were able to incur only a small predicate-argument F-score degradation over using manual PropBank annotation.", "labels": [], "entities": [{"text": "F-score degradation", "start_pos": 74, "end_pos": 93, "type": "METRIC", "confidence": 0.9326276481151581}]}, {"text": "The output also provides much more fine-grained argument mapping that can be used for downstream MT applications.", "labels": [], "entities": [{"text": "MT", "start_pos": 97, "end_pos": 99, "type": "TASK", "confidence": 0.9726856350898743}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Chinese argument type (column) to English argument type (row) mapping on triple-gold Xinhua corpus", "labels": [], "entities": []}, {"text": " Table 2: SRL results on triple-gold Xinhua corpus. \"arg  match\" is the standard CoNLL 2005 evaluation metric,  \"oracle\" is the oracle SRL based on automatic parser out- put, and \"word match\" is scoring based on length of ar- gument overlap with the reference", "labels": [], "entities": [{"text": "SRL", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.8672800660133362}, {"text": "Xinhua corpus", "start_pos": 37, "end_pos": 50, "type": "DATASET", "confidence": 0.8270414769649506}, {"text": "arg  match", "start_pos": 53, "end_pos": 63, "type": "METRIC", "confidence": 0.9416510462760925}, {"text": "CoNLL 2005 evaluation metric", "start_pos": 81, "end_pos": 109, "type": "DATASET", "confidence": 0.8814879804849625}]}, {"text": " Table 3: Predicate-argument mapping results", "labels": [], "entities": [{"text": "Predicate-argument mapping", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.755903571844101}]}, {"text": " Table 4: Predicate-argument mapping coverage. Predi- cate coverage denotes the number of mapped predicates  over all predicates in the corpus, word coverage denotes  the number of words in the mapped predicate-arguments  over all words in the corpus", "labels": [], "entities": [{"text": "Predicate-argument mapping coverage", "start_pos": 10, "end_pos": 45, "type": "TASK", "confidence": 0.7686394651730856}, {"text": "Predi- cate coverage", "start_pos": 47, "end_pos": 67, "type": "METRIC", "confidence": 0.842946857213974}]}, {"text": " Table 5: Frameset coverage on the 400K parallel sentence  corpus", "labels": [], "entities": []}]}