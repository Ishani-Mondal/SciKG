{"title": [{"text": "The Karlsruhe Institute of Technology Translation Systems for the WMT 2011", "labels": [], "entities": [{"text": "Karlsruhe Institute of Technology Translation", "start_pos": 4, "end_pos": 49, "type": "TASK", "confidence": 0.547641932964325}, {"text": "WMT", "start_pos": 66, "end_pos": 69, "type": "TASK", "confidence": 0.706723153591156}]}], "abstractContent": [{"text": "This paper describes the phrase-based SMT systems developed for our participation in the WMT11 Shared Translation Task.", "labels": [], "entities": [{"text": "SMT", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.8538193702697754}, {"text": "WMT11 Shared Translation Task", "start_pos": 89, "end_pos": 118, "type": "TASK", "confidence": 0.7584615647792816}]}, {"text": "Translations for English\u2194German and English\u2194French were generated using a phrase-based translation system which is extended by additional models such as bilingual and fine-grained POS language models, POS-based reordering, lattice phrase extraction and discriminative word alignment.", "labels": [], "entities": [{"text": "lattice phrase extraction", "start_pos": 223, "end_pos": 248, "type": "TASK", "confidence": 0.6265798509120941}, {"text": "word alignment", "start_pos": 268, "end_pos": 282, "type": "TASK", "confidence": 0.7228794991970062}]}, {"text": "Furthermore, we present a special filtering method for the English-French Giga corpus and the phrase scoring step in the training is parallelized.", "labels": [], "entities": [{"text": "English-French Giga corpus", "start_pos": 59, "end_pos": 85, "type": "DATASET", "confidence": 0.6596740384896597}, {"text": "phrase scoring", "start_pos": 94, "end_pos": 108, "type": "TASK", "confidence": 0.7151639312505722}]}], "introductionContent": [{"text": "In this paper we describe our systems for the EMNLP 2011 Sixth Workshop on Statistical Machine Translation.", "labels": [], "entities": [{"text": "EMNLP 2011 Sixth Workshop on Statistical Machine Translation", "start_pos": 46, "end_pos": 106, "type": "TASK", "confidence": 0.682486280798912}]}, {"text": "We participated in the Shared Translation Task and submitted translations for English\u2194German and English\u2194French.", "labels": [], "entities": [{"text": "Shared Translation Task", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.9281519254048666}]}, {"text": "We use a phrase-based decoder that can use lattices as input and developed several models that extend the standard log-linear model combination of phrase-based MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 160, "end_pos": 162, "type": "TASK", "confidence": 0.7789296507835388}]}, {"text": "These include advanced reordering models and corresponding adaptations to the phrase extraction process as well as extension to the translation and language model inform of discriminative word alignment and a bilingual language model to extend source word context.", "labels": [], "entities": [{"text": "phrase extraction process", "start_pos": 78, "end_pos": 103, "type": "TASK", "confidence": 0.836758573849996}, {"text": "discriminative word alignment", "start_pos": 173, "end_pos": 202, "type": "TASK", "confidence": 0.6939106285572052}]}, {"text": "For English-German, language models based on fine-grained part-of-speech tags were used to address the difficult target language generation due to the rich morphology of German.", "labels": [], "entities": []}, {"text": "We also present a filtering method directly addressing the problems of web-crawled corpora, which enabled us to make use of the French-English Giga corpus.", "labels": [], "entities": [{"text": "French-English Giga corpus", "start_pos": 128, "end_pos": 154, "type": "DATASET", "confidence": 0.8272907535235087}]}, {"text": "Another novelty in our systems this year is the parallel phrase scoring method that reduces the time needed for training which is especially convenient for such big corpora as the Giga corpus.", "labels": [], "entities": [{"text": "parallel phrase scoring", "start_pos": 48, "end_pos": 71, "type": "TASK", "confidence": 0.5886813302834829}, {"text": "Giga corpus", "start_pos": 180, "end_pos": 191, "type": "DATASET", "confidence": 0.9540907740592957}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results of the filtering experiments", "labels": [], "entities": []}, {"text": " Table 2: Comparison of Moses and KIT phrase extraction  systems", "labels": [], "entities": [{"text": "KIT phrase extraction", "start_pos": 34, "end_pos": 55, "type": "TASK", "confidence": 0.5837953090667725}]}, {"text": " Table 3: Analysis of context length", "labels": [], "entities": []}, {"text": " Table 4: Translation results for German-English", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9220781922340393}]}, {"text": " Table 5: Translation results for English-German", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9261349439620972}]}, {"text": " Table 6: Translation results for English-French", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9173445105552673}]}, {"text": " Table 7: Translation results for French-English", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9139726161956787}]}]}