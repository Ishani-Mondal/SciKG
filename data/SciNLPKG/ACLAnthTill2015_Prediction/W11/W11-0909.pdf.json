{"title": [{"text": "A Joint Model of Implicit Arguments for Nominal Predicates", "labels": [], "entities": [{"text": "Nominal Predicates", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7157998979091644}]}], "abstractContent": [{"text": "Many prior studies have investigated the recovery of semantic arguments for nominal predicates.", "labels": [], "entities": [{"text": "recovery of semantic arguments for nominal predicates", "start_pos": 41, "end_pos": 94, "type": "TASK", "confidence": 0.7402402332850865}]}, {"text": "The models in many of these studies have assumed that arguments are independent of each other.", "labels": [], "entities": []}, {"text": "This assumption simplifies the computational modeling of semantic arguments, but it ignores the joint nature of natural language.", "labels": [], "entities": []}, {"text": "This paper presents a preliminary investigation into the joint modeling of implicit arguments for nominal predicates.", "labels": [], "entities": [{"text": "joint modeling of implicit arguments for nominal predicates", "start_pos": 57, "end_pos": 116, "type": "TASK", "confidence": 0.585041344165802}]}, {"text": "The joint model uses propositional knowledge extracted from millions of Internet webpages to help guide prediction.", "labels": [], "entities": []}], "introductionContent": [{"text": "Much recent work on semantic role labeling has focused on joint models of arguments.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.7456719080607096}]}, {"text": "This work is motivated by the fact that one argument can either promote or inhibit the presence of another argument.", "labels": [], "entities": []}, {"text": "Because most of this work has been done for verbal SRL, nominal SRL has lagged behind somewhat.", "labels": [], "entities": [{"text": "SRL", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.7659749388694763}, {"text": "SRL", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.634134829044342}]}, {"text": "In particular, the \"implicit\" nominal SRL model created by does not address joint argument structures.", "labels": [], "entities": []}, {"text": "Implicit arguments are similar to standard SRL arguments, a primary difference being their ability to cross sentence boundaries.", "labels": [], "entities": [{"text": "SRL arguments", "start_pos": 43, "end_pos": 56, "type": "TASK", "confidence": 0.9216967225074768}]}, {"text": "In the model created by Gerber and Chai, implicit argument candidates are classified independently and a heuristic post-processing method is applied to derive the final structure.", "labels": [], "entities": []}, {"text": "This paper presents a preliminary joint implicit argument model.", "labels": [], "entities": []}, {"text": "Consider the following sentences: 1 We will use the notation of, where In Example 2, we are searching for the iarg 0 of loss (the entity that is losing).", "labels": [], "entities": []}, {"text": "The sentence in Example 1 supplies two candidates c 1 and c 2 . If one only considers the predicate loss, then c 1 and c 2 would both be reasonable fillers for the iarg 0 : presidents often lose things (e.g., votes and allegiance) and economies often lose things (e.g., jobs and value).", "labels": [], "entities": []}, {"text": "However, the sentence in Example 2 supplies additional information.", "labels": [], "entities": [{"text": "Example", "start_pos": 25, "end_pos": 32, "type": "DATASET", "confidence": 0.7198727130889893}]}, {"text": "It tells the reader that the next election is the entity being lost.", "labels": [], "entities": []}, {"text": "Given this information, one would likely prefer c 1 over c 2 because economies don't generally lose elections, whereas presidents often do.", "labels": [], "entities": []}, {"text": "This type of inference is common in textual discourses because authors assume a shared knowledge base with their readers.", "labels": [], "entities": []}, {"text": "This knowledge base contains information about events and their typical participants (e.g., the fact that presidents lose elections but economies do not).", "labels": [], "entities": []}, {"text": "The model presented in this paper relies on a knowledge base constructed by automatically mining semantic propositions from Internet webpages.", "labels": [], "entities": []}, {"text": "These propositions help to identify likely joint implicit argument configurations.", "labels": [], "entities": []}, {"text": "In the following section, we review work on joint inference within semantic role labeling.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 67, "end_pos": 89, "type": "TASK", "confidence": 0.6590633193651835}]}, {"text": "In Sections 4 and 5, we present the joint implicit argument model and its features.", "labels": [], "entities": []}, {"text": "Evaluation results for this model are given in Secstandard nominal arguments are indicated with argn and implicit arguments are indicated with iargn.", "labels": [], "entities": [{"text": "Secstandard", "start_pos": 47, "end_pos": 58, "type": "DATASET", "confidence": 0.898443877696991}, {"text": "argn", "start_pos": 96, "end_pos": 100, "type": "METRIC", "confidence": 0.9739073514938354}]}, {"text": "The joint model contains many simplifying assumptions, which we address in Section 7.", "labels": [], "entities": []}, {"text": "We conclude in Section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the joint model described in the previous sections over the manually annotated implicit argument data created by.", "labels": [], "entities": []}, {"text": "This dataset contains full-text implicit argument annotations for approximately 1,200 predicate instances within the Penn TreeBank.", "labels": [], "entities": [{"text": "Penn TreeBank", "start_pos": 117, "end_pos": 130, "type": "DATASET", "confidence": 0.9953028559684753}]}, {"text": "As mentioned in Section 4, all experiments were conducted using predicate instances that take an iarg 0 and iarg 1 in the ground-truth annotations.", "labels": [], "entities": []}, {"text": "We used a tenfold cross-validation setup and the evaluation metrics proposed by, which were also used by Gerber and Chai.", "labels": [], "entities": []}, {"text": "For each evaluation fold, features were selected using only the corresponding training data and the greedy selection algorithm proposed by, which starts with an empty feature set and incrementally adds features that provide the highest gains.", "labels": [], "entities": []}, {"text": "For comparison with Gerber and Chai's model, we also evaluated the local prediction model on the evaluation data.", "labels": [], "entities": []}, {"text": "Because this model predicted implicit arguments independently, it continued to use the heuristic post-processing algorithm to arrive at the final labeling.", "labels": [], "entities": []}, {"text": "However, the prediction threshold twas eliminated because the system could safely assume that a true filler for the iarg 0 and iarg 1 positions existed.", "labels": [], "entities": [{"text": "prediction threshold", "start_pos": 13, "end_pos": 33, "type": "METRIC", "confidence": 0.9553402364253998}]}, {"text": "The first thing to note is that these results are not comparable to the results presented by.", "labels": [], "entities": []}, {"text": "In general, performance is much higher because predicate instances reliably take implicit arguments in the iarg 0 and iarg 1 positions.", "labels": [], "entities": []}, {"text": "The overall performance increase versus the local model is relatively small (approximately 1 percentage point); however, the bid predicate in particular showed a substantial increase (greater than 11 percentage points).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Joint implicit argument evaluation results. The second column gives the total number of implicit arguments  in the ground-truth annotations. P , R, and F 1 indicate precision, recall, and f-measure (\u03b2 = 1) as defined by Ruppen- hofer et al. (2009).", "labels": [], "entities": [{"text": "F 1", "start_pos": 162, "end_pos": 165, "type": "METRIC", "confidence": 0.9627095758914948}, {"text": "precision", "start_pos": 175, "end_pos": 184, "type": "METRIC", "confidence": 0.9930484294891357}, {"text": "recall", "start_pos": 186, "end_pos": 192, "type": "METRIC", "confidence": 0.998753547668457}]}]}