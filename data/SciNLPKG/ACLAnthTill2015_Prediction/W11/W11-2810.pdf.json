{"title": [{"text": "Content selection from an ontology-based knowledge base for the generation of football summaries", "labels": [], "entities": [{"text": "generation of football summaries", "start_pos": 64, "end_pos": 96, "type": "TASK", "confidence": 0.7265894562005997}]}], "abstractContent": [{"text": "We present an approach to content selection that works on an ontology-based knowledge base developed independently from the task at hand, i.e., Natural Language Generation.", "labels": [], "entities": [{"text": "content selection", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7458910346031189}, {"text": "Natural Language Generation", "start_pos": 144, "end_pos": 171, "type": "TASK", "confidence": 0.6428493559360504}]}, {"text": "Prior to content selection, a stage akin to signal analysis and data assessment used in the generation from numerical data is performed for identifying and abstracting patterns and trends, and identifying relations between individuals.", "labels": [], "entities": [{"text": "content selection", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.790277361869812}]}, {"text": "This new information is modeled as an extended ontology on top of the domain ontology which is populated via inference rules.", "labels": [], "entities": []}, {"text": "Content selection leverages the ontology-based description of the domain and is performed throughout the text planning at increasing levels of granularity.", "labels": [], "entities": [{"text": "Content selection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.811727374792099}]}, {"text": "It includes a main topic selection phase that takes into account a simple user model, a set of heuristics, and semantic relations that link individuals of the KB.", "labels": [], "entities": []}, {"text": "The heuristics are based on weights determined empirically by supervised learning on a corpus of summaries aligned with data.", "labels": [], "entities": []}, {"text": "The generated texts are short football match summaries that take into account the user perspective .", "labels": [], "entities": []}], "introductionContent": [{"text": "Content selection (or determination) forms one of the major tasks in Natural Language Generation (NLG).", "labels": [], "entities": [{"text": "Content selection (or determination)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8646741708119711}, {"text": "Natural Language Generation (NLG)", "start_pos": 69, "end_pos": 102, "type": "TASK", "confidence": 0.7978825867176056}]}, {"text": "Traditionally, it has been done from purpose-built KBs intertwined with discourse structuring; see, e.g.,.", "labels": [], "entities": []}, {"text": "In an attempt to systematize the structure of the used KBs and to build an intermediate knowledge-oriented layer between them and linguistic structures, language-oriented ontologies such as the Upper Models () have been developed.", "labels": [], "entities": []}, {"text": "However, in view of the rise of the semantic web and the rapidly increasing volumes of KBs codified in OWL/RDF, the question on content selection from large scale purpose-neutral ontologies becomes very essential-at least for practical applications of NLG-and has scarcely been addressed.", "labels": [], "entities": [{"text": "OWL/RDF", "start_pos": 103, "end_pos": 110, "type": "DATASET", "confidence": 0.8067091107368469}]}, {"text": "In what follows, we present a framework for content selection from large scale OWL/RDF ontologybased domain KBs that were developed independently from the task of NLG.", "labels": [], "entities": [{"text": "OWL/RDF ontologybased domain KBs", "start_pos": 79, "end_pos": 111, "type": "DATASET", "confidence": 0.6210813969373703}]}, {"text": "The framework is novel in that it (i) foresees a separation of the domain communication ontology from the general purpose domain ontology, and (ii) implements mechanisms for selecting content from large scale (at least for NLG standards) ontology-based knowledge bases.", "labels": [], "entities": []}, {"text": "To identify and abstract regular patterns and trends and introduce semantic relations between the individuals of a generic domain ontology, which are critical for high quality generation, but absent from any general purpose ontology, prior to content selection a stage akin to signal analysis and data assessment used for the generation from numerical data) is performed.", "labels": [], "entities": []}, {"text": "This new information is modeled as an additional layer on top of the domain ontology, which is populated via rule-based inferences.", "labels": [], "entities": []}, {"text": "Content selection proper then takes place at a number of levels of increasing granularity.", "labels": [], "entities": [{"text": "Content selection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8645228743553162}]}, {"text": "First, a content bounding task is in charge of selecting, based on the user query, a subset of the KB that includes the maximal set of information that might be communicated to the user.", "labels": [], "entities": [{"text": "content bounding task", "start_pos": 9, "end_pos": 30, "type": "TASK", "confidence": 0.7872786124547323}]}, {"text": "Next the main topics to be included in the content plan are selected, taking into account: 1) a user model, 2) a set of heuristics, and 3) the seman-tic relations that link individuals of the KB.", "labels": [], "entities": []}, {"text": "Finally, discourse unit determination in the discourse structuring submodule is in charge of deciding which details to include (or not) in each message.", "labels": [], "entities": [{"text": "discourse unit determination", "start_pos": 9, "end_pos": 37, "type": "TASK", "confidence": 0.6559008757273356}]}, {"text": "The whole text planning procedure that includes both content selection and discourse structuring is presented in).", "labels": [], "entities": [{"text": "content selection", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.7211684882640839}]}, {"text": "The framework has been implemented with a KB that models the First Spanish Football League competitions for the generation (in Spanish) of short user perspective-tailored summaries of the individual matches.", "labels": [], "entities": [{"text": "First Spanish Football League competitions", "start_pos": 61, "end_pos": 103, "type": "DATASET", "confidence": 0.9001073718070984}]}, {"text": "The user model is a simple model that contains the preference of the user for one of the teams.", "labels": [], "entities": []}, {"text": "The content bounding parameters include the time, location and protagonists of the match of interest.", "labels": [], "entities": []}, {"text": "The heuristics are based on weights determined empirically by supervised learning on a corpus of summaries aligned with data, as in The first and the last sentences of the text are template-based.", "labels": [], "entities": []}, {"text": "The content selection strategy is responsible for dynamically selecting the contents used to generate the text in between.", "labels": [], "entities": [{"text": "content selection", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.699192687869072}]}, {"text": "For this example the system selected 30 RDF triples involving 17 individuals and 8 datatype values.", "labels": [], "entities": []}, {"text": "For example, the fragment \"a goal by Ronaldinho in minute 34 and another goal by Eto'o in minute 56\" is generated from the following 6 triples: minute(goal-1, 34), player(goal-1, player-1), name(player-1, Ronaldinho), minute(goal-2, 56), player(goal-2, player-2), name(player-2, Eto'o).", "labels": [], "entities": []}, {"text": "In the next section, we outline the base and extended ontologies and their corresponding knowledge bases.", "labels": [], "entities": []}, {"text": "In Section 3, we discuss the ontologybased content selection procedure.", "labels": [], "entities": [{"text": "ontologybased content selection", "start_pos": 29, "end_pos": 60, "type": "TASK", "confidence": 0.7195183237393697}]}, {"text": "In Section 4, we present a corpus-based evaluation of the content selection procedure, before reviewing some related work in Section 5 and providing some conclusions and discussing future work in Section 6.", "labels": [], "entities": [{"text": "content selection", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.7292082905769348}]}], "datasetContent": [{"text": "Our evaluation of the content selection consisted of three stages: (1) evaluation of the automatic dataarticle alignment procedure, (2) evaluation of the performance of the classifiers for the empirical relevance determination, and (3) evaluation of the content selection as a whole.", "labels": [], "entities": [{"text": "empirical relevance determination", "start_pos": 193, "end_pos": 226, "type": "TASK", "confidence": 0.6387598514556885}]}, {"text": "The evaluation of the automatic alignment against 158 manually aligned summaries resulted in an Fscore of 100% for red cards, 87% for goals and 51% for classification.", "labels": [], "entities": [{"text": "Fscore", "start_pos": 96, "end_pos": 102, "type": "METRIC", "confidence": 0.9964479207992554}]}, {"text": "The low performance of classification alignment is due to the low efficiency of its anchors: positions, zones and points are seldom mentioned explicitly and both team names often appear in the summary, leading to ambiguity.", "labels": [], "entities": [{"text": "classification alignment", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.9365072548389435}]}, {"text": "For this reason, classification alignment was edited manually.", "labels": [], "entities": [{"text": "classification alignment", "start_pos": 17, "end_pos": 41, "type": "TASK", "confidence": 0.9838691055774689}]}, {"text": "shows the performance of the classifiers for the determination of the relevance of the three categories (goal, red card and classification) with respect to their inclusion into the summary section, comparing it to the baseline, which is the majority class.", "labels": [], "entities": []}, {"text": "For red cards, the results correspond to considering title and summary from a source together, given that the results are not significant when considering summary section only (accuracy is 78.1%, baseline accuracy is 65.4% and t = 4.4869 with p<0.0001).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 177, "end_pos": 185, "type": "METRIC", "confidence": 0.9989173412322998}, {"text": "accuracy", "start_pos": 205, "end_pos": 213, "type": "METRIC", "confidence": 0.8925595283508301}]}, {"text": "In all cases, the best performance is obtained by considering the content from any of the online sources.", "labels": [], "entities": []}, {"text": "The evaluation of the content selection as a whole is done by comparing the content of generated summaries with that of existing summaries (the gold standard).", "labels": [], "entities": []}, {"text": "We say \"as a whole\" since this evaluation also considers the template-based content selection performed during discourse unit determination.", "labels": [], "entities": [{"text": "discourse unit determination", "start_pos": 111, "end_pos": 139, "type": "TASK", "confidence": 0.6055269042650858}]}, {"text": "Our test corpus consists of 36 randomly selected matches from the set of matches of the  three different web sources (namely espn, marca, terra).", "labels": [], "entities": []}, {"text": "We compiled a list of all individuals considered for inclusion in the content selection and discourse unit determination modules and for which explicitly references could be found in target texts, including instances of the semantic relations, which were modelled as classes in the KB.", "labels": [], "entities": [{"text": "content selection and discourse unit determination", "start_pos": 70, "end_pos": 120, "type": "TASK", "confidence": 0.6175559957822164}]}, {"text": "For each of the 108 (36\u00d73) summaries, we manually annotated whether an individual was verbalized or not.", "labels": [], "entities": []}, {"text": "We also annotated for each text the team of interest by checking whether the majority of content units was from one team or another; in case of equality, the user profile was considered neutral.", "labels": [], "entities": []}, {"text": "This allowed us to compare the generated text of a given match fora given profile with the text(s) for the same profile.", "labels": [], "entities": []}, {"text": "11 As baseline, we always select both teams and the final result regardless of profile since the result (and most likely the associated teams-as shown in Table 1) is almost always included in the summaries.", "labels": [], "entities": []}, {"text": "This baseline is likely to have high precision and lower recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9995700716972351}, {"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.999245285987854}]}, {"text": "We performed three runs of generation: (1) a full run with relevance weights determined by the trained models (\"estimated\"), (2) a run in which the relevance of the instances is determined from the aligned texts, taking the profile into account (\"real w., prof.\"), and (3) a run like (2), but without taking into account the user profile when determining relevance (\"real w., no prof.\").", "labels": [], "entities": []}, {"text": "shows the results of the evaluation for each of the three sources.", "labels": [], "entities": []}, {"text": "In the context of sports commentaries, readers usually tolerate better a certain excess of information than lack of (relevant) information.", "labels": [], "entities": []}, {"text": "Therefore, recall can be considered of higher prominence than precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9985826015472412}, {"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.998891294002533}]}, {"text": "Precision and recall are obtained by measuring", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.6008011698722839}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9991703033447266}]}], "tableCaptions": [{"text": " Table 1: Verbalization of some categories in title, sum- mary and body of Spanish Football League articles  (2007/2008 season) in all sources", "labels": [], "entities": [{"text": "Verbalization", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9664645791053772}, {"text": "sum- mary", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9702397783597311}, {"text": "Spanish Football League articles", "start_pos": 75, "end_pos": 107, "type": "DATASET", "confidence": 0.7853028178215027}]}, {"text": " Table 2: Performance of the best classifiers (vs majority baseline) on a test set for the summary section (+title in case  of red cards)", "labels": [], "entities": []}, {"text": " Table 3: Content selection evaluation results", "labels": [], "entities": [{"text": "Content selection evaluation", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.8766909241676331}]}]}