{"title": [], "abstractContent": [{"text": "Quotation extraction consists of identifying quotations and their authors.", "labels": [], "entities": [{"text": "Quotation extraction", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.944197028875351}]}, {"text": "In this work, we present a Quotation Extraction system for Portuguese that is based on Entropy Guided Transformation Learning, a supervised Machine Learning algorithm.", "labels": [], "entities": []}, {"text": "This is the first system that uses a Machine Learning approach for Portuguese.", "labels": [], "entities": []}, {"text": "In order to train and evaluate the proposed system, we build the GLOBOQUOTES corpus, with news extracted from the GLOBO.COM portal.", "labels": [], "entities": [{"text": "GLOBOQUOTES corpus", "start_pos": 65, "end_pos": 83, "type": "DATASET", "confidence": 0.9405339360237122}, {"text": "GLOBO.COM portal", "start_pos": 114, "end_pos": 130, "type": "DATASET", "confidence": 0.9212346076965332}]}, {"text": "Our system obtains an F \u03b2=1 score of 79.02% for the subtask of associating a quotation to its author.", "labels": [], "entities": [{"text": "F \u03b2=1 score", "start_pos": 22, "end_pos": 33, "type": "METRIC", "confidence": 0.9814473867416382}]}, {"text": "For the whole Quotation Extraction task, the observed F \u03b2=1 score value is 66.03%.", "labels": [], "entities": [{"text": "Quotation Extraction task", "start_pos": 14, "end_pos": 39, "type": "TASK", "confidence": 0.929498573144277}, {"text": "F \u03b2=1 score value", "start_pos": 54, "end_pos": 71, "type": "METRIC", "confidence": 0.9814503292242686}]}, {"text": "These findings indicate that the overall extraction quality is highly dependant on the quotation identification subtask.", "labels": [], "entities": [{"text": "quotation identification subtask", "start_pos": 87, "end_pos": 119, "type": "TASK", "confidence": 0.9256754716237386}]}], "introductionContent": [{"text": "Quotation extraction consists of identifying quotations from a text and associating them to their authors.", "labels": [], "entities": [{"text": "Quotation extraction", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9501733481884003}]}, {"text": "In this work, we propose a Quotation Extraction system that handles direct and mixed quotations for Portuguese based on Entropy Guided Transformation Learning (ETL) algorithm.", "labels": [], "entities": [{"text": "Quotation Extraction", "start_pos": 27, "end_pos": 47, "type": "TASK", "confidence": 0.8308791816234589}]}, {"text": "ETL solves the main bottleneck of Transformation Based, which is the automatic generation of template rules.", "labels": [], "entities": []}, {"text": "ETL is applied successfully in several computational linguistic problems.", "labels": [], "entities": []}, {"text": "Since we employ a supervised Machine Learning algorithm, we need an annotated corpus to train and evaluate the system.", "labels": [], "entities": []}, {"text": "In order to accomplish this task, we build the GLOBOQUOTES corpus, with news extracted from the GLOBO.COM portal.", "labels": [], "entities": [{"text": "GLOBOQUOTES corpus", "start_pos": 47, "end_pos": 65, "type": "DATASET", "confidence": 0.9484445750713348}, {"text": "GLOBO.COM portal", "start_pos": 96, "end_pos": 112, "type": "DATASET", "confidence": 0.9201575517654419}]}, {"text": "We generate the golden features for entities, coreferences, quotations and associations between quotations and authors.", "labels": [], "entities": []}, {"text": "Moreover, we include the part-of-speech (POS) annotation in the corpus using a state-of-the-art tagger , also based on ETL.", "labels": [], "entities": [{"text": "ETL", "start_pos": 119, "end_pos": 122, "type": "DATASET", "confidence": 0.9272238612174988}]}, {"text": "After producing the annotations, we separate the GLOBOQUOTES corpus into two sets, training set and test set.", "labels": [], "entities": [{"text": "GLOBOQUOTES corpus", "start_pos": 49, "end_pos": 67, "type": "DATASET", "confidence": 0.8524415791034698}]}, {"text": "Quotation Extraction has been previously approached using different techniques and for several languages.", "labels": [], "entities": [{"text": "Quotation Extraction", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8811936378479004}]}, {"text": "The NewsExplorer 1 system, based on lexical rules, extracts quotations from multilingual news].", "labels": [], "entities": []}, {"text": "The Sapiens system, based on syntatic rules, extracts quotations from news wires in French.", "labels": [], "entities": []}, {"text": "The verbatim 2 system, based on speech act rules, extracts quotations for Portuguese.", "labels": [], "entities": []}, {"text": "The EVRI portal 3 offers a Quotation Extraction API for En-glish news feeds.", "labels": [], "entities": [{"text": "EVRI portal 3", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9787773092587789}]}, {"text": "Their approach is based on rules that use several linguistic features automatically provided by standard auxiliary processors.", "labels": [], "entities": []}, {"text": "Our proposal differs from previous work since we use Machine Learning to automatically build specialized rules instead of human derived rules.", "labels": [], "entities": []}, {"text": "We train our system for Portuguese, although our approach is language independent.", "labels": [], "entities": []}, {"text": "In, we present the proposed system quality evaluated on the test set.", "labels": [], "entities": []}, {"text": "Our system obtains an F \u03b2=1 score of 79.02% for the subtask of associating a quotation to its author.", "labels": [], "entities": [{"text": "F \u03b2=1 score", "start_pos": 22, "end_pos": 33, "type": "METRIC", "confidence": 0.9814473867416382}]}, {"text": "For the whole Quotation Extraction task, the observed F \u03b2=1 score value is 66.03%.", "labels": [], "entities": [{"text": "Quotation Extraction task", "start_pos": 14, "end_pos": 39, "type": "TASK", "confidence": 0.929498573144277}, {"text": "F \u03b2=1 score value", "start_pos": 54, "end_pos": 71, "type": "METRIC", "confidence": 0.9814503292242686}]}, {"text": "These findings indicate that the overall extraction quality has a strong dependency on the quotation identification subtask.", "labels": [], "entities": [{"text": "quotation identification subtask", "start_pos": 91, "end_pos": 123, "type": "TASK", "confidence": 0.9314092596371969}]}, {"text": "The proposed system performance cannot be directly compared to previous work, since the corresponding corpora are not publicly available.", "labels": [], "entities": []}, {"text": "The remaining of this work is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2, we describe the Quotation Extraction task.", "labels": [], "entities": [{"text": "Quotation Extraction task", "start_pos": 30, "end_pos": 55, "type": "TASK", "confidence": 0.9040059844652811}]}, {"text": "In section 3, we present the corpus as well as the adopted annotation.", "labels": [], "entities": []}, {"text": "We report our modeling in section 4 and experiments in section 5.", "labels": [], "entities": []}, {"text": "Finally, in section 6, we present our conclusions and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present the experimental setup and results.", "labels": [], "entities": []}, {"text": "In order to evaluate the proposed system, we separate the annotated corpus into training set, with 802 quotations, and test set, with 205 quotations.", "labels": [], "entities": []}, {"text": "In, we present the performance of the whole system, along with the baseline system.", "labels": [], "entities": []}, {"text": "When we use the automatically identified quotations, our system achieves an F \u03b2=1 score of 66.03%.", "labels": [], "entities": [{"text": "F \u03b2=1 score", "start_pos": 76, "end_pos": 87, "type": "METRIC", "confidence": 0.9835212349891662}]}, {"text": "In, we show the performance when using the golden annotation of quotations.", "labels": [], "entities": []}, {"text": "In this setup, we obtain an F \u03b2=1 score of 79.02%.", "labels": [], "entities": [{"text": "F \u03b2=1 score", "start_pos": 28, "end_pos": 39, "type": "METRIC", "confidence": 0.9806091547012329}]}, {"text": "These findings indicate that the overall extraction quality has a strong dependency on the quotation identification subtask.", "labels": [], "entities": [{"text": "quotation identification subtask", "start_pos": 91, "end_pos": 123, "type": "TASK", "confidence": 0.9314087430636088}]}], "tableCaptions": [{"text": " Table 1. Quotation Extraction performance on the test set", "labels": [], "entities": []}, {"text": " Table 2. Performance of the Quotation Extraction task", "labels": [], "entities": [{"text": "Quotation Extraction", "start_pos": 29, "end_pos": 49, "type": "TASK", "confidence": 0.8677249848842621}]}, {"text": " Table 3. Performance of the association between quotation and author subtask", "labels": [], "entities": []}]}