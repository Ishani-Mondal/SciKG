{"title": [{"text": "Sentence-Level Instance-Weighting for Graph-Based and Transition-Based Dependency Parsing", "labels": [], "entities": []}], "abstractContent": [{"text": "Instance-weighting has been shown to be effective in statistical machine translation (Foster et al., 2010), as well as cross-language adaptation of dependency parsers (S\u00f8gaard, 2011).", "labels": [], "entities": [{"text": "Instance-weighting", "start_pos": 0, "end_pos": 18, "type": "METRIC", "confidence": 0.9008980989456177}, {"text": "statistical machine translation", "start_pos": 53, "end_pos": 84, "type": "TASK", "confidence": 0.7373767793178558}, {"text": "cross-language adaptation", "start_pos": 119, "end_pos": 144, "type": "TASK", "confidence": 0.7855790555477142}]}, {"text": "This paper presents new methods to do instance-weighting in state-of-the-art dependency parsers.", "labels": [], "entities": []}, {"text": "The methods are evaluated on Danish and English data with consistent improvements over un-adapted baselines.", "labels": [], "entities": [{"text": "Danish and English data", "start_pos": 29, "end_pos": 52, "type": "DATASET", "confidence": 0.6704931408166885}]}], "introductionContent": [{"text": "The default assumption in theoretical machine learning is that training and test data are independently and identically (iid) drawn from the same distribution.", "labels": [], "entities": []}, {"text": "If the distributions differ, we face what is referred to as sample selection bias in the statistical literature.", "labels": [], "entities": [{"text": "sample selection bias", "start_pos": 60, "end_pos": 81, "type": "TASK", "confidence": 0.6746332248051962}]}, {"text": "Sample selection bias is typically ignored in machine learning, but it occurs often in practice.", "labels": [], "entities": [{"text": "Sample selection bias", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9047092994054159}]}, {"text": "In natural language processing, the problem shows up in almost any real-world application.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 3, "end_pos": 30, "type": "TASK", "confidence": 0.6548081735769907}]}, {"text": "Machine translation systems are trained on large amounts of parallel text, but typically this text comes from a small set of sources or institutions, e.g. the Europarl corpora of transcribed debates from the European Parliament (.", "labels": [], "entities": [{"text": "Europarl corpora of transcribed debates from the European Parliament", "start_pos": 159, "end_pos": 227, "type": "DATASET", "confidence": 0.9551210403442383}]}, {"text": "Machine translation systems are used to translate many different kinds of texts, however.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7863318622112274}]}, {"text": "In machine translation, which can be seen as a structured learning problem of predicting target sentence y given a source sentence x, we typically see a bias in P (y) and P (x), but not in P (y|x).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.7603070437908173}]}, {"text": "Statistical parsers for English are typically trained on annotated text from the Wall Street Journal corpus of newspaper articles, but are used to process many different kinds of text.", "labels": [], "entities": [{"text": "Wall Street Journal corpus of newspaper articles", "start_pos": 81, "end_pos": 129, "type": "DATASET", "confidence": 0.9443792956215995}]}, {"text": "Since the problem of sample selection bias in natural language processing is typically related to differences in textual domains, computational linguists typically refer to the problem as domain adaptation.", "labels": [], "entities": [{"text": "sample selection bias", "start_pos": 21, "end_pos": 42, "type": "TASK", "confidence": 0.7716459035873413}, {"text": "domain adaptation", "start_pos": 188, "end_pos": 205, "type": "TASK", "confidence": 0.7864290177822113}]}, {"text": "Domain adaptation is one of the most fundamental yet-to-be-solved problems in natural language processing.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.801624596118927}]}, {"text": "While statistical parsers have accuracies of 90-92% parsing newspaper articles, accuracy on transcribed telephone conversations or child-directed speech often drop to 60-70% ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9989323019981384}]}, {"text": "Domain adaptation is therefore also receiving more and more attention, and it has recently been studied in the context of named entity recognition, sentiment analysis ( , dependency parsing (), text classification (, context-free parsing) and machine translation.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7984489798545837}, {"text": "named entity recognition", "start_pos": 122, "end_pos": 146, "type": "TASK", "confidence": 0.662451813618342}, {"text": "sentiment analysis", "start_pos": 148, "end_pos": 166, "type": "TASK", "confidence": 0.9412966370582581}, {"text": "dependency parsing", "start_pos": 171, "end_pos": 189, "type": "TASK", "confidence": 0.7032848447561264}, {"text": "text classification", "start_pos": 194, "end_pos": 213, "type": "TASK", "confidence": 0.8063313961029053}, {"text": "context-free parsing", "start_pos": 217, "end_pos": 237, "type": "TASK", "confidence": 0.7042922228574753}, {"text": "machine translation", "start_pos": 243, "end_pos": 262, "type": "TASK", "confidence": 0.8143911361694336}]}, {"text": "Domain adaptation is the problem of learning a target distribution from a labeled sample of source data with a similar, but different distribution.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7892751097679138}]}, {"text": "The problem comes in two variants; one where we also have a small amount of labeled target domain data, and one in which we only have labeled source domain data and must rely on unlabeled source and target domain data to do the actual adaptation of the model that can be learned from source domain data.", "labels": [], "entities": []}, {"text": "Much work in natural language processing has assumed a small amount of labeled target domain data), but we consider the more difficult case where none is available.", "labels": [], "entities": []}, {"text": "This is sometimes referred to as unsupervised domain adaptation.", "labels": [], "entities": [{"text": "unsupervised domain adaptation", "start_pos": 33, "end_pos": 63, "type": "TASK", "confidence": 0.6780579388141632}]}, {"text": "How domain adaptation is tackled depends much on the assumptions we may have about the similarities and differences between the two distributions.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7843994796276093}]}, {"text": "One line of approaches to domain adaptation is to change the feature representation of the source domain data, typically focusing on the features that are also predictive in the target domain.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7730749845504761}]}, {"text": "Such approaches assume a bias in P (x), but may also try to deal with sce-narios where there is a bias in P (y|x).", "labels": [], "entities": []}, {"text": "Others have proposed using priors to encode knowledge about one domain in a model induced from data in another domain, or they have promoted frequent target domain classes if they were less frequent in the source domain.", "labels": [], "entities": []}, {"text": "Such approaches assume a bias in P (y) and have become popular in word sense disambiguation (, for example, where a particular reading of bank maybe much more frequent in some domains rather than others.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 66, "end_pos": 91, "type": "TASK", "confidence": 0.6940057476361593}]}, {"text": "Classes can be promoted using instance weighting, but instance weighting can also be used to change the marginal distribution of data.", "labels": [], "entities": []}, {"text": "The first case is typically referred to as solving class imbalance, while the second case is called covariate shift).", "labels": [], "entities": []}, {"text": "We will, assuming a bias in P (x), consider the covariate shift scenario.", "labels": [], "entities": []}, {"text": "A fourth line of research in domain adaptation applies semi-supervised or transductive learning algorithms to domain adaptation problems, using unlabeled data from the target domain.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.7664793729782104}, {"text": "domain adaptation", "start_pos": 110, "end_pos": 127, "type": "TASK", "confidence": 0.7156261503696442}]}, {"text": "In dependency parsing, domain adaptation received attention in the CoNLL 2007 Shared Task.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.8578164577484131}, {"text": "domain adaptation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7267083525657654}, {"text": "CoNLL 2007 Shared Task", "start_pos": 67, "end_pos": 89, "type": "DATASET", "confidence": 0.8951981216669083}]}, {"text": "While semi-supervised learning and structural correspondence learning were used by participants in the CoNLL 2007 Shared Task, none of the participants used instance-weighting techniques.", "labels": [], "entities": [{"text": "CoNLL 2007 Shared Task", "start_pos": 103, "end_pos": 125, "type": "DATASET", "confidence": 0.9116788059473038}]}, {"text": "In this paper, we follow suggestions in the related literature on learning under sample selection bias to transform the density ratio estimation problem in co-variate shift into a problem of predicting whether an instance is from the source domain or from the target domain.", "labels": [], "entities": []}, {"text": "We show how to do this in the context of graph-based and transition-based dependency parsing.", "labels": [], "entities": [{"text": "transition-based dependency parsing", "start_pos": 57, "end_pos": 92, "type": "TASK", "confidence": 0.6310699979464213}]}, {"text": "Related work includes S\u00f8gaard (2011) who uses perplexity per word to select the source data most similar to the target data, so a form of instance weighting with weights 0 and 1, but applies the technique to cross-language adaptation of dependency parsers; but also who in a similar fashion use topic similarity measures to select articles rather than sentences.", "labels": [], "entities": [{"text": "cross-language adaptation of dependency parsers", "start_pos": 208, "end_pos": 255, "type": "TASK", "confidence": 0.674651962518692}]}, {"text": "Our instance-weighted parsers are evaluated primarily on anew data set, namely a partitioning of the Danish treebank into four different textual domains.", "labels": [], "entities": [{"text": "Danish treebank", "start_pos": 101, "end_pos": 116, "type": "DATASET", "confidence": 0.9759853184223175}]}, {"text": "We do experiments with all pair-wise combinations of the four domain-specific treebanks.", "labels": [], "entities": []}, {"text": "Our results are supplemented by a subset of the CoNLL 2007 Shared Task data.", "labels": [], "entities": [{"text": "CoNLL 2007 Shared Task data", "start_pos": 48, "end_pos": 75, "type": "DATASET", "confidence": 0.9442448258399964}]}, {"text": "It has been noted in several places that there were annotation differences between the source and target data in the original data which makes domain adaptation almost impossible ( . Consequently, we only use the three small target domain evaluation datasets, which were annotated more consistently, and do experiments with all pair-wise combinations of these datasets.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 143, "end_pos": 160, "type": "TASK", "confidence": 0.7667147219181061}]}, {"text": "Our experiments can also be seen as transductive learning experiments, since no target data other than the data used for evaluation is used.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Unlabeled attachment scores for Danish.", "labels": [], "entities": [{"text": "Unlabeled attachment scores", "start_pos": 10, "end_pos": 37, "type": "METRIC", "confidence": 0.6497517426808676}]}, {"text": " Table 2: Unlabeled attachment scores for English.", "labels": [], "entities": [{"text": "Unlabeled attachment scores", "start_pos": 10, "end_pos": 37, "type": "METRIC", "confidence": 0.6555955012639364}]}]}