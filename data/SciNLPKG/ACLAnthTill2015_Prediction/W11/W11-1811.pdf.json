{"title": [{"text": "Overview of the Protein Coreference task in BioNLP Shared Task 2011", "labels": [], "entities": [{"text": "Protein Coreference task", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.8949976166089376}, {"text": "BioNLP Shared Task 2011", "start_pos": 44, "end_pos": 67, "type": "DATASET", "confidence": 0.5905210226774216}]}], "abstractContent": [{"text": "This paper summarizes the Protein Coref-erence Resolution task of BioNLP Shared Task 2011.", "labels": [], "entities": [{"text": "Protein Coref-erence Resolution", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.7289224863052368}, {"text": "BioNLP Shared Task 2011", "start_pos": 66, "end_pos": 89, "type": "DATASET", "confidence": 0.699908971786499}]}, {"text": "After 7 weeks of system development period, the task received final submissions from 6 teams.", "labels": [], "entities": []}, {"text": "Evaluation results show that state-of-the-art performance on the task can find 22.18% of protein coreferences with the precision of 73.26%.", "labels": [], "entities": [{"text": "precision", "start_pos": 119, "end_pos": 128, "type": "METRIC", "confidence": 0.9991812109947205}]}, {"text": "Analysis of the submissions shows that several types of anaphoric expressions including definite expressions , which occupies a significant part of the problem, have not yet been solved.", "labels": [], "entities": []}], "introductionContent": [{"text": "While named entity recognition (NER) and relation or event extraction are regarded as standard tasks of information extraction (IE), coreference resolution) is more and more recognized as an important component of IE fora higher performance.", "labels": [], "entities": [{"text": "named entity recognition (NER)", "start_pos": 6, "end_pos": 36, "type": "TASK", "confidence": 0.8037574291229248}, {"text": "relation or event extraction", "start_pos": 41, "end_pos": 69, "type": "TASK", "confidence": 0.5998508632183075}, {"text": "information extraction (IE)", "start_pos": 104, "end_pos": 131, "type": "TASK", "confidence": 0.8504069685935974}, {"text": "coreference resolution", "start_pos": 133, "end_pos": 155, "type": "TASK", "confidence": 0.9305387437343597}, {"text": "IE", "start_pos": 214, "end_pos": 216, "type": "TASK", "confidence": 0.9531209468841553}]}, {"text": "Without coreference resolution, the performance of IE is often substantially limited due to an abundance of coreference structures in natural language text, i.e. information pieces written in text with involvement of a coreference structure are hard to be captured (.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 8, "end_pos": 30, "type": "TASK", "confidence": 0.9148276448249817}, {"text": "IE", "start_pos": 51, "end_pos": 53, "type": "TASK", "confidence": 0.9851888418197632}]}, {"text": "There have been several attempts for coreference resolution, particularly for newswire texts (.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.9869062304496765}]}, {"text": "It is also one of the lessons from BioNLP Shared Task (BioNLP-ST, hereafter) 2009 that coreference structures in biomedical text substantially hinder the progress of fine-grained IE (.", "labels": [], "entities": [{"text": "IE", "start_pos": 179, "end_pos": 181, "type": "TASK", "confidence": 0.9202930331230164}]}, {"text": "To address the problem of coreference resolution in molecular biology literature, the Protein Coreference (COREF) task is arranged in BioNLP-ST 2011 as a supporting task.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.9679795801639557}, {"text": "BioNLP-ST 2011", "start_pos": 134, "end_pos": 148, "type": "DATASET", "confidence": 0.9162073135375977}]}, {"text": "While the task itself is not an IE task, it is expected to be a useful component in performing the main IE tasks more effectively.", "labels": [], "entities": [{"text": "IE task", "start_pos": 32, "end_pos": 39, "type": "TASK", "confidence": 0.90835902094841}]}, {"text": "To establish a stable evaluation and to observe the effect of the results of the task to the main IE tasks, the COREF task particularly focuses on finding anaphoric protein references.", "labels": [], "entities": []}, {"text": "The benchmark data sets for developing and testing coreference resolution system were developed based on various manual annotations made to the Genia corpus ().", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.9493973553180695}, {"text": "Genia corpus", "start_pos": 144, "end_pos": 156, "type": "DATASET", "confidence": 0.7807656228542328}]}, {"text": "After 7 weeks of system development phase, for which training and development data sets with coreference annotation were given, six teams submitted their prediction of coreferences for the test data.", "labels": [], "entities": []}, {"text": "The best system according to our primary evaluation criteria is evaluated to find 22.18% of anaphoric protein references at the precision of 73.26%.", "labels": [], "entities": [{"text": "precision", "start_pos": 128, "end_pos": 137, "type": "METRIC", "confidence": 0.9981833100318909}]}, {"text": "This paper presents overall explanation of the COREF task, which includes task definition (Section 2), data preparation (Section 4), evaluation methods (Section 5), results (Section 7), and thorough analyses (Section 8) to figure out what are remaining problems for coreference resolution in biomedical text.", "labels": [], "entities": [{"text": "COREF task", "start_pos": 47, "end_pos": 57, "type": "TASK", "confidence": 0.6693214774131775}, {"text": "coreference resolution in biomedical text", "start_pos": 266, "end_pos": 307, "type": "TASK", "confidence": 0.8850126147270203}]}], "datasetContent": [{"text": "The coreference resolution performance is evaluated in two modes.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.9187359809875488}]}, {"text": "The Surface coreference mode evaluates the performance of finding anaphoric protein references and their antecedents, regardless whether the antecedents actually embed protein names or not.", "labels": [], "entities": []}, {"text": "In other words, it evaluates the ability to predict the coreference relations as provided in the gold coreference annotation file, which we call surface coreference links.", "labels": [], "entities": []}, {"text": "The protein coreference mode evaluates the performance of finding anaphoric protein references with their links to actual protein names (protein coreference links).", "labels": [], "entities": []}, {"text": "In the implementation of the evaluation, the chain of surface coreference linkes is traced until an antecedent embedding a protein name is found.", "labels": [], "entities": []}, {"text": "If a protein-name-embedding antecedent is connected to an anaphora through only one surfs link, we call the antecedent a direct protein antecedent.", "labels": [], "entities": []}, {"text": "If a protein-name-embedding anteceden is connected to an anaphora through more than one surface link, we call it an indirect protein antecedent, and the antecedents in the middle of the chain intermediate antecedents.", "labels": [], "entities": []}, {"text": "The performance evaluated in this mode maybe directly connected to the potential performance in main IE tasks: the more the (anaphoric) protein references are found, the more the protein-related events maybe found.", "labels": [], "entities": [{"text": "IE tasks", "start_pos": 101, "end_pos": 109, "type": "TASK", "confidence": 0.9166141748428345}]}, {"text": "For this reason, the protein coreference mode is chosen as the primary evaluation mode.", "labels": [], "entities": []}, {"text": "Evaluation results for both evaluation modes are given in traditional precision, recall and f-score, which are similar to (Baldwin, 1997).", "labels": [], "entities": [{"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9994655251502991}, {"text": "recall", "start_pos": 81, "end_pos": 87, "type": "METRIC", "confidence": 0.99831223487854}, {"text": "f-score", "start_pos": 92, "end_pos": 99, "type": "METRIC", "confidence": 0.9740169644355774}]}], "tableCaptions": [{"text": " Table 1: Statistics of coreference entities in COREF data  sets: N/C = not-classified.", "labels": [], "entities": [{"text": "COREF data  sets", "start_pos": 48, "end_pos": 64, "type": "DATASET", "confidence": 0.9222023288408915}]}, {"text": " Table 2: Participation. UU = UofU, UZ = UZH,  CU=ConcordU, UT = UTurku, UZ = UZH, US =  Uszeged, UC = UCD SCI, RB = Rule-based, ML = Ma- chine learning-based.", "labels": [], "entities": [{"text": "ConcordU", "start_pos": 50, "end_pos": 58, "type": "DATASET", "confidence": 0.9194272756576538}]}, {"text": " Table 3: Protein coreference results.  Total num- ber of gold link = 284. RESP=response, C=correct,  P=precision, R=recall, F=fscore", "labels": [], "entities": [{"text": "Protein coreference", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.7302801311016083}, {"text": "Total num- ber of gold link", "start_pos": 40, "end_pos": 67, "type": "METRIC", "confidence": 0.7924690757478986}, {"text": "RESP", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.9986997842788696}, {"text": "precision", "start_pos": 104, "end_pos": 113, "type": "METRIC", "confidence": 0.9445849657058716}, {"text": "recall", "start_pos": 117, "end_pos": 123, "type": "METRIC", "confidence": 0.8676810264587402}, {"text": "F=fscore", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.7860680818557739}]}, {"text": " Table 4: Surface coreference results. Total num- ber of gold link = 210. RESP=response, C=correct,  P=precision, R=recall, F=fscore", "labels": [], "entities": [{"text": "Total num- ber of gold link", "start_pos": 39, "end_pos": 66, "type": "METRIC", "confidence": 0.867384706224714}, {"text": "RESP", "start_pos": 74, "end_pos": 78, "type": "METRIC", "confidence": 0.9988860487937927}, {"text": "correct", "start_pos": 91, "end_pos": 98, "type": "METRIC", "confidence": 0.8393130898475647}, {"text": "precision", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.9667168259620667}, {"text": "recall", "start_pos": 116, "end_pos": 122, "type": "METRIC", "confidence": 0.9099507927894592}, {"text": "F=fscore", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.7746002276738485}]}, {"text": " Table 5: Count of anaphors that have different status in  different evaluation modes. S = surface coreference eval- uation mode, P = protein coreference evaluation mode", "labels": [], "entities": []}, {"text": " Table 8: Fine-grained results (f-score, %)", "labels": [], "entities": []}, {"text": " Table 10: Mapping from sub type to coreference type. Count = number of anaphors", "labels": [], "entities": [{"text": "Count", "start_pos": 54, "end_pos": 59, "type": "METRIC", "confidence": 0.9955815672874451}]}, {"text": " Table 12: Numbers of correct protein coreference links  by anaphor type and by number of antecedents, based on  manual type annotation. A=APPOS, R=RELAT, D=DNP,  P=PRON, O=Others. Di=direct, In=indirect.", "labels": [], "entities": [{"text": "APPOS", "start_pos": 139, "end_pos": 144, "type": "METRIC", "confidence": 0.745612621307373}, {"text": "RELAT", "start_pos": 148, "end_pos": 153, "type": "METRIC", "confidence": 0.9140070676803589}]}]}