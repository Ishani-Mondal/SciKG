{"title": [{"text": "Word Sense Disambiguation with Multilingual Features", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6878030896186829}]}], "abstractContent": [{"text": "This paper explores the role played by a multilingual feature representation for the task of word sense disambiguation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 93, "end_pos": 118, "type": "TASK", "confidence": 0.7534378369649252}]}, {"text": "We translate the context of an ambiguous word in multiple languages, and show through experiments on standard datasets that by using a multilingual vector space we can obtain error rate reductions of up to 25%, as compared to a monolingual classifier.", "labels": [], "entities": [{"text": "error rate reductions", "start_pos": 175, "end_pos": 196, "type": "METRIC", "confidence": 0.963125745455424}]}], "introductionContent": [{"text": "Ambiguity is inherent to human language.", "labels": [], "entities": []}, {"text": "In particular, word sense ambiguity is prevalent in all natural languages, with a large number of the words in any given language carrying more than one meaning.", "labels": [], "entities": [{"text": "word sense ambiguity", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.7622090180714926}]}, {"text": "For instance, the English noun plant can mean green plant or factory; similarly the French word feuille can mean leaf or paper.", "labels": [], "entities": []}, {"text": "The correct sense of an ambiguous word can be selected based on the context where it occurs, and correspondingly the problem of word sense disambiguation is defined as the task of automatically assigning the most appropriate meaning to a polysemous word within a given context.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 128, "end_pos": 153, "type": "TASK", "confidence": 0.7387332618236542}]}, {"text": "Among the various knowledge-based) and data-driven) word sense disambiguation methods that have been proposed to date, supervised systems have been constantly observed as leading to the highest performance.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 52, "end_pos": 77, "type": "TASK", "confidence": 0.6904720862706503}]}, {"text": "In these systems, the sense disambiguation problem is formulated as a supervised learning task, where each sense-tagged occurrence of a particular word is transformed into a feature vector which is then used in an automatic learning process.", "labels": [], "entities": [{"text": "sense disambiguation problem", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.7985489467779795}]}, {"text": "One of the main drawbacks associated with these methods is the fact that their performance is closely connected to the amount of labeled data available at hand.", "labels": [], "entities": []}, {"text": "In this paper, we investigate anew supervised word sense disambiguation method that is able to take additional advantage of the sense-labeled examples by exploiting the information that can be obtained from a multilingual representation.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 46, "end_pos": 71, "type": "TASK", "confidence": 0.6657234032948812}]}, {"text": "We show that by representing the features in a multilingual space, we are able to improve the performance of a word sense disambiguation system by a significant margin, as compared to a traditional system that uses only monolingual features.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 111, "end_pos": 136, "type": "TASK", "confidence": 0.6457883417606354}]}], "datasetContent": [{"text": "We test our model on two publicly available word sense disambiguation datasets.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 44, "end_pos": 69, "type": "TASK", "confidence": 0.6687120000521342}]}, {"text": "Each dataset includes a number of ambiguous words.", "labels": [], "entities": []}, {"text": "For each word, a number of sample contexts were extracted and then manually labeled with their correct sense.", "labels": [], "entities": []}, {"text": "Therefore, both datasets follow a Zipfian distribution of senses in context, given their natural usage.", "labels": [], "entities": []}, {"text": "Note also that senses do not cross part-of-speech boundaries.", "labels": [], "entities": []}, {"text": "The TWA 2 (two-way ambiguities) dataset contains sense tagged examples for six words that have two-way ambiguities (bass, crane, motion, palm, plant, tank).", "labels": [], "entities": [{"text": "TWA 2 (two-way ambiguities) dataset", "start_pos": 4, "end_pos": 39, "type": "DATASET", "confidence": 0.5894983836582729}]}, {"text": "These are words that have been previously used in word sense disambiguation experiments reported in.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 50, "end_pos": 75, "type": "TASK", "confidence": 0.6894964377085367}]}, {"text": "Each word has approximately 100 to 200 examples extracted from the British National Corpus.", "labels": [], "entities": [{"text": "British National Corpus", "start_pos": 67, "end_pos": 90, "type": "DATASET", "confidence": 0.9178578853607178}]}, {"text": "Since the words included in this dataset have only two homonym senses, the classification task is easier.", "labels": [], "entities": [{"text": "classification", "start_pos": 75, "end_pos": 89, "type": "TASK", "confidence": 0.964625358581543}]}, {"text": "In order to determine the effect of the multilingual expanded feature space on word sense disambiguation, we conduct several experiments using the TWA and SEMEVAL datasets.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 79, "end_pos": 104, "type": "TASK", "confidence": 0.7422719399134318}, {"text": "TWA", "start_pos": 147, "end_pos": 150, "type": "DATASET", "confidence": 0.9306244850158691}, {"text": "SEMEVAL datasets", "start_pos": 155, "end_pos": 171, "type": "DATASET", "confidence": 0.8498971164226532}]}, {"text": "The results are shown in Our proposed model relies on a multilingual vector space, where each individual feature is weighted using a scheme based on a modified normal distribution (Section 4.2.1).", "labels": [], "entities": []}, {"text": "As eight possible combinations are available when selecting one main language (English) and combinations of three additional languages taken 0 through 3 at a time (Spanish, French and German), we train eight Na\u00a8\u0131veNa\u00a8\u0131ve Bayes learners 7 on the resulted datasets: one monolingual (En), three bilingual (En-De, En-Fr, En-Es), three tri-lingual (EnDe-Es, En-De-Fr, En-Fr-Es), and one quadri-lingual (En-Fr-De-Es).", "labels": [], "entities": []}, {"text": "Each dataset is evaluated using tenfold cross-validation; the resulting micro-accuracy measures are averaged across each of the language groupings and they appear in in ND-L1 (column 4), ND-L2 (column 5), ND-L3 (column 6), and ND-L4 (column 7), respectively.", "labels": [], "entities": []}, {"text": "Our hypothesis is that as more languages are added to the mix (and therefore the number of features increases), the learner will be able to distinguish better between the various senses.", "labels": [], "entities": []}, {"text": "Comparing the accuracies obtained when training on the monolingual data, the binary weighted baseline surpasses the normal distribution-based weighting model in only three out of six cases on the TWA dataset (difference ranging from .5% to 4.81%), and in 6 out of 31 cases on the SEMEVAL dataset (difference ranging from .53% to 7.57%, where for 5 of the words, the difference is lower than 3%).", "labels": [], "entities": [{"text": "TWA dataset", "start_pos": 196, "end_pos": 207, "type": "DATASET", "confidence": 0.9835986793041229}, {"text": "SEMEVAL dataset", "start_pos": 280, "end_pos": 295, "type": "DATASET", "confidence": 0.8986459672451019}]}, {"text": "The normal distribution-based model is thus able to activate regions around a particular headword, and not an entire context, ensuring more accurate sense boundaries, and allowing this behavior to be expressed in multilingual vector spaces as well (as seen in columns 7-9 in.", "labels": [], "entities": []}, {"text": "When comparing the normal distribution-based model using one language versus more languages, 5 out of 6 words in TWA score highest when the expanded feature space includes all languages, and one scores highest for combinations of 3 languages (only .17% higher than the accuracy obtained for all languages).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 269, "end_pos": 277, "type": "METRIC", "confidence": 0.9967844486236572}]}, {"text": "We notice the same behavior in the SEMEVAL dataset, where 18 of the words exhibit their highest accuracy when all four languages are taken into consideration, and 3 achieve the highest score for three-language groupings (at most .37% higher than the accuracy obtained for the four language grouping).", "labels": [], "entities": [{"text": "SEMEVAL dataset", "start_pos": 35, "end_pos": 50, "type": "DATASET", "confidence": 0.8124878406524658}, {"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.9962553977966309}, {"text": "accuracy", "start_pos": 250, "end_pos": 258, "type": "METRIC", "confidence": 0.9943361878395081}]}, {"text": "While the model displays a steady improvement as more languages are added to the mix, four of the SEMEVAL words are unable to benefit from this expansion, namely the verbs buy (-0.61%), care (-1.45%), feel (-0.29%) and propose (-2.94%).", "labels": [], "entities": []}, {"text": "Even so, we are able to achieve error rate reductions ranging from 6.52% to 63.41% for TWA, and from 3.33% to 34.62% for SEMEVAL.", "labels": [], "entities": [{"text": "error rate", "start_pos": 32, "end_pos": 42, "type": "METRIC", "confidence": 0.9725844860076904}, {"text": "TWA", "start_pos": 87, "end_pos": 90, "type": "DATASET", "confidence": 0.7262703776359558}, {"text": "SEMEVAL", "start_pos": 121, "end_pos": 128, "type": "DATASET", "confidence": 0.5272879004478455}]}, {"text": "To summarize the performance of the model based on the expanded feature set and the proposed baselines, we aggregate all the accuracies from, and present the results obtained in.", "labels": [], "entities": []}, {"text": "The monolingual modified normal-distribution model is able to exceed the most commonsense baseline and the binary-weighted Na\u00a8\u0131veNa\u00a8\u0131ve Bayes learner for both datasets, proving its superiority as compared to a purely binary-weighted model.", "labels": [], "entities": []}, {"text": "Furthermore, we notice a consistent increase inaccuracy as more languages are added to the vector space, displaying an average increment of 1.7% at every step for TWA, and 0.67% for SEMEVAL.", "labels": [], "entities": [{"text": "SEMEVAL", "start_pos": 182, "end_pos": 189, "type": "DATASET", "confidence": 0.6807728409767151}]}], "tableCaptions": []}