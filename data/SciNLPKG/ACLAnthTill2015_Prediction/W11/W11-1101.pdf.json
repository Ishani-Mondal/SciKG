{"title": [{"text": "A Combination of Topic Models with Max-margin Learning for Relation Detection", "labels": [], "entities": [{"text": "Relation Detection", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.6932060122489929}]}], "abstractContent": [{"text": "This paper proposes a novel application of a supervised topic model to do entity relation detection (ERD).", "labels": [], "entities": [{"text": "entity relation detection (ERD)", "start_pos": 74, "end_pos": 105, "type": "TASK", "confidence": 0.7869484275579453}]}, {"text": "We adapt Maximum En-tropy Discriminant Latent Dirichlet Allocation (MEDLDA) with mixed membership for relation detection.", "labels": [], "entities": [{"text": "En-tropy Discriminant Latent Dirichlet Allocation (MEDLDA)", "start_pos": 17, "end_pos": 75, "type": "METRIC", "confidence": 0.7681058309972286}, {"text": "relation detection", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.8884045481681824}]}, {"text": "The ERD task is refor-mulated to fit into the topic modeling framework.", "labels": [], "entities": [{"text": "ERD task", "start_pos": 4, "end_pos": 12, "type": "TASK", "confidence": 0.8768797218799591}]}, {"text": "Our approach combines the benefits of both, maximum-likelihood estimation (MLE) and max-margin estimation (MME), and the mixed membership formulation enables the system to incorporate heterogeneous features.", "labels": [], "entities": []}, {"text": "We incorporate different features into the system and perform experiments on the ACE 2005 corpus.", "labels": [], "entities": [{"text": "ACE 2005 corpus", "start_pos": 81, "end_pos": 96, "type": "DATASET", "confidence": 0.9869101842244467}]}, {"text": "Our approach achieves better overall performance for precision, recall and Fmeasure metrics as compared to SVM-based and LLDA-based models.", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9995161294937134}, {"text": "recall", "start_pos": 64, "end_pos": 70, "type": "METRIC", "confidence": 0.9992040991783142}, {"text": "Fmeasure", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.994749128818512}]}], "introductionContent": [{"text": "Entity relation detection (ERD) aims at finding relations between pairs of Named Entities (NEs) in text.", "labels": [], "entities": [{"text": "Entity relation detection (ERD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8320700228214264}]}, {"text": "Availability of annotated corpora) and introduction of shared tasks (e.g. () has spurred a large amount of research in this field in recent times.", "labels": [], "entities": []}, {"text": "Researchers have used supervised and semi-supervised approaches, and explored rich features, kernel design (; and inference algorithms (, to detect predefined relations between NEs.", "labels": [], "entities": []}, {"text": "In this work, we explore if and how the latent semantics of the text can help in detecting entity relations.", "labels": [], "entities": [{"text": "detecting entity relations", "start_pos": 81, "end_pos": 107, "type": "TASK", "confidence": 0.794355571269989}]}, {"text": "For this, we adapt the Latent Dirichlet Allocation (LDA) approach to solve the ERD task.", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation (LDA", "start_pos": 23, "end_pos": 55, "type": "METRIC", "confidence": 0.8412798047065735}, {"text": "ERD task", "start_pos": 79, "end_pos": 87, "type": "TASK", "confidence": 0.9117257297039032}]}, {"text": "Specifically, we present a ERD system based on Maximum Entropy Discriminant Latent Dirichlet Allocation (MEDLDA).", "labels": [], "entities": [{"text": "Maximum Entropy Discriminant Latent Dirichlet Allocation (MEDLDA)", "start_pos": 47, "end_pos": 112, "type": "METRIC", "confidence": 0.7809959848721822}]}, {"text": "MEDLDA (, is an extension of Latent Dirichlet Allocation (LDA) that combines capability of capturing latent semantics with the discriminative capabilities of SVM.", "labels": [], "entities": []}, {"text": "There area number of challenges in employing the LDA framework for ERD.", "labels": [], "entities": [{"text": "ERD", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.8868416547775269}]}, {"text": "Latent Dirichlet Allocation and its supervised extensions such as Labeled LDA (LLDA) () and supervised LDA (sLDA) are powerful generative models that capture the underlying semantics of texts.", "labels": [], "entities": []}, {"text": "However, they have trouble discovering marginal classes and easily employing rich feature sets, both of which are important for ERD.", "labels": [], "entities": [{"text": "ERD", "start_pos": 128, "end_pos": 131, "type": "TASK", "confidence": 0.9721528887748718}]}, {"text": "We overcome the first drawback by employing a MEDLDA framework, which integrates maximum likelihood estimation (MLE) and maximum margin estimation (MME).", "labels": [], "entities": [{"text": "maximum likelihood estimation (MLE)", "start_pos": 81, "end_pos": 116, "type": "METRIC", "confidence": 0.7834595143795013}, {"text": "maximum margin estimation (MME)", "start_pos": 121, "end_pos": 152, "type": "METRIC", "confidence": 0.7188816467920939}]}, {"text": "Specifically, it is a combination of sLDA and support vector machines (SVMs).", "labels": [], "entities": []}, {"text": "Further, in order to employ rich and heterogeneous features we introduce a separate exponential family distribution for each feature, similar to (, into our MEDLDA model.", "labels": [], "entities": []}, {"text": "We formulate the relation detection task within the topic model framework as follows.", "labels": [], "entities": [{"text": "relation detection", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.873765766620636}]}, {"text": "Pairs of NE mentions and the text between them is considered Adopting the terminology used in the Automatic Context Extraction (ACE) program, specific NE instances are called mentions.", "labels": [], "entities": [{"text": "Automatic Context Extraction (ACE)", "start_pos": 98, "end_pos": 132, "type": "TASK", "confidence": 0.8031543691953024}]}, {"text": "Each mini-document has a relation type (analogous to the response variable in the supervised topic model).", "labels": [], "entities": []}, {"text": "The topic model infers the topic (relation type) distribution of the minidocuments.", "labels": [], "entities": []}, {"text": "The supervised topic model discovers a latent topic representation of the mini-documents and a response parameter distribution.", "labels": [], "entities": []}, {"text": "The topic representation is discovered with observed response variables during training.", "labels": [], "entities": []}, {"text": "During testing, the topic distribution of each mini-document can form a prediction of the relation types.", "labels": [], "entities": []}, {"text": "We carryout experiments to measure the effectiveness of our approach and compare it to SVMbased and LLDA-based models, as well as to a previous work using the same corpora.", "labels": [], "entities": []}, {"text": "We also measure and analyze the effectiveness of incorporating different features in our model relative to other models.", "labels": [], "entities": []}, {"text": "Our approach exhibits better overall precision, recall and Fmeasure than baseline systems.", "labels": [], "entities": [{"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.999523401260376}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9997603297233582}, {"text": "Fmeasure", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9974960684776306}]}, {"text": "We also find that the MEDLDA-based approach shows consistent capability for incorporation and improvement due to a variety of heterogeneous features.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "We describe the proposed model in Section 2 and the features that we explore in this work in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 describes the data, experiments, results and analyses.", "labels": [], "entities": []}, {"text": "We discuss the related work in Section 5 before concluding in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "As MEDLDA is a combination of maximum margin principle with maximum likelihood estimation for topic modes, we compare it with two baseline systems.", "labels": [], "entities": [{"text": "maximum likelihood estimation", "start_pos": 60, "end_pos": 89, "type": "METRIC", "confidence": 0.6846963167190552}]}, {"text": "The first, SVM, uses only the maximum margin principle, while the second, LLDA, uses only maximum likelihood estimation for topic modeling.", "labels": [], "entities": [{"text": "topic modeling", "start_pos": 124, "end_pos": 138, "type": "TASK", "confidence": 0.7596441805362701}]}, {"text": "We use 80% of the instances for training and 20% for testing.", "labels": [], "entities": []}, {"text": "The topic numbers and the penalty parameter of the cost function C are first determined", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Overall performance of the 3 systems", "labels": [], "entities": []}, {"text": " Table 3: Multi-class Classification Results with PlusCOMP for SVM, LLDA and MEDLDA for the six ACE 05  categories and NO-REL", "labels": [], "entities": [{"text": "PlusCOMP", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9691812992095947}, {"text": "SVM", "start_pos": 63, "end_pos": 66, "type": "DATASET", "confidence": 0.8309499621391296}, {"text": "MEDLDA", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.956825315952301}, {"text": "ACE 05", "start_pos": 96, "end_pos": 102, "type": "DATASET", "confidence": 0.842618465423584}, {"text": "NO-REL", "start_pos": 119, "end_pos": 125, "type": "DATASET", "confidence": 0.7130929231643677}]}]}