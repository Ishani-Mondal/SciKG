{"title": [{"text": "Semantic Clustering: an Attempt to Identify Multiword Expressions in Bengali", "labels": [], "entities": []}], "abstractContent": [{"text": "One of the key issues in both natural language understanding and generation is the appropriate processing of Multiword Expressions (MWEs).", "labels": [], "entities": [{"text": "natural language understanding and generation", "start_pos": 30, "end_pos": 75, "type": "TASK", "confidence": 0.6524759232997894}]}, {"text": "MWE can be defined as a semantic issue of a phrase where the meaning of the phrase may not be obtained from its constituents in a straightforward manner.", "labels": [], "entities": [{"text": "MWE", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9173480868339539}]}, {"text": "This paper presents an approach of identifying bigram noun-noun MWEs from a medium-size Bengali corpus by clustering the semantically related nouns and incorporating a vector space model for similarity measurement.", "labels": [], "entities": [{"text": "identifying bigram noun-noun MWEs", "start_pos": 35, "end_pos": 68, "type": "TASK", "confidence": 0.6631622388958931}]}, {"text": "Additional inclusion of the English WordNet::Similarity module also improves the results considerably.", "labels": [], "entities": []}, {"text": "The present approach also contributes to locate clusters of the synonymous noun words present in a document.", "labels": [], "entities": [{"text": "locate clusters of the synonymous noun words present in a document", "start_pos": 41, "end_pos": 107, "type": "TASK", "confidence": 0.6891791387037798}]}, {"text": "Experimental results draw a satisfactory conclusion after analyzing the Precision, Recall and F-score values.", "labels": [], "entities": [{"text": "Precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9989163875579834}, {"text": "Recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.987114429473877}, {"text": "F-score", "start_pos": 94, "end_pos": 101, "type": "METRIC", "confidence": 0.9949951171875}]}], "introductionContent": [{"text": "Over the past two decades or so, Multi-Word Expressions (MWEs) have been identified with an increasing amount of interest in the field of Computational linguistics and Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Multi-Word Expressions (MWEs)", "start_pos": 33, "end_pos": 62, "type": "TASK", "confidence": 0.7817533850669861}, {"text": "Natural Language Processing (NLP)", "start_pos": 168, "end_pos": 201, "type": "TASK", "confidence": 0.6558699856201807}]}, {"text": "The term MWE is used to refer the various types of linguistic units and expressions including idioms (kick the bucket, 'to die'), noun compounds (village community), phrasal verbs (find out, 'search') and other habitual collocations like conjunction (as well as), institutionalized phrases (many thanks) etc.", "labels": [], "entities": []}, {"text": "They can also be grossly defined as \"idiosyncratic interpretations that cross the word boundaries\").", "labels": [], "entities": []}, {"text": "MWE is considered as a special issue of semantics where the individual components of an expression often fail to keep their meanings intact within the actual meaning of the expression.", "labels": [], "entities": [{"text": "MWE", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9377678036689758}]}, {"text": "This opaqueness in meaning maybe partial or total depending on the degree of compositionality of the whole expression.", "labels": [], "entities": []}, {"text": "In Bengali, an analogous scenario can be observed when dealing with the expressions like compound nouns (taser ghar, 'house of cards', 'fragile'), complex predicates such as conjunct verbs (anuvab kara, 'to feel') and compound verbs (uthe para, 'to arise'), idioms (matir manus, 'down to the earth'), Named Entities (NEs) (Rabindranath Thakur, 'Rabindranath Tagore') etc.", "labels": [], "entities": []}, {"text": "In this paper, we analyze MWEs from the perspective of semantic interpretation.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 55, "end_pos": 78, "type": "TASK", "confidence": 0.7616539597511292}]}, {"text": "We have focused mainly on the fact that the individual meanings of the components are totally or partially diminished in order to form the actual semantics of the expression.", "labels": [], "entities": []}, {"text": "A constellation technique has been employed to group all nouns that are somehow related to the meaning of the component of any expression in the corpus and hence to build cluster for that component.", "labels": [], "entities": []}, {"text": "Two types of vector space based similarity techniques are applied to make a binary classification of the candidate nouns.", "labels": [], "entities": []}, {"text": "The intuition was that more the similarity of the components of an expression, less the probability of the candidate to become a MWE.", "labels": [], "entities": []}, {"text": "We have also shown the results using WordNet::Similarity module.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In the next section, we review the related work on MWE and graph-clustering approach for detecting compositionality.", "labels": [], "entities": [{"text": "MWE", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.8672099709510803}, {"text": "detecting compositionality", "start_pos": 89, "end_pos": 115, "type": "TASK", "confidence": 0.8740729093551636}]}, {"text": "Section 3 proposes a brief description of the semantic clustering approach.", "labels": [], "entities": [{"text": "semantic clustering", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.732264369726181}]}, {"text": "The system framework is elaborated in Section 4.", "labels": [], "entities": []}, {"text": "Experimental results and the various observations derived from our research are discussed in Section 5.", "labels": [], "entities": []}, {"text": "Finally, Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have used the standard IR matrices like Precision (P), Recall (R) and F-score (F) for evaluating the final results obtained from three modules.", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 43, "end_pos": 56, "type": "METRIC", "confidence": 0.9454966932535172}, {"text": "Recall (R)", "start_pos": 58, "end_pos": 68, "type": "METRIC", "confidence": 0.961568608880043}, {"text": "F-score (F)", "start_pos": 73, "end_pos": 84, "type": "METRIC", "confidence": 0.9667693972587585}]}, {"text": "Human annotated list is used as the gold standard for the evaluation.", "labels": [], "entities": []}, {"text": "The present system results are shown in.", "labels": [], "entities": []}, {"text": "These results are compared with the statistical baseline system described in).", "labels": [], "entities": []}, {"text": "Our baseline system is reported with the precision of 39.64%.", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9996198415756226}]}, {"text": "The predefined threshold has been varied to catch individual results in each case.", "labels": [], "entities": []}, {"text": "Increasing Recall in accordance with the increment of cut-off infers that the maximum numbers of MWEs are identified in a wide range of threshold.", "labels": [], "entities": [{"text": "Recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9614197015762329}]}, {"text": "But the Precision does not increase considerably.", "labels": [], "entities": [{"text": "Precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9592700004577637}]}, {"text": "It shows that the higher cut-off degrades the performance.", "labels": [], "entities": []}, {"text": "The reasonable results for Precision and Recall have been achieved in case of cosine-similarity at the cut-off value of 0.5 where Euclidean distance and WordNet Similarity give maximum precision at cut-off values of 0.4 and 0.5 respectively.", "labels": [], "entities": [{"text": "Precision", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.7573567032814026}, {"text": "Recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.6805628538131714}, {"text": "precision", "start_pos": 185, "end_pos": 194, "type": "METRIC", "confidence": 0.9933226704597473}]}, {"text": "In all cases, our system outperforms the baseline system.", "labels": [], "entities": []}, {"text": "It is interesting to observe that English WordNet becomes a very helpful tool to identify Bengali MWEs.", "labels": [], "entities": [{"text": "identify Bengali MWEs", "start_pos": 81, "end_pos": 102, "type": "TASK", "confidence": 0.6547409991423289}]}, {"text": "WordNet detects maximum MWEs correctly at the cut-off of 0.5.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9583138823509216}]}, {"text": "suggested that WordNet::Similarity measure is effective to identify empirical model of Multiword Expression Decomposability.", "labels": [], "entities": [{"text": "Multiword Expression Decomposability", "start_pos": 87, "end_pos": 123, "type": "TASK", "confidence": 0.7591864267985026}]}, {"text": "This is also proved in this experiment as well and even for Bengali language.", "labels": [], "entities": []}, {"text": "There are also candidates with very low value of similarity between their constituents (for example, ganer gajat (earth of song, affectionate of song), yet they are discarded from this experiment because of their low frequency of occurrence in the corpus which could not give any judgment regarding collocation.", "labels": [], "entities": []}, {"text": "Whether such an unexpectedly low frequent high decomposable elements warrant an entry in the lexicon depends on the type of the lexicon being built.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Total number of words, synsets and Fre- quencies of different POS based synsets", "labels": [], "entities": []}, {"text": " Table 3: Precision (P), Recall (R) and F-score (FS) (in %) for various measurements", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.9578355401754379}, {"text": "Recall (R)", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9657946825027466}, {"text": "F-score (FS)", "start_pos": 40, "end_pos": 52, "type": "METRIC", "confidence": 0.9660327732563019}]}]}