{"title": [{"text": "The Potsdam NLG systems at the GIVE-2.5 Challenge", "labels": [], "entities": [{"text": "GIVE-2.5 Challenge", "start_pos": 31, "end_pos": 49, "type": "DATASET", "confidence": 0.8862581253051758}]}], "abstractContent": [{"text": "We present the Potsdam natural language generation systems P1 and P2 of the GIVE-2.5 Challenge.", "labels": [], "entities": [{"text": "GIVE-2.5 Challenge", "start_pos": 76, "end_pos": 94, "type": "DATASET", "confidence": 0.7930913269519806}]}, {"text": "The systems implement two different referring expression generation models from Garoufi and Koller (2011) while behaving identically in all other respects.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.6437122126420339}]}, {"text": "In particular , P1 combines symbolic and corpus-based methods for the generation of successful referring expressions, while P2 is based on a purely symbolic model which serves as a qualified baseline for comparison.", "labels": [], "entities": []}, {"text": "We describe how the systems operated in the challenge and discuss the results, which indicate that P1 outperforms P2 in terms of several measures of referring expression success.", "labels": [], "entities": []}], "introductionContent": [{"text": "The Challenge on Generating Instructions in Virtual Environments (GIVE;) is an evaluation effort for natural language generation (NLG) systems, which focuses on real-time generation of situated language.", "labels": [], "entities": [{"text": "natural language generation (NLG)", "start_pos": 101, "end_pos": 134, "type": "TASK", "confidence": 0.8318725426991781}]}, {"text": "In this shared task, the role of the NLG system is to guide a human instruction follower (IF) through a 3D virtual world with the goal of completing a treasure-hunting task.", "labels": [], "entities": []}, {"text": "As an internet-based evaluation, GIVE has been successful in attracting both a large number of volunteers for the IF role and a high level of interest from the research community.", "labels": [], "entities": [{"text": "GIVE", "start_pos": 33, "end_pos": 37, "type": "DATASET", "confidence": 0.7908771634101868}, {"text": "IF", "start_pos": 114, "end_pos": 116, "type": "TASK", "confidence": 0.9447203278541565}]}, {"text": "In this paper, we report on our participation in the third installment of GIVE (GIVE-2.5;).", "labels": [], "entities": [{"text": "GIVE", "start_pos": 74, "end_pos": 78, "type": "DATASET", "confidence": 0.8169742822647095}]}, {"text": "Although most of the work on the generation of referring expressions (REs) to date has focused either on logical properties of REs, such as uniqueness and minimality, or on their degree of similarity to human-produced expressions (see Krahmer and van Deemter (To appear) fora comprehensive survey), we believe that it would be desirable to optimize a system directly for usefulness.", "labels": [], "entities": [{"text": "generation of referring expressions (REs)", "start_pos": 33, "end_pos": 74, "type": "TASK", "confidence": 0.6627907923289708}]}, {"text": "We therefore approach the RE generation task with a model that aims at computing the unique RE which is fastest for the hearer to resolve ().", "labels": [], "entities": [{"text": "RE generation task", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.9618648489316305}]}, {"text": "The purpose of the Potsdam NLG systems P1 and P2 at the challenge was to assess with a task-based evaluation to what extent the model actually manages to do so.", "labels": [], "entities": []}, {"text": "While we cannot present the RE generation modules in detail here (see for that), note that P1 implements the hybrid model mSCRISP of Garoufi and Koller, which extends the planning-based approach to sentence generation () with a statistical model of RE success.", "labels": [], "entities": [{"text": "RE generation", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.946489542722702}, {"text": "sentence generation", "start_pos": 198, "end_pos": 217, "type": "TASK", "confidence": 0.7468803524971008}, {"text": "RE", "start_pos": 249, "end_pos": 251, "type": "TASK", "confidence": 0.9694744944572449}]}, {"text": "This model was learnt from a corpus of human instruction giving sessions in the GIVE domain (, in which every RE was annotated with a measure of how easy it has been for the hearer to resolve.", "labels": [], "entities": [{"text": "GIVE domain", "start_pos": 80, "end_pos": 91, "type": "DATASET", "confidence": 0.8335108160972595}]}, {"text": "System P1 is therefore designed to optimize the REs it generates for understandability.", "labels": [], "entities": []}, {"text": "On the other hand, system P2 is an implementation of the baseline model EqualCosts of Garoufi and Koller.", "labels": [], "entities": []}, {"text": "This is a purely symbolic model that always computes a correct and unique RE, but does so without any empirical guidance about expected understandability.", "labels": [], "entities": [{"text": "RE", "start_pos": 74, "end_pos": 76, "type": "METRIC", "confidence": 0.8965314626693726}]}, {"text": "System P2 behaves in the exact same way as P1 in all respects, with the exception of the RE generation module.", "labels": [], "entities": []}, {"text": "It therefore serves as a qualified baseline against which we can compare the performance of the mSCRISP model.", "labels": [], "entities": []}, {"text": "We describe the two systems P1 and P2 in Section 2.", "labels": [], "entities": []}, {"text": "As the RE generation modules have been presented in full detail in, we mostly focus on the other aspects of the systems' behavior here.", "labels": [], "entities": [{"text": "RE generation", "start_pos": 7, "end_pos": 20, "type": "TASK", "confidence": 0.9219906330108643}]}, {"text": "We then comment on the evaluation results in Section 3 and conclude in Section 4.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}