{"title": [{"text": "Discovering Commonsense Entailment Rules Implicit in Sentences", "labels": [], "entities": [{"text": "Discovering Commonsense Entailment Rules Implicit in Sentences", "start_pos": 0, "end_pos": 62, "type": "TASK", "confidence": 0.8275593859808785}]}], "abstractContent": [{"text": "Reasoning about ordinary human situations and activities requires the availability of diverse types of knowledge, including expectations about the probable results of actions and the lexical entailments for many predicates.", "labels": [], "entities": [{"text": "Reasoning about ordinary human situations and activities", "start_pos": 0, "end_pos": 56, "type": "TASK", "confidence": 0.860663618360247}]}, {"text": "We describe initial work to acquire such a collection of conditional (if-then) knowledge by exploiting presuppositional discourse patterns (such as ones involving 'but', 'yet', and 'hop-ing to') and abstracting the matched material into general rules.", "labels": [], "entities": []}], "introductionContent": [{"text": "We are interested, ultimately, in enabling an inference system to reason forward from facts as well as backward from goals, using lexical knowledge together with world knowledge.", "labels": [], "entities": []}, {"text": "Creating appropriate collections of general world knowledge to support reasoning has long been a goal of researchers in Artificial Intelligence.", "labels": [], "entities": []}, {"text": "Efforts in information extraction, e.g.,, have focused on learning base facts about specific entities (such as that Barack Obama is president), and work in knowledge extraction, e.g., Van Durme and Schubert, has found generalizations (such as that a president may make a speech).", "labels": [], "entities": [{"text": "information extraction", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.7768944501876831}, {"text": "knowledge extraction", "start_pos": 156, "end_pos": 176, "type": "TASK", "confidence": 0.7414682507514954}]}, {"text": "While the latter provides a basis for possibilistic forward inference (Barack Obama probably makes a speech at least occasionally) when its meaning is sharpened), these resources don't provide a basis for saying what we might expect to happen if, for instance, someone crashes their car.", "labels": [], "entities": [{"text": "possibilistic forward inference", "start_pos": 38, "end_pos": 69, "type": "TASK", "confidence": 0.6310275495052338}]}, {"text": "That the driver in a car crash might be injured and the car damaged is a matter of commonsense, and, as such, is rarely stated directly.", "labels": [], "entities": []}, {"text": "However, it can be found in sentences where this expectation is disconfirmed: 'Sally crashed her car into a tree, but she wasn't hurt.'", "labels": [], "entities": []}, {"text": "We have been exploring the use of lexico-syntactic discourse patterns indicating disconfirmed expectations, as well as people's goals ('Joe apologized repeatedly, hoping to be forgiven').", "labels": [], "entities": []}, {"text": "The resulting rules, expressed at this point in natural language, area first step toward obtaining classes of general conditional knowledge typically not obtained by other methods.", "labels": [], "entities": []}], "datasetContent": [{"text": "Development was based on examples from the (handparsed) Brown Corpus and the (machine-parsed) British National Corpus, as alluded to above.", "labels": [], "entities": [{"text": "Brown Corpus", "start_pos": 56, "end_pos": 68, "type": "DATASET", "confidence": 0.9782699346542358}, {"text": "British National Corpus", "start_pos": 94, "end_pos": 117, "type": "DATASET", "confidence": 0.9425063729286194}]}, {"text": "These corpora were chosen for their broad coverage of everyday situations and edited writing.", "labels": [], "entities": []}, {"text": "As the examples in the preceding subsections indicate, rules extracted by our method often describe complex consequences or reasons, and subtle relations among adjectival attributes, that appear to be quite different from the kinds of rules targeted in previous work (as discussed earlier, or at venues such as that of).", "labels": [], "entities": []}, {"text": "While we would like to evaluate the discovered rules by looking at inferences made with them, that must wait until logical forms are automatically created; here we judge the rules themselves.", "labels": [], "entities": []}, {"text": "The statement above is a reasonably clear, entirely plausible, generic claim and seems neither too specific nor too general or vague to be useful: 1.", "labels": [], "entities": []}, {"text": "2. I lean towards agreement.", "labels": [], "entities": [{"text": "agreement", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9704089760780334}]}, {"text": "3. I'm not sure..", "labels": [], "entities": []}, {"text": "Figure 2: Instructions for judging of unsharpened factoids.", "labels": [], "entities": [{"text": "judging of unsharpened factoids", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.8745185732841492}]}], "tableCaptions": []}