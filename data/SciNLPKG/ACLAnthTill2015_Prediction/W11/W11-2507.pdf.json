{"title": [{"text": "Experimenting with Transitive Verbs in a DisCoCat", "labels": [], "entities": []}], "abstractContent": [{"text": "Formal and distributional semantic models offer complementary benefits in modeling meaning.", "labels": [], "entities": []}, {"text": "The categorical compositional dis-tributional model of meaning of Coecke et al.", "labels": [], "entities": []}, {"text": "(2010) (abbreviated to DisCoCat in the title) combines aspects of both to provide a general framework in which meanings of words, obtained distributionally, are composed using methods from the logical setting to form sentence meaning.", "labels": [], "entities": []}, {"text": "Concrete consequences of this general abstract setting and applications to empirical data are under active study (Grefen-stette et al., 2011; Grefenstette and Sadrzadeh, 2011).", "labels": [], "entities": []}, {"text": "In this paper, we extend this study by examining transitive verbs, represented as matrices in a DisCoCat.", "labels": [], "entities": []}, {"text": "We discuss three ways of constructing such matrices, and evaluate each method in a disambiguation task developed by Grefenstette and Sadrzadeh (2011).", "labels": [], "entities": []}, {"text": "1 Background The categorical distributional compositional model of meaning of Coecke et al.", "labels": [], "entities": []}, {"text": "(2010) combines the modularity of formal semantic models with the empirical nature of vector space models of lexical semantics.", "labels": [], "entities": []}, {"text": "The meaning of a sentence is defined to be the application of its grammatical structure-represented in a type-logical model-to the kro-necker product of the meanings of its words, as computed in a distributional model.", "labels": [], "entities": []}, {"text": "The concrete and experimental consequences of this setting, and other models that aim to bring together the logical and distributional approaches, are active topics in current natural language semantics research, e.g. see (Grefenstette et al.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "In this section, we describe the experiment used to evaluate and compare these three methods.", "labels": [], "entities": []}, {"text": "The experiment is on the dataset developed in ( ).", "labels": [], "entities": []}, {"text": "Parameters We used the parameters described by for the noun and verb vectors.", "labels": [], "entities": []}, {"text": "All vectors were built from a lemmatised version of the BNC.", "labels": [], "entities": [{"text": "BNC", "start_pos": 56, "end_pos": 59, "type": "DATASET", "confidence": 0.9799550175666809}]}, {"text": "The noun basis was the 2000 most common context words, basis weights were the probability of context words given the target word divided by the overall probability of the context word.", "labels": [], "entities": []}, {"text": "These features were chosen to enable easy comparison of our experimental results with those of Mitchell and Lapata's original experiment, in spite of the fact that there maybe more sophisticated lexical distributional models available.", "labels": [], "entities": []}, {"text": "Task This is an extension of Mitchell and Lapata (2008)'s disambiguation task from intransitive to transitive sentences.", "labels": [], "entities": []}, {"text": "The general idea behind the transitive case (similar to the intransitive one) is as follows: meanings of ambiguous transitive verbs vary based on their subject-object context.", "labels": [], "entities": []}, {"text": "For instance the verb 'meet' means 'satisfied' in the context 'the system met the criterion' and it means 'visit', in the context 'the child met the house'.", "labels": [], "entities": []}, {"text": "Hence if we build meaning vectors for these sentences compositionally, the degrees of synonymity of the sentences can be used to disambiguate the meanings of the verbs in them.", "labels": [], "entities": []}, {"text": "Suppose a verb has two meanings a and band that it has occurred in two sentences.", "labels": [], "entities": []}, {"text": "Then if in both of these sentences it has its meaning a, the two sentences will have a high degree of synonymity, whereas if in one sentence the verb has meaning a and in the other meaning b, the sentences will have a lower degree of synonymity.", "labels": [], "entities": []}, {"text": "For instance 'the system met the criterion' and 'the system satisfied the criterion' have a high degree of semantic similarity, and similarly for 'the child met the house' and 'the child visited the house'.", "labels": [], "entities": []}, {"text": "This degree decreases for the pair 'the child met the house' and 'the child satisfied the house'.", "labels": [], "entities": [{"text": "degree", "start_pos": 5, "end_pos": 11, "type": "METRIC", "confidence": 0.9779874086380005}]}, {"text": "Dataset The dataset is built using the same guidelines as, using transitive verbs obtained from CELEX 1 paired with subjects and objects.", "labels": [], "entities": [{"text": "CELEX 1", "start_pos": 96, "end_pos": 103, "type": "DATASET", "confidence": 0.8959671258926392}]}, {"text": "We first picked 10 transitive verbs from the most frequent verbs of the BNC.", "labels": [], "entities": [{"text": "BNC", "start_pos": 72, "end_pos": 75, "type": "DATASET", "confidence": 0.9585769176483154}]}, {"text": "For each verb, two different non-overlapping meanings were retrieved, by using the JCN (Jiang Conrath) information content synonymity measure of WordNet to select maximally different synsets.", "labels": [], "entities": [{"text": "JCN (Jiang Conrath) information content", "start_pos": 83, "end_pos": 122, "type": "DATASET", "confidence": 0.8969572016171047}, {"text": "WordNet", "start_pos": 145, "end_pos": 152, "type": "DATASET", "confidence": 0.7739779949188232}]}, {"text": "For instance for 'meet' we obtained 'visit' and 'satisfy'.", "labels": [], "entities": [{"text": "satisfy", "start_pos": 49, "end_pos": 56, "type": "METRIC", "confidence": 0.9604771733283997}]}, {"text": "For each original verb, ten sentences containing that verb with the same role were retrieved from the BNC.", "labels": [], "entities": [{"text": "BNC", "start_pos": 102, "end_pos": 105, "type": "DATASET", "confidence": 0.9540101885795593}]}, {"text": "Examples of such sentences are 'the system met the criterion' and 'the child met the house'.", "labels": [], "entities": []}, {"text": "For each such sentence, we generated two other related sentences by substituting their verbs by each of their two synonyms.", "labels": [], "entities": []}, {"text": "For instance, we obtained 'the system satisfied the criterion' and 'the system visited the criterion' for the first meaning and 'the child satisfied the house' and 'the child visited the house' for the second meaning . This procedure provided us with 200 pairs of sentences.", "labels": [], "entities": []}, {"text": "The dataset was split into four non-identical sections of 100 entries such that each sentence appears in exactly two sections.", "labels": [], "entities": []}, {"text": "Each section was given to a group of evaluators who were asked to assign a similarity score to simple transitive sentence pairs formed from the verb, subject, and object provided in each entry (e.g. 'the system met the criterion' from 'system meet criterion').", "labels": [], "entities": [{"text": "similarity score", "start_pos": 75, "end_pos": 91, "type": "METRIC", "confidence": 0.9527141749858856}]}, {"text": "The scoring scale for human judgement was, where 1 was most dissimilar and 7 most identical.", "labels": [], "entities": [{"text": "scoring scale", "start_pos": 4, "end_pos": 17, "type": "METRIC", "confidence": 0.9455220699310303}, {"text": "human judgement", "start_pos": 22, "end_pos": 37, "type": "TASK", "confidence": 0.689267635345459}]}, {"text": "Separately from the group annotation, each pair in the dataset was given the additional arbitrary classification of HIGH or LOW similarity by the authors.", "labels": [], "entities": [{"text": "HIGH", "start_pos": 116, "end_pos": 120, "type": "METRIC", "confidence": 0.9894598722457886}, {"text": "LOW similarity", "start_pos": 124, "end_pos": 138, "type": "METRIC", "confidence": 0.8802630603313446}]}, {"text": "Evaluation Method To evaluate our methods, we first applied our formulae to compute the similarity of each phrase pair on a scale of and then compared it with human judgement of the same pair.", "labels": [], "entities": []}, {"text": "The comparison was performed by measuring Spearman's \u03c1, a rank correlation coefficient ranging from -1 to 1.", "labels": [], "entities": [{"text": "Spearman's \u03c1", "start_pos": 42, "end_pos": 54, "type": "METRIC", "confidence": 0.6386826435724894}, {"text": "rank correlation coefficient", "start_pos": 58, "end_pos": 86, "type": "METRIC", "confidence": 0.80320805311203}]}, {"text": "This provided us with the degree of correlation between the similarities as computed by our model and as judged by human evaluators.", "labels": [], "entities": []}, {"text": "Following, we also computed the mean of HIGH and LOW scores.", "labels": [], "entities": [{"text": "HIGH", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9831621646881104}, {"text": "LOW scores", "start_pos": 49, "end_pos": 59, "type": "METRIC", "confidence": 0.9658010900020599}]}, {"text": "However, these scores were solely based on the authors' personal judgements and as such (and on their own) do not provide a very reliable measure.", "labels": [], "entities": []}, {"text": "Therefore, like, the models were ultimately judged by Spearman's \u03c1.", "labels": [], "entities": []}, {"text": "The results are presented in table 4.", "labels": [], "entities": []}, {"text": "The additive and multiplicative rows have, as composition operation, vector addition and component-wise multiplication.", "labels": [], "entities": []}, {"text": "The Baseline is from a non-compositional approach; it is obtained by comparing the verb vectors of each pair directly and ignoring their subjects and objects.", "labels": [], "entities": []}, {"text": "The UpperBound is set to be interannotator agreement.", "labels": [], "entities": [{"text": "UpperBound", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.9832655191421509}]}], "tableCaptions": [{"text": " Table 1: Results of compositional disambiguation.", "labels": [], "entities": [{"text": "compositional disambiguation", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.9338161051273346}]}]}