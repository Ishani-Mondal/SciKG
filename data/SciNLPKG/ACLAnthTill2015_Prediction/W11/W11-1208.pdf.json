{"title": [{"text": "Paraphrase Fragment Extraction from Monolingual Comparable Corpora", "labels": [], "entities": [{"text": "Paraphrase Fragment Extraction from Monolingual Comparable Corpora", "start_pos": 0, "end_pos": 66, "type": "TASK", "confidence": 0.8213787249156407}]}], "abstractContent": [{"text": "We present a novel paraphrase fragment pair extraction method that uses a monolingual comparable corpus containing different articles about the same topics or events.", "labels": [], "entities": [{"text": "paraphrase fragment pair extraction", "start_pos": 19, "end_pos": 54, "type": "TASK", "confidence": 0.7523021847009659}]}, {"text": "The procedure consists of document pair extraction, sentence pair extraction, and fragment pair extraction.", "labels": [], "entities": [{"text": "document pair extraction", "start_pos": 26, "end_pos": 50, "type": "TASK", "confidence": 0.6843324104944865}, {"text": "sentence pair extraction", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.7630013624827067}, {"text": "fragment pair extraction", "start_pos": 82, "end_pos": 106, "type": "TASK", "confidence": 0.7099133133888245}]}, {"text": "At each stage, we evaluate the intermediate results manually, and tune the later stages accordingly.", "labels": [], "entities": []}, {"text": "With this minimally supervised approach, we achieve 62% of accuracy on the paraphrase fragment pairs we collected and 67% extracted from the MSR corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9994606375694275}, {"text": "MSR corpus", "start_pos": 141, "end_pos": 151, "type": "DATASET", "confidence": 0.863492339849472}]}, {"text": "The results look promising, given the minimal supervision of the approach, which can be further scaled up.", "labels": [], "entities": []}], "introductionContent": [{"text": "Paraphrase is an important linguistic phenomenon which occurs widely inhuman languages.", "labels": [], "entities": [{"text": "Paraphrase is", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.901839941740036}]}, {"text": "Since paraphrases capture the variations of linguistic expressions while preserving the meaning, they are very useful in many applications, such as machine translation, document summarization (), and recognizing textual entailment (RTE) ().", "labels": [], "entities": [{"text": "machine translation", "start_pos": 148, "end_pos": 167, "type": "TASK", "confidence": 0.798220694065094}, {"text": "document summarization", "start_pos": 169, "end_pos": 191, "type": "TASK", "confidence": 0.7051747143268585}, {"text": "recognizing textual entailment (RTE)", "start_pos": 200, "end_pos": 236, "type": "TASK", "confidence": 0.85128386815389}]}, {"text": "However, such resources are not trivial to obtain.", "labels": [], "entities": []}, {"text": "If we make a comparison between paraphrase and MT, the latter has large parallel bilingual/multilingual corpora to acquire translation pairs in different granularity; while it is difficult to find a \"naturally\" occurred paraphrase \"parallel\" corpora.", "labels": [], "entities": [{"text": "MT", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.8908258080482483}]}, {"text": "Furthermore, in MT, certain words can be translated into a (rather) small set of candidate words in the target language; while in principle, each paraphrase can have infinite number of \"target\" expressions, which reflects the variety of each human language.", "labels": [], "entities": [{"text": "MT", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.9897380471229553}]}, {"text": "A variety of paraphrase extraction approaches have been proposed recently, and they require different types of training data.", "labels": [], "entities": [{"text": "paraphrase extraction", "start_pos": 13, "end_pos": 34, "type": "TASK", "confidence": 0.9116852581501007}]}, {"text": "Some require bilingual parallel corpora, others require monolingual parallel corpora ( or monolingual comparable corpora ( . In this paper, we focus on extracting paraphrase fragments from monolingual corpora, because this is the most abundant source of data.", "labels": [], "entities": []}, {"text": "Additionally, this would potentially allow us to extract paraphrases fora variety of languages that have monolingual corpora, but which do not have easily accessible parallel corpora.", "labels": [], "entities": []}, {"text": "This paper makes the following contributions: 1.", "labels": [], "entities": []}, {"text": "We adapt a translation fragment pair extraction method to paraphrase extraction, i.e., from bilingual corpora to monolingual corpora.", "labels": [], "entities": [{"text": "translation fragment pair extraction", "start_pos": 11, "end_pos": 47, "type": "TASK", "confidence": 0.7143504470586777}, {"text": "paraphrase extraction", "start_pos": 58, "end_pos": 79, "type": "TASK", "confidence": 0.7157675623893738}]}, {"text": "2. We construct a large collection of paraphrase fragments from monolingual comparable corpora and achieve similar quality from a manually-checked paraphrase corpus.", "labels": [], "entities": []}, {"text": "3. We evaluate both intermediate and final results of the paraphrase collection, using the crowdsourcing technique, which is effective, fast, and cheap.", "labels": [], "entities": [{"text": "paraphrase collection", "start_pos": 58, "end_pos": 79, "type": "TASK", "confidence": 0.9317905008792877}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Distribution of the Extracted Fragment Pairs of  our Corpus and MSR Corpus. We manually evaluated  1051 sentence pairs in all. We use LCS or word aligner as  the initialization and apply n-gram-based or chunk-based  phrase extraction. The first column serves as the baseline.", "labels": [], "entities": [{"text": "MSR Corpus", "start_pos": 74, "end_pos": 84, "type": "DATASET", "confidence": 0.9612146317958832}, {"text": "phrase extraction", "start_pos": 226, "end_pos": 243, "type": "TASK", "confidence": 0.6731624752283096}]}, {"text": " Table 3: The size of our corpus. We only used ca. 10%  of the GIGAWORD corpus in the experiments and the size  of the collection at each stage are shown in the table.", "labels": [], "entities": [{"text": "GIGAWORD corpus", "start_pos": 63, "end_pos": 78, "type": "DATASET", "confidence": 0.9543998837471008}]}]}