{"title": [], "abstractContent": [{"text": "This paper describes an error detection mechanism which helps in validation of dependency treebank annotation.", "labels": [], "entities": [{"text": "error detection", "start_pos": 24, "end_pos": 39, "type": "TASK", "confidence": 0.6379209160804749}]}, {"text": "Consistency in treebank annotation is a must for making data as error-free as possible and for assuring the usefulness of treebank.", "labels": [], "entities": []}, {"text": "This work is aimed at ensuring this consistency and to make the task of validation cost effective by detecting major errors induced during completely manual annotation.", "labels": [], "entities": [{"text": "consistency", "start_pos": 36, "end_pos": 47, "type": "METRIC", "confidence": 0.9936771988868713}, {"text": "validation", "start_pos": 72, "end_pos": 82, "type": "TASK", "confidence": 0.980305552482605}]}, {"text": "We evaluated our system on the Hindi dependency treebank which is currently underdevelopment.", "labels": [], "entities": [{"text": "Hindi dependency treebank", "start_pos": 31, "end_pos": 56, "type": "DATASET", "confidence": 0.8155808647473654}]}, {"text": "We could detect 76.63% of errors at dependency level.", "labels": [], "entities": [{"text": "errors", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.9001706838607788}]}, {"text": "Results show that our system performs well even when the training data is low.", "labels": [], "entities": []}], "introductionContent": [{"text": "For effective processing of text, tools at different conceptual levels, say from letter/syllable level to discourse level are needed.", "labels": [], "entities": []}, {"text": "Output of these tools can then be used in different NLP based applications, beginning with simple spell checkers to sophisticated machine translation systems.", "labels": [], "entities": [{"text": "spell checkers", "start_pos": 98, "end_pos": 112, "type": "TASK", "confidence": 0.836495578289032}, {"text": "machine translation", "start_pos": 130, "end_pos": 149, "type": "TASK", "confidence": 0.7183544635772705}]}, {"text": "These tools could be completely rule-based, statistical or hybrid systems.", "labels": [], "entities": []}, {"text": "To build such tools, manually annotated gold standard corpora are required.", "labels": [], "entities": []}, {"text": "Annotated corpora are mostly obtained by either manual or semi-automated processes.", "labels": [], "entities": []}, {"text": "Hence, there are chances that errors are introduced either by human annotators or by the preprocessed output of automated tools.", "labels": [], "entities": []}, {"text": "It is crucial that the annotated corpora are free of anomalies (errors) and inconsistencies.", "labels": [], "entities": []}, {"text": "In the process of making these corpora error free, experts need to validate them.", "labels": [], "entities": []}, {"text": "As the data is already annotated carefully (which is a time-consuming task), we need tools that can supplement the validators\" task with a view of making the overall task fast, without compromising on reliability.", "labels": [], "entities": []}, {"text": "With the help of such a tool, a validator can directly go to error instances and correct them.", "labels": [], "entities": []}, {"text": "Therefore, we need the tool to have high recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9993019104003906}]}, {"text": "It is easy to see that a human validator can reject unintuitive errors (false positives) without much effort; one can therefore compromise a little bit on precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 155, "end_pos": 164, "type": "METRIC", "confidence": 0.997890293598175}]}, {"text": "In this paper, we propose an error detection mechanism to detect dependency errors in the Hindi treebank ) annotation.", "labels": [], "entities": [{"text": "error detection", "start_pos": 29, "end_pos": 44, "type": "TASK", "confidence": 0.6315599977970123}, {"text": "Hindi treebank ) annotation", "start_pos": 90, "end_pos": 117, "type": "DATASET", "confidence": 0.9206751137971878}]}, {"text": "We classify the identified errors under specific categories for the benefit of the validators, who may choose to correct a specific type of error atone time.", "labels": [], "entities": []}, {"text": "Though we did experiments on Hindi treebank, our approach can be applied to any under developing treebank with minimal effort.", "labels": [], "entities": [{"text": "Hindi treebank", "start_pos": 29, "end_pos": 43, "type": "DATASET", "confidence": 0.8205865323543549}]}, {"text": "The paper is arranged as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives a brief overview of the Hindi dependency treebank.", "labels": [], "entities": [{"text": "Hindi dependency treebank", "start_pos": 40, "end_pos": 65, "type": "DATASET", "confidence": 0.7082115610440572}]}, {"text": "Details of the information annotated, annotation procedure and types of possible errors in the treebank are discussed in section 3.", "labels": [], "entities": []}, {"text": "We present the related work in section 4.", "labels": [], "entities": []}, {"text": "In section 5, we describe our approach.", "labels": [], "entities": []}, {"text": "Results of our approach are presented in section 6.", "labels": [], "entities": []}, {"text": "Section 7 focuses on a general discussion about the results and approach and proposes a future direction to our work.", "labels": [], "entities": []}, {"text": "We conclude our paper in section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used same data used by for evaluation.", "labels": [], "entities": []}, {"text": "This is a 65k-token manually annotated and validated sample of data (2694 sentences) derived from the Hindi dependency treebank.", "labels": [], "entities": [{"text": "Hindi dependency treebank", "start_pos": 102, "end_pos": 127, "type": "DATASET", "confidence": 0.682529071966807}]}, {"text": "The data is divided into 40k, 10k and 15k for training, development and testing respectively.", "labels": [], "entities": []}, {"text": "We used training data to train the model and development data to tune the parameters like threshold values.", "labels": [], "entities": []}, {"text": "For our experiments, thres_max= 0.8, thres_min = 0.2, thres_minX = 0.25 and thres_dif = 0.25 gave the best performance.", "labels": [], "entities": [{"text": "thres_max", "start_pos": 21, "end_pos": 30, "type": "METRIC", "confidence": 0.7860711812973022}]}, {"text": "shows the performance of PBSM and compares it with FBSM.", "labels": [], "entities": [{"text": "PBSM", "start_pos": 25, "end_pos": 29, "type": "DATASET", "confidence": 0.8472532629966736}, {"text": "FBSM", "start_pos": 51, "end_pos": 55, "type": "DATASET", "confidence": 0.8264519572257996}]}, {"text": "FBSM of could identify only 18.74% of the dependency errors.", "labels": [], "entities": [{"text": "FBSM", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.6943672299385071}]}, {"text": "The precision recorded for this approach was also quite low.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9997459053993225}]}, {"text": "But with our PBSM, we could detect 57.06% of the dependency errors with a reasonable precision value.", "labels": [], "entities": [{"text": "precision", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9987963438034058}]}, {"text": "Note that, our main aim is to achieve a high recall value.", "labels": [], "entities": [{"text": "recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9992864727973938}]}, {"text": "The false positives can be easily discarded by the validators.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Error detection at dependency level us- ing FBSM of Ambati et al. (2010) and our PBSM", "labels": [], "entities": [{"text": "Error detection", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.7056198716163635}, {"text": "FBSM", "start_pos": 54, "end_pos": 58, "type": "DATASET", "confidence": 0.798861563205719}, {"text": "PBSM", "start_pos": 91, "end_pos": 95, "type": "DATASET", "confidence": 0.6896716356277466}]}, {"text": " Table 2. Error Detection at dependency level us- ing overall system of Ambati et al. (2010) with  FBSM and PBSM", "labels": [], "entities": [{"text": "FBSM", "start_pos": 99, "end_pos": 103, "type": "DATASET", "confidence": 0.9249252080917358}, {"text": "PBSM", "start_pos": 108, "end_pos": 112, "type": "DATASET", "confidence": 0.6045299172401428}]}]}