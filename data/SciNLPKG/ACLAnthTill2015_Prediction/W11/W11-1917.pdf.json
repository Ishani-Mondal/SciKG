{"title": [{"text": "Coreference Resolution with Loose Transitivity Constraints", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9415118396282196}]}], "abstractContent": [{"text": "Our system treats coreference resolution as an integer linear programming (ILP) problem.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.9739244878292084}]}, {"text": "Extending Denis and Baldridge (2007) and Finkel and Manning (2008)'s work, we exploit loose transitivity constraints on coreference pairs.", "labels": [], "entities": []}, {"text": "Instead of enforcing transitivity closure constraints, which brings \u00c7\u00b4\u00d2 \u00bf \u00b5 complexity, we employ a strategy to reduce the number of constraints without large performance decrease , i.e., eliminating coreference pairs with probability below a threshold \ud97b\udf59.", "labels": [], "entities": []}, {"text": "Experimental results show that it achieves a better performance than pairwise classifiers.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes our coreference resolution system participating in the close track of CoNLL 2011 shared task).", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.9184467196464539}, {"text": "CoNLL 2011 shared task", "start_pos": 91, "end_pos": 113, "type": "DATASET", "confidence": 0.8669653534889221}]}, {"text": "The task aims to identify all mentions of entities and events and cluster them into equivalence classes in OntoNotes Corpus ().", "labels": [], "entities": [{"text": "OntoNotes Corpus", "start_pos": 107, "end_pos": 123, "type": "DATASET", "confidence": 0.8901201486587524}]}, {"text": "During the last decade, several machine learning methods for coreference resolution have been developed, from local pairwise classifiers () to global learning methods (, from simple morphological, grammatical features to more liguistically rich features on syntactic structures and semantic relations (.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.9554708003997803}]}, {"text": "Our system supports both local classifiers and global learning.", "labels": [], "entities": []}, {"text": "Maximum entropy model is used for anaphoricity and coreference, because it assigns probability mass to mentions and coreference pairs directly.", "labels": [], "entities": [{"text": "coreference", "start_pos": 51, "end_pos": 62, "type": "TASK", "confidence": 0.9776586890220642}]}, {"text": "In global phase, instead of determining each coreference pair independently in a greedy fashion, we employ an integer linear programming (ILP) formulation for this problem.", "labels": [], "entities": []}, {"text": "Extending and's work, we introduce a loose selection strategy for transitivity constraints, attempting to overcome huge computation complexity brought by transitivity closure constraints.", "labels": [], "entities": []}, {"text": "Details are described in section 2.3.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the paper we mainly take noun phrases (NPs) and pronouns as candidate mentions, and ignore other phrases since more than 91% of the mentions are NPs and pronouns.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results of mention dection", "labels": [], "entities": [{"text": "mention dection", "start_pos": 21, "end_pos": 36, "type": "DATASET", "confidence": 0.6151552349328995}]}, {"text": " Table 2: Results of baseline systems", "labels": [], "entities": []}, {"text": " Table 3: Results on different probability thresholds and strategies", "labels": [], "entities": []}, {"text": " Table 5: Results for development and test data", "labels": [], "entities": []}]}