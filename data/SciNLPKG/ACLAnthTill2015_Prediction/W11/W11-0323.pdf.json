{"title": [{"text": "Filling the Gap: Semi-Supervised Learning for Opinion Detection Across Domains", "labels": [], "entities": [{"text": "Opinion Detection Across Domains", "start_pos": 46, "end_pos": 78, "type": "TASK", "confidence": 0.8142244070768356}]}], "abstractContent": [{"text": "We investigate the use of Semi-Supervised Learning (SSL) in opinion detection both in sparse data situations and for domain adaptation.", "labels": [], "entities": [{"text": "opinion detection", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.887150913476944}, {"text": "domain adaptation", "start_pos": 117, "end_pos": 134, "type": "TASK", "confidence": 0.7365841716527939}]}, {"text": "We show that co-training reaches the best results in an in-domain setting with small labeled data sets, with a maximum absolute gain of 33.5%.", "labels": [], "entities": []}, {"text": "For domain transfer, we show that self-training gains an absolute improvement in labeling accuracy for blog data of 16% over the supervised approach with target domain training data.", "labels": [], "entities": [{"text": "domain transfer", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.8541260063648224}, {"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9585459232330322}]}], "introductionContent": [{"text": "Rich and free opinions published electronically and, more recently, on the WWW offer ample opportunities to discover individual's attitudes towards certain topics, products, or services.", "labels": [], "entities": [{"text": "WWW", "start_pos": 75, "end_pos": 78, "type": "DATASET", "confidence": 0.9078189134597778}]}, {"text": "To capitalize on this enormous body of opinions, researchers have been working in the area of opinion mining since the late 1990s.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 94, "end_pos": 108, "type": "TASK", "confidence": 0.7344755679368973}]}, {"text": "Opinion detection seeks to automatically determine the presence or absence of opinions in a text, and it is therefore a fundamental task for opinion mining.", "labels": [], "entities": [{"text": "Opinion detection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8741668462753296}, {"text": "opinion mining", "start_pos": 141, "end_pos": 155, "type": "TASK", "confidence": 0.829988569021225}]}, {"text": "In order to capture subtle and creative opinions, opinion detection systems generally assume that a large body of opinion-labeled data are available.", "labels": [], "entities": [{"text": "opinion detection", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.8024567365646362}]}, {"text": "However, collections of opinion-labeled data are often limited, especially at the granularity level of sentences; and manual annotation is tedious, expensive and error-prone.", "labels": [], "entities": []}, {"text": "The shortage of opinion-labeled data is less challenging in some data domains (e.g., reviews) than in others (e.g., blog posts).", "labels": [], "entities": []}, {"text": "A simple method for improving accuracies in challenging domains would be to borrow opinion-labeled data from a non-target data domain; but this approach often fails because opinion detection strategies designed for one data domain generally do not perform well in another domain.", "labels": [], "entities": [{"text": "opinion detection", "start_pos": 173, "end_pos": 190, "type": "TASK", "confidence": 0.7371940314769745}]}, {"text": "One reason for failure of the simple transfer approach is that the information used for opinion detection is typically lexical, and lexical means of expressing opinions may vary not only from domain to domain, but also from register to register.", "labels": [], "entities": [{"text": "opinion detection", "start_pos": 88, "end_pos": 105, "type": "TASK", "confidence": 0.803140252828598}]}, {"text": "For example, while the word \"awesome\" is a good indicator of an opinion in blogs, it is less likely to occur in the same role in newspaper texts.", "labels": [], "entities": []}, {"text": "While it is difficult to obtain opinion-labeled data, one can easily collect almost infinite unlabeled usergenerated data that contain opinions.", "labels": [], "entities": []}, {"text": "The use of Semi-Supervised Learning (SSL), motivated by limited labeled data and plentiful unlabeled data in the real world, has achieved promising results in various NLP studies (e.g.,), yet it has not been fully investigated for use in opinion detection.", "labels": [], "entities": [{"text": "opinion detection", "start_pos": 238, "end_pos": 255, "type": "TASK", "confidence": 0.9227242469787598}]}, {"text": "Although studies have shown that simple SSL methods are promising for extracting opinion features or patterns using limited opinion-labeled data (e.g.,), few efforts have been made either to apply SSL directly to opinion detection or to examine more sophisticated SSL methods.", "labels": [], "entities": [{"text": "opinion detection", "start_pos": 213, "end_pos": 230, "type": "TASK", "confidence": 0.7801454961299896}]}, {"text": "This research is intended to fill the gap regarding application of SSL in opinion detection.", "labels": [], "entities": [{"text": "SSL", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.981484055519104}, {"text": "opinion detection", "start_pos": 74, "end_pos": 91, "type": "TASK", "confidence": 0.8490934073925018}]}, {"text": "We investigate a range of SSL algorithms with a focus on selftraining and co-training in three types of electronic documents: edited news articles, semi-structured movie reviews, and the informal and unstructured content of the blogosphere.", "labels": [], "entities": []}, {"text": "We conclude that SSL is a successful method for handling the shortage of opinion labeled data and the domain transfer problem.", "labels": [], "entities": [{"text": "SSL", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9817677140235901}, {"text": "domain transfer", "start_pos": 102, "end_pos": 117, "type": "TASK", "confidence": 0.785245418548584}]}], "datasetContent": [{"text": "Our research treats opinion detection as a binary classification problem with two categories: subjective sentences and objective sentences.", "labels": [], "entities": [{"text": "opinion detection", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.8534438610076904}]}, {"text": "It is evaluated in terms of classification accuracy.", "labels": [], "entities": [{"text": "classification", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.9332234859466553}, {"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9572394490242004}]}, {"text": "Since a document is normally a mixture of facts and opinions (), sub-document level opinion detection is more useful and meaningful than document-level opinion detection.", "labels": [], "entities": [{"text": "sub-document level opinion detection", "start_pos": 65, "end_pos": 101, "type": "TASK", "confidence": 0.7634588778018951}, {"text": "document-level opinion detection", "start_pos": 137, "end_pos": 169, "type": "TASK", "confidence": 0.5926454762617747}]}, {"text": "Thus, we conduct all experiments on the sentence level.", "labels": [], "entities": []}, {"text": "The remainder of this section explains the data sets and tools used in this study and presents the experimental design and parameter settings.", "labels": [], "entities": []}, {"text": "We conducted three groups of experiments: 1) to investigate the effectiveness of the SSL approach for opinion detection; 2) to explore different co-training strategies; and 3) to evaluate the applicability of SSL for domain adaptation.", "labels": [], "entities": [{"text": "opinion detection", "start_pos": 102, "end_pos": 119, "type": "TASK", "confidence": 0.8412424027919769}, {"text": "domain adaptation", "start_pos": 217, "end_pos": 234, "type": "TASK", "confidence": 0.7653931379318237}]}, {"text": "Overall, our results suggest that SSL improves accuracy for opinion detection although the contribution of SSL varies across data domains and different strategies need to be applied to achieve optimized performance.", "labels": [], "entities": [{"text": "SSL", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.9889709949493408}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9974978566169739}, {"text": "opinion detection", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.8656465411186218}]}, {"text": "For the movie review data set, almost all SSL runs outperformed their corresponding baseline SL runs and approached full SL runs; for the news article data set, SSL performance followed a similar trend but with only a small rate of increase; for the blog post data set, SSL runs using only blog data showed no benefits over the SL baseline, but with labeled movie review data, SSL runs produced results comparable with full SL result.", "labels": [], "entities": [{"text": "movie review data set", "start_pos": 8, "end_pos": 29, "type": "DATASET", "confidence": 0.6928557232022285}, {"text": "news article data set", "start_pos": 138, "end_pos": 159, "type": "DATASET", "confidence": 0.7797152400016785}]}, {"text": "reports the performance of SSL and SL runs on movie review data based on different numbers of initial labeled sentences.", "labels": [], "entities": []}, {"text": "Both the self-and cotraining runs reported here used the same parameter settings: k=0, u=20, p=2, n=2, \u03bb =0, with no feature selection.", "labels": [], "entities": []}, {"text": "The co-training results in used a CLM and a BOW model (see section 5.2).", "labels": [], "entities": [{"text": "BOW", "start_pos": 44, "end_pos": 47, "type": "METRIC", "confidence": 0.9812915325164795}]}, {"text": "SL runs for co-training classified sentences based on the highest score generated by two classifiers; SL runs for S 3 VM applied the default SVM setting in SVM light ; and SL runs for EM-NB used the Na\u00a8\u0131veNa\u00a8\u0131ve Bayes classifier in the EM-NB implementation in LingPipe.", "labels": [], "entities": [{"text": "LingPipe", "start_pos": 260, "end_pos": 268, "type": "DATASET", "confidence": 0.88837069272995}]}, {"text": "shows that, except for S 3 VM, SSL always outperforms the corresponding SL baseline on movie reviews: When SSL converges, it achieves improvement in the range of 8% to 34% over the SL baseline.", "labels": [], "entities": [{"text": "SSL", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9329822063446045}]}, {"text": "The fewer initial labeled data, the more benefits an SSL run gained from using unlabeled data.", "labels": [], "entities": []}, {"text": "For example, using 100 labeled sentences, selftraining achieved a classification accuracy of 85.2% and outperformed the baseline SL by 33.5%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.8762199282646179}, {"text": "SL", "start_pos": 129, "end_pos": 131, "type": "METRIC", "confidence": 0.7373647689819336}]}, {"text": "Although this SSL run was surpassed by 4.9% by the full SL run using all labeled data, a great amount of effort was saved by labeling only 100 sentences rather than 9,500.", "labels": [], "entities": []}, {"text": "Co-training produced the best SSL results.", "labels": [], "entities": [{"text": "SSL", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.975324809551239}]}, {"text": "For example, with only 200 labeled sentences, co-training yielded accuracy as high as 93.8%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9993108510971069}]}, {"text": "Overall, SSL for opinion detection on movie reviews shows similar trends to SSL for traditional topical classification).", "labels": [], "entities": [{"text": "SSL", "start_pos": 9, "end_pos": 12, "type": "METRIC", "confidence": 0.5977612137794495}, {"text": "opinion detection on movie reviews", "start_pos": 17, "end_pos": 51, "type": "TASK", "confidence": 0.842973268032074}]}], "tableCaptions": [{"text": " Table 1: Classification accuracy(%) of SSL and SL on  movie reviews", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.8628727197647095}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.8528176546096802}, {"text": "SL", "start_pos": 48, "end_pos": 50, "type": "METRIC", "confidence": 0.9928334951400757}]}]}