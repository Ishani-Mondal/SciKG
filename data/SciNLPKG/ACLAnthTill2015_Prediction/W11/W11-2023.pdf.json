{"title": [], "abstractContent": [{"text": "We propose a method for modelling how dialogue moves influence and are influenced by the agents' preferences.", "labels": [], "entities": []}, {"text": "We extract constraints on preferences and dependencies among them, even when they are expressed indirectly, by exploiting discourse structure.", "labels": [], "entities": []}, {"text": "Our method relies on a study of 20 dialogues chosen at random from the Verbmobil corpus.", "labels": [], "entities": [{"text": "Verbmobil corpus", "start_pos": 71, "end_pos": 87, "type": "DATASET", "confidence": 0.980125904083252}]}, {"text": "We then test the algorithms predictions against the judgements of naive annotators on 3 random unseen dialogues.", "labels": [], "entities": []}, {"text": "The average annotator-algorithm agreement and the average inter-annotator agreement show that our method is reliable.", "labels": [], "entities": []}], "introductionContent": [{"text": "Dialogues are structured by various moves that the participants make-e.g., answering questions, asking follow-up questions, elaborating prior claims, and soon.", "labels": [], "entities": []}, {"text": "Such moves come with commitments to certain attitudes such as intentions and preferences.", "labels": [], "entities": []}, {"text": "While mapping utterances to their underlying intentions is well studied through the application of plan recognition techniques (e.g.,,), game-theoretic models of rationality generally suggest that intentions result from a deliberation to find the optimal tradeoff between one's preferences and one's beliefs about possible outcomes.", "labels": [], "entities": []}, {"text": "So mapping dialogue moves to preferences is an important task: for instance, they are vital in decisions on how to re-plan and repair should the agents' current plan fail, for they inform the agents about the relative importance of their various goals.", "labels": [], "entities": []}, {"text": "Classical game theory, however, demands a complete and cardinal representation of preferences for the optimal intention to be defined.", "labels": [], "entities": []}, {"text": "This is not realistic for modelling dialogue because agents often lack complete information about preferences prior to talking: they learn about the domain, each other's preferences and even their own preferences through dialogue exchange.", "labels": [], "entities": []}, {"text": "For instance, utterance (1) implies that the speaker wants to go to the mall given that he wants to eat, but we do not know his preferences over \"go to the mall\" if he does not want to eat.", "labels": [], "entities": []}, {"text": "(1) I want to go to the mall to eat something.", "labels": [], "entities": []}, {"text": "Existing formal models of dialogue content either do not formalise a link between utterances and preferences (e.g., Ginzburg (to appear)), or they encode such links in a typed feature structure, where desire is represented as a feature that takes conjunctions of values as arguments (e.g.,), making the language too restricted to express dependencies among preferences of the kind we just described.", "labels": [], "entities": []}, {"text": "Existing implemented dialogue systems likewise typically represent goals as simple combinations of values on certain information 'slots' (e.g.,,); thus (1) yields a conjunction of preferences, to go to the mall and to eat something.", "labels": [], "entities": []}, {"text": "But such a system could lead to suboptimal dialogue moves-e.g., to help the speaker go to the mall even if he has already received food.", "labels": [], "entities": []}, {"text": "What's required, then, is a method for extracting partial information about preferences and the dependencies among them that are expressed in dialogue, perhaps indirectly, and a method for exploiting that partial information to identify the next optimal action.", "labels": [], "entities": []}, {"text": "This paper proposes a method for achieving these tasks by exploiting discourse structure.", "labels": [], "entities": []}, {"text": "We exploited the corpus of, who annotated 100 randomly chosen spontaneous face-to-face dialogues from the Verbmobil corpus () with their discourse structure according to Segmented Discourse Representation Theory (SDRT,)-these structures represent the types of (relational) speech acts that the agents perform.", "labels": [], "entities": [{"text": "Verbmobil corpus", "start_pos": 106, "end_pos": 122, "type": "DATASET", "confidence": 0.8705034554004669}, {"text": "Segmented Discourse Representation Theory (SDRT", "start_pos": 170, "end_pos": 217, "type": "TASK", "confidence": 0.7855527798334757}]}, {"text": "Here's atypical fragment: Across the corpus, more than 30% of the discourse units are either questions or assertions that help to elaborate a plan to achieve the preferences revealed by a prior part of the dialogue-these are marked respectively with the discourse relations Q-Elab and Plan-Elab in SDRT, and utterances (2b) and (2e) and the segments (2c) and (2d) invoke these relations (see Section 2).", "labels": [], "entities": []}, {"text": "Moreover, 10% of the moves revise or correct prior preferences (like (2d)).", "labels": [], "entities": []}, {"text": "We will model the interaction between dialogue content and preferences in two steps.", "labels": [], "entities": []}, {"text": "The first maps utterances and their rhetorical connections into a partial description of the agents' preferences.", "labels": [], "entities": []}, {"text": "The mapping is compositional and monotonic over the dialogue's logical form (i.e., the description of preferences for an extended segment is defined in terms of and always subsumes those for its subsegments): it exploits recursion over discourse structure.", "labels": [], "entities": []}, {"text": "The descriptions partially describe ceteris paribus preference nets or CP-nets with Boolean variables).", "labels": [], "entities": []}, {"text": "We chose CPnets over alternative logics of preferences, because they provide a compact, computationally efficient, qualitative and relational representation of preferences and their dependencies, making them compatible with the kind of partial information about preferences that utterances reveal.", "labels": [], "entities": []}, {"text": "Our mapping from the logical form of dialogue to partial descriptions of Boolean CP-nets proceeds in a purely linguistic or domain independent way (e.g., it ignores information such as Monday and Tuesday cannot co-refer) and will therefore apply to dialogue generally and not just Verbmobil.", "labels": [], "entities": [{"text": "Verbmobil", "start_pos": 281, "end_pos": 290, "type": "DATASET", "confidence": 0.9186827540397644}]}, {"text": "Ina second stage, we \"compress\" and refine our description making use of constraints proper to CP-nets (e.g., that preference is transitive) and constraints provided by the domain-in this case constraints about times and places, as well as constraints from deep semantics.", "labels": [], "entities": []}, {"text": "This second step reduces the complexity of inferring which CP-net(s) satisfy the partial description and allows us to identify the minimal CP-net that satisfies the domaindependent description of preferences.", "labels": [], "entities": []}, {"text": "We can thus exploit dependencies between dialogue moves and mental states in a compact, efficient and intuitive way.", "labels": [], "entities": []}, {"text": "We start by motivating and describing the semantic representation of dialogue from which our CP-net descriptions and then our CP-nets will be constructed.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our method by testing it against the judgments of three annotators on three randomly chosen unseen test dialogues from the Verbmobil corpus.", "labels": [], "entities": [{"text": "Verbmobil corpus", "start_pos": 135, "end_pos": 151, "type": "DATASET", "confidence": 0.9746466279029846}]}, {"text": "The test corpus contains 75 EDUs and the proportion of discourse relations is the same as in the corpus overall.", "labels": [], "entities": []}, {"text": "The three annotators were naive in the sense that they were not familiar with preference representations and preference reasoning strategies.", "labels": [], "entities": []}, {"text": "For each dialogue segment, we checked if the judges had the same intuitions that we did on: (i) how commitments to preferences are extracted from EDUs, and (ii) how preferences evolve through dialogue exchange.", "labels": [], "entities": []}, {"text": "The judges were given a manual with all the instructions and definitions needed to make the annotations.", "labels": [], "entities": []}, {"text": "For example, the manual defined preference to be \"a notion of comparison between one thing at least one other\".", "labels": [], "entities": []}, {"text": "The manual also instructs annotators to label each EDU with the following four bits of information: (1) preferences (if any) expressed in the EDU; (2) dependencies between preferences expressed in the EDU; (3) dependencies between preferences in the current EDU and previous ones; and (4) preference evolution (namely, the appearance of anew factor that affects preferred outcomes, update to preferences over values for an existing factor, and so on).", "labels": [], "entities": []}, {"text": "For each of these four components, example dialogues were given for each type of decision they would need to make, and instructions were given on the format in which to code their judgements.", "labels": [], "entities": []}, {"text": "Appendix A shows an example of an annotated dialogue.", "labels": [], "entities": []}, {"text": "presents results of the evaluation of (i).", "labels": [], "entities": []}, {"text": "For each EDU, we asked the annotator to list the preferences expressed in the EDU and we compared the preferences extracted by each judge with those extracted by our algorithm.", "labels": [], "entities": []}, {"text": "presents the preliminary results where the couple (a,b) indicates respectively the proportion of common elaborations (preference updates or new preferences) and the proportion of common corrections.", "labels": [], "entities": []}, {"text": "Since elaboration is also applied in case of other discourse relations (e.g., Q-Elab), the measure a evaluates the rules 8, 9, 10 (yes) and 11.", "labels": [], "entities": []}, {"text": "Similarly, the measure b evaluates the rules 10 (no), 13 and 14.", "labels": [], "entities": []}, {"text": "We obtain AAA=91% IAA=92.7% for elaboration and AAA=85.7% IAA=81% for correction.", "labels": [], "entities": [{"text": "AAA", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9995878338813782}, {"text": "IAA", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.9980677962303162}, {"text": "AAA", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9993817806243896}, {"text": "IAA", "start_pos": 58, "end_pos": 61, "type": "METRIC", "confidence": 0.9911826848983765}]}], "tableCaptions": [{"text": " Table 4: The DSDRS for Dialogue (6).", "labels": [], "entities": []}]}