{"title": [{"text": "Bilingual Lexicon Extraction from Comparable Corpora Enhanced with Parallel Corpora", "labels": [], "entities": [{"text": "Bilingual Lexicon Extraction", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7005194822947184}]}], "abstractContent": [{"text": "In this article, we present a simple and effective approach for extracting bilingual lexicon from comparable corpora enhanced with parallel corpora.", "labels": [], "entities": []}, {"text": "We make use of structural characteristics of the documents comprising the comparable corpus to extract parallel sentences with a high degree of quality.", "labels": [], "entities": []}, {"text": "We then use state-of-the-art techniques to build a specialized bilingual lexicon from these sentences and evaluate the contribution of this lexicon when added to the comparable corpus-based alignment technique.", "labels": [], "entities": []}, {"text": "Finally, the value of this approach is demonstrated by the improvement of translation accuracy for medical words.", "labels": [], "entities": [{"text": "translation", "start_pos": 74, "end_pos": 85, "type": "TASK", "confidence": 0.9354140758514404}, {"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.8849971890449524}]}], "introductionContent": [{"text": "Bilingual lexicons are important resources of many applications of natural language processing such as cross-language information retrieval or machine translation.", "labels": [], "entities": [{"text": "cross-language information retrieval", "start_pos": 103, "end_pos": 139, "type": "TASK", "confidence": 0.6967237591743469}, {"text": "machine translation", "start_pos": 143, "end_pos": 162, "type": "TASK", "confidence": 0.7867579162120819}]}, {"text": "These lexicons are traditionally extracted from bilingual corpora.", "labels": [], "entities": []}, {"text": "In this area, the main work involves parallel corpora, i.e. a corpus that contains source texts and their translations.", "labels": [], "entities": []}, {"text": "From sentence-to-sentence aligned corpora, symbolic), statistical, or hybrid techniques ( are used for word and expression alignments.", "labels": [], "entities": [{"text": "word and expression alignments", "start_pos": 103, "end_pos": 133, "type": "TASK", "confidence": 0.609989270567894}]}, {"text": "However, despite good results in the compilation of bilingual lexicons, parallel corpora are rather scarce resources, especially for technical domains and for language pairs not involving English.", "labels": [], "entities": []}, {"text": "For instance, current resources of parallel corpora are built from the proceedings of international institutions such as the European Union (11 languages) or the United Nations (6 languages), bilingual countries such as Canada (English and French languages), or bilingual regions such as Hong Kong (Chinese and English languages).", "labels": [], "entities": []}, {"text": "For these reasons, research in bilingual lexicon extraction is focused on another kind of bilingual corpora.", "labels": [], "entities": [{"text": "bilingual lexicon extraction", "start_pos": 31, "end_pos": 59, "type": "TASK", "confidence": 0.660621335109075}]}, {"text": "These corpora, known as comparable corpora, are comprised of texts sharing common features such as domain, genre, register, sampling period, etc.", "labels": [], "entities": []}, {"text": "without having a source text-target text relationship.", "labels": [], "entities": []}, {"text": "Although the building of comparable corpora is easier than the building of parallel corpora, the results obtained thus far on comparable corpora are contrasted.", "labels": [], "entities": []}, {"text": "For instance, good results are obtained from large corpora -several million words -for which the accuracy of the proposed translation is between 76% (Fung, 1998) and 89%) for the first 20 candidates.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9994811415672302}]}, {"text": "() have achieved 91% accuracy for the top three candidates using the Web as a comparable corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9759096503257751}]}, {"text": "But for technical domains, for which large corpora are not available, the results obtained, even though encouraging, are not completely satisfactory yet.", "labels": [], "entities": []}, {"text": "For instance,) obtained a precision of 44% and 57% for the first 10 and 20 candidates in a 100,000-word medical corpus, and 35% and 42% in a multi-domain 8 million-word corpus.", "labels": [], "entities": [{"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9992407560348511}]}, {"text": "For French/English single words, () using a medical corpus of 1.2 million words, obtained a precision of about 50% and 60% for the top 10 and top 20 candidates.", "labels": [], "entities": [{"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9991909861564636}]}, {"text": "() obtained a precision of 51% and 60% for the top 10 and 20 candidates in a 1.5 million-word French-Japanese diabetes corpus.", "labels": [], "entities": [{"text": "precision", "start_pos": 14, "end_pos": 23, "type": "METRIC", "confidence": 0.9993878602981567}, {"text": "French-Japanese diabetes corpus", "start_pos": 94, "end_pos": 125, "type": "DATASET", "confidence": 0.6644915640354156}]}, {"text": "The above work in bilingual lexicon extraction from comparable corpora relies on the assumption that words which have the same meaning in different languages tend to appear in the same lexical contexts).", "labels": [], "entities": [{"text": "bilingual lexicon extraction from comparable corpora", "start_pos": 18, "end_pos": 70, "type": "TASK", "confidence": 0.7912982404232025}]}, {"text": "Based on this assumption, a standard approach consists of building context vectors for each word of the source and target languages.", "labels": [], "entities": []}, {"text": "The candidate translations fora particular word are obtained by comparing the translated source context vector with all target context vectors.", "labels": [], "entities": []}, {"text": "In this approach, the translation of the words of the source context vectors depends on the coverage of the bilingual dictionary vis-` a-vis the corpus.", "labels": [], "entities": []}, {"text": "This aspect can be a potential problem if too few corpus words are found in the bilingual dictionary.", "labels": [], "entities": []}, {"text": "In this article, we want to show how this problem can be partially circumvented by combining a general bilingual dictionary with a specialized bilingual dictionary based on a parallel corpus extracted through mining of the comparable corpus.", "labels": [], "entities": []}, {"text": "In the same way that recent works in Statistical Machine Translation (SMT) mines comparable corpora to discover parallel sentences, among others), this work contributes to the bridging of the gap between comparable and parallel corpora by offering a framework for bilingual lexicon extraction from comparable corpus with the help of parallel corpusbased pairs of terms.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 37, "end_pos": 74, "type": "TASK", "confidence": 0.8376599649588267}, {"text": "bilingual lexicon extraction", "start_pos": 264, "end_pos": 292, "type": "TASK", "confidence": 0.6798867583274841}]}, {"text": "The remainder of this article is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we first present the method for bilingual lexicon extraction from comparable corpora enhanced with parallel corpora and the associated system architecture.", "labels": [], "entities": [{"text": "bilingual lexicon extraction", "start_pos": 46, "end_pos": 74, "type": "TASK", "confidence": 0.6372460623582205}]}, {"text": "We then quantify and analyse in Section 3 the performance improvement of our method on a medical comparable corpora when used to extract specialized bilingual lexicon.", "labels": [], "entities": []}, {"text": "Finally, in Section 4, we discuss the present study and present our conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the previous section, we have introduced our comparable corpus and described the method dedicated to bilingual lexicon extraction from comparable corpora enhanced with parallel corpora.", "labels": [], "entities": [{"text": "bilingual lexicon extraction from comparable corpora", "start_pos": 104, "end_pos": 156, "type": "TASK", "confidence": 0.7543849448362986}]}, {"text": "In this section, we then quantify and analyse the performance improvement of our method on a medical comparable corpus when used to extract specialized bilingual lexicon.", "labels": [], "entities": []}, {"text": "The documents comprising the French/English specialized comparable corpus have been normalised through the following linguistic pre-processing steps: tokenisation, part-of-speech tagging, and lemmatisation.", "labels": [], "entities": [{"text": "French/English specialized comparable corpus", "start_pos": 29, "end_pos": 73, "type": "DATASET", "confidence": 0.6969147324562073}, {"text": "tokenisation", "start_pos": 150, "end_pos": 162, "type": "TASK", "confidence": 0.9596561789512634}, {"text": "part-of-speech tagging", "start_pos": 164, "end_pos": 186, "type": "TASK", "confidence": 0.6644717752933502}]}, {"text": "Next, the function words were removed and the words occurring less than twice in the French and the English parts were discarded.", "labels": [], "entities": []}, {"text": "Finally, the comparable corpus comprised about 7,400 distinct words in In this study, we used four types of bilingual dictionary: i) the Wiktionary 6 free-content multilingual dictionary, ii) the ELRA-M0033 7 professional French/English bilingual dictionary, iii) the MeSH 8 metha-thesaurus, and iv) the BC dictionary (see Section 2.2).", "labels": [], "entities": [{"text": "Wiktionary 6 free-content multilingual dictionary", "start_pos": 137, "end_pos": 186, "type": "DATASET", "confidence": 0.7439311504364013}, {"text": "ELRA-M0033 7 professional French/English bilingual dictionary", "start_pos": 196, "end_pos": 257, "type": "DATASET", "confidence": 0.7808468714356422}, {"text": "MeSH 8 metha-thesaurus", "start_pos": 268, "end_pos": 290, "type": "DATASET", "confidence": 0.8588141997655233}, {"text": "BC dictionary", "start_pos": 304, "end_pos": 317, "type": "DATASET", "confidence": 0.8857737481594086}]}, {"text": "shows the main features of the dictionaries, namely: the number of distinct French single words in the dictionary (# SWs dico.), the number of distinct French single words in the dictionary after projection on the French part of the comparable corpus (# SWs corpus), and the number of translations per entry in the dictionary (# TPE).", "labels": [], "entities": []}, {"text": "For instance, 42% of the French context vectors could be translated with the Wiktionary (3,099/7,400).", "labels": [], "entities": [{"text": "Wiktionary", "start_pos": 77, "end_pos": 87, "type": "DATASET", "confidence": 0.8737867474555969}]}, {"text": "In bilingual terminology extraction from specialized comparable corpora, the terminology reference list required to evaluate the performance of the alignment programs are often composed of 100 single-word terms (SWTs)), 95 SWTs in (, and 100 SWTs in).", "labels": [], "entities": [{"text": "bilingual terminology extraction", "start_pos": 3, "end_pos": 35, "type": "TASK", "confidence": 0.6067843635876974}]}, {"text": "To build our reference list, we selected 400 French/English SWTs from the UMLS 9 meta-thesaurus and the Grand dictionnaire terminologique . We kept only the French/English pair of SWTs which occur more than five times in each part of the comparable corpus.", "labels": [], "entities": [{"text": "UMLS 9 meta-thesaurus", "start_pos": 74, "end_pos": 95, "type": "DATASET", "confidence": 0.9369942545890808}]}, {"text": "As a result of filtering, 122 French/English SWTs were extracted.", "labels": [], "entities": [{"text": "French/English SWTs", "start_pos": 30, "end_pos": 49, "type": "DATASET", "confidence": 0.7953264862298965}]}, {"text": "In order to evaluate the influence of the parallel corpus-based bilingual lexicon induced from the comparable corpus on the quality of comparable corpus based-bilingual terminology extraction, four experiments were carried out.", "labels": [], "entities": [{"text": "terminology extraction", "start_pos": 169, "end_pos": 191, "type": "TASK", "confidence": 0.7276826798915863}]}, {"text": "For each experiment, we change the bilingual dictionary required for the translation phase of the standard approach (see Section 2.3): 1.", "labels": [], "entities": [{"text": "translation", "start_pos": 73, "end_pos": 84, "type": "TASK", "confidence": 0.9678329825401306}]}, {"text": "The first experiment uses only the Wiktionary.", "labels": [], "entities": []}, {"text": "Since the coverage of the Wiktionary from the comparable corpus is small (see), the results obtained with this dictionary yield a lower boundary.", "labels": [], "entities": []}, {"text": "2. The second experiment uses the Wiktionary added to the BC dictionary.", "labels": [], "entities": [{"text": "BC dictionary", "start_pos": 58, "end_pos": 71, "type": "DATASET", "confidence": 0.9407411217689514}]}, {"text": "This experiment attempts to verify the hypothesis of this study.", "labels": [], "entities": []}, {"text": "3. The third experiment uses the Wiktionary added to the MeSH thesaurus.", "labels": [], "entities": [{"text": "MeSH thesaurus", "start_pos": 57, "end_pos": 71, "type": "DATASET", "confidence": 0.976094663143158}]}, {"text": "This experiment attempts to determine whether a specialised dictionary (in this case the MeSH) would be more suitable than a specialized bilingual dictionary (in this case the BC dictionary) directly extracted from the corpus.", "labels": [], "entities": [{"text": "MeSH", "start_pos": 89, "end_pos": 93, "type": "DATASET", "confidence": 0.9353892207145691}]}, {"text": "4. The last experiment uses only the ELRA dictionary.", "labels": [], "entities": [{"text": "ELRA dictionary", "start_pos": 37, "end_pos": 52, "type": "DATASET", "confidence": 0.8827029466629028}]}, {"text": "Since the coverage of the ELRA dictionary from the comparable corpus is the best (see), the results obtained with this one yield a higher boundary.", "labels": [], "entities": [{"text": "ELRA dictionary", "start_pos": 26, "end_pos": 41, "type": "DATASET", "confidence": 0.8797250092029572}]}, {"text": "shows the coverage of the four bilingual lexical resources involved in the previous experiments in the comparable corpus.", "labels": [], "entities": []}, {"text": "The first column indicates the number of single words belonging to a dictionary found in the comparable corpus (# SWs corpus).", "labels": [], "entities": []}, {"text": "The other column indicates the coverage of each dictionary in the ELRA dictionary (Coverage ELRA).", "labels": [], "entities": [{"text": "ELRA dictionary (Coverage ELRA)", "start_pos": 66, "end_pos": 97, "type": "DATASET", "confidence": 0.7818418145179749}]}, {"text": "Here, 98.9% of the single words belonging to the Wiktionary are included http://www.granddictionnaire.com/ in the ELRA dictionary whereas less than 95% of the single words belonging to the Wiktionary+BC and Wiktionary+MeSH dictionaries are included in the ELRA dictionary.", "labels": [], "entities": [{"text": "ELRA dictionary", "start_pos": 114, "end_pos": 129, "type": "DATASET", "confidence": 0.9412921667098999}, {"text": "Wiktionary+BC and Wiktionary+MeSH dictionaries", "start_pos": 189, "end_pos": 235, "type": "DATASET", "confidence": 0.5929695814847946}, {"text": "ELRA dictionary", "start_pos": 256, "end_pos": 271, "type": "DATASET", "confidence": 0.980402946472168}]}, {"text": "Moreover, the MeSH and BC dictionaries are two rather distinct specialized resources since they have only 117 single words in common.", "labels": [], "entities": [{"text": "MeSH and BC dictionaries", "start_pos": 14, "end_pos": 38, "type": "DATASET", "confidence": 0.7185971587896347}]}, {"text": "In the experiments reported here, the size of the context window n was set to 3 (i.e. a seven-word window), the association measure was the Mutual Information and the distance measure the Cosine (see Section 2.3).", "labels": [], "entities": [{"text": "Cosine", "start_pos": 188, "end_pos": 194, "type": "METRIC", "confidence": 0.9427900314331055}]}, {"text": "Other combinations of parameters were assessed but the previous parameters turned out to give the best performance.", "labels": [], "entities": []}, {"text": "summarises the results obtained for the four experiments for the terms belonging to the reference list according to the French to English direction.", "labels": [], "entities": []}, {"text": "As one could expect, the precision of the result obtained with the ELRA dictionary is the best and the precision obtained with the Wiktionary is the lowest.", "labels": [], "entities": [{"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9993016719818115}, {"text": "ELRA dictionary", "start_pos": 67, "end_pos": 82, "type": "DATASET", "confidence": 0.915541261434555}, {"text": "precision", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.9975741505622864}]}, {"text": "For instance, the ELRA dictionary improves the precision of the Wiktionary by about 14 points for the Top 10 and 9 points for the top 20.", "labels": [], "entities": [{"text": "ELRA dictionary", "start_pos": 18, "end_pos": 33, "type": "DATASET", "confidence": 0.7755573987960815}, {"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9995131492614746}]}, {"text": "These results confirm that the coverage of the dictionary is an important factor in the quality of the results obtained.", "labels": [], "entities": []}, {"text": "Now, when you add the BC dictionary to the Wiktionary, the results obtained are also much better than those obtained with the Wiktionary alone and very similar to those obtained with the ELRA dictionary alone (without taking into account the top 5).", "labels": [], "entities": [{"text": "BC dictionary", "start_pos": 22, "end_pos": 35, "type": "DATASET", "confidence": 0.7127180099487305}, {"text": "ELRA dictionary", "start_pos": 187, "end_pos": 202, "type": "DATASET", "confidence": 0.9353494942188263}]}, {"text": "This result suggests that a standard general language dictionary enriched with a small specialized dictionary can replace a large general language dictionary.", "labels": [], "entities": []}, {"text": "Furthermore, this combination is more interesting than the combination of the MeSH dictionary with the Wiktionary.", "labels": [], "entities": [{"text": "MeSH dictionary", "start_pos": 78, "end_pos": 93, "type": "DATASET", "confidence": 0.9503684043884277}]}, {"text": "Since the BC dictionary is induced from the corpus, this dictionary is directly correlated to the theme of breast cancer involved in the corpus.", "labels": [], "entities": [{"text": "BC dictionary", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.6999087333679199}]}, {"text": "Consequently the BC dictionary is more suitable than the MeSH dictionary i) even if the MeSH dictionary specializes in the medical domain and ii) even if more words in the comparable corpus are found in the MeSH dictionary than in the BC dictionary.", "labels": [], "entities": [{"text": "BC dictionary", "start_pos": 17, "end_pos": 30, "type": "DATASET", "confidence": 0.8388105034828186}, {"text": "MeSH dictionary", "start_pos": 57, "end_pos": 72, "type": "DATASET", "confidence": 0.9481538832187653}, {"text": "MeSH dictionary", "start_pos": 88, "end_pos": 103, "type": "DATASET", "confidence": 0.9521969854831696}, {"text": "MeSH dictionary", "start_pos": 207, "end_pos": 222, "type": "DATASET", "confidence": 0.9598683714866638}, {"text": "BC dictionary", "start_pos": 235, "end_pos": 248, "type": "DATASET", "confidence": 0.9039678275585175}]}, {"text": "This last observation should make us relativize the claim: the greater the number of context vector elements that are translated, the more discriminating the context vector will be for selecting translations in the target language.", "labels": [], "entities": []}, {"text": "We must also take into account the specificity of the context vector elements in accordance with the thematic of the documents making up the corpus studied in order to improve bilingual lexicon extraction from specialized comparable corpora.", "labels": [], "entities": [{"text": "bilingual lexicon extraction", "start_pos": 176, "end_pos": 204, "type": "TASK", "confidence": 0.6620001991589864}]}], "tableCaptions": [{"text": " Table 2: Main features of the French/English dictionaries", "labels": [], "entities": []}, {"text": " Table 3: Coverage of the bilingual lexical resources in the  comparable corpus", "labels": [], "entities": []}]}