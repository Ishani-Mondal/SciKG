{"title": [{"text": "A scaleable automated quality assurance technique for semantic representations and proposition banks", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper presents an evaluation of an automated quality assurance technique fora type of semantic representation known as a predicate argument structure.", "labels": [], "entities": []}, {"text": "These representations are crucial to the development of an important class of corpus known as a proposition bank.", "labels": [], "entities": []}, {"text": "Previous work (Cohen and Hunter, 2006) proposed and tested an analytical technique based on a simple discovery procedure inspired by classic structural linguistic methodology.", "labels": [], "entities": []}, {"text": "Cohen and Hunter applied the technique manually to a small set of representations.", "labels": [], "entities": []}, {"text": "Here we test the feasibility of automating the technique, as well as the ability of the technique to scale to a set of semantic representations and to a corpus many times larger than that used by Cohen and Hunter.", "labels": [], "entities": []}, {"text": "We conclude that the technique is completely automatable, uncovers missing sense distinctions and other bad semantic representations, and does scale well, performing at an accuracy of 69% for identifying bad representations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 172, "end_pos": 180, "type": "METRIC", "confidence": 0.9984394907951355}]}, {"text": "We also report on the implications of our findings for the correctness of the semantic representations in PropBank.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 106, "end_pos": 114, "type": "DATASET", "confidence": 0.9350042939186096}]}], "introductionContent": [{"text": "It has recently been suggested that in addition to more, bigger, and better resources, we need a science of creating them (Palmer et al., Download date December 17 2010).", "labels": [], "entities": []}, {"text": "The corpus linguistics community has arguably been developing at least a nascent science of annotation for years, represented by publications such as) that address architectural, sampling, and procedural issues, as well as publications such as) that address issues in inter-annotator agreement.", "labels": [], "entities": []}, {"text": "However, there is not yet a significant body of work on the subject of quality assurance for corpora, or for that matter, for many other types of linguistic resources.) describe three error-checking measures used in the construction of NomBank, and the use of inter-annotator agreement as a quality control measure for corpus construction is discussed at some length in).", "labels": [], "entities": []}, {"text": "However, discussion of quality control for corpora is otherwise limited or nonexistent.", "labels": [], "entities": []}, {"text": "With the exception of the inter-annotatoragreement-oriented work mentioned above, none of this work is quantitative.", "labels": [], "entities": []}, {"text": "This is a problem if our goal is the development of a true science of annotation.", "labels": [], "entities": []}, {"text": "Work on quality assurance for computational lexical resources other than ontologies is especially lacking.", "labels": [], "entities": []}, {"text": "However, the body of work on quality assurance for ontologies () is worth considering in the context of this paper.", "labels": [], "entities": []}, {"text": "One common theme in that work is that even manually curated lexical resources contain some percentage of errors.", "labels": [], "entities": []}, {"text": "The small size of the numbers of errors uncovered in some of these studies should not betaken as a significance-reducing factor for the development of quality assurance measures for lexical resources-rather, the opposite: as lexical resources become larger, it becomes correspondingly more difficult to locate errors in them.", "labels": [], "entities": []}, {"text": "Finding problems in a very errorful resource is easy; finding them in a mostly correct resource is an entirely different challenge.", "labels": [], "entities": []}, {"text": "We present here an evaluation of a methodology for quality assurance fora particular type of lexical resource: the class of semantic representation known as a predicate argument structure (PAS).", "labels": [], "entities": []}, {"text": "Predicate argument structures are important in the context of resource development in part because they are the fundamental annotation target of the class of corpus known as a proposition bank.", "labels": [], "entities": []}, {"text": "Much of the significance claim for this work comes from the significance of proposition banks themselves in recent research on natural language processing and computational lexical semantics.", "labels": [], "entities": [{"text": "computational lexical semantics", "start_pos": 159, "end_pos": 190, "type": "TASK", "confidence": 0.629037618637085}]}, {"text": "The impact of proposition banks on work in these fields is suggested by the large number of citations of just the three publications)-at the time of writing, 290, 220, and 567, respectively.", "labels": [], "entities": []}, {"text": "Additional indications of the impact of PropBank on the field of natural language processing include its use as the data source for two shared tasks ().", "labels": [], "entities": []}, {"text": "The methodology consists of looking for arguments that never co\u00f6ccur with each other.", "labels": [], "entities": []}, {"text": "In structural linguistics, this property of non-co\u00f6ccurrence is known as complementary distribution.", "labels": [], "entities": []}, {"text": "Complementary distribution occurs when two linguistic elements never occur in the same environment.", "labels": [], "entities": []}, {"text": "In this case, the environment is defined as any sentence containing a given predicate.", "labels": [], "entities": []}, {"text": "Earlier work showed a proof-of-concept application to a small set of rolesets (defined below) representing the potential PAS of 34 biomedical predicates).", "labels": [], "entities": []}, {"text": "The only inputs to the method area set of rolesets and a corpus annotated with respect to those rolesets.", "labels": [], "entities": []}, {"text": "Here, we evaluate the ability of the technique to scale to a set of semantic representations 137 times larger (4,654 in PropBank versus 34 in Cohen and Hunter's pilot project) and to a corpus about 1500 times larger (1M words in PropBank versus about 680 in Cohen and Hunter's pilot project) than that considered in previous work.", "labels": [], "entities": []}, {"text": "We also use a set of independent judges to assess the technique, wherein the earlier work, the results were only assessed by one of the authors.", "labels": [], "entities": []}, {"text": "Novel aspects of the current study include: \u2022 Investigating the feasibility of automating the previously manual process \u2022 Scaling up the size of the set of semantic representations evaluated \u2022 Scaling up the size of the corpus against which the representations are evaluated \u2022 Using independent judges to assess the predictions of the method", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Ratios of BAD plus CONDITIONAL to GOOD  for the pooled judgements as broken down by arity", "labels": [], "entities": [{"text": "Ratios", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9938198924064636}, {"text": "BAD", "start_pos": 20, "end_pos": 23, "type": "METRIC", "confidence": 0.9948928356170654}, {"text": "CONDITIONAL", "start_pos": 29, "end_pos": 40, "type": "METRIC", "confidence": 0.9980828762054443}, {"text": "GOOD", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9945776462554932}]}, {"text": " Table 2: Ratios of BAD plus CONDITIONAL to GOOD  for the pooled judgements as broken down by minimum  number of observations", "labels": [], "entities": [{"text": "Ratios", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9848233461380005}, {"text": "BAD", "start_pos": 20, "end_pos": 23, "type": "METRIC", "confidence": 0.9974343180656433}, {"text": "CONDITIONAL", "start_pos": 29, "end_pos": 40, "type": "METRIC", "confidence": 0.9982258677482605}, {"text": "GOOD", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9962041974067688}]}, {"text": " Table 3: Distribution of arities by percentage and by  count in the 4,654 PropBank rolesets.", "labels": [], "entities": [{"text": "Distribution of arities", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.8340186278025309}, {"text": "PropBank rolesets", "start_pos": 75, "end_pos": 92, "type": "DATASET", "confidence": 0.979703962802887}]}, {"text": " Table 4: Summary statistics: counts of predicates with  at least one argument pair in complementary distribution  and of total argument pairs in complementary distribution  for four different minimum numbers of observations of  the predicates.", "labels": [], "entities": [{"text": "Summary", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.8508415222167969}]}]}