{"title": [{"text": "Combining Syntactic and Semantic Features by SVM for Unrestricted Coreference Resolution", "labels": [], "entities": []}], "abstractContent": [{"text": "The paper presents a system for the CoNLL-2011 share task of coreference resolution.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.9679732918739319}]}, {"text": "The system composes of two components: one for mentions detection and another one for their coreference resolution.", "labels": [], "entities": [{"text": "mentions detection", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.8248196840286255}, {"text": "coreference resolution", "start_pos": 92, "end_pos": 114, "type": "TASK", "confidence": 0.9331676363945007}]}, {"text": "For mentions detection , we adopted a number of heuristic rules from syntactic parse tree perspective.", "labels": [], "entities": [{"text": "mentions detection", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.9254403710365295}]}, {"text": "For coreference resolution, we apply SVM by exploiting multiple syntactic and semantic features.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.9777179062366486}]}, {"text": "The experiments on the CoNLL-2011 corpus show that our rule-based mention identification system obtains a recall of 87.69%, and the best result of the SVM-based corefer-ence resolution system is an average F-score 50.92% of the MUC, B-CUBED and CEAFE metrics.", "labels": [], "entities": [{"text": "CoNLL-2011 corpus", "start_pos": 23, "end_pos": 40, "type": "DATASET", "confidence": 0.9715571999549866}, {"text": "rule-based mention identification", "start_pos": 55, "end_pos": 88, "type": "TASK", "confidence": 0.5945021212100983}, {"text": "recall", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.9997021555900574}, {"text": "SVM-based corefer-ence resolution", "start_pos": 151, "end_pos": 184, "type": "TASK", "confidence": 0.5560466051101685}, {"text": "F-score", "start_pos": 206, "end_pos": 213, "type": "METRIC", "confidence": 0.9956701993942261}, {"text": "MUC", "start_pos": 228, "end_pos": 231, "type": "DATASET", "confidence": 0.5184468030929565}, {"text": "B-CUBED", "start_pos": 233, "end_pos": 240, "type": "METRIC", "confidence": 0.9458531737327576}, {"text": "CEAFE", "start_pos": 245, "end_pos": 250, "type": "DATASET", "confidence": 0.6530431509017944}]}], "introductionContent": [{"text": "Coreference resolution, defined as finding the different mentions in a document which refer to the same entity in reality, is an important subject in Natural Language Processing.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9119149148464203}, {"text": "Natural Language Processing", "start_pos": 150, "end_pos": 177, "type": "TASK", "confidence": 0.6234453121821085}]}, {"text": "In particular, coreference resolution is a critical component of information extraction systems and a series of coreference resolution tasks have been introduced and evaluated from MUC.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.9491855800151825}, {"text": "information extraction", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.8405050039291382}, {"text": "coreference resolution", "start_pos": 112, "end_pos": 134, "type": "TASK", "confidence": 0.85075244307518}, {"text": "MUC", "start_pos": 181, "end_pos": 184, "type": "DATASET", "confidence": 0.8188347220420837}]}, {"text": "Some machine learning approaches have been applied to coreference resolution ().", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.9769276678562164}]}, {"text": "use a decision tree classifier to decide whether two mentions in a document are coreferent.", "labels": [], "entities": []}, {"text": "exploit an effective feature of gender and number to a pronoun resolution system and improve the performance significantly, which is also appeared in our feature set.", "labels": [], "entities": [{"text": "pronoun resolution", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.7787719964981079}]}, {"text": "However, automatic coreference resolution is a hard task since it needs both syntactic and semantic knowledge and some intra-document knowledge.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.865812361240387}]}, {"text": "To improve the performance further, many deep knowledge resources like shallow syntactic and semantic knowledge are exploited for coreference resolution (.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 130, "end_pos": 152, "type": "TASK", "confidence": 0.9669683575630188}]}, {"text": "In order to make use of more syntactic information, employ a tree kernel to anaphoricity determination for coreference resolution and show that applying proper tree structure in corefernce resolution can achieve a good performance.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 107, "end_pos": 129, "type": "TASK", "confidence": 0.9439497590065002}, {"text": "corefernce resolution", "start_pos": 178, "end_pos": 199, "type": "TASK", "confidence": 0.8388819396495819}]}, {"text": "The) \"Modeling Unrestricted Coreference in OntoNotes\" proposes a task about unrestricted coreference resolution, which aims to recognize mentions and find coreference chains in one document.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 89, "end_pos": 111, "type": "TASK", "confidence": 0.846558690071106}]}, {"text": "We participate in the closed test.", "labels": [], "entities": []}, {"text": "In this paper, we exploit multi-features to a coreference resolution system for the CONLL-2011 Share Task, including flat features and a tree structure feature.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 46, "end_pos": 68, "type": "TASK", "confidence": 0.8538137972354889}, {"text": "CONLL-2011 Share Task", "start_pos": 84, "end_pos": 105, "type": "DATASET", "confidence": 0.8393655021985372}]}, {"text": "The task is divided into two steps in our system.", "labels": [], "entities": []}, {"text": "In the first step, we adopt some heuristic rules to recognize mentions which maybe in a coreference chain; in the second step, we exploit a number of features to a support vector machine (SVM) classifier to resolute unrestricted coreference.", "labels": [], "entities": []}, {"text": "The experiments show that our system gets a reasonable result.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In 66 Section 2, we describe in detail how our system does the work of coreference resolution, including how we recognize mentions and how we mark the coreference chains.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 71, "end_pos": 93, "type": "TASK", "confidence": 0.9576441049575806}]}, {"text": "The experimental results are discussed in Section 3.", "labels": [], "entities": []}, {"text": "Finally in Section 4, we give some conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments are all carried out on CONLL-2011 share task data set (.", "labels": [], "entities": [{"text": "CONLL-2011 share task data set", "start_pos": 39, "end_pos": 69, "type": "DATASET", "confidence": 0.9511292338371277}]}, {"text": "The result of mention identification in the first step is evaluated through mention recall.", "labels": [], "entities": [{"text": "mention identification", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.69781593978405}]}, {"text": "And the performance of coreference resolution in the second step is measured using the average F1-measures of MUC, B-CUBED and CEAFE metrics).", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.9605442881584167}, {"text": "F1-measures", "start_pos": 95, "end_pos": 106, "type": "METRIC", "confidence": 0.9969082474708557}, {"text": "MUC", "start_pos": 110, "end_pos": 113, "type": "DATASET", "confidence": 0.7295992970466614}, {"text": "B-CUBED", "start_pos": 115, "end_pos": 122, "type": "METRIC", "confidence": 0.9402983784675598}, {"text": "CEAFE", "start_pos": 127, "end_pos": 132, "type": "DATASET", "confidence": 0.7114494442939758}]}, {"text": "All the evaluations are implemented using the scorer downloaded from the CONLL-2011 share task website 1 . 1 http://conll.bbn.com/index.php/software.html", "labels": [], "entities": [{"text": "CONLL-2011 share task website 1 . 1", "start_pos": 73, "end_pos": 108, "type": "DATASET", "confidence": 0.9493442433221}]}], "tableCaptions": [{"text": " Table 2: parameter d in polynomial kernel in coreference  resolution using the baseline method with the GN fea- ture(%)", "labels": [], "entities": [{"text": "coreference  resolution", "start_pos": 46, "end_pos": 69, "type": "TASK", "confidence": 0.9535218775272369}]}, {"text": " Table 3: combining parameter r (K = tree \u2212 f orest \u2212  kernel  *  r + vector \u2212 kernel) in coreference resolution  using the baseline with the GN and MT features(%)", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 90, "end_pos": 112, "type": "TASK", "confidence": 0.9676486849784851}]}, {"text": " Table 4: effect of GN and SR features in coreference res- olution using no MT feature (%)", "labels": [], "entities": []}, {"text": " Table 6.  The average score achieves 50.92%.", "labels": [], "entities": [{"text": "average score", "start_pos": 15, "end_pos": 28, "type": "METRIC", "confidence": 0.9601609408855438}]}, {"text": " Table 6: official result in CoNLL-2011 Share Task using  baseline method with GN feature added (%)", "labels": [], "entities": [{"text": "CoNLL-2011 Share Task", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.5896153847376505}]}]}