{"title": [{"text": "Analysis of the Difficulties in Chinese Deep Parsing", "labels": [], "entities": [{"text": "Chinese Deep Parsing", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.6617625653743744}]}], "abstractContent": [{"text": "This paper discusses the difficulties in Chinese deep parsing, by comparing the accuracy of a Chinese HPSG parser to the accuracy of an English HPSG parser and the commonly used Chinese syntactic parsers.", "labels": [], "entities": [{"text": "Chinese deep parsing", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.6117154856522878}, {"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9992051720619202}, {"text": "accuracy", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9989708662033081}]}, {"text": "Analysis reveals that deep parsing for Chinese is more challenging than for English, due to the shortage of syntactic constraints of Chinese verbs, the widespread pro-drop, and the large distribution of ambiguous constructions.", "labels": [], "entities": [{"text": "deep parsing", "start_pos": 22, "end_pos": 34, "type": "TASK", "confidence": 0.482210710644722}]}, {"text": "Moreover, the inherent ambiguities caused by verbal coordination and relative clauses make semantic analysis of Chinese more difficult than the syntactic analysis of Chinese.", "labels": [], "entities": [{"text": "semantic analysis of Chinese", "start_pos": 91, "end_pos": 119, "type": "TASK", "confidence": 0.8237585574388504}]}], "introductionContent": [{"text": "Syntactic parsing provides only the syntactic structure of text, while deep parsing offers richer information, such as the semantic roles.", "labels": [], "entities": [{"text": "Syntactic parsing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8604412972927094}]}, {"text": "With the advancement of research in natural language processing, this rich information has become important for many applications, including statistical machine translation, information extraction, and question answering.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 36, "end_pos": 63, "type": "TASK", "confidence": 0.6732679406801859}, {"text": "statistical machine translation", "start_pos": 141, "end_pos": 172, "type": "TASK", "confidence": 0.7638749281565348}, {"text": "information extraction", "start_pos": 174, "end_pos": 196, "type": "TASK", "confidence": 0.8541004061698914}, {"text": "question answering", "start_pos": 202, "end_pos": 220, "type": "TASK", "confidence": 0.9306281805038452}]}, {"text": "Performing semantic role labeling ( ) with shallow parsing is one way to fulfill deep parsing.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.6649397810300192}]}, {"text": "Another alternative to semantic role labeling is to perform deep parsing based on lexicalized grammar theories, such as HeadDriven Phrase Structure Grammar (HPSG), Lexical Functional Grammar (LFG) (, Combinatory Categorial Grammar (CCG), and Lexicalized Tree Adjoining Grammar (LTAG)).", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.6458203792572021}]}, {"text": "Many research projects have been done successfully in this way, such as is the casein parsing English with HPSG (, CCG (, and LFG ().", "labels": [], "entities": [{"text": "casein parsing English", "start_pos": 79, "end_pos": 101, "type": "TASK", "confidence": 0.798788050810496}, {"text": "HPSG", "start_pos": 107, "end_pos": 111, "type": "DATASET", "confidence": 0.9185159802436829}]}, {"text": "However, obtaining the deep analysis of Chinese has proven to be more difficult.", "labels": [], "entities": []}, {"text": "We evaluated an existing HPSG parser, which has been used successfully for English deep parsing, on the Chinese HPSG Treebank constructed by.", "labels": [], "entities": [{"text": "English deep parsing", "start_pos": 75, "end_pos": 95, "type": "TASK", "confidence": 0.7291627128918966}, {"text": "Chinese HPSG Treebank", "start_pos": 104, "end_pos": 125, "type": "DATASET", "confidence": 0.7757413585980734}]}, {"text": "The results indicated that compared to English, this parser obtained a 12.97% decrease in semantic F1-score on Chinese deep parsing.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.6160765290260315}, {"text": "Chinese deep parsing", "start_pos": 111, "end_pos": 131, "type": "TASK", "confidence": 0.5441864331563314}]}, {"text": "Therefore, this paper focuses on investigating the difficulties in Chinese deep parsing, by comparing the parsing results of this HPSG parser on both Chinese and English, with the parsing results from commonly used Chinese syntactic parsers.", "labels": [], "entities": [{"text": "Chinese deep parsing", "start_pos": 67, "end_pos": 87, "type": "TASK", "confidence": 0.6209035019079844}]}, {"text": "This is the first time that the difficulties in Chinese deep parsing were analyzed; the resulting analysis provides insight into future research for Chinese deep parsing.", "labels": [], "entities": [{"text": "Chinese deep parsing", "start_pos": 48, "end_pos": 68, "type": "TASK", "confidence": 0.5840212106704712}, {"text": "Chinese deep parsing", "start_pos": 149, "end_pos": 169, "type": "TASK", "confidence": 0.6015976766745249}]}], "datasetContent": [{"text": "By using the Chinese HPSG Treebank described above, we re-trained the feature forest model and the supertagger, and built a Chinese HPSG parser.", "labels": [], "entities": [{"text": "Chinese HPSG Treebank", "start_pos": 13, "end_pos": 34, "type": "DATASET", "confidence": 0.856162965297699}]}, {"text": "The treebank was split into development, testing, and training data sets, following the recommendation from the authors of the Penn Chinese Treebank.", "labels": [], "entities": [{"text": "Penn Chinese Treebank", "start_pos": 127, "end_pos": 148, "type": "DATASET", "confidence": 0.9821671843528748}]}, {"text": "The training data was used to train the HPSG parser, and the testing data was used for parsing evaluation; the development data was used for parameter tuning.", "labels": [], "entities": [{"text": "HPSG parser", "start_pos": 40, "end_pos": 51, "type": "TASK", "confidence": 0.6304842382669449}, {"text": "parsing evaluation", "start_pos": 87, "end_pos": 105, "type": "TASK", "confidence": 0.9485702216625214}, {"text": "parameter tuning", "start_pos": 141, "end_pos": 157, "type": "TASK", "confidence": 0.7516821920871735}]}, {"text": "shows the statistics that resulted from the different data sets.", "labels": [], "entities": []}, {"text": "In the experiments performed with for the HPSG parser, the gold-standard word boundaries and POS tags were supplied.", "labels": [], "entities": [{"text": "HPSG", "start_pos": 42, "end_pos": 46, "type": "DATASET", "confidence": 0.8876134157180786}]}, {"text": "The Chinese HPSG parser offers predicateargument dependencies as the output of semantic parsing.", "labels": [], "entities": [{"text": "Chinese HPSG", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.7427368462085724}, {"text": "semantic parsing", "start_pos": 79, "end_pos": 95, "type": "TASK", "confidence": 0.7084804475307465}]}, {"text": "illustrates a parse tree with a predicate-argument dependency that has been built by the Chinese HPSG parser, in which the label of each dependency is the combination of rand l in a predicate-argument dependency <w p , w a , r, l>.", "labels": [], "entities": [{"text": "Chinese HPSG parser", "start_pos": 89, "end_pos": 108, "type": "DATASET", "confidence": 0.725201149781545}]}, {"text": "As an example, the predicate-argument dependencies of the verb '\ud97b\udf59(writes)' shown in indicates that the verb is a transitive verb (verb_arg12), and has a subject (ARG1) '\ud97b\udf59 (he)', and an object (ARG2) '\ud97b\udf59(book)'.", "labels": [], "entities": []}, {"text": "Therefore, we evaluated the performance of the Chinese HPSG parser on semantic parsing by analyzing the accuracy of the predicate-argument dependencies.", "labels": [], "entities": [{"text": "Chinese HPSG", "start_pos": 47, "end_pos": 59, "type": "DATASET", "confidence": 0.7874639928340912}, {"text": "semantic parsing", "start_pos": 70, "end_pos": 86, "type": "TASK", "confidence": 0.7218136787414551}, {"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9991247057914734}]}, {"text": "Six evaluation metrics used by were selected for the evaluation.", "labels": [], "entities": []}, {"text": "LP and LR refer to the labeled precision and recall of the predicate-argument dependencies, while UP and UR refer to the unlabeled precision and recall, respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9387853145599365}, {"text": "recall", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.9784501194953918}, {"text": "UP", "start_pos": 98, "end_pos": 100, "type": "METRIC", "confidence": 0.9835140705108643}, {"text": "UR", "start_pos": 105, "end_pos": 107, "type": "METRIC", "confidence": 0.8158085942268372}, {"text": "precision", "start_pos": 131, "end_pos": 140, "type": "METRIC", "confidence": 0.9706752896308899}, {"text": "recall", "start_pos": 145, "end_pos": 151, "type": "METRIC", "confidence": 0.9881568551063538}]}, {"text": "Sem.F1 is the semantic F1-score calculated based on LP and LR.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.8816477656364441}]}, {"text": "Sent.acc. is the accuracy of the sentences with the correct predicate-argument dependencies.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9989739656448364}]}, {"text": "(I read the book that he wrote.)", "labels": [], "entities": [{"text": "I read the book that he wrote", "start_pos": 1, "end_pos": 30, "type": "DATASET", "confidence": 0.8080132263047355}]}, {"text": "Besides of semantic analysis, the Chinese HPSG parser also provides the syntactic head for each branch in an HSPG parse tree and the schemas used to construct the branch, which can be used to extract the labeled syntactic dependency as the output of syntactic parsing.", "labels": [], "entities": [{"text": "Chinese HPSG parser", "start_pos": 34, "end_pos": 53, "type": "DATASET", "confidence": 0.7672186295191447}, {"text": "syntactic parsing", "start_pos": 250, "end_pos": 267, "type": "TASK", "confidence": 0.7306797802448273}]}, {"text": "In order to evaluate the syntactic analysis of the Chinese HPSG parser, we used the similar dependency labels as the CoNLL dependency labels ().", "labels": [], "entities": [{"text": "Chinese HPSG parser", "start_pos": 51, "end_pos": 70, "type": "DATASET", "confidence": 0.8808580040931702}]}, {"text": "shows the labeled syntactic dependency tree output by the parser, in which the label SUB and OBJ refer to the subject and object, respectively.", "labels": [], "entities": [{"text": "OBJ", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.9090911149978638}]}, {"text": "The common metrics used in CoNLL-2007 shared task () were applied in the evaluation of the syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 91, "end_pos": 108, "type": "TASK", "confidence": 0.7148043215274811}]}, {"text": "These metrics include the labeled attachment score (LAS), unlabeled attachment score (UAS), and the complete sentence accuracy (COMP) with labeled dependency.", "labels": [], "entities": [{"text": "labeled attachment score (LAS)", "start_pos": 26, "end_pos": 56, "type": "METRIC", "confidence": 0.8297236363093058}, {"text": "unlabeled attachment score (UAS)", "start_pos": 58, "end_pos": 90, "type": "METRIC", "confidence": 0.8475023905436198}, {"text": "complete sentence accuracy (COMP)", "start_pos": 100, "end_pos": 133, "type": "METRIC", "confidence": 0.7217565923929214}]}, {"text": "The accuracy of both syntactic parsing and semantic parsing of the Chinese HPSG parser was 83.75% LAS and 77.55% Sem.F1, and is listed in and.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997430443763733}, {"text": "syntactic parsing", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.6831628680229187}, {"text": "semantic parsing", "start_pos": 43, "end_pos": 59, "type": "TASK", "confidence": 0.7092730402946472}, {"text": "Chinese HPSG parser", "start_pos": 67, "end_pos": 86, "type": "DATASET", "confidence": 0.8466646869977316}, {"text": "LAS", "start_pos": 98, "end_pos": 101, "type": "METRIC", "confidence": 0.9919478297233582}]}, {"text": "To compare the performance of the Chinese HPSG parser on syntactic parsing with other related works, we evaluated two commonly used syntactic dependency parsers: MaltParser (Nivre et al., 2007 (a)) and MstParser (); the same syntactic dependency converted from the Chinese HPSG Treebank was used.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.7957383096218109}, {"text": "Chinese HPSG Treebank", "start_pos": 265, "end_pos": 286, "type": "DATASET", "confidence": 0.7918514013290405}]}, {"text": "In this experiment, the MaltParser and MstParser used both the gold-standard word boundaries and gold-standard POS tags, like the HPSG parser.", "labels": [], "entities": []}, {"text": "Since there has been no previous work conducted on the same Chinese HPSG formalism as used in the HPSG parser, comparing our semantic parsing results against the results of the existing approaches would not be accurate.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 125, "end_pos": 141, "type": "TASK", "confidence": 0.6910501420497894}]}, {"text": "However, a closely related work on joint syntactic and semantic parsing was done in the CoNLL-2009 shared task ().", "labels": [], "entities": [{"text": "syntactic and semantic parsing", "start_pos": 41, "end_pos": 71, "type": "TASK", "confidence": 0.6545190960168839}]}, {"text": "In this shared task, the Penn Chinese Treebank and the Chinese Proposition Bank () were merged to serve as the training and testing data, and a semantic labeled F1-score (Sem.F1) was applied to evaluate the performance of semantic role labeling (.", "labels": [], "entities": [{"text": "Penn Chinese Treebank", "start_pos": 25, "end_pos": 46, "type": "DATASET", "confidence": 0.9665852189064026}, {"text": "Chinese Proposition Bank", "start_pos": 55, "end_pos": 79, "type": "DATASET", "confidence": 0.954584002494812}, {"text": "F1-score (Sem.F1)", "start_pos": 161, "end_pos": 178, "type": "METRIC", "confidence": 0.8479275852441788}, {"text": "semantic role labeling", "start_pos": 222, "end_pos": 244, "type": "TASK", "confidence": 0.6564979751904806}]}, {"text": "While the CoNLL-2009 shared task only applied goldstandard word boundaries, our experiment used both gold-standard word boundaries and goldstandard POS tags.", "labels": [], "entities": []}, {"text": "lists the performance of the top three systems on the closed challenge for Chinese in the CoNLL-2009 shared task.", "labels": [], "entities": [{"text": "CoNLL-2009 shared task", "start_pos": 90, "end_pos": 112, "type": "DATASET", "confidence": 0.8395379384358724}]}, {"text": "Unfortunately, we cannot compare the result of the Chinese HPSG parser to the results of the top three systems in the CoNLL-2009 shared task, because of the different experimental settings.", "labels": [], "entities": [{"text": "Chinese HPSG parser", "start_pos": 51, "end_pos": 70, "type": "DATASET", "confidence": 0.8175946275393168}, {"text": "CoNLL-2009 shared task", "start_pos": 118, "end_pos": 140, "type": "DATASET", "confidence": 0.779126763343811}]}, {"text": "However, all the top systems in the shared task performed semantic role labeling after the syntactic parsing from the state-of-the-art parsers took place, whereas in our experiment, the Chinese HPSG parser applied a joint model that performed syntactic parsing and semantic parsing at the same time.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.619537760814031}, {"text": "syntactic parsing", "start_pos": 243, "end_pos": 260, "type": "TASK", "confidence": 0.7295850813388824}, {"text": "semantic parsing", "start_pos": 265, "end_pos": 281, "type": "TASK", "confidence": 0.740014523267746}]}], "tableCaptions": [{"text": " Table 1: Statistics for the Chinese HPSG Tree- bank", "labels": [], "entities": [{"text": "Chinese HPSG Tree- bank", "start_pos": 29, "end_pos": 52, "type": "DATASET", "confidence": 0.9327379107475281}]}, {"text": " Table 2: Accuracy of syntactic parsing\ud97b\udf59", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9951797723770142}, {"text": "syntactic parsing", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.8084755539894104}]}, {"text": " Table 3: Accuracy of semantic parsing by the  Chinese HPSG parser", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9932299852371216}, {"text": "semantic parsing", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.6709285080432892}, {"text": "Chinese HPSG parser", "start_pos": 47, "end_pos": 66, "type": "DATASET", "confidence": 0.8210882544517517}]}, {"text": " Table 4: Accuracy of the top three systems in  CoNLL-2009 Shared Task on Chinese Data", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.996121346950531}, {"text": "CoNLL-2009", "start_pos": 48, "end_pos": 58, "type": "DATASET", "confidence": 0.7765224575996399}, {"text": "Chinese Data", "start_pos": 74, "end_pos": 86, "type": "DATASET", "confidence": 0.7507152557373047}]}, {"text": " Table 5: Sem.F1 of the HPSG parser on both  English and Chinese, with different models", "labels": [], "entities": [{"text": "HPSG", "start_pos": 24, "end_pos": 28, "type": "DATASET", "confidence": 0.9291761517524719}]}, {"text": " Table 6: Average number of parses, words, and  verbs per sentence in the English and Chinese  development data", "labels": [], "entities": []}, {"text": " Table 7: Statistics of the supertags in the English  and Chinese HPSG Treebank", "labels": [], "entities": [{"text": "English  and Chinese HPSG Treebank", "start_pos": 45, "end_pos": 79, "type": "DATASET", "confidence": 0.669299304485321}]}, {"text": " Table 8: Distribution of the main reasons for  various verb supertags in Chinese", "labels": [], "entities": []}, {"text": " Table 9: Distribution of constructions in the Eng- lish and Chinese HPSG Treebank", "labels": [], "entities": [{"text": "Eng- lish and Chinese HPSG Treebank", "start_pos": 47, "end_pos": 82, "type": "DATASET", "confidence": 0.8792948637689862}]}, {"text": " Table 9. It re- veals that in the Chinese HPSG Treebank, there  are much more relative clauses than in the Eng- lish HPSG Treebank. Moreover, the proportion", "labels": [], "entities": [{"text": "Chinese HPSG Treebank", "start_pos": 35, "end_pos": 56, "type": "DATASET", "confidence": 0.8968327442804972}, {"text": "Eng- lish HPSG Treebank", "start_pos": 108, "end_pos": 131, "type": "DATASET", "confidence": 0.5965018451213837}]}, {"text": " Table 10: Occurrence of top 10 frequently occur- ring errors", "labels": [], "entities": [{"text": "Occurrence", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9913597702980042}, {"text": "ring errors", "start_pos": 50, "end_pos": 61, "type": "METRIC", "confidence": 0.914911687374115}]}]}