{"title": [{"text": "Integrating Models Derived from non-Parametric Bayesian Co-segmentation into a Statistical Machine Transliteration System", "labels": [], "entities": []}], "abstractContent": [{"text": "The system presented in this paper is based upon a phrase-based statistical machine transliteration (SMT) framework.", "labels": [], "entities": [{"text": "statistical machine transliteration (SMT)", "start_pos": 64, "end_pos": 105, "type": "TASK", "confidence": 0.7392963518699011}]}, {"text": "The SMT system's log-linear model is augmented with a set of features specifically suited to the task of transliteration.", "labels": [], "entities": [{"text": "SMT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9898897409439087}]}, {"text": "In particular our model utilizes a feature based on a joint source-channel model, and a feature based on a maximum entropy model that predicts target grapheme sequences using the local context of graphemes and grapheme sequences in both source and target languages.", "labels": [], "entities": []}, {"text": "The segmentation for our approach was performed using a non-parametric Bayesian co-segmentation model, and in this paper we present experiments comparing the effectiveness of this segmentation relative to the publicly available state-of-the-art m2m alignment tool.", "labels": [], "entities": []}, {"text": "In all our experiments we have taken a strictly language independent approach.", "labels": [], "entities": []}, {"text": "Each of the language pairs were processed automatically with no special treatment.", "labels": [], "entities": []}], "introductionContent": [{"text": "In the NEWS2010 workshop, reported that the performance of a phrasebased statistical machine transliteration system) could be improved significantly by combining it with a model based on the n-gram context of source-target grapheme sequence pairs: a joint source-channel model similar to that of ().", "labels": [], "entities": [{"text": "NEWS2010 workshop", "start_pos": 7, "end_pos": 24, "type": "DATASET", "confidence": 0.8760063350200653}]}, {"text": "Their system integrated the two approaches by using a re-scoring step at the end of the decoding process.", "labels": [], "entities": []}, {"text": "Our system goes one step further and integrates a joint source-channel model directly into the SMT decoder to allow the probabilities from it to betaken into account within a single search process in the similar manner to ().", "labels": [], "entities": [{"text": "SMT", "start_pos": 95, "end_pos": 98, "type": "TASK", "confidence": 0.881942093372345}]}], "datasetContent": [{"text": "A novel feature of our system is the Bayesian co-segmentation approach used to bilingually segment the data in order to yield training data from which to train the models in our system.", "labels": [], "entities": []}, {"text": "It has been shown) that in transliteration, this Bayesian approach can give rise to a smaller and more useful phrase-table than that derived by using GIZA++ for alignment and the grow-diag-final-and heuristics which have been shown to be effective for transliteration.", "labels": [], "entities": []}, {"text": "In these experiments we compare the Bayesian segmenter to a similar state-of-the-art segmentation tool that is capable of many-to-many alignments: the publicly available m2m alignment tool 2 () that is trained using the EM algorithm and is based on the principles set out in (.", "labels": [], "entities": []}, {"text": "We used a similar system to that in the shared task, but without the maximum entropy model.", "labels": [], "entities": []}, {"text": "The experiments were run in the same way using the same script, the only difference being the choice of aligner used.", "labels": [], "entities": []}, {"text": "We used data from the 2009 NEWS workshop for our experiments, and evaluated using the F-score metric used for the shared task evaluation.", "labels": [], "entities": [{"text": "NEWS workshop", "start_pos": 27, "end_pos": 40, "type": "DATASET", "confidence": 0.7959704399108887}, {"text": "F-score metric", "start_pos": 86, "end_pos": 100, "type": "METRIC", "confidence": 0.9731322526931763}]}, {"text": "The aligners were run with their default settings, and with the same limits for source and target segment size.", "labels": [], "entities": []}, {"text": "It may have been possible to obtain better performance from the aligners by adjusting specific parameters, but no attempt was made to do this.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "In all experiments, the Bayesian segmenter gave the best performance, and the largest improvement was on language pairs that have large grapheme set sizes on the target side.", "labels": [], "entities": [{"text": "Bayesian segmenter", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.6339551210403442}]}, {"text": "The grapheme set size is shown in in the 'Target Types' column.", "labels": [], "entities": []}, {"text": "The source grapheme set sizes were very similar and small (around 27) for all experiments, as the source language was either English or in the case of Jn-Jk, a romanized form of Japanese.", "labels": [], "entities": []}, {"text": "Looking at the n-gram statistics in, for languages with large grapheme sets the number of unigrams in the Bayesian model is less than half that used by the m2m model.", "labels": [], "entities": []}, {"text": "Learning a compact model is one of the signature characteristics of the Bayesian model we use; adding anew parameter to the model is extremely costly, and the algorithm will therefore 2 http://code.google.com/p/m2m-aligner/ strongly prefer to learn a model in which the parameters are re-used.", "labels": [], "entities": []}, {"text": "Initially we considered the hypotheses that the difference in performance between these two approaches came from differences in the sparseness of the language models.", "labels": [], "entities": []}, {"text": "Surprisingly however, the numbers of bi-grams and tri-grams in the joint language models are quite similar.", "labels": [], "entities": []}, {"text": "Another explanation is that the smaller number of unigrams indicates that the segmentation is more self-consistent and therefore makes the generation task less ambiguous.", "labels": [], "entities": []}, {"text": "This is supported by looking at the development set perplexity.", "labels": [], "entities": []}, {"text": "On the Jn-Jk task where the differences between the systems are the largest, we found that a joint language model trained on the Bayesian segmentation had 1-, 2-, and 3-gram perplexities of 218.3, 88.4 and 87.5 respectively, whereas the corresponding m2m model's perplexities were 321.8, 120.5 and 119.3.", "labels": [], "entities": []}, {"text": "The number of segments used to segment the corpus was the same for both systems in this experiment.", "labels": [], "entities": []}, {"text": "gives an example from the data of the differences in segmentation consistency.", "labels": [], "entities": []}, {"text": "The Bayesian segmentation is strongly self-consistent.", "labels": [], "entities": [{"text": "Bayesian segmentation", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.587511345744133}]}, {"text": "The source sequence 'ara' has been segmented identically as a single unit in all cases.", "labels": [], "entities": []}, {"text": "The m2m system also shows self-consistency, but uses a few different strategies to segment the start of the sequence.", "labels": [], "entities": []}, {"text": "Interestingly the Bayesian method in this example has segmented according to the correct linguistic readings of the kanji.", "labels": [], "entities": []}, {"text": "We investigate this further in the next section.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: System performance in terms of F-score, by using alternative segmentation schemes together  with statistics relating to be number of parameters in the models derived from the segmentations.", "labels": [], "entities": [{"text": "F-score", "start_pos": 41, "end_pos": 48, "type": "METRIC", "confidence": 0.9953945279121399}]}]}