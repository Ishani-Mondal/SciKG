{"title": [{"text": "A Cross-corpus Study of Unsupervised Subjectivity Identification based on Calibrated EM", "labels": [], "entities": [{"text": "Unsupervised Subjectivity Identification", "start_pos": 24, "end_pos": 64, "type": "TASK", "confidence": 0.6819000144799551}]}], "abstractContent": [{"text": "In this study we investigate using an unsu-pervised generative learning method for sub-jectivity detection in text across different domains.", "labels": [], "entities": [{"text": "sub-jectivity detection", "start_pos": 83, "end_pos": 106, "type": "TASK", "confidence": 0.7512843608856201}]}, {"text": "We create an initial training set using simple lexicon information, and then evaluate a calibrated EM (expectation-maximization) method to learn from unannotated data.", "labels": [], "entities": [{"text": "EM", "start_pos": 99, "end_pos": 101, "type": "METRIC", "confidence": 0.7908494472503662}]}, {"text": "We evaluate this unsupervised learning approach on three different domains: movie data, news resource, and meeting dialogues.", "labels": [], "entities": []}, {"text": "We also perform a thorough analysis to examine impact-ing factors on unsupervised learning, such as the size and self-labeling accuracy of the initial training set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.9457773566246033}]}, {"text": "Our experiments and analysis show inherent differences across domains and performance gain from calibration in EM.", "labels": [], "entities": []}], "introductionContent": [{"text": "Subjectivity identification is to identify whether an expression contains opinion or sentiment.", "labels": [], "entities": [{"text": "Subjectivity identification", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.938662052154541}]}, {"text": "Automatic subjectivity identification can benefit many natural language processing (NLP) tasks.", "labels": [], "entities": [{"text": "subjectivity identification", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.6943283230066299}]}, {"text": "For example, information retrieval systems can provide affective or informative articles separately.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 13, "end_pos": 34, "type": "TASK", "confidence": 0.7549992799758911}]}, {"text": "Summarization systems may want to summarize factual and opinionated content differently (.", "labels": [], "entities": [{"text": "summarize factual and opinionated content", "start_pos": 34, "end_pos": 75, "type": "TASK", "confidence": 0.8319687366485595}]}, {"text": "In this paper, we perform subjectivity detection at sentence level, which is more appropriate for some subsequent processing such as opinion summarization.", "labels": [], "entities": [{"text": "subjectivity detection", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.7362549901008606}, {"text": "opinion summarization", "start_pos": 133, "end_pos": 154, "type": "TASK", "confidence": 0.7810685336589813}]}, {"text": "Previous work has shown that when enough labeled data is available, supervised classification methods can achieve high accuracy for subjectivity detection in some domains.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9930452704429626}, {"text": "subjectivity detection", "start_pos": 132, "end_pos": 154, "type": "TASK", "confidence": 0.7390901446342468}]}, {"text": "However, it is often expensive to create such training data.", "labels": [], "entities": []}, {"text": "On the other hand, a lot of unannotated data is readily available in various domains.", "labels": [], "entities": []}, {"text": "Therefore an interesting and important problem is to develop semi-supervised or unsupervised learning methods that can learn from an unannotated corpus.", "labels": [], "entities": []}, {"text": "In this study, we use an unsupervised learning approach where we first use a knowledge-based method to create an initial training set, and then apply a calibrated EM method to learn from an unannotated corpus.", "labels": [], "entities": []}, {"text": "Our experiments show significant differences among the three domains: movie, news article, and meeting dialog.", "labels": [], "entities": []}, {"text": "This can be explained by the inherent difference of the data, especially the task difficulty and classifier's performance fora domain.", "labels": [], "entities": []}, {"text": "We demonstrate that for some domains (e.g., movie data) the unsupervised learning methods can rival the supervised approach.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we evaluate our unsupervised learning method and analyze various impacting factors.", "labels": [], "entities": []}, {"text": "In preprocessing, we removed the punctuation and numbers from the data and performed word stemming.", "labels": [], "entities": [{"text": "word stemming", "start_pos": 85, "end_pos": 98, "type": "TASK", "confidence": 0.7485441863536835}]}, {"text": "To measure performance, we use classification accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.8735507130622864}]}], "tableCaptions": [{"text": " Table 1: Statistics for the three data sets: movie, MPQA, and", "labels": [], "entities": [{"text": "MPQA", "start_pos": 53, "end_pos": 57, "type": "DATASET", "confidence": 0.5135514736175537}]}, {"text": " Table 2: Initial pseudo training accuracy for SUBJECTIVE", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9347542524337769}, {"text": "SUBJECTIVE", "start_pos": 47, "end_pos": 57, "type": "TASK", "confidence": 0.9625566601753235}]}]}