{"title": [], "abstractContent": [{"text": "The paper presents a semi-automatic approach to creating sentiment dictionaries in many languages.", "labels": [], "entities": [{"text": "sentiment dictionaries", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.8084247410297394}]}, {"text": "We first produced high-level gold-standard sentiment dictionaries for two languages and then translated them automatically into third languages.", "labels": [], "entities": []}, {"text": "Those words that can be found in both target language word lists are likely to be useful because their word senses are likely to be similar to that of the two source languages.", "labels": [], "entities": []}, {"text": "These dictionaries can be further corrected, extended and improved.", "labels": [], "entities": []}, {"text": "In this paper, we present results that verify our triangulation hypothesis, by evaluating tri-angulated lists and comparing them to non-triangulated machine-translated word lists.", "labels": [], "entities": []}], "introductionContent": [{"text": "When developing software applications for sentiment analysis or opinion mining, there are basically two main options: (1) writing rules that assign sentiment values to text or text parts (e.g. names, products, product features), typically making use of dictionaries consisting of sentiment words and their positive or negative values, and (2) inferring rules (and sentiment dictionaries), e.g. using machine learning techniques, from previously annotated documents such as product reviews annotated with an overall judgment of the product.", "labels": [], "entities": [{"text": "sentiment analysis or opinion mining", "start_pos": 42, "end_pos": 78, "type": "TASK", "confidence": 0.7492324352264405}]}, {"text": "While movie or product reviews for many languages can frequently be found online, sentiment-annotated data for other fields are not usually available, or they are almost exclusively available for English.", "labels": [], "entities": []}, {"text": "Sentiment dictionaries are also mostly available for English only or, if they exist for other languages, they are not comparable, in the sense that they have been developed for different purposes, have different sizes, are based on different definitions of what sentiment or opinion means.", "labels": [], "entities": [{"text": "Sentiment dictionaries", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8559664487838745}]}, {"text": "In this paper, we are addressing the resource bottleneck for sentiment dictionaries, by developing highly multilingual and comparable sentiment dictionaries having similar sizes and based on a common specification.", "labels": [], "entities": [{"text": "sentiment dictionaries", "start_pos": 61, "end_pos": 83, "type": "TASK", "confidence": 0.9338011741638184}]}, {"text": "The aim is to develop such dictionaries, consisting of typically one or two thousand words, for tens of languages, although in this paper we only present results for eight languages (English, Spanish, Arabic, Czech, French, German, Italian and Russian).", "labels": [], "entities": []}, {"text": "The task raises the obvious question how the human effort of producing this resource can be minimized.", "labels": [], "entities": []}, {"text": "Simple translation, be it using standard dictionaries or using machine translation, is not very efficient as most words have two, five or ten different possible translations, depending on context, part-of-speech, etc.", "labels": [], "entities": [{"text": "Simple translation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7480663955211639}, {"text": "machine translation", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.7479244768619537}]}, {"text": "The approach we therefore chose is that of triangulation.", "labels": [], "entities": []}, {"text": "We first produced high-level gold-standard sentiment dictionaries for two languages (English and Spanish) and then translated them automatically into third languages, e.g. French.", "labels": [], "entities": []}, {"text": "Those words that can be found in both target language word lists (En Fr and Es Fr) are likely to be useful because their word senses are likely to be similar to that of the two source languages.", "labels": [], "entities": []}, {"text": "These word lists can then be used as they are or better they can be corrected, extended and improved.", "labels": [], "entities": []}, {"text": "In this paper, we present evaluation results verifying our triangulation hypothesis, by evaluating triangulated lists and comparing them to non-triangulated machine-translated word lists.", "labels": [], "entities": []}, {"text": "Two further issues need to be addressed.", "labels": [], "entities": []}, {"text": "The first one concerns morphological inflection.", "labels": [], "entities": [{"text": "morphological inflection", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.867601752281189}]}, {"text": "Automatic translation will yield one word form (often, but not always the base form), which is not sufficient when working with highly inflected languages: A single English adjective typically has four Spanish or Italian word forms (two each for gender and for number) and many Russian word forms (due to gender, number and case distinctions).", "labels": [], "entities": []}, {"text": "The target language word lists thus need to be expanded to coverall these morphological variants with minimal effort and considering the number of different languages involved without using software, such as morphological analysers or generators.", "labels": [], "entities": []}, {"text": "The second issue has to do with the subjectivity involved in the human annotation and evaluation effort.", "labels": [], "entities": []}, {"text": "First of all, it is important that the task is well-defined (this is a challenge by itself) and, secondly, the inter-annotator agreement for pairs of human evaluators working on different languages has to be checked in order to get an idea of the natural variation involved in such a highly subjective task.", "labels": [], "entities": []}, {"text": "Our main field of interest is news opinion mining.", "labels": [], "entities": [{"text": "news opinion mining", "start_pos": 30, "end_pos": 49, "type": "TASK", "confidence": 0.6847283244132996}]}, {"text": "We would like to answer the question how certain entities (persons, organisations, event names, programmes) are discussed in different media overtime, comparing different media sources, media in different countries, and media written in different languages.", "labels": [], "entities": []}, {"text": "One possible end product would be a graph showing how the popularity of a certain entity has changed overtime across different languages and countries.", "labels": [], "entities": []}, {"text": "News differs significantly from those text types that are typically analysed in opinion mining work, i.e. product or movie reviews: While a product review is about a product (e.g. a printer) and its features (e.g. speed, price or printing quality), the news is about any possible subject (news content), which can by itself be perceived to be positive or negative.", "labels": [], "entities": []}, {"text": "Entities mentioned in the news can have many different roles in the events described.", "labels": [], "entities": []}, {"text": "If the method does not specifically separate positive or negative news content from positive or negative opinion about that entity, the sentiment analysis results will be strongly influenced by the news context.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 136, "end_pos": 154, "type": "TASK", "confidence": 0.7626522779464722}]}, {"text": "For instance, the automatically identified sentiment towards a politician would most likely to below if the politician is mentioned in the context of negative news content such as bombings or disasters.", "labels": [], "entities": []}, {"text": "In our approach, we therefore aim to distinguish news content from sentiment values, and this distinction has an impact on the sentiment dictionaries: unlike in other approaches, words like death, killing, award or winner are purposefully not included in the sentiment dictionaries as they typically represent news content.", "labels": [], "entities": []}, {"text": "The rest of the paper is structured as follows: the next section (2) describes related work, especially in the context of creating sentiment resources.", "labels": [], "entities": []}, {"text": "Section 3 gives an overview of our approach to dictionary creation, ranging from the automatic learning of the sentiment vocabulary, the triangulation process, the expansion of the dictionaries in size and regarding morphological inflections.", "labels": [], "entities": [{"text": "dictionary creation", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.8855666220188141}]}, {"text": "Section 4 presents a number of results regarding dictionary creation using simple translation versus triangulation, morphological expansion and inter-annotator agreement.", "labels": [], "entities": [{"text": "dictionary creation", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.861828476190567}, {"text": "morphological expansion", "start_pos": 116, "end_pos": 139, "type": "TASK", "confidence": 0.7429179549217224}]}, {"text": "Section 5 summarises, concludes and points to future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The size of the pilot dictionaries. HN=highly  negative terms, N=negative, P=positive, HP=highly posi- tive, INV=invertors, DIM=diminishers, INV=invertors.", "labels": [], "entities": [{"text": "INV", "start_pos": 151, "end_pos": 154, "type": "METRIC", "confidence": 0.9824452996253967}]}, {"text": " Table 6: Inter-annotator agreement on checking the trian- gulated list. In the case of HP all terms were annotated as  correct by one of the annotators resulting in Kappa=0.", "labels": [], "entities": []}, {"text": " Table 7: Inter-annotator agreement on checking the can- didates. In ALL diminishers, intensifiers and invertors  are included as well.", "labels": [], "entities": []}, {"text": " Table 2: The size and quality of the triangulated dictionaries. Triangulated=No. of terms coming directly from triangu- lation, Correct=terms annotated as correct, Removed=terms not relevant to sentiment analysis, Change category=terms  in wrong category (e.g., positive from triangulation, but annotator changed the category to highly positive).", "labels": [], "entities": [{"text": "Removed", "start_pos": 165, "end_pos": 172, "type": "METRIC", "confidence": 0.9762261509895325}, {"text": "sentiment analysis", "start_pos": 195, "end_pos": 213, "type": "TASK", "confidence": 0.8351379036903381}]}, {"text": " Table 3: The size and quality of the candidate terms (translated from English but not from Spanish). Terms=No. of  terms translated from English but not from Spanish, Correct=terms annotated as correct, Removed=terms not relevant  to sentiment analysis, Change category=terms in wrong category (e.g., positive in the original list, but annotator  changed the category to highly positive).", "labels": [], "entities": [{"text": "Correct", "start_pos": 168, "end_pos": 175, "type": "METRIC", "confidence": 0.9658111929893494}, {"text": "Removed", "start_pos": 204, "end_pos": 211, "type": "METRIC", "confidence": 0.9913404583930969}, {"text": "sentiment analysis", "start_pos": 235, "end_pos": 253, "type": "TASK", "confidence": 0.8910161256790161}]}, {"text": " Table 4: The size and quality of the translated terms from English. Terms=No. of (distinct) terms translated from En- glish, Correct=terms annotated as correct, Removed=terms not relevant to sentiment analysis, Change category=terms  in wrong category (e.g., positive in the original list, but annotator changed the category to highly positive).", "labels": [], "entities": [{"text": "Removed", "start_pos": 162, "end_pos": 169, "type": "METRIC", "confidence": 0.9903016090393066}, {"text": "sentiment analysis", "start_pos": 192, "end_pos": 210, "type": "TASK", "confidence": 0.8735085129737854}]}, {"text": " Table 5: Statistics of introducing wild cards and its evaluation. Initial terms=checked triangulated terms extended by  relevant translated terms from English, Patterns=number of patterns after introducing wildcards, Matched terms=terms  matched in the large corpus -their count and correctness + checked=how many mentions were checked (based on the  fact that the most frequent terms were annotated).", "labels": [], "entities": []}]}