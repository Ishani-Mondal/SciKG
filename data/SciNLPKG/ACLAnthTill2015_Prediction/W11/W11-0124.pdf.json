{"title": [{"text": "Abductive Reasoning with a Large Knowledge Base for Discourse Processing", "labels": [], "entities": [{"text": "Abductive Reasoning", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7394416034221649}]}], "abstractContent": [{"text": "This paper presents a discourse processing framework based on weighted abduction.", "labels": [], "entities": []}, {"text": "We elaborate on ideas described in Hobbs et al.", "labels": [], "entities": []}, {"text": "(1993) and implement the abductive inference procedure in a system called Mini-TACITUS.", "labels": [], "entities": []}, {"text": "Particular attention is paid to constructing a large and reliable knowledge base for supporting inferences.", "labels": [], "entities": []}, {"text": "For this purpose we exploit such lexical-semantic resources as WordNet and FrameNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 63, "end_pos": 70, "type": "DATASET", "confidence": 0.963988184928894}]}, {"text": "We test the proposed procedure and the obtained knowledge base on the Recognizing Textual Entailment task using the data sets from the RTE-2 challenge for evaluation.", "labels": [], "entities": [{"text": "Recognizing Textual Entailment task", "start_pos": 70, "end_pos": 105, "type": "TASK", "confidence": 0.833462581038475}, {"text": "RTE-2 challenge", "start_pos": 135, "end_pos": 150, "type": "DATASET", "confidence": 0.7714032828807831}]}, {"text": "In addition, we provide an evaluation of the semantic role labeling produced by the system taking the Frame-Annotated Corpus for Textual Entailment as a gold standard.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.6698908607165018}, {"text": "Frame-Annotated Corpus", "start_pos": 102, "end_pos": 124, "type": "DATASET", "confidence": 0.8126081824302673}]}], "introductionContent": [{"text": "In this paper, we elaborate on a semantic processing framework based on a mode of inference called abduction, or inference to the best explanation.", "labels": [], "entities": []}, {"text": "In logics, abduction is a kind of inference which arrives at an explanatory hypothesis given an observation.", "labels": [], "entities": []}, {"text": "describe how abductive reasoning can be applied to the discourse processing problem viewing the process of interpreting sentences in discourse as the process of providing the best explanation of why the sentence would be true.", "labels": [], "entities": []}, {"text": "In this framework, interpreting a sentence means 1) proving its logical form, 2) merging redundancies where possible, and 3) making assumptions where necessary.", "labels": [], "entities": [{"text": "interpreting a sentence", "start_pos": 19, "end_pos": 42, "type": "TASK", "confidence": 0.8865931431452433}]}, {"text": "As the reader will see later in this paper, abductive reasoning as a discourse processing technique helps to solve many pragmatic problems such as reference resolution, the interpretation of noun compounds, the resolution of some kinds of syntactic, and semantic ambiguity as a by-product.", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 147, "end_pos": 167, "type": "TASK", "confidence": 0.7955968081951141}, {"text": "interpretation of noun compounds", "start_pos": 173, "end_pos": 205, "type": "TASK", "confidence": 0.8052575290203094}]}, {"text": "Specifically, we use a system we have built called Mini-TACITUS 1 () that provides the expressivity of logical inference but also allows probabilistic, fuzzy, or defeasible inference and includes measures of the \"goodness\" of abductive proofs and hence of interpretations of texts and other situations.", "labels": [], "entities": []}, {"text": "The success of a discourse processing system based on inferences heavily depends on a knowledge base.", "labels": [], "entities": []}, {"text": "The main contribution of this paper is in showing how a large and reliable knowledge base can be obtained by exploiting existing lexical semantic resources and can be successfully applied to reasoning tasks on a large scale.", "labels": [], "entities": []}, {"text": "In particular, we experiment with axioms extracted from WordNet, see, and FrameNet, see.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 56, "end_pos": 63, "type": "DATASET", "confidence": 0.9793915152549744}]}, {"text": "In axiomatizing FrameNet we rely on the study described in.", "labels": [], "entities": []}, {"text": "We evaluate our inference system and the obtained knowledge base in recognizing textual entailment (RTE).", "labels": [], "entities": [{"text": "recognizing textual entailment (RTE)", "start_pos": 68, "end_pos": 104, "type": "TASK", "confidence": 0.7807059288024902}]}, {"text": "As the reader will see in the following sections, inferences carried out by Mini-TACITUS are fairly general and not tuned fora particular application.", "labels": [], "entities": [{"text": "Mini-TACITUS", "start_pos": 76, "end_pos": 88, "type": "DATASET", "confidence": 0.895146906375885}]}, {"text": "We decided to test our approach on RTE because this is a well-defined task that captures major semantic inference needs across many natural language processing applications, such as question answering, information retrieval, information extraction, and document summarization.", "labels": [], "entities": [{"text": "RTE", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.965833306312561}, {"text": "question answering", "start_pos": 182, "end_pos": 200, "type": "TASK", "confidence": 0.8535671532154083}, {"text": "information retrieval", "start_pos": 202, "end_pos": 223, "type": "TASK", "confidence": 0.8101765215396881}, {"text": "information extraction", "start_pos": 225, "end_pos": 247, "type": "TASK", "confidence": 0.8258658647537231}, {"text": "document summarization", "start_pos": 253, "end_pos": 275, "type": "TASK", "confidence": 0.7187350392341614}]}, {"text": "For evaluation, we have chosen the RTE-2 data set (), because besides providing text-hypothesis pairs and a gold standard this data set has been annotated with FrameNet frame and role labels) which gives us the possibility of evaluating our frame and role labeling based on the axioms extracted from FrameNet.", "labels": [], "entities": [{"text": "RTE-2 data set", "start_pos": 35, "end_pos": 49, "type": "DATASET", "confidence": 0.9463231960932413}, {"text": "FrameNet", "start_pos": 300, "end_pos": 308, "type": "DATASET", "confidence": 0.9484750032424927}]}], "datasetContent": [{"text": "We have evaluated our procedure on the RTE-2 dataset 8 , see . The RTE-2 dataset contains the development and the test set, both including 800 text-hypothesis pairs.", "labels": [], "entities": [{"text": "RTE-2 dataset 8", "start_pos": 39, "end_pos": 54, "type": "DATASET", "confidence": 0.9481170574824015}, {"text": "RTE-2 dataset", "start_pos": 67, "end_pos": 80, "type": "DATASET", "confidence": 0.9738473296165466}]}, {"text": "Each dataset consists of four subsets, which correspond to typical success and failure settings in different applications: information extraction (IE), information retrieval (IR), question answering (QA), and summarization (SUM).", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 123, "end_pos": 150, "type": "TASK", "confidence": 0.8429369568824768}, {"text": "information retrieval (IR)", "start_pos": 152, "end_pos": 178, "type": "TASK", "confidence": 0.8339288711547852}, {"text": "question answering (QA)", "start_pos": 180, "end_pos": 203, "type": "TASK", "confidence": 0.8613820433616638}, {"text": "summarization (SUM)", "start_pos": 209, "end_pos": 228, "type": "TASK", "confidence": 0.825866162776947}]}, {"text": "In total, 200 pairs were collected for each application in each dataset.", "labels": [], "entities": []}, {"text": "As a baseline we have processed the datasets with an empty knowledge base.", "labels": [], "entities": []}, {"text": "Then we have done 2 runs, first, using axioms extracted from WordNet 3.0 plus FrameNet, and, second, using axioms extracted from the WordNet 2.0 definitions.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 61, "end_pos": 68, "type": "DATASET", "confidence": 0.9587123990058899}, {"text": "WordNet 2.0 definitions", "start_pos": 133, "end_pos": 156, "type": "DATASET", "confidence": 0.9196141759554545}]}, {"text": "In both runs the depth parameter was set to 3.", "labels": [], "entities": [{"text": "depth", "start_pos": 17, "end_pos": 22, "type": "METRIC", "confidence": 0.9844827055931091}]}, {"text": "The development set was used to train the threshold as described in the previous section.", "labels": [], "entities": []}, {"text": "9 contains results of our experiments.", "labels": [], "entities": []}, {"text": "Accuracy was calculated as the percentage of pairs correctly judged.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9970276951789856}]}, {"text": "The results suggest that the proposed method seems to be promising as compared to the other systems evaluated on the same task.", "labels": [], "entities": []}, {"text": "Our best run gives 63% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9998138546943665}]}, {"text": "Two systems participating the RTE-2 Challenge had 73% and 75% accuracy, two systems achieved 62% and 63%, while most of the systems achieved 55%-61%, cf..", "labels": [], "entities": [{"text": "RTE-2 Challenge", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.5380380153656006}, {"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9995800852775574}]}, {"text": "For our best run (WN 3.0 + FN), we present the accuracy data for each application separately (table 2).", "labels": [], "entities": [{"text": "FN", "start_pos": 27, "end_pos": 29, "type": "METRIC", "confidence": 0.7053351998329163}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.999345600605011}]}, {"text": "The distribution of the performance of Mini-TACITUS on the four datasets corresponds to the average performance of systems participating in RTE-2 as reported by.", "labels": [], "entities": [{"text": "RTE-2", "start_pos": 140, "end_pos": 145, "type": "DATASET", "confidence": 0.647907018661499}]}, {"text": "The most challenging task in RTE-2 appeared to be IE.", "labels": [], "entities": [{"text": "RTE-2", "start_pos": 29, "end_pos": 34, "type": "TASK", "confidence": 0.5596709847450256}, {"text": "IE", "start_pos": 50, "end_pos": 52, "type": "TASK", "confidence": 0.8843544721603394}]}, {"text": "QA and IR follow, and finally, SUM was titled the \"easiest\" task, with a performance significantly higher than that of any other task.", "labels": [], "entities": [{"text": "QA", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9325971603393555}, {"text": "IR", "start_pos": 7, "end_pos": 9, "type": "METRIC", "confidence": 0.7702488899230957}, {"text": "SUM", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9684712886810303}]}, {"text": "It is worth noting that the performance of Mini-TACITUS increases with the increasing time of processing.", "labels": [], "entities": []}, {"text": "We use the time parameter t for restricting the processing time.", "labels": [], "entities": []}, {"text": "The smaller t is, the fewer chances Mini-TACITUS has for applying all relevant axioms.", "labels": [], "entities": []}, {"text": "The experiments carried out suggest that optimizing the system computationally could lead to producing significantly better results.", "labels": [], "entities": []}, {"text": "Tracing the reasoning process, we found out that given along sentence and a short processing time Mini-TACITUS had time to construct only a few interpretations, and the real best interpretation was not always among them.", "labels": [], "entities": []}, {"text": "The lower performance of the system using the KB based on axioms extracted from extended WordNet can be easily explained.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 89, "end_pos": 96, "type": "DATASET", "confidence": 0.9462112188339233}]}, {"text": "At the moment we define non-merge constraints (see section 2) for the input propositions only.", "labels": [], "entities": []}, {"text": "The axioms extracted from the synset definitions introduce a lot of new lexemes into the logical form, since these axioms define words with the help of other words rather than abstract concepts.", "labels": [], "entities": []}, {"text": "These new lexemes, especially those which are frequent in English, result in undesired mergings (e.g., mergings of frequent prepositions), since no non-merge constraints are defined for them.", "labels": [], "entities": []}, {"text": "In order to fix this problem, we will need to implement dynamic non-merge constraints which will be added on the fly if anew lexeme is introduced during reasoning.", "labels": [], "entities": []}, {"text": "The WN 3.0 + FN axiom set does not fall into this problem, because these axioms operate on frames and synsets rather than on lexemes.", "labels": [], "entities": []}, {"text": "In addition, for the run using axioms derived from FrameNet, we have evaluated how well we do in assigning frames and frame roles.", "labels": [], "entities": [{"text": "FrameNet", "start_pos": 51, "end_pos": 59, "type": "DATASET", "confidence": 0.8925287127494812}]}, {"text": "For Mini-TACITUS, semantic role labeling is a by-product of constructing the best interpretation.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.7006377577781677}]}, {"text": "But since this task is considered to be important as such in the NLP community, we provide an additional evaluation for it.", "labels": [], "entities": []}, {"text": "As a gold standard we have used the FrameAnnotated Corpus for Textual Entailment, FATE, see.", "labels": [], "entities": [{"text": "FrameAnnotated Corpus", "start_pos": 36, "end_pos": 57, "type": "DATASET", "confidence": 0.8217842280864716}, {"text": "Textual Entailment", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.6284705996513367}, {"text": "FATE", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.5050833821296692}]}, {"text": "This corpus provides frame and semantic role label annotations for the RTE-2 challenge test set.", "labels": [], "entities": [{"text": "RTE-2 challenge test set", "start_pos": 71, "end_pos": 95, "type": "DATASET", "confidence": 0.7879286557435989}]}, {"text": "It is important to http://pascallin.ecs.soton.ac.uk/Challenges/RTE2/ 9 Interpretation costs were normalized to the number of propositions in the input.", "labels": [], "entities": []}, {"text": "\"Time\" stands for the value of the time parameter -processing time per sentence, in minutes; \"Numb. of ax.\" stands for the average number of axioms per sentence.", "labels": [], "entities": [{"text": "Time", "start_pos": 1, "end_pos": 5, "type": "METRIC", "confidence": 0.9772467613220215}, {"text": "Numb. of ax.", "start_pos": 94, "end_pos": 106, "type": "METRIC", "confidence": 0.8902518153190613}]}, {"text": "In order to get a better understanding of which parts of our KB are useful for computing entailment and for which types of entailment, in future, we are planning to use the detailed annotation of the RTE-2 dataset describing the source of the entailment which was produced by.", "labels": [], "entities": [{"text": "RTE-2 dataset", "start_pos": 200, "end_pos": 213, "type": "DATASET", "confidence": 0.9494686722755432}]}, {"text": "We would like to thank one of our reviewers forgiving us this idea.", "labels": [], "entities": []}, {"text": "12 FATE was annotated with the FrameNet 1.3 labels, while we have been using 1.5 version for extracting axioms.", "labels": [], "entities": [{"text": "FATE", "start_pos": 3, "end_pos": 7, "type": "DATASET", "confidence": 0.5765429139137268}, {"text": "FrameNet 1.3 labels", "start_pos": 31, "end_pos": 50, "type": "DATASET", "confidence": 0.9124578833580017}]}, {"text": "However,  note that FATE annotates only those frames which are relevant for computing entailment.", "labels": [], "entities": [{"text": "FATE", "start_pos": 20, "end_pos": 24, "type": "DATASET", "confidence": 0.5878849625587463}]}, {"text": "Since Mini-TACITUS makes all possible frame assignments fora sentence, we provide only the recall measure for the frame match and leave the precision out.", "labels": [], "entities": [{"text": "recall", "start_pos": 91, "end_pos": 97, "type": "METRIC", "confidence": 0.9992196559906006}, {"text": "precision", "start_pos": 140, "end_pos": 149, "type": "METRIC", "confidence": 0.9972645044326782}]}, {"text": "The FATE corpus was also used as a gold standard for evaluating the Shalmaneser system) which is a state-of-the-art system for assigning FrameNet frames and roles.", "labels": [], "entities": [{"text": "FATE corpus", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9144507050514221}]}, {"text": "In table 2 we replicate results for Shalmaneser alone and Shalmaneser boosted with the WordNet Detour to FrameNet).", "labels": [], "entities": [{"text": "WordNet Detour", "start_pos": 87, "end_pos": 101, "type": "DATASET", "confidence": 0.8996637165546417}]}, {"text": "The WN-FN Detour extended the frame labels assigned by Shalmaneser with the labels related via the FrameNet hierarchy or by the WordNet inheritance relation, cf..", "labels": [], "entities": []}, {"text": "In frame matching, the number of frame labels in the gold standard annotation that can also be found in the system annotation (recall) was counted.", "labels": [], "entities": [{"text": "frame matching", "start_pos": 3, "end_pos": 17, "type": "TASK", "confidence": 0.8141657412052155}, {"text": "recall", "start_pos": 127, "end_pos": 133, "type": "METRIC", "confidence": 0.9933852553367615}]}, {"text": "Role matching was evaluated only on the frames that are correctly annotated by the system.", "labels": [], "entities": [{"text": "Role matching", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8677879869937897}]}, {"text": "The number of role labels in the gold standard annotation that can also be found in the system annotation (recall) as well as the number of role labels found by the system which also occur in the gold standard (precision) were counted.", "labels": [], "entities": [{"text": "recall", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.9953083395957947}, {"text": "precision", "start_pos": 211, "end_pos": 220, "type": "METRIC", "confidence": 0.9594500660896301}]}, {"text": "13 shows that given FrameNet axioms, the performance of Mini-TACITUS on semantic role labeling is compatible with those of the system specially designed to solve this task.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.6548238495985667}]}], "tableCaptions": [{"text": " Table 1: Statistics for extracted axioms", "labels": [], "entities": []}, {"text": " Table 2: Evaluation results for the RTE-2 test set", "labels": [], "entities": [{"text": "RTE-2 test set", "start_pos": 37, "end_pos": 51, "type": "DATASET", "confidence": 0.8532459338506063}]}, {"text": " Table 3: Evaluation of frames/roles labeling towards FATE", "labels": [], "entities": [{"text": "FATE", "start_pos": 54, "end_pos": 58, "type": "TASK", "confidence": 0.4062778055667877}]}]}