{"title": [{"text": "Unsupervised Concept Annotation using Latent Dirichlet Allocation and Segmental Methods", "labels": [], "entities": [{"text": "Unsupervised Concept Annotation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.5604324837525686}]}], "abstractContent": [{"text": "Training efficient statistical approaches for natural language understanding generally requires data with segmental semantic annotations.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 46, "end_pos": 76, "type": "TASK", "confidence": 0.6512670417626699}]}, {"text": "Unfortunately, building such resources is costly.", "labels": [], "entities": []}, {"text": "In this paper, we propose an approach that produces annotations in an unsu-pervised way.", "labels": [], "entities": []}, {"text": "The first step is an implementation of latent Dirichlet allocation that produces a set of topics with probabilities for each topic to be associated with a word in a sentence.", "labels": [], "entities": []}, {"text": "This knowledge is then used as a bootstrap to infer a segmentation of a word sentence into topics using either integer linear optimisation or stochastic word alignment models (IBM models) to produce the final semantic annotation.", "labels": [], "entities": []}, {"text": "The relation between automatically-derived topics and task-dependent concepts is evaluated on a spoken dialogue task with an available reference annotation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spoken dialogue systems in the field of information query are basically used to interface a database with users using speech.", "labels": [], "entities": []}, {"text": "When probabilistic models are used in such systems, good performance can only be reached at the price of collecting a lot of field data, which must be transcribed and annotated at the semantic level.", "labels": [], "entities": []}, {"text": "It becomes then possible to train efficient models in a supervised manner.", "labels": [], "entities": []}, {"text": "However, the annotation process is costly and as a consequence represents areal difficulty hindering the widespread development of these systems.", "labels": [], "entities": []}, {"text": "Therefore any means to avoid it would be profitable as portability to new tasks, domains or languages would be greatly facilitated.", "labels": [], "entities": []}, {"text": "To give a full description of the architecture of a dialogue system is out of the scope of this paper.", "labels": [], "entities": []}, {"text": "Instead we limit ourselves to briefly recall that once a speech recognizer has transcribed the signal it is common (though avoidable for very simple tasks) to use a module dedicated to extract the meaning of the user's queries.", "labels": [], "entities": []}, {"text": "This meaning representation is then conveyed to an interaction manager that decides upon the next best action to perform considering the current user's input and the dialogue history.", "labels": [], "entities": []}, {"text": "One of the very first steps to build the spoken language understanding (SLU) module is the identification of literal concepts in the word sequence hypothesised by the speech recogniser.", "labels": [], "entities": [{"text": "spoken language understanding (SLU)", "start_pos": 41, "end_pos": 76, "type": "TASK", "confidence": 0.7170094152291616}, {"text": "identification of literal concepts in the word sequence hypothesised by the speech recogniser", "start_pos": 91, "end_pos": 184, "type": "TASK", "confidence": 0.6861206797453073}]}, {"text": "An example of a semantic representation in terms of literal concept is given in.", "labels": [], "entities": []}, {"text": "Once the concepts are identified they can be further composed to form the overall meaning of the sentence, for instance by means of a tree representation based on hierarchical semantic frames.", "labels": [], "entities": []}, {"text": "To address the issue of concept tagging several techniques are available.", "labels": [], "entities": [{"text": "concept tagging", "start_pos": 24, "end_pos": 39, "type": "TASK", "confidence": 0.722163587808609}]}, {"text": "Some of these techniques now classical rely on probabilistic models, that can be either discriminative or generative.", "labels": [], "entities": []}, {"text": "Among these, the most efficiently studied this last decade are: hidden Markov models, finite state transducers, maximum entropy Markov models, support vector machines, dynamic fields (CRF).", "labels": [], "entities": []}, {"text": "In () it is shown that CRFs obtain the best performance on a tourist information retrieval task in French (ME-DIA (), but also in two other comparable corpora in Italian and Polish.", "labels": [], "entities": [{"text": "tourist information retrieval task", "start_pos": 61, "end_pos": 95, "type": "TASK", "confidence": 0.6638268679380417}, {"text": "ME-DIA", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.8472935557365417}]}, {"text": "To be able to apply any such technique, basic con-72 words concept normalized value donnez-moi null le refLink-coRef singular tarif object payment-amount-room puisque connectProp imply je voudrais null une chambre number-room 1 qui co\u00fbte object payment-amount-room pas plus de comparative-payment less than cinquante payment-amount-integer-room 50 euros payment-unit euro cept units have to be defined by an expert.", "labels": [], "entities": []}, {"text": "In the best case, most of these concepts can be derived straightforwardly from the pieces of information lurking in the database tables (mainly table fields but not exclusively).", "labels": [], "entities": []}, {"text": "Some others are general (dialogic units but also generic entities such as number, dates, etc).", "labels": [], "entities": []}, {"text": "However, to provide an efficient and usable information to the reasoning modules (the dialogue manager in our case) concepts have to be fine-grained enough and application-dependent (even general concepts might have to be tailored to peculiar uses).", "labels": [], "entities": []}, {"text": "To that extent it seems out of reach to derive the concept definitions using a fully automatic procedure.", "labels": [], "entities": []}, {"text": "Anyhow the process can be bootstrapped, for instance by induction of semantic classes such as in (Siu and Meng, 1999) or ().", "labels": [], "entities": []}, {"text": "Our assumption here is that the most time-consuming parts of concept inventory and data tagging could be obtained in an unsupervised way even though a final (but hopefully minimal) manual procedure is still required to tag the classes so as to manually correct automatic annotation.", "labels": [], "entities": [{"text": "data tagging", "start_pos": 83, "end_pos": 95, "type": "TASK", "confidence": 0.7430934309959412}]}, {"text": "Unlike the previous attempts cited above which developed ad hoc approaches, we investigate here the use of broad-spectrum knowledge extraction methods.", "labels": [], "entities": [{"text": "broad-spectrum knowledge extraction", "start_pos": 107, "end_pos": 142, "type": "TASK", "confidence": 0.6184537510077158}]}, {"text": "The notion most related to that of concept in SLU is the topic, as used in information retrieval systems.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.7475378811359406}]}, {"text": "Anyhow fora longtime, the topic detection task was limited to associate a single topic to a document and thus was not fitted to our requirements.", "labels": [], "entities": [{"text": "topic detection", "start_pos": 26, "end_pos": 41, "type": "TASK", "confidence": 0.898141622543335}]}, {"text": "The recently proposed LDA technique allows to have a probabilistic representation of a document as a mixture of topics.", "labels": [], "entities": []}, {"text": "Then multiple topics can co-occur inside a document and the same topic can be repeated.", "labels": [], "entities": []}, {"text": "From these characteristics it is possible to consider the application of LDA to unsupervised concept inventory and concept tagging for SLU.", "labels": [], "entities": [{"text": "concept tagging", "start_pos": 115, "end_pos": 130, "type": "TASK", "confidence": 0.7264556288719177}, {"text": "SLU", "start_pos": 135, "end_pos": 138, "type": "TASK", "confidence": 0.8578383326530457}]}, {"text": "A shortcoming is that LDA does not modelize at all the sequentiality of the data.", "labels": [], "entities": []}, {"text": "To address this issue we propose to conclude the procedure with a final step to introduce specific constraints fora correct segmentation of the data: the assignments of topics proposed by LDA are modified to be more segmentally coherent.", "labels": [], "entities": []}, {"text": "The paper is organised as follows.", "labels": [], "entities": []}, {"text": "Principles of automatic induction of semantic classes are presented in Section 2, followed by the presentation of an induction system based on LDA.", "labels": [], "entities": [{"text": "LDA", "start_pos": 143, "end_pos": 146, "type": "DATASET", "confidence": 0.843652069568634}]}, {"text": "The additional step of segmentation is presented in Section 3 with two variants: stochastic word alignment (GIZA) and integer linear programming (ILP).", "labels": [], "entities": [{"text": "segmentation", "start_pos": 23, "end_pos": 35, "type": "TASK", "confidence": 0.9705086350440979}, {"text": "stochastic word alignment", "start_pos": 81, "end_pos": 106, "type": "TASK", "confidence": 0.6035496592521667}]}, {"text": "Then evaluations and results are reported in Section 4 on the French MEDIA dialogue task.", "labels": [], "entities": [{"text": "French MEDIA dialogue task", "start_pos": 62, "end_pos": 88, "type": "DATASET", "confidence": 0.8914819657802582}]}], "datasetContent": [{"text": "Unlike previous studies, we chose a fully automatic way to evaluate the systems.", "labels": [], "entities": []}, {"text": "In (), a manual process is introduced to reject induced classes or rules that are not relevant to the task and also to name the semantic classes with the appropriate label.", "labels": [], "entities": []}, {"text": "Thus, they were able to evaluate their semi-supervised annotation on the ATIS corpus.", "labels": [], "entities": [{"text": "ATIS corpus", "start_pos": 73, "end_pos": 84, "type": "DATASET", "confidence": 0.9713161587715149}]}, {"text": "In (), the relevance of the generated semantic classes was manually evaluated giving a mark to each induced semantic rule.", "labels": [], "entities": []}, {"text": "To evaluate the unsupervised procedure it is necessary to associate each induced topic with a MEDIA concept.", "labels": [], "entities": []}, {"text": "To that purpose, the reference annotation is used to align topics with MEDIA concepts at the word level.", "labels": [], "entities": []}, {"text": "A co-occurrence matrix is computed and each topic is associated with its most co-occurring concept.", "labels": [], "entities": []}, {"text": "As MEDIA reference concepts are very finegrained, we also define a high-level concept hierarchy containing 18 clusters of concepts.", "labels": [], "entities": []}, {"text": "For example, a high-level concept payment is created from the 4 concepts payment-meansOfPayment, paymentcurrency, payment-total-amount, payment-approxamount; a high-level concept location corresponds to 12 concepts (location-country, location-district, location-street, . .", "labels": [], "entities": []}, {"text": "). Thus, two levels of concepts are considered for the evaluation: high-level and fine-level.", "labels": [], "entities": []}, {"text": "The evaluation is presented in terms of the classical F-measure, defined as a combination of precision and recall measures.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 54, "end_pos": 63, "type": "METRIC", "confidence": 0.9841093420982361}, {"text": "precision", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.9991174340248108}, {"text": "recall", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.9869333505630493}]}, {"text": "Two levels are also considered to measure topic assignment quality: \u2022 alignment corresponds to a full evaluation where each word is considered and associated with one topic; \u2022 generation corresponds to the set of topics generated fora turn (no order, no word-alignment).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Proportion of user utterances as a function of the  number of concepts in the utterance.", "labels": [], "entities": []}, {"text": " Table 2: Number of concepts according to their occur- rence range.", "labels": [], "entities": [{"text": "occur- rence range", "start_pos": 48, "end_pos": 66, "type": "METRIC", "confidence": 0.9287832081317902}]}, {"text": " Table 3: Examples of topics discovered by LDA (K = 100).", "labels": [], "entities": []}]}