{"title": [{"text": "Spoken Dialog Challenge 2010: Comparison of Live and Control Test Results", "labels": [], "entities": [{"text": "Spoken Dialog Challenge 2010", "start_pos": 0, "end_pos": 28, "type": "DATASET", "confidence": 0.6816000640392303}]}], "abstractContent": [{"text": "The Spoken Dialog Challenge 2010 was an exercise to investigate how different spoken dialog systems perform on the same task.", "labels": [], "entities": [{"text": "Spoken Dialog Challenge 2010", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.8366245031356812}]}, {"text": "The existing Let's Go Pittsburgh Bus Information System was used as a task and four teams provided systems that were first tested in controlled conditions with speech researchers as users.", "labels": [], "entities": [{"text": "Let's Go Pittsburgh Bus Information System", "start_pos": 13, "end_pos": 55, "type": "DATASET", "confidence": 0.7741722634860447}]}, {"text": "The three most stable systems were then deployed to real callers.", "labels": [], "entities": []}, {"text": "This paper presents the results of the live tests, and compares them with the control test results.", "labels": [], "entities": []}, {"text": "Results show considerable variation both between systems and between the control and live tests.", "labels": [], "entities": []}, {"text": "Interestingly , relatively high task completion for controlled tests did not always predict relatively high task completion for live tests.", "labels": [], "entities": []}, {"text": "Moreover, even though the systems were quite different in their designs, we saw very similar correlations between word error rate and task completion for all the systems.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 114, "end_pos": 129, "type": "METRIC", "confidence": 0.6551192800203959}]}, {"text": "The dialog data collected is available to the research community.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "The SDC2010 database of all logs from all systems including audio plus hand transcribed utterances, and hand defined success values is released through CMU's Dialog Research Center (http://dialrc.org).", "labels": [], "entities": [{"text": "SDC2010 database", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.8893185555934906}, {"text": "CMU's Dialog Research Center", "start_pos": 152, "end_pos": 180, "type": "DATASET", "confidence": 0.8362818360328674}]}, {"text": "One of the core goals of the Spoken Dialog Challenge is to not only create an opportunity for researchers to test their systems on a common platform with real users, but also create common data sets for testing evaluation metrics.", "labels": [], "entities": [{"text": "Spoken Dialog Challenge", "start_pos": 29, "end_pos": 52, "type": "TASK", "confidence": 0.7776317993799845}]}, {"text": "Although some work has been done on this for the control test data (e.g. [), we expect further evaluation techniques will be applied to these data.", "labels": [], "entities": []}, {"text": "One particular issue which arose during this evaluation concerned the difficulty of defining precisely what constitutes task success.", "labels": [], "entities": []}, {"text": "A precise definition is important to developers, especially if reinforcement style learning is being used to optimize the success.", "labels": [], "entities": []}, {"text": "In an information seeking task of the type described here, task success is straightforward when the user's requirements can be satisfied but more difficult if some form of constraint relaxation is required.", "labels": [], "entities": [{"text": "information seeking task", "start_pos": 6, "end_pos": 30, "type": "TASK", "confidence": 0.8007919192314148}]}, {"text": "For example, if the user asks if there is a bus from the current location to the airport -the answer \"No.\" maybe strictly correct but not necessarily helpful.", "labels": [], "entities": []}, {"text": "Should this dialogue be scored as successful or not?", "labels": [], "entities": []}, {"text": "The answer \"No, but there is a stop two blocks away where you can take the number 28X bus direct to the airport.\" is clearly more useful to the user.", "labels": [], "entities": []}, {"text": "Should success therefore be a numeric measure rather than a binary decision?", "labels": [], "entities": []}, {"text": "And if a measure, how can it be precisely defined?", "labels": [], "entities": []}, {"text": "A second and related issue is the need for evaluation algorithms which determine task success automatically.", "labels": [], "entities": []}, {"text": "Without these, system optimization will remain an art rather than a science.", "labels": [], "entities": [{"text": "system optimization", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.8173874318599701}]}], "tableCaptions": [{"text": " Table 1. Results of hand analysis of the four systems in  the control test", "labels": [], "entities": []}, {"text": " Table 2. Results of hand analysis of the three systems in  the live tests. Row labels are the same as in Table 1.", "labels": [], "entities": []}, {"text": " Table 3: For live tests, average length of each call, aver- age number of turns per call, and average number of  words per turn (numbers in brackets are standard devia- tions).", "labels": [], "entities": [{"text": "aver- age number", "start_pos": 55, "end_pos": 71, "type": "METRIC", "confidence": 0.8772358596324921}]}, {"text": " Table 4: Average dialogue word error rate (WER).", "labels": [], "entities": [{"text": "Average dialogue word error rate (WER)", "start_pos": 10, "end_pos": 48, "type": "METRIC", "confidence": 0.8620287887752056}]}]}