{"title": [{"text": "SampleRank Training for Phrase-Based Machine Translation", "labels": [], "entities": [{"text": "Phrase-Based Machine Translation", "start_pos": 24, "end_pos": 56, "type": "TASK", "confidence": 0.8060563405354818}]}], "abstractContent": [{"text": "Statistical machine translation systems are normally optimised fora chosen gain function (metric) by using MERT to find the best model weights.", "labels": [], "entities": [{"text": "Statistical machine translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6104146341482798}, {"text": "MERT", "start_pos": 107, "end_pos": 111, "type": "METRIC", "confidence": 0.9439721703529358}]}, {"text": "This algorithm suffers from stability problems and cannot scale beyond 20-30 features.", "labels": [], "entities": []}, {"text": "We present an alternative algorithm for discriminative training of phrase-based MT systems, SampleRank, which scales to hundreds of features, equals or beats MERT on both small and medium sized systems, and permits the use of sentence or document level features.", "labels": [], "entities": [{"text": "MT", "start_pos": 80, "end_pos": 82, "type": "TASK", "confidence": 0.8583824634552002}]}, {"text": "SampleRank proceeds by repeatedly updating the model weights to ensure that the ranking of output sentences induced by the model is the same as that induced by the gain function.", "labels": [], "entities": []}], "introductionContent": [{"text": "In phrase-based machine translation (PBMT), the standard approach is to express the probability distribution p(a, e|f ) (where f is the source sentence and (a, e) is the aligned target sentence) in terms of a linear model based on a small set of feature functions The feature functions {h i } typically include log probabilities of generative models such as translation, language and reordering, as well as nonprobabilistic features such as word, phrase and distortion penalties.", "labels": [], "entities": [{"text": "phrase-based machine translation (PBMT)", "start_pos": 3, "end_pos": 42, "type": "TASK", "confidence": 0.778529683748881}]}, {"text": "The feature weights w = {w i } are normally trained using MERT (minimum error rate training), to maximise performance as measured by an automated metric such as BLEU ().", "labels": [], "entities": [{"text": "MERT", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9907181859016418}, {"text": "minimum error rate training", "start_pos": 64, "end_pos": 91, "type": "METRIC", "confidence": 0.740078940987587}, {"text": "BLEU", "start_pos": 161, "end_pos": 165, "type": "METRIC", "confidence": 0.9954023361206055}]}, {"text": "MERT training uses a parallel data set (known as the tuning set) consisting of about 1000-2000 sentences, distinct from the data set used to build the generative models.", "labels": [], "entities": [{"text": "MERT training", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8567425608634949}]}, {"text": "Optimising the weights in Equation is often referred to as tuning the MT system, to differentiate it from the process of training the generative models.", "labels": [], "entities": [{"text": "MT", "start_pos": 70, "end_pos": 72, "type": "TASK", "confidence": 0.756926417350769}]}, {"text": "MERT's inability to scale beyond 20-30 features, as well as its instability have led to investigation into alternative ways of tuning MT systems.", "labels": [], "entities": [{"text": "MERT", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7548906803131104}, {"text": "MT", "start_pos": 134, "end_pos": 136, "type": "TASK", "confidence": 0.9457868337631226}]}, {"text": "The development of tuning methods is complicated, however by, the use of BLEU as an objective function.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.9974937438964844}]}, {"text": "This objective in its usual form is not differentiable, and has a highly non-convex error surface.", "labels": [], "entities": []}, {"text": "Furthermore BLEU is evaluated at the corpus level rather than at the sentence level, so tuning methods either have to consider the entire corpus, or resort to a sentencelevel approximation of BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.9973347187042236}, {"text": "BLEU", "start_pos": 192, "end_pos": 196, "type": "METRIC", "confidence": 0.9921572208404541}]}, {"text": "It is unlikely, however, that the difficulties in discriminative MT tuning are due solely to the use of BLEU as a metricbecause evaluation of translation is so difficult, any reasonable gain function is likely to have a complex relationship with the model parameters.", "labels": [], "entities": [{"text": "MT tuning", "start_pos": 65, "end_pos": 74, "type": "TASK", "confidence": 0.9459961354732513}, {"text": "BLEU", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.9975264668464661}]}, {"text": "Gradient-based tuning methods, such as minimum risk training, have been investigated as possible alternatives to MERT.", "labels": [], "entities": [{"text": "MERT", "start_pos": 113, "end_pos": 117, "type": "TASK", "confidence": 0.7446496486663818}]}, {"text": "Expected BLEU is normally adopted as the objective since it is differentiable and so can be optimised by a form of stochastic gradient ascent.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.9232631921768188}]}, {"text": "The feature expectations required for the gradient calculation can be obtained from n-best lists or lattices (;, or using sampling (, both of which can be computationally expensive.", "labels": [], "entities": []}, {"text": "Margin-based techniques such as perceptron training () and MIRA ( have also been shown to be able to tune MT systems and scale to large numbers of features, but these generally involve repeatedly decoding the tuning set (and so are expensive) and require sentence-level approximations to the BLEU objective.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.9526267051696777}, {"text": "MT", "start_pos": 106, "end_pos": 108, "type": "TASK", "confidence": 0.9645837545394897}, {"text": "BLEU", "start_pos": 292, "end_pos": 296, "type": "METRIC", "confidence": 0.9963181018829346}]}, {"text": "In this paper we present an alternative method of tuning MT systems known as SampleRank, which has certain advantages over other methods in use today.", "labels": [], "entities": [{"text": "MT", "start_pos": 57, "end_pos": 59, "type": "TASK", "confidence": 0.8590692281723022}]}, {"text": "SampleRank operates by repeatedly sampling pairs of translation hypotheses (for a given source sentence) and updating the feature weights if the ranking induced by the MT model (1) is different from the ranking induced by the gain function (i.e. BLEU).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 246, "end_pos": 250, "type": "METRIC", "confidence": 0.9975898265838623}]}, {"text": "By considering the translation hypotheses in batches, it is possible to directly optimise corpus level metrics like BLEU without resorting to sentence level approximations.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 116, "end_pos": 120, "type": "METRIC", "confidence": 0.9870184659957886}]}, {"text": "Tuning using SampleRank does not limit the size of the feature set in the same way as MERT does, and indeed it will be shown that SampleRank can successfully train a model with several hundred features.", "labels": [], "entities": []}, {"text": "Using just the core PBMT features and training using SampleRank will be shown to achieve BLEU scores which equal or exceed those produced by MERT trained models.", "labels": [], "entities": [{"text": "SampleRank", "start_pos": 53, "end_pos": 63, "type": "DATASET", "confidence": 0.8603881597518921}, {"text": "BLEU", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.9994210004806519}]}, {"text": "Since SampleRank does not require repeated decoding of the tuning set, and is easily parallelisable, it can run at an acceptable speed, and since it always maintains a complete translation hypothesis, it opens up the possibility of sentence or document level features 1 .", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Untrained and MERT-trained performance  on heldout. MERT training is repeated five times,  with the table showing the mean BLEU, and standard  deviation in brackets.", "labels": [], "entities": [{"text": "MERT-trained", "start_pos": 24, "end_pos": 36, "type": "METRIC", "confidence": 0.8790664672851562}, {"text": "MERT", "start_pos": 62, "end_pos": 66, "type": "TASK", "confidence": 0.6047935485839844}, {"text": "BLEU", "start_pos": 133, "end_pos": 137, "type": "METRIC", "confidence": 0.9836528301239014}]}, {"text": " Table 2: Mean maximum heldout performance for  SampleRank training of the French-English WMT- SMALL model. Standard deviations are shown in  brackets.", "labels": [], "entities": [{"text": "French-English WMT- SMALL model", "start_pos": 75, "end_pos": 106, "type": "DATASET", "confidence": 0.715294349193573}]}, {"text": " Table 3: Mean maximum heldout performance for  SampleRank training of the German-English WMT- SMALL model. Standard deviations are shown in  brackets", "labels": [], "entities": [{"text": "WMT- SMALL", "start_pos": 90, "end_pos": 100, "type": "TASK", "confidence": 0.47175537546475727}]}, {"text": " Table 4: Mean (and standard deviation) of maximum  heldout performance for SampleRank training of the  WMT-LARGE model.", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9979016780853271}, {"text": "WMT-LARGE", "start_pos": 104, "end_pos": 113, "type": "DATASET", "confidence": 0.6372812390327454}]}, {"text": " Table 5: Mean (and standard deviation) of maximum  heldout performance for SampleRank training of the  WMT-SMALL model, with the phrase boundary fea- ture.", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9961671233177185}, {"text": "WMT-SMALL", "start_pos": 104, "end_pos": 113, "type": "DATASET", "confidence": 0.6839994192123413}]}]}