{"title": [{"text": "Instance Level Transfer Learning for Cross Lingual Opinion Analysis", "labels": [], "entities": [{"text": "Instance Level Transfer", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.8598304390907288}, {"text": "Cross Lingual Opinion Analysis", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.7514421343803406}]}], "abstractContent": [{"text": "This paper presents two instance-level transfer learning based algorithms for cross lingual opinion analysis by transferring useful translated opinion examples from other languages as the supplementary training data for improving the opinion classifier in target language.", "labels": [], "entities": [{"text": "cross lingual opinion analysis", "start_pos": 78, "end_pos": 108, "type": "TASK", "confidence": 0.7449125498533249}]}, {"text": "Starting from the union of small training data in target language and large translated examples in other languages, the Transfer AdaBoost algorithm is applied to iteratively reduce the influence of low quality translated examples.", "labels": [], "entities": []}, {"text": "Alternatively, starting only from the training data in target language, the Transfer Self-training algorithm is designed to iteratively select high quality translated examples to enrich the training data set.", "labels": [], "entities": []}, {"text": "These two algorithms are applied to sentence-and document-level cross lingual opinion analysis tasks, respectively.", "labels": [], "entities": [{"text": "sentence-and document-level cross lingual opinion analysis tasks", "start_pos": 36, "end_pos": 100, "type": "TASK", "confidence": 0.6211297341755458}]}, {"text": "The evaluations show that these algorithms effectively improve the opinion analysis by exploiting small target language training data and large cross lingual training data.", "labels": [], "entities": [{"text": "opinion analysis", "start_pos": 67, "end_pos": 83, "type": "TASK", "confidence": 0.7679339945316315}]}], "introductionContent": [{"text": "In recent years, with the popularity of Web 2.0, massive amount of personal opinions including comments, reviews and recommendations in different languages have been shared on the Internet.", "labels": [], "entities": []}, {"text": "Accordingly, automated opinion analysis has attracted growing attentions.", "labels": [], "entities": [{"text": "automated opinion analysis", "start_pos": 13, "end_pos": 39, "type": "TASK", "confidence": 0.6439309517542521}]}, {"text": "Opinion analysis, also known as sentiment analysis, sentiment classification, and opinion mining, aims to identify opinions in text and classify their sentiment polarity).", "labels": [], "entities": [{"text": "Opinion analysis", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7850978374481201}, {"text": "sentiment analysis", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.9363783001899719}, {"text": "sentiment classification", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.8694391250610352}, {"text": "opinion mining", "start_pos": 82, "end_pos": 96, "type": "TASK", "confidence": 0.7200433909893036}]}, {"text": "Many sentiment resources such as sentiment lexicons (e.g.,))and opinion corpora (e.g., MPQA)) have been developed on different languages in which most of them are for English.", "labels": [], "entities": []}, {"text": "The lack of reliably sentiment resources is one of the core issues in opinion analysis for other languages.", "labels": [], "entities": [{"text": "opinion analysis", "start_pos": 70, "end_pos": 86, "type": "TASK", "confidence": 0.7659033238887787}]}, {"text": "Meanwhile, the manually annotation is costly, thus the amount of available annotated opinion corpora are still insufficient for supporting supervised learning, even for English.", "labels": [], "entities": []}, {"text": "These facts motivate to \"borrow\" the opinion resources in one language (source language, SL) to another language (target language, TL) for improving the opinion analysis on the target language.", "labels": [], "entities": []}, {"text": "Cross lingual opinion analysis (CLOA) techniques are investigated to improve opinion analysis in TL through leveraging the opinion-related resources, such as dictionaries and annotated corpus in SL.", "labels": [], "entities": [{"text": "Cross lingual opinion analysis (CLOA)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7498293135847364}, {"text": "opinion analysis", "start_pos": 77, "end_pos": 93, "type": "TASK", "confidence": 0.7792964577674866}]}, {"text": "Some CLOA works used bilingual dictionaries (, or aligned corpus () to align the expressions between source and target languages.", "labels": [], "entities": []}, {"text": "These works are puzzled by the limited aligned opinion resources.", "labels": [], "entities": []}, {"text": "Alternatively, some works used machine translation system to do the opinion expression alignment.", "labels": [], "entities": [{"text": "opinion expression alignment", "start_pos": 68, "end_pos": 96, "type": "TASK", "confidence": 0.7078239719072977}]}, {"text": "proposed several approaches for cross lingual subjectivity analysis by directly applying the translations of opinion corpus in source language to train the opinion classifier on target language.", "labels": [], "entities": [{"text": "cross lingual subjectivity analysis", "start_pos": 32, "end_pos": 67, "type": "TASK", "confidence": 0.7841279953718185}]}, {"text": "combined the annotated English reviews, unannotated Chinese reviews and their translations to co-train two separate classifiers for each language, respectively.", "labels": [], "entities": []}, {"text": "These works directly used all of the translation of annotated corpus in source language as the training data for target language without considering the following two problems: (1) the machine translation errors propagate to following CLOA procedure; (2) The annotated corpora from different languages are collected from different domains and different writing styles which lead the training and testing data having different feature spaces and distributions.", "labels": [], "entities": []}, {"text": "Therefore, the performances of these supervised learning algorithms are affected.", "labels": [], "entities": []}, {"text": "To address these problems, we propose two instance level transfer learning based algorithms to estimate the confidence of translated SL examples and to transfer the promising ones as the supplementary TL training data.", "labels": [], "entities": []}, {"text": "We firstly apply Transfer AdaBoost (TrAdaBoost) to improve the overall performance with the union of target and translated source language training corpus.", "labels": [], "entities": []}, {"text": "A boosting-like strategy is used to down-weight the wrongly classified translated examples during iterative training procedure.", "labels": [], "entities": []}, {"text": "This method aims to reduce the negative affection of low quality translated examples.", "labels": [], "entities": []}, {"text": "Secondly, we propose anew Transfer Self-training algorithm (TrStr).", "labels": [], "entities": [{"text": "TrStr", "start_pos": 60, "end_pos": 65, "type": "METRIC", "confidence": 0.8206048607826233}]}, {"text": "This algorithm trains the classifier by using only the target language training data at the beginning.", "labels": [], "entities": []}, {"text": "By automatically labeling and selecting the translated examples which is correct classified with higher confidence, the classifier is iteratively trained by appending new selected training examples.", "labels": [], "entities": []}, {"text": "The training procedure is terminated until no new promising examples can be selected.", "labels": [], "entities": []}, {"text": "Different from TrAdaBoost, TrStr aims to select high quality translated examples for classifier training.", "labels": [], "entities": []}, {"text": "These algorithms are evaluated on sentence-and document-level CLOA tasks, respectively.", "labels": [], "entities": []}, {"text": "The evaluations on simplified Chinese (SC) opinion analysis by using small SC training data and large traditional Chinese (TC) and English (EN) training data, respectively, show that the proposed transfer learning based algorithms effectively improve the CLOA.", "labels": [], "entities": []}, {"text": "Noted that, these algorithms are applicable to different language pairs.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the transfer learning based approaches for opinion analysis.", "labels": [], "entities": [{"text": "opinion analysis", "start_pos": 63, "end_pos": 79, "type": "TASK", "confidence": 0.9347856342792511}]}, {"text": "Evaluations and discussions are presented in Section 3.", "labels": [], "entities": []}, {"text": "Finally, Section 4 gives the conclusions and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The proposed approaches are evaluated on sentenceand document-level opinion analysis tasks in the bi-lingual case, respectively.", "labels": [], "entities": []}, {"text": "In our experiments, the TL is simplified Chinese (SC) and the SL for the two experiments are English (EN)/traditional Chinese (TC) and EN, respectively.", "labels": [], "entities": []}, {"text": "In the sentence-level opinionated sentence recognition experiment , the dataset is from the NTCIR-7 Multilingual Opinion Analysis Tasks (MOAT) (Seki et al., 2008) corpora.", "labels": [], "entities": [{"text": "sentence-level opinionated sentence recognition", "start_pos": 7, "end_pos": 54, "type": "TASK", "confidence": 0.6115091517567635}, {"text": "NTCIR-7 Multilingual Opinion Analysis Tasks (MOAT) (Seki et al., 2008) corpora", "start_pos": 92, "end_pos": 170, "type": "DATASET", "confidence": 0.5723920855671167}]}, {"text": "The information of this dataset is given in.", "labels": [], "entities": []}, {"text": "The first one is denoted by SenOR : T C \u2192 SC, which uses T C s as source language training dataset, while the second one In the document-level review polarity classification experiment,, we used the dataset adopted in.", "labels": [], "entities": [{"text": "SenOR", "start_pos": 28, "end_pos": 33, "type": "METRIC", "confidence": 0.9000646471977234}, {"text": "document-level review polarity classification", "start_pos": 128, "end_pos": 173, "type": "TASK", "confidence": 0.6081158965826035}]}, {"text": "Its English subset is collected by, which contains a collection of 8,000 product reviews about four types of products: books, DVDs, electronics and kitchen appliances.", "labels": [], "entities": []}, {"text": "For each type of products, there are 1,000 positive reviews and 1,000 negative ones, respectively.", "labels": [], "entities": []}, {"text": "The Chinese subset has 451 positive reviews and 435 negative reviews of electronics products such as mp3 players, mobile phones etc.", "labels": [], "entities": [{"text": "Chinese subset", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.8524528443813324}]}, {"text": "In our experiments, the Chinese subset is further split into two parts randomly: TL training dataset and test set.", "labels": [], "entities": [{"text": "TL training dataset", "start_pos": 81, "end_pos": 100, "type": "DATASET", "confidence": 0.5827379922072092}]}, {"text": "The cross lingual review polarity classification task is then denoted by DocSC: EN\u2192SC.", "labels": [], "entities": [{"text": "cross lingual review polarity classification task", "start_pos": 4, "end_pos": 53, "type": "TASK", "confidence": 0.693499743938446}, {"text": "DocSC", "start_pos": 73, "end_pos": 78, "type": "DATASET", "confidence": 0.821837842464447}]}, {"text": "In this study, Google Translate 3 is choose for providing machine translation results.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 58, "end_pos": 77, "type": "TASK", "confidence": 0.7533086836338043}]}, {"text": "Accuracy (Acc), precision (P), recall (R) and Fmeasure (F1) are used as evaluation metrics.", "labels": [], "entities": [{"text": "Accuracy (Acc)", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.9324887245893478}, {"text": "precision (P)", "start_pos": 16, "end_pos": 29, "type": "METRIC", "confidence": 0.944019228219986}, {"text": "recall (R)", "start_pos": 31, "end_pos": 41, "type": "METRIC", "confidence": 0.9560968279838562}, {"text": "Fmeasure (F1)", "start_pos": 46, "end_pos": 59, "type": "METRIC", "confidence": 0.9401752799749374}]}, {"text": "All the performances are the average of 10 experiments.", "labels": [], "entities": []}, {"text": "Here, the number of iterations in TrAdaBoost is set to 10 in order to avoid over-discarding SL examples.", "labels": [], "entities": [{"text": "TrAdaBoost", "start_pos": 34, "end_pos": 44, "type": "DATASET", "confidence": 0.8227667212486267}]}], "tableCaptions": [{"text": " Table 1: The NTCIR-7 MOAT Corpora(unit:sentence).", "labels": [], "entities": [{"text": "NTCIR-7 MOAT Corpora", "start_pos": 14, "end_pos": 34, "type": "DATASET", "confidence": 0.8105498353640238}]}, {"text": " Table 2: The Performance of Opinionated Sentence Recognition Task.", "labels": [], "entities": [{"text": "Sentence Recognition", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.8621006906032562}]}, {"text": " Table 3: The Results of Chinese Review Polarity Classi- fication Task (Features:Unigrams; m=20).", "labels": [], "entities": [{"text": "Chinese Review Polarity Classi- fication", "start_pos": 25, "end_pos": 65, "type": "DATASET", "confidence": 0.886900395154953}]}, {"text": " Table 4: The Results of Chinese Review Polarity Classi- fication Task (Features:Unigrams+Bigrams; m=20).", "labels": [], "entities": [{"text": "Chinese Review Polarity Classi- fication", "start_pos": 25, "end_pos": 65, "type": "DATASET", "confidence": 0.8792107204596201}]}]}