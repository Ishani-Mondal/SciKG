{"title": [{"text": "The Impact of Visual Context on the Content of Referring Expressions", "labels": [], "entities": [{"text": "Content of Referring Expressions", "start_pos": 36, "end_pos": 68, "type": "TASK", "confidence": 0.6624402850866318}]}], "abstractContent": [{"text": "Traditional approaches to referring expression generation (REG) have taken as a fundamental requirement the need to distinguish the intended referent from other entities in the context.", "labels": [], "entities": [{"text": "referring expression generation (REG)", "start_pos": 26, "end_pos": 63, "type": "TASK", "confidence": 0.8928265770276388}]}, {"text": "It seems obvious that this should be a necessary condition for successful reference; but we suggest that a number of recent investigations cast doubt on the significance of this aspect of reference.", "labels": [], "entities": [{"text": "reference", "start_pos": 74, "end_pos": 83, "type": "TASK", "confidence": 0.9676703214645386}]}, {"text": "In the present paper, we look at the role of visual context in determining the content of a referring expression, and come to the conclusion that, at least in the referential scenarios underlying our data, visual context appears not to be a major factor in content determination for reference.", "labels": [], "entities": []}, {"text": "We discuss the implications of this surprising finding.", "labels": [], "entities": []}], "introductionContent": [{"text": "Traditional approaches to referring expression generation are based on the idea of distinguishing the intended referent from the other entities in the context ().", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.8879799246788025}]}, {"text": "The task is generally characterised as involving the construction of a distinguishing description consisting of those attributes of the intended referent that distinguish it from the other entities with which it might be confused; building a referring expression thus requires us to have an appropriate formalisation of the notion of context.", "labels": [], "entities": []}, {"text": "Earlier work (for example,) took its cue from work on discourse structure (in particular, (), and defined the context in terms of the set of discourseaccessible referents; more recent work has tended to focus on visual scenes (for example,;), with the context being defined as the set of all the objects in the scene.", "labels": [], "entities": []}, {"text": "Most of the early approaches to REG were proposed without the support of rigorous empirical testing.", "labels": [], "entities": [{"text": "REG", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.9933034777641296}]}, {"text": "Probably the most fundamental shift in the field in the last five years has been the move towards the development of algorithms that attempt to replicate corpora of human-produced referring expressions.", "labels": [], "entities": []}, {"text": "This work has only really become possible with the advent of a number of publicly-available corpora of human-produced referring expressions collected under controlled circumstances: these include the TUNA Corpus (van der), the Drawer Corpus (), and the GRE3D3 and GRE3D7).", "labels": [], "entities": [{"text": "TUNA Corpus", "start_pos": 200, "end_pos": 211, "type": "DATASET", "confidence": 0.9270804226398468}, {"text": "Drawer Corpus", "start_pos": 227, "end_pos": 240, "type": "DATASET", "confidence": 0.7727082371711731}, {"text": "GRE3D3", "start_pos": 253, "end_pos": 259, "type": "DATASET", "confidence": 0.9042762517929077}, {"text": "GRE3D7", "start_pos": 264, "end_pos": 270, "type": "DATASET", "confidence": 0.8283036351203918}]}, {"text": "All of these corpora contain descriptions of target referents using a small number of attributes in simple visual scenes containing only a very small number of distractor objects.", "labels": [], "entities": []}, {"text": "The descriptions in all these cases were elicited in isolation, with no preceding discourse: the reference task they represent has sometimes been called 'one-shot reference'.", "labels": [], "entities": []}, {"text": "So there is no discourse context that provides a set of potential distractors, but there is a visual context of potential distractors.", "labels": [], "entities": []}, {"text": "The idea that the process of constructing a reference to an object in a visual scene needs to take account of the other entities in that scene in order to ensure that the reference is successful seems so obvious that it might bethought ridiculous to doubt it.", "labels": [], "entities": []}, {"text": "However, our exploration of a dataset that contains referring expressions for objects in visual scenes of somewhat greater complexity and involving dialogic discourse calls this fundamental assumption into question.", "labels": [], "entities": []}, {"text": "In ), we presented a machinelearning approach to REG, and distinguished two main kinds of features that might play a role in subsequent reference: 'traditional' REG features, which are concerned with distinguishing the intended referent from visual and discourse distractors; and 'alignment' features, representing aspects of the discourse history).", "labels": [], "entities": [{"text": "REG", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.974711537361145}]}, {"text": "We used feature ablation in a decision tree approach to investigate the role of the traditional features, and found that the impact of these features was negligible compared to that of the alignment features.", "labels": [], "entities": []}, {"text": "The bad performance of these features caused us to ask whether the method of determining the visual distractors that were taken into account was to be blamed.", "labels": [], "entities": []}, {"text": "In the present paper, we explore this question by trying out two different ways of determining the set of visual distractors and by varying the size of this set.", "labels": [], "entities": []}, {"text": "In Section 2 we provide some background by situating the investigation presented herewith respect to the literature.", "labels": [], "entities": []}, {"text": "In Section 3, we describe the corpus we work with, and in Section 4, we describe our machine-learning framework for exploring the data this corpus provides.", "labels": [], "entities": []}, {"text": "In Section 5, we present the results of some experiments that attempt to determine the role of visual context in REG, and in Section 6 we draw some conclusions.", "labels": [], "entities": [{"text": "REG", "start_pos": 113, "end_pos": 116, "type": "TASK", "confidence": 0.9688768982887268}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The 15 different content patterns that occur in our data  and their frequencies.", "labels": [], "entities": []}, {"text": " Table 5: Ablation of Discourse and Visual TradREG features  using average-6 to determine the visual context. Performance  is measured in percentage of perfect matches. Numbers in ital- ics were prevously reported in (Viethen et al., 2011).", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9802086353302002}]}, {"text": " Table 6: Sizes of the training and test sets for the different map  types.", "labels": [], "entities": []}, {"text": " Table 7: Maximum possible Accuracy using all features  achieved by choosing the best performing visual context by the  count method for each map type, compared to the performance  of the average-6 visual contexts.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9920355677604675}]}, {"text": " Table 8: Maximum possible Accuracy using all features  achieved by choosing the best performing visual context by the  distance method for each map type, compared to the perfor- mance of the average-6 visual contexts.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9900293946266174}]}]}