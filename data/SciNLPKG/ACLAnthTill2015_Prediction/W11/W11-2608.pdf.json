{"title": [{"text": "Phone set selection for HMM-based dialect speech synthesis", "labels": [], "entities": [{"text": "HMM-based dialect speech synthesis", "start_pos": 24, "end_pos": 58, "type": "TASK", "confidence": 0.8733906000852585}]}], "abstractContent": [{"text": "This paper describes a method for selecting an appropriate phone set in dialect speech synthesis fora so far undescribed dialect by applying hidden Markov model (HMM) based training and clustering methods.", "labels": [], "entities": [{"text": "dialect speech synthesis", "start_pos": 72, "end_pos": 96, "type": "TASK", "confidence": 0.7073472738265991}]}, {"text": "In this pilot study we show how a phone set derived from the pho-netic surface can be optimized given a small amount of dialect speech training data.", "labels": [], "entities": []}], "introductionContent": [{"text": "In acoustic modeling for dialect speech synthesis we are confronted with two closely related major problems 1 , (1) to find an appropriate phone set for synthesis and (2) to design a recording script with sufficient phonetic and prosodic coverage.", "labels": [], "entities": [{"text": "dialect speech synthesis", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.626990964015325}]}, {"text": "In HMMbased synthesis, we can use the training process of the voices itself to analyze the used phone set and to try to optimize it for synthesis.", "labels": [], "entities": [{"text": "HMMbased synthesis", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.7289518415927887}]}], "datasetContent": [{"text": "After the analysis of the voice that was trained with our basic phoneset PS1 we defined two new phonesets PS2 and PS3.", "labels": [], "entities": []}, {"text": "These phonesets were used to train additional voice models for the same speaker.", "labels": [], "entities": []}, {"text": "With these voice models, we synthesized our small set of 5 test sentences.", "labels": [], "entities": []}, {"text": "To evaluate the suitability of the phonesets for the training data, we resynthesized the training corpus of 145 prompts.", "labels": [], "entities": []}, {"text": "Ina pair-wise comparison test of the 150 prompts we evaluated the three voice models in a subjective listening test with three expert listeners.", "labels": [], "entities": []}, {"text": "The experts listened to a set of prompts, each prompt synthesized with two different voice models.", "labels": [], "entities": []}, {"text": "They were asked to compare them and to decide which prompt they would prefer in terms of overall quality, or whether they would rate them as \"equally good\".", "labels": [], "entities": []}, {"text": "PS1 PS2 PS3 56 102 105 illustrates that both approaches to reduce and redefine the phoneset (PS2, PS3) improved the overall quality estimation considerably compared to the initial phoneset PS1.", "labels": [], "entities": [{"text": "PS1 PS2 PS3 56 102 105", "start_pos": 0, "end_pos": 22, "type": "DATASET", "confidence": 0.8924170434474945}]}], "tableCaptions": [{"text": " Table 2: Vowels (33) and diphtongs (12) in phone set PS1  for training (72 phones) (Blue = not in PS2, Red = not in  PS2 and PS3, green = not in PS3).", "labels": [], "entities": [{"text": "Vowels", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.976450502872467}, {"text": "diphtongs", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9355626106262207}]}, {"text": " Table 3: Number of models and questions in mel- cepstrum, aperiodicity, F0, and duration model for central  HMM state.", "labels": [], "entities": [{"text": "F0", "start_pos": 73, "end_pos": 75, "type": "METRIC", "confidence": 0.9977255463600159}, {"text": "duration", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9950754046440125}]}]}