{"title": [{"text": "ETS: An Error Tolerable System for Coreference Resolution", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.978392481803894}]}], "abstractContent": [{"text": "This paper presents our error tolerable system for coreference resolution in CoNLL-2011(Pradhan et al., 2011) shared task (closed track).", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.9842939972877502}, {"text": "CoNLL-2011", "start_pos": 77, "end_pos": 87, "type": "DATASET", "confidence": 0.9077870845794678}]}, {"text": "Different from most previous reported work, we detect mention candidates based on packed forest instead of single parse tree, and we use beam search algorithm based on the Bell Tree to create entities.", "labels": [], "entities": [{"text": "Bell Tree", "start_pos": 172, "end_pos": 181, "type": "DATASET", "confidence": 0.8445002734661102}]}, {"text": "Experimental results show that our methods achieve promising results on the development set.", "labels": [], "entities": []}], "introductionContent": [{"text": "Over last decades, there has been increasing interest on coreference resolution within NLP community.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.9734942018985748}]}, {"text": "The task of coreference resolution is to identify expressions in a text that refer to the same discourse entity.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.9639565050601959}]}, {"text": "This year, CoNLL 1 holds a shared task aiming to model unrestricted coreference in OntoNotes.", "labels": [], "entities": []}, {"text": "The OntoNotes project has created a large-scale, accurate corpus for general anaphoric coreference that covers entities and events not limited to noun phrases or a limited set of entity types.", "labels": [], "entities": [{"text": "general anaphoric coreference", "start_pos": 69, "end_pos": 98, "type": "TASK", "confidence": 0.6810078422228495}]}, {"text": "And have ever used this corpus for similar unrestricted coreference task.", "labels": [], "entities": []}, {"text": "Our approach to this year's task could be divided into two steps: mention identification and creation of entities.", "labels": [], "entities": []}, {"text": "The first stage is conducted on the analysis of parse trees produced by input data.", "labels": [], "entities": []}, {"text": "The official data have provided gold and automatic parse trees for each sentences in training and development http://conll.bbn.com/ 2 http://www.bbn.com/ontonotes/ set.", "labels": [], "entities": []}, {"text": "However, according to statistics, almost 3% mentions have no corresponding constituents in automatic parse trees.", "labels": [], "entities": []}, {"text": "Since only automatic parse trees will be provided in the final test set, the effect of parsing errors are inevitable.", "labels": [], "entities": []}, {"text": "To alleviate this issue, based on given automatic parse trees, we modify a state-of-the-art parser) to generate packed forest, and determine mention candidates among all constituents from both given parse tree and packed forest.", "labels": [], "entities": []}, {"text": "The packed forest is a compact representation of all parse trees fora given sentence.", "labels": [], "entities": []}, {"text": "Readers can refer to () for detailed definitions.", "labels": [], "entities": []}, {"text": "Once the mentions are identified, the left step is to group mentions referring to same object into similar entity.", "labels": [], "entities": []}, {"text": "This problem can be viewed as binary classification problem of determining whether each mention pairs corefer.", "labels": [], "entities": [{"text": "binary classification", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.599469006061554}]}, {"text": "We use a Maximum Entropy classifier to predict the possibility that two mentions refer to the similar entity.", "labels": [], "entities": []}, {"text": "And mainly following the work of, we use abeam search algorithm based on Bell Tree to obtain the global optimal classification.", "labels": [], "entities": [{"text": "Bell Tree", "start_pos": 73, "end_pos": 82, "type": "DATASET", "confidence": 0.9676159918308258}]}, {"text": "As this is the first time we participate competition of coreference resolution, we mainly concentrate on developing fault tolerant capability of our system while omitting feature engineering and other helpful technologies.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 56, "end_pos": 78, "type": "TASK", "confidence": 0.964850515127182}]}], "datasetContent": [{"text": "We first implement a baseline system (baseline) that use single parse tree for mention detection and greedy algorithm for creation of entities.", "labels": [], "entities": [{"text": "mention detection", "start_pos": 79, "end_pos": 96, "type": "TASK", "confidence": 0.7164654284715652}]}, {"text": "We also run the baseline system using gold parse tree, namely baseline gold.", "labels": [], "entities": []}, {"text": "To investigate the contribution of packed forest, we design a reinforced system, namely sys forest.", "labels": [], "entities": []}, {"text": "And another system, named as sys btree, is used to seethe contribution of beam search with beam size k=10.", "labels": [], "entities": [{"text": "beam search", "start_pos": 74, "end_pos": 85, "type": "TASK", "confidence": 0.7843396663665771}]}, {"text": "Lastly, we combine two technologies and obtain system sys forest btree.", "labels": [], "entities": []}, {"text": "shows the experimental results on development data.", "labels": [], "entities": []}, {"text": "We find that the system using beam search achieve promising improvement over baseline.", "labels": [], "entities": [{"text": "beam search", "start_pos": 30, "end_pos": 41, "type": "TASK", "confidence": 0.8213575184345245}]}, {"text": "The reason for that has been discussed in last section.", "labels": [], "entities": []}, {"text": "We also find that compared to baseline, sys forest and baseline gold both achieve improvement in term of some metrics.", "labels": [], "entities": []}, {"text": "And we are glad to find that using forest, the performance of our system is approaching the system based on gold parse tree.", "labels": [], "entities": []}, {"text": "But even using the gold parse tree, the improvement is slight.", "labels": [], "entities": [{"text": "gold parse tree", "start_pos": 19, "end_pos": 34, "type": "DATASET", "confidence": 0.6768610874811808}]}, {"text": "One reason is that we used some lexical and grammar features which are dom-inant during prediction, and another explanation is that packed forest enlarges the size of mentions but brings difficulty to resolve them.", "labels": [], "entities": []}, {"text": "To investigate the effect of different genres to develop set, we also perform following compared experiments: \u2022 sys1: all training corpus + WSJ development corpus \u2022 sys2: WSJ training corpus + WSJ development corpus indicates that knowledge from other genres can help coreference resolution.", "labels": [], "entities": [{"text": "WSJ development corpus", "start_pos": 140, "end_pos": 162, "type": "DATASET", "confidence": 0.8076070149739584}, {"text": "WSJ training corpus", "start_pos": 171, "end_pos": 190, "type": "DATASET", "confidence": 0.6862701376279196}, {"text": "WSJ development corpus", "start_pos": 193, "end_pos": 215, "type": "DATASET", "confidence": 0.7539746761322021}, {"text": "coreference resolution", "start_pos": 268, "end_pos": 290, "type": "TASK", "confidence": 0.9819896519184113}]}, {"text": "Perhaps the reason is the same as last experiments, where syntax diversity affects the task not very seriously.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experimental results on development set (F score).", "labels": [], "entities": [{"text": "F score)", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9464277029037476}]}, {"text": " Table 2: Experimental results on development set with different training division (F score).", "labels": [], "entities": [{"text": "F score)", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.978236714998881}]}]}