{"title": [{"text": "Sense-level Subjectivity in a Multilingual Setting", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper explores the ability of senses aligned across languages to carry coherent subjectivity information.", "labels": [], "entities": []}, {"text": "We start outwith a manual annotation study, and then seek to create an automatic framework to determine subjectivity labeling for unseen senses.", "labels": [], "entities": []}, {"text": "We identify two methods that are able to incorporate subjectivity information originating from different languages, namely co-training and multilingual vector spaces, and show that for this task the latter method is better suited and obtains superior results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Following the terminology proposed by ), subjectivity and sentiment analysis focuses on the automatic identification of private states (opinions, emotions, sentiments, etc.) in natural language.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.7719733119010925}, {"text": "identification of private states (opinions, emotions, sentiments, etc.) in natural language", "start_pos": 102, "end_pos": 193, "type": "TASK", "confidence": 0.8202171660959721}]}, {"text": "While subjectivity classification labels text as either subjective or objective, sentiment or polarity classification further classifies subjective text as either positive, negative or neutral.", "labels": [], "entities": []}, {"text": "To date, a large number of text processing applications have used techniques for automatic sentiment and subjectivity analysis, including automatic expressive text-to-speech synthesis, tracking sentiment timelines in on-line forums and news (), and mining opinions from product reviews ().", "labels": [], "entities": [{"text": "automatic sentiment and subjectivity analysis", "start_pos": 81, "end_pos": 126, "type": "TASK", "confidence": 0.6891000688076019}, {"text": "expressive text-to-speech synthesis", "start_pos": 148, "end_pos": 183, "type": "TASK", "confidence": 0.7156691749890646}]}, {"text": "In many natural language processing tasks, subjectivity and sentiment classification has been used as a first phase filtering to generate more viable data.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 60, "end_pos": 84, "type": "TASK", "confidence": 0.9185812771320343}]}, {"text": "Research that benefited from this additional layering ranges from question answering (, to conversation summarization (), text semantic analysis;) and lexical substitution (.", "labels": [], "entities": [{"text": "question answering", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.8579719960689545}, {"text": "conversation summarization", "start_pos": 91, "end_pos": 117, "type": "TASK", "confidence": 0.7303512096405029}, {"text": "text semantic analysis", "start_pos": 122, "end_pos": 144, "type": "TASK", "confidence": 0.8054460883140564}, {"text": "lexical substitution", "start_pos": 151, "end_pos": 171, "type": "TASK", "confidence": 0.7137278914451599}]}, {"text": "While research in English has underlined that the most robust subjectivity delineation occurs at sense and not at word level (), we are not aware of this consideration impacting research in other languages.", "labels": [], "entities": []}, {"text": "For this reason, in this work we seek to analyze how subjectivity is maintained across sense aligned resources, and identify ways in which subjectivity at sense level maybe employed in a multilingual framework to provide a strengthened automatic senselevel classification.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the manually annotated data described in Section 3.1, and we filter out 20 examples that were labeled as both objective and subjective, since they could confuse the classifiers and prevent them from making strong predictions.", "labels": [], "entities": []}, {"text": "We then split the labeled data into three subsets to enable a three-fold cross validation.", "labels": [], "entities": []}, {"text": "Note that we enforce that all the senses belonging to a given word be found in either the test or the training set, but never in both.", "labels": [], "entities": []}, {"text": "This was done to ensure that the classifier would not have an unfair advantage due to finding similar senses in the training data.", "labels": [], "entities": []}, {"text": "For this reason, the fold sizes are not perfectly equal.", "labels": [], "entities": []}, {"text": "Furthermore, for every fold, each iteration is evaluated on the immutable test set corresponding to that fold, which has manually assigned labels in English and Romanian.", "labels": [], "entities": []}, {"text": "In order to generate a running test set, which is modified after every iteration, we append the remaining unlabeled WordNet senses to the corresponding test set for the fold (see).", "labels": [], "entities": []}, {"text": "presents the results obtained using the monolingual co-training algorithm over 40 iterations.", "labels": [], "entities": []}, {"text": "The accuracies obtained at position 0 represent the baseline fora simple monolingual classifier with no co-training.", "labels": [], "entities": []}, {"text": "Unlike the increasing accuracy with the number of iterations obtained by when applying a similar method to sentiment classification of reviews, we were unable to surpass these baselines.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.999164342880249}, {"text": "sentiment classification of reviews", "start_pos": 107, "end_pos": 142, "type": "TASK", "confidence": 0.9287338703870773}]}, {"text": "We attribute this behavior to the small size of the training set (approximately 400 samples in our case versus 8000 product reviews in) and the type of data itself (product reviews are longer and often contain a full paragraph of text, while senses may comprise an average often words).", "labels": [], "entities": []}, {"text": "The overall accuracy is slowly decreasing from 0.73 to 0.62 for English and from 0.68 to 0.54 for Romanian.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9997029900550842}]}, {"text": "The same trend is observed for class precision, recall and F-measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9259524345397949}, {"text": "recall", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9991204142570496}, {"text": "F-measure", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9877433776855469}]}], "tableCaptions": []}