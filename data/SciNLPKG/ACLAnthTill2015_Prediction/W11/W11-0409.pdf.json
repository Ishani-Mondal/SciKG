{"title": [], "abstractContent": [{"text": "In this paper, we propose a crowdsourcing methodology fora single-step construction of both an empirically-derived sense inventory and the corresponding sense-annotated corpus.", "labels": [], "entities": []}, {"text": "The methodology taps the intuitions of non-expert native speakers to create an expert-quality resource, and natively lends itself to supplementing such a resource with additional information about the structure and reliability of the produced sense inventories.", "labels": [], "entities": []}, {"text": "The resulting resource will provide several ways to empirically measure distances between related word senses, and will explicitly address the question of fuzzy boundaries between them.", "labels": [], "entities": []}], "introductionContent": [{"text": "A number of recent initiatives has focused on creating sense-annotated gold standards for word sense disambiguation and induction algorithms.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 90, "end_pos": 115, "type": "TASK", "confidence": 0.7131269176801046}]}, {"text": "However, such work has frequently come under criticism over the lack of a satisfactory set of standards for creating consistent, task-independent sense inventories.", "labels": [], "entities": []}, {"text": "More systematic efforts to replace ad hoc lexicographic procedures for sense inventory construction have often focused on working with existing sense inventories, attempting to resolve the specific associated problems (e.g. sense granularity, overlapping senses, etc.)", "labels": [], "entities": [{"text": "sense inventory construction", "start_pos": 71, "end_pos": 99, "type": "TASK", "confidence": 0.6519784033298492}]}, {"text": "Methodologically, defining a robust procedure for sense definition has remained an elusive task.", "labels": [], "entities": [{"text": "sense definition", "start_pos": 50, "end_pos": 66, "type": "TASK", "confidence": 0.916400820016861}]}, {"text": "In this paper, we propose a method for creating a sense inventory from scratch for any polysemous word, simultaneously with the corresponding senseannotated lexical sample.", "labels": [], "entities": []}, {"text": "The methodology we propose explicitly addresses the question of related word senses and fuzzy boundaries between them, without trying to establish hard divisions where empirically there are none.", "labels": [], "entities": []}, {"text": "The proposed method uses Amazon's Mechanical Turk for sense annotation.", "labels": [], "entities": [{"text": "Amazon's Mechanical Turk", "start_pos": 25, "end_pos": 49, "type": "DATASET", "confidence": 0.9146589487791061}, {"text": "sense annotation", "start_pos": 54, "end_pos": 70, "type": "TASK", "confidence": 0.7851335108280182}]}, {"text": "Over the last several of years, Mechanical Turk, introduced by Amazon as \"artificial artificial intelligence\", has been used successfully fora number of NLP tasks, including robust evaluation of machine translation systems by reading comprehension, and other tasks explored in the recent NAACL workshop.", "labels": [], "entities": [{"text": "NAACL workshop", "start_pos": 288, "end_pos": 302, "type": "DATASET", "confidence": 0.8929560482501984}]}, {"text": "Mechanical Turk has also been used to create labeled data sets for word sense disambiguation ( and even to modify sense inventories.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 67, "end_pos": 92, "type": "TASK", "confidence": 0.7363523840904236}]}, {"text": "But the original sense inventory construction has always been left to the experts.", "labels": [], "entities": []}, {"text": "In contrast, in the annotation method we describe, the expert is eliminated from the annotation process.", "labels": [], "entities": []}, {"text": "As has been the case with using Mechanical Turk for other NLP tasks, the proposed annotation is quite inexpensive and can be done very quickly, while maintaining expert-level annotation quality.", "labels": [], "entities": []}, {"text": "The resulting resource will produce several ways to empirically measure distances between senses, and should help to address some open research questions regarding word sense perceptions by native speakers.", "labels": [], "entities": []}, {"text": "We describe a set of pilot annotation studies needed to ensure reliability of this methodology and test the proposed quality control mechanisms.", "labels": [], "entities": [{"text": "reliability", "start_pos": 63, "end_pos": 74, "type": "METRIC", "confidence": 0.9671483039855957}]}, {"text": "The outcome will be a lexicon where sense inventories are represented as clusters of instances, and an explicit quantitative representation of sense con-sistency, distance between senses, and sense overlap is associated with the senses for each word.", "labels": [], "entities": []}, {"text": "The goal is to provide a more accurate representation the way speakers of a language conceptualize senses, which can be used for training and testing of the automated WSD systems, as well as to automatically induce semantic and syntactic context patterns that represent usage norms and permit native speakers to perform sense disambiguation.", "labels": [], "entities": [{"text": "sense disambiguation", "start_pos": 320, "end_pos": 340, "type": "TASK", "confidence": 0.7461522817611694}]}], "datasetContent": [], "tableCaptions": []}