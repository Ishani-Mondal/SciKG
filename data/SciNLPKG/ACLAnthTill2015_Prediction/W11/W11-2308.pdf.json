{"title": [{"text": "READ-IT: Assessing Readability of Italian Texts with a View to Text Simplification", "labels": [], "entities": [{"text": "READ-IT", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.511410653591156}, {"text": "Assessing Readability of Italian Texts", "start_pos": 9, "end_pos": 47, "type": "TASK", "confidence": 0.840770423412323}, {"text": "Text Simplification", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.7279645502567291}]}], "abstractContent": [{"text": "In this paper, we propose anew approach to readability assessment with a specific view to the task of text simplification: the intended audience includes people with low literacy skills and/or with mild cognitive impairment.", "labels": [], "entities": [{"text": "readability assessment", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.7181718945503235}, {"text": "text simplification", "start_pos": 102, "end_pos": 121, "type": "TASK", "confidence": 0.7768718302249908}]}, {"text": "READ-IT represents the first advanced read-ability assessment tool for what concerns Ital-ian, which combines traditional raw text features with lexical, morpho-syntactic and syntactic information.", "labels": [], "entities": [{"text": "READ-IT", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.529691755771637}]}, {"text": "In READ-IT readability assessment is carried outwith respect to both documents and sentences where the latter represents an important novelty of the proposed approach creating the prerequisites for aligning the readability assessment step with the text simplification process.", "labels": [], "entities": [{"text": "READ-IT readability assessment", "start_pos": 3, "end_pos": 33, "type": "TASK", "confidence": 0.8425188263257345}]}, {"text": "READ-IT shows a high accuracy in the document classification task and promising results in the sentence classification scenario.", "labels": [], "entities": [{"text": "READ-IT", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.4870623052120209}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9992914199829102}, {"text": "document classification task", "start_pos": 37, "end_pos": 65, "type": "TASK", "confidence": 0.8239173293113708}, {"text": "sentence classification", "start_pos": 95, "end_pos": 118, "type": "TASK", "confidence": 0.7753906548023224}]}], "introductionContent": [{"text": "Recently, there has been increasing interest in the exploitation of results from Natural Language Processing (NLP) for the development of assistive technologies.", "labels": [], "entities": []}, {"text": "Here, we address this topic by reporting the first but promising results in the development of a software architecture for the Italian language aimed at assisting people with low literacy skills (both native and foreign speakers) or who have language disabilities in reading texts.", "labels": [], "entities": []}, {"text": "Within an information society, where everyone should be able to access all available information, improving access to written language is becoming more and more a central issue.", "labels": [], "entities": []}, {"text": "This is the case, for instance, of administrative and governmental information which should be accessible to all members of the society, including people who have reading difficulties for different reasons: because of a low education level or because of the fact that the language in question is not their mother tongue, or because of language disabilities.", "labels": [], "entities": []}, {"text": "Health related information represents another crucial domain which should be accessible to a large and heterogenous target group.", "labels": [], "entities": []}, {"text": "Understandability in general and readability in particular is also an important issue for accessing information over the web as stated in the Web Content Accessibility Guidelines (WCAG) proposed by the Web Accessibility Initiative of the W3C.", "labels": [], "entities": []}, {"text": "In this paper, we describe the approach we developed for automatically assessing the readability of newspaper texts with a view to the specific task of text simplification.", "labels": [], "entities": [{"text": "text simplification", "start_pos": 152, "end_pos": 171, "type": "TASK", "confidence": 0.7178671956062317}]}, {"text": "The paper is organized as follows: Section 2 describes the background literature on the topic; Section 3 introduces the main features of our approach to readability assessment, with Section 4 illustrating its implementation in the READ-IT prototype; Sections 5 and 6 describe the experimental setting and discuss achieved results.", "labels": [], "entities": [{"text": "readability assessment", "start_pos": 153, "end_pos": 175, "type": "TASK", "confidence": 0.7623888552188873}]}], "datasetContent": [{"text": "READ-IT was tested on the 2Par and Rep corpora automatically POS tagged by the Part-OfSpeech tagger described in Dell'Orletta (2009) and dependency-parsed by the DeSR parser) using Support Vector Machine as learning algorithm.", "labels": [], "entities": [{"text": "DeSR", "start_pos": 162, "end_pos": 166, "type": "DATASET", "confidence": 0.8526764512062073}]}, {"text": "Three different sets of experiments were devised to test the performance of READ-IT in the following subtasks: i) document readability classification, ii) sentence readability classification and iii) detection of easy-to-read sentences within difficult-to-read texts.", "labels": [], "entities": [{"text": "READ-IT", "start_pos": 76, "end_pos": 83, "type": "TASK", "confidence": 0.820209264755249}, {"text": "document readability classification", "start_pos": 114, "end_pos": 149, "type": "TASK", "confidence": 0.6333385010560354}, {"text": "sentence readability classification", "start_pos": 155, "end_pos": 190, "type": "TASK", "confidence": 0.7433194716771444}, {"text": "detection of easy-to-read sentences within difficult-to-read texts", "start_pos": 200, "end_pos": 266, "type": "TASK", "confidence": 0.7109744378498623}]}, {"text": "For what concerns the document classification subtask, we used a corpus made up of 638 documents of which 319 were extracted from 2Par (taken as representative of the class easy-to-read texts) and 319 from Rep (representing the class of difficultto-read texts).", "labels": [], "entities": [{"text": "2Par", "start_pos": 130, "end_pos": 134, "type": "DATASET", "confidence": 0.8678159117698669}]}, {"text": "We have followed a 5-fold crossvalidation process: the corpus was randomly split into 5 training and test sets.", "labels": [], "entities": []}, {"text": "The test sets consisted of 20% of the individual documents belonging to the two considered readability levels, with each document being included in one test set only.", "labels": [], "entities": []}, {"text": "With regard to the sentence classification subtask, we used a training set of about 3,000 sentences extracted from 2Par and of about 3,000 sentences from Rep and a test corpus of 1,000 sentences of which 500 were extracted from 2Par (hereafter, 2Par test set) and 500 from Rep (hereafter, Rep test set).", "labels": [], "entities": [{"text": "sentence classification", "start_pos": 19, "end_pos": 42, "type": "TASK", "confidence": 0.6897672414779663}, {"text": "2Par test set", "start_pos": 245, "end_pos": 258, "type": "DATASET", "confidence": 0.753580907980601}]}, {"text": "In the third experiment, readability assessment was carried out by READ-IT with respect to a much bigger corpus of 2,5 milion of words extracted from the newspaper La Repubblica (hereafter, Rep 2.5), fora total of 123,171 sentences, with the final aim of detecting easy-to-read sentences.", "labels": [], "entities": [{"text": "READ-IT", "start_pos": 67, "end_pos": 74, "type": "METRIC", "confidence": 0.7438324093818665}]}, {"text": "All the experiments were carried out using four different readability models, described as follows: 1.", "labels": [], "entities": []}, {"text": "Base Model, using raw text features only; 2.", "labels": [], "entities": []}, {"text": "Lexical Model, using a combination of raw text and lexical features; 3.", "labels": [], "entities": []}, {"text": "MorphoS Model: using raw text, lexical and morpho-syntactic features; 4.", "labels": [], "entities": []}, {"text": "Syntax Model: combining all feature types, namely raw text, lexical, morpho-syntactic and syntactic features.", "labels": [], "entities": []}, {"text": "Note that in the Lexical and Syntax Models, different sets of features were selected for the subtasks of document and sentence classification.", "labels": [], "entities": [{"text": "document and sentence classification", "start_pos": 105, "end_pos": 141, "type": "TASK", "confidence": 0.6376360654830933}]}, {"text": "In particular, for sentence-based readability assesment we did not take into account the Type/Token Ratio feature, all features concerning the distribution of 'chains' of embedded complements and subordinate clauses and the distribution of verbal predicates by arity.", "labels": [], "entities": []}, {"text": "Since, to our knowledge, a machine learning readability classifier does not exist for the Italian language we consider the Base Model as our baseline: this can be seen as an approximation of the GulpEase index, which is based on the same raw text features (i.e. sentence and word length).", "labels": [], "entities": []}, {"text": "Different evaluation methods have been defined in order to assess achieved results in the three aforementioned experiment sets.", "labels": [], "entities": []}, {"text": "The performance of both document and sentence classification experiments have been evaluated in terms of i) overall Accuracy of the system and ii) Precision and Recall.", "labels": [], "entities": [{"text": "sentence classification", "start_pos": 37, "end_pos": 60, "type": "TASK", "confidence": 0.698068231344223}, {"text": "Accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9993734955787659}, {"text": "Precision", "start_pos": 147, "end_pos": 156, "type": "METRIC", "confidence": 0.9930811524391174}, {"text": "Recall", "start_pos": 161, "end_pos": 167, "type": "METRIC", "confidence": 0.9678941369056702}]}, {"text": "In particular, Accuracy is a global score referring to the percentage of documents or sentences correctly classified, either as easy-to-read or difficultto-read objects.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9993589520454407}]}, {"text": "Precision and Recall have been computed with respect to two the target reading levels: in particular, Precision is the ratio of the number of correctly classified documents or sentences over the total number of documents and sentences classified by READ-IT as belonging to the easy-to-read (i.e. 2Par) or difficult-to-read (i.e. Rep) classes; Recall has been computed as the ratio of the number of correctly classified documents or sentences over the total number of documents or sentences belonging to each reading level in the test sets.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9192010760307312}, {"text": "Recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9904749989509583}, {"text": "Precision", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.9946222305297852}, {"text": "READ-IT", "start_pos": 249, "end_pos": 256, "type": "DATASET", "confidence": 0.8021478652954102}, {"text": "Recall", "start_pos": 343, "end_pos": 349, "type": "METRIC", "confidence": 0.9682635068893433}]}, {"text": "For each set of experiments, evaluation was carried outwith respect to the four models of the classifier.", "labels": [], "entities": []}, {"text": "Following from the assumption that 2Par contains only easy-to-read sentences while Rep does not necessarily contain only difficult-to-read ones, we consider READ-IT errors in the classification of 2Par sentences as erroneously classified sentences.", "labels": [], "entities": [{"text": "READ-IT", "start_pos": 157, "end_pos": 164, "type": "METRIC", "confidence": 0.9093760251998901}]}, {"text": "On the other hand, classification errors within the set of Rep sentences deserve an in-depth error analysis, since we need to discern real errors from misclassifications due to the fact that we are in front of easy-to-read sentences occurring in a difficult-toread context.", "labels": [], "entities": []}, {"text": "In order discern errors from 'correct' misclassifications, we introduced anew evaluation methodology, based on the notion of Euclidean distance between feature vectors.", "labels": [], "entities": []}, {"text": "Each feature vector is a n-dimensional vector of linguistic features (see Section 4.1) that represents a set of sentences.", "labels": [], "entities": []}, {"text": "Two vectors with 0 distance represent the same set of sentences, i.e. those sentences sharing the same values for the monitored linguistic features.", "labels": [], "entities": []}, {"text": "Conversely, the bigger the distance between two vectors is, the more distant are the two represented sets of sentences with respect to the monitored features.", "labels": [], "entities": []}, {"text": "The same notion of distance has also been used to test which model was more effective in predicting the readability of n-word long sentences.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Document classification results", "labels": [], "entities": [{"text": "Document classification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.9480920135974884}]}, {"text": " Table 2: Sentence classification results", "labels": [], "entities": [{"text": "Sentence classification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.9929363131523132}]}, {"text": " Table 3: Distances between 2Par and Rep on the basis of  the Syntax Model", "labels": [], "entities": []}, {"text": " Table 4: Accuracy in sentence classification of Rep 2.5.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9852151870727539}, {"text": "sentence classification", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.7040399014949799}]}, {"text": " Table 5: Distance between 2Par and i) difficult-to-read  sentences according to the Syntax Model, ii) Rep 2.5, iii)  easy-to-read sentences by the four models.", "labels": [], "entities": [{"text": "Rep", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.9306890964508057}]}]}