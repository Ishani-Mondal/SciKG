{"title": [{"text": "Implementing Weighted Abduction in Markov Logic", "labels": [], "entities": [{"text": "Implementing Weighted Abduction", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8622511426607767}]}], "abstractContent": [{"text": "Abduction is a method for finding the best explanation for observations.", "labels": [], "entities": []}, {"text": "Arguably the most advanced approach to abduction, especially for natural language processing, is weighted abduction, which uses logical formulas with costs to guide inference.", "labels": [], "entities": []}, {"text": "But it has no clear probabilistic semantics.", "labels": [], "entities": []}, {"text": "In this paper we propose an approach that implements weighted abduction in Markov logic, which uses weighted first-order formulas to represent probabilistic knowledge, pointing toward a sound probabilistic semantics for weighted abduction.", "labels": [], "entities": []}, {"text": "Application to a series of challenge problems shows the power and coverage of our approach.", "labels": [], "entities": [{"text": "coverage", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.98244309425354}]}], "introductionContent": [{"text": "Abduction is inference to the best explanation.", "labels": [], "entities": []}, {"text": "1 Typically, one uses it to find the best hypothesis explaining a set of observations, e.g., in diagnosis and plan recognition.", "labels": [], "entities": [{"text": "diagnosis", "start_pos": 96, "end_pos": 105, "type": "TASK", "confidence": 0.9765433669090271}, {"text": "plan recognition", "start_pos": 110, "end_pos": 126, "type": "TASK", "confidence": 0.704958125948906}]}, {"text": "In natural language processing the content of an utterance can be viewed as a set of observations, and the best explanation then constitutes the interpretation of the utterance.", "labels": [], "entities": [{"text": "natural language processing the content of an utterance", "start_pos": 3, "end_pos": 58, "type": "TASK", "confidence": 0.7819186151027679}]}, {"text": "Hobbs et al. described a variety of abduction called \"weighted abduction\" for interpreting natural language discourse.", "labels": [], "entities": [{"text": "interpreting natural language discourse", "start_pos": 78, "end_pos": 117, "type": "TASK", "confidence": 0.8873884379863739}]}, {"text": "The key idea was that the best interpretation of a text is the best explanation or proof of the logical form of the text, allowing for assumptions.", "labels": [], "entities": []}, {"text": "What counted as \"best\" was defined in terms of a cost function which favored proofs with the fewest number of assumptions and the most salient and plausible axioms, and in which the pervasive redundancy implicit in natural language discourse was exploited.", "labels": [], "entities": []}, {"text": "It was argued in that paper that such interpretation problems as coreference and syntactic ambiguity resolution, determining the specific meanings of vague predicates and lexical ambiguity resolution, metonymy resolution, metaphor interpretation, and the recognition of discourse structure could be seen to \"fall out\" of the best abductive proof.", "labels": [], "entities": [{"text": "syntactic ambiguity resolution", "start_pos": 81, "end_pos": 111, "type": "TASK", "confidence": 0.7373698155085245}, {"text": "lexical ambiguity resolution", "start_pos": 171, "end_pos": 199, "type": "TASK", "confidence": 0.8161839842796326}, {"text": "metonymy resolution", "start_pos": 201, "end_pos": 220, "type": "TASK", "confidence": 0.8570540547370911}, {"text": "metaphor interpretation", "start_pos": 222, "end_pos": 245, "type": "TASK", "confidence": 0.8106273710727692}, {"text": "recognition of discourse structure", "start_pos": 255, "end_pos": 289, "type": "TASK", "confidence": 0.8065780103206635}]}, {"text": "Specifically, weighted abduction has the following features: 1.", "labels": [], "entities": []}, {"text": "Ina goal expression consisting of an existentially quantified conjunction of positive literals, each literal is given a cost that represents the utility of proving that literal as opposed to assuming it.", "labels": [], "entities": []}, {"text": "That is, a low cost on a literal will make it more likely for it to be assumed, whereas a high cost will result in a greater effort to find a proof.", "labels": [], "entities": []}, {"text": "We are indebted to Jesse Davis, Parag Singla and Marc Sumner for discussions about this work.", "labels": [], "entities": []}, {"text": "This research was supported in part by the Defense Advanced Research Projects Agency (DARPA) Machine Reading Program under Air Force Research Laboratory (AFRL) prime contract no.", "labels": [], "entities": [{"text": "Defense Advanced Research Projects Agency (DARPA) Machine Reading", "start_pos": 43, "end_pos": 108, "type": "TASK", "confidence": 0.556908717751503}]}, {"text": "FA8750-09-C-0172, in part by the Office of Naval Research under contract no.", "labels": [], "entities": [{"text": "FA8750-09-C-0172", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.9633691310882568}]}, {"text": "N00014-09-1-1029, and in part by the Army Research Office under grant W911NF-08-1-0242.", "labels": [], "entities": [{"text": "N00014-09-1-1029", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.9181230068206787}, {"text": "Army Research Office", "start_pos": 37, "end_pos": 57, "type": "DATASET", "confidence": 0.9301166733105978}, {"text": "W911NF-08-1-0242", "start_pos": 70, "end_pos": 86, "type": "DATASET", "confidence": 0.6605290770530701}]}, {"text": "Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the view of the DARPA, AFRL, ONR, ARO, or the US government.", "labels": [], "entities": [{"text": "DARPA", "start_pos": 158, "end_pos": 163, "type": "DATASET", "confidence": 0.834720253944397}, {"text": "AFRL", "start_pos": 165, "end_pos": 169, "type": "DATASET", "confidence": 0.5986378192901611}, {"text": "ONR", "start_pos": 171, "end_pos": 174, "type": "DATASET", "confidence": 0.7288421988487244}, {"text": "ARO", "start_pos": 176, "end_pos": 179, "type": "DATASET", "confidence": 0.6936478614807129}]}], "datasetContent": [{"text": "We have tested our approach on a set of fourteen challenge problems from and subsequent papers, designed to exercise the principal features of weighted abduction and show its utility for solving natural language interpretation problems.", "labels": [], "entities": [{"text": "natural language interpretation", "start_pos": 195, "end_pos": 226, "type": "TASK", "confidence": 0.625303715467453}]}, {"text": "The knowledge bases used for each of these problems are sparse, consisting of only the axioms required for solving the problems plus a few distractors.", "labels": [], "entities": []}, {"text": "An example of a relatively simple problem is #5 in the table below, resolving \"he\" in the text I saw my doctor last week.", "labels": [], "entities": []}, {"text": "He told me to get more exercise.", "labels": [], "entities": []}, {"text": "where we are given a knowledge base that says a doctor is a person and a male person is a \"he\".", "labels": [], "entities": []}, {"text": "Solving the problem requires assuming the doctor is male.", "labels": [], "entities": []}, {"text": "The logical form fragment to prove is (\u2203 x)he(x), where we know doctor(D).", "labels": [], "entities": []}, {"text": "A problem of intermediate difficulty (#7) is resolving the three lexical ambiguities in the sentence The plane taxied to the terminal.", "labels": [], "entities": []}, {"text": "where we are given a knowledge base saying that airplanes and wood smoothers are planes, planes moving on the ground and people taking taxis are both described as \"taxiing\", and computer terminals and airport terminals are both terminals.", "labels": [], "entities": []}, {"text": "An example of a difficult problem is #12, finding the coherence relation, thereby resolving the pronoun \"they\", between the sentences The police prohibited the women from demonstrating.", "labels": [], "entities": []}, {"text": "The axioms specify relations between fearing, not wanting, and prohibiting, as well as the defeasible transitivity of causality and the fact that a causal relation between sentences makes the discourse coherent.", "labels": [], "entities": []}, {"text": "The weights in the axioms were mostly distributed evenly across the conjuncts in the antecedents and summed to 1.2.", "labels": [], "entities": []}, {"text": "For each of these problems, we compare the performance of the method described herewith a manually constructed gold standard and also with a method based on Kate and Mooney's (KM) approach.", "labels": [], "entities": []}, {"text": "In this method, weights were assigned to the reversed clauses based on the negative log of the sum of weights in the original clause.", "labels": [], "entities": []}, {"text": "This approach does not capture different weights for different antecedents of the same rule, and so has less fidelity to weighted abduction than our approach.", "labels": [], "entities": []}, {"text": "In each case, we used Alchemy's probabilistic inference to determine the most probable explanation (MPE).", "labels": [], "entities": [{"text": "probable explanation (MPE)", "start_pos": 78, "end_pos": 104, "type": "METRIC", "confidence": 0.7150489330291748}]}, {"text": "In some of the problems the system should make more than one assumption, so there are 22 assumptions in total overall 14 problems in the gold standard.", "labels": [], "entities": [{"text": "gold standard", "start_pos": 137, "end_pos": 150, "type": "DATASET", "confidence": 0.9214203953742981}]}, {"text": "Using our method, 18 of the assumptions were found, while 15 were found using the KM method.", "labels": [], "entities": []}, {"text": "shows the number of correct assumptions found and the running time for the two approaches for each problem.", "labels": [], "entities": []}, {"text": "Our method in particular provides good coverage, with a recall of over 80% of the assumptions made in the gold standard.", "labels": [], "entities": [{"text": "coverage", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9647335410118103}, {"text": "recall", "start_pos": 56, "end_pos": 62, "type": "METRIC", "confidence": 0.9990590214729309}, {"text": "gold standard", "start_pos": 106, "end_pos": 119, "type": "DATASET", "confidence": 0.9120238423347473}]}, {"text": "It has a shorter running time overall, approximately 5.3 seconds versus 8.7 seconds for the reversal method.", "labels": [], "entities": []}, {"text": "This is largely due to one problem in the test set, problem #9, where the running time for the KM method is relatively high because the technique finds a less sparse network, leading to larger cliques.", "labels": [], "entities": []}, {"text": "There were two problems in the test set that neither approach could solve.", "labels": [], "entities": []}, {"text": "One of these contains predicates that have a large number of arguments, leading to large clique sizes.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance on each problem in our test set, comparing two encodings of weighted abduction  into Markov logic networks and a gold standard.", "labels": [], "entities": []}]}