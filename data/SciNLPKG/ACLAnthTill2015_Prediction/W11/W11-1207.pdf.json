{"title": [{"text": "Two Ways to Use a Noisy Parallel News corpus for improving Statistical Machine Translation", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 59, "end_pos": 90, "type": "TASK", "confidence": 0.8411494692166647}]}], "abstractContent": [{"text": "In this paper, we present two methods to use a noisy parallel news corpus to improve statistical machine translation (SMT) systems.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 85, "end_pos": 122, "type": "TASK", "confidence": 0.801545242468516}]}, {"text": "Taking full advantage of the characteristics of our corpus and of existing resources, we use a bootstrapping strategy, whereby an existing SMT engine is used both to detect parallel sentences in comparable data and to provide an adaptation corpus for translation models.", "labels": [], "entities": [{"text": "SMT", "start_pos": 139, "end_pos": 142, "type": "TASK", "confidence": 0.9662259817123413}]}, {"text": "MT experiments demonstrate the benefits of various combinations of these strategies.", "labels": [], "entities": [{"text": "MT", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9518810510635376}]}], "introductionContent": [{"text": "In Statistical Machine Translation (SMT), systems are created from parallel corpora consisting of a set of source language texts aligned with its translation in the target language.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 3, "end_pos": 40, "type": "TASK", "confidence": 0.8784775336583456}]}, {"text": "Such corpora however only exist (at least are publicly documented and available) fora limited number of domains, genres, registers, and language pairs.", "labels": [], "entities": []}, {"text": "In fact, there area few language pairs for which parallel corpora can be accessed, except for very narrow domains such as political debates or international regulatory texts.", "labels": [], "entities": []}, {"text": "Another very valuable resource for SMT studies, especially for under-resource languages, are comparable corpora, made of pairs of monolingual corpora that contain texts of similar genres, from similar periods, and/or about similar topics.", "labels": [], "entities": [{"text": "SMT", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.9969115853309631}]}, {"text": "The potential of comparable corpora has long been established as a useful source from which to extract bilingual word dictionaries (see eg.) or to learn multilingual terms (see e.g.).", "labels": [], "entities": []}, {"text": "More recently, the relative corpus has caused the usefulness of comparable corpora be reevaluated as a potential source of parallel fragments, be they paragraphs, sentences, phrases, terms, chunks, or isolated words.", "labels": [], "entities": []}, {"text": "This tendency is illustrated by the work of e.g. (, which combines Information Retrieval techniques (to identify parallel documents) and sentence similarity detection to detect parallel sentences.", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 67, "end_pos": 88, "type": "TASK", "confidence": 0.6875861883163452}, {"text": "sentence similarity detection", "start_pos": 137, "end_pos": 166, "type": "TASK", "confidence": 0.7361882428328196}]}, {"text": "There are many other ways to improve SMT models with comparable or monolingual data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9968804121017456}]}, {"text": "For instance, the work reported in draws inspiration from recent advances in unsupervised training of acoustic models for speech recognition and proposes to use self-training on in-domain data to adapt and improve a baseline system trained mostly with out-of-domain data.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 122, "end_pos": 140, "type": "TASK", "confidence": 0.7529080212116241}]}, {"text": "As discussed e.g. in (), comparable corpora are of various nature: there exists a continuum between truly parallel and completely unrelated texts.", "labels": [], "entities": []}, {"text": "Algorithms for exploiting comparable corpora should thus be tailored to the peculiarities of the data on which they are applied.", "labels": [], "entities": []}, {"text": "In this paper, we report on experiments aimed at using a noisy parallel corpus made out of news stories in French and Arabic in two different ways: first, to extract new, in-domain, parallel sentences; second, to adapt our translation and language models.", "labels": [], "entities": []}, {"text": "This approach is made possible due to the specificities of our corpus.", "labels": [], "entities": []}, {"text": "In fact, our work is part of a project aiming at developing a platform for processing multimedia news documents (texts, interviews, images and videos) in Arabic, so as to streamline the work of a major international news agency.", "labels": [], "entities": [{"text": "processing multimedia news documents (texts, interviews, images and videos)", "start_pos": 75, "end_pos": 150, "type": "TASK", "confidence": 0.7021965957604922}]}, {"text": "As part as the standard daily workflow, a significant portion of the French news are translated (or adapted) in Arabic by journalists.", "labels": [], "entities": []}, {"text": "Having access to one full year of the French and Arabic corpus (consisting, to date, of approximately one million stories (150 million words)), we have in our hands an ideal comparable resource to perform large scale experiments.", "labels": [], "entities": [{"text": "French and Arabic corpus", "start_pos": 38, "end_pos": 62, "type": "DATASET", "confidence": 0.656829297542572}]}, {"text": "These experiments aim at comparing various ways to build an accurate machine translation system for the news domain using (i) a baseline system trained mostly with out-of-domain data (ii) the comparable dataset.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.7356651723384857}]}, {"text": "As will be discussed, given the very large number of parallel news in the data, our best option seems to reconstruct an in-domain training corpus of automatically detected parallel sentences.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we relate our work to some existing approaches for using comparable corpora.", "labels": [], "entities": []}, {"text": "Section 3 presents our methodology for extracting parallel sentences, while our phrase-table adaptation strategies are described in Section 4.", "labels": [], "entities": [{"text": "extracting parallel sentences", "start_pos": 39, "end_pos": 68, "type": "TASK", "confidence": 0.8645863930384318}, {"text": "phrase-table adaptation", "start_pos": 80, "end_pos": 103, "type": "TASK", "confidence": 0.7860859632492065}]}, {"text": "In Section 5, we describe our experiments and contrast the results obtained with several adaptation strategies.", "labels": [], "entities": []}, {"text": "Finally, Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}