{"title": [{"text": "(Linear) Maps of the Impossible: Capturing semantic anomalies in distributional space", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we present a first attempt to characterize the semantic deviance of composite expressions in distributional semantics.", "labels": [], "entities": []}, {"text": "Specifically, we look for properties of adjective-noun combinations within a vector-based semantic space that might cue their lack of meaning.", "labels": [], "entities": []}, {"text": "We evaluate four different com-positionality models shown to have various levels of success in representing the meaning of AN pairs: the simple additive and multiplicative models of Mitchell and Lap-ata (2008), and the linear-map-based models of Guevara (2010) and Baroni and Zamparelli (2010).", "labels": [], "entities": []}, {"text": "For each model, we generate composite vectors fora set of AN combinations unattested in the source corpus and which have been deemed either acceptable or semantically deviant.", "labels": [], "entities": []}, {"text": "We then compute measures that might cue semantic anomaly, and compare each model's results for the two classes of ANs.", "labels": [], "entities": []}, {"text": "Our study shows that simple, unsuper-vised cues can indeed significantly tell unat-tested but acceptable ANs apart from impossible , or deviant, ANs, and that the simple additive and multiplicative models are the most effective in this task.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical approaches to describe, represent and understand natural language have been criticized as failing to account for linguistic 'creativity', a property which has been accredited to the compositional nature of natural language.", "labels": [], "entities": []}, {"text": "Specifically, criticisms against statistical methods were based on the argument that a corpus cannot significantly sample a natural language because natural language is infinite.", "labels": [], "entities": []}, {"text": "This cricticism also applies to distributional semantic models that build semantic representations of words or phrases in terms of vectors recording their distributional co-occurrence patterns in a corpus, but have no obvious way to generalize to word combinations that have not been observed in the corpus.", "labels": [], "entities": []}, {"text": "To address this problem, there have been several recent attempts to incorporate into distributional semantic models a component that generates vectors for unseen linguistic structures by compositional operations in the vector space (.", "labels": [], "entities": []}, {"text": "The ability to work with unattested data leads to the question of why a linguistic expression might not be attested in even an extremely large and wellbalanced corpus.", "labels": [], "entities": []}, {"text": "Its absence might be motivated by a number of factors: pure chance, the fact that the expression is ungrammatical, uses a rare structure, describes false facts, or, finally, is nonsensical.", "labels": [], "entities": []}, {"text": "One criticism from generative linguists is precisely that statistical methods could not distinguish between these various possibilities.", "labels": [], "entities": [{"text": "generative linguists", "start_pos": 19, "end_pos": 39, "type": "TASK", "confidence": 0.9625524282455444}]}, {"text": "The difficulty of solving this problem can be illustrated by the difference in semantics between the adjective-noun pairs in (1a) and (1b): (1) a. blue rose b. residential steak tually seen a blue rose, the concept is not inconceivable.", "labels": [], "entities": []}, {"text": "On the other hand, the concept of a residential steak is rather unimaginable, and intuitively its absence in a corpus is motivated by more than just chance or data sparseness.", "labels": [], "entities": []}, {"text": "The present paper is a first attempt to use compositionality and distributional measures to distinguish nonsensical, or semantically deviant, linguistic expression from other types of unattested structures.", "labels": [], "entities": []}, {"text": "The task of distinguishing between unattested but acceptable and unattested but semantically deviant linguistic expressions is not only away to address the criticism about the meaning of 'unattestedness', but also a task that could have a large impact on the (computational) linguistic community as a whole (see Section 2.1).", "labels": [], "entities": []}, {"text": "Our specific goal is to automatically detect semantic deviance in attributive Adjective-Noun (AN) expressions, using a small number of simple cues in the vectorial representation of an AN as it is generated from the distributional vectors of its component A and N by four compositional models found in the literature.", "labels": [], "entities": []}, {"text": "The choice of AN as our testbed is motivated by two facts: first of all, ANs are common, small constituents containing no functional material, and secondly, ANs have already been studied in compositional distributional semantics (.", "labels": [], "entities": []}, {"text": "It is important to note that in this research we talk about 'semantically deviant' expressions, but we do not exclude the possibility that such expressions are interpreted as metaphors, via a chain of associations.", "labels": [], "entities": []}, {"text": "In fact, distributional measures are desirable models to account for this, since they naturally lead to a gradient notion of semantic anomaly.", "labels": [], "entities": []}, {"text": "The rest of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses relevant earlier work, introducing the literature on semantic deviance as well as compositional methods in distributional semantics.", "labels": [], "entities": []}, {"text": "Section 3 presents some hypotheses about cues of semantic deviance in distributional space.", "labels": [], "entities": []}, {"text": "Our experimental setup and procedure are detailed in Section 4, whereas the experiments' results are presented and analyzed in Section 5.", "labels": [], "entities": []}, {"text": "We conclude by summarizing and proposing future directions in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our initial step was to construct a semantic space for our experiments, consisting of a matrix where each row vector represents an adjective, noun or AN.", "labels": [], "entities": []}, {"text": "We first introduce the source corpus, then the vocabulary of words and ANs that we represent in the space, and finally the procedure adopted to build the vectors representing the vocabulary items from corpus statistics, in order to obtain the semantic space matrix.", "labels": [], "entities": []}, {"text": "We work herewith a \"vanilla\" semantic space (essentially, we follow the steps of), since our focus is on the effect of different composition methods given a common semantic space.", "labels": [], "entities": []}, {"text": "We leave it to further work to study how choices in semantic space construction affect composition operations.", "labels": [], "entities": [{"text": "semantic space construction", "start_pos": 52, "end_pos": 79, "type": "TASK", "confidence": 0.6922540664672852}]}, {"text": "Our goal is to study what happens when compositional methods are used to construct a distributional representation for ANs that are semantically deviant, compared to the AN representations they generate for ANs they have not encountered before, but that are semantically acceptable.", "labels": [], "entities": []}, {"text": "In order to assemble these lists, we started from the set of 3.5M unattested ANs described in Section 4.1.2 above, focusing on 30 randomly chosen adjectives.", "labels": [], "entities": []}, {"text": "For each of these, we randomly picked 100 ANs for manual inspection (3K ANs in total).", "labels": [], "entities": []}, {"text": "Two authors went through this list, marking those ANs that they found semantically highly anomalous, no matter how much effort one would put in constructing metaphorical or context-dependent interpretations, as well as those they found completely acceptable (so, rating was on a 3-way scale: deviant,  Using each composition method, we generate composite vectors for all the ANs in the two (acceptable and deviant) evaluation sets (see Section 4.2 above).", "labels": [], "entities": []}, {"text": "We then compute the measures that might cue semantic deviance discussed in Section 3 above, and compare their values between the two AN sets.", "labels": [], "entities": []}, {"text": "In order to smooth out adjective-specific effects, we znormalize the values of each measure across all the ANs sharing an adjective before computing global statistics (i.e., the values for all ANs sharing an adjective from the two sets are transformed by subtracting their mean and dividing by their variance).", "labels": [], "entities": []}, {"text": "We then compare the two sets, for each composition method and deviance cue, by means of two-tailed Welch's t tests.", "labels": [], "entities": []}, {"text": "We report the estimated t score, that is, the standardized difference between the mean acceptable and deviant AN values, with the corresponding significance level.", "labels": [], "entities": [{"text": "standardized difference", "start_pos": 46, "end_pos": 69, "type": "METRIC", "confidence": 0.9620465338230133}, {"text": "AN", "start_pos": 110, "end_pos": 112, "type": "METRIC", "confidence": 0.9388726949691772}, {"text": "significance level", "start_pos": 144, "end_pos": 162, "type": "METRIC", "confidence": 0.9538323879241943}]}, {"text": "For all our cues, we predict t to be significantly larger than 0: Acceptable AN vectors should be longer than deviant ones, they should be nearer -that is, have a higher cosine with -the component N vectors and their neighbourhood should be denser -that is, the average cosines with their top neighbours should be higher than the ones of deviant ANs with their top neighbours.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: t scores for difference between acceptable and  deviant ANs with respect to 3 cues of deviance: length  of the AN vector, cosine of the AN vector with the com- ponent noun vector and density, measured as the average  cosine of an AN vector with its nearest 10 neighbours in  semantic space. For all significant results, p< 0.01.", "labels": [], "entities": []}, {"text": " Table 2: Percentage distributions of various properties of  the top 10 neighbours of ANs in the acceptable (2800)  and deviant (4130) sets for add, mult and alm. The last  two columns express whether the neighbor contains the  same Adjective or Noun as the target AN.", "labels": [], "entities": []}]}