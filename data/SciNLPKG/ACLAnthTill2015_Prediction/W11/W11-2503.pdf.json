{"title": [{"text": "Distributional semantics from text and images", "labels": [], "entities": [{"text": "Distributional semantics", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9130341708660126}]}], "abstractContent": [{"text": "We present a distributional semantic model combining text-and image-based features.", "labels": [], "entities": []}, {"text": "We evaluate this multimodal semantic model on simulating similarity judgments, concept clustering and the BLESS benchmark.", "labels": [], "entities": [{"text": "concept clustering", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.7205770611763}, {"text": "BLESS", "start_pos": 106, "end_pos": 111, "type": "METRIC", "confidence": 0.989325761795044}]}, {"text": "When integrated with the same core text-based model, image-based features are at least as good as further text-based features, and they capture different qualitative aspects of the tasks, suggesting that the two sources of information are complementary.", "labels": [], "entities": []}], "introductionContent": [{"text": "Distributional semantic models use large text corpora to derive estimates of semantic similarities between words.", "labels": [], "entities": []}, {"text": "The basis of these procedures lies in the hypothesis that semantically similar words tend to appear in similar contexts.", "labels": [], "entities": []}, {"text": "For example, the meaning of spinach (primarily) becomes the result of statistical computations based on the association between spinach and words like plant, green, iron, Popeye, muscles.", "labels": [], "entities": [{"text": "Popeye", "start_pos": 171, "end_pos": 177, "type": "DATASET", "confidence": 0.9487658143043518}]}, {"text": "Alongside their applications in NLP areas such as information retrieval or word sense disambiguation), a strong debate has arisen on whether distributional semantic models are also reflecting human cognitive processes ().", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 50, "end_pos": 71, "type": "TASK", "confidence": 0.7541498243808746}, {"text": "word sense disambiguation", "start_pos": 75, "end_pos": 100, "type": "TASK", "confidence": 0.6222013731797537}]}, {"text": "Many cognitive scientists have however observed that these techniques relegate the process of meaning extraction solely to linguistic regularities, forgetting that humans can also rely on non-verbal experience, and comprehension also involves the activation of non-linguistic representations ().", "labels": [], "entities": [{"text": "meaning extraction", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.724659875035286}]}, {"text": "They argue that, without grounding words to bodily actions and perceptions in the environment, we can never get past defining a symbol by simply pointing to covariation of amodal symbolic patterns.", "labels": [], "entities": []}, {"text": "Going back to our example, the meaning of spinach should come (at least partially) from our experience with spinach, its colors, smell and the occasions in which we tend to encounter it.", "labels": [], "entities": []}, {"text": "We can thus distinguish two different views of how meaning emerges, one stating that it emerges from association between linguistic units reflected by statistical computations on large bodies of text, the other stating that meaning is still the result of an association process, but one that concerns the association between words and perceptual information.", "labels": [], "entities": []}, {"text": "In our work, we try to make these two apparently mutually exclusive accounts communicate, to construct a richer and more human-like notion of meaning.", "labels": [], "entities": []}, {"text": "In particular, we concentrate on perceptual information coming from images, and we create a multimodal distributional semantic model extracted from texts and images, putting side by side techniques from NLP and computer vision.", "labels": [], "entities": []}, {"text": "Ina nutshell, our technique is based on using a collection of labeled pictures to build vectors recording the cooccurrences of words with image-based features, exactly as we would do with textual co-occurrences.", "labels": [], "entities": []}, {"text": "We then concatenate the image-based vector with a standard text-based distributional vector, to obtain our multimodal representation.", "labels": [], "entities": []}, {"text": "The preliminary results reported in this paper indicate that en-riching a text-based model with image-based features is at least not damaging, with respect to enlarging the purely textual component, and it leads to qualitatively different results, indicating that the two sources of information are not redundant.", "labels": [], "entities": []}, {"text": "The rest of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews relevant work including distributional semantic models, computer vision techniques suitable to our purpose and systems combining text and image information, including the only work we are aware of that attempts something similar to what we try here.", "labels": [], "entities": []}, {"text": "We introduce our multimodal distributional semantic model in Section 3, and our experimental setup and procedure in Section 4.", "labels": [], "entities": []}, {"text": "Our experiments' results are discussed in Section 5.", "labels": [], "entities": []}, {"text": "Section 6 concludes summarizing current achievements and discussing next directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "DM has been shown to be near or at the state of the art in a great variety of semantic tasks, ranging from modeling similarity judgments to concept categorization, predicting selectional preferences, relation classification and more.", "labels": [], "entities": [{"text": "predicting selectional preferences", "start_pos": 164, "end_pos": 198, "type": "TASK", "confidence": 0.8602697451909384}, {"text": "relation classification", "start_pos": 200, "end_pos": 223, "type": "TASK", "confidence": 0.8778550922870636}]}, {"text": "The DM model is described in detail by, where it is referred to as TypeDM.", "labels": [], "entities": []}, {"text": "In brief, the model is trained on a large corpus of about 2.8 billion tokens that include Web documents, the Wikipedia and the BNC.", "labels": [], "entities": [{"text": "BNC", "start_pos": 127, "end_pos": 130, "type": "DATASET", "confidence": 0.8998867273330688}]}, {"text": "DM is a structured model, where the collocates are labeled with the link that connect them to the target words.", "labels": [], "entities": []}, {"text": "The links are determined by a mixture of dependency parse information and lexico-syntactic patterns, resulting in distributional features (the dimensions of the semantic space) such as subject kill, with gun or as sharp as.", "labels": [], "entities": []}, {"text": "The score of a target word with a feature is not based on the absolute number of times they co-occur in the corpus, but on the variety of different surface realizations of the feature the word co-occurs with.", "labels": [], "entities": []}, {"text": "For example, for the word fat and the feature of animal, the raw score is 9 because fat co-occurs with 9 different forms of the feature (a fat of the animal, the fat of the animal, fats of animal.", "labels": [], "entities": []}, {"text": "). Refer to for how the surface realizations of a feature are determined.", "labels": [], "entities": []}, {"text": "Raw scores are then transformed into Local Mutual Information values.", "labels": [], "entities": []}, {"text": "The DM semantic space is a matrix with 30K rows (target words) represented in a space of more than 700M dimensions.", "labels": [], "entities": []}, {"text": "Since our visual dimension extraction algorithms are maximally producing 32K dimensions (see Section 4.2 below), we make the impact of text features on the combined model directly comparable to the one of visual features by selecting only the top n DM dimensions (with n varying as explained below).", "labels": [], "entities": [{"text": "visual dimension extraction", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.6881576577822367}]}, {"text": "The top dimensions are picked based on their cumulative Local Mutual Information mass.", "labels": [], "entities": []}, {"text": "We show in the experiments below that trimming DM in this way does not have a negative impact on its performance, so that we are justified in claiming that we are adding visual information to a state-of-the-art text-based semantic space.", "labels": [], "entities": [{"text": "trimming DM", "start_pos": 38, "end_pos": 49, "type": "TASK", "confidence": 0.8815128207206726}]}, {"text": "We conduct our most extensive evaluation on the WordSim353 data set (), a widely used benchmark constructed by asking 16 subjects to rate a set of word pairs on a 10-point similarity scale and averaging the ratings (dollar/buck receive a high 9.22 average rating, professor/cucumber a low 0.31).", "labels": [], "entities": [{"text": "WordSim353 data set", "start_pos": 48, "end_pos": 67, "type": "DATASET", "confidence": 0.9771758715311686}]}, {"text": "We cover 260 WordSim (mostly noun/noun) pairs.", "labels": [], "entities": []}, {"text": "We evaluate models in terms of the Spearman correlation of the cosines they produce for the WordSim pairs with the average human ratings for the same pairs (here and below, we do not report comparisons with the state of the art in the literature, because we have reduced coverage of the data sets, making the comparison not meaningful).", "labels": [], "entities": []}, {"text": "To verify if the conclusions reached on WordSim extend to different semantic tasks, we use two concept categorization benchmarks, where the goal is to cluster a set of (nominal) concepts into broader categories.", "labels": [], "entities": []}, {"text": "The Almuhareb-Poesio (AP) concept set), in the version we cover, contains 230 concepts to be clustered into 21 classes such as vehicle (airplane, car.", "labels": [], "entities": [{"text": "Almuhareb-Poesio (AP) concept set", "start_pos": 4, "end_pos": 37, "type": "DATASET", "confidence": 0.7511133303244909}]}, {"text": "), time (aeon, future.", "labels": [], "entities": []}, {"text": ") or social unit (brigade, nation).", "labels": [], "entities": []}, {"text": "The Battig set ( , in the version we cover, contains 72 concepts to be clustered into 10 classes.", "labels": [], "entities": [{"text": "Battig set", "start_pos": 4, "end_pos": 14, "type": "DATASET", "confidence": 0.7847560942173004}]}, {"text": "Unlike AP, Battig only contains concrete basic-level concepts belonging to categories such as bird (eagle, owl.", "labels": [], "entities": []}, {"text": "), kitchenware (bowl, spoon.", "labels": [], "entities": []}, {"text": ") or vegetable (broccoli, potato.", "labels": [], "entities": []}, {"text": "). For both sets, following the original proponents and others, we cluster the words based on their pairwise cosines in the semantic space defined by a model using the CLUTO toolkit.", "labels": [], "entities": []}, {"text": "We use CLUTO's built-in repeated bisections with global optimization method, accepting all of CLUTO's default values.", "labels": [], "entities": []}, {"text": "Cluster quality is evaluated by percentage purity (.", "labels": [], "entities": []}, {"text": "If n i r is the number of items from the i-th true (gold standard) class that were assigned to the r-th cluster, n is the total number of items and k the number of clusters, then: In the best case (perfect clusters), purity is 100% and as cluster quality deteriorates, purity approaches 0.", "labels": [], "entities": [{"text": "purity", "start_pos": 217, "end_pos": 223, "type": "METRIC", "confidence": 0.9949625730514526}, {"text": "purity", "start_pos": 269, "end_pos": 275, "type": "METRIC", "confidence": 0.9971923232078552}]}, {"text": "Finally, we use the Baroni-Lenci Evaluation of Semantic Similarity (BLESS) data set made available by the GEMS 2011 organizers.", "labels": [], "entities": [{"text": "BLESS) data set", "start_pos": 68, "end_pos": 83, "type": "DATASET", "confidence": 0.8659474104642868}, {"text": "GEMS 2011 organizers", "start_pos": 106, "end_pos": 126, "type": "DATASET", "confidence": 0.9181830485661825}]}, {"text": "In the version we cover, the data set contains 174 concrete nominal concepts, each paired with a set of words that instantiate the following 6 relations: hypernymy (spear/weapon), coordination (tiger/coyote), meronymy (castle/hall), typical attribute (an adjective: grapefruit/tart) and typical event (a verb: cat/hiss).", "labels": [], "entities": [{"text": "coordination", "start_pos": 180, "end_pos": 192, "type": "METRIC", "confidence": 0.9801234602928162}]}, {"text": "Concepts are moreover matched with 3 sets of randomly picked unrelated words (nouns, adjectives and verbs).", "labels": [], "entities": []}, {"text": "For each true and random relation, the data set contains at least one word per concept, typically more.", "labels": [], "entities": []}, {"text": "Following the GEMS guidelines, we apply a model to BLESS as follows.", "labels": [], "entities": [{"text": "GEMS", "start_pos": 14, "end_pos": 18, "type": "DATASET", "confidence": 0.9034879207611084}, {"text": "BLESS", "start_pos": 51, "end_pos": 56, "type": "METRIC", "confidence": 0.9372814297676086}]}, {"text": "Given the similarity scores provided by the model fora concept with all associated words within a relation, we pick the term with the highest score.", "labels": [], "entities": []}, {"text": "We then zstandardize the 8 scores we obtain for each concept (one per relation), and we produce a boxplot summarizing the distribution of z scores per relation across the concepts (i.e., each box of the plot summarizes the distribution of the 174 scores picked for each relation, standardized as we just described).", "labels": [], "entities": []}, {"text": "Boxplots are produced accepting the default boxplotting option of the R statistical package 5 (boxes extend from first to third quartile, median is horizontal line inside the box).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: WordSim pairs with highest (first column) and  lowest (second column) combined-to-text+ cosine ratios", "labels": [], "entities": []}, {"text": " Table 2: Percentage AP and Battig purities of distribu- tional models", "labels": [], "entities": [{"text": "Percentage", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9541868567466736}, {"text": "AP", "start_pos": 21, "end_pos": 23, "type": "METRIC", "confidence": 0.5874041318893433}]}]}