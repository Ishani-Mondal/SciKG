{"title": [{"text": "Applying Sentiment-oriented Sentence Filtering to Multilingual Review Classification", "labels": [], "entities": [{"text": "Applying", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.8231653571128845}, {"text": "Sentiment-oriented Sentence Filtering", "start_pos": 9, "end_pos": 46, "type": "TASK", "confidence": 0.7017975648244222}]}], "abstractContent": [{"text": "A method for multilingual review classification is described.", "labels": [], "entities": [{"text": "multilingual review classification", "start_pos": 13, "end_pos": 47, "type": "TASK", "confidence": 0.7390082279841105}]}, {"text": "In this classification task, machine translation techniques are used to remove language gaps in the dataset, but many translation errors occur as a side-effect.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7481229603290558}]}, {"text": "These errors cause a decrease in the review classification performance.", "labels": [], "entities": []}, {"text": "To resolve this problem, we introduce a sentiment-oriented sentence filtering module to the process of multilingual review classification.", "labels": [], "entities": [{"text": "sentiment-oriented sentence filtering", "start_pos": 40, "end_pos": 77, "type": "TASK", "confidence": 0.6090727547804514}, {"text": "multilingual review classification", "start_pos": 103, "end_pos": 137, "type": "TASK", "confidence": 0.7356433471043905}]}, {"text": "Experimental results showed that the proposed method achieved 81.7% classification accuracy for the evaluation data.", "labels": [], "entities": [{"text": "classification", "start_pos": 68, "end_pos": 82, "type": "TASK", "confidence": 0.896082878112793}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9688916802406311}]}], "introductionContent": [{"text": "People can nowadays easily disseminate information including their personal subjective opinions on products and services on the Internet.", "labels": [], "entities": []}, {"text": "The massive amounts of this type of information are beneficial for both product companies and users who are planning to purchase and use the products.", "labels": [], "entities": []}, {"text": "The information is mainly presented in a textual form, so in the research field of natural language processing, many researchers have focused on developing techniques for sentiment analysis (or opinion mining) (.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 83, "end_pos": 110, "type": "TASK", "confidence": 0.6649444003899893}, {"text": "sentiment analysis", "start_pos": 171, "end_pos": 189, "type": "TASK", "confidence": 0.9488784074783325}, {"text": "opinion mining", "start_pos": 194, "end_pos": 208, "type": "TASK", "confidence": 0.7074360698461533}]}, {"text": "One fundamental technique in sentiment analysis (opinion mining) is to classify review texts.", "labels": [], "entities": [{"text": "sentiment analysis (opinion mining)", "start_pos": 29, "end_pos": 64, "type": "TASK", "confidence": 0.814598614970843}]}, {"text": "Unlike the conventional topic-based text classification task, classifiers for review classification must discriminate between positive and negative aspects of opinions in a review text.", "labels": [], "entities": [{"text": "topic-based text classification task", "start_pos": 24, "end_pos": 60, "type": "TASK", "confidence": 0.7254636883735657}, {"text": "review classification", "start_pos": 78, "end_pos": 99, "type": "TASK", "confidence": 0.7437240183353424}]}, {"text": "In the review classification task, supervised machine learning methods such as Naive Bayes and Support Vector Machines have been mostly applied ().", "labels": [], "entities": [{"text": "review classification task", "start_pos": 7, "end_pos": 33, "type": "TASK", "confidence": 0.8202685117721558}]}, {"text": "These supervised approaches have achieved good performance, but they have a crucial issue: they require a large amount of labeled data, which involves the high cost of manual annotation.", "labels": [], "entities": []}, {"text": "Approaches to reduce or avoid the cost of annotation have been proposed, such as semisupervised and substitutional data approaches.", "labels": [], "entities": []}, {"text": "Semi-supervised approaches (e.g., that by Aue and) provide a simple solution by combining labeled and unlabeled data.", "labels": [], "entities": []}, {"text": "Substitutional data approaches provide substitutional labeled data, available at low costs, instead of pure labeled data.", "labels": [], "entities": []}, {"text": "The tasks of domain adaption and multilingual text classification ( are special cases of substitutional approaches.", "labels": [], "entities": [{"text": "domain adaption", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.7317785322666168}, {"text": "multilingual text classification", "start_pos": 33, "end_pos": 65, "type": "TASK", "confidence": 0.6138447721799215}]}, {"text": "In this paper, we examine the effectiveness of applying a sentence filtering module to multilingual document classification, especially to multilingual review classification.", "labels": [], "entities": [{"text": "multilingual document classification", "start_pos": 87, "end_pos": 123, "type": "TASK", "confidence": 0.6323467989762624}, {"text": "multilingual review classification", "start_pos": 139, "end_pos": 173, "type": "TASK", "confidence": 0.7461183071136475}]}, {"text": "In multilingual review classification, machine translation techniques are usually used to remove language gaps in the dataset.", "labels": [], "entities": [{"text": "multilingual review classification", "start_pos": 3, "end_pos": 37, "type": "TASK", "confidence": 0.7782502770423889}, {"text": "machine translation", "start_pos": 39, "end_pos": 58, "type": "TASK", "confidence": 0.7228517383337021}]}, {"text": "But, even if one can use the stateof-the-art machine translation techniques, many translation errors occur as a side-effect.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.7281469404697418}]}, {"text": "These errors cause a decrease in the review classification performance.", "labels": [], "entities": []}, {"text": "In this study, to resolve this problem, we introduce a sentiment-oriented sentence filtering module to the process of multilingual review classification.", "labels": [], "entities": [{"text": "sentiment-oriented sentence filtering", "start_pos": 55, "end_pos": 92, "type": "TASK", "confidence": 0.6093706786632538}, {"text": "multilingual review classification", "start_pos": 118, "end_pos": 152, "type": "TASK", "confidence": 0.7331367234388987}]}, {"text": "we focus on the quality rather than the quantity of the training data, and attempt to filter out some worthless sentences from the dataset.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "First, we provide an overview of multilingual review classification in Section 2.", "labels": [], "entities": [{"text": "multilingual review classification", "start_pos": 33, "end_pos": 67, "type": "TASK", "confidence": 0.7488650480906168}]}, {"text": "In addition, an issue essentially related to the task of multilingual review classification is presented.", "labels": [], "entities": [{"text": "multilingual review classification", "start_pos": 57, "end_pos": 91, "type": "TASK", "confidence": 0.7274742722511292}]}, {"text": "In Section 3, we explain our sentiment-oriented sentence filtering method.", "labels": [], "entities": [{"text": "sentiment-oriented sentence filtering", "start_pos": 29, "end_pos": 66, "type": "TASK", "confidence": 0.7871444622675577}]}, {"text": "In Section 4, we report on our experi- shows an ordinary processing flow of text (review) classification with monolingual data.", "labels": [], "entities": [{"text": "text (review) classification", "start_pos": 76, "end_pos": 104, "type": "TASK", "confidence": 0.6289946794509887}]}, {"text": "Ina monolingual setting, in both the training phase and classification phase, text documents in the dataset are described in the same language (language X in)., in contrast, shows a multilingual setting for review classification.", "labels": [], "entities": [{"text": "review classification", "start_pos": 207, "end_pos": 228, "type": "TASK", "confidence": 0.7376879155635834}]}, {"text": "In this setting, text documents in the classification phase are described in a different language, Y, from X.", "labels": [], "entities": [{"text": "classification phase", "start_pos": 39, "end_pos": 59, "type": "TASK", "confidence": 0.8935630321502686}]}], "datasetContent": [{"text": "We conducted experiments for investigating the effectiveness of applying our sentiment-oriented sentence filtering method to the multilingual review classification.", "labels": [], "entities": [{"text": "sentiment-oriented sentence filtering", "start_pos": 77, "end_pos": 114, "type": "TASK", "confidence": 0.5951422254244486}, {"text": "multilingual review classification", "start_pos": 129, "end_pos": 163, "type": "TASK", "confidence": 0.7150746385256449}]}, {"text": "4.1.1 Multilingual review classification methods Review classification methods that enable handling of multilingual data have been proposed.", "labels": [], "entities": [{"text": "Multilingual review classification", "start_pos": 6, "end_pos": 40, "type": "TASK", "confidence": 0.7595928907394409}]}, {"text": "We adopted those proposed by and in our experiments, since theirs are well-known and standard methods.", "labels": [], "entities": []}, {"text": "Banea's method (2008) has two classification models that are dependent on the running position of the MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 102, "end_pos": 104, "type": "TASK", "confidence": 0.9063130617141724}]}, {"text": "Works on sentiment analysis have usually been carried out in English because there is a large amount of English linguistic resources available for sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 9, "end_pos": 27, "type": "TASK", "confidence": 0.9757752418518066}, {"text": "sentiment analysis", "start_pos": 147, "end_pos": 165, "type": "TASK", "confidence": 0.956060916185379}]}, {"text": "Thus, in this study we set English as a source language and Japanese as a target language.", "labels": [], "entities": []}, {"text": "We collected reviews for use in our experiments from one of the most popular global e-commerce sites, Amazon.", "labels": [], "entities": []}, {"text": "We accessed Amazon.com (\"http://www.amazon.com/\") for English reviews and Amazon.co.jp (\"http://www.amazon.co.jp/\") for Japanese reviews.", "labels": [], "entities": []}, {"text": "First, we prepared a common product list.", "labels": [], "entities": []}, {"text": "This is a list of products that can be purchased through both Amazon.com and Amazon.co.jp.", "labels": [], "entities": [{"text": "Amazon.co.jp", "start_pos": 77, "end_pos": 89, "type": "DATASET", "confidence": 0.9255042672157288}]}, {"text": "We used in this study a list of MP3 audio players, such as \"iPod (Apple)\" and \"Walkman (Sony)\".", "labels": [], "entities": []}, {"text": "Second, we retrieved and crawled a set of reviews by using the above list from Amazon.com and Amazon.co.jp.", "labels": [], "entities": []}, {"text": "All crawled reviews hold an up-to-fivestar user rating.", "labels": [], "entities": []}, {"text": "We regarded reviews holding four or five stars as positive reviews and those holding one or two stars as negative reviews.", "labels": [], "entities": []}, {"text": "As a result, we obtained 1,000 Japanese reviews (500 positive / 500 negative reviews), and 10,000 English reviews (5,000 positive / 5,000 negative reviews).", "labels": [], "entities": []}, {"text": "In our setting, the source language was English.", "labels": [], "entities": []}, {"text": "The volume of English reviews was 10 times that of Japanese ones.", "labels": [], "entities": [{"text": "volume", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9596629738807678}]}, {"text": "All reviews were original, and there were no duplicates.", "labels": [], "entities": []}, {"text": "The experimental results are shown in (see also).", "labels": [], "entities": []}, {"text": "The value in each cell indicates the classification accuracy.", "labels": [], "entities": [{"text": "classification", "start_pos": 37, "end_pos": 51, "type": "TASK", "confidence": 0.9509527087211609}, {"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9760193228721619}]}, {"text": "Each column shows the multilingual review classification method, and each row shows the sentence extraction method in the sentence filtering step.", "labels": [], "entities": [{"text": "multilingual review classification", "start_pos": 22, "end_pos": 56, "type": "TASK", "confidence": 0.6932758986949921}, {"text": "sentence extraction", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.7338324934244156}, {"text": "sentence filtering", "start_pos": 122, "end_pos": 140, "type": "TASK", "confidence": 0.7250503897666931}]}, {"text": "PNWords is the sentence extraction method described in Section 3, i.e., our proposed method.", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.8154919445514679}]}, {"text": "The others are baseline methods for comparison.", "labels": [], "entities": []}, {"text": "WITHOUT means that the sentence filtering step was skipped at the training phase of text classifiers; all sentences in the reviews in the training dataset were used in the training phase.", "labels": [], "entities": [{"text": "WITHOUT", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.7527248859405518}, {"text": "sentence filtering", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.7078859806060791}]}, {"text": "RANDOM means that snippets were generated by randomly extracting K percent of sentences from the original reviews in the dataset.", "labels": [], "entities": [{"text": "RANDOM", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.5534462332725525}]}, {"text": "We set K=50 in the experiments.", "labels": [], "entities": []}, {"text": "Unlike WITHOUT and PNWords, RANDOM had essentially randomness.", "labels": [], "entities": []}, {"text": "Therefore, we prepared five sets of snippets by running RANDOM five times and then measured five accuracy values.", "labels": [], "entities": [{"text": "RANDOM", "start_pos": 56, "end_pos": 62, "type": "DATASET", "confidence": 0.743312656879425}, {"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9989713430404663}]}, {"text": "The average accuracy is shown in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9985532164573669}]}, {"text": "We also developed a system which was trained on documents written in Japanese in order to see what is the accuracy of the system when a MT is not used.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9993084669113159}, {"text": "MT", "start_pos": 136, "end_pos": 138, "type": "TASK", "confidence": 0.9067493081092834}]}, {"text": "The accuracy of this system is 77.9%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9998495578765869}]}, {"text": "To investigate the performances of the three multilingual classification methods, we first ignored the effects of sentence filtering modules and simply compared the accuracies of the first row, i.e., the results obtained by WITHOUT.", "labels": [], "entities": [{"text": "multilingual classification", "start_pos": 45, "end_pos": 72, "type": "TASK", "confidence": 0.7062960863113403}]}, {"text": "shows that the accuracy of Co-training is higher than that of both TrTM and TeTM.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9998366832733154}, {"text": "TeTM", "start_pos": 76, "end_pos": 80, "type": "DATASET", "confidence": 0.8501132130622864}]}, {"text": "Thus, the cotraining model is considered to have an advantage over both TrTM and TeTM.", "labels": [], "entities": [{"text": "TeTM", "start_pos": 81, "end_pos": 85, "type": "DATASET", "confidence": 0.8521794080734253}]}, {"text": "This result corresponds with those reported by.", "labels": [], "entities": []}, {"text": "We confirmed that Wan's co-training method outperforms TrTM and TeTM in a multilingual review classification problem.", "labels": [], "entities": [{"text": "multilingual review classification", "start_pos": 74, "end_pos": 108, "type": "TASK", "confidence": 0.6153878470261892}]}, {"text": "Next, we investigated the effectiveness of the proposed sentence filtering method.", "labels": [], "entities": [{"text": "sentence filtering", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.826627254486084}]}, {"text": "In comparing WITHOUT and RANDOM for each multilingual review classification method, when the sentence filtering step with the RANDOM method was added to the training phase of text classifiers, the classification accuracy worsened rather than improved.", "labels": [], "entities": [{"text": "sentence filtering", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.7121374905109406}, {"text": "accuracy", "start_pos": 212, "end_pos": 220, "type": "METRIC", "confidence": 0.9360349774360657}]}, {"text": "One can see that extracting sentences without thought (namely, at random) does not contribute to improvement of the text classification performance.", "labels": [], "entities": [{"text": "text classification", "start_pos": 116, "end_pos": 135, "type": "TASK", "confidence": 0.7475415468215942}]}, {"text": "Last, in comparing WITHOUT and PNWords, one can see that PNWords outperforms WITHOUT for all the multilingual review classification methods and that the combination of Cotraining and PNWords achieves the best performance.", "labels": [], "entities": []}, {"text": "From the results, we can conclude that our sentiment-oriented sentence filtering method can improve multilingual review classification.", "labels": [], "entities": [{"text": "sentiment-oriented sentence filtering", "start_pos": 43, "end_pos": 80, "type": "TASK", "confidence": 0.6881318092346191}, {"text": "multilingual review classification", "start_pos": 100, "end_pos": 134, "type": "TASK", "confidence": 0.7691356539726257}]}], "tableCaptions": [{"text": " Table 1: Number of English/Japanese polarity words  polarity words  all  positive negative  English  1,392  609  783  Japanese  724  340  384", "labels": [], "entities": []}, {"text": " Table 2: Number of documents/sentences including a polarity word  data type  #documents  #sentences  English 9,738/10,000 (97%) 51,661/82,310 (63%)  EtoJ 8,283/10,000 (83%) 26,424/82,310 (32%)  Japanese  955/ 1,000 (96%) 3,498/ 7,466 (47%)  JtoE  985/ 1,000 (99%)  5,017/ 7,466 (67%)", "labels": [], "entities": [{"text": "EtoJ", "start_pos": 150, "end_pos": 154, "type": "DATASET", "confidence": 0.909285306930542}, {"text": "JtoE  985/ 1,000", "start_pos": 242, "end_pos": 258, "type": "DATASET", "confidence": 0.9223254472017288}]}, {"text": " Table 3: Effects of sentence extraction  TrTM TeTM Co-training  WITHOUT 73.6  73.7  78.4  RANDOM 73.0  69.0  77.5  PNWords  77.0  78.1  81.7", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.7192984223365784}, {"text": "TrTM TeTM Co-training  WITHOUT 73.6  73.7  78.4  RANDOM 73.0  69.0  77.5  PNWords  77.0  78.1  81.7", "start_pos": 42, "end_pos": 141, "type": "DATASET", "confidence": 0.7801895081996918}]}]}