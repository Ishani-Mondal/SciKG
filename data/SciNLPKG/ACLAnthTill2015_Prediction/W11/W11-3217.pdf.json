{"title": [{"text": "Named Entity Transliteration Generation Leveraging Statistical Machine Translation Technology", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 51, "end_pos": 82, "type": "TASK", "confidence": 0.702885627746582}]}], "abstractContent": [{"text": "Automatically identifying that different orthographic variants of names are referring to the same name is a significant challenge for processing natural language processing since they typically constitute the bulk of the out-of-vocabulary tokens.", "labels": [], "entities": [{"text": "processing natural language processing", "start_pos": 134, "end_pos": 172, "type": "TASK", "confidence": 0.6348643824458122}]}, {"text": "The problem is exacerbated when the name is foreign.", "labels": [], "entities": []}, {"text": "In this paper we address the problem of generating valid orthographic variants for proper names, namely transliterat-ing proper names in different scripts.", "labels": [], "entities": []}, {"text": "We attempt to solve the problem for three different language pairs: English \u2192 Hindi, English \u2192 Persian, and Arabic \u2192 English.", "labels": [], "entities": []}, {"text": "We adopt a unified approach to the problem.", "labels": [], "entities": []}, {"text": "We frame the problem from a statistical Machine Translation perspective.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.6886730939149857}]}, {"text": "We further post edit the output applying linguistically informed rules particular to the language pair and re-rank the output using machine learning methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "Ina world of pervasive online media and globalization, we are flooded with streams of events where participants come from allover the world and they spell things in a myriad of ways especially where there are no orthographic standards.", "labels": [], "entities": []}, {"text": "The problem is exacerbated for proper names especially when they are foreign.", "labels": [], "entities": []}, {"text": "There are no standard spellings for such names.", "labels": [], "entities": []}, {"text": "Accordingly orthographic variants are rampant.", "labels": [], "entities": []}, {"text": "People typically rely on some form of phonetic transcription or what is referred to as transliteration.", "labels": [], "entities": []}, {"text": "Humans have no issue identifying variants of names as the same, however for automatic algorithms in general and Natural Language Processing (NLP) in particular, proper name variants constitute a large portion of the out of vocabulary (OOV) phenomenon.", "labels": [], "entities": []}, {"text": "In this paper, we address the problem of generating valid transliterations for proper names in one language into some phonetic transcription (transliteration) in another language.", "labels": [], "entities": []}, {"text": "The problem is not so bad if the two languages are phonetically close, share a script, and there exists an orthographic standard.", "labels": [], "entities": []}, {"text": "However, if the two languages use different orthographic scripts and possess different phonetic inventories, we are faced with a much more complex situation.", "labels": [], "entities": []}, {"text": "We attempt to solve the problem for the latter case, namely for language pairs that are distant and that possess significantly different phonetic inventories.", "labels": [], "entities": []}, {"text": "We target three language pairs: English \u2192 Hindi, English \u2192 Persian, and Arabic \u2192 English.", "labels": [], "entities": []}, {"text": "English uses the Latin script, Arabic uses Arabic script, Persian uses an extended Arabic script to account for 6 extra sounds over Arabic, and Hindi uses Devanagari.", "labels": [], "entities": []}, {"text": "We adopt a unified approach to the problem for the three language pairs.", "labels": [], "entities": []}, {"text": "We leverage a statistical Machine Translation framework to address the problem.", "labels": [], "entities": [{"text": "statistical Machine Translation", "start_pos": 14, "end_pos": 45, "type": "TASK", "confidence": 0.6058600147565206}]}, {"text": "We apply linguistic expansion rules that are tailored for each language pair and transliteration direction.", "labels": [], "entities": []}, {"text": "We view this as a generation problem, and we apply some post hoc filtering techniques to re-rank the output.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our basic approach, we model the problem as a noisy channel problem.", "labels": [], "entities": []}, {"text": "We leverage Phrase Based Statistical Machine Translation (SMT) technology ().", "labels": [], "entities": [{"text": "Phrase Based Statistical Machine Translation (SMT)", "start_pos": 12, "end_pos": 62, "type": "TASK", "confidence": 0.760329581797123}]}, {"text": "Our statistical transliteration system is implemented using Moses(.", "labels": [], "entities": []}, {"text": "Each name is represented as a sentence for training, tuning and decoding.", "labels": [], "entities": []}, {"text": "A name could be composite comprising multiple name units, such as Michael Jackson corresponding to mAykyl jAkswn in Arabic.", "labels": [], "entities": []}, {"text": "Each character is treated as a separate token by the system, and name boundaries are marked using special characters.", "labels": [], "entities": []}, {"text": "Accordingly, the sentence pair for the name Michael Jackson and it's Arabic counterpart will be represented as follows to the SMT system for training and tuning: mi ch a e l # j ac k so n corresponding tom A y k y l # j A k s w n.) is used for building alignments between name pairs.", "labels": [], "entities": [{"text": "SMT", "start_pos": 126, "end_pos": 129, "type": "TASK", "confidence": 0.9883577227592468}]}, {"text": "For all the language pairs, the language scripts are represented in UTF-8 encoding.", "labels": [], "entities": []}, {"text": "We further improve the output of the MT system by applying some language specific post-processing techniques.", "labels": [], "entities": [{"text": "MT", "start_pos": 37, "end_pos": 39, "type": "TASK", "confidence": 0.9819574356079102}]}, {"text": "The following sub-sections describe those techniques for each language pair.", "labels": [], "entities": []}, {"text": "All the techniques (except section 4.3.1) essentially expand the output given by our SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 85, "end_pos": 88, "type": "TASK", "confidence": 0.9882686138153076}]}, {"text": "Since the methods of expansion yield large numbers of output candidates, a filtering technique is used to be able to distinguish the correct transliterations from the incorrect ones.", "labels": [], "entities": []}, {"text": "We build a binary classifier that labels each candidate transliteration as corrector incorrect.", "labels": [], "entities": []}, {"text": "We employ two features in training: a language model (LM) log probability for each name from the target side of the training data corpus to ensure that the generated candidate is a fluent target name; the second feature is the string edit distance of each candidate from its nearest name obtained from direct mapping.", "labels": [], "entities": [{"text": "language model (LM) log probability", "start_pos": 38, "end_pos": 73, "type": "METRIC", "confidence": 0.6672031283378601}]}, {"text": "This second feature is a measure of how much the candidate has changed due to expansion.", "labels": [], "entities": []}, {"text": "The filtering classifier is applied to the expanded data.", "labels": [], "entities": []}, {"text": "The training data is synthetically generated from expanding the candidates according to the linguistic rules.", "labels": [], "entities": []}, {"text": "We label the training data as correct and the expanded data as incorrect.", "labels": [], "entities": []}, {"text": "To make sure that incorrect expansions do not overwhelm correct transliterations, we remove some incorrect candidates from the training data for the classifier.", "labels": [], "entities": []}, {"text": "The official task training data was directly used for training.", "labels": [], "entities": []}, {"text": "The official task development data was split into two equal parts, with half the data being used for tuning the system and the other half for initial testing (Dev).", "labels": [], "entities": []}, {"text": "We report results of our systems on both the Dev and the official shared task Test data.", "labels": [], "entities": [{"text": "Dev", "start_pos": 45, "end_pos": 48, "type": "DATASET", "confidence": 0.8923631310462952}, {"text": "official shared task Test data", "start_pos": 57, "end_pos": 87, "type": "DATASET", "confidence": 0.6389687597751618}]}, {"text": "Details of the data used, their sizes and sources can be found in the Task Organizer's Whitepaper (TOW) (Zhang et al, 2011).", "labels": [], "entities": [{"text": "Task Organizer's Whitepaper (TOW) (Zhang et al, 2011)", "start_pos": 70, "end_pos": 123, "type": "DATASET", "confidence": 0.7029287538358143}]}, {"text": "contains the results of our system on English-Hindi.", "labels": [], "entities": []}, {"text": "The metrics used Accuracy, Fscore, MRR and MAP are described in detail in TOW.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9993921518325806}, {"text": "Fscore", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9991539716720581}, {"text": "MRR", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.9948766827583313}, {"text": "MAP", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.9977620840072632}, {"text": "TOW", "start_pos": 74, "end_pos": 77, "type": "DATASET", "confidence": 0.9512430429458618}]}, {"text": "The first set of results is of SMT output containing the top translation candidate for each source name (H-1best SMT).", "labels": [], "entities": [{"text": "SMT", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9895535707473755}, {"text": "H-1best SMT", "start_pos": 105, "end_pos": 116, "type": "TASK", "confidence": 0.43264611065387726}]}, {"text": "H-Nbest SMT corresponds to the output containing 10 top ranked transliterations per source language name.", "labels": [], "entities": [{"text": "H-Nbest SMT", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.456113800406456}]}, {"text": "H-SMT+exp and H-SMT+exp illustrate the results after application of the two expansion rules described in Section 4.1 on the Dev and Test data respectively.", "labels": [], "entities": []}, {"text": "The results clearly indicate that yielding more candidates results in better performance, i.e. returning N-best results is better that the top result (N-best is better than 1-best), improving the overall accuracy, F score, MRR and MAP for the system as a whole.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 204, "end_pos": 212, "type": "METRIC", "confidence": 0.9992765784263611}, {"text": "F score", "start_pos": 214, "end_pos": 221, "type": "METRIC", "confidence": 0.9911369979381561}, {"text": "MRR", "start_pos": 223, "end_pos": 226, "type": "METRIC", "confidence": 0.9985625147819519}, {"text": "MAP", "start_pos": 231, "end_pos": 234, "type": "METRIC", "confidence": 0.99892657995224}]}, {"text": "Moreover, applying expansion rules in the form of our devised linguistic rules significantly improves the quality of transliterations for the dev set on nearly all metrics except for MAP, (H-SMT+exp) outperforms (n-best H-SMT).", "labels": [], "entities": [{"text": "MAP", "start_pos": 183, "end_pos": 186, "type": "METRIC", "confidence": 0.7914238572120667}]}, {"text": "We note a significant drop inaccuracy between the Dev and Test data, however we see an improvement for the MAP metric.", "labels": [], "entities": [{"text": "Dev and Test data", "start_pos": 50, "end_pos": 67, "type": "DATASET", "confidence": 0.6232930272817612}, {"text": "MAP", "start_pos": 107, "end_pos": 110, "type": "METRIC", "confidence": 0.6032567620277405}]}, {"text": "3 shows three sets of results for EnglishPersian task.", "labels": [], "entities": [{"text": "EnglishPersian task", "start_pos": 34, "end_pos": 53, "type": "DATASET", "confidence": 0.8437718749046326}]}, {"text": "The first set is 10-best results from SMT system (P-SMT), without any expansion.", "labels": [], "entities": [{"text": "SMT", "start_pos": 38, "end_pos": 41, "type": "TASK", "confidence": 0.987612783908844}]}, {"text": "P-SMT+exp and P-SMT+exp correspond to the output of Dev and Test, respectively, as expanded using rules described in sec- 0.387 0.860 0.516 0.387 P-SMT 0.575 0.920 0.587 0.481 P-SMT+exp 0.710 0.953 0.725 0.339 P-SMT+exp 0.606 0.933 0.697 0.589: English-Hindi and English-Persian results tion 4.2.", "labels": [], "entities": []}, {"text": "Clearly, these rules significantly improve the quality of the transliterations on the Dev set for all metrics.", "labels": [], "entities": [{"text": "Dev set", "start_pos": 86, "end_pos": 93, "type": "DATASET", "confidence": 0.7746994197368622}]}, {"text": "We note a similar trend to the EnglishHindi results with a significant drop inaccuracy, F-score, MRR between the Dev and Test data, however we see an improvement for the MAP metric.", "labels": [], "entities": [{"text": "EnglishHindi", "start_pos": 31, "end_pos": 43, "type": "DATASET", "confidence": 0.9043294787406921}, {"text": "F-score", "start_pos": 88, "end_pos": 95, "type": "METRIC", "confidence": 0.9984835982322693}, {"text": "MRR", "start_pos": 97, "end_pos": 100, "type": "METRIC", "confidence": 0.9984764456748962}, {"text": "Test data", "start_pos": 121, "end_pos": 130, "type": "DATASET", "confidence": 0.758007675409317}]}, {"text": "For Arabic-English, illustrates the results of the different conditions: 1.", "labels": [], "entities": []}, {"text": "the direct mapping as described in section 4.3.1 for Dev; 2.", "labels": [], "entities": []}, {"text": "DirectMap with vowel expansion of the Dev (DirectMap+vow-exp); conditions 3, 5, and 8. are SMT N-best conditions for Dev data; conditions 4, 6, 9 and 11 are N-Best results for Dev and Test data; finally, conditions 7, 10 and 12 present the results after applying filtering to the output of the SMT expanded system for both Dev and Test data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 91, "end_pos": 94, "type": "TASK", "confidence": 0.9036758542060852}, {"text": "SMT", "start_pos": 294, "end_pos": 297, "type": "TASK", "confidence": 0.8855052590370178}]}, {"text": "We use three thresholds for N in the N Best conditions: 10, 40 and 150.", "labels": [], "entities": []}, {"text": "The Direct Map results in the worst performing conditions, however we do note relative improvement from DirectMap to DirectMap+vow-exp across the 4 metrics indicating that vowel expansion is a good move for this language pair.", "labels": [], "entities": [{"text": "vowel expansion", "start_pos": 172, "end_pos": 187, "type": "TASK", "confidence": 0.6866130828857422}]}, {"text": "Using SMT for transliteration improves significantly over Direct Mapping as illustrated by the relative improvement of condition 3 (10-best) over condition 2 DirectMap+vow-exp.", "labels": [], "entities": [{"text": "Direct Mapping", "start_pos": 58, "end_pos": 72, "type": "TASK", "confidence": 0.6731411069631577}]}, {"text": "Increasing the number of returned N Best results from 10 to 40 and subsequently to 150 shows significant improvement comparing conditions 3, 5, and 8.", "labels": [], "entities": [{"text": "N Best", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9350509643554688}]}, {"text": "Further applying vowel expansion shows consistent improvement in performance in conditions 4, 6, and 9.", "labels": [], "entities": [{"text": "vowel expansion", "start_pos": 17, "end_pos": 32, "type": "TASK", "confidence": 0.6382619738578796}]}, {"text": "We further applied filtering to the resulting output however this did not yield improvements in the results as illustrated in conditions 7 40-best+vow-exp+filt and 10 150-best+vow-exp+filt, however, filtering helped prune the 100s of outputs generated from the vowel expansion step in smart ways.", "labels": [], "entities": []}, {"text": "In fact we note that on the Test data the difference between condition 11) and 12 (150-best+vow-exp+filt) is not that significant, though 11 yields higher results.", "labels": [], "entities": [{"text": "Test data", "start_pos": 28, "end_pos": 37, "type": "DATASET", "confidence": 0.8383512794971466}]}], "tableCaptions": [{"text": " Table 1: English-Hindi and English-Persian re- sults", "labels": [], "entities": [{"text": "sults", "start_pos": 48, "end_pos": 53, "type": "TASK", "confidence": 0.31809747219085693}]}, {"text": " Table 2: Arabic-English -Transliteration Results", "labels": [], "entities": []}]}