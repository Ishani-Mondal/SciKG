{"title": [{"text": "Gibbs Sampling with Treeness Constraint in Unsupervised Dependency Parsing", "labels": [], "entities": [{"text": "Sampling", "start_pos": 6, "end_pos": 14, "type": "TASK", "confidence": 0.8643215298652649}, {"text": "Parsing", "start_pos": 67, "end_pos": 74, "type": "TASK", "confidence": 0.4532371163368225}]}], "abstractContent": [{"text": "This paper presents a work in progress on the task of unsupervised parsing, following the mainstream approach of optimizing the overall probability of the corpus.", "labels": [], "entities": []}, {"text": "We evaluate a sequence of experiments for Czech with various modifications of corpus initiation, of dependency edge probability model and of sampling procedure , stressing especially the treeness constraint.", "labels": [], "entities": []}, {"text": "The best configuration is then applied to 19 languages from CoNLL-2006 and CoNLL-2007 shared tasks.", "labels": [], "entities": [{"text": "CoNLL-2006", "start_pos": 60, "end_pos": 70, "type": "DATASET", "confidence": 0.9567689895629883}]}, {"text": "Our best achieved results are comparable to the state of the art in dependency parsing and outperform the previously published results for many languages.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.869873583316803}]}], "introductionContent": [{"text": "Unsupervised approaches receive considerably growing attention in NLP in the last years, and dependency parsing is not an exception.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.86602383852005}]}, {"text": "In recent years, quite a lot of works in unsupervised parsing (or grammar induction) was based on Dependency Model with Valence (DMV) introduced by; and) has focused on DMV variants, () introduced extended valency model (EVG) and added lexicalization and smoothing.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 66, "end_pos": 83, "type": "TASK", "confidence": 0.6962700486183167}]}, {"text": "() used punctuation marks for splitting a sentence and impose parsing restrictions over its fragments.", "labels": [], "entities": []}, {"text": "Gibbs sampling was used in).", "labels": [], "entities": []}, {"text": "Some of the papers focused on English only, but some presented the results across wide rage of languages.", "labels": [], "entities": []}, {"text": "The last such paper was (, where the evaluation was done on all 19 languages included in CoNLL shared tasks) and ().", "labels": [], "entities": []}, {"text": "The attachment scores are very high for English, for which the methods seems to be optimized, but the scores are quite low for some other languages.", "labels": [], "entities": [{"text": "attachment", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.8752235174179077}]}, {"text": "In this paper, we describe our new approach to unsupervised dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.7369323670864105}]}, {"text": "Unlike DMV, it is not based on constituency trees, which cannot handle non-projectivities.", "labels": [], "entities": []}, {"text": "We have been inspired rather by the experiment described in, in which the dependency parsing task is formulated as a problem of word alignment; every sentence is aligned with itself with one constraint: no word can be attached to itself.", "labels": [], "entities": [{"text": "dependency parsing task", "start_pos": 74, "end_pos": 97, "type": "TASK", "confidence": 0.81461101770401}, {"text": "word alignment", "start_pos": 128, "end_pos": 142, "type": "TASK", "confidence": 0.7240697890520096}]}, {"text": "However, unlike, where the output structures might not be trees and could contain cycles, we introduce a sampling method with the acyclicity constraint.", "labels": [], "entities": []}, {"text": "Our approach attempts at optimizing the overall probability of tree structures given the corpus.", "labels": [], "entities": []}, {"text": "We perform the optimization using Gibbs sampling (.", "labels": [], "entities": []}, {"text": "This is done without determining which part-of-speech tag is what.", "labels": [], "entities": []}, {"text": "All experiments are evaluated in detail using Czech data.", "labels": [], "entities": [{"text": "Czech data", "start_pos": 46, "end_pos": 56, "type": "DATASET", "confidence": 0.8251917660236359}]}, {"text": "The configuration which performs best for Czech is applied also on other languages available in the CoNLL shared task corpora () and (.", "labels": [], "entities": [{"text": "CoNLL shared task corpora", "start_pos": 100, "end_pos": 125, "type": "DATASET", "confidence": 0.8118671923875809}]}, {"text": "Our goal is to achieve good results across various languages without tuning the parser individually for each language, so we use the other language data exclusively for evaluation purposes.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section describes the ways of initialization, and how the final dependency trees are built from sampling.", "labels": [], "entities": [{"text": "initialization", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.9643820524215698}]}, {"text": "As in other unsupervised tasks (e.g. in unsupervised POS induction), there is a little consensus on evaluation measures.", "labels": [], "entities": [{"text": "POS induction)", "start_pos": 53, "end_pos": 67, "type": "TASK", "confidence": 0.8930034240086874}]}, {"text": "Performance of unsupervised methods is often measured by comparing the induced outputs with gold standard manual annotations.", "labels": [], "entities": []}, {"text": "However, this approach causes a general problem: manual annotation is inevitably guided by a number of conventions, such as the traditional POS categories in unsupervised POS tagging, or varying (often linguistically controversial) conventions for local tree shapes representing e.g. complex verb forms in unsupervised dependency parsing.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 171, "end_pos": 182, "type": "TASK", "confidence": 0.5903781056404114}]}, {"text": "It is obvious that using unlabeled attachment scores (UAS) leads to a strong bias towards such conventions and it might not be a good indicator of unsupervised parsing improvements.", "labels": [], "entities": [{"text": "unlabeled attachment scores (UAS)", "start_pos": 25, "end_pos": 58, "type": "METRIC", "confidence": 0.7875092675288519}]}, {"text": "Therefore we estimate parsing quality by two additional metrics: \u2022 UUAS -undirected UAS (edge direction is disregarded), \u2022 NED -neutral edge direction, introduced in (), which treats not only a node's gold parent and child as the correct answer, but also its gold grandparent.", "labels": [], "entities": [{"text": "parsing", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.9748697280883789}, {"text": "UUAS -undirected UAS", "start_pos": 67, "end_pos": 87, "type": "METRIC", "confidence": 0.6562079414725304}]}], "tableCaptions": [{"text": " Table 1: Lower and upper bounds for unsuper- vised parsing of Czech based on reduced POS  tags.", "labels": [], "entities": [{"text": "parsing of Czech", "start_pos": 52, "end_pos": 68, "type": "TASK", "confidence": 0.7566928068796793}]}, {"text": " Table 2: Evaluation of different configurations of the unsupervised parser for Czech.", "labels": [], "entities": []}, {"text": " Table 3: UAS for individual coarse-grained Czech  POS tags. The \"Err.\" column shows the percent- age of errors on the whole corpus.", "labels": [], "entities": [{"text": "UAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.7790495157241821}, {"text": "Czech  POS tags", "start_pos": 44, "end_pos": 59, "type": "DATASET", "confidence": 0.8655343651771545}, {"text": "Err.", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.9980329871177673}, {"text": "percent- age of errors", "start_pos": 89, "end_pos": 111, "type": "METRIC", "confidence": 0.757422685623169}]}]}