{"title": [{"text": "Dialect Translation: Integrating Bayesian Co-segmentation Models with Pivot-based SMT", "labels": [], "entities": [{"text": "Dialect Translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.892040491104126}, {"text": "SMT", "start_pos": 82, "end_pos": 85, "type": "TASK", "confidence": 0.7662287354469299}]}], "abstractContent": [{"text": "Recent research on multilingual statistical machine translation (SMT) focuses on the usage of pivot languages in order to overcome resource limitations for certain language pairs.", "labels": [], "entities": [{"text": "multilingual statistical machine translation (SMT)", "start_pos": 19, "end_pos": 69, "type": "TASK", "confidence": 0.7355291843414307}]}, {"text": "This paper proposes anew method to translate a dialect language into a foreign language by integrating transliteration approaches based on Bayesian co-segmentation (BCS) models with pivot-based SMT approaches.", "labels": [], "entities": [{"text": "SMT", "start_pos": 194, "end_pos": 197, "type": "TASK", "confidence": 0.9458934664726257}]}, {"text": "The advantages of the proposed method with respect to standard SMT approaches are three fold: (1) it uses a standard language as the pivot language and acquires knowledge about the relation between dialects and the standard language automatically, (2) it reduces the translation task complexity by using monotone decoding techniques, (3) it reduces the number of features in the log-linear model that have to be estimated from bilingual data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.988926887512207}, {"text": "translation task", "start_pos": 267, "end_pos": 283, "type": "TASK", "confidence": 0.8857118189334869}]}, {"text": "Experimental results translating four Japanese dialects (Kumamoto, Kyoto, Okinawa, Os-aka) into four Indo-European languages (En-glish, German, Russian, Hindi) and two Asian languages (Chinese, Korean) revealed that the proposed method improves the translation quality of dialect translation tasks and outper-forms standard pivot translation approaches concatenating SMT engines for the majority of the investigated language pairs.", "labels": [], "entities": [{"text": "dialect translation tasks", "start_pos": 272, "end_pos": 297, "type": "TASK", "confidence": 0.8202159603436788}, {"text": "SMT", "start_pos": 367, "end_pos": 370, "type": "TASK", "confidence": 0.990481972694397}]}], "introductionContent": [{"text": "The translation quality of SMT approaches heavily depends on the amount and coverage of the bilingual language resources available to train the statistical models.", "labels": [], "entities": [{"text": "SMT", "start_pos": 27, "end_pos": 30, "type": "TASK", "confidence": 0.9935495257377625}]}, {"text": "There are several data collection initiatives 1 amassing and distributing large amounts of textual data.", "labels": [], "entities": []}, {"text": "For frequently used language pairs like French-English, large-sized text data sets are readily available.", "labels": [], "entities": []}, {"text": "However, for less frequently used language pairs, only a limited amount of bilingual resources are available, if any at all.", "labels": [], "entities": []}, {"text": "In order to overcome language resource limitations, recent research on multilingual SMT focuses on the use of pivot languages (de).", "labels": [], "entities": [{"text": "multilingual SMT", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.552966758608818}]}, {"text": "Instead of a direct translation between two languages where only a limited amount of bilingual resources is available, the pivot translation approach makes use of a third language that is more appropriate due to the availability of more bilingual corpora and/or its relatedness to the source/target language.", "labels": [], "entities": [{"text": "pivot translation", "start_pos": 123, "end_pos": 140, "type": "TASK", "confidence": 0.7681088447570801}]}, {"text": "In most of the previous research, English has been the pivot language of choice due to the richness of available language resources.", "labels": [], "entities": []}, {"text": "However, recent research on pivot translation has shown that the usage of non-English pivot languages can improve translation quality of certain language pairs, especially when translating from or into Asian languages (.", "labels": [], "entities": [{"text": "pivot translation", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.8114840090274811}]}, {"text": "This paper focuses on the translation of dialects, i.e., a variety of a language that is characteristic of a particular group of the language's speakers, into a foreign language.", "labels": [], "entities": [{"text": "translation of dialects, i.e., a variety of a language that is characteristic of a particular group of the language's speakers", "start_pos": 26, "end_pos": 152, "type": "Description", "confidence": 0.8007287499697312}]}, {"text": "A standard dialect (or standard language) is a dialect that is recognized as the \"correct\" spoken and written form of the language.", "labels": [], "entities": []}, {"text": "Dialects typically differ in terms of morphology, vocabulary and pronunciation.", "labels": [], "entities": []}, {"text": "Various methods have been proposed to measure relatedness between dialects using phonetic distance measures), string distance algorithms, or statistical models.", "labels": [], "entities": []}, {"text": "Concerning data-driven natural language processing (NLP) applications like machine translation (MT), however, linguistic resources and tools usually are available for the standard language, but not for dialects.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 75, "end_pos": 99, "type": "TASK", "confidence": 0.8651502728462219}]}, {"text": "In order to create dialect language resources, previous research utilized explicit knowledge about the relation between the standard language and the dialect using rule-based and statistical models.", "labels": [], "entities": []}, {"text": "In addition, applying the linguistic tools for the standard language to dialect resources is often insufficient.", "labels": [], "entities": []}, {"text": "For example, the task of word segmentation, i.e., the identification of word boundaries in continuous text, is one of the fundamental preprocessing steps of MT applications.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 25, "end_pos": 42, "type": "TASK", "confidence": 0.7326745837926865}, {"text": "identification of word boundaries in continuous text", "start_pos": 54, "end_pos": 106, "type": "TASK", "confidence": 0.8573557904788426}, {"text": "MT", "start_pos": 157, "end_pos": 159, "type": "TASK", "confidence": 0.9908667802810669}]}, {"text": "In contrast to Indo-European languages like English, many Asian languages like Japanese do not use a whitespace character to separate meaningful word units.", "labels": [], "entities": []}, {"text": "However, the application of a linguistically motivated standard language word segmentation tool to a dialect corpus results in a poor segmentation quality due to morphological differences in verbs and adjectives, thus resulting in a lower translation quality for SMT systems that acquire the translation knowledge automatically from a parallel text corpus.", "labels": [], "entities": [{"text": "SMT", "start_pos": 263, "end_pos": 266, "type": "TASK", "confidence": 0.9918067455291748}]}, {"text": "This paper differs from previous research in the following aspects: \u2022 it reduces the data sparseness problem of direct translation approaches by translating a resource-limited dialect language into a foreign language by using the resource-rich standard language as the pivot language.", "labels": [], "entities": [{"text": "direct translation", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.7360266149044037}]}, {"text": "\u2022 it is language independent and acquires knowledge about the relation between the standard language and the dialect automatically.", "labels": [], "entities": []}, {"text": "\u2022 it avoids segmentation mismatches between the input and the translation model by mapping the characterized dialect language, i.e., each character is treated as a single token, to the word segmentation of the standard language using a Bayesian co-segmentation model.", "labels": [], "entities": []}, {"text": "\u2022 it reduces the translation task complexity by using monotone decoding techniques.", "labels": [], "entities": [{"text": "translation task", "start_pos": 17, "end_pos": 33, "type": "TASK", "confidence": 0.9164783358573914}]}, {"text": "\u2022 it reduces the number of features in the loglinear model that have to be estimated from bilingual data.", "labels": [], "entities": []}, {"text": "The details of the proposed dialect translation method are described in Section 2.", "labels": [], "entities": [{"text": "dialect translation", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.7650709450244904}]}, {"text": "Experiments were carried out for the translation of four Japanese dialects (Kumamoto, Kyoto, Okinawa, Osaka) into four Indo-European languages (English, German, Russian, Hindi) and two Asian languages (Chinese, Korean).", "labels": [], "entities": []}, {"text": "The utilized language resources and the outline of the experiments are summarized in Section 3.", "labels": [], "entities": []}, {"text": "The results reveal that the integration of Bayesian co-segmentation models with pivot-based SMT improves the translation quality of dialect to foreign language translation tasks and that the proposed system outperforms standard pivot translation approaches concatenating SMT engines that translate the dialect into the standard language and the standard language MT output into the foreign language for the majority of the investigated language pairs.", "labels": [], "entities": [{"text": "SMT", "start_pos": 92, "end_pos": 95, "type": "TASK", "confidence": 0.9607185125350952}, {"text": "SMT", "start_pos": 271, "end_pos": 274, "type": "TASK", "confidence": 0.9779938459396362}]}], "datasetContent": [{"text": "The effects of integrating Bayesian co-segmentation models with pivot-based SMT are investigated using the Basic Travel Expressions Corpus (BTEC), which is a collection of sentences that bilingual travel experts consider useful for people traveling abroad ().", "labels": [], "entities": [{"text": "SMT", "start_pos": 76, "end_pos": 79, "type": "TASK", "confidence": 0.950925886631012}]}, {"text": "For the dialect translation experiments, we selected Japanese (ja), a language that does not naturally separate word units, and the dialects from the Kumamoto (ja ku ), Kyoto (ja ky ), Okinawa (ja ok ), and Osaka (ja os ) areas.", "labels": [], "entities": [{"text": "dialect translation", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.7582330703735352}]}, {"text": "All dialects share the same Japanese writing system that combines logographic Chinese characters and two syllabic scripts, i.e., hiragana (used for native Japanese words) and katakana (used for foreign loanwords or onomatopoeia).", "labels": [], "entities": []}, {"text": "For the target language, we investigated four Indo-European languages, i.e., English (en), German (de), Russian (ru), and Hindi (hi) and two Asian languages, i.e., Chinese (zh) and Korean (ko).", "labels": [], "entities": []}, {"text": "The corpus statistics are summarized in, where Voc specifies the vocabulary size and Len the average sentence length of the respective data sets.", "labels": [], "entities": []}, {"text": "These languages differ largely in word order (Order: subject-object-verb (SOV), subject-verb-object (SVO)), segmentation unit (Unit: phrase, word, none), and degree of inflection (Infl: high, moderate, light).", "labels": [], "entities": []}, {"text": "Concerning word segmentation, the corpora were preprocessed using languagespecific word segmentation tools that are widelyaccepted within the MT community for languages that do not use white spaces to separate word/phrase tokens, i.e., CHASEN 4 for Japanese and ICTCLAS for Chinese.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.7347290366888046}, {"text": "languagespecific word segmentation", "start_pos": 66, "end_pos": 100, "type": "TASK", "confidence": 0.6864806413650513}]}, {"text": "For all other languages, simple tokenization tools were applied.", "labels": [], "entities": []}, {"text": "All data sets were case-sensitive with punctuation marks preserved.", "labels": [], "entities": []}, {"text": "The language resources were randomly split into three subsets for the evaluation of translation quality (eval, 1k sentences), the tuning of the SMT model weights (dev, 1k sentences) and the training of the statistical models (train, 160k sentences).", "labels": [], "entities": [{"text": "SMT", "start_pos": 144, "end_pos": 147, "type": "TASK", "confidence": 0.9766072630882263}]}, {"text": "For the dialect languages, a subset of 20k sentences was used for the training of translation models for all of the resource-limited language pairs.", "labels": [], "entities": []}, {"text": "In order to avoid word segmentation errors from the standard language segmentation tool beeing applied to dialect resources, these models are trained on bitext, where the local dialect source sentence is characterized and the target language is segmented using languagespecific segmentation tools.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 18, "end_pos": 35, "type": "TASK", "confidence": 0.7196487039327621}]}, {"text": "For the training of the SMT models, standard word alignment and language modeling) tools were used.", "labels": [], "entities": [{"text": "SMT", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9957341551780701}, {"text": "word alignment", "start_pos": 45, "end_pos": 59, "type": "TASK", "confidence": 0.7529676258563995}]}, {"text": "Minimum error rate training (MERT) was used to tune the decoder's parameters on the dev set using the technique proposed in.", "labels": [], "entities": [{"text": "Minimum error rate training (MERT", "start_pos": 0, "end_pos": 33, "type": "METRIC", "confidence": 0.7959746817747752}]}, {"text": "For the translation, an inhouse multi-stack phrase-based decoder was used.", "labels": [], "entities": [{"text": "translation", "start_pos": 8, "end_pos": 19, "type": "TASK", "confidence": 0.9885947704315186}]}, {"text": "For the evaluation of translation quality, we applied the standard automatic evaluation metric BLEU, which calculates the geometric mean of ngram precision by the system output with respect to reference translations with the addition of a brevity penalty to punish short sentences.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.9358564019203186}, {"text": "precision", "start_pos": 146, "end_pos": 155, "type": "METRIC", "confidence": 0.5375630259513855}]}, {"text": "Scores range between 0 (worst) and 1 (best) ().", "labels": [], "entities": []}, {"text": "For the experiments reported here, single translation references were used.", "labels": [], "entities": []}, {"text": "summarizes the translation performance of the SMT engines used to directly translate the source language dialects into the foreign language.", "labels": [], "entities": [{"text": "SMT", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9811651706695557}]}, {"text": "For the large training data condition (160k), the highest BLEU scores are obtained for the translation of Japanese into Korean followed by English, German, Russian, and Hindi with Chinese seeming to be the most difficult translation task out of the investigated target languages.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9993789196014404}, {"text": "translation of Japanese into Korean", "start_pos": 91, "end_pos": 126, "type": "TASK", "confidence": 0.8840144753456116}]}, {"text": "For the standard language (ja), the translation quality for the small data condition (20k) that corresponds to the language resources used for the translation of the dialect languages is also given.", "labels": [], "entities": []}, {"text": "For the Asian target languages, gains of 11%\u223c14% BLEU points are obtained when increasing the training data size from 20k to 160k.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 49, "end_pos": 53, "type": "METRIC", "confidence": 0.999554455280304}]}, {"text": "However, an even larger increase (24%\u223c27% BLEU points) in translation quality can be seen for all Indo-European target languages.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.9991093277931213}, {"text": "translation", "start_pos": 58, "end_pos": 69, "type": "TASK", "confidence": 0.9462469816207886}]}, {"text": "Therefore, larger gains are to be expected when the pivot translation framework is applied to the translation of dialect languages into Indo-European languages compared to Asian target languages.", "labels": [], "entities": []}, {"text": "Comparing the evaluation results for the small training data condition, the highest scores are achieved for the standard language for all target languages, indicating the difficulty in translating the dialects.", "labels": [], "entities": []}, {"text": "Moreover, the Kumamoto dialect seems to be the easiest task, followed by the Kyoto dialect and the Osaka dialect.", "labels": [], "entities": []}, {"text": "The lowest BLEU scores were obtained for the translation of the Okinawa dialect.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9996192455291748}, {"text": "translation", "start_pos": 45, "end_pos": 56, "type": "TASK", "confidence": 0.9830569624900818}, {"text": "Okinawa dialect", "start_pos": 64, "end_pos": 79, "type": "DATASET", "confidence": 0.6539649367332458}]}], "tableCaptions": [{"text": " Table 2: SMT-based Direct Translation Quality", "labels": [], "entities": [{"text": "SMT-based Direct Translation", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.9015547037124634}]}, {"text": " Table 3: SMT-based Pivot Translation Quality", "labels": [], "entities": [{"text": "SMT-based Pivot Translation", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.8976355393727621}]}, {"text": " Table 4: Dialect to Standard Language Transduction", "labels": [], "entities": [{"text": "Dialect to Standard Language Transduction", "start_pos": 10, "end_pos": 51, "type": "TASK", "confidence": 0.6970589816570282}]}, {"text": " Table 5: BCS-based Pivot Translation Quality", "labels": [], "entities": [{"text": "BCS-based Pivot Translation", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.6106792291005453}]}, {"text": " Table 6: Gains of BCS-based Pivot Translation", "labels": [], "entities": [{"text": "BCS-based Pivot Translation", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.6141193012396494}]}]}