{"title": [{"text": "Reestimation of Reified Rules in Semiring Parsing and Biparsing", "labels": [], "entities": [{"text": "Reestimation", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.9535524845123291}, {"text": "Semiring Parsing", "start_pos": 33, "end_pos": 49, "type": "TASK", "confidence": 0.948873907327652}, {"text": "Biparsing", "start_pos": 54, "end_pos": 63, "type": "TASK", "confidence": 0.5889726281166077}]}], "abstractContent": [{"text": "We show that reifying the rules from hyper-edge weights to first-class graph nodes automatically gives us rule expectations in any kind of grammar expressible as a deductive system, without any explicit algorithm for calculating rule expectations (such as the inside-outside algorithm).", "labels": [], "entities": []}, {"text": "This gives us expectation maximization training for any grammar class with a parsing algorithm that can be stated as a deductive system, for free.", "labels": [], "entities": [{"text": "expectation maximization", "start_pos": 14, "end_pos": 38, "type": "TASK", "confidence": 0.7216932773590088}]}, {"text": "Having such a framework in place accelerates turnover time for experimenting with new grammar classes and parsing algorithms-to implement a grammar learner, only the parse forest construction has to be implemented.", "labels": [], "entities": []}], "introductionContent": [{"text": "We propose contextual probability as a quantity that measures how often something has been used in a corpus, and when calculated for rules, it gives us everything needed to calculate rule expectations for expectation maximization.", "labels": [], "entities": []}, {"text": "For labeled spans in context-free parses, this quantity is called outside probability, and in semiring (bi-) parsing, it is called reverse value.", "labels": [], "entities": []}, {"text": "The inside-outside algorithm for reestimating context-free grammar rules uses this quantity for the symbols occurring in the parse forest.", "labels": [], "entities": []}, {"text": "Generally, the contextual probability is: The contextual probability of something is the sum of the probabilities of all contexts where it was used.", "labels": [], "entities": []}, {"text": "For symbols participating in a parse, we could state it like this: The contextual probability of an item is the sum of the probabilities of all contexts where it was used.", "labels": [], "entities": []}, {"text": "which is exactly what we mean with outside probability.", "labels": [], "entities": []}, {"text": "In semiring (bi-) parsing, this quantity is called reverse value, but in this framework it is also defined for rules, which means that we could restate our boxed statement as: The contextual probability of a rule is the sum of the probabilities of all contexts where it was used.", "labels": [], "entities": [{"text": "semiring (bi-) parsing", "start_pos": 3, "end_pos": 25, "type": "TASK", "confidence": 0.6093015193939209}]}, {"text": "This opens up an interesting line of inquiry into what this quantity might represent.", "labels": [], "entities": []}, {"text": "In this paper we show that the contextual probabilities of the rules contain precisely the new information needed in order to calculate the expectations needed to reestimate the rule probabilities.", "labels": [], "entities": []}, {"text": "This line of inquiry was discovered while working on a preterminalized version of linear inversion transduction grammars (LITGs), so we will use these preterminalized as an example throughout this paper.", "labels": [], "entities": [{"text": "linear inversion transduction grammars (LITGs)", "start_pos": 82, "end_pos": 128, "type": "TASK", "confidence": 0.788847735949925}]}, {"text": "We will start by examining semiring parsing (parsing as deductive systems over semirings, Section 3), followed by a section on how this relates to weighted hypergraphs, a common representation of parse forests.", "labels": [], "entities": [{"text": "semiring parsing", "start_pos": 27, "end_pos": 43, "type": "TASK", "confidence": 0.7524158358573914}]}, {"text": "This reveals a disparity between weighted hypergraphs and semiring parsing.", "labels": [], "entities": []}, {"text": "It seems like we are forced to choose between the inside-outside algorithm for context-free grammars on the one side, and the flexibility of grammar formalism and parsing algorithm development afforded by semiring (bi-) parsing.", "labels": [], "entities": []}, {"text": "It is, however, possible to have both, which we will show in Section 5.", "labels": [], "entities": []}, {"text": "An integral part of this unification is the concept of contextual probability.", "labels": [], "entities": []}, {"text": "Finally, we will offer some conclusions in Section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}