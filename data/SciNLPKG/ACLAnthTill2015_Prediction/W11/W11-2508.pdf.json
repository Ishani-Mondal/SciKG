{"title": [{"text": "A distributional similarity approach to the detection of semantic change in the Google Books Ngram corpus", "labels": [], "entities": [{"text": "Google Books Ngram corpus", "start_pos": 80, "end_pos": 105, "type": "DATASET", "confidence": 0.8551094830036163}]}], "abstractContent": [{"text": "This paper presents a novel approach for automatic detection of semantic change of words based on distributional similarity models.", "labels": [], "entities": [{"text": "automatic detection of semantic change of words", "start_pos": 41, "end_pos": 88, "type": "TASK", "confidence": 0.8482298254966736}]}, {"text": "We show that the method obtains good results with respect to a reference ranking produced by human raters.", "labels": [], "entities": []}, {"text": "The evaluation also analyzes the performance of frequency-based methods, comparing them to the similarity method proposed .", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently a large corpus of digitized books was made publicly available by Google (.", "labels": [], "entities": []}, {"text": "It contains more than 5 millions of books published between the sixteenth century and today.", "labels": [], "entities": []}, {"text": "Computational analysis of such representative diachronic data made it possible to trace different cultural trends in the last centuries.", "labels": [], "entities": []}, {"text": "exploit the change in word frequency as the main measure for the quantitative investigation of cultural and linguistic phenomena; in this paper, we extend this approach by measuring the semantic similarity of the word occurrences in two different time points using distributional semantics model.", "labels": [], "entities": []}, {"text": "Semantic change, defined as a change of one or more meanings of the word in time, is of interest to historical linguistics and is related to the natural language processing task of unknown word sense detection).", "labels": [], "entities": [{"text": "unknown word sense detection", "start_pos": 181, "end_pos": 209, "type": "TASK", "confidence": 0.6432335004210472}]}, {"text": "Developing automatic methods for identifying changes in word meaning can therefore be useful for both theoretical linguistics and a variety of NLP applications which depend on lexical information.", "labels": [], "entities": [{"text": "identifying changes in word meaning", "start_pos": 33, "end_pos": 68, "type": "TASK", "confidence": 0.696225357055664}]}, {"text": "Some first automatic approaches to the semantic change detection task were recently proposed by and.", "labels": [], "entities": [{"text": "semantic change detection task", "start_pos": 39, "end_pos": 69, "type": "TASK", "confidence": 0.8768942654132843}]}, {"text": "These works focus on specific types of semantic change, i.e., aim to identify widening and narrowing of meaning, while concentrate on amelioration and pejoration cases.", "labels": [], "entities": [{"text": "identify widening and narrowing of meaning", "start_pos": 69, "end_pos": 111, "type": "TASK", "confidence": 0.8431476851304373}]}, {"text": "Their evaluation of the proposed methods is rather qualitative, concerning just a few examples.", "labels": [], "entities": []}, {"text": "In present work we address the task of automatic detection of the semantic change of words in quantitative way, comparing our novel distributional similarity approach to a relative-frequency-based method.", "labels": [], "entities": [{"text": "automatic detection of the semantic change of words", "start_pos": 39, "end_pos": 90, "type": "TASK", "confidence": 0.8158340193331242}]}, {"text": "For the evaluation, we used the Google Books Ngram data from the 1960s and 1990s, taking as a reference standard a ranking produced by human raters.", "labels": [], "entities": [{"text": "Google Books Ngram data", "start_pos": 32, "end_pos": 55, "type": "DATASET", "confidence": 0.9303063452243805}]}, {"text": "We present the results of the method proposed, which highly correlate with the human judgements on a test set, and show the underlying relations with relative frequency.", "labels": [], "entities": []}], "datasetContent": [{"text": "From the list of 10,000 words we chose 100 as a representative random subset containing words with different similarities from the whole scale from 0 to 1 and taken from different frequency range, i.e., words that became more frequent in 90s (60%) and words that became less frequent (40%) (see: Correlation between similarity (sim), frequency (freq) and human ranking (HR) values for all words, words more frequent in 60s and more frequent in 90s.", "labels": [], "entities": [{"text": "similarity (sim), frequency (freq)", "start_pos": 316, "end_pos": 350, "type": "METRIC", "confidence": 0.7477736042605506}, {"text": "human ranking (HR)", "start_pos": 355, "end_pos": 373, "type": "METRIC", "confidence": 0.7511464536190033}]}, {"text": "Values statistically significant for p = 0.01(0.05) in onesample t-test are marked with * * ( * ).", "labels": [], "entities": []}, {"text": "Human raters were asked to rank the resulting list according to their intuitions about change in last 40 years on a 4-point scale (0: no change; 1: almost no change; 2: somewhat change; 3: changed significantly).", "labels": [], "entities": []}, {"text": "We took the average of judgments as the reference value with which distributional similarity scores were compared.", "labels": [], "entities": [{"text": "distributional similarity scores", "start_pos": 67, "end_pos": 99, "type": "METRIC", "confidence": 0.6784118413925171}]}, {"text": "For the 5 participants, the inter-rater agreement, computed as an average of pair-wise Pearson correlations, was 0.51 (p < 0.01).", "labels": [], "entities": [{"text": "pair-wise Pearson correlations", "start_pos": 77, "end_pos": 107, "type": "METRIC", "confidence": 0.7494180997212728}]}, {"text": "It shows that the collected judgements were highly correlated and the average judgement can be considered an enough reliable reference for semantic change measurements evaluation.", "labels": [], "entities": [{"text": "semantic change measurements evaluation", "start_pos": 139, "end_pos": 178, "type": "TASK", "confidence": 0.7763198763132095}]}], "tableCaptions": [{"text": " Table 1: Examples illustrating word selection with simi- larity (sim) and log-frequency (freq) metric values.", "labels": [], "entities": [{"text": "word selection", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.7408176064491272}]}, {"text": " Table 2: Correlation between similarity (sim), frequency  (freq) and human ranking (HR) values for all words,  words more frequent in 60s and more frequent in 90s.  Values statistically significant for p = 0.01(0.05) in one- sample t-test are marked with  *  *  (  *  ).", "labels": [], "entities": [{"text": "similarity (sim), frequency  (freq)", "start_pos": 30, "end_pos": 65, "type": "METRIC", "confidence": 0.8502314686775208}, {"text": "human ranking (HR)", "start_pos": 70, "end_pos": 88, "type": "METRIC", "confidence": 0.8316089153289795}]}, {"text": " Table 3: Examples of the top weighted 2-grams contain- ing 'sleep' and 'parent'.", "labels": [], "entities": []}]}