{"title": [{"text": "Automatic Sentiment Classification of Product Reviews Using Maximal Phrases Based Analysis", "labels": [], "entities": [{"text": "Sentiment Classification of Product Reviews", "start_pos": 10, "end_pos": 53, "type": "TASK", "confidence": 0.9143083333969116}]}], "abstractContent": [{"text": "In this paper we explore the use of phrases occurring maximally in text as features for sentiment classification of product reviews.", "labels": [], "entities": [{"text": "sentiment classification of product reviews", "start_pos": 88, "end_pos": 131, "type": "TASK", "confidence": 0.9243790626525878}]}, {"text": "The goal is to find in a statistical way representative words and phrases used typically in positive and negative reviews.", "labels": [], "entities": []}, {"text": "The approach does not rely on predefined sentiment lexicons, and the motivation for this is that potentially every word could be considered as expressing something positive and/or negative in different situations, and that the context and the personal attitude of the opinion holder should betaken into account when determining the polarity of the phrase, instead of doing this out of particular context.", "labels": [], "entities": []}], "introductionContent": [{"text": "As human beings we use different ways to express opinions or sentiments.", "labels": [], "entities": []}, {"text": "The field of sentiment analysis tries to identify the ways, in which people express opinions or sentiments towards a particular target or entity.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.9283296763896942}]}, {"text": "The entities could be persons, products, events, etc.", "labels": [], "entities": []}, {"text": "With the development of the Internet technologies and robust search engines in the last decade, people nowadays have a huge amount of free information.", "labels": [], "entities": []}, {"text": "Because of this huge amount, however, the data needs to be first effectively processed so that it could be used in a helpful way.", "labels": [], "entities": []}, {"text": "The automatic identification of sentiments would make possible the processing of large amounts of such opinionated data.", "labels": [], "entities": [{"text": "identification of sentiments", "start_pos": 14, "end_pos": 42, "type": "TASK", "confidence": 0.8178208072980245}]}, {"text": "The focus of this paper is sentiment classification at document\u00adlevel, namely classification of product reviews in the categories positive polarity or negative polarity.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.8800248801708221}]}, {"text": "Training and testing data for our experiments is the Multi\u00adDomain Sentiment Dataset (, which consists of product reviews of different domains, downloaded from Amazon 1 . We explore the use of phrases occurring maximally in text as features for sentiment classification of product reviews.", "labels": [], "entities": [{"text": "Multi\u00adDomain Sentiment Dataset", "start_pos": 53, "end_pos": 83, "type": "DATASET", "confidence": 0.5553452968597412}, {"text": "sentiment classification of product reviews", "start_pos": 244, "end_pos": 287, "type": "TASK", "confidence": 0.8956972479820251}]}, {"text": "In contrast to many related works on sentiment classification of documents, we do not use general polarity lexicons, which contain predefined positive and negative words.", "labels": [], "entities": [{"text": "sentiment classification of documents", "start_pos": 37, "end_pos": 74, "type": "TASK", "confidence": 0.9192997217178345}]}, {"text": "Very often the same word or phrase could express something positive in one situation and something negative in another.", "labels": [], "entities": []}, {"text": "We identify words and phrases, which are typically used in positive and negative documents of some specific domains, based on the frequencies of the words and phrases in the domain\u00adspecific corpora.", "labels": [], "entities": []}, {"text": "After that we use these phrases to classify new sentiment documents from the same type of documents, from which the phrases are extracted.", "labels": [], "entities": []}], "datasetContent": [{"text": "SVM is used as a machine learning algorithm for the experiments (the implementation of the SVM package LibSVM 3 in GATE 4 ).", "labels": [], "entities": [{"text": "SVM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7783474922180176}]}, {"text": "For each experiment we first divide the reviews of each domain into training and testing data with ratio two to one.", "labels": [], "entities": []}, {"text": "From this training data we extract the distinctive phrases, which are later used as features to the learning algorithm.", "labels": [], "entities": []}, {"text": "As evaluation method we apply the k\u00adfold cross validation test, with k=10.", "labels": [], "entities": []}, {"text": "For all experiments we used the default tf\u00adidf weight for the n\u00adgrams.", "labels": [], "entities": []}, {"text": "For each domain we conduct five different experiments, each time using different subsets of distinctive phrases.", "labels": [], "entities": []}, {"text": "All experiments were performed with GATE.", "labels": [], "entities": [{"text": "GATE", "start_pos": 36, "end_pos": 40, "type": "DATASET", "confidence": 0.7971450686454773}]}, {"text": "For each domain the training data from which the phrases are extracted consists of about 665 negative and 665 positive reviews.", "labels": [], "entities": []}, {"text": "The testing data consists of 333 negative and 333 positive reviews.", "labels": [], "entities": []}, {"text": "It is interesting to notice that although the results of the experiments are different, they are very close to each other, regardless of the big difference in the number of phrases used as features.", "labels": [], "entities": []}, {"text": "Therefore, we decided to experiment with all extracted phrases.", "labels": [], "entities": []}, {"text": "It turned out that the results of that experiment are the best.", "labels": [], "entities": []}, {"text": "This would imply that the bigger number of phrases is helpful and it compensates for the use of phrases that are not much distinctive.", "labels": [], "entities": []}, {"text": "The results of all experiments for domain books are summarized in.", "labels": [], "entities": []}, {"text": "The best achieved results of 81% precision, recall, and F\u00admeasure are given in bold.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9922999143600464}, {"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9996559619903564}, {"text": "F\u00admeasure", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9995144605636597}]}, {"text": "The rightmost column gives the number of negative (n.) and positive (p.) phrases used in each experiment.", "labels": [], "entities": []}, {"text": "In order to evaluate how well the results of the experiments are we performed several more experiments, in which the texts were represented with unigrams (1\u00adgrams) and bigrams (2\u00adgrams).", "labels": [], "entities": []}, {"text": "note that: whether higher\u00ad order n\u00adgrams are useful features appears to be a matter of some debate.", "labels": [], "entities": []}, {"text": "For example, report that unigrams outperform bigrams when classifying movie reviews by sentiment polarity, but find that in some settings, bigrams and trigrams yield better product\u00adreview polarity classification.", "labels": [], "entities": [{"text": "product\u00adreview polarity classification", "start_pos": 173, "end_pos": 211, "type": "TASK", "confidence": 0.6379608511924744}]}, {"text": "review the results of different experiments on text categorization in which n\u00ad gram approaches were used, and conclude that the use of bigrams for the representation of texts does not show general improvement", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. The best achieved  results of 81% precision, recall, and F\u00admeasure are  given in bold. The rightmost column gives the  number of negative (n.) and positive (p.) phrases  used in each experiment.", "labels": [], "entities": [{"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9927501678466797}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9995039701461792}, {"text": "F\u00admeasure", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9995319843292236}]}, {"text": " Table 3: Domain books, 1\u00adgram.", "labels": [], "entities": []}, {"text": " Table 4: Domain camera&photos, 1\u00adgram.", "labels": [], "entities": []}, {"text": " Table 5: Domain books, 2\u00adgram.", "labels": [], "entities": []}, {"text": " Table 6: Domain camera&photos, 2\u00adgram.", "labels": [], "entities": []}, {"text": " Table 7: Comparison, Domain books.", "labels": [], "entities": []}, {"text": " Table 8: Comparison, Domain camera&photos.", "labels": [], "entities": []}]}