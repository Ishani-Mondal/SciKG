{"title": [{"text": "GrawlTCQ: Terminology and Corpora Building by Ranking Simultaneously Terms, Queries and Documents using Graph Random Walks", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we present GrawlTCQ, anew bootstrapping algorithm for building specialized terminology, corpora and queries, based on a graph model.", "labels": [], "entities": []}, {"text": "We model links between documents, terms and queries, and use a random walk with restart algorithm to compute relevance propagation.", "labels": [], "entities": [{"text": "relevance propagation", "start_pos": 109, "end_pos": 130, "type": "TASK", "confidence": 0.7758730947971344}]}, {"text": "We have evaluated GrawlTCQ on an AFP English corpus of 57,441 news over 10 categories.", "labels": [], "entities": [{"text": "GrawlTCQ", "start_pos": 18, "end_pos": 26, "type": "DATASET", "confidence": 0.8647606372833252}, {"text": "AFP English corpus of 57,441 news", "start_pos": 33, "end_pos": 66, "type": "DATASET", "confidence": 0.9562491774559021}]}, {"text": "For corpora building, GrawlTCQ outperforms the Boot-CaT tool, which is vastly used in the domain.", "labels": [], "entities": [{"text": "corpora building", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.8246976137161255}]}, {"text": "For 1,000 documents retrieved, we improve mean precision by 25%.", "labels": [], "entities": [{"text": "mean", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.9778803586959839}, {"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9217811226844788}]}, {"text": "GrawlTCQ has also shown to be faster and more robust than Boot-CaT over iterations.", "labels": [], "entities": [{"text": "Boot-CaT", "start_pos": 58, "end_pos": 66, "type": "DATASET", "confidence": 0.8856418132781982}]}], "introductionContent": [{"text": "Specialized terminology and corpora are key resources in applications such as machine translation or lexicon-based classification, but they are expensive to develop because of the manual validation required.", "labels": [], "entities": [{"text": "machine translation or lexicon-based classification", "start_pos": 78, "end_pos": 129, "type": "TASK", "confidence": 0.7485811591148377}]}, {"text": "Bootstrapping is a powerful technique for minimizing the cost of building these resources.", "labels": [], "entities": []}, {"text": "In this paper, we present GrawlTCQ 1 , a bootstrapping algorithm for building specialized terminology, corpora and queries: from a small set of userprovided terms, GrawlTCQ builds the resources via automated queries to a search engine.", "labels": [], "entities": []}, {"text": "The algorithm relies on a graph that encodes the three kinds of entities involved in the procedure (terms, documents and queries) and relations between them.", "labels": [], "entities": []}, {"text": "We model the relevance propagation in our graph by using a random walk with restart algorithm.", "labels": [], "entities": [{"text": "relevance propagation", "start_pos": 13, "end_pos": 34, "type": "TASK", "confidence": 0.8932845592498779}]}, {"text": "We use BootCaT () as our baseline because it is a similar algorithm that has been vastly used and validated experimentally in the domain.", "labels": [], "entities": []}, {"text": "We have evaluated GrawlTCQ and BootCaT on an AFP (Agence France Presse) English corpus of 57,441 news over 10 categories.", "labels": [], "entities": [{"text": "GrawlTCQ", "start_pos": 18, "end_pos": 26, "type": "DATASET", "confidence": 0.832472562789917}, {"text": "BootCaT", "start_pos": 31, "end_pos": 38, "type": "DATASET", "confidence": 0.9319050908088684}, {"text": "AFP (Agence France Presse) English corpus of 57,441 news", "start_pos": 45, "end_pos": 101, "type": "DATASET", "confidence": 0.9053025841712952}]}, {"text": "Results show that, for corpora building, GrawlTCQ significantly outperforms the BootCaT algorithm.", "labels": [], "entities": [{"text": "corpora building", "start_pos": 23, "end_pos": 39, "type": "TASK", "confidence": 0.8219913840293884}]}, {"text": "As this is an on-going work, further work is needed to evaluate terminology and query results.", "labels": [], "entities": []}, {"text": "The article is structured as follows: in Section 2, we review the related work in terminology and corpora construction using bootstrapping techniques, as well as random walk applications.", "labels": [], "entities": [{"text": "terminology and corpora construction", "start_pos": 82, "end_pos": 118, "type": "TASK", "confidence": 0.6610959842801094}]}, {"text": "In Section 3, we describe GrawlTCQ.", "labels": [], "entities": [{"text": "GrawlTCQ", "start_pos": 26, "end_pos": 34, "type": "DATASET", "confidence": 0.8187804818153381}]}, {"text": "In Section 4, we evaluate GrawlTCQ and compare its results with those provided by BootCaT.", "labels": [], "entities": [{"text": "GrawlTCQ", "start_pos": 26, "end_pos": 34, "type": "DATASET", "confidence": 0.745119571685791}, {"text": "BootCaT", "start_pos": 82, "end_pos": 89, "type": "DATASET", "confidence": 0.9688289165496826}]}, {"text": "We conclude in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluating the proposed method on the web can hardly be done without laborious manual annotation.", "labels": [], "entities": []}, {"text": "Moreover, web-based evaluations are not reproducible as search engines index and ranking functions changeover time.", "labels": [], "entities": []}, {"text": "This is especially a problem when evaluating the impact of different parameters of our algorithm.", "labels": [], "entities": []}, {"text": "In this article, we have chosen to carryout an objective and reproducible evaluation based on a stable and annotated document collection.", "labels": [], "entities": []}, {"text": "The AFP has provided us an English corpus composed of 57,441 news documents written between January 1st and March).", "labels": [], "entities": [{"text": "AFP", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.9696496725082397}, {"text": "English corpus composed of 57,441 news documents written between January 1st", "start_pos": 27, "end_pos": 103, "type": "DATASET", "confidence": 0.9129100171002474}]}, {"text": "The corpus was then indexed using Apache Lucene (http://lucene.apache.org) in order to create a basic search engine . This setup has several advantages: first, the document collection is stable and quantifiable.", "labels": [], "entities": []}, {"text": "Documents are clean text written in a journalistic style.", "labels": [], "entities": []}, {"text": "As they are already annotated, several automatic evaluations can be run with different parameters.", "labels": [], "entities": []}, {"text": "Finally, querying the search engine and retrieving documents can be done efficiently.", "labels": [], "entities": []}, {"text": "However, note that, as the document collection is limited, queries might return few or no results (which is rarely the case on the web).", "labels": [], "entities": []}, {"text": "We have used the BootCaT algorithm as our baseline.", "labels": [], "entities": [{"text": "BootCaT algorithm", "start_pos": 17, "end_pos": 34, "type": "DATASET", "confidence": 0.9106306731700897}]}, {"text": "To the best of our knowledge this is the first attempt to rigorously evaluate BootCaT performances.", "labels": [], "entities": []}, {"text": "We have compared both algorithms in exactly the same conditions, on a task-based experiment: to retrieve 50, 100, 300, 500 and 1000 documents for each category, independently of the number of iterations done.", "labels": [], "entities": []}, {"text": "To be as close as possible to the original BootCaT algorithm, we have weighted document-term edges by log odds ratio.", "labels": [], "entities": []}, {"text": "This measure allows us to distinguish common terms by using a reference background corpus.", "labels": [], "entities": []}, {"text": "In all our experiments, we have used the ukWac corpus), a very large web-derived corpus, for this purpose.", "labels": [], "entities": [{"text": "ukWac corpus)", "start_pos": 41, "end_pos": 54, "type": "DATASET", "confidence": 0.983806331952413}]}, {"text": "In order to select initial seed terms we have used documents' metadata.", "labels": [], "entities": []}, {"text": "We have computed the fre- quency of occurrences of a keyword in a category and have then divided this score by the sum of occurrences in all other categories.", "labels": [], "entities": [{"text": "fre- quency", "start_pos": 21, "end_pos": 32, "type": "METRIC", "confidence": 0.9672116835912069}]}, {"text": "This strategy leads to relevant seed terms that are not necessarily exclusive to a category.", "labels": [], "entities": []}, {"text": "For instance, selected seeds for the 4th category are: economics, summary, rate, opec, distress, recession, zain, jal, gold, and spyker.", "labels": [], "entities": [{"text": "summary", "start_pos": 66, "end_pos": 73, "type": "METRIC", "confidence": 0.9125834107398987}, {"text": "rate", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.8413091897964478}]}, {"text": "We have fixed a number of parameters for our experiments: at each iteration, the top-10 seeds are selected (either from the initial set or from newly extracted terms).", "labels": [], "entities": []}, {"text": "Queries are composed of 2 seeds, all 45 possible combinations 6 are used and a total of 10 documents are retrieved for each query.", "labels": [], "entities": []}, {"text": "All scores are averaged over the 10 categories.", "labels": [], "entities": []}, {"text": "As can be seen in, GrawlTCQ shows much more robustness and outperforms BootCaT by 25% precision at 1000 documents.", "labels": [], "entities": [{"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9989448189735413}]}, {"text": "Detailed results for each category are shown in table 2 and confirm the relevance of our approach.", "labels": [], "entities": []}, {"text": "Interestingly, BootCaT and GrawlTCQ have very low precisions for the 14th category (Social issue).", "labels": [], "entities": [{"text": "BootCaT", "start_pos": 15, "end_pos": 22, "type": "DATASET", "confidence": 0.9387251138687134}, {"text": "GrawlTCQ", "start_pos": 27, "end_pos": 35, "type": "DATASET", "confidence": 0.7576218247413635}, {"text": "precisions", "start_pos": 50, "end_pos": 60, "type": "METRIC", "confidence": 0.9988730549812317}]}, {"text": "Documents found in this category are often ambiguous and both algorithms fail to extract the domain terminology.", "labels": [], "entities": []}, {"text": "We have also plotted the number of documents in function of the number of iterations as shown in.", "labels": [], "entities": []}, {"text": "The curve clearly shows that GrawlTCQ yields more When running the same experiment with randomly selected tuples several times, we have found similar results when averaging all runs output.", "labels": [], "entities": []}, {"text": "documents at a faster rate.", "labels": [], "entities": []}, {"text": "This is due to the seed selection process: GrawlTCQ's queries lead to many documents while BootCaT queries often lead to few or no documents.", "labels": [], "entities": []}, {"text": "Moreover, as we can see in, while fetching more documents faster, the mean precision of GrawlTCQ is still higher than the BootCaT one which shows that selected seeds are, at the same time, more prolific and more relevant.", "labels": [], "entities": [{"text": "precision", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9892633557319641}, {"text": "BootCaT", "start_pos": 122, "end_pos": 129, "type": "DATASET", "confidence": 0.8267384767532349}]}], "tableCaptions": [{"text": " Table 1: AFP corpus categories distribution.", "labels": [], "entities": [{"text": "AFP corpus categories distribution", "start_pos": 10, "end_pos": 44, "type": "DATASET", "confidence": 0.8853238523006439}]}, {"text": " Table 2: Precision at various cutoffs by category", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8281071782112122}]}]}