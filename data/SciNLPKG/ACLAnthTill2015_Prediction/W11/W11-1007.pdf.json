{"title": [{"text": "Improving Reordering for Statistical Machine Translation with Smoothed Priors and Syntactic Features", "labels": [], "entities": [{"text": "Improving Reordering", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.925053596496582}, {"text": "Statistical Machine Translation", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.8598989645640055}]}], "abstractContent": [{"text": "In this paper we propose several novel approaches to improve phrase reordering for statistical machine translation in the framework of maximum-entropy-based modeling.", "labels": [], "entities": [{"text": "phrase reordering", "start_pos": 61, "end_pos": 78, "type": "TASK", "confidence": 0.7937468588352203}, {"text": "statistical machine translation", "start_pos": 83, "end_pos": 114, "type": "TASK", "confidence": 0.6964797973632812}]}, {"text": "A smoothed prior probability is introduced to take into account the distortion effect in the priors.", "labels": [], "entities": []}, {"text": "In addition to that we propose multiple novel distortion features based on syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.725024551153183}]}, {"text": "A new metric is also introduced to measure the effect of distortion in the translation hypotheses.", "labels": [], "entities": []}, {"text": "We show that both smoothed priors and syntax-based features help to significantly improve the reordering and hence the translation performance on a large-scale Chinese-to-English machine translation task.", "labels": [], "entities": [{"text": "translation", "start_pos": 119, "end_pos": 130, "type": "TASK", "confidence": 0.9601536393165588}, {"text": "Chinese-to-English machine translation task", "start_pos": 160, "end_pos": 203, "type": "TASK", "confidence": 0.7227841541171074}]}], "introductionContent": [{"text": "Over the past decade, statistical machine translation (SMT) has evolved into an attractive area in natural language processing.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 22, "end_pos": 59, "type": "TASK", "confidence": 0.8749796152114868}, {"text": "natural language processing", "start_pos": 99, "end_pos": 126, "type": "TASK", "confidence": 0.6474651793638865}]}, {"text": "SMT takes a source sequence, S = [s 1 s 2 . .", "labels": [], "entities": [{"text": "SMT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9020014405250549}]}, {"text": "s K ] from the source language, and generates a target sequence, T * = [t 1 t 2 . .", "labels": [], "entities": []}, {"text": "t L ], by finding the most likely translation given by: In most of the existing approaches, following), Eq.", "labels": [], "entities": []}, {"text": "(1) is factored using the source-channel model into where the two models, the translation model, p(S|T ), and the language model (LM), p(T ), are estimated separately: the former using a parallel corpus and a hidden alignment model and the latter using a typically much larger monolingual corpus.", "labels": [], "entities": []}, {"text": "The weighting factor \u03bb is typically tuned on a development test set by optimizing a translation accuracy criterion such as BLEU ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.8669772148132324}, {"text": "BLEU", "start_pos": 123, "end_pos": 127, "type": "METRIC", "confidence": 0.9987282156944275}]}, {"text": "In recent years, among all the proposed approaches, the phrase-based method has become the widely adopted one in SMT due to its capability of capturing local context information from adjacent words.", "labels": [], "entities": [{"text": "SMT", "start_pos": 113, "end_pos": 116, "type": "TASK", "confidence": 0.9940953254699707}]}, {"text": "Word order in the translation output relies on how the phrases are reordered based on both language model scores and distortion cost/penalty (, among all the features utilized in a maximum-entropy (loglinear) model).", "labels": [], "entities": []}, {"text": "The distortion cost utilized during the decoding is usually a penalty linearly proportional to the number of words in the source sentence that are skipped in a translation path.", "labels": [], "entities": []}, {"text": "In this paper, we propose several novel approaches to improve reordering in the phrase-based translation with a maximum-entropy model.", "labels": [], "entities": []}, {"text": "In Section 2, we review the previous work that focused on the distortion and phrase reordering in SMT.", "labels": [], "entities": [{"text": "phrase reordering", "start_pos": 77, "end_pos": 94, "type": "TASK", "confidence": 0.7335340231657028}, {"text": "SMT", "start_pos": 98, "end_pos": 101, "type": "TASK", "confidence": 0.8873443007469177}]}, {"text": "In Section 3, we briefly review the baseline of this work.", "labels": [], "entities": []}, {"text": "In Section 4, we introduce a smoothed prior probability by taking into account the distortions in the priors.", "labels": [], "entities": []}, {"text": "In Section 5, we present multiple novel distortion features based on syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.7120189666748047}]}, {"text": "A new distortion evaluation metric is proposed in Section 6 and experimental results on a large-scale ChineseEnglish machine translation task are reported in Section 7.", "labels": [], "entities": [{"text": "ChineseEnglish machine translation task", "start_pos": 102, "end_pos": 141, "type": "TASK", "confidence": 0.8494458049535751}]}, {"text": "Section 8 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "MT performance is usually measured by such metric as BLEU which measures the MT output as a whole including word choice and reordering.", "labels": [], "entities": [{"text": "MT", "start_pos": 0, "end_pos": 2, "type": "TASK", "confidence": 0.9738982319831848}, {"text": "BLEU", "start_pos": 53, "end_pos": 57, "type": "METRIC", "confidence": 0.9968692660331726}, {"text": "MT", "start_pos": 77, "end_pos": 79, "type": "TASK", "confidence": 0.9478100538253784}]}, {"text": "It is useful to measure these components separately.", "labels": [], "entities": []}, {"text": "Unigram BLEU (BLEUn1) measures the precision of word choice.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 8, "end_pos": 12, "type": "METRIC", "confidence": 0.8460360169410706}, {"text": "BLEUn1", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.7194086313247681}, {"text": "precision", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9989238381385803}]}, {"text": "We need a metric for measuring reordering accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9732739329338074}]}, {"text": "The naive way of counting accuracy at every source position does not account for the case of the phrasal movement.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9610471725463867}]}, {"text": "If a phrase is moved to the wrong place, every source word in the phrase would be penalized whereas a more reasonable metric would penalize the phrase movement only once if the phrase boundary is correct.", "labels": [], "entities": []}, {"text": "We propose the following pair-wise distortion metric.", "labels": [], "entities": []}, {"text": "From an MT output, we first extract the source visit sequence: Hyp:{h 1, h 2, . .", "labels": [], "entities": [{"text": "MT", "start_pos": 8, "end_pos": 10, "type": "TASK", "confidence": 0.932270884513855}]}, {"text": "h n } where hi are the visit order of the source sentence.", "labels": [], "entities": []}, {"text": "From the reference, we extract the true visit sequence: 65 Ref:{r 1, r 2, . .", "labels": [], "entities": []}, {"text": "r n } The Pair-wise Distortion metric PDscore can be computed as follows: I(h i = r j \u2227 h i\u22121 = r j\u22121 ) n (8) It measures how often the translation output gets the pair-wise source visit order correct.", "labels": [], "entities": []}, {"text": "We notice that an MT metric named LRscore was proposed in.", "labels": [], "entities": [{"text": "MT", "start_pos": 18, "end_pos": 20, "type": "TASK", "confidence": 0.9434136748313904}, {"text": "LRscore", "start_pos": 34, "end_pos": 41, "type": "METRIC", "confidence": 0.7250381708145142}]}, {"text": "It computes the distance between two word order sequences, which is different from the metric we proposed here.", "labels": [], "entities": []}, {"text": "We evaluate the MT distortion using the metric in Eq.", "labels": [], "entities": [{"text": "MT distortion", "start_pos": 16, "end_pos": 29, "type": "TASK", "confidence": 0.7308204472064972}, {"text": "Eq", "start_pos": 50, "end_pos": 52, "type": "DATASET", "confidence": 0.8850710391998291}]}, {"text": "(8) on two hand-aligned test sets.", "labels": [], "entities": []}, {"text": "Test-278 includes 278 held-out sentences.", "labels": [], "entities": []}, {"text": "Test-52 contains the first 52 sentences from the MT08 Newswire set, with the Chinese input sentences manually aligned to the first set of reference translations.", "labels": [], "entities": [{"text": "MT08 Newswire set", "start_pos": 49, "end_pos": 66, "type": "DATASET", "confidence": 0.9463266531626383}]}, {"text": "From the hand alignment, we extract the true source visit sequence and this is the reference.", "labels": [], "entities": []}, {"text": "The evaluation results are in.", "labels": [], "entities": []}, {"text": "It is shown that the smoothed distortion prior, parse coverage feature and parse sibling feature each provides improvement on the PDscore on Test-278 and Test-52.", "labels": [], "entities": [{"text": "smoothed distortion prior", "start_pos": 21, "end_pos": 46, "type": "METRIC", "confidence": 0.7423484126726786}, {"text": "Test-278", "start_pos": 141, "end_pos": 149, "type": "DATASET", "confidence": 0.967438280582428}, {"text": "Test-52", "start_pos": 154, "end_pos": 161, "type": "DATASET", "confidence": 0.9070729613304138}]}, {"text": "The final system scores are 2 to 3 points absolute higher than the baseline scores.", "labels": [], "entities": []}, {"text": "The state visit sequence in the final system is closer to the true visit sequence than that of the baseline.", "labels": [], "entities": []}, {"text": "This indicates the advantage of using both parse-based syntactic features and also the smoothed prior that takes into account of the distortion effect.", "labels": [], "entities": []}, {"text": "We also provide an upper-bound in the last row by computing the PDscore between the first and second set of references for Test-52.", "labels": [], "entities": [{"text": "Test-52", "start_pos": 123, "end_pos": 130, "type": "DATASET", "confidence": 0.9781786799430847}]}, {"text": "The number shows the agreement between two human translators in terms of PDscore is around 71%.", "labels": [], "entities": [{"text": "PDscore", "start_pos": 73, "end_pos": 80, "type": "METRIC", "confidence": 0.9110563397407532}]}], "tableCaptions": [{"text": " Table 1: Parse Sibling Word Features (e 0 represents  empty target).", "labels": [], "entities": [{"text": "Parse Sibling Word", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.7221794128417969}]}, {"text": " Table 2: Distortion accuracy PDscore (Prior:smoothed  distortion prior; COV:parse coverage feature; SIB:parse  sibling feature).", "labels": [], "entities": [{"text": "Distortion accuracy PDscore", "start_pos": 10, "end_pos": 37, "type": "METRIC", "confidence": 0.6706587870915731}, {"text": "Prior:smoothed  distortion prior", "start_pos": 39, "end_pos": 71, "type": "METRIC", "confidence": 0.7406740009784698}]}, {"text": " Table 3: MT results on MT08 Newswire set (PBT:normal phrase-based MT; ME:Maximum-entropy baseline;  Prior:smoothed distortion prior; COV:parse coverage feature; SIB:parse sibling feature).", "labels": [], "entities": [{"text": "MT", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.9838900566101074}, {"text": "MT08 Newswire set", "start_pos": 24, "end_pos": 41, "type": "DATASET", "confidence": 0.8445223967234293}, {"text": "ME", "start_pos": 71, "end_pos": 73, "type": "METRIC", "confidence": 0.9823697805404663}, {"text": "Prior:smoothed distortion prior", "start_pos": 101, "end_pos": 132, "type": "METRIC", "confidence": 0.8446670055389405}]}, {"text": " Table 4: MT results on MT08 Weblog set (PBT:normal phrase-based MT; ME:Maximum-entropy baseline;  Prior:smoothed distortion prior; COV:parse coverage feature; SIB:parse sibling feature).", "labels": [], "entities": [{"text": "MT", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.9769482612609863}, {"text": "MT08 Weblog set", "start_pos": 24, "end_pos": 39, "type": "DATASET", "confidence": 0.8039834896723429}, {"text": "ME", "start_pos": 69, "end_pos": 71, "type": "METRIC", "confidence": 0.9697484374046326}, {"text": "Prior:smoothed distortion prior", "start_pos": 99, "end_pos": 130, "type": "METRIC", "confidence": 0.8289986252784729}]}, {"text": " Table 5: Parse Sibling Word Features related to Chinese \"PP VV\".", "labels": [], "entities": [{"text": "Parse Sibling Word", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.6922914286454519}, {"text": "Chinese \"PP VV\"", "start_pos": 49, "end_pos": 64, "type": "DATASET", "confidence": 0.8860035181045532}]}]}