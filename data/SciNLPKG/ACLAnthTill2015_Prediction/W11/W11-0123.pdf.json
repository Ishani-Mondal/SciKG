{"title": [], "abstractContent": [{"text": "In the Recognizing Textual Entailment (RTE) task, sentence pairs are classified into one of three semantic relations: ENTAILMENT, CONTRADICTION or UNKNOWN.", "labels": [], "entities": [{"text": "Recognizing Textual Entailment (RTE) task", "start_pos": 7, "end_pos": 48, "type": "TASK", "confidence": 0.8155899729047503}, {"text": "ENTAILMENT", "start_pos": 118, "end_pos": 128, "type": "METRIC", "confidence": 0.9829699993133545}, {"text": "CONTRADICTION", "start_pos": 130, "end_pos": 143, "type": "METRIC", "confidence": 0.9505013823509216}]}, {"text": "While we find some sentence pairs hold full entailments or contradictions, there area number of pairs that partially entail or contradict one another depending on a specific situation.", "labels": [], "entities": []}, {"text": "These partial contradiction sentence pairs contain useful information for opinion mining and other such tasks, but it is difficult for Internet users to access this knowledge because current frameworks do not differentiate between full contradictions and partial contradictions.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 74, "end_pos": 88, "type": "TASK", "confidence": 0.8162232637405396}]}, {"text": "In this paper, undercurrent approaches to semantic relation recognition, we define anew semantic relation known as CONFINEMENT in order to recognize this useful information.", "labels": [], "entities": [{"text": "semantic relation recognition", "start_pos": 42, "end_pos": 71, "type": "TASK", "confidence": 0.7968622843424479}]}, {"text": "This information is classified as either CONTRADICTION or ENTAILMENT.", "labels": [], "entities": [{"text": "CONTRADICTION", "start_pos": 41, "end_pos": 54, "type": "METRIC", "confidence": 0.6758636832237244}, {"text": "ENTAILMENT", "start_pos": 58, "end_pos": 68, "type": "METRIC", "confidence": 0.8028000593185425}]}, {"text": "We provide a series of semantic templates to recognize CONFINEMENT relations in Web texts, and then implement a system for recognizing CONFINEMENT between sentence pairs.", "labels": [], "entities": []}, {"text": "We show that our proposed system can obtains a F-score of 61% for recognizing CONFINEMENT in Japanese-language Web texts, and it outperforms a baseline which does not use a manually compiled list of lexico-syntactic patterns to instantiate the semantic templates.", "labels": [], "entities": [{"text": "F-score", "start_pos": 47, "end_pos": 54, "type": "METRIC", "confidence": 0.9993441700935364}, {"text": "recognizing CONFINEMENT in Japanese-language Web texts", "start_pos": 66, "end_pos": 120, "type": "TASK", "confidence": 0.6628300150235494}]}], "introductionContent": [{"text": "On the Internet, there are various kinds of documents, and they often include conflicting opinions or differing information on a single topic.", "labels": [], "entities": []}, {"text": "Collecting and organizing this diverse information is an important part of multi-document summarization.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 75, "end_pos": 103, "type": "TASK", "confidence": 0.6356899440288544}]}, {"text": "When searching with a particular query on the Internet, we want information that tells us what other people think about the query: e.g. do they believe it is true or not; what are the necessary conditions for it to apply.", "labels": [], "entities": []}, {"text": "For example, consider the hypothetical search results for the query given in (1).", "labels": [], "entities": []}, {"text": "You get opinion (2a), which supports the query, and opinion (2b) which opposes it.", "labels": [], "entities": []}, {"text": "(1) Xylitol is effective at preventing tooth decay.", "labels": [], "entities": [{"text": "tooth decay", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.6648558676242828}]}, {"text": "Xylitol can prevent tooth decay. b. Xylitol is not effective at all at preventing tooth decay.", "labels": [], "entities": [{"text": "tooth decay.", "start_pos": 20, "end_pos": 32, "type": "TASK", "confidence": 0.6577313095331192}, {"text": "tooth decay", "start_pos": 82, "end_pos": 93, "type": "TASK", "confidence": 0.6447757929563522}]}, {"text": "A major task in the Recognizing Textual Entailment (RTE) Challenge () is classifying the semantic relation between a Text and a Hypothesis into ENTAILMENT, CONTRADICTION, or UNKNOWN.", "labels": [], "entities": [{"text": "Recognizing Textual Entailment (RTE) Challenge", "start_pos": 20, "end_pos": 66, "type": "TASK", "confidence": 0.8060903591769082}, {"text": "classifying the semantic relation between a Text and a Hypothesis", "start_pos": 73, "end_pos": 138, "type": "TASK", "confidence": 0.7285340607166291}]}, {"text": "report on the STATEMENT MAP project, the goal of which is to help Internet users evaluate the credibility of information sources by analyzing supporting evidence from a variety of viewpoints on their topics of interest and presenting them to users together with the supporting evidence in away that makes it clear how they are related.", "labels": [], "entities": [{"text": "STATEMENT MAP", "start_pos": 14, "end_pos": 27, "type": "TASK", "confidence": 0.6983589828014374}]}, {"text": "A variety of techniques have been successfully employed in the RTE Challenge in order to recognize instances of textual entailment.", "labels": [], "entities": [{"text": "RTE Challenge", "start_pos": 63, "end_pos": 76, "type": "TASK", "confidence": 0.8052394390106201}]}, {"text": "* Current afflication: Rakuten Institute of Technology However, as far as we know, there have been no studies on recognizing sentences which specify conditions under which a query applies, despite the fact that these relations are useful information for Internet users.", "labels": [], "entities": [{"text": "afflication", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.979933500289917}, {"text": "Rakuten Institute of Technology", "start_pos": 23, "end_pos": 54, "type": "DATASET", "confidence": 0.9458070397377014}]}, {"text": "Such useful sentences are plentiful on the Web.", "labels": [], "entities": []}, {"text": "Consider the following examples of CONTRA-DICTION and ENTAILMENT.", "labels": [], "entities": [{"text": "CONTRA-DICTION", "start_pos": 35, "end_pos": 49, "type": "METRIC", "confidence": 0.44347265362739563}, {"text": "ENTAILMENT", "start_pos": 54, "end_pos": 64, "type": "METRIC", "confidence": 0.9449266195297241}]}, {"text": "Xylitol cannot prevent tooth decay if it not at least 50%. b. The effect of Xylitol on preventing tooth decay is limited.", "labels": [], "entities": [{"text": "tooth decay", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.6523952782154083}, {"text": "preventing tooth decay", "start_pos": 87, "end_pos": 109, "type": "TASK", "confidence": 0.5821046630541483}]}, {"text": "In example (3a), the necessary condition to prevent tooth decay by Xylitol is \"it contains at least fifty percent Xylitol\".", "labels": [], "entities": []}, {"text": "That condition is expressed by the phrase in bold in (3a).", "labels": [], "entities": []}, {"text": "This sentence informs users that if they want to prevent tooth decay, the products they use must contain a certain amount of Xylitol to be effective.", "labels": [], "entities": []}, {"text": "In example (3b), we obtain information on uncertainty of Xylitol's tooth decay prevention effectiveness from the phrase \"is limited\".", "labels": [], "entities": [{"text": "tooth decay prevention", "start_pos": 67, "end_pos": 89, "type": "TASK", "confidence": 0.6721067130565643}]}, {"text": "It tells that Xylitol is not necessarily effective at preventing tooth decay, and thus it is not completely in agreement with or contradiction to the original sentence (1).", "labels": [], "entities": [{"text": "preventing tooth decay", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.594795415798823}]}, {"text": "It is important to recognize the semantic relation shown in (3) because it provides more specific information about the query or specifies the conditions under which the statement holds or does not.", "labels": [], "entities": []}, {"text": "This is valuable information for Internet users and needs to be distinguished from fully contradicting or agreeing opinions.", "labels": [], "entities": []}, {"text": "We call this semantic relation CONFINEMENT because it confines the situation under which a query applies.", "labels": [], "entities": []}, {"text": "In this paper, we give a language independent definition of the CONFINEMENT relation in predicate logic and provide a framework for detecting the relation through a series of semantic templates that take logical and semantic features as input.", "labels": [], "entities": []}, {"text": "We implement a system that detects CONFINEMENT relations between sentence pairs in Japanese by instantiating the semantic templates using rules and a list of lexico-semantic patterns.", "labels": [], "entities": []}, {"text": "Finally, we conduct empirical evaluation of recognition of the CONFINEMENT relation between queries and sentences in Japanese-language Web texts.", "labels": [], "entities": []}], "datasetContent": [{"text": "In Section 4, we verified that the semantic templates defined in Section 3.2 can successfully classify semantic relations as CONFINEMENT given the correct feature values.", "labels": [], "entities": []}, {"text": "In this Section, we present the results of an experiment in a more realistic setting by using semantic templates together with the features automatically extracted as described with our proposed system in Section 5 to determine whether or not a sentence pair has a CONFINEMENT relation.", "labels": [], "entities": []}, {"text": "While more research on recognizing ENTAILMENT or CONTRADICTION between sentences pairs is necessary, it is important to recognize new relations that cannot be analysed in existing frameworks in order to provide Internet users with the information they need.", "labels": [], "entities": [{"text": "ENTAILMENT", "start_pos": 35, "end_pos": 45, "type": "METRIC", "confidence": 0.7814350724220276}]}, {"text": "Thus, We assume that unrelated sentence pairs will be discarded before classification, in this experiment we focus only on the recognition of CONFINEMENT relations.", "labels": [], "entities": []}, {"text": "So our goal in this experiment is to classify between CONFINEMENT and NOT CONFINEMENT.", "labels": [], "entities": []}, {"text": "We will evaluate determining whether CONFINEMENT sentence pairs are Explicit or Implicit in future.", "labels": [], "entities": [{"text": "Explicit", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9774327278137207}, {"text": "Implicit", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.8320332169532776}]}, {"text": "In our experiment, we used a gold data for structural alignment to evaluate semantic feature extraction.", "labels": [], "entities": [{"text": "structural alignment", "start_pos": 43, "end_pos": 63, "type": "TASK", "confidence": 0.7369992733001709}, {"text": "semantic feature extraction", "start_pos": 76, "end_pos": 103, "type": "TASK", "confidence": 0.739823559919993}]}], "tableCaptions": [{"text": " Table 1: Semantic templates for recognizing CONFINEMENT", "labels": [], "entities": [{"text": "CONFINEMENT", "start_pos": 45, "end_pos": 56, "type": "TASK", "confidence": 0.3625393211841583}]}, {"text": " Table 2: Data set (Counts of sentences out of parenthesis and statements in parentheses)", "labels": [], "entities": []}, {"text": " Table 3: Results of recognizing confinement relations with our proposal system", "labels": [], "entities": []}, {"text": " Table 4: Instances of incorrect classification", "labels": [], "entities": []}]}