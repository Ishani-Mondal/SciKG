{"title": [{"text": "Using Inverse \u03bb and Generalization to Translate English to Formal Languages", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a system to translate natural language sentences to formulas in a formal or a knowledge representation language.", "labels": [], "entities": []}, {"text": "Our system uses two inverse \u03bb-calculus operators and using them can take as input the semantic representation of some words, phrases and sentences and from that derive the semantic representation of other words and phrases.", "labels": [], "entities": []}, {"text": "Our inverse \u03bb operator works on many formal languages including first order logic, database query languages and answer set programming.", "labels": [], "entities": []}, {"text": "Our system uses a syntactic combinatorial categorial parser to parse natural language sentences and also to construct the semantic meaning of the sentences as directed by their parsing.", "labels": [], "entities": []}, {"text": "The same parser is used for both.", "labels": [], "entities": []}, {"text": "In addition to the inverse \u03bb-calculus operators, our system uses a notion of generalization to learn semantic representation of words from the semantic representation of other words that are of the same category.", "labels": [], "entities": []}, {"text": "Together with this, we use an existing statistical learning approach to assign weights to deal with multiple meanings of words.", "labels": [], "entities": []}, {"text": "Our system produces improved results on standard corpora on natural language interfaces for robot command and control and database queries.", "labels": [], "entities": []}], "introductionContent": [{"text": "Our long term goal is to develop general methodologies to translate natural language text into a formal knowledge representation (KR) language.", "labels": [], "entities": []}, {"text": "In the absence of a single KR language that is appropriate for expressing all the nuances of a natural language, currently, depending on the need different KR languages are used.", "labels": [], "entities": []}, {"text": "For example, while first-order logic is appropriate for mathematical knowledge, one of its subset Description logic is considered appropriate for expressing ontologies, temporal logics are considered appropriate for expressing goals of agents and robots, and various non-monotonic logics have been proposed to express common-sense knowledge.", "labels": [], "entities": []}, {"text": "Thus, one of of our goals in this paper is to develop general methodologies that can be used in translating natural language to a desired KR language.", "labels": [], "entities": []}, {"text": "There have been several learning based approaches, mainly from two groups at MIT and Austin.", "labels": [], "entities": []}, {"text": "These include the following works:,,,,, and.", "labels": [], "entities": []}, {"text": "Given a training corpus of natural language sentences coupled with their desired representations, these approaches learn a model capable of translating sentences to a desired meaning representation.", "labels": [], "entities": []}, {"text": "For example, in the work by, a set of hand crafted rules is used to learn syntactic categories and semantic representations of words based on combinatorial categorial grammar (CCG), as described by, and \u03bb-calculus formulas, as discussed by.", "labels": [], "entities": []}, {"text": "The later work of, also uses hand crafted rules.", "labels": [], "entities": []}, {"text": "The Austin group has several papers over the years.", "labels": [], "entities": [{"text": "Austin group", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.94075807929039}]}, {"text": "Many of their works including the one by use a word alignment method to learn semantic lexicon and learn rules for composing meaning representation.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.740471139550209}]}, {"text": "Similar to the work by, we use an existing syntactic parser to parse natural language.", "labels": [], "entities": []}, {"text": "However we use a CCG parser, as described by, to parse sentences, use lambda calculus for meaning representation, use the CCG parsing to compose meaning and have an initial dictionary.", "labels": [], "entities": [{"text": "meaning representation", "start_pos": 90, "end_pos": 112, "type": "TASK", "confidence": 0.7148617506027222}]}, {"text": "Note that unlike the work by, we do not need to learn rules for composing meaning representation.", "labels": [], "entities": []}, {"text": "We use a novel method to learn semantic lexicon which is based on two inverse lambda operators that allow us to compute F given G and H such that F @G = H or G@F = H.", "labels": [], "entities": []}, {"text": "Compared to the work by, we use the same learning approach but use a completely different approach in lexical generation.", "labels": [], "entities": [{"text": "lexical generation", "start_pos": 102, "end_pos": 120, "type": "TASK", "confidence": 0.733187347650528}]}, {"text": "Our inverse \u03bb operator has been tested to work for many languages including first order logic, database query language, CLANG by, answer set programming (ASP) as described by, and temporal logic.", "labels": [], "entities": [{"text": "answer set programming (ASP)", "start_pos": 130, "end_pos": 158, "type": "TASK", "confidence": 0.6629961480696996}]}, {"text": "Thus our approach is not dependent on the language used to represent the semantics, nor limited by a fixed set of rules.", "labels": [], "entities": []}, {"text": "Rather, the new \u03bb-calculus formulas and their semantic models, corresponding to the semantic or meaning representations, are directly obtained from known semantic representations which were provided with the data or learned before.", "labels": [], "entities": []}, {"text": "The richness of \u03bb calculus allows us to rely only on the syntactic parse itself without the need to have separate rules for composing the semantics.", "labels": [], "entities": []}, {"text": "The provided method yields improved experimental results on existing corpora on robot command and control and database queries.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Performance on GEOQUERY.", "labels": [], "entities": [{"text": "GEOQUERY", "start_pos": 25, "end_pos": 33, "type": "DATASET", "confidence": 0.8973916172981262}]}, {"text": " Table 3: Performance on CLANG.", "labels": [], "entities": []}]}