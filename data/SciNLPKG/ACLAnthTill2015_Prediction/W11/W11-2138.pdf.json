{"title": [{"text": "Improving Translation Model by Monolingual Data *", "labels": [], "entities": [{"text": "Improving Translation Model", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.916634182135264}]}], "abstractContent": [{"text": "We use target-side monolingual data to extend the vocabulary of the translation model in statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 89, "end_pos": 120, "type": "TASK", "confidence": 0.6527141630649567}]}, {"text": "This method called \"reverse self-training\" improves the de-coder's ability to produce grammatically correct translations into languages with morphology richer than the source language esp.", "labels": [], "entities": []}, {"text": "We empirically evaluate the gains for several pairs of European languages and discuss some approaches of the underlying back-off techniques needed to translate unseen forms of known words.", "labels": [], "entities": [{"text": "translate unseen forms of known words", "start_pos": 150, "end_pos": 187, "type": "TASK", "confidence": 0.8577225506305695}]}, {"text": "We also provide a description of the systems we submitted to WMT11 Shared Task.", "labels": [], "entities": [{"text": "WMT11 Shared Task", "start_pos": 61, "end_pos": 78, "type": "DATASET", "confidence": 0.7836673061052958}]}], "introductionContent": [{"text": "Like any other statistical NLP task, SMT relies on sizable language data for training.", "labels": [], "entities": [{"text": "SMT", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9948012828826904}]}, {"text": "However the parallel data required for MT area very scarce resource, making it difficult to train MT systems of decent quality.", "labels": [], "entities": [{"text": "MT", "start_pos": 39, "end_pos": 41, "type": "TASK", "confidence": 0.9826516509056091}, {"text": "MT", "start_pos": 98, "end_pos": 100, "type": "TASK", "confidence": 0.9792051911354065}]}, {"text": "On the other hand, it is usually possible to obtain large amounts of monolingual data.", "labels": [], "entities": []}, {"text": "In this paper, we attempt to make use of the monolingual data to reduce the sparseness of surface forms, an issue typical for morphologically rich languages.", "labels": [], "entities": []}, {"text": "When MT systems translate into such languages, the limited size of parallel data often causes the situation where the output should include a word form never observed in the training data.", "labels": [], "entities": [{"text": "MT", "start_pos": 5, "end_pos": 7, "type": "TASK", "confidence": 0.9859909415245056}]}, {"text": "Even though the parallel data do contain the desired word in other forms, a standard phrase-based decoder has noway of using it to generate the correct translation.", "labels": [], "entities": []}, {"text": "Reverse self-training addresses this problem by incorporating the available monolingual data in the translation model.", "labels": [], "entities": []}, {"text": "This paper builds upon the idea outlined in, describing how this technique was incorporated in the WMT Shared Task and extending the experimental evaluation of reverse self-training in several directionsthe examined language pairs (Section 4.2), data size (Section 4.3) and back-off techniques (Section 4.4).", "labels": [], "entities": [{"text": "WMT Shared Task", "start_pos": 99, "end_pos": 114, "type": "TASK", "confidence": 0.7071424523989359}]}], "datasetContent": [{"text": "We used common tools for phrase-based translation -Moses ( ) decoder and tools, SRILM) and KenLM (Heafield, 2011) for language modelling and GIZA++) for word alignments.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.7603357434272766}, {"text": "language modelling", "start_pos": 118, "end_pos": 136, "type": "TASK", "confidence": 0.7359829246997833}, {"text": "word alignments", "start_pos": 153, "end_pos": 168, "type": "TASK", "confidence": 0.7805891633033752}]}, {"text": "For reverse self-training, we needed Moses to also output word alignments between source sentences and their translations.", "labels": [], "entities": [{"text": "word alignments between source sentences and their translations", "start_pos": 58, "end_pos": 121, "type": "TASK", "confidence": 0.8308756351470947}]}, {"text": "As we were notable to make the existing version of this feature work, we added anew option and re-implemented this funcionality.", "labels": [], "entities": []}, {"text": "We rely on automatic translation quality evaluation throughout our paper, namely the wellestablished BLEU metric ().", "labels": [], "entities": [{"text": "BLEU metric", "start_pos": 101, "end_pos": 112, "type": "METRIC", "confidence": 0.9762245118618011}]}, {"text": "We estimate 95% confidence bounds for the scores as described in.", "labels": [], "entities": []}, {"text": "We evaluated our translations on lower-cased sentences.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: BLEU scores of European language pairs on JRC data. Asterisks in the last column mark experiments for  which MERT had to be re-run.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9990705847740173}, {"text": "JRC data", "start_pos": 52, "end_pos": 60, "type": "DATASET", "confidence": 0.7401499599218369}]}, {"text": " Table 2: Reduction of vocabulary size by suffix trimming", "labels": [], "entities": [{"text": "suffix trimming", "start_pos": 42, "end_pos": 57, "type": "TASK", "confidence": 0.7269723415374756}]}, {"text": " Table 3: Back-off BLEU scores comparison", "labels": [], "entities": [{"text": "Back-off", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9055348634719849}, {"text": "BLEU", "start_pos": 19, "end_pos": 23, "type": "METRIC", "confidence": 0.9282713532447815}]}, {"text": " Table 4: Case-insensitive BLEU of WMT systems", "labels": [], "entities": [{"text": "BLEU", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.9512903690338135}, {"text": "WMT", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.6983692049980164}]}]}