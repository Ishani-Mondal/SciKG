{"title": [{"text": "Large-Scale Corpus-Driven PCFG Approximation of an HPSG", "labels": [], "entities": [{"text": "HPSG", "start_pos": 51, "end_pos": 55, "type": "DATASET", "confidence": 0.6135528087615967}]}], "abstractContent": [{"text": "We present a novel corpus-driven approach towards grammar approximation fora linguistically deep Head-driven Phrase Structure Grammar.", "labels": [], "entities": [{"text": "grammar approximation", "start_pos": 50, "end_pos": 71, "type": "TASK", "confidence": 0.7139747887849808}]}, {"text": "With an unlexicalized prob-abilistic context-free grammar obtained by Maximum Likelihood Estimate on a large-scale automatically annotated corpus, we are able to achieve parsing accuracy higher than the original HPSG-based model.", "labels": [], "entities": [{"text": "parsing", "start_pos": 170, "end_pos": 177, "type": "TASK", "confidence": 0.9551364183425903}, {"text": "accuracy", "start_pos": 178, "end_pos": 186, "type": "METRIC", "confidence": 0.9350219964981079}]}, {"text": "Different ways of enriching the annotations carried by the approximating PCFG are proposed and compared.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 73, "end_pos": 77, "type": "DATASET", "confidence": 0.8086950182914734}]}, {"text": "Comparison to the state-of-the-art latent-variable PCFG shows that our approach is more suitable for the grammar approximation task where training data can be acquired automatically.", "labels": [], "entities": [{"text": "grammar approximation task", "start_pos": 105, "end_pos": 131, "type": "TASK", "confidence": 0.8023093740145365}]}, {"text": "The best approximating PCFG achieved ParsE-val F 1 accuracy of 84.13%.", "labels": [], "entities": [{"text": "ParsE-val F 1", "start_pos": 37, "end_pos": 50, "type": "METRIC", "confidence": 0.9440833926200867}, {"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.6858789920806885}]}, {"text": "The high ro-bustness of the PCFG suggests it is a viable way of achieving full coverage parsing with the handwritten deep linguistic grammars.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 28, "end_pos": 32, "type": "DATASET", "confidence": 0.962648332118988}, {"text": "full coverage parsing", "start_pos": 74, "end_pos": 95, "type": "TASK", "confidence": 0.5569285055001577}]}], "introductionContent": [{"text": "Deep linguistic processing technologies have been evolving closely around the development of rich formalisms which typically introduce mild context-sensitivity.", "labels": [], "entities": [{"text": "Deep linguistic processing", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6044037640094757}]}, {"text": "Examples of welladopted frameworks include various Tree Adjoining Grammars, Combinatory Categorial Grammars, Lexical Functional Grammars (with untyped Features Structures in F-structures), and HeadDriven Phrase Structure Grammars (with Typed Featured Structures).", "labels": [], "entities": []}, {"text": "Such formalisms have been successfully powering the modern formal linguistic studies.", "labels": [], "entities": []}, {"text": "However, the intrinsic complexity of deeper formalisms 1 hinders the deployment of In the context of this paper, by deeper formalism we mean formalisms which are at least mildly context-sensitive, such resources in language technology applications.", "labels": [], "entities": []}, {"text": "The linguistic framework is built on top of the typed feature logic formalisms (e.g.,).", "labels": [], "entities": []}, {"text": "The monostratal representation integrates various syntactic and semantic information concerning a linguistic object (and all its sub-components) in a single typed features structure.", "labels": [], "entities": []}, {"text": "And the integration of information and compatibility checking is achieved by the unification operation.", "labels": [], "entities": [{"text": "compatibility checking", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.7442931830883026}, {"text": "unification", "start_pos": 81, "end_pos": 92, "type": "TASK", "confidence": 0.9497511982917786}]}, {"text": "Such a formalism is especially suitable for developing and implementing a linguistic theory.", "labels": [], "entities": []}, {"text": "But the lack of a polynomial upperbound time complexity in unification-based parsing raises concerns of the processing efficiency.", "labels": [], "entities": [{"text": "unification-based parsing", "start_pos": 59, "end_pos": 84, "type": "TASK", "confidence": 0.6199509799480438}]}, {"text": "Meanwhile, from the grammar engineering perspective we see grammar developers constantly joggling between two somewhat conflicting goals: on the one hand, to describe the linguistic phenomena in a precisely constrained way; on the other hand, to achieve broad coverage when parsing unseen real-world texts.", "labels": [], "entities": [{"text": "parsing unseen real-world texts", "start_pos": 274, "end_pos": 305, "type": "TASK", "confidence": 0.8687507510185242}]}, {"text": "As a result, many of these large-scale grammar implementations are forced to choose to either compromise the linguistic preciseness, or to accept the low coverage in parsing.", "labels": [], "entities": []}, {"text": "In this paper, we propose PCFG approximation as away to alleviate some of these issues in HPSG processing.", "labels": [], "entities": [{"text": "PCFG approximation", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.772600531578064}, {"text": "HPSG processing", "start_pos": 90, "end_pos": 105, "type": "TASK", "confidence": 0.6949115991592407}]}, {"text": "While HPSG framework is great for linguistic description, we show that when carefully designed, a much simpler approximating probabilistic context-free grammar can be extracted automatically, and is capable of achieving good parsing accuracy while maintaining high robustness and efficiency.", "labels": [], "entities": [{"text": "linguistic description", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.7243649661540985}, {"text": "parsing", "start_pos": 225, "end_pos": 232, "type": "TASK", "confidence": 0.9474426507949829}, {"text": "accuracy", "start_pos": 233, "end_pos": 241, "type": "METRIC", "confidence": 0.8244714736938477}]}, {"text": "The rest of the paper is organized as the following: Section 2 gives an overview of HPSG as an linguistic theory and its application in parsing; in a comparative sense to the context-free grammars.", "labels": [], "entities": []}, {"text": "Section 3 reviews the previous related work on CFG approximation of HPSG; Section 4 presents the corpus-driven PCFG approximation with both internal and external annotations; Section 5 describes the evaluation setup and results; Section 6 compares our approach with other related work on parsing (such as self-training), and foresees the application of the approximating PCFGs; Section 7 concludes the paper.", "labels": [], "entities": [{"text": "CFG approximation", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.6499573886394501}, {"text": "HPSG", "start_pos": 68, "end_pos": 72, "type": "DATASET", "confidence": 0.8466123938560486}]}], "datasetContent": [{"text": "For the evaluation of our approximating PCFGs, we compare the top-1 parses produced by the PCFG with the manually disambiguated gold trees in \"ws13\".", "labels": [], "entities": [{"text": "PCFG", "start_pos": 91, "end_pos": 95, "type": "DATASET", "confidence": 0.9275556206703186}]}, {"text": "We assume the inputs have been pretokenized but not tagged.", "labels": [], "entities": []}, {"text": "All comparisons are done on the original derivations.", "labels": [], "entities": []}, {"text": "Several accuracy measures are used, including the ParsEval labeled bracketing precision, recall, F 1 and exact match ratio.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9993358254432678}, {"text": "ParsEval labeled bracketing precision", "start_pos": 50, "end_pos": 87, "type": "METRIC", "confidence": 0.7304091304540634}, {"text": "recall", "start_pos": 89, "end_pos": 95, "type": "METRIC", "confidence": 0.9996336698532104}, {"text": "F 1", "start_pos": 97, "end_pos": 100, "type": "METRIC", "confidence": 0.9940346777439117}, {"text": "exact match ratio", "start_pos": 105, "end_pos": 122, "type": "METRIC", "confidence": 0.9183224638303121}]}, {"text": "Since the ParsEval scores ignore the preterminal nodes, we also report the (lexical type) tagging accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.8547404408454895}]}, {"text": "Several different training sets are used.", "labels": [], "entities": []}, {"text": "WS contains 7636 \"gold\" trees from the sections \"ws01-ws11\" of the WeScience.", "labels": [], "entities": [{"text": "WS", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.9653545022010803}, {"text": "WeScience", "start_pos": 67, "end_pos": 76, "type": "DATASET", "confidence": 0.9641798734664917}]}, {"text": "The MEM parse selection model is trained with this dataset.", "labels": [], "entities": [{"text": "MEM parse selection", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.8332719604174296}]}, {"text": "The dataset is too small to acquire high coverage PCFGs with heavy annotations.", "labels": [], "entities": []}, {"text": "Therefore, only PCFG(0) and PCFG(FP1) results are reported here.", "labels": [], "entities": [{"text": "PCFG(0)", "start_pos": 16, "end_pos": 23, "type": "METRIC", "confidence": 0.8374681621789932}, {"text": "PCFG(FP1)", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.6628299802541733}]}, {"text": "WW000 contains 85,553 automatically parsed and disambiguated trees from the WikiWoods (all fragments with 000 as suffix).", "labels": [], "entities": [{"text": "WW000", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9681983590126038}]}, {"text": "This is less than 0.2% of the entire WikiWoods, but close to the limit for the latent-variable PCFG training with the Berkeley Parser.", "labels": [], "entities": []}, {"text": "WW00 contains about 482K sentences (all fragments with 00 as suffix), roughly 1% of the entire WikiWoods.", "labels": [], "entities": [{"text": "WW00", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9625864624977112}]}, {"text": "We were able to successfully train PCFGs with relatively rich annotations.", "labels": [], "entities": []}, {"text": "WW contains the complete WikiWoods with \u223c48M parsed tress.", "labels": [], "entities": [{"text": "WW", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.973334550857544}]}, {"text": "With feature-path annotations, the training of the models takes too long.", "labels": [], "entities": []}, {"text": "Also, excessive annotation makes it difficult to parse with the resulting huge grammar.", "labels": [], "entities": []}, {"text": "We stop at two levels of grandparent annotation, a PCFG with almost 4M rules and over 128K non-terminal symbols.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 51, "end_pos": 55, "type": "DATASET", "confidence": 0.9372815489768982}]}, {"text": "summarizes the results of the accuracy evaluation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9994984865188599}]}, {"text": "All results are reported on the 785 trees from the section \"ws13\" of the WeScience.", "labels": [], "entities": [{"text": "WeScience", "start_pos": 73, "end_pos": 82, "type": "DATASET", "confidence": 0.7964121699333191}]}, {"text": "MEM is the accuracy of the HPSG parser disambiguation model given the candidate parse forest. is the unannotated PCFG read off the bare (normalized) derivation trees.", "labels": [], "entities": [{"text": "MEM", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9896966218948364}, {"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9995015859603882}, {"text": "HPSG parser disambiguation", "start_pos": 27, "end_pos": 53, "type": "TASK", "confidence": 0.6888885597387949}]}, {"text": "PCFG is the annotated PCFG model with m-levels of grandparents and n feature-paths.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9545143246650696}]}, {"text": "And PCFG-LA(SM3) is the latent-variable PCFG after three split-merge iterations.", "labels": [], "entities": []}, {"text": "With the small WS training set, the baseline PCFG without annotation achieved F 1 of merely 60.96.", "labels": [], "entities": [{"text": "WS training set", "start_pos": 15, "end_pos": 30, "type": "DATASET", "confidence": 0.7802247405052185}, {"text": "PCFG", "start_pos": 45, "end_pos": 49, "type": "DATASET", "confidence": 0.7923672795295715}, {"text": "F 1", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.9658894836902618}]}, {"text": "Even one level of grandparent annotation, the parsing coverage drops by over 10%.", "labels": [], "entities": [{"text": "parsing", "start_pos": 46, "end_pos": 53, "type": "TASK", "confidence": 0.9579023122787476}, {"text": "coverage", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.526644766330719}]}, {"text": "With 1 feature-path annotation, F 1 improved significantly to 66.45.", "labels": [], "entities": [{"text": "F 1", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.9910869300365448}]}, {"text": "On the larger WW-000, the performance of the baseline PCFG decreases by two 2% of F 1 , most likely due to the noise introduced by the automatic disambiguation.", "labels": [], "entities": [{"text": "WW-000", "start_pos": 14, "end_pos": 20, "type": "DATASET", "confidence": 0.9384669661521912}, {"text": "F 1", "start_pos": 82, "end_pos": 85, "type": "METRIC", "confidence": 0.9893058836460114}]}, {"text": "However, the larger training set enables 1-level grandparent annotation, which brings F 1 up to 71.42.", "labels": [], "entities": [{"text": "F 1", "start_pos": 86, "end_pos": 89, "type": "METRIC", "confidence": 0.9901750385761261}]}, {"text": "The latent-variable PCFG also performs well, delivering the best F 1 at 71.87 after three split-merge iterations.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 20, "end_pos": 24, "type": "DATASET", "confidence": 0.840142548084259}, {"text": "F 1", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.9934401512145996}]}, {"text": "But the learning curve of the Berkeley parser has already flatten out at this point, and we were unsuccessful in further scaling up the training set.", "labels": [], "entities": []}, {"text": "With our annotated PCFGs, significant improvements are achieved on the even larger WW-00.", "labels": [], "entities": [{"text": "PCFGs", "start_pos": 19, "end_pos": 24, "type": "DATASET", "confidence": 0.9355648756027222}, {"text": "WW-00", "start_pos": 83, "end_pos": 88, "type": "DATASET", "confidence": 0.9307740926742554}]}, {"text": "The baseline PCFG seems to have recovered from the previous drop, and outperforms the one trained with the \"gold\" trees.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 13, "end_pos": 17, "type": "DATASET", "confidence": 0.8257109522819519}]}, {"text": "With the mixture of 1-level of grandparent and some feature-path annotations, F 1 reached over 80.", "labels": [], "entities": [{"text": "F 1", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.9816975593566895}]}, {"text": "The best performance on WW-00 is achieved with PCFG(GP1,FP5).", "labels": [], "entities": [{"text": "WW-00", "start_pos": 24, "end_pos": 29, "type": "DATASET", "confidence": 0.7551584243774414}, {"text": "PCFG", "start_pos": 47, "end_pos": 51, "type": "DATASET", "confidence": 0.7152323722839355}]}, {"text": "2-levels of grandparents alone outperforms 1-level of grandparent, but the grammar quickly reaches its size limit on this training set and starts to loose coverage when more feature-path annotations are added.", "labels": [], "entities": []}, {"text": "Finally, with the complete WikiWoods, both PCFG(GP1) and PCFG(GP2) improved further, with PCFG(GP2) reaching the highest F 1 at 84.13.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 43, "end_pos": 47, "type": "DATASET", "confidence": 0.8456305861473083}, {"text": "PCFG", "start_pos": 57, "end_pos": 61, "type": "DATASET", "confidence": 0.8845962882041931}, {"text": "F 1", "start_pos": 121, "end_pos": 124, "type": "METRIC", "confidence": 0.9956046938896179}]}, {"text": "It is interesting to note that this is even higher than the F 1 of the MEM disambiguation model.", "labels": [], "entities": [{"text": "F 1", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.9931926131248474}, {"text": "MEM disambiguation", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.6256489455699921}]}, {"text": "This is partially due to the self-training effect on the huge corpus.", "labels": [], "entities": []}, {"text": "Another explanation is that the objective function of the discriminative MEM was optimized on the complete parse match instead of individual constituents, which will explain its high exact match ratio at 43.57%.", "labels": [], "entities": [{"text": "exact match ratio", "start_pos": 183, "end_pos": 200, "type": "METRIC", "confidence": 0.9641615152359009}]}], "tableCaptions": [{"text": " Table 2: Parsing Accuracy on 'ws13' with various models and training sets. Reported are grammar size (#Rule,  #NT, #T); ParsEval precision (P), recall (R), F 1 , and exact match ratio (Ex) on the original derivation tree; and  tagging accuracy (TA) on the lexical types.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.923112154006958}, {"text": "ParsEval precision (P)", "start_pos": 121, "end_pos": 143, "type": "METRIC", "confidence": 0.9198006153106689}, {"text": "recall (R)", "start_pos": 145, "end_pos": 155, "type": "METRIC", "confidence": 0.9459813237190247}, {"text": "F 1", "start_pos": 157, "end_pos": 160, "type": "METRIC", "confidence": 0.9690314531326294}, {"text": "exact match ratio (Ex)", "start_pos": 167, "end_pos": 189, "type": "METRIC", "confidence": 0.9440537889798483}, {"text": "accuracy (TA)", "start_pos": 236, "end_pos": 249, "type": "METRIC", "confidence": 0.938105896115303}]}]}