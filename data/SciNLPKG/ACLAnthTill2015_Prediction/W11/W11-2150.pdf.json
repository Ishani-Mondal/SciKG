{"title": [{"text": "ILLC-UvA translation system for EMNLP-WMT 2011", "labels": [], "entities": [{"text": "ILLC-UvA translation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6462052911520004}]}], "abstractContent": [{"text": "In this paper we describe the Institute for Logic, Language and Computation (Uni-versity of Amsterdam) phrase-based statistical machine translation system for English-to-German translation proposed within the EMNLP-WMT 2011 shared task.", "labels": [], "entities": [{"text": "Logic, Language and Computation (Uni-versity of Amsterdam) phrase-based statistical machine translation", "start_pos": 44, "end_pos": 147, "type": "TASK", "confidence": 0.6114270772252764}, {"text": "EMNLP-WMT 2011 shared task", "start_pos": 209, "end_pos": 235, "type": "TASK", "confidence": 0.737464651465416}]}, {"text": "The main novelty of the submitted system is a syntax-driven pre-translation reordering algorithm implemented as source string permutation via transfer of the source-side syntax tree.", "labels": [], "entities": []}], "introductionContent": [{"text": "For the WMT 2011 shared task, ILLC-UvA submitted two translations (primary and secondary) for the English-to-German translation task.", "labels": [], "entities": [{"text": "WMT 2011 shared task", "start_pos": 8, "end_pos": 28, "type": "TASK", "confidence": 0.7572537064552307}, {"text": "English-to-German translation task", "start_pos": 98, "end_pos": 132, "type": "TASK", "confidence": 0.7134567697842916}]}, {"text": "This year, we directed our research toward addressing the word order problem for statistical machine translation (SMT) and discover its impact on output translation quality.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 81, "end_pos": 118, "type": "TASK", "confidence": 0.8043891688187917}]}, {"text": "We reorder the words of a sentence of the source language with respect to the word order of the target language and a given source-side parse tree.", "labels": [], "entities": []}, {"text": "The difference from the baseline Moses-based translation system lies in the pre-translation step, in which we introduce a discriminative source string permutation model based on probabilistic parse tree transduction.", "labels": [], "entities": []}, {"text": "The idea here is to permute the order of the source words in such away that the resulting permutation allows as monotone a translation process as possible is not new.", "labels": [], "entities": []}, {"text": "This approach to enhance SMT by using a reordering step prior to translation has proved to be successful in improving translation quality for many translation tasks, see), for example.", "labels": [], "entities": [{"text": "SMT", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9956936836242676}]}, {"text": "The general problem of source-side reordering is that the number of permutations is factorial inn, and learning a sequence of transductions for explaining a source permutation can be computationally rather challenging.", "labels": [], "entities": []}, {"text": "We propose to address this problem by defining the source-side permutation process as the learning problem of how to transfer a given source parse tree into a parse tree that minimizes the divergence from target word order.", "labels": [], "entities": []}, {"text": "Our reordering system is inspired by the direction taken in), but differs in defining the space of permutations, using local probabilistic tree transductions, as well as in the learning objective aiming at scoring permutations based on a log-linear interpolation of a local syntax-based model with a global string-based (language) model.", "labels": [], "entities": []}, {"text": "The reordering (novel) and translation (standard) components are described in the following sections.", "labels": [], "entities": []}, {"text": "The rest of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "After a brief description of the phrase-based translation system in Section 2, we present the architecture and details of our reordering system (Section 3), Section 4 reviews related work, Section 5 reports the experimental setup, details the submissions and discusses the results, while Section 6 concludes the article.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 33, "end_pos": 57, "type": "TASK", "confidence": 0.6182902157306671}]}], "datasetContent": [{"text": "Design, architecture and configuration of the translation system that we used in experimentation coincides with the Moses-based translation system (Baseline system) described in details on the WMT 2011 web page 2 . This section details the experiments carried out to evaluate the proposed reordering model, experimental set-up and data.", "labels": [], "entities": [{"text": "WMT 2011 web page", "start_pos": 193, "end_pos": 210, "type": "DATASET", "confidence": 0.9712348878383636}]}, {"text": "Moses toolkit () in its standard setting was used to build the SMT systems: \u2022 GIZA++/mkcls) for word alignment.", "labels": [], "entities": [{"text": "SMT", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.9847726821899414}, {"text": "word alignment", "start_pos": 96, "end_pos": 110, "type": "TASK", "confidence": 0.8001464307308197}]}, {"text": "\u2022 SRI LM) for language modeling.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 14, "end_pos": 31, "type": "TASK", "confidence": 0.77796870470047}]}, {"text": "A 3-gram target language model was estimated and smoothed with modified KneserNey discounting.", "labels": [], "entities": []}, {"text": "\u2022 MOSES ( to build an unfactored translation system.", "labels": [], "entities": [{"text": "MOSES", "start_pos": 2, "end_pos": 7, "type": "METRIC", "confidence": 0.5439389944076538}]}, {"text": "\u2022 the Stanford parser () was used as a source-side parsing engine 3 . \u2022 For maximum entropy modeling we used the maxent toolkit 4 . The discriminative syntactic reordering model is applied to reorder training, development, and test corpora.", "labels": [], "entities": []}, {"text": "A Moses-based translation system (corpus realignment included 5 ) is then trained using the reordered input.", "labels": [], "entities": [{"text": "Moses-based translation", "start_pos": 2, "end_pos": 25, "type": "TASK", "confidence": 0.5731913298368454}]}], "tableCaptions": [{"text": " Table 3: Internal testing results.", "labels": [], "entities": []}]}