{"title": [{"text": "Towards Strict Sentence Intersection: Decoding and Evaluation Strategies", "labels": [], "entities": [{"text": "Strict Sentence Intersection", "start_pos": 8, "end_pos": 36, "type": "TASK", "confidence": 0.6947214802106222}]}], "abstractContent": [{"text": "We examine the task of strict sentence intersection: a variant of sentence fusion in which the output must only contain the information present in all input sentences and nothing more.", "labels": [], "entities": [{"text": "strict sentence intersection", "start_pos": 23, "end_pos": 51, "type": "TASK", "confidence": 0.6674467027187347}, {"text": "sentence fusion", "start_pos": 66, "end_pos": 81, "type": "TASK", "confidence": 0.7621689736843109}]}, {"text": "Our proposed approach involves alignment and generalization over the input sentences to produce a generation lattice; we then compare a standard search-based approach for decoding an intersection from this lattice to an integer linear program that preserves aligned content while minimizing the disfluency in interleaving text segments.", "labels": [], "entities": []}, {"text": "In addition, we introduce novel evaluation strategies for intersection problems that employ entailment-style judgments for determining the validity of system-generated intersections.", "labels": [], "entities": []}, {"text": "Our experiments show that the proposed models produce valid intersections a majority of the time and that the segmented decoder yields advantages over the search-based approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, there has been growing interest in text-to-text generation problems which transform text according to specifications.", "labels": [], "entities": [{"text": "text-to-text generation", "start_pos": 52, "end_pos": 75, "type": "TASK", "confidence": 0.7243722081184387}]}, {"text": "Tasks such as sentence compression, which strives to retain the most salient content of an input sentence, and sentence fusion, which attempts to combine the important content in related sentences, are useful components for tackling larger natural language problems such as abstractive summarization of documents.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 14, "end_pos": 34, "type": "TASK", "confidence": 0.741835817694664}, {"text": "sentence fusion", "start_pos": 111, "end_pos": 126, "type": "TASK", "confidence": 0.7634439766407013}, {"text": "abstractive summarization of documents", "start_pos": 274, "end_pos": 312, "type": "TASK", "confidence": 0.708645410835743}]}, {"text": "Systems for these types of text-to-text problems are typically evaluated on the informativeness of the output text as judged by human annotators.", "labels": [], "entities": []}, {"text": "A natural aspect of most text generation systems is that a given input can map to a range of lexically diverse outputs.", "labels": [], "entities": [{"text": "text generation", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.7481340169906616}]}, {"text": "However, text-to-text tasks defined with vague criteria such as the preservation of the \"important\" information in text can also permit outputs that are semantically distinct.", "labels": [], "entities": []}, {"text": "This can make evaluation difficult; for instance, systemgenerated sentences may differ (partially or completely) in informational content from reference human-annotated text.", "labels": [], "entities": []}, {"text": "This phenomenon has been noted and discussed in the task of pairwise sentence fusion) and also in sentence compression).", "labels": [], "entities": [{"text": "pairwise sentence fusion", "start_pos": 60, "end_pos": 84, "type": "TASK", "confidence": 0.6026375492413839}, {"text": "sentence compression", "start_pos": 98, "end_pos": 118, "type": "TASK", "confidence": 0.7636843323707581}]}, {"text": "Some examples are listed in.", "labels": [], "entities": []}, {"text": "In this work, we examine the task of sentence intersection: a variant of sentence fusion that does not permit semantic variation in the output.", "labels": [], "entities": [{"text": "sentence intersection", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.7359277158975601}, {"text": "sentence fusion", "start_pos": 73, "end_pos": 88, "type": "TASK", "confidence": 0.7591874003410339}]}, {"text": "A strict 1 intersection system is expected to produce a fused sentence that contains all the information common to its input sentences and avoid information that is in just one of the inputs.", "labels": [], "entities": []}, {"text": "In other words, a valid intersection should only contain information that is substantiated by all input sentences.", "labels": [], "entities": []}, {"text": "The set-theoretic notions of intersection (along with union) have been employed to describe variants of sentence fusion tasks in previous work) but, to our knowledge, this work is the first to explicitly tackle and evaluate the strict intersection task.", "labels": [], "entities": [{"text": "sentence fusion tasks", "start_pos": 104, "end_pos": 125, "type": "TASK", "confidence": 0.7985995411872864}]}, {"text": "We focus on the case of unsupervised pairwise sentence intersection and propose a strategy to yield (a) Fusion example from (i) After years of pursuing separate and conflicting paths, AT&T and Digital Equipment Corp.", "labels": [], "entities": [{"text": "pairwise sentence intersection", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.6835745672384897}]}, {"text": "agreed in June to settle their computer-to-PBX differences.", "labels": [], "entities": []}, {"text": "(ii) The two will jointly develop an applications interface that can be shared by computers and PBXs of any stripe.", "labels": [], "entities": []}, {"text": "Human fusion #1 AT&T and Digital Equipment Corp.", "labels": [], "entities": [{"text": "Human fusion", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.691657617688179}]}, {"text": "agreed in June to settle their computer-to-PBX differences and develop an applications interface that can be shared by any computer or PBX.", "labels": [], "entities": []}, {"text": "Human fusion #2 After years of pursuing different paths, AT&T and Digital agreed to jointly develop an applications interface that can be shared by computers and PBXs of any stripe.", "labels": [], "entities": [{"text": "Human fusion", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.6954891681671143}]}, {"text": "(b) Compression example from TapeWare , which supports DOS and NetWare 286 , is a value-added process that lets you directly connect the QA150-EXAT to a file server and issue a command from any workstation to backup the server Human compression #1 TapeWare supports DOS and NetWare 286 Human compression #2 TapeWare lets you connect the QA150-EXAT to a file server  valid intersections that follows the basic framework of previous unsupervised fusion systems ().", "labels": [], "entities": []}, {"text": "In our approach, the input sentences are first aligned using a modified version of a recent phrase-based alignment approach (.", "labels": [], "entities": []}, {"text": "We assume the alignments that are produced define aspects of the input that must appear in the output fusion and consider decoding strategies to recover intersections that preserve these alignments.", "labels": [], "entities": []}, {"text": "In addition to a search-based decoding strategy, we propose a constrained integer linear programming (ILP) formulation that attempts to decode the most fluent sentence covering all these aspects while minimizing the size and disfluency of interleaving text.", "labels": [], "entities": []}, {"text": "This is a fairly general model which can also be extended to other alignment-based tasks such as pairwise union and difference.", "labels": [], "entities": []}, {"text": "As this is a substantially more constrained task than generic sentence fusion, we also present a novel evaluation approach that avoids out-of-context salience judgments.", "labels": [], "entities": [{"text": "generic sentence fusion", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.6740361154079437}]}, {"text": "We make use of a recentlyreleased corpus of fusion candidates and propose a crowdsourced entailmentstyle evaluation to determine the validity of generated intersections, as well as the grammaticality of the sentences produced.", "labels": [], "entities": []}, {"text": "Additionally, automated machine translation (MT) metrics are explored to quantify the amount of information missing from valid intersections.", "labels": [], "entities": [{"text": "automated machine translation (MT)", "start_pos": 14, "end_pos": 48, "type": "TASK", "confidence": 0.7911625951528549}]}, {"text": "Our decoding strategies show promise under these experiments and we discuss potential directions for improving intersection performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "A corpus of sentence fusion instances was recently made available by, consisting of 297 sentence pairs taken from newswire clusters and manually judged as being good candidates for fusion.", "labels": [], "entities": [{"text": "sentence fusion instances", "start_pos": 12, "end_pos": 37, "type": "TASK", "confidence": 0.7909172177314758}]}, {"text": "Each sentence pair is accompanied by human-produced intersections and unions collected via Amazon's Mechanical Turk service . noted that union responses are mostly valid but intersections are frequently incorrect and 1 (i) Home Secretary John Reid said Sunday the inquiry would go wherever \"the police take it.\"", "labels": [], "entities": [{"text": "Amazon's Mechanical Turk service", "start_pos": 91, "end_pos": 123, "type": "DATASET", "confidence": 0.8051380395889283}]}, {"text": "(ii) It comes as Home Secretary John Reid said the inquiry into Mr Litvinenko's poisoning would expand beyond Britain.", "labels": [], "entities": []}, {"text": "2 (i) Traces of polonium have been found on the planes on which they are believed to have travelled between London and Moscow.", "labels": [], "entities": []}, {"text": "(ii) Small traces of radioactive substances had been found on the planes.", "labels": [], "entities": []}, {"text": "3 (i) Prosecutors allege that the accuser, who appeared in the program, was molested after the show aired.", "labels": [], "entities": []}, {"text": "(ii) Prosecutors allege that the boy, a cancer survivor, was molested twice after the program aired.", "labels": [], "entities": []}, {"text": "contains the corresponding systemgenerated intersections for these sentence pairs.", "labels": [], "entities": []}, {"text": "hypothesized that the task is more confusing for untrained annotators.", "labels": [], "entities": []}, {"text": "A similar phenomenon was noted by: while demonstrating that query-based human fusions exhibited less variation than generic fusions, it was also observed that intersections varied more than unions.", "labels": [], "entities": []}, {"text": "Due to the absence of adequate training data for intersection, our approach to the task is unsupervised, similar to previous work in fusion () and sentence compression).", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 147, "end_pos": 167, "type": "TASK", "confidence": 0.7334241718053818}]}, {"text": "Additionally, we focus on the case of pairwise sentence intersection and assume that the common information between the input sentence pair can be represented within a single output sentence.", "labels": [], "entities": [{"text": "pairwise sentence intersection", "start_pos": 38, "end_pos": 68, "type": "TASK", "confidence": 0.6533988813559214}]}, {"text": "As a result, although the McKeown et al.", "labels": [], "entities": [{"text": "McKeown et al.", "start_pos": 26, "end_pos": 40, "type": "DATASET", "confidence": 0.9406292587518692}]}, {"text": "(2010) corpus cannot be used for training an intersection model, we can make use of the sentence pairs it contains for evaluation.", "labels": [], "entities": []}, {"text": "We now turn to the design of experiments for the strict sentence intersection task and discuss the performance of the proposed models using the corpus provided by.", "labels": [], "entities": [{"text": "strict sentence intersection task", "start_pos": 49, "end_pos": 82, "type": "TASK", "confidence": 0.7319218516349792}]}, {"text": "We use abeam size of 50 for the beam search decoder and a 4-gram LM for all experiments.", "labels": [], "entities": [{"text": "beam search decoder", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.863651176293691}]}, {"text": "Dependency parsing is accomplished with MICA, a TAG-based parser (Bangalore et al., 2009).", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8339416980743408}]}, {"text": "Our primary considerations for studying system-generated fusions are validity (whether the output contains only the information common to each sentence), coverage (whether the output contains all the common information in the input sentences) and the fluency of the output.", "labels": [], "entities": [{"text": "validity", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9910680651664734}, {"text": "coverage", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.9885138869285583}]}, {"text": "Turning to the systems understudy, we observe that the ILP-based segmented decoder produces text that is judged more fluent on average than the beam search decoder.", "labels": [], "entities": []}, {"text": "In order to judge the degree of overlap between the two systems, we also report the performance of a pseudo-hybrid oracle combination system which assumes the presence of an oracle that runs both decoders and always chooses the output intersection that is more grammatical.", "labels": [], "entities": []}, {"text": "The improved performance illustrates that each decoder has its advantages and that areal hybrid system might yield improvements over either approach.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Intersections produced for the examples introduced in Table 2 along with judgments from AMT users.", "labels": [], "entities": []}, {"text": " Table 4: Results of the AMT evaluation described in  \u00a75.1.  Statistically insignificant differences within columns are  indicated with  \u2020; all other entries are significantly distinct  at p \u2264 0.05.", "labels": [], "entities": [{"text": "AMT", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.9095335602760315}]}, {"text": " Table 5: Results of the automated evaluation for coverage  of intersections described in  \u00a75.3.", "labels": [], "entities": [{"text": "coverage  of intersections", "start_pos": 50, "end_pos": 76, "type": "TASK", "confidence": 0.762724240620931}]}]}