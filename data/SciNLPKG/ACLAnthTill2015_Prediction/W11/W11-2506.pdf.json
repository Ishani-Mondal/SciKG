{"title": [{"text": "Assessing Interpretable, Attribute-related Meaning Representations for Adjective-Noun Phrases in a Similarity Prediction Task", "labels": [], "entities": [{"text": "Assessing Interpretable, Attribute-related Meaning Representations for Adjective-Noun Phrases", "start_pos": 0, "end_pos": 93, "type": "TASK", "confidence": 0.5985329217380948}, {"text": "Similarity Prediction", "start_pos": 99, "end_pos": 120, "type": "TASK", "confidence": 0.8520436584949493}]}], "abstractContent": [{"text": "We present a distributional vector space model that incorporates Latent Dirichlet Allocation in order to capture the semantic relation holding between adjectives and nouns along inter-pretable dimensions of meaning: The meaning of adjective-noun phrases is characterized in terms of ontological attributes that are prominent in their compositional semantics.", "labels": [], "entities": []}, {"text": "The model is evaluated in a similarity prediction task based on paired adjective-noun phrases from the Mitchell and Lapata (2010) benchmark data.", "labels": [], "entities": [{"text": "similarity prediction", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.7665033340454102}, {"text": "Mitchell and Lapata (2010) benchmark data", "start_pos": 103, "end_pos": 144, "type": "DATASET", "confidence": 0.7610250636935234}]}, {"text": "Comparing our model against a high-dimensional latent word space, we observe qualitative differences that shed light on different aspects of similarity conveyed by both models and suggest integrating their complementary strengths.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper offers a comparative evaluation of two types of accounts to the compositional meaning of adjective-noun phrases.", "labels": [], "entities": []}, {"text": "This comparison is embedded in a similarity judgement task that determines the semantic similarity of pairs of adjective-noun phrases.", "labels": [], "entities": []}, {"text": "All models we consider establish the similarity of adjective-noun pairs by measuring similarity between vectors representing the meaning of the individual adjective-noun phrases.", "labels": [], "entities": []}, {"text": "However, the models we investigate differ in the type of interpretation they assign to adjectives, nouns and the phrases composed from them.", "labels": [], "entities": []}, {"text": "One type of approach is represented by the classical vector space model (VSM) of.", "labels": [], "entities": []}, {"text": "It represents the semantics of adjective-noun phrases in latent semantic space, based on dimensions defined by bags of context words.", "labels": [], "entities": []}, {"text": "This classical model will be compared against a compositional analysis of adjectivenoun phrases that represents adjectives and nouns along interpretable dimensions of meaning, i.e. discrete ontological attributes such as SIZE, COLOR, SPEED, WEIGHT.", "labels": [], "entities": [{"text": "COLOR", "start_pos": 227, "end_pos": 232, "type": "METRIC", "confidence": 0.9019610285758972}, {"text": "SPEED", "start_pos": 234, "end_pos": 239, "type": "METRIC", "confidence": 0.9618377089500427}, {"text": "WEIGHT", "start_pos": 241, "end_pos": 247, "type": "METRIC", "confidence": 0.7657032608985901}]}, {"text": "Here, lexical vectors for adjectives and nouns define possible attribute meanings as component values; vector composition is intended to elicit those attributes that are prominent in the meaning of the whole phrase.", "labels": [], "entities": []}, {"text": "For instance, a composed vector representation of the phrase hot pepper is expected to yield high component values on the dimensions TASTE and SMELL, rather than TEM-PERATURE.", "labels": [], "entities": [{"text": "TASTE", "start_pos": 133, "end_pos": 138, "type": "METRIC", "confidence": 0.9902464151382446}, {"text": "SMELL", "start_pos": 143, "end_pos": 148, "type": "METRIC", "confidence": 0.9491264224052429}, {"text": "TEM-PERATURE", "start_pos": 162, "end_pos": 174, "type": "METRIC", "confidence": 0.8206048607826233}]}, {"text": "The underlying relations between adjectives and nouns, respectively, and the attributes they denote is captured byway of latent semantic information obtained from Latent Dirichlet Allocation (LDA;).", "labels": [], "entities": []}, {"text": "Thus, we treat attributes as an abstract meaning layer that generalizes over latent topics inferred by LDA and utilize this interpretable layer as the dimensions of our VSM.", "labels": [], "entities": []}, {"text": "This approach has been shown to be effective in an attribute selection task (, where the goal is to predict the most prominent attribute(s) \"hidden\" in the compositional semantics of adjective-noun phrases.", "labels": [], "entities": [{"text": "attribute selection task", "start_pos": 51, "end_pos": 75, "type": "TASK", "confidence": 0.7742681503295898}]}, {"text": "In this paper, our main interest is to assess the potential of modeling adjective semantics in terms of discrete, interpretable attribute meanings in a similarity judgement task, as opposed to a representation in latent semantic space that is usually applied to tasks of this kind.", "labels": [], "entities": []}, {"text": "For this purpose, we rely on the evaluation data set of M&L which serves as a shared benchmark in the GEMS 2011 workshop.", "labels": [], "entities": [{"text": "evaluation data set of M&L", "start_pos": 33, "end_pos": 59, "type": "DATASET", "confidence": 0.8139949100358146}, {"text": "GEMS 2011 workshop", "start_pos": 102, "end_pos": 120, "type": "DATASET", "confidence": 0.6322954098383585}]}, {"text": "Their similarity judgement task, being tailored to measuring latent similarity, represents a true challenge for an analysis focused on discrete ontological attributes.", "labels": [], "entities": []}, {"text": "Our results show that the latent semantic model of M&L cannot be beaten by an interpreted analysis based on LDA topic models.", "labels": [], "entities": [{"text": "M&L", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.8910741209983826}]}, {"text": "However, we show substantial performance improvements of the interpreted analysis in specific settings with adapted training and test sets that enable focused comparison.", "labels": [], "entities": []}, {"text": "An interesting outcome of our investigations is that -using an interpreted LDA analysis of adjective-noun phrases -we uncover divergences in the notions of similarity underlying the judgement task that go virtually unnoticed in a latent semantic VSM, while they need to be clearly distinguished in models focused on interpretable representations.", "labels": [], "entities": []}, {"text": "The paper is structured as follows: After a brief summarization of related work, Section 3 introduces Controled LDA, a weakly supervised extension to standard LDA, and explains how it can be utilized to inject interpretable meaning dimensions into VSMs.", "labels": [], "entities": []}, {"text": "In Section 4, we describe the parameters and experimental settings for comparing our model to M&L's word-based latent VSM in a similarity prediction task.", "labels": [], "entities": [{"text": "M&L's word-based latent VSM", "start_pos": 94, "end_pos": 121, "type": "DATASET", "confidence": 0.8027343835149493}, {"text": "similarity prediction task", "start_pos": 127, "end_pos": 153, "type": "TASK", "confidence": 0.8022949894269308}]}, {"text": "Section 5 presents the results of this experiment, followed by a thorough qualitative analysis of the specific strengths and weaknesses of both models in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments are based on the adjectivenoun section of M&L's 2010 evaluation data set 2 . It consists of 108 pairs of adjective-noun phrases that were rated for similarity by human judges.", "labels": [], "entities": [{"text": "M&L's 2010 evaluation data set 2", "start_pos": 58, "end_pos": 90, "type": "DATASET", "confidence": 0.9357897705501981}]}, {"text": "We contrast the two LDA-based models (i, ii) C-LDA-A and C-LDA-T with two standard VSMs: (iii) a re-implementation of the latent VSM of M&L and (iv) a dependency-based VSM (DepVSM) which relies on dependency paths that connect the target elements and attribute nouns in local contexts.", "labels": [], "entities": []}, {"text": "The paths are identical to the ones used for constructing pseudo-documents in (i) and (ii).", "labels": [], "entities": []}, {"text": "Thus, DepVSM relies on the same information as C-LDA-A and C-LDA-T, without capitalizing on the smoothing power provided by LDA.", "labels": [], "entities": []}, {"text": "In the C-LDA models, we experiment with several topic number settings.", "labels": [], "entities": []}, {"text": "Depending on the number of attributes |A| contained in the training material (see below), we train one model instance for each topic number in the range from 0.5 \u00b7 |A| to 2 \u00b7 |A|.", "labels": [], "entities": []}, {"text": "For our LDA implementations, we use MALLET).", "labels": [], "entities": [{"text": "MALLET", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9829713702201843}]}, {"text": "We run 1000 iterations of Gibbs sampling with hyperparameters set to the default values.", "labels": [], "entities": []}, {"text": "For C-LDA-A, C-LDA-T and DepVSM we apply two different training scenarios: In the first setting, we collect pseudo-documents instantiating 262 attribute nouns that are linked to adjectives by an attribute relation in WordNet.", "labels": [], "entities": [{"text": "DepVSM", "start_pos": 25, "end_pos": 31, "type": "DATASET", "confidence": 0.9230096340179443}, {"text": "WordNet", "start_pos": 217, "end_pos": 224, "type": "DATASET", "confidence": 0.9656087160110474}]}, {"text": "The topic distributions induced from this data cover the broadest space of attribute meanings we could produce from WordNet 3 . Ina second setting, we assume the presence of an \"oracle\" that confines the training data to a subset of 33 attribute nouns that are linked to those adjectives that actually occur in the M&L test set, to allow fora focused evaluation.", "labels": [], "entities": [{"text": "M&L test set", "start_pos": 315, "end_pos": 327, "type": "DATASET", "confidence": 0.7774497270584106}]}, {"text": "In both C-LDA variants, all adjectives and nouns occurring at least five times in the pseudo-documents become target elements in the VSM.", "labels": [], "entities": []}, {"text": "The pseudo-documents are collected along dependency paths extracted from section 2 of the pukWaC corpus (.", "labels": [], "entities": [{"text": "pukWaC corpus", "start_pos": 90, "end_pos": 103, "type": "DATASET", "confidence": 0.9889638423919678}]}, {"text": "The same settings are used for training the DepVSM model.", "labels": [], "entities": []}, {"text": "As the M&L model is not intended to reflect attribute meaning, the training data for this model remains constant.", "labels": [], "entities": []}, {"text": "Like M&L, we set the target elements of this model to all types contained in the complete evaluation data set (including nouns, ad-jectives and verbs) and select the 2000 context words that co-occur most frequently with these targets in pukWaC 2 as the dimensions of the space.", "labels": [], "entities": [{"text": "pukWaC 2", "start_pos": 237, "end_pos": 245, "type": "DATASET", "confidence": 0.9206331074237823}]}, {"text": "Given the different types of \"semantic gist\" of the models described above, we expect that the LDA models perform best on those test pairs that involve attributes known to the model.", "labels": [], "entities": []}, {"text": "To test this expectation, we compile a restricted test set containing 43 pairs (adj 1 n 1 , adj 2 n 2 ) where both adj 1 and adj 2 bear an attribute meaning according to WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 170, "end_pos": 177, "type": "DATASET", "confidence": 0.9825437664985657}]}, {"text": "In our experiments, we use a subset of the operators proposed by to obtain a compositional representation of adjective-noun phrases from individual vectors: vector multiplication (\u00d7; best operator in M&L's experiments on adjective-noun phrases) and vector addition (+).", "labels": [], "entities": []}, {"text": "Besides, in order to assess the contribution of individual vectors in the composition process, we experiment with two \"composition surrogates\" by taking the individual adjective (ADJonly) or noun vector (N-only) as the result of the composition process.", "labels": [], "entities": []}, {"text": "The models described above are evaluated against the human similarity judgements data provided by as follows: We compute the cosine similarity between the composed vectors representing the adjective-noun phrases in each test pair.", "labels": [], "entities": []}, {"text": "Next, we measure the correlation between the model scores and the human judgements in terms of Spearman's \u03c1, where each human rating is treated as an individual data point.", "labels": [], "entities": [{"text": "Spearman's \u03c1", "start_pos": 95, "end_pos": 107, "type": "METRIC", "confidence": 0.7072228093942007}]}, {"text": "The correlation coefficient finally reported is the average overall instances 4 of one model.", "labels": [], "entities": [{"text": "correlation", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9699007868766785}]}, {"text": "For completeness, we also report the correlation score of the best model instance and the standard deviation overall model instances.", "labels": [], "entities": [{"text": "correlation score", "start_pos": 37, "end_pos": 54, "type": "METRIC", "confidence": 0.9771370589733124}]}], "tableCaptions": [{"text": " Table 1: Correlation coefficients (Spearman's \u03c1) for different training sets, complete test set", "labels": [], "entities": [{"text": "Correlation", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9362939596176147}, {"text": "Spearman's \u03c1)", "start_pos": 36, "end_pos": 49, "type": "METRIC", "confidence": 0.73530363291502}]}, {"text": " Table 2: Correlation coefficients (Spearman's \u03c1) for different training sets and filtered test sets", "labels": [], "entities": [{"text": "Spearman's \u03c1)", "start_pos": 36, "end_pos": 49, "type": "METRIC", "confidence": 0.7026352807879448}]}, {"text": " Table 4: Similarity scores predicted by optimal C-LDA-A and M&L model instances; 33-ATTR setting", "labels": [], "entities": [{"text": "Similarity", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.850967526435852}]}, {"text": " Table 5: Test pairs showing high and low agreement between systems and human raters, together with system similarity  scores as obtained from optimal model instances; 33-ATTR setting", "labels": [], "entities": []}]}