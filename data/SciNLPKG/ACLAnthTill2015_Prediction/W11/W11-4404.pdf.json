{"title": [{"text": "Supervised and Semi-Supervised Sequence Learning for Recognition of Requisite Part and Effectuation Part in Law Sentences", "labels": [], "entities": [{"text": "Recognition of Requisite Part and Effectuation Part in Law Sentences", "start_pos": 53, "end_pos": 121, "type": "TASK", "confidence": 0.6415535509586334}]}], "abstractContent": [{"text": "Analyzing the logical structure of a sentence is important for understanding natural language.", "labels": [], "entities": [{"text": "Analyzing the logical structure of a sentence", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.8234689065388271}]}, {"text": "In this paper, we present a task of Recognition of Requisite Part and Effectuation Part in Law Sentences, or RRE task for short, which is studied in research on Legal Engineering.", "labels": [], "entities": []}, {"text": "The goal of this task is to recognize the structure of a law sentence.", "labels": [], "entities": [{"text": "recognize the structure of a law sentence", "start_pos": 28, "end_pos": 69, "type": "TASK", "confidence": 0.793537301676614}]}, {"text": "We empirically investigate how the RRE task is conducted with respect to various supervised machine learning models.", "labels": [], "entities": [{"text": "RRE task", "start_pos": 35, "end_pos": 43, "type": "TASK", "confidence": 0.9196245670318604}]}, {"text": "We also compared the impact of un-labeled data to RRE tasks.", "labels": [], "entities": [{"text": "RRE tasks", "start_pos": 50, "end_pos": 59, "type": "TASK", "confidence": 0.895706057548523}]}, {"text": "Experimental results for Japanese legal text domains showed that sequence learning models are suitable for RRE tasks and unlabled data also significantly contribute to the performance of RRE tasks.", "labels": [], "entities": [{"text": "RRE tasks", "start_pos": 107, "end_pos": 116, "type": "TASK", "confidence": 0.9316039681434631}, {"text": "RRE tasks", "start_pos": 187, "end_pos": 196, "type": "TASK", "confidence": 0.9198273718357086}]}], "introductionContent": [{"text": "Legal Engineering (Katayama 07) is anew research field which aims to achieve a trustworthy electronic society.", "labels": [], "entities": [{"text": "Legal Engineering (Katayama 07)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6291658282279968}]}, {"text": "There are two important goals of Legal Engineering.", "labels": [], "entities": [{"text": "Legal Engineering", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.8955213725566864}]}, {"text": "The first goal is to help experts make complete and consistent laws, and the other is to design an information system which works based on laws.", "labels": [], "entities": []}, {"text": "To achieve this we need to develop a system which can process legal texts automatically.", "labels": [], "entities": []}, {"text": "Legal texts have some specific characteristics that make them different from other daily-use documents.", "labels": [], "entities": []}, {"text": "Legal texts are usually long and complicated.", "labels": [], "entities": []}, {"text": "They are composed by experts who spent a lot of time to write and check them carefully.", "labels": [], "entities": []}, {"text": "One of the most important characteristics of legal texts is that law sentences have some specific structures.", "labels": [], "entities": []}, {"text": "In most cases, a law sentence can roughly be divided into two parts: a requisite part and an effectuation part ().", "labels": [], "entities": []}, {"text": "For example, the Hiroshima city provision 13-2 When the mayor designates a district for promoting beautification, s/he must in advance listen to opinions from the organizations and the administrative agencies which are recognized to be concerned with the district, includes a requisite part (before the comma) and an effectuation part (after the comma) (Nakamura et al., 07).", "labels": [], "entities": []}, {"text": "The requisite part and the effectuation part of a law sentence are composed from three parts: a topic part, an antecedent part, and a consequent part.", "labels": [], "entities": []}, {"text": "There are four cases (illustrated in) basing on where the topic part depends on: case 0 (no topic part), case 1 (the topic part depends on the antecedent part), case 2 (the topic part depends on the consequent part), and case 3 (the topic part depends on both the antecedent part and the consequent part).", "labels": [], "entities": []}, {"text": "In case 0, the requisite part is the antecedent part and the effectuation part is the consequent part.", "labels": [], "entities": []}, {"text": "In case 1, the requisite part is composed from the topic part and the antecedent part, while the effectuation part is the consequent part.", "labels": [], "entities": []}, {"text": "In case 2, the requisite part is the antecedent part, while the effectuation part is composed from the topic part and the consequent part.", "labels": [], "entities": []}, {"text": "In case 3, the requisite part is composed from the topic part and the antecedent part, while the effectuation part is composed from the topic part and the consequent part.", "labels": [], "entities": []}, {"text": "gives examples of law sentences in four cases.", "labels": [], "entities": []}, {"text": "Analyzing the logical structure of law sentences is an important task in Legal Engineering.", "labels": [], "entities": [{"text": "Analyzing the logical structure of law sentences", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.8534573316574097}, {"text": "Legal Engineering", "start_pos": 73, "end_pos": 90, "type": "TASK", "confidence": 0.7956109344959259}]}, {"text": "This task is  Examples of four cases of the logical structure of a law sentence.", "labels": [], "entities": []}, {"text": "A means antecedent part, C means consequent part, and T1, T2, T3 mean topic parts which correspond to case 1, case 2, and case 3 (the translations keep the ordinal sentence structures).", "labels": [], "entities": []}, {"text": "a preliminary step to support tasks in legal text processing, such as translating legal articles into logical and formal representations and verifying legal documents, legal article retrieval, legal text summarization, question answering in legal domains, etc (Katayama 07;.", "labels": [], "entities": [{"text": "legal text processing", "start_pos": 39, "end_pos": 60, "type": "TASK", "confidence": 0.6701145470142365}, {"text": "legal article retrieval", "start_pos": 168, "end_pos": 191, "type": "TASK", "confidence": 0.6029883821805319}, {"text": "legal text summarization", "start_pos": 193, "end_pos": 217, "type": "TASK", "confidence": 0.6074664493401846}, {"text": "question answering in legal domains", "start_pos": 219, "end_pos": 254, "type": "TASK", "confidence": 0.8575588345527649}, {"text": "Katayama 07", "start_pos": 261, "end_pos": 272, "type": "DATASET", "confidence": 0.7931211888790131}]}, {"text": "Ina law sentence, the consequent part usually describes a law provision, and the antecedent part describes cases in which the law provision can be applied.", "labels": [], "entities": []}, {"text": "The topic part describes the subjects which are related to the law provision.", "labels": [], "entities": []}, {"text": "Hence, the outputs of the RRE task will be very helpful to not only lawyers but also people who want to understand the law sentence.", "labels": [], "entities": [{"text": "RRE task", "start_pos": 26, "end_pos": 34, "type": "TASK", "confidence": 0.9024694859981537}]}, {"text": "They can easily understand 1) what does a law sentence say?", "labels": [], "entities": []}, {"text": "2) what cases in which the law sentence can be applied? and 3) what subjects are related to the provision described in the law sentence?", "labels": [], "entities": []}, {"text": "In this paper, we present a task of Recognition of Requisite Part and Effectuation Part in Law Sentences -the RRE task.", "labels": [], "entities": [{"text": "Recognition", "start_pos": 36, "end_pos": 47, "type": "TASK", "confidence": 0.9581106901168823}, {"text": "Law Sentences", "start_pos": 91, "end_pos": 104, "type": "TASK", "confidence": 0.6522103399038315}, {"text": "RRE task", "start_pos": 110, "end_pos": 118, "type": "TASK", "confidence": 0.8202169239521027}]}, {"text": "We show how to model this task by using sequence learning models.", "labels": [], "entities": []}, {"text": "The first one applies Conditional Random Fields (CRFs), a special version of conditionally-trained finite state machines.", "labels": [], "entities": []}, {"text": "We studies two different machine learning models for CRFs.", "labels": [], "entities": [{"text": "CRFs", "start_pos": 53, "end_pos": 57, "type": "TASK", "confidence": 0.9254676103591919}]}, {"text": "The second one focus on discriminative sequence learning models using online learning framework ().", "labels": [], "entities": []}, {"text": "We then empirically investigate several sequence learn-ing models for RRE task.", "labels": [], "entities": [{"text": "RRE task", "start_pos": 70, "end_pos": 78, "type": "TASK", "confidence": 0.9002765715122223}]}, {"text": "In addition, We depict a simple semi-supervised learning method for the RRE task using the Brown clustering algorithm.", "labels": [], "entities": [{"text": "RRE task", "start_pos": 72, "end_pos": 80, "type": "TASK", "confidence": 0.9124258458614349}]}, {"text": "We also show experimental results on an annotated corpus of Japanese national pension law sentences.", "labels": [], "entities": [{"text": "annotated corpus of Japanese national pension law sentences", "start_pos": 40, "end_pos": 99, "type": "DATASET", "confidence": 0.6325855776667595}]}, {"text": "Our models achieved 88.58% (using supervised learning) and 88.84% (using semi-supervised learning) in the F \u03b2=1 score.", "labels": [], "entities": [{"text": "F \u03b2=1 score", "start_pos": 106, "end_pos": 117, "type": "METRIC", "confidence": 0.9735276341438294}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "First, Section 2 presents how to model the RRE task as a sequence labeling problem, and shows experimental results about the effect of features on the task.", "labels": [], "entities": [{"text": "RRE task", "start_pos": 43, "end_pos": 51, "type": "TASK", "confidence": 0.9221673905849457}, {"text": "sequence labeling", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.6681343168020248}]}, {"text": "Next, we describe another setting for the task based on Bunsetsu (chunks in English) in Section 3.", "labels": [], "entities": [{"text": "Bunsetsu", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.8094190955162048}]}, {"text": "Then, Section 5 describes a simple semisupervised learning method for the task.", "labels": [], "entities": []}, {"text": "Finally, some conclusions are given in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Note that we used CRF++ 7 for Conditional Random Fields using LBFGS, and for Stochastic Gradient Descent (SGD) we used SGD1.3 which is developed by Leon Bottou 8 . For the RRE task, we extracted features at 4-bit depth and 6-bit depth.", "labels": [], "entities": [{"text": "RRE task", "start_pos": 172, "end_pos": 180, "type": "TASK", "confidence": 0.9323604702949524}]}, {"text": "We integrated these features into three sequence learning models: CRFs-LBFG, CRF-SGD, and online learning (MIRA).", "labels": [], "entities": []}, {"text": "The experimental results of the semi-supervised method with extra word features are shown in.", "labels": [], "entities": []}, {"text": "In three models, the semi-supervised method outperforms the supervised method.", "labels": [], "entities": []}, {"text": "For CRF-LBFG model, the F \u03b2=1 score was 88.80%, compared with 88.18% for the supervised method.", "labels": [], "entities": [{"text": "F \u03b2=1 score", "start_pos": 24, "end_pos": 35, "type": "METRIC", "confidence": 0.9793777942657471}]}, {"text": "The CRF-sgd model got 88.58% in the F \u03b2=1 score, compared with 88.03% for the supervised method.", "labels": [], "entities": [{"text": "F \u03b2=1 score", "start_pos": 36, "end_pos": 47, "type": "METRIC", "confidence": 0.9771250009536743}]}, {"text": "MIRA method got 82.3% and 83.21% for supervised and semi-supervised models.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.49496421217918396}]}, {"text": "In conclusion, word cluster models significantly improve the performance of sequence learning models for RRE tasks.", "labels": [], "entities": [{"text": "RRE tasks", "start_pos": 105, "end_pos": 114, "type": "TASK", "confidence": 0.9334871768951416}]}, {"text": "We believe that word cluster models are also suitable for other sequence learning models.", "labels": [], "entities": []}, {"text": "This sub-section presents our corpus for the RRE task and evaluation method.The Japanese National Pension Law corpus includes 764 annotated Japanese law sentences 6 . Some statistics on this corpus are shown in.", "labels": [], "entities": [{"text": "RRE task", "start_pos": 45, "end_pos": 53, "type": "TASK", "confidence": 0.8692988157272339}, {"text": "Japanese National Pension Law corpus", "start_pos": 80, "end_pos": 116, "type": "DATASET", "confidence": 0.8233818888664246}]}, {"text": "We have some remarks to make here.", "labels": [], "entities": []}, {"text": "First, about 98.5% of sentences belong to the implication type, and only 1.5% of sentences belong to the equivalence type.", "labels": [], "entities": []}, {"text": "Second, about 83.5% of topic parts are T 2 , 15.2% of topic parts are T 3 , and only 1.3% of topic parts are T 1 . Finally, four main types of parts, C, A, T 2 , and T 3 makeup more than 98.3% of all types.", "labels": [], "entities": []}, {"text": "We divided the corpus into 10 sets and performed 10-fold cross-validation tests.", "labels": [], "entities": []}, {"text": "The results were evaluated using precision, recall, and F \u03b2=1 scores as follows: A logical part is recognized correctly if and only if it has correct start word, correct end word, and correct part category (kind of logical part).", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9995378255844116}, {"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.999527096748352}, {"text": "F \u03b2=1", "start_pos": 56, "end_pos": 61, "type": "METRIC", "confidence": 0.9762465059757233}]}, {"text": "shows the comparison of three discriminative learning methods for RRE tasks.", "labels": [], "entities": [{"text": "RRE tasks", "start_pos": 66, "end_pos": 75, "type": "TASK", "confidence": 0.9346128702163696}]}, {"text": "Three sequence learning methods include: CRFs using the LBFGS method, CRFs with SGD, and Online Learning.", "labels": [], "entities": [{"text": "CRFs", "start_pos": 41, "end_pos": 45, "type": "TASK", "confidence": 0.9228879809379578}]}, {"text": "Experiment results show that the CRFs-LBFGS is the best in comparison with others.", "labels": [], "entities": []}, {"text": "However, the computational times for training is slower than either SGD or Online Learning.", "labels": [], "entities": []}, {"text": "The SGD is faster than CRF-LBFS approximately 6 times.", "labels": [], "entities": [{"text": "SGD", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.520169198513031}]}], "tableCaptions": [{"text": " Table 1: Statistics on the Japanese National Pension Law corpus.", "labels": [], "entities": [{"text": "Japanese National Pension Law corpus", "start_pos": 28, "end_pos": 64, "type": "DATASET", "confidence": 0.7328648686408996}]}, {"text": " Table 2: Experimental results with sequence learning models for RRE task.  Methods  Accuracy Precision  Recall  F-measure  CRF-LBFG  91.27  89.328% 87.039%  88.158  CRF-LBFG-B  91.45  89.708% 87.866%  88.807  CRF-SGD  91.39  90.046% 86.953%  88.023  CRF-SGD-B  92.041  90.011% 87.787%  88.584  MIRA  87.081  81.881% 82.909%  82.339  MIRA-B  87.139  80.679%  84.59%  83.213", "labels": [], "entities": [{"text": "RRE task", "start_pos": 65, "end_pos": 73, "type": "TASK", "confidence": 0.9014472365379333}, {"text": "Accuracy Precision  Recall  F-measure", "start_pos": 85, "end_pos": 122, "type": "METRIC", "confidence": 0.7968759983778}, {"text": "MIRA  87.081  81.881% 82.909%  82.339  MIRA-B  87.139  80.679%  84.59%  83.213", "start_pos": 295, "end_pos": 373, "type": "METRIC", "confidence": 0.8163015586989266}]}]}