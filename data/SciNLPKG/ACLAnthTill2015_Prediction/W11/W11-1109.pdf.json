{"title": [{"text": "From ranked words to dependency trees: two-stage unsupervised non-projective dependency parsing", "labels": [], "entities": [{"text": "non-projective dependency parsing", "start_pos": 62, "end_pos": 95, "type": "TASK", "confidence": 0.7585725585619608}]}], "abstractContent": [{"text": "Usually unsupervised dependency parsing tries to optimize the probability of a corpus by modifying the dependency model that was presumably used to generate the corpus.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.724524587392807}]}, {"text": "In this article we explore a different view in which a dependency structure is among other things a partial order on the nodes in terms of centrality or saliency.", "labels": [], "entities": []}, {"text": "Under this assumption we model the partial order directly and derive dependency trees from this order.", "labels": [], "entities": []}, {"text": "The result is an approach to unsupervised dependency parsing that is very different from standard ones in that it requires no training data.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.6967581659555435}]}, {"text": "Each sentence induces a model from which the parse is read off.", "labels": [], "entities": []}, {"text": "Our approach is evaluated on data from 12 different languages.", "labels": [], "entities": []}, {"text": "Two scenarios are considered: a scenario in which information about part-of-speech is available, and a scenario in which parsing relies only on word forms and distributional clusters.", "labels": [], "entities": []}, {"text": "Our approach is competitive to state-of-the-art in both scenarios.", "labels": [], "entities": []}], "introductionContent": [{"text": "Unsupervised dependency parsers do not achieve the same quality as supervised or semi-supervised parsers, but in some situations precision maybe less important compared to the cost of producing manually annotated data.", "labels": [], "entities": []}, {"text": "Moreover, unsupervised dependency parsing is attractive from a theoretical point of view as it does not rely on a particular style of annotation and may potentially provide insights about the difficulties of human language learning.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.7251140475273132}]}, {"text": "Unsupervised dependency parsing has seen rapid progress recently, with error reductions on English) of about 15% in six years (, and better and better results for other languages), but results are still far from what can be achieved with small seeds, language-specific rules) or using cross-language adaptation).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.635222315788269}]}, {"text": "The standard method in unsupervised dependency parsing is to optimize the overall probability of the corpus by assigning trees to its sentences that capture general patterns in the distribution of part-ofspeech (POS).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.6928907036781311}]}, {"text": "This happens in several iterations over the corpus.", "labels": [], "entities": []}, {"text": "This method requires clever initialization, which can be seen as a kind of minimal supervision.", "labels": [], "entities": [{"text": "initialization", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.9575949907302856}]}, {"text": "State-of-the-art unsupervised dependency parsers, except, also rely on manually annotated text or text processed by supervised POS taggers.", "labels": [], "entities": []}, {"text": "Since there is an intimate relationship between POS tagging and dependency parsing, the POS tags can also be seen as a seed or as partial annotation.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 48, "end_pos": 59, "type": "TASK", "confidence": 0.7870532274246216}, {"text": "dependency parsing", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.7799869775772095}]}, {"text": "Inducing a model from the corpus is typically a very slow process.", "labels": [], "entities": []}, {"text": "This paper presents anew and very different approach to unsupervised dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.7285780012607574}]}, {"text": "The parser does not induce a model from a big corpus, but with a few exceptions only considers the sentence in question.", "labels": [], "entities": []}, {"text": "It does use a larger corpus to induce distributional clusters and a ranking of key words in terms of frequency and centrality, but this is computationally efficient and is only indirectly related to the subsequent assignment of dependency structures to sentences.", "labels": [], "entities": []}, {"text": "The obvious advantage of not relying on training data is that we do not have to worry about whether the test data reflects the same distribution as the target data (domain adaptation), and since our models are much smaller, parsing will be very fast.", "labels": [], "entities": [{"text": "parsing", "start_pos": 224, "end_pos": 231, "type": "TASK", "confidence": 0.9804630875587463}]}, {"text": "The parser assigns a dependency structure to a sequence of words in two stages.", "labels": [], "entities": []}, {"text": "It first decorates then nodes of what will become our dependency structure with word forms and distributional clusters, constructs a directed acyclic graph from the nodes in O(n 2 ), and ranks the nodes using iterative graph-based ranking.", "labels": [], "entities": []}, {"text": "Subsequently, it constructs a tree from the ranked list of words using a simple O(n log n) parsing algorithm.", "labels": [], "entities": []}, {"text": "Our parser is evaluated on the selection of 12 dependency treebanks also used in.", "labels": [], "entities": []}, {"text": "We consider two cases: parsing raw text and parsing text with information about POS.", "labels": [], "entities": [{"text": "parsing raw text", "start_pos": 23, "end_pos": 39, "type": "TASK", "confidence": 0.8969414432843527}, {"text": "parsing text with information about POS", "start_pos": 44, "end_pos": 83, "type": "TASK", "confidence": 0.7273357113202413}]}, {"text": "Strictly unsupervised dependency parsing is of course a more difficult problem than unsupervised dependency parsing of manually annotated POS sequences.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.6397189348936081}, {"text": "dependency parsing of manually annotated POS sequences", "start_pos": 97, "end_pos": 151, "type": "TASK", "confidence": 0.8048936724662781}]}, {"text": "Nevertheless our strictly unsupervised parser, which only sees word forms, performs significantly better than structural baselines, and it outperforms the standard POS-informed DMV-EM model () on 3/12 languages.", "labels": [], "entities": []}, {"text": "The full parser, which sees manually annotated text, is competitive to state-of-the-art models such as E-DMV PR AS 140 ().", "labels": [], "entities": [{"text": "E-DMV PR AS 140", "start_pos": 103, "end_pos": 118, "type": "DATASET", "confidence": 0.8097869902849197}]}], "datasetContent": [{"text": "We use exactly the same experimental set-up as.", "labels": [], "entities": []}, {"text": "The edge model was developed on development data from the English Penn-III treebank, and we evaluate on Sect.", "labels": [], "entities": [{"text": "English Penn-III treebank", "start_pos": 58, "end_pos": 83, "type": "DATASET", "confidence": 0.9019357363382975}]}, {"text": "23 of the English treebanks and the test sections of the remaining 11 treebanks, which were all used in the CoNLL-X Shared Task ().", "labels": [], "entities": [{"text": "English treebanks", "start_pos": 10, "end_pos": 27, "type": "DATASET", "confidence": 0.9857942163944244}]}, {"text": "for some reason did not evaluate on the Arabic and Chinese treebanks also used in the shared task.", "labels": [], "entities": []}, {"text": "We also follow in only evaluating our parser on sentences of at most 10 non-punctuation words and in reporting unlabeled attachment scores excluding punctuation.", "labels": [], "entities": []}], "tableCaptions": []}