{"title": [{"text": "Word Disambiguation in Shahmukhi to Gurmukhi Transliteration", "labels": [], "entities": [{"text": "Word Disambiguation in Shahmukhi to Gurmukhi Transliteration", "start_pos": 0, "end_pos": 60, "type": "TASK", "confidence": 0.6079212810311999}]}], "abstractContent": [{"text": "To write Punjabi language, Punjabi speakers use two different scripts, Perso-Arabic (re-ferred as Shahmukhi) and Gurmukhi.", "labels": [], "entities": []}, {"text": "Shah-mukhi is used by the people of Western Pun-jab in Pakistan, whereas Gurmukhi is used by most people of Eastern Punjab in India.", "labels": [], "entities": []}, {"text": "The natural written text in Shahmukhi script has missing short vowels and other diacritical marks.", "labels": [], "entities": []}, {"text": "Additionally, the presence of ambiguous character having multiple mappings in Gurmukhi script cause ambiguity at character as well as word level while transliterating Shahmukhi text into Gurmukhi script.", "labels": [], "entities": []}, {"text": "In this paper we focus on the word level ambiguity problem.", "labels": [], "entities": []}, {"text": "The ambiguous Shahmukhi word tokens have many interpretations in target Gur-mukhi script.", "labels": [], "entities": []}, {"text": "We have proposed two different algorithms for Shahmukhi word disambigua-tion.", "labels": [], "entities": [{"text": "Shahmukhi word disambigua-tion", "start_pos": 46, "end_pos": 76, "type": "TASK", "confidence": 0.6329686840375265}]}, {"text": "The first algorithm formulates this problem using a state sequence representation as a Hidden Markov Model (HMM).", "labels": [], "entities": []}, {"text": "The second approach proposes n-gram model in which the joint occurrence of words within a small window of size \u00b1 5 is used.", "labels": [], "entities": []}, {"text": "After evaluation we found that both approaches have more than 92% word disambiguation accuracy.", "labels": [], "entities": [{"text": "word disambiguation", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.6838483661413193}, {"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.85761958360672}]}], "introductionContent": [], "datasetContent": [{"text": "Additionally, a similar experiment was performed on a Shahmukhi book having a total of 37,620 words.", "labels": [], "entities": []}, {"text": "After manual evaluation, we discovered that the extent of ambiguous words in this book was 17.12%.", "labels": [], "entities": [{"text": "extent", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.9941051006317139}]}, {"text": "Hence, both the test cases figure out that there is significant percentage of ambiguous words in Shahmukhi text and must be addressed to achieve higher rate of transliteration accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 176, "end_pos": 184, "type": "METRIC", "confidence": 0.9678731560707092}]}, {"text": "The natural sources of Shahmukhi text are very limited.", "labels": [], "entities": [{"text": "Shahmukhi text", "start_pos": 23, "end_pos": 37, "type": "DATASET", "confidence": 0.815061628818512}]}, {"text": "With this limitation we have identified the available online and offline sources and three different test sets are taken from different domains as shown in.", "labels": [], "entities": []}, {"text": "After manual evaluation, the word disambiguation results on the three datasets are given in.", "labels": [], "entities": []}, {"text": "The overall 13.85% word ambiguity corresponding to all datasets has a significant value.", "labels": [], "entities": []}, {"text": "The upper bound contribution is from Set-1(book) having a highest percentage 17.12% of word ambiguity and the corresponding performance of two different disambiguation tasks is also highest.", "labels": [], "entities": []}, {"text": "The accuracy of both algorithms is more that 92%, indicating there is still room for improvement.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997372031211853}]}, {"text": "A comparative analysis of both outputs is performed.", "labels": [], "entities": []}, {"text": "We found that there are cases when both HMM and N-gram based methods individually outperform as shown in.", "labels": [], "entities": []}, {"text": "It is observed that due to lack of training data both the proposed approaches have failed to distinguish correctly like \u0a05\u0a24\u0a47 /at\u0113/ or \u0a09\u0a71\u0a24\u0a47 /utt\u0113/ as shown in 5 throw of.", "labels": [], "entities": []}, {"text": "Similarly, in some other cases system fails to predict name entity abbreviations as shown in 6 throw of.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4.  Sr.  Most Frequent  Words", "labels": [], "entities": [{"text": "Sr.  Most Frequent  Words", "start_pos": 11, "end_pos": 36, "type": "TASK", "confidence": 0.46013953909277916}]}, {"text": " Table 7. Context Window Probabilities for \u0a39\u0a28", "labels": [], "entities": []}, {"text": " Table 11. The  overall 13.85% word ambiguity corresponding to  all datasets has a significant value. The upper  bound contribution is from Set-1(book) having a  highest percentage 17.12% of word ambiguity  and the corresponding performance of two dif- ferent disambiguation tasks is also highest.", "labels": [], "entities": []}, {"text": " Table 11. Word Disambiguation Result", "labels": [], "entities": [{"text": "Word Disambiguation Result", "start_pos": 11, "end_pos": 37, "type": "TASK", "confidence": 0.7671641608079275}]}]}