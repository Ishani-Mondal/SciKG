{"title": [{"text": "Active Learning for Dependency Parsing Using Partially Annotated Sentences", "labels": [], "entities": [{"text": "Dependency Parsing", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.7304281294345856}]}], "abstractContent": [{"text": "Current successful probabilistic parsers require large treebanks which are difficult, time consuming, and expensive to produce.", "labels": [], "entities": [{"text": "probabilistic parsers", "start_pos": 19, "end_pos": 40, "type": "TASK", "confidence": 0.6032750010490417}]}, {"text": "Some parts of these data do not contain any useful information for training a parser.", "labels": [], "entities": []}, {"text": "Active learning strategies allow to select the most informative samples for annotation.", "labels": [], "entities": []}, {"text": "Most existing active learning strategies for parsing rely on selecting uncertain sentences for annotation.", "labels": [], "entities": [{"text": "parsing", "start_pos": 45, "end_pos": 52, "type": "TASK", "confidence": 0.9781849384307861}]}, {"text": "We show in this paper that selecting full sentences is not an optimal solution and propose away to select only subparts of sentences.", "labels": [], "entities": []}], "introductionContent": [{"text": "Current probabilistic parsers rely on treebanks in order to estimate their parameters.", "labels": [], "entities": []}, {"text": "Such data is known to be difficult and expensive to produce.", "labels": [], "entities": []}, {"text": "One can also observe that the quality of parsers increase when they model complex lexicosyntactic phenomena.", "labels": [], "entities": []}, {"text": "Unfortunately, increasing the precision of models is quickly confronted with data sparseness which prevents to reliably estimate the model parameters.", "labels": [], "entities": [{"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.998077392578125}]}, {"text": "Treebanks size is therefore a limit to the accuracy of probabilistic parsers.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9988904595375061}]}, {"text": "Given the cost of annotating new data with syntactic structures, it is natural to ask oneself, before annotating anew sentence and adding it to a treebank, if this new piece of information will benefit a parser trained on the treebank.", "labels": [], "entities": []}, {"text": "This question is at the heart of active learning which assumes that \"a machine learning algorithm can achieve greater accuracy with fewer training labels if it is allowed to choose the data from which it learns.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.99471515417099}]}, {"text": "An active learner may pose queries, usually in the form of unlabeled data instances to be labeled by an oracle (e.g. human annotator).", "labels": [], "entities": []}, {"text": "Active learning is well-motivated in many modern machine learning problems, where unlabeled data maybe abundant or easily obtained, but labels are difficult, time-consuming, or expensive to obtain.\"", "labels": [], "entities": [{"text": "Active learning", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7836429476737976}]}, {"text": "Different scenarios have been proposed for active learning.", "labels": [], "entities": []}, {"text": "The work described here is based on the Pool-Based Sampling scenario ( which is adapted to the problem at hand.", "labels": [], "entities": []}, {"text": "Pool-based sampling scenario assumes that there is a small set of labeled data Land a large pool of unlabeled data U available.", "labels": [], "entities": []}, {"text": "Instances are drawn from U according to a selection strategy.", "labels": [], "entities": []}, {"text": "The chosen instance(s) are then labeled and added to L.", "labels": [], "entities": []}, {"text": "These steps are repeated until either U is empty or does not contain informative instances anymore.", "labels": [], "entities": []}, {"text": "Many selection strategies have been proposed in the literature.", "labels": [], "entities": []}, {"text": "Uncertainty sampling, which is the strategy that has been used in this work, is the simplest and the most commonly used one.", "labels": [], "entities": [{"text": "Uncertainty sampling", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6716643422842026}]}, {"text": "In this strategy, instances for which the prediction of the label is the most uncertain are selected by the learner.", "labels": [], "entities": []}, {"text": "The performances of such methods heavily rely on the definition of a good confidence measure, which measures the confidence the model, in our case the parser, has in the solution it proposes.", "labels": [], "entities": []}, {"text": "Active learning has been used for many NLP applications, such as automatic speech recognition, information extraction, part of speech tagging or syntactic parsing.", "labels": [], "entities": [{"text": "automatic speech recognition", "start_pos": 65, "end_pos": 93, "type": "TASK", "confidence": 0.6137707134087881}, {"text": "information extraction", "start_pos": 95, "end_pos": 117, "type": "TASK", "confidence": 0.8265708386898041}, {"text": "speech tagging", "start_pos": 127, "end_pos": 141, "type": "TASK", "confidence": 0.6895312666893005}, {"text": "syntactic parsing", "start_pos": 145, "end_pos": 162, "type": "TASK", "confidence": 0.7456347644329071}]}, {"text": "We will not detail the way active learning has been applied to those tasks, the interested reader can find two reasonably recent surveys in and, and concentrate on its application to statistical parsing.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 183, "end_pos": 202, "type": "TASK", "confidence": 0.7515926957130432}]}, {"text": "( and) proposed active learning techniques for training probabilistic parsers.", "labels": [], "entities": []}, {"text": "They both used uncertainty sampling and suggested a measure of uncertainty based on the entropy of the probability distribution of the parses of a sentence.", "labels": [], "entities": []}, {"text": "The idea being that the higher this entropy is, the more uncertain the parser is of its choice.", "labels": [], "entities": []}, {"text": "( proposed to combine uncertainty with representativeness, the idea here is to make sure that the instances selected with uncertainty criterion are also representative of the data distribution.", "labels": [], "entities": []}, {"text": "The common point to these two approaches, and most work on active learning applied to parsing is that they only consider full sentences in their instance selection.", "labels": [], "entities": [{"text": "parsing", "start_pos": 86, "end_pos": 93, "type": "TASK", "confidence": 0.9677263498306274}]}, {"text": "There is something not satisfactory in considering only full sentences as instances since, in many cases, only part of the syntactic structure is uncertain.", "labels": [], "entities": []}, {"text": "The manual annotation of this part would benefit the parser while the annotation of the remaining part of the sentence would be a waste of effort.", "labels": [], "entities": []}, {"text": "The main novelty of the work reported here is that we explore the other extreme position: instead of considering uncertain sentences, we consider single uncertain word tokens in a sentence.", "labels": [], "entities": []}, {"text": "More precisely, we consider the attachment of single word tokens.", "labels": [], "entities": [{"text": "attachment of single word tokens", "start_pos": 32, "end_pos": 64, "type": "TASK", "confidence": 0.8209550976753235}]}, {"text": "In the framework of dependency parsing, which is used here, this boils down to selecting, fora token w, its governor and the label of the dependency between wand its governor.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.8625173270702362}]}, {"text": "The task is therefore to select, in a sentence, the most uncertain dependencies.", "labels": [], "entities": []}, {"text": "Active learning for parsing using sub-sentential units has already been explored by.", "labels": [], "entities": [{"text": "parsing", "start_pos": 20, "end_pos": 27, "type": "TASK", "confidence": 0.9662801027297974}]}, {"text": "In their work they select unreliable dependencies predicted by a parser (a simple shift-reduce parser where dependencies are weighted using an averaged perceptron with polynomial kernels), based on the score the parser assigns to the dependencies.", "labels": [], "entities": []}, {"text": "Such dependencies are hand labeled and, based on syntactic characteristics of Japanese syntax (dependencies are projective and oriented from left to right (the governor is always to the right of the dependent)) other dependencies are deduced and this set of dependencies are added to the training set.", "labels": [], "entities": []}, {"text": "Our work departs from their in the uncertainty measure that we use, in the kind of parser used, on the way hand annotated single dependencies are added to the training data (without using language specific properties) as well as on the fact that we use both sentence based and dependency based uncertainty measures.", "labels": [], "entities": []}, {"text": "The structure of the paper is the following: in section 2, we describe, in some details, the parsing model on which this work is based, namely the graph-based dependency parsing framework.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 159, "end_pos": 177, "type": "TASK", "confidence": 0.6808609068393707}]}, {"text": "Such a detailed description is motivated by two extensions of graph based parsing that we describe.", "labels": [], "entities": []}, {"text": "The first one is how to take into account, in the input of the parser, part of the syntactic structure of the sentence to parse, a feature that is needed when annotating only a subpart of the syntactic structure of a sentence.", "labels": [], "entities": []}, {"text": "We will see that this can be done very easily and this is the main reason why we chose this parsing framework.", "labels": [], "entities": [{"text": "parsing", "start_pos": 92, "end_pos": 99, "type": "TASK", "confidence": 0.9636586308479309}]}, {"text": "The second extension concerns the production of a list of n-best candidates, which is necessary for computing our uncertainty measure and is not a standard operation for this kind of parsers, contrary to syntagmatic parsers, for example.", "labels": [], "entities": []}, {"text": "In section 3, we report a first series of experiments in which full sentences are selected during the instance selection procedure.", "labels": [], "entities": []}, {"text": "The techniques used here are not novel and the aim of this section is to constitute a baseline for evaluating our idea of partial annotation, which is described in section 4.", "labels": [], "entities": []}, {"text": "Section 5 shows that better results can be reached when taking into account both uncertainty of a sentence and uncertainty of parts of it.", "labels": [], "entities": []}, {"text": "Finally, section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}