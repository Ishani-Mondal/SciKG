{"title": [{"text": "BioNLP Shared Task 2011: Supporting Resources", "labels": [], "entities": [{"text": "BioNLP Shared Task 2011", "start_pos": 0, "end_pos": 23, "type": "DATASET", "confidence": 0.6521099358797073}]}], "abstractContent": [{"text": "This paper describes the supporting resources provided for the BioNLP Shared Task 2011.", "labels": [], "entities": [{"text": "BioNLP Shared Task 2011", "start_pos": 63, "end_pos": 86, "type": "DATASET", "confidence": 0.6002690866589546}]}, {"text": "These resources were constructed with the goal to alleviate some of the burden of system development from the participants and allow them to focus on the novel aspects of constructing their event extraction systems.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 190, "end_pos": 206, "type": "TASK", "confidence": 0.7211405783891678}]}, {"text": "With the availability of these resources we also seek to enable the evaluation of the applicability of specific tools and representations towards improving the performance of event extraction systems.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 175, "end_pos": 191, "type": "TASK", "confidence": 0.7604118883609772}]}, {"text": "Additionally we supplied evaluation software and services and constructed a vi-sualisation tool, stav, which visualises event extraction results and annotations.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 120, "end_pos": 136, "type": "TASK", "confidence": 0.6558171212673187}]}, {"text": "These resources helped the participants make sure that their final submissions and research efforts were on track during the development stages and evaluate their progress throughout the duration of the shared task.", "labels": [], "entities": []}, {"text": "The visualisation software was also employed to show the differences between the gold annotations and those of the submitted results, allowing the participants to better understand the performance of their system.", "labels": [], "entities": []}, {"text": "The resources, evaluation tools and visualisation tool are provided freely for research purposes and can be found at", "labels": [], "entities": []}], "introductionContent": [{"text": "For the BioNLP'09 Shared Task (, the first in the ongoing series, the organisers provided the participants with automatically generated syntactic analyses for the sentences from the annotated data.", "labels": [], "entities": []}, {"text": "For evaluation purposes, tools were made publicly available as both distributed software and online services.", "labels": [], "entities": []}, {"text": "These resources were well received.", "labels": [], "entities": []}, {"text": "A majority of the participants made use of one or more of the syntactic analyses, which have remained available after the shared task ended and have been employed in at least two independent efforts studying the contribution of different tools and forms of syntactic representation to the domain of information extraction (.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 299, "end_pos": 321, "type": "TASK", "confidence": 0.7460154294967651}]}, {"text": "The evaluation software for the BioNLP'09 Shared Task has also been widely adopted in subsequent studies.", "labels": [], "entities": [{"text": "BioNLP'09 Shared Task", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.5791996121406555}]}, {"text": "The reception and research contribution from providing these resources encouraged us to continue providing similar resources for the BioNLP Shared Task 2011.", "labels": [], "entities": [{"text": "BioNLP Shared Task 2011", "start_pos": 133, "end_pos": 156, "type": "DATASET", "confidence": 0.6136502176523209}]}, {"text": "Along with the parses we also encouraged the participants and external groups to process the data with any NLP (Natural Language Processing) tools of their choice and make the results available to the participants.", "labels": [], "entities": [{"text": "parses", "start_pos": 15, "end_pos": 21, "type": "TASK", "confidence": 0.9559730291366577}]}, {"text": "We provided continuous verification and evaluation of the participating systems using a suite of inhouse evaluation tools.", "labels": [], "entities": []}, {"text": "Lastly, we provided a tool for visualising the annotated data to enable the participants to better grasp the results of their experiments and to help gain a deeper understanding of the underlying concepts and the annotated data.", "labels": [], "entities": []}, {"text": "This paper presents these supporting resources.", "labels": [], "entities": []}], "datasetContent": [{"text": "The tasks of BioNLP-ST 2011 exhibit very high complexity, including multiple non-trivial subproblems that are partially, but not entirely, independent of each other.", "labels": [], "entities": [{"text": "BioNLP-ST 2011", "start_pos": 13, "end_pos": 27, "type": "DATASET", "confidence": 0.6601523756980896}]}, {"text": "With such tasks, the evaluation of participating systems itself becomes a major challenge.", "labels": [], "entities": []}, {"text": "Clearly defined evaluation criteria and their precise implementation is critical not only for the comparison of submissions, but also to help participants follow the status of their development and to identify the specific strengths and weaknesses of their approach.", "labels": [], "entities": []}, {"text": "A further challenge arising from the complexity of the tasks is the need to process the relatively intricate format in which annotations are represented, which in turn carries a risk of errors in submissions.", "labels": [], "entities": []}, {"text": "To reduce the risk of submissions being rejected or the evaluation showing poor results due to formatting errors, tools for checking the validity of the file format and annotation semantics are indispensable.", "labels": [], "entities": []}, {"text": "For these reasons, we placed emphasis in the organisation of the BioNLP-ST'11 on making tools for format checking, validation and evaluation available to the participants already during the early stages of system development.", "labels": [], "entities": [{"text": "BioNLP-ST'11", "start_pos": 65, "end_pos": 77, "type": "DATASET", "confidence": 0.7810142040252686}, {"text": "format checking", "start_pos": 98, "end_pos": 113, "type": "TASK", "confidence": 0.9143675565719604}]}, {"text": "The tools were made available in two ways: as downloads, and as online services.", "labels": [], "entities": []}, {"text": "With downloaded tools, participants can perform format checking and evaluation at anytime without online access, allowing more efficient optimisation processes.", "labels": [], "entities": [{"text": "format checking", "start_pos": 48, "end_pos": 63, "type": "TASK", "confidence": 0.9589137136936188}]}, {"text": "Each task in BioNLP-ST also: An example of a false negative illustrated by the evaluation tools in co-ordination with stav maintained an online evaluation tool for the development set during the development period.", "labels": [], "entities": [{"text": "BioNLP-ST", "start_pos": 13, "end_pos": 22, "type": "DATASET", "confidence": 0.8040713667869568}]}, {"text": "The online evaluation is intended to provide an identical interface and criteria for submitted data as the final online submission system, allowing participants to be better prepared for the final submission.", "labels": [], "entities": []}, {"text": "With online evaluation, the organisers could also monitor submissions to ensure that there were no problems in, for example, the evaluation software implementations.", "labels": [], "entities": []}, {"text": "The system logs of online evaluation systems show that the majority of the participants submitted at least one package with formatting errors, confirming the importance of tools for format checking.", "labels": [], "entities": [{"text": "format checking", "start_pos": 182, "end_pos": 197, "type": "TASK", "confidence": 0.8663893640041351}]}, {"text": "Further, most of the participants made use of the online development set evaluation at least once before their final submission.", "labels": [], "entities": []}, {"text": "To enhance the evaluation tools we drew upon the stav visualiser to provide a view of the submitted results.", "labels": [], "entities": []}, {"text": "This was done by comparing the submitted results and the gold data to produce a visualisation where errors are highlighted, as illustrated in.", "labels": [], "entities": []}, {"text": "This experimental feature was available for the EPI and ID tasks and we believe that by doing so it enables participants to better understand the performance of their system and work on remedies for current shortcomings.", "labels": [], "entities": []}], "tableCaptions": []}