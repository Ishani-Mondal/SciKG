{"title": [{"text": "Mining Multi-word Named Entity Equivalents from Comparable Corpora", "labels": [], "entities": []}], "abstractContent": [{"text": "Named entity (NE) equivalents are useful in many multilingual tasks including MT, transliteration, cross-language IR, etc.", "labels": [], "entities": [{"text": "MT", "start_pos": 78, "end_pos": 80, "type": "TASK", "confidence": 0.9891024827957153}]}, {"text": "Recently, several works have addressed the problem of mining NE equivalents from comparable corpora.", "labels": [], "entities": []}, {"text": "These methods usually focus only on single-word NE equivalents whereas, in practice, most NEs are multi-word.", "labels": [], "entities": []}, {"text": "In this work, we present a generative model for extracting equivalents of multi-word NEs (MWNEs) from a comparable corpus, given a NE tagger in only one of the languages.", "labels": [], "entities": []}, {"text": "We show that our method is highly effective on three language pairs, and provide a detailed error analysis for one of them.", "labels": [], "entities": []}], "introductionContent": [{"text": "NEs are important for many applications in natural language processing and information retrieval.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.826546311378479}]}, {"text": "In particular, NE equivalents, i.e. the same NE expressed in multiple languages, are used in several cross-language tasks such as machine translation, machine transliteration, cross-language information retrieval, cross-language news aggregation, etc.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 130, "end_pos": 149, "type": "TASK", "confidence": 0.809818834066391}, {"text": "cross-language information retrieval", "start_pos": 176, "end_pos": 212, "type": "TASK", "confidence": 0.7260270416736603}, {"text": "cross-language news aggregation", "start_pos": 214, "end_pos": 245, "type": "TASK", "confidence": 0.7208610475063324}]}, {"text": "Recently, the problem of automatically constructing a table of NE equivalents in multiple languages has received considerable attention from the research community.", "labels": [], "entities": []}, {"text": "One approach to solving this problem is to leverage the abundantly available comparable corpora in many different languages of the world ().", "labels": [], "entities": []}, {"text": "While considerable progress has been made in improving both recall and precision of mining of NE equivalents from comparable corpora, most approaches in the literature are applicable only to single-word NEs, and particularly to transliterations (e.g..", "labels": [], "entities": [{"text": "recall", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9980283379554749}, {"text": "precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9966468214988708}]}, {"text": "In this work, we consider the more general problem of MWNE equivalents from comparable corpora.", "labels": [], "entities": [{"text": "MWNE equivalents", "start_pos": 54, "end_pos": 70, "type": "TASK", "confidence": 0.9025914072990417}]}, {"text": "In the MWNE equivalents mining problem, a NE in the source language could be related to a NE in the target language by, not just transliteration, but a combination of transliteration, translation, acronyms, deletion/addition of terms, etc.", "labels": [], "entities": [{"text": "MWNE equivalents mining", "start_pos": 7, "end_pos": 30, "type": "TASK", "confidence": 0.8743963638941447}]}, {"text": "To give an example, shows a pair of comparable articles in English and Hindi.", "labels": [], "entities": []}, {"text": "'Sachin Tendulkar' and ' ' are MWNE equivalents, and both words have been transliterated.", "labels": [], "entities": [{"text": "MWNE", "start_pos": 31, "end_pos": 35, "type": "DATASET", "confidence": 0.6497599482536316}]}, {"text": "Another example is the pair 'Siddhivinayak Temple Trust' and ' siddhivinayak mandir'.", "labels": [], "entities": []}, {"text": "Here, the first word has been transliterated, the second one translated, and the third omitted in Hindi.", "labels": [], "entities": []}, {"text": "The task is to (a) identify these MWNEs as equivalents, (b) infer the word correspondence between the MWNE equivalents, and (c) identify the type of correspondence (transliteration, translation, etc.).", "labels": [], "entities": []}, {"text": "Such NE equivalents would not be mined correctly by the previously mentioned approaches as they would mine only the pair ).", "labels": [], "entities": []}, {"text": "In practice, most NEs are multiword and hence it makes sense to address the problem of mining MWNE equivalents.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, this is the first work on mining MWNEs in a language-neutral manner.", "labels": [], "entities": []}, {"text": "In this work, we make the following contributions: \u2022 We perform an empirical study of MWNE occurrences, and the issues involved in mining (Section 2).", "labels": [], "entities": [{"text": "MWNE occurrences", "start_pos": 86, "end_pos": 102, "type": "TASK", "confidence": 0.8442180752754211}]}, {"text": "\u2022 We define a two-tier generative model for MWNE equivalents in a comparable corpus (Section 4).", "labels": [], "entities": []}, {"text": "\u2022 We propose a modified Viterbi algorithm for identifying MWNE equivalents, and Mumbai, July 29: Sachin Tendulkar will make his Bollywood debut with a cameo role in a film about the miracles of Lord Ganesh.", "labels": [], "entities": []}, {"text": "Tendulkar, widely regarded as one of the world's best batsmen, will play himself in Vighnaharta Shri Siddhivinayak,\" a film about the god, who is sometimes referred to as Siddhivinayak.", "labels": [], "entities": []}, {"text": "\"He will play a small role, as himself, either in a song sequence or in an actual scene,\" said Rajiv Sanghvi, whose company is handling the film's production.", "labels": [], "entities": []}, {"text": "Tendulkar's office confirmed the cricketer would be shooting for the film after he returns from Sri Lanka where India is touring at the moment.", "labels": [], "entities": []}, {"text": "Tendulkar, a devotee of Ganesh, had offered to be apart of the project and will not be charging for the role.", "labels": [], "entities": []}, {"text": "The film is being produced by the Siddhivinayak Temple Trust, which looks after a famous temple dedicated to Ganesh in Mumbai.", "labels": [], "entities": []}, {"text": "[  for inferring correspondence information (Section 4.3).", "labels": [], "entities": []}, {"text": "\u2022 We evaluate the method on three language pairs (involving English (En), Arabic (Ar), Hindi (Hi) and Tamil (Ta)) (Section 6).", "labels": [], "entities": []}, {"text": "In our method, we assume the existence of the following linguistic resources: a NE tagger, a translation model, a transliteration model, and a language model.", "labels": [], "entities": []}, {"text": "We show good mining performance for En-Hi and En-Ta.", "labels": [], "entities": []}, {"text": "We perform error analysis for En-Ar, and identify sources of error (Section 6.5).", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we study the overall precision and recall of our algorithm for three different language pairs.", "labels": [], "entities": [{"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9994221925735474}, {"text": "recall", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9989053010940552}]}, {"text": "English (En) is the source language, and Hindi (Hi), Tamil (Ta) and Arabic (Ar) are the target languages.", "labels": [], "entities": []}, {"text": "Hindi belongs to the Indo-Aryan family, Tamil belongs to Dravidian family, and Arabic belongs to the Semitic family of languages.", "labels": [], "entities": []}, {"text": "The results show that the method is applicable fora wide spectrum of languages.", "labels": [], "entities": []}, {"text": "Annotation Given an article pair, a human annotator looks through the list of source NEs, and En-Hi from Webdunia, En-Ta from The New Indian identifies transliterations in the target document.", "labels": [], "entities": []}, {"text": "For MWNEs, the annotator also marks which word in the source corresponds to each word in the target MWNE.", "labels": [], "entities": []}, {"text": "This constitutes gold standard data that can be used to measure performance.", "labels": [], "entities": []}, {"text": "120 article pairs were annotated for En-Hi, 120 for En-Ta, and 36 for En-Ar.", "labels": [], "entities": []}, {"text": "Evaluation The NEs mined from one article pair are compared with the gold standard for that pair, and one of three possible judgements is made: \u2022 Fully matched (if it fully matches some annotated NE (both source and target)).", "labels": [], "entities": []}, {"text": "\u2022 Partially matched (if source NEs match, and the mined target NE is a subset of the gold target NE).", "labels": [], "entities": []}, {"text": "\u2022 Incorrect match (in all other cases).", "labels": [], "entities": [{"text": "Incorrect match", "start_pos": 2, "end_pos": 17, "type": "METRIC", "confidence": 0.8399931788444519}]}, {"text": "The algorithm is agnostic of the type of the NE (Person, Organization, etc.).", "labels": [], "entities": []}, {"text": "So, reporting the precision and recall for each NE type does not provide much insight into the performance of the method.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9994237422943115}, {"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9967868328094482}]}, {"text": "Instead, we report at different levels of match-full or partial, and for different categories of MWNEs-single word transliteration equivalents (SW), multi word transliteration equivalents (including acronyms) (MW-Translit) and multi word NEs having at least one translation equivalent (MW-Mixed).", "labels": [], "entities": []}, {"text": "We compute the numbers for each article pair and then average overall pairs.", "labels": [], "entities": []}, {"text": "Parameter Tuning Parameter tuning was done following the procedure described in Section 5.", "labels": [], "entities": [{"text": "Parameter Tuning Parameter tuning", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8323115259408951}]}, {"text": "For En-Hi and En-Ta, the following values were used: p NE = 1, m tlit = 100, r tlit = 7, m tlat = 1, r tlat = 1.", "labels": [], "entities": []}, {"text": "For En-Ar, m tlit = 1, r tlit = 14 was used, the other parameters remaining the same.", "labels": [], "entities": []}, {"text": "For the tuning exercise, 40 annotated article pairs were used for En-Hi, 40 pairs for En-Ta, and 26 pairs for En-Ar.", "labels": [], "entities": [{"text": "tuning", "start_pos": 8, "end_pos": 14, "type": "TASK", "confidence": 0.9580580592155457}]}], "tableCaptions": [{"text": " Table 2: Precision and recall of the system", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9950174689292908}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.998783528804779}]}, {"text": " Table 3: Category-wise recall of the system", "labels": [], "entities": [{"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9798577427864075}]}]}