{"title": [{"text": "Authorship Attribution with Latent Dirichlet Allocation", "labels": [], "entities": [{"text": "Authorship Attribution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.5632630735635757}, {"text": "Latent Dirichlet Allocation", "start_pos": 28, "end_pos": 55, "type": "METRIC", "confidence": 0.6665479938189188}]}], "abstractContent": [{"text": "The problem of authorship attribution-attributing texts to their original authors-has been an active research area since the end of the 19th century, attracting increased interest in the last decade.", "labels": [], "entities": [{"text": "authorship attribution-attributing texts to their original authors-has", "start_pos": 15, "end_pos": 85, "type": "TASK", "confidence": 0.8580003976821899}]}, {"text": "Most of the work on authorship attribution focuses on scenarios with only a few candidate authors, but recently considered cases with tens to thousands of candidate authors were found to be much more challenging.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.8586169481277466}]}, {"text": "In this paper, we propose ways of employing Latent Dirichlet Allocation in authorship attribution.", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation", "start_pos": 44, "end_pos": 71, "type": "METRIC", "confidence": 0.6247221430142721}, {"text": "authorship attribution", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.8082320690155029}]}, {"text": "We show that our approach yields state-of-the-art performance for both a few and many candidate authors, in cases where these authors wrote enough texts to be modelled effectively.", "labels": [], "entities": []}], "introductionContent": [{"text": "The problem of authorship attribution -attributing texts to their original authors -has received considerable attention in the last decade).", "labels": [], "entities": [{"text": "authorship attribution -attributing texts to their original authors", "start_pos": 15, "end_pos": 82, "type": "TASK", "confidence": 0.8581643104553223}]}, {"text": "Most of the work in this field focuses on cases where texts must be attributed to one of a few candidate authors, e.g.,.", "labels": [], "entities": []}, {"text": "Recently, researchers have turned their attention to scenarios with tens to thousands of candidate authors.", "labels": [], "entities": []}, {"text": "In this paper, we study authorship attribution with few to many candidate authors, and introduce anew method that achieves state-of-the-art performance in the latter case.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.7436308264732361}]}, {"text": "Our approach to authorship attribution consists of building models of authors and their texts using Latent Dirichlet Allocation (LDA) (.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 16, "end_pos": 38, "type": "TASK", "confidence": 0.7700497508049011}, {"text": "Latent Dirichlet Allocation (LDA)", "start_pos": 100, "end_pos": 133, "type": "METRIC", "confidence": 0.9105406999588013}]}, {"text": "We compare these models to models built from texts with unknown authors to find the most likely authors of these texts (Section 3.2).", "labels": [], "entities": []}, {"text": "Our evaluation shows that our approach yields a higher accuracy than the method recently introduced by in several cases where prolific authors are considered, while requiring less runtime.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9991374015808105}]}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "Related work is surveyed in Section 2.", "labels": [], "entities": []}, {"text": "Our LDA-based approach to authorship attribution is described in Section 3, together with the baselines we considered in our evaluation.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.836471289396286}]}, {"text": "Section 4 presents and discusses the results of our evaluation, and Section 5 discusses our conclusions and plans for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe the experimental setup and datasets used in our experiments, followed by the evaluation of our methods.", "labels": [], "entities": []}, {"text": "We evaluate Topic SVM for binary authorship attribution, and LDA+Hellinger on a binary dataset, a dataset with tens of authors, and a dataset with thousands of authors.", "labels": [], "entities": []}, {"text": "Our results show that LDA+Hellinger yields a higher accuracy than baseline method in several cases where prolific authors are considered, while requiring less runtime.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9988527297973633}]}, {"text": "In all the experiments, we perform ten-fold cross validation, employing stratified sampling where possible.", "labels": [], "entities": []}, {"text": "The results are evaluated using classification accuracy, i.e., the percentage of test documents that were correctly assigned to their author.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.7847781777381897}]}, {"text": "Note that we use different accuracy ranges in the figures that present our results for clarity of presentation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9988548755645752}, {"text": "clarity", "start_pos": 87, "end_pos": 94, "type": "METRIC", "confidence": 0.9600726366043091}]}, {"text": "Statistically significant differences are reported when p < 0.05 according to a paired two-tailed t-test.", "labels": [], "entities": []}, {"text": "We used the LDA implementation from LingPipe (alias-i.com/lingpipe) and the SVM implementation from Weka (www.cs.waikato.ac. nz/ml/weka).", "labels": [], "entities": []}, {"text": "Since our focus is on testing the impact of LDA, we used a linear SVM kernel and the default SVM settings.", "labels": [], "entities": []}, {"text": "For the LDA parameters, we followed  and the recommendations in LingPipe's documentation, and set the Dirichlet hyperparameters to \u03b1 = min(0.1, 50/T ) and \u03b2 = 0.01, varying only the number of topics T . We ran the Gibbs sampling process for S = 1000 iterations, and based the document representations on the last sample.", "labels": [], "entities": [{"text": "LingPipe's documentation", "start_pos": 64, "end_pos": 88, "type": "DATASET", "confidence": 0.9631705482800802}]}, {"text": "While taking more than one sample is generally considered good practice (Steyvers and Griffiths, 2007), we found that the impact of taking several samples on accuracy is minimal, but it substantially increases the runtime.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.999299168586731}]}, {"text": "Hence, we decided to use only one sample in our experiments.", "labels": [], "entities": []}, {"text": "We considered three datasets that cover different writing styles and settings: Judgement, IMDb62 and Blog.", "labels": [], "entities": [{"text": "Judgement", "start_pos": 79, "end_pos": 88, "type": "TASK", "confidence": 0.8574394583702087}, {"text": "IMDb62", "start_pos": 90, "end_pos": 96, "type": "DATASET", "confidence": 0.8687534928321838}, {"text": "Blog", "start_pos": 101, "end_pos": 105, "type": "DATASET", "confidence": 0.8902272582054138}]}, {"text": "shows a summary of these datasets.", "labels": [], "entities": []}, {"text": "The Judgement dataset contains judgements by three judges who served on the Australian High In this paper, we considered the Dixon/McTiernan and the Dixon/Rich binary classification cases, using judgements from non-overlapping periods).", "labels": [], "entities": [{"text": "Judgement dataset", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.9237962067127228}, {"text": "Australian High", "start_pos": 76, "end_pos": 91, "type": "DATASET", "confidence": 0.9871551394462585}]}, {"text": "We removed numbers from the texts to ensure that dates could not be used to discriminate between judges.", "labels": [], "entities": []}, {"text": "We also removed quotes to ensure that the classifiers take into account only the actual author's language use.", "labels": [], "entities": []}, {"text": "Employing this dataset in our experiments allows us to test our methods on formal texts with a minimal amount of noise.", "labels": [], "entities": []}, {"text": "The IMDb62 dataset contains 62,000 movie reviews by 62 prolific users of the Internet Movie database (IMDb, www.imdb.com, available upon request from the authors of ().", "labels": [], "entities": [{"text": "IMDb62 dataset", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.9640629887580872}, {"text": "Internet Movie database", "start_pos": 77, "end_pos": 100, "type": "DATASET", "confidence": 0.7990255554517111}]}, {"text": "Each user wrote 1,000 reviews.", "labels": [], "entities": []}, {"text": "This dataset is noisier than the Judgement dataset, since it may contain spelling and grammatical errors, and the reviews are not as professionally edited as judgements.", "labels": [], "entities": [{"text": "Judgement dataset", "start_pos": 33, "end_pos": 50, "type": "DATASET", "confidence": 0.9000623524188995}]}, {"text": "This dataset allows us to test our approach in a setting where all the texts have similar themes, and the number of authors is relatively small, but is already much larger than the number of authors considered in traditional authorship attribution settings.", "labels": [], "entities": []}, {"text": "The Blog dataset is the largest dataset we considered, containing 678,161 blog posts by 19,320 authors () (available for download from u.cs.biu.ac.il/ \u02dc koppel).", "labels": [], "entities": [{"text": "Blog dataset", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.9826329052448273}]}, {"text": "In contrast to IMDb reviews, blog posts can be about any topic, but the large number of authors ensures that every topic is likely to interest at least some authors.", "labels": [], "entities": []}, {"text": "used a different blog dataset consisting of 10,240 authors in their work on authorship attribution with many candidate authors.", "labels": [], "entities": []}, {"text": "Unfortunately, their dataset is not publicly available.", "labels": [], "entities": []}, {"text": "However, authorship attribution is more challenging on the dataset we used, because they imposed some restrictions on their dataset, such as setting a minimal number of words per author, and truncating the training and testing texts so that they all have the same length.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.8356827199459076}]}, {"text": "The dataset we use has no such restrictions.", "labels": [], "entities": []}], "tableCaptions": []}