{"title": [], "abstractContent": [{"text": "While many computational models have been created to explore how children might learn to segment words, the focus has largely been on achieving higher levels of performance and exploring cues suggested by artificial learning experiments.", "labels": [], "entities": []}, {"text": "We propose a broader focus that includes designing models that display properties of infants' performance as they begin to segment words.", "labels": [], "entities": []}, {"text": "We develop an efficient bootstrapping online learner with this focus in mind, and evaluate it on child-directed speech.", "labels": [], "entities": []}, {"text": "In addition to attaining a high level of performance , this model predicts the error patterns seen in infants learning to segment words.", "labels": [], "entities": []}], "introductionContent": [{"text": "The last fifteen years have seen an increased interest in the problem of how infants learn to segment a continuous stream of speech into words.", "labels": [], "entities": [{"text": "segment a continuous stream of speech into words", "start_pos": 94, "end_pos": 142, "type": "TASK", "confidence": 0.6860002987086773}]}, {"text": "Much of this work has been inspired by experiments with infants focusing on what capabilities infants have and which cues they attend to.", "labels": [], "entities": []}, {"text": "While experimental work provides insight into the types of cues infants maybe using, computational modeling of the task provides a unique opportunity to test proposed cues on representative data and validate potential approaches to using them.", "labels": [], "entities": []}, {"text": "While there are many potential approaches to the problem, a desirable solution to the problem should demonstrate acceptable performance in a simulation of the task, rely on cues in the input that an infant learner is able to detect at the relevant age, and exhibit learning patterns similar to those of infant learners.", "labels": [], "entities": []}, {"text": "Most work in computational modeling of language acquisition has primarily focused on achieving acceptable performance using a single cue, transitional probabilities, but little effort has been made in that work to try to connect these learning solutions to the actual learning patterns observed in children outside of performance on short artificial language learning experiments.", "labels": [], "entities": [{"text": "computational modeling of language acquisition", "start_pos": 13, "end_pos": 59, "type": "TASK", "confidence": 0.6353074729442596}]}, {"text": "In this work we present a simple, easily extended algorithm for unsupervised word segmentation that, in addition to achieving a high level of performance in the task, correlates with the developmental patterns observed in infants.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 77, "end_pos": 94, "type": "TASK", "confidence": 0.7352219223976135}]}, {"text": "We discuss the connections between the design and behavior of our algorithm and the cognitive capabilities of infants at the age at which they appear to begin segmenting words.", "labels": [], "entities": []}, {"text": "We also discuss how our technique can easily be extended to accept additional cues to word segmentation beyond those implemented in our learner.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 86, "end_pos": 103, "type": "TASK", "confidence": 0.7188273221254349}]}], "datasetContent": [{"text": "To evaluate the performance of our model, we measured performance on child-directed speech, using the same corpus used in a number of previous studies that used syllabified input.", "labels": [], "entities": []}, {"text": "The eval-uation set was comprised of adult utterances from the Brown (1973) data of the CHILDES database).", "labels": [], "entities": [{"text": "Brown (1973) data of the CHILDES database", "start_pos": 63, "end_pos": 104, "type": "DATASET", "confidence": 0.7828938563664755}]}, {"text": "1 Phonemic transcriptions of words from the Carnegie Mellon Pronouncing Dictionary (CMUdict) Version 0.7 (Weide, 1998), using the first pronunciation for each word and marking syllables with level 1 stress as strong syllables.", "labels": [], "entities": [{"text": "Carnegie Mellon Pronouncing Dictionary (CMUdict) Version 0.7 (Weide, 1998)", "start_pos": 44, "end_pos": 118, "type": "DATASET", "confidence": 0.821377986243793}]}, {"text": "The corpus was syllabified using onset maximization.", "labels": [], "entities": []}, {"text": "Any utterance in which a word could not be transcribed using CMUDICT was excluded, leaving 55,840 utterances.", "labels": [], "entities": [{"text": "CMUDICT", "start_pos": 61, "end_pos": 68, "type": "DATASET", "confidence": 0.8657103776931763}]}, {"text": "We applied a probabilistic recall function to the lexicon to simulate the fact that a child learner will not perfectly recall all hypothesized words either due to memory limitations, variability in the input, or any other possible source of failure.", "labels": [], "entities": [{"text": "recall", "start_pos": 27, "end_pos": 33, "type": "METRIC", "confidence": 0.9521077275276184}]}, {"text": "We used the same function and constant as used by.", "labels": [], "entities": []}, {"text": "To adjust the word-level stress information to better reflect natural speech, the stress information obtained from CMUdict was post-processed in the context of each utterance using the technique of.", "labels": [], "entities": []}, {"text": "For any n adjacent primarystress syllables, only the nth syllable retains primary stress; all others are made into weak syllables.", "labels": [], "entities": []}, {"text": "This reflects the fact that stress clash is avoided in English and that infants may not reliably detect acoustic correlates of stress in the input.", "labels": [], "entities": []}, {"text": "In addition to variations of our algorithm, we evaluated a baseline segmenter which marks every syllable boundary as a word boundary, treating each syllable as a word.", "labels": [], "entities": []}, {"text": "We tested five variants of our algorithm, adding combinations of USS, subtractive segmentation, and adding beam search with abeam size of two 2 to subtractive segmentation.", "labels": [], "entities": [{"text": "USS", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.9872263073921204}, {"text": "subtractive segmentation", "start_pos": 70, "end_pos": 94, "type": "TASK", "confidence": 0.6704077273607254}]}, {"text": "Precision and recall metrics were calculated overall word boundaries overall utterances in the corpus.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9826909899711609}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9871360063552856}]}, {"text": "The segmenter's task is effectively to classify each syllable boundary as a word boundary or not.", "labels": [], "entities": []}, {"text": "As single-syllable utterances are unambiguously a single word with no possible boundaries, they are excluded from evaluation but still given as input.", "labels": [], "entities": []}, {"text": "Evaluation was performed by giving each algorithm a single pass over the data set, with the performance on every utterance included in the total score.", "labels": [], "entities": []}, {"text": "This is the most challenging metric for an online segmenter, as early mistakes made when the learner has been exposed to no data still count against it.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Learner and baseline performance", "labels": [], "entities": []}]}