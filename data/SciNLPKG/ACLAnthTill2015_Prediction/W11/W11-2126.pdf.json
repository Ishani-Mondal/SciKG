{"title": [{"text": "Agreement Constraints for Statistical Machine Translation into German", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.8890235622723898}]}], "abstractContent": [{"text": "Languages with rich inflectional morphology pose a difficult challenge for statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 75, "end_pos": 106, "type": "TASK", "confidence": 0.7990574439366659}]}, {"text": "To address the problem of morphologically inconsistent output, we add unification-based constraints to the target-side of a string-to-tree model.", "labels": [], "entities": []}, {"text": "By integrating constraint evaluation into the decoding process, implausible hypotheses can be penalised or filtered out during search.", "labels": [], "entities": []}, {"text": "We use a simple heuristic process to extract agreement constraints for German and test our approach on an English-German system trained on WMT data, achieving a small improvement in translation accuracy as measured by BLEU.", "labels": [], "entities": [{"text": "WMT data", "start_pos": 139, "end_pos": 147, "type": "DATASET", "confidence": 0.8280324339866638}, {"text": "accuracy", "start_pos": 194, "end_pos": 202, "type": "METRIC", "confidence": 0.9230034351348877}, {"text": "BLEU", "start_pos": 218, "end_pos": 222, "type": "METRIC", "confidence": 0.9918770790100098}]}], "introductionContent": [{"text": "Historically, most work in statistical machine translation (SMT) has focused on translation into English.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 27, "end_pos": 64, "type": "TASK", "confidence": 0.8288493702809016}]}, {"text": "Languages with richer inflectional morphologies pose additional challenges for translation and conventional SMT approaches tend to perform poorly when either source or target language has rich morphology ().", "labels": [], "entities": [{"text": "translation", "start_pos": 79, "end_pos": 90, "type": "TASK", "confidence": 0.984943151473999}, {"text": "SMT", "start_pos": 108, "end_pos": 111, "type": "TASK", "confidence": 0.9895957112312317}]}, {"text": "For complex source inflection, a successful approach has been to cluster inflectional variants into equivalence classes.", "labels": [], "entities": []}, {"text": "This removes information that is redundant for translation and can be performed as a preprocessing step for input to a conventional surface form based translation model).", "labels": [], "entities": [{"text": "translation", "start_pos": 47, "end_pos": 58, "type": "TASK", "confidence": 0.9755245447158813}]}, {"text": "For complex target inflection, investigate how postprocessing can be used to generate inflection fora system that produces uninflected output.", "labels": [], "entities": []}, {"text": "Their approach is successfully applied to English-Arabic and English-Russian systems by.", "labels": [], "entities": []}, {"text": "Another promising line of research involves the direct integration of linguistic information into SMT models.", "labels": [], "entities": [{"text": "SMT", "start_pos": 98, "end_pos": 101, "type": "TASK", "confidence": 0.9945283532142639}]}, {"text": "generalise the phrase-based model's representation of the word from a string to a vector, allowing additional features such as part-of-speech and morphology to be associated with, or even to replace, surface forms during search.", "labels": [], "entities": []}, {"text": "decompose words into morphemes and use this extended representation throughout the training, tuning, and testing pipeline.", "labels": [], "entities": []}, {"text": "Departing further from traditional SMT models, the transfer-based systems of,, and employ rich feature structure representations for linguistic attributes, but have so far been limited by their dependence on nonstochastic parsers with limited coverage.", "labels": [], "entities": [{"text": "SMT", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.9917399883270264}]}, {"text": "The Stat-XFER transfer-based framework is neutral with regard to the rule acquisition method and the author describes a manually developed Hebrew-English transfer grammar, which includes a small number of constraints between agreement features.", "labels": [], "entities": [{"text": "rule acquisition", "start_pos": 69, "end_pos": 85, "type": "TASK", "confidence": 0.7622380256652832}]}, {"text": "In the framework is used with a large automatically-extracted grammar, though this does not use feature constraints.", "labels": [], "entities": []}, {"text": "In this paper we propose a model that retains the use of surface forms during decoding whilst also checking linguistic constraints defined over associated feature structures.", "labels": [], "entities": []}, {"text": "Specifically, we extend a string-to-tree model by adding unification-based constraints to the target-side of the synchronous grammar.", "labels": [], "entities": []}, {"text": "We suggest that such a constraint system can: \u2022 improve the model by enforcing inflectional consistency in combinations unseen by the language model \u2022 improve search by allowing the early elimination of morphologically-inconsistent hypotheses To evaluate the approach, we develop a system for English-German with constraints to enforce intra-NP/PP and subject-verb agreement, and with a simple probabilistic model for NP case.", "labels": [], "entities": []}], "datasetContent": [{"text": "The systems were evaluated against constrained versions of the newstest2009, newstest2010, and newstest2011 test sets.", "labels": [], "entities": [{"text": "newstest2011 test sets", "start_pos": 95, "end_pos": 117, "type": "DATASET", "confidence": 0.9095708926518759}]}, {"text": "We used a maximum rule span of 20 tokens for decoding.", "labels": [], "entities": []}, {"text": "In order that the input could be covered without the use of glue rules (except for unknown words), we used sentences of 20 or fewer tokens, giving test sets of 1,025, 1,054, and 1,317 sentences, respectively.", "labels": [], "entities": []}, {"text": "We evaluated translation quality using case-sensitive BLEU-4 (Papineni ) with a single reference.", "labels": [], "entities": [{"text": "translation", "start_pos": 13, "end_pos": 24, "type": "TASK", "confidence": 0.9685247540473938}, {"text": "BLEU-4", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9845298528671265}]}, {"text": "shows the results for the three constrained test tests.", "labels": [], "entities": []}, {"text": "The p-values were calculated using paired bootstrap resampling).", "labels": [], "entities": []}, {"text": "We suspect that the substantially lower baseline scores on the newstest2011 test set are largely due to recency effects (since we use 2010 data for training).", "labels": [], "entities": [{"text": "newstest2011 test set", "start_pos": 63, "end_pos": 84, "type": "DATASET", "confidence": 0.9802329142888387}]}, {"text": "To gauge the frequency of agreement violations in the baseline output we matched constraint rules to the 1-best baseline derivations and performed a bottom-up evaluation for each target-side tree.", "labels": [], "entities": []}, {"text": "For the three constrained test sets, newstest2009, newstest2010, and newstest2011, we found that 15.5%, 14.4%, and 15.6% of sentences, respectively, contained one or more constraint failures.", "labels": [], "entities": []}, {"text": "shows the tree fragments for the first five failures found in newstest2009.", "labels": [], "entities": [{"text": "newstest2009", "start_pos": 62, "end_pos": 74, "type": "DATASET", "confidence": 0.9757753610610962}]}, {"text": "In order to explore the interaction of the constraint model with search we then repeated the experiments for varying cube pruning pop limits.", "labels": [], "entities": []}, {"text": "shows how the mean test set BLEU score varies against pop limit.", "labels": [], "entities": [{"text": "mean test set", "start_pos": 14, "end_pos": 27, "type": "METRIC", "confidence": 0.8892190257708231}, {"text": "BLEU", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.7324019074440002}]}, {"text": "Except at very low pop limits, the soft constraint system outperforms the hard constraint system.", "labels": [], "entities": []}, {"text": "Together with the high p-values for the hard constraint system, this suggests that, despite filtering, our simple constraint extraction heuristics maybe introducing significant numbers of spurious constraints.", "labels": [], "entities": []}, {"text": "Alternatively, enforcing the hard constraint may eliminate too many hypotheses that cannot be satisifactorily substituted -constraint-satisfying alternatives frequently differ in more than just inflection.", "labels": [], "entities": []}, {"text": "Either way, the soft constraint model is able to overcome some of these deficiencies by permitting some constraint failures in the 1-best output.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The 10 most freqently occurring NP labels with  their case frequencies (shown as percentages)", "labels": [], "entities": []}, {"text": " Table 2: BLEU scores and p-values for the three test sets", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9991613626480103}]}]}