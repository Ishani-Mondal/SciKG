{"title": [], "abstractContent": [{"text": "This paper presents a machine learning-based approach to the incremental understanding of dialogue utterances, with a focus on the recognition of their communicative functions.", "labels": [], "entities": [{"text": "incremental understanding of dialogue utterances", "start_pos": 61, "end_pos": 109, "type": "TASK", "confidence": 0.6530996084213256}]}, {"text": "A token-based approach combining the use of local classifiers, which exploit local utterance features, and global classifiers which use the outputs of local classifiers applied to previous and subsequent tokens, is shown to result in excellent dialogue act recognition scores for unsegmented spoken dialogue.", "labels": [], "entities": [{"text": "dialogue act recognition", "start_pos": 244, "end_pos": 268, "type": "TASK", "confidence": 0.6381393074989319}]}, {"text": "This can be seen as a significant step forward towards the development of fully incremental, on-line methods for computing the meaning of utterances in spoken dialogue.", "labels": [], "entities": [{"text": "computing the meaning of utterances in spoken dialogue", "start_pos": 113, "end_pos": 167, "type": "TASK", "confidence": 0.7922365292906761}]}], "introductionContent": [{"text": "When reading a sentence in a text, a human language understander obviously does not wait trying to understand what he is reading until he has come to the end of the sentence.", "labels": [], "entities": []}, {"text": "Similarly for participants in a spoken conversation.", "labels": [], "entities": []}, {"text": "There is overwhelming psycholinguistic evidence that human understanders construct syntactic, semantic, and pragmatic hypotheses on the fly, while receiving the written or spoken input.", "labels": [], "entities": []}, {"text": "Dialogue phenomena such as backchannelling (providing feedback while someone else is speaking), the completion of a partner utterance, and requests for clarification that overlap the utterance of the main speaker, illustrate this.", "labels": [], "entities": []}, {"text": "Evidence from the analysis of nonverbal behaviour in multimodal dialogue lends further support to the claim that human understanding works incrementally, as input is being received.", "labels": [], "entities": []}, {"text": "Dialogue participants start to perform certain body movements and facial expressions that are perceived and interpreted by others as dialogue acts (such as head nods, smiles, frowns) while another participant is speaking, see e.g..", "labels": [], "entities": []}, {"text": "As another kind of evidence, eye-tracking experiments by, and showed that definite descriptions are resolved incrementally when the referent is visually accessible.", "labels": [], "entities": []}, {"text": "Traditional models of language understanding for dialogue systems, by contrast, are pipelined, modular, and operate on complete utterances.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.7546308040618896}]}, {"text": "Typically, such a system has an automatic speech recognition module, a language understanding module responsible for syntactic and semantic analysis, an interpretation manager, a dialogue manager, a natural language generation module, and a module for speech synthesis.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.7271962463855743}, {"text": "syntactic and semantic analysis", "start_pos": 117, "end_pos": 148, "type": "TASK", "confidence": 0.754836231470108}, {"text": "speech synthesis", "start_pos": 252, "end_pos": 268, "type": "TASK", "confidence": 0.7377170771360397}]}, {"text": "The output of each module is the input for another.", "labels": [], "entities": []}, {"text": "The language understanding module typically performs the following tasks: (1) segmentation: identification of relevant segments in the input, such as sentences;(2) lexical analysis: lexical lookup, possibly supported by morphological processing, and by additional resources such as WordNet, VerbNet, or lexical ontologies; (3) parsing: construction of syntactic interpretations; (4) semantic analysis: computation of propositional, referential, or actionrelated content; and (5) pragmatic analysis: determination of speaker intentions.", "labels": [], "entities": []}, {"text": "Of these tasks, lexical analysis, being concerned with local information at word level, can be done for each word as soon as it has been recognized, and is naturally performed as an incremental part of utterance processing, but syntactic, semantic and pragmatic analysis are traditionally performed on complete utterances.", "labels": [], "entities": [{"text": "lexical analysis", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.7562689483165741}]}, {"text": "Tomita's pioneering work in left-to-right syntactic parsing has shown that incremental parsing can be much more efficient and of equal quality as the parsing of complete utterances).", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 42, "end_pos": 59, "type": "TASK", "confidence": 0.7240519821643829}, {"text": "incremental parsing", "start_pos": 75, "end_pos": 94, "type": "TASK", "confidence": 0.6884691417217255}, {"text": "parsing of complete utterances", "start_pos": 150, "end_pos": 180, "type": "TASK", "confidence": 0.8466878533363342}]}, {"text": "Computational approaches to incremental semantic and pragmatic interpretation have been less successful (see e.g.;), but work in computational semantics on the design of underspecified representation formalisms has shown that such formalisms, developed originally for the underspecified representation of quantifier scopes, can also be applied in situations where incomplete input information is available (see e.g.,,) and as such hold a promise for incremental semantic interpretation.", "labels": [], "entities": [{"text": "incremental semantic and pragmatic interpretation", "start_pos": 28, "end_pos": 77, "type": "TASK", "confidence": 0.6586753964424134}, {"text": "semantic interpretation", "start_pos": 462, "end_pos": 485, "type": "TASK", "confidence": 0.8076335787773132}]}, {"text": "Pragmatic interpretation, in particular the recognition of a speaker's intentions in incoming dialogue utterances, is another major aspect of language understanding for dialogue systems.", "labels": [], "entities": [{"text": "Pragmatic interpretation", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7454386353492737}, {"text": "recognition of a speaker's intentions in incoming dialogue utterances", "start_pos": 44, "end_pos": 113, "type": "TASK", "confidence": 0.7956112504005433}]}, {"text": "Computational modelling of dialogue behaviour in terms of dialogue acts aims to capture speaker intentions in the communicative functions of dialogue acts, and offers an effective integration with semantic content analysis through the information state update approach ().", "labels": [], "entities": [{"text": "information state update", "start_pos": 235, "end_pos": 259, "type": "TASK", "confidence": 0.6956813732782999}]}, {"text": "In this approach, a dialogue act is viewed as having as its main components a communicative function and a semantic content, where the semantic content is the referential, propositional, or action-related information that the dialogue act addresses, and the communicative function defines how an understander's information state is to be updated with that information.", "labels": [], "entities": []}, {"text": "Evaluation of a non-incremental dialogue system and its incremental counterpart reported in showed that the latter is faster overall than the former due to the incorporation of pragmatic information in early stages of the understanding process.", "labels": [], "entities": []}, {"text": "Since users formulate utterances incrementally, partial utterances maybe available fora substantial amount of time and maybe interpreted by the system.", "labels": [], "entities": []}, {"text": "An incremental interpretation strategy may allow the system to respond more quickly, by minimizing the delay between the time the user finishes and the time the utterance is interpreted.", "labels": [], "entities": []}, {"text": "This suggests that a dialogue system performance may benefit from reliable partial processing of input.", "labels": [], "entities": []}, {"text": "This paper is concerned with the automatic recognition of dialogue acts based on partially available input and shows that in order to arrive at the best output prediction two different classification strategies are needed: (1) local classification that is based on features observed in dialogue behaviour and that can be extracted from the annotated data; and (2) global classification that takes the locally predicted context into account.", "labels": [], "entities": [{"text": "automatic recognition of dialogue acts", "start_pos": 33, "end_pos": 71, "type": "TASK", "confidence": 0.7095519065856933}, {"text": "global classification", "start_pos": 364, "end_pos": 385, "type": "TASK", "confidence": 0.7020680159330368}]}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we will outline performed experiments describing the data, tagset, features, algorithms and evaluation metrics that have been used.", "labels": [], "entities": []}, {"text": "Section 3 reports on the experimental results, applying a variety of machine learning techniques and feature selection algorithms, to assess the automatic recognition and classification of dialogue acts using simultaneous incremental segmentation and dialogue act classification.", "labels": [], "entities": [{"text": "automatic recognition and classification of dialogue acts", "start_pos": 145, "end_pos": 202, "type": "TASK", "confidence": 0.7535884380340576}, {"text": "dialogue act classification", "start_pos": 251, "end_pos": 278, "type": "TASK", "confidence": 0.6815016071001688}]}, {"text": "In Section 4 we discuss strategies in management and correction of the output of local classifies.", "labels": [], "entities": []}, {"text": "2 Incremental understanding experiments 2.1 Related work) proposed a method for the incremental understanding of utterances whose boundaries are not known.", "labels": [], "entities": [{"text": "Incremental understanding", "start_pos": 2, "end_pos": 27, "type": "TASK", "confidence": 0.8099994361400604}, {"text": "incremental understanding of utterances whose boundaries", "start_pos": 84, "end_pos": 140, "type": "TASK", "confidence": 0.751105010509491}]}, {"text": "The Incremental Sentence Sequence Search (ISSS) algorithm finds plausible boundaries of utterances, called significant utterances (SUs), which can be a full sentence or a subsentential phrase, such as a noun phrase or a verb phrase.", "labels": [], "entities": [{"text": "Incremental Sentence Sequence Search (ISSS)", "start_pos": 4, "end_pos": 47, "type": "TASK", "confidence": 0.7735587315899985}]}, {"text": "Any phrase that can change the belief state is defined as a SU.", "labels": [], "entities": []}, {"text": "In this sense an SU corresponds more or less with what we calla 'functional segment', which is defined as a minimal stretch of behaviour that has a communicative function (see).", "labels": [], "entities": [{"text": "SU", "start_pos": 17, "end_pos": 19, "type": "TASK", "confidence": 0.957655131816864}]}, {"text": "ISSS maintains multiple possible belief states, and updates these each time a word hypothesis is input.", "labels": [], "entities": [{"text": "ISSS", "start_pos": 0, "end_pos": 4, "type": "TASK", "confidence": 0.6723389625549316}]}, {"text": "The ISSS approach does not deal with the multifunctionality of segments, however, and does not allow segments to overlap.) proposed token-based dialogue act segmentation and classification, which was worked out in more detail in.", "labels": [], "entities": [{"text": "token-based dialogue act segmentation and classification", "start_pos": 132, "end_pos": 188, "type": "TASK", "confidence": 0.6580420384804407}]}, {"text": "This approach takes dialogue data that is not segmented into syntactic or semantic units, but operates on the transcribed speech as a stream of words and other vocal signs (e.g. laughs), including disfluent elements (e.g. abandoned or interrupted words).", "labels": [], "entities": []}, {"text": "Segmentation and classification of dialogue acts are performed simultaneously in one step.", "labels": [], "entities": [{"text": "classification of dialogue acts", "start_pos": 17, "end_pos": 48, "type": "TASK", "confidence": 0.803168460726738}]}, {"text": "Geertzen (2009) reports on classifier performance on this task for the DIAMOND data 1 using DIT ++ labels.", "labels": [], "entities": [{"text": "DIAMOND data 1", "start_pos": 71, "end_pos": 85, "type": "DATASET", "confidence": 0.8207721710205078}]}, {"text": "The success scores in terms of F-scores range from 47.7 to 81.7.", "labels": [], "entities": [{"text": "success", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9646731019020081}, {"text": "F-scores", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.99908447265625}]}, {"text": "It was shown that performing segmentation and classification together results in better segmentation, but affects the dialogue act classification negatively.", "labels": [], "entities": [{"text": "dialogue act classification", "start_pos": 118, "end_pos": 145, "type": "TASK", "confidence": 0.7297335068384806}]}, {"text": "The incremental dialogue act recognition system proposed here takes the token-based approach for building classifiers for the recognition (segmentation and classification) of multiple dialogue acts for each input token, and adopts the ISSS idea for information-state updates based on partial input interpretation.", "labels": [], "entities": [{"text": "dialogue act recognition", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.6481079359849294}, {"text": "recognition (segmentation and classification) of multiple dialogue acts", "start_pos": 126, "end_pos": 197, "type": "TASK", "confidence": 0.8317568868398666}]}], "datasetContent": [{"text": "A wide variety of machine-learning techniques has been used for NLP tasks with various instantiations of feature sets and target class encodings.", "labels": [], "entities": []}, {"text": "For dialogue processing, it is still an open issue which techniques are the most suitable for which task.", "labels": [], "entities": [{"text": "dialogue processing", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.9616251587867737}]}, {"text": "We used two different types of classifiers to test their performance on our dialogue data: a probabilistic one and a rule inducer.", "labels": [], "entities": []}, {"text": "As a probabilistic classifier we used Bayes Nets.", "labels": [], "entities": []}, {"text": "This classifier estimates probabilities rather than produce predictions, which is often more useful because this allows us to rank predictions.", "labels": [], "entities": []}, {"text": "Bayes Nets estimate the conditional probability distribution on the values of the class attributes given the values of the other attributes.", "labels": [], "entities": []}, {"text": "As a rule induction algorithm we chose).", "labels": [], "entities": []}, {"text": "The advantage of a rule inducer is that the regularities discovered in the data are represented as human-readable rules.", "labels": [], "entities": []}, {"text": "The results of all experiments were obtained using 10-fold cross-validation.", "labels": [], "entities": []}, {"text": "As a baseline it is common practice to use the majority class tag, but for our data sets such a baseline is not very useful because of the relatively low frequencies of the tags in some dimensions.", "labels": [], "entities": []}, {"text": "Instead, we use a baseline The A \u00af ugmented M \u00af ulti-party I \u00af nteraction meeting corpus consists of multimodal task-oriented human-human multi-party dialogues in English, for more information visit (http://www.amiproject.org/ 4 Difference between the time that a turn starts and the moment the previous turn ends.", "labels": [], "entities": []}, {"text": "These features were computed using the PRAAT tool . We examined both raw and normalized versions of these features.", "labels": [], "entities": [{"text": "PRAAT", "start_pos": 39, "end_pos": 44, "type": "DATASET", "confidence": 0.5834240913391113}]}, {"text": "Speaker-normalized features were obtained by computing z-scores (z = (X-mean)/standard deviation) for the feature, where mean and standard deviation were calculated from all functional segments produced by the same speaker in the dialogues.", "labels": [], "entities": [{"text": "X-mean)/standard deviation)", "start_pos": 70, "end_pos": 97, "type": "METRIC", "confidence": 0.8144658088684082}]}, {"text": "We also used normalizations by first speaker turn and by previous speaker turn.", "labels": [], "entities": []}, {"text": "In order to reduce the effect of imbalances in the data, it is partitioned ten times.", "labels": [], "entities": []}, {"text": "Each time a different 10% of the data is used as test set and the remaining 90% as training set.", "labels": [], "entities": []}, {"text": "The procedure is repeated ten times so that in the end, every instance has been used exactly once for testing and the scores are averaged.", "labels": [], "entities": []}, {"text": "The cross-validation was stratified, i.e. the 10 folds contained approximately the same proportions of instances with relevant tags as in the entire dataset. that is based on a single feature, namely, the tag of the previous dialogue utterance (see)).", "labels": [], "entities": []}, {"text": "Several metrics have been proposed for the evaluation of a classifier's performance: error metrics and performance metrics.", "labels": [], "entities": []}, {"text": "The word-based error rate metric, introduced in, measures the percentage of words that were placed in a segment perfectly identical to that in the reference.", "labels": [], "entities": [{"text": "word-based error rate metric", "start_pos": 4, "end_pos": 32, "type": "METRIC", "confidence": 0.7297981306910515}]}, {"text": "The dialogue act based metric (DER) was proposed in.", "labels": [], "entities": [{"text": "dialogue act based metric (DER)", "start_pos": 4, "end_pos": 35, "type": "METRIC", "confidence": 0.5396120165075574}]}, {"text": "In this metric a word is considered to be correctly classified if and only if it has been assigned the correct dialogue act type and it lies in exactly the same segment as the corresponding word of the reference.", "labels": [], "entities": []}, {"text": "We will use the combined DER sc error metric to evaluate joint segmentation (s) and classification (c): T okens with wrong boundaries and/or function class total number of tokens \u00d7 100 To assess the quality of classification results, the standard F-score metric is used, which represents the balance between precision and recall.", "labels": [], "entities": [{"text": "DER sc error metric", "start_pos": 25, "end_pos": 44, "type": "METRIC", "confidence": 0.8344147205352783}, {"text": "F-score metric", "start_pos": 247, "end_pos": 261, "type": "METRIC", "confidence": 0.9739123582839966}, {"text": "precision", "start_pos": 308, "end_pos": 317, "type": "METRIC", "confidence": 0.9993335604667664}, {"text": "recall", "start_pos": 322, "end_pos": 328, "type": "METRIC", "confidence": 0.9965156316757202}]}], "tableCaptions": [{"text": " Table 1: Distribution of functional tags across dimensions and general-purpose functions for the AMI corpus (in", "labels": [], "entities": [{"text": "AMI corpus", "start_pos": 98, "end_pos": 108, "type": "DATASET", "confidence": 0.7851260900497437}]}, {"text": " Table 2: Overview of F-scores and DER sc for the baseline (BL) and the classifiers for joint segmentation and", "labels": [], "entities": [{"text": "F-scores", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9580100178718567}, {"text": "DER", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.988849937915802}, {"text": "joint segmentation", "start_pos": 88, "end_pos": 106, "type": "TASK", "confidence": 0.6387184858322144}]}, {"text": " Table 3: Overview of F-scores and DER sc for the baseline (BL) and the classifiers upon joint segmentation", "labels": [], "entities": [{"text": "F-scores", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9665582180023193}, {"text": "DER", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.9833400845527649}]}, {"text": " Table 4: Overview of F-scores and DER sc of the global classifiers for the AMI data based on added previous", "labels": [], "entities": [{"text": "F-scores", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9670712351799011}, {"text": "DER", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.99725741147995}, {"text": "AMI data", "start_pos": 76, "end_pos": 84, "type": "DATASET", "confidence": 0.9055717885494232}]}, {"text": " Table 5: Overview of F-scores and DER sc of global classifiers for the AMI data per DIT ++ dimension.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9131413102149963}, {"text": "DER", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.9970910549163818}, {"text": "AMI data", "start_pos": 72, "end_pos": 80, "type": "DATASET", "confidence": 0.9109342694282532}]}]}