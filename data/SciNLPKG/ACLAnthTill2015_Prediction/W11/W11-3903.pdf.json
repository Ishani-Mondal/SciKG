{"title": [{"text": "Robust Unsupervised and Semi-Supervised Methods in Natural Language Processing", "labels": [], "entities": []}], "abstractContent": [{"text": "In the field of subjectivity detection, algorithms automatically classify pieces of text into factor opinion.", "labels": [], "entities": [{"text": "subjectivity detection", "start_pos": 16, "end_pos": 38, "type": "TASK", "confidence": 0.7401147186756134}]}, {"text": "Many different approaches have been successfully evaluated on English or Chinese texts.", "labels": [], "entities": []}, {"text": "Nevertheless the assumption that these algorithms equally perform on all other languages cannot be verified yet.", "labels": [], "entities": []}, {"text": "It is our intention to encourage more research in other languages, making a start with Ger-man.", "labels": [], "entities": []}, {"text": "Therefore, this work introduces a German corpus for subjectivity detection on German news articles.", "labels": [], "entities": [{"text": "subjectivity detection", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.7379980385303497}]}, {"text": "We carryout this study in which we choose a number of state of the art subjectivity detection approaches and implement them.", "labels": [], "entities": [{"text": "subjectivity detection", "start_pos": 71, "end_pos": 93, "type": "TASK", "confidence": 0.7939358353614807}]}, {"text": "Finally we show and compare these algorithms' performances and give advice on how to use and extend the introduced dataset.", "labels": [], "entities": []}], "introductionContent": [{"text": "The detection of subjective statements in natural language texts is necessary for the analysis of opinions and the extraction of facts for knowledge retrieval.", "labels": [], "entities": [{"text": "detection of subjective statements in natural language texts", "start_pos": 4, "end_pos": 64, "type": "TASK", "confidence": 0.8195860534906387}, {"text": "knowledge retrieval", "start_pos": 139, "end_pos": 158, "type": "TASK", "confidence": 0.7155483216047287}]}, {"text": "The continuously increasing number of natural language texts on the Internet and the need for opinion detection and fact retrieval makes research on subjectivity detection more and more important.", "labels": [], "entities": [{"text": "opinion detection", "start_pos": 94, "end_pos": 111, "type": "TASK", "confidence": 0.7932306230068207}, {"text": "fact retrieval", "start_pos": 116, "end_pos": 130, "type": "TASK", "confidence": 0.797153502702713}, {"text": "subjectivity detection", "start_pos": 149, "end_pos": 171, "type": "TASK", "confidence": 0.7604717314243317}]}, {"text": "The economic impact is rising just as much.", "labels": [], "entities": []}, {"text": "The Internet has long turned into an open platform in which everybody can participate and contribute his or her share of opinions.", "labels": [], "entities": []}, {"text": "Subjectivity detection also affects upcoming fields of research like knowledge retrieval.", "labels": [], "entities": [{"text": "Subjectivity detection", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9565207362174988}, {"text": "knowledge retrieval", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.8127191066741943}]}, {"text": "Crawlers have to distinguish between objective and subjective texts in order to extract given facts only from the objective parts.", "labels": [], "entities": []}, {"text": "The other way round, in the field of opinion analysis, many approaches are supposed to be applied on subjective texts.", "labels": [], "entities": [{"text": "opinion analysis", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.825105756521225}]}, {"text": "In polarity classification pieces of text are classified into complementary viewpoints.", "labels": [], "entities": [{"text": "polarity classification pieces of text", "start_pos": 3, "end_pos": 41, "type": "TASK", "confidence": 0.8211848497390747}]}, {"text": "In this field of research facts are considered noise to the problem.", "labels": [], "entities": []}, {"text": "So, finding the subjective parts beforehand can increase the accuracy of such a classifier ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9993839263916016}]}, {"text": "Subjectivity detection can support question-answering systems.", "labels": [], "entities": [{"text": "Subjectivity detection", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8951205313205719}]}, {"text": "The knowledge about the subjectivity of sentences and sections is important, especially for complex questions that cannot be answered with a single fact, but should rather treat different viewpoints on an issue.", "labels": [], "entities": []}, {"text": "Also, subjectivity detection can be useful for text summarization which may want to list facts separately from different viewpoints.", "labels": [], "entities": [{"text": "subjectivity detection", "start_pos": 6, "end_pos": 28, "type": "TASK", "confidence": 0.7625407874584198}, {"text": "text summarization", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.7408434450626373}]}, {"text": "In conclusion it can be stated that subjectivity detection is one of the most important preprocessing steps for many IR applications.", "labels": [], "entities": [{"text": "subjectivity detection", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.8057975172996521}]}, {"text": "Such pre-processing has to be language independent or at least the drawbacks for each language have to be known.", "labels": [], "entities": []}, {"text": "Hence, the overall goal of this work is to investigate the differences in subjectivity detection in different languages, starting with German and English.", "labels": [], "entities": [{"text": "subjectivity detection", "start_pos": 74, "end_pos": 96, "type": "TASK", "confidence": 0.729437455534935}]}, {"text": "In this work we evaluate a number of machine learning based subjectivity detection approaches on German news texts and on the MPQA corpus, which is the current English standard corpus for subjectivity annotations.", "labels": [], "entities": [{"text": "subjectivity detection", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.7420989871025085}, {"text": "MPQA corpus", "start_pos": 126, "end_pos": 137, "type": "DATASET", "confidence": 0.9712315499782562}]}, {"text": "We focus on supervised learning approaches for sentence-wise binary classification between subjective and non-subjective sentences without polarity.", "labels": [], "entities": [{"text": "sentence-wise binary classification", "start_pos": 47, "end_pos": 82, "type": "TASK", "confidence": 0.615188995997111}]}, {"text": "After giving an overview over the state of the art in subjectivity detection, we provide details about the MPQA corpus.", "labels": [], "entities": [{"text": "subjectivity detection", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.7599070966243744}, {"text": "MPQA corpus", "start_pos": 107, "end_pos": 118, "type": "DATASET", "confidence": 0.9296315610408783}]}, {"text": "Afterwards we introduce the Subjectivity in News Corpus (SNC), which was created in the course of this work.", "labels": [], "entities": [{"text": "Subjectivity in News Corpus (SNC)", "start_pos": 28, "end_pos": 61, "type": "TASK", "confidence": 0.5836305873734611}]}, {"text": "The corpus, precisely the German part of the corpus, was annotated in such away that it provides maximum compatibility with MPQA.", "labels": [], "entities": [{"text": "MPQA", "start_pos": 124, "end_pos": 128, "type": "DATASET", "confidence": 0.921288251876831}]}, {"text": "Evaluation results on both corpora are compared to conclude if current machine learning based subjectivity detection approaches are equally applicable on both languages.", "labels": [], "entities": [{"text": "machine learning based subjectivity detection", "start_pos": 71, "end_pos": 116, "type": "TASK", "confidence": 0.7257858037948608}]}, {"text": "In the concluding part of this work we show which features and ideas are better fit to detect subjectivity in which language and give advice on how to handle subjectivity detection on German texts.", "labels": [], "entities": [{"text": "subjectivity detection", "start_pos": 158, "end_pos": 180, "type": "TASK", "confidence": 0.7489849627017975}]}], "datasetContent": [{"text": "Experiments were performed according to selected approaches of Section 3.2.", "labels": [], "entities": []}, {"text": "For the experiments with SVMs we chose a linear SVM and used the implementation of Libsvm 4 . For the Naive Bayes classifier the weka 5 implementation was used.", "labels": [], "entities": []}, {"text": "The Minimum-Cut classifier was implemented by ourselves based on the description in the publication.", "labels": [], "entities": []}, {"text": "For the creation and manipulation of graphs we used the JUNG 6 API.", "labels": [], "entities": [{"text": "JUNG 6 API", "start_pos": 56, "end_pos": 66, "type": "DATASET", "confidence": 0.8890828688939413}]}, {"text": "For the features of the baseline classifier we chose POS-tags and a limited number of the most frequent unigrams of the training corpus.", "labels": [], "entities": []}, {"text": "It is a simple feature set which nevertheless performs strongly compared to other approaches.", "labels": [], "entities": []}, {"text": "We carried out a number of experiments with a Naive Bayes classifier and an SVM and a variable number of unigrams as shown in.", "labels": [], "entities": []}, {"text": "It can be observed that the SVM on the English corpus is rising slightly more steeply than the SVM on the German corpus.", "labels": [], "entities": [{"text": "English corpus", "start_pos": 39, "end_pos": 53, "type": "DATASET", "confidence": 0.895701140165329}, {"text": "German corpus", "start_pos": 106, "end_pos": 119, "type": "DATASET", "confidence": 0.7855930626392365}]}, {"text": "This indicates that large numbers of unigrams are more useful for English texts than for German ones.", "labels": [], "entities": []}, {"text": "For the following experiments, the baseline classifier shall be the one using 1500 unigrams.", "labels": [], "entities": []}, {"text": "This number seems a reasonable trade-off between computational cost and accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9980010390281677}]}, {"text": "For every approach where it is applicable we carryout two types of experiments.", "labels": [], "entities": []}, {"text": "The first type we would like to call the standalone experiment, in which we use exactly the feature vector described for the approach.", "labels": [], "entities": []}, {"text": "The second experiment, the merged-feature-vector-experiment, is done by merging the feature set of our baseline classifier with that of the approach.", "labels": [], "entities": []}, {"text": "The second experiment allows us to evaluate if an approach can improve a simple but effective classifier.", "labels": [], "entities": []}, {"text": "This is important because some approaches may not be intended as full-blown classifiers, but rather as additional ideas to existing classifiers.", "labels": [], "entities": []}, {"text": "All experiments were carried out by 5-fold cross validation, except some of the experiments with machine-translated data, which is explained separately in the respective section.", "labels": [], "entities": []}, {"text": "In all tables the column denotes the corpus used for the crossvalidation and the row denotes the experiment's setting, i.e. feature set and classifier.", "labels": [], "entities": []}, {"text": "Most experiments are compared to the results of the baseline classifier and to the corpus baseline.", "labels": [], "entities": []}, {"text": "The latter is the percentage of the label that occurs more often in the corpus.", "labels": [], "entities": []}, {"text": "For both experiment settings, the standalone setting and the merged-feature-vector setting, we carried out three variants with different features.", "labels": [], "entities": []}, {"text": "In the first variant we used a counter for words, that are unique in the scope of the training data, in the second one a counter for words unique according to statistics about the BNC or the LCC and thirdly a feature vector with both of the latter features (see).", "labels": [], "entities": [{"text": "BNC", "start_pos": 180, "end_pos": 183, "type": "DATASET", "confidence": 0.928176760673523}, {"text": "LCC", "start_pos": 191, "end_pos": 194, "type": "DATASET", "confidence": 0.6692492365837097}]}], "tableCaptions": [{"text": " Table 1: Text Statistics about the Corpora.  c: characters; s: sentences; a: article", "labels": [], "entities": []}, {"text": " Table 2: Unique Words Feature Experiments.  UW: Unique Words; BUW: Base+Unique Words", "labels": [], "entities": [{"text": "BUW", "start_pos": 63, "end_pos": 66, "type": "METRIC", "confidence": 0.9949355721473694}]}, {"text": " Table 3: Experiments with Unigrams, Bigrams,  Trigrams and POS-Tags", "labels": [], "entities": []}, {"text": " Table 4: Long-Distance Bigrams Experiments;  (DB: Distance Bigrams)", "labels": [], "entities": []}, {"text": " Table 5: Machine-Translated Data Experiments.", "labels": [], "entities": []}]}