{"title": [{"text": "A Normalized-Cut Alignment Model for Mapping Hierarchical Semantic Structures onto Spoken Documents", "labels": [], "entities": [{"text": "Normalized-Cut Alignment", "start_pos": 2, "end_pos": 26, "type": "TASK", "confidence": 0.7277283370494843}, {"text": "Mapping Hierarchical Semantic Structures onto Spoken Documents", "start_pos": 37, "end_pos": 99, "type": "TASK", "confidence": 0.8091439179011753}]}], "abstractContent": [{"text": "We propose a normalized-cut model for the problem of aligning a known hierarchical browsing structure, e.g., electronic slides of lecture recordings, with the sequential transcripts of the corresponding spoken documents , with the aim to help index and access the latter.", "labels": [], "entities": []}, {"text": "This model optimizes a normalized-cut graph-partitioning criterion and considers local tree constraints at the same time.", "labels": [], "entities": []}, {"text": "The experimental results show the advantage of this model over Viterbi-like, sequential alignment, under typical speech recognition errors.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.7313649952411652}]}], "introductionContent": [{"text": "Learning semantic structures of written text has been studied in a number of specific tasks, which include, but not limited to, those finding semantic representations for individual sentences, and those constructing hierarchical structures among sentences or larger text blocks.", "labels": [], "entities": []}, {"text": "The inverse problem of the latter kind, e.g., aligning certain form of alreadyexisting semantic hierarchies with the corresponding text sequence, is not so much a prominent problem for written text as it is for spoken documents.", "labels": [], "entities": []}, {"text": "In this paper, we study a specific type of such a problem, in which a hierarchical browsing structure, i.e., electronic slides of oral presentations, have already existed, the goal being to impose such a structure onto the transcripts of the corresponding speech, with the aim to help index and access spoken documents as such.", "labels": [], "entities": []}, {"text": "Navigating audio documents is often inherently much more difficult than browsing text; an obvious solution, in relying on human beings' ability to read text, is to conduct a speech-to-text conversion through automatic speech recognition (ASR).", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 208, "end_pos": 242, "type": "TASK", "confidence": 0.729255790511767}]}, {"text": "Implicitly, solutions as such change the conventional speaking-for-hearing construals: now speech can be read through its transcripts, though, inmost cases, it was not intended for this purpose, which in turn raises anew set of problems.", "labels": [], "entities": []}, {"text": "The convenience and efficiency of reading transcripts () are first affected by errors produced in transcription channels for various reasons, though if the goal is only to browse salient excerpts, recognition errors on the extracts can be reduced by considering ASR confidence scores): trading off the expected salience of excerpts with their recognition-error rate could actually result in the improvement of excerpt quality in terms of the amount of important content being correctly presented).", "labels": [], "entities": [{"text": "ASR confidence scores", "start_pos": 262, "end_pos": 283, "type": "METRIC", "confidence": 0.8524143695831299}]}, {"text": "Even if transcription quality were not a problem, browsing transcripts is not straightforward.", "labels": [], "entities": []}, {"text": "When intended to be read, written documents are almost always presented as more than uninterrupted strings of text.", "labels": [], "entities": []}, {"text": "Consider that for many written documents, e.g., books, indicative structures such as section/subsection headings and tables-of-contents are standard constituents created manually to help readers.", "labels": [], "entities": []}, {"text": "Structures of this kind, even when existing, are rarely aligned with spoken documents completely.", "labels": [], "entities": []}, {"text": "This paper studies the problem of imposing a known hierarchical browsing structure, e.g., the electronic slides of lecture recordings, onto the sequential transcripts of the corresponding spoken document, with the aim to help index and hence access the latter more effectively.", "labels": [], "entities": []}, {"text": "Specifically, we propose a graph-partitioning approach that optimizes a normalized-cut criterion globally, in traversing the given hierarchical semantic structures.", "labels": [], "entities": []}, {"text": "The experimental results show the advantage of this model over Viterbi-like, sequential alignment, under typical speech recognition errors.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.7313649952411652}]}], "datasetContent": [{"text": "The metric used in our evaluation is straightforward-automatically acquired boundaries on transcripts for each slide bullet are compared against the corresponding gold-standard boundaries to calculate offsets measured in number of words.", "labels": [], "entities": []}, {"text": "The offset scores are averaged overall boundaries to evaluate model performance.", "labels": [], "entities": []}, {"text": "Though one may consider that different bullets maybe of different importance, in this paper we do not use any heuristics to judge this and we treat all bullets equally in our evaluation.", "labels": [], "entities": []}, {"text": "Note that topic segmentation research often uses metrics such as P k and WindowDiff ().", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.767717182636261}]}, {"text": "Our problem here, as an alignment problem, has an exact 1-to-1 correspondence between a gold and automatic boundary, in which we can directly measure the exact offset of each boundary.", "labels": [], "entities": []}, {"text": "shows that comparing these two polynomial-time models, G-CUT reduces the average offsets of SEG-ALN under both WERs.", "labels": [], "entities": [{"text": "G-CUT", "start_pos": 55, "end_pos": 60, "type": "METRIC", "confidence": 0.8259970545768738}, {"text": "SEG-ALN", "start_pos": 92, "end_pos": 99, "type": "METRIC", "confidence": 0.5829384326934814}, {"text": "WERs", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.6044559478759766}]}, {"text": "On the transcripts with 0.48 WER, the average word-offset score is reduced by approximately 18% from 20.38 to 16.77, while for the transcripts with WER at 0.43, the offset reduction is 12%, from 15.22 to 13.41.", "labels": [], "entities": []}, {"text": "Since both models use exactly the same input similarity matrices, the differences between their results confirm the advantage of the modeling principle behind the proposed approach.", "labels": [], "entities": []}, {"text": "Although the graphpartitioning model could be extended further, e.g., with the approach in (, our primary interest here is the principle modeling advantage of this normalized-cut framework.", "labels": [], "entities": []}, {"text": "The results in also suggest that the graphpartitioning model is more robust to speech recognition errors: when WERs increase from 0.43 to 0.48, the error of G-CUT increases by 25%, from 13.41 to 16.77, while that of SEQ-ALN increases by 44%, from 15.22 to 20.38.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.7055231034755707}, {"text": "WERs", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.8223844766616821}, {"text": "error", "start_pos": 148, "end_pos": 153, "type": "METRIC", "confidence": 0.9546022415161133}, {"text": "G-CUT", "start_pos": 157, "end_pos": 162, "type": "METRIC", "confidence": 0.9087997674942017}]}, {"text": "We due this to the fact that the graph-partitioning model considers multiple alignments between bullets, including their descendants, and the transcribed utterances, where mismatching between bullet and transcript words, e.g., that caused by recognition errors, is less likely to impact the graph-partitioning method, which bases its optimization criterion on multiple alignments, e.g., when calculating cut(.) and assoc(.) in equation (5) and (6).", "labels": [], "entities": []}, {"text": "Recall that the ASR Model 2 includes domain-specific Web data to train the language models, which were acquired by using bullet words to search the Web.", "labels": [], "entities": []}, {"text": "It is expected to increase the recognition accuracy on domain words, particularly those appearing on the slides.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9822564721107483}]}, {"text": "Therefore, Model 2 is likely to particularly increase the correct matching between bullets and transcript.", "labels": [], "entities": [{"text": "correct matching", "start_pos": 58, "end_pos": 74, "type": "METRIC", "confidence": 0.807458221912384}]}, {"text": "The results in also show the usefulness of better ASR modeling on the structure-imposing task here.", "labels": [], "entities": [{"text": "ASR modeling", "start_pos": 50, "end_pos": 62, "type": "TASK", "confidence": 0.9559783041477203}]}, {"text": "As discussed in the introduction section earlier, browsing automatic transcripts of long spoken documents, such as lectures, is affected by both speech recognition errors and lack of browsing structures.", "labels": [], "entities": [{"text": "browsing automatic transcripts of long spoken documents", "start_pos": 50, "end_pos": 105, "type": "TASK", "confidence": 0.6656178917203631}]}, {"text": "shows that the improvement in solving the first problem also helps the second.", "labels": [], "entities": []}, {"text": "Last, from a pragmatic viewpoint of system development, the graph-partitioning algorithm is simple to implement: the essence of equation- is to find the optimal normalized-cut score characterized by computing D and updating the formulae with it, which is not much more complicate to build than the baseline.", "labels": [], "entities": []}, {"text": "Also, the practical speed difference between these two types of models is not obvious on our dataset.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The average word offsets of automatic bound- aries from the gold-standard.", "labels": [], "entities": []}]}