{"title": [{"text": "Source Language Categorization for improving a Speech into Sign Lan- guage Translation System", "labels": [], "entities": [{"text": "Speech into Sign Lan- guage Translation", "start_pos": 47, "end_pos": 86, "type": "TASK", "confidence": 0.616022846528462}]}], "abstractContent": [{"text": "This paper describes a categorization module for improving the performance of a Spanish into Spanish Sign Language (LSE) translation system.", "labels": [], "entities": [{"text": "Spanish into Spanish Sign Language (LSE) translation", "start_pos": 80, "end_pos": 132, "type": "TASK", "confidence": 0.6579167379273309}]}, {"text": "This categorization module replaces Spanish words with associated tags.", "labels": [], "entities": []}, {"text": "When implementing this module , several alternatives for dealing with non-relevant words have been studied.", "labels": [], "entities": []}, {"text": "Non-relevant words are Spanish words not relevant in the translation process.", "labels": [], "entities": []}, {"text": "The catego-rization module has been incorporated into a phrase-based system and a Statistical Finite State Transducer (SFST).", "labels": [], "entities": [{"text": "Statistical Finite State Transducer (SFST", "start_pos": 82, "end_pos": 123, "type": "TASK", "confidence": 0.5499336769183477}]}, {"text": "The evaluation results reveal that the BLEU has increased from 69.11% to 78.79% for the phrase-based system and from 69.84% to 75.59% for the SFST.", "labels": [], "entities": [{"text": "the", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.9381090998649597}, {"text": "BLEU", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9350375533103943}, {"text": "SFST", "start_pos": 142, "end_pos": 146, "type": "DATASET", "confidence": 0.6014582514762878}]}], "introductionContent": [{"text": "In the world, there are around 70 million people with hearing deficiencies (information from World Federation of the Deaf http://www.wfdeaf.org/).", "labels": [], "entities": []}, {"text": "Deafness brings about significant communication problems: most deaf people are unable to use written languages, having serious problems when expressing themselves in these languages or understanding written texts.", "labels": [], "entities": []}, {"text": "They have problems with verb tenses, concordances of gender and number, etc., and they have difficulties when creating a mental image of abstract concepts.", "labels": [], "entities": []}, {"text": "This fact can cause deaf people to have problems when accessing information, education, job, social relationship, culture, etc.", "labels": [], "entities": []}, {"text": "According to information from INE (Statistic Spanish Institute), in Spain, there are 1,064,000 deaf people.", "labels": [], "entities": [{"text": "INE (Statistic Spanish Institute)", "start_pos": 30, "end_pos": 63, "type": "DATASET", "confidence": 0.6786576807498932}]}, {"text": "47% of deaf population do not have basic studies or are illiterate, and only between 1% and 3% have finished their studies (as opposed to 21% of Spanish hearing people).", "labels": [], "entities": []}, {"text": "Another example are the figures from the National Deaf Children's Society (NDCS), Cymru, revealing for the first time a shocking attainment gap between deaf and hearing pupils in Wales.", "labels": [], "entities": [{"text": "National Deaf Children's Society (NDCS)", "start_pos": 41, "end_pos": 80, "type": "DATASET", "confidence": 0.9464101642370224}]}, {"text": "In 2008, deaf pupils were 30% less likely than hearing pupils to gain five A*-C grades at General Certificate of Secondary Education (GCSE) level, while at key stage 3 only 42% of deaf pupils achieved the core subject indicators, compared to 71% of their hearing counterparts.", "labels": [], "entities": [{"text": "A*-C grades", "start_pos": 75, "end_pos": 86, "type": "METRIC", "confidence": 0.953366756439209}, {"text": "General Certificate of Secondary Education (GCSE) level", "start_pos": 90, "end_pos": 145, "type": "DATASET", "confidence": 0.5637236932913462}]}, {"text": "Another example is a study carried out in Ireland in 2006; of 330 respondents \"38% said they did not feel confident to read a newspaper and more than half were not fully confident in writing a letter or filling out a form\").", "labels": [], "entities": []}, {"text": "Deaf people use a sign language (their mother tongue) for communicating and there are not enough sign-language interpreters and communication systems.", "labels": [], "entities": []}, {"text": "In Spain, there is the Spanish Sign Language (Lengua de Signos Espa\u00f1ola LSE) that is the official sign language.", "labels": [], "entities": []}, {"text": "In the USA, there are 650,000 Deaf people (who use a sign language).", "labels": [], "entities": []}, {"text": "Although there are more people with hearing deficiencies, there are only 7,000 sign-language interpreters, i.e. a ratio of 93 deaf people to 1 interpreter.", "labels": [], "entities": []}, {"text": "In Finland we find the best ratio, 6 to 1, and in Slovakia the worst with 3,000 users to 1 interpreter (.", "labels": [], "entities": []}, {"text": "Spanish into LSE translation system.", "labels": [], "entities": [{"text": "LSE translation", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.6588410437107086}]}, {"text": "It is necessary to make a difference between \"deaf\" and \"Deaf\": the first one refers to nonhearing people, and the second one refers to hearing and non-hearing people who use a sign language to communicate between them, being part of the \"Deaf community\".", "labels": [], "entities": []}, {"text": "Each country has a different sign language, but there may even be different sign languages in different regions.", "labels": [], "entities": []}, {"text": "This paper describes a categorization module for improving the performance of a Speech into Sign Language Translation System.", "labels": [], "entities": [{"text": "Speech into Sign Language Translation", "start_pos": 80, "end_pos": 117, "type": "TASK", "confidence": 0.6495926201343536}]}, {"text": "This system helps Deaf people to communicate with government employees in a restricted domain: the renewal of Identity Documents and Driver's License.", "labels": [], "entities": []}, {"text": "This system has been designed to translate the government employee's explanations into LSE when government employees provide these face-to-face services.", "labels": [], "entities": [{"text": "LSE", "start_pos": 87, "end_pos": 90, "type": "METRIC", "confidence": 0.4385608732700348}]}, {"text": "The system is made up of a speech recognizer (for decoding the spoken utterance into a word sequence), a natural language translator (a phrase-based system for converting a word sequence into a sequence of signs belonging to the sign language), and a 3D avatar animation module (for playing back the signs)).", "labels": [], "entities": []}, {"text": "This paper proposes to include a fourth module named \"categorization\" between the speech recognition and language translation modules ().", "labels": [], "entities": [{"text": "speech recognition and language translation", "start_pos": 82, "end_pos": 125, "type": "TASK", "confidence": 0.7851760983467102}]}, {"text": "This categorization module replaces Spanish words with associated tags as will be shown further.", "labels": [], "entities": []}, {"text": "For the natural language translation module, two different statistical strategies have been analyzed: a phrase-based system (Moses) and a Statistical Finite State Transducer (SFST).", "labels": [], "entities": [{"text": "natural language translation", "start_pos": 8, "end_pos": 36, "type": "TASK", "confidence": 0.6458467443784078}]}, {"text": "The proposed categorization module has been incorporated into and evaluated with both translation strategies.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: section 2 describes the state of the art.", "labels": [], "entities": []}, {"text": "Section 3 describes the parallel corpus used in these experiments.", "labels": [], "entities": []}, {"text": "The main characteristics of the LSE are presented in section 4.", "labels": [], "entities": [{"text": "LSE", "start_pos": 32, "end_pos": 35, "type": "DATASET", "confidence": 0.639552116394043}]}, {"text": "Section 5 details the two main translation strategies considered.", "labels": [], "entities": [{"text": "translation", "start_pos": 31, "end_pos": 42, "type": "TASK", "confidence": 0.9733831286430359}]}, {"text": "The categorization module is described in section 6.", "labels": [], "entities": []}, {"text": "Section 7 includes the main experiments and the obtained results, and finally, sections 8 and 9 include the main conclusions and the future work. and it is has been used in this work.", "labels": [], "entities": []}, {"text": "Not only the data but also new practice  and new uses of traditional annotation tools) have been developed.", "labels": [], "entities": []}, {"text": "The work presented in this paper describes experiments with a relevant database Despite the small amount of data available for research into sign languages, the system presented in this paper demonstrates a very good performance compared to similar systems previously developed.", "labels": [], "entities": []}, {"text": "The presented results are also the best results for translating Spanish into LSE using the biggest database that includes these languages.", "labels": [], "entities": [{"text": "translating Spanish into LSE", "start_pos": 52, "end_pos": 80, "type": "TASK", "confidence": 0.8182255923748016}]}, {"text": "In Europe, the two main research projects involving sign languages are DICTA-SIGN ( and SIGN-SPEAK (, both financed by The European Commission within the Seventh Frame Program.", "labels": [], "entities": []}, {"text": "DICTA-SIGN (http://www.dictasign.eu/) aims to develop the technologies necessary to make Web 2.0 interactions in sign language possible: users sign to a webcam using a dictation style.", "labels": [], "entities": []}, {"text": "The computer recognizes the signed phrases, converts them into an internal representation of sign language, and then it has an animated avatar that signs them back to the users.", "labels": [], "entities": []}, {"text": "In SIGN-SPEAK (http://www.signspeak.eu/), the overall goal is to develop anew vision-based technology for recognizing and translating continuous sign language into text.", "labels": [], "entities": [{"text": "recognizing and translating continuous sign language into text", "start_pos": 106, "end_pos": 168, "type": "TASK", "confidence": 0.7264753431081772}]}], "datasetContent": [{"text": "For the experiments, the corpus (described in section 3) was divided randomly into three sets: training (75%), development (12.5%) and test (12.5%).", "labels": [], "entities": []}, {"text": "Results are compared with a baseline.", "labels": [], "entities": []}, {"text": "This baseline consists of training models with original source and target corpus without any type of factorization, i.e, sentences contain words and signs from the original database.", "labels": [], "entities": []}, {"text": "For example: this sentence \"debes pagar las tasas en la caja\" (you must pay the taxes in the cash desk) is translated into \"VENTANILLA ESPEC\u00cdFICO CAJA TU PAGAR\" (WINDOW SPECIFIC CASH-DESK YOU PAY).", "labels": [], "entities": [{"text": "VENTANILLA ESPEC\u00cdFICO CAJA TU PAGAR\" (WINDOW SPECIFIC CASH-DESK YOU PAY", "start_pos": 124, "end_pos": 195, "type": "METRIC", "confidence": 0.7904499769210815}]}, {"text": "For evaluating the performance of the translation systems, the BLEU (BiLingual Evaluation Understudy) metric () has been used.", "labels": [], "entities": [{"text": "BLEU (BiLingual Evaluation Understudy) metric", "start_pos": 63, "end_pos": 108, "type": "METRIC", "confidence": 0.8271124362945557}]}, {"text": "BLEU is one of the most well-known metric for evaluating automatic translation systems because this metric presents a good correlation with human evaluations.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9867104887962341}, {"text": "evaluating automatic translation", "start_pos": 46, "end_pos": 78, "type": "TASK", "confidence": 0.5479736824830373}]}, {"text": "This metric has been also adopted to evaluate speech into sign language translation systems (.", "labels": [], "entities": [{"text": "sign language translation", "start_pos": 58, "end_pos": 83, "type": "TASK", "confidence": 0.7348102331161499}]}, {"text": "In order to analyze the significance of the differences between several systems, for every BLEU result, the confidence interval (at 95%) is also presented.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.9959595799446106}, {"text": "confidence interval", "start_pos": 108, "end_pos": 127, "type": "METRIC", "confidence": 0.9271133542060852}]}, {"text": "This interval is calculated using the following formula: n is the number of signs used in evaluation, in this case n=2,906.", "labels": [], "entities": []}, {"text": "An improvement between two systems is statistically significant when there is no overlap between the confidence intervals of both systems.", "labels": [], "entities": []}, {"text": "Related to the speech recognizer, it is important to comment that the Word Error Rate (WER) obtained in these experiments has been 4.7%.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 15, "end_pos": 32, "type": "TASK", "confidence": 0.6941542625427246}, {"text": "Word Error Rate (WER)", "start_pos": 70, "end_pos": 91, "type": "METRIC", "confidence": 0.9256508151690165}]}, {"text": "compares the baseline system and the system with the categorization module for translating the references (Reference) and the speech recognizer outputs (ASR output) using the phrasebased translation system..", "labels": [], "entities": []}, {"text": "Evaluation results for the phrase-based translation system.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 27, "end_pos": 51, "type": "TASK", "confidence": 0.7932614684104919}]}, {"text": "compares the baseline system and the system with the categorization module for translating the references (Reference) and the speech recognizer outputs (ASR output) using the SFSTbased translation system.", "labels": [], "entities": [{"text": "SFSTbased translation", "start_pos": 175, "end_pos": 196, "type": "TASK", "confidence": 0.6998277604579926}]}, {"text": "Comparing the three alternatives for dealing with the non-relevant words, it is shown that adding tags to the words and removing \"non-relevant\" words are complementary actions that allow reaching the best results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Main statistics of the corpus", "labels": [], "entities": []}, {"text": " Table 2. Evaluation results for the phrase-based  translation system.", "labels": [], "entities": [{"text": "phrase-based  translation", "start_pos": 37, "end_pos": 62, "type": "TASK", "confidence": 0.8014151453971863}]}, {"text": " Table 3. Evaluation results for the SFST-based  translation system.", "labels": [], "entities": [{"text": "SFST-based  translation", "start_pos": 37, "end_pos": 60, "type": "TASK", "confidence": 0.958320677280426}]}]}