{"title": [{"text": "Unsupervised Entailment Detection between Dependency Graph Fragments", "labels": [], "entities": [{"text": "Unsupervised Entailment Detection between Dependency Graph Fragments", "start_pos": 0, "end_pos": 68, "type": "TASK", "confidence": 0.712237719978605}]}], "abstractContent": [{"text": "Entailment detection systems are generally designed to work either on single words, relations or full sentences.", "labels": [], "entities": [{"text": "Entailment detection", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9283090233802795}]}, {"text": "We propose anew task-detecting entailment between dependency graph fragments of any type-which relaxes these restrictions and leads to much wider entailment discovery.", "labels": [], "entities": [{"text": "entailment discovery", "start_pos": 146, "end_pos": 166, "type": "TASK", "confidence": 0.7201174348592758}]}, {"text": "An unsupervised framework is described that uses intrinsic similarity , multi-level extrinsic similarity and the detection of negation and hedged language to assign a confidence score to entailment relations between two fragments.", "labels": [], "entities": []}, {"text": "The final system achieves 84.1% average precision on a data set of entailment examples from the biomedical domain.", "labels": [], "entities": [{"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9970622658729553}]}], "introductionContent": [{"text": "Understanding that two different texts are semantically similar has benefits for nearly all NLP tasks, including IR, IE, QA and Summarisation.", "labels": [], "entities": [{"text": "IR", "start_pos": 113, "end_pos": 115, "type": "TASK", "confidence": 0.6391482949256897}, {"text": "Summarisation", "start_pos": 128, "end_pos": 141, "type": "TASK", "confidence": 0.9376270771026611}]}, {"text": "Similarity detection is usually performed either on single words (synonymy) or full sentences and paragraphs (paraphrasing).", "labels": [], "entities": [{"text": "Similarity detection", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9747382700443268}]}, {"text": "A symmetric similarity relation implies that both elements can be interchanged (synonymy and paraphrasing), while directional similarity suggests that one fragment can be substituted for the other but not the opposite (hyponymy and entailment).", "labels": [], "entities": []}, {"text": "All of these language phenomena can be expressed using a single entailment relation.", "labels": [], "entities": []}, {"text": "For paraphrases and synonyms the relation holds in both directions (observe \u2194 notice), whereas entailment and hyponymy are modelled as a unidirectional relation (overexpress \u2192 express).", "labels": [], "entities": [{"text": "paraphrases and synonyms", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.7684481938680013}]}, {"text": "Such relations, however, can be defined between text fragments of any size and shape, ranging from a single word to a complete text segment.", "labels": [], "entities": []}, {"text": "For example (argues against \u2192 does not support; the protein has been implicated \u2194 the protein has been shown to be involved).", "labels": [], "entities": []}, {"text": "We propose anew task -detecting entailment relations between any kinds of text fragments.", "labels": [], "entities": []}, {"text": "A unified approach is not expected to perform better when compared to systems optimised only fora specific task (e.g. recognising entailment between sentences), but constructing a common theory to coverall text fragments has important benefits.", "labels": [], "entities": []}, {"text": "A broader approach will allow for entailment discovery among a much wider range of fragment types for which no specialised systems exist.", "labels": [], "entities": [{"text": "entailment discovery", "start_pos": 34, "end_pos": 54, "type": "TASK", "confidence": 0.6466352939605713}]}, {"text": "In addition, entailment relations can be found between different types of fragments (e.g. a predicate entailing an adjunct).", "labels": [], "entities": []}, {"text": "Finally, a common system is much easier to develop and integrate with potential applications compared to having a separate system for each type of fragment.", "labels": [], "entities": []}, {"text": "In this paper we present a unified framework that can be used to detect entailment relations between fragments of various types and sizes.", "labels": [], "entities": []}, {"text": "The system is designed to work with anything that can be represented as a dependency graph, including single words, constituents of various sizes, text adjuncts, predicates, relations and full sentences.", "labels": [], "entities": []}, {"text": "The approach is completely unsupervised and requires only a large plain text corpus to gather information for calculating distributional similarity.", "labels": [], "entities": []}, {"text": "This makes it ideal for the biomedical domain where the availability of annotated training data is limited.", "labels": [], "entities": []}, {"text": "We apply these methods by using a background corpus of biomedical papers and evaluate on a manually constructed dataset of entailing fragment pairs, extracted from biomedical texts.", "labels": [], "entities": []}], "datasetContent": [{"text": "A \"pilot\" dataset was created to evaluate different entailment detection methods between fragments 3 . In order to look for valid entailment examples, 1000 biomedical papers from the BioMed Central full-text corpus were randomly chosen and analysed.", "labels": [], "entities": [{"text": "BioMed Central full-text corpus", "start_pos": 183, "end_pos": 214, "type": "DATASET", "confidence": 0.9457666277885437}]}, {"text": "We hypothesised that two very similar sentences originating from the same paper are likely to be more and less general versions of the same proposition.", "labels": [], "entities": []}, {"text": "First, the similarities between all sentences in a single paper were calculated using a bag-of-words approach.", "labels": [], "entities": []}, {"text": "Then, ten of the most similar but nonidentical sentence pairs from each paper were presented for manual review and 150 fragment pairs were created based on these sentences, 100 of which were selected for the final set.", "labels": [], "entities": []}, {"text": "When applied to sentence-level entailment extraction, similar methods can suffer from high lexical overlap as sentences need to contain many matching words to pass the initial filter.", "labels": [], "entities": [{"text": "sentence-level entailment extraction", "start_pos": 16, "end_pos": 52, "type": "TASK", "confidence": 0.7765321234862009}]}, {"text": "However, for the extraction of entailing fragments most of the matching words are discarded and only the non-identical fragments are stored, greatly reducing the overlap problem.", "labels": [], "entities": []}, {"text": "Experiments in Section 5 demonstrate that a simple bag-of-words approach performs rather poorly on the task, confirming that the extraction method produces a diverse selection of fragments.", "labels": [], "entities": []}, {"text": "Two annotators assigned a relation type to candidate pairs based on how well one fragment can be substituted for the other in text while preserving meaning (A \u2194 B, A \u2192 B, A \u2190 B or A = B).", "labels": [], "entities": []}, {"text": "Cohen's Kappa between the annotators was 0.88, indicating very high agreement.", "labels": [], "entities": [{"text": "Kappa", "start_pos": 8, "end_pos": 13, "type": "METRIC", "confidence": 0.5077263712882996}, {"text": "agreement", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.9919907450675964}]}, {"text": "Instances with disagreement were then reviewed and replaced for the final dataset.", "labels": [], "entities": []}, {"text": "Each fragment pair has two binary entailment decisions (one in either direction) and the set is evenly balanced, containing 100 entailment and 100 nonentailment relations.", "labels": [], "entities": []}, {"text": "An example sentence with the first fragment is also included.", "labels": [], "entities": []}, {"text": "Fragment sizes range from 1 to 20 words, with the average of 2.86 words.", "labels": [], "entities": []}, {"text": "The system assigns a score to each entailment relation, with higher values indicating higher confidence in entailment.", "labels": [], "entities": []}, {"text": "All the relations are ranked based on their score, and average precision (AP) is used to evaluate the performance: where R is the number of correct entailment relations, N is the number of possible relations in the test set, E(i) is 1 if the i-th relation is entailment in the gold standard and 0 otherwise, and CorrectU pT o(i) is the number of correctly returned entailment relations up to rank i.", "labels": [], "entities": [{"text": "average precision (AP)", "start_pos": 55, "end_pos": 77, "type": "METRIC", "confidence": 0.8198751211166382}, {"text": "CorrectU pT o(i)", "start_pos": 312, "end_pos": 328, "type": "METRIC", "confidence": 0.9377810557683309}]}, {"text": "Average precision assigns a higher score to systems which rank correct entailment examples higher in the list.", "labels": [], "entities": [{"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9939086437225342}]}, {"text": "As a secondary measure we also report the BreakEven Point (BEP) which is defined as precision at the rank where precision is equal to recall.", "labels": [], "entities": [{"text": "BreakEven Point (BEP)", "start_pos": 42, "end_pos": 63, "type": "METRIC", "confidence": 0.9719187617301941}, {"text": "precision", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.9994475245475769}, {"text": "precision", "start_pos": 112, "end_pos": 121, "type": "METRIC", "confidence": 0.9988264441490173}, {"text": "recall", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.9981474876403809}]}, {"text": "Using the previous annotation, this can also be calculated as precision at rank R: BEP = CorrectU pT o(R) R BEP is a much more strict measure, treating the task as binary classification and ignoring changes to the ranks within the classes.", "labels": [], "entities": [{"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9989125728607178}, {"text": "BEP", "start_pos": 83, "end_pos": 86, "type": "METRIC", "confidence": 0.9979183077812195}, {"text": "CorrectU pT o(R) R", "start_pos": 89, "end_pos": 107, "type": "METRIC", "confidence": 0.922406724521092}, {"text": "BEP", "start_pos": 108, "end_pos": 111, "type": "METRIC", "confidence": 0.5070652961730957}]}], "tableCaptions": [{"text": " Table 2: Results for the system described in Section 3.  Components are added incrementally.", "labels": [], "entities": [{"text": "Components", "start_pos": 58, "end_pos": 68, "type": "METRIC", "confidence": 0.9605168700218201}]}, {"text": " Table 3: Results of tuning the weights for intrinsic and  distributional similarity.", "labels": [], "entities": []}]}