{"title": [{"text": "An Evaluation and Possible Improvement Path for Current SMT Behavior on Ambiguous Nouns", "labels": [], "entities": [{"text": "SMT Behavior", "start_pos": 56, "end_pos": 68, "type": "TASK", "confidence": 0.9214748442173004}]}], "abstractContent": [{"text": "Mistranslation of an ambiguous word can have a large impact on the understandability of a given sentence.", "labels": [], "entities": [{"text": "Mistranslation of an ambiguous word", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8019532680511474}]}, {"text": "In this article, we describe a thorough evaluation of the translation quality of ambiguous nouns in three different setups.", "labels": [], "entities": []}, {"text": "We compared two statistical Machine Translation systems and one dedicated Word Sense Disambiguation (WSD) system.", "labels": [], "entities": [{"text": "statistical Machine Translation", "start_pos": 16, "end_pos": 47, "type": "TASK", "confidence": 0.6083849966526031}, {"text": "Word Sense Disambiguation (WSD)", "start_pos": 74, "end_pos": 105, "type": "TASK", "confidence": 0.7288182973861694}]}, {"text": "Our WSD system incorporates multilingual information and is independent from external lexical resources.", "labels": [], "entities": []}, {"text": "Word senses are derived automatically from word alignments on a parallel corpus.", "labels": [], "entities": []}, {"text": "We show that the two WSD classifiers that were built for these experiments (English-French and English-Dutch) outperform the SMT system that was trained on the same corpus.", "labels": [], "entities": [{"text": "WSD classifiers", "start_pos": 21, "end_pos": 36, "type": "TASK", "confidence": 0.8404560089111328}, {"text": "SMT", "start_pos": 125, "end_pos": 128, "type": "TASK", "confidence": 0.9796556234359741}]}, {"text": "This opens perspectives for the integration of our multilingual WSD module in a statistical Machine Translation framework, in order to improve the automated translation of ambiguous words, and by consequence make the translation output more understandable.", "labels": [], "entities": [{"text": "statistical Machine Translation", "start_pos": 80, "end_pos": 111, "type": "TASK", "confidence": 0.6238937675952911}, {"text": "automated translation of ambiguous words", "start_pos": 147, "end_pos": 187, "type": "TASK", "confidence": 0.7248520851135254}]}], "introductionContent": [{"text": "Word Sense Disambiguation (WSD) is the NLP task that consists in assigning a correct sense to an ambiguous word in a given context.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.791299358010292}]}, {"text": "Traditionally, WSD relies on a predefined monolingual senseinventory such as WordNet and WSD modules are trained on corpora, which are manually tagged with senses from these inventories.", "labels": [], "entities": [{"text": "WSD", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.9301712512969971}, {"text": "WordNet", "start_pos": 77, "end_pos": 84, "type": "DATASET", "confidence": 0.9647318720817566}]}, {"text": "A number of issues arise with these monolingual supervised approaches to WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.9743841886520386}]}, {"text": "First of all, there is alack of large sense-inventories and sense-tagged corpora for languages other than English.", "labels": [], "entities": []}, {"text": "Furthermore, sense inventories such as WordNet contain very finegrained sense distinctions that make the sense disambiguation task very challenging (even for human annotators), whereas very detailed sense distinctions are often irrelevant for practical applications.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 39, "end_pos": 46, "type": "DATASET", "confidence": 0.9664203524589539}, {"text": "sense disambiguation", "start_pos": 105, "end_pos": 125, "type": "TASK", "confidence": 0.7446737587451935}]}, {"text": "In addition to this, there is a growing feeling in the community that WSD should be used and evaluated in real application such as Machine Translation (MT) or Information Retrieval (IR)).", "labels": [], "entities": [{"text": "WSD", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.8317703604698181}, {"text": "Machine Translation (MT)", "start_pos": 131, "end_pos": 155, "type": "TASK", "confidence": 0.8459431767463684}, {"text": "Information Retrieval (IR))", "start_pos": 159, "end_pos": 186, "type": "TASK", "confidence": 0.7734014987945557}]}, {"text": "An important line of research consists in the development of dedicated WSD modules for MT.", "labels": [], "entities": [{"text": "WSD", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.9118277430534363}, {"text": "MT", "start_pos": 87, "end_pos": 89, "type": "TASK", "confidence": 0.9881904125213623}]}, {"text": "Instead of assigning a sense label from a monolingual sense-inventory to the ambiguous words, the WSD system has to predict a correct translation for the ambiguous word in a given context.", "labels": [], "entities": [{"text": "WSD", "start_pos": 98, "end_pos": 101, "type": "TASK", "confidence": 0.8246092200279236}]}, {"text": "In), the problem was defined as a word translation task.", "labels": [], "entities": [{"text": "word translation task", "start_pos": 34, "end_pos": 55, "type": "TASK", "confidence": 0.8033552765846252}]}, {"text": "The translation choices of ambiguous words are gathered from a parallel corpus by means of word alignment.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 91, "end_pos": 105, "type": "TASK", "confidence": 0.6855411380529404}]}, {"text": "The authors reported improvements on two simplified translation tasks: word translation and blank filling.", "labels": [], "entities": [{"text": "word translation", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.8142145872116089}, {"text": "blank filling", "start_pos": 92, "end_pos": 105, "type": "TASK", "confidence": 0.7679432034492493}]}, {"text": "The evaluation was done on an English-French parallel corpus but is confronted with the important limitation of having only one valid translation (the aligned translation in the parallel corpus) as a gold standard translation.", "labels": [], "entities": []}, {"text": "tried to improve an SMT system by adding additional translations to the phrase table, but were confronted with tuning problems of this dedicated WSD feature.", "labels": [], "entities": [{"text": "SMT", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.996478259563446}]}, {"text": "used an inductive logic programming-based WSD system which was tested on seven ambiguous verbs in English-Portuguese translation.", "labels": [], "entities": []}, {"text": "The latter systems already present promising results for the use of WSD in MT, but really significant improvements in terms of general machine translation qual-52 ity were for the first time obtained by and.", "labels": [], "entities": [{"text": "WSD", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.8775245547294617}, {"text": "MT", "start_pos": 75, "end_pos": 77, "type": "TASK", "confidence": 0.9611415266990662}]}, {"text": "Both papers describe the integration of a dedicated WSD module in a Chinese-English statistical machine translation framework and report statistically significant improvements in terms of standard MT evaluation metrics.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 84, "end_pos": 115, "type": "TASK", "confidence": 0.661824107170105}, {"text": "MT evaluation", "start_pos": 197, "end_pos": 210, "type": "TASK", "confidence": 0.8721476197242737}]}, {"text": "take a completely different approach to perform some sort of implicit Word Sense Disambiguation in MT.", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 70, "end_pos": 95, "type": "TASK", "confidence": 0.5889784793059031}, {"text": "MT", "start_pos": 99, "end_pos": 101, "type": "TASK", "confidence": 0.8103319406509399}]}, {"text": "They introduce context-information features that exploit source similarity, in addition to target similarity that is modeled by the language model, in an SMT framework.", "labels": [], "entities": [{"text": "SMT", "start_pos": 154, "end_pos": 157, "type": "TASK", "confidence": 0.9807413220405579}]}, {"text": "For the estimation of these features that are very similar to the typical WSD local context features (left and right context words, Part-of-Speech of the focus phrase and context words), they use a memory-based classification framework.", "labels": [], "entities": [{"text": "WSD local context", "start_pos": 74, "end_pos": 91, "type": "TASK", "confidence": 0.8213284015655518}]}, {"text": "The work we present in this paper is different from previous research in two aspects.", "labels": [], "entities": []}, {"text": "Firstly, we evaluate the performance of two state-of-the-art SMT systems and a dedicated WSD system on the translation of ambiguous words.", "labels": [], "entities": [{"text": "SMT", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.988131046295166}, {"text": "translation of ambiguous words", "start_pos": 107, "end_pos": 137, "type": "TASK", "confidence": 0.8932201862335205}]}, {"text": "The comparison is done against a manually constructed gold-standard for two language pairs, viz.", "labels": [], "entities": []}, {"text": "Although it is crucial to measure the general translation quality after integrating a dedicated WSD module in the SMT system, we think it is equally interesting to conduct a dedicated evaluation of the translation quality on ambiguous nouns.", "labels": [], "entities": [{"text": "SMT", "start_pos": 114, "end_pos": 117, "type": "TASK", "confidence": 0.9732922315597534}]}, {"text": "Standard SMT evaluation metrics such as BLEU) or edit-distance metrics (e.g. Word Error Rate) measure the global overlap of the translation with a reference, and are thus not very sensitive to WSD errors.", "labels": [], "entities": [{"text": "SMT evaluation", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.8936037123203278}, {"text": "BLEU", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9942349791526794}, {"text": "Word Error Rate", "start_pos": 77, "end_pos": 92, "type": "METRIC", "confidence": 0.4869413375854492}, {"text": "WSD", "start_pos": 193, "end_pos": 196, "type": "TASK", "confidence": 0.969035267829895}]}, {"text": "The mistranslation of an ambiguous word might be a subtle change compared to the reference sentence, but it often drastically affects the global understanding of the sentence.", "labels": [], "entities": []}, {"text": "Secondly, we explore the potential benefits of areal multilingual approach to WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 78, "end_pos": 81, "type": "TASK", "confidence": 0.9715037941932678}]}, {"text": "The idea to use translations from parallel corpora to distinguish between word senses is based on the hypothesis that different meanings of a polysemous word are often lexicalized across languages).", "labels": [], "entities": []}, {"text": "Many WSD studies have incorporated this cross-lingual evidence idea and have successfully applied bilingual WSD classifiers () or systems that use a combination of existing WordNets with multilingual evidence).", "labels": [], "entities": [{"text": "WSD", "start_pos": 5, "end_pos": 8, "type": "TASK", "confidence": 0.933764636516571}, {"text": "WSD classifiers", "start_pos": 108, "end_pos": 123, "type": "TASK", "confidence": 0.8896900713443756}]}, {"text": "Our WSD system is different in the sense that it is independent from a predefined sense-inventory (it only uses the parallel corpus at hand) and that it is truly multilingual as it incorporates information from four other languages (French, Dutch, Spanish, Italian and German depending on the target language of the classifier).", "labels": [], "entities": []}, {"text": "Although our classifiers are still very preliminary in terms of the feature set and parameters that are used, we obtain interesting results on our test sample of ambiguous nouns.", "labels": [], "entities": []}, {"text": "We therefore believe our system can have areal added value for SMT, as it can easily be trained for different language pairs on exactly the same corpus which is used to train the SMT system, which should make the integration a lot easier.", "labels": [], "entities": [{"text": "SMT", "start_pos": 63, "end_pos": 66, "type": "TASK", "confidence": 0.9935217499732971}, {"text": "SMT", "start_pos": 179, "end_pos": 182, "type": "TASK", "confidence": 0.9746565818786621}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces the two machine translation systems we evaluated, while section 3 describes the feature construction and learning algorithm of our multilingual WSD system.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7088833898305893}, {"text": "feature construction", "start_pos": 101, "end_pos": 121, "type": "TASK", "confidence": 0.733174741268158}]}, {"text": "Section 4 gives an overview of the experimental setup and results.", "labels": [], "entities": []}, {"text": "We finally draw conclusions and present some future research in Section 5.", "labels": [], "entities": [{"text": "Section 5", "start_pos": 64, "end_pos": 73, "type": "DATASET", "confidence": 0.8757281601428986}]}], "datasetContent": [{"text": "To evaluate the two machine translation systems as well as the ParaSense system on their performance on the lexical sample of twenty ambiguous words, we used the sense inventory and test set of the SemEval Cross-Lingual Word Sense Disambiguation task.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 20, "end_pos": 39, "type": "TASK", "confidence": 0.7100235372781754}, {"text": "SemEval Cross-Lingual Word Sense Disambiguation task", "start_pos": 198, "end_pos": 250, "type": "TASK", "confidence": 0.8146104514598846}]}, {"text": "The sense inventory was built upon the basis of the Europarl corpus: all retrieved translations of a polysemous word were manually grouped into clusters, which constitute different senses of that given word.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 52, "end_pos": 67, "type": "DATASET", "confidence": 0.9881672263145447}]}, {"text": "The test instances were selected from the JRC-ACQUIS Multilingual Parallel Corpus 2 and BNC 3 . There were in total 50 test instances for each of the twenty ambiguous words in the sample.", "labels": [], "entities": [{"text": "JRC-ACQUIS Multilingual Parallel Corpus 2", "start_pos": 42, "end_pos": 83, "type": "DATASET", "confidence": 0.9028718709945679}, {"text": "BNC", "start_pos": 88, "end_pos": 91, "type": "DATASET", "confidence": 0.7607986927032471}]}, {"text": "To label the test data, native speakers assigned three valid translations from the predefined clusters of Europarl translations to each test instance.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 106, "end_pos": 114, "type": "DATASET", "confidence": 0.9631589651107788}]}, {"text": "A more detailed description of the construction of the data set can be found in ().", "labels": [], "entities": []}, {"text": "As evaluation metric, we used a straightforward accuracy measure that divides the number of correct answers by the total amount of test instances.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9983764886856079}]}, {"text": "As a baseline, we selected the most frequent lemmatized translation that resulted from the automated word alignment (GIZA++).", "labels": [], "entities": [{"text": "word alignment", "start_pos": 101, "end_pos": 115, "type": "TASK", "confidence": 0.6543265134096146}]}, {"text": "The output of the ParaSense WSD module consists of a lemmatized translation of the ambiguous focus word in the target language.", "labels": [], "entities": []}, {"text": "The output of the two statistical machine translation systems, however, is a translation of the full English input sentence.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 22, "end_pos": 53, "type": "TASK", "confidence": 0.6131177941958109}]}, {"text": "Therefore we manually selected the translation of the ambiguous focus word from the full translation, and made sure the translation was put in its base form (masculine singular form for nouns and adjectives, infinitive form for verbs).", "labels": [], "entities": []}, {"text": "lists the accuracy figures for the baseline, two flavors of the ParaSense system (with and without correction of the word alignment output), Moses and Google for English-French and English-Dutch.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9996157884597778}]}, {"text": "A first conclusion is that all systems beat the most frequent sense baseline.", "labels": [], "entities": []}, {"text": "As expected, the Google system (where there was no limitation on the training data) achieves the best results, but for French the considerable difference in training size only leads to modest performance gains compared to the ParaSense System.", "labels": [], "entities": []}, {"text": "Another interesting observation is that the ParaSense system that uses manually verified translation labels hardly beats the system that uses automatically generated class labels.", "labels": [], "entities": []}, {"text": "This is promising as it makes the manual interventions on the data superfluous and leads to a fully automatic system development process.", "labels": [], "entities": []}, {"text": "illustrates the accuracy figures for French for all three systems (for the ParaSense system we used the flavor that incorporates the non-validated translation labels) on all individual test words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9994978904724121}]}, {"text": "The three curves follow a similar pattern, except for some words where Moses (mood, scene, side) or both Moses and ParaSense (figure) perform worse.", "labels": [], "entities": []}, {"text": "As the curves show, some words (e.g. coach, figure, 56   match, range) are particularly hard to disambiguate, while others obtain very high scores (e.g. letter, mission, soil).", "labels": [], "entities": [{"text": "56   match", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.6821975111961365}]}, {"text": "The almost perfect scores for the latter can be explained by the fact that these words all have a very generic translation in French (respectively lettre, mission, sol) that can be used for all senses of the word, although there might be more suited translations for each of the senses depending on the context.", "labels": [], "entities": []}, {"text": "As the manual annotators could pick three good translations for each test instance, the most generic translation often figures between the gold standard translations.", "labels": [], "entities": []}, {"text": "The low scores for some other words can often be explained through the relationship with the number of training instances (corresponding to the frequency, both for coach and match there are very few examples in the corpus, while figure and range 57 are very ambiguous (respectively 167 and 145 translations to choose from).", "labels": [], "entities": []}, {"text": "The main novelty of our ParaSense system lies in the application of a multilingual approach to perform WSD, as opposed to the more classical approach that only uses monolingual local context features.", "labels": [], "entities": [{"text": "WSD", "start_pos": 103, "end_pos": 106, "type": "TASK", "confidence": 0.9155737161636353}]}, {"text": "Consequently we also ran a set of additional experiments to examine the contribution of the different translation features to the WSD performance.", "labels": [], "entities": [{"text": "WSD", "start_pos": 130, "end_pos": 133, "type": "TASK", "confidence": 0.9288879632949829}]}, {"text": "shows the accuracy figures for French and Dutch fora varying number of translation features including the other four languages: Italian, Spanish, French and Dutch for the French classifier or French for the Dutch classifier.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9997747540473938}]}, {"text": "The scores clearly confirm the validity of our hypothesis: the classifiers using translation features are constantly better than the one that merely uses English local context features.", "labels": [], "entities": []}, {"text": "For French, the other two romance languages seem to contribute most: the classifier that uses Italian and Spanish bag-of-words features achieves the best performance (75.50%), whereas the classifier that incorporates German and Dutch translations obtains the worst scores (71.90%).", "labels": [], "entities": []}, {"text": "For Dutch, the interpretation of the scores is less straightforward: the Italian-German combination achieves the best result (69%), but the difference with the other classifiers that use two romance languages (Italian-Spanish: 67.70% and Italian-French: 67.20%) is less salient than for French.", "labels": [], "entities": []}, {"text": "In order to draw final conclusions on the contribution of the different languages, we probably first need to optimize our feature base and classification parameters.", "labels": [], "entities": []}, {"text": "For the current experiments, we use very sparse bag-of-words features that can be optimized in different ways (e.g. feature selection, reduction of the bag-of-words features by applying semantic analysis such as Singular Value Decomposition, etc.).", "labels": [], "entities": [{"text": "feature selection", "start_pos": 116, "end_pos": 133, "type": "TASK", "confidence": 0.6988460272550583}]}], "tableCaptions": [{"text": " Table 1: Statistics resulting from the Moses training  phase", "labels": [], "entities": []}, {"text": " Table 2: Accuracy figures averaged over all twenty test  words", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9995810389518738}]}, {"text": " Table 3: Number of instances and classes for all twenty  test words in French", "labels": [], "entities": []}, {"text": " Table 4: Accuracy figures for French and Dutch for a  varying number of translation features including the other  four languages viz. Italian (It), Spanish (Es), German  (De) and French (Fr) or Dutch (Nl)", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9989640712738037}]}]}