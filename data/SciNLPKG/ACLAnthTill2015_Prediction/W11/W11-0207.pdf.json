{"title": [{"text": "Medical Entity Recognition: A Comparison of Semantic and Statistical Methods", "labels": [], "entities": [{"text": "Medical Entity Recognition", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.7308026850223541}]}], "abstractContent": [{"text": "Medical Entity Recognition is a crucial step towards efficient medical texts analysis.", "labels": [], "entities": [{"text": "Medical Entity Recognition", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6341691513856252}, {"text": "medical texts analysis", "start_pos": 63, "end_pos": 85, "type": "TASK", "confidence": 0.6544865071773529}]}, {"text": "In this paper we present and compare three methods based on domain-knowledge and machine-learning techniques.", "labels": [], "entities": []}, {"text": "We study two research directions through these approaches: (i) a first direction where noun phrases are extracted in a first step with a chunker before the final classification step and (ii) a second direction where machine learning techniques are used to identify simultaneously entities boundaries and categories.", "labels": [], "entities": []}, {"text": "Each of the presented approaches is tested on a standard corpus of clinical texts.", "labels": [], "entities": []}, {"text": "The obtained results show that the hybrid approach based on both machine learning and domain knowledge obtains the best performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Medical Entity Recognition (MER) consists in two main steps: (i) detection and delimitation of phrasal information referring to medical entities in textual corpora (e.g. pyogenic liver abscess, infection of biliary system) and (ii) identification of the semantic category of located entities (e.g. Medical Problem, Test).", "labels": [], "entities": [{"text": "Medical Entity Recognition (MER)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7803478240966797}]}, {"text": "Example 1 shows the result of MER on a sentence where the located entity and its category are marked with treatment and problem tags.", "labels": [], "entities": [{"text": "MER", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.9095937013626099}]}, {"text": "(1) <treatment> Adrenal-sparing surgery </treatment> is safe and effective , and may become the treatment of choice in patients with <problem> hereditary phaeochromocytoma </problem>.", "labels": [], "entities": []}, {"text": "This task is very important for many applications such as Question-Answering where MER is used in the question analysis step (to determine the expected answers' type, the question focus, etc.) and in the offline text tagging or annotation.", "labels": [], "entities": [{"text": "MER", "start_pos": 83, "end_pos": 86, "type": "METRIC", "confidence": 0.8267304301261902}, {"text": "question analysis", "start_pos": 102, "end_pos": 119, "type": "TASK", "confidence": 0.7454867362976074}, {"text": "offline text tagging", "start_pos": 204, "end_pos": 224, "type": "TASK", "confidence": 0.6540656189123789}]}, {"text": "One of the most important obstacles to identifying medical entities is the high terminological variation in the medical domain (e.g. Diabetes mellitus type 1, Type 1 diabetes, IDDM, or juvenile diabetes all express the same concept).", "labels": [], "entities": []}, {"text": "Other aspects also have incidence on MER processes such as the evolution of entity naming (e.g. new abbreviations, names for new drugs or diseases).", "labels": [], "entities": [{"text": "MER", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9521687626838684}, {"text": "entity naming", "start_pos": 76, "end_pos": 89, "type": "TASK", "confidence": 0.7313577830791473}]}, {"text": "These obstacles limit the scalability of methods relying on dictionaries and/or gazetteers.", "labels": [], "entities": []}, {"text": "Thus, it is often the case that other types of approaches are developed by exploiting not only domain knowledge but also domainindependent techniques such as machine learning and natural language processing tools.", "labels": [], "entities": []}, {"text": "In this paper, we study MER with three different methods: (i) a semantic method relying on MetaMap) (a state-of-the-art tool for MER) (ii) chunker-based noun phrase extraction and SVM classification and (iii) a last method using supervised learning with Conditional Random Fields (CRF), which is then combined with the semantic method.", "labels": [], "entities": [{"text": "MER", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9773916006088257}, {"text": "noun phrase extraction", "start_pos": 153, "end_pos": 175, "type": "TASK", "confidence": 0.6420316298802694}, {"text": "SVM classification", "start_pos": 180, "end_pos": 198, "type": "TASK", "confidence": 0.9226124286651611}]}, {"text": "With these methods we particularly study two processing directions: (i) pre-extraction of noun phrases with specialized tools, followed by a medical classification step and (ii) exploitation of machine-learning techniques to detect simultaneously entity boundaries and their categories.", "labels": [], "entities": [{"text": "medical classification", "start_pos": 141, "end_pos": 163, "type": "TASK", "confidence": 0.6791388839483261}]}, {"text": "We also present a comparative study of the performance of different noun phrase chunkers on medical texts: Treetagger-chunker, OpenNLP and MetaMap.", "labels": [], "entities": [{"text": "OpenNLP", "start_pos": 127, "end_pos": 134, "type": "DATASET", "confidence": 0.9390347003936768}]}, {"text": "The best chunker was then used to feed some of the proposed MER approaches.", "labels": [], "entities": [{"text": "MER", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.8839501142501831}]}, {"text": "All three methods were experimented on the i2b2/VA 2010 challenge corpus of clinical texts.", "labels": [], "entities": [{"text": "i2b2/VA 2010 challenge corpus of clinical texts", "start_pos": 43, "end_pos": 90, "type": "DATASET", "confidence": 0.8928954071468778}]}, {"text": "Our study shows that hybrid methods achieve the best performance w.r.t machine learning approaches or domain knowledge-based approaches if applied separately.", "labels": [], "entities": []}, {"text": "After a review of related work (Section 2), we describe the chunker comparison and the three MER methods (Section 3).", "labels": [], "entities": [{"text": "chunker comparison", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.8681255578994751}]}, {"text": "We present experiments on clinical texts (Section 4), followed by a discussion and variant experiments on literature abstracts (Section 5), then conclude and draw some perspectives for further work (Section 6).", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed MER experiments on English clinical texts.", "labels": [], "entities": [{"text": "MER", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9059538245201111}]}, {"text": "We tested the above-described five configurations (see): We evaluate the usual metrics of Recall (proportion of correctly detected entities among the reference entities), Precision (proportion of correctly detected entities among those output by the system), and Fmeasure (harmonic means of Recall and Precision).", "labels": [], "entities": [{"text": "Recall", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.9499943852424622}, {"text": "Precision", "start_pos": 171, "end_pos": 180, "type": "METRIC", "confidence": 0.9528541564941406}, {"text": "Fmeasure", "start_pos": 263, "end_pos": 271, "type": "METRIC", "confidence": 0.9951581358909607}]}, {"text": "presents the results obtained by each configuration.", "labels": [], "entities": []}, {"text": "BIO-CRF and BIO-CRF-H obtained the best precision, recall and F-measures.", "labels": [], "entities": [{"text": "BIO-CRF", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.7893981337547302}, {"text": "BIO-CRF-H", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9434645175933838}, {"text": "precision", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9997144341468811}, {"text": "recall", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.9997232556343079}, {"text": "F-measures", "start_pos": 62, "end_pos": 72, "type": "METRIC", "confidence": 0.9960507750511169}]}, {"text": "MM+ comes next, followed by TT-SVM and MetaMap alone.", "labels": [], "entities": [{"text": "MM", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.8829246759414673}, {"text": "TT-SVM", "start_pos": 28, "end_pos": 34, "type": "DATASET", "confidence": 0.7614641785621643}]}, {"text": "We presented three different methods for MER: MM+, TT-SVM, and BIO-CRF (with variant BIO-CRF-H).", "labels": [], "entities": [{"text": "MER", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.9726699590682983}, {"text": "BIO-CRF", "start_pos": 63, "end_pos": 70, "type": "METRIC", "confidence": 0.9814205765724182}]}, {"text": "In this section we quickly present supplementary results obtained on a second corpus with the same methods, and discuss differences in results when corpora and methods vary.", "labels": [], "entities": []}, {"text": "Section 4 presented experiments in MER on English clinical texts.", "labels": [], "entities": [{"text": "MER", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.90755295753479}]}, {"text": "To have a complementary view on the performance of our methods, we performed additional experiments on the Berkeley corpus () of scientific literature abstracts and titles extracted from MEDLINE.", "labels": [], "entities": [{"text": "Berkeley corpus", "start_pos": 107, "end_pos": 122, "type": "DATASET", "confidence": 0.8875896334648132}, {"text": "MEDLINE", "start_pos": 187, "end_pos": 194, "type": "DATASET", "confidence": 0.631016194820404}]}, {"text": "The original aim of this corpus was to study the extraction of semantic relationships between problems and treatments (e.g. cures, prevents, and side effect).", "labels": [], "entities": [{"text": "extraction of semantic relationships between problems and treatments (e.g. cures, prevents", "start_pos": 49, "end_pos": 139, "type": "TASK", "confidence": 0.7183596216715299}]}, {"text": "In our context, we only use its annotation of medical entities.", "labels": [], "entities": []}, {"text": "The corpus contains two categories of medical entities: problems (1,660 entities) and treatments (1,179 entities) in 3,654 sentences (74,754 words) with a mean of 20.05 words per sentence.", "labels": [], "entities": []}, {"text": "We divided the corpus into 1,462 sentences for training and 2,193 for testing.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Proposed MER methods", "labels": [], "entities": [{"text": "MER", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.6607879400253296}]}, {"text": " Table 3: Number of training and test sentences", "labels": [], "entities": [{"text": "Number", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9567880034446716}]}, {"text": " Table 4: Results per setting on the i2b2 corpus. R = recall,  P = precision, F = F-measure", "labels": [], "entities": [{"text": "R", "start_pos": 50, "end_pos": 51, "type": "METRIC", "confidence": 0.9814352989196777}, {"text": "recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.8872548937797546}, {"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9547585844993591}, {"text": "F-measure", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.9465879201889038}]}, {"text": " Table 5: Results per setting and per category on the i2b2  corpus", "labels": [], "entities": [{"text": "i2b2  corpus", "start_pos": 54, "end_pos": 66, "type": "DATASET", "confidence": 0.8879566788673401}]}, {"text": " Table 6: Results on the Berkeley Corpus", "labels": [], "entities": [{"text": "Berkeley Corpus", "start_pos": 25, "end_pos": 40, "type": "DATASET", "confidence": 0.9616338014602661}]}, {"text": " Table 7: Contribution of each feature category (BIO-CRF  method) on the i2b2 corpus", "labels": [], "entities": [{"text": "BIO-CRF", "start_pos": 49, "end_pos": 56, "type": "METRIC", "confidence": 0.9614352583885193}]}]}