{"title": [{"text": "Instance Selection for Machine Translation using Feature Decay Algorithms", "labels": [], "entities": [{"text": "Instance Selection", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9395523369312286}, {"text": "Machine Translation", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.8010293543338776}]}], "abstractContent": [{"text": "We present an empirical study of instance selection techniques for machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.7773858308792114}]}, {"text": "In an active learning setting, instance selection minimizes the human effort by identifying the most informative sentences for translation.", "labels": [], "entities": [{"text": "instance selection", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.7502281665802002}]}, {"text": "Ina transductive learning setting, selection of training instances relevant to the test set improves the final translation quality.", "labels": [], "entities": []}, {"text": "After reviewing the state of the art in the field, we generalize the main ideas in a class of instance selection algorithms that use feature decay.", "labels": [], "entities": []}, {"text": "Feature decay algorithms increase diversity of the training set by devaluing features that are already included.", "labels": [], "entities": []}, {"text": "We show that the feature decay rate has a very strong effect on the final translation quality whereas the initial feature values, inclusion of higher order features, or sentence length normalizations do not.", "labels": [], "entities": []}, {"text": "We evaluate the best instance selection methods using a standard Moses baseline using the whole 1.6 million sentence English-German section of the Eu-roparl corpus.", "labels": [], "entities": [{"text": "Eu-roparl corpus", "start_pos": 147, "end_pos": 163, "type": "DATASET", "confidence": 0.8944794833660126}]}, {"text": "We show that selecting the best 3000 training sentences fora specific test sentence is sufficient to obtain a score within 1 BLEU of the baseline, using 5% of the training data is sufficient to exceed the baseline, and a \u223c 2 BLEU improvement over the baseline is possible by optimally selected subset of the training data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 125, "end_pos": 129, "type": "METRIC", "confidence": 0.9980560541152954}, {"text": "BLEU", "start_pos": 225, "end_pos": 229, "type": "METRIC", "confidence": 0.9955099821090698}]}, {"text": "In out-of-domain translation, we are able to reduce the training set size to about 7% and achieve a similar performance with the baseline.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical machine translation (SMT) makes use of a large number of parallel sentences, sentences whose translations are known in the target language, to derive translation tables, estimate parameters, and generate the actual translation.", "labels": [], "entities": [{"text": "Statistical machine translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8083392928044001}]}, {"text": "Not all of the parallel corpus nor the translation table that is generated is used during decoding a given set of test sentences and filtering is usually performed for computational advantage (.", "labels": [], "entities": []}, {"text": "Some recent regression-based statistical machine translation systems rely on a small sized training data to learn the mappings between source and target features (.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 29, "end_pos": 60, "type": "TASK", "confidence": 0.5949665506680807}]}, {"text": "Regression has some computational disadvantages when scaling to large number of training instances.", "labels": [], "entities": [{"text": "Regression", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.6640687584877014}]}, {"text": "Previous work shows that the more the training data, the better the translations become).", "labels": [], "entities": []}, {"text": "However, with the increased size of the parallel corpus there is also the added noise, making relevant instance selection important.", "labels": [], "entities": []}, {"text": "Phrasebased SMT systems rely heavily on accurately learning word alignments from the given parallel corpus.", "labels": [], "entities": [{"text": "Phrasebased SMT", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.676079273223877}]}, {"text": "Proper instance selection plays an important role in obtaining a small sized training set with which correct alignments can be learned.", "labels": [], "entities": []}, {"text": "Wordlevel translation accuracy is also affected by the number of times a word occurs in the parallel corpus ().", "labels": [], "entities": [{"text": "Wordlevel translation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.6825046092271805}, {"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.7777482271194458}]}, {"text": "Koehn and Knight find that about 50 examples per word are required to achieve a performance close to using a bilingual lexicon in their experiments.", "labels": [], "entities": []}, {"text": "Translation performance can improve as we include multiple possible translations fora given word, which increases the diversity of the training set.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.9598828554153442}]}, {"text": "Transduction uses test instances, which can sometimes be accessible at training time, to learn specific models tailored towards the test set which also reduces computation by not using the full training set.", "labels": [], "entities": []}, {"text": "Transductive retrieval selects training data close to the test set given a parallel corpus and a test set.", "labels": [], "entities": [{"text": "Transductive retrieval", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8539858460426331}]}, {"text": "This work shows that transductive retrieval of the training set for statistical machine translation allows us to achieve a performance better than using all of the parallel corpus.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 68, "end_pos": 99, "type": "TASK", "confidence": 0.7217714389165243}]}, {"text": "When selecting training data, we seek to maximize the coverage or the percentage of test source and target features (i.e. n-grams) found in the training set using minimal number of target training features and a fixed number of training instances.", "labels": [], "entities": [{"text": "coverage", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.958102285861969}]}, {"text": "Diversifying the set of training sentences can help us increase the coverage.", "labels": [], "entities": [{"text": "coverage", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9882624745368958}]}, {"text": "We show that target coverage bounds the achievable BLEU score with a given training set and small increases can result in large increases on this BLEU bound.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 51, "end_pos": 61, "type": "METRIC", "confidence": 0.972799688577652}, {"text": "BLEU", "start_pos": 146, "end_pos": 150, "type": "METRIC", "confidence": 0.9983164072036743}]}, {"text": "We develop the feature decay algorithms (FDA) that aim to maximize the coverage of the target language features and achieve significant gains in translation performance.", "labels": [], "entities": []}, {"text": "We find that decaying feature weights has significant effect on the performance.", "labels": [], "entities": []}, {"text": "We achieve improvements of \u223c2 BLEU points using about 20% of the available training data in terms of target words and \u223c1 BLEU points with only about 5%.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.9912250638008118}, {"text": "BLEU", "start_pos": 121, "end_pos": 125, "type": "METRIC", "confidence": 0.993330180644989}]}, {"text": "We show that selecting 3000 instances fora test sentence is sufficient to obtain a score within 1 BLEU of the baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.9994155168533325}]}, {"text": "In the outof-domain translation task, we are able to reduce the training set size to its 7% to achieve a similar performance with the baseline.", "labels": [], "entities": [{"text": "outof-domain translation task", "start_pos": 7, "end_pos": 36, "type": "TASK", "confidence": 0.7472501993179321}]}, {"text": "The next section reviews related previous work.", "labels": [], "entities": []}, {"text": "We discuss the FDA in section 3.", "labels": [], "entities": [{"text": "FDA", "start_pos": 15, "end_pos": 18, "type": "DATASET", "confidence": 0.8702325820922852}]}, {"text": "Section 4 presents our coverage and translation results both in and out-of-domain and includes an instance selection method also designed for improving word alignment results.", "labels": [], "entities": [{"text": "translation", "start_pos": 36, "end_pos": 47, "type": "TASK", "confidence": 0.9586209058761597}, {"text": "word alignment", "start_pos": 152, "end_pos": 166, "type": "TASK", "confidence": 0.7857830226421356}]}, {"text": "We list our contributions in the last section.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform translation experiments on the English-German language pair using the parallel corpus provided in WMT'10 ( ).", "labels": [], "entities": [{"text": "WMT'10", "start_pos": 109, "end_pos": 115, "type": "DATASET", "confidence": 0.9543513655662537}]}, {"text": "The English-German section of the Europarl corpus contains about 1.6 million sentences.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 34, "end_pos": 49, "type": "DATASET", "confidence": 0.9676342308521271}]}, {"text": "We perform in-domain experiments to discriminate among different instance selection techniques better in a setting with low out-of-vocabulary rate.", "labels": [], "entities": []}, {"text": "We randomly select the test set test with 2, 588 target words and separate development set dev with 26, 178 target words.", "labels": [], "entities": []}, {"text": "We use the language model corpus provided in WMT'10 (Callison-Burch et al., 2010) to build a 5-gram model.", "labels": [], "entities": [{"text": "WMT'10", "start_pos": 45, "end_pos": 51, "type": "DATASET", "confidence": 0.918747067451477}]}, {"text": "We use target language bigram coverage, tcov, as a quality measure fora given training set, which measures the percentage of the target bigram features of the test sentence found in a given training set.", "labels": [], "entities": []}, {"text": "We compare tcov and the translation performance of FDA with related work.", "labels": [], "entities": []}, {"text": "We also perform small scale SMT experiments where only a couple of thousand training instances are used for each test sentence.", "labels": [], "entities": [{"text": "SMT", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9744815230369568}]}], "tableCaptions": [{"text": " Table 1: FDA experiments. The first two columns  give the initial value and decay formula used for  features. f is the corpus frequency of a feature  and n is its count in selected instances. The next  four columns give the expected coverage of the  source and target language bigrams of a test sen- tence when 100 training sentences are selected.", "labels": [], "entities": []}, {"text": " Table 2: Statistics of the obtained target L for N =  1000.", "labels": [], "entities": []}, {"text": " Table 3: Performance for en-de using L \u222a F . ALL  corresponds to the baseline system using all of the  parallel corpus. bold correspond to statistically  significant improvement over the baseline result.", "labels": [], "entities": [{"text": "ALL", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.9618293046951294}]}, {"text": " Table 4: L I performance for en-de using 100 sen- tences for tuning or mean of the weights or dev  weights obtained with the union setting.", "labels": [], "entities": []}, {"text": " Table 5: BLEU results using different techniques  with N = 1000. High coverage \u2192 High BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9977449178695679}, {"text": "coverage", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9001427888870239}, {"text": "BLEU", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.9984191656112671}]}]}