{"title": [{"text": "Reconciling OntoNotes: Unrestricted Coreference Resolution in OntoNotes with Reconcile", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 36, "end_pos": 58, "type": "TASK", "confidence": 0.8368190228939056}]}], "abstractContent": [{"text": "This paper describes our entry to the 2011 CoNLL closed task (Pradhan et al., 2011) on modeling unrestricted coreference in OntoNotes.", "labels": [], "entities": []}, {"text": "Our system is based on the Reconcile coreference resolution research platform.", "labels": [], "entities": [{"text": "Reconcile coreference resolution", "start_pos": 27, "end_pos": 59, "type": "TASK", "confidence": 0.7981891830762228}]}, {"text": "Reconcile is a general software infrastructure for the development of learning-based noun phrase (NP) coreference resolution systems.", "labels": [], "entities": [{"text": "noun phrase (NP) coreference resolution", "start_pos": 85, "end_pos": 124, "type": "TASK", "confidence": 0.6650491612298148}]}, {"text": "Our entry for the CoNLL closed task is a configuration of Reconcile intended to do well on OntoNotes data.", "labels": [], "entities": [{"text": "OntoNotes data", "start_pos": 91, "end_pos": 105, "type": "DATASET", "confidence": 0.9036659896373749}]}, {"text": "This paper describes our configuration of Reconcile as well as the changes that we had to implement to integrate with the OntoNotes task definition and data formats.", "labels": [], "entities": []}, {"text": "We also present and discuss the performance of our system under different testing conditions on a withheld validation set.", "labels": [], "entities": []}], "introductionContent": [{"text": "Noun phrase (NP) coreference resolution is one of the fundamental tasks of the field of Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Noun phrase (NP) coreference resolution", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.6229906763349261}, {"text": "Natural Language Processing (NLP)", "start_pos": 88, "end_pos": 121, "type": "TASK", "confidence": 0.6988069415092468}]}, {"text": "Recently, the creation of the OntoNotes corpus ( has provided researchers with a large standard data collection with which to create and empirically compare coreference resolution systems.", "labels": [], "entities": [{"text": "OntoNotes corpus", "start_pos": 30, "end_pos": 46, "type": "DATASET", "confidence": 0.8578334748744965}, {"text": "coreference resolution", "start_pos": 157, "end_pos": 179, "type": "TASK", "confidence": 0.8546177446842194}]}, {"text": "Reconcile () is a general coreference resolution research platform that aims to abstract the architecture of different learningbased coreference systems and to provide infrastructure for their quick implementation.", "labels": [], "entities": [{"text": "coreference resolution research", "start_pos": 26, "end_pos": 57, "type": "TASK", "confidence": 0.869053304195404}]}, {"text": "Reconcile is distributed with several state-of-the art NLP components and a set of optimized feature implementations.", "labels": [], "entities": [{"text": "Reconcile", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.8356771469116211}]}, {"text": "We decided to adapt Reconcile for the OntoNotes corpus and enter it in the 2011 CoNLL shared task with three goals in mind: (i) to compare the architecture and components of Reconcile with other state-of-the-art coreference systems, (ii) to implement and provide the capability of running Reconcile on the OntoNotes corpus, and, (iii) to provide a baseline for future algorithm implementations in Reconcile that evaluate on the OntoNotes corpus.", "labels": [], "entities": [{"text": "OntoNotes corpus", "start_pos": 38, "end_pos": 54, "type": "DATASET", "confidence": 0.7895663678646088}, {"text": "OntoNotes corpus", "start_pos": 306, "end_pos": 322, "type": "DATASET", "confidence": 0.8248098790645599}, {"text": "OntoNotes corpus", "start_pos": 428, "end_pos": 444, "type": "DATASET", "confidence": 0.8663960993289948}]}, {"text": "Although Reconcile can be easily adapted to new corpora, doing so requires introducing new components.", "labels": [], "entities": []}, {"text": "More precisely, the system has to be modified to be consistent with the specific definition of the coreference task embodied in the OntoNotes annotation instructions.", "labels": [], "entities": []}, {"text": "Additionally, different corpora use different data formats, so the system needs to implement capabilities for dealing with these new formats.", "labels": [], "entities": []}, {"text": "Finally, Reconcile can be configured with different features and components to create an instantiation that models well the particular data.", "labels": [], "entities": []}, {"text": "In this paper we describe, Reconcile CoN LL , our entry to the 2011 CoNLL shared task based on the Reconcile research platform.", "labels": [], "entities": [{"text": "Reconcile CoN LL", "start_pos": 27, "end_pos": 43, "type": "DATASET", "confidence": 0.6160210172335306}, {"text": "Reconcile research platform", "start_pos": 99, "end_pos": 126, "type": "DATASET", "confidence": 0.8482638994852701}]}, {"text": "We begin by describing the general Reconcile architecture (Section 2), then describe the changes that we incorporated in order to enable Reconcile to work on OntoNotes data (Sections 3 and 4).", "labels": [], "entities": [{"text": "OntoNotes data", "start_pos": 158, "end_pos": 172, "type": "DATASET", "confidence": 0.7973149716854095}]}, {"text": "Finally, we describe our experimental setup and results from running Reconcile CoN LL under different conditions (Section 5).", "labels": [], "entities": [{"text": "Reconcile CoN LL", "start_pos": 69, "end_pos": 85, "type": "TASK", "confidence": 0.6036228736241659}]}], "datasetContent": [{"text": "In this section we present and discuss the results for Reconcile CoN LL when trained and evaluated on OntoNotes data.", "labels": [], "entities": [{"text": "Reconcile CoN LL", "start_pos": 55, "end_pos": 71, "type": "TASK", "confidence": 0.7609795530637106}, {"text": "OntoNotes data", "start_pos": 102, "end_pos": 116, "type": "DATASET", "confidence": 0.9003268480300903}]}, {"text": "For all experiments, we train on a set of 750 randomly selected documents from the OntoNotes corpus.", "labels": [], "entities": [{"text": "OntoNotes corpus", "start_pos": 83, "end_pos": 99, "type": "DATASET", "confidence": 0.9250266253948212}]}, {"text": "We use another 674 randomly selected documents for validation.", "labels": [], "entities": []}, {"text": "We report scores using the scorers implemented internally in Reconcile as well as the scorers supplied by the CoNLL shared task.", "labels": [], "entities": [{"text": "Reconcile", "start_pos": 61, "end_pos": 70, "type": "DATASET", "confidence": 0.901185929775238}, {"text": "CoNLL shared task", "start_pos": 110, "end_pos": 127, "type": "DATASET", "confidence": 0.8393983642260233}]}, {"text": "In the rest of the section, we describe our results when controlling two aspects of the system -the threshold of the pairwise CE classifier, which is tuned on training data, and the method used for pair generation.", "labels": [], "entities": [{"text": "pair generation", "start_pos": 198, "end_pos": 213, "type": "TASK", "confidence": 0.8289061486721039}]}, {"text": "We conclude by presenting the official results for the CoNLL shared task.", "labels": [], "entities": [{"text": "CoNLL shared task", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.6129543781280518}]}, {"text": "Influence of Classifier Threshold As previously mentioned, the threshold above which the decision of the classifier is considered positive provides us with a knob that controls the precision/recall trade-off.", "labels": [], "entities": [{"text": "Threshold", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.8647372126579285}, {"text": "precision", "start_pos": 181, "end_pos": 190, "type": "METRIC", "confidence": 0.9985799789428711}, {"text": "recall", "start_pos": 191, "end_pos": 197, "type": "METRIC", "confidence": 0.911834180355072}]}, {"text": "Reconcile includes a module that can automatically search fora threshold value that optimizes a particular evaluation metric.", "labels": [], "entities": [{"text": "Reconcile", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.7718372344970703}]}, {"text": "Results using three Reconcile-internal scorers (BCubed, CEAF, MUC) are shown in.", "labels": [], "entities": [{"text": "BCubed", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.5863640308380127}, {"text": "CEAF", "start_pos": 56, "end_pos": 60, "type": "DATASET", "confidence": 0.438764363527298}]}, {"text": "First, we see that the threshold that optimizes performance on the validation data also exhibits the best results on the test data.", "labels": [], "entities": []}, {"text": "The same does not hold when using the CoNLL scorer for testing, however: as shows, the best results for almost all of the CoNLL scores are achieved at the threshold that optimizes the Reconcile-internal MUC score.", "labels": [], "entities": [{"text": "CoNLL scorer", "start_pos": 38, "end_pos": 50, "type": "DATASET", "confidence": 0.7733255922794342}, {"text": "Reconcile-internal MUC", "start_pos": 184, "end_pos": 206, "type": "TASK", "confidence": 0.32890458405017853}]}, {"text": "Note that we did not optimize thresholds for the external scorer in the name of saving implementation effort.", "labels": [], "entities": []}, {"text": "Unfortunately, the results that we submitted for the official evaluations were for the suboptimal threshold that optimizes Reconcile-internal BCubed score.", "labels": [], "entities": [{"text": "Reconcile-internal BCubed score", "start_pos": 123, "end_pos": 154, "type": "METRIC", "confidence": 0.7891859213511149}]}], "tableCaptions": [{"text": " Table 1: Reconcile-internal scores for different  thresholds. The table lists the best threshold for  the validation data and results using that threshold.", "labels": [], "entities": [{"text": "Reconcile-internal", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.9764242172241211}]}, {"text": " Table 3: Influence of different pair generators.", "labels": [], "entities": []}, {"text": " Table 2: CoNLL scores for different thresholds on validation data.", "labels": [], "entities": [{"text": "CoNLL", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.8527628779411316}]}, {"text": " Table 4: Official CoNLL 2011 test scores. Combined score is the average of MUC, BCubed and CEAFe.", "labels": [], "entities": [{"text": "Official CoNLL 2011 test scores", "start_pos": 10, "end_pos": 41, "type": "DATASET", "confidence": 0.8722707152366638}, {"text": "MUC", "start_pos": 76, "end_pos": 79, "type": "DATASET", "confidence": 0.6725277304649353}, {"text": "BCubed", "start_pos": 81, "end_pos": 87, "type": "METRIC", "confidence": 0.9355549812316895}, {"text": "CEAFe", "start_pos": 92, "end_pos": 97, "type": "DATASET", "confidence": 0.77336585521698}]}]}