{"title": [{"text": "Web-based validation for contextual targeted paraphrasing", "labels": [], "entities": [{"text": "contextual targeted paraphrasing", "start_pos": 25, "end_pos": 57, "type": "TASK", "confidence": 0.7090012828509012}]}], "abstractContent": [{"text": "In this work, we present a scenario where con-textual targeted paraphrasing of sub-sentential phrases is performed automatically to support the task of text revision.", "labels": [], "entities": [{"text": "text revision", "start_pos": 152, "end_pos": 165, "type": "TASK", "confidence": 0.7310949862003326}]}, {"text": "Candidate paraphrases are obtained from a preexisting repertoire and validated in the context of the original sentence using information derived from the Web.", "labels": [], "entities": []}, {"text": "We report on experiments on French, where the original sentences to be rewritten are taken from a rewriting memory automatically extracted from the edit history of Wikipedia.", "labels": [], "entities": []}], "introductionContent": [{"text": "There are many instances where it is reasonable to expect machines to produce text automatically.", "labels": [], "entities": []}, {"text": "Traditionally, this was tackled as a concept-to-text realization problem.", "labels": [], "entities": [{"text": "concept-to-text realization", "start_pos": 37, "end_pos": 64, "type": "TASK", "confidence": 0.740422248840332}]}, {"text": "However, such needs apply sometimes to cases where anew text should be derived from some existing texts, an instance of text-to-text generation.", "labels": [], "entities": [{"text": "text-to-text generation", "start_pos": 120, "end_pos": 143, "type": "TASK", "confidence": 0.7403919994831085}]}, {"text": "The general idea is not anymore to produce a text from data, but to transform a text so as to ensure that it has desirable properties appropriate for some intended application (.", "labels": [], "entities": []}, {"text": "For example, one may want a text to be shorter ( , tailored to some reader profile (, compliant with some specific norms), or more adapted for subsequent machine processing tasks).", "labels": [], "entities": []}, {"text": "The generation process must produce a text having a meaning which is compatible with the definition of the task at hand (e.g. strict paraphrasing for document normalization, relaxed paraphrasing for text simplification), while ensuring that it remains grammatically correct.", "labels": [], "entities": [{"text": "document normalization", "start_pos": 150, "end_pos": 172, "type": "TASK", "confidence": 0.7221018373966217}, {"text": "text simplification", "start_pos": 199, "end_pos": 218, "type": "TASK", "confidence": 0.7192259132862091}]}, {"text": "Its complexity, compared with concept-to-text generation, mostly stems from the fact that the semantic relationship between the original text and the new one is more difficult to control, as the mapping from one text to another is very dependent on the rewriting context.", "labels": [], "entities": [{"text": "concept-to-text generation", "start_pos": 30, "end_pos": 56, "type": "TASK", "confidence": 0.7885763347148895}]}, {"text": "The wide variety of techniques for acquiring phrasal paraphrases, which can subsequently be used by text paraphrasing techniques , the inherent polysemy of such linguistic units and the pragmatic constraints on their uses make it impossible to ensure that potential paraphrase pairs will be substitutable in any context, an observation which was already made at a lexical level (.", "labels": [], "entities": [{"text": "text paraphrasing", "start_pos": 100, "end_pos": 117, "type": "TASK", "confidence": 0.7020349055528641}]}, {"text": "Hence, automatic contextual validation of candidate rewritings is a fundamental issue for text paraphrasing with phrasal units.", "labels": [], "entities": [{"text": "automatic contextual validation of candidate rewritings", "start_pos": 7, "end_pos": 62, "type": "TASK", "confidence": 0.6569357961416245}, {"text": "text paraphrasing", "start_pos": 90, "end_pos": 107, "type": "TASK", "confidence": 0.7412458956241608}]}, {"text": "In this article, we tackle the problem of what we call targeted paraphrasing, defined as the rewriting of a subpart of a sentence, as in e.g. ( where it is applied to making parts of sentences easier to translate automatically.", "labels": [], "entities": []}, {"text": "While this problem is simpler than full sentence rewriting, its study is justified as it should be handled correctly for the more complex task to be successful.", "labels": [], "entities": [{"text": "full sentence rewriting", "start_pos": 35, "end_pos": 58, "type": "TASK", "confidence": 0.6394190887610117}]}, {"text": "Moreover, being simpler, it offers evaluation scenarios which make the performance on the task easier to assess.", "labels": [], "entities": []}, {"text": "Our particular experiments here aim to assist a Wikipedia contributor in revising a text to improve its quality.", "labels": [], "entities": []}, {"text": "For this, we use a collection of phrases that have been rewritten in Wikipedia, and test the substitutability of paraphrases coming from a repertoire of sub-sentential paraphrases acquired from different sources.", "labels": [], "entities": []}, {"text": "We thus consider that preexisting repertoires of sub-sentential paraphrase pairs are available, and that each potential candidate has to be tested in the specific context of the desired rewriting.", "labels": [], "entities": []}, {"text": "Due to the large variety of potential phrases and their associated known paraphrases, we do not rely on precomputed models of substitutability, but rather build them on-the-fly using information derived from web queries.", "labels": [], "entities": []}, {"text": "This article is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2, we first describe the task of text revision, where a subpart of a sentence is rewritten, as an instance of targeted paraphrasing.", "labels": [], "entities": [{"text": "text revision", "start_pos": 44, "end_pos": 57, "type": "TASK", "confidence": 0.7537941932678223}]}, {"text": "Section 3 presents previous works on the acquisition of sub-sentential paraphrases and describes the knowledge sources that we have used in this work.", "labels": [], "entities": [{"text": "acquisition of sub-sentential paraphrases", "start_pos": 41, "end_pos": 82, "type": "TASK", "confidence": 0.7643279135227203}]}, {"text": "We then describe in section 4 how we estimate models of phrase substitution in context by exploiting information coming from the web.", "labels": [], "entities": [{"text": "phrase substitution", "start_pos": 56, "end_pos": 75, "type": "TASK", "confidence": 0.7937868535518646}]}, {"text": "We present our experiments and their results in section 5, and finally discuss our current results and future work in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we report on experiments conducted to assess the performance of our proposed approach for validating candidate sub-sentential paraphrases using information from the Web.", "labels": [], "entities": []}, {"text": "We used the models described in Section 4 to build a SVM classifier using the LIBSVM package).", "labels": [], "entities": [{"text": "LIBSVM package", "start_pos": 78, "end_pos": 92, "type": "DATASET", "confidence": 0.8665294051170349}]}, {"text": "Accuracy results are reported on.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9919146299362183}]}, {"text": "The first notable observation is that our task is not surprisingly a difficult one.", "labels": [], "entities": []}, {"text": "The best performance achieved is an accuracy of 70.69 with our system in the SURE condition.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9997113347053528}, {"text": "SURE", "start_pos": 77, "end_pos": 81, "type": "METRIC", "confidence": 0.9934872388839722}]}, {"text": "There are, however, some important variations across conditions, with a result as low as 57.67 for our system in the POSSIBLE condition (recall that in this condition candidates are considered paraphrases when only one of the two judges considered it a paraphrase, i.e. when the two judges disagreed).", "labels": [], "entities": [{"text": "POSSIBLE", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9694713950157166}]}, {"text": "Overall, the WEBLM baseline and our system appear as stronger than the two other baselines.", "labels": [], "entities": [{"text": "WEBLM baseline", "start_pos": 13, "end_pos": 27, "type": "DATASET", "confidence": 0.9065427780151367}]}, {"text": "The two lower baselines, BOUNDLM and CONTDEP, attempt to model local grammatical constraints, which are not surprisingly not sufficient for paraphrase identification.", "labels": [], "entities": [{"text": "BOUNDLM", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.9955430626869202}, {"text": "CONTDEP", "start_pos": 37, "end_pos": 44, "type": "METRIC", "confidence": 0.7366991639137268}, {"text": "paraphrase identification", "start_pos": 140, "end_pos": 165, "type": "TASK", "confidence": 0.9041203558444977}]}, {"text": "WEBLM is comparatively a much more competitive baseline, but its accuracy in the SURER condition is not very strong.", "labels": [], "entities": [{"text": "WEBLM", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.6119166612625122}, {"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9996480941772461}, {"text": "SURER", "start_pos": 81, "end_pos": 86, "type": "METRIC", "confidence": 0.718388020992279}]}, {"text": "As this latter condition considers only consensual judgements for the two judges, we can hypothesize that the interpretation of its results is more reliable.", "labels": [], "entities": []}, {"text": "In this condi- Figure 6: Paraphrase accuracy of our different paraphrase acquisition methods for the three conditions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9517420530319214}, {"text": "paraphrase acquisition", "start_pos": 62, "end_pos": 84, "type": "TASK", "confidence": 0.7368179559707642}]}, {"text": "tion, our system obtains the best performance, with a +6.06 advantage over WEBLM.", "labels": [], "entities": [{"text": "WEBLM", "start_pos": 75, "end_pos": 80, "type": "DATASET", "confidence": 0.8169152736663818}]}, {"text": "As found in other works (e.g. ()), using language models for paraphrase validation is not sufficient as it cannot model meaning preservation, and our results show that this is also true even when counts are estimated from the Web.", "labels": [], "entities": [{"text": "paraphrase validation", "start_pos": 61, "end_pos": 82, "type": "TASK", "confidence": 0.7651467025279999}, {"text": "meaning preservation", "start_pos": 120, "end_pos": 140, "type": "TASK", "confidence": 0.7737570703029633}]}, {"text": "Using a ratio of normalized LM scores may have improved the situation a bit.", "labels": [], "entities": []}, {"text": "Lastly, we report in the paraphrase accuracy of each individual acquisition technique (i.e. source of paraphrases from the preexisting repertoire).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9345227479934692}]}, {"text": "The original rewritting from WICO-PACO obtains not surprisingly a very high paraphrase accuracy, in particular in the POSSIBLE and SURER conditions.", "labels": [], "entities": [{"text": "WICO-PACO", "start_pos": 29, "end_pos": 38, "type": "DATASET", "confidence": 0.7338427901268005}, {"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9830179214477539}, {"text": "POSSIBLE", "start_pos": 118, "end_pos": 126, "type": "METRIC", "confidence": 0.9676180481910706}, {"text": "SURER", "start_pos": 131, "end_pos": 136, "type": "METRIC", "confidence": 0.7777886986732483}]}, {"text": "Paraphrases obtained through our Web-based game have an acceptable accuracy: the numbers confirm that paraphrase pairs are highly context-dependent, because the pairs which were likely to be paraphrases in the context of the game are not necessarily so in a different context.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.999372661113739}]}, {"text": "This, of course, maybe due to a number of reasons that we will have to investigate.", "labels": [], "entities": []}, {"text": "Lastly, there is a significant drop inaccuracy for the automatic pivot paraphrasers, but pivoting through Spanish obtained, not suprisingly again, a much better performance than pivoting through Chinese.", "labels": [], "entities": []}], "tableCaptions": []}