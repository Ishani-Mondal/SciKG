{"title": [{"text": "Phrase Extraction for Japanese Predictive Input Method as Post-Processing", "labels": [], "entities": [{"text": "Phrase Extraction", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9289532005786896}]}], "abstractContent": [{"text": "We propose a novel phrase extraction system to generate a phrase dictionary for predictive input methods from a large corpus.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.7821051776409149}]}, {"text": "This system extracts phrases after counting n-grams so that it can be easily maintained, tuned, and re-executed independently.", "labels": [], "entities": []}, {"text": "We developed a rule-based filter based on part-of-speech (POS) patterns to extract Japanese phrases.", "labels": [], "entities": []}, {"text": "Our experiment shows usefulness of our system, which achieved a precision of 0.90 and a recall of 0.81, outperforming the N-gram baseline by a large margin.", "labels": [], "entities": [{"text": "precision", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9988228678703308}, {"text": "recall", "start_pos": 88, "end_pos": 94, "type": "METRIC", "confidence": 0.9996370077133179}]}], "introductionContent": [{"text": "Predictive input methods for personal computers or mobile devices have been quite popular).", "labels": [], "entities": []}, {"text": "They suggest options of entire words or phrases to select when a user inputs first few characters or words.", "labels": [], "entities": []}, {"text": "Recently, the growth of the Web has increased the availability of large corpora for natural language processing.", "labels": [], "entities": []}, {"text": "Large corpora are effective in generating dictionaries, since they include frequently used words and phrases.", "labels": [], "entities": []}, {"text": "One of the possible simple ways to enlarge a dictionary is the n-gram approach.", "labels": [], "entities": []}, {"text": "N-gram is a word sequence of length n.", "labels": [], "entities": []}, {"text": "The N-gram approach consists of the following steps: count n-gram sequences in the corpus and show the most frequent n-grams for user input.", "labels": [], "entities": []}, {"text": "This approach enables the dictionary to cover most of the useful options.", "labels": [], "entities": []}, {"text": "However, such a naive n-gram approach has three major problems: Trade-offs between lengths and frequencies Longer n-grams always have lower frequencies than shorter n-grams.", "labels": [], "entities": []}, {"text": "For predictive input methods, longer options are favorable because they reduce user keystrokes much more.", "labels": [], "entities": []}, {"text": "Halfway options N-gram contains partial portions of eligible phrases.", "labels": [], "entities": []}, {"text": "For example, the trigram of \"you very much\" has high frequency, which maybe a subsequence of \"Thank you very much\".", "labels": [], "entities": [{"text": "frequency", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9519243836402893}]}, {"text": "Enormous memory consumption N-grams are also too large for client-side input methods.", "labels": [], "entities": []}, {"text": "Predictive dictionaries are preferable to fit into memory for rapid access.", "labels": [], "entities": []}, {"text": "Since input methods always remain in memory, it should save memory for other applications.", "labels": [], "entities": []}, {"text": "To cope with these problems, phrase-based approaches are considered.", "labels": [], "entities": []}, {"text": "These approaches use phrase extraction to reduce unnecessary n-grams.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.783357709646225}]}, {"text": "A phrase represents a semantic or syntactic unit of a word sequence in texts.", "labels": [], "entities": []}, {"text": "For predictive input methods, phrases should be rather comprehensive; we want to extract various phrases which users possibly input, containing noun phrases, verbal phrases, proper noun, idioms, and soon.", "labels": [], "entities": []}, {"text": "There are two types of approaches to extract phrases from a large corpus: pre-processing and post-processing approaches.", "labels": [], "entities": []}, {"text": "Ina pre-processing approach, phrase extraction is applied to a corpus before counting.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.8709964454174042}]}, {"text": "This setting is similar to a chunking task), extracting non-overlapping chunks from a corpus.", "labels": [], "entities": []}, {"text": "In this approach, each time we try anew algorithm, re-execution of counting is required to construct a phrase dictionary.", "labels": [], "entities": []}, {"text": "This is too painful and expensive.", "labels": [], "entities": []}, {"text": "For these reasons, we adopted a post-processing approach.", "labels": [], "entities": []}, {"text": "Ina post-processing approach, phrases are picked out from n-grams after counting.", "labels": [], "entities": []}, {"text": "In addition to counting, cutting off n-grams with low frequencies significantly reduce data size of n-grams.", "labels": [], "entities": [{"text": "counting", "start_pos": 15, "end_pos": 23, "type": "TASK", "confidence": 0.9674687385559082}]}, {"text": "Therefore, we can develop and run the phrase extraction algorithm in a local machine, using commonly-available script languages.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.8789273798465729}]}, {"text": "Additionally, once we count frequencies of n-grams, we need no more counting frequencies again to generate a dictionary after changing of the algorithm.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the Japanese language to utilize grammatical knowledge.", "labels": [], "entities": []}, {"text": "Since the Japanese language has many characters than physical keys, Japanese people normally use input methods called Kana Kanji conversion, therefore predictive input methods are easily brought in.", "labels": [], "entities": [{"text": "Kana Kanji conversion", "start_pos": 118, "end_pos": 139, "type": "TASK", "confidence": 0.622639666001002}]}, {"text": "The rest of this paper is organized as follows: section 2 introduces related work in similar tasks.", "labels": [], "entities": []}, {"text": "Section 3 describes an algorithm that we developed.", "labels": [], "entities": []}, {"text": "Section 4 explains experiments and evaluations of our algorithm.", "labels": [], "entities": []}, {"text": "Section 5 summarizes the whole paper and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used a Japanese blog corpus whose size is about 300GB, containing 70G words.", "labels": [], "entities": []}, {"text": "Since blogs are written by ordinary people, we expect them to fit typical use cases.", "labels": [], "entities": []}, {"text": "We counted n-grams from the corpus with 20 machines of a Hadoop MapReduce cluster.", "labels": [], "entities": []}, {"text": "The counting took 17 hours.", "labels": [], "entities": [{"text": "counting", "start_pos": 4, "end_pos": 12, "type": "TASK", "confidence": 0.9734981060028076}]}, {"text": "We set n from 1 to 5 and cut-off threshold to 1,000.", "labels": [], "entities": []}, {"text": "Resulted n-gram has about 6M unique n-grams and size of 700MB in plain text.", "labels": [], "entities": []}, {"text": "Then we applied our rule-based filter extracting 1.2M different phrases and size of 100MB in plain text.", "labels": [], "entities": []}, {"text": "The filtering took only 5 minutes in a local machine.", "labels": [], "entities": [{"text": "filtering", "start_pos": 4, "end_pos": 13, "type": "TASK", "confidence": 0.9626792669296265}]}, {"text": "We conducted sampling from original n-grams in two ways: token-based and type-based.", "labels": [], "entities": []}, {"text": "Tokenbased sampling means that samples are extracted from n-gram according to their probabilities or relative frequencies.", "labels": [], "entities": [{"text": "Tokenbased sampling", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.6540162861347198}]}, {"text": "Type-based sampling uniformly extracts entries from n-gram.", "labels": [], "entities": []}, {"text": "After sampling, 5 people judged the same 200 n-grams into necessary phrase or not by hand, for each token-based and type-based sampling.", "labels": [], "entities": []}, {"text": "In addition to the definition of phrase described in section 1, we assumed typical Japanese blog writer as target user for clarification.", "labels": [], "entities": []}, {"text": "shows our average evaluation results for both phrases extracted by our system and n-grams as baseline.", "labels": [], "entities": []}, {"text": "N-gram as baseline has recall of 1.0 because of the assumption, but a low precision of 0.41 for the reasons described in section 1.", "labels": [], "entities": [{"text": "recall", "start_pos": 23, "end_pos": 29, "type": "METRIC", "confidence": 0.9997265934944153}, {"text": "precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.996367335319519}]}], "tableCaptions": []}