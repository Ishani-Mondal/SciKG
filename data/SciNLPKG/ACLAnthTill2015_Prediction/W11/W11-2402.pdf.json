{"title": [{"text": "Towards a Probabilistic Model for Lexical Entailment", "labels": [], "entities": [{"text": "Lexical Entailment", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.8808338344097137}]}], "abstractContent": [{"text": "While modeling entailment at the lexical-level is a prominent task, addressed by most textual entailment systems, it has been approached mostly by heuristic methods, neglecting some of its important aspects.", "labels": [], "entities": []}, {"text": "We present a prob-abilistic approach for this task which covers aspects such as differentiating various resources by their reliability levels, considering the length of the entailed sentence, the number of its covered terms and the existence of multiple evidence for the entailment of a term.", "labels": [], "entities": []}, {"text": "The impact of our model components is validated by evaluations, which also show that its performance is inline with the best published entailment systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Textual Entailment was proposed as a generic paradigm for applied semantic inference ).", "labels": [], "entities": [{"text": "Textual Entailment", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7250857800245285}]}, {"text": "Given two textual fragments, termed hypothesis (H) and text (T ), the text is said to textually entail the hypothesis (T\u2192 H) if a person reading the text can infer the meaning of the hypothesis.", "labels": [], "entities": []}, {"text": "Since it was first introduced, the six rounds of the Recognizing Textual Entailment (RTE) challenges have become a standard benchmark for entailment systems.", "labels": [], "entities": [{"text": "Recognizing Textual Entailment (RTE)", "start_pos": 53, "end_pos": 89, "type": "TASK", "confidence": 0.7231585681438446}]}, {"text": "Entailment systems apply various techniques to tackle this task, including logical inference (, semantic analysis ( and syntactic parsing ().", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 96, "end_pos": 113, "type": "TASK", "confidence": 0.8115202188491821}, {"text": "syntactic parsing", "start_pos": 120, "end_pos": 137, "type": "TASK", "confidence": 0.7170712947845459}]}, {"text": "Inference at these levels usually requires substantial processing and resources, aiming at high performance.", "labels": [], "entities": []}, {"text": "Nevertheless, simple lexical level entailment systems pose strong baselines which most complex entailment systems did not outperform (.", "labels": [], "entities": []}, {"text": "Additionally, within a complex system, lexical entailment modeling is one of the most effective component.", "labels": [], "entities": [{"text": "lexical entailment modeling", "start_pos": 39, "end_pos": 66, "type": "TASK", "confidence": 0.6903428236643473}]}, {"text": "Finally, the simpler lexical approach can be used in cases where complex systems cannot be used, e.g. when there is no parser fora targeted language.", "labels": [], "entities": []}, {"text": "For these reasons lexical entailment systems are widely used.", "labels": [], "entities": []}, {"text": "They derive sentence-level entailment decision base on lexical-level entailment evidence.", "labels": [], "entities": []}, {"text": "Typically, this is done by quantifying the degree of lexical coverage of the hypothesis terms by the text terms (where a term maybe multi-word).", "labels": [], "entities": []}, {"text": "A hypothesis term is covered by a text term if either they are identical (possibly at the stem or lemma level) or there is a lexical entailment rule suggesting the entailment of the former by the latter.", "labels": [], "entities": []}, {"text": "Such rules are derived from lexical semantic resources, such as WordNet, which capture lexical entailment relations.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 64, "end_pos": 71, "type": "DATASET", "confidence": 0.9579935073852539}]}, {"text": "Common heuristics for quantifying the degree of coverage are setting a threshold on the percentage of coverage of H's terms, counting the absolute number of uncovered terms, or applying an Information Retrieval-style vector space similarity score).", "labels": [], "entities": [{"text": "Information Retrieval-style vector space similarity score", "start_pos": 189, "end_pos": 246, "type": "TASK", "confidence": 0.626813272635142}]}, {"text": "Other works) have applied heuristic formu-las to estimate the similarity between text fragments based on a similarity function between their terms.", "labels": [], "entities": []}, {"text": "The above mentioned methods do not capture several important aspects of entailment.", "labels": [], "entities": []}, {"text": "Such aspects include the varying reliability levels of entailment resources and the impact of rule chaining and multiple evidence on entailment likelihood.", "labels": [], "entities": [{"text": "rule chaining", "start_pos": 94, "end_pos": 107, "type": "TASK", "confidence": 0.7774996757507324}]}, {"text": "An additional observation from these and other systems is that their performance improves only moderately when utilizing lexical-semantic resources 2 . We believe that the textual entailment field would benefit from more principled models for various entailment phenomena.", "labels": [], "entities": []}, {"text": "In this work we formulate a concrete generative probabilistic modeling framework that captures the basic aspects of lexical entailment.", "labels": [], "entities": [{"text": "generative probabilistic modeling", "start_pos": 37, "end_pos": 70, "type": "TASK", "confidence": 0.8167596459388733}]}, {"text": "A first step in this direction was proposed in Shnarch et al.", "labels": [], "entities": []}, {"text": "(2011) (a short paper), where we presented abase model with a somewhat complicated and difficult to estimate extension to handle coverage.", "labels": [], "entities": []}, {"text": "This paper extends that work to a more mature model with new extensions.", "labels": [], "entities": []}, {"text": "We first consider the \"logical\" structure of lexical entailment reasoning and then interpret it in probabilistic terms.", "labels": [], "entities": [{"text": "lexical entailment reasoning", "start_pos": 45, "end_pos": 73, "type": "TASK", "confidence": 0.6779066820939382}]}, {"text": "Over this base model we suggest several extensions whose significance is then assessed by our evaluations.", "labels": [], "entities": []}, {"text": "Learning the parameters of a lexical model poses a challenge since there are no lexical-level entailment annotations.", "labels": [], "entities": []}, {"text": "We do, however, have sentence-level annotations available for the RTE data sets.", "labels": [], "entities": [{"text": "RTE data sets", "start_pos": 66, "end_pos": 79, "type": "DATASET", "confidence": 0.9267465074857076}]}, {"text": "To bridge this gap, we formulate an instance of the EM algorithm to estimate hidden lexical-level entailment parameters from sentence-level annotations.", "labels": [], "entities": []}, {"text": "Overall, we suggest that the main contribution of this paper is in presenting a probabilistic model for lexical entailment.", "labels": [], "entities": [{"text": "lexical entailment", "start_pos": 104, "end_pos": 122, "type": "TASK", "confidence": 0.7182822823524475}]}, {"text": "Such a model can better integrate entailment indicators and has the advantage of being able to utilize well-founded probabilistic methods such as the EM algorithm.", "labels": [], "entities": []}, {"text": "Our model's performance is inline with the best entailment systems, while opening up directions for future improvements.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Evaluation of the impact of resources and chaining.", "labels": [], "entities": []}, {"text": " Table 2: Impact of model components.", "labels": [], "entities": []}, {"text": " Table 3: A parameter set of the full model which maximizes", "labels": [], "entities": []}]}