{"title": [{"text": "Extracting Parallel Phrases from Comparable Data", "labels": [], "entities": [{"text": "Extracting Parallel Phrases from Comparable Data", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.826439619064331}]}], "abstractContent": [{"text": "Mining parallel data from comparable corpora is a promising approach for overcoming the data sparseness in statistical machine translation and other NLP applications.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 107, "end_pos": 138, "type": "TASK", "confidence": 0.7226233383019766}]}, {"text": "Even if two comparable documents have few or no parallel sentence pairs, there is still potential for parallelism in the sub-sentential level.", "labels": [], "entities": []}, {"text": "The ability to detect these phrases creates a valuable resource, especially for low-resource languages.", "labels": [], "entities": []}, {"text": "In this paper we explore three phrase alignment approaches to detect parallel phrase pairs embedded in comparable sentences: the standard phrase extraction algorithm , which relies on the Viterbi path; a phrase extraction approach that does not rely on the Viterbi path, but uses only lexical features ; and a binary classifier that detects parallel phrase pairs when presented with a large collection of phrase pair candidates.", "labels": [], "entities": [{"text": "phrase alignment", "start_pos": 31, "end_pos": 47, "type": "TASK", "confidence": 0.7646753191947937}, {"text": "phrase extraction", "start_pos": 138, "end_pos": 155, "type": "TASK", "confidence": 0.7690434455871582}, {"text": "phrase extraction", "start_pos": 204, "end_pos": 221, "type": "TASK", "confidence": 0.7933517098426819}]}, {"text": "We evaluate the effectiveness of these approaches in detecting alignments for phrase pairs that have a known alignment in comparable sentence pairs.", "labels": [], "entities": []}, {"text": "The results show that the Non-Viterbi alignment approach outperforms the other two approaches on F1 measure.", "labels": [], "entities": [{"text": "F1", "start_pos": 97, "end_pos": 99, "type": "METRIC", "confidence": 0.9962427616119385}]}], "introductionContent": [{"text": "Statistical Machine Translation (SMT), like many natural language processing tasks, relies primarily on parallel corpora.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8661540846029917}]}, {"text": "The translation performance of SMT systems directly depends on the quantity and the quality of the available parallel data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.993421733379364}]}, {"text": "However, such corpora are only available in large quantities fora handful of languages, including English, Arabic, Chinese and some European languages.", "labels": [], "entities": []}, {"text": "Much of this data is derived from parliamentary proceedings, though a limited amount of newswire text is also available.", "labels": [], "entities": []}, {"text": "For most other languages, especially for less commonly used languages, parallel data is virtually non-existent.", "labels": [], "entities": []}, {"text": "Comparable corpora provide a possible solution to this data sparseness problem.", "labels": [], "entities": []}, {"text": "Comparable documents are not strictly parallel, but contain rough translations of each other, with overlapping information.", "labels": [], "entities": []}, {"text": "A good example for comparable documents is the newswire text produced by multilingual news organizations such as AFP or Reuters.", "labels": [], "entities": []}, {"text": "The degree of parallelism can vary greatly, ranging from noisy parallel documents that contain many parallel sentences, to quasi parallel documents that may cover different topics ().", "labels": [], "entities": []}, {"text": "The Web is by far the largest source of comparable data.", "labels": [], "entities": []}, {"text": "exploit the similarities in URL structure, document structure and other clues for mining the Web for parallel documents.", "labels": [], "entities": []}, {"text": "Wikipedia has become an attractive source of comparable documents in more recent work).", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9375748634338379}]}, {"text": "Comparable corpora may contain parallel data in different levels of granularity.", "labels": [], "entities": []}, {"text": "This includes: parallel documents, parallel sentence pairs, or parallel sub-sentential fragments.", "labels": [], "entities": []}, {"text": "To simplify the process and reduce the computational overhead, the parallel sentence extraction is typically divided into two tasks.", "labels": [], "entities": [{"text": "parallel sentence extraction", "start_pos": 67, "end_pos": 95, "type": "TASK", "confidence": 0.6703002055486044}]}, {"text": "First, a document level alignment is identified between comparable documents, and second, the parallel sentences are detected within the identified document pairs.", "labels": [], "entities": []}, {"text": "Cross-lingual information retrieval methods (Munteanu and) and other similarity measures ( have been used for the document alignment task.", "labels": [], "entities": [{"text": "Cross-lingual information retrieval", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.6473918557167053}, {"text": "document alignment task", "start_pos": 114, "end_pos": 137, "type": "TASK", "confidence": 0.8525940974553426}]}, {"text": "have extended parallel sentence alignment algorithms to identify parallel sentence pairs within comparable news corpora.", "labels": [], "entities": [{"text": "parallel sentence alignment", "start_pos": 14, "end_pos": 41, "type": "TASK", "confidence": 0.6558466951052347}]}, {"text": "Tillmann and Xu (2009) introduced a system that performs both tasks in a single run without any document level pre-filtering.", "labels": [], "entities": []}, {"text": "Such a system is useful when document level boundaries are not available in the comparable corpus.", "labels": [], "entities": []}, {"text": "Even if two comparable documents have few or no parallel sentence pairs, there could still be parallel sub-sentential fragments, including word translation pairs, named entities, and long phrase pairs.", "labels": [], "entities": [{"text": "word translation pairs", "start_pos": 139, "end_pos": 161, "type": "TASK", "confidence": 0.7693366905053457}]}, {"text": "The ability to identify these pairs would create a valuable resource for SMT, especially for low-resource languages.", "labels": [], "entities": [{"text": "SMT", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.9955517649650574}]}, {"text": "The first attempt to detect sub-sentential fragments from comparable sentences is ().", "labels": [], "entities": []}, {"text": "later extended this work by proposing two generative models for comparable sentences and showed improvements when applied to cross-domain test data.", "labels": [], "entities": []}, {"text": "In both these approaches the extracted fragment data was used as additional training data to train alignment models.", "labels": [], "entities": []}, {"text": "have proposed a phrasal alignment approach for comparable corpora using the joint probability SMT model.", "labels": [], "entities": []}, {"text": "While this approach is appealing for low-resource scenarios as it does not require any seed parallel corpus, the high computational cost is a deterrent in its applicability to large corpora.", "labels": [], "entities": []}, {"text": "In this paper we explore several phrase alignment approaches to detect parallel phrase pairs embedded in comparable sentence pairs.", "labels": [], "entities": [{"text": "phrase alignment", "start_pos": 33, "end_pos": 49, "type": "TASK", "confidence": 0.7864347398281097}]}, {"text": "We assume that comparable sentence pairs have already been detected.", "labels": [], "entities": []}, {"text": "Our intention is to use the extracted phrases directly in the translation process, along with other phrase pairs extracted from parallel corpora.", "labels": [], "entities": []}, {"text": "In particular, we study three alignment approaches: \u2022 the standard phrase extraction algorithm, which relies on the Viterbi path of the word alignment; \u2022 a phrase extraction approach that does not rely on the Viterbi path, but only uses lexical features; \u2022 and a binary classifier to detect parallel phrase pairs when presented with a large collection of phrase pair candidates.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 67, "end_pos": 84, "type": "TASK", "confidence": 0.7619422972202301}, {"text": "phrase extraction", "start_pos": 156, "end_pos": 173, "type": "TASK", "confidence": 0.787968635559082}]}, {"text": "We evaluate the effectiveness of these approaches in detecting alignments for phrase pairs that have a known translation a comparable sentence pair.", "labels": [], "entities": []}, {"text": "Section 2 introduces the phrase alignment problem in comparable sentences and discusses some of the challenges involved.", "labels": [], "entities": [{"text": "phrase alignment", "start_pos": 25, "end_pos": 41, "type": "TASK", "confidence": 0.8025605380535126}]}, {"text": "It also explains the different alignment approaches we explore.", "labels": [], "entities": []}, {"text": "Section 3 presents the experimental setup and the results of the evaluation.", "labels": [], "entities": []}, {"text": "We conclude, in section 4, with an analysis of the results and some directions for future work.", "labels": [], "entities": []}, {"text": "shows three sample sentences that were extracted from Gigaword Arabic and Gigaword English collections.", "labels": [], "entities": [{"text": "Gigaword English collections", "start_pos": 74, "end_pos": 102, "type": "DATASET", "confidence": 0.8525445858637491}]}, {"text": "For each comparable sentence pair, the Arabic sentence is shown first, followed by its literal English translation (in Italics).", "labels": [], "entities": []}, {"text": "The English sentence is shown next.", "labels": [], "entities": []}, {"text": "The parallel sections in each sentence are marked in boldface.", "labels": [], "entities": []}, {"text": "In the first two sentences pairs, the English sentence contains the full translation of the Arabic sentence, but there are additional phrases on the English side that are not present on the Arabic sentence.", "labels": [], "entities": []}, {"text": "These phrases appear at the beginning of sentence 1 and at the end of sentence 2.", "labels": [], "entities": []}, {"text": "In sentence 3, there are parallel phrases as well as phrases that appear only on one side.", "labels": [], "entities": []}, {"text": "The phrase \"to Iraq\" appears only on the Arabic sentence while the phrase \"the former Egyptian foreign minister\" appears only on the English side.", "labels": [], "entities": []}, {"text": "Standard word alignment and phrase alignment algorithms are formulated to work on parallel sentence pairs.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.7351331114768982}, {"text": "phrase alignment", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.7715953588485718}]}, {"text": "Therefore, these standard algorithms are not well suited to operate on partially parallel sentence pairs.", "labels": [], "entities": []}, {"text": "Presence of non-parallel phrases may result in undesirable alignments.", "labels": [], "entities": []}, {"text": "It compares atypical word alignment pattern in a parallel sentence pair (a) to one in a non-parallel sentence pair (b).", "labels": [], "entities": [{"text": "word alignment", "start_pos": 21, "end_pos": 35, "type": "TASK", "confidence": 0.703763797879219}]}, {"text": "The darkness of a square indicates the strength of the word alignment probability between the corresponding word pair.", "labels": [], "entities": []}, {"text": "In 2(a), we observe high probability word-to-word alignments (dark squares) over the entire length of the sentences.", "labels": [], "entities": []}, {"text": "In 2(b), we see one dark area above \"weapons of mass destruction\", corresponding to the parallel phrase pair, and some scattered dark spots, where high frequency English words pair with high frequency Arabic words.", "labels": [], "entities": []}, {"text": "This spurious alignments pose problems to the phrase alignment, and indicate that word alignment probabilities alone might not be sufficient.", "labels": [], "entities": [{"text": "phrase alignment", "start_pos": 46, "end_pos": 62, "type": "TASK", "confidence": 0.6928028613328934}]}, {"text": "Our aim is to identify such parallel phrase pairs from comparable sentence pairs.", "labels": [], "entities": []}, {"text": "In the following subsections we briefly explain the different phrase alignment approaches we use.", "labels": [], "entities": [{"text": "phrase alignment", "start_pos": 62, "end_pos": 78, "type": "TASK", "confidence": 0.7499161660671234}]}], "datasetContent": [{"text": "We conducted our experiments on Arabic-English language pair.", "labels": [], "entities": []}, {"text": "We obtained manual alignments for 663 Arabic-English sentence pairs.", "labels": [], "entities": []}, {"text": "From this, we selected 300 sentences, and extracted phrase pairs up to 10 words long that are consistent with the underlying word alignment.", "labels": [], "entities": []}, {"text": "From the resulting list of phrase pairs, we removed the 50 most frequently occurring pairs as well as those only consisting of punctuations.", "labels": [], "entities": []}, {"text": "Almost all high frequency phrases are function words, which are typically covered by the translation lexicon.", "labels": [], "entities": []}, {"text": "Line 1 in gives the ngram type distribution for the source phrases.", "labels": [], "entities": []}, {"text": "Using the phrase pairs extracted from the manually aligned sentences, we constructed a comparable corpus as follows: 1.", "labels": [], "entities": []}, {"text": "For each Arabic phrase, we search the Arabic Gigaword 1 corpus for sentences that contain the phrase and select up to 5 sentences.", "labels": [], "entities": [{"text": "Arabic Gigaword 1 corpus", "start_pos": 38, "end_pos": 62, "type": "DATASET", "confidence": 0.7530964463949203}]}, {"text": "Similarly, for each corresponding English phrase we select up to 5 sentences from English Gigaword 2 . 2. For each phrase pair, we generate the Cartesian product of the sentences and produce a sentence pair collection.", "labels": [], "entities": []}, {"text": "I.e. up to 25 comparable sentence pairs were constructed for each phrase pair.", "labels": [], "entities": []}, {"text": "3. We only select sentences up to 100 words long, resulting in a final comparable corpus consisting of 170K sentence pairs.", "labels": [], "entities": []}, {"text": "Line 2 in gives the n-gram type distribution for the phrase pairs for which we found both a source sentence and a target sentence in the monolingual corpora.", "labels": [], "entities": []}, {"text": "As expected, the longer the phrases, the less likely it is to find them in even larger corpora.", "labels": [], "entities": []}, {"text": "We consider the resulting set as our comparable corpus which we will use to evaluate all alignment approaches.", "labels": [], "entities": []}, {"text": "In most sentence pairs, except for the phrase pair that we are interested in, the rest of the sentence does not typically match the other side.", "labels": [], "entities": []}, {"text": "We obtained the Viterbi alignment using standard word alignment techniques: IBM4 word alignment for both directions, Viterbi path combination using heuristics ('grow-diag-final') and phrase extraction from two-sided training, as implemented in the Moses package (.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 49, "end_pos": 63, "type": "TASK", "confidence": 0.7107727080583572}, {"text": "IBM4 word alignment", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.8280784885088602}, {"text": "phrase extraction", "start_pos": 183, "end_pos": 200, "type": "TASK", "confidence": 0.7889674305915833}]}, {"text": "Because the non-parallel segments will lead the word alignment astray, this may have a negative effect on the alignment in the parallel sections.", "labels": [], "entities": []}, {"text": "Alignment models trained on parallel data are used to generate the Viterbi alignment for the comparable sentences.", "labels": [], "entities": []}, {"text": "We then extract the target phrases that are aligned to the embedded source phrases.", "labels": [], "entities": []}, {"text": "A phrase pair is extracted only when the alignment does not conflict with other word alignments in the sentence pair.", "labels": [], "entities": []}, {"text": "The alignments are not constrained to produce contiguous phrases.", "labels": [], "entities": []}, {"text": "We allow unaligned words to be present in the phrase pair.", "labels": [], "entities": []}, {"text": "For each source phrase we selected the target phrase that has the least number of unaligned words.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: N-gram type distribution of manually aligned phrases set", "labels": [], "entities": []}, {"text": " Table 2: Results for Alignment Evaluation of test phrases", "labels": [], "entities": [{"text": "Alignment Evaluation", "start_pos": 22, "end_pos": 42, "type": "TASK", "confidence": 0.8910249173641205}]}]}