{"title": [{"text": "Structured Databases of Named Entities from Bayesian Nonparametrics", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a nonparametric Bayesian approach to extract a structured database of entities from text.", "labels": [], "entities": []}, {"text": "Neither the number of entities nor the fields that characterize each entity are provided in advance; the only supervision is a set of five prototype examples.", "labels": [], "entities": []}, {"text": "Our method jointly accomplishes three tasks: (i) identifying a set of canonical entities, (ii) inferring a schema for the fields that describe each entity, and (iii) matching entities to their references in raw text.", "labels": [], "entities": []}, {"text": "Empirical evaluation shows that the approach learns an accurate database of entities and a sensible model of name structure.", "labels": [], "entities": []}], "introductionContent": [{"text": "Consider the task of building a set of structured records from a collection of text: for example, extracting the names of people or businesses from blog posts, where each full name decomposes into fields corresponding to first-name, last-name, title, etc.", "labels": [], "entities": [{"text": "extracting the names of people or businesses from blog posts", "start_pos": 98, "end_pos": 158, "type": "TASK", "confidence": 0.8498796403408051}]}, {"text": "To instruct a person to perform this task, one might begin with a few examples of the records to be obtained; assuming that the mapping from text to records is relatively straightforward, no additional instruction would be necessary.", "labels": [], "entities": []}, {"text": "In this paper, we present a method for training information extraction software in the same way: starting from a small table of partially-complete \"prototype\" records, our system learns to add new entries and fields to the table, while simultaneously aligning the records to text.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 48, "end_pos": 70, "type": "TASK", "confidence": 0.7246857136487961}]}, {"text": "We assume that the dimensionality of the database is unknown, so that neither the number of entries", "labels": [], "entities": []}], "datasetContent": [{"text": "Our model jointly performs three tasks: identifying a set of entities, discovering the set of fields, and matching mention strings with the entities and fields to which they refer.", "labels": [], "entities": []}, {"text": "We are aware of no prior work that performs these tasks jointly, nor any dataset that is annotated for all three tasks.", "labels": [], "entities": []}, {"text": "Consequently, we focus our quantitative evaluation on what we take to be the most important subtask: identifying the entities which are mentioned in raw text.", "labels": [], "entities": []}, {"text": "We annotate anew dataset of blog text for this purpose, and design precision and recall metrics to reward systems that recover as much of the reference set as possible, while avoiding spurious entities and fields.", "labels": [], "entities": [{"text": "precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.9986166954040527}, {"text": "recall", "start_pos": 81, "end_pos": 87, "type": "METRIC", "confidence": 0.9961234927177429}]}, {"text": "We also perform a qualitative analysis, noting the areas where our method outperforms string matching approaches, and where there is need for further improvement.", "labels": [], "entities": [{"text": "string matching", "start_pos": 86, "end_pos": 101, "type": "TASK", "confidence": 0.726319283246994}]}, {"text": "Data Evaluation was performed on a corpus of blogs describing United States politics in.", "labels": [], "entities": []}, {"text": "We ran the Stanford Named Entity Recognition system () to obtain a set of 25,000 candidate mentions which the system judged to be names of people.", "labels": [], "entities": [{"text": "Stanford Named Entity Recognition", "start_pos": 11, "end_pos": 44, "type": "TASK", "confidence": 0.7272866666316986}]}, {"text": "We then pruned strings that appeared fewer than four times and eliminated strings with more than seven tokens (these were usually errors).", "labels": [], "entities": []}, {"text": "The resulting dataset has 19,247 mentions comprising 45,466 word tokens, and 813 unique mention strings.", "labels": [], "entities": []}, {"text": "Gold standard We develop a reference set of 100 entities for evaluation.", "labels": [], "entities": []}, {"text": "This set was created by sorting the unique name strings in the training set by frequency, and manually merging strings that reference the same entity.", "labels": [], "entities": []}, {"text": "We also manually discarded strings from the reference set if they resulted from errors in the preprocessing pipeline (tokenization and named entity recognition).", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 135, "end_pos": 159, "type": "TASK", "confidence": 0.6562996506690979}]}, {"text": "Each entity is represented by the set of all word tokens that appear in its references; there area total of 231 tokens for the 100 entities.", "labels": [], "entities": []}, {"text": "Most entities only include first and last names, though the most frequent entities have many more: for example, the entity Barack Obama has known names: {Barack, Obama, Sen., Mr.}.", "labels": [], "entities": []}], "tableCaptions": []}