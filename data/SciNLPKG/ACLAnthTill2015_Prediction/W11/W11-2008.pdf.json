{"title": [{"text": "Spoken Dialogue System based on Information Extraction using Similarity of Predicate Argument Structures", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.6998291909694672}]}], "abstractContent": [{"text": "We present a novel scheme of spoken dialogue systems which uses the up-to-date information on the web.", "labels": [], "entities": []}, {"text": "The scheme is based on information extraction which is defined by the predicate-argument (P-A) structure and realized by semantic parsing.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.8112378120422363}, {"text": "semantic parsing", "start_pos": 121, "end_pos": 137, "type": "TASK", "confidence": 0.7315041124820709}]}, {"text": "Based on the information structure, the dialogue system can perform question answering and also proac-tive information presentation.", "labels": [], "entities": [{"text": "question answering", "start_pos": 68, "end_pos": 86, "type": "TASK", "confidence": 0.817606657743454}, {"text": "proac-tive information presentation", "start_pos": 96, "end_pos": 131, "type": "TASK", "confidence": 0.6039524674415588}]}, {"text": "Feasibility of this scheme is demonstrated with experiments using a domain of baseball news.", "labels": [], "entities": []}, {"text": "In order to automatically select useful domain-dependent P-A templates, statistical measures are introduced , resulting to a completely unsupervised learning of the information structure given a corpus.", "labels": [], "entities": []}, {"text": "Similarity measures of P-A structures are also introduced to select relevant information.", "labels": [], "entities": []}, {"text": "An experimental evaluation shows that the proposed system can make more relevant responses compared with the conventional \"bag-of-words\" scheme.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently, a huge amount of information is accumulated and distributed on the web day by day.", "labels": [], "entities": []}, {"text": "As a result, many people get information via web rather than the conventional mass media.", "labels": [], "entities": []}, {"text": "On the other hand, the amount of information on the web is so huge that we often encounter the difficulty in finding information we want.", "labels": [], "entities": []}, {"text": "Keyword search is the most widely-used means for the web information access.", "labels": [], "entities": [{"text": "Keyword search", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.6689682751893997}]}, {"text": "However, this style is not necessarily the best for information demands of all users who do not have definite goals or just want to know what would be interesting.", "labels": [], "entities": []}, {"text": "To cope with user's vague information demands is an important mission for interactive spoken dialogue systems.", "labels": [], "entities": []}, {"text": "Moreover, supporting user's information collection in a small-talk style is one of the new directions of spoken dialogue systems.", "labels": [], "entities": [{"text": "user's information collection", "start_pos": 21, "end_pos": 50, "type": "TASK", "confidence": 0.6742986142635345}]}, {"text": "Existing spoken dialogue systems can be classified into two types (T.: those using relational databases (RDB) such as the Airline Travel Information System (ATIS), and those using information retrieval techniques based on statistical document matching (T..", "labels": [], "entities": [{"text": "Airline Travel Information System (ATIS)", "start_pos": 122, "end_pos": 162, "type": "DATASET", "confidence": 0.8426115087100438}, {"text": "statistical document matching", "start_pos": 222, "end_pos": 251, "type": "TASK", "confidence": 0.6689394116401672}]}, {"text": "The first scheme can achieve a well-defined task by using a structural database, but this scheme cannot be applied to the web information in which the structure and task are not well defined.", "labels": [], "entities": []}, {"text": "The second scheme has been studied to handle large-scale texts such as web, but most of the conventional systems adopt a \"bag-ofwords\" model, and naive statistical matching often generates irrelevant responses which have nothing to do with the user's requests.", "labels": [], "entities": []}, {"text": "Our proposed scheme solves this problem by using information extraction based on semantic parsing from web texts, without constructing an RDB.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 49, "end_pos": 71, "type": "TASK", "confidence": 0.7298774421215057}, {"text": "semantic parsing from web texts", "start_pos": 81, "end_pos": 112, "type": "TASK", "confidence": 0.8218077182769775}]}, {"text": "We adopt the predicateargument (P-A) structure generated by a parser as a baseline, but every P-A structure is not useful for information extraction and retrieval(Y.; M.O.).", "labels": [], "entities": [{"text": "information extraction and retrieval", "start_pos": 126, "end_pos": 162, "type": "TASK", "confidence": 0.715275801718235}]}, {"text": "In fact, the useful information structure is dependent on domains.", "labels": [], "entities": []}, {"text": "Conventionally, the templates for information extraction were hand-crafted (R., but this heuristic process is so costly that it cannot be applied to a variety of domains on the web.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.8257019519805908}]}, {"text": "In this paper, therefore, we pro- pose a filtering method of predicate-argument (P-A) patterns generated by the parser, in order to automatically define the domain-dependent useful information structure.", "labels": [], "entities": []}, {"text": "We also address flexible matching based on the P-A structure, because the exact matching often fails and does not generate any outputs.", "labels": [], "entities": []}, {"text": "In order to retrieve most relevant information, we define similarity measures of predicates and arguments, which are also learned from a domain corpus.", "labels": [], "entities": []}, {"text": "In this paper, the proposed scheme is applied to a domain of baseball news, and implemented as a spoken dialogue system which can reply to the user's question as well as make proactive information presentation using a news website.", "labels": [], "entities": []}, {"text": "An overview of this system is described in Section 2, and the template filtering method is presented in Section 3.", "labels": [], "entities": []}, {"text": "Then, system response generation based on flexible matching is explained in Section 4.", "labels": [], "entities": [{"text": "system response generation", "start_pos": 6, "end_pos": 32, "type": "TASK", "confidence": 0.7412474552790324}]}, {"text": "Finally, an evaluation of the system is presented in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed an experimental evaluation to compare the effectiveness of the two significance measures (TF-IDF and Naive Bayes (NB)) in the Japanese professional baseball domain.", "labels": [], "entities": [{"text": "Naive Bayes (NB))", "start_pos": 114, "end_pos": 131, "type": "METRIC", "confidence": 0.6027880668640136}]}, {"text": "The models are trained with the Mainichi Newspaper corpus 2008.", "labels": [], "entities": [{"text": "Mainichi Newspaper corpus 2008", "start_pos": 32, "end_pos": 62, "type": "DATASET", "confidence": 0.9786713868379593}]}, {"text": "The clustering of named entities is applied to both methods.", "labels": [], "entities": [{"text": "clustering of named entities", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.8447965979576111}]}, {"text": "The P-A templates having larger significance scores are selected.", "labels": [], "entities": []}, {"text": "We determined a threshold for selecting templates using a development set which was held out from the test set by 10%.", "labels": [], "entities": []}, {"text": "The test set was made from Mainichi newspaper's website which talks about games played between April 21-23, 2010.", "labels": [], "entities": [{"text": "Mainichi newspaper's website", "start_pos": 27, "end_pos": 55, "type": "DATASET", "confidence": 0.9798852503299713}]}, {"text": "Manual annotation was made on typical predicates and semantic cases which can be used for question answering and proactive presentation.", "labels": [], "entities": [{"text": "question answering", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.8867344558238983}, {"text": "proactive presentation", "start_pos": 113, "end_pos": 135, "type": "TASK", "confidence": 0.6972735822200775}]}, {"text": "The filtering was performed on the test set by matching the patterns defined by each measure, and evaluated against the annotated answers in terms of recall, precision and F-measure (F).", "labels": [], "entities": [{"text": "recall", "start_pos": 150, "end_pos": 156, "type": "METRIC", "confidence": 0.9994271993637085}, {"text": "precision", "start_pos": 158, "end_pos": 167, "type": "METRIC", "confidence": 0.9985826015472412}, {"text": "F-measure (F)", "start_pos": 172, "end_pos": 185, "type": "METRIC", "confidence": 0.9504640102386475}]}, {"text": "lists the result for the two measures using predicate-only, argument-only, and both of them.", "labels": [], "entities": []}, {"text": "In this result, using both predicates and arguments in the Naive Bayes (NB) model performs the best.", "labels": [], "entities": []}, {"text": "Compared with the baseline without any filtering, the proposed methods significantly improved precision with some degradation of recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9994320273399353}, {"text": "recall", "start_pos": 129, "end_pos": 135, "type": "METRIC", "confidence": 0.9988516569137573}]}, {"text": "This property is important in realizing informative response generation robust against ASR and parsing errors.", "labels": [], "entities": [{"text": "informative response generation", "start_pos": 40, "end_pos": 71, "type": "TASK", "confidence": 0.6645795404911041}, {"text": "ASR", "start_pos": 87, "end_pos": 90, "type": "TASK", "confidence": 0.9837735891342163}, {"text": "parsing", "start_pos": 95, "end_pos": 102, "type": "TASK", "confidence": 0.9205988645553589}]}, {"text": "Among the selected templates, we can find typical and important patterns like \"have a win\", \"come into pitch\", and \"make it consecutive wins\".", "labels": [], "entities": []}, {"text": "Most of recall errors are infrequent patterns, and majority of precision errors are those patterns that are frequently observed but not useful for presentation.", "labels": [], "entities": [{"text": "recall errors", "start_pos": 8, "end_pos": 21, "type": "METRIC", "confidence": 0.9778399467468262}, {"text": "precision errors", "start_pos": 63, "end_pos": 79, "type": "METRIC", "confidence": 0.9858246743679047}]}, {"text": "We have implemented a spoken dialogue system based on the significance measure (Naive Bayes model) and the relevance measures, which were learned using the Mainichi Newspaper corpus often years.", "labels": [], "entities": [{"text": "Mainichi Newspaper corpus", "start_pos": 156, "end_pos": 181, "type": "DATASET", "confidence": 0.9913276831309}]}, {"text": "For evaluation of the system, we prepared 201 questions from news articles (September 19-26, 2010) seen at the website of Mainichi Newspaper 2 . Correct answers to the test queries were annotated manually.", "labels": [], "entities": [{"text": "Mainichi Newspaper 2", "start_pos": 122, "end_pos": 142, "type": "DATASET", "confidence": 0.9746928413709005}]}, {"text": "Evaluation was done with the text input as well as speech input.", "labels": [], "entities": []}, {"text": "A word Ngram language model for ASR dedicated to the domain was trained using the relevant newspaper article corpus.", "labels": [], "entities": [{"text": "ASR", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.9940939545631409}, {"text": "newspaper article corpus", "start_pos": 91, "end_pos": 115, "type": "DATASET", "confidence": 0.7687487403551737}]}, {"text": "The word error rate was approximately 24%.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 4, "end_pos": 19, "type": "METRIC", "confidence": 0.721105714639028}]}, {"text": "The system responses for the test queries are categorized into one of the following four: correct answer only (\"Correct\"), case which includes the correct answer but also other redundant answers (\"Ambiguous\"), incorrect answer (\"Incorrect\"), and (\"No Answer\").", "labels": [], "entities": [{"text": "Correct", "start_pos": 112, "end_pos": 119, "type": "METRIC", "confidence": 0.7581222653388977}]}, {"text": "The ambiguous cases occur when multiple sentences or predicates are matched.", "labels": [], "entities": []}, {"text": "We also calculate recall, precision and F-measure by counting individual answers separately even when multiple answers are output.", "labels": [], "entities": [{"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9995487332344055}, {"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.999643087387085}, {"text": "F-measure", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9994267225265503}]}, {"text": "The results based on these evaluation measures are summarized in for text input and speech input.", "labels": [], "entities": []}, {"text": "In the tables, the proposed method is broken down into three phases as shown in: exact matching of P-A structure (Section 3), incorporation of the partial matching (Section 4.1), and back-off to the \"bag-of-words\" (BOW) model (Section 4.4).", "labels": [], "entities": []}, {"text": "For comparison, we also tested the BOW model and  \"sequence-of-words\" (SOW) model, which consider the sequence order in the BOW model.", "labels": [], "entities": [{"text": "BOW", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.634813666343689}]}, {"text": "The exact matching assumes strong constraint of P-A patterns, so the generated answers are almost correct, but no answers are generated very often.", "labels": [], "entities": []}, {"text": "By incorporating the partial matching and BOW model, the system can output more relevant answers.", "labels": [], "entities": [{"text": "BOW", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.9974676370620728}]}, {"text": "Compared with the BOW model, the proposed method achieves much higher ratio or precision of correct answers.", "labels": [], "entities": [{"text": "BOW", "start_pos": 18, "end_pos": 21, "type": "METRIC", "confidence": 0.6526694297790527}, {"text": "ratio", "start_pos": 70, "end_pos": 75, "type": "METRIC", "confidence": 0.9872051477432251}, {"text": "precision", "start_pos": 79, "end_pos": 88, "type": "METRIC", "confidence": 0.9968637228012085}]}, {"text": "Fmeasure is also higher by 17% absolute.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9900687336921692}]}, {"text": "A similar tendency is observed for speech input, although the overall accuracy is degraded because of the ASR errors.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 70, "end_pos": 78, "type": "METRIC", "confidence": 0.9994181394577026}, {"text": "ASR", "start_pos": 106, "end_pos": 109, "type": "TASK", "confidence": 0.6351444721221924}]}, {"text": "However, degradation is relatively small considering the word accuracy of 76%.", "labels": [], "entities": [{"text": "degradation", "start_pos": 9, "end_pos": 20, "type": "METRIC", "confidence": 0.9547665119171143}, {"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.964897871017456}]}, {"text": "The partial matching works effectively even if the exact matching fails due to ASR errors.", "labels": [], "entities": [{"text": "ASR", "start_pos": 79, "end_pos": 82, "type": "TASK", "confidence": 0.5838256478309631}]}, {"text": "Moreover, the back-off to the BOW model is effective in ASR input.", "labels": [], "entities": [{"text": "BOW", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.9501043558120728}, {"text": "ASR input", "start_pos": 56, "end_pos": 65, "type": "TASK", "confidence": 0.8939085304737091}]}, {"text": "The proposed method generates concise responses by selecting the relevant portion as described in Section 4.5, while the BOW method often generates long responses which includes many redundant portions.", "labels": [], "entities": [{"text": "BOW", "start_pos": 121, "end_pos": 124, "type": "METRIC", "confidence": 0.8715556263923645}]}, {"text": "This property is particularly important in the speech interface.", "labels": [], "entities": []}, {"text": "We show a dialogue example in which is in Japanese and translated to English for reference (=Italic).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Evaluation of template filtering.", "labels": [], "entities": [{"text": "template filtering", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.7290709167718887}]}, {"text": " Table 2: Evaluation of system response.", "labels": [], "entities": []}, {"text": " Table 3: Accuracy of system response.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9954180717468262}]}]}