{"title": [{"text": "Two Approaches for Generating Size Modifiers", "labels": [], "entities": [{"text": "Size Modifiers", "start_pos": 30, "end_pos": 44, "type": "TASK", "confidence": 0.7789759933948517}]}], "abstractContent": [{"text": "This paper offers a solution to a small problem within a much larger problem.", "labels": [], "entities": []}, {"text": "We focus on modelling how people use size in reference, words like \"big\" and \"tall\", which is one piece within the much larger problem of how people refer to visible objects.", "labels": [], "entities": []}, {"text": "Examining size in isolation allows us to begin untangling a few of the complex and interacting features that affect reference, and we isolate a set of features that maybe used in a hand-coded algorithm or a machine learning approach to generate one of six basic size types.", "labels": [], "entities": []}, {"text": "The hand-coded algorithm generates a modifier type with a high correspondence to those observed inhuman data, and achieves 81.3% accuracy in an entirely new domain.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.9976509213447571}]}, {"text": "This trails oracle accuracy for this task by just 8%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9983910918235779}]}, {"text": "Features used by the hand-coded algorithm are added to a larger set of features in the machine learning approach, and we do not find a statistically significant difference between the precision and recall of the two systems.", "labels": [], "entities": [{"text": "precision", "start_pos": 184, "end_pos": 193, "type": "METRIC", "confidence": 0.9991979002952576}, {"text": "recall", "start_pos": 198, "end_pos": 204, "type": "METRIC", "confidence": 0.996324360370636}]}, {"text": "The input and output of these systems area novel characterization of the factors that affect referring expression generation , and the methods described here may serve as one building block in future work connecting vision to language.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 93, "end_pos": 124, "type": "TASK", "confidence": 0.7014324267705282}]}], "introductionContent": [{"text": "The task of referring expression generation (REG) has often been contextualized as a problem of generating uniquely identifying reference to visible items.", "labels": [], "entities": [{"text": "referring expression generation (REG)", "start_pos": 12, "end_pos": 49, "type": "TASK", "confidence": 0.888636569182078}]}, {"text": "Properties such as COLOR, SIZE, LOCATION, and ORIENTATION have been treated as exemplars of attributes used to distinguish a referent;.", "labels": [], "entities": [{"text": "COLOR", "start_pos": 19, "end_pos": 24, "type": "METRIC", "confidence": 0.9914413690567017}, {"text": "SIZE", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.892785370349884}, {"text": "LOCATION", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9686216115951538}, {"text": "ORIENTATION", "start_pos": 46, "end_pos": 57, "type": "METRIC", "confidence": 0.9919497966766357}]}, {"text": "This paper is no exception.", "labels": [], "entities": []}, {"text": "However, we approach the task of REG by examining in depth what it means to uniquely identify something that is visible.", "labels": [], "entities": [{"text": "REG", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9803343415260315}]}, {"text": "We specifically address the attribute of size and explore ways to connect the dimensional properties of real-world objects to surface forms used by people to pick out a referent.", "labels": [], "entities": []}, {"text": "This work contributes to recent research examining naturalistic reference in visual domains explicitly.", "labels": [], "entities": []}, {"text": "Traditionally, to create an algorithm for the generation of reference, one considers a set of different properties and develops ways to decide which properties to include in a final surface string.", "labels": [], "entities": []}, {"text": "This maybe considered a breadth-based methodology, where many properties are considered, but the details of how those properties are input to the algorithm is left unspecified.", "labels": [], "entities": []}, {"text": "Here, we begin creating an algorithm for the generation of naturalistic reference by considering a single property -size -and tracing how it is realized based on a variety of different inputs and outputs.", "labels": [], "entities": [{"text": "generation of naturalistic reference", "start_pos": 45, "end_pos": 81, "type": "TASK", "confidence": 0.781699150800705}]}, {"text": "This we will calla depth-based methodology.", "labels": [], "entities": []}, {"text": "This is a departure from previous approaches to the construction of an REG algorithm.", "labels": [], "entities": []}, {"text": "Instead of a more general-purpose algorithm, a small set of abstract semantic types are mapped to a variety of surface forms.", "labels": [], "entities": []}, {"text": "This allows us to understand the task of referring expression generation at a finegrained level, analyzing the specific visual characteristics that need to be considered in order to generate reference similar to that produced by people.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 41, "end_pos": 72, "type": "TASK", "confidence": 0.8293319145838419}]}, {"text": "The algorithm is developed for the microplanning stage of a natural language generation system), generating a size type that directly informs lexical choice and surface realization of a final string.", "labels": [], "entities": []}, {"text": "Comparisons made by the algorithm may also be represented as features within classifiers that predict size type, and so we compare the size algorithm with such a method, using decision trees to model human participants' selection of size modifiers.", "labels": [], "entities": []}, {"text": "We introduce two broad size classes, individuating size modifiers and overall size modifiers.", "labels": [], "entities": []}, {"text": "Individuating size modifiers pick out specific configurations of object axes.", "labels": [], "entities": []}, {"text": "Overall size modifiers identify the overall size of an object.", "labels": [], "entities": []}, {"text": "This follows distinctions made in psycholinguistic work on size) that until now have not been formalized.", "labels": [], "entities": []}, {"text": "Each class contains several modifier types, and these map to sets of modifier surface forms.", "labels": [], "entities": []}], "datasetContent": [{"text": "Before testing on the new domain, we test how well the two approaches do on the size corpus.", "labels": [], "entities": []}, {"text": "The con-discy <= 1: no struction of the size algorithm was informed by this corpus, and so this provides a measure of how well the algorithm does in the domain for which it was designed.", "labels": [], "entities": []}, {"text": "The decision trees are evaluated in this domain using leave-one-out validation, where the set of expressions fora referent containing at least one size modifier is tested against the models trained on the size expressions for all other referents.", "labels": [], "entities": []}, {"text": "An example tree is shown in.", "labels": [], "entities": []}, {"text": "Features developed from the hand-coded algorithm (features 16 and 17 in) appear to have high discriminative utility in the trained models.", "labels": [], "entities": []}, {"text": "Unlike the machine learning approach, the size algorithm generates no more than one size type for each referent, although participants may produce several.", "labels": [], "entities": []}, {"text": "To understand the upper bound of both approaches, we therefore implement an oracle method for the size algorithm (ORACLE alg ) that always guesses the most common size type for each referent, and an oracle method for the classifiers (ORACLE tree ) that always guesses the most common set of size types for each referent.", "labels": [], "entities": [{"text": "ORACLE alg )", "start_pos": 114, "end_pos": 126, "type": "METRIC", "confidence": 0.961455225944519}, {"text": "ORACLE", "start_pos": 234, "end_pos": 240, "type": "METRIC", "confidence": 0.9571446180343628}]}, {"text": "To understand the lower bound, we implement a baseline method that guesses the most common size type and most common set of size types in the training data for each testing fold.", "labels": [], "entities": []}, {"text": "We find that the most common set of size types across folds contains a single modifier, making the baseline of the two approaches equivalent.", "labels": [], "entities": []}, {"text": "We evaluate the systems using precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9996310472488403}, {"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9993246793746948}]}, {"text": "Since we are comparing the set of predicted modifiers with the set of modifiers that a description contains, it would have been possible to use the: Precision and recall for models, testing on expressions that contain size.", "labels": [], "entities": [{"text": "Precision", "start_pos": 149, "end_pos": 158, "type": "METRIC", "confidence": 0.9746332764625549}, {"text": "recall", "start_pos": 163, "end_pos": 169, "type": "METRIC", "confidence": 0.9971924424171448}]}, {"text": "The size algorithm is averaged over 5 iterations.", "labels": [], "entities": []}, {"text": "DICE metric, as has often been done in evaluations of REG algorithms.", "labels": [], "entities": [{"text": "DICE", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.8352767825126648}]}, {"text": "But DICE does not distinguish between recall (i.e., modifiers that are not predicted but should have been) and precision (i.e., modifiers that are predicted but should not have been), collapsing both of these into one single metric.", "labels": [], "entities": [{"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9972680807113647}, {"text": "precision", "start_pos": 111, "end_pos": 120, "type": "METRIC", "confidence": 0.9990038275718689}]}, {"text": "For our purposes, it will be more informative to separate precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9987449645996094}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9942545294761658}]}, {"text": "Given: O e = The set of size modifier types observed in an expression e Pr = The set of size modifier types predicted fora referent r E = The multiset of expressions in the corpus Er = The multiset of expressions fora referent r shows how well the different systems perform.", "labels": [], "entities": []}, {"text": "Testing instances are limited to those that contain a size modifier.", "labels": [], "entities": []}, {"text": "The second column lists precision and recall on the size corpus.", "labels": [], "entities": [{"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9995918869972229}, {"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9992108345031738}]}, {"text": "The difference in results between the two systems is not statistically significant.", "labels": [], "entities": []}, {"text": "The third column of lists how well the systems do when tested on the new domain, the craft corpus.", "labels": [], "entities": [{"text": "craft corpus", "start_pos": 85, "end_pos": 97, "type": "DATASET", "confidence": 0.7233221977949142}]}, {"text": "The precision and recall values here are identical for the systems that generate one modifier because almost all size expressions in the craft cor-pus contain just one modifier.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9994565844535828}, {"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9977332353591919}]}, {"text": "This also allows a more direct comparison between the two systems, as both the lower bounds (BASELINE) and upper bounds (ORACLE) of the two systems are equal.", "labels": [], "entities": [{"text": "BASELINE) and upper bounds (ORACLE)", "start_pos": 93, "end_pos": 128, "type": "METRIC", "confidence": 0.7583195008337498}]}, {"text": "As discussed in Section 6, both systems are adapted slightly for the new domain.", "labels": [], "entities": []}, {"text": "The size algorithm uses the height and width average of items that are the same type as the referent.", "labels": [], "entities": [{"text": "width", "start_pos": 39, "end_pos": 44, "type": "METRIC", "confidence": 0.8344558477401733}]}, {"text": "The decision trees are trained on the full size corpus, and when the models are built from all of the features listed in, precision / recall on this task is 44.1% / 48.1%.", "labels": [], "entities": [{"text": "precision", "start_pos": 122, "end_pos": 131, "type": "METRIC", "confidence": 0.9997279047966003}, {"text": "recall", "start_pos": 134, "end_pos": 140, "type": "METRIC", "confidence": 0.9980326294898987}]}, {"text": "However, once we adapt the classifiers to the subset of relative measurement features, there is a large jump for both measures.", "labels": [], "entities": []}, {"text": "The two systems perform similarly.", "labels": [], "entities": []}, {"text": "The size algorithm achieves just over 81.3% precision and recall, while the machine learning approach reaches 80.5% precision and 81.3% recall, and the differences between the two methods are not statistically significant.", "labels": [], "entities": [{"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9987063407897949}, {"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9991149306297302}, {"text": "precision", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.9943915009498596}, {"text": "recall", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.9972490668296814}]}, {"text": "Oracle accuracy is higher by around 8%, suggesting that both systems are reasonable, and further work may want to finesse the kinds of size information that each uses.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 7, "end_pos": 15, "type": "METRIC", "confidence": 0.9914063215255737}]}], "tableCaptions": [{"text": " Table 4: Frequency of observed size modifier types in the  craft corpus.", "labels": [], "entities": [{"text": "Frequency", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9269693493843079}]}, {"text": " Table 5: Precision and recall for models, testing on ex- pressions that contain size. The size algorithm is aver- aged over 5 iterations.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9918625354766846}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9981697797775269}]}]}