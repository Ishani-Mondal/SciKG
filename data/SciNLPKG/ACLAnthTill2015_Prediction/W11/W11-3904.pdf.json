{"title": [{"text": "Robust Unsupervised and Semi-Supervised Methods in Natural Language Processing", "labels": [], "entities": []}], "abstractContent": [{"text": "Most relation extraction methods, especially in the domain of biology, rely on machine learning methods to classify a co-occurring pair of entities in a sentence to be related or not.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 5, "end_pos": 24, "type": "TASK", "confidence": 0.9107185006141663}]}, {"text": "Such an approach requires a training corpus, which involves expert annotation and is tedious, time-consuming, and expensive.", "labels": [], "entities": []}, {"text": "We overcome this problem by the use of existing knowledge in structured databases to automatically generate a training corpus for protein-protein interactions.", "labels": [], "entities": []}, {"text": "An extensive evaluation of different instance selection strategies is performed to maximize robustness on this presumably noisy resource.", "labels": [], "entities": []}, {"text": "Successful strategies to consistently improve performance include a majority voting ensemble of classifiers trained on subsets of the training corpus and the use of knowledge bases consisting of proven non-interactions.", "labels": [], "entities": []}, {"text": "Our best configured model built without manually annotated data shows very competitive results on several publicly available benchmark corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "Protein function depends, to a large degree, on the functional context of its interaction partners, e.g. other proteins or metabolites.", "labels": [], "entities": []}, {"text": "Accordingly, getting a better understanding of protein-protein interactions (PPIs) is vital to understand biological processes within organisms.", "labels": [], "entities": []}, {"text": "Several databases, such as IntAct, DIP, or MINT, contain detailed information about these interactions.", "labels": [], "entities": []}, {"text": "To populate such databases, curators extract experimentally validated PPIs from peer reviewed publications (.", "labels": [], "entities": []}, {"text": "Therefore, the automated extraction of PPIs from publications for assisting database curators has attracted considerable attention (.", "labels": [], "entities": [{"text": "automated extraction of PPIs from publications", "start_pos": 15, "end_pos": 61, "type": "TASK", "confidence": 0.7090326646963755}]}, {"text": "PPI extraction is usually tackled by classifying then 2 undirected protein mention pairs within a sentence, where n is the number of protein mentions in the sentence.", "labels": [], "entities": [{"text": "PPI extraction", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8684702217578888}]}, {"text": "Classification of such pairs is often approached by machine learning or pattern-based methods ( both requiring manually annotated corpora, which are costly to obtain and often biased to the annotation guidelines and corpus selection criteria.", "labels": [], "entities": []}, {"text": "To overcome this issue, recent work has concentrated on distant supervision and multiple instance learning ().", "labels": [], "entities": []}, {"text": "Instead of manually annotated corpora, such approaches infer training instances from nonannotated texts using knowledge bases, thus allowing to increase the training set size by a few orders of magnitude.", "labels": [], "entities": []}, {"text": "Corpora derived by distant supervision are inherently noisy, thus benefiting from robust classification methods.", "labels": [], "entities": []}], "datasetContent": [{"text": "For classification, we use a support vector machine with the shallow linguistic (SL) kernel () which has been previously shown to generate state-of-the-art results for PPI extraction (.", "labels": [], "entities": [{"text": "classification", "start_pos": 4, "end_pos": 18, "type": "TASK", "confidence": 0.9688665270805359}, {"text": "PPI extraction", "start_pos": 168, "end_pos": 182, "type": "TASK", "confidence": 0.9228388369083405}]}, {"text": "This method uses syntactic features, e.g. word, stem, part-of-speech tag and morphologic properties of the surrounding words to train a classifier, but no parse tree information.", "labels": [], "entities": []}, {"text": "For evaluation, we use the five benchmark PPI corpora listed in.", "labels": [], "entities": []}, {"text": "Each training procedure, except for the ensemble experiments, is repeated 10 times randomly, thus resulting in 10 independent estimates for precision, recall, F 1 , and area under the ROC curve (AUC).", "labels": [], "entities": [{"text": "precision", "start_pos": 140, "end_pos": 149, "type": "METRIC", "confidence": 0.9995088577270508}, {"text": "recall", "start_pos": 151, "end_pos": 157, "type": "METRIC", "confidence": 0.9989782571792603}, {"text": "F 1", "start_pos": 159, "end_pos": 162, "type": "METRIC", "confidence": 0.9889829754829407}, {"text": "area", "start_pos": 169, "end_pos": 173, "type": "METRIC", "confidence": 0.981650173664093}, {"text": "ROC curve (AUC)", "start_pos": 184, "end_pos": 199, "type": "METRIC", "confidence": 0.9654277086257934}]}, {"text": "This allows for robust estimation of all evaluation metrics.", "labels": [], "entities": []}, {"text": "Using single sided MannWhitney U test p-values for F 1 and AUC between two different models are calculated, with the null hypothesis that median of two samples is equal.", "labels": [], "entities": [{"text": "F 1", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.9880240857601166}, {"text": "AUC", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.8067491054534912}]}, {"text": "Significance of Kendall correlation is determined using with the null hypothesis that correlation equals zero.", "labels": [], "entities": [{"text": "Kendall correlation", "start_pos": 16, "end_pos": 35, "type": "METRIC", "confidence": 0.5503247380256653}, {"text": "correlation", "start_pos": 86, "end_pos": 97, "type": "METRIC", "confidence": 0.9910203814506531}]}, {"text": "For all tests we assume a p-value of 0.01 to determine significance.", "labels": [], "entities": [{"text": "significance", "start_pos": 55, "end_pos": 67, "type": "METRIC", "confidence": 0.9928355813026428}]}, {"text": "A clear drawback of Negatome is the comparable small sample size of protein pairs.", "labels": [], "entities": [{"text": "Negatome", "start_pos": 20, "end_pos": 28, "type": "DATASET", "confidence": 0.8006098866462708}]}, {"text": "The number of confidently negative training instances could be increased by generalizing proteins across species using, for instance, Homologene.", "labels": [], "entities": [{"text": "Homologene", "start_pos": 134, "end_pos": 144, "type": "DATASET", "confidence": 0.9077299237251282}]}, {"text": "On our data set we could infer approximately 4,200 additional training instances.", "labels": [], "entities": []}, {"text": "However, it is unclear if these derived instances are of the same quality than the Negatome data set.", "labels": [], "entities": [{"text": "Negatome data set", "start_pos": 83, "end_pos": 100, "type": "DATASET", "confidence": 0.9613860050837199}]}, {"text": "Another possibility is the usage of additional text repositories.", "labels": [], "entities": []}, {"text": "clearly indicates that positive to negative ratio on training data affects performance of a classifier.", "labels": [], "entities": []}, {"text": "Precision and recall strongly correlate with the pos/neg ratio seen in the training set.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9897395968437195}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9990296363830566}]}, {"text": "The observed correlation between recall and pos/neg ratio (Kendall's tau ranging from 0.524 to 1 for all five corpora) is expected, as the classifier tends to assign more test instances to the majority (positive) class.", "labels": [], "entities": [{"text": "recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9993773102760315}, {"text": "pos/neg ratio", "start_pos": 44, "end_pos": 57, "type": "METRIC", "confidence": 0.7336204051971436}]}, {"text": "This procedure works best for corpora with many positive examples.", "labels": [], "entities": []}, {"text": "A strong correlation (Kendall's tau ranging from \u22120.9 to \u22121.0) between precision and class ratio can be observed for AIMed, BioInfer, and HPRD50.", "labels": [], "entities": [{"text": "precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9992103576660156}, {"text": "AIMed", "start_pos": 117, "end_pos": 122, "type": "DATASET", "confidence": 0.839257001876831}, {"text": "BioInfer", "start_pos": 124, "end_pos": 132, "type": "DATASET", "confidence": 0.7925897836685181}, {"text": "HPRD50", "start_pos": 138, "end_pos": 144, "type": "DATASET", "confidence": 0.967524528503418}]}, {"text": "Correlation for IEPA is close to zero and for LLL the correlation is even positive but not significant (p-value of 0.13).", "labels": [], "entities": [{"text": "IEPA", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.8438926935195923}, {"text": "correlation", "start_pos": 54, "end_pos": 65, "type": "METRIC", "confidence": 0.9605116248130798}]}, {"text": "Overall, the observed influence is less pronounced than expected.", "labels": [], "entities": []}, {"text": "For instance F 1 remains comparably robust with an average standard deviation of 2.6 pp for ratios between 0.1 and 10 . With more pronounced differences in the training ratio, a strong impact on F 1 can be observed.", "labels": [], "entities": [{"text": "F 1", "start_pos": 13, "end_pos": 16, "type": "METRIC", "confidence": 0.9514641761779785}, {"text": "F 1", "start_pos": 195, "end_pos": 198, "type": "METRIC", "confidence": 0.9267092943191528}]}], "tableCaptions": [{"text": " Table 1: Overview of the 5 corpora used for evalu- ation. For state-of-the-art results on these corpora,  see", "labels": [], "entities": []}, {"text": " Table 3: Results of different instance selection strategies, different positive to negative ratios in the  training set, sample size and employing Negatome as negative knowledge base.", "labels": [], "entities": []}, {"text": " Table 4: Result of bagging over 11 classifier trained on different subsets. For comparison we show the  average results for these 11 runs.", "labels": [], "entities": []}]}