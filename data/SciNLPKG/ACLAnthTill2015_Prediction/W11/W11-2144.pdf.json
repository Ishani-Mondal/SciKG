{"title": [{"text": "The Uppsala-FBK systems at WMT 2011", "labels": [], "entities": [{"text": "Uppsala-FBK", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9933911561965942}, {"text": "WMT 2011", "start_pos": 27, "end_pos": 35, "type": "DATASET", "confidence": 0.8696479201316833}]}], "abstractContent": [{"text": "This paper presents our submissions to the shared translation task at WMT 2011.", "labels": [], "entities": [{"text": "shared translation task at WMT 2011", "start_pos": 43, "end_pos": 78, "type": "TASK", "confidence": 0.6666164894898733}]}, {"text": "We created two largely independent systems for English-to-French and Haitian Creole-to-English translation to evaluate different features and components from our ongoing research on these language pairs.", "labels": [], "entities": [{"text": "Haitian Creole-to-English translation", "start_pos": 69, "end_pos": 106, "type": "TASK", "confidence": 0.681551198164622}]}, {"text": "Key features of our systems include anaphora resolution, hierarchical lexical reordering, data selection for language modelling, linear transduction grammars for word alignment and syntax-based decoding with monolingual dependency information.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.7148818522691727}, {"text": "language modelling", "start_pos": 109, "end_pos": 127, "type": "TASK", "confidence": 0.7133588939905167}, {"text": "word alignment", "start_pos": 162, "end_pos": 176, "type": "TASK", "confidence": 0.777379184961319}]}], "introductionContent": [], "datasetContent": [{"text": "We ran several experiments with slightly different settings.", "labels": [], "entities": []}, {"text": "We used the same basic setup for all of them including the same language models and GIZA++ word alignments that we have used for the phrase-based models already.", "labels": [], "entities": [{"text": "GIZA++ word alignments", "start_pos": 84, "end_pos": 106, "type": "TASK", "confidence": 0.6630991399288177}]}, {"text": "Further, we used Moses for extracting rules of the syntax-based translation model.", "labels": [], "entities": []}, {"text": "We use standard settings for the baseline system (=hiero) that does not employ any linguistic markup.", "labels": [], "entities": []}, {"text": "For the models that include dependency-based trees we changed the maximum span threshold to a high value of 999 (default: 15) in order to extract as many rules as possible.", "labels": [], "entities": []}, {"text": "This large degree of freedom is possible due to the otherwise strong constraints on rule flexibility imposed by the monolingual syntactic markup.", "labels": [], "entities": []}, {"text": "Rule tables are dramatically smaller than for the unrestricted hierarchical models (see).", "labels": [], "entities": []}, {"text": "However, rule restriction by linguistic constraints usually hurts performance due to the decreased coverage of the rule set.", "labels": [], "entities": [{"text": "rule restriction", "start_pos": 9, "end_pos": 25, "type": "TASK", "confidence": 0.8963739573955536}]}, {"text": "One common way of improving Please help me because my situation very critical.", "labels": [], "entities": []}, {"text": "reference I don't have money to go and give blood in Port au Prince from La Gonave.", "labels": [], "entities": [{"text": "Port au Prince from La Gonave", "start_pos": 53, "end_pos": 82, "type": "DATASET", "confidence": 0.9452686111132304}]}, {"text": "pbsmt I don't have money, so that I go to give blood Port-au-Prince since lagonave.", "labels": [], "entities": []}, {"text": "hiero I don 't have any money , for me to go to give blood Port-au-Prince since lagonave . samt2 I don't have any money, to be able to go to give blood Port-au-Prince since Gon\u00e2ve Island.", "labels": [], "entities": [{"text": "Gon\u00e2ve Island", "start_pos": 173, "end_pos": 186, "type": "DATASET", "confidence": 0.9382728636264801}]}, {"text": "rule extraction is based on tree manipulation and relaxed extraction algorithms.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7985813617706299}]}, {"text": "Moses implements several algorithms that have been proposed in the literature.", "labels": [], "entities": []}, {"text": "Tree binarisation is one of them.", "labels": [], "entities": [{"text": "Tree binarisation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.60312320291996}]}, {"text": "This can be done in a left-branching and in a right-branching mode.", "labels": [], "entities": []}, {"text": "We used a combination of both in the settings denoted as binarised.", "labels": [], "entities": []}, {"text": "The other relaxation algorithms are based on methods proposed for syntaxaugmented machine translation (.", "labels": [], "entities": [{"text": "syntaxaugmented machine translation", "start_pos": 66, "end_pos": 101, "type": "TASK", "confidence": 0.6588792204856873}]}, {"text": "We used two of them: samt1 combines pairs of neighbouring children nodes into combined complex nodes and creates additional complex nodes of all children nodes except the first child and similar complex nodes for all but the last child.", "labels": [], "entities": []}, {"text": "samt2 combines any pair of neighbouring nodes even if they are not children of the same parent.", "labels": [], "entities": []}, {"text": "All of these relaxation algorithms lead to increased rule sets.", "labels": [], "entities": []}, {"text": "In terms of translation performance there seems to be a strong correlation between rule table size and translation quality as measured by BLEU.", "labels": [], "entities": [{"text": "translation", "start_pos": 12, "end_pos": 23, "type": "TASK", "confidence": 0.9604246020317078}, {"text": "BLEU", "start_pos": 138, "end_pos": 142, "type": "METRIC", "confidence": 0.978642463684082}]}, {"text": "None of the dependency-based models beats the unrestricted hierarchical model.", "labels": [], "entities": []}, {"text": "Both translation directions behave similar with slightly worse performances of the dependency-based models (relative to the baseline) when syntax is used on the source language side.", "labels": [], "entities": []}, {"text": "Note also that all syntax-based models (including hiero) are below the corresponding phrase-based SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 98, "end_pos": 101, "type": "TASK", "confidence": 0.8480087518692017}]}, {"text": "Of course, automatic evaluation has its limits and interesting qualitative differences maybe more visible in manual assessments.", "labels": [], "entities": [{"text": "automatic evaluation", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.6656552851200104}]}, {"text": "The use of linguistic information certainly has an impact on the translation hypotheses produced as we can see in the examples in.", "labels": [], "entities": []}, {"text": "In the future, we plan to investigate the effect of dependency information on grammaticality of translated sentences in more detail.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Perplexity reduction after interpolating the News  LM with data selected from the 10 9 corpus.  newstest  2009 2010 2011  Primary submission  0.246 0.286 0.284", "labels": [], "entities": [{"text": "News  LM with data selected from the 10 9 corpus.  newstest  2009 2010 2011  Primary submission  0.246 0.286 0.284", "start_pos": 55, "end_pos": 169, "type": "DATASET", "confidence": 0.8559979736804962}]}, {"text": " Table 2: Ablation test results (case-sensitive BLEU)", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.989500105381012}, {"text": "BLEU", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.9817653894424438}]}, {"text": " Table 3: Phrase-based SMT (pbsmt) on the Haitian  Creole-English test set with different word alignments.", "labels": [], "entities": [{"text": "Phrase-based SMT", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.6454242467880249}, {"text": "Haitian  Creole-English test set", "start_pos": 42, "end_pos": 74, "type": "DATASET", "confidence": 0.7433231920003891}]}, {"text": " Table 4: Syntax-based SMT on the Haitian Creole- English test set with (=malt) or without (=hiero) English  parse trees and various parse relaxation strategies. The  final system submitted to WMT11 is malt(target)-samt2.", "labels": [], "entities": [{"text": "SMT", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.9923620223999023}, {"text": "Haitian Creole- English test set", "start_pos": 34, "end_pos": 66, "type": "DATASET", "confidence": 0.6979493300120035}, {"text": "WMT11", "start_pos": 193, "end_pos": 198, "type": "DATASET", "confidence": 0.8963512182235718}]}]}