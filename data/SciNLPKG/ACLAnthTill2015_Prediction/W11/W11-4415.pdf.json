{"title": [{"text": "Measuring the confusability of pronunciations in speech recognition", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.7238470911979675}]}], "abstractContent": [{"text": "In this work, we define a measure aimed at assessing how well a pronunciation model will function when used as a component of a speech recognition system.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 128, "end_pos": 146, "type": "TASK", "confidence": 0.6976283937692642}]}, {"text": "This measure, pronunciation entropy, fuses information from both the pronunciation model and the language model.", "labels": [], "entities": []}, {"text": "We show how to compute this score by effectively composing the output of a phoneme recognizer with a pronunciation dictionary and a language model, and investigate its role as predictor of pronunciation model performance.", "labels": [], "entities": []}, {"text": "We present results of this measure for different dictionaries with and without pronunciation variants and counts.", "labels": [], "entities": []}], "introductionContent": [{"text": "As explained in), pronunciation variations can be incorporated at different levels in ASR systems: the lexicon, the acoustic model, the language model.", "labels": [], "entities": [{"text": "ASR", "start_pos": 86, "end_pos": 89, "type": "TASK", "confidence": 0.9814060926437378}]}, {"text": "At the acoustic level, context dependent phone modeling captures the phone variations within particular contexts.", "labels": [], "entities": []}, {"text": "At the lexicon level, a lexicon with alternative pronunciations is used.", "labels": [], "entities": []}, {"text": "At the language model (LM) level, the inter-word pronunciation variations are handled with grammar network, statistical LMs or multiword models.", "labels": [], "entities": []}, {"text": "The growing interest in automatic transcription of Conversational Speech (CTS) increases the need for modeling pronunciation variation.", "labels": [], "entities": [{"text": "automatic transcription of Conversational Speech (CTS)", "start_pos": 24, "end_pos": 78, "type": "TASK", "confidence": 0.7943718284368515}]}, {"text": "Indeed, there is a large number of possible pronunciation variants occurring in spontaneous speech; these variants often extend beyond single speech sounds (modeled by the acoustic model) and reach up to whole words or word tuples.", "labels": [], "entities": []}, {"text": "Not even context-dependent acoustic models for sub-word units (like phonemes) are able to cover pronunciation variants of this kind).", "labels": [], "entities": []}, {"text": "Thus, pronunciation variation is usually modeled by enumerating appropriate pronunciations for each word in the vocabulary using a pronunciation lexicon.", "labels": [], "entities": []}, {"text": "However, when adding alternative pronunciations to a lexicon, there is always the potential of introducing a detrimental amount of confusability.", "labels": [], "entities": []}, {"text": "The homophone (words that sound the same but are written differently) rate increases, which means that these additional variants may not be helpful to the recognition performance).", "labels": [], "entities": []}, {"text": "A typical example in English is the word you: the received pronunciation is /yu/ and is chosen when one single variant is used; modeling some variation requires to consider the pronunciations /yu/ and /yc/, which both occur in our multiple pronunciation dictionary.", "labels": [], "entities": []}, {"text": "The latter pronunciation (/yc/), in the phrase you are is easily confused with /ycr/, the pronunciation of your.", "labels": [], "entities": []}, {"text": "Such confusions, in particular when they involve frequent words, can cause a degradation of the ASR system as more alternatives are added.", "labels": [], "entities": [{"text": "ASR", "start_pos": 96, "end_pos": 99, "type": "TASK", "confidence": 0.974202573299408}]}, {"text": "A lot of work has been carried out on the generation of pronunciation and pronunciation variants independently of the speech (g2p conversion, p2p conversion) or in a task specific framework using surface pronunciations generated from a phoneme recognizer or including acoustic and language model information.", "labels": [], "entities": []}, {"text": "However, most works lack a sense of how added alternative pronunciations will affect the overall decoding process.", "labels": [], "entities": []}, {"text": "For example, some of the confusability introduced by the pronunciation model is compensated by the LM.", "labels": [], "entities": []}, {"text": "Thus, a method for quantifying the confusion inherent in a combined acoustic-lexical system is needed.", "labels": [], "entities": []}, {"text": "A confusability measure traditionally used to measure the uncertainty residual to a system is entropy.", "labels": [], "entities": []}, {"text": "Specifically in an ASR system, lexical entropy measures the confusability introduced by an LM.", "labels": [], "entities": [{"text": "ASR", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.9777697324752808}]}, {"text": "In some previous works, lexical entropy not only takes the LM scores into account, but also integrate the scores of the acoustic and pronunciation models).", "labels": [], "entities": []}, {"text": "In (), the authors consider as a measure of the pronunciation confusability the entropy of the variant distribution, but they do not take into account the language model.", "labels": [], "entities": []}, {"text": "Our aim is to integrate pronunciation model and language model information into a single framework for describing the confusability.", "labels": [], "entities": []}, {"text": "Especially incorporating language model information would provide a more accurate reflection of the decoding process, and hence a more accurate picture of the possible lexical/acoustic confusions).", "labels": [], "entities": []}, {"text": "The idea is then to introduce a measure inspired by the proposed formulation in) but in a somewhat reverse fashion.", "labels": [], "entities": []}, {"text": "Instead of measuring the \"true\" disambiguation capacity of the LM by taking acoustic similarities into account, we aim at measuring the actual confusability introduced in the system by the pronunciation model, taking also into account the LM.", "labels": [], "entities": []}, {"text": "We call this measure pronunciation entropy.", "labels": [], "entities": [{"text": "pronunciation entropy", "start_pos": 21, "end_pos": 42, "type": "METRIC", "confidence": 0.9292808473110199}]}, {"text": "To compute this measure, we will decompose the decoding process in two separate parts: the acoustic decoding on the one hand, the linguistic decoding on the other hand.", "labels": [], "entities": []}, {"text": "Given an input signal, a phoneme recognizer is first used to obtain a sequence of phonemes; the rest of the decoding process is realized using a set of Finite State Machines (FSMs) modeling the various linguistic resources involved in the process.", "labels": [], "entities": [{"text": "phoneme recognizer", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.7460176646709442}]}, {"text": "Doing so allows us to measure the confusability incurred by the acoustic decoder for fixed linguistic models; or, conversely, to assess the impact of adding more pronunciations, for fixed acoustic and language models.", "labels": [], "entities": []}, {"text": "This latter scenario is especially appealing, as these measurements do not require to redecode the speech signal: it thus become possible to try to iteratively optimize the pronunciation lexicon at a moderate computational cost.", "labels": [], "entities": []}, {"text": "Experiments are carried out to measure the confusability introduced by single and multiple pronunciation dictionaries in an ASR system, using the newly introduced pronunciation entropy.", "labels": [], "entities": [{"text": "ASR", "start_pos": 124, "end_pos": 127, "type": "TASK", "confidence": 0.9640969038009644}]}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the necessary Finite State Tranducers (FSTs) background.", "labels": [], "entities": [{"text": "Finite State Tranducers (FSTs)", "start_pos": 34, "end_pos": 64, "type": "TASK", "confidence": 0.46420617401599884}]}, {"text": "Section 3 presents the FST decoding and details the new confusability measure.", "labels": [], "entities": [{"text": "FST decoding", "start_pos": 23, "end_pos": 35, "type": "DATASET", "confidence": 0.6567534506320953}]}, {"text": "Sections 4 and 5 present the recognition experiments and the pronunciation entropy results.", "labels": [], "entities": [{"text": "pronunciation entropy", "start_pos": 61, "end_pos": 82, "type": "TASK", "confidence": 0.7703260183334351}]}, {"text": "The paper concludes with a discussion of the results and of some future work in Section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Average number of states and arcs in the lattices", "labels": [], "entities": []}, {"text": " Table 2: Pronunciation entropy on baselines", "labels": [], "entities": [{"text": "Pronunciation entropy", "start_pos": 10, "end_pos": 31, "type": "TASK", "confidence": 0.8617168664932251}]}, {"text": " Table 3: Pronunciation entropy with the 4-gram LM af- ter adding n-best pronunciations, produced by a Moses- based g2p converter, to the \"longest\" baseline", "labels": [], "entities": []}, {"text": " Table 4: Pronunciation entropy with the 4-gram LM after  adding Moses' n-best pronunciations to the \"most fre- quent\" baseline", "labels": [], "entities": []}]}