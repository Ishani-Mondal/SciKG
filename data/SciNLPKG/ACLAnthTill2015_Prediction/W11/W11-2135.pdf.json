{"title": [], "abstractContent": [{"text": "This paper describes LIMSI's submissions to the Sixth Workshop on Statistical Machine Translation.", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 66, "end_pos": 97, "type": "TASK", "confidence": 0.6324043869972229}]}, {"text": "We report results for the French-English and German-English shared translation tasks in both directions.", "labels": [], "entities": [{"text": "German-English shared translation", "start_pos": 45, "end_pos": 78, "type": "TASK", "confidence": 0.5784926613171896}]}, {"text": "Our systems use n-code, an open source Statistical Machine Translation system based on bilingual n-grams.", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 39, "end_pos": 70, "type": "TASK", "confidence": 0.7108018398284912}]}, {"text": "For the French-English task, we focussed on finding efficient ways to take advantage of the large and heterogeneous training parallel data.", "labels": [], "entities": []}, {"text": "In particular, using a simple filtering strategy helped to improve both processing time and translation quality.", "labels": [], "entities": []}, {"text": "To translate from English to French and Ger-man, we also investigated the use of the SOUL language model in Machine Translation and showed significant improvements with a 10-gram SOUL model.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 108, "end_pos": 127, "type": "TASK", "confidence": 0.8485930263996124}]}, {"text": "We also briefly report experiments with several alternatives to the standard n-best MERT procedure, leading to a significant speed-up.", "labels": [], "entities": [{"text": "MERT", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.6806843876838684}]}], "introductionContent": [{"text": "This paper describes LIMSI's submissions to the Sixth Workshop on Statistical Machine Translation, where LIMSI participated in the French-English and German-English tasks in both directions.", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 66, "end_pos": 97, "type": "TASK", "confidence": 0.6242264409859976}]}, {"text": "For this evaluation, we used n-code, our in-house Statistical Machine Translation (SMT) system which is opensource and based on bilingual n-grams.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 50, "end_pos": 87, "type": "TASK", "confidence": 0.7832074016332626}]}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 provides an overview of n-code, while the data preprocessing and filtering steps are described in Section 3.", "labels": [], "entities": []}, {"text": "Given the large amount of parallel data available, we proposed a method to filter the FrenchEnglish GigaWord corpus (Section 3.2).", "labels": [], "entities": [{"text": "FrenchEnglish GigaWord corpus", "start_pos": 86, "end_pos": 115, "type": "DATASET", "confidence": 0.9271080096562704}]}, {"text": "As in our previous participations, data cleaning and filtering constitute a non-negligible part of our work.", "labels": [], "entities": [{"text": "data cleaning", "start_pos": 35, "end_pos": 48, "type": "TASK", "confidence": 0.8406944274902344}]}, {"text": "For target language modeling (Section 4), a standard back-off n-gram model is estimated and tuned as described in Section 4.1.", "labels": [], "entities": [{"text": "target language modeling", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.6238993704319}]}, {"text": "Moreover, we also introduce in Section 4.2 the use of the SOUL language model (LM) () in SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.9904028177261353}]}, {"text": "Based on neural networks, the SOUL LM can handle an arbitrary large vocabulary and a high order markovian assumption (up to 10-gram in this work).", "labels": [], "entities": [{"text": "SOUL LM", "start_pos": 30, "end_pos": 37, "type": "TASK", "confidence": 0.6275468170642853}]}, {"text": "Finally, experimental results are reported in Section 5 both in terms of BLEU scores and translation edit rates (TER) measured on the provided newstest2010 dataset.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.9981436729431152}, {"text": "translation edit rates (TER)", "start_pos": 89, "end_pos": 117, "type": "METRIC", "confidence": 0.8363562822341919}, {"text": "newstest2010 dataset", "start_pos": 143, "end_pos": 163, "type": "DATASET", "confidence": 0.9435064196586609}]}], "datasetContent": [{"text": "The experimental results are reported in terms of BLEU and translation edit rate (TER) using the newstest2010 corpus as evaluation set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.9994227886199951}, {"text": "translation edit rate (TER)", "start_pos": 59, "end_pos": 86, "type": "METRIC", "confidence": 0.8540851473808289}, {"text": "newstest2010 corpus", "start_pos": 97, "end_pos": 116, "type": "DATASET", "confidence": 0.9655145704746246}]}, {"text": "These automatic metrics are computed using the scripts provided by the NIST after a detokenization step.", "labels": [], "entities": [{"text": "NIST", "start_pos": 71, "end_pos": 75, "type": "DATASET", "confidence": 0.9582662582397461}]}], "tableCaptions": [{"text": " Table 1: English-French translation results in terms of  BLEU score and TER estimated on newstest2010 with  the NIST script. All means that the translation model is  trained on news-commentary, Europarl, and the whole  GigaWord. The rows upper quartile and median corre- spond to the use of a filtered version of the GigaWord.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 58, "end_pos": 68, "type": "METRIC", "confidence": 0.9868094027042389}, {"text": "TER", "start_pos": 73, "end_pos": 76, "type": "METRIC", "confidence": 0.9995597004890442}, {"text": "NIST script", "start_pos": 113, "end_pos": 124, "type": "DATASET", "confidence": 0.9402489066123962}, {"text": "Europarl", "start_pos": 195, "end_pos": 203, "type": "DATASET", "confidence": 0.9768201112747192}, {"text": "GigaWord", "start_pos": 318, "end_pos": 326, "type": "DATASET", "confidence": 0.9399464726448059}]}, {"text": " Table 2. Results show that to translate from En- glish to German, the use of a fine-grained POS infor- mation (RFTagger) leads to a slight improvement,  whereas it harms the source reordering model in the  other direction. It is worth noticing that to translate  from German to English, the RFTagger is always  used during the data pre-processing step, while a dif- ferent POS tagger may be involved for the source  reordering model training.", "labels": [], "entities": [{"text": "POS infor- mation (RFTagger)", "start_pos": 93, "end_pos": 121, "type": "METRIC", "confidence": 0.5746930199010032}]}, {"text": " Table 2: Translation results in terms of BLEU score  and translation edit rate (TER) estimated on newstest2010  with the NIST scoring script.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9736663699150085}, {"text": "BLEU score", "start_pos": 42, "end_pos": 52, "type": "METRIC", "confidence": 0.9843071103096008}, {"text": "translation edit rate (TER)", "start_pos": 58, "end_pos": 85, "type": "METRIC", "confidence": 0.8273681104183197}, {"text": "newstest2010", "start_pos": 99, "end_pos": 111, "type": "DATASET", "confidence": 0.9543302655220032}, {"text": "NIST scoring script", "start_pos": 122, "end_pos": 141, "type": "DATASET", "confidence": 0.8891037106513977}]}, {"text": " Table 3: Translation results from English to French and  English to German measured on newstest2010 using a  100-best rescoring with SOUL LMs of different orders.", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9356458783149719}, {"text": "newstest2010", "start_pos": 88, "end_pos": 100, "type": "DATASET", "confidence": 0.9509699940681458}, {"text": "rescoring", "start_pos": 119, "end_pos": 128, "type": "METRIC", "confidence": 0.883864164352417}]}]}