{"title": [{"text": "Modeling of Stylistic Variation in Social Media with Stretchy Patterns", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we describe a novel feature discovery technique that can be used to model stylistic variation in sociolects.", "labels": [], "entities": [{"text": "feature discovery", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.8042905926704407}]}, {"text": "While structural features offer much in terms of expressive power over simpler features used more frequently in machine learning approaches to modeling linguistic variation, they frequently come at an excessive cost in terms of feature space size expansion.", "labels": [], "entities": []}, {"text": "We propose a novel form of structural features referred to as \"stretchy patterns\" that strike a balance between expressive power and compactness in order to enable modeling stylistic variation with reasonably small datasets.", "labels": [], "entities": []}, {"text": "As an example we focus on the problem of modeling variation related to gender in personal blogs.", "labels": [], "entities": []}, {"text": "Our evaluation demonstrates a significant improvement over standard baselines.", "labels": [], "entities": []}], "introductionContent": [{"text": "The contribution of this paper is a novel approach to feature induction seeking to model stylistic variation at a level that not only achieves high performance, but generalizes across domains better than alternative techniques.", "labels": [], "entities": [{"text": "feature induction", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.7752843797206879}]}, {"text": "Building on an earlier template based approach for modeling sarcasm, we investigate the use of what we have termed \"stretchy\" features to model stylistic variation related to sociolects, which can bethought of as a form of dialect.", "labels": [], "entities": []}, {"text": "Specifically, we focus on the problem of gender based classification.", "labels": [], "entities": [{"text": "gender based classification", "start_pos": 41, "end_pos": 68, "type": "TASK", "confidence": 0.6435287892818451}]}, {"text": "Gender classification and age classification have both received increased attention in the social media analysis community in recent years (), most likely because large data sets annotated with these variables have recently become available.", "labels": [], "entities": [{"text": "Gender classification", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7853926718235016}, {"text": "age classification", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.6770508140325546}]}, {"text": "Machine learning technology provides a lens with which to explore linguistic variation that complements earlier statistical techniques used by variationist sociolinguists in their work mapping out the space of dialect variation and its accompanying social interpretation).", "labels": [], "entities": []}, {"text": "These complementary approaches share a common foundation in numerical methods, however while descriptive statistics and inferential statistics mainly serve the purpose of describing non-random differences in distributions between communities, machine learning work in the area of social media analysis asks the more challenging question of whether the differences described are big enough to enable identification of community membership by means of those differences.", "labels": [], "entities": [{"text": "identification of community membership", "start_pos": 399, "end_pos": 437, "type": "TASK", "confidence": 0.8215043842792511}]}, {"text": "In the remainder of the paper, we first introduce prior work in a variety of related areas that both demonstrates why generalizable models characterizing sociolects within social media contexts are challenging to create and motivates our novel approach.", "labels": [], "entities": []}, {"text": "Next we describe our technical approach for inducing \"stretchy patterns\".", "labels": [], "entities": []}, {"text": "We then present a series of experiments that demonstrate that our stretchy patterns provide advantages over alternative feature spaces in terms of avoiding overfitting to irrelevant content-based features as evidenced both in terms of achieving higher performance with smaller amounts of training data and in terms of generalizing better across subpopulations that share other demographic and individual difference variables.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have motivated the design of our stretchy patterns by the desire to balance expressive power and compactness.", "labels": [], "entities": []}, {"text": "The evidence of our success should be demonstrated along two dimensions: first, that these compact features allow our models to achieve a higher performance when trained on small datasets and second, that models trained with our stretchy patterns generalize better between domains.", "labels": [], "entities": []}, {"text": "Thus, in this section, we present two evaluations of our approach in comparison to three baseline approaches.", "labels": [], "entities": []}, {"text": "We chose to use the Blog Authorship Corpus for our evaluation, which has been used in earlier work related to gender classification), and which is available for web download . Each instance contains a series of personal blog entries from a single author.", "labels": [], "entities": [{"text": "Blog Authorship Corpus", "start_pos": 20, "end_pos": 42, "type": "DATASET", "confidence": 0.9065636396408081}, {"text": "gender classification", "start_pos": 110, "end_pos": 131, "type": "TASK", "confidence": 0.7330570966005325}]}, {"text": "For each blog, we have metadata indicating the gender, age, occupation, and astrological sign of the author.", "labels": [], "entities": []}, {"text": "From this corpus, for each experiment, we randomly selected a subset in which we have balanced the distribution of gender and occupation.", "labels": [], "entities": []}, {"text": "In particular, we selected 10 of the most common occupations in the dataset, specifically Science, Law, Non-Profit, Internet, Engineering, Media, Arts, Education, Technology, and Student.", "labels": [], "entities": []}, {"text": "We randomly select the same number of blogs from each of these occupations, and within occupation based sets, we maintain an even distribution of male and female authors.", "labels": [], "entities": []}, {"text": "We treat the occupation variable as a proxy for topic since bloggers typically make reference to their work in their posts.", "labels": [], "entities": []}, {"text": "We make use of this proxy for topic in our evaluation of domain generality below.", "labels": [], "entities": []}, {"text": "The purpose of Study 1 was to test the claim that our stretchy patterns achieve higher performance when we train using a small amount of data.", "labels": [], "entities": []}, {"text": "For this evaluation, we constructed a test set of 3,000 instances that we use consistently across training configurations.", "labels": [], "entities": []}, {"text": "Specifically, we selected 300 blogs from each of the 10 occupations listed above such that 150 of them were from male authors and 150 from female authors.", "labels": [], "entities": []}, {"text": "We constructed also a set of training sets of size 300, 800, 1500, 2000, and 3000 randomly selected blogs respectively, in which we maintain the same occupation and gender distribution as in the test set.", "labels": [], "entities": []}, {"text": "To compensate for sampling eccentricities, two samples of each training size were extracted, and their results averaged for each experiment.", "labels": [], "entities": []}, {"text": "In all cases, from each blog, we randomly selected one blog entry that was at least 100 words long.", "labels": [], "entities": []}, {"text": "For each baseline approach as well as the stretchy feature approach, we build a model using each training set, which we then test using the common test set.", "labels": [], "entities": []}, {"text": "Thus, for each approach, we can examine how performance increases as amount of training data increases, and we can compare this growth curve between approaches.", "labels": [], "entities": []}, {"text": "The dramatic mediocrity of the baselines' performance highlights the difficulty of the selected data set, confirming the sense that most of what these n-gram models pickup is not truly gender-specific usage, but shadows of the distribution of topics (here, occupations) between the genders.", "labels": [], "entities": []}, {"text": "At all sizes except the smallest (where no approach is significantly better than random), our approach outperforms the baselines.", "labels": [], "entities": []}, {"text": "At size 800, this difference is marginal (p < .1), and at the larger sizes, it is a significant increase (p < .05).", "labels": [], "entities": []}, {"text": "For our evaluation of domain generality, we randomly selected 200 blogs from each of the 10 most common occupations in the corpus, 100 of which were by male authors and 100 by female authors.", "labels": [], "entities": [{"text": "domain generality", "start_pos": 22, "end_pos": 39, "type": "TASK", "confidence": 0.7416924834251404}]}, {"text": "As in the evaluation above, from each blog, we randomly selected one blog entry that was at least 100 words long.", "labels": [], "entities": []}, {"text": "In order to test domain generality, we perform a leave-one-occupation-out cross validation experiment, which we refer to as a Cross Domain evaluation setting.", "labels": [], "entities": []}, {"text": "In this setting, on each fold, we always test on blogs from an occupation that was not represented within the training data.", "labels": [], "entities": []}, {"text": "Thus, indicators of gender that are specific to an occupation will not generalize from training to test.", "labels": [], "entities": []}, {"text": "displays the results from the comparison of our stretchy feature approach with each of the baseline approaches.", "labels": [], "entities": []}, {"text": "On average, stretchy patterns generalized better to new domains than the other approaches.", "labels": [], "entities": []}, {"text": "The stretchy feature approach beat the baseline approaches in a statistically significant way (p < .05).", "labels": [], "entities": []}, {"text": "For random cross-validation, our approach performed marginally better than the unigram baseline, and again significantly exceeds the performance of the other two baselines.", "labels": [], "entities": []}, {"text": "Note that for all approaches, there is a significant drop in performance from Random CV to the crossdomain setting, showing that all approaches, including ours, suffer from domain specificity to some extent.", "labels": [], "entities": []}, {"text": "However, while all of the baselines drop down to essentially random performance in the cross-domain setting, and stretchy patterns remain significantly higher than random, we show that our approach has more domain generality, although it still leaves room for improvement on that score.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2 Classification accuracy for varying data sizes  (with kappa in parentheses)", "labels": [], "entities": [{"text": "Classification", "start_pos": 9, "end_pos": 23, "type": "METRIC", "confidence": 0.841174304485321}, {"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.7548215985298157}]}]}