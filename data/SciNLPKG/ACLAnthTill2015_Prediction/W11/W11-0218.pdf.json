{"title": [{"text": "SimSem: Fast Approximate String Matching in Relation to Semantic Category Disambiguation", "labels": [], "entities": [{"text": "Semantic Category Disambiguation", "start_pos": 56, "end_pos": 88, "type": "TASK", "confidence": 0.7322616378466288}]}], "abstractContent": [{"text": "In this study we investigate the merits of fast approximate string matching to address challenges relating to spelling variants and to utilise large-scale lexical resources for semantic class disambiguation.", "labels": [], "entities": [{"text": "approximate string matching", "start_pos": 48, "end_pos": 75, "type": "TASK", "confidence": 0.7234703699747721}, {"text": "semantic class disambiguation", "start_pos": 177, "end_pos": 206, "type": "TASK", "confidence": 0.7304059664408366}]}, {"text": "We integrate string matching results into machine learning-based disambiguation through the use of a novel set of features that represent the distance of a given textual span to the closest match in each of a collection of lexical resources.", "labels": [], "entities": [{"text": "string matching", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.7053596675395966}]}, {"text": "We collect lexical resources fora multitude of semantic categories from a variety of biomedi-cal domain sources.", "labels": [], "entities": []}, {"text": "The combined resources, containing more than twenty million lexical items, are queried using a recently proposed fast and efficient approximate string matching algorithm that allows us to query large resources without severely impacting system performance.", "labels": [], "entities": [{"text": "approximate string matching", "start_pos": 132, "end_pos": 159, "type": "TASK", "confidence": 0.6979261636734009}]}, {"text": "We evaluate our results on six corpora representing a variety of disambigua-tion tasks.", "labels": [], "entities": []}, {"text": "While the integration of approximate string matching features is shown to substantially improve performance on one corpus, results are modest or negative for others.", "labels": [], "entities": []}, {"text": "We suggest possible explanations and future research directions.", "labels": [], "entities": []}, {"text": "Our lexical resources and implementation are made freely available for research purposes at: http://github.com/ninjin/ simsem", "labels": [], "entities": []}], "introductionContent": [{"text": "The use of dictionaries for boosting performance has become commonplace for Named Entity Recognition (NER) systems ().", "labels": [], "entities": [{"text": "Named Entity Recognition (NER)", "start_pos": 76, "end_pos": 106, "type": "TASK", "confidence": 0.7838551104068756}]}, {"text": "In particular, dictionaries can give an initial improvement when little or no training data is available.", "labels": [], "entities": []}, {"text": "However, no dictionary is perfect, and all resources lack certain spelling variants and lag behind current vocabulary usage and thus are unable to cover the intended domain in full.", "labels": [], "entities": []}, {"text": "Further, due to varying dictionary curation and corpus annotation guidelines, the definition of what constitutes a semantic category is highly unlikely to precisely match for any two specific resources ().", "labels": [], "entities": []}, {"text": "Ideally, for applying a lexical resource to an entity recognition or disambiguation task to serve as a definition of a semantic category there would be a precise match between the definitions of the lexical resource and target domain, but this is seldom or never the case.", "labels": [], "entities": [{"text": "entity recognition or disambiguation task", "start_pos": 47, "end_pos": 88, "type": "TASK", "confidence": 0.8523612976074219}]}, {"text": "Most previous work studying the use of dictionary resources in entity mention-related tasks has focused on single-class NER, in particular this is true for BioNLP where it has mainly concerned the detection of proteins.", "labels": [], "entities": [{"text": "BioNLP", "start_pos": 156, "end_pos": 162, "type": "DATASET", "confidence": 0.828848659992218}]}, {"text": "These efforts include, utilising dictionaries for protein detection by considering each dictionary entry using a novel distance measure, and, applying dictionaries to restrain the contexts in which proteins appear in text.", "labels": [], "entities": [{"text": "protein detection", "start_pos": 50, "end_pos": 67, "type": "TASK", "confidence": 0.738701805472374}]}, {"text": "In this work, we do not consider entity mention detection, but instead focus solely on the related task of disambiguating the semantic category fora given continuous sequence of characters (a textual span), doing so we side-step the issue of boundary detection in favour of focusing on novel aspects of semantic category disambiguation.", "labels": [], "entities": [{"text": "entity mention detection", "start_pos": 33, "end_pos": 57, "type": "TASK", "confidence": 0.730347216129303}, {"text": "boundary detection", "start_pos": 242, "end_pos": 260, "type": "TASK", "confidence": 0.7750979065895081}, {"text": "semantic category disambiguation", "start_pos": 303, "end_pos": 335, "type": "TASK", "confidence": 0.6651784976323446}]}, {"text": "Also, we are yet to see a high-performing multi-class biomedical NER system, this motivates our desire to include multiple semantic categories.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we introduce our experimental set-up and discuss the outcome of our experiments.", "labels": [], "entities": []}, {"text": "To ensure that our results are not biased by overfitting on a specific set of data, all data sets were separated into training, development and test sets.", "labels": [], "entities": []}, {"text": "NLPBA defines only a training and test set, GREC and CALBC CII are provided as resources and lack any given division, and for the BioNLP'11 ST data the test sets are not distributed.", "labels": [], "entities": [{"text": "NLPBA", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9583039879798889}, {"text": "GREC", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.7522996068000793}, {"text": "BioNLP'11 ST data", "start_pos": 130, "end_pos": 147, "type": "DATASET", "confidence": 0.8533259431521097}]}, {"text": "Thus, we combined all the available data for each dataset and separated the documents into fixed sets with the following ratios: 1/2 training, 1/4 development and 1/4 test.", "labels": [], "entities": []}, {"text": "We use a total of six classifiers for our experiments.", "labels": [], "entities": []}, {"text": "First, a naive baseline (Naive): a majority class voter with a memory based on the exact text of the textual span.", "labels": [], "entities": []}, {"text": "The remaining five are machine learning classifiers trained using five different feature sets: gazetteer features constituting strict string matching towards our SimString databases (Gazetteer), SimString features generated from our SimString databases (SimString), the span internal features listed in (Internal), the span internal and gazetteer features (Internal-Gazetteer) and the span internal and SimString features (InternalSimString).", "labels": [], "entities": []}, {"text": "We evaluate performance using simple instancelevel accuracy (correct classifications / all classifications).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.8417454361915588}]}, {"text": "Results are represented as learning curves for each data set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Lexical resources gathered for our experiments", "labels": [], "entities": []}, {"text": " Table 3: Statistics per dictionary resource", "labels": [], "entities": []}, {"text": " Table 5: Semantic categories in EPI", "labels": [], "entities": [{"text": "EPI", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.42273879051208496}]}, {"text": " Table 6: Semantic categories in ID", "labels": [], "entities": [{"text": "ID", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.5931798219680786}]}]}