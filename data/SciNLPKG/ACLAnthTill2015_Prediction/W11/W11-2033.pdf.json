{"title": [], "abstractContent": [{"text": "We present anew approach to dialogue management based on the use of multiple, interconnected policies.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.7804390490055084}]}, {"text": "Instead of capturing the complexity of the interaction in a single large policy, the dialogue manager operates with a collection of small local policies combined concurrently and hierarchically.", "labels": [], "entities": []}, {"text": "The meta-control of these policies relies on an activation vector updated before and after each turn.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many dialogue domains are naturally open-ended.", "labels": [], "entities": []}, {"text": "This is especially the casein situated dialogue, where the conversational agent must operate in continuously changing environments where there is often no single, pre-specified goal to achieve.", "labels": [], "entities": []}, {"text": "Depending on the situation and the (perceived) user requests, many distinct tasks maybe performed.", "labels": [], "entities": []}, {"text": "For instance, a service robot for the elderly might be used for cleaning, monitoring health status, and delivering information.", "labels": [], "entities": []}, {"text": "Each of these tasks features a specific set of observations, goals, constraints, internal dynamics, and associated actions.", "labels": [], "entities": []}, {"text": "This diversity of tasks and models poses significant challenges for dialogue systems, and particularly for dialogue management.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 107, "end_pos": 126, "type": "TASK", "confidence": 0.9047806859016418}]}, {"text": "Open-ended interactions are indeed usually much more difficult to model than classical slot-filling applications, where the application domain can provide strong constraints on the possible dialogue transitions.", "labels": [], "entities": []}, {"text": "Using machine learning techniques to learn the model parameters can help alleviate this issue, but only if the task can be efficiently factored and if a sufficient amount of data is available.", "labels": [], "entities": []}, {"text": "Once a model of the interaction and its associated environment is available, a control policy then needs to be learned or designed for the resulting state space.", "labels": [], "entities": []}, {"text": "The extraction of good control policies can be computationally challenging, especially for interactions which simultaneously combine partial observability (to deal with noisy and incomplete observations) and large state spaces (if the optimal behaviour depends on a wide range of user-and context-specific factors) -which is the case for many open-ended domains.", "labels": [], "entities": []}, {"text": "In this paper, we present ongoing work on anew approach to dialogue management which seeks to address these issues by leveraging prior knowledge about the interaction structure to breakup the full domain into a set of smaller, more predictable subdomains.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.8104393780231476}]}, {"text": "Moving away from the idea of capturing the full interaction complexity into a unique, monolithic policy, we extend the execution algorithm of the dialogue manager to directly operate with a collection of small, interconnected local policies.", "labels": [], "entities": []}, {"text": "Viewing dialogue management as a decision process over multiple policies has several benefits.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.7250252366065979}]}, {"text": "First, it is usually easier for the application developer to model several small, local interactions than a single large one.", "labels": [], "entities": []}, {"text": "Each local model can also be independently modified, extended or replaced without interfering with the rest of the system, which is crucial for system maintenance.", "labels": [], "entities": []}, {"text": "Finally, different theoretical frameworks can be used for different policies, which means that the developer is free to decide which approach is most appropriate to solve a specific problem, without having to commit to a unique theoretical framework for the whole application.", "labels": [], "entities": []}, {"text": "For instance, one policy might be expressed as a solution to a Partially Observable Markov Decision Process (POMDP) while another policy is encoded as a hand-crafted finite-state controller, and the two can be integrated in the same control algorithm.", "labels": [], "entities": []}, {"text": "One of the challenges when operating with multiple policies is the \"meta-control\" of these policies.", "labels": [], "entities": []}, {"text": "At each turn, the system must know which policy is currently in focus and is responsible for deciding the next action to perform.", "labels": [], "entities": []}, {"text": "Since dialogue management operates under significant uncertainty, the system can never be sure whether a given policy is terminated or not.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 6, "end_pos": 25, "type": "TASK", "confidence": 0.793075293302536}]}, {"text": "We thus need a \"soft\" control mechanism which is able to explicitly account for the uncertainty about the completion status of each policy.", "labels": [], "entities": []}, {"text": "This is precisely what we present in this paper.", "labels": [], "entities": []}, {"text": "The rest of the paper is as follows.", "labels": [], "entities": []}, {"text": "We first provide general definitions of dialogue policies, and present an algorithm for dialogue management operating on multiple policies.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.798988938331604}]}, {"text": "We then present an implementation of the algorithm together with an empirical evaluation of its performance, and conclude the paper by comparing our approach to related work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The described algorithm has been implemented and tested with different types of policies.", "labels": [], "entities": []}, {"text": "We present here a preliminary experiment performed with a small dialogue domain.", "labels": [], "entities": []}, {"text": "The domain consists of a (simulated) visual learning task between a human and a robot in a shared scene including a small number of objects, described by various properties such as color or shape.", "labels": [], "entities": []}, {"text": "The human asks questions related to these object properties, and subsequently confirms or corrects the robot's answers -as the case maybe.", "labels": [], "entities": []}, {"text": "We account for the uncertainty both in the linguistic inputs and in the visual perception.", "labels": [], "entities": []}, {"text": "We model this domain with two connected policies, one top policy handling the general interaction (including engagement and closing acts), and one bottom policy dedicated to answering each user question.", "labels": [], "entities": []}, {"text": "The top policy is encoded as a finite-state controller and the bottom policy as a POMDP solved using the SARSOP algorithm, available in the APPL toolkit 2 (.", "labels": [], "entities": [{"text": "APPL toolkit 2", "start_pos": 140, "end_pos": 154, "type": "DATASET", "confidence": 0.9183969497680664}]}, {"text": "A sample run is provided in Appendix A. The experiment was designed to empirically compare the performance of the presented algorithm with a simpler hierarchical control algorithm which does not use any activation vector, but where the top policy is blocked until the sub-policy releases its turn.", "labels": [], "entities": []}, {"text": "The policies themselves remain identical in both scenarios.", "labels": [], "entities": []}, {"text": "We implemented a handcrafted user simulator for the domain, and tested the policies with various levels of artificial noise.", "labels": [], "entities": []}, {"text": "The average return for the two scenarios are provided in.", "labels": [], "entities": []}, {"text": "The results show that activation values are beneficial for multi-policy dialogue management, especially in the presence of noise..", "labels": [], "entities": [{"text": "multi-policy dialogue management", "start_pos": 59, "end_pos": 91, "type": "TASK", "confidence": 0.7340735991795858}]}, {"text": "This is due to the soft control behaviour provided by the activation vector, which is more robust than hierarchical control.", "labels": [], "entities": []}, {"text": "Activation values provide a more finegrained mechanism for expressing the completion status of a policy, and therefore avoid fully \"blocking\" the control at a given level.", "labels": [], "entities": []}], "tableCaptions": []}