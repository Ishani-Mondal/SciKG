{"title": [{"text": "Improving a Method for Quantifying Readers' Impressions of News Articles with a Regression Equation", "labels": [], "entities": [{"text": "Improving", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9842108488082886}, {"text": "Quantifying Readers' Impressions of News Articles", "start_pos": 23, "end_pos": 72, "type": "TASK", "confidence": 0.9260416527589163}]}], "abstractContent": [{"text": "In this paper, we focus on the impressions that people gain from reading articles in Japanese newspapers, and we propose a method for extracting and quantifying these impressions in real numbers.", "labels": [], "entities": []}, {"text": "The target impressions are limited to those represented by three bipo-lar scales, \"Happy-Sad,\" \"Glad-Angry,\" and \"Peaceful-Strained,\" and the strength of each impression is computed as areal number between 1 and 7.", "labels": [], "entities": []}, {"text": "First, we implement a method for computing impression values of articles using an impression lexicon.", "labels": [], "entities": []}, {"text": "This lexicon represents a correlation between the words appearing in articles and the influence of these words on the readers' impressions, and is created from a newspaper database using a word co-occurrence based method.", "labels": [], "entities": []}, {"text": "We considered that some gaps would occur between values computed by such an unsuper-vised method and those judged by the readers, and we conducted experiments with 900 subjects to identify what gaps actually occurred.", "labels": [], "entities": []}, {"text": "Consequently, we propose anew approach that uses regression equations to correct impression values computed by the method.", "labels": [], "entities": []}, {"text": "Our investigation shows that accuracy is improved by a range of 23.2% to 42.7% by using regression equations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9995884299278259}]}], "introductionContent": [{"text": "In recent years, many researchers have been attempting to model the role of emotion in interactions between people or between people and computers, and to establish how to make computers recognize and express emotions).", "labels": [], "entities": []}, {"text": "However, there have not been many studies that have extracted the impressions that people form after seeing or listening to text and multimedia content.", "labels": [], "entities": []}, {"text": "For multimedia content such as music and images, several impressionbased retrieval methods have been proposed for locating paintings and pieces of music that convey impressions similar to those registered by users ().", "labels": [], "entities": []}, {"text": "By comparison, there are only a few studies that have extracted the readers' impressions gained from text such as news articles, novels, and poems (.", "labels": [], "entities": []}, {"text": "In this paper, we focus on the impressions that people gain from reading articles in Japanese newspapers, and we propose a method for extracting and quantifying these impressions in real numbers.", "labels": [], "entities": []}, {"text": "The target impressions are limited to those represented by three bipolar scales, \"Happy -Sad,\" \"Glad -Angry,\" and \"Peaceful -Strained,\" and the strength of each impression is computed as areal number between 1 and 7 denoting a position on the corresponding scale.", "labels": [], "entities": []}, {"text": "Then, interpretation of the position is grounded based on a seven-point scale.", "labels": [], "entities": []}, {"text": "For example, on the scale \"Happy -Sad,\" the score 1 equals \"Happy,\" the middle score 4 denotes \"Neither happy nor sad,\" and the score 7 equals \"Sad.\"", "labels": [], "entities": []}, {"text": "If the impression value of an article is 2.5, then the average reader will experience an intermediate impression between \"Comparatively happy (2)\" and \"A little happy (3)\" from reading the article.", "labels": [], "entities": [{"text": "A", "start_pos": 152, "end_pos": 153, "type": "METRIC", "confidence": 0.972268283367157}]}, {"text": "First, we assumed that words causing a certain impression from articles co-occur often with impression words that express that impression, and do not co-occur very often with impression words that express the opposite impression.", "labels": [], "entities": []}, {"text": "Proceeding with this assumption, we implemented a method for analyzing co-occurrence relationships between words in every article extracted from a newspaper database.", "labels": [], "entities": []}, {"text": "We then created an impression lexicon.", "labels": [], "entities": []}, {"text": "This lexicon represents a correlation between the words appearing in articles and the influence of these words on the readers' impressions.", "labels": [], "entities": []}, {"text": "We then implemented a method that computes impression values of articles using the lexicon.", "labels": [], "entities": []}, {"text": "We considered that some gaps occur between values computed by such an unsupervised method and those judged by the readers, and we conducted experiments with 900 subjects to identify what gaps actually occurred.", "labels": [], "entities": []}, {"text": "In these experiments, each subject read ten news articles and estimated her/his impressions of each article using the three bipolar scales.", "labels": [], "entities": []}, {"text": "Thereafter, for each scale, we drew a scatter diagram to identify the potential correspondence relationships between the values computed by the method and those judged by the subjects.", "labels": [], "entities": []}, {"text": "As a result, we found that the correspondence relationships could be approximately represented by cubic and quintic regression equations.", "labels": [], "entities": []}, {"text": "We, therefore, propose anew approach that uses regression equations to correct impression values computed by the method.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we present related work.", "labels": [], "entities": []}, {"text": "In Section 3, we present the design of the three bipolar scales, a method for the automated construction of an impression lexicon, and a method for computing impression values of articles using this lexicon.", "labels": [], "entities": []}, {"text": "In Section 4, we analyze the correspondence relationships between values computed using the lexicon and those judged by the readers, and based on the results of this analysis, we propose a method of using regression equations to correct impression values computed using the lexicon.", "labels": [], "entities": []}, {"text": "In Section 5, we investigate how far accuracy can be improved by using the regression equations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9984153509140015}]}, {"text": "Finally, in Section 6, we conclude the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "First, we estimated the accuracy of the proposed method for learned data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9995338916778564}]}, {"text": "For that, we used the data obtained in the experiments described in 4.1, and investigated how far gaps between the computed values and the averages of the manually rated values were reduced by using the regression equations.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "In this table, D Before denotes the Euclidean distance between the computed values without correction and the averages for the 90 articles, and D After denotes the Euclidean distance between the values corrected with the corresponding regression equation and the averages for the 90 articles.", "labels": [], "entities": [{"text": "Before", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.6315037608146667}, {"text": "After", "start_pos": 146, "end_pos": 151, "type": "METRIC", "confidence": 0.614822268486023}]}, {"text": "Then Rate1 was calculated as an improvement rate by the following formula: shows fairly high improvement rates in all the scales, and hence we find that accuracy is improved by using the regression equations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 153, "end_pos": 161, "type": "METRIC", "confidence": 0.9994544386863708}]}, {"text": "In particular, D After for the scale \"Glad -Angry\" is less than 0.5 or a half of a step and is sufficiently small.", "labels": [], "entities": [{"text": "D After", "start_pos": 15, "end_pos": 22, "type": "METRIC", "confidence": 0.9757714569568634}]}, {"text": "Next, we calculated the accuracy of the method () on which the proposed method is based, and compared it with that of the proposed method.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.999541163444519}]}, {"text": "The results are shown in Table 4.", "labels": [], "entities": []}, {"text": "In this table, D Baseline denotes the Euclidean 92.", "labels": [], "entities": [{"text": "Euclidean 92", "start_pos": 38, "end_pos": 50, "type": "DATASET", "confidence": 0.8996106088161469}]}, {"text": "Then Rate2 is calculated as an improvement rate by the following formula: Table 4 also shows that fairly high improvement rates were obtained in all the scales.", "labels": [], "entities": []}, {"text": "Note that the baseline method was implemented in the following way.", "labels": [], "entities": []}, {"text": "First, a pair of reference words was prepared for each scale.", "labels": [], "entities": []}, {"text": "Actually, the pair \"tanoshii (happy)\" and \"kanashii (sad)\" was used for the scale \"Happy -Sad\"; the pair \"ureshii (glad)\" and \"ikaru/okoru (get angry)\" for the scale \"Glad -Angry\"; and \"nodokada (peaceful)\" and \"kinpakusuru (strained)\" for the scale \"Peaceful -Strained.\"", "labels": [], "entities": []}, {"text": "Next, an impression lexicon for the baseline method was constructed from the news articles which were used to construct our impression lexicon.", "labels": [], "entities": []}, {"text": "The results shown in prove that the proposed method has a high level of accuracy for the articles used in obtaining the regression equations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9993895292282104}]}, {"text": "As the next step, we estimated the accuracy of the proposed method for unlearned data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9995808005332947}]}, {"text": "For that, we performed five-fold cross-validation using the data obtained in 4.1.", "labels": [], "entities": []}, {"text": "First, the data were randomly divided into five equal parts, each part consisting of data for 18 articles.", "labels": [], "entities": []}, {"text": "Next, a learned data set was created arbitrarily from four of the five parts, or data for 72 articles, and an unlearned data set was created from the remaining part, or data for 18 articles.", "labels": [], "entities": []}, {"text": "Regression analysis was then applied to the learned data set.", "labels": [], "entities": [{"text": "Regression", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9352135062217712}]}, {"text": "As a result, an optimal regression equation that expressed a correspondence relationship between the computed values and the averages of the manually rated values in the learned and D Mean in, we find that they are almost equivalent.", "labels": [], "entities": []}, {"text": "This means that the proposed method is also effective for unlearned data.", "labels": [], "entities": []}, {"text": "Finally, we investigated how the accuracy of the proposed method was influenced by the size of the newspaper database used in constructing an impression lexicon.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9993233680725098}]}, {"text": "First, using each of the 2002 to 2006 editions, the 2005 to 2006 editions, and the 2006 edition only, impression lexicons were constructed.", "labels": [], "entities": []}, {"text": "Three regression equations were then obtained for each lexicon in the same way.", "labels": [], "entities": []}, {"text": "Next, for each scale, we calculated the Euclidean distance between the values which were computed from all the 90 articles using each lexicon and corrected with the corresponding regression equation, and the averages obtained in 4.1.", "labels": [], "entities": [{"text": "Euclidean distance", "start_pos": 40, "end_pos": 58, "type": "METRIC", "confidence": 0.751733124256134}]}, {"text": "The results are shown in. shows that the accuracy of the proposed method is reduced slightly as the size of newspaper database 93 becomes smaller.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9996298551559448}, {"text": "newspaper database 93", "start_pos": 108, "end_pos": 129, "type": "DATASET", "confidence": 0.9249428908030192}]}, {"text": "Conversely, this suggests that the accuracy of the proposed method can be improved as the size of newspaper database increases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9993354678153992}]}, {"text": "We would like to verify this suggestion in the near future.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Specifications of our impression lexicon.", "labels": [], "entities": []}, {"text": " Table 3: Change of the Euclidean distance by using re- gression equations.", "labels": [], "entities": []}, {"text": " Table 4: Comparison with a baseline method.", "labels": [], "entities": []}, {"text": " Table 3. Then  Rate2 is calculated as an improvement rate by the  following formula:", "labels": [], "entities": []}, {"text": " Table 5: Estimation of overall accuracy based on five-fold  cross-validation.", "labels": [], "entities": [{"text": "Estimation", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9546504616737366}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9942776560783386}]}, {"text": " Table 6: Influence of size of target newspaper database to  Euclidean distance.", "labels": [], "entities": [{"text": "Influence", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9541266560554504}]}]}