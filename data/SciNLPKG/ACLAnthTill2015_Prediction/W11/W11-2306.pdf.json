{"title": [{"text": "Improving the Accessibility of Line Graphs in Multimodal Documents", "labels": [], "entities": [{"text": "Improving", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9697819352149963}]}], "abstractContent": [{"text": "This paper describes our work on improving access to the content of multimodal documents containing line graphs in popular media for people with visual impairments.", "labels": [], "entities": []}, {"text": "We provide an overview of our implemented system, including our method for recognizing and conveying the intended message of a line graph.", "labels": [], "entities": []}, {"text": "The textual description of the graphic generated by our system is presented at the most relevant point in the document.", "labels": [], "entities": []}, {"text": "We also describe ongoing work into obtaining additional propositions that elaborate on the intended message, and examine the potential benefits of analyzing the text and graphical content together in order to extend our system to produce summaries of entire multimodal documents.", "labels": [], "entities": []}], "introductionContent": [{"text": "Individuals with visual impairments have difficulty accessing the information contained in multimodal documents.", "labels": [], "entities": []}, {"text": "Although screen-reading software can render the text of the document as speech, the graphical content is largely inaccessible.", "labels": [], "entities": []}, {"text": "Here we consider information graphics (e.g., bar charts, line graphs) often found in popular media sources such as Time magazine, Businessweek, and USA Today.", "labels": [], "entities": [{"text": "USA Today", "start_pos": 148, "end_pos": 157, "type": "DATASET", "confidence": 0.9070454239845276}]}, {"text": "These graphics are typically intended to convey a message that is an important part of the overall story, yet this message is generally not repeated in the article text).", "labels": [], "entities": []}, {"text": "People who are unable to see and assimilate the graphical material will be left with only partial information.", "labels": [], "entities": []}, {"text": "While some work has addressed the accessibility of scientific graphics through alternative means like touch or sound (see Section 7), such graphs are designed for an audience of experts trained to use them for data visualization.", "labels": [], "entities": []}, {"text": "In contrast, graphs in popular media are constructed to make a point which should be obvious without complicated scientific reasoning.", "labels": [], "entities": []}, {"text": "We are thus interested in generating a textual presentation of the content of graphs in popular media.", "labels": [], "entities": []}, {"text": "Other research has focused on textual descriptions (e.g.,); however in that work the same information is included in the textual summary for each instance of a graph type (i.e., all summaries of line graphs contain the same sorts of information), and the summary does not attempt to present the overall intended message of the graph.", "labels": [], "entities": []}, {"text": "SIGHT) is a natural language system whose overall goal is providing blind users with interactive access to multimodal documents from electronically-available popular media sources.", "labels": [], "entities": []}, {"text": "To date, the SIGHT project has concentrated on simple bar charts.", "labels": [], "entities": [{"text": "SIGHT", "start_pos": 13, "end_pos": 18, "type": "TASK", "confidence": 0.9602436423301697}]}, {"text": "Its user interface is implemented as a browser helper object within Internet Explorer that works with the JAWS screen reader.", "labels": [], "entities": [{"text": "JAWS screen reader", "start_pos": 106, "end_pos": 124, "type": "DATASET", "confidence": 0.8993920286496481}]}, {"text": "When the system detects a bar chart in a document being read by the user, it prompts the user to use keystrokes to request a brief summary of the graphic capturing its primary contribution to the overall communicative goal of the document.", "labels": [], "entities": []}, {"text": "The summary text can either be read to the user with JAWS or read by the user with a screen magnifier tool.", "labels": [], "entities": [{"text": "JAWS", "start_pos": 53, "end_pos": 57, "type": "DATASET", "confidence": 0.9023144245147705}]}, {"text": "The interface also enables the user to request further information about the graphic, if desired.", "labels": [], "entities": []}, {"text": "However, SIGHT is limited to bar charts only.", "labels": [], "entities": [{"text": "SIGHT", "start_pos": 9, "end_pos": 14, "type": "TASK", "confidence": 0.8275464773178101}]}, {"text": "In this work, we follow the methodology put forth by SIGHT, but investigate producing a summary of 52 line graphs.", "labels": [], "entities": []}, {"text": "Line graphs have different discourse goals and communicative signals than bar charts, 1 and thus require significantly different processing.", "labels": [], "entities": []}, {"text": "In addition, our work addresses the issue of coherent placement of a graphic's summary when reading the text to the user and considers the summarization of entire documents -not just their graphics.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}