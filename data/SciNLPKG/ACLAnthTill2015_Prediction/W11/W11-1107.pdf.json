{"title": [{"text": "Simultaneous Similarity Learning and Feature-Weight Learning for Document Clustering", "labels": [], "entities": []}], "abstractContent": [{"text": "A key problem in document classification and clustering is learning the similarity between documents.", "labels": [], "entities": [{"text": "document classification", "start_pos": 17, "end_pos": 40, "type": "TASK", "confidence": 0.7158564329147339}]}, {"text": "Traditional approaches include estimating similarity between feature vectors of documents where the vectors are computed using TF-IDF in the bag-of-words model.", "labels": [], "entities": [{"text": "estimating similarity between feature vectors of documents", "start_pos": 31, "end_pos": 89, "type": "TASK", "confidence": 0.7834422630923135}]}, {"text": "However, these approaches do notwork well when either similar documents do not use the same vocabulary or the feature vectors are not estimated correctly.", "labels": [], "entities": []}, {"text": "In this paper, we represent documents and keywords using multiple layers of connected graphs.", "labels": [], "entities": []}, {"text": "We pose the problem of simultaneously learning similarity between documents and keyword weights as an edge-weight regu-larization problem over the different layers of graphs.", "labels": [], "entities": []}, {"text": "Unlike most feature weight learning algorithms, we propose an unsupervised algorithm in the proposed framework to simultaneously optimize similarity and the keyword weights.", "labels": [], "entities": []}, {"text": "We extrinsically evaluate the performance of the proposed similarity measure on two different tasks, clustering and classification.", "labels": [], "entities": []}, {"text": "The proposed similarity measure out-performs the similarity measure proposed by (Muthukrishnan et al., 2010), a state-of-the-art classification algorithm (Zhou and Burges, 2007) and three different baselines on a variety of standard, large data sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "The recent upsurge in the amount of text available due to the widespread growth of the Internet has led to the need for large scale, efficient Machine Learning (ML), Information Retrieval (IR) tools for text mining.", "labels": [], "entities": [{"text": "text mining", "start_pos": 203, "end_pos": 214, "type": "TASK", "confidence": 0.8216705322265625}]}, {"text": "At the heart of many of the ML, IR algorithms is the need fora good similarity measure between documents.", "labels": [], "entities": [{"text": "ML, IR", "start_pos": 28, "end_pos": 34, "type": "TASK", "confidence": 0.7382503747940063}]}, {"text": "For example, a better similarity measure almost always leads to better performance in tasks like document classification, clustering, etc.", "labels": [], "entities": [{"text": "document classification", "start_pos": 97, "end_pos": 120, "type": "TASK", "confidence": 0.7735403180122375}]}, {"text": "Traditional approaches represent documents with many keywords using a simple feature vector description.", "labels": [], "entities": []}, {"text": "Then, similarity between two documents is estimated using the dot product between their corresponding vectors.", "labels": [], "entities": [{"text": "similarity", "start_pos": 6, "end_pos": 16, "type": "METRIC", "confidence": 0.9787524342536926}]}, {"text": "However, such similarity measures do not use all the keywords together and hence, suffer from problems due to sparsity.", "labels": [], "entities": []}, {"text": "There are two major issues in computing similarity between documents \u2022 Similar documents may not use the same vocabulary.", "labels": [], "entities": []}, {"text": "\u2022 Estimating feature weights or weight of a keyword to the document it is contained in.", "labels": [], "entities": []}, {"text": "For example, consider two publications, X and Y , in the field of Machine Learning.", "labels": [], "entities": [{"text": "Machine Learning", "start_pos": 66, "end_pos": 82, "type": "TASK", "confidence": 0.877763032913208}]}, {"text": "Let X be a paper on clustering while Y is on classification.", "labels": [], "entities": []}, {"text": "Although the two publications use very different vocabulary, they are semantically similar.", "labels": [], "entities": []}, {"text": "Keyword weights are mostly estimated using the frequency of the keyword in the document.", "labels": [], "entities": []}, {"text": "For example, TF-IDF based scoring is the most commonly used approach to compute keyword weights to compute similarity between documents.", "labels": [], "entities": []}, {"text": "However, suppose publications X and Y mention the keyword \"'Machine Learning\"' only once.", "labels": [], "entities": [{"text": "Machine Learning\"'", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.7895108858744303}]}, {"text": "Although, they are mentioned only once in the text of the document, for the purposes of computing semantic similarity between the docu-ments, it would be beneficial to give it a high keyword weight.", "labels": [], "entities": []}, {"text": "A commonly used approach to estimate semantic similarity between documents is to use an external knowledge source like WordNet ().", "labels": [], "entities": [{"text": "estimate semantic similarity between documents", "start_pos": 28, "end_pos": 74, "type": "TASK", "confidence": 0.8201126456260681}, {"text": "WordNet", "start_pos": 119, "end_pos": 126, "type": "DATASET", "confidence": 0.9536998271942139}]}, {"text": "However, these approaches are domain dependent and language dependent.", "labels": [], "entities": []}, {"text": "If document similarity cannot be estimated accurately using just the text, there have been approaches incorporating multiple sources of similarity like link similarity, authorship similarity between publications (.) also uses multiple sources of similarity.", "labels": [], "entities": [{"text": "link similarity", "start_pos": 152, "end_pos": 167, "type": "METRIC", "confidence": 0.9121453762054443}]}, {"text": "In addition to improving similarity estimates between documents, it also improves similarity estimates between keywords.", "labels": [], "entities": [{"text": "similarity", "start_pos": 82, "end_pos": 92, "type": "METRIC", "confidence": 0.9478095173835754}]}, {"text": "Co-clustering () based approaches are used to alleviate problems due to the sparsity and highdimensionality of the data.", "labels": [], "entities": []}, {"text": "In co-clustering, the keywords and the documents are simultaneously clustered by exploiting the duality between them.", "labels": [], "entities": []}, {"text": "However, the approach relies solely on the keyword distributions to cluster the documents and vice-versa.", "labels": [], "entities": []}, {"text": "It does not take into account the inherent similarity between the keywords (documents) when clustering the documents (keywords).", "labels": [], "entities": []}, {"text": "Also, co-clustering takes as input the weight of all keywords to corresponding documents.", "labels": [], "entities": []}], "datasetContent": [{"text": "It is very hard to evaluate similarity measures in isolation.", "labels": [], "entities": []}, {"text": "Thus, most of the algorithms to compute similarity scores are evaluated extrinsically, i.e, the similarity scores are used for an external task like clustering or classification and the performance in the external task is used as the performance measure for the similarity scores.", "labels": [], "entities": [{"text": "clustering or classification", "start_pos": 149, "end_pos": 177, "type": "TASK", "confidence": 0.7079614897569021}]}, {"text": "This also helps demonstrate the different applications of the computed similarity measure.", "labels": [], "entities": []}, {"text": "Thus, we perform a variety of different experiments on standard data sets to illustrate the improved performance of the proposed similarity measure.", "labels": [], "entities": []}, {"text": "There are three natural variants of the algorithm, \u2022 Unified: We compare against the edge-weight regularization algorithm proposed in.", "labels": [], "entities": []}, {"text": "The algorithm has the same representation as our algorithm but the optimization is strictly defined over the edge weights in the two layers of the graph, w i j sand not on the keyword weights.", "labels": [], "entities": []}, {"text": "Therefore, Z i j are maintained constant throughout the algorithm.", "labels": [], "entities": []}, {"text": "\u2022 Unified-binary: In this variant, we initialize the keyword weights to 1, i.e, Z i j = 1 whenever document i contains the keyword j.: Details of a few sample papers classified according to research topic \u2022 Unified-TFIDF: We initialize the keyword weights to the TFIDF scores, Z i j is set to the TFIDF score of keyword j for document i.", "labels": [], "entities": []}, {"text": "Experiment Set I: We compare our similarity measure against other similarity measures in the context of classification.", "labels": [], "entities": []}, {"text": "We also compare against a state of the art classification algorithm which uses different similarity measures due to different feature types without integrating them into one single similarity measure.", "labels": [], "entities": []}, {"text": "Specifically, we compare our algorithm against three other similarity baselines in the context of classification which are listed below.", "labels": [], "entities": []}, {"text": "\u2022 Content Similarity: Similarity is computed using just the feature vector representation using just the text.", "labels": [], "entities": [{"text": "Content Similarity", "start_pos": 2, "end_pos": 20, "type": "TASK", "confidence": 0.6834193468093872}]}, {"text": "We use cosine similarity after preprocessing each document into a tf.idf vector for the AAN data set.", "labels": [], "entities": [{"text": "AAN data set", "start_pos": 88, "end_pos": 100, "type": "DATASET", "confidence": 0.9454440673192342}]}, {"text": "For all other data sets, we use the cosine similarity on the binary feature vector representation that is available.", "labels": [], "entities": []}, {"text": "\u2022 Link Similarity: Similarity is computed using only the links (citations, in the case of publications).", "labels": [], "entities": []}, {"text": "To compute link similarity, we use the node similarity algorithm proposed by) using a random walk of length 3 on the link graph.", "labels": [], "entities": [{"text": "link similarity", "start_pos": 11, "end_pos": 26, "type": "TASK", "confidence": 0.7617683112621307}]}, {"text": "\u2022 Linear combination: The content similarity (CS) and link similarity (LS) between documents x and y are combined in a linear fashion as \u03b1CS(x, y) + (1 \u2212 \u03b1)LS(x, y).", "labels": [], "entities": [{"text": "link similarity (LS)", "start_pos": 54, "end_pos": 74, "type": "METRIC", "confidence": 0.9601493954658509}]}, {"text": "We tried different values of \u03b1 and report only the best accuracy that can be achieved using linear combination of similarity measures.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9993411898612976}]}, {"text": "Note that this is an upper bound on the accuracy of Multiple Kernel Learning with the restriction of the combination being affine.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.999583899974823}, {"text": "Multiple Kernel Learning", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.7082411249478658}]}, {"text": "We also compare our algorithm against the following algorithms SC-MV: We compare our algorithm against the spectral classification algorithm for data with multiple views (.", "labels": [], "entities": [{"text": "spectral classification", "start_pos": 107, "end_pos": 130, "type": "TASK", "confidence": 0.7170984148979187}]}, {"text": "The algorithm tries to classify data when multiple views of the data are available.", "labels": [], "entities": []}, {"text": "The multiple views are represented using multiple homogeneous graphs with a common vertex set.", "labels": [], "entities": []}, {"text": "In each graph, the edge weights represent similarity between the nodes computed using a single feature type.", "labels": [], "entities": []}, {"text": "For our experiments, we used the link similarity graph and the content similarity graph as described above as the two views of the same data We use a semi-supervised graph classification algorithm () to perform the classification.", "labels": [], "entities": []}, {"text": "Experiment Set II: We illustrate the improved performance of our similarity measure in the context of clustering.", "labels": [], "entities": []}, {"text": "We compare our similarity measure against the three similarity baselines mentioned above.", "labels": [], "entities": [{"text": "similarity measure", "start_pos": 15, "end_pos": 33, "type": "METRIC", "confidence": 0.9715472459793091}]}, {"text": "We use a spectral graph clustering algorithm proposed in ( to perform the clustering.", "labels": [], "entities": []}, {"text": "We performed our experiments on three different data sets.", "labels": [], "entities": []}, {"text": "The three data sets are explained below.", "labels": [], "entities": []}, {"text": "\u2022 AAN Data: The ACL Anthology is a collection of papers from the Computational Linguistics journal as well as proceedings from ACL conferences and workshops and includes 15, 160 papers.", "labels": [], "entities": [{"text": "AAN Data: The ACL Anthology", "start_pos": 2, "end_pos": 29, "type": "DATASET", "confidence": 0.8372985124588013}]}, {"text": "To build the ACL Anthology Network (AAN),) manually performed some preprocessing tasks including parsing references and building the network metadata, the citation, and the author collaboration networks.", "labels": [], "entities": [{"text": "ACL Anthology Network (AAN),)", "start_pos": 13, "end_pos": 42, "type": "DATASET", "confidence": 0.855470597743988}]}, {"text": "The full AAN includes the raw text of all the papers in addition to full citation and collaboration networks.", "labels": [], "entities": []}, {"text": "We chose a subset of papers in 3 topics (Ma- chine Translation, Dependency Parsing, Summarization) from the ACL anthology.", "labels": [], "entities": [{"text": "Ma- chine Translation", "start_pos": 41, "end_pos": 62, "type": "TASK", "confidence": 0.6018312573432922}, {"text": "Dependency Parsing", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.7812227606773376}, {"text": "Summarization", "start_pos": 84, "end_pos": 97, "type": "TASK", "confidence": 0.9224279522895813}, {"text": "ACL anthology", "start_pos": 108, "end_pos": 121, "type": "DATASET", "confidence": 0.9755456447601318}]}, {"text": "These topics are three main research areas in Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 46, "end_pos": 79, "type": "TASK", "confidence": 0.7626132269700369}]}, {"text": "Specifically, we collected all papers which were cited by papers whose titles contain any of the following phrases, \"'Dependency Parsing\"', \"'Machine Translation\"', \"'Summarization\"'.", "labels": [], "entities": [{"text": "Dependency Parsing\"'", "start_pos": 118, "end_pos": 138, "type": "TASK", "confidence": 0.812365730603536}, {"text": "Machine Translation\"'", "start_pos": 142, "end_pos": 163, "type": "TASK", "confidence": 0.8119978308677673}, {"text": "Summarization\"'", "start_pos": 167, "end_pos": 182, "type": "TASK", "confidence": 0.9346030354499817}]}, {"text": "From this list, we removed all the papers which contained any of the above phrases in their title because this would make the clustering task easy.", "labels": [], "entities": [{"text": "clustering", "start_pos": 126, "end_pos": 136, "type": "TASK", "confidence": 0.973251223564148}]}, {"text": "The pruned list contains 1190 papers.", "labels": [], "entities": [{"text": "pruned list contains 1190 papers", "start_pos": 4, "end_pos": 36, "type": "DATASET", "confidence": 0.7778349995613099}]}, {"text": "We manually classified each paper into four classes (Dependency Parsing, Machine Translation, Summarization, Other) by considering the full text of the paper.", "labels": [], "entities": [{"text": "Dependency Parsing", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.7513377070426941}, {"text": "Machine Translation", "start_pos": 73, "end_pos": 92, "type": "TASK", "confidence": 0.7900450229644775}, {"text": "Summarization", "start_pos": 94, "end_pos": 107, "type": "TASK", "confidence": 0.8597090244293213}]}, {"text": "The manually cleaned data set consists of 275 Machine Translation papers, 73 Dependency Parsing papers and 32 Summarization papers.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 46, "end_pos": 65, "type": "TASK", "confidence": 0.7697666585445404}]}, {"text": "lists a few sample papers from each class.", "labels": [], "entities": []}, {"text": "WebKB(: The data set consists of a subset of the original WebKB data set.", "labels": [], "entities": [{"text": "WebKB", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9426796436309814}, {"text": "WebKB data set", "start_pos": 58, "end_pos": 72, "type": "DATASET", "confidence": 0.953610897064209}]}, {"text": "The corpus consists of 877 web pages collected from four different universities.", "labels": [], "entities": []}, {"text": "Each web page is represented by a 0/1-valued word vector with 1703 unique words after stemming and removing stopwords.", "labels": [], "entities": []}, {"text": "All words with document frequency less than 10 were removed.", "labels": [], "entities": []}, {"text": "Cora(: The Cora dataset consists of 2708 scientific publications classified into one of seven classes.", "labels": [], "entities": [{"text": "Cora", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.7351762652397156}, {"text": "Cora dataset", "start_pos": 11, "end_pos": 23, "type": "DATASET", "confidence": 0.9123342335224152}]}, {"text": "The citation network consists of 5429 links.", "labels": [], "entities": []}, {"text": "Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary.", "labels": [], "entities": []}, {"text": "The dictionary consists of 1433 unique words.", "labels": [], "entities": []}, {"text": "For all the data sets, we constructed two graphs, the kewyord feature graph and the link similarity graph.", "labels": [], "entities": []}, {"text": "The keyword feature layer graph, G f = (V f , E f , w f ) is a weighted graph where V f is the set of all features.", "labels": [], "entities": []}, {"text": "The edge weight between keywords f i and f j represents the similarity between the features.", "labels": [], "entities": []}, {"text": "The edge weights are initialized to the cosine similarity between their corresponding document vectors.", "labels": [], "entities": []}, {"text": "The link similarity graph, is another weighted graph where V o is the set of objects.", "labels": [], "entities": []}, {"text": "The edge weight represents the similarity between the documents and is initialized to the similarity between the documents due to the link structure.", "labels": [], "entities": []}, {"text": "The link similarity between two documents is computed using the similarity measure proposed by) on the citation graph.", "labels": [], "entities": []}, {"text": "We also performed experiments by initializing the similarity between documents to the keyword similarity.", "labels": [], "entities": []}, {"text": "Although, our algorithm still outperforms other algorithms and the baselines (not shown due to space restrictions), the accuracy using citation similarity is higher.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9995137453079224}]}, {"text": "shows the accuracy of the classification obtained using different similarity measures.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9996984004974365}]}, {"text": "It can be seen that the proposed algorithm (both the variants) performs much better than other similarity measures by a large margin.", "labels": [], "entities": []}, {"text": "The algorithm performs much better when more information is provided in the form of TF-IDF scores.", "labels": [], "entities": []}, {"text": "We attribute this to the rich representation of the data.", "labels": [], "entities": []}, {"text": "In our algorithm, the data is represented as a set of heterogeneous graphs (layers) which are connected together instead of the normal feature vector representation.", "labels": [], "entities": []}, {"text": "Thus, we can leverage on the similarity between the keywords and the objects (documents) to iteratively improve similarity in both layers.", "labels": [], "entities": [{"text": "similarity", "start_pos": 112, "end_pos": 122, "type": "METRIC", "confidence": 0.9759144186973572}]}, {"text": "Whereas, in the case of the algorithm in ( all the graphs are isolated homogeneous graphs.", "labels": [], "entities": []}, {"text": "Hence there is no information transfer across the different graphs.", "labels": [], "entities": []}], "tableCaptions": []}