{"title": [{"text": "Lexical Co-occurrence, Statistical Significance, and Word Association", "labels": [], "entities": [{"text": "Word Association", "start_pos": 53, "end_pos": 69, "type": "TASK", "confidence": 0.696685180068016}]}], "abstractContent": [{"text": "Lexical co-occurrence is an important cue for detecting word associations.", "labels": [], "entities": [{"text": "detecting word associations", "start_pos": 46, "end_pos": 73, "type": "TASK", "confidence": 0.859291156133016}]}, {"text": "We propose anew measure of word association based on anew notion of statistical significance for lexical co-occurrences.", "labels": [], "entities": [{"text": "word association", "start_pos": 27, "end_pos": 43, "type": "TASK", "confidence": 0.7437053620815277}]}, {"text": "Existing measures typically rely on global unigram frequencies to determine expected co-occurrence counts.", "labels": [], "entities": []}, {"text": "Instead , we focus only on documents that contain both terms (of a candidate word-pair) and ask if the distribution of the observed spans of the word-pair resembles that under a random null model.", "labels": [], "entities": []}, {"text": "This would imply that the words in the pair are not related strongly enough for one word to influence placement of the other.", "labels": [], "entities": []}, {"text": "However, if the words are found to occur closer together than explainable by the null model, then we hypothesize a more direct association between the words.", "labels": [], "entities": []}, {"text": "Through extensive empirical evaluation on most of the publicly available benchmark data sets, we show the advantages of our measure over existing co-occurrence measures.", "labels": [], "entities": []}], "introductionContent": [{"text": "Lexical co-occurrence is an important indicator of word association and this has motivated several co-occurrence 1 measures for word association like PMI, LLR, Dice, and CWCD (.", "labels": [], "entities": [{"text": "word association", "start_pos": 51, "end_pos": 67, "type": "TASK", "confidence": 0.7647200226783752}]}, {"text": "In this paper, we present anew measure of word association based on anew notion of statistical significance for lexical co-occurrences.", "labels": [], "entities": [{"text": "word association", "start_pos": 42, "end_pos": 58, "type": "TASK", "confidence": 0.7443757653236389}]}, {"text": "In general, a lexical co-occurrence could refer to a pair of words that co-occur in a large number of documents; or it could refer to a pair of words that, although co-occur only in a small number of documents, occur close to each other within those documents.", "labels": [], "entities": []}, {"text": "We formalize these ideas and construct a significance test that allows us to detect different kinds of co-occurrences within a single unified framework (a feature which is absent in current measures for co-occurrence).", "labels": [], "entities": []}, {"text": "Another distinguishing feature of our measure is that it is based solely on the cooccurrence counts in the documents containing both words of the pair, unlike all existing measures which also take global unigram frequencies in account.", "labels": [], "entities": []}, {"text": "We need a null hypothesis that can account for an observed co-occurrence as a pure chance event and this in-turn requires a corpus generation model.", "labels": [], "entities": []}, {"text": "Documents in a corpus can be assumed to be generated independent of each other.", "labels": [], "entities": []}, {"text": "Existing cooccurrence measures further assume that each document is drawn from a multinomial distribution based on global unigram frequencies.", "labels": [], "entities": []}, {"text": "The main concern with such a null model is the overbearing influence of the unigram frequencies on the detection of word associations.", "labels": [], "entities": [{"text": "detection of word associations", "start_pos": 103, "end_pos": 133, "type": "TASK", "confidence": 0.7522792816162109}]}, {"text": "For example, the association between anomochilidae (dwarf pipe snakes) and snake could go undetected in our wikipedia corpus, since less than 0.1% of the pages containing snake also contained anomochilidae.", "labels": [], "entities": []}, {"text": "Also, undercurrent models, the expected span 2 of a word pair is very sensitive to the associated unigram frequencies: the expected span of a word pair composed of low frequency unigrams is much larger than that with high frequency unigrams.", "labels": [], "entities": []}, {"text": "This is contrary to how word associa-tions appear in language, where semantic relationships manifest with small inter-word distances irrespective of the underlying unigram distributions.", "labels": [], "entities": []}, {"text": "Based on these considerations we employ a null model that represents each document as a bag of words . A random permutation of the associated bag of words gives a linear representation for the document.", "labels": [], "entities": []}, {"text": "Under this null model, the locations of an unrelated pair of words will likely be randomly distributed in the documents in which they co-occur.", "labels": [], "entities": []}, {"text": "If the observed span distribution of a word-pair resembles that under the (random permutation) null model, then the relation between the words is not strong enough for one word to influence the placement of the other.", "labels": [], "entities": []}, {"text": "However, if the words are found to occur closer together than explainable by our null model, then we hypothesize a more direct association between the words.", "labels": [], "entities": []}, {"text": "Therefore, this null model detects biases in span distributions of word-pairs while being agnostic to variations in global unigram frequencies.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew measure of word association based on the statistical significance of the observed span distribution of a word-pair.", "labels": [], "entities": [{"text": "word association", "start_pos": 42, "end_pos": 58, "type": "TASK", "confidence": 0.7707010507583618}]}, {"text": "We perform extensive experiments on all the publicly available benchmark data sets and compare our measure against other popular co-occurrence measures.", "labels": [], "entities": []}, {"text": "Our experiments demonstrate the advantages of our measure overall the competing measures.", "labels": [], "entities": []}, {"text": "The ranked list of word associations output by our measure has the best correlation with the corresponding gold-standard in three (out of seven) data sets in our experiments, while remaining in the top three in other four datasets.", "labels": [], "entities": []}, {"text": "While different measures perform best on different data sets, our measure outperforms other measures by being consistently either the best measure or very close to the best measure on all the data sets.", "labels": [], "entities": []}, {"text": "The average deviation of our measure's correlation with the gold-standard from the best measure's correlation with the gold-standard (average taken across all the datasets) is 0.02, which is the least average deviation among all the measures, the next best deviations being 0.04 and 0.06.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "We present our notion of statistical significance of span distribution in Section 2.", "labels": [], "entities": []}, {"text": "Algorithm for computing the proposed word association measure is described in Section 3.", "labels": [], "entities": []}, {"text": "We discuss related work in Section 4.", "labels": [], "entities": []}, {"text": "Performance evaluation is presented in Section 5 followed with conclusions in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Two main aspects of word association studied in literature are: a) semantic relatedness, and b) free association.", "labels": [], "entities": [{"text": "word association", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.7448294758796692}]}, {"text": "Semantic relatedness encompasses many different relationships between words, like synonymy, meronymy, antonymy, and functional association ().", "labels": [], "entities": []}, {"text": "Free association refers to the first response-words that come to mind when presented with a stimulus..", "labels": [], "entities": []}, {"text": "We experiment with all the publicly available datasets that come with gold standard judgement of these aspects, except the very small ones with less than 80 word-pairs 8 .  Details 9 of the datasets used in our experiments are listed in.", "labels": [], "entities": []}, {"text": "Each data set comes with a goldstandard of human judgments -a ranked list of association scores for the word-pairs in the data set.", "labels": [], "entities": []}, {"text": "The wordsim dataset was prepared by asking the subjects to estimate the relatedness of the word pairs on a 8 (MillerCharles, RubensteinGoodenough ( and TOEFL) We removed word-pairs containing multiword expressions.", "labels": [], "entities": [{"text": "TOEFL", "start_pos": 152, "end_pos": 157, "type": "DATASET", "confidence": 0.6888052821159363}]}, {"text": "For data sets with more than 10,000 word-pairs, we filtered out pairs that contain stop words listed in    scale from 0 to 10 ().", "labels": [], "entities": []}, {"text": "The methodology for collecting free association data is explained at: The degree of free association between a stimulus (S) and response (R) is the percentage of respondents who respond R as the first response when presented with stimulus S.", "labels": [], "entities": []}, {"text": "These datasets are of varying size, and they were constructed at different point in time, in different geographies.", "labels": [], "entities": []}, {"text": "This allows us to compare different measures comprehensively under varying range of circumstances.", "labels": [], "entities": []}, {"text": "To the best of our knowledge, no previous work has reported such a detailed comparison of co-occurrence measures.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. The main  data-dependent computations for a spanned measure are in determining span-constrained frequencies; all  other steps are simple arithmetic operations or mem- ory lookups. To illustrate this, Procedure 4 gives de- tails of computing PMI. The comparison of Proce- dures 3 and 4 shows their almost parallel structures.  The main overhead in these procedures is incurred  in line 7, where span-constrained frequencies in a  given document are computed.", "labels": [], "entities": []}, {"text": " Table 3: Characteristics of data sets used.", "labels": [], "entities": []}, {"text": " Table 4: Comparison of the average Spearman coefficients obtained across five cross-validation runs by different  measures. The best performing measure for each data-set is shown in bold. All standard deviations for Edinburg and  Florida were less than 0.01, for Kent and Minnesota were between 0.01 and 0.02, for White-Abrams were between  0.05 and 0.08, for Goldfarb-Halpern between 0.05 and 0.15 and for wordsim were between 0.02 and 0.15. Number of  word-pairs in each dataset is shown in brackets against its name.", "labels": [], "entities": []}, {"text": " Table 5: Comparison of deviations from the best performing measure on each data set. Number of word-pairs in each  dataset is shown in brackets against its name. Figures in brackets against the deviation values denote the ranks of the  measures in the corresponding data sets.", "labels": [], "entities": []}, {"text": " Table 6: Comparison of co-occurrence based measures with knowledge-based and distributional similarity based  measures. These other measures have not been applied to the free association datasets shown in Table 3. Data for  missing entries is not available. Note that sim and rel are subsets of wordsim dataset. Number of word-pairs in each  dataset is shown in brackets against its name.", "labels": [], "entities": []}]}