{"title": [{"text": "A Cascaded Classification Approach to Semantic Head Recognition", "labels": [], "entities": [{"text": "Semantic Head Recognition", "start_pos": 38, "end_pos": 63, "type": "TASK", "confidence": 0.7402299642562866}]}], "abstractContent": [{"text": "Most NLP systems use tokenization as part of preprocessing.", "labels": [], "entities": []}, {"text": "Generally, tokenizers are based on simple heuristics and do not recognize multi-word units (MWUs) like hot dog or black hole unless a precompiled list of MWUs is available.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew cascaded model for detecting MWUs of arbitrary length for tokenization, focusing on noun phrases in the physics domain.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 89, "end_pos": 101, "type": "TASK", "confidence": 0.9699796438217163}]}, {"text": "We adopt a classification approach because-unlike other work on MWUs-tokenization requires a completely automatic approach.", "labels": [], "entities": []}, {"text": "We achieve an accuracy of 68% for recognizing non-compositional MWUs and show that our MWU recognizer improves retrieval performance when used as part of an information retrieval system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9994485974311829}]}], "introductionContent": [{"text": "Most NLP systems use tokenization as part of preprocessing.", "labels": [], "entities": []}, {"text": "Generally, tokenizers are based on simple heuristics and do not recognize multi-word units (MWUs) like hot dog or black hole.", "labels": [], "entities": []}, {"text": "Our long-term goal is to build MWU-aware tokenizers that are used as part of the standard toolkit for NLP preprocessing alongside part-of-speech and named-entity tagging.", "labels": [], "entities": []}, {"text": "We define an MWU as a sequence of words that has properties that cannot be inferred from the component words (cf. e.g.,).", "labels": [], "entities": []}, {"text": "The most important of these properties is non-compositionality, the fact that the meaning of a phrase cannot be predicted from the meanings of its component words.", "labels": [], "entities": []}, {"text": "For example, a hot dog is not a hot animal but a sausage in a bun and a black hole in astrophysics is a region of space with special properties, not a dark cavity.", "labels": [], "entities": []}, {"text": "The correct recognition of MWUs is an important building block of many NLP tasks.", "labels": [], "entities": [{"text": "recognition of MWUs", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.7522488633791605}, {"text": "NLP", "start_pos": 71, "end_pos": 74, "type": "TASK", "confidence": 0.9569533467292786}]}, {"text": "For example, in information retrieval (IR) the query hot dog should not retrieve documents that only contain the words hot and dog individually, outside of the phrase hot dog.", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 16, "end_pos": 42, "type": "TASK", "confidence": 0.8608221352100373}]}, {"text": "In this study, we focus on noun phrases in the physics domain.", "labels": [], "entities": []}, {"text": "For specialized domains such as physics, adaptable and reliable MWU recognition is of particular importance because comprehensive and up-to-date lists of MWUs are not available and would have to be created by hand.", "labels": [], "entities": [{"text": "MWU recognition", "start_pos": 64, "end_pos": 79, "type": "TASK", "confidence": 0.9678411781787872}]}, {"text": "We chose noun phrases because domain-specific terminology is commonly encoded in noun phrase MWUs; other types of phrases -e.g., verb constructions -rarely give rise to fixed domain-specific multi-word sequences that should be treated as a unit.", "labels": [], "entities": []}, {"text": "We cast the task of MWU tokenization as semantic head recognition in this paper.", "labels": [], "entities": [{"text": "MWU tokenization", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.7604566514492035}, {"text": "semantic head recognition", "start_pos": 40, "end_pos": 65, "type": "TASK", "confidence": 0.6346698304017385}]}, {"text": "The importance of syntactic heads for many NLP tasks is generally accepted.", "labels": [], "entities": []}, {"text": "For example, in coreference resolution identity of syntactic heads is predictive of coreference; in parse disambiguation, the syntactic head of a noun phrase is a powerful feature for resolving attachment ambiguities.", "labels": [], "entities": [{"text": "coreference resolution identity of syntactic heads", "start_pos": 16, "end_pos": 66, "type": "TASK", "confidence": 0.9150463143984476}, {"text": "parse disambiguation", "start_pos": 100, "end_pos": 120, "type": "TASK", "confidence": 0.7013421207666397}, {"text": "resolving attachment ambiguities", "start_pos": 184, "end_pos": 216, "type": "TASK", "confidence": 0.8189897537231445}]}, {"text": "However, in all of these cases, the syntactic head is only an approximation of the information that is really needed; the underlying assumption made when using the syntactic head as a substitute for the entire phrase is that the syntactic head is representative of the phrase.", "labels": [], "entities": []}, {"text": "This is not the case when the phrase is non-compositional.", "labels": [], "entities": []}, {"text": "We define the semantic head of a noun phrase as the non-compositional part of a phrase.", "labels": [], "entities": []}, {"text": "Semantic heads would serve most NLP tasks better than syntactic heads.", "labels": [], "entities": []}, {"text": "For example, a coreference resolution system is misled if it looks at syntactic heads to termine possible coreference of a hot dog . .", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.9526659250259399}]}, {"text": "the dog in I first ate a hot dog and then fed the dog.", "labels": [], "entities": []}, {"text": "This is not the case fora system that makes the decision based on the semantic heads hot dog of a hot dog and dog of the dog.", "labels": [], "entities": []}, {"text": "The specific NLP application we evaluate in this paper is information retrieval.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 58, "end_pos": 79, "type": "TASK", "confidence": 0.87900111079216}]}, {"text": "We will show that semantic head recognition improves the performance of an information retrieval system.", "labels": [], "entities": [{"text": "semantic head recognition", "start_pos": 18, "end_pos": 43, "type": "TASK", "confidence": 0.7580360571543375}]}, {"text": "We introduce a cascaded classification framework for recognizing semantic heads that allows us to treat noun phrases of arbitrary length.", "labels": [], "entities": []}, {"text": "We use a number of previously proposed features for recognizing noncompositionality and semantic heads.", "labels": [], "entities": []}, {"text": "In addition, we compare three features that measure contextual similarity.", "labels": [], "entities": []}, {"text": "Our main contributions in this paper are as follows.", "labels": [], "entities": []}, {"text": "First, we introduce the notion of semantic head, in analogy to syntactic head, and propose semantic head recognition as anew component of NLP preprocessing.", "labels": [], "entities": [{"text": "semantic head recognition", "start_pos": 91, "end_pos": 116, "type": "TASK", "confidence": 0.6449844837188721}]}, {"text": "Second, we develop a cascaded classification framework for semantic head recognition.", "labels": [], "entities": [{"text": "semantic head recognition", "start_pos": 59, "end_pos": 84, "type": "TASK", "confidence": 0.6964930295944214}]}, {"text": "Third, we investigate the utility of contextual similarity for detecting non-compositionality and show that it significantly enhances a baseline semantic head recognizer.", "labels": [], "entities": []}, {"text": "However, we also identify a number of challenges of using contextual similarity in high-confidence semantic head recognition.", "labels": [], "entities": [{"text": "semantic head recognition", "start_pos": 99, "end_pos": 124, "type": "TASK", "confidence": 0.6396119296550751}]}, {"text": "Fourth, we show that our approach to semantic head recognition improves the performance of an IR system.", "labels": [], "entities": [{"text": "semantic head recognition", "start_pos": 37, "end_pos": 62, "type": "TASK", "confidence": 0.7601879636446635}, {"text": "IR", "start_pos": 94, "end_pos": 96, "type": "TASK", "confidence": 0.9576148986816406}]}, {"text": "Section 2 discusses previous work.", "labels": [], "entities": []}, {"text": "In Section 3 we introduce semantic heads and present our cascaded model for semantic head recognition.", "labels": [], "entities": [{"text": "semantic head recognition", "start_pos": 76, "end_pos": 101, "type": "TASK", "confidence": 0.7046764492988586}]}, {"text": "In Section 4, we describe our data and three different measures of contextual similarity.", "labels": [], "entities": []}, {"text": "Section 5 introduces the classifier and its features.", "labels": [], "entities": []}, {"text": "Section 6 presents classification results and discussion.", "labels": [], "entities": [{"text": "classification", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.9699060916900635}]}, {"text": "Section 7 describes the information retrieval experiments.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 24, "end_pos": 45, "type": "TASK", "confidence": 0.8517018854618073}]}, {"text": "In Section 8 we present our conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Typically, IR systems do not process noncompositional phrases as one semantic entity, missing out on potentially important information captured by non-compositionality.", "labels": [], "entities": [{"text": "IR", "start_pos": 11, "end_pos": 13, "type": "TASK", "confidence": 0.9787355065345764}]}, {"text": "This section illustrates one way of adjusting the retrieval process so that non-compositional phrases are processed as semantic entities that may enhance retrieval performance.", "labels": [], "entities": []}, {"text": "The underlying hypothesis is that, given 800: The 20 most confident classifications where the prediction is semantic head = syntactic head.", "labels": [], "entities": []}, {"text": "= confidence a query that contains a non-compositional phrase, boosting the retrieval weight of documents that contain this phrase will improve overall retrieval performance.", "labels": [], "entities": []}, {"text": "We do this boosting using Indri's 10 combination of the language modeling and inference network approaches (, which allows assigning different degrees of belief to different parts of the query.", "labels": [], "entities": []}, {"text": "This belief can be drawn from any suitable external evidence of relevance.", "labels": [], "entities": []}, {"text": "In our case, this source of evidence is the knowledge that certain query terms constitute a non-compositional phrase.", "labels": [], "entities": []}, {"text": "Under this approach, and using the #weight and #combine operators for combining beliefs, the relevance of a document D to a query Q is computed as the probability that D generates Q, P (Q|D): where t is a term and wt is the belief weight assigned tot.", "labels": [], "entities": []}, {"text": "The higher wt is, the higher the rank of documents containing t.", "labels": [], "entities": []}, {"text": "In this work, we dis-10 http://www.lemurproject.org/ tinguish between two types of query terms: terms occurring in non-compositional phrases (Q nc ), and the remaining query terms (Q c ).", "labels": [], "entities": []}, {"text": "Terms t \u2208 Q nc receive belief weight w nc and terms t \u2208 Q c belief weight w c , (w nc + w c = 1 and w nc , w c \u2208 [0, 1]).", "labels": [], "entities": []}, {"text": "To boost the ranking of documents containing noncompositional phrases, we increase w nc at the expense of w c . We estimate P (t|D) in Eq.", "labels": [], "entities": [{"text": "P", "start_pos": 124, "end_pos": 125, "type": "METRIC", "confidence": 0.9727636575698853}]}, {"text": "1 using Dirichlet smoothing).", "labels": [], "entities": []}, {"text": "We use Indri for indexing and retrieval without removing stopwords or stemming.", "labels": [], "entities": []}, {"text": "This choice is motivated by two reasons: (i) We do not have a domain-specific stopword list or stemmer.", "labels": [], "entities": []}, {"text": "(ii) Baseline performance is higher when keeping stopwords and without stemming, rather than without stopwords and with stemming.", "labels": [], "entities": [{"text": "Baseline", "start_pos": 5, "end_pos": 13, "type": "METRIC", "confidence": 0.9617400169372559}]}, {"text": "We use the iSearch collection discussed in Section 4.", "labels": [], "entities": [{"text": "iSearch collection", "start_pos": 11, "end_pos": 29, "type": "DATASET", "confidence": 0.8738448619842529}]}, {"text": "It comprises 453,254 documents and a set of 65 queries with relevance assessments.", "labels": [], "entities": []}, {"text": "To match documents to queries without any treatment of non-compositionality (baseline run), we use the Kullback-Leibler language model with Dirichlet smoothing (KL-Dir)).", "labels": [], "entities": []}, {"text": "We applied the preprocessing described 801  in Section 4 to the queries and identified noncompositional phrases with the base AM classifier from Section 5.", "labels": [], "entities": []}, {"text": "Our approach for boosting the weight of these non-compositional phrases uses the same retrieval model enhanced with belief weights as described in Eq.", "labels": [], "entities": []}, {"text": "1 (real NC run).", "labels": [], "entities": [{"text": "real NC run)", "start_pos": 3, "end_pos": 15, "type": "DATASET", "confidence": 0.7737106531858444}]}, {"text": "In addition, we include five runs that boost the weight of pseudo non-compositional phrases that were created randomly from the query text (pseudo NC runs).", "labels": [], "entities": []}, {"text": "These pseudo non-compositional phrases have exactly the same length as the observed noncompositional phrases for each query.", "labels": [], "entities": []}, {"text": "We measure retrieval performance in terms of mean average precision (MAP), precision at 20 (P20), and recall (REC, number of relevant documents retrieved -total is 2878).", "labels": [], "entities": [{"text": "mean average precision (MAP)", "start_pos": 45, "end_pos": 73, "type": "METRIC", "confidence": 0.9122407734394073}, {"text": "precision", "start_pos": 75, "end_pos": 84, "type": "METRIC", "confidence": 0.9993762373924255}, {"text": "recall", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9997063279151917}, {"text": "REC", "start_pos": 110, "end_pos": 113, "type": "METRIC", "confidence": 0.8793690204620361}]}, {"text": "For each evaluation measure separately, we tune the following parameters and report the best performance: (i) the smoothing parameter \u00b5 of the KL-Dir retrieval model (\u00b5 \u2208 {100, 500, 800, 1000, 2000, 3000, 4000, 5000, 8000, 10000}, following); (ii) the belief weights w nc , w c \u2208 {0.1, . .", "labels": [], "entities": []}, {"text": ", 0.9} in steps of 0.1 while preserving w nc + w c = 1 at all times.", "labels": [], "entities": []}, {"text": "displays retrieval performance of our approach against the baseline and five runs with pseudo non-compositional phrases.", "labels": [], "entities": []}, {"text": "We see a 9.61% improvement in the number of relevant retrieved documents over the baseline.", "labels": [], "entities": []}, {"text": "MAP and P20 also show improvements.", "labels": [], "entities": [{"text": "MAP", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.820871889591217}]}, {"text": "Our approach is better than any of the 5 random runs on all three metrics -the probability of getting such a good result by chance is 1 2 5 < .05, and thus the improvements are statistically significant.", "labels": [], "entities": []}, {"text": "On doing a query-wise analysis of MAP scores, we find that large improvements over the baseline occur when a non-compositional phrase aligns with what the user is looking for.", "labels": [], "entities": [{"text": "MAP", "start_pos": 34, "end_pos": 37, "type": "TASK", "confidence": 0.8678916096687317}]}, {"text": "The system seems to retrieve more relevant documents in that case.", "labels": [], "entities": []}, {"text": "E.g., the improvement in MAP is 0.0977 for query #19.", "labels": [], "entities": [{"text": "MAP", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.9518016576766968}]}, {"text": "The user was looking for \"articles . .", "labels": [], "entities": []}, {"text": "on making tunable vertical cavity surface emitting laser diodes\" and laser diodes was one of the non-compositional phrases recognized.", "labels": [], "entities": []}, {"text": "On the other hand, a decrease in MAP occurs for non-compositional phrases unrelated to the information need.", "labels": [], "entities": [{"text": "MAP", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.8588480949401855}]}, {"text": "In query #4 the user is looking for \"protein-protein interaction, the surface charge distribution of these proteins and how this has been investigated with Electrostatic Force Microscopy\" and though non-compositional phrases such as Force Microscopy are recognized, these do not reflect the core information need \"The proteins of interest are the Avidin-Biotin and IgG-anti-IgG systems\".", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Performance for base AM features plus context feature subsets. A '\u2022' indicates the use of the corresponding  context feature.", "labels": [], "entities": []}, {"text": " Table 6: The 20 most confident classifications where the prediction is semantic head = syntactic head. \"c.\" = confi- dence", "labels": [], "entities": []}, {"text": " Table 7: IR performance without considering non- compositionality (baseline), versus boosting real and  pseudo non-compositionality (real NC, pseudo NC i ).", "labels": [], "entities": [{"text": "IR", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.9351854920387268}]}]}