{"title": [{"text": "Rumor has it: Identifying Misinformation in Microblogs", "labels": [], "entities": [{"text": "Identifying Misinformation", "start_pos": 14, "end_pos": 40, "type": "TASK", "confidence": 0.9555438458919525}]}], "abstractContent": [{"text": "A rumor is commonly defined as a statement whose true value is unverifiable.", "labels": [], "entities": []}, {"text": "Rumors may spread misinformation (false information) or disinformation (deliberately false information) on a network of people.", "labels": [], "entities": []}, {"text": "Identifying rumors is crucial in online social media where large amounts of information are easily spread across a large network by sources with unverified authority.", "labels": [], "entities": [{"text": "Identifying rumors", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9497252404689789}]}, {"text": "In this paper, we address the problem of rumor detection in microblogs and explore the effectiveness of 3 categories of features: content-based, network-based, and microblog-specific memes for correctly identifying rumors.", "labels": [], "entities": [{"text": "rumor detection", "start_pos": 41, "end_pos": 56, "type": "TASK", "confidence": 0.7283452749252319}]}, {"text": "Moreover, we show how these features are also effective in identifying disin-formers, users who endorse a rumor and further help it to spread.", "labels": [], "entities": []}, {"text": "We perform our experiments on more than 10,000 manually annotated tweets collected from Twitter and show how our retrieval model achieves more than 0.95 in Mean Average Precision (MAP).", "labels": [], "entities": [{"text": "Mean Average Precision (MAP)", "start_pos": 156, "end_pos": 184, "type": "METRIC", "confidence": 0.9641193846861521}]}, {"text": "Finally , we believe that our dataset is the first large-scale dataset on rumor detection.", "labels": [], "entities": [{"text": "rumor detection", "start_pos": 74, "end_pos": 89, "type": "TASK", "confidence": 0.9283455312252045}]}, {"text": "It can open new dimensions in analyzing online mis-information and other aspects of microblog conversations.", "labels": [], "entities": []}], "introductionContent": [{"text": "A rumor is an unverified and instrumentally relevant statement of information spread among people.", "labels": [], "entities": []}, {"text": "Social psychologists argue that rumors arise in contexts of ambiguity, when the meaning of a situation is not readily apparent, or potential threat, when people feel an acute need for security.", "labels": [], "entities": []}, {"text": "For instance rumors about 'office renovation in a company' is an example of an ambiguous context, and the rumor that 'underarm deodorants cause breast cancer' is an example of a context in which one's well-being is at risk (.", "labels": [], "entities": [{"text": "office renovation in a company'", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.8172126511732737}]}, {"text": "The rapid growth of online social media has made it possible for rumors to spread more quickly.", "labels": [], "entities": []}, {"text": "Online social media enable unreliable sources to spread large amounts of unverified information among people).", "labels": [], "entities": []}, {"text": "Therefore, it is crucial to design systems that automatically detect misinformation and disinformation (the former often seen as simply false and the latter as deliberately false information).", "labels": [], "entities": []}, {"text": "Our definition of a rumor is established based on social psychology, where a rumor is defined as a statement whose truth-value is unverifiable or deliberately false.", "labels": [], "entities": []}, {"text": "In-depth rumor analysis such as determining the intent and impact behind the spread of a rumor is a very challenging task and is not possible without first retrieving the complete set of social conversations (e.g., tweets) that are actually about the rumor.", "labels": [], "entities": [{"text": "determining the intent and impact behind the spread of a rumor", "start_pos": 32, "end_pos": 94, "type": "TASK", "confidence": 0.670583036812869}]}, {"text": "In our work, we take this first step to retrieve a complete set of tweets that discuss a specific rumor.", "labels": [], "entities": []}, {"text": "In our approach, we address two basic problems.", "labels": [], "entities": []}, {"text": "The first problem concerns retrieving online microblogs that are rumor-related.", "labels": [], "entities": []}, {"text": "In the second problem, we try to identify tweets in which the rumor is endorsed (the posters show that they believe the rumor).", "labels": [], "entities": []}], "datasetContent": [{"text": "We design 2 sets of experiments to evaluate our approach.", "labels": [], "entities": []}, {"text": "In the first experiment we assess the effectiveness of the proposed method when employed in an Information Retrieval (IR) framework for rumor retrieval and in the second experiment we employ various features to detect users' beliefs in rumors.", "labels": [], "entities": [{"text": "rumor retrieval", "start_pos": 136, "end_pos": 151, "type": "TASK", "confidence": 0.7741945087909698}]}], "tableCaptions": [{"text": " Table 2: Number of instances in each class from the an- notated data", "labels": [], "entities": []}, {"text": " Table 3: Inter-judge agreement in two annotation tasks in  terms of \u03ba-statistic", "labels": [], "entities": []}, {"text": " Table 5: Mean Average Precision (MAP) and F \u03b2=1 of each method in the rumor retrieval task. (C.I.: Confidence  Interval)", "labels": [], "entities": [{"text": "Mean Average Precision (MAP)", "start_pos": 10, "end_pos": 38, "type": "METRIC", "confidence": 0.9590972562630972}, {"text": "F \u03b2", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.9865019917488098}, {"text": "rumor retrieval task", "start_pos": 71, "end_pos": 91, "type": "TASK", "confidence": 0.844166119893392}]}, {"text": " Table 6: Accuracy, precision, recall, F \u03b2=1 , and win/loss ratio of belief classification using different features.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.999202311038971}, {"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9996885061264038}, {"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9997820258140564}, {"text": "F \u03b2", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.9918673634529114}, {"text": "belief classification", "start_pos": 69, "end_pos": 90, "type": "TASK", "confidence": 0.6656462550163269}]}]}