{"title": [], "abstractContent": [{"text": "Linear models have enjoyed great success in structured prediction in NLP.", "labels": [], "entities": [{"text": "structured prediction", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.8175245523452759}]}, {"text": "While a lot of progress has been made on efficient training with several loss functions, the problem of endowing learners with a mechanism for feature selection is still unsolved.", "labels": [], "entities": []}, {"text": "Common approaches employ ad hoc filtering or L 1-regularization; both ignore the structure of the feature space, preventing practicioners from encoding structural prior knowledge.", "labels": [], "entities": []}, {"text": "We fill this gap by adopting regularizers that promote structured sparsity, along with efficient algorithms to handle them.", "labels": [], "entities": []}, {"text": "Experiments on three tasks (chunking, entity recognition, and dependency parsing) show gains in performance, compactness, and model interpretability.", "labels": [], "entities": [{"text": "chunking", "start_pos": 28, "end_pos": 36, "type": "TASK", "confidence": 0.960479736328125}, {"text": "entity recognition", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.781988650560379}, {"text": "dependency parsing", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.7176406383514404}]}], "introductionContent": [{"text": "Models for structured outputs are in demand across natural language processing, with applications in information extraction, parsing, and machine translation.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 101, "end_pos": 123, "type": "TASK", "confidence": 0.8162033259868622}, {"text": "parsing", "start_pos": 125, "end_pos": 132, "type": "TASK", "confidence": 0.944469153881073}, {"text": "machine translation", "start_pos": 138, "end_pos": 157, "type": "TASK", "confidence": 0.800862193107605}]}, {"text": "State-of-the-art models usually involve linear combinations of features and are trained discriminatively; examples are conditional random fields (), structured support vector machines (), and the structured perceptron.", "labels": [], "entities": []}, {"text": "In all these cases, the underlying optimization problems differ only in the choice of loss function; choosing among them has usually a small impact on predictive performance.", "labels": [], "entities": []}, {"text": "In this paper, we are concerned with model selection: which features should be used to define the prediction score?", "labels": [], "entities": [{"text": "model selection", "start_pos": 37, "end_pos": 52, "type": "TASK", "confidence": 0.6960961818695068}]}, {"text": "The fact that models with few features (\"sparse\" models) are desirable for several reasons (compactness, interpretability, good generalization) has stimulated much research work which has produced a wide variety of methods.", "labels": [], "entities": []}, {"text": "Our focus is on methods which embed this selection into the learning problem via the regularization term.", "labels": [], "entities": []}, {"text": "We depart from previous approaches in that we seek to make decisions jointly about all candidate features, and we want to promote sparsity patterns that go beyond the mere cardinality of the set of features.", "labels": [], "entities": []}, {"text": "For example, we want to be able to select entire feature templates (rather than features individually), or to make the inclusion of some features depend on the inclusion of other features.", "labels": [], "entities": []}, {"text": "We achieve the goal stated above by employing regularizers which promote structured sparsity.", "labels": [], "entities": []}, {"text": "Such regularizers are able to encode prior knowledge and guide the selection of features by modeling the structure of the feature space.", "labels": [], "entities": []}, {"text": "Lately, this type of regularizers has received a lot of attention in computer vision, signal processing, and computational biology ().", "labels": [], "entities": []}, {"text": "employed structured sparsity in computational sociolinguistics.", "labels": [], "entities": []}, {"text": "However, none of these works have addressed structured prediction.", "labels": [], "entities": [{"text": "structured prediction", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.8037815988063812}]}, {"text": "Here, we combine these two levels of structure: structure in the output space, and structure in the feature space.", "labels": [], "entities": []}, {"text": "The result is a framework that allows building structured predictors with high predictive power, while reducing manual feature engineering.", "labels": [], "entities": []}, {"text": "We obtain models that are interpretable, accurate, and often much more compact than L 2 -regularized ones.", "labels": [], "entities": []}, {"text": "Compared with L 1 -regularized models, ours are often more accurate and yield faster runtime.", "labels": [], "entities": []}], "datasetContent": [{"text": "We present experiments in three structured prediction tasks for several group choices.", "labels": [], "entities": []}, {"text": "We use the English dataset provided in the CoNLL 2000 shared task, which consists of 8,936 training and 2,012 testing sentences (sections 15-18 and 20 of the WSJ.)", "labels": [], "entities": [{"text": "CoNLL 2000 shared task", "start_pos": 43, "end_pos": 65, "type": "DATASET", "confidence": 0.929748922586441}, {"text": "WSJ", "start_pos": 158, "end_pos": 161, "type": "DATASET", "confidence": 0.9704746007919312}]}, {"text": "The input observations are the token words and their POS tags; we want to predict the sequences of IOB tags representing phrase chunks.", "labels": [], "entities": []}, {"text": "We built 96 contextual feature templates as follows: \u2022 Up to 5-grams of POS tags, in windows of 5 tokens on the left and 5 tokens on the right; \u2022 Up to 3-grams of words, in windows of 3 tokens on the left and 3 tokens on the right; \u2022 Up to 2-grams of word shapes, in windows of 2 tokens on the left and 2 tokens on the right.", "labels": [], "entities": []}, {"text": "Each shape replaces characters by their types (case sensitive letters, digits, and punctuation), and deletes repeated types-e.g., Confidence and 2,664,098 are respectively mapped to Aa and 0,0+,0+ (Collins, 2002b).", "labels": [], "entities": [{"text": "Collins, 2002b", "start_pos": 198, "end_pos": 212, "type": "DATASET", "confidence": 0.8981229662895203}]}, {"text": "We defined unigram features by conjoining these templates with each of the 22 output labels.", "labels": [], "entities": []}, {"text": "An additional template was defined to account for label bigrams-features in this template do not look at the input string, but only at consecutive pairs of labels.", "labels": [], "entities": []}, {"text": "We evaluate the ability of group-Lasso regularization to perform feature template selection.", "labels": [], "entities": [{"text": "feature template selection", "start_pos": 65, "end_pos": 91, "type": "TASK", "confidence": 0.6639124155044556}]}, {"text": "To do that, we ran 5 epochs of the sparseptron algorithm with template-based groups and budget-driven shrinkage (budgets of 10, 20, 30, 40, and 50 templates were tried).", "labels": [], "entities": []}, {"text": "For each group G m , we set d m = log 2 |G m |, which is the average number of bits necessary to encode a feature in that group, if all features were equiprobable.", "labels": [], "entities": []}, {"text": "We set K = 1000 (the number of instances between consecutive proximal steps).", "labels": [], "entities": []}, {"text": "Then, we refit the model with 10 iterations of the max-loss 1-best MIRA algorithm (    the model sizes obtained with the several budgets against those obtained by running 15 iterations of MIRA with the original set of features.", "labels": [], "entities": [{"text": "max-loss 1-best MIRA algorithm", "start_pos": 51, "end_pos": 81, "type": "METRIC", "confidence": 0.822690412402153}, {"text": "MIRA", "start_pos": 188, "end_pos": 192, "type": "DATASET", "confidence": 0.7799325585365295}]}, {"text": "Note that the total number of iterations is the same; yet, the group-Lasso approach has a much smaller memory footprint (see) and yields much more compact models.", "labels": [], "entities": []}, {"text": "The small memory footprint comes from the fact that Alg.", "labels": [], "entities": []}, {"text": "1 may entertain a large number of features without ever instantiating all of them.", "labels": [], "entities": []}, {"text": "The predictive power is comparable (although some choices of budget yield slightly better scores for the group-Lasso approach).", "labels": [], "entities": []}, {"text": "We experiment with the Spanish, Dutch, and English datasets provided in the CoNLL 2002/2003 shared tasks).", "labels": [], "entities": [{"text": "CoNLL 2002/2003 shared tasks", "start_pos": 76, "end_pos": 104, "type": "DATASET", "confidence": 0.9279897312323252}]}, {"text": "For Spanish, we use the POS tags provided by Car-(described next), we used L2-regularized MIRA and tuned the regularization constant with cross-validation.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 90, "end_pos": 94, "type": "METRIC", "confidence": 0.9587444067001343}]}, {"text": "We also tried label-based group-Lasso and sparse groupLasso ( \u00a73.1), with less impressive results (omitted for space).", "labels": [], "entities": []}, {"text": "reras (http://www.lsi.upc.es/ \u02dc nlp/tools/ nerc/nerc.html); for English, we ignore the syntactic chunk tags provided with the dataset.", "labels": [], "entities": []}, {"text": "Hence, all datasets have the same sort of input observations (words and POS) and all have 9 output labels.", "labels": [], "entities": []}, {"text": "We use the feature templates described above plus some additional ones (yielding a total of 452 templates): \u2022 Up to 3-grams of shapes, in windows of size 3; \u2022 For prefix/suffix sizes of 1, 2, 3, up to 3-grams of word prefixes/suffixes, in windows of size 3; \u2022 Up to 5-grams of case, punctuation, and digit indicators, in windows of size 5.", "labels": [], "entities": []}, {"text": "As before, an additional feature template was defined to account for label bigrams.", "labels": [], "entities": []}, {"text": "We do feature template selection (same setting as before) for budget sizes of 100, 200, and 300.", "labels": [], "entities": []}, {"text": "We compare with both MIRA (using all the features) and the sparseptron with a standard Lasso regularizer \u2126 L 1 \u03c4 , for several values of C = 1/(\u03c4 N ).", "labels": [], "entities": [{"text": "MIRA", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.8800247311592102}]}, {"text": "We observe that template-based group-Lasso wins both in terms of accuracy and compactness.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9994520545005798}]}, {"text": "Note also that the ability to discard feature templates (rather than individual features) yields faster test runtime than models regularized with the standard Lasso: fewer templates will need to be instantiated, with a speed-up in score computation.", "labels": [], "entities": []}, {"text": "We trained non-projective dependency parsers for 6 languages using the CoNLL-X shared task datasets): Arabic, Danish, Dutch, Japanese, Slovene, and Spanish.", "labels": [], "entities": [{"text": "CoNLL-X shared task datasets", "start_pos": 71, "end_pos": 99, "type": "DATASET", "confidence": 0.8549467474222183}]}, {"text": "We chose the languages with the smallest datasets, because regularization is more important when data is scarce.", "labels": [], "entities": []}, {"text": "The output to be predicted from each input sentence is the set of dependency links, which jointly define a spanning tree.", "labels": [], "entities": []}, {"text": "1507 We use arc-factored models, for which exact inference is tractable ().", "labels": [], "entities": []}, {"text": "We defined M = 684 feature templates for each candidate arc by conjoining the words, shapes, lemmas, and POS of the head and the modifier, as well as the contextual POS, and the distance and direction of attachment.", "labels": [], "entities": []}, {"text": "We followed the same two-stage approach as before, and compared with a baseline which selects feature templates by ranking them according to the information gain criterion.", "labels": [], "entities": []}, {"text": "This baseline assigns a score to each template Tm which reflects an empirical estimate of the mutual information between Tm and the binary variable A that indicates the presence/absence of a dependency link: where P (f, a) is the joint probability of feature f firing and an arc being active (a = 1) or innactive (a = 0), and P (f ) and P (a) are the corresponding marginals.", "labels": [], "entities": []}, {"text": "All probabilities are estimated from the empirical counts of events observed in the data.", "labels": [], "entities": []}, {"text": "The results are plotted in, for budget sizes of 200, 300, and 400.", "labels": [], "entities": []}, {"text": "We observe that for all but one language (Spanish is the exception), nonoverlapping group-Lasso regularization is more effective at selecting feature templates than the information gain criterion, and slightly better than coarse-to-fine group-Lasso.", "labels": [], "entities": []}, {"text": "For completeness, we also display the results obtained with a standard Lasso regularizer.", "labels": [], "entities": []}, {"text": "shows what kind of feature templates were most selected for each language.", "labels": [], "entities": []}, {"text": "Some interesting patterns can be observed: morphologically-rich languages with small datasets (such as Turkish and Slovene) seem to avoid lexical features, arguably due to potential for overfitting; in Japanese, contextual POS appear to be specially relevant.", "labels": [], "entities": []}, {"text": "It should be noted, however, that some of these patterns maybe properties of the datasets rather than of the languages themselves.: Variation of feature templates that were selected accross languages.", "labels": [], "entities": []}, {"text": "Each line groups together similar templates, involving lexical, contextual POS, word shape information, as well as attachment direction and length.", "labels": [], "entities": []}, {"text": "Empty cells denote that very few or none of the templates in that category was selected; + denotes that some were selected; ++ denotes that most or all were selected.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results for named entity recognition. Each cell shows F 1 (%) and the number of features.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.6485997041066488}, {"text": "F 1", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.9961387813091278}]}]}