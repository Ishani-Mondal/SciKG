{"title": [{"text": "Improving Bilingual Projections via Sparse Covariance Matrices", "labels": [], "entities": [{"text": "Improving Bilingual Projections", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8774121403694153}]}], "abstractContent": [{"text": "Mapping documents into an interlingual representation can help bridge the language barrier of cross-lingual corpora.", "labels": [], "entities": []}, {"text": "Many existing approaches are based on word co-occurrences extracted from aligned training data, represented as a covariance matrix.", "labels": [], "entities": []}, {"text": "In theory, such a covariance matrix should represent semantic equivalence, and should be highly sparse.", "labels": [], "entities": []}, {"text": "Unfortunately, the presence of noise leads to dense covariance matrices which in turn leads to suboptimal document representations.", "labels": [], "entities": []}, {"text": "In this paper, we explore techniques to recover the desired sparsity in covariance matrices in two ways.", "labels": [], "entities": []}, {"text": "First, we explore word association measures and bilingual dictionaries to weigh the word pairs.", "labels": [], "entities": []}, {"text": "Later, we explore different selection strategies to remove the noisy pairs based on the association scores.", "labels": [], "entities": []}, {"text": "Our experimental results on the task of aligning comparable documents shows the efficacy of sparse covariance matrices on two data sets from two different language pairs.", "labels": [], "entities": []}], "introductionContent": [{"text": "Aligning documents from different languages arises in a range of tasks such as parallel phrase extraction (, mining translations for out-of-vocabulary words for statistical machine translation (Daume III and Jagarlamudi, 2011) and document retrieval (.", "labels": [], "entities": [{"text": "Aligning documents from different languages", "start_pos": 0, "end_pos": 43, "type": "TASK", "confidence": 0.8583672523498536}, {"text": "parallel phrase extraction", "start_pos": 79, "end_pos": 105, "type": "TASK", "confidence": 0.6291025578975677}, {"text": "statistical machine translation", "start_pos": 161, "end_pos": 192, "type": "TASK", "confidence": 0.6308798094590505}, {"text": "document retrieval", "start_pos": 231, "end_pos": 249, "type": "TASK", "confidence": 0.7835921347141266}]}, {"text": "In this task, we are given a comparable corpora and some documents in one language are assumed to have a comparable document in the other language and the goal is to recover this hidden alignment.", "labels": [], "entities": []}, {"text": "In this paper, we address this problem by mapping the documents into a common subspace (interlingual representation).", "labels": [], "entities": []}, {"text": "This common subspace generalizes the notion of vector space model for cross-lingual applications).", "labels": [], "entities": []}, {"text": "Most of the existing approaches use manually aligned document pairs to find a common subspace in which the aligned document pairs are maximally correlated.", "labels": [], "entities": []}, {"text": "The sub-space can be found using either generative approaches based on topic modeling () or discriminative approaches based on variants of Principal Component Analysis (PCA) and Canonical Correlation Analysis (CCA).", "labels": [], "entities": []}, {"text": "Both styles rely on document level term co-occurrences to find the latent representation.", "labels": [], "entities": []}, {"text": "The discriminative approaches capture essential word co-occurrences in terms of two monolingual covariance matrices and a cross-covariance matrix.", "labels": [], "entities": []}, {"text": "Subsequently, they use these covariance matrices to find projection directions in each language such that aligned documents lie close to each other (Sec. 2).", "labels": [], "entities": []}, {"text": "The strong reliance of these approaches on the covariance matrices leads to problems, especially with the noisy data caused either by the noisy words in a document or the noisy document alignments.", "labels": [], "entities": []}, {"text": "Noisy data is not uncommon and is usually the case with data collected from community based resources such as Wikipedia.", "labels": [], "entities": []}, {"text": "This degrades performance of a variety of tasks, such as transliteration Mining and multilingual web search (.", "labels": [], "entities": [{"text": "transliteration Mining", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.8176579177379608}]}, {"text": "In this paper, we address the problem of identifying and removing noisy entries in the covariance matrices.", "labels": [], "entities": []}, {"text": "We address this problem in two stages.", "labels": [], "entities": []}, {"text": "In the first stage, we explore the use of word association measures such as Mutual Information (MI) and Yule's \u03c9) in computing the strength of a word pair (Sec.", "labels": [], "entities": [{"text": "Mutual Information (MI)", "start_pos": 76, "end_pos": 99, "type": "METRIC", "confidence": 0.9088229417800904}, {"text": "Yule's \u03c9", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.7982217272122701}]}, {"text": "We also explore the use of bilingual dictionaries developed from cleaner resources such as parallel data.", "labels": [], "entities": []}, {"text": "In the second stage, we use the association strengths in filtering out the noisy word pairs from the covariance matrices.", "labels": [], "entities": []}, {"text": "We pose this as a word pair selection problem and explore multiple strategies (Sec. 3.2).", "labels": [], "entities": [{"text": "word pair selection", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.737015942732493}]}, {"text": "We evaluate the utility of sparse covariance matrices in improving the bilingual projections incrementally (Sec. 4).", "labels": [], "entities": []}, {"text": "We first report results on synthetic multi-view data where the true correspondences between features of different views are available.", "labels": [], "entities": []}, {"text": "Moreover, this also lets us systematically explore the effect of noise level on the accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9990535378456116}]}, {"text": "Our experimental results show a significant improvement when the true correspondences are available.", "labels": [], "entities": []}, {"text": "Later, we report our experimental results on the document alignment task on Europarl and Wikipedia data sets and on two language pairs.", "labels": [], "entities": [{"text": "document alignment task", "start_pos": 49, "end_pos": 72, "type": "TASK", "confidence": 0.8333171407381693}, {"text": "Europarl", "start_pos": 76, "end_pos": 84, "type": "DATASET", "confidence": 0.9918100237846375}, {"text": "Wikipedia data sets", "start_pos": 89, "end_pos": 108, "type": "DATASET", "confidence": 0.8703886667887369}]}, {"text": "We found that sparsifying the covariance matrices helps in general, but using cleaner resource such bilingual dictionaries performed best.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance of our models in comparison with CCA and OPCA on English-Spanish and English-German  language pairs.  *  and + indicate statistical significance measured by paired t-test at p=0.01 and 0.05 levels respectively.  When an improvement is significant at p=0.01 it is automatically significant at p=0.05 and hence is not shown.", "labels": [], "entities": []}]}