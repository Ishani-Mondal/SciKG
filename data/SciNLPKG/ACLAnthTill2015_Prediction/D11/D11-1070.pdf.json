{"title": [{"text": "Learning Local Content Shift Detectors from Document-level Information", "labels": [], "entities": [{"text": "Learning Local Content Shift Detectors", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.6663323998451233}]}], "abstractContent": [{"text": "Information-oriented document labeling is a special document multi-labeling task where the target labels refer to a specific information instead of the topic of the whole document.", "labels": [], "entities": [{"text": "Information-oriented document labeling", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.5912012656529745}]}, {"text": "These kind of tasks are usually solved by looking up indicator phrases and analyzing their local context to filter false positive matches.", "labels": [], "entities": []}, {"text": "Here, we introduce an approach for machine learning local content shifters which detects irrelevant local contexts using just the original document-level training labels.", "labels": [], "entities": [{"text": "machine learning local content shifters", "start_pos": 35, "end_pos": 74, "type": "TASK", "confidence": 0.6565183579921723}]}, {"text": "We handle content shifters in general, instead of learning a particular language phenomenon detector (e.g. negation or hedging) and form a single system for document labeling and content shift detection.", "labels": [], "entities": [{"text": "content shift detection", "start_pos": 179, "end_pos": 202, "type": "TASK", "confidence": 0.8023497462272644}]}, {"text": "Our empirical results achieved 24% error reduction-compared to supervised baseline methods-on three document labeling tasks.", "labels": [], "entities": [{"text": "error reduction-compared", "start_pos": 35, "end_pos": 59, "type": "METRIC", "confidence": 0.9382949471473694}, {"text": "document labeling tasks", "start_pos": 100, "end_pos": 123, "type": "TASK", "confidence": 0.711925228436788}]}], "introductionContent": [{"text": "There are special document multi-labeling tasks where the target labels refer to a specific piece of information extractable from the document instead of the overall topic of the document.", "labels": [], "entities": []}, {"text": "In these kinds of tasks the target information is usually an attribute or relation related to the target entity (usually a person or an organisation) of the document in question, but the task is to assign class labels at the document (entity) level.", "labels": [], "entities": []}, {"text": "For example, the smoking habits of the patients are frequently discussed in the textual parts of clinical notes.", "labels": [], "entities": []}, {"text": "In this case the task is to find specific information in the text -i.e. the patient in question is a smoker, past smoker, non-smoker -but at the end an application has to assign labels to the documents(patients).", "labels": [], "entities": []}, {"text": "Similarly, the soccer club names where a sportsman played for are document(sportman)-level labels in Wikipedia articles expressed by the Wikipedia categories.", "labels": [], "entities": []}, {"text": "The target information in these tasks is usually just mentioned in the document and much of the document is irrelevant for this information request in contrast to standard document classification tasks where the goal is to identify the topics of the whole document.", "labels": [], "entities": []}, {"text": "On the other hand, they are not a standard information extraction task as the task is to assign class labels to documents, and the training dataset contains labels just at this level.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.7729121446609497}]}, {"text": "These special tasks lie somewhere between information extraction and document classification and require special approaches to solve them.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.8100012838840485}, {"text": "document classification", "start_pos": 69, "end_pos": 92, "type": "TASK", "confidence": 0.7511788904666901}]}, {"text": "We will call them Information-oriented document labeling throughout this paper.", "labels": [], "entities": [{"text": "Information-oriented document labeling", "start_pos": 18, "end_pos": 56, "type": "TASK", "confidence": 0.6139839688936869}]}, {"text": "There are several application areas where information-oriented document labels are naturally present in an enormous amount like clinical records, Wikipedia categories and usergenerated tags of news.", "labels": [], "entities": []}, {"text": "Previous evaluation campaigns () demonstrated that information-oriented document labeling can be effectively performed by looking up indicator phrases which can be gathered by hand, by corpus statistics or in a hybrid way.", "labels": [], "entities": [{"text": "information-oriented document labeling", "start_pos": 51, "end_pos": 89, "type": "TASK", "confidence": 0.6583360433578491}]}, {"text": "However these campaigns also highlighted that the analysis of the local context of the indicator phrases is crucial.", "labels": [], "entities": []}, {"text": "For instance, in the smoking habit detection task there area few indicator words (e.g. smokes, cigarette) and the local context of their occurrences in texts should 759 be analysed to see whether their semantic was radically changed (e.g. they are negated or in a past tense), for instance: The patient has a 20 pack-year smoking history.", "labels": [], "entities": [{"text": "smoking habit detection task", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.7131849527359009}]}, {"text": "The patient denies any smoking history.", "labels": [], "entities": []}, {"text": "He has a greater than 100 pack year smoking history and quit 9 to 10 years ago.", "labels": [], "entities": []}, {"text": "We propose a simple but efficient approach for information-oriented document labeling tasks by addressing the automatic detection of language phenomena fora particular task which alters the sense or information content of the indicator phrase's occurrences.", "labels": [], "entities": [{"text": "information-oriented document labeling tasks", "start_pos": 47, "end_pos": 91, "type": "TASK", "confidence": 0.7054045647382736}]}, {"text": "For example, they maybe logical modifiers (e.g. negation) or modal modifiers (e.g. auxiliaries like might and can); they may refer to a subject which differs from the target entity of the task (e.g. clinical notes usually contain information about the family history of the patient); or the semantic content of the shifter may change the role of the target span of a text (e.g. a sportsman can play for or against a particular team).", "labels": [], "entities": []}, {"text": "We call these phenomena content shifters and the task of identifying them content shift detection (CSD).", "labels": [], "entities": [{"text": "content shift detection (CSD)", "start_pos": 74, "end_pos": 103, "type": "TASK", "confidence": 0.75693246225516}]}, {"text": "Existing CSD approaches focus on a particular class of language phenomena (especially negation or hedging) and use hand-crafted rules) or a supervised learning approach that exploits corpora manually annotated at the token-level fora particular type of content shifter.", "labels": [], "entities": []}, {"text": "Moreover higher level applications (like document labeling and information extraction) use a separate CSD module which is developed independently from the target task.", "labels": [], "entities": [{"text": "document labeling", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.7717382907867432}, {"text": "information extraction", "start_pos": 63, "end_pos": 85, "type": "TASK", "confidence": 0.8218916952610016}]}, {"text": "We argue that the nature of content shifters is domain and task dependent, so training corpora (at the token-level) are required for content shifters which are important fora particular task but the construction of such training corpora is expensive.", "labels": [], "entities": []}, {"text": "Here, we propose an alternative approach which uses only document-level labels.", "labels": [], "entities": []}, {"text": "The input of our system is a training corpus labeled on the document level (e.g. a clinical dataset consisting clinical notes and meta-data about patients).", "labels": [], "entities": []}, {"text": "Our approach extracts indicator phrases and trains a CSD jointly.", "labels": [], "entities": []}, {"text": "We focus on local content shifters and we analyse just the sentences of indicator phrase occurrences.", "labels": [], "entities": []}, {"text": "Our chief assumption is that CSD can be learnt by exploiting the false positive occurrences of indicator phrases in the training dataset.", "labels": [], "entities": [{"text": "CSD", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.9672414064407349}]}, {"text": "We show that our method performs significantly better than standard document classifiers (which were designed fora slightly different task).", "labels": [], "entities": []}, {"text": "The chief contributions of our work are that (i) we handle the CSD problem in general, so we detect all content shifters instead of focusing on one particular language phenomenon, (ii) we form a single framework for joint CSD and document labeling, (iii) moreover our approach does not require a dedicated annotated training dataset for content shifters.", "labels": [], "entities": [{"text": "CSD and document labeling", "start_pos": 222, "end_pos": 247, "type": "TASK", "confidence": 0.5775701925158501}]}], "datasetContent": [{"text": "Before introducing our approach in detail we describe three tasks and datasets which were used in our experiments in order to give an insight into the challenges of the information-oriented document labeling tasks.", "labels": [], "entities": [{"text": "information-oriented document labeling tasks", "start_pos": 169, "end_pos": 213, "type": "TASK", "confidence": 0.6842780634760857}]}, {"text": "summarizes the key statistical figures (the number of documents in the corpora, the size of the label sets along with the average number of tokens and label assignments per document) of the datasets used for the experimental evaluations. has one label 786.50 (cough) as 486 (pneumonia) is ruled out.", "labels": [], "entities": []}, {"text": "The main conclusion of the shared task in 2007 was that simple rule-based systems generally outperform bag-of-words-based machine learning models.", "labels": [], "entities": []}, {"text": "The rules were extracted from ICD guidelines and/or from the training corpus using simple statistical measures, then they were checked or extended manually.", "labels": [], "entities": [{"text": "ICD", "start_pos": 30, "end_pos": 33, "type": "DATASET", "confidence": 0.6865122318267822}]}, {"text": "Several systems of the challenge employed a negation and speculation detection submodule.", "labels": [], "entities": [{"text": "negation and speculation detection", "start_pos": 44, "end_pos": 78, "type": "TASK", "confidence": 0.7205909043550491}]}, {"text": "The (manually highly fine-tuned) top systems of the CMC shared task achieved an F-measure of 88-89 ().", "labels": [], "entities": [{"text": "CMC shared task", "start_pos": 52, "end_pos": 67, "type": "DATASET", "confidence": 0.7030713558197021}, {"text": "F-measure", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.9996250867843628}]}, {"text": "The I2B2 Obesity Dataset was also the subject of a clinical natural language processing shared task.", "labels": [], "entities": [{"text": "I2B2 Obesity Dataset", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.7526533603668213}]}, {"text": "The challenge in 2008 focused on analyzing clinical discharge summary texts and addressed the following question: \"Who is obese and what comorbidities do they have?\".", "labels": [], "entities": []}, {"text": "Target diseases (document labels) included obesity and its 15 most frequent co-morbidities exhibited by patients.", "labels": [], "entities": []}, {"text": "In our experiments, we used the same train/evaluation split as that of the shared task.", "labels": [], "entities": []}, {"text": "Here a special aspect of the corpus is that the documents are semi-structured, i.e. they contain headings like discharge medications and admit diagnosis.", "labels": [], "entities": []}, {"text": "By pasting the given heading to the beginning of each sentence, we incorporated it into the local context.", "labels": [], "entities": []}, {"text": "The top performing systems of the shared task employed mostly hand-crafted rules for indicator selection and for negation and uncertainty detection as well.", "labels": [], "entities": [{"text": "indicator selection", "start_pos": 85, "end_pos": 104, "type": "TASK", "confidence": 0.8675773739814758}, {"text": "negation and uncertainty detection", "start_pos": 113, "end_pos": 147, "type": "TASK", "confidence": 0.6378684341907501}]}, {"text": "They achieved an F-measure 1 of 96-97).", "labels": [], "entities": [{"text": "F-measure 1", "start_pos": 17, "end_pos": 28, "type": "METRIC", "confidence": 0.991248220205307}]}, {"text": "We constructed a corpus based on Wikipedia articles and categories 2 . The categories assigned to Wikipedia articles can be regarded as labels (for example, the labels of David Beckham in the Wikipedia are English people, expatriate soccer player, male model and A.C. Milan player, Manchester United player).", "labels": [], "entities": []}, {"text": "Based on the categories of Wikipedia, classifiers can be trained to tag unlabeled texts or even add missing category assignments to Wikipedia).", "labels": [], "entities": []}, {"text": "For a case study we focused on learning English soccer clubs that a given sportsman played for.", "labels": [], "entities": []}, {"text": "Note that this task is an information-oriented document labeling task as the clubs for which a sportsman played are usually just mentioned (especially for smaller clubs) in the article of a player.", "labels": [], "entities": []}, {"text": "The Wikipedia category Footballers in England by club contains 408 subcategories (for the present and past).", "labels": [], "entities": [{"text": "Wikipedia category Footballers in England by club", "start_pos": 4, "end_pos": 53, "type": "DATASET", "confidence": 0.6873242046151843}]}, {"text": "We selected the best known clubs (where the category label for the club is assigned to more than 500 player pages).", "labels": [], "entities": []}, {"text": "Each article referring to a player having a category assignment to these clubs was downloaded and the textual parts were extracted.", "labels": [], "entities": []}, {"text": "Then a random 3:1 train:evaluation split of the document set was used.", "labels": [], "entities": []}, {"text": "Experiments were carried out on the three datasets introduced in Section 3 with local content shift detection as an individual task and also to investigate its added value to information-oriented document labeling.", "labels": [], "entities": [{"text": "local content shift detection", "start_pos": 80, "end_pos": 109, "type": "TASK", "confidence": 0.6776008829474449}, {"text": "information-oriented document labeling", "start_pos": 175, "end_pos": 213, "type": "TASK", "confidence": 0.6254654030005137}]}, {"text": "In our experiments, we applied the sentence splitter and lemmatizer implementation of the MorphAdorner package and the Stanford tokenizer and lexicalized PCFG parser ( . morphadorner.northwestern.edu/ 7 The JAVA implementation of the entire framework and", "labels": [], "entities": [{"text": "sentence splitter", "start_pos": 35, "end_pos": 52, "type": "TASK", "confidence": 0.7084733247756958}, {"text": "JAVA", "start_pos": 207, "end_pos": 211, "type": "DATASET", "confidence": 0.7829868793487549}]}], "tableCaptions": [{"text": " Table 1: The datasets used in our experiments.", "labels": [], "entities": []}, {"text": " Table 3: Results obtained for local content shift detection in a precision/recall/F-measure format.", "labels": [], "entities": [{"text": "local content shift detection", "start_pos": 31, "end_pos": 60, "type": "TASK", "confidence": 0.6639590933918953}, {"text": "precision", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9985083937644958}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.733054518699646}, {"text": "F-measure", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.804828405380249}]}, {"text": " Table 4: Results obtained by document multi-labeling algorithms in a precision/recall/F-measure format.", "labels": [], "entities": [{"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9968597888946533}, {"text": "recall", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.7166620492935181}, {"text": "F-measure", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.6873048543930054}]}]}