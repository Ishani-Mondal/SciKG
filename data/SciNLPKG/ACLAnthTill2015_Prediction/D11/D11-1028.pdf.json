{"title": [{"text": "A Model of Discourse Predictions in Human Sentence Processing", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper introduces a psycholinguistic model of sentence processing which combines a Hidden Markov Model noun phrase chun-ker with a co-reference classifier.", "labels": [], "entities": [{"text": "sentence processing", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.7431690990924835}]}, {"text": "Both models are fully incremental and generative, giving probabilities of lexical elements conditional upon linguistic structure.", "labels": [], "entities": []}, {"text": "This allows us to compute the information theoretic measure of surprisal, which is known to correlate with human processing effort.", "labels": [], "entities": []}, {"text": "We evaluate our surprisal predictions on the Dundee corpus of eye-movement data show that our model achieve a better fit with human reading times than a syntax-only model which does not have access to co-reference information.", "labels": [], "entities": [{"text": "Dundee corpus of eye-movement data", "start_pos": 45, "end_pos": 79, "type": "DATASET", "confidence": 0.9743284225463867}]}], "introductionContent": [{"text": "Recent research in psycholinguistics has seen a growing interest in the role of prediction in sentence processing.", "labels": [], "entities": [{"text": "sentence processing", "start_pos": 94, "end_pos": 113, "type": "TASK", "confidence": 0.7240964770317078}]}, {"text": "Prediction refers to the fact that the human sentence processor is able to anticipate upcoming material, and that processing is facilitated when predictions turnout to be correct (evidenced, e.g., by shorter reading times on the predicted word or phrase).", "labels": [], "entities": [{"text": "Prediction", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.8368419408798218}]}, {"text": "Prediction is presumably one of the factors that contribute to the efficiency of human language understanding.", "labels": [], "entities": [{"text": "Prediction", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.8158020973205566}, {"text": "human language understanding", "start_pos": 81, "end_pos": 109, "type": "TASK", "confidence": 0.6258400678634644}]}, {"text": "Sentence processing is incremental (i.e., it proceeds on a word-by-word basis); therefore, it is beneficial if unseen input can be anticipated and relevant syntactic and semantic structure constructed in advance.", "labels": [], "entities": [{"text": "Sentence processing", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9460060596466064}]}, {"text": "This allows the processor to save time and makes it easier to cope with the constant stream of new input.", "labels": [], "entities": []}, {"text": "Evidence for prediction has been found in a range of psycholinguistic processing domains.", "labels": [], "entities": [{"text": "prediction", "start_pos": 13, "end_pos": 23, "type": "TASK", "confidence": 0.9662643074989319}]}, {"text": "Semantic prediction has been demonstrated by studies that show anticipation based on selectional restrictions: listeners are able to launch eye-movements to the predicted argument of a verb before having encountered it, e.g., they will fixate an edible object as soon as they hear the word eat (.", "labels": [], "entities": [{"text": "Semantic prediction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9063107073307037}]}, {"text": "Semantic prediction has also been shown in the context of semantic priming: a word that is preceded by a semantically related prime or by a semantically congruous sentence fragment is processed faster).", "labels": [], "entities": [{"text": "Semantic prediction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9263854920864105}]}, {"text": "An example for syntactic prediction can be found in coordinate structures: readers predict that the second conjunct in a coordination will have the same syntactic structure as the first conjunct).", "labels": [], "entities": [{"text": "syntactic prediction", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.8892993628978729}]}, {"text": "Ina similar vein, having encountered the word either, readers predict that or and a conjunct will follow it ().", "labels": [], "entities": []}, {"text": "Again, priming studies corroborate this: Comprehenders are faster at naming words that are syntactically compatible with prior context, even when they bear no semantic relationship to it.", "labels": [], "entities": []}, {"text": "Predictive processing is not confined to the sentence level.", "labels": [], "entities": [{"text": "Predictive processing", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.756901204586029}]}, {"text": "Recent experimental results also provide evidence for discourse prediction.", "labels": [], "entities": [{"text": "discourse prediction", "start_pos": 54, "end_pos": 74, "type": "TASK", "confidence": 0.8271668255329132}]}, {"text": "An example is the study by van, who used a context that made a target noun highly predictable, and found a mismatch effect in the ERP (event-related brain potential) when an adjective appeared that was inconsistent with the target noun.", "labels": [], "entities": [{"text": "ERP (event-related brain potential)", "start_pos": 130, "end_pos": 165, "type": "METRIC", "confidence": 0.7118288179238638}]}, {"text": "An example is (we give translations of their Dutch materials): (1) The burglar had no trouble locating the secret family safe. a. Of course, it was situated behind a 304 big neu but unobtrusive painting neu . b. Of course, it was situated behind a big com but unobtrusive bookcase com . Here, the adjective big, which can have neutral or common gender in Dutch, is consistent with the predicted noun painting in (1-a), but inconsistent with it in (1-b), leading to a mismatch ERP on big in (1-b) but not in (1-a).", "labels": [], "entities": [{"text": "ERP", "start_pos": 476, "end_pos": 479, "type": "METRIC", "confidence": 0.9908985495567322}]}, {"text": "Previous results on discourse effects in sentence processing can also be interpreted in terms of prediction.", "labels": [], "entities": []}, {"text": "Ina classical paper, demonstrated that PP-attachment preferences can change through discourse context: if the context contains two potential referents for the target NP, then NP-attachment of a subsequent PP is preferred (to disambiguate between the two referents), while if the context only contains one target NP, VP-attachment is preferred (as there is no need to disambiguate).", "labels": [], "entities": []}, {"text": "This result (and a large body of related findings) is compatible with an interpretation in which the processor predicts upcoming syntactic attachment based on the presence of referents in the preceding discourse.", "labels": [], "entities": []}, {"text": "Most attempts to model prediction inhuman language processing have focused on syntactic prediction.", "labels": [], "entities": [{"text": "prediction inhuman language processing", "start_pos": 23, "end_pos": 61, "type": "TASK", "confidence": 0.7232515513896942}, {"text": "syntactic prediction", "start_pos": 78, "end_pos": 98, "type": "TASK", "confidence": 0.7266864776611328}]}, {"text": "Examples include surprisal model, which relates processing effort to the conditional probability of the current word given the previous words in the sentence.", "labels": [], "entities": []}, {"text": "This approach has been elaborated by in a model that explicitly constructs predicted structure, and includes a verification process that incurs additional processing cost if predictions are not met.", "labels": [], "entities": []}, {"text": "Recent work has attempted to integrate semantic and discourse prediction with models of syntactic processing.", "labels": [], "entities": [{"text": "discourse prediction", "start_pos": 52, "end_pos": 72, "type": "TASK", "confidence": 0.7005055099725723}]}, {"text": "This includes approach, which combines an incremental parser with a vector-space model of semantics.", "labels": [], "entities": []}, {"text": "However, this approach only provides a loose integration of the two components (through simple addition of their probabilities), and the notion of semantics used is restricted to lexical meaning approximated byword co-occurrences.", "labels": [], "entities": []}, {"text": "At the discourse level, has proposed a model that combines an incremental parser with a probabilistic logic-based model of co-reference resolution.", "labels": [], "entities": [{"text": "co-reference resolution", "start_pos": 123, "end_pos": 146, "type": "TASK", "confidence": 0.7700266540050507}]}, {"text": "However, this model does not explicitly model discourse effects in terms of prediction, and again only proposes a loose integration of co-reference and syntax.", "labels": [], "entities": []}, {"text": "Furthermore, model has only been tested on two experimental data sets (pertaining to the interaction of ambiguity resolution with context), no broad coverage evaluation is available.", "labels": [], "entities": []}, {"text": "The aim of the present paper is to overcome these limitations.", "labels": [], "entities": []}, {"text": "We propose a computational model that captures discourse effects on syntax in terms of prediction.", "labels": [], "entities": []}, {"text": "The model comprises a co-reference component which explicitly stores discourse mentions of NPs, and a syntactic component which adjust the probabilities of NPs in the syntactic structure based on the mentions tracked by the discourse component.", "labels": [], "entities": []}, {"text": "Our model is HMM-based, which makes it possible to efficiently process large amounts of data, allowing an evaluation on eye-tracking corpora, which has recently become the gold-standard in computational psycholinguistics (e.g.,).", "labels": [], "entities": []}, {"text": "The paper is structured as follows: In Section 2, we describe the co-reference and the syntactic models and evaluate their performance on standard data sets.", "labels": [], "entities": []}, {"text": "Section 3 presents an evaluation of the overall model on the Dundee eye-tracking corpus.", "labels": [], "entities": [{"text": "Dundee eye-tracking corpus", "start_pos": 61, "end_pos": 87, "type": "DATASET", "confidence": 0.9433134992917379}]}, {"text": "The paper closes with a comparison with related work and a general discussion in Sections 4 and 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "Eye tracking data is noisy fora number of reasons, including the fact that experimental participants can look at any word which is currently displayed.", "labels": [], "entities": [{"text": "Eye tracking", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.8372597992420197}]}, {"text": "While English is normally read in a leftto-right manner, readers often skip words or make regressions (i.e., look at a word to the left of the one they are currently fixating).", "labels": [], "entities": []}, {"text": "Deviations from a strict left-to-right progression of fixations motivate the need for several different measures of eye movement.", "labels": [], "entities": []}, {"text": "The model presented here predicts the Total Time that participants spent looking at a region, which includes any re-fixations after looking away.", "labels": [], "entities": [{"text": "Total Time", "start_pos": 38, "end_pos": 48, "type": "METRIC", "confidence": 0.94379922747612}]}, {"text": "In addition to total time, other possible measures include (a) First Pass, which measures the initial fixation and any re-fixations before looking at any other word (this occurs, for instance, if the eye initially lands at the start of along word -the eye will tend to re-fixate on a more central viewing location), (b) Right Bounded reading time, which includes all fixations on a word before moving to the right of the word (i.e., re-fixations after moving left are included), and (c) Second Pass, which includes any re-fixation on a word after looking at any other word (be it to the left or the right of the word of interest).", "labels": [], "entities": [{"text": "First Pass", "start_pos": 63, "end_pos": 73, "type": "METRIC", "confidence": 0.948914110660553}, {"text": "Right Bounded reading time", "start_pos": 320, "end_pos": 346, "type": "METRIC", "confidence": 0.720823809504509}, {"text": "Second Pass", "start_pos": 487, "end_pos": 498, "type": "METRIC", "confidence": 0.9313238859176636}]}, {"text": "We found that the model performed similarly across all these reading time metrics, we therefore only report results for Total Time.", "labels": [], "entities": []}, {"text": "As mentioned above, reading measures are hypothesised to correlate with Surprisal, which is defined as: We compute the surprisal scores for the syntax-only HMM, which does not have access to co-reference information (henceforth referred to as 'HMM') and the full model, which combines the syntaxonly HMM with the co-reference model (henceforth 'HMM+Ref').", "labels": [], "entities": [{"text": "Surprisal", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.982624888420105}]}, {"text": "To determine if our Dundee corpus simulations provide a reasonable model of human sentence processing, we perform a regression analysis with the Dundee corpus reading time measure as the dependent variable and the surprisal scores as the independent variable.", "labels": [], "entities": [{"text": "Dundee corpus", "start_pos": 20, "end_pos": 33, "type": "DATASET", "confidence": 0.9446219801902771}, {"text": "human sentence processing", "start_pos": 76, "end_pos": 101, "type": "TASK", "confidence": 0.6598091224829356}, {"text": "Dundee corpus reading time measure", "start_pos": 145, "end_pos": 179, "type": "METRIC", "confidence": 0.7729202747344971}]}, {"text": "To account for noise in the corpus, we also use a number of additional explanatory variables which are known to strongly influence reading times.", "labels": [], "entities": []}, {"text": "These include the logarithm of the frequency of a word (measured in occurrences per million) and the length of a word in letters.", "labels": [], "entities": []}, {"text": "Two additional explanatory variables were available in the Dundee corpus, which we also included in the regression model.", "labels": [], "entities": [{"text": "Dundee corpus", "start_pos": 59, "end_pos": 72, "type": "DATASET", "confidence": 0.9935791492462158}]}, {"text": "These were the position of a word on a line, and which line in a document a word appeared in.", "labels": [], "entities": []}, {"text": "As participants could only view one line at a time (i.e., one line per screen), these covariates are known as line position and screen position, respectively.", "labels": [], "entities": []}, {"text": "All the covariates, including the surprisal estimates, were centered before including them in the regression model.", "labels": [], "entities": []}, {"text": "Because the HMM and HMM+Ref surprisal values are highly collinear, the HMM+Ref surprisal values were added as residuals of the HMM surprisal values.", "labels": [], "entities": [{"text": "HMM", "start_pos": 12, "end_pos": 15, "type": "DATASET", "confidence": 0.8926258087158203}]}, {"text": "Ina normal regression analysis, one must either assume that participants or the particular choice of 308 items add some randomness to the experiment, and either each participant's responses for all items must be averaged (treating participants as a random factor), or all participant's responses for each item is averaged (treating items as a random factor).", "labels": [], "entities": []}, {"text": "However, in the present analysis we utilise a mixed effects model, which allows both items and participants to be treated as random factors.", "labels": [], "entities": []}, {"text": "The area number of criteria which can be used to test the efficacy of one regression model over another.", "labels": [], "entities": []}, {"text": "These include the Aikake Information Criterion (AIC), the Bayesian Information Criterion (BIC), which trade off model fit and number of model parameters (lower scores are better).", "labels": [], "entities": [{"text": "Aikake Information Criterion (AIC)", "start_pos": 18, "end_pos": 52, "type": "DATASET", "confidence": 0.8343105812867483}]}, {"text": "It is also common to compare the log-likelihood of the models (higher log-likelihood is better), in which case a \u03c7 2 can be used to evaluate if a model offers a significantly better fit, given the number of parameters is uses.", "labels": [], "entities": []}, {"text": "We test three models: (i) a baseline, with only low-level factors as independent variables; (ii) the HMM model, with the baseline factors plus surprisal computed by the syntax-only HMM; and (iii) the HMM+Ref model which includes the raw surprisal values of the syntax-only HMM and the surprisal of the HMM+Ref models as computed as a residual of the HMM surprisal score.", "labels": [], "entities": []}, {"text": "We compare the HMM and HMM+Ref to the baseline, and the HMM+Ref model against the HMM model.", "labels": [], "entities": []}, {"text": "Some of the data needed to be trimmed.", "labels": [], "entities": []}, {"text": "If, due to data sparsity, the surprisal of a word goes to infinity for one of the models, we entirely remove that word from the analysis.", "labels": [], "entities": []}, {"text": "This occurred seven times form the HMM+Ref model, but did not occur at all with the HMM model.", "labels": [], "entities": []}, {"text": "Some of the eye-movement data was trimmed, as well.", "labels": [], "entities": []}, {"text": "Fixations on the first and last words of a line were excluded, as were tracklosses.", "labels": [], "entities": [{"text": "Fixations", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9360184669494629}]}, {"text": "However, we did not trim any items due to abnor-1 We assume that each participant and item bias the reading time of the experiment.", "labels": [], "entities": [{"text": "abnor-1", "start_pos": 42, "end_pos": 49, "type": "METRIC", "confidence": 0.976729154586792}]}, {"text": "Such an analysis is known as having random intercepts of participant and item.", "labels": [], "entities": []}, {"text": "It is also possible to assume a more involved analysis, known as random slopes, where the participants and items bias the slope of the predictor.", "labels": [], "entities": []}, {"text": "The model did not converge when using random intercept and slopes on both participant and item.", "labels": [], "entities": []}, {"text": "If random slopes on items were left out, the HMM regression model did converge, but not the HMM+Ref model.", "labels": [], "entities": []}, {"text": "As the HMM+Ref is the model of interest random slopes were left out entirely to allow a like-with-like comparison between the HMM and HMM+Ref regression models.", "labels": [], "entities": [{"text": "HMM+Ref", "start_pos": 7, "end_pos": 14, "type": "DATASET", "confidence": 0.7600079774856567}]}, {"text": "mally short or abnormally long fixation durations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Model comparison (upper part) and absolute scores for the Baseline model (lower part)", "labels": [], "entities": [{"text": "absolute", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9615052342414856}]}, {"text": " Table 2: Coefficients of the HMM+Ref model on Total Reading Times. Note that t > 2 indicates that the factor in  question is a significant predictor.", "labels": [], "entities": []}]}