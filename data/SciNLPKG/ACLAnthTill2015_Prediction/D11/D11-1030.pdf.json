{"title": [{"text": "Universal Morphological Analysis using Structured Nearest Neighbor Prediction", "labels": [], "entities": [{"text": "Universal Morphological Analysis", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.5633753935496012}, {"text": "Structured Nearest Neighbor Prediction", "start_pos": 39, "end_pos": 77, "type": "TASK", "confidence": 0.6317785978317261}]}], "abstractContent": [{"text": "In this paper, we consider the problem of un-supervised morphological analysis from anew angle.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 56, "end_pos": 78, "type": "TASK", "confidence": 0.682529479265213}]}, {"text": "Past work has endeavored to design un-supervised learning methods which explicitly or implicitly encode inductive biases appropriate to the task at hand.", "labels": [], "entities": []}, {"text": "We propose instead to treat morphological analysis as a structured prediction problem, where languages with labeled data serve as training examples for un-labeled languages, without the assumption of parallel data.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.7445967495441437}]}, {"text": "We define a universal morphological feature space in which every language and its morphological analysis reside.", "labels": [], "entities": []}, {"text": "We develop a novel structured nearest neighbor prediction method which seeks to find the morphological analysis for each unlabeled language which lies as close as possible in the feature space to a training language.", "labels": [], "entities": [{"text": "nearest neighbor prediction", "start_pos": 30, "end_pos": 57, "type": "TASK", "confidence": 0.70457657178243}]}, {"text": "We apply our model to eight inflecting languages, and induce nominal morphology with substantially higher accuracy than a traditional, MDL-based approach.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9964333772659302}]}, {"text": "Our analysis indicates that accuracy continues to improve substantially as the number of training languages increases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9995618462562561}]}], "introductionContent": [{"text": "Over the past several decades, researchers in the natural language processing community have focused most of their efforts on developing text processing tools and techniques for English, a morphologically simple language.", "labels": [], "entities": []}, {"text": "Recently, increasing attention has been paid to the wide variety of other languages of the world.", "labels": [], "entities": []}, {"text": "Most of these languages still pose severe difficulties, due to (i) their lack of annotated textual data, and (ii) the fact that they exhibit linguistic structure not found in English, and are thus not immediately susceptible to many traditional NLP techniques.", "labels": [], "entities": []}, {"text": "Consider the example of nominal part-of-speech analysis.", "labels": [], "entities": [{"text": "nominal part-of-speech analysis", "start_pos": 24, "end_pos": 55, "type": "TASK", "confidence": 0.6232265532016754}]}, {"text": "The Penn Treebank defines only four English noun tags, and as a result, it is easy to treat the words bearing these tags as completely distinct word classes, with no internal morphological structure.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 4, "end_pos": 17, "type": "DATASET", "confidence": 0.9930573105812073}]}, {"text": "In contrast, a comparable tagset for Hungarian includes 154 distinct noun tags), reflecting Hungarian's rich inflectional morphology.", "labels": [], "entities": []}, {"text": "When dealing with such languages, treating words as atoms leads to severe data sparsity problems.", "labels": [], "entities": []}, {"text": "Because annotated resources do not exist for most morphologically rich languages, prior research has focused on unsupervised methods, with a focus on developing appropriate inductive biases.", "labels": [], "entities": []}, {"text": "However, inductive biases and declarative knowledge are notoriously difficult to encode in well-founded models.", "labels": [], "entities": []}, {"text": "Even putting aside this practical matter, a universally correct inductive bias, if there is one, is unlikely to be be discovered by a priori reasoning alone.", "labels": [], "entities": []}, {"text": "In this paper, we argue that languages for which we have gold-standard morphological analyses can be used as effective guides for languages lacking such resources.", "labels": [], "entities": []}, {"text": "In other words, instead of treating each language's morphological analysis as a de novo induction problem to be solved with a purely handcoded bias, we instead learn from our labeled languages what linguistically plausible morphological analyses looks like, and guide our analysis in this direction.", "labels": [], "entities": []}, {"text": "322 More formally, we recast morphological induction as anew kind of supervised structured prediction problem, where each annotated language serves as a single training example.", "labels": [], "entities": []}, {"text": "Each language's noun lexicon serves as a single input x, and the analysis of the nouns into stems and suffixes serves as a complex structured label y.", "labels": [], "entities": []}, {"text": "Our first step is to define a universal morphological feature space, into which each language and its morphological analysis can be mapped.", "labels": [], "entities": []}, {"text": "We opt fora simple and intuitive mapping, which measures the sizes of the stem and suffix lexicons, the entropy of these lexicons, and the fraction of word forms which appear without any inflection.", "labels": [], "entities": []}, {"text": "Because languages tend to cluster into well defined morphological groups, we cast our learning and prediction problem in the nearest neighbor framework.", "labels": [], "entities": []}, {"text": "In contrast to its typical use in classification problems, where one can simply pick the label of the nearest training example, we are here faced with a structured prediction problem, where locations in feature space depend jointly on the input-label pair (x, y).", "labels": [], "entities": []}, {"text": "Finding a nearest neighbor thus consists of searching over the space of morphological analyses, until a point in feature space is reached which lies closest to one of the labeled languages.", "labels": [], "entities": []}, {"text": "To provide a measure of empirical validation, we applied our approach to eight languages with inflectional nominal morphology, ranging in complexity from very simple (English) to very complex.", "labels": [], "entities": []}, {"text": "In all but one case, our approach yields substantial improvements over a comparable monolingual baseline, which uses the minimum description length principle (MDL) as its inductive bias.", "labels": [], "entities": [{"text": "minimum description length principle (MDL)", "start_pos": 121, "end_pos": 163, "type": "METRIC", "confidence": 0.7663885951042175}]}, {"text": "On average, our method increases accuracy by 11.8 percentage points, corresponding to a 42% decrease in error relative to a supervised upper bound.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9994945526123047}, {"text": "error", "start_pos": 104, "end_pos": 109, "type": "METRIC", "confidence": 0.993240237236023}]}, {"text": "Further analysis indicates that accuracy improves as the number of training languages increases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9995143413543701}]}], "datasetContent": [{"text": "In this section we turn to experimental findings to provide empirical support for our proposed framework.", "labels": [], "entities": []}, {"text": "Corpus: To test our cross-lingual model, we apply it to a morphologically analyzed corpus of eight languages).", "labels": [], "entities": []}, {"text": "The corpus includes a roughly 100,000 word English text, Orwell's novel \"Nineteen Eighty Four,\" and its translation into seven languages: Bulgarian, Czech, Estonian, Hungarian, Romanian, Slovene, and Serbian.", "labels": [], "entities": []}, {"text": "All the words in the corpus are tagged with morphological stems and a detailed morpho-syntactic analysis.", "labels": [], "entities": []}, {"text": "Although the texts are parallel, we note that parallelism is nowhere assumed nor exploited by our model.", "labels": [], "entities": []}, {"text": "See fora summary of relevant corpus statistics.", "labels": [], "entities": []}, {"text": "As indicated in the table, the raw number of nominal word types varies quite a bit across the languages, almost doubling from 4,178 (English) to 8,051 (Hungarian).", "labels": [], "entities": []}, {"text": "In contrast, the number of stems appearing within these words is relatively stable across languages, ranging from a minimum of 3,112 (Bulgarian) to a maximum of 3,746, an increase of just 20%.", "labels": [], "entities": []}, {"text": "In contrast, the number of suffixes across the languages varies quite a bit.", "labels": [], "entities": []}, {"text": "Hungarian and Estonian, both Uralic languages with very complex nominal morphology, use 231 and 141 nominal suffixes, respectively.", "labels": [], "entities": []}, {"text": "Besides English, the remaining languages employ between 21 and 32 suffixes, and English is the outlier in the other direction, with just three nominal inflectional suffixes.", "labels": [], "entities": []}, {"text": "Baselines and Results: As our unsupervised monolingual baseline, we use the Linguistica program).", "labels": [], "entities": []}, {"text": "We apply Linguistica's default settings, and run the \"suffix prediction\" option.", "labels": [], "entities": [{"text": "suffix prediction", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.7145029902458191}]}, {"text": "Our model's search procedure closely mirrors the one used by Linguistica, with the crucial difference that instead of attempting to greedily minimize description length, our algorithm instead tries to find the analysis as close as possible in the universal feature space to that of another language.", "labels": [], "entities": []}, {"text": "To apply our model, we treat each of the eight 327: Prediction accuracy over word types for the Linguistica baseline, our cross-lingual model, and the monolingual supervised perceptron model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.5927988886833191}]}, {"text": "For our model, we provide both prediction accuracy and resulting distance to the training language in three different scenarios: (i) Nearest Neighbor: The training languages include all seven other languages in our data set, and the predictions with minimal distance to a training language are chosen (the nearest neighbor is indicated in parentheses).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9836083054542542}]}, {"text": "languages in turn as the test language, with the other seven serving as training examples.", "labels": [], "entities": []}, {"text": "For each test language, we iterate the search procedure for each training language (performed in parallel), until convergence.", "labels": [], "entities": []}, {"text": "The number of required iterations varies from 6 to 36 (depending on the test-training language pair), and each iteration takes no more than 30 seconds of run-time on a 2.4GHz Intel Xeon E5620 processor.", "labels": [], "entities": []}, {"text": "We also consider two variants of our method.", "labels": [], "entities": []}, {"text": "In the first (Self (oracle)), we train each test language to minimize the distance to its own gold standard feature values.", "labels": [], "entities": []}, {"text": "In the second variant (Avg.), we average the feature values of all seven training languages into a single objective.", "labels": [], "entities": []}, {"text": "As a plausible upper bound on performance, we implemented the structured perceptron described in Section 3.2.", "labels": [], "entities": []}, {"text": "For each language, we train the perceptron on a randomly selected set of 80% of the nouns, and test on the remaining 20%.", "labels": [], "entities": []}, {"text": "The prediction accuracy for all models is calculated as the fraction of word types with correctly predicted suffixes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9380152225494385}]}, {"text": "For all languages other than English (which is a morphological loner in our group of languages), our model improves over the baseline by a substantial margin, yielding an average increase of 11.8 absolute percentage points, and a reduction in error relative to the supervised upper bound of 42%.", "labels": [], "entities": [{"text": "error", "start_pos": 243, "end_pos": 248, "type": "METRIC", "confidence": 0.9971484541893005}]}, {"text": "Some of the most striking improvements are seen on Serbian and Slovene.", "labels": [], "entities": []}, {"text": "These languages are closely related to one another, and indeed our model discovers that they are each others' nearest neighbors.", "labels": [], "entities": []}, {"text": "By guiding their morphological analyses towards one another, our model achieves a 21 percentage point increase in the case of Slovene and a 15 percentage point increase in the case of Slovene.", "labels": [], "entities": []}, {"text": "Perhaps unsurprisingly, when each language's gold standard feature values are used as its own target (Self (oracle) in), performance increases even further, to an average of 81.1%.", "labels": [], "entities": []}, {"text": "By the same token, the resulting distance in universal feature space between training and test analyses is cut in half under this variant, when compared to the nonoracular nearest neighbor method.", "labels": [], "entities": []}, {"text": "The remaining errors maybe due to limitations of the search procedure (i.e. getting caught in local minima), or to the coarseness of the feature space (i.e. incorrect analyses might map to the same feature values as the correct analysis).", "labels": [], "entities": []}, {"text": "Finally, we note that minimizing the distance to the average feature values of the seven training languages (Avg.", "labels": [], "entities": []}, {"text": "in) yields subpar performance and very large distances between between predicted analyses and target feature values (4.14 compared to 0.40 for nearest neighbor).", "labels": [], "entities": []}, {"text": "This 328 result may indicate that the average feature point between training languages is simply unattainable as an analysis of areal lexicon of nouns.", "labels": [], "entities": []}, {"text": "Visualizing Locations in Feature Space: Besides assessing our method quantitatively, we can also visualize the the eight languages in universal feature space according to (i) their gold standard analyses, (ii) the predictions of our model and (iii) the predictions of Linguistica.", "labels": [], "entities": []}, {"text": "To do so, we reduce the 8-dimensional features space down to two dimensions while preserving the distances between the predicted and gold standard feature vectors, using Multidimensional Scaling (MDS).", "labels": [], "entities": []}, {"text": "The results of this analysis are shown in.", "labels": [], "entities": []}, {"text": "With the exception of English, our model's analyses lie closer in feature space to their gold standard counterparts than those of the baseline.", "labels": [], "entities": []}, {"text": "It is interesting to note that Serbian and Slovene, which are very similar languages, have essentially swapped places under our model's analysis, as have Estonian and Hungarian (both highly inflected Uralic languages).", "labels": [], "entities": []}, {"text": "English has (unfortunately) been pulled towards Bulgarian, the second least inflecting language in our set.", "labels": [], "entities": []}, {"text": "Learning Curves: We also measured the performance of our method as a function of the number of languages in the training set.", "labels": [], "entities": []}, {"text": "For each target language, we consider all possible training sets of sizes ranging from 1 to 7 and select the predictions which bring our test language closest in distance to one of the languages in the set.", "labels": [], "entities": []}, {"text": "We then average the resulting accuracy overall training sets of each size.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9995489716529846}]}, {"text": "shows the resulting learning curves averaged overall test languages (left), as well as broken down by test language (right).", "labels": [], "entities": []}, {"text": "The overall trend is clear: as additional languages are added to the training set, test performance improves.", "labels": [], "entities": []}, {"text": "In fact, with only one training language, our method performs worse (on average) than the Linguistica baseline.", "labels": [], "entities": []}, {"text": "However, with two or more training languages available, our method achieves superior results.", "labels": [], "entities": []}, {"text": "Accuracy vs. Distance: We can gain some insight into these learning curves if we consider the relationship between accuracy (of the test language analysis) and distance to the training language (of the same predicted analysis).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9858930706977844}, {"text": "Distance", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9687069654464722}, {"text": "accuracy", "start_pos": 115, "end_pos": 123, "type": "METRIC", "confidence": 0.999138355255127}]}, {"text": "The more training languages available, the greater the chance that we can guide our test language into very close proximity to 329  one of them.", "labels": [], "entities": []}, {"text": "It thus stands to reason that a strong (negative) correlation between distance and accuracy would lead to increased accuracy with larger training sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9990907907485962}, {"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9991419315338135}]}, {"text": "In order to assess this correlation, we considered all 56 test-train language pairs and collected the resulting accuracy and distance for each pair.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.999480664730072}]}, {"text": "We separately scaled accuracy and distance to the unit interval for each test language (as some test languages are inherently more difficult than others).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9994657635688782}]}, {"text": "The resulting plot, shown in, shows the expected correlation: When our test language can be guided very closely to the training language, the resulting predictions are likely to be good.", "labels": [], "entities": []}, {"text": "If not, the predictions are likely to be bad.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Corpus statistics for the eight languages. The first four columns give the number of unique word, stem, suffix,  and phonological deletion rule types. The next three columns give, respectively, the entropies of the distributions", "labels": [], "entities": []}, {"text": " Table 2: Prediction accuracy over word types for the Linguistica baseline, our cross-lingual model, and the monolin- gual supervised perceptron model. For our model, we provide both prediction accuracy and resulting distance to the  training language in three different scenarios: (i) Nearest Neighbor: The training languages include all seven other  languages in our data set, and the predictions with minimal distance to a training language are chosen (the nearest  neighbor is indicated in parentheses).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9382230043411255}, {"text": "accuracy", "start_pos": 194, "end_pos": 202, "type": "METRIC", "confidence": 0.9611032605171204}]}]}