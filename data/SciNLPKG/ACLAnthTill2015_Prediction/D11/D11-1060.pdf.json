{"title": [{"text": "Large-Scale Noun Compound Interpretation Using Bootstrapping and the Web as a Corpus", "labels": [], "entities": [{"text": "Large-Scale Noun Compound Interpretation", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.6219485551118851}]}], "abstractContent": [{"text": "Responding to the need for semantic lexical resources in natural language processing applications , we examine methods to acquire noun compounds (NCs), e.g., orange juice, together with suitable fine-grained semantic interpretations , e.g., squeezed from, which are directly usable as paraphrases.", "labels": [], "entities": []}, {"text": "We employ bootstrapping and web statistics, and utilize the relationship between NCs and paraphrasing patterns to jointly extract NCs and such patterns in multiple alternating iterations.", "labels": [], "entities": []}, {"text": "In evaluation, we found that having one compound noun fixed yields both a higher number of semantically interpreted NCs and improved accuracy due to stronger semantic restrictions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9990447163581848}]}], "introductionContent": [{"text": "Noun compounds (NCs) such as malaria mosquito and colon cancer tumor suppressor protein are challenging for text processing since the relationship between the nouns they are composed of is implicit.", "labels": [], "entities": [{"text": "text processing", "start_pos": 108, "end_pos": 123, "type": "TASK", "confidence": 0.8029956519603729}]}, {"text": "NCs are abundant in English and understanding their semantics is important in many natural language processing (NLP) applications.", "labels": [], "entities": []}, {"text": "For example, a question answering system might need to know whether protein acting as a tumor suppressor is a good paraphrase for tumor suppressor protein.", "labels": [], "entities": [{"text": "question answering", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.8244760036468506}]}, {"text": "Similarly, a machine translation system facing the unknown noun compound Geneva headquarters might translate it better if it could first paraphrase it as Geneva headquarters of the WTO.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7088028192520142}]}, {"text": "Given a query for \"migraine treatment\", an information retrieval system could use paraphrasing verbs like relieve and prevent for query expansion and result ranking.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 130, "end_pos": 145, "type": "TASK", "confidence": 0.7875916659832001}]}, {"text": "Most work on noun compound interpretation has focused on two-word NCs.", "labels": [], "entities": [{"text": "noun compound interpretation", "start_pos": 13, "end_pos": 41, "type": "TASK", "confidence": 0.8610567649205526}]}, {"text": "There have been two general lines of research: the first one derives the NC semantics from the semantics of the nouns it is made of (, while the second one models the relationship between the nouns directly;.", "labels": [], "entities": []}, {"text": "In either case, the semantics of an NC is typically expressed by an abstract relation like CAUSE (e.g., malaria mosquito), SOURCE (e.g., olive oil), or PURPOSE (e.g., migraine drug), coming from a small fixed inventory.", "labels": [], "entities": [{"text": "CAUSE", "start_pos": 91, "end_pos": 96, "type": "METRIC", "confidence": 0.8465871810913086}, {"text": "SOURCE", "start_pos": 123, "end_pos": 129, "type": "METRIC", "confidence": 0.95859694480896}, {"text": "PURPOSE", "start_pos": 152, "end_pos": 159, "type": "METRIC", "confidence": 0.9824551939964294}]}, {"text": "Some researchers however, have argued fora more fine-grained, even infinite, inventory.", "labels": [], "entities": []}, {"text": "Verbs are particularly useful in this respect and can capture elements of the semantics that the abstract relations cannot.", "labels": [], "entities": []}, {"text": "For example, while most NCs expressing MAKE, can be paraphrased by common patterns like be made of and be composed of, some NCs allow more specific patterns, e.g., be squeezed from for orange juice, and be topped with for bacon pizza.", "labels": [], "entities": []}, {"text": "Recently, the idea of using fine-grained paraphrasing verbs for NC semantics has been gaining popularity (; there has also been a related shared task at SemEval-2010 (.", "labels": [], "entities": [{"text": "NC semantics", "start_pos": 64, "end_pos": 76, "type": "TASK", "confidence": 0.7706847488880157}]}, {"text": "This interest is partly driven by practicality: verbs are directly usable as paraphrases.", "labels": [], "entities": []}, {"text": "Still, abstract relations remain dominant since they offer a more natural generalization, which is useful for many NLP applications.", "labels": [], "entities": []}, {"text": "One good contribution to this debate would be a direct study of the relationship between fine-grained and coarse-grained relations for NC interpretation.", "labels": [], "entities": [{"text": "NC interpretation", "start_pos": 135, "end_pos": 152, "type": "TASK", "confidence": 0.9567008316516876}]}, {"text": "Unfortunately, the existing datasets do not allow this since they are tied to one particular granularity; moreover, they only contain a few hundred NCs.", "labels": [], "entities": []}, {"text": "Thus, our objective is to build a large-scale dataset of hundreds of thousands of NCs, each interpreted (1) by an abstract semantic relation and (2) by a set of paraphrasing verbs.", "labels": [], "entities": []}, {"text": "Having such a large dataset would also help the overall advancement of the field.", "labels": [], "entities": []}, {"text": "Since there is no universally accepted abstract relation inventory in NLP, and since we are interested in NC semantics from both a theoretical and a practical viewpoint, we chose the set of abstract relations proposed in the theory of, which is dominant in theoretical linguistics and has been also used in NLP.", "labels": [], "entities": []}, {"text": "We use a two-step algorithm to jointly harvest NCs and patterns (verbs and prepositions) that interpret them fora given abstract relation.", "labels": [], "entities": []}, {"text": "First, we extract NCs using a small number of seed patterns from a given abstract relation.", "labels": [], "entities": []}, {"text": "Then, using the extracted NCs, we harvest more patterns.", "labels": [], "entities": []}, {"text": "This is repeated until no new NCs and patterns can be extracted or fora pre-specified number of iterations.", "labels": [], "entities": []}, {"text": "Our approach combines pattern-based extraction and bootstrapping, which is novel for NC interpretation; however, such combinations have been used in other areas, e.g., named entity recognition (.", "labels": [], "entities": [{"text": "pattern-based extraction", "start_pos": 22, "end_pos": 46, "type": "TASK", "confidence": 0.7315043956041336}, {"text": "NC interpretation", "start_pos": 85, "end_pos": 102, "type": "TASK", "confidence": 0.9279466569423676}, {"text": "named entity recognition", "start_pos": 168, "end_pos": 192, "type": "TASK", "confidence": 0.6359310944875082}]}, {"text": "The remainder of the paper is organized as follows: Section 2 gives an overview of related work, Section 3 motivates our semantic representation, Sections 4, 5, and 6 explain our method, dataset and experiments, respectively, Section 7 discusses the results, Section 8 provides error analysis, and Section 9 concludes with suggestions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Using the NCs and patterns in as initial seeds, we ran our algorithm for three iterations of loose bootstrapping and strict bootstrapping, and for two iterations of NC-only strict bootstrapping.", "labels": [], "entities": []}, {"text": "We only performed up to three iterations because of the huge number of noun compounds extracted for NC-only strict bootstrapping (which we only ran for two iterations) and because of the low number of new NCs extracted by loose bootstrapping on iteration 3.", "labels": [], "entities": []}, {"text": "While we could have run strict bootstrapping for more iterations, we opted fora comparable number of iterations for all three methods.", "labels": [], "entities": []}, {"text": "Examples of noun compounds that we have extracted are bronze bell (be made of, be made from) and child team (be composed of, include).", "labels": [], "entities": []}, {"text": "Example patterns are be filled with (cotton bag, water cup) and use (water sculpture, wood statue).", "labels": [], "entities": []}, {"text": "As we mentioned in section 4.2.3, at each iteration, we filtered out all patterns that were extracted less than N times or with less than M NCs.", "labels": [], "entities": []}, {"text": "Note that we only used the 10 most frequent NCs per pattern as NC seeds for NC extraction in the next iteration of strict bootstrapping and NC-only strict bootstrapping.", "labels": [], "entities": [{"text": "NC extraction", "start_pos": 76, "end_pos": 89, "type": "TASK", "confidence": 0.7468867599964142}]}, {"text": "shows the results for two value combinations of (N ;M ): (5;50) and.", "labels": [], "entities": []}, {"text": "Note also that if some NC was extracted by several different patterns, it was only counted once.", "labels": [], "entities": []}, {"text": "Patterns are subject to particular NCs, and thus we show (1) the number of patterns extracted with all NCs, i.e., unique NCpattern pairs, (2) the accuracy of these pairs, 4 and (3) the number of unique patterns retained after filtering, which will be used to extract new noun compounds on the second step of the current iteration.: Evaluation results for up to three iterations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9992731213569641}]}, {"text": "For NCs, we show the number of unique NCs extracted and their accuracy in %.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9995823502540588}]}, {"text": "For patterns, we show the number of unique NC-pattern pairs extracted, their accuracy in %, and the number of unique patterns retained and used to extract NCs on the second step of the current iteration.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 77, "end_pos": 85, "type": "METRIC", "confidence": 0.9993016719818115}]}, {"text": "The first column shows the pattern filtering thresholds used (see Section 4.2.3 for details).", "labels": [], "entities": [{"text": "pattern filtering", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.7237658202648163}]}, {"text": "The above accuracies were calculated based on human judgments by an experienced, well-trained annotator.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.955428421497345}]}, {"text": "We also hired a second annotator fora small subset of the examples.", "labels": [], "entities": []}, {"text": "For NCs, the first annotator judged whether each NC is an instance of MAKE 2 . All NCs were judged, except for iteration 2 of NC-only strict bootstrapping, where their number was prohibitively high and only the most frequent noun compounds extracted for each modifier and for each head were checked: 9,004 NCs for N =5 and 4,262 NCs for N =10.", "labels": [], "entities": []}, {"text": "For patterns, our first annotator judged the correctness of the unique NC-pattern pairs, i.e., whether the NC is paraphrasable with the target pattern.", "labels": [], "entities": []}, {"text": "Given the large number of NC-pattern pairs, the annotator only judged patterns with their top 10 most frequent NCs.", "labels": [], "entities": []}, {"text": "For example, if there were 5 patterns extracted, then the NC-pattern pairs to be judged would be no more than 5 \u00d7 10 = 50.", "labels": [], "entities": []}, {"text": "Our second annotator judged 340 random examples: 100 NCs and 20 patterns with their top 10 NCs for each iteration.", "labels": [], "entities": []}, {"text": "The Cohen's kappa between the two annotators is .66 (85% initial agreement), which corresponds to substantial agreement (.", "labels": [], "entities": []}, {"text": "show that fixing one of the two nouns in the pattern, as in strict bootstrapping and NC-only strict bootstrapping, yields significantly higher accuracy (\u03c7 2 test) for both NC and NC-pattern pair extraction compared to loose bootstrapping.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.9991794228553772}, {"text": "NC-pattern pair extraction", "start_pos": 179, "end_pos": 205, "type": "TASK", "confidence": 0.6482361753781637}]}], "tableCaptions": [{"text": " Table 2: Total number and accuracy in % for NCs, pat- terns and NC-pattern pairs extracted and retained for each  of the three methods over all iterations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9943966865539551}]}, {"text": " Table 3: Evaluation results for up to three iterations. For NCs, we show the number of unique NCs extracted and  their accuracy in %. For patterns, we show the number of unique NC-pattern pairs extracted, their accuracy in %, and  the number of unique patterns retained and used to extract NCs on the second step of the current iteration. The first  column shows the pattern filtering thresholds used (see Section 4.2.3 for details).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9969019889831543}, {"text": "accuracy", "start_pos": 212, "end_pos": 220, "type": "METRIC", "confidence": 0.9872075915336609}]}, {"text": " Table 4: Number of extracted noun compounds and ac- curacy in % for the method of Kim and Baldwin (2007).  The abbreviations Syn., Hyp., and Sis. indicate using syn- onyms, hypernyms, and sister words, respectively.", "labels": [], "entities": [{"text": "ac- curacy", "start_pos": 49, "end_pos": 59, "type": "METRIC", "confidence": 0.9000996152559916}]}]}