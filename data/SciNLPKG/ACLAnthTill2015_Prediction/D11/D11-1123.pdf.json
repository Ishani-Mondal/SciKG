{"title": [{"text": "Structural Opinion Mining for Graph-based Sentiment Representation", "labels": [], "entities": [{"text": "Structural Opinion Mining", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8374337752660116}, {"text": "Graph-based Sentiment Representation", "start_pos": 30, "end_pos": 66, "type": "TASK", "confidence": 0.6781395673751831}]}], "abstractContent": [{"text": "Based on analysis of on-line review corpus we observe that most sentences have complicated opinion structures and they cannot be well represented by existing methods, such as frame-based and feature-based ones.", "labels": [], "entities": []}, {"text": "In this work, we propose a novel graph-based representation for sentence level sentiment.", "labels": [], "entities": [{"text": "sentence level sentiment", "start_pos": 64, "end_pos": 88, "type": "TASK", "confidence": 0.6516245106856028}]}, {"text": "An integer linear programming-based structural learning method is then introduced to produce the graph representations of input sentences.", "labels": [], "entities": []}, {"text": "Experimental evaluations on a manually labeled Chinese corpus demonstrate the effectiveness of the proposed approach.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentiment analysis has received much attention in recent years.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9805858135223389}]}, {"text": "A number of automatic methods have been proposed to identify and extract opinions, emotions, and sentiments from text.", "labels": [], "entities": [{"text": "identify and extract opinions, emotions, and sentiments from text", "start_pos": 52, "end_pos": 117, "type": "TASK", "confidence": 0.7052057222886519}]}, {"text": "Previous researches on sentiment analysis tackled the problem on various levels of granularity including document, sentence, phrase and word (;.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.9575017392635345}]}, {"text": "They mainly focused on two directions: sentiment classification which detects the overall polarity of a text; sentiment related information extraction which tries to answer the questions like \"who expresses what opinion on which target\".", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 39, "end_pos": 63, "type": "TASK", "confidence": 0.9431163966655731}, {"text": "sentiment related information extraction", "start_pos": 110, "end_pos": 150, "type": "TASK", "confidence": 0.6570509821176529}]}, {"text": "Most of the current studies on the second direction assume that an opinion can be structured as a frame which is composed of a fixed number of slots.", "labels": [], "entities": []}, {"text": "Typical slots include opinion holder, opinion expression, and evaluation target.", "labels": [], "entities": [{"text": "opinion holder", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.6854680776596069}, {"text": "opinion expression", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.6675148010253906}]}, {"text": "Under this representation, they defined the task as a slots filling problem for each of the opinions.", "labels": [], "entities": [{"text": "slots filling", "start_pos": 54, "end_pos": 67, "type": "TASK", "confidence": 0.7325104922056198}]}, {"text": "Named entity recognition and relation extraction techniques are usually applied in this task (.", "labels": [], "entities": [{"text": "Named entity recognition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6797630985577902}, {"text": "relation extraction", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.8499701023101807}]}, {"text": "However, through data analysis, we observe that 60.5% of sentences in our corpus do not follow the assumption used by them.", "labels": [], "entities": []}, {"text": "A lot of important information about an opinion maybe lost using those representation methods.", "labels": [], "entities": []}, {"text": "Consider the following examples, which are extracted from real online reviews: Example 1: The interior is a bit noisy on the freeway . Example 2: Takes good pictures during the daytime.", "labels": [], "entities": []}, {"text": "Very poor picture quality at night 2 . Based on the definition of opinion unit proposed by, from the first example, the information we can get is the author's negative opinion about \"interior\" using an opinion expression \"noisy\".", "labels": [], "entities": []}, {"text": "However, the important restriction \"on the freeway\", which narrows the scope of the opinion, is ignored.", "labels": [], "entities": []}, {"text": "In fact, the tuple (\"noisy\",\"on the freeway\") cannot correctly express the original opinion: it is negative but under certain condition.", "labels": [], "entities": []}, {"text": "The second example is similar.", "labels": [], "entities": []}, {"text": "If the conditions \"during the daytime\" and \"at night\" are dropped, the extracted elements cannot correctly represent user's opinions.", "labels": [], "entities": []}, {"text": "Example 3: The camera is actually quite good for outdoors because of the software.", "labels": [], "entities": []}, {"text": "Besides that, an opinion expression may induce other opinions which are not expressed directly.", "labels": [], "entities": []}, {"text": "In example 3, the opinion expression is \"good\" whose target is \"camera\".", "labels": [], "entities": []}, {"text": "But the \"software\" which triggers the opinion expression \"good\" is also endowed with a positive opinion.", "labels": [], "entities": []}, {"text": "In practice, this induced opinion on \"software\" is actually more informative than its direct counterpart.", "labels": [], "entities": []}, {"text": "Mining those opinions may help to form a complete sentiment analysis result.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.9239518940448761}]}, {"text": "Example 4: The image quality is in the middle of its class, but it can still be a reasonable choice for students.", "labels": [], "entities": []}, {"text": "Furthermore, the relations among individual opinions also provide additional information which is lost when they are considered separately.", "labels": [], "entities": []}, {"text": "Example 4 is such a case that the whole positive comment of camera is expressed by a transition from a negative opinion to a positive one.", "labels": [], "entities": []}, {"text": "In order to address those issues, this paper describes a novel sentiment representation and analysis method.", "labels": [], "entities": [{"text": "sentiment representation and analysis", "start_pos": 63, "end_pos": 100, "type": "TASK", "confidence": 0.8234633877873421}]}, {"text": "Our main contributions are as follows: 1.", "labels": [], "entities": []}, {"text": "We investigate the use of graphs for representing sentence level sentiment.", "labels": [], "entities": [{"text": "sentence level sentiment", "start_pos": 50, "end_pos": 74, "type": "TASK", "confidence": 0.6601634919643402}]}, {"text": "The vertices are evaluation target, opinion expression, modifiers of opinion.", "labels": [], "entities": []}, {"text": "The Edges represent relations among them.", "labels": [], "entities": []}, {"text": "The semantic relations among individual opinions are also included.", "labels": [], "entities": []}, {"text": "Through the graph, various information on opinion expressions which is ignored by current representation methods can be well handled.", "labels": [], "entities": []}, {"text": "And the proposed representation is language-independent.", "labels": [], "entities": []}, {"text": "2. We propose a supervised structural learning method which takes a sentence as input and the proposed sentiment representation for it as output.", "labels": [], "entities": []}, {"text": "The inference algorithm is based on integer linear programming which helps to concisely and uniformly handle various properties of our sentiment representation.", "labels": [], "entities": []}, {"text": "By setting appropriate prior substructure constraints of the graph, the whole algorithm achieves reasonable performances.", "labels": [], "entities": []}, {"text": "The remaining part of this paper is organized as follows: In Section 2 we discuss the proposed representation method.", "labels": [], "entities": []}, {"text": "Section 3 describes the computational model used to construct it.", "labels": [], "entities": []}, {"text": "Experimental results in test collections and analysis are shown in Section 4.", "labels": [], "entities": []}, {"text": "In Section 5, we present the related work and Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "In all the experiments below, we take 90% of the corpus as training set, 10% as test set and run 10 folder cross validation.", "labels": [], "entities": []}, {"text": "In feature construction, we use an external Chinese sentiment lexicon which contains 4566 positive opinion words and 4370 negative opinion words.", "labels": [], "entities": [{"text": "feature construction", "start_pos": 3, "end_pos": 23, "type": "TASK", "confidence": 0.7260694056749344}]}, {"text": "For Chinese word segment, we use ctbparser . Stanford parser () is used for dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.8598602712154388}]}, {"text": "In the settings of PA, the maximum iteration number is set to 2, which is chosen by maximizing the testing performances, aggressiveness parameter C is set to 0.00001.", "labels": [], "entities": []}, {"text": "For parameters in inference algorithm, Ct = 2, the solver of ILP is lpsolve . We evaluate the system from the following aspects: 1) whether the structural information helps to mining opinion relations.", "labels": [], "entities": []}, {"text": "2) How the proposed inference algorithm performs with different constraints.", "labels": [], "entities": []}, {"text": "3) How the various features affect the system.", "labels": [], "entities": []}, {"text": "Except for the last one, the feature set used for different experiments are the same (\"In+Out+Dep\" in).", "labels": [], "entities": []}, {"text": "The criteria for evaluation are similar to the unlabeled attachment score in parser evaluations, but due to the equation |E| = |V | \u2212 1 is not valid if G is not a tree, we evaluate precision P = #true edges in result graph , and F-score", "labels": [], "entities": [{"text": "precision", "start_pos": 181, "end_pos": 190, "type": "METRIC", "confidence": 0.9923296570777893}, {"text": "F-score", "start_pos": 229, "end_pos": 236, "type": "METRIC", "confidence": 0.9827650189399719}]}], "tableCaptions": [{"text": " Table 2: Statistics of relation types", "labels": [], "entities": []}, {"text": " Table 3: Binary classifier and structural learning", "labels": [], "entities": []}, {"text": " Table 4: Results on inference methods. \"MST\" is the ba- sic multicommodity flow formulation of maximum span- ning tree; c1, c2, c3 are groups of constraint from Section  3.2.2; \"g\" is our heuristic method for additional non span- ning tree edges.", "labels": [], "entities": []}, {"text": " Table 5. From the results, the outside feature set is  more effective than inside feature set, even if it does  not use any external resource. A possible reason is  that the content of a vertex can be very complicated  (a vertex even can be a clause), but the features sur- rounding the vertex are relatively simple and easy  to identify (for example, a single preposition can  identify a complex condition). The dependency fea- ture has limited effect, due to that lots of online re- view sentences are ungrammatical and parsing re- sults are unreliable. And the complexity of vertices  also messes the dependency feature.", "labels": [], "entities": []}, {"text": " Table 5: Results with different features. \"In\" repre- sents the result of inside feature set; \"In-s\" is \"In\" with- out the external opinion lexicon feature; \"Out\" uses the  outside feature set; \"In+Out\" uses both \"In\" and \"Out\",  \"In+Out+Dep\" adds the dependency feature. The infer- ence algorithm is \"MST+c1+c2+c3+g\" in", "labels": [], "entities": []}, {"text": " Table 6: Features for vertex extraction. The sequential  labeling is conducted on character level (c i ). The senti- ment lexicon used in c i .inDict is the same as Table1. We  also use bigram feature templates on c i .char, c i .isAlpha,  c i .inDict with respect to c i\u22121 and c i+1 .", "labels": [], "entities": [{"text": "vertex extraction", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7763917744159698}]}, {"text": " Table 7: Results on vertices extraction with 10 folder  cross validation. We use two criterion: 1) the vertex is  correct if it is exactly same as ground truth(\"E\"), 2) the  vertex is correct if it overlaps with ground truth(\"O\").", "labels": [], "entities": [{"text": "vertices extraction", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.7640073895454407}]}]}