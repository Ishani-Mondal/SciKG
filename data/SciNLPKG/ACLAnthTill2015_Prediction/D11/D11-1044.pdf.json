{"title": [{"text": "Quasi-Synchronous Phrase Dependency Grammars for Machine Translation", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.7490992844104767}]}], "abstractContent": [{"text": "We present a quasi-synchronous dependency grammar (Smith and Eisner, 2006) for machine translation in which the leaves of the tree are phrases rather than words as in previous work (Gimpel and Smith, 2009).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 79, "end_pos": 98, "type": "TASK", "confidence": 0.7608947455883026}]}, {"text": "This formulation allows us to combine structural components of phrase-based and syntax-based MT in a single model.", "labels": [], "entities": [{"text": "MT", "start_pos": 93, "end_pos": 95, "type": "TASK", "confidence": 0.8483307957649231}]}, {"text": "We describe a method of extracting phrase dependencies from parallel text using a target-side dependency parser.", "labels": [], "entities": [{"text": "extracting phrase dependencies from parallel text", "start_pos": 24, "end_pos": 73, "type": "TASK", "confidence": 0.7684484471877416}]}, {"text": "For decoding, we describe a coarse-to-fine approach based on lattice dependency parsing of phrase lattices.", "labels": [], "entities": [{"text": "lattice dependency parsing of phrase lattices", "start_pos": 61, "end_pos": 106, "type": "TASK", "confidence": 0.8021378616491953}]}, {"text": "We demonstrate performance improvements for Chinese-English and Urdu-English translation over a phrase-based base-line.", "labels": [], "entities": [{"text": "Urdu-English translation", "start_pos": 64, "end_pos": 88, "type": "TASK", "confidence": 0.721333920955658}]}, {"text": "We also investigate the use of unsuper-vised dependency parsers, reporting encouraging preliminary results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Two approaches currently dominate statistical machine translation (MT) research.", "labels": [], "entities": [{"text": "statistical machine translation (MT)", "start_pos": 34, "end_pos": 70, "type": "TASK", "confidence": 0.8248008638620377}]}, {"text": "Phrase-based models () excel at capturing local reordering phenomena and memorizing multi-word translations.", "labels": [], "entities": []}, {"text": "Models that employ syntax or syntaxlike representations;) handle long-distance reordering better than phrase-based systems () but often require constraints on the formalism or rule extraction method in order to achieve computational tractability.", "labels": [], "entities": [{"text": "rule extraction", "start_pos": 176, "end_pos": 191, "type": "TASK", "confidence": 0.734003871679306}]}, {"text": "As a result, certain instances of syntactic divergence are more naturally handled by phrase-based systems.", "labels": [], "entities": [{"text": "syntactic divergence", "start_pos": 34, "end_pos": 54, "type": "TASK", "confidence": 0.7319818437099457}]}, {"text": "In this paper we present anew way of combining the advantages of phrase-based and syntax-based MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 95, "end_pos": 97, "type": "TASK", "confidence": 0.8329609632492065}]}, {"text": "We propose a model in which phrases are organized into a tree structure inspired by dependency syntax.", "labels": [], "entities": []}, {"text": "Instead of standard dependency trees in which words are vertices, our trees have phrases as vertices.", "labels": [], "entities": []}, {"text": "We describe a simple heuristic to extract phrase dependencies from an aligned parallel corpus parsed on the target side, and use them to compute target-side tree features.", "labels": [], "entities": []}, {"text": "We define additional string-to-tree features and, if a source-side dependency parser is available, tree-to-tree features to capture properties of how phrase dependencies interact with reordering.", "labels": [], "entities": []}, {"text": "To leverage standard phrase-based features alongside our novel features, we require a formalism that supports flexible feature combination and efficient decoding.", "labels": [], "entities": []}, {"text": "Quasi-synchronous grammar (QG) provides this backbone (); we describe a coarse-to-fine approach for decoding within this framework, advancing substantially over earlier QG machine translation systems.", "labels": [], "entities": [{"text": "Quasi-synchronous grammar (QG)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.652208811044693}, {"text": "QG machine translation", "start_pos": 169, "end_pos": 191, "type": "TASK", "confidence": 0.52580925822258}]}, {"text": "The decoder involves generating a phrase lattice () in a coarse pass using a phrase-based model, followed by lattice dependency parsing of the phrase lattice.", "labels": [], "entities": []}, {"text": "This approach allows us to feasibly explore the combined search space of segmentations, phrase alignments, and target phrase dependency trees.", "labels": [], "entities": [{"text": "phrase alignments", "start_pos": 88, "end_pos": 105, "type": "TASK", "confidence": 0.7011484950780869}]}, {"text": "Our experiments demonstrate an average improvement of +0.65 BLEU in Chinese-English translation across three test sets and an improvement of +0.75 BLEU in Urdu-English translation over a phrase-based baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.9942740797996521}, {"text": "BLEU", "start_pos": 147, "end_pos": 151, "type": "METRIC", "confidence": 0.9965529441833496}]}, {"text": "We also describe experiments in which we replace supervised dependency parsers with unsupervised parsers, reporting promising results: using a supervised Chinese parser and a state-of-the-art unsupervised English parser provides our best results, giving an averaged gain of +0.79 BLEU over the baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 280, "end_pos": 284, "type": "METRIC", "confidence": 0.9990181922912598}]}, {"text": "We also discuss how our model improves translation quality and discuss future possibilities for combining approaches to ma-chine translation using our framework.", "labels": [], "entities": [{"text": "ma-chine translation", "start_pos": 120, "end_pos": 140, "type": "TASK", "confidence": 0.7199324071407318}]}], "datasetContent": [{"text": "For experimental evaluation, we consider Chineseto-English (ZH-EN) and Urdu-to-English (UR-EN) translation and compare our system to Moses ().", "labels": [], "entities": []}, {"text": "For ZH-EN, we used 303k sentence pairs from the FBIS corpus (LDC2003E14).", "labels": [], "entities": [{"text": "FBIS corpus", "start_pos": 48, "end_pos": 59, "type": "DATASET", "confidence": 0.9542409479618073}]}, {"text": "We segmented the Chinese data using the Stanford Chinese segmenter in \"CTB\" mode (), giving us 7.9M Chinese words and 9.4M English words.", "labels": [], "entities": []}, {"text": "For UR-EN, we used parallel data from the NIST MT08 evaluation consisting of 1.2M Urdu words and 1.1M English words.", "labels": [], "entities": [{"text": "NIST MT08 evaluation", "start_pos": 42, "end_pos": 62, "type": "DATASET", "confidence": 0.9063562949498495}]}, {"text": "We trained a baseline Moses system using default settings and features.", "labels": [], "entities": []}, {"text": "Word alignment was performed using GIZA++) in both directions and the grow-diag-final-and heuristic was used to symmetrize the alignments.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.6422843635082245}]}, {"text": "We used a max phrase length of 7 when extracting phrases.", "labels": [], "entities": []}, {"text": "Trigram language models were estimated using the SRI language modeling toolkit) with modified Kneser-Ney smoothing).", "labels": [], "entities": [{"text": "SRI language modeling", "start_pos": 49, "end_pos": 70, "type": "TASK", "confidence": 0.6231759985287985}]}, {"text": "To estimate language models for each language pair, we used the English side of the parallel corpus concatenated with 200M words of randomly-selected sentences from the Gigaword v4 corpus (excluding the NY Times and LA Times).", "labels": [], "entities": [{"text": "Gigaword v4 corpus (excluding the NY Times and LA Times", "start_pos": 169, "end_pos": 224, "type": "DATASET", "confidence": 0.7831500389359214}]}, {"text": "We used this baseline Moses system to generate phrase lattices for our system, so our model includes all of the Moses features in addition to the  QPDG features described in \u00a74.", "labels": [], "entities": []}, {"text": "In our experiments, we compare our QPDG system (lattice parsing on each lattice) to the Moses baseline (finding the best path through each lattice).", "labels": [], "entities": []}, {"text": "The conventional wisdom holds that hierarchical phrase-based translation () performs better than phrasebased translation for language pairs that require large amounts of reordering, such as ZH-EN and UR-EN.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 48, "end_pos": 72, "type": "TASK", "confidence": 0.6885994225740433}, {"text": "phrasebased translation", "start_pos": 97, "end_pos": 120, "type": "TASK", "confidence": 0.6987628489732742}]}, {"text": "However, researchers have shown that this performance gap diminishes when using a larger distortion limit () and may disappear entirely when using a lexicalized reordering model.", "labels": [], "entities": []}, {"text": "So, we increase the Moses distortion limit from 6 (the default) to 10 and use Moses' default lexicalized reordering model ().", "labels": [], "entities": []}, {"text": "We parsed the Chinese text using the Stanford parser ( and the English text using TurboParser ().", "labels": [], "entities": []}, {"text": "We note that computing our features requires parsing the target (English) side of the parallel text, but not the source side.", "labels": [], "entities": []}, {"text": "We only need to parse the source side of the tuning and test sets, and the only features that look at the source-side parse are those from \u00a74.3.", "labels": [], "entities": []}, {"text": "To obtain Brown clusters for the target tree features in \u00a74.1, we used code from.", "labels": [], "entities": []}, {"text": "We induced 100 clusters from the English side of the parallel corpus concatenated with 10M words of randomly-selected Gigaword sentences.", "labels": [], "entities": []}, {"text": "Only words that appeared at least twice in this data were considered during clustering.", "labels": [], "entities": []}, {"text": "An additional cluster was created for all other words; this allowed us to use phrase dependency cluster features even for out-ofvocabulary words.", "labels": [], "entities": []}, {"text": "We used a max phrase length of 7 when extracting phrase dependencies to match the max phrase length used in phrase extraction.", "labels": [], "entities": [{"text": "max phrase length", "start_pos": 10, "end_pos": 27, "type": "METRIC", "confidence": 0.7129517396291097}, {"text": "phrase extraction", "start_pos": 108, "end_pos": 125, "type": "TASK", "confidence": 0.7990682721138}]}, {"text": "Approximately 87M unique phrase dependencies were extracted from the ZH-EN data and 7M from the UR-EN data.", "labels": [], "entities": [{"text": "ZH-EN data", "start_pos": 69, "end_pos": 79, "type": "DATASET", "confidence": 0.8072854578495026}, {"text": "UR-EN data", "start_pos": 96, "end_pos": 106, "type": "DATASET", "confidence": 0.8095618784427643}]}, {"text": "We tuned the weights of our model using the pro-  cedure described in \u00a76.", "labels": [], "entities": []}, {"text": "For ZH-EN we used MT03 for tuning and MT02, MT05, and MT06 for testing.", "labels": [], "entities": [{"text": "ZH-EN", "start_pos": 4, "end_pos": 9, "type": "DATASET", "confidence": 0.9193474650382996}, {"text": "MT03", "start_pos": 18, "end_pos": 22, "type": "DATASET", "confidence": 0.8269835710525513}, {"text": "MT02", "start_pos": 38, "end_pos": 42, "type": "DATASET", "confidence": 0.8653317093849182}, {"text": "MT05", "start_pos": 44, "end_pos": 48, "type": "DATASET", "confidence": 0.8149750232696533}, {"text": "MT06", "start_pos": 54, "end_pos": 58, "type": "DATASET", "confidence": 0.8750766515731812}]}, {"text": "For UR-EN we used half of the documents (882 sentence pairs) from the MT08 test set for tuning (\"Dev\") and MT09 for testing.", "labels": [], "entities": [{"text": "MT08 test set", "start_pos": 70, "end_pos": 83, "type": "DATASET", "confidence": 0.9466477831204733}, {"text": "MT09", "start_pos": 107, "end_pos": 111, "type": "DATASET", "confidence": 0.9242896437644958}]}, {"text": "We evaluated translation output using case-insensitive IBM BLEU).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.8914041519165039}]}], "tableCaptions": [{"text": " Table 3: Most probable child phrases for the parent  phrase \"made up\" for each direction, sorted by the con- ditional probability of the child phrase given the parent  phrase and direction.", "labels": [], "entities": []}, {"text": " Table 4: Chinese-English Results (% BLEU).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.999032735824585}]}, {"text": " Table 5: Urdu-English Results (% BLEU).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 34, "end_pos": 38, "type": "METRIC", "confidence": 0.9990590214729309}]}, {"text": " Table 6: Results when using unsupervised dependency  parsers. Cells contain averaged % BLEU on the three test  sets and % BLEU on tuning data (MT03) in parentheses.  Feature  Initial Learned  Left child, same order  9.0  8.9  Left child, swap phrases  1.1  0.0  Right child, same order  7.3  7.3  Right child, swap phrases  1.6  2.3  Root-root  0.4  0.8  Parent-child  4.2  6.1  Child-parent  1.2  0.4  Grandparent-grandchild  1.0  0.2  Sibling  2.4  1.9  C-command  6.1  6.7  Other  1.5  0.9", "labels": [], "entities": [{"text": "BLEU", "start_pos": 88, "end_pos": 92, "type": "METRIC", "confidence": 0.9971440434455872}, {"text": "BLEU", "start_pos": 123, "end_pos": 127, "type": "METRIC", "confidence": 0.9966416358947754}, {"text": "MT03", "start_pos": 144, "end_pos": 148, "type": "DATASET", "confidence": 0.6780591011047363}]}, {"text": " Table 7: Average feature values across best translations  of sentences in the MT03 tuning set, both before MERT  (column 2) and after (column 3). \"Same\" versions of tree- to-tree configuration features are shown; the rarer \"swap\"  features showed a similar trend.", "labels": [], "entities": [{"text": "MT03 tuning set", "start_pos": 79, "end_pos": 94, "type": "DATASET", "confidence": 0.8746987183888754}, {"text": "MERT", "start_pos": 108, "end_pos": 112, "type": "METRIC", "confidence": 0.8046594858169556}]}]}