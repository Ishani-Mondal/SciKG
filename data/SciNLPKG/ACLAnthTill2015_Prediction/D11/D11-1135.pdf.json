{"title": [{"text": "Structured Relation Discovery using Generative Models", "labels": [], "entities": [{"text": "Structured Relation Discovery", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.9141192436218262}]}], "abstractContent": [{"text": "We explore unsupervised approaches to relation extraction between two named entities; for instance, the semantic bornIn relation between a person and location entity.", "labels": [], "entities": [{"text": "relation extraction between two named entities", "start_pos": 38, "end_pos": 84, "type": "TASK", "confidence": 0.8367193539937338}]}, {"text": "Concretely , we propose a series of generative probabilistic models, broadly similar to topic models, each which generates a corpus of observed triples of entity mention pairs and the surface syntactic dependency path between them.", "labels": [], "entities": []}, {"text": "The output of each model is a clustering of observed relation tuples and their associated textual expressions to underlying semantic relation types.", "labels": [], "entities": []}, {"text": "Our proposed models exploit entity type constraints within a relation as well as features on the dependency path between entity mentions.", "labels": [], "entities": []}, {"text": "We examine effectiveness of our approach via multiple evaluations and demonstrate 12% error reduction in precision over a state-of-the-art weakly supervised baseline.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 86, "end_pos": 101, "type": "METRIC", "confidence": 0.9683839380741119}, {"text": "precision", "start_pos": 105, "end_pos": 114, "type": "METRIC", "confidence": 0.9710938930511475}]}], "introductionContent": [{"text": "Many NLP applications would benefit from large knowledge bases of relational information about entities.", "labels": [], "entities": []}, {"text": "For instance, knowing that the entity Steve Balmer bears the leaderOf relation to the entity Microsoft, would facilitate question answering (), data mining, and a host of other end-user applications.", "labels": [], "entities": [{"text": "question answering", "start_pos": 121, "end_pos": 139, "type": "TASK", "confidence": 0.8929327428340912}, {"text": "data mining", "start_pos": 144, "end_pos": 155, "type": "TASK", "confidence": 0.8564471006393433}]}, {"text": "Due to these many potential applications, relation extraction has gained much attention in information extraction).", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 42, "end_pos": 61, "type": "TASK", "confidence": 0.9602155983448029}, {"text": "information extraction", "start_pos": 91, "end_pos": 113, "type": "TASK", "confidence": 0.9085931777954102}]}, {"text": "We propose a series of generative probabilistic models, broadly similar to standard topic models, which generate a corpus of observed triples of entity mention pairs and the surface syntactic dependency path between them.", "labels": [], "entities": []}, {"text": "Our proposed models exploit entity type constraints within a relation as well as features on the dependency path between entity mentions.", "labels": [], "entities": []}, {"text": "The output of our approach is a clustering over observed relation paths (e.g. \"X was born in Y\" and \"X is from Y\") such that expressions in the same cluster bear the same semantic relation type between entities.", "labels": [], "entities": []}, {"text": "Past work has shown that standard supervised techniques can yield high-performance relation detection when abundant labeled data exists fora fixed inventory of individual relation types (e.g. leaderOf )).", "labels": [], "entities": [{"text": "relation detection", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.8759153187274933}]}, {"text": "However, less explored are open-domain approaches where the set of possible relation types are not fixed and little to no labeled is given for each relation type (.", "labels": [], "entities": []}, {"text": "A more related line of research has explored inducing relation types via clustering.", "labels": [], "entities": []}, {"text": "For example, DIRT) aims to discover different representations of the same semantic relation using distributional similarity of dependency paths.", "labels": [], "entities": []}, {"text": "present an Unsupervised semantic parsing (USP) approach to partition dependency trees into meaningful fragments (or \"parts\" to use their terminology).", "labels": [], "entities": [{"text": "Unsupervised semantic parsing (USP)", "start_pos": 11, "end_pos": 46, "type": "TASK", "confidence": 0.7688921143611273}]}, {"text": "The combinatorial nature of this dependency partition model makes it difficult for USP to scale to large data sets despite several necessary approximations during learning and infer-1456 ence.", "labels": [], "entities": [{"text": "USP", "start_pos": 83, "end_pos": 86, "type": "DATASET", "confidence": 0.6384226679801941}]}, {"text": "Our work is similar to DIRT and USP in that we induce relation types from observed dependency paths, but our approach is a straightforward and principled generative model which can be efficiently learned.", "labels": [], "entities": [{"text": "USP", "start_pos": 32, "end_pos": 35, "type": "DATASET", "confidence": 0.7571990489959717}]}, {"text": "As we show empirically, our approach outperforms these related works when trained with the same amount of data and further gains are observed when trained with more data.", "labels": [], "entities": []}, {"text": "We evaluate our approach using 'intrinsic' clustering evaluation and 'extrinsic' evaluation settings.", "labels": [], "entities": []}, {"text": "The former evaluation is performed using subset of induced clusters against Freebase relations, a large manually-built entity and relational database.", "labels": [], "entities": []}, {"text": "We also show some clusters which are not included as Freebase relations, as well as some entity clusters found by our approach.", "labels": [], "entities": []}, {"text": "The latter evaluation uses the clustering induced by our models as features for relation extraction in distant supervision framework.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.8227618932723999}]}, {"text": "Empirical results show that we can find coherent clusters.", "labels": [], "entities": []}, {"text": "In relation extraction, we can achieve 12% error reduction in precision over a state-of-the-art weakly supervised baseline and we show that using features from our proposed models can find more facts fora relation without significant accuracy loss.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 3, "end_pos": 22, "type": "TASK", "confidence": 0.914682149887085}, {"text": "error reduction", "start_pos": 43, "end_pos": 58, "type": "METRIC", "confidence": 0.9538785815238953}, {"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9563852548599243}, {"text": "accuracy", "start_pos": 234, "end_pos": 242, "type": "METRIC", "confidence": 0.9970229268074036}]}], "datasetContent": [{"text": "The task of relation extraction is mapping surface textual relations to underlying semantic relations.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.8586688339710236}]}, {"text": "For instance, the textual expression \"X was born in Y\" indicates a semantic relation bornIn between entities \"X\" and \"Y\".", "labels": [], "entities": []}, {"text": "This relation can be expressed textually in several ways: for instance, \"X, a native of Y\" or \"X grew up in Y\".", "labels": [], "entities": []}, {"text": "There are several components to a coherent relation type, including a tight small number of textual expressions as well as constraints on the entities involved in the relation.", "labels": [], "entities": []}, {"text": "For instance, in the bornIn relation \"X\" must be a person entity and \"Y\" a location (typically a city or nation).", "labels": [], "entities": []}, {"text": "In this work, we present an unsupervised probabilistic generative model for inducing clusters of relation types and recognizing their textual expressions.", "labels": [], "entities": []}, {"text": "The set of relation types is not pre-specified but induced from observed unlabeled data.", "labels": [], "entities": []}, {"text": "See for examples of learned semantic relations.", "labels": [], "entities": []}, {"text": "Our observed data consists of a corpus of documents and each document is represented by a bag See Section 4 fora fuller discussion of evaluation. of relation tuples.", "labels": [], "entities": []}, {"text": "Each tuple represents an observed syntactic relationship between two Named Entities (NE) and consists of three components: the dependency path between two NE mentions, the source argument NE, and the destination argument NE.", "labels": [], "entities": []}, {"text": "A dependency path is a concatenation of dependency relations (edges) and words (nodes) along a path in a dependency tree.", "labels": [], "entities": []}, {"text": "For instance, the sentence \"John Lennnon was born in Liverpool\" would yield the relation tuple (Lennon, [\u2191 \u2212nsubjpass, born, \u2193 \u2212in], Liverpool).", "labels": [], "entities": [{"text": "John Lennnon was born in Liverpool", "start_pos": 28, "end_pos": 62, "type": "DATASET", "confidence": 0.8587010006109873}]}, {"text": "This relation tuple reflects a semantic bornIn relation between the John Lennon and Liverpool entities.", "labels": [], "entities": []}, {"text": "The dependency path in this example corresponds to the \"X was born in Y\" textual expression given earlier.", "labels": [], "entities": []}, {"text": "Note that for the above example, the bornIn relation can only occur between a person and a location.", "labels": [], "entities": []}, {"text": "The relation tuple is the primary observed random variable in our model and we construct our models (see Section 3) so that clusters consist of textual expressions representing the same underlying relation type.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Clustering quality evaluation (%), Rec. is mea- sured against Freebase, Prec. is measured according to  human annotators", "labels": [], "entities": [{"text": "Rec.", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.6179617047309875}, {"text": "Prec.", "start_pos": 82, "end_pos": 87, "type": "METRIC", "confidence": 0.7655170559883118}]}, {"text": " Table 6: Precision (%) of some frequent relations", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9975855350494385}]}, {"text": " Table 7: Manual evaluation, Precision and recall of some frequent relations", "labels": [], "entities": [{"text": "Precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9978712797164917}, {"text": "recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.9986698627471924}]}]}