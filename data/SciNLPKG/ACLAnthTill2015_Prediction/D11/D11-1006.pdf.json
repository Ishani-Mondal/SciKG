{"title": [{"text": "Multi-Source Transfer of Delexicalized Dependency Parsers", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a simple method for transferring dependency parsers from source languages with labeled training data to target languages without labeled training data.", "labels": [], "entities": []}, {"text": "We first demonstrate that delexicalized parsers can be directly transferred between languages, producing significantly higher accuracies than unsu-pervised parsers.", "labels": [], "entities": []}, {"text": "We then use a constraint driven learning algorithm where constraints are drawn from parallel corpora to project the final parser.", "labels": [], "entities": []}, {"text": "Unlike previous work on projecting syntactic resources, we show that simple methods for introducing multiple source languages can significantly improve the overall quality of the resulting parsers.", "labels": [], "entities": []}, {"text": "The projected parsers from our system result in state-of-the-art performance when compared to previously studied unsupervised and projected parsing systems across eight different languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical parsing has been one of the most active areas of research in the computational linguistics community since the construction of the Penn Treebank (.", "labels": [], "entities": [{"text": "Statistical parsing", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9230372905731201}, {"text": "Penn Treebank", "start_pos": 143, "end_pos": 156, "type": "DATASET", "confidence": 0.9937965869903564}]}, {"text": "This includes work on phrasestructure parsing), dependency parsing () as well as a number of other formalisms.", "labels": [], "entities": [{"text": "phrasestructure parsing", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.8333178162574768}, {"text": "dependency parsing", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.8636995255947113}]}, {"text": "As underlying modeling techniques have improved, these parsers have begun to converge to high levels of accuracy for English newswire text.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9979885816574097}]}, {"text": "Subsequently, researchers have begun to look at both porting these parsers to new domains) and constructing parsers for new languages.", "labels": [], "entities": []}, {"text": "One major obstacle in building statistical parsers for new languages is that they often lack the manually annotated resources available for English.", "labels": [], "entities": []}, {"text": "This observation has led to avast amount of research on unsupervised grammar induction.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 69, "end_pos": 86, "type": "TASK", "confidence": 0.6968429088592529}]}, {"text": "Grammar induction systems have seen large advances in quality, but parsing accuracies still significantly lag behind those of supervised systems.", "labels": [], "entities": []}, {"text": "Furthermore, they are often trained and evaluated under idealized conditions, e.g., only on short sentences or assuming the existence of gold-standard part-ofspeech (POS) tags.", "labels": [], "entities": []}, {"text": "The reason for these assumptions is clear.", "labels": [], "entities": []}, {"text": "Unsupervised grammar induction is difficult given the complexity of the analysis space.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.7635655403137207}]}, {"text": "These assumptions help to give the model traction.", "labels": [], "entities": []}, {"text": "The study of unsupervised grammar induction has many merits.", "labels": [], "entities": [{"text": "unsupervised grammar induction", "start_pos": 13, "end_pos": 43, "type": "TASK", "confidence": 0.6911578277746836}]}, {"text": "Most notably, it increases our understanding of how computers (and possibly humans) learn in the absence of any explicit feedback.", "labels": [], "entities": []}, {"text": "However, the gold POS tag assumption weakens any conclusions that can be drawn, as part-of-speech are also a form of syntactic analysis, only shallower.", "labels": [], "entities": []}, {"text": "Furthermore, from a practical standpoint, it is rarely the case that we are completely devoid of resources for most languages.", "labels": [], "entities": []}, {"text": "This point has been made by studies that transfer parsers to new languages by projecting syntax across word alignments extracted from parallel corpora (.", "labels": [], "entities": []}, {"text": "Although again, most of these studies also assume the existence of POS tags.", "labels": [], "entities": []}, {"text": "In this work we present a method for creating dependency parsers for languages for which no labeled training data is available.", "labels": [], "entities": []}, {"text": "First, we train a source side English parser that, crucially, is delexicalized so that its predictions rely soley on the part-of-speech tags of the input sentence, in the same vein as.", "labels": [], "entities": []}, {"text": "We empirically show that directly transferring delexicalized models (i.e. parsing a foreign language POS sequence with an English parser) already outperforms state-of-the-art unsupervised parsers by a significant margin.", "labels": [], "entities": []}, {"text": "This result holds in the presence of both gold POS tags as well as automatic tags projected from English.", "labels": [], "entities": []}, {"text": "This emphasizes that even for languages with no syntactic resources -or possibly even parallel data -simple transfer methods can already be more powerful than grammar induction systems.", "labels": [], "entities": []}, {"text": "Next, we use this delexicalized English parser to seed a perceptron learner for the target language.", "labels": [], "entities": []}, {"text": "The model is trained to update towards parses that are in high agreement with a source side English parse based on constraints drawn from alignments in the parallel data.", "labels": [], "entities": []}, {"text": "We use the augmented-loss learning procedure) which is closely related to constraint driven learning (.", "labels": [], "entities": []}, {"text": "The resulting parser consistently improves on the directly transferred delexicalized parser, reducing relative errors by 8% on average, and as much as 18% on some languages.", "labels": [], "entities": [{"text": "errors", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.5552482604980469}]}, {"text": "Finally, we show that by transferring parsers from multiple source languages we can further reduce errors by 16% over the directly transferred English baseline.", "labels": [], "entities": [{"text": "errors", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9786883592605591}]}, {"text": "This is consistent with previous work on multilingual part-of-speech) and grammar) induction, that shows that adding languages leads to improvements.", "labels": [], "entities": [{"text": "multilingual part-of-speech) and grammar) induction", "start_pos": 41, "end_pos": 92, "type": "TASK", "confidence": 0.6295791140624455}]}, {"text": "We present a comprehensive set of experiments on eight Indo-European languages for which a significant amount of parallel data exists.", "labels": [], "entities": []}, {"text": "We make no language specific enhancements in our experiments.", "labels": [], "entities": []}, {"text": "We report results for sentences of all lengths, as well as with gold and automatically induced part-of-speech tags.", "labels": [], "entities": []}, {"text": "We also report results on sentences of length 10 or less with gold part-of-speech tags to compare with previous work.", "labels": [], "entities": []}, {"text": "Our results consistently outperform the previous state-of-the-art across all languages and training configurations.", "labels": [], "entities": []}], "datasetContent": [{"text": "All systems are evaluated using unlabeled attachment score (UAS), which is the percentage of words (ignoring punctuation tokens) in a corpus that modify the correct head ().", "labels": [], "entities": [{"text": "unlabeled attachment score (UAS)", "start_pos": 32, "end_pos": 64, "type": "METRIC", "confidence": 0.795538862546285}]}, {"text": "Furthermore, we evaluate with both gold-standard part-of-speech tags, as well as predicted part-ofspeech tags from the projected part-of-speech tagger of . This tagger relies only on labeled training data for English, and achieves accuracies around 85% on the languages that we consider.", "labels": [], "entities": []}, {"text": "We evaluate in the former setting to compare to previous studies that make this assumption.", "labels": [], "entities": []}, {"text": "We evaluate in the latter setting to measure performance in a more realistic scenario -when no target language resources are available.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: UAS for the unsupervised DMV model (DMV),  a delexicalized English direct transfer parser (en-dir.)  and a English projected parser (en-proj.). Measured on  all sentence lengths for both gold and predicted part-of- speech tags as input.", "labels": [], "entities": [{"text": "UAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.6775286197662354}]}, {"text": " Table 2: UAS for all source-target language pairs. Each column represents which source language was used to train a  delexicalized parser and each row represents which target language test data was used. Bold numbers are when source  equals target and underlined numbers are the single best UAS for a target language. Results are for all sentence lengths  without punctuation.", "labels": [], "entities": []}, {"text": " Table 3: UAS for multi-source direct (multi-dir.) and projected (multi-proj.) transfer systems. best-source is the best  source model from the languages in", "labels": [], "entities": [{"text": "UAS", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.6900317072868347}]}, {"text": " Table 4: UAS on sentences of length 10 or less without punctuation, comparing the systems presented in this work  to three representative systems from related work. en-dir./en-proj. are the direct/projected English parsers and multi- dir./multi-proj. are the multi-source direct/projected parsers. Section 5 contains a description of the baseline systems.", "labels": [], "entities": [{"text": "UAS", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.8259952664375305}]}]}