{"title": [{"text": "Random Walk Inference and Learning in A Large Scale Knowledge Base", "labels": [], "entities": [{"text": "Random Walk Inference", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.6147714654604594}]}], "abstractContent": [{"text": "We consider the problem of performing learning and inference in a large scale knowledge base containing imperfect knowledge with incomplete coverage.", "labels": [], "entities": []}, {"text": "We show that a soft inference procedure based on a combination of constrained, weighted, random walks through the knowledge base graph can be used to reliably infer new beliefs for the knowledge base.", "labels": [], "entities": []}, {"text": "More specifically, we show that the system can learn to infer different target relations by tuning the weights associated with random walks that follow different paths through the graph, using aversion of the Path Ranking Algorithm (Lao and Cohen, 2010b).", "labels": [], "entities": []}, {"text": "We apply this approach to a knowledge base of approximately 500,000 beliefs extracted imperfectly from the web by NELL, a never-ending language learner (Carlson et al., 2010).", "labels": [], "entities": []}, {"text": "This new system improves significantly over NELL's earlier Horn-clause learning and inference method: it obtains nearly double the precision at rank 100, and the new learning method is also applicable to many more inference tasks.", "labels": [], "entities": [{"text": "precision", "start_pos": 131, "end_pos": 140, "type": "METRIC", "confidence": 0.9992156028747559}]}], "introductionContent": [{"text": "Although there is a great deal of recent research on extracting knowledge from text;, much less progress has been made on the problem of drawing reliable inferences from this imperfectly extracted knowledge.", "labels": [], "entities": []}, {"text": "In particular, traditional logical inference methods are too brittle to be used to make complex inferences from automatically-extracted knowledge, and probabilistic inference methods () suffer from scalability problems.", "labels": [], "entities": []}, {"text": "This paper considers the problem of constructing inference methods that can scale to large knowledge bases (KB's), and that are robust to imperfect knowledge.", "labels": [], "entities": []}, {"text": "The KB we consider is a large triple store, which can be represented as a labeled, directed graph in which each entity a is anode, each binary relation R(a, b) is an edge labeled R between a and b, and unary concepts C(a) are represented as an edge labeled \"isa\" between the node for the entity a and anode for the concept C.", "labels": [], "entities": []}, {"text": "We present a trainable inference method that learns to infer relations by combining the results of different random walks through this graph, and show that the method achieves good scaling properties and robust inference in a KB containing over 500,000 triples extracted from the web by the NELL system ().", "labels": [], "entities": []}], "datasetContent": [{"text": "The cross-validation result above assumes that the knowledge base is complete and correct, which we know to be untrue.", "labels": [], "entities": []}, {"text": "To accurately compare PRA and N-FOIL's ability to reliably infer new beliefs from an imperfect knowledge base, we use human assessments obtained from Amazon Mechanical Turk.", "labels": [], "entities": [{"text": "PRA", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9183828234672546}, {"text": "Amazon Mechanical Turk", "start_pos": 150, "end_pos": 172, "type": "DATASET", "confidence": 0.9595169623692831}]}, {"text": "To limit labeling costs, and since our goal is to improve the performance of NELL, we do not include RWR-based approaches in this comparison.", "labels": [], "entities": [{"text": "NELL", "start_pos": 77, "end_pos": 81, "type": "TASK", "confidence": 0.8711604475975037}]}, {"text": "Among all the 24 functional predicates, N-FOIL discovers confident rules for 8 of them (it produces no result for the other 16 predicates).", "labels": [], "entities": []}, {"text": "Therefore, we compare the quality of PRA to N-FOIL on these 8 predicates only.", "labels": [], "entities": [{"text": "PRA", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.8343064188957214}]}, {"text": "Among all the 72 non-functional predicates-which 535", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Number of paths in PRA models of maximum  path length 3 and 4. Averaged over 96 tasks.  =3  =4  all paths up to length L  15, 376 1, 906, 624  +query support\u2265 \u03b1 = 0.01  522  5016  +ever reach a target entity  136  792  +L 1 regularization  63  271", "labels": [], "entities": []}, {"text": " Table 2: Comparing PRA with RWR models. MRRs and  training times are averaged over 96 tasks.  =2  =3  MRR Time MRR Time  RWR(no train) 0.271  0.456  RWR  0.280  3.7s 0.471  9.2s  PRA  0.307  5.7s 0.516 15.4s", "labels": [], "entities": [{"text": "PRA", "start_pos": 20, "end_pos": 23, "type": "TASK", "confidence": 0.9755211472511292}, {"text": "MRRs", "start_pos": 41, "end_pos": 45, "type": "TASK", "confidence": 0.5633691549301147}, {"text": "MRR Time MRR Time", "start_pos": 103, "end_pos": 120, "type": "METRIC", "confidence": 0.6478296369314194}, {"text": "RWR(no train) 0.271  0.456  RWR  0.280  3.7s 0.471  9.2s  PRA  0.307  5.7s 0.516 15.4s", "start_pos": 122, "end_pos": 208, "type": "DATASET", "confidence": 0.6401073161293479}]}, {"text": " Table 5: Comparing Mechanical Turk workers' voted  assessments with our gold standard labels based on 100  samples.  AMT=F AMT=T  Gold=F  25%  15%  Gold=T  11%  49%", "labels": [], "entities": [{"text": "AMT=F AMT=T  Gold=F", "start_pos": 118, "end_pos": 137, "type": "METRIC", "confidence": 0.7755683726734586}]}]}