{"title": [{"text": "Learning to Simplify Sentences with Quasi-Synchronous Grammar and Integer Programming", "labels": [], "entities": []}], "abstractContent": [{"text": "Text simplification aims to rewrite text into simpler versions, and thus make information accessible to a broader audience.", "labels": [], "entities": [{"text": "Text simplification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.818137526512146}]}, {"text": "Most previous work simplifies sentences using hand-crafted rules aimed at splitting long sentences, or substitutes difficult words using a prede-fined dictionary.", "labels": [], "entities": []}, {"text": "This paper presents a data-driven model based on quasi-synchronous grammar, a formalism that can naturally capture structural mismatches and complex rewrite operations.", "labels": [], "entities": []}, {"text": "We describe how such a grammar can be induced from Wikipedia and propose an integer linear programming model for selecting the most appropriate simplification from the space of possible rewrites generated by the grammar.", "labels": [], "entities": []}, {"text": "We show experimentally that our method creates simplifications that significantly reduce the reading difficulty of the input, while maintaining grammaticality and preserving its meaning.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentence simplification is perhaps one of the oldest text rewriting problems.", "labels": [], "entities": [{"text": "Sentence simplification", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9565100073814392}, {"text": "text rewriting", "start_pos": 53, "end_pos": 67, "type": "TASK", "confidence": 0.7711993753910065}]}, {"text": "Given a source sentence, the goal is to create a grammatical target that is easier to read with simpler vocabulary and syntactic structure.", "labels": [], "entities": []}, {"text": "An example is shown in involving abroad spectrum of rewrite operations such as deletion, substitution, insertion, and reordering.", "labels": [], "entities": []}, {"text": "The popularity of the simplification task stems from its potential relevance to various applications.", "labels": [], "entities": [{"text": "simplification task", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.9148481786251068}]}, {"text": "Examples include the development of reading aids for people with aphasia (), non-native Also contributing to the firmness in copper, the analyst noted, was a report by Chicago purchasing agents, which precedes the full purchasing agents report that is due out today and gives an indication of what the full report might hold.", "labels": [], "entities": []}, {"text": "Also contributing to the firmness in copper, the analyst noted, was a report by Chicago purchasing agents.", "labels": [], "entities": []}, {"text": "The Chicago report precedes the full purchasing agents report.", "labels": [], "entities": [{"text": "Chicago report", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.9280399680137634}]}, {"text": "The Chicago report gives an indication of what the full report might hold.", "labels": [], "entities": [{"text": "Chicago report", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.9728716313838959}]}, {"text": "The full report is due out today.: Example of a source sentence (top) and its simplification (bottom).", "labels": [], "entities": []}, {"text": "speakers and more generally individuals with low literacy (.", "labels": [], "entities": []}, {"text": "A simplification component could be also used as a preprocessing step to improve the performance of parsers (, summarizers) and semantic role labelers.", "labels": [], "entities": [{"text": "semantic role labelers", "start_pos": 128, "end_pos": 150, "type": "TASK", "confidence": 0.5847435593605042}]}, {"text": "Simplification is related to, but different from paraphrase extraction.", "labels": [], "entities": [{"text": "paraphrase extraction", "start_pos": 49, "end_pos": 70, "type": "TASK", "confidence": 0.840193122625351}]}, {"text": "We must not only have access to paraphrases (i.e., rewrite rules), but also be able to combine them to generate new text, in a simpler language.", "labels": [], "entities": []}, {"text": "The task is also distinct from sentence compression as it aims to render a sentence more accessible while preserving its meaning.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.7282763421535492}]}, {"text": "On the contrary, compression unavoidably leads to some information loss as it creates shorter sentences without necessarily reducing complexity.", "labels": [], "entities": []}, {"text": "In fact, one of the commonest simplification operations is sentence splitting which usually produces longer rather than shorter output!", "labels": [], "entities": [{"text": "sentence splitting", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.7996291816234589}]}, {"text": "Moreover, mod-els developed for sentence compression have been mostly designed with one rewrite operation in mind, namely word deletion, and are thus unable to model consistent syntactic effects such as reordering, sentence splitting, changes in non-terminal categories, and lexical substitution (but see for notable exceptions).", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.7613666653633118}, {"text": "word deletion", "start_pos": 122, "end_pos": 135, "type": "TASK", "confidence": 0.6726154386997223}, {"text": "sentence splitting", "start_pos": 215, "end_pos": 233, "type": "TASK", "confidence": 0.7402070164680481}, {"text": "lexical substitution", "start_pos": 275, "end_pos": 295, "type": "TASK", "confidence": 0.7454933524131775}]}, {"text": "In this paper we propose a sentence simplification model that is able to handle structural mismatches and complex rewriting operations.", "labels": [], "entities": [{"text": "sentence simplification", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.7545651197433472}]}, {"text": "Our approach is based on quasi-synchronous grammar), a formalism that is well suited for text rewriting.", "labels": [], "entities": [{"text": "text rewriting", "start_pos": 89, "end_pos": 103, "type": "TASK", "confidence": 0.7787653803825378}]}, {"text": "Rather than postulating a strictly synchronous structure over the source and target sentences, QG identifies a \"sloppy\" alignment of parse trees assuming that the target tree is in someway \"inspired by\" the source tree.", "labels": [], "entities": []}, {"text": "Specifically, our model is formulated as an integer linear program and uses QG to capture the space of all possible rewrites.", "labels": [], "entities": []}, {"text": "Given a source tree, it finds the best target tree licensed by the grammar subject to constraints such as sentence length and reading ease.", "labels": [], "entities": []}, {"text": "Our model is conceptually simple and computationally efficient.", "labels": [], "entities": []}, {"text": "Furthermore, it finds globally optimal simplifications without resorting to heuristics or approximations during the decoding process.", "labels": [], "entities": []}, {"text": "Contrary to most previous approaches (see the discussion in Section 2) which rely heavily on hand-crafted rules, our model learns simplification rewrites automatically from examples of source-target sentences.", "labels": [], "entities": []}, {"text": "Our work joins others in using Wikipedia to extract data appropriate for model training.", "labels": [], "entities": []}, {"text": "Advantageously, the Simple English Wikipedia (henceforth SimpleEW) provides a large repository of simplified language; it uses fewer words and simpler grammar than the ordinary English Wikipedia (henceforth MainEW) and is aimed at non-native English speakers, children, translators, people with learning disabilities or low reading proficiency.", "labels": [], "entities": [{"text": "Simple English Wikipedia", "start_pos": 20, "end_pos": 44, "type": "DATASET", "confidence": 0.7687690854072571}, {"text": "MainEW", "start_pos": 207, "end_pos": 213, "type": "DATASET", "confidence": 0.8924407958984375}]}, {"text": "We exploit Wikipedia and create a (parallel) simplification corpus in two ways: by aligning MainEW sentences to their SimpleEW counterparts, and by extracting training instances from SimpleEW revision histories, thus leveraging Wikipedia's collaborative editing process.", "labels": [], "entities": [{"text": "MainEW", "start_pos": 92, "end_pos": 98, "type": "DATASET", "confidence": 0.8946043252944946}]}, {"text": "Our experimental results demonstrate that a simplification model can be learned from Wikipedia data alone without any manual effort.", "labels": [], "entities": []}, {"text": "Perhaps unsurprisingly, the quality of the QG grammar rules greatly improves when these are learned from revision histories which are less noisy than sentence alignments.", "labels": [], "entities": []}, {"text": "When compared against current stateof-the-art methods () our model yields significantly simpler output that is both grammatical and meaning preserving.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present our experimental setup for assessing the performance of the simplification model described above.", "labels": [], "entities": []}, {"text": "We give details on the corpora and grammars we used, model parameters, the systems used for comparison with our approach, and explain how the output was evaluated.", "labels": [], "entities": []}, {"text": "Grammar Extraction QG rules were learned from revision histories and an aligned simplification corpus, which we obtained from snapshots 4 of MainEW and SimpleEW.", "labels": [], "entities": [{"text": "Grammar Extraction QG", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.6055834492047628}, {"text": "MainEW", "start_pos": 141, "end_pos": 147, "type": "DATASET", "confidence": 0.9344081282615662}, {"text": "SimpleEW", "start_pos": 152, "end_pos": 160, "type": "DATASET", "confidence": 0.8999514579772949}]}, {"text": "Wiki-related mark-up and meta-information was removed to extract the plain text from the articles.", "labels": [], "entities": []}, {"text": "SimpleEW revisions not only simplify the text of existing articles, they may also introduce new content, vandalize or remove vandalism, or perform numerous automatic \"house-keeping\" modifications.: Number of QG rules extracted (after removing singletons) from revision-based and aligned corpora.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Number of QG rules extracted (after removing  singletons) from revision-based and aligned corpora.", "labels": [], "entities": []}, {"text": " Table 5: Model performance using automatic evaluation  measures.", "labels": [], "entities": []}, {"text": " Table 6: Average human ratings for gold standard Sim- pleEW sentences, a simple baseline (SpencerK) based on  lexical substitution, Zhu et al.'s 2010 model, and two ver- sions of our ILP model (RevILP and AlignILP).", "labels": [], "entities": [{"text": "simple baseline (SpencerK)", "start_pos": 74, "end_pos": 100, "type": "METRIC", "confidence": 0.7980595827102661}, {"text": "RevILP", "start_pos": 195, "end_pos": 201, "type": "DATASET", "confidence": 0.8523549437522888}]}, {"text": " Table 7: 2/: is/not sig. diff. wrt simplicity; \u2666/: is/not  sig. diff. wrt grammaticality; /: is/not sig. diff. wrt  meaning.", "labels": [], "entities": []}]}