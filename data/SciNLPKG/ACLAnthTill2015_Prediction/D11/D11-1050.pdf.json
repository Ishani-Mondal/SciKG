{"title": [{"text": "Exploring Supervised LDA Models for Assigning Attributes to Adjective-Noun Phrases", "labels": [], "entities": [{"text": "Assigning Attributes to Adjective-Noun Phrases", "start_pos": 36, "end_pos": 82, "type": "TASK", "confidence": 0.8917839646339416}]}], "abstractContent": [{"text": "This paper introduces an attribute selection task as away to characterize the inherent meaning of property-denoting adjectives in adjective noun phrases, such as e.g. hot in hot summer denoting the attribute TEMPERATURE, rather than TASTE.", "labels": [], "entities": [{"text": "TEMPERATURE", "start_pos": 208, "end_pos": 219, "type": "METRIC", "confidence": 0.9328441023826599}, {"text": "TASTE", "start_pos": 233, "end_pos": 238, "type": "METRIC", "confidence": 0.9814432859420776}]}, {"text": "We formulate this task in a vector space model that represents adjectives and nouns as vectors in a semantic space defined over possible attributes.", "labels": [], "entities": []}, {"text": "The vectors incorporate latent semantic information obtained from two variants of LDA topic models.", "labels": [], "entities": []}, {"text": "Our LDA models outperform previous approaches on a small set of 10 attributes with considerable gains on sparse representations, which highlights the strong smoothing power of LDA models.", "labels": [], "entities": []}, {"text": "For the first time, we extend the attribute selection task to anew data set with more than 200 classes.", "labels": [], "entities": [{"text": "attribute selection task", "start_pos": 34, "end_pos": 58, "type": "TASK", "confidence": 0.7899772723515829}]}, {"text": "We observe that large-scale attribute selection is a hard problem , but a subset of attributes performs robustly on the large scale as well.", "labels": [], "entities": [{"text": "attribute selection", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.72286456823349}]}, {"text": "Again, the LDA models outperform the VSM baseline.", "labels": [], "entities": [{"text": "VSM baseline", "start_pos": 37, "end_pos": 49, "type": "DATASET", "confidence": 0.8589635789394379}]}], "introductionContent": [{"text": "Corpus-based statistical modeling of semantics is gaining increased attention in computational linguistics.", "labels": [], "entities": [{"text": "Corpus-based statistical modeling of semantics", "start_pos": 0, "end_pos": 46, "type": "TASK", "confidence": 0.7120845437049865}]}, {"text": "This field of research includes distributional vector space models (VSMs), i.e., models that represent the semantics of words or phrases as vectors over high-dimensional cooccurrence data, i.a.), as well as latent variable models (LVMs) which aggregate distributional observations in 'hidden', or latent variables, thereby reducing the dimensionality of the data.", "labels": [], "entities": []}, {"text": "An example of the latter are topic models (, which have recently been applied to modeling selectional preferences of verbs (, or word sense disambiguation (.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 129, "end_pos": 154, "type": "TASK", "confidence": 0.6302103698253632}]}, {"text": "A topic that is increasingly studied in distributional semantics is the semantics of adjectives, both in isolation) and in compositional adjective-noun phrases.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew approach to a problem we denote as attribute selection: The task is to predict the hidden attribute meaning expressed by a property-denoting adjective in composition with a noun.", "labels": [], "entities": []}, {"text": "The adjective hot, e.g., may denote attributes such as TEMPERATURE, TASTE or EMO-TIONALITY.", "labels": [], "entities": [{"text": "TEMPERATURE", "start_pos": 55, "end_pos": 66, "type": "METRIC", "confidence": 0.9767754077911377}, {"text": "TASTE", "start_pos": 68, "end_pos": 73, "type": "METRIC", "confidence": 0.9892377853393555}]}, {"text": "These adjective meanings can be combined with nouns such as tea, soup or debate, which can be characterized in terms of attributes as well.", "labels": [], "entities": []}, {"text": "The goal of the task is to determine the hidden attribute meaning predicated over the noun in a given adjective-noun phrase, as illustrated in (1).", "labels": [], "entities": []}, {"text": "(1) a. a hot value summer concept b.", "labels": [], "entities": []}, {"text": "TEMPERATURE(summer) = hot It is byway of the composition of adjective and noun that specific attributes are selected from the adjective's space of possible attribute meanings, and typically lead to a disambiguation of the adjective and possibly the noun. were the first to model this insight in a VSM by representing the meaning of adjectives and nouns in semantic vectors defined over attributes.", "labels": [], "entities": [{"text": "TEMPERATURE", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.9878491163253784}]}, {"text": "vector composition, such that the 'hidden' attribute meaning of the phrase can be 'selected' as a prominent component from the composed vector.", "labels": [], "entities": []}, {"text": "This is illustrated in for the adjective enormous ( e) in combination with the noun ball ( b), with alternative composition operations: vector multiplication (\u00d7) and addition (+).", "labels": [], "entities": []}, {"text": "Both yield SIZE as the most prominent component in the composed vector.", "labels": [], "entities": [{"text": "SIZE", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9133909344673157}]}, {"text": "In the present paper we offer anew approach to this formalization of the compositional meaning of adjectives and nouns that owes to both distributional VSMs and LVMs.", "labels": [], "entities": []}, {"text": "Through this combination, we attempt to improve on earlier work in and, which are both embedded in a purely distributional setting.", "labels": [], "entities": []}, {"text": "Specifically, we use Latent Dirichlet Allocation (LDA;) to train an attribute model that captures semantic information encoded in adjectives and nouns independently of one another.", "labels": [], "entities": [{"text": "Latent Dirichlet Allocation (LDA", "start_pos": 21, "end_pos": 53, "type": "METRIC", "confidence": 0.8652040839195252}]}, {"text": "Following, this model is embedded into a VSM that employs vector composition to combine the meaning of adjectives and nouns.", "labels": [], "entities": []}, {"text": "We present two variants of LDA that differ in the way attributes are associated with the induced LDA topics: Controled LDA (C-LDA) and Labeled LDA (L-LDA;).", "labels": [], "entities": []}, {"text": "Both will be presented in detail in Section 3.", "labels": [], "entities": []}, {"text": "Our aims in this paper are two-fold: (i) We investigate LDA as a modeling framework in the attribute selection task, as its use of topics as latent variables may alleviate inherent sparsity problems faced by prior work using pattern-based or vector space models.", "labels": [], "entities": [{"text": "attribute selection task", "start_pos": 91, "end_pos": 115, "type": "TASK", "confidence": 0.7883678674697876}]}, {"text": "(ii) While these prior approaches were restricted to a confined set of 10 attributes, we will we apply our models on a much larger space of attributes, to probe their capacity on a more realistic data set.", "labels": [], "entities": []}, {"text": "The remainder of this paper is divided as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews related work on distributional models of adjective semantics, and introduces the two frameworks in which we ground our approach: LVMs and VSMs.", "labels": [], "entities": []}, {"text": "In Section 3 we introduce two LDA models for attribute selection: C-LDA and L-LDA.", "labels": [], "entities": [{"text": "attribute selection", "start_pos": 45, "end_pos": 64, "type": "TASK", "confidence": 0.6762779802083969}]}, {"text": "Section 4 describes the settings for two experiments: In the first experiment, we perform attribute selection confined to a space of 10 attributes to compare against prior work.", "labels": [], "entities": []}, {"text": "In the second setting we perform attribute selection on a large scale, using 206 attributes.", "labels": [], "entities": [{"text": "attribute selection", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.6842436492443085}]}, {"text": "Section 5 presents and discusses the results.", "labels": [], "entities": []}], "datasetContent": [{"text": "Attribute selection over small and large semantic spaces.", "labels": [], "entities": []}, {"text": "We evaluate the performance of the VSMs based on C-LDA and L-LDA in two experimental settings, contrasting the problem of attribute selection on semantic spaces of radically different dimensionality, using sets of 10 vs. 206 attributes.", "labels": [], "entities": []}, {"text": "We evaluate against two gold standards consisting of adjective-noun phrases (or adjective-noun pairs) and their associated attribute meanings.", "labels": [], "entities": []}, {"text": "We report precision, recall and f 1 -score.", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9970697164535522}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.99981290102005}, {"text": "f 1 -score", "start_pos": 32, "end_pos": 42, "type": "METRIC", "confidence": 0.9780790209770203}]}, {"text": "Where appropriate, we test differences in the performance of various model configurations for statistical significance in a randomized permutation test), using the sigf tool).", "labels": [], "entities": []}, {"text": "We compare our models against two baselines, PATTVSM and DEPVSM.", "labels": [], "entities": [{"text": "PATTVSM", "start_pos": 45, "end_pos": 52, "type": "METRIC", "confidence": 0.6699241995811462}, {"text": "DEPVSM", "start_pos": 57, "end_pos": 63, "type": "DATASET", "confidence": 0.6727505326271057}]}, {"text": "It is grounded in a selection of lexical patterns that identify the target elements (adjectives and nouns) for the vector basis elements (i.e., the attribute nouns) in a local context window.", "labels": [], "entities": []}, {"text": "The component values are defined using raw frequency counts over the extracted patterns.", "labels": [], "entities": []}, {"text": "DEPVSM is similar to PATTVSM; however, it relies on dependency paths that connect the target elements and attributes in local contexts.", "labels": [], "entities": [{"text": "DEPVSM", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8801298141479492}]}, {"text": "The paths are identical to the ones used for constructing pseudo-documents in C-LDA and L-LDA.", "labels": [], "entities": []}, {"text": "As in PATTVSM, the vector components are set to raw frequencies over extracted paths.", "labels": [], "entities": []}, {"text": "To implement our models, we rely on MALLET) for C-LDA and the Stanford Topic Modeling Toolbox 3 for L-LDA.", "labels": [], "entities": [{"text": "MALLET", "start_pos": 36, "end_pos": 42, "type": "METRIC", "confidence": 0.9868554472923279}]}, {"text": "In both cases, we run 1000 iterations of Gibbs sampling, using default values for all hyperparameters.", "labels": [], "entities": []}, {"text": "Data set for attribute selection over 10 attributes.", "labels": [], "entities": []}, {"text": "The first experiment is conducted on the data set used in.", "labels": [], "entities": []}, {"text": "It consists of 100 adjective-noun pairs manually annotated for ten attributes: COLOR, DIRECTION, DURATION, SHAPE, SIZE, SMELL, SPEED, TASTE, TEMPER-ATURE, WEIGHT.", "labels": [], "entities": [{"text": "COLOR", "start_pos": 79, "end_pos": 84, "type": "METRIC", "confidence": 0.997280478477478}, {"text": "DIRECTION", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9182360768318176}, {"text": "DURATION", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9225702285766602}, {"text": "SHAPE", "start_pos": 107, "end_pos": 112, "type": "METRIC", "confidence": 0.9733768105506897}, {"text": "SIZE", "start_pos": 114, "end_pos": 118, "type": "METRIC", "confidence": 0.8709387183189392}, {"text": "SMELL", "start_pos": 120, "end_pos": 125, "type": "METRIC", "confidence": 0.974385678768158}, {"text": "SPEED", "start_pos": 127, "end_pos": 132, "type": "METRIC", "confidence": 0.9844681620597839}, {"text": "TASTE", "start_pos": 134, "end_pos": 139, "type": "METRIC", "confidence": 0.972080647945404}, {"text": "TEMPER-ATURE", "start_pos": 141, "end_pos": 153, "type": "METRIC", "confidence": 0.9668434262275696}, {"text": "WEIGHT", "start_pos": 155, "end_pos": 161, "type": "METRIC", "confidence": 0.9680449366569519}]}, {"text": "To enable comparison, the dimensions of our models are set to exactly these attributes.", "labels": [], "entities": []}, {"text": "Data set for attribute selection over a large semantic space (206 attributes).", "labels": [], "entities": [{"text": "attribute selection", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.6970892995595932}]}, {"text": "In the second experiment, we max out the attribute selection task to a much larger set of attributes in order to analyze the difficulty of the task on more representative data.", "labels": [], "entities": [{"text": "attribute selection task", "start_pos": 41, "end_pos": 65, "type": "TASK", "confidence": 0.7625706195831299}]}, {"text": "We automatically construct a data set of adjective-noun phrases labeled with appropriate attributes from WordNet 3.0, relying on the assumption that examples given in glosses correspond to the respective word sense of the adjective.", "labels": [], "entities": []}, {"text": "We first extract all adjectives that are linked to at least one attribute synset by the attribute relation.", "labels": [], "entities": []}, {"text": "Next, we run the glosses of these adjectives (3592 in number) through TreeTagger to find examples of adjectives modifying nouns in attributive constructions.", "labels": [], "entities": []}, {"text": "The resulting adjective-noun phrases are labeled with the attribute label linked to the given adjective sense.", "labels": [], "entities": []}, {"text": "This method yields 7901 labeled adjective-noun phrases.", "labels": [], "entities": []}, {"text": "They are divided into development and test data according to a sampling procedure that respects the following criteria: (i) Both sets must contain all attributes with an equal number of phrases for each attribute; (ii) phrases with both elements contained in CoreWordNet 4 are preferred, while others are only considered if necessary to satisfy the first criterion.", "labels": [], "entities": []}, {"text": "This procedure yields 496/345 phrases in the development/test set, distributed over 206 attributes 5 . 3 http://nlp.stanford.edu/software/tmt/.", "labels": [], "entities": []}, {"text": "A subset of WordNet restricted to the 5000 most frequently used word senses.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 12, "end_pos": 19, "type": "DATASET", "confidence": 0.959330677986145}]}, {"text": "Available from: http:// wordnetcode.princeton.edu/standoff-files/ core-wordnet.txt If an attribute provides only one example, this was added to the development set.", "labels": [], "entities": []}, {"text": "Therefore, the test set only comprises Training data.", "labels": [], "entities": []}, {"text": "The pseudo-documents are collected from dependency paths obtained from section 2 of the parsed pukWaC corpus ().", "labels": [], "entities": [{"text": "pukWaC corpus", "start_pos": 95, "end_pos": 108, "type": "DATASET", "confidence": 0.9762991964817047}]}, {"text": "In Experiment 1, we evaluate the performance of C-LDA and L-LDA on the attribute selection task over 10 attributes against the pattern-based and dependency-based models PATTVSM and DE-PVSM as competitive baselines.", "labels": [], "entities": []}, {"text": "Besides a comparison to standard VSMs, we are especially interested in the relative performance of the LDA models.", "labels": [], "entities": []}, {"text": "Given that C-LDA and L-LDA estimate attribute-specific topic distributions in the structured pseudo-documents under different assumptions regarding the correspondence of attributes and topics (cf. Sec.", "labels": [], "entities": []}, {"text": "3.2 and 3.3), we expect the two LDA variants to differ in their capability to capture the topic distributions in the labeled pseudo-documents.", "labels": [], "entities": []}, {"text": "summarize the results for attribute selection over 10 attributes against the labeled adjective-noun pairs in the test set, using ESel and MPC as selection functions on vectors composed by multiplication and addition (Table 2).", "labels": [], "entities": [{"text": "ESel", "start_pos": 129, "end_pos": 133, "type": "METRIC", "confidence": 0.6438494324684143}]}, {"text": "The results reported for C-LDA correspond to the best performing model (with number of topics set to 42, as this setting yields the best and most constant results over both composition operators).", "labels": [], "entities": []}, {"text": "C-LDA shows highest f-scores and recall overall settings, and highest precision with vector addition.", "labels": [], "entities": [{"text": "recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9995481371879578}, {"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9995160102844238}]}, {"text": "In line with Mitchell and Lapata (2010) (cf. Sec. 2), we obtain the best overall results with vector addition (ESel: P: 0.55, R: 0.66, F: 0.61; MPC: P: 0.59, R: 0.71, F: 0.64).", "labels": [], "entities": [{"text": "ESel", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.9014451503753662}, {"text": "F", "start_pos": 135, "end_pos": 136, "type": "METRIC", "confidence": 0.9493758082389832}, {"text": "F", "start_pos": 167, "end_pos": 168, "type": "METRIC", "confidence": 0.9745551347732544}]}, {"text": "The difference between C-LDA and L-LDA is small but significant for vector multiplication; for vector addition, it is not significant.", "labels": [], "entities": [{"text": "vector multiplication", "start_pos": 68, "end_pos": 89, "type": "TASK", "confidence": 0.7460286021232605}, {"text": "vector addition", "start_pos": 95, "end_pos": 110, "type": "TASK", "confidence": 0.8069584965705872}]}, {"text": "Experiment 2 is designed to max out the space of attributes to be modeled, to assess the capacity of both LDA models and the DEPVSM baseline model in the attribute selection task on a large attribute space.", "labels": [], "entities": [{"text": "DEPVSM baseline", "start_pos": 125, "end_pos": 140, "type": "DATASET", "confidence": 0.8676833808422089}]}, {"text": "In contrast to Experiment 1, with its confined semantic space of 10 target attributes, this represents a huge undertaking.", "labels": [], "entities": []}, {"text": "dimensions, contrasting vector addition and multiplication.", "labels": [], "entities": []}, {"text": "The number of topics was set to 400.", "labels": [], "entities": []}, {"text": "As the overall performance is close to 0 for both composition methods, no parameter setting can be identified as particularly suited for this large-scale attribute selection task.", "labels": [], "entities": []}, {"text": "The differences between the three models are very small and not significant 8 .  To gain a deeper insight into the modeling capacity of the LDA models for this large-scale selection task, (column all) presents a partial evaluation of attributes that could be assigned to adjectivenoun pairs with an f-score >0 by C-LDA ESel,\u00d7 . Despite  the LDA models on this large attribute space, it is remarkable that C-LDA is able to induce distinctive topic distributions fora number of attributes with up to 0.51 f-score with balanced precision and recall, a moderate drop of only -0.10 relative to the corresponding model induced over 10 attributes.", "labels": [], "entities": [{"text": "precision", "start_pos": 525, "end_pos": 534, "type": "METRIC", "confidence": 0.9983910322189331}, {"text": "recall", "start_pos": 539, "end_pos": 545, "type": "METRIC", "confidence": 0.9985700845718384}]}, {"text": "Raising the attribute selection task from 10 to 206 attributes poses a true challenge to our models, by the sheer size and diversity of the semantic space considered.", "labels": [], "entities": []}, {"text": "gives an insight into the nature of the data and the difficulty of the task, by listing correct and false preditions of C-LDA fora small sample of adjective-noun pairs.", "labels": [], "entities": []}, {"text": "Possible explanations for false predictions are manifold, among them near misses (e.g. serious book, weak president, short flight, rough bark), idiomatic expressions (e.g. faint heart, blue line) or questionable labels provided by WordNet (e.g. serious book).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 231, "end_pos": 238, "type": "DATASET", "confidence": 0.963365912437439}]}, {"text": "As seen above, C-LDA achieves relatively high performance figures on selected attributes (cf., col. all).", "labels": [], "entities": []}, {"text": "In order to identify what makes these attributes different from others that resist successful modeling, we investigated three factors: (i) the amount of training data available for each attribute, (ii) the ambiguity rate per attribute, and (iii) their ontological subtype.", "labels": [], "entities": []}, {"text": "(i) Measuring the dependence between training data size and f-score per attribute shows that a large amount of training data is generally helpful, but not the decisive factor (Pearson's r = 0.19, p < 0.01).", "labels": [], "entities": [{"text": "Pearson's r", "start_pos": 176, "end_pos": 187, "type": "METRIC", "confidence": 0.8248226642608643}]}, {"text": "(ii) The ambiguity rate AR attr per attribute attr is computed by averaging overall test pairs T P attr labeled with attr, counting the total number of attributes attr \u2032 that are associated with each adjective in pairs adj, n \u2208 T P attr in WordNet: Correlating this figure with the performance per attribute in terms of f-score yields only a small positive correlation (Pearson's r = 0.23, p < 0.01).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 240, "end_pos": 247, "type": "DATASET", "confidence": 0.9427265524864197}]}, {"text": "In fact, the qualitative analysis in shows that C-LDA is capable of assigning meaningful attributes to adjective-noun phrases not only in easy, but also ambiguous cases (cf. shallow water, where DEPTH is the only attribute provided for shallow in WordNet vs. short holiday, short hair or short flight).", "labels": [], "entities": [{"text": "DEPTH", "start_pos": 195, "end_pos": 200, "type": "METRIC", "confidence": 0.9251030683517456}, {"text": "WordNet", "start_pos": 247, "end_pos": 254, "type": "DATASET", "confidence": 0.9548704028129578}]}, {"text": "(iii) Although the 206 attributes used in Exp.", "labels": [], "entities": [{"text": "Exp", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.8956484794616699}]}, {"text": "2 are rather diverse, including concepts such as HEIGHT, KINDNESS or INDIVIDUALITY, we observe a high number of attributes from Exp.", "labels": [], "entities": [{"text": "HEIGHT", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.8940982818603516}, {"text": "KINDNESS", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9416651129722595}, {"text": "INDIVIDUALITY", "start_pos": 69, "end_pos": 82, "type": "METRIC", "confidence": 0.9693071246147156}, {"text": "Exp", "start_pos": 128, "end_pos": 131, "type": "DATASET", "confidence": 0.9050715565681458}]}, {"text": "1 that are successfully modeled in Exp.", "labels": [], "entities": [{"text": "Exp.", "start_pos": 35, "end_pos": 39, "type": "DATASET", "confidence": 0.8840897679328918}]}, {"text": "2 (5 out of 10, cf. column all in).", "labels": [], "entities": []}, {"text": "Given that they are categorized into the property class in WordNet 9 , we presume that the varying performance across attributes might be influenced by their ontological subtype.", "labels": [], "entities": []}, {"text": "This hypothesis is validated in a replication of Exp.", "labels": [], "entities": [{"text": "Exp.", "start_pos": 49, "end_pos": 53, "type": "DATASET", "confidence": 0.9071578085422516}]}, {"text": "2, with training data limited to the 73 attributes pertaining to the property subtype in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 89, "end_pos": 96, "type": "DATASET", "confidence": 0.9640316367149353}]}, {"text": "The test set was restricted accordingly, resulting in 112 pairs that are linked to a property attribute.", "labels": [], "entities": []}, {"text": "The overall performance of the models in this experiment is shown in (column property): With vector multiplication, the best-performing operation across all models, all models benefit considerably (+0.10 or more).", "labels": [], "entities": []}, {"text": "C-LDA shows the largest improvement, significantly outperforming both L-LDA and DEPVSM.", "labels": [], "entities": [{"text": "DEPVSM", "start_pos": 80, "end_pos": 86, "type": "DATASET", "confidence": 0.8515399098396301}]}, {"text": "With vector addition, the performance gains are slightly lower in general.", "labels": [], "entities": []}, {"text": "In this setting, L-LDA shows higher f-score than C-LDA, though this difference is not statistically significant.", "labels": [], "entities": [{"text": "f-score", "start_pos": 36, "end_pos": 43, "type": "METRIC", "confidence": 0.986072301864624}]}, {"text": "Still, C-LDA significantly outranges DE-PVSM.", "labels": [], "entities": []}, {"text": "Note that we cannot show a significant difference between C-LDA ESel,\u00d7 and L-LDA ESel,+ , so the comparison between these models remains inconclusive here.", "labels": [], "entities": []}, {"text": "Note further that the affinity of C-LDA with vector addition and L-LDA with vector multiplication, respectively, is inverted in the largescale experiment (cf.).", "labels": [], "entities": []}, {"text": "While these overall results are far from satisfactory, they still clearly indicate that the LDA models work effectively for at least a subset of attributes, and outperform the VSM baseline.", "labels": [], "entities": [{"text": "VSM baseline", "start_pos": 176, "end_pos": 188, "type": "DATASET", "confidence": 0.8153952658176422}]}, {"text": "Again, a more detailed analysis is given in Table 6 (column property), showing the performance of the best individual property attributes (F >0) in the restricted experiment.", "labels": [], "entities": [{"text": "F >0)", "start_pos": 139, "end_pos": 144, "type": "METRIC", "confidence": 0.9426517486572266}]}, {"text": "Average performance of the best property attributes with F >0, individually, amounts to F =0.63 . In comparison to the unrestricted setting (cf. column all), nearly all property attributes benefit from model training on selective data.", "labels": [], "entities": [{"text": "F", "start_pos": 57, "end_pos": 58, "type": "METRIC", "confidence": 0.9812993407249451}, {"text": "F", "start_pos": 88, "end_pos": 89, "type": "METRIC", "confidence": 0.9972954392433167}]}, {"text": "Exceptions are WIDTH, WEIGHT, THICKNESS, AGE, DEGREE and LIGHT.", "labels": [], "entities": [{"text": "WIDTH", "start_pos": 15, "end_pos": 20, "type": "METRIC", "confidence": 0.9739426374435425}, {"text": "WEIGHT", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9855477809906006}, {"text": "THICKNESS", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.9935401082038879}, {"text": "AGE", "start_pos": 41, "end_pos": 44, "type": "METRIC", "confidence": 0.9982559084892273}, {"text": "DEGREE", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9915980100631714}, {"text": "LIGHT", "start_pos": 57, "end_pos": 62, "type": "METRIC", "confidence": 0.9944033622741699}]}, {"text": "Thus, apparently, some of the adjectives associated with non-property attributes in the full set provide some discriminative power that is helpful to distinguish property types.", "labels": [], "entities": []}, {"text": "Ina qualitative analysis of the 133 non-property attributes filtered out in this experiment, we find that the WordNet-SUMO mapping does not provide differentiating definitions for about 60% of these attributes, linking them instead to a single subjective assessment attribute.", "labels": [], "entities": [{"text": "WordNet-SUMO mapping", "start_pos": 110, "end_pos": 130, "type": "DATASET", "confidence": 0.9221712350845337}]}, {"text": "This suggests that in many cases the distinctions drawn by WordNet are too subtle even for humans to reproduce.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.9629566073417664}]}], "tableCaptions": [{"text": " Table 1: Attribute selection over 10 attributes (\u00d7)", "labels": [], "entities": []}, {"text": " Table 2: Attribute selection over 10 attributes (+)", "labels": [], "entities": []}, {"text": " Table 4: Performance figures on sparse vectors (+)", "labels": [], "entities": []}, {"text": " Table 6: Attribute selection on 206 attributes (all) and 73  property attributes (property); performance figures of C- LDA ESel,\u00d7 for best attributes (F>0)", "labels": [], "entities": [{"text": "C- LDA ESel", "start_pos": 117, "end_pos": 128, "type": "DATASET", "confidence": 0.689334973692894}]}]}