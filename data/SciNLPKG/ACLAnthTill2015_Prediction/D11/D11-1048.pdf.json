{"title": [{"text": "A generative model for unsupervised discovery of relations and argument classes from clinical texts", "labels": [], "entities": [{"text": "unsupervised discovery of relations and argument classes", "start_pos": 23, "end_pos": 79, "type": "TASK", "confidence": 0.6190836642469678}]}], "abstractContent": [{"text": "This paper presents a generative model for the automatic discovery of relations between entities in electronic medical records.", "labels": [], "entities": [{"text": "automatic discovery of relations between entities in electronic medical records", "start_pos": 47, "end_pos": 126, "type": "TASK", "confidence": 0.7562652587890625}]}, {"text": "The model discovers relation instances and their types by determining which context tokens express the relation.", "labels": [], "entities": []}, {"text": "Additionally, the valid semantic classes for each type of relation are determined.", "labels": [], "entities": []}, {"text": "We show that the model produces clusters of relation trigger words which better correspond with manually annotated relations than several existing clustering techniques.", "labels": [], "entities": []}, {"text": "The discovered relations reveal some of the implicit semantic structure present in patient records.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic relations in electronic medical records (EMRs) capture important meaning about the associations between medical concepts.", "labels": [], "entities": []}, {"text": "Knowledge about how concepts such as medical problems, treatments, and tests are related can be used to improve medical care by speeding up the retrieval of relevant patient information or alerting doctors to critical information that may have been overlooked.", "labels": [], "entities": []}, {"text": "When doctors write progress notes and discharge summaries they include information about how treatments (e.g., aspirin, stent) were administered for problems (e.g. pain, lesion) along with the outcome, such as an improvement or deterioration.", "labels": [], "entities": []}, {"text": "Additionally, a doctor will describe the tests (e.g., xray, blood sugar level) performed on a patient and whether the tests were conducted to investigate a known problem or revealed anew one.", "labels": [], "entities": [{"text": "xray, blood sugar level)", "start_pos": 54, "end_pos": 78, "type": "METRIC", "confidence": 0.7912531594435374}]}, {"text": "These textual descriptions written in a patient's record encode important information about the relationships between the problems a patients has, the treatments taken for the problems, and the tests which reveal and investigate the problems.", "labels": [], "entities": []}, {"text": "The ability to accurately detect semantic relations in EMRs, such as Treatment-Administered-forProblem, can aid in querying medical records.", "labels": [], "entities": []}, {"text": "After a preprocessing phase in which the relations are detected in all records they can be indexed and retrieved later as needed.", "labels": [], "entities": []}, {"text": "A doctor could search for all the times that a certain treatment has been used on a particular problem, or determine all the treatments used fora specific problem.", "labels": [], "entities": []}, {"text": "An additional application is the use of the relational information to flag situations that merit further review.", "labels": [], "entities": []}, {"text": "If a patient's medical record indicates a test that was found to reveal a critical problem but no subsequent treatment was performed for the problem, the patient's record could be flagged for review.", "labels": [], "entities": []}, {"text": "Similarly, if a Treatment-Worsens-Problem relation is detected previously in a patient's record, that information can be brought to the attention of a doctor who advises such a treatment in the future.", "labels": [], "entities": []}, {"text": "By considering all of the relations present in a corpus, better medical ontologies could be built automatically or existing ones can be improved by adding additional connections between concepts that have a relation in text.", "labels": [], "entities": []}, {"text": "Given the large size of EMR repositories, we argue that it is quite important to have the ability to perform relation discovery between medical concepts.", "labels": [], "entities": [{"text": "relation discovery between medical concepts", "start_pos": 109, "end_pos": 152, "type": "TASK", "confidence": 0.8759795069694519}]}, {"text": "Relations between medical concepts benefit translational medicine whenever possible relations are known.", "labels": [], "entities": [{"text": "translational medicine", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.9761380553245544}]}, {"text": "show that super-519 vised methods recognize such relations with high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9980314373970032}]}, {"text": "However, large sets of annotated relations need to be provided for this purpose.", "labels": [], "entities": []}, {"text": "To address both the problem of discovering unknown relations between medical concepts and the related problem of generating examples for known relations, we have developed an unsupervised method.", "labels": [], "entities": []}, {"text": "This approach has the advantages of not requiring an expensive annotation effort to provide training data for semantic relations, which is particularly difficult for medical records, characterized by many privacy concerns.", "labels": [], "entities": []}, {"text": "Our analysis shows a high level of overlap between the manually annotated relations and those that were discovered automatically.", "labels": [], "entities": []}, {"text": "Our experimental results show that this approach improves upon simpler clustering techniques.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses the related work.", "labels": [], "entities": []}, {"text": "Section 3 reports our novel generative model for discovering relations in EMRs, Section 4 details the inference and parameter estimation of our method.", "labels": [], "entities": []}, {"text": "Section 5 details our experiments, Section 6 discusses our findings.", "labels": [], "entities": []}, {"text": "Section 7 summarizes the conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the RDM using a corpus of electronic medical records provided by the 2010 i2b2/VA Challenge).", "labels": [], "entities": [{"text": "RDM", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9546469449996948}, {"text": "2010 i2b2/VA Challenge", "start_pos": 82, "end_pos": 104, "type": "DATASET", "confidence": 0.6380788147449493}]}, {"text": "We used the training set, which consists of 349 medical records from 4 hospitals, annotated with medical concepts (specifically problems, treatments, and tests), along with any relations present between those concepts.", "labels": [], "entities": []}, {"text": "We used these manually annotated relations to evaluate how well the RDM performs at relation discovery.", "labels": [], "entities": [{"text": "relation discovery", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.8077167570590973}]}, {"text": "The corpus is annotated with a set of eight relations: illustrates four of the fifteen trigger word clusters (most likely words according to \u03c6 r ) learned from dataset DS1 using the best set of parameters according to normalized mutual information (NMI) as described in section 5.3.", "labels": [], "entities": []}, {"text": "These parameters were:  . This indicates the model is detecting stylistic differences in addition to semantic differences.", "labels": [], "entities": []}, {"text": "This is one of shortcomings of simple generative models.", "labels": [], "entities": []}, {"text": "Because they cannot reflect the true underlying distribution of the data they will model the observations in ways that are irrelevant to the task at hand.", "labels": [], "entities": []}, {"text": "Relation 2 also contains certain punctuation, such as parentheses which the examples show are used to delineate a treatment code.", "labels": [], "entities": []}, {"text": "Instances of Relation 2 were often marked as Treatment-Addresses-Problem relations by annotators.", "labels": [], "entities": []}, {"text": "For a more objective analysis of the relations detected, we evaluated the discovered relation types by comparing them with the manually annotated ones from the data using normalized mutual information (NMI) (.", "labels": [], "entities": []}, {"text": "NMI is an information-theoretic measure of the quality of a clustering which indicates how much information about the gold classes is obtained by knowing the clustering.", "labels": [], "entities": [{"text": "NMI", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6221555471420288}]}, {"text": "It is normalized to have a range from 0.0 to 1.0.", "labels": [], "entities": []}, {"text": "It is defined as: where \u2126 is the system-produced clustering, C is the gold clustering, I is the mutual information, and H is the entropy.", "labels": [], "entities": []}, {"text": "The mutual information of two clusterings can be defined as: where N is the number of items in the clustering.", "labels": [], "entities": []}, {"text": "The entropy is defined as The reference clusters consist of all relations annotated with the same relation type.", "labels": [], "entities": []}, {"text": "The predicted clusters consist of all relations which were assigned the same relation type.", "labels": [], "entities": []}, {"text": "In addition to NMI, we also compute the F measure).", "labels": [], "entities": [{"text": "NMI", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.705155074596405}, {"text": "F measure", "start_pos": 40, "end_pos": 49, "type": "METRIC", "confidence": 0.9882895648479462}]}, {"text": "The F measure is computed as: and P recision is defined as: while Recall is simply precision with the arguments swapped: Recall(L, C) = P recision(C, L) shows the NMI and F measure scores for several baselines along with the RDM.", "labels": [], "entities": [{"text": "F measure", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9650157392024994}, {"text": "Recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9976428151130676}, {"text": "precision", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9983062744140625}]}, {"text": "Evaluation was performed on both DS1 (concept pairs having a manually annotated relation) and DS2 (all consecutive concept pairs).", "labels": [], "entities": []}, {"text": "For DS2 we learned the models using all of the data, and evaluated on those entity pairs which had a manual relation annotated.", "labels": [], "entities": []}, {"text": "The LDA-based model from Section 3.1 is used as one baseline.", "labels": [], "entities": []}, {"text": "Two other baselines are K-means and Complete-Link hierarchical agglomerative clustering using TF-IDF vectors of the context and argument words (similar to Complete-link clustering did not finish on DS2 because of the large size of the data set.", "labels": [], "entities": []}, {"text": "This highlights another advantage of the RDM.", "labels": [], "entities": []}, {"text": "Hierarchical agglomerative clustering is quadratic in the size of the number of instances to be clustered, while the RDM's time and memory requirements both grow linearly in the number of entity pairs.", "labels": [], "entities": []}, {"text": "The scores shown in use the best parameterization of each model as measured by NMI.", "labels": [], "entities": [{"text": "NMI", "start_pos": 79, "end_pos": 82, "type": "DATASET", "confidence": 0.8922873735427856}]}, {"text": "For DS1 the best LDA-based model used 15 clusters.", "labels": [], "entities": []}, {"text": "K-means achieved the best result with 40 clusters, while the best Complete-Link clustering was obtained by using 40 clusters.", "labels": [], "entities": []}, {"text": "The best RDM model used parameters R = 9 relation, K = 15 general word classes, and A = 15 argument classes.", "labels": [], "entities": []}, {"text": "For DS2 the best number of clusters for LDA was 10, while K-means performed best with 58 clusters.", "labels": [], "entities": []}, {"text": "The best RDM model used R = 100 relations, K = 50 general word classes, and A = 15 argument classes.", "labels": [], "entities": []}, {"text": "The LDA-based approach saw an improvement when using the larger data set, however the RDM still performed the best.", "labels": [], "entities": []}, {"text": "To assess how well the RDM performs on unseen data we also evaluated the relations extracted by the model on the test set.", "labels": [], "entities": [{"text": "RDM", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.9522163271903992}]}, {"text": "Only the RDM and LDA models were evaluated as clusters produced by K-means and hierarchical clustering are valid only for the data used to generate the clusters.", "labels": [], "entities": []}, {"text": "Generative models on the other hand can provide an estimate of the probability for each relation type on unseen text.", "labels": [], "entities": []}, {"text": "For each model we generate 10 samples after a burn in period of 30 iterations and form clusters by assigning each pair of concepts to the relation assigned most often in the samples.", "labels": [], "entities": []}, {"text": "The results of this evaluation are presented in.", "labels": [], "entities": []}, {"text": "While these cluster scores are lower than those on the data used to train the models, they still show the RDM outperforming the LDA baseline model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: NMI and F measure scores for the RDM and  baselines. The first two columns of numbers show the  scores when evaluation is restricted to only those pairs  of concepts which had a relation identified by annotators.  The last two columns are the NMI and F measure scores  when each method clusters all consecutive entity pairs,  but is only evaluated on those with a relation identified  by annotators.", "labels": [], "entities": []}]}