{"title": [{"text": "Probabilistic models of similarity in syntactic context", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper investigates novel methods for incorporating syntactic information in proba-bilistic latent variable models of lexical choice and contextual similarity.", "labels": [], "entities": []}, {"text": "The resulting models capture the effects of context on the interpretation of a word and in particular its effect on the appropriateness of replacing that word with a potentially related one.", "labels": [], "entities": []}, {"text": "Evaluating our techniques on two datasets, we report performance above the prior state of the art for estimating sentence similarity and ranking lexical substitutes.", "labels": [], "entities": [{"text": "estimating sentence similarity", "start_pos": 102, "end_pos": 132, "type": "TASK", "confidence": 0.7618866364161173}]}], "introductionContent": [{"text": "Distributional models of lexical semantics, which assume that aspects of a word's meaning can be related to the contexts in which that word is typically used, have along history in Natural Language Processing.", "labels": [], "entities": []}, {"text": "Such models still constitute one of the most popular approaches to lexical semantics, with many proven applications.", "labels": [], "entities": [{"text": "lexical semantics", "start_pos": 67, "end_pos": 84, "type": "TASK", "confidence": 0.811985433101654}]}, {"text": "Much work in distributional semantics treats words as non-contextualised units; the models that are constructed can answer questions such as \"how similar are the words body and corpse?\" but do not capture the way the syntactic context in which a word appears can affect its interpretation.", "labels": [], "entities": []}, {"text": "Recent developments) have aimed to address compositionality of meaning in terms of distributional semantics, leading to new kinds of questions such as \"how similar are the usages of the words body and corpse in the phrase the body/corpse deliberated the motion.", "labels": [], "entities": []}, {"text": "?\" and \"how similar are the phrases the body deliberated the motion and the corpse rotted?\".", "labels": [], "entities": []}, {"text": "In this paper we focus on answering questions of the former type and investigate models that describe the effect of syntactic context on the meaning of a single word.", "labels": [], "entities": []}, {"text": "The work described in this paper uses probabilistic latent variable models to describe patterns of syntactic interaction, building on the selectional preference models of\u00b4Oof\u00b4 of\u00b4O and and the lexical substitution models of.", "labels": [], "entities": []}, {"text": "We propose novel methods for incorporating information about syntactic context in models of lexical choice, yielding a probabilistic analogue to dependency-based models of contextual similarity.", "labels": [], "entities": []}, {"text": "Our models attain state-of-the-art performance on two evaluation datasets: a set of sentence similarity judgements collected by and the dataset of the English Lexical Substitution Task.", "labels": [], "entities": []}, {"text": "In view of the well-established effectiveness of dependency-based distributional semantics and of probabilistic frameworks for semantic inference, we expect that our approach will prove to be of value in a wide range of application settings.", "labels": [], "entities": []}], "datasetContent": [{"text": "Mitchell and Lapata (2008) collected human judgements of semantic similarity for pairs of short sentences, where the sentences in a pair share the same subject but different verbs.", "labels": [], "entities": []}, {"text": "For example, the sales slumped and the sales declined should be judged as very similar while the shoulders slumped and the shoulders declined should be judged as less similar.", "labels": [], "entities": []}, {"text": "The resulting dataset (henceforth ML08) consists of 120 such pairs using 15 verbs, balanced across high and low expected similarity.", "labels": [], "entities": []}, {"text": "60 subjects rated the data using a scale of 1-7; Mitchell and Lapata calculate average interannotator correlation to be 0.40 (using Spearman's \u03c1).", "labels": [], "entities": [{"text": "interannotator correlation", "start_pos": 87, "end_pos": 113, "type": "METRIC", "confidence": 0.7292390763759613}]}, {"text": "Both Mitchell and split the data into a development portion and a test portion, the development portion consisting of the judgements of six annotators; in order to compare our results with previous research we use the same data split.", "labels": [], "entities": []}, {"text": "To evaluate performance, the predictions made by a model are compared to the judgements of each annotator in turn (using \u03c1) and the resulting per-annotator \u03c1 values are averaged.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance (average \u03c1) on the ML08 test  set", "labels": [], "entities": [{"text": "ML08 test  set", "start_pos": 41, "end_pos": 55, "type": "DATASET", "confidence": 0.9151663780212402}]}, {"text": " Table 4: Type and token counts for the BNC and downsampled BNC+Wikipedia corpora", "labels": [], "entities": [{"text": "BNC", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.9201169610023499}, {"text": "BNC+Wikipedia corpora", "start_pos": 60, "end_pos": 81, "type": "DATASET", "confidence": 0.8261377215385437}]}, {"text": " Table 5: Results on the English Lexical Substitution Task dataset; boldface denotes best performance at full  coverage for each corpus", "labels": [], "entities": [{"text": "English Lexical Substitution Task dataset", "start_pos": 25, "end_pos": 66, "type": "DATASET", "confidence": 0.7228832483291626}]}, {"text": " Table 6: Performance by part of speech", "labels": [], "entities": []}]}