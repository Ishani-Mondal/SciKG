{"title": [{"text": "Learning General Connotation of Words using Graph-based Algorithms", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we introduce a connotation lexicon , anew type of lexicon that lists words with connotative polarity, i.e., words with positive connotation (e.g., award, promotion) and words with negative connotation (e.g., cancer, war).", "labels": [], "entities": [{"text": "award, promotion)", "start_pos": 162, "end_pos": 179, "type": "TASK", "confidence": 0.6851807534694672}]}, {"text": "Connotation lexicons differ from much studied sentiment lexicons: the latter concerns words that express sentiment, while the former concerns words that evoke or associate with a specific polarity of sentiment.", "labels": [], "entities": [{"text": "Connotation lexicons", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8431364595890045}]}, {"text": "Understanding the connotation of words would seem to require commonsense and world knowledge.", "labels": [], "entities": [{"text": "Understanding the connotation of words", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.8006616592407226}]}, {"text": "However, we demonstrate that much of the connotative polarity of words can be inferred from natural language text in a nearly unsu-pervised manner.", "labels": [], "entities": []}, {"text": "The key linguistic insight behind our approach is selectional preference of connotative predicates.", "labels": [], "entities": []}, {"text": "We present graph-based algorithms using PageRank and HITS that collectively learn connotation lexicon together with connotative predicates.", "labels": [], "entities": []}, {"text": "Our empirical study demonstrates that the resulting connotation lexicon is of great value for sentiment analysis complementing existing sentiment lexicons.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.9624744057655334}]}], "introductionContent": [{"text": "In this paper, we introduce a connotation lexicon, anew type of lexicon that lists words with connotative polarity, i.e., words with positive connotation (e.g., award, promotion) and words with negative connotation (e.g., cancer, war).", "labels": [], "entities": [{"text": "award, promotion)", "start_pos": 161, "end_pos": 178, "type": "TASK", "confidence": 0.6851807534694672}]}, {"text": "Connotation lexicons differ from sentiment lexicons that are studied in much of previous research (e.g.,,): the latter concerns words that express sentiment either explicitly or implicitly, while the former concerns words that evoke or even simply associate with a specific polarity of sentiment.", "labels": [], "entities": [{"text": "Connotation lexicons", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8254272043704987}]}, {"text": "To our knowledge, there has been no previous research that investigates polarized connotation lexicons.", "labels": [], "entities": []}, {"text": "Understanding the connotation of words would seem to require commonsense and world knowledge at first glance, which in turn might seem to require human encoding of knowledge base.", "labels": [], "entities": [{"text": "Understanding the connotation of words", "start_pos": 0, "end_pos": 38, "type": "TASK", "confidence": 0.8775334835052491}]}, {"text": "However, we demonstrate that much of the connotative polarity of words can be inferred from natural language text in a nearly unsupervised manner.", "labels": [], "entities": []}, {"text": "The key linguistic insight behind our approach is selectional preference of connotative predicates.", "labels": [], "entities": []}, {"text": "We define a connotative predicate as a predicate that has selectional preference on the connotative polarity of some of its semantic arguments.", "labels": [], "entities": []}, {"text": "For instance, in the case of the connotative predicate \"prevent\", there is strong selectional preference on negative connotation with respect to the thematic role (semantic role) \"THEME\".", "labels": [], "entities": [{"text": "THEME", "start_pos": 180, "end_pos": 185, "type": "METRIC", "confidence": 0.7221049666404724}]}, {"text": "That is, statistically speaking, people tend to associate negative connotation with the THEME of \"prevent\", e.g., \"prevent cancer\" or \"prevent war\", rather than positive connotation, e.g., \"prevent promotion\".", "labels": [], "entities": [{"text": "THEME", "start_pos": 88, "end_pos": 93, "type": "METRIC", "confidence": 0.9988692402839661}, {"text": "prevent promotion", "start_pos": 190, "end_pos": 207, "type": "TASK", "confidence": 0.7093942165374756}]}, {"text": "In other words, even though it is perfectly valid to use words with positive connotation in the THEME role of \"prevent\", statistically more dominant connotative polarity is negative.", "labels": [], "entities": [{"text": "THEME", "start_pos": 96, "end_pos": 101, "type": "METRIC", "confidence": 0.7228901982307434}]}, {"text": "Similarly, the THEME of \"congratulate\" or \"praise\" has strong selectional preference on positive connotation.", "labels": [], "entities": [{"text": "THEME", "start_pos": 15, "end_pos": 20, "type": "METRIC", "confidence": 0.996044933795929}]}, {"text": "The theoretical concept supporting the selective 1092 accomplish, achieve, advance, advocate, admire, applaud, appreciate, compliment, congratulate, develop, desire, enhance, enjoy, improve, praise, promote, respect, save, support, win  preference of connotative predicates is that of semantic prosody in corpus linguistics.", "labels": [], "entities": [{"text": "1092 accomplish, achieve, advance, advocate, admire, applaud, appreciate, compliment, congratulate, develop, desire, enhance, enjoy, improve, praise, promote, respect, save, support, win  preference of connotative predicates", "start_pos": 49, "end_pos": 273, "type": "Description", "confidence": 0.8363251320340417}]}, {"text": "Semantic prosody describes how some of the seemingly neutral words (e.g., \"cause\") can be perceived with positive or negative polarity because they tend to collocate with words with corresponding polarity (e.g.,,,,).", "labels": [], "entities": [{"text": "Semantic prosody", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8046445548534393}]}, {"text": "In this work, we demonstrate that statistical approaches that exploit this very concept of semantic prosody can successfully infer connotative polarity of words.", "labels": [], "entities": []}, {"text": "Having described the key linguistic insight, we now illustrate our graph-based algorithms.", "labels": [], "entities": []}, {"text": "depicts the mutually reinforcing relation between connotative predicates (nodes on the left-hand side) and words with connotative polarity (node on the right-hand side).", "labels": [], "entities": []}, {"text": "The thickness of edges represents the strength of the association between predicates and arguments.", "labels": [], "entities": []}, {"text": "For brevity, we only consider connotation of words that appear in the THEME thematic role.", "labels": [], "entities": [{"text": "THEME thematic", "start_pos": 70, "end_pos": 84, "type": "TASK", "confidence": 0.5335543155670166}]}, {"text": "We expect that words that appear often in the THEME role of various positively (or negatively) connotative predicates are likely to be words with positive (or negative) connotation.", "labels": [], "entities": [{"text": "THEME", "start_pos": 46, "end_pos": 51, "type": "METRIC", "confidence": 0.5345248579978943}]}, {"text": "Likewise, predicates whose THEME contains words with mostly positive (or negative) connotation are likely to be positively (or negatively) connotative predicates.", "labels": [], "entities": []}, {"text": "In short, we can induce the connotative polarity of words using connotative predicates, and inversely, we can learn new connotative predicates based on words with connotative polarity.", "labels": [], "entities": []}, {"text": "We hypothesize that this mutually reinforcing re- lation between connotative predicates and their arguments can be captured via graph centrality in graph-based algorithms.", "labels": [], "entities": []}, {"text": "Given a small set of seed words for connotative predicates, our algorithms collectively learn connotation lexicon together with connotative predicates in a nearly unsupervised manner.", "labels": [], "entities": []}, {"text": "A number of different graph representations are explored using both PageRank () and HITS algorithms.", "labels": [], "entities": []}, {"text": "Empirical study demonstrates that our graph based algorithms are highly effective in learning both connotation lexicon and connotative predicates.", "labels": [], "entities": []}, {"text": "Finally, we quantify the practical value of our connotation lexicon in concrete sentiment analysis applications, and demonstrate that the connotation lexicon is of great value for sentiment classification tasks complementing conventional sentiment lexicons.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.7960827350616455}, {"text": "sentiment classification", "start_pos": 180, "end_pos": 204, "type": "TASK", "confidence": 0.8332942128181458}]}], "datasetContent": [{"text": "As a baseline, we use a simple method dubbed FREQ, which uses co-occurrence frequency with respect to the seed predicates.", "labels": [], "entities": [{"text": "FREQ", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.969093918800354}]}, {"text": "Using the pattern [] n\u22122 [a] (see Section 6), we collect two sets of n-gram records: one set using the positive connotative predicates, and the other using the negative connotative predicates.", "labels": [], "entities": []}, {"text": "With respect to each set, we calculate the following for each word a, We then obtain the score \u03c3 a + for positive connotation and \u03c3 a \u2212 for negative connotation using the following equations that take a linear combination off 1, f 2, and f 3 that we computed above with respect to each polarity.", "labels": [], "entities": []}, {"text": "Note that the coefficients \u03b1, \u03b2 and \u03b3 are determined experimentally.", "labels": [], "entities": []}, {"text": "We assign positive polarity to the word a, if \u03c3 a + >> \u03c3 a \u2212 and vice versa.", "labels": [], "entities": []}, {"text": "Next we perform extrinsic evaluation to quantify the practical value of our connotation lexicon in concrete sentiment analysis applications.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 108, "end_pos": 126, "type": "TASK", "confidence": 0.7617081701755524}]}, {"text": "In particular, we make use of our connotation lexicon for binary sentiment classification tasks in two different ways: \u2022 Unsupervised classification by voting.", "labels": [], "entities": [{"text": "binary sentiment classification tasks", "start_pos": 58, "end_pos": 95, "type": "TASK", "confidence": 0.7545127719640732}, {"text": "Unsupervised classification", "start_pos": 121, "end_pos": 148, "type": "TASK", "confidence": 0.5724417269229889}]}, {"text": "We definer as the ratio of positive polarity words to negative polarity words in the lexicon.", "labels": [], "entities": []}, {"text": "In our experiment, penalty is 0 for positive and \u22120.5 for negative.", "labels": [], "entities": [{"text": "penalty", "start_pos": 19, "end_pos": 26, "type": "METRIC", "confidence": 0.9786800146102905}]}, {"text": "score(x + ) = 1 + penalty + (r, #positive) \u2022 Supervised classification using SVM.", "labels": [], "entities": [{"text": "Supervised classification", "start_pos": 45, "end_pos": 70, "type": "TASK", "confidence": 0.47648759186267853}, {"text": "SVM", "start_pos": 77, "end_pos": 80, "type": "DATASET", "confidence": 0.8374152779579163}]}, {"text": "We use bag-of-words features for baseline.", "labels": [], "entities": []}, {"text": "In order to quantify the effect of different lexicons, we add additional features based on the following scores as defined below: The two corpora we use are SemEval2007 and Sentiment Twitter.", "labels": [], "entities": []}, {"text": "The Twitter dataset consists of tweets containing either a smiley emoticon (representing positive sentiment) or a frowny emoticon (representing negative sentiment), we randomly select 50000 smiley tweets and 50000 frowny tweets.", "labels": [], "entities": []}, {"text": "We perform a 5-fold cross validation.", "labels": [], "entities": []}, {"text": "In, we find very promising results, particularly for Twitter dataset, which is known to be very noisy.", "labels": [], "entities": [{"text": "Twitter dataset", "start_pos": 53, "end_pos": 68, "type": "DATASET", "confidence": 0.9383146166801453}]}, {"text": "Notice that the use of Top 6k words from our connotation lexicon along with OpinionFinder lexicon boost the performance up to 78.0%, which is significantly better than than 71.4% using only the conventional OpinionFinder lexicon.", "labels": [], "entities": []}, {"text": "This result shows that our connotation lexicon nicely complements existing sentiment lexicon, improving practical sentiment analysis tasks.: Twitter Classification Result(%) -() denotes that all features in the previous row are copied over.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.8172523081302643}]}, {"text": "In order to measure the quality of the connotation lexicon, we also perform human judgment study on a subset of the lexicon.", "labels": [], "entities": []}, {"text": "Human judges are asked to quantify the degree of connotative polarity of each given word using an integer value between 1 and 5, where 1 and 5 correspond to the most negative and positive connotation respectively.", "labels": [], "entities": []}, {"text": "When computing the annotator agreement score or evaluating our connotation lexicon against human judgment, we consolidate 1 and 2 into a single negative class and 4 and 5 into a single positive class.", "labels": [], "entities": []}, {"text": "The Kappa score between two human annotators is 0.78.", "labels": [], "entities": [{"text": "Kappa score", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9832018911838531}]}, {"text": "As a control set, we also include 100 words taken from the General Inquirer lexicon: 50 words with positive sentiment, and 50 words with negative sentiment.", "labels": [], "entities": [{"text": "General Inquirer lexicon", "start_pos": 59, "end_pos": 83, "type": "DATASET", "confidence": 0.8914920091629028}]}, {"text": "These words are included so as to measure the quality of human judgment against a wellestablished sentiment lexicon.", "labels": [], "entities": []}, {"text": "The words were presented in a random order so that the human judges will not know which words are from the General Inquirer lexicon and which are from our connotative lexicon.", "labels": [], "entities": [{"text": "General Inquirer lexicon", "start_pos": 107, "end_pos": 131, "type": "DATASET", "confidence": 0.8858372966448466}]}, {"text": "For the words in the control set, the annotators achieved 94% (97% lenient) accuracy on the positive set and 97% on the negative set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9931381344795227}]}, {"text": "Note that some words appear in both positive and negative connotation graphs, while others appear in only one of them.", "labels": [], "entities": []}, {"text": "For instance, if a given word x appears as an argument for only positive connotative predicates, but never for negative ones, then x would appear only in the positive connotation graph.", "labels": [], "entities": []}, {"text": "This means that for such word, we can assume the connotative polarity even without applying the algorithms for graph centrality.", "labels": [], "entities": []}, {"text": "Therefore, we first evaluate the accuracy of the polarity of such words that appear only in one of the connotation graphs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.999396562576294}]}, {"text": "We discard words with low frequency (300 in terms of Google n-gram frequency), and randomly select 50 words from each polarity.", "labels": [], "entities": []}, {"text": "The accuracy of such words is 88% by strict evaluation and 94.5% by lenient evaluation, where lenient evaluation counts words in our polarized connotation lexicon to be correct if the human judges assign non-conflicting polarities, i.e., either neutral or identical polarity.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9992751479148865}]}, {"text": "For words that appear in both positive and negative connotation graphs, we determine the final polarity of such words as one with higher scores given by HITS or PageRank.", "labels": [], "entities": [{"text": "HITS", "start_pos": 153, "end_pos": 157, "type": "DATASET", "confidence": 0.8796981573104858}, {"text": "PageRank", "start_pos": 161, "end_pos": 169, "type": "DATASET", "confidence": 0.9319889545440674}]}, {"text": "We randomly select words that rank at 5% of top 100, top 1000, top 2000, and top 5000 by each algorithm for human judgment.", "labels": [], "entities": []}, {"text": "We only evaluate the top performing algorithms -HITS-aT and Page-aF -and FREQ baseline.", "labels": [], "entities": [{"text": "HITS-aT", "start_pos": 48, "end_pos": 55, "type": "METRIC", "confidence": 0.4725160002708435}, {"text": "FREQ", "start_pos": 73, "end_pos": 77, "type": "METRIC", "confidence": 0.9966171383857727}]}, {"text": "The stratified performance for each of these methods is given in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Comparison Result with General Inquirer Lexicon(%)", "labels": [], "entities": [{"text": "Comparison Result", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7274638712406158}, {"text": "General Inquirer Lexicon", "start_pos": 33, "end_pos": 57, "type": "DATASET", "confidence": 0.8174204428990682}]}, {"text": " Table 4: Comparison Result with OpinionFinder (%)", "labels": [], "entities": [{"text": "Comparison Result", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7256430089473724}]}, {"text": " Table 7: SemEval Classification Result(%) -() denotes  that all features in the previous row are copied over.", "labels": [], "entities": [{"text": "SemEval Classification Result", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.7395763297875723}]}, {"text": " Table 8: Twitter Classification Result(%) -() denotes  that all features in the previous row are copied over.", "labels": [], "entities": [{"text": "Twitter Classification", "start_pos": 10, "end_pos": 32, "type": "DATASET", "confidence": 0.8469395935535431}, {"text": "Result", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.4623427987098694}]}, {"text": " Table 9: Human Annotation Accuracies(%) -Str. de- notes strict evaluation & Len. denotes lenient evaluation.", "labels": [], "entities": [{"text": "Annotation Accuracies", "start_pos": 16, "end_pos": 37, "type": "METRIC", "confidence": 0.6362391114234924}]}]}