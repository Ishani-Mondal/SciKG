{"title": [{"text": "Reducing Grounded Learning Tasks to Grammatical Inference", "labels": [], "entities": [{"text": "Grammatical Inference", "start_pos": 36, "end_pos": 57, "type": "TASK", "confidence": 0.6538669466972351}]}], "abstractContent": [{"text": "It is often assumed that 'grounded' learning tasks are beyond the scope of grammatical inference techniques.", "labels": [], "entities": []}, {"text": "In this paper, we show that the grounded task of learning a semantic parser from ambiguous training data as discussed in Kim and Mooney (2010) can be reduced to a Probabilistic Context-Free Grammar learning task in away that gives state of the art results.", "labels": [], "entities": []}, {"text": "We further show that additionally letting our model learn the lan-guage's canonical word order improves its performance and leads to the highest semantic parsing f-scores previously reported in the literature.", "labels": [], "entities": [{"text": "semantic parsing f-scores", "start_pos": 145, "end_pos": 170, "type": "TASK", "confidence": 0.7179387807846069}]}], "introductionContent": [{"text": "One of the most fundamental ideas about language is that we use it to express our thoughts.", "labels": [], "entities": []}, {"text": "Learning a natural language, then, amounts to (at least) learning a mapping between the things we utter and the things we think, and can therefore be seen as the task of learning a semantic parser, i.e. something that maps natural language expressions such as sentences into meaning representations such as logical forms.", "labels": [], "entities": []}, {"text": "Obviously, this learning can neither take place in a fully supervised nor in a fully unsupervised fashion: the learner does not 'hear' the meanings of the sentences she observes, but she is also not treating them as merely meaningless strings.", "labels": [], "entities": []}, {"text": "Rather, it seems plausible to assume that she uses extra-linguistic context The source code used for our experiments and the evaluation is available as supplementary material for this article.", "labels": [], "entities": []}, {"text": "to assign certain meanings to the linguistic input she is confronted with.", "labels": [], "entities": []}, {"text": "In this sense, learning a semantic parser seems to go beyond the well-studied task of unsupervised grammar induction.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 99, "end_pos": 116, "type": "TASK", "confidence": 0.7682658433914185}]}, {"text": "It involves not only learning a grammar for the form-side of language, i.e. language expressions such as sentences, but also the 'grounding' of this structure in meaning representations.", "labels": [], "entities": []}, {"text": "It requires going beyond the mere linguistic input to incorporate, for example, perceptual information that provides a clue to the meaning of the observed forms.", "labels": [], "entities": []}, {"text": "Essentially, it seems as if 'grounded' learning tasks like this require dealing with two different kinds of information, the purely formal (phonemic) and meaningful (semantic) aspects of language.", "labels": [], "entities": []}, {"text": "Grammatical inference seems to be limited to dealing with one level of formal information).", "labels": [], "entities": [{"text": "Grammatical inference", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8415005803108215}]}, {"text": "For this reason, probably, approaches to the task of learning a semantic parser employ a variety of sophisticated and task-specific techniques that go beyond (but often elaborate on) the techniques used for grammatical inference (.", "labels": [], "entities": []}, {"text": "In this paper, we show that one can reduce the task of learning a semantic parser to a Probabilistic Context Free Grammar (PCFG) learning task, and more generally, that grounded learning tasks are not in principle beyond the scope of grammatical inference techniques.", "labels": [], "entities": []}, {"text": "In particular, we show how to formulate the task of learning a semantic parser as discussed by Chen, as the task of learning a PCFG from strings.", "labels": [], "entities": []}, {"text": "Our model does not only constitute a proof of concept that this reduction is possible for certain cases, it also yields highly competitive results.", "labels": [], "entities": []}, {"text": "By reducing the problem to the well understood PCFG formalism, it also becomes easy to consider extensions, leading to our second contribution.", "labels": [], "entities": []}, {"text": "We demonstrate that a slight modification to our model so that it also learns the language's canonical word order improves its performance even beyond the best results previously reported in the literature.", "labels": [], "entities": []}, {"text": "This language-independent and linguistically well motivated elaboration allows the model to learn a global fact about the language's syntax, its canonical word order.", "labels": [], "entities": []}, {"text": "We provide an illustration of how to reduce grounded learning tasks to grammatical inference.", "labels": [], "entities": []}, {"text": "Secondly, we show that extending the model so that it can learn linguistically well motivated generalizations such as the canonical word order can lead to better results.", "labels": [], "entities": []}, {"text": "The structure of the paper is as follows.", "labels": [], "entities": []}, {"text": "First we give a short overview of the previous work by Chen, Kim and Mooney and describe their dataset.", "labels": [], "entities": []}, {"text": "Then, we show how to reduce the parsing task addressed by them to a PCFG-learning task.", "labels": [], "entities": [{"text": "parsing task", "start_pos": 32, "end_pos": 44, "type": "TASK", "confidence": 0.8943524360656738}]}, {"text": "Finally, we explain how to let our model additionally learn the language's canonical word order.", "labels": [], "entities": []}], "datasetContent": [{"text": "The CFG described in the previous section is trained on the same training data used by KM, except that we reduce it to strings (without changing the information present in the original data) by prefixing every sentence with a context-identifier.", "labels": [], "entities": [{"text": "CFG", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.9063421487808228}]}, {"text": "For training we run the Inside-Outside algorithm 8 with uniform initialization weights until convergence.", "labels": [], "entities": []}, {"text": "For English, this results in an average number of 76 iterations for each fold, for Korean the average number of iterations is 50.", "labels": [], "entities": []}, {"text": "To deal with the fact that the model might not observe certain meanings during training, we apply a simple smoothing technique by using a Dirichlet prior of \u03b1=0.1 on the rule probabilities.", "labels": [], "entities": []}, {"text": "In effect, this provides our system with a small number of pseudo-observations for each rule which prevents the automatic assignment of zero probability to rules not used during training.", "labels": [], "entities": []}, {"text": "For parsing, the resulting PCFG is slightly modified by removing the context-identifiers.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9785999655723572}, {"text": "PCFG", "start_pos": 27, "end_pos": 31, "type": "DATASET", "confidence": 0.9231734871864319}]}, {"text": "This is done because the task of a semantic parser is to establish a mapping between NLs and MRs, irrespective of contexts which were only used for learning the parser and should not play a role in its final performance.", "labels": [], "entities": []}, {"text": "To do this, we add up the probability of all rules which differ only in the context-identifier which can bethought of as marginalizing out the different contexts, giving our first model which we call NoWo-PCFG.", "labels": [], "entities": [{"text": "NoWo-PCFG", "start_pos": 200, "end_pos": 209, "type": "DATASET", "confidence": 0.9592443108558655}]}, {"text": "Note that the context-deletion (and the simple smoothing) enables NoWo-PCFG to parse sentences into meanings not present in the data it was trained on which, in fact, happens.", "labels": [], "entities": []}, {"text": "For example, there are 81 meanings in the training data for the first English We experimented with \u03b1=0.1, \u03b1=0.5 and \u03b1=1.0 and found that overall, 0.1 yields the best results.", "labels": [], "entities": []}, {"text": "We also tried jittering the initial rule weights during training and found that our results are very robust and seem to be independent of a specific initialization.", "labels": [], "entities": []}, {"text": "10 NoWo because this model, unlike the one described in Section 4, does not make explicit use of word order generalisations.", "labels": [], "entities": [{"text": "NoWo", "start_pos": 3, "end_pos": 7, "type": "DATASET", "confidence": 0.9553399682044983}]}, {"text": "match that are not present in any of the other games' training data.", "labels": [], "entities": []}, {"text": "The PCFG trained on games 2, 3 and 4 is still able to correctly assign 12 of those 81 meanings which it has not seen during the training phase which shows the effectiveness of the bottom-up constraint.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.953309953212738}]}, {"text": "For evaluation, we employ 4-fold cross validation as described in detail in and used by KM: the model is trained on all possible combinations of 3 of the 4 games and is then used to produce an MR for all sentences of the held-out game for which there is a matching gold-standard meaning.", "labels": [], "entities": [{"text": "MR", "start_pos": 193, "end_pos": 195, "type": "METRIC", "confidence": 0.9919614195823669}]}, {"text": "For an NL W, our model produces an MR m by finding the most probable parse of W with the CKY algorithm and reading off mat the Sm -node.", "labels": [], "entities": [{"text": "MR m", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.9726638197898865}]}, {"text": "An MR is considered correct if and only if it matches the gold-standard MR exactly; the final evaluation result is averaged overall 4 folds.", "labels": [], "entities": [{"text": "MR", "start_pos": 3, "end_pos": 5, "type": "METRIC", "confidence": 0.9760512709617615}]}, {"text": "Our evaluation results for NoWo-PCFG are given in.", "labels": [], "entities": [{"text": "NoWo-PCFG", "start_pos": 27, "end_pos": 36, "type": "DATASET", "confidence": 0.9266440272331238}]}, {"text": "All scores are reported in F-measure which is the harmonic mean of Precision and Recall.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9982386827468872}, {"text": "Precision", "start_pos": 67, "end_pos": 76, "type": "METRIC", "confidence": 0.959756076335907}, {"text": "Recall", "start_pos": 81, "end_pos": 87, "type": "METRIC", "confidence": 0.859457790851593}]}, {"text": "In this specific case, precision is the fraction of correct parses out: A summary of results for the parsing task, in Fmeasure.", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9992631077766418}, {"text": "parsing task", "start_pos": 101, "end_pos": 113, "type": "TASK", "confidence": 0.9145794808864594}, {"text": "Fmeasure", "start_pos": 118, "end_pos": 126, "type": "DATASET", "confidence": 0.9041197896003723}]}, {"text": "We also show the results of, as given in , which to our knowledge are the highest previously reported scores for Korean.", "labels": [], "entities": []}, {"text": "WO-PCFG, described in Section 4 performs better than all previously reported models, but only slightly so for Korean. of the total number of parses the model returns.", "labels": [], "entities": [{"text": "WO-PCFG", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.7696900367736816}]}, {"text": "Recall is the fraction of correct parses out of the total number of test sentences.", "labels": [], "entities": [{"text": "Recall", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9937970638275146}]}, {"text": "NoWo-PCFG performs a little worse than KM's model.", "labels": [], "entities": [{"text": "NoWo-PCFG", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9371138215065002}]}, {"text": "Its scores are virtually identical for English (0.742) and worse for Korean (0.718 vs 0.764).", "labels": [], "entities": []}, {"text": "We are not sure as to why our model performs worse on the Korean data, but it might have to do with the fact that the Korean average ambiguity is higher than for the English data.", "labels": [], "entities": [{"text": "Korean average ambiguity", "start_pos": 118, "end_pos": 142, "type": "METRIC", "confidence": 0.5247316062450409}]}, {"text": "This shows that it is not only possible to reduce the task of learning a semantic parser to standard grammatical inference, but that this way of approaching the problem yields comparable results.", "labels": [], "entities": []}, {"text": "The remainder of the paper focuses on our second main point: that letting the model learn additional kinds of information, such as the language's canonical word order, can further improve its performance.", "labels": [], "entities": []}, {"text": "In order to do this we propose a model that learns the word order as well as the mapping from NLs to MRs, and compare its performance to that of the other models.", "labels": [], "entities": []}, {"text": "Training and evaluating WO-PCFG in exactly the same way as the previous grammar gives an Fmeasure of 0.860 for English and an F-measure of 0.829 for Korean.", "labels": [], "entities": [{"text": "WO-PCFG", "start_pos": 24, "end_pos": 31, "type": "DATASET", "confidence": 0.6480672359466553}, {"text": "Fmeasure", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9990372657775879}, {"text": "F-measure", "start_pos": 126, "end_pos": 135, "type": "METRIC", "confidence": 0.9957172274589539}]}, {"text": "Those scores are, to our knowledge, the highest scores previously reported for this parsing task and establish our second main point: letting the model learn the language's word order in addition to learning the mapping from sentences to MR increases semantic parsing accuracy.", "labels": [], "entities": [{"text": "parsing task", "start_pos": 84, "end_pos": 96, "type": "TASK", "confidence": 0.910501629114151}, {"text": "semantic parsing", "start_pos": 251, "end_pos": 267, "type": "TASK", "confidence": 0.7132110148668289}, {"text": "accuracy", "start_pos": 268, "end_pos": 276, "type": "METRIC", "confidence": 0.9251871705055237}]}, {"text": "An intuitive explanation for the increase in performance is that by allowing the model to learn word order, we are providing it with anew dimension along which it can generalize.", "labels": [], "entities": []}, {"text": "In this sense, we can look at our refinement as providing the model with abstract linguistic knowledge, namely that languages tend to have a canon-14's model can be seen as capturing something similar to our word order generalization with the help of a Field Choice Model which primarily captures discourse coherence and salience properties.", "labels": [], "entities": [{"text": "word order generalization", "start_pos": 208, "end_pos": 233, "type": "TASK", "confidence": 0.6573391656080881}]}, {"text": "It differs, however, in that it can only learn one generalization for each predicate type and no language wide generalization.", "labels": [], "entities": []}, {"text": "The usefulness of this kind of information is impressive -for English, it improves the accuracy of semantic parsing by almost 12% in F-measure and for Korean by 11.1%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.999473512172699}, {"text": "semantic parsing", "start_pos": 99, "end_pos": 115, "type": "TASK", "confidence": 0.6601529717445374}, {"text": "F-measure", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.8418598175048828}]}, {"text": "In addition, our model correctly learns that English's predominant word order is SVO and that Korean is predominantly SOV, assigning by far the highest probability to the corresponding Root rewrite rule (0.91 for English and 0.98 for Korean).", "labels": [], "entities": []}, {"text": "This kind of information is useful in its own right and could, for example, be exploited by coupling word order with other linguistic properties, perhaps following's implicational universals.", "labels": [], "entities": []}, {"text": "In this sense, the reduction of grounded learning problems to grammatical inference does not only make possible the application of a wide variety of tools and insights developed over years of research, it might also make it easier to bring abstract (and not so abstract) linguistic knowledge to bear on those tasks.", "labels": [], "entities": []}, {"text": "The overall slightly worse performance of our system on Korean data might stem from the fact that Korean, unlike English, has a rich morphology, and that our model does not learn anything about morphology at all.", "labels": [], "entities": []}, {"text": "We plan on further investigating effects like this in the future, as well as applying more advanced grammatical inference algorithms.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics for the Korean and the English datasets. The numbers are basically identical to those reported in", "labels": [], "entities": [{"text": "English datasets", "start_pos": 44, "end_pos": 60, "type": "DATASET", "confidence": 0.7220959961414337}]}, {"text": " Table 2: A summary of results for the parsing task, in F- measure. We also show the results of", "labels": [], "entities": [{"text": "parsing task", "start_pos": 39, "end_pos": 51, "type": "TASK", "confidence": 0.9169421494007111}, {"text": "F- measure", "start_pos": 56, "end_pos": 66, "type": "METRIC", "confidence": 0.9718679587046305}]}]}