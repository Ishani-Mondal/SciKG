{"title": [{"text": "A Joint Model for Extended Semantic Role Labeling", "labels": [], "entities": [{"text": "Extended Semantic Role Labeling", "start_pos": 18, "end_pos": 49, "type": "TASK", "confidence": 0.5842123851180077}]}], "abstractContent": [{"text": "This paper presents a model that extends semantic role labeling.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.712427536646525}]}, {"text": "Existing approaches independently analyze relations expressed by verb predicates or those expressed as nominal-izations.", "labels": [], "entities": []}, {"text": "However, sentences express relations via other linguistic phenomena as well.", "labels": [], "entities": []}, {"text": "Furthermore , these phenomena interact with each other, thus restricting the structures they articulate.", "labels": [], "entities": []}, {"text": "In this paper, we use this intuition to define a joint inference model that captures the inter-dependencies between verb semantic role labeling and relations expressed using prepositions.", "labels": [], "entities": [{"text": "verb semantic role labeling", "start_pos": 116, "end_pos": 143, "type": "TASK", "confidence": 0.6611903160810471}]}, {"text": "The scarcity of jointly labeled data presents a crucial technical challenge for learning a joint model.", "labels": [], "entities": []}, {"text": "The key strength of our model is that we use existing structure predictors as black boxes.", "labels": [], "entities": []}, {"text": "By enforcing consistency constraints between their predictions, we show improvements in the performance of both tasks without retraining the individual models.", "labels": [], "entities": []}], "introductionContent": [{"text": "The identification of semantic relations between sentence constituents has been an important task in NLP research.", "labels": [], "entities": [{"text": "identification of semantic relations between sentence constituents", "start_pos": 4, "end_pos": 70, "type": "TASK", "confidence": 0.8423400606427874}]}, {"text": "It finds applications in various natural language understanding tasks that require complex inference going beyond the surface representation.", "labels": [], "entities": [{"text": "natural language understanding", "start_pos": 33, "end_pos": 63, "type": "TASK", "confidence": 0.6714330911636353}]}, {"text": "In the literature, semantic role extraction has been studied mostly in the context of verb predicates, using the Propbank annotation of, and also for nominal predicates, using the Nombank corpus of.", "labels": [], "entities": [{"text": "semantic role extraction", "start_pos": 19, "end_pos": 43, "type": "TASK", "confidence": 0.767759641011556}, {"text": "Nombank corpus", "start_pos": 180, "end_pos": 194, "type": "DATASET", "confidence": 0.9013732671737671}]}, {"text": "However, sentences express semantic relations through other linguistic phenomena.", "labels": [], "entities": []}, {"text": "For example, consider the following sentence: (1) The field goal by Brien changed the game in the fourth quarter.", "labels": [], "entities": []}, {"text": "Verb centered semantic role labeling would identify the arguments of the predicate change as (a) The field goal by Brien (A0, the causer of the change), (b) the game (A1, the thing changing), and (c) in the fourth quarter (temporal modifier).", "labels": [], "entities": [{"text": "Verb centered semantic role labeling", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.5772602915763855}]}, {"text": "However, this does not tell us that the scorer of the field goal was Brien, which is expressed by the preposition by.", "labels": [], "entities": []}, {"text": "Also, note that the in indicates a temporal relation, which overlaps with the verb's analysis.", "labels": [], "entities": []}, {"text": "In this paper, we propose an extension of the standard semantic role labeling task to include relations expressed by lexical items other than verbs and nominalizations.", "labels": [], "entities": [{"text": "semantic role labeling task", "start_pos": 55, "end_pos": 82, "type": "TASK", "confidence": 0.7572231441736221}]}, {"text": "Further, we argue that there are interactions between the different phenomena which suggest that there is a benefit in studying them together.", "labels": [], "entities": []}, {"text": "However, one key challenge is that large jointly labeled corpora do not exist.", "labels": [], "entities": []}, {"text": "This motivates the need for novel learning and inference schemes that address the data problem and can still benefit from the interactions among the phenomena.", "labels": [], "entities": []}, {"text": "This paper has two main contributions.", "labels": [], "entities": []}, {"text": "1. From the machine learning standpoint, we propose a joint inference scheme to combine existing structure predictors for multiple linguistic phenomena.", "labels": [], "entities": []}, {"text": "We do so using hard constraints that involve only the labels of the phenomena.", "labels": [], "entities": []}, {"text": "The strength of our model is that it is easily extensible, since adding new phenomena does not require fully retraining the joint model from scratch.", "labels": [], "entities": []}, {"text": "Furthermore, our approach minimizes the need for extensive jointly labeled corpora and, instead, uses existing predictors as black boxes.", "labels": [], "entities": []}, {"text": "2. From an NLP perspective, we motivate the extension of semantic role labeling beyond verbs and nominalizations.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.7219734390576681}]}, {"text": "We instantiate our joint model for the case of extracting preposition and verb relations together.", "labels": [], "entities": [{"text": "extracting preposition and verb relations", "start_pos": 47, "end_pos": 88, "type": "TASK", "confidence": 0.7927851676940918}]}, {"text": "Our model uses existing systems that identify verb semantic roles and preposition object roles and jointly predicts the output of the two systems in the presence of linguistic constraints that enforce coherence between the predictions.", "labels": [], "entities": []}, {"text": "We show that using constraints to combine models improves the performance on both tasks.", "labels": [], "entities": []}, {"text": "Furthermore, since the constraints depend only on the labels of the two tasks and not on any specific dataset, our experiments also demonstrate that enforcing them allows for better domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 182, "end_pos": 199, "type": "TASK", "confidence": 0.7084587067365646}]}, {"text": "The rest of the paper is organized as follows: We motivate the need for extending semantic role labeling and the necessity for joint inference in Section 2.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 82, "end_pos": 104, "type": "TASK", "confidence": 0.685817281405131}]}, {"text": "In Section 3, we describe the component verb SRL and preposition role systems.", "labels": [], "entities": []}, {"text": "The global model is defined in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 provides details on the coherence constraints we use and demonstrates the effectiveness of the joint model through experiments.", "labels": [], "entities": []}, {"text": "Section 6 discusses our approach in comparison to existing work and Section 7 provides concluding remarks.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe our experimental setup and evaluate the performance of our approach.", "labels": [], "entities": []}, {"text": "The research question addressed by the experiments is the following: Given independently trained systems for verb SRL and preposition roles, can their performance be improved using joint inference between the two tasks?", "labels": [], "entities": [{"text": "verb SRL and preposition roles", "start_pos": 109, "end_pos": 139, "type": "TASK", "confidence": 0.7516574501991272}]}, {"text": "To address this, we report the results of the following two experiments: 1.", "labels": [], "entities": []}, {"text": "First, we compare the joint system against the baseline systems and with pipelines in both directions.", "labels": [], "entities": []}, {"text": "In this setting, both base systems are trained on the Penn Treebank data.", "labels": [], "entities": [{"text": "Penn Treebank data", "start_pos": 54, "end_pos": 72, "type": "DATASET", "confidence": 0.9955511490503947}]}, {"text": "2. Second, we show that using joint inference can provide strong a performance gain even when the underlying systems are trained on different domains.", "labels": [], "entities": []}, {"text": "In all experiments, we report the F1 measure for the verb SRL performance using the evaluation metric and the accuracy for the preposition role labeling task.", "labels": [], "entities": [{"text": "F1 measure", "start_pos": 34, "end_pos": 44, "type": "METRIC", "confidence": 0.9819254279136658}, {"text": "accuracy", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9993236064910889}, {"text": "preposition role labeling task", "start_pos": 127, "end_pos": 157, "type": "TASK", "confidence": 0.6940656006336212}]}], "tableCaptions": [{"text": " Table 2: Preposition sense performance. This table re- ports accuracy of sense prediction on the prepositions that  have been annotated for the Penn Treebank dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.9990646243095398}, {"text": "Penn Treebank dataset", "start_pos": 145, "end_pos": 166, "type": "DATASET", "confidence": 0.995431919892629}]}, {"text": " Table 3: Preposition role data statistics for the Penn Tree- bank preposition dataset.", "labels": [], "entities": [{"text": "Penn Tree- bank preposition dataset", "start_pos": 51, "end_pos": 86, "type": "DATASET", "confidence": 0.9876355628172556}]}, {"text": " Table 4: Performance of the joint system, compared to  the individual systems and the pipelines. All performance  measures are reported on Section 23 of the Penn Tree- bank. The verb SRL systems were trained on sections  2-21, while the preposition role classifiers were trained  on sections 2-4. For the joint inference system, the scal- ing parameters were trained on the first 500 sentences of  section 2, which were held out. All the improvements in  this table are statistically significant at the 0.05 level.", "labels": [], "entities": [{"text": "Section 23 of the Penn Tree- bank", "start_pos": 140, "end_pos": 173, "type": "DATASET", "confidence": 0.9401078075170517}]}]}