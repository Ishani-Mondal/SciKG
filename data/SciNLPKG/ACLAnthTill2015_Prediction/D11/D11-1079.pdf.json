{"title": [{"text": "Soft Dependency Constraints for Reordering in Hierarchical Phrase-Based Translation", "labels": [], "entities": [{"text": "Hierarchical Phrase-Based Translation", "start_pos": 46, "end_pos": 83, "type": "TASK", "confidence": 0.5905588765939077}]}], "abstractContent": [{"text": "Long-distance reordering remains one of the biggest challenges facing machine translation.", "labels": [], "entities": [{"text": "Long-distance reordering", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7308473587036133}, {"text": "machine translation", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.7736226320266724}]}, {"text": "We derive soft constraints from the source dependency parsing to directly address the reordering problem for the hierarchical phrase-based model.", "labels": [], "entities": [{"text": "source dependency parsing", "start_pos": 36, "end_pos": 61, "type": "TASK", "confidence": 0.7610233028729757}]}, {"text": "Our approach significantly improves Chinese-English machine translation on a large-scale task by 0.84 BLEU points on average.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.6451142579317093}, {"text": "BLEU", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.9996048808097839}]}, {"text": "Moreover, when we switch the tuning function from BLEU to the LRscore which promotes reordering, we observe total improvements of 1.21 BLEU, 1.30 LRscore and 3.36 TER over the baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.9975392818450928}, {"text": "LRscore", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.9241871237754822}, {"text": "BLEU", "start_pos": 135, "end_pos": 139, "type": "METRIC", "confidence": 0.9982934594154358}, {"text": "LRscore", "start_pos": 146, "end_pos": 153, "type": "METRIC", "confidence": 0.9654284715652466}, {"text": "TER", "start_pos": 163, "end_pos": 166, "type": "METRIC", "confidence": 0.9986039996147156}]}, {"text": "On average our approach improves reordering precision and recall by 6.9 and 0.3 absolute points, respectively, and is found to be especially effective for long-distance reodering.", "labels": [], "entities": [{"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9827612042427063}, {"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9996496438980103}]}], "introductionContent": [{"text": "Reordering, especially movement over longer distances, continues to be a hard problem in statistical machine translation.", "labels": [], "entities": [{"text": "Reordering", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.9246023893356323}, {"text": "statistical machine translation", "start_pos": 89, "end_pos": 120, "type": "TASK", "confidence": 0.7156187693277994}]}, {"text": "It motivates much of the recent work on tree-based translation models, such as the hierarchical phrase-based model which extends the phrase-based model ( by allowing the so-called hierarchical phrases containing subphrases.", "labels": [], "entities": []}, {"text": "The hierarchical phrase-based model captures the recursiveness of language without relying on syntactic annotation, and promises better reordering than the phrase-based model.", "labels": [], "entities": []}, {"text": "However, find that although the hierarchical phrasebased model outperforms the phrase-based model in terms of medium-range reordering, it does equally poorly in long-distance reordering due to constraints to guarantee efficiency.", "labels": [], "entities": []}, {"text": "Syntax-based models that use phrase structure constituent labels as non-terminals in their transfer rules, exemplified by that of, produce smarter and syntactically motivated reordering.", "labels": [], "entities": []}, {"text": "However, when working with off-the-shelf tools for parsing and alignment, this approach may impose harsh limits on rule extraction and requires serious efforts of optimization ().", "labels": [], "entities": [{"text": "parsing and alignment", "start_pos": 51, "end_pos": 72, "type": "TASK", "confidence": 0.6898213624954224}, {"text": "rule extraction", "start_pos": 115, "end_pos": 130, "type": "TASK", "confidence": 0.8018528819084167}]}, {"text": "An alternative approach is to augment the general hierarchical phrase-based model with soft syntactic constraints.", "labels": [], "entities": []}, {"text": "Here, we derive three word-based, complementary constraints from the source dependency parsing, including: \u2022 A dependency orientation feature, trained with maximum entropy on the word-aligned parallel data, which directly models the headdependent orientation for source words; \u2022 An integer-valued cohesion penalty that complements the dependency orientation feature, and fires when a word is not translated with its head.", "labels": [], "entities": []}, {"text": "It measures derivation well-formedness and is used to indirectly help reordering;", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: The dependency orientation probabilities for  words of the", "labels": [], "entities": []}, {"text": " Table 4: Results for the baseline model and the complete feature-augmented model with 2 bins (\"bin-2\"), using BLEU  and LRscore (\"-lr\") as the tuning function. The BLEU scores of \"bin-2\" and \"bin-2-lr\" are significantly better than  baseline (p < 0.05), computed by paired bootstrap resampling", "labels": [], "entities": [{"text": "BLEU", "start_pos": 111, "end_pos": 115, "type": "METRIC", "confidence": 0.9983240962028503}, {"text": "LRscore", "start_pos": 121, "end_pos": 128, "type": "METRIC", "confidence": 0.9429787397384644}, {"text": "BLEU", "start_pos": 165, "end_pos": 169, "type": "METRIC", "confidence": 0.9977923631668091}]}, {"text": " Table 2: Results of the baseline model as well as our  complete feature-augmented model with 1, 2 and 3 bins.  BLEU is the tuning function.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 112, "end_pos": 116, "type": "METRIC", "confidence": 0.9990516304969788}]}, {"text": " Table 3: Contributions of the three soft dependency con- straints, with the \"bin-2\" setting", "labels": [], "entities": []}, {"text": " Table 5: Overall precision for the test sets.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9983832836151123}]}, {"text": " Table 6: Overall recall for the test sets.", "labels": [], "entities": [{"text": "recall", "start_pos": 18, "end_pos": 24, "type": "METRIC", "confidence": 0.9155964851379395}]}]}