{"title": [{"text": "Compositional Matrix-Space Models for Sentiment Analysis", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.976839005947113}]}], "abstractContent": [{"text": "We present a general learning-based approach for phrase-level sentiment analysis that adopts an ordinal sentiment scale and is explicitly compositional in nature.", "labels": [], "entities": [{"text": "phrase-level sentiment analysis", "start_pos": 49, "end_pos": 80, "type": "TASK", "confidence": 0.8500212033589681}]}, {"text": "Thus, we can model the compositional effects required for accurate assignment of phrase-level sentiment.", "labels": [], "entities": [{"text": "assignment of phrase-level sentiment", "start_pos": 67, "end_pos": 103, "type": "TASK", "confidence": 0.7727334052324295}]}, {"text": "For example, combining an adverb (e.g., \"very\") with a positive polar adjective (e.g., \"good\") produces a phrase (\"very good\") with increased polarity over the adjective alone.", "labels": [], "entities": []}, {"text": "Inspired by recent work on distributional approaches to compositionality, we model each word as a matrix and combine words using iterated matrix multiplication, which allows for the modeling of both additive and multiplicative semantic effects.", "labels": [], "entities": []}, {"text": "Although the multiplication-based matrix-space framework has been shown to be a theoretically elegant way to model composition (Rudolph and Giesbrecht, 2010), training such models has to be done carefully: the optimization is non-convex and requires a good initial starting point.", "labels": [], "entities": []}, {"text": "This paper presents the first such algorithm for learning a matrix-space model for semantic composition.", "labels": [], "entities": [{"text": "semantic composition", "start_pos": 83, "end_pos": 103, "type": "TASK", "confidence": 0.7692780494689941}]}, {"text": "In the context of the phrase-level sentiment analysis task, our experimental results show statistically significant improvements in performance over a bag-of-words model.", "labels": [], "entities": [{"text": "phrase-level sentiment analysis task", "start_pos": 22, "end_pos": 58, "type": "TASK", "confidence": 0.8945237100124359}]}], "introductionContent": [{"text": "Sentiment analysis has been an active research area in recent years.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.981979638338089}]}, {"text": "Work in the area ranges from identifying the sentiment of individual words to determining the sentiment of phrases, sentences and documents (see fora survey).", "labels": [], "entities": [{"text": "identifying the sentiment of individual words", "start_pos": 29, "end_pos": 74, "type": "TASK", "confidence": 0.7917162179946899}]}, {"text": "The bulk of previous research, however, models just positive vs. negative sentiment, collapsing positive (or negative) words, phrases and documents of differing intensities into just one positive (or negative) class.", "labels": [], "entities": []}, {"text": "For word-level sentiment, therefore, these methods would not recognize a difference in sentiment between words like \"good\" and \"great\", which have the same direction of polarity (i.e., positive) but different intensities.", "labels": [], "entities": [{"text": "word-level sentiment", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.6974562704563141}]}, {"text": "At the phrase level, the methods will fail to register compositional effects in sentiment brought about by intensifiers like \"very\", \"absolutely\", \"extremely\", etc.", "labels": [], "entities": []}, {"text": "\"Happy\" and \"very happy\", for example, will both be considered simply \"positive\" in sentiment.", "labels": [], "entities": []}, {"text": "In real-world settings, on the other hand, sentiment values extend across a polarity spectrum -from very negative, to neutral, to very positive.", "labels": [], "entities": []}, {"text": "Recent research has shown, in particular, that modeling intensity at the phrase level is important for real-world natural language processing tasks including question answering and textual entailment.", "labels": [], "entities": [{"text": "question answering", "start_pos": 158, "end_pos": 176, "type": "TASK", "confidence": 0.8321706652641296}, {"text": "textual entailment", "start_pos": 181, "end_pos": 199, "type": "TASK", "confidence": 0.6868809014558792}]}, {"text": "This paper describes a general approach for phrase-level sentiment analysis that takes these realworld requirements into account: we adopt a fivelevel ordinal sentiment scale and present a learningbased method that assigns ordinal sentiment scores to phrases.", "labels": [], "entities": [{"text": "phrase-level sentiment analysis", "start_pos": 44, "end_pos": 75, "type": "TASK", "confidence": 0.8397142887115479}]}, {"text": "Importantly, our approach will also be explicitly compositional 1 in nature so that it can accurately account for critical interactions among the words in each sentiment-bearing phrase.", "labels": [], "entities": []}, {"text": "Consider, for example, combining an adverb like \"very\" with a polar adjective like \"good\".", "labels": [], "entities": []}, {"text": "\"Good\" has an a priori positive sentiment, so \"very good\" should be considered more positive even though \"very\", on its own, does not bear sentiment.", "labels": [], "entities": []}, {"text": "Combining \"very\" with a negative adjective, like \"bad\", produces a phrase (\"very bad\") that should be characterized as more negative than the original adjective.", "labels": [], "entities": []}, {"text": "Thus, it is convenient to think of the effect of combining an intensifying adverb with a polar adjective as being multiplicative in nature, if we assume the adjectives (\"good\" and \"bad\") to have positive and a negative sentiment scores, respectively.", "labels": [], "entities": []}, {"text": "Next, let us consider adverbial negators like \"not\" combined with polar adjectives.", "labels": [], "entities": []}, {"text": "When modeling only positive and negative labels for sentiment, negators are generally treated as flipping the polarity of the adjective it modifies.", "labels": [], "entities": []}, {"text": "However, recent work () suggests that the effect of the negator when ordinal sentiment scores are employed is more akin to dampening the adjective's polarity rather than flipping it.", "labels": [], "entities": []}, {"text": "For example, if \"perfect\" has a strong positive sentiment, then the phrase \"not perfect\" is still positive, though to a lesser degree.", "labels": [], "entities": []}, {"text": "And while \"not terrible\" is still negative, it is less negative than \"terrible\".", "labels": [], "entities": []}, {"text": "For these cases, it is convenient to view \"not\" as shifting polarity to the opposite side of polarity scale by some value.", "labels": [], "entities": []}, {"text": "There are, of course, more interesting examples of compositional semantic effects on sentiment: e.g., prevent cancer, ease the burden.", "labels": [], "entities": []}, {"text": "Here, the verbs prevent and ease act as content-word negators) in that they modify the negative sentiment of their direct object arguments so that the phrase as a whole is perceived as somewhat positive.", "labels": [], "entities": []}, {"text": "Nonetheless, the vast majority of methods for phrase-and sentence-level sentiment analysis do not tackle the task compositionally: they, instead, employ a bag-of-words representation and, at best, incorporate additional features to account for negators, intensifiers, and for contextual valence shifters, which can change the sentiment over neighboring words (e.g.,,  ,,).", "labels": [], "entities": [{"text": "phrase-and sentence-level sentiment analysis", "start_pos": 46, "end_pos": 90, "type": "TASK", "confidence": 0.7082787752151489}, {"text": "contextual valence shifters", "start_pos": 276, "end_pos": 303, "type": "TASK", "confidence": 0.6558815737565359}]}, {"text": "One notable exception is, who propose a compositional semantic approach to assign a positive or negative sentiment to newspaper article titles.", "labels": [], "entities": [{"text": "assign a positive or negative sentiment to newspaper article titles", "start_pos": 75, "end_pos": 142, "type": "TASK", "confidence": 0.6474377334117889}]}, {"text": "However, their knowledgebased approach presupposes the existence of a sentiment lexicon and a set of symbolic compositional rules.", "labels": [], "entities": []}, {"text": "But learning-based compositional approaches for sentiment analyis also exist., for example, propose an algorithm for phrase-based sentiment analysis that learns proper assignments of intermediate sentiment analysis decision variables given the a priori (i.e., out of context) polarity of the words in the phrase and the (correct) phrase-level polarity.", "labels": [], "entities": [{"text": "sentiment analyis", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.876901388168335}, {"text": "phrase-based sentiment analysis", "start_pos": 117, "end_pos": 148, "type": "TASK", "confidence": 0.7835483948389689}]}, {"text": "As in, semantic inference is based on (a small set of) hand-written compositional rules.", "labels": [], "entities": [{"text": "semantic inference", "start_pos": 7, "end_pos": 25, "type": "TASK", "confidence": 0.8065087795257568}]}, {"text": "In contrast, Nakagawa et. al (2010) use a dependency parse tree to guide the learning of compositional effects.", "labels": [], "entities": []}, {"text": "Each of the above, however, uses a binary rather than an ordinal sentiment scale.", "labels": [], "entities": []}, {"text": "In contrast, our proposed method for phraselevel sentiment analysis is inspired by recent work on distributional approaches to compositionality.", "labels": [], "entities": [{"text": "phraselevel sentiment analysis", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.9229685266812643}]}, {"text": "In particular, tackle adjective-noun compositions using a vector representation for nouns and learning a matrix representation for each adjective.", "labels": [], "entities": []}, {"text": "The adjective matrices are then applied as functions over the meanings of nouns -via matrix-vector multiplication -to derive the meaning of adjective-noun combinations.", "labels": [], "entities": []}, {"text": "show theoretically, that multiplicative matrix-space models area general case of vector-space models and furthermore exhibit desirable properties for semantic analysis: they take into account word order and are algebraically, neurologically and psychologically plausible.", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 150, "end_pos": 167, "type": "TASK", "confidence": 0.8987243175506592}]}, {"text": "This work, however, does not present an algorithm for learning such models; nor does it provide empirical evidence in favor of matrix-space models over vector-space models.", "labels": [], "entities": []}, {"text": "In the sections below, we propose a learningbased approach to assign ordinal sentiment scores to sentiment-bearing phrases using a general compositional matrix-space model of language.", "labels": [], "entities": []}, {"text": "In contrast to previous work, all words are modeled as matrices, independent of their part-of-speech, and compositional inference is uniformly modeled as ma-trix multiplication.", "labels": [], "entities": []}, {"text": "To predict an ordinal scale sentiment value, we employ Ordered Logistic Regression, introducing a novel training algorithm to accommodate our compositional matrix-space representations (Section 2).", "labels": [], "entities": []}, {"text": "To our knowledge, this is the first such algorithm for learning matrix-space models for semantic composition.", "labels": [], "entities": [{"text": "semantic composition", "start_pos": 88, "end_pos": 108, "type": "TASK", "confidence": 0.7423941493034363}]}, {"text": "We evaluate the approach on a standard sentiment corpus ( ) (Section 3), making use of its manually annotated phrase-level annotations for polarity and intensity, and compare our approach to the more commonly employed bag-of-words model.", "labels": [], "entities": []}, {"text": "We show (Section 4) that our matrix-space model significantly outperforms a bag-of-words model for the ordinal scale sentiment prediction task.", "labels": [], "entities": [{"text": "sentiment prediction task", "start_pos": 117, "end_pos": 142, "type": "TASK", "confidence": 0.8543031016985575}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Mapping of combination of polarities and inten- sities from MPQA dataset to our ordinal sentiment scale.", "labels": [], "entities": [{"text": "MPQA dataset", "start_pos": 70, "end_pos": 82, "type": "DATASET", "confidence": 0.9777669906616211}]}, {"text": " Table 2: Ranking loss for vector-space Ordered Logistic  Regression and Matrix-Space Logistic Regression.", "labels": [], "entities": [{"text": "Ranking loss", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.960529088973999}]}, {"text": " Table 3: Phrase and the sentiment scores of the phrase for  2 models Matrix-space OLogReg+BowInit and Bag-of- words OLogReg respectively. Notice that relative rank- ing order what matters", "labels": [], "entities": []}]}