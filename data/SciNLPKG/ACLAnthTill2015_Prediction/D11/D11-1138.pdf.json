{"title": [{"text": "Training dependency parsers by jointly optimizing multiple objectives", "labels": [], "entities": [{"text": "Training dependency parsers", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6413286030292511}]}], "abstractContent": [{"text": "We present an online learning algorithm for training parsers which allows for the inclusion of multiple objective functions.", "labels": [], "entities": []}, {"text": "The primary example is the extension of a standard supervised parsing objective function with additional loss-functions, either based on intrinsic parsing quality or task-specific extrinsic measures of quality.", "labels": [], "entities": []}, {"text": "Our empirical results show how this approach performs for two dependency parsing algorithms (graph-based and transition-based parsing) and how it achieves increased performance on multiple target tasks including reordering for machine translation and parser adaptation.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.7399835586547852}, {"text": "machine translation", "start_pos": 227, "end_pos": 246, "type": "TASK", "confidence": 0.7928105890750885}, {"text": "parser adaptation", "start_pos": 251, "end_pos": 268, "type": "TASK", "confidence": 0.8780905604362488}]}], "introductionContent": [{"text": "The accuracy and speed of state-of-the-art dependency parsers has motivated a resumed interest in utilizing the output of parsing as an input to many downstream natural language processing tasks.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9984174966812134}, {"text": "dependency parsers", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.709430068731308}]}, {"text": "This includes work on question answering (, sentiment analysis (, MT reordering (, and many other tasks.", "labels": [], "entities": [{"text": "question answering", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.9192769825458527}, {"text": "sentiment analysis", "start_pos": 44, "end_pos": 62, "type": "TASK", "confidence": 0.9657318890094757}, {"text": "MT reordering", "start_pos": 66, "end_pos": 79, "type": "TASK", "confidence": 0.9866190850734711}]}, {"text": "In most cases, the accuracy of parsers degrades when run on out-of-domain data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9993960857391357}]}, {"text": "But these accuracies are measured with respect to gold-standard out-of-domain parse trees.", "labels": [], "entities": []}, {"text": "There are few tasks that actually depend on the complete parse tree.", "labels": [], "entities": []}, {"text": "Furthermore, when evaluated on a downstream task, often the optimal parse output has a model score lower than the best parse as predicted by the parsing model.", "labels": [], "entities": []}, {"text": "While this means that we are not properly modeling the downstream task in the parsers, it also means that there is some information from small task or domain-specific data sets which could help direct our search for optimal parameters during parser training.", "labels": [], "entities": []}, {"text": "The goal being not necessarily to obtain better parse performance, but to exploit the structure induced from human labeled treebank data while targeting specific extrinsic metrics of quality, which can include task specific metrics or external weak constraints on the parse structure.", "labels": [], "entities": [{"text": "parse", "start_pos": 48, "end_pos": 53, "type": "TASK", "confidence": 0.9654370546340942}]}, {"text": "One obvious approach to this problem is to employ parser reranking).", "labels": [], "entities": []}, {"text": "In such a setting, an auxiliary reranker is added in a pipeline following the parser.", "labels": [], "entities": []}, {"text": "The standard setting involves training the base parser and applying it to a development set (this is often done in a cross-validated jack-knife training framework).", "labels": [], "entities": []}, {"text": "The reranker can then be trained to optimize for the downstream or extrinsic objective.", "labels": [], "entities": []}, {"text": "While this will bias the reranker towards the target task, it is limited by the oracle performance of the original base parser.", "labels": [], "entities": []}, {"text": "In this paper, we propose a training algorithm for statistical dependency parsers in which a single model is jointly optimized fora regular supervised training objective over the treebank data as well as a task-specific objective -or more generally an extrinsic objective -on an additional data set.", "labels": [], "entities": [{"text": "statistical dependency parsers", "start_pos": 51, "end_pos": 81, "type": "TASK", "confidence": 0.710158109664917}]}, {"text": "The case where there are both gold-standard trees and a task-specific objective for the entire training set is a specific instance of the larger problem that we address here.", "labels": [], "entities": []}, {"text": "Specifically, the algorithm takes the form of an online learner where a training instance is selected and the param-1489 eters are optimized based on the objective function associated with the instance (either intrinsic or extrinsic), thus jointly optimizing multiple objectives.", "labels": [], "entities": []}, {"text": "An update schedule trades-off the relative importance of each objective function.", "labels": [], "entities": []}, {"text": "We call our algorithm augmented-loss training as it optimizes multiple losses to augment the traditional supervised parser loss.", "labels": [], "entities": []}, {"text": "There have been a number of efforts to exploit weak or external signals of quality to train better prediction models.", "labels": [], "entities": []}, {"text": "This includes work on generalized expectation (, posterior regularization () and constraint driven learning (.", "labels": [], "entities": []}, {"text": "The work of on constraint driven learning is perhaps the closest to our framework and we draw connections to it in Section 5.", "labels": [], "entities": []}, {"text": "In these studies the typical goal is to use the weak signal to improve the structured prediction models on the intrinsic evaluation metrics.", "labels": [], "entities": []}, {"text": "For our setting this would mean using weak application specific signals to improve dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.7833675444126129}]}, {"text": "Though we explore such ideas in our experiments, in particular for semi-supervised domain adaptation, we are primarily interested in the case where the weak signal is precisely what we wish to optimize, but also desire the benefit from using both data with annotated parse structures and data specific to the task at hand to guide parser training.", "labels": [], "entities": [{"text": "semi-supervised domain adaptation", "start_pos": 67, "end_pos": 100, "type": "TASK", "confidence": 0.7323457598686218}]}, {"text": "In Section 2 we outline the augmented-loss algorithm and provide a convergence analysis.", "labels": [], "entities": []}, {"text": "In Section 3 and 4 we present a set of experiments defining diffent augmented losses covering a task-specific extrinsic loss (MT reordering), a domain adaptation loss, and an alternate intrinsic parser loss.", "labels": [], "entities": []}, {"text": "In all cases we show the augmented-loss framework can lead to significant gains in performance.", "labels": [], "entities": []}, {"text": "In Section 5 we tie our augmented-loss algorithm to other frameworks for encoding auxiliary information and/or joint objective optimization.", "labels": [], "entities": [{"text": "joint objective optimization", "start_pos": 111, "end_pos": 139, "type": "TASK", "confidence": 0.7004999121030172}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Reordering scores for parser-based reordering  (English-to-Japanese). Exact is the number of correctly  reordered sentences. All models use the same treebank- data (PTB, QTB, and the Brown corpus). Results for  three augmented-loss schedules are shown: 0.5 where for  every two treebank updates we make one augmented-loss  update, 1 is a 1-to-1 mix, and 2 is where we make twice  as many augmented-loss updates as treebank updates.", "labels": [], "entities": [{"text": "PTB", "start_pos": 175, "end_pos": 178, "type": "DATASET", "confidence": 0.83055180311203}]}, {"text": " Table 2: Domain adaptation results. Table shows (for  both transition and graph-based parsers) the labeled ac- curacy score (LAS), unlabeled accuracy score (UAS)", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7523763179779053}, {"text": "labeled ac- curacy score (LAS)", "start_pos": 100, "end_pos": 130, "type": "METRIC", "confidence": 0.8206284195184708}, {"text": "accuracy score (UAS", "start_pos": 142, "end_pos": 161, "type": "METRIC", "confidence": 0.9283050894737244}]}, {"text": " Table 3: Results for both parsers on the development set  of the PTB. When training with ALS (labeled and unla- beled), we see an improvement in UAS, LAS, and ALS.  Furthermore, if we use a labeled-ALS as the metric for  augmented-loss training, we also see a considerable in- crease in LAS.", "labels": [], "entities": [{"text": "PTB", "start_pos": 66, "end_pos": 69, "type": "DATASET", "confidence": 0.9178118705749512}, {"text": "UAS", "start_pos": 146, "end_pos": 149, "type": "METRIC", "confidence": 0.5339310765266418}]}]}