{"title": [{"text": "Augmenting String-to-Tree Translation Models with Fuzzy Use of Source-side Syntax", "labels": [], "entities": [{"text": "Augmenting String-to-Tree Translation", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8926414251327515}]}], "abstractContent": [{"text": "Due to its explicit modeling of the grammaticality of the output via target-side syntax, the string-to-tree model has been shown to be one of the most successful syntax-based translation models.", "labels": [], "entities": []}, {"text": "However, a major limitation of this model is that it does not utilize any useful syntactic information on the source side.", "labels": [], "entities": []}, {"text": "In this paper, we analyze the difficulties of incorporating source syntax in a string-to-tree model.", "labels": [], "entities": []}, {"text": "We then propose anew way to use the source syntax in a fuzzy manner, both in source syntactic annotation and in rule matching.", "labels": [], "entities": [{"text": "rule matching", "start_pos": 112, "end_pos": 125, "type": "TASK", "confidence": 0.7899051904678345}]}, {"text": "We further explore three algorithms in rule matching: 0-1 matching, likelihood matching, and deep similarity matching.", "labels": [], "entities": [{"text": "rule matching", "start_pos": 39, "end_pos": 52, "type": "TASK", "confidence": 0.7897874414920807}]}, {"text": "Our method not only guarantees grammatical output with an explicit target tree, but also enables the system to choose the proper translation rules via fuzzy use of the source syntax.", "labels": [], "entities": []}, {"text": "Our extensive experiments have shown significant improvements over the state-of-the-art string-to-tree system.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, statistical translation models based upon linguistic syntax have shown promising progress in improving translation quality.", "labels": [], "entities": []}, {"text": "It appears that encoding syntactic annotations on either side or both sides in translation rules can increase the expressiveness of rules and can produce more accurate translations with improved reordering.", "labels": [], "entities": []}, {"text": "One of the most successful syntax-based models is the string-to-tree model (;.", "labels": [], "entities": []}, {"text": "Since it explicitly models the grammaticality of the output via target-side syntax, the string-to-tree model ( significantly outperforms both the state-of-the-art phrase-based system Moses ( and the formal syntax-based system Hiero.", "labels": [], "entities": []}, {"text": "However, there is a major limitation in the string-to-tree model: it does not utilize any useful source-side syntactic information, and thus to some extent lacks the ability to distinguish good translation rules from bad ones.", "labels": [], "entities": []}, {"text": "The source syntax is well-known to be helpful in improving translation accuracy, as shown especially by tree-to-string systems;).", "labels": [], "entities": [{"text": "translation", "start_pos": 59, "end_pos": 70, "type": "TASK", "confidence": 0.9625846743583679}, {"text": "accuracy", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.8440234661102295}]}, {"text": "The tree-to-string systems are simple and efficient, but they also have a major limitation: they cannot guarantee the grammaticality of the translation output because they lack target-side syntactic constraints.", "labels": [], "entities": []}, {"text": "Thus a promising solution is to combine the advantages of the tree-to-string and string-to-tree approaches.", "labels": [], "entities": []}, {"text": "A natural idea is the tree-to-tree model;.", "labels": [], "entities": []}, {"text": "However, as discussed by, while tree-to-tree translation is indeed promising in theory, in practice it usually ends up over-constrained.", "labels": [], "entities": [{"text": "tree-to-tree translation", "start_pos": 32, "end_pos": 56, "type": "TASK", "confidence": 0.6798584461212158}]}, {"text": "Alternatively, proposed to enhance the tree-to-string model with target dependency structures (as a language model).", "labels": [], "entities": []}, {"text": "In this paper, we explore in the other direction: based on the strong string-to-tree model which builds an explicit target syntactic tree during decoding rather than apply only a syntactic language model, we aim to find a useful way to incorporate the source-side syntax.", "labels": [], "entities": []}, {"text": "First, we give a motivating example to show the importance of the source syntax fora string-to-tree model.", "labels": [], "entities": []}, {"text": "Then we discuss the difficulties of integrating the source syntax into the string-to-tree model.", "labels": [], "entities": []}, {"text": "Finally, we propose our solutions.", "labels": [], "entities": []}, {"text": "depicts a standard process that transforms a Chinese string into an English tree using several string-to-tree translation rules.", "labels": [], "entities": []}, {"text": "The tree with solid lines is produced by the baseline string-to-tree system.", "labels": [], "entities": []}, {"text": "Although the yield is grammatical, the translation is not correct since the system mistakenly applies ruler 2 , thus translating the Chinese preposition \u548c (h \u00e9 ) in the example sentence into the English conjunction and.", "labels": [], "entities": []}, {"text": "As a result, the Chinese prepositional phrase '\u548c \u6050\u6016 \u7ec4\u7ec7 \u7f51' (\"with terrorist networks\") is wrongly translated as apart of the relevant noun phrase (\" and terrorists networks\").", "labels": [], "entities": []}, {"text": "We find that r 2 occurs 103316 times in our training data, while r 3 occurs only 1021 times.", "labels": [], "entities": []}, {"text": "Thus, without source syntactic clues, the Chinese word \u548c (h \u00e9 ) is converted into the conjunction and inmost cases.", "labels": [], "entities": []}, {"text": "In general, this conversion is correct when the word \u548c(h\u00e9) is used as a conjunction.", "labels": [], "entities": []}, {"text": "But \u548c(h\u00e9) is a preposition in the source sentence.", "labels": [], "entities": []}, {"text": "If we are given this source syntactic clue, ruler 3 will be preferred.", "labels": [], "entities": []}, {"text": "This example motivates us to provide a moderate amount of source-side syntactic information so as to obtain the correct English tree with dotted lines (as our proposed system does).", "labels": [], "entities": []}, {"text": "A natural question may arise that is it easy to incorporate source syntax in the string-to-tree model?", "labels": [], "entities": []}, {"text": "To the best of our knowledge, no one has studied this approach before.", "labels": [], "entities": []}, {"text": "In fact, it is not a trivial question if we look into the string-to-tree model.", "labels": [], "entities": []}, {"text": "We find that the difficulties lie in at least three problems: 1) For a string-to-tree rule such as r 6 in, how should we syntactically annotate its source string?", "labels": [], "entities": []}, {"text": "2) Given the source-annotated string-to-tree rules, how should we match these rules according to the test source tree during decoding?", "labels": [], "entities": []}, {"text": "3) How should we binarize the sourceannotated string-to-tree rules for efficient decoding?", "labels": [], "entities": []}, {"text": "For the first problem, one may require the source side of a string-to-tree rule to be a constituent.", "labels": [], "entities": []}, {"text": "However, such excessive constraints will exclude many good string-to-tree rules whose source strings are not constituents.", "labels": [], "entities": []}, {"text": "Inspired by, we adopt a fuzzy way to label every source string with the complex syntactic categories of SAMT ().", "labels": [], "entities": []}, {"text": "This method leads to a one-to-one correspondence between the new rules and the string-to-tree rules.", "labels": [], "entities": []}, {"text": "We will detail our fuzzy labeling method in Section 2.", "labels": [], "entities": [{"text": "fuzzy labeling", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.6011299788951874}]}, {"text": "For the second problem, it appears simple and intuitive to match rules by requiring a rule's source syntactic category to be the same as the category of the test string.", "labels": [], "entities": []}, {"text": "However, this hard constraint will greatly narrow the search space during decoding.", "labels": [], "entities": []}, {"text": "Continuing to pursue the fuzzy methodology, we adopt a fuzzy matching procedure to enable matching of all the rules whose source strings match the test string, and then determine the degree of matching between the test source tree and each rule.", "labels": [], "entities": []}, {"text": "We will discuss three fuzzy matching algorithms, from simple to complex, in Section 3.", "labels": [], "entities": []}, {"text": "The third question is a technical problem, and we will give our solution in Section 4.", "labels": [], "entities": []}, {"text": "Our method not only guarantees the grammaticality of the output via the target tree structure, but also enables the system to choose appropriate translation rules during decoding through source syntactic fuzzy labeling and fuzzy matching.", "labels": [], "entities": []}, {"text": "The main contributions of this paper are as follows: 1) We propose a fuzzy method for both source syntax annotation and rule matching for augmenting string-to-tree models.", "labels": [], "entities": [{"text": "rule matching", "start_pos": 120, "end_pos": 133, "type": "TASK", "confidence": 0.7106488198041916}]}, {"text": "2) We design and investigate three fuzzy rule matching algorithms: 0-1 matching, likelihood matching, and deep similarity matching.", "labels": [], "entities": [{"text": "fuzzy rule matching", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.7148765524228414}, {"text": "deep similarity matching", "start_pos": 106, "end_pos": 130, "type": "TASK", "confidence": 0.5885876615842184}]}, {"text": "We hope that this paper will demonstrate how to effectively incorporate both source and target syntax into a translation model with promising results.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments are conducted on Chinese-toEnglish translation, with training data consisting of about 19 million English words and 17 million Chinese words . We performed bidirectional word alignment using GIZA++, and employed the growdiag-final balancing strategy to generate the final symmetric word alignment.", "labels": [], "entities": [{"text": "Chinese-toEnglish translation", "start_pos": 33, "end_pos": 62, "type": "TASK", "confidence": 0.6103393286466599}]}, {"text": "We parsed both sides of the parallel text with the Berkeley parser () and trained a 5-gram language model with the target part of the bilingual data and the Xinhua portion of the English Gigaword corpus.", "labels": [], "entities": [{"text": "English Gigaword corpus", "start_pos": 179, "end_pos": 202, "type": "DATASET", "confidence": 0.8583404620488485}]}, {"text": "For tuning and testing, we use NIST MT evaluation data for Chinese-to-English from 2003 to 2006 (MT03 to MT06).", "labels": [], "entities": [{"text": "NIST MT evaluation data", "start_pos": 31, "end_pos": 54, "type": "DATASET", "confidence": 0.8837270885705948}, {"text": "MT03", "start_pos": 97, "end_pos": 101, "type": "DATASET", "confidence": 0.8488463163375854}, {"text": "MT06", "start_pos": 105, "end_pos": 109, "type": "DATASET", "confidence": 0.5094828605651855}]}, {"text": "The development data set comes from MT06 in which sentences with more than 20 words are removed to speedup MERT 6.", "labels": [], "entities": [{"text": "development data set", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.7410779794057211}, {"text": "MT06", "start_pos": 36, "end_pos": 40, "type": "DATASET", "confidence": 0.9463370442390442}, {"text": "MERT 6", "start_pos": 107, "end_pos": 113, "type": "TASK", "confidence": 0.41365480422973633}]}, {"text": "The test set includes MT03 to MT05.", "labels": [], "entities": [{"text": "MT03", "start_pos": 22, "end_pos": 26, "type": "DATASET", "confidence": 0.9279663562774658}, {"text": "MT05", "start_pos": 30, "end_pos": 34, "type": "DATASET", "confidence": 0.9487765431404114}]}, {"text": "We implemented the baseline string-to-tree system ourselves according to).", "labels": [], "entities": []}, {"text": "We extracted minimal GHKM rules and the rules of SPMT Model 1 with source language phrases up to length L=4.", "labels": [], "entities": []}, {"text": "We further extracted composed rules by composing two or three minimal GHKM rules.", "labels": [], "entities": []}, {"text": "We also ran the stateof-the-art hierarchical phrase-based system Joshua ( ) for comparison.", "labels": [], "entities": []}, {"text": "In all systems, we set the beam size to 200.", "labels": [], "entities": []}, {"text": "The final translation quality is evaluated in terms of case-insensitive BLEU-4 with shortest length penalty.", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9877591729164124}]}, {"text": "The statistical significance testis performed using the re-sampling approach).", "labels": [], "entities": []}, {"text": "shows the translation results on development and test sets.", "labels": [], "entities": [{"text": "translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9578756093978882}]}, {"text": "First, we investigate the performance of the strong baseline string-to-tree model (s2t for short).", "labels": [], "entities": []}, {"text": "As the table shows, s2t outperforms the hierarchical phrase-based system Joshua by more than 1.0 BLEU point in all translation tasks.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.9990322589874268}]}, {"text": "This result verifies the superiority of the baseline string-to-tree model.", "labels": [], "entities": []}, {"text": "With the s2t system providing a baseline, we further study the effectiveness of our sourcesyntax-augmented string-to-tree system with fuzzy-tree to exact-tree rules (we use FT2ET to denote our proposed system).", "labels": [], "entities": [{"text": "FT2ET", "start_pos": 173, "end_pos": 178, "type": "DATASET", "confidence": 0.8761580586433411}]}, {"text": "The last three lines in show that, for each fuzzy matching algorithm, our new system TF2ET performs significantly better than the baseline s2t system, with an improvement of more than 0.5 absolute BLEU points in all tasks.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 197, "end_pos": 201, "type": "METRIC", "confidence": 0.9686849117279053}]}, {"text": "This result demonstrates the success of our new method of incorporating source-side syntax in a string-to-tree model.", "labels": [], "entities": []}, {"text": "The average decoding speed is about 50 words per minute in the baseline string-to-tree system and our proposed systems.: Results (in BLEU scores) of different translation models in multiple tasks.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 133, "end_pos": 137, "type": "METRIC", "confidence": 0.997797966003418}]}, {"text": "*or**=significantly better than s2t system (p<0.05 or 0.01 respectively).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results (in BLEU scores) of different  translation models in multiple tasks. LH=likelihood.  *or**=significantly better than s2t system (p<0.05 or  0.01 respectively).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9951430559158325}, {"text": "LH", "start_pos": 87, "end_pos": 89, "type": "METRIC", "confidence": 0.9821857810020447}, {"text": "likelihood", "start_pos": 90, "end_pos": 100, "type": "METRIC", "confidence": 0.9687363505363464}]}]}