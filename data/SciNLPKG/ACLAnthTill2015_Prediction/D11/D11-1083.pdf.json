{"title": [{"text": "Heuristic Search for Non-Bottom-Up Tree Structure Prediction", "labels": [], "entities": [{"text": "Non-Bottom-Up Tree Structure Prediction", "start_pos": 21, "end_pos": 60, "type": "TASK", "confidence": 0.6516925394535065}]}], "abstractContent": [{"text": "State of the art Tree Structures Prediction techniques rely on bottom-up decoding.", "labels": [], "entities": [{"text": "Tree Structures Prediction", "start_pos": 17, "end_pos": 43, "type": "TASK", "confidence": 0.5706526637077332}]}, {"text": "These approaches allow the use of context-free features and bottom-up features.", "labels": [], "entities": []}, {"text": "We discuss the limitations of mainstream techniques in solving common Natural Language Processing tasks.", "labels": [], "entities": [{"text": "solving common Natural Language Processing tasks", "start_pos": 55, "end_pos": 103, "type": "TASK", "confidence": 0.6646886567274729}]}, {"text": "Then we devise anew framework that goes beyond Bottom-up Decoding, and that allows a better integration of contextual features.", "labels": [], "entities": []}, {"text": "Furthermore we design a system that addresses these issues and we test it on Hierarchical Machine Translation, a well known tree structure prediction problem.", "labels": [], "entities": [{"text": "Hierarchical Machine Translation", "start_pos": 77, "end_pos": 109, "type": "TASK", "confidence": 0.6624767084916433}, {"text": "tree structure prediction", "start_pos": 124, "end_pos": 149, "type": "TASK", "confidence": 0.6664071182409922}]}, {"text": "The structure of the proposed system allows the incorporation of non-bottom-up features and relies on a more sophisticated decoding approach.", "labels": [], "entities": []}, {"text": "We show that the proposed approach can find better translations using a smaller portion of the search space.", "labels": [], "entities": []}], "introductionContent": [{"text": "Tree Structure Prediction (TSP) techniques have become relevant in many Natural Language Processing (NLP) applications, such as Syntactic Parsing, Semantic Role Labeling and Hierarchical Machine Translation (HMT).", "labels": [], "entities": [{"text": "Tree Structure Prediction (TSP)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.788916289806366}, {"text": "Syntactic Parsing", "start_pos": 128, "end_pos": 145, "type": "TASK", "confidence": 0.8627329170703888}, {"text": "Semantic Role Labeling", "start_pos": 147, "end_pos": 169, "type": "TASK", "confidence": 0.6314710179964701}, {"text": "Hierarchical Machine Translation (HMT)", "start_pos": 174, "end_pos": 212, "type": "TASK", "confidence": 0.8443613350391388}]}, {"text": "HMT approaches have a higher complexity than PhraseBased Machine Translation techniques, but exploit a more sophisticated reordering model, and can produce translations with higher Syntactic-Semantic quality.", "labels": [], "entities": [{"text": "PhraseBased Machine Translation", "start_pos": 45, "end_pos": 76, "type": "TASK", "confidence": 0.6440078814824423}]}, {"text": "TSP requires as inputs: a weighted grammar, G, and a sequence of symbols or a set of sequences encoded as a Lattice ().", "labels": [], "entities": [{"text": "TSP", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8952111005783081}]}, {"text": "The input sequence is often a sentence for NLP applications.", "labels": [], "entities": []}, {"text": "Tree structures generating the input sequence can be composed using rules, r, from the weighted grammar, G. TSP techniques return as output a tree structure or a set of trees (forest) that generate the input string or lattice.", "labels": [], "entities": []}, {"text": "The output forest can be represented compactly as a weighted hypergraph).", "labels": [], "entities": []}, {"text": "TSP tasks require finding the tree, t, with the highest score, or the best-k such trees.", "labels": [], "entities": [{"text": "TSP", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9202615022659302}]}, {"text": "Mainstream TSP relies on Bottom-up Decoding (BD) techniques.", "labels": [], "entities": [{"text": "Mainstream TSP", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.5695821344852448}, {"text": "Bottom-up Decoding (BD)", "start_pos": 25, "end_pos": 48, "type": "TASK", "confidence": 0.6064089715480805}]}, {"text": "With this paper we propose anew framework as a generalization of the CKY-like Bottom-up approach.", "labels": [], "entities": []}, {"text": "We also design and test an instantiation of this framework, empirically showing that wider contextual information leads to higher accuracy for TSP tasks that rely on non-local features, like HMT.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.9977534413337708}, {"text": "TSP tasks", "start_pos": 143, "end_pos": 152, "type": "TASK", "confidence": 0.9191928803920746}]}], "datasetContent": [{"text": "In this section we test the algorithm presented, and empirically show that it produces better translations searching a smaller portion of the search space.", "labels": [], "entities": []}, {"text": "We implemented UD on top of a widely-used HMT open-source system, cdec.", "labels": [], "entities": []}, {"text": "We compare with cdec Cube Pruning BD.", "labels": [], "entities": []}, {"text": "The ex- periments are executed on the NIST MT03 ChineseEnglish parallel corpus.", "labels": [], "entities": [{"text": "NIST MT03 ChineseEnglish parallel corpus", "start_pos": 38, "end_pos": 78, "type": "DATASET", "confidence": 0.892715060710907}]}, {"text": "The training corpus contains 239k sentence pairs with 6.9M Chinese words and 8.9M English words.", "labels": [], "entities": []}, {"text": "We use a hierarchical phrase-based translation grammar extracted using a suffix array rule extractor.", "labels": [], "entities": [{"text": "phrase-based translation grammar", "start_pos": 22, "end_pos": 54, "type": "TASK", "confidence": 0.6895516713460287}]}, {"text": "The NIST-03 test set is used for decoding, it has 919 sentence pairs.", "labels": [], "entities": [{"text": "NIST-03 test set", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.9763287901878357}]}, {"text": "The experiments can be reproduced on an average desktop computer.", "labels": [], "entities": []}, {"text": "Since we compare two different decoding strategies that rely on the same training technique, the evaluation is primarily based on search errors rather than on BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 159, "end_pos": 163, "type": "METRIC", "confidence": 0.997035026550293}]}, {"text": "We compare the two systems on a variety of beam sizes between 1 and 16.", "labels": [], "entities": []}, {"text": "reports a comparison of the translation quality for the two systems in relation to the beam size.", "labels": [], "entities": []}, {"text": "The blue area represents the portion of sentences for which UD found a better translation.", "labels": [], "entities": [{"text": "UD", "start_pos": 60, "end_pos": 62, "type": "TASK", "confidence": 0.8748866319656372}]}, {"text": "The white area represents the portion of sentences for which the two systems found a translation with the same search score.", "labels": [], "entities": []}, {"text": "With beam 1 the two systems obviously have a similar behavior, since both the systems stop investigating the candidates fora node after having selected the best candidate immediately available.", "labels": [], "entities": []}, {"text": "For beams 2-4, UD has a clear advantage.", "labels": [], "entities": [{"text": "UD", "start_pos": 15, "end_pos": 17, "type": "METRIC", "confidence": 0.8015484809875488}]}, {"text": "In this range UD finds a better translation for two thirds of the sentences.", "labels": [], "entities": [{"text": "UD", "start_pos": 14, "end_pos": 16, "type": "TASK", "confidence": 0.7024845480918884}]}, {"text": "With beam 4, we observe that UD is able to find a better translation for 63.76% of the sentences, instead BD is able to find a better translation for only 21.54% of the sentences.", "labels": [], "entities": [{"text": "UD", "start_pos": 29, "end_pos": 31, "type": "METRIC", "confidence": 0.7407964468002319}, {"text": "BD", "start_pos": 106, "end_pos": 108, "type": "METRIC", "confidence": 0.9883238077163696}]}, {"text": "For searches that employ abeam bigger than 8, we notice that the UD advantage slightly decreases, and the number of sentences with equivalent translation slowly increases.", "labels": [], "entities": [{"text": "UD", "start_pos": 65, "end_pos": 67, "type": "METRIC", "confidence": 0.9854640364646912}]}, {"text": "We can understand this behavior considering that as the beam increases the two systems get closer to exhaustive search.", "labels": [], "entities": []}, {"text": "Anyway with this experiment UD shows a consistent accuracy advantage over BD.", "labels": [], "entities": [{"text": "UD", "start_pos": 28, "end_pos": 30, "type": "METRIC", "confidence": 0.8135574460029602}, {"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9996687173843384}, {"text": "BD", "start_pos": 74, "end_pos": 76, "type": "METRIC", "confidence": 0.9936740398406982}]}, {"text": "plots the search score variation for different beam sizes.", "labels": [], "entities": []}, {"text": "We can see that UD search leads to an average search score that is consistently better than the one computed for BD.", "labels": [], "entities": [{"text": "UD search", "start_pos": 16, "end_pos": 25, "type": "TASK", "confidence": 0.7772470116615295}]}, {"text": "Undirected Decoding improves the average search score by 0.411 for beam 16.", "labels": [], "entities": []}, {"text": "The search score is the logarithm of a probability.", "labels": [], "entities": []}, {"text": "This variation corresponds to a relative gain of 50.83% in terms of probability.", "labels": [], "entities": []}, {"text": "For beams greater than 8 we see that the two curves keep a monotonic ascendant behavior while converging to exhaustive search.", "labels": [], "entities": []}, {"text": "shows the BLEU score variation.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9716981649398804}]}, {"text": "Again we can seethe consistent improvement of UD over BD.", "labels": [], "entities": [{"text": "UD", "start_pos": 46, "end_pos": 48, "type": "METRIC", "confidence": 0.8545280694961548}, {"text": "BD", "start_pos": 54, "end_pos": 56, "type": "METRIC", "confidence": 0.9719756841659546}]}, {"text": "In the graph we report also the performance obtained using BD with beam 32.", "labels": [], "entities": []}, {"text": "BD reaches BLEU score of 32.07 with beam 32 while UD reaches 32.38 with beam 16: UD reaches a clearly higher BLEU score using half the beam size.", "labels": [], "entities": [{"text": "BD", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9542862176895142}, {"text": "BLEU score", "start_pos": 11, "end_pos": 21, "type": "METRIC", "confidence": 0.9838458299636841}, {"text": "UD", "start_pos": 50, "end_pos": 52, "type": "METRIC", "confidence": 0.9007737040519714}, {"text": "BLEU score", "start_pos": 109, "end_pos": 119, "type": "METRIC", "confidence": 0.9829476177692413}]}, {"text": "The difference is even more impressive if we consider that UD reaches a BLEU of 32.19 with beam 4.", "labels": [], "entities": [{"text": "UD", "start_pos": 59, "end_pos": 61, "type": "TASK", "confidence": 0.40581753849983215}, {"text": "BLEU", "start_pos": 72, "end_pos": 76, "type": "METRIC", "confidence": 0.9996535778045654}]}, {"text": "In we plot the percentage reduction of the size of the hypergraphs generated by UD compared to those generated by BD.", "labels": [], "entities": []}, {"text": "The size reduction grows quickly for both nodes and edges.", "labels": [], "entities": []}, {"text": "This is due to the fact that BD, using Cube Pruning, must select k candidates for each node.", "labels": [], "entities": [{"text": "BD", "start_pos": 29, "end_pos": 31, "type": "METRIC", "confidence": 0.7143266201019287}]}, {"text": "Instead, UD is not obliged to  select k candidates per f -node.", "labels": [], "entities": [{"text": "UD", "start_pos": 9, "end_pos": 11, "type": "TASK", "confidence": 0.5608359575271606}]}, {"text": "As we can see from Algorithm 1, the decoding loop terminates when the queue of candidates is empty, and the statements at line 5 and line 11 ensure that no more thank candidates are selected per f -node, but nothing requires the selection of k elements, and some bad candidates may not be generated due to the sophisticated propagation strategy.", "labels": [], "entities": []}, {"text": "The number of derivations that a hypergraph represents is exponential in the number of nodes and edges composing the structure.", "labels": [], "entities": []}, {"text": "With beam 16, the hypergraphs produced by UD contain on average 4.6k fewer translations.", "labels": [], "entities": []}, {"text": "Therefore UD is able to find better translations even if exploring a smaller portion of the search space.", "labels": [], "entities": [{"text": "UD", "start_pos": 10, "end_pos": 12, "type": "DATASET", "confidence": 0.5065258741378784}]}, {"text": "reports the time comparison between BD and UD with respect to sentence length.", "labels": [], "entities": [{"text": "BD", "start_pos": 36, "end_pos": 38, "type": "METRIC", "confidence": 0.9663267135620117}]}, {"text": "The sentence length is measured with the number of ideogram groups appearing in the source Chinese sentences.", "labels": [], "entities": []}, {"text": "We compare BD with beam of 16 and UD with beam of 8, so that we compare two systems with comparable search score.", "labels": [], "entities": [{"text": "BD", "start_pos": 11, "end_pos": 13, "type": "METRIC", "confidence": 0.9884610176086426}, {"text": "UD", "start_pos": 34, "end_pos": 36, "type": "METRIC", "confidence": 0.8336601853370667}]}, {"text": "We can notice that for short sentences UD is faster, while for longer sentences UD becomes slower.", "labels": [], "entities": [{"text": "UD", "start_pos": 39, "end_pos": 41, "type": "METRIC", "confidence": 0.9931783676147461}, {"text": "UD", "start_pos": 80, "end_pos": 82, "type": "METRIC", "confidence": 0.9813024401664734}]}, {"text": "To understand this result consider that for simple sentences UD can rely on the advantage of exploring a smaller search space.", "labels": [], "entities": [{"text": "UD", "start_pos": 61, "end_pos": 63, "type": "TASK", "confidence": 0.9342399835586548}]}, {"text": "While, for longer sentences, the amount of candidates considered during decoding grows exponentially with the size of the sentence, and UD needs to maintain an unique queue whose size is not bounded by the beam size k, as for the queues used in BD's Cube Pruning.", "labels": [], "entities": []}, {"text": "It maybe possible to address this issue with more efficient handling of the queue.", "labels": [], "entities": []}, {"text": "In conclusion we can assert that, even if exploring a smaller portion of the search space, UD finds often a translation that is better than the one found with standard BD.", "labels": [], "entities": []}, {"text": "UD's higher accuracy is due to its sophisticated search strategy that allows a more efficient integration of contextual features.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9992896318435669}]}, {"text": "This set of experiments show the validity of the UD approach and empirically confirm our intuition about the BD's inadequacy in solving tasks that rely on fundamental contextual features.", "labels": [], "entities": []}], "tableCaptions": []}