{"title": [{"text": "Discovering Morphological Paradigms from Plain Text Using a Dirichlet Process Mixture Model", "labels": [], "entities": [{"text": "Discovering Morphological Paradigms from Plain Text", "start_pos": 0, "end_pos": 51, "type": "TASK", "confidence": 0.8307201464970907}]}], "abstractContent": [{"text": "We present an inference algorithm that organizes observed words (tokens) into structured inflectional paradigms (types).", "labels": [], "entities": []}, {"text": "It also naturally predicts the spelling of unobserved forms that are missing from these paradigms, and discovers inflectional principles (grammar) that generalize to wholly unobserved words.", "labels": [], "entities": []}, {"text": "Our Bayesian generative model of the data explicitly represents tokens, types, inflections, paradigms, and locally conditioned string edits.", "labels": [], "entities": []}, {"text": "It assumes that inflected word tokens are generated from an infinite mixture of inflectional paradigms (string tuples).", "labels": [], "entities": []}, {"text": "Each paradigm is sampled all at once from a graphical model, whose potential functions are weighted finite-state transducers with language-specific parameters to be learned.", "labels": [], "entities": []}, {"text": "These assumptions naturally lead to an elegant empirical Bayes inference procedure that exploits Monte Carlo EM, belief propagation, and dynamic programming.", "labels": [], "entities": [{"text": "belief propagation", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.7748706638813019}]}, {"text": "Given 50-100 seed paradigms, adding a 10-million-word corpus reduces prediction error for morphological inflections by up to 10%.", "labels": [], "entities": [{"text": "error", "start_pos": 80, "end_pos": 85, "type": "METRIC", "confidence": 0.7428578734397888}]}], "introductionContent": [], "datasetContent": [{"text": "We evaluated how well our model learns German verbal morphology.", "labels": [], "entities": []}, {"text": "As corpus we used the first 1 million or 10 million words from WaCky ().", "labels": [], "entities": [{"text": "WaCky", "start_pos": 63, "end_pos": 68, "type": "DATASET", "confidence": 0.9207311868667603}]}, {"text": "For seed and test paradigms we used verbal inflectional paradigms from the CELEX morphological database (.", "labels": [], "entities": [{"text": "CELEX morphological database", "start_pos": 75, "end_pos": 103, "type": "DATASET", "confidence": 0.9350695411364237}]}, {"text": "We fully observed the seed paradigms.", "labels": [], "entities": []}, {"text": "For each test paradigm, we observed the lemma type (Appendix C) and evaluated how well the system completed the other 21 forms (see Appendix E.2) in the paradigm.", "labels": [], "entities": [{"text": "Appendix C)", "start_pos": 52, "end_pos": 63, "type": "METRIC", "confidence": 0.9374870260556539}]}, {"text": "We simplified inference by fixing the POS tag sequence to the automatic tags delivered with the WaCky corpus.", "labels": [], "entities": [{"text": "WaCky corpus", "start_pos": 96, "end_pos": 108, "type": "DATASET", "confidence": 0.9491177201271057}]}, {"text": "The result that we evaluated for each variable was the value whose probability, averaged over the entire Monte Carlo EM run, 15 was highest.", "labels": [], "entities": []}, {"text": "For more details, see.", "labels": [], "entities": []}, {"text": "All results are averaged over 10 different training/test splits of the CELEX data.", "labels": [], "entities": [{"text": "CELEX data", "start_pos": 71, "end_pos": 81, "type": "DATASET", "confidence": 0.9881143569946289}]}, {"text": "Each split sampled 100 paradigms as seed data and used the remaining 5,415 paradigms for evaluation.", "labels": [], "entities": []}, {"text": "From the 100 paradigms, we also sampled 50 to obtain results with smaller seed data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Whole-word accuracy and edit distance of pre- dicted inflection forms given the lemma. Edit distance to  the correct form is measured in characters. Best numbers  per set of seed paradigms in bold (statistically signifi- cant on our large test set under a paired permutation test,  p < 0.05). Appendix E breaks down these results per  inflection and gives an error analysis and other statistics.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9824956655502319}, {"text": "Edit distance", "start_pos": 97, "end_pos": 110, "type": "METRIC", "confidence": 0.9500463604927063}, {"text": "Appendix E", "start_pos": 303, "end_pos": 313, "type": "METRIC", "confidence": 0.9494118988513947}, {"text": "error analysis", "start_pos": 369, "end_pos": 383, "type": "METRIC", "confidence": 0.9317195415496826}]}, {"text": " Table 3: The inflected verb forms from 5,615 inflectional  paradigms, split into 5 token frequency bins. The frequen- cies are based on the 10-million word corpus.", "labels": [], "entities": []}, {"text": " Table 4: Token-based analysis: Whole-word accuracy re- sults split into different frequency bins. In the last two  rows, all predictions are included, weighted by the fre- quency of the form to predict. Last row is edit distance.", "labels": [], "entities": [{"text": "Token-based analysis", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.9401560723781586}, {"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9267272353172302}]}]}