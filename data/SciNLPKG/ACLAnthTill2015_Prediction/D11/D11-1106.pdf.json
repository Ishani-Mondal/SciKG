{"title": [{"text": "Syntax-Based Grammaticality Improvement using CCG and Guided Search", "labels": [], "entities": [{"text": "Syntax-Based Grammaticality", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.872921496629715}]}], "abstractContent": [{"text": "Machine-produced text often lacks grammat-icality and fluency.", "labels": [], "entities": []}, {"text": "This paper studies gram-maticality improvement using a syntax-based algorithm based on CCG.", "labels": [], "entities": []}, {"text": "The goal of the search problem is to find an optimal parse tree among all that can be constructed through selection and ordering of the input words.", "labels": [], "entities": []}, {"text": "The search problem, which is significantly harder than parsing, is solved by guided learning for best-first search.", "labels": [], "entities": [{"text": "parsing", "start_pos": 55, "end_pos": 62, "type": "TASK", "confidence": 0.9734392762184143}]}, {"text": "Ina standard word ordering task, our system gives a BLEU score of 40.1, higher than the previous result of 33.7 achieved by a dependency-based system.", "labels": [], "entities": [{"text": "word ordering task", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.8220468958218893}, {"text": "BLEU score", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.9844481647014618}]}], "introductionContent": [{"text": "Machine-produced text, such as SMT output, often lacks grammaticality and fluency, especially when using n-gram language modelling.", "labels": [], "entities": [{"text": "SMT output", "start_pos": 31, "end_pos": 41, "type": "TASK", "confidence": 0.9271258413791656}]}, {"text": "Recent efforts have been made to improve grammaticality using local language models) and global dependency structures ().", "labels": [], "entities": []}, {"text": "We study grammaticality improvement using a syntax-based system.", "labels": [], "entities": [{"text": "grammaticality improvement", "start_pos": 9, "end_pos": 35, "type": "TASK", "confidence": 0.8741078078746796}]}, {"text": "The task is effectively a text-to-text generation problem where the goal is to produce a grammatical sentence from an ungrammatical and fragmentary input.", "labels": [], "entities": [{"text": "text-to-text generation", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.7264464199542999}]}, {"text": "The input can range from a bag-ofwords () to a fully-ordered sentence.", "labels": [], "entities": []}, {"text": "A general form of the problem is to construct a grammatical sentence from a set of un-ordered input words.", "labels": [], "entities": []}, {"text": "However, in cases where the base system produces fluent subsequences within the sentence, constraints on the choice and order of certain words can be fed to the grammaticality improvement system.", "labels": [], "entities": []}, {"text": "The input may also include words beyond the output of the base system, e.g. extra words from the SMT lattice, so that content word insertion and deletion can be performed implicity via word selection.", "labels": [], "entities": [{"text": "SMT", "start_pos": 97, "end_pos": 100, "type": "TASK", "confidence": 0.9451287984848022}, {"text": "content word insertion", "start_pos": 118, "end_pos": 140, "type": "TASK", "confidence": 0.6980915466944376}]}, {"text": "We study the above task using CCG).", "labels": [], "entities": []}, {"text": "The main challenge is the search problem, which is to find an optimal parse tree among all that can be constructed with any word choice and order from the set of input words.", "labels": [], "entities": []}, {"text": "We use an approximate best-first algorithm, guided by learning, to tackle the more-than-factorial complexity.", "labels": [], "entities": []}, {"text": "Beam-search is used to control the volume of accepted hypotheses, so that only a very small portion of the whole search space is explored.", "labels": [], "entities": []}, {"text": "The search algorithm is guided by perceptron training, which ensures that the explored path in the search space consists of highly probable hypotheses.", "labels": [], "entities": []}, {"text": "This framework of best-first search guided by learning is a general contribution of the paper, which could be applied to problems outside grammaticality improvement.", "labels": [], "entities": []}, {"text": "We evaluate our system using the generation task of word-order recovery, which is to recover the original word order of a fully scrambled input sentence ().", "labels": [], "entities": [{"text": "word-order recovery", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.7796427607536316}]}, {"text": "This problem is an instance of our general task formulation, but without any input constraints, or content word selection (since all input words are used).", "labels": [], "entities": [{"text": "content word selection", "start_pos": 99, "end_pos": 121, "type": "TASK", "confidence": 0.6496043503284454}]}, {"text": "It is straightforward to use this task to evaluate our system and compare with existing approaches.", "labels": [], "entities": []}, {"text": "Our system gave 40.1 BLEU score, higher than the dependency-based system of, for which a BLEU score of 33.7 was reported.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 21, "end_pos": 31, "type": "METRIC", "confidence": 0.9654554128646851}, {"text": "BLEU score", "start_pos": 89, "end_pos": 99, "type": "METRIC", "confidence": 0.9821752905845642}]}, {"text": "1147 Combinatory Categorial Grammar) is a lexicalized grammar formalism, which associates words with lexical categories.", "labels": [], "entities": []}, {"text": "Lexical categories are detailed grammatical labels, typically expressing subcategorisation information.", "labels": [], "entities": []}, {"text": "CCG, and parsing with CCG, has been described in detail elsewhere; here we provide only a short description.", "labels": [], "entities": [{"text": "CCG", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9240298271179199}, {"text": "parsing", "start_pos": 9, "end_pos": 16, "type": "TASK", "confidence": 0.9669888615608215}]}, {"text": "During CCG parsing, adjacent categories are combined using CCG's combinatory rules.", "labels": [], "entities": [{"text": "CCG parsing", "start_pos": 7, "end_pos": 18, "type": "TASK", "confidence": 0.5928156226873398}]}, {"text": "For example, a verb phrase in English (S \\NP ) can combine with an NP to its left: In addition to binary rule instances, such as the one above, there are also unary rules which operate on a single category in order to change its type.", "labels": [], "entities": []}, {"text": "For example, forward type-raising can change a subject NP into a complex category looking to the right fora verb phrase: Following Hockenmaier (2003), we extract the grammar by reading rule instances directly from the derivations in CCGbank, rather than defining the combinatory rule schema manually as in.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 233, "end_pos": 240, "type": "DATASET", "confidence": 0.9412290453910828}]}], "datasetContent": [{"text": "We use CCGBank) for experimental data.", "labels": [], "entities": []}, {"text": "CCGbank is the CCG version of the Penn Treebank.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9585425853729248}, {"text": "Penn Treebank", "start_pos": 34, "end_pos": 47, "type": "DATASET", "confidence": 0.9941976070404053}]}, {"text": "Sections 02-21 are 1151 used for training, section 00 is used for development and section 23 for the final test.", "labels": [], "entities": []}, {"text": "Original sentences from CCGBank are transformed into bags of words, with sequence information removed, and passed to our system as input data.", "labels": [], "entities": []}, {"text": "The system outputs are compared to the original sentences for evaluation.", "labels": [], "entities": []}, {"text": "Following, we use the BLEU metric () for string comparison.", "labels": [], "entities": [{"text": "BLEU metric", "start_pos": 22, "end_pos": 33, "type": "METRIC", "confidence": 0.9758162200450897}]}, {"text": "Whilst BLEU is not an ideal measure of fluency or grammaticality, being based on n-gram precision, it is currently widely used for automatic evaluation and allows us to compare directly with existing work (.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.9980962872505188}, {"text": "precision", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.8777773976325989}]}, {"text": "In addition to the surface string, our system also produces the CCG parse given an input bag of words.", "labels": [], "entities": []}, {"text": "The quality of the parse tree can reflect both the grammaticality of the surface string and the quality of the trained grammar model.", "labels": [], "entities": []}, {"text": "However, there is no direct way to automatically evaluate parse trees since output word choice and order can be different from the gold-standard.", "labels": [], "entities": []}, {"text": "Instead, we indirectly measure parse quality by calculating the precision of CCG lexical categories.", "labels": [], "entities": [{"text": "precision", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.998663067817688}]}, {"text": "Since CCG lexical categories contain so much syntactic information, they provide a useful measure of parse quality.", "labels": [], "entities": []}, {"text": "Again because the word order can be different, we turn both the output and the gold-standard into a bag of word/category pairs, and calculate the percentage of matched pairs as the lexical category precision.", "labels": [], "entities": []}, {"text": "For fair comparison with, we keep base NPs as atomic units when preparing the input.", "labels": [], "entities": []}, {"text": "used base NPs from Penn Treebank annotation, while we extract base NPs from the CCGBbank by taking as base NPs the NPs that do not recursively contain other NPs.", "labels": [], "entities": [{"text": "Penn Treebank annotation", "start_pos": 19, "end_pos": 43, "type": "DATASET", "confidence": 0.9815161824226379}, {"text": "CCGBbank", "start_pos": 80, "end_pos": 88, "type": "DATASET", "confidence": 0.9836216568946838}]}, {"text": "These base NPs mostly correspond to the base NPs from the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 58, "end_pos": 71, "type": "DATASET", "confidence": 0.9675247073173523}]}, {"text": "In the training data, there are 242,813 Penn Treebank base NPs with an average size of 1.09, and 216,670 CCGBank base NPs with an average size of 1.19.", "labels": [], "entities": [{"text": "Penn Treebank base NPs", "start_pos": 40, "end_pos": 62, "type": "DATASET", "confidence": 0.9701749980449677}]}, {"text": "shows a set of development experiment results after one training iteration.", "labels": [], "entities": []}, {"text": "Three different methods of assigning lexical categories are used.", "labels": [], "entities": [{"text": "assigning lexical categories", "start_pos": 27, "end_pos": 55, "type": "TASK", "confidence": 0.8538967172304789}]}, {"text": "The first (\"dictionary\") is to assign all possible lexical categories to each input word from the dictionary.", "labels": [], "entities": []}, {"text": "The lexical category dictionary is built using  the training sections of CCGBank.", "labels": [], "entities": [{"text": "CCGBank", "start_pos": 73, "end_pos": 80, "type": "DATASET", "confidence": 0.9738581776618958}]}, {"text": "For each word occurring more than 20 times in the corpus, the dictionary has an entry with all lexical categories the word has been seen with.", "labels": [], "entities": []}, {"text": "For the rest of the words, the dictionary maintains an entry for each POS which contains all lexical categories it has been seen with.", "labels": [], "entities": []}, {"text": "There are on average 26.8 different categories for each input word by this method.", "labels": [], "entities": []}, {"text": "In practice, it is often unnecessary to leave lexical category disambiguation completely to the grammaticality improvement system.", "labels": [], "entities": [{"text": "lexical category disambiguation", "start_pos": 46, "end_pos": 77, "type": "TASK", "confidence": 0.7122827172279358}]}, {"text": "When it is reasonable to assume that the input sentence for the grammaticality improvement system is sufficiently fluent, a list of candidate lexical categories can be assigned automatically to each word via supertagging) on the input sequence.", "labels": [], "entities": []}, {"text": "We use the C&C supertagger 1 to assign a set of probable lexical categories to each input word using the goldstandard order.", "labels": [], "entities": []}, {"text": "When the input is noisy, the accuracy of a supertagger tends to be lower than when the input is grammatical.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.999560534954071}]}, {"text": "One way to address this problem is to allow the supertagger to produce a larger list of possible supertags for each input word, and leave the ambiguity to the grammatical improvement system.", "labels": [], "entities": []}, {"text": "We simulate the noisy input situation by using Precision dictionary 58.5% \u03b2 = 0.0001 59.7% \u03b2 = 0.075% 77.0%: Lexical category accuracies.", "labels": [], "entities": []}, {"text": "a small probability cutoff (\u03b2) value in the supertagger, and supertag correctly ordered input sentences before breaking them into bags of words.", "labels": [], "entities": []}, {"text": "With a \u03b2 value of 0.0001, there are 5.4 lexical categories for each input word in the development test (which is smaller than the dictionary case).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Development tests using various levels of lexical  categories and timeouts, after one training iteration.", "labels": [], "entities": []}, {"text": " Table 4: BLEU scores measured on different lengths on  development data. Timeout = 5s. 1 training iteration.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9983932375907898}, {"text": "Timeout", "start_pos": 74, "end_pos": 81, "type": "METRIC", "confidence": 0.9925413131713867}]}]}