{"title": [{"text": "Training a Log-Linear Parser with Loss Functions via Softmax-Margin", "labels": [], "entities": [{"text": "Softmax-Margin", "start_pos": 53, "end_pos": 67, "type": "DATASET", "confidence": 0.7970333695411682}]}], "abstractContent": [{"text": "Log-linear parsing models are often trained by optimizing likelihood, but we would prefer to optimise fora task-specific metric like F-measure.", "labels": [], "entities": [{"text": "Log-linear parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.591794803738594}]}, {"text": "Softmax-margin is a convex objective for such models that minimises abound on expected risk fora given loss function, but its na\u00a8\u0131vena\u00a8\u0131ve application requires the loss to decompose over the predicted structure, which is not true of F-measure.", "labels": [], "entities": []}, {"text": "We use softmax-margin to optimise a log-linear CCG parser fora variety of loss functions, and demonstrate a novel dynamic programming algorithm that enables us to use it with F-measure, leading to substantial gains inaccuracy on CCG-Bank.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 175, "end_pos": 184, "type": "METRIC", "confidence": 0.9295951128005981}]}, {"text": "When we embed our loss-trained parser into a larger model that includes supertagging features incorporated via belief propagation, we obtain further improvements and achieve a labelled/unlabelled dependency F-measure of 89.3%/94.0% on gold part-of-speech tags, and 87.2%/92.8% on automatic part-of-speech tags, the best reported results for this task.", "labels": [], "entities": [{"text": "belief propagation", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.7431661784648895}, {"text": "F-measure", "start_pos": 207, "end_pos": 216, "type": "METRIC", "confidence": 0.9042742848396301}]}], "introductionContent": [{"text": "Parsing models based on Conditional Random Fields (CRFs;) have been very successful.", "labels": [], "entities": []}, {"text": "In practice, they are usually trained by maximising the conditional log-likelihood (CLL) of the training data.", "labels": [], "entities": [{"text": "conditional log-likelihood (CLL)", "start_pos": 56, "end_pos": 88, "type": "METRIC", "confidence": 0.8174249172210694}]}, {"text": "However, it is widely appreciated that optimizing for task-specific metrics often leads to better performance on those tasks).", "labels": [], "entities": []}, {"text": "An especially attractive means of accomplishing this for CRFs is the softmax-margin (SMM) objective () ( \u00a72).", "labels": [], "entities": [{"text": "CRFs", "start_pos": 57, "end_pos": 61, "type": "TASK", "confidence": 0.9193682074546814}, {"text": "softmax-margin (SMM) objective", "start_pos": 69, "end_pos": 99, "type": "METRIC", "confidence": 0.6692050039768219}]}, {"text": "In addition to retaining a probabilistic interpretation and optimizing towards a loss function, it is also convex, making it straightforward to optimise.", "labels": [], "entities": []}, {"text": "show that it can be easily implemented with a simple change to standard likelihood-based training, provided that the loss function decomposes over the predicted structure.", "labels": [], "entities": []}, {"text": "Unfortunately, the widely-used F-measure metric does not decompose over parses.", "labels": [], "entities": [{"text": "F-measure metric", "start_pos": 31, "end_pos": 47, "type": "METRIC", "confidence": 0.890287846326828}]}, {"text": "To solve this, we introduce a novel dynamic programming algorithm that enables us to compute the exact quantities needed under the softmax-margin objective using F-measure as a loss ( \u00a73).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 162, "end_pos": 171, "type": "METRIC", "confidence": 0.9827163219451904}]}, {"text": "We experiment with this and several other metrics, including precision, recall, and decomposable approximations thereof.", "labels": [], "entities": [{"text": "precision", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9996121525764465}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9992213249206543}]}, {"text": "Our ability to optimise towards exact metrics enables us to verify the effectiveness of more efficient approximations.", "labels": [], "entities": []}, {"text": "We test the training procedures on the state-of-the-art Combinatory Categorial Grammar (CCG; Steedman 2000) parser of, obtaining substantial improvements under a variety of conditions.", "labels": [], "entities": []}, {"text": "We then embed this model into a more accurate model that incorporates additional supertagging features via loopy belief propagation.", "labels": [], "entities": [{"text": "belief propagation", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.6959943622350693}]}, {"text": "The improvements are additive, obtaining the best reported results on this task ( \u00a74).", "labels": [], "entities": []}], "datasetContent": [{"text": "CCG parsers use a pipeline strategy: we first multitag each word of the sentence with a small subset of its possible lexical categories using a supertagger, a sequence model over these categories ().", "labels": [], "entities": []}, {"text": "Then we parse the sentence under the requirement that the lexical categories are fixed to those preferred by the supertagger.", "labels": [], "entities": []}, {"text": "In our experiments we used two variants on this strategy.", "labels": [], "entities": []}, {"text": "First is the adaptive supertagging (AST) approach of.", "labels": [], "entities": []}, {"text": "It is based on a step function over supertagger beam widths, relaxing the pruning threshold for lexical categories only if the parser fails to find an analysis.", "labels": [], "entities": []}, {"text": "The process either succeeds and returns a parse after some iteration or gives up after a predefined number of iterations.", "labels": [], "entities": []}, {"text": "As show, most sentences can be parsed with very tight beams.", "labels": [], "entities": []}, {"text": "Reverse adaptive supertagging is a much less aggressive method that seeks only to make sentences parsable when they otherwise would not be due to an impractically large search space.", "labels": [], "entities": [{"text": "Reverse adaptive supertagging", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7354809840520223}]}, {"text": "Reverse AST starts with a wide beam, narrowing it at each iteration only if a maximum chart size is exceeded.", "labels": [], "entities": [{"text": "Reverse AST", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.744525820016861}]}, {"text": "shows beam settings for both strategies.", "labels": [], "entities": []}, {"text": "Adaptive supertagging aims for speed via pruning while the reverse strategy aims for accuracy by exposing the parser to a larger search space.", "labels": [], "entities": [{"text": "speed", "start_pos": 31, "end_pos": 36, "type": "METRIC", "confidence": 0.9789166450500488}, {"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9985445737838745}]}, {"text": "Although found no actual improvements from the latter strategy, we will show that with our softmax-margin-trained models it can have a substantial effect.", "labels": [], "entities": []}, {"text": "We use the C&C parser) and its supertagger).", "labels": [], "entities": []}, {"text": "Our baseline is the hybrid model of, which contains features over both normalform derivations and CCG dependencies.", "labels": [], "entities": []}, {"text": "The parser relies solely on the supertagger for pruning, using exact CKY for search over the pruned space.", "labels": [], "entities": []}, {"text": "Training requires calculation of feature expectations over packed charts of derivations.", "labels": [], "entities": []}, {"text": "For training, we limited the number of items in this chart to 0.3 million, and for testing, 1 million.", "labels": [], "entities": []}, {"text": "We also used a more permissive training supertagger beam) than in previous work.", "labels": [], "entities": []}, {"text": "Models were trained with the parser's L-BFGS trainer.", "labels": [], "entities": []}, {"text": "We evaluated on CCGbank, a right-most normalform CCG version of the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 68, "end_pos": 81, "type": "DATASET", "confidence": 0.9957896769046783}]}, {"text": "We use sections 02-21 (39603 sentences) for training, section 00 (1913 sentences) for development and section 23 (2407 sentences) for testing.", "labels": [], "entities": []}, {"text": "We supply gold-standard part-of-speech tags to the parsers.", "labels": [], "entities": []}, {"text": "We evaluate on labelled and unlabelled predicate argument structure recovery and supertag accuracy.", "labels": [], "entities": [{"text": "predicate argument structure recovery", "start_pos": 39, "end_pos": 76, "type": "TASK", "confidence": 0.6025387346744537}, {"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9329398274421692}]}], "tableCaptions": [{"text": " Table 1: Beam step function used for standard (AST) and less aggressive (Reverse) AST throughout our experiments.  Parameter \u03b2 is a beam threshold while k bounds the number of lexical categories considered for each word.", "labels": [], "entities": [{"text": "AST", "start_pos": 83, "end_pos": 86, "type": "TASK", "confidence": 0.9101581573486328}]}, {"text": " Table 2: Beam step functions used for training: The first row shows the large scale settings used for most experiments  and the standard C&C settings. (cf. Table 1)", "labels": [], "entities": []}, {"text": " Table 3: Performance on section 00 of CCGbank when comparing models trained with treebank-parses (Baseline)  and maximum F-score parses (Max-F) using adaptive supertagging as well as a combination of CCGbank and Max-F  parses. Evaluation is based on labelled and unlabelled F-measure (LF/UF), precision (LP/UP) and recall (LR/UR).", "labels": [], "entities": [{"text": "precision (LP/UP)", "start_pos": 294, "end_pos": 311, "type": "METRIC", "confidence": 0.9021978775660197}, {"text": "recall (LR/UR)", "start_pos": 316, "end_pos": 330, "type": "METRIC", "confidence": 0.9252272645632426}]}, {"text": " Table 4: Performance of exact and approximate loss functions against conditional log-likelihood (CLL): decomposable  precision (DecP), recall (DecR) and F-measure (DecF1) versus exact precision (P), recall (R) and F-measure (F1).  Evaluation is based on labelled and unlabelled F-measure (LF/UF), precision (LP/UP) and recall (LR/UR).", "labels": [], "entities": [{"text": "decomposable  precision (DecP)", "start_pos": 104, "end_pos": 134, "type": "METRIC", "confidence": 0.776376736164093}, {"text": "recall (DecR)", "start_pos": 136, "end_pos": 149, "type": "METRIC", "confidence": 0.90880486369133}, {"text": "F-measure (DecF1)", "start_pos": 154, "end_pos": 171, "type": "METRIC", "confidence": 0.8774673193693161}, {"text": "exact precision (P)", "start_pos": 179, "end_pos": 198, "type": "METRIC", "confidence": 0.9021435379981995}, {"text": "recall (R)", "start_pos": 200, "end_pos": 210, "type": "METRIC", "confidence": 0.9295203238725662}, {"text": "F-measure (F1)", "start_pos": 215, "end_pos": 229, "type": "METRIC", "confidence": 0.8663710206747055}, {"text": "precision (LP/UP)", "start_pos": 298, "end_pos": 315, "type": "METRIC", "confidence": 0.8955695529778799}, {"text": "recall (LR/UR)", "start_pos": 320, "end_pos": 334, "type": "METRIC", "confidence": 0.8928159276644388}]}, {"text": " Table 5: Performance of decomposed loss functions in large-scale training setting. Evaluation is based on labelled and  unlabelled F-measure (LF/UF) and supertag accuracy (ST).", "labels": [], "entities": [{"text": "F-measure (LF/UF)", "start_pos": 132, "end_pos": 149, "type": "METRIC", "confidence": 0.911418209473292}, {"text": "supertag accuracy (ST)", "start_pos": 154, "end_pos": 176, "type": "METRIC", "confidence": 0.821857464313507}]}, {"text": " Table 6: Performance of combined parsing and supertagging with belief propagation (BP); using decomposed-F1 as  parser-loss function and supertag-accuracy (SA) as loss in the supertagger.", "labels": [], "entities": [{"text": "belief propagation (BP)", "start_pos": 64, "end_pos": 87, "type": "TASK", "confidence": 0.7710883855819702}, {"text": "supertag-accuracy (SA)", "start_pos": 138, "end_pos": 160, "type": "METRIC", "confidence": 0.7688635587692261}]}, {"text": " Table 7: Results on automatically assigned POS tags. Petrov I-5 is based on the parser output of Fowler and Penn", "labels": [], "entities": []}]}