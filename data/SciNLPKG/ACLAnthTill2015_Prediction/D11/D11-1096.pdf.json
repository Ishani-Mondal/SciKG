{"title": [{"text": "Structured Lexical Similarity via Convolution Kernels on Dependency Trees", "labels": [], "entities": [{"text": "Structured Lexical Similarity", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7003874977429708}]}], "abstractContent": [{"text": "A central topic in natural language processing is the design of lexical and syntactic features suitable for the target application.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.6589079896608988}]}, {"text": "In this paper, we study convolution dependency tree kernels for automatic engineering of syntactic and semantic patterns exploiting lexical similarities.", "labels": [], "entities": []}, {"text": "We define efficient and powerful kernels for measuring the similarity between dependency structures, whose surface forms of the lexical nodes are in part or completely different.", "labels": [], "entities": []}, {"text": "The experiments with such kernels for question classification show an unprecedented results, e.g. 41% of error reduction of the former state-of-the-art.", "labels": [], "entities": [{"text": "question classification", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.843612551689148}, {"text": "error reduction", "start_pos": 105, "end_pos": 120, "type": "METRIC", "confidence": 0.9437225759029388}]}, {"text": "Additionally, semantic role classification confirms the benefit of semantic smoothing for dependency kernels.", "labels": [], "entities": [{"text": "semantic role classification", "start_pos": 14, "end_pos": 42, "type": "TASK", "confidence": 0.7457559704780579}]}], "introductionContent": [{"text": "A central topic in Natural Language Processing is the design of lexical and syntactic features suitable for the target application.", "labels": [], "entities": []}, {"text": "The selection of effective patterns composed of syntactic dependencies and lexical constraints is typically a complex task.", "labels": [], "entities": []}, {"text": "Additionally, the availability of training data is usually scarce.", "labels": [], "entities": []}, {"text": "This requires the development of generalized features or the definition of semantic similarities between them, e.g. as proposed in or in semisupervised settings, e.g. ().", "labels": [], "entities": []}, {"text": "A semantic similarity can be defined at structural level over a graph, e.g., as well as combining structural and lexical similarity over semantic networks, e.g. ().", "labels": [], "entities": []}, {"text": "More recent research also focuses on mechanisms to define if two structures, e.g. graphs, are enough similar, as explored in).", "labels": [], "entities": []}, {"text": "On one hand, previous work shows that there is a substantial lack of automatic methods for engineering lexical/syntactic features (or more in general syntactic/semantic similarity).", "labels": [], "entities": []}, {"text": "On the other hand, automatic feature engineering of syntactic or shallow semantic structures has been carried out by means of structural kernels, e.g. (;).", "labels": [], "entities": []}, {"text": "The main idea of structural kernels is to generate structures that in turn represent syntactic or shallow semantic features.", "labels": [], "entities": []}, {"text": "Most notably, the work in) encodes lexical similarity in such kernels.", "labels": [], "entities": []}, {"text": "This is essentially the syntactic tree kernel (STK) proposed in () in which syntactic fragments from constituency trees can be matched even if they only differ in the leaf nodes (i.e. they have different surface forms).", "labels": [], "entities": []}, {"text": "This implies matching scores lower than 1, depending on the semantic similarity of the corresponding leaves in the syntactic fragments.", "labels": [], "entities": []}, {"text": "Although this kernel achieves state-of-the-art performance in NLP tasks, such as Question Classification) and Textual Entailment (, it offers clearly possibility of improvement: (i) better possibility to exploit semantic smoothing since, e.g., trivially STK only matches the syntactic structure apple/orange when comparing the big beautiful apple to a nice large orange; and (ii) STK cannot be effectively applied to dependency structures, e.g. see experiments and motivation in.", "labels": [], "entities": [{"text": "Question Classification", "start_pos": 81, "end_pos": 104, "type": "TASK", "confidence": 0.8495844006538391}, {"text": "Textual Entailment", "start_pos": 110, "end_pos": 128, "type": "TASK", "confidence": 0.7567827999591827}, {"text": "semantic smoothing", "start_pos": 212, "end_pos": 230, "type": "TASK", "confidence": 0.7142803072929382}]}, {"text": "Additionally, to our knowledge, there is no previous study that clearly describes how dependency structures should be converted in trees to be fully and effectively exploitable by convolution kernels.", "labels": [], "entities": []}, {"text": "Indeed, although the work in () defines a dependency tree also using node similarity, it is not a convolution kernel: this results in a much poorer feature space.", "labels": [], "entities": []}, {"text": "In this paper, we propose a study of convolution kernels for dependency structures aiming at jointly modeling syntactic and lexical semantic similarity.", "labels": [], "entities": []}, {"text": "More precisely, we define several dependency trees exploitable by the Partial Tree Kernel (PTK)) and compared them with STK over constituency trees.", "labels": [], "entities": []}, {"text": "Most importantly, we define an innovative and efficient class of kernels, i.e. the Smoothed Partial Tree Kernels (SPTKs), which can measure the similarity of structural similar trees whose nodes are associated with different but related lexicals.", "labels": [], "entities": []}, {"text": "Given the convolution nature of such kernels any possible node path of lexicals provide a contribution smoothed by the similarity accounted by its nodes.", "labels": [], "entities": []}, {"text": "The extensive experimentation on two datasets of question classification (QC) and semantic role labeling (SRL), shows that: (i) PTK applied to our dependency trees outperforms STK, demonstrating that dependency parsers are fully exploitable for feature engineering based on structural kernels; (ii) SPTK outperforms any previous kernels achieving an unprecedented result of 41% of error reduction with respect to the former state-of-the-art on QC; and (iii) the experiments on SRL confirm that the approach can be applied to different tasks without any tuning and again achieving state-of-the-art accuracy.", "labels": [], "entities": [{"text": "question classification (QC)", "start_pos": 49, "end_pos": 77, "type": "TASK", "confidence": 0.8403358340263367}, {"text": "semantic role labeling (SRL)", "start_pos": 82, "end_pos": 110, "type": "TASK", "confidence": 0.7547603994607925}, {"text": "error reduction", "start_pos": 381, "end_pos": 396, "type": "METRIC", "confidence": 0.9499075412750244}, {"text": "accuracy", "start_pos": 597, "end_pos": 605, "type": "METRIC", "confidence": 0.9938642978668213}]}, {"text": "In the reminder of this paper, Section 2 provides the background for structural and lexical similarity kernels.", "labels": [], "entities": []}, {"text": "Section 4 provides our representation models for dependency trees.", "labels": [], "entities": []}, {"text": "Section 5 presents the experimental evaluation for QC and SRL.", "labels": [], "entities": [{"text": "QC", "start_pos": 51, "end_pos": 53, "type": "TASK", "confidence": 0.6018521189689636}, {"text": "SRL", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.7110483646392822}]}, {"text": "Section 6 derives the conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We followed the idea in) for efficiently computing SPTK.", "labels": [], "entities": []}, {"text": "2 evaluated with respect to sequences of different length p; it follows that where \u2206 p evaluates the number of common subtrees rooted in subsequences of exactly p children (of n 1 and n 2 ) and m = min{l(c n1 ), l(c n2 )}.", "labels": [], "entities": []}, {"text": "Given the two child sequences s 1 a = c n 1 and s 2 b = c n 2 (a and bare the last children) where s 1 [1 : i] and s 2 [1 : r] are the child subsequences from 1 to i and from 1 tor of s 1 and s 2 . If we name the double summation term as D p , we can 1037 rewrite the relation as: Note that D p satisfies the recursive relation: By means of the above relation, we can compute the child subsequences of two sequences s 1 and s 2 in O(p|s 1 ||s 2 |).", "labels": [], "entities": []}, {"text": "Thus the worst case complexity of the SPTK is identical to PTK, i.e. where \u03c1 is the maximum branching factor of the two trees.", "labels": [], "entities": [{"text": "SPTK", "start_pos": 38, "end_pos": 42, "type": "TASK", "confidence": 0.8969079852104187}, {"text": "PTK", "start_pos": 59, "end_pos": 62, "type": "METRIC", "confidence": 0.5766714215278625}]}, {"text": "The latter is very small in natural language parse trees and we also avoid the computation of node pairs with non similar labels.", "labels": [], "entities": []}, {"text": "We note that PTK generalizes both (i) SK, allowing the similarity between sequences (node children) structured in a tree and (ii) STK, allowing the computation of STK over any possible pair of subtrees extracted from the original tree.", "labels": [], "entities": []}, {"text": "For this reason, we do not dedicate additional space on the definition of the smoothed SK or smoothed STK, which are in any case important corollary findings of our research.", "labels": [], "entities": []}, {"text": "The aim of the experiments is to analyze different levels of representation, i.e. structure, for syntactic dependency parses.", "labels": [], "entities": [{"text": "syntactic dependency parses", "start_pos": 97, "end_pos": 124, "type": "TASK", "confidence": 0.7394819060961405}]}, {"text": "At the same time, we compare with the constituency trees and different kernels to derive the best syntactic paradigm for convolution kernels.", "labels": [], "entities": []}, {"text": "Most importantly, the role of lexical similarity embedded in syntactic structures will be investigated.", "labels": [], "entities": []}, {"text": "For this purpose, we first carryout extensive experiments on coarse and fine grained QC and then we verify our findings on a completely different task, i.e. Argument Classification in SRL.", "labels": [], "entities": [{"text": "Argument Classification in SRL", "start_pos": 157, "end_pos": 187, "type": "TASK", "confidence": 0.6197143346071243}]}, {"text": "Tools: for SVM learning, we extended the SVMLightTK software 3 (Moschitti, 2006a) (which in-3 http://disi.unitn.it/moschitti/Tree-Kernel.htm cludes structural kernels in SVMLight) with the smooth match between tree nodes.", "labels": [], "entities": [{"text": "SVM learning", "start_pos": 11, "end_pos": 23, "type": "TASK", "confidence": 0.9659006297588348}]}, {"text": "For generating constituency trees, we used the Charniak parser) whereas we applied LTH syntactic parser (described in) to generate dependency trees.", "labels": [], "entities": []}, {"text": "Lexical Similarity: we used the Eq.", "labels": [], "entities": [{"text": "Lexical Similarity", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7466236054897308}]}, {"text": "1 with \u03c9 1 = \u03c9 2 = 1 and \u03c3 is derived with both approaches described in Sec.", "labels": [], "entities": []}, {"text": "The first approach is LSA-based: LSA was applied to ukWak (, which is a large scale document collection made by 2 billion tokens.", "labels": [], "entities": [{"text": "ukWak", "start_pos": 52, "end_pos": 57, "type": "DATASET", "confidence": 0.9779491424560547}]}, {"text": "More specifically, to build the matrix M, POS tagging is first applied to build rows with pairs lemma, ::POS, or lemma::POS in brief.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 42, "end_pos": 53, "type": "TASK", "confidence": 0.6545728147029877}]}, {"text": "The contexts of such items are the columns of M and are short windows of size, centered on the items.", "labels": [], "entities": []}, {"text": "This allows for better capturing syntactic properties of words.", "labels": [], "entities": []}, {"text": "The most frequent 20,000 items are selected along with their 20k contexts.", "labels": [], "entities": []}, {"text": "The entries of M are the point-wise mutual information between them.", "labels": [], "entities": []}, {"text": "The SVD reduction is then applied to M, with a dimensionality cut of l = 250.", "labels": [], "entities": [{"text": "dimensionality cut", "start_pos": 47, "end_pos": 65, "type": "METRIC", "confidence": 0.8999184668064117}]}, {"text": "The second approach uses the similarity based on word list (WL) as provided in (.", "labels": [], "entities": []}, {"text": "Models: SVM-LightTK is applied to the different tree representations discussed in Section 4.", "labels": [], "entities": []}, {"text": "Since PTK and SPTK are typically used in our experiments, to have a more compact acronym for each model, we associate the latter with the name of the structure, i.e. this indicates that PTK is applied to it.", "labels": [], "entities": [{"text": "PTK", "start_pos": 6, "end_pos": 9, "type": "DATASET", "confidence": 0.6381493210792542}]}, {"text": "Then the presence of the subscript W Land LSA indicates that SPTK is applied along with the corresponding similarity, e.g. LCT W L is the SPTK kernel applied to LCT structure, using WL similarity.", "labels": [], "entities": []}, {"text": "We experiment with multi-classification, which we model through one-vs-all scheme by selecting the category associated with the maximum SVM margin.", "labels": [], "entities": []}, {"text": "The quality of such classification is measured with accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9987758994102478}]}, {"text": "We determine the statistical signicance by using the model described in and implemented in).", "labels": [], "entities": []}, {"text": "The parameterization of each classifier is carried on a held-out set (30% of the training) and concerns with the setting of the trade-off parameter (optionc) and the Leaf Weight (LeW ) (see Sec.", "labels": [], "entities": [{"text": "Leaf Weight (LeW )", "start_pos": 166, "end_pos": 184, "type": "METRIC", "confidence": 0.8830618977546691}]}, {"text": "5.2), which is used to linearly scale the contribution of the leaf nodes.", "labels": [], "entities": []}, {"text": "In contrast, the cost-factor parameter of the SVM-LightTK is set as the ratio between the num-1040  For these experiments, we used the UIUC dataset ().", "labels": [], "entities": [{"text": "SVM-LightTK", "start_pos": 46, "end_pos": 57, "type": "DATASET", "confidence": 0.866087019443512}, {"text": "UIUC dataset", "start_pos": 135, "end_pos": 147, "type": "DATASET", "confidence": 0.9699137806892395}]}, {"text": "It is composed by a training set of 5,452 questions and a test set of 500 questions . Question classes are organized in two levels: 6 coarse-grained classes (like ENTITY or HUMAN) and 50 fine-grained sub-classes (e.g. Plant, Food as subclasses of ENTITY).", "labels": [], "entities": []}, {"text": "The outcome of the several kernels applied to several structures for the coarse and fine grained QC is reported in.", "labels": [], "entities": []}, {"text": "The first column shows the experimented models, obtained by applying PTK/SPTK to the structures described in Sec.", "labels": [], "entities": [{"text": "PTK", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.5209349393844604}]}, {"text": "4. The last two rows are: CT-STK, i.e. STK applied to a constituency tree and BOW, which is a linear ker-4 http://cogcomp.cs.illinois.edu/Data/QA/QC/ nel applied to lexical vectors.", "labels": [], "entities": [{"text": "CT-STK", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.8807973265647888}, {"text": "BOW", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.9982923865318298}]}, {"text": "Column 2, 3 and 4 report the accuracy using no, LSA and WL similarity, where LeW is the amplifying parameter, i.e. a weight associated with the leaves in the tree.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9996857643127441}, {"text": "LSA", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9771690964698792}, {"text": "WL similarity", "start_pos": 56, "end_pos": 69, "type": "METRIC", "confidence": 0.9430286288261414}, {"text": "LeW", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.9399375319480896}]}, {"text": "The last three columns refer to the fine grained task.", "labels": [], "entities": []}, {"text": "It is worth nothing that when no similarity is applied: (i) BOW produces high accuracy, i.e. 88.8% but it is improved by STK (the current state-of-theart 5 in QC (); (ii) PTK applied to the same tree of STK produces a slightly lower value (non-statistically significant difference); (iii) interestingly, when PTK is instead applied to dependency structures, it improves STK, i.e. 91.60% vs 91.40% (although not significantly); and (iv) LCT, strongly based on lexical nodes, is the least accurate, i.e 90.80% since it is obviously subject to data sparseness (fragments only composed by lexicals are very sparse).", "labels": [], "entities": [{"text": "BOW", "start_pos": 60, "end_pos": 63, "type": "METRIC", "confidence": 0.9848905205726624}, {"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9985173344612122}, {"text": "QC", "start_pos": 159, "end_pos": 161, "type": "DATASET", "confidence": 0.9270171523094177}, {"text": "STK", "start_pos": 370, "end_pos": 373, "type": "METRIC", "confidence": 0.6581419110298157}]}, {"text": "The very important results can be noted when lexical similarity is used, i.e. SPTK is applied: (a) all the syntactic-base structures using both LSA or WL improve the classification accuracy.", "labels": [], "entities": [{"text": "SPTK", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.7616447806358337}, {"text": "accuracy", "start_pos": 181, "end_pos": 189, "type": "METRIC", "confidence": 0.9789174795150757}]}, {"text": "(b) CT gets the lowest improvement whereas LCT achieves an impressive result of 94.80%, i.e more than 41% of relative error reduction.", "labels": [], "entities": [{"text": "CT", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.944656491279602}, {"text": "relative error reduction", "start_pos": 109, "end_pos": 133, "type": "METRIC", "confidence": 0.7766189972559611}]}, {"text": "It seems that the lexical similar paths when driven by syntax produces accurate features.", "labels": [], "entities": []}, {"text": "Indeed, when syntax is missing such as for the unstructured lexical path of LST LSA , the accuracy does not highly improve or may also decrease.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9995980858802795}]}, {"text": "Additionally, the result of our best model is so high that its errors only refer to questions like What did Jesse Jackson organize ?, where the classifier selected Entity instead of Human category.", "labels": [], "entities": []}, {"text": "These refer to clear cases where a huge amount of background knowledge is needed for deriving the exact solution.", "labels": [], "entities": []}, {"text": "Finally, on the fine grained experiments LCT still produces the most accurate outcome again exceeding the state-of-the-art (, where WL significantly improves on all models (CT included).", "labels": [], "entities": [{"text": "LCT", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.7527933120727539}, {"text": "WL", "start_pos": 132, "end_pos": 134, "type": "METRIC", "confidence": 0.9603674411773682}]}, {"text": "To verify that our findings are general and that our syntactic/semantic dependency kernels can be effectively exploited for diverse NLP tasks, we experimented with a completely different application, i.e. FrameNet SRL classification (gold standard boundaries).", "labels": [], "entities": [{"text": "FrameNet SRL classification", "start_pos": 205, "end_pos": 232, "type": "TASK", "confidence": 0.6373843848705292}]}, {"text": "We used the FrameNet version 1.3 with the 90/10% split between training and test set (i.e 271,560 and 30,173 examples respectively), as defined in), one of the best system for FrameNet parsing.", "labels": [], "entities": [{"text": "FrameNet version 1.3", "start_pos": 12, "end_pos": 32, "type": "DATASET", "confidence": 0.8888282775878906}, {"text": "FrameNet parsing", "start_pos": 176, "end_pos": 192, "type": "TASK", "confidence": 0.736897349357605}]}, {"text": "We used the LTH dependency parser.", "labels": [], "entities": [{"text": "LTH dependency parser", "start_pos": 12, "end_pos": 33, "type": "TASK", "confidence": 0.5719479521115621}]}, {"text": "LSA was applied to the BNC corpus, the source of the FrameNet annotations.", "labels": [], "entities": [{"text": "LSA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.6538401246070862}, {"text": "BNC corpus", "start_pos": 23, "end_pos": 33, "type": "DATASET", "confidence": 0.9789246916770935}]}, {"text": "For each of 648 frames, we applied SVM along with the best models for QC, i.e. GRCT and LCT, to learn its associated binary role classifiers (RC) fora total of 4,254 classifiers.", "labels": [], "entities": [{"text": "GRCT", "start_pos": 79, "end_pos": 83, "type": "DATASET", "confidence": 0.8680205345153809}]}, {"text": "For example, shows the LCT representation of the first two roles of the following sentence:   Finally, it should be noted that, to learn and test the SELF MOTION multi-classifier, containing 14,584 examples, distributed on 22 roles, SVM-SPTK employed 1.5 hand 10 minutes, respectively 6 .", "labels": [], "entities": [{"text": "SELF MOTION", "start_pos": 150, "end_pos": 161, "type": "METRIC", "confidence": 0.8236762583255768}]}], "tableCaptions": [{"text": " Table 1. The first column shows  the experimented models, obtained by applying  PTK/SPTK to the structures described in Sec. 4. The  last two rows are: CT-STK, i.e. STK applied to a  constituency tree and BOW, which is a linear ker-", "labels": [], "entities": [{"text": "BOW", "start_pos": 206, "end_pos": 209, "type": "METRIC", "confidence": 0.9985049962997437}]}, {"text": " Table 1: Accuracy of structural several kernels on different structures for coarse and fine grained QC", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9971526861190796}]}, {"text": " Table 2: Argument Classification Accuracy", "labels": [], "entities": [{"text": "Argument Classification", "start_pos": 10, "end_pos": 33, "type": "METRIC", "confidence": 0.8777175843715668}, {"text": "Accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.8286370635032654}]}]}