{"title": [{"text": "Unsupervised Structure Prediction with Non-Parallel Multilingual Guidance", "labels": [], "entities": [{"text": "Unsupervised Structure Prediction", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.5503615736961365}]}], "abstractContent": [{"text": "We describe a method for prediction of linguistic structure in a language for which only unlabeled data is available, using annotated data from a set of one or more helper languages.", "labels": [], "entities": [{"text": "prediction of linguistic structure", "start_pos": 25, "end_pos": 59, "type": "TASK", "confidence": 0.849768802523613}]}, {"text": "Our approach is based on a model that locally mixes between supervised models from the helper languages.", "labels": [], "entities": []}, {"text": "Parallel data is not used, allowing the technique to be applied even in domains where human-translated texts are unavailable.", "labels": [], "entities": []}, {"text": "We obtain state-of-the-art performance for two tasks of structure prediction: unsupervised part-of-speech tagging and unsupervised dependency parsing.", "labels": [], "entities": [{"text": "structure prediction", "start_pos": 56, "end_pos": 76, "type": "TASK", "confidence": 0.7185561656951904}, {"text": "part-of-speech tagging", "start_pos": 91, "end_pos": 113, "type": "TASK", "confidence": 0.667626217007637}, {"text": "dependency parsing", "start_pos": 131, "end_pos": 149, "type": "TASK", "confidence": 0.6986299157142639}]}], "introductionContent": [{"text": "A major focus of recent NLP research has involved unsupervised learning of structure such as POS tag sequences and parse trees (.", "labels": [], "entities": []}, {"text": "In its purest form, such research has improved our understanding of unsupervised learning practically and formally, and has led to a wide range of new algorithmic ideas.", "labels": [], "entities": []}, {"text": "Another strain of research has sought to exploit resources and tools in some languages (especially English) to construct similar resources and tools for other languages, through heuristic \"projection\" or constraints in learning) or inference ().", "labels": [], "entities": []}, {"text": "Joint unsupervised learning) is yet another research direction that seeks to learn models for many languages at once, exploiting linguistic universals and language similarity.", "labels": [], "entities": []}, {"text": "The driving force behind all of this work has been the hope of building NLP tools for languages that lack annotated resources.", "labels": [], "entities": []}, {"text": "In this paper, we present an approach to using annotated data from one or more languages (helper languages) to learn models for another language that lacks annotated data (the target language).", "labels": [], "entities": []}, {"text": "Unlike the previous work mentioned above, our framework does not rely on parallel data in any form.", "labels": [], "entities": []}, {"text": "This is advantageous because parallel text exists only in a few text domains (e.g., religious texts, parliamentary proceedings, and news).", "labels": [], "entities": []}, {"text": "We focus on generative probabilistic models parameterized by multinomial distributions.", "labels": [], "entities": []}, {"text": "We begin with supervised maximum likelihood estimates for models of the helper languages.", "labels": [], "entities": []}, {"text": "In the second stage, we learn a model for the target language using unannotated data, maximizing likelihood over interpolations of the helper language models' distributions.", "labels": [], "entities": []}, {"text": "The tying is performed at the parameter level, through coarse, nearly-universal syntactic categories (POS tags).", "labels": [], "entities": []}, {"text": "The resulting model is then used to initialize learning of the target language's model using standard unsupervised parameter estimation.", "labels": [], "entities": []}, {"text": "Some previous multilingual research, such as Bayesian parameter tying across languages) or models of parameter drift down phylogenetic trees ) is comparable, but the practical assumption of supervised helper languages is new to this work.", "labels": [], "entities": [{"text": "Bayesian parameter tying across languages", "start_pos": 45, "end_pos": 86, "type": "TASK", "confidence": 0.7309873998165131}]}, {"text": "used universal syntactic categories and rules to improve grammar induction, but their model required expert handwritten rules as constraints.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.7191392183303833}]}, {"text": "Herein, we specifically focus on two problems in linguistic structure prediction: unsupervised POS tagging and unsupervised dependency grammar induction.", "labels": [], "entities": [{"text": "linguistic structure prediction", "start_pos": 49, "end_pos": 80, "type": "TASK", "confidence": 0.6838279763857523}, {"text": "POS tagging", "start_pos": 95, "end_pos": 106, "type": "TASK", "confidence": 0.7747191488742828}, {"text": "dependency grammar induction", "start_pos": 124, "end_pos": 152, "type": "TASK", "confidence": 0.6603436668713888}]}, {"text": "Our experiments demonstrate that the presented method outperforms strong state-of-the-art unsupervised baselines for both tasks.", "labels": [], "entities": []}, {"text": "Our approach can be applied to other problems in which a subset of the model parameters can be linked across languages.", "labels": [], "entities": []}, {"text": "We also experiment with unsupervised learning of dependency structures from words, by combining our tagger and parser.", "labels": [], "entities": []}, {"text": "Our results show that combining our tagger and parser with joint inference outperforms pipeline inference, and, in several cases, even outperforms models built using gold-standard part-of-speech tags.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we describe the experiments undertaken and the results achieved.", "labels": [], "entities": []}, {"text": "We first note the characteristics of the datasets and the universal POS tags used in multilingual modeling.", "labels": [], "entities": []}, {"text": "For experiments, we considered three configurations, and for each, we implemented two variants of POS induction, one without any kind of supervision, and the other with a tag dictionary.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 98, "end_pos": 111, "type": "TASK", "confidence": 0.775881439447403}]}, {"text": "Our baseline is 56 the direct gradient approach of , which is the current state of the art for this task, outperforming classical HMMs.", "labels": [], "entities": []}, {"text": "Because this model achieves strong performance using straightforward MLE, it also serves as the core model within our approach.", "labels": [], "entities": [{"text": "MLE", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.9512428045272827}]}, {"text": "This model has also been applied in a multilingual setting with parallel data ( . In this baseline, we set the number of HMM states to the number of fine-grained treebank tags for the given language.", "labels": [], "entities": []}, {"text": "We test two versions of our model.", "labels": [], "entities": []}, {"text": "The first initializes training of the target language's POS model using a uniform mixture of the helper language models (i.e., each \u03b2 ,y = 1 L = 1 4 ), and expansion from coarse-grained to fine-grained POS tags as described in \u00a75.", "labels": [], "entities": []}, {"text": "We call this model \"Uniform+DG.\"", "labels": [], "entities": []}, {"text": "The second version estimates the mixture coefficients to maximize likelihood, then expands the POS tags ( \u00a75), using the result to initialize training of the final model.", "labels": [], "entities": [{"text": "likelihood", "start_pos": 66, "end_pos": 76, "type": "METRIC", "confidence": 0.9837788939476013}, {"text": "POS tags", "start_pos": 95, "end_pos": 103, "type": "DATASET", "confidence": 0.6555630564689636}]}, {"text": "We call this model \"Mixture+DG.\"", "labels": [], "entities": [{"text": "Mixture+DG", "start_pos": 20, "end_pos": 30, "type": "TASK", "confidence": 0.7148542205492655}]}, {"text": "No Tag Dictionary For each of the above configurations, we ran purely unsupervised training without a tag dictionary, and evaluated using one-to-one mapping accuracy constraining at most one HMM state to map to a unique treebank tag in the test data, using maximum bipartite matching.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 157, "end_pos": 165, "type": "METRIC", "confidence": 0.9473493695259094}]}, {"text": "This is a variant of the greedy one-to-one mapping scheme of.", "labels": [], "entities": []}, {"text": "With a Tag Dictionary We also ran a second version of each experimental configuration, where we used a tag dictionary to restrict the possible path sequences of the HMM during both learning and inference.", "labels": [], "entities": []}, {"text": "This tag dictionary was constructed only from the training section of a given language's treebank.", "labels": [], "entities": []}, {"text": "It is widely known that such knowledge improves the quality of the model, though it is an open debate whether such knowledge is realistic to assume.", "labels": [], "entities": []}, {"text": "For this experiment we removed punctuation from the training and test data, enabling direct use within the dependency grammar induction experiments.", "labels": [], "entities": [{"text": "dependency grammar induction", "start_pos": 107, "end_pos": 135, "type": "TASK", "confidence": 0.743914524714152}]}], "tableCaptions": [{"text": " Table 1: The first two rows show the sizes of the training and test datasets for each language. The third row shows the  number of fine POS tags in each language including punctuations.", "labels": [], "entities": []}, {"text": " Table 2: Results for unsupervised POS induction (a) without a tagging dictionary and (b) with a tag dictionary con- structed from the training section of the corresponding treebank. DG (at the bottom) stands for the direct gradient  method of", "labels": [], "entities": [{"text": "POS induction", "start_pos": 35, "end_pos": 48, "type": "TASK", "confidence": 0.8729376196861267}]}, {"text": " Table 3: Results for dependency grammar induction given gold-standard POS tags, reported as attachment accuracy  (fraction of parents which are correct). The three existing methods are: our replication of EM with the initializer from", "labels": [], "entities": [{"text": "dependency grammar induction", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.8726932406425476}, {"text": "attachment accuracy", "start_pos": 93, "end_pos": 112, "type": "METRIC", "confidence": 0.8098585307598114}]}, {"text": " Table 4: Results for dependency grammar induction over words. \"Joint\"/\"Pipeline\" refers to joint/pipeline decoding  of tags and dependencies as described in the text. See  \u00a76.3 for a description of DG and Mixture+DG. For the induction  of dependencies we use the Mixture+EM setting as described in  \u00a76.4. All tag induction uses a dictionary as specified  in  \u00a76.3. The last row in this table indicates the best results using multilingual guidance taken from our methods in", "labels": [], "entities": [{"text": "dependency grammar induction", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.7600064476331075}]}]}