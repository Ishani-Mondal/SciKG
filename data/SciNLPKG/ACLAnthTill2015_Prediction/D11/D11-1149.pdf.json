{"title": [{"text": "A Probabilistic Forest-to-String Model for Language Generation from Typed Lambda Calculus Expressions", "labels": [], "entities": [{"text": "Language Generation", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.7486272752285004}]}], "abstractContent": [{"text": "This paper describes a novel probabilistic approach for generating natural language sentences from their underlying semantics in the form of typed lambda calculus.", "labels": [], "entities": []}, {"text": "The approach is built on top of a novel reduction-based weighted synchronous context free grammar formalism, which facilitates the transformation process from typed lambda calculus into natural language sentences.", "labels": [], "entities": []}, {"text": "Sentences can then be generated based on such grammar rules with a log-linear model.", "labels": [], "entities": []}, {"text": "To acquire such grammar rules automatically in an unsuper-vised manner, we also propose a novel approach with a generative model, which maps from sub-expressions of logical forms to word sequences in natural language sentences.", "labels": [], "entities": []}, {"text": "Experiments on benchmark datasets for both En-glish and Chinese generation tasks yield significant improvements over results obtained by two state-of-the-art machine translation models, in terms of both automatic metrics and human evaluation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 158, "end_pos": 177, "type": "TASK", "confidence": 0.7330743372440338}]}], "introductionContent": [{"text": "This work focuses on the task of generating natural language sentences from their underlying meaning representations in the form of formal logical expressions (typed lambda calculus).", "labels": [], "entities": []}, {"text": "Many early approaches to generation from logical forms make use of rule-based methods, which concern surface realization (ordering and inflecting of words) but largely ignore lexical acquisition.", "labels": [], "entities": [{"text": "generation from logical forms", "start_pos": 25, "end_pos": 54, "type": "TASK", "confidence": 0.82286436855793}]}, {"text": "Recent approaches start to employ corpusbased probabilistic methods, but many of them assume the underlying meaning representations are of specific forms such as variable-free tree-structured representations) or database entries (.", "labels": [], "entities": []}, {"text": "While these algorithms usually work well on specific semantic formalisms, it is unclear how well they could be applied to a different semantic formalism.", "labels": [], "entities": []}, {"text": "In this work, we propose a general probabilistic model that performs generation from underlying formal semantics in the form of typed lambda calculus expressions (we refer to them as \u03bb-expressions throughout this paper), where both lexical acquisition and surface realization are integrated in a single framework.", "labels": [], "entities": []}, {"text": "One natural proposal is to adopt a state-of-the-art statistical machine translation approach.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 52, "end_pos": 83, "type": "TASK", "confidence": 0.6196585595607758}]}, {"text": "However, unlike text to text translation, which has been extensively studied in the machine translation community, translating from logical forms into text presents additional challenges.", "labels": [], "entities": [{"text": "text to text translation", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.7256649732589722}, {"text": "machine translation", "start_pos": 84, "end_pos": 103, "type": "TASK", "confidence": 0.7211763113737106}]}, {"text": "Specifically, logical forms such as \u03bb-expressions may have complex internal structures and variable dependencies across subexpressions.", "labels": [], "entities": []}, {"text": "Problems arise when performing automatic acquisition of a translation lexicon, as well as performing lexical selection and surface realization during generation.", "labels": [], "entities": [{"text": "automatic acquisition of a translation lexicon", "start_pos": 31, "end_pos": 77, "type": "TASK", "confidence": 0.7059859732786814}]}, {"text": "In this work, we tackle these challenges by making the following contributions: \u2022 A novel forest-to-string generation algorithm: Inspired by the work of Chiang (2007), we introduce a novel reduction-based weighted binary synchronous context-free grammar formalism for generation from logical forms (\u03bb-expressions), which can then be integrated with a probabilistic forest-to-string generation algo-rithm.", "labels": [], "entities": []}, {"text": "\u2022 A novel grammar induction algorithm: To automatically induce such synchronous grammar rules, we propose a novel generative model that establishes phrasal correspondences between logical sub-expressions and natural language word sequences, by extending a previous model proposed for parsing natural language into meaning representations ().", "labels": [], "entities": []}, {"text": "To our best knowledge, this is the first probabilistic model for generating sentences from the lambda calculus encodings of their underlying formal meaning representations, that concerns both surface realization and lexical acquisition.", "labels": [], "entities": [{"text": "surface realization", "start_pos": 192, "end_pos": 211, "type": "TASK", "confidence": 0.7835797369480133}]}, {"text": "We demonstrate the effectiveness of our model in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "For experiments, we evaluated on the GEOQUERY dataset, which consists of 880 queries on U.S. geography.", "labels": [], "entities": [{"text": "GEOQUERY dataset", "start_pos": 37, "end_pos": 53, "type": "DATASET", "confidence": 0.9508687853813171}]}, {"text": "The dataset was manually labeled with \u03bb-expressions as their semantics in.", "labels": [], "entities": []}, {"text": "It was used in many previous research efforts on semantic parsing).", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 49, "end_pos": 65, "type": "TASK", "confidence": 0.8531605899333954}]}, {"text": "The original dataset was annotated with English sentences only.", "labels": [], "entities": []}, {"text": "In order to assess the generation performance across different languages, in our work the entire dataset was also manually annotated with Chinese by a native Chinese speaker with linguistics background . For all the experiments we present in this section, we use the same split as that of, where 280 instances are used for testing, and the remaining instances are used for learning.", "labels": [], "entities": []}, {"text": "We further split the learning set into two portions, where 500 instances are used for training the models, which includes induction of grammar rules, training a language model, and computing feature values, and the remaining 100 instances are used for tuning the feature weights.", "labels": [], "entities": []}, {"text": "As we have mentioned earlier, we are not aware of any previous work that performs generation from formal logical forms that concerns both lexical acquisition and surface realization.", "labels": [], "entities": [{"text": "surface realization", "start_pos": 162, "end_pos": 181, "type": "TASK", "confidence": 0.7520362436771393}]}, {"text": "The recent work by presented a generation system from database records with an additional focus on content selection (selection of records and their subfields for generation).", "labels": [], "entities": []}, {"text": "It is not obvious how to adopt their algorithm in our context where content selection is not required but the more complex logical semantic representation is used as input.", "labels": [], "entities": []}, {"text": "Other earlier approaches such as the work of and made use of rule-based approaches without automatic lexical acquisition.", "labels": [], "entities": []}, {"text": "We thus compare our system against two stateof-the-art machine translation systems: a phrasebased translation system, implemented in the Moses toolkit ( , and a hierarchical phrase-based translation system, implemented in the Joshua toolkit (, which is a reimplementation of the original Hiero system.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.7473003268241882}, {"text": "phrasebased translation", "start_pos": 86, "end_pos": 109, "type": "TASK", "confidence": 0.6787281036376953}]}, {"text": "The state-of-the-art unsupervised Berkeley aligner () with default setting is used to construct word alignments.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 96, "end_pos": 111, "type": "TASK", "confidence": 0.6867121905088425}]}, {"text": "We train a trigram language model with modified Kneser-Ney smoothing from the training dataset using the SRILM toolkit, and use the same language model for all three systems.", "labels": [], "entities": [{"text": "SRILM toolkit", "start_pos": 105, "end_pos": 118, "type": "DATASET", "confidence": 0.8898832201957703}]}, {"text": "We use an n-best list of size 100 for all three systems when performing MERT.", "labels": [], "entities": [{"text": "MERT", "start_pos": 72, "end_pos": 76, "type": "TASK", "confidence": 0.8381629586219788}]}, {"text": "For automatic evaluation, we measure the original IBM BLEU score () (4-gram precision with brevity penalty) and the TER score () (the amount of edits required to change a system output into the reference) . Note that TER measures the translation error rate, thus a smaller score indicates a better result.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 54, "end_pos": 64, "type": "METRIC", "confidence": 0.9300820827484131}, {"text": "precision", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9391039609909058}, {"text": "TER score", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.9905836284160614}, {"text": "TER", "start_pos": 217, "end_pos": 220, "type": "METRIC", "confidence": 0.9700291156768799}]}, {"text": "For clarity, we report 1\u2212TER scores.", "labels": [], "entities": [{"text": "TER", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.9261807799339294}]}, {"text": "Following the tuning procedure as conducted in, we perform MERT using BLEU as the metric.", "labels": [], "entities": [{"text": "MERT", "start_pos": 59, "end_pos": 63, "type": "METRIC", "confidence": 0.9911276698112488}, {"text": "BLEU", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.9987302422523499}]}, {"text": "We compare our model against state-of-the-art statistical machine translation systems.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 46, "end_pos": 77, "type": "TASK", "confidence": 0.6704249382019043}]}, {"text": "As a baseline, we first conduct an experiment with the following naive approach: we treat the \u03bb-expressions as plain texts.", "labels": [], "entities": []}, {"text": "All the bound variables (e.g., x in \u03bbx.state(x)) which do not convey semantics are removed, but free variables (e.g., state in \u03bbx.state(x)) which might convey semantics are left intact.", "labels": [], "entities": []}, {"text": "Quantifiers and logical connectives are also left intact.", "labels": [], "entities": []}, {"text": "While this naive approach might not appear very sensible, we merely want to treat it as our simplest baseline.", "labels": [], "entities": []}, {"text": "Alternatively, analogous to the work of Wong and Mooney (2007a), we could first parse the \u03bb-expressions into binary tree structures with a deterministic procedure, and then linearize the tree structure as a sequence.", "labels": [], "entities": []}, {"text": "Since there exists different ways to linearize a binary tree, we consider preorder, inorder, and postorder traversal of the trees, and linearize them in these three different ways.", "labels": [], "entities": []}, {"text": "As for our system, during the grammar learning phase, we initialize the generative model parameters with output from the IBM alignment model 1 ( 8 , and run the \u03bb-hybrid tree generative model with the unigram emission assumption for 10 iterations, followed by another 10 iterations with the bigram assumption.", "labels": [], "entities": []}, {"text": "Grammar rules are then extracted based on the \u03bb-hybrid trees obtained from such learned generative model parameters.", "labels": [], "entities": []}, {"text": "Since MERT is prone to search errors, we run each experiment 5 times with randomly initialized feature weights, and report the averaged scores.", "labels": [], "entities": [{"text": "MERT", "start_pos": 6, "end_pos": 10, "type": "TASK", "confidence": 0.6374015808105469}]}, {"text": "Experimental results for both English and Chinese are presented in.", "labels": [], "entities": []}, {"text": "As we can observe, the way that a meaning representation tree is linearized has a significant impact on the translation performance.", "labels": [], "entities": []}, {"text": "Interestingly, for both Moses and Joshua, the preorder setting yields the best performance for English, whereas it is inorder that yields the best performance for Chinese.", "labels": [], "entities": []}, {"text": "This is perhaps due to the fact that Chinese presents a very different syntactic structure and word ordering from English.", "labels": [], "entities": []}, {"text": "We assume word unigrams are generated from free variables, quantifiers, and logical connectives in IBM model 1.", "labels": [], "entities": []}, {"text": "Our system, on the other hand, employs a packed forest representation for \u03bb-expressions.", "labels": [], "entities": []}, {"text": "Therefore, it eliminates the ordering constraint by encompassing exponentially many possible tree structures during both the alignment and decoding stage.", "labels": [], "entities": []}, {"text": "As a result, our system obtains significant improvements in both BLEU and 1\u2212TER using the significance test under the paired bootstrap resampling method of.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 65, "end_pos": 69, "type": "METRIC", "confidence": 0.9995573163032532}, {"text": "TER", "start_pos": 76, "end_pos": 79, "type": "METRIC", "confidence": 0.6145681738853455}]}, {"text": "We obtain p < 0.01 for all cases, except when comparing against Joshua-preorder for English, where we obtain p < 0.05 for both metrics.", "labels": [], "entities": []}, {"text": "We also conducted human evaluation with 5 evaluators each on English and Chinese.", "labels": [], "entities": []}, {"text": "We randomly selected about 50% (139) test instances and obtained output sentences from the three systems.", "labels": [], "entities": []}, {"text": "Moses and Joshua were run with the top-performing settings in terms of automatic metrics (i.e., preorder for English and inorder for Chinese For each test instance, we first randomly shuffled the output sentences of the three systems, and presented them together with the correct reference to the evaluators.", "labels": [], "entities": [{"text": "preorder", "start_pos": 96, "end_pos": 104, "type": "METRIC", "confidence": 0.984516441822052}]}, {"text": "The evaluators were then asked to score all the output sentences at once.", "labels": [], "entities": []}, {"text": "This evaluation process not only ensures that the annotators have no access to which system generated the out-  put, but also minimizes bias associated with scoring different outputs for the same input.", "labels": [], "entities": []}, {"text": "The detailed and averaged results (with one standard deviation) for human evaluation are presented in for English and Chinese respectively.", "labels": [], "entities": []}, {"text": "For both languages, our system achieves a significant improvement over Moses and Joshua (p < 0.01 with paired t-tests), in terms of both language fluency and semantic correctness.", "labels": [], "entities": []}, {"text": "This set of results is important, as it demonstrates that our system produces more fluent texts with more accurate semantics when perceived by real humans.", "labels": [], "entities": []}, {"text": "We also performed the following additional experiments.", "labels": [], "entities": []}, {"text": "First, we attempted to increase the number of EM iterations (to 100) when training the model with the bigram assumption, so as to assess the effect of the number of EM iterations on the final generation performance.", "labels": [], "entities": []}, {"text": "Second, in order to assess the importance of the two types of novel rules -subtree rules (type 2) and two-level \u03bb-hybrid sequence rules (type 3), we also conducted experiments without these rules for generation.", "labels": [], "entities": []}, {"text": "Experiments show that these two types of rules are important.", "labels": [], "entities": []}, {"text": "Specifically, type 3 rules, which are able to capture longer structural dependencies, are of particular importance for generating Chinese.", "labels": [], "entities": []}, {"text": "Detailed results for these additional experiments are presented in.", "labels": [], "entities": []}, {"text": "Finally, we also assess the effectiveness of our model on an alternative meaning representation formalism in the form of variable-free tree structures.", "labels": [], "entities": []}, {"text": "Specifically, we tested on the ROBOCUP dataset (), which consists of 300 English instructions for coaching robots for soccer games, and a variable-free version of the GEO-QUERY dataset.", "labels": [], "entities": [{"text": "ROBOCUP dataset", "start_pos": 31, "end_pos": 46, "type": "DATASET", "confidence": 0.8782418668270111}, {"text": "GEO-QUERY dataset", "start_pos": 167, "end_pos": 184, "type": "DATASET", "confidence": 0.9687026739120483}]}, {"text": "These are the standard datasets used in the generation tasks of Wong and Mooney (2007a) and.", "labels": [], "entities": []}, {"text": "Similar to the technique introduced in, our proposed algorithm could still be applied to such datasets by writing the tree-structured representations as function-arguments forms.", "labels": [], "entities": []}, {"text": "The higher order unification-based decomposition algorithm could be applied on top of such forms accordingly.", "labels": [], "entities": [{"text": "unification-based decomposition", "start_pos": 17, "end_pos": 48, "type": "TASK", "confidence": 0.8289842903614044}]}, {"text": "For example, midf ield(opp) \u2261 \u03bbx.midf ield(x) \u00a1 opp.", "labels": [], "entities": []}, {"text": "However, since such forms present monotonous structures, and thus give less alternative options in the higher-order unification-based decomposition process, it prevents the algorithm from creating many disjunctive nodes in the packed forest.", "labels": [], "entities": []}, {"text": "It is thus hypothesized that the advantages of the packed forest representation could not be fully exploited with such a meaning representation formalism.", "labels": [], "entities": []}, {"text": "Following previous works, we performed 4 runs of 10-fold cross validation based on the same split as that of and, and measured standard BLEU percentage and NIST) scores.", "labels": [], "entities": [{"text": "BLEU percentage", "start_pos": 136, "end_pos": 151, "type": "METRIC", "confidence": 0.9828391373157501}, {"text": "NIST", "start_pos": 156, "end_pos": 160, "type": "METRIC", "confidence": 0.6740119457244873}]}, {"text": "For experimentation on each fold, we trained a trigram language model on the training data of that fold, and randomly selected 70% of the training data for grammar induction, with the remaining 30% for learning of the feature weights using MERT.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 156, "end_pos": 173, "type": "TASK", "confidence": 0.7960746884346008}]}, {"text": "Next, we performed grammar induction with the complete training data of that fold, and used the learned feature weights for decoding of the test instances.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.8333798944950104}]}, {"text": "The averaged results are shown in Table 3.", "labels": [], "entities": []}, {"text": "Our approach outperforms the previous system WASP \u22121 ++ (Wong and Mooney, 2007a) significantly, and achieves comparable or slightly better performance as compared to.", "labels": [], "entities": []}, {"text": "This set of results is particularly striking.", "labels": [], "entities": []}, {"text": "We note argmax what is the longest river in the states that border indiana \u03bb-expression : density(\u03b9x.loc(argmax(y, loc(y, usa co) \u2227 river(y), size(y)), x) \u2227 state(x)) Reference : which is the density of the state that the largest river in the united states runs through Moses : what is the population density in lie on the state with the smallest state in the us Joshua : what is the population density of states lie on the smallest state in the us This work : what is the population density of the state with the largest river in the us Variable-free datasets \u03bb-expression : population(largest one density(state all)) Reference : what is the population of the state with the highest population density This work : how many people live in the state with the largest population density \u03bb-expression : rule(and(bpos(f rom goal line(our, jnum(n0.0, n32.0))), not(bpos(lef t(penalty area(our))))),-dont(player our(n3), intercept)) Reference : player 3 should not intercept the ball if the ball is within 32 meters of our goal line and not in our left penalty area This work : if the ball is within 32 meters from our goal line and not on the left side of our penalty area then player 3 should not intercept it that the algorithm of is capable of modeling dependencies over phrases, which gives global optimization over the sentence generated, and works by building conditional random fields) over trees.", "labels": [], "entities": []}, {"text": "But the algorithm of is also limited to handling treestructured meaning representation, and is therefore unable to accept inputs such as the variable version of \u03bb-expressions.", "labels": [], "entities": []}, {"text": "Our algorithm works well by introducing additional new types of synchronous rules that are able to capture longer range dependencies.", "labels": [], "entities": []}, {"text": "WASP \u22121 ++, on the other hand, also makes use of asynchronous parsing-based statistical machine translation approach.", "labels": [], "entities": [{"text": "parsing-based statistical machine translation", "start_pos": 62, "end_pos": 107, "type": "TASK", "confidence": 0.708943784236908}]}, {"text": "Their system, however, requires linearization of the tree structure for both alignment and translation.", "labels": [], "entities": []}, {"text": "In contrast, our model directly performs alignment and translation from a packed forest representation to a sentence.", "labels": [], "entities": []}, {"text": "As a result, though WASP \u22121 ++ made use of additional features (lexical weights), our system yielded better performance.", "labels": [], "entities": []}, {"text": "Sample English output sentences are given in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance on generating English and Chinese from  \u03bb-expressions with automatic evaluation metrics (we report per- centage scores).", "labels": [], "entities": []}, {"text": " Table 2: Human evaluation results on English and Chinese generation. FLU: language fluency; SEM: semantic correctness.", "labels": [], "entities": [{"text": "English and Chinese generation", "start_pos": 38, "end_pos": 68, "type": "TASK", "confidence": 0.6788502633571625}, {"text": "FLU", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.9976123571395874}, {"text": "SEM", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.944833517074585}]}, {"text": " Table 3: Performance on variable-free representations", "labels": [], "entities": []}]}