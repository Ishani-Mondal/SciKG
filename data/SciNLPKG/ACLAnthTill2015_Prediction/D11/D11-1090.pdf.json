{"title": [{"text": "Enhancing Chinese Word Segmentation Using Unlabeled Data", "labels": [], "entities": [{"text": "Enhancing Chinese Word Segmentation", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8275834172964096}]}], "abstractContent": [{"text": "This paper investigates improving supervised word segmentation accuracy with unlabeled data.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.675340473651886}, {"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.7920936942100525}]}, {"text": "Both large-scale in-domain data and small-scale document text are considered.", "labels": [], "entities": []}, {"text": "We present a unified solution to include features derived from unlabeled data to a discrimina-tive learning model.", "labels": [], "entities": []}, {"text": "For the large-scale data, we derive string statistics from Gigaword to assist a character-based segmenter.", "labels": [], "entities": []}, {"text": "In addition , we introduce the idea about transductive, document-level segmentation, which is designed to improve the system recall for out-of-vocabulary (OOV) words which appear more than once inside a document.", "labels": [], "entities": [{"text": "document-level segmentation", "start_pos": 56, "end_pos": 83, "type": "TASK", "confidence": 0.6620718091726303}, {"text": "recall", "start_pos": 125, "end_pos": 131, "type": "METRIC", "confidence": 0.9900667667388916}]}, {"text": "Novel features 1 result in relative error reductions of 13.8% and 15.4% in terms of F-score and the recall of OOV words respectively.", "labels": [], "entities": [{"text": "relative error reductions", "start_pos": 27, "end_pos": 52, "type": "METRIC", "confidence": 0.7688267429669698}, {"text": "F-score", "start_pos": 84, "end_pos": 91, "type": "METRIC", "confidence": 0.9991839528083801}, {"text": "recall", "start_pos": 100, "end_pos": 106, "type": "METRIC", "confidence": 0.9991146922111511}]}], "introductionContent": [{"text": "Chinese sentences are written in continuous sequence of characters without explicit delimiters such as space characters.", "labels": [], "entities": []}, {"text": "To find the basic language units, i.e. words, segmentation is a necessary initial step for Chinese language processing.", "labels": [], "entities": [{"text": "Chinese language processing", "start_pos": 91, "end_pos": 118, "type": "TASK", "confidence": 0.6892085274060568}]}, {"text": "Previous research shows that word segmentation models trained on labeled data are reasonably accurate.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.7577700316905975}]}, {"text": "In this paper, we investigate improving supervised word segmentation with unlabeled data.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.7074667662382126}]}, {"text": "We distinguish three types of unlabeled data, namely large-scale in-domain data, out-of-domain data and small-scale document text.", "labels": [], "entities": []}, {"text": "Both large-scale in-domain and out-of-domain data is popular for enhancing NLP tasks.", "labels": [], "entities": [{"text": "NLP tasks", "start_pos": 75, "end_pos": 84, "type": "TASK", "confidence": 0.8785973191261292}]}, {"text": "Learning from these two types of unlabeled data normally involves semi-supervised learning.", "labels": [], "entities": []}, {"text": "The difference between them is that outof-domain data is usually used for domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 74, "end_pos": 91, "type": "TASK", "confidence": 0.7560060620307922}]}, {"text": "For a number of NLP tasks, there are relatively large amounts of labeled training data.", "labels": [], "entities": []}, {"text": "In this situation, supervised learning can provide competitive results, and it is difficult to improve them any further by using extra unlabeled data.", "labels": [], "entities": []}, {"text": "Chinese word segmentation is one of this kind of tasks, since several large-scale manually annotated corpora are publicly available.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.5301133294900259}]}, {"text": "In this work, we first exploit unlabeled indomain data to improve strong supervised models.", "labels": [], "entities": []}, {"text": "We leave domain adaptation for our future work.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.7849952578544617}]}, {"text": "We introduce the third type of unlabeled data with a transductive learning, document-level view.", "labels": [], "entities": []}, {"text": "Many applications of word segmentation involve processing a whole document, such as information retrieval.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.7413901090621948}, {"text": "information retrieval", "start_pos": 84, "end_pos": 105, "type": "TASK", "confidence": 0.8186888992786407}]}, {"text": "In this situation, the text of the current document can provide additional useful information to segment a sentence.", "labels": [], "entities": []}, {"text": "Take the word \"\u6c28\u7eb6\u4e1d/elastane\" for example . As a translated terminology word, it lacks compositionality.", "labels": [], "entities": []}, {"text": "Moreover, this word appears rarely in general texts.", "labels": [], "entities": []}, {"text": "As a result, if it does not appear in the training data, it is very hard for statistical models to recognize this word.", "labels": [], "entities": []}, {"text": "Nevertheless, when we deal with an article discussing an elastane company, this word may appear more than once in this article, and the document information can help recognize this word.", "labels": [], "entities": []}, {"text": "This idea is closely related to transductive learning in the sense that the segmentation model knows something about the problem it is going to resolve.", "labels": [], "entities": []}, {"text": "In this work, we are also concerned with enhancing word segmentation with the document information.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.7035142332315445}]}, {"text": "We present a unified \"feature engineering\" approach for learning segmentation models from both labeled and unlabeled data.", "labels": [], "entities": []}, {"text": "Our method is a simple two-stage process.", "labels": [], "entities": []}, {"text": "First, we use unannotated corpus to extract string and document information, and then we use these information to construct new statisticsbased and document-based feature mapping fora discriminative word segmenter.", "labels": [], "entities": []}, {"text": "We are relying on the ability of discriminative learning method to identify and explore informative features, which play central role to boost the segmentation performance.", "labels": [], "entities": []}, {"text": "This simple solution has been shown effective for named entity recognition) and dependency parsing (.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 50, "end_pos": 74, "type": "TASK", "confidence": 0.6929578185081482}, {"text": "dependency parsing", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.8989987671375275}]}, {"text": "In their implementations, word clusters derived from unlabeled data are imported as features to discriminative learning approaches.", "labels": [], "entities": []}, {"text": "To demonstrate the effectiveness of our approach, we conduct experiments on the Penn Chinese Treebank (CTB) data.", "labels": [], "entities": [{"text": "Penn Chinese Treebank (CTB) data", "start_pos": 80, "end_pos": 112, "type": "DATASET", "confidence": 0.9810203824724469}]}, {"text": "CTB is a collection of documents which are separately annotated.", "labels": [], "entities": [{"text": "CTB", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8869826197624207}]}, {"text": "This annotation style allows us to evaluate our transductive segmentation method.", "labels": [], "entities": []}, {"text": "Our experiments show that both statistics-based and document-based features are effective in the word segmentation application.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 97, "end_pos": 114, "type": "TASK", "confidence": 0.7763506472110748}]}, {"text": "In general, the use of unlabeled data can be motivated by two concerns: First, given a fixed amount of labeled data, we might wish to leverage unlabeled data to improve the performance of a supervised model.", "labels": [], "entities": []}, {"text": "Second, given a fixed target performance level, we might wish to use unlabeled data to reduce the amount of annotated data necessary to reach this target.", "labels": [], "entities": []}, {"text": "We show that our approach yields improvements for fixed data sets, even when large-scale labeled data is available.", "labels": [], "entities": []}, {"text": "The new features result in relative error reductions of 13.8% and 15.4% in terms of the balanced F-score and the recall of out-of-vocabulary (OOV) words respectively.", "labels": [], "entities": [{"text": "error", "start_pos": 36, "end_pos": 41, "type": "METRIC", "confidence": 0.5846531987190247}, {"text": "F-score", "start_pos": 97, "end_pos": 104, "type": "METRIC", "confidence": 0.9873597025871277}, {"text": "recall", "start_pos": 113, "end_pos": 119, "type": "METRIC", "confidence": 0.9990361928939819}]}, {"text": "By conducting experiments on data sets of varying sizes, we demonstrate that for fixed levels of performance, the new features derived from unlabeled data can significantly reduce the need of labeled data.", "labels": [], "entities": []}, {"text": "The remaining part of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the details of our system, especially the design of the derived features.", "labels": [], "entities": []}, {"text": "B Current character is the start of a word consisting of more than one character.", "labels": [], "entities": []}, {"text": "E Current character is the end of a word consisting of more than one character.", "labels": [], "entities": [{"text": "E Current character", "start_pos": 0, "end_pos": 19, "type": "METRIC", "confidence": 0.7900540033976237}]}, {"text": "I Current character is a middle of a word consisting of more than two characters.", "labels": [], "entities": []}, {"text": "S Current character is a word consisting of only one character.", "labels": [], "entities": []}, {"text": "Section 3 presents experimental results and empirical analysis.", "labels": [], "entities": []}, {"text": "Section 4 reviews the related work.", "labels": [], "entities": []}, {"text": "Section 5 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Training, development and test data on CTB 6.0", "labels": [], "entities": [{"text": "CTB 6.0", "start_pos": 49, "end_pos": 56, "type": "DATASET", "confidence": 0.913318932056427}]}, {"text": " Table 4: Segmentation performance on the test data.", "labels": [], "entities": []}]}