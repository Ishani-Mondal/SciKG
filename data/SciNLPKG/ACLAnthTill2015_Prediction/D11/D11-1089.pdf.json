{"title": [{"text": "Splitting Noun Compounds via Monolingual and Bilingual Paraphrasing: A Study on Japanese Katakana Words", "labels": [], "entities": [{"text": "Splitting Noun Compounds", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9142576654752096}]}], "abstractContent": [{"text": "Word boundaries within noun compounds are not marked by white spaces in a number of languages, unlike in English, and it is beneficial for various NLP applications to split such noun compounds.", "labels": [], "entities": []}, {"text": "In the case of Japanese, noun compounds made up of katakana words (i.e., transliterated foreign words) are particularly difficult to split, because katakana words are highly productive and are often out-of-vocabulary.", "labels": [], "entities": []}, {"text": "To overcome this difficulty, we propose using monolingual and bilingual paraphrases of katakana noun compounds for identifying word boundaries.", "labels": [], "entities": [{"text": "identifying word boundaries", "start_pos": 115, "end_pos": 142, "type": "TASK", "confidence": 0.8213626344998678}]}, {"text": "Experiments demonstrated that splitting accuracy is substantially improved by extracting such paraphrases from unlabeled textual data, the Web in our case, and then using that information for constructing splitting models.", "labels": [], "entities": [{"text": "splitting", "start_pos": 30, "end_pos": 39, "type": "TASK", "confidence": 0.9773154258728027}, {"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.8748063445091248}]}], "introductionContent": [], "datasetContent": [{"text": "We conducted experiments to investigate how the use of the paraphrasing and the back-transliteration improves the performance of the discriminative model.", "labels": [], "entities": []}, {"text": "To train the phonetic similarity model, we used a set of transliteration pairs extracted from the Wikipedia.", "labels": [], "entities": []}, {"text": "Since person names are almost always transliterated when they are imported from English into Japanese, we made use of the Wikipedia articles that belong to the Living people category.", "labels": [], "entities": []}, {"text": "From the titles of those articles, we automatically extracted person names written in katakana, together with their English counterparts obtainable via the multilingual links provided by the Wikipedia.", "labels": [], "entities": []}, {"text": "This yielded 17,509 transliteration pairs for training.", "labels": [], "entities": []}, {"text": "In performing the EM algorithm, we tried ten different initial parameters and selected the model that achieved the highest likelihood.", "labels": [], "entities": [{"text": "likelihood", "start_pos": 123, "end_pos": 133, "type": "METRIC", "confidence": 0.9795039296150208}]}, {"text": "The data for training and testing the perceptron was built using a Japanese-English dictionary EDICT.", "labels": [], "entities": [{"text": "Japanese-English dictionary EDICT", "start_pos": 67, "end_pos": 100, "type": "DATASET", "confidence": 0.6113130152225494}]}, {"text": "We randomly extracted 5286 entries written in katakana from EDICT and manually annotated word boundaries by establishing word correspondences to their English transliterations.", "labels": [], "entities": []}, {"text": "Since English transliterations are already provided by EDICT, the annotation can be trivially done by native speakers of Japanese.", "labels": [], "entities": [{"text": "EDICT", "start_pos": 55, "end_pos": 60, "type": "DATASET", "confidence": 0.9276357293128967}]}, {"text": "Using this data set, we performed 2-fold cross-validation for testing the perceptron.", "labels": [], "entities": []}, {"text": "The number of iterations was set to 20 in all the experiments.", "labels": [], "entities": []}, {"text": "To compute the dictionary-based feature DICT(y) in our basic feature set, we used NAIST-jdic.", "labels": [], "entities": [{"text": "NAIST-jdic", "start_pos": 82, "end_pos": 92, "type": "DATASET", "confidence": 0.9713469743728638}]}, {"text": "It is the largest dictionary used for Japanese word segmentation, and it includes 19,885 katakana words.", "labels": [], "entities": [{"text": "Japanese word segmentation", "start_pos": 38, "end_pos": 64, "type": "TASK", "confidence": 0.6108692387739817}]}, {"text": "As Web corpora, we used 1.7 G sentences of blog articles.", "labels": [], "entities": []}, {"text": "From the corpora, we extracted 14,966,205 (potential) paraphrases of katakana noun compounds together with their frequencies.", "labels": [], "entities": []}, {"text": "We also extracted 151,195 word-aligned transliteration pairs.", "labels": [], "entities": []}, {"text": "In doing this, we ranged the threshold \u03b8 in {\u221210, \u221220, \u00b7 \u00b7 \u00b7 \u2212 150} and chose the value that performed the best (\u03b8 = \u221280).", "labels": [], "entities": []}, {"text": "The results were evaluated using precision, recall, F 1 -score, and accuracy.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9997597336769104}, {"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9997147917747498}, {"text": "F 1 -score", "start_pos": 52, "end_pos": 62, "type": "METRIC", "confidence": 0.9895172268152237}, {"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9992892742156982}]}, {"text": "Precision is the number of correctly identified words divided by the number of all identified words, recall is the number of correctly identified words divided by the number of all oracle words, the F 1 -score is their harmonic mean, and accuracy is the number of correctly split katakana noun compounds divided by the number of all the katakana noun compounds.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9901592135429382}, {"text": "recall", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.9992181062698364}, {"text": "F 1 -score", "start_pos": 199, "end_pos": 209, "type": "METRIC", "confidence": 0.9887272119522095}, {"text": "accuracy", "start_pos": 238, "end_pos": 246, "type": "METRIC", "confidence": 0.9995668530464172}]}], "tableCaptions": [{"text": " Table 3: Word-aligned transliteration pairs. The number  indicates the word alignment.", "labels": [], "entities": []}, {"text": " Table 5: Comparison with baseline systems.", "labels": [], "entities": []}, {"text": " Table 6: Splitting results of the supervised systems for w/ OOV and w/o OOV data.", "labels": [], "entities": [{"text": "Splitting", "start_pos": 10, "end_pos": 19, "type": "TASK", "confidence": 0.9718690514564514}]}, {"text": " Table 7: Effectiveness of paraphrase (PARA) and back- transliteration feature (TRANS).", "labels": [], "entities": [{"text": "Effectiveness of paraphrase (PARA)", "start_pos": 10, "end_pos": 44, "type": "METRIC", "confidence": 0.8308294912179311}, {"text": "back- transliteration feature (TRANS)", "start_pos": 49, "end_pos": 86, "type": "METRIC", "confidence": 0.6753964977605003}]}]}