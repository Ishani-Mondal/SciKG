{"title": [{"text": "Relaxed Cross-lingual Projection of Constituent Syntax", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a relaxed correspondence assumption for cross-lingual projection of constituent syntax, which allows a supposed constituent of the target sentence to correspond to an unrestricted treelet in the source parse.", "labels": [], "entities": [{"text": "cross-lingual projection of constituent syntax", "start_pos": 51, "end_pos": 97, "type": "TASK", "confidence": 0.8349156737327575}]}, {"text": "Such a relaxed assumption fundamentally tolerates the syntactic non-isomorphism between languages, and enables us to learn the target-language-specific syntactic idiosyncrasy rather than a strained grammar directly projected from the source language syntax.", "labels": [], "entities": []}, {"text": "Based on this assumption, a novel constituency projection method is also proposed in order to induce a projected constituent tree-bank from the source-parsed bilingual corpus.", "labels": [], "entities": []}, {"text": "Experiments show that, the parser trained on the projected treebank dramatically out-performs previous projected and unsupervised parsers.", "labels": [], "entities": []}], "introductionContent": [{"text": "For languages with treebanks, supervised models give the state-of-the-art performance in dependency parsing; and constituent parsing).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 89, "end_pos": 107, "type": "TASK", "confidence": 0.7657733261585236}, {"text": "constituent parsing", "start_pos": 113, "end_pos": 132, "type": "TASK", "confidence": 0.6876307278871536}]}, {"text": "To break the restriction of the treebank scale, lots of works have been devoted to the unsupervised methods () and the semi-supervised methods; to utilize the unannotated text.", "labels": [], "entities": []}, {"text": "In recent years, researchers have also conducted many investigations on syntax projection (, in order to borrow syntactic knowledge from another language.", "labels": [], "entities": [{"text": "syntax projection", "start_pos": 72, "end_pos": 89, "type": "TASK", "confidence": 0.7433315962553024}]}, {"text": "Different from the bilingual parsing () that improves parsing performance with bilingual constraints, and the bilingual grammar induction) that induces grammar from parallel text, the syntax projection aims to project the syntactic knowledge from one language to another.", "labels": [], "entities": [{"text": "bilingual parsing", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.6324645280838013}]}, {"text": "This seems especially promising for the languages that have bilingual corpora parallel to resource-rich languages with large treebanks.", "labels": [], "entities": []}, {"text": "Previous works mainly focus on dependency projection.", "labels": [], "entities": [{"text": "dependency projection", "start_pos": 31, "end_pos": 52, "type": "TASK", "confidence": 0.9344845116138458}]}, {"text": "The dependency relationship between words in the parsed source sentences can be directly projected across the word alignment to words in the target sentences, following the direct correspondence assumption (DCA) ().", "labels": [], "entities": [{"text": "direct correspondence assumption (DCA)", "start_pos": 173, "end_pos": 211, "type": "METRIC", "confidence": 0.5666981289784113}]}, {"text": "Due to the syntactic nonisomorphism between languages, DCA assumption usually leads to conflicting or incomplete projection.", "labels": [], "entities": [{"text": "DCA", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.8898228406906128}]}, {"text": "Researchers have to adopt strategies to tackle this problem, such as designing rules to handle language non-isomorphism (, and resorting to the quasi-synchronous grammar).", "labels": [], "entities": []}, {"text": "For constituency projection, however, the lack of isomorphism becomes much more serious, since a constituent grammar describes a language in a more detailed way.", "labels": [], "entities": [{"text": "constituency projection", "start_pos": 4, "end_pos": 27, "type": "TASK", "confidence": 0.9123091399669647}]}, {"text": "In this paper we propose a relaxed correspondence assumption (RCA) for constituency Figure 1: An example for constituency projection based on the RCA assumption.", "labels": [], "entities": [{"text": "correspondence assumption (RCA)", "start_pos": 35, "end_pos": 66, "type": "METRIC", "confidence": 0.8091875433921814}, {"text": "constituency projection", "start_pos": 109, "end_pos": 132, "type": "TASK", "confidence": 0.8599075376987457}, {"text": "RCA", "start_pos": 146, "end_pos": 149, "type": "METRIC", "confidence": 0.9587047696113586}]}, {"text": "The projection is from English to Chinese.", "labels": [], "entities": []}, {"text": "A dash dot line links a projected constituent to its corresponding treelet, which is marked with gray background; An Arabic numeral relates a directly-projected constituent to its counter-part in the source parse. projection.", "labels": [], "entities": []}, {"text": "It allows a supposed constituent of the target sentence to correspond to an unrestricted treelet in the source parse.", "labels": [], "entities": []}, {"text": "Such a relaxed assumption fundamentally tolerates the syntactic nonisomorphism between languages, and enables us to learn the target-language-specific syntactic idiosyncrasy, rather than induce a strained grammar directly projected from the source language syntax.", "labels": [], "entities": []}, {"text": "We also propose a novel cross-lingual projection method for constituent syntax based on the RCA assumption.", "labels": [], "entities": [{"text": "cross-lingual projection", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.7009304314851761}]}, {"text": "Given a word-aligned source-parsed bilingual corpus, a PCFG grammar can be induced for the target language by maximum likelihood estimation on the exhaustive enumeration of candidate projected productions, where each nonterminal in a production is an unrestricted treelet extracted from the source parse.", "labels": [], "entities": []}, {"text": "The projected PCFG grammar is then used to parse each target sentence under the guidance of the corresponding source tree, so as to produce an optimized projected constituent tree.", "labels": [], "entities": []}, {"text": "Experiments validate the effectiveness of the RCA assumption and the constituency projection method.", "labels": [], "entities": [{"text": "constituency projection", "start_pos": 69, "end_pos": 92, "type": "TASK", "confidence": 0.8438640236854553}]}, {"text": "We induce a projected Chinese constituent treebank from the FBIS Chinese-English parallel corpus with English sentences parsed by the Charniak parser.", "labels": [], "entities": [{"text": "FBIS Chinese-English parallel corpus", "start_pos": 60, "end_pos": 96, "type": "DATASET", "confidence": 0.9035509824752808}]}, {"text": "The Berkeley Parser trained on the projected treebank dramatically outperforms the previous projected and unsupervised parsers.", "labels": [], "entities": []}, {"text": "This provides an promising substitute for unsupervised parsing methods, to the resource-scarce languages that have bilingual corpora parallel to resource-rich languages with human-annotated treebanks.", "labels": [], "entities": []}, {"text": "In the rest of this paper we first presents the RCA assumption, and the algorithm used to determine the corresponding treelet in the source parse fora candidate constituent in the target sentence.", "labels": [], "entities": [{"text": "RCA", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9900761246681213}]}, {"text": "Then we describe the induction of the projected PCFG grammar and the projected constituent treebank from the word-aligned source-parsed parallel corpus.", "labels": [], "entities": []}, {"text": "After giving experimental results and the comparison with previous unsupervised and projected parsers, we finally conclude our work and point out several aspects to be improved in the future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our work focuses on the constituency projection from English to Chinese.", "labels": [], "entities": [{"text": "constituency projection", "start_pos": 24, "end_pos": 47, "type": "TASK", "confidence": 0.7519843280315399}]}, {"text": "The FBIS Chinese-English parallel corpus is used to obtain a projected constituent treebank.", "labels": [], "entities": [{"text": "FBIS Chinese-English parallel corpus", "start_pos": 4, "end_pos": 40, "type": "DATASET", "confidence": 0.9102445542812347}]}, {"text": "It contains 239 thousand sentence pairs, with about 6.9/8.9 million Chinese/English words.", "labels": [], "entities": []}, {"text": "We parse the English sentences with the Charniak Parser, and tag the Chinese sentences with a POS tagger implemented faithfully according to) and trained on the Penn Chinese Treebank 5.0 ().", "labels": [], "entities": [{"text": "Penn Chinese Treebank 5.0", "start_pos": 161, "end_pos": 186, "type": "DATASET", "confidence": 0.9861445724964142}]}, {"text": "We perform word alignment by runing GIZA++), and then use the alignment results for constituency projection.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 11, "end_pos": 25, "type": "TASK", "confidence": 0.8021672964096069}, {"text": "constituency projection", "start_pos": 84, "end_pos": 107, "type": "TASK", "confidence": 0.8671674430370331}]}, {"text": "Following the previous works of unsupervised constituent parsing, we evaluate the projected parser on the subsets of CTB 1.0 and CTB 5.0, which contain no more than 10 or 40 words after the removal of punctuation.", "labels": [], "entities": [{"text": "CTB 5.0", "start_pos": 129, "end_pos": 136, "type": "DATASET", "confidence": 0.874287873506546}]}, {"text": "The gold-standard POS tags are directly used for testing.", "labels": [], "entities": [{"text": "POS tags", "start_pos": 18, "end_pos": 26, "type": "DATASET", "confidence": 0.75824835896492}]}, {"text": "The evaluation for unsupervised parsing differs slightly from the standard PARSEVAL metrics, it ignores the multiplicity of brackets, brackets of span one, and the bracket labels.", "labels": [], "entities": []}, {"text": "In all experiments we report the unlabeled F1 value which is the harmonic mean of the unlabeled precision and recall.", "labels": [], "entities": [{"text": "F1", "start_pos": 43, "end_pos": 45, "type": "METRIC", "confidence": 0.9780086278915405}, {"text": "precision", "start_pos": 96, "end_pos": 105, "type": "METRIC", "confidence": 0.9851945042610168}, {"text": "recall", "start_pos": 110, "end_pos": 116, "type": "METRIC", "confidence": 0.9978078007698059}]}], "tableCaptions": [{"text": " Table 1: The performance of the Berkeley Parser trained on 160 thousand best projected trees, compared with previous  works on constituency projection and unsupervised parsing. CTB-TEST-40: sentences \u2264 40 words from CTB standard  test set (chapter 271-300); CTB1-ALL-10/CTB5-ALL-10: sentences \u2264 10 words from CTB 1.0/CTB 5.0 after the  removal of punctuation; CTB5-ALL-40: sentences \u2264 40 words from CTB 5.0 after the removal of punctuation.", "labels": [], "entities": [{"text": "constituency projection", "start_pos": 128, "end_pos": 151, "type": "TASK", "confidence": 0.8120530545711517}, {"text": "CTB-TEST-40", "start_pos": 178, "end_pos": 189, "type": "DATASET", "confidence": 0.9531104564666748}, {"text": "CTB standard  test set", "start_pos": 217, "end_pos": 239, "type": "DATASET", "confidence": 0.9630470275878906}, {"text": "CTB1-ALL-10", "start_pos": 259, "end_pos": 270, "type": "DATASET", "confidence": 0.9178805947303772}, {"text": "CTB5-ALL-40", "start_pos": 361, "end_pos": 372, "type": "DATASET", "confidence": 0.9235268831253052}]}]}