{"title": [{"text": "Timeline Generation through Evolutionary Trans-Temporal Summarization", "labels": [], "entities": [{"text": "Timeline Generation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7037676870822906}, {"text": "Evolutionary Trans-Temporal Summarization", "start_pos": 28, "end_pos": 69, "type": "TASK", "confidence": 0.606550395488739}]}], "abstractContent": [{"text": "We investigate an important and challenging problem in summary generation, i.e., Evolutionary Trans-Temporal Summarization (ETTS), which generates news timelines from massive data on the Internet.", "labels": [], "entities": [{"text": "summary generation", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.8483705818653107}, {"text": "Evolutionary Trans-Temporal Summarization (ETTS)", "start_pos": 81, "end_pos": 129, "type": "TASK", "confidence": 0.7381637990474701}]}, {"text": "ETTS greatly facilitates fast news browsing and knowledge comprehension, and hence is a necessity.", "labels": [], "entities": [{"text": "ETTS", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.5387066006660461}]}, {"text": "Given the collection of time-stamped web documents related to the evolving news, ETTS aims to return news evolution along the time-line, consisting of individual but correlated summaries on each date.", "labels": [], "entities": []}, {"text": "Existing summariza-tion algorithms fail to utilize trans-temporal characteristics among these component summaries.", "labels": [], "entities": []}, {"text": "We propose to model trans-temporal correlations among component summaries for timelines, using inter-date and intra-date sentence dependencies, and present a novel combination.", "labels": [], "entities": []}, {"text": "We develop experimental systems to compare 5 rival algorithms on 6 instinctively different datasets which amount to 10251 documents.", "labels": [], "entities": []}, {"text": "Evaluation results in ROUGE metrics indicate the effectiveness of the proposed approach based on trans-temporal information.", "labels": [], "entities": []}], "introductionContent": [{"text": "Along with the rapid growth of the World Wide Web, document floods spread throughout the Internet.", "labels": [], "entities": []}, {"text": "Given a large document collection related to a news subject (for example, BP Oil Spill), readers get lost in the sea of articles, feeling confused and powerless.", "labels": [], "entities": [{"text": "BP Oil Spill)", "start_pos": 74, "end_pos": 87, "type": "TASK", "confidence": 0.8157728314399719}]}, {"text": "General search engines can rank these * Corresponding author.", "labels": [], "entities": []}, {"text": "news webpages by relevance to a user specified aspect, i.e., a query such as \"first relief effort for BP Oil Spill\", but search engines are not quite capable of ranking documents given the whole news subject without particular aspects.", "labels": [], "entities": [{"text": "first relief effort for BP Oil Spill", "start_pos": 78, "end_pos": 114, "type": "TASK", "confidence": 0.5432041670594897}]}, {"text": "Faced with thousands of news documents, people usually have a myriad of interest aspects about the beginning, the development or the latest situation.", "labels": [], "entities": []}, {"text": "However, traditional information retrieval techniques can only rank webpages according to their understanding of relevance, which is obviously insufficient (.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 21, "end_pos": 42, "type": "TASK", "confidence": 0.7231413722038269}]}, {"text": "Even if the ranked documents could be in a satisfying order to help users understand news evolution, readers prefer to monitor the evolutionary trajectories by simply browsing rather than navigate every document in the overwhelming collection.", "labels": [], "entities": []}, {"text": "Summarization is an ideal solution to provide an abbreviated, informative reorganization for faster and better representation of news documents.", "labels": [], "entities": [{"text": "Summarization", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.9806612730026245}]}, {"text": "Particularly, a timeline (see) can summarize evolutionary news as a series of individual but correlated component summaries (items in) and offer an option to understand the big picture of evolution.", "labels": [], "entities": [{"text": "summarize evolutionary news", "start_pos": 35, "end_pos": 62, "type": "TASK", "confidence": 0.8983505169550577}]}, {"text": "With unique characteristics, summarizing timelines is significantly different from traditional summarization methods which are awkward in such scenarios.", "labels": [], "entities": [{"text": "summarizing timelines", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.8956379294395447}, {"text": "summarization", "start_pos": 95, "end_pos": 108, "type": "TASK", "confidence": 0.9739116430282593}]}, {"text": "We first study a manual timeline of BP Oil Spill in Mexico Gulf in from Reuters News 1 to understand why timelines generation is observably different from traditional summarization.", "labels": [], "entities": [{"text": "BP Oil Spill in Mexico Gulf in from Reuters News 1", "start_pos": 36, "end_pos": 86, "type": "DATASET", "confidence": 0.9340058077465404}]}, {"text": "No traditional method has considered to partition corpus into subsets by timestamps for trans-temporal correlations.", "labels": [], "entities": []}, {"text": "However, we discover two unique trans- The Deepwater Horizon rig, valued at more than $560 million, sinks and a five mile long (8 km) oil slick is seen.", "labels": [], "entities": [{"text": "Deepwater Horizon rig", "start_pos": 43, "end_pos": 64, "type": "DATASET", "confidence": 0.8486217856407166}]}], "datasetContent": [{"text": "There is no existing standard test set for ETTS methods.", "labels": [], "entities": [{"text": "ETTS", "start_pos": 43, "end_pos": 47, "type": "TASK", "confidence": 0.8186813592910767}]}, {"text": "We randomly choose 6 news subjects with special coverage and handcrafted timelines by editors from 10 selected news websites: these 6 test sets consist of news datasets and golden standards to evaluate our proposed framework empirically, which amount to 10251 news articles.", "labels": [], "entities": []}, {"text": "As shown in Table 2, three of the sources are in UK, one of them is in China and the rest are in the US.", "labels": [], "entities": [{"text": "UK", "start_pos": 49, "end_pos": 51, "type": "DATASET", "confidence": 0.9071142673492432}]}, {"text": "We choose these sites because many of them provide timelines edited by professional editors, which serve as reference summaries.", "labels": [], "entities": []}, {"text": "The news belongs to different categories of Rule of Interpretation (ROI) ().", "labels": [], "entities": [{"text": "Rule of Interpretation (ROI)", "start_pos": 44, "end_pos": 72, "type": "TASK", "confidence": 0.5200061351060867}]}, {"text": "More detailed statistics are in.", "labels": [], "entities": []}, {"text": "As ETTS faces with much larger corpus compared with traditional MDS, we apply further data preprocessing besides stemming and stop-word removal.", "labels": [], "entities": []}, {"text": "We extract text snippets representing atomic \"events\" from all documents with a toolkit provided by, by which we attempt to assign more fine-grained and accurate timestamps for every sentence within the text snippets.", "labels": [], "entities": []}, {"text": "After the snippet extraction procedure, we filter the corpora by discarding non-event texts.", "labels": [], "entities": [{"text": "snippet extraction", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.7130371183156967}]}, {"text": "\u2022 Compression Rate and Date Selection.", "labels": [], "entities": [{"text": "Compression Rate", "start_pos": 2, "end_pos": 18, "type": "METRIC", "confidence": 0.8931712508201599}, {"text": "Date Selection", "start_pos": 23, "end_pos": 37, "type": "TASK", "confidence": 0.7983792126178741}]}, {"text": "After preprocessing, we obtain numerous snippets with fine-grained timestamps, and then decompose them into temporally tagged sentences as the global collection C.", "labels": [], "entities": []}, {"text": "We partition C according to timestamps of sentences, i.e., Each component summary is generated from its corresponding sub-collection.", "labels": [], "entities": []}, {"text": "The sizes of component summaries are not necessarily equal, and moreover, not all dates maybe represented, so date selection is also important.", "labels": [], "entities": [{"text": "date selection", "start_pos": 110, "end_pos": 124, "type": "TASK", "confidence": 0.6309432834386826}]}, {"text": "We apply a simple mechanism that users specify the overall compression rate \u03c6, and we extract more sentences for important dates while fewer sentences for others.", "labels": [], "entities": [{"text": "\u03c6", "start_pos": 76, "end_pos": 77, "type": "METRIC", "confidence": 0.6763024926185608}]}, {"text": "The importance of dates is measured by the burstiness, which indicates probable significant occurrences ().", "labels": [], "entities": [{"text": "burstiness", "start_pos": 43, "end_pos": 53, "type": "METRIC", "confidence": 0.9777127504348755}]}, {"text": "The compression rate on ti is set as \u03c6 i = |C i | |C| .  The ROUGE measure is widely used for evaluation (: the DUC contests usually officially employ ROUGE for automatic summarization evaluation.", "labels": [], "entities": [{"text": "ROUGE measure", "start_pos": 61, "end_pos": 74, "type": "METRIC", "confidence": 0.9789166152477264}, {"text": "summarization evaluation", "start_pos": 171, "end_pos": 195, "type": "TASK", "confidence": 0.904946506023407}]}, {"text": "In ROUGE evaluation, the summarization quality is measured by counting the number of overlapping units, such as N-gram, word sequences, and word pairs between the candidate timelines CT and the reference timelines RT . There are several kinds of ROUGE metrics, of which the most important one is ROUGE-N with 3 sub-metrics: 3 ROUGE-N-F is an N-gram F 1 metric: I denotes a timeline.", "labels": [], "entities": []}, {"text": "N in these metrics stands for the length of N-gram and N-gram\u2208RT denotes the N-grams in reference timelines while N-gram\u2208CT denotes the N-grams in the candidate timeline.", "labels": [], "entities": []}, {"text": "Count match (N-gram) is the maximum number of Ngram in the candidate timeline and in the set of reference timelines.", "labels": [], "entities": [{"text": "Count match (N-gram)", "start_pos": 0, "end_pos": 20, "type": "METRIC", "confidence": 0.9511493682861328}]}, {"text": "Count is the number of Ngrams in reference timelines or candidate timelines.", "labels": [], "entities": [{"text": "Count", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9879962801933289}]}, {"text": "According to, among all sub-metrics, unigram-based ROUGE (ROUGE-1) has been shown to agree with human judgment most and bigram-based ROUGE (ROUGE-2) fits summarization well.", "labels": [], "entities": []}, {"text": "We report three ROUGE F-measure scores: ROUGE-1, ROUGE-2, and ROUGE-W, where ROUGE-W is based on the weighted longest common subsequence.", "labels": [], "entities": [{"text": "ROUGE F-measure", "start_pos": 16, "end_pos": 31, "type": "METRIC", "confidence": 0.7479452788829803}, {"text": "ROUGE-1", "start_pos": 40, "end_pos": 47, "type": "METRIC", "confidence": 0.9854782819747925}, {"text": "ROUGE-2", "start_pos": 49, "end_pos": 56, "type": "METRIC", "confidence": 0.9662157893180847}, {"text": "ROUGE-W", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.9897475242614746}, {"text": "ROUGE-W", "start_pos": 77, "end_pos": 84, "type": "METRIC", "confidence": 0.9545844197273254}]}, {"text": "The weight Wis set to be 1.2 in our experiments by ROUGE package (version 1.55).", "labels": [], "entities": [{"text": "Wis", "start_pos": 11, "end_pos": 14, "type": "METRIC", "confidence": 0.49712085723876953}, {"text": "ROUGE", "start_pos": 51, "end_pos": 56, "type": "METRIC", "confidence": 0.9057186841964722}]}, {"text": "Intuitively, the higher the ROUGE scores, the similar the two summaries are.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 28, "end_pos": 33, "type": "METRIC", "confidence": 0.9962270259857178}]}], "tableCaptions": [{"text": " Table 2: News sources of 6 datasets", "labels": [], "entities": []}, {"text": " Table 3: Detailed basic information of 6 datasets.", "labels": [], "entities": []}, {"text": " Table 4: Overall performance comparison on Influenza  A (ROI  *  category: Science) and Financial Crisis (ROI  category: Finance). \u03b1=0.4, kernel=Gaussian, \u03c3=60.", "labels": [], "entities": []}, {"text": " Table 5: Overall performance comparison on BP Oil  (ROI category: Accidents) and Haiti Quake (ROI cate- gory: Disasters). \u03b1=0.4, kernel=Gaussian, \u03c3=30.", "labels": [], "entities": [{"text": "BP Oil", "start_pos": 44, "end_pos": 50, "type": "DATASET", "confidence": 0.964120477437973}]}, {"text": " Table 6: Overall performance comparison on Jackson  Death (ROI category: Legal Cases) and Obama Presi- dency (ROI category: Politics). \u03b1=0.4, kernel=Gaussian,  \u03c3=30.", "labels": [], "entities": [{"text": "Jackson  Death", "start_pos": 44, "end_pos": 58, "type": "DATASET", "confidence": 0.9610095024108887}, {"text": "Obama Presi- dency", "start_pos": 91, "end_pos": 109, "type": "TASK", "confidence": 0.6841153055429459}]}]}