{"title": [{"text": "Predicting a Scientific Community's Response to an Article", "labels": [], "entities": [{"text": "Predicting a Scientific Community's Response to an Article", "start_pos": 0, "end_pos": 58, "type": "TASK", "confidence": 0.8970928920639886}]}], "abstractContent": [{"text": "We consider the problem of predicting measurable responses to scientific articles based primarily on their text content.", "labels": [], "entities": [{"text": "predicting measurable responses to scientific articles", "start_pos": 27, "end_pos": 81, "type": "TASK", "confidence": 0.883910596370697}]}, {"text": "Specifically , we consider papers in two fields (economics and computational linguistics) and make predictions about downloads and within-community citations.", "labels": [], "entities": []}, {"text": "Our approach is based on generalized linear models, allowing interpretability; a novel extension that captures first-order temporal effects is also presented.", "labels": [], "entities": []}, {"text": "We demonstrate that text features significantly improve accuracy of predictions over metadata features like authors, topical categories, and publication venues.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9974867105484009}]}], "introductionContent": [{"text": "Written communication is an essential component of the complex social phenomenon of science.", "labels": [], "entities": []}, {"text": "As such, natural language processing is well-positioned to provide tools for understanding the scientific process, by analyzing the textual artifacts (papers, proceedings, etc.) that it produces.", "labels": [], "entities": []}, {"text": "This paper is about modeling collections of scientific documents to understand how their textual content relates to how a scientific community responds to them.", "labels": [], "entities": []}, {"text": "While past work has often focused on citation structure (, our emphasis is on the text content, following and.", "labels": [], "entities": [{"text": "citation structure", "start_pos": 37, "end_pos": 55, "type": "TASK", "confidence": 0.9279224574565887}]}, {"text": "Instead of task-independent exploratory data analysis (e.g., topic modeling) or multi-document summarization, we consider supervised models of the collective response of a scientific community to a published article.", "labels": [], "entities": [{"text": "topic modeling)", "start_pos": 61, "end_pos": 76, "type": "TASK", "confidence": 0.8318135341008505}]}, {"text": "There are many measures of impact of a scientific paper; ours come from direct measurements of the number of downloads (from an established website where prominent economists post papers before formal publication) and citations (within a fixed scientific community).", "labels": [], "entities": []}, {"text": "We adopt a discriminative approach based on generalized linear models that can make use of any text or metadata features, and show that simple lexical features offer substantial power in modeling out-ofsample response and in forecasting response for future articles.", "labels": [], "entities": [{"text": "forecasting response", "start_pos": 225, "end_pos": 245, "type": "TASK", "confidence": 0.9041439592838287}]}, {"text": "Realistic forecasting evaluations require methodological care beyond the usual best practices of train/test separation, and we elucidate these issues.", "labels": [], "entities": [{"text": "Realistic forecasting evaluations", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.8110623359680176}, {"text": "train/test separation", "start_pos": 97, "end_pos": 118, "type": "TASK", "confidence": 0.7139175981283188}]}, {"text": "In addition, we introduce anew regularization technique that leverages the intuition that the relationship between observable features and response should evolve smoothly overtime.", "labels": [], "entities": []}, {"text": "This regularizer allows the learner to rely more strongly on more recent evidence, while taking into account along history of training data.", "labels": [], "entities": [{"text": "regularizer", "start_pos": 5, "end_pos": 16, "type": "METRIC", "confidence": 0.9570217728614807}]}, {"text": "Our time series-inspired regularizer is computationally efficient in learning and is a significant advance over earlier text-driven forecasting models that ignore the time variable altogether (.", "labels": [], "entities": []}, {"text": "We evaluate our approaches in two novel experimental settings: predicting downloads of economics articles and predicting citation of papers at ACL conferences.", "labels": [], "entities": [{"text": "predicting downloads of economics articles", "start_pos": 63, "end_pos": 105, "type": "TASK", "confidence": 0.8886967420578002}, {"text": "predicting citation of papers at ACL conferences", "start_pos": 110, "end_pos": 158, "type": "TASK", "confidence": 0.8334175603730338}]}, {"text": "Our approaches substantially outper-594: Left: the distribution of log download counts for papers in the NBER dataset one year after posting.", "labels": [], "entities": [{"text": "NBER dataset", "start_pos": 105, "end_pos": 117, "type": "DATASET", "confidence": 0.9688752889633179}]}, {"text": "Right: the distribution of within-dataset citations of ACL papers within three years of publication (outliers excluded for readability).", "labels": [], "entities": []}, {"text": "form text-ignorant baselines on ground-truth predictions.", "labels": [], "entities": []}, {"text": "Our time series models permit flexibility in features and offer a novel and perhaps more interpretable view of the data than summary statistics.", "labels": [], "entities": []}], "datasetContent": [{"text": "For each of the datasets in \u00a72, we test our models for two tasks: forecasting about future papers (i.e., making predictions about papers that appeared after a training dataset) and modeling held-out papers from the past (i.e., making predictions within the same time period as the training dataset, on held-out examples).", "labels": [], "entities": [{"text": "forecasting about future papers", "start_pos": 66, "end_pos": 97, "type": "TASK", "confidence": 0.865419790148735}]}, {"text": "For the NBER dataset, the task is to predict the number of downloads a paper will receive in its first year after publication.", "labels": [], "entities": [{"text": "NBER dataset", "start_pos": 8, "end_pos": 20, "type": "DATASET", "confidence": 0.9480723142623901}]}, {"text": "For the ACL dataset, the task is to predict whether a paper will be cited at all (by another ACL paper in our dataset) within the first three years after its publication.", "labels": [], "entities": [{"text": "ACL dataset", "start_pos": 8, "end_pos": 19, "type": "DATASET", "confidence": 0.9541313946247101}]}, {"text": "To our knowledge, clean, reliable citation counts are not available for the NBER dataset; nor are download statistics available for the ACL dataset.", "labels": [], "entities": [{"text": "NBER dataset", "start_pos": 76, "end_pos": 88, "type": "DATASET", "confidence": 0.9877071678638458}, {"text": "ACL dataset", "start_pos": 136, "end_pos": 147, "type": "DATASET", "confidence": 0.9745875298976898}]}, {"text": "summarizes the variables of interest, model types, and evaluation metrics for the tasks.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Descriptive statistics about the datasets.", "labels": [], "entities": []}, {"text": " Table 3: Mean absolute errors for the NBER download  predictions. \" * \" indicates statistical significance between  time series models using metadata features and the full  feature set. \" \u2020\" indicates statistical significance between  the time series and ridge regression models using the full  feature set (Wilcoxon signed-rank test, p < 0.01).", "labels": [], "entities": [{"text": "NBER download  predictions", "start_pos": 39, "end_pos": 65, "type": "DATASET", "confidence": 0.9108150800069174}]}, {"text": " Table 4: Classification accuracy (%) for predicting  whether ACL papers will be cited within three years. \" * \"  indicates statistical significance between time series mod- els using metadata features and the full feature set (bi- nomial sign test, p < 0.01). With the full feature set,  differences between the time series and ridge (all years)  models are not statistically significant at the 0.01 level,  but for the modeling task p is estimated at 0.026, and for  the 2006 forecasting task, p is estimated at 0.050.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9165970087051392}, {"text": "predicting  whether ACL papers", "start_pos": 42, "end_pos": 72, "type": "TASK", "confidence": 0.7983431965112686}]}, {"text": " Table 5: Kendall's \u03c4 rank correlation for future prediction  models on both datasets.", "labels": [], "entities": [{"text": "Kendall's \u03c4 rank correlation", "start_pos": 10, "end_pos": 38, "type": "METRIC", "confidence": 0.6288324594497681}]}]}