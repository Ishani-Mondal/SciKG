{"title": [{"text": "Literal and Metaphorical Sense Identification through Concrete and Abstract Context", "labels": [], "entities": [{"text": "Literal and Metaphorical Sense Identification", "start_pos": 0, "end_pos": 45, "type": "TASK", "confidence": 0.6074307262897491}]}], "abstractContent": [{"text": "Metaphor is ubiquitous in text, even in highly technical text.", "labels": [], "entities": []}, {"text": "Correct inference about tex-tual entailment requires computers to distinguish the literal and metaphorical senses of a word.", "labels": [], "entities": []}, {"text": "Past work has treated this problem as a classical word sense disambiguation task.", "labels": [], "entities": [{"text": "word sense disambiguation task", "start_pos": 50, "end_pos": 80, "type": "TASK", "confidence": 0.7769393250346184}]}, {"text": "In this paper, we take anew approach, based on research in cognitive linguistics that views metaphor as a method for transferring knowledge from a familiar, well-understood, or concrete domain to an unfamiliar, less understood, or more abstract domain.", "labels": [], "entities": []}, {"text": "This view leads to the hypothesis that metaphorical word usage is correlated with the degree of abstractness of the word's context.", "labels": [], "entities": [{"text": "metaphorical word usage", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.629944642384847}]}, {"text": "We introduce an algorithm that uses this hypothesis to classify a word sense in a given context as either literal (de-notative) or metaphorical (connotative).", "labels": [], "entities": []}, {"text": "We evaluate this algorithm with a set of adjective-noun phrases (e.g., in dark comedy, the adjective dark is used metaphorically; in dark hair, it is used literally) and with the TroFi (Trope Finder) Example Base of literal and nonliteral usage for fifty verbs.", "labels": [], "entities": []}, {"text": "We achieve state-of-the-art performance on both datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Metaphor is a natural consequence of our ability to reason by analogy ().", "labels": [], "entities": []}, {"text": "It is so common in our daily language that we rarely notice it.", "labels": [], "entities": []}, {"text": "Identifying metaphorical word usage is important for reasoning about the implications of text.", "labels": [], "entities": [{"text": "Identifying metaphorical word usage", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.8630637526512146}]}, {"text": "Past work on the problem of distinguishing literal and metaphorical senses has approached it as a classical word sense disambiguation (WSD) task).", "labels": [], "entities": [{"text": "word sense disambiguation (WSD) task", "start_pos": 108, "end_pos": 144, "type": "TASK", "confidence": 0.8081505809511457}]}, {"text": "Here, we take a different approach to the problem.", "labels": [], "entities": []}, {"text": "argue that metaphor is a method for transferring knowledge from a concrete domain to an abstract domain.", "labels": [], "entities": []}, {"text": "Therefore we hypothesize that the degree of abstractness in a word's context is correlated with the likelihood that the word is used metaphorically.", "labels": [], "entities": []}, {"text": "This hypothesis is the basis for our algorithm for distinguishing literal and metaphorical senses.", "labels": [], "entities": []}, {"text": "Consider the following sentences: L: He shot down my plane.", "labels": [], "entities": []}, {"text": "\u2192 C 1 : He fired at my plane.", "labels": [], "entities": []}, {"text": "A 1 : He refuted my plane.", "labels": [], "entities": []}, {"text": "M : He shot down my argument.", "labels": [], "entities": []}, {"text": "C 2 : He fired at my argument.", "labels": [], "entities": []}, {"text": "\u2192 A 2 : He refuted my argument.", "labels": [], "entities": []}, {"text": "The literal sense of shot down in L invokes knowledge from the domain of war.", "labels": [], "entities": []}, {"text": "The metaphorical usage of shot down in M transfers knowledge from the concrete domain of war to the abstract domain of debate (.", "labels": [], "entities": []}, {"text": "The entailments of Land M depend on the intended senses of shot down.", "labels": [], "entities": [{"text": "Land M", "start_pos": 19, "end_pos": 25, "type": "TASK", "confidence": 0.8004091382026672}]}, {"text": "L entails the concrete fired at in C 1 (because, in order to literally shoot something down, you must first fire at it) but not the abstract refuted in A 1 (except perhaps as a joke).", "labels": [], "entities": [{"text": "L", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.8913134336471558}]}, {"text": "On the other hand, M entails refuted in A 2 but not fired at in C 2 (except perhaps as a novel metaphor).", "labels": [], "entities": [{"text": "refuted", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.9282828569412231}]}, {"text": "In semiotics, argues that metaphor transfers associations from the source domain to the target domain.", "labels": [], "entities": []}, {"text": "The metaphorical usage of shot down in M carries associations of violence and destruc-680 tion that are not conveyed by A 2 . To make correct inferences about textual entailment, computers must be able to distinguish the literal and metaphorical senses of a word.", "labels": [], "entities": []}, {"text": "Since recognizing textual entailment (RTE) is a core problem for NLP, with applications in Question Answering, Information Retrieval, Information Extraction, and Text Summarization, it follows that distinguishing literal and metaphorical senses is a problem fora wide variety of NLP tasks.", "labels": [], "entities": [{"text": "recognizing textual entailment (RTE)", "start_pos": 6, "end_pos": 42, "type": "TASK", "confidence": 0.8712382614612579}, {"text": "Question Answering", "start_pos": 91, "end_pos": 109, "type": "TASK", "confidence": 0.8418649435043335}, {"text": "Information Retrieval", "start_pos": 111, "end_pos": 132, "type": "TASK", "confidence": 0.7870596051216125}, {"text": "Information Extraction", "start_pos": 134, "end_pos": 156, "type": "TASK", "confidence": 0.7850231826305389}, {"text": "Text Summarization", "start_pos": 162, "end_pos": 180, "type": "TASK", "confidence": 0.7542676031589508}]}, {"text": "The ability to recognize metaphorical word usage is a core requirement in the Intelligence Advanced Research Projects Activity (IARPA) Metaphor Program (Madrigal, 2011).", "labels": [], "entities": [{"text": "recognize metaphorical word usage", "start_pos": 15, "end_pos": 48, "type": "TASK", "confidence": 0.7969378978013992}, {"text": "Intelligence Advanced Research Projects Activity (IARPA) Metaphor Program (Madrigal, 2011)", "start_pos": 78, "end_pos": 168, "type": "DATASET", "confidence": 0.5625269114971161}]}, {"text": "Our approach to the problem of distinguishing literal and metaphorical senses is based on an algorithm for calculating the degree of abstractness of words.", "labels": [], "entities": [{"text": "distinguishing literal and metaphorical senses", "start_pos": 31, "end_pos": 77, "type": "TASK", "confidence": 0.6992741227149963}]}, {"text": "For instance, plane in L is rated 0.36396 (relatively concrete), whereas argument in M is rated 0.64617 (relatively abstract), which suggests that the verb shot down is used literally in L, whereas it is used metaphorically in M . Our abstractness rating algorithm is similar to algorithm for rating words according to their semantic orientation.", "labels": [], "entities": []}, {"text": "To classify a word usage as literal or metaphorical, based on the context, we use supervised learning with logistic regression.", "labels": [], "entities": []}, {"text": "The abstractness rating algorithm is used to generate feature vectors from a word's context and training data is used to learn a logistic regression model that relates degrees of abstractness to the classes literal and metaphorical.", "labels": [], "entities": []}, {"text": "We evaluate our algorithm with three experiments.", "labels": [], "entities": []}, {"text": "The first experiment involves one hundred adjective-noun phrases labeled denotative (literal) or connotative (metaphorical or nonliteral) by five annotators, according to the sense of the adjective.", "labels": [], "entities": []}, {"text": "For instance, deep snow is labeled denotative and deep appreciation is labeled connotative.", "labels": [], "entities": []}, {"text": "The algorithm is able to predict the labels of the annotators with an average accuracy of 79%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9986217021942139}]}, {"text": "The next two experiments use the TroFi (Trope Finder) Example Base of literal and nonliteral usage for fifty verbs.", "labels": [], "entities": [{"text": "TroFi", "start_pos": 33, "end_pos": 38, "type": "METRIC", "confidence": 0.825724184513092}]}, {"text": "The fifty verbs occur in 3,737 sentences from The 1987-89 Wall Street Journal (WSJ) Corpus Release 1.", "labels": [], "entities": [{"text": "The 1987-89 Wall Street Journal (WSJ) Corpus Release 1", "start_pos": 46, "end_pos": 100, "type": "DATASET", "confidence": 0.8812937303022905}]}, {"text": "In each sentence, the target verb See http://www.iarpa.gov/solicitations metaphor.html.", "labels": [], "entities": []}, {"text": "The labeled phrases are available from Yair Neuman.", "labels": [], "entities": []}, {"text": "Available at http://www.cs.sfu.ca/ anoop/students/jbirke/. is labeled L (literal) or N (nonliteral), according to the sense of the verb that is invoked by the sentence.", "labels": [], "entities": []}, {"text": "A subset of twenty-five of the fifty verbs was used by.", "labels": [], "entities": []}, {"text": "In our second experiment, we duplicate the setup of so that we can compare our results with theirs.", "labels": [], "entities": []}, {"text": "In particular, a separate model is learned for each individual verb.", "labels": [], "entities": []}, {"text": "We achieve an average f-score of 63.9%, compared to 64.9%.", "labels": [], "entities": [{"text": "f-score", "start_pos": 22, "end_pos": 29, "type": "METRIC", "confidence": 0.9969080090522766}]}, {"text": "In the third experiment, we train the algorithm on the twenty-five new verbs that were not used by and then we test it on the old verbs.", "labels": [], "entities": []}, {"text": "That is, the algorithm is tested with verbs that it has never seen before.", "labels": [], "entities": []}, {"text": "The training verbs are merged to build a single model, instead of building a separate model for each individual verb.", "labels": [], "entities": []}, {"text": "In this experiment, the average f-score is 68.1%.", "labels": [], "entities": [{"text": "f-score", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.992938220500946}]}, {"text": "The next section presents our algorithm for calculating the degree of abstractness of words.", "labels": [], "entities": []}, {"text": "In Section 3, we review related work.", "labels": [], "entities": []}, {"text": "The experiments are described in Section 4.", "labels": [], "entities": []}, {"text": "We discuss the results of the experiments in Section 5 and conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the following experiments, we use the abstractness ratings of Section 2.2 to generate features for supervised machine learning.", "labels": [], "entities": []}, {"text": "The learning algorithm we apply is logistic regression (Le Cessie and Van Houwelingen, 1992), as implemented in Weka (.", "labels": [], "entities": [{"text": "Weka", "start_pos": 112, "end_pos": 116, "type": "DATASET", "confidence": 0.9327819347381592}]}, {"text": "In all experiments, we used the Weka parameter settings R = 0.2 (for robust ridge regression) and M = \u22121 (for unlimited iterations).", "labels": [], "entities": [{"text": "M", "start_pos": 98, "end_pos": 99, "type": "METRIC", "confidence": 0.9788732528686523}]}], "tableCaptions": [{"text": " Table 1: Examples of abstract and concrete words from  the MRC Dictionary (Coltheart, 1981).", "labels": [], "entities": [{"text": "MRC Dictionary (Coltheart, 1981)", "start_pos": 60, "end_pos": 92, "type": "DATASET", "confidence": 0.9374141267367772}]}, {"text": " Table 2: The forty paradigm words and the Pearson correlation on the training set.", "labels": [], "entities": [{"text": "Pearson correlation", "start_pos": 43, "end_pos": 62, "type": "METRIC", "confidence": 0.9650767147541046}]}, {"text": " Table 3: Some examples of adjective-noun pairs and the  abstractness rating of the noun.", "labels": [], "entities": []}, {"text": " Table 4. On average, we were able to predict a  judge's labels with 79% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9987109899520874}]}, {"text": " Table 4: The accuracy of logistic regression at predicting  the labels of each judge.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9996374845504761}]}, {"text": " Table 5: The performance with known verbs.", "labels": [], "entities": []}, {"text": " Table 5. The num- bers are in bold font when the performance of an  algorithm is significantly below the performance of  Concrete-Abstract. In no case is any score signifi- cantly above the performance of Concrete-Abstract,  at the 95% confidence level. NA indicates scores that  were not calculated by", "labels": [], "entities": [{"text": "NA", "start_pos": 255, "end_pos": 257, "type": "METRIC", "confidence": 0.9805933237075806}]}, {"text": " Table 6. The  numbers are in bold font when the performance of  an algorithm is significantly below the performance", "labels": [], "entities": []}, {"text": " Table 6: The performance with unknown verbs.", "labels": [], "entities": []}, {"text": " Table 7: The logistic regression coefficients for class N.", "labels": [], "entities": []}]}