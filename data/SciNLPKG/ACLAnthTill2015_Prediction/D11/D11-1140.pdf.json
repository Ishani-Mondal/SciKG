{"title": [{"text": "Lexical Generalization in CCG Grammar Induction for Semantic Parsing", "labels": [], "entities": [{"text": "Lexical Generalization", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.852736085653305}]}], "abstractContent": [{"text": "We consider the problem of learning fac-tored probabilistic CCG grammars for semantic parsing from data containing sentences paired with logical-form meaning representations.", "labels": [], "entities": [{"text": "semantic parsing from data containing sentences paired with logical-form meaning representations", "start_pos": 77, "end_pos": 173, "type": "TASK", "confidence": 0.763262233950875}]}, {"text": "Traditional CCG lexicons list lexical items that pair words and phrases with syntactic and semantic content.", "labels": [], "entities": []}, {"text": "Such lexicons can be inefficient when words appear repeatedly with closely related lexical content.", "labels": [], "entities": []}, {"text": "In this paper, we introduce factored lexicons, which include both lexemes to model word meaning and templates to model systematic variation in word usage.", "labels": [], "entities": []}, {"text": "We also present an algorithm for learning factored CCG lexicons, along with a probabilistic parse-selection model.", "labels": [], "entities": []}, {"text": "Evaluations on benchmark datasets demonstrate that the approach learns highly accurate parsers, whose generalization performance benefits greatly from the lexical factoring.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic parsers automatically recover representations of meaning from natural language sentences.", "labels": [], "entities": []}, {"text": "Recent work has focused on learning such parsers directly from corpora made up of sentences paired with logical meaning representations (.", "labels": [], "entities": []}, {"text": "For example, in a flight booking domain we might have access to training examples such as: Sentence: I want flights from Boston Meaning: \u03bb x. f light(x) \u2227 from and the goal is to learn a grammar that can map new, unseen, sentences onto their corresponding meanings, or logical forms.", "labels": [], "entities": [{"text": "Boston Meaning", "start_pos": 121, "end_pos": 135, "type": "DATASET", "confidence": 0.8833367228507996}]}, {"text": "One approach to this problem has developed algorithms for leaning probabilistic CCG grammars).", "labels": [], "entities": []}, {"text": "These grammars are well-suited to the task of semantic parsing, as they closely link syntax and semantics.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 46, "end_pos": 62, "type": "TASK", "confidence": 0.731696605682373}]}, {"text": "They can be used to model a wide range of complex linguistic phenomena and are strongly lexicalized, storing all language-specific grammatical information directly with the words in the lexicon.", "labels": [], "entities": []}, {"text": "For example, atypical learned lexicon might include entries such as: Although lexicalization of this kind is useful for learning, as we will see, these grammars can also suffer from sparsity in the training data, since closely related entries must be repeatedly learned for all members of a certain class of words.", "labels": [], "entities": []}, {"text": "For example, the list above shows a selection of lexical items that would have to be learned separately.", "labels": [], "entities": []}, {"text": "In this list, the word \"flight\" is paired with the predicate flight in three separate lexical items which are required for different syntactic contexts.", "labels": [], "entities": []}, {"text": "Item 1512 (1) has the standard N category for entries of this type, item (2) allows the use of the word \"flight\" with that-less relative clauses such as \"flight departing Boston\", and item (3) is useful for phrases with unconventional word order such as \"from Boston flight to New York\".", "labels": [], "entities": []}, {"text": "Representing these three lexical items separately is inefficient, since each word of this class (such as \"fare\") will require three similarly structured lexical entries differing only in predicate name.", "labels": [], "entities": []}, {"text": "There may also be systemtatic semantic variation between entries fora certain class of words.", "labels": [], "entities": []}, {"text": "For example, in (6) \"Boston\" is paired with the constant bos that represents its meaning.", "labels": [], "entities": [{"text": "Boston", "start_pos": 21, "end_pos": 27, "type": "DATASET", "confidence": 0.9539245963096619}]}, {"text": "However, item (7) also adds the predicate from to the logical form.", "labels": [], "entities": []}, {"text": "This might be used to analyse somewhat elliptical, unedited sentences such as \"Show me flights Boston to New York,\" which can be challenging for semantic parsers.", "labels": [], "entities": []}, {"text": "This paper builds upon the insight that a large proportion of the variation between lexical items fora given class of words is systematic.", "labels": [], "entities": []}, {"text": "Therefore it should be represented once and applied to a small set of basic lexical units.", "labels": [], "entities": []}, {"text": "We develop a factored lexicon that captures this insight by distinguishing lexemes, which pair words with logical constants, from lexical templates, which map lexemes to full lexical items.", "labels": [], "entities": []}, {"text": "As we will see, this can lead to a significantly more compact lexicon that can be learned from less data.", "labels": [], "entities": []}, {"text": "Each word or phrase will be associated with a few lexemes that can be combined with a shared set of general templates.", "labels": [], "entities": []}, {"text": "We develop an approach to learning factored, probabilistic CCG grammars for semantic parsing.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 76, "end_pos": 92, "type": "TASK", "confidence": 0.804031103849411}]}, {"text": "Following previous work (, we make use of a higher-order unification learning scheme that defines a space of CCG grammars consistent with the (sentence, logical form) training pairs.", "labels": [], "entities": []}, {"text": "However, instead of constructing fully specified lexical items for the learned grammar, we automatically generate sets of lexemes and lexical templates to model each example.", "labels": [], "entities": []}, {"text": "This is a difficult learning problem, since the CCG analyses that 1 A related tactic is commonly used in wide-coverage CCG parsers derived from treebanks, such as work by and.", "labels": [], "entities": []}, {"text": "These parsers make extensive use of category-changing unary rules, to avoid data sparsity for systematically related categories (such as those related by type-raising).", "labels": [], "entities": []}, {"text": "We will automatically learn to represent these types of generalizations in the factored lexicon. are required to construct the final meaning representations are not explicitly labeled in the training data.", "labels": [], "entities": []}, {"text": "Instead, we model them with hidden variables and develop an online learning approach that simultaneously estimates the parameters of a log-linear parsing model, while inducing the factored lexicon.", "labels": [], "entities": []}, {"text": "We evaluate the approach on the benchmark Atis and GeoQuery domains.", "labels": [], "entities": [{"text": "Atis", "start_pos": 42, "end_pos": 46, "type": "DATASET", "confidence": 0.8305278420448303}, {"text": "GeoQuery domains", "start_pos": 51, "end_pos": 67, "type": "DATASET", "confidence": 0.7917338907718658}]}, {"text": "This is a challenging setup, since the GeoQuery data has complex meaning representations and sentences in multiple languages, while the Atis data contains spontaneous, unedited text that can be difficult to analyze with a formal grammar representation.", "labels": [], "entities": [{"text": "GeoQuery data", "start_pos": 39, "end_pos": 52, "type": "DATASET", "confidence": 0.9135312139987946}, {"text": "Atis data", "start_pos": 136, "end_pos": 145, "type": "DATASET", "confidence": 0.8059855103492737}]}, {"text": "Our approach achieves at or near state-of-the-art recall across all conditions, despite having no English or domain-specific information builtin.", "labels": [], "entities": [{"text": "recall", "start_pos": 50, "end_pos": 56, "type": "METRIC", "confidence": 0.976830005645752}]}, {"text": "We believe that ours is the only system of sufficient generality to run with this degree of success on all of these datasets.", "labels": [], "entities": []}], "datasetContent": [{"text": "Data Sets We evaluate on two benchmark semantic parsing datasets: GeoQuery, which is made up of natural language queries to a database of geographical information; and Atis, which contains natural language queries to a flight booking system.", "labels": [], "entities": [{"text": "benchmark semantic parsing", "start_pos": 29, "end_pos": 55, "type": "TASK", "confidence": 0.7722598910331726}]}, {"text": "The Geo880 dataset has 880 (English-sentence, logicalform) pairs split into a training set of 600 pairs and a test set of 280.", "labels": [], "entities": [{"text": "Geo880 dataset", "start_pos": 4, "end_pos": 18, "type": "DATASET", "confidence": 0.9594731032848358}]}, {"text": "The Geo250 data is a subset of the Geo880 sentences that have been translated into Japanese, Spanish and Turkish as well as the original English.", "labels": [], "entities": [{"text": "Geo250 data", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9486943483352661}]}, {"text": "We follow the standard evaluation procedure for Geo250, using 10-fold cross validation experiments with the same splits of the data as.", "labels": [], "entities": [{"text": "Geo250", "start_pos": 48, "end_pos": 54, "type": "DATASET", "confidence": 0.9203633069992065}]}, {"text": "The Atis dataset contains 5410 (sentence, logical-form) pairs split into a 4480 example training set, a 480 example development set and a 450 example test set.", "labels": [], "entities": [{"text": "Atis dataset", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.8148607909679413}]}, {"text": "Evaluation Metrics We report exact match Recall (percentage of sentences for which the correct logical-form was returned), Precision (percentage of returned logical-forms that are correct) and F1 (harmonic mean of Precision and Recall).", "labels": [], "entities": [{"text": "exact match Recall", "start_pos": 29, "end_pos": 47, "type": "METRIC", "confidence": 0.8459469477335612}, {"text": "Precision", "start_pos": 123, "end_pos": 132, "type": "METRIC", "confidence": 0.8758277297019958}, {"text": "F1", "start_pos": 193, "end_pos": 195, "type": "METRIC", "confidence": 0.9996939897537231}]}, {"text": "For Atis we also report partial match Recall (percentage of correct literals returned), Precision (percentage of returned literals that are correct) and F1, computed as described by.", "labels": [], "entities": [{"text": "Recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9573498964309692}, {"text": "Precision", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.9978322386741638}, {"text": "F1", "start_pos": 153, "end_pos": 155, "type": "METRIC", "confidence": 0.9996874332427979}]}, {"text": "Features We introduce two types of features to discriminate between parses: lexical features and logical-form features.", "labels": [], "entities": []}, {"text": "Lexical features fire on the lexemes and templates used to build the lexical items used in a parse.", "labels": [], "entities": []}, {"text": "For each (lexeme,template) pair used to create a lexical item we have indicator features \u03c6 l for the lexeme used, \u03c6 t for the template used, and \u03c6 (l,t) for the pair that was used.", "labels": [], "entities": []}, {"text": "We assign the features on lexical templates a weight of 0.1 to prevent them from swamping the far less frequent but equally informative lexeme features.", "labels": [], "entities": []}, {"text": "Logical-form features are computed on the lambda-calculus expression z returned at the root of the parse.", "labels": [], "entities": []}, {"text": "Each time a predicate pin z takes an argument a with type Ty(a) in position i, it triggers two binary indicator features: \u03c6 (p,a,i) for the predicate-argument relation; and \u03c6 (p,Ty(a),i) for the predicate argument-type relation.", "labels": [], "entities": []}, {"text": "Boolean operator features look at predicates that occurr together in conjunctions and disjunctions.", "labels": [], "entities": []}, {"text": "For each variable vi that fills argument slot i in two conjoined predicates p 1 and p 2 we introduce a binary indicator feature \u03c6 con j(i,p 1 ,p 2 ) . We introduce similar features \u03c6 dis j(i,p 1 ,p 2 ) for variables vi that are shared by predicates in a disjunction.", "labels": [], "entities": []}, {"text": "Initialization The weights for lexeme features are initialized according to coocurrance statistics between words and logical constants.", "labels": [], "entities": [{"text": "Initialization", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9679288864135742}]}, {"text": "These are estimated with the Giza++ (", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance on the Atis development set.", "labels": [], "entities": [{"text": "Atis development set", "start_pos": 29, "end_pos": 49, "type": "DATASET", "confidence": 0.9133685231208801}]}, {"text": " Table 2: Performance on the Atis test set.", "labels": [], "entities": [{"text": "Atis test set", "start_pos": 29, "end_pos": 42, "type": "DATASET", "confidence": 0.9559812943140665}]}, {"text": " Table 3: Exact match accuracy on the Geo880 test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.975252628326416}, {"text": "Geo880 test set", "start_pos": 38, "end_pos": 53, "type": "DATASET", "confidence": 0.9767467578252157}]}, {"text": " Table 4: Exact-match accuracy on the Geo250 data set.", "labels": [], "entities": [{"text": "Exact-match", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9578405022621155}, {"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9566469192504883}, {"text": "Geo250 data set", "start_pos": 38, "end_pos": 53, "type": "DATASET", "confidence": 0.9894317984580994}]}, {"text": " Table 5: Example lexemes and templates learned from  the Atis development set.", "labels": [], "entities": [{"text": "Atis development set", "start_pos": 58, "end_pos": 78, "type": "DATASET", "confidence": 0.844083309173584}]}]}