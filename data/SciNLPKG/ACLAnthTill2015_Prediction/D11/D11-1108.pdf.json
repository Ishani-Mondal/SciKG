{"title": [{"text": "Learning Sentential Paraphrases from Bilingual Parallel Corpora for Text-to-Text Generation", "labels": [], "entities": [{"text": "Text-to-Text Generation", "start_pos": 68, "end_pos": 91, "type": "TASK", "confidence": 0.686324268579483}]}], "abstractContent": [{"text": "Previous work has shown that high quality phrasal paraphrases can be extracted from bilingual parallel corpora.", "labels": [], "entities": []}, {"text": "However, it is not clear whether bitexts are an appropriate resource for extracting more sophisticated sen-tential paraphrases, which are more obviously learnable from monolingual parallel corpora.", "labels": [], "entities": []}, {"text": "We extend bilingual paraphrase extraction to syntactic paraphrases and demonstrate its ability to learn a variety of general paraphrastic transformations, including passivization, da-tive shift, and topicalization.", "labels": [], "entities": [{"text": "bilingual paraphrase extraction", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.6261730988820394}]}, {"text": "We discuss how our model can be adapted to many text generation tasks by augmenting its feature set, development data, and parameter estimation routine.", "labels": [], "entities": [{"text": "text generation", "start_pos": 48, "end_pos": 63, "type": "TASK", "confidence": 0.7409740686416626}]}, {"text": "We illustrate this adaptation by using our paraphrase model for the task of sentence compression and achieve results competitive with state-of-the-art compression systems.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 76, "end_pos": 96, "type": "TASK", "confidence": 0.7584101855754852}]}], "introductionContent": [{"text": "Paraphrases are alternative ways of expressing the same information.", "labels": [], "entities": []}, {"text": "Automatically generating and detecting paraphrases is a crucial aspect of many NLP tasks.", "labels": [], "entities": [{"text": "Automatically generating and detecting paraphrases", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.6256308078765869}]}, {"text": "In multi-document summarization, paraphrase detection is used to collapse redundancies (.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 3, "end_pos": 31, "type": "TASK", "confidence": 0.5869477987289429}, {"text": "paraphrase detection", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.8458790183067322}]}, {"text": "Paraphrase generation can be used for query expansion in information retrieval and question answering systems.", "labels": [], "entities": [{"text": "Paraphrase generation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8589330017566681}, {"text": "query expansion", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.8338501453399658}, {"text": "information retrieval", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.7203349769115448}, {"text": "question answering", "start_pos": 83, "end_pos": 101, "type": "TASK", "confidence": 0.8217569887638092}]}, {"text": "Paraphrases allow for more flexible matching of system output against human references for tasks like machine translation and automatic summarization ().", "labels": [], "entities": [{"text": "machine translation", "start_pos": 102, "end_pos": 121, "type": "TASK", "confidence": 0.7979642450809479}]}, {"text": "Broadly, we can distinguish two forms of paraphrases: phrasal paraphrases denote a set of surface text forms with the same meaning: the committee's second proposal the second proposal of the committee while syntactic paraphrases augment the surface forms by introducing nonterminals (or slots) that are annotated with syntactic constraints: the NP 1 's NP 2 the NP 2 of the NP 1 It is evident that the latter have a much higher potential for generalization and for capturing interesting paraphrastic transformations.", "labels": [], "entities": []}, {"text": "A variety of different types of corpora (and semantic equivalence cues) have been used to automatically induce paraphrase collections for English.", "labels": [], "entities": []}, {"text": "Perhaps the most natural type of corpus for this task is a monolingual parallel text, which allows sentential paraphrases to be extracted since the sentence pairs in such corpora are perfect paraphrases of each other (.", "labels": [], "entities": []}, {"text": "While rich syntactic paraphrases have been learned from monolingual parallel corpora, they suffer from very limited data availability and thus have poor coverage.", "labels": [], "entities": []}, {"text": "Other methods obtain paraphrases from raw monolingual text by relying on distributional similarity (.", "labels": [], "entities": []}, {"text": "While vast amounts of data are readily available for these approaches, the distributional similarity signal they use is noisier than the sentence-level correspondency in parallel corpora and additionally suffers from problems such as mistaking cousin expressions or antonyms (such as {boy, girl } or {rise, fall }) for paraphrases.", "labels": [], "entities": []}, {"text": "1168 Abundantly available bilingual parallel corpora have been shown to address both these issues, obtaining paraphrases via a pivoting step over foreign language phrases).", "labels": [], "entities": []}, {"text": "The coverage of paraphrase lexica extracted from bitexts has been shown to outperform that obtained from other sources ().", "labels": [], "entities": []}, {"text": "While there have been efforts pursuing the extraction of more powerful paraphrases (), it is not yet clear to what extent sentential paraphrases can be induced from bitexts.", "labels": [], "entities": []}, {"text": "In this paper we: \u2022 Extend the bilingual pivoting approach to paraphrase induction to produce rich syntactic paraphrases.", "labels": [], "entities": [{"text": "paraphrase induction", "start_pos": 62, "end_pos": 82, "type": "TASK", "confidence": 0.9663268029689789}]}, {"text": "\u2022 Perform a thorough analysis of the types of paraphrases we obtain and discuss the paraphrastic transformations we are capable of capturing.", "labels": [], "entities": []}, {"text": "\u2022 Describe how training paradigms for syntactic/sentential paraphrase models should be tailored to different text-to-text generation tasks.", "labels": [], "entities": [{"text": "text-to-text generation", "start_pos": 109, "end_pos": 132, "type": "TASK", "confidence": 0.7393389642238617}]}, {"text": "\u2022 Demonstrate our framework's suitability fora variety of text-to-text generation tasks by obtaining state-of-the-art results on the example task of sentence compression.", "labels": [], "entities": [{"text": "text-to-text generation", "start_pos": 58, "end_pos": 81, "type": "TASK", "confidence": 0.7485378980636597}, {"text": "sentence compression", "start_pos": 149, "end_pos": 169, "type": "TASK", "confidence": 0.7409881949424744}]}], "datasetContent": [{"text": "We extracted a paraphrase grammar from the French-English Europarl corpus (v5).", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 58, "end_pos": 73, "type": "DATASET", "confidence": 0.8631223738193512}]}, {"text": "The bitext was aligned using the Berkeley aligner and the English side was parsed with the Berkeley parser.", "labels": [], "entities": []}, {"text": "We  obtained the initial translation grammar using the SAMT toolkit).", "labels": [], "entities": [{"text": "SAMT toolkit", "start_pos": 55, "end_pos": 67, "type": "DATASET", "confidence": 0.8626643717288971}]}, {"text": "The grammars we extract tend to be extremely large.", "labels": [], "entities": []}, {"text": "To keep their size manageable, we only consider translation rules that have been seen more than 3 times and whose translation probability exceeds 10 \u22124 for pivot recombination.", "labels": [], "entities": []}, {"text": "Additionally, we only retain the top 25 most likely paraphrases of each phrase, ranked by a uniformly weighted combination of phrasal and lexical paraphrase probabilities.", "labels": [], "entities": []}, {"text": "We tuned the model parameters to our PR\u00c9CISPR\u00b4 objective function, implemented in the Z-MERT toolkit.", "labels": [], "entities": []}, {"text": "For decoding we used the Joshua decoder ().", "labels": [], "entities": []}, {"text": "The language model used in our paraphraser and the Clarke and Lapata (2008) baseline system is a Kneser-Ney discounted 5-gram model estimated on the Gigaword corpus using the SRILM toolkit).", "labels": [], "entities": [{"text": "Clarke and Lapata (2008) baseline system", "start_pos": 51, "end_pos": 91, "type": "DATASET", "confidence": 0.7211575396358967}, {"text": "Gigaword corpus", "start_pos": 149, "end_pos": 164, "type": "DATASET", "confidence": 0.9470516741275787}, {"text": "SRILM toolkit", "start_pos": 175, "end_pos": 188, "type": "DATASET", "confidence": 0.895101010799408}]}, {"text": "To assess the output quality of the resulting sentence compression system, we compare it to two state-ofthe-art sentence compression systems.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.7160291820764542}, {"text": "sentence compression", "start_pos": 112, "end_pos": 132, "type": "TASK", "confidence": 0.758833259344101}]}, {"text": "Specifically, we compare against our implementation of Clarke and Lapata (2008)'s compression model which uses a series of constraints in an integer linear programming (ILP) solver, and Cohn and Lapata (2007)'s tree transducer toolkit (T3) which learns asynchronous tree substitution grammar (STSG) from paired monolingual sentences.", "labels": [], "entities": [{"text": "asynchronous tree substitution grammar (STSG) from paired monolingual sentences", "start_pos": 253, "end_pos": 332, "type": "TASK", "confidence": 0.8128891641443426}]}, {"text": "Unlike SCFGs, the STSG formalism allows changes to the tree topology.", "labels": [], "entities": []}, {"text": "Cohn and Lapata argue that this is a natural fit for sentence compression, since deletions introduce structural mismatches.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 53, "end_pos": 73, "type": "TASK", "confidence": 0.7673565447330475}]}, {"text": "We trained the T3 software 2 on the 936 full, compressed sentence pairs that comprise our development set.", "labels": [], "entities": []}, {"text": "This is equivalent in size to the training corpora that Cohn and Lapata (2007) used (their training corpora ranged from 882-1020 sentence pairs), and has the advantage of being in-domain with respect to our test set.", "labels": [], "entities": []}, {"text": "Both these systems reported results outperforming previous systems such as.", "labels": [], "entities": []}, {"text": "To showcase the value of the adaptations discussed above, we also compare variants of our paraphrase-based compression systems: using Hiero instead of syntax, using syntax with or without compression features, using an augmented grammar with optional deletion rules.", "labels": [], "entities": []}, {"text": "We solicit human judgments of the compressions along two five-point scales: grammaticality and meaning.", "labels": [], "entities": []}, {"text": "Judges are instructed to decide how much the meaning from a reference translation is retained in the compressed sentence, with a score of 5 indicating that all of the important information is present, and 1 being that the compression does not retain any of the original meaning.", "labels": [], "entities": []}, {"text": "Similarly, a grammar score of 5 indicates perfect grammaticality, and a grammar score of 1 is assigned to sentences that are entirely ungrammatical.", "labels": [], "entities": []}, {"text": "To ensure fairness, we perform pairwise system comparisons with compression rates strictly tied on the sentence-level.", "labels": [], "entities": []}, {"text": "For any comparison, a sentence is only included in the computation of average scores if the difference between both systems' compression rates is < 0.05. 3 shows a set of pairwise comparisons for compression rates \u2248 0.5.", "labels": [], "entities": []}, {"text": "We see that going from a Hiero-based to a syntactic paraphrase grammar yields a significant improvement in grammaticality.", "labels": [], "entities": []}, {"text": "Adding compression-specific features improves grammaticality even further.", "labels": [], "entities": []}, {"text": "Further augmenting the grammar with deletion rules significantly helps retain the core meaning at compression rates this high, however compared to the un-augmented syntactic system grammaticality scores drop.", "labels": [], "entities": []}, {"text": "While our approach significantly outperforms the T3 system, we are notable to match ILP's results in grammaticality.", "labels": [], "entities": []}, {"text": "In we compare our system to the ILP approach at a modest compression rate of \u2248 0.8.", "labels": [], "entities": []}, {"text": "Here, we significantly outperform ILP in meaning retention while achieving comparable results in grammaticality.", "labels": [], "entities": [{"text": "meaning retention", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.7856224179267883}]}, {"text": "This improvement is significant at p < 0.0001, using the sign test, while the better grammaticality score of the ILP system is not statisti-   cally significant (p < 0.088).", "labels": [], "entities": []}, {"text": "These results indicate that, over a variety of compression rates, our framework for text-to-text generation is performing as well as or better than specifically tailored stateof-the-art methods.", "labels": [], "entities": [{"text": "text-to-text generation", "start_pos": 84, "end_pos": 107, "type": "TASK", "confidence": 0.728063777089119}]}, {"text": "shows an example sentence drawn from our test set and the compressions produced by the different systems.", "labels": [], "entities": []}, {"text": "We see that both the paraphrase and ILP systems produce good quality results, with the paraphrase system retaining the meaning of the source sentence more accurately.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Results of the human evaluation on longer com- pressions: pairwise compression rates (CR), meaning and  grammaticality scores. Bold indicates a statistically sig- nificance difference at p < 0.05.", "labels": [], "entities": [{"text": "pairwise compression rates (CR)", "start_pos": 68, "end_pos": 99, "type": "METRIC", "confidence": 0.8633706271648407}]}, {"text": " Table 4: Human evaluation for shorter compressions and  for variations of our paraphrase system. +Feat. includes  the compression features from Section 6.1, +Aug. in- cludes optional deletion rules from Section 6.4.", "labels": [], "entities": []}]}