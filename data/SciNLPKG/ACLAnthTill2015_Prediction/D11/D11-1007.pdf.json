{"title": [], "abstractContent": [{"text": "We propose a method to improve the accuracy of parsing bilingual texts (bitexts) with the help of statistical machine translation (SMT) systems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9981617331504822}, {"text": "parsing bilingual texts (bitexts)", "start_pos": 47, "end_pos": 80, "type": "TASK", "confidence": 0.854516347249349}, {"text": "statistical machine translation (SMT)", "start_pos": 98, "end_pos": 135, "type": "TASK", "confidence": 0.7684076726436615}]}, {"text": "Previous bitext parsing methods use human-annotated bilingual treebanks that are hard to obtain.", "labels": [], "entities": [{"text": "bitext parsing", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.5963180065155029}]}, {"text": "Instead, our approach uses an auto-generated bilingual treebank to produce bilingual constraints.", "labels": [], "entities": []}, {"text": "However, because the auto-generated bilingual treebank contains errors , the bilingual constraints are noisy.", "labels": [], "entities": []}, {"text": "To overcome this problem, we use large-scale unannotated data to verify the constraints and design a set of effective bilingual features for parsing models based on the verified results.", "labels": [], "entities": []}, {"text": "The experimental results show that our new parsers significantly outperform state-of-the-art baselines.", "labels": [], "entities": []}, {"text": "Moreover, our approach is still able to provide improvement when we use a larger monolingual treebank that results in a much stronger baseline.", "labels": [], "entities": []}, {"text": "Especially notable is that our approach can be used in a purely monolingual setting with the help of SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 101, "end_pos": 104, "type": "TASK", "confidence": 0.9685667157173157}]}], "introductionContent": [{"text": "Recently there have been several studies aiming to improve the performance of parsing bilingual texts (bitexts) (.", "labels": [], "entities": [{"text": "parsing bilingual texts (bitexts)", "start_pos": 78, "end_pos": 111, "type": "TASK", "confidence": 0.8084514836470286}]}, {"text": "In bitext parsing, we can use the information based on \"bilingual constraints\", which do not exist in monolingual sentences.", "labels": [], "entities": [{"text": "bitext parsing", "start_pos": 3, "end_pos": 17, "type": "TASK", "confidence": 0.5449294000864029}]}, {"text": "More accurate bitext parsing results can be effectively used in the training of syntax-based machine translation systems (.", "labels": [], "entities": [{"text": "bitext parsing", "start_pos": 14, "end_pos": 28, "type": "TASK", "confidence": 0.5273349285125732}, {"text": "machine translation", "start_pos": 93, "end_pos": 112, "type": "TASK", "confidence": 0.7132288068532944}]}, {"text": "Most previous studies rely on bilingual treebanks to provide bilingual constraints for bitext parsing.", "labels": [], "entities": [{"text": "bitext parsing", "start_pos": 87, "end_pos": 101, "type": "TASK", "confidence": 0.5637124627828598}]}, {"text": "proposed joint models on bitexts to improve the performance on either or both sides.", "labels": [], "entities": []}, {"text": "Their method uses bilingual treebanks that have human-annotated tree structures on both sides.", "labels": [], "entities": []}, {"text": "presented a method to train a source-language parser by using the reordering information on words between the sentences on two sides.", "labels": [], "entities": []}, {"text": "It uses another type of bilingual treebanks that have tree structures on the source sentences and their human-translated sentences.", "labels": [], "entities": []}, {"text": "also used bilingual treebanks and made use of tree structures on the target side.", "labels": [], "entities": []}, {"text": "However, the bilingual treebanks are hard to obtain, partly because of the high cost of human translation.", "labels": [], "entities": []}, {"text": "Thus, in their experiments, they applied their methods to a small data set, the manually translated portion of the Chinese Treebank (CTB) which contains only about 3,000 sentences.", "labels": [], "entities": [{"text": "Chinese Treebank (CTB)", "start_pos": 115, "end_pos": 137, "type": "DATASET", "confidence": 0.9467839956283569}]}, {"text": "On the other hand, many large-scale monolingual treebanks exist, such as the Penn English Treebank (PTB)) (about 40,000 sentences in Version 3) and the latest version of CTB (over 50,000 sentences in Version 7).", "labels": [], "entities": [{"text": "Penn English Treebank (PTB))", "start_pos": 77, "end_pos": 105, "type": "DATASET", "confidence": 0.9616054793198904}, {"text": "CTB", "start_pos": 170, "end_pos": 173, "type": "DATASET", "confidence": 0.926116406917572}]}, {"text": "In this paper, we propose a bitext parsing approach in which we produce the bilingual constraints on existing monolingual treebanks with the help of SMT systems.", "labels": [], "entities": [{"text": "bitext parsing", "start_pos": 28, "end_pos": 42, "type": "TASK", "confidence": 0.4838622659444809}, {"text": "SMT", "start_pos": 149, "end_pos": 152, "type": "TASK", "confidence": 0.9796963930130005}]}, {"text": "In other words, we aim to improve source-language parsing with the help of automatic translations.", "labels": [], "entities": [{"text": "source-language parsing", "start_pos": 34, "end_pos": 57, "type": "TASK", "confidence": 0.6304970234632492}]}, {"text": "In our approach, we first use an SMT system to translate the sentences of a source monolingual treebank into the target language.", "labels": [], "entities": [{"text": "SMT", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.980701744556427}]}, {"text": "Then, the target sentences are parsed by a parser trained on a target monolingual treebank.", "labels": [], "entities": []}, {"text": "We then obtain a bilingual treebank that has human annotated trees on the source side and auto-generated trees on the target side.", "labels": [], "entities": []}, {"text": "Although the sentences and parse trees on the target side are not perfect, we expect that we can improve bitext parsing performance by using this newly auto-generated bilingual treebank.", "labels": [], "entities": [{"text": "bitext parsing", "start_pos": 105, "end_pos": 119, "type": "TASK", "confidence": 0.6002077907323837}]}, {"text": "We build word alignment links automatically using a word alignment tool.", "labels": [], "entities": [{"text": "word alignment links", "start_pos": 9, "end_pos": 29, "type": "TASK", "confidence": 0.7889638841152191}, {"text": "word alignment", "start_pos": 52, "end_pos": 66, "type": "TASK", "confidence": 0.7339962273836136}]}, {"text": "Then we can produce a set of bilingual constraints between the two sides.", "labels": [], "entities": []}, {"text": "Because the translation, parsing, and word alignment are done automatically, the constraints are not reliable.", "labels": [], "entities": [{"text": "translation", "start_pos": 12, "end_pos": 23, "type": "TASK", "confidence": 0.9713698029518127}, {"text": "parsing", "start_pos": 25, "end_pos": 32, "type": "TASK", "confidence": 0.7494471669197083}, {"text": "word alignment", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.7928392589092255}]}, {"text": "To overcome this problem, we verify the constraints by using large-scale unannotated monolingual sentences and bilingual sentence pairs.", "labels": [], "entities": []}, {"text": "Finally, we design a set of bilingual features based on the verified results for parsing models.", "labels": [], "entities": [{"text": "parsing", "start_pos": 81, "end_pos": 88, "type": "TASK", "confidence": 0.9667871594429016}]}, {"text": "Our approach uses existing resources including monolingual treebanks to train monolingual parsers on both sides, bilingual unannotated data to train SMT systems and to extract bilingual subtrees, and target monolingual unannotated data to extract monolingual subtrees.", "labels": [], "entities": [{"text": "SMT", "start_pos": 149, "end_pos": 152, "type": "TASK", "confidence": 0.9708353877067566}]}, {"text": "In summary, we make the following contributions: \u2022 We propose an approach that uses an autogenerated bilingual treebank rather than human-annotated bilingual treebanks used in previous studies).", "labels": [], "entities": []}, {"text": "The auto-generated bilingual treebank is built with the help of SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9527742862701416}]}, {"text": "\u2022 We verify the unreliable constraints by using the existing large-scale unannotated data and design a set of effective bilingual features over the verified results.", "labels": [], "entities": []}, {"text": "Compared to that also used tree structures on the target side, our approach defines the features on the auto-translated sentences and auto-parsed trees, while theirs generates the features by some rules on the human-translated sentences.", "labels": [], "entities": []}, {"text": "\u2022 Our parser significantly outperforms state-ofthe-art baseline systems on the standard test data of CTB containing about 3,000 sentences.", "labels": [], "entities": [{"text": "CTB", "start_pos": 101, "end_pos": 104, "type": "DATASET", "confidence": 0.740737795829773}]}, {"text": "Moreover, our approach continues to achieve improvement when we build our system using the latest version of CTB (over 50,000 sentences) that results in a much stronger baseline.", "labels": [], "entities": [{"text": "CTB", "start_pos": 109, "end_pos": 112, "type": "DATASET", "confidence": 0.9268664121627808}]}, {"text": "\u2022 We show the possibility that we can improve the performance even if the test set has no human translation.", "labels": [], "entities": []}, {"text": "This means that our proposed approach can be used in a purely monolingual setting with the help of SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 99, "end_pos": 102, "type": "TASK", "confidence": 0.9747241735458374}]}, {"text": "To our knowledge, this paper is the first one that demonstrates this widened applicability, unlike the previous studies that assumed that the parser is applied only on the bitexts made by humans.", "labels": [], "entities": [{"text": "applicability", "start_pos": 77, "end_pos": 90, "type": "METRIC", "confidence": 0.9829896092414856}]}, {"text": "Throughout this paper, we use Chinese as the source language and English as the target language.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 introduces the motivation of this work.", "labels": [], "entities": []}, {"text": "Section 3 briefly introduces the parsing model used in the experiments.", "labels": [], "entities": [{"text": "parsing", "start_pos": 33, "end_pos": 40, "type": "TASK", "confidence": 0.9764599204063416}]}, {"text": "Section 4 describes a set of bilingual features based on the bilingual constraints and Section 5 describes how to use large-scale unannotated data to verify the bilingual constraints and define another set of bilingual features based on the verified results.", "labels": [], "entities": []}, {"text": "Section 6 explains the experimental results.", "labels": [], "entities": []}, {"text": "Finally, in Section 7 we draw conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the proposed method on the translated portion of the Chinese Treebank V2 (referred to as CTB2 tp ) (, articles 1-325 of CTB, which have English translations with gold-standard parse trees.", "labels": [], "entities": [{"text": "Chinese Treebank V2", "start_pos": 66, "end_pos": 85, "type": "DATASET", "confidence": 0.9439529379208883}, {"text": "CTB", "start_pos": 133, "end_pos": 136, "type": "DATASET", "confidence": 0.9496911764144897}]}, {"text": "The tool \"Penn2Malt\" 2 was used to convert the data into dependency structures.", "labels": [], "entities": [{"text": "Penn2Malt", "start_pos": 10, "end_pos": 19, "type": "DATASET", "confidence": 0.9617844223976135}]}, {"text": "Following the studies of, and, we used the exact same data split: 1-270 for training, 301-325 for development, and 271-300 for testing.", "labels": [], "entities": []}, {"text": "Note that we did not use human translation on the English side of this bilingual treebank to train our new parsers.", "labels": [], "entities": []}, {"text": "For testing, we used two settings: a test with human translation and another with auto-translation.", "labels": [], "entities": []}, {"text": "To process unannotated data, we trained a first-order Parser son the training data.", "labels": [], "entities": []}, {"text": "To prove that the proposed method can work on larger monolingual treebanks, we also tested our 2 http://w3.msi.vxu.se/\u02dcnivre/research/Penn2Malt.html methods on the CTB7 (LDC2010T07) that includes much more sentences than CTB2 tp . We used articles 301-325 for development, 271-300 for testing, and the other articles for training.", "labels": [], "entities": [{"text": "CTB7 (LDC2010T07)", "start_pos": 164, "end_pos": 181, "type": "DATASET", "confidence": 0.9065113216638565}]}, {"text": "That is, we evaluated the systems on the same test data as CTB2 tp . shows the statistical information on the data sets.", "labels": [], "entities": [{"text": "CTB2 tp", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.9572255313396454}]}, {"text": "We built Chinese-to-English SMT systems based on Moses 3 . Minimum error rate training (MERT) with respect to BLEU score was used to tune the decoder's parameters.", "labels": [], "entities": [{"text": "SMT", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9063923954963684}, {"text": "Minimum error rate training (MERT)", "start_pos": 59, "end_pos": 93, "type": "METRIC", "confidence": 0.9259775621550423}, {"text": "BLEU score", "start_pos": 110, "end_pos": 120, "type": "METRIC", "confidence": 0.9817354381084442}]}, {"text": "The translation model was created from the FBIS corpus (LDC2003E14).", "labels": [], "entities": [{"text": "FBIS corpus (LDC2003E14)", "start_pos": 43, "end_pos": 67, "type": "DATASET", "confidence": 0.946884024143219}]}, {"text": "We used SRILM 4 to train a 5-gram language model.", "labels": [], "entities": []}, {"text": "The language model was trained on the target side of the FBIS corpus and the Xinhua news in English Gigaword corpus (LDC2009T13).", "labels": [], "entities": [{"text": "FBIS corpus", "start_pos": 57, "end_pos": 68, "type": "DATASET", "confidence": 0.961230605840683}, {"text": "Xinhua news in English Gigaword corpus (LDC2009T13)", "start_pos": 77, "end_pos": 128, "type": "DATASET", "confidence": 0.8429241511556838}]}, {"text": "The development and test sets were from NIST MT08 evaluation campaign . We then used the SMT systems to translate the training data of CTB2 tp and CTB7.", "labels": [], "entities": [{"text": "NIST MT08 evaluation campaign", "start_pos": 40, "end_pos": 69, "type": "DATASET", "confidence": 0.8971805721521378}, {"text": "SMT", "start_pos": 89, "end_pos": 92, "type": "TASK", "confidence": 0.8690069317817688}, {"text": "CTB2 tp", "start_pos": 135, "end_pos": 142, "type": "DATASET", "confidence": 0.922989010810852}, {"text": "CTB7", "start_pos": 147, "end_pos": 151, "type": "DATASET", "confidence": 0.8723345398902893}]}, {"text": "To directly compare with the results of and, we also used the same word alignment tool, Berkeley Aligner (, to perform word alignment for CTB2 tp and CTB7.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 67, "end_pos": 81, "type": "TASK", "confidence": 0.7178062200546265}, {"text": "word alignment", "start_pos": 119, "end_pos": 133, "type": "TASK", "confidence": 0.754724383354187}]}, {"text": "We trained a Berkeley Aligner on the FBIS corpus (LDC2003E14).", "labels": [], "entities": [{"text": "FBIS corpus (LDC2003E14)", "start_pos": 37, "end_pos": 61, "type": "DATASET", "confidence": 0.9259961009025574}]}, {"text": "We removed notoriously bad links in {a, an, the}\u00d7{(de), (le)} following the work of.", "labels": [], "entities": []}, {"text": "To train an English parser, we used the PTB ( in our experiments and the tool \"Penn2Malt\" to convert the data.", "labels": [], "entities": [{"text": "PTB", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.8339058756828308}, {"text": "Penn2Malt", "start_pos": 79, "end_pos": 88, "type": "DATASET", "confidence": 0.9512448906898499}]}, {"text": "We split the data into a training set (sections 2-21), a development set (section 22), and a test set (section 23).", "labels": [], "entities": []}, {"text": "We trained first-order and second-order Parser ton the training data.", "labels": [], "entities": [{"text": "Parser", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.4215943217277527}]}, {"text": "The unlabeled attachment score (UAS) of the second-order Parser twas 91.92, indicating state-of-the-art accuracy on the test data.", "labels": [], "entities": [{"text": "unlabeled attachment score (UAS)", "start_pos": 4, "end_pos": 36, "type": "METRIC", "confidence": 0.8324893712997437}, {"text": "Parser twas 91.92", "start_pos": 57, "end_pos": 74, "type": "DATASET", "confidence": 0.7671459317207336}, {"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9994658827781677}]}, {"text": "We used the second-order Parser t to parse the autotranslated/human-made target sentences in the CTB data.", "labels": [], "entities": [{"text": "Parser", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.8599587082862854}, {"text": "CTB data", "start_pos": 97, "end_pos": 105, "type": "DATASET", "confidence": 0.9454832375049591}]}, {"text": "To extract English subtrees, we used the BLLIP corpus () that contains about 43 million words of WSJ texts.", "labels": [], "entities": [{"text": "BLLIP corpus", "start_pos": 41, "end_pos": 53, "type": "DATASET", "confidence": 0.879477322101593}, {"text": "WSJ texts", "start_pos": 97, "end_pos": 106, "type": "DATASET", "confidence": 0.9001398682594299}]}, {"text": "We used the MX-POST tagger) trained on training data to assign POS tags and used the first-order Parser t to process the sentences of the BLLIP corpus.", "labels": [], "entities": [{"text": "BLLIP corpus", "start_pos": 138, "end_pos": 150, "type": "DATASET", "confidence": 0.9412006735801697}]}, {"text": "To extract bilingual subtrees, we used the FBIS corpus and an additional bilingual corpus containing 800,000 sentence pairs from the training data of NIST MT08 evaluation campaign.", "labels": [], "entities": [{"text": "FBIS corpus", "start_pos": 43, "end_pos": 54, "type": "DATASET", "confidence": 0.9194808006286621}, {"text": "NIST MT08 evaluation campaign", "start_pos": 150, "end_pos": 179, "type": "DATASET", "confidence": 0.8780290931463242}]}, {"text": "On the Chinese side, we used the morphological analyzer described in () trained on the training data of CTB tp to perform word segmentation and POS tagging and used the first-order Parser s to parse all the sentences in the data.", "labels": [], "entities": [{"text": "CTB tp", "start_pos": 104, "end_pos": 110, "type": "DATASET", "confidence": 0.9038150310516357}, {"text": "word segmentation", "start_pos": 122, "end_pos": 139, "type": "TASK", "confidence": 0.7511364817619324}, {"text": "POS tagging", "start_pos": 144, "end_pos": 155, "type": "TASK", "confidence": 0.7891310155391693}]}, {"text": "On the English side, we used the same procedure as we did for the BLLIP corpus.", "labels": [], "entities": [{"text": "BLLIP corpus", "start_pos": 66, "end_pos": 78, "type": "DATASET", "confidence": 0.9513078033924103}]}, {"text": "Word alignment was performed using the Berkeley Aligner.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7426743060350418}]}, {"text": "We reported the parser quality by the UAS, i.e., the percentage of tokens (excluding all punctuation tokens) with correct HEADs.", "labels": [], "entities": [{"text": "UAS", "start_pos": 38, "end_pos": 41, "type": "DATASET", "confidence": 0.9004578590393066}]}, {"text": "For baseline systems, we used the monolingual features mentioned in Section 3.", "labels": [], "entities": []}, {"text": "We called these features basic features.", "labels": [], "entities": []}, {"text": "To compare the results of, we used the test data with human translation in the following three experiments.", "labels": [], "entities": []}, {"text": "The target sentences were parsed by using the second-order Parser t . We used PAG to refer to our parsers trained on the auto-generated bilingual treebank.", "labels": [], "entities": [{"text": "PAG", "start_pos": 78, "end_pos": 81, "type": "METRIC", "confidence": 0.8461106419563293}]}], "tableCaptions": [{"text": " Table 3: Number of sentences of data sets used", "labels": [], "entities": []}, {"text": " Table 4: Results of training with CTB2 tp", "labels": [], "entities": [{"text": "CTB2 tp", "start_pos": 35, "end_pos": 42, "type": "DATASET", "confidence": 0.8416008949279785}]}, {"text": " Table 5: Results of using different translations", "labels": [], "entities": []}, {"text": " Table 6: Results of testing with auto-translation (training  with CTB2 tp )", "labels": [], "entities": []}, {"text": " Table 7: Comparison of our results with other pre- vious reported systems. Type M denotes training on  monolingual treebank. Types HA and AG denote training  on human-annotated and auto-generated bilingual tree- banks respectively.", "labels": [], "entities": [{"text": "AG", "start_pos": 139, "end_pos": 141, "type": "METRIC", "confidence": 0.9808403849601746}]}]}