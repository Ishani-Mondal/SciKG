{"title": [], "abstractContent": [{"text": "Context-dependent word similarity can be measured over multiple cross-cutting dimensions.", "labels": [], "entities": []}, {"text": "For example, lung and breath are similar thematically, while authoritative and superficial occur in similar syntactic contexts, but share little semantic similarity.", "labels": [], "entities": []}, {"text": "Both of these notions of similarity play a role in determining word meaning, and hence lexical semantic models must take them both into account.", "labels": [], "entities": []}, {"text": "Towards this end, we develop a novel model, Multi-View Mixture (MVM), that represents words as multiple overlapping clus-terings.", "labels": [], "entities": [{"text": "Multi-View Mixture (MVM)", "start_pos": 44, "end_pos": 68, "type": "TASK", "confidence": 0.7470979273319245}]}, {"text": "MVM finds multiple data partitions based on different subsets of features, subject to the marginal constraint that feature subsets are distributed according to Latent Dirich-let Allocation.", "labels": [], "entities": []}, {"text": "Intuitively, this constraint favors feature partitions that have coherent topical semantics.", "labels": [], "entities": []}, {"text": "Furthermore, MVM uses soft feature assignment, hence the contribution of each data point to each clustering view is variable , isolating the impact of data only to views where they assign the most features.", "labels": [], "entities": []}, {"text": "Through a series of experiments, we demonstrate the utility of MVM as an inductive bias for capturing relations between words that are intuitive to humans, outperforming related models such as Latent Dirichlet Allocation.", "labels": [], "entities": []}], "introductionContent": [{"text": "Humans categorize objects using multiple orthogonal taxonomic systems, where category generalization depends critically on what features are relevant to one particular system.", "labels": [], "entities": []}, {"text": "For example, foods can be organized in terms of their nutritional value (high in fiber) or situationally (commonly eaten for Thanksgiving;).", "labels": [], "entities": []}, {"text": "Human knowledgebases such as Wikipedia also exhibit such multiple clustering structure (e.g. people are organized by occupation or by nationality).", "labels": [], "entities": []}, {"text": "The effects of these overlapping categorization systems manifest themselves at the lexical semantic level, implying that lexicographical word senses and traditional computational models of word-sense based on clustering or exemplar activation are too impoverished to capture the rich dynamics of word usage.", "labels": [], "entities": []}, {"text": "In this work, we introduce a novel probabilistic clustering method, Multi-View Mixture (MVM), based on cross-cutting categorization () that generalizes traditional vector-space or distributional models of lexical semantics).", "labels": [], "entities": [{"text": "Multi-View Mixture (MVM)", "start_pos": 68, "end_pos": 92, "type": "TASK", "confidence": 0.789587652683258}]}, {"text": "Cross-cutting categorization finds multiple feature subsets (categorization systems) that produce high quality clusterings of the data.", "labels": [], "entities": []}, {"text": "For example words might be clustered based on their part of speech, or based on their thematic usage.", "labels": [], "entities": []}, {"text": "Contextdependent variation in word usage can be accounted for by leveraging multiple latent categorization systems.", "labels": [], "entities": []}, {"text": "In particular, cross-cutting models can be used to capture both syntagmatic and paradigmatic notions of word relatedness, breaking up word features into multiple categorization systems and then computing similarity separately for each system.", "labels": [], "entities": []}, {"text": "MVM leverages primitives from Dirichlet-Process Mixture Models (DPMMs) and Latent Dirichlet Allocation (LDA).", "labels": [], "entities": []}, {"text": "Each clustering (view) in MVM consists of a distribution over features and data and views are further subdivided into clusters based on a DPMM.", "labels": [], "entities": []}, {"text": "View marginal distributions are determined by LDA, allowing data features to be distributed over multiple views, explaining subsets of features.", "labels": [], "entities": []}, {"text": "1405 We evaluate MVM against several other modelbased clustering procedures in a series of human evaluation tasks, measuring its ability to find meaningful syntagmatic and paradigmatic structure.", "labels": [], "entities": [{"text": "MVM", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9686702489852905}]}, {"text": "We find that MVM finds more semantically and syntactically coherent fine-grained structure, using both common and rare n-gram contexts.", "labels": [], "entities": [{"text": "MVM", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9545708298683167}]}], "datasetContent": [{"text": "Our main goal in this work is to find models that capture aspects of the syntactic and semantic organization of word in text that are intuitive to humans.", "labels": [], "entities": []}, {"text": "According to the use theory of meaning, lexical semantic knowledge is equivalent to knowing the contexts that words appear in, and hence being able to form reasonable hypotheses about the relatedness of syntactic contexts.", "labels": [], "entities": []}, {"text": "Vector space models are commonly evaluated by comparing their similarity predictions to a nominal set of human similarity judgments).", "labels": [], "entities": []}, {"text": "In this work, since we are evaluating models that potentially yield many different similarity scores, we take a different approach, scoring clusters on their semantic and syntactic coherence using a set intrusion task (.", "labels": [], "entities": []}, {"text": "In set intrusion, human raters are shown a set of options from a coherent group and asked to identify a single intruder drawn from a different group.", "labels": [], "entities": []}, {"text": "We extend intrusion to three different lexical semantic tasks: (1) context intrusion, where the top contexts from each cluster are used, (3) document intrusion, where the top document contexts from each cluster are used, and (2) word intrusion, where the top words from each cluster are used.", "labels": [], "entities": [{"text": "word intrusion", "start_pos": 229, "end_pos": 243, "type": "TASK", "confidence": 0.7401784360408783}]}, {"text": "For each cluster, the top four contexts/words are selected and appended with another context/word from a different cluster.", "labels": [], "entities": []}, {"text": "The resulting set is then shuffled, and the human raters are asked to identify the intruder, af-ter being given a short introduction (with common examples) to the task.", "labels": [], "entities": []}, {"text": "shows sample questions of varying degrees of difficulty.", "labels": [], "entities": []}, {"text": "As the semantic coherence and distinctness from other clusters increases, this task becomes easier.", "labels": [], "entities": []}, {"text": "Set intrusion is a more robust way to account for human similarity judgments than asking directly fora numeric score (e.g., the set) as less calibration is required across raters.", "labels": [], "entities": []}, {"text": "Furthermore, the additional cluster context significantly reduces the variability of responses.", "labels": [], "entities": []}, {"text": "Human raters were recruited from Amazon's Mechanical Turk.", "labels": [], "entities": [{"text": "Amazon's Mechanical Turk", "start_pos": 33, "end_pos": 57, "type": "DATASET", "confidence": 0.9557339549064636}]}, {"text": "A total of 1256 raters completed 30438 evaluations for 5780 unique intrusion tasks (5 evaluations per task).", "labels": [], "entities": []}, {"text": "2736 potentially fraudulent evaluations from 11 raters were rejected.", "labels": [], "entities": []}, {"text": "Overall we found \u03ba 0.4 for most tasks; a set of comments about the task difficulty is given in, drawn from an anonymous public message board.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Fleiss' \u03ba scores for various model and data com- binations. Results from MVM have higher \u03ba scores than  LDA or DPMM; likewise Syntax+Documents data yields  higher agreement, primarily due to the relative ease of the  document intrusion task.", "labels": [], "entities": [{"text": "agreement", "start_pos": 173, "end_pos": 182, "type": "METRIC", "confidence": 0.9895048141479492}]}]}