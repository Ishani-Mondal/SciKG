{"title": [{"text": "Computation of Infix Probabilities for Probabilistic Context-Free Grammars", "labels": [], "entities": []}], "abstractContent": [{"text": "The notion of infix probability has been introduced in the literature as a generalization of the notion of prefix (or initial substring) probability , motivated by applications in speech recognition and word error correction.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 180, "end_pos": 198, "type": "TASK", "confidence": 0.7471035122871399}, {"text": "word error correction", "start_pos": 203, "end_pos": 224, "type": "TASK", "confidence": 0.7575882077217102}]}, {"text": "For the case where a probabilistic context-free grammar is used as language model, methods for the computation of infix probabilities have been presented in the literature, based on various simplifying assumptions.", "labels": [], "entities": []}, {"text": "Here we present a solution that applies to the problem in its full generality.", "labels": [], "entities": []}], "introductionContent": [{"text": "Probabilistic context-free grammars (PCFGs for short) area statistical model widely used in natural language processing.", "labels": [], "entities": []}, {"text": "Several computational problems related to PCFGs have been investigated in the literature, motivated by applications in modeling of natural language syntax.", "labels": [], "entities": []}, {"text": "One such problem is the computation of prefix probabilities for PCFGs, where we are given as input a PCFG G and a string w, and we are asked to compute the probability that a sentence generated by G starts with w, that is, has was a prefix.", "labels": [], "entities": []}, {"text": "This quantity is defined as the possibly infinite sum of the probabilities of all strings of the form wx, for any string x over the alphabet of G.", "labels": [], "entities": []}, {"text": "The problem of computation of prefix probabilities for PCFGs was first formulated by.", "labels": [], "entities": []}, {"text": "Efficient algorithms for its solution have been proposed by and.", "labels": [], "entities": []}, {"text": "Prefix probabilities can be used to compute probability distributions for the next word or part-of-speech, when a prefix of the input has already been processed, as discussed by.", "labels": [], "entities": [{"text": "Prefix", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9078450202941895}]}, {"text": "Such distributions are useful for speech recognition, where the result of the acoustic processor is represented as a lattice, and local choices must be made fora next transition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.8496576249599457}]}, {"text": "In addition, distributions for the next word are also useful for applications of word error correction, when one is processing 'noisy' text and the parser recognizes an error that must be recovered by operations of insertion, replacement or deletion.", "labels": [], "entities": [{"text": "word error correction", "start_pos": 81, "end_pos": 102, "type": "TASK", "confidence": 0.664238969484965}]}, {"text": "Motivated by the above applications, the problem of the computation of infix probabilities for PCFGs has been introduced in the literature as a generalization of the prefix probability problem.", "labels": [], "entities": []}, {"text": "We are now given a PCFG G and a string w, and we are asked to compute the probability that a sentence generated by G has was an infix.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 19, "end_pos": 23, "type": "DATASET", "confidence": 0.9111098051071167}]}, {"text": "This probability is defined as the possibly infinite sum of the probabilities of all strings of the form xwy, for any pair of strings x and y over the alphabet of G.", "labels": [], "entities": []}, {"text": "Besides applications in computation of the probability distribution for the next word token and in word error correction, infix probabilities can also be exploited in speech understanding systems to score partial hypotheses in algorithms based on beam search, as discussed by. have pointed out that the computation of infix probabilities is more difficult than the computation of prefix probabilities, due to the added ambiguity that several occurrences of the given infix can be found in a single string generated by the PCFG.", "labels": [], "entities": [{"text": "word error correction", "start_pos": 99, "end_pos": 120, "type": "TASK", "confidence": 0.681624968846639}, {"text": "speech understanding", "start_pos": 167, "end_pos": 187, "type": "TASK", "confidence": 0.7203148156404495}, {"text": "PCFG", "start_pos": 522, "end_pos": 526, "type": "DATASET", "confidence": 0.9766339659690857}]}, {"text": "The authors developed solutions for the case where some distribution can be defined on 1213 the distance of the infix from the sentence boundaries, which is a simplifying assumption.", "labels": [], "entities": []}, {"text": "The problem is also considered by, which provides algorithms for the case where the language model is a probabilistic regular grammar.", "labels": [], "entities": []}, {"text": "However, the algorithm in) does not apply to cases with multiple occurrences of the given infix within a string in the language, which is what was pointed out to be the problematic case.", "labels": [], "entities": []}, {"text": "In this paper we adopt a novel approach to the problem of computation of infix probabilities, by removing the ambiguity that would be caused by multiple occurrences of the given infix.", "labels": [], "entities": []}, {"text": "Although our result is obtained by a combination of well-known techniques from the literature on PCFG parsing and pattern matching, as far as we know this is the first algorithm for the computation of infix probabilities that works for general PCFG models without any restrictive assumption.", "labels": [], "entities": [{"text": "PCFG parsing", "start_pos": 97, "end_pos": 109, "type": "TASK", "confidence": 0.742348849773407}, {"text": "pattern matching", "start_pos": 114, "end_pos": 130, "type": "TASK", "confidence": 0.7585548162460327}]}, {"text": "The remainder of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we explain how the sum of the probabilities of all trees generated by a PCFG can be computed as the least fixed-point solution of a non-linear system of equations.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 85, "end_pos": 89, "type": "DATASET", "confidence": 0.9158217906951904}]}, {"text": "In Section 3 we recall the construction of anew PCFG out of a given PCFG and a given finite automaton, such that the language generated by the new grammar is the intersection of the languages generated by the given PCFG and the automaton, and the probabilities of the generated strings are preserved.", "labels": [], "entities": []}, {"text": "In Section 4 we show how one can efficiently construct an unambiguous finite automaton that accepts all strings with a given infix.", "labels": [], "entities": []}, {"text": "The material from these three sections is combined into anew algorithm in Section 5, which allows computation of the infix probability for PCFGs.", "labels": [], "entities": []}, {"text": "This is the main result of this paper.", "labels": [], "entities": []}, {"text": "Several extensions of the basic technique are discussed in Section 6.", "labels": [], "entities": []}, {"text": "Section 7 discusses implementation and some experiments.", "labels": [], "entities": [{"text": "implementation", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.9550071358680725}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Running time for infixes from length 2 to length 7. The infixes are prefixes of 10 random strings of length 7,  and reported CPU times (in seconds) are averaged over the 10 strings.", "labels": [], "entities": []}]}