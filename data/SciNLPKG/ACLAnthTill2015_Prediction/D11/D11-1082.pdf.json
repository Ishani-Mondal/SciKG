{"title": [{"text": "A Correction Model for Word Alignments", "labels": [], "entities": [{"text": "Word Alignments", "start_pos": 23, "end_pos": 38, "type": "TASK", "confidence": 0.7389525771141052}]}], "abstractContent": [{"text": "Models of word alignment built as sequences of links have limited expressive power, but are easy to decode.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.7670771777629852}]}, {"text": "Word aligners that model the alignment matrix can express arbitrary alignments , but are difficult to decode.", "labels": [], "entities": []}, {"text": "We propose an alignment matrix model as a correction algorithm to an underlying sequence-based aligner.", "labels": [], "entities": []}, {"text": "Then a greedy decoding algorithm enables the full expressive power of the alignment matrix formulation.", "labels": [], "entities": []}, {"text": "Improved alignment performance is shown for all nine language pairs tested.", "labels": [], "entities": []}, {"text": "The improved alignments also improved translation quality from Chinese to English and English to Italian.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word-level alignments of parallel text are crucial for enabling machine learning algorithms to fully utilize parallel corpora as training data.", "labels": [], "entities": []}, {"text": "Word alignments appear as hidden variables in IBM Models 1-5 () in order to bridge a gap between the sentence-level granularity that is explicit in the training data, and the implicit word-level correspondence that is needed to statistically model lexical ambiguity and word order rearrangements that are inherent in the translation process.", "labels": [], "entities": [{"text": "Word alignments", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7118155509233475}]}, {"text": "Other notable applications of word alignments include crosslanguage projection of linguistic analyzers (such as POS taggers and named entity detectors,) a subject which continues to be of interest.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 30, "end_pos": 45, "type": "TASK", "confidence": 0.7437972128391266}, {"text": "crosslanguage projection of linguistic analyzers", "start_pos": 54, "end_pos": 102, "type": "TASK", "confidence": 0.7973901271820069}, {"text": "POS taggers and named entity detectors", "start_pos": 112, "end_pos": 150, "type": "TASK", "confidence": 0.6491680939992269}]}, {"text": "(), The structure of the alignment model is tightly linked to the task of finding the optimal alignment.", "labels": [], "entities": []}, {"text": "Many alignment models are factorized in order to use dynamic programming and beam search for efficient marginalization and search.", "labels": [], "entities": []}, {"text": "Such a factorization encourages -but does not require -a sequential (often left-to-right) decoding order.", "labels": [], "entities": []}, {"text": "If left-to-right decoding is adopted (and exact dynamic programming is intractable) important right context may exist beyond the search window.", "labels": [], "entities": []}, {"text": "For example, the linkage of an English determiner maybe considered before the linkage of a distant head noun.", "labels": [], "entities": []}, {"text": "An alignment model that jointly models all of the links in the entire sentence does not motivate a particular decoding order.", "labels": [], "entities": []}, {"text": "It simply assigns comparable scores to the alignment of the entire sentence, and maybe used to rescore the top-N hypotheses of another aligner, or to decide whether heuristic perturbations to the output of an existing aligner constitute an improvement.", "labels": [], "entities": []}, {"text": "Both the training and decoding of full-sentence models have presented difficulties in the past, and approximations are necessary.", "labels": [], "entities": []}, {"text": "In this paper, we will show that by using an existing alignment as a starting point, we can make a significant improvement to the alignment by proposing a series of heuristic perturbations.", "labels": [], "entities": []}, {"text": "In effect, we train a model to fix the errors of the existing aligner.", "labels": [], "entities": []}, {"text": "From any initial alignment configuration, these perturbations define a multitude of paths to the reference (gold) alignment.", "labels": [], "entities": []}, {"text": "Our model learns alignment moves that modify an initial alignment into the reference alignment.", "labels": [], "entities": []}, {"text": "Furthermore, the resulting model assigns a score to the alignment and thus could be used in numerous rescoring algorithms, such as top-N rescorers.", "labels": [], "entities": []}, {"text": "In particular, we use the maximum entropy frame-work to choose alignment moves.", "labels": [], "entities": []}, {"text": "The model is symmetric: source and target languages are interchangeable.", "labels": [], "entities": []}, {"text": "The alignment moves are sufficiently rich to reach arbitrary phrase to phrase alignments.", "labels": [], "entities": []}, {"text": "Since most of the features in the model are not languagespecific, we are able to test the correction model easily on nine language pairs; our corrections improved the alignment quality compared to the input alignments in all nine.", "labels": [], "entities": []}, {"text": "We also tested the impact on translation and found a 0.48 BLEU improvement on Chinese to English and a 1.26 BLEU improvement on English to Italian translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 29, "end_pos": 40, "type": "TASK", "confidence": 0.9824946522712708}, {"text": "BLEU", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9993491768836975}, {"text": "BLEU", "start_pos": 108, "end_pos": 112, "type": "METRIC", "confidence": 0.9989223480224609}, {"text": "English to Italian translation", "start_pos": 128, "end_pos": 158, "type": "TASK", "confidence": 0.6843747049570084}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Alignment accuracy for Arabic-English systems in percentage recall (R), precision(P), and F -measure.  *   denotes statistical significance (see text.)", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.6826279759407043}, {"text": "percentage recall (R)", "start_pos": 59, "end_pos": 80, "type": "METRIC", "confidence": 0.8858232140541077}, {"text": "precision(P)", "start_pos": 82, "end_pos": 94, "type": "METRIC", "confidence": 0.9701759666204453}, {"text": "F -measure", "start_pos": 100, "end_pos": 110, "type": "METRIC", "confidence": 0.9932156205177307}]}, {"text": " Table 2: Alignment accuracy for Chinese(ZH)-English(EN) systems.  *  denotes statistical significance", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.5898106694221497}]}, {"text": " Table 3: Alignment accuracy for additional languages.  *  denotes statistical significance;  \u2020 statistical significance not  available. IT=Italian, PT=Portuguese, JA=Japanese, RU=Russian, DE=German, ES=Spanish, FR=French", "labels": [], "entities": [{"text": "Alignment", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.6642727255821228}, {"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.8554712533950806}, {"text": "FR", "start_pos": 212, "end_pos": 214, "type": "METRIC", "confidence": 0.977605402469635}]}, {"text": " Table 4: Analysis of 2\u22121 alignments errors (misses and false alarms) for Zh-En and Ar-En aligners", "labels": [], "entities": []}, {"text": " Table 5: Importance of feature classes -ablation experi- ments", "labels": [], "entities": [{"text": "Importance", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9462714195251465}, {"text": "ablation experi- ments", "start_pos": 41, "end_pos": 63, "type": "METRIC", "confidence": 0.8474669903516769}]}, {"text": " Table 6: Translation results, Zh to En. BLEU=BLEUr4n4", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9297717213630676}, {"text": "BLEU", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.908735454082489}, {"text": "BLEUr4n4", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9935327768325806}]}, {"text": " Table 7: Translation results, En to It", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9797869920730591}]}]}