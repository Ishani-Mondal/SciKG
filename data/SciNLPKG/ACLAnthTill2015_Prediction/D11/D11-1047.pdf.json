{"title": [{"text": "Efficient retrieval of tree translation examples for Syntax-Based Machine Translation", "labels": [], "entities": [{"text": "tree translation", "start_pos": 23, "end_pos": 39, "type": "TASK", "confidence": 0.7094333171844482}, {"text": "Syntax-Based Machine Translation", "start_pos": 53, "end_pos": 85, "type": "TASK", "confidence": 0.7958064277966818}]}], "abstractContent": [{"text": "We propose an algorithm allowing to efficiently retrieve example treelets in a parsed tree database in order to allow on-the-fly extraction of syntactic translation rules.", "labels": [], "entities": [{"text": "extraction of syntactic translation", "start_pos": 129, "end_pos": 164, "type": "TASK", "confidence": 0.5671435818076134}]}, {"text": "We also propose improvements of this algorithm allowing several kinds of flexible matchings.", "labels": [], "entities": []}], "introductionContent": [{"text": "The popular Example-Based (EBMT) and Statistical Machine Translation (SMT) paradigms make use of the translation examples provided by a parallel bilingual corpus to produce new translations.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 37, "end_pos": 74, "type": "TASK", "confidence": 0.7565520703792572}]}, {"text": "Most of these translation systems process the example data in a similar way: The parallel sentences are first word-aligned.", "labels": [], "entities": []}, {"text": "Then, translation rules are extracted from these aligned sentences.", "labels": [], "entities": []}, {"text": "Finally, the translation rules are used in a decoding step to translate sentences.", "labels": [], "entities": []}, {"text": "We use the term translation rule in a very broad sense here, as it may refer to substring pairs as in (, synchronous grammar rules as in or treelet pairs as in.", "labels": [], "entities": []}, {"text": "As the size of bilingual corpus grow larger, the number of translation rules to be stored can easily become unmanageable.", "labels": [], "entities": []}, {"text": "As a solution to this problem in the context of phrase-based Machine Translation,) proposed to prealign the example corpora, but delay the rule extraction to the decoding stage.", "labels": [], "entities": [{"text": "phrase-based Machine Translation", "start_pos": 48, "end_pos": 80, "type": "TASK", "confidence": 0.6315276821454366}, {"text": "rule extraction", "start_pos": 139, "end_pos": 154, "type": "TASK", "confidence": 0.7200577557086945}]}, {"text": "They showed that using Suffix Arrays, it was possible to efficiently retrieve all sentences containing substrings of the sentence to be translated, and thus extract the needed translation rules on-the-fly.", "labels": [], "entities": []}, {"text": "( proposed an extension of this method for retrieving discontinuous substrings, making it suitable for systems such as.", "labels": [], "entities": []}, {"text": "In this paper, we propose a method to apply the same idea to.", "labels": [], "entities": []}, {"text": "Since Syntax-Based systems usually work with the parse trees of the source-side sentences, we will need to be able to retrieve efficiently examples trees from fragments (treelets) of the parse tree of the sentence we want to translate.", "labels": [], "entities": []}, {"text": "We will also propose extensions of this method allowing more flexible matchings.", "labels": [], "entities": []}], "datasetContent": [{"text": "Using the above ideas, we have made some experiments for computing query dependency trees labeled with both words and POS.", "labels": [], "entities": []}, {"text": "We score the treelets by giving them a penalty of -1 for each POS they contain, and stop the search when all remaining treelets have a score lower than -2 (in other words, treelets are allowed at most 2 POS-matchings).", "labels": [], "entities": []}, {"text": "We also require POS-matched nodes to be non-adjacent.", "labels": [], "entities": []}, {"text": "We only have some small modifications to do to algorithm 2.", "labels": [], "entities": []}, {"text": "In line 3 of algorithm 2, elementary treelets are assigned a weight of 0 or -1 depending on whether their label is a word or POS.", "labels": [], "entities": []}, {"text": "Line 5 is replaced by \"pop the first treelet with minimal weight and break the loop if the minimal weight is inferior to -2\".", "labels": [], "entities": []}, {"text": "In compute-supertreelets, we give a weight to the generated supertreelets by combining the weights of the child treelets.", "labels": [], "entities": []}, {"text": "shows the increase in the size of the biggest non-empty treelets when allowing 2 nodes to be matched by POS.", "labels": [], "entities": []}, {"text": "It also shows the impact on BLEU score of using these additional treelets for onthe-fly rule generation in our simple MT system.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 28, "end_pos": 38, "type": "METRIC", "confidence": 0.9808520078659058}, {"text": "onthe-fly rule generation", "start_pos": 78, "end_pos": 103, "type": "TASK", "confidence": 0.6780362327893575}, {"text": "MT", "start_pos": 118, "end_pos": 120, "type": "TASK", "confidence": 0.965650200843811}]}, {"text": "Improvement on BLEU is limited, but it might be due to a very experimental handling of approximately matched treelet examples in our MT system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.9975870847702026}, {"text": "MT", "start_pos": 133, "end_pos": 135, "type": "TASK", "confidence": 0.8858034014701843}]}, {"text": "The computation time, while manageable, was much slower than in the one-label case.", "labels": [], "entities": []}, {"text": "This is due to the increased number of treelets to be computed, and to the fact that POS-labeled elementary treelets have a high number of occurrences.", "labels": [], "entities": []}, {"text": "It would be more efficient to use more specific labeling (e.g V- mvt for verbs of movement instead of V).", "labels": [], "entities": []}], "tableCaptions": []}