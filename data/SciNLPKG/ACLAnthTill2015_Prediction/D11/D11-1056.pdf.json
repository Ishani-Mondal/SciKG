{"title": [{"text": "Non-parametric Bayesian Segmentation of Japanese Noun Phrases", "labels": [], "entities": [{"text": "Bayesian Segmentation of Japanese Noun Phrases", "start_pos": 15, "end_pos": 61, "type": "TASK", "confidence": 0.7097706447045008}]}], "abstractContent": [{"text": "A key factor of high quality word segmenta-tion for Japanese is a high-coverage dictionary , but it is costly to manually build such a lexical resource.", "labels": [], "entities": []}, {"text": "Although external lexical resources for human readers are potentially good knowledge sources, they have not been utilized due to differences in segmentation criteria.", "labels": [], "entities": []}, {"text": "To supplement a morphological dictionary with these resources, we propose anew task of Japanese noun phrase segmentation.", "labels": [], "entities": [{"text": "Japanese noun phrase segmentation", "start_pos": 87, "end_pos": 120, "type": "TASK", "confidence": 0.5660180896520615}]}, {"text": "We apply non-parametric Bayesian language models to segment each noun phrase in these resources according to the statistical behavior of its supposed constituents in text.", "labels": [], "entities": []}, {"text": "For inference , we propose a novel block sampling procedure named hybrid type-based sampling, which has the ability to directly escape a local optimum that is not too distant from the global optimum.", "labels": [], "entities": []}, {"text": "Experiments show that the proposed method efficiently corrects the initial segmentation given by a morphological ana-lyzer.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word segmentation is the first step of natural language processing for Japanese, Chinese and Thai because they do not delimit words by white-space.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6862821131944656}, {"text": "natural language processing", "start_pos": 39, "end_pos": 66, "type": "TASK", "confidence": 0.7504256765047709}]}, {"text": "Segmentation for Japanese is a successful field of research, achieving the F-score of nearly 99% ().", "labels": [], "entities": [{"text": "Segmentation for Japanese", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.7446858286857605}, {"text": "F-score", "start_pos": 75, "end_pos": 82, "type": "METRIC", "confidence": 0.9996668100357056}]}, {"text": "This success rests on a high-coverage dictionary.", "labels": [], "entities": []}, {"text": "Unknown words, or words not covered by the dictionary, are often misidentified.", "labels": [], "entities": []}, {"text": "Historically, researchers have devoted extensive human resources to build and maintain highcoverage dictionaries.", "labels": [], "entities": []}, {"text": "Since the orthography of Japanese does not specify a standard for segmentation, researchers define their own criteria before constructing lexical resources.", "labels": [], "entities": []}, {"text": "For this reason, it is difficult to exploit existing external resources, such as dictionaries and encyclopedias for human readers, where entry words are not segmented according to the criteria.", "labels": [], "entities": []}, {"text": "Among them, encyclopedias are especially important in that they contain a lot of terms that a morphological dictionary fails to cover.", "labels": [], "entities": []}, {"text": "Most of these terms are noun phrases and consist of more than one word (morpheme).", "labels": [], "entities": []}, {"text": "For example, an encyclopedia has an entry \"\" (tsuneyama-jou, \"Tsuneyama Castle\").", "labels": [], "entities": []}, {"text": "According to our segmentation criteria, it consists of two words \"\" (tsuneyama) and \"\" (jou).", "labels": [], "entities": [{"text": "segmentation", "start_pos": 17, "end_pos": 29, "type": "TASK", "confidence": 0.9578660726547241}]}, {"text": "However, the morphological analyzer wrongly segments it into \"\" (tsune) and \"\" (yamashiro) because \"\" (tsuneyama) is an unknown word.", "labels": [], "entities": []}, {"text": "In this paper, we present the first attempt to utilize encyclopedias for word segmentation.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 73, "end_pos": 90, "type": "TASK", "confidence": 0.7612770795822144}]}, {"text": "We segment each entry noun phrase into words.", "labels": [], "entities": []}, {"text": "To do this, we examine the main text of the entry, on the assumption that if the noun phrase in question consists of more than one word, its constituents appear in the main text either freely or as part of other noun phrases.", "labels": [], "entities": []}, {"text": "For \"\" (tsuneyama-jou), its constituent \"\" (tsune) appears by itself and as constituents of other nouns phrases such as \" \" (peak of Tsuneyama) and \"\" (Tsuneyama Station) while \"\" (yamashiro) does not.", "labels": [], "entities": []}, {"text": "To segment each noun phrase, we use nonparametric Bayesian language models.", "labels": [], "entities": []}, {"text": "Our approach is based on two key factors: the bigram model and type-based block sampling.", "labels": [], "entities": []}, {"text": "The bigram model alleviates a problem of the unigram model, that is, a tendency to misidentify a sequence of words in common collocations as a single word.", "labels": [], "entities": []}, {"text": "Type-based sampling ( has the ability to directly escape a local optimum, making inference very efficient.", "labels": [], "entities": []}, {"text": "However, type-based sampling is not easily applicable to the bigram model owing to sparsity and its dependence on latent assignments.", "labels": [], "entities": []}, {"text": "We propose a hybrid type-based sampling procedure, which combines the Metropolis-Hastings algorithm with Gibbs sampling.", "labels": [], "entities": []}, {"text": "We circumvent the sparsity problem by joint sampling of unigram-level type.", "labels": [], "entities": []}, {"text": "Also, instead of calculating the probability of every possible state of the jointly sampled random variables, we only compare the current state with a proposed state.", "labels": [], "entities": []}, {"text": "This greatly eases the sampling procedure while retaining the efficiency of typebased sampling.", "labels": [], "entities": [{"text": "sampling", "start_pos": 23, "end_pos": 31, "type": "TASK", "confidence": 0.9611260294914246}]}, {"text": "Experiments show that the proposed method quickly corrects the initial segmentation given by a morphological analyzer.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}