{"title": [], "abstractContent": [{"text": "Targeted paraphrasing is anew approach to the problem of obtaining cost-effective, reasonable quality translation that makes use of simple and inexpensive human computations by monolin-gual speakers in combination with machine translation.", "labels": [], "entities": []}, {"text": "The key insight behind the process is that it is possible to spot likely translation errors with only monolingual knowledge of the target language, and it is possible to generate alternative ways to say the same thing (i.e. paraphrases) with only monolingual knowledge of the source language.", "labels": [], "entities": []}, {"text": "Evaluations demonstrate that this approach can yield substantial improvements in translation quality.", "labels": [], "entities": [{"text": "translation", "start_pos": 81, "end_pos": 92, "type": "TASK", "confidence": 0.9640657305717468}]}], "introductionContent": [{"text": "For most of the world's languages, the availability of translation is limited to two possibilities: high quality at high cost, via professional translators, and low quality at low cost, via machine translation (MT).", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 190, "end_pos": 214, "type": "TASK", "confidence": 0.8408029079437256}]}, {"text": "The spectrum between these two extremes is very poorly populated, and at any point on the spectrum the ready availability of translation is limited to only a small fraction of the world's languages.", "labels": [], "entities": []}, {"text": "There is, of course, along history of technological assistance to translators, improving cost effectiveness using translation memory) or other interactive tools to assist translators ().", "labels": [], "entities": []}, {"text": "And there is a recent and rapidly growing interest in crowdsourcing with non-professional translators, which can be remarkably effective.", "labels": [], "entities": []}, {"text": "However, all these alternatives face a central availability bottleneck: they require the participation of humans with bilingual expertise.", "labels": [], "entities": []}, {"text": "In this paper, we report on anew exploration of the middle ground, taking advantage of a virtually unutilized resource: speakers of the source and target language who are effectively monolingual, i.e. who each only know one of the two languages relevant for the translation task.", "labels": [], "entities": [{"text": "translation task", "start_pos": 262, "end_pos": 278, "type": "TASK", "confidence": 0.9140042066574097}]}, {"text": "The solution we are proposing has the potential to provide a more cost effective approach to translation in scenarios where machine translation would be considered acceptable to use, if only it were generally of high enough quality.", "labels": [], "entities": [{"text": "translation", "start_pos": 93, "end_pos": 104, "type": "TASK", "confidence": 0.9798378944396973}, {"text": "machine translation", "start_pos": 124, "end_pos": 143, "type": "TASK", "confidence": 0.7434273958206177}]}, {"text": "This would clearly exclude tasks like translation of medical reports, business contracts, or literary works, where the validation of a qualified bilingual translator is absolutely necessary.", "labels": [], "entities": [{"text": "translation of medical reports, business contracts", "start_pos": 38, "end_pos": 88, "type": "TASK", "confidence": 0.8725616931915283}]}, {"text": "However, it does include a great many real-world scenarios, such as following news reports in another country, reading international comments about a product, or generating a decent first draft translation of a Wikipedia page for Wikipedia editors to improve.", "labels": [], "entities": []}, {"text": "The use of monolingual participants in a humanmachine translation process is not entirely new.", "labels": [], "entities": [{"text": "humanmachine translation process", "start_pos": 41, "end_pos": 73, "type": "TASK", "confidence": 0.782117227713267}]}, {"text": "pioneered the exploration of monolingual post-editing within the MT community, an approach extended more recently to provide richer information to the user by and.", "labels": [], "entities": [{"text": "MT community", "start_pos": 65, "end_pos": 77, "type": "TASK", "confidence": 0.8471646904945374}]}, {"text": "There have also been at least two independently developed human-machine translation frameworks that employ an iterative protocol involving monolinguals on both the source and target side.", "labels": [], "entities": [{"text": "human-machine translation", "start_pos": 58, "end_pos": 83, "type": "TASK", "confidence": 0.7291079461574554}]}, {"text": "Morita and Ishida (2009) describe a system in which target and source language speakers perform editing of MT output to improve fluency and adequacy, respectively; they utilize source-side paraphrasing at a course grain level, although their approach is limited to requests to paraphrase the entire sentence when the translation cannot be understood.", "labels": [], "entities": [{"text": "MT output", "start_pos": 107, "end_pos": 116, "type": "TASK", "confidence": 0.8919122517108917}]}, {"text": "describe a similar protocol in which cross-language communication is enhanced by metalinguistic communication in the user interface.", "labels": [], "entities": []}, {"text": "use machine translation as a specific instance of a general game-based framework for combining a range of machine and human capabilities.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.7678272128105164}]}, {"text": "We call the technique used here targeted paraphrasing.", "labels": [], "entities": []}, {"text": "Ina nutshell, target-language monolinguals identify parts of an initial machine translation that don't appear to be right, and source-language monolinguals provide the MT system with alternative phrasings that might lead to better translations; these are then passed through MT again and the best scoring hypothesis is selected as the final translation.", "labels": [], "entities": []}, {"text": "This technique can be viewed as compatible with the richer protocol-and game-based approaches, but it is considerably simpler; in Sections 2 through 4 we describe the method and present evaluation results on Chinese-English translation.", "labels": [], "entities": []}, {"text": "Unlike other approaches, the technique also offers clear opportunities to replace human participation with machine components if the latter are up to the task; we discuss this in Section 5 before wrapping up in Section 6 with conclusions and directions for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "As a followup to our pilot study, we conducted an evaluation using Chinese-English test data taken from the NIST MT'08 machine translation evaluation, in order to obtain fully automatic translation evaluation scores.", "labels": [], "entities": [{"text": "NIST MT'08 machine translation evaluation", "start_pos": 108, "end_pos": 149, "type": "TASK", "confidence": 0.7961369037628174}]}, {"text": "We report on results for 49 sentences of the 1,357 in this data set.", "labels": [], "entities": []}, {"text": "These underwent the same targeted paraphrasing process as in the pilot study, with the addition of a basic step to filter out cheaters: we disregarded as invalid any responses consisting purely of ASCII characters (signifying a non-Chinese response) or responses that were identical to the original source text.", "labels": [], "entities": []}, {"text": "Target English speakers identified 115 potential mistranslation spans, or 2.3 spans per sentence, that yielded at least one source paraphrase on the source Chinese side.", "labels": [], "entities": []}, {"text": "Chinese speakers provided 138 valid paraphrases.", "labels": [], "entities": []}, {"text": "The entire cost for the human tasks in this experiment was $5.06, or a bit under $0.11 per sentence on average.", "labels": [], "entities": []}, {"text": "Table 1 reports on the results, evaluating in standard fashion using BLEU with the four English MT'08 references for each Chinese sentence.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9979345798492432}]}, {"text": "Since the targeted paraphrasing translation process (TP) produces multiple hypotheses -one automatic translation output per sentential paraphrases -we selected the single best output for each sentence by   One could argue that this result is simply a result of having more hypotheses to choose from, not a result of the targeted paraphrasing process itself.", "labels": [], "entities": [{"text": "paraphrasing translation process (TP)", "start_pos": 19, "end_pos": 56, "type": "TASK", "confidence": 0.7196003297964731}]}, {"text": "In order to rule out this possibility, we generated (n + 1)-best Google translations, setting n for each sentence to match the number of alternative translations generated via targeted paraphrasing.", "labels": [], "entities": []}, {"text": "We then chose the best translation for each sentence, among the (n + 1)-best Google hypotheses, via oracle selection, using the TERp metric () to evaluate each hypothesis against the reference translations.", "labels": [], "entities": [{"text": "TERp metric", "start_pos": 128, "end_pos": 139, "type": "METRIC", "confidence": 0.9701806008815765}]}, {"text": "The resulting BLEU score for the full set showed negligible improvement (GT n-best oracle).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 14, "end_pos": 18, "type": "METRIC", "confidence": 0.9990839958190918}]}, {"text": "We did a similar oracle-best calculation using TERp for targeted paraphrasing (TP oracle).", "labels": [], "entities": [{"text": "TERp", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.862415611743927}]}, {"text": "The result shows a potential gain of 2.46 BLEU points over the baseline, if the best scoring alternative from the targeted paraphrasing process were always chosen.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.9995318651199341}]}, {"text": "In addition to aggregate scoring using BLEU, we also looked at oracle results on a per-sentence basis using TERp (since BLEU more appropriate to use at the document level, not the sentence level).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 39, "end_pos": 43, "type": "METRIC", "confidence": 0.9881576895713806}, {"text": "TERp", "start_pos": 108, "end_pos": 112, "type": "METRIC", "confidence": 0.9628298878669739}, {"text": "BLEU", "start_pos": 120, "end_pos": 124, "type": "METRIC", "confidence": 0.9720457196235657}]}, {"text": "Identifying the best sentential paraphrase alternative using TERp as an oracle, we find that the TERp score would improve for 32 of the 49 test sentences, An \"oracle\" telling us which variant is best is not available in the real world, of course, but in situations like this one, oracle studies are often used to establish the magnitude of the potential gain ().", "labels": [], "entities": [{"text": "TERp", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.9980134963989258}]}, {"text": "For those 32 sentences, the average gain is 8.36 TERp points.", "labels": [], "entities": [{"text": "TERp", "start_pos": 49, "end_pos": 53, "type": "METRIC", "confidence": 0.9973053932189941}]}, {"text": "A fairer measure is the average obtained when scoring zero gain for the 17 sentences where no improvement was obtained; taking these into account, i.e. assuming an oracle who chooses the original translation if none of the paraphrase-based alternatives are better, the average improvement over the entire set of 49 sentences is 5.46 TERp points.", "labels": [], "entities": [{"text": "TERp", "start_pos": 333, "end_pos": 337, "type": "METRIC", "confidence": 0.9991232752799988}]}, {"text": "Although we have obtained results on only a small subset of the full NIST MT'08 test set, our automatic evaluation confirms the qualitative impressions in and the subjective ratings results obtained in our pilot study in Section 3.", "labels": [], "entities": [{"text": "NIST MT'08 test set", "start_pos": 69, "end_pos": 88, "type": "DATASET", "confidence": 0.9268158823251724}]}, {"text": "The TP oracle results establish that by taking advantage of monolingual human speakers, it is possible to obtain quite substantial gains in translation quality.", "labels": [], "entities": []}, {"text": "The TP one-best results demonstrate that the majority of that oracle gain is obtained in automatic hypothesis selection, simply by selecting the paraphrase-based alternative translation with the highest translation score.", "labels": [], "entities": []}, {"text": "The last line in shows a human upper bound computed using the reference translations via cross validation; that is, for each of the four reference translations, we evaluate it as a hypothesized translation using the other three references as ground truth; these four scores were then averaged.", "labels": [], "entities": []}, {"text": "The value of this upper bound is quite consistent with the bound computed similarly by.", "labels": [], "entities": []}, {"text": "As we noted in Section 2, the targeted paraphrasing translation process defines a set of human-machine combinations that do not require bilingual expertise.", "labels": [], "entities": [{"text": "paraphrasing translation process", "start_pos": 39, "end_pos": 71, "type": "TASK", "confidence": 0.7385661005973816}]}, {"text": "The previous section described human identification of mistranslated spans on the target side, human generation of paraphrases for problematic sub-sentential spans on the source side, and both automatic hypothesis selection and human selection (via fluency ratings, in Section 3).", "labels": [], "entities": [{"text": "human identification of mistranslated spans", "start_pos": 31, "end_pos": 74, "type": "TASK", "confidence": 0.7832919776439666}]}, {"text": "In this section, we take a step toward more automated processing, replacing human identification of mistranslated spans with an a fully automatic method.", "labels": [], "entities": []}, {"text": "The idea behind our automatic error identification is straightforward: if the source sentence GT: WTO chief negotiator on behalf of the United States to propose substantial reduction of agricultural subsidies, Kai Fa countries substantially reduce industrial products import tariffs to Dapo ??", "labels": [], "entities": [{"text": "automatic error identification", "start_pos": 20, "end_pos": 50, "type": "TASK", "confidence": 0.615585575501124}]}, {"text": "Doha Round of negotiations deadlock.", "labels": [], "entities": []}, {"text": "TP: World Trade Organization negotiator suggested the United States today, a substantial reduction of agricultural subsidies, developing countries substantially reduce industrial products??", "labels": [], "entities": [{"text": "TP", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.6085280179977417}]}, {"text": "Import tariffs, in order to break the deadlock in the Doha Round of trade negotiations.", "labels": [], "entities": []}, {"text": "REF: the main delegates at the world trade organization talks today suggested that the us make major cuts in its agricultural subsidies and that developing countries significantly reduce import duties on industrial products in order to break the deadlock in the doha round of trade talks . GT: Emergency session of the Palestinian prime minister Salam Fayyad state will set anew Government TP: Emergency session of the Palestinian Prime Minister Salam Fayyad will set the new government REF: state of emergency period ends ; palestinian prime minister fayyad to form new government GT: Indian territory from south to north, one week before the start after another wet season, the provincial residents hold long drought every rain in the mood to meet the heavy rain, but did not expect rain came unexpectedly fierce, a rain disaster, roads become rivers, low-lying areas housing to make Mo in the water, transport almost paralyzed, Zhi Jin statistics about You nearly 500 people due to floods were killed.", "labels": [], "entities": [{"text": "REF", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.863791286945343}]}, {"text": "TP: Indian territory from south to north, one week before the start have entered into the rainy season, provincial residents hold long drought to hope rain in the mood to meet the heavy rain, but did not feed rain came unexpectedly fierce, a rain disaster, roads change the river, low-lying areas housing do not water, traffic almost to a standstill, since statistics are nearly 500 people due to floods killed.", "labels": [], "entities": []}, {"text": "REF: the whole of india , from south to north , started to progressively enter the monsoon season a week ago . the residents of each state all greeted the heavy rains as relief at the end of along drought , but didn't expect that the rain would come with unexpected violence , areal deluge . highways have become rivers ; houses in low-lying areas have been surbmerged in the water ; the transport system is nearly paralyzed . to date , figures show that nearly 500 people have unfortunately lost their lives to the floods . GT: But the Taliban said in the meantime, the other a German hostages kidnapped in very poor health, began to fall into a coma and lost consciousness.", "labels": [], "entities": [{"text": "REF", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9279950857162476}]}, {"text": "TP: But the Taliban said in the meantime, another German hostages kidnapped a very weak body fell into a coma and began to lose consciousness.", "labels": [], "entities": [{"text": "TP", "start_pos": 0, "end_pos": 2, "type": "DATASET", "confidence": 0.525562047958374}]}, {"text": "REF: but at the same time the taliban said that another german hostage who had been kidnapped was in extremely poor health , and had started to become comatose and to lose consciousness . GT: Taliban spokesman Ahmadi told AFP in an unknown location telephone interview, said: We, through tribal elders, representatives of direct contact with South Korea.", "labels": [], "entities": [{"text": "REF", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.5987387299537659}]}, {"text": "TP: Taliban spokesman Ahmadi told AFP in an unknown location telephone interview, said: We are through tribal elders, directly with the South Korean leadership, business REF: taliban spokesperson ahmadi said in a telephone interview by afp at an undisclosed location : we have established direct contact with the south korean delegation through tribal elders . is translated to the target and then back-translated, a comparison of the result with the original is likely to identify places where the translation process encountered difficulty.", "labels": [], "entities": [{"text": "AFP", "start_pos": 34, "end_pos": 37, "type": "DATASET", "confidence": 0.95216965675354}]}, {"text": "Briefly, we automatically translate source F to target E, then back-translate to produce F' in the source language.", "labels": [], "entities": []}, {"text": "We compare F and F' using TERp -which, in addition to its use as an evaluation metric, is a form of string-edit distance that identifies various categories of differences between two sentences.", "labels": [], "entities": [{"text": "TERp", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.9934087991714478}]}, {"text": "When at least two consecutive edits are found, we flag their smallest containing syntactic constituent as a potential source of translation difficulty.", "labels": [], "entities": []}, {"text": "In more detail, we posit that if an area of backtranslation F' has many edits relative to original sentence F, then that area probably comes from parts of the target translation that did not represent the desired meaning in F very well.", "labels": [], "entities": []}, {"text": "We only consider consecutive edits in certain of the TERp edit categories, specifically, deletions (D), insertions (I), and shifts (S); the two remaining categories, matches (M) and paraphrases (P), indicate that the words are identical or that the original meaning was preserved.", "labels": [], "entities": []}, {"text": "Furthermore, we assume that while a single D, S, or I edit might be fairly meaningless, a string of at least two of those types of edits is likely to represent a substantive problem in the translation.", "labels": [], "entities": []}, {"text": "In order to identify reasonably meaningful paraphrase units based on potential errors, we rely on a source language constituency parser.", "labels": [], "entities": []}, {"text": "Using the parse, we find the smallest constituent of the sentence containing all of the tokens in a particular error string.", "labels": [], "entities": []}, {"text": "At times, these constituents can be quite large, even the entire sentence.", "labels": [], "entities": []}, {"text": "To weed out these cases, we restrict constituent length to no more than 7 tokens.", "labels": [], "entities": []}, {"text": "For example, given F The most recent probe to visit Jupiter was the Pluto-bound New Horizons spacecraft in late February 2007.", "labels": [], "entities": []}, {"text": "E La investigaci\u00f3n m\u00e1s reciente fue la visita de J\u00fapiter a Plut\u00f3n de la envolvente sonda New Horizons a fines de febrero spans in the the bolded phrase in F would be identified, based on the TERp alignment and smallest containing constituent as shown in.", "labels": [], "entities": [{"text": "TERp alignment", "start_pos": 191, "end_pos": 205, "type": "METRIC", "confidence": 0.9597715139389038}]}, {"text": "In order to evaluate this approach, we again use NIST MT08 data, this time going in the Englishto-Chinese direction since we are assuming source language resources not currently available for Chinese.", "labels": [], "entities": [{"text": "NIST MT08 data", "start_pos": 49, "end_pos": 63, "type": "DATASET", "confidence": 0.8931755224863688}]}, {"text": "We used English reference 0 as the source sentence, and the original Chinese sentence as the target.", "labels": [], "entities": []}, {"text": "The data set comprises 1,357 sentence pairs.", "labels": [], "entities": []}, {"text": "Using the above described algorithm to automatically identify possible problem areas in the translation, with the Google Translate API providing both the translation and back-translation, we generated 1,780 potential error spans in 1,006 of the sentences, and, continuing the targeted paraphrasing process, we obtained up to three source paraphrases per span, for the problemantic spans in 1,000 of those sentences.", "labels": [], "entities": []}, {"text": "(For six sentences, no paraphrases weres suggested for any of the problematic spans.)", "labels": [], "entities": []}, {"text": "These yielded full-sentence paraphrase alternatives for the 1,000 sentences, which we again evaluated via an oracle study.", "labels": [], "entities": []}, {"text": "For this study we used the TER metric) rather than TERp.", "labels": [], "entities": [{"text": "TER metric", "start_pos": 27, "end_pos": 37, "type": "METRIC", "confidence": 0.9812034666538239}, {"text": "TERp", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.986028254032135}]}, {"text": "Comparing with the GT output, we find that TP yields a better-translated paraphrase sentence is available in 313 of the 1000 cases, or 31.3%, and for those 313 cases, TER for the oracle-best paraphrase alternative improves on the TER for the original sentence by 12.16 TER points.", "labels": [], "entities": [{"text": "TP", "start_pos": 43, "end_pos": 45, "type": "METRIC", "confidence": 0.9430267810821533}, {"text": "TER", "start_pos": 167, "end_pos": 170, "type": "METRIC", "confidence": 0.9984616041183472}, {"text": "TER", "start_pos": 230, "end_pos": 233, "type": "METRIC", "confidence": 0.9919590950012207}, {"text": "TER", "start_pos": 269, "end_pos": 272, "type": "METRIC", "confidence": 0.977073073387146}]}, {"text": "Also taking into account the cases where there is no improvement over the baseline, the average TER score improves by 3.8 points.", "labels": [], "entities": [{"text": "TER score", "start_pos": 96, "end_pos": 105, "type": "METRIC", "confidence": 0.9885721206665039}]}, {"text": "The cost for human tasks in this study -just paraphrases, since identifying problematic spans was done automaticallywas $117.48, or a bit under $0.12 per sentence.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on a 49-sentence subset of the NIST  MT'08 Chinese-English test set", "labels": [], "entities": [{"text": "NIST  MT'08 Chinese-English test set", "start_pos": 49, "end_pos": 85, "type": "DATASET", "confidence": 0.9039833188056946}]}]}