{"title": [{"text": "Clustering-based Stratified Seed Sampling for Semi-Supervised Relation Classification", "labels": [], "entities": [{"text": "Stratified Seed Sampling", "start_pos": 17, "end_pos": 41, "type": "TASK", "confidence": 0.5903032720088959}, {"text": "Semi-Supervised Relation Classification", "start_pos": 46, "end_pos": 85, "type": "TASK", "confidence": 0.7880797187487284}]}], "abstractContent": [{"text": "Seed sampling is critical in semi-supervised learning.", "labels": [], "entities": [{"text": "Seed sampling", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8471882939338684}]}, {"text": "This paper proposes a clustering-based stratified seed sampling approach to semi-supervised learning.", "labels": [], "entities": []}, {"text": "First, various clustering algorithms are explored to partition the unlabeled instances into different strata with each stratum represented by a center.", "labels": [], "entities": []}, {"text": "Then, diversity-motivated intra-stratum sampling is adopted to choose the center and additional instances from each stratum to form the unla-beled seed set for an oracle to annotate.", "labels": [], "entities": []}, {"text": "Finally , the labeled seed set is fed into a bootstrapping procedure as the initial labeled data.", "labels": [], "entities": []}, {"text": "We systematically evaluate our stratified bootstrapping approach in the semantic relation classification subtask of the ACE RDC (Relation Detection and Classification) task.", "labels": [], "entities": [{"text": "semantic relation classification", "start_pos": 72, "end_pos": 104, "type": "TASK", "confidence": 0.6426974833011627}, {"text": "ACE RDC (Relation Detection and Classification) task", "start_pos": 120, "end_pos": 172, "type": "TASK", "confidence": 0.7211916744709015}]}, {"text": "In particular, we compare various clustering algorithms on the stratified bootstrapping performance.", "labels": [], "entities": []}, {"text": "Experimental results on the ACE RDC 2004 corpus show that our clustering-based stratified bootstrapping approach achieves the best F1-score of 75.9 on the sub-task of semantic relation classification, approaching the one with golden clustering.", "labels": [], "entities": [{"text": "ACE RDC 2004 corpus", "start_pos": 28, "end_pos": 47, "type": "DATASET", "confidence": 0.970873087644577}, {"text": "F1-score", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9987924098968506}, {"text": "semantic relation classification", "start_pos": 167, "end_pos": 199, "type": "TASK", "confidence": 0.7240477204322815}]}], "introductionContent": [{"text": "Semantic relation extraction aims to detect and classify semantic relationships between a pair of named entities occurring in a natural language text.", "labels": [], "entities": [{"text": "Semantic relation extraction", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7923591136932373}, {"text": "classify semantic relationships between a pair of named entities occurring in a natural language text", "start_pos": 48, "end_pos": 149, "type": "TASK", "confidence": 0.7524492422739665}]}, {"text": "Many machine learning approaches have been proposed to attack this problem, including supervised (;, semisupervised, and unsupervised methods ().", "labels": [], "entities": []}, {"text": "Current work on relation extraction mainly adopts supervised learning methods, since they achieve much better performance.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.9747202396392822}]}, {"text": "However, they normally require a large number of manually labeled relation instances, whose acquisition is both time consuming and labor intensive.", "labels": [], "entities": []}, {"text": "In contrast, unsupervised methods do not need any manually labeled instances.", "labels": [], "entities": []}, {"text": "Nevertheless, it is difficult to assess their performance due to the lack of evaluation criteria.", "labels": [], "entities": []}, {"text": "As something between them, semisupervised learning has received more and more attention recently.", "labels": [], "entities": []}, {"text": "With the plenitude of unlabeled natural language text at hand, semi-supervised learning can significantly reduce the need for labeled data with only limited sacrifice in performance.", "labels": [], "entities": []}, {"text": "For example, proposes a bootstrapping algorithm which chooses the unlabeled instances with the highest probability of being correctly labeled and add them in turn into the labeled training data iteratively.", "labels": [], "entities": []}, {"text": "This paper focuses on bootstrapping-based semisupervised learning in relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 69, "end_pos": 88, "type": "TASK", "confidence": 0.9223354160785675}]}, {"text": "Since the performance of bootstrapping depends much on the quality and quantity of the seed set and researchers tend to employ as few seeds as possible (e.g. 100 instances) to save time and labor, the quality of the seed set plays a critical role in bootstrapping.", "labels": [], "entities": []}, {"text": "Furthermore, the imbalance of different classes and the inherent structural complexity of instances will severely weaken the strength of bootstrapping and semi-supervised learning as well.", "labels": [], "entities": []}, {"text": "Therefore, it is critical fora bootstrapping procedure to select an appropriate seed set, which should be representative and diverse.", "labels": [], "entities": []}, {"text": "However, most of current semisupervised relation extraction systems) use a random seed sampling strategy, which fails to fully exploit the affinity nature in the training data to derive the seed set.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.7194068133831024}]}, {"text": "Alternatively,  bootstrap a set of weighted support vectors from both labeled and unlabeled data using SVM and feed these instances into semi-supervised relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 153, "end_pos": 172, "type": "TASK", "confidence": 0.7433396875858307}]}, {"text": "However, their seed set is sequentially generated only to ensure that there are at least 5 instances for each relation class.", "labels": [], "entities": []}, {"text": "Our previous work  attempts to solve this problem via a simple stratified sampling strategy for selecting the seed set.", "labels": [], "entities": []}, {"text": "Experimentation on the ACE RDC 2004 corpus shows that the stratified sampling strategy achieves promising results for semi-supervised learning.", "labels": [], "entities": [{"text": "ACE RDC 2004 corpus", "start_pos": 23, "end_pos": 42, "type": "DATASET", "confidence": 0.9707924425601959}]}, {"text": "Nevertheless, the success of the strategy relies on the assumption that the true distribution of all relation types is already known, which is impractical for real NLP applications.", "labels": [], "entities": []}, {"text": "This paper presents a clustering-based stratified seed sampling approach for semi-supervised relation extraction, without the assumption on the true distribution of different relation types.", "labels": [], "entities": [{"text": "clustering-based stratified seed sampling", "start_pos": 22, "end_pos": 63, "type": "TASK", "confidence": 0.5735082179307938}, {"text": "semi-supervised relation extraction", "start_pos": 77, "end_pos": 112, "type": "TASK", "confidence": 0.6506149967511495}]}, {"text": "The motivations behind our approach are that the unlabeled data can be partitioned into a number of strata using a clustering algorithm and that representative and diverse seeds can be derived from such strata in the framework of stratified sampling for an oracle to annotate.", "labels": [], "entities": []}, {"text": "Particularly, we employ a diversity-motivated intra-stratum sampling scheme to pick a center and additional instances as seeds from each stratum.", "labels": [], "entities": []}, {"text": "Experimental results show the effectiveness of the clusteringbased stratified seed sampling for semi-supervised relation classification.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 112, "end_pos": 135, "type": "TASK", "confidence": 0.6821411848068237}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "First an overview of the related work is given in Section 2.", "labels": [], "entities": []}, {"text": "Then, Section 3 introduces the stratified bootstrapping framework including an intrastratum sampling scheme while Section 4 describes various clustering algorithms.", "labels": [], "entities": []}, {"text": "The experimental results on the ACE RDC 2004 corpus are reported in Section 5.", "labels": [], "entities": [{"text": "ACE RDC 2004 corpus", "start_pos": 32, "end_pos": 51, "type": "DATASET", "confidence": 0.969128355383873}]}, {"text": "Finally we conclude our work and indicate some future directions in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section systematically evaluates the bootstrapping approach using clustering-based stratified seed sampling, in the relation classification (i.e., given the relationship already detected) subtask of relation extraction on the ACE RDC 2004 corpus.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 204, "end_pos": 223, "type": "TASK", "confidence": 0.724474623799324}, {"text": "ACE RDC 2004 corpus", "start_pos": 231, "end_pos": 250, "type": "DATASET", "confidence": 0.9686678349971771}]}, {"text": "The ACE RDC 2004 corpus 3 is gathered from various newspapers, newswire and broadcasts.", "labels": [], "entities": [{"text": "ACE RDC 2004 corpus 3", "start_pos": 4, "end_pos": 25, "type": "DATASET", "confidence": 0.9549129486083985}]}, {"text": "It contains 451 documents and 5702 positive relation instances of 7 relation types and 23 subtypes between 7 entity types.", "labels": [], "entities": []}, {"text": "For easy reference with related work in the literature, evaluation is done on 347 documents (from nwire and bnews domains), which include 4305 relation instances.: Relation types and their corresponding instance numbers and ratios in the ACE RDC 2004 corpus 10% of them (35 files, around 400 instances) held out as the test data set, 10% of them (35 files, around 400 instances) used as the development data set to fine-tune various settings and parameters, while the remaining 277 files (over 3400 instances) used as the training data set, from which the seed set will be sampled.", "labels": [], "entities": [{"text": "ACE RDC 2004 corpus", "start_pos": 238, "end_pos": 257, "type": "DATASET", "confidence": 0.9658114612102509}]}, {"text": "The corpus is parsed using Charniak's parser) and relation instances are generated by extracting all pairs of entity mentions occurring in the same sentence with positive relationships.", "labels": [], "entities": []}, {"text": "For easy comparison with related work, we only evaluate the relation classification task on the 7 major relation types of the ACE RDC 2004 corpus.", "labels": [], "entities": [{"text": "relation classification", "start_pos": 60, "end_pos": 83, "type": "TASK", "confidence": 0.9045277535915375}, {"text": "ACE RDC 2004 corpus", "start_pos": 126, "end_pos": 145, "type": "DATASET", "confidence": 0.9581794887781143}]}, {"text": "For the SVM light -TK classifier, the training parameters C (SVM) and \u03bb (tree kernel) are fine-tuned to 2.4 and 0.4 respectively.", "labels": [], "entities": [{"text": "SVM light -TK classifier", "start_pos": 8, "end_pos": 32, "type": "TASK", "confidence": 0.717973816394806}]}, {"text": "The performance is measured using the standard P/R/F1 (Precision/Recall/F1-measure).", "labels": [], "entities": [{"text": "P/R/F1 (Precision/Recall/F1-measure)", "start_pos": 47, "end_pos": 83, "type": "METRIC", "confidence": 0.7664903601010641}]}, {"text": "For each relation type, P is the ratio of the true relation instances in all the relation instances being identified, R is the ratio of the true relation instances being identified in all the true relation instances in the corpus, and F1 is the harmonic mean of P and R.", "labels": [], "entities": [{"text": "F1", "start_pos": 235, "end_pos": 237, "type": "METRIC", "confidence": 0.9983294606208801}]}, {"text": "The overall performance P/R/F1 is then calculated using the micro-average measure overall major class types.", "labels": [], "entities": [{"text": "P/R", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.795648197333018}, {"text": "F1", "start_pos": 28, "end_pos": 30, "type": "METRIC", "confidence": 0.5413097143173218}]}, {"text": "compares the performance of bootstrapping-based relation classification using various seed sampling strategies without intra-stratum sampling on the development data.", "labels": [], "entities": [{"text": "bootstrapping-based relation classification", "start_pos": 28, "end_pos": 71, "type": "TASK", "confidence": 0.7123137513796488}]}, {"text": "Here, the size of the seed set L is set to 100, and the top 100 instances with the highest confidence (c.f. Formula 1) are augmented at each iteration.", "labels": [], "entities": []}, {"text": "For sampling strategies marked with an asterisk, we performed 10 trials and calculated their averages.", "labels": [], "entities": []}, {"text": "Since for these strategies the seed sets sampled from different trials maybe quite different, their performance scores vary in a great degree accordingly.", "labels": [], "entities": []}, {"text": "This experimental setting and notation are also used in all the subsequent experiments unless specified.", "labels": [], "entities": []}, {"text": "Besides, two additional baseline sampling strategies are included for comparison: sequential sampling (SEQ), which selects a sequentially-occurring L instances as the seed set, and random sampling (RAND), which randomly selects L instances as the seed set.", "labels": [], "entities": []}, {"text": "shows that 1) RAND outperforms SEQ by 1.2 units in F1-score.", "labels": [], "entities": [{"text": "RAND", "start_pos": 14, "end_pos": 18, "type": "METRIC", "confidence": 0.9350616335868835}, {"text": "SEQ", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.8794191479682922}, {"text": "F1-score", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9987785220146179}]}, {"text": "This is due to the fact that the seed set via RAND may better reflect the distribution of the whole training data than that via SEQ, nevertheless at the expense of collecting the whole training data in advance.", "labels": [], "entities": [{"text": "RAND", "start_pos": 46, "end_pos": 50, "type": "DATASET", "confidence": 0.757444441318512}]}, {"text": "2) While HAC performs moderately better than RAND, it is surprising that both KM and AP perform even worse than SEQ, and that SC performs worse than RAND.", "labels": [], "entities": []}, {"text": "Furthermore, all the four clustering-based seed sampling strategies achieve much smaller performance improvement in F1-score than RAND, among which KM performs worst with performance improvement of only 0.1 in F1-score.: Comparison of various seed sampling strategies without intra-stratum sampling on the development data 3) All the performance improvements from bootstrapping largely come from the improvements in precision.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9983739852905273}, {"text": "F1-score.", "start_pos": 210, "end_pos": 219, "type": "METRIC", "confidence": 0.9885588884353638}, {"text": "precision", "start_pos": 416, "end_pos": 425, "type": "METRIC", "confidence": 0.9990605711936951}]}, {"text": "While the bootstrapping procedure makes the SVM classifier more accurate, it lacks enough generalization ability.", "labels": [], "entities": [{"text": "SVM classifier", "start_pos": 44, "end_pos": 58, "type": "TASK", "confidence": 0.7658971548080444}]}], "tableCaptions": [{"text": " Table 1: Relation types and their corresponding instance  numbers and ratios in the ACE RDC 2004 corpus", "labels": [], "entities": [{"text": "ACE RDC 2004 corpus", "start_pos": 85, "end_pos": 104, "type": "DATASET", "confidence": 0.9724421203136444}]}, {"text": " Table 3: Performance in F1-score over different cluster  numbers with intra-stratum sampling on the develop- ment data", "labels": [], "entities": [{"text": "F1-score", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.99481201171875}]}]}