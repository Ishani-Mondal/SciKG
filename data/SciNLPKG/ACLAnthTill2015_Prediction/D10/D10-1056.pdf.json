{"title": [{"text": "Two Decades of Unsupervised POS induction: How far have we come?", "labels": [], "entities": [{"text": "POS induction", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.9235480427742004}]}], "abstractContent": [{"text": "Part-of-speech (POS) induction is one of the most popular tasks in research on unsuper-vised NLP.", "labels": [], "entities": [{"text": "Part-of-speech (POS) induction", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.6123080432415009}]}, {"text": "Many different methods have been proposed, yet comparisons are difficult to make since there is little consensus on evaluation framework, and many papers evaluate against only one or two competitor systems.", "labels": [], "entities": []}, {"text": "Here we evaluate seven different POS induction systems spanning nearly 20 years of work, using a variety of measures.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 33, "end_pos": 46, "type": "TASK", "confidence": 0.8776886761188507}]}, {"text": "We show that some of the oldest (and simplest) systems stand up surprisingly well against more recent approaches.", "labels": [], "entities": []}, {"text": "Since most of these systems were developed and tested using data from the WSJ corpus, we compare their generalization abilities by testing on both WSJ and the multilingual Multext-East corpus.", "labels": [], "entities": [{"text": "WSJ corpus", "start_pos": 74, "end_pos": 84, "type": "DATASET", "confidence": 0.9719191789627075}, {"text": "WSJ", "start_pos": 147, "end_pos": 150, "type": "DATASET", "confidence": 0.9679800271987915}, {"text": "Multext-East corpus", "start_pos": 172, "end_pos": 191, "type": "DATASET", "confidence": 0.9528439939022064}]}, {"text": "Finally, we introduce the idea of evaluating systems based on their ability to produce cluster prototypes that are useful as input to a prototype-driven learner.", "labels": [], "entities": []}, {"text": "In most cases, the prototype-driven learner outperforms the unsupervised system used to initialize it, yielding state-of-the-art results on WSJ and improvements on non-English corpora.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 140, "end_pos": 143, "type": "DATASET", "confidence": 0.6745681762695312}]}], "introductionContent": [{"text": "In recent years, unsupervised learning has become a hot area in NLP, in large part due to the use of sophisticated machine learning approaches which promise to deliver better results than more traditional methods.", "labels": [], "entities": []}, {"text": "Often the new approaches are tested using part-of-speech (POS) tagging as an example application, and usually they are shown to perform better than one or another comparison system.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging", "start_pos": 42, "end_pos": 70, "type": "TASK", "confidence": 0.6453625202178955}]}, {"text": "However, it is difficult to draw overall conclusions about the relative performance of unsupervised POS tagging systems because of differences in evaluation measures, and the fact that no paper includes direct comparisons against more than a few other systems.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 100, "end_pos": 111, "type": "TASK", "confidence": 0.8031898736953735}]}, {"text": "In this paper, we attempt to remedy that situation by providing a comprehensive evaluation of seven different POS induction systems spanning nearly 20 years of research.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 110, "end_pos": 123, "type": "TASK", "confidence": 0.8583426773548126}]}, {"text": "We focus specifically on POS induction systems, where no prior knowledge is available, in contrast to POS disambiguation systems), which use a dictionary to provide possible tags for some or all of the words in the corpus, or prototype-driven systems (), which use a small set of prototypes for each tag class, but no dictionary.", "labels": [], "entities": []}, {"text": "Our motivation stems from another part of our own research, in which we are trying to use NLP systems on over 50 low-density languages (some of them dead) where both tagged corpora and language speakers are mostly unavailable.", "labels": [], "entities": []}, {"text": "We therefore desire to use these systems straight out of the box and to know how well we can expect them to work.", "labels": [], "entities": []}, {"text": "One difficulty in evaluating POS induction systems is that there is no straightforward way to map the clusters found by the algorithm onto the gold standard tags; moreover, some systems are designed to induce the number of clusters as well as their contents, so the number of found clusters may not match either the gold standard or that of another system.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 29, "end_pos": 42, "type": "TASK", "confidence": 0.8700111508369446}]}, {"text": "Nevertheless, most recent papers have used mapping-based performance measures (either oneto-one or many-to-one accuracy).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9801378846168518}]}, {"text": "Here, we argue that the entropy-based V-Measure () is more useful in many cases, being more stable across different numbers of found and true clusters, and avoiding several of the problems with another commonly used entropy-based measure, Variation of Information.", "labels": [], "entities": []}, {"text": "Using V-Measure along with several other evaluation measures, we compare the performance of the different induction systems on both WSJ (the data on which most systems were developed and tested) and Multext East, a corpus of parallel texts in eight different languages.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 132, "end_pos": 135, "type": "DATASET", "confidence": 0.9378687143325806}, {"text": "Multext East, a corpus of parallel texts", "start_pos": 199, "end_pos": 239, "type": "DATASET", "confidence": 0.9424498379230499}]}, {"text": "We find that for virtually all measures and datasets, older systems using relatively simple models and algorithms work as well or better than systems using newer and often far more sophisticated and time-consuming machine learning methods).", "labels": [], "entities": []}, {"text": "Thus, although these newer methods have introduced potentially useful machine learning techniques, they should not be assumed to provide the best performance for unsupervised POS induction.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 175, "end_pos": 188, "type": "TASK", "confidence": 0.9034822285175323}]}, {"text": "In addition to our review and comparison, we introduce anew way to both evaluate and potentially improve a POS induction system.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 107, "end_pos": 120, "type": "TASK", "confidence": 0.7607220113277435}]}, {"text": "Our method is based on the prototype-driven learning system of, which achieves very good performance by using a hand-selected list of prototypes for each syntactic cluster.", "labels": [], "entities": []}, {"text": "We instead use the existing POS induction systems to induce prototypes automatically, and evaluate the systems based on the quality of their prototypes.", "labels": [], "entities": []}, {"text": "We find that the oldest system tested () produces the best prototypes, and that using these prototypes as input to Haghighi and Klein's system yields stateof-the-art performance on WSJ and improvements on seven of the eight non-English corpora.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 181, "end_pos": 184, "type": "DATASET", "confidence": 0.8019121885299683}]}], "datasetContent": [{"text": "One difficulty in comparing POS induction methods is in finding an appropriate evaluation measure.", "labels": [], "entities": [{"text": "POS induction", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.9164203703403473}]}, {"text": "Many different measures have been proposed over the years, but there is still no consensus on which is best.", "labels": [], "entities": []}, {"text": "In addition, some measures with supposed theoretical advantages, such as Variation of Information (VI)) have had little empirical analysis.", "labels": [], "entities": [{"text": "Variation of Information (VI", "start_pos": 73, "end_pos": 101, "type": "TASK", "confidence": 0.6086485743522644}]}, {"text": "Our goal in this section is to determine which of these measures is most sensible for evaluating the systems presented above.", "labels": [], "entities": []}, {"text": "We first describe each measure before presenting empirical results.", "labels": [], "entities": []}, {"text": "Except for VI, all measures range from 0 to 1, with higher scores indicating better performance.", "labels": [], "entities": [{"text": "VI", "start_pos": 11, "end_pos": 13, "type": "METRIC", "confidence": 0.9803465604782104}]}, {"text": "[many-to-1]: Many-to-one mapping accuracy (also known as cluster purity) maps each cluster to the gold standard tag that is most common for the words in that cluster (henceforth, the preferred tag), and then computes the proportion of words tagged correctly.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9814737439155579}]}, {"text": "More than one cluster maybe mapped to the same gold standard tag.", "labels": [], "entities": []}, {"text": "This is the most commonly used metric across the literature as it is intuitive and creates a meaningful POS sequence out of the cluster identifiers.", "labels": [], "entities": []}, {"text": "However, it tends to yield higher scores as |C| increases, making comparisons difficult when |C| can vary.", "labels": [], "entities": []}, {"text": "[crossval]: Cross-validation accuracy () is intended to address the problem with many-to-one accuracy which is that assigning each word to its own class yields a perfect score.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9387451410293579}, {"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.8998604416847229}]}, {"text": "In this measure, the first half of the corpus is used to obtain the many-to-one mapping of clusters to tags, and this mapping is used to compute the accuracy of the clustering on the second half of the corpus.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 149, "end_pos": 157, "type": "METRIC", "confidence": 0.9991894364356995}]}, {"text": "[1-to-1]: One-to-one mapping accuracy () constrains the mapping from clusters to tags, so that at most one cluster can be mapped to any tag.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9786179065704346}]}, {"text": "The mapping is performed greedily.", "labels": [], "entities": []}, {"text": "In general, as the number of clusters increases, fewer clusters will be mapped to their preferred tag and scores will decrease (especially if the number of clusters is larger than the number of tags, so that some clusters are unassigned and receive zero credit).", "labels": [], "entities": []}, {"text": "Again, this makes it difficult to compare solutions with different values of |C|.", "labels": [], "entities": []}, {"text": "[vi]: Variation of Information) is an information-theoretic measure that regards the system output C and the gold standard tags T as two separate clusterings, and evaluates the amount of information lost in going from C to T and the amount of information gained, i.e., the sum of the conditional entropy of each clustering conditioned on the other.", "labels": [], "entities": []}, {"text": "More formally, is the entropy function and I(.) is the mutual information.", "labels": [], "entities": [{"text": "I", "start_pos": 43, "end_pos": 44, "type": "METRIC", "confidence": 0.9837132692337036}]}, {"text": "VI and other entropy-based measures have been argued to be superior to accuracy-based measures such as those above, because they consider not only the majority tag in each cluster, but also whether the remainder of the cluster is more or less homogeneous.", "labels": [], "entities": [{"text": "VI", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.8714585900306702}, {"text": "accuracy-based", "start_pos": 71, "end_pos": 85, "type": "METRIC", "confidence": 0.9948441982269287}]}, {"text": "Unlike the other measures we consider, lower scores are better (since VI measures the difference between clusterings in bits).", "labels": [], "entities": [{"text": "VI", "start_pos": 70, "end_pos": 72, "type": "METRIC", "confidence": 0.9497847557067871}]}, {"text": "[vm]: V-Measure () is another entropy-based measure that is designed to be analogous to F-measure, in that it is defined as the weighted harmonic mean of two values, homogeneity (h, the precision analogue) and completeness (c, the recall analogue): As with F-measure, \u03b2 is normally set to 1.", "labels": [], "entities": [{"text": "precision", "start_pos": 186, "end_pos": 195, "type": "METRIC", "confidence": 0.9877718687057495}, {"text": "recall", "start_pos": 231, "end_pos": 237, "type": "METRIC", "confidence": 0.981590211391449}]}, {"text": "[vmb]: V-beta is an extension to V-Measure, proposed by ).", "labels": [], "entities": []}, {"text": "They noted that V-Measure favors clusterings where the number of clusters |C| is larger than the number of POS tags |T |.", "labels": [], "entities": []}, {"text": "To address this issue the parameter \u03b2 in equation 3 is set to |C|/|T | in order adjust the balance between homogeneity and completeness.", "labels": [], "entities": []}, {"text": "[s-fscore]: Substitutable F-score (.", "labels": [], "entities": [{"text": "F-score", "start_pos": 26, "end_pos": 33, "type": "METRIC", "confidence": 0.8874045610427856}]}, {"text": "One potential issue with all of the above measures is that they require a gold standard tagging to compute.", "labels": [], "entities": []}, {"text": "This is normally available during development of a system, but if the system is deployed on a novel language a gold standard may not be available.", "labels": [], "entities": []}, {"text": "In addition, there is the question of whether the gold standard itself is \"correct\".", "labels": [], "entities": [{"text": "gold standard", "start_pos": 50, "end_pos": 63, "type": "DATASET", "confidence": 0.8841289281845093}]}, {"text": "Recently, proposed this novel evaluation measure that requires no gold standard, instead using the concept of substitutability to evaluate performance.", "labels": [], "entities": []}, {"text": "Instead of comparing the system's clusters C to gold standard clusters T , they are compared to a set of clusters S created from substitutable frames, i.e., clusters of words that occur in the same syntactic environment.", "labels": [], "entities": []}, {"text": "Ideally a substitutable frame would be created by sentences differing in only one word (e.g. \"I want the blue ball.\" and \"I want the red ball.\") and the resulting cluster would contain the words that change (e.g.).", "labels": [], "entities": []}, {"text": "However since it is almost impossible to find these types of sentences in real-world corpora, the authors use frames created by two words appearing in the corpus with exactly one word between (e.g. the --ball).", "labels": [], "entities": []}, {"text": "Once the substitutable clusters have been created, they can be used to calculate the Precision (SP ), Recall (SR) and F-score (SF ) of the system's clustering:", "labels": [], "entities": [{"text": "Precision (SP )", "start_pos": 85, "end_pos": 100, "type": "METRIC", "confidence": 0.9315782785415649}, {"text": "Recall (SR)", "start_pos": 102, "end_pos": 113, "type": "METRIC", "confidence": 0.9534088522195816}, {"text": "F-score (SF )", "start_pos": 118, "end_pos": 131, "type": "METRIC", "confidence": 0.9498153775930405}]}], "tableCaptions": [{"text": " Table 1: Baseline scores for the different evaluation mea- sures on the WSJ corpus. For all measures except VI  higher is better.", "labels": [], "entities": [{"text": "Baseline", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.973950207233429}, {"text": "WSJ corpus", "start_pos": 73, "end_pos": 83, "type": "DATASET", "confidence": 0.9674422740936279}]}, {"text": " Table 3: Scores on WSJ for our prototype-based POS in- duction system, with prototypes extracted from each of  the existing systems [|C|:45,|T |:45]. Numbers in paren- theses are the improvement over the same system without  using the prototype step. Scores in bold indicate the best  performance (improvement) in each column. h&k uses  gold standard prototypes.", "labels": [], "entities": [{"text": "WSJ", "start_pos": 20, "end_pos": 23, "type": "DATASET", "confidence": 0.9333397746086121}]}]}