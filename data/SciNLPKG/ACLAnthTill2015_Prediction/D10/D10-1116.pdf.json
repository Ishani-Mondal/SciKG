{"title": [{"text": "Practical Linguistic Steganography using Contextual Synonym Substitution and Vertex Colour Coding", "labels": [], "entities": [{"text": "Vertex Colour Coding", "start_pos": 77, "end_pos": 97, "type": "TASK", "confidence": 0.5871574282646179}]}], "abstractContent": [{"text": "Linguistic Steganography is concerned with hiding information in natural language text.", "labels": [], "entities": []}, {"text": "One of the major transformations used in Linguistic Steganography is synonym substitution.", "labels": [], "entities": [{"text": "synonym substitution", "start_pos": 69, "end_pos": 89, "type": "TASK", "confidence": 0.9206685721874237}]}, {"text": "However, few existing studies have studied the practical application of this approach.", "labels": [], "entities": []}, {"text": "In this paper we propose two improvements to the use of synonym substitution for encoding hidden bits of information.", "labels": [], "entities": [{"text": "synonym substitution", "start_pos": 56, "end_pos": 76, "type": "TASK", "confidence": 0.8176257908344269}]}, {"text": "First, we use the Web 1T Google n-gram corpus for checking the applicability of a synonym in context, and we evaluate this method using data from the SemEval lexical substitution task.", "labels": [], "entities": [{"text": "Web 1T Google n-gram corpus", "start_pos": 18, "end_pos": 45, "type": "DATASET", "confidence": 0.789981997013092}, {"text": "SemEval lexical substitution task", "start_pos": 150, "end_pos": 183, "type": "TASK", "confidence": 0.8272116035223007}]}, {"text": "Second, we address the problem that arises from words with more than one sense, which creates a potential ambiguity in terms of which bits are encoded by a particular word.", "labels": [], "entities": []}, {"text": "We develop a novel method in which words are the vertices in a graph, synonyms are linked by edges, and the bits assigned to a word are determined by a vertex colouring algorithm.", "labels": [], "entities": []}, {"text": "This method ensures that each word encodes a unique sequence of bits, without cutting out large number of synonyms, and thus maintaining a reasonable embedding capacity.", "labels": [], "entities": []}], "introductionContent": [{"text": "Steganography is concerned with hiding information in a cover medium, in order to facilitate covert communication, such that the presence of the information is imperceptible to a user (human or computer).", "labels": [], "entities": []}, {"text": "Much of the existing research in steganography has used images as cover media; however, given the ubiquitous nature of electronic text, interest is growing in using natural language as the cover medium.", "labels": [], "entities": []}, {"text": "Linguistic Steganography-lying at the intersection of Computational Linguistics and Computer Security-is concerned with making changes to a cover text in order to embed information, in such away that the changes do not result in ungrammatical or unnatural text.", "labels": [], "entities": []}, {"text": "A related area is natural language watermarking, in which changes are made to a text in order to identify it, for example for copyright purposes.", "labels": [], "entities": []}, {"text": "An interesting watermarking application is \"traitor tracing\", in which documents are changed in order to embed individual watermarks.", "labels": [], "entities": [{"text": "traitor tracing\"", "start_pos": 44, "end_pos": 60, "type": "TASK", "confidence": 0.8840811053911845}]}, {"text": "These marks can then be used to later identify particular documents, for example if a set of documents-identical except for the changes used to embed the watermarks-have been sent to a group of individuals, and one of the documents has been leaked to a newspaper.", "labels": [], "entities": []}, {"text": "In terms of security, a linguistic stegosystem should impose minimum embedding distortion to the cover text so that the resulting stegotext in which a message is camouflaged is inconspicuous, resulting in high imperceptibility.", "labels": [], "entities": []}, {"text": "In addition, since steganography aims at covert communication, a linguistic stegosystem should allow sufficient embedding capacity, known as the payload.", "labels": [], "entities": []}, {"text": "There is a fundamental tradeoff between imperceptibility and payload, since any attempt to embed more information via changes to the cover text increases the chance of introducing anomalies into the text and therefore raising the suspicion of an observer.", "labels": [], "entities": []}, {"text": "A linguistic transformation is required to embed information.", "labels": [], "entities": []}, {"text": "Transformations studied in previous work include lexical substitution), phrase paraphrasing (, sentence structure manipulations (;) and semantic transformations).", "labels": [], "entities": [{"text": "phrase paraphrasing", "start_pos": 72, "end_pos": 91, "type": "TASK", "confidence": 0.8044019043445587}, {"text": "sentence structure manipulations", "start_pos": 95, "end_pos": 127, "type": "TASK", "confidence": 0.6684004366397858}]}, {"text": "Many of these transformations require some sophisticated NLP tools; for example, in order to perform semantic transformations on text, word sense disambiguation, semantic role parsing and anaphora resolution tools maybe required.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 135, "end_pos": 160, "type": "TASK", "confidence": 0.6596768200397491}, {"text": "semantic role parsing", "start_pos": 162, "end_pos": 183, "type": "TASK", "confidence": 0.6722530126571655}, {"text": "anaphora resolution", "start_pos": 188, "end_pos": 207, "type": "TASK", "confidence": 0.7459692656993866}]}, {"text": "However, the current state-of-the-art in language technology is arguably not good enough for secure linguistic steganography based on sophisticated semantic transformations, and the level of robustness required to perform practical experiments has only just become available.", "labels": [], "entities": []}, {"text": "Hence many existing linguistic stegosystems are proof-of-concept implementations with little practical evaluation of the imperceptibility or payload.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to evaluate the proposed synonym checking method, we need some data to test whether our method can pick out acceptable substitutions.", "labels": [], "entities": [{"text": "synonym checking", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.9823267459869385}]}, {"text": "The English Lexical Substitution task for SemEval-2007 has created human-annotated data for developing systems that can automatically find feasible substitutes given a target word in context.", "labels": [], "entities": [{"text": "English Lexical Substitution task", "start_pos": 4, "end_pos": 37, "type": "TASK", "confidence": 0.7083298340439796}]}, {"text": "This data comprises 2010 sentences selected from the English Internet Corpus 3 , and consists of 201 words: nouns, verbs, adjectives and adverbs each with ten sentences containing that word.", "labels": [], "entities": [{"text": "English Internet Corpus 3", "start_pos": 53, "end_pos": 78, "type": "DATASET", "confidence": 0.9282894134521484}]}, {"text": "The five annotators were asked to provide up to three substitutes fora target word in the context of a sentence, and were permitted to consult a dictionary or thesaurus of their choosing.", "labels": [], "entities": []}, {"text": "We use the sentences in this gold standard as the cover text in our experiments so that the substitutes provided by the annotators can be the positive data for evaluating the proposed synonym check-  ing methods.", "labels": [], "entities": [{"text": "synonym check-  ing", "start_pos": 184, "end_pos": 203, "type": "TASK", "confidence": 0.6810798943042755}]}, {"text": "Since we only take into consideration the single word substitutions for the reason described earlier, multi-word substitutes are removed from the positive data.", "labels": [], "entities": []}, {"text": "Moreover, we use WordNet as the source of providing candidate substitutes in our stegosystem, so if a human-provided substitute does not appear in any synsets of its target word in WordNet, there is no chance for our system to replace the target word with the substitute and therefore, the substitute can be eliminated.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 17, "end_pos": 24, "type": "DATASET", "confidence": 0.9586432576179504}, {"text": "WordNet", "start_pos": 181, "end_pos": 188, "type": "DATASET", "confidence": 0.9571735858917236}]}, {"text": "presents the statistics of the positive data for our experiments.", "labels": [], "entities": []}, {"text": "Apart from positive data, we also need some negative data to test whether our method has the ability to filter out bad substitutions.", "labels": [], "entities": []}, {"text": "Since the annotators were allowed to refer to a dictionary or thesaurus, we assume that annotators used WordNet as one of the reference resources while generating candidates.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 104, "end_pos": 111, "type": "DATASET", "confidence": 0.9525822401046753}]}, {"text": "Hence we assume that, if a word in the correct synset fora target word is not in the set produced by the human annotators, then it is inappropriate for that context and a suitable negative example.", "labels": [], "entities": []}, {"text": "This method is appropriate because our steganography system has to distinguish between good and bad synonyms from WordNet, given a particular context.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 114, "end_pos": 121, "type": "DATASET", "confidence": 0.9425179958343506}]}, {"text": "For the above reasons, we extract the negative data for our experiments by first matching positive substitutes of a target word to all the synsets that contain the target word in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 179, "end_pos": 186, "type": "DATASET", "confidence": 0.9793261289596558}]}, {"text": "The synset that includes the most positive substitutes is used to represent the meaning of the target word.", "labels": [], "entities": []}, {"text": "If there is more than one synset containing the highest number of positives, all the synsets are taken into consideration.", "labels": [], "entities": []}, {"text": "We then randomly select up to six single-word synonyms other than positive substitutes from the chosen synset(s) as negative instances of the target word.", "labels": [], "entities": []}, {"text": "shows an example of automatically collected negative data from WordNet given a target word and its positive substitutes.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 63, "end_pos": 70, "type": "DATASET", "confidence": 0.8968530297279358}]}, {"text": "The synset {'remainder', 'balance', 'residual', 'residue',  'residuum', 'rest'} is selected for negative data collection since it contains one of the positives while the other synsets do not.", "labels": [], "entities": []}, {"text": "We assume the selected synset represents the meaning of the original word, and those synonyms in the synset which are not annotated as positives must have a certain degree of mismatch to the context.", "labels": [], "entities": []}, {"text": "Therefore, from this example, 'balance', 'residue', 'residuum' and 'rest' are extracted as negatives to test whether our synonym checking method can pick out bad substitutions from a set of words sharing similar or the same meaning.", "labels": [], "entities": [{"text": "residuum", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9604854583740234}]}, {"text": "In order to examine whether the automatically collected instances are true negatives and hence form a useful test set, a sample of automatically generated negatives was selected for human evaluation.", "labels": [], "entities": []}, {"text": "For each PoS one sentence of each different target word is selected, which results in roughly 13% of the collected negative data, and every negative substitute of the selected sentences was judged by the second author.", "labels": [], "entities": []}, {"text": "As can be seen from the annotation results shown in, most of the instances are true negatives, and only a few cases are incorrectly chosen as false negatives.", "labels": [], "entities": []}, {"text": "Since the main purpose of the data set is to test whether the proposed synonym checking method can guard against inappropriate synonym substitutions and be integrated in the stegosystem, it is reasonable to have a few false negatives in our experimental data.", "labels": [], "entities": [{"text": "synonym checking", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.9347764849662781}]}, {"text": "Also, it is more harmless to rule out a permissible substitu-: Performance of the synonym checking method tion than including an inappropriate replacement fora stegosystem in terms of the security.", "labels": [], "entities": []}, {"text": "gives the statistics of the automatically collected negative data for our experiments.", "labels": [], "entities": []}, {"text": "Note that, although we use the data from the lexical substitution task, our task is different: the possible substitutions fora target word need to be fixed in advance for linguistic steganography (in order for the receiver to be able to recover the hidden bits), whereas for the lexical substitution task participants were asked to discover possible replacements.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics of synsets used in our stegosystem", "labels": [], "entities": []}, {"text": " Table 2: Statistics of experimental data", "labels": [], "entities": []}, {"text": " Table 3: Annotation results for negative data", "labels": [], "entities": [{"text": "Annotation", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.7053964138031006}]}, {"text": " Table 4: Performance of the synonym checking method", "labels": [], "entities": [{"text": "synonym checking", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.9858001470565796}]}]}