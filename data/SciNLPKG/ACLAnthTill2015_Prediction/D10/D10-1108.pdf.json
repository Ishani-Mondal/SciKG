{"title": [{"text": "A Semi-Supervised Method to Learn and Construct Taxonomies using the Web", "labels": [], "entities": []}], "abstractContent": [{"text": "Although many algorithms have been developed to harvest lexical resources, few organize the mined terms into taxonomies.", "labels": [], "entities": []}, {"text": "We propose (1) a semi-supervised algorithm that uses a root concept, a basic level concept, and re-cursive surface patterns to learn automatically from the Web hyponym-hypernym pairs subordinated to the root; (2) a Web based concept positioning procedure to validate the learned pairs' is-a relations; and (3) a graph algorithm that derives from scratch the integrated tax-onomy structure of all the terms.", "labels": [], "entities": []}, {"text": "Comparing results with WordNet, we find that the algorithm misses some concepts and links, but also that it discovers many additional ones lacking in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 23, "end_pos": 30, "type": "DATASET", "confidence": 0.9587054252624512}, {"text": "WordNet", "start_pos": 150, "end_pos": 157, "type": "DATASET", "confidence": 0.9618798494338989}]}, {"text": "We evaluate the taxonomization power of our method on reconstructing parts of the WordNet taxonomy.", "labels": [], "entities": [{"text": "WordNet taxonomy", "start_pos": 82, "end_pos": 98, "type": "DATASET", "confidence": 0.9586792886257172}]}, {"text": "Experiments show that starting from scratch, the algorithm can reconstruct 62% of the WordNet taxonomy for the regions tested.", "labels": [], "entities": [{"text": "WordNet taxonomy", "start_pos": 86, "end_pos": 102, "type": "DATASET", "confidence": 0.9410487711429596}]}], "introductionContent": [{"text": "A variety of NLP tasks, including inference, textual entailment (, and question answering (), rely on semantic knowledge derived from term taxonomies and thesauri such as WordNet.", "labels": [], "entities": [{"text": "textual entailment", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.6790382564067841}, {"text": "question answering", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.7873401045799255}, {"text": "WordNet", "start_pos": 171, "end_pos": 178, "type": "DATASET", "confidence": 0.9592089056968689}]}, {"text": "However, the coverage of WordNet is still limited in many regions (even well-studied ones such as the concepts and instances below Animals and People), as noted by researchers such as ( ) and () who perform automated semantic class learning.", "labels": [], "entities": []}, {"text": "This happens because WordNet and most other existing taxonomies are manually created, which makes them difficult to maintain in rapidly changing domains, and (in the face of taxonomic complexity) makes them hard to build with consistency.", "labels": [], "entities": []}, {"text": "To surmount these problems, it would be advantageous to have an automatic procedure that cannot only augment existing resources but can also produce taxonomies for existing and new domains and tasks starting from scratch.", "labels": [], "entities": []}, {"text": "The main stages of automatic taxonomy induction are term extraction and term organization.", "labels": [], "entities": [{"text": "taxonomy induction", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.8055988848209381}, {"text": "term extraction", "start_pos": 52, "end_pos": 67, "type": "TASK", "confidence": 0.739779457449913}, {"text": "term organization", "start_pos": 72, "end_pos": 89, "type": "TASK", "confidence": 0.6911271065473557}]}, {"text": "In recent years there has been a substantial amount of work on term extraction, including semantic class learning, relation acquisition between entities (, and creation of concept lists.", "labels": [], "entities": [{"text": "term extraction", "start_pos": 63, "end_pos": 78, "type": "TASK", "confidence": 0.7664597034454346}, {"text": "semantic class learning", "start_pos": 90, "end_pos": 113, "type": "TASK", "confidence": 0.699174702167511}, {"text": "relation acquisition between entities", "start_pos": 115, "end_pos": 152, "type": "TASK", "confidence": 0.8716317117214203}]}, {"text": "Various attempts have been made to learn the taxonomic organization of concepts).", "labels": [], "entities": [{"text": "taxonomic organization of concepts", "start_pos": 45, "end_pos": 79, "type": "TASK", "confidence": 0.8405604511499405}]}, {"text": "Among the most common is to start with a good ontology and then to try to position the missing concepts into it.", "labels": [], "entities": []}, {"text": "() maximize the conditional probability of hyponym-hypernym relations given certain evidence, while) combines heterogenous features like context, co-occurrence, and surface patterns to produce a more-inclusive inclusion ranking formula.", "labels": [], "entities": []}, {"text": "The obtained results are promising, but the problem of how to organize the gathered knowledge when there is no initial taxonomy, or when the initial taxonomy is grossly impoverished, still remains.", "labels": [], "entities": []}, {"text": "The major problem in performing taxonomy construction from scratch is that overall concept positioning is not trivial.", "labels": [], "entities": [{"text": "taxonomy construction", "start_pos": 32, "end_pos": 53, "type": "TASK", "confidence": 0.8821591436862946}, {"text": "concept positioning", "start_pos": 83, "end_pos": 102, "type": "TASK", "confidence": 0.7854564785957336}]}, {"text": "It is difficult to discover whether concepts are unrelated, subordinated, or parallel to each other.", "labels": [], "entities": []}, {"text": "In this paper, we address the following question: How can one induce the taxonomic organization of concepts in a given domain starting from scratch?", "labels": [], "entities": []}, {"text": "The contributions of this paper are as follows: \u2022 An automatic procedure for harvesting hyponym-hypernym pairs given a domain of interest.", "labels": [], "entities": []}, {"text": "\u2022 A ranking mechanism for validating the learned is-a relations between the pairs.", "labels": [], "entities": []}, {"text": "\u2022 A graph-based approach for inducing the taxonomic organization of the harvested terms starting from scratch.", "labels": [], "entities": [{"text": "taxonomic organization of the harvested terms", "start_pos": 42, "end_pos": 87, "type": "TASK", "confidence": 0.8434749444325765}]}, {"text": "\u2022 An experiment on reconstructing WordNet's taxonomy forgiven domains.", "labels": [], "entities": []}, {"text": "Before focusing on the harvesting and taxonomy induction algorithms, we are going to describe some basic terminology following.", "labels": [], "entities": [{"text": "taxonomy induction", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.7746148109436035}]}, {"text": "A term is an English word (for our current purposes, a noun or a proper name).", "labels": [], "entities": []}, {"text": "A concept is an item in the classification taxonomy we are building.", "labels": [], "entities": []}, {"text": "A root concept is a fairly general concept which is located on the high level of the taxonomy.", "labels": [], "entities": []}, {"text": "A basic-level concept corresponds to the Basic Level categories defined in Prototype Theory in Psychology.", "labels": [], "entities": []}, {"text": "For example, a dog, not a mammal or a collie.", "labels": [], "entities": []}, {"text": "An instance is an item in the classification taxonomy that is more specific than a concept.", "labels": [], "entities": []}, {"text": "For example, Lassie, not a dog or collie . The rest of the paper is organized as follows.", "labels": [], "entities": [{"text": "Lassie", "start_pos": 13, "end_pos": 19, "type": "TASK", "confidence": 0.9625977277755737}]}, {"text": "Section 2 reviews related work.", "labels": [], "entities": []}, {"text": "Section 3 describes the taxonomization framework.", "labels": [], "entities": []}, {"text": "Section 4 discusses the experiments.", "labels": [], "entities": []}, {"text": "We conclude in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the performance of a taxonomy induction algorithm, one can compare against a simple taxonomy composed of 2-3 levels.", "labels": [], "entities": [{"text": "taxonomy induction", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.8679818212985992}]}, {"text": "However, one cannot guarantee that the algorithm can learn larger hierarchies completely or correctly.", "labels": [], "entities": []}, {"text": "Animals provide a good example of the true complexity of concept organization: there are many types, they are of numerous kinds, people take numerous perspectives over them, and they are relatively well-known to human annotators.", "labels": [], "entities": []}, {"text": "In addition, WordNet has a very rich and deep taxonomic structure for animals that can be used for direct comparison.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 13, "end_pos": 20, "type": "DATASET", "confidence": 0.9666078090667725}]}, {"text": "We further evaluate our algorithm on the domains of Plants and Vehicles, which share some of these properties.", "labels": [], "entities": []}, {"text": "To evaluate the performance of our taxonomy induction approach, we use the following measures: shows results of the taxonomy induction of the Vehicles domain using different concept positioning patterns.", "labels": [], "entities": [{"text": "taxonomy induction", "start_pos": 35, "end_pos": 53, "type": "TASK", "confidence": 0.8091979324817657}]}, {"text": "The most productive ones are: \"X are Y that\" and \"X including Y\".", "labels": [], "entities": []}, {"text": "However, the highest yield is obtained when we combine evidence from all patterns.", "labels": [], "entities": []}, {"text": "The biggest challenge of the taxonomization process is the merging of independent taxonomic per-spectives (a deer is a grazer in BehaviorByFeeding, a wildlife in BehaviorByHabitat, a herd in BehaviorSocialGroup and an even-toed ungulate in MorphologicalType) into a single hierarchy.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 5: Data for WordNet reconstruction.", "labels": [], "entities": [{"text": "WordNet reconstruction", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.8318833112716675}]}]}