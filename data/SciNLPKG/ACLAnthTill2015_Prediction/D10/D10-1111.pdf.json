{"title": [{"text": "Staying Informed: Supervised and Semi-Supervised Multi-view Topical Analysis of Ideological Perspective", "labels": [], "entities": [{"text": "Topical Analysis of Ideological Perspective", "start_pos": 60, "end_pos": 103, "type": "TASK", "confidence": 0.8140505790710449}]}], "abstractContent": [{"text": "With the proliferation of user-generated articles over the web, it becomes imperative to develop automated methods that are aware of the ideological-bias implicit in a document collection.", "labels": [], "entities": []}, {"text": "While there exist methods that can classify the ideological bias of a given document , little has been done toward understanding the nature of this bias on a topical-level.", "labels": [], "entities": []}, {"text": "In this paper we address the problem of modeling ideological perspective on a topical level using a factored topic model.", "labels": [], "entities": []}, {"text": "We develop efficient inference algorithms using Collapsed Gibbs sampling for posterior inference, and give various evaluations and illustrations of the utility of our model on various document collections with promising results.", "labels": [], "entities": []}, {"text": "Finally we give a Metropolis-Hasting inference algorithm fora semi-supervised extension with decent results.", "labels": [], "entities": []}], "introductionContent": [{"text": "With the avalanche of user-generated articles over the web, it is quite important to develop models that can recognize the ideological bias behind a given document, summarize where this bias is manifested on a topical level, and provide the user with alternate views that would help him/her staying informed about different perspectives.", "labels": [], "entities": []}, {"text": "In this paper, we follow the notion of ideology as defines by Van Dijk in ( as \"a set of general abstract beliefs commonly shared by a group of people.\"", "labels": [], "entities": []}, {"text": "In other words, an ideology is a set of ideas that directs one's goals, expectations, and actions.", "labels": [], "entities": []}, {"text": "For instance, freedom of choice is a general aim that directs the actions of\"liberals\", whereas conservation of values is the parallel for \"conservatives\".", "labels": [], "entities": []}, {"text": "We can attribute the lexical variations of the word content of a document to three factors: \u2022 Writer Ideological Belief.", "labels": [], "entities": []}, {"text": "A liberal writer might use words like freedom and choice regardless of the topical content of the document.", "labels": [], "entities": []}, {"text": "These words define the abstract notion of belief held by the writer and its frequency in the document largely depends on the writer's style.", "labels": [], "entities": []}, {"text": "This constitutes the main source of the lexical variations in a given document.", "labels": [], "entities": []}, {"text": "For instance, a document about abortion is more likely to have facts related to abortion, health, marriage and relationships.", "labels": [], "entities": []}, {"text": "When a liberal thinker writes about abortion, his/her abstract beliefs are materialized into a set of concrete opinions and stances, therefore, we might find words like: pro-choice and feminism.", "labels": [], "entities": []}, {"text": "On the contrary, a conservative writer might stress issues like pro-life, God and faith.", "labels": [], "entities": []}, {"text": "Given a collection of ideologically-labeled documents, our goal is to develop a computer model that factors the document collection into a representation that reflects the aforementioned three sources of lexical variations.", "labels": [], "entities": []}, {"text": "This representation can then be used for: \u2022 Visualization.", "labels": [], "entities": []}, {"text": "By visualizing the abstract notion of belief in each ideology, and the way each ideology approaches and views mainstream topics, the user can view and contrast each ideology side-by-side and build the right mental landscape that acts as the basis for his/her future decision making.", "labels": [], "entities": []}, {"text": "\u2022 Classification or Ideology Identification.", "labels": [], "entities": [{"text": "Classification or Ideology Identification", "start_pos": 2, "end_pos": 43, "type": "TASK", "confidence": 0.9129359275102615}]}, {"text": "Given a document, we would like to tell the user from which side it was written, and explain the ideological bias in the document at a topical level.", "labels": [], "entities": []}, {"text": "\u2022 Staying Informed: Getting alternative views . Given a document written from perspective A, we would like the model to provide the user with other documents that represent alternative views about the same topic addressed in the original document.", "labels": [], "entities": []}, {"text": "In this paper, we approach this problem using Topic Models ().", "labels": [], "entities": []}, {"text": "We introduce a factored topic model that we call multi-view Latent Dirichlet Allocation or mview-LDA for short.", "labels": [], "entities": []}, {"text": "Our model views the word content of each document as the result of the interaction between the document's idealogical and topical dimensions.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "First, in Section 2, we review related work, and then present our model in Section 3.", "labels": [], "entities": []}, {"text": "Then in Section 4, we detail a collapsed Gibbs sampling algorithm for posterior inference.", "labels": [], "entities": []}, {"text": "Sections 5 and 6 give details about the dataset used in the evaluation and illustrate the capabilities of our model using both qualitative and quantitative measures.", "labels": [], "entities": []}, {"text": "Section 7 describes and evaluates the efficacy of a semi-supervised extension, and finally in Section 8 we conclude and list several directions for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "The bitterlemons corpus consists of the articles published on the website http://bitterlemons.org/.", "labels": [], "entities": [{"text": "bitterlemons corpus", "start_pos": 4, "end_pos": 23, "type": "DATASET", "confidence": 0.9244407415390015}]}, {"text": "The website is setup to contribute to mutual understanding between Palestinians and Israelis through the open exchange of ideas.", "labels": [], "entities": []}, {"text": "Every week, an issue about the Israeli-Palestinian conflict is selected for discussion, and a Palestinian editor and an Israeli editor contribute one article each addressing the issue.", "labels": [], "entities": []}, {"text": "In addition, the Israeli and Palestinian editors invite one Israeli and one Palestinian to express their views on the issue.", "labels": [], "entities": []}, {"text": "The data was collected and pre-proceed as describes in (.", "labels": [], "entities": []}, {"text": "Overall, the dataset contains 297 documents written from the Israeli's point of view, and 297 documents written from the Palestinian's point of view.", "labels": [], "entities": []}, {"text": "On average each document contains around 740 words.", "labels": [], "entities": []}, {"text": "After trimming words appearing less than 5 times, we ended up with a vocabulary size of 4100 words.", "labels": [], "entities": []}, {"text": "We split the dataset randomly and used 80% of the documents for training and the rest for testing.", "labels": [], "entities": []}, {"text": "The first dataset refereed to as Blog-1 is a subset of the data collected and processed in (  of the liberal view (left-ideology).", "labels": [], "entities": [{"text": "Blog-1", "start_pos": 33, "end_pos": 39, "type": "DATASET", "confidence": 0.9246169924736023}]}, {"text": "After trimming short posts of less than 20 words, we ended up with 2040 posts distributed as 1400 from the left-wing and the rest from the right-wing.", "labels": [], "entities": []}, {"text": "On average, each post contains around 100 words and the total size of the vocabulary is 14276 words.", "labels": [], "entities": []}, {"text": "For this dataset, we followed the train-test split in (.", "labels": [], "entities": []}, {"text": "In this split each blog is represented in both training and test sets.", "labels": [], "entities": []}, {"text": "Thus this dataset does not measure the model's ability to generalize to a totally different writing style.", "labels": [], "entities": []}, {"text": "The second dataset refereed to as Blog-2 is similar to Blog-1 in its topical content and time frame but larger in its blog coverage.", "labels": [], "entities": [{"text": "Blog-2", "start_pos": 34, "end_pos": 40, "type": "DATASET", "confidence": 0.9640644192695618}, {"text": "Blog-1", "start_pos": 55, "end_pos": 61, "type": "DATASET", "confidence": 0.9547637701034546}]}, {"text": "Blog-2 spans 6 blogs: three from the leftwing and three from the right-wing.", "labels": [], "entities": [{"text": "Blog-2", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.9218080639839172}]}, {"text": "The dataset contains 13246 posts.", "labels": [], "entities": []}, {"text": "After removing words that appear less then 20 times, the total vocabulary becomes 13236 with an average of 200 words per post.", "labels": [], "entities": []}, {"text": "We used 4 blogs (2 from each view) for training and held two blogs (one from each view) for testing.", "labels": [], "entities": []}, {"text": "Thus this dataset measures the model's ability to generalize to a totally new blog.", "labels": [], "entities": []}, {"text": "In this section we gave various qualitative and quantitative evaluations of our model over the datasets listed in Section 5.", "labels": [], "entities": []}, {"text": "For all experiments, we set \u03b1 1 = .01, \u03b1 2 = .1, a = 1 and b = 1.", "labels": [], "entities": []}, {"text": "We run Gibbs sampling during training for 1000 iterations.", "labels": [], "entities": []}, {"text": "During inference, we ran Gibbs sampling for 300 iterations, and took 10 samples, with 50-iterations lag, for evaluations.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Classification performance of the semi- supervised model. R is the ratio of labeled documents.", "labels": [], "entities": [{"text": "Classification", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.95599764585495}, {"text": "R", "start_pos": 68, "end_pos": 69, "type": "METRIC", "confidence": 0.9928215146064758}]}]}