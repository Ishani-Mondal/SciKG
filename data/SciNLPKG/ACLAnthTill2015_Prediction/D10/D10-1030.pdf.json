{"title": [{"text": "Joint Inference for Bilingual Semantic Role Labeling", "labels": [], "entities": [{"text": "Bilingual Semantic Role Labeling", "start_pos": 20, "end_pos": 52, "type": "TASK", "confidence": 0.771820068359375}]}], "abstractContent": [{"text": "We show that jointly performing semantic role labeling (SRL) on bitext can improve SRL results on both sides.", "labels": [], "entities": [{"text": "semantic role labeling (SRL)", "start_pos": 32, "end_pos": 60, "type": "TASK", "confidence": 0.7604258010784785}, {"text": "SRL", "start_pos": 83, "end_pos": 86, "type": "TASK", "confidence": 0.9816488027572632}]}, {"text": "In our approach, we use monolingual SRL systems to produce argument candidates for predicates in bitext at first.", "labels": [], "entities": []}, {"text": "Then, we simultaneously generate SRL results for two sides of bitext using our joint inference model.", "labels": [], "entities": [{"text": "SRL", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.6411640048027039}]}, {"text": "Our model prefers the bilingual SRL result that is not only reasonable on each side of bitext, but also has more consistent argument structures between two sides.", "labels": [], "entities": [{"text": "SRL", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.8915172219276428}]}, {"text": "To evaluate the consistency between two argument structures, we also formulate a log-linear model to compute the probability of aligning two arguments.", "labels": [], "entities": []}, {"text": "We have experimented with our model on Chinese-English parallel Prop-Bank data.", "labels": [], "entities": [{"text": "Chinese-English parallel Prop-Bank data", "start_pos": 39, "end_pos": 78, "type": "DATASET", "confidence": 0.5800469145178795}]}, {"text": "Using our joint inference model, F1 scores of SRL results on Chinese and En-glish text achieve 79.53% and 77.87% respectively , which are 1.52 and 1.74 points higher than the results of baseline monolingual SRL combination systems respectively.", "labels": [], "entities": [{"text": "F1", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9994726777076721}, {"text": "SRL", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.983893632888794}, {"text": "SRL combination", "start_pos": 207, "end_pos": 222, "type": "TASK", "confidence": 0.8880999386310577}]}], "introductionContent": [{"text": "In recent years, there has been an increasing interest in SRL on several languages.", "labels": [], "entities": [{"text": "SRL", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.9931061863899231}]}, {"text": "However, little research has been done on how to effectively perform SRL on bitext, which has important applications including machine translation (.", "labels": [], "entities": [{"text": "SRL", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.994543194770813}, {"text": "machine translation", "start_pos": 127, "end_pos": 146, "type": "TASK", "confidence": 0.8376438319683075}]}, {"text": "A conventional way to perform SRL on bitext is performing SRL on each side of bitext separately, as has been done by on Chinese-English bitext.", "labels": [], "entities": [{"text": "SRL", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.9921497106552124}]}, {"text": "However, it is very difficult to obtain good SRL results on both sides of bitext in this way.", "labels": [], "entities": [{"text": "SRL", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9276221990585327}]}, {"text": "The reason is that even the state-ofthe-art SRL systems do not have very high accuracy on both English text, and Chinese text ().", "labels": [], "entities": [{"text": "SRL", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.9346058368682861}, {"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9991084933280945}]}, {"text": "On the other hand, the semantic equivalence between two sides of bitext means that they should have consistent predicate-argument structures.", "labels": [], "entities": []}, {"text": "This bilingual argument structure consistency can guide us to find better SRL results.", "labels": [], "entities": [{"text": "SRL", "start_pos": 74, "end_pos": 77, "type": "TASK", "confidence": 0.9902547001838684}]}, {"text": "For example, in Figure 1(a), the argument structure consistency can guide us to choose a correct SRL result on Chinese side.", "labels": [], "entities": []}, {"text": "Consistency between two argument structures is reflected by sound argument alignments between them, as shown in(b).", "labels": [], "entities": []}, {"text": "Previous research has shown that bilingual constraints can be very helpful for parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 79, "end_pos": 86, "type": "TASK", "confidence": 0.9846267104148865}]}, {"text": "In this paper, we show that the bilingual argument structure consistency can be leveraged to substantially improve SRL results on both sides of bitext.", "labels": [], "entities": [{"text": "SRL", "start_pos": 115, "end_pos": 118, "type": "TASK", "confidence": 0.9781718254089355}]}, {"text": "Formally, we present a joint inference model to preform bilingual SRL.", "labels": [], "entities": [{"text": "preform bilingual SRL", "start_pos": 48, "end_pos": 69, "type": "TASK", "confidence": 0.5802056690057119}]}, {"text": "Using automatic word alignment on bitext, we first identify a pair of predicates that align with each other.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 16, "end_pos": 30, "type": "TASK", "confidence": 0.7189732044935226}]}, {"text": "And we use monolingual SRL systems to produce argument candidates for each predicate.", "labels": [], "entities": []}, {"text": "Then, our model jointly generate SRL results for both predicates from their argument candidates, using integer linear programming technique.", "labels": [], "entities": [{"text": "SRL", "start_pos": 33, "end_pos": 36, "type": "TASK", "confidence": 0.9289389848709106}]}, {"text": "An overview of our approach is shown in.", "labels": [], "entities": []}, {"text": "Our joint inference model consists of three components: the source side, the target side, and the ar-    gument alignment between two sides.", "labels": [], "entities": []}, {"text": "These three components correspond to three interrelated factors: the quality of the SRL result on source side, the quality of the SRL result on target side, and the argument structure consistency between the SRL results on both sides.", "labels": [], "entities": []}, {"text": "To evaluate the consistency between the two argument structures in our joint inference model, we formulate a log-linear model to compute the probability of aligning two arguments.", "labels": [], "entities": []}, {"text": "Experiments on Chinese-English parallel PropBank shows that our model significantly outperforms monolingual SRL combination systems on both Chinese and English sides.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 40, "end_pos": 48, "type": "DATASET", "confidence": 0.7464920878410339}]}, {"text": "The rest of this paper is organized as follows: Section 2 introduces related work.", "labels": [], "entities": []}, {"text": "Section 3 describes how we generate SRL candidates on each side of bitext.", "labels": [], "entities": [{"text": "SRL", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9424115419387817}]}, {"text": "Section 4 presents our joint inference model.", "labels": [], "entities": []}, {"text": "Section 5 presents our experiments.", "labels": [], "entities": []}, {"text": "And Section 6 concludes our work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In our experiments, we use the Xinhua News portion of Chinese and English data in LDC OntoNotes Release 3.0.", "labels": [], "entities": [{"text": "Xinhua News portion of Chinese and English data", "start_pos": 31, "end_pos": 78, "type": "DATASET", "confidence": 0.9124027341604233}, {"text": "LDC OntoNotes Release 3.0", "start_pos": 82, "end_pos": 107, "type": "DATASET", "confidence": 0.8287005126476288}]}, {"text": "This data is a Chinese-English parallel proposition bank described in).", "labels": [], "entities": []}, {"text": "It contains parallel proposition annotations for 325 files (chtb 0001.fid to chtb 0325.fid) from ChineseEnglish parallel Treebank.", "labels": [], "entities": [{"text": "ChineseEnglish parallel Treebank", "start_pos": 97, "end_pos": 129, "type": "DATASET", "confidence": 0.9348781506220499}]}, {"text": "The English part of this data contains proposition annotations only for verbal predicates.", "labels": [], "entities": []}, {"text": "Therefore, we only consider verbal predicates in this paper.", "labels": [], "entities": []}, {"text": "We employ the GIZA++ toolkit to perform automatic word alignment.", "labels": [], "entities": [{"text": "GIZA++ toolkit", "start_pos": 14, "end_pos": 28, "type": "DATASET", "confidence": 0.8653748432795206}, {"text": "word alignment", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.7062193900346756}]}, {"text": "Besides the parallel PropBank data, we use additional 4,500K Chinese-English sentence pairs 3 to induce word alignments for both directions, with the default GIZA++ settings.", "labels": [], "entities": [{"text": "PropBank data", "start_pos": 21, "end_pos": 34, "type": "DATASET", "confidence": 0.9306350350379944}, {"text": "word alignments", "start_pos": 104, "end_pos": 119, "type": "TASK", "confidence": 0.7035398483276367}]}, {"text": "The alignments are symmetrized using the intersection heuristic, which is known to produce high-precision alignments.", "labels": [], "entities": []}, {"text": "We use 80 files (chtb 0001.fid to chtb 0080.fid) as test data, and 40 files (chtb 0081.fid to chtb 0120.fid) as development data.", "labels": [], "entities": []}, {"text": "Although our joint inference model needs no training, we still need to train a log-linear argument alignment probability model, which is used in the joint inference model.", "labels": [], "entities": []}, {"text": "As specified in subsection 4.2.1, the train-ing set for the argument alignment probability model consists of 60 files (chtb 0121.fid to chtb 0180.fid) with manual argument alignment.", "labels": [], "entities": [{"text": "argument alignment", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.6759478002786636}]}, {"text": "Unfortunately, the quality of automatic word alignment on oneto-many Chinese-English sentence pairs is usually very poor.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 40, "end_pos": 54, "type": "TASK", "confidence": 0.703762024641037}]}, {"text": "So we only include one-to-one ChineseEnglish sentence pairs in all data.", "labels": [], "entities": []}, {"text": "And not all predicates in a sentence pair can be included.", "labels": [], "entities": []}, {"text": "Only bilingual predicate pairs are included.", "labels": [], "entities": []}, {"text": "A bilingual predicate pair is defined to be a pair of predicates in bitext which align with each other in automatic word alignment.", "labels": [], "entities": []}, {"text": "shows how many sentences and predicates are included in each data set.", "labels": [], "entities": []}, {"text": "Our monolingual SRL systems are trained separately.", "labels": [], "entities": [{"text": "SRL", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9612725973129272}]}, {"text": "Our Chinese SRL system is trained on 640 files (chtb 0121.fid to chtb 0931.fid) in Chinese Propbank 1.0.", "labels": [], "entities": [{"text": "SRL", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.5760100483894348}, {"text": "Chinese Propbank 1.0", "start_pos": 83, "end_pos": 103, "type": "DATASET", "confidence": 0.9123792846997579}]}, {"text": "Because Xinhua News is a quite different domain from WSJ, the training set for our English SRL system includes not only Sections 02\u223c21 of WSJ data in English Propbank, but also 205 files (chtb 0121.fid to chtb 0325.fid) in the English part of parallel PropBank.", "labels": [], "entities": [{"text": "Xinhua News", "start_pos": 8, "end_pos": 19, "type": "DATASET", "confidence": 0.903964638710022}, {"text": "WSJ", "start_pos": 53, "end_pos": 56, "type": "DATASET", "confidence": 0.9311153292655945}, {"text": "WSJ data", "start_pos": 138, "end_pos": 146, "type": "DATASET", "confidence": 0.9597215354442596}, {"text": "PropBank", "start_pos": 252, "end_pos": 260, "type": "DATASET", "confidence": 0.5884042978286743}]}, {"text": "For Chinese, the syntactic parsers are trained on 640 files (chtb 0121.fid to chtb 0931.fid) plus the broadcast news portion of Chinese Treebank 6.0.", "labels": [], "entities": [{"text": "Chinese Treebank 6.0", "start_pos": 128, "end_pos": 148, "type": "DATASET", "confidence": 0.9575312932332357}]}, {"text": "For English, the syntactic parsers are trained on the following data: Sections 02\u223c21 of WSJ data in English Treebank, 205 files (chtb 0121.fid to chtb 0325.fid) of Xinhua News data in OntoNotes 3.0, and the Sinorama data in OntoNotes 3.0.", "labels": [], "entities": [{"text": "WSJ data", "start_pos": 88, "end_pos": 96, "type": "DATASET", "confidence": 0.9532450139522552}, {"text": "English Treebank", "start_pos": 100, "end_pos": 116, "type": "DATASET", "confidence": 0.9130720496177673}, {"text": "Xinhua News data", "start_pos": 164, "end_pos": 180, "type": "DATASET", "confidence": 0.8876646558443705}, {"text": "Sinorama data", "start_pos": 207, "end_pos": 220, "type": "DATASET", "confidence": 0.9587045013904572}, {"text": "OntoNotes", "start_pos": 224, "end_pos": 233, "type": "DATASET", "confidence": 0.6576472520828247}]}, {"text": "We treat discontinuous and coreferential arguments in accordance to the).", "labels": [], "entities": []}, {"text": "The first part of a discontinuous argument is labeled as it is, and the second part is labeled with a prefix \"C-\".", "labels": [], "entities": []}, {"text": "All coreferential arguments are labeled with a prefix \"R-\".", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The argument alignment matrix on manually  aligned corpus.", "labels": [], "entities": [{"text": "argument alignment", "start_pos": 14, "end_pos": 32, "type": "TASK", "confidence": 0.7190475016832352}]}, {"text": " Table 3: Sentence and predicate counts.", "labels": [], "entities": [{"text": "Sentence and predicate counts", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.620782732963562}]}, {"text": " Table 4: Parameter values in models.", "labels": [], "entities": [{"text": "Parameter", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8891159296035767}]}, {"text": " Table 5: The results of individual monolingual SRL out- puts on test set.", "labels": [], "entities": [{"text": "SRL", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.9139603972434998}]}, {"text": " Table 6: Results of different joint models on test set.", "labels": [], "entities": []}, {"text": " Table 7: Comparison between monolingual combination  model and our joint inference model on test set.", "labels": [], "entities": []}]}