{"title": [{"text": "Mining Name Translations from Entity Graph Mapping *", "labels": [], "entities": [{"text": "Mining Name Translations from Entity Graph Mapping", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.605077075106757}]}], "abstractContent": [{"text": "This paper studies the problem of mining entity translation, specifically, mining English and Chinese name pairs.", "labels": [], "entities": [{"text": "mining entity translation", "start_pos": 34, "end_pos": 59, "type": "TASK", "confidence": 0.7379789352416992}]}, {"text": "Existing efforts can be categorized into (a) a transliteration-based approach leveraging phonetic similarity and (b) a corpus-based approach exploiting bilingual co-occurrences, each of which suffers from inaccuracy and scarcity respectively.", "labels": [], "entities": []}, {"text": "In clear contrast, we use unleveraged resources of monolingual entity co-occurrences, crawled from entity search engines, represented as two entity-relationship graphs extracted from two language corpora respectively.", "labels": [], "entities": []}, {"text": "Our problem is then abstracted as finding correct mappings across two graphs.", "labels": [], "entities": []}, {"text": "To achieve this goal, we propose a holistic approach , of exploiting both transliteration similarity and monolingual co-occurrences.", "labels": [], "entities": []}, {"text": "This approach, building upon monolingual corpora, complements existing corpus-based work, requiring scarce resources of parallel or comparable corpus, while significantly boosting the accuracy of transliteration-based work.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 184, "end_pos": 192, "type": "METRIC", "confidence": 0.9975098371505737}]}, {"text": "We validate our proposed system using real-life datasets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Entity translation aims at mapping the entity names (e.g., people, locations, and organizations) in source language into their corresponding names in target language.", "labels": [], "entities": [{"text": "Entity translation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8315539658069611}]}, {"text": "While high quality entity translation is essential in cross-lingual information access and trans- * This work was done when the first two authors visited Microsoft Research Asia.", "labels": [], "entities": [{"text": "entity translation", "start_pos": 19, "end_pos": 37, "type": "TASK", "confidence": 0.7133566439151764}, {"text": "cross-lingual information access", "start_pos": 54, "end_pos": 86, "type": "TASK", "confidence": 0.7191175222396851}, {"text": "Microsoft Research Asia", "start_pos": 154, "end_pos": 177, "type": "DATASET", "confidence": 0.8440898656845093}]}, {"text": "lation, it is non-trivial to achieve, due to the challenge that entity translation, though typically bearing pronunciation similarity, can also be arbitrary, e.g., Jackie Chan and (pronounced Cheng Long).", "labels": [], "entities": [{"text": "entity translation", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.7434391975402832}]}, {"text": "Existing efforts to address these challenges can be categorized into transliteration-and corpusbased approaches.", "labels": [], "entities": []}, {"text": "Transliteration-based approaches ( identify translations based on pronunciation similarity, while corpus-based approaches mine bilingual co-occurrences of translation pairs obtained from parallel) or comparable () corpora, or alternatively mined from bilingual sentences ().", "labels": [], "entities": []}, {"text": "These two approaches have complementary strength-transliteration-based similarity can be computed for any name pair but cannot mine translations of little (or none) phonetic similarity.", "labels": [], "entities": []}, {"text": "Corpus-based similarity can support arbitrary translations, but require highly scarce resources of bilingual co-occurrences, obtained from parallel or comparable bilingual corpora.", "labels": [], "entities": []}, {"text": "In this paper, we propose a holistic approach, leveraging both transliteration-and corpus-based similarity.", "labels": [], "entities": []}, {"text": "Our key contribution is to replace the use of scarce resources of bilingual co-occurrences with the use of untapped and significantly larger resources of monolingual co-occurrences for translation.", "labels": [], "entities": []}, {"text": "In particular, we extract monolingual cooccurrences of entities from English and Chinese Web corpora, which are readily available from entity search engines such as PeopleEntityCube 1 , deployed by Microsoft Research Asia.", "labels": [], "entities": []}, {"text": "Such engine automatically extracts people names from text and their co-occurrences to retrieve related entities based on co-occurrences.", "labels": [], "entities": []}, {"text": "To illustrate,(a) demonstrates the query result for \"Bill Gates,\" retrieving and visualizing the \"entity-relationship graph\" of related people names that frequently co-occur with Bill in English corpus.", "labels": [], "entities": []}, {"text": "Similarly, entity-relationship graphs can be built over other language corpora, as(b) demonstrates the corresponding results for the same query, from Renlifang 2 on Chinese Web corpus.", "labels": [], "entities": [{"text": "Renlifang 2 on Chinese Web corpus", "start_pos": 150, "end_pos": 183, "type": "DATASET", "confidence": 0.7971016665299734}]}, {"text": "From this point on, for the sake of simplicity, we refer to English and Chinese graphs, simply as Ge and G c respectively.", "labels": [], "entities": []}, {"text": "Though we illustrate with English-Chinese pairs in the paper, our method can be easily adapted to other language pairs.", "labels": [], "entities": []}, {"text": "In particular, we propose a novel approach of abstracting entity translation as a graph matching problem of two graphs Ge and G c in and (b).", "labels": [], "entities": [{"text": "abstracting entity translation", "start_pos": 46, "end_pos": 76, "type": "TASK", "confidence": 0.8469705184300741}]}, {"text": "Specifically, the similarity between two nodes v e and v c in Ge and G c is initialized as their transliteration similarity, which is iteratively refined based on relational similarity obtained from monolingual cooccurrences.", "labels": [], "entities": []}, {"text": "To illustrate this, an English news article mentioning \"Bill Gates\" and \"Melinda Gates\" evidences a relationship between the two entities, which can be quantified from their co-occurrences in the entire English Web corpus.", "labels": [], "entities": [{"text": "English Web corpus", "start_pos": 203, "end_pos": 221, "type": "DATASET", "confidence": 0.7644535601139069}]}, {"text": "Similarly, we can mine Chinese news articles to obtain the relationships between \"\u00b7\" and \"\u00b7 \".", "labels": [], "entities": []}, {"text": "Once these two bilingual graphs of people and their relationships are harvested, entity translation can leverage these parallel relationships to further evidence the mapping between translation pairs, as(c) illustrates.", "labels": [], "entities": [{"text": "entity translation", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.8166302740573883}]}, {"text": "To highlight the advantage of our proposed approach, we compare our results with commercial machine translators (1) Engkoo 3 developed in Microsoft Research Asia and (2) Google Translator 4 . In particular, reports the precision for two groups-\"heads\" that belong to top-100 popular people (determined by the number of hits), among randomly sampled 304 people names 5 from six graph pairs of size 1,000 each, and the remaining \"tails\".", "labels": [], "entities": [{"text": "precision", "start_pos": 219, "end_pos": 228, "type": "METRIC", "confidence": 0.9995169639587402}]}, {"text": "Commercial translators such as Google, leveraging 2 http://renlifang.msra.cn 3 http://www.engkoo.com 4 http://translate.google.com See Section 4 for the sampling process.", "labels": [], "entities": []}, {"text": "bilingual co-occurrences that are scarce for tails, show significantly lower precision for tails.", "labels": [], "entities": [{"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9990241527557373}]}, {"text": "Meanwhile, our work, depending solely on monolingual co-occurrences, shows high precision, for both heads and tails.", "labels": [], "entities": [{"text": "precision", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.9980117082595825}]}, {"text": "Our focus is to boost translation accuracy for long tails with non-trivial Web occurrences in each monolingual corpus, but not with much bilingual cooccurrences, e.g., researchers publishing actively in two languages but not famous enough to be featured in multi-lingual Wikipedia entries or news articles.", "labels": [], "entities": [{"text": "translation", "start_pos": 22, "end_pos": 33, "type": "TASK", "confidence": 0.9679110050201416}, {"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.908076286315918}]}, {"text": "As existing translators are already highly accurate for popular heads, this focus well addresses the remaining challenges for entity translation.", "labels": [], "entities": [{"text": "entity translation", "start_pos": 126, "end_pos": 144, "type": "TASK", "confidence": 0.7978820502758026}]}, {"text": "To summarize, we believe that this paper has the following contributions: \u2022 We abstract entity translation problem as a graph mapping between entity-relationship graphs in two languages.", "labels": [], "entities": [{"text": "entity translation problem", "start_pos": 88, "end_pos": 114, "type": "TASK", "confidence": 0.8077394962310791}]}, {"text": "\u2022 We develop an effective matching algorithm leveraging both pronunciation and cooccurrence similarity.", "labels": [], "entities": []}, {"text": "This holistic approach complements existing approaches and enhances the translation coverage and accuracy.", "labels": [], "entities": [{"text": "translation coverage", "start_pos": 72, "end_pos": 92, "type": "TASK", "confidence": 0.786279559135437}, {"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9968647360801697}]}, {"text": "\u2022 We validate the effectiveness of our approach using various real-life datasets.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews existing work.", "labels": [], "entities": []}, {"text": "Section 3 then develops our framework.", "labels": [], "entities": []}, {"text": "Section 4 reports experimental results and Section 5 concludes our work.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section reports our experimental results to evaluate our proposed approach.", "labels": [], "entities": []}, {"text": "First, we report our experimental setting in Section 4.1.", "labels": [], "entities": []}, {"text": "Second, we validate the effectiveness and the scalability of our approach over a real-life dataset in Section 4.2.", "labels": [], "entities": []}, {"text": "This section describes (1) how we collect the English and Chinese EntityCube datasets, (2) how to build ground-truth test datasets for evaluating our framework, and (3) how to setup three parameters \u03bb, \u03b8, and \u03b4.", "labels": [], "entities": [{"text": "Chinese EntityCube datasets", "start_pos": 58, "end_pos": 85, "type": "DATASET", "confidence": 0.7485228578249613}]}, {"text": "First, we crawled Ge = (V e , E e ) and G c = (V c , E c ) from English and Chinese EntityCubes.", "labels": [], "entities": []}, {"text": "Specifically, we built a graph pairs (G e , G c ) expanding from a \"seed pair\" of nodes s e \u2208 V e and s c \u2208 V c until the number of nodes for each graph becomes 1,000 . More specifically, when we build a graph Ge by expanding from s e , we use a queue Q.", "labels": [], "entities": []}, {"text": "We first initialize Q by pushing the seed node s e . We then iteratively pop anode v e from Q, save v e into V e , and push its neighbor nodes in decreasing order of co-occurrence scores with v e . Similarly, we can get G c from a counterpart seed node v c . By using this procedure, we built six graph pairs from six different seed pairs.", "labels": [], "entities": []}, {"text": "In particular, the six seed nodes are English names and its corresponding Chinese names representing a wide range of occupation domains (e.g., 'Barack Obama,' 'Bill Gates,' 'Britney Spears,' 'Bruno Senna,' 'Chris Paul,' and 'Eminem') as depicts.", "labels": [], "entities": []}, {"text": "Meanwhile, though we demonstrate the effectiveness of the proposed method for mining name translations in Chinese and English languages, the method can be easily adapted to other language pairs.", "labels": [], "entities": [{"text": "mining name translations", "start_pos": 78, "end_pos": 102, "type": "TASK", "confidence": 0.7337994575500488}]}, {"text": "Second, we manually searched for about 50 \"ground-truth\" matched translations for each graph pair to build test datasets Ti , by randomly selecting nodes within two hops 7 from the seed pair (s e , s c ), since nodes outside two hops may include nodes whose neighbors are not fully crawled.", "labels": [], "entities": []}, {"text": "More specifically, due to our crawling process expanding to add neighbors from the seed, the nodes close to the seed have all the neighbors they would have in the full graph, while those far from the node may not.", "labels": [], "entities": []}, {"text": "In order to pick the nodes that well represent the actual neighbors, we built test datasets among those within two hops.", "labels": [], "entities": []}, {"text": "However, this crawling is used for the evaluation sake only, and thus does not suggest the bias in our proposed framework.", "labels": [], "entities": []}, {"text": "describes the size of such test dataset for each graph pair.", "labels": [], "entities": []}, {"text": "Lastly, we setup the three parameters \u03bb, \u03b8, and \u03b4 using 6-fold cross validation with 6 test datasets Ti 's of the graphs.", "labels": [], "entities": []}, {"text": "More specifically, for each dataset Ti , we decide \u03bb i and \u03b8 i such that average MRR for the other 5 test datasets is maximized.", "labels": [], "entities": [{"text": "MRR", "start_pos": 81, "end_pos": 84, "type": "METRIC", "confidence": 0.9850355386734009}]}, {"text": "(About MRR, see more details of Equation in Section 4.2.)", "labels": [], "entities": [{"text": "MRR", "start_pos": 7, "end_pos": 10, "type": "DATASET", "confidence": 0.6281157732009888}, {"text": "Equation", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9927045106887817}]}, {"text": "We then decide \u03b4 i such that average F1-score is maximized.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9970325231552124}]}, {"text": "This section reports our experimental results using the evaluation datasets explained in previous section.", "labels": [], "entities": []}, {"text": "For each graph pair, we evaluated the effectiveness of (1) reinforcement model using MRR measure in Section 4.2.1 and (2) overall framework using precision, recall, and F1 measures in Section 4.2.2.", "labels": [], "entities": [{"text": "MRR measure", "start_pos": 85, "end_pos": 96, "type": "METRIC", "confidence": 0.943878173828125}, {"text": "precision", "start_pos": 146, "end_pos": 155, "type": "METRIC", "confidence": 0.9992960691452026}, {"text": "recall", "start_pos": 157, "end_pos": 163, "type": "METRIC", "confidence": 0.9968408346176147}, {"text": "F1", "start_pos": 169, "end_pos": 171, "type": "METRIC", "confidence": 0.9996058344841003}]}, {"text": "We also validated (3) scalability of our framework over larger scale of graphs (with up to five thousand nodes) in Section 4.2.3.", "labels": [], "entities": []}, {"text": "(In all experimental results, Bold numbers indicate the best performance for each metric.)", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Summary for graphs and test datasets obtained  from each seed pair", "labels": [], "entities": []}, {"text": " Table 2: MRR of baseline and reinforced matrices", "labels": [], "entities": [{"text": "MRR", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.9581555724143982}]}, {"text": " Table 4: Precision, Recall, and F1-score of Engkoo, Google, and Ours with head and tail datasets", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9987596273422241}, {"text": "Recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9935557246208191}, {"text": "F1-score", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9996768236160278}, {"text": "Engkoo", "start_pos": 45, "end_pos": 51, "type": "DATASET", "confidence": 0.9473908543586731}]}]}