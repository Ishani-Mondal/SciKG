{"title": [], "abstractContent": [{"text": "Part-of-speech (POS) tag distributions are known to exhibit sparsity-a word is likely to take a single predominant tag in a corpus.", "labels": [], "entities": []}, {"text": "Recent research has demonstrated that incorporating this sparsity constraint improves tagging accuracy.", "labels": [], "entities": [{"text": "tagging", "start_pos": 86, "end_pos": 93, "type": "TASK", "confidence": 0.9642511606216431}, {"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9269912242889404}]}, {"text": "However, in existing systems, this expansion come with a steep increase in model complexity.", "labels": [], "entities": []}, {"text": "This paper proposes a simple and effective tagging method that directly models tag sparsity and other distributional properties of valid POS tag assignments.", "labels": [], "entities": [{"text": "POS tag assignments", "start_pos": 137, "end_pos": 156, "type": "TASK", "confidence": 0.6656070351600647}]}, {"text": "In addition, this formulation results in a dramatic reduction in the number of model parameters thereby, enabling unusually rapid training.", "labels": [], "entities": []}, {"text": "Our experiments consistently demonstrate that this model architecture yields substantial performance gains over more complex tagging counterparts.", "labels": [], "entities": []}, {"text": "On several languages, we report performance exceeding that of more complex state-of-the art systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "Since the early days of statistical NLP, researchers have observed that a part-of-speech tag distribution exhibits \"one tag per discourse\" sparsity -words are likely to select a single predominant tag in a corpus, even when several tags are possible.", "labels": [], "entities": []}, {"text": "Simply assigning to each word its most frequent associated tag in a corpus achieves 94.6% accuracy on the WSJ portion of the Penn Treebank.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.999087929725647}, {"text": "WSJ portion of the Penn Treebank", "start_pos": 106, "end_pos": 138, "type": "DATASET", "confidence": 0.9156496127446493}]}, {"text": "This distributional sparsity of syntactic tags is not unique to English The source code for the work presented in this paper is available at http://groups.csail.mit.edu/rbg/code/typetagging/.", "labels": [], "entities": []}, {"text": "-similar results have been observed across multiple languages.", "labels": [], "entities": []}, {"text": "Clearly, explicitly modeling such a powerful constraint on tagging assignment has a potential to significantly improve the accuracy of an unsupervised part-of-speech tagger learned without a tagging dictionary.", "labels": [], "entities": [{"text": "tagging assignment", "start_pos": 59, "end_pos": 77, "type": "TASK", "confidence": 0.9417440593242645}, {"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9988635778427124}]}, {"text": "In practice, this sparsity constraint is difficult to incorporate in a traditional POS induction system.", "labels": [], "entities": []}, {"text": "These sequence models-based approaches commonly treat token-level tag assignment as the primary latent variable.", "labels": [], "entities": [{"text": "token-level tag assignment", "start_pos": 54, "end_pos": 80, "type": "TASK", "confidence": 0.6674309968948364}]}, {"text": "By design, they readily capture regularities at the token-level.", "labels": [], "entities": []}, {"text": "However, these approaches are ill-equipped to directly represent type-based constraints such as sparsity.", "labels": [], "entities": []}, {"text": "Previous work has attempted to incorporate such constraints into token-level models via heavy-handed modifications to inference procedure and objective function (e.g., posterior regularization and ILP decoding).", "labels": [], "entities": []}, {"text": "In most cases, however, these expansions come with a steep increase in model complexity, with respect to training procedure and inference time.", "labels": [], "entities": []}, {"text": "In this work, we take a more direct approach and treat a word type and its allowed POS tags as a primary element of the model.", "labels": [], "entities": []}, {"text": "The model starts by generating a tag assignment for each word type in a vocabulary, assuming one tag per word.", "labels": [], "entities": []}, {"text": "Then, tokenlevel HMM emission parameters are drawn conditioned on these assignments such that each word is only allowed probability mass on a single assigned tag.", "labels": [], "entities": []}, {"text": "In this way we restrict the parameterization of a token-level HMM to reflect lexicon sparsity.", "labels": [], "entities": []}, {"text": "This model admits a simple Gibbs sampling algorithm where the number of latent variables is proportional to the number of word types, rather than the size of a corpus as fora standard HMM sampler.", "labels": [], "entities": []}, {"text": "There are two key benefits of this model architecture.", "labels": [], "entities": []}, {"text": "First, it directly encodes linguistic intuitions about POS tag assignments: the model structure reflects the one-tag-per-word property, and a typelevel tag prior captures the skew on tag assignments (e.g., there are fewer unique determiners than unique nouns).", "labels": [], "entities": [{"text": "POS tag assignments", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.8443191250165304}]}, {"text": "Second, the reduced number of hidden variables and parameters dramatically speeds up learning and inference.", "labels": [], "entities": []}, {"text": "We evaluate our model on seven languages exhibiting substantial syntactic variation.", "labels": [], "entities": []}, {"text": "On several languages, we report performance exceeding that of state-of-the art systems.", "labels": [], "entities": []}, {"text": "Our analysis identifies three key factors driving our performance gain: 1) selecting a model structure which directly encodes tag sparsity, 2) a type-level prior on tag assignments, and 3) a straightforward na\u00a8\u0131vena\u00a8\u0131ve-Bayes approach to incorporate features.", "labels": [], "entities": []}, {"text": "The observed performance gains, coupled with the simplicity of model implementation, makes it a compelling alternative to existing more complex counterparts.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our approach on seven languages: English, Danish, Dutch, German, Portuguese, Spanish, and Swedish.", "labels": [], "entities": []}, {"text": "On each language we investigate the contribution of each component of our model.", "labels": [], "entities": []}, {"text": "For all languages we do not make use of a tagging dictionary.: Multi-lingual Results: We report token-level one-to-one and many-to-one accuracy on a variety of languages under several experimental settings (Section 5).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 135, "end_pos": 143, "type": "METRIC", "confidence": 0.9836527109146118}]}, {"text": "For each language and setting, we report one-to-one (1-1) and manyto-one (m-1) accuracies.", "labels": [], "entities": []}, {"text": "For each cell, the first row corresponds to the result using the best hyperparameter choice, where best is defined by the 1-1 metric.", "labels": [], "entities": []}, {"text": "The second row represents the performance of the median hyperparameter setting.", "labels": [], "entities": []}, {"text": "Model components cascade, so the row corresponding to +FEATS also includes the PRIOR component (see", "labels": [], "entities": [{"text": "FEATS", "start_pos": 55, "end_pos": 60, "type": "METRIC", "confidence": 0.9949865341186523}]}], "tableCaptions": [{"text": " Table 1: Upper bound on tagging accuracy assuming each  word type is assigned to majority POS tag. Across all  languages, high performance can be attained by selecting  a single tag per word type.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.959433376789093}]}, {"text": " Table 3: Multi-lingual Results: We report token-level one-to-one and many-to-one accuracy on a variety of languages  under several experimental settings (Section 5). For each language and setting, we report one-to-one (1-1) and many- to-one (m-1) accuracies. For each cell, the first row corresponds to the result using the best hyperparameter choice,  where best is defined by the 1-1 metric. The second row represents the performance of the median hyperparameter  setting. Model components cascade, so the row corresponding to +FEATS also includes the PRIOR component (see", "labels": [], "entities": [{"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9956150054931641}, {"text": "FEATS", "start_pos": 531, "end_pos": 536, "type": "METRIC", "confidence": 0.9955554604530334}, {"text": "PRIOR", "start_pos": 555, "end_pos": 560, "type": "METRIC", "confidence": 0.7975162863731384}]}, {"text": " Table 2: Statistics for various corpora utilized in exper- iments. See Section 5. The English data comes from  the WSJ portion of the Penn Treebank and the other lan- guages from the training set of the CoNLL-X multilin- gual dependency parsing shared task.", "labels": [], "entities": [{"text": "WSJ portion of the Penn Treebank", "start_pos": 116, "end_pos": 148, "type": "DATASET", "confidence": 0.9210781852404276}, {"text": "CoNLL-X multilin- gual dependency parsing shared task", "start_pos": 204, "end_pos": 257, "type": "TASK", "confidence": 0.7076803855597973}]}, {"text": " Table 4: Comparison of our method (FEATS) to state-of-the-art methods. Feature-based HMM Model (Berg- Kirkpatrick et al., 2010): The KM model uses a variety of orthographic features and employs the EM or LBFGS  optimization algorithm; Posterior regulariation model (Gra\u00e7a et al., 2009): The G10 model uses the posterior regular- ization approach to ensure tag sparsity constraint.", "labels": [], "entities": []}, {"text": " Table 6: Type-level Results: Each cell report the type- level accuracy computed against the most frequent tag of  each word type. The state-to-tag mapping is obtained  from the best hyperparameter setting for 1-1 mapping  shown in", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.6390340328216553}]}]}