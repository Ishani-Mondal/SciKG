{"title": [{"text": "Crouching Dirichlet, Hidden Markov Model: Unsupervised POS Tagging with Context Local Tag Generation", "labels": [], "entities": [{"text": "POS Tagging", "start_pos": 55, "end_pos": 66, "type": "TASK", "confidence": 0.6936057209968567}]}], "abstractContent": [{"text": "We define the crouching Dirichlet, hidden Markov model (CDHMM), an HMM for part-of-speech tagging which draws state prior distributions for each local document context.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.6968205571174622}]}, {"text": "This simple modification of the HMM takes advantage of the dichotomy in natural language between content and function words.", "labels": [], "entities": []}, {"text": "In contrast, a standard HMM draws all prior distributions once overall states and it is known to perform poorly in unsupervised and semi-supervised POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 148, "end_pos": 159, "type": "TASK", "confidence": 0.7338825166225433}]}, {"text": "This modification significantly improves unsupervised POS tagging performance across several measures on five data sets for four languages.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 54, "end_pos": 65, "type": "TASK", "confidence": 0.8649362027645111}]}, {"text": "We also show that simply using different hyperparameter values for content and function word states in a standard HMM (which we call HMM+) is surprisingly effective.", "labels": [], "entities": []}], "introductionContent": [{"text": "Hidden Markov Models (HMMs) are simple, versatile, and widely-used generative sequence models.", "labels": [], "entities": []}, {"text": "They have been applied to part-of-speech (POS) tagging in supervised), semi-supervised ( and unsupervised training scenarios.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.6147038996219635}]}, {"text": "Though discriminative models achieve better performance in both semi-supervised () and supervised () learning, there has been only limited work on unsupervised discriminative sequence models (e.g., on synthetic data and protein sequences ()), and none to POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 255, "end_pos": 266, "type": "TASK", "confidence": 0.8499757647514343}]}, {"text": "The tagging accuracy of purely unsupervised HMMs is far below that of supervised and semisupervised HMMs; this is unsurprising as it is still not well understood what kind of structure is being found by an unconstrained HMM.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9507902264595032}]}, {"text": "However, HMMs are fairly simple directed graphical models, and it is straightforward to extend them to define alternative generative processes.", "labels": [], "entities": []}, {"text": "This also applies to linguistically motivated HMMs for recovering states and sequences that correspond more closely to those implicitly defined by linguists when they label sentences with parts-of-speech.", "labels": [], "entities": []}, {"text": "One way in which a basic HMM's structure is a poor model for POS tagging is that there is no inherent distinction between (open-class) content words and (closed-class) function words.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 61, "end_pos": 72, "type": "TASK", "confidence": 0.8367534875869751}]}, {"text": "Here, we propose two extensions to the HMM.", "labels": [], "entities": []}, {"text": "The first, HMM+, is a very simple modification where two different hyperparameters are posited for content states and function states, respectively.", "labels": [], "entities": []}, {"text": "The other is the crouching Dirichlet, hidden Markov model (CDHMM), an extended HMM that captures this dichotomy based on the statistical evidence that comes from context.", "labels": [], "entities": []}, {"text": "Content states display greater variance across local context (e.g. sentences, paragraphs, documents), and we capture this variance by adding a component to the model for content states that is based on latent Dirichlet allocation (.", "labels": [], "entities": []}, {"text": "This extension is in some ways similar to the LDAHMM of.", "labels": [], "entities": []}, {"text": "Both models are composite in that two distributions do not mix with each other.", "labels": [], "entities": []}, {"text": "Unlike the LDAHMM, the generation of content states is folded into the CDHMM process.", "labels": [], "entities": []}, {"text": "We compare the HMM+ and CDHMM against a basic HMM and LDAHMM on POS tagging on a more extensive and diverse set of languages than previous work in monolingual unsupervised POS tagging: four languages from three families (Germanic: English and German; Romance: Portuguese; and Mayan: Uspanteko).", "labels": [], "entities": [{"text": "LDAHMM", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.820743203163147}, {"text": "POS tagging", "start_pos": 64, "end_pos": 75, "type": "TASK", "confidence": 0.6767784059047699}]}, {"text": "The CDHMM easily outperforms all other models, including HMM+, across three measures (accuracy, F-score, and variation of information) for unsupervised POS tagging on most data sets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.9991160035133362}, {"text": "F-score", "start_pos": 96, "end_pos": 103, "type": "METRIC", "confidence": 0.9899185299873352}, {"text": "POS tagging", "start_pos": 152, "end_pos": 163, "type": "TASK", "confidence": 0.7929705083370209}]}, {"text": "However, the HMM+ is surprisingly competitive, outperforming the basic HMM and LDAHMM, and rivaling or even passing the CDHMM on some measures and data sets.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use five datasets from four languages (English, German, Portuguese, Uspanteko) for evaluating POS tagging performance.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 97, "end_pos": 108, "type": "TASK", "confidence": 0.8783780038356781}]}, {"text": "\u2022 English: the Brown corpus ( and the Wall Street Journal portion of the Penn Treebank ().", "labels": [], "entities": [{"text": "English: the Brown corpus", "start_pos": 2, "end_pos": 27, "type": "DATASET", "confidence": 0.6697934806346894}, {"text": "Wall Street Journal portion of the Penn Treebank", "start_pos": 38, "end_pos": 86, "type": "DATASET", "confidence": 0.9433425068855286}]}, {"text": "\u2022 German: the Tiger corpus ().", "labels": [], "entities": [{"text": "German: the Tiger corpus", "start_pos": 2, "end_pos": 26, "type": "DATASET", "confidence": 0.7541990637779236}]}, {"text": "\u2022 Portuguese: the full Bosque subset of the Floresta corpus ().", "labels": [], "entities": [{"text": "Bosque subset of the Floresta corpus", "start_pos": 23, "end_pos": 59, "type": "DATASET", "confidence": 0.6716869721810023}]}, {"text": "provides the statistics for these corpora.", "labels": [], "entities": []}, {"text": "We lowercase all words, do not remove any punctuation or hapax legomena, and we do not replace numerals with a single identifier.", "labels": [], "entities": []}, {"text": "Due to the nature of the models, document boundaries are retained.", "labels": [], "entities": []}, {"text": "We report values for three evaluation metrics on all five corpora, using their full tagsets.", "labels": [], "entities": []}, {"text": "\u2022 Accuracy: We use a greedy search algorithm to map each unsupervised tag to a gold label such that accuracy is maximized.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 2, "end_pos": 10, "type": "METRIC", "confidence": 0.9988522529602051}, {"text": "accuracy", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9991543292999268}]}, {"text": "We evaluate on a 1-to-1 mapping between unsupervised tags and gold labels, as well as many-to-1 (M-to-1), corresponding to the evaluation mappings used in.", "labels": [], "entities": []}, {"text": "The 1-to-1 mapping provides a stricter evaluation.", "labels": [], "entities": []}, {"text": "The many-to-one mapping, on the other hand, maybe more adequate as unsupervised tags tend to be more fine-grained than gold part-of-speech tags.", "labels": [], "entities": []}, {"text": "In particular, they tend to form semantically coherent sub-classes of gold parts of speech.", "labels": [], "entities": []}, {"text": "\u2022 Pairwise Precision and Recall: Viewing tagging as a clustering task over tokens, we evaluate pairwise precision (P ) and recall (R) between the model tag sequence (M ) and gold tag sequence (G) by counting the true positives (tp), false positives (f p) and false negatives (f n) between the two and setting P = tp/(tp + f p) and R = tp/(tp + f n).", "labels": [], "entities": [{"text": "Recall", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9733930826187134}, {"text": "Viewing tagging", "start_pos": 33, "end_pos": 48, "type": "TASK", "confidence": 0.8980650007724762}, {"text": "precision", "start_pos": 104, "end_pos": 113, "type": "METRIC", "confidence": 0.7967064380645752}, {"text": "recall (R)", "start_pos": 123, "end_pos": 133, "type": "METRIC", "confidence": 0.9511150121688843}]}, {"text": "tp is the number of token pairs that share a tag in M as well as in G, f p is the number token pairs that share the same tag in M but have different tags in G, and f n is the number token pairs assigned a different tag in M but the same in G (.", "labels": [], "entities": []}, {"text": "We also provide the f -score which is the harmonic mean of P and R.", "labels": [], "entities": [{"text": "f -score", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9150365789731344}]}, {"text": "\u2022 Variation of Information (VI): The variation of information is an information theoretic metric that measures the amount of information lost and gained in going from tag sequence M to G.", "labels": [], "entities": []}, {"text": "It is defined as where H denotes entropy and I mutual information.", "labels": [], "entities": []}, {"text": "noted that this measure can point out models that have more consistent errors in the form of lower VI, even when accuracy figures are the same.", "labels": [], "entities": [{"text": "VI", "start_pos": 99, "end_pos": 101, "type": "METRIC", "confidence": 0.9273104667663574}, {"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9982669353485107}]}, {"text": "We also report learning curves on M-to-1 with geometrically increasing training set sizes of, and all documents, or as many as possible given the corpus.", "labels": [], "entities": []}, {"text": "In this section we discuss our parameter settings and experimental results.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Evaluation for Uspanteko and Floresta. Experiments in this table use state sizes that correspond  more closely to the size of the tag sets in the respective corpora.", "labels": [], "entities": []}]}