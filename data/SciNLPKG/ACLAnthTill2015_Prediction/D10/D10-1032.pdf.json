{"title": [{"text": "Tense Sense Disambiguation: a New Syntactic Polysemy Task", "labels": [], "entities": [{"text": "Tense Sense Disambiguation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.951883594195048}]}], "abstractContent": [{"text": "Polysemy is a major characteristic of natural languages.", "labels": [], "entities": []}, {"text": "Like words, syntactic forms can have several meanings.", "labels": [], "entities": []}, {"text": "Understanding the correct meaning of a syntactic form is of great importance to many NLP applications.", "labels": [], "entities": []}, {"text": "In this paper we address an important type of syntactic polysemy-the multiple possible senses of tense syntactic forms.", "labels": [], "entities": [{"text": "syntactic polysemy-the multiple possible senses of tense syntactic forms", "start_pos": 46, "end_pos": 118, "type": "TASK", "confidence": 0.7191762394375272}]}, {"text": "We make our discussion concrete by introducing the task of Tense Sense Disambiguation (TSD): given a concrete tense syntactic form present in a sentence , select its appropriate sense among a set of possible senses.", "labels": [], "entities": [{"text": "Tense Sense Disambiguation (TSD)", "start_pos": 59, "end_pos": 91, "type": "TASK", "confidence": 0.8184837301572164}]}, {"text": "Using English grammar textbooks, we compiled a syntactic sense dictionary comprising common tense syntactic forms and semantic senses for each.", "labels": [], "entities": []}, {"text": "We annotated thousands of BNC sentences using the defined senses.", "labels": [], "entities": []}, {"text": "We describe a supervised TSD algorithm trained on these annotations, which outperforms a strong baseline for the task.", "labels": [], "entities": [{"text": "TSD", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.8769066333770752}]}], "introductionContent": [{"text": "The function of syntax is to combine words to express meanings, using syntactic devices such as word order, auxiliary words, and morphology.", "labels": [], "entities": []}, {"text": "Virtually all natural language devices used for expressing meanings (e.g., words) exhibit polysemy.", "labels": [], "entities": []}, {"text": "Like words, concrete syntactic forms (the sentence words generated by specific syntactic devices) can have several meanings.", "labels": [], "entities": []}, {"text": "Consider the following sentences: (a) They are playing chess in the park.", "labels": [], "entities": []}, {"text": "(b) They are playing chess next Tuesday.", "labels": [], "entities": []}, {"text": "Both contain the concrete syntactic form 'are playing', generated by the abstract syntactic form usually known as 'present progressive' (am/is/are + Ving).", "labels": [], "entities": []}, {"text": "In (a), the meaning is 'something happening now', while in (b) it is 'a plan to do something in the future'.", "labels": [], "entities": []}, {"text": "Note that the polysemy is of the syntactic form as a unit, not of individual words.", "labels": [], "entities": []}, {"text": "In particular, the verb 'play' is used in the same sense in both cases.", "labels": [], "entities": []}, {"text": "In this paper we address a prominent type of syntactic form polysemy: the multiple possible senses that tense syntactic forms can have.", "labels": [], "entities": []}, {"text": "Disambiguating the polysemy of tense forms is of theoretical and practical importance (Section 2).", "labels": [], "entities": []}, {"text": "To make our discussion concrete, we introduce the task of Tense Sense Disambiguation (TSD): given a concrete tense syntactic form in a sentence, select its correct sense among a given set of possible senses (Section 3).", "labels": [], "entities": [{"text": "Tense Sense Disambiguation (TSD)", "start_pos": 58, "end_pos": 90, "type": "TASK", "confidence": 0.8036716282367706}]}, {"text": "The disambiguation of polysemy is a fundamental problem in NLP.", "labels": [], "entities": []}, {"text": "For example, Word Sense Disambiguation (WSD) continues to attract a large number of researchers ().", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 13, "end_pos": 44, "type": "TASK", "confidence": 0.8097331672906876}]}, {"text": "TSD has the same structure as WSD, with different disambiguated entities.", "labels": [], "entities": [{"text": "TSD", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.71983402967453}]}, {"text": "For experimenting with the TSD task, we compiled an English syntactic sense dictionary based on a thorough study of three major English grammar projects (Section 4).", "labels": [], "entities": [{"text": "TSD task", "start_pos": 27, "end_pos": 35, "type": "TASK", "confidence": 0.9137773513793945}]}, {"text": "We selected 3000 sentences from the British National Corpus containing 4702 concrete syntactic forms, and annotated each of these by its sense (Section 5).We developed a supervised learning TSD algorithm that uses various feature types and takes advantage of the task structure (Section 6).", "labels": [], "entities": [{"text": "British National Corpus", "start_pos": 36, "end_pos": 59, "type": "DATASET", "confidence": 0.9463005264600118}]}, {"text": "Our algorithm substantially outper-forms the 'most frequent sense' baseline (Section 7).", "labels": [], "entities": []}, {"text": "TSD is fundamental to sentence understanding and thus to NLP applications such as textual inference, question answering and information retrieval.", "labels": [], "entities": [{"text": "TSD", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.6413741111755371}, {"text": "sentence understanding", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.822449117898941}, {"text": "question answering", "start_pos": 101, "end_pos": 119, "type": "TASK", "confidence": 0.8786340951919556}, {"text": "information retrieval", "start_pos": 124, "end_pos": 145, "type": "TASK", "confidence": 0.7880700826644897}]}, {"text": "To the best of our knowledge, this is the first paper to address this task.", "labels": [], "entities": []}, {"text": "In Section 8 we discuss research directions relevant to TSD placing the new task in the context of the previous research of syntactic ambiguity resolution.", "labels": [], "entities": [{"text": "TSD", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.9927669763565063}, {"text": "syntactic ambiguity resolution", "start_pos": 124, "end_pos": 154, "type": "TASK", "confidence": 0.719540516535441}]}], "datasetContent": [{"text": "We divided the 3000 annotated sentences (containing 4702 CSFs) to three datasets: training data (2100 sentences, 3183 forms), development data (300 sentences, 498 forms) and test data (600 sentences, 1021 forms).", "labels": [], "entities": []}, {"text": "We used the development data to design the features for our learning model and to tune the parameters of the SNOW sequential model.", "labels": [], "entities": []}, {"text": "In addition we used this data to design the rules of the ASF type classifier (which is not statistical and does not have a training phase).", "labels": [], "entities": [{"text": "ASF type classifier", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.7864537636439005}]}, {"text": "For the POS features, we induced POS tags using the MXPOST POS tagger.", "labels": [], "entities": [{"text": "MXPOST POS tagger", "start_pos": 52, "end_pos": 69, "type": "DATASET", "confidence": 0.846775750319163}]}, {"text": "The tagger was trained on sections 2-21 of the WSJ PennTreebank () annotated with gold standard POS tags.", "labels": [], "entities": [{"text": "tagger", "start_pos": 4, "end_pos": 10, "type": "TASK", "confidence": 0.9685414433479309}, {"text": "WSJ PennTreebank () annotated", "start_pos": 47, "end_pos": 76, "type": "DATASET", "confidence": 0.932163879275322}]}, {"text": "We used a publicly available implementation of the sequential SNOW model 8 . We experimented in three conditions.", "labels": [], "entities": []}, {"text": "In the first (TypeUnknown), the ASF type is not known attest time.", "labels": [], "entities": [{"text": "ASF type", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.7737495005130768}]}, {"text": "In the last two, it is known attest time.", "labels": [], "entities": []}, {"text": "These two conditions differ in whether the type is taken from the gold standard annotation of the test sentences (TypeKnown), or from the output of the simple rule-based classifier (TypeClassifier, see Section 6).", "labels": [], "entities": []}, {"text": "For both conditions, the results reported below are when both ASF type features and possible labels sets are provided during training by the manual annotation.", "labels": [], "entities": []}, {"text": "This is true also for the training of the MFS baseline (see below) . We report an algorithm's quality using accuracy, that is, the number of test CSFs that were correctly resolved by the algorithm divided by the total number of test CSFs.", "labels": [], "entities": [{"text": "MFS baseline", "start_pos": 42, "end_pos": 54, "type": "DATASET", "confidence": 0.708031564950943}, {"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.9990881681442261}]}, {"text": "We compared the performance of our algorithm to the 'most frequent sense' (MFS) base-: Impact of POS features.", "labels": [], "entities": []}, {"text": "When the constrained model is used (left section), POS features have no effect on the results when ASF type information is encoded.", "labels": [], "entities": []}, {"text": "When an unconstrained classifier is used, POS features affect the results both when ASF type features are used and when they are not (see discussion in the text). line.", "labels": [], "entities": []}, {"text": "This baseline is common in semantic disambiguation tasks and is known to be quite strong.", "labels": [], "entities": [{"text": "semantic disambiguation tasks", "start_pos": 27, "end_pos": 56, "type": "TASK", "confidence": 0.8261990944544474}]}, {"text": "In the condition where the ASF type is not known attest time, MFS gives each form in the test set the sense that was the overall most frequent in the training set.", "labels": [], "entities": [{"text": "MFS", "start_pos": 62, "end_pos": 65, "type": "DATASET", "confidence": 0.44787541031837463}]}, {"text": "That is, in this case the baseline gives all test set CSFs the same sense.", "labels": [], "entities": []}, {"text": "When the ASF type is known attest time, MFS gives each test CSF the most frequent sense of that ASF type in the training set.", "labels": [], "entities": [{"text": "MFS", "start_pos": 40, "end_pos": 43, "type": "DATASET", "confidence": 0.6867144703865051}]}, {"text": "That is, in this case all CSFs having the same ASF type get the same sense, and forms of different types are guaranteed to get different senses.", "labels": [], "entities": []}, {"text": "Recall that the condition where ASF type is known attest time is further divided to two conditions.", "labels": [], "entities": [{"text": "ASF type", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.7525236308574677}]}, {"text": "In the TypeKnown condition, MFS selects the most frequent sense of the manually created ASF type, while in the TypeClassifier condition it selects the most frequent sense of the type decided by the rule-based classifier.", "labels": [], "entities": []}, {"text": "In this condition, if the classifier makes a mistake, MFS will necessarily make a mistake as well.", "labels": [], "entities": []}, {"text": "Note that a random baseline which selects a sense for every test CSF from a uniform distribution over the possible senses (103 in our case) would score very poorly.", "labels": [], "entities": []}, {"text": "Results are shown where ASF type is not known attest time (left), when it is decided attest time by a rule-based classifier (middle) and when it is known attest time (right).", "labels": [], "entities": [{"text": "ASF type", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.6348134279251099}]}, {"text": "Our algorithm outperforms the MFS baseline in all three conditions.", "labels": [], "entities": [{"text": "MFS baseline", "start_pos": 30, "end_pos": 42, "type": "DATASET", "confidence": 0.7334898114204407}]}, {"text": "As expected, both our algorithm and the MFS baseline perform better when ASF type information is available attest time (TypeClassifier and TypeKnown conditions), and improve as this data becomes more accurate (the TypeKnown condition) . Analyzing the per-type performance of our algorithm reveals that it outperforms the MFS baseline for each and every ASF type.", "labels": [], "entities": [{"text": "MFS baseline", "start_pos": 40, "end_pos": 52, "type": "DATASET", "confidence": 0.7955817580223083}, {"text": "MFS baseline", "start_pos": 321, "end_pos": 333, "type": "DATASET", "confidence": 0.8277835547924042}]}, {"text": "For example, in the TypeKnown condition, the accuracy gain of our algorithm over the baseline  Below we analyze the roles of the different components of our learning algorithm in performing the TSD task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9991982579231262}, {"text": "TSD task", "start_pos": 194, "end_pos": 202, "type": "TASK", "confidence": 0.8884744346141815}]}, {"text": "Since this is the first exploration of the task, it is important to understand what properties are essential for achieving good performance.", "labels": [], "entities": []}, {"text": "The analysis is done by experimenting with development data, and focuses on the TypeKnown and TypeUnknown conditions.", "labels": [], "entities": [{"text": "TypeKnown", "start_pos": 80, "end_pos": 89, "type": "DATASET", "confidence": 0.8912889361381531}]}, {"text": "Patterns for the TypeClassifier condition are very similar to the patterns for the TypeKnown condition.", "labels": [], "entities": []}, {"text": "We use the learning model of, which allows us to constrain the possible senses an input vector can get to the senses of its ASF type.", "labels": [], "entities": []}, {"text": "We ran our model without this constraint during both training and test time (recall that for the above results, this constraint was always active during training).", "labels": [], "entities": []}, {"text": "In this case, the only difference between the TypeKnown and the TypeUnknown conditions is whether ASF type features are encoded attest time.", "labels": [], "entities": []}, {"text": "In the TypeKnown condition, the accuracy of the algorithm drops from 57.9% (when using training and test time constraints and ASF type features) to 53% (when using only ASF type features but no constraints).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9997614026069641}]}, {"text": "In the TypeUnknown condition, accuracy drops from 57.24% (when using training time constraints) to 48.03% (when neither constraints nor ASF type features are used).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9995390176773071}]}, {"text": "Note that the difference between the constrained model and the unconstrained model is quite large.", "labels": [], "entities": []}, {"text": "The MFS baseline achieves on development data 42.9% and 13.2% in the TypeKnown and TypeUnknown conditions respectively 12 . Thus, the algorithm outperforms the baseline both when the constrained model is used and when an unconstrained multi-class classifier is used.", "labels": [], "entities": []}, {"text": "Note also that when constraints on the possible labels are available at training time, test time constraints and ASF type features (whose inclusion is the difference between the TypeKnown and TypeUnknown) have a minor effect on the results (57.9% for TypeKnown compared to 57.24% for TypeUnknown).", "labels": [], "entities": [{"text": "ASF", "start_pos": 113, "end_pos": 116, "type": "METRIC", "confidence": 0.8546643257141113}, {"text": "TypeKnown", "start_pos": 251, "end_pos": 260, "type": "DATASET", "confidence": 0.8848293423652649}, {"text": "TypeUnknown", "start_pos": 284, "end_pos": 295, "type": "DATASET", "confidence": 0.8566041588783264}]}, {"text": "However, when training time constraints on the possible labels are not available at training time, ASF type features alone do have a significant effect on the result (53% for TypeKnown compared to 48.03% for TypeUnknown).", "labels": [], "entities": [{"text": "TypeKnown", "start_pos": 175, "end_pos": 184, "type": "DATASET", "confidence": 0.883682131767273}, {"text": "TypeUnknown", "start_pos": 208, "end_pos": 219, "type": "DATASET", "confidence": 0.8613264560699463}]}], "tableCaptions": [{"text": " Table 3: Performance of our algorithm and of the MFS  baseline where at test time ASF type is known (right),  unknown (left) or given by a simple rule-based classifier  (middle). Our algorithm is superior in all three condi- tions.", "labels": [], "entities": [{"text": "MFS  baseline", "start_pos": 50, "end_pos": 63, "type": "DATASET", "confidence": 0.8537781834602356}]}, {"text": " Table 4: Impact of POS features. When the constrained  model is used (left section), POS features have no effect  on the results when ASF type information is encoded.  When an unconstrained classifier is used, POS features  affect the results both when ASF type features are used  and when they are not (see discussion in the text).", "labels": [], "entities": []}]}