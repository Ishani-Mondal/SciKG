{"title": [{"text": "Better Punctuation Prediction with Dynamic Conditional Random Fields", "labels": [], "entities": [{"text": "Punctuation Prediction", "start_pos": 7, "end_pos": 29, "type": "TASK", "confidence": 0.6495196670293808}]}], "abstractContent": [{"text": "This paper focuses on the task of inserting punctuation symbols into transcribed conversational speech texts, without relying on prosodic cues.", "labels": [], "entities": [{"text": "inserting punctuation symbols into transcribed conversational speech texts", "start_pos": 34, "end_pos": 108, "type": "TASK", "confidence": 0.6708016730844975}]}, {"text": "We investigate limitations associated with previous methods, and propose a novel approach based on dynamic conditional random fields.", "labels": [], "entities": []}, {"text": "Different from previous work, our proposed approach is designed to jointly perform both sentence boundary and sentence type prediction, and punctuation prediction on speech utterances.", "labels": [], "entities": [{"text": "sentence boundary and sentence type prediction", "start_pos": 88, "end_pos": 134, "type": "TASK", "confidence": 0.5821963747342428}, {"text": "punctuation prediction", "start_pos": 140, "end_pos": 162, "type": "TASK", "confidence": 0.7491701543331146}]}, {"text": "We performed evaluations on a transcribed conversational speech domain consisting of both English and Chinese texts.", "labels": [], "entities": []}, {"text": "Empirical results show that our method outperforms an approach based on linear-chain conditional random fields and other previous approaches.", "labels": [], "entities": []}], "introductionContent": [{"text": "Outputs of standard automatic speech recognition (ASR) systems typically consist of utterances where important linguistic and structural information (e.g., true case, sentence boundaries, punctuation symbols, etc) is not available.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 20, "end_pos": 54, "type": "TASK", "confidence": 0.8270247379938761}]}, {"text": "Such information is crucial in improving the readability of the transcribed speech texts, and plays an important role when further processing is required, such as in part-of-speech (POS) tagging, parsing, information extraction, and machine translation.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging", "start_pos": 166, "end_pos": 194, "type": "TASK", "confidence": 0.6075941622257233}, {"text": "parsing", "start_pos": 196, "end_pos": 203, "type": "TASK", "confidence": 0.9532341361045837}, {"text": "information extraction", "start_pos": 205, "end_pos": 227, "type": "TASK", "confidence": 0.8251522481441498}, {"text": "machine translation", "start_pos": 233, "end_pos": 252, "type": "TASK", "confidence": 0.7872584462165833}]}, {"text": "We focus on the punctuation prediction task in this work.", "labels": [], "entities": [{"text": "punctuation prediction task", "start_pos": 16, "end_pos": 43, "type": "TASK", "confidence": 0.8037797013918558}]}, {"text": "Most previous punctuation prediction techniques, developed mostly by the speech processing community, exploit both lexical and prosodic cues.", "labels": [], "entities": [{"text": "punctuation prediction", "start_pos": 14, "end_pos": 36, "type": "TASK", "confidence": 0.8567180335521698}]}, {"text": "However, in order to fully exploit prosodic features such as pitch and pause duration, it is necessary to have access to the original raw speech waveforms.", "labels": [], "entities": []}, {"text": "In some scenarios where further natural language processing (NLP) tasks on the transcribed speech texts become the main concern, speech prosody information may not be readily available.", "labels": [], "entities": []}, {"text": "For example, in the recent evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT), only manually transcribed or automatically recognized speech texts are provided but the original raw speech waveforms are not available.", "labels": [], "entities": [{"text": "International Workshop on Spoken Language Translation (IWSLT)", "start_pos": 54, "end_pos": 115, "type": "TASK", "confidence": 0.6590094500117831}]}, {"text": "In this paper, we tackle the task of predicting punctuation symbols from a standard text processing perspective, where only the speech texts are available, without relying on additional prosodic features such as pitch and pause duration.", "labels": [], "entities": [{"text": "predicting punctuation symbols", "start_pos": 37, "end_pos": 67, "type": "TASK", "confidence": 0.8959862589836121}]}, {"text": "Specifically, we perform the punctuation prediction task on transcribed conversational speech texts, using the IWSLT corpus as the evaluation data.", "labels": [], "entities": [{"text": "punctuation prediction", "start_pos": 29, "end_pos": 51, "type": "TASK", "confidence": 0.7710464596748352}, {"text": "IWSLT corpus", "start_pos": 111, "end_pos": 123, "type": "DATASET", "confidence": 0.9441412091255188}]}, {"text": "Different from many other corpora such as broadcast news corpora, a conversational speech corpus consists of dialogs where informal and short sentences frequently appear.", "labels": [], "entities": []}, {"text": "In addition, due to the nature of conversation, it also contains more question sentences compared to other corpora.", "labels": [], "entities": []}, {"text": "An example English utterance randomly selected from the IWSLT corpus, along with its punctuated and cased version, are shown below: you are quite welcome and by the way we may get other reservations so could you please callus as soon as you fix the date You are quite welcome . And by the way , we may get other reservations , so could you please callus as soon as you fix the date ? The rest of this paper is organized as follows.", "labels": [], "entities": [{"text": "IWSLT corpus", "start_pos": 56, "end_pos": 68, "type": "DATASET", "confidence": 0.9443439543247223}]}, {"text": "We start with surveying related work in Section 2.", "labels": [], "entities": []}, {"text": "One class of widely-used previous techniques is then studied in detail in Section 3.", "labels": [], "entities": []}, {"text": "Next, we investigate methods for improving existing methods in Section 4 and 5.", "labels": [], "entities": []}, {"text": "Empirical evaluation results are presented and discussed in Section 6.", "labels": [], "entities": []}, {"text": "We finally conclude in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform experiments on part of the corpus of the IWSLT09 evaluation campaign  For the methods based on the hidden event language model, we design extensive experiments due 2 http://www.cis.upenn.edu/\u223ctreebank/tokenization.html to many possible setups.", "labels": [], "entities": [{"text": "IWSLT09 evaluation campaign", "start_pos": 52, "end_pos": 79, "type": "DATASET", "confidence": 0.8725494543711344}]}, {"text": "Specifically, these experiments can be divided into two categories: with or without duplicating the ending punctuation symbol to the start of a sentence before training.", "labels": [], "entities": []}, {"text": "This setting can be used to assess the impact of the proximity between the punctuation symbol and the indicative words for the prediction task.", "labels": [], "entities": []}, {"text": "Under each category, two possible approaches are tried.", "labels": [], "entities": []}, {"text": "The single pass approach performs prediction in one single step, where all the punctuation symbols are predicted sequentially from left to right.", "labels": [], "entities": []}, {"text": "In the cascaded approach, we format the training sentences by replacing all sentence-ending punctuation symbols with special sentence boundary symbols first.", "labels": [], "entities": []}, {"text": "A model for sentence boundary prediction is learned based on such training data.", "labels": [], "entities": [{"text": "sentence boundary prediction", "start_pos": 12, "end_pos": 40, "type": "TASK", "confidence": 0.7322923839092255}]}, {"text": "This step is then followed by predicting the actual punctuation symbols.", "labels": [], "entities": []}, {"text": "Both trigram and 5-gram language models are tried for all combinations of the above settings.", "labels": [], "entities": []}, {"text": "This gives us a total of 8 possible combinations based on the hidden event language model.", "labels": [], "entities": []}, {"text": "When training all the language models, modified Kneser-Ney smoothing for n-grams is used.", "labels": [], "entities": []}, {"text": "To assess the performance of the punctuation prediction task, we compute precision (prec.), recall (rec.), and F1-measure (F 1 ), as defined by the following equations: prec.", "labels": [], "entities": [{"text": "punctuation prediction task", "start_pos": 33, "end_pos": 60, "type": "TASK", "confidence": 0.8275736967722574}, {"text": "precision", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.9988594055175781}, {"text": "recall (rec.)", "start_pos": 92, "end_pos": 105, "type": "METRIC", "confidence": 0.9012808203697205}, {"text": "F1-measure (F 1 )", "start_pos": 111, "end_pos": 128, "type": "METRIC", "confidence": 0.8666301131248474}]}, {"text": "= # Correctly predicted punctuation symbols # predicted punctuation symbols rec.", "labels": [], "entities": []}, {"text": "= # Correctly predicted punctuation symbols # expected punctuation symbols", "labels": [], "entities": [{"text": "Correctly", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9616756439208984}]}], "tableCaptions": [{"text": " Table 3: Statistics of the BTEC and CT datasets", "labels": [], "entities": [{"text": "BTEC and CT datasets", "start_pos": 28, "end_pos": 48, "type": "DATASET", "confidence": 0.7547249048948288}]}, {"text": " Table 4: Punctuation prediction performance on Chinese (CN) and English (EN) texts in the correctly recognized  output of the BTEC dataset. Percentage scores of precision (P rec.), recall (Rec.), and F1 measure (F 1 ) are reported.", "labels": [], "entities": [{"text": "BTEC dataset", "start_pos": 127, "end_pos": 139, "type": "DATASET", "confidence": 0.9855798482894897}, {"text": "precision (P rec.)", "start_pos": 162, "end_pos": 180, "type": "METRIC", "confidence": 0.9415692448616028}, {"text": "recall (Rec.)", "start_pos": 182, "end_pos": 195, "type": "METRIC", "confidence": 0.9657967537641525}, {"text": "F1 measure (F 1 )", "start_pos": 201, "end_pos": 218, "type": "METRIC", "confidence": 0.9472451309363047}]}, {"text": " Table 5: Punctuation prediction performance on Chinese (CN) and English (EN) texts in the correctly recognized  output of the CT dataset. Percentage scores of precision (P rec.), recall (Rec.), and F1 measure (F 1 ) are reported.", "labels": [], "entities": [{"text": "CT dataset", "start_pos": 127, "end_pos": 137, "type": "DATASET", "confidence": 0.8978914320468903}, {"text": "precision (P rec.)", "start_pos": 160, "end_pos": 178, "type": "METRIC", "confidence": 0.9416670083999634}, {"text": "recall (Rec.)", "start_pos": 180, "end_pos": 193, "type": "METRIC", "confidence": 0.9662745594978333}, {"text": "F1 measure (F 1 )", "start_pos": 199, "end_pos": 216, "type": "METRIC", "confidence": 0.9470031360785166}]}, {"text": " Table 6: Punctuation prediction performance on Chinese (CN) and English (EN) texts in the ASR output of IWSLT08  BTEC evaluation dataset. Percentage scores of precision (P rec.), recall (Rec.), and F1 measure (F 1 ) are reported.", "labels": [], "entities": [{"text": "Punctuation prediction", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.6531508266925812}, {"text": "IWSLT08  BTEC evaluation dataset", "start_pos": 105, "end_pos": 137, "type": "DATASET", "confidence": 0.857569009065628}, {"text": "precision (P rec.)", "start_pos": 160, "end_pos": 178, "type": "METRIC", "confidence": 0.9335947394371032}, {"text": "recall (Rec.)", "start_pos": 180, "end_pos": 193, "type": "METRIC", "confidence": 0.9607526510953903}, {"text": "F1 measure (F 1 )", "start_pos": 199, "end_pos": 216, "type": "METRIC", "confidence": 0.9506992697715759}]}, {"text": " Table 7: Translation performance on punctuated ASR outputs using Moses (Averaged percentage scores of BLEU)", "labels": [], "entities": [{"text": "Translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9701898694038391}, {"text": "ASR outputs", "start_pos": 48, "end_pos": 59, "type": "TASK", "confidence": 0.9168680012226105}, {"text": "BLEU", "start_pos": 103, "end_pos": 107, "type": "METRIC", "confidence": 0.9911540150642395}]}]}