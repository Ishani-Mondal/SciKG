{"title": [{"text": "What's with the Attitude? Identifying Sentences with Attitude in Online Discussions", "labels": [], "entities": [{"text": "Identifying Sentences with Attitude in Online Discussions", "start_pos": 26, "end_pos": 83, "type": "TASK", "confidence": 0.8029176337378365}]}], "abstractContent": [{"text": "Mining sentiment from user generated content is a very important task in Natural Language Processing.", "labels": [], "entities": [{"text": "Mining sentiment from user generated content", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.87790846824646}]}, {"text": "An example of such content is threaded discussions which act as a very important tool for communication and collaboration in the Web.", "labels": [], "entities": []}, {"text": "Threaded discussions include e-mails, e-mail lists, bulletin boards, newsgroups, and Internet forums.", "labels": [], "entities": []}, {"text": "Most of the work on sentiment analysis has been centered around finding the sentiment toward products or topics.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.9534364640712738}]}, {"text": "In this work, we present a method to identify the attitude of participants in an online discussion toward one another.", "labels": [], "entities": []}, {"text": "This would enable us to build a signed network representation of participant interaction where every edge has a sign that indicates whether the interaction is positive or negative.", "labels": [], "entities": []}, {"text": "This is different from most of the research on social networks that has focused almost exclusively on positive links.", "labels": [], "entities": []}, {"text": "The method is experimentally tested using a manually labeled set of discussion posts.", "labels": [], "entities": []}, {"text": "The results show that the proposed method is capable of identifying at-titudinal sentences, and their signs, with high accuracy and that it outperforms several other baselines.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9992073178291321}]}], "introductionContent": [{"text": "Mining sentiment from text has a wide range of applications from mining product reviews on the Web ( to analyzing political speeches ().", "labels": [], "entities": [{"text": "Mining sentiment from text", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8591581434011459}]}, {"text": "Automatic methods for sentiment mining are very important because manual extraction of them is very costly, and inefficient.", "labels": [], "entities": [{"text": "sentiment mining", "start_pos": 22, "end_pos": 38, "type": "TASK", "confidence": 0.9762281775474548}]}, {"text": "A new application of sentiment mining is to automatically identify attitudes between participants in an online discussion.", "labels": [], "entities": [{"text": "sentiment mining", "start_pos": 21, "end_pos": 37, "type": "TASK", "confidence": 0.9518735110759735}]}, {"text": "An automatic tool to identify attitudes will enable us to build a signed network representation of participant interaction in which the interaction between two participants is represented using a positive or a negative edge.", "labels": [], "entities": []}, {"text": "Even though using signed edges in social network studies is clearly important, most of the social networks research has focused only on positive links between entities.", "labels": [], "entities": []}, {"text": "Some work has recently investigated signed networks (, however this work was limited to a few number of datasets in which users were allowed to explicitly add negative, as well as positive, relations.", "labels": [], "entities": []}, {"text": "This work will pave the way for research efforts to examine signed social networks in more detail.", "labels": [], "entities": []}, {"text": "It will also allow us to study the relation between explicit relations and the text underlying those relation.", "labels": [], "entities": []}, {"text": "Although similar, identifying sentences that display an attitude in discussions is different from identifying opinionated sentences.", "labels": [], "entities": []}, {"text": "A sentence in a discussion may bear opinions about a definite target (e.g., price of a camera) and yet have no attitude toward the other participants in the discussion.", "labels": [], "entities": []}, {"text": "For instance, in the following discussion Alice's sentence has her opinion against something, yet no attitude toward the recipient of the sentence, Bob.", "labels": [], "entities": []}, {"text": "Alice: \"You know what, he turned out to be a great disappointment\" Bob: \"You are completely unqualified to judge this great person\" However, Bob shows strong attitude toward Alice.", "labels": [], "entities": []}, {"text": "In this work, we look at ways to predict whether a sentence displays an attitude toward the text recipient.", "labels": [], "entities": []}, {"text": "An attitude is the mental position of one participant with regard to another participant.", "labels": [], "entities": []}, {"text": "it could be either positive or negative.", "labels": [], "entities": []}, {"text": "We consider features which takes into account the entire structure of sentences at different levels or generalization.", "labels": [], "entities": []}, {"text": "Those features include lexical items, part-of-speech tags, and dependency relations.", "labels": [], "entities": []}, {"text": "We use all those patterns to build several pairs of models that represent sentences with and without attitude.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we review some of the related prior work on identifying polarized words and subjectivity analysis.", "labels": [], "entities": [{"text": "subjectivity analysis", "start_pos": 89, "end_pos": 110, "type": "TASK", "confidence": 0.732904851436615}]}, {"text": "We explain the problem definition and discuss our approach in.", "labels": [], "entities": []}, {"text": "Finally, in Sections 5 & 6 we introduce our dataset and discuss the experimental setup.", "labels": [], "entities": []}, {"text": "Finally, we conclude in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed experiments on the data described in the previous section.", "labels": [], "entities": []}, {"text": "The number of sentences with an attitude was around 20% of the entire dataset.", "labels": [], "entities": []}, {"text": "The class imbalance caused by the small number of attitude sentences may hurt the performance of the learning algorithm.", "labels": [], "entities": []}, {"text": "A common way of addressing this problem is to artificially rebalance the training data.", "labels": [], "entities": []}, {"text": "To do this we down-sample the majority class by randomly selecting, without replacement, a number of sentences without an attitude that equals the number of sentences with an attitude.", "labels": [], "entities": []}, {"text": "That resulted in a balanced subset, approximately 4000 sentences, that we used in our experiments.", "labels": [], "entities": []}, {"text": "We used Support Vector Machines (SVM) as a classifier.", "labels": [], "entities": []}, {"text": "We optimized SVM separately for every experiment.", "labels": [], "entities": [{"text": "SVM", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.8804905414581299}]}, {"text": "We used 10-fold cross validation for all tests.", "labels": [], "entities": []}, {"text": "We evaluate our results in terms of precision, recall, accuracy, and F1.", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9997698664665222}, {"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9995520710945129}, {"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.9995817542076111}, {"text": "F1", "start_pos": 69, "end_pos": 71, "type": "METRIC", "confidence": 0.9997312426567078}]}, {"text": "Statistical significance was tested using a 2-tailed paired t-test.", "labels": [], "entities": [{"text": "Statistical significance", "start_pos": 0, "end_pos": 24, "type": "METRIC", "confidence": 0.8020097017288208}]}, {"text": "All reported results are statistically significant at the 0.05 level.", "labels": [], "entities": []}, {"text": "We compare the proposed method to several other baselines that will be described in the next subsection.", "labels": [], "entities": []}, {"text": "We also perform experiments to measure the performance if we mix features from the baselines and the proposed method.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Precision, Recall, F1, and Accuracy for the pro- posed method, the baselines, and different combinations  of proposed method and the baselines features", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9994089603424072}, {"text": "Recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9972706437110901}, {"text": "F1", "start_pos": 29, "end_pos": 31, "type": "METRIC", "confidence": 0.9990793466567993}, {"text": "Accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9994321465492249}]}, {"text": " Table 5: Precision, Recall, F1, and Accuracy for different  combinations of the proposed method's features.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9994755387306213}, {"text": "Recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9986627101898193}, {"text": "F1", "start_pos": 29, "end_pos": 31, "type": "METRIC", "confidence": 0.9993320107460022}, {"text": "Accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9996356964111328}]}]}