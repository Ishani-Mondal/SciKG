{"title": [{"text": "Handling Noisy Queries In Cross Language FAQ Retrieval", "labels": [], "entities": [{"text": "Cross Language FAQ Retrieval", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.576862059533596}]}], "abstractContent": [{"text": "Recent times have seen a tremendous growth in mobile based data services that allow people to use Short Message Service (SMS) to access these data services.", "labels": [], "entities": []}, {"text": "Ina multilingual society it is essential that data services that were developed fora specific language be made accessible through other local languages also.", "labels": [], "entities": []}, {"text": "In this paper, we present a service that allows a user to query a Frequently-Asked-Questions (FAQ) database builtin a local language (Hindi) using Noisy SMS En-glish queries.", "labels": [], "entities": []}, {"text": "The inherent noise in the SMS queries, along with the language mismatch makes this a challenging problem.", "labels": [], "entities": []}, {"text": "We handle these two problems by formulating the query similarity over FAQ questions as a combina-torial search problem where the search space consists of combinations of dictionary variations of the noisy query and its top-N translations.", "labels": [], "entities": []}, {"text": "We demonstrate the effectiveness of our approach on a real-life dataset.", "labels": [], "entities": []}], "introductionContent": [{"text": "There has been a tremendous growth in the number of new mobile subscribers in the recent past.", "labels": [], "entities": []}, {"text": "Most of these new subscribers are from developing countries where mobile is the primary information device.", "labels": [], "entities": []}, {"text": "Even for users familiar with computers and the internet, the mobile provides unmatched portability.", "labels": [], "entities": []}, {"text": "This has encouraged the proliferation of information services built around SMS technology.", "labels": [], "entities": []}, {"text": "Several applications, traditionally available on Internet, are now being made available on mobile devices using SMS.", "labels": [], "entities": []}, {"text": "Examples include SMS short code services.", "labels": [], "entities": []}, {"text": "Short codes are numbers where a short message in a predesignated format can be sent to get specific information.", "labels": [], "entities": []}, {"text": "For example, to get the closing stock price of a particular share, the user has to send a message IBMSTOCKPR.", "labels": [], "entities": [{"text": "IBMSTOCKPR", "start_pos": 98, "end_pos": 108, "type": "METRIC", "confidence": 0.717799961566925}]}, {"text": "Other examples are search (), access to Yellow Page services (, Email 1 , Blog 2 , FAQ retrieval 3 etc.", "labels": [], "entities": [{"text": "FAQ retrieval", "start_pos": 83, "end_pos": 96, "type": "TASK", "confidence": 0.5911111384630203}]}, {"text": "The SMS-based FAQ retrieval services use human experts to answer SMS questions.", "labels": [], "entities": [{"text": "FAQ retrieval", "start_pos": 14, "end_pos": 27, "type": "TASK", "confidence": 0.6873462796211243}]}, {"text": "Recent studies have shown that instant messaging is emerging as the preferred mode of communication after speech and email.", "labels": [], "entities": []}, {"text": "Millions of users of instant messaging (IM) services and short message service (SMS) generate electronic content in a dialect that does not adhere to conventional grammar, punctuation and spelling standards.", "labels": [], "entities": []}, {"text": "Words are intentionally compressed by non-standard spellings, abbreviations and phonetic transliteration are used.", "labels": [], "entities": []}, {"text": "Typical question answering systems are built for use with languages which are free from such errors.", "labels": [], "entities": [{"text": "question answering", "start_pos": 8, "end_pos": 26, "type": "TASK", "confidence": 0.8953628242015839}]}, {"text": "It is difficult to build an automated question answering system around SMS technology.", "labels": [], "entities": [{"text": "question answering", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.7685093283653259}]}, {"text": "This is true even for questions whose answers are well documented like in a Frequently-Asked-Questions (FAQ) database.", "labels": [], "entities": []}, {"text": "Unlike other automatic question answering systems that focus on searching answers from a given text collection, Q&A archive ( or the Web (), in a FAQ database the questions and answers are already pro- vided by an expert.", "labels": [], "entities": [{"text": "question answering", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.7463680505752563}]}, {"text": "The main task is then to identify the best matching question to retrieve the relevant answer) (.", "labels": [], "entities": []}, {"text": "The high level of noise in SMS queries makes this a difficult problem (.", "labels": [], "entities": []}, {"text": "Ina multilingual setting this problem is even more formidable.", "labels": [], "entities": []}, {"text": "Natural language FAQ services built for users in one language cannot be accessed in another language.", "labels": [], "entities": []}, {"text": "In this paper we present a FAQ-based question answering system over a SMS interface that solves this problem for two languages.", "labels": [], "entities": [{"text": "FAQ-based question answering", "start_pos": 27, "end_pos": 55, "type": "TASK", "confidence": 0.7043950160344442}]}, {"text": "We allow the FAQ to be in one language and the SMS query to be in another.", "labels": [], "entities": [{"text": "FAQ", "start_pos": 13, "end_pos": 16, "type": "DATASET", "confidence": 0.601353108882904}]}, {"text": "Multi-lingual question answering and information retrieval has been studied in the past.", "labels": [], "entities": [{"text": "Multi-lingual question answering", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6512560447057089}, {"text": "information retrieval", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.8000804781913757}]}, {"text": "Such systems resort to machine translation so that the search can be performed over a single language space.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 23, "end_pos": 42, "type": "TASK", "confidence": 0.7553573846817017}]}, {"text": "In the two language setting, it involves building a machine translation system engine and using it such that the question answering system built fora single language can be used.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.7195557653903961}, {"text": "question answering", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.7178655862808228}]}, {"text": "Typical statistical machine translation systems use large parallel corpora to learn the translation probabilities (.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 8, "end_pos": 39, "type": "TASK", "confidence": 0.6268994708855947}]}, {"text": "Traditionally such corpora have consisted of news articles and other well written articles.", "labels": [], "entities": []}, {"text": "Since the translation systems are not trained on SMS language they perform very poorly when translating noisy SMS language.", "labels": [], "entities": []}, {"text": "Parallel corpora comprising noisy sentences in one language and clean sentences in another language are not available and it would be hard to build such large parallel corpora to train a machine translation system.", "labels": [], "entities": []}, {"text": "There exists some work to remove noise from SMS (.", "labels": [], "entities": []}, {"text": "However, all of these techniques require an aligned corpus of SMS and conventional language for training.", "labels": [], "entities": []}, {"text": "Such data is extremely hard to create.", "labels": [], "entities": []}, {"text": "Unsupervised techniques require huge amounts of SMS data to learn mappings of nonstandard words to their corresponding conventional form ().", "labels": [], "entities": []}, {"text": "Removal of noise from SMS without the use of parallel data has been studied but the methods used are highly dependent on the language model and the degree of noise present in the SMS ().", "labels": [], "entities": []}, {"text": "These systems are not very effective if the SMSes contain grammatical errors (or the system would require large amounts of training data in the language model to be able to deal with all possible types of noise) in addition to misspellings etc.", "labels": [], "entities": []}, {"text": "Thus, the translation of a cleaned SMS, into a second language, will not be very accurate and it would not give good results if such a translated SMS is used to query an FAQ collection.", "labels": [], "entities": [{"text": "FAQ collection", "start_pos": 170, "end_pos": 184, "type": "TASK", "confidence": 0.5351101011037827}]}, {"text": "Token based noise-correction techniques (such as those using edit-distance, LCS etc) cannot be directly applied to handle the noise present in the SMS query.", "labels": [], "entities": []}, {"text": "These noise-correction methods return a list of candidate terms fora given noisy token (E.g. 'gud' \u2212 > 'god','good','guide' ) . Considering all these candidate terms and their corresponding translations drastically increase the search space for any multi-lingual IR system.", "labels": [], "entities": []}, {"text": "Also , naively replacing the noisy token in the SMS query with the top matching candidate term gives poor performance as shown by our experiments.", "labels": [], "entities": []}, {"text": "Our algorithm handles these and related issues in an efficient manner.", "labels": [], "entities": []}, {"text": "In this paper we address the challenges arising when building across language FAQ-based question answering system over an SMS interface.", "labels": [], "entities": [{"text": "FAQ-based question answering", "start_pos": 78, "end_pos": 106, "type": "TASK", "confidence": 0.6807213028271993}]}, {"text": "Our method handles noisy representation of questions in a source language to retrieve answers across target languages.", "labels": [], "entities": []}, {"text": "The proposed method does not require hand corrected data or an aligned corpus for explicit SMS normalization to mitigate the effects of noise.", "labels": [], "entities": [{"text": "SMS normalization", "start_pos": 91, "end_pos": 108, "type": "TASK", "confidence": 0.7903186082839966}]}, {"text": "It also works well with grammatical noise.", "labels": [], "entities": []}, {"text": "To the best of our knowledge we are the first to address issues in noisy SMS based cross-language FAQ retrieval.", "labels": [], "entities": [{"text": "FAQ retrieval", "start_pos": 98, "end_pos": 111, "type": "TASK", "confidence": 0.8278729915618896}]}, {"text": "We propose an efficient algorithm that can handle noise in the form of lexical and semantic corruptions in the source language.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate our system we used noisy English SMS queries to query a collection of 10, 000 Hindi FAQs.", "labels": [], "entities": []}, {"text": "These FAQs were collected from websites of various government organizations and other online resources.", "labels": [], "entities": []}, {"text": "These FAQs are related to railway reservation, railway enquiry, passport application and health related issues.", "labels": [], "entities": [{"text": "FAQs", "start_pos": 6, "end_pos": 10, "type": "METRIC", "confidence": 0.9074387550354004}, {"text": "railway reservation", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.757917732000351}, {"text": "railway enquiry", "start_pos": 47, "end_pos": 62, "type": "TASK", "confidence": 0.7467099130153656}, {"text": "passport application", "start_pos": 64, "end_pos": 84, "type": "TASK", "confidence": 0.6309059113264084}]}, {"text": "For our experiments we asked 6 human evaluators, proficient in both English and Hindi, to create English SMS queries based on the general topics that our FAQ collection dealt with.", "labels": [], "entities": [{"text": "FAQ collection", "start_pos": 154, "end_pos": 168, "type": "DATASET", "confidence": 0.8508561551570892}]}, {"text": "We found 60 SMS queries created by the evaluators, had answers in our FAQ collection and we designated these as the in-domain queries.", "labels": [], "entities": [{"text": "FAQ collection", "start_pos": 70, "end_pos": 84, "type": "DATASET", "confidence": 0.8899571597576141}]}, {"text": "To measure the effectiveness of our system in handling out of domain queries we used a total of 380 SMSes part of which were taken from the NUS corpus ( whch metro statn z nr pragati maidan ? dus metro goes frm airpot 2 new delhi rlway statn? is dere any special metro pas 4 delhi uni students?", "labels": [], "entities": [{"text": "NUS corpus", "start_pos": 140, "end_pos": 150, "type": "DATASET", "confidence": 0.9816768765449524}]}, {"text": "whn is d last train of delhi metro?", "labels": [], "entities": []}, {"text": "whr rd auto stands N delhi?", "labels": [], "entities": []}, {"text": "Our objective was to retrieve the correct Hindi FAQ response given a noisy English SMS query.", "labels": [], "entities": [{"text": "Hindi FAQ response", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.4307182530562083}]}, {"text": "A given English SMS query was matched against the list of indexed FAQs and the best matching FAQ was returned by the Pruning Algorithm described in Section 5.", "labels": [], "entities": [{"text": "FAQ", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.8893473744392395}]}, {"text": "A score of 1 was assigned if the retrieved answer was indeed the response to the posed SMS query else we assigned a score of 0.", "labels": [], "entities": []}, {"text": "In case of out of domain queries a score of 1 was assigned if the output was NULL else we assigned a score of 0.", "labels": [], "entities": []}, {"text": "We perform three sets of experiments to show how each stage of the algorithm contributes in improving the overall results.", "labels": [], "entities": []}, {"text": "For Experiment 1 the threshold \u03c6 in Equation 5 is set to 1 i.e. we consider only those tokens in the query which belong to the dictionary.", "labels": [], "entities": [{"text": "\u03c6", "start_pos": 31, "end_pos": 32, "type": "METRIC", "confidence": 0.9059515595436096}]}, {"text": "This setup illustrates the case when no noise handling is done.", "labels": [], "entities": []}, {"text": "The results are reported in.", "labels": [], "entities": []}, {"text": "For Experiment 2 the noisy SMS query was cleaned using the following approach.", "labels": [], "entities": []}, {"text": "Given a noisy token in the SMS query it's similarity (Equation 1) with each word in the Dictionary is calculated.", "labels": [], "entities": [{"text": "similarity", "start_pos": 42, "end_pos": 52, "type": "METRIC", "confidence": 0.9918437600135803}, {"text": "Equation 1)", "start_pos": 54, "end_pos": 65, "type": "METRIC", "confidence": 0.9633501370747884}]}, {"text": "The noisy token is replaced with the Dictionary word with the maximum similarity score.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 70, "end_pos": 86, "type": "METRIC", "confidence": 0.9296446442604065}]}, {"text": "This gives us a clean English query.", "labels": [], "entities": []}, {"text": "For each token in the cleaned English SMS query, we create a list of possible Hindi translations of the token using the statistical translation table.", "labels": [], "entities": []}, {"text": "Each Hindi word was assigned a weight according to Equation 4.", "labels": [], "entities": [{"text": "Equation", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9672389626502991}]}, {"text": "The Pruning algorithm in Section 5 was then applied to get the best matching FAQ.", "labels": [], "entities": [{"text": "Pruning", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.909695029258728}, {"text": "FAQ", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.6756749749183655}]}, {"text": "In this experiment, for each token in the noisy English SMS we obtain a list of possible English variations.", "labels": [], "entities": []}, {"text": "For each English variation a corresponding set of Hindi words from the statistical translation table was obtained.", "labels": [], "entities": []}, {"text": "Each Hindi word was assigned a weight according to Equation 4.", "labels": [], "entities": [{"text": "Equation", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9672389626502991}]}, {"text": "As described in Section 5.2, all Hindi words obtained from English variations of a given SMS token are merged to create   The Pruning algorithm as described in Section 5 was then applied to get the best matching FAQ.", "labels": [], "entities": [{"text": "FAQ", "start_pos": 212, "end_pos": 215, "type": "METRIC", "confidence": 0.6934241056442261}]}, {"text": "We evaluated our system using two different criteria.", "labels": [], "entities": []}, {"text": "We used MRR (Mean reciprocal rank) and the best matching accuracy.", "labels": [], "entities": [{"text": "MRR", "start_pos": 8, "end_pos": 11, "type": "METRIC", "confidence": 0.9943683743476868}, {"text": "Mean reciprocal rank)", "start_pos": 13, "end_pos": 34, "type": "METRIC", "confidence": 0.9263469129800797}, {"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.8593605160713196}]}, {"text": "Mean reciprocal rank is used to evaluate a system by producing a list of possible responses to a query, ordered by probability of correctness.", "labels": [], "entities": [{"text": "Mean reciprocal rank", "start_pos": 0, "end_pos": 20, "type": "METRIC", "confidence": 0.7802637815475464}]}, {"text": "The reciprocal rank of a query response is the multiplicative inverse of the rank of the first correct answer.", "labels": [], "entities": []}, {"text": "The mean reciprocal rank is the average of the reciprocal ranks of results fora sample of queries Q.", "labels": [], "entities": [{"text": "mean reciprocal rank", "start_pos": 4, "end_pos": 24, "type": "METRIC", "confidence": 0.735040416320165}]}, {"text": "Best match accuracy can be considered as a special case of MRR where the size of the ranked list is 1.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.9855470657348633}, {"text": "MRR", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.6805340051651001}]}, {"text": "As the SMS based FAQ retrieval system will be used via mobile phones where screen size is a major constraint it is crucial to have the correct result on the top.", "labels": [], "entities": [{"text": "FAQ retrieval", "start_pos": 17, "end_pos": 30, "type": "TASK", "confidence": 0.7668449282646179}]}, {"text": "Hence in our settings the best match accuracy is a more relevant and stricter performance evaluation measure than MRR.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 37, "end_pos": 45, "type": "METRIC", "confidence": 0.9143056273460388}, {"text": "MRR", "start_pos": 114, "end_pos": 117, "type": "METRIC", "confidence": 0.791281521320343}]}, {"text": "compares the MRR scores for all three experiments.", "labels": [], "entities": [{"text": "MRR", "start_pos": 13, "end_pos": 16, "type": "METRIC", "confidence": 0.9249774813652039}]}, {"text": "Our method reports the highest MRR of 0.83.", "labels": [], "entities": [{"text": "MRR", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.9992038607597351}]}, {"text": "shows the performance using the strict evaluation criterion of the top result returned being correct.", "labels": [], "entities": []}, {"text": "We also experimented with different values of the threshold for Score(Q) (Section 5.3).", "labels": [], "entities": [{"text": "Score(Q)", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9380076974630356}]}, {"text": "The ROC curve for various threshold is shown in.", "labels": [], "entities": [{"text": "ROC", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9959088563919067}]}, {"text": "The result for both in-domain and out-of-domain queries for the three experiments are shown in for Score(Q) = 8.", "labels": [], "entities": [{"text": "Score(Q)", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9466442465782166}]}, {"text": "The F1 Score for experiments 1, 2 and 3 are shown in.", "labels": [], "entities": [{"text": "F1 Score", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9701421558856964}]}], "tableCaptions": [{"text": " Table 3: Perplexity for Cleaned and Noisy SMS", "labels": [], "entities": [{"text": "Perplexity", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.8990347385406494}]}]}