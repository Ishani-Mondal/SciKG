{"title": [{"text": "Cross Language Text Classification by Model Translation and Semi-Supervised Learning", "labels": [], "entities": [{"text": "Cross Language Text Classification", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7664060145616531}, {"text": "Model Translation", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.7462761998176575}]}], "abstractContent": [{"text": "In this paper, we introduce a method that automatically builds text classifiers in anew language by training on already labeled data in another language.", "labels": [], "entities": []}, {"text": "Our method transfers the classification knowledge across languages by translating the model features and by using an Expectation Maximization (EM) algorithm that naturally takes into account the ambiguity associated with the translation of a word.", "labels": [], "entities": []}, {"text": "We further exploit the readily available un-labeled data in the target language via semi-supervised learning, and adapt the translated model to better fit the data distribution of the target language.", "labels": [], "entities": []}], "introductionContent": [{"text": "Given the accelerated growth of the number of multilingual documents on the Web and elsewhere, the need for effective multilingual and cross-lingual text processing techniques is becoming increasingly important.", "labels": [], "entities": []}, {"text": "There is a growing number of methods that use data available in one language to build text processing tools for another language, for diverse tasks such as word sense disambiguation (, syntactic parsing (), information retrieval (), subjectivity analysis (, and others.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 156, "end_pos": 181, "type": "TASK", "confidence": 0.6714302698771158}, {"text": "syntactic parsing", "start_pos": 185, "end_pos": 202, "type": "TASK", "confidence": 0.7121048718690872}, {"text": "information retrieval", "start_pos": 207, "end_pos": 228, "type": "TASK", "confidence": 0.8050224781036377}, {"text": "subjectivity analysis", "start_pos": 233, "end_pos": 254, "type": "TASK", "confidence": 0.7192369997501373}]}, {"text": "In this paper, we address the task of cross-lingual text classification (CLTC), which builds text classifiers for multiple languages by using training data in one language, thereby avoiding the costly and timeconsuming process of labeling training data for each individual language.", "labels": [], "entities": [{"text": "cross-lingual text classification (CLTC)", "start_pos": 38, "end_pos": 78, "type": "TASK", "confidence": 0.7564602941274643}]}, {"text": "The main idea underlying our approach to CLTC is that although content can be expressed in different forms in different languages, there is a significant amount of knowledge that is shared for similar topics that can be effectively used to port topic classifiers across languages.", "labels": [], "entities": []}, {"text": "Previous methods for CLTC relied mainly on machine translation, by translating the training data into the language of the test data or vice versa, so that both training and test data belong to the same language.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.7239623218774796}]}, {"text": "Monolingual text classification algorithms can then be applied on these translated data.", "labels": [], "entities": [{"text": "text classification", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.7298420667648315}]}, {"text": "Although intuitive, these methods suffer from two major drawbacks.", "labels": [], "entities": []}, {"text": "First, most off-the-shelf machine translation systems typically generate only their best translation fora given text.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.7287520468235016}]}, {"text": "Since machine translation is known to be a notoriously hard problem, applying monolingual text classification algorithms directly on the erroneous translation of training or test data may severely deteriorate the classification accuracy.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 6, "end_pos": 25, "type": "TASK", "confidence": 0.7834088206291199}, {"text": "text classification", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.7509826123714447}, {"text": "accuracy", "start_pos": 228, "end_pos": 236, "type": "METRIC", "confidence": 0.7822450399398804}]}, {"text": "Second, similar to domain adaptation in statistical machine learning, due to the discrepancy of data distribution between the training domain and test domain, data distribution across languages may vary because of the difference of culture, people's interests, linguistic expression in different language regions.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 19, "end_pos": 36, "type": "TASK", "confidence": 0.7456724643707275}]}, {"text": "So even if the translation of training or test data is perfectly correct, the cross language classifier may not perform as well as the monolingual one trained and tested on the data from the same language.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew approach to CLTC, which trains a classification model in the source language and ports the model to the target language, with the translation knowledge learned using the EM algorithm.", "labels": [], "entities": []}, {"text": "Unlike previous methods based on machine translation), our method takes into account dif-ferent possible translations for model features.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.7256984412670135}]}, {"text": "The translated model serves as an initial classifier fora semi-supervised process, by which the model is further adjusted to fit the distribution of the target language.", "labels": [], "entities": []}, {"text": "Our method does not require any labeled data in the target language, nor a machine translation system.", "labels": [], "entities": []}, {"text": "Instead, the only requirement is a reasonable amount of unlabeled data in the target language, which is often easy to obtain.", "labels": [], "entities": []}, {"text": "In the following sections, we first review related work.", "labels": [], "entities": []}, {"text": "In section 3, we introduce our method that translates the classification model with the translation knowledge learned using the EM algorithm.", "labels": [], "entities": []}, {"text": "Section 4 describes model adaptation by training the translated model with unlabeled documents in the target language.", "labels": [], "entities": [{"text": "model adaptation", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.7522921860218048}]}, {"text": "Experiments and evaluations are presented in section 5 and finally we conclude the paper in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the effectiveness of our method, we carryout several experiments.", "labels": [], "entities": []}, {"text": "First, we compare the performance of our method on five different categories, from five different domains, in order to see its generality and applicability on different domains.", "labels": [], "entities": []}, {"text": "We also run experiments with two different language pairs -English-Chinese and English-French -to see if the distance between language families influences the effectiveness of our method.", "labels": [], "entities": []}, {"text": "To determine the performance of the method with respect to other approaches, we compare the classification accuracy with that of a machine translation approach that translates the training (test) data from the source language to the target language, as well as with a classifier trained on monolingual training data in the target language.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.8009945750236511}]}, {"text": "Finally, we evaluate the performance of each of the two steps of our proposed method.", "labels": [], "entities": []}, {"text": "First, we evaluate the model translated with the parameters learned with EM, and then the model after the semisupervised learning for data distribution adaptation with different parameters, including the number of iterations and different amounts of unlabeled data.", "labels": [], "entities": [{"text": "EM", "start_pos": 73, "end_pos": 75, "type": "METRIC", "confidence": 0.8734232187271118}, {"text": "data distribution adaptation", "start_pos": 134, "end_pos": 162, "type": "TASK", "confidence": 0.6286030610402426}]}], "tableCaptions": [{"text": " Table 1: number of documents in each class", "labels": [], "entities": []}, {"text": " Table 2: Comparison of different methods for model  translation", "labels": [], "entities": [{"text": "model  translation", "start_pos": 46, "end_pos": 64, "type": "TASK", "confidence": 0.7288857400417328}]}, {"text": " Table 3: Comparison of different methods and different language pairs", "labels": [], "entities": []}]}