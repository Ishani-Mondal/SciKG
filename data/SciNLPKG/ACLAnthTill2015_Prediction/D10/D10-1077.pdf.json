{"title": [{"text": "Enhancing domain portability of Chinese segmentation model using chi-square statistics and bootstrapping", "labels": [], "entities": []}], "abstractContent": [{"text": "Almost all Chinese language processing tasks involve word segmentation of the language input as their first steps, thus robust and reliable segmentation techniques are always required to make sure those tasks well-performed.", "labels": [], "entities": [{"text": "Chinese language processing", "start_pos": 11, "end_pos": 38, "type": "TASK", "confidence": 0.6307624578475952}, {"text": "word segmentation", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.7080773413181305}]}, {"text": "In recent years, machine learning and sequence labeling models such as Conditional Random Fields (CRFs) are often used in segmenting Chinese texts.", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 38, "end_pos": 55, "type": "TASK", "confidence": 0.6398106217384338}, {"text": "segmenting Chinese texts", "start_pos": 122, "end_pos": 146, "type": "TASK", "confidence": 0.8939143220583597}]}, {"text": "Compared with traditional lexicon-driven models, machine learned models achieve higher F-measure scores.", "labels": [], "entities": [{"text": "F-measure scores", "start_pos": 87, "end_pos": 103, "type": "METRIC", "confidence": 0.9718128442764282}]}, {"text": "But machine learned models heavily depend on training materials.", "labels": [], "entities": []}, {"text": "Although they can effectively process texts from the same domain as the training texts, they perform relatively poorly when texts from new domains are to be processed.", "labels": [], "entities": []}, {"text": "In this paper, we propose to use \u03c7 2 statistics when training an SVM-HMM based segmentation model to improve its ability to recall OOV words and then use bootstrapping strategies to maintain its ability to recall IV words.", "labels": [], "entities": []}, {"text": "Experiments show the approach proposed in this paper enhances the domain portability of the Chinese word segmentation model and prevents drastic decline in performance when processing texts across domains.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 92, "end_pos": 117, "type": "TASK", "confidence": 0.6123077670733134}]}], "introductionContent": [{"text": "Chinese word segmentation plays a fundamental role in Chinese language processing tasks, because almost all Chinese language processing tasks are assumed to work with segmented input.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.5872308611869812}, {"text": "Chinese language processing tasks", "start_pos": 54, "end_pos": 87, "type": "TASK", "confidence": 0.7381591722369194}]}, {"text": "After intensive research for more than twenty years, the performance of Chinese segmentation made considerable progress.", "labels": [], "entities": [{"text": "Chinese segmentation", "start_pos": 72, "end_pos": 92, "type": "TASK", "confidence": 0.6782479584217072}]}, {"text": "The bakeoff series hosted by the Chinese Information Processing Society (CIPS) and ACL SIGHAN shows that an F measure of 0.95 can be achieved in the closed test tracks, in which only specified training materials can be used in learning segmentation models . Traditional word segmentation approaches are lexicon-driven and assume predefined lexicons of Chinese words are available.", "labels": [], "entities": [{"text": "F measure", "start_pos": 108, "end_pos": 117, "type": "METRIC", "confidence": 0.9942406713962555}, {"text": "word segmentation", "start_pos": 270, "end_pos": 287, "type": "TASK", "confidence": 0.7416055202484131}]}, {"text": "Segmentation results are obtained by finding a best match between the input texts and the lexicons.", "labels": [], "entities": []}, {"text": "Such lexicon-driven approaches can be rule-based, statistic-based or in some hybrid form.", "labels": [], "entities": []}, {"text": "proposed a novel way of segmenting Chinese texts, and it views the Chinese word segmentation task as a character tagging task.", "labels": [], "entities": [{"text": "segmenting Chinese texts", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.8840534090995789}, {"text": "Chinese word segmentation task", "start_pos": 67, "end_pos": 97, "type": "TASK", "confidence": 0.7149995565414429}, {"text": "character tagging task", "start_pos": 103, "end_pos": 125, "type": "TASK", "confidence": 0.7803642551104227}]}, {"text": "According to Xue's approach, no predefined Chinese lexicons are required; a tagging model is learned by using manually segmented training texts.", "labels": [], "entities": []}, {"text": "The model is then used to assign each character a tag indicating the position of this character within a word.", "labels": [], "entities": []}, {"text": "Xue's approach has become the most popular approach to Chinese word segmentation for its high performance and unified way of dealing with out-of-vocabulary (OOV) issues.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 55, "end_pos": 80, "type": "TASK", "confidence": 0.6034421622753143}]}, {"text": "Most segmentation work began to follow this approach later.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 5, "end_pos": 17, "type": "TASK", "confidence": 0.9769129753112793}]}, {"text": "Major improvements in this line of research include: 1) More sophisticated learning models were introduced other than the maximum entropy model that Xue used, such as the conditional random fields (CRFs) model which fits the sequence tagging tasks much better than the maximum entropy model ().", "labels": [], "entities": [{"text": "sequence tagging tasks", "start_pos": 225, "end_pos": 247, "type": "TASK", "confidence": 0.7506856322288513}]}, {"text": "2) More tags were in-troduced, as shows 6 tags are superior to 4 tags.", "labels": [], "entities": []}, {"text": "3) New feature templates were added, such as the templates that were used in representing numbers, dates, letters etc.", "labels": [], "entities": []}, {"text": "( Character tagging approaches require manually segmented training texts to learn models usually in a supervised way.", "labels": [], "entities": [{"text": "Character tagging", "start_pos": 2, "end_pos": 19, "type": "TASK", "confidence": 0.8176172375679016}]}, {"text": "The performance is always evaluated on a test set from the same domain as the training set.", "labels": [], "entities": []}, {"text": "Such evaluation does not reveal its ability to deal with domain variation.", "labels": [], "entities": []}, {"text": "Actually, when test set is from other domains than the domain where training set is from, the learned model normally underperforms substantially.", "labels": [], "entities": []}, {"text": "One of the main reasons of such performance degradation lies in the model's ability to cope with OOV words.", "labels": [], "entities": []}, {"text": "Actually, even when the test set has the same domain properties as the training set, the ability of the model to recall OOV words is still the main obstacle to achieve better performance of segmentation.", "labels": [], "entities": []}, {"text": "However, when the test set is different with the training set in nature, the OOV recall normally drops much more substantially, and becomes much lower.", "labels": [], "entities": [{"text": "OOV", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.9968892931938171}, {"text": "recall", "start_pos": 81, "end_pos": 87, "type": "METRIC", "confidence": 0.6493284702301025}]}, {"text": "Apart from the supervised approach, proposed an unsupervised way of Chinese word segmentation.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 68, "end_pos": 93, "type": "TASK", "confidence": 0.5875001847743988}]}, {"text": "The approach did not use any predefined lexicons or segmented texts.", "labels": [], "entities": []}, {"text": "A statistic named as md, combining the mutual information and t score, was proposed to measure whether a string of characters forms word.", "labels": [], "entities": []}, {"text": "The unsupervised nature of the approach means good ability to deal with domain variation.", "labels": [], "entities": []}, {"text": "However, the approach did not show a segmentation performance as good as that of the supervised approach.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 37, "end_pos": 49, "type": "TASK", "confidence": 0.959457278251648}]}, {"text": "The approach was not evaluated in F measurement, but inaccuracy of word break prediction.", "labels": [], "entities": [{"text": "F measurement", "start_pos": 34, "end_pos": 47, "type": "METRIC", "confidence": 0.9796058535575867}, {"text": "word break prediction", "start_pos": 67, "end_pos": 88, "type": "TASK", "confidence": 0.7458731134732565}]}, {"text": "As their experiment showed, the approach successfully predicted 85.88% of the word breaks, which is much lower than that of the character tagging approach if in terms of F measurement.", "labels": [], "entities": [{"text": "character tagging", "start_pos": 128, "end_pos": 145, "type": "TASK", "confidence": 0.79234379529953}, {"text": "F measurement", "start_pos": 170, "end_pos": 183, "type": "METRIC", "confidence": 0.9855199754238129}]}, {"text": "Aiming at preventing the OOV recall from dropping sharply and still maintaining an overall performance as good as that of the state-of-art segmenter when working with heterogeneous test sets, we propose in this paper to use a semisupervised way for Chinese word segmentation task.", "labels": [], "entities": [{"text": "OOV", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.9714478850364685}, {"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.5947744846343994}, {"text": "Chinese word segmentation task", "start_pos": 249, "end_pos": 279, "type": "TASK", "confidence": 0.7231555432081223}]}, {"text": "Specifically, we propose to use \u03c7 2 statistics together with bootstrapping strategies to build Chinese word segmentation model.", "labels": [], "entities": [{"text": "Chinese word segmentation", "start_pos": 95, "end_pos": 120, "type": "TASK", "confidence": 0.5540936688582102}]}, {"text": "The experiment shows the approach can effectively promote the OOV recall and lead to a higher overall performance.", "labels": [], "entities": [{"text": "OOV", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.6510197520256042}, {"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.8144705891609192}]}, {"text": "In addition, instead of using the popular CRF model, we use another sequence labeling model in this paper ---the hidden Markov Support Vector Machines (SVM-HMM).", "labels": [], "entities": []}, {"text": "We just wish to show that there are alternatives other than CRF model to use and comparable results can be obtained.", "labels": [], "entities": []}, {"text": "Our work differs from the previous supervised work in its ability to cope with domain variation and differs from the previous unsupervised work in its much better overall segmentation performance.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows: In section 2, we give a brief introduction to the hidden Markov Support Vector Machines, on which we rely to build the segmentation model.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 166, "end_pos": 178, "type": "TASK", "confidence": 0.9627394676208496}]}, {"text": "In section 3, we list the segmentation tags and the basic feature templates we used in the paper.", "labels": [], "entities": []}, {"text": "In section 4 we show how \u03c7 2 statistics can be encoded as features to promote OOV recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.6816006898880005}]}, {"text": "In section 5 we give the bootstrapping strategy.", "labels": [], "entities": []}, {"text": "In section 6, we report the experiments and in section 7 we present our conclusions.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}