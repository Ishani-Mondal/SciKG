{"title": [{"text": "Learning Recurrent Event Queries for Web Search", "labels": [], "entities": []}], "abstractContent": [{"text": "Recurrent event queries (REQ) constitute a special class of search queries occurring at regular, predictable time intervals.", "labels": [], "entities": [{"text": "Recurrent event queries (REQ)", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7909700771172842}]}, {"text": "The freshness of documents ranked for such queries is generally of critical importance.", "labels": [], "entities": []}, {"text": "REQ forms a significant volume, as much as 6% of query traffic received by search engines.", "labels": [], "entities": [{"text": "REQ", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.6324009299278259}]}, {"text": "In this work, we develop an improved REQ classi-fier that could provide significant improvements in addressing this problem.", "labels": [], "entities": [{"text": "REQ", "start_pos": 37, "end_pos": 40, "type": "METRIC", "confidence": 0.5497077703475952}]}, {"text": "We analyze REQ queries, and develop novel features from multiple sources, and evaluate them using machine learning techniques.", "labels": [], "entities": [{"text": "REQ queries", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.7618314921855927}]}, {"text": "From historical query logs, we develop features utilizing query frequency, click information, and user intent dynamics within a search session.", "labels": [], "entities": []}, {"text": "We also develop temporal features by time series analysis from query frequency.", "labels": [], "entities": []}, {"text": "Other generated features include word matching with recurrent event seed words and time sensitivity of search result set.", "labels": [], "entities": [{"text": "word matching", "start_pos": 33, "end_pos": 46, "type": "TASK", "confidence": 0.8084999322891235}, {"text": "time sensitivity", "start_pos": 83, "end_pos": 99, "type": "METRIC", "confidence": 0.8980691432952881}]}, {"text": "We use Naive Bayes, SVM and decision tree based logistic regression model to train REQ classifier.", "labels": [], "entities": [{"text": "REQ classifier", "start_pos": 83, "end_pos": 97, "type": "TASK", "confidence": 0.6257930099964142}]}, {"text": "The results on test data show that our models outper-formed baseline approach significantly.", "labels": [], "entities": []}, {"text": "Experiments on a commercial Web search engine also show significant gains in overall relevance , and thus overall user experience.", "labels": [], "entities": []}], "introductionContent": [{"text": "REQ pertains to queries about events which occur at regular, predictable time intervals, most often weekly, monthly, annually, bi-annually, etc.", "labels": [], "entities": [{"text": "REQ pertains", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.7246868312358856}]}, {"text": "Naturally, users issue REQ periodically.", "labels": [], "entities": [{"text": "REQ", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.778791069984436}]}, {"text": "REQ usually refer to: Organized public events such as festivals, conferences, expos, sports competitions, elections: winter olympics, boston marathon, the International Ocean Research Conference, oscar night.", "labels": [], "entities": [{"text": "REQ", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7153071761131287}, {"text": "International Ocean Research Conference", "start_pos": 155, "end_pos": 194, "type": "TASK", "confidence": 0.6860905885696411}]}, {"text": "Public holidays and other noteworthy dates: labor day, date of Good Friday, Thanksgiving, black friday.", "labels": [], "entities": []}, {"text": "Products with annual model releases, such as car models: ford explorer, prius.", "labels": [], "entities": [{"text": "ford explorer", "start_pos": 57, "end_pos": 70, "type": "TASK", "confidence": 0.6299843639135361}]}, {"text": "Lottery drawings: California lotto results.", "labels": [], "entities": [{"text": "California lotto", "start_pos": 18, "end_pos": 34, "type": "TASK", "confidence": 0.5449601709842682}]}, {"text": "TV shows and programs which are currently running: American idol, Inside Edition.", "labels": [], "entities": [{"text": "Inside Edition", "start_pos": 66, "end_pos": 80, "type": "DATASET", "confidence": 0.895137220621109}]}, {"text": "Cultural related activities: presidential election, tax return, 1040 form.", "labels": [], "entities": []}, {"text": "Our interest in studying REQ arises from the challenge imposed on Web search ranking.", "labels": [], "entities": [{"text": "REQ", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.7479894161224365}]}, {"text": "To illustrate this, we show an example in that snapshots the real ranking results of the query, EMNLP, issued in 2010 when the authors composed this paper, on Google search engine.", "labels": [], "entities": [{"text": "EMNLP", "start_pos": 96, "end_pos": 101, "type": "DATASET", "confidence": 0.742457926273346}]}, {"text": "It is obvious the ranking is not satisfactory because the page about EMNLP2008 is on the first position in 2010.", "labels": [], "entities": [{"text": "EMNLP2008", "start_pos": 69, "end_pos": 78, "type": "DATASET", "confidence": 0.9369813203811646}]}, {"text": "Ideally, the page about EMNLP2010 on the 6th position should be on the first position even if users don't explicitly issue the query, EMNLP 2010, because EMNLP is a REQ.", "labels": [], "entities": [{"text": "EMNLP2010", "start_pos": 24, "end_pos": 33, "type": "DATASET", "confidence": 0.9292901158332825}, {"text": "EMNLP 2010", "start_pos": 134, "end_pos": 144, "type": "DATASET", "confidence": 0.916946679353714}, {"text": "EMNLP", "start_pos": 154, "end_pos": 159, "type": "DATASET", "confidence": 0.949398398399353}]}, {"text": "The query, \"EMNLP\", implicitly, without a year qualifier, needs to be served the most recent pages about \"EMNLP\".", "labels": [], "entities": [{"text": "EMNLP", "start_pos": 12, "end_pos": 17, "type": "DATASET", "confidence": 0.7814974784851074}]}, {"text": "A better search ranking result cannot be achieved if we do not categorize \"EMNLP\" as a REQ, and provide special ranking treatment to such queries.", "labels": [], "entities": [{"text": "REQ", "start_pos": 87, "end_pos": 90, "type": "METRIC", "confidence": 0.866344153881073}]}, {"text": "Existing search engines adopt a fairly involved ranking algorithm to order Web search results by considering many factors.", "labels": [], "entities": []}, {"text": "Time is an important factor but not the most critical.", "labels": [], "entities": [{"text": "Time", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9704755544662476}]}, {"text": "The page's ranking score mostly depends on other features such as tf-idf, BM25 (Jones et al.,), anchor text, historical clicks, pagerank (, and overall page quality.", "labels": [], "entities": [{"text": "BM25", "start_pos": 74, "end_pos": 78, "type": "METRIC", "confidence": 0.9758254289627075}]}, {"text": "New pages about EMNLP2010 obtain less favorable feature values than the pages of 2009 earlier in terms of anchor text, click or pagerank because they have existed fora shorter time and haven't accumulated sufficient popularity to make them standout.", "labels": [], "entities": [{"text": "EMNLP2010", "start_pos": 16, "end_pos": 25, "type": "DATASET", "confidence": 0.9595314860343933}, {"text": "click", "start_pos": 119, "end_pos": 124, "type": "METRIC", "confidence": 0.969454824924469}]}, {"text": "Without special treatment, the new pages about \"EMNLP2010\" will typically not be ranked appropriately for the users.", "labels": [], "entities": [{"text": "EMNLP2010\"", "start_pos": 48, "end_pos": 58, "type": "DATASET", "confidence": 0.86833855509758}]}, {"text": "Typically, a recurrent event is associated with a root, and spawns a large set of queries.", "labels": [], "entities": []}, {"text": "Oscar, for instance, is a recurrent event about the annual Academy Award.", "labels": [], "entities": [{"text": "Oscar", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.77479088306427}, {"text": "Academy Award", "start_pos": 59, "end_pos": 72, "type": "DATASET", "confidence": 0.7148519456386566}]}, {"text": "Based on this, queries like \"oscar best actress\", \"oscar best dress\", \"oscar best movie award\", are all recurrent event queries.", "labels": [], "entities": []}, {"text": "As such, REQ is a highly frequent category of query in Web search.", "labels": [], "entities": [{"text": "REQ", "start_pos": 9, "end_pos": 12, "type": "METRIC", "confidence": 0.4697481393814087}]}, {"text": "By Web search query log analysis, we observe that thereabout 5-6% queries of total query volume belongs to this category.", "labels": [], "entities": []}, {"text": "In this work, we learn if a query is in the REQ class, by effectively combining multiple features.", "labels": [], "entities": []}, {"text": "Our features are developed through analysis of historical query logs.", "labels": [], "entities": []}, {"text": "We discuss our approaches in detail in Section 3.", "labels": [], "entities": []}, {"text": "We then develop a REQ classifier where all the features are integrated by machine learning models.", "labels": [], "entities": [{"text": "REQ classifier", "start_pos": 18, "end_pos": 32, "type": "TASK", "confidence": 0.664970800280571}]}, {"text": "We use Naive Bayes, SVM and decision tree based logistic regression models.", "labels": [], "entities": []}, {"text": "These models are described in Section 4.", "labels": [], "entities": []}, {"text": "Our experiments for REQ classifier and Web search ranking are detailed in Section 5 and 6.", "labels": [], "entities": [{"text": "REQ classifier", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.814992755651474}, {"text": "Web search ranking", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.5966008802254995}]}], "datasetContent": [{"text": "We collected 6,000 queries labeled as either Recurrent or Non-recurrent by professional human editors.", "labels": [], "entities": []}, {"text": "The 6,000 queries were sampled from Implicit Timestamp queries according to frequency distribution to be representative.", "labels": [], "entities": []}, {"text": "We split the queries into 5,000 for training and 1,000 for test.", "labels": [], "entities": []}, {"text": "For each query, we calculated features' values as described in Section 3.", "labels": [], "entities": []}, {"text": "The Naive Bayes method used single Gaussian function for each independent feature.", "labels": [], "entities": []}, {"text": "Mean and variance were calculated from the training data.", "labels": [], "entities": [{"text": "Mean", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9945500493049622}, {"text": "variance", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.871499240398407}]}, {"text": "As for LIBSVM, we used C-SVC, linear function as kernel and 1.0 of shrinkage.", "labels": [], "entities": []}, {"text": "The parameters used in the regression model were 20 of trees, 20 of nodes and 0.8 of learning rate (shrinkage).", "labels": [], "entities": [{"text": "learning rate", "start_pos": 85, "end_pos": 98, "type": "METRIC", "confidence": 0.9574186503887177}]}, {"text": "The test results are shown in, recallprecision curve.", "labels": [], "entities": [{"text": "recallprecision", "start_pos": 31, "end_pos": 46, "type": "METRIC", "confidence": 0.9980279803276062}]}, {"text": "We set a series of threshold to the probability of c = +1 calculated by Eq.", "labels": [], "entities": []}, {"text": "1 so that we can get the point values of recall and precision in.", "labels": [], "entities": [{"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9995587468147278}, {"text": "precision", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9994117021560669}]}, {"text": "For example, if we set a threshold of 0.6, a query with a probability larger than 0.6 is classified as REQ.", "labels": [], "entities": [{"text": "REQ", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.9642756581306458}]}, {"text": "Otherwise, it is non-REQ.", "labels": [], "entities": []}, {"text": "The precision is a measure of correctly classified REQ queries divided by all classified REQ queries.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9991968274116516}]}, {"text": "The recall is a measure of correctly classified REQ queries divided by all REQ queries in test data.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9986030459403992}]}, {"text": "In addition to the three plots, we also show the results using only one feature, ExplicitQueryRatio, for comparison with the classification method used by ).All the three models using all features performed better than the existing method using ExplicitQueryRatio.", "labels": [], "entities": []}, {"text": "The highest improvement was achieved by GBDT regression tree model.", "labels": [], "entities": [{"text": "GBDT regression tree", "start_pos": 40, "end_pos": 60, "type": "DATASET", "confidence": 0.8251953721046448}]}, {"text": "The results of Naive Bayes were lower than SVM and GBDTree.", "labels": [], "entities": [{"text": "SVM", "start_pos": 43, "end_pos": 46, "type": "DATASET", "confidence": 0.9025819301605225}, {"text": "GBDTree", "start_pos": 51, "end_pos": 58, "type": "DATASET", "confidence": 0.8839038610458374}]}, {"text": "This model is weaker because it treats features independently.", "labels": [], "entities": []}, {"text": "Typically SVMs and GBDT gives comparable results on a large class of problems.", "labels": [], "entities": [{"text": "GBDT", "start_pos": 19, "end_pos": 23, "type": "DATASET", "confidence": 0.7805104851722717}]}, {"text": "Since for this task we use features from different sources, the feature values are designed to have larger dynamic range, which is better handled by GBDT.", "labels": [], "entities": [{"text": "GBDT", "start_pos": 149, "end_pos": 153, "type": "DATASET", "confidence": 0.8959875106811523}]}, {"text": "The features' importance ranked by Equation 3 is shown in.", "labels": [], "entities": [{"text": "Equation", "start_pos": 35, "end_pos": 43, "type": "METRIC", "confidence": 0.9834866523742676}]}, {"text": "We list the top 10 features.", "labels": [], "entities": []}, {"text": "The No.1 important feature is ExplicitQueryRatio.", "labels": [], "entities": []}, {"text": "The second and seventh features are from search session analysis by counting users who changed queries from Implicit Timestamp to Explicit Timestamp.", "labels": [], "entities": [{"text": "search session analysis", "start_pos": 41, "end_pos": 64, "type": "TASK", "confidence": 0.6205869019031525}]}, {"text": "This is a strong source of features.", "labels": [], "entities": []}, {"text": "The time series analysis feature is ranked No.3.", "labels": [], "entities": [{"text": "time series analysis", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.571175237496694}]}, {"text": "Calculation of this feature needs two years query log to be much more effective, but we didn't get so large data for many queries.", "labels": [], "entities": []}, {"text": "One of the features from recurrent event seed list is ranked No.4.", "labels": [], "entities": [{"text": "recurrent event seed list", "start_pos": 25, "end_pos": 50, "type": "DATASET", "confidence": 0.6276155710220337}]}, {"text": "This is also an important feature source.", "labels": [], "entities": []}, {"text": "The ChiSquareYearDist feature is ranked 5th, that proves the recurrent event query frequency has a statistical distribution pattern over years.", "labels": [], "entities": []}, {"text": "TitleYearTop30 and TitleYearTop10 that are derived from scraping results are ranked the 9th and 10th important.", "labels": [], "entities": [{"text": "TitleYearTop30", "start_pos": 0, "end_pos": 14, "type": "DATASET", "confidence": 0.9771506786346436}, {"text": "TitleYearTop10", "start_pos": 19, "end_pos": 33, "type": "DATASET", "confidence": 0.9816387891769409}]}, {"text": "each sample of the 6,000 data, where each point represents a query and each line represents a feature's value for all queries.", "labels": [], "entities": []}, {"text": "One point is a query.", "labels": [], "entities": []}, {"text": "The features are ordered according to feature importance of.", "labels": [], "entities": []}, {"text": "The \"blue\" points indicate REQ queries and the \"red\" points, non-REQ queries.", "labels": [], "entities": [{"text": "REQ", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9377960562705994}]}, {"text": "Some features are continuous like the 1st and 2nd.", "labels": [], "entities": []}, {"text": "Some feature values are discrete like the last two indicating TitleYearTop30 and TitleYearTop10.", "labels": [], "entities": [{"text": "TitleYearTop30", "start_pos": 62, "end_pos": 76, "type": "DATASET", "confidence": 0.983244001865387}, {"text": "TitleYearTop10", "start_pos": 81, "end_pos": 95, "type": "DATASET", "confidence": 0.9842236638069153}]}, {"text": "There are \"red\" samples in the 4th feature but overlapped with and covered by \"blue\" samples visually.", "labels": [], "entities": []}, {"text": "In the   Some query examples, and their scores from our model are listed in.", "labels": [], "entities": []}, {"text": "The last two examples, google ipo and adidas jp, have very low values, and are not REQs.", "labels": [], "entities": [{"text": "REQs", "start_pos": 83, "end_pos": 87, "type": "METRIC", "confidence": 0.9309942126274109}]}, {"text": "The first four queries are typical REQs.", "labels": [], "entities": []}, {"text": "They have higher values of features ExplicitQueryRatio,Normalized UserSwitch and YearUrlF-PCTR.", "labels": [], "entities": [{"text": "ExplicitQueryRatio,Normalized", "start_pos": 36, "end_pos": 65, "type": "METRIC", "confidence": 0.95613694190979}]}, {"text": "Although both new apple iphone release reviews and academy awards reviews are about reviews, academy awards reviews has lower value of NormalizedUserSwitch and ChiSquareYearDist could be the reason fora lower score.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Top 10 most important features: rank and im- portance score (100 is maximum)", "labels": [], "entities": [{"text": "rank", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.9436197876930237}, {"text": "im- portance score", "start_pos": 51, "end_pos": 69, "type": "METRIC", "confidence": 0.7666050642728806}]}, {"text": " Table 2. The \"blue\" points indicate REQ queries and  the \"red\" points, non-REQ queries. Some features  are continuous like the 1st and 2nd. Some feature  values are discrete like the last two indicating Ti- tleYearTop30 and TitleYearTop10. There are \"red\"  samples in the 4th feature but overlapped with and  covered by \"blue\" samples visually.", "labels": [], "entities": [{"text": "TitleYearTop10", "start_pos": 225, "end_pos": 239, "type": "DATASET", "confidence": 0.9566540122032166}]}, {"text": " Table 3: F-Measures as varying thresholds by adding top  features.", "labels": [], "entities": [{"text": "F-Measures", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9882305860519409}]}, {"text": " Table 4: Probabilities of example queries by GBDT tree  classifier", "labels": [], "entities": [{"text": "GBDT tree  classifier", "start_pos": 46, "end_pos": 67, "type": "DATASET", "confidence": 0.8955223162968954}]}, {"text": " Table 4. The last two exam- ples, google ipo and adidas jp, have very low values,  and are not REQs. The first four queries are typical  REQs. They have higher values of features Explicit- QueryRatio,Normalized UserSwitch and YearUrlF- PCTR. Although both new apple iphone release re- views and academy awards reviews are about re- views, academy awards reviews has lower value  of NormalizedUserSwitch and ChiSquareYearDist  could be the reason for a lower score.", "labels": [], "entities": []}, {"text": " Table 5: REQ learner improves search engine organic results. The numbers in the brackets are by Zhang's methods.  Direct comparison with Zhang's method is valid only in the last line, using all queries. A sign \" * \" indicates statistical  significance (p-value<0.05)", "labels": [], "entities": [{"text": "REQ learner", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.5351952910423279}, {"text": "statistical  significance", "start_pos": 227, "end_pos": 252, "type": "METRIC", "confidence": 0.8859450221061707}]}]}