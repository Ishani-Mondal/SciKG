{"title": [{"text": "Automatic Detection and Classification of Social Events", "labels": [], "entities": [{"text": "Automatic Detection and Classification of Social Events", "start_pos": 0, "end_pos": 55, "type": "TASK", "confidence": 0.720765335219247}]}], "abstractContent": [{"text": "In this paper we introduce the new task of social event extraction from text.", "labels": [], "entities": [{"text": "social event extraction from text", "start_pos": 43, "end_pos": 76, "type": "TASK", "confidence": 0.7486992537975311}]}, {"text": "We distinguish two broad types of social events depending on whether only one or both parties are aware of the social contact.", "labels": [], "entities": []}, {"text": "We annotate part of Automatic Content Extraction (ACE) data, and perform experiments using Support Vector Machines with Kernel methods.", "labels": [], "entities": [{"text": "Automatic Content Extraction (ACE)", "start_pos": 20, "end_pos": 54, "type": "TASK", "confidence": 0.7606690923372904}]}, {"text": "We use a combination of structures derived from phrase structure trees and dependency trees.", "labels": [], "entities": []}, {"text": "A characteristic of our events (which distinguishes them from ACE events) is that the participating entities can be spread far across the parse trees.", "labels": [], "entities": []}, {"text": "We use syntactic and semantic insights to devise anew structure derived from dependency trees and show that this plays a role in achieving the best performing system for both social event detection and classification tasks.", "labels": [], "entities": [{"text": "social event detection and classification tasks", "start_pos": 175, "end_pos": 222, "type": "TASK", "confidence": 0.6814616173505783}]}, {"text": "We also use three data sampling approaches to solve the problem of data skewness.", "labels": [], "entities": []}, {"text": "Sampling methods improve the F1-measure for the task of relation detection by over 20% absolute over the baseline.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 29, "end_pos": 39, "type": "METRIC", "confidence": 0.9987038373947144}, {"text": "relation detection", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.931151956319809}]}], "introductionContent": [{"text": "This paper introduces a novel natural language processing (NLP) task, social event extraction.", "labels": [], "entities": [{"text": "social event extraction", "start_pos": 70, "end_pos": 93, "type": "TASK", "confidence": 0.6864054004351298}]}, {"text": "We are interested in this task because it contributes to our overall research goal, which is to extract asocial network from written text.", "labels": [], "entities": []}, {"text": "The extracted social network can be used for various applications such as summarization, question-answering, or the detection of main characters in a story.", "labels": [], "entities": [{"text": "summarization", "start_pos": 74, "end_pos": 87, "type": "TASK", "confidence": 0.9917433857917786}, {"text": "detection of main characters in a story", "start_pos": 116, "end_pos": 155, "type": "TASK", "confidence": 0.8239378929138184}]}, {"text": "For example, we manually extracted the social network of characters in Alice in Wonderland and ran standard social network analysis algorithms on the network.", "labels": [], "entities": []}, {"text": "The most influential characters in the story were correctly detected.", "labels": [], "entities": []}, {"text": "Moreover, characters occurring in a scene together were given same social roles and positions.", "labels": [], "entities": []}, {"text": "Social network extraction has recently been applied to literary theory and has the potential to help organize novels that are becoming machine readable.", "labels": [], "entities": [{"text": "Social network extraction", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6636199653148651}, {"text": "literary theory", "start_pos": 55, "end_pos": 70, "type": "TASK", "confidence": 0.7495594322681427}]}, {"text": "We take a \"social network\" to be a network consisting of individual human beings and groups of human beings who are connected to each other by the virtue of participating in social events.", "labels": [], "entities": []}, {"text": "We define social events to be events that occur between people whereat least one person is aware of the other and of the event taking place.", "labels": [], "entities": []}, {"text": "For example, in the sentence John talks to Mary, entities John and Mary are aware of each other and the talking event.", "labels": [], "entities": []}, {"text": "In the sentence John thinks Mary is great, only John is aware of Mary and the event is the thinking event.", "labels": [], "entities": []}, {"text": "In the sentence Rabbit ran by Alice there is no evidence about the cognitive states of Rabbit and Alice (because the Rabbit could have run by Alice without anyone of them noticing each other).", "labels": [], "entities": []}, {"text": "A text can describe asocial network in two ways: explicitly, by stating the type of relationship between two individuals (e.g. husband-wife), or implicitly, by describing an event which creates or perpetuates asocial relationship (e.g. John talked to Mary).", "labels": [], "entities": []}, {"text": "We will call these types of events social events.", "labels": [], "entities": []}, {"text": "We define two types of social events: interaction, in which both parties are aware of the social event (e.g., a conversation), and observation, in which only one party is aware of the interaction (e.g., thinking about or spying on someone).", "labels": [], "entities": []}, {"text": "Note that the notion of cognitive state is crucial to our definition.", "labels": [], "entities": []}, {"text": "This paper is the first attempt to detect and classify social events present in text.", "labels": [], "entities": [{"text": "classify social events present in text", "start_pos": 46, "end_pos": 84, "type": "TASK", "confidence": 0.8578543762365977}]}, {"text": "Our task is different from related tasks, notably from the Automated Content Extraction (ACE) relation and event extraction tasks because the events are different (they area class of events defined through the effect on participants' cognitive state), and the linguistic realization is different.", "labels": [], "entities": [{"text": "Automated Content Extraction (ACE) relation and event extraction", "start_pos": 59, "end_pos": 123, "type": "TASK", "confidence": 0.7312047928571701}]}, {"text": "Mentions of entities 1 engaged in asocial event are often quite distant from each other in the sentence (unlike in ACE relations where about 70% of relations are local, in our social event annotation, only 25% of the events are local.", "labels": [], "entities": []}, {"text": "In fact, the average number of words between entities participating in any social event is 9.)", "labels": [], "entities": []}, {"text": "We use tree kernel methods (on structures derived from phrase structure trees and dependency trees) in conjunction with Support Vector Machines (SVMs) to solve our tasks.", "labels": [], "entities": []}, {"text": "For the design of structures and type of kernel, we take motivation from a system proposed by which is a stateof-the-art system for relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 132, "end_pos": 151, "type": "TASK", "confidence": 0.8079084753990173}]}, {"text": "Data skewness turns out to be a big challenge for the task of relation detection since there are many more pairs of entities without a relation as compared to pairs of entities that have a relation.", "labels": [], "entities": [{"text": "relation detection", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.7983368933200836}]}, {"text": "In this paper we discuss three data sampling techniques that deal with this skewness and allow us to gain over 20% in F1-measure over our baseline system.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 118, "end_pos": 128, "type": "METRIC", "confidence": 0.9982578158378601}]}, {"text": "Moreover, we introduce anew sequence kernel that outperforms previously proposed sequence kernels for the task of social event detection and plays a role to achieve the best performing system for the task of social event detection and classification.", "labels": [], "entities": [{"text": "social event detection", "start_pos": 114, "end_pos": 136, "type": "TASK", "confidence": 0.6404268344243368}, {"text": "social event detection and classification", "start_pos": 208, "end_pos": 249, "type": "TASK", "confidence": 0.7127705812454224}]}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we compare our work to existing work, notably the ACE extraction literature.", "labels": [], "entities": [{"text": "ACE extraction", "start_pos": 64, "end_pos": 78, "type": "TASK", "confidence": 0.7629922926425934}]}, {"text": "In Section 3, we present our task in detail, and explain how we annotated our corpus.", "labels": [], "entities": []}, {"text": "We also show why this is a novel task, and how it is different from the ACE extraction tasks.", "labels": [], "entities": [{"text": "ACE extraction", "start_pos": 72, "end_pos": 86, "type": "TASK", "confidence": 0.837185263633728}]}, {"text": "We then discuss kernel methods and the structures we use, and introduce our new structure in Section 4.", "labels": [], "entities": []}, {"text": "In Section 5, we present the sampling methods used for experiments.", "labels": [], "entities": []}, {"text": "In Section 6 we present our exper-iments and results for social event detection and social event classification tasks.", "labels": [], "entities": [{"text": "social event detection", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.6578969458738962}, {"text": "social event classification", "start_pos": 84, "end_pos": 111, "type": "TASK", "confidence": 0.6243833005428314}]}, {"text": "We conclude in Section 7 and mention our future direction of research.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present experiments and results for our two tasks: social event detection and classification.", "labels": [], "entities": [{"text": "social event detection", "start_pos": 70, "end_pos": 92, "type": "TASK", "confidence": 0.6807547410329183}]}, {"text": "For the social event detection task, we wish to validate the following research hypotheses.", "labels": [], "entities": [{"text": "social event detection task", "start_pos": 8, "end_pos": 35, "type": "TASK", "confidence": 0.7351901158690453}]}, {"text": "First, we aim to show the importance of using data sampling when evaluating on F-measure; specifically, we expect under-sampling to outperform no sampling, over-sampling to outperform under-sampling, and over-sampling with transformations to outperform over-sampling without transformations.", "labels": [], "entities": []}, {"text": "In contrast, the social event classification task does not suffer from data skewness because the INR and COG relations; both occur almost the same number of times.", "labels": [], "entities": [{"text": "social event classification task", "start_pos": 17, "end_pos": 49, "type": "TASK", "confidence": 0.6934579536318779}, {"text": "INR", "start_pos": 97, "end_pos": 100, "type": "METRIC", "confidence": 0.7753049731254578}]}, {"text": "Therefore, sampling methods may not be applied for this task.", "labels": [], "entities": []}, {"text": "Second, for both tasks, we expect that a combination of kernels will out-perform individual kernels.", "labels": [], "entities": []}, {"text": "Moreover, we expect that dependency trees will have a crucial role in achieving the best performance.", "labels": [], "entities": []}, {"text": "We use part of ACE data that we annotated for social events.", "labels": [], "entities": [{"text": "ACE data", "start_pos": 15, "end_pos": 23, "type": "DATASET", "confidence": 0.9512911736965179}]}, {"text": "In all, we annotated 138 ACE documents.", "labels": [], "entities": [{"text": "ACE documents", "start_pos": 25, "end_pos": 38, "type": "DATASET", "confidence": 0.9251354336738586}]}, {"text": "We retained the ACE entity annotations.", "labels": [], "entities": [{"text": "ACE entity annotations", "start_pos": 16, "end_pos": 38, "type": "DATASET", "confidence": 0.8877227306365967}]}, {"text": "We consider all entity mention pairs in a sentence.", "labels": [], "entities": []}, {"text": "If our annotators recorded a relation between a pair of entity mentions, we say there is a relation between the corresponding entities.", "labels": [], "entities": []}, {"text": "If there are any other pairs of entity mentions for the same pair of entity, we discard those.", "labels": [], "entities": []}, {"text": "For all other pairs of entity mentions, we say there is no relation.", "labels": [], "entities": []}, {"text": "Out of 138 files, four files did not have any positive or negative examples (because there were very few and sparse entity mentions in these four files).", "labels": [], "entities": []}, {"text": "We found a total of 1291 negative examples, 172 examples belonging to class INR and 174 belonging to class COG.", "labels": [], "entities": [{"text": "INR", "start_pos": 76, "end_pos": 79, "type": "DATASET", "confidence": 0.6242173314094543}, {"text": "COG", "start_pos": 107, "end_pos": 110, "type": "DATASET", "confidence": 0.7534120678901672}]}, {"text": "We use Jet's sentence splitter and the Stanford Parser () for phrase structure trees and dependency parses.", "labels": [], "entities": [{"text": "sentence splitter", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.6811372190713882}, {"text": "dependency parses", "start_pos": 89, "end_pos": 106, "type": "TASK", "confidence": 0.7623310089111328}]}, {"text": "For classifica-tion, we used Alessandro Moschitti's SVM-Light-TK package) which is built on the SVM-Light implementation of Joakhims (1999).", "labels": [], "entities": []}, {"text": "For all our experiments, we perform 5-fold crossvalidation.", "labels": [], "entities": []}, {"text": "We randomly divide the whole corpus into 5 equal parts, such that no news story (or document) gets divided among two parts.", "labels": [], "entities": []}, {"text": "For each fold, we then merge 4 parts to create a training corpus and treat the remaining part as a test corpus.", "labels": [], "entities": []}, {"text": "By keeping individual news stories intact, we make sure that vocabulary specific to one story does not unrealistically improve the performance.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Baseline System for the task of social event  detection. The proportion of positive data in training  and test set is 21.1% and 20.6% respectively.", "labels": [], "entities": [{"text": "social event  detection", "start_pos": 42, "end_pos": 65, "type": "TASK", "confidence": 0.6277249455451965}]}, {"text": " Table 2: Under-sampled system for the task of rela- tion detection. The proportion of positive examples  in the training and test corpus is 50.0% and 20.6%  respectively.", "labels": [], "entities": [{"text": "rela- tion detection", "start_pos": 47, "end_pos": 67, "type": "TASK", "confidence": 0.7038449421525002}]}, {"text": " Table 3: Over-sampled system for the task of rela- tion detection. The proportion of positive examples  in the training and test corpus is 50.0% and 20.6%  respectively.", "labels": [], "entities": [{"text": "rela- tion detection", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.7087056189775467}]}, {"text": " Table 4: Over-sampled System with transformation  for relation detection. The proportion of positive ex- amples in the training and test corpus is 51.7% and  20.6% respectively.", "labels": [], "entities": [{"text": "relation detection", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.9606324136257172}]}, {"text": " Table 5: System for the task of relation classifica- tion. The two classes are INR and COG, and we  evaluate using accuracy (Acc.). The proportion of  INR relations in training and test set is 49.7% and  49.63% respectively.", "labels": [], "entities": [{"text": "INR", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.8237080574035645}, {"text": "COG", "start_pos": 88, "end_pos": 91, "type": "METRIC", "confidence": 0.7667039632797241}, {"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.999134361743927}, {"text": "Acc.", "start_pos": 126, "end_pos": 130, "type": "METRIC", "confidence": 0.9948441982269287}]}]}