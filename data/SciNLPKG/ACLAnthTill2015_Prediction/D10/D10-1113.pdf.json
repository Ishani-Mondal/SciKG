{"title": [], "abstractContent": [{"text": "The computation of meaning similarity as operationalized by vector-based models has found widespread use in many tasks ranging from the acquisition of synonyms and paraphrases to word sense disambiguation and tex-tual entailment.", "labels": [], "entities": [{"text": "acquisition of synonyms and paraphrases", "start_pos": 136, "end_pos": 175, "type": "TASK", "confidence": 0.7824369192123413}, {"text": "word sense disambiguation", "start_pos": 179, "end_pos": 204, "type": "TASK", "confidence": 0.6887275179227194}, {"text": "tex-tual entailment", "start_pos": 209, "end_pos": 228, "type": "TASK", "confidence": 0.7491586804389954}]}, {"text": "Vector-based models are typically directed at representing words in isolation and thus best suited for measuring similarity out of context.", "labels": [], "entities": []}, {"text": "In his paper we propose a probabilistic framework for measuring similarity in context.", "labels": [], "entities": []}, {"text": "Central to our approach is the intuition that word meaning is represented as a probability distribution over a set of latent senses and is modulated by context.", "labels": [], "entities": []}, {"text": "Experimental results on lexical substitution and word similarity show that our algorithm out-performs previously proposed models.", "labels": [], "entities": [{"text": "lexical substitution", "start_pos": 24, "end_pos": 44, "type": "TASK", "confidence": 0.7678380906581879}, {"text": "word similarity", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.7918830513954163}]}], "introductionContent": [{"text": "The computation of meaning similarity as operationalized by vector-based models has found widespread use in many tasks within natural language processing (NLP).", "labels": [], "entities": [{"text": "natural language processing (NLP)", "start_pos": 126, "end_pos": 159, "type": "TASK", "confidence": 0.7108996411164602}]}, {"text": "These range from the acquisition of synonyms) and paraphrases) to word sense disambiguation, textual entailment, and notably information retrieval (.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 66, "end_pos": 91, "type": "TASK", "confidence": 0.7205441395441691}, {"text": "textual entailment", "start_pos": 93, "end_pos": 111, "type": "TASK", "confidence": 0.7069641500711441}, {"text": "information retrieval", "start_pos": 125, "end_pos": 146, "type": "TASK", "confidence": 0.8104779124259949}]}, {"text": "The popularity of vector-based models lies in their unsupervised nature and ease of computation.", "labels": [], "entities": []}, {"text": "In their simplest incarnation, these models represent the meaning of each word as a point in a high-dimensional space, where each component corresponds to some co-occurring contextual element.", "labels": [], "entities": []}, {"text": "The advantage of taking such a geometric approach is that the similarity of word meanings can be easily quantified by measuring their distance in the vector space, or the cosine of the angle between them.", "labels": [], "entities": []}, {"text": "Vector-based models do not explicitly identify the different senses of words and consequently represent their meaning invariably (i.e., irrespective of cooccurring context).", "labels": [], "entities": []}, {"text": "Consider for example the adjective heavy which we may associate with the general meaning of \"dense\" or \"massive\".", "labels": [], "entities": []}, {"text": "However, when attested in context, heavy may refer to an overweight person (e.g., She is short and heavy but she has a heart of gold.) or an excessive cannabis user (e.g., Some heavy users develop a psychological dependence on cannabis.).", "labels": [], "entities": []}, {"text": "Recent work addresses this issue indirectly with the development of specialized models that represent word meaning in context).", "labels": [], "entities": []}, {"text": "These methods first extract typical co-occurrence vectors representing a mixture of senses and then use vector operations to either obtain contextualized representations of a target word or a representation fora set of words.", "labels": [], "entities": []}, {"text": "In this paper we propose a probabilistic framework for representing word meaning and measuring similarity in context.", "labels": [], "entities": []}, {"text": "We model the meaning of isolated words as a probability distribution over a set of latent senses.", "labels": [], "entities": []}, {"text": "This distribution reflects the a priori, out-of-context likelihood of each sense.", "labels": [], "entities": []}, {"text": "Because sense ambiguity is taken into account directly in the vector construction process, contextualized meaning can be modeled naturally as a change in the original sense distribution.", "labels": [], "entities": []}, {"text": "We evaluate our approach on word similarity () and lexical substitution and show improvements over competitive baselines.", "labels": [], "entities": [{"text": "lexical substitution", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.7537184059619904}]}, {"text": "In the remainder of this paper we give a brief overview of related work, emphasizing vector-based approaches that compute word meaning in context (Section 2).", "labels": [], "entities": []}, {"text": "Next, we present our probabilistic framework and different instantiations thereof (Sections 3 and 4).", "labels": [], "entities": []}, {"text": "Finally, we discuss our experimental results (Sections 5 and 6) and conclude the paper with future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we discuss the experiments we performed in order to evaluate our model.", "labels": [], "entities": []}, {"text": "We describe the tasks on which it was applied, the corpora used for model training and our evaluation methodology.", "labels": [], "entities": []}, {"text": "Tasks The probabilistic model presented in Section 3 represents words via a set of induced senses.", "labels": [], "entities": []}, {"text": "We experimented with two types of semantic space based on NMF and LDA and optimized parameters for these models on a word similarity task.", "labels": [], "entities": [{"text": "word similarity task", "start_pos": 117, "end_pos": 137, "type": "TASK", "confidence": 0.787071943283081}]}, {"text": "The latter involves judging the similarity sim(t i , ti ) = sim(v(t i ), v(t i )) of words ti and ti out of context, where v(t i ) and v(t i ) are obtained from the output of NMF or LDA, respectively.", "labels": [], "entities": [{"text": "NMF", "start_pos": 175, "end_pos": 178, "type": "DATASET", "confidence": 0.9007871150970459}]}, {"text": "In our experiments we used the data set of.", "labels": [], "entities": []}, {"text": "It contains 353 pairs of words and their similarity scores as perceived by human subjects.", "labels": [], "entities": []}, {"text": "The contextualized representations were next evaluated on lexical substitution.", "labels": [], "entities": []}, {"text": "The task requires systems to find appropriate substitutes for target words occurring in context.", "labels": [], "entities": []}, {"text": "Typically, systems are given a set of substitutes, and must produce a ranking such that appropriate substitutes are assigned a higher rank compared to non-appropriate ones.", "labels": [], "entities": []}, {"text": "We made use of the SemEval 2007 Lexical Substitution Task benchmark data set.", "labels": [], "entities": [{"text": "SemEval 2007 Lexical Substitution Task benchmark data set", "start_pos": 19, "end_pos": 76, "type": "DATASET", "confidence": 0.7623905315995216}]}, {"text": "It contains 200 target words, namely nouns, verbs, adjectives and adverbs, each of which occurs in 10 distinct sentential contexts.", "labels": [], "entities": []}, {"text": "The total set contains 2,000 sentences.", "labels": [], "entities": []}, {"text": "Five human annotators were asked to provide substitutes for these target words.", "labels": [], "entities": []}, {"text": "gives an example of the adjective still and its substitutes.", "labels": [], "entities": []}, {"text": "Following, we pool together the total set of substitutes for each target word.", "labels": [], "entities": []}, {"text": "Then, for each instance the model has to produce a ranking for the total substitute set.", "labels": [], "entities": []}, {"text": "We rank the candidate substitutes based on the similarity of the contextualized target and the out-of-context substitute, sim(v(t i , c j ), v(t i )), where ti is the target word, c j a context word and ti a substitute.", "labels": [], "entities": []}, {"text": "Contextualizing just one of the words brings higher discriminative power to the model rather than performing comparSentences Substitutes It is important to apply the herbicide on a still day, because spray drift can kill non-target plants.", "labels": [], "entities": []}, {"text": "calm (5) not-windy windless A movie is a visual document comprised of a series of still images.", "labels": [], "entities": []}, {"text": "motionless (3) unmoving (2) fixed (1) stationary (1) static (1) isons with the target and its substitute embedded in an identical context (see also fora similar observation).", "labels": [], "entities": []}, {"text": "Model Training All the models we experimented with use identical input data, i.e., a bag-of-words matrix extracted from the GigaWord collection of news text.", "labels": [], "entities": [{"text": "GigaWord collection of news text", "start_pos": 124, "end_pos": 156, "type": "DATASET", "confidence": 0.9439032316207886}]}, {"text": "Rows in this matrix are target words and columns are their co-occurring neighbors, within asymmetric window of size 5.", "labels": [], "entities": []}, {"text": "As context words, we used a vocabulary of the 3,000 most frequent words in the corpus.", "labels": [], "entities": []}, {"text": "We implemented the classical NMF factorization algorithm described in.", "labels": [], "entities": []}, {"text": "The input matrix was normalized so that all elements summed to 1.", "labels": [], "entities": []}, {"text": "We experimented with four dimensions K: [600 \u2212 1000] with step size 200.", "labels": [], "entities": []}, {"text": "We ran the algorithm for 150 iterations to obtain factors W and H which we further processes as described in Section 4 to obtain the desired probability distributions.", "labels": [], "entities": []}, {"text": "Since the only parameter of the NMF model is the factorization dimension K, we performed two independent runs with each K value and averaged their predictions.", "labels": [], "entities": []}, {"text": "The parameters for the LDA model are the number of topics K and Dirichlet priors \u03b1 and \u03b2.", "labels": [], "entities": []}, {"text": "We experimented with topics K: [600 \u2212 1400], again with step size 200.", "labels": [], "entities": []}, {"text": "We fixed \u03b2 to 0.01 and tested two values for \u03b1: 2 K (Porteous et al., 2008) and 50 K ().", "labels": [], "entities": []}, {"text": "We used Gibbs sampling on the \"document collection\" obtained from the input matrix and estimated the sense distributions as described in Section 4.", "labels": [], "entities": []}, {"text": "We ran the chains for 1000 iter-ations and averaged over five iterations at lag 100 (we observed no topic drift).", "labels": [], "entities": []}, {"text": "We measured similarity using the scalar product, cosine, and inverse Jensen-Shannon (IJS) divergence (see, (8), and (9), respectively): cos(v, w) = v, w ||v|| ||w|| (8) where m is a shorthand for 1 2 (v + w) and KL the Kullback-Leibler divergence, KL(v|w) = Among the above similarity measures, the scalar product has the most straightforward interpretation as the probability of two targets sharing a common meaning (i.e., the sum overall possible meanings).", "labels": [], "entities": []}, {"text": "The scalar product assigns 1 to a pair of identical vectors if and only if P (z i ) = 1 for some i and P (z j ) = 0, \u2200j = i.", "labels": [], "entities": []}, {"text": "Thus, only fully disambiguated words receive a score of 1.", "labels": [], "entities": []}, {"text": "Beyond similarity, the measure also reflects how \"focused\" the distributions in question are, as very ambiguous words are unlikely to receive high scalar product values.", "labels": [], "entities": []}, {"text": "Given a set of context words, we contextualize the target using one context word at a time and compute the overall similarity score by multiplying the individual scores.", "labels": [], "entities": [{"text": "similarity score", "start_pos": 115, "end_pos": 131, "type": "METRIC", "confidence": 0.9685558080673218}]}, {"text": "Baselines Our baseline models for measuring similarity out of context are Latent Semantic Analysis) and a simple semantic space without any dimensionality reduction.", "labels": [], "entities": []}, {"text": "For LSA, we computed the U \u03a3V SVD decomposition of the original matrix to rank k = 1000.", "labels": [], "entities": [{"text": "LSA", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.8064336180686951}]}, {"text": "Any decomposition of lower rank can be obtained from this by setting rows and columns to 0.", "labels": [], "entities": []}, {"text": "We evaluated decompositions to ranks K:, at each 100 step.", "labels": [], "entities": []}, {"text": "Similarity computations were performed in the lower rank approximation matrix U \u03a3V , as originally proposed in, and in matrix U which maps the words into the concept space.", "labels": [], "entities": []}, {"text": "It is common to compute SVD decompositions on matrices to which prior weighting schemes have been applied.", "labels": [], "entities": [{"text": "SVD decompositions", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.856360673904419}]}, {"text": "We experimented with tf-idf weighting and line normalization.", "labels": [], "entities": [{"text": "line normalization", "start_pos": 42, "end_pos": 60, "type": "TASK", "confidence": 0.7068760097026825}]}, {"text": "Our second baseline, the simple semantic space, was based on the original input matrix on which we applied several weighting schemes such as pointwise mutual information, tf-idf, and line normalization.", "labels": [], "entities": []}, {"text": "Again, we measured similarity using cosine, scalar product and inverse JS divergence.", "labels": [], "entities": [{"text": "similarity", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.9544860124588013}, {"text": "JS divergence", "start_pos": 71, "end_pos": 84, "type": "METRIC", "confidence": 0.7260303199291229}]}, {"text": "In addition, we also experimented with Lin's (1998) similarity measure: where the values in v and ware point-wise mutual information, and I(\u00b7) gives the indices of positive values in a vector.", "labels": [], "entities": [{"text": "similarity measure", "start_pos": 52, "end_pos": 70, "type": "METRIC", "confidence": 0.8144868314266205}, {"text": "I", "start_pos": 138, "end_pos": 139, "type": "METRIC", "confidence": 0.9773141741752625}]}, {"text": "Our baselines for contextualized similarity were vector addition and vector multiplication which we performed using the simple semantic space and dimensionality reduced representations obtained from NMF and LDA.", "labels": [], "entities": [{"text": "vector addition", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.7735588848590851}, {"text": "vector multiplication", "start_pos": 69, "end_pos": 90, "type": "TASK", "confidence": 0.6858905702829361}]}, {"text": "To create a ranking of the candidate substitutes we compose the vector of the target with its context and compare it with each substitute vector.", "labels": [], "entities": []}, {"text": "Given a set of context words, we contextualize the target using each context word at a time and multiply the individual scores.", "labels": [], "entities": []}, {"text": "Evaluation Method For the word similarity task we used correlation analysis to examine the relationship between the human ratings and their corresponding vector-based similarity values.", "labels": [], "entities": []}, {"text": "We report Spearman's \u03c1 correlations between the similarity values provided by the models and the mean participant similarity ratings in the data set.", "labels": [], "entities": [{"text": "Spearman's \u03c1 correlations", "start_pos": 10, "end_pos": 35, "type": "METRIC", "confidence": 0.6558393687009811}]}, {"text": "For the lexical substitution task, we compare the system ranking with the gold standard ranking using Kendall's \u03c4 b rank correlation (which is adjusted for tied ranks).", "labels": [], "entities": [{"text": "lexical substitution task", "start_pos": 8, "end_pos": 33, "type": "TASK", "confidence": 0.7840574582417806}, {"text": "\u03c4 b rank correlation", "start_pos": 112, "end_pos": 132, "type": "METRIC", "confidence": 0.6655372679233551}]}, {"text": "For all contextualized models we defined the context of a target word as the words occurring within asymmetric context window of size 5.", "labels": [], "entities": []}, {"text": "We assess differences between models using stratified shuffling: Results on out of context word similarity using a simple co-occurrence based vector space model (SVS), latent semantic analysis, non-negative matrix factorization and latent Dirichlet allocation as individual models with the best parameter setting (LSA, NMF, LDA) and as mixtures (LSA MIX , NMF MIX , LDA MIX ).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results on out of context word similarity using  a simple co-occurrence based vector space model (SVS),  latent semantic analysis, non-negative matrix factoriza- tion and latent Dirichlet allocation as individual models  with the best parameter setting (LSA, NMF, LDA) and as  mixtures (LSA MIX , NMF MIX , LDA MIX ).", "labels": [], "entities": [{"text": "out of context word similarity", "start_pos": 21, "end_pos": 51, "type": "TASK", "confidence": 0.7300358355045319}, {"text": "latent semantic analysis", "start_pos": 115, "end_pos": 139, "type": "TASK", "confidence": 0.6549382209777832}]}, {"text": " Table 4: Results on lexical substitution for different parts  of speech with a simple semantic space model (SVS), two  compositional models (Add-SVS, Mult-SVS), and con- textualized mixture models with NMF and LDA (Cont- NMF MIX , Cont-LDA MIX ), using Kendall's \u03c4 b correlation  coefficient.", "labels": [], "entities": [{"text": "\u03c4 b correlation  coefficient", "start_pos": 264, "end_pos": 292, "type": "METRIC", "confidence": 0.6909223273396492}]}]}