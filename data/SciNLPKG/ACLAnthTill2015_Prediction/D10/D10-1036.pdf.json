{"title": [{"text": "Automatic Keyphrase Extraction via Topic Decomposition", "labels": [], "entities": [{"text": "Automatic Keyphrase Extraction", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.5884199837843577}, {"text": "Topic Decomposition", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.7775948643684387}]}], "abstractContent": [{"text": "Existing graph-based ranking methods for keyphrase extraction compute a single importance score for each word via a single random walk.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.8487465083599091}]}, {"text": "Motivated by the fact that both documents and words can be represented by a mixture of semantic topics, we propose to decompose traditional random walk into multiple random walks specific to various topics.", "labels": [], "entities": []}, {"text": "We thus build a Topical PageRank (TPR) on word graph to measure word importance with respect to different topics.", "labels": [], "entities": []}, {"text": "After that, given the topic distribution of the document, we further calculate the ranking scores of words and extract the top ranked ones as keyphrases.", "labels": [], "entities": []}, {"text": "Experimental results show that TPR outperforms state-of-the-art keyphrase extraction methods on two datasets under various evaluation met-rics.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 64, "end_pos": 84, "type": "TASK", "confidence": 0.7154704034328461}]}], "introductionContent": [{"text": "Keyphrases are defined as a set of terms in a document that give a brief summary of its content for readers.", "labels": [], "entities": []}, {"text": "Automatic keyphrase extraction is widely used in information retrieval and digital library.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.7383574694395065}, {"text": "information retrieval", "start_pos": 49, "end_pos": 70, "type": "TASK", "confidence": 0.8306567072868347}]}, {"text": "Keyphrase extraction is also an essential step in various tasks of natural language processing such as document categorization, clustering and summarization).", "labels": [], "entities": [{"text": "Keyphrase extraction", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8782968819141388}, {"text": "summarization", "start_pos": 143, "end_pos": 156, "type": "TASK", "confidence": 0.9585061073303223}]}, {"text": "There are two principled approaches to extracting keyphrases: supervised and unsupervised.", "labels": [], "entities": []}, {"text": "The supervised approach) regards keyphrase extraction as a classification task, in which a model is trained to determine whether a candidate phrase is a keyphrase.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.8812377154827118}]}, {"text": "Supervised methods require a document set with human-assigned keyphrases as training set.", "labels": [], "entities": []}, {"text": "In Web era, articles increase exponentially and change dynamically, which demands keyphrase extraction to be efficient and adaptable.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 82, "end_pos": 102, "type": "TASK", "confidence": 0.7699982821941376}]}, {"text": "However, since human labeling is time consuming, it is impractical to label training set from time to time.", "labels": [], "entities": [{"text": "human labeling", "start_pos": 15, "end_pos": 29, "type": "TASK", "confidence": 0.5938231348991394}]}, {"text": "We thus focus on the unsupervised approach in this study.", "labels": [], "entities": []}, {"text": "In the unsupervised approach, graph-based ranking methods are state-of-the-art ().", "labels": [], "entities": []}, {"text": "These methods first build a word graph according to word co-occurrences within the document, and then use random walk techniques (e.g., PageRank) to measure word importance.", "labels": [], "entities": []}, {"text": "After that, top ranked words are selected as keyphrases.", "labels": [], "entities": []}, {"text": "Existing graph-based methods maintain a single importance score for each word.", "labels": [], "entities": []}, {"text": "However, a document (e.g., news article or research article) is usually composed of multiple semantic topics.", "labels": [], "entities": []}, {"text": "Taking this paper for example, it refers to two major topics, \"keyphrase extraction\" and \"random walk\".", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 63, "end_pos": 83, "type": "TASK", "confidence": 0.8068360686302185}]}, {"text": "As words are used to express various meanings corresponding to different semantic topics, a word will play different importance roles in different topics of the document.", "labels": [], "entities": []}, {"text": "For example, the words \"phrase\" and \"extraction\" will be ranked to be more important in topic \"keyphrase extraction\", while the words \"graph\" and \"PageRank\" will be more important in topic \"random walk\".", "labels": [], "entities": [{"text": "topic \"keyphrase extraction\"", "start_pos": 88, "end_pos": 116, "type": "TASK", "confidence": 0.6516237378120422}]}, {"text": "Since they do not take topics into account, graph-based methods may suffer from the following two problems: 1.", "labels": [], "entities": []}, {"text": "Good keyphrases should be relevant to the major topics of the given document.", "labels": [], "entities": []}, {"text": "In graphbased methods, the words that are strongly connected with other words tend to be ranked high, which do not necessarily guarantee they are relevant to major topics of the document.", "labels": [], "entities": []}, {"text": "2. An appropriate set of keyphrases should also have a good coverage of the document's major topics.", "labels": [], "entities": []}, {"text": "In graph-based methods, the extracted keyphrases may fall into a single topic of the document and fail to cover other substantial topics of the document.", "labels": [], "entities": []}, {"text": "To address the problem, it is intuitive to consider the topics of words and document in random walk for keyphrase extraction.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 104, "end_pos": 124, "type": "TASK", "confidence": 0.7734943926334381}]}, {"text": "In this paper, we propose to decompose traditional PageRank into multiple PageRanks specific to various topics and obtain the importance scores of words under different topics.", "labels": [], "entities": []}, {"text": "After that, with the help of the document topics, we can further extract keyphrases that are relevant to the document and at the same time have a good coverage of the document's major topics.", "labels": [], "entities": []}, {"text": "We call the topic-decomposed PageRank as Topical PageRank (TPR).", "labels": [], "entities": []}, {"text": "In experiments we find that TPR can extract keyphrases with high relevance and good coverage, which outperforms other baseline methods under various evaluation metrics on two datasets.", "labels": [], "entities": [{"text": "coverage", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9579448103904724}]}, {"text": "We also investigate the performance of TPR with different parameter values and demonstrate its robustness.", "labels": [], "entities": []}, {"text": "Moreover, TPR is unsupervised and languageindependent, which is applicable in Web era with enormous information.", "labels": [], "entities": []}, {"text": "TPR for keyphrase extraction is a two-stage process: 1.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 8, "end_pos": 28, "type": "TASK", "confidence": 0.8034205734729767}]}, {"text": "Build a topic interpreter to acquire the topics of words and documents.", "labels": [], "entities": []}, {"text": "2. Perform TPR to extract keyphrases for documents.", "labels": [], "entities": [{"text": "Perform TPR", "start_pos": 3, "end_pos": 14, "type": "TASK", "confidence": 0.7373855710029602}]}, {"text": "We will introduce the two stages in Section 2 and Section 3.", "labels": [], "entities": []}], "datasetContent": [{"text": "To evaluate the performance of TPR for keyphrase extraction, we carryout experiments on two datasets.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 39, "end_pos": 59, "type": "TASK", "confidence": 0.8481031060218811}]}, {"text": "One dataset was built by Wan and Xiao 2 which was used in (.", "labels": [], "entities": []}, {"text": "This dataset contains 308 news articles in DUC2001 () with 2, 488 manually annotated keyphrases.", "labels": [], "entities": [{"text": "DUC2001", "start_pos": 43, "end_pos": 50, "type": "DATASET", "confidence": 0.9540798664093018}]}, {"text": "There are at most 10 keyphrases for each document.", "labels": [], "entities": []}, {"text": "In experiments we refer to this dataset as NEWS.", "labels": [], "entities": [{"text": "NEWS", "start_pos": 43, "end_pos": 47, "type": "DATASET", "confidence": 0.9258649945259094}]}, {"text": "The other dataset was built by Hulth 3 which was used in.", "labels": [], "entities": [{"text": "Hulth", "start_pos": 31, "end_pos": 36, "type": "DATASET", "confidence": 0.7173362374305725}]}, {"text": "This dataset contains 2, 000 abstracts of research articles and 19, 254 manually annotated keyphrases.", "labels": [], "entities": []}, {"text": "In experiments we refer to this dataset as RESEARCH.", "labels": [], "entities": [{"text": "RESEARCH", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9715512990951538}]}, {"text": "Since neither NEWS nor RESEARCH itself is large enough to learn efficient topics, we use the Wikipedia snapshot at March 2008 4 to build topic interpreters with LDA.", "labels": [], "entities": [{"text": "NEWS", "start_pos": 14, "end_pos": 18, "type": "DATASET", "confidence": 0.8702120780944824}, {"text": "Wikipedia snapshot at March 2008 4", "start_pos": 93, "end_pos": 127, "type": "DATASET", "confidence": 0.9662415385246277}]}, {"text": "After removing non-article pages and the articles shorter than 100 words, we collected 2, 122, 618 articles.", "labels": [], "entities": []}, {"text": "After tokenization, stop word removal and word stemming, we build the vocabulary by selecting 20, 000 words according to their document frequency.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 6, "end_pos": 18, "type": "TASK", "confidence": 0.9630199670791626}, {"text": "stop word removal", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.6095960835615793}, {"text": "word stemming", "start_pos": 42, "end_pos": 55, "type": "TASK", "confidence": 0.7468740791082382}]}, {"text": "We learn LDA models by taking each Wikipedia article as a document.", "labels": [], "entities": []}, {"text": "In experiments we learned several models with different numbers of topics, from 50 to 1, 500 respectively.", "labels": [], "entities": []}, {"text": "For the words absent in topic models, we simply set the topic distribution of the word as uniform distribution.", "labels": [], "entities": []}, {"text": "For evaluation, the words in both standard and extracted keyphrases are reduced to base forms using Porter Stemmer 5 for comparison.", "labels": [], "entities": [{"text": "Porter Stemmer 5", "start_pos": 100, "end_pos": 116, "type": "DATASET", "confidence": 0.8548340002695719}]}, {"text": "In experiments we select three evaluation metrics.", "labels": [], "entities": []}, {"text": "The first metric is precision/recall/F-measure represented as follows, where c correct is the total number of correct keyphrases extracted by a method, c extract the total number of automatic extracted keyphrases, and c standard the total number of human-labeled standard keyphrases.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9992169141769409}, {"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.8706426620483398}, {"text": "F-measure", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9583443999290466}]}, {"text": "We note that the ranking order of extracted keyphrases also indicates the method performance.", "labels": [], "entities": []}, {"text": "An extraction method will be better than another one if it can rank correct keyphrases higher.", "labels": [], "entities": []}, {"text": "However, precision/recall/F-measure does not take the order of extracted keyphrases into account.", "labels": [], "entities": [{"text": "precision", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.999362051486969}, {"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.8949166536331177}, {"text": "F-measure", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9786247611045837}]}, {"text": "To address the problem, we select the following two additional metrics.", "labels": [], "entities": []}, {"text": "One metric is binary preference measure (Bpref) ().", "labels": [], "entities": [{"text": "binary preference measure (Bpref)", "start_pos": 14, "end_pos": 47, "type": "METRIC", "confidence": 0.8148559133211771}]}, {"text": "Bpref is desirable to evaluate the performance considering the order in which the extracted keyphrases are ranked.", "labels": [], "entities": [{"text": "Bpref", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9607691168785095}]}, {"text": "For a document, if there are R correct keyphrases within M extracted keyphrases by a method, in which r is a correct keyphrase and n is an incorrect keyphrase, Bpref is defined as follows, The other metric is mean reciprocal rank (MRR) which is used to evaluate how the first correct keyphrase for each document is ranked.", "labels": [], "entities": [{"text": "Bpref", "start_pos": 160, "end_pos": 165, "type": "METRIC", "confidence": 0.9948662519454956}, {"text": "mean reciprocal rank (MRR)", "start_pos": 209, "end_pos": 235, "type": "METRIC", "confidence": 0.9412624835968018}]}, {"text": "For a document d, rank dis denoted as the rank of the first correct keyphrase with all extracted keyphrases, MRR is defined as follows, where Dis the document set for keyphrase extraction.", "labels": [], "entities": [{"text": "MRR", "start_pos": 109, "end_pos": 112, "type": "METRIC", "confidence": 0.7788979411125183}, {"text": "keyphrase extraction", "start_pos": 167, "end_pos": 187, "type": "TASK", "confidence": 0.7377725690603256}]}, {"text": "Note that although the evaluation scores of most keyphrase extractors are still lower compared to other NLP-tasks, it does not indicate the performance is poor because even different annotators may assign different keyphrases to the same document.", "labels": [], "entities": [{"text": "keyphrase extractors", "start_pos": 49, "end_pos": 69, "type": "TASK", "confidence": 0.703309640288353}]}], "tableCaptions": [{"text": " Table 1. This observation is consistent  with the findings reported in (", "labels": [], "entities": []}, {"text": " Table 1: Influence of window size W when the num- ber of keyphrases M = 10 on NEWS.", "labels": [], "entities": [{"text": "NEWS", "start_pos": 79, "end_pos": 83, "type": "DATASET", "confidence": 0.9415844678878784}]}, {"text": " Table 2: Influence of the number of topics K when  the number of keyphrases M = 10 on NEWS.", "labels": [], "entities": [{"text": "Influence", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9777259230613708}, {"text": "NEWS", "start_pos": 87, "end_pos": 91, "type": "DATASET", "confidence": 0.9577256441116333}]}, {"text": " Table 3: Influence of three preference value settings  when the number of keyphrases M = 10 on NEWS.", "labels": [], "entities": [{"text": "NEWS", "start_pos": 96, "end_pos": 100, "type": "DATASET", "confidence": 0.9598488807678223}]}, {"text": " Table 4: Comparing results on NEWS when the num- ber of keyphrases M = 10.", "labels": [], "entities": [{"text": "NEWS", "start_pos": 31, "end_pos": 35, "type": "DATASET", "confidence": 0.8580895662307739}]}, {"text": " Table 5: Comparing results on RESEARCH when the  number of keyphrases M = 5.", "labels": [], "entities": [{"text": "RESEARCH", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9462742805480957}]}]}