{"title": [{"text": "Automatic Discovery of Manner Relations and its Applications", "labels": [], "entities": [{"text": "Automatic Discovery of Manner Relations", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.830765300989151}]}], "abstractContent": [{"text": "This paper presents a method for the automatic discovery of MANNER relations from text.", "labels": [], "entities": [{"text": "MANNER relations from text", "start_pos": 60, "end_pos": 86, "type": "TASK", "confidence": 0.8475358188152313}]}, {"text": "An extended definition of MANNER is proposed, including restrictions on the sorts of concepts that can be part of its domain and range.", "labels": [], "entities": []}, {"text": "The connections with other relations and the lexico-syntactic patterns that encode MANNER are analyzed.", "labels": [], "entities": []}, {"text": "A new feature set specialized on MANNER detection is depicted and justified.", "labels": [], "entities": [{"text": "MANNER detection", "start_pos": 33, "end_pos": 49, "type": "TASK", "confidence": 0.9742820560932159}]}, {"text": "Experimental results show improvement over previous attempts to extract MANNER.", "labels": [], "entities": [{"text": "extract MANNER", "start_pos": 64, "end_pos": 78, "type": "TASK", "confidence": 0.5162817686796188}]}, {"text": "Combinations of MANNER with other semantic relations are also discussed.", "labels": [], "entities": []}], "introductionContent": [{"text": "Extracting semantic relations from text is an important step towards understanding the meaning of text.", "labels": [], "entities": [{"text": "Extracting semantic relations from text", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.9015611290931702}]}, {"text": "Many applications that use no semantics, or only shallow semantics, could benefit by having available more text semantics.", "labels": [], "entities": []}, {"text": "Recently, there is a growing interest in text semantics).", "labels": [], "entities": [{"text": "text semantics", "start_pos": 41, "end_pos": 55, "type": "TASK", "confidence": 0.7942635118961334}]}, {"text": "An important semantic relation for many applications is the MANNER relation.", "labels": [], "entities": [{"text": "MANNER relation", "start_pos": 60, "end_pos": 75, "type": "TASK", "confidence": 0.5180122256278992}]}, {"text": "Broadly speaking, MANNER encodes the mode, style, way or fashion in which something is done or happened.", "labels": [], "entities": [{"text": "MANNER encodes the mode, style, way or fashion in which something is done or happened", "start_pos": 18, "end_pos": 103, "type": "Description", "confidence": 0.697660802041783}]}, {"text": "For example, quick delivery encodes a MANNER relation, since quick is the manner in which the delivery happened.", "labels": [], "entities": [{"text": "MANNER relation", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.6192248463630676}]}, {"text": "An application of MANNER detection is Question Answering, where many how questions refer to this particular relation.", "labels": [], "entities": [{"text": "MANNER detection", "start_pos": 18, "end_pos": 34, "type": "TASK", "confidence": 0.9882015585899353}, {"text": "Question Answering", "start_pos": 38, "end_pos": 56, "type": "TASK", "confidence": 0.8298929631710052}]}, {"text": "Consider for example the question How did the President communicate his message?, and the text Through his spokesman, Obama sent a strong message.", "labels": [], "entities": []}, {"text": "To answer such questions, it is useful to identify first the MANNER relations in text.", "labels": [], "entities": [{"text": "MANNER relations", "start_pos": 61, "end_pos": 77, "type": "TASK", "confidence": 0.6424166858196259}]}, {"text": "MANNER occurs frequently in text and it is expressed by a wide variety of lexico-syntactic patterns.", "labels": [], "entities": []}, {"text": "For example, PropBank annotates 8,037 ARGM-MNR relations (10.7%) out of 74,980 adjunct-like arguments (ARGMs).", "labels": [], "entities": []}, {"text": "There are verbs that state a particular way of doing something, e.g., to limp implicitly states a particular way of walking.", "labels": [], "entities": []}, {"text": "Adverbial phrases and prepositional phrases are the most productive patterns, e.g., The nation's industrial sector is now growing very slowly if at all and He started the company on his own.", "labels": [], "entities": []}, {"text": "Consider the following example: The company said Mr. Stronach will personally direct the restructuring assisted by Manfred Gingl, 1 . There are two MANNER relations in this sentence: the underlined chunks of text encode the way in which Mr. Stronach will direct the restructuring.", "labels": [], "entities": []}], "datasetContent": [{"text": "As a learning algorithm we use a Naive Bayes classifier, well known for its simplicity and yet good performance.", "labels": [], "entities": []}, {"text": "We trained our models with the training corpus using 10-fold cross validation, and used the held-out portion to tune the feature set and adjust parameters.", "labels": [], "entities": []}, {"text": "More features than the ones depicted were tried, but we only report the final set.", "labels": [], "entities": []}, {"text": "For example, named entity recognition and flags indicating the presence of AT-LOCATION and AT-TIME relations for the verb were tried, but they did not bring any significant improvement.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 13, "end_pos": 37, "type": "TASK", "confidence": 0.6620392600695292}, {"text": "AT-LOCATION", "start_pos": 75, "end_pos": 86, "type": "METRIC", "confidence": 0.9396089911460876}]}, {"text": "We report results only on the test corpus, which corresponds to instances not seen before and therefore they area honest estimation of the performance.", "labels": [], "entities": []}, {"text": "The improvement brought by subsets of features and statistical significance tests are also reported.", "labels": [], "entities": []}, {"text": "We test the significance of the difference in performance between two feature sets i and j on a set of ins instances with the Z-score test, where z = abs(err i ,err j ) \u03c3 d , err k is the error made using set k, and ADVPs The full set of features yields a F-measure of 0.815.", "labels": [], "entities": [{"text": "ADVPs", "start_pos": 216, "end_pos": 221, "type": "METRIC", "confidence": 0.972419261932373}, {"text": "F-measure", "start_pos": 256, "end_pos": 265, "type": "METRIC", "confidence": 0.9988296627998352}]}, {"text": "The three specialized features (3, 4 and 5) are responsible for an improvement of .168 in the F-measure.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.8814941048622131}]}, {"text": "This difference in performance yields a Z-score of 7.1, which indicates that it is statistically significant.", "labels": [], "entities": [{"text": "Z-score", "start_pos": 40, "end_pos": 47, "type": "METRIC", "confidence": 0.9918662905693054}]}, {"text": "PPs All the features proposed yield a F-measure of 0.693.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9993374943733215}]}, {"text": "The novel features specialized in MANNER detection from PPs (in bold letters in) bring an improvement of 0.059, which again is significant.", "labels": [], "entities": [{"text": "MANNER detection", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.8597805500030518}]}, {"text": "The Z-score is 2.35, i.e., the difference in performance is statistically significant with a confidence greater than 97.5%.", "labels": [], "entities": [{"text": "Z-score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9926284551620483}]}, {"text": "Thus, adding the specialized features is justified.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Mapping for the semantic classes used for defining DOMAIN(MNR) and RANGE(MNR).", "labels": [], "entities": []}, {"text": " Table 2: Syntactic patterns encoding MANNER in PropBank, number of occurrences, and examples. A total of 7,852  MANNER relations are encoded in PropBank between a single node in the syntactic tree and a verb. In all examples,  MNR(x, y) holds, where x is the text underlined. Syntactic annotation comes straight from the Penn TreeBank.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 48, "end_pos": 56, "type": "DATASET", "confidence": 0.931731104850769}, {"text": "MNR", "start_pos": 228, "end_pos": 231, "type": "METRIC", "confidence": 0.9668567776679993}, {"text": "Penn TreeBank", "start_pos": 322, "end_pos": 335, "type": "DATASET", "confidence": 0.9937231242656708}]}, {"text": " Table 6: Results obtained during testing for different sets of features.", "labels": [], "entities": []}]}