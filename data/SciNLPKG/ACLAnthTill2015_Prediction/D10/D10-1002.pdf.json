{"title": [{"text": "Self-training with Products of Latent Variable Grammars", "labels": [], "entities": []}], "abstractContent": [{"text": "We study self-training with products of latent variable grammars in this paper.", "labels": [], "entities": []}, {"text": "We show that increasing the quality of the automatically parsed data used for self-training gives higher accuracy self-trained grammars.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.994339644908905}]}, {"text": "Our genera-tive self-trained grammars reach F scores of 91.6 on the WSJ test set and surpass even discriminative reranking systems without self-training.", "labels": [], "entities": [{"text": "F", "start_pos": 44, "end_pos": 45, "type": "METRIC", "confidence": 0.9990307092666626}, {"text": "WSJ test set", "start_pos": 68, "end_pos": 80, "type": "DATASET", "confidence": 0.977057417233785}]}, {"text": "Additionally, we show that multiple self-trained grammars can be combined in a product model to achieve even higher accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9950329065322876}]}, {"text": "The product model is most effective when the individual underlying grammars are most diverse.", "labels": [], "entities": []}, {"text": "Combining multiple grammars that were self-trained on disjoint sets of un-labeled data results in a final test accuracy of 92.5% on the WSJ test set and 89.6% on our Broadcast News test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9746793508529663}, {"text": "WSJ test set", "start_pos": 136, "end_pos": 148, "type": "DATASET", "confidence": 0.9911174178123474}, {"text": "Broadcast News test set", "start_pos": 166, "end_pos": 189, "type": "DATASET", "confidence": 0.9839551448822021}]}], "introductionContent": [{"text": "The latent variable approach of is capable of learning high accuracy context-free grammars directly from a raw treebank.", "labels": [], "entities": []}, {"text": "It starts from a coarse treebank grammar, and uses latent variables to refine the context-free assumptions encoded in the grammar.", "labels": [], "entities": []}, {"text": "A hierarchical split-and-merge algorithm introduces grammar complexity gradually, iteratively splitting (and potentially merging back) each observed treebank category into a number of increasingly refined latent subcategories.", "labels": [], "entities": []}, {"text": "The Expectation Maximization (EM) algorithm is used to train the model, guaranteeing that each EM iteration will increase the training likelihood.", "labels": [], "entities": [{"text": "Expectation Maximization (EM)", "start_pos": 4, "end_pos": 33, "type": "TASK", "confidence": 0.7037986040115356}]}, {"text": "However, because the latent variable grammars are not explicitly regularized, EM keeps fitting the training data and eventually begins overfitting (.", "labels": [], "entities": []}, {"text": "Moreover, EM is a local method, making no promises regarding the final point of convergence when initialized from different random seeds.", "labels": [], "entities": []}, {"text": "Recently, showed that substantial differences between the learned grammars remain, even if the hierarchical splitting reduces the variance across independent runs of EM.", "labels": [], "entities": []}, {"text": "In order to counteract the overfitting behavior, introduced a linear smoothing procedure that allows training grammars for 6 splitmerge (SM) rounds without overfitting.", "labels": [], "entities": []}, {"text": "The increased expressiveness of the model, combined with the more robust parameter estimates provided by the smoothing, results in a nice increase in parsing accuracy on a held-out set.", "labels": [], "entities": [{"text": "parsing", "start_pos": 150, "end_pos": 157, "type": "TASK", "confidence": 0.961974024772644}, {"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.9618260264396667}]}, {"text": "However, as reported by and, an additional 7th SM round actually hurts performance.", "labels": [], "entities": []}, {"text": "addressed the issue of data sparsity and overfitting from a different angle.", "labels": [], "entities": []}, {"text": "They showed that self-training latent variable grammars on their own output can mitigate data sparsity issues and improve parsing accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 122, "end_pos": 129, "type": "TASK", "confidence": 0.9674041271209717}, {"text": "accuracy", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.8341397643089294}]}, {"text": "Because the capacity of the model can grow with the size of the training data, latent variable grammars are able to benefit from the additional training data, even though it is not perfectly labeled.", "labels": [], "entities": []}, {"text": "Consequently, they also found that a 7th round of SM training was beneficial in the presence of large amounts of training data.", "labels": [], "entities": [{"text": "SM training", "start_pos": 50, "end_pos": 61, "type": "TASK", "confidence": 0.9201341867446899}]}, {"text": "However, variation still remains in their self-trained grammars and they had to use a held-out set for model selection.", "labels": [], "entities": [{"text": "variation", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.9570423364639282}]}, {"text": "The observation of variation is not surprising; EM's tendency to get stuck in local maxima has been studied extensively in the literature, resulting in various proposals for model selection methods (e.g., see).", "labels": [], "entities": []}, {"text": "What is perhaps more surprising is that the different latent variable grammars seem to capture complementary aspects of the data.", "labels": [], "entities": []}, {"text": "showed that a simple randomization scheme produces widely varying grammars.", "labels": [], "entities": []}, {"text": "Quite serendipitously, these grammars can be combined into an unweighted product model that substantially outperforms the individual grammars.", "labels": [], "entities": []}, {"text": "In this paper, we combine the ideas of selftraining and product models and show that both techniques provide complementary effects.", "labels": [], "entities": []}, {"text": "We hypothesize that the main factors contributing to the final accuracy of the product model of self-trained grammars are (i) the accuracy of the grammar used to parse the unlabeled data for retraining (single grammar versus product of grammars) and (ii) the diversity of the grammars that are being combined (self-trained grammars trained using the same automatically labeled subset or different subsets).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9972979426383972}, {"text": "accuracy", "start_pos": 130, "end_pos": 138, "type": "METRIC", "confidence": 0.9992458820343018}]}, {"text": "We conduct a series of analyses to develop an understanding of these factors, and conclude that both dimensions are important for obtaining significant improvements over the standard product models.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we compare single grammars and their products that are trained in the standard way with gold WSJ training data, as well as the three self-training scenarios discussed in Section 3.", "labels": [], "entities": [{"text": "WSJ training data", "start_pos": 110, "end_pos": 127, "type": "DATASET", "confidence": 0.7997990051905314}]}, {"text": "We  report the F scores of both SM6 and SM7 grammars on the development set in order to evaluate the effect of model complexity on the performance of the self-trained and product models.", "labels": [], "entities": [{"text": "F scores", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9803761541843414}]}, {"text": "Note that we use 6th round grammars to produce the automatic parse trees for the self-training experiments.", "labels": [], "entities": []}, {"text": "Parsing with the product of the 7th round grammars is slow and requires a large amount of memory (32GB).", "labels": [], "entities": [{"text": "Parsing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9755673408508301}]}, {"text": "Since we had limited access to such machines, it was infeasible for us to parse all of the unlabeled data with the SM7 product grammars.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The number of words and sentences, together with average (Avg.) sentence length and its standard deviation  (Std.), for the data sets used in our experiments.", "labels": [], "entities": [{"text": "Avg.) sentence length", "start_pos": 68, "end_pos": 89, "type": "METRIC", "confidence": 0.9157192558050156}, {"text": "standard deviation  (Std.)", "start_pos": 98, "end_pos": 124, "type": "METRIC", "confidence": 0.9259353756904602}]}, {"text": " Table 2: Performance of the regular grammars and their  products on the WSJ development set.", "labels": [], "entities": [{"text": "WSJ development set", "start_pos": 73, "end_pos": 92, "type": "DATASET", "confidence": 0.9466489553451538}]}, {"text": " Table 3: Performance of the ST-Reg grammars and their  products on the WSJ development set.", "labels": [], "entities": [{"text": "WSJ development set", "start_pos": 72, "end_pos": 91, "type": "DATASET", "confidence": 0.9570910533269247}]}, {"text": " Table 4: Performance of the ST-Prod grammars and their  products on the WSJ development set.", "labels": [], "entities": [{"text": "WSJ development set", "start_pos": 73, "end_pos": 92, "type": "DATASET", "confidence": 0.9522607127825419}]}, {"text": " Table 5: Performance of the ST-Prod-Mult grammars and  their products on the WSJ development set.", "labels": [], "entities": [{"text": "WSJ development set", "start_pos": 78, "end_pos": 97, "type": "DATASET", "confidence": 0.9519783655802408}]}, {"text": " Table 6: F-score for various models on the BN develop- ment set.", "labels": [], "entities": [{"text": "F-score", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9987998008728027}, {"text": "BN develop- ment set", "start_pos": 44, "end_pos": 64, "type": "DATASET", "confidence": 0.918937373161316}]}, {"text": " Table 7: Final test set accuracies on WSJ.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.9334977865219116}, {"text": "WSJ", "start_pos": 39, "end_pos": 42, "type": "DATASET", "confidence": 0.8421295285224915}]}]}