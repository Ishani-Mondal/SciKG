{"title": [{"text": "Lessons Learned in Part-of-Speech Tagging of Conversational Speech", "labels": [], "entities": [{"text": "Part-of-Speech Tagging of Conversational Speech", "start_pos": 19, "end_pos": 66, "type": "TASK", "confidence": 0.8314479112625122}]}], "abstractContent": [{"text": "This paper examines tagging models for spontaneous English speech transcripts.", "labels": [], "entities": []}, {"text": "We analyze the performance of state-of-the-art tagging models, either generative or discrimi-native, left-to-right or bidirectional, with or without latent annotations, together with the use of ToBI break indexes and several methods for segmenting the speech transcripts (i.e., conversation side, speaker turn, or human-annotated sentence).", "labels": [], "entities": []}, {"text": "Based on these studies, we observe that: (1) bidirectional models tend to achieve better accuracy levels than left-to-right models, (2) generative models seem to perform somewhat better than discriminative models on this task, and (3) prosody improves tagging performance of models on conversation sides, but has much less impact on smaller segments.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9971202611923218}]}, {"text": "We conclude that, although the use of break indexes can indeed significantly improve performance over baseline models without them on conversation sides, tagging accuracy improves more by using smaller segments , for which the impact of the break indexes is marginal.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 162, "end_pos": 170, "type": "METRIC", "confidence": 0.9111285209655762}]}], "introductionContent": [{"text": "Natural language processing technologies, such as parsing and tagging, often require reconfiguration when they are applied to challenging domains that differ significantly from newswire, e.g., blogs, twitter text, or speech.", "labels": [], "entities": [{"text": "parsing and tagging", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.6896298229694366}]}, {"text": "In contrast to text, conversational speech represents a significant challenge because the transcripts are not segmented into sentences.", "labels": [], "entities": []}, {"text": "Furthermore, the transcripts are often disfluent and lack punctuation and case information.", "labels": [], "entities": []}, {"text": "On the other hand, speech provides additional information, beyond simply the sequence of words, which could be exploited to more accurately assign each word in the transcript a part-of-speech (POS) tag.", "labels": [], "entities": []}, {"text": "One potentially beneficial type of information is prosody (.", "labels": [], "entities": []}, {"text": "Prosody provides cues for lexical disambiguation, sentence segmentation and classification, phrase structure and attachment, discourse structure, speaker affect, etc.", "labels": [], "entities": [{"text": "sentence segmentation and classification", "start_pos": 50, "end_pos": 90, "type": "TASK", "confidence": 0.7256275936961174}, {"text": "phrase structure and attachment", "start_pos": 92, "end_pos": 123, "type": "TASK", "confidence": 0.7914682775735855}]}, {"text": "Prosody has been found to play an important role in speech synthesis systems (, as well as in speech recognition (.", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 52, "end_pos": 68, "type": "TASK", "confidence": 0.7787895798683167}, {"text": "speech recognition", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.8364394009113312}]}, {"text": "Additionally, prosodic features such as pause length, duration of words and phones, pitch contours, energy contours, and their normalized values have been used for speech processing tasks like sentence boundary detection ( ).", "labels": [], "entities": [{"text": "sentence boundary detection", "start_pos": 193, "end_pos": 220, "type": "TASK", "confidence": 0.6776664555072784}]}, {"text": "Linguistic encoding schemes like ToBI) have also been used for sentence boundary detection), as well as for parsing).", "labels": [], "entities": [{"text": "sentence boundary detection", "start_pos": 63, "end_pos": 90, "type": "TASK", "confidence": 0.6942607164382935}, {"text": "parsing", "start_pos": 108, "end_pos": 115, "type": "TASK", "confidence": 0.9673247337341309}]}, {"text": "In the ToBI scheme, aspects of prosody such as tone, prominence, and degree of juncture between words are represented symbolically.", "labels": [], "entities": []}, {"text": "For instance, use three classes of automatically detected ToBI break indexes, indicating major intonational breaks with a 4, hesitation with a p, and all other breaks with a 1.", "labels": [], "entities": [{"text": "hesitation", "start_pos": 125, "end_pos": 135, "type": "METRIC", "confidence": 0.9753395915031433}]}, {"text": "Recently, found that they could effectively integrate prosodic informa-tion in the form of this simplified three class ToBI encoding when parsing spontaneous speech by using a prosodically enriched PCFG model with latent annotations (PCFG-LA) () to rescore n-best parses produced by a baseline PCFG-LA model without prosodic enrichment.", "labels": [], "entities": [{"text": "parsing spontaneous speech", "start_pos": 138, "end_pos": 164, "type": "TASK", "confidence": 0.8878408670425415}]}, {"text": "However, the prosodically enriched models by themselves did not perform significantly better than the baseline PCFG-LA model without enrichment, due to the negative effect that misalignments between automatic prosodic breaks and true phrase boundaries have on the model.", "labels": [], "entities": []}, {"text": "This paper investigates methods for using stateof-the-art taggers on conversational speech transcriptions and the effect that prosody has on tagging accuracy.", "labels": [], "entities": [{"text": "conversational speech transcriptions", "start_pos": 69, "end_pos": 105, "type": "TASK", "confidence": 0.6998857657114664}, {"text": "accuracy", "start_pos": 149, "end_pos": 157, "type": "METRIC", "confidence": 0.9055857062339783}]}, {"text": "Improving POS tagging performance of speech transcriptions has implications for improving downstream applications that rely on accurate POS tags, including sentence boundary detection ( ), automatic punctuation (), information extraction from speech, parsing, and syntactic language modeling.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.8427794277667999}, {"text": "sentence boundary detection", "start_pos": 156, "end_pos": 183, "type": "TASK", "confidence": 0.6655321021874746}, {"text": "information extraction from speech", "start_pos": 215, "end_pos": 249, "type": "TASK", "confidence": 0.8556932210922241}, {"text": "syntactic language modeling", "start_pos": 264, "end_pos": 291, "type": "TASK", "confidence": 0.7048641641934713}]}, {"text": "While there have been several attempts to integrate prosodic information to improve parse accuracy of speech transcripts, to the best of our knowledge there has been little work on using this type of information for POS tagging.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9354828000068665}, {"text": "POS tagging", "start_pos": 216, "end_pos": 227, "type": "TASK", "confidence": 0.9715857803821564}]}, {"text": "Furthermore, most of the parsing work has involved generative models and rescoring/reranking of hypotheses from the generative models.", "labels": [], "entities": [{"text": "parsing", "start_pos": 25, "end_pos": 32, "type": "TASK", "confidence": 0.9760538339614868}, {"text": "generative", "start_pos": 51, "end_pos": 61, "type": "TASK", "confidence": 0.9809393882751465}]}, {"text": "In this work, we will analyze several factors related to effective POS tagging of conversational speech: \u2022 discriminative versus generative POS tagging models (Section 2) \u2022 prosodic features in the form of simplified ToBI break indexes (Section 4) \u2022 type of speech segmentation (Section 5)", "labels": [], "entities": [{"text": "POS tagging of conversational speech", "start_pos": 67, "end_pos": 103, "type": "TASK", "confidence": 0.8673137903213501}, {"text": "POS tagging", "start_pos": 140, "end_pos": 151, "type": "TASK", "confidence": 0.6442181617021561}, {"text": "type of speech segmentation", "start_pos": 250, "end_pos": 277, "type": "TASK", "confidence": 0.6500672623515129}]}], "datasetContent": [{"text": "In the rest of this paper, we evaluate the tagging models described in Section 2 on conversational speech.", "labels": [], "entities": []}, {"text": "We chose to utilize the Penn Switchboard ( and Fisher treebanks () because they provide gold standard tags for conversational speech and we have access to corresponding automatically generated ToBI break indexes provided by) 2 . We utilized the Fisher dev1 and dev2 sets containing 16,519 sentences (112,717 words) as the primary training data and the entire Penn Switchboard treebank containing 110,504 sentences (837,863 words) as an additional training source . The treebanks were preprocessed as follows: the tags of auxiliary verbs were replaced with the AUX tag, empty nodes and function tags were removed, words were downcased, punctuation was deleted, and the words and their tags were extracted.", "labels": [], "entities": [{"text": "Penn Switchboard", "start_pos": 24, "end_pos": 40, "type": "DATASET", "confidence": 0.969031810760498}, {"text": "Fisher treebanks", "start_pos": 47, "end_pos": 63, "type": "DATASET", "confidence": 0.9037069976329803}, {"text": "Penn Switchboard treebank", "start_pos": 359, "end_pos": 384, "type": "DATASET", "confidence": 0.9694154659907023}]}, {"text": "Because the Fisher treebank was developed using the lessons learned when developing Switchboard, we chose to use its eval portion for development (the first 1,020 tagged sentences containing 7,184 words) and evaluation (the remaining 3,917 sentences with 29,173 words).", "labels": [], "entities": [{"text": "Fisher treebank", "start_pos": 12, "end_pos": 27, "type": "DATASET", "confidence": 0.8748282790184021}]}, {"text": "We utilize the development set differently for the generative and discriminative models.", "labels": [], "entities": [{"text": "generative", "start_pos": 51, "end_pos": 61, "type": "TASK", "confidence": 0.964643657207489}]}, {"text": "Since the EM algorithm used for estimating the parameters in the latent variable models introduces a lot of variability, we train five models with a different seed and then choose the best one based on dev set performance.", "labels": [], "entities": []}, {"text": "For the discriminative models, we tuned their respective regularization parameters on the dev set.", "labels": [], "entities": []}, {"text": "All results reported in the rest of this paper are on the test set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Tagging accuracy on WSJ", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9790810942649841}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9818665385246277}, {"text": "WSJ", "start_pos": 30, "end_pos": 33, "type": "DATASET", "confidence": 0.803024411201477}]}, {"text": " Table 4: Baseline tagging accuracy on automatically de- tected sentence boundaries", "labels": [], "entities": [{"text": "Baseline tagging", "start_pos": 10, "end_pos": 26, "type": "TASK", "confidence": 0.8105379343032837}, {"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9873338937759399}]}, {"text": " Table 6: Length statistics of different data segmentations", "labels": [], "entities": [{"text": "Length", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9208917021751404}]}]}