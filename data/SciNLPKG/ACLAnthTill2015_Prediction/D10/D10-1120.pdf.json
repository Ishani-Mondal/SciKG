{"title": [{"text": "Using Universal Linguistic Knowledge to Guide Grammar Induction", "labels": [], "entities": []}], "abstractContent": [{"text": "We present an approach to grammar induction that utilizes syntactic universals to improve dependency parsing across a range of languages.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7292712330818176}, {"text": "dependency parsing", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.7809484899044037}]}, {"text": "Our method uses a single set of manually-specified language-independent rules that identify syntactic dependencies between pairs of syntactic categories that commonly occur across languages.", "labels": [], "entities": []}, {"text": "During inference of the probabilistic model, we use posterior expectation constraints to require that a minimum proportion of the dependencies we infer be instances of these rules.", "labels": [], "entities": []}, {"text": "We also automatically refine the syntactic categories given in our coarsely tagged input.", "labels": [], "entities": []}, {"text": "Across six languages our approach outperforms state-of-the-art unsupervised methods by a significant margin.", "labels": [], "entities": []}], "introductionContent": [{"text": "Despite surface differences, human languages exhibit striking similarities in many fundamental aspects of syntactic structure.", "labels": [], "entities": []}, {"text": "These structural correspondences, referred to as syntactic universals, have been extensively studied in linguistics) and underlie many approaches in multilingual parsing.", "labels": [], "entities": [{"text": "multilingual parsing", "start_pos": 149, "end_pos": 169, "type": "TASK", "confidence": 0.6900047659873962}]}, {"text": "In fact, much recent work has demonstrated that learning cross-lingual correspondences from corpus data greatly reduces the ambiguity inherent in syntactic analysis: The manually-specified universal dependency rules used in our experiments.", "labels": [], "entities": [{"text": "syntactic analysis", "start_pos": 146, "end_pos": 164, "type": "TASK", "confidence": 0.7153857946395874}]}, {"text": "These rules specify headdependent relationships between coarse (i.e., unsplit) syntactic categories.", "labels": [], "entities": []}, {"text": "An explanation of the ruleset is provided in In this paper, we present an alternative grammar induction approach that exploits these structural correspondences by declaratively encoding a small set of universal dependency rules.", "labels": [], "entities": []}, {"text": "As input to the model, we assume a corpus annotated with coarse syntactic categories (i.e., high-level part-ofspeech tags) and a set of universal rules defined over these categories, such as those in.", "labels": [], "entities": []}, {"text": "These rules incorporate the definitional properties of syntactic categories in terms of their interdependencies and thus are universal across languages.", "labels": [], "entities": []}, {"text": "They can potentially help disambiguate structural ambiguities that are difficult to learn from data alone -for example, our rules prefer analyses in which verbs are dependents of auxiliaries, even though analyzing auxiliaries as dependents of verbs is also consistent with the data.", "labels": [], "entities": []}, {"text": "Leveraging these universal rules has the potential to improve parsing performance fora large number of human languages; this is particularly relevant to the processing of low-resource languages.", "labels": [], "entities": []}, {"text": "Furthermore, these universal rules are compact and well-understood, making them easy to manually construct.", "labels": [], "entities": []}, {"text": "In addition to these universal dependencies, each specific language typically possesses its own idiosyncratic set of dependencies.", "labels": [], "entities": []}, {"text": "We address this challenge by requiring the universal constraints to only hold in expectation rather than absolutely, i.e., we permit a certain number of violations of the constraints.", "labels": [], "entities": []}, {"text": "We formulate a generative Bayesian model that explains the observed data while accounting for declarative linguistic rules during inference.", "labels": [], "entities": []}, {"text": "These rules are used as expectation constraints on the posterior distribution over dependency structures.", "labels": [], "entities": []}, {"text": "This approach is based on the posterior regularization technique), which we apply to a variational inference algorithm for our parsing model.", "labels": [], "entities": []}, {"text": "Our model can also optionally refine common high-level syntactic categories into per-language categories by inducing a clustering of words using Dirichlet Processes.", "labels": [], "entities": []}, {"text": "Since the universals guide induction toward linguistically plausible structures, automatic refinement becomes feasible even in the absence of manually annotated syntactic trees.", "labels": [], "entities": []}, {"text": "We test the effectiveness of our grammar induction model on six Indo-European languages from three language groups: English, Danish, Portuguese, Slovene, Spanish, and Swedish.", "labels": [], "entities": []}, {"text": "Though these languages share a high-level Indo-European ancestry, they cover a diverse range of syntactic phenomenon.", "labels": [], "entities": []}, {"text": "Our results demonstrate that universal rules greatly improve the accuracy of dependency parsing across all of these languages, outperforming current stateof-the-art unsupervised grammar induction methods).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9984910488128662}, {"text": "dependency parsing", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.7042693197727203}]}], "datasetContent": [{"text": "Datasets and Evaluation We test the effectiveness of our grammar induction approach on English, Danish, Portuguese, Slovene, Spanish, and Swedish.", "labels": [], "entities": [{"text": "grammar induction", "start_pos": 57, "end_pos": 74, "type": "TASK", "confidence": 0.6872923523187637}]}, {"text": "For English we use the Penn Treebank (, transformed from CFG parses into depen-dencies with the Collins head finding rules; for the other languages we use data from the 2006 CoNLL-X Shared Task ().", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 23, "end_pos": 36, "type": "DATASET", "confidence": 0.9925311207771301}, {"text": "CFG", "start_pos": 57, "end_pos": 60, "type": "DATASET", "confidence": 0.933451771736145}]}, {"text": "Each dataset provides manually annotated part-of-speech tags that are used for both training and testing.", "labels": [], "entities": []}, {"text": "For comparison purposes with previous work, we limit the cross-lingual experiments to sentences of length 10 or less (not counting punctuation).", "labels": [], "entities": []}, {"text": "For English, we also explore sentences of length up to 20.", "labels": [], "entities": []}, {"text": "The final output metric is directed dependency accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.8374612331390381}]}, {"text": "This is computed based on the Viterbi parses produced using the final unnormalized variational distribution q(z) over dependency structures.", "labels": [], "entities": []}, {"text": "Hyperparameters and Training Regimes Unless otherwise stated, in experiments with rule-based constraints the expected proportion of dependencies that must satisfy those constraints is set to 0.8.", "labels": [], "entities": []}, {"text": "This threshold value was chosen based on minimal tuning on a single language and ruleset (English with universal rules) and carried over to each other experimental condition.", "labels": [], "entities": []}, {"text": "A more detailed discussion of the threshold's empirical impact is presented in Section 7.1.", "labels": [], "entities": [{"text": "Section 7.1", "start_pos": 79, "end_pos": 90, "type": "DATASET", "confidence": 0.8788986802101135}]}, {"text": "Variational approximations to the HDP are truncated at 10.", "labels": [], "entities": [{"text": "HDP", "start_pos": 34, "end_pos": 37, "type": "DATASET", "confidence": 0.8601460456848145}]}, {"text": "All hyperparameter values are fixed to 1 except \u03b1 which is fixed to 10.", "labels": [], "entities": []}, {"text": "We also conduct a set of No-Split experiments to evaluate the importance of syntactic refinement; in these experiments each coarse symbol corresponds to only one refined symbol.", "labels": [], "entities": []}, {"text": "This is easily effected during inference by setting the HDP variational approximation truncation level to one.", "labels": [], "entities": [{"text": "HDP variational approximation truncation level", "start_pos": 56, "end_pos": 102, "type": "METRIC", "confidence": 0.6940356373786927}]}, {"text": "For each experiment we run 50 iterations of variational updates; for each iteration we perform five steps of gradient search to compute the update for the variational distribution q(z) over dependency structures.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Directed dependency accuracy using our model  with universal dependency rules (No-Split and HDP- DEP), compared to DMV (", "labels": [], "entities": [{"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9637580513954163}]}, {"text": " Table 5: Ablation experiment results for universal depen- dency rules on English and Spanish. For each rule, we  evaluate the model using the ruleset excluding that rule,  and list the most significant rules for each language. The  second last column is the absolute loss in performance  compared to the setting where all rules are available. The  last column shows the percentage of the gold dependen- cies that satisfy the rule.", "labels": [], "entities": []}]}