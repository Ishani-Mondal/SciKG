{"title": [{"text": "Discriminative Word Alignment with a Function Word Reordering Model", "labels": [], "entities": [{"text": "Discriminative Word Alignment", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6724794606367747}]}], "abstractContent": [{"text": "We address the modeling, parameter estimation and search challenges that arise from the introduction of reordering models that capture non-local reordering in alignment modeling.", "labels": [], "entities": [{"text": "parameter estimation", "start_pos": 25, "end_pos": 45, "type": "TASK", "confidence": 0.7162005305290222}, {"text": "alignment modeling", "start_pos": 159, "end_pos": 177, "type": "TASK", "confidence": 0.9221062362194061}]}, {"text": "In particular, we introduce several reordering models that utilize (pairs of) function words as contexts for alignment reordering.", "labels": [], "entities": []}, {"text": "To address the parameter estimation challenge, we propose to estimate these reordering models from a relatively small amount of manually-aligned corpora.", "labels": [], "entities": [{"text": "parameter estimation", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.6706394106149673}]}, {"text": "To address the search challenge , we devise an iterative local search algorithm that stochastically explores reordering possibilities.", "labels": [], "entities": []}, {"text": "By capturing non-local reordering phenomena, our proposed alignment model bears a closer resemblance to state-of-the-art translation model.", "labels": [], "entities": []}, {"text": "Empirical results show significant improvements in alignment quality as well as in translation performance over baselines in a large-scale Chinese-English translation task.", "labels": [], "entities": [{"text": "translation", "start_pos": 83, "end_pos": 94, "type": "TASK", "confidence": 0.9548206329345703}, {"text": "Chinese-English translation task", "start_pos": 139, "end_pos": 171, "type": "TASK", "confidence": 0.7582346200942993}]}], "introductionContent": [{"text": "In many Statistical Machine Translation (SMT) systems, alignment represents an important piece of information, from which translation rules are learnt.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 8, "end_pos": 45, "type": "TASK", "confidence": 0.8327998022238413}]}, {"text": "However, while translation models have evolved from word-based to syntax-based modeling, the de facto alignment model remains word-based ().", "labels": [], "entities": []}, {"text": "This gap between alignment modeling and translation modeling is clearly undesirable as it often generates tensions that would prevent the extraction of many useful translation rules.", "labels": [], "entities": [{"text": "alignment modeling", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.9752756357192993}, {"text": "translation modeling", "start_pos": 40, "end_pos": 60, "type": "TASK", "confidence": 0.9834830164909363}]}, {"text": "Recent work, e.g. by and just to name a few, show that alignment models that bear closer resemblance to state-of-theart translation model consistently yields not only a better alignment quality but also an improved translation quality.", "labels": [], "entities": []}, {"text": "In this paper, we follow this recent effort to narrow the gap between alignment model and translation model to improve translation quality.", "labels": [], "entities": [{"text": "translation", "start_pos": 119, "end_pos": 130, "type": "TASK", "confidence": 0.9588097333908081}]}, {"text": "More concretely, we focus on the reordering component since we observe that the treatment of reordering remains significantly different when comparing alignment versus translation: the reordering component in state-of-the-art translation models has focused on long-distance reordering, but its counterpart in alignment models has remained focused on local reordering, typically modeling distortion based entirely on positional information.", "labels": [], "entities": []}, {"text": "This leaves most alignment decisions to association-based scores.", "labels": [], "entities": []}, {"text": "Why is employing stronger reordering models more challenging in alignment than in translation?", "labels": [], "entities": []}, {"text": "One answer can be attributed to the fact that alignment points are unobserved in parallel text, thus so are their reorderings.", "labels": [], "entities": []}, {"text": "As such, introducing stronger reordering often further exacerbates the computational complexity to do inference over the model.", "labels": [], "entities": []}, {"text": "Some recent alignment models appeal to external linguistic knowledge, mostly by using monolingual syntactic parses), which at the same time, provides an approximation of the bilingual syntactic divergences that drive the reordering.", "labels": [], "entities": []}, {"text": "To our knowledge, however, this approach has been used mainly to constrain reordering possibilities, or to add to the generalization ability of association-based scores, not to directly model reordering in the context of alignment.", "labels": [], "entities": []}, {"text": "In this paper, we introduce anew approach to improving the modeling of reordering in alignment.", "labels": [], "entities": []}, {"text": "Instead of relying on monolingual parses, we condition our reordering model on the behavior of function words and the phrases that surround them.", "labels": [], "entities": []}, {"text": "Function words are the \"syntactic glue\" of sentences, and in fact many syntacticians believe that functional categories, as opposed to substantive categories like noun and verb, are primarily responsible for cross-language syntactic variation.", "labels": [], "entities": [{"text": "cross-language syntactic variation", "start_pos": 208, "end_pos": 242, "type": "TASK", "confidence": 0.7318290869394938}]}, {"text": "Our reordering model can be seen as offering a reasonable approximation to more fully elaborated bilingual syntactic modeling, and this approximation is also highly practical, as it demands no external knowledge (other than a list of function words) and avoids the practical issues associated with the use of monolingual parses, e.g. whether the monolingual parser is robust enough to produce reliable output for every sentence in training data.", "labels": [], "entities": []}, {"text": "At a glance, our reordering model enumerates the function words on both source and target sides, modeling their reordering relative to their neighboring phrases, their neighboring function words, and the sentence boundaries.", "labels": [], "entities": []}, {"text": "Because the frequency of function words is high, we find that by predicting the reordering of function words accurately, the reordering of the remaining words improves inaccuracy as well.", "labels": [], "entities": []}, {"text": "In total, we introduce six sub-models involving function words, and these serve as features in a log linear model.", "labels": [], "entities": []}, {"text": "We train model weights discriminatively using Minimum Error Rate Training (MERT), optimizing F-measure.", "labels": [], "entities": [{"text": "Minimum Error Rate Training (MERT)", "start_pos": 46, "end_pos": 80, "type": "METRIC", "confidence": 0.8401489853858948}, {"text": "F-measure", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.9846889972686768}]}, {"text": "The parameters of our sub-models are estimated from manually-aligned corpora, leading the reordering model more directly toward reproducing human alignments, rather than maximizing the likelihood of unaligned training data.", "labels": [], "entities": []}, {"text": "This use of manual data for parameter estimation is a reasonable choice because these models depend on a small, fixed number of lexical items that occur frequently in language, hence only small training corpora are required.", "labels": [], "entities": [{"text": "parameter estimation", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.7123348712921143}]}, {"text": "In addition, the availability of manually-aligned corpora has been growing steadily.", "labels": [], "entities": []}, {"text": "The remainder of the paper proceeds as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we provide empirical motivation for our approach.", "labels": [], "entities": []}, {"text": "In Section 3, we discuss six submodels based on function word relationships and how their parameters are estimated; these are com-  bined with additional features in Section 4 to produce a single discriminative alignment model.", "labels": [], "entities": []}, {"text": "Section 5 describes a simple decoding algorithm to find the most probable alignment under the combined model, Section 6 describes the training of our discriminative model and Section 7 presents experimental results for the model using this algorithm.", "labels": [], "entities": []}, {"text": "We wrap up in Sections 8 and 9 with a discussion of related work and a summary of our conclusions.", "labels": [], "entities": []}, {"text": "shows an example of a Chinese-English sentence pair together with correct alignment points.", "labels": [], "entities": []}, {"text": "Predicting the alignment for this particular ChineseEnglish sentence pair is challenging, since the significantly different syntactic structures of these two languages lead to non-monotone reordering.", "labels": [], "entities": []}, {"text": "For example, an accurate alignment model should account for the fact that prepositional phrases in Chinese appear in a different order than in English, as illustrated by the movement of the phrase \"\u4e0e\u5317\u97e9/with North Korea\" from the beginning of the Chinese noun phrase to the end of the corresponding English.", "labels": [], "entities": []}, {"text": "The central question that concerns us here is how to define and infer regularities that can be useful to predict alignment reorderings.", "labels": [], "entities": [{"text": "alignment reorderings", "start_pos": 113, "end_pos": 134, "type": "TASK", "confidence": 0.8424356877803802}]}, {"text": "The approach we take here is supported by empirical results from a pilot study, conducted as an inquiry into the idea of focusing on function words to model alignment reordering, which we briefly describe.", "labels": [], "entities": [{"text": "alignment reordering", "start_pos": 157, "end_pos": 177, "type": "TASK", "confidence": 0.8459296226501465}]}], "datasetContent": [{"text": "We evaluated our proposed alignment model intrinsically on an alignment task and extrinsically on a large-scale translation task, focusing on ChineseEnglish as the language pair.", "labels": [], "entities": []}, {"text": "Our training data consists of manually aligned corpora available from LDC (LDC2006E93 and LDC2008E57) and unaligned corpora, which include FBIS, ISI, HKNews and Xinhua.", "labels": [], "entities": [{"text": "FBIS", "start_pos": 139, "end_pos": 143, "type": "DATASET", "confidence": 0.9146462678909302}, {"text": "ISI", "start_pos": 145, "end_pos": 148, "type": "DATASET", "confidence": 0.859493613243103}, {"text": "HKNews", "start_pos": 150, "end_pos": 156, "type": "DATASET", "confidence": 0.9339668154716492}]}, {"text": "In total, the manually aligned corpora consist of more than 21 thousand sentence pairs, while the unaligned corpora consist of more than 710 thousand sentence pairs.", "labels": [], "entities": []}, {"text": "The manually-aligned corpora are primarily used for training the reordering models and for discriminative training purposes.", "labels": [], "entities": []}, {"text": "For translation experiments, we used cdec (, a fast implementation of hierarchical phrase-based translation models, which represents a state-of-the-art translation system.", "labels": [], "entities": []}, {"text": "We constructed the list of function words in English manually and in Chinese from).", "labels": [], "entities": []}, {"text": "Punctuation marks were added to the list, resulting in 883 and 359 tokens in the Chinese and English lists, respectively.", "labels": [], "entities": []}, {"text": "For the alignment experiments, we took the first 500 sentence pairs from the newswire genre of the manually-aligned corpora and used the first 250 sentences as the development set, with the remaining 250 as the test set.", "labels": [], "entities": []}, {"text": "To ensure blind experimentation, we excluded these sentence pairs from the training of the features, including the reordering models.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Alignment quality results (F 0.1 ) for our discrim- inative reordering models with various features (lines 2- 5) versus the baseline IBM word-based Model 4 sym- metrized using the grow-diag-final-and heuristic. The  balanced F 0.5 measure is reported for reference. The best  scores are bolded.", "labels": [], "entities": [{"text": "F 0.1 )", "start_pos": 37, "end_pos": 44, "type": "METRIC", "confidence": 0.9731764992078146}, {"text": "F 0.5 measure", "start_pos": 235, "end_pos": 248, "type": "METRIC", "confidence": 0.9515853921572367}]}]}