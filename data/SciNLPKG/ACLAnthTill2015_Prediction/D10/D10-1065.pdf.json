{"title": [{"text": "Combining Unsupervised and Supervised Alignments for MT: An Empirical Study", "labels": [], "entities": [{"text": "MT", "start_pos": 53, "end_pos": 55, "type": "TASK", "confidence": 0.9739636778831482}]}], "abstractContent": [{"text": "Word alignment plays a central role in statistical MT (SMT) since almost all SMT systems extract translation rules from word aligned parallel training data.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7374887019395828}, {"text": "MT (SMT)", "start_pos": 51, "end_pos": 59, "type": "TASK", "confidence": 0.8513707667589188}, {"text": "SMT", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.9704799056053162}]}, {"text": "While most SMT systems use unsupervised algorithms (e.g. GIZA++) for training word alignment, supervised methods, which exploit a small amount of human-aligned data, have become increasingly popular recently.", "labels": [], "entities": [{"text": "SMT", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9919219017028809}, {"text": "training word alignment", "start_pos": 69, "end_pos": 92, "type": "TASK", "confidence": 0.6213504473368326}]}, {"text": "This work empirically studies the performance of these two classes of alignment algorithms and explores strategies to combine them to improve overall system performance.", "labels": [], "entities": []}, {"text": "We used two unsupervised aligners, GIZA++ and HMM, and one supervised aligner, ITG, in this study.", "labels": [], "entities": [{"text": "GIZA", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.7720676064491272}]}, {"text": "To avoid language and genre specific conclusions, we ran experiments on test sets consisting of two language pairs (Chinese-to-English and Arabic-to-English) and two genres (newswire and we-blog).", "labels": [], "entities": []}, {"text": "Results show that the two classes of algorithms achieve the same level of MT performance.", "labels": [], "entities": [{"text": "MT", "start_pos": 74, "end_pos": 76, "type": "TASK", "confidence": 0.9850326776504517}]}, {"text": "Modest improvements were achieved by taking the union of the translation grammars extracted from different alignments.", "labels": [], "entities": []}, {"text": "Significant improvements (around 1.0 in BLEU) were achieved by combining outputs of different systems trained with different alignments.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9972749352455139}]}, {"text": "The improvements are consistent across languages and genres.", "labels": [], "entities": []}], "introductionContent": [{"text": "Word alignment plays a central role in training statistical machine translation (SMT) systems since almost all SMT systems extract translation rules from word aligned parallel training data.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7573826909065247}, {"text": "training statistical machine translation (SMT)", "start_pos": 39, "end_pos": 85, "type": "TASK", "confidence": 0.7475188715117318}, {"text": "SMT", "start_pos": 111, "end_pos": 114, "type": "TASK", "confidence": 0.9618852734565735}]}, {"text": "Until recently, most SMT systems used GIZA++, an unsupervised algorithm, for aligning parallel training data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9943208694458008}]}, {"text": "In recent years, with the availability of human aligned training data, supervised methods (e.g. the ITG aligner () have become increasingly popular.", "labels": [], "entities": []}, {"text": "The main objective of this work is to show the two classes (unsupervised and supervised) of algorithms are complementary and combining them will improve overall system performance.", "labels": [], "entities": []}, {"text": "The use of human aligned training data allows supervised methods such as ITG to more accurately align frequent words, such as the alignments of Chinese particles (e.g. \"bei\", \"de\", etc) to their English equivalents (e.g. \"is/are/was/..\", \"of\", etc).", "labels": [], "entities": [{"text": "ITG", "start_pos": 73, "end_pos": 76, "type": "DATASET", "confidence": 0.8794153928756714}]}, {"text": "On the other hand, supervised methods can be affected by suboptimal alignments in hand-aligned data.", "labels": [], "entities": []}, {"text": "For example, the hand-aligned data used in our experiments contain some coarse-grained alignments (e.g. \"lianhe guo\" to \"United Nations\") although fine-grained alignments (\"lian-he\" to \"United\" and \"guo\" to \"Nations\") are usually more appropriate for SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 251, "end_pos": 254, "type": "TASK", "confidence": 0.9957836866378784}]}, {"text": "Unsupervised methods are less likely to be affected by this problem.", "labels": [], "entities": []}, {"text": "We used two well studied unsupervised aligners, GIZA++ and HMM () and one supervised aligner, ITG () as representatives in this work.", "labels": [], "entities": []}, {"text": "We explored two techniques to combine different alignment algorithms.", "labels": [], "entities": []}, {"text": "One is to take the union of the translation rules extracted from alignments produced by different aligners.", "labels": [], "entities": []}, {"text": "This is motivated by studies that showed that the coverage of translation rules is critical to SMT.", "labels": [], "entities": [{"text": "coverage of translation rules", "start_pos": 50, "end_pos": 79, "type": "TASK", "confidence": 0.6263159587979317}, {"text": "SMT", "start_pos": 95, "end_pos": 98, "type": "TASK", "confidence": 0.9954696893692017}]}, {"text": "The other method is to combine the outputs of different MT systems trained using different aligners.", "labels": [], "entities": [{"text": "MT", "start_pos": 56, "end_pos": 58, "type": "TASK", "confidence": 0.9823243618011475}]}, {"text": "Assuming different systems make independent errors, system combination can generate a better translation than those of individual systems through voting (.", "labels": [], "entities": []}, {"text": "Our work differs from previous work in two ways.", "labels": [], "entities": []}, {"text": "Past studies of combining alternative alignments focused on minimizing alignment errors, usually by merging alternative alignments fora sentence pair into a single alignment with the fewest number of incorrect alignment links ().", "labels": [], "entities": []}, {"text": "In contrast, our work is based on the assumption that perfect word alignment is impossible due to the intrinsic difficulty of the problem, and it is more effective to resolve translation ambiguities at later stages of the MT pipeline.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 62, "end_pos": 76, "type": "TASK", "confidence": 0.7117459625005722}, {"text": "MT pipeline", "start_pos": 222, "end_pos": 233, "type": "TASK", "confidence": 0.9405460953712463}]}, {"text": "A main focus of much previous work on word alignments is on theoretical aspects of the proposed algorithms.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.7711004316806793}]}, {"text": "In contrast, the nature of this work is purely empirical.", "labels": [], "entities": []}, {"text": "Our system was trained on a large amount of training data and evaluated on multiple languages (Chinese-to-English and Arabic-to-English) and multiple genres (newswire and weblog).", "labels": [], "entities": []}, {"text": "Furthermore, we used a state of the art string-to-tree decoder) to establish the strongest possible baseline.", "labels": [], "entities": []}, {"text": "In comparison, experiments in previous studies typically used one language pair and one genre (usually newswire), a reduced amount of training data and a phrase based decoder.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the three alignment algorithms.", "labels": [], "entities": []}, {"text": "Section 3 describes the two methods used to combine these aligners to improve MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 78, "end_pos": 80, "type": "TASK", "confidence": 0.9853115081787109}]}, {"text": "The experimental setup used to compare these methods is presented in Section 4.", "labels": [], "entities": []}, {"text": "Section 5 shows the results including a discussion.", "labels": [], "entities": []}, {"text": "Section 6 discusses related work.", "labels": [], "entities": []}, {"text": "Section 7 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "To establish strong baselines, we used a string-totree SMT system, one of the top performing systems in the NIST 2009 MT evaluation, and trained it with very large amounts of parallel and language model data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.8693456053733826}, {"text": "NIST 2009 MT evaluation", "start_pos": 108, "end_pos": 131, "type": "DATASET", "confidence": 0.7264206558465958}]}, {"text": "The system used large sets of discriminatively tuned features (up to 55,000 on Arabic) inspired by the work of.", "labels": [], "entities": []}, {"text": "To avoid drawing language, genre, and metric specific conclusions, we experimented with two language pairs, Arabic-English and ChineseEnglish, and two genres, newswire and weblog, and report both BLEU () and TER () scores.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 196, "end_pos": 200, "type": "METRIC", "confidence": 0.9988625049591064}, {"text": "TER () scores", "start_pos": 208, "end_pos": 221, "type": "METRIC", "confidence": 0.942389170328776}]}, {"text": "Systems were tuned to maximize BLEU on the tuning set using a procedure described in.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.9982407093048096}]}, {"text": "The sizes of the parallel training corpora are 238M words (target side) for Arabic-English MT and 265M words for Chinese-English.", "labels": [], "entities": [{"text": "MT", "start_pos": 91, "end_pos": 93, "type": "TASK", "confidence": 0.8761855959892273}]}, {"text": "While the majority of the data is publicly available from the Linguistic Data Consortium (LDC), some of the data is available under the DARPA GALE program.", "labels": [], "entities": [{"text": "Linguistic Data Consortium (LDC)", "start_pos": 62, "end_pos": 94, "type": "DATASET", "confidence": 0.8424976120392481}, {"text": "DARPA GALE program", "start_pos": 136, "end_pos": 154, "type": "DATASET", "confidence": 0.7581191460291544}]}, {"text": "Due to the size of the parallel corpora, we divided them into five chunks and aligned them in parallel to save time.", "labels": [], "entities": []}, {"text": "Due to its running complexity, we ran ITG only on sentences with 60 or fewer words.", "labels": [], "entities": []}, {"text": "For longer sentences, we used HMM alignments instead, which were conveniently generated in the preprocessing step of ITG aligner.", "labels": [], "entities": []}, {"text": "For language model training, we used about 9 billion words of English text, most of which are from English Gigaword corpus and GoogleNews.", "labels": [], "entities": [{"text": "English Gigaword corpus", "start_pos": 99, "end_pos": 122, "type": "DATASET", "confidence": 0.8587233821551005}]}, {"text": "Each system used a 3-gram LM for decoding and a 5-gram LM for re-scoring.", "labels": [], "entities": []}, {"text": "The same 5-gram LM was also used for re-scoring system combination results.", "labels": [], "entities": []}, {"text": "For each combination of language pair and genre, we used three development sets: \u2022 Tune, which was used to tune parameters of individual MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 137, "end_pos": 139, "type": "TASK", "confidence": 0.9489721059799194}]}, {"text": "Each system was tuned ten iterations based on BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 46, "end_pos": 50, "type": "METRIC", "confidence": 0.9922215342521667}]}, {"text": "\u2022 SysCombTune, which was used to tune parameters of system combination.", "labels": [], "entities": []}, {"text": "A subset of it was also used as validation for determining the best iteration in tuning individual systems.", "labels": [], "entities": []}, {"text": "\u2022 Test, which was the blind test corpus for measuring performances of both individual systems and system combination.", "labels": [], "entities": [{"text": "Test", "start_pos": 2, "end_pos": 6, "type": "METRIC", "confidence": 0.9356846213340759}]}, {"text": "Test materials were drawn from two sources: NIST MT evaluations 2004 to 2008, and development and evaluation data for the DARPA GALE program.", "labels": [], "entities": [{"text": "NIST MT evaluations 2004", "start_pos": 44, "end_pos": 68, "type": "DATASET", "confidence": 0.6660267934203148}, {"text": "DARPA GALE", "start_pos": 122, "end_pos": 132, "type": "TASK", "confidence": 0.5216903537511826}]}, {"text": "Due to the mixing of different data sources, some test sentences have four reference translations while the rest have only one.", "labels": [], "entities": []}, {"text": "The average number of references per test sentence varies across test sets.", "labels": [], "entities": []}, {"text": "For this reason, MT scores are not comparable across test sets.", "labels": [], "entities": [{"text": "MT", "start_pos": 17, "end_pos": 19, "type": "TASK", "confidence": 0.9207519292831421}]}, {"text": "shows the size and the average number of references per sentence of the test sets.", "labels": [], "entities": []}, {"text": "Two hand-aligned corpora were used to train the ITG aligner: LDC2009E82 (Arabic-English) and LDC2009E83 (Chinese-English).", "labels": [], "entities": [{"text": "ITG", "start_pos": 48, "end_pos": 51, "type": "DATASET", "confidence": 0.7916144728660583}]}, {"text": "We re-tokenized the corpora using our tokenizers and projected the LDC alignments to our tokenization heuristically.", "labels": [], "entities": []}, {"text": "The projection was not perfect and sometimes created very coarse-grained alignments.", "labels": [], "entities": []}, {"text": "We used a set of filters to remove such problematic data.", "labels": [], "entities": []}, {"text": "We ended up with 3,667 Arabic-English and 879 ChineseEnglish hand-aligned sentence pairs with sufficient quality for training automatic aligners.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: MT results on Arabic newswire (see footnote 2).", "labels": [], "entities": [{"text": "MT", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.9853212237358093}]}, {"text": " Table 3: MT results on Arabic weblog (see footnote 2).", "labels": [], "entities": [{"text": "MT", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.9774875044822693}, {"text": "Arabic weblog", "start_pos": 24, "end_pos": 37, "type": "DATASET", "confidence": 0.9017412066459656}]}, {"text": " Table 4: MT results on Chinese newswire (see footnote  2).", "labels": [], "entities": [{"text": "MT", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.9866155385971069}, {"text": "Chinese newswire", "start_pos": 24, "end_pos": 40, "type": "DATASET", "confidence": 0.9295650124549866}]}, {"text": " Table 5: MT results on Chinese weblog (see footnote 2).", "labels": [], "entities": [{"text": "MT", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.9689379334449768}, {"text": "Chinese weblog", "start_pos": 24, "end_pos": 38, "type": "DATASET", "confidence": 0.9555265605449677}]}]}