{"title": [{"text": "A Multi-Pass Sieve for Coreference Resolution", "labels": [], "entities": [{"text": "Coreference Resolution", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.9740536212921143}]}], "abstractContent": [{"text": "Most coreference resolution models determine if two mentions are coreferent using a single function over a set of constraints or features.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 5, "end_pos": 27, "type": "TASK", "confidence": 0.950862467288971}]}, {"text": "This approach can lead to incorrect decisions as lower precision features often overwhelm the smaller number of high precision ones.", "labels": [], "entities": [{"text": "precision", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.992052435874939}]}, {"text": "To overcome this problem, we propose a simple coreference architecture based on a sieve that applies tiers of deterministic coreference models one at a time from highest to lowest precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 180, "end_pos": 189, "type": "METRIC", "confidence": 0.9362182021141052}]}, {"text": "Each tier builds on the previous tier's entity cluster output.", "labels": [], "entities": []}, {"text": "Further, our model propagates global information by sharing attributes (e.g., gender and number) across mentions in the same cluster.", "labels": [], "entities": []}, {"text": "This cautious sieve guarantees that stronger features are given precedence over weaker ones and that each decision is made using all of the information available at the time.", "labels": [], "entities": []}, {"text": "The framework is highly modular: new coreference modules can be plugged in without any change to the other modules.", "labels": [], "entities": []}, {"text": "In spite of its simplicity, our approach outperforms many state-of-the-art supervised and unsupervised models on several standard corpora.", "labels": [], "entities": []}, {"text": "This suggests that sieve-based approaches could be applied to other NLP tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recent work on coreference resolution has shown that a rich feature space that models lexical, syntactic, semantic, and discourse phenomena is crucial to successfully address the task.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 15, "end_pos": 37, "type": "TASK", "confidence": 0.9779433906078339}]}, {"text": "When such a rich representation is available, even a simple deterministic model can achieve state-of-the-art performance.", "labels": [], "entities": []}, {"text": "By and large most approaches decide if two mentions are coreferent using a single function overall these features and information local to the two mentions.", "labels": [], "entities": []}, {"text": "1 This is problematic for two reasons: (1) lower precision features may overwhelm the smaller number of high precision ones, and (2) local information is often insufficient to make an informed decision.", "labels": [], "entities": [{"text": "precision", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9943692088127136}]}, {"text": "Consider this example: The second attack occurred after some rocket firings aimed, apparently, toward [the israelis], apparently in retaliation.'re checking our facts on that one.", "labels": [], "entities": []}, {"text": "the president, quoted by ari fleischer, his spokesman, is saying he's concerned the strike will undermine efforts by palestinian authorities to bring an end to terrorist attacks and does not contribute to the security of.", "labels": [], "entities": []}, {"text": "Most state-of-the-art models will incorrectly link we to the israelis because of their proximity and compatibility of attributes (both we and the israelis are plural).", "labels": [], "entities": []}, {"text": "In contrast, a more cautious approach is to first cluster the israelis with israel because the demonymy relation is highly precise.", "labels": [], "entities": []}, {"text": "This initial clustering step will assign the correct animacy attribute (inanimate) to the corresponding geo-political entity, which will prevent the incorrect merging with the mention we (animate) in later steps.", "labels": [], "entities": []}, {"text": "We propose an unsupervised sieve-like approach to coreference resolution that addresses these is-sues.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 50, "end_pos": 72, "type": "TASK", "confidence": 0.9753511846065521}]}, {"text": "The approach applies tiers of coreference models one at a time from highest to lowest precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.9855865240097046}]}, {"text": "Each tier builds on the entity clusters constructed by previous models in the sieve, guaranteeing that stronger features are given precedence over weaker ones.", "labels": [], "entities": []}, {"text": "Furthermore, each model's decisions are richly informed by sharing attributes across the mentions clustered in earlier tiers.", "labels": [], "entities": []}, {"text": "This ensures that each decision uses all of the information available at the time.", "labels": [], "entities": []}, {"text": "We implemented all components in our approach using only deterministic models.", "labels": [], "entities": []}, {"text": "All our components are unsupervised, in the sense that they do not require training on gold coreference links.", "labels": [], "entities": []}, {"text": "The contributions of this work are the following: \u2022 We show that a simple scaffolding framework that deploys strong features through tiers of models performs significantly better than a single-pass model.", "labels": [], "entities": []}, {"text": "Additionally, we propose several simple, yet powerful, new features.", "labels": [], "entities": []}, {"text": "\u2022 We demonstrate how far one can get with simple, deterministic coreference systems that do not require machine learning or detailed semantic information.", "labels": [], "entities": []}, {"text": "Our approach outperforms most other unsupervised coreference models and several supervised ones on several datasets.", "labels": [], "entities": []}, {"text": "\u2022 Our modular framework can be easily extended with arbitrary models, including statistical or supervised models.", "labels": [], "entities": []}, {"text": "We believe that our approach also serves as an ideal platform for the development of future coreference systems.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use three evaluation metrics widely used in the literature: (a) pairwise F1 (Ghosh, 2003) -computed over mention pairs in the same entity cluster; (b) MUC ( -which measures how many predicted clusters need to be merged to cover the gold clusters; and (c) B 3 (Amit and Baldwin, 1998) -which uses the intersection between predicted and gold clusters fora given mention to mark correct mentions and the sizes of the the predicted and gold clusters as denominators for precision and recall, respectively.", "labels": [], "entities": [{"text": "F1", "start_pos": 76, "end_pos": 78, "type": "METRIC", "confidence": 0.6285811066627502}, {"text": "MUC", "start_pos": 154, "end_pos": 157, "type": "METRIC", "confidence": 0.9911879301071167}, {"text": "precision", "start_pos": 469, "end_pos": 478, "type": "METRIC", "confidence": 0.9979277849197388}, {"text": "recall", "start_pos": 483, "end_pos": 489, "type": "METRIC", "confidence": 0.9981714487075806}]}, {"text": "We refer the interested reader to (X. for an analysis of these metrics.", "labels": [], "entities": []}, {"text": "We present the results of our approach and other relevant prior work in.", "labels": [], "entities": []}, {"text": "We include in the table all recent systems that report results under the same conditions as our experimental setup (i.e., using gold mentions) and use the same corpora.", "labels": [], "entities": []}, {"text": "We exclude from this analysis two notable works that report results only on aversion of the task that includes finding mentions (.", "labels": [], "entities": []}, {"text": "The numbers have two variants: with semantics (+S) and without (\u2212S).", "labels": [], "entities": []}, {"text": "To measure the contribution of our multi-pass system, we also present results from a single-pass variant of our system that uses all applicable features from the multi-pass system (marked as \"single pass\" in the table).", "labels": [], "entities": []}, {"text": "Our sieve model outperforms all systems on two out of the four evaluation corpora (ACE2004-ROTH-DEV and ACE2004-NWIRE), on all metrics.", "labels": [], "entities": [{"text": "ACE2004-ROTH-DEV", "start_pos": 83, "end_pos": 99, "type": "DATASET", "confidence": 0.9144414663314819}, {"text": "ACE2004-NWIRE", "start_pos": 104, "end_pos": 117, "type": "DATASET", "confidence": 0.8637477159500122}]}, {"text": "On the corpora where our model is not best, it ranks a close second.", "labels": [], "entities": []}, {"text": "For example, in ACE2004-CULOTTA-TEST our system has a B 3 F1 score only .4 points lower than and it outperforms all unsupervised approaches.", "labels": [], "entities": [{"text": "ACE2004-CULOTTA-TEST", "start_pos": 16, "end_pos": 36, "type": "DATASET", "confidence": 0.9247344136238098}, {"text": "B 3 F1 score", "start_pos": 54, "end_pos": 66, "type": "METRIC", "confidence": 0.9009967297315598}]}, {"text": "In MUC6-TEST, our sieve's B 3 F1 score is 1.8 points lower than +S, but it outperforms a supervised system that used gold named entity labels.", "labels": [], "entities": [{"text": "MUC6-TEST", "start_pos": 3, "end_pos": 12, "type": "DATASET", "confidence": 0.7792837619781494}, {"text": "B 3 F1 score", "start_pos": 26, "end_pos": 38, "type": "METRIC", "confidence": 0.9266570061445236}]}, {"text": "Finally, the multi-pass architecture always beats the equivalent single-pass system with its contribution ranging between 1 and 4 F1 points depending on the corpus and evaluation metric.", "labels": [], "entities": [{"text": "F1", "start_pos": 130, "end_pos": 132, "type": "METRIC", "confidence": 0.9936843514442444}]}, {"text": "Our approach has the highest precision on all corpora, regardless of evaluation metric.", "labels": [], "entities": [{"text": "precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.9989007711410522}]}, {"text": "We believe this is particularly useful for large-scale NLP applications that use coreference resolution components, e.g., question answering or information extraction.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 81, "end_pos": 103, "type": "TASK", "confidence": 0.837104320526123}, {"text": "question answering", "start_pos": 122, "end_pos": 140, "type": "TASK", "confidence": 0.9210549890995026}, {"text": "information extraction", "start_pos": 144, "end_pos": 166, "type": "TASK", "confidence": 0.8269384503364563}]}, {"text": "These applications can generally function without coreference information so it is beneficial to provide such information only when it is highly precise.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Cumulative performance on development (ACE2004-ROTH-DEV) as passes are added to the sieve.", "labels": [], "entities": []}, {"text": " Table 3: Results using gold mention boundaries. Where available, we show results for a given corpus grouped in  two blocks: the top block shows results of unsupervised systems and the bottom block contains supervised systems.  Bold numbers indicate best results in a given block. +/-S indicates if the (", "labels": [], "entities": []}, {"text": " Table 4: Number of pair-wise errors produced by the  sieve after transitive closure in the MUC6-TEST corpus.  Rows indicate mention types; columns are types of an- tecedent. Each cell shows the number of precision/recall  errors for that configuration. The total number of gold  links in MUC6-TEST is 11,236.", "labels": [], "entities": [{"text": "MUC6-TEST corpus", "start_pos": 92, "end_pos": 108, "type": "DATASET", "confidence": 0.9475202262401581}, {"text": "precision", "start_pos": 205, "end_pos": 214, "type": "METRIC", "confidence": 0.9941878318786621}, {"text": "recall", "start_pos": 215, "end_pos": 221, "type": "METRIC", "confidence": 0.7595904469490051}, {"text": "MUC6-TEST", "start_pos": 289, "end_pos": 298, "type": "DATASET", "confidence": 0.9160506129264832}]}]}