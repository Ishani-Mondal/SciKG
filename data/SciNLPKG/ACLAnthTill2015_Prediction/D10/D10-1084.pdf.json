{"title": [{"text": "Classifying Dialogue Acts in One-on-one Live Chats", "labels": [], "entities": [{"text": "Classifying Dialogue Acts", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.914922813574473}]}], "abstractContent": [{"text": "We explore the task of automatically classifying dialogue acts in 1-on-1 online chat forums, an increasingly popular means of providing customer service.", "labels": [], "entities": [{"text": "classifying dialogue acts in 1-on-1 online chat forums", "start_pos": 37, "end_pos": 91, "type": "TASK", "confidence": 0.8070976808667183}]}, {"text": "In particular, we investigate the effectiveness of various features and machine learners for this task.", "labels": [], "entities": []}, {"text": "While a simple bag-of-words approach provides a solid baseline, we find that adding information from dialogue structure and inter-utterance dependency provides some increase in performance; learners that account for sequential dependencies (CRFs) show the best performance.", "labels": [], "entities": []}, {"text": "We report our results from testing using a corpus of chat dialogues derived from online shopping customer-feedback data.", "labels": [], "entities": []}], "introductionContent": [{"text": "Recently, live chats have received attention due to the growing popularity of chat services and the increasing body of applications.", "labels": [], "entities": []}, {"text": "For example, large organizations are increasingly providing support or information services through live chat.", "labels": [], "entities": []}, {"text": "One advantage of chat-based customer service over conventional telephone-based customer service is that it becomes possible to semi-automate aspects of the interaction (e.g. conventional openings or canned responses to standard questions) without the customer being aware of it taking place, something that is not possible with speech-based dialogue systems (as synthesised speech is still easily distinguishable from natural speech).", "labels": [], "entities": []}, {"text": "Potentially huge savings can be made by organisations providing customer help services if we can increase the degree of automation of live chat.", "labels": [], "entities": []}, {"text": "Given the increasing impact of live chat services, there is surprisingly little published computational linguistic research on the topic.", "labels": [], "entities": []}, {"text": "There has been substantially more work done on dialogue and dialogue corpora, mostly in spoken dialogue (e.g.) but also multimodal dialogue systems in application areas such as telephone support service () and tutoring systems).", "labels": [], "entities": []}, {"text": "Spoken dialogue analysis introduces many complications related to the error inherent in current speech recognition technologies.", "labels": [], "entities": [{"text": "Spoken dialogue analysis", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.9139502843221029}, {"text": "speech recognition", "start_pos": 96, "end_pos": 114, "type": "TASK", "confidence": 0.7168405801057816}]}, {"text": "As an instance of written dialogue, an advantage of live chats is that recognition errors are not such an issue, although the nature of language used in chat is typically ill-formed and turn-taking is complicated by the semi-asynchronous nature of the interaction (e.g.).", "labels": [], "entities": []}, {"text": "In this paper, we investigate the task of automatic classification of dialogue acts in 1-on-1 live chats, focusing on \"information delivery\" chats since these are proving increasingly popular as part of enterprise customer-service solutions.", "labels": [], "entities": [{"text": "automatic classification of dialogue acts in 1-on-1 live chats", "start_pos": 42, "end_pos": 104, "type": "TASK", "confidence": 0.7163587543699477}]}, {"text": "Our main challenge is to develop effective features and classifiers for classifying aspects of 1-on-1 live chat.", "labels": [], "entities": []}, {"text": "Much of the work on analysing dialogue acts in spoken dialogues has relied on non-lexical features, such as prosody and acoustic features (), which are not available for written dialogues.", "labels": [], "entities": [{"text": "analysing dialogue acts in spoken dialogues", "start_pos": 20, "end_pos": 63, "type": "TASK", "confidence": 0.824820081392924}]}, {"text": "Previous dialogue-act detection for chat systems has used bags-of-words (hereafter, BoW) as features for dialogue-act detection; this simple approach has shown some promise (e.g., and).", "labels": [], "entities": [{"text": "dialogue-act detection", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.7814101576805115}, {"text": "dialogue-act detection", "start_pos": 105, "end_pos": 127, "type": "TASK", "confidence": 0.7701313495635986}]}, {"text": "Other features such as keywords/ontologies ( and lexical cues () have also been used for dialogue act classification.", "labels": [], "entities": [{"text": "dialogue act classification", "start_pos": 89, "end_pos": 116, "type": "TASK", "confidence": 0.8597572644551595}]}, {"text": "In this paper, we first re-examine BoW features for dialogue act classification.", "labels": [], "entities": [{"text": "dialogue act classification", "start_pos": 52, "end_pos": 79, "type": "TASK", "confidence": 0.8310316403706869}]}, {"text": "As a baseline, we use the work of, which explored 1-grams and 2-grams with Boolean values in 1-on-1 live chats in the MSN Online Shopping domain (this dataset is described in Section 5).", "labels": [], "entities": [{"text": "MSN Online Shopping domain", "start_pos": 118, "end_pos": 144, "type": "DATASET", "confidence": 0.922230139374733}]}, {"text": "Although this work achieved reasonably high performance (up to a micro-averaged F-score of around 80%), we believe that there is still room for improvement using BoW only.", "labels": [], "entities": [{"text": "F-score", "start_pos": 80, "end_pos": 87, "type": "METRIC", "confidence": 0.9742338061332703}, {"text": "BoW", "start_pos": 162, "end_pos": 165, "type": "DATASET", "confidence": 0.9309180974960327}]}, {"text": "We extend this work by using ideas from related research such as text categorization, and explore variants of BoW based on analysis of live chats, along with feature weighting.", "labels": [], "entities": [{"text": "text categorization", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.7832083404064178}, {"text": "BoW", "start_pos": 110, "end_pos": 113, "type": "DATASET", "confidence": 0.8888535499572754}]}, {"text": "Finally, our main aim is to explore new features based on dialogue structure and dependencies between utterances 1 that can enhance the use of BoW for dialogue act classification.", "labels": [], "entities": [{"text": "BoW", "start_pos": 143, "end_pos": 146, "type": "DATASET", "confidence": 0.8425926566123962}, {"text": "dialogue act classification", "start_pos": 151, "end_pos": 178, "type": "TASK", "confidence": 0.6929782430330912}]}, {"text": "Our hypothesis is that, for task-oriented 1-on-1 live chats, the structure and interactions among utterances are useful in predicting future dialogue acts: for example, conversations typically start with a greeting, and questions and answers typically appear as adjacency pairs in a conversation.", "labels": [], "entities": []}, {"text": "Therefore, we propose new features based on structural and dependency information derived from utterances (Sections 4.2 and 4.3).", "labels": [], "entities": []}], "datasetContent": [{"text": "As stated earlier, we use the data set from for our experiments; it contains 1-on-1 live chats from an information delivery task.", "labels": [], "entities": [{"text": "information delivery task", "start_pos": 103, "end_pos": 128, "type": "TASK", "confidence": 0.7822498877843221}]}, {"text": "This dataset contains 8 live chats, including 542 manuallysegmented utterances.", "labels": [], "entities": []}, {"text": "The maximum and minimum number of utterances in a dialogue are 84 and 42, respectively; the maximum number of utterances in a turn is 14.", "labels": [], "entities": []}, {"text": "The live chats were manually tagged with the 12 dialogue acts described in Section 3.", "labels": [], "entities": []}, {"text": "The utterance distribution over the dialogue acts is described in.", "labels": [], "entities": []}, {"text": "For our experiments, we calculated TF, TF\u00b7IDF and IG (Information Gain) over the utterances, which were optionally lemmatized with the morph tool ().", "labels": [], "entities": [{"text": "TF", "start_pos": 35, "end_pos": 37, "type": "METRIC", "confidence": 0.9876201748847961}, {"text": "IDF", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.5927143692970276}, {"text": "IG (Information Gain)", "start_pos": 50, "end_pos": 71, "type": "METRIC", "confidence": 0.7180859625339509}]}, {"text": "We then built a dialogue act classifier using three different machine learners: SVM-HMM   from the WEKA machine learning toolkit, and Conditional Random Fields (CRF) using CRF++.", "labels": [], "entities": [{"text": "dialogue act classifier", "start_pos": 16, "end_pos": 39, "type": "TASK", "confidence": 0.6527719298998514}, {"text": "WEKA machine learning toolkit", "start_pos": 99, "end_pos": 128, "type": "DATASET", "confidence": 0.8196782916784286}]}, {"text": "3 Note that we chose to test CRF and SVM-HMM as previous work (e.g. () has shown the effectiveness of structured classification models on sequential dependencies.", "labels": [], "entities": []}, {"text": "Thus, we expect similar effects with CRF and SVM-HMM.", "labels": [], "entities": []}, {"text": "Finally, we ran 8-fold cross-validation using the feature sets described above (partitioning across the 8 sessions).", "labels": [], "entities": []}, {"text": "All results are presented in terms of classification accuracy.", "labels": [], "entities": [{"text": "classification", "start_pos": 38, "end_pos": 52, "type": "TASK", "confidence": 0.9298702478408813}, {"text": "accuracy", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.9336380362510681}]}, {"text": "The accuracy of a zero-R (i.e. majority vote) baseline is 0.36.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997889399528503}]}, {"text": "shows the best accuracy achieved by the different learners, in combination with BoW represen-  tations and feature weighting methods.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.999430239200592}, {"text": "BoW represen-  tations", "start_pos": 80, "end_pos": 102, "type": "METRIC", "confidence": 0.7012725174427032}]}, {"text": "Note that the CRF learner ran using 1-grams only, as CRF++ does not accept large numbers of features.", "labels": [], "entities": [{"text": "CRF learner", "start_pos": 14, "end_pos": 25, "type": "DATASET", "confidence": 0.7493322491645813}]}, {"text": "As a benchmark, we also tested the method in and present the best performance over words (rather than lemmas).", "labels": [], "entities": []}, {"text": "Overall, we found using just 1-grams produced the best performance for all learners, although SVM achieved the best performance when using all three n-gram orders (i.e. 1+2+3).", "labels": [], "entities": []}, {"text": "Since the utterances are very short, 2-grams or 3-grams alone are too sparse to be effective.", "labels": [], "entities": []}, {"text": "Among the feature weighting methods, Boolean and IG achieved higher accuracy than TF and TF\u00b7IDF.", "labels": [], "entities": [{"text": "Boolean", "start_pos": 37, "end_pos": 44, "type": "DATASET", "confidence": 0.6328091025352478}, {"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9993720650672913}, {"text": "IDF", "start_pos": 92, "end_pos": 95, "type": "METRIC", "confidence": 0.9276402592658997}]}, {"text": "Likewise, due to the short utterances, simple Boolean values were often the most effective.", "labels": [], "entities": []}, {"text": "However, as IG was computed using the training data, it also achieved high performance.", "labels": [], "entities": [{"text": "IG", "start_pos": 12, "end_pos": 14, "type": "TASK", "confidence": 0.800009548664093}]}, {"text": "When comparing the learners, we found that CRF produced the best performance, due to its ability to capture inter-utterance dependencies.", "labels": [], "entities": []}, {"text": "Finally, we confirmed that using lemmas results in higher accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9990787506103516}]}, {"text": "shows the accuracy overall feature sets; for brevity, we show this for SVM only since the pattern is similar across all learners.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9995062351226807}]}], "tableCaptions": [{"text": " Table 3: Dialogue act distribution in the corpus", "labels": [], "entities": [{"text": "Dialogue act distribution", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.8336876034736633}]}, {"text": " Table 4: Best accuracy achieved by the different learn- ers over different feature sets and weighting methods (1  = 1-gram; 1+2+3 = 1/2/3-grams; B = Boolean; IG = in- formation gain)", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9995392560958862}, {"text": "IG", "start_pos": 159, "end_pos": 161, "type": "METRIC", "confidence": 0.9902623891830444}, {"text": "in- formation gain", "start_pos": 164, "end_pos": 182, "type": "METRIC", "confidence": 0.7146825939416885}]}, {"text": " Table 5: Accuracy of different feature representations and  weighting methods for SVM-HMM", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9930444359779358}, {"text": "SVM-HMM", "start_pos": 83, "end_pos": 90, "type": "TASK", "confidence": 0.4320914149284363}]}, {"text": " Table 6: Accuracy with structural information", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9980660080909729}]}, {"text": " Table 7: Accuracy for the different learners with depen- dency features", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9989283680915833}]}, {"text": " Table 8: Accuracy with Structural and Dependency Infor- mation: C means lemmatized Unigram+Position+Author", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9980105757713318}]}]}