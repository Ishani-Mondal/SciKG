{"title": [{"text": "Using Unknown Word Techniques To Learn Known Words", "labels": [], "entities": [{"text": "Learn Known Words", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.8573296268781027}]}], "abstractContent": [{"text": "Unknown words area hindrance to the performance of hand-crafted computational grammars of natural language.", "labels": [], "entities": []}, {"text": "However, words with incomplete and incorrect lexical entries pose an even bigger problem because they can be the cause of a parsing failure despite being listed in the lexicon of the grammar.", "labels": [], "entities": []}, {"text": "Such lexical entries are hard to detect and even harder to correct.", "labels": [], "entities": []}, {"text": "We employ an error miner to pinpoint words with problematic lexical entries.", "labels": [], "entities": []}, {"text": "An automated lexical acquisition technique is then used to learn new entries for those words which allows the grammar to parse previously uncovered sentences successfully.", "labels": [], "entities": []}, {"text": "We test our method on a large-scale grammar of Dutch and a set of sentences for which this grammar fails to produce a parse.", "labels": [], "entities": []}, {"text": "The application of the method enables the grammar to cover 83.76% of those sentences with an accuracy of 86.15%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9994829893112183}]}], "introductionContent": [{"text": "In this paper, we present an automated two-phase method for treating incomplete or incorrect lexical entries in the lexicons of large-scale computational grammars.", "labels": [], "entities": []}, {"text": "The performance of our approach is tested in a case study with the wide-coverage Alpino grammar) of Dutch.", "labels": [], "entities": []}, {"text": "When applied to real test sentences previously not covered by Alpino, the method causes a parsing coverage of 83.76% and the accuracy of the delivered analyses is 86.15%.", "labels": [], "entities": [{"text": "coverage", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.48011788725852966}, {"text": "accuracy", "start_pos": 125, "end_pos": 133, "type": "METRIC", "confidence": 0.9995606541633606}]}, {"text": "The main advantage of our approach is the successful combination of efficient error mining and lexical acquisition techniques.", "labels": [], "entities": [{"text": "error mining", "start_pos": 78, "end_pos": 90, "type": "TASK", "confidence": 0.7092607766389847}]}, {"text": "In the first phase, error mining pinpoints words which are listed in the lexicon of a given grammar but which nevertheless often lead to a parsing failure.", "labels": [], "entities": [{"text": "error mining pinpoints words", "start_pos": 20, "end_pos": 48, "type": "TASK", "confidence": 0.8461947441101074}]}, {"text": "This indicates that the current lexical entry for such a word is either wrong or incomplete and that one or more correct entries for this word are missing from the lexicon.", "labels": [], "entities": []}, {"text": "Our idea is to treat the word as if it was unknown and, in the second phase, to employ lexical acquisition (LA) to learn the missing correct entries.", "labels": [], "entities": [{"text": "lexical acquisition (LA)", "start_pos": 87, "end_pos": 111, "type": "TASK", "confidence": 0.5575065195560456}]}, {"text": "In the case study presented here, we employ the iterative error miner of de.", "labels": [], "entities": []}, {"text": "Since it has to be run on a large parsed corpus, we have parsed the Flemish Mediargus corpus (\u223c1.5 billion words) with Alpino.", "labels": [], "entities": [{"text": "Flemish Mediargus corpus", "start_pos": 68, "end_pos": 92, "type": "DATASET", "confidence": 0.9307552377382914}]}, {"text": "The reason for this choice is the relatively large lexical difference between standard Dutch and Flemish.", "labels": [], "entities": []}, {"text": "This increases the chance to encounter words which are used in Flemish in away not handled by Alpino yet.", "labels": [], "entities": []}, {"text": "For example, the word afwater (to drain) is listed as a first person singular present verb in the Alpino lexicon.", "labels": [], "entities": [{"text": "Alpino lexicon", "start_pos": 98, "end_pos": 112, "type": "DATASET", "confidence": 0.9600591659545898}]}, {"text": "However, the error miner identifies this word as the reason for the parsing failure of 9 sentences.", "labels": [], "entities": [{"text": "parsing", "start_pos": 68, "end_pos": 75, "type": "TASK", "confidence": 0.9668259024620056}]}, {"text": "A manual examination reveals that the word is used as a neuter noun in these cases-het afwater (the drainage).", "labels": [], "entities": []}, {"text": "Since there is no noun entry in the lexicon, Alpino was notable to produce full-span analyses.", "labels": [], "entities": []}, {"text": "After the error miner identifies afwater as a problematic word, we employ our machine learning based LA method presented in to learn new entries for this word.", "labels": [], "entities": [{"text": "LA", "start_pos": 101, "end_pos": 103, "type": "METRIC", "confidence": 0.9889280796051025}]}, {"text": "This method has already been successfully applied to the task of learning lexical entries for unknown words and, as the error miner, it can be used 'out of the box'.", "labels": [], "entities": []}, {"text": "LA correctly predicts a neuter noun en-try for afwater and the addition of this entry to the lexicon enables Alpino to cover the 9 problematic sentences from the Mediargus corpus.", "labels": [], "entities": [{"text": "Mediargus corpus", "start_pos": 162, "end_pos": 178, "type": "DATASET", "confidence": 0.9831347167491913}]}, {"text": "It should be noted that since our approach cannot differentiate between incomplete and incorrect entries, no entry in the lexicon is modified.", "labels": [], "entities": []}, {"text": "We simply add the lexical entries which, according to the LA method, are most suitable fora given problematic word and assume that, if these entries are correct, the grammar should be able to cover previously unparsable sentences in which the word occurs.", "labels": [], "entities": [{"text": "LA", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.9759522080421448}]}, {"text": "The remainder of the paper is organised as follows.", "labels": [], "entities": []}, {"text": "Section 2 describes the error miner.", "labels": [], "entities": []}, {"text": "Section 3 presents the Alpino grammar and parser and the LA technique we employ.", "labels": [], "entities": [{"text": "LA", "start_pos": 57, "end_pos": 59, "type": "METRIC", "confidence": 0.8118438720703125}]}, {"text": "Section 4 describes an experiment where error mining is performed on the Mediargus corpus and then, LA is applied to learn new lexical entries for problematic words.", "labels": [], "entities": [{"text": "error mining", "start_pos": 40, "end_pos": 52, "type": "TASK", "confidence": 0.6992206275463104}, {"text": "Mediargus corpus", "start_pos": 73, "end_pos": 89, "type": "DATASET", "confidence": 0.9906200170516968}, {"text": "LA", "start_pos": 100, "end_pos": 102, "type": "METRIC", "confidence": 0.9977419376373291}]}, {"text": "Section 5 discusses the effect which the addition of the new entries to the lexicon has on the parsing coverage and accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 95, "end_pos": 102, "type": "TASK", "confidence": 0.9650474190711975}, {"text": "coverage", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.5349598526954651}, {"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9971576929092407}]}, {"text": "Section 6 provides a comparison between our approach and previous work similar in nature.", "labels": [], "entities": []}, {"text": "This section also discusses the application of our method to other systems and languages as well as some ideas for future research.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Problematic unigrams and their suspicions", "labels": [], "entities": []}, {"text": " Table 4. The average sentence  length is 18.9 tokens.", "labels": [], "entities": []}, {"text": " Table 4: Accuracy results for the 100 annotated sentences", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9995071887969971}]}]}