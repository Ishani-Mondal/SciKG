{"title": [{"text": "A Tree Kernel-based Unified Framework for Chinese Zero Anaphora Resolution", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper proposes a unified framework for zero anaphora resolution, which can be divided into three sub-tasks: zero anaphor detection , anaphoricity determination and antecedent identification.", "labels": [], "entities": [{"text": "zero anaphora resolution", "start_pos": 44, "end_pos": 68, "type": "TASK", "confidence": 0.6235383252302805}, {"text": "zero anaphor detection", "start_pos": 113, "end_pos": 135, "type": "TASK", "confidence": 0.6576808194319407}, {"text": "anaphoricity determination", "start_pos": 138, "end_pos": 164, "type": "TASK", "confidence": 0.6680469363927841}, {"text": "antecedent identification", "start_pos": 169, "end_pos": 194, "type": "TASK", "confidence": 0.7315466105937958}]}, {"text": "In particular, all the three sub-tasks are addressed using tree kernel based methods with appropriate syntactic parse tree structures.", "labels": [], "entities": []}, {"text": "Experimental results on a Chinese zero anaphora corpus show that the proposed tree kernel-based methods significantly outperform the feature-based ones.", "labels": [], "entities": [{"text": "Chinese zero anaphora corpus", "start_pos": 26, "end_pos": 54, "type": "DATASET", "confidence": 0.5632824376225471}]}, {"text": "This indicates the critical role of the structural information in zero anaphora resolution and the necessity of tree kernel-based methods in modeling such structural information.", "labels": [], "entities": [{"text": "zero anaphora resolution", "start_pos": 66, "end_pos": 90, "type": "TASK", "confidence": 0.6093467672665914}]}, {"text": "To our best knowledge, this is the first systematic work dealing with all the three sub-tasks in Chinese zero anaphora resolution via a unified framework.", "labels": [], "entities": [{"text": "Chinese zero anaphora resolution", "start_pos": 97, "end_pos": 129, "type": "TASK", "confidence": 0.5544871762394905}]}, {"text": "Moreover, we release a Chinese zero anaphora corpus of 100 documents, which adds a layer of annotation to the manually parsed sentences in the Chinese Treebank (CTB) 6.0.", "labels": [], "entities": [{"text": "Chinese Treebank (CTB) 6.0", "start_pos": 143, "end_pos": 169, "type": "DATASET", "confidence": 0.9605893095334371}]}], "introductionContent": [{"text": "As one of the most important techniques in discourse analysis, anaphora resolution has been a focus of research in Natural Language Processing (NLP) for decades and achieved much success in English recently (e.g.).", "labels": [], "entities": [{"text": "discourse analysis", "start_pos": 43, "end_pos": 61, "type": "TASK", "confidence": 0.7442570328712463}, {"text": "anaphora resolution", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.8019546568393707}]}, {"text": "However, there is little work on anaphora resolution in Chinese.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.8590468764305115}]}, {"text": "A major reason for this phenomenon is that Chinese, unlike English, is a prodrop language, whereas in English, definite noun phrases (e.g. the company) and overt pronouns (e.g. he) are frequently employed as referring expressions, which refer to preceding entities.", "labels": [], "entities": []}, {"text": "compared the use of overt subjects in English and Chinese.", "labels": [], "entities": []}, {"text": "He found that overt subjects occupy over 96% in English, while this percentage drops to only 64% in Chinese.", "labels": [], "entities": []}, {"text": "This indicates the prevalence of zero anaphors in Chinese and the necessity of zero anaphora resolution in Chinese anaphora resolution.", "labels": [], "entities": [{"text": "Chinese anaphora resolution", "start_pos": 107, "end_pos": 134, "type": "TASK", "confidence": 0.6026467581590017}]}, {"text": "Since zero anaphors give little hints (e.g. number or gender) about their possible antecedents, zero anaphora resolution is much more challenging than traditional anaphora resolution.", "labels": [], "entities": [{"text": "zero anaphora resolution", "start_pos": 96, "end_pos": 120, "type": "TASK", "confidence": 0.652586430311203}, {"text": "anaphora resolution", "start_pos": 163, "end_pos": 182, "type": "TASK", "confidence": 0.8201006352901459}]}, {"text": "Although Chinese zero anaphora has been widely studied in the linguistics research), only a small body of prior work in computational linguistics deals with Chinese zero anaphora resolution;.", "labels": [], "entities": [{"text": "Chinese zero anaphora resolution", "start_pos": 157, "end_pos": 189, "type": "TASK", "confidence": 0.5828109756112099}]}, {"text": "Moreover, zero anaphor detection, as a critical component for real applications of zero anaphora resolution, has been largely ignored.", "labels": [], "entities": [{"text": "zero anaphor detection", "start_pos": 10, "end_pos": 32, "type": "TASK", "confidence": 0.641218344370524}, {"text": "zero anaphora resolution", "start_pos": 83, "end_pos": 107, "type": "TASK", "confidence": 0.7072996497154236}]}, {"text": "This paper proposes a unified framework for Chinese zero anaphora resolution, which can be divided into three sub-tasks: zero anaphor detection, which detects zero anaphors from a text, anaphoricity determination, which determines whether a zero anaphor is anaphoric or not, and antecedent identification, which finds the antecedent for an anaphoric zero anaphor.", "labels": [], "entities": [{"text": "Chinese zero anaphora resolution", "start_pos": 44, "end_pos": 76, "type": "TASK", "confidence": 0.7046643942594528}, {"text": "zero anaphor detection", "start_pos": 121, "end_pos": 143, "type": "TASK", "confidence": 0.6656672557195028}, {"text": "antecedent identification", "start_pos": 279, "end_pos": 304, "type": "TASK", "confidence": 0.6882972121238708}]}, {"text": "To our best knowledge, this is the first systematic work dealing with all the three sub-tasks via a unified framework.", "labels": [], "entities": []}, {"text": "Moreover, we release a Chinese zero anaphora corpus of 100 documents, which adds a layer of annotation to the manually-parsed sentences in the Chinese Treebank (CTB) 6.0.", "labels": [], "entities": [{"text": "Chinese Treebank (CTB) 6.0", "start_pos": 143, "end_pos": 169, "type": "DATASET", "confidence": 0.9607446591059366}]}, {"text": "This is done by assigning anaphoric/non-anaphoric zero anaphora labels to the null constituents in a parse tree.", "labels": [], "entities": []}, {"text": "Finally, this paper illustrates the critical role of the structural information in zero anaphora resolution and the necessity of tree kernel-based methods in modeling such structural information.", "labels": [], "entities": [{"text": "zero anaphora resolution", "start_pos": 83, "end_pos": 107, "type": "TASK", "confidence": 0.6078904668490092}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 briefly describes the related work on both zero anaphora resolution and tree kernelbased anaphora resolution.", "labels": [], "entities": [{"text": "zero anaphora resolution", "start_pos": 53, "end_pos": 77, "type": "TASK", "confidence": 0.6361692051092783}, {"text": "tree kernelbased anaphora resolution", "start_pos": 82, "end_pos": 118, "type": "TASK", "confidence": 0.5909405797719955}]}, {"text": "Section 3 introduces the overwhelming problem of zero anaphora in Chinese and our developed Chinese zero anaphora corpus, which is available for research purpose.", "labels": [], "entities": [{"text": "Chinese zero anaphora corpus", "start_pos": 92, "end_pos": 120, "type": "DATASET", "confidence": 0.5858182907104492}]}, {"text": "Section 4 presents our tree kernel-based unified framework in zero anaphora resolution.", "labels": [], "entities": [{"text": "zero anaphora resolution", "start_pos": 62, "end_pos": 86, "type": "TASK", "confidence": 0.6943417191505432}]}, {"text": "Section 5 reports the experimental results.", "labels": [], "entities": []}, {"text": "Finally, we conclude our work in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have systematically evaluated our tree kernelbased unified framework on our developed Chinese zero anaphora corpus, as described in Section 3.2.", "labels": [], "entities": [{"text": "Chinese zero anaphora corpus", "start_pos": 89, "end_pos": 117, "type": "DATASET", "confidence": 0.6520390957593918}]}, {"text": "Besides, in order to focus on zero anaphor resolution itself and compare with related work, all the experiments are done on golden parse trees provided by CTB 6.0.", "labels": [], "entities": [{"text": "CTB 6.0", "start_pos": 155, "end_pos": 162, "type": "DATASET", "confidence": 0.961862325668335}]}, {"text": "Finally, all the performances are achieved using 5-fold cross validation.", "labels": [], "entities": []}, {"text": "gives the performance of zero anaphor detection, which achieves 70.05%, 83.24% and 76.08 in precision, recall and F-measure, respectively.", "labels": [], "entities": [{"text": "zero anaphor detection", "start_pos": 25, "end_pos": 47, "type": "TASK", "confidence": 0.5447437266508738}, {"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9997327923774719}, {"text": "recall", "start_pos": 103, "end_pos": 109, "type": "METRIC", "confidence": 0.9993377327919006}, {"text": "F-measure", "start_pos": 114, "end_pos": 123, "type": "METRIC", "confidence": 0.9987573623657227}]}, {"text": "Here, the lower precision is much due to the simple heuristic rules used to generate zero anaphors candidates.", "labels": [], "entities": [{"text": "precision", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9990392923355103}]}, {"text": "In fact, the ratio of positive and negative instances reaches about 1:12.", "labels": [], "entities": []}, {"text": "However, this ratio is much better than that (1:30) using the heuristic rule as described in.", "labels": [], "entities": []}, {"text": "It is also worth to point out that lower precision higher recall is much beneficial than higher precision lower recall as higher recall means less filtering of true zero anaphors and we can still rely on anaphoricity determination to filter out those false zero anaphors introduced by lower precision in zero anaphor detection.", "labels": [], "entities": [{"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.50652676820755}, {"text": "recall", "start_pos": 129, "end_pos": 135, "type": "METRIC", "confidence": 0.9931881427764893}, {"text": "zero anaphor detection", "start_pos": 304, "end_pos": 326, "type": "TASK", "confidence": 0.7049392859141032}]}], "tableCaptions": [{"text": " Table 1: Statistics on different categories of zero  anaphora (AZA and ZA indicates anaphoric zero ana- phor and zero anaphor respectively)", "labels": [], "entities": [{"text": "AZA", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.990662157535553}]}, {"text": " Table 5: Performance of anaphoricity determination", "labels": [], "entities": []}, {"text": " Table 6: Performance of antecedent identification given  golden zero anaphors", "labels": [], "entities": []}, {"text": " Table 8: Performance of zero anaphora resolution over  sentence distances", "labels": [], "entities": [{"text": "zero anaphora resolution", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.7175621191660563}]}, {"text": " Table 9: Performance of zero anaphora resolution over  major zero anaphora categories", "labels": [], "entities": [{"text": "zero anaphora resolution", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.6287074287732443}]}, {"text": " Table 10: Performance of the feature-based method  (Zhao and Ng 2007) in anaphoricity determination on  our developed corpus", "labels": [], "entities": [{"text": "anaphoricity determination", "start_pos": 74, "end_pos": 100, "type": "TASK", "confidence": 0.6405126005411148}]}, {"text": " Table 11: Performance of the feature-based method", "labels": [], "entities": []}]}