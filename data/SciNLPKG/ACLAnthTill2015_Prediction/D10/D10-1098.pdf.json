{"title": [{"text": "Domain Adaptation of Rule-Based Annotators for Named-Entity Recognition Tasks", "labels": [], "entities": [{"text": "Domain Adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7182443737983704}, {"text": "Named-Entity Recognition Tasks", "start_pos": 47, "end_pos": 77, "type": "TASK", "confidence": 0.7818642854690552}]}], "abstractContent": [{"text": "Named-entity recognition (NER) is an important task required in a wide variety of applications.", "labels": [], "entities": [{"text": "Named-entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8678877949714661}]}, {"text": "While rule-based systems are appealing due to their well-known \"explainabil-ity,\" most, if not all, state-of-the-art results for NER tasks are based on machine learning techniques.", "labels": [], "entities": [{"text": "NER tasks", "start_pos": 129, "end_pos": 138, "type": "TASK", "confidence": 0.9142074882984161}]}, {"text": "Motivated by these results, we explore the following natural question in this paper: Are rule-based systems still a viable approach to named-entity recognition?", "labels": [], "entities": [{"text": "named-entity recognition", "start_pos": 135, "end_pos": 159, "type": "TASK", "confidence": 0.720228299498558}]}, {"text": "Specifically , we have designed and implemented a high-level language NERL on top of Sys-temT, a general-purpose algebraic information extraction system.", "labels": [], "entities": [{"text": "general-purpose algebraic information extraction", "start_pos": 97, "end_pos": 145, "type": "TASK", "confidence": 0.6003395318984985}]}, {"text": "NERL is tuned to the needs of NER tasks and simplifies the process of building, understanding, and customiz-ing complex rule-based named-entity annota-tors.", "labels": [], "entities": [{"text": "NERL", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8157240748405457}]}, {"text": "We show that these customized annota-tors match or outperform the best published results achieved with machine learning techniques.", "labels": [], "entities": []}, {"text": "These results confirm that we can reap the benefits of rule-based extractors' ex-plainability without sacrificing accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9957066178321838}]}, {"text": "We conclude by discussing lessons learned while building and customizing complex rule-based annotators and outlining several research directions towards facilitating rule development.", "labels": [], "entities": [{"text": "rule development", "start_pos": 166, "end_pos": 182, "type": "TASK", "confidence": 0.8642564713954926}]}], "introductionContent": [{"text": "Named-entity recognition (NER) is the task of identifying mentions of rigid designators from text belonging to named-entity types such as persons, organizations and locations (.", "labels": [], "entities": [{"text": "Named-entity recognition (NER)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8730488598346711}, {"text": "identifying mentions of rigid designators from text belonging to named-entity types such as persons, organizations and locations", "start_pos": 46, "end_pos": 174, "type": "TASK", "confidence": 0.5857871456278695}]}, {"text": "While NER over formal text such as news articles and webpages is a well-studied problem), there has been recent work on NER over informal text such as emails and blogs;).", "labels": [], "entities": [{"text": "NER over formal text such as news articles and webpages", "start_pos": 6, "end_pos": 61, "type": "TASK", "confidence": 0.6146377176046371}]}, {"text": "The techniques proposed in the literature fall under three categories: rule-based (), machine learningbased (O. and hybrid solutions).", "labels": [], "entities": []}], "datasetContent": [{"text": "We now present an experimental evaluation of the customizability of CoreNER.", "labels": [], "entities": [{"text": "CoreNER", "start_pos": 68, "end_pos": 75, "type": "DATASET", "confidence": 0.8741198182106018}]}, {"text": "The main goals are to investigate: (i) the feasibility of CoreNER customization for different application domains; (ii) the effectiveness of such customization compared to state-of-the-art results; (iii) the impact of different types of customization (Tab.", "labels": [], "entities": [{"text": "Tab.", "start_pos": 252, "end_pos": 256, "type": "DATASET", "confidence": 0.9161312282085419}]}, {"text": "1); and (iv) how often different categories of NERL rules (Tab. 2) are used during customization.", "labels": [], "entities": []}, {"text": "We measured the effectiveness of customization using the improvement in extraction quality of the customized CoreNER over CoreNER orig . As shown in Tab.", "labels": [], "entities": [{"text": "Tab.", "start_pos": 149, "end_pos": 153, "type": "DATASET", "confidence": 0.9700012803077698}]}, {"text": "6, customization significantly improved   F \u03b2=1 score for CoreNER orig across all datasets.", "labels": [], "entities": [{"text": "F \u03b2=1 score", "start_pos": 42, "end_pos": 53, "type": "METRIC", "confidence": 0.9781655311584473}]}, {"text": "We note that the extraction quality of CoreNER orig was low on CoNLL03 and ACE05 mainly due to differences in entity type definitions.", "labels": [], "entities": [{"text": "CoNLL03", "start_pos": 63, "end_pos": 70, "type": "DATASET", "confidence": 0.8916310667991638}, {"text": "ACE05", "start_pos": 75, "end_pos": 80, "type": "DATASET", "confidence": 0.8383059501647949}]}, {"text": "In particular, sports organizations, which occurred frequently in the CoNLL03 collection, were not considered during the development of CoreNER orig , while in ACE05, ORG and LOC entity types were split into four entity types (Organization, Location, Geo-Political Entity and Facility).", "labels": [], "entities": [{"text": "CoNLL03 collection", "start_pos": 70, "end_pos": 88, "type": "DATASET", "confidence": 0.9643300771713257}, {"text": "ACE05", "start_pos": 160, "end_pos": 165, "type": "DATASET", "confidence": 0.9627021551132202}]}, {"text": "Customizations such as C Sand C G address the above changes in named-entity type definition and substantially improve the extraction quality of CoreNER orig . Next, we compare the extraction quality of the customized CoreNER for CoNLL03 and Enron 3 with the corresponding best published results by and).", "labels": [], "entities": [{"text": "CoNLL03", "start_pos": 229, "end_pos": 236, "type": "DATASET", "confidence": 0.9029859900474548}]}, {"text": "7 shows that our customized CoreNER outperforms the corresponding state-of-the-art numbers for all the NER tasks on both These results demonstrate that high-quality annotators can be built by customizing CoreNER orig using NERL, with the final extraction quality matching that of state-of-theart machine learning-based extractors.", "labels": [], "entities": []}, {"text": "It is worthwhile noting that the best published results for) were obtained by using four different classifiers (Robust Risk Minimization, Maximum Entropy, Transformation-based learning, and Hidden Markov Model) and trying six different classifier combination methods.", "labels": [], "entities": [{"text": "Robust Risk Minimization", "start_pos": 112, "end_pos": 136, "type": "TASK", "confidence": 0.639031300942103}]}, {"text": "Compared to the best published result obtained by combining the four classifiers, the individual classifiers performed between 2.5-7.6% worse for Location, 5.6-15.2% for Organization and 3.9-14.0% for Person 5 . Taking this into account, the extraction quality advantage of customized CoreNER is significant when compared with the individual state-of-the-art classifiers.", "labels": [], "entities": []}, {"text": "Impact of Customizations by Type.", "labels": [], "entities": []}, {"text": "While customizing CoreNER for the three datasets, all types of changes described in Sec.", "labels": [], "entities": []}, {"text": "We measured the impact of each type of customization by comparing the extraction quality of CoreNER orig with CoreNER orig enhanced with all the customizations of that type.", "labels": [], "entities": []}, {"text": "From the results for CoNLL03 (Tab. 8), we make the following observations.", "labels": [], "entities": [{"text": "CoNLL03 (Tab. 8", "start_pos": 21, "end_pos": 36, "type": "DATASET", "confidence": 0.7993423789739609}]}, {"text": "\u2022 Customizations that identify additional subtypes of entities (C S ) or modify existing instances for multiple types (C AT A ) have significant impact.", "labels": [], "entities": []}, {"text": "This effect can be especially high when the missing subtype appears very often in the new domain (E.g., over 50% of the organizations in CoNLL03 are sports teams  own (e.g., identifying all names that appear as part of a player list increases the recall of PER by over 6% on both CoNLL03 dev and CoNLL03 test ), the overall impact relies on the accumulative effect of many small improvements.", "labels": [], "entities": [{"text": "recall of PER", "start_pos": 247, "end_pos": 260, "type": "METRIC", "confidence": 0.8162734111150106}]}, {"text": "\u2022 Certain customizations (C EB and C DSD ) provide smaller quality improvements, both per rule and in aggregate.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: Rules added during customization", "labels": [], "entities": [{"text": "customization", "start_pos": 29, "end_pos": 42, "type": "TASK", "confidence": 0.9277271032333374}]}, {"text": " Table 5: Quality of customization on train datasets (%)", "labels": [], "entities": [{"text": "Quality", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9615892171859741}]}, {"text": " Table 6: Overall Improvement due to Customization (%)", "labels": [], "entities": []}, {"text": " Table 7: Comparison with state-of-the-art results(%)", "labels": [], "entities": []}]}