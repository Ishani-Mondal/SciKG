{"title": [{"text": "When Did that Happen? -Linking Events and Relations to Timestamps", "labels": [], "entities": [{"text": "When Did that Happen? -Linking Events and Relations to Timestamps", "start_pos": 0, "end_pos": 65, "type": "TASK", "confidence": 0.7308040335774422}]}], "abstractContent": [{"text": "We present work on linking events and flu-ents (i.e., relations that hold for certain periods of time) to temporal information in text, which is an important enabler for many applications such as timelines and reasoning.", "labels": [], "entities": []}, {"text": "Previous research has mainly focused on temporal links for events, and we extend that work to include fluents as well, presenting a common methodology for linking both events and relations to timestamps within the same sentence.", "labels": [], "entities": []}, {"text": "Our approach combines tree kernels with classical feature-based learning to exploit context and achieves competitive F1-scores on event-time linking, and comparable F1-scores for fluents.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 117, "end_pos": 126, "type": "METRIC", "confidence": 0.9989181756973267}, {"text": "F1-scores", "start_pos": 165, "end_pos": 174, "type": "METRIC", "confidence": 0.9954270124435425}]}, {"text": "Our best systems achieve F1-scores of 0.76 on events and 0.72 on flu-ents.", "labels": [], "entities": [{"text": "F1-scores", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9997169375419617}]}], "introductionContent": [{"text": "It is a long-standing goal of NLP to process natural language content in such away that machines can effectively reason over the entities, relations, and events discussed within that content.", "labels": [], "entities": []}, {"text": "The applications of such technology are numerous, including intelligence gathering, business analytics, healthcare, education, etc.", "labels": [], "entities": [{"text": "intelligence gathering", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.7668275833129883}]}, {"text": "Indeed, the promise of machine reading is actively driving research in this area (.", "labels": [], "entities": [{"text": "machine reading", "start_pos": 23, "end_pos": 38, "type": "TASK", "confidence": 0.8222586214542389}]}, {"text": "Temporal information is a crucial aspect of this task.", "labels": [], "entities": [{"text": "Temporal information", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8457072675228119}]}, {"text": "For a machine to successfully understand natural language text, it must be able to associate time points and temporal durations with relations and events it discovers in text.", "labels": [], "entities": []}, {"text": "* The first author conducted this research during an internship at In this paper we present methods to establish links between events (e.g. \"bombing\" or \"election\") or fluents (e.g. \"spouseOf\" or \"employedBy\") and temporal expressions (e.g. \"last Tuesday\" and \".", "labels": [], "entities": []}, {"text": "While previous research has mainly focused on temporal links for events only, we deal with both events and fluents with the same method.", "labels": [], "entities": []}, {"text": "For example, consider the sentence below Before his death in October, Steve Jobs led Apple for 15 years.", "labels": [], "entities": [{"text": "Apple", "start_pos": 85, "end_pos": 90, "type": "DATASET", "confidence": 0.9263787865638733}]}, {"text": "For a machine reading system processing this sentence, we would expect it to link the fluent CEO of (Steve Jobs, Apple) to time duration \"15 years\".", "labels": [], "entities": []}, {"text": "Similarly we expect it to link the event \"death\" to the time expression \"October\".", "labels": [], "entities": []}, {"text": "We do not take a strong \"ontological\" position on what events and fluents are, as part of our task these distinctions are made a priori.", "labels": [], "entities": []}, {"text": "In other words, events and fluents are input to our temporal linking framework.", "labels": [], "entities": []}, {"text": "In the remainder of this paper, we also do not make a strong distinction between relations in general and fluents in particular, and use them interchangeably, since our focus is only on the specific types of relations that represent fluents.", "labels": [], "entities": []}, {"text": "While we only use binary relations in this work, there is nothing in the framework that would prevent the use of n-ary relations.", "labels": [], "entities": []}, {"text": "Our work focuses on accurately identifying temporal links for eventual use in a machine reading context.", "labels": [], "entities": []}, {"text": "In this paper, we describe a single approach that applies to both fluents and events, using feature engineering as well as tree kernels.", "labels": [], "entities": []}, {"text": "We show that we can achieve good results for both events and fluents using the same feature space, and advocate the versatility of our approach by achieving competitive results on yet another similar task with a different data set.", "labels": [], "entities": []}, {"text": "Our approach requires us to capture contextual properties of text surrounding events, fluents and time expressions that enable an automatic system to detect temporal linking within our framework.", "labels": [], "entities": []}, {"text": "A common strategy for this is to follow standard feature engineering methodology and manually develop features fora machine learning model from the lexical, syntactic and semantic analysis of the text.", "labels": [], "entities": []}, {"text": "A key contribution of our work in this paper is to demonstrate a shallow tree-like representation of the text that enables us to employ tree kernel models, and more accurately detect temporal linking.", "labels": [], "entities": []}, {"text": "The feature space represented by such tree kernels is far larger than a manually engineered feature space, and is capable of capturing the contextual information required for temporal linking.", "labels": [], "entities": []}, {"text": "The remainder of this paper goes into the details of our approach for temporal linking, and presents empirical evidence for the effectiveness of our approach.", "labels": [], "entities": [{"text": "temporal linking", "start_pos": 70, "end_pos": 86, "type": "TASK", "confidence": 0.7593777477741241}]}, {"text": "The contributions of this paper can be summarized as follows: 1.", "labels": [], "entities": []}, {"text": "We define a common methodology to link events and fluents to timestamps.", "labels": [], "entities": []}, {"text": "2. We use tree kernels in combination with classical feature-based approaches to obtain significant gains by exploiting context.", "labels": [], "entities": []}, {"text": "3. Empirical evidence illustrates that our framework for temporal linking is very effective for the task, achieving an F1-score of 0.76 on events and 0.72 on fluents/relations, as well as 0.65 for TempEval2, approaching state-of-the-art.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9995797276496887}]}], "datasetContent": [{"text": "We now apply our models to real world data, and empirically demonstrate their effectiveness at the task of temporal linking.", "labels": [], "entities": [{"text": "temporal linking", "start_pos": 107, "end_pos": 123, "type": "TASK", "confidence": 0.7162528336048126}]}, {"text": "In this section, we describe the data sets that were used for evaluation, the baselines for comparison, parameter settings, and the results of the experiments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison to Best Systems in TempEval-2", "labels": [], "entities": [{"text": "TempEval-2", "start_pos": 40, "end_pos": 50, "type": "TASK", "confidence": 0.48628494143486023}]}]}