{"title": [{"text": "Computing Lattice BLEU Oracle Scores for Machine Translation", "labels": [], "entities": [{"text": "BLEU Oracle Scores", "start_pos": 18, "end_pos": 36, "type": "METRIC", "confidence": 0.8071692188580831}, {"text": "Machine Translation", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7257892042398453}]}], "abstractContent": [{"text": "The search space of Phrase-Based Statistical Machine Translation (PBSMT) systems can be represented under the form of a directed acyclic graph (lattice).", "labels": [], "entities": [{"text": "Phrase-Based Statistical Machine Translation (PBSMT)", "start_pos": 20, "end_pos": 72, "type": "TASK", "confidence": 0.697549262217113}]}, {"text": "The quality of this search space can thus be evaluated by computing the best achievable hypothesis in the lattice, the so-called oracle hypothesis.", "labels": [], "entities": []}, {"text": "For common SMT metrics, this problem is however NP-hard and can only be solved using heuristics.", "labels": [], "entities": [{"text": "SMT metrics", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.9216984212398529}]}, {"text": "In this work, we present two new methods for efficiently computing BLEU oracles on lattices: the first one is based on a linear approximation of the corpus BLEU score and is solved using the FST formalism; the second one relies on integer linear programming formulation and is solved directly and using the Lagrangian relaxation framework.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 156, "end_pos": 166, "type": "METRIC", "confidence": 0.8834123611450195}, {"text": "FST", "start_pos": 191, "end_pos": 194, "type": "DATASET", "confidence": 0.7507098913192749}]}, {"text": "These new decoders are positively evaluated and compared with several alternatives from the literature for three language pairs, using lattices produced by two PBSMT systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "The search space of Phrase-Based Statistical Machine Translation (PBSMT) systems has the form of a very large directed acyclic graph.", "labels": [], "entities": [{"text": "Phrase-Based Statistical Machine Translation (PBSMT)", "start_pos": 20, "end_pos": 72, "type": "TASK", "confidence": 0.6966510840824672}]}, {"text": "In several softwares, an approximation of this search space can be outputted, either as a n-best list containing then top hypotheses found by the decoder, or as a phrase or word graph (lattice) which compactly encodes those hypotheses that have survived search space pruning.", "labels": [], "entities": []}, {"text": "Lattices usually contain much more hypotheses than n-best lists and better approximate the search space.", "labels": [], "entities": []}, {"text": "Exploring the PBSMT search space is one of the few means to perform diagnostic analysis and to better understand the behavior of the system ().", "labels": [], "entities": [{"text": "PBSMT search space", "start_pos": 14, "end_pos": 32, "type": "DATASET", "confidence": 0.8107440074284872}, {"text": "diagnostic analysis", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.9263797104358673}]}, {"text": "Useful diagnostics are, for instance, provided by looking at the best (oracle) hypotheses contained in the search space, i.e, those hypotheses that have the highest quality score with respect to one or several references.", "labels": [], "entities": []}, {"text": "Such oracle hypotheses can be used for failure analysis and to better understand the bottlenecks of existing translation systems (.", "labels": [], "entities": [{"text": "failure analysis", "start_pos": 39, "end_pos": 55, "type": "TASK", "confidence": 0.7039663791656494}]}, {"text": "Indeed, the inability to faithfully reproduce reference translations can have many causes, such as scantiness of the translation table, insufficient expressiveness of reordering models, inadequate scoring function, non-literal references, over-pruned lattices, etc.", "labels": [], "entities": []}, {"text": "Oracle decoding has several other applications: for instance, in ( it is used as a work-around to the problem of non-reachability of the reference in discriminative training of MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 177, "end_pos": 179, "type": "TASK", "confidence": 0.9305117130279541}]}, {"text": "Lattice reranking (, a promising way to improve MT systems, also relies on oracle decoding to build the training data fora reranking algorithm.", "labels": [], "entities": [{"text": "MT", "start_pos": 48, "end_pos": 50, "type": "TASK", "confidence": 0.9933058619499207}]}, {"text": "For sentence level metrics, finding oracle hypotheses in n-best lists is a simple issue; however, solving this problem on lattices proves much more challenging, due to the number of embedded hypotheses, which prevents the use of bruteforce approaches.", "labels": [], "entities": []}, {"text": "When using BLEU, or rather sentence-level approximations thereof, the problem is in fact known to be NP-hard (.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9944646954536438}]}, {"text": "This complexity stems from the fact that the contribution of a given edge to the total modified n-gram precision cannot be computed without looking at all other edges on the path.", "labels": [], "entities": [{"text": "precision", "start_pos": 103, "end_pos": 112, "type": "METRIC", "confidence": 0.9276527762413025}]}, {"text": "Similar (or worse) complexity result are expected for other metrics such as METEOR () or TER ().", "labels": [], "entities": [{"text": "complexity", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.9609001278877258}, {"text": "METEOR", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9081203937530518}, {"text": "TER", "start_pos": 89, "end_pos": 92, "type": "METRIC", "confidence": 0.9752574563026428}]}, {"text": "The exact computation of oracles under corpus level metrics, such as BLEU, poses supplementary combinatorial problems that will not be addressed in this work.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9911385178565979}]}, {"text": "In this paper, we present two original methods for finding approximate oracle hypotheses on lattices.", "labels": [], "entities": []}, {"text": "The first one is based on a linear approximation of the corpus BLEU, that was originally designed for efficient Minimum Bayesian Risk decoding on lattices ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9863854050636292}, {"text": "Minimum Bayesian Risk decoding", "start_pos": 112, "end_pos": 142, "type": "TASK", "confidence": 0.5931124910712242}]}, {"text": "The second one, based on Integer Linear Programming, is an extension to lattices of a recent work on failure analysis for phrase-based decoders (.", "labels": [], "entities": [{"text": "failure analysis", "start_pos": 101, "end_pos": 117, "type": "TASK", "confidence": 0.7243141233921051}]}, {"text": "In this framework, we study two decoding strategies: one based on a generic ILP solver, and one, based on Lagrangian relaxation.", "labels": [], "entities": [{"text": "ILP solver", "start_pos": 76, "end_pos": 86, "type": "TASK", "confidence": 0.621691882610321}]}, {"text": "Our contribution is also experimental as we compare the quality of the BLEU approximations and the time performance of these new approaches with several existing methods, for different language pairs and using the lattice generation capacities of two publicly-available state-of-theart phrase-based decoders: Moses 1 and N-code 2 . The rest of this paper is organized as follows.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.9619743824005127}]}, {"text": "In Section 2, we formally define the oracle decoding task and recall the formalism of finite state automata on semirings.", "labels": [], "entities": []}, {"text": "We then describe (Section 3) two existing approaches for solving this task, before detailing our new proposals in sections 4 and 5.", "labels": [], "entities": []}, {"text": "We then report evaluations of the existing and new oracles on machine translation tasks.", "labels": [], "entities": [{"text": "machine translation tasks", "start_pos": 62, "end_pos": 87, "type": "TASK", "confidence": 0.8292649785677592}]}], "datasetContent": [{"text": "For the proposed new oracles and the existing approaches, we compare the quality of oracle translations and the average time per sentence needed to compute them 8 on several datasets for 3 language pairs, using lattices generated by two opensource decoders: N-code and Moses 9 8 Experiments were run in parallel on a server with 64G of RAM and 2 Xeon CPUs with 4 cores at 2.3 GHz.", "labels": [], "entities": []}, {"text": "As the ILP (and RLX) oracle were implemented in Python, we pruned Moses lattices to accelerate task preparation for it.  and 4).", "labels": [], "entities": []}, {"text": "Systems were trained on the data provided for the WMT'11 Evaluation task 10 , tuned on the WMT'09 test data and evaluated on WMT'10 test set 11 to produce lattices.", "labels": [], "entities": [{"text": "WMT'11 Evaluation task 10", "start_pos": 50, "end_pos": 75, "type": "DATASET", "confidence": 0.9156959056854248}, {"text": "WMT'09 test data", "start_pos": 91, "end_pos": 107, "type": "DATASET", "confidence": 0.9891684055328369}, {"text": "WMT'10 test set 11", "start_pos": 125, "end_pos": 143, "type": "DATASET", "confidence": 0.9819550663232803}]}, {"text": "The BLEU test scores and oracle scores on 100-best lists with the approximation (4) for N-code and Moses are given in.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9910976886749268}]}, {"text": "It is not until considering 10,000-best lists that n-best oracles achieve performance comparable to the (mediocre) SP oracle.", "labels": [], "entities": []}, {"text": "To make a fair comparison with the ILP and RLX oracles which optimize 2-BLEU, we included 2-BLEU versions of the LB and LM oracles, identified below with the \"-2g\" suffix.", "labels": [], "entities": []}, {"text": "The two versions of the PB oracle are respectively denoted as PB and PB, by the type of the \u2295-operation they consider (Section 3.2).", "labels": [], "entities": []}, {"text": "Parameters p and r for the LB-4g oracle for N-code were found with grid search and reused for Moses: p = 0.25, r = 0.15 (fr2en); p = 0.175, r = 0.575 (en2de) and p = 0.35, r = 0.425 (de2en).", "labels": [], "entities": []}, {"text": "Correspondingly, for the LB-2g oracle: p = 0.3, r = 0.15; p = 0.3, r = 0.175 and p = 0.575, r = 0.1.", "labels": [], "entities": []}, {"text": "The proposed LB, ILP and RLX oracles were the best performing oracles, with the ILP and RLX oracles being considerably faster, suffering only a negligible decrease in BLEU, compared to the 4-BLEU-optimized LB oracle.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 167, "end_pos": 171, "type": "METRIC", "confidence": 0.9993570446968079}]}, {"text": "We stopped RLX oracle after 20 iterations, as letting it converge had a small negative effect (\u223c1 point of the corpus BLEU), because of the sentence/corpus discrepancy ushered by the BLEU score approximation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 118, "end_pos": 122, "type": "METRIC", "confidence": 0.9922324419021606}, {"text": "BLEU score approximation", "start_pos": 183, "end_pos": 207, "type": "METRIC", "confidence": 0.9705027341842651}]}, {"text": "Experiments showed consistently inferior performance of the LM-oracle resulting from the optimization of the sentence probability rather than BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 142, "end_pos": 146, "type": "METRIC", "confidence": 0.997333288192749}]}, {"text": "The PB oracle often performed comparably to our new oracles, however, with sporadic resource-consumption bursts, that are difficult to   avoid without more cursory hypotheses recombination strategies and the induced effect on the translations quality.", "labels": [], "entities": []}, {"text": "The length-aware PB oracle has unexpectedly poorer scores compared to its length-agnostic PB counterpart, while it should, at least, stay even, as it takes the brevity penalty into account.", "labels": [], "entities": []}, {"text": "We attribute this fact to the complex effect of clipping coupled with the lack of control of the process of selecting one hypothesis among several having the same BLEU score, length and recent history.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 163, "end_pos": 173, "type": "METRIC", "confidence": 0.9831494688987732}, {"text": "length", "start_pos": 175, "end_pos": 181, "type": "METRIC", "confidence": 0.9419013261795044}]}, {"text": "Anyhow, BLEU scores of both of PB oracles are only marginally different, so the PB's conservative policy of pruning and, consequently, much heavier memory consumption makes it an unwanted choice.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 8, "end_pos": 12, "type": "METRIC", "confidence": 0.9994213581085205}]}], "tableCaptions": [{"text": " Table 2: Test BLEU scores and oracle scores on  100-best lists for the evaluated systems.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.9888033270835876}]}]}