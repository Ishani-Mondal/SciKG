{"title": [{"text": "Cutting the Long Tail: Hybrid Language Models for Translation Style Adaptation", "labels": [], "entities": [{"text": "Translation Style Adaptation", "start_pos": 50, "end_pos": 78, "type": "TASK", "confidence": 0.9193285504976908}]}], "abstractContent": [{"text": "In this paper, we address statistical machine translation of public conference talks.", "labels": [], "entities": [{"text": "statistical machine translation of public conference talks", "start_pos": 26, "end_pos": 84, "type": "TASK", "confidence": 0.7629605191094535}]}, {"text": "Modeling the style of this genre can be very challenging given the shortage of available in-domain training data.", "labels": [], "entities": []}, {"text": "We investigate the use of a hybrid LM, where infrequent words are mapped into classes.", "labels": [], "entities": []}, {"text": "Hybrid LMs are used to complement word-based LMs with statistics about the language style of the talks.", "labels": [], "entities": []}, {"text": "Extensive experiments comparing different settings of the hybrid LM are reported on publicly available benchmarks based on TED talks, from Arabic to English and from English to French.", "labels": [], "entities": []}, {"text": "The proposed models show to better exploit in-domain data than conventional word-based LMs for the target language modeling component of a phrase-based statistical machine translation system.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 139, "end_pos": 183, "type": "TASK", "confidence": 0.5801371708512306}]}], "introductionContent": [{"text": "The translation of TED conference talks 1 is an emerging task in the statistical machine translation (SMT) community ).", "labels": [], "entities": [{"text": "translation of TED conference talks 1", "start_pos": 4, "end_pos": 41, "type": "TASK", "confidence": 0.8330633640289307}, {"text": "statistical machine translation (SMT)", "start_pos": 69, "end_pos": 106, "type": "TASK", "confidence": 0.7993978361288706}]}, {"text": "The variety of topics covered by the speeches, as well as their specific language style, make this a very challenging problem.", "labels": [], "entities": []}, {"text": "Fixed expressions, colloquial terms, figures of speech and other phenomena recurrent in the talks should be properly modeled to produce translations that are not only fluent but that also employ the right register.", "labels": [], "entities": []}, {"text": "In this paper, we propose a language modeling technique that leverages indomain training data for style adaptation.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.6967474222183228}, {"text": "style adaptation", "start_pos": 98, "end_pos": 114, "type": "TASK", "confidence": 0.8449842035770416}]}, {"text": "1 http://www.ted.com/talks Hybrid class-based LMs are trained on text where only infrequent words are mapped to Partof-Speech (POS) classes.", "labels": [], "entities": []}, {"text": "In this way, topicspecific words are discarded and the model focuses on generic words that we assume more useful to characterize the language style.", "labels": [], "entities": []}, {"text": "The factorization of similar expressions made possible by this mixed text representation yields a better ngram coverage, but with a much higher discriminative power than POS-level LMs.", "labels": [], "entities": []}, {"text": "Hybrid LM also differs from POS-level LM in that it uses a word-to-class mapping to determine POS tags.", "labels": [], "entities": []}, {"text": "Consequently, it doesn't require the decoding overload of factored models nor the tagging of all parallel data used to build phrase tables.", "labels": [], "entities": []}, {"text": "A hybrid LM trained on in-domain data can thus be easily added to an existing baseline system trained on large amounts of background data.", "labels": [], "entities": []}, {"text": "The proposed models are used in addition to standard word-based LMs, in the framework of log-linear phrase-based SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 113, "end_pos": 116, "type": "TASK", "confidence": 0.8006715178489685}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "After discussing the language style adaptation problem, we will give an overview of relevant work.", "labels": [], "entities": [{"text": "language style adaptation", "start_pos": 21, "end_pos": 46, "type": "TASK", "confidence": 0.7399423917134603}]}, {"text": "In the following sections we will describe in detail hybrid LM and its possible variants.", "labels": [], "entities": []}, {"text": "Finally, we will present an empirical analysis of the proposed technique, including intrinsic evaluation and SMT experiments.", "labels": [], "entities": [{"text": "SMT", "start_pos": 109, "end_pos": 112, "type": "TASK", "confidence": 0.99357670545578}]}], "datasetContent": [{"text": "In this section we perform an intrinsic evaluation of the proposed LM technique, then we measure its impact on translation quality when integrated into a state-of-the-art phrase-based SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 184, "end_pos": 187, "type": "TASK", "confidence": 0.8774731159210205}]}, {"text": "We analyze here a set of hybrid LMs trained on the English TED corpus by varying the ratio of POS-mapped words and the word representation technique (word vs lemma).", "labels": [], "entities": [{"text": "English TED corpus", "start_pos": 51, "end_pos": 69, "type": "DATASET", "confidence": 0.8328254024187723}, {"text": "word representation", "start_pos": 119, "end_pos": 138, "type": "TASK", "confidence": 0.6732961535453796}]}, {"text": "All models were trained with the IRSTLM toolkit (, using a very high n-gram order (10) and Witten-Bell smoothing.", "labels": [], "entities": [{"text": "IRSTLM toolkit", "start_pos": 33, "end_pos": 47, "type": "DATASET", "confidence": 0.8207203149795532}]}, {"text": "First, we estimate an upper bound of the POS tagging errors introduced by deterministic tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 41, "end_pos": 52, "type": "TASK", "confidence": 0.7080131769180298}]}, {"text": "At this end, the hybridly mapped data is compared with the actual output of Tree Tagger on the TED training corpus (see).", "labels": [], "entities": [{"text": "TED training corpus", "start_pos": 95, "end_pos": 114, "type": "DATASET", "confidence": 0.8484514156977335}]}, {"text": "Naturally, the impact of tagging errors correlates with the ratio of POS-mapped tokens, as no error is counted on non-mapped tokens.", "labels": [], "entities": []}, {"text": "For instance, we note that the POS error rate is only 1.9% in our primary setting, WP =.25 and word representation, whereas on a fully POS-mapped text it is 6.6%.", "labels": [], "entities": [{"text": "POS error rate", "start_pos": 31, "end_pos": 45, "type": "METRIC", "confidence": 0.6884320775667826}, {"text": "WP", "start_pos": 83, "end_pos": 85, "type": "METRIC", "confidence": 0.9433508515357971}]}, {"text": "Note that the English tag set used by Tree Tagger includes 43 classes.", "labels": [], "entities": [{"text": "Tree Tagger", "start_pos": 38, "end_pos": 49, "type": "TASK", "confidence": 0.6808086335659027}]}, {"text": "Now we focus on the main goal of hybrid text representation, namely increasing the coverage of the in-domain LM on the test data.", "labels": [], "entities": [{"text": "hybrid text representation", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.6194128096103668}]}, {"text": "Here too, we measure coverage by the average length of word history h used to score the test reference translations (see Section 2).", "labels": [], "entities": [{"text": "coverage", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9745950698852539}]}, {"text": "We do not provide perplexity figures, since these are not directly comparable across models with different vocabularies.", "labels": [], "entities": []}, {"text": "As shown by  course, the more words are mapped, the less discriminative our model will be.", "labels": [], "entities": []}, {"text": "Thus, choosing the best hybrid mapping means finding the best tradeoff between coverage and informativeness.", "labels": [], "entities": []}, {"text": "We also applied hybrid LM to the French language, again using Tree Tagger to create the POS mapping.", "labels": [], "entities": []}, {"text": "The tag set in this case comprises 34 classes and the POS error rate with WP =.25 is 1.2% (compare with 1.9% in English).", "labels": [], "entities": [{"text": "POS error rate", "start_pos": 54, "end_pos": 68, "type": "METRIC", "confidence": 0.8172401388486227}, {"text": "WP", "start_pos": 74, "end_pos": 76, "type": "METRIC", "confidence": 0.9645543694496155}]}, {"text": "As previously discussed, morphology has a notable effect on the modeling of French.", "labels": [], "entities": [{"text": "modeling of French", "start_pos": 64, "end_pos": 82, "type": "TASK", "confidence": 0.7719825903574625}]}, {"text": "In fact, the vocabulary reduction obtained by mapping all the words to their most probable lemma is -45% (57959 to 31908 types in the TED corpus), while in English it is only -25%.", "labels": [], "entities": [{"text": "vocabulary reduction", "start_pos": 13, "end_pos": 33, "type": "METRIC", "confidence": 0.8450838327407837}, {"text": "TED corpus", "start_pos": 134, "end_pos": 144, "type": "DATASET", "confidence": 0.8892887532711029}]}], "tableCaptions": [{"text": " Table 4: Most common hybrid 5-grams containing the  words guy and actually, along with absolute frequency.", "labels": [], "entities": [{"text": "frequency", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.6863800883293152}]}, {"text": " Table 5: Comparison of LMs obtained from different  hybrid mappings of the English TED corpus: vocabu- lary size, POS error rate, and average word history on  IWSLT-tst2010's reference translations.", "labels": [], "entities": [{"text": "English TED corpus", "start_pos": 76, "end_pos": 94, "type": "DATASET", "confidence": 0.7601649165153503}, {"text": "vocabu- lary size", "start_pos": 96, "end_pos": 113, "type": "METRIC", "confidence": 0.766449585556984}, {"text": "POS error rate", "start_pos": 115, "end_pos": 129, "type": "METRIC", "confidence": 0.895500123500824}, {"text": "IWSLT-tst2010's reference translations", "start_pos": 160, "end_pos": 198, "type": "DATASET", "confidence": 0.9500377923250198}]}, {"text": " Table 6: IWSLT11 training and test data statistics:  number of sentences |S|, number of tokens |W | and  average sentence length . Token numbers are com- puted on the target language, except for the test sets.", "labels": [], "entities": [{"text": "IWSLT11", "start_pos": 10, "end_pos": 17, "type": "DATASET", "confidence": 0.7815067172050476}]}, {"text": " Table 7: Comparison of various hybrid LM variants. Translation quality is measured with BLEU, METEOR and  TER (all in percentage form). The settings used for weight tuning are marked with  \u2020. Best models according to  all metrics are highlighted in bold.", "labels": [], "entities": [{"text": "Translation", "start_pos": 52, "end_pos": 63, "type": "TASK", "confidence": 0.8926324248313904}, {"text": "BLEU", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.9993126392364502}, {"text": "METEOR", "start_pos": 95, "end_pos": 101, "type": "METRIC", "confidence": 0.9971381425857544}, {"text": "TER", "start_pos": 107, "end_pos": 110, "type": "METRIC", "confidence": 0.9970779418945312}, {"text": "weight tuning", "start_pos": 159, "end_pos": 172, "type": "TASK", "confidence": 0.6679033190011978}]}, {"text": " Table 8: Final MT results: baseline vs unsupervised  word classes-based LM and best hybrid LM. Statis- tically significant improvements over the baseline are  marked with \u2022 at the p < .01 and \u2022 at the p < .05 level.", "labels": [], "entities": [{"text": "MT", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.9648388624191284}]}]}