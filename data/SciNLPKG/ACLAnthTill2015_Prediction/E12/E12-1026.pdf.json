{"title": [{"text": "Adapting Translation Models to Translationese Improves SMT", "labels": [], "entities": [{"text": "Adapting Translation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9490679204463959}, {"text": "SMT", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.5757185220718384}]}], "abstractContent": [{"text": "Translation models used for statistical machine translation are compiled from parallel corpora; such corpora are manually translated, but the direction of translation is usually unknown, and is consequently ignored.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 28, "end_pos": 59, "type": "TASK", "confidence": 0.6524515251318613}]}, {"text": "However, much research in Translation Studies indicates that the direction of translation matters, as translated language (translationese) has many unique properties.", "labels": [], "entities": [{"text": "Translation Studies", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.9749013185501099}]}, {"text": "Specifically, phrase tables constructed from parallel corpora translated in the same direction as the translation task perform better than ones constructed from corpora translated in the opposite direction.", "labels": [], "entities": []}, {"text": "We reconfirm that this is indeed the case, but emphasize the importance of using also texts translated in the 'wrong' direction.", "labels": [], "entities": []}, {"text": "We take advantage of information pertaining to the direction of translation in constructing phrase tables, by adapting the translation model to the special properties of translationese.", "labels": [], "entities": []}, {"text": "We define entropy-based measures that estimate the correspondence of target-language phrases to transla-tionese, thereby eliminating the need to annotate the parallel corpus with information pertaining to the direction of translation.", "labels": [], "entities": []}, {"text": "We show that incorporating these measures as features in the phrase tables of statistical machine translation systems results in consistent, statistically significant improvement in the quality of the translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 78, "end_pos": 109, "type": "TASK", "confidence": 0.6118102272351583}]}], "introductionContent": [{"text": "Much research in Translation Studies indicates that translated texts have unique characteristics that set them apart from original texts.", "labels": [], "entities": [{"text": "Translation Studies", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.9826279282569885}]}, {"text": "Known as translationese, translated texts (in any language) constitute a genre, or a dialect, of the target language, which reflects both artifacts of the translation process and traces of the original language from which the texts were translated.", "labels": [], "entities": []}, {"text": "Among the better-known properties of translationese are simplification and explicitation: translated texts tend to be shorter, to have lower type/token ratio, and to use certain discourse markers more frequently than original texts.", "labels": [], "entities": []}, {"text": "Incidentally, translated texts are so markedly different from original ones that automatic classification can identify them with very high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9876132011413574}]}, {"text": "Contemporary Statistical Machine Translation (SMT) systems use parallel corpora to train translation models that reflect source-and targetlanguage phrase correspondences.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 13, "end_pos": 50, "type": "TASK", "confidence": 0.7852522085110346}]}, {"text": "Typically, SMT systems ignore the direction of translation used to produce those corpora.", "labels": [], "entities": [{"text": "SMT", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9945433139801025}]}, {"text": "Given the unique properties of translationese, however, it is reasonable to assume that this direction may affect the quality of the translation.", "labels": [], "entities": []}, {"text": "Recently, showed that this is indeed the case.", "labels": [], "entities": []}, {"text": "They train a system to translate between French and English (and vice versa) using a Frenchtranslated-to-English parallel corpus, and then an English-translated-to-French one.", "labels": [], "entities": [{"text": "translate between French and English", "start_pos": 23, "end_pos": 59, "type": "TASK", "confidence": 0.8228442788124084}]}, {"text": "They find that in translating into French the latter parallel corpus yields better results, whereas for translating into English it is better to use the former.", "labels": [], "entities": []}, {"text": "Usually, of course, the translation direction of a parallel corpus is unknown.", "labels": [], "entities": []}, {"text": "Therefore, train an SVM-based classifier to predict which side of a bi-text is the origin and which one is the translation, and only use the subset of the corpus that corresponds to the translation direction of the task in training their translation model.", "labels": [], "entities": []}, {"text": "We use these results as our departure point, but improve them in two major ways.", "labels": [], "entities": []}, {"text": "First, we demonstrate that the other subset of the corpus, reflecting translation in the 'wrong' direction, is also important for the translation task, and must not be ignored; second, we show that explicit information on the direction of translation of the parallel corpus, whether manually-annotated or machine-learned, is not mandatory.", "labels": [], "entities": [{"text": "translation task", "start_pos": 134, "end_pos": 150, "type": "TASK", "confidence": 0.9233607947826385}]}, {"text": "This is achieved by casting the problem in the framework of domain adaptation: we use domain-adaptation techniques to direct the SMT system toward producing output that better reflects the properties of translationese.", "labels": [], "entities": [{"text": "SMT", "start_pos": 129, "end_pos": 132, "type": "TASK", "confidence": 0.9845971465110779}]}, {"text": "We show that SMT systems adapted to translationese produce better translations than vanilla systems trained on exactly the same resources.", "labels": [], "entities": [{"text": "SMT", "start_pos": 13, "end_pos": 16, "type": "TASK", "confidence": 0.9928120970726013}, {"text": "translationese", "start_pos": 36, "end_pos": 50, "type": "TASK", "confidence": 0.9755471348762512}]}, {"text": "We confirm these findings using an automatic evaluation metric, BLEU), as well as through a qualitative analysis of the results.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 64, "end_pos": 68, "type": "METRIC", "confidence": 0.8885263204574585}]}, {"text": "Our departure point is the results of, which we successfully replicate in Section 3.", "labels": [], "entities": []}, {"text": "First (Section 4), we explain why translation quality improves when the parallel corpus is translated in the 'right' direction.", "labels": [], "entities": [{"text": "translation", "start_pos": 34, "end_pos": 45, "type": "TASK", "confidence": 0.9552561640739441}]}, {"text": "We do so by showing that the subset of the corpus that was translated in the direction of the translation task (the 'right' direction, henceforth source-to-target, or S \u2192 T ) yields phrase tables that are better suited for translation of the original language than the subset translated in the reverse direction (the 'wrong' direction, henceforth target-to-source, or T \u2192 S).", "labels": [], "entities": []}, {"text": "We use several statistical measures that indicate the better quality of the phrase tables in the former case.", "labels": [], "entities": []}, {"text": "Then (Section 5), we explore ways to build a translation model that is adapted to the unique properties of translationese.", "labels": [], "entities": []}, {"text": "We first show that using the entire parallel corpus, including texts that are translated both in the 'right' and in the 'wrong' direction, improves the quality of the results.", "labels": [], "entities": []}, {"text": "Furthermore, we show that the direction of translation used for producing the parallel corpus can be approximated by defining several entropybased measures that correlate well with translationese, and, consequently, with the quality of the translation.", "labels": [], "entities": []}, {"text": "Specifically, we use the entire corpus, create a single, unified phrase table and then use the statistical measures mentioned above, and in particular cross-entropy, as a clue for selecting phrase pairs from this table.", "labels": [], "entities": []}, {"text": "The benefit of this method is that not only does it yield the best results, but it also eliminates the need to directly predict the direction of translation of the parallel corpus.", "labels": [], "entities": []}, {"text": "The main contribution of this work, therefore, is a methodology that improves the quality of SMT by building translation models that are adapted to the nature of translationese. are the first to address the direction of translation in the context of SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 93, "end_pos": 96, "type": "TASK", "confidence": 0.9940604567527771}, {"text": "SMT", "start_pos": 250, "end_pos": 253, "type": "TASK", "confidence": 0.9495720863342285}]}, {"text": "Their main finding is that using the S \u2192 T portion of the parallel corpus results in mucqqh better translation quality than when the T \u2192 S portion is used for training the translation model.", "labels": [], "entities": []}, {"text": "We indeed replicate these results here (Section 3), and view them as a baseline.", "labels": [], "entities": []}, {"text": "Additionally, we show that the T \u2192 S portion is also important for machine translation and thus should not be discarded.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.7772936522960663}]}, {"text": "Using information-theory measures, and in particular cross-entropy, we gain statistically significant improvements in translation quality beyond the results of.", "labels": [], "entities": []}, {"text": "Furthermore, we eliminate the need to (manually or automatically) detect the direction of translation of the parallel corpus.", "labels": [], "entities": []}], "datasetContent": [{"text": "The tasks we focus on are translation between French and English, in both directions.", "labels": [], "entities": [{"text": "translation between French and English", "start_pos": 26, "end_pos": 64, "type": "TASK", "confidence": 0.8866769790649414}]}, {"text": "We use the Hansard corpus, containing transcripts of the Canadian parliament from 1996-2007, as the source of all parallel data.", "labels": [], "entities": [{"text": "Hansard corpus", "start_pos": 11, "end_pos": 25, "type": "DATASET", "confidence": 0.989931583404541}]}, {"text": "The Hansard is a bilingual French-English corpus comprising approximately 80% English-original texts and 20% French-original texts.", "labels": [], "entities": [{"text": "The Hansard", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.7096520662307739}]}, {"text": "Crucially, each sentence pair in the corpus is annotated with the direction of translation.", "labels": [], "entities": []}, {"text": "Both English and French are lowercased and tokenized using MOSES (.", "labels": [], "entities": [{"text": "MOSES", "start_pos": 59, "end_pos": 64, "type": "DATASET", "confidence": 0.6305873394012451}]}, {"text": "Sentences longer than 80 words are discarded.", "labels": [], "entities": []}, {"text": "To address the effect of the corpus size, we compile six subsets of different sizes (250K, 500K, 750K, 1M, 1.25M and 1.5M parallel sentences) from each portion (English-original and French-original) of the corpus.", "labels": [], "entities": []}, {"text": "Additionally, we use the devtest section of the Hansard corpus to randomly select French-original and English-original sentences that are used for tuning (1,000 sentences each) and evaluation (5,000 sentences each).", "labels": [], "entities": [{"text": "Hansard corpus", "start_pos": 48, "end_pos": 62, "type": "DATASET", "confidence": 0.9851876199245453}]}, {"text": "French-to-English MT systems are tuned and tested on French-original sentences and English-to-French systems on Englishoriginal ones.", "labels": [], "entities": [{"text": "MT", "start_pos": 18, "end_pos": 20, "type": "TASK", "confidence": 0.7943408489227295}]}, {"text": "To replicate the results of and setup a baseline, we train twelve French-to-English and twelve English-to-French phrase-based (PB-) SMT systems using the MOSES toolkit (), each trained on a different subset of the corpus.", "labels": [], "entities": []}, {"text": "We use GIZA++) with grow-diagfinal alignment, and extract phrases of length up to 10 words.", "labels": [], "entities": []}, {"text": "We prune the resulting phrase tables as in, using at most 30 translations per source phrase and discarding singleton phrase pairs.", "labels": [], "entities": []}, {"text": "We construct English and French 5-gram language models from the English and French subsections of the Europarl-V6 corpus, using interpolated modified Kneser-Ney discounting and no cut-off on all n-grams.", "labels": [], "entities": [{"text": "Europarl-V6 corpus", "start_pos": 102, "end_pos": 120, "type": "DATASET", "confidence": 0.9949672222137451}]}, {"text": "Europarl consists of a large number of subsets translated from various languages, and is therefore unlikely to be biased towards a specific source language.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9216545820236206}]}, {"text": "The reordering model used in all MT systems is trained on the union of the 1.5M French-original and the 1.5M Englishoriginal subsets, using msd-bidirectional-fe reordering.", "labels": [], "entities": [{"text": "MT", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.9799854755401611}]}, {"text": "We use the MERT algorithm for tuning and BLEU () as our evaluation metric.", "labels": [], "entities": [{"text": "MERT", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9301847815513611}, {"text": "BLEU", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.9994741082191467}]}, {"text": "We test the statistical significance of the differences between the results using the bootstrap resampling method.", "labels": [], "entities": []}, {"text": "A word on notation: We use 'English-original' (EO) and 'French-original' (FO) to refer to the subsets of the corpus that are translated from English to French and from French to English, respectively.", "labels": [], "entities": [{"text": "French-original' (FO)", "start_pos": 56, "end_pos": 77, "type": "METRIC", "confidence": 0.6425429522991181}]}, {"text": "The translation tasks are English-toFrench (E2F) and French-to-English (F2E).", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9678338766098022}, {"text": "French-to-English (F2E)", "start_pos": 53, "end_pos": 76, "type": "METRIC", "confidence": 0.5902586206793785}]}, {"text": "We thus use 'S \u2192 T ' when the FO corpus is used for the F2E task or when the EO corpus is used for the E2F task; and 'T \u2192 S' when the FO corpus is used for the E2F task or when the EO corpus is used for the F2E task.", "labels": [], "entities": [{"text": "FO corpus", "start_pos": 30, "end_pos": 39, "type": "DATASET", "confidence": 0.846552848815918}, {"text": "FO corpus", "start_pos": 134, "end_pos": 143, "type": "DATASET", "confidence": 0.8574661910533905}]}, {"text": "depicts the BLEU scores of the baseline systems.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 12, "end_pos": 23, "type": "METRIC", "confidence": 0.9659368097782135}]}, {"text": "The data are consistent with the findings of: systems trained on S \u2192 T parallel texts outperform systems trained on T \u2192 S texts, even when the latter are much larger.", "labels": [], "entities": []}, {"text": "The difference in BLEU score can be as high as 3 points.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 18, "end_pos": 28, "type": "METRIC", "confidence": 0.950131893157959}]}], "tableCaptions": [{"text": " Table 1: BLEU scores of baseline systems", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9988881945610046}]}, {"text": " Table 3: Correlation of BLEU scores with phrase table  statistical measures", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9771073460578918}]}, {"text": " Table 2: Statistic measures computed on the phrase tables: total size, in tokens ('Total'); the number of unique  source phrases ('Source'); the average number of translations per source phrase ('AvgTran'); phrase table entropy  ('PtEnt') and covering set entropy ('CovEnt'); phrase table cross-entropy ('PtCrEnt') and covering set cross- entropy ('CovCrEnt'); and the covering set average length", "labels": [], "entities": []}, {"text": " Table 4: Evaluation of the MIX systems", "labels": [], "entities": [{"text": "MIX", "start_pos": 28, "end_pos": 31, "type": "DATASET", "confidence": 0.6066035032272339}]}, {"text": " Table 5: Statistical measures computed for mixed vs.  source-to-target phrase tables", "labels": [], "entities": []}, {"text": " Table 6: Evaluation of MT Systems", "labels": [], "entities": [{"text": "MT", "start_pos": 24, "end_pos": 26, "type": "TASK", "confidence": 0.9613417983055115}]}]}