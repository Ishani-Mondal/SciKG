{"title": [{"text": "Towards a model of formal and informal address in English", "labels": [], "entities": []}], "abstractContent": [{"text": "Informal and formal (\"T/V\") address in dialogue is not distinguished overtly in modern English, e.g. by pronoun choice like in many other languages such as French (\"tu\"/\"vous\").", "labels": [], "entities": []}, {"text": "Our study investigates the status of the T/V distinction in English literary texts.", "labels": [], "entities": []}, {"text": "Our main findings are: (a) human raters can label monolingual English utterances as T or V fairly well, given sufficient context; (b), a bilingual corpus can be exploited to induce a supervised classifier for T/V without human annotation.", "labels": [], "entities": []}, {"text": "It assigns T/V at sentence level with up to 68% accuracy , relying mainly on lexical features; (c), there is a marked asymmetry between lexical features for formal speech (which are conventionalized and therefore general) and informal speech (which are text-specific).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9988848567008972}]}], "introductionContent": [{"text": "In many Indo-European languages, there are two pronouns corresponding to the English you.", "labels": [], "entities": []}, {"text": "This distinction is generally referred to as the T/V dichotomy, from the Latin pronouns tu (informal, T) and vos (formal, V) (.", "labels": [], "entities": []}, {"text": "The V form (such as Sie in German and Vous in French) can express neutrality or polite distance and is used to address social superiors.", "labels": [], "entities": []}, {"text": "The T form (German du, French tu) is employed towards friends or addressees of lower social standing, and implies solidarity or lack of formality.", "labels": [], "entities": []}, {"text": "English used to have a T/V distinction until the 18th century, using you as V pronoun and thou for T.", "labels": [], "entities": []}, {"text": "However, in contemporary English, you has taken over both uses, and the T/V distinction is not marked anymore.", "labels": [], "entities": []}, {"text": "In NLP, this makes generation in English and translation into English easy.", "labels": [], "entities": [{"text": "generation", "start_pos": 19, "end_pos": 29, "type": "TASK", "confidence": 0.969619631767273}, {"text": "translation", "start_pos": 45, "end_pos": 56, "type": "TASK", "confidence": 0.9609327912330627}]}, {"text": "Conversely, many NLP tasks suffer from the lack of information about formality, e.g. the extraction of social relationships or, notably, machine translation from English into languages with a T/V distinction which involves a pronoun choice.", "labels": [], "entities": [{"text": "extraction of social relationships", "start_pos": 89, "end_pos": 123, "type": "TASK", "confidence": 0.8309731483459473}, {"text": "machine translation from English", "start_pos": 137, "end_pos": 169, "type": "TASK", "confidence": 0.7723458707332611}]}, {"text": "In this paper, we investigate the possibility to recover the T/V distinction for (monolingual) sentences of 19th and 20th-century English such as: ( Can I help you, Sir?", "labels": [], "entities": []}, {"text": "(V) You are my best friend!", "labels": [], "entities": []}, {"text": "(T) After describing the creation of an English corpus of T/V labels via annotation projection (Section 3), we present an annotation study (Section 4) which establishes that taggers can indeed assign T/V labels to monolingual English utterances in context fairly reliably.", "labels": [], "entities": []}, {"text": "Section 5 investigates how T/V is expressed in English texts by experimenting with different types of features, including words, semantic classes, and expressions based on Politeness Theory.", "labels": [], "entities": []}, {"text": "We find word features to be most reliable, obtaining an accuracy of close to 70%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9996097683906555}]}], "datasetContent": [{"text": "We first perform model selection on the development set and then validate our results on the test set (cf. Section 3.3).", "labels": [], "entities": []}, {"text": "shows the influence of size and type of context, using only words as features.", "labels": [], "entities": []}, {"text": "Without context, we obtain a performance of 61.1% (sentence context) and of 62.9% (direct speech context).", "labels": [], "entities": []}, {"text": "These numbers beat the random baseline (50.0%) and the frequency baseline (59.1%).  spectively.", "labels": [], "entities": [{"text": "frequency baseline", "start_pos": 55, "end_pos": 73, "type": "METRIC", "confidence": 0.9437701404094696}]}, {"text": "This indicates that sparseness is indeed a major challenge, and context can become large before the effects mentioned in Section 5.3 counteract the positive effect of more data.", "labels": [], "entities": []}, {"text": "Direct speech context outperforms sentence context throughout, with a maximum accuracy of 67.0% as compared to 65.2%, even though it shows higher variation, which we attribute to the less stable nature of the direct speech chunks and their automatically created labels.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9992302656173706}]}, {"text": "From now on, we adopt a direct speech context of size 8 unless specified differently.", "labels": [], "entities": []}, {"text": "shows the results for different feature types.", "labels": [], "entities": []}, {"text": "The best model (word features only) is highly significantly better than the frequency baseline (which it beats by 8%) as determined by a bootstrap resampling test.", "labels": [], "entities": []}, {"text": "It gains 17% over the random baseline, but is still more than 10% below inter-annotator agreement in context, which is often seen as an upper bound for automatic models.", "labels": [], "entities": []}, {"text": "Disappointingly, the comparison of the feature groups yields a null result: We are notable to improve over the results for just word features with either the semantic class or the politeness features.", "labels": [], "entities": []}, {"text": "Neither feature type outperforms the frequency baseline significantly (p>0.05).", "labels": [], "entities": []}, {"text": "Combinations of the different feature types also do worse than just words.", "labels": [], "entities": []}, {"text": "The differences between the best model (just words) and the combination models are all not significant (p>0.05).", "labels": [], "entities": []}, {"text": "These negative results warrant further analysis.", "labels": [], "entities": []}, {"text": "It follows in Section 6.3.", "labels": [], "entities": [{"text": "Section 6.3", "start_pos": 14, "end_pos": 25, "type": "DATASET", "confidence": 0.9200958907604218}]}, {"text": "not overfit on the development set when picking the best model.", "labels": [], "entities": []}, {"text": "The tendencies correspond well to the development set: the frequency baseline is almost identical, as are the results for the different models.", "labels": [], "entities": []}, {"text": "The differences to the development set are all equal to or smaller than 1% accuracy, and the best result at 67.5% is 0.5% better than on the development set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9996351003646851}]}, {"text": "This is a reassuring result, as our model appears to generalize well to unseen data.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: 16 Politeness theory-based features with intended classes and example expressions", "labels": [], "entities": []}, {"text": " Table 4: T/V classification accuracy on the develop- ment set (direct speech context, size 8).  *  *  : Significant  difference to frequency baseline (p<0.01)", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9450766444206238}]}, {"text": " Table 6: Most indicative word features for T or V", "labels": [], "entities": []}, {"text": " Table 7: T/V prediction models for individual novels  (50% of each novel for training and 50% testing)", "labels": [], "entities": [{"text": "T/V prediction", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.8648808896541595}]}]}