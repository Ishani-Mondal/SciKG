{"title": [{"text": "Does more data always yield better translations?", "labels": [], "entities": []}], "abstractContent": [{"text": "Nowadays, there are large amounts of data available to train statistical machine translation systems.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 61, "end_pos": 92, "type": "TASK", "confidence": 0.6444938679536184}]}, {"text": "However, it is not clear whether all the training data actually help or not.", "labels": [], "entities": []}, {"text": "A system trained on a subset of such huge bilingual corpora might outperform the use of all the bilingual data.", "labels": [], "entities": []}, {"text": "This paper studies such issues by analysing two training data selection techniques: one based on approximating the probability of an in-domain corpus; and another based on infrequent n-gram occurrence.", "labels": [], "entities": []}, {"text": "Experimental results not only report significant improvements over random sentence selection but also an improvement over a system trained with the whole available data.", "labels": [], "entities": []}, {"text": "Surprisingly, the improvements are obtained with just a small fraction of the data that accounts for less than 0.5% of the sentences.", "labels": [], "entities": []}, {"text": "After-wards, we show that a much larger room for improvement exists, although this is done under non-realistic conditions.", "labels": [], "entities": []}], "introductionContent": [{"text": "Globalisation and the popularisation of the Internet have lead to a rapid increase in the amount of bilingual corpora available.", "labels": [], "entities": []}, {"text": "Entities such as the European Union, the United Nations and other multinational organisations need to translate all the documentation they generate.", "labels": [], "entities": []}, {"text": "Such translations happen everyday and provide very large multilingual corpora, which are oftentimes difficult to process and significantly increase the computational requirements needed to train statistical machine translation (SMT) systems.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 195, "end_pos": 232, "type": "TASK", "confidence": 0.775274987022082}]}, {"text": "For instance, the corpora made available for recent machine translation evaluations are in the order of 1 billion running words . However, two main problems arise when attempting to use this huge pool of sentences for training SMT systems: firstly, a large portion of this data is obtained from domains that differ from that in which the SMT system is to be used or assessed; secondly, the use of all this data for training the system increases the computational training requirements.", "labels": [], "entities": [{"text": "machine translation evaluations", "start_pos": 52, "end_pos": 83, "type": "TASK", "confidence": 0.850645899772644}, {"text": "SMT", "start_pos": 227, "end_pos": 230, "type": "TASK", "confidence": 0.9309185743331909}, {"text": "SMT", "start_pos": 338, "end_pos": 341, "type": "TASK", "confidence": 0.9541343450546265}]}, {"text": "Despite the previous remarks, the de facto standard consists in training SMT systems with all the available data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.9671173691749573}]}, {"text": "This is due to the widespread misconception that the more data a system is trained with, the better its performance should be.", "labels": [], "entities": []}, {"text": "Although the previous statement is theoretically true if all the data belongs to the same domain, this is not the casein the problems tackled by most of the SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 157, "end_pos": 160, "type": "TASK", "confidence": 0.9904126524925232}]}, {"text": "For instance, enterprises often need to build on-demand systems (.", "labels": [], "entities": []}, {"text": "In this case, since we are interested in translating some specific text, it is not clear whether training a system with all data yields better performance than training it with a wisely selected subset of bilingual sentences.", "labels": [], "entities": []}, {"text": "The bilingual sentence selection (BSS) task is stated as the problem of selecting the best subset of bilingual sentences from an available pool of sentences, with which to train a SMT system.", "labels": [], "entities": [{"text": "bilingual sentence selection (BSS) task", "start_pos": 4, "end_pos": 43, "type": "TASK", "confidence": 0.796422941344125}, {"text": "SMT", "start_pos": 180, "end_pos": 183, "type": "TASK", "confidence": 0.9949147701263428}]}, {"text": "This paper is concerned to BSS, and mainly two ideas are developed.", "labels": [], "entities": [{"text": "BSS", "start_pos": 27, "end_pos": 30, "type": "DATASET", "confidence": 0.7121343016624451}]}, {"text": "On the one hand, two BSS strategies that attempt to build better translation systems are analysed.", "labels": [], "entities": [{"text": "BSS", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.8713298439979553}]}, {"text": "Such strategies are able to improve state-ofthe-art translation quality without the very high computational resources that are required when using the complete pool of sentences.", "labels": [], "entities": []}, {"text": "Both techniques span through two orthogonal criteria when selecting bilingual sentences from the available pool: avoiding to introduce a bias in the original data distribution, and increasing the informativeness of the corpus.", "labels": [], "entities": []}, {"text": "On the other hand, we prove that among all possible subsets from the sentence pool, there is at least a small one that yields large improvements (up to 10 BLEU points) with respect to a system trained with all the data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 155, "end_pos": 159, "type": "METRIC", "confidence": 0.9989140033721924}]}, {"text": "In order to retrieve such subset, we had to use an oracle that employs information extracted from the reference translations only for the purpose of selecting bilingual sentences.", "labels": [], "entities": []}, {"text": "However, references are not used at any stage within the translation system for obtaining the hypotheses.", "labels": [], "entities": []}, {"text": "Note that although we are notable to achieve such an improvement without an oracle, this result restates the BSS problem as an interesting approach not only for reducing computational effort but also for significantly boosting performance.", "labels": [], "entities": [{"text": "BSS", "start_pos": 109, "end_pos": 112, "type": "TASK", "confidence": 0.8563143610954285}]}, {"text": "To our knowledge, no previous work has quantified the room of improvement in which BSS techniques could incur.", "labels": [], "entities": [{"text": "BSS", "start_pos": 83, "end_pos": 86, "type": "TASK", "confidence": 0.9559899568557739}]}, {"text": "In order to assess the performance of the different BSS techniques, translation results are obtained by using a standard state-of-the-art SMT system (.", "labels": [], "entities": [{"text": "BSS", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.9492220282554626}, {"text": "translation", "start_pos": 68, "end_pos": 79, "type": "TASK", "confidence": 0.9722375869750977}, {"text": "SMT", "start_pos": 138, "end_pos": 141, "type": "TASK", "confidence": 0.9799341559410095}]}, {"text": "The most recent literature defines the SMT problem () as follows: given an input sentence f from a certain source language, the purpose is to find an output sentenc\u00ea e in a certain target language such that\u00ea where h k (f , e) is a score function representing an important feature for the translation off into e, as for example the language model of the target language, a reordering model or several translation models.", "labels": [], "entities": [{"text": "SMT", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.9974445104598999}]}, {"text": "\u03bb k are the log-linear combination weights.", "labels": [], "entities": []}, {"text": "The main contributions of this paper are: \u2022 A BSS technique is analysed, which improves the results obtained with a random bilingual sentence selection strategy when the specific domain to be translated significantly differs from that of the pool of sentences.", "labels": [], "entities": [{"text": "BSS", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.8150447607040405}]}, {"text": "\u2022 Another BSS technique is analysed that, using less than 0.5% of the sentences available, significantly improves over random selection, beating a system trained with all the pool of sentences.", "labels": [], "entities": [{"text": "BSS", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.719128429889679}]}, {"text": "\u2022 We prove, by means of an oracle, that a wise BSS technique can yield large improvements when compared with systems trained with all data available.", "labels": [], "entities": [{"text": "BSS", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.9513546824455261}]}, {"text": "The remaining of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 summarises the related work.", "labels": [], "entities": []}, {"text": "Sections 3 and 4 present two BSS techniques, namely, probabilistic sampling and recovery of infrequent n-grams.", "labels": [], "entities": [{"text": "BSS", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.6699205636978149}]}, {"text": "In Section 5 experimental results are reported.", "labels": [], "entities": []}, {"text": "Finally, the main results of the work and several future work directions are discussed in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the present Section, we first describe the experimental framework employed to assess the performance of the BSS techniques described.", "labels": [], "entities": [{"text": "BSS", "start_pos": 111, "end_pos": 114, "type": "TASK", "confidence": 0.904259443283081}]}, {"text": "Then, results for the probabilistic sentence selection strategy are shown, followed by results obtained with the infrequent n-grams technique.", "labels": [], "entities": [{"text": "sentence selection", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.6843195557594299}]}, {"text": "Some example translations are shown and, finally, we also report experiments using the infrequent n-grams technique in Oracle mode, in order to establish the potential improvement for such technique and for BSS in general.", "labels": [], "entities": [{"text": "BSS", "start_pos": 207, "end_pos": 210, "type": "TASK", "confidence": 0.8938543200492859}]}, {"text": "All experiments were carried out using the open-source SMT toolkit Moses (   GIZA++).", "labels": [], "entities": [{"text": "SMT", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.9541371464729309}]}, {"text": "The language model used was a 5-gram with modified KneserNey smoothing, built with SRILM toolkit).", "labels": [], "entities": []}, {"text": "The loglinear combination weights in Eq.   effective technique that is commonly used is to reproduce out-of-vocabulary words from the source sentence in the target hypothesis.", "labels": [], "entities": []}, {"text": "However, invariable n-grams are usually infrequent as well, which implies that the infrequent n-grams technique would select sentences containing such ngrams, even though they do not provide further information.", "labels": [], "entities": []}, {"text": "As a first approach, we exclude ngrams without any letter.", "labels": [], "entities": []}, {"text": "Baseline experiments have been carried out for TED and NC corpora using the corresponding training set.", "labels": [], "entities": [{"text": "TED", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.7264544367790222}]}, {"text": "For comparison purposes, we also included results fora purely random sentence selection without replacement.", "labels": [], "entities": []}, {"text": "In the plots, each point corresponding to random selection represent the average of 10 repetitions.", "labels": [], "entities": []}, {"text": "Experiments using all data are also reported, although a 64GB machine was necessary, even with binarized phrase and distortion tables.", "labels": [], "entities": []}, {"text": "Experiments were conducted by selecting a fixed amount of sentences according to each one of the techniques described above.", "labels": [], "entities": []}, {"text": "Then, these sentences were included into the training data and subsequent SMT systems were built for translating the test set.", "labels": [], "entities": [{"text": "SMT", "start_pos": 74, "end_pos": 77, "type": "TASK", "confidence": 0.9859364032745361}]}, {"text": "Results are shown in terms of BLEU (), which is an accuracy metric that measures n-gram precision, with a penalty for sentences that are too short.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.9993370175361633}, {"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.9979498982429504}, {"text": "precision", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.9506707191467285}]}, {"text": "Although it could be argued that improvements obtained might be due to aside effect of the brevity penalty, this was not found to be true: the BSS techniques (including random) and considering all data yielded very similar brevity penalties (\u00b10.005), within each corpus.", "labels": [], "entities": []}, {"text": "In addition, TER scores () were also computed, but are omitted for clarity purposes and since they were found to be coherent with BLEU.", "labels": [], "entities": [{"text": "TER scores", "start_pos": 13, "end_pos": 23, "type": "METRIC", "confidence": 0.9832484126091003}, {"text": "clarity", "start_pos": 67, "end_pos": 74, "type": "METRIC", "confidence": 0.9494382739067078}, {"text": "BLEU", "start_pos": 130, "end_pos": 134, "type": "METRIC", "confidence": 0.9927485585212708}]}, {"text": "TER is an error metric that computes the minimum number of edits required to modify the system hypotheses so that they match the references translations.", "labels": [], "entities": [{"text": "TER", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9805704951286316}]}], "tableCaptions": [{"text": " Table 1: Percentage of infrequent n-grams in the TED  test set when considering only the TED training set  (tr), and when adding the out-of-domain pool (all),  for different infrequency thresholds t.", "labels": [], "entities": [{"text": "TED  test set", "start_pos": 50, "end_pos": 63, "type": "DATASET", "confidence": 0.8986953099568685}, {"text": "TED training set", "start_pos": 90, "end_pos": 106, "type": "DATASET", "confidence": 0.8042183121045431}]}, {"text": " Table 2: TED corpus main figures. K denotes thou- sands of elements. |S| stands for number of sentences,  |W | for number of running words, and |V | for vocab- ulary size.", "labels": [], "entities": []}, {"text": " Table 5: Effect of the infrequent n-gram recovery tech- nique for an unseen test set, when setting t = 10 and  number of phrases (parameters) of the models.", "labels": [], "entities": []}]}