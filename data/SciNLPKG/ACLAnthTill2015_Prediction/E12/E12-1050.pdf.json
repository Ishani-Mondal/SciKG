{"title": [{"text": "Feature-Rich Part-of-speech Tagging for Morphologically Complex Languages: Application to Bulgarian", "labels": [], "entities": [{"text": "Feature-Rich Part-of-speech Tagging", "start_pos": 0, "end_pos": 35, "type": "TASK", "confidence": 0.5591822862625122}, {"text": "Bulgarian", "start_pos": 90, "end_pos": 99, "type": "DATASET", "confidence": 0.7119834423065186}]}], "abstractContent": [{"text": "We present experiments with part-of-speech tagging for Bulgarian, a Slavic language with rich inflectional and deriva-tional morphology.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.6668863892555237}]}, {"text": "Unlike most previous work, which has used a small number of grammatical categories, we work with 680 morpho-syntactic tags.", "labels": [], "entities": []}, {"text": "We combine a large morphological lexicon with prior linguistic knowledge and guided learning from a POS-annotated corpus, achieving accuracy of 97.98%, which is a significant improvement over the state-of-the-art for Bulgarian.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 132, "end_pos": 140, "type": "METRIC", "confidence": 0.9996300935745239}]}], "introductionContent": [{"text": "Part-of-speech (POS) tagging is the task of assigning each of the words in a given piece of text a contextually suitable grammatical category.", "labels": [], "entities": [{"text": "Part-of-speech (POS) tagging", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.6238885223865509}]}, {"text": "This is not trivial since words can play different syntactic roles in different contexts, e.g., can is a noun in \"I opened a can of coke.\" but a verb in \"I can write.\"", "labels": [], "entities": []}, {"text": "Traditionally, linguists have classified English words into the following eight basic POS categories: noun, pronoun, adjective, verb, adverb, preposition, conjunction, and interjection; this list is often extended a bit, e.g., with determiners, particles, participles, etc., but the number of categories considered is rarely more than 15.", "labels": [], "entities": []}, {"text": "Computational linguistics works with a larger inventory of POS tags, e.g., the Penn Treebank () uses 48 tags: 36 for partof-speech, and 12 for punctuation and currency symbols.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 79, "end_pos": 92, "type": "DATASET", "confidence": 0.9929311871528625}]}, {"text": "This increase in the number of tags is partially due to finer granularity, e.g., there are special tags for determiners, particles, modal verbs, cardinal numbers, foreign words, existential there, etc., but also to the desire to encode morphological information as part of the tags.", "labels": [], "entities": []}, {"text": "For example, there are six tags for verbs in the Penn Treebank: VB (verb, base form; e.g., sing), VBD (verb, past tense; e.g., sang), VBG (verb, gerund or present participle; e.g., singing), VBN (verb, past participle; e.g., sung) VBP (verb, non3rd person singular present; e.g., sing), and VBZ (verb, 3rd person singular present; e.g., sings); these tags are morpho-syntactic in nature.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 49, "end_pos": 62, "type": "DATASET", "confidence": 0.9945928752422333}, {"text": "VBD", "start_pos": 98, "end_pos": 101, "type": "METRIC", "confidence": 0.5457703471183777}, {"text": "VBN", "start_pos": 191, "end_pos": 194, "type": "DATASET", "confidence": 0.7581589221954346}, {"text": "VBZ", "start_pos": 291, "end_pos": 294, "type": "METRIC", "confidence": 0.5242471694946289}]}, {"text": "Other corpora have used even larger tagsets, e.g., the Brown corpus) and the Lancaster-Oslo/Bergen (LOB) corpus) use 87 and 135 tags, respectively.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 55, "end_pos": 67, "type": "DATASET", "confidence": 0.9837276935577393}, {"text": "Lancaster-Oslo/Bergen (LOB) corpus", "start_pos": 77, "end_pos": 111, "type": "DATASET", "confidence": 0.7600923946925572}]}, {"text": "POS tagging poses major challenges for morphologically complex languages, whose tagsets encode a lot of additional morpho-syntactic features (for most of the basic POS categories), e.g., gender, number, person, etc.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.806616485118866}]}, {"text": "For example, the BulTreeBank ( ) for Bulgarian uses 680 tags, while the Prague Dependency Treebank for Czech has over 1,400 tags.", "labels": [], "entities": [{"text": "Prague Dependency Treebank", "start_pos": 72, "end_pos": 98, "type": "DATASET", "confidence": 0.9209402600924174}]}, {"text": "Below we present experiments with POS tagging for Bulgarian, which is an inflectional language with rich morphology.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 34, "end_pos": 45, "type": "TASK", "confidence": 0.8378062546253204}]}, {"text": "Unlike most previous work, which has used a reduced set of POS tags, we use all 680 tags in the BulTreeBank.", "labels": [], "entities": [{"text": "BulTreeBank", "start_pos": 96, "end_pos": 107, "type": "DATASET", "confidence": 0.9647443890571594}]}, {"text": "We combine prior linguistic knowledge and statistical learning, achieving accuracy comparable to that reported for state-of-the-art systems for English.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9995748400688171}]}, {"text": "The remainder of the paper is organized as follows: Section 2 provides an overview of related work, Section 3 describes Bulgarian morphology, Section 4 introduces our approach, Section 5 describes the datasets, Section 6 presents our experiments in detail, Section 7 discusses the results, Section 8 offers application-specific error analysis, and Section 9 concludes and points to some promising directions for future work.", "labels": [], "entities": [{"text": "application-specific error analysis", "start_pos": 307, "end_pos": 342, "type": "TASK", "confidence": 0.6107404331366221}]}], "datasetContent": [{"text": "State-of-the-art POS taggers for English typically build a lexicon containing all tags a word type has taken in the training dataset; this lexicon is then used to limit the set of possible tags that an input token can be assigned, i.e., it imposes a hard constraint on the possibilities explored by the POS tagger.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 17, "end_pos": 28, "type": "TASK", "confidence": 0.7918468713760376}]}, {"text": "For example, if can has only been tagged as a verb and as a noun in the training dataset, it will be only assigned those two tags attest time; other tags such as adjective, adverb and pronoun will not be considered.", "labels": [], "entities": []}, {"text": "Out-of-vocabulary words, i.e., those that were not seen in the training dataset, are constrained as well, e.g., to a small set of frequent open-class tags.", "labels": [], "entities": []}, {"text": "In our experiments, we used a morphological lexicon that is much larger than what could be built from the training corpus only: building a lexicon from the training corpus only is of limited utility since one can hardly expect to see in the training corpus all 52 synthetic forms a verb can possibly have.", "labels": [], "entities": []}, {"text": "Moreover, we did not use the tags listed in the lexicon as hard constraints (except in one of our baselines); instead, we experimented with a different, non-restrictive approach: we used the lexicon's predictions as features or soft constraints, i.e., as suggestions only, thus allowing each token to take any possible tag.", "labels": [], "entities": []}, {"text": "Note that for both known and out-of-vocabulary words we used all 680 tags rather than the 552 tags observed in the training dataset; we could afford to explore this huge search space thanks to the efficiency of the guided learning framework.", "labels": [], "entities": []}, {"text": "Allowing all 680 tags on training helped the model by exposing it to a larger set of negative examples.", "labels": [], "entities": []}, {"text": "We combined these lexicon features with standard features extracted from the training corpus.", "labels": [], "entities": []}, {"text": "We further experimented with the 70 contextual linguistic rules, using them (a) as soft and (b) as hard constraints.", "labels": [], "entities": []}, {"text": "Finally, we set four baselines: three that do not use the lexicon and one that does.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Note that only 552 of all 680  tag types were used in the training dataset, and  the development and the test datasets combined  contain a total of 128 new tag types that were not  seen in the training dataset. Moreover, 32% of the  word types in the development dataset and 31%  of those in the testing dataset do not occur in the  training dataset. Thus, data sparseness is an issue  at two levels: word-level and tag-level.", "labels": [], "entities": []}, {"text": " Table 2: Statistics about our datasets.", "labels": [], "entities": []}, {"text": " Table 3: Most-frequent-tag (MFT) baselines.", "labels": [], "entities": []}, {"text": " Table 4: Evaluation results on the test dataset. Line 1 shows the evaluation results when using features derived  from the text corpus only; these features are used by all systems in the table. Line 2 further uses the contextual  linguistic rules to limit the set of possible POS tags that can be predicted. Note that these rules (1) consult the  lexicon, and (2) always predict a single POS tag. Line 3 uses the POS tags listed in the lexicon as features, i.e.,  as soft suggestions only. Line 4 is like line 3, but the list of feature-tags proposed by the lexicon is filtered by  the contextual linguistic rules. Line 5 is like line 4, but the linguistic rules filtering is only applied at test time;  it is not done on training. Lines 6 and 7 are similar to lines 3 and 4, respectively, but here the linguistic rules  are further applied to limit the set of possible POS tags that can be predicted, i.e., the rules are used as hard  constraints. Finally, line 8 is like line 7, but here the beam size is increased to 3.", "labels": [], "entities": []}, {"text": " Table 5: Comparison to previous work for Bulgarian. The first four lines report evaluation results for various  standard POS tagging tools, which were retrained and evaluated on the BulTreeBank. The following lines report  token-level accuracy for previously published work, as compared to our own experiments using guided learning.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 122, "end_pos": 133, "type": "TASK", "confidence": 0.6708301901817322}, {"text": "BulTreeBank", "start_pos": 183, "end_pos": 194, "type": "DATASET", "confidence": 0.9507107734680176}, {"text": "accuracy", "start_pos": 236, "end_pos": 244, "type": "METRIC", "confidence": 0.9694982767105103}]}]}