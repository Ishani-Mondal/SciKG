{"title": [{"text": "Power-Law Distributions for Paraphrases Extracted from Bilingual Corpora", "labels": [], "entities": [{"text": "Paraphrases Extracted from Bilingual Corpora", "start_pos": 28, "end_pos": 72, "type": "TASK", "confidence": 0.8345641970634461}]}], "abstractContent": [{"text": "We describe a novel method that extracts paraphrases from a bitext, for both the source and target languages.", "labels": [], "entities": []}, {"text": "In order to reduce the search space, we decompose the phrase-table into sub-phrase-tables and construct separate clusters for source and target phrases.", "labels": [], "entities": []}, {"text": "We convert the clusters into graphs, add smoothing/syntactic-information-carrier vertices, and compute the similarity between phrases with a random walk-based measure, the commute time.", "labels": [], "entities": []}, {"text": "The resulting phrase-paraphrase probabilities are built upon the conversion of the commute times into artificial co-occurrence counts with a novel technique.", "labels": [], "entities": []}, {"text": "The co-occurrence count distribution belongs to the power-law family.", "labels": [], "entities": []}], "introductionContent": [{"text": "Paraphrase extraction has emerged as an important problem in NLP.", "labels": [], "entities": [{"text": "Paraphrase extraction", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9509713053703308}]}, {"text": "Currently, there exists an abundance of methods for extracting paraphrases from monolingual, comparable and bilingual corpora (; we focus on the latter and specifically on the phrase-table that is extracted from a bitext during the training stage of Statistical Machine Translation (SMT).", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 250, "end_pos": 287, "type": "TASK", "confidence": 0.8568185667196909}]}, {"text": "introduced the pivoting approach, which relies on a 2-step transition from a phrase, via its translations, to a paraphrase candidate.", "labels": [], "entities": []}, {"text": "By incorporating the syntactic structure of phrases), the quality of the paraphrases extracted with pivoting can be improved.", "labels": [], "entities": []}, {"text": "(henceforth KB) used a random walk framework to determine the similarity between phrases, which was shown to outperform pivoting with syntactic information, when multiple phrase-tables are used.", "labels": [], "entities": []}, {"text": "In SMT, extracted paraphrases with associated pivot-based) and cluster-based () probabilities have been found to improve the quality of translation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 3, "end_pos": 6, "type": "TASK", "confidence": 0.9920392036437988}]}, {"text": "Pivoting has also been employed in the extraction of syntactic paraphrases, which area mixture of phrases and nonterminals ().", "labels": [], "entities": []}, {"text": "We develop a method for extracting paraphrases from a bitext for both the source and target languages.", "labels": [], "entities": []}, {"text": "Emphasis is placed on the quality of the phrase-paraphrase probabilities as well as on providing a steppingstone for extracting syntactic paraphrases with equally reliable probabilities.", "labels": [], "entities": []}, {"text": "In line with previous work, our method depends on the connectivity of the phrase-table, but the resulting construction treats each side separately, which can potentially be benefited from additional monolingual data.", "labels": [], "entities": []}, {"text": "The initial problem in harvesting paraphrases from a phrase-table is the identification of the search space.", "labels": [], "entities": []}, {"text": "Previous work has relied on breadth first search from the query phrase with a depth of 2 (pivoting) and 6 (KB).", "labels": [], "entities": [{"text": "breadth", "start_pos": 28, "end_pos": 35, "type": "METRIC", "confidence": 0.971344530582428}]}, {"text": "The former can be too restrictive and the latter can lead to excessive noise contamination when taking shallow syntactic information features into account.", "labels": [], "entities": []}, {"text": "Instead, we choose to cluster the phrase-table into separate source and target clusters and in order to make this task computationally feasible, we decompose the phrase-table into sub-phrase-tables.", "labels": [], "entities": []}, {"text": "We propose a novel heuristic algorithm for the decomposition of the phrase-table (Section 2.1), and use a wellestablished co-clustering algorithm for clustering each sub-phrase-table (Section 2.2).", "labels": [], "entities": []}, {"text": "The underlying connectivity of the source and target clusters gives rise to a natural graph representation for each cluster (Section 3.1).", "labels": [], "entities": []}, {"text": "The vertices of the graphs consist of phrases and features with a dual smoothing/syntacticinformation-carrier role.", "labels": [], "entities": []}, {"text": "The latter allow (a) redistribution of the mass for phrases with no appropriate paraphrases and (b) the extraction of syntactic paraphrases.", "labels": [], "entities": []}, {"text": "The proximity among vertices of a graph is measured by means of a random walk distance measure, the commute time).", "labels": [], "entities": []}, {"text": "This measure is known to perform well in identifying similar words on the graph of WordNet () and a related measure, the hitting time is known to perform well in harvesting paraphrases on a graph constructed from multiple phrase-tables (KB).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 83, "end_pos": 90, "type": "DATASET", "confidence": 0.9711760878562927}]}, {"text": "Generally in NLP, power-law distributions are typically encountered in the collection of counts during the training stage.", "labels": [], "entities": []}, {"text": "The distances of Section 3.1 are converted into artificial co-occurrence counts with a novel technique (Section 3.2).", "labels": [], "entities": []}, {"text": "Although they need not be integers, the main challenge is the type of the underlying distributions; it should ideally emulate the resulting count distributions from the phrase extraction stage of a monolingual parallel corpus ().", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 169, "end_pos": 186, "type": "TASK", "confidence": 0.7127078771591187}]}, {"text": "These counts give rise to the desired probability distributions by means of relative frequencies.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}