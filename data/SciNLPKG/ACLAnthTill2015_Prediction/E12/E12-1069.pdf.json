{"title": [{"text": "Identifying Broken Plurals, Irregular Gender, and Rationality in Arabic Text", "labels": [], "entities": [{"text": "Identifying Broken Plurals", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8554581006368002}]}], "abstractContent": [{"text": "Arabic morphology is complex, partly because of its richness, and partly because of common irregular word forms, such as broken plurals (which resemble singular nouns), and nouns with irregular gender (feminine nouns that look masculine and vice versa).", "labels": [], "entities": []}, {"text": "In addition, Arabic morpho-syntactic agreement interacts with the lexical semantic feature of rationality, which has no morphological realization.", "labels": [], "entities": []}, {"text": "In this paper, we present a series of experiments on the automatic prediction of the latent linguistic features of functional gender and number, and rationality in Arabic.", "labels": [], "entities": []}, {"text": "We compare two techniques, using simple maximum likelihood (MLE) with back-off and a support vector machine based sequence tagger (Yamcha).", "labels": [], "entities": [{"text": "maximum likelihood (MLE)", "start_pos": 40, "end_pos": 64, "type": "METRIC", "confidence": 0.7504592955112457}]}, {"text": "We study a number of orthographic, morphological and syntactic learning features.", "labels": [], "entities": []}, {"text": "Our results show that the MLE technique is preferred for words seen in the training data, while the Yam-cha technique is optimal for unseen words, which are our real target.", "labels": [], "entities": [{"text": "MLE", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.6730297207832336}]}, {"text": "Furthermore, we show that for unseen words, morphological features help beyond orthographic features and that syntactic features help even more.", "labels": [], "entities": []}, {"text": "A combination of the two techniques improves overall performance even further.", "labels": [], "entities": []}], "introductionContent": [{"text": "Arabic morphology is complex, partly because of its richness, and partly because of its complex morpho-syntactic agreement rules which depend on functional features not necessarily expressed in word forms.", "labels": [], "entities": []}, {"text": "Particularly challenging are broken plurals (which resemble singular nouns), nouns with irregular gender (masculine nouns that look feminine and feminine nouns that look masculine), and the semantic feature of rationality, which has no morphological realization).", "labels": [], "entities": []}, {"text": "These features heavily participate in Arabic morpho-syntactic agreement.", "labels": [], "entities": []}, {"text": "show that without proper modeling, Arabic agreement cannot be accounted for in about a third of all noun-adjective pairs and a quarter of verb-subject pairs.", "labels": [], "entities": []}, {"text": "They also report that over half of all plurals in Arabic are irregular, 8% of nominals have irregular gender and almost half of all proper nouns and 5% of all nouns are rational.", "labels": [], "entities": []}, {"text": "In this paper, we present results on the task of automatic identification of functional gender, number and rationality of Arabic words in context.", "labels": [], "entities": []}, {"text": "We consider two supervised learning techniques: a simple maximum-likelihood model with back-off (MLE) and a support-vector-machinebased sequence tagger, Yamcha ().", "labels": [], "entities": []}, {"text": "We consider a large number of orthographic, morphological and syntactic learning features.", "labels": [], "entities": []}, {"text": "Our results show that the MLE technique is preferred for words seen in the training data, while the Yamcha technique is optimal for unseen words, which are our real target.", "labels": [], "entities": [{"text": "MLE", "start_pos": 26, "end_pos": 29, "type": "METRIC", "confidence": 0.5927188992500305}]}, {"text": "Furthermore, we show that for unseen words, morphological features help beyond orthographic features and that syntactic features help even more.", "labels": [], "entities": []}, {"text": "A combination of the two techniques improves overall performance even further.", "labels": [], "entities": []}, {"text": "This paper is structured as follows: Sections 2 and 3 present relevant linguistic facts and related work, respectively.", "labels": [], "entities": []}, {"text": "Section 4 presents the data collection we use and the metrics we target.", "labels": [], "entities": []}, {"text": "Section 5 discusses our approach.", "labels": [], "entities": []}, {"text": "And Section 6 presents our results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use the corpus of, which is based on the PATB.", "labels": [], "entities": [{"text": "PATB", "start_pos": 44, "end_pos": 48, "type": "DATASET", "confidence": 0.9204597473144531}]}, {"text": "The corpus contains around 16.6K sentences and over 400K tokens.", "labels": [], "entities": []}, {"text": "We use the train/development/test splits of.", "labels": [], "entities": []}, {"text": "We train on a quarter of the training set and classify words in sequence.", "labels": [], "entities": []}, {"text": "We only use a portion of the training data to increase the percentage of words unseen in training.", "labels": [], "entities": []}, {"text": "We also compare to using all of the training data in Section 6.7.", "labels": [], "entities": [{"text": "Section 6.7", "start_pos": 53, "end_pos": 64, "type": "DATASET", "confidence": 0.8787357807159424}]}, {"text": "Our data is gold tokenized; however, all of the features we use are predicted using MADA) following the work of.", "labels": [], "entities": [{"text": "MADA", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.8866397142410278}]}, {"text": "Words whose tags are unknown in the training set are excluded from the evaluation, but not training.", "labels": [], "entities": []}, {"text": "In terms of ambiguity, the percentage of word types with ambiguous gender, number and rationality in the train set is 1.35%, 0.79%, and 4.8% respectively.", "labels": [], "entities": []}, {"text": "These percentages are consistent with how we perform on these features, with number being the easiest and rationality the hardest.", "labels": [], "entities": []}, {"text": "The first set of experiments uses the orthographic features.", "labels": [], "entities": []}, {"text": "The MLE system with the word only feature (W1) is effectively our baseline.", "labels": [], "entities": []}, {"text": "It does surprisingly well for seen cases.", "labels": [], "entities": []}, {"text": "In fact it is the highest performer across all experiments in this paper for seen cases.", "labels": [], "entities": []}, {"text": "For unseen cases, it produces a miserable and expected low score of 21.0% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9988969564437866}]}, {"text": "The addition of the ngram features (W2) improves statistically significantly over W1 for unseen cases, but it is indistinguishable for seen cases.", "labels": [], "entities": []}, {"text": "The Yamcha system shows the same difference in results between W1 and W2.", "labels": [], "entities": []}, {"text": "Across the two sets of features, the MLE system consistently outperforms Yamcha in the case of seen words, while Yamcha does better for unseen words.", "labels": [], "entities": []}, {"text": "This can be explained by the fact that the MLE system matches only on the word form and if the word is unseen, it backs off to the most common value across all words.", "labels": [], "entities": [{"text": "MLE", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.7533300518989563}]}, {"text": "Moreover, Yamcha uses some limited context information that allows it to generalize for unseen words.", "labels": [], "entities": []}, {"text": "Among the target features, number is the easiest to predict, while rationality is the hardest.", "labels": [], "entities": []}, {"text": "Individual Morphological Features In this set of experiments, we use our best system from the previous set, W2, and add individual morphological features to it.", "labels": [], "entities": []}, {"text": "We organize these features in three sub-groups: (i) form-based features (F), (ii) lemma and LMM, and (iii) the five POS tag sets.", "labels": [], "entities": []}, {"text": "The F, Lemma and LMM improve over the baseline in terms of unseen words for both MLE and Yamcha techniques.", "labels": [], "entities": [{"text": "F", "start_pos": 4, "end_pos": 5, "type": "METRIC", "confidence": 0.9904168844223022}, {"text": "Lemma", "start_pos": 7, "end_pos": 12, "type": "METRIC", "confidence": 0.9379842281341553}, {"text": "LMM", "start_pos": 17, "end_pos": 20, "type": "METRIC", "confidence": 0.9678566455841064}]}, {"text": "However, for seen words, these systems do worse than or equal to the baseline when the MLE technique is used.", "labels": [], "entities": []}, {"text": "The MLE system in these cases tries to match the word and its morphological features as a single unit and if such a combination is not seen, it backs off to the morphological feature which is more general.", "labels": [], "entities": []}, {"text": "Since we are using predicted data, prediction errors could be the reason behind this decrease inaccuracy for seen words.", "labels": [], "entities": []}, {"text": "Among these systems, W2+F is the best for both Yamcha and MLE except for rationality which is expected since there are no form-based features for rationality.", "labels": [], "entities": []}, {"text": "In this set of experiments, Yamcha consistently outperforms MLE when it comes to unseen words, but for seen words, MLE does better almost always.", "labels": [], "entities": [{"text": "MLE", "start_pos": 115, "end_pos": 118, "type": "METRIC", "confidence": 0.7416676878929138}]}, {"text": "LMM overall does better than Lemma.", "labels": [], "entities": [{"text": "LMM", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.5878922343254089}, {"text": "Lemma", "start_pos": 29, "end_pos": 34, "type": "METRIC", "confidence": 0.9323797821998596}]}, {"text": "This is reasonable given that LMM is easier to predict; although LMM is more ambiguous.", "labels": [], "entities": [{"text": "LMM", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.8256288766860962}, {"text": "LMM", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.6685052514076233}]}, {"text": "As for the POS tag sets, looking at the MLE results, CATIB-EX is the best performer for seen words, and BW-is the best for unseen.", "labels": [], "entities": [{"text": "MLE", "start_pos": 40, "end_pos": 43, "type": "METRIC", "confidence": 0.883411705493927}, {"text": "CATIB-EX", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.850239634513855}, {"text": "BW-is", "start_pos": 104, "end_pos": 109, "type": "METRIC", "confidence": 0.9884018301963806}]}, {"text": "CATIB-6 is a general POS tag set and since the MLE technique is very strict in its matching process (an exact match or no match), using a general key to match on adds a lot of ambiguity.", "labels": [], "entities": [{"text": "CATIB-6", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8474876284599304}]}, {"text": "With Yamcha, BW and BW-are the best among all POS.", "labels": [], "entities": [{"text": "BW", "start_pos": 13, "end_pos": 15, "type": "METRIC", "confidence": 0.9778452515602112}, {"text": "BW-are", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.9895148277282715}]}, {"text": "Yamcha is still doing consistently better in terms of unseen words.", "labels": [], "entities": []}, {"text": "The best two systems from both Yamcha and MLE are used as the basic systems for the next subset of experiments where we combine the morphological features.", "labels": [], "entities": [{"text": "MLE", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.5121796131134033}]}, {"text": "Combined Morphological Features Until this point, all experiments using the two techniques are similar.", "labels": [], "entities": []}, {"text": "In this subset, MLE explores the effect of using the CATIB-EX and BW-with other morphological features.", "labels": [], "entities": [{"text": "MLE", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.843016505241394}, {"text": "BW-with", "start_pos": 66, "end_pos": 73, "type": "METRIC", "confidence": 0.8189462423324585}]}, {"text": "And Yamcha explores the effect of using BW-and BW with other morphological features.", "labels": [], "entities": [{"text": "BW-and BW", "start_pos": 40, "end_pos": 49, "type": "DATASET", "confidence": 0.4605080783367157}]}, {"text": "Again, Yamcha is still doing consistently better in terms of unseen words, but when it comes to seen words, MLE performs better.", "labels": [], "entities": [{"text": "MLE", "start_pos": 108, "end_pos": 111, "type": "METRIC", "confidence": 0.7724251747131348}]}, {"text": "For seen words, our best results come from MLE using CATIB-EX and LMM.", "labels": [], "entities": [{"text": "MLE", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.82346111536026}]}, {"text": "For unseen words, our best results come from Yamcha with the BW-tag and the form-based features seen unseen seen unseen seen unseen seen unseen W2 seen unseen seen unseen seen unseen seen unseen +CATIB-EX 99.", "labels": [], "entities": [{"text": "BW-tag", "start_pos": 61, "end_pos": 67, "type": "METRIC", "confidence": 0.8212676644325256}, {"text": "CATIB-EX", "start_pos": 196, "end_pos": 204, "type": "METRIC", "confidence": 0.7688045501708984}]}, {"text": "for both gender and number.", "labels": [], "entities": []}, {"text": "For rationality, the best features to use with Yamcha are BW, LMM and form-based features.", "labels": [], "entities": [{"text": "BW", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.8851161599159241}]}, {"text": "The lemma seems to actually hurt when predicting gender and number.", "labels": [], "entities": []}, {"text": "This can be explained by the fact that gender and number features are often properties of the word form and not of the lemma.", "labels": [], "entities": []}, {"text": "This is different for rationality, which is a property of the lemma and therefore, we expect the lemma to help.", "labels": [], "entities": []}, {"text": "The fact that the predicted BW set helps is not consistent with previous work by.", "labels": [], "entities": [{"text": "BW set", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9547063708305359}]}, {"text": "In that effort, BW helps parsing only in the gold condition.", "labels": [], "entities": [{"text": "BW", "start_pos": 16, "end_pos": 18, "type": "METRIC", "confidence": 0.7924133539199829}, {"text": "parsing", "start_pos": 25, "end_pos": 32, "type": "TASK", "confidence": 0.9909276962280273}]}, {"text": "BW prediction accuracy is low because it includes case endings.", "labels": [], "entities": [{"text": "BW prediction", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.7580441832542419}, {"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.954169750213623}]}, {"text": "We postulate that perhaps in our task, which is far more limited than general parsing, errors in case prediction may not matter too much.", "labels": [], "entities": [{"text": "case prediction", "start_pos": 97, "end_pos": 112, "type": "TASK", "confidence": 0.8133577406406403}]}, {"text": "The more complex tag set may actually help establish good local agreement sequences (even if incorrect casewise), which is relevant to the target features.", "labels": [], "entities": []}, {"text": "This set of experiments adds syntactic features to the experiments in set II.", "labels": [], "entities": []}, {"text": "We add syntax to the systems that uses Yamcha only since it is not obvious how to add syntactic information to the MLE system.", "labels": [], "entities": []}, {"text": "Syntax improves the prediction accuracy for unseen words but not for seen words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9795071482658386}]}, {"text": "In Yamcha, we can argue that the +/-2 word window allows some form of shallow syntax modeling, which is why Yamcha is doing better from the start.", "labels": [], "entities": []}, {"text": "But the longer distance features are helping even more, perhaps because they capture agreement relations.", "labels": [], "entities": []}, {"text": "The overall best system for unseen words is W2+BW+LMM+F+SYN, except for number, where W2+BW-+F+SYN is slightly better.", "labels": [], "entities": []}, {"text": "In terms of G+N+R scores, W2+BW+LMM+F+SYN is statistically significantly better than all other systems in this set for seen and unseen words, except for unseen words with W2+BW+F+SYN.", "labels": [], "entities": [{"text": "G+N+R scores", "start_pos": 12, "end_pos": 24, "type": "METRIC", "confidence": 0.6379909714063009}]}, {"text": "W2+BW+LMM+F+SYN is also statistically significantly better than its non-syntactic variant for both seen and unseen words.", "labels": [], "entities": [{"text": "BW+LMM+F+SYN", "start_pos": 3, "end_pos": 15, "type": "METRIC", "confidence": 0.6533736629145486}]}, {"text": "The prediction accuracy for seen words is still not as good as the MLE systems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9676373600959778}]}, {"text": "We use the predicted gender, number and rationality features that we get from training on the full train set in a dependency syntactic parsing experiment.", "labels": [], "entities": [{"text": "dependency syntactic parsing", "start_pos": 114, "end_pos": 142, "type": "TASK", "confidence": 0.7070500453313192}]}, {"text": "The parsing feature set we use is the best performing feature set described in, which used an earlier unpublished version of our MLE model.", "labels": [], "entities": []}, {"text": "The parser we use is the EasyFirst Parser (.", "labels": [], "entities": []}, {"text": "More details on this parsing experiment is in.", "labels": [], "entities": []}, {"text": "The functional gender and number features increase the labeled attachment score by 0.4% absolute over a comparable model that uses the formbased gender and number features.", "labels": [], "entities": [{"text": "labeled attachment score", "start_pos": 55, "end_pos": 79, "type": "METRIC", "confidence": 0.6830878754456838}]}, {"text": "Rationality on the other hand does not help much.", "labels": [], "entities": [{"text": "Rationality", "start_pos": 0, "end_pos": 11, "type": "METRIC", "confidence": 0.5150944590568542}]}, {"text": "One possible reason for this is the lower quality of the predicted rationality feature compared to the other features.", "labels": [], "entities": []}, {"text": "Another possible reason is that the rationality feature is not utilized optimally in the parser.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Experiment Set I: Baselines and simple orthographic features. W1 is the word only. W2 is the word  with additional 1-gram and 2-gram prefix and suffix features. All numbers are accuracy percentages.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 187, "end_pos": 195, "type": "METRIC", "confidence": 0.9990053772926331}]}, {"text": " Table 2: Experiment Set II.a: Morphological features: (i) form-based gender and number, (ii) lemma and LMM  (undiacritized lemma) and (iii) a variety of POS tag sets. For each subset, the best performers are bolded.", "labels": [], "entities": [{"text": "LMM", "start_pos": 104, "end_pos": 107, "type": "METRIC", "confidence": 0.9286729693412781}]}, {"text": " Table 3: Experiment Set II.b: Combining different morphological features.", "labels": [], "entities": []}, {"text": " Table 4: Experiment Set III: Syntactic features.", "labels": [], "entities": []}, {"text": " Table 5: Results on blind test.  Scores for  All/Seen/Unseen are shown for the G+N+R condition.  We compare the MLE word baseline, with the best  Yamcha system with and without syntactic features  and the combined system.", "labels": [], "entities": []}]}