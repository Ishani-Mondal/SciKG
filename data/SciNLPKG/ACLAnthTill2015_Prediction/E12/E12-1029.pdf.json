{"title": [{"text": "Bootstrapped Training of Event Extraction Classifiers", "labels": [], "entities": [{"text": "Bootstrapped Training of Event Extraction Classifiers", "start_pos": 0, "end_pos": 53, "type": "TASK", "confidence": 0.5410838077465693}]}], "abstractContent": [{"text": "Most event extraction systems are trained with supervised learning and rely on a collection of annotated documents.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 5, "end_pos": 21, "type": "TASK", "confidence": 0.8216177523136139}]}, {"text": "Due to the domain-specificity of this task, event extraction systems must be retrained with new annotated data for each domain.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 44, "end_pos": 60, "type": "TASK", "confidence": 0.7863560020923615}]}, {"text": "In this paper, we propose a bootstrapping solution for event role filler extraction that requires minimal human supervision.", "labels": [], "entities": [{"text": "event role filler extraction", "start_pos": 55, "end_pos": 83, "type": "TASK", "confidence": 0.8163488209247589}]}, {"text": "We aim to rapidly train a state-of-the-art event extraction system using a small set of \"seed nouns\" for each event role, a collection of relevant (in-domain) and irrelevant (out-of-domain) texts, and a semantic dictionary.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 43, "end_pos": 59, "type": "TASK", "confidence": 0.7452683746814728}]}, {"text": "The experimental results show that the bootstrapped system outperforms previous weakly supervised event extraction systems on the MUC-4 data set, and achieves performance levels comparable to supervised training with 700 manually annotated documents.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 98, "end_pos": 114, "type": "TASK", "confidence": 0.7553402185440063}, {"text": "MUC-4 data set", "start_pos": 130, "end_pos": 144, "type": "DATASET", "confidence": 0.9714972575505575}]}], "introductionContent": [{"text": "Event extraction systems process stories about domain-relevant events and identify the role fillers of each event.", "labels": [], "entities": [{"text": "Event extraction", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7761889100074768}]}, {"text": "A key challenge for event extraction is that recognizing role fillers is inherently contextual.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.8763717710971832}]}, {"text": "For example, a PERSON can be a perpetrator or a victim in different contexts (e.g., \"John Smith assassinated the mayor\" vs. \"John Smith was assassinated\").", "labels": [], "entities": []}, {"text": "Similarly, any COM-PANY can bean acquirer or an acquiree depending on the context.", "labels": [], "entities": []}, {"text": "Many supervised learning techniques have been used to create event extraction systems using gold standard \"answer key\" event templates for training (e.g.,).", "labels": [], "entities": [{"text": "event extraction", "start_pos": 61, "end_pos": 77, "type": "TASK", "confidence": 0.7538776397705078}]}, {"text": "However, manually generating answer keys for event extraction is time-consuming and tedious.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 45, "end_pos": 61, "type": "TASK", "confidence": 0.7735562026500702}]}, {"text": "And more importantly, event extraction annotations are highly domain-specific, so new annotations must be obtained for each domain.", "labels": [], "entities": [{"text": "event extraction annotations", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.8265435099601746}]}, {"text": "The goal of our research is to use bootstrapping techniques to automatically train a state-ofthe-art event extraction system without humangenerated answer key templates.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 101, "end_pos": 117, "type": "TASK", "confidence": 0.7444449365139008}]}, {"text": "The focus of our work is the TIER event extraction model, which is a multi-layered architecture for event extraction ().", "labels": [], "entities": [{"text": "TIER event extraction", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.6992557247479757}, {"text": "event extraction", "start_pos": 100, "end_pos": 116, "type": "TASK", "confidence": 0.7304913848638535}]}, {"text": "TIER's innovation over previous techniques is the use of four different classifiers that analyze a document at increasing levels of granularity.", "labels": [], "entities": [{"text": "TIER", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.699747622013092}]}, {"text": "TIER progressively zooms in on event information using a pipeline of classifiers that perform document-level classification, sentence classification, and noun phrase classification.", "labels": [], "entities": [{"text": "TIER", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8133383989334106}, {"text": "document-level classification", "start_pos": 94, "end_pos": 123, "type": "TASK", "confidence": 0.6871669590473175}, {"text": "sentence classification", "start_pos": 125, "end_pos": 148, "type": "TASK", "confidence": 0.7326692044734955}, {"text": "noun phrase classification", "start_pos": 154, "end_pos": 180, "type": "TASK", "confidence": 0.717533012231191}]}, {"text": "TIER outperformed previous event extraction systems on the MUC-4 data set, but relied heavily on a large collection of 1,300 documents coupled with answer key templates to train its four classifiers.", "labels": [], "entities": [{"text": "TIER", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.4968477189540863}, {"text": "event extraction", "start_pos": 27, "end_pos": 43, "type": "TASK", "confidence": 0.7378254681825638}, {"text": "MUC-4 data set", "start_pos": 59, "end_pos": 73, "type": "DATASET", "confidence": 0.9362728397051493}]}, {"text": "In this paper, we present a bootstrapping solution that exploits a large unannotated corpus for training by using role-identifying nouns as seed terms.", "labels": [], "entities": []}, {"text": "Phillips and Riloff observed that some nouns, by definition, refer to entities or objects that play a specific role in an event.", "labels": [], "entities": []}, {"text": "For example, \"assassin\", \"sniper\", and \"hitman\" refer to people who play the role of PERPETRATOR in a criminal event.", "labels": [], "entities": [{"text": "PERPETRATOR", "start_pos": 85, "end_pos": 96, "type": "METRIC", "confidence": 0.9751896858215332}]}, {"text": "Similarly, \"victim\", \"casualty\", and \"fatality\" refer to people who play the role of VICTIM, by virtue of their lexical semantics.", "labels": [], "entities": [{"text": "VICTIM", "start_pos": 85, "end_pos": 91, "type": "TASK", "confidence": 0.8486733436584473}]}, {"text": "Phillips and Riloff called these words role-identifying nouns and used them to learn extraction patterns.", "labels": [], "entities": [{"text": "learn extraction patterns", "start_pos": 79, "end_pos": 104, "type": "TASK", "confidence": 0.763816257317861}]}, {"text": "Our research also uses role-identifying nouns to learn extraction patterns, but the role-identifying nouns and patterns are then used to create training data for event extraction classifiers.", "labels": [], "entities": [{"text": "learn extraction patterns", "start_pos": 49, "end_pos": 74, "type": "TASK", "confidence": 0.7199547092119852}, {"text": "event extraction classifiers", "start_pos": 162, "end_pos": 190, "type": "TASK", "confidence": 0.7905870974063873}]}, {"text": "Each classifier is then selftrained in a bootstrapping loop.", "labels": [], "entities": []}, {"text": "Our weakly supervised training procedure requires a small set of \"seed nouns\" for each event role, and a collection of relevant (in-domain) and irrelevant (out-of-domain) texts.", "labels": [], "entities": []}, {"text": "No answer key templates or annotated texts are needed.", "labels": [], "entities": []}, {"text": "The seed nouns are used to automatically generate a set of role-identifying patterns, and then the nouns, patterns, and a semantic dictionary are used to label training instances.", "labels": [], "entities": []}, {"text": "We also propagate the event role labels across coreferent noun phrases within a document to produce additional training instances.", "labels": [], "entities": []}, {"text": "The automatically labeled texts are used to train three components of TIER: its two types of sentence classifiers and its noun phrase classifiers.", "labels": [], "entities": [{"text": "TIER", "start_pos": 70, "end_pos": 74, "type": "DATASET", "confidence": 0.5671424269676208}, {"text": "noun phrase classifiers", "start_pos": 122, "end_pos": 145, "type": "TASK", "confidence": 0.6306362946828207}]}, {"text": "To create TIER's fourth component, its document genre classifier, we apply heuristics to the output of the sentence classifiers.", "labels": [], "entities": [{"text": "document genre classifier", "start_pos": 39, "end_pos": 64, "type": "TASK", "confidence": 0.6264512538909912}]}, {"text": "We present experimental results on the MUC-4 data set, which is a standard benchmark for event extraction research.", "labels": [], "entities": [{"text": "MUC-4 data set", "start_pos": 39, "end_pos": 53, "type": "DATASET", "confidence": 0.9508895476659139}, {"text": "event extraction", "start_pos": 89, "end_pos": 105, "type": "TASK", "confidence": 0.8563748300075531}]}, {"text": "Our results show that the bootstrapped system, TIER lite , outperforms previous weakly supervised event extraction systems and achieves performance levels comparable to supervised training with 700 manually annotated documents.", "labels": [], "entities": [{"text": "TIER", "start_pos": 47, "end_pos": 51, "type": "METRIC", "confidence": 0.7989769577980042}, {"text": "event extraction", "start_pos": 98, "end_pos": 114, "type": "TASK", "confidence": 0.7466985583305359}]}], "datasetContent": [{"text": "In this section, we evaluate our bootstrapped system, TIER lite , on the MUC-4 event extraction data set.", "labels": [], "entities": [{"text": "TIER", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.9547107219696045}, {"text": "MUC-4 event extraction data set", "start_pos": 73, "end_pos": 104, "type": "DATASET", "confidence": 0.8603691458702087}]}, {"text": "First, we describe the IE task, the data set, and the weakly supervised baseline systems that we use for comparison.", "labels": [], "entities": [{"text": "IE task", "start_pos": 23, "end_pos": 30, "type": "TASK", "confidence": 0.8935017883777618}]}, {"text": "Then we present the results of our fully bootstrapped system TIER lite , the weakly supervised baseline systems, and two fully supervised event extraction systems, TIER and GLACIER.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 138, "end_pos": 154, "type": "TASK", "confidence": 0.7324773967266083}, {"text": "TIER", "start_pos": 164, "end_pos": 168, "type": "METRIC", "confidence": 0.6783743500709534}, {"text": "GLACIER", "start_pos": 173, "end_pos": 180, "type": "METRIC", "confidence": 0.9638010263442993}]}, {"text": "In addition, we analyze the performance of TIER lite using different configurations to assess the impact of its components.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: # of Role Fillers in the MUC-4 Test Set", "labels": [], "entities": [{"text": "Role Fillers", "start_pos": 15, "end_pos": 27, "type": "TASK", "confidence": 0.7344216406345367}, {"text": "MUC-4 Test Set", "start_pos": 35, "end_pos": 49, "type": "DATASET", "confidence": 0.9515474041302999}]}, {"text": " Table 2: Role-Identifying Seed Nouns", "labels": [], "entities": [{"text": "Role-Identifying Seed Nouns", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.7633398771286011}]}, {"text": " Table 3: # of Automatically Labeled NPs", "labels": [], "entities": []}, {"text": " Table 4: Performance of the Bootstrapped Event Extraction System (Precision/Recall/F-score)", "labels": [], "entities": [{"text": "Bootstrapped Event Extraction", "start_pos": 29, "end_pos": 58, "type": "TASK", "confidence": 0.5678750475247701}, {"text": "Precision/Recall/", "start_pos": 67, "end_pos": 84, "type": "METRIC", "confidence": 0.7589782476425171}, {"text": "F-score", "start_pos": 84, "end_pos": 91, "type": "METRIC", "confidence": 0.5952135920524597}]}, {"text": " Table 5: Evaluation of Bootstrapped Noun Phrase Classifiers (Precision/Recall/F-score)", "labels": [], "entities": [{"text": "Precision/Recall", "start_pos": 62, "end_pos": 78, "type": "METRIC", "confidence": 0.7495277921358744}, {"text": "F-score", "start_pos": 79, "end_pos": 86, "type": "METRIC", "confidence": 0.55477374792099}]}]}