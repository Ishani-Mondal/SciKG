{"title": [{"text": "Unsupervised Detection of Downward-Entailing Operators By Maximizing Classification Certainty", "labels": [], "entities": [{"text": "Maximizing Classification Certainty", "start_pos": 58, "end_pos": 93, "type": "TASK", "confidence": 0.770415206750234}]}], "abstractContent": [{"text": "We propose an unsupervised, iterative method for detecting downward-entailing operators (DEOs), which are important for deducing entailment relations between sentences.", "labels": [], "entities": []}, {"text": "Like the distillation algorithm of Danescu-Niculescu-Mizil et al.", "labels": [], "entities": []}, {"text": "(2009), the initialization of our method depends on the correlation between DEOs and negative polarity items (NPIs).", "labels": [], "entities": []}, {"text": "However, our method trusts the initialization more and aggressively separates likely DEOs from spurious distractors and other words, unlike distillation , which we show to be equivalent to one iteration of EM prior re-estimation.", "labels": [], "entities": []}, {"text": "Our method is also amenable to a bootstrap-ping method that co-learns DEOs and NPIs, and achieves the best results in identifying DEOs in two corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "Reasoning about text has been a long-standing challenge in NLP, and there has been considerable debate both on what constitutes inference and what techniques should be used to support inference.", "labels": [], "entities": []}, {"text": "One task involving inference that has recently received much attention is that of recognizing textual entailment (RTE), in which the goal is to determine whether a hypothesis sentence can be entailed from apiece of source text, for example).", "labels": [], "entities": [{"text": "recognizing textual entailment (RTE)", "start_pos": 82, "end_pos": 118, "type": "TASK", "confidence": 0.8415982822577158}]}, {"text": "An important consideration in RTE is whether a sentence or context produces an entailment relation for events that area superset or subset of the original sentence.", "labels": [], "entities": [{"text": "RTE", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.9902721047401428}]}, {"text": "By default, contexts are upward-entailing, allowing reasoning from a set of events to a superset of events as seen in.", "labels": [], "entities": []}, {"text": "In the scope of a downward-entailing operator (DEO), however, this entailment relation is reversed, such as in the scope of the classical DEO not (2).", "labels": [], "entities": []}, {"text": "There are also operators which are neither upward-nor downward entailing, such as the expression exactly three (3).", "labels": [], "entities": []}, {"text": "(1) She sang in French.", "labels": [], "entities": []}, {"text": "(upward-entailing) proposed the first computational methods for detecting DEOs from a corpus.", "labels": [], "entities": [{"text": "detecting DEOs from a corpus", "start_pos": 64, "end_pos": 92, "type": "TASK", "confidence": 0.8341074466705323}]}, {"text": "They proposed two unsupervised algorithms which rely on the correlation between DEOs and negative polarity items (NPIs), which by the definition of must appear in the context of DEOs.", "labels": [], "entities": []}, {"text": "An example of an NPI is yet, as in the sentence This project is not complete yet.", "labels": [], "entities": []}, {"text": "The first baseline method proposed by DLD09 simply calculates a ratio of the relative frequencies of a word in NPI contexts versus in a general corpus, and the second is a distillation method which appears to refine the baseline ratios using a task-specific heuristic.", "labels": [], "entities": []}, {"text": "Danescu-Niculescu-Mizil and Lee (2010) (henceforth DL10) extend this approach to Romanian, where a comprehensive list of NPIs is not available, by proposing a bootstrapping approach to co-learn DEOs and NPIs.", "labels": [], "entities": []}, {"text": "DLD09 are to be commended for having identified a crucial component of inference that nevertheless lends itself to a classification-based ap-proach, as we will show.", "labels": [], "entities": [{"text": "DLD09", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9417173266410828}]}, {"text": "However, as noted by DL10, the performance of the distillation method is mixed across languages and in the semi-supervised bootstrapping setting, and there is no mathematical grounding of the heuristic to explain why it works and whether the approach can be refined or extended.", "labels": [], "entities": []}, {"text": "This paper supplies the missing mathematical basis for distillation and shows that, while its intentions are fundamentally sound, the formulation of distillation neglects an important requirement that the method not be easily distracted by other word co-occurrences in NPI contexts.", "labels": [], "entities": []}, {"text": "We call our alternative certainty, which uses an unusual posterior classification confidence score (based on the max function) to favour single, definite assignments of DEOhood within every NPI context.", "labels": [], "entities": [{"text": "certainty", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9838802218437195}]}, {"text": "DLD09 actually speculated on the use of max as an alternative, but within the context of an EM-like optimization procedure that throws away its initial parameter settings too willingly.", "labels": [], "entities": [{"text": "DLD09", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9634013175964355}]}, {"text": "Certainty iteratively and directly boosts the scores of the currently bestranked DEO candidates relative to the alternatives in a Na\u00a8\u0131veNa\u00a8\u0131ve Bayes model, which thus pays more respect to the initial weights, constructively building on top of what the model already knows.", "labels": [], "entities": []}, {"text": "This method proves to perform better on two corpora than distillation, and is more amenable to the colearning of NPIs and DEOs.", "labels": [], "entities": []}, {"text": "In fact, the best results are obtained by co-learning the NPIs and DEOs in conjunction with our method.", "labels": [], "entities": [{"text": "DEOs", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.8623810410499573}]}], "datasetContent": [{"text": "We evaluate the performance of these methods on the BLLIP corpus (\u223c30M words) and the AFP portion of the Gigaword corpus (\u223c338M words).", "labels": [], "entities": [{"text": "BLLIP corpus", "start_pos": 52, "end_pos": 64, "type": "DATASET", "confidence": 0.7640990912914276}, {"text": "Gigaword corpus", "start_pos": 105, "end_pos": 120, "type": "DATASET", "confidence": 0.9486674070358276}]}, {"text": "Following DLD09, we define an NPI context to be all the words to the left of an NPI, up to the closest comma or semi-colon, and removed NPI contexts which contain the most common DEOs like not.", "labels": [], "entities": []}, {"text": "We further removed all empty NPI contexts or those which only contain other punctuation.", "labels": [], "entities": []}, {"text": "After this filtering, there were 26696 NPI contexts in BLLIP and 211041 NPI contexts in AFP, using the same list of 26 NPIs defined by DLD09.", "labels": [], "entities": [{"text": "BLLIP", "start_pos": 55, "end_pos": 60, "type": "DATASET", "confidence": 0.8147037029266357}, {"text": "AFP", "start_pos": 88, "end_pos": 91, "type": "DATASET", "confidence": 0.9245447516441345}]}, {"text": "We first define an automatic measure of performance that is common in information retrieval.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 70, "end_pos": 91, "type": "TASK", "confidence": 0.7875628769397736}]}, {"text": "We use average precision to quantify how well a system separates DEOs from non-DEOs.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.7691689133644104}]}, {"text": "Given a list of known DEOs, G, and non-DEOs, the average precision of a ranked list of items, X, is defined by the following equation: where P (X 1...k ) is the precision of the first k items and 1(x k \u2208 G) is an indicator function which is 1 if x is in the gold standard list of DEOs and 0 otherwise.", "labels": [], "entities": [{"text": "precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.940871000289917}, {"text": "precision", "start_pos": 161, "end_pos": 170, "type": "METRIC", "confidence": 0.9902487397193909}]}, {"text": "DLD09 simply evaluated the top 150 output DEO candidates by their systems, and qualitatively judged the precision of the top-k candidates at various values of k up to 150.", "labels": [], "entities": [{"text": "DLD09", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.9617898464202881}, {"text": "precision", "start_pos": 104, "end_pos": 113, "type": "METRIC", "confidence": 0.9982098340988159}]}, {"text": "Average precision can be seen as a generalization of this evaluation procedure that is sensitive to the ranking of DEOs and non-DEOs.", "labels": [], "entities": [{"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9544815421104431}]}, {"text": "For development purposes, we use the list of 150 annotations by DLD09.", "labels": [], "entities": [{"text": "DLD09", "start_pos": 64, "end_pos": 69, "type": "DATASET", "confidence": 0.9568358659744263}]}, {"text": "Of these, 90 were DEOs, 30 were not, and 30 were classified as \"other\" (they were either difficult to classify, or were other types of non-veridical operators like comparatives or conditionals).", "labels": [], "entities": []}, {"text": "We discarded the 30 \"other\" items and ignored all items not in the remaining 120 items when evaluating a ranked list of DEO candidates.", "labels": [], "entities": []}, {"text": "We call this measure AP 120 . In addition, we annotated DEO candidates from the top-150 rankings produced by our certainty-absolve, abstain, banish, bereft, boycott, caution, clear, coy, delay, denial, desist, devoid, disavow, discount, dispel, disqualify, downplay, exempt, exonerate, foil, forbid, forego, impossible, inconceivable, irrespective, limit, mitigate, nip, noone, omit, outweigh, precondition, pre-empt, prerequisite, refute, remove 5 , repel, repulse, scarcely, scotch, scuttle, seldom, sensitive, shy, sidestep, snuff, thwart, waive, zero-tolerance based heuristic on BLLIP and also by the distillation and heuristic methods on AFP, in order to better evaluate the final output of the methods.", "labels": [], "entities": [{"text": "AP", "start_pos": 21, "end_pos": 23, "type": "METRIC", "confidence": 0.6693417429924011}, {"text": "certainty-absolve, abstain, banish, bereft, boycott, caution, clear, coy, delay, denial, desist, devoid, disavow, discount, dispel, disqualify, downplay, exempt, exonerate, foil, forbid, forego, impossible, inconceivable, irrespective, limit, mitigate, nip, noone, omit, outweigh, precondition, pre-empt, prerequisite, refute, remove 5 , repel, repulse, scarcely, scotch, scuttle, seldom, sensitive, shy, sidestep, snuff, thwart, waive", "start_pos": 113, "end_pos": 548, "type": "Description", "confidence": 0.8601424135267735}, {"text": "AFP", "start_pos": 644, "end_pos": 647, "type": "DATASET", "confidence": 0.9654801487922668}]}, {"text": "This produced an additional 68 DEOs (narrowly defined)), 58 non-DEOs, and 31 \"other\" items 4 . Adding the DEOs and non-DEOs we found to the 120 items from above, we have an expanded list of 246 items to rank, and a corresponding average precision which we call AP 246 . We employ the frequency cut-offs used by DLD09 for sparsity reasons.", "labels": [], "entities": [{"text": "precision", "start_pos": 237, "end_pos": 246, "type": "METRIC", "confidence": 0.9458397030830383}, {"text": "AP", "start_pos": 261, "end_pos": 263, "type": "METRIC", "confidence": 0.9485679864883423}]}, {"text": "A word-type must appear at least 10 times in an NPI context and 150 times in the corpus overall to be considered.", "labels": [], "entities": []}, {"text": "We treat BLLIP as a development corpus and use AP 120 on AFP to determine the number of iterations to run our heuristic (5 iterations for BLLIP and 13 iterations for AFP).", "labels": [], "entities": [{"text": "AP 120", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9780663251876831}, {"text": "AFP", "start_pos": 57, "end_pos": 60, "type": "DATASET", "confidence": 0.9163718223571777}, {"text": "AFP", "start_pos": 166, "end_pos": 169, "type": "DATASET", "confidence": 0.8558688163757324}]}, {"text": "We run EM/distillation for one iteration in development and testing, because more iterations hurt performance, as explained in Section 3.", "labels": [], "entities": []}, {"text": "We first report the AP 120 results of our experiments on the BLLIP corpus second column).", "labels": [], "entities": [{"text": "AP", "start_pos": 20, "end_pos": 22, "type": "METRIC", "confidence": 0.7693443894386292}, {"text": "BLLIP corpus second column", "start_pos": 61, "end_pos": 87, "type": "DATASET", "confidence": 0.9218845963478088}]}, {"text": "Our method outperforms both EM/distillation and the baseline method.", "labels": [], "entities": []}, {"text": "These results are replicated on the final test set from AFP using the full set of annotations AP 246 (Table 1 third column).", "labels": [], "entities": [{"text": "AFP", "start_pos": 56, "end_pos": 59, "type": "DATASET", "confidence": 0.5502274036407471}, {"text": "AP 246", "start_pos": 94, "end_pos": 100, "type": "DATASET", "confidence": 0.7178884744644165}]}, {"text": "Note that the scores are lower when using all the annotations because there are more non-DEOs relative to DEOs in this list, making the ranking task more challenging.", "labels": [], "entities": []}, {"text": "A better understanding of the algorithms can The complete list will be made publicly available.", "labels": [], "entities": []}, {"text": "We disagree with DLD09 that remove is not downwardentailing; e.g., be obtained by examining the data likelihood and the classification certainty at each iteration of the algorithms ().", "labels": [], "entities": [{"text": "DLD09", "start_pos": 17, "end_pos": 22, "type": "DATASET", "confidence": 0.9204834699630737}]}, {"text": "Whereas EM/distillation maximizes the former expression, the certaintybased heuristic method actually decreases data likelihood for the first couple of iterations before increasing it again.", "labels": [], "entities": []}, {"text": "In terms of classification certainty, EM/distillation converges to a lower classification certainty score compared to our heuristic method.", "labels": [], "entities": [{"text": "EM", "start_pos": 38, "end_pos": 40, "type": "METRIC", "confidence": 0.803059995174408}, {"text": "classification certainty score", "start_pos": 75, "end_pos": 105, "type": "METRIC", "confidence": 0.7048386832078298}]}, {"text": "Thus, our method better captures the assumption of one DEO per NPI context.", "labels": [], "entities": [{"text": "DEO", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.9252919554710388}]}], "tableCaptions": [{"text": " Table 1: Average precision results on the BLLIP and  AFP corpora.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9856578707695007}, {"text": "BLLIP", "start_pos": 43, "end_pos": 48, "type": "METRIC", "confidence": 0.5014519691467285}, {"text": "AFP corpora", "start_pos": 54, "end_pos": 65, "type": "DATASET", "confidence": 0.7915059924125671}]}]}