{"title": [{"text": "Efficient Parsing with Linear Context-Free Rewriting Systems", "labels": [], "entities": []}], "abstractContent": [{"text": "Previous work on treebank parsing with discontinuous constituents using Linear Context-Free Rewriting systems (LCFRS) has been limited to sentences of up to 30 words, for reasons of computational complexity.", "labels": [], "entities": [{"text": "treebank parsing", "start_pos": 17, "end_pos": 33, "type": "TASK", "confidence": 0.6185268461704254}]}, {"text": "There have been some results on binarizing an LCFRS in a manner that minimizes parsing complexity, but the present work shows that parsing long sentences with such an optimally binarized grammar remains infeasible.", "labels": [], "entities": [{"text": "parsing long sentences", "start_pos": 131, "end_pos": 153, "type": "TASK", "confidence": 0.8863904277483622}]}, {"text": "Instead, we introduce a technique which removes this length restriction , while maintaining a respectable accuracy.", "labels": [], "entities": [{"text": "length restriction", "start_pos": 53, "end_pos": 71, "type": "METRIC", "confidence": 0.9692448079586029}, {"text": "accuracy", "start_pos": 106, "end_pos": 114, "type": "METRIC", "confidence": 0.9986079335212708}]}, {"text": "The resulting parser has been applied to a discontinuous treebank with favorable results.", "labels": [], "entities": []}], "introductionContent": [{"text": "Discontinuity in constituent structures (cf. figure) is important fora variety of reasons.", "labels": [], "entities": []}, {"text": "For one, it allows a tight correspondence between syntax and semantics by letting constituent structure express argument structure ().", "labels": [], "entities": []}, {"text": "Other reasons are phenomena such as extraposition and word-order freedom, which arguably require discontinuous annotations to be treated systematically in phrase-structures).", "labels": [], "entities": []}, {"text": "Empirical investigations demonstrate that discontinuity is present in non-negligible amounts: around 30% of sentences contain discontinuity in two German treebanks.", "labels": [], "entities": [{"text": "discontinuity", "start_pos": 42, "end_pos": 55, "type": "METRIC", "confidence": 0.948550820350647}, {"text": "German treebanks", "start_pos": 147, "end_pos": 163, "type": "DATASET", "confidence": 0.8543411195278168}]}, {"text": "Recent work on treebank parsing with discontinuous constituents shows that it is feasible to directly parse discontinuous constituency annotations, as given in the German Negra (Skut et al., 1997) and Tiger () corpora, or those that can be extracted from traces such as in the Penn treebank) annotation.", "labels": [], "entities": [{"text": "German Negra (Skut et al., 1997)", "start_pos": 164, "end_pos": 196, "type": "DATASET", "confidence": 0.9380671580632528}, {"text": "Penn treebank) annotation", "start_pos": 277, "end_pos": 302, "type": "DATASET", "confidence": 0.9767556935548782}]}, {"text": "However, the computational complexity is such that until now, the length of sentences needed to be restricted.", "labels": [], "entities": []}, {"text": "In the case of and Evang and Kallmeyer (2011) the limit was 25 words. and van manage to parse up to 30 words with heuristics and optimizations, but no further.", "labels": [], "entities": []}, {"text": "Algorithms have been suggested to binarize the grammars in such away as to minimize parsing complexity, but the current paper shows that these techniques are not sufficient to parse longer sentences.", "labels": [], "entities": []}, {"text": "Instead, this work presents a novel form of coarse-to-fine parsing which does alleviate this limitation.", "labels": [], "entities": []}, {"text": "The rest of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "First, we introduce linear context-free rewriting systems (LCFRS).", "labels": [], "entities": []}, {"text": "Next, we discuss and evaluate binarization strategies for LCFRS.", "labels": [], "entities": []}, {"text": "Third, we present a technique for approximating an LCFRS by a PCFG in a coarse-to-fine framework.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 62, "end_pos": 66, "type": "DATASET", "confidence": 0.9230282306671143}]}, {"text": "Lastly, we evaluate this technique on a large corpus without the usual length restrictions.", "labels": [], "entities": []}], "datasetContent": [{"text": "As data we use version 2 of the Negra () treebank, with the common training, devel- opment and test splits.", "labels": [], "entities": [{"text": "Negra () treebank", "start_pos": 32, "end_pos": 49, "type": "DATASET", "confidence": 0.9002203543980917}]}, {"text": "Following common practice, punctuation, which is left out of the phrase-structure in Negra, is reattached to the nearest constituent.", "labels": [], "entities": []}, {"text": "In the course of experiments it was discovered that the heuristic method for punctuation attachment used in previous work (e.g.,), as implemented in rparse, 3 introduces additional discontinuity.", "labels": [], "entities": [{"text": "punctuation attachment", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.7709521353244781}]}, {"text": "We applied a slightly different heuristic: punctuation is attached to the highest constituent that contains a neighbor to its right.", "labels": [], "entities": []}, {"text": "The result is that punctuation can be introduced into the phrase-structure without any additional discontinuity, and thus without artificially inflating the fan-out and complexity of grammars read off from the treebank.", "labels": [], "entities": []}, {"text": "This new heuristic provides a significant improvement: instead of a fan-out of 9 and a parsing complexity of 19, we obtain values of 4 and 9 respectively.", "labels": [], "entities": []}, {"text": "The parser is presented with the gold part-ofspeech tags from the corpus.", "labels": [], "entities": []}, {"text": "For reasons of efficiency we restrict sentences to 25 words (including punctuation) in this experiment: NEGRA-25.", "labels": [], "entities": [{"text": "NEGRA-25", "start_pos": 104, "end_pos": 112, "type": "DATASET", "confidence": 0.8840235471725464}]}, {"text": "A grammar was read off from the training part of NEGRA-25, and sentences of up to 25 words in the development set were parsed using the resulting PLCFRS, using the different binarization schemes.", "labels": [], "entities": [{"text": "NEGRA-25", "start_pos": 49, "end_pos": 57, "type": "DATASET", "confidence": 0.8747024536132812}]}, {"text": "First with a right-branching, right-to-left binarization, and second with the minimal binarization according to parsing complexity and fan- out.", "labels": [], "entities": []}, {"text": "The last two binarizations are head-driven and Markovized-the first straightforwardly from left-to-right, the latter optimized for minimal parsing complexity.", "labels": [], "entities": []}, {"text": "With Markovization we are forced to add a level of parent annotation to tame the increase in productivity caused by h = 1.", "labels": [], "entities": []}, {"text": "The distribution of parsing complexity (measured with eq.", "labels": [], "entities": [{"text": "parsing", "start_pos": 20, "end_pos": 27, "type": "TASK", "confidence": 0.9699466824531555}]}, {"text": "6) in the grammars with different binarization strategies is shown in figure 5 and 6.", "labels": [], "entities": []}, {"text": "Although the optimal binarizations do seem to have some effect on the distribution of parsing complexities, it remains to be seen whether this can be cashed out as a performance improvement in practice.", "labels": [], "entities": [{"text": "parsing complexities", "start_pos": 86, "end_pos": 106, "type": "TASK", "confidence": 0.9201773405075073}]}, {"text": "To this end, we also parse using the binarized grammars.", "labels": [], "entities": []}, {"text": "In this work we binarize and parse with disco-dop introduced in van In this experiment we report scores of the (exact) Viterbi derivations of a treebank PLCFRS; cf. table 1 for the results.", "labels": [], "entities": []}, {"text": "Times represent CPU time (single core); accuracy is given with a generalization of PARSEVAL to discontinuous structures, described in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9996153116226196}, {"text": "PARSEVAL", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.8895130753517151}]}, {"text": "Instead of using Maier's implementation of discontinuous F 1 scores in rparse, we employ a variant that ignores (a) punctuation, and (b) the root node of each tree.", "labels": [], "entities": []}, {"text": "This makes our evaluation incomparable to previous results on discontinuous parsing, but brings it inline with common practice on the Wall street journal benchmark.", "labels": [], "entities": [{"text": "Wall street journal benchmark", "start_pos": 134, "end_pos": 163, "type": "DATASET", "confidence": 0.9684439152479172}]}, {"text": "Note that this change yields scores about 2 or 3 percentage points lower than those of rparse.", "labels": [], "entities": []}, {"text": "Despite the fact that obtaining optimal bina-rizations is exponential and NPhard (Crescenzi et al., 2011), they can be computed relatively quickly on this data set.", "labels": [], "entities": [{"text": "NPhard", "start_pos": 74, "end_pos": 80, "type": "METRIC", "confidence": 0.9536778926849365}]}, {"text": "Importantly, in the first case there is no improvement on fan-out or parsing complexity, while in the head-driven case there is a minimal improvement because of a single production with parsing complexity 15 without optimal binarization.", "labels": [], "entities": [{"text": "parsing", "start_pos": 69, "end_pos": 76, "type": "TASK", "confidence": 0.9535693526268005}]}, {"text": "On the other hand, the optimal binarizations might still have a significant effect on the average case complexity, rather than the worst-case complexities.", "labels": [], "entities": []}, {"text": "Indeed, in both cases parsing with the optimal grammar is faster; in the first case, however, when the time for binarization is considered as well, this advantage mostly disappears.", "labels": [], "entities": []}, {"text": "The difference in F 1 scores might relate to the efficacy of Markovization in the binarizations.", "labels": [], "entities": [{"text": "F 1 scores", "start_pos": 18, "end_pos": 28, "type": "METRIC", "confidence": 0.9750078519185384}]}, {"text": "It should be noted that it makes little theoretical sense to 'Markovize' a binarization when it is not a left-to-right or right-to-left binarization, because with an optimal binarization the non-terminals of a constituent are introduced in an arbitrary order.", "labels": [], "entities": []}, {"text": "More importantly, in our experiments, these techniques of optimal binarizations did not scale to longer sentences.", "labels": [], "entities": []}, {"text": "While it is possible to obtain an optimal binarization of the unrestricted Negra corpus, parsing long sentences with the resulting grammar remains infeasible.", "labels": [], "entities": [{"text": "Negra corpus", "start_pos": 75, "end_pos": 87, "type": "DATASET", "confidence": 0.8445712924003601}, {"text": "parsing long sentences", "start_pos": 89, "end_pos": 111, "type": "TASK", "confidence": 0.860505998134613}]}, {"text": "Therefore we need to look at other techniques for parsing longer sentences.", "labels": [], "entities": [{"text": "parsing longer sentences", "start_pos": 50, "end_pos": 74, "type": "TASK", "confidence": 0.8917394081751505}]}, {"text": "We will stick with the straightforward head-driven, head-outward binarization strategy, despite this being a computationally sub-optimal binarization.", "labels": [], "entities": []}, {"text": "One technique for efficient parsing of LCFRS is the use of context-summary estimates, as part of a best-first parsing algorithm.", "labels": [], "entities": [{"text": "parsing of LCFRS", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.7681539058685303}]}, {"text": "This allowed Maier (2010) to parse sentences of up to 30 words.", "labels": [], "entities": []}, {"text": "However, the calculation of these estimates is not feasible for longer sentences and large grammars).", "labels": [], "entities": []}, {"text": "Another strategy is to perform an online approximation of the sentence to be parsed, after which parsing with the LCFRS can be pruned effectively.", "labels": [], "entities": [{"text": "LCFRS", "start_pos": 114, "end_pos": 119, "type": "DATASET", "confidence": 0.851514995098114}]}, {"text": "This is the strategy that will be explored in the current work.", "labels": [], "entities": []}, {"text": "We We first establish the viability of the CFG-CTF method on NEGRA-25, with a head-driven v = 1, h = 2 binarization, and reporting again the scores of the exact Viterbi derivations from a treebank PLCFRS versus a PCFG using our transformations.", "labels": [], "entities": [{"text": "NEGRA-25", "start_pos": 61, "end_pos": 69, "type": "DATASET", "confidence": 0.9668144583702087}]}, {"text": "compares the parsing times of LCFRS with and without the new CFG-CTF method.", "labels": [], "entities": [{"text": "parsing", "start_pos": 13, "end_pos": 20, "type": "TASK", "confidence": 0.9812421798706055}, {"text": "CFG-CTF", "start_pos": 61, "end_pos": 68, "type": "DATASET", "confidence": 0.9100762009620667}]}, {"text": "The graph shows a steep incline for parsing with LCFRS directly, which makes it infeasible to parse longer sentences, while the CFG-CTF method is faster for    from the PCFG chart.", "labels": [], "entities": [{"text": "parsing", "start_pos": 36, "end_pos": 43, "type": "TASK", "confidence": 0.971846878528595}, {"text": "CFG-CTF", "start_pos": 128, "end_pos": 135, "type": "DATASET", "confidence": 0.8780907988548279}, {"text": "PCFG chart", "start_pos": 169, "end_pos": 179, "type": "DATASET", "confidence": 0.9659907519817352}]}, {"text": "The result shows that the PLCFRS gives a slight improvement over the split--pcfg, which accords with the observation that the latter makes stronger independence assumptions in the case of discontinuity.", "labels": [], "entities": [{"text": "PLCFRS", "start_pos": 26, "end_pos": 32, "type": "DATASET", "confidence": 0.6250741481781006}]}, {"text": "In the next experiments we turn to an allfragments grammar encoded in a PLCFRS using reduction, to realize a (discontinuous) Data-Oriented Parsing (DOP;) model-which goes by the name of Disco-DOP.", "labels": [], "entities": []}, {"text": "This provides an effective yet conceptually simple method to weaken the independence assumptions of treebank grammars.", "labels": [], "entities": []}, {"text": "gives statistics on the grammars, including the parsing complexities.", "labels": [], "entities": []}, {"text": "The fine grammar has a parsing complexity of 9, which means that parsing with this grammar has complexity O(|w| 9 ).", "labels": [], "entities": []}, {"text": "We use the same parameters as van, except that unlike van Cranenburgh et al., we can use v = 1, h = 1 Markovization, in order to obtain a higher coverage.", "labels": [], "entities": []}, {"text": "The DOP grammar is added as a third stage in the coarse-to-fine pipeline.", "labels": [], "entities": []}, {"text": "This gave slightly better results than substituting the the DOP grammar for the PLCFRS stage.", "labels": [], "entities": []}, {"text": "Parsing with NEGRA-40 took about 11 hours and 4 GB of memory.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9649032354354858}, {"text": "NEGRA-40", "start_pos": 13, "end_pos": 21, "type": "DATASET", "confidence": 0.9425560235977173}]}, {"text": "The same model from NEGRA-40 can also be used to parse the full development set, without length restrictions, establishing that the CFG-CTF method effectively eliminates any limitation of length for parsing with LCFRS.", "labels": [], "entities": [{"text": "NEGRA-40", "start_pos": 20, "end_pos": 28, "type": "DATASET", "confidence": 0.9086509943008423}, {"text": "CFG-CTF", "start_pos": 132, "end_pos": 139, "type": "DATASET", "confidence": 0.8746969699859619}, {"text": "parsing", "start_pos": 199, "end_pos": 206, "type": "TASK", "confidence": 0.973432719707489}]}], "tableCaptions": [{"text": " Table 1: The effect of binarization strategies on parsing efficiency, with sentences from the development section of", "labels": [], "entities": [{"text": "parsing", "start_pos": 51, "end_pos": 58, "type": "TASK", "confidence": 0.9761152863502502}]}, {"text": " Table 2: Some statistics on the coarse and fine grammars read off from NEGRA-40.", "labels": [], "entities": [{"text": "NEGRA-40", "start_pos": 72, "end_pos": 80, "type": "DATASET", "confidence": 0.9393107891082764}]}, {"text": " Table 3: Previous work on discontinuous parsing of Negra.", "labels": [], "entities": [{"text": "discontinuous parsing of Negra", "start_pos": 27, "end_pos": 57, "type": "TASK", "confidence": 0.5827236399054527}]}, {"text": " Table 4: Results on NEGRA-25 and NEGRA-40 with the CFG-CTF method. NB: As explained in section 3.3, these  F 1 scores are incomparable to the results in table 3; for comparison, the F 1 score for Disco-DOP on the dev set  \u2264 40 is 77.13 % using that evaluation scheme.", "labels": [], "entities": [{"text": "NEGRA-25", "start_pos": 21, "end_pos": 29, "type": "DATASET", "confidence": 0.8982042670249939}, {"text": "NEGRA-40", "start_pos": 34, "end_pos": 42, "type": "DATASET", "confidence": 0.9226585626602173}, {"text": "CFG-CTF", "start_pos": 52, "end_pos": 59, "type": "DATASET", "confidence": 0.9563442468643188}, {"text": "NB", "start_pos": 68, "end_pos": 70, "type": "METRIC", "confidence": 0.6909576058387756}, {"text": "F 1 scores", "start_pos": 108, "end_pos": 118, "type": "METRIC", "confidence": 0.9286979834238688}, {"text": "F 1 score", "start_pos": 183, "end_pos": 192, "type": "METRIC", "confidence": 0.9678422212600708}]}]}