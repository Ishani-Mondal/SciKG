{"title": [{"text": "Combining Tree Structures, Flat Features and Patterns for Biomedical Relation Extraction", "labels": [], "entities": [{"text": "Biomedical Relation Extraction", "start_pos": 58, "end_pos": 88, "type": "TASK", "confidence": 0.8704606493314108}]}], "abstractContent": [{"text": "Kernel based methods dominate the current trend for various relation extraction tasks including protein-protein interaction (PPI) extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.7785351574420929}, {"text": "protein-protein interaction (PPI) extraction", "start_pos": 96, "end_pos": 140, "type": "TASK", "confidence": 0.6370066901048025}]}, {"text": "PPI information is critical in understanding biological processes.", "labels": [], "entities": []}, {"text": "Despite considerable efforts, previously reported PPI extraction results show that none of the approaches already known in the literature is consistently better than other approaches when evaluated on different benchmark PPI corpora.", "labels": [], "entities": [{"text": "PPI extraction", "start_pos": 50, "end_pos": 64, "type": "TASK", "confidence": 0.9520970582962036}]}, {"text": "In this paper, we propose a novel hybrid kernel that combines (auto-matically collected) dependency patterns, trigger words, negative cues, walk features and regular expression patterns along with tree kernel and shallow linguistic kernel.", "labels": [], "entities": []}, {"text": "The proposed kernel outperforms the exiting state-of-the-art approaches on the BioInfer corpus, the largest PPI benchmark corpus available.", "labels": [], "entities": [{"text": "BioInfer corpus", "start_pos": 79, "end_pos": 94, "type": "DATASET", "confidence": 0.9526937901973724}]}, {"text": "On the other four smaller benchmark corpora, it performs either better or almost as good as the existing approaches.", "labels": [], "entities": []}, {"text": "Moreover, empirical results show that the proposed hybrid kernel attains considerably higher precision than the existing approaches, which indicates its capability of learning more accurate models.", "labels": [], "entities": [{"text": "precision", "start_pos": 93, "end_pos": 102, "type": "METRIC", "confidence": 0.9986459612846375}]}, {"text": "This also demonstrates that the different types of information that we use are able to complement each other for relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 113, "end_pos": 132, "type": "TASK", "confidence": 0.8699071705341339}]}], "introductionContent": [{"text": "Kernel methods are considered the most effective techniques for various relation extraction (RE) tasks on both general (e.g. newspaper text) and specialized (e.g. biomedical text) domains.", "labels": [], "entities": [{"text": "relation extraction (RE) tasks", "start_pos": 72, "end_pos": 102, "type": "TASK", "confidence": 0.8646026899417242}]}, {"text": "In particular, as the importance of syntactic structures for deriving the relationships between entities in text has been growing, several graph and tree kernels have been designed and experimented.", "labels": [], "entities": []}, {"text": "Early RE approaches more or less fall in one of the following categories: (i) exploitation of statistics about co-occurrences of entities, (ii) usage of patterns and rules, and (iii) usage of flat features to train machine learning (ML) classifiers.", "labels": [], "entities": [{"text": "RE", "start_pos": 6, "end_pos": 8, "type": "TASK", "confidence": 0.9848052859306335}]}, {"text": "These approaches have been studied fora long period and have their own pros and cons.", "labels": [], "entities": []}, {"text": "Exploitation of co-occurrence statistics results in high recall but low precision, while rule or pattern based approaches can increase precision but suffer from low recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 57, "end_pos": 63, "type": "METRIC", "confidence": 0.9985995888710022}, {"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9990273714065552}, {"text": "precision", "start_pos": 135, "end_pos": 144, "type": "METRIC", "confidence": 0.9980411529541016}, {"text": "recall", "start_pos": 165, "end_pos": 171, "type": "METRIC", "confidence": 0.9957696199417114}]}, {"text": "Flat feature based ML approaches employ various kinds of linguistic, syntactic or contextual information and integrate them into the feature space.", "labels": [], "entities": []}, {"text": "They obtain relatively good results but are hindered by drawbacks of limited feature space and excessive feature engineering.", "labels": [], "entities": []}, {"text": "Kernel based approaches have become an attractive alternative solution, as they can exploit huge amount of features without an explicit representation.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew hybrid kernel for RE.", "labels": [], "entities": []}, {"text": "We apply the kernel to Protein-protein interaction (PPI) extraction, the most widely researched topic in biomedical relation extraction.", "labels": [], "entities": [{"text": "Protein-protein interaction (PPI) extraction", "start_pos": 23, "end_pos": 67, "type": "TASK", "confidence": 0.7433056831359863}, {"text": "biomedical relation extraction", "start_pos": 105, "end_pos": 135, "type": "TASK", "confidence": 0.6659006476402283}]}, {"text": "PPI 1 information is very critical in understanding biological processes.", "labels": [], "entities": []}, {"text": "Considerable progress has been made for this task.", "labels": [], "entities": []}, {"text": "Nevertheless, empirical results of previous studies show that none of the approaches already known in the literature is consistently better than other approaches when evaluated on different benchmark PPI corpora (see).", "labels": [], "entities": []}, {"text": "This demands further study and innovation of new approaches that are sensitive to the variations of complex linguistic constructions.", "labels": [], "entities": []}, {"text": "The proposed hybrid kernel is the composition of one tree kernel and two feature based kernels (one of them is already known in the literature and the other is proposed in this paper for the first time).", "labels": [], "entities": []}, {"text": "The novelty of the newly proposed feature based kernel is that it envisages to accommodate the advantages of pattern based approaches.", "labels": [], "entities": []}, {"text": "We propose anew feature based kernel (details in Section 4.1) by using syntactic dependency patterns, trigger words, negative cues, regular expression (henceforth, regex) patterns and walk features (i.e. e-walks and v-walks) 2 . 2. The syntactic dependency patterns are automatically collected from a type of dependency subgraph (we call it reduced graph, more details in Section 4.1.1) during runtime.", "labels": [], "entities": []}, {"text": "3. We only use the regex patterns, trigger words and negative cues mentioned in the literature ().", "labels": [], "entities": []}, {"text": "The objective is to verify whether we can exploit knowledge which is already known and used.", "labels": [], "entities": []}, {"text": "4. We propose a hybrid kernel by combining the proposed feature based kernel (outlined above) with the Shallow Linguistic (SL) kernel () and the Path-enclosed Tree (PET) kernel).", "labels": [], "entities": []}, {"text": "The aim of our work is to take advantage of different types of information (i.e., dependency patterns, regex patterns, trigger words, negative cues, syntactic dependencies among words and constituent parse trees) and their different representations (i.e. flat features, tree structures and graphs) which can complement each other to learn more accurate models.", "labels": [], "entities": []}, {"text": "The syntactic dependencies of the words of a sentence create a dependency graph.", "labels": [], "entities": []}, {"text": "A v-walk feature consists of (wordi \u2212 dependency typei,i+1 \u2212 wordi+1), and an ewalk feature is composed of (dependency typei\u22121,i \u2212 wordi \u2212 dependency typei,i+1).", "labels": [], "entities": []}, {"text": "Note that, in a dependency graph, the words are nodes while the dependency types are edges.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we briefly review previous work.", "labels": [], "entities": []}, {"text": "Section 3 lists the datasets.", "labels": [], "entities": []}, {"text": "Then, in Section 4, we define our proposed hybrid kernel and describe its individual component kernels.", "labels": [], "entities": []}, {"text": "Section 5 outlines the experimental settings.", "labels": [], "entities": []}, {"text": "Following that, empirical results are discussed in Section 6.", "labels": [], "entities": []}, {"text": "Finally, we conclude with a summary of our study as well as suggestions for further improvement of our approach.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have followed the same criteria commonly used for the PPI extraction tasks, i.e. abstractwise 10-fold cross validation on individual corpus and one-answer-per-occurrence criterion.", "labels": [], "entities": [{"text": "PPI extraction tasks", "start_pos": 57, "end_pos": 77, "type": "TASK", "confidence": 0.9400516351064047}]}, {"text": "In fact, we have used exactly the same (abstract-wise) fold splitting of the 5 benchmark (converted) corpora used by for benchmarking various kernel methods . The Charniak-Johnson reranking parser, along with a self-trained biomedical parsing model, has been used for tokenization, POS-tagging and parsing of the sentences.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 268, "end_pos": 280, "type": "TASK", "confidence": 0.9722896814346313}, {"text": "parsing of the sentences", "start_pos": 298, "end_pos": 322, "type": "TASK", "confidence": 0.8866789489984512}]}, {"text": "Before parsing the sentences, all the entities are blinded by assigning names as EntityX where X is the entity index.", "labels": [], "entities": []}, {"text": "In each example, the POS tags of the two candidate entities are changed to EntityX.", "labels": [], "entities": [{"text": "EntityX", "start_pos": 75, "end_pos": 82, "type": "DATASET", "confidence": 0.909693717956543}]}, {"text": "The parse trees produced by the Charniak-Johnson reranking parser are then processed by the Stanford parser ( to obtain syntactic dependencies according to the Stanford Typed Dependency format.", "labels": [], "entities": []}, {"text": "The Stanford parser often skips some syntactic dependencies in output.", "labels": [], "entities": []}, {"text": "We use the following two rules to add some of such dependencies: \u2022 If there is a \"conj and\" or \"conj or\" dependency between two words X and Y, then X should be dependent on any word Z on which Y is dependent and vice versa.", "labels": [], "entities": []}, {"text": "\u2022 If there are two verbs X and Y such that inside the corresponding sentence they have only the word \"and\" or \"or\" between them, then any word Z dependent on X should be also dependent on Y and vice versa.", "labels": [], "entities": []}, {"text": "Our system exploits SVM-LIGHT-TK 6).", "labels": [], "entities": []}, {"text": "We made minor changes in the toolkit to compute the proposed hybrid kernel.", "labels": [], "entities": []}, {"text": "The ratio of negative and positive examples has been used as the value of the costratio-factor parameter.", "labels": [], "entities": []}, {"text": "We have done parameter tuning following the approach described by", "labels": [], "entities": [{"text": "parameter tuning", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.7791353464126587}]}], "tableCaptions": [{"text": " Table 1: Basic statistics of the 5 benchmark PPI cor- pora.", "labels": [], "entities": []}, {"text": " Table 2: Results of the proposed TPWF feature based kernel on 5 benchmark PPI corpora before and after adding  features collected using dependency patterns, regex patterns, trigger words and negative cues to the walk features.  The TPWF kernel is a component of the new hybrid kernel.", "labels": [], "entities": []}, {"text": " Table 3: Results of the proposed hybrid kernel and its individual components. Pos. and Neg. refer to number  positive and negative relations respectively. PET refers to the path-enclosed tree kernel, SL refers to the shallow  linguistic kernel, and TPWF refers to the kernel computed using trigger, pattern, negative cue and walk features.", "labels": [], "entities": []}, {"text": " Table 4: Comparison of the results on the 5 benchmark PPI corpora. Pos. and Neg. refer to number positive and  negative relations respectively. The underlined numbers indicate the best results for the corresponding corpus  reported by any of the existing state-of-the-art approaches. The results of Bui et al. (2010) on LLL, HPRD50,  and IEPA are not reported since thy did not use all the positive and negative examples during cross validation.", "labels": [], "entities": [{"text": "IEPA", "start_pos": 339, "end_pos": 343, "type": "METRIC", "confidence": 0.8731049299240112}]}]}