{"title": [{"text": "Large-Margin Learning of Submodular Summarization Models", "labels": [], "entities": [{"text": "Submodular Summarization", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.5524844378232956}]}], "abstractContent": [{"text": "In this paper, we present a supervised learning approach to training submodu-lar scoring functions for extractive multi-document summarization.", "labels": [], "entities": [{"text": "extractive multi-document summarization", "start_pos": 103, "end_pos": 142, "type": "TASK", "confidence": 0.5543716649214426}]}, {"text": "By taking a structured prediction approach, we provide a large-margin method that directly optimizes a convex relaxation of the desired performance measure.", "labels": [], "entities": []}, {"text": "The learning method applies to all submodular summa-rization methods, and we demonstrate its effectiveness for both pairwise as well as coverage-based scoring functions on multiple datasets.", "labels": [], "entities": []}, {"text": "Compared to state-of-the-art functions that were tuned manually, our method significantly improves performance and enables high-fidelity models with number of parameters well beyond what could reasonably be tuned by hand.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic document summarization is the problem of constructing a short text describing the main points in a (set of) document(s).", "labels": [], "entities": [{"text": "Automatic document summarization", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.5842080215613047}]}, {"text": "Example applications range from generating short summaries of news articles, to presenting snippets for URLs in web-search.", "labels": [], "entities": [{"text": "generating short summaries of news articles", "start_pos": 32, "end_pos": 75, "type": "TASK", "confidence": 0.7265748977661133}]}, {"text": "In this paper we focus on extractive multi-document summarization, where the final summary is a subset of the sentences from multiple input documents.", "labels": [], "entities": [{"text": "extractive multi-document summarization", "start_pos": 26, "end_pos": 65, "type": "TASK", "confidence": 0.5335477491219839}]}, {"text": "In this way, extractive summarization avoids the hard problem of generating well-formed natural-language sentences, since only existing sentences from the input documents are presented as part of the summary.", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 13, "end_pos": 37, "type": "TASK", "confidence": 0.7222888767719269}]}, {"text": "A current state-of-the-art method for document summarization was recently proposed by, using a submodular scoring function based on inter-sentence similarity.", "labels": [], "entities": [{"text": "document summarization", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.697174072265625}]}, {"text": "On the one hand, this scoring function rewards summaries that are similar to many sentences in the original documents (i.e. promotes coverage).", "labels": [], "entities": []}, {"text": "On the other hand, it penalizes summaries that contain sentences that are similar to each other (i.e. discourages redundancy).", "labels": [], "entities": [{"text": "penalizes summaries", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.6258366405963898}]}, {"text": "While obtaining the exact summary that optimizes the objective is computationally hard, they show that a greedy algorithm is guaranteed to compute a good approximation.", "labels": [], "entities": []}, {"text": "However, their work does not address how to select a good inter-sentence similarity measure, leaving this problem as well as selecting an appropriate trade-off between coverage and redundancy to manual tuning.", "labels": [], "entities": [{"text": "coverage", "start_pos": 168, "end_pos": 176, "type": "METRIC", "confidence": 0.9592537879943848}]}, {"text": "To overcome this problem, we propose a supervised learning method that can learn both the similarity measure as well as the coverage/reduncancy trade-off from training data.", "labels": [], "entities": [{"text": "similarity measure", "start_pos": 90, "end_pos": 108, "type": "METRIC", "confidence": 0.9206076562404633}]}, {"text": "Furthermore, our learning algorithm is not limited to the model of, but applies to all monotone submodular summarization models.", "labels": [], "entities": []}, {"text": "Due to the diminishing-returns property of monotone submodular set functions and their computational tractability, this class of functions provides a rich space for designing summarization methods.", "labels": [], "entities": [{"text": "summarization", "start_pos": 175, "end_pos": 188, "type": "TASK", "confidence": 0.9739960432052612}]}, {"text": "To illustrate the generality of our approach, we also provide experiments fora coverage-based model originally developed for diversified information retrieval.", "labels": [], "entities": [{"text": "diversified information retrieval", "start_pos": 125, "end_pos": 158, "type": "TASK", "confidence": 0.6187432805697123}]}, {"text": "In general, our method learns a parameterized monotone submodular scoring function from supervised training data, and its implementation is available for download.", "labels": [], "entities": []}, {"text": "Given a set of documents and their summaries as training examples, we formulate the learning problem as a structured prediction problem and derive a maximummargin algorithm in the structural support vector machine (SVM) framework.", "labels": [], "entities": []}, {"text": "Note that, unlike other learning approaches, our method does not require a heuristic decomposition of the learning task into binary classification problems (, but directly optimizes a structured prediction.", "labels": [], "entities": []}, {"text": "This enables our algorithm to directly optimize the desired performance measure (e.g. ROUGE) during training.", "labels": [], "entities": [{"text": "ROUGE)", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.9748952090740204}]}, {"text": "Furthermore, our method is not limited to linear-chain dependencies like, but can learn any monotone submodular scoring function.", "labels": [], "entities": []}, {"text": "This ability to easily train summarization models makes it possible to efficiently tune models to various types of document collections.", "labels": [], "entities": [{"text": "summarization", "start_pos": 29, "end_pos": 42, "type": "TASK", "confidence": 0.959407389163971}]}, {"text": "In particular, we find that our learning method can reliably tune models with hundreds of parameters based on a training set of about 30 examples.", "labels": [], "entities": []}, {"text": "This increases the fidelity of models compared to their hand-tuned counterparts, showing significantly improved empirical performance.", "labels": [], "entities": []}, {"text": "We provide a detailed investigation into the sources of these improvements, identifying further directions for research.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we empirically evaluate the approach proposed in this paper.", "labels": [], "entities": []}, {"text": "Following, experiments were conducted on two different datasets (DUC '03 and '04).", "labels": [], "entities": [{"text": "DUC '03", "start_pos": 65, "end_pos": 72, "type": "DATASET", "confidence": 0.9444735844930013}]}, {"text": "These datasets contain document sets with four manual summaries for each set.", "labels": [], "entities": []}, {"text": "For each document set, we concatenated all the articles and split them into sentences using the tool provided with the '03 dataset.", "labels": [], "entities": [{"text": "'03 dataset", "start_pos": 119, "end_pos": 130, "type": "DATASET", "confidence": 0.7129575312137604}]}, {"text": "For the supervised setting we used 10 resamplings with a random 20/5/5 ('03) and 40/5/5 ('04) train/test/validation split.", "labels": [], "entities": []}, {"text": "We determined the best C value in (9) using the performance on each validation set and then report average performence over the corresponding test sets.", "labels": [], "entities": []}, {"text": "Baseline performance (the approach of) was computed using all 10 test sets as a single test set.", "labels": [], "entities": []}, {"text": "For all experiments and datasets, we used r = 0.3 in the greedy algorithm as recommended in for the '03 dataset.", "labels": [], "entities": [{"text": "'03 dataset", "start_pos": 100, "end_pos": 111, "type": "DATASET", "confidence": 0.6599527796109518}]}, {"text": "We find that changing r has only a small influence on performance.", "labels": [], "entities": []}, {"text": "The construction of features for learning is organized byword groups.", "labels": [], "entities": []}, {"text": "The most trivial group is simply all words (basic).", "labels": [], "entities": []}, {"text": "Considering the properties of the words themselves, we constructed several features from properties such as capitalized words, non-stop words and words of certain length (cap+stop+len).", "labels": [], "entities": []}, {"text": "We obtained another set of features from the most frequently occuring words in all the articles (minmax).", "labels": [], "entities": []}, {"text": "We also considered the position of a sentence (containing the word) in the article as another feature (location).", "labels": [], "entities": []}, {"text": "All those word groups can then be further refined by selecting different thresholds, weighting schemes (e.g. TFIDF) and forming binned variants of these features.", "labels": [], "entities": [{"text": "TFIDF", "start_pos": 109, "end_pos": 114, "type": "METRIC", "confidence": 0.8834021091461182}]}, {"text": "For the pairwise model we use cosine similarity between sentences using only words in a given word group during computation.", "labels": [], "entities": []}, {"text": "For the word coverage model we create separate features for covering words in different groups.", "labels": [], "entities": [{"text": "word coverage", "start_pos": 8, "end_pos": 21, "type": "TASK", "confidence": 0.7634777426719666}]}, {"text": "This gives us fairly comparable feature strength in both models.", "labels": [], "entities": []}, {"text": "The only further addition is the use of different word coverage levels in the coverage model.", "labels": [], "entities": []}, {"text": "First we consider how well does a sentence cover a word (e.g. a sentence with five instances of the same word might cover it better than another with only a single instance).", "labels": [], "entities": []}, {"text": "And secondly we look at how important it is to cover a word (e.g. if a word appears in a large fraction of sentences we might want to be sure to cover it).", "labels": [], "entities": []}, {"text": "Combining those two criteria using different thresholds we get a set of features for each word.", "labels": [], "entities": []}, {"text": "Our coverage features are motivated from the approach of.", "labels": [], "entities": []}, {"text": "In contrast, the hand-tuned pairwise baseline uses only TFIDF weighted cosine similarity between sentences using all words, following the approach in.", "labels": [], "entities": [{"text": "TFIDF weighted cosine similarity", "start_pos": 56, "end_pos": 88, "type": "METRIC", "confidence": 0.8782443404197693}]}, {"text": "The resulting summaries are evaluated using ROUGE version 1.5.5 (.", "labels": [], "entities": []}, {"text": "We selected the ROUGE-1 F measure because it was used by and because it is one of the commonly used performance scores in recent work.", "labels": [], "entities": [{"text": "ROUGE-1", "start_pos": 16, "end_pos": 23, "type": "METRIC", "confidence": 0.9953953623771667}, {"text": "F measure", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.8721101880073547}]}, {"text": "However, our learning method applies to other performance measures as well.", "labels": [], "entities": []}, {"text": "Note that we use the ROUGE-1 F measure both for the loss function during learning, as well as for the evaluation of the predicted summaries.", "labels": [], "entities": [{"text": "ROUGE-1 F measure", "start_pos": 21, "end_pos": 38, "type": "METRIC", "confidence": 0.88686203956604}]}], "tableCaptions": []}