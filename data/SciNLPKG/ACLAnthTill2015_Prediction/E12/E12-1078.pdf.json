{"title": [{"text": "To what extent does sentence-internal realisation reflect discourse context? A study on word order", "labels": [], "entities": [{"text": "word order", "start_pos": 88, "end_pos": 98, "type": "TASK", "confidence": 0.6998460739850998}]}], "abstractContent": [{"text": "We compare the impact of sentence-internal vs. sentence-external features on word order prediction in two generation settings: starting out from a discrimina-tive surface realisation ranking model for an LFG grammar of German, we enrich the feature set with lexical chain features from the discourse context which can be robustly detected and reflect rough grammatical correlates of notions from theoretical approaches to discourse coherence.", "labels": [], "entities": [{"text": "word order prediction", "start_pos": 77, "end_pos": 98, "type": "TASK", "confidence": 0.7227378090222677}]}, {"text": "Ina more controlled setting, we develop a constituent ordering classifier that is trained on a German treebank with gold corefer-ence annotation.", "labels": [], "entities": [{"text": "German treebank", "start_pos": 95, "end_pos": 110, "type": "DATASET", "confidence": 0.8472566306591034}]}, {"text": "Surprisingly, in both settings , the sentence-external features perform poorly compared to the sentence-internal ones, and do not improve over a baseline model capturing the syntactic functions of the constituents.", "labels": [], "entities": []}], "introductionContent": [{"text": "The task of surface realization, especially in a relatively free word order language like German, is only partially determined by hard syntactic constraints.", "labels": [], "entities": [{"text": "surface realization", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.7323235273361206}]}, {"text": "The space of alternative realizations that are strictly speaking grammatical is typically considerable.", "labels": [], "entities": []}, {"text": "Nevertheless, for any given choice of lexical items and prior discourse context, only a few realizations will come across as natural and will contribute to a coherent text.", "labels": [], "entities": []}, {"text": "Hence, any NLP application involving a non-trivial generation step is confronted with the issue of soft constraints on grammatical alternatives in one way or another.", "labels": [], "entities": []}, {"text": "There are countless approaches to modelling these soft constraints, taking into account their interaction with various aspects of the discourse context (givenness or salience of particular referents, prior mentioning of particular concepts).", "labels": [], "entities": []}, {"text": "Since so many factors are involved and there is further interaction with subtle semantic and pragmatic differentiations, lexical choice, stylistics and presumably processing factors, theoretical accounts making reliable predictions for real corpus examples have fora longtime proven elusive.", "labels": [], "entities": []}, {"text": "As for German, only quite recently, a number of corpus-based studies) have made some good progress towards a coherenceoriented account of at least the left edge of the German clause structure, the Vorfeld constituent.", "labels": [], "entities": []}, {"text": "What makes the technological application of theoretical insights even harder is that for most relevant factors, automatic recognition cannot be performed with high accuracy (e.g., a coreference accuracy in the 70's means there is a good deal of noise) and for the higher-level notions such as the information-structural focus, interannotator agreement on real corpus data tends to be much lower than for core-grammatical notions.", "labels": [], "entities": [{"text": "automatic recognition", "start_pos": 112, "end_pos": 133, "type": "TASK", "confidence": 0.6987076550722122}, {"text": "accuracy", "start_pos": 164, "end_pos": 172, "type": "METRIC", "confidence": 0.9822200536727905}, {"text": "agreement", "start_pos": 342, "end_pos": 351, "type": "METRIC", "confidence": 0.6920942068099976}]}, {"text": "On the other hand, many of the relevant discourse factors are reflected indirectly in properties of the sentence-internal material.", "labels": [], "entities": []}, {"text": "Most notably, knowing the shape of referring expressions narrows down many aspects of givenness and salience of its referent; pronominal realizations indicate givenness, and in German there are even two variants of the personal pronoun (er and der) for distinguishing salience.", "labels": [], "entities": []}, {"text": "So, if the generation task is set in such away that the actual lexical choice, including functional categories such as determiners, is fully fixed (which is of course not always the case), one can take advantage of these reflexes.", "labels": [], "entities": []}, {"text": "This explains in part the fairly high baseline performance of n-gram language models in the surface realization task.", "labels": [], "entities": [{"text": "surface realization task", "start_pos": 92, "end_pos": 116, "type": "TASK", "confidence": 0.8120250701904297}]}, {"text": "And the effect can indeed betaken much further: the discriminative training experiments of show how effective it is to systematically take advantage of asymmetry patterns in the morphosyntactic reflexes of the discourse notion of information status (i.e., using a feature set with well-chosen purely sentence-bound features).", "labels": [], "entities": []}, {"text": "These observations give rise to the question: in the light of the difficulty in obtaining reliable discourse information on the one hand and the effectiveness of exploiting the reflexes of discourse in the sentence-internal material on the other -can we nevertheless expect to gain something from adding sentence-external feature information?", "labels": [], "entities": []}, {"text": "We propose two scenarios for adressing this question: first, we choose an approximative access to context information and relations between discourse referents -lexical reiteration of head words, combined with information about their grammatical relation and topological positioning in prior sentences.", "labels": [], "entities": []}, {"text": "We apply these features in a rich sentence-internal surface realisation ranking model for German.", "labels": [], "entities": []}, {"text": "Secondly, we choose a more controlled scenario: we train a constituent ordering classifier based on a feature model that captures properties of discourse referents in terms of manually annotated coreference relations.", "labels": [], "entities": []}, {"text": "As we get the same effect in both setups -the sentenceexternal features do not improve over a baseline that captures basic morphosyntactic properties of the constituents -we conclude that sentenceinternal realisation is actually a relatively accurate predictor of discourse context, even more accurate than information that can be obtained from coreference and lexical chain relations.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this Section, we present an experiment that investigates sentence-external context in a surface realisation task.", "labels": [], "entities": []}, {"text": "The sentence-external context is represented in terms of lexical chain features and compared to sentence-internal models which are based on morphosyntactic features.", "labels": [], "entities": []}, {"text": "The experiment thus targets a generation scenario where no coreference information is available and aims at assessing whether relatively naive context information is also useful.", "labels": [], "entities": []}, {"text": "We now look at a simpler generation setup where we concentrate on the ordering of constituents in the German Vorfeld and Mittelfeld.", "labels": [], "entities": [{"text": "Vorfeld", "start_pos": 109, "end_pos": 116, "type": "DATASET", "confidence": 0.5563241243362427}, {"text": "Mittelfeld", "start_pos": 121, "end_pos": 131, "type": "DATASET", "confidence": 0.5718348622322083}]}, {"text": "This strategy has also been adopted in previous investigations of German word order: show that once the German Vorfeld is correctly chosen, the prediction accuracy for the Mittelfeld (the constituents following the finite verb) is in the 90s.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 155, "end_pos": 163, "type": "METRIC", "confidence": 0.771678626537323}]}, {"text": "In order to eliminate noise introduced from potentially heterogeneous chain features, we look at coreference features and, again, compare them to sentence-internal morphosyntactic features.", "labels": [], "entities": []}, {"text": "We target a generation scenario where coreference information is available.", "labels": [], "entities": [{"text": "coreference", "start_pos": 38, "end_pos": 49, "type": "TASK", "confidence": 0.9611882567405701}]}, {"text": "The aim is to establish an upper bound concerning the quality improvement for word order prediction by recurring to manual corefence annotation.", "labels": [], "entities": [{"text": "word order prediction", "start_pos": 78, "end_pos": 99, "type": "TASK", "confidence": 0.7576386531194051}]}], "tableCaptions": [{"text": " Table 1: The percentage of sentences that have at least  one overlapping entity in the previous n sentences", "labels": [], "entities": []}, {"text": " Table 2: Tenfold-crossvalidation for feature model  FullMorphSyn and different context windows (S c )", "labels": [], "entities": [{"text": "FullMorphSyn", "start_pos": 53, "end_pos": 65, "type": "DATASET", "confidence": 0.8955854773521423}]}, {"text": " Table 3: Evaluation for different feature models; 'Lan- guage Model': ranking based on language model  scores, 'BaseSyn': precedence between constituent  functions, 'FullMorphSyn': entire set of sentence- internal features.", "labels": [], "entities": []}, {"text": " Table 4: Backward and forward centers and their posi- tions", "labels": [], "entities": []}, {"text": " Table 5: Results from Vorfeld classification, training  and evaluation on entire treebank", "labels": [], "entities": [{"text": "Vorfeld classification", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.7261339575052261}]}, {"text": " Table 6: Results from Vorfeld classification, training  and evaluation on sentences that contain a coreference  link", "labels": [], "entities": [{"text": "Vorfeld classification", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.6389058232307434}]}]}