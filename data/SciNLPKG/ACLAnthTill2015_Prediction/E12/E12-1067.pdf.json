{"title": [{"text": "Probabilistic Hierarchical Clustering of Morphological Paradigms", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a novel method for learning morphological paradigms that are struc-tured within a hierarchy.", "labels": [], "entities": []}, {"text": "The hierarchical structuring of paradigms groups morphologically similar words close to each other in a tree structure.", "labels": [], "entities": []}, {"text": "This allows detecting morphological similarities easily leading to improved morphological segmen-tation.", "labels": [], "entities": []}, {"text": "Our evaluation using (Kurimo et al., 2011a; Kurimo et al., 2011b) dataset shows that our method performs competitively when compared with current state-of-art systems.", "labels": [], "entities": [{"text": "Kurimo et al., 2011b) dataset", "start_pos": 44, "end_pos": 73, "type": "DATASET", "confidence": 0.6095338463783264}]}], "introductionContent": [{"text": "Unsupervised morphological segmentation of a text involves learning rules for segmenting words into their morphemes.", "labels": [], "entities": [{"text": "Unsupervised morphological segmentation of a text", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.7923804620901743}]}, {"text": "Morphemes are the smallest meaning bearing units of words.", "labels": [], "entities": []}, {"text": "The learning process is fully unsupervised, using only raw text as input to the learning system.", "labels": [], "entities": []}, {"text": "For example, the word respectively is split into morphemes respect, ive and ly.", "labels": [], "entities": [{"text": "respect", "start_pos": 59, "end_pos": 66, "type": "METRIC", "confidence": 0.8291565179824829}]}, {"text": "Many fields, such as machine translation, information retrieval, speech recognition etc., require morphological segmentation since new words are always created and storing all the word forms will require a massive dictionary.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.8001993894577026}, {"text": "information retrieval", "start_pos": 42, "end_pos": 63, "type": "TASK", "confidence": 0.8014979362487793}, {"text": "speech recognition", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.7550329566001892}]}, {"text": "The task is even more complex, when morphologically complicated languages (i.e. agglutinative languages) are considered.", "labels": [], "entities": []}, {"text": "The sparsity problem is more severe for more morphologically complex languages.", "labels": [], "entities": []}, {"text": "Applying morphological segmentation mitigates data sparsity by tackling the issue with out-of-vocabulary (OOV) words.", "labels": [], "entities": []}, {"text": "In this paper, we propose a paradigmatic approach.", "labels": [], "entities": []}, {"text": "A morphological paradigm is a pair (StemList, SuffixList) such that each concatenation of Stem+Suffix (where Stem \u2208 StemList and Suffix \u2208 SuffixList) is a valid word form.", "labels": [], "entities": []}, {"text": "The learning of morphological paradigms is not novel as there has already been existing work in this area such as,,, and.", "labels": [], "entities": []}, {"text": "However, none of these existing approaches address learning of the hierarchical structure of paradigms.", "labels": [], "entities": []}, {"text": "Hierarchical organisation of words help capture morphological similarities between words in a compact structure by factoring these similarities through stems, suffixes or prefixes.", "labels": [], "entities": []}, {"text": "Our inference algorithm simultaneously infers latent variables (i.e. the morphemes) along with their hierarchical organisation.", "labels": [], "entities": []}, {"text": "Most hierarchical clustering algorithms are single-pass, where once the hierarchical structure is built, the structure does not change further.", "labels": [], "entities": []}, {"text": "The paper is structured as follows: section 2 gives the related work, section 3 describes the probabilistic hierarchical clustering scheme, section 4 explains the morphological segmentation model by embedding it into the clustering scheme and describes the inference algorithm along with how the morphological segmentation is performed, section 5 presents the experiment settings along with the evaluation scores, and finally section 6 presents a discussion with a comparison with other systems that participated in Morpho Challenge 2009 and 2010 .", "labels": [], "entities": [{"text": "Morpho Challenge 2009 and 2010", "start_pos": 516, "end_pos": 546, "type": "DATASET", "confidence": 0.8109505534172058}]}], "datasetContent": [{"text": "Two sets of experiments were performed for the evaluation of the model.", "labels": [], "entities": []}, {"text": "In the first set of experiments, each word is split at single point giving a single stem and a single suffix.", "labels": [], "entities": []}, {"text": "In the second set of experiments, potentially multiple split points are generated, by splitting each stem and suffix once more, if it is possible to do so.", "labels": [], "entities": []}, {"text": "Morpho Challenge () provides a well established evaluation framework that additionally allows comparing our model in a range of languages.", "labels": [], "entities": [{"text": "Morpho Challenge", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.8773897886276245}]}, {"text": "In both sets of experiments, the Morpho Challenge 2010 dataset is used ().", "labels": [], "entities": [{"text": "Morpho Challenge 2010 dataset", "start_pos": 33, "end_pos": 62, "type": "DATASET", "confidence": 0.944644033908844}]}, {"text": "Experiments are performed for English, where the dataset consists of 878,034 words.", "labels": [], "entities": []}, {"text": "Although the dataset provides word frequencies, we have not used any frequency information.", "labels": [], "entities": []}, {"text": "However, for training our model, we only chose words with frequency greater than 200.", "labels": [], "entities": []}, {"text": "In our experiments, we used dataset sizes of 10K, 16K, 22K words.", "labels": [], "entities": []}, {"text": "However, for final evaluation, we trained our models on 22K words.", "labels": [], "entities": []}, {"text": "We were unable to complete the experiments with larger training datasets due to memory limitations.", "labels": [], "entities": []}, {"text": "We plan to report this in future work.", "labels": [], "entities": []}, {"text": "Once the tree is learned by the inference algorithm, the final tree is used for the segmentation of the entire dataset.", "labels": [], "entities": []}, {"text": "Several experiments are performed for each setting where the setting varies with the tree size and the model parameters.", "labels": [], "entities": []}, {"text": "Model parameters are the concentration parameters \u03b2 = {\u03b2 s , \u03b2 m } of the Dirichlet processes.", "labels": [], "entities": []}, {"text": "The concentration parameters, which are set for the experiments, are 0.1, 0.2, 0.02, 0.001, 0.002.", "labels": [], "entities": []}, {"text": "In all experiments, the initial temperature of the system is assigned as \u03b3 = 2 and it is reduced to the temperature \u03b3 = 0.01 with decrements \u03b7 = 0.0001.", "labels": [], "entities": []}, {"text": "shows how the log likelihoods of trees of size 16K and 22K converge in time (where the time axis refers to sampling iterations).", "labels": [], "entities": []}, {"text": "Since different training sets will lead to different tree structures, each experiment is repeated three times keeping the experiment setting the same.: Evaluation scores of multiple split point experiments obtained from the trees with 10K, 16K, and 22K words.", "labels": [], "entities": []}, {"text": "In the first set of experiments, words are split into a single stem and suffix.", "labels": [], "entities": []}, {"text": "During the segmentation, Equation 12 is used to determine the split position of each word.", "labels": [], "entities": [{"text": "Equation 12", "start_pos": 25, "end_pos": 36, "type": "METRIC", "confidence": 0.973024994134903}]}, {"text": "Evaluation scores are given in Table 1.", "labels": [], "entities": []}, {"text": "The highest F-measure obtained is 51.28% with the dataset of 22K words.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9984556436538696}]}, {"text": "The scores are noticeably higher with the largest training set.", "labels": [], "entities": []}, {"text": "The evaluation scores of experiments with multiple split points are given in.", "labels": [], "entities": []}, {"text": "The highest F-measure obtained is 62.56% with the dataset with 22K words.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9990045428276062}]}, {"text": "As for single split points, the scores are noticeably higher with the largest training set.", "labels": [], "entities": []}, {"text": "For both, single and multiple segmentation, the same inferred tree has been used.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Highest evaluation scores of single split point  experiments obtained from the trees with 10K, 16K,  and 22K words.", "labels": [], "entities": []}, {"text": " Table 2: Evaluation scores of multiple split point ex- periments obtained from the trees with 10K, 16K, and  22K words.", "labels": [], "entities": []}, {"text": " Table 3: Comparison with other unsupervised systems  that participated in Morpho Challenge 2009 for En- glish.", "labels": [], "entities": [{"text": "Morpho Challenge 2009", "start_pos": 75, "end_pos": 96, "type": "DATASET", "confidence": 0.791097899278005}]}, {"text": " Table 4: Comparison with other unsupervised systems  that participated in Morpho Challenge 2010 for Turk- ish.", "labels": [], "entities": []}, {"text": " Table 6: Comparison of our model with other unsuper- vised systems that participated in Morpho Challenge  2010 for English.", "labels": [], "entities": [{"text": "Morpho Challenge  2010", "start_pos": 89, "end_pos": 111, "type": "DATASET", "confidence": 0.8119629224141439}]}]}