{"title": [{"text": "Bootstrapping Events and Relations from Text", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we describe anew approach to semi-supervised adaptive learning of event extraction from text.", "labels": [], "entities": [{"text": "semi-supervised adaptive learning of event extraction from text", "start_pos": 44, "end_pos": 107, "type": "TASK", "confidence": 0.7121195048093796}]}, {"text": "Given a set of examples and an un-annotated text corpus, the BEAR system (Bootstrapping Events And Relations) will automatically learn how to recognize and understand descriptions of complex semantic relationships in text, such as events involving multiple entities and their roles.", "labels": [], "entities": [{"text": "BEAR", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9967798590660095}]}, {"text": "For example, given a series of descriptions of bombing and shooting incidents (e.g., in newswire) the system will learn to extract, with a high degree of accuracy , other attack-type events mentioned elsewhere in text, irrespective of the form of description.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.9927674531936646}]}, {"text": "A series of evaluations using the ACE data and event set show a significant performance improvement over our baseline system.", "labels": [], "entities": [{"text": "ACE data and event set", "start_pos": 34, "end_pos": 56, "type": "DATASET", "confidence": 0.8076037168502808}]}], "introductionContent": [{"text": "We constructed a semi-supervised machine learning process that effectively exploits statistical and structural properties of natural language discourse in order to rapidly acquire rules to detect mentions of events and other complex relationships in text, extract their key attributes, and construct template-like representations.", "labels": [], "entities": []}, {"text": "The learning process exploits descriptive and structural redundancy, which is common in language; it is often critical for achieving successful communication despite distractions, different contexts, or incompatible semantic models between a speaker/writer and a hearer/reader.", "labels": [], "entities": []}, {"text": "We also take advantage of the high degree of referential consistency in discourse (e.g., as observed in word sense distribution by, and arguably applicable to larger linguistic units), which enables the reader to efficiently correlate different forms of description across coherent spans of text.", "labels": [], "entities": []}, {"text": "The method we describe here consists of two steps: (1) supervised acquisition of initial extraction rules from an annotated training corpus, and (2) self-adapting unsupervised multi-pass bootstrapping by which the system learns new rules as it reads un-annotated text using the rules learnt in the first step and in the subsequent learning passes.", "labels": [], "entities": []}, {"text": "When a sufficient quantity and quality of text material is supplied, the system will learn many ways in which a specific class of events can be described.", "labels": [], "entities": []}, {"text": "This includes the capability to detect individual event mentions using a system of context-sensitive triggers and to isolate pertinent attributes such as agent, object, instrument, time, place, etc., as maybe specific for each type of event.", "labels": [], "entities": []}, {"text": "This method produces an accurate and highly adaptable event extraction that significantly outperforms current information extraction techniques both in terms of accuracy and robustness, as well as in deployment cost.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 54, "end_pos": 70, "type": "TASK", "confidence": 0.7425715923309326}, {"text": "information extraction", "start_pos": 110, "end_pos": 132, "type": "TASK", "confidence": 0.7431876510381699}, {"text": "accuracy", "start_pos": 161, "end_pos": 169, "type": "METRIC", "confidence": 0.9989210367202759}]}], "datasetContent": [{"text": "We test the system learning effectiveness by comparing its performance immediately following the first iteration (i.e., using rules derived from the training data) with its performance after N cycles of unsupervised learning.", "labels": [], "entities": []}, {"text": "We split ACE training corpus 8 randomly into 5 folders and trained BEAR on the four folders and evaluated it on the left one.", "labels": [], "entities": [{"text": "ACE training corpus 8", "start_pos": 9, "end_pos": 30, "type": "DATASET", "confidence": 0.8162846565246582}, {"text": "BEAR", "start_pos": 67, "end_pos": 71, "type": "METRIC", "confidence": 0.9994632601737976}]}, {"text": "Then, we did 5 fold cross validation.", "labels": [], "entities": []}, {"text": "Our experiments showed that BEAR 8 ACE training data contains 599 documents from news, weblog, usenet, and conversational telephone speech.", "labels": [], "entities": [{"text": "BEAR 8 ACE training data", "start_pos": 28, "end_pos": 52, "type": "DATASET", "confidence": 0.7173009157180786}]}, {"text": "Total 33 types of events are defined in ACE corpus.", "labels": [], "entities": [{"text": "ACE corpus", "start_pos": 40, "end_pos": 50, "type": "DATASET", "confidence": 0.9564177393913269}]}, {"text": "reached the best cross-validated score, 66.72%, when pattern accuracy threshold is set at 0.5.", "labels": [], "entities": [{"text": "accuracy threshold", "start_pos": 61, "end_pos": 79, "type": "METRIC", "confidence": 0.9501061737537384}]}, {"text": "The highest score of single run is 67.62%.", "labels": [], "entities": []}, {"text": "In the following of this section, we will use results of one single run to display the learning behavior of BEAR.", "labels": [], "entities": [{"text": "BEAR", "start_pos": 108, "end_pos": 112, "type": "METRIC", "confidence": 0.5145742297172546}]}, {"text": "In, X-axis shows values of the learning threshold (in descending order), while Y-axis is the average F-score achieved by the automatically learned patterns for all types of events against the test corpus.", "labels": [], "entities": [{"text": "F-score", "start_pos": 101, "end_pos": 108, "type": "METRIC", "confidence": 0.9950542449951172}]}, {"text": "The red (lower) line represents BEAR's base run immediately after the first iteration (supervised learning step); the blue (upper) line represents BEAR's performance after an additional 10 unsupervised learning cycles 9 are completed.", "labels": [], "entities": []}, {"text": "We note that the final performance of the bootstrapped system steadily increases as the learning threshold is lowered, peaking at about 0.5 threshold value, and then declines as the threshold value is further decreased, although it remains solidly above the base run.", "labels": [], "entities": []}, {"text": "Analyzing more closely a few selected points on this chart we note, for example, that the base run at threshold of 0 has F-score of 34.5%, which represents 30.42% recall, 40% precision.", "labels": [], "entities": [{"text": "F-score", "start_pos": 121, "end_pos": 128, "type": "METRIC", "confidence": 0.9996155500411987}, {"text": "recall", "start_pos": 163, "end_pos": 169, "type": "METRIC", "confidence": 0.9990342855453491}, {"text": "precision", "start_pos": 175, "end_pos": 184, "type": "METRIC", "confidence": 0.9985672235488892}]}, {"text": "On the other end of the curve, at the threshold of 0.9, the base run precision is 91.8% but recall at only 21.5%, which produces F-score of 34.8%.", "labels": [], "entities": [{"text": "base run", "start_pos": 60, "end_pos": 68, "type": "METRIC", "confidence": 0.9725906848907471}, {"text": "precision", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.6302309036254883}, {"text": "recall", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.9996148347854614}, {"text": "F-score", "start_pos": 129, "end_pos": 136, "type": "METRIC", "confidence": 0.99967360496521}]}, {"text": "It is interesting to observe that at neither of these two extremes the system learning effectiveness is particularly good, and is significantly less than at.", "labels": [], "entities": []}, {"text": "Event mention extraction after learning: recall for each type of event.", "labels": [], "entities": [{"text": "Event mention extraction", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.5938118596871694}, {"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.9983611702919006}]}, {"text": "Event mention extraction after learning: precision for each type of event the median threshold of 0.5 (based on the experiments conducted thus far), where the system performance improves from 42% to 66.86% Fscore, which represents 83.9% precision and 55.57% recall.", "labels": [], "entities": [{"text": "Event mention extraction", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.5787909030914307}, {"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9995725750923157}, {"text": "Fscore", "start_pos": 206, "end_pos": 212, "type": "METRIC", "confidence": 0.9998443126678467}, {"text": "precision", "start_pos": 237, "end_pos": 246, "type": "METRIC", "confidence": 0.9995042085647583}, {"text": "recall", "start_pos": 258, "end_pos": 264, "type": "METRIC", "confidence": 0.9988102912902832}]}, {"text": "explains BEAR's learning effectiveness at what we determined empirically to be the optimal confidence threshold (0.5) for pattern acquisition.", "labels": [], "entities": [{"text": "BEAR", "start_pos": 9, "end_pos": 13, "type": "METRIC", "confidence": 0.6141213178634644}, {"text": "pattern acquisition", "start_pos": 122, "end_pos": 141, "type": "TASK", "confidence": 0.714870274066925}]}, {"text": "We note that the performance of the system steadily increases until it reaches a plateau after about 10 learning cycles. and show a detailed breakdown of BEAR extraction performance after 10 learning cycles for different types of events.", "labels": [], "entities": [{"text": "BEAR extraction", "start_pos": 154, "end_pos": 169, "type": "TASK", "confidence": 0.8592940866947174}]}, {"text": "We note that while precision holds steady across the event types, recall levels vary significantly.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9994719624519348}, {"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9991323351860046}]}, {"text": "The main reason for low recall in some types of events is the failure to find a sufficient number of high-confidence patterns.", "labels": [], "entities": [{"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9988553524017334}]}, {"text": "This may point to limitations of the current pattern discovery methods and may require new ways of reaching outside of the current feature set.", "labels": [], "entities": [{"text": "pattern discovery", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.726172685623169}]}, {"text": "In the previous section we described several learning methods that BEAR uses to discover, validate and adapt new event extraction rules.", "labels": [], "entities": [{"text": "event extraction rules", "start_pos": 113, "end_pos": 135, "type": "TASK", "confidence": 0.7696896195411682}]}, {"text": "Some of them work by manipulating already learnt patterns and adapting them to new data in order to create new patterns, and we shall call these pattern-mutation methods (PMM).", "labels": [], "entities": []}, {"text": "Other described methods work by exploiting a broader linguistic context in which the events occur, or context-based methods (CBM).", "labels": [], "entities": []}, {"text": "CB methods look for structural duality in text surrounding the events and thus discover alternative extraction patterns.", "labels": [], "entities": []}, {"text": "In, we report the results of running BEAR with each of these two groups of learning methods separately and then in combination to see how they contribute to the end performance.", "labels": [], "entities": []}, {"text": "Base1 and Base2 showed the result without and with adding trigger synonyms in event extraction.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 78, "end_pos": 94, "type": "TASK", "confidence": 0.7245328724384308}]}, {"text": "By introducing trigger synonyms, 27% more good events were extracted at the first iteration and thus, BEAR had more resources to use in the unsupervised learning steps.", "labels": [], "entities": [{"text": "BEAR", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.7666372060775757}]}, {"text": "The ALL is the combination of PMM and CBM, which demonstrate both methods have the contribution to the final results.", "labels": [], "entities": [{"text": "ALL", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.9133762121200562}]}, {"text": "Furthermore, as explained before, new extraction rules are learned in each iteration cycle based on what was learned in prior cycles and that new rules are adopted only after they are tested for their projected accuracy (confidence score), so that the overall precision of the resulting rule set is maintained at a high level relative to the base run.", "labels": [], "entities": [{"text": "accuracy (confidence score)", "start_pos": 211, "end_pos": 238, "type": "METRIC", "confidence": 0.857235586643219}, {"text": "precision", "start_pos": 260, "end_pos": 269, "type": "METRIC", "confidence": 0.9968068599700928}]}], "tableCaptions": [{"text": " Table 2. BEAR performance following different selections of  learning steps", "labels": [], "entities": [{"text": "BEAR", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9947260022163391}]}]}