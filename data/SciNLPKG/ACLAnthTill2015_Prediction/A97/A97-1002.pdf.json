{"title": [{"text": "Natural Language in Four Spatial Interfaces", "labels": [], "entities": []}], "abstractContent": [{"text": "We describe our experiences building spoken language interfaces to four demonstration applications all involving 2-or 3-D spatial displays or gestural interactions: an air combat command and control simulation, an immersive VR tactical scenario viewer, a map-based airstrike simulation tool with cartographic database, and a speech/gesture controller for mobile robots.", "labels": [], "entities": []}], "introductionContent": [{"text": "The NAUTILUS natural language processor has been underdevelopment at our facility since about 1988.", "labels": [], "entities": [{"text": "NAUTILUS natural language processor", "start_pos": 4, "end_pos": 39, "type": "DATASET", "confidence": 0.8339770883321762}]}, {"text": "During those years it has been used and tested in five different demonstration projects, four of which we describe in some detail in this report: an air combat command and control simulation, an immersive VR tactical scenario viewer, a map-based airstrike simulation tool with cartographic database, and a speech/gesture controller for mobile robots.", "labels": [], "entities": []}, {"text": "All four applications involve spatial displays or interactions, including 2D map-based graphical displays (radar screen, geographic map), 3D perspective scenes, and hand gesture input.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}