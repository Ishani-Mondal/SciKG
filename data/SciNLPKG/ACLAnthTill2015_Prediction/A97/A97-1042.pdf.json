{"title": [], "abstractContent": [{"text": "This paper addresses the problem of identifying likely topics of texts by their position in the text.", "labels": [], "entities": []}, {"text": "It describes the automated training and evaluation of an Optimal Position Policy, a method of locating the likely positions of topic-bearing sentences based on genre-specific regularities of discourse structure.", "labels": [], "entities": []}, {"text": "This method can be used in applications such as information retrieval, routing, and text summarization.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 48, "end_pos": 69, "type": "TASK", "confidence": 0.8666076064109802}, {"text": "routing", "start_pos": 71, "end_pos": 78, "type": "TASK", "confidence": 0.9058043360710144}, {"text": "text summarization", "start_pos": 84, "end_pos": 102, "type": "TASK", "confidence": 0.8103994727134705}]}], "introductionContent": [], "datasetContent": [{"text": "The goal of creating an Optimal Position Policy is to adapt the position hypothesis to various domains or genres in order to achieve maximal topic coverage.", "labels": [], "entities": []}, {"text": "Two checkpoints are required: Two evaluations were conducted to confirm these points.", "labels": [], "entities": []}, {"text": "In both cases, we compared the sentences extracted according to the OPP to the sentences contained in the human-generated abstracts.", "labels": [], "entities": [{"text": "OPP", "start_pos": 68, "end_pos": 71, "type": "DATASET", "confidence": 0.7967479228973389}]}, {"text": "Though we could have used topic keywords for both training and evaluation, we decided that the abstracts would provide a more interesting and practical measure for output, since the OPP method extracts from the text full sentences instead of topic phrases.", "labels": [], "entities": []}, {"text": "Accordingly, we used as test corpus another, previously unseen, set of 2,907 texts from Vol. 2 of the Ziff-Davis corpus, which contained texts of the same nature and genre as Vol. 1.  This evaluation established the validity of the Position Hypothesis, namely that the OPP so determined does in fact provide away of identifying highyield sentences, and is not just a list of average highyield positions of the corpus we happened to pick.", "labels": [], "entities": []}, {"text": "following the same steps as before, we therefore derived anew OPP on the test corpus.", "labels": [], "entities": [{"text": "OPP", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.948492705821991}]}, {"text": "The result of the average scores of 300 positions (Pro, Sn) shown in, with 1 < m < 30 and 1 < n < 10, was a contour map highly similar to.", "labels": [], "entities": []}, {"text": "Both peak at position (P2, $1) and decrease gradually in the X direction and more rapidly in the Y direction.", "labels": [], "entities": []}, {"text": "The similarity between the policy de-287 termination maps of the training and test sets confirms two things: First, correspondences exist between topics and sentence positions in texts such as the ZIFF-Davis collection.", "labels": [], "entities": [{"text": "ZIFF-Davis collection", "start_pos": 197, "end_pos": 218, "type": "DATASET", "confidence": 0.8549483120441437}]}, {"text": "Second, the regularity between topics and sentence positions can be used to identify topic sentences in texts.", "labels": [], "entities": []}, {"text": "In the evaluation, we measured the word overlap of sentences contained in the abstracts with sentence(s) extracted from a text according to the OPP.", "labels": [], "entities": [{"text": "OPP", "start_pos": 144, "end_pos": 147, "type": "DATASET", "confidence": 0.9117515087127686}]}, {"text": "For each measure, we recorded scores cumulatively, choosing first the most promising sentence according to the OPP, then the two most promising, and soon.", "labels": [], "entities": [{"text": "OPP", "start_pos": 111, "end_pos": 114, "type": "DATASET", "confidence": 0.7206307053565979}]}, {"text": "We measured word overlap as follows: first, we removed all function (closed-class) words from the abstract and from the text under consideration.", "labels": [], "entities": []}, {"text": "Then, for the first 500 sentence positions (the top 1, 2, 3,..., taken according to the OPP), we counted the number of times a window of text in the extracted sentences matched (i.e., exactly equalled) a window of text in the abstract.", "labels": [], "entities": [{"text": "OPP", "start_pos": 88, "end_pos": 91, "type": "DATASET", "confidence": 0.868290364742279}]}, {"text": "(Again we performed no morphology manipulations or reference resolution, steps which would improve the resulting scores.)", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 51, "end_pos": 71, "type": "TASK", "confidence": 0.6515776813030243}]}, {"text": "We performed the counts for window lengths of 1, 2, 3, 4, and 5 words.", "labels": [], "entities": []}, {"text": "If a sentence in an abstract matched more than one sentence extracted by the OP, only the first match was tallied.", "labels": [], "entities": []}, {"text": "For each number of sentences extracted, and for each window size, we averaged the counts overall 2,907 texts.", "labels": [], "entities": []}, {"text": "We define some terms and three measures used to assess the quality of the OPP-selected extracts.", "labels": [], "entities": [{"text": "OPP-selected extracts", "start_pos": 74, "end_pos": 95, "type": "DATASET", "confidence": 0.7498604953289032}]}, {"text": "For an extract E and a abstract A:", "labels": [], "entities": []}], "tableCaptions": []}