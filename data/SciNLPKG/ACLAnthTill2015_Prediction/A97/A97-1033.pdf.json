{"title": [{"text": "Building a Generation Knowledge Source using Internet-Accessible Newswire", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we describe a method for automatic creation of a knowledge source for text generation using information extraction over the Internet.", "labels": [], "entities": [{"text": "text generation", "start_pos": 85, "end_pos": 100, "type": "TASK", "confidence": 0.7693369090557098}, {"text": "information extraction", "start_pos": 107, "end_pos": 129, "type": "TASK", "confidence": 0.7301016598939896}]}, {"text": "We present a prototype system called PROFILE which uses a client-server architecture to extract noun-phrase descriptions of entities such as people, places, and organizations.", "labels": [], "entities": []}, {"text": "The system serves two purposes: as an information extraction tool, it allows users to search for textual descriptions of entities; as a utility to generate functional descriptions (FD), it is used in a functional-unification based generation system.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 38, "end_pos": 60, "type": "TASK", "confidence": 0.7605377733707428}]}, {"text": "We present an evaluation of the approach and its applications to natural language generation and summarization.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 65, "end_pos": 92, "type": "TASK", "confidence": 0.6832776069641113}, {"text": "summarization", "start_pos": 97, "end_pos": 110, "type": "TASK", "confidence": 0.9665198922157288}]}], "introductionContent": [{"text": "In our work to date on news summarization at Columbia University (, information is extracted from a series of input news articles and is analyzed by a generation component to produce a summary that shows how perception of the event has changed overtime.", "labels": [], "entities": [{"text": "news summarization", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.6261242032051086}]}, {"text": "In this summarization paradigm, problems arise when information needed for the summary is either missing from the input article(s) or not extracted by the information extraction system.", "labels": [], "entities": [{"text": "summarization", "start_pos": 8, "end_pos": 21, "type": "TASK", "confidence": 0.9671845436096191}]}, {"text": "In such cases, the information maybe readily available in other current news stories, in past news, or in online databases.", "labels": [], "entities": []}, {"text": "If the summarization system can find the needed information in other online sources, then it can produce an improved summary by merging information from multiple sources with information extracted from the input articles.", "labels": [], "entities": []}, {"text": "In the news domain, a summary needs to refer to people, places, and organizations and provide descriptions that clearly identify the entity for the reader.", "labels": [], "entities": []}, {"text": "Such descriptions may not be present in the original text that is being summarized.", "labels": [], "entities": []}, {"text": "For example, the American pilot Scott O'Grady, downed in Bosnia in June of 1995, was unheard of by the American public prior to the incident.", "labels": [], "entities": []}, {"text": "If a reader tuned into news on this event days later, descriptions from the initial articles maybe more useful.", "labels": [], "entities": []}, {"text": "A summarizer that has access to different descriptions will be able to select the description that best suits both the reader and the series of articles being summarized.", "labels": [], "entities": []}, {"text": "In this paper, we describe a system called PROFILE that tracks prior references to a given entity by extracting descriptions for later use in summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 142, "end_pos": 155, "type": "TASK", "confidence": 0.9759337306022644}]}, {"text": "In contrast with previous work on information extraction, our work has the following features: \u2022 It builds a database of profiles for entities by storing descriptions from a collected corpus of \u2022 past news.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 34, "end_pos": 56, "type": "TASK", "confidence": 0.7272514998912811}]}, {"text": "\u2022 It operates in real time, allowing for connections with the latest breaking, online news to extract information about the most recently mentioned individuals and organizations.", "labels": [], "entities": []}, {"text": "\u2022 It collects and merges information from distributed sources thus allowing fora more complete record of information.", "labels": [], "entities": []}, {"text": "\u2022 As it parses and identifies descriptions, it builds a lexicalized, syntactic representation of the description in a form suitable for input to the FUF/SURGE language generation system.", "labels": [], "entities": [{"text": "FUF/SURGE language generation", "start_pos": 149, "end_pos": 178, "type": "DATASET", "confidence": 0.7847001314163208}]}, {"text": "The result is a system that can combine descriptions from articles appearing only a few minutes before the ones being summarized with descriptions from past news in a permanent record for future use.", "labels": [], "entities": []}, {"text": "Its utility lies in its potential for representing entities, present in one article, with descriptions found in other articles, possibly coming from another source.", "labels": [], "entities": []}, {"text": "Since the system constructs a lexicalized, syntactic functional description (FD) from the extracted description, the generator can re-use the description in new contexts, merging it with other descriptions, into anew grammatical sentence.", "labels": [], "entities": []}, {"text": "This would not be possible if only canned strings were used, with no information about their internal structure.", "labels": [], "entities": []}, {"text": "Thus, in addition to collecting a knowledge source which provides identifying features of individuals, PROFILE also provides a lexicon of domain appropriate phrases that can be integrated with individual words from a generator's lexicon to flexibly produce summary wording.", "labels": [], "entities": []}, {"text": "We have extended the system by semantically categorizing descriptions using WordNet, so that a generator can more easily determine which description is relevant in different contexts.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 76, "end_pos": 83, "type": "DATASET", "confidence": 0.9565114974975586}]}, {"text": "PROFILE can also be used in a real-time fashion to monitor entities and the changes of descriptions associated with them over the course of time.", "labels": [], "entities": [{"text": "PROFILE", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.6952494382858276}]}, {"text": "In the following sections, we first overview related work in the area of information extraction.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.8684384822845459}]}, {"text": "We then turn to a discussion of the system components which build the profile database, followed by a description of how the results are used in generation.", "labels": [], "entities": []}, {"text": "We close with our current directions, describing what parameters can influence a strategy for generating a sequence of anaphoric references to the same entity overtime.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Two-word and three-word entities retrieved by the system.", "labels": [], "entities": []}]}