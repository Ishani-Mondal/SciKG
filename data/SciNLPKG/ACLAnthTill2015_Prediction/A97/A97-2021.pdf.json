{"title": [{"text": "A Spoken Language Interface to a Virtual Reality System (Video)", "labels": [], "entities": []}], "abstractContent": [{"text": "1 Description of videotape Format: VHS.", "labels": [], "entities": [{"text": "VHS", "start_pos": 35, "end_pos": 38, "type": "DATASET", "confidence": 0.8719210028648376}]}, {"text": "Immersive, interactive 3D computer display systems (often called virtual reality systems, or virtual environments) are rapidly emerging as practical options for training, command and control (C2), hazardous operations, visualization and other applications.", "labels": [], "entities": []}, {"text": "However, the need for improved control and navigation techniques is well recognized (Herndon et al., 1994).", "labels": [], "entities": [{"text": "navigation", "start_pos": 43, "end_pos": 53, "type": "TASK", "confidence": 0.8982797861099243}]}, {"text": "The Navy Center for Applied Research in Artificial Intelligence has developed NAU-TILUS (Navy AUTomated Intelligent Language Understanding System), a general-purpose natural language processing system, which has previously been integrated with the graphical user interface of a simulation-based C2 system to illustrate the advantages to be gained by combining natural language understanding (NLU) and direct manipulation in a human-computer interface (Wauchope, 1994).", "labels": [], "entities": [{"text": "natural language understanding (NLU)", "start_pos": 360, "end_pos": 396, "type": "TASK", "confidence": 0.8075015942255656}]}, {"text": "Using the NAUTILUS system in the interface to a virtual environment (VE) is a natural extension of this work.", "labels": [], "entities": []}, {"text": "The purpose of the project documented in this video was to demonstrate and explore some of the capabilities of a NLU interface to a VE system, and to identify some of the research issues that need to be addressed in this area.", "labels": [], "entities": []}, {"text": "It is important to recognize that NLU is not simply speech recognition, where each individual utterance maps to a specific command.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 52, "end_pos": 70, "type": "TASK", "confidence": 0.7239429503679276}]}, {"text": "Ina NLU system, a given sentence may have different meanings depending on the context, so a logical analysis of the utterance is required to determine the appropriate interpretation.", "labels": [], "entities": []}, {"text": "This allows us to take advantage of certain powerful linguistic properties as described below.", "labels": [], "entities": []}, {"text": "One major difficulty with interfaces to VE systems is that the user's hands and eyes are occupied in the virtual world, so standard input devices such as mice and keyboards that require a physical support and/or visual attention are impractical.", "labels": [], "entities": []}, {"text": "Joysticks, 36 gloves, and other manual input devices are useful for some types of control (pointing, manipulating objects), but they are not well suited to more abstract input functions.", "labels": [], "entities": []}, {"text": "Language, however, is ideally suited to abstract manipulations; it is also the most natural form of communication for humans, and does not require the use of one's hands or eyes.", "labels": [], "entities": []}, {"text": "It is especially useful for controlling things that do not have a physical presence in the VE, such as object scale, display characteristics, and time.", "labels": [], "entities": [{"text": "VE", "start_pos": 91, "end_pos": 93, "type": "DATASET", "confidence": 0.7070785760879517}]}, {"text": "It also provides a powerful means to access the knowledge that underlies the VE by allowing the user to ask questions of the system.", "labels": [], "entities": [{"text": "VE", "start_pos": 77, "end_pos": 79, "type": "DATASET", "confidence": 0.7777254581451416}]}, {"text": "Using speech output in combination with speech recognition helps to avoid the use of textual displays which can be difficult to read on immer-sire presentation equipment, and which can interfere with the user's view and the \"reality\" of the virtual world.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7446207702159882}]}, {"text": "The prototype system shown in this film uses off-the-shelf speech recognition and synthesis technology combined with the NAUTILUS system and VIEWER (Solan and Hill, 1993), a 3D tactical scenario playback system developed by NRL's Tactical Electronic Warfare Division fora separate project.", "labels": [], "entities": [{"text": "speech recognition and synthesis", "start_pos": 59, "end_pos": 91, "type": "TASK", "confidence": 0.7750994116067886}, {"text": "VIEWER", "start_pos": 141, "end_pos": 147, "type": "METRIC", "confidence": 0.918929398059845}, {"text": "tactical scenario playback", "start_pos": 177, "end_pos": 203, "type": "TASK", "confidence": 0.5740876992543539}]}, {"text": "Building the prototype involved the creation of an application-specific dictionary and lexical semantics for NAUTILUS, a few minor extensions to its En-glish grammar, and the development of two sets of code: one to translate the logical forms generated by NAUTILUS into messages for the application software , and one to interpret these messages and instruct VIEWER to produce the appropriate actions or responses.", "labels": [], "entities": []}, {"text": "The interface supports two classes of spoken input: commands and questions.", "labels": [], "entities": []}, {"text": "The commands allow the user to control the playback of the simulation and its speed, as well as various display characteristics, such as viewpoint (Show me lhe lop-down/ou~-the-window view) and overlays (Display the map rings).", "labels": [], "entities": []}, {"text": "The user can also tell the system to hide or display", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": []}