{"title": [{"text": "Automatic Selection of Class Labels from a Thesaurus for an Effective Semantic Tagging of Corpora", "labels": [], "entities": [{"text": "Semantic Tagging of Corpora", "start_pos": 70, "end_pos": 97, "type": "TASK", "confidence": 0.8337199091911316}]}], "abstractContent": [{"text": "It is widely accepted that tagging text with semantic information would improve the quality of lexical learning in corpus-based NLP methods.", "labels": [], "entities": [{"text": "tagging text with semantic information", "start_pos": 27, "end_pos": 65, "type": "TASK", "confidence": 0.8348261713981628}]}, {"text": "However available on-line taxonomies are rather entangled and introduce an unnecessary level of ambiguity.", "labels": [], "entities": []}, {"text": "The noise produced by the redundant number of tags often overrides the advantage of semantic tagging.", "labels": [], "entities": [{"text": "semantic tagging", "start_pos": 84, "end_pos": 100, "type": "TASK", "confidence": 0.7787027657032013}]}, {"text": "In this paper we propose an automatic method to select from WordNet a subset of domain-appropriate categories that effectively reduce the overambiguity of WordNet, and help at identifying and cate-gorise relevant language patterns in a more compact way.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 60, "end_pos": 67, "type": "DATASET", "confidence": 0.961572527885437}, {"text": "WordNet", "start_pos": 155, "end_pos": 162, "type": "DATASET", "confidence": 0.9478323459625244}]}, {"text": "The method is evaluated against a manually tagged corpus, SEMCOR.", "labels": [], "entities": [{"text": "SEMCOR", "start_pos": 58, "end_pos": 64, "type": "DATASET", "confidence": 0.9084978699684143}]}], "introductionContent": [{"text": "It is well known that statistically-based approaches to lexical knowledge acquisition are faced with the problem of low counts.", "labels": [], "entities": [{"text": "lexical knowledge acquisition", "start_pos": 56, "end_pos": 85, "type": "TASK", "confidence": 0.620603879292806}]}, {"text": "Many language patterns (from simple cooccurrences to more complex syntactic associations among words) occur very rarely, or are never encountered, in the learning corpus.", "labels": [], "entities": []}, {"text": "Since rare patterns are the majority, the quality and coverage of lexical learning may result severely affected.", "labels": [], "entities": [{"text": "coverage", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9781182408332825}]}, {"text": "The obvious strategy to reduce this problem is to generalise word patterns according to some clustering techniques.", "labels": [], "entities": []}, {"text": "In the literature, two generalisation strategies have been adopted: Distributional approaches: Several papers adopt distributional techniques to identify clusters of words according to some defined measure of similarity.", "labels": [], "entities": []}, {"text": "Among these, in a method is proposed to cluster syntactic triples, while in (, pure bigrams are analysed.", "labels": [], "entities": []}, {"text": "The most intuitive evaluation of the effectiveness of distributional approaches to the problem of word generalization is presented in.", "labels": [], "entities": [{"text": "word generalization", "start_pos": 98, "end_pos": 117, "type": "TASK", "confidence": 0.7500456869602203}]}, {"text": "In this paper it is argued that distributional (called also smoothing) techniques introduce a certain degree of additional error, because co-occurrences maybe erroneously conflated in a cluster, and some of the co-occurrences being generalized are themselves incorrect.", "labels": [], "entities": []}, {"text": "In general the effect is a higher recall at the price of a lower precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9994742274284363}, {"text": "precision", "start_pos": 65, "end_pos": 74, "type": "METRIC", "confidence": 0.9942942261695862}]}, {"text": "Another drawback of these methods is that, since clusters have only a numeric description, they are often hard to evaluate on a linguistic ground.", "labels": [], "entities": []}, {"text": "Semantic tagging: Another adopted solution is to gener-", "labels": [], "entities": [{"text": "Semantic tagging", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.8653660714626312}]}], "datasetContent": [{"text": "The algorithm was applied to the 10,235 different nouns of the Wall Street Journal (hereafter WSJ) corpus that are classified in WordNet.", "labels": [], "entities": [{"text": "Wall Street Journal (hereafter WSJ) corpus", "start_pos": 63, "end_pos": 105, "type": "DATASET", "confidence": 0.9278619363903999}, {"text": "WordNet", "start_pos": 129, "end_pos": 136, "type": "DATASET", "confidence": 0.8330361843109131}]}, {"text": "Categories are generated with h= 0.4 and k=l,000.", "labels": [], "entities": []}, {"text": "The cardinality of each set varies, but not uniformly, from 456 categories for UB--2000 (remember that words are frequency-weighted), to I category (i.e. the topmost entity) for UB=264,000.", "labels": [], "entities": [{"text": "UB--2000", "start_pos": 79, "end_pos": 87, "type": "DATASET", "confidence": 0.6579896907011668}]}, {"text": "Mediumhigh level categories (those between 50,000 and 100,000 maximum words) range between 10-20 members for each plots the values of G, CO, DP and 1/A for the different sets of categories generated by the algorithm of Section 2.", "labels": [], "entities": [{"text": "CO", "start_pos": 137, "end_pos": 139, "type": "METRIC", "confidence": 0.9251090884208679}, {"text": "DP", "start_pos": 141, "end_pos": 143, "type": "METRIC", "confidence": 0.8563889265060425}]}, {"text": "Alternative sets of categories are identified by their upperbound 3.", "labels": [], "entities": []}, {"text": "The figure shows that DP(Ci) has a regular decreasing behaviour, while 1/A(Ci) is less regular.", "labels": [], "entities": [{"text": "DP", "start_pos": 22, "end_pos": 24, "type": "METRIC", "confidence": 0.8543874025344849}]}, {"text": "The coverage CO(C i) has a rather unstable behaviour due to the entangled structure of WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 87, "end_pos": 94, "type": "DATASET", "confidence": 0.9754862189292908}]}, {"text": "We attempted slight changes in the definitions and computation of CO, DP and 1/A (for example, weighting words with their frequency), but globally, the behaviour remain as those in.", "labels": [], "entities": []}, {"text": "To compute the score of each set Ci.", "labels": [], "entities": []}, {"text": ", the parameters (x,13,;\u00a2 and 8 in (1) must be estimated.", "labels": [], "entities": []}, {"text": "To perform this task, we adopted a linear interpolation method, using SEMCOR (the semantically tagged Brown Corpus) as a reference corpus.", "labels": [], "entities": [{"text": "SEMCOR (the semantically tagged Brown Corpus)", "start_pos": 70, "end_pos": 115, "type": "DATASET", "confidence": 0.5974803045392036}]}, {"text": "In SEMCOR every word is unambiguously tagged with its leaf-synset.", "labels": [], "entities": []}, {"text": "To build a reference scoring function against which to evaluate our model parameters, we proceeded as follows: \u2022 Since our categories are generated for an economic domain (WSJ) while SEMCOR is a tagged balanced corpus (the Brown Corpus), we extracted only the fragment of the corpus dealing with economic and financial texts.", "labels": [], "entities": [{"text": "Brown Corpus)", "start_pos": 223, "end_pos": 236, "type": "DATASET", "confidence": 0.9290260473887125}]}, {"text": "We obtained a reference corpus including 475 of the 1,235 nouns of the WSJ corpus.", "labels": [], "entities": [{"text": "WSJ corpus", "start_pos": 71, "end_pos": 81, "type": "DATASET", "confidence": 0.9625822305679321}]}, {"text": "\u2022 For each set of categories Ci generated by the algorithm in section 2, we computed on the reference corpus the following two l:~rformance figures: Precision: For each Ci, let W(C i) be the set of words in the reference corpus covered by the met Ci.", "labels": [], "entities": []}, {"text": "For each wk in 3Remember that words are weighted by their frequency in the corpus.", "labels": [], "entities": []}, {"text": "This seems reasonable, but in any case we observed that our results do not vary when counting each word only once.", "labels": [], "entities": []}, {"text": "W(Ci), let S(w k) be the total set of leaves-synsets of wk in WordNet, SR(w k) the subset of leaves-synsets of wk found in the reference corpus, SC(w k) the subset of leaves-synsets that reach some of the categories of Ci.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 62, "end_pos": 69, "type": "DATASET", "confidence": 0.9470087289810181}]}, {"text": "Let WR(Ci) ~ W(C i) be the set of wk having SC(w k) c S(Wk).", "labels": [], "entities": []}, {"text": "Following the algorithm: for any wk in WR(C i) { for any s i in SR(w k) where freq(w k) is the number of occurrences of wk in the reference corpus, the precision Precision(C i) is then defined as N+/N -t\u00b0t.", "labels": [], "entities": [{"text": "freq", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.971839427947998}, {"text": "precision", "start_pos": 152, "end_pos": 161, "type": "METRIC", "confidence": 0.9952316880226135}, {"text": "Precision", "start_pos": 162, "end_pos": 171, "type": "METRIC", "confidence": 0.45849815011024475}]}, {"text": "The precision measures the ability of each set Ci at correctly pruning out some of the senses of W(Ci).", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9995238780975342}]}, {"text": "Global reduction of ambiguity: For each Ci, let S(W i) be the total number of WordNet leaves-synsets reached by the words in WR(Ci), and SCON i) ~ S(W i) the set of these synsets that reach some category in Ci.", "labels": [], "entities": [{"text": "Global reduction", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.6224453449249268}]}, {"text": "By tagging the corpus with Ci, we obtain a reduction of ambiguity measured by: where card (X) is the number of elements in the set X Starting from these two performance figures, the global performance function Perf(C i ) is measured by: The is computed for all the generated sets of categories Ci, and then normalised in the interval.", "labels": [], "entities": [{"text": "card (X)", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9235597401857376}]}, {"text": "The obtained plot is the reference against which we apply a standard linear interpolation method to estimate the values of the model parameters c\u00a2,~,X and 8 that minimize the difference between the values of the two functions for each Ci.", "labels": [], "entities": []}, {"text": "In the (not normalised) Precision and GRAmb are plotted for the test corpus.", "labels": [], "entities": [{"text": "Precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9973857998847961}, {"text": "GRAmb", "start_pos": 38, "end_pos": 43, "type": "METRIC", "confidence": 0.9988262057304382}]}, {"text": "In the normalised reference performance function and the \"best fitting\" scoring function are shown, with the estimated values of a,~,X and 8.", "labels": [], "entities": []}, {"text": "While the reference function has a peak on the class set Cj with UB--55,000 and the score function assigns the maximum value to the class set C k with UB=62,000, the performance of the sets in the range j-k is very similar.", "labels": [], "entities": [{"text": "UB", "start_pos": 151, "end_pos": 153, "type": "METRIC", "confidence": 0.9585490822792053}]}, {"text": "shows the values of precision and global reduction of ambiguity in the range.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9996449947357178}]}], "tableCaptions": []}