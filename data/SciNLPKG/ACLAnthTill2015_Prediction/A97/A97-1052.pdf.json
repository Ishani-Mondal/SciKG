{"title": [{"text": "Automatic Extraction of Subcategorization from Corpora", "labels": [], "entities": [{"text": "Automatic Extraction of Subcategorization", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.6530569568276405}]}], "abstractContent": [{"text": "We describe a novel technique and implemented system for constructing a subcate-gorization dictionary from textual corpora.", "labels": [], "entities": []}, {"text": "Each dictionary entry encodes the relative frequency of occurrence of a comprehensive set of subcategorization classes for En-glish.", "labels": [], "entities": []}, {"text": "An initial experiment, on a sample of 14 verbs which exhibit multiple comple-mentation patterns, demonstrates that the technique achieves accuracy comparable to previous approaches, which are all limited to a highly restricted set of subcategoriza-tion classes.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9989569187164307}]}, {"text": "We also demonstrate that a subcategorization dictionary built with the system improves the accuracy of a parser by an appreciable amount 1. 1 Motivation Predicate subcategorization is a key component of a lexical entry, because most, if not all, recent syntactic theories 'project' syntactic structure from the lexicon.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 91, "end_pos": 99, "type": "METRIC", "confidence": 0.9987824559211731}]}, {"text": "Therefore, a wide-coverage parser utilizing such a lexicalist grammar must have access to an accurate and comprehensive dictionary encoding (at a minimum) the number and category of a predi-cate's arguments and ideally also information about control with predicative arguments, semantic selection preferences on arguments, and so forth, to allow the recovery of the correct predicate-argument structure.", "labels": [], "entities": []}, {"text": "If the parser uses statistical techniques to rank analyses, it is also critical that the dictionary encode the relative frequency of distinct subcategorization classes for each predicate.", "labels": [], "entities": []}, {"text": "1This work was supported by UK DTI/SALT project 41/5808 'Integrated Language Database', CEC Telematics Applications Programme project LE1-211i 'SPARKLE: Shallow PARsing and Knowledge extraction for Language Engineering', and by SERC/EPSRC Advanced Fellowships to both authors.", "labels": [], "entities": [{"text": "UK DTI/SALT project 41/5808", "start_pos": 28, "end_pos": 55, "type": "DATASET", "confidence": 0.8909875229001045}, {"text": "CEC Telematics Applications Programme project LE1-211i", "start_pos": 88, "end_pos": 142, "type": "DATASET", "confidence": 0.8793547848860422}, {"text": "Knowledge extraction", "start_pos": 173, "end_pos": 193, "type": "TASK", "confidence": 0.7244723290205002}, {"text": "SERC/EPSRC Advanced Fellowships", "start_pos": 228, "end_pos": 259, "type": "DATASET", "confidence": 0.7906623005867004}]}, {"text": "We would like to thank the COMLEX Syntax development team for allowing us access to pre-release data (for an early experiment), and for useful feedback.", "labels": [], "entities": [{"text": "COMLEX Syntax development team", "start_pos": 27, "end_pos": 57, "type": "DATASET", "confidence": 0.8796472251415253}]}, {"text": "Several substantial machine-readable subcatego-rization dictionaries exist for English, either built largely automatically from machine-readable versions of conventional learners' dictionaries, or manually by (computational) linguists (e.g. the Alvey NL Tools (ANLT) dictionary, Boguraev et al. (1987); the COMLEX Syntax dictionary, Grishman et al. (1994)).", "labels": [], "entities": [{"text": "COMLEX Syntax dictionary", "start_pos": 307, "end_pos": 331, "type": "DATASET", "confidence": 0.7952601313591003}]}, {"text": "Unfortunately, neither approach can yield a genuinely accurate or comprehensive computational lexicon, because both rest ultimately on the manual efforts of lexicographers / linguists and are, therefore , prone to errors of omission and commission which are hard or impossible to detect automatically (e.g. Boguraev & Briscoe, 1989; see also section 3.1 below for an example).", "labels": [], "entities": []}, {"text": "Furthermore, manual encoding is labour intensive and, therefore, it is costly to extend it to neologisms, information not currently encoded (such as relative frequency of different sub-categorizations), or other (sub)languages.", "labels": [], "entities": [{"text": "manual encoding", "start_pos": 13, "end_pos": 28, "type": "TASK", "confidence": 0.7218136191368103}]}, {"text": "These problems are compounded by the fact that predicate subcategorization is closely associated to lexical sense and the senses of a word change between corpora , sublanguages and/or subject domains (Jensen, 1991).", "labels": [], "entities": []}, {"text": "Ina recent experiment with a wide-coverage parsing system utilizing a lexicalist grammatical framework , Briscoe & Carroll (1993) observed that half of parse failures on unseen test data were caused by inaccurate subcategorization information in the ANLT dictionary.", "labels": [], "entities": [{"text": "wide-coverage parsing", "start_pos": 29, "end_pos": 50, "type": "TASK", "confidence": 0.6019697189331055}, {"text": "ANLT dictionary", "start_pos": 250, "end_pos": 265, "type": "DATASET", "confidence": 0.813224732875824}]}, {"text": "The close connection between sense and subcategorization and between subject domain and sense makes it likely that a fully accurate 'static' subcategorization dictionary of a language is unattainable in any case.", "labels": [], "entities": []}, {"text": "Moreover, although Sch-abes (1992) and others have proposed 'lexicalized' probabilistic grammars to improve the accuracy of parse ranking, no wide-coverage parser has yet been constructed incorporating probabilities of different subcategorizations for individual predicates, because of the problems of accurately estimating them.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9977454543113708}, {"text": "parse ranking", "start_pos": 124, "end_pos": 137, "type": "TASK", "confidence": 0.8817419111728668}]}, {"text": "These problems suggest that automatic construction or updating of subcategorization dictionaries from textual corpora is a more promising avenue to pursue.", "labels": [], "entities": []}, {"text": "Preliminary experiments acquiring a few 356", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "In order to test the accuracy of our system (as developed so far) and to provide empirical feedback for further development, we took the Susanne, SEC and LOB corpora (--a total of 1.2 million words--and extracted all sentences containing an occurrence of one of fourteen verbs, up to a maximum of 1000 citations of each.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9989379048347473}, {"text": "Susanne, SEC and LOB corpora", "start_pos": 137, "end_pos": 165, "type": "DATASET", "confidence": 0.7060729265213013}]}, {"text": "These verbs, listed in, were chosen at random, subject to the constraint that they exhibited multiple complementation patterns.", "labels": [], "entities": []}, {"text": "The sentences containing these verbs were tagged and parsed automatically, and the extractor, classifier and evaluator were applied to the resulting successful analyses.", "labels": [], "entities": []}, {"text": "The citations from which entries were derived totaled approximately 70K words.", "labels": [], "entities": []}, {"text": "The results were evaluated against a merged entry for these verbs from the ANLT and COMLEX Syntax dictionaries, and also against a manual analysis of the corpus data for seven of the verbs.", "labels": [], "entities": [{"text": "ANLT and COMLEX Syntax dictionaries", "start_pos": 75, "end_pos": 110, "type": "DATASET", "confidence": 0.6281085968017578}]}, {"text": "The process of evaluating the performance of the system relative to the dictionaries could, in principle, be reduced to an automated report of type precision (percentage of correct subcategorization classes to all classes found) and recall (perCentage of correct classes found in the dictionary entry).", "labels": [], "entities": [{"text": "precision", "start_pos": 148, "end_pos": 157, "type": "METRIC", "confidence": 0.7019799947738647}, {"text": "recall", "start_pos": 233, "end_pos": 239, "type": "METRIC", "confidence": 0.9995001554489136}]}, {"text": "However, since there are disagreements between the dictionaries and there are classes found in the corpus data that are not contained in either dictionary, we report results relative both to a manually merged entry from ANLT and COMLEX, and also, for seven of the verbs, to a manual analysis of the actual corpus data.", "labels": [], "entities": [{"text": "COMLEX", "start_pos": 229, "end_pos": 235, "type": "DATASET", "confidence": 0.7840244770050049}]}, {"text": "The latter analysis is necessary because precision and recall measures against the merged entry will still tend to yield inaccurate results as the system cannot acquire classes not exemplified in the data, and may acquire classes incorrectly absent from the dictionaries.", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9992164373397827}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9977433681488037}]}, {"text": "We illustrate these problems with reference to seem, where there is overlap, but not agreement between the COMLEX and ANLT entries.", "labels": [], "entities": [{"text": "COMLEX and ANLT entries", "start_pos": 107, "end_pos": 130, "type": "DATASET", "confidence": 0.6732590645551682}]}, {"text": "Thus, both predict that seem will occur with a sentential complement and dummy subject, but only ANLT predicts the possibility of a 'wh' complement and only COMLEX predicts the (optional) presence of a PP argument with the sentential complement.", "labels": [], "entities": [{"text": "ANLT", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.9599700570106506}]}, {"text": "One ANLT entry covers two COMLEX entries given the different treatment of the relevant complements but the classifier keeps them distinct.", "labels": [], "entities": [{"text": "ANLT", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.8471475839614868}, {"text": "COMLEX", "start_pos": 26, "end_pos": 32, "type": "DATASET", "confidence": 0.8566954135894775}]}, {"text": "The corpus data for seem contains examples of further classes which we judge valid, in which seem can take a PP and infinitive complement, as in he seems tome to be insane, and a passive participle, as in he seemed depressed.", "labels": [], "entities": []}, {"text": "This comparison illustrates the problem of errors of omission common to computational lexicons constructed manually and also from machine-readable dictionaries.", "labels": [], "entities": []}, {"text": "All classes for seem are exemplified in the corpus data, but for ask, for example, eight classes (out of a possible 27 in the merged entry) are not present, so comparison only to the merged entry would give an unreasonably low estimate of recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 239, "end_pos": 245, "type": "METRIC", "confidence": 0.998015284538269}]}, {"text": "gives the raw results for the merged entries and corpus analysis on each verb.", "labels": [], "entities": []}, {"text": "It shows the number of true positives (TP), correct classes proposed by our system, false positives (FP), incorrect classes proposed by our system, and false negatives (FN), correct classes not proposed by our system, as judged against the merged entry, and, for seven of the verbs, against the corpus analysis.", "labels": [], "entities": [{"text": "false positives (FP)", "start_pos": 84, "end_pos": 104, "type": "METRIC", "confidence": 0.654345577955246}, {"text": "false negatives (FN)", "start_pos": 152, "end_pos": 172, "type": "METRIC", "confidence": 0.71614590883255}]}, {"text": "It also shows, in the final column, the number of sentences from which classes were extracted.", "labels": [], "entities": []}, {"text": "In addition to evaluating the acquired subcategorization information against existing lexical resources, we have also evaluated the information in the context of an actual parsing system.", "labels": [], "entities": []}, {"text": "In particular we wanted to establish whether the subcategorization frequency information for individual verbs could be used to improve the accuracy of a parser that uses statistical techniques to rank analyses.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9988634586334229}]}, {"text": "The experiment used the same probabilistic parser and tag sequence grammar as are present in the acquisition system (see references above)--although the experiment does not in anyway rely on the 'Baseline' Lexicalised", "labels": [], "entities": []}], "tableCaptions": []}