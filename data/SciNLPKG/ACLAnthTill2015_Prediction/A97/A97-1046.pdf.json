{"title": [{"text": "Fast Statistical Parsing of Noun Phrases for Document Indexing", "labels": [], "entities": [{"text": "Document Indexing", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.855655699968338}]}], "abstractContent": [{"text": "Information Retrieval (IR) is an important application area of Natural Language Processing (NLP) where one encounters the genuine challenge of processing large quantities of unrestricted natural language text.", "labels": [], "entities": [{"text": "Information Retrieval (IR)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8705175757408142}]}, {"text": "While much effort has been made to apply NLP techniques to IR, very few NLP techniques have been evaluated on a document collection larger than several megabytes.", "labels": [], "entities": [{"text": "IR", "start_pos": 59, "end_pos": 61, "type": "TASK", "confidence": 0.9849202632904053}]}, {"text": "Many NLP techniques are simply not efficient enough, and not robust enough, to handle a large amount of text.", "labels": [], "entities": []}, {"text": "This paper proposes anew probabilistic model for noun phrase parsing, and reports on the application of such a parsing technique to enhance document indexing.", "labels": [], "entities": [{"text": "noun phrase parsing", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.738273004690806}, {"text": "document indexing", "start_pos": 140, "end_pos": 157, "type": "TASK", "confidence": 0.6292787939310074}]}, {"text": "The effectiveness of using syntactic phrases provided by the parser to supplement single words for indexing is evaluated with a 250 megabytes document collection.", "labels": [], "entities": []}, {"text": "The experiment's results show that supplementing single words with syntactic phrases for indexing consistently and significantly improves retrieval performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Information Retrieval (IR) is an increasingly important application area of Natural Language Processing (NLP).", "labels": [], "entities": [{"text": "Information Retrieval (IR)", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8860069751739502}]}, {"text": "An IR task can be described as to find, from a given document collection, a subset of documents whose content is relevant to the information need of a user as expressed by a query.", "labels": [], "entities": [{"text": "IR task", "start_pos": 3, "end_pos": 10, "type": "TASK", "confidence": 0.9283872842788696}]}, {"text": "As the documents and query are often natural language texts, an IR task can usually be regarded as a special NLP task, where the document text and the query text need to be processed in order to judge the relevancy.", "labels": [], "entities": [{"text": "IR task", "start_pos": 64, "end_pos": 71, "type": "TASK", "confidence": 0.9128025472164154}]}, {"text": "A general strategy followed by most IR systems is to transform documents and the query into certain level of representation.", "labels": [], "entities": [{"text": "IR", "start_pos": 36, "end_pos": 38, "type": "TASK", "confidence": 0.9644155502319336}]}, {"text": "A query representation can then be compared with a document representation to decide if the document is relevant to the query.", "labels": [], "entities": []}, {"text": "In practice, the level of representation in an IR system is quite \"shallow\" --often merely a set of word-like strings, or indexing terms.", "labels": [], "entities": []}, {"text": "The process to extract indexing terms from each document in the collection is called indexing.", "labels": [], "entities": []}, {"text": "A query is often subject to similax processing, and the relevancy is judged based on the matching of query terms and document terms.", "labels": [], "entities": []}, {"text": "In most systems, weights are assigned to terms to indicate how well they can be used to discriminate relevant documents from irrelevant ones.", "labels": [], "entities": []}, {"text": "The challenge in applying NLP to IR is to deal with a large amount of unrestricted natural language text.", "labels": [], "entities": [{"text": "IR", "start_pos": 33, "end_pos": 35, "type": "TASK", "confidence": 0.9548212885856628}]}, {"text": "The NLP techniques used must be very efficient and robust, since the amount of text in the databases accessed is typically measured in gigabytes.", "labels": [], "entities": []}, {"text": "In the past, NLP techniques of different levels, including morphological, syntactic/semantic, and discourse processing, were exploited to enhance retrieval (Smeaton 92; Lewis and Spaxck Jones 96), but were rarely evaluated using collections of documents larger than several megabytes.", "labels": [], "entities": []}, {"text": "Many NLP techniques are simply not efficient enough or are too labor-intensive to successfully handle a large size document set.", "labels": [], "entities": []}, {"text": "However, there are some exceptions.", "labels": [], "entities": []}, {"text": "Evans et al. used selective NLP techniques, that are especially robust and efficient, for indexing ().", "labels": [], "entities": [{"text": "indexing", "start_pos": 90, "end_pos": 98, "type": "TASK", "confidence": 0.9774900078773499}]}, {"text": "Strzalkowski reported a fast and robust parser called TTP in.", "labels": [], "entities": []}, {"text": "These NLP techniques have been successfully used to process quite large collections, as shown in a series of TREC conference reports by the CLARIT TM1 system group and the New York University (later GE/NYU) group (cf., for example, (Evans and Lefferts 95;, and (Strzalkowski 95;) These research efforts demonstrated the feasibility of using selective NLP to handle large collections.", "labels": [], "entities": [{"text": "CLARIT TM1 system group", "start_pos": 140, "end_pos": 163, "type": "DATASET", "confidence": 0.886451467871666}]}, {"text": "A special NLP track emphasizing the evaluation of NLP techniques for IR is currently held in the context of TREC (Hatman 96).", "labels": [], "entities": [{"text": "IR", "start_pos": 69, "end_pos": 71, "type": "TASK", "confidence": 0.9935478568077087}, {"text": "TREC (Hatman 96)", "start_pos": 108, "end_pos": 124, "type": "DATASET", "confidence": 0.8013132333755493}]}, {"text": "In this paper, a fast probabilistic noun phrase parser is described.", "labels": [], "entities": [{"text": "noun phrase parser", "start_pos": 36, "end_pos": 54, "type": "TASK", "confidence": 0.6725993355115255}]}, {"text": "The parser can be exploited to 1CLARIT is a registered trademark of CLARITECH Corporation.", "labels": [], "entities": []}, {"text": "automatically extract syntactic phrases from a large amount of documents for indexing.", "labels": [], "entities": []}, {"text": "A 250-megabyte document set 2 is used to evaluate the effectiveness of indexing using the phrases extracted by the parser.", "labels": [], "entities": []}, {"text": "The experiment's results show that using syntactic phrases to supplement single words for indexing improves the retrieval performance significantly.", "labels": [], "entities": []}, {"text": "This is quite encouraging compared to earlier experiments on phrase indexing.", "labels": [], "entities": [{"text": "phrase indexing", "start_pos": 61, "end_pos": 76, "type": "TASK", "confidence": 0.8142194151878357}]}, {"text": "The noun phrase parser provides the possibility of combining different kinds of phrases with single words.", "labels": [], "entities": [{"text": "noun phrase parser", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.6434537768363953}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses document indexing, and argues for the rationality of using syntactic phrases for indexing; Section 3 describes the fast noun phrase parser that we use to extract candidate phrases; Section 4 describes how we use a commercial IR system to perform the desired experiments; Section 5 reports and discusses the experiment results; Section 6 summarizes the conclusions.", "labels": [], "entities": [{"text": "document indexing", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.6672352254390717}]}], "datasetContent": [{"text": "We used the CLARIT commercial retrieval system as a retrieval engine to test the effectiveness of different indexing sets.", "labels": [], "entities": []}, {"text": "The CLARIT system uses the vector space retrieval model(Salton and McGill 83), in which documents and the query are all represented by a vector of weighted terms (either single words or phrases), and the relevancy judgment is based on the similarity (measured by the cosine measure) between the query vector and any document vector(Evans et al. 93; Evans and Lefferts 95;).", "labels": [], "entities": []}, {"text": "The experiment procedure is described by.", "labels": [], "entities": []}, {"text": "First, the original database is parsed to form different sets of indexing terms (say, using different combination of phrases).", "labels": [], "entities": []}, {"text": "Then, each indexing set is passed to the CLARIT retrieval engine as a source document set.", "labels": [], "entities": []}, {"text": "The CLARIT system is configured to accept the indexing set we passed as is to ensure that Different combinations of the three kinds of terms can be selected for indexing.", "labels": [], "entities": []}, {"text": "In particular, the indexing set formed solely of single words is used as a baseline to test the effect of using phrases.", "labels": [], "entities": []}, {"text": "In the experiments reported here, we generated four different combinations of phrases: single word only (no phrases, baseline) --WD-HM-SET: The results from these different phrase sets are discussed in the next section.", "labels": [], "entities": [{"text": "WD-HM-SET", "start_pos": 129, "end_pos": 138, "type": "METRIC", "confidence": 0.7813585996627808}]}], "tableCaptions": [{"text": " Table 1: Effects of Phrases with feedback and  TREC-5 topics", "labels": [], "entities": [{"text": "TREC-5", "start_pos": 48, "end_pos": 54, "type": "METRIC", "confidence": 0.995266318321228}]}]}