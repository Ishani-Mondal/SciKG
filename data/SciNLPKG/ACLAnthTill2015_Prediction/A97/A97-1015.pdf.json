{"title": [], "abstractContent": [{"text": "A major concern in corpus based approaches is that the applicability of the acquired knowledge maybe limited by some feature of the corpus, in particular, the notion of text 'domain'.", "labels": [], "entities": []}, {"text": "In order to examine the domain dependence of parsing, in this paper, we report 1) Comparison of structure distributions across domains; 2) Examples of domain specific structures; and 3) Parsing experiment using some domain dependent grammars.", "labels": [], "entities": [{"text": "Parsing experiment", "start_pos": 186, "end_pos": 204, "type": "TASK", "confidence": 0.8443634510040283}]}, {"text": "The observations using the Brown corpus demonstrate domain dependence and idiosyncrasy of syntactic structure.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 27, "end_pos": 39, "type": "DATASET", "confidence": 0.8834713995456696}]}, {"text": "The parsing results show that the best accuracy is obtained using the grammar acquired from the same domain or the same class (fiction or non-fiction).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9991403818130493}]}, {"text": "We will also discuss the relationship between parsing accuracy and the size of training corpus.", "labels": [], "entities": [{"text": "parsing", "start_pos": 46, "end_pos": 53, "type": "TASK", "confidence": 0.9799858331680298}, {"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.9068785905838013}]}], "introductionContent": [{"text": "A major concern in corpus based approaches is that the applicability of the acquired knowledge maybe limited by some feature of the corpus.", "labels": [], "entities": []}, {"text": "In particular, the notion of text 'domain' has been seen as a major constraint on the applicability of the knowledge.", "labels": [], "entities": []}, {"text": "This is a crucial issue for most application systems, since most systems operate within a specific domain and we are generally limited in the corpora available in that domain.", "labels": [], "entities": []}, {"text": "There has been considerable research in this area ().", "labels": [], "entities": []}, {"text": "For example, the domain dependence of lexical semantics is widely known.", "labels": [], "entities": []}, {"text": "It is easy to observe that usage of the word 'bank' is different between the 'economic document' domain and the 'geographic' domain.", "labels": [], "entities": []}, {"text": "Also, there are surveys of domain dependencies concerning syntax or syntaxrelated features.", "labels": [], "entities": []}, {"text": "It is intuitively conceivable that there are syntactic differences between 'telegraphic messages' and 'press report', or between 'weather forecast sentences' and 'romance and love story'.", "labels": [], "entities": []}, {"text": "But, how about the difference between 'press report' and 'romance and love story'?", "labels": [], "entities": []}, {"text": "Is there a general and simple method to compare domains?", "labels": [], "entities": []}, {"text": "More importantly, shall we prepare different knowledge for these two domain sets?", "labels": [], "entities": []}, {"text": "In this paper, we describe two observations and an experiment which suggest an answer to the questions.", "labels": [], "entities": []}, {"text": "Among the several types of linguistic knowledge, we are interested in parsing, the essential component of many NLP systems, and hence domain dependencies of syntactic knowledge.", "labels": [], "entities": [{"text": "parsing", "start_pos": 70, "end_pos": 77, "type": "TASK", "confidence": 0.971592903137207}]}, {"text": "The observations and an experiment are the following: \u2022 Comparison of structure distributions across domains \u2022 Examples of domain specific structures \u2022 Parsing experiment using some domain dependent grammars 2", "labels": [], "entities": []}], "datasetContent": [{"text": "We can see that the result is always the best when the grammar acquired from either the same domain or the same class (fiction or non-fiction) is used.", "labels": [], "entities": []}, {"text": "We will call the division into fiction and non-fiction as 'class'.", "labels": [], "entities": []}, {"text": "It is interesting to see that the grammar acquired from all domains is not the best grammar in any tests.", "labels": [], "entities": []}, {"text": "In other words, if the size of the training corpus is the same, using a training corpus drawn from a wide variety of domains does not help to achieve better parsing performance.", "labels": [], "entities": []}, {"text": "For non-fiction domain texts (A, B, E and J), the performance of the fiction grammar is notably worse than that of the same domain grammar or the same class grammar.", "labels": [], "entities": []}, {"text": "In contrast, the performance on some fiction domain texts (K and L) with the non-fiction grammar is not so different from that of the same domain.", "labels": [], "entities": []}, {"text": "Here, we can find a relationship between these results and the cross entropy observations.", "labels": [], "entities": []}, {"text": "The cross entropies where any of the fiction domains are models and any of the non-fiction domains are test are the highest figures in the table.", "labels": [], "entities": []}, {"text": "This means that the fiction domains are not suitable for modeling the syntactic structure of the non-fiction domains.", "labels": [], "entities": []}, {"text": "On the other hand, the cross entropies where any of the non-fiction domains are models and any of the non-fiction domains (except P) are test have some lower figures.", "labels": [], "entities": []}, {"text": "Except for the case of N with the non-fiction grammar, these observations explains the result of parsing very nicely.", "labels": [], "entities": [{"text": "parsing", "start_pos": 97, "end_pos": 104, "type": "TASK", "confidence": 0.9628788232803345}]}, {"text": "The higher the cross entropy, the worse the parsing performance.", "labels": [], "entities": [{"text": "parsing", "start_pos": 44, "end_pos": 51, "type": "TASK", "confidence": 0.9614062309265137}]}, {"text": "It is not easy to argue why, for some domains, the result is better with the grammar of the same class rather than the same domain.", "labels": [], "entities": []}, {"text": "One rationale we can think of is based on the comparison observation described in section 3.", "labels": [], "entities": []}, {"text": "For example, in the cross comparison experiment, we have seen that domains K, Land N are very close.", "labels": [], "entities": []}, {"text": "So it maybe plausible to say that the grammar of the fiction domains is mainly representing K, Land N and, because it covers wide syntactic structure, it gives better performance for each of these domains.", "labels": [], "entities": []}, {"text": "This could be the explanation that the grammar of fiction domains are superior to the own grammar for the three domains.", "labels": [], "entities": []}, {"text": "In other words, it is a small sampling problem, which can be seen in the next experiment, too.", "labels": [], "entities": []}, {"text": "Because only 24 samples are used, a single domain grammar tends to covers relatively small part of the language phenomena.", "labels": [], "entities": []}, {"text": "On the other hands, a corpus of similar domains could provide wider coverage for the grammar.", "labels": [], "entities": []}, {"text": "The assumption that the fiction domain grammar represents domains of K, Land M may explain that the parsing result of domain P strongly favors the grammar of the same domain compared to that of the fiction class domains.", "labels": [], "entities": []}, {"text": "In this section, the parsing experiments on texts of two domains are reported.", "labels": [], "entities": []}, {"text": "The texts of the two domains are parsed with several grammars, e.g. grammars acquired from different domains or classes, and different sizes of the training corpus.", "labels": [], "entities": []}, {"text": "The size of the training corpus is an interesting and important issue.", "labels": [], "entities": []}, {"text": "We can easily imagine that the smaller the training corpus, the poorer the parsing performance.", "labels": [], "entities": [{"text": "parsing", "start_pos": 75, "end_pos": 82, "type": "TASK", "confidence": 0.9535788297653198}]}, {"text": "However, we don't know which of the following two types of grammar produce better performance: a grammar trained on a smaller corpus of the same domain, or a grammar trained on a larger corpus including different domains. text.", "labels": [], "entities": []}, {"text": "This text is also parsed with 5 different types of grammars.", "labels": [], "entities": []}, {"text": "The graph between the size of training corpus and accuracy is generally an increasing curve with the slope graduMly flattening as the size of the corpus increases.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9996559619903564}]}, {"text": "Note that the small declines of some graphs at large number of samples are mainly due to the memory limitation for parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 115, "end_pos": 122, "type": "TASK", "confidence": 0.9713560938835144}]}, {"text": "Parsing is carried outwith the same memory size, but when the training corpus grows and the grammar becomes large, some long sentences can't be parsed because of data area limitation.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9561961889266968}]}, {"text": "When the data area is exhausted during the parsing, a fitted parsing technique is used to build the most plausible parse tree from the partially parsed trees.", "labels": [], "entities": [{"text": "parsing", "start_pos": 43, "end_pos": 50, "type": "TASK", "confidence": 0.9714625477790833}]}, {"text": "These are generally worse than the trees completely parsed.", "labels": [], "entities": []}, {"text": "It is very interesting to see that the saturation point of any graph is about 10 to 30 samples.", "labels": [], "entities": []}, {"text": "That is about 20,000 to 60,000 words, or about 1,000 to 3,000 sentences.", "labels": [], "entities": []}, {"text": "In the romance and love story domain, the precision of the grammar acquired from 8 samples of the same domain is only about 2% lower than the precision of the grammar trained on 26 samples of the same domain.", "labels": [], "entities": [{"text": "precision", "start_pos": 42, "end_pos": 51, "type": "METRIC", "confidence": 0.9994097948074341}, {"text": "precision", "start_pos": 142, "end_pos": 151, "type": "METRIC", "confidence": 0.9945536851882935}]}, {"text": "We believe that the reason why the performance in this domain saturates with such a small corpus is that there is relatively little variety in the syntactical structure of this domain.", "labels": [], "entities": []}, {"text": "The order of the performance is generally the following: the same domain (best), the same class, all domMns, the other class and the other domain (worst).", "labels": [], "entities": []}, {"text": "The performance of the last two grammars are very close in many cases.", "labels": [], "entities": []}, {"text": "In the romance and love story domain, the grammar acquired from the same domain made the solo best performance.", "labels": [], "entities": []}, {"text": "The difference of the accuracy of the grammars of the same domain and the other domain is quite large.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9991641044616699}]}, {"text": "The results for the press reportage is not so obvious, but the same tendencies can be observed.", "labels": [], "entities": []}, {"text": "In terms of the relationship between the size of training corpus and domain dependency, we will compare the performance of the grammar acquired from 24 samples of the same domain (we will call it 'baseline grammar'), and that of the other grammars.", "labels": [], "entities": []}, {"text": "In the press reportage domain, one needs a three to four times bigger corpus of all domains or non-fiction domains to catch up to the performance of the baseline grammar.", "labels": [], "entities": []}, {"text": "It should be noticed that a quarter of the non-fiction domain corpus and one eighth of the all domain corpus consists of the press report domain corpus.", "labels": [], "entities": [{"text": "press report domain corpus", "start_pos": 125, "end_pos": 151, "type": "DATASET", "confidence": 0.5985482633113861}]}, {"text": "In other words, the fact that the performance of the baseline grammar is about the same as that of 92 samples of the non-fiction domains means that in the latter grammar, the rest of the corpus does not improve or is not harmful for the parsing performance.", "labels": [], "entities": []}, {"text": "In the romance and love story domain, the wide variety grammar, in particular the fiction domain grammar quickly catch up to the performance of the baseline grammar.", "labels": [], "entities": []}, {"text": "It needs only less than twice size of fiction domain corpus to achieve the performance of the baseline grammar.", "labels": [], "entities": []}, {"text": "These two results and the evidence that fiction domains are close in terms of structure indicate that if you have a corpus consisting of similar domains, it is worthwhile to include the corpus in grammar acquisition, otherwise not so useful.", "labels": [], "entities": [{"text": "grammar acquisition", "start_pos": 196, "end_pos": 215, "type": "TASK", "confidence": 0.73320272564888}]}, {"text": "We need to further quantify these trade-offs in terms of the syntactic diversity of individual domains and the difference between domains.", "labels": [], "entities": []}, {"text": "We also find the small sampling problem in this experiment.", "labels": [], "entities": []}, {"text": "In the press reportage experiment, the grammar acquired from the same domain does not make the best performance when the size of the training corpus is small.", "labels": [], "entities": []}, {"text": "We observed the same phenomena in the previous experiment.", "labels": [], "entities": []}], "tableCaptions": []}