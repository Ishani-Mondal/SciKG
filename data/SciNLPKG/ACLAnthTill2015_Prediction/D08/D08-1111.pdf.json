{"title": [{"text": "Information Retrieval Oriented Word Segmentation based on Character Associative Strength Ranking", "labels": [], "entities": [{"text": "Information Retrieval Oriented Word Segmentation", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.8526653587818146}, {"text": "Character Associative Strength", "start_pos": 58, "end_pos": 88, "type": "TASK", "confidence": 0.6996110280354818}]}], "abstractContent": [{"text": "This paper presents a novel, ranking-style word segmentation approach, called RSVM-Seg, which is well tailored to Chinese information retrieval(CIR).", "labels": [], "entities": [{"text": "ranking-style word segmentation", "start_pos": 29, "end_pos": 60, "type": "TASK", "confidence": 0.6246941884358724}, {"text": "Chinese information retrieval(CIR)", "start_pos": 114, "end_pos": 148, "type": "TASK", "confidence": 0.7482837984959284}]}, {"text": "This strategy makes seg-mentation decision based on the ranking of the internal associative strength between each pair of adjacent characters of the sentence.", "labels": [], "entities": []}, {"text": "On the training corpus composed of query items, a ranking model is learned by a widely-used tool Ranking SVM, with some useful statistical features, such as mutual information, difference of t-test, frequency and dictionary information.", "labels": [], "entities": [{"text": "frequency", "start_pos": 199, "end_pos": 208, "type": "METRIC", "confidence": 0.9545491933822632}]}, {"text": "Experimental results show that, this method is able to eliminate overlapping ambiguity much more effectively, compared to the current word segmentation methods.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 134, "end_pos": 151, "type": "TASK", "confidence": 0.7178554087877274}]}, {"text": "Furthermore , as this strategy naturally generates segmentation results with different granular-ity, the performance of CIR systems is improved and achieves the state of the art.", "labels": [], "entities": []}], "introductionContent": [{"text": "To improve information retrieval systems' performance, it is important to comprehend both queries and corpus precisely.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 11, "end_pos": 32, "type": "TASK", "confidence": 0.7367402017116547}]}, {"text": "Unlike English and other western languages, Chinese does not delimit words by white-space.", "labels": [], "entities": []}, {"text": "Word segmentation is therefore a key preprocessor for Chinese information retrieval to comprehend sentences.", "labels": [], "entities": [{"text": "Word segmentation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.6576070636510849}, {"text": "Chinese information retrieval", "start_pos": 54, "end_pos": 83, "type": "TASK", "confidence": 0.6291967133680979}]}, {"text": "Due to the characteristics of Chinese, two main problems remain unresolved in word segmentation: segmentation ambiguity and unknown words, which are also demonstrated to affect the performance of Chinese information retrieval ().", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 78, "end_pos": 95, "type": "TASK", "confidence": 0.7294640690088272}, {"text": "Chinese information retrieval", "start_pos": 196, "end_pos": 225, "type": "TASK", "confidence": 0.5849016805489858}]}, {"text": "Overlapping ambiguity and combinatory ambiguity are two forms of segmentation ambiguity.", "labels": [], "entities": []}, {"text": "The first one refers to that ABC can be segmented into ABC or ABC.", "labels": [], "entities": []}, {"text": "The second one refers to that string AB can be a word, or A can be a word and B can be a word.", "labels": [], "entities": []}, {"text": "In CIR, the combinatory ambiguity is also called segmentation granularity problem.", "labels": [], "entities": []}, {"text": "There are many researches on the relationship between word segmentation and Chinese information retrieval ().", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.7455134689807892}, {"text": "Chinese information retrieval", "start_pos": 76, "end_pos": 105, "type": "TASK", "confidence": 0.6254124045372009}]}, {"text": "Their studies show that the segmentation accuracy does not monotonically influence subsequent retrieval performance.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 28, "end_pos": 40, "type": "TASK", "confidence": 0.9667306542396545}, {"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.7328200340270996}]}, {"text": "Especially the overlapping ambiguity, as shown in experiments of), will cause more performance decrement of CIR.", "labels": [], "entities": []}, {"text": "Thus a CIR system with a word segmenter better solving the overlapping ambiguity, may achieve better performance.", "labels": [], "entities": [{"text": "word segmenter", "start_pos": 25, "end_pos": 39, "type": "TASK", "confidence": 0.6891171783208847}]}, {"text": "Besides, it also showed that the precision of new word identification was more important than the recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9994008541107178}, {"text": "word identification", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.7269693613052368}, {"text": "recall", "start_pos": 98, "end_pos": 104, "type": "METRIC", "confidence": 0.9970664381980896}]}, {"text": "There are some researches show that when compound words are split into smaller constituents, better retrieval results can be achieved ().", "labels": [], "entities": []}, {"text": "On the other hand, it is reasonable that the longer the word which co-exists in query and corpus, the more similarity they may have.", "labels": [], "entities": []}, {"text": "A hypothesis, therefore, comes to our mind, that different segmentation granularity can be incorporated to obtain better CIR performance.", "labels": [], "entities": []}, {"text": "In this paper we present a novel word segmentation approach for CIR, which cannot only obviously reduce the overlapping ambiguity, but also introduce different segmentation granularity for the first time.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.7103640288114548}]}, {"text": "In our method, we first predict the ranking result of all internal association strength (IAS) between each pair of adjacent characters in a sentence using Ranking SVM model, and then, we segment the sentence into sub-sentences with smaller and smaller granularity by cutting adjacent character pairs according to this rank.", "labels": [], "entities": [{"text": "internal association strength (IAS)", "start_pos": 58, "end_pos": 93, "type": "METRIC", "confidence": 0.8278412421544393}]}, {"text": "Other machine-learning based segmentation algorithms () treat segmentation problem as a character sequence tagging problem based on classification.", "labels": [], "entities": [{"text": "segmentation problem", "start_pos": 62, "end_pos": 82, "type": "TASK", "confidence": 0.913084089756012}, {"text": "character sequence tagging", "start_pos": 88, "end_pos": 114, "type": "TASK", "confidence": 0.6828665932019552}]}, {"text": "However, these methods cannot directly obtain different segmentation granularity.", "labels": [], "entities": []}, {"text": "Experiments show that our method can actually improve information retrieval performance.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 54, "end_pos": 75, "type": "TASK", "confidence": 0.8313857018947601}]}, {"text": "This paper is structured as follows.", "labels": [], "entities": []}, {"text": "It starts with a brief introduction of the related work on the word segmentation approaches.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 63, "end_pos": 80, "type": "TASK", "confidence": 0.7433531880378723}]}, {"text": "Then in Section 3, we introduce our segmentation method.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 36, "end_pos": 48, "type": "TASK", "confidence": 0.9833980798721313}]}, {"text": "Section 4 evaluates the method based on experimental results.", "labels": [], "entities": []}, {"text": "Finally, Section 5 makes summary of this whole paper and proposes the future research orientation.", "labels": [], "entities": []}], "datasetContent": [{"text": "Since the label scheme and evaluation measure (described in next subsection) of our segmentation method are both different from the traditional segmentation methods, we did not carryout experiments on SIGHAN.", "labels": [], "entities": [{"text": "SIGHAN", "start_pos": 201, "end_pos": 207, "type": "DATASET", "confidence": 0.6728444695472717}]}, {"text": "Instead, we used two query logs (QueryLog1 and QueryLog2) as our experiment corpus, which are from two Chinese search engine companies.", "labels": [], "entities": []}, {"text": "900 queries randomly from QueryLog1 were chosen as training corpus.", "labels": [], "entities": []}, {"text": "110 Chinese queries from PKU Tianwang 1 , randomly selected 150 queries from QueryLog1 and 100 queries from QueryLog2 were used as test corpus.", "labels": [], "entities": [{"text": "PKU Tianwang 1", "start_pos": 25, "end_pos": 39, "type": "DATASET", "confidence": 0.9263863762219747}]}, {"text": "The train and test corpus have been tagged by three people.", "labels": [], "entities": []}, {"text": "They were given written information need statements, and were asked to judge the IAS of every two adjacent characters in a sentence on a three level scale as mentioned above, separable, partially inseparable, and definitely inseparable.", "labels": [], "entities": [{"text": "IAS", "start_pos": 81, "end_pos": 84, "type": "METRIC", "confidence": 0.7424505949020386}]}, {"text": "The assessors agreed in 84% of the sentences, the other sentences were checked Title field of SEWM2006 and SEWM2007 web retrieval TD task topics.", "labels": [], "entities": [{"text": "Title field", "start_pos": 79, "end_pos": 90, "type": "METRIC", "confidence": 0.6251407265663147}, {"text": "SEWM2006", "start_pos": 94, "end_pos": 102, "type": "DATASET", "confidence": 0.9621179103851318}, {"text": "SEWM2007 web retrieval TD task", "start_pos": 107, "end_pos": 137, "type": "DATASET", "confidence": 0.9307419657707214}]}, {"text": "See http://www.cwirf.org/ by all assessors, and a more plausible alternative was selected.", "labels": [], "entities": []}, {"text": "We exploited SV M light2 as the toolkit to implement Ranking SVM model.", "labels": [], "entities": []}, {"text": "Since our approach is based on the ranking of IAS values, it is inappropriate to evaluate our method by the traditional method used in other segmentation algorithms.", "labels": [], "entities": []}, {"text": "Here, we proposed an evaluation measure RankPrecision based on, which compared the similarity between the predicted ranking of IAS values and the rankings of these tags as descending order.", "labels": [], "entities": []}, {"text": "RankPrecision formula is as follows: where s i represents the ith sentence (unsegmented string), InverseCount(s i ) represents the number of discordant pairs inversions in the ranking of the predicted IAS value compared to the correct labeled ranking.", "labels": [], "entities": [{"text": "InverseCount", "start_pos": 97, "end_pos": 109, "type": "METRIC", "confidence": 0.9862048029899597}]}, {"text": "CompInverseCount(s i ) represents the number of discordant pairs inversions when the labels totally inverse.", "labels": [], "entities": []}, {"text": "Contributions of the Features: We investigated the contribution of each feature by generating many versions of Ranking SVM model.", "labels": [], "entities": []}, {"text": "RankPrecision as described above was used for evaluations in these and following experiments.", "labels": [], "entities": []}, {"text": "We used Mutual Information(MI); Difference of T-Score(DTS); Frequency(F); mutual information and difference of t-score(MI+DTS); mu-  .90 .92 .94 .96 .98 1.00", "labels": [], "entities": [{"text": "Frequency(F)", "start_pos": 60, "end_pos": 72, "type": "METRIC", "confidence": 0.9638759344816208}, {"text": "mu-  .90 .92 .94 .96 .98 1.00", "start_pos": 128, "end_pos": 157, "type": "DATASET", "confidence": 0.7023842999568353}]}], "tableCaptions": [{"text": " Table 1: Example of feature vector", "labels": [], "entities": []}, {"text": " Table 2: The segmentation performance with different  features", "labels": [], "entities": [{"text": "segmentation", "start_pos": 14, "end_pos": 26, "type": "TASK", "confidence": 0.9896422028541565}]}, {"text": " Table 3: The segmentation performance with different  size training corpus", "labels": [], "entities": [{"text": "segmentation", "start_pos": 14, "end_pos": 26, "type": "TASK", "confidence": 0.9874199032783508}]}, {"text": " Table 4: Number of Overlapping Ambiguity", "labels": [], "entities": [{"text": "Number", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9038112759590149}, {"text": "Ambiguity", "start_pos": 32, "end_pos": 41, "type": "TASK", "confidence": 0.2766658365726471}]}]}