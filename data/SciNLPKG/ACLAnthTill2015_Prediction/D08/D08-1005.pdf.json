{"title": [{"text": "One-Class Clustering in the Text Domain", "labels": [], "entities": []}], "abstractContent": [{"text": "Having seen a news title \"Alba denies wedding reports\", how do we infer that it is primarily about Jessica Alba, rather than about weddings or reports?", "labels": [], "entities": []}, {"text": "We probably realize that, in a randomly driven sentence, the word \"Alba\" is less anticipated than \"wedding\" or \"reports\", which adds value to the word \"Alba\" if used.", "labels": [], "entities": []}, {"text": "Such anticipation can be modeled as a ratio between an empirical probability of the word (in a given corpus) and its estimated probability in general English.", "labels": [], "entities": []}, {"text": "Aggregated overall words in a document, this ratio maybe used as a measure of the document's topicality.", "labels": [], "entities": []}, {"text": "Assuming that the corpus consists of on-topic and off-topic documents (we call them the core and the noise), our goal is to determine which documents belong to the core.", "labels": [], "entities": []}, {"text": "We propose two unsupervised methods for doing this.", "labels": [], "entities": []}, {"text": "First, we assume that words are sampled i.i.d., and propose an information-theoretic framework for determining the core.", "labels": [], "entities": []}, {"text": "Second, we relax the independence assumption and use a simple graphical model to rank documents according to their likelihood of belonging to the core.", "labels": [], "entities": []}, {"text": "We discuss theoretical guarantees of the proposed methods and show their usefulness for Web Mining and Topic Detection and Tracking (TDT).", "labels": [], "entities": [{"text": "Topic Detection and Tracking (TDT)", "start_pos": 103, "end_pos": 137, "type": "TASK", "confidence": 0.8464630331311908}]}], "introductionContent": [{"text": "Many intelligent applications in the text domain aim at determining whether a document (a sentence, a snippet etc.) is on-topic or off-topic.", "labels": [], "entities": []}, {"text": "In some applications, topics are explicitly given.", "labels": [], "entities": []}, {"text": "In binary text classification, for example, the topic is described in terms of positively and negatively labeled documents.", "labels": [], "entities": [{"text": "binary text classification", "start_pos": 3, "end_pos": 29, "type": "TASK", "confidence": 0.6820844014485677}]}, {"text": "In information retrieval, the topic is imposed by a query.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 3, "end_pos": 24, "type": "TASK", "confidence": 0.8089694678783417}]}, {"text": "In many other applications, the topic is unspecified, however, its existence is assumed.", "labels": [], "entities": []}, {"text": "Examples of such applications are within text summarization (extract the most topical sentences), text clustering (group documents that are close topically), novelty detection (reason whether or not test documents are on the same topic as training documents), spam filtering (reject incoming email messages that are too far topically from the content of a personal email repository), etc.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.7064209282398224}, {"text": "text clustering", "start_pos": 98, "end_pos": 113, "type": "TASK", "confidence": 0.7604313790798187}, {"text": "novelty detection", "start_pos": 158, "end_pos": 175, "type": "TASK", "confidence": 0.7307177931070328}, {"text": "spam filtering", "start_pos": 260, "end_pos": 274, "type": "TASK", "confidence": 0.8744724988937378}]}, {"text": "Under the (standard) Bag-Of-Words (BOW) representation of a document, words are the functional units that bear the document's topic.", "labels": [], "entities": []}, {"text": "Since some words are topical and some are not, the problem of detecting on-topic documents has a dual formulation of detecting topical words.", "labels": [], "entities": []}, {"text": "This paper deals with the following questions: (a) Which words can be considered topical?", "labels": [], "entities": []}, {"text": "(b) How can topical words be detected?", "labels": [], "entities": []}, {"text": "(c) How can on-topic documents be detected given a set of topical words?", "labels": [], "entities": []}, {"text": "The BOW formalism is usually translated into the generative modeling terms by representing documents as multinomial word distributions.", "labels": [], "entities": [{"text": "generative modeling", "start_pos": 49, "end_pos": 68, "type": "TASK", "confidence": 0.9532873630523682}]}, {"text": "For the on-topic/off-topic case, we assume that words in a document are sampled from a mixture of two multinomials: one over topical words and another one over general English (i.e. the background).", "labels": [], "entities": []}, {"text": "Obviously enough, the support of the \"topic\" multinomial is significantly smaller than the support of the background.", "labels": [], "entities": []}, {"text": "A document's topicality is then determined by aggregating the topicality of its words (see below for details).", "labels": [], "entities": []}, {"text": "Note that by introducing the background distribution we refrain from explicitly modeling the class of off-topic documents-a document is supposed to be off-topic if it is \"not topical enough\".", "labels": [], "entities": []}, {"text": "Such a formulation of topicality prescribes using the one-class modeling paradigm, as opposed to sticking to the binary case.", "labels": [], "entities": []}, {"text": "Besides being much less widely studied and therefore much more attractive from the scientific point of view, one-class models appear to be more adequate for many real-world tasks, where negative examples are not straightforwardly observable.", "labels": [], "entities": []}, {"text": "One-class models separate the desired class of data instances (the core) from other data instances (the noise).", "labels": [], "entities": []}, {"text": "Structure of noise is either unknown, or too complex to be explicitly modeled.", "labels": [], "entities": []}, {"text": "One-class problems are traditionally approached using vector-space methods, where a convex decision boundary is built around the data instances of the desired class, separating it from the rest of the universe.", "labels": [], "entities": []}, {"text": "In the text domain, however, those vectorspace models are questionably applicable-unlike effective binary vector-space models.", "labels": [], "entities": []}, {"text": "In binary models, decision boundaries are linear 1 , whereas in (vector-space) one-class models, the boundaries are usually hyperspherical.", "labels": [], "entities": []}, {"text": "Intuitively, since core documents tend to lie on a lower-dimensional manifold, inducing hyperspherical boundaries maybe sub-optimal as they tend to either capture just a portion of the core, or capture too much space around it (see illustration in).", "labels": [], "entities": []}, {"text": "Here we propose alternative ways for detecting the core, which work well in text.", "labels": [], "entities": []}, {"text": "One-class learning problems have been studied as either outlier detection or identifying a small coherent subset.", "labels": [], "entities": [{"text": "outlier detection", "start_pos": 56, "end_pos": 73, "type": "TASK", "confidence": 0.7075098156929016}]}, {"text": "In one-class outlier detection), the goal is to identify a few outliers from the given set of examples, where the vast majority of the examples are considered relevant.", "labels": [], "entities": [{"text": "one-class outlier detection", "start_pos": 3, "end_pos": 30, "type": "TASK", "confidence": 0.6632456878821055}]}, {"text": "Alternatively, a complementary goal is to distill a subset of relevant examples, in the space with many outliers (.", "labels": [], "entities": []}, {"text": "Most of the one-class approaches employ geometrical concepts to capture the notion of relevancy (or irrelevancy) using either hyperplanes () or hyperspheres.", "labels": [], "entities": []}, {"text": "In this paper we adopt the latter approach: we formulate one-class clustering in text as an optimization task of identifying the most coherent subset (the core) of k documents drawn from a given pool of n > k documents.", "labels": [], "entities": []}, {"text": "Given a collection D of on-topic and off-topic documents, we assume that on-topic documents share a portion of their vocabulary that consists of \"relatively rare\" words, i.e. words that are used in D more often than they are used in general English.", "labels": [], "entities": []}, {"text": "We call them topical words.", "labels": [], "entities": []}, {"text": "For example, if some documents in D share words such as \"Bayesian\", \"classifier\", \"reinforcement\" and other machine learning terms (infrequent in general English), whereas other documents do not seem to share any subset of words (besides stopwords), then we conclude that the machine learning documents compose the core of D, while non-machine learning documents are noise.", "labels": [], "entities": []}, {"text": "We express the level of topicality of a word win terms of the ratio \u03c1(w) = p(w) q(w) , where p(w) is w's empirical probability (in D), and q(w) is its estimated probability in general English.", "labels": [], "entities": []}, {"text": "We discuss an interesting characteristic of \u03c1(w): if Dis large enough, then, with high probability, \u03c1(w) values are greater for topical words than for non-topical words.", "labels": [], "entities": []}, {"text": "Therefore, \u03c1(w) can be used as a mean to measure the topicality of w.", "labels": [], "entities": []}, {"text": "Obviously, the quality of this measure depends on the quality of estimating q(w), i.e. the general English word distribution, which is usually estimated over a large text collection.", "labels": [], "entities": []}, {"text": "The larger the collection is, the better would be the estimation.", "labels": [], "entities": [{"text": "estimation", "start_pos": 54, "end_pos": 64, "type": "METRIC", "confidence": 0.9923402070999146}]}, {"text": "Recently, Google has released the Web 1T dataset 3 that provides q(w) estimated on a text collection of one trillion tokens.", "labels": [], "entities": [{"text": "Web 1T dataset 3", "start_pos": 34, "end_pos": 50, "type": "DATASET", "confidence": 0.8046780824661255}]}, {"text": "We use it in our experimentation.", "labels": [], "entities": []}, {"text": "We propose two methods that use the \u03c1 ratio to The parameter k is analogous to the number of clusters in (multi-class) clustering, as well as to the number of outliers) or the radius of Bregmanian ball)-in other formulations of one-class clustering.", "labels": [], "entities": []}, {"text": "solve the one-class clustering problem.", "labels": [], "entities": [{"text": "one-class clustering", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.49525879323482513}]}, {"text": "First, we express documents' topicality in terms of aggregating their words' \u03c1 ratios into an information-theoretic \"topicality measure\".", "labels": [], "entities": []}, {"text": "The core is then composed of k documents with the highest topicality measure.", "labels": [], "entities": []}, {"text": "We show that the proposed measure is optimal for constructing the core cluster among documents of equal length.", "labels": [], "entities": []}, {"text": "However, our method is not useful in a setup where some long documents have a topical portion: such documents should be considered on-topic, but their heavy tail of background words overcomes the topical words' influence.", "labels": [], "entities": []}, {"text": "We generalize our method to non-equally-long documents by first extracting words that are supposed to be topical and then projecting documents over those words.", "labels": [], "entities": []}, {"text": "Such projection preserves the optimality characteristic and results in constructing a more accurate core cluster in practice.", "labels": [], "entities": []}, {"text": "We call such a method of choosing both topical words and core documents OneClass Co-Clustering (OCCC).", "labels": [], "entities": []}, {"text": "It turns out that our OCCC method's performance depends heavily on choosing the number of topical words.", "labels": [], "entities": []}, {"text": "We propose a heuristic for setting this number.", "labels": [], "entities": []}, {"text": "As another alternative, we propose a method that does not require tuning this parameter: we use words' \u03c1 ratios to initialize an EM algorithm that computes the likelihood of documents to belong to the core-we then choose k documents of maximal likelihood.", "labels": [], "entities": []}, {"text": "We call this model the Latent Topic/Background (LTB) model.", "labels": [], "entities": []}, {"text": "LTB outperforms OCCC inmost of our test cases.", "labels": [], "entities": [{"text": "LTB", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.7435050010681152}, {"text": "OCCC", "start_pos": 16, "end_pos": 20, "type": "DATASET", "confidence": 0.7640283703804016}]}, {"text": "Our one-class clustering models have interesting cross-links with models applied to other Information Retrieval tasks.", "labels": [], "entities": [{"text": "Information Retrieval tasks", "start_pos": 90, "end_pos": 117, "type": "TASK", "confidence": 0.8662299116452535}]}, {"text": "For example, a model that resembles our OCCC, is proposed by for query performance prediction.", "labels": [], "entities": [{"text": "OCCC", "start_pos": 40, "end_pos": 44, "type": "DATASET", "confidence": 0.754326581954956}, {"text": "query performance prediction", "start_pos": 65, "end_pos": 93, "type": "TASK", "confidence": 0.7650771339734396}]}, {"text": "describe a pseudo-relevance feedback model that is similar to our LTB.", "labels": [], "entities": []}, {"text": "These types of cross-links are common for the models that are general enough and relatively simple.", "labels": [], "entities": []}, {"text": "In this paper we put particular emphasis on the simplicity of our models, such that they are feasible for theoretical analysis as well as for efficient implementation.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our OCCC and LTB models on two applications: a Web Mining task (Section 5.1), and a Topic Detection and Tracking (TDT)) task (Section 5.2).", "labels": [], "entities": [{"text": "Topic Detection and Tracking (TDT)) task", "start_pos": 96, "end_pos": 136, "type": "TASK", "confidence": 0.8286700211465359}]}, {"text": "To define our evaluation criteria, let C be the constructed cluster and let Cr be its portion consisting of documents that actually belong to the core.", "labels": [], "entities": []}, {"text": "We define precision as Prec = |C r |/|C|, recall as Rec = |C r |/k and F-measure as (2 Prec Rec)/(Prec+Rec).", "labels": [], "entities": [{"text": "precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.999360978603363}, {"text": "Prec", "start_pos": 23, "end_pos": 27, "type": "METRIC", "confidence": 0.9557610750198364}, {"text": "Rec", "start_pos": 52, "end_pos": 55, "type": "METRIC", "confidence": 0.9804988503456116}, {"text": "F-measure", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9820325970649719}]}, {"text": "Unless stated otherwise, in our experiments we fix |C| = k, such that precision equals recall and is then called one-class clustering accuracy, or just accuracy.", "labels": [], "entities": [{"text": "precision", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9992443323135376}, {"text": "recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9987534284591675}, {"text": "accuracy", "start_pos": 134, "end_pos": 142, "type": "METRIC", "confidence": 0.8962975144386292}, {"text": "accuracy", "start_pos": 152, "end_pos": 160, "type": "METRIC", "confidence": 0.9962816834449768}]}, {"text": "We applied our one-class clustering methods in four setups: \u2022 OCCC with the heuristic to choose m r (from Section 3.1).", "labels": [], "entities": [{"text": "OCCC", "start_pos": 62, "end_pos": 66, "type": "DATASET", "confidence": 0.7006142139434814}]}, {"text": "\u2022 OCCC with optimal m r . We unfairly choose the number m r of topical words such that the resulting accuracy is maximal.", "labels": [], "entities": [{"text": "OCCC", "start_pos": 2, "end_pos": 6, "type": "DATASET", "confidence": 0.6641722917556763}, {"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.999240517616272}]}, {"text": "This setup can be considered as the upper limit of the OCCC's performance, which can be hypothetically achieved if a better heuristic for choosing m r is proposed.", "labels": [], "entities": []}, {"text": "\u2022 LTB initialized with \u03c0 i = 0.5 (for each i).", "labels": [], "entities": [{"text": "LTB", "start_pos": 2, "end_pos": 5, "type": "METRIC", "confidence": 0.6247245073318481}]}, {"text": "As we show in Section 5.1 below, the LTB model demonstrates good performance with this straightforward initialization.", "labels": [], "entities": []}, {"text": "\u2022 LTB initialized with \u03c0 i = pd . Quite naturally, the number of topical words in a dataset depends on the number of core documents.", "labels": [], "entities": []}, {"text": "For example, if the core is only 10% of a dataset, it is unrealistic to assume that 50% of all words are topical.", "labels": [], "entities": []}, {"text": "In this setup, we condition the ratio of topical words on the ratio of core documents.", "labels": [], "entities": []}, {"text": "We compare our methods with two existing algorithms: (a) One-Class SVM clustering 6); (b) One-Class Rate Distortion (OC-RD)).", "labels": [], "entities": [{"text": "SVM clustering", "start_pos": 67, "end_pos": 81, "type": "TASK", "confidence": 0.7925227582454681}]}, {"text": "The later is considered a state-of-the-art in one-class clustering.", "labels": [], "entities": [{"text": "one-class clustering", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.5880947411060333}]}, {"text": "Also, to establish the lowest baseline, we show the result of a random assignment of documents to the core D k . The OC-RD algorithm is based on rate-distortion theory and expresses the one-class problem as a lossy coding of each instance into a few possible instance-dependent codewords.", "labels": [], "entities": []}, {"text": "Each document is represented as a distribution over words, and the KLdivergence is used as a distortion function (generally, it can be any Bregman function).", "labels": [], "entities": []}, {"text": "The algorithm also uses an \"inverse temperature\" parameter (denoted by \u03b2) that represents the tradeoff between compression and distortion.", "labels": [], "entities": []}, {"text": "An annealing process is employed, in which the algorithm is applied with a sequence of increasing values of \u03b2, when initialized with the result obtained at the previous itera- 48.8% 63.6 \u00b1 3.5% OCCC with them r heuristic 80.2% 61.4 \u00b1 4.5% OCCC with optimal m 82.4% 68.3 \u00b1 3.6% LTB initialized with \u03c0 i = 0.5 79.8% 65.3 \u00b1 7.3% LTB initialized with \u03c0i = pd 78.3% 68.0 \u00b1 5.9%: One-class clustering accuracy of our OCCC and LTB models on the WAD and the TW detection tasks, as compared to OC-SVM and OC-RD.", "labels": [], "entities": [{"text": "OCCC", "start_pos": 194, "end_pos": 198, "type": "METRIC", "confidence": 0.8380184173583984}, {"text": "accuracy", "start_pos": 395, "end_pos": 403, "type": "METRIC", "confidence": 0.9504879117012024}, {"text": "TW detection tasks", "start_pos": 450, "end_pos": 468, "type": "TASK", "confidence": 0.7937856316566467}]}, {"text": "For TW, the accuracies are macro-averaged over the 26 weekly chunks, with the standard error of the mean presented after the \u00b1 sign. tion.", "labels": [], "entities": [{"text": "TW", "start_pos": 4, "end_pos": 6, "type": "DATASET", "confidence": 0.649756908416748}, {"text": "accuracies", "start_pos": 12, "end_pos": 22, "type": "METRIC", "confidence": 0.9913333058357239}]}, {"text": "The outcome is a sequence of cores with decreasing sizes.", "labels": [], "entities": []}, {"text": "The annealing process is stopped once the largest core size is equal to k.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Most highly ranked words by OCCC and LTB,  on the WAD dataset.", "labels": [], "entities": [{"text": "OCCC", "start_pos": 38, "end_pos": 42, "type": "DATASET", "confidence": 0.8941499590873718}, {"text": "WAD dataset", "start_pos": 60, "end_pos": 71, "type": "DATASET", "confidence": 0.8702101707458496}]}]}