{"title": [{"text": "When Harry Met Harri, 1234 and 12: Cross-lingual Name Spelling Normalization", "labels": [], "entities": [{"text": "Cross-lingual Name Spelling Normalization", "start_pos": 35, "end_pos": 76, "type": "TASK", "confidence": 0.7828341200947762}]}], "abstractContent": [{"text": "Foreign name translations typically include multiple spelling variants.", "labels": [], "entities": []}, {"text": "These variants cause data sparseness problems, increase Out-of-Vocabulary (OOV) rate, and present challenges for machine translation, information extraction and other NLP tasks.", "labels": [], "entities": [{"text": "Out-of-Vocabulary (OOV) rate", "start_pos": 56, "end_pos": 84, "type": "METRIC", "confidence": 0.944856333732605}, {"text": "machine translation", "start_pos": 113, "end_pos": 132, "type": "TASK", "confidence": 0.8169628083705902}, {"text": "information extraction", "start_pos": 134, "end_pos": 156, "type": "TASK", "confidence": 0.799695760011673}]}, {"text": "This paper aims to identify name spelling variants in the target language using the source name as an anchor.", "labels": [], "entities": [{"text": "name spelling variants", "start_pos": 28, "end_pos": 50, "type": "TASK", "confidence": 0.792653093735377}]}, {"text": "Based on word-to-word translation and transliteration probabilities, as well as the string edit distance metric, target name translations with similar spellings are clustered.", "labels": [], "entities": [{"text": "word-to-word translation", "start_pos": 9, "end_pos": 33, "type": "TASK", "confidence": 0.6804692298173904}]}, {"text": "With this approach tens of thousands of high precision name translation spelling variants are extracted from sentence-aligned bilingual corpora.", "labels": [], "entities": [{"text": "name translation spelling variants", "start_pos": 55, "end_pos": 89, "type": "TASK", "confidence": 0.8314401805400848}]}, {"text": "When these name spelling variants are applied to Machine Translation and Information Extraction tasks, improvements over strong baseline systems are observed in both cases.", "labels": [], "entities": [{"text": "Machine Translation and Information Extraction tasks", "start_pos": 49, "end_pos": 101, "type": "TASK", "confidence": 0.7903538147608439}]}], "introductionContent": [{"text": "Foreign names typically have multiple spelling variants after translation, as seen in the following examples: These spelling variants present challenges for many NLP tasks, increasing vocabulary size and OOV rate, exacerbating the data sparseness problem and reducing the readability of MT output when different spelling variants are generated for the same name in one document.", "labels": [], "entities": [{"text": "OOV rate", "start_pos": 204, "end_pos": 212, "type": "METRIC", "confidence": 0.9792957901954651}, {"text": "MT output", "start_pos": 287, "end_pos": 296, "type": "TASK", "confidence": 0.9081604778766632}]}, {"text": "We address this problem by replacing each spelling variant with its corresponding canonical form.", "labels": [], "entities": []}, {"text": "Such text normalization could potentially benefit many NLP tasks including information retrieval, information extraction, question answering, speech recognition and machine translation.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 5, "end_pos": 23, "type": "TASK", "confidence": 0.7457678616046906}, {"text": "information retrieval", "start_pos": 75, "end_pos": 96, "type": "TASK", "confidence": 0.8056896924972534}, {"text": "information extraction", "start_pos": 98, "end_pos": 120, "type": "TASK", "confidence": 0.8209304213523865}, {"text": "question answering", "start_pos": 122, "end_pos": 140, "type": "TASK", "confidence": 0.8858208358287811}, {"text": "speech recognition", "start_pos": 142, "end_pos": 160, "type": "TASK", "confidence": 0.7593802213668823}, {"text": "machine translation", "start_pos": 165, "end_pos": 184, "type": "TASK", "confidence": 0.78630131483078}]}, {"text": "Research on name spelling variants has been studied mostly in Information Retrieval research, especially in query expansion and cross-lingual IR.", "labels": [], "entities": [{"text": "name spelling variants", "start_pos": 12, "end_pos": 34, "type": "TASK", "confidence": 0.7552521129449209}, {"text": "Information Retrieval", "start_pos": 62, "end_pos": 83, "type": "TASK", "confidence": 0.8301444947719574}, {"text": "query expansion", "start_pos": 108, "end_pos": 123, "type": "TASK", "confidence": 0.7732812166213989}, {"text": "cross-lingual IR", "start_pos": 128, "end_pos": 144, "type": "TASK", "confidence": 0.5468885004520416}]}, {"text": "proposed two approaches for spelling variants generation, based on the letters-to-phonemes mapping and Soundex algorithm.", "labels": [], "entities": [{"text": "spelling variants generation", "start_pos": 28, "end_pos": 56, "type": "TASK", "confidence": 0.7962438662846884}]}, {"text": "proposed several techniques to group names in ASR output and evaluated their effectiveness in spoken document retrieval (SDR).", "labels": [], "entities": [{"text": "ASR output", "start_pos": 46, "end_pos": 56, "type": "TASK", "confidence": 0.8421658277511597}, {"text": "spoken document retrieval (SDR)", "start_pos": 94, "end_pos": 125, "type": "TASK", "confidence": 0.7868910133838654}]}, {"text": "Both approaches use a named entity extraction system to automatically identify names.", "labels": [], "entities": [{"text": "named entity extraction", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.7451878190040588}]}, {"text": "For multi-lingual name spelling variants, proposed to use a general edit distance metric with a weighted FST to find technical term translations (which were referred to as \"cross-lingual spelling variants\").", "labels": [], "entities": [{"text": "multi-lingual name spelling variants", "start_pos": 4, "end_pos": 40, "type": "TASK", "confidence": 0.6980475038290024}, {"text": "FST", "start_pos": 105, "end_pos": 108, "type": "METRIC", "confidence": 0.9937771558761597}]}, {"text": "These variants are typically translated words with similar stems in another language.", "labels": [], "entities": []}, {"text": "Toivonen and colleagues proposed a two-step fuzzy translation technique to solve similar problems., and investigated the general name entity translation problem, especially in the context of machine translation.", "labels": [], "entities": [{"text": "fuzzy translation", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.7780550122261047}, {"text": "general name entity translation problem", "start_pos": 121, "end_pos": 160, "type": "TASK", "confidence": 0.6504767417907715}, {"text": "machine translation", "start_pos": 191, "end_pos": 210, "type": "TASK", "confidence": 0.8087866306304932}]}, {"text": "This paper aims to identify mono-lingual name spelling variants using cross-lingual information.", "labels": [], "entities": [{"text": "mono-lingual name spelling variants", "start_pos": 28, "end_pos": 63, "type": "TASK", "confidence": 0.7664320468902588}]}, {"text": "Instead of using a named entity tagger to identify name spelling variants, we treat names in one language as the anchor of spelling variants in another language.", "labels": [], "entities": []}, {"text": "From sentence-aligned bilingual corpora we collect word co-occurrence statistics and calculate word translation 1 probabilities.", "labels": [], "entities": []}, {"text": "For each source word, we group its target translations into clusters according to string edit distances, then calculate the transliteration cost between the source word and each target translation cluster.", "labels": [], "entities": []}, {"text": "Word pairs with small transliteration costs are considered as name translations, and the target cluster contains multiple spelling variants corresponding to the source name.", "labels": [], "entities": [{"text": "name translations", "start_pos": 62, "end_pos": 79, "type": "TASK", "confidence": 0.7260275930166245}]}, {"text": "We apply this approach to extract name transliteration spelling variants from bilingual corpora.", "labels": [], "entities": [{"text": "extract name transliteration spelling variants from bilingual corpora", "start_pos": 26, "end_pos": 95, "type": "TASK", "confidence": 0.7764714658260345}]}, {"text": "We obtained tens of thousands of high precision name translation pairs.", "labels": [], "entities": [{"text": "name translation", "start_pos": 48, "end_pos": 64, "type": "TASK", "confidence": 0.7096438407897949}]}, {"text": "We further apply these spelling variants to Machine Translation (MT) and Information Extraction (IE) tasks, and observed statistically significant improvement on the IE task, and close to oracle improvement on the MT task.", "labels": [], "entities": [{"text": "Machine Translation (MT) and Information Extraction (IE) tasks", "start_pos": 44, "end_pos": 106, "type": "TASK", "confidence": 0.8114113186796507}, {"text": "MT task", "start_pos": 214, "end_pos": 221, "type": "TASK", "confidence": 0.859955370426178}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2 we describe the technique to identify name spelling variants from bilingual data.", "labels": [], "entities": [{"text": "identify name spelling variants", "start_pos": 42, "end_pos": 73, "type": "TASK", "confidence": 0.6767207533121109}]}, {"text": "In section 3 and 4 we address their application to MT and IE respectively.", "labels": [], "entities": [{"text": "MT", "start_pos": 51, "end_pos": 53, "type": "TASK", "confidence": 0.8575713634490967}, {"text": "IE", "start_pos": 58, "end_pos": 60, "type": "METRIC", "confidence": 0.5881397724151611}]}, {"text": "We present our experiment results and detailed analysis in section 5.", "labels": [], "entities": []}, {"text": "Section 6 concludes this paper with future work.", "labels": [], "entities": []}, {"text": "In this paper, the translation cost measures the semantic difference between source and target names, which are estimated from their co-occurrence statistics.", "labels": [], "entities": [{"text": "translation", "start_pos": 19, "end_pos": 30, "type": "TASK", "confidence": 0.9669373631477356}]}, {"text": "The transliteration cost measures their phonetic distance and are estimated based on a character transliteration model.", "labels": [], "entities": []}, {"text": "Starting from sentence-aligned parallel data, we run HMM alignment) to obtain a word translation model.", "labels": [], "entities": [{"text": "HMM alignment", "start_pos": 53, "end_pos": 66, "type": "TASK", "confidence": 0.7628270983695984}, {"text": "word translation", "start_pos": 80, "end_pos": 96, "type": "TASK", "confidence": 0.7380852103233337}]}, {"text": "For each source word this model generates target candidate translations as well as their translation probabilities.", "labels": [], "entities": []}, {"text": "A typical entry is shown in.", "labels": [], "entities": []}, {"text": "It can be observed that the Arabic name's translations include several English words with similar spellings, all of which are correct translations.", "labels": [], "entities": []}, {"text": "However, because the lexical translation probabilities are distributed among these variants, none of them has the highest probability.", "labels": [], "entities": []}, {"text": "As a result, the incorrect translation, iqlim, is assigned the highest probability and often selected in MT output.", "labels": [], "entities": [{"text": "MT", "start_pos": 105, "end_pos": 107, "type": "TASK", "confidence": 0.9514948725700378}]}, {"text": "To fix this problem, it is desirable to identify and group these target spelling variants, convert them into a canonical form and merge their translation probabilities.", "labels": [], "entities": []}, {"text": "For each source word in the word translation model, we cluster its target translations based on string edit distances using group average agglomerative clustering algorithm).", "labels": [], "entities": [{"text": "word translation", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.7225773334503174}]}, {"text": "Initially each target word is a single word cluster.", "labels": [], "entities": []}, {"text": "We calculate the average editing distance between any two clusters, and merge them if the distance is smaller than a certain threshold.", "labels": [], "entities": []}, {"text": "This process repeats until the minimum distance between any two clusters is above a threshold.", "labels": [], "entities": []}, {"text": "In the above example, alkharrub, al-kharub, al-khurub and al-kharroub are grouped into a single cluster, and each of the ungrouped words remains in its single word cluster.", "labels": [], "entities": []}, {"text": "Note that the source word may not be a name while its translations may still have similar spellings.", "labels": [], "entities": []}, {"text": "An example is the Arabic word 2 which is aligned to English words brief, briefing, briefed and briefings.", "labels": [], "entities": []}, {"text": "To detect whether a source word is a name, we calculate the transliteration cost between the source word and its target translation cluster, which is defined as the average transliteration cost between the source word and each target word in the cluster.", "labels": [], "entities": []}, {"text": "As many names are translated based on their pronunciations, the source and target names have similar phonetic features and lower transliteration costs.", "labels": [], "entities": []}, {"text": "Word pairs whose transliteration cost is lower than an empirically selected threshold are considered as name translations.", "labels": [], "entities": [{"text": "name translations", "start_pos": 104, "end_pos": 121, "type": "TASK", "confidence": 0.7222663760185242}]}], "datasetContent": [{"text": "We apply the Arabic-English name spelling variants on the machine translation task.", "labels": [], "entities": [{"text": "machine translation task", "start_pos": 58, "end_pos": 82, "type": "TASK", "confidence": 0.8052289485931396}]}, {"text": "Our baseline system is trained with 5.6M ArabicEnglish sentence pairs, the same training data used to extract A-E spelling variants.", "labels": [], "entities": []}, {"text": "The language model is a modified Kneser-Ney 5-gram model trained on roughly 3.5 billion words.", "labels": [], "entities": []}, {"text": "After pruning (using count cutoffs), it contains a total of 935 million N-grams.", "labels": [], "entities": []}, {"text": "We updated the translation models and the language model with the name spelling variant class.", "labels": [], "entities": []}, {"text": "shows a Romanized Arabic sentence, the translation output from the baseline system and the output from the updated models.", "labels": [], "entities": []}, {"text": "In the baseline system output, the Arabic name \"Alxrwb\" was incorrectly translated into \"regional\".", "labels": [], "entities": []}, {"text": "This error was fixed in the updated model, where both translation and language models assign higher probabilities to the correct translation \"al-kharroub\" after spelling variant normalization.", "labels": [], "entities": []}, {"text": "Mention detection system experiments are conducted on the ACE 2007 data sets in Arabic and English.", "labels": [], "entities": [{"text": "Mention detection system", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.8675317764282227}, {"text": "ACE 2007 data sets", "start_pos": 58, "end_pos": 76, "type": "DATASET", "confidence": 0.9861127883195877}]}, {"text": "Since the evaluation test set is not publicly available, we have split the publicly available training corpus into an 85%/15% data split.", "labels": [], "entities": []}, {"text": "To facilitate future comparisons with work presented here, and to simulate a realistic scenario, the splits are created based on article dates: the test data is selected as the latest 15% of the data in chronological order.", "labels": [], "entities": []}, {"text": "This way, the documents in the training and test data sets do not overlap in time, and the content of the test data is more recent than the training data.", "labels": [], "entities": []}, {"text": "For English we use 499 documents for training and 100 documents for testing, while for Arabic we use 323 documents for training and 56 documents for testing.", "labels": [], "entities": []}, {"text": "English and Arabic mention detection systems are using a large range of features, including lexical (e.g., words and morphs in a 3-word window, prefixes and suffixes of length up to 4, stems in a 4-word window for Arabic), syntactic (POS tags, text chunks), and the output of other information extraction models.", "labels": [], "entities": [{"text": "English and Arabic mention detection", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.5840862631797791}, {"text": "information extraction", "start_pos": 282, "end_pos": 304, "type": "TASK", "confidence": 0.7220215201377869}]}, {"text": "These features were described in () with more details.", "labels": [], "entities": []}, {"text": "Our goal here is to investigate the effectiveness of name These scores treat information bearing words, like names, the same as any other words, like punctuations.", "labels": [], "entities": []}, {"text": "spelling variants information in improving mention detection system performance.", "labels": [], "entities": [{"text": "mention detection system", "start_pos": 43, "end_pos": 67, "type": "TASK", "confidence": 0.8357043266296387}]}, {"text": "Results in show that the use of name spelling variants (NSV) improves mention detection systems performance, especially for English; an interesting improvement is obtained in recall -which is to be expected, given the method -, but also in precision, leading to systems with better performance in terms of Fmeasure.", "labels": [], "entities": [{"text": "mention detection", "start_pos": 70, "end_pos": 87, "type": "TASK", "confidence": 0.7151965498924255}, {"text": "recall", "start_pos": 175, "end_pos": 181, "type": "METRIC", "confidence": 0.9993693232536316}, {"text": "precision", "start_pos": 240, "end_pos": 249, "type": "METRIC", "confidence": 0.9993863105773926}, {"text": "Fmeasure", "start_pos": 306, "end_pos": 314, "type": "METRIC", "confidence": 0.9849514365196228}]}, {"text": "This improvement in performance is statistically significant according to the stratified bootstrap re-sampling approach.", "labels": [], "entities": []}, {"text": "This approach is used in the named entity recognition shared task of CoNLL-2002 7 . However, the small improvement obtained for Arabic is not statistically significant based on the approach described earlier.", "labels": [], "entities": [{"text": "named entity recognition shared task", "start_pos": 29, "end_pos": 65, "type": "TASK", "confidence": 0.7290364325046539}, {"text": "CoNLL-2002 7", "start_pos": 69, "end_pos": 81, "type": "DATASET", "confidence": 0.75154909491539}]}, {"text": "One hypothesis is that Arabic name spelling variants are not rich enough and that a better tuning of the alignment score is required to improve precision.", "labels": [], "entities": [{"text": "alignment score", "start_pos": 105, "end_pos": 120, "type": "METRIC", "confidence": 0.9134055078029633}, {"text": "precision", "start_pos": 144, "end_pos": 153, "type": "METRIC", "confidence": 0.9985806941986084}]}], "tableCaptions": [{"text": " Table 5. English translation output with the baseline MT system and the system with updated models", "labels": [], "entities": [{"text": "English translation", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.6160894185304642}, {"text": "MT", "start_pos": 55, "end_pos": 57, "type": "TASK", "confidence": 0.826652467250824}]}, {"text": " Table 6. MT scores with updated TM and LM", "labels": [], "entities": [{"text": "MT", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.8275086879730225}, {"text": "TM", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9464754462242126}]}, {"text": " Table 7: Performance of English and Arabic mention  detection systems without (Baseline) and with  (Baseline+NSV) the use of name spelling variants.  Performance is presented in terms of Precision (P),  Recall (R), and F-measure (F).", "labels": [], "entities": [{"text": "English and Arabic mention  detection", "start_pos": 25, "end_pos": 62, "type": "TASK", "confidence": 0.6840739846229553}, {"text": "Precision (P)", "start_pos": 188, "end_pos": 201, "type": "METRIC", "confidence": 0.9473273009061813}, {"text": "Recall (R)", "start_pos": 204, "end_pos": 214, "type": "METRIC", "confidence": 0.9515339881181717}, {"text": "F-measure (F)", "start_pos": 220, "end_pos": 233, "type": "METRIC", "confidence": 0.9588939547538757}]}]}