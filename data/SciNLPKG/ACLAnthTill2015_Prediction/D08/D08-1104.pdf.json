{"title": [{"text": "Construction of an Idiom Corpus and its Application to Idiom Identification based on WSD incorporating Idiom-Specific Features", "labels": [], "entities": [{"text": "Idiom Identification", "start_pos": 55, "end_pos": 75, "type": "TASK", "confidence": 0.7170622050762177}, {"text": "WSD", "start_pos": 85, "end_pos": 88, "type": "DATASET", "confidence": 0.6938751339912415}]}], "abstractContent": [{"text": "Some phrases can be interpreted either idiomatically (figuratively) or literally in context , and the precise identification of idioms is indispensable for full-fledged natural language processing (NLP).", "labels": [], "entities": [{"text": "full-fledged natural language processing (NLP)", "start_pos": 156, "end_pos": 202, "type": "TASK", "confidence": 0.747805757181985}]}, {"text": "To this end, we have constructed an idiom corpus for Japanese.", "labels": [], "entities": []}, {"text": "This paper reports on the corpus and the results of an idiom identification experiment using the corpus.", "labels": [], "entities": [{"text": "idiom identification", "start_pos": 55, "end_pos": 75, "type": "TASK", "confidence": 0.7205120474100113}]}, {"text": "The corpus targets 146 ambiguous idioms, and consists of 102,846 sentences , each of which is annotated with a lit-eral/idiom label.", "labels": [], "entities": []}, {"text": "For idiom identification, we targeted 90 out of the 146 idioms and adopted a word sense disambiguation (WSD) method using both common WSD features and idiom-specific features.", "labels": [], "entities": [{"text": "idiom identification", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.7532958388328552}, {"text": "word sense disambiguation (WSD)", "start_pos": 77, "end_pos": 108, "type": "TASK", "confidence": 0.7126326362291971}]}, {"text": "The corpus and the experiment are the largest of their kind, as far as we know.", "labels": [], "entities": []}, {"text": "As a result, we found that a standard supervised WSD method works well for the idiom identification and achieved an accuracy of 89.25% and 88.86% with/without idiom-specific features and that the most effective idiom-specific feature is the one involving the adjacency of idiom constituents.", "labels": [], "entities": [{"text": "WSD", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.8709410429000854}, {"text": "idiom identification", "start_pos": 79, "end_pos": 99, "type": "TASK", "confidence": 0.7449485063552856}, {"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9993693232536316}]}], "introductionContent": [{"text": "Some phrases like kick the bucket are ambiguous with regard to whether they carry literal or idiomatic meaning in a certain context.", "labels": [], "entities": []}, {"text": "This ambiguity needs to be resolved in the same manner as ambiguous words that have been dealt within the WSD literature.", "labels": [], "entities": [{"text": "WSD", "start_pos": 106, "end_pos": 109, "type": "TASK", "confidence": 0.9189157485961914}]}, {"text": "We term the resolution of the literal/idiomatic ambiguity as idiom identification, hereafter.", "labels": [], "entities": [{"text": "idiom identification", "start_pos": 61, "end_pos": 81, "type": "TASK", "confidence": 0.7108840495347977}]}, {"text": "Idiom identification is classified into two kinds; one is for idiom types and the other is for idiom tokens.", "labels": [], "entities": [{"text": "Idiom identification", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.907232791185379}]}, {"text": "With the former, phrases that can be interpreted as idioms are found in text corpora, typically for compiling idiom dictionaries.", "labels": [], "entities": []}, {"text": "On the other hand, the latter helps identify a phrase in context as a true idiom or a phrase that should be interpreted literally (a literal phrase, henceforth).", "labels": [], "entities": []}, {"text": "In this paper, we deal with the latter, i.e., idiom token identification.", "labels": [], "entities": [{"text": "idiom token identification", "start_pos": 46, "end_pos": 72, "type": "TASK", "confidence": 0.6978238622347513}]}, {"text": "Despite the recent enthusiasm for multiword expressions (MWEs) (, the idiom token identification is in an early phase of its development.", "labels": [], "entities": [{"text": "multiword expressions (MWEs)", "start_pos": 34, "end_pos": 62, "type": "TASK", "confidence": 0.6655509352684021}, {"text": "idiom token identification", "start_pos": 70, "end_pos": 96, "type": "TASK", "confidence": 0.684334804614385}]}, {"text": "Given that many NLP tasks like machine translation or parsing have been developed as a result of the availability of language resources, idiom token identification should also be developed when adequate idiom resources are provided.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.7946541607379913}, {"text": "idiom token identification", "start_pos": 137, "end_pos": 163, "type": "TASK", "confidence": 0.7447928587595621}]}, {"text": "To this end, we have constructed a Japanese idiom corpus.", "labels": [], "entities": [{"text": "Japanese idiom corpus", "start_pos": 35, "end_pos": 56, "type": "DATASET", "confidence": 0.6954954862594604}]}, {"text": "We have also conducted an idiom identification experiment using the corpus that we hope will be a good reference point for future studies on the task.", "labels": [], "entities": [{"text": "idiom identification", "start_pos": 26, "end_pos": 46, "type": "TASK", "confidence": 0.7173420488834381}]}, {"text": "We drew on a standard WSD framework with machine learning exploiting both features commonly used in the WSD studies and idiom-specific features.", "labels": [], "entities": []}, {"text": "This paper reports in detail the corpus and the result of the experiment; herein, it must be noted that to the best of our knowledge, the corpus and the experiment are the largest ever of their kind.", "labels": [], "entities": []}, {"text": "We only deal with the ambiguity between literal and idiomatic interpretations.", "labels": [], "entities": []}, {"text": "However, some phrases have two or more idiomatic meanings without context.", "labels": [], "entities": []}, {"text": "For example, a Japanese idiom te-o dasu (hand-ACC stretch) can be interpreted as ei-ther \"punch,\" \"steal\" or \"make moves on.\"", "labels": [], "entities": []}, {"text": "This kind of ambiguity should be placed on the agenda.", "labels": [], "entities": []}, {"text": "We do not tackle the problem of what constitutes the notion of \"idiom.\"", "labels": [], "entities": []}, {"text": "We simply regard phrases listed in as idioms.", "labels": [], "entities": []}, {"text": "The reminder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In \u00a72 we present related works.", "labels": [], "entities": []}, {"text": "\u00a73 shows the target idioms.", "labels": [], "entities": []}, {"text": "After the idiom corpus is described in \u00a74, we detail our idiom identification method and experiment in \u00a75.", "labels": [], "entities": [{"text": "idiom identification", "start_pos": 57, "end_pos": 77, "type": "TASK", "confidence": 0.6974482238292694}]}, {"text": "Finally \u00a76 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the experiment, we dealt with 90 idioms for which more than 50 examples for both idiomatic and literal usages were available.", "labels": [], "entities": []}, {"text": "We conducted experiments for each idiom.", "labels": [], "entities": []}, {"text": "The performance measure is the accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9992554783821106}]}, {"text": "Accuracy = # of examples correctly identified # of all example The baseline system uniformly regards all examples as either positive or negative depending on which is more dominant in the idiom corpus.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9959164261817932}]}, {"text": "Naturally, this is prepared for each idiom.", "labels": [], "entities": []}, {"text": "The accuracy and the baseline accuracy for each idiom are calculated in a 10-fold cross validation style; we split examples of an idiom into 10 pieces in advance of the experiment.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9994248151779175}, {"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9213869571685791}]}, {"text": "Also, we calculated the overall accuracy and baseline accuracy from the individual results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9992918968200684}, {"text": "baseline", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.949193000793457}, {"text": "accuracy", "start_pos": 54, "end_pos": 62, "type": "METRIC", "confidence": 0.8709654808044434}]}, {"text": "We summed up all accuracy scores of all the 90 idioms and then divided it by 90, which is called the macroaverage.", "labels": [], "entities": [{"text": "accuracy scores", "start_pos": 17, "end_pos": 32, "type": "METRIC", "confidence": 0.9726024568080902}]}, {"text": "We did this for the baseline accuracy, too.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9882928729057312}]}, {"text": "Another performance measure is the relative error reduction (RER).", "labels": [], "entities": [{"text": "relative error reduction (RER)", "start_pos": 35, "end_pos": 65, "type": "METRIC", "confidence": 0.9228308995564779}]}, {"text": "All in all, we see relatively high baseline performances.", "labels": [], "entities": []}, {"text": "Nevertheless, both systems outperformed the baseline.", "labels": [], "entities": []}, {"text": "Especially, the system without the idiom-specific features has a noticeable lead over the baseline, showing that WSD technologies are effective in the idiom identification.", "labels": [], "entities": [{"text": "idiom identification", "start_pos": 151, "end_pos": 171, "type": "TASK", "confidence": 0.7141563594341278}]}, {"text": "Incorporating the idiom features into the system improved the overall performance, which is statistically significant (McNemar test, p<0.01).", "labels": [], "entities": [{"text": "McNemar test", "start_pos": 119, "end_pos": 131, "type": "DATASET", "confidence": 0.5502205491065979}]}, {"text": "But performances of some idioms slightly degraded by the incorporation of the idiom features.", "labels": [], "entities": []}, {"text": "shows overall results without using one of the idiom features.", "labels": [], "entities": []}, {"text": "As you see, the adjacency flag (f13) contributes to idiom identification accuracy the most.", "labels": [], "entities": [{"text": "idiom identification", "start_pos": 52, "end_pos": 72, "type": "TASK", "confidence": 0.8076254427433014}, {"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9257053136825562}]}, {"text": "On the other hand, the adnominal modification flag (f8) contributes to the task only slightly.", "labels": [], "entities": []}, {"text": "23 shows the results reported in CFS.", "labels": [], "entities": [{"text": "CFS", "start_pos": 33, "end_pos": 36, "type": "DATASET", "confidence": 0.6606259346008301}]}, {"text": "Their baseline system regards all instances as idioms.", "labels": [], "entities": []}, {"text": "The performance of the supervised one is obtained by the method of.", "labels": [], "entities": []}, {"text": "Though we cannot simply compare this with our results due to the difference in experimental conditions, this implies that our WSD-based method was equally good or possibly better than their methods that are tailored to MWEs.", "labels": [], "entities": [{"text": "WSD-based", "start_pos": 126, "end_pos": 135, "type": "TASK", "confidence": 0.8830018639564514}]}], "tableCaptions": [{"text": " Table 3: Individual Results (2/2)", "labels": [], "entities": [{"text": "Individual", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9615374803543091}]}, {"text": " Table 4: Overall Results without Using One of the Idiom  Features", "labels": [], "entities": []}, {"text": " Table 5: Results reported in CFS", "labels": [], "entities": [{"text": "CFS", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.5963099002838135}]}]}