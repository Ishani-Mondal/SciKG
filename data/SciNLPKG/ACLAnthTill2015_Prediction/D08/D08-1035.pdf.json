{"title": [], "abstractContent": [{"text": "This paper describes a novel Bayesian approach to unsupervised topic segmentation.", "labels": [], "entities": [{"text": "unsupervised topic segmentation", "start_pos": 50, "end_pos": 81, "type": "TASK", "confidence": 0.6858570476373037}]}, {"text": "Unsupervised systems for this task are driven by lexical cohesion: the tendency of well-formed segments to induce a compact and consistent lexical distribution.", "labels": [], "entities": []}, {"text": "We show that lexical cohesion can be placed in a Bayesian context by modeling the words in each topic segment as draws from a multinomial language model associated with the segment; maximizing the observation likelihood in such a model yields a lexically-cohesive segmenta-tion.", "labels": [], "entities": []}, {"text": "This contrasts with previous approaches, which relied on hand-crafted cohesion met-rics.", "labels": [], "entities": []}, {"text": "The Bayesian framework provides a prin-cipled way to incorporate additional features such as cue phrases, a powerful indicator of discourse structure that has not been previously used in unsupervised segmentation systems.", "labels": [], "entities": []}, {"text": "Our model yields consistent improvements over an array of state-of-the-art systems on both text and speech datasets.", "labels": [], "entities": []}, {"text": "We also show that both an entropy-based analysis and a well-known previous technique can be derived as special cases of the Bayesian framework.", "labels": [], "entities": []}], "introductionContent": [{"text": "Topic segmentation is one of the fundamental problems in discourse analysis, where the task is to divide a text into a linear sequence of topicallycoherent segments.", "labels": [], "entities": [{"text": "Topic segmentation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8250274658203125}, {"text": "discourse analysis", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.725727841258049}]}, {"text": "introduced the idea that unsupervised segmentation can be driven by lexical cohesion, as high-quality segmentations feature homogeneous lexical distributions within each topic segment.", "labels": [], "entities": []}, {"text": "Lexical cohesion has provided the inspiration for several successful systems (e.g.,), and is currently the dominant approach to unsupervised topic segmentation.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 141, "end_pos": 159, "type": "TASK", "confidence": 0.7017258107662201}]}, {"text": "But despite the effectiveness of lexical cohesion for unsupervised topic segmentation, it is clear that there are other important indicators that are ignored by the current generation of unsupervised systems.", "labels": [], "entities": [{"text": "topic segmentation", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.7795065343379974}]}, {"text": "For example, consider cue phrases, which are explicit discourse markers such as \"now\" or \"however\" (.", "labels": [], "entities": []}, {"text": "Cue phrases have been shown to be a useful feature for supervised topic segmentation (), but cannot be incorporated by current unsupervised models.", "labels": [], "entities": [{"text": "supervised topic segmentation", "start_pos": 55, "end_pos": 84, "type": "TASK", "confidence": 0.6034963925679525}]}, {"text": "One reason for this is that existing unsupervised methods use arbitrary, hand-crafted metrics for quantifying lexical cohesion, such as weighted cosine similarity).", "labels": [], "entities": []}, {"text": "Without supervision, it is not possible to combine such metrics with additional sources of information.", "labels": [], "entities": []}, {"text": "Moreover, such hand-crafted metrics may not generalize well across multiple datasets, and often include parameters which must be tuned on development sets (;.", "labels": [], "entities": []}, {"text": "In this paper, we situate lexical cohesion in a Bayesian framework, allowing other sources of information to be incorporated without the need for labeled data.", "labels": [], "entities": []}, {"text": "We formalize lexical cohesion in a generative model in which the text for each seg-ment is produced by a distinct lexical distribution.", "labels": [], "entities": []}, {"text": "Lexically-consistent segments are favored by this model because probability mass is conserved fora narrow subset of words.", "labels": [], "entities": []}, {"text": "Thus, lexical cohesion arises naturally through the generative process, and other sources of information -such as cue words -can easily be incorporated as emissions from the segment boundaries.", "labels": [], "entities": []}, {"text": "More formally, we treat the words in each sentence as draws from a language model associated with the topic segment.", "labels": [], "entities": []}, {"text": "This is related to topicmodeling methods such as latent Dirichlet allocation (LDA;), but here the induced topics are tied to a linear discourse structure.", "labels": [], "entities": []}, {"text": "This property enables a dynamic programming solution to find the exact maximum-likelihood segmentation.", "labels": [], "entities": []}, {"text": "We consider two approaches to handling the language models: estimating them explicitly, and integrating them out, using the Dirichlet Compound Multinomial distribution (also known as the multivariate Polya distribution).", "labels": [], "entities": []}, {"text": "We model cue phrases as generated from a separate multinomial that is shared across all topics and documents in the dataset; a high-likelihood model will obtain a compact set of cue phrases.", "labels": [], "entities": []}, {"text": "The addition of cue phrases renders our dynamic programming-based inference inapplicable, so we design a sampling-based inference technique.", "labels": [], "entities": []}, {"text": "This algorithm can learn in a completely unsupervised fashion, but it also provides a principled mechanism to improve search through the addition of declarative linguistic knowledge.", "labels": [], "entities": []}, {"text": "This is achieved by biasing the selection of samples towards boundaries with known cue phrases; this does not change the underlying probabilistic model, but guides search in the direction of linguistically-plausible segmentations.", "labels": [], "entities": []}, {"text": "We evaluate our algorithm on corpora of spoken and written language, including the benchmark ICSI meeting dataset () and anew textual corpus constructed from the contents of a medical textbook.", "labels": [], "entities": [{"text": "ICSI meeting dataset", "start_pos": 93, "end_pos": 113, "type": "DATASET", "confidence": 0.7586534221967062}]}, {"text": "In both cases our model achieves performance surpassing multiple state-of-the-art baselines.", "labels": [], "entities": []}, {"text": "Moreover, we demonstrate that the addition of cue phrases can further improve segmentation performance over cohesion-based methods.", "labels": [], "entities": []}, {"text": "In addition to the practical advantages demonstrated by these experimental results, our model reveals interesting theoretical properties.", "labels": [], "entities": []}, {"text": "Other researchers have observed relationships between discourse structure and entropy (e.g.,).", "labels": [], "entities": []}, {"text": "We show that in a special case of our model, the segmentation objective is equal to a weighted sum of the negative entropies for each topic segment.", "labels": [], "entities": []}, {"text": "This finding demonstrates that a relationship between discourse segmentation and entropy is a natural consequence of modeling topic structure in a generative Bayesian framework.", "labels": [], "entities": []}, {"text": "In addition, we show that the benchmark segmentation system of can be viewed as another special case of our Bayesian model.", "labels": [], "entities": [{"text": "benchmark segmentation", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.5963046103715897}]}], "datasetContent": [{"text": "Corpora We evaluate our approach on corpora from two different domains: transcribed meetings and written text.", "labels": [], "entities": []}, {"text": "For multi-speaker meetings, we use the ICSI corpus of meeting transcripts (, which is becoming a standard for speech segmentation (e.g.,).", "labels": [], "entities": [{"text": "ICSI corpus of meeting transcripts", "start_pos": 39, "end_pos": 73, "type": "DATASET", "confidence": 0.9509798526763916}, {"text": "speech segmentation", "start_pos": 110, "end_pos": 129, "type": "TASK", "confidence": 0.7259035110473633}]}, {"text": "This dataset includes transcripts of 75 multi-party meetings, of which 25 are annotated for segment boundaries.", "labels": [], "entities": []}, {"text": "For text, we introduce a dataset in which each document is a chapter selected from a medical textbook (.", "labels": [], "entities": []}, {"text": "The task is to divide each chapter into the sections indicated by the author.", "labels": [], "entities": []}, {"text": "This dataset contains 227 chapters, with 1136 sections (an average of 5.00 per chapter).", "labels": [], "entities": []}, {"text": "Each chapter contains an average of 140 sentences, giving an average of 28 sentences per segment.", "labels": [], "entities": []}, {"text": "Metrics All experiments are evaluated in terms of the commonly-used P k () and WindowDiff (WD)) scores.", "labels": [], "entities": []}, {"text": "Both metrics pass a window through the document, and assess whether the sentences on the edges of the window are properly segmented with respect to each other.", "labels": [], "entities": []}, {"text": "WindowDiff is stricter in that it requires that the number of intervening segments between the two sentences be identical in the hypothesized and the reference segmentations, while P k only asks whether the two sentences are in the same segment or not.", "labels": [], "entities": [{"text": "WindowDiff", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.8556729555130005}]}, {"text": "P k and WindowDiff are penalties, so lower values indicate better segmentations.", "labels": [], "entities": [{"text": "WindowDiff", "start_pos": 8, "end_pos": 18, "type": "DATASET", "confidence": 0.8811267614364624}]}, {"text": "We use the evaluation source code provided by.", "labels": [], "entities": []}, {"text": "System configuration We evaluate our Bayesian approach both with and without cue phrases.", "labels": [], "entities": []}, {"text": "Without cue phrases, we use the dynamic programming inference described in section 3.3.", "labels": [], "entities": []}, {"text": "This system is referred to as BAYESSEG in.", "labels": [], "entities": [{"text": "BAYESSEG", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.6864065527915955}]}, {"text": "When adding cue phrases, we use the Metropolis-Hastings model described in 4.1.", "labels": [], "entities": []}, {"text": "Both basic and linguisticallymotivated proposal distributions are evaluated (see Section 4.2); these are referred to as BAYESSEG-CUE and BAYESSEG-CUE-PROP in the table.", "labels": [], "entities": [{"text": "BAYESSEG-CUE", "start_pos": 120, "end_pos": 132, "type": "DATASET", "confidence": 0.5058274865150452}, {"text": "BAYESSEG-CUE-PROP", "start_pos": 137, "end_pos": 154, "type": "DATASET", "confidence": 0.7406325936317444}]}, {"text": "For the sampling-based systems, results are averaged over five runs.", "labels": [], "entities": []}, {"text": "The initial configuration is obtained from the dynamic programming inference, and then 100,000 sampling iterations are performed.", "labels": [], "entities": []}, {"text": "The final segmentation is obtained by annealing the last 25,000 iterations to a temperature of zero.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.9810235500335693}]}, {"text": "The use of annealing to obtain a maximum a posteriori (MAP) configuration from sampling-based inference is common (e.g.,).", "labels": [], "entities": []}, {"text": "The total running time of our system is on the order of three minutes per document.", "labels": [], "entities": []}, {"text": "Due to memory constraints, we divide the textbook dataset into ten parts, and perform inference in each part separately.", "labels": [], "entities": [{"text": "textbook dataset", "start_pos": 41, "end_pos": 57, "type": "DATASET", "confidence": 0.9501813650131226}]}, {"text": "We may achieve better results by performing inference over the entire dataset simultaneously, due to pooling counts for cue phrases across all documents.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Comparison of segmentation algorithms. Both  metrics are penalties, so lower scores indicate bet- ter performance.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 24, "end_pos": 36, "type": "TASK", "confidence": 0.9236498475074768}]}, {"text": " Table 2: Cue phrases selected by our unsupervised  model, sorted by chi-squared. Boldface indicates that the  chi-squared value is significant at the level of p < .01.  Asterisks indicate cue phrases that were extracted by the  supervised procedure of Galley et al. (2003).", "labels": [], "entities": []}]}