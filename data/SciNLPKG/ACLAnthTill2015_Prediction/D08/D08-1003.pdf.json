{"title": [{"text": "Regular Expression Learning for Information Extraction", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 32, "end_pos": 54, "type": "TASK", "confidence": 0.7014661282300949}]}], "abstractContent": [{"text": "Regular expressions have served as the dominant workhorse of practical information extraction for several years.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 71, "end_pos": 93, "type": "TASK", "confidence": 0.729389488697052}]}, {"text": "However, there has been little work on reducing the manual effort involved in building high-quality, complex regular expressions for information extraction tasks.", "labels": [], "entities": [{"text": "information extraction tasks", "start_pos": 133, "end_pos": 161, "type": "TASK", "confidence": 0.8839276432991028}]}, {"text": "In this paper, we propose Re-LIE, a novel transformation-based algorithm for learning such complex regular expressions.", "labels": [], "entities": []}, {"text": "We evaluate the performance of our algorithm on multiple datasets and compare it against the CRF algorithm.", "labels": [], "entities": []}, {"text": "We show that ReLIE, in addition to being an order of magnitude faster, outperforms CRF under conditions of limited training data and cross-domain data.", "labels": [], "entities": [{"text": "ReLIE", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.6060193181037903}]}, {"text": "Finally, we show how the accuracy of CRF can be improved by using features extracted by ReLIE.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9994232654571533}, {"text": "CRF", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.8867430686950684}, {"text": "ReLIE", "start_pos": 88, "end_pos": 93, "type": "DATASET", "confidence": 0.7635279297828674}]}], "introductionContent": [{"text": "A large class of entity extraction tasks can be accomplished by the use of carefully constructed regular expressions (regexes).", "labels": [], "entities": [{"text": "entity extraction", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.7597270011901855}]}, {"text": "Examples of entities amenable to such extractions include email addresses and software names (web collections), credit card numbers and social security numbers (email compliance), and gene and protein names (bioinformatics), etc.", "labels": [], "entities": []}, {"text": "These entities share the characteristic that their key representative patterns (features) are expressible in standard constructs of regular expressions.", "labels": [], "entities": []}, {"text": "At first glance, it may seem that constructing * Supported in part by NSF 0438909 and NIH 1-U54-DA021519.", "labels": [], "entities": [{"text": "NSF 0438909", "start_pos": 70, "end_pos": 81, "type": "DATASET", "confidence": 0.8828017711639404}]}, {"text": "a regex to extract such entities is fairly straightforward.", "labels": [], "entities": []}, {"text": "In reality, robust extraction requires the use of rather complex expressions, as illustrated by the following example.", "labels": [], "entities": [{"text": "robust extraction", "start_pos": 12, "end_pos": 29, "type": "TASK", "confidence": 0.7061777859926224}]}, {"text": "Example 1 (Phone number extraction).", "labels": [], "entities": [{"text": "Phone number extraction", "start_pos": 11, "end_pos": 34, "type": "TASK", "confidence": 0.6286788682142893}]}, {"text": "An obvious pattern for identifying phone numbers is \"blocks of digits separated by hyphens\" represented as R 1 = (\\d+\\-)+\\d+.", "labels": [], "entities": []}, {"text": "1 While R 1 matches valid phone numbers like 800-865-1125 and 725-1234, it suffers from both \"precision\" and \"recall\" problems.", "labels": [], "entities": [{"text": "precision", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9992274045944214}, {"text": "recall", "start_pos": 110, "end_pos": 116, "type": "METRIC", "confidence": 0.9988909363746643}]}, {"text": "Not only does R 1 produce incorrect matches (e.g., social security numbers like 123-45-6789), it also fails to identify valid phone numbers such as 800.865-CARE.", "labels": [], "entities": [{"text": "R 1", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.7297122478485107}]}, {"text": "An improved regex that addresses these problems is R 2 = (\\d{3}[-.\\ ()]){1,2}[\\dA-Z]{4}.", "labels": [], "entities": []}, {"text": "While multiple machine learning approaches have been proposed for information extraction in recent years (), manually created regexes remain a widely adopted practical solution for information extraction).", "labels": [], "entities": [{"text": "information extraction", "start_pos": 66, "end_pos": 88, "type": "TASK", "confidence": 0.8629577159881592}, {"text": "information extraction", "start_pos": 181, "end_pos": 203, "type": "TASK", "confidence": 0.8201687633991241}]}, {"text": "Yet, with a few notable exceptions, which we discuss later in Section 1.1, there has been very little work in reducing this human effort through the use of automatic learning techniques.", "labels": [], "entities": []}, {"text": "In this paper, we propose a novel formulation of the problem of learn-ing regexes for information extraction tasks.", "labels": [], "entities": [{"text": "information extraction tasks", "start_pos": 86, "end_pos": 114, "type": "TASK", "confidence": 0.8517902890841166}]}, {"text": "We demonstrate that high quality regex extractors can be learned with significantly reduced manual effort.", "labels": [], "entities": [{"text": "regex extractors", "start_pos": 33, "end_pos": 49, "type": "TASK", "confidence": 0.8031144142150879}]}, {"text": "To motivate our approach, we first discuss prior work in the area of learning regexes and describe some of the limitations of these techniques.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we present an empirical study of the ReLIE algorithm using four extraction tasks over three real-life data sets.", "labels": [], "entities": [{"text": "ReLIE algorithm", "start_pos": 54, "end_pos": 69, "type": "TASK", "confidence": 0.78178671002388}]}, {"text": "The goal of this study is to evaluate the effectiveness of ReLIE in learning complex regexes and to investigate how it compares with standard machine learning algorithms.", "labels": [], "entities": []}, {"text": "Data Set The datasets used in our experiments are: \u2022 EWeb: A collection of 50,000 web pages crawled from a corporate intranet.", "labels": [], "entities": []}, {"text": "Fanout is the number of ways in which a character class maybe restricted as defined by the hierarchy (e.g.).", "labels": [], "entities": []}, {"text": "\u2022 AWeb: A set of 50,000 web pages obtained from the publicly available University of Michigan Web page collection (), including a subcollection of 10,000 pages (AWeb-S).", "labels": [], "entities": [{"text": "AWeb", "start_pos": 2, "end_pos": 6, "type": "DATASET", "confidence": 0.5621309876441956}, {"text": "University of Michigan Web page collection", "start_pos": 71, "end_pos": 113, "type": "DATASET", "confidence": 0.6854824125766754}]}, {"text": "\u2022 Email: A collection of 10,000 emails obtained from the publicly available Enron email collection ().", "labels": [], "entities": [{"text": "Enron email collection", "start_pos": 76, "end_pos": 98, "type": "DATASET", "confidence": 0.9021708170572916}]}, {"text": "Extraction Tasks SoftwareNameTask, CourseNumberTask and PhoneNumberTask were evaluated on EWeb, AWeb and Email, respectively.", "labels": [], "entities": [{"text": "CourseNumberTask", "start_pos": 35, "end_pos": 51, "type": "DATASET", "confidence": 0.8722442984580994}, {"text": "PhoneNumberTask", "start_pos": 56, "end_pos": 71, "type": "DATASET", "confidence": 0.8499234318733215}, {"text": "EWeb", "start_pos": 90, "end_pos": 94, "type": "DATASET", "confidence": 0.971203625202179}, {"text": "AWeb", "start_pos": 96, "end_pos": 100, "type": "DATASET", "confidence": 0.9331828355789185}, {"text": "Email", "start_pos": 105, "end_pos": 110, "type": "DATASET", "confidence": 0.890114963054657}]}, {"text": "Since web pages have large number of URLs, to keep the labeling task manageable, URLTask was evaluated on AWeb-S.", "labels": [], "entities": [{"text": "AWeb-S", "start_pos": 106, "end_pos": 112, "type": "DATASET", "confidence": 0.9820935726165771}]}, {"text": "Gold Standard For each task, the gold standard was created by manually labeling all matches for the initial regex.", "labels": [], "entities": []}, {"text": "Note that only exact matches with the gold standard are considered correct in our evaluations.", "labels": [], "entities": []}, {"text": "6 Comparison Study To evaluate ReLIE for entity extraction vis-a-vis existing algorithms, we used the popular conditional random field (CRF).", "labels": [], "entities": [{"text": "ReLIE", "start_pos": 31, "end_pos": 36, "type": "TASK", "confidence": 0.8241637349128723}, {"text": "entity extraction", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.7549135088920593}]}, {"text": "Specifically, we used the MinorThird) implementation of CRF to train models for all four extraction tasks.", "labels": [], "entities": []}, {"text": "For training the CRF we provided it with the set of positive and negative matches from the initial regex with a context of 200 characters on either side of each match . Since it is unlikely that useful features are located faraway from the entity, we believe that 200 characters on either side is sufficient context.", "labels": [], "entities": []}, {"text": "The CRF used the base features described in).", "labels": [], "entities": []}, {"text": "To ensure fair comparison with ReLIE, we also included the matches corresponding to the input regex as a feature to the CRF.", "labels": [], "entities": [{"text": "ReLIE", "start_pos": 31, "end_pos": 36, "type": "DATASET", "confidence": 0.6812578439712524}]}, {"text": "In practice, more complex features (e.g., dictionaries, simple regexes) derived by domain experts are often provided to CRFs.", "labels": [], "entities": []}, {"text": "However, such features can also be used to refine the initial regex given to ReLIE.", "labels": [], "entities": [{"text": "ReLIE", "start_pos": 77, "end_pos": 82, "type": "DATASET", "confidence": 0.8203946352005005}]}, {"text": "Hence, with a view to investigating the \"raw\" learning capability of the two approaches, we chose to run all our experiments without any additional manually derived features.", "labels": [], "entities": []}, {"text": "In fact, the patterns learned by ReLIE through transformations are often similar to the features that domain experts may provide to CRF.", "labels": [], "entities": []}, {"text": "We will revisit this issue in Section 5.4.", "labels": [], "entities": []}, {"text": "Evaluation We used the standard F-measure to evaluate the effectiveness of ReLIE and CRF.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9830601811408997}, {"text": "ReLIE", "start_pos": 75, "end_pos": 80, "type": "METRIC", "confidence": 0.4810248017311096}]}, {"text": "We divided each dataset into 10 equal parts and used X% of the dataset for training (X=10, 40 and 80), 10% for validation, and remaining (90-X)% for testing.", "labels": [], "entities": []}, {"text": "All results are reported on the test set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Cross Domain Test (F-measure).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.7025312185287476}]}, {"text": " Table 2: Average Training/Testing Time (sec)(with 40% data for training)", "labels": [], "entities": [{"text": "Average Training/Testing Time (sec)(", "start_pos": 10, "end_pos": 46, "type": "METRIC", "confidence": 0.8625058978796005}]}, {"text": " Table 3: ReLIE as Feature Extractor (C+RL is CRF enhanced with  features learned by ReLIE).", "labels": [], "entities": []}, {"text": " Table 4: Sample Regular Expressions Learned by ReLIE(R0: input regex; R f inal : final regex learned; the parts of R0", "labels": [], "entities": [{"text": "ReLIE", "start_pos": 48, "end_pos": 53, "type": "METRIC", "confidence": 0.7845829129219055}]}, {"text": " Table 3. The first point worthy of", "labels": [], "entities": []}]}