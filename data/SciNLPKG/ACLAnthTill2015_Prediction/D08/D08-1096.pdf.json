{"title": [{"text": "A graph-theoretic model of lexical syntactic acquisition", "labels": [], "entities": [{"text": "lexical syntactic acquisition", "start_pos": 27, "end_pos": 56, "type": "TASK", "confidence": 0.6260534028212229}]}], "abstractContent": [{"text": "This paper presents a graph-theoretic model of the acquisition of lexical syntactic representations.", "labels": [], "entities": [{"text": "acquisition of lexical syntactic representations", "start_pos": 51, "end_pos": 99, "type": "TASK", "confidence": 0.7786388754844665}]}, {"text": "The representations the model learns are non-categorical or graded.", "labels": [], "entities": []}, {"text": "We propose anew evaluation methodology of syntactic acquisition in the framework of exemplar theory.", "labels": [], "entities": [{"text": "syntactic acquisition", "start_pos": 42, "end_pos": 63, "type": "TASK", "confidence": 0.8151694238185883}]}, {"text": "When applied to the CHILDES corpus, the evaluation shows that the model's graded syntactic representations perform better than previously proposed categorical representations.", "labels": [], "entities": [{"text": "CHILDES corpus", "start_pos": 20, "end_pos": 34, "type": "DATASET", "confidence": 0.9006404280662537}]}], "introductionContent": [{"text": "In recent years, exemplar theory has had great explanatory success in phonetics.", "labels": [], "entities": [{"text": "exemplar theory", "start_pos": 17, "end_pos": 32, "type": "TASK", "confidence": 0.9739575386047363}]}, {"text": "Exemplar theory posits that linguistic production and perception are not mediated via abstract categories, but that instead each production and perception of a linguistic unit is stored and retained.", "labels": [], "entities": []}, {"text": "Linguistic inference then directly operates on these stored exemplars.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew approach to lexical syntactic acquisition in the framework of exemplar theory.", "labels": [], "entities": [{"text": "lexical syntactic acquisition", "start_pos": 43, "end_pos": 72, "type": "TASK", "confidence": 0.6239936351776123}]}, {"text": "Our approach uses an evaluation measure that is different from previous work.", "labels": [], "entities": []}, {"text": "Lexical syntactic acquisition is most often evaluated with respect to standard syntactic categories like verb and noun.", "labels": [], "entities": [{"text": "Lexical syntactic acquisition", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.8423252900441488}]}, {"text": "Our first contribution in this paper is that we instead evaluate learned representations in the context of a syntactic task.", "labels": [], "entities": []}, {"text": "This task is the determination of an aspect of grammaticality that we call local syntactic coherence.", "labels": [], "entities": []}, {"text": "Our second contribution is a graph-theoretic model of the acquisition of lexical syntactic representations that is more rigorous than previous heuristic proposals.", "labels": [], "entities": [{"text": "acquisition of lexical syntactic representations", "start_pos": 58, "end_pos": 106, "type": "TASK", "confidence": 0.7500553488731384}]}, {"text": "The graph-theoretic model can learn both categorical and non-categorical (or graded) representations.", "labels": [], "entities": []}, {"text": "The model is also a unified framework for syntagmatic and paradigmatic relations (as will be discussed below), and for lowerorder syntactic relations (those that can be directly observed from the input) and higher-order syntactic relations (those that require some generalization from what is directly observable).", "labels": [], "entities": []}, {"text": "give an influential account of the acquisition of lexical syntactic representations in which a standard syntactic category like verb or noun is assigned to each word.", "labels": [], "entities": []}, {"text": "Our third contribution is to show that, in the context of acquisition, graded representations are superior to standard categorical representations in supporting judgments of local syntactic coherence.", "labels": [], "entities": []}, {"text": "A graded representation formalism is one that, for any two words, can represent a third word whose syntactic properties are intermediate between the two words ().", "labels": [], "entities": []}, {"text": "Clearly exemplar theory is not the only framework in which lexical acquisition has been explored.", "labels": [], "entities": [{"text": "lexical acquisition", "start_pos": 59, "end_pos": 78, "type": "TASK", "confidence": 0.7170545756816864}]}, {"text": "for example argues for syntactic bootstrapping to infer lexical semantics, work not at odds with our own (see discussion on the role of semantics below).", "labels": [], "entities": []}, {"text": "Our argument for the importance of distributional evidence does not call into question the large body of work in child language acquisition that demonstrates that \"part of the capacity to learn languages must be 'innate' \".", "labels": [], "entities": [{"text": "child language acquisition", "start_pos": 113, "end_pos": 139, "type": "TASK", "confidence": 0.6701058149337769}]}, {"text": "Tabula rasa learning is not possible.", "labels": [], "entities": [{"text": "Tabula rasa learning", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9407559633255005}]}, {"text": "Our goal is not to show that language acquisition proceeds with a minimum of inductive bias.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 29, "end_pos": 49, "type": "TASK", "confidence": 0.7514858543872833}]}, {"text": "Rather, we attempt to formalize one aspect of language acquisition, the use of distributional information.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 46, "end_pos": 66, "type": "TASK", "confidence": 0.7362787425518036}]}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 motivates the exemplar-theoretic approach by reviewing its success in phonetics.", "labels": [], "entities": []}, {"text": "Section 3 defines local syntactic coherence, which is the basis fora new evaluation methodology for the acquisition of lexical representations.", "labels": [], "entities": []}, {"text": "Section 4 develops the graph-theoretic model.", "labels": [], "entities": []}, {"text": "Section 5 compares graded and categorical representations for the task of inferring local syn-tactic coherence.", "labels": [], "entities": []}, {"text": "Section 6 presents our evaluation.", "labels": [], "entities": []}, {"text": "Sections 7 and 8 discuss related and future work, and present our conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Recall from Section 3 that our evaluation task is to discriminate sentences that exhibit local coherence from those that do not; that sentences are represented as sequences of half-words; that syntactic coherence of a sentence is defined as all subsequences of a given length n exhibiting local coherence; and that a subsequence is locally coherent if its distance from a sequence in memory is less than \u03b8.", "labels": [], "entities": []}, {"text": "These definitions can be applied to the graph model as follows.", "labels": [], "entities": []}, {"text": "A left half-word is a left syntagmatic (or paradigmatic) distribution and aright halfword is aright syntagmatic (or paradigmatic) distribution.", "labels": [], "entities": []}, {"text": "We compute the distance of two half-words either as the Jensen-Shannon (JS) divergence or as (1 \u2212 cos(\u03b1)).", "labels": [], "entities": []}, {"text": "JS divergence is more appropriate for the comparison of probability distributions.", "labels": [], "entities": [{"text": "JS divergence", "start_pos": 0, "end_pos": 13, "type": "TASK", "confidence": 0.8461035192012787}]}, {"text": "But the cosine is more efficient when a sparse vector is compared to a dense vector.", "labels": [], "entities": []}, {"text": "We therefore employ the cosine for the compute-intensive experiments in Section 6.", "labels": [], "entities": []}, {"text": "The baseline representation is the categorical representation proposed by.", "labels": [], "entities": []}, {"text": "A difficulty in replicating their experiments is that they use hierarchical agglomerative clustering (HAC), which eventually agglomerates all words in a single category.", "labels": [], "entities": []}, {"text": "To circumvent the need fora stopping criterion, we represent each word as the temporal sequence of clusters it occurred in during agglomeration and define the distance of two words as the agglomeration step in which the two words are joined in a cluster.", "labels": [], "entities": []}, {"text": "E.g., given the agglomeration sequences {1}, {1, 2}, {1, 2, 4}, {1, 2, 3, 4} for w 1 and {4}, {4}, {1, 2, 4}, {1, 2, 3, 4} for w 4 , the distance between w 1 and w 4 is 3 since they are joined in step 3 when cluster {1, 2, 4} is created.", "labels": [], "entities": []}, {"text": "For both graded (graph-theoretic) and categorical (cluster-based) representations, we need to set the parameter \u03b8 that is the boundary between locally coherent and locally incoherent sentences.", "labels": [], "entities": []}, {"text": "This parameter gives rise to a precision-recall tradeoff.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 31, "end_pos": 47, "type": "METRIC", "confidence": 0.9965234398841858}]}, {"text": "A small \u03b8 will impose strict requirements on which sequences in memory match, resulting in false negative decisions for local grammaticality.", "labels": [], "entities": []}, {"text": "A large \u03b8 will incorrectly judge many locally incoherent sequences to be grammatical.", "labels": [], "entities": []}, {"text": "We will pick the optimal \u03b8 in both cases.", "labels": [], "entities": []}, {"text": "For categorical representations, this amounts to selecting the HAC dendrogram with optimal performance.", "labels": [], "entities": []}, {"text": "The experiment below evaluates whether grammatical and ungrammatical sentences are well separated by the proposed measure.", "labels": [], "entities": []}, {"text": "We used the wellknown CHILDES database), a corpus of conversations between young children and their playmates, siblings, and caretakers.", "labels": [], "entities": [{"text": "wellknown CHILDES database", "start_pos": 12, "end_pos": 38, "type": "DATASET", "confidence": 0.5584982832272848}]}, {"text": "In order to avoid mixing varieties of English (e.g., British English vs. American English), we selected the largest homogeneous subcorpus of CHILDES, the Manchester corpus.", "labels": [], "entities": [{"text": "CHILDES", "start_pos": 141, "end_pos": 148, "type": "DATASET", "confidence": 0.9023069739341736}, {"text": "Manchester corpus", "start_pos": 154, "end_pos": 171, "type": "DATASET", "confidence": 0.9854457080364227}]}, {"text": "It contains roughly 350,000 sentences and 1.5 million words.", "labels": [], "entities": []}, {"text": "This is a conservative estimate of the amount of child-directed speech a child would receive annually ().", "labels": [], "entities": []}, {"text": "All names in the corpus (i.e., all capitalized words) were replaced with a special word \" n \".", "labels": [], "entities": []}, {"text": "A boundary symbol \" b \" was introduced to separate sentences.", "labels": [], "entities": []}, {"text": "The representation of the corpus is then a concatenation of all its sentences.", "labels": [], "entities": []}, {"text": "The vocabulary consists of V = 8601 words.", "labels": [], "entities": []}, {"text": "Construction of the evaluation set.", "labels": [], "entities": []}, {"text": "We tested the ability of the two models to distinguish locally coherent vs. incoherent sentences by selecting 100 unattested sentences from the corpus, which were not used to train the model.", "labels": [], "entities": []}, {"text": "We only selected unattested sentences that were not a substring of a sentence in the training corpus since, presumably, any substring of a sentence in the training corpus is locally coherent.", "labels": [], "entities": []}, {"text": "A further constraint was that the unattested sentence was not allowed to contain a word that did not occur in the training corpus, the rationale being that we want to address the problem of local coherence for known words only since unknown words present special challenges.", "labels": [], "entities": []}, {"text": "Finally, we ensured that each unattested sentence contained a word that occurred in only one sentence type in the training corpus.", "labels": [], "entities": []}, {"text": "In early experiments, we found that local grammatical inference for frequent words is easy as there is redundant evidence available that characterizes legal syntactic environments for frequent words.", "labels": [], "entities": [{"text": "local grammatical inference", "start_pos": 36, "end_pos": 63, "type": "TASK", "confidence": 0.6553231676419576}]}, {"text": "Since rare words area key challenge in syntactic acquisition, we only selected sentences as unattested sentences that contained at least one rare word (where a rare word is defined as a word that occurs once in the training set).", "labels": [], "entities": [{"text": "syntactic acquisition", "start_pos": 39, "end_pos": 60, "type": "TASK", "confidence": 0.8216318488121033}]}, {"text": "100 ungrammatical sentences were generated by randomly selecting and concatenating words from the vocabulary.", "labels": [], "entities": []}, {"text": "Ungrammatical sentences were matched in length to unattested sentences, so that both sets contained the same number of sentences of a given length.", "labels": [], "entities": []}, {"text": "As with unattested sentences, ungrammatical sentences that were substrings of sentences in the training corpus were eliminated.", "labels": [], "entities": []}, {"text": "As there are many more infrequent words than frequent words in the vocabulary, the construction ensured that, as with unattested sentences, infrequent words were overrepresented in ungrammatical sentences.", "labels": [], "entities": []}, {"text": "To summarize, our setup consists of 348,463 training sentences, 100 unattested grammatical sentences and 100 ungrammatical sentences.", "labels": [], "entities": []}, {"text": "The task of discriminating the 100 unattested from the 100 ungrammatical sentences cannot be solved perfectly as CHILDES contains ungrammatical sentences, a few of which were randomly selected as unattested sentences (e.g., yes pleas, which is missing the final letter).", "labels": [], "entities": []}, {"text": "Similarly, one or two of the automatically generated ungrammatical sentences were actually grammatical.", "labels": [], "entities": []}, {"text": "Since the test set does not consist of a random sample of sentences, performance on the test set is not a direct indicator of the percentage of sentences that the model can correctly discriminate in a child's typical input.", "labels": [], "entities": []}, {"text": "A large proportion of sentences in child input are simple 1-word, 2-word, and 3-word sentences that even simplistic models can evaluate with high accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9907119870185852}]}, {"text": "However, the test set is appropriate fora comparative evaluation of graded and categorical syntactic representations in language acquisition, which is one of the goals of the paper.", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 120, "end_pos": 140, "type": "TASK", "confidence": 0.6904444098472595}]}, {"text": "Difficult sentences (those with rare words and greater length) are overrepresented in the test set as the discrimination of short sentences containing only frequent words can easily be done by simplistic models.", "labels": [], "entities": []}, {"text": "Thus, a test set of \"easy\" sentences would not distinguish good models from bad models.", "labels": [], "entities": []}, {"text": "In order to train the graph model, the entries of matrix J were estimated using maximum likelihood based on the training corpus.", "labels": [], "entities": []}, {"text": "p i,s,l,1 and p i,s,r,1 were then computed for all 8601 words., the most frequent 1000 words were clustered (using single-link HAC,).", "labels": [], "entities": []}, {"text": "For each remaining word w, the closest neighbor w \u2032 in the 1000 most frequent words was determined and w was then assigned to the cluster of w \u2032 . shows the performance of graded and categorical representations for different subsequence sizes n.", "labels": [], "entities": []}, {"text": "To compute the accuracy for each n, the \u03b8 with optimal discrimination performance was chosen (for both graded and categorical).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9992846846580505}]}, {"text": "For a subsequence of size n = 1, the performance is 0.5 in both cases since the 200-sentence test set does not contain unknown words.", "labels": [], "entities": []}, {"text": "So for every halfword, there is a sequence of one half-word in the training corpus with distance 0.", "labels": [], "entities": []}, {"text": "Thus, all sentences get the same local coherence scores, both for graded and categorical representations.", "labels": [], "entities": []}, {"text": "This argument does not apply ton = 2 since we earlier defined a sentence to be locally coherent if all of its subsequences are coherent.", "labels": [], "entities": []}, {"text": "While subsequences of 2 half-words that are part of the same word have local coherence score 0, this is not true of subsequences of 2 half-words that are part of different words, e.g., the subsequence <black r ,dog l > in black dog.", "labels": [], "entities": []}, {"text": "If black dog does not occur in the training set, then its local coherence score is > 0.", "labels": [], "entities": []}, {"text": "The main result of the experiment is that except for n=1 (p = 1) and n=2 (p = 0.39) the differences between categorical and graded representations are significant (\u03c7 2 test, p < 0.05 for 3 \u2264 n \u2264 10).", "labels": [], "entities": []}, {"text": "This is evidence that graded representations are more accurate when determining local syntactic coherence and grammaticality than categorical representations.", "labels": [], "entities": []}, {"text": "The experimental results demonstrate that, for syntagmatic distributions of order 1, graded representations discriminate locally coherent vs. incoherent sentences better than categorical representations.", "labels": [], "entities": []}, {"text": "We attribute this to the ability of exemplar theory to incorporate rich context information into discrimination decisions.", "labels": [], "entities": []}, {"text": "This is of particular importance for ambiguous words.", "labels": [], "entities": []}, {"text": "Categorical representations of ambiguous words are problematic because they are either too similar or not similar enough to the two alternatives.", "labels": [], "entities": []}, {"text": "E.g., if a word with a verb/noun ambiguity is represented as one of the alternatives, say, as a verb, then subsequences containing its noun use will no longer be similar to other subsequences with nouns.", "labels": [], "entities": []}, {"text": "If a special conflation category noun/verb is introduced, then we are faced with the same problem: subsequences containing the noun/verb category are not similar to subsequences containing either non-ambiguous verbs or non-ambiguous nouns.", "labels": [], "entities": []}], "tableCaptions": []}