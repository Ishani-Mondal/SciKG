{"title": [{"text": "Latent-Variable Modeling of String Transductions with Finite-State Methods *", "labels": [], "entities": [{"text": "Latent-Variable Modeling of String Transductions", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.6782076776027679}]}], "abstractContent": [{"text": "String-to-string transduction is a central problem in computational linguistics and natural language processing.", "labels": [], "entities": [{"text": "String-to-string transduction", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7494401931762695}, {"text": "natural language processing", "start_pos": 84, "end_pos": 111, "type": "TASK", "confidence": 0.6504780352115631}]}, {"text": "It occurs in tasks as diverse as name transliteration, spelling correction , pronunciation modeling and inflectional morphology.", "labels": [], "entities": [{"text": "name transliteration", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.8156858086585999}, {"text": "spelling correction", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.9366245865821838}, {"text": "pronunciation modeling", "start_pos": 77, "end_pos": 99, "type": "TASK", "confidence": 0.9080320000648499}]}, {"text": "We present a conditional log-linear model for string-to-string transduction, which employs overlapping features over latent alignment sequences, and which learns latent classes and latent string pair regions from incomplete training data.", "labels": [], "entities": [{"text": "string-to-string transduction", "start_pos": 46, "end_pos": 75, "type": "TASK", "confidence": 0.7115953862667084}]}, {"text": "We evaluate our approach on morphological tasks and demonstrate that latent variables can dramatically improve results, even when trained on small data sets.", "labels": [], "entities": []}, {"text": "On the task of generating morphological forms, we outperform a baseline method reducing the error rate by up to 48%.", "labels": [], "entities": [{"text": "error rate", "start_pos": 92, "end_pos": 102, "type": "METRIC", "confidence": 0.9862448871135712}]}, {"text": "On a lemmatization task, we reduce the error rates in Wicentowski (2002) by 38-92%.", "labels": [], "entities": [{"text": "error rates", "start_pos": 39, "end_pos": 50, "type": "METRIC", "confidence": 0.9825038313865662}]}], "introductionContent": [{"text": "A recurring problem in computational linguistics and language processing is transduction of character strings, e.g., words.", "labels": [], "entities": [{"text": "language processing", "start_pos": 53, "end_pos": 72, "type": "TASK", "confidence": 0.7288703620433807}, {"text": "transduction of character strings", "start_pos": 76, "end_pos": 109, "type": "TASK", "confidence": 0.8064715713262558}]}, {"text": "That is, one wishes to model some systematic mapping from an input string x to an output stringy.", "labels": [], "entities": []}, {"text": "Applications include: \u2022 phonology: underlying representation \u2194 surface representation \u2022 orthography: pronunciation \u2194 spelling \u2022 morphology: inflected form \u2194 lemma, or differently inflected form \u2022 fuzzy name matching (duplicate detection) and spelling correction: spelling \u2194 variant spelling * This work was supported by the Human Language Technology Center of Excellence and by National Science Foundation grant No. 0347822 to the final author.", "labels": [], "entities": [{"text": "fuzzy name matching", "start_pos": 196, "end_pos": 215, "type": "TASK", "confidence": 0.665120929479599}, {"text": "spelling correction", "start_pos": 242, "end_pos": 261, "type": "TASK", "confidence": 0.6514556705951691}]}, {"text": "We would also like to thank Richard Wicentowski for providing us with datasets for lemmatization, and the anonymous reviewers for their valuable feedback.", "labels": [], "entities": []}, {"text": "\u2022 lexical translation (cognates, loanwords, transliterated names): English word \u2194 foreign word We present a configurable and robust framework for solving such word transduction problems.", "labels": [], "entities": [{"text": "lexical translation (cognates, loanwords, transliterated names", "start_pos": 2, "end_pos": 64, "type": "TASK", "confidence": 0.7547922597991096}, {"text": "word transduction", "start_pos": 159, "end_pos": 176, "type": "TASK", "confidence": 0.7548178136348724}]}, {"text": "Our results in morphology generation show that the presented approach improves upon the state of the art.", "labels": [], "entities": [{"text": "morphology generation", "start_pos": 15, "end_pos": 36, "type": "TASK", "confidence": 0.7670679092407227}]}], "datasetContent": [{"text": "We evaluate our model on two tasks of morphology generation.", "labels": [], "entities": [{"text": "morphology generation", "start_pos": 38, "end_pos": 59, "type": "TASK", "confidence": 0.7536058127880096}]}, {"text": "Predicting morphological forms has been shown to be useful for machine translation and other tasks.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.8113459944725037}]}, {"text": "Here we describe two sets of experiments: an inflectional morphology task in which models are trained to transduce verbs from one form into another (section 4.2), and a lemmatization task (section 4.3), in which any inflected verb is to be reduced to its root form.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Exact-match accuracy and average edit distance (the latter in parentheses) versus the correct answer on the  German inflection task, using different combinations of feature classes. The label ngrams corresponds to the second  stage of training, ngrams+x to the third where backoff features may fire (vc = vowel/consonant, tlm = target LM, tlm- coll = collapsed tlm, id = identity/substitution/deletion features), and ngrams+x+latent to the fourth where features  sensitive to latent classes and latent regions are allowed to fire. The highest n-gram order used is 3, except for Moses9  and Moses15 which examine windows of up to 9 and 15 characters, respectively. We mark in bold the best result for  each dataset, along with all results that are statistically indistinguishable (paired permutation test, p < 0.05).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9964964985847473}]}, {"text": " Table 3: Exact-match accuracy and average edit distance (the latter in parentheses) on the 8 lemmatization tasks (2  tasks \u00d7 4 languages). The numbers from Wicentowski (2002) are for his Base, Affix and WFAffix models. The  numbers for our models are for the feature sets ngrams, ngrams+x, ngrams+x+latent. The best result per task is in  bold (as are statistically indistinguishable results when we can do the comparison, i.e., for our own models). Corpus  sizes: Basque 5,842, English 4,915, Irish 1,376, Tagalog 9,479.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9853163361549377}, {"text": "average edit distance", "start_pos": 35, "end_pos": 56, "type": "METRIC", "confidence": 0.6282494068145752}, {"text": "Affix", "start_pos": 194, "end_pos": 199, "type": "METRIC", "confidence": 0.9189549088478088}]}]}