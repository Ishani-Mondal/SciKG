{"title": [{"text": "Automatic induction of FrameNet lexical units", "labels": [], "entities": []}], "abstractContent": [{"text": "Most attempts to integrate FrameNet in NLP systems have so far failed because of its limited coverage.", "labels": [], "entities": []}, {"text": "In this paper, we investigate the applicability of distributional and WordNet-based models on the task of lexical unit induction , i.e. the expansion of FrameNet with new lexical units.", "labels": [], "entities": [{"text": "lexical unit induction", "start_pos": 106, "end_pos": 128, "type": "TASK", "confidence": 0.6878006060918173}]}, {"text": "Experimental results show that our distributional and WordNet-based models achieve good level of accuracy and coverage, especially when combined.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9992535710334778}, {"text": "coverage", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9792385697364807}]}], "introductionContent": [{"text": "Most inference-based NLP tasks require a large amount of semantic knowledge at the predicateargument level.", "labels": [], "entities": []}, {"text": "This type of knowledge allows to identify meaning-preserving transformations, such as active/passive, verb alternations and nominalizations, which are crucial in several linguistic inferences.", "labels": [], "entities": []}, {"text": "Recently, the integration of NLP systems with manually-built resources at the predicate argument-level, such as FrameNet () and) has received growing interest.", "labels": [], "entities": []}, {"text": "For example, show the potential improvement that FrameNet can bring on the performance of a Question Answering (QA) system.", "labels": [], "entities": [{"text": "Question Answering (QA)", "start_pos": 92, "end_pos": 115, "type": "TASK", "confidence": 0.8260964334011078}]}, {"text": "Similarly, several other studies (e.g. () indicate that frame semantics plays a central role in Recognizing Textual Entailment (RTE).", "labels": [], "entities": [{"text": "Recognizing Textual Entailment (RTE)", "start_pos": 96, "end_pos": 132, "type": "TASK", "confidence": 0.8640323380629221}]}, {"text": "Unfortunately, most attempts to integrate FrameNet or similar resources in QA and RTE systems have so far failed, as reviewed respectively in and ).", "labels": [], "entities": []}, {"text": "These studies indicate limited coverage as the main reason of insuccess.", "labels": [], "entities": [{"text": "coverage", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9772847890853882}]}, {"text": "Indeed, the FrameNet database only contains 10,000 lexical units (LUs), far less than the 210,000 entries in WordNet 3.0.", "labels": [], "entities": [{"text": "FrameNet database", "start_pos": 12, "end_pos": 29, "type": "DATASET", "confidence": 0.8786610066890717}]}, {"text": "Also, frames are based on more complex information than word senses, so that their manual development is much more demanding.", "labels": [], "entities": []}, {"text": "Therefore, there is nowadays a pressing need to adopt learning approaches to extend the coverage of the FrameNet lexicon by automatically acquiring new LUs, a task we call LU induction, as recently proposed at.", "labels": [], "entities": [{"text": "FrameNet lexicon", "start_pos": 104, "end_pos": 120, "type": "DATASET", "confidence": 0.8590401113033295}, {"text": "LU induction", "start_pos": 172, "end_pos": 184, "type": "TASK", "confidence": 0.6203361749649048}]}, {"text": "Unfortunately, research in this area is still somehow limited and fragmentary.", "labels": [], "entities": []}, {"text": "The aim of our study is to pioneer in this field by proposing two unsupervised models for LU induction, one based on distributional techniques and one using WordNet as a support; and a combined model which mixes the two.", "labels": [], "entities": [{"text": "LU induction", "start_pos": 90, "end_pos": 102, "type": "TASK", "confidence": 0.9237493276596069}, {"text": "WordNet", "start_pos": 157, "end_pos": 164, "type": "DATASET", "confidence": 0.9428832530975342}]}, {"text": "The goal is to investigate to what extent distributional and WordNet-based models can be used to induce frame semantic knowledge in order to safely extend FrameNet, thus limiting the high costs of manual annotation.", "labels": [], "entities": []}, {"text": "In Section 2 we introduce the LU induction task and present related work.", "labels": [], "entities": [{"text": "LU induction task", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.7455987830956777}]}, {"text": "In Sections 3, 4 and 5 we present our distributional, WordNet-based and combined models.", "labels": [], "entities": []}, {"text": "Then, in Section 6 we report experimental results and comparative evaluations.", "labels": [], "entities": []}, {"text": "Finally, in Section 7 we draw final conclusions and outline future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present a comparative evaluation of our models on the task of inducing LUs, in a leave-one-out setting over a reference gold standard.", "labels": [], "entities": []}, {"text": "Our gold standard is the FrameNet 1.3 database, containing 795 frames and a set L of 7,522 unique LUs (in all there are 10,196 LUs possibly assigned to more than one frame).", "labels": [], "entities": [{"text": "FrameNet 1.3 database", "start_pos": 25, "end_pos": 46, "type": "DATASET", "confidence": 0.833816667397817}]}, {"text": "Given a lexical unit l \u2208 L, we simulate the induction task by executing a leaveone-out procedure, similarly to Burchardt and colleagues (2005).", "labels": [], "entities": []}, {"text": "First, we remove l from all its original frames.", "labels": [], "entities": []}, {"text": "Then, we ask our models to reassign it to the most similar frame(s) f , according to the similarity measure . We repeat this procedure for all lexical units.", "labels": [], "entities": []}, {"text": "Though our experiment is not completely realistic (we test over LUs already in FrameNet), it has the advantage of a reliable gold standard produced by expert annotators.", "labels": [], "entities": [{"text": "FrameNet", "start_pos": 79, "end_pos": 87, "type": "DATASET", "confidence": 0.910892128944397}]}, {"text": "A second, more realistic, small-scale experiment is described in Section 6.2.", "labels": [], "entities": []}, {"text": "We compute accuracy as the fraction of LUs in L that are correctly re-assigned to the original frame.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.999257504940033}]}, {"text": "Accuracy is computed at different levels k: a LU l is correctly assigned if its gold standard frame appears among the best-k frames f ranked by the model using the sim(l, f ) measure.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9875820875167847}]}, {"text": "As LUs can have more than one correct frame, we deem as correct an assignment for which at least one of the correct frames is among the best-k.", "labels": [], "entities": []}, {"text": "We also measure coverage, intended as the percentage of LUs that have been assigned to at least one frame by the model.", "labels": [], "entities": [{"text": "coverage", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9969056248664856}]}, {"text": "Notice that when no sense preference can be found above the threshold , the WordNet-based model cannot predict any frame, thus decreasing coverage.", "labels": [], "entities": [{"text": "WordNet-based", "start_pos": 76, "end_pos": 89, "type": "DATASET", "confidence": 0.9148204326629639}, {"text": "coverage", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9593572020530701}]}, {"text": "We present results for the following models and parametrizations (further parametrizations have revealed comparable performance).", "labels": [], "entities": []}, {"text": "Dist-word : the word-based space described in Section 3.", "labels": [], "entities": []}, {"text": "Contextual features correspond to the set of the 4,000 most frequent words in the BNC.", "labels": [], "entities": [{"text": "BNC", "start_pos": 82, "end_pos": 85, "type": "DATASET", "confidence": 0.9396910667419434}]}, {"text": "The association measure between LUs and contexts is the pointwise mutual information.", "labels": [], "entities": []}, {"text": "Valid contexts for LUs are fixed to a 20-window.", "labels": [], "entities": []}, {"text": "Dist-syntax : the syntax-based space described in Section 3.", "labels": [], "entities": []}, {"text": "Context features are the 10,000 most frequent syntactic relations in the BNC . As association measure we apply log-likelihood ratio) to normalized frequency.", "labels": [], "entities": [{"text": "BNC", "start_pos": 73, "end_pos": 76, "type": "DATASET", "confidence": 0.9181758761405945}]}, {"text": "Syntactic relations are extracted using the Minipar parser.", "labels": [], "entities": [{"text": "Minipar", "start_pos": 44, "end_pos": 51, "type": "DATASET", "confidence": 0.9691248536109924}]}, {"text": "Dist-mixed : the mixed space described in Sec-tion 3.", "labels": [], "entities": []}, {"text": "As for the Dist-word model, contextual features are 4,000 and pointwise mutual information is the association measure.", "labels": [], "entities": []}, {"text": "The maximal dependency path length for selecting each context word is 3.", "labels": [], "entities": [{"text": "maximal dependency path length", "start_pos": 4, "end_pos": 34, "type": "METRIC", "confidence": 0.77145866304636}]}, {"text": "Syntactic relations are extracted using Minipar.", "labels": [], "entities": [{"text": "Minipar", "start_pos": 40, "end_pos": 47, "type": "DATASET", "confidence": 0.9695596694946289}]}, {"text": "WNet-full : the WordNet based model described in Section 4.", "labels": [], "entities": [{"text": "WNet-full", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9022865891456604}]}, {"text": "WNet-bsense : this model is computed as WNetfull but using only the most frequent sense for each LU as defined in WordNet.", "labels": [], "entities": [{"text": "WNet-bsense", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.8691635131835938}, {"text": "WNetfull", "start_pos": 40, "end_pos": 48, "type": "DATASET", "confidence": 0.9237525463104248}, {"text": "WordNet", "start_pos": 114, "end_pos": 121, "type": "DATASET", "confidence": 0.9608623385429382}]}, {"text": "Combined : the combined method presented in Section 5.", "labels": [], "entities": []}, {"text": "Specifically, it uses WNet-full as a default and Dist-word as back-off.", "labels": [], "entities": [{"text": "WNet-full", "start_pos": 22, "end_pos": 31, "type": "DATASET", "confidence": 0.9501102566719055}]}, {"text": "Baseline-rnd : a baseline model, randomly assigning LUs to frames.", "labels": [], "entities": []}, {"text": "Baseline-mostfreq : a model predicting as best-k frames the most likely ones in FrameNet -i.e. those containing the highest number of LUs.", "labels": [], "entities": []}, {"text": "reports accuracy and coverage results for the different models, considering only 6792 LUs with frequency higher than 5 in the BNC, and frames with more than 2 lexical units (to allow better generalizations in all models).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.9995015859603882}, {"text": "coverage", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9816372990608215}, {"text": "BNC", "start_pos": 126, "end_pos": 129, "type": "DATASET", "confidence": 0.9165816307067871}]}, {"text": "Results show that all our models largely outperform both baselines, achieving a good level of accuracy and high coverage.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9995046854019165}, {"text": "coverage", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.99644935131073}]}, {"text": "In particular, accuracy for the best-10 frames is high enoungh to support tasks such as the semi-automatic creation of new FrameNets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9992544054985046}]}, {"text": "This claim is supported by a further task-driven experiment, in which we asked 3 annotators to assign 60 unknown LUs (from the Detour system log) to frames, with and without the support of the Dist-word model's predictions as suggestions . We verified that our model guarantee an annotation speed-up of 25% -i.e. in average an annotator saves 25% of annotation time by using the system's suggestions.", "labels": [], "entities": [{"text": "Detour system log", "start_pos": 127, "end_pos": 144, "type": "DATASET", "confidence": 0.8024928967157999}]}], "tableCaptions": [{"text": " Table 1: Accuracy and coverage of different models on best-k ranking with frequency threshold 5 and frame threshold  2", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9975329637527466}, {"text": "coverage", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9577139616012573}, {"text": "frame", "start_pos": 101, "end_pos": 106, "type": "METRIC", "confidence": 0.9556525349617004}]}]}