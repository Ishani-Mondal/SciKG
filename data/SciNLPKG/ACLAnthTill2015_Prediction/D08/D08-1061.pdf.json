{"title": [{"text": "Weakly-Supervised Acquisition of Labeled Class Instances using Graph Random Walks", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a graph-based semi-supervised label propagation algorithm for acquiring open-domain labeled classes and their instances from a combination of unstructured and struc-tured text sources.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.7592991590499878}]}, {"text": "This acquisition method significantly improves coverage compared to a previous set of labeled classes and instances derived from free text, while achieving comparable precision.", "labels": [], "entities": [{"text": "coverage", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9490744471549988}, {"text": "precision", "start_pos": 167, "end_pos": 176, "type": "METRIC", "confidence": 0.9973158240318298}]}], "introductionContent": [], "datasetContent": [{"text": "We evaluated the Adsorption algorithm under two experimental settings.", "labels": [], "entities": [{"text": "Adsorption", "start_pos": 17, "end_pos": 27, "type": "TASK", "confidence": 0.9390062093734741}]}, {"text": "First, we evaluate Adsorption's extraction precision on (instance, class) pairs obtained by Adsorption but not present in A8 (Section 5.1).", "labels": [], "entities": [{"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.6064131855964661}, {"text": "A8", "start_pos": 122, "end_pos": 124, "type": "DATASET", "confidence": 0.903813362121582}]}, {"text": "This measures whether Adsorption can add to the A8 extractions at fairly high precision.", "labels": [], "entities": [{"text": "A8 extractions", "start_pos": 48, "end_pos": 62, "type": "TASK", "confidence": 0.5473527908325195}, {"text": "precision", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9950254559516907}]}, {"text": "Second, we measured Adsorption's ability to assign labels to a fixed set of gold instances drawn from various classes (Section 5.2).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2.  Adsorption was run for each class separately and the resulting ranked extractions were manually evalu- ated.  Since the A8 system does not produce ranked lists  of instances, we chose 100 random instances from  the A8 results to compare to the top 100 instances  produced by Adsorption. Each of the resulting 500  instance-class pairs (i, C) was presented to two hu- man evaluators, who were asked to evaluate whether  the relation \"i is a C\" was correct or incorrect. The  user was also presented with Web search link to ver- ify the results against actual documents. Results  from these experiments are presented in", "labels": [], "entities": []}, {"text": " Table 4: Precision of top 100 Adsorption extractions (for  five classes) which were not present in A8.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9854132533073425}, {"text": "Adsorption extractions", "start_pos": 31, "end_pos": 53, "type": "TASK", "confidence": 0.9535074830055237}, {"text": "A8", "start_pos": 100, "end_pos": 102, "type": "DATASET", "confidence": 0.9128273725509644}]}, {"text": " Table 6: Mean-Reciprocal Rank scores of instance class  labels over 38 Wordnet classes (WN-gold). MRR (full)  refers to evaluation across the entire gold instance set.  MRR (found only) computes MRR only on recalled in- stances.", "labels": [], "entities": [{"text": "Mean-Reciprocal Rank scores", "start_pos": 10, "end_pos": 37, "type": "METRIC", "confidence": 0.9256704250971476}, {"text": "Wordnet", "start_pos": 72, "end_pos": 79, "type": "DATASET", "confidence": 0.9270333647727966}, {"text": "MRR", "start_pos": 99, "end_pos": 102, "type": "METRIC", "confidence": 0.9578049182891846}, {"text": "MRR", "start_pos": 196, "end_pos": 199, "type": "METRIC", "confidence": 0.8245782852172852}]}]}