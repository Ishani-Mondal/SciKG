{"title": [{"text": "Sampling Alignment Structure under a Bayesian Translation Model", "labels": [], "entities": [{"text": "Sampling Alignment Structure", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.9126790364583334}]}], "abstractContent": [{"text": "We describe the first tractable Gibbs sampling procedure for estimating phrase pair frequencies under a probabilistic model of phrase alignment.", "labels": [], "entities": [{"text": "phrase alignment", "start_pos": 127, "end_pos": 143, "type": "TASK", "confidence": 0.8137454986572266}]}, {"text": "We propose and evaluate two nonparametric priors that successfully avoid the degenerate behavior noted in previous work, where overly large phrases memorize the training data.", "labels": [], "entities": []}, {"text": "Phrase table weights learned under our model yield an increase in BLEU score over the word-alignment based heuristic estimates used regularly in phrase-based translation systems.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 66, "end_pos": 76, "type": "METRIC", "confidence": 0.9827362596988678}, {"text": "phrase-based translation", "start_pos": 145, "end_pos": 169, "type": "TASK", "confidence": 0.7042042911052704}]}], "introductionContent": [{"text": "In phrase-based translation, statistical knowledge of translation equivalence is primarily captured by counts of how frequently various phrase pairs occur in training bitexts.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 3, "end_pos": 27, "type": "TASK", "confidence": 0.7474275231361389}, {"text": "translation equivalence", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.9104167222976685}]}, {"text": "Since bitexts do not come segmented and aligned into phrase pairs, these counts are typically gathered by fixing a word alignment and applying phrase extraction heuristics to this word-aligned training corpus.", "labels": [], "entities": [{"text": "phrase extraction heuristics", "start_pos": 143, "end_pos": 171, "type": "TASK", "confidence": 0.7730263272921244}]}, {"text": "Alternatively, phrase pair frequencies can be learned via a probabilistic model of phrase alignment, but this approach has presented several practical challenges.", "labels": [], "entities": [{"text": "phrase alignment", "start_pos": 83, "end_pos": 99, "type": "TASK", "confidence": 0.8150418996810913}]}, {"text": "In this paper, we address the two most significant challenges in phrase alignment modeling.", "labels": [], "entities": [{"text": "phrase alignment modeling", "start_pos": 65, "end_pos": 90, "type": "TASK", "confidence": 0.9421249230702718}]}, {"text": "The first challenge is with inference: computing alignment expectations under general phrase models is #P-hard.", "labels": [], "entities": []}, {"text": "Previous phrase alignment work has sacrificed consistency for efficiency, employing greedy hill-climbing algorithms and constraining inference with word alignments ().", "labels": [], "entities": [{"text": "phrase alignment", "start_pos": 9, "end_pos": 25, "type": "TASK", "confidence": 0.8257052302360535}, {"text": "consistency", "start_pos": 46, "end_pos": 57, "type": "METRIC", "confidence": 0.9615980386734009}]}, {"text": "We describe a Gibbs sampler that consistently and efficiently approximates expectations, using only polynomial-time computable operators.", "labels": [], "entities": []}, {"text": "Despite the combinatorial complexity of the phrase alignment space, our sampled phrase pair expectations are guaranteed to converge to the true posterior distributions under the model (in theory) and do converge to effective values (in practice).", "labels": [], "entities": [{"text": "phrase alignment", "start_pos": 44, "end_pos": 60, "type": "TASK", "confidence": 0.7429710030555725}]}, {"text": "The second challenge in learning phrase alignments is avoiding a degenerate behavior of the general model class: as with many models which can choose between large and small structures, the larger structures win out in maximum likelihood estimation.", "labels": [], "entities": [{"text": "learning phrase alignments", "start_pos": 24, "end_pos": 50, "type": "TASK", "confidence": 0.6285453836123148}]}, {"text": "Indeed, the maximum likelihood estimate of a joint phrase alignment model analyzes each sentence pair as one large phrase with no internal structure ().", "labels": [], "entities": [{"text": "joint phrase alignment", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.6668514211972555}]}, {"text": "We describe two nonparametric priors that empirically avoid this degenerate solution.", "labels": [], "entities": []}, {"text": "Fixed word alignments are used in virtually every statistical machine translation system, if not to extract phrase pairs or rules directly, then at least to constrain the inference procedure for higher-level models.", "labels": [], "entities": [{"text": "Fixed word alignments", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.655232310295105}, {"text": "statistical machine translation", "start_pos": 50, "end_pos": 81, "type": "TASK", "confidence": 0.6355421940485636}]}, {"text": "We estimate phrase translation features consistently using an inference procedure that is not constrained byword alignments, or any other heuristic.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.7898249924182892}]}, {"text": "Despite this substantial change in approach, we report translation improvements over the standard word-alignment-based heuristic estimates of phrase table weights.", "labels": [], "entities": []}, {"text": "We view this result as an important step toward building fully model-based translation systems that rely on fewer procedural heuristics.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: BLEU results for learned distributions improve  over a heuristic baseline. Estimate labels are described  fully in section 5.3. The label lex indicates the addition  of a lexical weighting feature.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9978426694869995}]}]}