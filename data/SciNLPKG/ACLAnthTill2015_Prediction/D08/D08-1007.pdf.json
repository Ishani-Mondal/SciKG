{"title": [{"text": "Discriminative Learning of Selectional Preference from Unlabeled Text", "labels": [], "entities": [{"text": "Discriminative Learning of Selectional Preference from Unlabeled Text", "start_pos": 0, "end_pos": 69, "type": "TASK", "confidence": 0.7413414306938648}]}], "abstractContent": [{"text": "We present a discriminative method for learning selectional preferences from unlabeled text.", "labels": [], "entities": []}, {"text": "Positive examples are taken from observed predicate-argument pairs, while negatives are constructed from unobserved combinations.", "labels": [], "entities": []}, {"text": "We train a Support Vector Machine classifier to distinguish the positive from the negative instances.", "labels": [], "entities": []}, {"text": "We show how to partition the examples for efficient training with 57 thousand features and 6.5 million training instances.", "labels": [], "entities": []}, {"text": "The model outperforms other recent approaches, achieving excellent correlation with human plausibility judgments.", "labels": [], "entities": []}, {"text": "Compared to Mutual Information, it identifies 66% more verb-object pairs in unseen text, and resolves 37% more pronouns correctly in a pronoun resolution experiment.", "labels": [], "entities": [{"text": "Mutual Information", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.859764575958252}, {"text": "pronoun resolution", "start_pos": 135, "end_pos": 153, "type": "TASK", "confidence": 0.8351320922374725}]}], "introductionContent": [{"text": "Selectional preferences (SPs) tell us which arguments are plausible fora particular predicate.", "labels": [], "entities": []}, {"text": "For example, (Section 4.4) lists plausible and implausible direct objects (arguments) for particular verbs (predicates).", "labels": [], "entities": []}, {"text": "SPs can help resolve syntactic, word sense, and reference ambiguity), and so gathering them has received a lot of attention in the NLP community.", "labels": [], "entities": []}, {"text": "One way to determine SPs is from co-occurrences of predicates and arguments in text.", "labels": [], "entities": [{"text": "SPs", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.6333237290382385}]}, {"text": "Unfortunately, no matter how much text we use, many acceptable pairs will be missing.", "labels": [], "entities": []}, {"text": "found that only 1.49% of the bilexical dependencies considered by Collins' parser during decoding were observed during training.", "labels": [], "entities": []}, {"text": "In our parsed corpus (Section 4.1), for example, we find eat with nachos, burritos, and tacos, but not with the equally tasty quesadillas, chimichangas, or tostadas.", "labels": [], "entities": []}, {"text": "Rather than solely relying on co-occurrence counts, we would like to use them to generalize to unseen pairs.", "labels": [], "entities": []}, {"text": "In particular, we would like to exploit a number of arbitrary and potentially overlapping properties of predicates and arguments when we assign SPs.", "labels": [], "entities": []}, {"text": "We do this by representing these properties as features in a linear classifier, and training the weights using discriminative learning.", "labels": [], "entities": []}, {"text": "Positive examples are taken from observed predicate-argument pairs, while pseudo-negatives are constructed from unobserved combinations.", "labels": [], "entities": []}, {"text": "We train a Support Vector Machine (SVM) classifier to distinguish the positives from the negatives.", "labels": [], "entities": []}, {"text": "We refer to our model's scores as Discriminative Selectional Preference (DSP).", "labels": [], "entities": [{"text": "Discriminative Selectional Preference (DSP)", "start_pos": 34, "end_pos": 77, "type": "METRIC", "confidence": 0.674369345108668}]}, {"text": "By creating training vectors automatically, DSP enjoys all the advantages of supervised learning, but without the need for manual annotation of examples.", "labels": [], "entities": []}, {"text": "We evaluate DSP on the task of assigning verbobject selectional preference.", "labels": [], "entities": [{"text": "DSP", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.8308887481689453}]}, {"text": "We encode a noun's textual distribution as feature information.", "labels": [], "entities": []}, {"text": "The learned feature weights are linguistically interesting, yielding high-quality similar-word lists as latent information.", "labels": [], "entities": []}, {"text": "Despite its representational power, DSP scales to real-world data sizes: examples are partitioned by predicate, and a separate SVM is trained for each partition.", "labels": [], "entities": []}, {"text": "This allows us to efficiently learn with over 57 thousand features and 6.5 million examples.", "labels": [], "entities": []}, {"text": "DSP outperforms recently proposed alternatives in a range of experiments, and better correlates with human plausibility judgments.", "labels": [], "entities": []}, {"text": "It also shows strong gains over a Mutual Information-based co-occurrence model on two tasks: identifying objects of verbs in an unseen corpus and finding pronominal antecedents in coreference data.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Pseudodisambiguation results averaged across each example (MacroAvg), weighted by word frequency (Mi- croAvg), plus coverage and accuracy of pairwise competition (Pairwise).", "labels": [], "entities": [{"text": "word frequency (Mi- croAvg)", "start_pos": 92, "end_pos": 119, "type": "METRIC", "confidence": 0.7086376803261893}, {"text": "coverage", "start_pos": 126, "end_pos": 134, "type": "METRIC", "confidence": 0.9879807829856873}, {"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9985427856445312}]}, {"text": " Table 3: Recall on identification of Verb-Object pairs  from an unseen corpus (divided by pair frequency).", "labels": [], "entities": []}, {"text": " Table 2: Selectional ratings for plausible/implausible direct objects (Holmes", "labels": [], "entities": []}, {"text": " Table 4: Pronoun resolution accuracy on nouns in current  or previous sentence in MUC.", "labels": [], "entities": [{"text": "Pronoun resolution", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.8402885794639587}, {"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9429788589477539}, {"text": "MUC", "start_pos": 83, "end_pos": 86, "type": "DATASET", "confidence": 0.6408732533454895}]}]}