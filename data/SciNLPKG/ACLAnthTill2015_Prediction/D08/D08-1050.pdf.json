{"title": [{"text": "Adapting a Lexicalized-Grammar Parser to Contrasting Domains", "labels": [], "entities": [{"text": "Adapting", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.9739358425140381}]}], "abstractContent": [{"text": "Most state-of-the-art wide-coverage parsers are trained on newspaper text and suffer a loss of accuracy in other domains, making parser adaptation a pressing issue.", "labels": [], "entities": [{"text": "wide-coverage parsers", "start_pos": 22, "end_pos": 43, "type": "TASK", "confidence": 0.5906934440135956}, {"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9967151880264282}, {"text": "parser adaptation", "start_pos": 129, "end_pos": 146, "type": "TASK", "confidence": 0.9384715855121613}]}, {"text": "In this paper we demonstrate that a CCG parser can be adapted to two new domains, biomedical text and questions fora QA system, by using manually-annotated training data at the POS and lexical category levels only.", "labels": [], "entities": []}, {"text": "This approach achieves parser accuracy comparable to that on newspaper data without the need for annotated parse trees in the new domain.", "labels": [], "entities": [{"text": "parser", "start_pos": 23, "end_pos": 29, "type": "TASK", "confidence": 0.960177481174469}, {"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.8954735398292542}]}, {"text": "We find that retraining at the lexical category level yields a larger performance increase for questions than for biomedical text and analyze the two datasets to investigate why different domains might behave differently for parser adaptation.", "labels": [], "entities": [{"text": "parser adaptation", "start_pos": 225, "end_pos": 242, "type": "TASK", "confidence": 0.9079496562480927}]}], "introductionContent": [{"text": "Most state-of-the-art wide-coverage parsers are based on the Penn Treebank (, making such parsers highly tuned to newspaper text.", "labels": [], "entities": [{"text": "Penn Treebank (", "start_pos": 61, "end_pos": 76, "type": "DATASET", "confidence": 0.9907957514127096}]}, {"text": "A pressing question facing the parsing community is how to adapt these parsers to other domains, such as biomedical research papers and web pages.", "labels": [], "entities": [{"text": "parsing community", "start_pos": 31, "end_pos": 48, "type": "TASK", "confidence": 0.9105426967144012}]}, {"text": "A related question is how to improve the performance of these parsers on constructions that are rare in the Penn Treebank, such as questions.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 108, "end_pos": 121, "type": "DATASET", "confidence": 0.995219886302948}]}, {"text": "Questions are particularly important since a question parser is a component inmost Question Answering (QA) systems (.", "labels": [], "entities": [{"text": "Question Answering (QA)", "start_pos": 83, "end_pos": 106, "type": "TASK", "confidence": 0.8153495192527771}]}, {"text": "In this paper we investigate parser adaptation in the context of lexicalized grammars, by using a parser based on Combinatory Categorial Grammar (CCG).", "labels": [], "entities": [{"text": "parser adaptation", "start_pos": 29, "end_pos": 46, "type": "TASK", "confidence": 0.8902774453163147}]}, {"text": "A key property of CCG is that it is lexicalized, meaning that each word in a sentence is associated with an elementary syntactic structure.", "labels": [], "entities": []}, {"text": "In the case of CCG this is a lexical category expressing subcategorization information.", "labels": [], "entities": []}, {"text": "We exploit this property of CCG by performing manual annotation in the new domain, but only up to this level of representation, where the annotation can be carried out relatively quickly.", "labels": [], "entities": []}, {"text": "Since CCG lexical categories are so expressive, many of the syntactic characteristics of a domain are captured at this level.", "labels": [], "entities": []}, {"text": "The two domains we consider are the biomedical domain and questions fora QA system.", "labels": [], "entities": []}, {"text": "We use the term \"domain\" somewhat loosely here, since questions are best described as a particular set of syntactic constructions, rather than a set of documents about a particular topic.", "labels": [], "entities": []}, {"text": "However, we consider question data to be interesting in the context of domain adaptation for the following reasons: 1) there are few examples in the Penn Treebank (PTB) and so PTB parsers typically perform poorly on them; 2) questions form a fairly homogeneous set with respect to the syntactic constructions employed, and it is an interesting question how easy it is to adapt a parser to such data; and 3) QA is becoming an important example of NLP technology, and question parsing is an important task for QA systems.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 71, "end_pos": 88, "type": "TASK", "confidence": 0.7537685632705688}, {"text": "Penn Treebank (PTB)", "start_pos": 149, "end_pos": 168, "type": "DATASET", "confidence": 0.9728574156761169}, {"text": "question parsing", "start_pos": 466, "end_pos": 482, "type": "TASK", "confidence": 0.8089405298233032}]}, {"text": "The CCG parser we use) makes use of three levels of representation: one, a POS tag level based on the fairly coarse-grained POS tags in the Penn Treebank; two, a lexical category level based on the more fine-grained CCG lexical categories, which are assigned to words by a CCG su-pertagger; and three, a hierarchical level consisting of CCG derivations.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 140, "end_pos": 153, "type": "DATASET", "confidence": 0.9622814953327179}]}, {"text": "A key idea in this paper, following a pilot study in, is to perform manual annotation only at the first two levels.", "labels": [], "entities": []}, {"text": "Since the lexical category level consists of sequences of tags, rather than hierarchical derivations, the annotation can be performed relatively quickly.", "labels": [], "entities": []}, {"text": "For the biomedical and question domains we manually annotated approximately 1,000 and 2,000 sentences, respectively, with CCG lexical categories.", "labels": [], "entities": []}, {"text": "We also created a gold standard set of grammatical relations (GR) in the Stanford format (), using 500 of the questions.", "labels": [], "entities": [{"text": "grammatical relations (GR)", "start_pos": 39, "end_pos": 65, "type": "TASK", "confidence": 0.5953800141811371}, {"text": "Stanford format", "start_pos": 73, "end_pos": 88, "type": "DATASET", "confidence": 0.8655470609664917}]}, {"text": "For the biomedical domain we used the BioInfer corpus (), an existing gold-standard GR resource also in the Stanford format.", "labels": [], "entities": [{"text": "BioInfer corpus", "start_pos": 38, "end_pos": 53, "type": "DATASET", "confidence": 0.8788982629776001}]}, {"text": "We evaluated the parser on both lexical category assignment and recovery of The results show that the domain adaptation approach used here is successful in two very different domains, achieving parsing accuracy comparable to state-of-the-art accuracy for newspaper text.", "labels": [], "entities": [{"text": "lexical category assignment", "start_pos": 32, "end_pos": 59, "type": "TASK", "confidence": 0.5999213953812917}, {"text": "recovery", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.8885396718978882}, {"text": "domain adaptation", "start_pos": 102, "end_pos": 119, "type": "TASK", "confidence": 0.7047160714864731}, {"text": "accuracy", "start_pos": 202, "end_pos": 210, "type": "METRIC", "confidence": 0.8960291743278503}, {"text": "accuracy", "start_pos": 242, "end_pos": 250, "type": "METRIC", "confidence": 0.975858211517334}]}, {"text": "The results also show, however, that the two domains have different profiles with regard to the levels of representation used by the parser.", "labels": [], "entities": []}, {"text": "We find that simply retraining the POS tagger used by the parser leads to a large improvement in performance for the biomedical domain, and that retraining the CCG supertagger on the annotated biomedical data improves the performance further.", "labels": [], "entities": []}, {"text": "For the question data, retraining just the POS tagger also improves parser performance, but retraining the supertagger has a much greater effect.", "labels": [], "entities": []}, {"text": "We perform some analysis of the two datasets in order to explain the different behaviours with regard to porting the CCG parser.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: POS tagger accuracy (%) for original and re- trained models.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 10, "end_pos": 20, "type": "TASK", "confidence": 0.664934441447258}, {"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9700779318809509}]}, {"text": " Table 2: Supertagging accuracy (%) and the effect of re- training the POS model and the supertagger model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9443642497062683}]}, {"text": " Table 3: Parser F-score on grammatical relations and the  effect of retraining the POS and supertagger models.", "labels": [], "entities": [{"text": "Parser", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.799968421459198}, {"text": "F-score", "start_pos": 17, "end_pos": 24, "type": "METRIC", "confidence": 0.5920682549476624}]}, {"text": " Table 5: Unknown word rate and word-POS tag pair rate  (%) compared to WSJ 02-21 (by token).", "labels": [], "entities": [{"text": "Unknown word rate", "start_pos": 10, "end_pos": 27, "type": "METRIC", "confidence": 0.8499297102292379}, {"text": "word-POS tag pair rate", "start_pos": 32, "end_pos": 54, "type": "METRIC", "confidence": 0.6532373204827309}, {"text": "WSJ 02-21", "start_pos": 72, "end_pos": 81, "type": "DATASET", "confidence": 0.6724902987480164}]}, {"text": " Table 6: Unknown POS n-gram rate (%) compared to WSJ  02-21, and when in-domain data is added (by token).", "labels": [], "entities": [{"text": "Unknown POS n-gram rate", "start_pos": 10, "end_pos": 33, "type": "METRIC", "confidence": 0.7065626084804535}, {"text": "WSJ  02-21", "start_pos": 50, "end_pos": 60, "type": "DATASET", "confidence": 0.8585107624530792}]}]}