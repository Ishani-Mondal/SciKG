{"title": [{"text": "Jointly Combining Implicit Constraints Improves Temporal Ordering", "labels": [], "entities": [{"text": "Combining Implicit Constraints Improves Temporal Ordering", "start_pos": 8, "end_pos": 65, "type": "TASK", "confidence": 0.8028053840001425}]}], "abstractContent": [{"text": "Previous work on ordering events in text has typically focused on local pairwise decisions, ignoring globally inconsistent labels.", "labels": [], "entities": []}, {"text": "However , temporal ordering is the type of domain in which global constraints should be relatively easy to represent and reason over.", "labels": [], "entities": []}, {"text": "This paper presents a framework that informs local decisions with two types of implicit global constraints: transitivity (A before B and B before C implies A before C) and time expression normalization (e.g. last month is before yesterday).", "labels": [], "entities": []}, {"text": "We show how these constraints can be used to create a more densely-connected network of events, and how global consistency can be enforced by incorporating these constraints into an integer linear programming framework.", "labels": [], "entities": []}, {"text": "We present results on two event ordering tasks, showing a 3.6% absolute increase in the accuracy of before/after classification over a pairwise model.", "labels": [], "entities": [{"text": "event ordering tasks", "start_pos": 26, "end_pos": 46, "type": "TASK", "confidence": 0.7777729034423828}, {"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9993740916252136}]}], "introductionContent": [{"text": "Being able to temporally order events is a necessary component for complete document understanding.", "labels": [], "entities": [{"text": "complete document understanding", "start_pos": 67, "end_pos": 98, "type": "TASK", "confidence": 0.5922483404477438}]}, {"text": "Interest in machine learning approaches for this task has recently been encouraged through the creation of the Timebank Corpus (.", "labels": [], "entities": [{"text": "Timebank Corpus", "start_pos": 111, "end_pos": 126, "type": "DATASET", "confidence": 0.9654578566551208}]}, {"text": "However, most work on event-event ordering has focused on improving classifiers for pairwise decisions, ignoring obvious contradictions in the global space of events when misclassifications occur.", "labels": [], "entities": [{"text": "event-event ordering", "start_pos": 22, "end_pos": 42, "type": "TASK", "confidence": 0.7444082796573639}]}, {"text": "A global framework to repair these event ordering mistakes has not yet been explored.", "labels": [], "entities": [{"text": "event ordering", "start_pos": 35, "end_pos": 49, "type": "TASK", "confidence": 0.712282344698906}]}, {"text": "This paper addresses three main factors involved in a global framework: the global optimization algorithm, the constraints that are relevant to the task, and the level of connectedness across pairwise decisions.", "labels": [], "entities": []}, {"text": "We employ Integer Linear Programming to address the first factor, drawing from related work in paragraph ordering).", "labels": [], "entities": [{"text": "paragraph ordering", "start_pos": 95, "end_pos": 113, "type": "TASK", "confidence": 0.7701666057109833}]}, {"text": "After finding minimal gain with the initial model, we explore reasons for and solutions to the remaining two factors through temporal reasoning and transitivity rule expansion.", "labels": [], "entities": [{"text": "transitivity rule expansion", "start_pos": 148, "end_pos": 175, "type": "TASK", "confidence": 0.6292211413383484}]}, {"text": "We analyze the connectivity of the Timebank Corpus and show how textual events can be indirectly connected through a time normalization algorithm that automatically creates new relations between time expressions.", "labels": [], "entities": [{"text": "Timebank Corpus", "start_pos": 35, "end_pos": 50, "type": "DATASET", "confidence": 0.9686772525310516}]}, {"text": "We show how this increased connectivity is essential fora global model to improve performance.", "labels": [], "entities": []}, {"text": "We present three progressive evaluations of our global model on the Timebank Corpus, showing a 3.6% gain inaccuracy over its original set of relations, and an 81% increase in training data size from previous work.", "labels": [], "entities": [{"text": "Timebank Corpus", "start_pos": 68, "end_pos": 83, "type": "DATASET", "confidence": 0.9875790178775787}]}, {"text": "In addition, we present the first results on Timebank that include an unknown relation, establishing a benchmark for performance on the full task of document ordering.", "labels": [], "entities": [{"text": "Timebank", "start_pos": 45, "end_pos": 53, "type": "DATASET", "confidence": 0.9485419392585754}, {"text": "document ordering", "start_pos": 149, "end_pos": 166, "type": "TASK", "confidence": 0.693809375166893}]}], "datasetContent": [{"text": "The first evaluation of our global temporal model is on the Timebank Corpus over the labeled relations before and after.", "labels": [], "entities": [{"text": "Timebank Corpus", "start_pos": 60, "end_pos": 75, "type": "DATASET", "confidence": 0.9527560174465179}]}, {"text": "We merged ibefore and iafter into these two relations as well, ignoring all others.", "labels": [], "entities": []}, {"text": "We use this task as a reduced evaluation to study the specific contribution of global constraints.", "labels": [], "entities": []}, {"text": "We also chose this strict ordering task because it is well defined from a human understanding perspective.", "labels": [], "entities": []}, {"text": "shows that average internet users can make before/after decisions with very high confidence, although the distinction with an unknown relation is not as clear.", "labels": [], "entities": []}, {"text": "An evaluation including unknown (or vague as in TempEval) is presented later.", "labels": [], "entities": []}, {"text": "We expanded the corpus (prior to selecting the before/after relations) using transitive closure overall 12 relations as described above.", "labels": [], "entities": []}, {"text": "shows the increase in data size.", "labels": [], "entities": []}, {"text": "The number of before and after relations increase by a factor of six.", "labels": [], "entities": []}, {"text": "We trained and tested the system with 10-fold cross validation and micro-averaged accuracies.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 82, "end_pos": 92, "type": "METRIC", "confidence": 0.6440693140029907}]}, {"text": "The folds were randomly generated to separate the 186 files into 10 folds (18 or 19 files per fold).", "labels": [], "entities": []}, {"text": "The same 10-way split is used for all the evaluations.", "labels": [], "entities": []}, {"text": "We used  Our second evaluation continues the use of the twoway classification task with before and after to explore the contribution of closure, time normalization, and global constraints.", "labels": [], "entities": [{"text": "twoway classification task", "start_pos": 56, "end_pos": 82, "type": "TASK", "confidence": 0.7635239561398824}]}, {"text": "We augmented the corpus with the labeled relations from and added the automatically created time-time relations as described in section 5.1.", "labels": [], "entities": []}, {"text": "We then expanded the corpus using transitive closure.", "labels": [], "entities": []}, {"text": "shows the progressive data size increase as we incrementally add each to the closure algorithm.", "labels": [], "entities": []}, {"text": "The time-time generation component automatically added 2459 new before and after time-time relations into the 186 Timebank documents.", "labels": [], "entities": [{"text": "Timebank documents", "start_pos": 114, "end_pos": 132, "type": "DATASET", "confidence": 0.9763592779636383}]}, {"text": "This is in comparison to only 157 relations that the human annotators tagged, less than 1 per document on average.", "labels": [], "entities": []}, {"text": "The second row of shows the drastic effect that these time-time relations have on the number of available event-event relations for training and testing.", "labels": [], "entities": []}, {"text": "Adding both Bethard's data and the time-time data increases our training set by 81% over closure without it.", "labels": [], "entities": [{"text": "Bethard's data", "start_pos": 12, "end_pos": 26, "type": "DATASET", "confidence": 0.8359566529591879}]}, {"text": "We again performed 10-fold cross validation with micro-averaged accuracies, but each fold tested only on the transitively closed Timebank data (the first row of).", "labels": [], "entities": [{"text": "Timebank data", "start_pos": 129, "end_pos": 142, "type": "DATASET", "confidence": 0.9748628437519073}]}, {"text": "The training set used all available data (the third row of) including the Bethard data as well as our new time-time links.", "labels": [], "entities": [{"text": "Bethard data", "start_pos": 74, "end_pos": 86, "type": "DATASET", "confidence": 0.9632945656776428}]}, {"text": "shows the results from the new model.", "labels": [], "entities": []}, {"text": "The first row is the baseline pairwise classification trained and tested on the original relations only.", "labels": [], "entities": []}, {"text": "Our model improves by 3.6% absolute.", "labels": [], "entities": [{"text": "absolute", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9803127646446228}]}, {"text": "This improvement is statistically significant (p < 0.000001, McNemar's test, 2-tailed).", "labels": [], "entities": [{"text": "McNemar's test", "start_pos": 61, "end_pos": 75, "type": "METRIC", "confidence": 0.671674907207489}]}, {"text": "Our final evaluation expands the set of relations to include unlabeled relations and tests on the entire dataset available to us.", "labels": [], "entities": []}, {"text": "The following is now a classification task between the three relations: before, after, and unknown.", "labels": [], "entities": []}, {"text": "We duplicated the previous evaluation by adding the labeled relations from and our automatically created time-time relations.", "labels": [], "entities": []}, {"text": "We then expanded this dataset using transitive closure.", "labels": [], "entities": []}, {"text": "Unlike the previous evaluation, we also use this entire dataset for testing, not just for training.", "labels": [], "entities": []}, {"text": "Thus, all event-event relations in Bethard as well as Timebank are used to expand the dataset with transitive closure and are used in training and testing.", "labels": [], "entities": [{"text": "Bethard", "start_pos": 35, "end_pos": 42, "type": "DATASET", "confidence": 0.9815293550491333}, {"text": "Timebank", "start_pos": 54, "end_pos": 62, "type": "DATASET", "confidence": 0.9790593385696411}]}, {"text": "We wanted to fully evaluate document performance on every possible event-event relation that logically follows from the data.", "labels": [], "entities": []}, {"text": "As before, we converted IBefore and IAfter into before and after respectively, while all other relations are reduced to unknown.", "labels": [], "entities": []}, {"text": "This relation set coincides with TempEval-07's core three relations (although they use vague instead of unknown).", "labels": [], "entities": []}, {"text": "Rather than include all unlabeled pairs in our unknown set, we only include the unlabeled pairs that span at most one sentence boundary.", "labels": [], "entities": []}, {"text": "In other words, events in adjacent sentences are included in the unknown set if they were not tagged by the Timebank annotators.", "labels": [], "entities": [{"text": "Timebank annotators", "start_pos": 108, "end_pos": 127, "type": "DATASET", "confidence": 0.9463379681110382}]}, {"text": "The intuition is that annotators are more likely to label nearby events, and so events in adjacent sentences are more likely to be actual unknown relations if they are unlabeled.", "labels": [], "entities": []}, {"text": "It is more likely that distant events in the text were overlooked by convenience, not because they truly constituted an unknown relationship.", "labels": [], "entities": []}, {"text": "The set of possible sentence-adjacent unknown relations is very large (approximately 50000 unknown compared to 7000 before), and so we randomly select a percentage of these relations for each evalu-  ation.", "labels": [], "entities": []}, {"text": "We used the same SVM approach with the features described in section 4.1.", "labels": [], "entities": []}], "tableCaptions": []}