{"title": [{"text": "Syntactic Constraints on Paraphrases Extracted from Parallel Corpora", "labels": [], "entities": [{"text": "Paraphrases Extracted from Parallel Corpora", "start_pos": 25, "end_pos": 68, "type": "TASK", "confidence": 0.7765695333480835}]}], "abstractContent": [{"text": "We improve the quality of paraphrases extracted from parallel corpora by requiring that phrases and their paraphrases be the same syntactic type.", "labels": [], "entities": []}, {"text": "This is achieved by parsing the En-glish side of a parallel corpus and altering the phrase extraction algorithm to extract phrase labels alongside bilingual phrase pairs.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 84, "end_pos": 101, "type": "TASK", "confidence": 0.7664215564727783}]}, {"text": "In order to retain broad coverage of non-constituent phrases, complex syntactic labels are introduced.", "labels": [], "entities": []}, {"text": "A manual evaluation indicates a 19% absolute improvement in paraphrase quality over the baseline method.", "labels": [], "entities": []}], "introductionContent": [{"text": "Paraphrases are alternative ways of expressing the same information.", "labels": [], "entities": []}, {"text": "Being able to identify or generate paraphrases automatically is useful in a wide range of natural language applications.", "labels": [], "entities": []}, {"text": "Recent work has shown how paraphrases can improve question answering through query expansion (, automatic evaluation of translation and summarization by modeling alternative lexicalization (;), and machine translation both by dealing without of vocabulary words and phrases) and by expanding the set of reference translations for minimum error rate training (.", "labels": [], "entities": [{"text": "question answering", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.8067969381809235}, {"text": "query expansion", "start_pos": 77, "end_pos": 92, "type": "TASK", "confidence": 0.7206614911556244}, {"text": "summarization", "start_pos": 136, "end_pos": 149, "type": "TASK", "confidence": 0.9532307386398315}, {"text": "machine translation", "start_pos": 198, "end_pos": 217, "type": "TASK", "confidence": 0.8041191399097443}]}, {"text": "While all applications require the preservation of meaning when a phrase is replaced by its paraphrase, some additionally require the resulting sentence to be grammatical.", "labels": [], "entities": []}, {"text": "In this paper we examine the effectiveness of placing syntactic constraints on a commonly used paraphrasing technique that extracts paraphrases from parallel corpora).", "labels": [], "entities": []}, {"text": "The paraphrasing technique employs various aspects of phrase-based statistical machine translation including phrase extraction heuristics to obtain bilingual phrase pairs from word alignments.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 54, "end_pos": 98, "type": "TASK", "confidence": 0.5941037014126778}, {"text": "phrase extraction heuristics", "start_pos": 109, "end_pos": 137, "type": "TASK", "confidence": 0.8166470925013224}]}, {"text": "English phrases are considered to be potential paraphrases of each other if they share a common foreign language phrase among their translations.", "labels": [], "entities": []}, {"text": "Multiple paraphrases are frequently extracted for each phrase and can be ranked using a paraphrase probability based on phrase translation probabilities.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 120, "end_pos": 138, "type": "TASK", "confidence": 0.6840734332799911}]}, {"text": "We find that the quality of the paraphrases that are generated in this fashion improves significantly when they are required to be the same syntactic type as the phrase that they are paraphrasing.", "labels": [], "entities": []}, {"text": "This constraint: \u2022 Eliminates a trivial but pervasive error that arises from the interaction of unaligned words with phrase extraction heuristics.", "labels": [], "entities": [{"text": "phrase extraction heuristics", "start_pos": 117, "end_pos": 145, "type": "TASK", "confidence": 0.7882579267024994}]}, {"text": "\u2022 Refines the results for phrases that can take on different syntactic labels.", "labels": [], "entities": []}, {"text": "\u2022 Applies both to phrases which are linguistically coherent and to arbitrary sequences of words.", "labels": [], "entities": [{"text": "Applies", "start_pos": 2, "end_pos": 9, "type": "METRIC", "confidence": 0.995507001876831}]}, {"text": "\u2022 Results in much more grammatical output when phrases are replaced with their paraphrases.", "labels": [], "entities": []}, {"text": "A thorough manual evaluation of the refined paraphrasing technique finds a 19% absolute improve-ment in the number of paraphrases that are judged to be correct.", "labels": [], "entities": []}, {"text": "This paper is structured as follows: Section 2 describes related work in syntactic constraints on phrase-based SMT and work utilizing syntax in paraphrase discovery.", "labels": [], "entities": [{"text": "SMT", "start_pos": 111, "end_pos": 114, "type": "TASK", "confidence": 0.7371043562889099}, {"text": "paraphrase discovery", "start_pos": 144, "end_pos": 164, "type": "TASK", "confidence": 0.8487193584442139}]}, {"text": "Section 3 details the problems with extracting paraphrases from parallel corpora and our improvements to the technique.", "labels": [], "entities": [{"text": "extracting paraphrases from parallel corpora", "start_pos": 36, "end_pos": 80, "type": "TASK", "confidence": 0.8200983881950379}]}, {"text": "Section 4 describes our experimental design and evaluation methodology.", "labels": [], "entities": []}, {"text": "Section 5 gives the results of our experiments, and Section 6 discusses their implications.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted a manual evaluation to evaluate paraphrase quality.", "labels": [], "entities": []}, {"text": "We evaluated whether paraphrases retained the meaning of their original phrases and whether they remained grammatical when they replaced the original phrase in a sentence.", "labels": [], "entities": []}, {"text": "We produced paraphrases under the following eight conditions: 1.", "labels": [], "entities": []}, {"text": "Baseline -The paraphrase probability defined by.", "labels": [], "entities": []}, {"text": "Calculated over multiple parallel corpora as given in Equation 5.", "labels": [], "entities": []}, {"text": "Note that under this condition the best paraphrase is the same for each occurrence of the phrase irrespective of which sentence it occurs in.", "labels": [], "entities": []}, {"text": "2. Baseline + LM -The paraphrase probability (as above) combined with the language model probability calculated for the sentence with the phrase replaced with the paraphrase.", "labels": [], "entities": []}, {"text": "3. Extraction Constraints -This condition selected the best paraphrase according to Equation 10.", "labels": [], "entities": [{"text": "Extraction Constraints", "start_pos": 3, "end_pos": 25, "type": "TASK", "confidence": 0.7804650962352753}, {"text": "Equation", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9671350121498108}]}, {"text": "It chooses the single best paraphrase overall labels.", "labels": [], "entities": []}, {"text": "Conditions 3 and 5 only apply the syntactic constraints at the phrase extraction stage, and do not require that the paraphrase have the same syntactic label as the phrase in the sentence that it is being subtituted into.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 63, "end_pos": 80, "type": "TASK", "confidence": 0.7238852232694626}]}, {"text": "4. Extraction Constraints + LM -As above, but the paraphrases are also ranked with a language model probability.", "labels": [], "entities": []}, {"text": "5. Substitution Constraints -This condition corresponds to Equation 8, which selects the highest probability paraphrase which matches at least one of the syntactic labels of the phrase in the test sentence.", "labels": [], "entities": [{"text": "Equation 8", "start_pos": 59, "end_pos": 69, "type": "METRIC", "confidence": 0.9626913964748383}]}, {"text": "Conditions 5-8 apply the syntactic constraints both and the phrase extraction and at the substitution stages.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.7527767717838287}]}, {"text": "6. Syntactic Constraints + LM -As above, but including a language model probability as well.", "labels": [], "entities": []}, {"text": "7. Averaged Substitution Constraints -This condition corresponds to Equation 9, which averages overall of the syntactic labels for the phrase in the sentence, instead of choosing the single one which maximizes the probability.", "labels": [], "entities": [{"text": "Equation", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9872009754180908}]}, {"text": "MEANING 5 All of the meaning of the original phrase is retained, and nothing is added 4 The meaning of the original phrase is retained, although some additional information maybe added but does not transform the meaning 3 The meaning of the original phrase is retained, although some information maybe deleted without too great a loss in the meaning 2 Substantial amount of the meaning is different 1 The paraphrase doesn't mean anything close to the original phrase GRAMMAR 5 The sentence with the paraphrase inserted is perfectly grammatical 4 The sentence is grammatical, but might sound slightly awkward 3 The sentence has an agreement error (such as between its subject and verb, or between a plural noun and singular determiner) 2 The sentence has multiple errors or omits words that would be required to make it grammatical 1 The sentence is totally ungrammatical: Annotators rated paraphrases along two 5-point scales.", "labels": [], "entities": [{"text": "MEANING", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.9631372690200806}, {"text": "GRAMMAR", "start_pos": 467, "end_pos": 474, "type": "METRIC", "confidence": 0.9106946587562561}]}, {"text": "8. Averaged Substitution Constraints + LMAs above, but including a language model probability.", "labels": [], "entities": []}, {"text": "We evaluated the paraphrase quality through a substitution test.", "labels": [], "entities": []}, {"text": "We retrieved a number of sentences which contained each test phrase and substituted the phrase with automatically-generated paraphrases.", "labels": [], "entities": []}, {"text": "Annotators judged whether the paraphrases had the same meaning as the original and whether the resulting sentences were grammatical.", "labels": [], "entities": []}, {"text": "They assigned two values to each sentence using the 5-point scales given in.", "labels": [], "entities": []}, {"text": "We considered an item to have the same meaning if it was assigned a score of 3 or greater, and to be grammatical if it was assigned a score of 4 or 5.", "labels": [], "entities": []}, {"text": "We evaluated several instances of a phrase when it occurred multiple times in the test corpus, since paraphrase quality can vary based on context (.", "labels": [], "entities": []}, {"text": "There were an average of 3.1 instances for each phrase, with a maximum of 6.", "labels": [], "entities": []}, {"text": "There were a total of 1,195 sentences that para-phrases were substituted into, with a total of 8,422 judgements collected.", "labels": [], "entities": []}, {"text": "Note that 7 different paraphrases were judged on average for every instance.", "labels": [], "entities": []}, {"text": "This is because annotators judged paraphrases for eight conditions, and because we collected judgments for the 5-best paraphrases for many of the conditions.", "labels": [], "entities": []}, {"text": "We measured inter-annotator agreement with the Kappa statistic) using the 1,391 items that two annotators scored in common.", "labels": [], "entities": [{"text": "agreement", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.7037519812583923}]}, {"text": "The two annotators assigned the same absolute score 47% of the time.", "labels": [], "entities": [{"text": "absolute score", "start_pos": 37, "end_pos": 51, "type": "METRIC", "confidence": 0.9056393802165985}]}, {"text": "If we consider chance agreement to be 20% for 5-point scales, then K = 0.33, which is commonly interpreted as \"fair\".", "labels": [], "entities": [{"text": "K", "start_pos": 67, "end_pos": 68, "type": "METRIC", "confidence": 0.9908357858657837}]}, {"text": "If we instead measure agreement in terms of how often the annotators both judged an item to be above or below the thresholds that we set, then their rate of agreement was 80%.", "labels": [], "entities": [{"text": "agreement", "start_pos": 157, "end_pos": 166, "type": "METRIC", "confidence": 0.8665021061897278}]}, {"text": "In this case chance agreement would be 50%, so K = 0.61, which is \"substantial\".", "labels": [], "entities": [{"text": "chance agreement", "start_pos": 13, "end_pos": 29, "type": "METRIC", "confidence": 0.9139635562896729}, {"text": "K", "start_pos": 47, "end_pos": 48, "type": "METRIC", "confidence": 0.9924301505088806}]}], "tableCaptions": [{"text": " Table 1: The baseline method's paraphrases of equal and  their probabilities (excluding items with p < .01).", "labels": [], "entities": []}, {"text": " Table 2: The baseline's paraphrases of create equal. Most  are clearly bad, and the most probable e 2 = e 1 is a sub- string of e 1 .", "labels": [], "entities": []}, {"text": " Table 4: Paraphrases and syntactic labels for the non- constituent phrase create equal.", "labels": [], "entities": []}, {"text": " Table 6: The results of the manual evaluation for each  of the eight conditions. Correct meaning is the percent of  time that a condition was assigned a 3, 4, or 5, and correct  grammar is the percent of time that it was given a 4 or 5,  using the scales from", "labels": [], "entities": [{"text": "correct  grammar", "start_pos": 170, "end_pos": 186, "type": "METRIC", "confidence": 0.8985978364944458}]}]}