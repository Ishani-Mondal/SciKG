{"title": [{"text": "Topic-Driven Multi-Document Summarization with Encyclopedic Knowledge and Spreading Activation", "labels": [], "entities": [{"text": "Topic-Driven Multi-Document Summarization", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.5447199543317159}]}], "abstractContent": [{"text": "Information of interest to users is often distributed over a set of documents.", "labels": [], "entities": []}, {"text": "Users can specify their request for information as a query/topic-a set of one or more sentences or questions.", "labels": [], "entities": []}, {"text": "Producing a good summary of the relevant information relies on understanding the query and linking it with the associated set of documents.", "labels": [], "entities": []}, {"text": "To \"understand\" the query we expand it using encyclopedic knowledge in Wikipedia.", "labels": [], "entities": []}, {"text": "The expanded query is linked with its associated documents through spreading activation in a graph that represents words and their grammatical connections in these documents.", "labels": [], "entities": []}, {"text": "The topic expanded words and activated nodes in the graph are used to produce an extractive summary.", "labels": [], "entities": []}, {"text": "The method proposed is tested on the DUC summariza-tion data.", "labels": [], "entities": [{"text": "DUC summariza-tion data", "start_pos": 37, "end_pos": 60, "type": "DATASET", "confidence": 0.9638406236966451}]}, {"text": "The system implemented ranks high compared to the participating systems in the DUC competitions, confirming our hypothesis that encyclopedic knowledge is a useful addition to a summarization system.", "labels": [], "entities": [{"text": "DUC competitions", "start_pos": 79, "end_pos": 95, "type": "DATASET", "confidence": 0.8878389596939087}]}], "introductionContent": [{"text": "Topic-driven summarization reflects a user-based summarization task: from a set of documents derive a summary that contains information on a specific topic of interest to a user.", "labels": [], "entities": [{"text": "Topic-driven summarization", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.5218258202075958}]}, {"text": "Producing a good summary relies on \"understanding\" the user's information request, and the documents to be summarized.", "labels": [], "entities": []}, {"text": "It is commonly agreed that the verbal part of a text provides pointers to a much larger body of knowledge we assume the listener has.", "labels": [], "entities": []}, {"text": "An American citizen, for example, when told There will be fireworks on July 4 th , understands that there will be a celebration involving fireworks on the occasion of the U.S. Independence Day.", "labels": [], "entities": []}, {"text": "Understanding an utterance implies lexical, common-sense and encyclopedic knowledge.", "labels": [], "entities": []}, {"text": "Lexical knowledge is usually incorporated in systems through machine readable dictionaries, wordnets or thesauri.", "labels": [], "entities": []}, {"text": "Common-sense and encyclopedic knowledge were harder to capture, but recently Wikipedia has opened the possibility of accessing such knowledge on a large scale, and in numerous languages.", "labels": [], "entities": []}, {"text": "To \"understand\" a user's information requestone or more sentences or questions (the topic of the summary) -summarization systems try to expand it.", "labels": [], "entities": []}, {"text": "This will provide later stages of processing with more keywords/keyphrases for retrieving from the documents relevant fragments.", "labels": [], "entities": []}, {"text": "In this paper we experiment with Wikipedia for topic expansion.", "labels": [], "entities": [{"text": "topic expansion", "start_pos": 47, "end_pos": 62, "type": "TASK", "confidence": 0.8569515645503998}]}, {"text": "The body of research involving Wikipedia as a source of knowledge is growing fast, as the NLP community finds more and more applications of this useful resource: it is used to acquire knowledge (; to induce taxonomies and compute semantic relatedness; as a source of features for text classification) and for answering questions).", "labels": [], "entities": [{"text": "text classification", "start_pos": 280, "end_pos": 299, "type": "TASK", "confidence": 0.7638244330883026}]}, {"text": "The work presented here uses hyperlinks in Wikipedia articles to expand keywords and keyphrases extracted from the query.", "labels": [], "entities": []}, {"text": "Ambiguous words are disambiguated using the context provided by the query.", "labels": [], "entities": []}, {"text": "\"Understanding\" the documents to be summarized implies identifying the entities mentioned, how they are connected, and how they are related to the entities in the topic.", "labels": [], "entities": []}, {"text": "For this, we start again from the topic, and spread an activation signal in a large graph that covers all documents for this topic -nodes are words/named entities in the texts, links are grammatical relations.", "labels": [], "entities": []}, {"text": "This way we cross from the topic to the documents, and combine information which is important in the topic with information which is important and relevant in the documents.", "labels": [], "entities": []}, {"text": "We take the most highly activated nodes as additional topic expansions, and produce an extractive summary by choosing from the sentences that connect the topic expansion words in the large document graph.", "labels": [], "entities": []}, {"text": "The experiments confirm that Wikipedia is a source of useful knowledge for summarization, and that further expanding the topic within the associated set of documents improves the summarization results even more.", "labels": [], "entities": [{"text": "summarization", "start_pos": 75, "end_pos": 88, "type": "TASK", "confidence": 0.9932901859283447}, {"text": "summarization", "start_pos": 179, "end_pos": 192, "type": "TASK", "confidence": 0.9788150191307068}]}, {"text": "We compare the performance of the summarization system to that of participating systems in the DUC competitions.", "labels": [], "entities": [{"text": "DUC competitions", "start_pos": 95, "end_pos": 111, "type": "DATASET", "confidence": 0.900006502866745}]}, {"text": "The system we describe ranks 2 nd , 9 th and 5 thin terms of ROUGE-SU4 on the and DUC 2007 data respectively.", "labels": [], "entities": [{"text": "ROUGE-SU4", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.871995210647583}, {"text": "DUC 2007 data", "start_pos": 82, "end_pos": 95, "type": "DATASET", "confidence": 0.9864464203516642}]}], "datasetContent": [{"text": "Experiments are run on DUC 2007 main summarization task data, for the last experiment we used the DUC 2005 and DUC 2006 data as well.", "labels": [], "entities": [{"text": "DUC 2007 main summarization task data", "start_pos": 23, "end_pos": 60, "type": "DATASET", "confidence": 0.88272292415301}, {"text": "DUC 2005 and DUC 2006 data", "start_pos": 98, "end_pos": 124, "type": "DATASET", "confidence": 0.8684101502100626}]}, {"text": "Performance is evaluated in terms of ROUGE-2, ROUGE-SU4 and BE recall, following the methodology and using the same parameters as in the DUC summarization events.", "labels": [], "entities": [{"text": "ROUGE-2", "start_pos": 37, "end_pos": 44, "type": "METRIC", "confidence": 0.9782617092132568}, {"text": "ROUGE-SU4", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9196068644523621}, {"text": "BE", "start_pos": 60, "end_pos": 62, "type": "METRIC", "confidence": 0.9989213943481445}, {"text": "recall", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.7262482643127441}, {"text": "DUC summarization events", "start_pos": 137, "end_pos": 161, "type": "DATASET", "confidence": 0.8388106822967529}]}, {"text": "We analyze several types of topic expansion: no expansion, WordNet, Wikipedia, and within document collection expansion using spreading activation and Page Rank.", "labels": [], "entities": [{"text": "topic expansion", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.7070929706096649}, {"text": "WordNet", "start_pos": 59, "end_pos": 66, "type": "DATASET", "confidence": 0.9603071808815002}, {"text": "Wikipedia", "start_pos": 68, "end_pos": 77, "type": "DATASET", "confidence": 0.8975700736045837}, {"text": "within document collection expansion", "start_pos": 83, "end_pos": 119, "type": "TASK", "confidence": 0.595272958278656}]}, {"text": "The spreading activation method has several parameters whose values must be determined.", "labels": [], "entities": [{"text": "spreading activation", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.9324129819869995}]}, {"text": "We first compare the summaries produced with no topic expansion, WordNet (WN) and Wikipedia (Wiki) respectively.", "labels": [], "entities": [{"text": "WordNet (WN)", "start_pos": 65, "end_pos": 77, "type": "DATASET", "confidence": 0.8665694445371628}, {"text": "Wikipedia (Wiki)", "start_pos": 82, "end_pos": 98, "type": "DATASET", "confidence": 0.8464806824922562}]}, {"text": "shows the results in terms of ROUGE and BE recall on the DUC 2007 (main) data.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 30, "end_pos": 35, "type": "METRIC", "confidence": 0.9978103041648865}, {"text": "BE", "start_pos": 40, "end_pos": 42, "type": "METRIC", "confidence": 0.9994812607765198}, {"text": "recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.7726019024848938}, {"text": "DUC 2007 (main) data", "start_pos": 57, "end_pos": 77, "type": "DATASET", "confidence": 0.9623352686564127}]}, {"text": "Word sense disambiguation (WSD) for expansion with WordNet did notwork very well, as evidenced by the lower results for disambiguated expansion (WN with WSD) compared to the non-disambiguated one.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 51, "end_pos": 58, "type": "DATASET", "confidence": 0.9281784892082214}]}, {"text": "A better disambiguation algorithm may reverse the situation.", "labels": [], "entities": []}, {"text": "Expanding a topic only with Wikipedia hyperlinks gives the best results.", "labels": [], "entities": []}, {"text": "At the document level, the results are not as clear cut.", "labels": [], "entities": []}, {"text": "shows a comparison in terms of ROUGE-SU4 recall scores at the document level of the Wikipedia and WN (no WSD) expansion methods, sorted in increasing order of the Wikipediabased expansion scores.", "labels": [], "entities": [{"text": "ROUGE-SU4", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9785659909248352}, {"text": "recall", "start_pos": 41, "end_pos": 47, "type": "METRIC", "confidence": 0.7489752769470215}]}, {"text": "The points are connected to allow the reader to follow the results for each method.", "labels": [], "entities": []}, {"text": "Because the overlap between Wikipedia and WordNet expanded queries was very low, we expected the two types of expansion to be complementary, and the combination to give better results than either expansion by itself.", "labels": [], "entities": []}, {"text": "An analysis of results for each document with the three expansion methods -Wikipedia, WordNet, and their combinationshowed that the simple combination of the expanded words cannot take advantage of the situations when one of the two methods performs better.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 75, "end_pos": 84, "type": "DATASET", "confidence": 0.9498800039291382}, {"text": "WordNet", "start_pos": 86, "end_pos": 93, "type": "DATASET", "confidence": 0.9275881052017212}]}, {"text": "In future work we will explore how to detect, based on the words in the query, which type of expansion is best, and how to combine them using a weighting scheme.", "labels": [], "entities": []}, {"text": "We choose the best configuration from above (Wikipedia expansion), and further expand the query through spreading activation and PageRank.", "labels": [], "entities": []}, {"text": "This new type of expansion has two main parameters which influence the summarization outcome: number of top ranked nodes to add to the topic expansion, and the decay of the spreading activation algorithm.", "labels": [], "entities": []}, {"text": "The decay parameter determines how far the influence of the starting nodes (words from query or Wikipedia-expanded query) should be felt.", "labels": [], "entities": []}, {"text": "The results in -for decay values 0.1, 0.5, 0.95, 0.99, 0.999, 0.9999, 1 -indicate that faster decay (reflected through a higher decay value) keeps the summary more focused around the given topic, and leads to better results.", "labels": [], "entities": []}, {"text": "For a high enough decay -and eventually a decay of 1 -the weights of the edges become extremely small, and due to real number representation in memory, practically 0.", "labels": [], "entities": []}, {"text": "In this situation PageRank has no effect, and all nodes have the same rank.", "labels": [], "entities": [{"text": "PageRank", "start_pos": 18, "end_pos": 26, "type": "DATASET", "confidence": 0.8886926174163818}]}, {"text": "We fix the decay parameter to 0.9999, and we study the impact of the number of top nodes chosen after ranking with PageRank.", "labels": [], "entities": [{"text": "PageRank", "start_pos": 115, "end_pos": 123, "type": "DATASET", "confidence": 0.9758484363555908}]}, {"text": "shows the results when the number of top ranked nodes chosen varies.", "labels": [], "entities": []}, {"text": "Adding highly ranked nodes benefits the performance of the system only up to a certain limit.", "labels": [], "entities": []}, {"text": "From the values we tested, the best results were obtained when adding 40 nodes to the expanded topic.", "labels": [], "entities": []}, {"text": "The best system configuration from the ones explored 7 is run on the data.", "labels": [], "entities": []}, {"text": "The performance and rank (in parentheses) compared to participating systems is presented in.", "labels": [], "entities": []}], "tableCaptions": []}