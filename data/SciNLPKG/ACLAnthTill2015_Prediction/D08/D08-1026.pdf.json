{"title": [{"text": "Incorporating Temporal and Semantic Information with Eye Gaze for Automatic Word Acquisition in Multimodal Conversational Systems", "labels": [], "entities": [{"text": "Automatic Word Acquisition", "start_pos": 66, "end_pos": 92, "type": "TASK", "confidence": 0.6202881038188934}]}], "abstractContent": [{"text": "One major bottleneck in conversational systems is their incapability in interpreting unexpected user language inputs such as out-of-vocabulary words.", "labels": [], "entities": [{"text": "interpreting unexpected user language inputs such as out-of-vocabulary words", "start_pos": 72, "end_pos": 148, "type": "TASK", "confidence": 0.8009902238845825}]}, {"text": "To overcome this problem, conversational systems must be able to learn new words automatically during human machine conversation.", "labels": [], "entities": []}, {"text": "Motivated by psycholin-guistic findings on eye gaze and human language processing, we are developing techniques to incorporate human eye gaze for automatic word acquisition in multimodal conversational systems.", "labels": [], "entities": [{"text": "word acquisition", "start_pos": 156, "end_pos": 172, "type": "TASK", "confidence": 0.7258804589509964}]}, {"text": "This paper investigates the use of temporal alignment between speech and eye gaze and the use of domain knowledge in word acquisition.", "labels": [], "entities": [{"text": "word acquisition", "start_pos": 117, "end_pos": 133, "type": "TASK", "confidence": 0.7983404695987701}]}, {"text": "Our experiment results indicate that eye gaze provides a potential channel for automatically acquiring new words.", "labels": [], "entities": [{"text": "automatically acquiring new words", "start_pos": 79, "end_pos": 112, "type": "TASK", "confidence": 0.6866635382175446}]}, {"text": "The use of extra temporal and domain knowledge can significantly improve acquisition performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "Interpreting human language is a challenging problem inhuman machine conversational systems due to the flexibility of human language behavior.", "labels": [], "entities": [{"text": "Interpreting human language", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.9084373513857523}]}, {"text": "When the encountered vocabulary is outside of the system's knowledge, conversational systems tend to fail.", "labels": [], "entities": []}, {"text": "It is desirable that conversational systems can learn new words automatically during human machine conversation.", "labels": [], "entities": []}, {"text": "While automatic word acquisition in general is quite challenging, multimodal conversational systems offer an unique opportunity to explore word acquisition.", "labels": [], "entities": [{"text": "word acquisition", "start_pos": 16, "end_pos": 32, "type": "TASK", "confidence": 0.7024028301239014}, {"text": "word acquisition", "start_pos": 139, "end_pos": 155, "type": "TASK", "confidence": 0.7468357682228088}]}, {"text": "Ina multimodal conversational system where users can talk and interact with a graphical display, users' eye gaze, which occurs naturally with speech production, provides a potential channel for the system to learn new words automatically during human machine conversation.", "labels": [], "entities": []}, {"text": "Psycholinguistic studies have shown that eye gaze is tightly linked to human language processing.", "labels": [], "entities": []}, {"text": "Eye gaze is one of the reliable indicators of what a person is \"thinking about\" ().", "labels": [], "entities": []}, {"text": "The direction of eye gaze carries information about the focus of the user's attention.", "labels": [], "entities": []}, {"text": "The perceived visual context influences spoken word recognition and mediates syntactic processing of spoken sentences.", "labels": [], "entities": [{"text": "spoken word recognition", "start_pos": 40, "end_pos": 63, "type": "TASK", "confidence": 0.6522541344165802}]}, {"text": "In addition, directly before speaking a word, the eyes move to the mentioned object).", "labels": [], "entities": []}, {"text": "Motivated by these psycholinguistic findings, we are investigating the use of eye gaze for automatic word acquisition in multimodal conversation.", "labels": [], "entities": [{"text": "word acquisition", "start_pos": 101, "end_pos": 117, "type": "TASK", "confidence": 0.7157771289348602}]}, {"text": "Particulary, this paper investigates the use of temporal information about speech and eye gaze and domain semantic relatedness for automatic word acquisition.", "labels": [], "entities": [{"text": "automatic word acquisition", "start_pos": 131, "end_pos": 157, "type": "TASK", "confidence": 0.606825977563858}]}, {"text": "The domain semantic and temporal information are incorporated in statistical translation models for word acquisition.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 65, "end_pos": 88, "type": "TASK", "confidence": 0.6962067633867264}, {"text": "word acquisition", "start_pos": 100, "end_pos": 116, "type": "TASK", "confidence": 0.8057590425014496}]}, {"text": "Our experiments show that the use of domain semantic and temporal information significantly improves word acquisition performance.", "labels": [], "entities": [{"text": "word acquisition", "start_pos": 101, "end_pos": 117, "type": "TASK", "confidence": 0.8358629941940308}]}, {"text": "In the following sections, we first describe the basic translation models for word acquisition.", "labels": [], "entities": [{"text": "word acquisition", "start_pos": 78, "end_pos": 94, "type": "TASK", "confidence": 0.7844653129577637}]}, {"text": "Then, we describe the enhanced models that incorporate temporal and semantic information about speech and eye gaze for word acquisition.", "labels": [], "entities": [{"text": "word acquisition", "start_pos": 119, "end_pos": 135, "type": "TASK", "confidence": 0.7878608405590057}]}, {"text": "Finally, we present the results of empirical evaluation.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate word acquisition performance of different models on the data collected from our user studies (see Section 3).", "labels": [], "entities": [{"text": "word acquisition", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.8541553318500519}]}, {"text": "The following metrics are used to evaluate the words acquired for domain concepts (i.e., entity properties) {c i e }.", "labels": [], "entities": []}, {"text": "\u2022 Precision The metrics of precision, recall, and F-measure are based on the n-best words acquired for the entity properties.", "labels": [], "entities": [{"text": "Precision", "start_pos": 2, "end_pos": 11, "type": "METRIC", "confidence": 0.9899933934211731}, {"text": "precision", "start_pos": 27, "end_pos": 36, "type": "METRIC", "confidence": 0.9994359612464905}, {"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9991452693939209}, {"text": "F-measure", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.9984835982322693}]}, {"text": "Therefore, we have different precision, recall, and F-measure when n changes.", "labels": [], "entities": [{"text": "precision", "start_pos": 29, "end_pos": 38, "type": "METRIC", "confidence": 0.999675989151001}, {"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9997411370277405}, {"text": "F-measure", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9992173910140991}]}, {"text": "The metrics of precision, recall, and F-measure only provide evaluation on the top n candidate words.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9995649456977844}, {"text": "recall", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.999190628528595}, {"text": "F-measure", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9985817670822144}]}, {"text": "To measure the acquisition performance on the entire ranked list of candidate words, we define anew metric as follows: where Ne is the number of all ground-truth words {w i e } for entity e, index(w i e ) is the index of word w i e in the ranked list of candidate words for entity e.", "labels": [], "entities": []}, {"text": "Entities may have a different number of groundtruth words.", "labels": [], "entities": []}, {"text": "For each entity e, we calculate a Reciprocal Rank Rate (RRR), which measures how close the ranks of the ground-truth words in the candidate word list is to the best scenario where the top Ne words are the ground-truth words fore.", "labels": [], "entities": [{"text": "Reciprocal Rank Rate (RRR)", "start_pos": 34, "end_pos": 60, "type": "METRIC", "confidence": 0.980930507183075}]}, {"text": "RRR is in the range of (0, 1].", "labels": [], "entities": [{"text": "RRR", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.964145302772522}]}, {"text": "The higher the RRR, the better is the word acquisition performance.", "labels": [], "entities": [{"text": "RRR", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.9903996586799622}, {"text": "word acquisition", "start_pos": 38, "end_pos": 54, "type": "TASK", "confidence": 0.8268521130084991}]}, {"text": "The average of RRRs across all entities gives the Mean Reciprocal Rank Rate (MRRR).", "labels": [], "entities": [{"text": "Mean Reciprocal Rank Rate (MRRR)", "start_pos": 50, "end_pos": 82, "type": "METRIC", "confidence": 0.9591813513210842}]}, {"text": "Note that MRRR is directly based on the learned word-entity associations p(w|e), it is in fact a measure of grounding words to entities.", "labels": [], "entities": [{"text": "MRRR", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.736451268196106}]}, {"text": "To compare the effects of different speech-gaze alignments on word acquisition, we evaluate the following models: \u2022 Model-1 -base model I without word-entity alignment (Equation).", "labels": [], "entities": [{"text": "word acquisition", "start_pos": 62, "end_pos": 78, "type": "TASK", "confidence": 0.7656979858875275}]}, {"text": "\u2022 Model-2 -base model II with positional alignment (Equation).", "labels": [], "entities": [{"text": "Equation", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.7440524697303772}]}, {"text": "\u2022 Model-2t -enhanced model with temporal alignment (Equation).", "labels": [], "entities": [{"text": "Equation", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9183266162872314}]}, {"text": "\u2022 Model-2s -enhanced model with semantic alignment (Equation).", "labels": [], "entities": []}, {"text": "\u2022 Model-2ts -enhanced model with both temporal and semantic alignment (Equation).", "labels": [], "entities": [{"text": "Equation", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9202865362167358}]}, {"text": "To compare the different ways of incorporating semantic relatedness in word acquisition as discussed in Section 6.3.1, we also evaluate the following models: \u2022 Model-1-r -Model-1 with semantic relatedness rescoring of word-entity association.", "labels": [], "entities": [{"text": "word acquisition", "start_pos": 71, "end_pos": 87, "type": "TASK", "confidence": 0.7925176322460175}]}, {"text": "\u2022 Model-2t-r -Model-2t with semantic relatedness rescoring of word-entity association.", "labels": [], "entities": []}, {"text": "shows the results of models with different speech-gaze alignments.", "labels": [], "entities": []}, {"text": "shows the results of models with semantic relatedness rescoring.", "labels": [], "entities": []}, {"text": "In & 6, n-best means the top n word candidates are chosen as acquired words for each entity.", "labels": [], "entities": []}, {"text": "The Mean Reciprocal Rank Rates of all models are compared in.", "labels": [], "entities": [{"text": "Mean Reciprocal Rank Rates", "start_pos": 4, "end_pos": 30, "type": "METRIC", "confidence": 0.9206838756799698}]}, {"text": "8.2.1 Results of using different speech-gaze alignments As shown in, Model-2 does not show a consistent improvement compared to Model-1 when a different number of n-best words are chosen as acquired words.", "labels": [], "entities": []}, {"text": "This result shows that it is not very helpful to consider the index-based positional alignment of word and entity for word acquisition.", "labels": [], "entities": [{"text": "word acquisition", "start_pos": 118, "end_pos": 134, "type": "TASK", "confidence": 0.7732288837432861}]}, {"text": "also shows that models considering temporal or/and semantic information (Model-2t, Model-2s, Model-2ts) consistently perform better than the models considering neither temporal nor  semantic information (Model-1, Model-2).", "labels": [], "entities": []}, {"text": "Among Model-2t, Model-2s, and Model-2ts, it is found that they do not make consistent differences.", "labels": [], "entities": []}, {"text": "As shown in, the MRRRs of different models are consistent with their performances on Fmeasure.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 85, "end_pos": 93, "type": "DATASET", "confidence": 0.9362131953239441}]}, {"text": "A t-test has shown that the difference between the MRRRs of Model-1 and Model-2 is not statistically significant.", "labels": [], "entities": [{"text": "MRRRs", "start_pos": 51, "end_pos": 56, "type": "METRIC", "confidence": 0.7207847237586975}]}, {"text": "Compared to Model-1, ttests have confirmed that MRRR is significantly improved by Model-2t (t = 2.27, p < 0.02), Model-2s (t = 3.40, p < 0.01), and Model-2ts(t = 2.60, p < 0.01).", "labels": [], "entities": [{"text": "MRRR", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.779333233833313}]}, {"text": "T-tests have shown no significant differences among Model-2t, Model-2s, and Model-2ts.", "labels": [], "entities": [{"text": "T-tests", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.5894195437431335}]}, {"text": "shows that semantic relatedness rescoring improves word acquisition.", "labels": [], "entities": [{"text": "semantic relatedness rescoring", "start_pos": 11, "end_pos": 41, "type": "TASK", "confidence": 0.7819740970929464}, {"text": "word acquisition", "start_pos": 51, "end_pos": 67, "type": "TASK", "confidence": 0.811617374420166}]}, {"text": "After semantic relatedness rescoring of the word-entity associations learned by Model-1, Model-1-r improves the Fmeasure consistently when a different number of n-best words are chosen as acquired words.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9432660341262817}]}, {"text": "Compared to Model-2t, Model-2t-r also improves the Fmeasure consistently.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.979288637638092}]}], "tableCaptions": []}