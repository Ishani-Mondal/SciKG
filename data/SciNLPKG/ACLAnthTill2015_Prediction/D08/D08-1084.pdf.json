{"title": [{"text": "A Phrase-Based Alignment Model for Natural Language Inference", "labels": [], "entities": [{"text": "Phrase-Based Alignment", "start_pos": 2, "end_pos": 24, "type": "TASK", "confidence": 0.7733945548534393}, {"text": "Natural Language Inference", "start_pos": 35, "end_pos": 61, "type": "TASK", "confidence": 0.6848863760630289}]}], "abstractContent": [{"text": "The alignment problem-establishing links between corresponding phrases in two related sentences-is as important in natural language inference (NLI) as it is in machine translation (MT).", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 160, "end_pos": 184, "type": "TASK", "confidence": 0.837463915348053}]}, {"text": "But the tools and techniques of MT alignment do not readily transfer to NLI, where one cannot assume semantic equivalence , and for which large volumes of bitext are lacking.", "labels": [], "entities": [{"text": "MT alignment", "start_pos": 32, "end_pos": 44, "type": "TASK", "confidence": 0.9952709972858429}]}, {"text": "We present anew NLI aligner, the MANLI system, designed to address these challenges.", "labels": [], "entities": [{"text": "MANLI", "start_pos": 33, "end_pos": 38, "type": "DATASET", "confidence": 0.902856171131134}]}, {"text": "It uses a phrase-based alignment representation, exploits external lexical resources , and capitalizes on anew set of supervised training data.", "labels": [], "entities": [{"text": "phrase-based alignment representation", "start_pos": 10, "end_pos": 47, "type": "TASK", "confidence": 0.7229929069677988}]}, {"text": "We compare the performance of MANLI to existing NLI and MT aligners on an NLI alignment task over the well-known Recognizing Textual Entailment data.", "labels": [], "entities": [{"text": "MANLI", "start_pos": 30, "end_pos": 35, "type": "DATASET", "confidence": 0.7519691586494446}, {"text": "NLI alignment task", "start_pos": 74, "end_pos": 92, "type": "TASK", "confidence": 0.814970592657725}, {"text": "Recognizing Textual Entailment data", "start_pos": 113, "end_pos": 148, "type": "DATASET", "confidence": 0.6108983084559441}]}, {"text": "We show that MANLI significantly out-performs existing aligners, achieving gains of 6.2% in F 1 over a representative NLI aligner and 10.5% over GIZA++.", "labels": [], "entities": [{"text": "MANLI", "start_pos": 13, "end_pos": 18, "type": "DATASET", "confidence": 0.5480335354804993}, {"text": "F 1", "start_pos": 92, "end_pos": 95, "type": "METRIC", "confidence": 0.9931821525096893}]}], "introductionContent": [{"text": "The problem of natural language inference (NLI) is to determine whether a natural-language hypothesis H can reasonably be inferred from a given premise text P . In order to recognize that Kennedy was killed can be inferred from JFK was assassinated, one must first recognize the correspondence between Kennedy and JFK, and between killed and assassinated.", "labels": [], "entities": [{"text": "natural language inference (NLI)", "start_pos": 15, "end_pos": 47, "type": "TASK", "confidence": 0.8368908067544302}]}, {"text": "Consequently, most current approaches to NLI rely, implicitly or explicitly, on a facility for alignment-that is, establishing links between corresponding entities and predicates in P and H.", "labels": [], "entities": []}, {"text": "Recent entries in the annual Recognizing Textual Entailment (RTE) competition ) have addressed the alignment problem in a variety of ways, though often without distinguishing it as a separate subproblem.  and Jijkoun and de, among others, have explored approaches based on measuring the degree of lexical overlap between bags of words.", "labels": [], "entities": [{"text": "Recognizing Textual Entailment (RTE) competition", "start_pos": 29, "end_pos": 77, "type": "TASK", "confidence": 0.7376623196261269}]}, {"text": "While ignoring structure, such methods depend on matching each word in H to the word in P with which it is most similar-in effect, an alignment.", "labels": [], "entities": []}, {"text": "At the other extreme, and have formulated the inference problem as analogous to proof search, using inferential rules which encode (among other things) knowledge of lexical relatedness.", "labels": [], "entities": [{"text": "proof search", "start_pos": 80, "end_pos": 92, "type": "TASK", "confidence": 0.7598320841789246}]}, {"text": "In such approaches, the correspondence between the words of P and H is implicit in the steps of the proof.", "labels": [], "entities": []}, {"text": "Increasingly, however, the most successful RTE systems have made the alignment problem explicit. and) first advocated pipelined system architectures containing a distinct alignment component, a strategy crucial to the top-performing systems of and.", "labels": [], "entities": []}, {"text": "However, each of these systems has pursued alignment in idiosyncratic and poorly-documented ways, often using proprietary data, making comparisons and further development difficult.", "labels": [], "entities": []}, {"text": "In this paper we undertake the first systematic study of alignment for NLI.", "labels": [], "entities": [{"text": "alignment", "start_pos": 57, "end_pos": 66, "type": "TASK", "confidence": 0.9423954486846924}]}, {"text": "We propose anew NLI alignment system which uses a phrase-based representation of alignment, exploits external resources for knowledge of semantic relatedness, and capitalizes on the recent appearance of new supervised training data for NLI alignment.", "labels": [], "entities": [{"text": "NLI alignment", "start_pos": 16, "end_pos": 29, "type": "TASK", "confidence": 0.8371800780296326}, {"text": "NLI alignment", "start_pos": 236, "end_pos": 249, "type": "TASK", "confidence": 0.8865649402141571}]}, {"text": "In addition, we examine the relation between NLI alignment and MT alignment, and investigate whether existing MT aligners can usefully be applied in the NLI setting.", "labels": [], "entities": [{"text": "MT alignment", "start_pos": 63, "end_pos": 75, "type": "TASK", "confidence": 0.8915046751499176}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance of various aligners on the MSR  RTE2 alignment data. The columns show the data set  used (800 problems each); average precision, recall, and  F-measure; and the exact match rate (see text).", "labels": [], "entities": [{"text": "MSR  RTE2 alignment data", "start_pos": 49, "end_pos": 73, "type": "DATASET", "confidence": 0.8675622791051865}, {"text": "precision", "start_pos": 140, "end_pos": 149, "type": "METRIC", "confidence": 0.9298269748687744}, {"text": "recall", "start_pos": 151, "end_pos": 157, "type": "METRIC", "confidence": 0.9987024068832397}, {"text": "F-measure", "start_pos": 164, "end_pos": 173, "type": "METRIC", "confidence": 0.9991136193275452}, {"text": "exact match rate", "start_pos": 183, "end_pos": 199, "type": "METRIC", "confidence": 0.8245474894841512}]}, {"text": " Table 2: Performance of various aligners and complete  RTE systems in predicting RTE2 answers. The columns  show the data set used, accuracy, and average precision  (the recommended metric for RTE2).", "labels": [], "entities": [{"text": "predicting RTE2 answers", "start_pos": 71, "end_pos": 94, "type": "TASK", "confidence": 0.7700008749961853}, {"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9996540546417236}, {"text": "precision", "start_pos": 155, "end_pos": 164, "type": "METRIC", "confidence": 0.8969168066978455}]}]}