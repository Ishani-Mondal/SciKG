{"title": [{"text": "Syntactic Models for Structural Word Insertion and Deletion", "labels": [], "entities": [{"text": "Structural Word Insertion and Deletion", "start_pos": 21, "end_pos": 59, "type": "TASK", "confidence": 0.8309291005134583}]}], "abstractContent": [{"text": "An important problem in translation neglected by most recent statistical machine translation systems is insertion and deletion of words, such as function words, motivated by linguistic structure rather than adjacent lexical context.", "labels": [], "entities": [{"text": "translation", "start_pos": 24, "end_pos": 35, "type": "TASK", "confidence": 0.9619849920272827}, {"text": "statistical machine translation", "start_pos": 61, "end_pos": 92, "type": "TASK", "confidence": 0.6529724895954132}]}, {"text": "Phrasal and hierarchical systems can only insert or delete words in the context of a larger phrase or rule.", "labels": [], "entities": []}, {"text": "While this may suffice when translating in-domain, it performs poorly when trying to translate broad domains such as web text.", "labels": [], "entities": []}, {"text": "Various syntactic approaches have been proposed that begin to address this problem by learning lexicalized and unlexicalized rules.", "labels": [], "entities": []}, {"text": "Among these, the treelet approach uses unlexicalized order templates to model ordering separately from lexical choice.", "labels": [], "entities": []}, {"text": "We introduce an extension to the latter that allows for structural word insertion and deletion, without requiring a lexical anchor, and show that it produces gains of more than 1.0% BLEU over both phrasal and baseline treelet systems on broad domain text.", "labels": [], "entities": [{"text": "word insertion", "start_pos": 67, "end_pos": 81, "type": "TASK", "confidence": 0.729343056678772}, {"text": "BLEU", "start_pos": 182, "end_pos": 186, "type": "METRIC", "confidence": 0.9993234872817993}]}], "introductionContent": [{"text": "Among the phenomena that are modeled poorly by modern SMT systems is the insertion and deletion of words, such as function words, that are motivated by the divergent linguistic structure between source and target language.", "labels": [], "entities": [{"text": "SMT", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9934117197990417}]}, {"text": "To take the simplest of examples, the English noun compound \"file name\" would typically be translated into Spanish as \"nombre de archivo\", which requires the insertion of the preposition \"de\".", "labels": [], "entities": []}, {"text": "Conversely, when translating from Spanish to English, the \"de\" must be deleted.", "labels": [], "entities": []}, {"text": "At first glance, the problem may seem trivial, yet the presence and position of these function words can have crucial impact on the adequacy and fluency of translation.", "labels": [], "entities": []}, {"text": "In particular, function words are often used to denote key semantic information.", "labels": [], "entities": []}, {"text": "They maybe used to denote case information, in languages such as Japanese.", "labels": [], "entities": []}, {"text": "Failing to insert the proper case marker may render a sentence unreadable or significantly change its meaning.", "labels": [], "entities": []}, {"text": "Learning these operations can be tricky for MT models best suited to contiguous word sequences.", "labels": [], "entities": [{"text": "MT", "start_pos": 44, "end_pos": 46, "type": "TASK", "confidence": 0.9851608276367188}]}, {"text": "From a fluency standpoint, proper insertion of determiners and prepositions can often make the difference between laughably awkward output and natural sounding translations; consider the output \"it's a cake piece\" as opposed to \"it's apiece of cake\".", "labels": [], "entities": []}, {"text": "Furthermore, since missing or spurious function words can confuse the target language model, handling these words properly can have an impact beyond the words themselves.", "labels": [], "entities": []}, {"text": "This paper focuses on methods of inserting and deleting words based on syntactic cues, to be used in the context of a syntax-informed translation system.", "labels": [], "entities": []}, {"text": "While the models we build are relatively simple and the underlying templates are easy to extract, they add significant generalization ability to the base translation system, and result in significant gains.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the translation quality of the system using the BLEU metric ().", "labels": [], "entities": [{"text": "translation", "start_pos": 17, "end_pos": 28, "type": "TASK", "confidence": 0.9491811990737915}, {"text": "BLEU", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9967858791351318}]}, {"text": "We compared three systems: (a) a standard phrasal system using a decoder based on Pharaoh, (, (b) A baseline treelet system using unlexicalized order templates and (c) The present work, which adds structural insertion and deletion templates.", "labels": [], "entities": []}], "tableCaptions": []}