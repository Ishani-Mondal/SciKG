{"title": [{"text": "A Tale of Two Parsers: investigating and combining graph-based and transition-based dependency parsing using beam-search", "labels": [], "entities": [{"text": "transition-based dependency parsing", "start_pos": 67, "end_pos": 102, "type": "TASK", "confidence": 0.7437624136606852}]}], "abstractContent": [{"text": "Graph-based and transition-based approaches to dependency parsing adopt very different views of the problem, each view having its own strengths and limitations.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.8427806794643402}]}, {"text": "We study both approaches under the framework of beam-search.", "labels": [], "entities": []}, {"text": "By developing a graph-based and a transition-based dependency parser, we show that a beam-search decoder is a competitive choice for both methods.", "labels": [], "entities": []}, {"text": "More importantly, we propose a beam-search-based parser that combines both graph-based and transition-based parsing into a single system for training and decoding, showing that it outper-forms both the pure graph-based and the pure transition-based parsers.", "labels": [], "entities": []}, {"text": "Testing on the En-glish and Chinese Penn Treebank data, the combined system gave state-of-the-art accuracies of 92.1% and 86.2%, respectively.", "labels": [], "entities": [{"text": "En-glish", "start_pos": 15, "end_pos": 23, "type": "DATASET", "confidence": 0.9207184910774231}, {"text": "Chinese Penn Treebank data", "start_pos": 28, "end_pos": 54, "type": "DATASET", "confidence": 0.8737262785434723}, {"text": "accuracies", "start_pos": 98, "end_pos": 108, "type": "METRIC", "confidence": 0.9961987137794495}]}], "introductionContent": [{"text": "Graph-based () and transition-based () parsing algorithms offer two different approaches to data-driven dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 104, "end_pos": 122, "type": "TASK", "confidence": 0.6840586066246033}]}, {"text": "Given an input sentence, a graph-based algorithm finds the highest scoring parse tree from all possible outputs, scoring each complete tree, while a transition-based algorithm builds a parse by a sequence of actions, scoring each action individually.", "labels": [], "entities": []}, {"text": "The terms \"graph-based\" and \"transition-based\" were used by to describe the difference between MSTParser), which is a graph-based parser with an exhaustive search decoder, and MaltParser (), which is a transition-based parser with a greedy search decoder.", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 95, "end_pos": 104, "type": "DATASET", "confidence": 0.8715935945510864}]}, {"text": "In this paper, we do not differentiate graph-based and transitionbased parsers by their search algorithms: a graphbased parser can use an approximate decoder while a transition-based parser is not necessarily deterministic.", "labels": [], "entities": []}, {"text": "To make the concepts clear, we classify the two types of parser by the following two criteria: 1. whether or not the outputs are built by explicit transition-actions, such as \"Shift\" and \"Reduce\"; 2. whether it is dependency graphs or transitionactions that the parsing model assigns scores to.", "labels": [], "entities": []}, {"text": "By this classification, beam-search can be applied to both graph-based and transition-based parsers.", "labels": [], "entities": []}, {"text": "Representative of each method, MSTParser and MaltParser gave comparable accuracies in the CoNLL-X shared task ().", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 31, "end_pos": 40, "type": "DATASET", "confidence": 0.9157105088233948}, {"text": "MaltParser", "start_pos": 45, "end_pos": 55, "type": "DATASET", "confidence": 0.8874308466911316}]}, {"text": "However, they make different types of errors, which can be seen as a reflection of their theoretical differences.", "labels": [], "entities": []}, {"text": "MSTParser has the strength of exact inference, but its choice of features is constrained by the requirement of efficient dynamic programming.", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9026671051979065}]}, {"text": "MaltParser is deterministic, yet its comparatively larger feature range is an advantage.", "labels": [], "entities": [{"text": "MaltParser", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9659482836723328}]}, {"text": "By comparing the two, three interesting research questions arise: (1) how to increase the flexibility in defining features for graph-based parsing; (2) how to add search to transition-based parsing; and (3) how to combine the two parsing approaches so that the strengths of each are utilized.", "labels": [], "entities": []}, {"text": "In this paper, we study these questions under one framework: beam-search.", "labels": [], "entities": []}, {"text": "Beam-search has been successful in many NLP tasks ( Inputs: training examples (x i , y i ) Initialization: set w = 0 Algorithm: // R training iterations; N examples fort = 1..R, i = 1..N : w: The perceptron learning algorithm, and can achieve accuracy that is close to exact inference.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 243, "end_pos": 251, "type": "METRIC", "confidence": 0.9991838335990906}]}, {"text": "Moreover, a beamsearch decoder does not impose restrictions on the search problem in the way that an exact inference decoder typically does, such as requiring the \"optimal subproblem\" property for dynamic programming, and therefore enables a comparatively wider range of features fora statistical system.", "labels": [], "entities": []}, {"text": "Firstly, using the same features as MSTParser, we develop a graph-based parser to examine the accuracy loss from beamsearch compared to exact-search, and the accuracy gain from extra features that are hard to encode for exact inference.", "labels": [], "entities": [{"text": "MSTParser", "start_pos": 36, "end_pos": 45, "type": "DATASET", "confidence": 0.8716467618942261}, {"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9983357787132263}, {"text": "accuracy", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.9983536005020142}]}, {"text": "Our conclusion is that beamsearch is a competitive choice for graph-based parsing.", "labels": [], "entities": []}, {"text": "Secondly, using the transition actions from MaltParser, we build a transition-based parser and show that search has a positive effect on its accuracy compared to deterministic parsing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 141, "end_pos": 149, "type": "METRIC", "confidence": 0.9981513619422913}]}, {"text": "Finally, we show that by using a beam-search decoder, we are able to combine graph-based and transition-based parsing into a single system, with the combined system significantly outperforming each individual system.", "labels": [], "entities": []}, {"text": "In experiments with the English and Chinese Penn Treebank data, the combined parser gave 92.1% and 86.2% accuracy, respectively, which are comparable to the best parsing results for these data sets, while the Chinese accuracy outperforms the previous best reported by 1.8%.", "labels": [], "entities": [{"text": "Penn Treebank data", "start_pos": 44, "end_pos": 62, "type": "DATASET", "confidence": 0.8815131783485413}, {"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9977352619171143}, {"text": "Chinese accuracy", "start_pos": 209, "end_pos": 225, "type": "METRIC", "confidence": 0.7074973881244659}]}, {"text": "In line with previous work on dependency parsing using the Penn Treebank, we focus on projective dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.8809135258197784}, {"text": "Penn Treebank", "start_pos": 59, "end_pos": 72, "type": "DATASET", "confidence": 0.9960961043834686}, {"text": "projective dependency parsing", "start_pos": 86, "end_pos": 115, "type": "TASK", "confidence": 0.6109550992647806}]}], "datasetContent": [{"text": "We evaluate the parsers using the English and Chinese Penn Treebank corpora.", "labels": [], "entities": [{"text": "English and Chinese Penn Treebank corpora", "start_pos": 34, "end_pos": 75, "type": "DATASET", "confidence": 0.773075799147288}]}, {"text": "The English data is prepared by following.", "labels": [], "entities": [{"text": "English data", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.7528859674930573}]}, {"text": "Bracketed sentences from the Penn Treebank (PTB) 3 are split into training, development and test sets, and then translated into dependency structures using the head-finding rules from.", "labels": [], "entities": [{"text": "Penn Treebank (PTB) 3", "start_pos": 29, "end_pos": 50, "type": "DATASET", "confidence": 0.9776381254196167}]}, {"text": "Before parsing, POS tags are assigned to the input sentence using our reimplementation of the POStagger from.", "labels": [], "entities": []}, {"text": "Like, we evaluate the parsing accuracy by the precision of lexical heads (the percentage of input words, excluding punctuation, that have been assigned the correct parent) and by the percentage of complete matches, in which all words excluding punctuation have been assigned the correct parent.", "labels": [], "entities": [{"text": "parsing", "start_pos": 22, "end_pos": 29, "type": "TASK", "confidence": 0.9492558240890503}, {"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.948456883430481}, {"text": "precision", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9991016387939453}]}, {"text": "Since the beam size affects all three parsers, we study its influence first; here we show the effect on the transition-based parser.", "labels": [], "entities": []}, {"text": "shows different accuracy curves using the development data, each with a different beam size B.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9990440011024475}]}, {"text": "The X-axis represents the number of training iterations, and the Y-axis the precision of lexical heads.", "labels": [], "entities": [{"text": "precision", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9988162517547607}]}, {"text": "The parsing accuracy generally increases as the beam size increases, while the quantity of increase becomes very small when B becomes large enough.", "labels": [], "entities": [{"text": "parsing", "start_pos": 4, "end_pos": 11, "type": "TASK", "confidence": 0.9792056679725647}, {"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9591737985610962}]}, {"text": "The decoding times after the first training iteration are 10.2s, 27.3s, 45.5s, 79.0s, 145.4s, 261.3s and 469.5s, respectively, when B = 1, 2, 4, 8, 16, 32, 64.", "labels": [], "entities": [{"text": "B", "start_pos": 132, "end_pos": 133, "type": "METRIC", "confidence": 0.9824004173278809}]}, {"text": "In the rest of the experiments, we set B = 64 in order to obtain the highest possible accuracy.", "labels": [], "entities": [{"text": "B", "start_pos": 39, "end_pos": 40, "type": "METRIC", "confidence": 0.9965751767158508}, {"text": "accuracy", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.998309850692749}]}, {"text": "When B = 1, the transition-based parser becomes a deterministic parser.", "labels": [], "entities": []}, {"text": "By comparing the curves when B = 1 and B = 2, we can see that, while the use of search reduces the parsing speed, it improves the quality of the output parses.", "labels": [], "entities": [{"text": "parsing", "start_pos": 99, "end_pos": 106, "type": "TASK", "confidence": 0.9739234447479248}]}, {"text": "Therefore, beam-search is a reasonable choice for transitionbased parsing.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 4: The training, development and test data from", "labels": [], "entities": []}, {"text": " Table 5: Accuracy comparisons using PTB 3", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9975959658622742}, {"text": "PTB", "start_pos": 37, "end_pos": 40, "type": "DATASET", "confidence": 0.8642542362213135}]}, {"text": " Table 6: Training, development and test data from CTB", "labels": [], "entities": [{"text": "CTB", "start_pos": 51, "end_pos": 54, "type": "DATASET", "confidence": 0.7475279569625854}]}, {"text": " Table 7: Test accuracies with CTB 5 data", "labels": [], "entities": [{"text": "accuracies", "start_pos": 15, "end_pos": 25, "type": "METRIC", "confidence": 0.9177990555763245}]}]}