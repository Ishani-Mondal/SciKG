{"title": [{"text": "Acquiring Domain-Specific Dialog Information from Task-Oriented Human-Human Interaction through an Unsupervised Learning", "labels": [], "entities": [{"text": "Acquiring Domain-Specific Dialog Information from Task-Oriented Human-Human Interaction", "start_pos": 0, "end_pos": 87, "type": "TASK", "confidence": 0.8094432502985001}]}], "abstractContent": [{"text": "We describe an approach for acquiring the domain-specific dialog knowledge required to configure a task-oriented dialog system that uses human-human interaction data.", "labels": [], "entities": []}, {"text": "The key aspects of this problem are the design of a dialog information representation and a learning approach that supports capture of domain information from in-domain dialogs.", "labels": [], "entities": []}, {"text": "To represent a dialog fora learning purpose, we based our representation, the form-based dialog structure representation, on an observable structure.", "labels": [], "entities": []}, {"text": "We show that this representation is sufficient for modeling phenomena that occur regularly in several dissimilar task-oriented domains, including information-access and problem-solving.", "labels": [], "entities": []}, {"text": "With the goal of ultimately reducing human annotation effort, we examine the use of unsupervised learning techniques in acquiring the components of the form-based representation (i.e. task, subtask, and concept).", "labels": [], "entities": []}, {"text": "These techniques include statistical word clustering based on mutual information and Kullback-Liebler distance, TextTiling, HMM-based segmentation, and bisecting K-mean document clustering.", "labels": [], "entities": [{"text": "statistical word clustering", "start_pos": 25, "end_pos": 52, "type": "TASK", "confidence": 0.7250720659891764}, {"text": "HMM-based segmentation", "start_pos": 124, "end_pos": 146, "type": "TASK", "confidence": 0.8433815240859985}, {"text": "bisecting K-mean document clustering", "start_pos": 152, "end_pos": 188, "type": "TASK", "confidence": 0.5731689780950546}]}, {"text": "With some modifications to make these algorithms more suitable for inferring the structure of a spoken dialog, the unsupervised learning algorithms show promise.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent dialog management frameworks, such as RavenClaw ( and Collagen (), domain-dependent components of a dialog manager are clearly separated from domain-independent components.", "labels": [], "entities": [{"text": "dialog management", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.8204415142536163}, {"text": "RavenClaw", "start_pos": 48, "end_pos": 57, "type": "DATASET", "confidence": 0.9589430093765259}]}, {"text": "This separation allows rapid development of a dialog management module in anew task-oriented domain as dialog system developers can focus only on specifying domain-specific dialog information (e.g. the Dialog Task Specification in RavenClaw and Task Models in Collagen) while general dialog behaviors (e.g. turn-taking, confirmation mechanism, and generic help) are provided by the framework.", "labels": [], "entities": [{"text": "RavenClaw", "start_pos": 231, "end_pos": 240, "type": "DATASET", "confidence": 0.7245954871177673}]}, {"text": "For task-oriented domains, the domain-specific dialog information is equivalent to task-specific information.", "labels": [], "entities": []}, {"text": "Examples of the task-specific information are steps in a task and domain keywords.", "labels": [], "entities": []}, {"text": "Specifying task-specific knowledge by hand is still a time consuming process (.", "labels": [], "entities": []}, {"text": "Furthermore, the hand-crafted knowledge may not reflect users' perceptions of a task.", "labels": [], "entities": []}, {"text": "To reduce the subjectivity of system developers, recorded conversations of humans performing a similar task as a target dialog system have been used to help the developers design the task specification.", "labels": [], "entities": []}, {"text": "Nevertheless, analyzing a corpus of dialogs by hand requires a great deal of human effort ().", "labels": [], "entities": [{"text": "analyzing a corpus of dialogs", "start_pos": 14, "end_pos": 43, "type": "TASK", "confidence": 0.6761648893356323}]}, {"text": "This paper investigates the feasibility of automating this dialog analysis process through a machine-learning approach.", "labels": [], "entities": [{"text": "dialog analysis process", "start_pos": 59, "end_pos": 82, "type": "TASK", "confidence": 0.8905228773752848}]}, {"text": "By inferring the task-specific dialog information automatically from human-human interaction data, the knowledge engineering effort could be reduced as the developers need to only revise learned information rather than analyzing a large amount of data.", "labels": [], "entities": []}, {"text": "Acquiring the task-specific knowledge from a corpus of human-human dialogs is considered a knowledge acquisition process, where the target task structure has not yet been specified but will be explored from data before a dialog system is built.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 91, "end_pos": 112, "type": "TASK", "confidence": 0.7262344807386398}]}, {"text": "This is contrasted with a dialog structure recognition process), where pre-specified dialog structure components are recognized as a dialog progresses.", "labels": [], "entities": [{"text": "dialog structure recognition process", "start_pos": 26, "end_pos": 62, "type": "TASK", "confidence": 0.788900837302208}]}, {"text": "We use an unsupervised learning approach in our knowledge acquisition process as it can freely explore the structure in the data without any influence from human supervision.", "labels": [], "entities": [{"text": "knowledge acquisition", "start_pos": 48, "end_pos": 69, "type": "TASK", "confidence": 0.7672647833824158}]}, {"text": "showed that when modeling a dialog state transition diagram from data an unsupervised approach outperformed a supervised one as it better reflects the characteristic of the data.", "labels": [], "entities": []}, {"text": "It is also interesting to see how well a machine-learning approach can perform on the problem of taskspecific knowledge acquisition when no assumption about the domain is made and no prior knowledge is used.", "labels": [], "entities": [{"text": "taskspecific knowledge acquisition", "start_pos": 97, "end_pos": 131, "type": "TASK", "confidence": 0.725768506526947}]}, {"text": "Examination of task-oriented human-human dialogs show that task-specific information can be observed in dialog transcription; therefore, it should be feasible to be infer it through an unsupervised learning approach.", "labels": [], "entities": []}, {"text": "(a) shows a dialog in an air travel domain.", "labels": [], "entities": []}, {"text": "This dialog is organized into three parts according to the three steps (i.e. reserve a flight, reserve a car, reserve a hotel) required to accomplish the task, creating a travel itinerary.", "labels": [], "entities": []}, {"text": "Domain keywords (highlighted in bold) required to accomplish each step are clearly communicated.", "labels": [], "entities": []}, {"text": "To infer task-specific knowledge from data using an unsupervised learning approach, two problems need to be addressed: 1) choosing an appropriate dialog representation that captures observable task-specific knowledge in a dialog, and 2) developing an unsupervised learning approach that infers the task-specific knowledge modeled by this representation from in-domain human-human dialogs.", "labels": [], "entities": []}, {"text": "The first problem is discussed in Section 3 where a form-based dialog structure representation is proposed.", "labels": [], "entities": []}, {"text": "After describing the definition of each component in the form-based dialog structure representation, examples of how a domain expert models the task-specific information in a dialog with the form-based representation are given Section 3.1.", "labels": [], "entities": []}, {"text": "Then the annotation experiment which was used to verify that the form-based representation can be understood and applied by other human annotators is discussed in Section 3.2.", "labels": [], "entities": []}, {"text": "For the second problem, we modify existing unsupervised learning approaches to make them suitable for inferring the structure of a spoken dialog.", "labels": [], "entities": []}, {"text": "Section 4 describes these modifications and their performances when inferring the components of the form-based dialog structure representation from interaction data.", "labels": [], "entities": []}], "datasetContent": [{"text": "The goal of this annotation experiment is to verify that the form-based dialog structure framework can be understood by human annotators other than its developers, and that they can consistently apply the framework to model task-specific information in a dialog.", "labels": [], "entities": []}, {"text": "In this experiment, each annotator had to design a form-based dialog structure representation fora given task-oriented domain by specifying a hierarchical structure of tasks, sub-tasks and concepts in that domain.", "labels": [], "entities": []}, {"text": "Note that we are interested in the process of designing a domain-specific tagset from the definitions of task, subtask, and concept provided by the framework, not in the process of using an existing tagset to annotate data (see for example ().", "labels": [], "entities": []}, {"text": "The description of the framework is provided in annotation guidelines along with examples from the domains that were not used in the experiment.", "labels": [], "entities": []}, {"text": "The experimental procedure is as follows: the subjects first developed their own tagset according to the guidelines by analyzing a set of in-domain dialogs, and then annotate those dialogs with the tagset they had designed.", "labels": [], "entities": []}, {"text": "To obtain enough annotated instances for each dialog structure component and to make the annotation simple, the dialog structure annotation part of the experiment was divided into two sub-parts: concept annotation and task/sub-task annotation.", "labels": [], "entities": []}, {"text": "Two domains were used in the experiment, air travel planning and map reading.", "labels": [], "entities": [{"text": "air travel planning", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.7313169240951538}, {"text": "map reading", "start_pos": 65, "end_pos": 76, "type": "TASK", "confidence": 0.8719625771045685}]}, {"text": "Four subjects were assigned to each domain.", "labels": [], "entities": []}, {"text": "None had used the scheme previously.", "labels": [], "entities": []}, {"text": "The average number of tags that each subject annotated is shown in the first row of.", "labels": [], "entities": []}, {"text": "Since some variations in tagset designs are acceptable as long as they conform to the guidelines, each subject's annotation is judged against the guidelines rather than one specific reference annotation.", "labels": [], "entities": []}, {"text": "An annotation instance is marked as incorrect only when it does not conform to the guidelines.", "labels": [], "entities": []}, {"text": "Each subject's annotation was evaluated by both a coding scheme expert and by other subjects.", "labels": [], "entities": []}, {"text": "Accuracy is computed from the expert's judgment while acceptability is computed from peers' judgments.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9920811653137207}]}, {"text": "Acceptability scores shown in were averaged from all other subjects in the same group.", "labels": [], "entities": [{"text": "Acceptability", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.9939602613449097}]}, {"text": "Please note that the result presented in this table should not be compared to the results from machine-learning approaches presented in: Accuracy and acceptability on concept annotation (C), and task/subtask annotation (T) Both accuracy and acceptability are high for all annotation tasks except for the accuracy of task/subtask annotation in the map reading domain.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.9986516833305359}, {"text": "accuracy", "start_pos": 228, "end_pos": 236, "type": "METRIC", "confidence": 0.9979373216629028}, {"text": "accuracy", "start_pos": 304, "end_pos": 312, "type": "METRIC", "confidence": 0.9982512593269348}]}, {"text": "Most of the errors come from the annotation of the grounding subtasks.", "labels": [], "entities": []}, {"text": "Since its corresponding action is quite difficult to observe, subjects may not have a concrete definition of grounding and were more likely to produce errors.", "labels": [], "entities": []}, {"text": "In addition, they were less critical when judging other subjects' annotations.", "labels": [], "entities": []}, {"text": "Consistency in applying the form-based dialog structure representation shows that the representation is unambiguous and could potentially be identified through a machine-learning approach.", "labels": [], "entities": []}, {"text": "When comparing among components, concepts were annotated more consistently than tasks and subtasks in terms of both accuracy and acceptability.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.998661994934082}]}, {"text": "One possible reason is that, a concept is easier to observe as its unit is smaller than a task or a subtask.", "labels": [], "entities": []}, {"text": "Moreover, dialog participants have to clearly communicate the concepts in order to execute a domain action.", "labels": [], "entities": []}, {"text": "The subjects usually agreed on tasks and top-level subtasks, but did not quite agree on low-level subtasks.", "labels": [], "entities": []}, {"text": "The low-level subtasks are correlated with the implementation of a dialog system; hence, the designs of these subtasks are more subjective and likely to be different.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy and acceptability on concept annota- tion (C), and task/subtask annotation (T)", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9979017972946167}]}, {"text": " Table 2: Dialog segmentation results", "labels": [], "entities": [{"text": "Dialog segmentation", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.9437672197818756}]}, {"text": " Table 3: Subtask clustering results", "labels": [], "entities": [{"text": "Subtask clustering", "start_pos": 10, "end_pos": 28, "type": "TASK", "confidence": 0.9582400023937225}]}]}