{"title": [{"text": "Learning with Compositional Semantics as Structural Inference for Subsentential Sentiment Analysis", "labels": [], "entities": [{"text": "Structural Inference", "start_pos": 41, "end_pos": 61, "type": "TASK", "confidence": 0.7560586631298065}, {"text": "Subsentential Sentiment Analysis", "start_pos": 66, "end_pos": 98, "type": "TASK", "confidence": 0.7934990127881368}]}], "abstractContent": [{"text": "Determining the polarity of a sentiment-bearing expression requires more than a simple bag-of-words approach.", "labels": [], "entities": []}, {"text": "In particular, words or constituents within the expression can interact with each other to yield a particular overall polarity.", "labels": [], "entities": []}, {"text": "In this paper, we view such subsentential interactions in light of composi-tional semantics, and present a novel learning-based approach that incorporates structural inference motivated by compositional semantics into the learning procedure.", "labels": [], "entities": []}, {"text": "Our experiments show that (1) simple heuristics based on compositional semantics can perform better than learning-based methods that do not incorporate compositional semantics (accuracy of 89.7% vs. 89.1%), but (2) a method that integrates compositional semantics into learning performs better than all other alternatives (90.7%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 177, "end_pos": 185, "type": "METRIC", "confidence": 0.9985021352767944}]}, {"text": "We also find that \"content-word negators\", not widely employed in previous work, play an important role in determining expression-level polarity.", "labels": [], "entities": []}, {"text": "Finally, in contrast to conventional wisdom, we find that expression-level classification accuracy uniformly decreases as additional, potentially disambiguating, context is considered.", "labels": [], "entities": [{"text": "expression-level classification", "start_pos": 58, "end_pos": 89, "type": "TASK", "confidence": 0.6438464820384979}, {"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9246089458465576}]}], "introductionContent": [{"text": "Determining the polarity of sentiment-bearing expressions at or below the sentence level requires more than a simple bag-of-words approach.", "labels": [], "entities": []}, {"text": "One of the difficulties is that words or constituents within the expression can interact with each other to yield a particular overall polarity.", "labels": [], "entities": []}, {"text": "To facilitate our discussion, consider the following examples: In the first example, \"doubt\" in isolation carries a negative sentiment, but the overall polarity of the sentence is positive because there is a negator \"not\", which flips the polarity.", "labels": [], "entities": []}, {"text": "In the second example, both \"eliminated\" and \"doubt\" carry negative sentiment in isolation, but the overall polarity of the sentence is positive because \"eliminated\" acts as a negator for its argument \"doubt\".", "labels": [], "entities": []}, {"text": "In the last example, there are effectively two negators -\"not\" and \"eliminated\" -which reverse the polarity of \"doubt\" twice, resulting in the negative polarity for the overall sentence.", "labels": [], "entities": []}, {"text": "These examples demonstrate that words or constituents interact with each other to yield the expression-level polarity.", "labels": [], "entities": []}, {"text": "And a system that simply takes the majority vote of the polarity of individual words will notwork well on the above examples.", "labels": [], "entities": []}, {"text": "Indeed, much of the previous learning-based research on this topic tries to incorporate salient interactions by encoding them as features.", "labels": [], "entities": []}, {"text": "One approach includes features based on contextual valence shifters 1 (), which are words that affect the polarity or intensity of sentiment over neighboring text spans (e.g.,, ,).", "labels": [], "entities": []}, {"text": "Another approach encodes frequent subsentential patterns (e.g.,) as features; these might indirectly capture some of the subsentential interactions that affect polarity.", "labels": [], "entities": []}, {"text": "How-ever, both types of approach are based on learning models with a flat bag-of-features: some structural information can be encoded as higher order features, but the final representation of the input is still a flat feature vector that is inherently too limited to adequately reflect the complex structural nature of the underlying subsentential interactions.", "labels": [], "entities": []}, {"text": "(), on the other hand, handle the structural nature of the interactions more directly using the ideas from compositional semantics (e.g.,,).", "labels": [], "entities": []}, {"text": "In short, the Principle of Compositionality states that the meaning of a compound expression is a function of the meaning of its parts and of the syntactic rules by which they are combined (e.g.,,).", "labels": [], "entities": []}, {"text": "And Moilanen and Pulman (2007) develop a collection of composition rules to assign a sentiment value to individual expressions, clauses, or sentences.", "labels": [], "entities": []}, {"text": "Their approach can be viewed as a type of structural inference, but their hand-written rules have not been empirically compared to learning-based alternatives, which one might expect to be more effective in handling some aspects of the polarity classification task.", "labels": [], "entities": [{"text": "polarity classification task", "start_pos": 236, "end_pos": 264, "type": "TASK", "confidence": 0.7898945609728495}]}, {"text": "In this paper, we begin to close the gap between learning-based approaches to expression-level polarity classification and those founded on compositional semantics: we present a novel learning-based approach that incorporates structural inference motivated by compositional semantics into the learning procedure.", "labels": [], "entities": [{"text": "expression-level polarity classification", "start_pos": 78, "end_pos": 118, "type": "TASK", "confidence": 0.716309130191803}]}, {"text": "Adopting the viewpoint of compositional semantics, our working assumption is that the polarity of a sentiment-bearing expression can be determined in a two-step process: (1) assess the polarities of the constituents of the expression, and then (2) apply a relatively simple set of inference rules to combine them recursively.", "labels": [], "entities": []}, {"text": "Rather than a rigid application of handwritten compositional inference rules, however, we hypothesize that an ideal solution to the expressionlevel polarity classification task will be a method that can exploit ideas from compositional semantics while providing the flexibility needed to handle the complexities of real-world natural languageexceptions, unknown words, missing semantic features, and inaccurate or missing rules.", "labels": [], "entities": [{"text": "expressionlevel polarity classification", "start_pos": 132, "end_pos": 171, "type": "TASK", "confidence": 0.7317472696304321}]}, {"text": "The learningbased approach proposed in this paper takes a first step in this direction.", "labels": [], "entities": []}, {"text": "In addition to the novel learning approach, this paper presents new insights for content-word negators, which we define as content words that can negate the polarity of neighboring words or constituents.", "labels": [], "entities": []}, {"text": "(e.g., words such as \"eliminated\" in the example sentences).", "labels": [], "entities": []}, {"text": "Unlike function-word negators, such as \"not\" or \"never\", content-word negators have been recognized and utilized less actively in previous work.", "labels": [], "entities": []}, {"text": "(Notable exceptions include e.g.,, , and. ) In our experiments, we compare learning-and non-learning-based approaches to expression-level polarity classification -with and without compositional semantics -and find that (1) simple heuristics based on compositional semantics outperform (89.7% in accuracy) other reasonable heuristics that do not incorporate compositional semantics (87.7%); they can also perform better than simple learning-based methods that do not incorporate compositional semantics (89.1%), (2) combining learning with the heuristic rules based on compositional semantics further improves the performance (90.7%), (3) content-word negators play an important role in determining the expression-level polarity, and, somewhat surprisingly, we find that (4) expression-level classification accuracy uniformly decreases as additional, potentially disambiguating, context is considered.", "labels": [], "entities": [{"text": "expression-level polarity classification", "start_pos": 121, "end_pos": 161, "type": "TASK", "confidence": 0.6511132121086121}, {"text": "accuracy", "start_pos": 295, "end_pos": 303, "type": "METRIC", "confidence": 0.9941946864128113}, {"text": "accuracy", "start_pos": 806, "end_pos": 814, "type": "METRIC", "confidence": 0.8911911845207214}]}, {"text": "In what follows, we first explore heuristic-based approaches in \u00a72, then we present learning-based approaches in \u00a73.", "labels": [], "entities": []}, {"text": "Next we present experimental results in \u00a74, followed by related work in \u00a75.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experiments below evaluate our heuristic-and learning-based methods for subsentential sentiment analysis ( \u00a7 4.1).", "labels": [], "entities": [{"text": "subsentential sentiment analysis", "start_pos": 76, "end_pos": 108, "type": "TASK", "confidence": 0.8887064258257548}]}, {"text": "In addition, we explore the role of context by expanding the boundaries of the sentiment-bearing expressions ( \u00a7 4.2).", "labels": [], "entities": []}, {"text": "For evaluation, we use the Multi-Perspective Question Answering (MPQA) corpus ), which consists of 535 newswire documents manually annotated with phrase-level subjectivity information.", "labels": [], "entities": [{"text": "Multi-Perspective Question Answering (MPQA)", "start_pos": 27, "end_pos": 70, "type": "TASK", "confidence": 0.7621724804242452}]}, {"text": "We evaluate on all strong (i.e., intensity of expression is 'medium' or higher), sentimentbearing (i.e., polarity is 'positive' or 'negative') expressions.", "labels": [], "entities": []}, {"text": "As a result, we can assume the boundaries of the expressions are given.", "labels": [], "entities": []}, {"text": "Performance is reported using 10-fold cross-validation on 400 documents; a separate 135 documents were used as a development set.", "labels": [], "entities": []}, {"text": "Based on pilot experiments on the development data, we set parameters for MIRA as follows: slack variable to 0.5, and the number of incorrect labels (constraints) for each parameter update to 1.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 74, "end_pos": 78, "type": "TASK", "confidence": 0.5097536444664001}]}, {"text": "The number of iterations (epochs) for training is set to 1 for simple classification, and to 4   for classification with compositional inference.", "labels": [], "entities": []}, {"text": "We use K = 20 for classification with compositional inference.", "labels": [], "entities": []}, {"text": "Interestingly, the heuristic-based methods NEG (\u223c 82.2%) that only consider function-word negators perform even worse than VOTE (86.5%), which does not consider negators.", "labels": [], "entities": []}, {"text": "On the other hand, the NEGEX methods (87.7%) that do consider content-word negators as well as function-word negators perform better than VOTE.", "labels": [], "entities": []}, {"text": "This confirms the importance of content-word negators for determining the polarities of expressions.", "labels": [], "entities": []}, {"text": "The heuristic-based methods motivated by compositional semantics COMPO further improve the performance over NEGEX, achieving up to 89.7% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.9967358708381653}]}, {"text": "In fact, these heuristics perform even better than the SC learning-based methods (\u223c 89.1%).", "labels": [], "entities": []}, {"text": "This shows that heuristics that take into account the compositional structure of the expression can perform better than learning-based methods that do not exploit such structure.", "labels": [], "entities": []}, {"text": "Finally, the learning-based methods that incorporate compositional inference CCI-COMPO (\u223c 90.7%) perform better than all of the previous methods.", "labels": [], "entities": []}, {"text": "The difference between CCI-COMPOPR (90.7%) and SC-NEGEX (89.1%) is statistically significant at the .05 level by paired t-test.", "labels": [], "entities": []}, {"text": "The difference between COMPO and any other heuristic that is not based on computational semantics is also statistically significant.", "labels": [], "entities": []}, {"text": "In addition, the difference between CCICOMPOPR (learning-based) and COM-POMC (non-learning-based) is statistically significant, as is the difference between NEGEX and VOTE.", "labels": [], "entities": [{"text": "VOTE", "start_pos": 167, "end_pos": 171, "type": "DATASET", "confidence": 0.8924934267997742}]}, {"text": "One might wonder whether employing additional context outside the annotated expression boundaries could further improve the performance.", "labels": [], "entities": []}, {"text": "Indeed, conventional wisdom would say that it is necessary to employ such contextual information (e.g., ).", "labels": [], "entities": []}, {"text": "In any case, it is important to determine whether our results will apply to more real-world settings where human-annotated expression boundaries are not available.", "labels": [], "entities": []}, {"text": "To address these questions, we gradually relax our previous assumption that the exact boundaries of expressions are given: for each annotation boundary, we expand the boundary by x words for each direction, up to sentence boundaries, where x \u2208 {1, 5, \u221e}.", "labels": [], "entities": []}, {"text": "We stop expanding the boundary if it will collide with the boundary of an expression with a different polarity, so that we can consistently recover the expression-level gold standard for evaluation.", "labels": [], "entities": []}, {"text": "This expansion is applied to both the training and test data, and the performance is reported in.", "labels": [], "entities": []}, {"text": "From this experiment, we make the following observations: \u2022 Expanding the boundaries hurts the perfor-mance for any method.", "labels": [], "entities": []}, {"text": "This shows that most of relevant context for judging the polarity is contained within the expression boundaries, and motivates the task of finding the boundaries of opinion expressions.", "labels": [], "entities": []}, {"text": "\u2022 The NEGEX methods perform better than VOTE only when the expression boundaries are reasonably accurate.", "labels": [], "entities": []}, {"text": "When the expression boundaries are expanded up to sentence boundaries, they perform worse than VOTE.", "labels": [], "entities": []}, {"text": "We conjecture this is because the scope of negators tends to be limited to inside of expression boundaries.", "labels": [], "entities": []}, {"text": "\u2022 The COMPO methods always perform better than any other heuristic-based methods.", "labels": [], "entities": []}, {"text": "And their performance does not decrease as steeply as the NEGEX methods as the expression boundaries expand.", "labels": [], "entities": []}, {"text": "We conjecture this is because methods based on compositional semantics can handle the scope of negators more adequately.", "labels": [], "entities": []}, {"text": "\u2022 Among the learning-based methods, those that involve compositional inference (CCI-COMPO) always perform better than those that do not (SC) for any boundaries.", "labels": [], "entities": []}, {"text": "And learning with compositional inference tend to perform better than the rigid application of heuristic rules (COMPO), although the relative performance gain decreases once the boundaries are relaxed.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Heuristic methods. (n refers to the number of negators found in a given expression.)", "labels": [], "entities": []}, {"text": " Table 3: Performance (in accuracy) on MPQA dataset.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9983899593353271}, {"text": "MPQA dataset", "start_pos": 39, "end_pos": 51, "type": "DATASET", "confidence": 0.9764977097511292}]}, {"text": " Table 4: Performance (in accuracy) on MPQA data set with varying boundaries of expressions.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9988278746604919}, {"text": "MPQA data set", "start_pos": 39, "end_pos": 52, "type": "DATASET", "confidence": 0.9527836044629415}]}]}