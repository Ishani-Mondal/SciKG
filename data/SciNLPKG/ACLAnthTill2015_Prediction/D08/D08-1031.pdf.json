{"title": [{"text": "Understanding the Value of Features for Coreference Resolution", "labels": [], "entities": [{"text": "Coreference", "start_pos": 40, "end_pos": 51, "type": "TASK", "confidence": 0.968702495098114}]}], "abstractContent": [{"text": "In recent years there has been substantial work on the important problem of coreference resolution , most of which has concentrated on the development of new models and algo-rithmic techniques.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 76, "end_pos": 98, "type": "TASK", "confidence": 0.9860684871673584}]}, {"text": "These works often show that complex models improve over a weak pairwise baseline.", "labels": [], "entities": []}, {"text": "However, less attention has been given to the importance of selecting strong features to support learning a corefer-ence model.", "labels": [], "entities": []}, {"text": "This paper describes a rather simple pair-wise classification model for coreference resolution , developed with a well-designed set of features.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 72, "end_pos": 94, "type": "TASK", "confidence": 0.9796506464481354}]}, {"text": "We show that this produces a state-of-the-art system that outperforms systems built with complex models.", "labels": [], "entities": []}, {"text": "We suggest that our system can be used as a baseline for the development of more complex models-which may have less impact when a more robust set of features is used.", "labels": [], "entities": []}, {"text": "The paper also presents an ablation study and discusses the relative contributions of various features.", "labels": [], "entities": []}], "introductionContent": [{"text": "Coreference resolution is the task of grouping all the mentions of entities 1 in a document into equivalence classes so that all the mentions in a given class refer to the same discourse entity.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9252078831195831}]}, {"text": "For example, given the sentence (where the head noun of each mention is subscripted) An American 1 official 2 announced that American 1 President 3 Bill Clinton 3 met his 3 Russian 4 counterpart 5 , Vladimir Putin 5 , today.", "labels": [], "entities": []}, {"text": "the task is to group the mentions so that those referring to the same entity are placed together into an equivalence class.", "labels": [], "entities": []}, {"text": "Many NLP tasks detect attributes, actions, and relations between discourse entities.", "labels": [], "entities": []}, {"text": "In order to discover all information about a given entity, textual mentions of that entity must be grouped together.", "labels": [], "entities": []}, {"text": "Thus coreference is an important prerequisite to such tasks as textual entailment and information extraction, among others.", "labels": [], "entities": [{"text": "textual entailment", "start_pos": 63, "end_pos": 81, "type": "TASK", "confidence": 0.761721134185791}, {"text": "information extraction", "start_pos": 86, "end_pos": 108, "type": "TASK", "confidence": 0.823061466217041}]}, {"text": "Although coreference resolution has received much attention, that attention has not focused on the relative impact of high-quality features.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 9, "end_pos": 31, "type": "TASK", "confidence": 0.9740343689918518}]}, {"text": "Thus, while many structural innovations in the modeling approach have been made, those innovations have generally been tested on systems with features whose strength has not been established, and compared to weak pairwise baselines.", "labels": [], "entities": []}, {"text": "As a result, it is possible that some modeling innovations may have less impact or applicability when applied to a stronger baseline system.", "labels": [], "entities": []}, {"text": "This paper introduces a rather simple but stateof-the-art system, which we intend to be used as a strong baseline to evaluate the impact of structural innovations.", "labels": [], "entities": []}, {"text": "To this end, we combine an effective coreference classification model with a strong set of features, and present an ablation study to show the relative impact of a variety of features.", "labels": [], "entities": [{"text": "coreference classification", "start_pos": 37, "end_pos": 63, "type": "TASK", "confidence": 0.9055087864398956}]}, {"text": "As we show, this combination of a pairwise model and strong features produces a 1.5 percent-age point increase in B-Cubed F-Score over a complex model in the state-of-the-art system by, although their system uses a complex, non-pairwise model, computing features over partial clusters of mentions.", "labels": [], "entities": [{"text": "B-Cubed F-Score", "start_pos": 114, "end_pos": 129, "type": "METRIC", "confidence": 0.8058421909809113}]}], "datasetContent": [{"text": "B-Cubed F-Score We evaluate over the commonly used B-Cubed F-Score (, which is a measure of the overlap of predicted clusters and true clusters.", "labels": [], "entities": []}, {"text": "It is computed as the harmonic mean of precision (P ), and recall (R), where cm is the number of mentions appearing both in m's predicted cluster and in m's true cluster, pm is the size of the predicted cluster containing m, and t m is the size of m's true cluster.", "labels": [], "entities": [{"text": "precision (P )", "start_pos": 39, "end_pos": 53, "type": "METRIC", "confidence": 0.9299196749925613}, {"text": "recall (R)", "start_pos": 59, "end_pos": 69, "type": "METRIC", "confidence": 0.9097094237804413}]}, {"text": "Finally, d represents a document from the set D, and N is the total number of mentions in D.", "labels": [], "entities": []}, {"text": "B-Cubed F-Score has the advantage of being able to measure the impact of singleton entities, and of giving more weight to the splitting or merging of larger entities.", "labels": [], "entities": [{"text": "B-Cubed F-Score", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.7966016232967377}]}, {"text": "It also gives equal weight to all types of entities and mentions.", "labels": [], "entities": []}, {"text": "For these reasons, we report our results using B-Cubed F-Score.", "labels": [], "entities": [{"text": "B-Cubed F-Score", "start_pos": 47, "end_pos": 62, "type": "METRIC", "confidence": 0.7680519819259644}]}, {"text": "MUC F-Score We also provide results using the official MUC scoring algorithm (.", "labels": [], "entities": [{"text": "MUC", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.972950279712677}, {"text": "F-Score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.6863416433334351}, {"text": "MUC scoring algorithm", "start_pos": 55, "end_pos": 76, "type": "DATASET", "confidence": 0.6780322194099426}]}, {"text": "The MUC F-score is also the harmonic mean of precision and recall.", "labels": [], "entities": [{"text": "MUC", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.5112534165382385}, {"text": "F-score", "start_pos": 8, "end_pos": 15, "type": "METRIC", "confidence": 0.5896276831626892}, {"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9995891451835632}, {"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9971169233322144}]}, {"text": "However, the MUC precision counts precision errors by computing the minimum number of links that must be added to ensure that all mentions referring to a given entity are connected in the graph.", "labels": [], "entities": [{"text": "MUC", "start_pos": 13, "end_pos": 16, "type": "DATASET", "confidence": 0.644090473651886}, {"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.8342301845550537}, {"text": "precision", "start_pos": 34, "end_pos": 43, "type": "METRIC", "confidence": 0.9970276951789856}]}, {"text": "Recall errors are the number of links that must be removed to ensure that no two mentions referring to different entities are connected in the graph.", "labels": [], "entities": [{"text": "Recall errors", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.9560312032699585}]}, {"text": "To evaluate, we align the heads of the detected mentions to the gold standard heads greedily based on number of overlapping words.", "labels": [], "entities": []}, {"text": "We choose not to impute errors to the coreference system for mentions that were not detected or for spuriously detected mentions (following and others).", "labels": [], "entities": []}, {"text": "Although this evaluation is lenient, given that the mention detection component performs at over 90% F 1 , we believe it provides a realistic measure for the performance of the end-to-end system and focuses the evaluation on the coreference component.", "labels": [], "entities": [{"text": "mention detection", "start_pos": 52, "end_pos": 69, "type": "TASK", "confidence": 0.6723780632019043}, {"text": "F 1", "start_pos": 101, "end_pos": 104, "type": "METRIC", "confidence": 0.9948320388793945}]}, {"text": "The results of our end-to-end coreference system are shown in.", "labels": [], "entities": []}, {"text": "Precision Recall B 3 F End-to-End System 84.91 72.53 78.24: Coreference results using detected mentions on unseen Test Data.", "labels": [], "entities": [{"text": "Precision Recall B 3 F End-to-End System 84.91 72.53 78.24", "start_pos": 0, "end_pos": 58, "type": "METRIC", "confidence": 0.806144404411316}, {"text": "Coreference", "start_pos": 60, "end_pos": 71, "type": "TASK", "confidence": 0.9360202550888062}]}], "tableCaptions": [{"text": " Table 4: Evaluation on unseen Test Data using B 3 score.  Shows that our system outperforms the advanced system  of Culotta et al. The improvement is statistically signifi- cant at the p = 0.05 level according to a non-parametric  bootstrapping percentile test.", "labels": [], "entities": [{"text": "B 3 score", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9673128724098206}]}, {"text": " Table 5: Evaluation of our system on unseen Test Data  using MUC score.", "labels": [], "entities": [{"text": "unseen Test Data", "start_pos": 38, "end_pos": 54, "type": "DATASET", "confidence": 0.6189021368821462}, {"text": "MUC score", "start_pos": 62, "end_pos": 71, "type": "DATASET", "confidence": 0.6294741332530975}]}, {"text": " Table 6: Contribution of Features as evaluated on a development set. Bold results are significantly better than the  previous line at the p = 0.05 level according to a paired non-parametric bootstrapping percentile test. These results  show the importance of Distance, Entity Type, and Apposition features.", "labels": [], "entities": [{"text": "Distance", "start_pos": 260, "end_pos": 268, "type": "METRIC", "confidence": 0.9948651194572449}, {"text": "Apposition", "start_pos": 287, "end_pos": 297, "type": "METRIC", "confidence": 0.9968480467796326}]}]}