{"title": [{"text": "Adding Redundant Features for CRFs-based Sentence Sentiment Classification", "labels": [], "entities": [{"text": "Sentence Sentiment Classification", "start_pos": 41, "end_pos": 74, "type": "TASK", "confidence": 0.8099008798599243}]}], "abstractContent": [{"text": "In this paper, we present a novel method based on CRFs in response to the two special characteristics of \"contextual dependency\" and \"label redundancy\" in sentence sentiment classification.", "labels": [], "entities": [{"text": "sentence sentiment classification", "start_pos": 155, "end_pos": 188, "type": "TASK", "confidence": 0.8115968704223633}]}, {"text": "We try to capture the contextual constraints on sentence sentiment using CRFs.", "labels": [], "entities": [{"text": "sentence sentiment", "start_pos": 48, "end_pos": 66, "type": "TASK", "confidence": 0.7568300068378448}]}, {"text": "Through introducing redundant labels into the original sentimental label set and organizing all labels into a hierarchy, our method can add redundant features into training for capturing the label redundancy.", "labels": [], "entities": []}, {"text": "The experimental results prove that our method outperforms the traditional methods like NB, SVM, MaxEnt and standard chain CRFs.", "labels": [], "entities": [{"text": "NB", "start_pos": 88, "end_pos": 90, "type": "DATASET", "confidence": 0.8924275040626526}]}, {"text": "In comparison with the cascaded model, our method can effectively alleviate the error propagation among different layers and obtain better performance in each layer.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Result of Sentimental Strength Rating", "labels": [], "entities": [{"text": "Result", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9551270604133606}]}, {"text": " Table 2. Result of Polarity Classification Extracted from Table 1.", "labels": [], "entities": [{"text": "Result", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.8623570203781128}]}, {"text": " Table 3. Result of Polarity Classification", "labels": [], "entities": [{"text": "Result of Polarity Classification", "start_pos": 10, "end_pos": 43, "type": "TASK", "confidence": 0.5609097369015217}]}, {"text": " Table 4. Data Statistics for Movies Reviews  Corpus  There is a problem in the dataset that more than  70% of the sentences are labeled as \"Neu\" and  labels are seriously unbalanced. As a result, the  \"Neu\" label is over-emphasized. For this problem,", "labels": [], "entities": []}, {"text": " Table 5. The accuracy of Sentimental Strength Rating", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9998087286949158}, {"text": "Sentimental Strength Rating", "start_pos": 26, "end_pos": 53, "type": "TASK", "confidence": 0.8947247465451559}]}, {"text": " Table 7. The accuracy of Subjective/Objective Classification", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.999679446220398}, {"text": "Subjective/Objective Classification", "start_pos": 26, "end_pos": 61, "type": "TASK", "confidence": 0.842887356877327}]}]}