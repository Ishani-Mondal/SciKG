{"title": [{"text": "Two Languages are Better than One (for Syntactic Parsing)", "labels": [], "entities": [{"text": "Syntactic Parsing)", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.8881086707115173}]}], "abstractContent": [{"text": "We show that jointly parsing a bitext can substantially improve parse quality on both sides.", "labels": [], "entities": [{"text": "parsing a bitext", "start_pos": 21, "end_pos": 37, "type": "TASK", "confidence": 0.8435372312863668}]}, {"text": "Ina maximum entropy bitext parsing model, we define a distribution over source trees, target trees, and node-to-node alignments between them.", "labels": [], "entities": []}, {"text": "Features include monolingual parse scores and various measures of syntactic divergence.", "labels": [], "entities": [{"text": "syntactic divergence", "start_pos": 66, "end_pos": 86, "type": "TASK", "confidence": 0.6632868349552155}]}, {"text": "Using the translated portion of the Chinese treebank, our model is trained iteratively to maximize the marginal likelihood of training tree pairs, with alignments treated as latent variables.", "labels": [], "entities": [{"text": "Chinese treebank", "start_pos": 36, "end_pos": 52, "type": "DATASET", "confidence": 0.9313145279884338}]}, {"text": "The resulting bi-text parser outperforms state-of-the-art mono-lingual parser baselines by 2.5 F 1 at predicting English side trees and 1.8 F 1 at predicting Chi-nese side trees (the highest published numbers on these corpora).", "labels": [], "entities": [{"text": "F 1", "start_pos": 140, "end_pos": 143, "type": "METRIC", "confidence": 0.9735327064990997}]}, {"text": "Moreover, these improved trees yield a 2.4 BLEU increase when used in a downstream MT evaluation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9994194507598877}, {"text": "MT", "start_pos": 83, "end_pos": 85, "type": "TASK", "confidence": 0.9818838834762573}]}], "introductionContent": [{"text": "Methods for machine translation (MT) have increasingly leveraged not only the formal machinery of syntax (), but also linguistic tree structures of either the source side (), the target side (), or both ().", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.8615716218948364}]}, {"text": "These methods all rely on automatic parsing of one or both sides of input bitexts and are therefore impacted by parser quality.", "labels": [], "entities": []}, {"text": "Unfortunately, parsing general bitexts well can be a challenge for newswiretrained treebank parsers for many reasons, including out-of-domain input and tokenization issues.", "labels": [], "entities": [{"text": "parsing general bitexts", "start_pos": 15, "end_pos": 38, "type": "TASK", "confidence": 0.8784618775049845}]}, {"text": "On the other hand, the presence of translation pairs offers anew source of information: bilingual constraints.", "labels": [], "entities": []}, {"text": "For example, shows a case where a state-of-the-art English parser has chosen an incorrect structure which is incompatible with the (correctly chosen) output of a comparable Chinese parser.", "labels": [], "entities": []}, {"text": "previously showed that such bilingual constraints can be leveraged to transfer parse quality from a resource-rich language to a resourceimpoverished one.", "labels": [], "entities": []}, {"text": "In this paper, we show that bilingual constraints and reinforcement can be leveraged to substantially improve parses on both sides of a bitext, even for two resource-rich languages.", "labels": [], "entities": []}, {"text": "Formally, we present a log-linear model over triples of source trees, target trees, and node-tonode tree alignments between them.", "labels": [], "entities": []}, {"text": "We consider a set of core features which capture the scores of monolingual parsers as well as measures of syntactic alignment.", "labels": [], "entities": []}, {"text": "Our model conditions on the input sentence pair and so features can and do reference input characteristics such as posterior distributions from a word-level aligner (.", "labels": [], "entities": []}, {"text": "Our training data is the translated section of the Chinese treebank (), so at training time correct trees are observed on both the source and target side.", "labels": [], "entities": [{"text": "Chinese treebank", "start_pos": 51, "end_pos": 67, "type": "DATASET", "confidence": 0.9428193271160126}]}, {"text": "Gold tree alignments are not present and so are induced as latent variables using an iterative training procedure.", "labels": [], "entities": []}, {"text": "To make the process efficient and modular to existing monolingual parsers, we introduce several approximations: use of k-best lists in candidate generation, an adaptive bound to avoid considering all k 2 combinations, and Viterbi approximations to alignment posteriors.: Two possible parse pairs fora Chinese-English sentence pair.", "labels": [], "entities": []}, {"text": "The parses in a) are chosen by independent monolingual statistical parsers, but only the Chinese side is correct.", "labels": [], "entities": []}, {"text": "The gold English parse shown in b) is further down in the 100-best list, despite being more consistent with the gold Chinese parse.", "labels": [], "entities": []}, {"text": "The circles show where the two parses differ.", "labels": [], "entities": []}, {"text": "Note that in b), the ADVP and PP nodes correspond nicely to Chinese tree nodes, whereas the correspondence for nodes in a), particularly the SBAR node, is less clear.", "labels": [], "entities": []}, {"text": "We evaluate our system primarily as a parser and secondarily as a component in a machine translation pipeline.", "labels": [], "entities": [{"text": "machine translation pipeline", "start_pos": 81, "end_pos": 109, "type": "TASK", "confidence": 0.7629861334959666}]}, {"text": "For both English and Chinese, we begin with the state-of-the-art parsers presented in as a baseline.", "labels": [], "entities": []}, {"text": "Joint parse selection improves the English trees by 2.5 F 1 and the Chinese trees by 1.8 F 1 . While other Chinese treebank parsers do not have access to English side translations, this Chinese figure does outperform all published monolingual Chinese treebank results on an equivalent split of the data.", "labels": [], "entities": [{"text": "F", "start_pos": 56, "end_pos": 57, "type": "METRIC", "confidence": 0.9868090152740479}, {"text": "F", "start_pos": 89, "end_pos": 90, "type": "METRIC", "confidence": 0.9845055937767029}]}, {"text": "As MT motivates this work, another valuable evaluation is the effect of joint selection on downstream MT quality.", "labels": [], "entities": [{"text": "MT", "start_pos": 3, "end_pos": 5, "type": "TASK", "confidence": 0.984570324420929}, {"text": "MT", "start_pos": 102, "end_pos": 104, "type": "TASK", "confidence": 0.980279803276062}]}, {"text": "In an experiment using a syntactic MT system, we find that rules extracted from joint parses results in an increase of 2.4 BLEU points over rules extracted from independent parses.", "labels": [], "entities": [{"text": "MT", "start_pos": 35, "end_pos": 37, "type": "TASK", "confidence": 0.7698373198509216}, {"text": "BLEU", "start_pos": 123, "end_pos": 127, "type": "METRIC", "confidence": 0.9989325404167175}]}, {"text": "1 In sum, jointly parsing bitexts improves parses substantially, and does so in away that that carries all the way through the MT pipeline.", "labels": [], "entities": [{"text": "parsing bitexts", "start_pos": 18, "end_pos": 33, "type": "TASK", "confidence": 0.7943109571933746}, {"text": "MT pipeline", "start_pos": 127, "end_pos": 138, "type": "DATASET", "confidence": 0.6822435408830643}]}], "datasetContent": [{"text": "All the data used to train the joint parsing model and to evaluate parsing performance were taken from articles 1-325 of the Chinese treebank, which all have English translations with gold-standard parse trees.", "labels": [], "entities": [{"text": "parsing", "start_pos": 37, "end_pos": 44, "type": "TASK", "confidence": 0.6562957167625427}, {"text": "parsing", "start_pos": 67, "end_pos": 74, "type": "TASK", "confidence": 0.9649850130081177}, {"text": "Chinese treebank", "start_pos": 125, "end_pos": 141, "type": "DATASET", "confidence": 0.8908147215843201}]}, {"text": "The articles were split into training, development, and test sets according to the standard breakdown for Chinese parsing evaluations.", "labels": [], "entities": [{"text": "Chinese parsing evaluations", "start_pos": 106, "end_pos": 133, "type": "TASK", "confidence": 0.6277584830919901}]}, {"text": "Not all sentence pairs could be included for various reasons, including one-to-many Chinese-English sentence alignments, sentences omitted from the English translations, and low-fidelity translations.", "labels": [], "entities": [{"text": "Chinese-English sentence alignments", "start_pos": 84, "end_pos": 119, "type": "TASK", "confidence": 0.6703510085741679}]}, {"text": "Additional sentence pairs were dropped from the training data because they had unambiguous parses in at least one of the two languages.", "labels": [], "entities": []}, {"text": "shows how many sentences were included in each dataset.", "labels": [], "entities": []}, {"text": "We had two training setups: rapid and full.", "labels": [], "entities": [{"text": "rapid", "start_pos": 28, "end_pos": 33, "type": "METRIC", "confidence": 0.9792654514312744}]}, {"text": "In the rapid training setup, only 1000 sentence pairs from the training set were used, and we used fixed alignments for each tree pair rather than iterating (see \u00a74.1).", "labels": [], "entities": []}, {"text": "The full training setup used the iterative training procedure on all 2298 training sentence pairs.", "labels": [], "entities": []}, {"text": "We used the English and Chinese parsers in to generate all k-best lists and as our evaluation baseline.", "labels": [], "entities": []}, {"text": "Because our bilingual data is from the Chinese treebank, and the data typically used to train a Chinese parser contains the Chinese side of our bilingual training data, we had to train anew Chinese grammar using only articles 400-1151 (omitting articles 1-270).", "labels": [], "entities": [{"text": "Chinese treebank", "start_pos": 39, "end_pos": 55, "type": "DATASET", "confidence": 0.6990984529256821}]}, {"text": "This modified grammar was used to generate the k-best lists that we trained our model on.", "labels": [], "entities": []}, {"text": "However, as we tested on the same set of articles used for monolingual Chinese parser evaluation, there was no need to use a modified grammar to generate k-best lists attest time, and so we used a regularly trained Chinese parser for this purpose.", "labels": [], "entities": []}, {"text": "We also note that since all parsing evaluations were performed on Chinese treebank data, the Chinese test sentences were in-domain, whereas the English sentences were very far out-of-domain for the Penn Treebank-trained baseline English parser.", "labels": [], "entities": [{"text": "parsing", "start_pos": 28, "end_pos": 35, "type": "TASK", "confidence": 0.9633023142814636}, {"text": "Chinese treebank data", "start_pos": 66, "end_pos": 87, "type": "DATASET", "confidence": 0.7887681325276693}, {"text": "Penn Treebank-trained baseline English parser", "start_pos": 198, "end_pos": 243, "type": "DATASET", "confidence": 0.9576789259910583}]}, {"text": "Hence, in these evaluations, Chinese scores tend to be higher than English ones.", "labels": [], "entities": []}, {"text": "Posterior word alignment probabilities were obtained from the word aligner of and , trained on approximately 1.7 million sentence pairs.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.6355542540550232}]}, {"text": "For our alignment model we used an HMM in each direction, trained to agree (), and we combined the posteriors using soft union method.", "labels": [], "entities": []}, {"text": "Unless otherwise specified, the maximum value of k was set to 100 for both training and testing, and all experiments used a value of 25 as the parameter for training set pruning and a cutoff rank of 500 for test set pruning.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Sentence counts from bilingual Chinese tree- bank corpus.", "labels": [], "entities": [{"text": "bilingual Chinese tree- bank corpus", "start_pos": 31, "end_pos": 66, "type": "DATASET", "confidence": 0.7190440644820532}]}, {"text": " Table 2: Feature ablation study. F 1 on dev set after train- ing with individual feature groups removed. Performance  with individual baseline parsers included for reference.", "labels": [], "entities": [{"text": "F 1", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.9907486736774445}]}, {"text": " Table 3: Training set pruning study. F 1 on dev set after  training with different values of the parameter for train- ing set pruning.", "labels": [], "entities": [{"text": "F 1", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.9812657833099365}]}, {"text": " Table 4: Test set pruning study. F 1 on dev set obtained  using different cutoffs for test set pruning.", "labels": [], "entities": [{"text": "F 1", "start_pos": 34, "end_pos": 37, "type": "METRIC", "confidence": 0.983306884765625}]}, {"text": " Table 4.  For F 1 evaluation, which is on a very small set of  sentences, we selected 500 as the value with the best  speed/performance tradeoff. However, when rerank- ing our entire MT corpus, we used a value of 200,  sacrificing a tiny bit of performance for an extra fac- tor of 2 in speed. 8", "labels": [], "entities": [{"text": "MT corpus", "start_pos": 184, "end_pos": 193, "type": "DATASET", "confidence": 0.8456049263477325}]}, {"text": " Table 5: Sensitivity to k study. Joint parsing and oracle  F 1 obtained on dev set using different maximum values  of k when generating baseline k-best lists.", "labels": [], "entities": []}, {"text": " Table 6: Final evaluation. Comparison of F 1 on test set  between baseline parsers and joint parser.", "labels": [], "entities": [{"text": "F 1", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.9537241756916046}]}]}