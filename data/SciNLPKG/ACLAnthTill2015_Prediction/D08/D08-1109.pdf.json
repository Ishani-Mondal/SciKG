{"title": [{"text": "Unsupervised Multilingual Learning for POS Tagging", "labels": [], "entities": [{"text": "POS Tagging", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.8309000134468079}]}], "abstractContent": [{"text": "We demonstrate the effectiveness of multilingual learning for unsupervised part-of-speech tagging.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 75, "end_pos": 97, "type": "TASK", "confidence": 0.7026724517345428}]}, {"text": "The key hypothesis of multilingual learning is that by combining cues from multiple languages, the structure of each becomes more apparent.", "labels": [], "entities": []}, {"text": "We formulate a hierarchical Bayesian model for jointly predicting bilingual streams of part-of-speech tags.", "labels": [], "entities": []}, {"text": "The model learns language-specific features while capturing cross-lingual patterns in tag distribution for aligned words.", "labels": [], "entities": []}, {"text": "Once the parameters of our model have been learned on bilingual parallel data, we evaluate its performance on a held-out monolingual test set.", "labels": [], "entities": []}, {"text": "Our evaluation on six pairs of languages shows consistent and significant performance gains over a state-of-the-art monolingual baseline.", "labels": [], "entities": []}, {"text": "For one language pair, we observe a relative reduction in error of 53%.", "labels": [], "entities": [{"text": "relative reduction in error", "start_pos": 36, "end_pos": 63, "type": "METRIC", "confidence": 0.7564709484577179}]}], "introductionContent": [{"text": "In this paper, we explore the application of multilingual learning to part-of-speech tagging when no annotation is available.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 70, "end_pos": 92, "type": "TASK", "confidence": 0.7363055944442749}]}, {"text": "This core task has been studied in an unsupervised monolingual framework for over a decade and is still an active area of research.", "labels": [], "entities": []}, {"text": "In this paper, we demonstrate the effectiveness of multilingual learning when applied to both closely related and distantly related language pairs.", "labels": [], "entities": []}, {"text": "We further analyze the language features which lead to robust bilingual performance.", "labels": [], "entities": []}, {"text": "The fundamental idea upon which our work is based is that the patterns of ambiguity inherent in part-of-speech tag assignments differ across languages.", "labels": [], "entities": []}, {"text": "At the lexical level, a word with part-ofspeech tag ambiguity in one language may correspond to an unambiguous word in the other language.", "labels": [], "entities": []}, {"text": "For example, the word \"can\" in English may function as an auxiliary verb, a noun, or a regular verb.", "labels": [], "entities": []}, {"text": "However, each of the corresponding functions in Serbian is expressed with a distinct lexical item.", "labels": [], "entities": []}, {"text": "Languages also differ in their patterns of structural ambiguity.", "labels": [], "entities": []}, {"text": "For example, the presence of an article in English greatly reduces the ambiguity of the succeeding tag.", "labels": [], "entities": []}, {"text": "In Serbian, a language without articles, this constraint is obviously absent.", "labels": [], "entities": []}, {"text": "The key idea of multilingual learning is that by combining cues from multiple languages, the structure of each becomes more apparent.", "labels": [], "entities": []}, {"text": "While multilingual learning can address ambiguities in each language, it must be flexible enough to accommodate cross-lingual variations such as tag inventory and syntactic structure.", "labels": [], "entities": []}, {"text": "As a result of such variations, two languages often select and order their tags differently even when expressing the same meaning.", "labels": [], "entities": []}, {"text": "A key challenge of multilingual learning is to model language-specific structure while allowing information to flow between languages.", "labels": [], "entities": []}, {"text": "We jointly model bilingual part-of-speech tag sequences in a hierarchical Bayesian framework.", "labels": [], "entities": []}, {"text": "For each word, we posit a hidden tag state which generates the word as well as the succeeding tag.", "labels": [], "entities": []}, {"text": "In addition, the tags of words with common semantic or syntactic function in parallel sentences are combined into bilingual nodes representing the tag pair.", "labels": [], "entities": []}, {"text": "These joined nodes serve as anchors that create probabilistic dependencies between the tag se-quences in each language.", "labels": [], "entities": []}, {"text": "We use standard tools from machine translation to discover aligned wordpairs, and thereafter our model treats the alignments as observed data.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.6989930719137192}]}, {"text": "Our model structure allows language-specific tag inventories.", "labels": [], "entities": []}, {"text": "Additionally, it assumes only that the tags at joined nodes are correlated; they need not be identical.", "labels": [], "entities": []}, {"text": "We factor the conditional probabilities of joined nodes into two individual transition probabilities as well as a coupling probability.", "labels": [], "entities": []}, {"text": "We define priors over the transition, emission, and coupling parameters and perform Bayesian inference using Gibbs sampling and the Metropolis-Hastings algorithm.", "labels": [], "entities": []}, {"text": "We evaluate our model on a parallel corpus of four languages: English, Bulgarian, Serbian, and Slovene.", "labels": [], "entities": []}, {"text": "For each of the six language pairs, we train a bilingual model on this corpus, and evaluate it on held-out monolingual test sets.", "labels": [], "entities": []}, {"text": "Our results show consistent improvement over a monolingual baseline for all languages and all pairings.", "labels": [], "entities": []}, {"text": "In fact, for one language pair -Serbian and Slovene -the error is reduced by over 53%.", "labels": [], "entities": [{"text": "error", "start_pos": 57, "end_pos": 62, "type": "METRIC", "confidence": 0.9978038668632507}]}, {"text": "Moreover, the multilingual model significantly reduces the gap between unsupervised and supervised performance.", "labels": [], "entities": []}, {"text": "For instance, in the case of Slovene this gap is reduced by 71%.", "labels": [], "entities": []}, {"text": "We also observe significant variation in the level of improvement across language pairs.", "labels": [], "entities": []}, {"text": "We show that a cross-lingual entropy measure corresponds with the observed differentials in performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our evaluation framework follows the standard procedures established for unsupervised part-of-speech tagging.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 86, "end_pos": 108, "type": "TASK", "confidence": 0.7244565784931183}]}, {"text": "Given a tag dictionary (i.e., a set of possible tags for each word type), the model has to select the appropriate tag for each token occurring in a text.", "labels": [], "entities": []}, {"text": "We also evaluate tagger performance when only incomplete dictionaries are available.", "labels": [], "entities": [{"text": "tagger", "start_pos": 17, "end_pos": 23, "type": "TASK", "confidence": 0.9704750776290894}]}, {"text": "In both scenarios, the model is trained only using untagged text.", "labels": [], "entities": []}, {"text": "In this section, we first describe the parallel data and part-of-speech annotations used for system evaluation.", "labels": [], "entities": []}, {"text": "Next we describe a monolingual baseline and our procedures for initialization and hyperparameter setting.", "labels": [], "entities": [{"text": "initialization", "start_pos": 63, "end_pos": 77, "type": "TASK", "confidence": 0.9623305797576904}]}, {"text": "Data As a source of parallel data, we use Orwell's novel \"Nineteen Eighty Four\" in the original English as well as translations to three Slavic languagesBulgarian, Serbian and Slovene.", "labels": [], "entities": [{"text": "Orwell's novel \"Nineteen Eighty Four\"", "start_pos": 42, "end_pos": 79, "type": "DATASET", "confidence": 0.851298913359642}]}, {"text": "This data is distributed as part of the Multext-East corpus which is publicly available.", "labels": [], "entities": [{"text": "Multext-East corpus", "start_pos": 40, "end_pos": 59, "type": "DATASET", "confidence": 0.9812145531177521}]}, {"text": "The corpus provides detailed morphological annotation at the world level, including part-of-speech tags.", "labels": [], "entities": []}, {"text": "In addition a lexicon for each language is provided.", "labels": [], "entities": []}, {"text": "We obtain six parallel corpora by considering all pairings of the four languages.", "labels": [], "entities": []}, {"text": "We compute word level alignments for each language pair using Giza++.", "labels": [], "entities": [{"text": "word level alignments", "start_pos": 11, "end_pos": 32, "type": "TASK", "confidence": 0.6193182865778605}]}, {"text": "To generate one-to-one alignments at the word level, we intersect the one-to-many alignments going in each direction and automatically remove crossing edges in the order in which they appear left to right.", "labels": [], "entities": []}, {"text": "This process results in alignment of about half the tokens in each bilingual parallel corpus.", "labels": [], "entities": []}, {"text": "We treat the alignments as fixed and observed variables throughout the training procedure.", "labels": [], "entities": []}, {"text": "The corpus consists of 94,725 English words (see).", "labels": [], "entities": []}, {"text": "For every language, a random three quarters of the data are used for learning the model while the remaining quarter is used for testing.", "labels": [], "entities": []}, {"text": "In the test set, only monolingual information is made available to the model, in order to simulate future performance on non-parallel data.) as well as a supervised HMM.", "labels": [], "entities": []}, {"text": "In addition, the trigram part-of-speech tag entropy is given for each language.", "labels": [], "entities": []}, {"text": "In the Multext-East corpus, punctuation marks are not annotated.", "labels": [], "entities": [{"text": "Multext-East corpus", "start_pos": 7, "end_pos": 26, "type": "DATASET", "confidence": 0.9743491411209106}]}, {"text": "We expand the tag repository by defining a separate tag for all punctuation marks.", "labels": [], "entities": []}, {"text": "This allows the model to make use of any transition or coupling patterns involving punctuation marks.", "labels": [], "entities": []}, {"text": "We do not consider punctuation tokens when computing model accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9712648987770081}]}, {"text": "shows the tag/token ratio for these languages.", "labels": [], "entities": []}, {"text": "For Slavic languages, we use the tag dictionaries provided with the corpus.", "labels": [], "entities": []}, {"text": "For English, we use a different process for dictionary construction.", "labels": [], "entities": [{"text": "dictionary construction", "start_pos": 44, "end_pos": 67, "type": "TASK", "confidence": 0.8564406037330627}]}, {"text": "Using the original dictionary would result in the tag/token ratio of 1.5, in comparison to the ratio of 2.3 observed in the Wall Street Journal (WSJ) corpus.", "labels": [], "entities": [{"text": "Wall Street Journal (WSJ) corpus", "start_pos": 124, "end_pos": 156, "type": "DATASET", "confidence": 0.921391453061785}]}, {"text": "To make our results on English tagging more comparable to previous benchmarks, we expand the original dictionary of English tags by merging it with the tags from the WSJ dictionary.", "labels": [], "entities": [{"text": "English tagging", "start_pos": 23, "end_pos": 38, "type": "TASK", "confidence": 0.7250403165817261}, {"text": "WSJ dictionary", "start_pos": 166, "end_pos": 180, "type": "DATASET", "confidence": 0.9714843928813934}]}, {"text": "This process results in a tag/token ratio of 2.58, yielding a slightly more ambiguous dictionary than the one used in previous tagging work.", "labels": [], "entities": []}, {"text": "Monolingual Baseline As our monolingual baseline we use the unsupervised Bayesian HMM model of.", "labels": [], "entities": []}, {"text": "This model modifies the standard HMM by adding priors and by performing Bayesian inference.", "labels": [], "entities": []}, {"text": "Its is inline with state-of-the-art unsupervised models.", "labels": [], "entities": []}, {"text": "This model is a particulary informative baseline, since our model reduces to this baseline model when there are no alignments in the data.", "labels": [], "entities": []}, {"text": "This implies that any performance gain over the baseline can only be at- The remaining two tags are Particle and Determiner; The English tagset does not include Particle while the other three languages Serbian, Slovene and Bulgarian do not have Determiner in their tagset.", "labels": [], "entities": [{"text": "Determiner", "start_pos": 113, "end_pos": 123, "type": "METRIC", "confidence": 0.946113646030426}]}, {"text": "We couldn't perform the same dictionary expansion for the Slavic languages due to alack of additional annotated resources.", "labels": [], "entities": []}, {"text": "tributed to the multilingual aspect of our model.", "labels": [], "entities": []}, {"text": "We used our own implementation after verifying that its performance on WSJ was identical to that reported in).", "labels": [], "entities": [{"text": "WSJ", "start_pos": 71, "end_pos": 74, "type": "DATASET", "confidence": 0.9340972304344177}]}, {"text": "Supervised Performance In order to provide a point of comparison, we also provide supervised results when an annotated corpus is provided.", "labels": [], "entities": []}, {"text": "We use the standard supervised HMM with Viterbi decoding.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Corpus statistics: SR=Serbian, SL=Slovene,  EN=English, BG=Bulgarian", "labels": [], "entities": [{"text": "BG", "start_pos": 66, "end_pos": 68, "type": "METRIC", "confidence": 0.9748552441596985}]}, {"text": " Table 1: Monolingual tagging accuracy for English, Bulgarian, Slovene, and Serbian for two unsupervised baselines  (random tag selection and a Bayesian HMM (", "labels": [], "entities": [{"text": "Monolingual tagging", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.5658136010169983}, {"text": "accuracy", "start_pos": 30, "end_pos": 38, "type": "METRIC", "confidence": 0.9799023866653442}]}, {"text": " Table 3: The tagging accuracy of our bilingual models  on different language pairs, when a full tag dictionary is  provided. The Monolingual Unsupervised results from  Table 1 are repeated for easy comparison. The first col- umn shows the cross-lingual entropy of a tag when the  tag of the aligned word in the other language is known.  The final column shows the absolute improvement over  the monolingual Bayesian HMM. The best result for each  language is shown in boldface.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9825116991996765}]}, {"text": " Table 4: Tagging accuracy for Bilingual models with re- duced dictionary: Lexicon entries are available for only  the 100 most frequent words, while all other words be- come fully ambiguous. The improvement over the mono- lingual Bayesian HMM trained under similar circum- stances is shown. The best result for each language is  shown in boldface.", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9588828086853027}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9735740423202515}]}]}