{"title": [{"text": "An Analysis of Active Learning Strategies for Sequence Labeling Tasks", "labels": [], "entities": [{"text": "Sequence Labeling Tasks", "start_pos": 46, "end_pos": 69, "type": "TASK", "confidence": 0.9329012831052145}]}], "abstractContent": [{"text": "Active learning is well-suited to many problems in natural language processing, where unlabeled data maybe abundant but annotation is slow and expensive.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 51, "end_pos": 78, "type": "TASK", "confidence": 0.6599509119987488}]}, {"text": "This paper aims to shed light on the best active learning approaches for sequence labeling tasks such as information extraction and document segmen-tation.", "labels": [], "entities": [{"text": "sequence labeling tasks", "start_pos": 73, "end_pos": 96, "type": "TASK", "confidence": 0.7354349990685781}, {"text": "information extraction", "start_pos": 105, "end_pos": 127, "type": "TASK", "confidence": 0.8035126030445099}]}, {"text": "We survey previously used query selection strategies for sequence models, and propose several novel algorithms to address their shortcomings.", "labels": [], "entities": []}, {"text": "We also conduct a large-scale empirical comparison using multiple corpora, which demonstrates that our proposed methods advance the state of the art.", "labels": [], "entities": []}], "introductionContent": [{"text": "Traditional supervised learning algorithms use whatever labeled data is provided to induce a model.", "labels": [], "entities": []}, {"text": "By contrast, active learning gives the learner a degree of control by allowing it to select which instances are labeled and added to the training set.", "labels": [], "entities": []}, {"text": "A typical active learner begins with a small labeled set L, selects one or more informative query instances from a large unlabeled pool U, learns from these labeled queries (which are then added to L), and repeats.", "labels": [], "entities": []}, {"text": "In this way, the learner aims to achieve high accuracy with as little labeling effort as possible.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9973234534263611}]}, {"text": "Thus, active learning can be valuable in domains where unlabeled data are readily available, but obtaining training labels is expensive.", "labels": [], "entities": []}, {"text": "Such is the case with many sequence labeling tasks in natural language domains.", "labels": [], "entities": [{"text": "sequence labeling tasks", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.7570699254671732}]}, {"text": "For example, part-of-speech tagging (), information extraction (;), and document segmentation () are all typically treated as sequence labeling problems.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.7763911187648773}, {"text": "information extraction", "start_pos": 40, "end_pos": 62, "type": "TASK", "confidence": 0.8374138474464417}, {"text": "document segmentation", "start_pos": 72, "end_pos": 93, "type": "TASK", "confidence": 0.7347671240568161}]}, {"text": "The source data for these tasks (i.e., text documents in electronic form) are often easily obtained.", "labels": [], "entities": []}, {"text": "However, due to the nature of sequence labeling tasks, annotating these texts can be rather tedious and time-consuming, making active learning an attractive technique.", "labels": [], "entities": [{"text": "sequence labeling tasks", "start_pos": 30, "end_pos": 53, "type": "TASK", "confidence": 0.7471997837225596}]}, {"text": "While there has been much work on active learning for classification, active learning for sequence labeling has received considerably less attention.", "labels": [], "entities": [{"text": "classification", "start_pos": 54, "end_pos": 68, "type": "TASK", "confidence": 0.9684857130050659}, {"text": "sequence labeling", "start_pos": 90, "end_pos": 107, "type": "TASK", "confidence": 0.5910216271877289}]}, {"text": "A few methods have been proposed, based mostly on the conventions of uncertainty sampling, where the learner queries the instance about which it has the least certainty (), or query-by-committee, where a \"committee\" of models selects the instance about which its members most disagree.", "labels": [], "entities": []}, {"text": "We provide more detail on these and the new strategies we propose in Section 3.", "labels": [], "entities": []}, {"text": "The comparative effectiveness of these approaches, however, has not been studied.", "labels": [], "entities": []}, {"text": "Furthermore, it has been suggested that uncertainty sampling and query-by-committee fail on occasion;) by querying outliers, e.g., instances considered informative in isolation by the learner, but containing little information about the rest of the distribution of instances.", "labels": [], "entities": [{"text": "uncertainty sampling", "start_pos": 40, "end_pos": 60, "type": "TASK", "confidence": 0.7460014224052429}]}, {"text": "Proposed methods for dealing with these shortcomings have so far only considered classification tasks.", "labels": [], "entities": [{"text": "classification tasks", "start_pos": 81, "end_pos": 101, "type": "TASK", "confidence": 0.9041814804077148}]}, {"text": "This paper presents two major contributions for active learning and sequence labeling tasks.", "labels": [], "entities": [{"text": "sequence labeling tasks", "start_pos": 68, "end_pos": 91, "type": "TASK", "confidence": 0.7718858520189921}]}, {"text": "First, we motivate and introduce several new query strategies for probabilistic sequence models.", "labels": [], "entities": []}, {"text": "Second, we conduct a thorough empirical analysis of previously proposed methods with our algorithms on a variety of benchmark corpora.", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 provides a brief introduction to sequence labeling and conditional random fields (the sequence model used in our experiments).", "labels": [], "entities": [{"text": "sequence labeling", "start_pos": 43, "end_pos": 60, "type": "TASK", "confidence": 0.7734377086162567}]}, {"text": "Section 3 describes in detail all the query selection strategies we consider.", "labels": [], "entities": [{"text": "query selection", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.7705941796302795}]}, {"text": "Section 4 presents the results of our empirical study.", "labels": [], "entities": []}, {"text": "Section 5 concludes with a summary of our findings.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present a large-scale empirical analysis of the query strategies described in Section 3 on eight benchmark information extraction and document segmentation corpora.", "labels": [], "entities": [{"text": "benchmark information extraction and document segmentation corpora", "start_pos": 116, "end_pos": 182, "type": "TASK", "confidence": 0.6721875497273037}]}, {"text": "The data sets are summarized in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Properties of the different evaluation corpora.", "labels": [], "entities": []}, {"text": " Table 2: Detailed results for all query strategies on all evaluation corpora. Reported is the area under the F 1 learning  curve for each strategy after 150 queries (maximum possible score is 150). For each row, the best method is shown  boxed in bold, the second best is shown underlined in bold, and the third best is shown in bold. The last row summa- rizes the results across all eight tasks by reporting the average area for each strategy. Query strategy formulations for  sequence models introduced in this paper are indicated with italics along the top.", "labels": [], "entities": [{"text": "F 1 learning  curve", "start_pos": 110, "end_pos": 129, "type": "METRIC", "confidence": 0.8898283839225769}]}]}