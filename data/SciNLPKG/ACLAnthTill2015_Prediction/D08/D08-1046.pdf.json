{"title": [{"text": "Legal Docket-Entry Classification: Where Machine Learning stumbles", "labels": [], "entities": [{"text": "Legal Docket-Entry Classification", "start_pos": 0, "end_pos": 33, "type": "DATASET", "confidence": 0.9425346453984579}]}], "abstractContent": [{"text": "We investigate the problem of binary text classification in the domain of legal docket entries.", "labels": [], "entities": [{"text": "binary text classification", "start_pos": 30, "end_pos": 56, "type": "TASK", "confidence": 0.7019823590914408}]}, {"text": "This work presents an illustrative instance of a domain-specific problem where the state-of-the-art Machine Learning (ML) classifiers such as SVMs are inadequate.", "labels": [], "entities": []}, {"text": "Our investigation into the reasons for the failure of these classifiers revealed two types of prominent errors which we call conjunctive and disjunctive errors.", "labels": [], "entities": []}, {"text": "We developed simple heuristics to address one of these error types and improve the performance of the SVMs.", "labels": [], "entities": []}, {"text": "Based on the intuition gained from our experiments, we also developed a simple propositional logic based classifier using hand-labeled features, that addresses both types of errors simultaneously.", "labels": [], "entities": []}, {"text": "We show that this new, but simple, approach outperforms all existing state-of-the-art ML models, with statistically significant gains.", "labels": [], "entities": [{"text": "ML", "start_pos": 86, "end_pos": 88, "type": "TASK", "confidence": 0.9668534398078918}]}, {"text": "We hope this work serves as a motivating example of the need to build more expressive classifiers beyond the standard model classes, and to address text classification problems in such non-traditional domains.", "labels": [], "entities": [{"text": "text classification", "start_pos": 148, "end_pos": 167, "type": "TASK", "confidence": 0.7349864840507507}]}], "introductionContent": [{"text": "Text Classification is a widely researched area, with publications spanning more than a decade.", "labels": [], "entities": [{"text": "Text Classification", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7101374864578247}]}, {"text": "Although earlier models used logic based rules and decision trees (, recently the emphasis has been on statistical classifiers such as the naive Bayes model, logistic regression) and support vector machines.", "labels": [], "entities": []}, {"text": "Although several complex features were considered for classification, eventually researchers have settled down to simple bag-of-words features such as unigrams and some times bigrams (), thereby completely ignoring the grammar and other semantic information in the text.", "labels": [], "entities": []}, {"text": "Despite this fact, the stateof-the-art performance is close to or above 90% on F1 scores on most standard test collections such as.", "labels": [], "entities": [{"text": "F1", "start_pos": 79, "end_pos": 81, "type": "METRIC", "confidence": 0.9992409944534302}]}, {"text": "As such, most researchers and practitioners believe text classification technology has reached a mature state, where it is suitable for deployment in real life applications.", "labels": [], "entities": [{"text": "text classification", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.8713269233703613}]}, {"text": "In this work, we present a text classification problem from the legal domain which challenges some of our understanding of text classification problems.", "labels": [], "entities": [{"text": "text classification", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.8363901972770691}, {"text": "text classification", "start_pos": 123, "end_pos": 142, "type": "TASK", "confidence": 0.7779370546340942}]}, {"text": "In the new domain, we found that the standard ML approaches using bag-of-words features perform relatively poorly.", "labels": [], "entities": [{"text": "ML", "start_pos": 46, "end_pos": 48, "type": "TASK", "confidence": 0.9688093066215515}]}, {"text": "Not only that, we noticed that the linear form (or even polynomial form) used by these classifiers is inadequate to capture the semantics of the text.", "labels": [], "entities": []}, {"text": "Our investigation into the shortcomings of the traditional models such as SVMs, lead us to build a simple propositional logic based classifier using hand-labeled features that outperforms these strong baselines.", "labels": [], "entities": []}, {"text": "Although the new model by itself is interesting, the main objective of our work is to present the text classification community with an interesting problem where the current models are found inadequate.", "labels": [], "entities": [{"text": "text classification community", "start_pos": 98, "end_pos": 127, "type": "TASK", "confidence": 0.8309803207715353}]}, {"text": "Our hope is that the new problem will encourage researchers to continue to build more sophisticated models to solve classification problems in diverse, non-traditional domains.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2, we introduce the problem of legal docket entry classification and describe the data with some representative examples.", "labels": [], "entities": [{"text": "legal docket entry classification", "start_pos": 42, "end_pos": 75, "type": "TASK", "confidence": 0.7416950166225433}]}, {"text": "In section 3, we describe the experiments performed with SVMs and several of its variants.", "labels": [], "entities": []}, {"text": "We also identify the shortcomings of the current classifiers in this section.", "labels": [], "entities": []}, {"text": "In section 3.2, we present results from using human selected features for the classification problem and motivate their application for the docket entry classification using propositional logic in subsection 3.3.", "labels": [], "entities": []}, {"text": "We also show that simple propositional logic using human selected features and their labels outperforms the state-of-the-art classifiers.", "labels": [], "entities": []}, {"text": "We conclude the discussion in section 4, where we argue the case for more sophisticated classifiers for specialized domains.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: An example (incomplete) docket: each row in the table corresponds to a docket-entry", "labels": [], "entities": []}, {"text": " Table 2: Order: re Summary Judgment: positive and negative docket entries. The entries are reproduced as they are.", "labels": [], "entities": [{"text": "Summary Judgment", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.7021593153476715}]}, {"text": " Table 5: Results for 'Order re: Summary Judgment': FS100 indicates that only top 100 features were selected using  Information Gain metric; HF stands for human built features, sentNgrams refers to the case where all the human-built  features in a given sentence were merged to form an n-gram feature. A '*' next to F1 value indicates statistically  significant result compared to its closest lower value, measured using a paired 2-tailed T-test, at 95% confidence level.  The highest numbers in each column are highlighted using boldface.", "labels": [], "entities": [{"text": "FS100", "start_pos": 52, "end_pos": 57, "type": "METRIC", "confidence": 0.8838210701942444}, {"text": "F1", "start_pos": 316, "end_pos": 318, "type": "METRIC", "confidence": 0.9965090155601501}]}]}