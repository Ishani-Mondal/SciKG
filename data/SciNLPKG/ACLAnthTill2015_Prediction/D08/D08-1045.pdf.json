{"title": [{"text": "Online Acquisition of Japanese Unknown Morphemes using Morphological Constraints", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a novel lexicon acquirer that works in concert with the morphological ana-lyzer and has the ability to run in online mode.", "labels": [], "entities": []}, {"text": "Every time a sentence is analyzed, it detects unknown morphemes, enumerates candidates and selects the best candidates by comparing multiple examples kept in the storage.", "labels": [], "entities": []}, {"text": "When a morpheme is unambiguously selected, the lexicon acquirer updates the dictionary of the analyzer, and it will be used in subsequent analysis.", "labels": [], "entities": []}, {"text": "We use the constraints of Japanese morphology and effectively reduce the number of examples required to acquire a morpheme.", "labels": [], "entities": []}, {"text": "Experiments show that unknown morphemes were acquired with high accuracy and improved the quality of morphological analysis .", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9986623525619507}]}], "introductionContent": [{"text": "Morphological analysis is the first step for most natural language processing applications.", "labels": [], "entities": [{"text": "Morphological analysis", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9517283737659454}]}, {"text": "In Japanese morphological analysis, segmentation is processed simultaneously with the assignment of apart of speech (POS) tag to each morpheme.", "labels": [], "entities": [{"text": "Japanese morphological analysis", "start_pos": 3, "end_pos": 34, "type": "TASK", "confidence": 0.6729963223139445}]}, {"text": "Segmentation is a nontrivial task in Japanese because it does not delimit words by white-space.", "labels": [], "entities": [{"text": "Segmentation", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.9600629806518555}]}, {"text": "Japanese morphological analysis has successfully adopted dictionary-based approaches ().", "labels": [], "entities": [{"text": "Japanese morphological analysis", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.6642282605171204}]}, {"text": "In these approaches, a sentence is transformed into a lattice of morphemes by searching a pre-defined dictionary, and an optimal path in the lattice is selected.", "labels": [], "entities": []}, {"text": "This area of research maybe considered almost completed, as previous studies reported the F-score of nearly 99% ().", "labels": [], "entities": [{"text": "F-score", "start_pos": 90, "end_pos": 97, "type": "METRIC", "confidence": 0.9996740818023682}]}, {"text": "When applied to web texts, however, more errors are made due to unknown morphemes.", "labels": [], "entities": []}, {"text": "In previous studies, experiments were performed on newspaper articles, but web texts include slang words, informal spelling alternates and technical terms.", "labels": [], "entities": []}, {"text": "For example, the verb \"\ud97b\udf59\ud97b\udf59\ud97b\udf59\" (gugu-ru, to google) is erroneously segmented into \"\ud97b\udf59\ud97b\udf59\" (gugu) and \"\ud97b\udf59\" (ru).", "labels": [], "entities": []}, {"text": "One solution to this problem is to augment the lexicon of the morphological analyzer by extracting unknown morphemes from texts.", "labels": [], "entities": []}, {"text": "In the previous method, a morpheme extraction module worked independently of the morphological analyzer and ran in off-line (batch) mode.", "labels": [], "entities": [{"text": "morpheme extraction", "start_pos": 26, "end_pos": 45, "type": "TASK", "confidence": 0.7791042625904083}]}, {"text": "It is inefficient because almost all high-frequency morphemes have already been registered to the predefined dictionary.", "labels": [], "entities": []}, {"text": "Moreover, it is inconvenient when applied to web texts because the web corpus is huge and diverse compared to newspaper corpora.", "labels": [], "entities": []}, {"text": "It is not necessarily easy to build subcorpora before lexicon acquisition.", "labels": [], "entities": []}, {"text": "Suppose that we want to analyze whaling-related documents.", "labels": [], "entities": []}, {"text": "It is unnecessary and probably harmful to acquire morphemes that are irrelevant to the topic.", "labels": [], "entities": []}, {"text": "A whaling-related subcorpus should be extracted from the whole corpus but it is not clear how large it must be.", "labels": [], "entities": []}, {"text": "We propose a novel lexicon acquirer that works in concert with the morphological analyzer and has the ability to run in online mode.", "labels": [], "entities": []}, {"text": "As shown in candidates and selects the best candidates by comparing multiple examples kept in the storage.", "labels": [], "entities": []}, {"text": "When a morpheme is unambiguously selected, the lexicon acquirer updates the automatically constructed dictionary, and it will be used in subsequent analysis.", "labels": [], "entities": []}, {"text": "The proposed method is flexible and gives the system more control over the process.", "labels": [], "entities": []}, {"text": "We do not have to limit the target corpus beforehand and the system can stop whenever appropriate.", "labels": [], "entities": []}, {"text": "We use the constraints of Japanese morphology that have already been coded in the morphological analyzer.", "labels": [], "entities": []}, {"text": "These constraints effectively reduce the number of examples required to acquire an unknown morpheme.", "labels": [], "entities": []}, {"text": "Experiments show that unknown morphemes were acquired with high accuracy and improved the quality of morphological analysis.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9986623525619507}]}], "datasetContent": [{"text": "We used the default dictionary of the morphological analyzer JUMAN as the initial lexicon.", "labels": [], "entities": [{"text": "JUMAN", "start_pos": 61, "end_pos": 66, "type": "DATASET", "confidence": 0.726798415184021}]}, {"text": "It contained 30 thousand basic morphemes.", "labels": [], "entities": []}, {"text": "If spelling variants were expanded and proper nouns were counted, the total number of morphemes was 120 thousands.", "labels": [], "entities": []}, {"text": "We used domain-specific corpora as target texts because efficient acquisition was expected.", "labels": [], "entities": []}, {"text": "If target texts shared a topic, relevant unknown morphemes were used frequently.", "labels": [], "entities": []}, {"text": "In the experiments, we used search engine TSUBAKI ( and casted the search results as domain-specific corpora.", "labels": [], "entities": [{"text": "TSUBAKI", "start_pos": 42, "end_pos": 49, "type": "METRIC", "confidence": 0.6957690119743347}]}, {"text": "For each query, our system sequentially read pages from the top of the result and acquired morphemes.", "labels": [], "entities": []}, {"text": "We terminated the acquisition at the 1000th page and analyzed the same 1000 pages with the augmented lexicon.", "labels": [], "entities": []}, {"text": "The queries used were \"\ud97b\udf59\ud97b\udf59\ud97b\udf59 \ud97b\udf59\" (whaling issue), \"\" (baby hatch), \"\" (JASRAC, a copyright collective), \"\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\" (tsundere, a slang word) and \"\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59 \ud97b\udf59\" (agaricus).", "labels": [], "entities": [{"text": "JASRAC, a copyright collective)", "start_pos": 68, "end_pos": 99, "type": "DATASET", "confidence": 0.7650144894917806}]}, {"text": "The proposed method is evaluated by measuring the accuracy of acquired morphemes and their contribution to the improvement of morphological analysis.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.9991982579231262}]}, {"text": "A morpheme is considered accurate if both segmentation and the POS tag are correct.", "labels": [], "entities": [{"text": "accurate", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9638544321060181}]}, {"text": "Note that segmentation is a nontrivial problem for evaluation.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.9771214127540588}]}, {"text": "In fact, the disagreement over segmentation criteria was considered one of the main reasons for reported errors by Nagata (1999) and.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 31, "end_pos": 43, "type": "TASK", "confidence": 0.9817491769790649}]}, {"text": "It is difficult to judge whether a compound term should be divided because there is no definite standard for morpheme boundaries in Japanese.", "labels": [], "entities": []}, {"text": "For example, \"\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\" (minku-kujira, minke whale) can be extracted as a single morpheme or decomposed into \"\ud97b\udf59\ud97b\udf59\ud97b\udf59\" and \"\ud97b\udf59.\"", "labels": [], "entities": []}, {"text": "While segmentation is an open question in Japanese morphological analysis, \"correct\" segmentation is not necessarily important for applications using morphological analysis.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 6, "end_pos": 18, "type": "TASK", "confidence": 0.9654780030250549}, {"text": "Japanese morphological analysis", "start_pos": 42, "end_pos": 73, "type": "TASK", "confidence": 0.6029777129491171}]}, {"text": "Even if a noun is split into two or more morphemes in morphological analysis, they are chunked to form a phrasal unit called bunsetsu in dependency parsing, and to extract a keyword ().", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 137, "end_pos": 155, "type": "TASK", "confidence": 0.7534765899181366}]}, {"text": "To avoid the decompositionality problem, we adopted manual evaluation.", "labels": [], "entities": [{"text": "decompositionality", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.9542644023895264}]}, {"text": "We analyzed the target texts with both the initial lexicon and the augmented lexicon.", "labels": [], "entities": []}, {"text": "Then we checked differences between the two analyses and extracted sentences that were affected by the augmentation.", "labels": [], "entities": []}, {"text": "Among these sentences, we evaluated randomly selected 50 sentences per query.", "labels": [], "entities": []}, {"text": "We checked the accuracy of segmentation and POS tagging of each \"diff\" block, which is illustrated in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.9996546506881714}, {"text": "segmentation", "start_pos": 27, "end_pos": 39, "type": "TASK", "confidence": 0.9717490077018738}, {"text": "POS tagging", "start_pos": 44, "end_pos": 55, "type": "TASK", "confidence": 0.8275969326496124}]}, {"text": "The segmentation of a block was judged correct unless morpheme boundaries were clearly wrong.", "labels": [], "entities": []}, {"text": "In the evaluation of POS tagging, we did not distinguish subclasses of noun 3 such as common noun: Examples of acquired morphemes query examples whaling issue \ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59 (moratorium), \ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59\ud97b\udf59 (giant beaked whale), \ud97b\udf59\ud97b\udf59 (bycatch) baby hatch \ud97b\udf59\ud97b\udf59\ud97b\udf59 (husband), \ud97b\udf59\ud97b\udf59\ud97b\udf59 (midwife), \ud97b\udf59\ud97b\udf59\ud97b\udf59 (to abandon), \ud97b\udf59\ud97b\udf59 (to inquire) JASRAC \ud97b\udf59\ud97b\udf59\ud97b\udf59 (an organization), \ud97b\udf59\ud97b\udf59\ud97b\udf59 Q (a pop-rock band), \ud97b\udf59\ud97b\udf59 (geek) tsundere \ud97b\udf59\ud97b\udf59\ud97b\udf59 (abbr. of Akihabara), \ud97b\udf59\ud97b\udf59\ud97b\udf59 (fujoshi, a slang word), \ud97b\udf59\ud97b\udf59\ud97b\udf59 (to be popular) agaricus \ud97b\udf59\ud97b\udf59\ud97b\udf59 (abbr. of suppliment), \ud97b\udf59\ud97b\udf59\ud97b\udf59 (aroma), \ud97b\udf59\ud97b\udf59 (enhanced nutritional function): A \"diff\" block in a sentence and proper noun.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 21, "end_pos": 32, "type": "TASK", "confidence": 0.8499205410480499}]}, {"text": "The special POS tag \"undefined\" given by JUMAN was treated as noun.", "labels": [], "entities": [{"text": "JUMAN", "start_pos": 41, "end_pos": 46, "type": "DATASET", "confidence": 0.8045280575752258}]}, {"text": "summarizes statistical information per query.", "labels": [], "entities": []}, {"text": "The number of sentences affected by the augmentation varied considerably (1.04%-15.4%).", "labels": [], "entities": []}, {"text": "The initial lexicon of the morphological analyzer lacked morphemes that appeared frequently in some corpora because morphological analysis had been tested mainly with newspaper articles.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistical information per query", "labels": [], "entities": []}, {"text": " Table 4: Evaluation of \"diff\" blocks  segmentation  POS tagging  query", "labels": [], "entities": [{"text": "diff\" blocks  segmentation  POS tagging  query", "start_pos": 25, "end_pos": 71, "type": "TASK", "confidence": 0.7680137412888663}]}]}