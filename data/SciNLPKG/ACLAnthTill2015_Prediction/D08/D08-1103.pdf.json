{"title": [], "abstractContent": [{"text": "Knowing the degree of antonymy between words has widespread applications in natural language processing.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 76, "end_pos": 103, "type": "TASK", "confidence": 0.6535417636235555}]}, {"text": "Manually-created lexicons have limited coverage and do not include most semantically contrasting word pairs.", "labels": [], "entities": []}, {"text": "We present anew automatic and empirical measure of antonymy that combines corpus statistics with the structure of a published thesaurus.", "labels": [], "entities": []}, {"text": "The approach is evaluated on a set of closest-opposite questions, obtaining a precision of over 80%.", "labels": [], "entities": [{"text": "precision", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9994938373565674}]}, {"text": "Along the way, we discuss what humans consider antonymous and how antonymy manifests itself in utterances.", "labels": [], "entities": []}], "introductionContent": [{"text": "Native speakers of a language intuitively recognize different degrees of antonymy-whether two words are strongly antonymous (hot-cold, goodbad, friend-enemy), just semantically contrasting (enemy-fan, cold-lukewarm, ascend-slip) or not antonymous at all (penguin-clown, cold-chilly, boat-rudder).", "labels": [], "entities": []}, {"text": "Over the years, many definitions of antonymy have been proposed by linguists, cognitive scientists, psycholinguists, and lexicographers, which differ from each other in small and large respects.", "labels": [], "entities": []}, {"text": "In its strictest sense, antonymy applies to gradable adjectives, such as hot-cold and tall-short, where the two words represent the two ends of a semantic dimension.", "labels": [], "entities": []}, {"text": "Ina broader sense, it includes other adjectives, nouns, and verbs as well.", "labels": [], "entities": []}, {"text": "In its broadest sense, it applies to any two words that represent contrasting meanings.", "labels": [], "entities": []}, {"text": "We will use the term degree of antonymy to encompass the complete semantic range-a combined measure of the contrast in meaning conveyed by two words and the tendency of native speakers to call them opposites.", "labels": [], "entities": []}, {"text": "The higher the degree of antonymy between a target word pair, the greater the semantic contrast between them and the greater their tendency to be considered antonym pairs by native speakers.", "labels": [], "entities": []}, {"text": "Automatically determining the degree of antonymy between words has many uses including detecting and generating paraphrases (The dementors caught Sirius Black / Black could not escape the dementors) and detecting contradictions) (Kyoto has a predominantly wet climate / It is mostly dry in Kyoto).", "labels": [], "entities": []}, {"text": "Of course, such \"contradictions\" maybe a result of differing sentiment, new information, non-coreferent mentions, or genuinely contradictory statements.", "labels": [], "entities": []}, {"text": "Antonyms often indicate the discourse relation of contrast ().", "labels": [], "entities": []}, {"text": "They are also useful for detecting humor), as satire and jokes tend to have contradictions and oxymorons.", "labels": [], "entities": [{"text": "detecting humor", "start_pos": 25, "end_pos": 40, "type": "TASK", "confidence": 0.912295937538147}]}, {"text": "Lastly, it is useful to know which words are semantically contrasting to a target word, even if simply to filter them out.", "labels": [], "entities": []}, {"text": "For example, in the automatic creation of a thesaurus it is necessary to distinguish nearsynonyms from word pairs that are semantically contrasting.", "labels": [], "entities": []}, {"text": "Measures of distributional similarity fail to do so.", "labels": [], "entities": []}, {"text": "Detecting antonymous words is not sufficient to solve most of these problems, but it remains a crucial, and largely unsolved, component.", "labels": [], "entities": [{"text": "Detecting antonymous words", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8875306844711304}]}, {"text": "Lexicons of pairs of words that native speakers consider antonyms have been created for certain languages, but their coverage has been limited.", "labels": [], "entities": []}, {"text": "Further, as each term of an antonymous pair can have many semantically close terms, the contrasting word pairs far outnumber those that are commonly considered antonym pairs, and they remain unrecorded.", "labels": [], "entities": []}, {"text": "Even though a number of computational approaches have been proposed for semantic closeness, and some for hypernymy-hyponymy, measures of antonymy have been less successful.", "labels": [], "entities": []}, {"text": "To some extent, this is because antonymy is not as well understood as other classical lexical-semantic relations.", "labels": [], "entities": []}, {"text": "We first very briefly summarize insights and intuitions about this phenomenon, as proposed by linguists and lexicographers (Section 2).", "labels": [], "entities": []}, {"text": "We discuss related work (Section 3).", "labels": [], "entities": []}, {"text": "We describe the resources we use (Section 4) and present experiments that examine the manifestation of antonymy in text (Sections 5 and 6).", "labels": [], "entities": []}, {"text": "We then propose anew empirical approach to determine the degree of antonymy between two words (Section 7).", "labels": [], "entities": []}, {"text": "We compiled a dataset of 950 closest-opposite questions, which we used for evaluation (Section 8).", "labels": [], "entities": []}, {"text": "We conclude with a discussion of the merits and limitations of this approach and outline future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the algorithm proposed in Section 7 to automatically solve the closest-opposite questions.", "labels": [], "entities": []}, {"text": "Since individual words may have more than one meaning, we relied on the hypothesis that the intended sense of the alternatives are those which are most antonymous to one of the senses of the target word.", "labels": [], "entities": []}, {"text": "(This follows from the discussion earlier in Section 7.2.3.)", "labels": [], "entities": []}, {"text": "So for each of the alternatives we used the target word as context (but not the other alternatives).", "labels": [], "entities": []}, {"text": "We think that using a larger context to determine antonymy will be especially useful when the target words are found in sentences and natural text-something we intend to explore in the future.", "labels": [], "entities": []}, {"text": "presents results obtained on the development and test data using different combinations of the seed sets and the adjacency heuristic.", "labels": [], "entities": []}, {"text": "If the system did not find any evidence of antonymy between the target and any of its alternatives, then it refrained from attempting that question.", "labels": [], "entities": []}, {"text": "We therefore report precision (number of questions answered correctly / number of questions attempted), recall (number of questions answered correctly / total number of questions), and F-score values (2 Observe that all results are well above the random baseline of 0.20 (obtained when a system randomly guesses one of the five alternatives to be the answer).", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9995457530021667}, {"text": "recall", "start_pos": 104, "end_pos": 110, "type": "METRIC", "confidence": 0.9996730089187622}, {"text": "F-score", "start_pos": 185, "end_pos": 192, "type": "METRIC", "confidence": 0.9994397759437561}]}, {"text": "Also, using only the small set of sixteen affix rules, the system performs almost as well as when it uses 10,807 WordNet antonym pairs.", "labels": [], "entities": []}, {"text": "Using both the affix-generated and the WordNet seed sets, the system obtains markedly improved precision and coverage.", "labels": [], "entities": [{"text": "WordNet seed sets", "start_pos": 39, "end_pos": 56, "type": "DATASET", "confidence": 0.9844323992729187}, {"text": "precision", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9993300437927246}, {"text": "coverage", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9604507088661194}]}, {"text": "Using only the adjacency heuristic gave best precision values (upwards of 0.8) with substan-tial coverage (attempting close to half the questions).", "labels": [], "entities": [{"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9985242486000061}, {"text": "substan-tial coverage", "start_pos": 84, "end_pos": 105, "type": "METRIC", "confidence": 0.7240762412548065}]}, {"text": "However, best overall performance was obtained using both seed sets and the adjacency heuristic (Fscore of 0.7).", "labels": [], "entities": [{"text": "Fscore", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9984757304191589}]}], "tableCaptions": [{"text": " Table 2: Results obtained on closest-opposite questions.", "labels": [], "entities": []}]}