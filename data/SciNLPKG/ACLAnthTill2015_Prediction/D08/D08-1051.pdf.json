{"title": [{"text": "Improving Interactive Machine Translation via Mouse Actions", "labels": [], "entities": [{"text": "Improving Interactive Machine Translation", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.8766353130340576}]}], "abstractContent": [{"text": "Although Machine Translation (MT) is a very active research field which is receiving an increasing amount of attention from the research community, the results that current MT systems are capable of producing are still quite faraway from perfection.", "labels": [], "entities": [{"text": "Machine Translation (MT)", "start_pos": 9, "end_pos": 33, "type": "TASK", "confidence": 0.8925210118293763}]}, {"text": "Because of this, and in order to build systems that yield correct translations, human knowledge must be integrated into the translation process, which will be carried out in our casein an Interactive-Predictive (IP) framework.", "labels": [], "entities": []}, {"text": "In this paper, we show that considering Mouse Actions as a significant information source for the underlying system improves the productivity of the human translator involved.", "labels": [], "entities": []}, {"text": "In addition, we also show that the initial translations that the MT system provides can be quickly improved by an expert by only performing additional Mouse Actions.", "labels": [], "entities": [{"text": "MT", "start_pos": 65, "end_pos": 67, "type": "TASK", "confidence": 0.9447912573814392}]}, {"text": "In this work, we will be using word graphs as an efficient interface between a phrase-based MT system and the IP engine.", "labels": [], "entities": [{"text": "MT", "start_pos": 92, "end_pos": 94, "type": "TASK", "confidence": 0.8819554448127747}]}], "introductionContent": [{"text": "Information technology advances in modern society have led to the need of more efficient methods of translation.", "labels": [], "entities": []}, {"text": "It is important to remark that current MT systems are notable to produce ready-to-use texts.", "labels": [], "entities": [{"text": "MT", "start_pos": 39, "end_pos": 41, "type": "TASK", "confidence": 0.9798188209533691}]}, {"text": "Indeed, MT systems are usually limited to specific semantic domains and the translations provided require human post-editing in order to achieve a correct high-quality translation.", "labels": [], "entities": [{"text": "MT", "start_pos": 8, "end_pos": 10, "type": "TASK", "confidence": 0.9903976917266846}]}, {"text": "A way of taking advantage of MT systems is to combine them with the knowledge of a human translator, constituting the so-called Computer-Assisted Translation (CAT) paradigm.", "labels": [], "entities": [{"text": "MT", "start_pos": 29, "end_pos": 31, "type": "TASK", "confidence": 0.9805132746696472}, {"text": "Computer-Assisted Translation (CAT) paradigm", "start_pos": 128, "end_pos": 172, "type": "TASK", "confidence": 0.8557786742846171}]}, {"text": "CAT offers different approaches in order to benefit from the synergy between humans and MT systems.", "labels": [], "entities": [{"text": "CAT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7431105375289917}, {"text": "MT", "start_pos": 88, "end_pos": 90, "type": "TASK", "confidence": 0.9600116014480591}]}, {"text": "An important contribution to interactive CAT technology was carried out around the TransType (TT) project (.", "labels": [], "entities": [{"text": "CAT", "start_pos": 41, "end_pos": 44, "type": "TASK", "confidence": 0.8719267249107361}]}, {"text": "This project entailed an interesting focus shift in which interaction directly aimed at the production of the target text, rather than at the disambiguation of the source text, as in former interactive systems.", "labels": [], "entities": []}, {"text": "The idea proposed was to embed data driven MT techniques within the interactive translation environment.", "labels": [], "entities": [{"text": "MT", "start_pos": 43, "end_pos": 45, "type": "TASK", "confidence": 0.9797540307044983}]}, {"text": "Following these TT ideas, ( propose the usage of fully-fledged statistical MT (SMT) systems to produce full target sentence hypotheses, or portions thereof, which can be partially or completely accepted and amended by a human translator.", "labels": [], "entities": [{"text": "MT (SMT)", "start_pos": 75, "end_pos": 83, "type": "TASK", "confidence": 0.7991733103990555}]}, {"text": "Each partial correct text segment is then used by the SMT system as additional information to achieve further, hopefully improved suggestions.", "labels": [], "entities": [{"text": "SMT", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9888715147972107}]}, {"text": "In this paper, we also focus on the interactive and predictive, statistical MT (IMT) approach to CAT.", "labels": [], "entities": [{"text": "MT (IMT)", "start_pos": 76, "end_pos": 84, "type": "TASK", "confidence": 0.7871587872505188}, {"text": "CAT", "start_pos": 97, "end_pos": 100, "type": "TASK", "confidence": 0.9746711850166321}]}, {"text": "The IMT paradigm fits well within the Interactive Pattern Recognition framework introduced in).", "labels": [], "entities": [{"text": "IMT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9579761028289795}, {"text": "Interactive Pattern Recognition", "start_pos": 38, "end_pos": 69, "type": "TASK", "confidence": 0.7323228716850281}]}], "datasetContent": [{"text": "Automatic evaluation of results is a difficult problem in MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 58, "end_pos": 60, "type": "TASK", "confidence": 0.9914455413818359}]}, {"text": "In fact, it has evolved to a research field with own identity.", "labels": [], "entities": []}, {"text": "This is due to the fact that, given an input sentence, a large amount of correct and different output sentences may exist.", "labels": [], "entities": []}, {"text": "Hence, there is no sentence which can be considered ground truth, as is the casein speech or text recognition.", "labels": [], "entities": [{"text": "text recognition", "start_pos": 93, "end_pos": 109, "type": "TASK", "confidence": 0.7713083624839783}]}, {"text": "By extension, this problem is also applicable to IMT.", "labels": [], "entities": [{"text": "IMT", "start_pos": 49, "end_pos": 52, "type": "TASK", "confidence": 0.9767923951148987}]}, {"text": "In this paper, we will be reporting our results as measured by Word Stroke Ratio (WSR) (Barrachina Seleccione el tipo de instalaci\u00f3n.", "labels": [], "entities": [{"text": "Word Stroke Ratio (WSR)", "start_pos": 63, "end_pos": 86, "type": "METRIC", "confidence": 0.6525942732890447}]}, {"text": "REFERENCE (y): Select the type of installation.", "labels": [], "entities": [{"text": "REFERENCE", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9927759170532227}]}, {"text": "Select the installation wizard. of installation.", "labels": [], "entities": []}, {"text": "As a first step, we built a SMT system for each of the language pairs cited in the previous subsection.", "labels": [], "entities": [{"text": "SMT", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9922890067100525}]}, {"text": "This was done by means of the Moses toolkit (, which is a complete system for building Phrase-Based SMT models.", "labels": [], "entities": [{"text": "Phrase-Based SMT models", "start_pos": 87, "end_pos": 110, "type": "TASK", "confidence": 0.6901721159617106}]}, {"text": "This toolkit involves the estimation from the training set of four different translation models, which are in turn com- bined in a log-linear fashion by adjusting a weight for each of them by means of the MERT procedure, optimising the BLEU () score obtained on the development partition.", "labels": [], "entities": [{"text": "MERT", "start_pos": 205, "end_pos": 209, "type": "METRIC", "confidence": 0.898807942867279}, {"text": "BLEU () score", "start_pos": 236, "end_pos": 249, "type": "METRIC", "confidence": 0.9303699533144633}]}, {"text": "This being done, word graphs were generated for the IMT system.", "labels": [], "entities": [{"text": "IMT", "start_pos": 52, "end_pos": 55, "type": "TASK", "confidence": 0.7465569972991943}]}, {"text": "For this purpose, we used a multi-stack phrase-based decoder which will be distributed in the near future together with the Thot toolkit).", "labels": [], "entities": []}, {"text": "We discarded the use of the Moses decoder because preliminary experiments performed with it revealed that the decoder by) performs clearly better when used to generate word graphs for use in IMT.", "labels": [], "entities": [{"text": "IMT", "start_pos": 191, "end_pos": 194, "type": "TASK", "confidence": 0.9407029151916504}]}, {"text": "In addition, we performed an experimental comparison in regular SMT with the Europarl corpus, and found that the performance difference was negligible.", "labels": [], "entities": [{"text": "SMT", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9461892247200012}, {"text": "Europarl corpus", "start_pos": 77, "end_pos": 92, "type": "DATASET", "confidence": 0.9960061013698578}]}, {"text": "The decoder was set to only consider monotonic translation, since in real IMT scenarios considering non-monotonic translation leads to excessive waiting time for the user.", "labels": [], "entities": []}, {"text": "Finally, the word graphs obtained were used within the IMT procedure to produce the reference translation contained in the test set, measuring WSR and MAR.", "labels": [], "entities": [{"text": "IMT", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.7509233355522156}, {"text": "WSR", "start_pos": 143, "end_pos": 146, "type": "METRIC", "confidence": 0.9877474308013916}, {"text": "MAR", "start_pos": 151, "end_pos": 154, "type": "METRIC", "confidence": 0.9860011339187622}]}, {"text": "The results of such a setup can be seen in.", "labels": [], "entities": []}, {"text": "As a baseline system, we report the traditional IMT framework, in which no MA is taken into account.", "labels": [], "entities": [{"text": "IMT", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.8928249478340149}, {"text": "MA", "start_pos": 75, "end_pos": 77, "type": "METRIC", "confidence": 0.9802389144897461}]}, {"text": "Then, we introduced non-explicit MAs, obtaining an average improvement in WSR of about 3.2% (4.9% relative).", "labels": [], "entities": [{"text": "WSR", "start_pos": 74, "end_pos": 77, "type": "METRIC", "confidence": 0.9698280096054077}]}, {"text": "The table also shows the confidence intervals at a confidence level of 95%.", "labels": [], "entities": [{"text": "confidence intervals", "start_pos": 25, "end_pos": 45, "type": "METRIC", "confidence": 0.9567177593708038}]}, {"text": "These intervals were computed following the bootstrap technique described in).", "labels": [], "entities": []}, {"text": "Since the confidence intervals do not overlap, it can be stated that the improvements obtained are statistically significant.", "labels": [], "entities": []}, {"text": "Confidence intervals at 95% confidence level following).", "labels": [], "entities": [{"text": "Confidence", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9705960154533386}]}, {"text": "Once the non-explicit MAs were considered and introduced into the system, we analysed the effect of performing up to a maximum of 5 explicit MAs.", "labels": [], "entities": []}, {"text": "Here, we modelled the user in such away that, in case a given word is considered incorrect, he will always ask for another translation hypothesis until he has asked for as many different suffixes as MAs considered.", "labels": [], "entities": []}, {"text": "The results of this setup can be seen in.", "labels": [], "entities": []}, {"text": "This yielded a further average improvement in WSR of about 16% (25% relative improvement) when considering a maximum of 5 explicit MAs.", "labels": [], "entities": [{"text": "WSR", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.9553787112236023}]}, {"text": "However, relative improvement in WSR and uMAR increase drop significantly when increasing the maximum allowed amount of explicit MAs from 1 to 5.", "labels": [], "entities": [{"text": "WSR", "start_pos": 33, "end_pos": 36, "type": "METRIC", "confidence": 0.8426188230514526}]}, {"text": "For this reason, it is difficult to imagine that a user would perform more than two or three MAs before actually typing in anew word.", "labels": [], "entities": [{"text": "MAs", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.9644065499305725}]}, {"text": "Nevertheless, just by asking twice fora new suffix before typing in the word he has in mind, the user might be saving about 15% of word-strokes.", "labels": [], "entities": []}, {"text": "Although the results in are only for the translation direction \"foreign\"\u2192English, the experiments in the opposite direction (i.e. English\u2192\"foreign\") were also performed.", "labels": [], "entities": []}, {"text": "However, the results were very similar to the ones displayed here.", "labels": [], "entities": []}, {"text": "Because of this, and for clarity purposes, we decided to omit them and only display the direction \"foreign\"\u2192English.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Characteristics of Europarl for each of the sub- corpora. OoV stands for \"Out of Vocabulary\" words,  Dev. for Development, K for thousands of elements and  M for millions of elements.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 29, "end_pos": 37, "type": "DATASET", "confidence": 0.9700341820716858}, {"text": "OoV", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.9732591509819031}]}, {"text": " Table 2: WSR improvement when considering non- explicit MAs. \"rel.\" indicates the relative improvement.  All results are given in %.", "labels": [], "entities": [{"text": "WSR", "start_pos": 10, "end_pos": 13, "type": "TASK", "confidence": 0.5016634464263916}]}]}