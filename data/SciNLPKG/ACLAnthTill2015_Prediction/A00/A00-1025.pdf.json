{"title": [{"text": "Examining the Role of Statistical and Linguistic Knowledge Sources in a General-Knowledge Question-Answering System", "labels": [], "entities": []}], "abstractContent": [{"text": "We describe and evaluate an implemented system for general-knowledge question answering.", "labels": [], "entities": [{"text": "general-knowledge question answering", "start_pos": 51, "end_pos": 87, "type": "TASK", "confidence": 0.7188660800457001}]}, {"text": "The system combines techniques for standard ad-hoc information retrieval (IR), query-dependent text summa-rization, and shallow syntactic and semantic sentence analysis.", "labels": [], "entities": [{"text": "ad-hoc information retrieval (IR)", "start_pos": 44, "end_pos": 77, "type": "TASK", "confidence": 0.7986690998077393}, {"text": "shallow syntactic and semantic sentence analysis", "start_pos": 120, "end_pos": 168, "type": "TASK", "confidence": 0.6038748373587927}]}, {"text": "Ina series of experiments we examine the role of each statistical and linguistic knowledge source in the question-answering system.", "labels": [], "entities": []}, {"text": "In contrast to previous results, we find first that statistical knowledge of word co-occurrences as computed by IR vector space methods can be used to quickly and accurately locate the relevant documents for each question.", "labels": [], "entities": []}, {"text": "The use of query-dependent text summarization techniques, however, provides only small increases in performance and severely limits recall levels when inaccurate.", "labels": [], "entities": [{"text": "query-dependent text summarization", "start_pos": 11, "end_pos": 45, "type": "TASK", "confidence": 0.6008897125720978}, {"text": "recall", "start_pos": 132, "end_pos": 138, "type": "METRIC", "confidence": 0.9985950589179993}]}, {"text": "Nevertheless, it is the text summarization component that allows subsequent linguistic filters to focus on relevant passages.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.648551344871521}]}, {"text": "We find that even very weak linguistic knowledge can offer substantial improvements over purely IR-based techniques for question answering, especially when smoothly integrated with statistical preferences computed by the IR subsystems.", "labels": [], "entities": [{"text": "question answering", "start_pos": 120, "end_pos": 138, "type": "TASK", "confidence": 0.8527443110942841}]}], "introductionContent": [{"text": "In this paper, we describe and evaluate an implemented system for general-knowledge question answering.", "labels": [], "entities": [{"text": "general-knowledge question answering", "start_pos": 66, "end_pos": 102, "type": "TASK", "confidence": 0.7427994608879089}]}, {"text": "Open-ended question-answering systems that allow users to pose a question of any type, in any language, without domain restrictions, remain beyond the scope of today's text-processing systems.", "labels": [], "entities": []}, {"text": "We investigate instead a restricted, but nevertheless useful variation of the problem): Given a large text collection and a set of questions specified in English, find answers to the questions in the collection.", "labels": [], "entities": []}, {"text": "In addition, the restricted task guarantees that: \u2022 the answer exists in the collection, \u2022 all supporting information for the answer lies in a single document, and \u2022 the answer is short m less than 50 bytes in length.", "labels": [], "entities": []}, {"text": "Consider, for example, the question Which country has the largest part of the Amazon rain forest?, taken from the TREC8 Question Answering development corpus.", "labels": [], "entities": [{"text": "TREC8 Question Answering development corpus", "start_pos": 114, "end_pos": 157, "type": "DATASET", "confidence": 0.8036985635757447}]}, {"text": "The answer (in document LA032590-0089) is Brazil Previous research has addressed similar questionanswering (QA) scenarios using a variety of natural language processing (NLP) and information retrieval (IR) techniques.", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 179, "end_pos": 205, "type": "TASK", "confidence": 0.8317162990570068}]}, {"text": "tackles the difficult task of answering questions in the context of story understanding.", "labels": [], "entities": [{"text": "story understanding", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.6434182077646255}]}, {"text": "Unlike our restricted QA task, questions to Lehnert's system often require answers that are not explicitly mentioned in the story.", "labels": [], "entities": []}, {"text": "Her goal then is to answer questions by making inferences about actions and actors in the story using world knowledge in the form of scripts, plans, and goals (.", "labels": [], "entities": []}, {"text": "More recently,) describe a system that answers natural language questions using a database of question-answer pairs built from existing frequentlyasked question (FAQ) files.", "labels": [], "entities": []}, {"text": "Their FAQFinder system uses IR techniques to match the given question to questions in the database.", "labels": [], "entities": []}, {"text": "It then uses the WordNet lexical semantic knowledge base ( to improve the quality of the match.", "labels": [], "entities": [{"text": "WordNet lexical semantic knowledge base", "start_pos": 17, "end_pos": 56, "type": "DATASET", "confidence": 0.9175919890403748}]}, {"text": "investigates a closed-class QA task that is similar in many respects to the TREC8 QA task that we address here: the system answers general-knowledge questions using an encyclopedia.", "labels": [], "entities": []}, {"text": "In addition, Kupiec assumes that all answers are noun phrases.", "labels": [], "entities": []}, {"text": "Although our task does not explicitly include a \"noun phrase\" constraint, the answer length restriction effectively imposes the same bias toward noun phrase answers.", "labels": [], "entities": []}, {"text": "Kupiec's MURAX system applies a combination of statistical (IR) and linguistic (NLP) techniques.", "labels": [], "entities": []}, {"text": "A series of secondary boolean search queries with proximity constraints is combined with shallow parsing methods to find relevant sections of the encyclopedia, to extract answer hypotheses, and to confirm phrase relations specified in the question.", "labels": [], "entities": []}, {"text": "In an evaluation on 70 \"Trivial Pursuit\" who and what questions, Kupiec concludes that robust natural language analysis can add to the quality of the information retrieval process.", "labels": [], "entities": [{"text": "Trivial Pursuit\" who and what questions", "start_pos": 24, "end_pos": 63, "type": "TASK", "confidence": 0.8360657436507088}, {"text": "information retrieval process", "start_pos": 150, "end_pos": 179, "type": "TASK", "confidence": 0.8000651001930237}]}, {"text": "In addition, he claims that, for their closed-class QA task, vector space IR methods () appear inadequate.", "labels": [], "entities": [{"text": "vector space IR", "start_pos": 61, "end_pos": 76, "type": "TASK", "confidence": 0.5928034881750742}]}, {"text": "We present here anew approach to the restricted question-answering task described above.", "labels": [], "entities": []}, {"text": "Like MURAX, our system draws from both statistical and linguistic sources to find answers to generalknowledge questions.", "labels": [], "entities": [{"text": "MURAX", "start_pos": 5, "end_pos": 10, "type": "DATASET", "confidence": 0.803514838218689}]}, {"text": "The underlying architecture of the system, however, is very different: it combines vector space IR techniques for document retrieval, a vector space approach to query-dependent text summarization, shallow corpus-based syntactic analysis, and knowledge-based semantic analysis.", "labels": [], "entities": [{"text": "document retrieval", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.7491413056850433}, {"text": "query-dependent text summarization", "start_pos": 161, "end_pos": 195, "type": "TASK", "confidence": 0.6252987682819366}, {"text": "knowledge-based semantic analysis", "start_pos": 242, "end_pos": 275, "type": "TASK", "confidence": 0.6687386333942413}]}, {"text": "We evaluate the system on the TREC8 QA development corpus as well as the TREC8 QA test corpus.", "labels": [], "entities": [{"text": "TREC8 QA development corpus", "start_pos": 30, "end_pos": 57, "type": "DATASET", "confidence": 0.9024260640144348}, {"text": "TREC8 QA test corpus", "start_pos": 73, "end_pos": 93, "type": "DATASET", "confidence": 0.948960080742836}]}, {"text": "In particular, all parameters for the final QA system are determined using the development corpus.", "labels": [], "entities": []}, {"text": "Our current results are encouraging but not outstanding: the system is able to correctly answer 22 out of 38 of the development questions and 91 out of 200 of the test questions given five guesses for each question.", "labels": [], "entities": []}, {"text": "Furthermore, the first guess is correct for 16 out of the 22 development questions and 53 out of 91 of the test questions.", "labels": [], "entities": []}, {"text": "More importantly, we investigate the relative role of each statistical and linguistic knowledge source in the proposed IR/NLP question-answering system.", "labels": [], "entities": [{"text": "IR/NLP question-answering", "start_pos": 119, "end_pos": 144, "type": "TASK", "confidence": 0.8106502443552017}]}, {"text": "In contrast to previous results, we find that statistical knowledge of word co-occurrences as computed by vector space models of IR can be used to quickly and accurately locate relevant documents in the restricted QA task.", "labels": [], "entities": []}, {"text": "When used in isolation, vector space methods for query-dependent text summarization, however, provide relatively small increases in performance.", "labels": [], "entities": [{"text": "query-dependent text summarization", "start_pos": 49, "end_pos": 83, "type": "TASK", "confidence": 0.5997814039389292}]}, {"text": "In addition, we find that the text summarization component can severely limit recall levels.", "labels": [], "entities": [{"text": "text summarization", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.7326143085956573}, {"text": "recall", "start_pos": 78, "end_pos": 84, "type": "METRIC", "confidence": 0.9976263642311096}]}, {"text": "Nevertheless, it is the summarization component that allows the linguistic filters to focus on relevant passages.", "labels": [], "entities": []}, {"text": "In particular, we find that very weak linguistic knowledge can offer substantial improvements over purely IR-based techniques for question answering, especially when smoothly integrated with the statistical preferences computed by the IR subsystems.", "labels": [], "entities": [{"text": "question answering", "start_pos": 130, "end_pos": 148, "type": "TASK", "confidence": 0.847836971282959}]}, {"text": "In the next section, we describe the general architecture of the question-answering system.", "labels": [], "entities": []}, {"text": "Section 3 describes the baseline system and its information retrieval component.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 48, "end_pos": 69, "type": "TASK", "confidence": 0.7795814871788025}]}, {"text": "Sections 4-7 describe and evaluate a series of variations to the baseline system that incorporate, in turn, query-dependent text summarization, a syntactic filter, a semantic filter, and an algorithm that allows syntactic knowledge to influence the initial ordering of summary extracts.", "labels": [], "entities": [{"text": "query-dependent text summarization", "start_pos": 108, "end_pos": 142, "type": "TASK", "confidence": 0.6004350582758585}]}, {"text": "Section 8 compares our approach to some of those in the recent TREC8 QA evaluation) and describes directions for future work.", "labels": [], "entities": [{"text": "TREC8 QA evaluation", "start_pos": 63, "end_pos": 82, "type": "DATASET", "confidence": 0.8608261346817017}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Evaluation of the Role of Statistical and Limited Linguistic Knowledge for the TREC8 Question  Answering Task. Results for 38 development and 200 test questions are shown. The mean answer rank  (MAR) is computed w.r.t, all questions correctly answered.", "labels": [], "entities": [{"text": "TREC8 Question  Answering Task", "start_pos": 89, "end_pos": 119, "type": "TASK", "confidence": 0.7101539373397827}, {"text": "mean answer rank  (MAR)", "start_pos": 186, "end_pos": 209, "type": "METRIC", "confidence": 0.8674085338910421}]}]}