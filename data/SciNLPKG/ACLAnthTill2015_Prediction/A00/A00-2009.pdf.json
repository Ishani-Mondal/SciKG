{"title": [{"text": "A Simple Approach to Building Ensembles of Naive Bayesian Classifiers for Word Sense Disambiguation", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 74, "end_pos": 99, "type": "TASK", "confidence": 0.7707718014717102}]}], "abstractContent": [{"text": "This paper presents a corpus-based approach to word sense disambiguation that builds an ensemble of Naive Bayesian classifiers, each of which is based on lexical features that represent co-occurring words in varying sized windows of context.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.7413159410158793}]}, {"text": "Despite the simplicity of this approach, empirical results disam-biguating the widely studied nouns line and interest show that such an ensemble achieves accuracy rival-ing the best previously published results.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.9980548620223999}]}], "introductionContent": [{"text": "Word sense disambiguation is often cast as a problem in supervised learning, where a disambiguator is induced from a corpus of manually sense-tagged text using methods from statistics or machine learning.", "labels": [], "entities": [{"text": "Word sense disambiguation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.6701830327510834}]}, {"text": "These approaches typically represent the context in which each sense-tagged instance of a word occurs with a set of linguistically motivated features.", "labels": [], "entities": []}, {"text": "A learning algorithm induces a representative model from these features which is employed as a classifier to perform disambiguation.", "labels": [], "entities": []}, {"text": "This paper presents a corpus-based approach that results in high accuracy by combining a number of very simple classifiers into an ensemble that performs disambiguation via a majority vote.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9981739521026611}]}, {"text": "This is motivated by the observation that enhancing the feature set or learning algorithm used in a corpus-based approach does not usually improve disambiguation accuracy beyond what can be attained with shallow lexical features and a simple supervised learning algorithm.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 162, "end_pos": 170, "type": "METRIC", "confidence": 0.9526423811912537}]}, {"text": "For example, a Naive Bayesian classifier) is based on a blanket assumption about the interactions among features in a sensetagged corpus and does not learn a representative model.", "labels": [], "entities": []}, {"text": "Despite making such an assumption, this proves to be among the most accurate techniques in comparative studies of corpus-based word sense disambiguation methodologies (e.g.,,,,).", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 127, "end_pos": 152, "type": "TASK", "confidence": 0.6379309495290121}]}, {"text": "These studies represent the context in which an ambiguous word occurs with a wide variety of features.", "labels": [], "entities": []}, {"text": "However, when the contribution of each type of feature to overall accuracy is analyzed), shallow lexical features such as co-occurrences and collocations prove to be stronger contributors to accuracy than do deeper, linguistically motivated features such as part-of-speech and verb-object relationships.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9963427186012268}, {"text": "accuracy", "start_pos": 191, "end_pos": 199, "type": "METRIC", "confidence": 0.9958887696266174}]}, {"text": "It has also been shown that the combined accuracy of an ensemble of multiple classifiers is often significantly greater than that of any of the individual classifiers that makeup the ensemble (e.g.,).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9986768364906311}]}, {"text": "In natural language processing, ensemble techniques have been successfully applied to partof-speech tagging (e.g.,) and parsing (e.g.,).", "labels": [], "entities": [{"text": "partof-speech tagging", "start_pos": 86, "end_pos": 107, "type": "TASK", "confidence": 0.7936082780361176}]}, {"text": "When combined with a history of disambiguation success using shallow lexical features and Naive Bayesian classifiers, these findings suggest that word sense disambiguation might best be improved by combining the output of a number of such classifiers into an ensemble.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 146, "end_pos": 171, "type": "TASK", "confidence": 0.6981398463249207}]}, {"text": "This paper begins with an introduction to the Naive Bayesian classifier.", "labels": [], "entities": [{"text": "Naive Bayesian classifier", "start_pos": 46, "end_pos": 71, "type": "TASK", "confidence": 0.6713222861289978}]}, {"text": "The features used to represent the context in which ambiguous words occur are presented, followed by the method for selecting the classifiers to include in the ensemble.", "labels": [], "entities": []}, {"text": "Then, the line and interest data is described.", "labels": [], "entities": []}, {"text": "Experimental results disambiguating these words with an ensemble of Naive Bayesian classifiers are shown to rival previously published results.", "labels": [], "entities": []}, {"text": "This paper closes with a discussion of the choices made in formulating this methodology and plans for future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The line data was created by by tagging every occurrence of line in the ACL/DCI Wall Street Journal corpus and the American Printing House for the Blind corpus with one of six possible WordNet senses.", "labels": [], "entities": [{"text": "ACL/DCI Wall Street Journal corpus", "start_pos": 72, "end_pos": 106, "type": "DATASET", "confidence": 0.8860038093158177}, {"text": "American Printing House for the Blind corpus", "start_pos": 115, "end_pos": 159, "type": "DATASET", "confidence": 0.8724625706672668}]}, {"text": "These senses and their frequency distribution are shown in.", "labels": [], "entities": []}, {"text": "This data has since been used in studies by, (Towell and Voorhees, 1998), and (.", "labels": [], "entities": []}, {"text": "In that work, as well as in this paper, a subset of the corpus is utilized such that each sense is uniformly distributed; this reduces the accuracy of the majority classifier to 17%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9995957016944885}]}, {"text": "The uniform distribution is created by randomly sampling 349 sense-tagged examples from each sense, resulting in a training corpus of 2094 sense-tagged sentences.", "labels": [], "entities": []}, {"text": "The interest data was created by by tagging all occurrences of interest in the ACL/DCI Wall Street Journal corpus with senses from the Longman Dictionary of Contemporary English.", "labels": [], "entities": [{"text": "ACL/DCI Wall Street Journal corpus", "start_pos": 79, "end_pos": 113, "type": "DATASET", "confidence": 0.913854581969125}, {"text": "Longman Dictionary of Contemporary English", "start_pos": 135, "end_pos": 177, "type": "DATASET", "confidence": 0.91140216588974}]}, {"text": "This data set was subsequently used for word sense disambiguation experiments by, ( , and  quency distribution are shown in.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 40, "end_pos": 65, "type": "TASK", "confidence": 0.7433178226153055}]}, {"text": "Unlike line, the sense distribution is skewed; the majority sense occurs in 53% of the sentences, while the smallest minority sense occurs in less than 1%.", "labels": [], "entities": []}, {"text": "Eighty-one Naive Bayesian classifiers were trained and tested with the line and interest data.", "labels": [], "entities": []}, {"text": "Fivefold cross validation was employed; all of the sensetagged examples fora word were randomly shuffled and divided into five equal folds.", "labels": [], "entities": []}, {"text": "Four folds were used to train the Naive Bayesian classifier while the remaining fold was randomly divided into two equal sized test sets.", "labels": [], "entities": []}, {"text": "The first, devtest, was used to evaluate the individual classifiers for inclusion in the ensemble.", "labels": [], "entities": []}, {"text": "The second, test, was used to evaluate the accuracy of the ensemble.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9992161989212036}]}, {"text": "Thus the training data for each word consists of 80% of the available sensetagged text, while each of the test sets contains 10%.", "labels": [], "entities": []}, {"text": "This process is repeated five times so that each fold serves as the source of the test data once.", "labels": [], "entities": []}, {"text": "The average accuracy of the individual Naive Bayesian classifiers across the five folds is reported in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9993048906326294}]}, {"text": "The standard deviations were between .01 and .025 and are not shown given their relative consistency.", "labels": [], "entities": [{"text": "consistency", "start_pos": 89, "end_pos": 100, "type": "METRIC", "confidence": 0.9954995512962341}]}, {"text": "Each classifier is based upon a distinct representation of context since each employs a different combination of right and left window sizes.", "labels": [], "entities": []}, {"text": "The size and range of the left window of context is indicated along the horizontal margin in while the right window size and range is shown along the vertical margin.", "labels": [], "entities": []}, {"text": "Thus, the boxes that subdivide each table correspond to a particular range category.", "labels": [], "entities": []}, {"text": "The classifier that achieves the highest accuracy in each range category is included as a member of the ensemble.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9981745481491089}]}, {"text": "In case of a tie, the classifier with the smallest total window of context is included in the ensemble.", "labels": [], "entities": []}, {"text": "The most accurate single classifier for line is Naive_Bayes (4,25), which attains accuracy of 84% The accuracy of the ensemble created from the most accurate classifier in each of the range categories is 88%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9993206262588501}, {"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9995123147964478}]}, {"text": "The single most accurate classifier for interest is Naive._Bayes(4,1), which attains accuracy of 86% while the ensemble approach reaches 89%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 85, "end_pos": 93, "type": "METRIC", "confidence": 0.9994506239891052}]}, {"text": "The increase inaccuracy achieved by both ensembles over the best individual classifier is statistically significant, as judged by McNemar's test with p = .01.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Distribution of senses for line -the exper- iments in this paper and previous work use a uni- formly distributed subset of this corpus, where each  sense occurs 349 times.", "labels": [], "entities": []}, {"text": " Table 2: Distribution of senses for interest -the ex- periments in this paper and previous work use the  entire corpus, where each sense occurs the number  of times shown above.", "labels": [], "entities": []}, {"text": " Table 3: Accuracy of Naive Bayesian classifiers for line evaluated with the devtest data. The italicized  accuracies are associated with the classifiers included in the ensemble, which attained accuracy of 88% when  evaluated with the test data.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9979960918426514}, {"text": "accuracy", "start_pos": 195, "end_pos": 203, "type": "METRIC", "confidence": 0.9988458156585693}]}, {"text": " Table 4: Accuracy of Naive Bayesian classifiers for interest evaluated with the devtest data. The italicized  accuracies are associated with the classifiers included in the ensemble, which attained accuracy of 89% when  evaluated with the test data.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.997670590877533}, {"text": "accuracy", "start_pos": 199, "end_pos": 207, "type": "METRIC", "confidence": 0.9989832043647766}]}]}