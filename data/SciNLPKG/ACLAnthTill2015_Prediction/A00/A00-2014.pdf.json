{"title": [{"text": "The Effectiveness of Corpus-Induced Dependency Grammars for Post-processing Speech*", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper investigates the impact of Constraint Dependency Grammars (CDG) on the accuracy of an integrated speech recognition and CDG parsing system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9973042011260986}, {"text": "speech recognition and CDG parsing", "start_pos": 108, "end_pos": 142, "type": "TASK", "confidence": 0.6504323244094848}]}, {"text": "We compare a conventional CDG with CDGs that are induced from annotated sentences and template-expanded sentences.", "labels": [], "entities": []}, {"text": "The grammars are evaluated on parsing speed, precision/coverage, and improvement of word and sentence accuracy of the integrated system.", "labels": [], "entities": [{"text": "parsing", "start_pos": 30, "end_pos": 37, "type": "TASK", "confidence": 0.9603773355484009}, {"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9992389678955078}, {"text": "coverage", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.6161734461784363}, {"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9052724838256836}]}, {"text": "Sentence-derived CDGs significantly improve recognition accuracy over the conventional CDG but are less general.", "labels": [], "entities": [{"text": "recognition", "start_pos": 44, "end_pos": 55, "type": "TASK", "confidence": 0.9054064750671387}, {"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9278171062469482}]}, {"text": "Expanding the sentences with templates provides us with a mechanism for increasing the coverage of the grammar with only minor reductions in recognition accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 153, "end_pos": 161, "type": "METRIC", "confidence": 0.9492834210395813}]}], "introductionContent": [], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Number of ARVs and ARVPs extracted for  each RM grammar.  ARVP  Sentence I Template  Percent", "labels": [], "entities": []}, {"text": " Table 3: Average parse times (SD), number of paths (SD), number of nodes (SD), and number of role values  (SD) remaining after parsing the 1,080 word graphs of 50 or fewer word nodes produced for the RM test set  using the 13 CDGs.", "labels": [], "entities": [{"text": "Average parse times (SD)", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.883814404408137}, {"text": "number of role values  (SD)", "start_pos": 84, "end_pos": 111, "type": "METRIC", "confidence": 0.6205065378120967}]}, {"text": " Table 4: The sentence accuracy, percent correct words, and word accuracy from parsing 1,080 word graphs  of 50 or fewer word nodes produced for the RM test set using the 13 CDGs.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 23, "end_pos": 31, "type": "METRIC", "confidence": 0.9602031111717224}, {"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.810171365737915}, {"text": "RM test set", "start_pos": 149, "end_pos": 160, "type": "DATASET", "confidence": 0.8273292581240336}]}]}