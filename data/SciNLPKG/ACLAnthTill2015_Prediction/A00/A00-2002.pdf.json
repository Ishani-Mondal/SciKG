{"title": [{"text": "The Automatic Translation of Discourse Structures", "labels": [], "entities": [{"text": "Automatic Translation of Discourse Structures", "start_pos": 4, "end_pos": 49, "type": "TASK", "confidence": 0.8261868000030518}]}], "abstractContent": [{"text": "We empirically show that there are significant differences between the discourse structure of Japanese texts and the discourse structure of their corresponding English translations.", "labels": [], "entities": []}, {"text": "To improve translation quality, we propose a computational model for rewriting discourse structures.", "labels": [], "entities": [{"text": "translation", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.9713903069496155}]}, {"text": "When we train our model on a parallel corpus of manually built Japanese and English discourse structure trees, we learn to rewrite Japanese trees as trees that are closer to the natural English rendering than the original ones.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "In order to assess the role of discourse structure in MT, we built manually a corpus of discourse trees for 40 Japanese texts and their corresponding translations.", "labels": [], "entities": [{"text": "MT", "start_pos": 54, "end_pos": 56, "type": "TASK", "confidence": 0.9907584190368652}]}, {"text": "The texts were selected randomly from the ARPA corpus (.", "labels": [], "entities": [{"text": "ARPA corpus", "start_pos": 42, "end_pos": 53, "type": "DATASET", "confidence": 0.9593149125576019}]}, {"text": "On average, each text had about 460 words.", "labels": [], "entities": []}, {"text": "The Japanese texts had a total of 335 paragraphs and 773 sentences.", "labels": [], "entities": []}, {"text": "The English texts had a total of 337 paragraphs and 827 sentences.", "labels": [], "entities": []}, {"text": "We developed a discourse annotation protocol for Japanese and English along the lines followed by . We used Marcu's discourse annotation tool (1999) in order to manually construct the discourse structure of all Japanese and English texts in the corpus.", "labels": [], "entities": []}, {"text": "10% of the Japanese and English texts were rhetorically labeled by two of us.", "labels": [], "entities": []}, {"text": "The tool and the annotation protocol are available at http://www.isi.edu/~marcu/software/.", "labels": [], "entities": []}, {"text": "The annotation procedure yielded over the entire corpus 2641 Japanese edus and 2363 English edus.", "labels": [], "entities": []}, {"text": "We computed the reliability of the annotation using 's method for computing kappa statistics) over hierarchical structures.", "labels": [], "entities": [{"text": "reliability", "start_pos": 16, "end_pos": 27, "type": "METRIC", "confidence": 0.9925904273986816}]}, {"text": "displays average kappa statistics that reflect the reliability of the annotation of elementary discourse units, k~,, hierarchical discourse spans, ks, hierarchical nuclearity assignments, k,~, and hierarchical rhetorical relation assignments, k~.", "labels": [], "entities": []}, {"text": "Kappa figures higher than 0.8 correspond to good agreement; kappa figures higher than 0.6 correspond to acceptable agreement.", "labels": [], "entities": [{"text": "agreement", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9346818327903748}]}, {"text": "All kappa statistics were statistically significant at levels higher than a = 0.01.", "labels": [], "entities": []}, {"text": "In addition to the kappa statistics, table 1 also displays in parentheses the average number of data points per document, over which the kappa statistics were computed.", "labels": [], "entities": []}, {"text": "For each pair of Japanese-English discourse structures, we also built manually an alignment file, which specified in the notation discussed on page 1 the correspondence between the edus of the Japanese text and the edus of its English translation.", "labels": [], "entities": []}, {"text": "We computed the similarity between English and Japanese discourse trees using labeled recall and precision figures that reflected the resemblance of tile Japanese and English discourse structures with respect to their assignment of edu boundaries, hierarchical spans, nuclearity, and rhetorical relations.", "labels": [], "entities": [{"text": "recall", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.9105393886566162}, {"text": "precision", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9783034920692444}]}, {"text": "Because the trees we compared differ from one language to the other in the number of elementary units, the order of these units, and the way the units are grouped recursively into discourse spans, we computed two types of recall and precision figures.", "labels": [], "entities": [{"text": "recall", "start_pos": 222, "end_pos": 228, "type": "METRIC", "confidence": 0.9987146854400635}, {"text": "precision", "start_pos": 233, "end_pos": 242, "type": "METRIC", "confidence": 0.99069744348526}]}, {"text": "In computing Position-Dependent (P-D) recall and precision figures, a Japanese span was considered to match an English span when the Japanese span contained all the Japanese edus that corresponded to tile edus in the English span, and when the Japanese and English spans appeared in tile same position with respect to the overall structure.", "labels": [], "entities": [{"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.8718776106834412}, {"text": "precision", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9952952265739441}]}, {"text": "For example, the English tree in is characterized by 10 subsentential spans:,,,,,,,,, and.", "labels": [], "entities": []}, {"text": "(Span subsumes 2 sentences, so it is not sub-sentential.)", "labels": [], "entities": []}, {"text": "The Japanese discourse tree has only 4 spans that could be matched in the same positions with English spans, namely spans,,, and.", "labels": [], "entities": []}, {"text": "Hence the similarity between the Japanese tree and the English tree with respect   In computing Position-Independent (P-I) recall and precision figures, even when a Japanese span \"floated\" during the translation to a position in the English tree that was different from the position in the initial tree, the P-I recall and precision figures were not affected.", "labels": [], "entities": [{"text": "precision", "start_pos": 134, "end_pos": 143, "type": "METRIC", "confidence": 0.9798315167427063}, {"text": "recall", "start_pos": 312, "end_pos": 318, "type": "METRIC", "confidence": 0.5710505843162537}, {"text": "precision", "start_pos": 323, "end_pos": 332, "type": "METRIC", "confidence": 0.9857719540596008}]}, {"text": "The Position-Independent figures reflect the intuition that if two trees tl and t2 both have a subtree t, tl and t2 are more similar than if they were if they didn't share any tree.", "labels": [], "entities": []}, {"text": "At the sentence level, we hence assume that if, for example, the syntactic structure of a relative clause is translated appropriately (even though it is not appropriately attached), this is better than translating wrongly that clause.", "labels": [], "entities": []}, {"text": "The Position-Independent figures offer a more optimistic metric for comparing discourse trees.", "labels": [], "entities": []}, {"text": "They span a wider range of values than the Position-Dependent figures, which enable a finer grained comparison, which in turn enables a better characterization of the differences between Japanese and English discourse structures.", "labels": [], "entities": []}, {"text": "When one takes an optimistic stance, for the spans at the sub-sentential level in the trees in the recall is 6/10 and the precision is 6/11 because in addition to spans,,, and, one can also match Japanese span to English span and Japanese span to Japanese span.", "labels": [], "entities": [{"text": "recall", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.9708849191665649}, {"text": "precision", "start_pos": 122, "end_pos": 131, "type": "METRIC", "confidence": 0.999061644077301}]}, {"text": "In order to provide a better estimate of how close two discourse trees were, we computed PositionDependent and -Independent recall and precision figures for the sentential level (where units are given by edus and spans are given by sets of edus or single sentences); paragraph level (where units are given by sentences and spans are given by sets of sentences or single paragraphs); and text level (where units are given by paragraphs and spans are given by sets of paragraphs).", "labels": [], "entities": [{"text": "recall", "start_pos": 124, "end_pos": 130, "type": "METRIC", "confidence": 0.8935308456420898}, {"text": "precision", "start_pos": 135, "end_pos": 144, "type": "METRIC", "confidence": 0.9970571994781494}]}, {"text": "These figures offer a detailed picture of how discourse structures and relations are mapped from one language to the other across all and English discourse structures discourse levels, from sentence to text.", "labels": [], "entities": []}, {"text": "The differences at the sentence level can be explained by differences between the syntactic structures of Japanese and English.", "labels": [], "entities": []}, {"text": "The differences at the paragraph and text levels have a purely rhetorical explanation.", "labels": [], "entities": []}, {"text": "As expected, when we computed the recall and precision figures with respect to the nuclearity and relation assignments, we also factored in the statuses and the rhetorical relations that labeled each pair of spans.", "labels": [], "entities": [{"text": "recall", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9991580247879028}, {"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9924342632293701}]}, {"text": "smnmarizes the results (P-D and P-I (R)ecall and (P)recision figures) for each level (Sentence, Paragraph, and Text).", "labels": [], "entities": []}, {"text": "The numbers in the \"Weighted Average\" line report averages of the Sentence-, Paragraph-, and Text-specific figures, weighted according to the number of units at each level.", "labels": [], "entities": []}, {"text": "The numbers in the \"All\" line reflect recall and precision figures computed across the entire trees, with no attention paid to sentence and paragraph boundaries.", "labels": [], "entities": [{"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9987156391143799}, {"text": "precision", "start_pos": 49, "end_pos": 58, "type": "METRIC", "confidence": 0.9946743249893188}]}, {"text": "Given the significantly different syntactic structures of Japanese and English, we were not surprised by the low recall and precision results that reflect the similarity between discourse trees built below the sentence level.", "labels": [], "entities": [{"text": "recall", "start_pos": 113, "end_pos": 119, "type": "METRIC", "confidence": 0.9989064931869507}, {"text": "precision", "start_pos": 124, "end_pos": 133, "type": "METRIC", "confidence": 0.997542142868042}]}, {"text": "However, as shows, there are significant differences between discourse trees at the paragraph and text levels as well.", "labels": [], "entities": []}, {"text": "For exampie, the Position-Independent figures show that only about 62% of the sentences and only about 53% of the hierarchical spans built across sentences could be matched between the two corpora.", "labels": [], "entities": [{"text": "exampie", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.9385873079299927}]}, {"text": "When one looks at the status and rhetorical relations associated with the spans built across sentences at the paragraph level, the P-I recall and precision figures drop to about 43% and 35% respectively.", "labels": [], "entities": [{"text": "P-I", "start_pos": 131, "end_pos": 134, "type": "METRIC", "confidence": 0.9451956748962402}, {"text": "recall", "start_pos": 135, "end_pos": 141, "type": "METRIC", "confidence": 0.820614218711853}, {"text": "precision", "start_pos": 146, "end_pos": 155, "type": "METRIC", "confidence": 0.9986329674720764}]}, {"text": "The differences in recall and precision are explained both by differences in the way information is packaged into paragraphs in the two languages and the way it is structured rhetorically both within and above the paragraph level.", "labels": [], "entities": [{"text": "recall", "start_pos": 19, "end_pos": 25, "type": "METRIC", "confidence": 0.9970694184303284}, {"text": "precision", "start_pos": 30, "end_pos": 39, "type": "METRIC", "confidence": 0.998902440071106}]}, {"text": "These results strongly suggest that if one attempts to translate Japanese into English on a sentence-bysentence basis, it is likely that the resulting text will be unnatural from a discourse perspective.", "labels": [], "entities": []}, {"text": "For example, if some information rendered using a CON-TRAST relation in Japanese is rendered using an ELABORATION relation in English, it would be inappropriate to use a discourse marker like \"but\" in the English translation, although that would be consistent with the Japanese discourse structure.", "labels": [], "entities": []}, {"text": "An inspection of the rhetorical mappings between Japanese and English revealed that some Japanese rhetorical renderings are consistently mapped into one or a few preferred renderings in English.", "labels": [], "entities": []}, {"text": "For example, 34 of 115 CONTRAST relations in the Japanese texts are mapped into CONTRAST relations in English; 27 become nuclei of relations such as ANTITHE-SIS and CONCESSION, 14 are translated as COMPAR-ISON relations, 6 as satellites of CONCESSION relations, 5 as LIST relations, etc.", "labels": [], "entities": [{"text": "ANTITHE-SIS", "start_pos": 149, "end_pos": 160, "type": "METRIC", "confidence": 0.8606688380241394}]}, {"text": "Our goal is to learn these systematic discourse mapping rules and exploit them in a machine translation context.", "labels": [], "entities": [{"text": "machine translation context", "start_pos": 84, "end_pos": 111, "type": "TASK", "confidence": 0.7679347197214762}]}], "tableCaptions": [{"text": " Table 3: Performance of the classifiers", "labels": [], "entities": []}, {"text": " Table 5: Confusion matrix for the Main Action Type  classifier.", "labels": [], "entities": [{"text": "Main Action Type  classifier", "start_pos": 35, "end_pos": 63, "type": "TASK", "confidence": 0.4965869188308716}]}]}