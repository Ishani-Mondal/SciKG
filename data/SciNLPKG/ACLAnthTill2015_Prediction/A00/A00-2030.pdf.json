{"title": [{"text": "A Novel Use of Statistical Parsing to Extract Information from Text", "labels": [], "entities": [{"text": "Statistical Parsing", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.8851627111434937}]}], "abstractContent": [{"text": "Since 1995, a few statistical parsing algorithms have demonstrated a breakthrough in parsing accuracy, as measured against the UPenn TREEBANK as a gold standard.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.5155088752508163}, {"text": "parsing", "start_pos": 85, "end_pos": 92, "type": "TASK", "confidence": 0.9794330596923828}, {"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9612864851951599}, {"text": "UPenn", "start_pos": 127, "end_pos": 132, "type": "DATASET", "confidence": 0.7410207986831665}, {"text": "TREEBANK", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.8236016035079956}]}, {"text": "In this paper we report adapting a lexicalized, probabilistic context-free parser to information extraction and evaluate this new technique on MUC-7 template elements and template relations.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 85, "end_pos": 107, "type": "TASK", "confidence": 0.8183779418468475}]}], "introductionContent": [{"text": "Since 1995, a few statistical parsing algorithms) demonstrated a breakthrough in parsing accuracy, as measured against the University of Pennsylvania TREEBANK as a gold standard.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 18, "end_pos": 37, "type": "TASK", "confidence": 0.5157397091388702}, {"text": "parsing", "start_pos": 81, "end_pos": 88, "type": "TASK", "confidence": 0.9815046191215515}, {"text": "accuracy", "start_pos": 89, "end_pos": 97, "type": "METRIC", "confidence": 0.9553123116493225}, {"text": "TREEBANK", "start_pos": 150, "end_pos": 158, "type": "METRIC", "confidence": 0.9691975116729736}]}, {"text": "Yet, relatively few have embedded one of these algorithms in a task.", "labels": [], "entities": []}, {"text": "Chiba, (1999) was able to use such a parsing algorithm to reduce perplexity with the long term goal of improved speech recognition.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.7890430092811584}]}, {"text": "In this paper, we report adapting a lexicalized, probabilistic context-free parser with head rules (LPCFG-HR) to information extraction.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 113, "end_pos": 135, "type": "TASK", "confidence": 0.8477419912815094}]}, {"text": "The technique was benchmarked in the Seventh Message Understanding Conference (MUC-7) in 1998.", "labels": [], "entities": [{"text": "Seventh Message Understanding Conference (MUC-7) in 1998", "start_pos": 37, "end_pos": 93, "type": "TASK", "confidence": 0.4643033461438285}]}, {"text": "Several technical challenges confronted us and were solved: \u2022 How could the limited semantic interpretation required in information extraction be integrated into the statistical learning algorithm?", "labels": [], "entities": [{"text": "information extraction", "start_pos": 120, "end_pos": 142, "type": "TASK", "confidence": 0.7602351307868958}]}, {"text": "We were able to integrate both syntactic and semantic information into the parsing process, thus avoiding potential errors of syntax first followed by semantics.", "labels": [], "entities": []}, {"text": "\u2022 Would TREEBANKing of the variety of news sources in MUC-7 be required?", "labels": [], "entities": [{"text": "TREEBANKing", "start_pos": 8, "end_pos": 19, "type": "METRIC", "confidence": 0.9881794452667236}, {"text": "MUC-7", "start_pos": 54, "end_pos": 59, "type": "DATASET", "confidence": 0.9132540225982666}]}, {"text": "Or could the University of Pennsylvania's TREEBANK on Wall Street Journal adequately train the algorithm for New York Times newswire, which includes dozens of newspapers?", "labels": [], "entities": [{"text": "TREEBANK", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9830307960510254}, {"text": "Wall Street Journal", "start_pos": 54, "end_pos": 73, "type": "DATASET", "confidence": 0.9285553296407064}]}, {"text": "Manually creating sourcespecific training data for syntax was not required.", "labels": [], "entities": []}, {"text": "Instead, our parsing algorithm, trained on the UPenn TREEBANK, was run on the New York Times source to create unsupervised syntactic training which was constrained to be consistent with semantic annotation.", "labels": [], "entities": [{"text": "UPenn", "start_pos": 47, "end_pos": 52, "type": "DATASET", "confidence": 0.7983593344688416}, {"text": "TREEBANK", "start_pos": 53, "end_pos": 61, "type": "METRIC", "confidence": 0.7820205092430115}, {"text": "New York Times source", "start_pos": 78, "end_pos": 99, "type": "DATASET", "confidence": 0.7041217312216759}]}, {"text": "* Would semantic annotation require computational linguists?", "labels": [], "entities": [{"text": "semantic annotation", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.9037638306617737}]}, {"text": "We were able to specify relatively simple guidelines that students with no training in computational linguistics could annotate.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our system for MUC-7 consisted of the sentential model described in this paper, coupled with a simple probability model for cross-sentence merging.", "labels": [], "entities": [{"text": "MUC-7", "start_pos": 15, "end_pos": 20, "type": "TASK", "confidence": 0.8954702019691467}, {"text": "cross-sentence merging", "start_pos": 124, "end_pos": 146, "type": "TASK", "confidence": 0.7811273336410522}]}, {"text": "The evaluation results are summarized in.", "labels": [], "entities": []}, {"text": "In both Template Entity (TE) and Template Relation (TR), our system finished in second place among all entrants.", "labels": [], "entities": [{"text": "Template Entity (TE)", "start_pos": 8, "end_pos": 28, "type": "TASK", "confidence": 0.7678301811218262}, {"text": "Template Relation (TR)", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.7739801406860352}]}, {"text": "Nearly all of the work was done by the sentential model; disabling the cross-sentence model entirely reduced our overall F-Score by only 2 points.", "labels": [], "entities": [{"text": "F-Score", "start_pos": 121, "end_pos": 128, "type": "METRIC", "confidence": 0.9952024221420288}]}], "tableCaptions": []}