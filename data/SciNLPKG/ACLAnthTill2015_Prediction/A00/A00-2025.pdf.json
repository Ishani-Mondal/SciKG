{"title": [{"text": "Minimizing Word Error Rate in Textual Summaries of Spoken Language", "labels": [], "entities": [{"text": "Minimizing Word Error Rate", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8165688067674637}, {"text": "Textual Summaries of Spoken Language", "start_pos": 30, "end_pos": 66, "type": "TASK", "confidence": 0.7706552565097808}]}], "abstractContent": [{"text": "Automatic generation of text summaries for spoken language faces the problem of containing incorrect words and passages due to speech recognition errors.", "labels": [], "entities": [{"text": "generation of text summaries", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.740110769867897}]}, {"text": "This paper describes comparative experiments where passages with higher speech recognizer confidence scores are favored in the ranking process.", "labels": [], "entities": [{"text": "speech recognizer", "start_pos": 72, "end_pos": 89, "type": "TASK", "confidence": 0.6490490883588791}]}, {"text": "Results show that a relative word error rate reduction of over 10% can be achieved while at the same time the accuracy of the summary improves markedly.", "labels": [], "entities": [{"text": "word error rate reduction", "start_pos": 29, "end_pos": 54, "type": "METRIC", "confidence": 0.7551603019237518}, {"text": "accuracy", "start_pos": 110, "end_pos": 118, "type": "METRIC", "confidence": 0.9989111423492432}]}], "introductionContent": [{"text": "The amount of audio data on-line has been growing rapidly in recent years, and so methods for efficiently indexing and retrieving non-textual information have become increasingly important (see, e.g., the TREC-7 branch for \"Spoken Document Retrieval\" ().", "labels": [], "entities": [{"text": "Spoken Document Retrieval\"", "start_pos": 224, "end_pos": 250, "type": "TASK", "confidence": 0.8487917631864548}]}, {"text": "One way of compressing audio information is the automatic creation of textual summaries which can be skimmed much faster and stored much more efficiently than the audio itself.", "labels": [], "entities": []}, {"text": "There has been plenty of research in the area of summarizing written language (see) fora comprehensive overview).", "labels": [], "entities": [{"text": "summarizing written language", "start_pos": 49, "end_pos": 77, "type": "TASK", "confidence": 0.9045267303784689}]}, {"text": "So far, however, very little attention has been given to the question how to create and evaluate a summary of spoken audio based on automatically generated transcripts from a speech recognizer.", "labels": [], "entities": []}, {"text": "One fundamental problem with those summaries is that they contain incorrectly recognized words, i.e., the original text is to some extent \"distorted\".", "labels": [], "entities": []}, {"text": "Several research groups have developed interactive \"browsing\" tools, where audio (and possibly video) can be accessed together with various types of textual information (transcripts, summaries) via a graphical user interface ().", "labels": [], "entities": []}, {"text": "With these tools, the problem of misrecognitions is alleviated in the sense that the user can always easily listen to the audio recording corresponding to a passage in a textual summary.", "labels": [], "entities": []}, {"text": "In some instances, however, this approach may not be feasible or too expensive to pursue, and a short, stand-alone textual representation of the spoken audio maybe preferred or even required.", "labels": [], "entities": []}, {"text": "This paper addresses in particular this latter case and (a) explores means of making textual summaries less distorted (i.e., reducing their word error rate (WElt)), and (b) assesses how the accuracy of the summaries changes when methods for word error rate reduction are applied.", "labels": [], "entities": [{"text": "word error rate (WElt))", "start_pos": 140, "end_pos": 163, "type": "METRIC", "confidence": 0.8386750469605128}, {"text": "accuracy", "start_pos": 190, "end_pos": 198, "type": "METRIC", "confidence": 0.9966913461685181}, {"text": "word error rate reduction", "start_pos": 241, "end_pos": 266, "type": "TASK", "confidence": 0.5415635257959366}]}, {"text": "Summary accuracy will be a function of how much relevant information is present in the sun'mary.", "labels": [], "entities": [{"text": "Summary", "start_pos": 0, "end_pos": 7, "type": "METRIC", "confidence": 0.971595823764801}, {"text": "accuracy", "start_pos": 8, "end_pos": 16, "type": "METRIC", "confidence": 0.8877925276756287}]}, {"text": "Our results from experiments on four television shows with multiple speakers show that it is possible to reduce word error rate while at the same time also improving the accuracy of the summary.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 112, "end_pos": 127, "type": "METRIC", "confidence": 0.6511438290278116}, {"text": "accuracy", "start_pos": 170, "end_pos": 178, "type": "METRIC", "confidence": 0.9986271858215332}]}, {"text": "Furthermore, this paper presents a novel method for evaluation of textual summaries from spoken language data.", "labels": [], "entities": [{"text": "evaluation of textual summaries from spoken language", "start_pos": 52, "end_pos": 104, "type": "TASK", "confidence": 0.6811116550649915}]}, {"text": "The paper is organized as follows: In the next : section, we review related work on spoken language summarization.", "labels": [], "entities": [{"text": "spoken language summarization", "start_pos": 84, "end_pos": 113, "type": "TASK", "confidence": 0.6375852425893148}]}, {"text": "In section 3 we describe our sum: marizer.", "labels": [], "entities": [{"text": "marizer", "start_pos": 34, "end_pos": 41, "type": "METRIC", "confidence": 0.9966139197349548}]}, {"text": "Next, we present and discuss our proposal for an audio summarization evaluation metric (section 4).", "labels": [], "entities": [{"text": "audio summarization evaluation", "start_pos": 49, "end_pos": 79, "type": "TASK", "confidence": 0.6244826118151346}]}, {"text": "In section 5 we describe the Corpus that we use for our experiments and how it was annotated.", "labels": [], "entities": []}, {"text": "Sections 6 and 7 describe experixnents on both hu ....", "labels": [], "entities": []}, {"text": "man and machine generated transcripts of the audio data.", "labels": [], "entities": []}, {"text": "Finally, we discuss and summarize the results in sections 8 and 9.", "labels": [], "entities": []}], "datasetContent": [{"text": "Using the same summarizer as before, we now created summaries from ASR transcripts.", "labels": [], "entities": []}, {"text": "Additionally to the summary accuracy, we evaluate now also the WER for each evaluation point.", "labels": [], "entities": [{"text": "summary", "start_pos": 20, "end_pos": 27, "type": "METRIC", "confidence": 0.9179027080535889}, {"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.8531520366668701}, {"text": "WER", "start_pos": 63, "end_pos": 66, "type": "METRIC", "confidence": 0.997401237487793}]}, {"text": "Again, we ran a series of experiments for different parameters of the MMR formula (if=log, smax, freq; with/without normalization).", "labels": [], "entities": [{"text": "MMR", "start_pos": 70, "end_pos": 73, "type": "TASK", "confidence": 0.7812937498092651}]}, {"text": "As before, we achieved the best results for non normalized scores and tf=log.", "labels": [], "entities": []}, {"text": "We varied a from 0.0 to 10.0 to see how much of an effect we would get from the \"boosting\" of turns with many high confidence scores (see equations 5 and 6).", "labels": [], "entities": []}, {"text": "The ExP formula yielded better results than MULl?, the optimum for ExP was reached for = 3.0 with a WER of 26.6%, an absolute improvement of over 8% over the average of WER=35.1% for the complete ASR transcripts (non-summarized).", "labels": [], "entities": [{"text": "ExP", "start_pos": 67, "end_pos": 70, "type": "METRIC", "confidence": 0.7774176597595215}, {"text": "WER", "start_pos": 100, "end_pos": 103, "type": "METRIC", "confidence": 0.9982573390007019}, {"text": "WER", "start_pos": 169, "end_pos": 172, "type": "METRIC", "confidence": 0.9929863810539246}]}, {"text": "The summarization accuracy peaks at 0.47, a 9% absolute improvement over the a = 0.0-baseline and only about 5% absolute lower than for reference summaries and).", "labels": [], "entities": [{"text": "summarization", "start_pos": 4, "end_pos": 17, "type": "TASK", "confidence": 0.9552185535430908}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9827179312705994}]}, {"text": "When we compare the baseline of ~ = 0.0 (i.e., no \u00b0If we use non-normalized scores, the value of the MMR-X does not have any measurable effect; we assigned it to be 0.95 for all subsequent experiments.", "labels": [], "entities": [{"text": "MMR-X", "start_pos": 101, "end_pos": 106, "type": "DATASET", "confidence": 0.6182315945625305}]}, {"text": "Results for the MULT formula confirm this trend, but it is considerably weaker: approximately 6% WER reduction and 14% accuracy improvement for c~ = 10.0 over the c~ = 0.0 baseline.", "labels": [], "entities": [{"text": "MULT", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.5939680337905884}, {"text": "WER reduction", "start_pos": 97, "end_pos": 110, "type": "METRIC", "confidence": 0.9540940821170807}, {"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9995001554489136}]}, {"text": "An appendix (section 11) provides an example of actual summaries generated by our system for the first topical segment of the BACK conversation.", "labels": [], "entities": [{"text": "BACK conversation", "start_pos": 126, "end_pos": 143, "type": "TASK", "confidence": 0.6099944710731506}]}, {"text": "It illustrates how WER reduction and summary accuracy improvement can be achieved by using our confidence boosting method.", "labels": [], "entities": [{"text": "WER reduction", "start_pos": 19, "end_pos": 32, "type": "TASK", "confidence": 0.7801958620548248}, {"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.8888190984725952}]}], "tableCaptions": [{"text": " Table 1: Pearson r correlation between WER and confidence scores", "labels": [], "entities": [{"text": "Pearson r correlation between WER and confidence scores", "start_pos": 10, "end_pos": 65, "type": "METRIC", "confidence": 0.7664709836244583}]}, {"text": " Table 2: Characteristics of the corpus", "labels": [], "entities": []}, {"text": " Table 3: Reference summarization accuracy of MMR  o~  summaries", "labels": [], "entities": [{"text": "summarization", "start_pos": 20, "end_pos": 33, "type": "TASK", "confidence": 0.9347436428070068}, {"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.8983498811721802}, {"text": "MMR", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.904970109462738}, {"text": "summaries", "start_pos": 55, "end_pos": 64, "type": "TASK", "confidence": 0.35503578186035156}]}, {"text": " Table 4: Effect of a on summary accuracy vs. WER (in %) transcripts with ExP and MULl\" boosting methods", "labels": [], "entities": [{"text": "summary", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.853499710559845}, {"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.8025420904159546}, {"text": "WER", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.9952521324157715}, {"text": "MULl", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.9328615069389343}]}, {"text": " Table 6: Relative summary accuracy, WER, and se- lected turns by the summarizer for (a) no boosting  and (b) P.XP boosting.", "labels": [], "entities": [{"text": "summary", "start_pos": 19, "end_pos": 26, "type": "METRIC", "confidence": 0.6796572804450989}, {"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.882034182548523}, {"text": "WER", "start_pos": 37, "end_pos": 40, "type": "METRIC", "confidence": 0.9980828762054443}, {"text": "P.XP boosting", "start_pos": 110, "end_pos": 123, "type": "TASK", "confidence": 0.7492731511592865}]}, {"text": " Table 7: Average relevance scores, WER, and confi- dence values for the five turns of BACK'S first topical  segment.", "labels": [], "entities": [{"text": "Average relevance scores", "start_pos": 10, "end_pos": 34, "type": "METRIC", "confidence": 0.8401891986529032}, {"text": "WER", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.9977664947509766}, {"text": "BACK'S first topical  segment", "start_pos": 87, "end_pos": 116, "type": "TASK", "confidence": 0.8653023540973663}]}]}