{"title": [{"text": "A Divide-and-Conquer Strategy for Shallow Parsing of German Free Texts", "labels": [], "entities": [{"text": "Shallow Parsing of German Free Texts", "start_pos": 34, "end_pos": 70, "type": "TASK", "confidence": 0.8034719328085581}]}], "abstractContent": [{"text": "We present a divide-and-conquer strategy based on finite state technology for shallow parsing of real-world German texts.", "labels": [], "entities": [{"text": "shallow parsing of real-world German texts", "start_pos": 78, "end_pos": 120, "type": "TASK", "confidence": 0.7592877944310507}]}, {"text": "Ina first phase only the topo-logical structure of a sentence (i.e., verb groups, subclauses) are determined.", "labels": [], "entities": []}, {"text": "Ina second phase the phrasal grammars are applied to the contents of the different fields of the main and sub-clauses.", "labels": [], "entities": []}, {"text": "Shallow parsing is supported by suitably configured prepro-cessing, including: morphological and on-line compound analysis, efficient POS-filtering, and named entity recognition.", "labels": [], "entities": [{"text": "Shallow parsing", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.6419807374477386}, {"text": "named entity recognition", "start_pos": 153, "end_pos": 177, "type": "TASK", "confidence": 0.7075868348280588}]}, {"text": "The whole approach proved to be very useful for processing of free word order languages like German.", "labels": [], "entities": []}, {"text": "Especially for the divide-and-conquer parsing strategy we obtained an f-measure of 87.14% on unseen data.", "labels": [], "entities": [{"text": "divide-and-conquer parsing", "start_pos": 19, "end_pos": 45, "type": "TASK", "confidence": 0.654555469751358}, {"text": "f-measure", "start_pos": 70, "end_pos": 79, "type": "METRIC", "confidence": 0.9762899279594421}]}], "introductionContent": [{"text": "Current information extraction (IE) systems are quite successful in efficient processing of large free text collections due to the fact that they can provide a partial understanding of specific types of text with a certain degree of partial accuracy using fast and robust language processing strategies (basically finite state technology).", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 8, "end_pos": 35, "type": "TASK", "confidence": 0.8772651195526123}, {"text": "accuracy", "start_pos": 241, "end_pos": 249, "type": "METRIC", "confidence": 0.9793516397476196}]}, {"text": "They have been \"made sensitive\" to certain key pieces of information and thereby provide an easy means to skip text without deep analysis.", "labels": [], "entities": []}, {"text": "The majority of existing IE systems are applied to English text, but there are now a number of systems which process other languages as well (e.g., German (),) or Japanese ().", "labels": [], "entities": []}, {"text": "The majority of current systems perform a partial parsing approach using only very few general syntactic knowledge for the identification of nominal and prepositional phrases and verb groups.", "labels": [], "entities": [{"text": "identification of nominal and prepositional phrases and verb groups", "start_pos": 123, "end_pos": 190, "type": "TASK", "confidence": 0.823699865076277}]}, {"text": "The combination of such units is then performed by means of domain-specific templates.", "labels": [], "entities": []}, {"text": "Usually, these templates are triggered by domain-specific predicates attached only to a relevant subset of verbs which express domain-specific selectional restrictions for possible argument fillers.", "labels": [], "entities": []}, {"text": "In most of the well-known shallow text processing systems and) cascaded chunk parsers are used which perform clause recognition after fragment recognition following a bottom-up style as described in (Abne), 1996).", "labels": [], "entities": [{"text": "clause recognition", "start_pos": 109, "end_pos": 127, "type": "TASK", "confidence": 0.8581424355506897}, {"text": "fragment recognition", "start_pos": 134, "end_pos": 154, "type": "TASK", "confidence": 0.6645261198282242}]}, {"text": "We have also developed a similar bottomup strategy for the processing of German texts, cf. (. However, the main problem we experienced using the bottom-up strategy was insufficient robustness: because the parser depends on the lower phrasal recognizers, its performance is heavily influenced by their respective performance.", "labels": [], "entities": []}, {"text": "As a consequence, the parser frequently wasn't able to process structurally simple sentences, because they contained, for example, highly complex nominal phrases, as in the following example: \"[Die vom Bundesgerichtshof und den Wettbewerbshfitern als Verstofi gegen das Kartellverbot gegeiflelte zentrale TVVermarktung] ist g~ngige Praxis.\"", "labels": [], "entities": []}, {"text": "Central television raarketing, censured by the German Federal High Court and the guards against unfair competition as an infringement of anti-cartel legislation, is common practice.", "labels": [], "entities": []}, {"text": "During free text processing it might be not possible (or even desirable) to recognize such a phrase completely.", "labels": [], "entities": []}, {"text": "However, if we assume that domain-specific templates are associated with certain verbs or verb groups which trigger template filling, then it will be very difficult to find the appropriate fillers without knowing the correct clause structure.", "labels": [], "entities": [{"text": "template filling", "start_pos": 116, "end_pos": 132, "type": "TASK", "confidence": 0.8061884343624115}]}, {"text": "Furthermore in a sole bottom-up approach some ambiguities -for example relative pronouns -can't be resolved without introducing much underspecification into the intermediate structures.", "labels": [], "entities": []}, {"text": "Therefore we propose the following divide-andconquer parsing strategy: Ina first phase only the verb groups and the topological structure of a sentence according to the linguistic field the- This information couldn't be verified by the Border Police, Kinkel spoke of horrible figures that he didn't believe.", "labels": [], "entities": [{"text": "divide-andconquer parsing", "start_pos": 35, "end_pos": 60, "type": "TASK", "confidence": 0.7496928870677948}, {"text": "Border Police", "start_pos": 236, "end_pos": 249, "type": "DATASET", "confidence": 0.9542512595653534}]}], "datasetContent": [{"text": "Due to the limited space, we concentrate on the evaluation of the topological structure.", "labels": [], "entities": []}, {"text": "An evaluation of the other components (based on a subset of 20.000 tokens of the mentioned corpus from the \"Wirtschaftswoche\", see below) yields: From the 93,89% of the tokens which were identified by the morphological component as valid word forms, 95,23% got a unique POS-assignment with an accuracy of 97,9%.", "labels": [], "entities": [{"text": "POS-assignment", "start_pos": 270, "end_pos": 284, "type": "METRIC", "confidence": 0.9566468000411987}, {"text": "accuracy", "start_pos": 293, "end_pos": 301, "type": "METRIC", "confidence": 0.9990144968032837}]}, {"text": "An initial evaluation on the same subset yielded a precision of 95.77% and a recall of 85% (90.1% F-measure) for our current named entity finder.", "labels": [], "entities": [{"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9991575479507446}, {"text": "recall", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.9996141195297241}, {"text": "F-measure", "start_pos": 98, "end_pos": 107, "type": "METRIC", "confidence": 0.9986163377761841}]}, {"text": "Evaluation of the compound analysis of nouns, i.e. how often a morphosyntactical correct segmentation was found yield: Based on the 20.000 tokens, 1427 compounds are found, where 1417 have the correct segmentation (0.9929% precision).", "labels": [], "entities": [{"text": "precision", "start_pos": 223, "end_pos": 232, "type": "METRIC", "confidence": 0.9961082339286804}]}, {"text": "On a smaller subset of 1000 tokens containing 102 compounds, 101 correct segmentations where found (0.9901% recall), which is a quite promising result.", "labels": [], "entities": [{"text": "recall", "start_pos": 108, "end_pos": 114, "type": "METRIC", "confidence": 0.9993140697479248}]}, {"text": "An evaluation of simple NPs yielded a recall of 0.7611% and precision of 0.9194%.", "labels": [], "entities": [{"text": "recall", "start_pos": 38, "end_pos": 44, "type": "METRIC", "confidence": 0.9997513890266418}, {"text": "precision", "start_pos": 60, "end_pos": 69, "type": "METRIC", "confidence": 0.9997755885124207}]}, {"text": "The low recall was mainly because of unknown words.", "labels": [], "entities": [{"text": "recall", "start_pos": 8, "end_pos": 14, "type": "METRIC", "confidence": 0.9995887875556946}]}, {"text": "During the 2nd and 5th of July 1999 a test corpus of 43 messages from different press releases (viz.", "labels": [], "entities": []}, {"text": "DEUTSCHE PREESSEAGENTUR (dpa), ASSOCIATED PRESS (ap) and REUTERS) and different domains (equal distribution of politics, business, sensations) was collected.", "labels": [], "entities": [{"text": "DEUTSCHE", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9529290795326233}, {"text": "ASSOCIATED PRESS (ap)", "start_pos": 31, "end_pos": 52, "type": "METRIC", "confidence": 0.925707995891571}, {"text": "REUTERS", "start_pos": 57, "end_pos": 64, "type": "METRIC", "confidence": 0.9758710265159607}]}, {"text": "6 The corpus contains 400 sentences 6This data collection and evaluation was carried out by). with a total of 6306 words.", "labels": [], "entities": []}, {"text": "Note that it also was created after the DC-PARSER and all grammars were finally implemented.", "labels": [], "entities": [{"text": "DC-PARSER", "start_pos": 40, "end_pos": 49, "type": "DATASET", "confidence": 0.9310185313224792}]}, {"text": "shows the result of the evaluations (the F-measure was computed with /3=1).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9863529205322266}]}, {"text": "We used the correctness criteria as defined in.", "labels": [], "entities": []}, {"text": "The evaluation of each component was measured on the basis of the result of all previous components.", "labels": [], "entities": []}, {"text": "For the BC and MC module we also measured the performance by manually correcting the errors of the previous components (denoted as \"isolated evaluation\").", "labels": [], "entities": []}, {"text": "In most cases the difference between the precision and recall values is quite small, meaning that the modules keep a good balance between coverage and correctness.", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.99940025806427}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9891246557235718}, {"text": "coverage", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.988298773765564}, {"text": "correctness", "start_pos": 151, "end_pos": 162, "type": "METRIC", "confidence": 0.9024861454963684}]}, {"text": "Only in the case of the MC-module the difference is about 5%.", "labels": [], "entities": []}, {"text": "However, the result for the isolated evaluation of the MC-module suggests that this is mainly due to errors caused by previous components.", "labels": [], "entities": []}, {"text": "A more detailed analysis showed that the majority of errors were caused by mistakes in the preprocessing phase.", "labels": [], "entities": []}, {"text": "For example ten errors were caused by an ambiguity between different verb stems (only the first reading is chosen) and ten errors because of wrong POS-filtering.", "labels": [], "entities": []}, {"text": "Seven errors were caused by unknown verb forms, and in eight cases the parser failed because it could not properly handle the ambiguities of some word forms being either a separated verb prefix or adverb.", "labels": [], "entities": []}, {"text": "The evaluation has been performed with the Lisp-based version of SMES (cf. () by replacing the original bidirectional shallow buttom-up parsing module with the DC-PARSER.", "labels": [], "entities": [{"text": "SMES", "start_pos": 65, "end_pos": 69, "type": "TASK", "confidence": 0.7138901352882385}, {"text": "buttom-up parsing", "start_pos": 126, "end_pos": 143, "type": "TASK", "confidence": 0.6047824323177338}]}, {"text": "The average run-time per sentence (average length 26 words) is 0.57 sec.", "labels": [], "entities": []}, {"text": "A C++-version is nearly finished missing only the re-implementation of the base and main clause recognition phases, cf.).", "labels": [], "entities": [{"text": "main clause recognition", "start_pos": 84, "end_pos": 107, "type": "TASK", "confidence": 0.6335163513819376}]}, {"text": "The run-time behavior is already encouraging: processing of a German text document (a collection of business news articles from the \"Wirtschaftswoche\") of 197118 tokens (1.26 MB) needs 45 seconds on a PentiumII, 266 MHz, 128 RAM, which corresponds to 4380 tokens per second.", "labels": [], "entities": [{"text": "German text document (a collection of business news articles from the \"Wirtschaftswoche\") of 197118 tokens", "start_pos": 62, "end_pos": 168, "type": "DATASET", "confidence": 0.5551179250081381}]}, {"text": "Since this is an increase in speed-up by a factor > 20 compared to the Lisp-version, we expect to be able to process 75-100 sentences per second.", "labels": [], "entities": [{"text": "speed-up", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.964712917804718}]}], "tableCaptions": [{"text": " Table 1: Results of the evaluation of the topological structure", "labels": [], "entities": []}]}