{"title": [{"text": "Exploiting auxiliary distributions in stochastic unification-based grammars", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper describes a method for estimating conditional probability distributions over the parses of \"unification-based\" grammars which can utilize auxiliary distributions that are estimated by other means.", "labels": [], "entities": []}, {"text": "We show how this can be used to incorporate information about lexical selectional preferences gathered from other sources into Stochastic \"Unification-based\" Grammars (SUBGs).", "labels": [], "entities": []}, {"text": "While we apply this estimator to a Stochastic Lexical-Functional Grammar, the method is general, and should be applicable to stochastic versions of HPSGs, categorial grammars and transfor-mational grammars.", "labels": [], "entities": []}], "introductionContent": [{"text": "\"Unification-based\" Grammars (UBGs) can capture a wide variety of linguistically important syntactic and semantic constraints.", "labels": [], "entities": []}, {"text": "However, because these constraints can be non-local or context-sensitive, developing stochastic versions of UBGs and associated estimation procedures is not as straight-forward as it is for, e.g., PCFGs.", "labels": [], "entities": []}, {"text": "Recent work has shown how to define probability distributions over the parses of UBGs ( and efficiently estimate and use conditional probabilities for parsing).", "labels": [], "entities": []}, {"text": "Like most other practical stochastic grammar estimation procedures, this latter estimation procedure requires a parsed training corpus.", "labels": [], "entities": [{"text": "stochastic grammar estimation", "start_pos": 26, "end_pos": 55, "type": "TASK", "confidence": 0.659377247095108}]}, {"text": "Unfortunately, large parsed UBG corpora are not yet available.", "labels": [], "entities": []}, {"text": "This restricts the kinds of models one can realistically expect to be able to estimate.", "labels": [], "entities": []}, {"text": "For example, a model incorporating lexical selectional preferences of the kind described below might have tensor hundreds of thousands of parameters, which one could not reasonably attempt to estimate from a corpus with on the order of a thousand clauses.", "labels": [], "entities": []}, {"text": "However, statistical models of lexical selectional preferences can be estimated from very large corpora based on simpler syntactic structures, e.g., those produced by a shallow parser.", "labels": [], "entities": []}, {"text": "While there is undoubtedly disagreement between these simple syntactic structures and the syntactic structures produced by the UBG, one might hope that they are close enough for lexical information gathered from the simpler syntactic structures to be of use in defining a probability distribution over the UBG's structures.", "labels": [], "entities": []}, {"text": "In the estimation procedure described here, we call the probability distribution estimated from the larger, simpler corpus an auxiliary distribution.", "labels": [], "entities": []}, {"text": "Our treatment of auxiliary distributions is inspired by the treatment of reference distributions in presentation of Maximum Entropy estimation, but in our estimation procedure we simply regard the logarithm of each auxiliary distribution as another (real-valued) feature.", "labels": [], "entities": [{"text": "Maximum Entropy estimation", "start_pos": 116, "end_pos": 142, "type": "TASK", "confidence": 0.6160458127657572}]}, {"text": "Despite its simplicity, our approach seems to offer several advantages over the reference distribution approach.", "labels": [], "entities": []}, {"text": "First, it is straight-forward to utilize several auxiliary distributions simultaneously: each is treated as a distinct feature.", "labels": [], "entities": []}, {"text": "Second, each auxiliary distribution is associated with a parameter which scales its contribution to the final distribution.", "labels": [], "entities": []}, {"text": "In applications such as ours where the auxiliary distribution maybe of questionable relevance to the distribution we are trying to estimate, it seems reasonable to permit the estimation procedure to discount or even ignore the auxiliary distribution.", "labels": [], "entities": []}, {"text": "Finally, note that neither Jelinek's nor our estimation procedures require that an auxiliary or reference distribution Q be a prob-ability distribution; i.e., it is not necessary that Q(i2) --1, where f~ is the set of well-formed linguistic structures.", "labels": [], "entities": []}, {"text": "The rest of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews how exponential models can be defined over the parses of UBGs, gives a brief description of Stochastic LexicalFunctional Grammar, and reviews why maximum pseudo-likelihood estimation is both feasible and sufficient of parsing purposes.", "labels": [], "entities": []}, {"text": "Section 3 presents our new estimator, and shows how it is related to the minimization of the KullbackLeibler divergence between the conditional estimated and auxiliary distributions.", "labels": [], "entities": []}, {"text": "Section 4 describes the auxiliary distribution used in our experiments, and section 5 presents the results of those experiments.", "labels": [], "entities": []}], "datasetContent": [{"text": "Hadar Shemtov and Ron Kaplan at Xerox PARC provided us with two LFG parsed corpora called the Verbmobil corpus and the Homecentre corpus.", "labels": [], "entities": [{"text": "Xerox PARC", "start_pos": 32, "end_pos": 42, "type": "DATASET", "confidence": 0.8828595578670502}, {"text": "Verbmobil corpus", "start_pos": 94, "end_pos": 110, "type": "DATASET", "confidence": 0.8525935113430023}, {"text": "Homecentre corpus", "start_pos": 119, "end_pos": 136, "type": "DATASET", "confidence": 0.9704129993915558}]}, {"text": "These contain parse forests for each sentence (packed according to scheme described in), together with a manual annotation as to which parse is correct.", "labels": [], "entities": []}, {"text": "The Verbmobil corpus contains 540 sentences relating to appointment planning, while the Homecentre corpus contains 980 sentences from Xerox documentation on their \"homecentre\" multifunction devices.", "labels": [], "entities": [{"text": "Verbmobil corpus", "start_pos": 4, "end_pos": 20, "type": "DATASET", "confidence": 0.8820782005786896}, {"text": "appointment planning", "start_pos": 56, "end_pos": 76, "type": "TASK", "confidence": 0.704152300953865}, {"text": "Homecentre corpus", "start_pos": 88, "end_pos": 105, "type": "DATASET", "confidence": 0.9650545418262482}]}, {"text": "Xerox did not provide us with the base LFGs for intellectual property reasons, but from inspection of the parses :::::::::::::::::::::::::::: Different numbers of features were used with the two corpora because some of the features were generated semiautomatically (e.g., we introduced a feature for every attribute-value pair found in any feature structure), and \"pseudo-constant\" features (i.e., features whose values never differ on the parses of the same sentence) are discarded.", "labels": [], "entities": [{"text": "Xerox", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.94883131980896}]}, {"text": "We used 172 features in the SLFG for the Verbmobil corpus and 186 features in the SLFG for the Homecentre corpus.", "labels": [], "entities": [{"text": "Verbmobil corpus", "start_pos": 41, "end_pos": 57, "type": "DATASET", "confidence": 0.9535146951675415}, {"text": "Homecentre corpus", "start_pos": 95, "end_pos": 112, "type": "DATASET", "confidence": 0.9752908051013947}]}, {"text": "We used three additional auxiliary features derived from the lexical selectional preference model described in section 4.", "labels": [], "entities": []}, {"text": "These were defined in the following way be the number of times that the f-structure: appears as a subgraph of the f-structure of w, i.e., the number of times that a fills the grammatical role r of g.", "labels": [], "entities": []}, {"text": "We used the lexical model described in the last section to estimate P(alg , r), and defined our first auxiliary feature ft(w) = logP(g0) + Zn (g,r,a) where g0 is the predicate of the root feature structure.", "labels": [], "entities": []}, {"text": "The justification for this feature is that if f-structures were in fact a tree, ft(w) would be the (logarithm of) a probability distribution over them.", "labels": [], "entities": []}, {"text": "The auxiliary feature ft is defective in many ways.", "labels": [], "entities": []}, {"text": "Because LFG fstructures are DAGs with reentrancies rather than trees we double count certain arguments, soft is certainly not the logarithm of a probability distribution (which is why we stressed that our approach does not require an auxiliary distribution to be a distribution).", "labels": [], "entities": []}, {"text": "The number of governor-argument tuples found in different parses of the same sentence can vary markedly.", "labels": [], "entities": []}, {"text": "Since the conditional probabilities P(alg, r) are usually very small, we found that ft(w) was strongly related to the number of tuples found in w, so the parse with the smaller number of tuples usually obtains the higher fl score.", "labels": [], "entities": [{"text": "fl score", "start_pos": 221, "end_pos": 229, "type": "METRIC", "confidence": 0.9505268037319183}]}, {"text": "We tried to address this by adding two additional features.", "labels": [], "entities": []}, {"text": "We set fc(w) to be the number of tuples in w, i.e.: Then we set .Q(w) = h(w)/L(w), i.e.,/,(w) is the average log probability of a lexical dependency tuple under the auxiliary lexical distribution.", "labels": [], "entities": []}, {"text": "We performed our experiments with ft as the sole auxiliary distribution, and with ft, fe and fn as three auxiliary distributions.", "labels": [], "entities": []}, {"text": "Because our corpora were so small, we trained and tested these models using a 10-fold crossvalidation paradigm; the cumulative results are shown in.", "labels": [], "entities": []}, {"text": "On each fold we evaluated each model in two ways.", "labels": [], "entities": []}, {"text": "The correct parses measure simply counts the number of test sentences for which the estimated model assigns its maximum parse probability to the correct parse, with ties broken randomly.", "labels": [], "entities": []}, {"text": "The pseudolikelihood measure is the pseudo-likelihood of test set parses; i.e., the conditional probability of the test parses given their yields.", "labels": [], "entities": []}, {"text": "We actually report the negative log of this measure, so a smaller score corresponds to better performance here.", "labels": [], "entities": []}, {"text": "The correct parses measure is most closely related to parser performance, but the pseudolikelihood measure is more closely related to the quantity we are optimizing and maybe more relevant to applications where the parser has to return a certainty factor associated with each parse.", "labels": [], "entities": []}, {"text": "also provides the number of indistinguishable sentences under each model.", "labels": [], "entities": []}, {"text": "A sentence y is indistinguishable with respect to features f iff f(wc) : f(w'), where wc is the correct parse of y and wc ~ w IE ~(y), i.e., the feature values of correct parse of y are identical to the feature values of some other parse of y.", "labels": [], "entities": []}, {"text": "If a sentence is indistinguishable it is not possible to assign its correct parse a (conditional) probability higher than the (conditional) probability assigned to other parses, so all else being equal we would expect a SUBG with with fewer indistinguishable sentences to perform better than one with more.", "labels": [], "entities": []}, {"text": "Adding auxiliary features reduced the already low number of indistinguishable sentences in the Verbmobil corpus by only 11%, while it reduced the number of indistinguishable sentences in the Homecentre corpus by 24%.", "labels": [], "entities": [{"text": "Verbmobil corpus", "start_pos": 95, "end_pos": 111, "type": "DATASET", "confidence": 0.9538407027721405}, {"text": "Homecentre corpus", "start_pos": 191, "end_pos": 208, "type": "DATASET", "confidence": 0.983633816242218}]}, {"text": "This probably reflects the fact that the feature set was designed by inspecting only the Verbmobil corpus.", "labels": [], "entities": [{"text": "Verbmobil corpus", "start_pos": 89, "end_pos": 105, "type": "DATASET", "confidence": 0.9893400967121124}]}, {"text": "We must admit disappointment with these results.", "labels": [], "entities": []}, {"text": "Adding auxiliary lexical features improves the correct parses measure only slightly, and degrades rather than improves performance on the pseudo-likelihood measure.", "labels": [], "entities": []}, {"text": "Perhaps this is due to the fact that adding auxiliary features increases the dimensionality of the feature vector f, so the pseudo-likelihood scores with different numbers of features are not strictly comparable.", "labels": [], "entities": []}, {"text": "The small improvement in the correct parses measure is typical of the improvement we might expect to achieve by adding a \"good\" nonauxiliary feature, but given the importance usually placed on lexical dependencies in statistical models one might have expected more improvement.", "labels": [], "entities": []}, {"text": "Probably the poor performance is due in part to the fairly large differences between the parses from which the lexical dependencies were estimated and the parses produced by the LFG.", "labels": [], "entities": []}, {"text": "LFG parses are very detailed, and many ambiguities depend on the precise grammatical The effect of adding auxiliary lexical dependency features to a SLFG.", "labels": [], "entities": [{"text": "LFG parses", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.6210654973983765}]}, {"text": "The auxiliary features are described in the text.", "labels": [], "entities": []}, {"text": "The column labelled \"indistinguishable\" gives the number of indistinguishable sentences with respect to each feature set, while \"correct\" and \"-log PL\" give the correct parses and pseudo-likelihood measures respectively.", "labels": [], "entities": []}, {"text": "relationship holding between a predicate and its argument.", "labels": [], "entities": []}, {"text": "It could also be that better performance could be achieved if the lexical dependencies were estimated from a corpus more closely related to the actual test corpus.", "labels": [], "entities": []}, {"text": "For example, the verb feed in the Homecentre corpus is used in the sense of \"insert (paper into printer)\", which hardly seems to be a prototypical usage.", "labels": [], "entities": [{"text": "Homecentre corpus", "start_pos": 34, "end_pos": 51, "type": "DATASET", "confidence": 0.9833624064922333}]}, {"text": "Note that overall system performance is quite good; taking the unambiguous sentences into account the combined LFG parser and statistical model finds the correct parse for 73% of the Verbmobil test sentences and 80% of the Homecentre test sentences.", "labels": [], "entities": [{"text": "Verbmobil test sentences", "start_pos": 183, "end_pos": 207, "type": "DATASET", "confidence": 0.9013583660125732}, {"text": "Homecentre test sentences", "start_pos": 223, "end_pos": 248, "type": "DATASET", "confidence": 0.9754360914230347}]}, {"text": "On just the ambiguous sentences, our system selects the correct parse for 56% of the Verbmobil test sentences and 59% of the Homecentre test sentences.", "labels": [], "entities": [{"text": "Verbmobil test sentences", "start_pos": 85, "end_pos": 109, "type": "DATASET", "confidence": 0.8762580752372742}, {"text": "Homecentre test sentences", "start_pos": 125, "end_pos": 150, "type": "DATASET", "confidence": 0.9676381349563599}]}], "tableCaptions": []}