{"title": [{"text": "A Compact Architecture for Dialogue Management Based on Scripts ond Meta-Outputs", "labels": [], "entities": [{"text": "Dialogue Management", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.8031609952449799}]}], "abstractContent": [{"text": "We describe an architecture for spoken dialogue interfaces to semi-autonomous systems that transforms speech signals through successive representations of linguistic, dialogue, and domain knowledge.", "labels": [], "entities": []}, {"text": "Each step produces an output, and a meta-output describing the transformation, with an executable program in a simple scripting language as the final result.", "labels": [], "entities": []}, {"text": "The output/meta-output distinction permits perspicuous treatment of diverse tasks such as resolving pronouns, correcting user misconceptions, and optimizing scripts.", "labels": [], "entities": []}], "introductionContent": [{"text": "The basic task we consider in this paper is that of using spoken language to give commands to a semiautonomous robot or other similar system.", "labels": [], "entities": []}, {"text": "As evidence of the importance of this task in the NLP community note that the early, influential system SHRDLU) was intended to address just this type of problem.", "labels": [], "entities": []}, {"text": "More recent work on spoken language interfaces to semi-antonomous robots include SRrs Flakey robot ( and NCARArs InterBOT project (.", "labels": [], "entities": [{"text": "SRrs Flakey robot", "start_pos": 81, "end_pos": 98, "type": "DATASET", "confidence": 0.5000035464763641}, {"text": "NCARArs InterBOT project", "start_pos": 105, "end_pos": 129, "type": "DATASET", "confidence": 0.8563855091730753}]}, {"text": "A number of other systems have addressed part of the task.", "labels": [], "entities": []}, {"text": "CommandTalk (), Circuit Fix-It Shop and) are spoken language systems but they interface to simulation or help facilities rather than semi-autonomous agents.", "labels": [], "entities": [{"text": "CommandTalk", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.862447202205658}]}, {"text": "Jack's MOOse Lodge () takes text rather than speech as natural language input and the avatars being controlled are not semi-autonomous.", "labels": [], "entities": [{"text": "MOOse Lodge", "start_pos": 7, "end_pos": 18, "type": "DATASET", "confidence": 0.8404514193534851}]}, {"text": "Other researchers have considered particular aspects of the problem such as accounting for various aspects of actions.", "labels": [], "entities": []}, {"text": "In most of this and other related work the treatment is some variant of the following.", "labels": [], "entities": []}, {"text": "If there is a speech interface, the input speech signal is converted into text.", "labels": [], "entities": []}, {"text": "Text either from the recognizer or directly input by the user is then converted into some kind of logical formula, which abstractly represents the user's intended command; this formula is then fed into a command interpreter, which executes the command.", "labels": [], "entities": []}, {"text": "We do not think the standard treatment outlined above is in essence incorrect, but we do believe that, as it stands, it is in need of some modification.", "labels": [], "entities": []}, {"text": "This paper will in particular make three points.", "labels": [], "entities": []}, {"text": "First, we suggest that the output representation should not be regarded as a logical expression, but rather as a program in some kind of scripting language.", "labels": [], "entities": []}, {"text": "Second, we argue that it is not merely the case that the process of converting the input signal to the final representation can sometimes go wrong; rather, this is the normal course of events, and the interpretation process should be organized with that assumption in mind.", "labels": [], "entities": []}, {"text": "Third, we claim, perhaps surprisingly, that the first and second points are related.", "labels": [], "entities": []}, {"text": "These claims are elaborated in Section 2.", "labels": [], "entities": []}, {"text": "The remainder of the paper describes an architecture which addresses the issues outlined above, and which has been used to implement a prototype speech interface to a simulated semi-autonomous robot intended for deployment on the International Space Station.", "labels": [], "entities": []}, {"text": "Sections 3 and 4 present an overview of the implemented interface, focussing on representational issues relevant to dialogue management.", "labels": [], "entities": [{"text": "dialogue management", "start_pos": 116, "end_pos": 135, "type": "TASK", "confidence": 0.7802779078483582}]}, {"text": "Illustrative examples of interactions with the system are provided in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "Recall that the DM simulates evaluation of the plan before running it, in order to obtain relevant metainformation.", "labels": [], "entities": []}, {"text": "At plan execution time, plan actions result in changes to the world; at plan evaluation time, they result in simulated changes to the world and/or produce meta-outputs.", "labels": [], "entities": []}, {"text": "Conceptualizing plans as scripts rather than logicai formulas permits an elegant treatment of the execution/evaluation dichotomy.", "labels": [], "entities": []}, {"text": "There is one script interpreter, which functions both as a script executive and a script evaluator, and one set of rules which defines the procedural semantics of script actions.", "labels": [], "entities": []}, {"text": "Rules are parameterized by execution type which is either \"execute\" or \"evaluate\".", "labels": [], "entities": []}, {"text": "In \"evaluate\" mode, primitive actions modify a state vector which is threaded through the interpreter; in \"execute\" mode, they result in commands being sent to (real or simulated) effector agents.", "labels": [], "entities": []}, {"text": "Conversely, \"meta-information\" actions, such as presupposition failures, result in output being sent to the metaoutput stream in \"evaluate\" mode, and in a null action in \"execute\" mode.", "labels": [], "entities": []}, {"text": "The upshot is that a simple semantics can be assigned to rules like the following one, which defines the action of attempting to open a door which may already be open:,", "labels": [], "entities": []}], "tableCaptions": []}