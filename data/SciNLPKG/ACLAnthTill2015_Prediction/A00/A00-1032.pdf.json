{"title": [], "abstractContent": [{"text": "This paper proposes a framework of language independent morphological analysis and mainly concentrate on tokenization, the first process of morphological analysis.", "labels": [], "entities": [{"text": "language independent morphological analysis", "start_pos": 35, "end_pos": 78, "type": "TASK", "confidence": 0.6192204356193542}, {"text": "morphological analysis", "start_pos": 140, "end_pos": 162, "type": "TASK", "confidence": 0.7498043477535248}]}, {"text": "Although tokenization is usually not regarded as a difficult task inmost segmented languages such as English, there area number of problems in achieving precise treatment of lexical entries.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 9, "end_pos": 21, "type": "TASK", "confidence": 0.962632417678833}]}, {"text": "We first introduce the concept of morpho-fragments, which are intermediate units between characters and lexical entries.", "labels": [], "entities": []}, {"text": "We describe our approach to resolve problems arising in tokenization so as to attain a language independent morphological analyzer.", "labels": [], "entities": []}], "introductionContent": [{"text": "The first step in natural language processing is to identify words in a sentence.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 18, "end_pos": 45, "type": "TASK", "confidence": 0.6747951706250509}]}, {"text": "We call this process a morphological analysis.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.7455487251281738}]}, {"text": "Various languages exist in the world, and strategies for morphological analysis differ by types of language.", "labels": [], "entities": [{"text": "morphological analysis", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.6840919405221939}]}, {"text": "Conventionally, morphological analyzers have been developed in one analyzer for each language approach.", "labels": [], "entities": [{"text": "morphological analyzers", "start_pos": 16, "end_pos": 39, "type": "TASK", "confidence": 0.688489556312561}]}, {"text": "This is a language dependent approach.", "labels": [], "entities": []}, {"text": "In contrast, We propose a framework of language independent morphological analysis system.", "labels": [], "entities": [{"text": "language independent morphological analysis", "start_pos": 39, "end_pos": 82, "type": "TASK", "confidence": 0.6106185466051102}]}, {"text": "We employ one analyzer for any language approach.", "labels": [], "entities": []}, {"text": "This approach enables a rapid implementation of morphological analysis systems for new languages.", "labels": [], "entities": []}, {"text": "We define two types of written languages: one is a segmented language, and the other is a nonsegmented language.", "labels": [], "entities": []}, {"text": "In non-segmented languages such as Chinese and Japanese, since words are not separated by delimiters such as white spaces, tokenization is a important and difficult task.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 123, "end_pos": 135, "type": "TASK", "confidence": 0.9622617363929749}]}, {"text": "In segmented languages such as English, since words are seemingly separated by white spaces or punctuation marks, tokenization is regarded as a relatively easy task and little attention has been paid to.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 114, "end_pos": 126, "type": "TASK", "confidence": 0.9678061604499817}]}, {"text": "Therefore, each language dependent morphological analyzer has its own strategy for tokenization.", "labels": [], "entities": []}, {"text": "We calla string defined in the dictionary lexeme.", "labels": [], "entities": []}, {"text": "From an algorithmic point of view, tokenization is regarded as the process of converting an input stream of characters into a stream of lexemes.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 35, "end_pos": 47, "type": "TASK", "confidence": 0.9621789455413818}]}, {"text": "We assume that a morphological analysis consists of three processes: tokenization, dictionary lookup, and disambiguation.", "labels": [], "entities": []}, {"text": "Dictionary look-up gets a string and returns a set of lexemes with part-ofspeech information.", "labels": [], "entities": []}, {"text": "Disambiguation selects the most plausible sequence of lexemes by a use of a rule-base model or a hidden Markov model (HMM)).", "labels": [], "entities": []}, {"text": "Disambiguation i s already language independent, since it does not process strings directly and therefore will not betaken up.", "labels": [], "entities": []}, {"text": "On the other hand, tokenization and dictionary look-up are language dependent and shall be explained more in this paper.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 19, "end_pos": 31, "type": "TASK", "confidence": 0.9815142750740051}]}, {"text": "We consider problems concerning tokenization of segmented languages in Section 2.", "labels": [], "entities": [{"text": "tokenization of segmented languages", "start_pos": 32, "end_pos": 67, "type": "TASK", "confidence": 0.8657527416944504}]}, {"text": "To resolve these problem, we first apply the method of nonsegmented languages processing to segmented languages (Section 3).", "labels": [], "entities": []}, {"text": "However, we do not obtain a satisfactory result.", "labels": [], "entities": []}, {"text": "Then, we introduce the concept of morpho-fragments to generalize the method of non-segmented language processing (Section 4).", "labels": [], "entities": []}, {"text": "The proposed framework resolves most problems in tokenization, and an efficient language independent part-of-speech tagging becomes possible.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 49, "end_pos": 61, "type": "TASK", "confidence": 0.9774502515792847}, {"text": "part-of-speech tagging", "start_pos": 101, "end_pos": 123, "type": "TASK", "confidence": 0.6440330445766449}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results of Experiments", "labels": [], "entities": []}]}