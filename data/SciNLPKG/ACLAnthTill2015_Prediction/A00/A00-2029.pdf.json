{"title": [{"text": "Predicting Automatic Speech Recognition Performance Using Prosodic Cues", "labels": [], "entities": [{"text": "Predicting Automatic Speech Recognition", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.8645442128181458}]}], "abstractContent": [{"text": "In spoken dialogue systems, it is important fora system to know how likely a speech recognition hypothesis is to be correct, so it can reprompt for fresh input, or, in cases where many errors have occurred, change its interaction strategy or switch the caller to a human attendant.", "labels": [], "entities": [{"text": "speech recognition hypothesis", "start_pos": 77, "end_pos": 106, "type": "TASK", "confidence": 0.8014615178108215}]}, {"text": "We have discovered prosodic features which more accurately predict when a recognition hypothesis contains a word error than the acoustic confidence score thresholds traditionally used in automatic speech recognition.", "labels": [], "entities": [{"text": "acoustic confidence score thresholds", "start_pos": 128, "end_pos": 164, "type": "METRIC", "confidence": 0.7590126469731331}, {"text": "automatic speech recognition", "start_pos": 187, "end_pos": 215, "type": "TASK", "confidence": 0.7016678849856058}]}, {"text": "We present analytic results indicating that there are significant prosodic differences between correctly and incorrectly recognized turns in the TOOT train information corpus.", "labels": [], "entities": [{"text": "TOOT train information corpus", "start_pos": 145, "end_pos": 174, "type": "DATASET", "confidence": 0.8737658262252808}]}, {"text": "We then present machine learning results showing how the use of prosodic features to automatically predict correct versus incorrectly recognized turns improves over the use of acoustic confidence scores alone.", "labels": [], "entities": []}], "introductionContent": [{"text": "One of the central tasks of the dialogue manager inmost current spoken dialogue systems (SDSs) is error handling.", "labels": [], "entities": [{"text": "error handling", "start_pos": 98, "end_pos": 112, "type": "TASK", "confidence": 0.7156040221452713}]}, {"text": "The automatic speech recognition (ASR) component of such systems is prone to error, especially when the system has to operate in noisy conditions or when the domain of the system is large.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 4, "end_pos": 38, "type": "TASK", "confidence": 0.7895202040672302}]}, {"text": "Given that it is impossible to fully prevent ASR errors, it is important fora system to know how likely a speech recognition hypothesis is to be correct, so it can take appropriate action, since users have considerable difficulty correcting incorrect information that is presented by the system as true ().", "labels": [], "entities": [{"text": "ASR errors", "start_pos": 45, "end_pos": 55, "type": "TASK", "confidence": 0.8817844390869141}, {"text": "speech recognition hypothesis", "start_pos": 106, "end_pos": 135, "type": "TASK", "confidence": 0.7740586002667745}]}, {"text": "Such action may include verifying the user's input, reprompting for fresh input, or, in cases where many errors have occurred, changing the interaction strategy or switching the caller to a human attendant).", "labels": [], "entities": []}, {"text": "Traditionally, the decision to reject a recognition hypothesis is based on acoustic confidence score thresholds, which provide a reliability measure on the hypothesis and are set in the application.", "labels": [], "entities": [{"text": "acoustic confidence score thresholds", "start_pos": 75, "end_pos": 111, "type": "METRIC", "confidence": 0.7382427901029587}]}, {"text": "However, this process often fails, as there is no simple one-to-one mapping between low confidence scores and incorrect recognitions, and the setting of a rejection threshold is a matter of trial and error).", "labels": [], "entities": []}, {"text": "Also, some incorrect recognitions do not necessarily lead to misunderstandings at a conceptual level (e.g. \"a.m.\" recognized as \"in the morning\").", "labels": [], "entities": []}, {"text": "The current paper looks at prosody as one possible predictor of ASR performance.", "labels": [], "entities": [{"text": "ASR", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9964261651039124}]}, {"text": "ASR performance is known to vary based upon speaking style, speaker gender and age, native versus non-native speaker status, and, in general, the deviation of new speech from the training data.", "labels": [], "entities": [{"text": "ASR", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9791698455810547}]}, {"text": "Some of this variation is linked to prosody, as prosodic differences have been found to characterize differences in speaking style and idiosyncratic differences).", "labels": [], "entities": []}, {"text": "Several other studies () report that hyperarticulated speech, characterized by careful enunciation, slowed speaking rate, and increase in pitch and loudness, often occurs when users in human-machine interactions try to correct system errors.", "labels": [], "entities": []}, {"text": "Still others have shown that such speech also decreases recognition performance (.", "labels": [], "entities": [{"text": "recognition", "start_pos": 56, "end_pos": 67, "type": "TASK", "confidence": 0.9274942874908447}]}, {"text": "Prosodic features have also been shown to be effective in ranking recognition hypotheses, as a post-processing filter to score ASR hypotheses.", "labels": [], "entities": [{"text": "ranking recognition hypotheses", "start_pos": 58, "end_pos": 88, "type": "TASK", "confidence": 0.8729084730148315}, {"text": "ASR hypotheses", "start_pos": 127, "end_pos": 141, "type": "TASK", "confidence": 0.8949509263038635}]}, {"text": "In this paper we present results of empirical studies testing the hypothesis that prosodic features provide an important clue to ASR performance.", "labels": [], "entities": [{"text": "ASR", "start_pos": 129, "end_pos": 132, "type": "TASK", "confidence": 0.9971972703933716}]}, {"text": "We first present results comparing prosodic analyses of correctly and incorrectly recognized speaker turns in TOOT, an experimental SDS for obtaining train information over the phone.", "labels": [], "entities": [{"text": "TOOT", "start_pos": 110, "end_pos": 114, "type": "DATASET", "confidence": 0.8593763709068298}]}, {"text": "We then describe machine learning experiments based on these results that explore the predictive power of prosodic features alone and in combination with other automatically available information, including ASR confidence scores and recognized string.", "labels": [], "entities": [{"text": "ASR confidence scores", "start_pos": 207, "end_pos": 228, "type": "METRIC", "confidence": 0.7386255264282227}]}, {"text": "Our results indicate that there are significant prosodic differences between correctly and incorrectly recognized utterances.", "labels": [], "entities": []}, {"text": "These differences can in fact be used to pre-dict whether an utterance has been misrecognized, with a high degree of accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 117, "end_pos": 125, "type": "METRIC", "confidence": 0.9969931840896606}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Comparison of Misrecognized (WER>0)  vs. Recognized Turns by Prosodic Feature Across  Speakers.", "labels": [], "entities": [{"text": "WER>0)", "start_pos": 39, "end_pos": 45, "type": "METRIC", "confidence": 0.8885551244020462}]}, {"text": " Table 2: Comparison of Misrecognized (CA<I)  vs. Recognized Turns by Prosodic Feature Across  Speakers.", "labels": [], "entities": []}, {"text": " Table 3: Estimated Error for Predicting Misrecognized Turns (WER>0).  Features Used  Error ] SE  Prosody, ASR Confidence, ASR String, ASR Grammar  6.53%  .63  ALL  6.68%  .63  Prosody, ASR String  7.34%  .75  ASR Confidence, ASR String, ASR Grammar  9.01%  .70  Prosody, ASR Confidence, ASR Grammar  10.63%  .88  Prosody, ASR Confidence  10.99%  .87  Prosody  12.76%  .79  ASR String  15.24% 1.11  Duration  17.42%  .88  ASR Confidence, ASR Grammar  17.77%  .72  ASR Confidence  22.23% 1.16  ASR Grammar  26.28%  .84  Tempo  32.76% 1.03  Hyperarticulation  35.24% 1.46  % Silence  36.46%  .79  Prior Pause  36.61%  .97  F0 Max  38.73%  .82  RMS Max  42.23%  .96  F0 Mean  46.33% 1.10  RMS Mean  48.35% 1.15  II Majority Baseline  J. 48.66%_%_[___~", "labels": [], "entities": [{"text": "Estimated Error", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.8867782652378082}, {"text": "F0 Mean  46.33% 1.10  RMS Mean  48.35% 1.15  II Majority Baseline  J. 48.66%_%_[___~", "start_pos": 664, "end_pos": 748, "type": "METRIC", "confidence": 0.9036778947886299}]}, {"text": " Table 4: Estimated Error for Predicting Misrecognized Turns (CA<l).  Features Used  [ Error  Prosody, ASR Confidence~ ASR String, ASR Grammar 10.43%  .63  ALL  10.68%  .71  Prosody, ASR Confidence, ASR Grammar  11.24%  .68  Prosody, ASR Confidence  11.34%  .64  ASR Confidence, ASR String, ASR Grammar  11.70%  .68  ASR Confidence  13.52%  .82  ASR Confidence, ASR Grammar  13.52%  .84  ASR String  13.62%  .83  Prosody, ASR String  15.04%  .84  Prosody  18.18%  .85  Duration  18.38%  .90  ASR Grammar  22.73%  .96  Tempo  24.61% 1.28  Hyperarticulation  25.27% 1.05  F0 Mean  28.61% 1.19  F0 Max  28.76%  .90  RMS Mean  28.86% 1.17  % Silence  28.91% 1.23  RMS Max  29.01% 1.16  Prior Pause  29.22% 1.26  Majority Baseline  [ 28.61%", "labels": [], "entities": [{"text": "Estimated Error", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.8774838149547577}]}]}