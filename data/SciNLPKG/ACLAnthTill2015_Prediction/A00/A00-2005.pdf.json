{"title": [{"text": "Bagging and Boosting a Treebank Parser", "labels": [], "entities": [{"text": "Bagging", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.969041645526886}, {"text": "Parser", "start_pos": 32, "end_pos": 38, "type": "TASK", "confidence": 0.5707677006721497}]}], "abstractContent": [{"text": "Bagging and boosting, two effective machine learning techniques, are applied to natural language parsing.", "labels": [], "entities": [{"text": "Bagging and boosting", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6623895565668741}, {"text": "natural language parsing", "start_pos": 80, "end_pos": 104, "type": "TASK", "confidence": 0.6372078458468119}]}, {"text": "Experiments using these techniques with a trainable statistical parser are described.", "labels": [], "entities": []}, {"text": "The best resulting system provides roughly as large of again in F-measure as doubling the corpus size.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 64, "end_pos": 73, "type": "METRIC", "confidence": 0.9799726605415344}]}, {"text": "Error analysis of the result of the boosting technique reveals some inconsistent annotations in the Penn Treebank, suggesting a semi-automatic method for finding inconsistent treebank annotations.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 100, "end_pos": 113, "type": "DATASET", "confidence": 0.9951179325580597}]}], "introductionContent": [{"text": "Henderson and  showed that independent human research efforts produce parsers that can be combined for an overall boost inaccuracy.", "labels": [], "entities": []}, {"text": "Finding an ensemble of parsers designed to complement each other is clearly desirable.", "labels": [], "entities": []}, {"text": "The parsers would need to be the result of a unified research effort, though, in which the errors made by one parser are targeted with priority by the developer of another parser.", "labels": [], "entities": []}, {"text": "A set of five parsers which each achieve only 40% exact sentence accuracy would be extremely valuable if they made errors in such away that at least two of the five were correct on any given sentence (and the others abstained or were wrong in different ways).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.6851798892021179}]}, {"text": "100% sentence accuracy could be achieved by selecting the hypothesis that was proposed by the two parsers that agreed completely.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9853370785713196}]}, {"text": "In this paper, the task of automatically creating complementary parsers is separated from the task of creating a single parser.", "labels": [], "entities": []}, {"text": "This facilitates study of the ensemble creation techniques in isolation.", "labels": [], "entities": []}, {"text": "The result is a method for increasing parsing performance by creating an ensemble of parsers, each produced from data using the same parser induction algorithm.", "labels": [], "entities": [{"text": "parsing", "start_pos": 38, "end_pos": 45, "type": "TASK", "confidence": 0.9730631113052368}]}], "datasetContent": [{"text": "The experimental results for boosting are shown in and.", "labels": [], "entities": [{"text": "boosting", "start_pos": 29, "end_pos": 37, "type": "TASK", "confidence": 0.9685787558555603}]}, {"text": "There is a large plateau in performance from iterations 5 through 12.", "labels": [], "entities": []}, {"text": "Because of their low accuracy and high degree of specialization, the parsers produced in these iterations had little weight during voting and had little effect on the cumulative decision making.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9972231388092041}]}, {"text": "As in the bagging experiment, it appears that there would be more precision and recall gain to be had by creating a larger ensemble.", "labels": [], "entities": [{"text": "precision", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9994133710861206}, {"text": "recall", "start_pos": 80, "end_pos": 86, "type": "METRIC", "confidence": 0.9985621571540833}]}, {"text": "In both the bagging and boosting experiments time and resource constraints dictated our ensemble size.", "labels": [], "entities": []}, {"text": "In the table we see that the boosting algorithm equaled bagging's test set gains in precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 84, "end_pos": 93, "type": "METRIC", "confidence": 0.9996216297149658}, {"text": "recall", "start_pos": 98, "end_pos": 104, "type": "METRIC", "confidence": 0.9974936246871948}]}, {"text": "The Initial performance for boosting was lower, though.", "labels": [], "entities": []}, {"text": "We cannot explain this, and expect it is due to unfortunate resampling of the data during the first iteration of boosting.", "labels": [], "entities": []}, {"text": "Exact sentence accuracy, though, was not significantly improved on the test set.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 15, "end_pos": 23, "type": "METRIC", "confidence": 0.943499743938446}]}, {"text": "Overall, we prefer bagging to boosting for this problem when raw performance is the goal.", "labels": [], "entities": []}, {"text": "There are side effects of boosting that are useful in other respects, though, which we explore in Section 4.2.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Bagging the Treebank", "labels": [], "entities": [{"text": "Bagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9839091897010803}, {"text": "Treebank", "start_pos": 22, "end_pos": 30, "type": "DATASET", "confidence": 0.527564287185669}]}, {"text": " Table 2: Boosting the Treebank", "labels": [], "entities": [{"text": "Treebank", "start_pos": 23, "end_pos": 31, "type": "DATASET", "confidence": 0.5105233788490295}]}, {"text": " Table 3: Boosting the Stable Corpus", "labels": [], "entities": [{"text": "Boosting", "start_pos": 10, "end_pos": 18, "type": "TASK", "confidence": 0.8142765164375305}]}, {"text": " Table 4: Effects of Varying Training Corpus Size", "labels": [], "entities": [{"text": "Varying Training Corpus Size", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.7443616390228271}]}]}