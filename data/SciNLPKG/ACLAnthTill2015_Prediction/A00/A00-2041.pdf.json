{"title": [{"text": "A Framework for Robust Semantic Interpretation", "labels": [], "entities": [{"text": "Robust Semantic Interpretation", "start_pos": 16, "end_pos": 46, "type": "TASK", "confidence": 0.6914473573366801}]}], "abstractContent": [{"text": "This paper describes AUTOSEM, a robust semantic interpretation framework that can operate both at parse time and repair time.", "labels": [], "entities": [{"text": "AUTOSEM", "start_pos": 21, "end_pos": 28, "type": "TASK", "confidence": 0.626887857913971}]}, {"text": "The evaluation demonstrates that AUTOSEM achieves a high level of ro-bustness efficiently and without requiring any hand coded knowledge dedicated to repair.", "labels": [], "entities": [{"text": "AUTOSEM", "start_pos": 33, "end_pos": 40, "type": "TASK", "confidence": 0.5213527679443359}]}], "introductionContent": [{"text": "In order for an approach to robust interpretation to be practical it must be efficient, address the major types of disfluencies that plague spontaneously produced language input, and be domain independent so thatachieving robustness in a particular domain does not require an additional knowledge engineering effort.", "labels": [], "entities": []}, {"text": "This paper describes AUTOSEM, a semantic interpretation framework that possesses these three qualities.", "labels": [], "entities": [{"text": "AUTOSEM", "start_pos": 21, "end_pos": 28, "type": "TASK", "confidence": 0.6566099524497986}]}, {"text": "While previous approaches to robust interpretation have offered robust parsers paired with separate repair modules~ with separate knowledge sources for each, AUTOSEM is a single unified framework that can operate both at parse time and repair time.", "labels": [], "entities": []}, {"text": "AUTOSEM is integrated with the LCFLEx robust parser (Ros@ and Lavie, to appear;).", "labels": [], "entities": [{"text": "AUTOSEM", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.4464534819126129}]}, {"text": "Together AUTOSEM and LCFLEx constitute the robust understanding engine within the CARMEL natural language understanding component developed in the context of the Atlas intelligent tutoring project (Freedman at al., to appear).", "labels": [], "entities": [{"text": "AUTOSEM", "start_pos": 9, "end_pos": 16, "type": "DATASET", "confidence": 0.5346011519432068}, {"text": "CARMEL natural language understanding", "start_pos": 82, "end_pos": 119, "type": "TASK", "confidence": 0.564556360244751}]}, {"text": "The evaluation reported here demonstrates that AUTOSEM's repair approach operates 200 times faster than the most similar competing approach while producing hypotheses of better quality.", "labels": [], "entities": [{"text": "AUTOSEM", "start_pos": 47, "end_pos": 54, "type": "TASK", "confidence": 0.5484564304351807}, {"text": "repair", "start_pos": 57, "end_pos": 63, "type": "TASK", "confidence": 0.7982027530670166}]}, {"text": "AUTOSEM provides an interface to allow semantic interpretation to operate in parallel with syntactic interpretation at parse time in a lexicon driven fashion.", "labels": [], "entities": [{"text": "AUTOSEM", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.863072395324707}, {"text": "semantic interpretation", "start_pos": 39, "end_pos": 62, "type": "TASK", "confidence": 0.7207825928926468}]}, {"text": "Domain specific semantic knowledge is encoded declaratively within a meaning representation specification.", "labels": [], "entities": []}, {"text": "Semantic constructor functions are compiled automatically from this specification and then linked into lexical entries as in the Glue Language Semantics approach to interpretation).", "labels": [], "entities": []}, {"text": "Based on syntactic head/argument relationships assigned at parse time, the constructot functions enforce semantic selectiona] restrictions and assemble meaning representation structures by composing the meaning representation associated with the constructor function with the meaning representation of each of its arguments.", "labels": [], "entities": []}, {"text": "AUTOSEM first attempts to construct analyses that satisfy both syntactic and semantic wellformedness conditions.", "labels": [], "entities": [{"text": "AUTOSEM", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.6821746230125427}]}, {"text": "The LCFLEx parser has the ability to efficiently relax syntactic constraints as needed and as allowed by its parameterized flexibility settings.", "labels": [], "entities": []}, {"text": "For sentences remaining beyond the parser's coverage, AUTOSEM's repair algorithm relies entirely on semantic knowledge to compose the partial analyses produced by the parser.", "labels": [], "entities": []}, {"text": "Each semantic representation built by AUTOSEM's interpretation framework contains a pointer to the constructor function that built it.", "labels": [], "entities": []}, {"text": "Thus, each partial analysis can be treated as a constructor function with builtin knowledge about how the associated partial analysis can be combined with other partial analyses in a semantically meaningful way.", "labels": [], "entities": []}, {"text": "Genetic programming search is used to efficiently compose the fragments produced by the parser.", "labels": [], "entities": []}, {"text": "The function definitions compiled from the meaning representation specification allow the genetic search to use semantic constraints to make effective use of its search space.", "labels": [], "entities": []}, {"text": "Thus, AU-TOSEM operates efficiently, free of any hand coded repair rules or any knowledge specifically dedicated to repair unlike other approaches to recovery from parser failure).", "labels": [], "entities": []}], "datasetContent": [{"text": "An experiment was conducted to evaluate AU-TOSEM's robustness by comparing the effectiveness and efficiency of AUTOSEM's repair approach with that of the alternative ROSE approach.", "labels": [], "entities": []}, {"text": "The test set used for this evaluation contains 750 sentences extracted from a corpus of spontaneous scheduling dialogues collected in English.", "labels": [], "entities": []}, {"text": "For both repair approaches we used the meaning representation developed for the appointment scheduling domain that was used in previous evaluations of the ROSE approach (.", "labels": [], "entities": []}, {"text": "It consists of 260 semantic types, each expressing domain specific concepts for the appointment scheduling domain such as busy, cancel, and out-of-~;own.", "labels": [], "entities": []}, {"text": "The ROSE meaning representation specification was easily converted to the format used in AUTOSEM.", "labels": [], "entities": [{"text": "ROSE meaning representation", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.5838931401570638}, {"text": "AUTOSEM", "start_pos": 89, "end_pos": 96, "type": "DATASET", "confidence": 0.8482765555381775}]}, {"text": "Because a pre-existing semantic grammar was available that parsed directly onto this meaning representation, that grammar was used in the parsing stage to construct analyses.", "labels": [], "entities": []}, {"text": "The final meaning representation structures for the first 300 sentences were then passed to a generation component, and the resulting texts were graded by a human judge not involved in developing the research reported here.", "labels": [], "entities": []}, {"text": "Each result was graded as either Bad, Okay, or Perfect, where Perfect indicates that the result was fluent and communicated the idea from the original sentence.", "labels": [], "entities": [{"text": "Perfect", "start_pos": 47, "end_pos": 54, "type": "METRIC", "confidence": 0.9977018237113953}, {"text": "Perfect", "start_pos": 62, "end_pos": 69, "type": "METRIC", "confidence": 0.9835072755813599}]}, {"text": "A grade of Okay indicates that the result communicated the correct information, but not fluently.", "labels": [], "entities": [{"text": "Okay", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.9983499050140381}]}, {"text": "Those graded Bad either communicated incorrect information or were missing part or all of the information communicated in the original sentence.", "labels": [], "entities": [{"text": "Bad", "start_pos": 13, "end_pos": 16, "type": "METRIC", "confidence": 0.9651103615760803}]}, {"text": "Each sentence was parsed in two different modes.", "labels": [], "entities": []}, {"text": "In LC w/restarts mode, the parser was allowed to construct analyses for contiguous portions of input starting at any point in the sentence.", "labels": [], "entities": []}, {"text": "In LCFLEx mode, the parser was allowed to start an analysis at any point and skip up to three words within the analysis.", "labels": [], "entities": []}, {"text": "Because the AUTOSEM repair algorithm runs significantly faster than the ROSE repair algorithm, repair was attempted after every parse rather than only when a parse quality heuristic indicated a need as in the ROSE approach (Ros6, 1997).", "labels": [], "entities": [{"text": "AUTOSEM repair", "start_pos": 12, "end_pos": 26, "type": "TASK", "confidence": 0.709738478064537}]}, {"text": "We compared the results of both AUTOSEM and ROSE in conjunction with the LC w/restarts parsing mode.", "labels": [], "entities": [{"text": "AUTOSEM", "start_pos": 32, "end_pos": 39, "type": "METRIC", "confidence": 0.43043267726898193}, {"text": "ROSE", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9700102806091309}, {"text": "LC w/restarts parsing", "start_pos": 73, "end_pos": 94, "type": "TASK", "confidence": 0.48065255880355834}]}, {"text": "The results are displayed in.", "labels": [], "entities": []}, {"text": "Because the ROSE approach only runs the full repair algorithm when its parse quality heuristic indicates a need and the parser returns more than one partial analysis, it only attempted repair for 14% of the sentences in the corpus.", "labels": [], "entities": []}, {"text": "Nevertheless, although the AUTOSEM repair algorithm ran for each sentence, demonstrates that processing time for parsing plus repair in the AUTOSEM condition was dramatically faster on average than with ROSE.", "labels": [], "entities": [{"text": "AUTOSEM repair", "start_pos": 27, "end_pos": 41, "type": "TASK", "confidence": 0.4267519414424896}, {"text": "parsing", "start_pos": 113, "end_pos": 120, "type": "TASK", "confidence": 0.9686869382858276}]}, {"text": "Average processing time for the ROSE algorithm was 200 times slower than that for AUTOSEM on sentences where both repair algorithms were used.", "labels": [], "entities": [{"text": "ROSE", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.8183936476707458}]}, {"text": "In addition to the advantage in terms of speed, the AUTOSEM repair approach achieved an acceptable grade (Okay or Perfect) on approximately 4% more sentences.", "labels": [], "entities": [{"text": "speed", "start_pos": 41, "end_pos": 46, "type": "METRIC", "confidence": 0.9928622841835022}, {"text": "AUTOSEM repair", "start_pos": 52, "end_pos": 66, "type": "TASK", "confidence": 0.7210312783718109}, {"text": "Okay or Perfect)", "start_pos": 106, "end_pos": 122, "type": "METRIC", "confidence": 0.8074546307325363}]}, {"text": "Parsing in LC w/restarts mode plus repair was also compared with parsing in LCFLEx mode with skipping up to three words.", "labels": [], "entities": [{"text": "repair", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9275944828987122}]}, {"text": "Again, LC w/restarts + AUTOSEM repair achieved a slightly higher number of acceptable grades, although LCFLEx achieved a slightly higher number of Perfect grades.", "labels": [], "entities": [{"text": "restarts", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.949688732624054}, {"text": "AUTOSEM repair", "start_pos": 23, "end_pos": 37, "type": "METRIC", "confidence": 0.8157072961330414}, {"text": "Perfect", "start_pos": 147, "end_pos": 154, "type": "METRIC", "confidence": 0.9991263747215271}]}, {"text": "On long sentences (between 15 and 20 words), LCFLEx mode required almost three times as much time as LC w/restarts mode plus AUTOSEM repair.", "labels": [], "entities": [{"text": "AUTOSEM repair", "start_pos": 125, "end_pos": 139, "type": "METRIC", "confidence": 0.8511518836021423}]}, {"text": "This evaluation confirms our previous results that two stage approaches offer a better processing time versus robustness trade-off.", "labels": [], "entities": []}, {"text": "The primary difference between ROSE and AU-TOSEM is that ROSE uses a single repair function, MY-C0bIB, to combine any two fragments by referring to the meaning representation specification.", "labels": [], "entities": [{"text": "MY-C0bIB", "start_pos": 93, "end_pos": 101, "type": "DATASET", "confidence": 0.7505824565887451}]}, {"text": "While it is possible to obtain the same set of repair hypotheses with ROSE as with AUTOSEM, the ROSE approach insulates the genetic search from the semantic restrictions imposed by the meaning representation.", "labels": [], "entities": []}, {"text": "These restrictions are visible only locally within individual applications of the I~Y-COMB function.", "labels": [], "entities": []}, {"text": "Thus, FIY-COMB must be able to cope with the case where the arguments passed in cannot be combined.", "labels": [], "entities": [{"text": "FIY-COMB", "start_pos": 6, "end_pos": 14, "type": "DATASET", "confidence": 0.8423677682876587}]}, {"text": "Large portions of the programs generated by ROSE as repair hypotheses do not end up contributing to the resulting structure.", "labels": [], "entities": []}, {"text": "The programs gener- ated by ROSE must therefore be much larger than in AUTOSEM in order to obtain the same results.", "labels": [], "entities": [{"text": "AUTOSEM", "start_pos": 71, "end_pos": 78, "type": "DATASET", "confidence": 0.7530362606048584}]}, {"text": "Furthermore, the fitness of each repair hypothesis can only be computed by executing the program to obtain a result.", "labels": [], "entities": []}, {"text": "The combination of all of these things makes the process of fitness evaluation in ROSE far more costly than in AUTOSEM.", "labels": [], "entities": [{"text": "ROSE", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.7291008830070496}, {"text": "AUTOSEM", "start_pos": 111, "end_pos": 118, "type": "DATASET", "confidence": 0.8218759894371033}]}, {"text": "In contrast, AU-TOSEM's constructor function definitions make it possible for the genetic search to make use of semantic restrictions to speedup the process of converging on a high quality repair hypothesis.", "labels": [], "entities": []}, {"text": "The tremendous speed-up offered by the AUTOSEM approach makes it practical to apply repair more often and to use a larger generation size (50 individuals as opposed to 32) and a larger number of generations (5 as opposed to 4) for the genetic search.", "labels": [], "entities": [{"text": "repair", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.9547842144966125}]}], "tableCaptions": []}