{"title": [{"text": "Spelling and Grammar Correction for Danish in SCARRIE", "labels": [], "entities": [{"text": "SCARRIE", "start_pos": 46, "end_pos": 53, "type": "TASK", "confidence": 0.3540774881839752}]}], "abstractContent": [{"text": "This paper reports on work carried out to develop a spelling and grammar corrector for Dan-ish, addressing in particular the issue of how a form of shallow parsing is combined with error detection and correction for the treatment of context-dependent spelling errors.", "labels": [], "entities": [{"text": "spelling and grammar corrector", "start_pos": 52, "end_pos": 82, "type": "TASK", "confidence": 0.6013458669185638}, {"text": "error detection", "start_pos": 181, "end_pos": 196, "type": "TASK", "confidence": 0.6752499938011169}]}, {"text": "The syntactic grammar for Danish used by the system has been developed with the aim of dealing with the most frequent error types found in a parallel corpus of unedited and proofread texts specifically collected by the project's end users.", "labels": [], "entities": []}, {"text": "By focussing on certain grammatical constructions and certain error types, it has been possible to exploit the linguistic 'intelligence' provided by syntactic parsing and yet keep the system robust and efficient.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 149, "end_pos": 166, "type": "TASK", "confidence": 0.7295397520065308}]}, {"text": "The system described is thus superior to other existing spelling checkers for Danish in its ability to deal with context-dependent errors.", "labels": [], "entities": []}], "introductionContent": [{"text": "In her much-quoted and still relevant review of technologies for automatic word correction), Kukich observes that \"research in context-dependent spelling correction is in its infancy\" (p.", "labels": [], "entities": [{"text": "word correction", "start_pos": 75, "end_pos": 90, "type": "TASK", "confidence": 0.7038316428661346}, {"text": "context-dependent spelling correction", "start_pos": 127, "end_pos": 164, "type": "TASK", "confidence": 0.6383643945058187}]}, {"text": "429), and that the task of treating context-dependent errors is still an elusive one due to the complexity of the linguistic knowledge often necessary to analyse the context in sufficient depth to find and correct such errors.", "labels": [], "entities": []}, {"text": "But progress in parsing technology and the growing speed of computers seem to have made the task less of a chimera.", "labels": [], "entities": [{"text": "parsing", "start_pos": 16, "end_pos": 23, "type": "TASK", "confidence": 0.9806400537490845}]}, {"text": "The '90s have in fact seen a renewed interest in grammar checking, and proposals have been made for systems covering English) and other languages such as Italian (,), Czech () and Swedish.", "labels": [], "entities": [{"text": "grammar checking", "start_pos": 49, "end_pos": 65, "type": "TASK", "confidence": 0.8166773915290833}]}, {"text": "This paper describes the prototype of a spelling and grammar corrector for Danish which combines traditional spelling checking functionalities with the ability to carryout compound analysis and to detect and correct certain types of context-dependent spelling errors (hereafter simply \"grammar errors\").", "labels": [], "entities": [{"text": "spelling and grammar corrector", "start_pos": 40, "end_pos": 70, "type": "TASK", "confidence": 0.6121011078357697}]}, {"text": "Grammar correction is carried out by parsing the text, making use of feature overriding and error weights to accommodate the errors.", "labels": [], "entities": [{"text": "Grammar correction", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8060015738010406}]}, {"text": "Although a full parse of each sentence is attempted, the grammar has been developed with the aim of dealing only with the most frequent error types found in a parallel corpus of unedited and proofread texts specifically collected by the project's end users.", "labels": [], "entities": []}, {"text": "By focussing on certain grammatical constructions and certain error types, it has been possible to exploit the linguistic 'intelligence' provided by syntactic parsing and yet keep the system robust and efficient.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 149, "end_pos": 166, "type": "TASK", "confidence": 0.7295397520065308}]}, {"text": "The system described is thus superior to other existing spelling checkers for Danish in its ability to deal with certain types of grammar errors.", "labels": [], "entities": []}, {"text": "We begin by giving an overview of the system's components in Section 2.", "labels": [], "entities": []}, {"text": "In Section 3 we describe the error types we want to deal with: Section 4 gives an overview of the grammar: in particular, the methods adopted for treating feature mismatches and structural errors are explained.", "labels": [], "entities": []}, {"text": "Finally, in Section 5 evaluation results are presented and a conclusion is drawn.", "labels": [], "entities": []}], "datasetContent": [{"text": "The project's access to a set of parallel unedited and proofread texts has made it possible to automate the evaluation of the system's linguistic functionality.", "labels": [], "entities": []}, {"text": "A tool has been implemented to compare the results obtained by the system with the corrections suggested by the publisher's human proofreaders in order to derive measures telling us how well the system performed on recall (lexical coverage as well as coverage of errors), precision (percentage of correct flaggings), as well as suggestion adequacy (hits, misses and no suggestions offered).", "labels": [], "entities": [{"text": "recall", "start_pos": 215, "end_pos": 221, "type": "METRIC", "confidence": 0.9958277344703674}, {"text": "precision", "start_pos": 272, "end_pos": 281, "type": "METRIC", "confidence": 0.9992691874504089}]}, {"text": "The reader is referred to) for more details on the evaluation methodology.", "labels": [], "entities": []}, {"text": "The automatic procedure was used to evaluate the system during development, and in connection with the user validation.", "labels": [], "entities": []}, {"text": "Testing was done on constructed test suites displaying examples of the errors targeted in the project and with text excerpts from the parallel corpora~ shows error recall and suggestion adequacy figures for the various error types represented in the test suites.", "labels": [], "entities": [{"text": "recall", "start_pos": 164, "end_pos": 170, "type": "METRIC", "confidence": 0.6449078917503357}]}, {"text": "These figures are very positive, especially with regard to the treatment of grammar errors.", "labels": [], "entities": []}, {"text": "To make a comparison with a commercial product, the Danish version of the spelling and grammar checker provided by Microsoft Word does not flag any of the grammar errors.", "labels": [], "entities": []}, {"text": "shows how the system performed on one of the test corpora.", "labels": [], "entities": []}, {"text": "The corpus was assembled by mixing short excerpts containing relevant grammar errors and randomly chosen text.", "labels": [], "entities": []}, {"text": "Since unlike test suites, the corpus also contains correct text, the figure this time also shows lexical coverage and precision figures.", "labels": [], "entities": [{"text": "precision", "start_pos": 118, "end_pos": 127, "type": "METRIC", "confidence": 0.9987872242927551}]}, {"text": "The corpus consists of 278 sentences, with an average length of 15.18 words per sentence.", "labels": [], "entities": []}, {"text": "It maybe surprising to see that it contains a limited number of errors, but it must be remembered that the texts targeted in the project are written by experienced journalists.", "labels": [], "entities": []}, {"text": "The corpus was processed in 58 cpu-seconds on an HP 9000/B160.", "labels": [], "entities": []}, {"text": "As expected, the system performs less well than on the test suites, and in general precision is clearly too low.", "labels": [], "entities": [{"text": "precision", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9995948672294617}]}, {"text": "However, we still consider these results encouraging given the relatively small resources the project has been able to spend on grammar development, and we  We regard error coverage as quite satisfactory fora research prototype.", "labels": [], "entities": [{"text": "grammar development", "start_pos": 128, "end_pos": 147, "type": "TASK", "confidence": 0.9013085067272186}]}, {"text": "Ina comparative test made on a similar (slightly smaller) corpus, SCARR/E obtained 58.1% error coverage, and Word 53.5%.", "labels": [], "entities": [{"text": "SCARR/E", "start_pos": 66, "end_pos": 73, "type": "DATASET", "confidence": 0.5314593315124512}, {"text": "error coverage", "start_pos": 89, "end_pos": 103, "type": "METRIC", "confidence": 0.9241326451301575}, {"text": "Word", "start_pos": 109, "end_pos": 113, "type": "DATASET", "confidence": 0.9261605143547058}]}, {"text": "To quote a figure from another recently published test), the ReGra system is reported to miss 48.1% real errors.", "labels": [], "entities": []}, {"text": "It is worth noting that ReGra has much more extensive linguistic resources available than SCARRIE, i.e. a dictionary of 1.5 million words and a grammar of 600 production rules.", "labels": [], "entities": [{"text": "ReGra", "start_pos": 24, "end_pos": 29, "type": "DATASET", "confidence": 0.853851854801178}]}, {"text": "Most of the errors not found by SCAR-RIE in the test have to do with punctuation and other stylistic matters not treated in the project.", "labels": [], "entities": []}, {"text": "There are also, however, agreement errors which go unnoticed.", "labels": [], "entities": [{"text": "agreement errors", "start_pos": 25, "end_pos": 41, "type": "METRIC", "confidence": 0.8826907873153687}]}, {"text": "These failures are due to one of two reasons: either that no parse has been produced for the sentence in question, or that the grammar has produced a wrong analysis.", "labels": [], "entities": []}, {"text": "The precision obtained is at least at first sight much too low.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9997720122337341}]}, {"text": "On the same test corpus, however, Word only reached 15.9% precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.998418927192688}]}, {"text": "On closer inspection, 72 of the bad flags produced by SCARRIE turned out to be due to unrecognised proper names.", "labels": [], "entities": []}, {"text": "Disregarding those, precision goes up to 34.9%.", "labels": [], "entities": [{"text": "precision", "start_pos": 20, "end_pos": 29, "type": "METRIC", "confidence": 0.9997550845146179}]}, {"text": "As was mentioned early, SCARRIE has a facility for guessing unknown proper names on the basis of their frequency of occurrence in the text.", "labels": [], "entities": [{"text": "guessing unknown proper names", "start_pos": 51, "end_pos": 80, "type": "TASK", "confidence": 0.8485071510076523}]}, {"text": "But since the test corpus consists of Short unrelated excerpts, a large number of proper names only occur once or twice.", "labels": [], "entities": []}, {"text": "To get an impression of how the system would perform in a situation where the same proper names and unknown words had a higher frequency of occurrence, we doubled the test corpus by simply repeating the same text twice.", "labels": [], "entities": []}, {"text": "As expected, precision increased.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9990668892860413}]}, {"text": "The system produced 178 flags, 60 of which were correct (39.7%).", "labels": [], "entities": []}, {"text": "This compares well with the 40% precision reported for instance for ReGra.", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9981824159622192}, {"text": "ReGra", "start_pos": 68, "end_pos": 73, "type": "DATASET", "confidence": 0.9299395680427551}]}, {"text": "In addition to the problem of unkown proper names, false flags are related to unrecognised acronyms and compounds (typically forms containing acronyms or dashes), and a not very precise treatment of capitalisation.", "labels": [], "entities": []}, {"text": "Only 13 false flags are due to wrong grammar analyses caused either by the fragment approach or by the grammar's limited coverage.", "labels": [], "entities": []}, {"text": "In particular, genitive phrases, which are not treated at the moment, are responsible for most of these false alarms.", "labels": [], "entities": []}, {"text": "In conclusion, we consider the results obtained so far promising, and the problems revealed by the evaluation tractable within the current system design.", "labels": [], "entities": []}, {"text": "In particular, future development should focus on treating stylistic matters such as capitalisation and punctuation which have not been in focus in the current prototype.", "labels": [], "entities": []}, {"text": "The coverage of the grammar, in particular the treatment of genitive phrases, should also be further developed.", "labels": [], "entities": []}, {"text": "The data pro-vided by the evaluation reported on in this paper, however, are much too limited to base further development on.", "labels": [], "entities": []}, {"text": "Therefore, more extensive testing and debugging should also be carried out.", "labels": [], "entities": []}, {"text": "In addition, two aspects of the system that have only be touched on in this paper would be worth further attention: one is the mechanism for the treatment of split-ups and run-ons, which as mentioned earlier is not well-integrated at the moment; the other is the weight adjustment process, which is done manually at the moment, and for which the adoption of a semiautomatic tool could be considered.", "labels": [], "entities": []}], "tableCaptions": []}