{"title": [{"text": "Analyzing Dependencies of Japanese Subordinate Clauses based on Statistics of Scope Embedding Preference", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper proposes a statistical method for learning dependency preference of Japanese subordinate clauses, in which scope embedding preference of subordinate clauses is exploited as a useful information source for disambiguat-ing dependencies between subordinate clauses.", "labels": [], "entities": []}, {"text": "Estimated dependencies of subordinate clauses successfully increase the precision of an existing statistical dependency analyzer.", "labels": [], "entities": [{"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9995471835136414}]}], "introductionContent": [{"text": "In the Japanese language, since word order in a sentence is relatively free compared with European languages, dependency analysis has been shown to be practical and effective in both rulebased and stochastic approaches to syntactic analysis.", "labels": [], "entities": [{"text": "dependency analysis", "start_pos": 110, "end_pos": 129, "type": "TASK", "confidence": 0.858159989118576}, {"text": "syntactic analysis", "start_pos": 222, "end_pos": 240, "type": "TASK", "confidence": 0.805635929107666}]}, {"text": "In dependency analysis of a Japanese sentence, among various source of ambiguities in a sentence, dependency ambiguities of subordinate clauses are one of the most problematic ones, partly because word order in a sentence is relatively free.", "labels": [], "entities": [{"text": "dependency analysis of a Japanese sentence", "start_pos": 3, "end_pos": 45, "type": "TASK", "confidence": 0.8732185761133829}]}, {"text": "In general, dependency ambiguities of subordinate clauses cause scope ambiguities of subordinate clauses, which result in enormous number of syntactic ambiguities of other types of phrases such as noun phrases.", "labels": [], "entities": []}, {"text": "1 1In our preliminary corpus analysis using the stochastic dependency analyzer of, about 30% of the 210,000 sentences in EDR bracketed corpus have dependency ambiguities of subordinate clauses, for which the precision of chunk (bunsetsu) level dependencies is about 85.3% and that of sentence level is about 25.4% (for best one) ~ 35.8% (for best five), while for the rest 70% of EDR bracketed corpus, the precision of chunk (bunsetsu) level dependencies is about 86.7% and that of sentence level is about 47.5% (for best one) ~ 60.2% (for best five).", "labels": [], "entities": [{"text": "EDR bracketed corpus", "start_pos": 121, "end_pos": 141, "type": "DATASET", "confidence": 0.8746583064397176}, {"text": "precision", "start_pos": 208, "end_pos": 217, "type": "METRIC", "confidence": 0.9945584535598755}, {"text": "EDR bracketed corpus", "start_pos": 380, "end_pos": 400, "type": "DATASET", "confidence": 0.897935688495636}, {"text": "precision", "start_pos": 406, "end_pos": 415, "type": "METRIC", "confidence": 0.9893446564674377}]}, {"text": "In addition to that, when assuming that those ambiguities of subordinate clause dependencies are initially resolved in someway, the chunk level precision increases to 90.4%, and the sentence level precision to 40.6% (for best one) ~ 67.7% (for best five).", "labels": [], "entities": [{"text": "precision", "start_pos": 144, "end_pos": 153, "type": "METRIC", "confidence": 0.698697030544281}, {"text": "sentence level precision", "start_pos": 182, "end_pos": 206, "type": "METRIC", "confidence": 0.5995606581370035}]}, {"text": "This result of our preliminary analysis In the Japanese linguistics, a theory of regarding scope embedding preference of subordinate clauses is well-known.", "labels": [], "entities": []}, {"text": "classifies Japanese subordinate clauses according to the breadths of their scopes and claim that subordinate clauses which inherently have narrower scopes are embedded within the scopes of subordinate clauses which inherently have broader scopes (details are in section 2).", "labels": [], "entities": []}, {"text": "By manually analyzing several raw corpora, classifies various types of Japanese subordinate clauses into three categories, which are totally ordered by the embedding relation of their scopes.", "labels": [], "entities": []}, {"text": "In the Japanese computational linguistics community, employed's theory on scope embedding preference of Japanese subordinate clauses and applied it to rule-based Japanese dependency analysis.", "labels": [], "entities": [{"text": "Japanese dependency analysis", "start_pos": 162, "end_pos": 190, "type": "TASK", "confidence": 0.5601043800512949}]}, {"text": "However, in their approach, since categories of subordinate clauses are obtained by manually analyzing a small number of sentences, their coverage against a large corpus such as EDR bracketed corpus) is quite low.", "labels": [], "entities": [{"text": "coverage", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9783245921134949}, {"text": "EDR bracketed corpus", "start_pos": 178, "end_pos": 198, "type": "DATASET", "confidence": 0.8326710065205892}]}, {"text": "2 In order to realize abroad coverage and high performance dependency analysis of Japanese sentences which exploits scope embedding preference of subordinate clauses, we propose a corpus-based and statistical alternative to the rule-based manual approach (section 3).", "labels": [], "entities": []}, {"text": "3 clearly shows that dependency ambiguities of subordinate clauses are among the most problematic source of syntactic ambiguities in a Japanese sentence.", "labels": [], "entities": []}, {"text": "2In our implementation, the coverage of the categories of is only 30% for all the subordinate clauses included in the whole EDR corpus.", "labels": [], "entities": [{"text": "coverage", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9632771015167236}, {"text": "EDR corpus", "start_pos": 124, "end_pos": 134, "type": "DATASET", "confidence": 0.958784431219101}]}, {"text": "~Previous works on statistical dependency analysis include and in Japanese analysis as well as, in English analysis.", "labels": [], "entities": [{"text": "statistical dependency analysis", "start_pos": 19, "end_pos": 50, "type": "TASK", "confidence": 0.7399462262789408}]}, {"text": "In later sections, we discuss the advantages of our approach over several closely related previous works.", "labels": [], "entities": []}, {"text": "First, we formalize the problem of deciding scope embedding preference as a classification problem, in which various types of linguistic information of each subordinate clause are encoded as features and used for deciding which one of given two subordinate clauses has a broader scope than the other.", "labels": [], "entities": []}, {"text": "As in the case of, we formalize the problem of deciding dependency preference of subordinate clauses by utilizing the correlation of scope embedding preference and dependency preference of Japanese subordinate clauses.", "labels": [], "entities": []}, {"text": "Then, as a statistical learning method, we employ the decision list learning method of, where optimal combination of those features are selected and sorted in the form of decision rules, according to the strength of correlation between those features and the dependency preference of the two subordinate clauses.", "labels": [], "entities": []}, {"text": "We evaluate the proposed method through the experiment on learning dependency preference of Japanese subordinate clauses from the EDR bracketed corpus (section 4).", "labels": [], "entities": [{"text": "EDR bracketed corpus", "start_pos": 130, "end_pos": 150, "type": "DATASET", "confidence": 0.8858329852422079}]}, {"text": "We show that the proposed method outperforms other related methods/models.", "labels": [], "entities": []}, {"text": "We also evaluate the estimated dependencies of subordinate clauses in's framework of the statistical dependency analysis of a whole sentence, in which we successfully increase the precisions of both chunk level and sentence level dependencies thanks to the estimated dependencies of subordinate clauses.", "labels": [], "entities": [{"text": "precisions", "start_pos": 180, "end_pos": 190, "type": "METRIC", "confidence": 0.9985356330871582}]}, {"text": "t Dependency (modification) Relation: An Example of Japanese Subordinate Clause (taken from the Sentence of part-of-speech tagged, and then chunked into a sequence of segments called bunsetsus.", "labels": [], "entities": []}, {"text": "4 Each chunk (bunsetsu) generally consists of a set of content words and function words.", "labels": [], "entities": []}, {"text": "Then, dependency relations among those chunks are estimated, where most practical dependency analyzers for the Japanese language usually assume the following two constraints: 1.", "labels": [], "entities": []}, {"text": "Every chunk (bunsetsu) except the last one modifies only one posterior chunk (bunsetsu).", "labels": [], "entities": []}, {"text": "2. No modification crosses to other modifications in a sentence.", "labels": [], "entities": []}, {"text": "gives an example of word segmentation, part-of-speech tagging, and bunsetsu segmentation (chunking) of a Japanese sentence, where the verb and the adjective are tagged with their parts-of-speech as well as conjugation forms.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.7501265406608582}, {"text": "part-of-speech tagging", "start_pos": 39, "end_pos": 61, "type": "TASK", "confidence": 0.7172976583242416}, {"text": "bunsetsu segmentation (chunking)", "start_pos": 67, "end_pos": 99, "type": "TASK", "confidence": 0.7693411350250244}]}, {"text": "shows the phrase structure, the bracketing, 5 and the dependency (modification) relation of the chunks (bunsetsus) within the sentence.", "labels": [], "entities": []}, {"text": "4Word segmentation and part-of-speech tagging are performed by the Japanese morphological analyzer Chasen (, and chunking is done by the preprocessor used in.", "labels": [], "entities": [{"text": "4Word segmentation", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.756309449672699}, {"text": "part-of-speech tagging", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.6800849288702011}, {"text": "Japanese morphological analyzer Chasen", "start_pos": 67, "end_pos": 105, "type": "DATASET", "confidence": 0.4618380218744278}]}, {"text": "5The phrase structure and the bracketing are shown just for explanation, and we do not consider them but consider only dependency relations in the analysis throughout this paper.", "labels": [], "entities": []}, {"text": "A Japanese subordinate clause is a clause whose head chunk satisfies the following properties.", "labels": [], "entities": []}, {"text": "content words part of the chunk (bunsetsu) is one of the following types: A predicate (i.e., a verb or an adjective).", "labels": [], "entities": []}, {"text": "nouns and a copula like \"Noun1 dearu\" (in English, \"be Noun1\").", "labels": [], "entities": []}, {"text": "function words part of the chunk (bunsetsu) is one of the following types: Null.", "labels": [], "entities": []}, {"text": "Adverb type such as \"Verbl ippou-de\" (in English, \"(subject) Verb1 ..., on the other hand,\").", "labels": [], "entities": []}, {"text": "Adverbial noun type such as \"Verb1 tame\" (in English, \"in order to Verb1\").", "labels": [], "entities": [{"text": "Verb1", "start_pos": 29, "end_pos": 34, "type": "METRIC", "confidence": 0.8850065469741821}]}, {"text": "FormM noun type such as \"Verb1 koto\" (in English, gerund \"Verbl-ing\").", "labels": [], "entities": []}, {"text": "Temporal noun type such as \"Verb1 mae\" (in English, \"before (subject) Verb1 ...\").", "labels": [], "entities": [{"text": "Verb1", "start_pos": 28, "end_pos": 33, "type": "METRIC", "confidence": 0.9676879048347473}]}, {"text": "A predicate conjunctive particle such as \"Verbl ga\" (in English, \"although (subject) Verbl ...,\").", "labels": [], "entities": []}, {"text": "A quoting particle such as \"Verbl to (iu)\" (in English, \"(say) that (subject) Verbl ...\").", "labels": [], "entities": []}, {"text": "(a),,~(g) followed by topic marking particles and/or sentence-final particles.", "labels": [], "entities": [{"text": "topic marking particles", "start_pos": 22, "end_pos": 45, "type": "TASK", "confidence": 0.7806461850802103}]}], "datasetContent": [{"text": "We divided the 210,000 sentences of the whole EDR bracketed Japanese corpus into 95% training sentences and 5~0 test sentences.", "labels": [], "entities": [{"text": "EDR bracketed Japanese corpus", "start_pos": 46, "end_pos": 75, "type": "DATASET", "confidence": 0.9305705577135086}]}, {"text": "Then, we extracted 162,443 pairs of subordinate clauses from the 199,500 training sentences, and learned a decision list for dependency preference of subordinate clauses from those pairs.", "labels": [], "entities": []}, {"text": "The default decision in the decision list is D =\"beyond\", where the marginal probability P(D = \"beyond\") = 0.5378, i.e., the baseline precision of deciding dependency between two subordinate clauses is 53.78 %.", "labels": [], "entities": [{"text": "precision", "start_pos": 134, "end_pos": 143, "type": "METRIC", "confidence": 0.9630418419837952}]}, {"text": "We limit the frequency of each evidence-decision pair to be more than 9.", "labels": [], "entities": []}, {"text": "The total number of obtained evidencedecision pairs is 7,812.", "labels": [], "entities": []}, {"text": "We evaluate the learned decision list through several experiments.", "labels": [], "entities": []}, {"text": "12 First, we apply the learned decision list to deciding dependency between two subordinate clauses of the 5% test sentences.", "labels": [], "entities": []}, {"text": "We change the threshold of the probability P(D I E) 13 in 12Details of the experimental evaluation will be presented in I~P( DI E) can be used equivalently to the likelihood the decision list and plot the trade-off between coverage and precision.", "labels": [], "entities": [{"text": "coverage", "start_pos": 223, "end_pos": 231, "type": "METRIC", "confidence": 0.9826316833496094}, {"text": "precision", "start_pos": 236, "end_pos": 245, "type": "METRIC", "confidence": 0.9953039884567261}]}, {"text": "14 As shown in the plot of \"Our Model\" in, the precision varies from 78% to 100% according to the changes of the threshold of the probability P(D I E).", "labels": [], "entities": [{"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9996079802513123}]}, {"text": "Next, we compare our model with the other two models: (a) the model learned by applying the decision tree learning method of to our task of deciding dependency between two subordinate clauses, and (b) a decision list whose decisions are the following two cases, i.e., the case where dependency relation holds between the given two vp chunks or clauses, and the case where dependency relation does not hold.", "labels": [], "entities": []}, {"text": "The model (b) corresponds to a model in which standard approaches to statistical dependency analysis) are applied to our task of deciding dependency between two subordinate clauses.", "labels": [], "entities": [{"text": "statistical dependency analysis", "start_pos": 69, "end_pos": 100, "type": "TASK", "confidence": 0.6162422200043997}]}, {"text": "Their results are also in Figures 5 and 6.", "labels": [], "entities": []}, {"text": "shows that \"Our Model\" outperforms the other two models in coverage.", "labels": [], "entities": [{"text": "coverage", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9960826635360718}]}, {"text": "shows that our model outperforms both of the models (a) and (b) in coverage and precision.", "labels": [], "entities": [{"text": "coverage", "start_pos": 67, "end_pos": 75, "type": "METRIC", "confidence": 0.998771607875824}, {"text": "precision", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.9993394017219543}]}, {"text": "Finally, we examine whether the estimated dependencies of subordinate clauses improve the precision of's statistical dependency analyzer.", "labels": [], "entities": [{"text": "precision", "start_pos": 90, "end_pos": 99, "type": "METRIC", "confidence": 0.9995417594909668}]}, {"text": "15 Depending on the threshold of P(D [ E), we achieve 0.8,,~1.8% improvement in chunk level precision, and 1.6~-4.7% improvement in sentence level, is", "labels": [], "entities": [{"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9511679410934448}]}], "tableCaptions": []}