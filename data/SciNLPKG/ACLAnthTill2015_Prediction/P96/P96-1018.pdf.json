{"title": [{"text": "High-Performance Bilingual Text Alignment Using Statistical and Dictionary Information", "labels": [], "entities": [{"text": "Bilingual Text Alignment", "start_pos": 17, "end_pos": 41, "type": "TASK", "confidence": 0.6989107728004456}]}], "abstractContent": [{"text": "This paper describes an accurate and robust text alignment system for structurally different languages.", "labels": [], "entities": [{"text": "text alignment", "start_pos": 44, "end_pos": 58, "type": "TASK", "confidence": 0.7038328945636749}]}, {"text": "Among structurally different languages such as Japanese and English, there is a limitation on the amount of word correspondences that can be statistically acquired.", "labels": [], "entities": []}, {"text": "The proposed method makes use of two kinds of word correspondences in aligning bilingual texts.", "labels": [], "entities": []}, {"text": "One is a bilingual dictionary of general use.", "labels": [], "entities": []}, {"text": "The other is the word correspondences that are statistically acquired in the alignment process.", "labels": [], "entities": []}, {"text": "Our method gradually determines sentence pairs (an-chors) that correspond to each other by relaxing parameters.", "labels": [], "entities": []}, {"text": "The method, by combining two kinds of word correspondences, achieves adequate word correspondences for complete alignment.", "labels": [], "entities": [{"text": "complete alignment", "start_pos": 103, "end_pos": 121, "type": "TASK", "confidence": 0.5325705111026764}]}, {"text": "As a result, texts of various length and of various genres in structurally different languages can be aligned with high precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 120, "end_pos": 129, "type": "METRIC", "confidence": 0.9824497699737549}]}, {"text": "Experimental results show our system outperforms conventional methods for various kinds of Japanese-English texts.", "labels": [], "entities": []}], "introductionContent": [{"text": "Corpus-based approaches based on bilingual texts are promising for various applications(i.e., lexical knowledge extraction, machine translation () and information retrieval).", "labels": [], "entities": [{"text": "lexical knowledge extraction", "start_pos": 94, "end_pos": 122, "type": "TASK", "confidence": 0.6785794893900553}, {"text": "machine translation", "start_pos": 124, "end_pos": 143, "type": "TASK", "confidence": 0.7660132646560669}, {"text": "information retrieval", "start_pos": 151, "end_pos": 172, "type": "TASK", "confidence": 0.8005370199680328}]}, {"text": "Most of these works assume voluminous aligned corpora.", "labels": [], "entities": []}, {"text": "Many methods have been proposed to align bilingual corpora.", "labels": [], "entities": []}, {"text": "One of the major approaches is based on the statistics of simple features such as sentence length in words or in characters ().", "labels": [], "entities": []}, {"text": "These techniques are widely used because they can be implemented in an efficient and simple way through dynamic programing.", "labels": [], "entities": []}, {"text": "However, their main targets are rigid translations that are almost literal translations.", "labels": [], "entities": []}, {"text": "In addition, the texts being aligned were structurally similar European languages (i.e., English-French, English-German).", "labels": [], "entities": []}, {"text": "The simple-feature based approaches don't work in flexible translations for structurally different languages such as Japanese and English, mainly for the following two reasons.", "labels": [], "entities": []}, {"text": "One is the difference in the character types of the two languages.", "labels": [], "entities": []}, {"text": "Japanese has three types of characters (Hiragana, Katakana, and Kanji), each of which has different amounts of information.", "labels": [], "entities": []}, {"text": "In contrast, English has only one type of characters.", "labels": [], "entities": []}, {"text": "The other is the grammatical and rhetorical difference of the two languages.", "labels": [], "entities": []}, {"text": "First, the systems of functional (closed) words are quite different from language to language.", "labels": [], "entities": []}, {"text": "Japanese has a quite different system of closed words, which greatly influence the length of simple features.", "labels": [], "entities": []}, {"text": "Second, due to rhetorical difference, the number of multiple match (i.e., 1-2, 1-3, 2-1 and so on) is more than that among European languages.", "labels": [], "entities": []}, {"text": "Thus, it is impossible in general to apply the simple-feature based methods to Japanese-English translations.", "labels": [], "entities": []}, {"text": "One alternative alignment method is the lexiconbased approach that makes use of the wordcorrespondence knowledge of the two languages.", "labels": [], "entities": []}, {"text": "employed n-grams shared by two languages.", "labels": [], "entities": []}, {"text": "His method is also effective for JapaneseEnglish computer manuals both containing lots of the same alphabetic technical terms.", "labels": [], "entities": [{"text": "JapaneseEnglish computer manuals", "start_pos": 33, "end_pos": 65, "type": "DATASET", "confidence": 0.7906418442726135}]}, {"text": "However, the method cannot be applied to general translations in structurally different languages.", "labels": [], "entities": []}, {"text": "proposed a relaxation method to iteratively align bilingual texts using the word correspondences acquired during the alignment process.", "labels": [], "entities": []}, {"text": "Although the method works well among European languages, the method does notwork in aligning structurally different languages.", "labels": [], "entities": []}, {"text": "In JapaneseEnglish translations, the method does not capture enough word correspondences to permit alignment.", "labels": [], "entities": []}, {"text": "As a result, it can align only some of the two texts.", "labels": [], "entities": []}, {"text": "This is mainly because the syntax and rhetoric are greatly differ in the two languages even in literal translations.", "labels": [], "entities": []}, {"text": "The number of confident word correspondences of words is not enough for complete alignment.", "labels": [], "entities": []}, {"text": "Thus, the problem cannot be addressed as long as the method relies only on statistics.", "labels": [], "entities": []}, {"text": "Other methods in the lexicon-based approach embed lexical knowledge into stochastic models, but these methods were tested using rigid translations.", "labels": [], "entities": []}, {"text": "To tackle the problem, we describe in this paper a text alignment system that uses both statistics and bilingual dictionaries at the same time.", "labels": [], "entities": [{"text": "text alignment", "start_pos": 51, "end_pos": 65, "type": "TASK", "confidence": 0.7366748452186584}]}, {"text": "Bilingual dictionaries are now widely available on-line due to advances in CD-ROM technologies.", "labels": [], "entities": [{"text": "Bilingual dictionaries", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7380439639091492}]}, {"text": "For example, English-Spanish, English-French, English-German, English-Japanese, Japanese-French, Japanese-Chinese and other dictionaries are now commercially available.", "labels": [], "entities": []}, {"text": "It is reasonable to make use of these dictionaries in bilingual text alignment.", "labels": [], "entities": [{"text": "bilingual text alignment", "start_pos": 54, "end_pos": 78, "type": "TASK", "confidence": 0.6132069230079651}]}, {"text": "The pros and cons of statistics and online dictionaries are discussed below.", "labels": [], "entities": []}, {"text": "They show that statistics and on-line dictionaries are complementary in terms of bilingual text alignment.", "labels": [], "entities": [{"text": "bilingual text alignment", "start_pos": 81, "end_pos": 105, "type": "TASK", "confidence": 0.6168523331483206}]}, {"text": "Statistics Merit Statistics is robust in the sense that it can extract context-dependent usage of words and that it works well even if word segmentation 1 is not correct.", "labels": [], "entities": [{"text": "Statistics Merit Statistics", "start_pos": 0, "end_pos": 27, "type": "DATASET", "confidence": 0.6942602097988129}, {"text": "word segmentation", "start_pos": 135, "end_pos": 152, "type": "TASK", "confidence": 0.6711952388286591}]}, {"text": "Statistics Demerit The amount of word correspondences acquired by statistics is not enough for complete alignment.", "labels": [], "entities": []}, {"text": "Dictionaries Merit They can contain the information about words that appear only once in the corpus.", "labels": [], "entities": []}, {"text": "Dictionaries Demerit They cannot capture context-dependent keywords in the corpus and are weak against incorrect word segmentation.", "labels": [], "entities": []}, {"text": "Entries in the dictionaries differ from author to author and are not always the same as those in the corpus.", "labels": [], "entities": []}, {"text": "Our system iteratively aligns sentences by using statistical and on-line dictionary word correspondences.", "labels": [], "entities": []}, {"text": "The characteristics of the system are as follows.", "labels": [], "entities": []}, {"text": "\u2022 The system performs well and is robust for various lengths (especially short) and various genres of texts.", "labels": [], "entities": []}, {"text": "\u2022 The system is very economical because it assumes only online-dictionaries of general use and doesn't require the labor-intensive construction of domain-specific dictionaries.", "labels": [], "entities": []}, {"text": "\u2022 The system is extendable by registering statistically acquired word correspondences into user dictionaries.", "labels": [], "entities": [{"text": "registering statistically acquired word correspondences into user dictionaries", "start_pos": 30, "end_pos": 108, "type": "TASK", "confidence": 0.6592524982988834}]}, {"text": "1In Japanese, there are no explicit delimiters between words.", "labels": [], "entities": []}, {"text": "The first task for alignment is , therefore, to divide the text stream into words.", "labels": [], "entities": [{"text": "alignment", "start_pos": 19, "end_pos": 28, "type": "TASK", "confidence": 0.9800149202346802}]}, {"text": "We will treat hereafter Japanese-English translations although the proposed method is language independent.", "labels": [], "entities": []}, {"text": "The construction of the paper is as follows.", "labels": [], "entities": []}, {"text": "First, Section 2 offers an overview of our alignment system.", "labels": [], "entities": [{"text": "alignment", "start_pos": 43, "end_pos": 52, "type": "TASK", "confidence": 0.9752547740936279}]}, {"text": "Section 3 describes the entire alignment algorithm in detail.", "labels": [], "entities": [{"text": "alignment", "start_pos": 31, "end_pos": 40, "type": "TASK", "confidence": 0.974755585193634}]}, {"text": "Section 4 reports experimental results for various kinds of Japanese-English texts including newspaper editorials, scientific papers and critiques on economics.", "labels": [], "entities": []}, {"text": "The evaluation is performed from two points of view: precision-recall of alignment and word correspondences acquired during alignment.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 53, "end_pos": 69, "type": "METRIC", "confidence": 0.9987370371818542}]}, {"text": "Section 5 concerns related works and Section 6 concludes the paper.", "labels": [], "entities": []}, {"text": "Figure 1 overviews our alignment system.", "labels": [], "entities": [{"text": "alignment", "start_pos": 23, "end_pos": 32, "type": "TASK", "confidence": 0.9798818826675415}]}, {"text": "The input to the system is a pair of Japanese and English texts, one the translation of the other.", "labels": [], "entities": []}, {"text": "First, sentence boundaries are found in both texts using finite state transducers.", "labels": [], "entities": []}, {"text": "The texts are then partof-speech (POS) tagged and separated into original form words z.", "labels": [], "entities": []}, {"text": "Original forms of English words are determined by 80 rules using the POS information.", "labels": [], "entities": [{"text": "POS information", "start_pos": 69, "end_pos": 84, "type": "DATASET", "confidence": 0.8526904881000519}]}, {"text": "From the word sequences, we extract only nouns, adjectives, adverbs verbs and unknown words (only in Japanese) because Japanese and English closed words are different and impede text alignment.", "labels": [], "entities": [{"text": "text alignment", "start_pos": 178, "end_pos": 192, "type": "TASK", "confidence": 0.6928248256444931}]}, {"text": "These pre-processing operation can be easily implemented with regular expressions.", "labels": [], "entities": []}, {"text": "2We use in this phase the JUMAN morphological analyzing system ( for tagging Japanese texts and Brill's transformation-based tagger  The initial state of the algorithm is a set of already known anchors (sentence pairs).", "labels": [], "entities": [{"text": "JUMAN morphological analyzing", "start_pos": 26, "end_pos": 55, "type": "TASK", "confidence": 0.5981724162896475}]}, {"text": "These are determined by article boundaries, section boundaries and paragraph boundaries.", "labels": [], "entities": []}, {"text": "In the most general case, initial anchors are only the first and final sentence pairs of both texts as depicted in.", "labels": [], "entities": []}, {"text": "Possible sentence correspondences are determined from the anchors.", "labels": [], "entities": []}, {"text": "Intuitively, the number of possible correspondences fora sentence is small near anchors, while large between the anchors.", "labels": [], "entities": []}, {"text": "In this phase, the most important point is that each set of possible sentence correspondences should include the correct correspondence.", "labels": [], "entities": []}, {"text": "The main task of the system is to find anchors from the possible sentence correspondences by using two kinds of word correspondences: statistical word correspondences and word correspondences as held in a bilingual dictionary 3.", "labels": [], "entities": []}, {"text": "By using both correspondences, the sentence pair whose correspondences exceeds a pre-defined threshold is judged as an anchor.", "labels": [], "entities": []}, {"text": "These newly found anchors make word correspondences more precise in the subsequent session.", "labels": [], "entities": [{"text": "word correspondences", "start_pos": 31, "end_pos": 51, "type": "TASK", "confidence": 0.7099436372518539}]}, {"text": "By repeating this anchor setting process with threshold reduction, sentence correspondences are gradually determined from confident pairs to nonconfident pairs.", "labels": [], "entities": []}, {"text": "The gradualism of the algorithm makes it robust because anchor-setting errors in the last stage of the algorithm have little effect on overall performance.", "labels": [], "entities": []}, {"text": "The output of the algorithm is the alignment result (a sequence of anchors) and word correspondences as by-products.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we report the result of experiments on aligning sentences in bilingual texts and on statistically acquired word correspondences.", "labels": [], "entities": []}, {"text": "The texts for the experiment varied in length and genres as summarized in.", "labels": [], "entities": []}, {"text": "Texts 1 and 2 are editorials taken from 'Yomiuri Shinbun' and its English version 'Daily Yomiuri'.", "labels": [], "entities": [{"text": "Yomiuri Shinbun'", "start_pos": 41, "end_pos": 57, "type": "DATASET", "confidence": 0.9483076532681783}]}, {"text": "This data was distributed electrically via a WWW server 4.", "labels": [], "entities": [{"text": "WWW server 4", "start_pos": 45, "end_pos": 57, "type": "DATASET", "confidence": 0.9129552245140076}]}, {"text": "The first two texts clarify the systems's performance on shorter texts.", "labels": [], "entities": []}, {"text": "Text 3 is an essay on economics taken from a quarterly publication of The International House of Japan.", "labels": [], "entities": [{"text": "The International House of Japan", "start_pos": 70, "end_pos": 102, "type": "DATASET", "confidence": 0.880093789100647}]}, {"text": "Text 4 is a scientific survey on brain science taken from 'Scientific American' and its Japanese version 'Nikkei Science '5.", "labels": [], "entities": [{"text": "Scientific American'", "start_pos": 59, "end_pos": 79, "type": "DATASET", "confidence": 0.8659408688545227}, {"text": "Nikkei Science '5", "start_pos": 106, "end_pos": 123, "type": "DATASET", "confidence": 0.8909857124090195}]}, {"text": "Jpn and Eng in Table2 represent the number of sentences in the Japanese and English texts respectively Yomiuri data can be obtained from www.yomiuri.co.jp.", "labels": [], "entities": [{"text": "Jpn", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.8038150072097778}, {"text": "Eng", "start_pos": 8, "end_pos": 11, "type": "METRIC", "confidence": 0.9103953838348389}]}, {"text": "We would like to thank Yomiuri Shinbun Co. for permitting us to use the data.", "labels": [], "entities": [{"text": "Yomiuri Shinbun Co.", "start_pos": 23, "end_pos": 42, "type": "DATASET", "confidence": 0.9457041223843893}]}, {"text": "~We obtained the data from paper version of the magazine by using OCR.", "labels": [], "entities": [{"text": "paper version of the magazine", "start_pos": 27, "end_pos": 56, "type": "DATASET", "confidence": 0.7815555155277252}, {"text": "OCR", "start_pos": 66, "end_pos": 69, "type": "METRIC", "confidence": 0.6470198631286621}]}, {"text": "We would like to thank Nikkei Science Co. for permitting us to use the data.", "labels": [], "entities": [{"text": "Nikkei Science Co.", "start_pos": 23, "end_pos": 41, "type": "DATASET", "confidence": 0.9748288989067078}]}, {"text": "categories of matches by manual alignment and indicate the difficulty of the task.", "labels": [], "entities": []}, {"text": "Our evaluation focuses on much smaller texts than those used in other study because our main targets are well-separated articles.", "labels": [], "entities": []}, {"text": "However, our method will work on larger and noisy sets too, by using word anchors rather than using sentence boundaries as segment boundaries.", "labels": [], "entities": []}, {"text": "In such a case, the method constructing initial ASM needs to be modified.", "labels": [], "entities": [{"text": "ASM", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.9568132162094116}]}, {"text": "We briefly report here the computation time of our method.", "labels": [], "entities": []}, {"text": "Let us consider Text 4 as an example.", "labels": [], "entities": []}, {"text": "After 15 seconds for full preprocessing, the first iteration took 25 seconds with tto~ = 1.55 and Izow = 1.8.", "labels": [], "entities": [{"text": "tto", "start_pos": 82, "end_pos": 85, "type": "METRIC", "confidence": 0.9524981379508972}, {"text": "Izow", "start_pos": 98, "end_pos": 102, "type": "METRIC", "confidence": 0.9610000848770142}]}, {"text": "The rest of the algorithm took 20 seconds in all.", "labels": [], "entities": []}, {"text": "This experiment was performed on a SPARC Station 20 Model tIS21.", "labels": [], "entities": [{"text": "SPARC Station 20 Model tIS21", "start_pos": 35, "end_pos": 63, "type": "DATASET", "confidence": 0.847180700302124}]}, {"text": "From the result, we may safely say that our method can be applied to voluminous corpora.", "labels": [], "entities": []}, {"text": "shows the performance on sentence alignments for the texts in.", "labels": [], "entities": [{"text": "sentence alignments", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.7204777002334595}]}, {"text": "Combined, Statistics and Dictionary represent the methods using both statistics and dictionary, only statistics and only dictionary, respectively.", "labels": [], "entities": [{"text": "Dictionary", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.830470085144043}]}, {"text": "Both Combined and Dictionary use a CD-ROM version of a JapaneseEnglish dictionary containing 40 thousands entries.", "labels": [], "entities": [{"text": "Dictionary", "start_pos": 18, "end_pos": 28, "type": "DATASET", "confidence": 0.7501067519187927}]}], "tableCaptions": [{"text": " Table 4: Statistically Acquired Keywords", "labels": [], "entities": [{"text": "Statistically Acquired Keywords", "start_pos": 10, "end_pos": 41, "type": "TASK", "confidence": 0.4751269320646922}]}]}