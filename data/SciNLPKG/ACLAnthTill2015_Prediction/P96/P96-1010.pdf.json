{"title": [{"text": "Combining Trigram-based and Feature-based Methods for Context-Sensitive Spelling Correction", "labels": [], "entities": [{"text": "Context-Sensitive Spelling Correction", "start_pos": 54, "end_pos": 91, "type": "TASK", "confidence": 0.6776702006657919}]}], "abstractContent": [{"text": "This paper addresses the problem of correcting spelling errors that result invalid, though unintended words (such as peace and piece, or quiet and quite) and also the problem of correcting particular word usage errors (such as amount and number , or among and between).", "labels": [], "entities": []}, {"text": "Such corrections require contextual information and are not handled by conventional spelling programs such as Unix spell.", "labels": [], "entities": []}, {"text": "First, we introduce a method called Trigrams that uses part-of-speech trigrams to encode the context.", "labels": [], "entities": []}, {"text": "This method uses a small number of parameters compared to previous methods based on word trigrams.", "labels": [], "entities": []}, {"text": "However , it is effectively unable to distinguish among words that have the same part of speech.", "labels": [], "entities": []}, {"text": "For this case, an alternative feature-based method called Bayes performs better; but Bayes is less effective than Trigrams when the distinction among words depends on syntactic constraints.", "labels": [], "entities": []}, {"text": "A hybrid method called Tribayes is then introduced that combines the best of the previous two methods.", "labels": [], "entities": [{"text": "Tribayes", "start_pos": 23, "end_pos": 31, "type": "DATASET", "confidence": 0.8317890763282776}]}, {"text": "The improvement in performance of Tribayes over its components is verified experimentally.", "labels": [], "entities": [{"text": "Tribayes", "start_pos": 34, "end_pos": 42, "type": "DATASET", "confidence": 0.9481407403945923}]}, {"text": "Tribayes is also compared with the grammar checker in Microsoft Word, and is found to have substantially higher performance.", "labels": [], "entities": []}, {"text": "1 Introduction Spelling correction has become a very common technology and is often not perceived as a problem where progress can be made.", "labels": [], "entities": [{"text": "Spelling correction", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.9701282680034637}]}, {"text": "However, conventional spelling checkers, such as Unix spell, are concerned only with spelling errors that result in words that cannot be found in a word list of a given language.", "labels": [], "entities": []}, {"text": "One analysis has shown that up to 15% of spelling errors that result from elementary typographical errors (character insertion, deletion, or transposition) yield another valid word in the language (Peterson, 1986).", "labels": [], "entities": [{"text": "character insertion", "start_pos": 107, "end_pos": 126, "type": "TASK", "confidence": 0.6972438842058182}]}, {"text": "These errors remain undetected by traditional spelling checkers.", "labels": [], "entities": []}, {"text": "In addition to typographical errors, words that can be easily confused with each other (for instance, the homophones peace and piece) also remain undetected.", "labels": [], "entities": []}, {"text": "Recent studies of actual observed spelling errors have estimated that overall, errors resulting invalid words account for anywhere from 25% to over 50% of the errors, depending on the application (Kukich, 1992).", "labels": [], "entities": []}, {"text": "We will use the term context-sensitive spelling correction to refer to the task of fixing spelling errors that result invalid words, such as: (1) * Can I have a peace of cake?", "labels": [], "entities": [{"text": "context-sensitive spelling correction", "start_pos": 21, "end_pos": 58, "type": "TASK", "confidence": 0.5869884689648946}]}, {"text": "where peace was typed when piece was intended.", "labels": [], "entities": []}, {"text": "The task will be cast as one of lexical disambigua-tion: we are given a predefined collection of confusion sets, such as {peace,piece}, {than, then}, etc., which circumscribe the space of spelling errors to look for.", "labels": [], "entities": []}, {"text": "A confusion set means that each word in the set could mistakenly be typed when another word in the set was intended.", "labels": [], "entities": []}, {"text": "The task is to predict, given an occurrence of a word in one of the confusion sets, which word in the set was actually intended.", "labels": [], "entities": []}, {"text": "Previous work on context-sensitive spelling correction and related lexical disambiguation tasks has its limitations.", "labels": [], "entities": [{"text": "context-sensitive spelling correction", "start_pos": 17, "end_pos": 54, "type": "TASK", "confidence": 0.6366248925526937}]}, {"text": "Word-trigram methods (Mays, Dam-erau, and Mercer, 1991) require an extremely large body of text to train the word-trigram model; even with extensive training sets, the problem of sparse data is often acute.", "labels": [], "entities": []}, {"text": "In addition, huge word-trigram tables need to be available at run time.", "labels": [], "entities": []}, {"text": "Moreover , word trigrams are ineffective at capturing long-distance properties such as discourse topic and tense.", "labels": [], "entities": []}, {"text": "Feature-based approaches, such as Bayesian clas-sifters (Gale, Church, and Yarowsky, 1993), decision lists (Yarowsky, 1994), and Bayesian hybrids (Golding, 1995), have had varying degrees of success for the problem of context-sensitive spelling correction.", "labels": [], "entities": [{"text": "context-sensitive spelling correction", "start_pos": 218, "end_pos": 255, "type": "TASK", "confidence": 0.6480665107568105}]}, {"text": "However, we report experiments that show that these methods are of limited effectiveness for cases such as {their, there, they're} and {than, then}, where the predominant distinction to be made among the words is syntactic.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spelling correction has become a very common technology and is often not perceived as a problem where progress can be made.", "labels": [], "entities": [{"text": "Spelling correction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9880965352058411}]}, {"text": "However, conventional spelling checkers, such as Unix spell, are concerned only with spelling errors that result in words that cannot be found in a word list of a given language.", "labels": [], "entities": []}, {"text": "One analysis has shown that up to 15% of spelling errors that result from elementary typographical errors (character insertion, deletion, or transposition) yield another valid word in the language.", "labels": [], "entities": [{"text": "character insertion", "start_pos": 107, "end_pos": 126, "type": "TASK", "confidence": 0.7057937979698181}]}, {"text": "These errors remain undetected by traditional spelling checkers.", "labels": [], "entities": []}, {"text": "In addition to typographical errors, words that can be easily confused with each other (for instance, the homophones peace and piece) also remain undetected.", "labels": [], "entities": []}, {"text": "Recent studies of actual observed spelling errors have estimated that overall, errors resulting invalid words account for anywhere from 25% to over 50% of the errors, depending on the application).", "labels": [], "entities": []}, {"text": "We will use the term context-sensitive spelling correction to refer to the task of fixing spelling errors that result invalid words, such as: (1) * Can I have a peace of cake?", "labels": [], "entities": [{"text": "context-sensitive spelling correction", "start_pos": 21, "end_pos": 58, "type": "TASK", "confidence": 0.58698836962382}]}, {"text": "where peace was typed when piece was intended.", "labels": [], "entities": []}, {"text": "The task will be cast as one of lexical disambiguation: we are given a predefined collection of confusion sets, such as {peace,piece}, {than, then}, etc., which circumscribe the space of spelling errors to look for.", "labels": [], "entities": []}, {"text": "A confusion set means that each word in the set could mistakenly be typed when another word in the set was intended.", "labels": [], "entities": []}, {"text": "The task is to predict, given an occurrence of a word in one of the confusion sets, which word in the set was actually intended.", "labels": [], "entities": []}, {"text": "Previous work on context-sensitive spelling correction and related lexical disambiguation tasks has its limitations.", "labels": [], "entities": [{"text": "context-sensitive spelling correction", "start_pos": 17, "end_pos": 54, "type": "TASK", "confidence": 0.6366248925526937}]}, {"text": "Word-trigram methods require an extremely large body of text to train the word-trigram model; even with extensive training sets, the problem of sparse data is often acute.", "labels": [], "entities": []}, {"text": "In addition, huge word-trigram tables need to be available at run time.", "labels": [], "entities": []}, {"text": "Moreover, word trigrams are ineffective at capturing longdistance properties such as discourse topic and tense.", "labels": [], "entities": []}, {"text": "Feature-based approaches, such as Bayesian classifters, decision lists, and Bayesian hybrids, have had varying degrees of success for the problem of context-sensitive spelling correction.", "labels": [], "entities": [{"text": "context-sensitive spelling correction", "start_pos": 149, "end_pos": 186, "type": "TASK", "confidence": 0.6463867326577505}]}, {"text": "However, we report experiments that show that these methods are of limited effectiveness for cases such as {their, there, they're} and {than, then}, where the predominant distinction to be made among the words is syntactic.: Performance of the baseline method for 18 confusion sets.", "labels": [], "entities": []}, {"text": "\"Train\" and \"Test\" give the number of occurrences of any word in the confusion set in the training and test corpora.", "labels": [], "entities": [{"text": "Test", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.892002284526825}]}, {"text": "\"Most freq.\" is the word in the confusion set that occurred most often in the training corpus.", "labels": [], "entities": []}, {"text": "\"Base\" is the percentage of correct predictions of the baseline system on the test corpus.", "labels": [], "entities": [{"text": "Base\"", "start_pos": 1, "end_pos": 6, "type": "METRIC", "confidence": 0.9770142138004303}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Performance of the baseline method for 18 confusion sets. \"Train\" and \"Test\" give the number  of occurrences of any word in the confusion set in the training and test corpora. \"Most freq.\" is the word", "labels": [], "entities": [{"text": "Most freq.", "start_pos": 187, "end_pos": 197, "type": "METRIC", "confidence": 0.814852237701416}]}, {"text": " Table 2: Performance of the component methods, Baseline (Base), Trigrams (T), and Bayes (B). System  scores are given as percentages of correct predictions. The results are broken down by whether or not all  words in the confusion set would have the same tagging when substituted into the target sentence. The  \"Breakdown\" columns show the percentage of examples that fall under each condition.", "labels": [], "entities": [{"text": "Bayes (B)", "start_pos": 83, "end_pos": 92, "type": "METRIC", "confidence": 0.9219333082437515}]}, {"text": " Table 3: Performance of the hybrid method, Tribayes (TB), as compared with Trigrams (T) and Bayes (B).  System scores are given as percentages of correct predictions. The results are broken down by whether or  not all words in the confusion set would have the same tagging when substituted into the target sentence.  The \"Breakdown\" columns give the percentage of examples under each condition.", "labels": [], "entities": []}, {"text": " Table 4: Overall performance of all methods: Baseline (Base), Trigrams  System scores are given as percentages of correct predictions.", "labels": [], "entities": [{"text": "Baseline", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9173593521118164}]}]}