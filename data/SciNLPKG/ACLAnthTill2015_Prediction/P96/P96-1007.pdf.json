{"title": [{"text": "INVITED TALK Eye Movements and Spoken Language Comprehension", "labels": [], "entities": [{"text": "INVITED TALK Eye Movements", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.5404103100299835}, {"text": "Spoken Language Comprehension", "start_pos": 31, "end_pos": 60, "type": "TASK", "confidence": 0.7188169956207275}]}], "abstractContent": [{"text": "We present an overview of recent work in which eye movements are monitored as people follow spoken instructions to move objects or pictures in a visual workspace.", "labels": [], "entities": []}, {"text": "Subjects naturally make saccadic eye-movements to objects that are closely time-locked to relevant information in the instruction.", "labels": [], "entities": []}, {"text": "Thus the eye-movements provide a window into the rapid mental processes that underlie spoken language comprehension.", "labels": [], "entities": []}, {"text": "We review studies of reference resolution, word recognition, and pragmatic effects on syntactic ambiguity resolution.", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 21, "end_pos": 41, "type": "TASK", "confidence": 0.8827022016048431}, {"text": "word recognition", "start_pos": 43, "end_pos": 59, "type": "TASK", "confidence": 0.8704575598239899}, {"text": "syntactic ambiguity resolution", "start_pos": 86, "end_pos": 116, "type": "TASK", "confidence": 0.7367390791575114}]}, {"text": "Our studies show that people seek to establish reference with respect to their behavioral goals during the earliest moments of linguistic processing.", "labels": [], "entities": []}, {"text": "Moreover, referentially relevant non-linguistic information immediately affects how the linguistic input is initially structured.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many important questions about language comprehension can only be answered by examining processes that are closely time-locked to the linguistic input.", "labels": [], "entities": []}, {"text": "These processes take place quite rapidly and they are largely opaque to introspection.", "labels": [], "entities": []}, {"text": "As a consequence, psycholinguists have increasingly turned to experimental methods designed to tap real-time language processing.", "labels": [], "entities": []}, {"text": "These include a variety of reading time measures as well as paradigms in which subjects monitor the incoming speech for targets or respond to visually presented probes.", "labels": [], "entities": []}, {"text": "The hope is that these \"online\" measures can provide information that can be used to inform and evaluate explicit computational models of language processing.", "labels": [], "entities": []}, {"text": "Although on-line measures have provided increasingly fine-grained information about the time-course of language processing, they ,are also limited in some important respects.", "labels": [], "entities": []}, {"text": "Perhaps the most serious limitation is that they cannot be used to study language in natural tasks with real-world referents.", "labels": [], "entities": []}, {"text": "This makes it difficult to study how interpretation develops.", "labels": [], "entities": []}, {"text": "Moreover, the emphasis on processing \"decontextualized\" language maybe underestimating the importance of interpretive processes in immediate language processing.", "labels": [], "entities": []}, {"text": "Recently, we have been exploring anew paradigm for studying spoken language comprehension.", "labels": [], "entities": []}, {"text": "Participants in our experiments follow spoken instructions to touch or manipulate objects in a visual workspace while we monitor their eye-movements using a lightweight camera mounted on a headband.", "labels": [], "entities": []}, {"text": "The camera, manufactured by Applied Scientific Laboratories, provides an infrared image of the eye at 60Hz.", "labels": [], "entities": [{"text": "Applied Scientific Laboratories", "start_pos": 28, "end_pos": 59, "type": "DATASET", "confidence": 0.888657828172048}]}, {"text": "The center of the pupil and the corneal reflection are tracked to determine the orbit of the eye relative to file head.", "labels": [], "entities": []}, {"text": "Accuracy is better than one degree of arc, with virtually unrestricted head and body movements.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.993181049823761}, {"text": "arc", "start_pos": 38, "end_pos": 41, "type": "METRIC", "confidence": 0.9720200896263123}]}, {"text": "Instructions are spoken into a microphone connected to a Hi-8 VCR.", "labels": [], "entities": []}, {"text": "The VCR also records the participant's field of view from a \"scene\" camera mounted on the headband.", "labels": [], "entities": []}, {"text": "The participant's gaze fixation is superimposed on the video image We analyze each frame of the instructions to determine the location and timing of eye movements with respect to critical words in the instruction.", "labels": [], "entities": []}, {"text": "We find that subjects make eye-movements to objects in the visual workspace that are closely time-locked to relevant information in the instruction.", "labels": [], "entities": []}, {"text": "Thus the timing and patterns of the eye movements provide a window into comprehension processes as the speech unfolds.", "labels": [], "entities": []}, {"text": "Unlike most of the on-line measures that have been used to study spoken language processing in the past, our procedure can be used to examine comprehension during natural tasks with real-world referents [Tanenhaus, M. K., Spivey-Knowlton, M. J.,.", "labels": [], "entities": []}, {"text": "In the remainder of this paper, we review some of our recent work using the visual world paradigm.", "labels": [], "entities": []}, {"text": "We will focus on three areas: (a) reference resolution; (b) word recognition, and (c) the interaction of referential context and syntactic ambiguity resolution.", "labels": [], "entities": [{"text": "reference resolution", "start_pos": 34, "end_pos": 54, "type": "TASK", "confidence": 0.7941587567329407}, {"text": "word recognition", "start_pos": 60, "end_pos": 76, "type": "TASK", "confidence": 0.849128782749176}, {"text": "syntactic ambiguity resolution", "start_pos": 129, "end_pos": 159, "type": "TASK", "confidence": 0.6489559412002563}]}], "datasetContent": [], "tableCaptions": []}