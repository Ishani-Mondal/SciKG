{"title": [{"text": "Integrating Multiple Knowledge Sources to Disambiguate Word Sense: An Exemplar-Based Approach", "labels": [], "entities": [{"text": "Integrating Multiple Knowledge Sources to Disambiguate Word Sense", "start_pos": 0, "end_pos": 65, "type": "TASK", "confidence": 0.7681630700826645}]}], "abstractContent": [{"text": "In this paper, we present anew approach for word sense disambiguation (WSD) using an exemplar-based learning algorithm.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 44, "end_pos": 75, "type": "TASK", "confidence": 0.8292004267374674}]}, {"text": "This approach integrates a diverse set of knowledge sources to disambiguate word sense, including part of speech of neighboring words, morphological form, the un-ordered set of surrounding words, local collocations, and verb-object syntactic relation.", "labels": [], "entities": []}, {"text": "We tested our WSD program, named LEXAS, on both a common data set used in previous work, as well as on a large sense-tagged corpus that we separately constructed.", "labels": [], "entities": [{"text": "WSD", "start_pos": 14, "end_pos": 17, "type": "TASK", "confidence": 0.8715431690216064}, {"text": "LEXAS", "start_pos": 33, "end_pos": 38, "type": "METRIC", "confidence": 0.9720360636711121}]}, {"text": "LEXAS achieves a higher accuracy on the common data set, and performs better than the most frequent heuristic on the highly ambiguous words in the large corpus tagged with the refined senses of WoRDNET.", "labels": [], "entities": [{"text": "LEXAS", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.977698802947998}, {"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9991480112075806}, {"text": "WoRDNET", "start_pos": 194, "end_pos": 201, "type": "DATASET", "confidence": 0.8994448184967041}]}], "introductionContent": [{"text": "One important problem of Natural Language Processing (NLP) is figuring out what a word means when it is used in a particular context.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP)", "start_pos": 25, "end_pos": 58, "type": "TASK", "confidence": 0.7454109092553457}]}, {"text": "The different meanings of a word are listed as its various senses in a dictionary.", "labels": [], "entities": []}, {"text": "The task of Word Sense Disambiguation (WSD) is to identify the correct sense of a word in context.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 12, "end_pos": 43, "type": "TASK", "confidence": 0.7961195160945257}, {"text": "identify the correct sense of a word in context", "start_pos": 50, "end_pos": 97, "type": "TASK", "confidence": 0.6625613239076402}]}, {"text": "Improvement in the accuracy of identifying the correct word sense will result in better machine translation systems, information retrieval systems, etc.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9979459643363953}, {"text": "identifying the correct word sense", "start_pos": 31, "end_pos": 65, "type": "TASK", "confidence": 0.678577721118927}, {"text": "machine translation", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.7445877194404602}, {"text": "information retrieval", "start_pos": 117, "end_pos": 138, "type": "TASK", "confidence": 0.7860666811466217}]}, {"text": "For example, in machine translation, knowing the correct word sense helps to select the appropriate target words to use in order to translate into a target language.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 16, "end_pos": 35, "type": "TASK", "confidence": 0.7792743742465973}]}, {"text": "In this paper, we present anew approach for WSD using an exemplar-based learning algorithm.", "labels": [], "entities": [{"text": "WSD", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.9835197329521179}]}, {"text": "This approach integrates a diverse set of knowledge sources to disambiguate word sense, including part of speech (POS) of neighboring words, morphological form, the unordered set of surrounding words, local collocations, and verb-object syntactic relation.", "labels": [], "entities": []}, {"text": "To evaluate our WSD program, named LEXAS (LEXical Ambiguity-resolving _System), we tested it on a common data set involving the noun \"interest\" used by.", "labels": [], "entities": [{"text": "WSD", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.8568960428237915}, {"text": "LEXAS", "start_pos": 35, "end_pos": 40, "type": "METRIC", "confidence": 0.9823023676872253}]}, {"text": "LEXAS achieves a mean accuracy of 87.4% on this data set, which is higher than the accuracy of 78% reported in.", "labels": [], "entities": [{"text": "LEXAS", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.8623764514923096}, {"text": "mean", "start_pos": 17, "end_pos": 21, "type": "METRIC", "confidence": 0.9724855422973633}, {"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.8971861600875854}, {"text": "accuracy", "start_pos": 83, "end_pos": 91, "type": "METRIC", "confidence": 0.9990039467811584}]}, {"text": "Moreover, to test the scalability of LEXAS, we have acquired a corpus in which 192,800 word occurrences have been manually tagged with senses from WORD-NET, which is a public domain lexical database containing about 95,000 word forms and 70,000 lexical concepts.", "labels": [], "entities": []}, {"text": "These sense tagged word occurrences consist of 191 most frequently occurring and most ambiguous nouns and verbs.", "labels": [], "entities": []}, {"text": "When tested on this large data set, LEXAS performs better than the default strategy of picking the most frequent sense.", "labels": [], "entities": [{"text": "LEXAS", "start_pos": 36, "end_pos": 41, "type": "METRIC", "confidence": 0.9960921406745911}]}, {"text": "To our knowledge, this is the first time that a WSD program has been tested on such a large scale, and yielding results better than the most frequent heuristic on highly ambiguous words with the refined sense distinctions of WOttDNET.", "labels": [], "entities": [{"text": "WSD", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.9553934931755066}, {"text": "WOttDNET", "start_pos": 225, "end_pos": 233, "type": "DATASET", "confidence": 0.9378024339675903}]}], "datasetContent": [{"text": "To evaluate the performance of LEXAS, we conducted two tests, one on a common data set used in, and another on a larger data set that we separately collected.", "labels": [], "entities": [{"text": "LEXAS", "start_pos": 31, "end_pos": 36, "type": "METRIC", "confidence": 0.6273535490036011}]}, {"text": "To our knowledge, very few of the existing work on WSD has been tested and compared on a common data set.", "labels": [], "entities": [{"text": "WSD", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.9641170501708984}]}, {"text": "This is in contrast to established practice in the machine learning community.", "labels": [], "entities": []}, {"text": "This is partly because there are not many common data sets publicly available for testing WSD programs.", "labels": [], "entities": [{"text": "WSD", "start_pos": 90, "end_pos": 93, "type": "TASK", "confidence": 0.9012603759765625}]}, {"text": "One exception is the sense-tagged data set used in, which has been made available in the public domain by Bruce and Wiebe.", "labels": [], "entities": []}, {"text": "This data set consists of 2369 sentences each containing an occurrence of the noun \"interest\" (or its plural form \"interests\") with its correct sense manually tagged.", "labels": [], "entities": []}, {"text": "The noun \"interest\" occurs in six different senses in this data set.", "labels": [], "entities": []}, {"text": "shows the distribution of sense tags from the data set that we obtained.", "labels": [], "entities": []}, {"text": "Note that the sense definitions used in this data set are those from Longman Dictionary of Contemporary English (LDOCE).", "labels": [], "entities": [{"text": "Longman Dictionary of Contemporary English (LDOCE)", "start_pos": 69, "end_pos": 119, "type": "DATASET", "confidence": 0.9621519967913628}]}, {"text": "This does not pose any problem for LEXAS, since LEXAS only requires that there be a division of senses into different classes, regardless of how the sense classes are defined or numbered.", "labels": [], "entities": []}, {"text": "POS of words are given in the data set, as well as the bracketings of noun groups.", "labels": [], "entities": [{"text": "POS", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.977281928062439}]}, {"text": "These are used to determine the POS of neighboring   In the results reported in, they used a test set of 600 randomly selected sentences from the 2369 sentences.", "labels": [], "entities": [{"text": "POS", "start_pos": 32, "end_pos": 35, "type": "METRIC", "confidence": 0.9965127110481262}]}, {"text": "Unfortunately, in the data set made available in the public domain, there is no indication of which sentences are used as test sentences.", "labels": [], "entities": []}, {"text": "As such, we conducted 100 random trials, and in each trial, 600 sentences were randomly selected to form the test set.", "labels": [], "entities": []}, {"text": "LEXAS is trained on the remaining 1769 sentences, and then tested on a separate test set of sentences in each trial.", "labels": [], "entities": [{"text": "LEXAS", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9153937697410583}]}, {"text": "Note that in Bruce and Wiebe's test run, the proportion of sentences in each sense in the test set is approximately equal to their proportion in the whole data set.", "labels": [], "entities": []}, {"text": "Since we use random selection of test sentences, the proportion of each sense in our test set is also approximately equal to their proportion in the whole data set in our random trials.", "labels": [], "entities": []}, {"text": "The average accuracy of LEXAS over 100 random trials is 87.4%, and the standard deviation is 1.37%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9997218251228333}, {"text": "LEXAS", "start_pos": 24, "end_pos": 29, "type": "METRIC", "confidence": 0.8870387077331543}, {"text": "standard", "start_pos": 71, "end_pos": 79, "type": "METRIC", "confidence": 0.9793070554733276}]}, {"text": "In each of our 100 random trials, the accuracy of LEXAS is always higher than the accuracy of 78% reported in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.9996949434280396}, {"text": "LEXAS", "start_pos": 50, "end_pos": 55, "type": "METRIC", "confidence": 0.9897038340568542}, {"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.9991864562034607}]}, {"text": "Bruce and Wiebe also performed a separate test by using a subset of the \"interest\" data set with only 4 senses (sense 1, 4, 5, and 6), so as to compare their results with previous work on WSD, which were tested on 4 senses of the noun \"interest\".", "labels": [], "entities": [{"text": "interest\" data set", "start_pos": 73, "end_pos": 91, "type": "DATASET", "confidence": 0.7894572764635086}, {"text": "WSD", "start_pos": 188, "end_pos": 191, "type": "TASK", "confidence": 0.624142050743103}]}, {"text": "However, the work of were not based on the present set of sentences, so the comparison is only suggestive.", "labels": [], "entities": []}, {"text": "We reproduced in the results of past work as well as the classification accuracy of LEXAS, which is 89.9% with a standard deviation of 1.09% over 100 random trials.", "labels": [], "entities": [{"text": "classification", "start_pos": 57, "end_pos": 71, "type": "TASK", "confidence": 0.5859284996986389}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.8290694952011108}, {"text": "LEXAS", "start_pos": 84, "end_pos": 89, "type": "METRIC", "confidence": 0.976824939250946}]}, {"text": "In summary, when tested on the noun \"interest\", LEXAS gives higher classification accuracy than previous work on WSD.", "labels": [], "entities": [{"text": "LEXAS", "start_pos": 48, "end_pos": 53, "type": "METRIC", "confidence": 0.995556652545929}, {"text": "accuracy", "start_pos": 82, "end_pos": 90, "type": "METRIC", "confidence": 0.8456906080245972}, {"text": "WSD", "start_pos": 113, "end_pos": 116, "type": "TASK", "confidence": 0.8562481999397278}]}, {"text": "In order to evaluate the relative contribution of the knowledge sources, including: Relative Contribution of Knowledge Sources phological form; (2) unordered set of surrounding words; (3) local collocations; and (4) verb to the left (verb-object syntactic relation), we conducted 4 separate runs of 100 random trials each.", "labels": [], "entities": []}, {"text": "In each run, we utilized only one knowledge source and compute the average classification accuracy and the standard deviation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9073836207389832}]}, {"text": "The results are given in.", "labels": [], "entities": []}, {"text": "Local collocation knowledge yields the highest accuracy, followed by POS and morphological form.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9995149374008179}, {"text": "POS", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.9185810685157776}]}, {"text": "Surrounding words give lower accuracy, perhaps because in our work, only the current sentence forms the surrounding context, which averages about 20 words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9988139867782593}]}, {"text": "Previous work on using the unordered set of surrounding words have used a much larger window, such as the 100-word window of, and the 2-sentence context of (.", "labels": [], "entities": []}, {"text": "Verb-object syntactic relation is the weakest knowledge source.", "labels": [], "entities": []}, {"text": "Our experimental finding, that local collocations are the most predictive, agrees with past observation that humans need a narrow window of only a few words to perform WSD (.", "labels": [], "entities": [{"text": "WSD", "start_pos": 168, "end_pos": 171, "type": "TASK", "confidence": 0.9325082302093506}]}, {"text": "The processing speed of LEXAS is satisfactory.", "labels": [], "entities": [{"text": "LEXAS", "start_pos": 24, "end_pos": 29, "type": "METRIC", "confidence": 0.7036599516868591}]}, {"text": "Running on an SGI Unix workstation, LEXAS can process about 15 examples per second when tested on the \"interest\" data set.", "labels": [], "entities": [{"text": "LEXAS", "start_pos": 36, "end_pos": 41, "type": "METRIC", "confidence": 0.8879521489143372}]}, {"text": "Previous research on WSD tend to be tested only on a dozen number of words, where each word frequently has either two or a few senses.", "labels": [], "entities": [{"text": "WSD", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9871362447738647}]}, {"text": "To test the scalability of LEXAS, we have gathered a corpus in which 192,800 word occurrences have been manually tagged with senses from WoRDNET 1.5.", "labels": [], "entities": [{"text": "WoRDNET 1.5", "start_pos": 137, "end_pos": 148, "type": "DATASET", "confidence": 0.866705447435379}]}, {"text": "This data set is almost two orders of magnitude larger in size than the above \"interest\" data set.", "labels": [], "entities": [{"text": "interest\" data set", "start_pos": 79, "end_pos": 97, "type": "DATASET", "confidence": 0.8134193122386932}]}, {"text": "Manual tagging was done by university undergraduates majoring in Linguistics, and approximately one man-year of efforts were expended in tagging our data set.", "labels": [], "entities": []}, {"text": "These 192,800 word occurrences consist of 121 nouns and 70 verbs which are the most frequently occurring and most ambiguous words of English.", "labels": [], "entities": []}, {"text": "The 121 nouns are: action activity age air area art board body book business car case center century change child church city class college community company condition cost country course day death development difference door effect effort end example experience face fact family field figure foot force form girl government ground head history home hour house information interest job land law level life light lineman material matter member mind moment money month name nation need number order part party picture place plan point policy position power pressure problem process program public purpose question reason result right room school section sense service side society stage state step student study surface system table term thing time town type use value voice waterway word work world The 70 verbs are: add appear ask become believe bring build call carry change come consider continue determine develop draw expect fall give go grow happen help hold indicate involve keep know lead leave lie like live look lose mean meet move need open pay raise read receive remember require return rise run see seem send set show sit speak stand start stop strike take talk tell think turn wait walk want work write For this set of nouns and verbs, the average number of senses per noun is 7.8, while the average number of senses per verb is 12.0.", "labels": [], "entities": [{"text": "action activity age air area art board body book business car case center century change child church city class college community company condition cost country course day death development difference door effect effort end example experience face fact family field figure foot force form girl government ground head history home hour house information interest job land law level life light lineman material matter member mind moment money month name nation need number order part party picture place plan point policy position power pressure problem process program public purpose question reason result right room school section sense service side society stage state step student study surface system table term thing time town", "start_pos": 19, "end_pos": 751, "type": "TASK", "confidence": 0.74317318227914}]}, {"text": "We draw our sentences containing the occurrences of the 191 words listed above from the combined corpus of the 1 million word Brown corpus and the 2.5 million word Wall Street Journal (WSJ) corpus.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 126, "end_pos": 138, "type": "DATASET", "confidence": 0.8577238917350769}, {"text": "Wall Street Journal (WSJ) corpus", "start_pos": 164, "end_pos": 196, "type": "DATASET", "confidence": 0.8869031327111381}]}, {"text": "For every word in the two lists, up to 1,500 sentences each containing an occurrence of the word are extracted from the combined corpus.", "labels": [], "entities": []}, {"text": "In all, there are about 113,000 noun occurrences and about 79,800 verb occurrences.", "labels": [], "entities": []}, {"text": "This set of 121 nouns accounts for about 20% of all occurrences of nouns that one expects to encounter in any unrestricted English text.", "labels": [], "entities": []}, {"text": "Similarly, about 20% of all verb occurrences in any unrestricted text come from the set of 70 verbs chosen.", "labels": [], "entities": []}, {"text": "We estimate that there are 10-20% errors in our sense-tagged data set.", "labels": [], "entities": []}, {"text": "To get an idea of how the sense assignments of our data set compare with those provided by WoRDNET linguists in SEMCOR, the sense-tagged subset of Brown corpus prepared by, we compare 68.6%: Evaluation on a Large Data Set a subset of the occurrences that overlap.", "labels": [], "entities": []}, {"text": "Out of 5,317 occurrences that overlap, about 57% of the sense assignments in our data set agree with those in SEMCOR.", "labels": [], "entities": [{"text": "SEMCOR", "start_pos": 110, "end_pos": 116, "type": "DATASET", "confidence": 0.8611968159675598}]}, {"text": "This should not be too surprising, as it is widely believed that sense tagging using the full set of refined senses found in a large dictionary like WORDNET involve making subtle human judgments (, such that there are many genuine cases where two humans will not agree fully on the best sense assignments.", "labels": [], "entities": [{"text": "sense tagging", "start_pos": 65, "end_pos": 78, "type": "TASK", "confidence": 0.8259587585926056}]}, {"text": "We evaluated LEXAS on this larger set of noisy, sense-tagged data.", "labels": [], "entities": [{"text": "LEXAS", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.996732234954834}]}, {"text": "We first set aside two subsets for testing.", "labels": [], "entities": []}, {"text": "The first test set, named BC50, consists of 7,119 occurrences of the 191 content words that occur in 50 text files of the Brown corpus.", "labels": [], "entities": [{"text": "BC50", "start_pos": 26, "end_pos": 30, "type": "METRIC", "confidence": 0.443744957447052}, {"text": "Brown corpus", "start_pos": 122, "end_pos": 134, "type": "DATASET", "confidence": 0.9413370192050934}]}, {"text": "The second test set, named WSJ6, consists of 14,139 occurrences of the 191 content words that occur in 6 text files of the WSJ corpus.", "labels": [], "entities": [{"text": "WSJ6", "start_pos": 27, "end_pos": 31, "type": "DATASET", "confidence": 0.9364359378814697}, {"text": "WSJ corpus", "start_pos": 123, "end_pos": 133, "type": "DATASET", "confidence": 0.9770925641059875}]}, {"text": "We compared the classification accuracy of LEXAS against the default strategy of picking the most frequent sense.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.7520103454589844}, {"text": "LEXAS", "start_pos": 43, "end_pos": 48, "type": "METRIC", "confidence": 0.8461833596229553}]}, {"text": "This default strategy has been advocated as the baseline performance level for comparison with WSD programs (.", "labels": [], "entities": []}, {"text": "There are two instantiations of this strategy in our current evaluation.", "labels": [], "entities": []}, {"text": "Since WORDNET orders its senses such that sense 1 is the most frequent sense, one possibility is to always pick sense 1 as the best sense assignment.", "labels": [], "entities": []}, {"text": "This assignment method does not even need to look at the training sentences.", "labels": [], "entities": []}, {"text": "We call this method \"Sense 1\" in.", "labels": [], "entities": []}, {"text": "Another assignment method is to determine the most frequently occurring sense in the training sentences, and to assign this sense to all test sentences.", "labels": [], "entities": []}, {"text": "We call this method \"Most Frequent\" in.", "labels": [], "entities": [{"text": "Frequent", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.7219127416610718}]}, {"text": "The accuracy of LEXAS on these two test sets is given in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997101426124573}, {"text": "LEXAS", "start_pos": 16, "end_pos": 21, "type": "METRIC", "confidence": 0.9913062453269958}]}, {"text": "Our results indicate that exemplar-based classification of word senses scales up quite well when tested on a large set of words.", "labels": [], "entities": [{"text": "exemplar-based classification of word senses", "start_pos": 26, "end_pos": 70, "type": "TASK", "confidence": 0.8425196886062623}]}, {"text": "The classification accuracy of LEXAS is always better than the default strategy of picking the most frequent sense.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9675378203392029}, {"text": "LEXAS", "start_pos": 31, "end_pos": 36, "type": "METRIC", "confidence": 0.9256157875061035}]}, {"text": "We believe that our result is significant, especially when the training data is noisy, and the words are highly ambiguous with a large number of refined sense distinctions per word.", "labels": [], "entities": []}, {"text": "The accuracy on Brown corpus test files is lower than that achieved on the Wall Street Journal test files, primarily because the Brown corpus consists of texts from a wide variety of genres, including newspaper reports, newspaper editorial, biblical passages, science and mathematics articles, general fiction, romance story, humor, etc.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995802044868469}, {"text": "Brown corpus test files", "start_pos": 16, "end_pos": 39, "type": "DATASET", "confidence": 0.9117802679538727}, {"text": "Wall Street Journal test files", "start_pos": 75, "end_pos": 105, "type": "DATASET", "confidence": 0.9532572507858277}, {"text": "Brown corpus", "start_pos": 129, "end_pos": 141, "type": "DATASET", "confidence": 0.8640468120574951}, {"text": "general fiction, romance story, humor", "start_pos": 294, "end_pos": 331, "type": "TASK", "confidence": 0.593512373311179}]}, {"text": "It is harder to dis-45 ambiguate words coming from such a wide variety of texts.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Features for Collocations", "labels": [], "entities": [{"text": "Collocations", "start_pos": 23, "end_pos": 35, "type": "TASK", "confidence": 0.869314968585968}]}, {"text": " Table 2: Distribution of Sense Tags", "labels": [], "entities": [{"text": "Distribution of Sense Tags", "start_pos": 10, "end_pos": 36, "type": "TASK", "confidence": 0.8826863318681717}]}, {"text": " Table 3: Comparison with previous results", "labels": [], "entities": []}, {"text": " Table 4:  Relative Contribution of Knowledge  Sources", "labels": [], "entities": [{"text": "Relative Contribution of Knowledge", "start_pos": 11, "end_pos": 45, "type": "TASK", "confidence": 0.9201516360044479}]}, {"text": " Table 5: Evaluation on a Large Data Set", "labels": [], "entities": []}]}