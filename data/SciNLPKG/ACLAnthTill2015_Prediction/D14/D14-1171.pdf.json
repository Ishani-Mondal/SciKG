{"title": [{"text": "Fast and Accurate Misspelling Correction in Large Corpora", "labels": [], "entities": [{"text": "Accurate", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.9952326416969299}]}], "abstractContent": [{"text": "There are several NLP systems whose accuracy depends crucially on finding mis-spellings fast.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 36, "end_pos": 44, "type": "METRIC", "confidence": 0.9980955719947815}]}, {"text": "However, the classical approach is based on a quadratic time algorithm with 80% coverage.", "labels": [], "entities": []}, {"text": "We present a novel algorithm for misspelling detection, which runs inconstant time and improves the coverage to more than 96%.", "labels": [], "entities": [{"text": "misspelling detection", "start_pos": 33, "end_pos": 54, "type": "TASK", "confidence": 0.9636858403682709}, {"text": "coverage", "start_pos": 100, "end_pos": 108, "type": "METRIC", "confidence": 0.9942277669906616}]}, {"text": "We use this algorithm together with across document coreference system in order to find proper name misspellings.", "labels": [], "entities": []}, {"text": "The experiments confirmed significant improvement over the state of the art.", "labels": [], "entities": []}], "introductionContent": [{"text": "The problem of finding the misspelled words in a corpus is an important issue for many NLP systems which have to process large collections of text documents, like news or tweets corpora, digitalized libraries etc.", "labels": [], "entities": []}, {"text": "Any accurate systems, such as the ones developed for cross document coreference, text similarity, semantic search or digital humanities, should be able to handle the misspellings in corpora.", "labels": [], "entities": [{"text": "cross document coreference", "start_pos": 53, "end_pos": 79, "type": "TASK", "confidence": 0.7150944868723551}, {"text": "text similarity", "start_pos": 81, "end_pos": 96, "type": "TASK", "confidence": 0.705040454864502}]}, {"text": "However, the issue is not easy and the required processing time, memory or the dependence on external resources grow fast with the size of the analyzed corpus; consequently, most of the existing algorithms are inefficient.", "labels": [], "entities": []}, {"text": "In this paper, we present a novel algorithm for misspelling detection which overcomes the drawbacks of the previous approaches and we show that this algorithm is instrumental in improving the state of the art of across document coreference system.", "labels": [], "entities": [{"text": "misspelling detection", "start_pos": 48, "end_pos": 69, "type": "TASK", "confidence": 0.8980028927326202}, {"text": "across document coreference", "start_pos": 212, "end_pos": 239, "type": "TASK", "confidence": 0.6007418036460876}]}, {"text": "Many spelling errors in a corpus are accidental and usually just one or two letters in a word are affected, like existnece vs. the dictionary form existence.", "labels": [], "entities": []}, {"text": "Such misspellings are rather a unique phenomenon occurring randomly in a text.", "labels": [], "entities": []}, {"text": "For an automatic speller which has access to a dictionary, finding and compiling a list of correct candidates for the misspelled words like the one above is not very difficult.", "labels": [], "entities": []}, {"text": "However, not all misspellings are in this category.", "labels": [], "entities": []}, {"text": "To begin with, proper nouns, especially foreign proper names, are not present in the dictionary and their misspelling may affect more than one or two characters.", "labels": [], "entities": []}, {"text": "Moreover, the misspelling of proper names may not be random, for example there might be different spellings of the same Chinese or Russian name in English, the incorrect ones occurring with some frequency.", "labels": [], "entities": []}, {"text": "Also, especially if the corpus contains documents written by nonnative speakers, the number of characters varying between the correct and the actual written form maybe more than two.", "labels": [], "entities": []}, {"text": "In this case, finding and compiling the list of correct candidates is computationally challenging for traditional algorithms, as the distance between the source string and the words in the candidates list is high.", "labels": [], "entities": []}, {"text": "The Levenshtein distance has been used to compile a list of correct form candidates fora misspelled word.", "labels": [], "entities": [{"text": "Levenshtein distance", "start_pos": 4, "end_pos": 24, "type": "METRIC", "confidence": 0.6017001271247864}]}, {"text": "The Levenshtein distance between two strings counts the number of changes needed to transform one string into the other, where a change is one of the basic edit operations: deletion, insertion, substitution of a character and the transposition of two characters.", "labels": [], "entities": [{"text": "Levenshtein distance", "start_pos": 4, "end_pos": 24, "type": "METRIC", "confidence": 0.775871753692627}]}, {"text": "The Edit Distance algorithm, (ED) computes the similarity between two strings according to the Levenshtein distance.", "labels": [], "entities": []}, {"text": "Most of the random misspellings which are produced by a native speaker are within one or maximum two basic edit operations.", "labels": [], "entities": []}, {"text": "For this reason the ED algorithm is the most common way to detect and correct the misspellings.", "labels": [], "entities": [{"text": "ED", "start_pos": 20, "end_pos": 22, "type": "METRIC", "confidence": 0.9182348847389221}]}, {"text": "However, there is a major inconvenience associated with the use of ED, namely, ED runs in quadratic time considering the length of the strings, O(n 2 ).", "labels": [], "entities": []}, {"text": "The computation time for more than a few thousands pairs is up to several tens of seconds, which is impracticably large for most of large scale applications.", "labels": [], "entities": []}, {"text": "By comparison, the number of proper names occurring in a medium sized English news corpus is around 200, 000, which means that there are some 200, 000, 000 pairs.", "labels": [], "entities": []}, {"text": "In order to cope with the need fora lower computation time, on the basis of ED, a series of algorithms have been developed that run in linear time.", "labels": [], "entities": [{"text": "ED", "start_pos": 76, "end_pos": 78, "type": "METRIC", "confidence": 0.4882616698741913}]}, {"text": "Unfortunately, this improvement is not enough for practical applications which involve a large amount of data coming from large corpora.", "labels": [], "entities": []}, {"text": "The reason is two-fold: firstly, the linear time is still too slow () and secondly, the required memory depends both on the strings' length and on the number of different characters between the source string and the correct word, and may well exceed several GBs.", "labels": [], "entities": []}, {"text": "Another solution is to index the corpus using structures like trie trees, or large finite state automata.", "labels": [], "entities": []}, {"text": "However, this solution may require large amounts of memory and is inefficient when the number of characters that differ between the source string and the candidate words is more than two characters).", "labels": [], "entities": []}, {"text": "We focus specifically on misspellings for which there is no dictionary containing the correct form and/or for which the Levenshtein distance to the correct word maybe higher than two characters.", "labels": [], "entities": [{"text": "Levenshtein distance", "start_pos": 120, "end_pos": 140, "type": "METRIC", "confidence": 0.6941505819559097}]}, {"text": "For this purpose, we developed a novel approach to misspelling correction based on anon indexing algorithm, which we call the prime mapping algorithm, PM.", "labels": [], "entities": [{"text": "misspelling correction", "start_pos": 51, "end_pos": 73, "type": "TASK", "confidence": 0.8889079988002777}]}, {"text": "PM runs inconstant time, O(1), with insignificant memory consumption.", "labels": [], "entities": [{"text": "O", "start_pos": 25, "end_pos": 26, "type": "METRIC", "confidence": 0.994155764579773}]}, {"text": "The running time of the PM algorithm does not depend either on the strings' length or on the number of different characters between the source string and the candidate word.", "labels": [], "entities": [{"text": "PM", "start_pos": 24, "end_pos": 26, "type": "TASK", "confidence": 0.9542213678359985}]}, {"text": "It requires a static amount of memory, ranging from a few KBs to a maximum of a few MBs, irrespective of the size of the corpus or the number of pairs for which the misspelling relationship is tested.", "labels": [], "entities": []}, {"text": "We run a series of experiments using PM on various corpora in English and Italian.", "labels": [], "entities": []}, {"text": "The results confirm that PM is practical for large corpora.", "labels": [], "entities": [{"text": "PM", "start_pos": 25, "end_pos": 27, "type": "TASK", "confidence": 0.8801116347312927}]}, {"text": "It successfully finds the candidate words for misspellings even for large Levenshtein distances, being more than 30 times faster than a linear algorithm, and several hundred times faster than ED.", "labels": [], "entities": [{"text": "ED", "start_pos": 192, "end_pos": 194, "type": "METRIC", "confidence": 0.49009469151496887}]}, {"text": "The running time difference is due to the fact that PM maps the strings into numbers and performs only one arithmetic operation in order to decide whether the two strings maybe in a misspelling relationship.", "labels": [], "entities": []}, {"text": "Instead of a quadratic number of characters comparisons, PM executes only one arithmetic operation with integers.", "labels": [], "entities": [{"text": "PM", "start_pos": 57, "end_pos": 59, "type": "TASK", "confidence": 0.9238477945327759}]}, {"text": "We also report here the results obtained when using PM inside across document coreference system for proper nouns.", "labels": [], "entities": [{"text": "PM inside across document coreference", "start_pos": 52, "end_pos": 89, "type": "TASK", "confidence": 0.4675648629665375}]}, {"text": "Correcting a proper name misspelling is actually a more complex task than correcting a misspelled common word.", "labels": [], "entities": [{"text": "Correcting a proper name misspelling", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.6910497725009919}]}, {"text": "Some misspellings may not be random and in order to cope with repetitive misspellings, as the ones resulting from the transliteration of foreign names, the PM is combined with a statistical learning algorithm which estimates the probability of a certain type of misspelling considering the surrounding characters in the source string.", "labels": [], "entities": []}, {"text": "Unlike with common words, where a misspelling is obvious, in the case of proper names, John vs. Jon for example, it is unclear whether we are looking at two different names or a misspelling.", "labels": [], "entities": []}, {"text": "The string similarity evidence is combined with contextual evidence provided by a CDC system to disambiguate.", "labels": [], "entities": []}, {"text": "To evaluate the PM algorithm we use publicly available misspelling annotated corpora containing documents created by both native and nonnative speakers.", "labels": [], "entities": [{"text": "PM", "start_pos": 16, "end_pos": 18, "type": "TASK", "confidence": 0.9040714502334595}]}, {"text": "The PM within a CDC system for proper names is evaluated using CRIPCO.", "labels": [], "entities": [{"text": "PM", "start_pos": 4, "end_pos": 6, "type": "METRIC", "confidence": 0.9960235357284546}, {"text": "CRIPCO", "start_pos": 63, "end_pos": 69, "type": "DATASET", "confidence": 0.8139955401420593}]}, {"text": "The experiments confirm that PM is a competitive algorithm and that the CDC system gains inaccuracy by using a module of misspelling correction.", "labels": [], "entities": [{"text": "PM", "start_pos": 29, "end_pos": 31, "type": "TASK", "confidence": 0.8949066400527954}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we review the relevant literature.", "labels": [], "entities": []}, {"text": "In Section 3 we introduce the PM algorithm and compare it against other algorithms.", "labels": [], "entities": [{"text": "PM", "start_pos": 30, "end_pos": 32, "type": "TASK", "confidence": 0.5159788727760315}]}, {"text": "In Section 4 we present the CDC system with misspelling correction for proper names.", "labels": [], "entities": []}, {"text": "In Section 5 we present the results obtained on English and Italian corpora.", "labels": [], "entities": []}], "datasetContent": [{"text": "We performed a set of experiments on different corpora in order to evaluate: (1) the performances of the PM algorithm for misspelling detection, (2) the accuracy of proper name misspelling pattern acquisition from large corpora, and (3) the improvements of a CDC system, employing a correction module for proper name misspellings.", "labels": [], "entities": [{"text": "misspelling detection", "start_pos": 122, "end_pos": 143, "type": "TASK", "confidence": 0.9334841668605804}, {"text": "accuracy", "start_pos": 153, "end_pos": 161, "type": "METRIC", "confidence": 0.9990659356117249}, {"text": "proper name misspelling pattern acquisition", "start_pos": 165, "end_pos": 208, "type": "TASK", "confidence": 0.8241023421287537}]}, {"text": "In Section 5.1 the accuracy of the PM algorithm is tested on various corpora containing annotated misspellings of English words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9994096755981445}, {"text": "PM", "start_pos": 35, "end_pos": 37, "type": "TASK", "confidence": 0.8009240627288818}]}, {"text": "In particular, we were interested to seethe results when the edit distance between the misspelled pair is bigger than 3, because handling bigger values fork is crucial for finding misspelling errors produced by non-native speakers.", "labels": [], "entities": []}, {"text": "The evaluation is directly relevant for the correction of the spelling of foreign names.", "labels": [], "entities": [{"text": "correction of the spelling of foreign names", "start_pos": 44, "end_pos": 87, "type": "TASK", "confidence": 0.6465670381273542}]}, {"text": "In Section 5.2 the proper name misspelling patterns were extracted from two large news corpora.", "labels": [], "entities": []}, {"text": "One corpus is part of the English Gigawords, LDC2009T13) and the second corpus is Adige500k in Italian ().", "labels": [], "entities": [{"text": "English Gigawords", "start_pos": 26, "end_pos": 43, "type": "DATASET", "confidence": 0.8810530006885529}]}, {"text": "We use a Named Entity Recognizer which has an accuracy above 90% for proper names.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 46, "end_pos": 54, "type": "METRIC", "confidence": 0.9985349178314209}]}, {"text": "We evaluated the accuracy of the patterns by random sampling.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9992817044258118}]}, {"text": "In Section 5.3 the accuracy of the CDC system with the correction module for proper name misspellings was tested against a gold standard.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9995704293251038}, {"text": "proper name misspellings", "start_pos": 77, "end_pos": 101, "type": "TASK", "confidence": 0.6004188060760498}]}, {"text": "We consider the following publicly available English corpora containing the annotation of the misspelled words: Birkbeck, Aspell, Holbrook, Wikipidia.", "labels": [], "entities": [{"text": "Birkbeck", "start_pos": 112, "end_pos": 120, "type": "DATASET", "confidence": 0.6143444776535034}, {"text": "Aspell", "start_pos": 122, "end_pos": 128, "type": "DATASET", "confidence": 0.6284974813461304}, {"text": "Holbrook", "start_pos": 130, "end_pos": 138, "type": "DATASET", "confidence": 0.5444644689559937}, {"text": "Wikipidia", "start_pos": 140, "end_pos": 149, "type": "DATASET", "confidence": 0.9162411093711853}]}, {"text": "Birkbeck is a heterogeneous collection of documents, so in the experiments below we refer to each document separately.", "labels": [], "entities": [{"text": "Birkbeck", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9269123673439026}]}, {"text": "In particular we distinguish between misspellings of native speakers vs. misspelling of non-native speakers.", "labels": [], "entities": []}, {"text": "shows that there are two types of corpora.", "labels": [], "entities": []}, {"text": "For the first type, the misspellings found within two characters are between 80% and 100% of the whole number of misspellings.", "labels": [], "entities": []}, {"text": "For the second type, less than 50% of the misspellings are within two characters.The second category is represented by the misspellings of nonnative speakers.", "labels": [], "entities": []}, {"text": "The misspellings are far from the correct forms and they represent chunks of phonetically similar phonemes, like boiz vs. boys.", "labels": [], "entities": []}, {"text": "The situation of the foreign name misspellings is likely to be similar to the misspellings found in the second type of corpora.", "labels": [], "entities": []}, {"text": "For those cases, handling a k value bigger than 2 is crucial.", "labels": [], "entities": []}, {"text": "Not only the non-indexing methods, but also indexing ones are rather inefficient fork values bigger than 2 for large corpora.", "labels": [], "entities": []}, {"text": "The PM algorithm does not have this drawback, and we tested the coverage of the errors we found for values of k ranging from 3 to 10.", "labels": [], "entities": [{"text": "PM", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.7236890196800232}, {"text": "coverage", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9603118300437927}]}, {"text": "In we plot the distributions for the The results showed PM is also able to find the phonemically similar misspellings.", "labels": [], "entities": []}, {"text": "We can see that fork bigger than 9 the number of misspellings is not significant.", "labels": [], "entities": []}, {"text": "The PM algorithm performed very well, being able to find the misspellings even for large k values.", "labels": [], "entities": [{"text": "PM", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.783514142036438}]}, {"text": "There were 47, 837 words in Aspell, in Birkbeck, and PM found all the misspelling pairs in a running time of 25 minutes.", "labels": [], "entities": [{"text": "Aspell", "start_pos": 28, "end_pos": 34, "type": "DATASET", "confidence": 0.941061794757843}, {"text": "Birkbeck", "start_pos": 39, "end_pos": 47, "type": "DATASET", "confidence": 0.7837539911270142}, {"text": "PM", "start_pos": 53, "end_pos": 55, "type": "METRIC", "confidence": 0.9508194327354431}]}, {"text": "This is a very competitive time, even for indexing methods.", "labels": [], "entities": [{"text": "indexing", "start_pos": 42, "end_pos": 50, "type": "TASK", "confidence": 0.9771146178245544}]}, {"text": "For k above 8 the access to the hash table containing the prime combinations was slower, but not significantly so.", "labels": [], "entities": []}, {"text": "We extracted the set of names using a NER from the two corpora, LDC2009T13 and Adige500k.", "labels": [], "entities": [{"text": "LDC2009T13", "start_pos": 64, "end_pos": 74, "type": "DATASET", "confidence": 0.8263387680053711}, {"text": "Adige500k", "start_pos": 79, "end_pos": 88, "type": "DATASET", "confidence": 0.9371887445449829}]}, {"text": "The set of proper names is rather large in both corpora -160, 869 names from the English corpus and 185, 508 from the Italian corpus.", "labels": [], "entities": [{"text": "English corpus", "start_pos": 81, "end_pos": 95, "type": "DATASET", "confidence": 0.8996257483959198}]}, {"text": "Apparently, the quasi-similar names, which are considered as misspelled name candidates, is very high.", "labels": [], "entities": []}, {"text": "In we plot this data.", "labels": [], "entities": []}, {"text": "The English Cand and Italian Cand are absolute values, while the English True and Italian True represent percentages.", "labels": [], "entities": [{"text": "English Cand", "start_pos": 4, "end_pos": 16, "type": "DATASET", "confidence": 0.8318067193031311}, {"text": "English True", "start_pos": 65, "end_pos": 77, "type": "DATASET", "confidence": 0.713670402765274}]}, {"text": "For example, a name of length 5 is likely to have around 23 misspelling candidates, but only 17% of them are likely to be true misspellings, the rest being different names.", "labels": [], "entities": []}, {"text": "The numbers are estimated considering samples having the size between 30 and 50, for each name length.", "labels": [], "entities": []}, {"text": "The percentages change rapidly with the length of the string.", "labels": [], "entities": []}, {"text": "For names with the length bigger than 11, the probability that a misspelling candidate is a true misspelling is more than 98%.", "labels": [], "entities": []}, {"text": "This fact suggests a strategy for pattern extraction: start from the higher name length towards the lower length names.", "labels": [], "entities": [{"text": "pattern extraction", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.7998538911342621}]}, {"text": "The patterns found by the algorithm described in Section 4 have between 900 and 20 occurrences.", "labels": [], "entities": []}, {"text": "There are 12 patterns having more than 400 occurrences, 20 having between 20 and 50 occurrences, see.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. The last column  indicates how many times the algorithm is slower  than the PM in its basic form.", "labels": [], "entities": [{"text": "PM", "start_pos": 86, "end_pos": 88, "type": "METRIC", "confidence": 0.8461140990257263}]}, {"text": " Table 2: ED variants versus MP", "labels": [], "entities": []}]}