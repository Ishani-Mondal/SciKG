{"title": [{"text": "Modeling Term Translation for Document-informed Machine Translation", "labels": [], "entities": [{"text": "Modeling Term Translation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8225458065668741}, {"text": "Document-informed Machine Translation", "start_pos": 30, "end_pos": 67, "type": "TASK", "confidence": 0.6298962235450745}]}], "abstractContent": [{"text": "Term translation is of great importance for statistical machine translation (SMT), especially document-informed SMT.", "labels": [], "entities": [{"text": "Term translation", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9365552365779877}, {"text": "statistical machine translation (SMT)", "start_pos": 44, "end_pos": 81, "type": "TASK", "confidence": 0.8187690873940786}, {"text": "document-informed SMT", "start_pos": 94, "end_pos": 115, "type": "TASK", "confidence": 0.45852161943912506}]}, {"text": "In this paper, we investigate three issues of term translation in the context of document-informed SMT and propose three corresponding models: (a) a term translation disambiguation model which selects desirable translations for terms in the source language with domain information, (b) a term translation consistency model that encourages consistent translations for terms with a high strength of translation consistency throughout a document, and (c) a term bracketing model that rewards translation hypotheses where bracketable source terms are translated as a whole unit.", "labels": [], "entities": [{"text": "term translation", "start_pos": 46, "end_pos": 62, "type": "TASK", "confidence": 0.7348431646823883}, {"text": "SMT", "start_pos": 99, "end_pos": 102, "type": "TASK", "confidence": 0.7261546850204468}, {"text": "term translation disambiguation", "start_pos": 149, "end_pos": 180, "type": "TASK", "confidence": 0.7418516278266907}, {"text": "term bracketing", "start_pos": 454, "end_pos": 469, "type": "TASK", "confidence": 0.6986128389835358}]}, {"text": "We integrate the three models into hierarchical phrase-based SMT and evaluate their effectiveness on NIST Chinese-English translation tasks with large-scale training data.", "labels": [], "entities": [{"text": "SMT", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.7540377378463745}, {"text": "NIST Chinese-English translation tasks", "start_pos": 101, "end_pos": 139, "type": "TASK", "confidence": 0.7429242432117462}]}, {"text": "Experiment results show that all three models can achieve significant improvements over the baseline.", "labels": [], "entities": []}, {"text": "Additionally, we can obtain a further improvement when combining the three models.", "labels": [], "entities": []}], "introductionContent": [{"text": "A term is a linguistic expression that is used as the designation of a defined concept in a language.", "labels": [], "entities": []}, {"text": "As terms convey concepts of a text, term translation becomes crucial when the text is translated from its original language to another language.", "labels": [], "entities": [{"text": "term translation", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.7769492268562317}]}, {"text": "The translations of terms are often affected by the domain in which terms are used and the context that surrounds terms (.", "labels": [], "entities": []}, {"text": "In this paper, we study domain-specific and context-sensitive term translation for SMT.", "labels": [], "entities": [{"text": "context-sensitive term translation", "start_pos": 44, "end_pos": 78, "type": "TASK", "confidence": 0.6263420581817627}, {"text": "SMT", "start_pos": 83, "end_pos": 86, "type": "TASK", "confidence": 0.9891672134399414}]}, {"text": "In order to achieve this goal, we focus on three issues of term translation: 1) translation ambiguity, 2) translation consistency and 3) bracketing.", "labels": [], "entities": [{"text": "term translation", "start_pos": 59, "end_pos": 75, "type": "TASK", "confidence": 0.7776935696601868}]}, {"text": "First, term translation ambiguity is related to translations of the same term in different domains.", "labels": [], "entities": [{"text": "term translation ambiguity", "start_pos": 7, "end_pos": 33, "type": "TASK", "confidence": 0.7853846748669943}]}, {"text": "A source language term may have different translations when it occurs in different domains.", "labels": [], "entities": []}, {"text": "Second, translation consistency is about consistent translations for terms that occur in the same document.", "labels": [], "entities": [{"text": "translation consistency", "start_pos": 8, "end_pos": 31, "type": "TASK", "confidence": 0.8192357420921326}]}, {"text": "Usually, it is undesirable to translate the same term in different ways as it occurs in different parts of a document.", "labels": [], "entities": []}, {"text": "Finally, bracketing concerns whether a multi-word term is bracketable during translation.", "labels": [], "entities": [{"text": "bracketing", "start_pos": 9, "end_pos": 19, "type": "TASK", "confidence": 0.9788973331451416}]}, {"text": "Normally, a multi-word term is translated as a whole unit into a contiguous target string.", "labels": [], "entities": []}, {"text": "We study these three issues in the context of document-informed SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.8065264225006104}]}, {"text": "We use documentinformed information to disambiguate term translations in different documents and maintain consistent translations for terms that occur in the same document.", "labels": [], "entities": []}, {"text": "We propose three different models for term translation that attempt to address the three issues mentioned above.", "labels": [], "entities": [{"text": "term translation", "start_pos": 38, "end_pos": 54, "type": "TASK", "confidence": 0.8069039881229401}]}, {"text": "In particular, \u2022 Term Translation Disambiguation Model: In this model, we condition the translations of terms in different documents on corresponding per-document topic distributions.", "labels": [], "entities": [{"text": "Term Translation Disambiguation", "start_pos": 17, "end_pos": 48, "type": "TASK", "confidence": 0.7558683852354685}]}, {"text": "In doing so, we enable the decoder to favor translation hypotheses with domain-specific term translations.", "labels": [], "entities": []}, {"text": "\u2022 Term Translation Consistency Model: This model encourages the same terms with a high strength of translation consistency that occur in different parts of a document to be translated in a consistent fashion.", "labels": [], "entities": [{"text": "Term Translation Consistency", "start_pos": 2, "end_pos": 30, "type": "TASK", "confidence": 0.7912390530109406}]}, {"text": "We calculate the translation consistency strength of a term based on the topic distribution of the documents where the term occurs in this model.", "labels": [], "entities": []}, {"text": "\u2022 Term Bracketing Model: We use the bracketing model to reward translation hypothe-ses where bracketable multi-word terms are translated as a whole unit.", "labels": [], "entities": []}, {"text": "We integrate the three models into hierarchical phrase-based SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.7822659611701965}]}, {"text": "Large-scale experiment results show that they are all able to achieve significant improvements of up to 0.89 BLEU points over the baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 109, "end_pos": 113, "type": "METRIC", "confidence": 0.999045193195343}]}, {"text": "When simultaneously integrating the three models into SMT, we can gain a further improvement, which outperforms the baseline by up to 1.16 BLEU points.", "labels": [], "entities": [{"text": "SMT", "start_pos": 54, "end_pos": 57, "type": "TASK", "confidence": 0.9591672420501709}, {"text": "BLEU", "start_pos": 139, "end_pos": 143, "type": "METRIC", "confidence": 0.9990701079368591}]}, {"text": "In the remainder of this paper, we begin with a brief overview of related work in Section 2, and bilingual term extraction in Section 3.", "labels": [], "entities": [{"text": "bilingual term extraction", "start_pos": 97, "end_pos": 122, "type": "TASK", "confidence": 0.6042656699816386}]}, {"text": "We then elaborate the proposed three models for term translation in Section 4.", "labels": [], "entities": [{"text": "term translation", "start_pos": 48, "end_pos": 64, "type": "TASK", "confidence": 0.8023911714553833}]}, {"text": "Next, we conduct experiments to validate the effectiveness of the proposed models in Section 5.", "labels": [], "entities": []}, {"text": "Finally, we conclude and provide directions for future work in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we conducted experiments to answer the following three questions.", "labels": [], "entities": []}, {"text": "1. Are our term translation disambiguation, consistency and bracketing models able to improve translation quality in BLEU?", "labels": [], "entities": [{"text": "consistency", "start_pos": 44, "end_pos": 55, "type": "METRIC", "confidence": 0.9915105700492859}, {"text": "BLEU", "start_pos": 117, "end_pos": 121, "type": "METRIC", "confidence": 0.667154848575592}]}, {"text": "2. Does the combination of the three models provide further improvements?", "labels": [], "entities": []}, {"text": "3. To what extent do the proposed models affect the translations of test sets?", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: BLEU-4 scores (%) of the term translation disambiguation model (Dis-Model), the term transla- tion consistency model (Cons-Model), the term bracketing model (Brack-Model), and the combination of  the three models, on the development test set MT06 and the final test set MT08. K \u2208 {50, 100, 150, 200}  which is the number of topics for the Dis-Model and the Cons-Model. \"Combined-Model\" is the combi- nation of the three single modes with topic number 150 for the Dis-Model and the Cons-Model. \"Base- line\" is the traditional hierarchical phrase-based system. \"CountFeat\" is the method that adds a counting  feature to reward translation hypotheses containing bilingual term pairs. The \"*\" and \"+\" denote that the  results are significantly", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9993995428085327}, {"text": "Brack-Model", "start_pos": 168, "end_pos": 179, "type": "METRIC", "confidence": 0.92653489112854}, {"text": "MT06", "start_pos": 252, "end_pos": 256, "type": "DATASET", "confidence": 0.7192913889884949}, {"text": "MT08", "start_pos": 280, "end_pos": 284, "type": "DATASET", "confidence": 0.9421989321708679}]}, {"text": " Table 3: Percentage (%) of 1-best translations  which are generated by the Combined-Model and  the three single models with best settings on the  development test set MT06 and the final test set  MT08. The topic number is 150 for Best-Dis- Model and Best-Cons-Model.", "labels": [], "entities": [{"text": "MT06", "start_pos": 168, "end_pos": 172, "type": "DATASET", "confidence": 0.5452465415000916}, {"text": "MT08", "start_pos": 197, "end_pos": 201, "type": "DATASET", "confidence": 0.9779350161552429}]}]}