{"title": [{"text": "Importance weighting and unsupervised domain adaptation of POS taggers: a negative result", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 59, "end_pos": 70, "type": "TASK", "confidence": 0.6868395954370499}]}], "abstractContent": [{"text": "Importance weighting is a generalization of various statistical bias correction techniques.", "labels": [], "entities": [{"text": "Importance weighting", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8626280128955841}, {"text": "statistical bias correction", "start_pos": 52, "end_pos": 79, "type": "TASK", "confidence": 0.6982165773709615}]}, {"text": "While our labeled data in NLP is heavily biased, importance weighting has seen only few applications in NLP, most of them relying on a small amount of labeled target data.", "labels": [], "entities": [{"text": "importance weighting", "start_pos": 49, "end_pos": 69, "type": "TASK", "confidence": 0.7275265455245972}]}, {"text": "The publication bias toward reporting positive results makes it hard to say whether researchers have tried.", "labels": [], "entities": []}, {"text": "This paper presents a negative result on unsu-pervised domain adaptation for POS tagging.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.7408183515071869}, {"text": "POS tagging", "start_pos": 77, "end_pos": 88, "type": "TASK", "confidence": 0.8268426656723022}]}, {"text": "In this setup, we only have unlabeled data and thus only indirect access to the bias in emission and transition probabilities.", "labels": [], "entities": []}, {"text": "Moreover, most errors in POS tagging are due to unseen words, and there, importance weighting cannot help.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 25, "end_pos": 36, "type": "TASK", "confidence": 0.813789576292038}]}, {"text": "We present experiments with a wide variety of weight functions, quantilizations, as well as with randomly generated weights, to support these claims.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many NLP tasks rely on the availability of annotated data.", "labels": [], "entities": []}, {"text": "The majority of annotated data, however, is sampled from newswire corpora.", "labels": [], "entities": []}, {"text": "The performance of NLP systems, e.g., part-of-speech (POS) tagger, parsers, relation extraction systems, etc., drops significantly when they are applied to data that departs from newswire conventions.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagger", "start_pos": 38, "end_pos": 65, "type": "TASK", "confidence": 0.6530184984207154}, {"text": "relation extraction", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.7511181831359863}]}, {"text": "So while we can extract information, translate and summarize newswire in major languages with some success, we are much less successful processing microblogs, chat, weblogs, answers, emails or literature in a robust way.", "labels": [], "entities": [{"text": "summarize newswire", "start_pos": 51, "end_pos": 69, "type": "TASK", "confidence": 0.7811887562274933}]}, {"text": "The main reasons for the drops inaccuracy have been attributed to factors such as previously unseen words and bigrams, missing punctuation and capitalization, as well as differences in the marginal distribution of data (.", "labels": [], "entities": []}, {"text": "The move from one domain to another (from a source to anew target domain), say from newspaper articles to weblogs, results in a sample selection bias.", "labels": [], "entities": []}, {"text": "Our training data is now biased, since it is sampled from a related, but nevertheless different distribution.", "labels": [], "entities": []}, {"text": "The problem of automatically adjusting the model induced from source to a different target is referred to as domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 109, "end_pos": 126, "type": "TASK", "confidence": 0.7191295325756073}]}, {"text": "Some researchers have studied domain adaptation scenarios, where small samples of labeled data have been assumed to be available for the target domains.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.7691973447799683}]}, {"text": "This is usually an unrealistic assumption, since even for major languages, small samples are only available from a limited number of domains, and in this work we focus on unsupervised domain adaptation, assuming only unlabeled target data is available., and have previously tried to use importance weighting to correct sample bias in NLP.", "labels": [], "entities": []}, {"text": "Importance weighting means assigning a weight to each training instance, reflecting its importance for modeling the target distribution.", "labels": [], "entities": []}, {"text": "Importance weighting is a generalization over poststratification and importance sampling () and can be used to correct bias in the labeled data.", "labels": [], "entities": [{"text": "Importance", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9141281247138977}]}, {"text": "Out of the four papers mentioned, only S\u00f8gaard and Haulrich (2011) and considered an unsupervised domain adaptation scenario, obtaining mixed results.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 98, "end_pos": 115, "type": "TASK", "confidence": 0.7259243279695511}]}, {"text": "These two papers assume covariate shift), i.e., that there is only a bias in the marginal distribution of the training data.", "labels": [], "entities": []}, {"text": "Under this assumption, we can correct the bias by applying a weight function Ps(x) to our training data points (labeled sentences) and learn from the weighted data.", "labels": [], "entities": []}, {"text": "Of course this weight function cannot be computed in general, but we can approximate it in different ways.", "labels": [], "entities": []}, {"text": "In POS tagging, we typically factorize sequences into emission and transition probabilities.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 3, "end_pos": 14, "type": "TASK", "confidence": 0.9336065351963043}]}, {"text": "Importance weighting can change emission probabilities and transition probabilities by assigning weights to sentences.", "labels": [], "entities": []}, {"text": "For instance, if our corpus consisted of three sequences: 1) a/A b/A, 2) a/A b/B, and 3) a/A b/B, then P (B|A) = 2/3.", "labels": [], "entities": []}, {"text": "If sequences two and three were down-weighted to 0.5, then P (B|A) = 1/2.", "labels": [], "entities": [{"text": "P (B|A)", "start_pos": 59, "end_pos": 66, "type": "METRIC", "confidence": 0.8463341891765594}]}, {"text": "However, this paper argues that importance weighting cannot help adapting POS taggers to new domains using only unlabeled target data.", "labels": [], "entities": [{"text": "importance weighting", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.7341883480548859}, {"text": "POS taggers", "start_pos": 74, "end_pos": 85, "type": "TASK", "confidence": 0.8292111158370972}]}, {"text": "We present three sources of evidence: (a) negative results with the most obvious weight functions across various English datasets, (b) negative results with randomly sampled weights, as well as (c) an analysis of annotated data indicating that there is little variation in emission and transition probabilities across the various domains.", "labels": [], "entities": [{"text": "English datasets", "start_pos": 113, "end_pos": 129, "type": "DATASET", "confidence": 0.7309132516384125}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Tagging accuracies and comparison to prior work on the SANCL test sets (fine-grained POS).", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.9824041128158569}, {"text": "accuracies", "start_pos": 18, "end_pos": 28, "type": "METRIC", "confidence": 0.6474675536155701}, {"text": "SANCL test sets", "start_pos": 65, "end_pos": 80, "type": "DATASET", "confidence": 0.9272255698839823}]}, {"text": " Table 2: Relevant statistics for our analysis ( \u00a74)  on the test sets: average tag ambiguity, out-of- vocabulary rate, and KL-divergence and Pearson  correlation coefficient (\u03c1) on POS bigrams.", "labels": [], "entities": [{"text": "Pearson  correlation coefficient (\u03c1)", "start_pos": 142, "end_pos": 178, "type": "METRIC", "confidence": 0.9772111475467682}]}, {"text": " Table 3: Results on the test sets by adding Wik- tionary type constraints.  \u2020=p-value < 0.001.", "labels": [], "entities": []}]}