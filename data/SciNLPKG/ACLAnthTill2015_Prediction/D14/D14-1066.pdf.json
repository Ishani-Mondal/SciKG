{"title": [{"text": "Lexical Substitution for the Medical Domain", "labels": [], "entities": [{"text": "Lexical Substitution", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8212225437164307}]}], "abstractContent": [{"text": "In this paper we examine the lexical substitution task for the medical domain.", "labels": [], "entities": [{"text": "lexical substitution task", "start_pos": 29, "end_pos": 54, "type": "TASK", "confidence": 0.8208242853482565}]}, {"text": "We adapt the current best system from the open domain, which trains a single classifier for all instances using delexicalized features.", "labels": [], "entities": []}, {"text": "We show significant improvements over a strong baseline coming from a distributional thesaurus (DT).", "labels": [], "entities": []}, {"text": "Whereas in the open domain system, features derived from WordNet show only slight improvements , we show that its counterpart for the medical domain (UMLS) shows a significant additional benefit when used for feature generation.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.9326019287109375}]}], "introductionContent": [{"text": "The task of lexical substitution) deals with the substitution of a target term within a sentence with words having the same meaning.", "labels": [], "entities": [{"text": "lexical substitution", "start_pos": 12, "end_pos": 32, "type": "TASK", "confidence": 0.7421466708183289}]}, {"text": "Thus, the task divides into two subtasks: \u2022 Identification of substitution candidates, i.e. terms that are, for some contexts, substitutable fora given target term.", "labels": [], "entities": []}, {"text": "\u2022 Ranking the substitution candidates according to their context Such a substitution system can help for semantic text similarity), textual entailment () or plagiarism detection (.", "labels": [], "entities": [{"text": "textual entailment", "start_pos": 132, "end_pos": 150, "type": "TASK", "confidence": 0.7456148564815521}, {"text": "plagiarism detection", "start_pos": 157, "end_pos": 177, "type": "TASK", "confidence": 0.7742083072662354}]}, {"text": "Datasets provided by and offer manually annotated substitutes fora given set of target words within a context (sentence).", "labels": [], "entities": []}, {"text": "Contrary to these two datasets in a dataset is offered where all words have are annotated with substitutes.", "labels": [], "entities": []}, {"text": "All the datasets are suited for the open domain.", "labels": [], "entities": []}, {"text": "But a system performing lexical substitution is not only of interest for the open domain, but also for the medical domain.", "labels": [], "entities": [{"text": "lexical substitution", "start_pos": 24, "end_pos": 44, "type": "TASK", "confidence": 0.7415138781070709}]}, {"text": "Such a system could then be applied to medical word sense disambiguation, entailment or question answering tasks.", "labels": [], "entities": [{"text": "medical word sense disambiguation", "start_pos": 39, "end_pos": 72, "type": "TASK", "confidence": 0.6278957575559616}, {"text": "question answering tasks", "start_pos": 88, "end_pos": 112, "type": "TASK", "confidence": 0.8287885387738546}]}, {"text": "Here we introduce anew dataset and adapt the lexical substitution system, provided by, to the medical domain.", "labels": [], "entities": []}, {"text": "Additionally, we do not make use of WordNet to provide similar terms, but rather employ a Distributional Thesaurus (DT), computed on medical texts.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 36, "end_pos": 43, "type": "DATASET", "confidence": 0.9648919105529785}]}], "datasetContent": [{"text": "Besides the lexical substitution data sets for the open domain) there is no dataset available that can be used for the medical domain.", "labels": [], "entities": []}, {"text": "Therefore, we constructed an annotation task for the medical domain using a medical corpus and domain experts.", "labels": [], "entities": []}, {"text": "In order to provide the annotators with a clear task, we presented a question, and a passage that contains the correct answer to the question.", "labels": [], "entities": []}, {"text": "We restricted this to a subset of passages that were previously annotated as justifying the answer to the question.", "labels": [], "entities": []}, {"text": "This is related to a textual entailment task, essentially the passage entails the question with the answer substituted for the focus of the question.", "labels": [], "entities": []}, {"text": "We instructed the annotators to first identify the terms that were relevant for the entailment relation.", "labels": [], "entities": []}, {"text": "For each relevant term we randomly extracted 10 terms from the ESG-based DT within the top 100 most similar terms.", "labels": [], "entities": [{"text": "ESG-based DT", "start_pos": 63, "end_pos": 75, "type": "DATASET", "confidence": 0.8525035679340363}]}, {"text": "Using this list of distributionally similar terms, the annotators selected those terms that would preserve the entailment relation if substituted.", "labels": [], "entities": []}, {"text": "This resulted in a dataset of 699 target terms with substitutes.", "labels": [], "entities": []}, {"text": "On average from the 10 terms 0.846 are annotated as correct substitutes.", "labels": [], "entities": []}, {"text": "Thus, the remaining terms can be used as false substitute candidates.", "labels": [], "entities": []}, {"text": "The agreement on this task by Fleiss Kappa was 0.551 indicating \"moderate agreement\".", "labels": [], "entities": [{"text": "Fleiss Kappa", "start_pos": 30, "end_pos": 42, "type": "DATASET", "confidence": 0.7612144351005554}]}, {"text": "On the metric of pairwise agreement, as defined in the SemEval lexical substitution task, we achieve 0.627.", "labels": [], "entities": [{"text": "SemEval lexical substitution task", "start_pos": 55, "end_pos": 88, "type": "TASK", "confidence": 0.8569981455802917}]}, {"text": "This number is not directly comparable to the pairwise agreement score of 0.277 for the SemEval lexical substitution task (McCarthy and Navigli, 2009) since in our task the candidates are given.", "labels": [], "entities": [{"text": "SemEval lexical substitution task", "start_pos": 88, "end_pos": 121, "type": "TASK", "confidence": 0.8880806714296341}]}, {"text": "However, it shows promise that subjectivity maybe reduced by casting lexical substitution into a task of maintaining entailment.", "labels": [], "entities": []}, {"text": "For the evaluation we use a ten-fold cross validation and report P@1 (also called Average Precision (AP) at 1) and Mean Average Precision (MAP) () scores.", "labels": [], "entities": [{"text": "P@1", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.9628275831540426}, {"text": "Average Precision (AP)", "start_pos": 82, "end_pos": 104, "type": "METRIC", "confidence": 0.9676773190498352}, {"text": "Mean Average Precision (MAP)", "start_pos": 115, "end_pos": 143, "type": "METRIC", "confidence": 0.9593970278898875}]}, {"text": "The P@1 score indicates how often the first substitute of the system matches the gold standard.", "labels": [], "entities": [{"text": "P@1 score", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.971688523888588}]}, {"text": "The MAP score is the mean of all AP from 1 to the number of all substitutes.", "labels": [], "entities": [{"text": "MAP score", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9675226509571075}, {"text": "AP", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9990321397781372}]}, {"text": "\u2022 Google Web 1T: We use the same Google n-gram features, as used in and.", "labels": [], "entities": [{"text": "Google Web 1T", "start_pos": 2, "end_pos": 15, "type": "DATASET", "confidence": 0.8803035418192545}]}, {"text": "These are frequencies of n-grams formed by the substitute candidate s i and the left and right words, taken from the context sentence, normalized by the frequency of the same context n-gram with the target term t.", "labels": [], "entities": []}, {"text": "Additionally, we add the same features, normalized by the frequency sum of all n-grams of the substitute candidates.", "labels": [], "entities": []}, {"text": "Another feature is generated using the frequencies where t and s are listed together using the words and, or and \",\" as separator and also add the left and right words of that phrase as context.", "labels": [], "entities": []}, {"text": "Then we normalize this frequency by the frequency of the context occurring only with t.", "labels": [], "entities": []}, {"text": "\u2022 DT features: To characterize if t and s i have similar words in common, and therefore are similar, we compute the percentage of words their thesauri entries share, considering the top n words in each entry with n = 1, 5, 20, 50, 100, 200.", "labels": [], "entities": []}, {"text": "During the DT calculation we also calculate the significances between each word and its context features (see Section 4.1).", "labels": [], "entities": [{"text": "DT", "start_pos": 11, "end_pos": 13, "type": "TASK", "confidence": 0.9510812759399414}]}, {"text": "Using this information, we compute if the words in the sentences also occur as context features for the substitute candidate.", "labels": [], "entities": []}, {"text": "A third feature group relying on DTs is created by the overlapping context features for the top m entries oft and s i with m = 1, 5, 20, 50, 100, 1000, which are ranked regarding their significance score.", "labels": [], "entities": []}, {"text": "Whereas, the similarities between the trigram-based and the ESGbased DT are similar, the context features are different.", "labels": [], "entities": [{"text": "ESGbased DT", "start_pos": 60, "end_pos": 71, "type": "DATASET", "confidence": 0.8954930901527405}]}, {"text": "Both feature types can be applied to the two DTs.", "labels": [], "entities": []}, {"text": "Additionally, we extract the thesaurus entry for the target word t and generate a feature indicating whether the substitute s i is within the top k entries with k = 1, 5, 10, 20, 100 entries 6 . \u2022 Part-of-speech n-grams: To identify the context of the word we use the POS-tag (only the first letter) of s i and t as feature and POS-tag combinations of up to three neighboring words.", "labels": [], "entities": []}, {"text": "\u2022 UMLS: Considering UMLS we lookup all concept unique identifiers (CUIs) for s i and t.", "labels": [], "entities": []}, {"text": "The first two features are the number of CUIs for s i and t.", "labels": [], "entities": []}, {"text": "The next features compute the number of CUIs that s i and t share, starting from the minimal to the maximum number of CUIs.", "labels": [], "entities": []}, {"text": "Additionally, we use a feature indicating that s i and t do not share any CUI.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results for the evaluation using substitute can- didates from the DT.", "labels": [], "entities": [{"text": "DT", "start_pos": 76, "end_pos": 78, "type": "DATASET", "confidence": 0.7767791152000427}]}, {"text": " Table 2: Error analysis for the task respectively to the  MAP score.", "labels": [], "entities": [{"text": "Error", "start_pos": 10, "end_pos": 15, "type": "METRIC", "confidence": 0.9833347201347351}, {"text": "MAP score", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9296560287475586}]}]}