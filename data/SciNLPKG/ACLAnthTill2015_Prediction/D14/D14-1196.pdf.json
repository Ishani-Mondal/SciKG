{"title": [{"text": "Dependency-based Discourse Parser for Single-Document Summarization", "labels": [], "entities": [{"text": "Summarization", "start_pos": 54, "end_pos": 67, "type": "TASK", "confidence": 0.8442379236221313}]}], "abstractContent": [{"text": "The current state-of-the-art single-document summarization method generates a summary by solving a Tree Knapsack Problem (TKP), which is the problem of finding the optimal rooted sub-tree of the dependency-based discourse tree (DEP-DT) of a document.", "labels": [], "entities": [{"text": "single-document summarization", "start_pos": 29, "end_pos": 58, "type": "TASK", "confidence": 0.5629102289676666}]}, {"text": "We can obtain a gold DEP-DT by transforming a gold Rhetorical Structure Theory-based discourse tree (RST-DT).", "labels": [], "entities": []}, {"text": "However, there is still a large difference between the ROUGE scores of a system with a gold DEP-DT and a system with a DEP-DT obtained from an automatically parsed RST-DT.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 55, "end_pos": 60, "type": "METRIC", "confidence": 0.9958290457725525}, {"text": "DEP-DT", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.757370114326477}]}, {"text": "To improve the ROUGE score, we propose a novel discourse parser that directly generates the DEP-DT.", "labels": [], "entities": [{"text": "ROUGE score", "start_pos": 15, "end_pos": 26, "type": "METRIC", "confidence": 0.9710437059402466}, {"text": "DEP-DT", "start_pos": 92, "end_pos": 98, "type": "DATASET", "confidence": 0.557355523109436}]}, {"text": "The evaluation results showed that the TKP with our parser outperformed that with the state-of-the-art RST-DT parser, and achieved almost equivalent ROUGE scores to the TKP with the gold DEP-DT.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 149, "end_pos": 154, "type": "METRIC", "confidence": 0.9984455704689026}]}], "introductionContent": [{"text": "Discourse structures of documents are believed to be highly beneficial for generating informative and coherent summaries.", "labels": [], "entities": []}, {"text": "Several discoursebased summarization methods have been developed, such as).", "labels": [], "entities": [{"text": "discoursebased summarization", "start_pos": 8, "end_pos": 36, "type": "TASK", "confidence": 0.6039912402629852}]}, {"text": "Moreover, the current best ROUGE score for the summarization benchmark data of the RSTdiscourse) has been provided by, whose method also utilizes discourse trees.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 27, "end_pos": 32, "type": "METRIC", "confidence": 0.9948122501373291}]}, {"text": "Thus, the discoursebased summarization approach is one promising way to obtain high-quality summaries.", "labels": [], "entities": [{"text": "summarization", "start_pos": 25, "end_pos": 38, "type": "TASK", "confidence": 0.7126240730285645}]}, {"text": "One possible weakness of discourse-based summarization techniques is that they rely greatly on the accuracy of the discourse parser they use.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.9974576830863953}]}, {"text": "For example, the above discourse-based summarization methods utilize discourse trees based on the Rhetorical Structure Theory (RST) () for their discourse information.", "labels": [], "entities": [{"text": "Rhetorical Structure Theory (RST)", "start_pos": 98, "end_pos": 131, "type": "TASK", "confidence": 0.6577008118232092}]}, {"text": "Unfortunately, the current state-of-the-art RST parser, as described in, is insufficient as an off-the-shelf discourse parser.", "labels": [], "entities": [{"text": "RST parser", "start_pos": 44, "end_pos": 54, "type": "TASK", "confidence": 0.9471755921840668}]}, {"text": "In fact, there is empirical evidence that the quality (i.e., ROUGE score) of summaries from autoparsed discourse trees is significantly degraded compared with those generated from gold discourse trees.", "labels": [], "entities": [{"text": "ROUGE score)", "start_pos": 61, "end_pos": 73, "type": "METRIC", "confidence": 0.9882003466288248}]}, {"text": "From this background, the goal of this paper is to develop an appropriate discourse parser for discourse-based summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 111, "end_pos": 124, "type": "TASK", "confidence": 0.6983414888381958}]}, {"text": "We first focus on one of the best discourse-based single document summarization methods as proposed in.", "labels": [], "entities": [{"text": "single document summarization", "start_pos": 50, "end_pos": 79, "type": "TASK", "confidence": 0.5762883226076762}]}, {"text": "Their method formulates a single document summarization problem as a Tree Knapsack Problem (TKP) over a dependency-based discourse tree (DEP-DT).", "labels": [], "entities": []}, {"text": "In their method, DEP-DTs are automatically transformed from (auto-parsed) RST-discourse trees (RST-DTs) by heuristic rules.", "labels": [], "entities": []}, {"text": "Instead, we develop a DEP-DT parser, that directly provides DEP-DTs for their state-of-the-art discourse-based summarization method.", "labels": [], "entities": []}, {"text": "We show that summaries generated by our parser improve the ROUGE scores to almost the same level as those generated by gold DEP-DTs.", "labels": [], "entities": [{"text": "ROUGE scores", "start_pos": 59, "end_pos": 71, "type": "METRIC", "confidence": 0.9716860949993134}]}, {"text": "We also investigate the way in which the parsing accuracy helps to improve the ROUGE scores.", "labels": [], "entities": [{"text": "parsing", "start_pos": 41, "end_pos": 48, "type": "TASK", "confidence": 0.9743899703025818}, {"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.9187459349632263}, {"text": "ROUGE", "start_pos": 79, "end_pos": 84, "type": "METRIC", "confidence": 0.9886640906333923}]}, {"text": "2 Single-Document Summarization as a Tree Knapsack Problem formulated single-document summarization as a TKP that is run on the DEP-DT.", "labels": [], "entities": [{"text": "Single-Document Summarization", "start_pos": 2, "end_pos": 31, "type": "TASK", "confidence": 0.7652189135551453}, {"text": "single-document summarization", "start_pos": 70, "end_pos": 99, "type": "TASK", "confidence": 0.5134143084287643}, {"text": "DEP-DT", "start_pos": 128, "end_pos": 134, "type": "DATASET", "confidence": 0.955544114112854}]}, {"text": "They obtained a summary by trimming the DEP-DT, i.e. the summary is a rooted subtree of the DEP-DT.", "labels": [], "entities": [{"text": "DEP-DT", "start_pos": 40, "end_pos": 46, "type": "DATASET", "confidence": 0.8518984913825989}, {"text": "DEP-DT", "start_pos": 92, "end_pos": 98, "type": "DATASET", "confidence": 0.9268563389778137}]}, {"text": "Suppose that we have N EDUs in a document,  and the i-th EDU e i has l i words.", "labels": [], "entities": []}, {"text": "L is the maximum number of words allowed in a summary.", "labels": [], "entities": [{"text": "L", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9766792058944702}]}, {"text": "In the TKP, if we select e i , we need to select its parent EDU in the DEP-DT.", "labels": [], "entities": [{"text": "DEP-DT", "start_pos": 71, "end_pos": 77, "type": "DATASET", "confidence": 0.8807383179664612}]}, {"text": "We denote parent(i) as the index of the parent of e i in the DEP-DT.", "labels": [], "entities": [{"text": "DEP-DT", "start_pos": 61, "end_pos": 67, "type": "DATASET", "confidence": 0.9247797727584839}]}, {"text": "x is an N -dimensional binary vector that represents a summary, i.e. xi = 1 denotes that e i is included in the summary.", "labels": [], "entities": []}, {"text": "The TKP is defined as the following ILP problem: where F (e i ) is the score of e i . We define F (e i ) as follows: where W (e i ) is the set of words contained in e i . tf(w, D) is the term frequency of word win a document D.", "labels": [], "entities": [{"text": "F", "start_pos": 55, "end_pos": 56, "type": "METRIC", "confidence": 0.980811357498169}, {"text": "F", "start_pos": 96, "end_pos": 97, "type": "METRIC", "confidence": 0.9222017526626587}]}, {"text": "Depth(e i ) is the depth of e i in the DEP-DT.", "labels": [], "entities": [{"text": "Depth", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9739145040512085}, {"text": "DEP-DT", "start_pos": 39, "end_pos": 45, "type": "DATASET", "confidence": 0.8753940463066101}]}], "datasetContent": [{"text": "We compared the following three systems that differ in the way they obtain the DEP-DT.", "labels": [], "entities": [{"text": "DEP-DT", "start_pos": 79, "end_pos": 85, "type": "DATASET", "confidence": 0.7486379742622375}]}, {"text": "TKP-GOLD Used a DEP-DT converted from a gold RST-DT.", "labels": [], "entities": [{"text": "TKP-GOLD", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9701279401779175}]}, {"text": "TKP-DIS-DEP Used a DEP-DT automatically parsed by our discourse dependency-based parser (DIS-DEP).(a) shows an overview of this system.", "labels": [], "entities": [{"text": "TKP-DIS-DEP", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.8335548639297485}]}, {"text": "TKP-DIS-DEP-LOSS Used a DEP-DT automatically parsed by our discourse dependencybased parser (DIS-DEP).: ROUGE Recall scores human-annotated reference summary.", "labels": [], "entities": [{"text": "TKP-DIS-DEP-LOSS", "start_pos": 0, "end_pos": 16, "type": "DATASET", "confidence": 0.8191055059432983}, {"text": "ROUGE", "start_pos": 104, "end_pos": 109, "type": "METRIC", "confidence": 0.8396081924438477}]}, {"text": "The average length of the reference summaries corresponds to about 10% of the words in the source document.", "labels": [], "entities": []}, {"text": "This is also the commonly used evaluation condition for single-document summarization evaluation on the RST-DT corpus.", "labels": [], "entities": [{"text": "summarization evaluation", "start_pos": 72, "end_pos": 96, "type": "TASK", "confidence": 0.8061695992946625}, {"text": "RST-DT corpus", "start_pos": 104, "end_pos": 117, "type": "DATASET", "confidence": 0.7721833288669586}]}, {"text": "We employed the recall of ROUGE-1, 2 as the evaluation measures.", "labels": [], "entities": [{"text": "recall", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.9995612502098083}, {"text": "ROUGE-1", "start_pos": 26, "end_pos": 33, "type": "METRIC", "confidence": 0.9510622620582581}]}, {"text": "shows ROUGE scores on the RST-DT corpus.", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 6, "end_pos": 11, "type": "METRIC", "confidence": 0.9894554018974304}, {"text": "RST-DT corpus", "start_pos": 26, "end_pos": 39, "type": "DATASET", "confidence": 0.8531506359577179}]}, {"text": "We can see TKP-DIS-DEP and TKP-DIS-DEP-LOSS outperformed TKP-HILDA, and achieved almost the same ROUGE scores as TKP-GOLD.", "labels": [], "entities": [{"text": "TKP-DIS-DEP", "start_pos": 11, "end_pos": 22, "type": "DATASET", "confidence": 0.7529491782188416}, {"text": "ROUGE", "start_pos": 97, "end_pos": 102, "type": "METRIC", "confidence": 0.9988424181938171}]}, {"text": "Wilcoxon's signed rank test in terms of ROUGE rejected the null hypothesis, \"there is a difference between TKP-HILDA and TKP-DIS-DEP (or TKP-DIS-DEP-LOSS)\".", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 40, "end_pos": 45, "type": "METRIC", "confidence": 0.9709214568138123}]}, {"text": "This would be because test documents are relatively small.", "labels": [], "entities": []}, {"text": "We analyzed the differences between the proposed systems (TKP-DIS-DEP and TKP-DIS-DEP-LOSS) and TKP-HILDA.", "labels": [], "entities": []}, {"text": "First, we evaluated the overlaps between the EDUs in summaries generated by the system and the EDUs in summaries generated by TKP-GOLD.", "labels": [], "entities": [{"text": "TKP-GOLD", "start_pos": 126, "end_pos": 134, "type": "DATASET", "confidence": 0.9452487230300903}]}, {"text": "To seethe overlaps, we calculated the average F-value using Recall and Precision defined as follows: where S sis a set of EDUs in a summary generated by a system, and S g a set of EDUs in a summary generated by TKP-GOLD.", "labels": [], "entities": [{"text": "F-value", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.9953597187995911}, {"text": "Recall", "start_pos": 60, "end_pos": 66, "type": "METRIC", "confidence": 0.9795693755149841}, {"text": "Precision", "start_pos": 71, "end_pos": 80, "type": "METRIC", "confidence": 0.9557042717933655}, {"text": "TKP-GOLD", "start_pos": 211, "end_pos": 219, "type": "DATASET", "confidence": 0.9496057033538818}]}, {"text": "The first line in shows the results.", "labels": [], "entities": []}, {"text": "TKP-DIS-DEP and TKP-DIS-DEP-LOSS outperformed TKP-HILDA as regards the average F-values.", "labels": [], "entities": [{"text": "TKP-DIS-DEP", "start_pos": 0, "end_pos": 11, "type": "DATASET", "confidence": 0.9274590015411377}, {"text": "F-values", "start_pos": 79, "end_pos": 87, "type": "METRIC", "confidence": 0.9818766117095947}]}, {"text": "The result revealed that TKP-DIS-DEP and TKP-DIS-DEP-LOSS have more EDUs in common with TKP-GOLD than TKP-HILDA.", "labels": [], "entities": []}, {"text": "This result is evidence that TKP-DIS-DEP and TKP-DIS-DEP-LOSS outperformed TKP-HILDA in terms of ROUGE score.", "labels": [], "entities": [{"text": "ROUGE score", "start_pos": 97, "end_pos": 108, "type": "METRIC", "confidence": 0.9803328216075897}]}, {"text": "Second, we evaluated the root accuracy (RA), the rate at which a parser can find the root of DEPDTs.", "labels": [], "entities": [{"text": "accuracy (RA)", "start_pos": 30, "end_pos": 43, "type": "METRIC", "confidence": 0.9086929708719254}, {"text": "DEPDTs", "start_pos": 93, "end_pos": 99, "type": "DATASET", "confidence": 0.7937306761741638}]}, {"text": "Since the root of a gold DEP-DT is the most salient EDU in a document, it should be included in the summary.", "labels": [], "entities": []}, {"text": "The second line in shows that our methods succeeded in extracting the root   of DEP-DT with high accuracy.", "labels": [], "entities": [{"text": "DEP-DT", "start_pos": 80, "end_pos": 86, "type": "DATASET", "confidence": 0.5574795007705688}, {"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9985440969467163}]}, {"text": "Third, to evaluate the coherency of the generated summaries, we compared the average Dependency Accuracy in Summary (DAS), which is defined as follows: where S is a set of EDUs contained in the summary and parent(e) returns the parent EDU of e in the gold DEP-DT.", "labels": [], "entities": [{"text": "average Dependency Accuracy in Summary (DAS)", "start_pos": 77, "end_pos": 121, "type": "METRIC", "confidence": 0.8432034775614738}]}, {"text": "DAS(S) measures the rate of the correct parent-child relationships in S.", "labels": [], "entities": [{"text": "DAS(S)", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.8339683413505554}]}, {"text": "When DAS equals 1, the summary is a rooted subtree of the gold DEP-DT.", "labels": [], "entities": [{"text": "DAS", "start_pos": 5, "end_pos": 8, "type": "METRIC", "confidence": 0.9965240359306335}]}, {"text": "The third line in shows the results.", "labels": [], "entities": []}, {"text": "The results demonstrate that the summaries generated by TKP-DIS-DEP or TKP-DIS-DEP-LOSS tend to preserve the upper level dependency relationships between the EDUs within the gold DEP-DT.", "labels": [], "entities": []}, {"text": "shows summaries of wsj 2317 generated by the three systems.", "labels": [], "entities": []}, {"text": "The EDUs corresponding to the root of the DEP-DT are used in each system shown in boldface.", "labels": [], "entities": [{"text": "DEP-DT", "start_pos": 42, "end_pos": 48, "type": "DATASET", "confidence": 0.7273430228233337}]}, {"text": "We can see that the root EDU in the gold DEP-DT is found in the summaries generated by TKP-DIS-DEP and TKP-DIS-DEP-LOSS, but not in the summary generated by TKP-HILDA.", "labels": [], "entities": [{"text": "EDU", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.9308634400367737}, {"text": "TKP-DIS-DEP", "start_pos": 87, "end_pos": 98, "type": "DATASET", "confidence": 0.8944432139396667}, {"text": "TKP-HILDA", "start_pos": 157, "end_pos": 166, "type": "DATASET", "confidence": 0.9473360776901245}]}], "tableCaptions": [{"text": " Table 2: Average F-value, Root Accuracy (RA), and average Dependency Accuracy in Summary (DAS).  Wilcoxon's signed rank test in terms of average F-value, RA and DAS accepted the null hypothesis.", "labels": [], "entities": [{"text": "F-value", "start_pos": 18, "end_pos": 25, "type": "METRIC", "confidence": 0.7111491560935974}, {"text": "Root Accuracy (RA)", "start_pos": 27, "end_pos": 45, "type": "METRIC", "confidence": 0.9468749642372132}, {"text": "average Dependency Accuracy in Summary (DAS)", "start_pos": 51, "end_pos": 95, "type": "METRIC", "confidence": 0.9479072988033295}, {"text": "RA", "start_pos": 155, "end_pos": 157, "type": "METRIC", "confidence": 0.9964954257011414}, {"text": "DAS", "start_pos": 162, "end_pos": 165, "type": "METRIC", "confidence": 0.7291584610939026}]}]}