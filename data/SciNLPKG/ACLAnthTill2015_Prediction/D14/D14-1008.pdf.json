{"title": [{"text": "A Constituent-Based Approach to Argument Labeling with Joint Inference in Discourse Parsing", "labels": [], "entities": [{"text": "Argument Labeling", "start_pos": 32, "end_pos": 49, "type": "TASK", "confidence": 0.7369145452976227}]}], "abstractContent": [{"text": "Discourse parsing is a challenging task and plays a critical role in discourse analysis.", "labels": [], "entities": [{"text": "Discourse parsing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.8602213561534882}, {"text": "discourse analysis", "start_pos": 69, "end_pos": 87, "type": "TASK", "confidence": 0.7420278340578079}]}, {"text": "In this paper, we focus on labeling full argument spans of discourse con-nectives in the Penn Discourse Treebank (PDTB).", "labels": [], "entities": [{"text": "Penn Discourse Treebank (PDTB)", "start_pos": 89, "end_pos": 119, "type": "DATASET", "confidence": 0.9656858245531718}]}, {"text": "Previous studies cast this task as a linear tagging or subtree extraction problem.", "labels": [], "entities": [{"text": "linear tagging or subtree extraction", "start_pos": 37, "end_pos": 73, "type": "TASK", "confidence": 0.6358239531517029}]}, {"text": "In this paper, we propose a novel constituent-based approach to argument labeling, which integrates the advantages of both linear tagging and sub-tree extraction.", "labels": [], "entities": [{"text": "argument labeling", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.699953019618988}, {"text": "sub-tree extraction", "start_pos": 142, "end_pos": 161, "type": "TASK", "confidence": 0.7428473830223083}]}, {"text": "In particular, the proposed approach unifies intra-and inter-sentence cases by treating the immediately preceding sentence as a special constituent.", "labels": [], "entities": []}, {"text": "Besides, a joint inference mechanism is introduced to incorporate global information across arguments into our constituent-based approach via integer linear programming.", "labels": [], "entities": []}, {"text": "Evaluation on PDT-B shows significant performance improvements of our constituent-based approach over the best state-of-the-art system.", "labels": [], "entities": []}, {"text": "It also shows the effectiveness of our joint inference mechanism in modeling global information across arguments.", "labels": [], "entities": []}], "introductionContent": [{"text": "Discourse parsing determines the internal structure of a text and identifies the discourse relations between its text units.", "labels": [], "entities": [{"text": "Discourse parsing", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7858600616455078}]}, {"text": "It has attracted increasing attention in recent years due to its importance in text understanding, especially since the release of the Penn Discourse Treebank (PDTB) corpus, which adds a layer of discourse annotations on top of the Penn Treebank * The research reported in this paper was carried out while Fang Kong was a research fellow at the National University of Singapore.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.8823158442974091}, {"text": "Penn Discourse Treebank (PDTB) corpus", "start_pos": 135, "end_pos": 172, "type": "DATASET", "confidence": 0.9445338674954006}, {"text": "Penn Treebank", "start_pos": 232, "end_pos": 245, "type": "DATASET", "confidence": 0.991546243429184}]}, {"text": "As the largest available discourse corpus, the PDTB corpus has become the defacto benchmark in recent studies on discourse parsing.", "labels": [], "entities": [{"text": "PDTB corpus", "start_pos": 47, "end_pos": 58, "type": "DATASET", "confidence": 0.9251973927021027}, {"text": "discourse parsing", "start_pos": 113, "end_pos": 130, "type": "TASK", "confidence": 0.6992256194353104}]}, {"text": "Compared to connective identification and discourse relation classification in discourse parsing, the task of labeling full argument spans of discourse connectives is much harder and thus more challenging.", "labels": [], "entities": [{"text": "connective identification", "start_pos": 12, "end_pos": 37, "type": "TASK", "confidence": 0.8342487215995789}, {"text": "discourse relation classification in discourse parsing", "start_pos": 42, "end_pos": 96, "type": "TASK", "confidence": 0.6904590080181757}, {"text": "labeling full argument spans of discourse connectives", "start_pos": 110, "end_pos": 163, "type": "TASK", "confidence": 0.772903961794717}]}, {"text": "For connective identification, achieved the performance of 95.76% and 93.62% in F-measure using gold-standard and automatic parse trees, respectively.", "labels": [], "entities": [{"text": "connective identification", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.8720248341560364}, {"text": "F-measure", "start_pos": 80, "end_pos": 89, "type": "METRIC", "confidence": 0.9789977669715881}]}, {"text": "For discourse relation classification, achieved the performance of 86.77% in F-measure on classifying discourse relations into 16 level 2 types.", "labels": [], "entities": [{"text": "discourse relation classification", "start_pos": 4, "end_pos": 37, "type": "TASK", "confidence": 0.8046279152234396}, {"text": "F-measure", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.9912151098251343}]}, {"text": "However, for argument labeling, only achieved the performance of 53.85% in Fmeasure using gold-standard parse trees and connectives, much lower than the inter-annotation agreement of 90.20% (.", "labels": [], "entities": [{"text": "argument labeling", "start_pos": 13, "end_pos": 30, "type": "TASK", "confidence": 0.7490003108978271}, {"text": "Fmeasure", "start_pos": 75, "end_pos": 83, "type": "DATASET", "confidence": 0.8719705939292908}]}, {"text": "In this paper, we focus on argument labeling in the PDTB corpus.", "labels": [], "entities": [{"text": "argument labeling", "start_pos": 27, "end_pos": 44, "type": "TASK", "confidence": 0.7554857432842255}, {"text": "PDTB corpus", "start_pos": 52, "end_pos": 63, "type": "DATASET", "confidence": 0.8839309811592102}]}, {"text": "In particular, we propose a novel constituent-based approach to argument labeling which views constituents as candidate arguments.", "labels": [], "entities": [{"text": "argument labeling", "start_pos": 64, "end_pos": 81, "type": "TASK", "confidence": 0.7178566455841064}]}, {"text": "Besides, our approach unifies intra-and inter-sentence cases by treating the immediately preceding sentence as a special constituent.", "labels": [], "entities": []}, {"text": "Finally, a joint inference mechanism is introduced to incorporate global information across arguments via integer linear programming.", "labels": [], "entities": []}, {"text": "Evaluation on the PDTB corpus shows the effectiveness of our approach.", "labels": [], "entities": [{"text": "PDTB corpus", "start_pos": 18, "end_pos": 29, "type": "DATASET", "confidence": 0.9331906735897064}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 briefly introduces the PDTB corpus.", "labels": [], "entities": [{"text": "PDTB corpus", "start_pos": 33, "end_pos": 44, "type": "DATASET", "confidence": 0.9097401797771454}]}, {"text": "Related work on argument labeling is reviewed in Section 3.", "labels": [], "entities": [{"text": "argument labeling", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.8121267259120941}, {"text": "Section", "start_pos": 49, "end_pos": 56, "type": "DATASET", "confidence": 0.8679561614990234}]}, {"text": "In Section 4, we describe our constituent-based approach to argument labeling.", "labels": [], "entities": [{"text": "argument labeling", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.7065357118844986}]}, {"text": "In Section 5, we present our joint inference mechanism via integer linear programming (ILP).", "labels": [], "entities": []}, {"text": "Section 6 gives the experimental results and analysis.", "labels": [], "entities": []}, {"text": "Finally, we conclude in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we systematically evaluate our constituent-based approach with a joint inference mechanism to argument labeling on the PDTB corpus.", "labels": [], "entities": [{"text": "argument labeling", "start_pos": 111, "end_pos": 128, "type": "TASK", "confidence": 0.7132006287574768}, {"text": "PDTB corpus", "start_pos": 136, "end_pos": 147, "type": "DATASET", "confidence": 0.9538435637950897}]}, {"text": "All our classifiers are trained using the OpenNLP maximum entropy package 3 with the default parameters (i.e. without smoothing and with 100 iterations).", "labels": [], "entities": []}, {"text": "As the PDTB corpus is aligned with the PTB corpus, the gold parse trees and sentence boundaries are obtained from PTB.", "labels": [], "entities": [{"text": "PDTB corpus", "start_pos": 7, "end_pos": 18, "type": "DATASET", "confidence": 0.9390830397605896}, {"text": "PTB corpus", "start_pos": 39, "end_pos": 49, "type": "DATASET", "confidence": 0.9764387011528015}, {"text": "PTB", "start_pos": 114, "end_pos": 117, "type": "DATASET", "confidence": 0.9685233235359192}]}, {"text": "Under the automatic setting, the NIST sentence segmenter 4 and the Charniak parser 5 are used to segment and parse the sentences, respectively.", "labels": [], "entities": [{"text": "NIST sentence segmenter", "start_pos": 33, "end_pos": 56, "type": "TASK", "confidence": 0.742069145043691}]}, {"text": "lp solve 6 is used for our joint inference.", "labels": [], "entities": []}, {"text": "This paper focuses on automatically labeling the full argument spans of discourse connectives.", "labels": [], "entities": []}, {"text": "For a fair comparison with start-of-theart systems, we use the NUS PDTB-style endto-end discourse parser 7 to perform other subtasks of discourse parsing except argument labeling, which includes connective identification, non-explicit discourse relation identification and classification.", "labels": [], "entities": [{"text": "NUS PDTB-style endto-end discourse parser 7", "start_pos": 63, "end_pos": 106, "type": "DATASET", "confidence": 0.862159917751948}, {"text": "discourse parsing", "start_pos": 136, "end_pos": 153, "type": "TASK", "confidence": 0.7829160094261169}, {"text": "connective identification", "start_pos": 195, "end_pos": 220, "type": "TASK", "confidence": 0.7305289655923843}, {"text": "discourse relation identification", "start_pos": 235, "end_pos": 268, "type": "TASK", "confidence": 0.7164295117060343}]}, {"text": "Finally, we evaluate our system on two aspects: (1) the dependence on the parse trees (GS/Auto, using gold standard or automatic parse trees and sentence boundaries); and (2) the impact of errors propagated from previous components (noEP/EP, using gold annotation or automatic results from previous components).", "labels": [], "entities": []}, {"text": "In combination, we have four different settings: GS+noEP, GS+EP, Auto+noEP and Auto+EP.", "labels": [], "entities": []}, {"text": "Same as, we report exact match results under these four settings.", "labels": [], "entities": []}, {"text": "Here, exact match means two spans match identically, except beginning or ending punctuation symbols.", "labels": [], "entities": [{"text": "exact match", "start_pos": 6, "end_pos": 17, "type": "METRIC", "confidence": 0.9039016962051392}]}, {"text": "We first evaluate the effectiveness of our constituent-based approach by comparing our system with the state-of-the-art systems, ignoring the joint inference mechanism.", "labels": [], "entities": []}, {"text": "Then, the contribution of the joint inference mechanism to our constituent-based approach, and finally the contribution of our argument labeling system to the endto-end discourse parser are presented.", "labels": [], "entities": [{"text": "endto-end discourse parser", "start_pos": 159, "end_pos": 185, "type": "TASK", "confidence": 0.6735208034515381}]}, {"text": "Effectiveness of our constituent-based approach By comparing with two state-of-the-art argument labeling approaches, we determine the effectiveness of our constituent-based approach.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Performance (F1) comparison of our ar- gument labeling approach with the linear tagging  approach as adopted in", "labels": [], "entities": [{"text": "F1", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.9602934718132019}]}, {"text": " Table 3: Performance (F1) comparison of our ar- gument labeling approach with the subtree extrac- tion approach as adopted in", "labels": [], "entities": [{"text": "F1", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.9570690989494324}]}, {"text": " Table 4: Performance (F1) of our argument label- ing approach.", "labels": [], "entities": [{"text": "F1", "start_pos": 23, "end_pos": 25, "type": "METRIC", "confidence": 0.9769182205200195}, {"text": "argument label- ing", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.6816587597131729}]}, {"text": " Table 5: Contribution of System Combination in  Joint Inference.", "labels": [], "entities": [{"text": "Joint Inference", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.7765112519264221}]}, {"text": " Table 6: Performance (F1) of the end-to-end dis- course parser.", "labels": [], "entities": [{"text": "F1)", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.9676850140094757}, {"text": "dis- course parser", "start_pos": 45, "end_pos": 63, "type": "TASK", "confidence": 0.6998690664768219}]}]}