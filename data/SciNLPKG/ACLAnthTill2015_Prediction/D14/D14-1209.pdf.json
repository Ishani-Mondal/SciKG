{"title": [], "abstractContent": [{"text": "Parameter tuning is an important problem in statistical machine translation, but surprisingly , most existing methods such as MERT, MIRA and PRO are agnostic about search, while search errors could severely degrade translation quality.", "labels": [], "entities": [{"text": "Parameter tuning", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7740389108657837}, {"text": "statistical machine translation", "start_pos": 44, "end_pos": 75, "type": "TASK", "confidence": 0.697136789560318}, {"text": "MERT", "start_pos": 126, "end_pos": 130, "type": "METRIC", "confidence": 0.8942583799362183}, {"text": "MIRA", "start_pos": 132, "end_pos": 136, "type": "METRIC", "confidence": 0.9157400131225586}]}, {"text": "We propose a search-aware framework to promote promising partial translations, preventing them from being pruned.", "labels": [], "entities": []}, {"text": "To do so we develop two met-rics to evaluate partial derivations.", "labels": [], "entities": []}, {"text": "Our technique can be applied to all of the three above-mentioned tuning methods, and extensive experiments on Chinese-to-English and English-to-Chinese translation show up to +2.6 BLEU gains over search-agnostic baselines.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 180, "end_pos": 184, "type": "METRIC", "confidence": 0.9992566704750061}]}], "introductionContent": [{"text": "Parameter tuning has been a key problem for machine translation since the statistical revolution.", "labels": [], "entities": [{"text": "Parameter tuning", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7576167285442352}, {"text": "machine translation", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.7893429398536682}]}, {"text": "However, most existing tuning algorithms treat the decoder as a black box, ignoring the fact that many potentially promising partial translations are pruned by the decoder due to the prohibitively large search space.", "labels": [], "entities": []}, {"text": "For example, the popular beam-search decoding algorithm for phrase-based MT) only explores O(nb) items fora sentence of n words (with abeam width of b), while the full search space is O(2 n n 2 ) or worse.", "labels": [], "entities": [{"text": "MT)", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.8188484609127045}]}, {"text": "As one of the very few exceptions to the \"search-agnostic\" majority, and propose a variant of the perceptron algorithm that learns to keep the reference translations in the beam or chart.", "labels": [], "entities": []}, {"text": "However, there are several obstacles that prevent their method from becoming popular: First of all, they rely on \"forced decoding\" to track gold derivations that lead to the reference translation, but in practice only a small portion of (mostly very short) sen- tence pairs have at least one such derivation.", "labels": [], "entities": []}, {"text": "Secondly, they learn the model on the training set, and while this does enable a sparse feature set, it is orders of magnitude slower compared to MERT and PRO.", "labels": [], "entities": [{"text": "MERT", "start_pos": 146, "end_pos": 150, "type": "METRIC", "confidence": 0.4607761800289154}, {"text": "PRO", "start_pos": 155, "end_pos": 158, "type": "DATASET", "confidence": 0.7605852484703064}]}, {"text": "We instead propose a very simple framework, search-aware tuning, which does not depend on forced decoding, and thus can be trained on all sentence pairs of any dataset.", "labels": [], "entities": []}, {"text": "The key idea is that, besides caring about the rankings of the complete translations, we also promote potentially promising partial translations so that they are more likely to survive throughout the search, see for illustration.", "labels": [], "entities": []}, {"text": "We make the following contributions: \u2022 Our idea of search-aware tuning can be applied (as a patch) to all of the three most popular tuning methods (MERT, PRO, and MIRA) by defining a modified objective function (Section 4).", "labels": [], "entities": [{"text": "MERT", "start_pos": 148, "end_pos": 152, "type": "METRIC", "confidence": 0.7644963264465332}, {"text": "MIRA", "start_pos": 163, "end_pos": 167, "type": "METRIC", "confidence": 0.8774700164794922}]}, {"text": "\u2022 To measure the \"promise\" or \"potential\" of a partial translation, we define anew concept \"potential BLEU\" inspired by future cost in MT decoding) and heuristics in A* search).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.9938103556632996}]}, {"text": "This work is the first study of evaluating metrics for partial translations.", "labels": [], "entities": []}, {"text": "\u2022 Our method obtains substantial and consistent improvements on both the large-scale NIST Chinese-to-English and English-to-Chinese translation tasks on top of MERT, MIRA, and PRO baselines.", "labels": [], "entities": [{"text": "NIST", "start_pos": 85, "end_pos": 89, "type": "DATASET", "confidence": 0.9051050543785095}, {"text": "MERT", "start_pos": 160, "end_pos": 164, "type": "METRIC", "confidence": 0.8652464747428894}, {"text": "MIRA", "start_pos": 166, "end_pos": 170, "type": "METRIC", "confidence": 0.8290538191795349}]}, {"text": "This is the first time that consistent improvements can be achieved with anew learning algorithm under dense feature settings (Section 5).", "labels": [], "entities": []}, {"text": "For simplicity reasons, in this paper we use phrase-based translation, but our work has the potential to be applied to other translation paradigms.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 45, "end_pos": 69, "type": "TASK", "confidence": 0.7839537262916565}]}], "datasetContent": [{"text": "We evaluate our new tuning methods on two large scale NIST translation tasks: Chinese-to-English (CH-EN) and English-to-Chinese (EN-CH) tasks.", "labels": [], "entities": [{"text": "NIST translation", "start_pos": 54, "end_pos": 70, "type": "TASK", "confidence": 0.7154455482959747}]}], "tableCaptions": [{"text": " Table 2: CH-EN task: BLEU scores on test sets (nist03, nist04, nist05, nist06, and nist08). par : partial BLEU; pot :  potential BLEU.  *  : SA-PRO tunes on only 109 short sentences (with less than 10 words) from nist02.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.998916506767273}, {"text": "BLEU", "start_pos": 107, "end_pos": 111, "type": "METRIC", "confidence": 0.9950641989707947}, {"text": "BLEU", "start_pos": 130, "end_pos": 134, "type": "METRIC", "confidence": 0.9960045218467712}]}, {"text": " Table 3: Evaluation on nist02 tuning set using two  methods: BLEU is used to evaluate 1-best complete  translations in the final bin; while potential BLEU is  used to evaluate 1-best partial translations in all bins.  The search-aware objective cares about (the potential  of) all bins, not just the final bin, which can explain this  result.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9990022778511047}, {"text": "BLEU", "start_pos": 151, "end_pos": 155, "type": "METRIC", "confidence": 0.99409419298172}]}, {"text": " Table 4: The k-best oracle BLEU comparison between  MERT and SA-MERT.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 28, "end_pos": 32, "type": "METRIC", "confidence": 0.9935367703437805}, {"text": "MERT", "start_pos": 53, "end_pos": 57, "type": "METRIC", "confidence": 0.7319689393043518}]}, {"text": " Table 6: Comparisons with MAXFORCE in terms of BLEU. nist02-px is the non-trivial reachable prefix-data from  nist02 via forced decoding; nist02-r is a subset of nist02-px consisting of the fully reachable data; train-r is a  subset of fully reachable data from training data that is comparable in size to nist02. All experiments use only  dense features.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.9956099390983582}]}]}