{"title": [{"text": "Muli-label Text Categorization with Hidden Components", "labels": [], "entities": []}], "abstractContent": [{"text": "Multi-label text categorization (MTC) is supervised learning, where a document maybe assigned with multiple categories (labels) simultaneously.", "labels": [], "entities": [{"text": "Multi-label text categorization (MTC)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8226467867692312}]}, {"text": "The labels in the MTC are correlated and the correlation results in some hidden components, which represent the \"share\" variance of correlated labels.", "labels": [], "entities": []}, {"text": "In this paper, we propose a method with hidden components for MTC.", "labels": [], "entities": [{"text": "MTC", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.9597294926643372}]}, {"text": "The proposed method employs PCA to capture the hidden components, and incorporates them into a joint learning framework to improve the performance.", "labels": [], "entities": []}, {"text": "Experiments with real-world data sets and evaluation metrics validate the effectiveness of the proposed method.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many real-world text categorization applications are multi-label text categorization, where a documents is usually assigned with multiple labels simultaneously.", "labels": [], "entities": [{"text": "multi-label text categorization", "start_pos": 53, "end_pos": 84, "type": "TASK", "confidence": 0.638208677371343}]}, {"text": "For example, as shows, a newspaper article concerning global warming can be classified into two categories, Environment, and Science simultaneously.", "labels": [], "entities": []}, {"text": "Let X = Rd be the documents corpus, and Y = {0, 1} m be the label space with m labels.", "labels": [], "entities": []}, {"text": "We denote by {(x x 1 x 1 , y 1 y 1 y 1 ), (x 2 x 2 x 2 , y 2 y 2 y 2 ), ..., (x n x n x n , y n y n y n )} the training set of n documents.", "labels": [], "entities": []}, {"text": "Each document is denoted by a vector xx xi = [x i,1 , x i,2 , ..., x i,d ] of d dimensions.", "labels": [], "entities": []}, {"text": "The labeling of the i-th document is denoted by vector y y y i = [y i,1 , y i,2 , ..., y i,m ], where y il is 1 when the i-th document has the l-th label and 0 otherwise.", "labels": [], "entities": []}, {"text": "The goal is to learn a function ff f : X \u2192 Y.", "labels": [], "entities": []}, {"text": "Generally, we can assume ff f consists of m functions, one fora label.", "labels": [], "entities": []}, {"text": "The labels in the MLC are correlated.", "labels": [], "entities": [{"text": "MLC", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.661625862121582}]}, {"text": "For example, a \"politics\" document is likely to bean \"economic\" document simultaneously, but likely not to be a \"literature\" document.", "labels": [], "entities": []}, {"text": "According to the latent variable model (), the labels with correlation result in some hidden components, which represent the \"share\" variance of correlated labels.", "labels": [], "entities": []}, {"text": "Intuitively, if we can capture and utilize these hidden components in MTC, the performance will be improved.", "labels": [], "entities": []}, {"text": "To implement this idea, we propose a multi-label text categorization method with hidden components, which employ PCA to capture the hidden components, and then incorporates these hidden components into a joint learning framework.", "labels": [], "entities": []}, {"text": "Experiments with various data sets and evaluation metrics validate the values of our method.", "labels": [], "entities": []}, {"text": "The research close to our work is ML-LOC (Multi-Label learning using LOcal Correlation) in).", "labels": [], "entities": []}, {"text": "The differ-ences between ours and ML-LOC is that ML-LOC employs the cluster method to gain the local correlation, but we employ the PCA to obtain the hidden code.", "labels": [], "entities": [{"text": "ML-LOC", "start_pos": 34, "end_pos": 40, "type": "DATASET", "confidence": 0.8464388847351074}]}, {"text": "Meanwhile, ML-LOC uses the linear programming in learning the local code, but we employ the gradient descent method since we add non-linear function to the hidden code.", "labels": [], "entities": []}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 presents the proposed method.", "labels": [], "entities": []}, {"text": "We conduct experiments to demonstrate the effectiveness of the proposed method in section 3.", "labels": [], "entities": []}, {"text": "Section 4 concludes this paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "Compared with the single-label classification, the multi-label setting introduces the additional degrees of freedom, so that various multi-label evaluation metrics are requisite.", "labels": [], "entities": []}, {"text": "We use three different multi-label evaluation metrics, include the hamming loss evaluation metric.", "labels": [], "entities": [{"text": "hamming loss evaluation", "start_pos": 67, "end_pos": 90, "type": "TASK", "confidence": 0.5519939064979553}]}, {"text": "The hamming loss is defined as the percentage of the wrong labels to the total number of labels.", "labels": [], "entities": []}, {"text": "where \u2206 denotes the symmetric difference of two sets, equivalent to XOR operator in Boolean logic.", "labels": [], "entities": [{"text": "XOR", "start_pos": 68, "end_pos": 71, "type": "METRIC", "confidence": 0.9369676113128662}]}, {"text": "m denotes the label number.", "labels": [], "entities": []}, {"text": "The multi-label 0/1 loss, also known as subset accuracy, is the exact match measure as it requires any predicted set of labels h(x x x) to match the true set of labels S exactly.", "labels": [], "entities": [{"text": "multi-label 0/1 loss", "start_pos": 4, "end_pos": 24, "type": "METRIC", "confidence": 0.6167901396751404}, {"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9051967859268188}]}, {"text": "The 0/1 loss is defined as follows: 0/1loss = I(h(x x x) = y y y) Leta j and r j denote the precision and recall for the j-th label.", "labels": [], "entities": [{"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9991173148155212}, {"text": "recall", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.9985472559928894}]}, {"text": "The macro-averaged F is a harmonic mean between precision and recall, defined as follows:  We perform experiments on three MTC data sets: 1) the first data set is slashdot).", "labels": [], "entities": [{"text": "F", "start_pos": 19, "end_pos": 20, "type": "METRIC", "confidence": 0.500539243221283}, {"text": "precision", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9990525841712952}, {"text": "recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9974675178527832}, {"text": "MTC data sets", "start_pos": 123, "end_pos": 136, "type": "DATASET", "confidence": 0.8891284863154093}]}, {"text": "The slashdot data set is concerned about science and technology news categorization, which predicts multiply labels given article titles and partial blurbs mined from Slashdot.org.", "labels": [], "entities": [{"text": "slashdot data set", "start_pos": 4, "end_pos": 21, "type": "DATASET", "confidence": 0.8447239597638448}, {"text": "science and technology news categorization", "start_pos": 41, "end_pos": 83, "type": "TASK", "confidence": 0.6553646802902222}]}, {"text": "2) the second data set is medical (.", "labels": [], "entities": []}, {"text": "This data set involves the assignment of ICD-9-CM codes to radiology reports.", "labels": [], "entities": []}, {"text": "3) the third data set is tmc2007 (Srivastava and Zane-).", "labels": [], "entities": []}, {"text": "It is concerned about safety report categorization, which is to label aviation safety reports with respect to what types of problems they describe.", "labels": [], "entities": []}, {"text": "The characteristics of them are shown in, where n denotes the size of the data set, d denotes the dimension of the document instance, and m denotes the number of labels.", "labels": [], "entities": []}, {"text": "The measure label cardinality Lcard, which is one of the standard measures of \"multi-labelness\", defined as follows, introduced in. where D denotes the data set, l i j denotes the j-th label of the i-th instance in the data set.", "labels": [], "entities": [{"text": "Lcard", "start_pos": 30, "end_pos": 35, "type": "METRIC", "confidence": 0.6258268356323242}]}], "tableCaptions": [{"text": " Table 1: Multi-label data sets and associated statis- tics", "labels": [], "entities": []}, {"text": " Table 2: Performance (mean\u00b1std.) of our method and baseline in terms of different evaluation metrics.", "labels": [], "entities": []}]}