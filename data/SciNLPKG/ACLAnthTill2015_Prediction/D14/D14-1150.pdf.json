{"title": [{"text": "Citation-Enhanced Keyphrase Extraction from Research Papers: A Supervised Approach", "labels": [], "entities": [{"text": "Citation-Enhanced Keyphrase Extraction from Research Papers", "start_pos": 0, "end_pos": 59, "type": "TASK", "confidence": 0.705512156089147}]}], "abstractContent": [{"text": "Given the large amounts of online textual documents available these days, e.g., news articles, weblogs, and scientific papers, effective methods for extracting keyphrases, which provide a high-level topic description of a document, are greatly needed.", "labels": [], "entities": []}, {"text": "In this paper, we propose a supervised model for keyphrase extraction from research papers , which are embedded in citation networks.", "labels": [], "entities": [{"text": "keyphrase extraction from research papers", "start_pos": 49, "end_pos": 90, "type": "TASK", "confidence": 0.8707449078559876}]}, {"text": "To this end, we design novel features based on citation network information and use them in conjunction with traditional features for keyphrase extraction to obtain remarkable improvements in performance over strong baselines.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 134, "end_pos": 154, "type": "TASK", "confidence": 0.8177863955497742}]}], "introductionContent": [{"text": "Keyphrase extraction is the problem of automatically extracting important phrases or concepts (i.e., the essence) of a document.", "labels": [], "entities": [{"text": "Keyphrase extraction", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8456619381904602}, {"text": "automatically extracting important phrases or concepts (i.e., the essence) of a document", "start_pos": 39, "end_pos": 127, "type": "TASK", "confidence": 0.5457286596298218}]}, {"text": "Keyphrases provide a high-level topic description of a document and are shown to be rich sources of information for many applications such as document classification, clustering, recommendation, indexing, searching, and summarization.", "labels": [], "entities": [{"text": "document classification", "start_pos": 142, "end_pos": 165, "type": "TASK", "confidence": 0.7279445230960846}, {"text": "summarization", "start_pos": 220, "end_pos": 233, "type": "TASK", "confidence": 0.9507808089256287}]}, {"text": "Despite the fact that keyphrase extraction has been widely researched in the natural language processing community, its performance is still far from being satisfactory).", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 22, "end_pos": 42, "type": "TASK", "confidence": 0.8989656567573547}]}, {"text": "Many previous approaches to keyphrase extraction generally used only the textual content of a target document to extract keyphrases.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 28, "end_pos": 48, "type": "TASK", "confidence": 0.8992922604084015}]}, {"text": "Recently, proposed a model that incorporates a local neighborhood of a document.", "labels": [], "entities": []}, {"text": "However, their neighborhood is limited to textually-similar documents, where the cosine similarity between the tf-idf vectors of documents is used to compute their similarity.", "labels": [], "entities": []}, {"text": "We posit that, in addition to a document's textual content and textually-similar neighbors, other informative neighborhoods exist that have the potential to improve keyphrase extraction.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 165, "end_pos": 185, "type": "TASK", "confidence": 0.7824018895626068}]}, {"text": "For example, in a scholarly domain, research papers are not isolated.", "labels": [], "entities": []}, {"text": "Rather, they are highly inter-connected in giant citation networks, in which papers cite or are cited by other papers.", "labels": [], "entities": []}, {"text": "Ina citation network, information flows from one paper to another via the citation relation (.", "labels": [], "entities": []}, {"text": "This information flow and the influence of one paper on another are specifically captured by means of citation contexts, i.e., short text segments surrounding a citation's mention.", "labels": [], "entities": []}, {"text": "These contexts are not arbitrary, but they serve as brief summaries of a cited paper.", "labels": [], "entities": []}, {"text": "illustrates this idea using a small citation network of a paper by that cites (), (, and and is cited by).", "labels": [], "entities": []}, {"text": "The citation mentions and citation contexts are shown with a dashed line.", "labels": [], "entities": []}, {"text": "Note the high overlap between the words in contexts and those in the title and abstract (shown in bold) and the author-annotated keywords.", "labels": [], "entities": []}, {"text": "One question that can be raised is the following: Can we effectively exploit information available in large inter-linked document networks in order to improve the performance of keyphrase extraction?", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 178, "end_pos": 198, "type": "TASK", "confidence": 0.8030678331851959}]}, {"text": "The research that we describe in this paper addresses specifically this question using citation networks of research papers as a case study.", "labels": [], "entities": []}, {"text": "Extracting keyphrases that can accurately \"represent\" research papers is crucial to dealing with the large numbers of research papers published during these \"big data\" times.", "labels": [], "entities": [{"text": "Extracting keyphrases", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.889543741941452}]}, {"text": "The importance of keyphrase extraction from research papers is also emphasized by the recent SemEval 2010 Shared Task on this topic (.", "labels": [], "entities": [{"text": "keyphrase extraction from research papers", "start_pos": 18, "end_pos": 59, "type": "TASK", "confidence": 0.8636775255203247}, {"text": "SemEval 2010 Shared Task", "start_pos": 93, "end_pos": 117, "type": "TASK", "confidence": 0.7175371646881104}]}, {"text": "We present a supervised: A small citation network corresponding to a paper by. approach to keyphrase extraction from research papers that, in addition to the information contained in a paper itself, effectively incorporates, in the learned models, information from the paper's local neighborhood available in citation networks.", "labels": [], "entities": [{"text": "keyphrase extraction from research papers", "start_pos": 91, "end_pos": 132, "type": "TASK", "confidence": 0.8313154578208923}]}, {"text": "To this end, we design novel features for keyphrase extraction based on citation context information and use them in conjunction with traditional features in a supervised probabilistic framework.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 42, "end_pos": 62, "type": "TASK", "confidence": 0.8422242105007172}]}, {"text": "We show empirically that the proposed models substantially outperform strong baselines on two datasets of research papers compiled from two machine learning conferences: the World Wide Web and Knowledge Discovery from Data.", "labels": [], "entities": [{"text": "Knowledge Discovery from Data", "start_pos": 193, "end_pos": 222, "type": "TASK", "confidence": 0.7699948251247406}]}, {"text": "The rest of the paper is organized as follows: We summarize closely related work in Section 2.", "labels": [], "entities": []}, {"text": "The supervised classification for keyphrase extraction is discussed in Section 3.", "labels": [], "entities": [{"text": "keyphrase extraction", "start_pos": 34, "end_pos": 54, "type": "TASK", "confidence": 0.8804270029067993}]}, {"text": "Experiments and results are presented in Section 4, followed by conclusions and future directions of our work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we first describe our datasets and then present experimental design and results.", "labels": [], "entities": []}, {"text": "In order to test the performance of our proposed approach, we built our own datasets since citationenhanced evaluation benchmarks are not available for keyphrase extraction tasks.", "labels": [], "entities": [{"text": "keyphrase extraction tasks", "start_pos": 152, "end_pos": 178, "type": "TASK", "confidence": 0.8168373703956604}]}, {"text": "In particular, we compiled two datasets consisting of research papers from two top-tier machine learning conferences: World Wide Web (WWW) and Knowledge Discovery and Data Mining (KDD).", "labels": [], "entities": [{"text": "Knowledge Discovery and Data Mining (KDD)", "start_pos": 143, "end_pos": 184, "type": "TASK", "confidence": 0.8427981249988079}]}, {"text": "Our choice for WWW and KDD was motivated by the availability of author-input keywords for each paper, which we used as gold-standard for evaluation.", "labels": [], "entities": [{"text": "WWW", "start_pos": 15, "end_pos": 18, "type": "DATASET", "confidence": 0.9096245765686035}, {"text": "KDD", "start_pos": 23, "end_pos": 26, "type": "DATASET", "confidence": 0.5931024551391602}]}, {"text": "Using the CiteSeer x digital library 1 , we retrieved the papers published in WWW and KDD (available in CiteSeer x ), and their citation network information, i.e., their cited and citing contexts.", "labels": [], "entities": [{"text": "CiteSeer x digital library", "start_pos": 10, "end_pos": 36, "type": "DATASET", "confidence": 0.8005421757698059}, {"text": "WWW and KDD", "start_pos": 78, "end_pos": 89, "type": "DATASET", "confidence": 0.7254215280214945}]}, {"text": "Since our goal is to study the impact of citation network information on extracting keyphrases, a paper was considered for analysis if it had at least 1 http://citeseerx.ist.psu.edu/ one cited and one citing context.", "labels": [], "entities": []}, {"text": "For each paper, we used: the title and abstract (referred to as the target paper) and its citation contexts.", "labels": [], "entities": []}, {"text": "The reason for not considering the entire text of a paper is that scientific papers contain details, e.g., discussion of results, experimental design, notation, that do not provide additional benefits for extracting keyphrases.", "labels": [], "entities": []}, {"text": "Hence, similar to), we did not use the entire text of a paper.", "labels": [], "entities": []}, {"text": "However, extracting keyphrases from sections such as \"introduction\" or \"conclusion\" needs further attention.", "labels": [], "entities": []}, {"text": "From the pdf of each paper, we extracted the author-input keyphrases.", "labels": [], "entities": []}, {"text": "An analysis of these keyphrases revealed that generally authors describe their work using, almost half of the time, bigrams, followed by unigrams and only rarely using trigrams (or higher n-grams).", "labels": [], "entities": []}, {"text": "A summary of our datasets that contains the number of papers, the average number of cited and citing contexts per paper, the average number of keyphrases per paper, and the number of unigrams, bigrams and trigrams, in each collection, is shown in.", "labels": [], "entities": []}, {"text": "Consistent with previous works, the positive and negative examples in our datasets correspond to candidate phrases that consist of up to three tokens.", "labels": [], "entities": []}, {"text": "The positive examples are candidate phrases that have a match in the author-input keyphrases, whereas negative examples correspond to the remaining candidate phrases.", "labels": [], "entities": []}, {"text": "In CiteSeer x , citation contexts have about 50 words on each side of a citation mention.", "labels": [], "entities": []}, {"text": "A previous study by shows that a fixed window length of about 100 words around a citation mention is generally effective for information retrieval tasks.", "labels": [], "entities": [{"text": "information retrieval", "start_pos": 125, "end_pos": 146, "type": "TASK", "confidence": 0.8000535666942596}]}, {"text": "For this reason, we used the contexts provided by CiteSeer x directly.", "labels": [], "entities": []}, {"text": "However, in future, it would be interesting to incorporate in our models more sophisticated approaches to identifying the text that is relevant to a target citation (Abu-Jbara and Radev, 2012; Teufel, 1999) and study the influence of context lengths on the quality of extracted keyphrase.: The comparison of CeKE with supervised approaches on WWW and KDD collections.", "labels": [], "entities": [{"text": "WWW and KDD collections", "start_pos": 343, "end_pos": 366, "type": "DATASET", "confidence": 0.7644518613815308}]}, {"text": "Our experiments are designed around the following research questions:.", "labels": [], "entities": []}, {"text": "For unsupervised, we considered top 5 and top 10 ranked phrases when computing \"@5\" and \"@10\" measures.", "labels": [], "entities": []}, {"text": "3. How well does our proposed model perform in the absence of either cited or citing contexts?", "labels": [], "entities": []}, {"text": "Since newly published scientific papers are not cited by many other papers, e.g., due to their recency, no cited contexts are available.", "labels": [], "entities": []}, {"text": "We studied the quality of predicted keyphrases when either cited or citing contexts are missing.", "labels": [], "entities": []}, {"text": "For this, we compared the performance of models trained using both cited and citing contexts with that of models that use either cited or citing contexts.", "labels": [], "entities": []}, {"text": "To evaluate the performance of CeKE, we used the following metrics: precision, recall and F1-score for the positive class since correct identification of keyphrases is of most interest.", "labels": [], "entities": [{"text": "precision", "start_pos": 68, "end_pos": 77, "type": "METRIC", "confidence": 0.9996776580810547}, {"text": "recall", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.9991061091423035}, {"text": "F1-score", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9996768236160278}]}, {"text": "These metrics were widely used in previous works.", "labels": [], "entities": []}, {"text": "The reported values are averaged in 10-fold crossvalidation experiments, where folds were created at document level and candidate phrases were extracted from the documents in each fold to form the training and test sets.", "labels": [], "entities": []}, {"text": "In all experiments, we used Na\u00a8\u0131veNa\u00a8\u0131ve Bayes and their Weka implementation 2 . However, any probabilistic classifier that returns a posterior probability of the class given an example, can be used with our features.", "labels": [], "entities": []}, {"text": "The \u03b8 parameter was set to the (title and abstract) tf-idf averaged over the entire collection, while \u03b2 was set to 20.", "labels": [], "entities": []}, {"text": "These values were estimated on a validation set sampled from training.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: A summary of our datasets.", "labels": [], "entities": []}, {"text": " Table 3: The comparison of CeKE with supervised approaches on WWW and KDD collections.", "labels": [], "entities": [{"text": "WWW and KDD collections", "start_pos": 63, "end_pos": 86, "type": "DATASET", "confidence": 0.7350694686174393}]}, {"text": " Table 5: The comparison of CeKE with unsupervised approaches on WWW and KDD collections.", "labels": [], "entities": [{"text": "WWW and KDD collections", "start_pos": 65, "end_pos": 88, "type": "DATASET", "confidence": 0.7639612704515457}]}, {"text": " Table 4: Feature ranking by Info Gain on WWW.", "labels": [], "entities": [{"text": "WWW", "start_pos": 42, "end_pos": 45, "type": "DATASET", "confidence": 0.9714255928993225}]}, {"text": " Table 6: Results of CeKE using both contexts and using with only cited or citing contexts.", "labels": [], "entities": [{"text": "CeKE", "start_pos": 21, "end_pos": 25, "type": "TASK", "confidence": 0.8296775817871094}]}, {"text": " Table 7: Frequency of the predicted keyphrases in  cited / citing contexts.", "labels": [], "entities": [{"text": "Frequency", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9608933925628662}]}]}