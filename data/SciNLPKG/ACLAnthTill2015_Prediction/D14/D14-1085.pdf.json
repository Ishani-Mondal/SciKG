{"title": [{"text": "Unsupervised Sentence Enhancement for Automatic Summarization", "labels": [], "entities": [{"text": "Sentence Enhancement", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.8336397409439087}, {"text": "Summarization", "start_pos": 48, "end_pos": 61, "type": "TASK", "confidence": 0.7028208374977112}]}], "abstractContent": [{"text": "We present sentence enhancement as a novel technique for text-to-text generation in abstractive summarization.", "labels": [], "entities": [{"text": "sentence enhancement", "start_pos": 11, "end_pos": 31, "type": "TASK", "confidence": 0.7282276749610901}, {"text": "text-to-text generation", "start_pos": 57, "end_pos": 80, "type": "TASK", "confidence": 0.7493142485618591}, {"text": "abstractive summarization", "start_pos": 84, "end_pos": 109, "type": "TASK", "confidence": 0.4727944880723953}]}, {"text": "Compared to extraction or previous approaches to sentence fusion, sentence enhancement increases the range of possible summary sentences by allowing the combination of dependency subtrees from any sentence from the source text.", "labels": [], "entities": [{"text": "sentence fusion", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.7318743765354156}, {"text": "sentence enhancement", "start_pos": 66, "end_pos": 86, "type": "TASK", "confidence": 0.6898567378520966}]}, {"text": "Our experiments indicate that our approach yields summary sentences that are competitive with a sentence fusion baseline in terms of content quality, but better in terms of gram-maticality, and that the benefit of sentence enhancement relies crucially on an event coreference resolution algorithm using distributional semantics.", "labels": [], "entities": [{"text": "event coreference resolution", "start_pos": 258, "end_pos": 286, "type": "TASK", "confidence": 0.7072930435339609}]}, {"text": "We also consider how text-to-text generation approaches to summarization can be extended beyond the source text by examining how human summary writers incorporate source-text-external elements into their summary sentences.", "labels": [], "entities": [{"text": "text-to-text generation", "start_pos": 21, "end_pos": 44, "type": "TASK", "confidence": 0.7535531222820282}, {"text": "summarization", "start_pos": 59, "end_pos": 72, "type": "TASK", "confidence": 0.9887418150901794}]}], "introductionContent": [{"text": "Sentence fusion is the technique of merging several input sentences into one output sentence while retaining the important content (.", "labels": [], "entities": [{"text": "Sentence fusion", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9045388102531433}]}, {"text": "For example, the input sentences in maybe fused into one output sentence.", "labels": [], "entities": []}, {"text": "As a text-to-text generation technique, sentence fusion is attractive because it provides an avenue for moving beyond sentence extraction in automatic summarization, while not requiring deep seInput: Bil Mar Foods Co., a meat processor owned by Sara Lee, announced a recall of certain lots of hot dogs and packaged meat.", "labels": [], "entities": [{"text": "text-to-text generation", "start_pos": 5, "end_pos": 28, "type": "TASK", "confidence": 0.7555202543735504}, {"text": "sentence fusion", "start_pos": 40, "end_pos": 55, "type": "TASK", "confidence": 0.7702657878398895}, {"text": "sentence extraction", "start_pos": 118, "end_pos": 137, "type": "TASK", "confidence": 0.7309227287769318}]}, {"text": "Input: The outbreak led to the recall on Tuesday of 15 million pounds of hot dogs and cold cuts produced at the Bil Mar Foods plant.", "labels": [], "entities": [{"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.9973598122596741}, {"text": "Bil Mar Foods plant", "start_pos": 112, "end_pos": 131, "type": "DATASET", "confidence": 0.9184787720441818}]}, {"text": "Output: The outbreak led to the recall on Tuesday of lots of hot dogs and packaged meats produced at the Bil Mar Foods plant.", "labels": [], "entities": [{"text": "Output", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9883499145507812}, {"text": "recall", "start_pos": 32, "end_pos": 38, "type": "METRIC", "confidence": 0.9956923127174377}, {"text": "Bil Mar Foods plant", "start_pos": 105, "end_pos": 124, "type": "DATASET", "confidence": 0.9097582846879959}]}, {"text": "mantic analysis beyond, say, a dependency parser and lexical semantic resources.", "labels": [], "entities": []}, {"text": "The overall trajectory pursued in the field can be characterized as a move away from local contexts relying heavily on the original source text towards more global contexts involving reformulation of the text.", "labels": [], "entities": []}, {"text": "Whereas sentence extraction and sentence compression, for example) involve taking one sentence and perhaps removing parts of it, traditional sentence fusion involves reformulating a small number of relatively similar sentences in order to take the union or intersection of the information present therein.", "labels": [], "entities": [{"text": "sentence extraction", "start_pos": 8, "end_pos": 27, "type": "TASK", "confidence": 0.7882481813430786}, {"text": "sentence compression", "start_pos": 32, "end_pos": 52, "type": "TASK", "confidence": 0.7302535623311996}, {"text": "sentence fusion", "start_pos": 141, "end_pos": 156, "type": "TASK", "confidence": 0.7553731501102448}]}, {"text": "In this paper, we move further along this path in the following ways.", "labels": [], "entities": []}, {"text": "First, we present sentence enhancement as a novel technique which extends sentence fusion by combining the subtrees of many sentences into the output sentence, rather than just a few.", "labels": [], "entities": [{"text": "sentence enhancement", "start_pos": 18, "end_pos": 38, "type": "TASK", "confidence": 0.7309190928936005}, {"text": "sentence fusion", "start_pos": 74, "end_pos": 89, "type": "TASK", "confidence": 0.734366312623024}]}, {"text": "Doing so allows relevant information from sentences that are not similar to the original input sentences to be added during fusion.", "labels": [], "entities": []}, {"text": "As Source text: This fact has been underscored in the last few months by two unexpected outbreaks of food-borne illness.", "labels": [], "entities": []}, {"text": "Output: The outbreak of food-borne illness led to the recall on Tuesday of lots of hot dogs and meats produced at the Bil Mar Foods plant.", "labels": [], "entities": [{"text": "Output", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.9828640222549438}, {"text": "recall", "start_pos": 54, "end_pos": 60, "type": "METRIC", "confidence": 0.9948511719703674}, {"text": "Bil Mar Foods plant", "start_pos": 118, "end_pos": 137, "type": "DATASET", "confidence": 0.916426494717598}]}, {"text": "Figure 2: An example of sentence enhancement, in which parts of dissimilar sentences are incorporated into the output sentence.", "labels": [], "entities": [{"text": "sentence enhancement", "start_pos": 24, "end_pos": 44, "type": "TASK", "confidence": 0.709660142660141}]}, {"text": "shown in, the phrase of food-borne illness can be added to the previous output sentence, despite originating in a source text sentence that is quite different overall.", "labels": [], "entities": []}, {"text": "proposed a supervised method to fuse disparate sentences, which takes as input a small number of sentences with compatible information that have been manually identified by editors of articles.", "labels": [], "entities": []}, {"text": "By contrast, our algorithm is unsupervised, and tackles the problem of identifying compatible event mergers in the entire source text using an event coreference module.", "labels": [], "entities": []}, {"text": "Our method outperforms a previous syntaxbased sentence fusion baseline on measures of summary content quality and grammaticality.", "labels": [], "entities": []}, {"text": "Second, we analyze how text-to-text generation systems may make use of text that is not in the source text itself, but in articles on a related topic in the same domain.", "labels": [], "entities": [{"text": "text-to-text generation", "start_pos": 23, "end_pos": 46, "type": "TASK", "confidence": 0.7284948080778122}]}, {"text": "By examining the parts of human-written summaries that are not found in the source text, we find that using in-domain text allows summary writers to more precisely express some target semantic content, but that more sophisticated computational semantic techniques will be required to enable automatic systems to likewise do so.", "labels": [], "entities": []}, {"text": "A more general argument of this paper is that the apparent dichotomy between text-to-text generation and semantics-to-text generation can be resolved by viewing them simply as having different starting points towards the same end goal of precise and wide-coverage NLG.", "labels": [], "entities": [{"text": "text-to-text generation", "start_pos": 77, "end_pos": 100, "type": "TASK", "confidence": 0.7203122824430466}, {"text": "semantics-to-text generation", "start_pos": 105, "end_pos": 133, "type": "TASK", "confidence": 0.7325666844844818}]}, {"text": "The statistical generation techniques developed by the textto-text generation community have been successful in many domains.", "labels": [], "entities": [{"text": "statistical generation", "start_pos": 4, "end_pos": 26, "type": "TASK", "confidence": 0.8235231041908264}, {"text": "textto-text generation", "start_pos": 55, "end_pos": 77, "type": "TASK", "confidence": 0.821004331111908}]}, {"text": "Yet the results of our experiments and studies demonstrate the following: as text-to-text generation techniques move beyond using local contexts towards more dramatic reformulations of the kind that human writers perform, more semantic analysis will be needed in order to ensure that the reformulations preserve the inferences that can be drawn from the input text.", "labels": [], "entities": [{"text": "text-to-text generation", "start_pos": 77, "end_pos": 100, "type": "TASK", "confidence": 0.7378012239933014}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Results of the sentence enhancement and fusion experiments.", "labels": [], "entities": [{"text": "sentence enhancement and fusion", "start_pos": 25, "end_pos": 56, "type": "TASK", "confidence": 0.7775610089302063}]}, {"text": " Table 3: Results of the domain study. 95% confidence intervals are given in parentheses.", "labels": [], "entities": [{"text": "95% confidence intervals", "start_pos": 39, "end_pos": 63, "type": "METRIC", "confidence": 0.6990873366594315}]}]}