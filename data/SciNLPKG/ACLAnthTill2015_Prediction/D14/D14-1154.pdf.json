{"title": [], "abstractContent": [{"text": "Several recent papers on Arabic dialect identification have hinted that using a word unigram model is sufficient and effective for the task.", "labels": [], "entities": [{"text": "Arabic dialect identification", "start_pos": 25, "end_pos": 54, "type": "TASK", "confidence": 0.666152815024058}]}, {"text": "However, most previous work was done on a standard fairly homogeneous dataset of dialec-tal user comments.", "labels": [], "entities": []}, {"text": "In this paper, we show that training on the standard dataset does not generalize, because a unigram model maybe tuned to topics in the comments and does not capture the distinguishing features of dialects.", "labels": [], "entities": []}, {"text": "We show that effective dialect identification requires that we account for the distinguishing lexical, morphological, and phonological phenomena of dialects.", "labels": [], "entities": [{"text": "dialect identification", "start_pos": 23, "end_pos": 45, "type": "TASK", "confidence": 0.7291804254055023}]}, {"text": "We show that accounting for such can improve dialect detection accuracy by nearly 10% absolute.", "labels": [], "entities": [{"text": "dialect detection", "start_pos": 45, "end_pos": 62, "type": "TASK", "confidence": 0.8784778714179993}, {"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9273544549942017}]}], "introductionContent": [{"text": "Modern Standard Arabic (MSA) is the lingua franca of the so-called Arab world, which includes northern Africa, the Arabian Peninsula, and Mesopotamia.", "labels": [], "entities": [{"text": "Modern Standard Arabic (MSA)", "start_pos": 0, "end_pos": 28, "type": "DATASET", "confidence": 0.6434397647778193}]}, {"text": "However, Arabic speakers generally use dramatically different languages (or dialects) in daily interactions and in social media.", "labels": [], "entities": []}, {"text": "These dialects may differ in vocabulary, morphology, and spelling from MSA and most do not have standard spellings.", "labels": [], "entities": [{"text": "MSA", "start_pos": 71, "end_pos": 74, "type": "DATASET", "confidence": 0.8964444398880005}]}, {"text": "There is often large lexical overlap between dialects and MSA.", "labels": [], "entities": []}, {"text": "Performing proper Arabic dialect identification may positively impact many Natural Language Processing (NLP) application.", "labels": [], "entities": [{"text": "Arabic dialect identification", "start_pos": 18, "end_pos": 47, "type": "TASK", "confidence": 0.7122113704681396}]}, {"text": "For example, transcribing dialectal speech or automatically translating into a particular dialect would be aided by the use of targeted language models that are trained on texts in that dialect.", "labels": [], "entities": [{"text": "transcribing dialectal speech", "start_pos": 13, "end_pos": 42, "type": "TASK", "confidence": 0.8437378803888956}]}, {"text": "This has led to recent interest in automatic identification of different Arabic dialects ().", "labels": [], "entities": [{"text": "automatic identification of different Arabic dialects", "start_pos": 35, "end_pos": 88, "type": "TASK", "confidence": 0.7894673844178518}]}, {"text": "Though previous work () have reported high accuracies for dialect identification using word unigram model, which implies that this is a solved problem, we argue that the problem is far from being solved.", "labels": [], "entities": [{"text": "dialect identification", "start_pos": 58, "end_pos": 80, "type": "TASK", "confidence": 0.7924540340900421}]}, {"text": "The reason for this assertion stems from the fact that the available dialectal data is drawn from singular sources, namely online news sites, for each dialect.", "labels": [], "entities": []}, {"text": "This is problematic because comments on singular news site are likely to have some homogeneity in topics and jargon.", "labels": [], "entities": []}, {"text": "Such homogeneity has caused fairly simple classification techniques that use word unigrams and character ngrams to yield very high identification accuracies.", "labels": [], "entities": []}, {"text": "Perhaps, this can be attributed to topical similarity and not just differences between dialects.", "labels": [], "entities": []}, {"text": "To showcase this, we trained a classifier using the best reported methods, and we tested the classifier on anew test set of 700 tweets, with dialectal Egyptian (ARZ) and MSA tweets, which led to a low accuracy of 83.3%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 201, "end_pos": 209, "type": "METRIC", "confidence": 0.9977216124534607}]}, {"text": "We also sorted words in the ARZ part from our training dataset by how much they discriminate between ARZ and MSA (using mutual information) and indeed many of the top words were in fact MSA words.", "labels": [], "entities": [{"text": "ARZ part", "start_pos": 28, "end_pos": 36, "type": "DATASET", "confidence": 0.9376506209373474}, {"text": "ARZ", "start_pos": 101, "end_pos": 104, "type": "DATASET", "confidence": 0.8895286917686462}]}, {"text": "There seems to be a necessity to identify lexical and linguistic features that discriminate between MSA and different dialects.", "labels": [], "entities": []}, {"text": "In this paper, we highlight some such features that help in separating between MSA and ARZ.", "labels": [], "entities": [{"text": "ARZ", "start_pos": 87, "end_pos": 90, "type": "DATASET", "confidence": 0.8369737863540649}]}, {"text": "We identify common ARZ words that do not overlap with MSA and identify specific linguistic phenomena that exist in ARZ, and not MSA, such as morphological patterns, word concatenations, and verb negation constructs (Section 3).", "labels": [], "entities": [{"text": "verb negation constructs", "start_pos": 190, "end_pos": 214, "type": "TASK", "confidence": 0.7873349189758301}]}, {"text": "We also devise methods for capturing the linguistic phenomena, and we use the appearance of such phenomena as features (Section 4).", "labels": [], "entities": []}, {"text": "Further, we show the positive impact of using the new features in identifying ARZ (Section 5).", "labels": [], "entities": [{"text": "identifying", "start_pos": 66, "end_pos": 77, "type": "TASK", "confidence": 0.8977705240249634}, {"text": "ARZ", "start_pos": 78, "end_pos": 81, "type": "DATASET", "confidence": 0.7223244905471802}]}], "datasetContent": [{"text": "Dataset: We performed dialect identification experiment for ARZ and MSA.", "labels": [], "entities": [{"text": "dialect identification", "start_pos": 22, "end_pos": 44, "type": "TASK", "confidence": 0.824567973613739}, {"text": "ARZ", "start_pos": 60, "end_pos": 63, "type": "DATASET", "confidence": 0.8874368071556091}]}, {"text": "For ARZ, we used the Egyptian side of the LDC2012T09 corpus ( . For MSA, we used the Arabic side of the English/Arabic parallel corpus from the International Workshop on Arabic Language Translation 6 which consists of \u2248 150k sentences.", "labels": [], "entities": [{"text": "ARZ", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.9082311391830444}, {"text": "LDC2012T09 corpus", "start_pos": 42, "end_pos": 59, "type": "DATASET", "confidence": 0.9316700398921967}, {"text": "International Workshop on Arabic Language Translation 6", "start_pos": 144, "end_pos": 199, "type": "TASK", "confidence": 0.8052895750318255}]}, {"text": "For testing, we constructed an evaluation set that is markedly different from the training set.", "labels": [], "entities": []}, {"text": "We crawled Arabic tweets from Twitter during March 2014 and selected those where user location was set to Egypt or a geographic location within Egypt, leading to 880k tweets.", "labels": [], "entities": []}, {"text": "We randomly selected 2k tweets, and we manually annotated them as ARZ, MSA, or neither until we obtained 350 ARZ and 350 MSA tweets.", "labels": [], "entities": [{"text": "ARZ", "start_pos": 66, "end_pos": 69, "type": "DATASET", "confidence": 0.5888721346855164}]}, {"text": "We used these tweets for testing.", "labels": [], "entities": []}, {"text": "We plan to release the tweet ID's and our annotations.", "labels": [], "entities": []}, {"text": "We preprocessed the training and test sets using the method described by, which includes performing letter and word normalizations, and segmented all data using an open-source MSA word segmentor ().", "labels": [], "entities": [{"text": "letter and word normalizations", "start_pos": 100, "end_pos": 130, "type": "TASK", "confidence": 0.6430713534355164}, {"text": "MSA word segmentor", "start_pos": 176, "end_pos": 194, "type": "TASK", "confidence": 0.5470779240131378}]}, {"text": "We also removed punctuations, hashtags, and name mentions from the test set.", "labels": [], "entities": []}, {"text": "We used a Random Forest (RF) ensemble classifier that generates many decision trees, each of which is trained on a subset of the features.", "labels": [], "entities": []}, {"text": "We used the RF implementation in Weka).", "labels": [], "entities": [{"text": "Weka", "start_pos": 33, "end_pos": 37, "type": "DATASET", "confidence": 0.9450823664665222}]}], "tableCaptions": [{"text": " Table 1:  Dialect identification accuracy using  various classification settings: only word-based  (WRD), character-based (CHAR), and both features.  BEST+LEX is built on the best feature of that system  plus a feature built on the concatenation of all lists", "labels": [], "entities": [{"text": "Dialect identification", "start_pos": 11, "end_pos": 33, "type": "TASK", "confidence": 0.8844895362854004}, {"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9173347353935242}, {"text": "BEST+LEX", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.8900584777196249}]}, {"text": " Table 2: Accuracy of the dialect identification system  with the addition of various types of lexicon", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9891995191574097}, {"text": "dialect identification", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.7170272916555405}]}]}