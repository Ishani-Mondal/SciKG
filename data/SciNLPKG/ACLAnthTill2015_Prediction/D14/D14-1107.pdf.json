{"title": [{"text": "A * CCG Parsing with a Supertag-factored Model", "labels": [], "entities": [{"text": "A", "start_pos": 0, "end_pos": 1, "type": "METRIC", "confidence": 0.9293797612190247}, {"text": "Parsing", "start_pos": 8, "end_pos": 15, "type": "TASK", "confidence": 0.8475552201271057}]}], "abstractContent": [{"text": "We introduce anew CCG parsing model which is factored on lexical category assignments.", "labels": [], "entities": [{"text": "CCG parsing", "start_pos": 18, "end_pos": 29, "type": "TASK", "confidence": 0.6277583837509155}]}, {"text": "Parsing is then simply a de-terministic search for the most probable category sequence that supports a CCG derivation.", "labels": [], "entities": [{"text": "Parsing", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.9427976608276367}]}, {"text": "The parser is extremely simple, with a tiny feature set, no POS tagger, and no statistical model of the derivation or dependencies.", "labels": [], "entities": []}, {"text": "Formulating the model in this way allows a highly effective heuris-tic for A * parsing, which makes parsing extremely fast.", "labels": [], "entities": [{"text": "A * parsing", "start_pos": 75, "end_pos": 86, "type": "TASK", "confidence": 0.544314573208491}, {"text": "parsing", "start_pos": 100, "end_pos": 107, "type": "TASK", "confidence": 0.9758170247077942}]}, {"text": "Compared to the standard C&C CCG parser, our model is more accurate out-of-domain, is four times faster, has higher coverage, and is greatly simplified.", "labels": [], "entities": [{"text": "C&C CCG parser", "start_pos": 25, "end_pos": 39, "type": "DATASET", "confidence": 0.7171537399291992}, {"text": "coverage", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.9807330369949341}]}, {"text": "We also show that using our parser improves the performance of a state-of-the-art question answering system.", "labels": [], "entities": [{"text": "question answering", "start_pos": 82, "end_pos": 100, "type": "TASK", "confidence": 0.7738622725009918}]}], "introductionContent": [{"text": "CCG is a strongly lexicalized grammatical formalism, in which the vast majority of the decisions made during interpretation involve choosing the correct definitions of words.", "labels": [], "entities": []}, {"text": "We explore the effect of modelling this explicitly in a parser, by only using a probabilistic model of lexical categories (based on a local context window), rather than modelling the derivation or dependencies.", "labels": [], "entities": []}, {"text": "Existing state-of-the-art CCG parsers use complex pipelines of POS-tagging, supertagging and parsing-each with its own feature sets and parameters (and sources of error)-together with further parameters governing their integration.", "labels": [], "entities": []}, {"text": "We show that much simpler models can achieve high performance.", "labels": [], "entities": []}, {"text": "Our model predicts lexical categories based on a tiny feature set of word embeddings, capitalization, and 2-character suffixes-with no parsing model beyond a small set of CCG combinators, and no POStagger.", "labels": [], "entities": []}, {"text": "Simpler models are easier to implement, replicate and extend.", "labels": [], "entities": []}, {"text": "Another goal of our model is to parse CCG optimally and efficiently, without using excessive pruning.", "labels": [], "entities": [{"text": "parse CCG", "start_pos": 32, "end_pos": 41, "type": "TASK", "confidence": 0.8521530628204346}]}, {"text": "CCG's large set of lexical categories, and generalized notion of constituency, mean that sentences can have a huge number of potential parses.", "labels": [], "entities": [{"text": "CCG", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.9300345182418823}]}, {"text": "Fast existing CCG parsers rely on aggressive pruning-for example, the C&C parser uses a supertagger to dramatically cut the search space considered by the parser.", "labels": [], "entities": []}, {"text": "Even the loosest beam setting for their supertagger discards the correct parse for 20% of sentences.", "labels": [], "entities": []}, {"text": "The structure of our model allows us to introduce a simple but powerful heuristic for A * parsing, meaning it can parse almost 50 sentences per second exactly, with no beam-search or pruning.", "labels": [], "entities": [{"text": "A * parsing", "start_pos": 86, "end_pos": 97, "type": "TASK", "confidence": 0.6190497080485026}]}, {"text": "Adding very mild pruning increases the speed to 186 sentences per second with minimal loss of accuracy.", "labels": [], "entities": [{"text": "speed", "start_pos": 39, "end_pos": 44, "type": "METRIC", "confidence": 0.9963014125823975}, {"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.9948535561561584}]}, {"text": "Our approach faces two obvious challenges.", "labels": [], "entities": []}, {"text": "Firstly, categories are assigned based on a local window, which may not contain the necessary context for resolving some attachment decisions.", "labels": [], "entities": []}, {"text": "For example, in I saw a squirrel 2 weeks ago with a nut, the model cannot make an informed decision on whether to assign with an adverbial or adnominal preposition category, as the crucial words saw and squirrel fall outside the local context window.", "labels": [], "entities": []}, {"text": "Secondly, even if the supertagger makes all lexical category decisions correctly, then the parser can still make erroneous decisions.", "labels": [], "entities": []}, {"text": "One example is in coordination-scope ambiguities, such as clever boys and girls, where the two interpretations use the same assignment of categories.", "labels": [], "entities": []}, {"text": "We hypothesise that such decisions are relatively rare, and are challenging for any parsing model, so a weak model is unlikely to result in substantially lower accuracy.", "labels": [], "entities": [{"text": "parsing", "start_pos": 84, "end_pos": 91, "type": "TASK", "confidence": 0.9727801084518433}, {"text": "accuracy", "start_pos": 160, "end_pos": 168, "type": "METRIC", "confidence": 0.9963789582252502}]}, {"text": "Our implementation of this model 1 , which we call EASYCCG, has high 1 Available from https://github.com/ mikelewis0/easyccg accuracy-suggesting that most parsing decisions can be made accurately based on a local context window.", "labels": [], "entities": [{"text": "EASYCCG", "start_pos": 51, "end_pos": 58, "type": "DATASET", "confidence": 0.590449333190918}, {"text": "easyccg", "start_pos": 117, "end_pos": 124, "type": "METRIC", "confidence": 0.9082062244415283}, {"text": "accuracy-suggesting", "start_pos": 125, "end_pos": 144, "type": "METRIC", "confidence": 0.5058171153068542}, {"text": "parsing", "start_pos": 155, "end_pos": 162, "type": "TASK", "confidence": 0.9644771814346313}]}, {"text": "Of course, there are many parsing decisions that can only be made accurately with more complex models.", "labels": [], "entities": [{"text": "parsing", "start_pos": 26, "end_pos": 33, "type": "TASK", "confidence": 0.9734790325164795}]}, {"text": "However, exploring the power and limitations of simpler models may help focus future research on the more challenging cases.", "labels": [], "entities": []}], "datasetContent": [{"text": "We trained our model on Sections 02-21 of CCGBank (, using Section 00 for development.", "labels": [], "entities": [{"text": "CCGBank", "start_pos": 42, "end_pos": 49, "type": "DATASET", "confidence": 0.7914205193519592}]}, {"text": "For testing, we used Section 23 of CCGBank, a Wikipedia corpus annotated by, and the Bioinfer corpus of biomedical abstracts (.", "labels": [], "entities": [{"text": "Section 23 of CCGBank", "start_pos": 21, "end_pos": 42, "type": "DATASET", "confidence": 0.7963183671236038}, {"text": "Bioinfer corpus of biomedical abstracts", "start_pos": 85, "end_pos": 124, "type": "DATASET", "confidence": 0.919885230064392}]}, {"text": "The latter two are out-of-domain, so are more challenging for the parsers.", "labels": [], "entities": []}, {"text": "We compare the performance of our model against both the C&C parser, and the system described in.", "labels": [], "entities": []}, {"text": "This model uses the same supertagger as used in EASY-CCG, but uses the C&C parser for parsing, using adaptive supertagging with the default values.", "labels": [], "entities": [{"text": "EASY-CCG", "start_pos": 48, "end_pos": 56, "type": "DATASET", "confidence": 0.8536298871040344}, {"text": "parsing", "start_pos": 86, "end_pos": 93, "type": "TASK", "confidence": 0.9703565239906311}]}, {"text": "All timing experiments used the same 1.8Ghz AMD machine.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Parsing F1-scores for labelled dependencies across a range of domains. F1 (cov) refers to  results on sentences which the parser is able to parse, and F1 (all) gives results over all sentences. For  the EASYCCG results, scores are only over parses where the C&C dependency extraction script was  successful, which was 99.3% on CCGBank, 99.5% on Wikipedia, and 100% on Bioinfer.", "labels": [], "entities": [{"text": "F1", "start_pos": 81, "end_pos": 83, "type": "METRIC", "confidence": 0.9962371587753296}, {"text": "F1", "start_pos": 161, "end_pos": 163, "type": "METRIC", "confidence": 0.9945780038833618}, {"text": "C&C dependency extraction script", "start_pos": 268, "end_pos": 300, "type": "TASK", "confidence": 0.6071109722057978}, {"text": "CCGBank", "start_pos": 337, "end_pos": 344, "type": "DATASET", "confidence": 0.9545572400093079}, {"text": "Wikipedia", "start_pos": 355, "end_pos": 364, "type": "DATASET", "confidence": 0.9649964570999146}, {"text": "Bioinfer", "start_pos": 378, "end_pos": 386, "type": "DATASET", "confidence": 0.9625007510185242}]}, {"text": " Table 3: Effect of our optimizations of parsing  speed.", "labels": [], "entities": [{"text": "parsing", "start_pos": 41, "end_pos": 48, "type": "TASK", "confidence": 0.9787663221359253}]}]}