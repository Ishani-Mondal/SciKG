{"title": [{"text": "Learning to Solve Arithmetic Word Problems with Verb Categorization", "labels": [], "entities": [{"text": "Learning to Solve Arithmetic Word Problems", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7525887141625086}]}], "abstractContent": [{"text": "This paper presents a novel approach to learning to solve simple arithmetic word problems.", "labels": [], "entities": []}, {"text": "Our system, ARIS, analyzes each of the sentences in the problem statement to identify the relevant variables and their values.", "labels": [], "entities": [{"text": "ARIS", "start_pos": 12, "end_pos": 16, "type": "METRIC", "confidence": 0.5145688056945801}]}, {"text": "ARIS then maps this information into an equation that represents the problem, and enables its (trivial) solution as shown in Figure 1.", "labels": [], "entities": [{"text": "ARIS", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8503427505493164}]}, {"text": "The paper analyzes the arithmetic-word problems \"genre\", identifying seven categories of verbs used in such problems.", "labels": [], "entities": []}, {"text": "ARIS learns to categorize verbs with 81.2% accuracy, and is able to solve 77.7% of the problems in a corpus of standard primary school test questions.", "labels": [], "entities": [{"text": "ARIS", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8223829865455627}, {"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9993199110031128}]}, {"text": "We report the first learning results on this task without reliance on pre-defined templates and make our data publicly available.", "labels": [], "entities": []}], "introductionContent": [{"text": "Designing algorithms to automatically solve math and science problems is a long-standing AI challenge.", "labels": [], "entities": []}, {"text": "For NLP, mathematical word problems are particularly attractive because the text is concise and relatively straightforward, while the semantics reduces to simple equations.", "labels": [], "entities": []}, {"text": "Arithmetic word problems begin by describing a partial world state, followed by simple updates or elaborations and end with a quantitative question.", "labels": [], "entities": []}, {"text": "For a child, the language understanding part is trivial, but the reasoning maybe challenging; for our system, the opposite is true.", "labels": [], "entities": [{"text": "language understanding", "start_pos": 17, "end_pos": 39, "type": "TASK", "confidence": 0.7646657824516296}]}, {"text": "ARIS needs to  make sense of multiple sentences, as shown in, without a priori restrictions on the syntax or vocabulary used to describe the problem.", "labels": [], "entities": [{"text": "ARIS", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.5992542505264282}]}, {"text": "shows an example where ARIS is asked to infer how many kittens Joan received based on facts and constraints expressed in the text, and represented by the state diagram and corresponding equation.", "labels": [], "entities": [{"text": "ARIS", "start_pos": 23, "end_pos": 27, "type": "DATASET", "confidence": 0.5308428406715393}]}, {"text": "While the equation is trivial, the text could have involved assembling toy aircraft, collecting coins, eating cookies, or just about any activity involving changes in the quantities of discrete objects.", "labels": [], "entities": []}, {"text": "This paper investigates the task of learning to solve such problems by mapping the verbs in the problem text into categories that describe their impact on the world state.", "labels": [], "entities": []}, {"text": "While the verbs category is crucial (e.g., what happens if \"give\" is replaced by \"receive\" in?), some elements of the problem are irrelevant.", "labels": [], "entities": []}, {"text": "For instance, the fact that three kittens have spots is immaterial to the solution.", "labels": [], "entities": []}, {"text": "Thus, ARIS has to determine what information is relevant to solving the problem.", "labels": [], "entities": []}, {"text": "To abstract from the problem text, ARIS maps the text to a state representation which consists of a set of entities, their containers, attributes, quantities, and relations.", "labels": [], "entities": []}, {"text": "A problem text is split into fragments where each fragment corresponds to an observation or an update of the quantity of an entity in one or two containers.", "labels": [], "entities": []}, {"text": "For example in Figure 1, the sentence \"Liz has 5 kittens left and 3 have spots\" has two fragments of \"Liz has 5 kittens left\" and \"3 have spots\".", "labels": [], "entities": []}, {"text": "The verb in each sentence is associated with one or two containers, and ARIS has to classify each verb in a sentence into one of seven categories that describe the impact of the verb on the containers).", "labels": [], "entities": [{"text": "ARIS", "start_pos": 72, "end_pos": 76, "type": "DATASET", "confidence": 0.7332651019096375}]}, {"text": "ARIS learns this classifier based on training data as described in section 4.2.", "labels": [], "entities": [{"text": "ARIS", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.88237065076828}]}, {"text": "To evaluate ARIS, we compiled a corpus of about 400 arithmetic (addition and subtraction) word problems and utilized cross validation to both train ARIS and evaluate its performance over this corpus.", "labels": [], "entities": []}, {"text": "We compare its performance to the template-based learning method developed independently and concurrently by.", "labels": [], "entities": []}, {"text": "We find that our approach is much more robust to domain diversity between the training and test sets.", "labels": [], "entities": []}, {"text": "Our contributions are three-fold: (a) We present ARIS, a novel, fully automated method that learns to solve arithmetic word problems; (b) We introduce a method to automatically categorize verbs for sentences from simple, easy-to-obtain training data; our results refine verb senses in WordNet for arithmetic word problems; (c) We introduce a corpus of arithmetic word problems, and report on a series of experiments showing high efficacy in solving addition and subtraction problems based on verb categorization.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 285, "end_pos": 292, "type": "DATASET", "confidence": 0.9506195187568665}]}], "datasetContent": [{"text": "To experimentally evaluate our method we build a dataset of arithmetic word problems along with their correct solutions.", "labels": [], "entities": []}, {"text": "We test our method on the accuracy of solving arithmetic word problems and identifying verb categories in sentences.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9987868666648865}]}, {"text": "Datasets: We compiled three diverse datasets MA1, MA2, IXL of Arithmetic word problems on addition and subtraction for third, fourth, and fifth graders.", "labels": [], "entities": [{"text": "IXL", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.9863134622573853}]}, {"text": "These datasets have similar problem types, but have different characteristics.", "labels": [], "entities": []}, {"text": "Problem types include combinations of additions, subtractions, one unknown equations, and U.S. money word problems.", "labels": [], "entities": []}, {"text": "Problems in MA2 include more irrelevant information compared to the other two datasets, and IXL includes more information gaps.", "labels": [], "entities": [{"text": "IXL", "start_pos": 92, "end_pos": 95, "type": "METRIC", "confidence": 0.686703085899353}]}, {"text": "In total, they include 395 problems, 13,632 words, 118 verbs, and 1,483 sentences.   sentences.", "labels": [], "entities": []}, {"text": "We use the percentage of correct answers to the problems as the evaluation metric for the first task and accuracy as the evaluation metric for the second task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 105, "end_pos": 113, "type": "METRIC", "confidence": 0.9992817044258118}]}, {"text": "We use Weka's SVM (Witten et al., 1999) with default parameters for classification which is trained with verb categories in sentences (as described in Section 4.2).", "labels": [], "entities": []}, {"text": "For the first task, we compare ARIS with KAZB (), majority baseline, ARIS 2 , and Gold ARIS.", "labels": [], "entities": [{"text": "ARIS", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.6562170386314392}, {"text": "KAZB", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.8912248015403748}]}, {"text": "KAZB requires training data in the form of equation systems and numerical answers to the problems.", "labels": [], "entities": [{"text": "KAZB", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8515939116477966}]}, {"text": "The majority baseline classifies every instance as increasing.", "labels": [], "entities": []}, {"text": "In ARIS 2 (a variant of ARIS) the system is trained in away that no verb is repeated in the training and test sets.", "labels": [], "entities": [{"text": "ARIS 2", "start_pos": 3, "end_pos": 9, "type": "DATASET", "confidence": 0.7800379395484924}, {"text": "ARIS", "start_pos": 24, "end_pos": 28, "type": "DATASET", "confidence": 0.8810492157936096}]}, {"text": "Gold ARIS uses the ground-truth sentence categories instead of predicted ones.", "labels": [], "entities": [{"text": "Gold ARIS", "start_pos": 0, "end_pos": 9, "type": "DATASET", "confidence": 0.9048322141170502}]}, {"text": "For the second task, we compare ARIS with a baseline that uses WordNet verb senses.", "labels": [], "entities": [{"text": "ARIS", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.594251811504364}]}], "tableCaptions": [{"text": " Table 2: Properties of the datasets.", "labels": [], "entities": []}, {"text": " Table 3: Accuracy of solving arithmetic word problems in", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9899653196334839}]}, {"text": " Table 4: Ablation study and baseline comparisons: this ta-", "labels": [], "entities": [{"text": "Ablation", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9974337220191956}]}]}