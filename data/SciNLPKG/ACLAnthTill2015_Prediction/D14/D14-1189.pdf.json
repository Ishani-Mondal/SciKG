{"title": [{"text": "Detecting Non-compositional MWE Components using Wiktionary", "labels": [], "entities": [{"text": "Detecting Non-compositional MWE", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8519682685534159}, {"text": "Wiktionary", "start_pos": 49, "end_pos": 59, "type": "DATASET", "confidence": 0.5448179841041565}]}], "abstractContent": [{"text": "We propose a simple unsupervised approach to detecting non-compositional components in multiword expressions based on Wiktionary.", "labels": [], "entities": []}, {"text": "The approach makes use of the definitions, synonyms and translations in Wiktionary, and is applicable to any type of MWE in any language, assuming the MWE is contained in Wiktionary.", "labels": [], "entities": []}, {"text": "Our experiments show that the proposed approach achieves higher F-score than state-of-the-art methods.", "labels": [], "entities": [{"text": "F-score", "start_pos": 64, "end_pos": 71, "type": "METRIC", "confidence": 0.9993317723274231}]}], "introductionContent": [{"text": "A multiword expression (MWE) is a combination of words with lexical, syntactic or semantic idiosyncrasy (;).", "labels": [], "entities": [{"text": "multiword expression (MWE)", "start_pos": 2, "end_pos": 28, "type": "TASK", "confidence": 0.6622238874435424}]}, {"text": "An MWE is considered (semantically) \"non-compositional\" when its meaning is not predictable from the meaning of its components.", "labels": [], "entities": []}, {"text": "Conversely, compositional MWEs are those whose meaning is predictable from the meaning of the components.", "labels": [], "entities": []}, {"text": "Based on this definition, a component is compositional within an MWE, if its meaning is reflected in the meaning of the MWE, and it is non-compositional otherwise.", "labels": [], "entities": []}, {"text": "Understanding which components are noncompositional within an MWE is important in NLP applications in which semantic information is required.", "labels": [], "entities": []}, {"text": "For example, when searching for spelling bee, we may also be interested in documents about spelling, but not those which contain only bee.", "labels": [], "entities": []}, {"text": "For research project, on the other hand, we are likely to be interested in documents which contain either research or project in isolation, and for swansong, we are only going to be interested in documents which contain the phrase swansong, and not just swan or song.", "labels": [], "entities": []}, {"text": "In this paper, we propose an unsupervised approach based on Wikitionary for predicting which components of a given MWE have a compositional usage.", "labels": [], "entities": [{"text": "Wikitionary", "start_pos": 60, "end_pos": 71, "type": "DATASET", "confidence": 0.953624427318573}]}, {"text": "Experiments over two widely-used datasets show that our approach outperforms stateof-the-art methods.", "labels": [], "entities": []}], "datasetContent": [{"text": "As mentioned above, we evaluate our method over the same two datasets as (which were later used, in addition to a third dataset of German noun compounds, in): (1) 90 binary English noun compounds (ENCs, e.g. spelling bee or swimming pool); and (2) 160 English verb particle constructions (EVPCs, e.g. stand up and give away).", "labels": [], "entities": []}, {"text": "Our results are not directly comparable with those of and, however, who evaluated in terms of a regression task, modelling the overall compositionality of the MWE.", "labels": [], "entities": []}, {"text": "In our case, the task setup is a binary classification task relative to each of the two components of the MWE.", "labels": [], "entities": []}, {"text": "The ENC dataset was originally constructed by The EVPC dataset was constructed by, and manually annotated for compositionality on a binary scale for each of the head verb and particle.", "labels": [], "entities": [{"text": "ENC dataset", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9065819084644318}, {"text": "EVPC dataset", "start_pos": 50, "end_pos": 62, "type": "DATASET", "confidence": 0.9518792629241943}]}, {"text": "For the 160 EVPCs, 76% are verb-compositional and 48% are particlecompositional.", "labels": [], "entities": []}, {"text": "On average, each EVPC in this dataset has 3.0 senses (definitions) in Wiktionary.", "labels": [], "entities": []}, {"text": "The baseline for each dataset takes the form of looking fora user-annotated idiom tag in the Wiktionary lexical entry for the MWE: if there is an idiomatic tag, both components are considered to be non-compositional; otherwise, both components are considered to be compositional.", "labels": [], "entities": []}, {"text": "We expect this method to suffer from low precision for two  reasons: first, the guidelines given to the annotators of our datasets might be different from what Wiktionary contributors assume to bean idiom.", "labels": [], "entities": [{"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9967470169067383}]}, {"text": "Second, the baseline method assumes that for any non-compositional MWE, all components must be equally non-compositional, despite the wealth of MWEs where one or more components are compositional (e.g. from the Wiktionary guidelines for idiom inclusion, 3 computer chess, basketball player, telephone box).", "labels": [], "entities": []}, {"text": "We also compare our method with: (1) \"LCS\", the string similarity-based method of, in which 54 languages are used; (2) \"DS\", the monolingual distributional similarity method of; (3) \"DS+DSL2\", the multilingual distributional similarity method of, including supervised language selection fora given dataset, based on crossvalidation; and (4) \"LCS+DS+DSL2\", whereby the first three methods are combined using a supervised support vector regression model.", "labels": [], "entities": []}, {"text": "In each case, the continuous output of the model is equal-width discretised to generate a binary classification.", "labels": [], "entities": []}, {"text": "We additionally present results for the combination of each of the six methods proposed in this paper with LCS, DS and DSL2, using a linear-kernel support vector machine (represented with the suffix \" COMB(LCS+DS+DSL2) \" fora given method).", "labels": [], "entities": []}, {"text": "The results are based on cross-3 http://en.wiktionary.org/wiki/ Wiktionary:Idioms_that_survived_RFD validation, and for direct comparability, the partitions are exactly the same as. provide the results when our proposed method for detecting non-compositionality is applied to the ENC and EVPC datasets, respectively.", "labels": [], "entities": [{"text": "ENC", "start_pos": 280, "end_pos": 283, "type": "DATASET", "confidence": 0.9498196840286255}, {"text": "EVPC datasets", "start_pos": 288, "end_pos": 301, "type": "DATASET", "confidence": 0.8506076037883759}]}, {"text": "The inclusion of translation data was found to improve all of precision, recall and F-score across the board for all of the proposed methods.", "labels": [], "entities": [{"text": "translation", "start_pos": 17, "end_pos": 28, "type": "TASK", "confidence": 0.9397481083869934}, {"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9997699856758118}, {"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9997327923774719}, {"text": "F-score", "start_pos": 84, "end_pos": 91, "type": "METRIC", "confidence": 0.9990969896316528}]}, {"text": "For reasons of space, results without translation data are therefore omitted from the paper.", "labels": [], "entities": []}, {"text": "Overall, the simple unsupervised methods proposed in this paper are comparable with the unsupervised and supervised state-of-the-art methods of and, with ITAG achieving the highest F-score for the ENC dataset and for the verb components of the EVPC dataset.", "labels": [], "entities": [{"text": "F-score", "start_pos": 181, "end_pos": 188, "type": "METRIC", "confidence": 0.9987724423408508}, {"text": "ENC dataset", "start_pos": 197, "end_pos": 208, "type": "DATASET", "confidence": 0.9670602679252625}, {"text": "EVPC dataset", "start_pos": 244, "end_pos": 256, "type": "DATASET", "confidence": 0.9807068705558777}]}, {"text": "The inclusion of synonyms boosts results inmost cases.", "labels": [], "entities": []}, {"text": "When we combine each of our proposed methods with the string and distributional similarity methods of and, we see substantial improvements over the comparable combined method of \"LCS+DS+DSL2\" inmost cases, demonstrating both the robustness of the proposed methods and their complementarity with the earlier methods.", "labels": [], "entities": [{"text": "LCS+DS+DSL2", "start_pos": 179, "end_pos": 190, "type": "DATASET", "confidence": 0.6725449323654175}]}, {"text": "It is important to reinforce that the proposed methods make no language-specific assumptions and are therefore applicable to any type of MWE and any language, with the only requirement being that the MWE of interest be listed in the Wiktionary for", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Compositionality prediction results over the ENC dataset, relative to the first component (the  modifier noun) and the second component (the head noun)", "labels": [], "entities": [{"text": "Compositionality prediction", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.9487732648849487}, {"text": "ENC dataset", "start_pos": 55, "end_pos": 66, "type": "DATASET", "confidence": 0.9417417347431183}]}, {"text": " Table 3: Compositionality prediction results over the EVPC dataset, relative to the first component (the  head verb) and the second component (the particle)", "labels": [], "entities": [{"text": "Compositionality prediction", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.9303115904331207}, {"text": "EVPC dataset", "start_pos": 55, "end_pos": 67, "type": "DATASET", "confidence": 0.9569835066795349}]}]}