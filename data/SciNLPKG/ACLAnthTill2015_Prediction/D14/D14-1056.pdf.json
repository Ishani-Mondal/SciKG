{"title": [], "abstractContent": [{"text": "Shell nouns, such as fact and problem, occur frequently in all kinds of texts.", "labels": [], "entities": []}, {"text": "These nouns themselves are unspecific, and can only be interpreted together with the shell content.", "labels": [], "entities": []}, {"text": "We propose a general approach to automatically identify shell content of shell nouns.", "labels": [], "entities": []}, {"text": "Our approach exploits lexico-syntactic knowledge derived from the linguistics literature.", "labels": [], "entities": []}, {"text": "We evaluate the approach on a variety of shell nouns with a variety of syntactic expectations, achieving accuracies in the range of 62% (base-line = 33%) to 83% (baseline = 74%) on crowd-annotated data.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 105, "end_pos": 115, "type": "METRIC", "confidence": 0.9957866072654724}]}], "introductionContent": [{"text": "Shell nouns are abstract nouns, such as fact, issue, idea, and problem, which facilitate efficiency by avoiding repetition of long stretches of text.", "labels": [], "entities": []}, {"text": "The shell metaphor comes from, and it captures the various functions of these nouns in a discourse: containment, signalling, pointing, and encapsulating.", "labels": [], "entities": []}, {"text": "Shell nouns themselves are unspecific, and can only be interpreted together with their shell content, i.e., the propositional content they encapsulate in the given context.", "labels": [], "entities": []}, {"text": "The process of identifying this content in the given context is referred to as shell noun resolution or interpretation.", "labels": [], "entities": [{"text": "shell noun resolution or interpretation", "start_pos": 79, "end_pos": 118, "type": "TASK", "confidence": 0.7105114102363587}]}, {"text": "Examples (1), (2), and show usages of the shell nouns fact and issue.", "labels": [], "entities": []}, {"text": "The shell noun phrases are resolved to the postnominal that clause, the complement wh clause, and the immediately preceding clause, respectively.", "labels": [], "entities": []}, {"text": "(1) The fact that a major label hadn't been at liberty to exploit and repackage the material on CD meant that prices on the vintage LP market were soaring.", "labels": [], "entities": []}, {"text": "(2) The issue that this country and Congress must address is how to provide optimal care for all without limiting access for the many.", "labels": [], "entities": []}, {"text": "(3) Living expenses are much lower in rural India than in New York, but this fact is not fully captured if prices are converted with currency exchange rates.", "labels": [], "entities": []}, {"text": "Observe that the relation between shell noun phrases and their shell content is similar to the relation of abstract anaphora (or cataphora) with backward-or forward-looking abstract-object antecedents.", "labels": [], "entities": []}, {"text": "For anaphoric shell noun examples, the shell content precedes the shell noun phrase, and for cataphoric shell noun examples the shell content follows the shell noun phrase.", "labels": [], "entities": []}, {"text": "Shell nouns as a group occur frequently in argumentative texts).", "labels": [], "entities": []}, {"text": "They play an important role in organizing a discourse and maintaining its coherence, and resolving them is an important component of various computational linguistics tasks that rely on Note that the postnominal that-clause in (1) is not a relative clause: the fact in question is not an argument of exploit and repackage.", "labels": [], "entities": []}, {"text": "2 All examples in this paper are from the New York Times corpus (https://catalog.ldc.upenn.edu/ LDC2008T19) We use the terms cataphoric shell noun and anaphoric shell noun for lack of better alternatives.", "labels": [], "entities": [{"text": "New York Times corpus", "start_pos": 42, "end_pos": 63, "type": "DATASET", "confidence": 0.8035252541303635}]}, {"text": "Accordingly, identifying shell content can be helpful in summarization, information retrieval, and ESL learning.", "labels": [], "entities": [{"text": "summarization", "start_pos": 57, "end_pos": 70, "type": "TASK", "confidence": 0.9944175481796265}, {"text": "information retrieval", "start_pos": 72, "end_pos": 93, "type": "TASK", "confidence": 0.8199432492256165}, {"text": "ESL learning", "start_pos": 99, "end_pos": 111, "type": "TASK", "confidence": 0.9125442802906036}]}, {"text": "Despite their importance in discourse, understanding of shell nouns from a computational linguistics perspective is only in the preliminary stage.", "labels": [], "entities": [{"text": "understanding of shell nouns", "start_pos": 39, "end_pos": 67, "type": "TASK", "confidence": 0.8150618076324463}]}, {"text": "Recently, we proposed an approach to annotate and resolve anaphoric cases of six typical shell nouns: fact, reason, issue, decision, question, and possibility ().", "labels": [], "entities": [{"text": "resolve anaphoric cases of six typical shell nouns: fact, reason, issue, decision, question, and possibility", "start_pos": 50, "end_pos": 158, "type": "Description", "confidence": 0.7638700434139797}]}, {"text": "This work drew on the observation that shell nouns following cataphoric constructions are easy to resolve.", "labels": [], "entities": []}, {"text": "We manually developed rules to identify shell content for such cases.", "labels": [], "entities": []}, {"text": "Later, we used these cataphoric examples and their shell content as training data to resolve harder anaphoric examples.", "labels": [], "entities": []}, {"text": "In this paper, we propose a general algorithm to resolve cataphoric shell noun examples.", "labels": [], "entities": [{"text": "resolve cataphoric shell noun examples", "start_pos": 49, "end_pos": 87, "type": "TASK", "confidence": 0.7708830237388611}]}, {"text": "Our longterm goal is to build an end-to-end shell-noun resolution system.", "labels": [], "entities": [{"text": "shell-noun resolution", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.7660979926586151}]}, {"text": "If we want to go beyond the six shell nouns from our previous work, and generalize our approach to other shell nouns, first we need to develop an approach to resolve cataphoric shell noun examples.", "labels": [], "entities": []}, {"text": "A number of challenges are associated with this seemingly easy task.", "labels": [], "entities": []}, {"text": "The primary challenges is that this resolution is in many crucial respects a semantic phenomenon.", "labels": [], "entities": []}, {"text": "To obtain the required semantic knowledge, we exploit the properties of shell nouns and their categorization described in the linguistics literature.", "labels": [], "entities": []}, {"text": "We evaluate our method using crowdsourcing, and demonstrate how far one can get with simple, deterministic shell content extraction.", "labels": [], "entities": [{"text": "deterministic shell content extraction", "start_pos": 93, "end_pos": 131, "type": "TASK", "confidence": 0.7333233505487442}]}], "datasetContent": [{"text": "We claim that our algorithm is able to resolve a variety of shell nouns.", "labels": [], "entities": []}, {"text": "That said, creating evaluation data for all of Schmid's 670 English shell 505 nouns is extremely time-consuming, and is therefore not pursued further in the current study.", "labels": [], "entities": []}, {"text": "Instead we create a sample of representative evaluation data to examine how well the algorithm works a) on a variety of shell nouns, b) for shell nouns within a family, c) for shell nouns across families with completely different semantic and syntactic expectations, and d) fora variety of shell patterns from Table 1.", "labels": [], "entities": []}, {"text": "Baseline We evaluate our algorithm against crowd-annotated data using a lexico-syntactic clause (LSC) baseline.", "labels": [], "entities": []}, {"text": "Given a sentence containing a shell instance and its parse tree, this baseline extracts the postnominal or complement clause from the parse tree depending only upon the lexico-syntactic pattern of the shell noun.", "labels": [], "entities": []}, {"text": "For instance, for the N-that and N-be-to patterns, it ex-describes the purpose or the goal for the reason, but not the shell content itself.", "labels": [], "entities": []}, {"text": "On the downside, adding Schmid's cues hurts the performance of more versatile nouns, which can take a variety of clauses.", "labels": [], "entities": []}, {"text": "Although the A-SC results for the shell nouns plan, policy, problem, trouble, difficulty, and phenomenon are well above the baseline, the A+SC results are markedly below it.", "labels": [], "entities": [{"text": "A-SC", "start_pos": 13, "end_pos": 17, "type": "METRIC", "confidence": 0.9726459980010986}]}, {"text": "That is, Schmid's cues were deleterious.", "labels": [], "entities": []}, {"text": "Our error analysis revealed that these nouns are versatile in terms of the clauses they take as shell content, and Schmid's cues restrict these clauses to be selected as shell content.", "labels": [], "entities": []}, {"text": "For instance, the shell noun problem occurs in two semantic families with N-be-that/of and N-be-to as pattern cues, and postnominal clauses are not allowed for this noun.", "labels": [], "entities": []}, {"text": "Although these cues help in filtering some unwanted cases, we observed a large number of cases where the shell content is given in postnominal clauses, as shown in (13).", "labels": [], "entities": []}, {"text": "(13) I was trying to address the problem of unreliable testimony by experts in capital cases.", "labels": [], "entities": []}, {"text": "Similarly, the Plan family does not allow the Nof pattern.", "labels": [], "entities": [{"text": "Plan family", "start_pos": 15, "end_pos": 26, "type": "DATASET", "confidence": 0.8925392627716064}]}, {"text": "This cue works well for the shell noun decision from the same family because often the postnominal of clause is the agent for this shell noun and not the shell content.", "labels": [], "entities": []}, {"text": "However, it hurts the performance of the shell noun policy, as Nof is a common pattern for this shell noun (e.g., . .", "labels": [], "entities": []}, {"text": "officials in Rwanda have established a policy of refusing to protect refugees.", "labels": [], "entities": []}, {"text": "). Other failures of the algorithm are due to parsing errors and lack of inclusion of context information.", "labels": [], "entities": [{"text": "parsing", "start_pos": 46, "end_pos": 53, "type": "TASK", "confidence": 0.9636219143867493}]}], "tableCaptions": [{"text": " Table 2: Distribution of cataphoric patterns for six shell nouns in the New York Times corpus. Each  column shows the percentage of instances following that pattern. The last column shows the total number  of cataphoric instances of each noun in the corpus.", "labels": [], "entities": [{"text": "New York Times corpus", "start_pos": 73, "end_pos": 94, "type": "DATASET", "confidence": 0.880800649523735}]}, {"text": " Table 4: Annotator agreement on shell content.  Each column shows the percentage of instances on  which at least n or fewer than n annotators agree  on a single answer.", "labels": [], "entities": []}]}