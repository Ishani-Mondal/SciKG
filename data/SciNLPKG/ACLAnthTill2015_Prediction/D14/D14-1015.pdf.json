{"title": [{"text": "Improve Statistical Machine Translation with Context-Sensitive Bilingual Semantic Embedding Model", "labels": [], "entities": [{"text": "Improve Statistical Machine Translation", "start_pos": 0, "end_pos": 39, "type": "TASK", "confidence": 0.8634108304977417}]}], "abstractContent": [{"text": "We investigate how to improve bilingual embedding which has been successfully used as a feature in phrase-based statistical machine translation (SMT).", "labels": [], "entities": [{"text": "phrase-based statistical machine translation (SMT)", "start_pos": 99, "end_pos": 149, "type": "TASK", "confidence": 0.738101431301662}]}, {"text": "Despite bilingual embedding's success, the contextual information, which is of critical importance to translation quality, was ignored in previous work.", "labels": [], "entities": [{"text": "translation", "start_pos": 102, "end_pos": 113, "type": "TASK", "confidence": 0.9626079201698303}]}, {"text": "To employ the contextual information, we propose a simple and memory-efficient model for learning bilingual embedding, taking both the source phrase and context around the phrase into account.", "labels": [], "entities": []}, {"text": "Bilingual translation scores generated from our proposed bilingual embedding model are used as features in our SMT system.", "labels": [], "entities": [{"text": "Bilingual translation", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7091842591762543}, {"text": "SMT", "start_pos": 111, "end_pos": 114, "type": "TASK", "confidence": 0.9940166473388672}]}, {"text": "Experimental results show that the proposed method achieves significant improvements on large-scale Chinese-English translation task.", "labels": [], "entities": [{"text": "Chinese-English translation", "start_pos": 100, "end_pos": 127, "type": "TASK", "confidence": 0.6477218568325043}]}], "introductionContent": [{"text": "In Statistical Machine Translation (SMT) system, it is difficult to determine the translation of some phrases that have ambiguous meanings.For example, the phrase \" jieguo\" can be translated to either \"results\", \"eventually\" or \"fruit\", depending on the context around it.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 3, "end_pos": 40, "type": "TASK", "confidence": 0.8295188347498575}]}, {"text": "There are two reasons for the problem: First, the length of phrase pairs is restricted due to the limitation of model size and training data.", "labels": [], "entities": []}, {"text": "Another reason is that SMT systems often fail to use contextual information in source sentence, therefore, phrase sense disambiguation highly depends on the language model which is trained only on target corpus.", "labels": [], "entities": [{"text": "SMT", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.9909446239471436}, {"text": "phrase sense disambiguation", "start_pos": 107, "end_pos": 134, "type": "TASK", "confidence": 0.8508234024047852}]}, {"text": "To solve this problem, we present to learn context-sensitive bilingual semantic embedding.", "labels": [], "entities": []}, {"text": "Our methodology is to train a supervised model where labels are automatically generated from phrase-pairs.", "labels": [], "entities": []}, {"text": "For each source phrase, the aligned target phrase is marked as the positive label whereas other phrases in our phrase table are treated as negative labels.", "labels": [], "entities": []}, {"text": "Different from previous work in bilingual embedding learning(), our framework is a supervised model that utilizes contextual information in source sentence as features and make use of phrase pairs as weak labels.", "labels": [], "entities": []}, {"text": "Bilingual semantic embeddings are trained automatically from our supervised learning task.", "labels": [], "entities": []}, {"text": "Our learned bilingual semantic embedding model is used to measure the similarity of phrase pairs which is treated as a feature in decoding.", "labels": [], "entities": []}, {"text": "We integrate our learned model into a phrase-based translation system and experimental results indicate that our system significantly outperform the baseline system.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 38, "end_pos": 62, "type": "TASK", "confidence": 0.6811789870262146}]}, {"text": "On the NIST08 Chinese-English translation task, we obtained 0.68 BLEU improvement.", "labels": [], "entities": [{"text": "NIST08 Chinese-English translation task", "start_pos": 7, "end_pos": 46, "type": "TASK", "confidence": 0.8210971653461456}, {"text": "BLEU", "start_pos": 65, "end_pos": 69, "type": "METRIC", "confidence": 0.9995688796043396}]}, {"text": "We also test our proposed method on much larger web dataset and obtain 0.49 BLEU improvement against the baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9982494711875916}]}], "datasetContent": [{"text": "Our experiments are performed using an inhouse phrase-based system with a log-linear framework.", "labels": [], "entities": []}, {"text": "Our system includes a phrase translation model, an n-gram language model, a lexicalized reordering model, a word penalty model and a phrase penalty model, which is similar to Moses (. The evaluation metric is BLEU).", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.8287981450557709}, {"text": "BLEU", "start_pos": 209, "end_pos": 213, "type": "METRIC", "confidence": 0.9984478950500488}]}], "tableCaptions": [{"text": " Table 1: Results of lowercase BLEU on NIST08  task. LOC is the location feature and POS is  the Part-of-Speech feature * or ** equals to sig- nificantly better than our baseline(\u03c1 < 0.05 or  \u03c1 < 0.01, respectively)", "labels": [], "entities": [{"text": "BLEU", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.9878820180892944}, {"text": "NIST08", "start_pos": 39, "end_pos": 45, "type": "DATASET", "confidence": 0.8743440508842468}, {"text": "LOC", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9687840342521667}, {"text": "POS", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.9683243036270142}]}]}