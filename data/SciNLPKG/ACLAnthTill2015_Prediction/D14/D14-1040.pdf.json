{"title": [{"text": "Probabilistic Models of Cross-Lingual Semantic Similarity in Context Based on Latent Cross-Lingual Concepts Induced from Comparable Data", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose the first probabilistic approach to modeling cross-lingual semantic similarity (CLSS) in context which requires only comparable data.", "labels": [], "entities": [{"text": "cross-lingual semantic similarity (CLSS)", "start_pos": 56, "end_pos": 96, "type": "TASK", "confidence": 0.7250983119010925}]}, {"text": "The approach relies on an idea of projecting words and sets of words into a shared latent semantic space spanned by language-pair independent latent semantic concepts (e.g., cross-lingual topics obtained by a multilingual topic model).", "labels": [], "entities": []}, {"text": "These latent cross-lingual concepts are induced from a comparable corpus without any additional lexical resources.", "labels": [], "entities": []}, {"text": "Word meaning is represented as a probability distribution over the latent concepts, and a change in meaning is represented as a change in the distribution over these latent concepts.", "labels": [], "entities": []}, {"text": "We present new models that modulate the isolated out-of-context word representations with contex-tual knowledge.", "labels": [], "entities": []}, {"text": "Results on the task of suggesting word translations in context for 3 language pairs reveal the utility of the proposed contextualized models of cross-lingual semantic similarity.", "labels": [], "entities": [{"text": "suggesting word translations in context for 3 language pairs", "start_pos": 23, "end_pos": 83, "type": "TASK", "confidence": 0.8055897951126099}]}], "introductionContent": [{"text": "Cross-lingual semantic similarity (CLSS) is a metric that measures to which extent words (or more generally, text units) describe similar semantic concepts and convey similar meanings across languages.", "labels": [], "entities": [{"text": "Cross-lingual semantic similarity (CLSS)", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.7951215257247289}]}, {"text": "Models of cross-lingual similarity are typically used to automatically induce bilingual lexicons and have found numerous applications in information retrieval (IR), statistical machine translation (SMT) and other natural language processing (NLP) tasks.", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 137, "end_pos": 163, "type": "TASK", "confidence": 0.8454623341560363}, {"text": "statistical machine translation (SMT)", "start_pos": 165, "end_pos": 202, "type": "TASK", "confidence": 0.7931536038716634}]}, {"text": "Within the IR framework, the output of the CLSS models is a key resource in the models of dictionary-based cross-lingual information retrieval;) or maybe utilized in query expansion in cross-lingual IR models).", "labels": [], "entities": [{"text": "cross-lingual information retrieval", "start_pos": 107, "end_pos": 142, "type": "TASK", "confidence": 0.6058028936386108}, {"text": "query expansion", "start_pos": 166, "end_pos": 181, "type": "TASK", "confidence": 0.733112633228302}]}, {"text": "These CLSS models may also be utilized as an additional source of knowledge in SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 79, "end_pos": 82, "type": "TASK", "confidence": 0.9958478212356567}]}, {"text": "Additionally, the models area crucial component in the crosslingual tasks involving a sort of cross-lingual knowledge transfer, where the knowledge about utterances in one language maybe transferred to another.", "labels": [], "entities": [{"text": "cross-lingual knowledge transfer", "start_pos": 94, "end_pos": 126, "type": "TASK", "confidence": 0.6314798394838969}]}, {"text": "The utility of the transfer or annotation projection by means of bilingual lexicons obtained from the CLSS models has already been proven in various tasks such as semantic role labeling), parsing (), POS tagging (, verb classification (), inducing selectional preferences, named entity recognition (, named entity segmentation (, etc.", "labels": [], "entities": [{"text": "transfer or annotation projection", "start_pos": 19, "end_pos": 52, "type": "TASK", "confidence": 0.6250398233532906}, {"text": "semantic role labeling", "start_pos": 163, "end_pos": 185, "type": "TASK", "confidence": 0.6443715691566467}, {"text": "parsing", "start_pos": 188, "end_pos": 195, "type": "TASK", "confidence": 0.9710039496421814}, {"text": "POS tagging", "start_pos": 200, "end_pos": 211, "type": "TASK", "confidence": 0.85371994972229}, {"text": "verb classification", "start_pos": 215, "end_pos": 234, "type": "TASK", "confidence": 0.7834511697292328}, {"text": "named entity recognition", "start_pos": 273, "end_pos": 297, "type": "TASK", "confidence": 0.6009307205677032}, {"text": "named entity segmentation", "start_pos": 301, "end_pos": 326, "type": "TASK", "confidence": 0.6514425277709961}]}, {"text": "The models of cross-lingual semantic similarity from parallel corpora rely on word alignment models (, but due to a relative scarceness of parallel texts for many language pairs and domains, the models of cross-lingual similarity from comparable corpora have gained much attention recently.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 78, "end_pos": 92, "type": "TASK", "confidence": 0.6986116468906403}]}, {"text": "All these models from parallel and comparable corpora provide ranked lists of semantically similar words in the target language in isolation or invariably, that is, they do not explicitly iden-tify and encode different senses of words.", "labels": [], "entities": []}, {"text": "In practice, it means that, given the sentence \"The coach of his team was not satisfied with the game yesterday.\", these context-insensitive models of similarity are notable to detect that the Spanish word entrenador is more similar to the polysemous word coach in the context of this sentence than the Spanish word autocar, although autocar is listed as the most semantically similar word to coach globally/invariably without any observed context.", "labels": [], "entities": []}, {"text": "In another example, while Spanish words partido, encuentro, cerilla or correspondencia are all highly similar to the ambiguous English word match when observed in isolation, given the Spanish sentence \"She was unable to find a match in her pocket to light up a cigarette.\", it is clear that the strength of semantic similarity should change in context as only cerilla exhibits a strong semantic similarity to match within this particular sentential context.", "labels": [], "entities": []}, {"text": "Following this intuition, in this paper we investigate models of cross-lingual semantic similarity in context.", "labels": [], "entities": []}, {"text": "The context-sensitive models of similarity target to re-rank the lists of semantically similar words based on the co-occurring contexts of words.", "labels": [], "entities": []}, {"text": "Unlike prior work (e.g.,), we explore these models in a particularly difficult and minimalist setting that builds only on co-occurrence counts and latent cross-lingual semantic concepts induced directly from comparable corpora, and which does not rely on any other resource (e.g., machine-readable dictionaries, parallel corpora, explicit ontology and category knowledge).", "labels": [], "entities": []}, {"text": "In that respect, the work reported in this paper extends the current research on purely statistical data-driven distributional models of cross-lingual semantic similarity that are built upon the idea of latent cross-lingual concepts () induced from non-parallel data.", "labels": [], "entities": []}, {"text": "While all the previous models in this framework are context-insensitive models of semantic similarity, we demonstrate how to build context-aware models of semantic similarity within the same probabilistic framework which relies on the same shared set of latent concepts.", "labels": [], "entities": []}, {"text": "The main contributions of this paper are: \u2022 We present anew probabilistic approach to modeling cross-lingual semantic similarity in context based on latent cross-lingual semantic concepts induced from non-parallel data.", "labels": [], "entities": []}, {"text": "\u2022 We show how to use the models of crosslingual semantic similarity in the task of suggesting word translations in context.", "labels": [], "entities": [{"text": "suggesting word translations in context", "start_pos": 83, "end_pos": 122, "type": "TASK", "confidence": 0.7378814458847046}]}, {"text": "\u2022 We provide results for three language pairs which demonstrate that contextualized models of similarity significantly outscore context-insensitive models.", "labels": [], "entities": []}], "datasetContent": [{"text": "Evaluation Task: Suggesting Word Translations in Context.", "labels": [], "entities": [{"text": "Suggesting Word Translations in Context", "start_pos": 17, "end_pos": 56, "type": "TASK", "confidence": 0.90286785364151}]}, {"text": "Given an occurrence of a polysemous word w S 1 \u2208 V S in the source language L S with vocabulary V S , the task is to choose the correct translation in the target language L T of that particular occurrence of w S 1 from the given set T = {t T 1 , . .", "labels": [], "entities": []}, {"text": ", t T q }, T \u2286 VT , of its q possible translations/meanings (i.e., its translation or sense inventory).", "labels": [], "entities": []}, {"text": "The task of suggesting a word translation in context maybe interpreted as ranking the q translations with respect to the observed local context Con(w S 1 ) of the occurrence of the word w S 1 . The best scoring translation candidate in the ranked list is then the suggested correct translation for that particular occurrence of w S 1 after observing its local context Con(w S 1 ).", "labels": [], "entities": [{"text": "word translation", "start_pos": 25, "end_pos": 41, "type": "TASK", "confidence": 0.7152681201696396}]}, {"text": "We use the following corpora for inducing latent cross-lingual concepts/topics, i.e., for training our multilingual topic model: (i) a collection of 13, 696 Spanish-English Wikipedia article pairs (Wiki-ES-EN), (ii) a collection of 18, 898 Italian-English Wikipedia article pairs, (iii) a collection of 7, 612 Dutch-English Wikipedia article pairs (Wiki-NL-EN), and (iv) the Wiki-NL-EN corpus augmented with 6,206 Dutch-English document pairs from Europarl () (Wiki+EP-NL-EN).", "labels": [], "entities": [{"text": "Wiki-NL-EN corpus", "start_pos": 375, "end_pos": 392, "type": "DATASET", "confidence": 0.7965786755084991}, {"text": "Europarl", "start_pos": 448, "end_pos": 456, "type": "DATASET", "confidence": 0.9568895697593689}]}, {"text": "The corpora were previously used in . No explicit use is made of sentence-level alignments in Europarl.: Sets of 15 ambiguous words in Spanish, Italian and Dutch from our test set accompanied by the sets of their respective possible senses/translations in English.", "labels": [], "entities": [{"text": "Europarl.", "start_pos": 94, "end_pos": 103, "type": "DATASET", "confidence": 0.9596599340438843}]}, {"text": "All corpora are theme-aligned comparable corpora, i.e, the aligned document pairs discuss similar themes, but are in general not direct translations (except for Europarl).", "labels": [], "entities": [{"text": "Europarl", "start_pos": 161, "end_pos": 169, "type": "DATASET", "confidence": 0.9681240320205688}]}, {"text": "By training on Wiki+EP-NL-EN we want to test how the training corpus of higher quality affects the estimation of latent cross-lingual concepts that span the shared latent semantic space and, consequently, the overall results in the task of suggesting word translations in context.", "labels": [], "entities": [{"text": "suggesting word translations in context", "start_pos": 240, "end_pos": 279, "type": "TASK", "confidence": 0.7443838357925415}]}, {"text": "Following prior work (, we retain only nouns that occur at least 5 times in the corpus.", "labels": [], "entities": []}, {"text": "We record lemmatized word forms when available, and original forms otherwise.", "labels": [], "entities": []}, {"text": "We use TreeTagger ( for POS tagging and lemmatization.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 24, "end_pos": 35, "type": "TASK", "confidence": 0.759546309709549}]}, {"text": "We have constructed test datasets in Spanish (ES), Italian (IT) and Dutch (NL), where the aim is to find their correct translation in English (EN) given the sentential context.", "labels": [], "entities": []}, {"text": "We have selected 15 polysemous nouns (see tab. 2 for the list of nouns along with their possible translations) in each of the 3 languages, and have manually extracted 24 sentences (not present in the training data) for each noun that capture different meanings of the noun from Wikipedia.", "labels": [], "entities": []}, {"text": "In order to construct datasets that are balanced across different possible translations of a noun, in case of q different translation candidates in T for some word w S 1 , the dataset contains exactly 24/q sentences for each translation from T . In total, we have designed 360 sentences for each language pair (ES/IT/NL-EN), 1080 sentences in total.", "labels": [], "entities": []}, {"text": "We have used 5 extra nouns with 20 sentences each as a development set to tune the parameters of our models.", "labels": [], "entities": []}, {"text": "As a by-product, we have built an initial repository of ES/IT/NL ambiguous words.", "labels": [], "entities": [{"text": "ES/IT/NL ambiguous words", "start_pos": 56, "end_pos": 80, "type": "DATASET", "confidence": 0.7683414646557399}]}, {"text": "1 presents a small sample from the IT evaluation dataset, and illustrates the task of suggesting word translations in context.", "labels": [], "entities": [{"text": "IT evaluation dataset", "start_pos": 35, "end_pos": 56, "type": "DATASET", "confidence": 0.6300227840741476}, {"text": "suggesting word translations in context", "start_pos": 86, "end_pos": 125, "type": "TASK", "confidence": 0.7190340638160706}]}, {"text": "Our task is to present the system a list of possible translations and let the system decide a single most likely translation given the word and its sentential context.", "labels": [], "entities": []}, {"text": "Ground truth thus contains one word, that is, one correct translation for each sentence from the evaluation dataset.", "labels": [], "entities": []}, {"text": "We have manually annotated the correct translation for the ground truth 1 by inspecting the discourse in Wikipedia articles and the interlingual Wikipedia links.", "labels": [], "entities": []}, {"text": "We measure the performance of all models as Top 1 accuracy (Acc 1 ) (.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.8354478478431702}, {"text": "Acc 1", "start_pos": 60, "end_pos": 65, "type": "METRIC", "confidence": 0.9776096045970917}]}, {"text": "It denotes the number of word instances from the evaluation dataset whose top proposed candidate in the ranked list of translation candidates from T is exactly the correct translation for that word instance as given by ground truth over the total number of test word instances (360 in each test dataset).", "labels": [], "entities": []}, {"text": "We have tuned \u03bb 1 and \u03bb 2 on the development sets.", "labels": [], "entities": []}, {"text": "We set \u03bb 1 = \u03bb 2 = 0.9 for all language pairs.", "labels": [], "entities": []}, {"text": "We use sorted context sets (see sect. 2) and perform a cut-off at M = 3 most descriptive context words in the sorted context sets for all models.", "labels": [], "entities": []}, {"text": "In the following section we discuss the utility of this context sorting and pruning, as well as its influence on the overall results.", "labels": [], "entities": [{"text": "context sorting", "start_pos": 56, "end_pos": 71, "type": "TASK", "confidence": 0.720135509967804}]}, {"text": "Our context-aware models are generic and allow experimentations with different models that induce latent cross-lingual semantic concepts.", "labels": [], "entities": []}, {"text": "However, in this particular work we present results obtained by a multilingual probabilistic topic model called bilingual LDA ().", "labels": [], "entities": []}, {"text": "The BiLDA model is a straightforward multilingual extension of the standard LDA model (.", "labels": [], "entities": []}, {"text": "For the details regarding the modeling, generative story and training of the bilingual LDA model, we refer the interested reader to the aforementioned relevant literature.", "labels": [], "entities": [{"text": "generative story", "start_pos": 40, "end_pos": 56, "type": "TASK", "confidence": 0.9020492136478424}]}, {"text": "We have used the Gibbs sampling procedure tailored for BiLDA in particular for training and have experimented with different number of topics K in the interval 300 \u2212 2500.", "labels": [], "entities": [{"text": "BiLDA", "start_pos": 55, "end_pos": 60, "type": "DATASET", "confidence": 0.7912777662277222}]}, {"text": "Here, we present only the results obtained with K = 2000 for all language pairs which also yielded the best or near-optimal performance in ().", "labels": [], "entities": []}, {"text": "Other parameters of the model are set to the typical values according to: \u03b1 = 50/K and \u03b2 = 0.01.", "labels": [], "entities": []}, {"text": "(1) We have tested different SF-s (e.g., the Kullback-Leibler and the Jensen-Shannon divergence, the cosine measure) on the K-dimensional vector representations, and have detected that in general the best scores are obtained with the Bhattacharyya coefficient (BC), (2) Another similarity method we use is the socalled Cue method (), which models the probability that a target word t Ti will be generated as an association response given some cue source word w S 1 . In short, the method computes the score P (t Ti |w S 1 ) = P (t Ti |z k )P (z k |w S 1 ).", "labels": [], "entities": [{"text": "Bhattacharyya coefficient (BC)", "start_pos": 234, "end_pos": 264, "type": "METRIC", "confidence": 0.9642704248428344}]}, {"text": "We can use the scores P (t Ti |w S 1 ) obtained by inputting out-ofcontext probability scores P (z k |w S 1 ) or modulated probability scores P (z k |w S 1 ) to produce the ranking of translation candidates.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Results on the 3 evaluation datasets. Translation direction is ES/IT/NL\u2192EN. The improvements  of all contextualized models over non-contextualized models are statistically significant according to a  chi-square statistical significance test (p<0.05). The asterisk (*) denotes significant improvements of  Smoothed-Fusion over Late-Fusion using the same significance test.", "labels": [], "entities": []}]}