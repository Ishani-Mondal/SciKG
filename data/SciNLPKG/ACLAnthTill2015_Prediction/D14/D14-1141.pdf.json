{"title": [{"text": "PCFG Induction for Unsupervised Parsing and Language Modelling", "labels": [], "entities": []}], "abstractContent": [{"text": "The task of unsupervised induction of probabilistic context-free grammars (PCFGs) has attracted a lot of attention in the field of computational linguistics.", "labels": [], "entities": [{"text": "induction of probabilistic context-free grammars (PCFGs)", "start_pos": 25, "end_pos": 81, "type": "TASK", "confidence": 0.7768348976969719}]}, {"text": "Although it is a difficult task, work in this area is still very much in demand since it can contribute to the advancement of language parsing and modelling.", "labels": [], "entities": [{"text": "language parsing", "start_pos": 126, "end_pos": 142, "type": "TASK", "confidence": 0.7684100270271301}]}, {"text": "In this work, we describe anew algorithm for PCFG induction based on a principled approach and capable of inducing accurate yet compact artificial natural language grammars and typical context-free grammars.", "labels": [], "entities": [{"text": "PCFG induction", "start_pos": 45, "end_pos": 59, "type": "TASK", "confidence": 0.934212863445282}]}, {"text": "Moreover, this algorithm can work on large grammars and datasets and infers correctly even from small samples.", "labels": [], "entities": []}, {"text": "Our analysis shows that the type of grammars induced by our algorithm are, in theory, capable of modelling natural language.", "labels": [], "entities": []}, {"text": "One of our experiments shows that our algorithm can potentially outperform the state-of-the-art in unsupervised parsing on the WSJ10 corpus.", "labels": [], "entities": [{"text": "WSJ10 corpus", "start_pos": 127, "end_pos": 139, "type": "DATASET", "confidence": 0.9885884821414948}]}], "introductionContent": [{"text": "The task of unsupervised induction of PCFGs has attracted a lot of attention in the field of computational linguistics.", "labels": [], "entities": [{"text": "computational linguistics", "start_pos": 93, "end_pos": 118, "type": "TASK", "confidence": 0.7032561898231506}]}, {"text": "This task can take the form of either parameter search or structure learning.", "labels": [], "entities": []}, {"text": "In parameter search, a CFG is fixed and the focus is on assigning probabilities to this grammar using Bayesian methods or maximum likelihood estimation).", "labels": [], "entities": []}, {"text": "In structure learning, the focus is on building the right grammar rules from scratch.", "labels": [], "entities": [{"text": "structure learning", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.9045627415180206}]}, {"text": "We take the latter approach.", "labels": [], "entities": []}, {"text": "Unsupervised structure learning of (P)CFGs is a notoriously difficult task (de la, with theoretical results showing that in general it is either impossible to achieve or requires impractical resources.", "labels": [], "entities": [{"text": "structure learning of (P)CFGs", "start_pos": 13, "end_pos": 42, "type": "TASK", "confidence": 0.7221126556396484}]}, {"text": "At the same time, it is well known that context-free structures are needed for better language parsing and modelling, since less expressive models (such as HMMs) are not good enough.", "labels": [], "entities": [{"text": "language parsing", "start_pos": 86, "end_pos": 102, "type": "TASK", "confidence": 0.690866082906723}]}, {"text": "Moreover, the trend is towards unsupervised (rather than supervised) learning methods due to the lack inmost languages of annotated data and the applicability in wider domains ().", "labels": [], "entities": []}, {"text": "Thus, despite its difficulty, unsupervised PCFG grammar induction (or induction of other similarly expressive models) is still an important task in computational linguistics.", "labels": [], "entities": [{"text": "PCFG grammar induction", "start_pos": 43, "end_pos": 65, "type": "TASK", "confidence": 0.7357030113538107}]}, {"text": "In this paper, we describe anew algorithm for PCFG induction based on a principled approach and capable of inducing accurate yet compact grammars.", "labels": [], "entities": [{"text": "PCFG induction", "start_pos": 46, "end_pos": 60, "type": "TASK", "confidence": 0.9270421266555786}]}, {"text": "Moreover, this algorithm can work on large grammars and datasets and infers correctly even from small samples.", "labels": [], "entities": []}, {"text": "We show that our algorithm is capable of achieving competitive results in both unsupervised parsing and language modelling of typical context-free languages and artificial natural language grammars.", "labels": [], "entities": []}, {"text": "We also show that the type of grammars we propose to learn are, in theory, capable of modelling natural language.", "labels": [], "entities": []}], "datasetContent": [{"text": "We tested our system on 11 typical context-free languages and 9 artificial natural language grammars taken from 4 different sources).", "labels": [], "entities": []}, {"text": "The 11 CFLs include 7 described by unambiguous grammars: UC1: an b n UC2: an b n cm d m UC3: an b m n \u2265 m UC4: a p b q , p = q UC5: Palindromes over alphabet {a, b} with a central marker UC6:Palindromes over alphabet {a, b} without a central marker in) NL2: Grammar 'b', in) NL3: Lexical categories and constituency, pg 96 in NL4: Recursive embedding of constituents, pg 97 in NL5: Agreement, pg 98 in NL6: Singular/plural NPs and number agreement, pg 99 in NL7: Experiment 3.1 grammar in () NL8:Grammar in () NL9: TA1 grammar in ().", "labels": [], "entities": []}, {"text": "The quality of the learned model depends on its capacity to predict the correct structure (parse trees) on the one hand and to predict the correct sentence probabilities on the other (i.e. assigns a probability distribution close to the target one).", "labels": [], "entities": []}, {"text": "To evaluate parse trees, we follow suggestions given by van and use micro-precision and micro-recall overall the nontrivial brackets.", "labels": [], "entities": []}, {"text": "We take the harmonic mean of these two values to obtain the Unlabelled brackets F 1 score (UF 1 ).", "labels": [], "entities": [{"text": "Unlabelled brackets F 1 score", "start_pos": 60, "end_pos": 89, "type": "METRIC", "confidence": 0.7469744503498077}, {"text": "UF 1", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.865422785282135}]}, {"text": "The learned distribution can be evaluated using perplexity (when the target distribution is not known) or some similarity metric between distributions (when the target distribution is known).", "labels": [], "entities": []}, {"text": "In our case, the target distribution is: Relative Entropy and UF 1 results of our system COMINO vs ADIOS and ABL respectively.", "labels": [], "entities": [{"text": "Relative Entropy", "start_pos": 41, "end_pos": 57, "type": "METRIC", "confidence": 0.8701671063899994}, {"text": "UF 1", "start_pos": 62, "end_pos": 66, "type": "METRIC", "confidence": 0.9855628907680511}, {"text": "ABL", "start_pos": 109, "end_pos": 112, "type": "METRIC", "confidence": 0.8920945525169373}]}, {"text": "Best results are highlighted, close results (i.e. with a difference of at most 0.1 for relative entropy and 1% for UF 1 ) are both highlighted known.", "labels": [], "entities": []}, {"text": "We chose relative entropy 2 as a good measure of distance between distributions.", "labels": [], "entities": []}, {"text": "Our UF 1 results over test sets of one thousand strings were compared to results obtained by ABL), which is a system whose primary aim is that of finding good parse trees (rather than identifying the target language).", "labels": [], "entities": [{"text": "ABL", "start_pos": 93, "end_pos": 96, "type": "DATASET", "confidence": 0.6763432025909424}]}, {"text": "Although ABL does not obtain state-of-the-art results on natural language corpora, it proved to be the best system (for which an implementation is readily available) for unsupervised parsing of sentences generated by artificial grammars.", "labels": [], "entities": [{"text": "parsing of sentences generated by artificial grammars", "start_pos": 183, "end_pos": 236, "type": "TASK", "confidence": 0.7893461074147906}]}, {"text": "We calculated the relative entropy on a test set of one million strings generated from the target grammar.", "labels": [], "entities": []}, {"text": "We compared our results with ADIOS (), a system which obtains competitive results on language modelling ( and whose primary aim is of correctly identifying the target language (rather than finding good parse trees).", "labels": [], "entities": []}, {"text": "For the tests in the first section of (i.e. above the first dashed line), our algorithm was capable of exactly identifying the structure of the target grammar.", "labels": [], "entities": []}, {"text": "Notwithstanding this, the bracketing results for these tests did not always yield perfect scores.", "labels": [], "entities": []}, {"text": "This happened whenever the target grammar was ambiguous, in which case the most probable parse trees of the target and learned grammar can be different, thus leading to incorrect bracketing.", "labels": [], "entities": []}, {"text": "For the tests in the second section of (i.e. between the two dashed lines), our algorithm was capable of exactly identifying the target language (but not the grammar).", "labels": [], "entities": []}, {"text": "In all of these cases, the induced grammar was slightly smaller than the target one.", "labels": [], "entities": []}, {"text": "For the remaining tests, our algorithm did not identify the target language.", "labels": [], "entities": []}, {"text": "In fact, it always overgeneralised.", "labels": [], "entities": []}, {"text": "The 3 typical CFLs UC3, UC4 and UC6 are not identified because they are not contained in our subclass of CFLs.", "labels": [], "entities": []}, {"text": "Inspite of this, the relative entropy results obtained are still relatively good.", "labels": [], "entities": []}, {"text": "Overall, it is fair to say that the results obtained by our system, for both language modelling and unsupervised parsing on artificial data, are competitive with the results obtained by other methods.", "labels": [], "entities": [{"text": "language modelling", "start_pos": 77, "end_pos": 95, "type": "TASK", "confidence": 0.7616862058639526}]}, {"text": "bution Dis defined as smoothing is used to solve the problem of zero probabilities.", "labels": [], "entities": []}, {"text": "We also experimented on natural language corpora.", "labels": [], "entities": []}, {"text": "For unsupervised parsing, we tested our system on the WSJ10 corpus, using POS tagged sentences as input.", "labels": [], "entities": [{"text": "WSJ10 corpus", "start_pos": 54, "end_pos": 66, "type": "DATASET", "confidence": 0.9913574159145355}]}, {"text": "Due to time efficiency, we changed the algorithm for finding congruence classes.", "labels": [], "entities": []}, {"text": "Instead of always choosing the best possible merge w.r.t. the distance function, a distance threshold is set and all congruence classes whose distance is smaller than the threshold are merged.", "labels": [], "entities": []}, {"text": "Also, we changed the distance function from L1-Distance to Pearson's \u03c7 2 test.", "labels": [], "entities": []}, {"text": "Ina first experiment (vaguely similar to the one done by), we constructed the best possible SC-CFG consistent with the merges done in the first phase and assigned probabilities to this grammar using Inside-Outside.", "labels": [], "entities": []}, {"text": "In other words, we ran the second phase of our system in a supervised fashion by using the treebank to decide which are the best congruence classes to choose as non-terminals.", "labels": [], "entities": []}, {"text": "The CNF grammar we obtained from this experiment (COMINO-UBOUND) gives very good parsing results which outperform results from state-of-theart systems DMV+CCM), U-DOP (Bod, 2006a), UML-DOP) and Incremental as shown in.", "labels": [], "entities": [{"text": "Incremental", "start_pos": 194, "end_pos": 205, "type": "METRIC", "confidence": 0.9754527807235718}]}, {"text": "Moreover, the results obtained are very close to the best results one can ever hope to obtain from any CNF grammar on WSJ10 (CNF-UBOUND).", "labels": [], "entities": [{"text": "WSJ10", "start_pos": 118, "end_pos": 123, "type": "DATASET", "confidence": 0.939651608467102}]}, {"text": "However, the grammar we obtain does not generalise enough and does not describe a good language model.", "labels": [], "entities": []}, {"text": "Ina second experiment, we ran the complete COMINO system.", "labels": [], "entities": []}, {"text": "The grammar obtained from this experiment did not give competitive parsing results.", "labels": [], "entities": []}, {"text": "The first experiment shows that the merge decisions taken in the first phase do not hinder the possibility of finding a very good grammar for parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 142, "end_pos": 149, "type": "TASK", "confidence": 0.9711306095123291}]}, {"text": "This means that the merge decisions taken by our system are good in general.", "labels": [], "entities": []}, {"text": "Manual analysis on some of the merges taken confirms this.", "labels": [], "entities": []}, {"text": "This experiment also shows that there exists a nontrivial PCFG in our restrictive class of grammars that is capable of achieving very good parsing results.", "labels": [], "entities": []}, {"text": "This is a positive sign for the question of how adequate SC-PCFGs are for modelling natural languages.", "labels": [], "entities": []}, {"text": "However, the real test remains that of finding SC-PCFGs that generate good bracketings and good language models.", "labels": [], "entities": []}, {"text": "The second experiment shows that the second phase of our al-: Parsing results on WSJ10.", "labels": [], "entities": [{"text": "WSJ10", "start_pos": 81, "end_pos": 86, "type": "DATASET", "confidence": 0.949016273021698}]}, {"text": "Note that Incremental is the only system listed as state-of-theart which parses from plain text and can generate non-binary trees gorithm is not giving good results.", "labels": [], "entities": []}, {"text": "This means that the smallest possible grammar might not be the best grammar for parsing.", "labels": [], "entities": []}, {"text": "Therefore, other criteria alongside the grammar size are needed when choosing a grammar consistent with the merges.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Size of the alphabet, number of non- terminals and productions rules of the grammars.", "labels": [], "entities": []}, {"text": " Table 2: Relative Entropy and UF 1 results of our  system COMINO vs ADIOS and ABL respec- tively. Best results are highlighted, close results  (i.e. with a difference of at most 0.1 for relative  entropy and 1% for UF 1 ) are both highlighted", "labels": [], "entities": [{"text": "Relative", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9325299859046936}, {"text": "UF 1", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.8573445677757263}, {"text": "ABL", "start_pos": 79, "end_pos": 82, "type": "METRIC", "confidence": 0.9096265435218811}]}, {"text": " Table 3: Parsing results on WSJ10. Note that In- cremental is the only system listed as state-of-the- art which parses from plain text and can generate  non-binary trees", "labels": [], "entities": [{"text": "WSJ10", "start_pos": 29, "end_pos": 34, "type": "DATASET", "confidence": 0.929551362991333}]}]}