{"title": [{"text": "A Graph-based Approach for Contextual Text Normalization", "labels": [], "entities": [{"text": "Contextual Text Normalization", "start_pos": 27, "end_pos": 56, "type": "TASK", "confidence": 0.6259856224060059}]}], "abstractContent": [{"text": "The informal nature of social media text renders it very difficult to be automatically processed by natural language processing tools.", "labels": [], "entities": []}, {"text": "Text normalization, which corresponds to restoring the non-standard words to their canonical forms, provides a solution to this challenge.", "labels": [], "entities": [{"text": "Text normalization", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7576897740364075}]}, {"text": "We introduce an unsupervised text normalization approach that utilizes not only lexical, but also con-textual and grammatical features of social text.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.7641007006168365}]}, {"text": "The contextual and grammatical features are extracted from a word association graph built by using a large unlabeled social media text corpus.", "labels": [], "entities": []}, {"text": "The graph encodes the relative positions of the words with respect to each other, as well as their part-of-speech tags.", "labels": [], "entities": []}, {"text": "The lexical features are obtained by using the longest common sub-sequence ratio and edit distance measures to encode the surface similarity among words, and the double metaphone algorithm to represent the phonetic similarity.", "labels": [], "entities": []}, {"text": "Unlike most of the recent approaches that are based on generating normalization dictionaries , the proposed approach performs normalization by considering the context of the non-standard words in the input text.", "labels": [], "entities": []}, {"text": "Our results show that it achieves state-of-the-art F-score performance on standard datasets.", "labels": [], "entities": [{"text": "F-score", "start_pos": 51, "end_pos": 58, "type": "METRIC", "confidence": 0.9805325269699097}]}, {"text": "In addition, the system can be tuned to achieve very high precision without sacrificing much from recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 58, "end_pos": 67, "type": "METRIC", "confidence": 0.9982258677482605}, {"text": "recall", "start_pos": 98, "end_pos": 104, "type": "METRIC", "confidence": 0.9976972937583923}]}], "introductionContent": [{"text": "Social text, which has been growing and evolving steadily, has its own lexical and grammatical features (.", "labels": [], "entities": []}, {"text": "lol meaning laughing out loud, xoxo meaning kissing, 4u meaning for you are among the most commonly used examples of this jargon.", "labels": [], "entities": []}, {"text": "In addition, these informal expressions in social text usually take many different lexical forms when generated by different individuals.", "labels": [], "entities": []}, {"text": "The limited accuracies of the Speech-to-Text (STT) tools in mobile devices, which are increasingly being used to post messages on social media platforms, along with the scarcity of attention of the users result in additional divergence of social text from more standard text such as from the newswire domain.", "labels": [], "entities": []}, {"text": "Tools such as spellchecker and slang dictionaries have been shown to be insufficient to cope with this challenge longtime ago).", "labels": [], "entities": []}, {"text": "In addition, most Natural Language Processing (NLP) tools including named entity recognizers and dependency parsers generally perform poorly on social text (.", "labels": [], "entities": []}, {"text": "Text normalization is a preprocessing step to restore non-standard words in text to their original (canonical) forms to make use in NLP applications or more broadly to understand the digitized text better ().", "labels": [], "entities": [{"text": "Text normalization", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.6877775639295578}]}, {"text": "For example, talk 2 u later can be normalized as talk to you later or similarly enormoooos, enrmss and enourmos can be normalized as enormous.", "labels": [], "entities": []}, {"text": "Other examples of text messages from Twitter and their corresponding normalized forms are shown in.", "labels": [], "entities": []}, {"text": "The non-standard words in text are referred to as Out of Vocabulary (OOV) words.", "labels": [], "entities": []}, {"text": "The normalization task restores the OOV words to their In Vocabulary (IV) forms.", "labels": [], "entities": []}, {"text": "Social text is continuously evolving with new words and named entities that are not in the vocabularies of the systems).", "labels": [], "entities": []}, {"text": "Therefore, not every OOV word (e.g. iPhone, WikiLeaks or tok-Hav guts to say wat u desire..", "labels": [], "entities": []}, {"text": "Dnt beat behind da bush!!", "labels": [], "entities": []}, {"text": "And 1 mre thng no mre say yr people's man!!", "labels": [], "entities": []}, {"text": "Have guts to say what you desire..", "labels": [], "entities": []}, {"text": "Don't beat behind the bush!!", "labels": [], "entities": []}, {"text": "And one more thing no more say you are people's man!!", "labels": [], "entities": []}, {"text": "There r sm songs u don't want 2 listen 2 yl walking cos when u start dancing ppl won't knw y.", "labels": [], "entities": []}, {"text": "There are some songs you don't want to listen to while walking because when you start dancing people won't know why.", "labels": [], "entities": []}, {"text": "enizing) should be considered for normalization.", "labels": [], "entities": [{"text": "normalization", "start_pos": 34, "end_pos": 47, "type": "TASK", "confidence": 0.9650829434394836}]}, {"text": "The OOV tokens that should be considered for normalization are referred to as ill-formed words.", "labels": [], "entities": []}, {"text": "Ill-formed words can be normalized to different canonical words depending on the context of the text.", "labels": [], "entities": []}, {"text": "For example, let's consider the two examples in.", "labels": [], "entities": []}, {"text": "\"y\" is normalized as \"you\" in the first one and as \"why\" in the second one.", "labels": [], "entities": []}, {"text": "In this paper, we propose a graph-based text normalization method that utilizes both contextual and grammatical features of social text.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 40, "end_pos": 58, "type": "TASK", "confidence": 0.7292603254318237}]}, {"text": "The contextual information of words is modeled by a word association graph that is created from a large social media text corpus.", "labels": [], "entities": []}, {"text": "The graph represents the relative positions of the words in the social media text messages and their Part-of-Speech (POS) tags.", "labels": [], "entities": []}, {"text": "The lexical similarity features among the words are modeled using the longest common subsequence ratio and edit distance that encode the surface similarity and the double metaphone algorithm that encodes the phonetic similarity.", "labels": [], "entities": []}, {"text": "The proposed approach is unsupervised, which is an important advantage over supervised systems, given the continuously evolving language in the social media domain.", "labels": [], "entities": []}, {"text": "The same OOV word may have different appropriate normalizations depending on the context of the input text message.", "labels": [], "entities": []}, {"text": "Recently proposed dictionary-based text normalization systems perform dictionary look-up and always normalize the same OOV word to the same IV word regardless of the context of the input text ().", "labels": [], "entities": [{"text": "dictionary-based text normalization", "start_pos": 18, "end_pos": 53, "type": "TASK", "confidence": 0.5884228746096293}]}, {"text": "On the other hand, the proposed approach does not only make use of the general context information in a large corpus of social media text, but it also makes use of the context of the OOV word in the input text message.", "labels": [], "entities": []}, {"text": "Thus, an OOV word can be normalized to different IV words depending on the context of the input text.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the LexNorm1.1 (LN) dataset (Han and Baldwin, 2011) and Pennell and Liu (2014)'s trigram dataset to evaluate our proposed approach.", "labels": [], "entities": [{"text": "LexNorm1.1 (LN) dataset", "start_pos": 12, "end_pos": 35, "type": "DATASET", "confidence": 0.9025186896324158}]}, {"text": "LexNorm1.1 contains 549 tweets with 1184 manually annotated ill-formed OOV tokens.", "labels": [], "entities": [{"text": "LexNorm1.1", "start_pos": 0, "end_pos": 10, "type": "DATASET", "confidence": 0.9591757655143738}]}, {"text": "It has been used by recent text normalization studies for evaluation, which enables us to directly compare our performance results with results obtained by the recent previous work (.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.6681666970252991}]}, {"text": "The trigram dataset is an SMS-like corpus collected from twitter status updates sent via SMS.", "labels": [], "entities": [{"text": "trigram dataset", "start_pos": 4, "end_pos": 19, "type": "DATASET", "confidence": 0.6847218871116638}]}, {"text": "The dataset does not include the complete tweet text but trigrams from tweets and one OOV word in each trigram is annotated.", "labels": [], "entities": []}, {"text": "In total 4661 twitter status messages and 7769 tokens are annotated.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Sample POS tagger output", "labels": [], "entities": [{"text": "Sample POS tagger", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.7714165250460306}]}, {"text": " Table 5: Results obtained when ill-formed words  are assumed to have been pre-identified in ad- vance.", "labels": [], "entities": []}, {"text": " Table 6: Results obtained without assuming that  ill-formed words have been pre-identified.", "labels": [], "entities": []}, {"text": " Table 7: Comparison of results for different  threshold values on LexNorm1.1, the setup we  have used for our other experiments is shown in  bold.", "labels": [], "entities": [{"text": "LexNorm1.1", "start_pos": 67, "end_pos": 77, "type": "DATASET", "confidence": 0.9831089377403259}]}, {"text": " Table 8: Comparison of results for different  threshold values on trigram dataset, the setup we  have used for our other experiments is shown in  bold.", "labels": [], "entities": [{"text": "trigram dataset", "start_pos": 67, "end_pos": 82, "type": "DATASET", "confidence": 0.7710134088993073}]}]}