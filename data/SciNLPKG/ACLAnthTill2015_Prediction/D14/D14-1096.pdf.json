{"title": [{"text": "What Can We Get From 1000 Tokens? A Case Study of Multilingual POS Tagging For Resource-Poor Languages", "labels": [], "entities": [{"text": "Multilingual POS Tagging", "start_pos": 50, "end_pos": 74, "type": "TASK", "confidence": 0.6041392982006073}]}], "abstractContent": [{"text": "In this paper we address the problem of multilingual part-of-speech tagging for resource-poor languages.", "labels": [], "entities": [{"text": "multilingual part-of-speech tagging", "start_pos": 40, "end_pos": 75, "type": "TASK", "confidence": 0.6174741784731547}]}, {"text": "We use parallel data to transfer part-of-speech information from resource-rich to resource-poor languages.", "labels": [], "entities": []}, {"text": "Additionally, we use a small amount of annotated data to learn to \"correct\" errors from projected approach such as tagset mismatch between languages , achieving state-of-the-art performance (91.3%) across 8 languages.", "labels": [], "entities": []}, {"text": "Our approach is based on modest data requirements , and uses minimum divergence classification.", "labels": [], "entities": []}, {"text": "For situations where no universal tagset mapping is available, we propose an alternate method, resulting in state-of-the-art 85.6% accuracy on the resource-poor language Malagasy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9986288547515869}]}], "introductionContent": [{"text": "Part-of-speech (POS) tagging is a crucial task for natural language processing (NLP) tasks, providing basic information about syntax.", "labels": [], "entities": [{"text": "Part-of-speech (POS) tagging", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.5783861696720123}]}, {"text": "Supervised POS tagging has achieved great success, reaching as high as 95% accuracy for many languages).", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.8090299665927887}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9976843595504761}]}, {"text": "However, supervised techniques need manually annotated data, and this is either lacking or limited inmost resourcepoor languages.", "labels": [], "entities": []}, {"text": "Fully unsupervised POS tagging is not yet useful in practice due to low accuracy (.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 19, "end_pos": 30, "type": "TASK", "confidence": 0.806932657957077}, {"text": "accuracy", "start_pos": 72, "end_pos": 80, "type": "METRIC", "confidence": 0.9988435506820679}]}, {"text": "In this paper, we propose a semi-supervised method to narrow the gap between supervised and unsupervised approaches.", "labels": [], "entities": []}, {"text": "We demonstrate that even a small amount of supervised data leads to substantial improvement.", "labels": [], "entities": []}, {"text": "Our method is motivated by the availability of parallel data.", "labels": [], "entities": []}, {"text": "Thanks to the development of multilingual documents from government projects, book translations, multilingual websites, and so forth, parallel data between resource-rich and resource-poor languages is relatively easy to acquire.", "labels": [], "entities": []}, {"text": "This parallel data provides the bridge that permits us to transfer POS information from a resource-rich to a resource-poor language.", "labels": [], "entities": []}, {"text": "Systems that make use of cross-lingual tag projection typically face several issues, including mismatches between the tagsets used for the languages, artifacts from noisy alignments and cross-lingual syntactic divergence.", "labels": [], "entities": [{"text": "cross-lingual tag projection", "start_pos": 25, "end_pos": 53, "type": "TASK", "confidence": 0.6543482740720113}]}, {"text": "Our approach compensates for these issues by training on a small amount of annotated data on the target side, demonstrating that only 1k tokens of annotated data is sufficient to improve performance.", "labels": [], "entities": []}, {"text": "We first tag the resource-rich language using a supervised POS tagger.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 59, "end_pos": 69, "type": "TASK", "confidence": 0.6335841715335846}]}, {"text": "We then project POS tags from the resource-rich language to the resourcepoor language using parallel word alignments.", "labels": [], "entities": []}, {"text": "The projected labels are noisy, and so we use various heuristics to select only \"good\" training examples.", "labels": [], "entities": []}, {"text": "We train the model in two stages.", "labels": [], "entities": []}, {"text": "First, we build a maximum entropy classifier T on the (noisy) projected data.", "labels": [], "entities": []}, {"text": "Next, we train a supervised classifier P on a small amount of annotated data (1,000 tokens) in the target language, using a minimum divergence technique to incorporate the first model, T . Compared with the state of the art, we make more-realistic assumptions (e.g. relying on a tiny amount of annotated data rather than a huge crowd-sourced dictionary) and useless parallel data, yet achieve a better overall result.", "labels": [], "entities": []}, {"text": "We achieved 91.3% average accuracy over 8 languages, exceeding's result of 88.8%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9512766599655151}]}, {"text": "The test data we employ makes use of mappings from language-specific POS tag inventories to a universal tagset (.", "labels": [], "entities": []}, {"text": "However, such a mapping might not be available for resource-poor languages.", "labels": [], "entities": []}, {"text": "Therefore, we also pro-pose a variant of our method which removes the need for identical tagsets between the projection model T and the correction model P , based on a two-output maximum entropy model over tag pairs.", "labels": [], "entities": []}, {"text": "Evaluating on the resource-poor language Malagasy, we achieved 85.6% accuracy, exceeding the state-of-the-art of 81.2% ( ).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9990788698196411}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Previously published token-level POS tagging accuracy for various models across 8 languages  -Danish (da), Dutch (nl), German (de), Greek (el), Italian (it), Portuguese (pt), Spanish (es), Swedish  (sv) -evaluated on CoNLL data (Buchholz", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 43, "end_pos": 54, "type": "TASK", "confidence": 0.7145216464996338}, {"text": "accuracy", "start_pos": 55, "end_pos": 63, "type": "METRIC", "confidence": 0.8126868605613708}, {"text": "CoNLL data", "start_pos": 227, "end_pos": 237, "type": "DATASET", "confidence": 0.9501190781593323}, {"text": "Buchholz", "start_pos": 239, "end_pos": 247, "type": "DATASET", "confidence": 0.5077886581420898}]}, {"text": " Table 2: The size of annotated data from  CoNLL (Buchholz and Marsi, 2006), and the  number of tags included and missing for 8 lan- guages.", "labels": [], "entities": [{"text": "CoNLL", "start_pos": 43, "end_pos": 48, "type": "DATASET", "confidence": 0.8634518980979919}]}, {"text": " Table 3: The coverage, and POS tagging accuracy with and without tagset mapping of directly projected  labels, averaged over 8 languages for different data sizes", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 28, "end_pos": 39, "type": "TASK", "confidence": 0.6654523015022278}, {"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.919203519821167}]}, {"text": " Table 5: The accuracy of Directed Project Model (DPM) with different feature sets, removing one feature  set at a time", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9996293783187866}]}, {"text": " Table 6: The comparison of our Directly Projected Model, Supervised Model, Correction Model and the  state-of-the-art system", "labels": [], "entities": []}, {"text": " Table 7: The performance of different models for  Malagasy.", "labels": [], "entities": []}]}