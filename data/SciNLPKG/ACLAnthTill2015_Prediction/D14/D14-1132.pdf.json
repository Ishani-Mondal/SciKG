{"title": [{"text": "Large-scale Expected BLEU Training of Phrase-based Reordering Models", "labels": [], "entities": [{"text": "BLEU", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.9422188997268677}, {"text": "Phrase-based Reordering", "start_pos": 38, "end_pos": 61, "type": "TASK", "confidence": 0.7284964323043823}]}], "abstractContent": [{"text": "Recent work by Cherry (2013) has shown that directly optimizing phrase-based reordering models towards BLEU can lead to significant gains.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 103, "end_pos": 107, "type": "METRIC", "confidence": 0.8701923489570618}]}, {"text": "Their approach is limited to small training sets of a few thousand sentences and a similar number of sparse features.", "labels": [], "entities": []}, {"text": "We show how the expected BLEU objective allows us to train a simple linear discriminative reordering model with millions of sparse features on hundreds of thousands of sentences resulting in significant improvements.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.9964776635169983}]}, {"text": "A comparison to likelihood training demonstrates that expected BLEU is vastly more effective.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 63, "end_pos": 67, "type": "METRIC", "confidence": 0.9989494681358337}]}, {"text": "Our best results improve a hierarchical lexicalized reordering baseline by up to 2.0 BLEU in a single-reference setting on a French-English WMT 2012 setup.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 85, "end_pos": 89, "type": "METRIC", "confidence": 0.9988861680030823}, {"text": "French-English WMT 2012 setup", "start_pos": 125, "end_pos": 154, "type": "DATASET", "confidence": 0.7808139473199844}]}], "introductionContent": [{"text": "Modeling reordering for phrase-based machine translation has been along standing problem.", "labels": [], "entities": [{"text": "Modeling reordering", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.925013542175293}, {"text": "phrase-based machine translation", "start_pos": 24, "end_pos": 56, "type": "TASK", "confidence": 0.6972542206446329}]}, {"text": "Contrary to synchronous context free grammarbased translation models, phrasebased models () have no in-built notion of reordering beyond what is captured in a single phrase pair, and the first phrase-based decoders simply scored interphrase reorderings using a restricted linear distortion feature, which scores a phrase reordering proportionally to the length of its displacement.", "labels": [], "entities": []}, {"text": "While phrase-based models allow in theory completely unrestricted reordering patterns, movements are generally limited to a finite distance for complexity reasons.", "labels": [], "entities": []}, {"text": "To address this limitation, extensive prior work focused on richer feature sets, in particular on lexicalized reordering models trained with maximum likelihood-based approaches;.", "labels": [], "entities": []}, {"text": "More recently, Cherry (2013) proposed a very effective sparse ordering model relying on a set of only a few thousand indicator features which are trained towards a task-specific metric such as BLEU ().", "labels": [], "entities": [{"text": "BLEU", "start_pos": 193, "end_pos": 197, "type": "METRIC", "confidence": 0.998480498790741}]}, {"text": "These features are simply added to the log-linear framework of translation that is trained with the Margin Infused Relaxed Algorithm (MIRA;) on a small development set of a few thousand sentences.", "labels": [], "entities": []}, {"text": "While simple, the approach outperforms the state-of-the-art hierarchical reordering model of, a maximum likelihood-based model trained on millions of sentences to fit millions of parameters.", "labels": [], "entities": []}, {"text": "Ideally, we would like to scale sparse reordering models to similar dimensions but recent attempts to increase the amount of training data for MIRA was met with little success.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 143, "end_pos": 147, "type": "TASK", "confidence": 0.9172171950340271}]}, {"text": "In this paper we propose much larger sparse ordering models that combine the scalability of likelihood-based approaches with the higher accuracy of maximum BLEU training ( \u00a73).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.9994176626205444}, {"text": "BLEU", "start_pos": 156, "end_pos": 160, "type": "METRIC", "confidence": 0.9982313513755798}]}, {"text": "We train on the output of a hierarchical reordering model-based system and scale to millions of features learned on hundreds of thousands of sentences ( \u00a74).", "labels": [], "entities": []}, {"text": "Specifically, we use the expected BLEU objective function () which allows us to train models that use training data and feature sets that are two to three orders of magnitudes larger than in previous work ( \u00a75).", "labels": [], "entities": [{"text": "BLEU objective function", "start_pos": 34, "end_pos": 57, "type": "METRIC", "confidence": 0.9560950994491577}]}, {"text": "Our models significantly outperform the state-of-the-art hierarchical lexicalized reordering model on two language pairs and we demonstrate that richer feature sets result in significantly higher accuracy than with a feature set similar to.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 196, "end_pos": 204, "type": "METRIC", "confidence": 0.9960072636604309}]}, {"text": "We also demonstrate that our approach greatly benefits from more training data than is typically used for maximum BLEU training.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 114, "end_pos": 118, "type": "METRIC", "confidence": 0.9889886975288391}]}, {"text": "Previous work concluded that sparse reordering models perform better than maximum entropy models, however, the two approaches do not only differ in the objective function but also the type of training data.", "labels": [], "entities": []}, {"text": "Our analysis isolates the objective function and shows that expected BLEU optimization is the most important factor to train accurate ordering models.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 69, "end_pos": 73, "type": "METRIC", "confidence": 0.9970133304595947}]}, {"text": "Finally, we compare expected BLEU training to pair-wise ranked optimization (PRO) on a feature set similar to Cherry (2013; \u00a77).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 29, "end_pos": 33, "type": "METRIC", "confidence": 0.9885348677635193}, {"text": "pair-wise ranked optimization (PRO)", "start_pos": 46, "end_pos": 81, "type": "TASK", "confidence": 0.6782243897517523}]}], "datasetContent": [{"text": "We experiment with a phrase-based system similar to Moses (, scoring translations by a set of common features including maximum likelihood estimates of source given target phrases p M LE (e|f ) and vice versa, p M LE (f |e), lexically weighted estimates p LW (e|f ) and p LW (f |e), word and phrasepenalties, as well as a linear distortion feature.", "labels": [], "entities": []}, {"text": "The baseline uses a hierarchical reordering model with five orientation types, including monotone and swap, described in \u00a72, as well as two discontinuous orientations, distinguishing if the previous phrase is to the left or right of the current phrase.", "labels": [], "entities": []}, {"text": "Finally, monotone global indicates that all previous phrases can be combined into a single hierarchical block.", "labels": [], "entities": []}, {"text": "The baseline includes a modified Kneser-Ney word-based language model trained on the target-side of the parallel data, which is described below.", "labels": [], "entities": []}, {"text": "Log-linear weights are estimated with MERT.", "labels": [], "entities": [{"text": "MERT", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9164575338363647}]}, {"text": "We regard the 1-best output of the phrase-based decoder with the hierarchical reordering model as the baseline accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 111, "end_pos": 119, "type": "METRIC", "confidence": 0.9834407567977905}]}, {"text": "We use training and test data from the WMT 2012 campaign and report results on French-English and German-English translation).", "labels": [], "entities": [{"text": "WMT 2012 campaign", "start_pos": 39, "end_pos": 56, "type": "DATASET", "confidence": 0.718086858590444}]}, {"text": "Translation models are estimated on 102M words of parallel data for French-English and 91M words for GermanEnglish; between 7.5-8.2M words are newswire, depending on the language pair, and the remainder are parliamentary proceedings.", "labels": [], "entities": [{"text": "Translation", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.946817934513092}]}, {"text": "All discriminative reordering models are trained on the newswire subset since we found this portion of the data to be most useful in initial experiments.", "labels": [], "entities": [{"text": "newswire subset", "start_pos": 56, "end_pos": 71, "type": "DATASET", "confidence": 0.9122001230716705}]}, {"text": "We evaluate on six newswire domain test sets from 2008, 2010 to 2013 as well as the 2010 system combination test set containing between 2034 to 3003 sentences.", "labels": [], "entities": [{"text": "newswire domain test sets", "start_pos": 19, "end_pos": 44, "type": "DATASET", "confidence": 0.8139435797929764}, {"text": "2010 system combination test set", "start_pos": 84, "end_pos": 116, "type": "DATASET", "confidence": 0.6802954196929931}]}, {"text": "Log-linear weights are estimated on the 2009 data set comprising 2525 sentences.", "labels": [], "entities": [{"text": "2009 data set", "start_pos": 40, "end_pos": 53, "type": "DATASET", "confidence": 0.8674470782279968}]}, {"text": "We evaluate using BLEU with a single reference.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 18, "end_pos": 22, "type": "METRIC", "confidence": 0.998044490814209}]}, {"text": "We use 100-best lists generated by the phrase-based decoder to train the discriminative reordering model.", "labels": [], "entities": []}, {"text": "The n-best lists are generated by ten systems, each trained on 90% of the available data in order to decode the remaining 10%.", "labels": [], "entities": []}, {"text": "The purpose of this procedure is to avoid a bias introduced by generating n-best lists for sentences on which the translation model was previously trained.", "labels": [], "entities": []}, {"text": "mentioned, we train our reordering model on the news portion of the parallel data, corresponding to 136K-150K sentences, depending on the language pair.", "labels": [], "entities": []}, {"text": "We tuned the various hyper-parameters on a held-out set, including the learning rate, for which we found a simple setting of 0.1 to be useful.", "labels": [], "entities": [{"text": "learning rate", "start_pos": 71, "end_pos": 84, "type": "METRIC", "confidence": 0.9311690032482147}]}, {"text": "To prevent overfitting, we experimented with 2 regularization, but found that it did not improve test accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 102, "end_pos": 110, "type": "METRIC", "confidence": 0.9933128952980042}]}, {"text": "We also tuned the probability scaling parameter \u03b3 (Eq.", "labels": [], "entities": []}, {"text": "6) but found \u03b3 = 1 to be very good among other settings.", "labels": [], "entities": []}, {"text": "We evaluate the performance on a held-out validation set during training and stop whenever the objective changes less than a factor of 0.0003.", "labels": [], "entities": []}, {"text": "For our PRO experiments, we tuned three hyper-parameters controlling 2 regularization, sentence-level BLEU smoothing, and length.", "labels": [], "entities": [{"text": "PRO", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9448423385620117}, {"text": "BLEU", "start_pos": 102, "end_pos": 106, "type": "METRIC", "confidence": 0.9739531874656677}]}, {"text": "The latter is important to eliminate PRO's tendency to produce too short translations (Nakov et al., 2012).", "labels": [], "entities": [{"text": "PRO", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.8969058394432068}]}], "tableCaptions": [{"text": " Table 1: French-English results of expected BLEU trained sparse reordering models compared to no  reordering model at all (noRM) and the likelihood trained baseline hierarchical reordering model (HRM)  on WMT test sets; sc2010 is the 2010 system combination test set. FeatTypes is the number of different  types and AllTest is the average BLEU score over all the test sets, weighted by corpus size. All results  for our sparse reordering models include a likelihood-trained hierarchical reordering model.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.9350878000259399}, {"text": "WMT test sets", "start_pos": 206, "end_pos": 219, "type": "DATASET", "confidence": 0.8640386660893759}, {"text": "2010 system combination test set", "start_pos": 235, "end_pos": 267, "type": "DATASET", "confidence": 0.7044923901557922}, {"text": "AllTest", "start_pos": 317, "end_pos": 324, "type": "METRIC", "confidence": 0.968887448310852}, {"text": "BLEU", "start_pos": 340, "end_pos": 344, "type": "METRIC", "confidence": 0.9928874373435974}]}, {"text": " Table 2: German-English results of expected BLEU trained sparse reordering models (cf. Table 1).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 45, "end_pos": 49, "type": "METRIC", "confidence": 0.9481533765792847}]}, {"text": " Table 3: French-English results comparing the baseline hierarchical reordering model (HRM) to sparse  reordering model trained towards conditional log-likelihood (CLL) and expected BLEU (xBLEU).", "labels": [], "entities": [{"text": "BLEU (xBLEU)", "start_pos": 182, "end_pos": 194, "type": "METRIC", "confidence": 0.892384722828865}]}, {"text": " Table 4: French-English results on the SparseHRMLocal feature set when when trained with pair-wise  ranked optimization (PRO) and expected BLEU (xBLEU).", "labels": [], "entities": [{"text": "SparseHRMLocal feature set", "start_pos": 40, "end_pos": 66, "type": "DATASET", "confidence": 0.8365800182024637}, {"text": "pair-wise  ranked optimization (PRO)", "start_pos": 90, "end_pos": 126, "type": "METRIC", "confidence": 0.700966035326322}, {"text": "BLEU (xBLEU)", "start_pos": 140, "end_pos": 152, "type": "METRIC", "confidence": 0.8926435858011246}]}]}