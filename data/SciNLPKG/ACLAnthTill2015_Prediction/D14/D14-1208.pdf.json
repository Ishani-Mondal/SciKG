{"title": [{"text": "Noisy Or-based model for Relation Extraction using Distant Supervision", "labels": [], "entities": [{"text": "Relation Extraction", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.9903405606746674}]}], "abstractContent": [{"text": "Distant supervision, a paradigm of relation extraction where training data is created by aligning facts in a database with a large unannotated corpus, is an attractive approach for training relation extractors.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 35, "end_pos": 54, "type": "TASK", "confidence": 0.8845801651477814}, {"text": "training relation extractors", "start_pos": 181, "end_pos": 209, "type": "TASK", "confidence": 0.6114555100599924}]}, {"text": "Various models are proposed in recent literature to align the facts in the database to their mentions in the corpus.", "labels": [], "entities": []}, {"text": "In this paper, we discuss and critically analyse a popular alignment strategy called the \"at least one\" heuristic.", "labels": [], "entities": []}, {"text": "We provide a simple , yet effective relaxation to this strategy.", "labels": [], "entities": []}, {"text": "We formulate the inference procedures in training as integer linear programming (ILP) problems and implement the relaxation to the \"at least one \" heuris-tic via a soft constraint in this formulation.", "labels": [], "entities": []}, {"text": "Empirically, we demonstrate that this simple strategy leads to a better performance under certain settings over the existing approaches .", "labels": [], "entities": []}], "introductionContent": [{"text": "Although supervised approaches to relation extraction () achieve very high accuracies, they do not scale as they are data intensive and the cost of creating annotated data is quite high.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.9491741359233856}]}, {"text": "To alleviate this problem, proposed relation extraction in the paradigm of distant supervision.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 36, "end_pos": 55, "type": "TASK", "confidence": 0.8892256617546082}]}, {"text": "In this approach, given a database of facts (e.g. Freebase ) and an unannotated document collection, the goal is to heuristically align the facts in the database to the sentences in the corpus which contain the entities mentioned in the fact.", "labels": [], "entities": []}, {"text": "This is done to create weakly labeled training data to train a classifier for relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.8430623114109039}]}, {"text": "The underlying assumption is that all mentions of 1 www.freebase.com an entity pair 2 (i.e. sentences containing the entity pair) in the corpus express the same relation as stated in the database.", "labels": [], "entities": []}, {"text": "The above assumption is a weak one and is often violated in natural language text.", "labels": [], "entities": []}, {"text": "For instance, the entity pair, participate in more than one relation: citizenOf, presidentOf, bornIn and every mention expresses either one of these fixed set of relations or none of them.", "labels": [], "entities": []}, {"text": "Consequently, a number of models have been proposed in literature to provide better heuristics for the mapping between the entity pair in the database and its mentions in the sentences of the corpus.", "labels": [], "entities": []}, {"text": "tightens the assumption of distant supervision in the following manner: \"Given a pair of entities and their mentions in sentences from a corpus, at least one of the mentions express the relation given in the database\".", "labels": [], "entities": []}, {"text": "In other words, it models the problem as that of multi-instance (mentions) single-label (relation) learning.", "labels": [], "entities": []}, {"text": "Following this, and propose models that consider the mapping as that of multi-instance multi-label learning.", "labels": [], "entities": []}, {"text": "The instances are the mentions of the entity pair in the sentences of the corpus and the entity pair can participate in more than one relation.", "labels": [], "entities": []}, {"text": "Although, these models work very well in practice, they have a number of shortcomings.", "labels": [], "entities": []}, {"text": "One of them is the possibility that during the alignment, a fact in the database might not have an instantiation in the corpus.", "labels": [], "entities": []}, {"text": "For instance, if our corpus only contains documents from the years 2000 to 2005, the fact presidentOf(Barack Obama, United States) will not be present in the corpus.", "labels": [], "entities": []}, {"text": "In such cases, the distant supervision assumption fails to provide a mapping for the fact in the corpus.", "labels": [], "entities": []}, {"text": "In this paper, we address this situation with a noisy-or model) in training the relation extractor by relaxing the \"at least one\" assumption discussed above.", "labels": [], "entities": [{"text": "relation extractor", "start_pos": 80, "end_pos": 98, "type": "TASK", "confidence": 0.7537398338317871}]}, {"text": "Our contributions in this paper are as follows: (i) We formulate the inference procedures in the training algorithm as integer linear programming (ILP) problems, (ii) We introduce a soft-constraint in the ILP objective to model noisy-or in training, and (iii) Empirically, our algorithm performs better than procedure under certain settings on two benchmark datasets.", "labels": [], "entities": []}, {"text": "Our paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we discuss our methodology.", "labels": [], "entities": []}, {"text": "We review the approach of and explain our modifications to it.", "labels": [], "entities": []}, {"text": "In Section 3, we discuss related work.", "labels": [], "entities": []}, {"text": "In Section 4, we discuss the experimental setup and our preliminary results.", "labels": [], "entities": []}, {"text": "We conclude in Section 4.", "labels": [], "entities": []}], "datasetContent": [{"text": "The experimental runs were carried out using the publicly available Stanford's distantly supervised slot-filling system  We report results on two standard datasets used as benchmarks by the community namely KBP and Riedel datasets.", "labels": [], "entities": [{"text": "KBP", "start_pos": 207, "end_pos": 210, "type": "DATASET", "confidence": 0.8899989128112793}, {"text": "Riedel datasets", "start_pos": 215, "end_pos": 230, "type": "DATASET", "confidence": 0.668994590640068}]}, {"text": "A complete description of these datasets is provided in.", "labels": [], "entities": []}, {"text": "The evaluation setup and module is the same as that described in.", "labels": [], "entities": []}, {"text": "We also use the same set of features used by the various systems in the package to ensure that the approaches are comparable.", "labels": [], "entities": []}, {"text": "As in previous work, we report precision/recall (P/R) graphs to evaluate the various techniques.", "labels": [], "entities": [{"text": "precision/recall (P/R) graphs", "start_pos": 31, "end_pos": 60, "type": "METRIC", "confidence": 0.8643704586558871}]}, {"text": "We used the publicly available lp solve package to solve our inference problems.", "labels": [], "entities": []}], "tableCaptions": []}