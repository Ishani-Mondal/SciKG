{"title": [{"text": "Why are You Taking this Stance? Identifying and Classifying Reasons in Ideological Debates", "labels": [], "entities": [{"text": "Identifying and Classifying Reasons in Ideological Debates", "start_pos": 32, "end_pos": 90, "type": "TASK", "confidence": 0.8161258527210781}]}], "abstractContent": [{"text": "Recent years have seen a surge of interest instance classification in online debates.", "labels": [], "entities": []}, {"text": "Oftentimes, however, it is important to determine not only the stance expressed by an author in her debate posts, but also the reasons behind her supporting or opposing the issue under debate.", "labels": [], "entities": []}, {"text": "We therefore examine the new task of reason classification in this paper.", "labels": [], "entities": [{"text": "reason classification", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.8148609399795532}]}, {"text": "Given the close interplay between stance classification and reason classification, we design computational models for examining how automatically computed stance information can be profitably exploited for reason classification.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 34, "end_pos": 55, "type": "TASK", "confidence": 0.8937201797962189}, {"text": "reason classification", "start_pos": 60, "end_pos": 81, "type": "TASK", "confidence": 0.7715165913105011}, {"text": "reason classification", "start_pos": 206, "end_pos": 227, "type": "TASK", "confidence": 0.7475242614746094}]}, {"text": "Experiments on our reason-annotated corpus of ideological debate posts from four domains demonstrate that sophisticated models of stances and reasons can indeed yield more accurate reason and stance classification results than their simpler counterparts.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 192, "end_pos": 213, "type": "TASK", "confidence": 0.6985675543546677}]}], "introductionContent": [{"text": "In recent years, researchers have begun exploring new opinion mining tasks.", "labels": [], "entities": [{"text": "opinion mining tasks", "start_pos": 54, "end_pos": 74, "type": "TASK", "confidence": 0.8648951450983683}]}, {"text": "One such task is debate stance classification (SC): given a post written fora two-sided topic discussed in an online debate forum, determine which of the two sides (i.e., for or against) its author is taking (;).", "labels": [], "entities": [{"text": "debate stance classification (SC)", "start_pos": 17, "end_pos": 50, "type": "TASK", "confidence": 0.9023463726043701}]}, {"text": "For example, the author of the post shown in is pro-abortion.", "labels": [], "entities": []}, {"text": "Oftentimes, however, it is important to determine not only the author's stance expressed in her debate posts, but also the reasons why she supports or opposes the issue under debate.", "labels": [], "entities": []}, {"text": "Intuitively, given a debate topic such as \"Should abortion be banned?\" or \"Do you support Obamacare?\", it [I feel that abortion should remain legal, or rather, parents should have the power to make the decision themselves and not face any legal hindrance of any form.]", "labels": [], "entities": []}, {"text": "1 Let us take a look from the social perspective.", "labels": [], "entities": []}, {"text": "[If parents cannot afford to provide for the child, or if the family is facing financial constraints, it is understandable that abortion can remain as one of the options.]", "labels": [], "entities": []}, {"text": "2 Reason 1: Woman's right to abort Reason 2: Unwanted babies are threat to their parents' future should not be difficult for us to come up with a set of reasons people typically use to backup their stances.", "labels": [], "entities": []}, {"text": "Given a set of reasons associated with each stance in an online debate, the goal of postlevel reason classification is to identify those reason(s) an author uses to backup her stance in her debate post.", "labels": [], "entities": [{"text": "postlevel reason classification", "start_pos": 84, "end_pos": 115, "type": "TASK", "confidence": 0.6215233306090037}]}, {"text": "A more challenging version of this task is sentence-level reason classification, where the goal is to identify not only the reason(s) an author uses in her post, but also the sentence(s) in the post that the author uses to describe each of her reasons.", "labels": [], "entities": [{"text": "sentence-level reason classification", "start_pos": 43, "end_pos": 79, "type": "TASK", "confidence": 0.6727064847946167}]}, {"text": "For example, the author of the post shown in mentions two reasons why she supports abortion, namely it's a woman's right to abort and unwanted babies are threat to their parents' future, which are mentioned in the first and third sentences in the post respectively.", "labels": [], "entities": []}, {"text": "Our goal in this paper is to examine post-and sentence-level reason classification (RC) in ideological debates.", "labels": [], "entities": [{"text": "sentence-level reason classification (RC)", "start_pos": 46, "end_pos": 87, "type": "TASK", "confidence": 0.7832223375638326}]}, {"text": "Many online debaters use emotional languages, which may involve sarcasm and insults, to express their points, thereby making RC and SC in ideological debates potentially more challenging than that in other debate settings such as congressional debates and company-internal discussions (.", "labels": [], "entities": []}, {"text": "Besides examining the new task of RC in ideological debates, we believe that our work makes three contributions.", "labels": [], "entities": []}, {"text": "First, we propose to address post-level RC by means of sentence-level RC by (1) determining the reason(s) associated with each of its sentences (if any), and then (2) taking the union of the set of reasons associated with all of its sentences to be the set of reasons associated with the post.", "labels": [], "entities": []}, {"text": "We hypothesize that this sentence-based approach, which exploits a training set in which each sentence in a post is labeled with its reason, would achieve better performance than a multilabel text classification approach to post-level RC, which learns to determine the subset of reasons a post contains directly from a training set in which each post is labeled with the corresponding set of reasons.", "labels": [], "entities": []}, {"text": "In other words, we hypothesize that we could achieve better results for post-level RC by learning from sentence-level than from post-level reason annotations, as sentence-level reason annotations can enable a learning algorithm to accurately attribute an annotated reason to a particular portion of a post.", "labels": [], "entities": [{"text": "post-level RC", "start_pos": 72, "end_pos": 85, "type": "TASK", "confidence": 0.6743147075176239}]}, {"text": "Second, we propose stance-supported RC systems, hypothesizing that automatically computed stance information can be profitably exploited for RC.", "labels": [], "entities": []}, {"text": "Since we are exploiting automatically computed (and thus potentially noisy) stance information, we hypothesize that the effectiveness of such information would depend in part on the way it is exploited in RC systems.", "labels": [], "entities": []}, {"text": "As a result, we introduce a set of stance-supported models for RC, starting with simple pipeline models and then moving onto joint models with increasing sophistication.", "labels": [], "entities": []}, {"text": "Note that exploiting stance information by no means guarantees that RC performance will improve, as an incorrect determination of stance could lead to an incorrect identification of reasons.", "labels": [], "entities": []}, {"text": "Hence, one of our goals is to examine how to model stances and reasons so that RC can benefit from stance information.", "labels": [], "entities": []}, {"text": "Finally, since progress on RC is hindered in part by the lack of an annotated corpus, we make our reason-annotated dataset publicly available.", "labels": [], "entities": [{"text": "RC", "start_pos": 27, "end_pos": 29, "type": "TASK", "confidence": 0.9679594039916992}]}, {"text": "1 To our knowledge, this will be the first publicly available corpus for sentence-and post-level RC.", "labels": [], "entities": [{"text": "sentence-and post-level RC", "start_pos": 73, "end_pos": 99, "type": "TASK", "confidence": 0.5972815752029419}]}], "datasetContent": [{"text": "While our primary goal is to evaluate the RC systems introduced in the previous section, we are also interested in whether SC performance can improve when SC is jointly modeled with RC.", "labels": [], "entities": []}, {"text": "More specifically, our evaluation is driven by the following question: will RC performance and SC performance improve as: SC accuracies and RC F-scores for our five-fold cross-validation experiments.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 143, "end_pos": 151, "type": "METRIC", "confidence": 0.5593246817588806}]}, {"text": "We express SC results in terms of accuracy (i.e., the percentage of test posts labeled with the correct stance) and RC results in terms of F-score micro-averaged overall reason classes except the NONE class.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9989596605300903}, {"text": "RC", "start_pos": 116, "end_pos": 118, "type": "METRIC", "confidence": 0.9915363788604736}, {"text": "F-score", "start_pos": 139, "end_pos": 146, "type": "METRIC", "confidence": 0.9752399325370789}, {"text": "NONE class", "start_pos": 196, "end_pos": 206, "type": "DATASET", "confidence": 0.6858453452587128}]}, {"text": "For each RC system, we report its sentence-level RC score and post-level RC score, which are computed over sentences and posts respectively.", "labels": [], "entities": [{"text": "sentence-level RC score", "start_pos": 34, "end_pos": 57, "type": "METRIC", "confidence": 0.7604678471883138}, {"text": "post-level RC score", "start_pos": 62, "end_pos": 81, "type": "METRIC", "confidence": 0.8765296339988708}]}, {"text": "As mentioned at the end of Section 3, the set of post-level reason labels of a given post is automatically obtained by taking the union of the set of reason labels assigned to each of its sentences.", "labels": [], "entities": []}, {"text": "Hence, a reason classifier will be rewarded as long as it can predict, for any sentence in a test post, a reason label that the annotators assigned to some sentence in the same post.", "labels": [], "entities": []}, {"text": "We obtain these scores via five-fold crossvalidation experiments.", "labels": [], "entities": []}, {"text": "During fold partition, all posts that are in the same post sequence are assigned to the same fold.", "labels": [], "entities": [{"text": "fold partition", "start_pos": 7, "end_pos": 21, "type": "TASK", "confidence": 0.7301324605941772}]}, {"text": "All reason and stance classifiers are domain-specific, meaning that each of them is trained on sentences/posts from exactly one domain and is applied to classify sentences/posts from the same domain.", "labels": [], "entities": []}, {"text": "We use the Stanford maximum entropy classifier 4 for classification and solve ILP programs using lpsolve 5 .", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Reason classes and their percentages in the corresponding stance for each domain.", "labels": [], "entities": []}, {"text": " Table 2: Stance and reason annotation statistics.", "labels": [], "entities": [{"text": "Stance and reason annotation", "start_pos": 10, "end_pos": 38, "type": "TASK", "confidence": 0.7111289277672768}]}, {"text": " Table 3: SC accuracies and RC F-scores for our five-fold cross-validation experiments.", "labels": [], "entities": [{"text": "SC accuracies", "start_pos": 10, "end_pos": 23, "type": "METRIC", "confidence": 0.5478409975767136}, {"text": "RC F-scores", "start_pos": 28, "end_pos": 39, "type": "METRIC", "confidence": 0.7536554336547852}]}, {"text": " Table 4: Post-level RC F-scores obtained via the  multi-class text classification approach.", "labels": [], "entities": [{"text": "Post-level RC F-scores", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.7152717709541321}, {"text": "multi-class text classification", "start_pos": 51, "end_pos": 82, "type": "TASK", "confidence": 0.6109247803688049}]}]}