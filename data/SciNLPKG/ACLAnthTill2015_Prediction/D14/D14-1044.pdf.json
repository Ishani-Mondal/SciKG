{"title": [{"text": "Incorporating Vector Space Similarity in Random Walk Inference over Knowledge Bases", "labels": [], "entities": [{"text": "Incorporating Vector Space Similarity", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.6468389183282852}]}], "abstractContent": [{"text": "Much work in recent years has gone into the construction of large knowledge bases (KBs), such as Freebase, DBPedia, NELL, and YAGO.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 97, "end_pos": 105, "type": "DATASET", "confidence": 0.9621676802635193}, {"text": "DBPedia", "start_pos": 107, "end_pos": 114, "type": "DATASET", "confidence": 0.8301128149032593}, {"text": "YAGO", "start_pos": 126, "end_pos": 130, "type": "DATASET", "confidence": 0.872118353843689}]}, {"text": "While these KBs are very large, they are still very incomplete, necessitating the use of inference to fill in gaps.", "labels": [], "entities": []}, {"text": "Prior work has shown how to make use of a large text corpus to augment random walk inference over KBs.", "labels": [], "entities": []}, {"text": "We present two improvements to the use of such large corpora to augment KB inference.", "labels": [], "entities": [{"text": "KB inference", "start_pos": 72, "end_pos": 84, "type": "TASK", "confidence": 0.7650396227836609}]}, {"text": "First, we present anew technique for combining KB relations and surface text into a single graph representation that is much more compact than graphs used in prior work.", "labels": [], "entities": []}, {"text": "Second, we describe how to incorporate vector space similarity into random walk inference over KBs, reducing the feature sparsity inherent in using surface text.", "labels": [], "entities": []}, {"text": "This allows us to combine distributional similarity with symbolic logical inference in novel and effective ways.", "labels": [], "entities": []}, {"text": "With experiments on many relations from two separate KBs, we show that our methods significantly outperform prior work on KB inference, both in the size of problem our methods can handle and in the quality of predictions made.", "labels": [], "entities": []}], "introductionContent": [{"text": "Much work in recent years has gone into the construction of large knowledge bases, either by collecting contributions from many users, as with Freebase () and, or automatically from web text or other resources, as done by NELL ( and.", "labels": [], "entities": [{"text": "Freebase", "start_pos": 143, "end_pos": 151, "type": "DATASET", "confidence": 0.939307451248169}, {"text": "NELL", "start_pos": 222, "end_pos": 226, "type": "DATASET", "confidence": 0.8482916951179504}]}, {"text": "These knowledge bases contain millions of real-world entities and relationships between them.", "labels": [], "entities": []}, {"text": "However, even though they are very large, they are still very incomplete, missing large fractions of possible relationships between common entities.", "labels": [], "entities": []}, {"text": "Thus the task of inference over these knowledge bases, predicting new relationships simply by examining the knowledge base itself, has become increasingly important.", "labels": [], "entities": []}, {"text": "A promising technique for inferring new relation instances in a knowledge base is random walk inference, first proposed by.", "labels": [], "entities": []}, {"text": "In this method, called the Path Ranking Algorithm (PRA), the knowledge base is encoded as a graph, and random walks are used to find paths that connect the source and target nodes of relation instances.", "labels": [], "entities": []}, {"text": "These paths are used as features in a logistic regression classifier that predicts new instances of the given relation.", "labels": [], "entities": []}, {"text": "Each path can be viewed as a horn clause using knowledge base relations as predicates, and so PRA can bethought of as a kind of discriminatively trained logical inference.", "labels": [], "entities": []}, {"text": "One major deficiency of random walk inference is the connectivity of the knowledge base graphif there is no path connecting two nodes in the graph, PRA cannot predict any relation instance between them.", "labels": [], "entities": []}, {"text": "Thus prior work has introduced the use of a text corpus to increase the connectivity of the graph used as input to PRA (.", "labels": [], "entities": []}, {"text": "This approach is not without its own problems, however.", "labels": [], "entities": []}, {"text": "Whereas knowledge base relations are semantically coherent and different relations have distinct meanings, this is not true of surface text.", "labels": [], "entities": []}, {"text": "For example, \"The Nile flows through Cairo\" and \"The Nile runs through Cairo\" have very similar if not identical meaning.", "labels": [], "entities": []}, {"text": "Adding a text corpus to the inference graph increases connectivity, but it also dramatically increases feature sparsity.", "labels": [], "entities": []}, {"text": "We introduce two new techniques for making better use of a text corpus for knowledge base inference.", "labels": [], "entities": [{"text": "knowledge base inference", "start_pos": 75, "end_pos": 99, "type": "TASK", "confidence": 0.6154665847619375}]}, {"text": "First, we describe anew way of incorporating the text corpus into the knowledge base graph that enables much more efficient processing than prior techniques, allowing us to approach problems that prior work could not feasibly solve.", "labels": [], "entities": []}, {"text": "Second, we introduce the use of vector space similarity in random walk inference in order to reduce the sparsity of surface forms.", "labels": [], "entities": [{"text": "random walk inference", "start_pos": 59, "end_pos": 80, "type": "TASK", "confidence": 0.6253824035326639}]}, {"text": "That is, when following a sequence of edge types in a random walk on a graph, we allow the walk to follow edges that are semantically similar to the given edge types, as defined by some vector space embedding of the edge types.", "labels": [], "entities": []}, {"text": "If a path calls for an edge of type \"flows through\", for example, we accept other edge types (such as \"runs through\") with probability proportional to the vector space similarity between the two edge types.", "labels": [], "entities": []}, {"text": "This lets us combine notions of distributional similarity with symbolic logical inference, with the result of decreasing the sparsity of the feature space considered by PRA.", "labels": [], "entities": [{"text": "PRA", "start_pos": 169, "end_pos": 172, "type": "DATASET", "confidence": 0.8153799772262573}]}, {"text": "We show with experiments using both the NELL and Freebase knowledge bases that this method gives significantly better performance than prior approaches to incorporating text data into random walk inference.", "labels": [], "entities": [{"text": "NELL", "start_pos": 40, "end_pos": 44, "type": "DATASET", "confidence": 0.8793491125106812}, {"text": "Freebase knowledge bases", "start_pos": 49, "end_pos": 73, "type": "DATASET", "confidence": 0.9069025119145712}]}], "datasetContent": [{"text": "We perform both the feature selection step and the feature computation step of PRA using GraphChi, an efficient single-machine graph processing library ().", "labels": [], "entities": [{"text": "feature selection", "start_pos": 20, "end_pos": 37, "type": "TASK", "confidence": 0.7126327157020569}]}, {"text": "We use MAL-LET's implementation of logistic regression, with both L1 and L2 regularization).", "labels": [], "entities": []}, {"text": "To obtain negative evidence, we used a closed world assumption, treating any (source, target) pair found during the feature computation step as a negative example if it was not given as a positive example.", "labels": [], "entities": []}, {"text": "We tuned the parameters to our methods using a coarse, manual grid search with cross validation on the training data described below.", "labels": [], "entities": []}, {"text": "The parameters we tuned were the L1 and L2 regularization parameters, how many random walks to perform in the feature selection and computation steps of PRA, and spikiness and restart parameters for vector space walks.", "labels": [], "entities": [{"text": "restart", "start_pos": 176, "end_pos": 183, "type": "METRIC", "confidence": 0.9862169027328491}]}, {"text": "The results presented were not very sensitive to changes in these parameters.", "labels": [], "entities": []}, {"text": "As evaluation metrics, we use mean average precision (MAP) and mean reciprocal rank (MRR), following recent work evaluating relation extraction performance).", "labels": [], "entities": [{"text": "mean average precision (MAP)", "start_pos": 30, "end_pos": 58, "type": "METRIC", "confidence": 0.919463574886322}, {"text": "mean reciprocal rank (MRR)", "start_pos": 63, "end_pos": 89, "type": "METRIC", "confidence": 0.9080124696095785}, {"text": "relation extraction", "start_pos": 124, "end_pos": 143, "type": "TASK", "confidence": 0.7933021187782288}]}, {"text": "We test significance using a paired permutation test.", "labels": [], "entities": []}, {"text": "The results of these experiments are shown in.", "labels": [], "entities": []}, {"text": "In we show average precision for every relation tested on the NELL KB, and we show the same for Freebase in.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9392439126968384}, {"text": "NELL KB", "start_pos": 62, "end_pos": 69, "type": "DATASET", "confidence": 0.8411366939544678}, {"text": "Freebase", "start_pos": 96, "end_pos": 104, "type": "DATASET", "confidence": 0.9462657570838928}]}], "tableCaptions": [{"text": " Table 1: Statistics of the data used in our experi- ments.", "labels": [], "entities": []}, {"text": " Table 2: Results on the NELL knowledge base.  The bolded line is significantly better than all other  results with p < 0.025.", "labels": [], "entities": [{"text": "NELL knowledge base", "start_pos": 25, "end_pos": 44, "type": "DATASET", "confidence": 0.8490699927012125}]}, {"text": " Table 3: Results on the Freebase knowledge base.  The bolded line is significantly better than all other  results with p < 0.0002.", "labels": [], "entities": [{"text": "Freebase knowledge base", "start_pos": 25, "end_pos": 48, "type": "DATASET", "confidence": 0.9890009959538778}]}, {"text": " Table 4: Average precision for each relation tested on the NELL KB. The best performing method on  each relation is bolded.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9566989541053772}, {"text": "NELL KB", "start_pos": 60, "end_pos": 67, "type": "DATASET", "confidence": 0.8885880410671234}]}, {"text": " Table 5: Average precision for each relation tested on the Freebase KB. The best performing method on  each relation is bolded. For space considerations, \"Clustered SVO\" is shortened to \"C-SVO\" and \"Vector  SVO\" is shortened to \"V-SVO\" in the table header.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9852257370948792}, {"text": "Freebase KB", "start_pos": 60, "end_pos": 71, "type": "DATASET", "confidence": 0.9821299016475677}]}]}