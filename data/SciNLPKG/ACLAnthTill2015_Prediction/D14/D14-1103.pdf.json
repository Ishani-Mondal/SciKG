{"title": [{"text": "Dependency parsing with latent refinements of part-of-speech tags", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8596875667572021}]}], "abstractContent": [{"text": "In this paper we propose a method to increase dependency parser performance without using additional labeled or unla-beled data by refining the layer of predicted part-of-speech (POS) tags.", "labels": [], "entities": [{"text": "dependency parser", "start_pos": 46, "end_pos": 63, "type": "TASK", "confidence": 0.7435983121395111}]}, {"text": "We perform experiments on English and Ger-man and show significant improvements for both languages.", "labels": [], "entities": []}, {"text": "The refinement is based on generative split-merge training for Hidden Markov models (HMMs).", "labels": [], "entities": []}], "introductionContent": [{"text": "Probabilistic Context-free Grammars with latent annotations (PCFG-LA) have been shown () to yield phrase structure parsers with state-of-the-art accuracy.", "labels": [], "entities": [{"text": "phrase structure parsers", "start_pos": 98, "end_pos": 122, "type": "TASK", "confidence": 0.7317225436369578}, {"text": "accuracy", "start_pos": 145, "end_pos": 153, "type": "METRIC", "confidence": 0.9962642788887024}]}, {"text": "While Hidden Markov Models with latent annotations (HMM-LA), stay somewhat behind the performance of state-of-the-art discriminative taggers.", "labels": [], "entities": []}, {"text": "In this paper we address the question of whether the resulting latent POS tags are linguistically meaningful and useful for upstream tasks such as syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 147, "end_pos": 164, "type": "TASK", "confidence": 0.7600959539413452}]}, {"text": "We find that this is indeed the case, leading to a procedure that significantly increases the performance of dependency parsers.", "labels": [], "entities": [{"text": "dependency parsers", "start_pos": 109, "end_pos": 127, "type": "TASK", "confidence": 0.7536649703979492}]}, {"text": "The procedure is attractive because the refinement of predicted part-of-speech sequences using a coarse-tofine strategy) is fast and efficient.", "labels": [], "entities": []}, {"text": "More precisely, we show that incorporating the induced POS into a state-of-the-art dependency parser gives increases in Labeled Attachment Score (LAS): from 90.34 to 90.57 for English and from 87.92 to 88.24 (resp. 88.35 to 88.51) for German without using (resp. with using) morphological features.", "labels": [], "entities": [{"text": "Labeled Attachment Score (LAS)", "start_pos": 120, "end_pos": 150, "type": "METRIC", "confidence": 0.8727553089459738}]}, {"text": "introduce generative splitmerge training for PCFGs and provide a fully automatic method for training state-of-the-art phrase structure parsers.", "labels": [], "entities": [{"text": "generative splitmerge training", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.8899773359298706}, {"text": "phrase structure parsers", "start_pos": 118, "end_pos": 142, "type": "TASK", "confidence": 0.7241615255673727}]}, {"text": "They argue that the resulting latent annotations are linguistically meaningful.", "labels": [], "entities": []}, {"text": "induce latent sub-states into CRFs and show that noun phrase (NP) recognition can be improved, especially if no part-of-speech features are available.", "labels": [], "entities": [{"text": "noun phrase (NP) recognition", "start_pos": 49, "end_pos": 77, "type": "TASK", "confidence": 0.610609749952952}]}, {"text": "apply split-merge training to create HMMs with latent annotations (HMM-LA) for Chinese POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 87, "end_pos": 98, "type": "TASK", "confidence": 0.7159295976161957}]}, {"text": "They report that the method outperforms standard generative bigram and trigram tagging, but do not compare to discriminative methods.", "labels": [], "entities": [{"text": "trigram tagging", "start_pos": 71, "end_pos": 86, "type": "TASK", "confidence": 0.6597737222909927}]}, {"text": "show that a bidirectional variant of latent HMMs with incorporation of prosodic information can yield state-of-the-art results in POS tagging of conversational speech.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 130, "end_pos": 141, "type": "TASK", "confidence": 0.8956217467784882}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: LAS and UAS 1 mean (\u00b5), best value (max) and std. deviation (\u03c3) for the development set for  English and German dependency parsing with (feat.) and without morphological features (no feat.).", "labels": [], "entities": [{"text": "LAS", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.866977334022522}, {"text": "UAS 1 mean (\u00b5)", "start_pos": 18, "end_pos": 32, "type": "METRIC", "confidence": 0.8157452593247095}, {"text": "best value (max)", "start_pos": 34, "end_pos": 50, "type": "METRIC", "confidence": 0.8102674365043641}, {"text": "std. deviation (\u03c3)", "start_pos": 55, "end_pos": 73, "type": "METRIC", "confidence": 0.899219791094462}, {"text": "dependency parsing", "start_pos": 122, "end_pos": 140, "type": "TASK", "confidence": 0.6801548153162003}]}]}