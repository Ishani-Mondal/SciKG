{"title": [{"text": "Vote Prediction on Comments in Social Polls", "labels": [], "entities": [{"text": "Vote Prediction", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.8887953162193298}]}], "abstractContent": [{"text": "A poll consists of a question and a set of predefined answers from which voters can select.", "labels": [], "entities": []}, {"text": "We present the new problem of vote prediction on comments, which involves determining which of these answers a voter selected given a comment she wrote after voting.", "labels": [], "entities": [{"text": "vote prediction on comments", "start_pos": 30, "end_pos": 57, "type": "TASK", "confidence": 0.8079590946435928}]}, {"text": "To address this task, we exploit not only the information extracted from the comments but also extra-textual information such as user demographic information and inter-comment constraints.", "labels": [], "entities": []}, {"text": "In an evaluation involving nearly one million comments collected from the popular SodaHead social polling website, we show that a vote prediction system that exploits only textual information can be improved significantly when extended with extra-textual information.", "labels": [], "entities": [{"text": "SodaHead social polling website", "start_pos": 82, "end_pos": 113, "type": "DATASET", "confidence": 0.7471482902765274}, {"text": "vote prediction", "start_pos": 130, "end_pos": 145, "type": "TASK", "confidence": 0.7188607603311539}]}], "introductionContent": [{"text": "We introduce in this paper anew opinion mining task, vote prediction on comments in social polls.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.7697161734104156}, {"text": "vote prediction on comments in social polls", "start_pos": 53, "end_pos": 96, "type": "TASK", "confidence": 0.8541593466486249}]}, {"text": "Recall that a poll consists of a question accompanied by a set of predefined answers.", "labels": [], "entities": []}, {"text": "A user who votes on the question will choose one of these answers and will be prompted to enter a comment giving an explanation of why she chose the answer.", "labels": [], "entities": []}, {"text": "Given a poll and a user comment written in response to it, the task of vote prediction seeks to determine which predefined answer was chosen by the author of the comment.", "labels": [], "entities": [{"text": "vote prediction", "start_pos": 71, "end_pos": 86, "type": "TASK", "confidence": 0.7202200293540955}]}, {"text": "A solution to the vote prediction problem would contribute significantly to our understanding of the underlying attitudes of individual social polling website users.", "labels": [], "entities": [{"text": "vote prediction", "start_pos": 18, "end_pos": 33, "type": "TASK", "confidence": 0.8131510615348816}]}, {"text": "This understanding could be exploited for tasks such as improving user experience or directed advertising; if we can predict how a user will vote on a question, we can make more accurate guesses about what kind of content/ads related to the question the user would like to see.", "labels": [], "entities": []}, {"text": "Unfortunately, a major difficulty of vote prediction arises from the casual nature of discussion in social media.", "labels": [], "entities": [{"text": "vote prediction", "start_pos": 37, "end_pos": 52, "type": "TASK", "confidence": 0.8558483421802521}]}, {"text": "A comment often contains insufficient information for inferring the user's vote, or in some cases may even be entirely absent.", "labels": [], "entities": []}, {"text": "In light of this difficulty, we exploit two additional types of information in the prediction process.", "labels": [], "entities": []}, {"text": "First, we employ demographic features derived from user profiles.", "labels": [], "entities": []}, {"text": "Demographic features maybe broadly useful for other opinion mining tasks such as stance classification, as many social media websites like CreateDebate 1 allow users to create profiles with similar demographic information.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 52, "end_pos": 66, "type": "TASK", "confidence": 0.7150662541389465}, {"text": "stance classification", "start_pos": 81, "end_pos": 102, "type": "TASK", "confidence": 0.9823317229747772}]}, {"text": "Previous work has attempted to predict such latent features (e.g.,,) rather than employing them for opinion mining tasks.", "labels": [], "entities": [{"text": "opinion mining tasks", "start_pos": 100, "end_pos": 120, "type": "TASK", "confidence": 0.8656097253163656}]}, {"text": "Second, we exploit inter-comment constraints to help us perform joint inference over votes on different questions.", "labels": [], "entities": []}, {"text": "Note that previous work on debate stance recognition has also employed constraints to improve the inference process.", "labels": [], "entities": [{"text": "debate stance recognition", "start_pos": 27, "end_pos": 52, "type": "TASK", "confidence": 0.8117840687433878}]}, {"text": "Specifically, instance prediction, it is typical to employ so-called author constraints (e.g.,,,,), which specify that two documents written by the same author for the same topic should have the same stance.", "labels": [], "entities": [{"text": "instance prediction", "start_pos": 14, "end_pos": 33, "type": "TASK", "confidence": 0.8679172992706299}]}, {"text": "However, in vote prediction, author constraints are not useful because a user is not permitted to cast more than one vote per question, unlike instance prediction, where users may engage in a debate and therefore post more than once per debate topic.", "labels": [], "entities": [{"text": "vote prediction", "start_pos": 12, "end_pos": 27, "type": "TASK", "confidence": 0.8144724667072296}, {"text": "instance prediction", "start_pos": 143, "end_pos": 162, "type": "TASK", "confidence": 0.7699219882488251}]}, {"text": "Consequently, we propose two new types of constraints for exploiting inter topic user voting patterns.", "labels": [], "entities": []}, {"text": "One constraint involves pairs of authors and the other involves pairs of questions.", "labels": [], "entities": []}, {"text": "These constraints are also potentially useful for other opin-ion mining tasks involving social media, as social media sites typically allow users to comment on multiple topics.", "labels": [], "entities": []}, {"text": "Note that enforcing constraints involving two questions is by no means trivial, as the possible class values associated with the two comments may not necessarily be the same.", "labels": [], "entities": []}, {"text": "Another contribution of our work lies in our adaptation of the label propagation algorithm () to enforce constraints for vote prediction.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 63, "end_pos": 80, "type": "TASK", "confidence": 0.7261592000722885}, {"text": "vote prediction", "start_pos": 121, "end_pos": 136, "type": "TASK", "confidence": 0.8131836652755737}]}, {"text": "Recall that existing stance classification approaches enforce constraints using minimum cut (), integer linear programming (, and loopy belief propagation.", "labels": [], "entities": [{"text": "stance classification", "start_pos": 21, "end_pos": 42, "type": "TASK", "confidence": 0.8830388486385345}, {"text": "loopy belief propagation", "start_pos": 130, "end_pos": 154, "type": "TASK", "confidence": 0.6936964591344198}]}, {"text": "Our decision to employ label propagation stems in part from the inability of loopy belief propagation and integer linear programming to efficiently process the nearly one million comments we have, and in part from the inability of the traditional two-way minimum cut algorithm to handle multiclass classification.", "labels": [], "entities": [{"text": "label propagation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7470259666442871}, {"text": "loopy belief propagation", "start_pos": 77, "end_pos": 101, "type": "TASK", "confidence": 0.7161660591761271}, {"text": "multiclass classification", "start_pos": 287, "end_pos": 312, "type": "TASK", "confidence": 0.7478625476360321}]}, {"text": "It is worth noting, however, that other variations of the label propagation algorithm have been proposed for unrelated NLP tasks such as automatically harvesting temporal facts from the web (e.g., and ).", "labels": [], "entities": [{"text": "label propagation", "start_pos": 58, "end_pos": 75, "type": "TASK", "confidence": 0.7325708121061325}]}, {"text": "While we are the first to address the vote prediction task, other researchers have previously used social media to predict the outcomes of various events, primarily by analyzing Twitter data.", "labels": [], "entities": [{"text": "vote prediction task", "start_pos": 38, "end_pos": 58, "type": "TASK", "confidence": 0.8213275074958801}]}, {"text": "For example, and performed the related task of predicting the outcomes of elections.", "labels": [], "entities": [{"text": "predicting the outcomes of elections", "start_pos": 47, "end_pos": 83, "type": "TASK", "confidence": 0.8535167813301087}]}, {"text": "Rather than predicting election outcomes, O' focused on finding correlations between measures derived from tweets and the outcomes of political events like elections and polls.", "labels": [], "entities": []}, {"text": "Finally, predicted movies' box office success.", "labels": [], "entities": []}, {"text": "These tasks contrast with our task of vote prediction in that they are concerned with aggregate measures such as the fraction of the vote each candidate or party will win in an election or how much money a movie will make at the box office, whereas vote prediction is concerned with predicting how individual people will vote on a much wider variety of news/political topics.", "labels": [], "entities": [{"text": "vote prediction", "start_pos": 38, "end_pos": 53, "type": "TASK", "confidence": 0.7239189893007278}, {"text": "vote prediction", "start_pos": 249, "end_pos": 264, "type": "TASK", "confidence": 0.7661233246326447}]}], "datasetContent": [{"text": "We mentioned in Section 3 that we split our dataset of 997,379 comments into a test set comprising about 20% of the dataset's comments and a training and development set comprising some fraction of the remaining 80% of the comments.", "labels": [], "entities": []}, {"text": "We actually split the data up like this five different times so that each comment appears in an experiment's test set exactly once.", "labels": [], "entities": []}, {"text": "In this way, through the use of five fold cross-validation, we can report our results on the entire dataset.", "labels": [], "entities": []}, {"text": "shows the accuracy of the predictions made by various systems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9994686245918274}]}, {"text": "First, let us compare our first and second baselines.", "labels": [], "entities": []}, {"text": "Recall that the first baseline (B 1 ) predicts that all test comments will have the same label as the majority of training comments, and the second baseline's (B 2 ) predictions are the output of ME classifiers trained with a generic feature set.", "labels": [], "entities": []}, {"text": "As we can see from the graph, at very small training set sizes, the standard set of features supplied to B 2 does little more than confuse the ME learner, as it performs slightly but not significantly worse 6 than the first baseline when the training/development set comprises only 25% of the available data.", "labels": [], "entities": []}, {"text": "This is understandable, as 25% of an average question's available data is only 42 comments, an extremely small number of examples to learn from for most NLP tasks.", "labels": [], "entities": []}, {"text": "Clearly a better approach than the one provided by the second baseline is needed.", "labels": [], "entities": []}, {"text": "Though the average training set sizes at the 50%, 75%, and 100% levels are still relatively small, B 2 significantly outperforms B 1 at all these levels.", "labels": [], "entities": []}], "tableCaptions": []}