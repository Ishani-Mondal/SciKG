{"title": [{"text": "Low-dimensional Embeddings for Interpretable Anchor-based Topic Inference", "labels": [], "entities": [{"text": "Interpretable Anchor-based Topic Inference", "start_pos": 31, "end_pos": 73, "type": "TASK", "confidence": 0.5264199450612068}]}], "abstractContent": [{"text": "The anchor words algorithm performs provably efficient topic model inference by finding an approximate convex hull in a high-dimensional word co-occurrence space.", "labels": [], "entities": [{"text": "topic model inference", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.7161116798718771}]}, {"text": "However, the existing greedy algorithm often selects poor anchor words, reducing topic quality and interpretability.", "labels": [], "entities": []}, {"text": "Rather than finding an approximate convex hull in a high-dimensional space, we propose to find an exact convex hull in a visualizable 2-or 3-dimensional space.", "labels": [], "entities": []}, {"text": "Such low-dimensional embeddings both improve topics and clearly show users why the algorithm selects certain words.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical topic modeling is useful in exploratory data analysis), but model inference is known to be NP-hard even for the simplest models with only two topics (, and training often remains a black box to users.", "labels": [], "entities": [{"text": "Statistical topic modeling", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.6903043786684672}, {"text": "model inference", "start_pos": 72, "end_pos": 87, "type": "TASK", "confidence": 0.7033606916666031}]}, {"text": "Likelihood-based training requires expensive approximate inference such as variational methods (, which are deterministic but sensitive to initialization, or Markov chain Monte Carlo (MCMC) methods (), which have no finite convergence guarantees.", "labels": [], "entities": []}, {"text": "Recently Arora et al. proposed the Anchor Words algorithm (, which casts topic inference as statistical recovery using a separability assumption: each topic has a specific anchor word that appears only in the context of that single topic.", "labels": [], "entities": []}, {"text": "Each anchor word can be used as a unique pivot to disambiguate the corresponding topic distribution.", "labels": [], "entities": []}, {"text": "We then reconstruct the word co-occurrence pattern of each nonanchor words as a convex combination of the cooccurrence patterns of the anchor words.", "labels": [], "entities": []}, {"text": "This algorithm is fast, requiring only one pass through the training documents, and provides provable guarantees, but results depend entirely on selecting good anchor words.", "labels": [], "entities": []}, {"text": "( propose a greedy method that finds an approximate convex hull around a set of vectors corresponding to the word co-occurrence patterns for each vocabulary word.", "labels": [], "entities": []}, {"text": "Although this method is an improvement over previous work that used impractical linear programming methods (), serious problems remain.", "labels": [], "entities": []}, {"text": "The method greedily chooses the farthest point from the current subspace until the given number of anchors have been found.", "labels": [], "entities": []}, {"text": "Particularly at the early stages of the algorithm, the words associated with the farthest points are likely to be infrequent and idiosyncratic, and thus form poor bases for human interpretation and topic recovery.", "labels": [], "entities": [{"text": "human interpretation", "start_pos": 173, "end_pos": 193, "type": "TASK", "confidence": 0.6805336773395538}, {"text": "topic recovery", "start_pos": 198, "end_pos": 212, "type": "TASK", "confidence": 0.8592103719711304}]}, {"text": "This poor choice of anchors noticeably affects topic quality: the anchor words algorithm tends to produce large numbers of nearly identical topics.", "labels": [], "entities": []}, {"text": "Besides providing a separability criterion, anchor words also have the potential to improve topic interpretability.", "labels": [], "entities": [{"text": "topic interpretability", "start_pos": 92, "end_pos": 114, "type": "TASK", "confidence": 0.7052426934242249}]}, {"text": "After learning topics forgiven text collections, users often request a label that summarizes each topic.", "labels": [], "entities": []}, {"text": "Manually labeling topics is arduous, and labels often do not carryover between random initializations and models with differing numbers of topics.", "labels": [], "entities": []}, {"text": "Moreover, it is hard to control the subjectivity in labelings between annotators, which is open to interpretive errors.", "labels": [], "entities": []}, {"text": "There has been considerable interest in automating the labeling process (.", "labels": [], "entities": [{"text": "labeling process", "start_pos": 55, "end_pos": 71, "type": "TASK", "confidence": 0.9179953634738922}]}, {"text": "() propose a measure of saliency: a good summary term should be both distinctive specifically to one topic and probable in that topic.", "labels": [], "entities": []}, {"text": "Anchor words are by definition optimally distinct, and therefore may seem to be good candidates for topic labels, but greedily selecting extreme words often results in anchor words that have low probability.", "labels": [], "entities": []}, {"text": "In this work we explore the opposite of Arora et al.'s method: rather than finding an approximate convex hull for an exact set of vectors, we find an exact convex hull for an approximate set of vectors.", "labels": [], "entities": []}, {"text": "We project the V \u00d7 V word co-occurrence matrix to visualizable 2-and 3-dimensional spaces using methods such as t-SNE (van der, resulting in an input matrix up to 3600 times narrower than the original input for our training corpora.", "labels": [], "entities": []}, {"text": "Despite this radically lowdimensional projection, the method not only finds topics that are as good or better than the greedy anchor method, it also finds highly salient, interpretable anchor words and provides users with a clear visual explanation for why the algorithm chooses particular words, all while maintaining the original algorithm's computational benefits.", "labels": [], "entities": []}], "datasetContent": [{"text": "We find that radically low-dimensional t-SNE projections are effective at finding anchor words that are much more salient than the greedy method, and topics that are more distinctive, while maintaining comparable held-out likelihood and semantic coherence.", "labels": [], "entities": []}, {"text": "As noted in Section 1, the previous greedy anchor words algorithm tends to produce many nearly identical topics.", "labels": [], "entities": []}, {"text": "For example, 37 out of 100 topics trained on a 2008 political blog corpus have obama, mccain, bush, iraq or palin as their most probable word, including 17 just for obama.", "labels": [], "entities": []}, {"text": "Only 66% of topics have a unique top word.", "labels": [], "entities": []}, {"text": "In contrast, the t-SNE model on the same dataset has only one topic whose most probable word is obama, and 86% of topics have a unique top word (mccain is the most frequent top word, with five topics).", "labels": [], "entities": []}, {"text": "We use three real datasets: business reviews from the Yelp Academic Dataset, 2 political blogs from the 2008 US presidential election, and New York Times articles from 2007.", "labels": [], "entities": [{"text": "Yelp Academic Dataset", "start_pos": 54, "end_pos": 75, "type": "DATASET", "confidence": 0.9769017497698466}]}, {"text": "3 Details are shown in.", "labels": [], "entities": [{"text": "Details", "start_pos": 2, "end_pos": 9, "type": "METRIC", "confidence": 0.576370358467102}]}, {"text": "Documents with fewer than 10 word tokens are discarded due to possible instability in constructing\u02c6Qstructing\u02c6 structing\u02c6Q.", "labels": [], "entities": []}, {"text": "We perform minimal vocabulary curation, eliminating a standard list of English stopwords and terms that occur below frequency cutoffs: 100 times (Yelp, Blog) and 150 times (NYT).", "labels": [], "entities": [{"text": "NYT", "start_pos": 173, "end_pos": 176, "type": "DATASET", "confidence": 0.8737136721611023}]}, {"text": "We further restrict possible anchor words to words that occur in more than three documents.", "labels": [], "entities": []}, {"text": "As our datasets are not artificially synthesized, we reserve 5% from each set of documents for held-out likelihood computation.: Statistics for datasets used in experiments Unlike (, which presents results on synthetic datasets to compare performance across different recovery methods given increasing numbers of documents, we are are interested in comparing anchor finding methods, and are mainly concerned with semantic quality.", "labels": [], "entities": [{"text": "anchor finding", "start_pos": 359, "end_pos": 373, "type": "TASK", "confidence": 0.7685643136501312}]}, {"text": "As a result, although we have conducted experiments on synthetic document collections, we focus on real datasets for this work.", "labels": [], "entities": []}, {"text": "We also choose to compare only anchor finding algorithms, so we do not report comparisons to likelihood-based methods, which can be found in ().", "labels": [], "entities": [{"text": "anchor finding", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.8763464093208313}]}, {"text": "For both PCA and t-SNE, we use threedimensional embeddings across all experiments.", "labels": [], "entities": []}, {"text": "This projection results in matrices that are 0.03% as wide as the original V \u00d7 V matrix for the NYT dataset.", "labels": [], "entities": [{"text": "NYT dataset", "start_pos": 96, "end_pos": 107, "type": "DATASET", "confidence": 0.9691725671291351}]}, {"text": "Without low-dimensional embedding, each word is represented by a V-dimensional vector where only several terms are non-zero due to the sparse co-occurrence patterns.", "labels": [], "entities": []}, {"text": "Thus a ver-tex captured by the greedy anchor-finding method is likely to be one of many eccentric vertices in very high-dimensional space.", "labels": [], "entities": []}, {"text": "In contrast, t-SNE creates an effective dense representation where a small number of pivotal vertices are more clearly visible, improving both performance and interpretability.", "labels": [], "entities": []}, {"text": "Note that since we can find an exact convex hull in these spaces, there is an upper bound to the number of topics that can be found given a particular projection.", "labels": [], "entities": []}, {"text": "If more topics are desired, one can simply increase the dimensionality of the projection.", "labels": [], "entities": []}, {"text": "For the greedy algorithm we use sparse random projections with 1,000 dimensions with 5% negative entries and 5% positive entries.", "labels": [], "entities": []}, {"text": "PCA and t-SNE choose (49, 32, 47) and) anchors, respectively for each of three Yelp, Blog, and NYTimes datasets.", "labels": [], "entities": [{"text": "PCA", "start_pos": 0, "end_pos": 3, "type": "DATASET", "confidence": 0.940089762210846}, {"text": "Yelp", "start_pos": 79, "end_pos": 83, "type": "DATASET", "confidence": 0.9405787587165833}, {"text": "Blog", "start_pos": 85, "end_pos": 89, "type": "DATASET", "confidence": 0.5088731050491333}, {"text": "NYTimes datasets", "start_pos": 95, "end_pos": 111, "type": "DATASET", "confidence": 0.8879490196704865}]}], "tableCaptions": [{"text": " Table 1: Statistics for datasets used in experiments", "labels": [], "entities": []}, {"text": " Table 3: Example t-SNE topics and their most  similar topics across algorithms. The Greedy algo- rithm can find similar topics, but the anchor words  are much less salient.", "labels": [], "entities": []}]}