{"title": [{"text": "A Neural Network Approach to Selectional Preference Acquisition", "labels": [], "entities": [{"text": "Selectional Preference Acquisition", "start_pos": 29, "end_pos": 63, "type": "TASK", "confidence": 0.8968759179115295}]}], "abstractContent": [{"text": "This paper investigates the use of neural networks for the acquisition of selectional preferences.", "labels": [], "entities": []}, {"text": "Inspired by recent advances of neural network models for NLP applications , we propose a neural network model that learns to discriminate between felicitous and infelicitous arguments fora particular predicate.", "labels": [], "entities": []}, {"text": "The model is entirely un-supervised-preferences are learned from unannotated corpus data.", "labels": [], "entities": []}, {"text": "We propose two neural network architectures: one that handles standard two-way selectional preferences and one that is able to deal with multi-way selectional preferences.", "labels": [], "entities": []}, {"text": "The model's performance is evaluated on a pseudo-disambiguation task, on which it is shown to achieve state of the art performance .", "labels": [], "entities": []}], "introductionContent": [{"text": "Predicates often have a semantically motivated preference for particular arguments.", "labels": [], "entities": []}, {"text": "Compare for example the sentences in (1) and (2).", "labels": [], "entities": []}, {"text": "(1) The vocalist sings a ballad.", "labels": [], "entities": []}, {"text": "(2) The exception sings a tomato.", "labels": [], "entities": []}, {"text": "Most language users would have no problems accepting the first sentence as well-formed: a vocalist can be expected to sing, and a ballad is something that can be sung.", "labels": [], "entities": []}, {"text": "The same language users, however, would likely consider the second sentence to be ill-formed: an exception is not supposed to sing, nor is a tomato something that is typically sung.", "labels": [], "entities": []}, {"text": "Within the field of natural language processing, this inclination of predicates to select for particular arguments is known as selectional preference.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 20, "end_pos": 47, "type": "TASK", "confidence": 0.6751394271850586}]}, {"text": "The automatic acquisition of selectional preferences has been a popular research subject within the field of natural language processing.", "labels": [], "entities": [{"text": "automatic acquisition of selectional preferences", "start_pos": 4, "end_pos": 52, "type": "TASK", "confidence": 0.7797457337379455}, {"text": "natural language processing", "start_pos": 109, "end_pos": 136, "type": "TASK", "confidence": 0.6493302881717682}]}, {"text": "An automatically acquired selectional preference resource is a versatile tool for numerous NLP applications, such as semantic role labeling (), word sense disambiguation, and metaphor processing.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 117, "end_pos": 139, "type": "TASK", "confidence": 0.6761349042256674}, {"text": "word sense disambiguation", "start_pos": 144, "end_pos": 169, "type": "TASK", "confidence": 0.7272022366523743}, {"text": "metaphor processing", "start_pos": 175, "end_pos": 194, "type": "TASK", "confidence": 0.9380519092082977}]}, {"text": "Models for selectional preference need to adequately deal with the consequences of Zipf's law: language is inherently sparse, and the majority of language utterances occur very infrequently.", "labels": [], "entities": []}, {"text": "As a consequence, models that are based on corpus data need to properly generalize beyond the mere co-occurrence frequencies of sparse corpus data, taking into account the semantic similarity of both predicates and arguments.", "labels": [], "entities": []}, {"text": "Researchers have come up with various approaches to this generalization step.", "labels": [], "entities": [{"text": "generalization step", "start_pos": 57, "end_pos": 76, "type": "TASK", "confidence": 0.9095344245433807}]}, {"text": "Earlier approaches to selectional preference acquisition mostly rely on hand-crafted resources such as WordNet), while later approaches tend to take advantage of unsupervised learning machinery, such as latent variable models ( and distributional similarity metrics.", "labels": [], "entities": [{"text": "selectional preference acquisition", "start_pos": 22, "end_pos": 56, "type": "TASK", "confidence": 0.7513285279273987}, {"text": "WordNet", "start_pos": 103, "end_pos": 110, "type": "DATASET", "confidence": 0.9707203507423401}]}, {"text": "This paper investigates the use of neural networks for the acquisition of selectional preferences.", "labels": [], "entities": []}, {"text": "Inspired by recent advances of neural network models for NLP applications, we propose a neural network model that learns to discriminate between felicitous and infelicitous arguments fora particular predicate.", "labels": [], "entities": []}, {"text": "The model is entirely unsupervisedpreferences are learned from unannotated corpus data.", "labels": [], "entities": []}, {"text": "Positive training instances are constructed from attested corpus data, while negative instances are constructed from randomly corrupted instances.", "labels": [], "entities": []}, {"text": "We propose two neural network architectures: one that handles standard two-way selectional preferences and one that is able to deal with multi-way selectional preferences, where the interaction be-tween multiple verb arguments is taken into account.", "labels": [], "entities": []}, {"text": "The model's performance is evaluated on a pseudo-disambiguation task, on which it is shown to achieve state of the art performance.", "labels": [], "entities": []}, {"text": "The contributions of this paper are twofold.", "labels": [], "entities": []}, {"text": "First of all, we apply and evaluate a neural network approach to the problem of standard (two-way) selectional preference acquisition.", "labels": [], "entities": [{"text": "selectional preference acquisition", "start_pos": 99, "end_pos": 133, "type": "TASK", "confidence": 0.6500115891297659}]}, {"text": "Selectional preference acquisition using neural networks has not yet been explored in the literature.", "labels": [], "entities": [{"text": "Selectional preference acquisition", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.8161061406135559}]}, {"text": "Secondly, we propose a novel network architecture and training objective for the acquisition of multi-way selectional preferences, where the interaction between a verb and its various arguments is captured at the same time.", "labels": [], "entities": []}, {"text": "The remainder of this paper is as follows.", "labels": [], "entities": []}, {"text": "Section 2 first discusses related work with respect to selectional preference acquisition and neural network modeling.", "labels": [], "entities": [{"text": "selectional preference acquisition", "start_pos": 55, "end_pos": 89, "type": "TASK", "confidence": 0.7794443368911743}, {"text": "neural network modeling", "start_pos": 94, "end_pos": 117, "type": "TASK", "confidence": 0.6977113286654154}]}, {"text": "Section 3 describes our neural network architecture and its training procedure.", "labels": [], "entities": []}, {"text": "Section 4 evaluates the model's performance, comparing it to other existing models for selectional preference acquisition.", "labels": [], "entities": [{"text": "selectional preference acquisition", "start_pos": 87, "end_pos": 121, "type": "TASK", "confidence": 0.7909774382909139}]}, {"text": "Finally, section 5 concludes and indicates a number of avenues for future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}