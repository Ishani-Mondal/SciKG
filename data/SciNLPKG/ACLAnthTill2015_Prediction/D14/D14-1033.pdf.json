{"title": [{"text": "Go Climb a Dependency Tree and Correct the Grammatical Errors", "labels": [], "entities": []}], "abstractContent": [{"text": "State-of-art systems for grammar error correction often correct errors based on word sequences or phrases.", "labels": [], "entities": [{"text": "grammar error correction", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.6724567810694376}]}, {"text": "In this paper, we describe a grammar error correction system which corrects grammatical errors at tree level directly.", "labels": [], "entities": [{"text": "grammar error correction", "start_pos": 29, "end_pos": 53, "type": "TASK", "confidence": 0.5870785315831503}]}, {"text": "We cluster all error into two groups and divide our system into two modules correspondingly: the general module and the special module.", "labels": [], "entities": []}, {"text": "In the general module, we propose a TreeNode Language Model to correct errors related to verbs and nouns.", "labels": [], "entities": []}, {"text": "The TreeNode Language Model is easy to train and the decoding is efficient.", "labels": [], "entities": []}, {"text": "In the special module, two extra classification models are trained to correct errors related to determiners and prepositions.", "labels": [], "entities": []}, {"text": "Experiments show that our system outperforms the state-of-art systems and improves the F 1 score.", "labels": [], "entities": [{"text": "F 1 score", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9907333453496298}]}], "introductionContent": [{"text": "The task of grammar error correction is difficult yet important.", "labels": [], "entities": [{"text": "grammar error correction", "start_pos": 12, "end_pos": 36, "type": "TASK", "confidence": 0.5718940496444702}]}, {"text": "An automatic grammar error correction system can help second language (L2) learners improve the quality of their writing.", "labels": [], "entities": []}, {"text": "In recent years, there are various competitions devoted to grammar error correction, such as the), HOO-2012() and the CoNLL-2013 shared task (.", "labels": [], "entities": [{"text": "grammar error correction", "start_pos": 59, "end_pos": 83, "type": "TASK", "confidence": 0.6799536744753519}, {"text": "HOO-2012", "start_pos": 99, "end_pos": 107, "type": "METRIC", "confidence": 0.7859517931938171}]}, {"text": "There has been a lot of work addressing errors made by L2 learners.", "labels": [], "entities": []}, {"text": "A significant proportion of the systems for grammar error correction train individual statistical models to correct each special kind of error word byword and ignore error interactions.", "labels": [], "entities": [{"text": "grammar error correction", "start_pos": 44, "end_pos": 68, "type": "TASK", "confidence": 0.6676195661226908}]}, {"text": "These methods assume no interactions between different kinds of grammatical errors.", "labels": [], "entities": []}, {"text": "In real problem settings errors are correlated, which makes grammar error correction much more difficult.", "labels": [], "entities": [{"text": "grammar error correction", "start_pos": 60, "end_pos": 84, "type": "TASK", "confidence": 0.6225642263889313}]}, {"text": "Recent research begins to focus on the error interaction problem.", "labels": [], "entities": []}, {"text": "For example, decodes a global optimized result based on the individual correction confidence of each kind of errors.", "labels": [], "entities": [{"text": "correction confidence", "start_pos": 71, "end_pos": 92, "type": "METRIC", "confidence": 0.9642025828361511}]}, {"text": "The individual correction confidence is still based on the noisy context.", "labels": [], "entities": [{"text": "correction confidence", "start_pos": 15, "end_pos": 36, "type": "METRIC", "confidence": 0.8683332800865173}]}, {"text": "uses a joint modeling approach, which considers corrections in phrase structures instead of words.", "labels": [], "entities": []}, {"text": "For dependencies that are not covered by the joint learning model, uses the results of Illinois system in the joint inference.", "labels": [], "entities": []}, {"text": "These results are still at word level and are based on the noisy context.", "labels": [], "entities": []}, {"text": "These systems can consider error interactions, however, the systems are complex and inefficient.", "labels": [], "entities": []}, {"text": "In both and, Integer Linear Programming (ILP) is used for decoding a global optimized result.", "labels": [], "entities": []}, {"text": "In the worst case, the time complexity of ILP can be exponent.", "labels": [], "entities": [{"text": "time complexity", "start_pos": 23, "end_pos": 38, "type": "METRIC", "confidence": 0.9460490047931671}]}, {"text": "In contrast, we think a better grammar error correction system should correct grammatical errors at sentence level directly and efficiently.", "labels": [], "entities": [{"text": "grammar error correction", "start_pos": 31, "end_pos": 55, "type": "TASK", "confidence": 0.6383279164632162}]}, {"text": "The system should correct as many kinds of errors as possible in a generalized framework, while allowing special models for some kinds of errors that we need to take special care.", "labels": [], "entities": []}, {"text": "We cluster all error into two groups and correspondingly divide our system into two modules: the general module and the special module.", "labels": [], "entities": []}, {"text": "In the general module, our system views each parsed sentence as a dependency tree.", "labels": [], "entities": []}, {"text": "The system generates correction candidates for each node on the dependency tree.", "labels": [], "entities": []}, {"text": "The correction can be made on the dependency tree globally.", "labels": [], "entities": []}, {"text": "In this module, nearly all replacement errors related to verb form, noun form and subject-verb agreement errors can be considered.", "labels": [], "entities": []}, {"text": "In the special module, two extra classification models are used to correct the determiner errors and preposition errors . The classifiers are also trained at tree node level.", "labels": [], "entities": []}, {"text": "We take special care of these two kinds of errors because these errors not only include replacement errors, but also include insertion and deletion errors.", "labels": [], "entities": [{"text": "insertion", "start_pos": 125, "end_pos": 134, "type": "METRIC", "confidence": 0.9543782472610474}]}, {"text": "A classification model is more suitable for handling insertion and deletion errors.", "labels": [], "entities": []}, {"text": "Besides, they are the most common errors made by English as a Second Language (ESL) learners and are much easier to be incorporated into a classification framework.", "labels": [], "entities": []}, {"text": "We propose a TreeNode Language Model (TNLM) to efficiently measure the correctness of selecting a correction candidate of anode in the general module.", "labels": [], "entities": []}, {"text": "Similar to the existing statistical language models which assign a probability to a linear chain of words, our TNLM assigns correctness scores directly on each node on the dependency tree.", "labels": [], "entities": []}, {"text": "We select candidates for each node to maximize the global correctness score and use these candidates to form the corrected sentence.", "labels": [], "entities": [{"text": "global correctness score", "start_pos": 51, "end_pos": 75, "type": "METRIC", "confidence": 0.638471911350886}]}, {"text": "The global optimized inference can be tackled efficiently using dynamic programming.", "labels": [], "entities": []}, {"text": "Because the decoding is based on the whole sentence, error interactions can be considered.", "labels": [], "entities": []}, {"text": "Our TNLM only needs to use context words related to each node on the dependency tree.", "labels": [], "entities": []}, {"text": "Training a TreeNode language model costs no more than training ordinary language models on the same corpus.", "labels": [], "entities": []}, {"text": "Experiments show that our system can outperform the state-ofart systems.", "labels": [], "entities": []}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 1 gives the introduction.", "labels": [], "entities": []}, {"text": "In section 2 we describe the task and give an overview of the system.", "labels": [], "entities": []}, {"text": "In section 3 we describe the general module and in section 4 we describe the special module.", "labels": [], "entities": []}, {"text": "Experiments are described in section 5.", "labels": [], "entities": []}, {"text": "In section 6 related works are introduced, and the paper is concluded in the last section.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the experiments, we use our parsed Gigaword corpus as the training data, use the training data provided by CoNLL-2013 as the develop data, and use the test data of CoNLL-2013 as test data directly.", "labels": [], "entities": [{"text": "Gigaword corpus", "start_pos": 38, "end_pos": 53, "type": "DATASET", "confidence": 0.835871011018753}, {"text": "CoNLL-2013", "start_pos": 110, "end_pos": 120, "type": "DATASET", "confidence": 0.8935430645942688}, {"text": "CoNLL-2013", "start_pos": 167, "end_pos": 177, "type": "DATASET", "confidence": 0.8857872486114502}]}, {"text": "In the general module, the training data is used for the training of TreeNode Language Model.", "labels": [], "entities": []}, {"text": "In the special module, the training data is used for training individual classification models.", "labels": [], "entities": []}, {"text": "We use the M2 scorer (Dahlmeier and Ng, 2012b) provided by the organizer of CoNLL-2013 for the evaluation of our system.", "labels": [], "entities": [{"text": "M2 scorer", "start_pos": 11, "end_pos": 20, "type": "METRIC", "confidence": 0.8415259420871735}, {"text": "CoNLL-2013", "start_pos": 76, "end_pos": 86, "type": "DATASET", "confidence": 0.7470123171806335}]}, {"text": "The M2 scorer is widely used as a standard scorer in previous systems.", "labels": [], "entities": [{"text": "M2 scorer", "start_pos": 4, "end_pos": 13, "type": "DATASET", "confidence": 0.6087386012077332}]}, {"text": "Because we make comparison with the state-of-art systems on the CoNLL-2013 corpus, we use the same evaluation metric F 1 score of M2 scorer as the evaluation metric.", "labels": [], "entities": [{"text": "CoNLL-2013 corpus", "start_pos": 64, "end_pos": 81, "type": "DATASET", "confidence": 0.982531726360321}, {"text": "evaluation metric F 1 score", "start_pos": 99, "end_pos": 126, "type": "METRIC", "confidence": 0.6501657426357269}]}, {"text": "In reality, some sentences may have more than one kind of possible correction.", "labels": [], "entities": []}, {"text": "As the example in \"The books of that boy is on the desk.\", the corresponding correction can be either \"The books of that boy are on the desk.\" or \"The book of that boy is on the desk.\".", "labels": [], "entities": [{"text": "correction", "start_pos": 77, "end_pos": 87, "type": "METRIC", "confidence": 0.9654770493507385}]}, {"text": "The gold test data can only con-Word Features: Feature templates for the determiner errors.", "labels": [], "entities": []}, {"text": "w i is the word at the ith position.", "labels": [], "entities": []}, {"text": "N N is the current noun node.", "labels": [], "entities": []}, {"text": "F a is the father node of the current noun node.", "labels": [], "entities": []}, {"text": "Ch is a child node of the current noun node.: Feature templates for preposition errors.", "labels": [], "entities": []}, {"text": "w i is the word at the ith position.", "labels": [], "entities": []}, {"text": "F a is the father node of the current preposition node.", "labels": [], "entities": []}, {"text": "Ch is a child node of the current preposition node.", "labels": [], "entities": []}, {"text": "sider a small portion of possible answers.", "labels": [], "entities": []}, {"text": "To relieve this, the CoNLL-2013 shared task allows all participating teams to provide alterative answers if they believe their system outputs are also correct.", "labels": [], "entities": []}, {"text": "These alterative answers form the \"Revised Data\" in the shared task, which indeed help evaluate the outputs of the participating systems.", "labels": [], "entities": []}, {"text": "However, the revised data only include alterative corrections from the participating teams.", "labels": [], "entities": []}, {"text": "Therefore the evaluation is not that fair for future systems.", "labels": [], "entities": []}, {"text": "In our experiment we only use the original test data as the evaluation dataset.", "labels": [], "entities": []}, {"text": "We first show the performance of each stage of our system.", "labels": [], "entities": []}, {"text": "In our system, the general module and the special module correct grammar errors consequently.", "labels": [], "entities": []}, {"text": "Therefore in: Results of each stage in our system.", "labels": [], "entities": []}, {"text": "TNLM is the general module.", "labels": [], "entities": [{"text": "TNLM", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8335681557655334}]}, {"text": "\"+Det\" is the system containing the general module and determiner part of special module.\"+Prep\" is the final system We evaluate the effect of using TreeNode language model for the general module.", "labels": [], "entities": [{"text": "Prep", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.9752224683761597}]}, {"text": "We compare the TNLM with ordinary tri-gram language model.", "labels": [], "entities": [{"text": "TNLM", "start_pos": 15, "end_pos": 19, "type": "DATASET", "confidence": 0.7848606109619141}]}, {"text": "We use the same amount of training data and the same smoothing strategy (i.e. interpolation) for both of them.", "labels": [], "entities": []}, {"text": "Based on the result of the general module using TNLM, we compare our tree level special module against the local classification approach.", "labels": [], "entities": [{"text": "TNLM", "start_pos": 48, "end_pos": 52, "type": "DATASET", "confidence": 0.9171069860458374}]}, {"text": "The special module of our system makes predictions on the dependency tree directly, while local classification approaches make predictions on linear chain of words and decide the article of a noun Phrase or the preposition of a preposition phrase.", "labels": [], "entities": []}, {"text": "We use the same word level features for the two approaches except for the local classifiers we do not add tree level features.", "labels": [], "entities": []}, {"text": "When using the parsed Gigaword texts as training data, the quality of the sentences we select will influence the result.", "labels": [], "entities": [{"text": "Gigaword texts", "start_pos": 22, "end_pos": 36, "type": "DATASET", "confidence": 0.9161514639854431}]}, {"text": "For comparison, we randomly select the same amount of sentences from the same source of Gigaword and parse them as a alterative training set.: Comparison for the special module on the test data.", "labels": [], "entities": [{"text": "Gigaword", "start_pos": 88, "end_pos": 96, "type": "DATASET", "confidence": 0.911812961101532}]}, {"text": "The input of the special module is the sentences corrected by the TNLM in the general module.", "labels": [], "entities": [{"text": "TNLM", "start_pos": 66, "end_pos": 70, "type": "DATASET", "confidence": 0.8468937277793884}]}, {"text": "the selected training data of our system.", "labels": [], "entities": []}, {"text": "We can see that the data selection (cleaning) procedure is important for the improvement of system F 1.", "labels": [], "entities": [{"text": "data selection (cleaning)", "start_pos": 20, "end_pos": 45, "type": "TASK", "confidence": 0.7858272075653077}]}], "tableCaptions": [{"text": " Table 6: Feature templates for preposition errors. w i is the word at the ith position. F a is the father node  of the current preposition node. Ch is a child node of the current preposition node.", "labels": [], "entities": []}, {"text": " Table 7: Results of each stage in our system.  TNLM is the general module. \"+Det\" is the sys- tem containing the general module and determiner  part of special module.\"+Prep\" is the final system", "labels": [], "entities": [{"text": "TNLM", "start_pos": 48, "end_pos": 52, "type": "METRIC", "confidence": 0.5031697750091553}]}, {"text": " Table 8: Comparison for the general module  between TNLM and ordinary tri-gram language  model on the test data.", "labels": [], "entities": []}, {"text": " Table 9: Comparison for the special module on the  test data. The input of the special module is the  sentences corrected by the TNLM in the general  module.", "labels": [], "entities": [{"text": "TNLM", "start_pos": 130, "end_pos": 134, "type": "DATASET", "confidence": 0.8168929219245911}]}, {"text": " Table 10: Comparison of training using random  chosen sentences and selected sentences.", "labels": [], "entities": []}, {"text": " Table 11: Comparison of F 1 of different systems  on the test data .", "labels": [], "entities": [{"text": "F 1", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.9606600105762482}]}]}