{"title": [{"text": "Greed is Good if Randomized: New Inference for Dependency Parsing", "labels": [], "entities": [{"text": "Dependency Parsing", "start_pos": 47, "end_pos": 65, "type": "TASK", "confidence": 0.6186367124319077}]}], "abstractContent": [{"text": "Dependency parsing with high-order features results in a provably hard decoding problem.", "labels": [], "entities": []}, {"text": "A lot of work has gone into developing powerful optimization methods for solving these combinatorial problems.", "labels": [], "entities": []}, {"text": "In contrast, we explore, analyze, and demonstrate that a substantially simpler randomized greedy inference algorithm already suffices for near optimal parsing: a) we analytically quantify the number of local optima that the greedy method has to overcome in the context of first-order parsing ; b) we show that, as a decoding algorithm , the greedy method surpasses dual decomposition in second-order parsing; c) we empirically demonstrate that our approach with up to third-order and global features outperforms the state-of-the-art dual decomposition and MCMC sampling methods when evaluated on 14 languages of non-projective CoNLL datasets.", "labels": [], "entities": [{"text": "CoNLL datasets", "start_pos": 627, "end_pos": 641, "type": "DATASET", "confidence": 0.9584803581237793}]}], "introductionContent": [{"text": "Dependency parsing is typically guided by parameterized scoring functions that involve rich features exerting refined control over the choice of parse trees.", "labels": [], "entities": [{"text": "Dependency parsing", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9233779907226562}]}, {"text": "As a consequence, finding the highest scoring parse tree is a provably hard combinatorial inference problem).", "labels": [], "entities": []}, {"text": "Much of the recent work on parsing has focused on solving these problems using powerful optimization techniques.", "labels": [], "entities": [{"text": "parsing", "start_pos": 27, "end_pos": 34, "type": "TASK", "confidence": 0.9817699790000916}]}, {"text": "In this paper, we follow a different strategy, arguing that a much simpler inference strategy suffices.", "labels": [], "entities": []}, {"text": "In fact, we demonstrate that a randomized greedy method of inference surpasses the state-of-the-art performance in dependency parsing.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 115, "end_pos": 133, "type": "TASK", "confidence": 0.8442581593990326}]}, {"text": "Our choice of a randomized greedy algorithm for parsing follows from a successful track record of such methods in other hard combinatorial problems.", "labels": [], "entities": [{"text": "parsing", "start_pos": 48, "end_pos": 55, "type": "TASK", "confidence": 0.9709191918373108}]}, {"text": "These conceptually simple and intuitive algorithms have delivered competitive approximations across abroad class of NP-hard problems ranging from set cover to MAX-SAT ().", "labels": [], "entities": []}, {"text": "Their success is predicated on the observation that most realizations of problems are much easier to solve than the worst-cases.", "labels": [], "entities": []}, {"text": "A simpler algorithm will therefore suffice in typical cases.", "labels": [], "entities": []}, {"text": "Evidence is accumulating that parsing problems may exhibit similar properties.", "labels": [], "entities": [{"text": "parsing", "start_pos": 30, "end_pos": 37, "type": "TASK", "confidence": 0.9817476868629456}]}, {"text": "For instance, methods such as dual decomposition offer certificates of optimality when the highest scoring tree is found.", "labels": [], "entities": [{"text": "dual decomposition", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.9025455713272095}]}, {"text": "Across languages, dual decomposition has shown to lead to a certificate of optimality for the vast majority of the sentences ().", "labels": [], "entities": [{"text": "dual decomposition", "start_pos": 18, "end_pos": 36, "type": "TASK", "confidence": 0.9458930492401123}]}, {"text": "These remarkable results suggest that, as a combinatorial problem, parsing appears simpler than its broader complexity class would suggest.", "labels": [], "entities": []}, {"text": "Indeed, we show that a simpler inference algorithm already suffices for superior results.", "labels": [], "entities": []}, {"text": "In this paper, we introduce a randomized greedy algorithm that can be easily used with any rich scoring function.", "labels": [], "entities": []}, {"text": "Starting with an initial tree drawn uniformly at random, the algorithm makes only local myopic changes to the parse tree in an attempt to climb the objective function.", "labels": [], "entities": []}, {"text": "While a single run of the hill-climbing algorithm may indeed get stuck in a locally optimal solution, multiple random restarts can help to overcome this problem.", "labels": [], "entities": []}, {"text": "The same algorithm is used both for learning the parameters of the scoring function as well as for parsing test sentences.", "labels": [], "entities": [{"text": "parsing test sentences", "start_pos": 99, "end_pos": 121, "type": "TASK", "confidence": 0.8746522267659506}]}, {"text": "The success of a randomized greedy algorithm is tied to the number of local maxima in the search space.", "labels": [], "entities": []}, {"text": "When the number is small, only a few restarts will suffice for the greedy algorithm to find the highest scoring parse.", "labels": [], "entities": []}, {"text": "We provide an al-gorithm for explicitly counting the number of local optima in the context of first-order parsing, and demonstrate that the number is typically quite small.", "labels": [], "entities": []}, {"text": "Indeed, we find that a first-order parser trained with exact inference or using our randomized greedy algorithm delivers basically the same performance.", "labels": [], "entities": []}, {"text": "We hypothesize that parsing with high-order scoring functions exhibits similar properties.", "labels": [], "entities": [{"text": "parsing", "start_pos": 20, "end_pos": 27, "type": "TASK", "confidence": 0.9741786122322083}]}, {"text": "The main rationale is that, even in the presence of highorder features, the resulting scoring function remains first-order dominant.", "labels": [], "entities": []}, {"text": "The performance of a simple arc-factored first-order parser is only a few percentage points behind higher-order parsers.", "labels": [], "entities": []}, {"text": "The higher-order features in the scoring function offer additional refinement but only a few changes above and beyond the first-order result.", "labels": [], "entities": []}, {"text": "As a consequence, most of the arc choices are already determined by a much simpler, polynomial time parser.", "labels": [], "entities": []}, {"text": "We use dual decomposition to show that the greedy method indeed succeeds as an inference algorithm even with higher-order scoring functions.", "labels": [], "entities": []}, {"text": "In fact, with second-order features, regardless of which method was used for training, the randomized greedy method outperforms dual decomposition by finding higher scoring trees.", "labels": [], "entities": []}, {"text": "For the sentences that dual decomposition is optimal (obtains a certificate), the greedy method finds the same solution in over 99% of the cases.", "labels": [], "entities": []}, {"text": "Our simple inference algorithm is therefore likely to scale to higher-order parsing and we demonstrate empirically that this is indeed so.", "labels": [], "entities": []}, {"text": "We validate our claim by evaluating the method on the CoNLL dependency benchmark that comprises treebanks from 14 languages.", "labels": [], "entities": [{"text": "CoNLL dependency benchmark", "start_pos": 54, "end_pos": 80, "type": "DATASET", "confidence": 0.8390346169471741}]}, {"text": "Averaged across all languages, our method outperforms state-of-the-art parsers, including TurboParser () and our earlier sampling-based parser ( ).", "labels": [], "entities": []}, {"text": "On seven languages, we report the best published results.", "labels": [], "entities": []}, {"text": "The method is not sensitive to initialization.", "labels": [], "entities": [{"text": "initialization", "start_pos": 31, "end_pos": 45, "type": "TASK", "confidence": 0.967190682888031}]}, {"text": "In fact, drawing the initial tree uniformly at random results in the same performance as when initialized from a trained first-order distribution.", "labels": [], "entities": []}, {"text": "In contrast, sufficient randomization of the starting point is critical.", "labels": [], "entities": []}, {"text": "Only a small number of restarts suffices for finding (near) optimal parse trees.", "labels": [], "entities": []}], "datasetContent": [{"text": "Dataset and Evaluation Measures We evaluate our model on CoNLL dependency treebanks for 14 different languages (, using standard training and testing splits.", "labels": [], "entities": [{"text": "CoNLL dependency treebanks", "start_pos": 57, "end_pos": 83, "type": "DATASET", "confidence": 0.8213090499242147}]}, {"text": "We use part-of-speech tags and the morphological information provided in the corpus.", "labels": [], "entities": []}, {"text": "Following standard practice, we use Unlabeled Attachment Score (UAS) excluding punctuation ( as the evaluation metric in all our experiments.", "labels": [], "entities": [{"text": "Unlabeled Attachment Score (UAS)", "start_pos": 36, "end_pos": 68, "type": "METRIC", "confidence": 0.8452362020810446}]}, {"text": "Baselines We compare our model with the TurboParser () and our earlier sampling-based parser ( ).", "labels": [], "entities": []}, {"text": "For both parsers, we directly compare with the recent published results on the CoNLL datasets.", "labels": [], "entities": [{"text": "CoNLL datasets", "start_pos": 79, "end_pos": 93, "type": "DATASET", "confidence": 0.9755405783653259}]}, {"text": "We also compare our parser against the best published results for the individual languages in our datasets.", "labels": [], "entities": []}, {"text": "This comparison set includes four additional parsers: Martins et al.", "labels": [], "entities": []}, {"text": "(2011),, and our tensor-based parser ( ).", "labels": [], "entities": []}, {"text": "Features We use the same feature templates as in our prior work ( . shows the first-to third-order feature templates that we use in our model.", "labels": [], "entities": []}, {"text": "For the global features we use right-branching, coordination, PP attachment, span length, neighbors, valency and non-projective arcs features.", "labels": [], "entities": []}, {"text": "Implementation Details Following standard practices, we train our model using the passiveaggressive online learning algorithm (MIRA) and parameter averaging; We refer the readers to  and  for the detailed definition of each feature template.).", "labels": [], "entities": [{"text": "Implementation", "start_pos": 0, "end_pos": 14, "type": "METRIC", "confidence": 0.9145498871803284}]}, {"text": "By default we use an adaptive strategy for running the hill-climbing algorithm -for a given sentence we repeatedly run the algorithm in parallel 5 until the best tree does not change for K = 300 consecutive restarts.", "labels": [], "entities": []}, {"text": "For each restart, by default we initialize the tree y (0) by sampling from the first-order distribution using the current learned parameter values (and firstorder scores).", "labels": [], "entities": []}, {"text": "We train our first-order and thirdorder model for 10 epochs and our full model for 20 epochs for all languages, and report the average performance across three independent runs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Head attachment accuracy of a first-order  local classifier (left) and a first-order structural  prediction model (right). The two types of mod- els are trained using the same set of features.", "labels": [], "entities": [{"text": "Head attachment", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.6410033404827118}, {"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9436248540878296}]}, {"text": " Table 2: The left part of the table shows the local optimum statistics of the first-order model. The  sentences are sorted by the number of local optima. Columns 3 to 5 show the number of local optima of  a sentence at different percentile of the sorted list. For example, on English 50% of the sentences have  no more than 21 local optimum trees. The right part shows the fraction of finding global optima using  300 uniform restarts for each sentence.", "labels": [], "entities": []}, {"text": " Table 3: Decoding quality comparison between hill-climbing (HC) and dual decomposition (DD). Mod- els are trained either with HC (left) or DD (right). s HC denotes the score of the tree retrieved by HC  and s DD gives the analogous score for DD. The columns show the percentage of all test sentences for  which one method succeeds in finding a higher or the same score. \"Cert\" column gives the percentage  of sentences for which DD finds a certificate.", "labels": [], "entities": []}, {"text": " Table 4: Results of our model and several state-of-the-art systems. \"Best Published UAS\" includes the  most accurate parsers among Martins et al. (2011), Martins et al. (2013), Koo et al. (2010), Zhang et  al. (2013), Lei et al. (2014) and Zhang et al. (2014). For the third-order model, we use the feature set  of TurboParser (Martins et al., 2013). The full model combines features of our sampling-based parser  (Zhang et al., 2014) and tensor features (Lei et al., 2014).", "labels": [], "entities": []}, {"text": " Table 5: Comparison between different initializa- tion strategies: (a) MAP-1st: only the MAP tree  of the first-order score; (b) Uniform: random trees  are sampled from the uniform distribution; and  (c) Rnd-1st: random trees are sampled from the  first-order distribution. For each method, the table  shows the average accuracy of the initial tree and  the final parsing accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 321, "end_pos": 329, "type": "METRIC", "confidence": 0.9960673451423645}, {"text": "accuracy", "start_pos": 373, "end_pos": 381, "type": "METRIC", "confidence": 0.48426294326782227}]}, {"text": " Table 6: Fractions (%) of the sentences that find  the best solution among 3,000 restarts within the  first 300 restarts.", "labels": [], "entities": [{"text": "Fractions", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9793166518211365}]}]}