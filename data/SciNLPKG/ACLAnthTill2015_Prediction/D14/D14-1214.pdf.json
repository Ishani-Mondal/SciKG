{"title": [{"text": "Major Life Event Extraction from Twitter based on Congratulations/Condolences Speech Acts", "labels": [], "entities": [{"text": "Major Life Event Extraction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.5740205645561218}]}], "abstractContent": [{"text": "Social media websites provide a platform for anyone to describe significant events taking place in their lives in realtime.", "labels": [], "entities": []}, {"text": "Currently, the majority of personal news and life events are published in a tex-tual format, motivating information extraction systems that can provide a struc-tured representations of major life events (weddings, graduation, etc.. .).", "labels": [], "entities": []}, {"text": "This paper demonstrates the feasibility of accurately extracting major life events.", "labels": [], "entities": [{"text": "extracting major life events", "start_pos": 54, "end_pos": 82, "type": "TASK", "confidence": 0.8444417268037796}]}, {"text": "Our system extracts a fine-grained description of users' life events based on their published tweets.", "labels": [], "entities": []}, {"text": "We are optimistic that our system can help Twitter users more easily grasp information from users they take interest in following and also facilitate many downstream applications, for example re-altime friend recommendation.", "labels": [], "entities": [{"text": "re-altime friend recommendation", "start_pos": 192, "end_pos": 223, "type": "TASK", "confidence": 0.6637944877147675}]}], "introductionContent": [{"text": "Social networking websites such as Facebook and Twitter have recently challenged mainstream media as the freshest source of information on important news events.", "labels": [], "entities": []}, {"text": "In addition to an important source for breaking news, social media presents a unique source of information on private events, for example a friend's engagement or college graduation (examples are presented in).", "labels": [], "entities": []}, {"text": "While a significant amount of previous work has investigated event extraction from Twitter (e.g.,), existing approaches mostly focus on public bursty event extraction, and little progress has been made towards the problem of automatically extracting the major life events of ordinary users.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 61, "end_pos": 77, "type": "TASK", "confidence": 0.7080295830965042}, {"text": "public bursty event extraction", "start_pos": 136, "end_pos": 166, "type": "TASK", "confidence": 0.6197861060500145}]}, {"text": "A system which can automatically extract major life events and generate fine-grained descriptions as in will not only help Twitter users with the problem of information overload by summarizing important events taking place in their friends lives, but could also facilitate downstream applications such as friend recommendation (e.g., friend recommendation in realtime to people who were just admitted into the same university, get the same jobs or internships), targeted online advertising (e.g., recommend baby care products to newly expecting mothers, or wedding services to new couples), information extraction, etc.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 591, "end_pos": 613, "type": "TASK", "confidence": 0.8116025328636169}]}, {"text": "Before getting started, we first identify a number of key challenges in extracting significant life events from user-generated text, which account the reason for the lack of previous work in this area:", "labels": [], "entities": []}], "datasetContent": [{"text": "While our seed patterns for identifying messages expressing CONGRATULATIONS and CON-DOLENCES are very high precision, they don't coverall the possible ways these speech acts can be expressed.", "labels": [], "entities": [{"text": "precision", "start_pos": 107, "end_pos": 116, "type": "METRIC", "confidence": 0.9918493032455444}]}, {"text": "We therefore adopt a semisupervised bootstrapping approach to expand our reply seeds and event-related tweets.", "labels": [], "entities": []}, {"text": "Our bootstrapping approach is related to previous work on semi-supervised information harvesting (e.g.,).", "labels": [], "entities": [{"text": "information harvesting", "start_pos": 74, "end_pos": 96, "type": "TASK", "confidence": 0.714549332857132}]}, {"text": "To preserve the labeled topics from the first iteration, we apply a streaming approach to inference) over unlabeled tweets (those which did not match one of the response congratulations (cong, congrats); (that's) fantastic; (so) cool; (I'm) (very) sorry to hear that; (that's) great (good) new; awesome; what a pity; have fun; great; that sucks; too bad; (that's) unfortunate; how sad; fabulous; (that's) terrific; (that's) (so) wonderful; my deepest condolences;: Responses retrieved from Bootstrapping. seeds).", "labels": [], "entities": [{"text": "Bootstrapping. seeds", "start_pos": 490, "end_pos": 510, "type": "DATASET", "confidence": 0.9505157470703125}]}, {"text": "We collect responses to the newly added tweets, then select the top 20 frequent replies 5 . Next we manually inspect and filter the top ranked replies, and use them to harvest more tweets.", "labels": [], "entities": []}, {"text": "This process is then repeated with another round of inference in LDA including manual labeling of newly inferred topics, etc...", "labels": [], "entities": []}, {"text": "An illustration of our approach is presented in and the details are presented in.", "labels": [], "entities": []}, {"text": "The algorithm outputs a collection of personal life topics L, and a collection of retrieved tweets D.", "labels": [], "entities": []}, {"text": "Each tweet d \u2208 Dis associated with a life event topic l, l \u2208 L.", "labels": [], "entities": []}, {"text": "We repeat the bootstrapping process for 4 iterations and end up with 30 different CONGRATU-LATIONS and CONDOLENCES patterns (shown in) and 42 coherent event types which refer to significant life events (statistics for harvested data from each step is shown in).", "labels": [], "entities": []}, {"text": "We show examples of the mined topics with correspondent human labels in, grouped according to a specific kind of resemblance.", "labels": [], "entities": []}, {"text": "The evaluation for each part of our system has been demonstrated in the corresponding section.", "labels": [], "entities": []}, {"text": "We now present a real-world evaluation: to what degree can our trained system automatically identify life events in real world.", "labels": [], "entities": []}, {"text": "We constructed a gold-standard life event dataset using annotators from Amazon's Mechanical Turk (: Labeling Event Property.", "labels": [], "entities": []}, {"text": "\u2022 Ask Twitter users to label their own tweets (Participants include friends, colleagues of the authors and Turkers from Amazon Mechanical Turk 13 ).", "labels": [], "entities": [{"text": "Turkers from Amazon Mechanical Turk 13", "start_pos": 107, "end_pos": 145, "type": "DATASET", "confidence": 0.6836391985416412}]}, {"text": "\u2022 Ask Turkers to label other people's tweets.", "labels": [], "entities": []}, {"text": "For option 1, we asked participants to directly label their own published tweets.", "labels": [], "entities": []}, {"text": "For option 2, for each tweet, we employed 2 Turkers.", "labels": [], "entities": []}, {"text": "Due to the ambiguity in defining life events, the value cohen's kappa 14 as a measure of inter-rater agreement is 0.54; this does not show significant interannotator agreement.", "labels": [], "entities": []}, {"text": "The authors examined disagreements and also verified all positively labeled tweets.", "labels": [], "entities": []}, {"text": "The resulting dataset contains around 900 positive tweets and about 60,000 negative tweets.", "labels": [], "entities": []}, {"text": "To demonstrate the advantage of leveraging large quantities of unlabeled data, the first baseline we investigate is a Supervised model which is trained on the manually annotated labeled dataset, and evaluated using 5 fold cross validation.", "labels": [], "entities": []}, {"text": "Our Supervised baseline consists of a linear SVM classifier using bag of words, NER and POS features.", "labels": [], "entities": []}, {"text": "We also tested a second baseline that combines Supervised algorithm with an our selfreported information classifier, denoted as Supervised+Self.", "labels": [], "entities": []}, {"text": "Results are reported in; as we can observe, the fully supervised approach is not suitable for this task with only one digit F1 score.", "labels": [], "entities": [{"text": "F1 score", "start_pos": 124, "end_pos": 132, "type": "METRIC", "confidence": 0.9749441742897034}]}, {"text": "The explanations are as follows: (1) the labeled data can only cover a small proportion of life events (2) supervised learning does not separate important event categories and will therefore classify any tweet with highly weighted features (e.g., the mention of \"I\" or \"marriage\") as positive.", "labels": [], "entities": []}, {"text": "By using an additional self-reported information classifier in Supervised+Self, we get a significant boost in precision with a minor recall loss.: Performance for different steps of bootstrapping for identifying life events in real world.", "labels": [], "entities": [{"text": "precision", "start_pos": 110, "end_pos": 119, "type": "METRIC", "confidence": 0.999481737613678}, {"text": "recall", "start_pos": 133, "end_pos": 139, "type": "METRIC", "confidence": 0.9990278482437134}]}, {"text": "Another interesting question is to what degree the bootstrapping contributes to the final results.", "labels": [], "entities": []}, {"text": "We keep the self-reported information classifier fixed (though it's based the ultimate identified data source), and train the personal event classifier based on topic distributions identified from each of the three steps of bootstrapping . Precision and recall at various stages of bootstrapping are presented in.", "labels": [], "entities": [{"text": "recall", "start_pos": 254, "end_pos": 260, "type": "METRIC", "confidence": 0.9971954822540283}]}, {"text": "As bootstrapping continues, the precision remains roughly constant, but recall increases as more life events and CONGRATULA-TIONS and CONDOLENCES are discovered.", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9995220899581909}, {"text": "recall", "start_pos": 72, "end_pos": 78, "type": "METRIC", "confidence": 0.9996019005775452}, {"text": "CONGRATULA-TIONS", "start_pos": 113, "end_pos": 129, "type": "METRIC", "confidence": 0.965256929397583}, {"text": "CONDOLENCES", "start_pos": 134, "end_pos": 145, "type": "METRIC", "confidence": 0.7378063797950745}]}], "tableCaptions": [{"text": " Table 2: List of automatically discovered life event  types with percentage (%) of data covered.", "labels": [], "entities": []}, {"text": " Table 4. And as we can observe, the dictionary  (with probability) contributes a lot to the perfor- mance and by taking into account a more compre- hensive set of information around the key word,  classifier on All feature setting generate signifi- cantly better performance, with 0.382 prevision  and 0.48 recall, which is acceptable considering  (1) This is is a 43-way classification with much  more negative data than positive (2) Some types of  events are very close to each other (e.g., Leaving  and Vocation). Note that recall is valued more than  precision here as false-positive examples will be  further screened in self-reported information iden- tification process in the following section.", "labels": [], "entities": [{"text": "recall", "start_pos": 308, "end_pos": 314, "type": "METRIC", "confidence": 0.9981120824813843}, {"text": "recall", "start_pos": 528, "end_pos": 534, "type": "METRIC", "confidence": 0.9989998936653137}, {"text": "precision", "start_pos": 556, "end_pos": 565, "type": "METRIC", "confidence": 0.9990678429603577}]}, {"text": " Table 4: Average Performance of Multi-Class  Classifier on Different Feature Settings. Negative  examples (non important event type) are not con- sidered.", "labels": [], "entities": []}, {"text": " Table 5: Performance for self-report information  identification regarding different feature settings.", "labels": [], "entities": [{"text": "self-report information  identification", "start_pos": 26, "end_pos": 65, "type": "TASK", "confidence": 0.6884204943974813}]}, {"text": " Table 6: Labeling Event Property.", "labels": [], "entities": [{"text": "Labeling Event Property", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.911513110001882}]}, {"text": " Table 8: Performance for different approaches for  identifying life events in real world.", "labels": [], "entities": []}, {"text": " Table 9: Performance for different steps of boot- strapping for identifying life events in real world.", "labels": [], "entities": []}]}