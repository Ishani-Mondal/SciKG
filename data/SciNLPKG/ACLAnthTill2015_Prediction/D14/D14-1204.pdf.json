{"title": [{"text": "Automatic Inference of the Tense of Chinese Events Using Implicit Linguistic Information", "labels": [], "entities": [{"text": "Automatic Inference of the Tense of Chinese Events", "start_pos": 0, "end_pos": 50, "type": "TASK", "confidence": 0.8286332003772259}]}], "abstractContent": [{"text": "We address the problem of automatically inferring the tense of events in Chinese text.", "labels": [], "entities": [{"text": "automatically inferring the tense of events", "start_pos": 26, "end_pos": 69, "type": "TASK", "confidence": 0.7132402509450912}]}, {"text": "We use anew corpus annotated with Chinese semantic tense information and other implicit Chinese linguistic information using a \"distant annotation\" method.", "labels": [], "entities": []}, {"text": "We propose three improvements over a relatively strong baseline method-a statistical learning method with extensive feature engineering.", "labels": [], "entities": []}, {"text": "First, we add two sources of implicit linguistic information as features eventuality type and modality of an event, which are also inferred automatically.", "labels": [], "entities": []}, {"text": "Second, we perform joint learning on semantic tense, eventuality type, and modality of an event.", "labels": [], "entities": []}, {"text": "Third, we train artificial neural network models for this problem and compare its performance with feature-based approaches.", "labels": [], "entities": []}, {"text": "Experimental results show considerable improvements on Chinese tense inference.", "labels": [], "entities": [{"text": "Chinese tense inference", "start_pos": 55, "end_pos": 78, "type": "TASK", "confidence": 0.7781736254692078}]}, {"text": "Our best performance reaches 68.6% inaccuracy, out-performing a strong baseline method.", "labels": [], "entities": [{"text": "inaccuracy", "start_pos": 35, "end_pos": 45, "type": "METRIC", "confidence": 0.9511497616767883}]}], "introductionContent": [{"text": "As a language with no grammatical tense, Chinese does not encode the temporal location of an event directly in a verb, while in English, the grammatical tense of a verb is a strong indicator of the temporal location of an event.", "labels": [], "entities": []}, {"text": "In this paper we address the problem of inferring the semantic tense, or the temporal location of an event (e.g., present, past, future) in Chinese text.", "labels": [], "entities": []}, {"text": "The semantic tense is defined relative to the utterance time or document creation time, and it does not always agree with the grammatical tense in languages like English where there is grammatical tense.", "labels": [], "entities": []}, {"text": "Inferring semantic tense potentially benefits natural language processing tasks such as Machine Translation and Information Extraction), but previous work has shown that automatic inference of the semantic tense of events in Chinese is a very challenging task;.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 88, "end_pos": 107, "type": "TASK", "confidence": 0.7929582893848419}, {"text": "Information Extraction", "start_pos": 112, "end_pos": 134, "type": "TASK", "confidence": 0.7098632156848907}, {"text": "automatic inference of the semantic tense of events", "start_pos": 170, "end_pos": 221, "type": "TASK", "confidence": 0.723224826157093}]}, {"text": "There are at least two reasons why this is a difficult problem.", "labels": [], "entities": []}, {"text": "First, since Chinese does not have grammatical tense which could serve as an important clue when annotating the semantic tense of an event, generating consistent annotation for Chinese semantic tense has proved to be a challenge.", "labels": [], "entities": []}, {"text": "use a \"distant annotation\" method to address this problem.", "labels": [], "entities": []}, {"text": "They take advantage of an English-Chinese parallel corpus with manual word alignments ( , and perform annotation on the English side, which provides more explicit information such as grammatical tense that helps annotators decide the appropriate semantic tense.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 70, "end_pos": 85, "type": "TASK", "confidence": 0.7549019157886505}]}, {"text": "The annotations are then projected to the Chinese side via the word alignments.", "labels": [], "entities": []}, {"text": "They show consistent annotation agreements on semantic tense.", "labels": [], "entities": []}, {"text": "Second, the lack of grammatical tense also makes automatic inference of Chinese semantic tense challenging since the grammatical tense would bean important source of information for predicting the semantic tense.", "labels": [], "entities": []}, {"text": "Previous work has shown that it is very difficult to achieve high accuracy using standard machine learning techniques such as Maximum Entropy and Conditional Random Field classifiers combined with extensive feature engineering.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.990453839302063}]}, {"text": "We address these challenges in two ways.", "labels": [], "entities": []}, {"text": "First of all, we take advantage of the newly annotated corpus described in) in which semantic tense is annotated together with eventuality type and modality using the distant annotation method.", "labels": [], "entities": []}, {"text": "This makes it possible to use these two additional sources of information to help predict tense.", "labels": [], "entities": []}, {"text": "Eventuality type and modality are intricately tied to tense.", "labels": [], "entities": []}, {"text": "For example, show that states by default hold in the present but (episodic) events occur by default in the past.", "labels": [], "entities": []}, {"text": "This means knowing the eventuality type of an event would help determine the tense.", "labels": [], "entities": []}, {"text": "Eventuality type and modality are also annotated on the English side and then projected onto the Chinese side via manual word alignments, taking advantage of the rich morphosyntactic clues in English.", "labels": [], "entities": []}, {"text": "High inter-annotator agreement scores are also reported on eventuality type and modality.", "labels": [], "entities": []}, {"text": "We experimented with two ways of using eventuality type and modality information.", "labels": [], "entities": []}, {"text": "In the first approach, we first train statistical machine learning models to predict eventuality type and modality and then use these two sources of information as features to predict semantic tense.", "labels": [], "entities": []}, {"text": "In the second approach we trained joint learning models between semantic tense and eventuality type, and between semantic tense and modality.", "labels": [], "entities": []}, {"text": "We show both approaches improve the tense inference accuracy over a baseline where these two sources of information are not used.", "labels": [], "entities": [{"text": "tense inference", "start_pos": 36, "end_pos": 51, "type": "TASK", "confidence": 0.7785382866859436}, {"text": "accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9651232361793518}]}, {"text": "Second, in our statistical machine learning experiments on tense inference using feature engineering, we find that the design of feature templates has great influence on the results.", "labels": [], "entities": [{"text": "tense inference", "start_pos": 59, "end_pos": 74, "type": "TASK", "confidence": 0.806067943572998}]}, {"text": "So in order to explore more possible feature combinations and mitigate the feature engineering work, we apply artificial neural network models to this problem.", "labels": [], "entities": []}, {"text": "This shows improvements on tense inference accuracy as well in some of the experiment settings.", "labels": [], "entities": [{"text": "tense inference", "start_pos": 27, "end_pos": 42, "type": "TASK", "confidence": 0.7936083674430847}, {"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9473217725753784}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses related work in automatic tense inference.", "labels": [], "entities": [{"text": "automatic tense inference", "start_pos": 36, "end_pos": 61, "type": "TASK", "confidence": 0.7146129806836446}]}, {"text": "Section 3 briefly introduces the distant annotation method.", "labels": [], "entities": []}, {"text": "In section 4, we describe our experiments and analyze the experimental results.", "labels": [], "entities": []}, {"text": "We conclude this paper in section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "Xue and Zhang (2014) annotated semantic tense, eventuality type and modality on top of the Parallel Aligned Treebank (), a corpus of word-aligned Chinese-English sentences treebanked based on the Penn TreeBank () and the Chinese TreeBank () standards.", "labels": [], "entities": [{"text": "Penn TreeBank", "start_pos": 196, "end_pos": 209, "type": "DATASET", "confidence": 0.9930738210678101}, {"text": "Chinese TreeBank", "start_pos": 221, "end_pos": 237, "type": "DATASET", "confidence": 0.9612654745578766}]}, {"text": "Human annotation of tense is performed on the newswire and webblog sections of this corpus.", "labels": [], "entities": []}, {"text": "They report that the average pairwise agreement among three annotators consistently stays above 80% and the average Kappa score consistently exceeds 70%, indicating reliable annotation.", "labels": [], "entities": [{"text": "agreement", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.7137207984924316}, {"text": "Kappa score", "start_pos": 116, "end_pos": 127, "type": "METRIC", "confidence": 0.9563017189502716}]}, {"text": "Apart from using the entire corpus, we also conducted experiments on three different subsets of the corpus.", "labels": [], "entities": []}, {"text": "An examination of the data indicates that newswire data is grammatically more formal and complete than webblog data, so we also conducted separate experiments on newswire data only.", "labels": [], "entities": []}, {"text": "Considering that the diversity of the parts of speech of the events may affect the inference accuracy and that most of our features extracted from the parse trees assume that our events being verbs, we also conducted experiments exclusively on \"v events\".", "labels": [], "entities": [{"text": "accuracy", "start_pos": 93, "end_pos": 101, "type": "METRIC", "confidence": 0.9906896352767944}]}, {"text": "\"v events\" consist of two parts.", "labels": [], "entities": []}, {"text": "One part is events that are realized as a single word and the word is a verb; the other one is events which have multiple words but there is only one verb among them.", "labels": [], "entities": []}, {"text": "In the latter case, we stripped off words tagged with other parts of speech and only keep the verbs as events.", "labels": [], "entities": []}, {"text": "This makes it more effective to use features from previous work that are designed for single verbs.", "labels": [], "entities": []}, {"text": "One such feature is the aspect marker.", "labels": [], "entities": []}, {"text": "Distinctions between newswire and webblog data and between v events and other events are further explored in Section 5.1 and Section 5.2.", "labels": [], "entities": []}, {"text": "For each subset, randomly selected 80% were used as the training set, while 10% were used as the development set and 10% were used as the test set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1 presents the statistics for each  subset of the experimental data.", "labels": [], "entities": []}, {"text": " Table 5: Accuracy of tense inference on v events.  Best performances for each group of methods are  in bold.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9919012188911438}, {"text": "tense inference", "start_pos": 22, "end_pos": 37, "type": "TASK", "confidence": 0.6066819876432419}]}, {"text": " Table 6: Accuracy of tense inference on all events.  Best performances for each group of methods are  in bold.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9952955842018127}, {"text": "tense inference", "start_pos": 22, "end_pos": 37, "type": "TASK", "confidence": 0.663616418838501}]}, {"text": " Table 7: Tense inference error rates for different  error types on newswire v events test set.", "labels": [], "entities": [{"text": "newswire v events test set", "start_pos": 68, "end_pos": 94, "type": "DATASET", "confidence": 0.8775803685188294}]}]}