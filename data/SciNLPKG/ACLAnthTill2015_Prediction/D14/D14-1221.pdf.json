{"title": [{"text": "Recall Error Analysis for Coreference Resolution", "labels": [], "entities": [{"text": "Recall Error Analysis", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.856743057568868}, {"text": "Coreference Resolution", "start_pos": 26, "end_pos": 48, "type": "TASK", "confidence": 0.9731585383415222}]}], "abstractContent": [{"text": "We present a novel method for coreference resolution error analysis which we apply to perform a recall error analysis of four state-of-the-art English coreference resolution systems.", "labels": [], "entities": [{"text": "coreference resolution error analysis", "start_pos": 30, "end_pos": 67, "type": "TASK", "confidence": 0.9378869831562042}, {"text": "recall", "start_pos": 96, "end_pos": 102, "type": "METRIC", "confidence": 0.9431535005569458}, {"text": "coreference resolution", "start_pos": 151, "end_pos": 173, "type": "TASK", "confidence": 0.7873027920722961}]}, {"text": "Our analysis highlights differences between the systems and identifies that the majority of recall errors for nouns and names are shared by all systems.", "labels": [], "entities": [{"text": "recall", "start_pos": 92, "end_pos": 98, "type": "METRIC", "confidence": 0.9904043674468994}]}, {"text": "We characterize this set of common challenging errors in terms of abroad range of lexical and semantic properties.", "labels": [], "entities": []}], "introductionContent": [{"text": "Coreference resolution is the task of determining which mentions in a text refer to the same entity.", "labels": [], "entities": [{"text": "Coreference resolution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9178739488124847}]}, {"text": "State-of-the-art approaches include both learningbased) and deterministic models (.", "labels": [], "entities": []}, {"text": "These approaches achieve state-of-the-art performance mainly relying on morphosyntactic and lexical factors.", "labels": [], "entities": []}, {"text": "However, consider the following example.", "labels": [], "entities": []}, {"text": "In order to improving the added value of oil products, the second phase project of the Qinghai Petroleum Bureau's Ge'ermu oil refinery has been put into production.", "labels": [], "entities": [{"text": "Qinghai Petroleum Bureau's Ge'ermu oil refinery", "start_pos": 87, "end_pos": 134, "type": "DATASET", "confidence": 0.8305626085826329}]}, {"text": "This will further improve the factory's oil products structure.", "labels": [], "entities": []}, {"text": "Due to the lack of any string overlap, most state-of-the-art systems will miss the link between the factory and the Qinghai Petroleum Bureau's Ge'ermu oil refinery.", "labels": [], "entities": [{"text": "Qinghai Petroleum Bureau's Ge'ermu oil refinery", "start_pos": 116, "end_pos": 163, "type": "DATASET", "confidence": 0.8576984831265041}]}, {"text": "The information that factory is a hypernym of refinery, however, maybe useful to resolve such links.", "labels": [], "entities": []}, {"text": "The aim of this paper is to quantify and characterize such recall errors made by state-of-theart coreference resolution systems.", "labels": [], "entities": [{"text": "recall", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9378970265388489}, {"text": "coreference resolution", "start_pos": 97, "end_pos": 119, "type": "TASK", "confidence": 0.7828333377838135}]}, {"text": "By doing so, we provide a solid foundation for work on employing knowledge sources for improving recall for coreference resolution (, inter alia).", "labels": [], "entities": [{"text": "recall", "start_pos": 97, "end_pos": 103, "type": "METRIC", "confidence": 0.9951516389846802}, {"text": "coreference resolution", "start_pos": 108, "end_pos": 130, "type": "TASK", "confidence": 0.9712145924568176}]}, {"text": "In particular, we make the following contributions: We present a novel framework for coreference resolution error analysis.", "labels": [], "entities": [{"text": "coreference resolution error analysis", "start_pos": 85, "end_pos": 122, "type": "TASK", "confidence": 0.9387349635362625}]}, {"text": "This yields a formal foundation for previous work on link-based error analysis and complements work on transformation-based error analysis (.", "labels": [], "entities": [{"text": "link-based error analysis", "start_pos": 53, "end_pos": 78, "type": "TASK", "confidence": 0.5899720291296641}, {"text": "transformation-based error analysis", "start_pos": 103, "end_pos": 138, "type": "TASK", "confidence": 0.673224002122879}]}, {"text": "We apply the method proposed in this paper to perform a recall error analysis of four state-ofthe-art systems, encompassing deterministic and learning-based approaches.", "labels": [], "entities": [{"text": "recall error", "start_pos": 56, "end_pos": 68, "type": "METRIC", "confidence": 0.9380050897598267}]}, {"text": "In particular, we identify and characterize a set of challenging errors common to all systems, and discuss strengths and weaknesses of each system regarding specific error types.", "labels": [], "entities": []}, {"text": "We also present a brief precision error analysis.", "labels": [], "entities": [{"text": "precision error analysis", "start_pos": 24, "end_pos": 48, "type": "METRIC", "confidence": 0.9179492592811584}]}, {"text": "A toolkit which implements the framework proposed in this paper is available for download.", "labels": [], "entities": []}], "datasetContent": [{"text": "Previous studies identified the presence of recall errors as a main bottleneck for improving performance (.", "labels": [], "entities": [{"text": "recall errors", "start_pos": 44, "end_pos": 57, "type": "METRIC", "confidence": 0.9754900634288788}]}, {"text": "This is also evidenced by the CoNLL shared tasks on coreference resolution, where most competitive systems had higher precision than recall.", "labels": [], "entities": [{"text": "coreference resolution", "start_pos": 52, "end_pos": 74, "type": "TASK", "confidence": 0.9722498655319214}, {"text": "precision", "start_pos": 118, "end_pos": 127, "type": "METRIC", "confidence": 0.9947125911712646}, {"text": "recall", "start_pos": 133, "end_pos": 139, "type": "METRIC", "confidence": 0.99216228723526}]}, {"text": "This indicates that an analysis of recall errors helps to understand and improve the state of the art.", "labels": [], "entities": [{"text": "recall", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9938905239105225}]}, {"text": "Hence, we focus on analyzing recall errors, and complement this by a brief analysis of precision errors.", "labels": [], "entities": [{"text": "recall", "start_pos": 29, "end_pos": 35, "type": "METRIC", "confidence": 0.9916025996208191}, {"text": "precision errors", "start_pos": 87, "end_pos": 103, "type": "METRIC", "confidence": 0.9743431210517883}]}, {"text": "We analyze errors of the four systems presented in the previous section on the CoNLL'12 English development data.", "labels": [], "entities": [{"text": "CoNLL'12 English development data", "start_pos": 79, "end_pos": 112, "type": "DATASET", "confidence": 0.9660920053720474}]}, {"text": "To extract recall errors we employ the spanning tree algorithm which chooses edges by accessibility.", "labels": [], "entities": [{"text": "recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9911013841629028}]}, {"text": "We obtain precision errors from the pairwise output of the systems.", "labels": [], "entities": [{"text": "precision errors", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.9786160588264465}]}], "tableCaptions": [{"text": " Table 1: Comparison of the systems with Fernan- des et al. (2012) and with Martschat (2013) on  CoNLL'12 English development data.", "labels": [], "entities": [{"text": "CoNLL'12 English development data", "start_pos": 97, "end_pos": 130, "type": "DATASET", "confidence": 0.9154093414545059}]}, {"text": " Table 2: Number of StanfordSieve's recall er- rors according to mention type, compared to the  maximum possible number of errors. Rows are  anaphors, columns antecedents.", "labels": [], "entities": [{"text": "StanfordSieve's", "start_pos": 20, "end_pos": 35, "type": "DATASET", "confidence": 0.9440012574195862}, {"text": "recall er- rors", "start_pos": 36, "end_pos": 51, "type": "METRIC", "confidence": 0.7475936263799667}]}, {"text": " Table 3: Recall error numbers for all systems.", "labels": [], "entities": [{"text": "Recall error numbers", "start_pos": 10, "end_pos": 30, "type": "METRIC", "confidence": 0.8138689398765564}]}, {"text": " Table 4: Name/Noun recall errors for all systems.", "labels": [], "entities": [{"text": "recall errors", "start_pos": 20, "end_pos": 33, "type": "METRIC", "confidence": 0.6930010616779327}]}, {"text": " Table 6: Classification of common name-name re- call errors without common tokens.", "labels": [], "entities": [{"text": "Classification of common name-name re- call errors", "start_pos": 10, "end_pos": 60, "type": "TASK", "confidence": 0.7466365322470665}]}, {"text": " Table 7: Distribution of top five named entity  types of common noun-name recall errors and all  possible noun-name recall errors.", "labels": [], "entities": []}, {"text": " Table 9: Name/Noun precision errors for all systems. The percentages are the proportion of precision  errors with respect to all decision of the system in that category.", "labels": [], "entities": [{"text": "precision errors", "start_pos": 20, "end_pos": 36, "type": "METRIC", "confidence": 0.9101569652557373}, {"text": "precision  errors", "start_pos": 92, "end_pos": 109, "type": "METRIC", "confidence": 0.977880597114563}]}]}