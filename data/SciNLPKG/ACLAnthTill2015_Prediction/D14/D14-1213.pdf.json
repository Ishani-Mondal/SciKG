{"title": [{"text": "Self-disclosure topic model for classifying and analyzing Twitter conversations", "labels": [], "entities": [{"text": "classifying and analyzing Twitter conversations", "start_pos": 32, "end_pos": 79, "type": "TASK", "confidence": 0.7132534742355346}]}], "abstractContent": [{"text": "Self-disclosure, the act of revealing oneself to others, is an important social behavior that strengthens interpersonal relationships and increases social support.", "labels": [], "entities": []}, {"text": "Although there are many social science studies of self-disclosure, they are based on manual coding of small datasets and questionnaires.", "labels": [], "entities": []}, {"text": "We conduct a computational analysis of self-disclosure with a large dataset of naturally-occurring conversations , a semi-supervised machine learning algorithm, and a computational analysis of the effects of self-disclosure on subsequent conversations.", "labels": [], "entities": []}, {"text": "We use a longitudinal dataset of 17 million tweets, all of which occurred in conversations that consist of five or more tweets directly replying to the previous tweet, and from dyads with twenty of more conversations each.", "labels": [], "entities": []}, {"text": "We develop self-disclosure topic model (SDTM), a variant of latent Dirichlet allocation (LDA) for automatically classifying the level of self-disclosure for each tweet.", "labels": [], "entities": []}, {"text": "We take the results of SDTM and analyze the effects of self-disclosure on subsequent conversations.", "labels": [], "entities": []}, {"text": "Our model significantly outperforms several comparable methods on classifying the level of self-disclosure, and the analysis of the longitudinal data using SDTM uncovers significant and positive correlation between self-disclosure and conversation frequency and length.", "labels": [], "entities": []}], "introductionContent": [{"text": "Self-disclosure is an important and pervasive social behavior.", "labels": [], "entities": []}, {"text": "People disclose personal information about themselves to improve and maintain * This work was done when JinYeong Bak was a visiting student at Microsoft Research, relationships.", "labels": [], "entities": []}, {"text": "A common instance of self-disclosure is the start of a conversation with an exchange of names and additional self-introductions.", "labels": [], "entities": []}, {"text": "Another example of self-disclosure, shown in, where the information disclosed about a family member's serious illness, is much more personal than the exchange of names.", "labels": [], "entities": []}, {"text": "In this paper, we seek to understand this important social behavior using a large-scale Twitter conversation data, automatically classifying the level of self-disclosure using machine learning and correlating the patterns with conversational behaviors which can serve as proxies for measuring intimacy between two conversational partners.", "labels": [], "entities": []}, {"text": "Twitter conversation data, explained in more detail in section 4.1, enable an extremely large scale study of naturally-occurring self-disclosure behavior, compared to traditional social science studies.", "labels": [], "entities": []}, {"text": "One challenge of such large scale study, though, remains in the lack of labeled groundtruth data of self-disclosure level.", "labels": [], "entities": []}, {"text": "That is, naturally-occurring Twitter conversations do not come tagged with the level of self-disclosure in each conversation.", "labels": [], "entities": []}, {"text": "To overcome that challenge, we propose a semi-supervised machine learning approach using probabilistic topic modeling.", "labels": [], "entities": []}, {"text": "Our self-disclosure topic model (SDTM) assumes that self-disclosure behavior can be modeled using a combination of simple linguistic features (e.g., pronouns) with automatically discovered semantic themes (i.e., topics).", "labels": [], "entities": []}, {"text": "For instance, an utterance \"I am finally through with this disastrous relationship\" uses a first-person pronoun and contains a topic about personal relationships.", "labels": [], "entities": []}, {"text": "In comparison with various other models, SDTM shows the highest accuracy, and the resulting conversation frequency and length patterns on self-disclosure are shown different overtime.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9994099140167236}]}, {"text": "Our contributions to the research community include the following: \u2022 We present key features and prior knowledge for identifying self-disclosure level, and show relevance of it with experiment results (Sec. 2).", "labels": [], "entities": []}, {"text": "\u2022 We present a topic model that explicitly includes the level of self-disclosure in a conversation using linguistic features and the latent semantic topics (Sec. 3).", "labels": [], "entities": []}, {"text": "\u2022 We collect a large dataset of Twitter conversations over three years and annotate a small subset with self-disclosure level (Sec. 4).", "labels": [], "entities": []}, {"text": "\u2022 We compare the classification accuracy of SDTM with other models and show that it performs the best (Sec. 5).", "labels": [], "entities": [{"text": "classification", "start_pos": 17, "end_pos": 31, "type": "TASK", "confidence": 0.9064825773239136}, {"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.7573262453079224}]}, {"text": "\u2022 We correlate the self-disclosure patterns and conversation behaviors to show that there is significant relationship overtime (Sec. 6).", "labels": [], "entities": []}], "datasetContent": [{"text": "We first run SDTM with all of our Twitter conversation data with 150; 120; 120 topics for SDTM K G , K M and K H respectively.", "labels": [], "entities": []}, {"text": "The hyper-parameters are the same as in section 5.", "labels": [], "entities": []}, {"text": "To handle a large dataset, we employ a distributed algorithm, and run with 28 threads.", "labels": [], "entities": []}, {"text": "shows some of the topics that were prominent in each SD level by KL-divergence.", "labels": [], "entities": []}, {"text": "As expected, G level includes general topics such as food, celebrity, soccer and IT devices, M level includes personal communication and birthday, and finally, H level includes sickness and profanity.", "labels": [], "entities": []}, {"text": "We define anew measurement, SD level score fora dyad in the period, which is a weighted sum of each conversation with SD levels mapped to 1, 2, and 3, for the levels G, M, and H, respectively.: Relationship between initial conversation frequency and subsequent SD level.", "labels": [], "entities": []}, {"text": "The solid line is the linear regression line, and the coefficient is 0.0020 with p < 0.0001, which shows a significant positive relationship.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 6: SD level classification accuracies and F- measures using annotated data. Acc is accuracy,  and G F 1 is F-measure for classifying the G level.  Avg F 1 is the macroaveraged value of G F 1 , M F 1  and H F 1 . SDTM outperforms all other methods  compared. The difference between SDTM and  FirstP is statistically significant (p-value < 0.05  for accuracy, < 0.0001 for Avg F 1 ).", "labels": [], "entities": [{"text": "SD level classification", "start_pos": 10, "end_pos": 33, "type": "TASK", "confidence": 0.7982385555903116}, {"text": "F- measures", "start_pos": 49, "end_pos": 60, "type": "METRIC", "confidence": 0.9420342246691386}, {"text": "Acc", "start_pos": 83, "end_pos": 86, "type": "METRIC", "confidence": 0.9954936504364014}, {"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9978074431419373}, {"text": "F-measure", "start_pos": 114, "end_pos": 123, "type": "METRIC", "confidence": 0.9724708199501038}, {"text": "Avg F 1", "start_pos": 154, "end_pos": 161, "type": "METRIC", "confidence": 0.9627419312795004}, {"text": "FirstP", "start_pos": 298, "end_pos": 304, "type": "DATASET", "confidence": 0.8990789651870728}, {"text": "accuracy", "start_pos": 355, "end_pos": 363, "type": "METRIC", "confidence": 0.9981313347816467}]}, {"text": " Table 7: High ranked topics in each level by comparing KL-divergence with other level's topics", "labels": [], "entities": []}]}