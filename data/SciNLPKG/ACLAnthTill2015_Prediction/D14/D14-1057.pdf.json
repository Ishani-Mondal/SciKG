{"title": [{"text": "A Comparison of Selectional Preference Models for Automatic Verb Classification", "labels": [], "entities": [{"text": "Automatic Verb Classification", "start_pos": 50, "end_pos": 79, "type": "TASK", "confidence": 0.627318799495697}]}], "abstractContent": [{"text": "We present a comparison of different selec-tional preference models and evaluate them on an automatic verb classification task in German.", "labels": [], "entities": [{"text": "verb classification task", "start_pos": 102, "end_pos": 126, "type": "TASK", "confidence": 0.7786495486895243}]}, {"text": "We find that all the models we compare are effective for verb clustering; the best-performing model uses syntactic information to induce nouns classes from unlabelled data in an unsupervised manner.", "labels": [], "entities": [{"text": "verb clustering", "start_pos": 57, "end_pos": 72, "type": "TASK", "confidence": 0.7459938228130341}]}, {"text": "Avery simple model based on lexical preferences is also found to perform well.", "labels": [], "entities": []}], "introductionContent": [{"text": "Selectional preferences are the tendency fora word to semantically selector constrain which other words may appear in a direct syntactic relation with it.", "labels": [], "entities": []}, {"text": "Selectional preferences (SPs) have been a perennial knowledge source for NLP tasks such as word sense disambiguation) and semantic role labelling; and recognising selectional violations is thought to play a role in identifying and interpreting metaphor.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 91, "end_pos": 116, "type": "TASK", "confidence": 0.6172013282775879}, {"text": "semantic role labelling", "start_pos": 122, "end_pos": 145, "type": "TASK", "confidence": 0.6302822728951772}, {"text": "identifying and interpreting metaphor", "start_pos": 215, "end_pos": 252, "type": "TASK", "confidence": 0.6756968572735786}]}, {"text": "We focus on the SPs of verbs, since determining which arguments are typical of a given verb sheds light on the semantics of that verb.", "labels": [], "entities": []}, {"text": "In this study, we present the first empirical comparison of different SP models from the perspective of automatic verb classification (Schulte im, the task of grouping verbs together based on shared syntactic and semantic properties.", "labels": [], "entities": [{"text": "automatic verb classification", "start_pos": 104, "end_pos": 133, "type": "TASK", "confidence": 0.6905004779497782}]}, {"text": "We cluster German verbs using features capturing their valency or subcategorisation, following prior work, and investigate the effect of adding information about verb argument preferences.", "labels": [], "entities": []}, {"text": "SPs are represented by features capturing lexical information about the heads of arguments to the verbs; we restrict our focus hereto nouns.", "labels": [], "entities": []}, {"text": "We operationalise a selectional preference model as a function which maps such an argument head to a concept label.", "labels": [], "entities": []}, {"text": "We submit that the primary characteristic of such a model is its granularity.", "labels": [], "entities": []}, {"text": "In our baseline condition, all nouns are mapped to the same label; this effectively captures no information about a verb's SPs (i.e., we cluster verbs using subcategorisation information only).", "labels": [], "entities": []}, {"text": "On the other extreme, each noun is its own concept label; we term this condition lexical preferences (LP).", "labels": [], "entities": []}, {"text": "Between the baseline and LP lie a spectrum of models, in which multiple concepts are distinguished, and each concept label can represent multiple nouns.", "labels": [], "entities": []}, {"text": "Our main hypothesis is that verb clustering will work best using a model of such intermediate granularity.", "labels": [], "entities": [{"text": "verb clustering", "start_pos": 28, "end_pos": 43, "type": "TASK", "confidence": 0.7392890155315399}]}, {"text": "This follows the intuition that verbs would seem to select for classes of nouns; for instance, we suppose that essen 'eat' would tend to prefer as a direct object a noun from the abstract concept Essen ('food').", "labels": [], "entities": []}, {"text": "We assume that these concepts can be expressed independently of particular predicates; that is, there exist selectional preference models that will work for all verbs (and all grammatical relations).", "labels": [], "entities": []}, {"text": "Further benefits of grouping nouns into classes include combating data sparsity, as well as deriving models which can generalise to nouns unseen in training data.", "labels": [], "entities": []}, {"text": "Another parameter of a selectional preference model is the methodology used to induce the conceptual classes; put another way, the success of an SP model hinges on how it represents concepts.", "labels": [], "entities": []}, {"text": "In this paper, we investigate the choice of noun categorisation method through an empirical comparison of selectional preference models previously used in the literature.", "labels": [], "entities": [{"text": "choice of noun categorisation", "start_pos": 34, "end_pos": 63, "type": "TASK", "confidence": 0.6010490283370018}]}, {"text": "We set out to investigate the following questions: 1.", "labels": [], "entities": []}, {"text": "What classes of nouns are effective descriptors 511 of selectional preference concepts?", "labels": [], "entities": []}, {"text": "For example, do they correspond to features such as ANIMATE?", "labels": [], "entities": [{"text": "ANIMATE", "start_pos": 52, "end_pos": 59, "type": "METRIC", "confidence": 0.7416214942932129}]}, {"text": "2. What is the appropriate granularity of selectional preference concepts?", "labels": [], "entities": []}, {"text": "3. Which methods of classifying nouns into concepts are most effective at capturing selectional preferences for verb clustering?", "labels": [], "entities": [{"text": "verb clustering", "start_pos": 112, "end_pos": 127, "type": "TASK", "confidence": 0.7454296946525574}]}, {"text": "This paper is structured as follows: In Section 2, we introduce our baseline method of clustering verbs using subcategorisation information and describe evaluation; Section 3 lists the models of selectional preferences that we compare in this work; Section 4 presents results and discussion; Section 5 summarises related work; and Section 6 concludes with directions for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate the automatically induced verb clusterings against a manually-constructed gold standard, published by Schulte im.", "labels": [], "entities": []}, {"text": "This Levin-style classification groups 168 highand low-frequency verbs into 43 semantic classes; examples include Aspect (e.g., anfangen 'begin'), Propositional Attitude (e.g., denken 'think'), and Weather (e.g., regnen 'rain').", "labels": [], "entities": []}, {"text": "Some of the classes are further sub-classified; for the purposes of our evaluation, we ignore the hierarchical structure of the classification and consider each class or subclass to be a separate entity.", "labels": [], "entities": []}, {"text": "In this way, we obtain classes of fairly comparable size and sufficient semantic consistency.", "labels": [], "entities": []}, {"text": "We evaluate a given verb clustering against the gold standard using the pairwise F -score (.", "labels": [], "entities": [{"text": "F -score", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9554547270139059}]}, {"text": "To calculate this statistic, we construct a contingency table over then 2 pairs of verbs, the idea being that the gold standard provides binary judgements about whether two verbs should be clustered together or not.", "labels": [], "entities": []}, {"text": "If a clustering agrees with the gold standard as to whether a pair of verbs belong together or not, this is a \"correct\" answer.", "labels": [], "entities": []}, {"text": "Using the contingency table, the standard information retrieval measures of precision (P ) and recall (R) can be computed; the F -score is then the harmonic mean of these: F = 2P R/(P + R).", "labels": [], "entities": [{"text": "precision (P )", "start_pos": 76, "end_pos": 90, "type": "METRIC", "confidence": 0.9448099434375763}, {"text": "recall (R)", "start_pos": 95, "end_pos": 105, "type": "METRIC", "confidence": 0.9692511558532715}, {"text": "F -score", "start_pos": 127, "end_pos": 135, "type": "METRIC", "confidence": 0.9871585369110107}]}, {"text": "The random baseline is 2.08 (calculated as the average score of 50 random partitions), and the optimal score is 95.81, calculated by evaluating the gold standard against itself.", "labels": [], "entities": []}, {"text": "As the gold standard includes polysemous verbs, which belong to more than one cluster, the optimal score is calculated by randomly picking one of their senses; the average is then taken over 50 such trials.", "labels": [], "entities": []}, {"text": "The pairwise F -score is known to be somewhat nonlinear (Schulte im), penalising early clustering \"mistakes\" more than later ones, but it has the advantage that we can easily determine statistical significance using the contingency table and McNemar's test.", "labels": [], "entities": [{"text": "F -score", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.960207462310791}]}, {"text": "We use only one clustering algorithm and one purity metric, because our prior work shows that the most important choices for verb clustering are the distance measure used, and how verbs are represented.", "labels": [], "entities": [{"text": "verb clustering", "start_pos": 125, "end_pos": 140, "type": "TASK", "confidence": 0.7155564725399017}]}, {"text": "These factors set, we expect similar performance trends from different algorithms, with predictable variation (e.g., spectral tends to outperform hierarchical clustering, which in turn outperforms k-means).", "labels": [], "entities": []}, {"text": "Combining Ward's criterion and F -score is a trade-off at this point; the criterion is deterministic, giving reproducible results without computational complexity, but disallows estimates of density over our evaluation metric and is greedy (see discussion in Section 4.3).", "labels": [], "entities": [{"text": "F -score", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9940318067868551}]}], "tableCaptions": [{"text": " Table 2: Evaluation of the best SP models.", "labels": [], "entities": []}]}