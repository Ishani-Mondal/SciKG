{"title": [{"text": "Explaining the Stars: Weighted Multiple-Instance Learning for Aspect-Based Sentiment Analysis", "labels": [], "entities": [{"text": "Explaining the Stars", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8805694778760275}, {"text": "Aspect-Based Sentiment Analysis", "start_pos": 62, "end_pos": 93, "type": "TASK", "confidence": 0.6944819092750549}]}], "abstractContent": [{"text": "This paper introduces a model of multiple-instance learning applied to the prediction of aspect ratings or judgments of specific properties of an item from user-contributed texts such as product reviews.", "labels": [], "entities": [{"text": "prediction of aspect ratings or judgments of specific properties of an item from user-contributed texts such as product reviews", "start_pos": 75, "end_pos": 202, "type": "TASK", "confidence": 0.6304550563034258}]}, {"text": "Each variable-length text is represented by several independent feature vectors; one word vector per sentence or paragraph.", "labels": [], "entities": []}, {"text": "For learning from texts with known aspect ratings, the model performs multiple-instance regression (MIR) and assigns importance weights to each of the sentences or paragraphs of a text, uncovering their contribution to the aspect ratings.", "labels": [], "entities": [{"text": "multiple-instance regression (MIR)", "start_pos": 70, "end_pos": 104, "type": "TASK", "confidence": 0.707722520828247}]}, {"text": "Next, the model is used to predict aspect ratings in previously unseen texts, demonstrating interpretability and explanatory power for its predictions.", "labels": [], "entities": []}, {"text": "We evaluate the model on seven multi-aspect sentiment analysis data sets, improving over four MIR baselines and two strong bag-of-words linear models , namely SVR and Lasso, by more than 10% relative in terms of MSE.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sentiment analysis of texts provides a coarsegrained view of their overall attitude towards an item, either positive or negative.", "labels": [], "entities": [{"text": "Sentiment analysis of texts", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.9147654473781586}]}, {"text": "The recent abundance of user texts accompanied by real-valued labels e.g. on a 5-star scale has contributed to the development of automatic sentiment analysis of reviews of items such as movies, books, music or other products, with applications in social computing, user modeling, and recommender systems.", "labels": [], "entities": [{"text": "automatic sentiment analysis of reviews of items such as movies, books, music or", "start_pos": 130, "end_pos": 210, "type": "TASK", "confidence": 0.8619041204452514}, {"text": "user modeling", "start_pos": 266, "end_pos": 279, "type": "TASK", "confidence": 0.7876921892166138}]}, {"text": "The overall sentiment of a text towards an item often results from the ratings of several specific aspects of the item.", "labels": [], "entities": []}, {"text": "For instance, the author of a review might have a rather positive sentiment about a movie, having particularly liked the plot and the music, but not too much the actors.", "labels": [], "entities": []}, {"text": "Determining the ratings of each aspect automatically is a challenging task, which may seem to require the engineering of a large number of features designed to capture each aspect.", "labels": [], "entities": []}, {"text": "Our goal is to put forward anew feature-agnostic solution for analyzing aspect-related ratings expressed in a text, thus aiming fora finer-grained, deeper analysis of text meaning than overall sentiment analysis.", "labels": [], "entities": []}, {"text": "Current state-of-the-art approaches to sentiment analysis and aspect-based sentiment analysis, attempt to go beyond word-level features either by using higher-level linguistic features such as POS tagging, parsing, and knowledge infusion, or by learning features that capture syntactic and semantic dependencies between words.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.9611165821552277}, {"text": "aspect-based sentiment analysis", "start_pos": 62, "end_pos": 93, "type": "TASK", "confidence": 0.771394670009613}, {"text": "POS tagging, parsing", "start_pos": 193, "end_pos": 213, "type": "TASK", "confidence": 0.6204578578472137}]}, {"text": "Once an appropriate feature space is found, the ratings are typically modeled using a linear model, such as Support Vector Regression (SVR) with 2 norm for regularization or Lasso Regression with 1 norm.", "labels": [], "entities": [{"text": "Support Vector Regression (SVR)", "start_pos": 108, "end_pos": 139, "type": "METRIC", "confidence": 0.8673094908396403}]}, {"text": "By treating a text globally, these models ignore the fact that the sentences of a text have diverse contributions to the overall sentiment or to the attitude towards a specific aspect of an item.", "labels": [], "entities": []}, {"text": "In this paper, we propose anew learning model which answers the following question: \"To what extent does each part of a text contribute to the prediction of its overall sentiment or the rating of a particular aspect?\"", "labels": [], "entities": [{"text": "prediction of its overall sentiment", "start_pos": 143, "end_pos": 178, "type": "TASK", "confidence": 0.7489304661750793}]}, {"text": "The model uses multipleinstance regression (MIR), based on the assumption that not all the parts of a text have the same contribution to the prediction of the rating.", "labels": [], "entities": [{"text": "multipleinstance regression (MIR)", "start_pos": 15, "end_pos": 48, "type": "TASK", "confidence": 0.6813745260238647}]}, {"text": "Specifically, a text is seen as a bag of sentences (instances), each of them modeled as a word vector.", "labels": [], "entities": []}, {"text": "The overall challenge is to learn which sentences refer to a given aspect, and how they contribute to the text's attitude towards it, but the model applies to overall sentiment analysis as well.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 167, "end_pos": 185, "type": "TASK", "confidence": 0.9107325077056885}]}, {"text": "For instance, displays a positive global comment on a TED talk and the weights assigned to two of its sentences by MIR.", "labels": [], "entities": [{"text": "MIR", "start_pos": 115, "end_pos": 118, "type": "METRIC", "confidence": 0.7050568461418152}]}, {"text": "Using regularized least squares, we formulate an optimization objective to jointly assign instance weights and regression hyperplane weights.", "labels": [], "entities": []}, {"text": "Then, an instance relevance estimation method is used to predict aspect ratings, or global ones, in previously unseen texts.", "labels": [], "entities": [{"text": "instance relevance estimation", "start_pos": 9, "end_pos": 38, "type": "TASK", "confidence": 0.5836536089579264}]}, {"text": "The parameters of the model are learned using an alternating optimization procedure inspired by.", "labels": [], "entities": []}, {"text": "Our model requires only text with ratings for training, with no particular assumption on the word features to be extracted, and provides interpretable explanations of the predicted ratings through the relevance weights assigned to sentences.", "labels": [], "entities": []}, {"text": "We also show that the model has reasonable computational demands.", "labels": [], "entities": []}, {"text": "The model is evaluated on aspect and sentiment rating prediction over seven datasets: five of them contain reviews with aspect labels about beers, audiobooks and toys, and two contain TED talks with emotion labels, and comments on them with sentiment labels.", "labels": [], "entities": [{"text": "sentiment rating prediction", "start_pos": 37, "end_pos": 64, "type": "TASK", "confidence": 0.7618928750356039}]}, {"text": "Our model outperforms previous MIR models and two strong linear models for rating prediction, namely SVR and Lasso by more than 10% relative in terms of MSE.", "labels": [], "entities": [{"text": "MIR", "start_pos": 31, "end_pos": 34, "type": "TASK", "confidence": 0.9641019701957703}, {"text": "rating prediction", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.8252650797367096}, {"text": "SVR", "start_pos": 101, "end_pos": 104, "type": "DATASET", "confidence": 0.6173760294914246}, {"text": "Lasso", "start_pos": 109, "end_pos": 114, "type": "METRIC", "confidence": 0.8862431645393372}]}, {"text": "The improvement is observed even when the sophistication of the feature space increases.", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 shows how our model innovates with respect to previous work on MIR and rating prediction.", "labels": [], "entities": [{"text": "MIR", "start_pos": 73, "end_pos": 76, "type": "TASK", "confidence": 0.9932045936584473}, {"text": "rating prediction", "start_pos": 81, "end_pos": 98, "type": "TASK", "confidence": 0.7850399911403656}]}, {"text": "Section 3 formulates the problem while Section 4 describes previous MIR models.", "labels": [], "entities": [{"text": "MIR", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.9819954633712769}]}, {"text": "Section 5 presents our MIR model and learning procedure.", "labels": [], "entities": [{"text": "MIR", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.9798114895820618}]}, {"text": "Section 6 presents the datasets and evaluation methods.", "labels": [], "entities": []}, {"text": "Section 7 reports our results on rating prediction tasks, and provides examples of rating explanation.", "labels": [], "entities": [{"text": "rating prediction tasks", "start_pos": 33, "end_pos": 56, "type": "TASK", "confidence": 0.8395769993464152}]}], "datasetContent": [{"text": "We use seven datasets summarized in.", "labels": [], "entities": []}, {"text": "Five publicly available datasets were built for aspect prediction by -BeerAdvocate, Ratebeer (ES), RateBeer (FR), Audiobooks and Toys & Games -and have aspect ratings assigned by their creators on the respective websites.", "labels": [], "entities": [{"text": "aspect prediction", "start_pos": 48, "end_pos": 65, "type": "TASK", "confidence": 0.9654244482517242}, {"text": "BeerAdvocate", "start_pos": 70, "end_pos": 82, "type": "DATASET", "confidence": 0.9682551026344299}]}, {"text": "On the set of comments on TED talks from Pappas and Popescu-Belis (2013), we aim to predict two things: talk-level emotion dimensions assigned by viewers through voting, and comment polarity scores assigned by crowdsourcing.", "labels": [], "entities": [{"text": "TED talks from Pappas", "start_pos": 26, "end_pos": 47, "type": "DATASET", "confidence": 0.784510001540184}]}, {"text": "The distributions of aspect ratings per dataset are shown in.", "labels": [], "entities": []}, {"text": "Five datasets are in English, one in Spanish (Ratebeer) and one in French (RateBeer), so our results will also demonstrate the language-independence of our method.", "labels": [], "entities": []}, {"text": "From every dataset we kept 1,200 texts as bags of sentences, but we also used three full-size datasets, namely Ratebeer ES (1,259 labeled reviews), Ratebeer FR (17,998) and Audiobooks (10,989).", "labels": [], "entities": [{"text": "Ratebeer ES", "start_pos": 111, "end_pos": 122, "type": "DATASET", "confidence": 0.7096148431301117}, {"text": "Ratebeer", "start_pos": 148, "end_pos": 156, "type": "DATASET", "confidence": 0.9404451251029968}, {"text": "FR", "start_pos": 157, "end_pos": 159, "type": "METRIC", "confidence": 0.5317384600639343}, {"text": "Audiobooks", "start_pos": 173, "end_pos": 183, "type": "DATASET", "confidence": 0.9276808500289917}]}, {"text": "The features for each of them are word vectors with binary attributes signaling word presence or absence, in a traditional bag-of-words model (BOW).", "labels": [], "entities": []}, {"text": "The word vectors are provided with the first five datasets and we generated them for the latter two, after lowercasing and stopword removal.", "labels": [], "entities": []}, {"text": "Moreover, for TED comments, we computed TF-IDF scores using the same dimensionality as with BOW to experiment with a different feature space.", "labels": [], "entities": []}, {"text": "The target class labels were normalized by the maximum rating in their scale, except for TED talks where the votes were normalized by the maximum number of votes overall the emotion classes for each talk, and two emotions, 'informative' and 'ok', were excluded as they are neutral ones.", "labels": [], "entities": []}, {"text": "We compare the proposed model, noted APWeights, with four baseline ones -Aggregated, Instance, Prime (Section 4) and Clus- tering (from github.com/garydoranjr/ mcr), which is an instance relevance method proposed by for aspect rating prediction.", "labels": [], "entities": [{"text": "APWeights", "start_pos": 37, "end_pos": 46, "type": "DATASET", "confidence": 0.9382122159004211}, {"text": "Aggregated", "start_pos": 73, "end_pos": 83, "type": "METRIC", "confidence": 0.9630259275436401}, {"text": "Clus- tering", "start_pos": 117, "end_pos": 129, "type": "METRIC", "confidence": 0.9166914025942484}, {"text": "aspect rating prediction", "start_pos": 220, "end_pos": 244, "type": "TASK", "confidence": 0.8602608640988668}]}, {"text": "First, for each aspect class, we optimize all methods on a development set of 25% of the data (300 randomly selected bags).", "labels": [], "entities": []}, {"text": "Then, we perform 5-fold cross-validation for every aspect on each entire data set and report the average error scores using the optimal hyper-parameters per method.", "labels": [], "entities": []}, {"text": "In addition, we report for comparison the scores of AverageRating, which always predicts the average rating over the training set.", "labels": [], "entities": [{"text": "AverageRating", "start_pos": 52, "end_pos": 65, "type": "METRIC", "confidence": 0.9422389268875122}]}, {"text": "We report standard error metrics for regression, namely the Mean Absolute Error (MAE) and the Mean Squared Error (MSE).", "labels": [], "entities": [{"text": "Mean Absolute Error (MAE)", "start_pos": 60, "end_pos": 85, "type": "METRIC", "confidence": 0.9675813615322113}, {"text": "Mean Squared Error (MSE)", "start_pos": 94, "end_pos": 118, "type": "METRIC", "confidence": 0.9011942446231842}]}, {"text": "The former measures the average magnitude of errors in a set of predictions while the latter measures the average of their squares, which are defined over the test set of bags Bi respectively as MAE = ( The crossvalidation scores are obtained by averaging the MAE and MSE scores on each fold.", "labels": [], "entities": [{"text": "MAE", "start_pos": 195, "end_pos": 198, "type": "METRIC", "confidence": 0.990401566028595}, {"text": "MAE", "start_pos": 260, "end_pos": 263, "type": "METRIC", "confidence": 0.9133738279342651}]}, {"text": "To find the optimal hyper-parameters for each model, we perform 3-fold cross-validation on the development set using exhaustive grid-search over a fine-grained range of possible values and select the ones that perform best in terms of MAE.", "labels": [], "entities": [{"text": "MAE", "start_pos": 235, "end_pos": 238, "type": "METRIC", "confidence": 0.9738667607307434}]}, {"text": "The hyper-parameters to be optimized for the baselines (except AverageRating) are the regularization terms \u03bb 2 , \u03bb 1 of their possible regression model f , namely SVR which uses the 2 norm and Lasso which uses the 1 norm.", "labels": [], "entities": [{"text": "AverageRating", "start_pos": 63, "end_pos": 76, "type": "METRIC", "confidence": 0.8151564598083496}]}, {"text": "As for APWeights, it relies on three regularization terms, namely 1 , 2 , 3 of the 2 -norm for f 1 , f 2 and f 3 regression models.", "labels": [], "entities": []}, {"text": "Lastly, for the Clustering baseline, we use the f 2 regression model, which relies on 2 and the number of clusters k, optimized over {5, ..., 50} with step 5, for its clustering algorithm, here k-Means.", "labels": [], "entities": [{"text": "Clustering baseline", "start_pos": 16, "end_pos": 35, "type": "DATASET", "confidence": 0.7908349633216858}]}, {"text": "All the regularization terms are optimized over the same range of possible values, noted a \u00b7 10 b with a \u2208 {1, . .", "labels": [], "entities": []}, {"text": ", 9} and b \u2208 {\u22124, . .", "labels": [], "entities": []}, {"text": ", +4}, hence 81 values per term.", "labels": [], "entities": []}, {"text": "For the regression models and evaluation protocol, we use the scikit-learn machine learning library (.", "labels": [], "entities": []}, {"text": "Our code and data are available in the first author's website.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Description of the seven datasets used for aspect, sentiment and emotion rating prediction.", "labels": [], "entities": [{"text": "aspect, sentiment and emotion rating prediction", "start_pos": 53, "end_pos": 100, "type": "TASK", "confidence": 0.6185741552284786}]}, {"text": " Table 2: Performance of aspect rating prediction (the lower the better) in terms of MAE and MSE (\u00d7 100)  with 5-fold cross-validation. All scores are averaged over all aspects in each dataset. The scores of the  best method are in bold and the second best ones are underlined. Significant improvements (paired t-test,  p < 0.05) are in italics.", "labels": [], "entities": [{"text": "aspect rating prediction", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.5235248108704885}, {"text": "MAE", "start_pos": 85, "end_pos": 88, "type": "METRIC", "confidence": 0.9889429807662964}, {"text": "MSE", "start_pos": 93, "end_pos": 96, "type": "METRIC", "confidence": 0.8831936120986938}]}, {"text": " Table 3: MAE and MSE (\u00d7 100) on sentiment  and emotion prediction with 5-fold c.-v. Scores  on TED talks are averaged over the 12 emotions.  The scores of the best method are in bold and the  second best ones are underlined. Significant im- provements (paired t-test, p < 0.05) are in italics.", "labels": [], "entities": [{"text": "MAE", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8129492402076721}, {"text": "sentiment  and emotion prediction", "start_pos": 33, "end_pos": 66, "type": "TASK", "confidence": 0.7867931872606277}]}]}