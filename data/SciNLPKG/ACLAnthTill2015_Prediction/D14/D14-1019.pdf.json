{"title": [{"text": "Syntax-Augmented Machine Translation using Syntax-Label Clustering", "labels": [], "entities": [{"text": "Syntax-Augmented Machine Translation", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7636919418970743}]}], "abstractContent": [{"text": "Recently, syntactic information has helped significantly to improve statistical machine translation.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 68, "end_pos": 99, "type": "TASK", "confidence": 0.7624476154645284}]}, {"text": "However, the use of syntactic information may have a negative impact on the speed of translation because of the large number of rules, especially when syntax labels are projected from a parser in syntax-augmented machine translation.", "labels": [], "entities": [{"text": "syntax-augmented machine translation", "start_pos": 196, "end_pos": 232, "type": "TASK", "confidence": 0.6829349597295126}]}, {"text": "In this paper, we propose a syntax-label clustering method that uses an exchange algorithm in which syntax labels are clustered together to reduce the number of rules.", "labels": [], "entities": [{"text": "syntax-label clustering", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.681554764509201}]}, {"text": "The proposed method achieves clustering by directly maximizing the likelihood of synchronous rules, whereas previous work considered only the similarity of proba-bilistic distributions of labels.", "labels": [], "entities": []}, {"text": "We tested the proposed method on Japanese-English and Chinese-English translation tasks and found order-of-magnitude higher clustering speeds for reducing labels and gains in translation quality compared with previous clustering method.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, statistical machine translation (SMT) models that use syntactic information have received significant research attention.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 17, "end_pos": 54, "type": "TASK", "confidence": 0.8132024506727854}]}, {"text": "These models use syntactic information on the source side (, the target side () or both sides) produce syntactically correct translations.", "labels": [], "entities": []}, {"text": "proposed syntax-augmented MT (SAMT), which is a MT system that uses syntax labels of a parser.", "labels": [], "entities": [{"text": "syntax-augmented MT (SAMT)", "start_pos": 9, "end_pos": 35, "type": "TASK", "confidence": 0.6670675933361053}]}, {"text": "The SAMT grammar directly encodes syntactic information into the synchronous contextfree grammar (SCFG) of Hiero, which relies on two nonterminal labels.", "labels": [], "entities": []}, {"text": "One problem in adding syntax labels to Hiero-style rules is that only partial phrases are assigned labels.", "labels": [], "entities": []}, {"text": "It is common practice to extend labels by using the idea of combinatory categorial grammar (CCG)) on the problem.", "labels": [], "entities": []}, {"text": "Although this extended syntactical information may improve the coverage of rules and syntactic correctness in translation, the increased grammar size causes serious speed and data-sparseness problems.", "labels": [], "entities": [{"text": "speed", "start_pos": 165, "end_pos": 170, "type": "METRIC", "confidence": 0.9890273809432983}]}, {"text": "To address these problems, coarsen syntactic labels using the similarity of the probabilistic distributions of labels in synchronous rules and showed that performance improved.", "labels": [], "entities": []}, {"text": "In the present work, we follow the idea of labelset coarsening and propose anew method to group syntax labels.", "labels": [], "entities": [{"text": "labelset coarsening", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.6792436689138412}]}, {"text": "First, as an optimization criterion, we use the logarithm of the likelihood of synchronous rules instead of the similarity of probabilistic distributions of syntax labels.", "labels": [], "entities": []}, {"text": "Second, we use exchange clustering, which is faster than the agglomerativeclustering algorithm used in the previous work.", "labels": [], "entities": [{"text": "exchange clustering", "start_pos": 15, "end_pos": 34, "type": "TASK", "confidence": 0.7681642770767212}]}, {"text": "We tested our proposed method on JapaneseEnglish and Chinese-English translation tasks and observed gains comparable to those of previous work with similar reductions in grammar size.", "labels": [], "entities": [{"text": "JapaneseEnglish and Chinese-English translation tasks", "start_pos": 33, "end_pos": 86, "type": "TASK", "confidence": 0.6354169189929962}]}], "datasetContent": [{"text": "We did experiments with the SAMT () model with the Moses (.", "labels": [], "entities": []}, {"text": "For the SAMT model, we conducted experiments with two label sets.", "labels": [], "entities": [{"text": "SAMT", "start_pos": 8, "end_pos": 12, "type": "TASK", "confidence": 0.6782807111740112}]}, {"text": "One is extracted from the phrase structure parses and the other is extended with CCG 4 . We applied the proposed method (+clustering) and the baseline method (+coarsening), which uses the Hanneman 3 LDC2003E14 4 Using the relax-parse with option SAMT 4 for IWSLT07 and FBIS and SAMT 2 for NIST08 in the Moses: SAMT grammars on zh-en experiments label-collapsing algorithm described in Section 2, for syntax-label clustering to the SAMT models with CCG.", "labels": [], "entities": [{"text": "phrase structure parses", "start_pos": 26, "end_pos": 49, "type": "TASK", "confidence": 0.6543590724468231}, {"text": "Hanneman 3 LDC2003E14", "start_pos": 188, "end_pos": 209, "type": "DATASET", "confidence": 0.8026089072227478}, {"text": "IWSLT07", "start_pos": 257, "end_pos": 264, "type": "DATASET", "confidence": 0.8589254021644592}]}, {"text": "The number of clusters for each clustering was set to 80.", "labels": [], "entities": []}, {"text": "The language models were built using SRILM Toolkits).", "labels": [], "entities": [{"text": "SRILM Toolkits", "start_pos": 37, "end_pos": 51, "type": "DATASET", "confidence": 0.9026662409305573}]}, {"text": "The language model with the IWSLT07 is a 5-gram model trained on the training data, and the language model with the FBIS and NIST08 is a 5-gram model trained on the Xinhua portion of English GigaWord.", "labels": [], "entities": [{"text": "IWSLT07", "start_pos": 28, "end_pos": 35, "type": "DATASET", "confidence": 0.9461276531219482}, {"text": "FBIS", "start_pos": 116, "end_pos": 120, "type": "DATASET", "confidence": 0.9302801489830017}, {"text": "NIST08", "start_pos": 125, "end_pos": 131, "type": "DATASET", "confidence": 0.6691867113113403}, {"text": "Xinhua portion of English GigaWord", "start_pos": 165, "end_pos": 199, "type": "DATASET", "confidence": 0.6632340013980865}]}, {"text": "For word alignments, we used MGIZA++ (.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 4, "end_pos": 19, "type": "TASK", "confidence": 0.7908275127410889}, {"text": "MGIZA++", "start_pos": 29, "end_pos": 36, "type": "DATASET", "confidence": 0.6610865592956543}]}, {"text": "To tune the weights for BLEU (), we used the n-best batch MIRA (Cherry and Foster, 2012).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 24, "end_pos": 28, "type": "METRIC", "confidence": 0.998673677444458}, {"text": "MIRA", "start_pos": 58, "end_pos": 62, "type": "METRIC", "confidence": 0.9363308548927307}]}], "tableCaptions": [{"text": " Table 2: Data sets: The \"sent\" column indicates the number of sentences. The \"src-tokens\" and \"tgt- tokens\" columns indicate the number of words in the source-and the target-side sentences.", "labels": [], "entities": []}, {"text": " Table 3: SAMT grammars on ja-en experiments", "labels": [], "entities": [{"text": "SAMT grammars", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.9552090764045715}]}, {"text": " Table 4: SAMT grammars on zh-en experiments", "labels": [], "entities": [{"text": "SAMT grammars", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.9479392170906067}]}, {"text": " Table 5: BLEU score and rule number for each  cluster number using IWSLT07", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9740630388259888}, {"text": "IWSLT07", "start_pos": 68, "end_pos": 75, "type": "DATASET", "confidence": 0.763945460319519}]}, {"text": " Table 6: BLEU scores on each experiments", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9992979764938354}]}]}