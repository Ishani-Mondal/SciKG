{"title": [{"text": "Word Translation Prediction for Morphologically Rich Languages with Bilingual Neural Networks", "labels": [], "entities": [{"text": "Word Translation Prediction", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8370781739552816}]}], "abstractContent": [{"text": "Translating into morphologically rich languages is a particularly difficult problem in machine translation due to the high degree of inflectional ambiguity in the target language, often only poorly captured by existing word translation models.", "labels": [], "entities": [{"text": "Translating into morphologically rich languages", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.8525945901870727}, {"text": "machine translation", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.8003003299236298}, {"text": "word translation", "start_pos": 219, "end_pos": 235, "type": "TASK", "confidence": 0.7553742229938507}]}, {"text": "We present a general approach that exploits source-side contexts of foreign words to improve translation prediction accuracy.", "labels": [], "entities": [{"text": "translation prediction", "start_pos": 93, "end_pos": 115, "type": "TASK", "confidence": 0.9732269048690796}, {"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.8366125822067261}]}, {"text": "Our approach is based on a probabilistic neural network which does not require linguistic annotation nor manual feature engineering.", "labels": [], "entities": []}, {"text": "We report significant improvements in word translation prediction accuracy for three morphologically rich target languages.", "labels": [], "entities": [{"text": "word translation prediction", "start_pos": 38, "end_pos": 65, "type": "TASK", "confidence": 0.849999189376831}, {"text": "accuracy", "start_pos": 66, "end_pos": 74, "type": "METRIC", "confidence": 0.9343619346618652}]}, {"text": "In addition, preliminary results for integrating our approach into a large-scale English-Russian statistical machine translation system show small but statistically significant improvements in translation quality.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 97, "end_pos": 128, "type": "TASK", "confidence": 0.6518676479657491}]}], "introductionContent": [{"text": "The ability to make context-sensitive translation decisions is one of the major strengths of phrasebased SMT (PSMT).", "labels": [], "entities": [{"text": "context-sensitive translation decisions", "start_pos": 20, "end_pos": 59, "type": "TASK", "confidence": 0.6130597988764445}, {"text": "phrasebased SMT", "start_pos": 93, "end_pos": 108, "type": "TASK", "confidence": 0.6388949155807495}]}, {"text": "However, the way PSMT exploits source-language context has several limitations as pointed out, for instance, by and.", "labels": [], "entities": [{"text": "PSMT", "start_pos": 17, "end_pos": 21, "type": "TASK", "confidence": 0.9567188024520874}]}, {"text": "First, the amount of context used to translate a given input word depends on the phrase segmentation, with hypotheses resulting from different segmentations competing with one another.", "labels": [], "entities": []}, {"text": "Another issue is that, given a phrase segmentation, each source phrase is translated independently from the others, which can be problematic especially for short phrases.", "labels": [], "entities": [{"text": "phrase segmentation", "start_pos": 31, "end_pos": 50, "type": "TASK", "confidence": 0.7300257682800293}]}, {"text": "As a result, the predictive translation of a source phrase does not access useful linguistic clues in the source sentence that are outside of the scope of the phrase.", "labels": [], "entities": [{"text": "predictive translation of a source phrase", "start_pos": 17, "end_pos": 58, "type": "TASK", "confidence": 0.9031783640384674}]}, {"text": "Lexical weighting tackles the problem of unreliable phrase probabilities, typically associated with long phrases, but does not alleviate the problem of context segmentation.", "labels": [], "entities": [{"text": "Lexical weighting", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9214609861373901}, {"text": "context segmentation", "start_pos": 152, "end_pos": 172, "type": "TASK", "confidence": 0.7279826998710632}]}, {"text": "An important share of the translation selection task is then left to the language model (LM), which is certainly very effective but can only leverage target language context.", "labels": [], "entities": [{"text": "translation selection", "start_pos": 26, "end_pos": 47, "type": "TASK", "confidence": 0.9807677567005157}]}, {"text": "Moreover, decisions that are taken at early decoding stages-such as the common practice of retaining only top n translation options for each source span-depend only on the translation models and on the target context available in the phrase.", "labels": [], "entities": []}, {"text": "Source context based translation models) naturally address these limitations.", "labels": [], "entities": [{"text": "Source context based translation", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.5475919023156166}]}, {"text": "These models can exploit a boundless context of the input text, but they assume that target words can be predicted independently from each other, which makes them easy to integrate into state-of-the-art PSMT systems.", "labels": [], "entities": []}, {"text": "Even though the independence assumption is made on the target side, these models have shown the benefits of utilizing source context, especially in translating into morphologically rich languages.", "labels": [], "entities": []}, {"text": "One drawback of previous research on this topic, though, is that it relied on rich sets of manually designed features, which in turn required the availability of linguistic annotation tools like POS taggers and syntactic parsers.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 195, "end_pos": 206, "type": "TASK", "confidence": 0.6797090917825699}]}, {"text": "In this paper, we specifically focus on improving the prediction accuracy for word translations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9800509810447693}, {"text": "word translations", "start_pos": 78, "end_pos": 95, "type": "TASK", "confidence": 0.7657179236412048}]}, {"text": "Achieving high levels of word translation accuracy is particularly challenging for language pairs where the source language is morphologically poor, such as English, and the target language is morphologically rich, such as Russian, i.e., language pairs with a high degree of surface realization ambiguity (.", "labels": [], "entities": [{"text": "word translation", "start_pos": 25, "end_pos": 41, "type": "TASK", "confidence": 0.7212007939815521}, {"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.8524109721183777}]}, {"text": "To address this problem we propose a general approach based on bilingual neural networks (BNN) exploiting source-side contextual information.", "labels": [], "entities": []}, {"text": "This paper makes a number of contributions: Unlike previous approaches our models do not require any form of linguistic annotation, nor do they require any feature engineering (.", "labels": [], "entities": []}, {"text": "Moreover, besides directly predicting fully inflected forms as, our approach can also model stem and suffix prediction explicitly.", "labels": [], "entities": [{"text": "stem and suffix prediction", "start_pos": 92, "end_pos": 118, "type": "TASK", "confidence": 0.6546284183859825}]}, {"text": "Prediction accuracy is evaluated with respect to three morphologically rich target languages showing that our approach consistently yields substantial improvements over a competitive baseline.", "labels": [], "entities": [{"text": "Prediction", "start_pos": 0, "end_pos": 10, "type": "METRIC", "confidence": 0.9349399209022522}, {"text": "accuracy", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.8367394208908081}]}, {"text": "We also show that these improvements in prediction accuracy can be beneficial in an end-to-end machine translation scenario by integrating into a large-scale EnglishRussian PSMT system.", "labels": [], "entities": [{"text": "prediction", "start_pos": 40, "end_pos": 50, "type": "TASK", "confidence": 0.9350875020027161}, {"text": "accuracy", "start_pos": 51, "end_pos": 59, "type": "METRIC", "confidence": 0.8634430170059204}, {"text": "machine translation", "start_pos": 95, "end_pos": 114, "type": "TASK", "confidence": 0.698934942483902}, {"text": "EnglishRussian PSMT", "start_pos": 158, "end_pos": 177, "type": "DATASET", "confidence": 0.8961548209190369}]}, {"text": "Finally, a detailed analysis shows that our approach induces a positive bias on phrase translation probabilities leading to a better ranking of the translation options employed by the decoder.", "labels": [], "entities": [{"text": "phrase translation probabilities", "start_pos": 80, "end_pos": 112, "type": "TASK", "confidence": 0.7876774867375692}]}], "datasetContent": [{"text": "The following parallel corpora are used to train the BNN models: \u2022 English-Russian: WMT13 data (News Commentary and Yandex corpora); \u2022 English-Czech: CzEng 1.0 corpus (Bojar et al., 2012) (Web Pages and News sections); \u2022 English-Bulgarian: a mix of crawled news data, TED talks and Europarl proceedings.", "labels": [], "entities": [{"text": "WMT13 data", "start_pos": 84, "end_pos": 94, "type": "DATASET", "confidence": 0.8832880258560181}, {"text": "Europarl proceedings", "start_pos": 282, "end_pos": 302, "type": "DATASET", "confidence": 0.9188288748264313}]}, {"text": "Detailed corpus statistics are given in.", "labels": [], "entities": []}, {"text": "For each language pair, accuracies are measured on a held-out set of 10K parallel sentences.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 24, "end_pos": 34, "type": "METRIC", "confidence": 0.9932830333709717}]}, {"text": "To prepare the candidate generation function, each dataset is first word-aligned with GIZA++, then a bilingual lexicon with maximum-likelihood probabilities (P mle ) is built from the symmetrized alignment.", "labels": [], "entities": [{"text": "maximum-likelihood probabilities (P mle )", "start_pos": 124, "end_pos": 165, "type": "METRIC", "confidence": 0.6427237192789713}]}, {"text": "After some frequency and significance pruning, 7 the top 200 translations sorted by P mle (t|s) \u00b7 P mle (s|t) are kept as candidate word translations for each source word in the vocabulary.", "labels": [], "entities": []}, {"text": "Word alignments are also used to train the BNN models: each alignment link constitutes a training sample, with no special treatment of unaligned words and 1-to-many alignments.", "labels": [], "entities": [{"text": "BNN", "start_pos": 43, "end_pos": 46, "type": "DATASET", "confidence": 0.7816423773765564}]}, {"text": "The context window size k is set to 3 (corresponding to 7-gram) and the dimensionality of source word representations to 100 in all experiments.", "labels": [], "entities": []}, {"text": "The number of hidden units in our feedforward neural networks and the target translation embedding size in LBL models are set to 200.", "labels": [], "entities": []}, {"text": "All models are trained for 10 iterations with learning rate set to 0.001.: BNN training corpora statistics: number of sentences, tokens, and type/token ratio (T/T).", "labels": [], "entities": [{"text": "BNN training corpora statistics", "start_pos": 75, "end_pos": 106, "type": "DATASET", "confidence": 0.6795848160982132}]}, {"text": "We evaluate the suffix BNN model at the part-ofspeech (POS) level.", "labels": [], "entities": [{"text": "BNN", "start_pos": 23, "end_pos": 26, "type": "METRIC", "confidence": 0.8838503956794739}]}, {"text": "provides suffix prediction accuracy per POS for En-Ru.", "labels": [], "entities": [{"text": "suffix prediction", "start_pos": 9, "end_pos": 26, "type": "TASK", "confidence": 0.6668750643730164}, {"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.8114749193191528}]}, {"text": "For this analysis, Russian data is segmented by TreeTag-ger.", "labels": [], "entities": [{"text": "Russian data", "start_pos": 19, "end_pos": 31, "type": "DATASET", "confidence": 0.8256326615810394}, {"text": "TreeTag-ger", "start_pos": 48, "end_pos": 59, "type": "DATASET", "confidence": 0.9667453765869141}]}, {"text": "Additionally, we report the average number of suffixes per stem given the part-of-speech.", "labels": [], "entities": []}, {"text": "Our results are consistent with the findings of: the prediction of adjectives is more difficult than that of other POS while Russian verb prediction is relatively easier in spite of the higher number of suffixes per stem.", "labels": [], "entities": [{"text": "Russian verb prediction", "start_pos": 125, "end_pos": 148, "type": "TASK", "confidence": 0.6160690089066824}]}, {"text": "These differences reflect the importance of source versus target context features in the prediction of the target inflection: For instance, adjectives agree in gender with the nouns they modify, but this maybe only inferred from the target context.: Suffix prediction accuracy at top-1 (%), breakdown by category (A: adjectives, V: verbs, N: nouns, M: numerals and P: pronouns).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 268, "end_pos": 276, "type": "METRIC", "confidence": 0.7759243249893188}]}, {"text": "|M \u03c3 | denotes the average number of suffixes per stem.", "labels": [], "entities": []}, {"text": "shows the stem and suffix accuracies of BNN variants on English-Czech.", "labels": [], "entities": []}, {"text": "Although none of the variants outperform our main FFNN architecture, we observe similar performances by the LBL on stem prediction, and by the ConvNet on suffix prediction.", "labels": [], "entities": [{"text": "stem prediction", "start_pos": 115, "end_pos": 130, "type": "TASK", "confidence": 0.8071329593658447}, {"text": "suffix prediction", "start_pos": 154, "end_pos": 171, "type": "TASK", "confidence": 0.8223038911819458}]}, {"text": "This suggests that future work could exploit their additional flexibilities (see Section 4.2) to improve the BNN predictive power.", "labels": [], "entities": [{"text": "BNN predictive", "start_pos": 109, "end_pos": 123, "type": "TASK", "confidence": 0.6164593994617462}]}, {"text": "As for the low suffix accuracy by the LBL, it can be explained by the absence of nonlinearity transformation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.8962283730506897}]}, {"text": "Nonlinearity is important for the suffix model where the prediction of target suffix \u00b5 j often does not depend linearly on s i and \u03c3 j . The predictive representation of target stem in the LBL stem model, however, mainly depends on the source representation r s i through a position dependent weight matrix C 0 . Thus, we observe a smaller accuracy drop in the stem model than in the suffix model.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 340, "end_pos": 348, "type": "METRIC", "confidence": 0.9987461566925049}]}, {"text": "Conversely, the ConvNet performs poorly on stem prediction because it captures the meaning of the whole source context instead of emphasizing the importance of the source word s i as the main predictor of the target translation t j .  While the main objective of this paper is to improve prediction accuracy of word translations, see Section 5, we are also interested in knowing to which extent these improvements carryover within an end-to-end machine translation task.", "labels": [], "entities": [{"text": "stem prediction", "start_pos": 43, "end_pos": 58, "type": "TASK", "confidence": 0.8869372606277466}, {"text": "accuracy", "start_pos": 299, "end_pos": 307, "type": "METRIC", "confidence": 0.9608892202377319}, {"text": "machine translation task", "start_pos": 445, "end_pos": 469, "type": "TASK", "confidence": 0.7837663491566976}]}, {"text": "To this end, we integrate our translation prediction models described in Section 4 into our existing English-Russian SMT system.", "labels": [], "entities": [{"text": "translation prediction", "start_pos": 30, "end_pos": 52, "type": "TASK", "confidence": 0.9678945541381836}, {"text": "SMT", "start_pos": 117, "end_pos": 120, "type": "TASK", "confidence": 0.8892099261283875}]}, {"text": "For each phrase pair matching the input, the phrase BNN score P BNN-p is computed as follows: where a is the word-level alignment of the phrase pair (\u02dc s, \u02dc t) and {a i } is the set of target positions aligned to s i . If a source-target link cannot be scored by the BNN model, we give it a P BNN probability of 1 and increment a separate count feature \u03b5.", "labels": [], "entities": [{"text": "BNN probability", "start_pos": 293, "end_pos": 308, "type": "METRIC", "confidence": 0.8891462087631226}]}, {"text": "Note that the same phrase pair can get different BNN scores if used in different source side contexts.", "labels": [], "entities": [{"text": "BNN", "start_pos": 49, "end_pos": 52, "type": "METRIC", "confidence": 0.9117997884750366}]}, {"text": "Our baseline is an in-house phrase-based () statistical machine translation system very similar to Moses (.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 44, "end_pos": 75, "type": "TASK", "confidence": 0.6626003682613373}]}, {"text": "All system runs use hierarchical lexicalized reordering (, distinguishing between monotone, swap, and discontinuous reordering, all with respect to left-to-right and right-to-left decoding.", "labels": [], "entities": []}, {"text": "Other features include linear distortion, bidirectional lexical weighting (), word and phrase penalties, and finally a word-level 5-gram target LM trained on all available monolingual data with modified Kneser-Ney smoothing: SMT training and test data statistics.", "labels": [], "entities": [{"text": "SMT", "start_pos": 225, "end_pos": 228, "type": "TASK", "confidence": 0.991004228591919}]}, {"text": "All numbers refer to tokenized, lowercased data.", "labels": [], "entities": []}, {"text": "limit is set to 6 and for each source phrase the top 30 translation candidates are considered.", "labels": [], "entities": []}, {"text": "When translating into a morphologically rich language, data sparsity issues in the target language become particularly apparent.", "labels": [], "entities": []}, {"text": "To compensate for this we also experiment with a 5-gram suffix-based LM in addition to the surface-based LM (.", "labels": [], "entities": []}, {"text": "The BNN models are integrated as additional log-probability feature functions (log P BNN-p ): one feature for the word prediction model or two features for the stem and suffix models respectively, plus the penalty feature \u03b5. shows the data used to train our EnglishRussian SMT system.", "labels": [], "entities": [{"text": "BNN-p", "start_pos": 85, "end_pos": 90, "type": "METRIC", "confidence": 0.9326949715614319}, {"text": "word prediction", "start_pos": 114, "end_pos": 129, "type": "TASK", "confidence": 0.7228590548038483}, {"text": "SMT", "start_pos": 273, "end_pos": 276, "type": "TASK", "confidence": 0.6980949640274048}]}, {"text": "The feature weights for all approaches were tuned by using pairwise ranking optimization (Hopkins and May, 2011) on the wmt12 benchmark.", "labels": [], "entities": [{"text": "wmt12 benchmark", "start_pos": 120, "end_pos": 135, "type": "DATASET", "confidence": 0.9071959257125854}]}, {"text": "During tuning, 14 PRO parameter estimation runs are performed in parallel on different samples of the n-best list after each decoder iteration.", "labels": [], "entities": [{"text": "PRO parameter estimation", "start_pos": 18, "end_pos": 42, "type": "TASK", "confidence": 0.8499823013941447}]}, {"text": "The weights of the individual PRO runs are then averaged and passed onto the next decoding iteration.", "labels": [], "entities": []}, {"text": "Performing weight estimation independently fora number of samples corrects for some of the instability that can be caused by individual samples.", "labels": [], "entities": [{"text": "weight estimation", "start_pos": 11, "end_pos": 28, "type": "TASK", "confidence": 0.6462291926145554}]}, {"text": "The wmt13 set () was used for testing.", "labels": [], "entities": [{"text": "wmt13 set", "start_pos": 4, "end_pos": 13, "type": "DATASET", "confidence": 0.8329885601997375}]}, {"text": "We use approximate randomization to test for statistically significant differences between runs ().", "labels": [], "entities": []}, {"text": "Translation quality is measured with caseinsensitive BLEU[%] using one reference translation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 53, "end_pos": 57, "type": "METRIC", "confidence": 0.9778122305870056}]}, {"text": "As shown in, statistically significant improvements over the respective baseline (Baseline and Base+suffLM) are marked at the p < .01 level.", "labels": [], "entities": [{"text": "Base+suffLM)", "start_pos": 95, "end_pos": 107, "type": "METRIC", "confidence": 0.8986589461565018}]}, {"text": "Integrating our bilingual neural network approach into our SMT system yields small but statistically significant improvements of 0.4 BLEU over a competitive baseline.", "labels": [], "entities": [{"text": "SMT", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.9919969439506531}, {"text": "BLEU", "start_pos": 133, "end_pos": 137, "type": "METRIC", "confidence": 0.9990960359573364}]}, {"text": "We can also  To better understand the BNN effect on the SMT system, we analyze the set of phrase pairs that are employed by the decoder to translate each sentence.", "labels": [], "entities": [{"text": "SMT", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.992905855178833}]}, {"text": "This set is ranked by the weighted combination of phrase translation and lexical weighting scores, target language model score and, if available, phrase BNN scores.", "labels": [], "entities": [{"text": "phrase translation and lexical weighting", "start_pos": 50, "end_pos": 90, "type": "TASK", "confidence": 0.7965776443481445}]}, {"text": "As shown in Table 9, the morphological BNN models have a positive effect on the decoder's lexical search space increasing the recall of reference tokens among the top 1 and 3 phrase translation candidates.", "labels": [], "entities": [{"text": "recall", "start_pos": 126, "end_pos": 132, "type": "METRIC", "confidence": 0.9978731870651245}, {"text": "phrase translation", "start_pos": 175, "end_pos": 193, "type": "TASK", "confidence": 0.7252068221569061}]}, {"text": "The mean reciprocal rank (MRR) also improves from 0.655 to 0.662.", "labels": [], "entities": [{"text": "mean reciprocal rank (MRR)", "start_pos": 4, "end_pos": 30, "type": "METRIC", "confidence": 0.8704027930895487}]}, {"text": "Looking at the 1-best SMT output, we observe a slight increase of reference/output recall (50.0% to 50.7%), which is less than the increase we observe for the top 1 translation candidates (57.6% to 59.0%: Target word coverage analysis of the English-Russian SMT system before and after adding the morphological BNN models.", "labels": [], "entities": [{"text": "SMT", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9736029505729675}, {"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9471833109855652}, {"text": "SMT", "start_pos": 258, "end_pos": 261, "type": "TASK", "confidence": 0.8927369117736816}]}, {"text": "like the target LM, that are based on traditional maximum-likelihood estimates.", "labels": [], "entities": []}, {"text": "While the suffixbased LMs proved beneficial in our experiments, we speculate that higher gains could be obtained by coupling our approach with a morphologyaware neural LM like the one recently presented by.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: BNN training corpora statistics: number  of sentences, tokens, and type/token ratio (T/T).", "labels": [], "entities": []}, {"text": " Table 3: BNN prediction accuracy (top-1/top-3)  compared to a context-independent maximum- likelihood baseline.", "labels": [], "entities": [{"text": "BNN prediction", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.6547124087810516}, {"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.8529478907585144}]}, {"text": " Table 4: Accuracy at top-1/top-3 (%) of stem and  suffix BNNs with different training data sizes.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9941315054893494}]}, {"text": " Table 5: Suffix prediction accuracy at top-1 (%),  breakdown by category (A: adjectives, V: verbs,  N: nouns, M: numerals and P: pronouns). |M \u03c3 |  denotes the average number of suffixes per stem.", "labels": [], "entities": [{"text": "Suffix prediction accuracy", "start_pos": 10, "end_pos": 36, "type": "METRIC", "confidence": 0.6549816330273946}]}, {"text": " Table 6: Accuracies at top-1/top-3 (%) of stem and  suffix models. +do indicates dropout instead of L 2  regularizer. FFNN is our main architecture.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9902961850166321}]}, {"text": " Table 7: SMT training and test data statistics. All  numbers refer to tokenized, lowercased data.", "labels": [], "entities": [{"text": "SMT training", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.8773484826087952}]}, {"text": " Table 8: Effect of our BNN models on English- Russian translation quality (BLEU[%]).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 76, "end_pos": 80, "type": "METRIC", "confidence": 0.9961685538291931}]}, {"text": " Table 9: Target word coverage analysis of the  English-Russian SMT system before and after  adding the morphological BNN models.", "labels": [], "entities": [{"text": "Target word coverage analysis", "start_pos": 10, "end_pos": 39, "type": "TASK", "confidence": 0.7096680700778961}, {"text": "SMT", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9333425164222717}]}]}