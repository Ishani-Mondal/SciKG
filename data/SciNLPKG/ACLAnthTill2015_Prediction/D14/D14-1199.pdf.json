{"title": [{"text": "Event Role Extraction using Domain-Relevant Word Representations", "labels": [], "entities": [{"text": "Event Role Extraction", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7177990674972534}]}], "abstractContent": [{"text": "The efficiency of Information Extraction systems is known to be heavily influenced by domain-specific knowledge but the cost of developing such systems is considerably high.", "labels": [], "entities": [{"text": "Information Extraction", "start_pos": 18, "end_pos": 40, "type": "TASK", "confidence": 0.7875894904136658}]}, {"text": "In this article, we consider the problem of event extraction and show that learning word representations from unla-beled domain-specific data and using them for representing event roles enable to out-perform previous state-of-the-art event extraction models on the MUC-4 data set.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 44, "end_pos": 60, "type": "TASK", "confidence": 0.7321188300848007}, {"text": "MUC-4 data set", "start_pos": 265, "end_pos": 279, "type": "DATASET", "confidence": 0.955707053343455}]}], "introductionContent": [{"text": "In the Information Extraction (IE) field, event extraction constitutes a challenging task.", "labels": [], "entities": [{"text": "Information Extraction (IE) field", "start_pos": 7, "end_pos": 40, "type": "TASK", "confidence": 0.8550145626068115}, {"text": "event extraction", "start_pos": 42, "end_pos": 58, "type": "TASK", "confidence": 0.7913782596588135}]}, {"text": "An event is described by a set of participants (i.e. attributes or roles) whose values are text excerpts.", "labels": [], "entities": []}, {"text": "The event extraction task is related to several subtasks: event mention detection, candidate rolefiller extraction, relation extraction and event template filling.", "labels": [], "entities": [{"text": "event extraction task", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.7972613374392191}, {"text": "event mention detection", "start_pos": 58, "end_pos": 81, "type": "TASK", "confidence": 0.754318118095398}, {"text": "candidate rolefiller extraction", "start_pos": 83, "end_pos": 114, "type": "TASK", "confidence": 0.6967986027399699}, {"text": "relation extraction", "start_pos": 116, "end_pos": 135, "type": "TASK", "confidence": 0.8706718981266022}, {"text": "event template filling", "start_pos": 140, "end_pos": 162, "type": "TASK", "confidence": 0.6590561270713806}]}, {"text": "The problem we address here is the detection of role-filler candidates and their association with specific roles in event templates.", "labels": [], "entities": []}, {"text": "For this task, IE systems adopt various ways of extracting patterns or generating rules based on the surrounding context, local context and global context (.", "labels": [], "entities": [{"text": "IE", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.969996452331543}]}, {"text": "Current approaches for learning such patterns include bootstrapping techniques;), weakly supervised learning algorithms (), fully supervised learning approaches () and other variations.", "labels": [], "entities": []}, {"text": "All these methods rely on substantial amounts of manually annotated corpora and use a large body of linguistic knowledge.", "labels": [], "entities": []}, {"text": "The performance of these approaches is related to the amount of knowledge engineering deployed and a good choice of features and classifiers.", "labels": [], "entities": []}, {"text": "Furthermore, the efficiency of the system relies on the a priori knowledge of the applicative domain (the nature of the events) and it is generally difficult to apply a system on a different domain with less annotated data without reconsidering the design of the features used.", "labels": [], "entities": []}, {"text": "An important step forwards is TIER light) that targeted the minimization of human supervision with a bootstrapping technique for event roles detection.", "labels": [], "entities": [{"text": "TIER", "start_pos": 30, "end_pos": 34, "type": "METRIC", "confidence": 0.8129394054412842}, {"text": "event roles detection", "start_pos": 129, "end_pos": 150, "type": "TASK", "confidence": 0.6732210516929626}]}, {"text": "Also, PIPER distinguishes between relevant and irrelevant regions and learns domain-relevant extraction patterns using a semantic affinity measure.", "labels": [], "entities": []}, {"text": "Another possible approach for dealing with this problem is to combine the use a restricted set of manually annotated data with a much larger set of data extracted in an unsupervised way from a corpus.", "labels": [], "entities": []}, {"text": "This approach was experimented for relations in the context of Open Information Extraction ( but not for extracting events and their participants to our knowledge.", "labels": [], "entities": [{"text": "Open Information Extraction", "start_pos": 63, "end_pos": 90, "type": "TASK", "confidence": 0.6132075687249502}]}, {"text": "In this paper, we propose to approach the task of labeling text spans with event roles by automatically learning relevant features that requires limited prior knowledge, using a neural model to induce semantic word representations (commonly referred as word embeddings) in an unsupervised fashion, as in (.", "labels": [], "entities": [{"text": "labeling text spans", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.8843469023704529}]}, {"text": "We exploit these word embeddings as features fora supervised event role (multiclass) classifier.", "labels": [], "entities": []}, {"text": "This type of approach has been proved efficient for numerous tasks in natural language processing, including named entity recognition (, semantic role labeling ), machine translation (, word sense disambiguation () or sentiment analysis) but has never been used, to our knowl-edge, for an event extraction task.", "labels": [], "entities": [{"text": "named entity recognition", "start_pos": 109, "end_pos": 133, "type": "TASK", "confidence": 0.6253737608591715}, {"text": "semantic role labeling )", "start_pos": 137, "end_pos": 161, "type": "TASK", "confidence": 0.7430462539196014}, {"text": "machine translation", "start_pos": 163, "end_pos": 182, "type": "TASK", "confidence": 0.7917070984840393}, {"text": "word sense disambiguation", "start_pos": 186, "end_pos": 211, "type": "TASK", "confidence": 0.6233610113461813}, {"text": "sentiment analysis", "start_pos": 218, "end_pos": 236, "type": "TASK", "confidence": 0.785762757062912}, {"text": "event extraction task", "start_pos": 289, "end_pos": 310, "type": "TASK", "confidence": 0.7941558460394541}]}, {"text": "Our goal is twofold: (1) to prove that using as only features word vector representations makes the approach competitive in the event extraction task; (2) to show that these word representations are scalable and robust when varying the size of the training data.", "labels": [], "entities": [{"text": "event extraction task", "start_pos": 128, "end_pos": 149, "type": "TASK", "confidence": 0.79380664229393}]}, {"text": "Focusing on the data provided in MUC-4 (, we prove the relevance of our approach by outperforming state-of-the-art methods, in the same evaluation environment as in previous works.", "labels": [], "entities": [{"text": "MUC-4", "start_pos": 33, "end_pos": 38, "type": "DATASET", "confidence": 0.8721683621406555}]}], "datasetContent": [{"text": "In all the experiments involving our model, we established the following stable choices of parameters: 50-dimensional vectors obtained by training on sequences of 5 words, which is consistent with previous studies.", "labels": [], "entities": []}, {"text": "All the hyper-parameters of our model (e.g. learning rate, size of the hidden layer, size of the word vectors) have been chosen by finetuning our event extraction system on the TST1+TST2 data set.", "labels": [], "entities": [{"text": "TST1+TST2 data set", "start_pos": 177, "end_pos": 195, "type": "DATASET", "confidence": 0.7468563199043274}]}, {"text": "For DRVR-50 and W2V-50, the embeddings were built from the whole training corpus (1,300 documents) and the dictionary was made of all the words of this corpus under their inflected form.", "labels": [], "entities": [{"text": "DRVR-50", "start_pos": 4, "end_pos": 11, "type": "DATASET", "confidence": 0.9722059369087219}]}, {"text": "We used the extra-trees ensemble classifier implemented in), with hyperparameters optimized on the validation data: forest of 500 trees and the maximum number of features to consider when looking for the best split is \u221a number f eatures.", "labels": [], "entities": []}, {"text": "We present a 3-fold evaluation: first, we compare our system with state-of-the-art systems on the same task, then we compare our domain-relevant vector representations (DRVR-50) to more generic word embeddings (C&W50, HLBL-50) and finally to another word representation construction on the domainspecific data (W2V-50) 4 . Figure 1: F1-score results for event role labeling on MUC-4 data, for different size of training data, of \"String Slots\" on the TST3+TST4 with different parameters, compared to the learning curve of TIER ().", "labels": [], "entities": [{"text": "F1-score", "start_pos": 333, "end_pos": 341, "type": "METRIC", "confidence": 0.9992951154708862}, {"text": "event role labeling", "start_pos": 354, "end_pos": 373, "type": "TASK", "confidence": 0.6275904973347982}, {"text": "MUC-4 data", "start_pos": 377, "end_pos": 387, "type": "DATASET", "confidence": 0.7676181793212891}, {"text": "TST3+TST4", "start_pos": 451, "end_pos": 460, "type": "DATASET", "confidence": 0.7691352963447571}, {"text": "TIER", "start_pos": 522, "end_pos": 526, "type": "METRIC", "confidence": 0.48314154148101807}]}, {"text": "The grey points represent the performances of other IE systems.", "labels": [], "entities": [{"text": "IE", "start_pos": 52, "end_pos": 54, "type": "TASK", "confidence": 0.8916382789611816}]}, {"text": "presents the average F1-score results, computed over the slots PerpInd, PerpOrg, Target, Victim and Weapon.", "labels": [], "entities": [{"text": "F1-score", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.9991875290870667}]}, {"text": "We observe that models relying on word embeddings globally outperform the state-of-the-art results, which demonstrates that the word embeddings capture enough semantic information to perform the task of event newswire corpus 4 W2V-50 are the embeddings induced from the MUC4 data set using the negative sampling training algorithm (), available at https://code.google.com/ p/word2vec/ role labeling on \"String Slots\" without using any additional hand-engineered features.", "labels": [], "entities": [{"text": "event newswire corpus 4 W2V-50", "start_pos": 203, "end_pos": 233, "type": "DATASET", "confidence": 0.6990050613880158}, {"text": "MUC4 data set", "start_pos": 270, "end_pos": 283, "type": "DATASET", "confidence": 0.9393949111302694}]}, {"text": "Moreover, our representations (DRVR-50) clearly surpass the models based on generic embeddings (C&W-50 and HLBL-50) and obtain better results than W2V-50, based the competitive model of), even if the difference is small.", "labels": [], "entities": [{"text": "DRVR-50", "start_pos": 31, "end_pos": 38, "type": "DATASET", "confidence": 0.9098135232925415}]}, {"text": "We can also note that the performance of our model is good even with a small amount of training data, which makes it a good candidate to easily develop an event extraction system on anew domain.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 155, "end_pos": 171, "type": "TASK", "confidence": 0.7504745423793793}]}, {"text": "provides a more detailed analysis of the comparative results.", "labels": [], "entities": []}, {"text": "We can see in this table that our results surpass those of previous systems (0.73 vs. 0.59) with, particularly, a consistently higher precision on all roles, whereas recall is smaller for certain roles (Target and Weapon).", "labels": [], "entities": [{"text": "precision", "start_pos": 134, "end_pos": 143, "type": "METRIC", "confidence": 0.9981638789176941}, {"text": "recall", "start_pos": 166, "end_pos": 172, "type": "METRIC", "confidence": 0.9992928504943848}]}, {"text": "To further explore the impact of these representations, we compared our word embeddings with other word embeddings (C&W-50, HLBL-50) and report the results in and.", "labels": [], "entities": []}, {"text": "The results show that our model also outperforms the models using others word embeddings (F1-score of 0.73 against 0.65, 0.66).", "labels": [], "entities": [{"text": "F1-score", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9995065927505493}]}, {"text": "This proves that a model learned on a domain-specific data set does indeed provide better results, even if its size is much smaller (whereas it is usually considered that neural models require often important training data).", "labels": [], "entities": []}, {"text": "Finally, we also achieve slightly better results than W2V-50 with other word representations built on the same corpus, which shows that the choices made for the word representation construction, such as the use of domain information for word ordering, tend to have a positive impact.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 237, "end_pos": 250, "type": "TASK", "confidence": 0.7191628515720367}]}], "tableCaptions": [{"text": " Table 1: Accuracy of \"String Slots\" on the TST3 + TST4 test set P/R/F1 (Precision/Recall/F1-Score)", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9978501796722412}, {"text": "TST3 + TST4 test set P", "start_pos": 44, "end_pos": 66, "type": "DATASET", "confidence": 0.83511949578921}, {"text": "F1", "start_pos": 69, "end_pos": 71, "type": "METRIC", "confidence": 0.6419622898101807}, {"text": "F1-Score", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.5013415217399597}]}]}