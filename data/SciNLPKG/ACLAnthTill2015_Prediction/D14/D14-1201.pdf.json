{"title": [{"text": "ZORE: A Syntax-based System for Chinese Open Relation Extraction", "labels": [], "entities": [{"text": "Chinese Open Relation Extraction", "start_pos": 32, "end_pos": 64, "type": "TASK", "confidence": 0.639825165271759}]}], "abstractContent": [{"text": "Open Relation Extraction (ORE) overcomes the limitations of traditional IE techniques, which train individual extrac-tors for every single relation type.", "labels": [], "entities": [{"text": "Open Relation Extraction (ORE)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7860032767057419}]}, {"text": "Systems such as ReVerb, PATTY, OLLIE, and Exemplar have attracted much attention on English ORE.", "labels": [], "entities": [{"text": "PATTY", "start_pos": 24, "end_pos": 29, "type": "METRIC", "confidence": 0.8013491630554199}, {"text": "OLLIE", "start_pos": 31, "end_pos": 36, "type": "METRIC", "confidence": 0.9498348236083984}, {"text": "ORE", "start_pos": 92, "end_pos": 95, "type": "METRIC", "confidence": 0.835457980632782}]}, {"text": "However, few studies have been reported on ORE for languages beyond English.", "labels": [], "entities": [{"text": "ORE", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.9822986125946045}]}, {"text": "This paper presents a syntax-based Chinese (Zh) ORE system, ZORE, for extracting relations and semantic patterns from Chinese text.", "labels": [], "entities": [{"text": "ORE", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9104204177856445}, {"text": "extracting relations and semantic patterns from Chinese text", "start_pos": 70, "end_pos": 130, "type": "TASK", "confidence": 0.7990506738424301}]}, {"text": "ZORE identifies relation candidates from automatically parsed dependency trees, and then extracts relations with their semantic patterns iteratively through a novel double propagation algorithm.", "labels": [], "entities": []}, {"text": "Empirical results on two data sets show the effectiveness of the proposed system.", "labels": [], "entities": []}], "introductionContent": [{"text": "Traditional Information Extraction (IE) systems train extractors for pre-specified relations.", "labels": [], "entities": [{"text": "Information Extraction (IE)", "start_pos": 12, "end_pos": 39, "type": "TASK", "confidence": 0.8054952383041382}]}, {"text": "This approach cannot scale to the web, where target relations are not defined in advance.", "labels": [], "entities": []}, {"text": "Open Relation Extraction (ORE) attempts to solve this problem by shallow-parsingbased, syntax-based or semantic-role-based pattern matching without pre-defined relation types, and has achieved great success on open-domain corpora ranging from news to Wikipedia ().", "labels": [], "entities": [{"text": "Open Relation Extraction (ORE)", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7835156520207723}]}, {"text": "Many NLP and IR applications, including selectional preference learning, commonsense knowledge and entailment rule mining, have benefited from ORE (.", "labels": [], "entities": [{"text": "selectional preference learning", "start_pos": 40, "end_pos": 71, "type": "TASK", "confidence": 0.771091639995575}, {"text": "entailment rule mining", "start_pos": 99, "end_pos": 121, "type": "TASK", "confidence": 0.6494050323963165}, {"text": "ORE", "start_pos": 143, "end_pos": 146, "type": "METRIC", "confidence": 0.9718179106712341}]}, {"text": "However, most existing ORE systems focus on English, and little research has been reported on other languages.", "labels": [], "entities": []}, {"text": "In addition, existing ORE techniques are mainly concerned with the extraction of textual relations, without trying to give semantic analysis, which is the advantage of traditional IE.", "labels": [], "entities": [{"text": "semantic analysis", "start_pos": 123, "end_pos": 140, "type": "TASK", "confidence": 0.7106253206729889}]}, {"text": "Our goal in this paper is to present a syntaxbased Chinese (Zh) ORE system, ZORE, which extracts relations by using syntactic dependency patterns, while associating them with explicit semantic information.", "labels": [], "entities": [{"text": "ORE", "start_pos": 64, "end_pos": 67, "type": "METRIC", "confidence": 0.892585813999176}]}, {"text": "An example is shown is, where the relation (c n \u00ea (Obama) o\u00da (President) , Pred[.'", "labels": [], "entities": [{"text": "Pred", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.9982125759124756}]}, {"text": "(graduate)], M \u00c3 (Harvard) { AE (Law School)) is extracted from the given sentence \"cn\u00ea (Obama) o \u00da (President) . ' (graduate) u (from) M \u00c3 (Harvard) { AE (Law School)\", and generalized into the syntactic-semantic pattern {nsubj-NR(Af) Pred[. ' (graduate)] prep-u (from) pobj-NN(Di)}.", "labels": [], "entities": []}, {"text": "Here, Af and Di stand for human and institution, respectively, according to a Chinese taxonomy Extended Cilin (.", "labels": [], "entities": []}, {"text": "Rather than extracting binary relations and then generalizing them into semantic patterns, which most previous work does, we develop a novel method that extracts relations and patterns simultaneously.", "labels": [], "entities": []}, {"text": "A double propagation algorithm is used to make relation and pattern information reinforce each other, so that negative effects from automatic syntactic and semantic analysis errors can be mitigated.", "labels": [], "entities": []}, {"text": "In this way, semantic pattern information is leveraged to improve relation extraction.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.9101801514625549}]}, {"text": "We manually annotate two sets of data, from news text and Wikipedia, respectively.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 58, "end_pos": 67, "type": "DATASET", "confidence": 0.9030442237854004}]}, {"text": "Experiments on both data sets show that the double propagation algorithm gives better precision and recall compared to the baseline.", "labels": [], "entities": [{"text": "precision", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.99932861328125}, {"text": "recall", "start_pos": 100, "end_pos": 106, "type": "METRIC", "confidence": 0.9994705319404602}]}, {"text": "To our knowledge, we are one of the first to report empirical results on Chinese ORE.", "labels": [], "entities": [{"text": "Chinese ORE", "start_pos": 73, "end_pos": 84, "type": "DATASET", "confidence": 0.7154077887535095}]}, {"text": "The ZORE system, together with the two sets of test data we annotated, and the sets of 5 million relations and 344K semantic patterns extracted from news and Wikipedia, is freely re-", "labels": [], "entities": []}], "datasetContent": [{"text": "We run ZORE on two difference corpora: the Chinese edition of Wikipedia (Wiki), which contains 4.3 million sentences (as of, and a corpus from the Sina News archive (Sina News), which includes 6.1 million sentences from January 2013 to May 2013.", "labels": [], "entities": [{"text": "Sina News archive (Sina News)", "start_pos": 147, "end_pos": 176, "type": "DATASET", "confidence": 0.906793475151062}]}, {"text": "The sentences that do not end with punctuations are filtered.", "labels": [], "entities": []}, {"text": "The Chinese taxonomy Extended Cilin 2 (Cilin) () is used to give semantic categories for each word.", "labels": [], "entities": []}, {"text": "Cilin contains 77,492 Chinese words, organized into a five-level hierarchy.", "labels": [], "entities": []}, {"text": "There are 12 categories in the top level, 94 in the second and 1492 in the third.", "labels": [], "entities": []}, {"text": "In this paper, the second level is used for semantic categories.", "labels": [], "entities": []}, {"text": "We create two test sets, containing 500 sentences from Wiki and 500 sentences from Sina News, respectively (see), annotated by two independent annotators using the annotation strategy of . The thresholds t lvc and t sem for pattern matching are set as 0.4 and 5, tuned on 100 sentences from Wiki-500 dataset, respectively.", "labels": [], "entities": [{"text": "Sina News", "start_pos": 83, "end_pos": 92, "type": "DATASET", "confidence": 0.8777039647102356}, {"text": "pattern matching", "start_pos": 224, "end_pos": 240, "type": "TASK", "confidence": 0.6826553791761398}, {"text": "Wiki-500 dataset", "start_pos": 291, "end_pos": 307, "type": "DATASET", "confidence": 0.9161631166934967}]}, {"text": "First, we compare ZORE with a baseline system to illustrate the effectiveness of the double propagation algorithm.", "labels": [], "entities": []}, {"text": "The baseline system does not have the double propagation tagging component in   measure the precision and recall of the extracted relations.", "labels": [], "entities": [{"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9987797141075134}, {"text": "recall", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.9962831139564514}]}, {"text": "An extracted relation is considered correct only when the predicate phrase and all the arguments match the the gold set.", "labels": [], "entities": []}, {"text": "On each data set, we perform 5-fold cross-validation test and take the average as the final precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9978229999542236}, {"text": "recall", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.9983336329460144}]}, {"text": "show the comparison of the two systems on Wiki and Sina News, respectively.", "labels": [], "entities": [{"text": "Wiki", "start_pos": 42, "end_pos": 46, "type": "DATASET", "confidence": 0.9594709873199463}, {"text": "Sina News", "start_pos": 51, "end_pos": 60, "type": "DATASET", "confidence": 0.8241633176803589}]}, {"text": "On Wiki, ZORE has higher precision than the baseline at all levels of recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 25, "end_pos": 34, "type": "METRIC", "confidence": 0.9994183778762817}, {"text": "recall", "start_pos": 70, "end_pos": 76, "type": "METRIC", "confidence": 0.9967495203018188}]}, {"text": "When the recall is 0.3, the precision of ZORE is 0.77, 0.11 higher than the baseline.", "labels": [], "entities": [{"text": "recall", "start_pos": 9, "end_pos": 15, "type": "METRIC", "confidence": 0.9995179176330566}, {"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9996765851974487}, {"text": "ZORE", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.8896246552467346}]}, {"text": "The result on Sina News is similar.", "labels": [], "entities": [{"text": "Sina News", "start_pos": 14, "end_pos": 23, "type": "DATASET", "confidence": 0.9123901724815369}]}, {"text": "The second column of shows the weights of all features trained on the Wiki data set, which indicates that the semantic pattern features can give a positive effect on relation filtering.", "labels": [], "entities": [{"text": "Wiki data set", "start_pos": 70, "end_pos": 83, "type": "DATASET", "confidence": 0.9479122559229533}, {"text": "relation filtering", "start_pos": 166, "end_pos": 184, "type": "TASK", "confidence": 0.9104814827442169}]}, {"text": "Second, we compare the intermediate results at Steps 1, 2, and 3 in Section 3.2, respectively.", "labels": [], "entities": []}, {"text": "The precision, recall and F1 of the three steps with different numbers of Wiki sentences (from 10K to 5M sentences) are shown in.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.999559223651886}, {"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9996352195739746}, {"text": "F1", "start_pos": 26, "end_pos": 28, "type": "METRIC", "confidence": 0.9996343851089478}]}, {"text": "This figure shows that Step 2 achieves higher precision than Step 1 at all levels of recall, indicating that the word sense tagging method in step 2 is useful for 1876  ZORE acquires 122K and 222K patterns from Wiki and Sina News, clustered into 59K and 118K pattern synsets, respectively.", "labels": [], "entities": [{"text": "precision", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9972317814826965}, {"text": "recall", "start_pos": 85, "end_pos": 91, "type": "METRIC", "confidence": 0.9893128275871277}, {"text": "word sense tagging", "start_pos": 113, "end_pos": 131, "type": "TASK", "confidence": 0.7009457548459371}]}, {"text": "The frequency distribution of the Wiki patterns is shown in, which conforms to Zipf's law.", "labels": [], "entities": []}, {"text": "To assess the accuracy of pattern extraction, we rank the extracted patterns by the size, and evaluated the precision of the top 100 and a random set of 100 pattern synsets.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9981493949890137}, {"text": "pattern extraction", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7979266047477722}, {"text": "precision", "start_pos": 108, "end_pos": 117, "type": "METRIC", "confidence": 0.9992778897285461}]}, {"text": "Two annotators were shown a pattern synset with its semantic signature and a few example relations, and then asked to judge whether it indicates a valid semantic relation or not.", "labels": [], "entities": []}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "The averaged precision is 92% for the top 100 set, and 85% for the random 100 set.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9631454944610596}]}, {"text": "The patterns in a pattern synset can betaken as paraphrases (.", "labels": [], "entities": []}, {"text": "We observe that two synonymous patterns might differ in three aspects.", "labels": [], "entities": []}, {"text": "First, two patterns can differ by the predicates, which are synonyms.", "labels": [], "entities": []}, {"text": "For instance, the verbs \"\u00fa ?, , ?, \u00d1 ?, \u2022, \u2030\" are synonyms, meaning \"to hold the appointment of\".", "labels": [], "entities": []}, {"text": "Second, two patterns in the same synset can belong to different syntactic patterns, and therefore are paraphrases in the syntactic level.", "labels": [], "entities": []}, {"text": "For instance, the semantic patterns of the two sentences \".'", "labels": [], "entities": []}, {"text": "(graduate) u (from) M\u00c3 (Harvard) {AE (Law School) (de, an auxiliary word) cn \u00ea (Obama) o\u00da (president)\" and \"cn\u00ea (Obama) o\u00da (president) l(from) M\u00c3 (Harvard) { AE (Law School) .' (graduate)\" are both synonymous to that of the sentence in; all the three patterns are found in the same synset obtained by ZORE.", "labels": [], "entities": [{"text": "AE", "start_pos": 34, "end_pos": 36, "type": "METRIC", "confidence": 0.7498098611831665}]}, {"text": "Third, two patterns can differ only by the POS-tag.", "labels": [], "entities": []}, {"text": "For instance, \"cn\u00ea (Obama) l(from) M\u00c3 (Harvard) {AE (Law School) .' (graduate)\" and \"@ \u2021 (That) AE\" (attorney) l(from) M\u00c3 (Harvard) {AE (Law School) .' (graduate)\" are synonyms with different POS-tags for the first argument (i.e. N-R and NN).", "labels": [], "entities": []}, {"text": "According to the grouping algorithm in Section 3.3, all the three types of paraphrases are grouped in a pattern synset, which makes some synsets very large.", "labels": [], "entities": []}, {"text": "The largest synset contains 110 patterns, while the top 100 synsets contain more than 20 patterns.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Features of the logistic regression classi- fier with weights trained on Wiki-500 dataset.", "labels": [], "entities": [{"text": "Wiki-500 dataset", "start_pos": 83, "end_pos": 99, "type": "DATASET", "confidence": 0.9781555235385895}]}, {"text": " Table 4: Annotated relation datasets.", "labels": [], "entities": []}, {"text": " Table 5: Accuracies on different numbers Wiki sentences.", "labels": [], "entities": [{"text": "Accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9925578832626343}]}, {"text": " Table 6: Precision of pattern synsets.", "labels": [], "entities": []}]}