{"title": [{"text": "Ambiguity Resolution for Vt-N Structures in Chinese", "labels": [], "entities": [{"text": "Ambiguity Resolution", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9120608866214752}]}], "abstractContent": [{"text": "The syntactic ambiguity of a transitive verb (Vt) followed by a noun (N) has long been a problem in Chinese parsing.", "labels": [], "entities": []}, {"text": "In this paper, we propose a classifier to resolve the ambiguity of Vt-N structures.", "labels": [], "entities": []}, {"text": "The design of the classifier is based on three important guidelines, namely, adopting linguistically motivated features, using all available resources, and easy integration into a parsing model.", "labels": [], "entities": []}, {"text": "The linguistically motivated features include semantic relations, context, and morphological structures; and the available resources are treebank, thesaurus, affix database , and large corpora.", "labels": [], "entities": []}, {"text": "We also propose two learning approaches that resolve the problem of data sparseness by auto-parsing and extracting relative knowledge from large-scale unlabeled data.", "labels": [], "entities": []}, {"text": "Our experiment results show that the Vt-N classifier outperforms the current PCFG parser.", "labels": [], "entities": []}, {"text": "Furthermore, it can be easily and effectively integrated into the PCFG parser and general statistical parsing models.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 66, "end_pos": 70, "type": "DATASET", "confidence": 0.8933508992195129}, {"text": "statistical parsing", "start_pos": 90, "end_pos": 109, "type": "TASK", "confidence": 0.5473766177892685}]}, {"text": "Evaluation of the learning approaches indicates that world knowledge facilitates Vt-N disambigua-tion through data selection and error correction .", "labels": [], "entities": [{"text": "Vt-N disambigua-tion", "start_pos": 81, "end_pos": 101, "type": "TASK", "confidence": 0.7835306823253632}]}], "introductionContent": [{"text": "In Chinese, the structure of a transitive verb (Vt) followed by a noun (N) maybe a verb phrase (VP), a noun phrase (NP), or there may not be a dependent relation, as shown in (1) below.", "labels": [], "entities": []}, {"text": "In general, parsers may prefer VP reading because a transitive verb followed by a noun object is normally a VP structure.", "labels": [], "entities": [{"text": "VP reading", "start_pos": 31, "end_pos": 41, "type": "TASK", "confidence": 0.898892343044281}]}, {"text": "However, Chinese verbs can also modify nouns without morphological inflection, e.g., \u990a\u6b96/farming \u6c60/pond.", "labels": [], "entities": []}, {"text": "Consequently, parsing Vt-N structures is difficult because it is hard to resolve such ambiguities without prior knowledge.", "labels": [], "entities": [{"text": "parsing Vt-N structures", "start_pos": 14, "end_pos": 37, "type": "TASK", "confidence": 0.8638165593147278}]}, {"text": "The following are some typical examples of various Vt-N structures:", "labels": [], "entities": []}], "datasetContent": [{"text": "We classify Vt-N structures into four types of syntactic structures by using the bracketed information (tree structure) and dependency relation (head-modifier) to extract the Vt-N relations from treebank automatically.", "labels": [], "entities": []}, {"text": "The resources used in the experiments as follows.", "labels": [], "entities": []}, {"text": "Treebank: The Sinica Treebank contains 61,087 syntactic tree structures with 361,834 words.", "labels": [], "entities": [{"text": "Sinica Treebank", "start_pos": 14, "end_pos": 29, "type": "DATASET", "confidence": 0.7189033180475235}]}, {"text": "We extracted 9,017 instances of Vt-N structures from the corpus.", "labels": [], "entities": []}, {"text": "Then, we randomly selected 1,000 of the instances as test data and used the remainder (8,017 instances) as training data.", "labels": [], "entities": []}, {"text": "Labeled information of word segmentation and PoS-tagging were retained and utilized in the experiments.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7260256409645081}]}, {"text": "E-HowNet: E-HowNet contains 99,525 lexical semantic definitions that provide information about the semantic type of words.", "labels": [], "entities": []}, {"text": "We also implement the semantic type predication algorithm in to generate the semantic types of all Vt and N words, including unknown words.", "labels": [], "entities": [{"text": "semantic type predication", "start_pos": 22, "end_pos": 47, "type": "TASK", "confidence": 0.6481798390547434}]}, {"text": "Affix Data: The database includes 13,287 examples of verbs and 27,267 examples of nouns, each example relates to an affix.", "labels": [], "entities": [{"text": "Affix", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.934985876083374}]}, {"text": "The detailed statistics of the verb morph-structure categorization are shown in.", "labels": [], "entities": []}, {"text": "The data is used to train a classifier to predicate the morph-structure of verbs.", "labels": [], "entities": []}, {"text": "We found that verbs with a conjunctive structure (VV) are more likely to play adjectival roles than the other three types of verbs.", "labels": [], "entities": []}, {"text": "The classifier achieved 87.88% accuracy on 10-fold cross validation of the above 13,287 verbs..", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9994820952415466}]}, {"text": "The statistics of verb morph-structure categorization Large Corpus: We used a Chinese parser to analyze sentence structures automatically.", "labels": [], "entities": [{"text": "verb morph-structure categorization", "start_pos": 18, "end_pos": 53, "type": "TASK", "confidence": 0.6608127951622009}]}, {"text": "The auto-parsed tree structures are used in Experiment 2 (described in the Sub-section 4.3).", "labels": [], "entities": []}, {"text": "We obtained 1,262,420 parsed sentences and derived 237,843 instances of Vt-N structure as our dataset (called as ASBC).", "labels": [], "entities": []}, {"text": "In this experiment, we used the Maximum Entropy Toolkit) to develop the Vt-N classifier.", "labels": [], "entities": []}, {"text": "Based on the features discussed in Section 3.1, we designed five models to evaluate the classifier's performance on different feature combinations.", "labels": [], "entities": []}, {"text": "The features and used in each model are described below.", "labels": [], "entities": []}, {"text": "The feature values shown in brackets refer to the example in.", "labels": [], "entities": []}, {"text": "\u2022 M1 is the baseline model.", "labels": [], "entities": []}, {"text": "It uses PoS-tag pairs as features, such as (t 1 =VC, t 2 =Na).", "labels": [], "entities": []}, {"text": "\u2022 M2 extends the M1 model by adding context features of (t -1 =VK, t 1 =VC), (t 2 =Na, t 3 =DE), (t -2 =Nep, t -1 =VK, t 1 =VC), (t 2 =Na, t 3 =DE, t 4 =Na) and (t -1 =VK, t 3 =DE).", "labels": [], "entities": [{"text": "DE", "start_pos": 92, "end_pos": 94, "type": "METRIC", "confidence": 0.9126093983650208}, {"text": "DE", "start_pos": 177, "end_pos": 179, "type": "METRIC", "confidence": 0.9033101797103882}]}, {"text": "\u2022 M3 extends the M2 model by adding lexicon features of (w 1 =\u5b78\u7fd2, t 1 =VK, w 2 =\u4e2d \u6587, t 2 =Na), (w 1 \uff1d\u5b78\u7fd2, w 2 =\u4e2d\u6587), (w 1 =\u5b78 \u7fd2) and (w 2 =\u4e2d\u6587).", "labels": [], "entities": []}, {"text": "\u2022 M4 extends the M3 model by adding semantic features of (st 1 =study|\u5b78\u7fd2, t 1 =VK , st 2 =language|\u8a9e\u8a00, t 2 =Na), (st 1 =study|\u5b78 \u7fd2 , t 1 =VK) and (st 2 =language| \u8a9e \u8a00 , t 2 =Na).", "labels": [], "entities": []}, {"text": "\u2022 M5 extends the M4 model by adding two features: the morph-structure of verbs; and the syllabic length of nouns (Vmorph='VV') and (Nlen=2).", "labels": [], "entities": []}, {"text": "shows the results of using different feature combinations in the models.", "labels": [], "entities": []}, {"text": "The symbol P1(%) is the 10-fold cross validation accuracy of the training data, and the symbol P2(%) is the accuracy of the test data.", "labels": [], "entities": [{"text": "P1", "start_pos": 11, "end_pos": 13, "type": "METRIC", "confidence": 0.8626442551612854}, {"text": "accuracy", "start_pos": 49, "end_pos": 57, "type": "METRIC", "confidence": 0.517042338848114}, {"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.9993963241577148}]}, {"text": "By adding contextual features, the accuracy rate of M2 increases from 59.10% to 72.30%.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 35, "end_pos": 48, "type": "METRIC", "confidence": 0.9687277674674988}, {"text": "M2", "start_pos": 52, "end_pos": 54, "type": "TASK", "confidence": 0.9005174040794373}]}, {"text": "The result shows that contextual information is the most important feature used to disambiguate VP, NP and independent structures.", "labels": [], "entities": []}, {"text": "The accuracy of M2 is approximately the same as the result of our PCFG parser because both systems use contextual information.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997075200080872}]}, {"text": "By adding lexical features (M3), the accuracy rate increases from 72.30% to 80.20%.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 37, "end_pos": 50, "type": "METRIC", "confidence": 0.9729377925395966}]}, {"text": "For semantic type features (M4), the accuracy rate increases from 80.20% to 81.90%.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 37, "end_pos": 50, "type": "METRIC", "confidence": 0.9841813147068024}]}, {"text": "The 1.7% increase in the accuracy rate indicates that semantic generalization is useful.", "labels": [], "entities": [{"text": "accuracy rate", "start_pos": 25, "end_pos": 38, "type": "METRIC", "confidence": 0.9904030561447144}, {"text": "semantic generalization", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.9058555066585541}]}, {"text": "Finally, in M5, the accuracy rate increases from 81.90% to 83.00%.", "labels": [], "entities": [{"text": "M5", "start_pos": 12, "end_pos": 14, "type": "DATASET", "confidence": 0.6743912100791931}, {"text": "accuracy rate", "start_pos": 20, "end_pos": 33, "type": "METRIC", "confidence": 0.9530932307243347}]}, {"text": "The improvement demonstrates the benefits of using the verb morph-structure and noun length features.", "labels": [], "entities": []}, {"text": "Models Feature for Vt-N P1(%) P2(%) M1 (.", "labels": [], "entities": []}, {"text": "The results of using different feature combinations Next, we consider the influence of unknown words on the Vt-N classifier.", "labels": [], "entities": []}, {"text": "The statistics shows that 17% of the words in Treebank lack semantic type information, e.g., \u7559\u5728/StayIn, \u586b\u98fd/fill, \u8cbc \u51fa/posted, and \u7d81\u597d/tied.", "labels": [], "entities": []}, {"text": "The accuracy of the Vt-N classifier declines by 0.7% without semantic type information for unknown words.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995075464248657}]}, {"text": "In other words, lexical semantic information improves the accuracy of the Vt-N classifier.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9991551637649536}]}, {"text": "Regarding the problem of unknown morph-structure of words, we observe that over 85% of verbs with more than 2 characters are not found in the affix database.", "labels": [], "entities": []}, {"text": "If we exclude unknown words, the accuracy of the Vt-N prediction decreases by 1%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.999762237071991}]}, {"text": "Therefore, morph-structure information has a positive effect on the classifier.", "labels": [], "entities": []}, {"text": "In this experiment, we evaluated the two methods discussed in Section 3, i.e., unsupervised NP selection and supervised error correction.", "labels": [], "entities": [{"text": "NP selection", "start_pos": 92, "end_pos": 104, "type": "TASK", "confidence": 0.8350132703781128}]}, {"text": "We applied the data selection method (i.e., distance=1, with an intransitive verb (Vi) followed by an object noun (Na)) to select 46,258 instances from the ASBC corpus and compile a dataset called Treebank+ASBC-Vi-N. shows the performance of model 5 (M5) on the training data derived from Treebank and Treebank+ASBC-Vi-N. The results demonstrate that learning more nouns that accept verbal modifiers improves the accuracy.", "labels": [], "entities": [{"text": "ASBC corpus", "start_pos": 156, "end_pos": 167, "type": "DATASET", "confidence": 0.9039497673511505}, {"text": "accuracy", "start_pos": 413, "end_pos": 421, "type": "METRIC", "confidence": 0.9984967708587646}]}, {"text": "We had also try to use the auto-parsed results of the Vt-N structures from the ASBC corpus as supplementary training data for train M5.", "labels": [], "entities": [{"text": "ASBC corpus", "start_pos": 79, "end_pos": 90, "type": "DATASET", "confidence": 0.9338941872119904}]}, {"text": "It degrades the model's performance by too much error when using the supplementary training data.", "labels": [], "entities": []}, {"text": "To resolve the problem, we utilize the supervised error correction method, which manually correct errors rapidly because high frequency instances (w 1 , w 2 ) rarely have ambiguous classifications in different contexts.", "labels": [], "entities": [{"text": "supervised error correction", "start_pos": 39, "end_pos": 66, "type": "TASK", "confidence": 0.6055762668450674}]}, {"text": "So we designed an editing tool to correct errors made by the parser in the classification of high frequency Vt-N word pairs.", "labels": [], "entities": [{"text": "classification of high frequency Vt-N word pairs", "start_pos": 75, "end_pos": 123, "type": "TASK", "confidence": 0.727951100894383}]}, {"text": "After the manual correction operation, which takes 40 man-hours, we assign the correct classifications (w 1 , t 1 , w 2 , t 2 , rt) for 2,674 Vt-N structure types which contains 10,263 instances to creates the ASBC+Correction dataset.", "labels": [], "entities": [{"text": "ASBC+Correction dataset", "start_pos": 210, "end_pos": 233, "type": "DATASET", "confidence": 0.8763147741556168}]}, {"text": "Adding the corrected data to the original training data increases the precision rate to 88.40% and reduces the number of errors by approximately 31.76%, as shown in the Treebank+ASBC+Correction column of Table 7.", "labels": [], "entities": [{"text": "precision rate", "start_pos": 70, "end_pos": 84, "type": "METRIC", "confidence": 0.9837223887443542}, {"text": "number of errors", "start_pos": 111, "end_pos": 127, "type": "METRIC", "confidence": 0.8864694237709045}, {"text": "Treebank+ASBC+Correction column", "start_pos": 169, "end_pos": 200, "type": "DATASET", "confidence": 0.8310954570770264}]}, {"text": "We also used the precision and recall rates to evaluate the performance of the models on each type of relation.", "labels": [], "entities": [{"text": "precision", "start_pos": 17, "end_pos": 26, "type": "METRIC", "confidence": 0.9996945858001709}, {"text": "recall", "start_pos": 31, "end_pos": 37, "type": "METRIC", "confidence": 0.998992383480072}]}, {"text": "The results are shown in.", "labels": [], "entities": []}, {"text": "Overall, the Treebank+ASBC+Correction method achieves the best performance in terms of the precision rate.", "labels": [], "entities": [{"text": "precision rate", "start_pos": 91, "end_pos": 105, "type": "METRIC", "confidence": 0.9792301058769226}]}, {"text": "The results for Treebank+ASBC-Vi-N show that the unsupervised data selection method can find some knowledge to help identify NP structures.", "labels": [], "entities": [{"text": "Treebank+ASBC-Vi-N", "start_pos": 16, "end_pos": 34, "type": "DATASET", "confidence": 0.6695923407872518}]}, {"text": "In addition, the proposed models achieve better precision rates than the PCFG parser.", "labels": [], "entities": [{"text": "precision rates", "start_pos": 48, "end_pos": 63, "type": "METRIC", "confidence": 0.976959764957428}]}, {"text": "The results demonstrate that using our guidelines to design a disambiguation model to resolve the Vt-N problem is successful..", "labels": [], "entities": []}, {"text": "Performance comparison of different classification models.", "labels": [], "entities": []}, {"text": "Identifying Vt-N structures correctly facilitates statistical parsing, machine translation, infor-mation retrieval, and text classification.", "labels": [], "entities": [{"text": "statistical parsing", "start_pos": 50, "end_pos": 69, "type": "TASK", "confidence": 0.8482420742511749}, {"text": "machine translation", "start_pos": 71, "end_pos": 90, "type": "TASK", "confidence": 0.7989912927150726}, {"text": "infor-mation retrieval", "start_pos": 92, "end_pos": 114, "type": "TASK", "confidence": 0.7193753123283386}, {"text": "text classification", "start_pos": 120, "end_pos": 139, "type": "TASK", "confidence": 0.8167734444141388}]}, {"text": "In this experiment, we develop a baseline PCFG parser based on feature-based grammar representation by  to find the best tree structures (T) of a given sentence (S).", "labels": [], "entities": []}, {"text": "The parser then selects the best tree according to the evaluation score Score(T,S) of all possible trees.", "labels": [], "entities": [{"text": "evaluation score Score(T,S)", "start_pos": 55, "end_pos": 82, "type": "METRIC", "confidence": 0.8643595079580942}]}, {"text": "If there are n PCFG rules in the tree T, the Score(T,S) is the accumulation of the logarithmic probabilities of the i-th grammar rule (RPi).", "labels": [], "entities": [{"text": "Score(T,S)", "start_pos": 45, "end_pos": 55, "type": "METRIC", "confidence": 0.8866200894117355}]}, {"text": "Formula 1 shows the baseline PCFG parser.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 29, "end_pos": 33, "type": "DATASET", "confidence": 0.868979811668396}]}, {"text": "The Vt-N models can be easily integrated into the PCFG parser.", "labels": [], "entities": [{"text": "PCFG", "start_pos": 50, "end_pos": 54, "type": "DATASET", "confidence": 0.926454484462738}]}, {"text": "Formula 2 represents the integrated structural evaluation model.", "labels": [], "entities": []}, {"text": "We combine RPi and VtNPi with the weights w 1 and w 2 respectively, and set the value of w 2 higher than that of w 1 . VtNPi is the probability produced by the Vt-N classifier for the type of the relation between Vt-N bigram determined by the PCFG parsing.", "labels": [], "entities": [{"text": "PCFG parsing", "start_pos": 243, "end_pos": 255, "type": "TASK", "confidence": 0.6751808673143387}]}, {"text": "The classifier is triggered when a structure is encountered; otherwise, the Vt-N model is not processed.", "labels": [], "entities": []}, {"text": "The results of evaluating the parsing model incorporated with the Vt-N classifier (see Formula 2) are shown in and.", "labels": [], "entities": [{"text": "parsing", "start_pos": 30, "end_pos": 37, "type": "TASK", "confidence": 0.9683319330215454}]}, {"text": "The performance of the PCFG parser with and without model M5 from Treebank+ASBC+Correction data set.", "labels": [], "entities": [{"text": "PCFG parser", "start_pos": 23, "end_pos": 34, "type": "TASK", "confidence": 0.6238545328378677}, {"text": "Treebank+ASBC+Correction data set", "start_pos": 66, "end_pos": 99, "type": "DATASET", "confidence": 0.8607869574001857}]}, {"text": "In  The evaluation results on the testing data, i.e. in P2 metric, are as follows.", "labels": [], "entities": []}, {"text": "The accuracy of PCFG parser is 77.09%; CDM parser reaches 78.45% of accuracy; and Berkeley parser is 70.68%.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9995843768119812}, {"text": "PCFG parser", "start_pos": 16, "end_pos": 27, "type": "TASK", "confidence": 0.611765131354332}, {"text": "accuracy", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9993163347244263}]}, {"text": "The results show that the problem of Vt-N cannot be well solved by any general parser including CDM parser and Berkeley's parser.", "labels": [], "entities": []}, {"text": "It is necessary to have a different approach aside from the general model.", "labels": [], "entities": []}, {"text": "So we set the target fora better model for Vt-N classification which can be easily integrated into the existing parsing model.", "labels": [], "entities": [{"text": "Vt-N classification", "start_pos": 43, "end_pos": 62, "type": "TASK", "confidence": 0.7782700955867767}]}, {"text": "So far our best model achieved the P2 accuracy of 87.88%.", "labels": [], "entities": [{"text": "P2", "start_pos": 35, "end_pos": 37, "type": "METRIC", "confidence": 0.8407911658287048}, {"text": "accuracy", "start_pos": 38, "end_pos": 46, "type": "METRIC", "confidence": 0.8966877460479736}]}], "tableCaptions": [{"text": " Table 5. The results of using different feature  combinations", "labels": [], "entities": []}, {"text": " Table 6. Experiment results on the test data for  various knowledge sources", "labels": [], "entities": []}, {"text": " Table 7. Experiment results of classifiers with  different training data", "labels": [], "entities": []}, {"text": " Table 8.  Overall, the Treebank+ASBC+Correction meth- od achieves the best performance in terms of the  precision rate. The results for Treebank+ASBC- Vi-N show that the unsupervised data selection  method can find some knowledge to help identi- fy NP structures. In addition, the proposed mod- els achieve better precision rates than the PCFG  parser. The results demonstrate that using our  guidelines to design a disambiguation model to  resolve the Vt-N problem is successful.", "labels": [], "entities": [{"text": "precision", "start_pos": 105, "end_pos": 114, "type": "METRIC", "confidence": 0.9989294409751892}, {"text": "precision", "start_pos": 315, "end_pos": 324, "type": "METRIC", "confidence": 0.9899848699569702}]}, {"text": " Table 8. Performance comparison of different  classification models.", "labels": [], "entities": []}, {"text": " Table 10. The P2 is  the accuracy of Vt-N classification on the test  data. The bracketed f-score (BF 2 ) is the parsing  performance metric. Based on these results, the  integrated model outperforms the PCFG parser in  terms of Vt-N classification. Because the Vt-N  classifier only considers sentences that contain  Vt-N structures, it does not affect the parsing  accuracies of other sentences.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9995261430740356}, {"text": "Vt-N classification", "start_pos": 38, "end_pos": 57, "type": "TASK", "confidence": 0.7259481847286224}, {"text": "bracketed f-score (BF 2 )", "start_pos": 81, "end_pos": 106, "type": "METRIC", "confidence": 0.7323821385701498}]}, {"text": " Table 9. The performance of the PCFG parser  with and without model M5 from Treebank.", "labels": [], "entities": [{"text": "PCFG parser", "start_pos": 33, "end_pos": 44, "type": "TASK", "confidence": 0.6173824220895767}, {"text": "Treebank", "start_pos": 77, "end_pos": 85, "type": "DATASET", "confidence": 0.6238889694213867}]}, {"text": " Table 10. The performance of the PCFG parser  with and without model M5 from Tree- bank+ASBC+Correction data set.", "labels": [], "entities": [{"text": "PCFG parser", "start_pos": 34, "end_pos": 45, "type": "TASK", "confidence": 0.6463747024536133}, {"text": "ASBC+Correction data set", "start_pos": 89, "end_pos": 113, "type": "DATASET", "confidence": 0.752481198310852}]}]}