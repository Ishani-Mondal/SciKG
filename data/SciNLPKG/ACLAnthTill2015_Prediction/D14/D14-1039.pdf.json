{"title": [{"text": "Hierarchical Discriminative Classification for Text-Based Geolocation", "labels": [], "entities": [{"text": "Hierarchical Discriminative Classification", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.738753060499827}]}], "abstractContent": [{"text": "Text-based document geolocation is commonly rooted in language-based information retrieval techniques over geodesic grids.", "labels": [], "entities": [{"text": "Text-based document geolocation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.5695557494958242}, {"text": "information retrieval", "start_pos": 69, "end_pos": 90, "type": "TASK", "confidence": 0.7198694199323654}]}, {"text": "These methods ignore the natural hierarchy of cells in such grids and fall afoul of independence assumptions.", "labels": [], "entities": []}, {"text": "We demonstrate the effectiveness of using logistic regression models on a hierarchy of nodes in the grid, which improves upon the state of the art accuracy by several percent and reduces mean error distances by hundreds of kilometers on data from Twitter, Wikipedia, and Flickr.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.9991843104362488}, {"text": "mean error distances", "start_pos": 187, "end_pos": 207, "type": "METRIC", "confidence": 0.8475295106569926}]}, {"text": "We also show that logistic regression performs feature selection effectively, assigning high weights to geocentric terms.", "labels": [], "entities": [{"text": "feature selection", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.7757618129253387}]}], "introductionContent": [{"text": "Document geolocation is the identification of the location-a specific latitude and longitude-that forms the primary focus of a given document.", "labels": [], "entities": [{"text": "Document geolocation", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8818004429340363}]}, {"text": "This assumes that a document can be adequately associated with a single location, which is only valid for certain documents, generally of fairly small size.", "labels": [], "entities": []}, {"text": "Nonetheless, there are many natural situations in which such collections arise.", "labels": [], "entities": []}, {"text": "For example, a great number of articles in Wikipedia have been manually geotagged; this allows those articles to appear in their geographic locations in geobrowsers like Google Earth.", "labels": [], "entities": []}, {"text": "Images in social networks such as Flickr maybe geotagged by a camera and their textual tags can be treated as documents.", "labels": [], "entities": []}, {"text": "Likewise, tweets in Twitter are often geotagged; in this case, it is possible to view either an individual tweet or the collection of tweets fora given user as a document, respectively identifying the location as the place from which the tweet was sent or the home location of the user.", "labels": [], "entities": []}, {"text": "Early work on document geolocation used heuristic algorithms, predicting locations based on toponyms in the text (named locations, determined with the aid of a gazetteer) ().", "labels": [], "entities": []}, {"text": "More recently, various researchers have used topic models for document geolocation) or other types of geographic document summarization (.", "labels": [], "entities": []}, {"text": "A number of researchers have used metadata of various sorts for document or user geolocation, including document links and social network connections.", "labels": [], "entities": []}, {"text": "This research has sometimes been applied to Wikipedia or Facebook () but more commonly to Twitter, focusing variously on friends and followers), time zone), declared location), or a combination of these (.", "labels": [], "entities": []}, {"text": "We tackle document geolocation using supervised methods based on the textual content of documents, ignoring their metadata.", "labels": [], "entities": [{"text": "document geolocation", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.6894001066684723}]}, {"text": "Metadatabased approaches can achieve great accuracy (e.g. obtain 79% accuracy within 100 miles fora US-based Twitter corpus, compared with 49% using our methods on a comparable corpus), but are very specific to the particular corpus and the types of metadata it makes available.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9979161620140076}, {"text": "accuracy", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.9981607794761658}]}, {"text": "For Twitter, the metadata includes the user's declared location and timezone, information which greatly simplifies geolocation and which is unavailable for other types of corpora, such as Wikipedia.", "labels": [], "entities": []}, {"text": "In many cases essentially no metadata is available at all, as in historical corpora in the digital humanities (), such as those in the Perseus project.", "labels": [], "entities": []}, {"text": "Text-based approaches can be applied to all types of corpora; metadata can be additionally incorporated when available.", "labels": [], "entities": []}, {"text": "We introduce a hierarchical discriminative classification method for text-based geotagging.", "labels": [], "entities": [{"text": "hierarchical discriminative classification", "start_pos": 15, "end_pos": 57, "type": "TASK", "confidence": 0.7001331448554993}]}, {"text": "We apply this to corpora in three languages.", "labels": [], "entities": []}, {"text": "This method scales well to large training sets and greatly improves results across a wide variety of corpora, beating current state-of-the-art results by wide margins, including Twitter users (; Wikipedia articles (Roller12; Wing and Baldridge, 2011, henceforth WB11); and Flickr images.", "labels": [], "entities": [{"text": "Roller12; Wing and Baldridge, 2011, henceforth WB11", "start_pos": 215, "end_pos": 266, "type": "DATASET", "confidence": 0.854939991235733}]}, {"text": "Importantly, this is the first method that improves upon straight uniform-grid Naive Bayes on all of these corpora, in contrast with k-d trees (Roller12) and the current state-of-the-art technique for Twitter users of geographically-salient feature selection (Han14).", "labels": [], "entities": [{"text": "Han14", "start_pos": 260, "end_pos": 265, "type": "DATASET", "confidence": 0.9158703088760376}]}, {"text": "We also show, contrary to Han14, that logistic regression when properly optimized is more accurate than state-of-the-art techniques, including feature selection, and fast enough to run on large corpora.", "labels": [], "entities": [{"text": "Han14", "start_pos": 26, "end_pos": 31, "type": "DATASET", "confidence": 0.9461444020271301}, {"text": "feature selection", "start_pos": 143, "end_pos": 160, "type": "TASK", "confidence": 0.6550115495920181}]}, {"text": "Logistic regression itself very effectively picks out words with high geographic significance.", "labels": [], "entities": [{"text": "Logistic regression", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8472376763820648}]}, {"text": "In addition, because logistic regression does not assume feature independence, complex and overlapping features of various sorts can be employed.", "labels": [], "entities": []}], "datasetContent": [{"text": "We experiment with several methods for configuring the grid and selecting the best cell.", "labels": [], "entities": []}, {"text": "For grids, we use either a uniform or k-d tree grid.", "labels": [], "entities": []}, {"text": "For uniform grids, the main tunable parameter is grid size (in degrees), while for k-d trees it is bucket size (BK), i.e. the number of documents above which anode is divided in two.", "labels": [], "entities": [{"text": "bucket size (BK)", "start_pos": 99, "end_pos": 115, "type": "METRIC", "confidence": 0.7759054362773895}]}, {"text": "For cell choice, the options are: \u2022 NB: Naive Bayes baseline \u2022 IGR: Naive Bayes using features selected by information gain ratio \u2022 FlatLR: logistic regression model overall leaf nodes \u2022 HierLR: product of logistic regression models at each node in a hierarchical grid (eq.", "labels": [], "entities": [{"text": "IGR", "start_pos": 63, "end_pos": 66, "type": "METRIC", "confidence": 0.920944094657898}]}, {"text": "3) For Dirichlet smoothing in conjunction with Naive Bayes, we set the Dirichlet parameter m = 1, 000, 000, which we found worked well in preliminary experiments.", "labels": [], "entities": [{"text": "Dirichlet smoothing", "start_pos": 7, "end_pos": 26, "type": "TASK", "confidence": 0.7522347569465637}]}, {"text": "For hierarchical classification, there are additional parameters: subdivision factor (SF) and beam size (BM) ( \u00a74), and hierarchy depth (D) ( \u00a76.4).", "labels": [], "entities": [{"text": "hierarchical classification", "start_pos": 4, "end_pos": 31, "type": "TASK", "confidence": 0.7937088310718536}, {"text": "subdivision factor (SF)", "start_pos": 66, "end_pos": 89, "type": "METRIC", "confidence": 0.9534347176551818}, {"text": "beam size (BM)", "start_pos": 94, "end_pos": 108, "type": "METRIC", "confidence": 0.8877987027168274}, {"text": "hierarchy depth (D)", "start_pos": 120, "end_pos": 139, "type": "METRIC", "confidence": 0.7845071256160736}]}, {"text": "All of our test-set results use a depth of three levels.", "labels": [], "entities": []}, {"text": "Due to its speed and flexibility, we use Vowpal Wabbit () for logistic regression, estimating parameters with limited-memory BFGS.", "labels": [], "entities": []}, {"text": "Unless otherwise mentioned, we use 26-bit feature hashing () and 40 passes over the data (optimized based on early experiments on development data) and turnoff the hold-out mechanism.", "labels": [], "entities": []}, {"text": "For the subcell classifiers in hierarchical classification, which have fewer classes and much less data, we use 24-bit features and 12 passes.", "labels": [], "entities": [{"text": "hierarchical classification", "start_pos": 31, "end_pos": 58, "type": "TASK", "confidence": 0.722819060087204}]}, {"text": "To measure geolocation performance, we use three standard metrics based on error distance, i.e. the distance between the correct location and the predicted location.", "labels": [], "entities": [{"text": "error distance", "start_pos": 75, "end_pos": 89, "type": "METRIC", "confidence": 0.942122220993042}]}, {"text": "These metrics are mean and median error distance () and accuracy at 161 km (acc@161), i.e. within a 161-km radius, which was introduced by as a proxy for accuracy within a metro area.", "labels": [], "entities": [{"text": "mean and median error distance", "start_pos": 18, "end_pos": 48, "type": "METRIC", "confidence": 0.8592485547065735}, {"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9996554851531982}, {"text": "acc", "start_pos": 76, "end_pos": 79, "type": "METRIC", "confidence": 0.9732342958450317}, {"text": "accuracy", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.9984286427497864}]}, {"text": "All of these metrics are independent of cell size, unlike the measure of cell accuracy (fraction of cells correctly predicted) used in.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 78, "end_pos": 86, "type": "METRIC", "confidence": 0.9100028276443481}]}, {"text": "Following Han14, we use acc@161 on development sets when choosing algorithmic parameter values such as cell and bucket sizes.", "labels": [], "entities": [{"text": "Han14", "start_pos": 10, "end_pos": 15, "type": "DATASET", "confidence": 0.9546354413032532}, {"text": "acc", "start_pos": 24, "end_pos": 27, "type": "METRIC", "confidence": 0.9464069604873657}]}], "tableCaptions": [{"text": " Table 1: Dev set performance for TWUS, with  uniform grids. HierLR and IGR parameters op- timized using acc@161. Best metric numbers for  a given method are underlined, except that overall  best numbers are in bold.", "labels": [], "entities": [{"text": "TWUS", "start_pos": 34, "end_pos": 38, "type": "DATASET", "confidence": 0.7478019595146179}, {"text": "IGR", "start_pos": 72, "end_pos": 75, "type": "METRIC", "confidence": 0.8530915379524231}]}, {"text": " Table 2: Performance on the test sets of TWUS and TWWORLD for different methods and metrics.", "labels": [], "entities": [{"text": "TWUS", "start_pos": 42, "end_pos": 46, "type": "DATASET", "confidence": 0.9392296075820923}, {"text": "TWWORLD", "start_pos": 51, "end_pos": 58, "type": "DATASET", "confidence": 0.9316859841346741}]}, {"text": " Table 3: Performance on the test sets of ENWIKI13 and COPHIR for different methods and metrics.", "labels": [], "entities": [{"text": "ENWIKI13", "start_pos": 42, "end_pos": 50, "type": "DATASET", "confidence": 0.9479092359542847}, {"text": "COPHIR", "start_pos": 55, "end_pos": 61, "type": "DATASET", "confidence": 0.6184880137443542}]}, {"text": " Table 5: Performance on the test sets of DEWIKI14 and PTWIKI14 for different methods and metrics.", "labels": [], "entities": [{"text": "DEWIKI14", "start_pos": 42, "end_pos": 50, "type": "DATASET", "confidence": 0.9155808091163635}, {"text": "PTWIKI14", "start_pos": 55, "end_pos": 63, "type": "DATASET", "confidence": 0.8483309149742126}]}]}