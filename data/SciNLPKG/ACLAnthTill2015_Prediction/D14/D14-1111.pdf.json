{"title": [{"text": "Reducing Dimensions of Tensors in Type-Driven Distributional Semantics", "labels": [], "entities": [{"text": "Reducing Dimensions of Tensors", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.733706921339035}]}], "abstractContent": [{"text": "Compositional distributional semantics is a subfield of Computational Linguistics which investigates methods for representing the meanings of phrases and sentences.", "labels": [], "entities": []}, {"text": "In this paper, we explore implementations of a framework based on Combinatory Categorial Grammar (CCG), in which words with certain grammatical types have meanings represented by multi-linear maps (i.e. multi-dimensional arrays, or tensors).", "labels": [], "entities": [{"text": "Combinatory Categorial Grammar (CCG)", "start_pos": 66, "end_pos": 102, "type": "TASK", "confidence": 0.731447825829188}]}, {"text": "An obstacle to full implementation of the framework is the size of these tensors.", "labels": [], "entities": []}, {"text": "We examine the performance of lower dimensional approximations of transitive verb tensors on a sentence plausi-bility/selectional preference task.", "labels": [], "entities": []}, {"text": "We find that the matrices perform as well as, and sometimes even better than, full tensors, allowing a reduction in the number of parameters needed to model the framework.", "labels": [], "entities": []}], "introductionContent": [{"text": "An emerging subfield of computational linguistics is concerned with learning compositional distributional representations of meaning (.", "labels": [], "entities": [{"text": "learning compositional distributional representations of meaning", "start_pos": 68, "end_pos": 132, "type": "TASK", "confidence": 0.8024100959300995}]}, {"text": "The advantage of such representations lies in their potential to combine the benefits of distributional approachs to word meaning) with the more traditional compositional methods from formal semantics (.", "labels": [], "entities": []}, {"text": "Distributional representations have the properties of robustness, learnability from data, ease of handling ambiguity, and the ability to represent gradations of meaning; whereas compositional models handle the unbounded nature of natural language, as well as providing established accounts of logical words, quantification, and inference.", "labels": [], "entities": []}, {"text": "One promising approach which attempts to combine elements of compositional and distributional semantics is by.", "labels": [], "entities": []}, {"text": "The underlying idea is to take the type-driven approach from formal semantics -in particular the idea that the meanings of complex grammatical types should be represented as functions -and apply it to distributional representations.", "labels": [], "entities": []}, {"text": "Since the mathematics of distributional semantics is provided by linear algebra, a natural set of functions to consider is the set of linear maps.", "labels": [], "entities": [{"text": "distributional semantics", "start_pos": 25, "end_pos": 49, "type": "TASK", "confidence": 0.7263593673706055}]}, {"text": "recognize that there is a natural correspondence from complex grammatical types to tensors (multi-linear maps), so that the meaning of an adjective, for example, is represented by a matrix (a 2nd-order tensor) and the meaning of a transitive verb is represented by a 3rd-order tensor.", "labels": [], "entities": []}, {"text": "Coecke et al. use the grammar of pregroups as the syntactic machinery to construct distributional meaning representations, since both pregroups and vector spaces can be seen as examples of the same abstract structure, which leads to a particularly clean mathematical description of the compositional process.", "labels": [], "entities": []}, {"text": "However, the approach applies more generally, for example to other forms of categorial grammar, such as Combinatory Categorial Grammar, and also to phrase-structure grammars in away that a formal linguist would recognize ().", "labels": [], "entities": [{"text": "Combinatory Categorial Grammar", "start_pos": 104, "end_pos": 134, "type": "TASK", "confidence": 0.623535563548406}]}, {"text": "Clark (2013) provides a description of the tensor-based framework aimed more at computational linguists, relying only on the mathematics of multi-linear algebra rather than the category theory used in.", "labels": [], "entities": []}, {"text": "Section 2 repeats some of this description.", "labels": [], "entities": []}, {"text": "A major open question associated with the tensor-based semantic framework is how to learn the tensors representing the meanings of words with complex types, such as verbs and adjectives.", "labels": [], "entities": []}, {"text": "The framework is essentially a compositional framework, providing a recipe for how to combine distributional representations, but leaving open what the underlying vector spaces are and how they can be acquired.", "labels": [], "entities": []}, {"text": "One significant challenge is an engineering one: in a wide-coverage grammar, which is able to handle naturally occurring text, there will be a) a large lexicon with many word-category pairs requiring tensor representations; and b) many higher-order tensors with large numbers of parameters which need to be learned.", "labels": [], "entities": []}, {"text": "In this paper we take a first step towards learning such representations, by learning tensors for transitive verbs.", "labels": [], "entities": []}, {"text": "One feature of the tensor-based framework is that it allows the meanings of words and phrases with different basic types, for example nouns and sentences, to live in different vector spaces.", "labels": [], "entities": []}, {"text": "This means that the sentence space is task specific, and must be defined in advance.", "labels": [], "entities": []}, {"text": "For example, to calculate sentence similarity, we would have to learn a vector space where distances between vectors representing the meanings of sentences reflect similarity scores assigned by human annotators.", "labels": [], "entities": []}, {"text": "In this paper we describe an initial investigation into the learning of word meanings with complex syntactic types, together with a simple sentence space.", "labels": [], "entities": [{"text": "learning of word meanings", "start_pos": 60, "end_pos": 85, "type": "TASK", "confidence": 0.747953325510025}]}, {"text": "The space we consider is the \"plausibility space\" described by, together with sentences of the form subject-verbobject.", "labels": [], "entities": []}, {"text": "This space is defined to distinguish semantically plausible sentences (e.g. Animals eat plants) from implausible ones (e.g. Animals eat planets).", "labels": [], "entities": []}, {"text": "Plausibility can be either represented as a single continuous variable between 0 and 1, or as a two-dimensional probability distribution over the classes plausible () and implausible (\u22a5).", "labels": [], "entities": []}, {"text": "Whether we consider a one-or two-dimensional sentence space depends on the architecture of the logistic regression classifier that is used to learn the verb (Section 3).", "labels": [], "entities": []}, {"text": "We begin with this simple plausibility sentence space to determine if, in fact, the tensor-based representation can be learned to a sufficiently useful degree.", "labels": [], "entities": []}, {"text": "Other simple sentence spaces which can perhaps be represented using one or two variables include a \"sentence space\" for the sentiment analysis task, where one variable represents positive sentiment and the other negative.", "labels": [], "entities": [{"text": "sentiment analysis task", "start_pos": 124, "end_pos": 147, "type": "TASK", "confidence": 0.937482496102651}]}, {"text": "We also expect that the insights gained from research on this task can be applied to more complex sentence spaces, for example a semantic similarity space which will require more than two variables.", "labels": [], "entities": []}], "datasetContent": [{"text": "In order to examine the quality of learning we run several experiments where we compare the different methods.", "labels": [], "entities": []}, {"text": "In these experiments we consider the DMat method as the baseline.", "labels": [], "entities": []}, {"text": "Some of the experiments employ cross-validation, in particular five repetitions of 2-fold cross validation (5x2cv), which has been shown to be statistically more robust than the traditional 10-fold cross validation).", "labels": [], "entities": []}, {"text": "The results of 5x2cv experiments can be compared using the regular paired t-test, but the specially designed 5x2cv F-test has been proven to produce fewer statistical errors).", "labels": [], "entities": []}, {"text": "The performance was evaluated using the area under the ROC (AUC) and the F 1 measure (based on precision and recall over the plausible class).", "labels": [], "entities": [{"text": "ROC (AUC)", "start_pos": 55, "end_pos": 64, "type": "METRIC", "confidence": 0.9113673716783524}, {"text": "F 1 measure", "start_pos": 73, "end_pos": 84, "type": "METRIC", "confidence": 0.982308566570282}, {"text": "precision", "start_pos": 95, "end_pos": 104, "type": "METRIC", "confidence": 0.9988390803337097}, {"text": "recall", "start_pos": 109, "end_pos": 115, "type": "METRIC", "confidence": 0.9973805546760559}]}, {"text": "The AUC evaluates whether a method is ranking positive examples above negative ones, regardless of the class cutoff value.", "labels": [], "entities": []}, {"text": "F 1 shows how accurately a method assigns the correct class label.", "labels": [], "entities": [{"text": "F 1", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9421457946300507}]}, {"text": "Another way to interpret the results is to consider the AUC as the measure of the quality of the parameters in the verb matrix or tensor, while the F-score indicates how well the softmax, the sigmoid, and the DMat cutoff algorithm are estimating class participation.", "labels": [], "entities": [{"text": "AUC", "start_pos": 56, "end_pos": 59, "type": "METRIC", "confidence": 0.96637362241745}, {"text": "F-score", "start_pos": 148, "end_pos": 155, "type": "METRIC", "confidence": 0.993359386920929}]}, {"text": "In the first experiment, we compare the different transitive verb representations by running 5x2cv experiments on ten verbs chosen to cover a range of concreteness and frequency values (Section 4.2).", "labels": [], "entities": []}, {"text": "In the initial experiments we found that some models had low performance, so we applied the column normalisation technique, which is often used with regression learning to standardise the numerical range of features: This preserves the relative values of features between training samples, while moving the values to the [0,1] range.", "labels": [], "entities": []}, {"text": "There are varying numbers of training examples for each of the verbs, so we repeated the 5x2cv with datasets of 52 training points for each verb, since this is the size of the smallest dataset of the verb CENSOR.", "labels": [], "entities": [{"text": "CENSOR", "start_pos": 205, "end_pos": 211, "type": "METRIC", "confidence": 0.608088493347168}]}, {"text": "The points were randomly sampled from the datasets used in the first experiment.", "labels": [], "entities": []}, {"text": "Finally, the four verbs with the largest datasets were used to examine how the performance of the methods changes as the amount of training data increases.", "labels": [], "entities": []}, {"text": "The 4,000 training samples were randomised and half were used for testing.", "labels": [], "entities": []}, {"text": "We sampled between 10 and 1000 training triples from the other half).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: The 10 chosen verbs together with their  concreteness scores. The number of positive SVO  examples was capped at 2000. Frequency is the  frequency of the verb in the GSN corpus.", "labels": [], "entities": [{"text": "Frequency", "start_pos": 129, "end_pos": 138, "type": "METRIC", "confidence": 0.9931047558784485}, {"text": "GSN corpus", "start_pos": 176, "end_pos": 186, "type": "DATASET", "confidence": 0.9398201406002045}]}, {"text": " Table 3: The best AUC and F 1 results for all the verbs, where  \u2020 denotes statistical significance compared  to DMat and  \u2021 denotes significance compared to Tensor according to the 5x2cv F-test with p < 0.05.", "labels": [], "entities": [{"text": "AUC", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.984565258026123}, {"text": "F 1", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9913069009780884}]}, {"text": " Table 4: The best AUC and F 1 results for all the verbs with normalised vectors, where  \u2020 denotes statistical  significance compared to DMat and  \u2021 denotes significance compared to Tensor according to the 5x2cv  F-test with p < 0.05.", "labels": [], "entities": [{"text": "AUC", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.9810166954994202}, {"text": "F 1", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9917117059230804}]}, {"text": " Table 5: Results show average of 5x2cv AUC on  small data (26 positive + 26 negative per verb).  None of the results are significant.", "labels": [], "entities": [{"text": "AUC", "start_pos": 40, "end_pos": 43, "type": "METRIC", "confidence": 0.9600883722305298}]}]}