{"title": [{"text": "+/-EffectWordNet: Sense-level Lexicon Acquisition for Opinion Inference", "labels": [], "entities": []}], "abstractContent": [{"text": "Recently, work in NLP was initiated on a type of opinion inference that arises when opinions are expressed toward events which have positive or negative effects on entities (+/-effect events).", "labels": [], "entities": [{"text": "opinion inference", "start_pos": 49, "end_pos": 66, "type": "TASK", "confidence": 0.7692014575004578}]}, {"text": "This paper addresses methods for creating a lexicon of such events, to support such work on opinion inference.", "labels": [], "entities": [{"text": "opinion inference", "start_pos": 92, "end_pos": 109, "type": "TASK", "confidence": 0.8013968169689178}]}, {"text": "Due to significant sense ambiguity, our goal is to develop a sense-level rather than word-level lexicon.", "labels": [], "entities": []}, {"text": "To maximize the effectiveness of different types of information, we combine a graph-based method using WordNet 1 relations and a standard classifier using gloss information.", "labels": [], "entities": []}, {"text": "A hybrid between the two gives the best results.", "labels": [], "entities": []}, {"text": "Further, we provide evidence that the model is an effective way to guide manual annotation to find +/-effect senses that are not in the seed set.", "labels": [], "entities": []}], "introductionContent": [{"text": "Opinion mining (or sentiment analysis) identifies positive or negative opinions in many kinds of texts such as reviews, blogs, and news articles.", "labels": [], "entities": [{"text": "Opinion mining (or sentiment analysis) identifies positive or negative opinions in many kinds of texts such as reviews, blogs, and news articles", "start_pos": 0, "end_pos": 144, "type": "Description", "confidence": 0.7675710629958373}]}, {"text": "It has been exploited in many application areas such as review mining, election analysis, and information extraction.", "labels": [], "entities": [{"text": "review mining", "start_pos": 56, "end_pos": 69, "type": "TASK", "confidence": 0.916822761297226}, {"text": "election analysis", "start_pos": 71, "end_pos": 88, "type": "TASK", "confidence": 0.796439915895462}, {"text": "information extraction", "start_pos": 94, "end_pos": 116, "type": "TASK", "confidence": 0.8938246965408325}]}, {"text": "While most previous research focusses on explicit opinion expressions, recent work addresses a type of opinion inference that arises when opinions are expressed toward events which have positive or negative effects on entities ().", "labels": [], "entities": [{"text": "opinion inference", "start_pos": 103, "end_pos": 120, "type": "TASK", "confidence": 0.7876728177070618}]}, {"text": "We call such events +/-effect events.", "labels": [], "entities": []}, {"text": "show how sentiments toward one WordNet 3.0, http://wordnet.princeton.edu/ 2 While the term goodFor/badFor is used in previous papers), we have since decided that +/-effect is a better term.", "labels": [], "entities": []}, {"text": "entity maybe propagated to other entities via opinion inference rules.", "labels": [], "entities": []}, {"text": "They give the following example: (1) The bill would curb skyrocketing healthcare costs.", "labels": [], "entities": []}, {"text": "The writer expresses an explicit negative sentiment (by skyrocketing) toward the object (health care costs).", "labels": [], "entities": []}, {"text": "The event, curb, has a negative effect on costs, since they are reduced.", "labels": [], "entities": []}, {"text": "We can reason that the writer is positive toward the event because it has a negative effect on costs, toward which the writer is negative.", "labels": [], "entities": []}, {"text": "From there, we can reason that the writer is positive toward the bill, since it is the agent of the positive event.", "labels": [], "entities": []}, {"text": "show that such inferences maybe exploited to significantly improve explicit sentiment analysis systems.", "labels": [], "entities": [{"text": "explicit sentiment analysis", "start_pos": 67, "end_pos": 94, "type": "TASK", "confidence": 0.6752087970574697}]}, {"text": "However, to achieve its results, the system developed by  requires that all instances of +/-effect events in the corpus be manually provided as input.", "labels": [], "entities": []}, {"text": "For the system to be fully automatic, it needs to be able to recognize +/-effect events automatically.", "labels": [], "entities": []}, {"text": "This paper addresses methods for creating lexicons of such events, to support such work on opinion inference.", "labels": [], "entities": [{"text": "opinion inference", "start_pos": 91, "end_pos": 108, "type": "TASK", "confidence": 0.7966640293598175}]}, {"text": "We have discovered that there is significant sense ambiguity, meaning that words often have mixtures of senses among the classes +effect, -effect, and Null.", "labels": [], "entities": []}, {"text": "Thus, we develop a sense-level rather than word-level lexicon.", "labels": [], "entities": []}, {"text": "One of our goals is to investigate whether the +/-effect property tends to be shared among semantically-related senses, and another is to use a method that applies to all word senses, not just to the senses of words in a given word-level lexicon.", "labels": [], "entities": []}, {"text": "Thus, we build a graph-based model in which each node is a WordNet sense, and edges represent semantic WordNet relations between senses.", "labels": [], "entities": []}, {"text": "In addition, we hypothesized that glosses also contain useful information.", "labels": [], "entities": []}, {"text": "Thus, we develop a supervised gloss classifier and define a hybrid model which gives the best overall performance.", "labels": [], "entities": []}, {"text": "Finally, because all WordNet verb senses are incorporated into the model, we investigate the ability of the method to identify unlabeled senses that are likely to be +/-effect senses.", "labels": [], "entities": []}, {"text": "We find that by iteratively labeling the top-weighted unlabeled senses and rerunning the model, it maybe used as an effective method for guiding annotation efforts.", "labels": [], "entities": []}], "datasetContent": [{"text": "Seed/TrainSet in is used to train the two classifiers, and TestSet is utilized for the evaluation.", "labels": [], "entities": []}, {"text": "So, the training set for +eClassifier consists of 129 +effect instances and 463 Other instances, and the training set for -eClassifier contains 243 -effect instances and 349 Other instances.", "labels": [], "entities": []}, {"text": "As a baseline, we adopt a majority class classifier.", "labels": [], "entities": []}, {"text": "shows the results on TestSet.", "labels": [], "entities": [{"text": "TestSet", "start_pos": 21, "end_pos": 28, "type": "DATASET", "confidence": 0.9753080606460571}]}, {"text": "Performance is better for the -effect than for the +effect class, perhaps because the -effect class has more instances.", "labels": [], "entities": []}, {"text": "When sentiment features (SF) are added, all metric values increase, providing evidence that sentiment features are helpful to determine +/-effect classes.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Distribution of annotated data.", "labels": [], "entities": []}, {"text": " Table 2: Results of UniGraph, BiGraph, and Bi- Graph*.", "labels": [], "entities": [{"text": "BiGraph", "start_pos": 31, "end_pos": 38, "type": "METRIC", "confidence": 0.9704852104187012}, {"text": "Bi- Graph", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9257709980010986}]}, {"text": " Table 3: Effect of each relation", "labels": [], "entities": [{"text": "Effect", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9862514138221741}]}, {"text": " Table 4: Results of the gloss classifier.", "labels": [], "entities": []}, {"text": " Table 6: Comparison to onlySL and onlyGraph.", "labels": [], "entities": [{"text": "onlyGraph", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.7241916060447693}]}, {"text": " Table 5: Results of an iterative approach.", "labels": [], "entities": []}, {"text": " Table 7: Accuracy and frequency of the top 5% for  each iteration", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9994122982025146}, {"text": "frequency", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9922835230827332}]}]}