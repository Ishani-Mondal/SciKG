{"title": [{"text": "Sentiment Analysis on the People's Daily", "labels": [], "entities": [{"text": "Sentiment Analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9853188991546631}, {"text": "People's Daily", "start_pos": 26, "end_pos": 40, "type": "DATASET", "confidence": 0.7851424018541971}]}], "abstractContent": [{"text": "We propose a semi-supervised bootstrap-ping algorithm for analyzing China's foreign relations from the People's Daily.", "labels": [], "entities": [{"text": "People's Daily", "start_pos": 103, "end_pos": 117, "type": "DATASET", "confidence": 0.887138287226359}]}, {"text": "Our approach addresses sentiment target clustering, subjective lexicons extraction and sentiment prediction in a unified framework.", "labels": [], "entities": [{"text": "sentiment target clustering", "start_pos": 23, "end_pos": 50, "type": "TASK", "confidence": 0.7820342381795248}, {"text": "subjective lexicons extraction", "start_pos": 52, "end_pos": 82, "type": "TASK", "confidence": 0.6713899771372477}, {"text": "sentiment prediction", "start_pos": 87, "end_pos": 107, "type": "TASK", "confidence": 0.878038614988327}]}, {"text": "Different from existing algorithms in the literature, time information is considered in our algorithm through a hierarchical bayesian model to guide the bootstrapping approach.", "labels": [], "entities": []}, {"text": "We are hopeful that our approach can facilitate quantitative political analysis conducted by social scientists and politicians.", "labels": [], "entities": [{"text": "quantitative political analysis", "start_pos": 48, "end_pos": 79, "type": "TASK", "confidence": 0.679925541083018}]}], "introductionContent": [{"text": "\"We have no permanent allies, no permanent friends, but only permanent interests.\"", "labels": [], "entities": []}], "datasetContent": [{"text": "Gold-standard foreign relations are taken from Political Science research at the Institute of Modern International Relations, Tsinghua University, extracted from monthly quantitative China foreign relations reports with 7 countries (U.S., Japan, Russia/Soviet, England, France, India, and Germany) from 1950 to 2012 20 . We consider several baselines.", "labels": [], "entities": []}, {"text": "For fair comparison, we use identical processing techniques for each approach.", "labels": [], "entities": []}, {"text": "Some baselines make article-level predictions, for which we obtain time-period level relation prediction by averaging the documents.", "labels": [], "entities": [{"text": "time-period level relation prediction", "start_pos": 67, "end_pos": 104, "type": "TASK", "confidence": 0.573357991874218}]}, {"text": "We then bootstrap sentiment terms and score based on entity coreference.", "labels": [], "entities": []}, {"text": "No-time: A simplified version of our approach where each article is considered as an independent unit and no time-level information is considered.", "labels": [], "entities": []}, {"text": "m dis obtained by averaging its containing sentences and used for later bootstrapping.", "labels": [], "entities": []}, {"text": "SVR-d: Uses SVM light (Joachims, 1999) to train a linear SVR () for document-level sentiment prediction using the unigram feature.", "labels": [], "entities": [{"text": "document-level sentiment prediction", "start_pos": 68, "end_pos": 103, "type": "TASK", "confidence": 0.7215835650761923}]}, {"text": "The 100 labeled documents are used as training data.", "labels": [], "entities": []}, {"text": "SLDA: supervised-LDA ( for document-level label prediction.", "labels": [], "entities": [{"text": "document-level label prediction", "start_pos": 27, "end_pos": 58, "type": "TASK", "confidence": 0.6165904601414999}]}, {"text": "Topic number is set to 10, 20, 50, 100 respectively and we report the best result.", "labels": [], "entities": []}, {"text": "SVR-S: Sentence-level SVR to sentences with presence of entity Ci 21 . We obtain document-level prediction by averaging its containing sentences and then time-period level prediction by averaging its containing documents.", "labels": [], "entities": []}, {"text": "We report the Pearson Correlation with gold standards in table 3.", "labels": [], "entities": [{"text": "Pearson", "start_pos": 14, "end_pos": 21, "type": "METRIC", "confidence": 0.7770276665687561}, {"text": "Correlation", "start_pos": 22, "end_pos": 33, "type": "METRIC", "confidence": 0.49226656556129456}]}, {"text": "As we can observe, simple document-level regression models, i.e., SVR and SLDA do not fit this task.", "labels": [], "entities": []}, {"text": "The reason is simple: one article d can appear in different collections.", "labels": [], "entities": []}, {"text": "Recall the Vietnam example in Section 1, it appears in both G Vietnam and G the U.S. .", "labels": [], "entities": [{"text": "G Vietnam", "start_pos": 60, "end_pos": 69, "type": "DATASET", "confidence": 0.793992668390274}]}, {"text": "Sentiment prediction ford should be totally opposite in the two document collections: very positive in G Vietnam and very negative in GU SA . But document level prediction would treat them equally.", "labels": [], "entities": [{"text": "G Vietnam", "start_pos": 103, "end_pos": 112, "type": "DATASET", "confidence": 0.8235131204128265}, {"text": "GU SA", "start_pos": 134, "end_pos": 139, "type": "DATASET", "confidence": 0.8716809451580048}]}, {"text": "Our approach outperforms No-Time, illustrating the meaningfulness of exploiting time-level information in our task.", "labels": [], "entities": []}, {"text": "Our system approaches around 0.9 correlation with the gold standards.", "labels": [], "entities": [{"text": "correlation", "start_pos": 33, "end_pos": 44, "type": "METRIC", "confidence": 0.9127293825149536}]}, {"text": "The reason why No-Time is better than CB is also simple: CB includes only coreferent entities in the target list (e.g., America for the USA article collection), and therefore overlooks rich information provided by non-coreferent entities (e.g., President Nixon or Features we explore include word entities in current sentence, POS, a window of k \u2208 {1, 2} words from the target and the expression and corresponding POS, and the dependency path between target and expression. Nixon Government).", "labels": [], "entities": [{"text": "America for the USA article collection", "start_pos": 120, "end_pos": 158, "type": "DATASET", "confidence": 0.8589015901088715}, {"text": "Nixon Government", "start_pos": 474, "end_pos": 490, "type": "DATASET", "confidence": 0.9581512808799744}]}, {"text": "No-Time instead groups entities according to attitude, thereby enabling more information to be harnessed.", "labels": [], "entities": []}, {"text": "For SVR-S, as the regression model trained from limited labeled data can hardly cover unseen terms during testing, the performance is just OK.", "labels": [], "entities": []}, {"text": "SVR-S also suffers from overlooking rich sources of information since it only considers sentences with exact mention of the name entity of the corresponding country.", "labels": [], "entities": [{"text": "SVR-S", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.8349301815032959}]}], "tableCaptions": [{"text": " Table 2: Results for Expressions/Targets extrac- tion.", "labels": [], "entities": []}, {"text": " Table 3: Pearson Correlation with Gold Standard.", "labels": [], "entities": [{"text": "Pearson Correlation with Gold Standard", "start_pos": 10, "end_pos": 48, "type": "DATASET", "confidence": 0.6850004851818084}]}]}