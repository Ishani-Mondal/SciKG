{"title": [{"text": "Confidence-based Rewriting of Machine Translation Output", "labels": [], "entities": [{"text": "Confidence-based Rewriting of Machine Translation Output", "start_pos": 0, "end_pos": 56, "type": "TASK", "confidence": 0.7816340923309326}]}], "abstractContent": [{"text": "Numerous works in Statistical Machine Translation (SMT) have attempted to identify better translation hypotheses obtained by an initial decoding using an improved, but more costly scoring function.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 18, "end_pos": 55, "type": "TASK", "confidence": 0.8544240196545919}]}, {"text": "In this work, we introduce an approach that takes the hypotheses produced by a state-of-the-art, reranked phrase-based SMT system , and explores new parts of the search space by applying rewriting rules selected on the basis of posterior phrase-level confidence.", "labels": [], "entities": [{"text": "SMT", "start_pos": 119, "end_pos": 122, "type": "TASK", "confidence": 0.8507148027420044}]}, {"text": "In the medical domain , we obtain a 1.9 BLEU improvement over a reranked baseline exploiting the same scoring function, corresponding to a 5.4 BLEU improvement over the original Moses baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9972993731498718}, {"text": "BLEU", "start_pos": 143, "end_pos": 147, "type": "METRIC", "confidence": 0.9965651631355286}]}, {"text": "We show that if an indication of which phrases require rewriting is provided, our automatic rewriting procedure yields an additional improvement of 1.5 BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 152, "end_pos": 156, "type": "METRIC", "confidence": 0.9973793029785156}]}, {"text": "Various analyses, including a manual error analysis, further illustrate the good performance and potential for improvement of our approach in spite of its simplicity.", "labels": [], "entities": []}], "introductionContent": [{"text": "The standard configuration of modern phrasebased Statistical Machine Translation (SMT) () systems can produce very acceptable results on some tasks.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 49, "end_pos": 86, "type": "TASK", "confidence": 0.7622024516264597}]}, {"text": "However, early integration of better features to guide the search for the best hypothesis can result in significant improvements, an expression of the complexity of modeling translation quality.", "labels": [], "entities": []}, {"text": "For instance, improvements have been obtained by integrating features into decoding that better model semantic coherence at the sentence level or syntactic well-formedness ().", "labels": [], "entities": []}, {"text": "However, early use of such complex features typically comes at a high computational cost.", "labels": [], "entities": []}, {"text": "Moreover, some informative features require or are better computed when complete translation hypotheses are available.", "labels": [], "entities": []}, {"text": "This is addressed in numerous works on reranking of the highest scored sub-space of hypotheses, on so-called n-best lists () or output lattices (, where many works specifically target the inclusion of better language modelling capabilities, a well-known weakness of current automatic generation approaches.", "labels": [], "entities": []}, {"text": "Another way to improve translation a posteriori can be done by rewriting initial hypotheses, for instance in a greedy fashion by including new models (, or by specifically modeling a task of automatic post-editing targeting a specific system.", "labels": [], "entities": [{"text": "translation a posteriori", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.8610817392667135}]}, {"text": "While such automatic post-editing may seem to be too limited, notably because of the limited initial diversity considered and the fact that it maybe in some instances agnostic to the internals of the initial system, it has been shown to potentially improve accuracy of the new translation hypotheses () and to offer very high oracle performance.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 257, "end_pos": 265, "type": "METRIC", "confidence": 0.9977395534515381}]}, {"text": "However, an important issue for such approaches is their capacity to only rewrite incorrect parts of the translation hypotheses and to use appropriate replacement candidates.", "labels": [], "entities": []}, {"text": "Many works have tackled the issue of word to n-gram confidence estimation in SMT output (;, and some attempts have been made to exploit confidence estimates for lattice rescoring or n-best reranking (.", "labels": [], "entities": [{"text": "word to n-gram confidence estimation", "start_pos": 37, "end_pos": 73, "type": "TASK", "confidence": 0.5568199455738068}, {"text": "SMT output", "start_pos": 77, "end_pos": 87, "type": "TASK", "confidence": 0.8821443617343903}]}, {"text": "In this work, we present an approach in which new complete hypotheses are produced by rewriting existing hypotheses, and are scored using complex models that could not be used during the initial decoding.", "labels": [], "entities": []}, {"text": "We will use as competitive baselines systems that rerank the output of an initial decoder using the complete set of available features, and will show that we manage to improve their translation.", "labels": [], "entities": []}, {"text": "The difference between our approach and the reranking baseline lies in the manner in which we expand our training data, as well as in our use of high-confidence rewritings to obtain new translation hypotheses.", "labels": [], "entities": []}, {"text": "Importantly, this work will only exploit simple confidence estimates corresponding to phrase-based posteriors, which do not require that large sets of human-annotated data be available as in other works ().", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 is devoted to the description of our approach, with details on our rewriting approach (2.1), additional features (2.2), rewriting phrase table (2.3), and training examples (2.4).", "labels": [], "entities": []}, {"text": "We first describe our experimental setup (3.1) and our baseline systems (3.2).", "labels": [], "entities": []}, {"text": "We then report results when naive rewriting is performed and then with confidencebased rewriting (3.3).", "labels": [], "entities": []}, {"text": "We next devote a significant part of the paper in section 4 to report further results and analyses: an analysis of the performance of our system depending on the quality of initial hypotheses (4.1); a semi-oracle experiment where correct phrases are known (4.2); an oracle experiment where only correct rewriting decisions are made (4.3); a manual error analysis of the main configurations studied in this work (4.4); and, finally, a study of the performance of our approach on a more difficult translation task (4.5).", "labels": [], "entities": []}, {"text": "Related work is discussed in section 5 and we conclude and introduce our future work in section 6. 2 Description of the approach 2.1 Rewriting of translation hypotheses proposed a greedy search procedure to improve translations by reusing the same translation table and scoring function that were used during an initial phrase-based decoding.", "labels": [], "entities": []}, {"text": "In our approach, we rewrite hypotheses by using the same greedy search algorithm, adding more complex models and using the most-confident biphrases according to the initial decoder's search space.", "labels": [], "entities": []}, {"text": "To select the hypothesis to rewrite for each sentence, we produce a n-best list of the initial decoder and rerank this list with anew, better informed scoring function (see section 2.2).", "labels": [], "entities": []}, {"text": "The one-best hypothesis obtained after reranking is then rewritten by our system (denoted as rewriter).", "labels": [], "entities": []}, {"text": "In this way, we ensure that the hypothesis that was rewritten had been so far the best one according to the initial decoding best subspace and the new models used.", "labels": [], "entities": []}, {"text": "At each iteration, new hypotheses are obtained from a current hypothesis by applying one rewriting operation on bi-phrases.", "labels": [], "entities": []}, {"text": "The set of all new hypotheses is called the neighborhood of the current hypothesis.", "labels": [], "entities": []}, {"text": "Focusing in this work on local rewriting, we used the following set of operations (N denotes the number of bi-phrases, T the maximum number of entries per source phrase in a rewriting phrase table (see 2.3), and S the average number of tokens per source phrase) 1 : 1.", "labels": [], "entities": []}, {"text": "replace (O(N.T )): replaces the translation of a source phrase with another translation from the rewriting phrase table; 2.", "labels": [], "entities": []}, {"text": "split (O(N.S.T 2 )): splits a source phrase into all possible sets of two (contiguous) phrases, and uses replace on each of the resulting phrases; 3.", "labels": [], "entities": []}, {"text": "merge (O(T.N )): merges two contiguous source phrases and uses replace on the resulting new phrase.", "labels": [], "entities": []}, {"text": "This rewriting algorithm is described in pseudocode in Algorithm 1.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used two datasets from two different domains: the data provided for the WMT'14 medical translation task (Medical) and a smaller task using the TED talks 4 (TED Talks) data of the IWSLT evaluation campaigns.", "labels": [], "entities": [{"text": "WMT'14 medical translation task", "start_pos": 75, "end_pos": 106, "type": "TASK", "confidence": 0.7695852071046829}, {"text": "TED talks 4 (TED Talks) data of the IWSLT evaluation campaigns", "start_pos": 146, "end_pos": 208, "type": "DATASET", "confidence": 0.7900135746368995}]}, {"text": "For the Medical task we used only the English to French translation direction, and both translation directions, English to French and French to English, for the TED Talks task.", "labels": [], "entities": [{"text": "TED Talks task", "start_pos": 161, "end_pos": 175, "type": "TASK", "confidence": 0.8145893216133118}]}, {"text": "In this work, the main part of our experiments uses Medical, and TED Talks will be used at a later stage to study a lower-quality situation (cf. 4.5).", "labels": [], "entities": []}, {"text": "For the Medical task, initial decodings were produced using a LM trained on all WMT'14 monolingual and bilingual medical data, while for the TED Talks task we used a much larger LM trained on all the data provided for WMT'13 5 . Both are 4-gram LMs estimated with Kneser-Ney smoothing).", "labels": [], "entities": [{"text": "WMT'14 monolingual and bilingual medical data", "start_pos": 80, "end_pos": 125, "type": "DATASET", "confidence": 0.7203024923801422}, {"text": "TED Talks task", "start_pos": 141, "end_pos": 155, "type": "TASK", "confidence": 0.5330926577250162}, {"text": "WMT'13", "start_pos": 218, "end_pos": 224, "type": "DATASET", "confidence": 0.8533442616462708}]}, {"text": "For the 6-gram POS LMs used (see 2.2), we used the same data as used for the token-based LM for Medical, and the concatenation of the News Commentaries and Europarl sub-parts of the WMT'13 data for TED Talks.: Corpora used in this work.", "labels": [], "entities": [{"text": "Europarl", "start_pos": 156, "end_pos": 164, "type": "DATASET", "confidence": 0.761981189250946}, {"text": "WMT'13 data", "start_pos": 182, "end_pos": 193, "type": "DATASET", "confidence": 0.9124013781547546}]}, {"text": "We first built a state-of-the-art phrase-based SMT system using Moses () with standard settings.", "labels": [], "entities": [{"text": "SMT", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.8231867551803589}]}, {"text": "We tuned its parameters towards BLEU () on the tuning dataset using the kb-mira implementation available in Moses with default parameters.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 32, "end_pos": 36, "type": "METRIC", "confidence": 0.9989997744560242}]}, {"text": "Our results will be compared using BLEU and TER) to a) the initial best translation produced by the Moses decoder (1-pass Moses) and b) the best translation obtained by reranking the 1,000-best list of 1-pass Moses (reranker).", "labels": [], "entities": [{"text": "BLEU", "start_pos": 35, "end_pos": 39, "type": "METRIC", "confidence": 0.9988467693328857}, {"text": "TER", "start_pos": 44, "end_pos": 47, "type": "METRIC", "confidence": 0.9973975419998169}]}, {"text": "Since reranker implements a well-documented approach and uses types of features commonly used in reranking tasks we will consider it as our main baseline.", "labels": [], "entities": []}, {"text": "It was trained using kb-mira on the 1,000-best of the development data decoded by 1-pass Moses.", "labels": [], "entities": []}, {"text": "In our experiments, rewriter rewrites the one-best hypothesis 6 produced by reranker using the operators Replace, Split and Merge as described in section 2.1.", "labels": [], "entities": [{"text": "Replace", "start_pos": 105, "end_pos": 112, "type": "METRIC", "confidence": 0.9816385507583618}, {"text": "Merge", "start_pos": 124, "end_pos": 129, "type": "METRIC", "confidence": 0.9642523527145386}]}, {"text": "gives the results of the 1-pass Moses decoding for the Medical task and the reranking results of reranker applied to the 1-pass Moses 1,000-best list.", "labels": [], "entities": []}, {"text": "We observed in section 3.3 that our opti configuration, which obtains strong improvements in translation quality (as given by corpus-BLEU), in fact degrades (as given by sentence-BLEU) a significant proportion of sentences.", "labels": [], "entities": []}, {"text": "To further analyze these results, we simulate a situation where oracle confidence information is available at the phrase-level: in particular, rewriter is prevented from rewriting bi-phrases whose target phrase appears exactly in the reference transla-  tion.", "labels": [], "entities": []}, {"text": "13 Furthermore, this \"freezing\" of bi-phrases can be repeated after each iteration of rewriter.", "labels": [], "entities": []}, {"text": "Thus, we now have an oracle situation for choosing which source phrases maybe rewritten, but the rest of the rewriting procedure is still fully automatic.", "labels": [], "entities": []}, {"text": "Moreover, we purposefully did not adapt the training procedure to this new configuration, and reused opti as is.", "labels": [], "entities": []}, {"text": "Results, reported in, indicate that an additional 1.5 BLEU is obtained from opti, or 3.1 BLEU from reranker and 6.6 BLEU from 1-pass Moses.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.9986112117767334}, {"text": "BLEU", "start_pos": 89, "end_pos": 93, "type": "METRIC", "confidence": 0.9980295300483704}, {"text": "BLEU", "start_pos": 116, "end_pos": 120, "type": "METRIC", "confidence": 0.9972928166389465}]}, {"text": "The use of a larger beam of size 10 did not improve those results any further.", "labels": [], "entities": []}, {"text": "At the first iteration, rewriter \"froze\" approximatively 65.6% of the bi-phrases, and 70.5% at the last iteration, demonstrating the ability of rewriter to find good rewritings that match the reference translation.", "labels": [], "entities": []}, {"text": "Looking at, we now find that, as expected, only a limited number of sentences are now degraded by rewriter.", "labels": [], "entities": []}, {"text": "The large improvements obtained clearly underlines the important role that better confidence estimates could play in our framework.: Results for the semi-oracle using opti.", "labels": [], "entities": []}, {"text": "We now turn to the situation where only rewritings that actually improve translation performance would be made.", "labels": [], "entities": []}, {"text": "In practice, we use a simple solution: we resort to greedy oracle search (GOS), where sentence-BLEU is maximized using rewritings from the opti phrase table.", "labels": [], "entities": [{"text": "GOS", "start_pos": 74, "end_pos": 77, "type": "METRIC", "confidence": 0.8523852825164795}]}, {"text": "At each iteration the rewriting in the neighborhood that maximizes sentence-BLEU is selected until convergence.", "labels": [], "entities": []}, {"text": "Results for this greedy search oracle appear in the last column of and allow us to put in perspective the individual potential of the var-ious tested configurations.", "labels": [], "entities": []}, {"text": "We can first notice that the rpt5pef phrase table allows the oracle to reach 50.6 BLEU, 8.1 BLEU below the oracle value obtained with conf10k, although rpt5pef contains twice as many bi-phrases.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.9978394508361816}, {"text": "BLEU", "start_pos": 92, "end_pos": 96, "type": "METRIC", "confidence": 0.988244891166687}]}, {"text": "The same conclusion can be made about rpt10pef, which is 3.9 BLEU higher than rpt5pef but contains nearly twice as many bi-phrases.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 61, "end_pos": 65, "type": "METRIC", "confidence": 0.9982802867889404}]}, {"text": "Finally, although conf10k contains approximatively four times fewer bi-phrases than rpt10pef, its oracle value is 4.2 BLEU higher.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 118, "end_pos": 122, "type": "METRIC", "confidence": 0.9989996552467346}]}, {"text": "This points out the fact that conf10k is a lot more precise rewriting phrase table for the translations to rewrite, as well as the fact that rpt5pef and rpt10pef are much noisier and consequently difficult to use efficiently by our automatic rewriting procedure.", "labels": [], "entities": []}, {"text": "We now turn to the question of how our rewriting system fares on a more difficult task, and used TED Talks, 6 BLEU below Medical for the English to French direction, for this purpose.", "labels": [], "entities": [{"text": "TED Talks", "start_pos": 97, "end_pos": 106, "type": "DATASET", "confidence": 0.7079875469207764}, {"text": "BLEU", "start_pos": 110, "end_pos": 114, "type": "METRIC", "confidence": 0.9934290051460266}]}, {"text": "In the same way as we did for Medical, we first tried to find the best training configuration for the ranker of the rewriting system.", "labels": [], "entities": [{"text": "Medical", "start_pos": 30, "end_pos": 37, "type": "DATASET", "confidence": 0.8337198495864868}]}, {"text": "For this task, mixing the n-best neighborhood and 10pefNeigh with n=10 seemed to be sufficient to have no more improvement on the development set by increasing n for both language directions, so we used this training configuration.", "labels": [], "entities": []}, {"text": "As for the rewriting phrase table used on the test set, we simply selected conf10k as in the Medical task.", "labels": [], "entities": []}, {"text": "Results are reported in for French to English and English to French.", "labels": [], "entities": []}, {"text": "We first observe that reranker performed similarly for the two translation directions, by improving 1-pass Moses by 0.5 BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 120, "end_pos": 124, "type": "METRIC", "confidence": 0.9972723126411438}]}, {"text": "The smaller improvements maybe partly attributed to the better LM used in 1-pass Moses, implying a better early modeling of grammaticality, but also by the fact that models such as SOUL and POS LMs rely on accurate contexts and are therefore more apt to help in choosing translations among generally better candidates.: Results for the baselines, our best configuration and the semi-oracle for the TED Talks.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Corpora used in this work.", "labels": [], "entities": []}, {"text": " Table 2: Results on Medical for different training configurations, rewriting phrase tables and beam  sizes. opti denotes our optimal configuration for rewriter.", "labels": [], "entities": []}, {"text": " Table 3: Results for the semi-oracle using opti.", "labels": [], "entities": []}, {"text": " Table 4: Results for manual error analysis for the first 70 test sentences.", "labels": [], "entities": []}, {"text": " Table 5: Results for the baselines, our best configuration and the semi-oracle for the TED Talks.", "labels": [], "entities": [{"text": "TED Talks", "start_pos": 88, "end_pos": 97, "type": "TASK", "confidence": 0.7209747731685638}]}]}