{"title": [{"text": "Correcting errors in speech recognition with articulatory dynamics", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.7217247039079666}]}], "abstractContent": [{"text": "We introduce a novel mechanism for incorporating articulatory dynamics into speech recognition with the theory of task dynamics.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 76, "end_pos": 94, "type": "TASK", "confidence": 0.7127786427736282}]}, {"text": "This system reranks sentence-level hypotheses by the likelihoods of their hypothetical articulatory realizations which are derived from relationships learned with aligned acoustic/articulatory data.", "labels": [], "entities": []}, {"text": "Experiments compare this with two baseline systems, namely an acoustic hidden Markov model and a dynamic Bayes network augmented with discretized representations of the vocal tract.", "labels": [], "entities": []}, {"text": "Our system based on task dynamics reduces word-error rates significantly by 10.2% relative to the best baseline models.", "labels": [], "entities": []}], "introductionContent": [{"text": "Although modern automatic speech recognition (ASR) takes several cues from the biological perception of speech, it rarely models its biological production.", "labels": [], "entities": [{"text": "automatic speech recognition (ASR)", "start_pos": 16, "end_pos": 50, "type": "TASK", "confidence": 0.8183835794528326}]}, {"text": "The result is that speech is treated as a surface acoustic phenomenon with lexical or phonetic hidden dynamics but without any physical constraints in between.", "labels": [], "entities": []}, {"text": "This omission leads to some untenable assumptions.", "labels": [], "entities": []}, {"text": "For example, speech is often treated out of convenience as a sequence of discrete, non-overlapping packets, such as phonemes, despite the fact that some major difficulties in ASR, such as co-articulation, are by definition the result of concurrent physiological phenomena).", "labels": [], "entities": [{"text": "ASR", "start_pos": 175, "end_pos": 178, "type": "TASK", "confidence": 0.9908151626586914}]}, {"text": "Many acoustic ambiguities can be resolved with knowledge of the vocal tract's configuration).", "labels": [], "entities": []}, {"text": "For example, the three nasal sonorants, /m/, /n/, and /ng/, are acoustically similar (i.e., they have large concentrations of energy at the same frequencies) but uniquely and reliably involve bilabial closure, tongue-tip elevation, and tongue-dorsum elevation, respectively.", "labels": [], "entities": []}, {"text": "Having access to the articulatory goals of the speaker would, in theory, make the identification of linguistic intent almost trivial.", "labels": [], "entities": [{"text": "identification of linguistic intent", "start_pos": 82, "end_pos": 117, "type": "TASK", "confidence": 0.8671678304672241}]}, {"text": "Although we don't typically have access to the vocal tract during speech recognition, its configuration can be estimated reasonably well from acoustics alone within adequate models or measurements of the vocal tract (.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 66, "end_pos": 84, "type": "TASK", "confidence": 0.7326507568359375}]}, {"text": "Evidence that such inversion takes place naturally in humans during speech perception suggests that the discriminability of speech sounds depends powerfully on their production (.", "labels": [], "entities": [{"text": "speech perception", "start_pos": 68, "end_pos": 85, "type": "TASK", "confidence": 0.7326086759567261}]}, {"text": "This paper describes the use of explicit models of physical speech production within recognition systems.", "labels": [], "entities": []}, {"text": "Initially, we augment traditional models of ASR with probabilistic relationships between acoustics and articulation learned from appropriate data.", "labels": [], "entities": [{"text": "ASR", "start_pos": 44, "end_pos": 47, "type": "TASK", "confidence": 0.993802547454834}]}, {"text": "This leads to the incorporation of a highlevel, goal-oriented, and control-based theory of speech production within a novel ASR system.", "labels": [], "entities": [{"text": "ASR", "start_pos": 124, "end_pos": 127, "type": "TASK", "confidence": 0.9872100353240967}]}], "datasetContent": [{"text": "Experimental data is obtained from two sources, as described in section 2.2.", "labels": [], "entities": []}, {"text": "We procure 1200 sentences from Toronto's TORGO database, and 896 from Edinburgh's MOCHA.", "labels": [], "entities": [{"text": "Toronto's TORGO database", "start_pos": 31, "end_pos": 55, "type": "DATASET", "confidence": 0.7649015486240387}, {"text": "Edinburgh's MOCHA", "start_pos": 70, "end_pos": 87, "type": "DATASET", "confidence": 0.8539847532908121}]}, {"text": "In total, there are 460 total unique sentence forms, 1092 total unique word forms, and 11065 total words uttered.", "labels": [], "entities": []}, {"text": "Except where noted, all experiments randomly split the data into 90% training and 10% testing sets for 5-cross validation.", "labels": [], "entities": []}, {"text": "MOCHA and TORGO data are never combined in a single training set due to differing EMA recording rates.", "labels": [], "entities": [{"text": "MOCHA", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7479756474494934}, {"text": "TORGO data", "start_pos": 10, "end_pos": 20, "type": "DATASET", "confidence": 0.7887044847011566}]}, {"text": "In all cases, models are database-dependent (i.e., all TORGO data is conflated, as is all of MOCHA).", "labels": [], "entities": [{"text": "TORGO data", "start_pos": 55, "end_pos": 65, "type": "DATASET", "confidence": 0.761926680803299}, {"text": "MOCHA", "start_pos": 93, "end_pos": 98, "type": "DATASET", "confidence": 0.82142174243927}]}, {"text": "For each of our baseline systems, we calculate the phoneme-error-rate (PER) and word-errorrate (WER) after training.", "labels": [], "entities": [{"text": "word-errorrate (WER)", "start_pos": 80, "end_pos": 100, "type": "METRIC", "confidence": 0.9151434749364853}]}, {"text": "The phoneme-errorrate is calculated according to the proportion of frames of speech incorrectly assigned to the proper phoneme.", "labels": [], "entities": []}, {"text": "The word-error-rate is calculated as the sum of insertion, deletion, and substitution errors in the highest-ranked hypothesis divided by the total number of words in the correct orthography.", "labels": [], "entities": []}, {"text": "The traditional HMM is compared by varying the number of Gaussians used in the modelling: Phoneme-and Word-Error-Rate (PER and WER) for different parameterizations of the baseline systems.", "labels": [], "entities": []}, {"text": "No. of Gaussians: Average log likelihood of true tract variable positions in test data, under distributions produced by mixture density networks with varying numbers of Gaussians. of acoustic observations.", "labels": [], "entities": [{"text": "Average log likelihood", "start_pos": 18, "end_pos": 40, "type": "METRIC", "confidence": 0.7966603438059489}]}, {"text": "Similarly, the DBN-A model is compared by varying the number of discrete quantizations of articulatory configurations, as described in section 3.", "labels": [], "entities": []}, {"text": "Results are obtained by direct decoding.", "labels": [], "entities": []}, {"text": "The average results across both databases, between which there are no significant differences, are shown in table 1.", "labels": [], "entities": []}, {"text": "In all cases the DBN-A model outperforms the HMM, which highlights the benefit of explicitly conditioning acoustic observations on articulatory causes.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Phoneme-and Word-Error-Rate (PER  and WER) for different parameterizations of the  baseline systems.", "labels": [], "entities": [{"text": "Word-Error-Rate (PER  and WER)", "start_pos": 22, "end_pos": 52, "type": "METRIC", "confidence": 0.5097927153110504}]}, {"text": " Table 2: Average log likelihood of true tract vari- able positions in test data, under distributions pro- duced by mixture density networks with varying  numbers of Gaussians.", "labels": [], "entities": [{"text": "Average log likelihood", "start_pos": 10, "end_pos": 32, "type": "METRIC", "confidence": 0.794158935546875}]}, {"text": " Table 3: Average difference between predicted  tract variables and observed data, on [0, 1] scale.  (*) Nasals are evaluated only with MOCHA data,  since TORGO data lacks velum measurements.", "labels": [], "entities": [{"text": "MOCHA", "start_pos": 136, "end_pos": 141, "type": "METRIC", "confidence": 0.7777716517448425}, {"text": "TORGO data", "start_pos": 155, "end_pos": 165, "type": "DATASET", "confidence": 0.8333878815174103}]}]}