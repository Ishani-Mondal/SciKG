{"title": [], "abstractContent": [{"text": "This paper introduces mNCD, a method for automatic evaluation of machine translations.", "labels": [], "entities": [{"text": "evaluation of machine translations", "start_pos": 51, "end_pos": 85, "type": "TASK", "confidence": 0.5721660256385803}]}, {"text": "The measure is based on normalized compression distance (NCD), a general information theoretic measure of string similarity, and flexible word matching provided by stemming and synonyms.", "labels": [], "entities": [{"text": "normalized compression distance (NCD)", "start_pos": 24, "end_pos": 61, "type": "METRIC", "confidence": 0.7728195091088613}, {"text": "word matching", "start_pos": 138, "end_pos": 151, "type": "TASK", "confidence": 0.7019801735877991}]}, {"text": "The mNCD measure outperforms NCD in system-level correlation to human judgments in English.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic evaluation of machine translation (MT) systems requires automated procedures to ensure consistency and efficient handling of large amounts of data.", "labels": [], "entities": [{"text": "Automatic evaluation of machine translation (MT)", "start_pos": 0, "end_pos": 48, "type": "TASK", "confidence": 0.729485847055912}]}, {"text": "In statistical MT systems, automatic evaluation of translations is essential for parameter optimization and system development.", "labels": [], "entities": [{"text": "MT", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.8478603959083557}, {"text": "parameter optimization", "start_pos": 81, "end_pos": 103, "type": "TASK", "confidence": 0.7824482023715973}]}, {"text": "Human evaluation is too labor intensive, time consuming and expensive for daily evaluations.", "labels": [], "entities": [{"text": "Human evaluation", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.5572953522205353}]}, {"text": "However, manual evaluation is important in the comparison of different MT systems and for the validation and development of automatic MT evaluation measures, which try to model human assessments of translations as closely as possible.", "labels": [], "entities": [{"text": "MT", "start_pos": 71, "end_pos": 73, "type": "TASK", "confidence": 0.9821450710296631}, {"text": "MT evaluation", "start_pos": 134, "end_pos": 147, "type": "TASK", "confidence": 0.9516352713108063}]}, {"text": "Furthermore, the ideal evaluation method would be language independent, fast to compute and simple.", "labels": [], "entities": []}, {"text": "Recently, normalized compression distance (NCD) has been applied to the evaluation of machine translations.", "labels": [], "entities": [{"text": "normalized compression distance (NCD)", "start_pos": 10, "end_pos": 47, "type": "METRIC", "confidence": 0.7648734599351883}, {"text": "machine translations", "start_pos": 86, "end_pos": 106, "type": "TASK", "confidence": 0.6730157434940338}]}, {"text": "NCD is a general information theoretic measure of string similarity, whereas most MT evaluation measures, e.g., BLEU and METEOR, are specifically constructed for the task.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 82, "end_pos": 95, "type": "TASK", "confidence": 0.8883147835731506}, {"text": "BLEU", "start_pos": 112, "end_pos": 116, "type": "METRIC", "confidence": 0.9972659349441528}, {"text": "METEOR", "start_pos": 121, "end_pos": 127, "type": "METRIC", "confidence": 0.9164676666259766}]}, {"text": "introduced BAD-GER, an MT evaluation measure that uses NCD and a language independent word normalization method.", "labels": [], "entities": [{"text": "BAD-GER", "start_pos": 11, "end_pos": 18, "type": "METRIC", "confidence": 0.9802983403205872}, {"text": "MT evaluation", "start_pos": 23, "end_pos": 36, "type": "TASK", "confidence": 0.9113058745861053}, {"text": "language independent word normalization", "start_pos": 65, "end_pos": 104, "type": "TASK", "confidence": 0.6145443022251129}]}, {"text": "BADGER scores were directly compared against the scores of METEOR and word error rate (WER).", "labels": [], "entities": [{"text": "BADGER", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.8692625761032104}, {"text": "METEOR", "start_pos": 59, "end_pos": 65, "type": "METRIC", "confidence": 0.9980337023735046}, {"text": "word error rate (WER)", "start_pos": 70, "end_pos": 91, "type": "METRIC", "confidence": 0.8971360921859741}]}, {"text": "The correlation between BADGER and METEOR were low and correlations between BADGER and WER high.", "labels": [], "entities": [{"text": "BADGER", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.8523260354995728}, {"text": "METEOR", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9446938037872314}, {"text": "BADGER", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9509106874465942}, {"text": "WER", "start_pos": 87, "end_pos": 90, "type": "METRIC", "confidence": 0.9955370426177979}]}, {"text": "uses the NCD directly as an MT evaluation measure.", "labels": [], "entities": [{"text": "NCD", "start_pos": 9, "end_pos": 12, "type": "DATASET", "confidence": 0.9743991494178772}, {"text": "MT evaluation", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.8249930739402771}]}, {"text": "He showed with a small corpus of three language pairs that NCD and METEOR 0.6 correlated for translations of 10-12 MT systems.", "labels": [], "entities": [{"text": "METEOR", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.9697368741035461}]}, {"text": "NCD was not compared to human assessments of translations, but correlations of NCD and METEOR scores were very high for all the three language pairs.", "labels": [], "entities": [{"text": "METEOR", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.980426549911499}]}, {"text": "have extended the work by including NCD in the ACL WMT08 evaluation framework and showing that NCD is correlated to human judgments.", "labels": [], "entities": [{"text": "ACL WMT08 evaluation framework", "start_pos": 47, "end_pos": 77, "type": "DATASET", "confidence": 0.7467425465583801}]}, {"text": "The NCD measure did not match the performance of the state-of-the-art MT evaluation measures in English, but it presented a viable alternative to de facto standard BLEU), which is simple and effective but has been shown to have a number of drawbacks).", "labels": [], "entities": [{"text": "NCD measure", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.7975930869579315}, {"text": "MT evaluation", "start_pos": 70, "end_pos": 83, "type": "TASK", "confidence": 0.891190230846405}, {"text": "BLEU", "start_pos": 164, "end_pos": 168, "type": "METRIC", "confidence": 0.996324360370636}]}, {"text": "Some recent advances in automatic MT evaluation have included non-binary matching between compared items (Banerjee and, which is implicitly present in the string-based NCD measure.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 34, "end_pos": 47, "type": "TASK", "confidence": 0.9674516916275024}]}, {"text": "Our motivation is to investigate whether including additional language dependent resources would improve the NCD measure.", "labels": [], "entities": [{"text": "NCD measure", "start_pos": 109, "end_pos": 120, "type": "DATASET", "confidence": 0.7995255887508392}]}, {"text": "We experiment with relaxed word matching using stemming and a lexical database to allow lexical changes.", "labels": [], "entities": [{"text": "word matching", "start_pos": 27, "end_pos": 40, "type": "TASK", "confidence": 0.7167239040136337}]}, {"text": "These additional modules attempt to make the reference sentences more similar to the evaluated translations on the string level.", "labels": [], "entities": []}, {"text": "We report an experiment showing that document-level NCD and aggregated NCD scores for individual sentences produce very similar correlations to human judgments.", "labels": [], "entities": []}], "datasetContent": [{"text": "The proposed mNCD and the basic NCD measure were evaluated by computing correlation to human judgments of translations.", "labels": [], "entities": []}, {"text": "A high correlation value between an MT evaluation measure and human judgments indicates that the measure is able to evaluate translations in a more similar way to humans.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 36, "end_pos": 49, "type": "TASK", "confidence": 0.8931654989719391}]}, {"text": "Relaxed alignments with the METEOR modules exact, stem and synonym were created for English for the computation of the mNCD score.", "labels": [], "entities": [{"text": "exact", "start_pos": 43, "end_pos": 48, "type": "METRIC", "confidence": 0.8526598811149597}]}, {"text": "The synonym module was not available with other target languages.", "labels": [], "entities": []}, {"text": "The 2008 ACL Workshop on Statistical Machine Translation) shared task data includes translations from a total of 30 MT systems between English and five European languages, as well as automatic and human trans-Candidate C/ Reference R/ Similarized Reference S 1-NCD METEOR C There is no effective means to stop a Tratsch, which was already included in the world.", "labels": [], "entities": [{"text": "ACL Workshop on Statistical Machine Translation) shared task", "start_pos": 9, "end_pos": 69, "type": "TASK", "confidence": 0.6341222325960795}, {"text": "METEOR", "start_pos": 265, "end_pos": 271, "type": "METRIC", "confidence": 0.6183894276618958}]}, {"text": "R There is no good way to halt gossip that has already begun to spread.", "labels": [], "entities": []}, {"text": ".41 .31 S There is no effective means to stop gossip that has already begun to spread.", "labels": [], "entities": []}, {"text": "For the translation tasks into English, the relaxed alignment using a stem module and the synonym module affected 7.5 % of all words, whereas only 5.1 % of the words were changed in the tasks from English into the other languages.", "labels": [], "entities": [{"text": "translation tasks", "start_pos": 8, "end_pos": 25, "type": "TASK", "confidence": 0.9087500274181366}]}, {"text": "The data was preprocessed in two different ways.", "labels": [], "entities": []}, {"text": "For NCD we kept the data as is, which we called real casing (rc).", "labels": [], "entities": [{"text": "NCD", "start_pos": 4, "end_pos": 7, "type": "DATASET", "confidence": 0.9025737643241882}]}, {"text": "Since the used METEOR align module lowercases all text, we restored the case information in mNCD by copying the correct case from the reference translation to the similarized reference, based on METEOR's alignment.", "labels": [], "entities": []}, {"text": "The other way was to lowercase all data (lc).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Example German-English translations showing the effect of relaxed matching in the 1-mNCD  score (for rows S) compared with METEOR using the exact module only, since the modules stem  and synonym are already used in the similarized reference. Replaced words are emphasized.", "labels": [], "entities": [{"text": "METEOR", "start_pos": 133, "end_pos": 139, "type": "METRIC", "confidence": 0.9500946402549744}]}, {"text": " Table 2: Mean system level correlations over  all translation tasks into English for variants of  mNCD and NCD. Higher values are emphasized.  Parameters are the compressor PPMZ or bz2 and  the preprocessing choice lowercasing (lc) or real  casing (rc).", "labels": [], "entities": []}, {"text": " Table 3: mNCD versus NCD system correlation  RANK results with different parameters (the same  as in Table 2) for each target language. Higher  values are emphasized. Target languages DE, FR  and ES use only the stem module.", "labels": [], "entities": [{"text": "NCD system correlation  RANK", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.5366790592670441}, {"text": "FR", "start_pos": 189, "end_pos": 191, "type": "METRIC", "confidence": 0.8032956123352051}]}, {"text": " Table 4: Average system-level correlations over  translation tasks into English for NCD, mNCD  and other MT evaluations measures", "labels": [], "entities": [{"text": "MT evaluations", "start_pos": 106, "end_pos": 120, "type": "TASK", "confidence": 0.892617255449295}]}, {"text": " Table 5: Average system-level correlations for the  RANK category from English for NCD, mNCD  and other MT evaluation measures.", "labels": [], "entities": [{"text": "RANK category", "start_pos": 53, "end_pos": 66, "type": "DATASET", "confidence": 0.5902436226606369}, {"text": "NCD", "start_pos": 84, "end_pos": 87, "type": "DATASET", "confidence": 0.8317288160324097}, {"text": "MT evaluation", "start_pos": 105, "end_pos": 118, "type": "TASK", "confidence": 0.884207159280777}]}]}