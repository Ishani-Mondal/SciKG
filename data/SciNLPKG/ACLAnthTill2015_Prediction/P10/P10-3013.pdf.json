{"title": [{"text": "Automatic Selectional Preference Acquisition for Latin verbs", "labels": [], "entities": [{"text": "Selectional Preference Acquisition", "start_pos": 10, "end_pos": 44, "type": "TASK", "confidence": 0.7559794584910074}]}], "abstractContent": [{"text": "We present a system that automatically induces Selectional Preferences (SPs) for Latin verbs from two treebanks by using Latin WordNet.", "labels": [], "entities": []}, {"text": "Our method overcomes some of the problems connected with data sparseness and the small size of the input corpora.", "labels": [], "entities": []}, {"text": "We also suggest away to evaluate the acquired SPs on unseen events extracted from other Latin corpora.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic acquisition of semantic information from corpora is a challenge for research on lowresourced languages, especially when semantically annotated corpora are not available.", "labels": [], "entities": [{"text": "Automatic acquisition of semantic information from corpora", "start_pos": 0, "end_pos": 58, "type": "TASK", "confidence": 0.7541025536400932}]}, {"text": "Latin is definitely a high-resourced language for what concerns the number of available texts and traditional lexical resources such as dictionaries.", "labels": [], "entities": []}, {"text": "Nevertheless, it is a low-resourced language from a computational point of view ( . As far as NLP tools for Latin are concerned, parsing experiments with machine learning techniques are ongoing (, although more work is still needed in this direction, especially given the small size of the training data.", "labels": [], "entities": []}, {"text": "As a matter of fact, only three syntactically annotated Latin corpora are available (and still in progress): the Latin Dependency Treebank (LDT, 53,000 tokens) for classical Latin (), the Index Thomisticus Treebank (IT-TB, 54,000 tokens) for Thomas Aquinas's works, and the PROIEL treebank (approximately 100,000 tokens) for the Bible (.", "labels": [], "entities": [{"text": "Latin Dependency Treebank (LDT", "start_pos": 113, "end_pos": 143, "type": "DATASET", "confidence": 0.7068477928638458}, {"text": "Index Thomisticus Treebank (IT-TB", "start_pos": 188, "end_pos": 221, "type": "DATASET", "confidence": 0.7199060976505279}, {"text": "PROIEL treebank", "start_pos": 274, "end_pos": 289, "type": "DATASET", "confidence": 0.8606795072555542}]}, {"text": "In addition, a Latin version of WordNet -Latin WordNet (LWN; Minozzi, (2009) -is being compiled, consisting of around 10,000 lemmas inserted in the multilingual structure of MultiWordNet ().", "labels": [], "entities": [{"text": "WordNet -Latin WordNet (LWN; Minozzi, (2009)", "start_pos": 32, "end_pos": 76, "type": "DATASET", "confidence": 0.9020766913890839}]}, {"text": "The number and the size of these resources are small when compared with the corpora and the lexicons for modern languages, e. g. English.", "labels": [], "entities": []}, {"text": "Concerning semantic processing, no semantically annotated Latin corpus is available yet; building such a corpus manually would take considerable time and energy.", "labels": [], "entities": [{"text": "semantic processing", "start_pos": 11, "end_pos": 30, "type": "TASK", "confidence": 0.8326528370380402}]}, {"text": "Hence, research in computational semantics for Latin would benefit from exploiting the existing resources and tools through automatic lexical acquisition methods.", "labels": [], "entities": []}, {"text": "In this paper we deal with automatic acquisition of verbal selectional preferences (SPs) for Latin, i. e. the semantic preferences of verbs on their arguments: e. g. we expect the object position of the verb edo 'eat' to be mostly filled by nouns from the food domain.", "labels": [], "entities": [{"text": "automatic acquisition of verbal selectional preferences (SPs)", "start_pos": 27, "end_pos": 88, "type": "TASK", "confidence": 0.5822248856226603}]}, {"text": "For this task, we propose a method inspired by and outlined in an earlier version on the IT-TB in.", "labels": [], "entities": [{"text": "IT-TB in", "start_pos": 89, "end_pos": 97, "type": "DATASET", "confidence": 0.9376897215843201}]}, {"text": "SPs are defined as probability distributions over semantic features extracted as sets of LWN nodes.", "labels": [], "entities": []}, {"text": "The input data are two subcategorization lexicons automatically extracted from the LDT and the IT-TB ( . Our main contribution is to create anew tool for semantic processing of Latin by adapting computational techniques developed for extant languages to the special case of Latin.", "labels": [], "entities": [{"text": "semantic processing of Latin", "start_pos": 154, "end_pos": 182, "type": "TASK", "confidence": 0.826376274228096}]}, {"text": "A successful adaptation is contingent on overcoming corpus size differences.", "labels": [], "entities": []}, {"text": "The way our model combines the syntactic information contained in the treebanks with the lexical semantic knowledge from LWN allows us to overcome some of the difficulties related to the small size of the input corpora.", "labels": [], "entities": []}, {"text": "This is the main difference from corpora for modern languages, together with the absence of semantic annotation.", "labels": [], "entities": []}, {"text": "Moreover, we face the problem of evaluating our system's ability to generalize over unseen cases by using text occurrences, as access to human linguistic judgements is denied for Latin.", "labels": [], "entities": []}, {"text": "In the rest of the paper we will briefly summarize previous work on SP acquisition and motivate our approach (section 2); we will then describe our system (section 3), report on first results and evaluation (section 4), and finally conclude by suggesting future directions of research (section 5).", "labels": [], "entities": [{"text": "SP acquisition", "start_pos": 68, "end_pos": 82, "type": "TASK", "confidence": 0.9783714115619659}]}], "datasetContent": [{"text": "The clustering algorithm was run on 15509 frames and it generated 7105 constructions.", "labels": [], "entities": []}, {"text": "displays the 5 constructions assigned to the 9 frames where the verb introduco 'bring in, introduce' occurs.", "labels": [], "entities": []}, {"text": "Note the semantic similarity between addo 'add to, bring to', immitto 'send against, insert', induco 'bring forward, introduce' and introduco, and the similarity between the syntactic patterns and the argument fillers within the same construction.", "labels": [], "entities": []}, {"text": "For example, finis 'end, borders' and effectus 'result' share the semantic properties AT-TRIBUTE, COGNITIO 'cognition', CONSCIENTIA 'conscience', EVENTUM 'event', among others.", "labels": [], "entities": [{"text": "AT-TRIBUTE", "start_pos": 86, "end_pos": 96, "type": "METRIC", "confidence": 0.9943811297416687}]}, {"text": "The vast majority of constructions contain less than 4 frames.", "labels": [], "entities": []}, {"text": "This contrasts with the more general constructions found by Alishahi (2008) and can be explained by several factors.", "labels": [], "entities": []}, {"text": "First, the coverage of LWN is quite low with respect to the fillers in our dataset.", "labels": [], "entities": [{"text": "coverage", "start_pos": 11, "end_pos": 19, "type": "METRIC", "confidence": 0.996742308139801}, {"text": "LWN", "start_pos": 23, "end_pos": 26, "type": "DATASET", "confidence": 0.7402117252349854}]}, {"text": "In fact, 782 fillers out of 2408 could not be assigned to any LWN synset; for these lemmas the semantic scores with all the other nouns are 0, causing probabilities lower than the baseline; this results in assigning the frame to the singleton construction consisting of the frame itself.", "labels": [], "entities": []}, {"text": "The same happens for fillers consisting of verbal lemmas, participles, pronouns and named entities, which amount to a third of the total number.", "labels": [], "entities": []}, {"text": "Furthermore, the data are not tagged by sense and the system deals with noun ambiguity by listing together all synsets of a word n (and their hypernyms) to form the semantic properties for n: consequently, each sense contributes to the semantic description of n in relation to the number of hypernyms it carries, rather than to its observed: Top 20 semantic properties in the semantic profile for ascendo 'ascend' + A (de)Obj. frequency.", "labels": [], "entities": [{"text": "A (de)Obj. frequency", "start_pos": 416, "end_pos": 436, "type": "METRIC", "confidence": 0.7733240638460431}]}, {"text": "Finally, a common problem in SP acquisition systems is the noise in the data, including tagging and metaphorical usages.", "labels": [], "entities": [{"text": "SP acquisition", "start_pos": 29, "end_pos": 43, "type": "TASK", "confidence": 0.9852373600006104}]}, {"text": "This problem is even greater in our case, where the small size of the data underestimates the variance and therefore overestimates the contribution of noisy observations.", "labels": [], "entities": []}, {"text": "Metaphorical and abstract usages are especially frequent in the data from the IT-TB, due to the philosophical domain of the texts.", "labels": [], "entities": [{"text": "IT-TB", "start_pos": 78, "end_pos": 83, "type": "DATASET", "confidence": 0.7640379667282104}]}, {"text": "As to the SP acquisition, we ran the system on all constructions generated by the clustering.", "labels": [], "entities": [{"text": "SP acquisition", "start_pos": 10, "end_pos": 24, "type": "TASK", "confidence": 0.603264570236206}]}, {"text": "We excluded the pronouns occurring as argument fillers, and manually tagged the named entities.", "labels": [], "entities": []}, {"text": "For each verb lemma and slot we obtained a probability distribution over the 6608 LWN noun nodes.", "labels": [], "entities": []}, {"text": "displays the 20 semantic properties with the highest SP probabilities as ablative arguments of ascendo 'ascend' introduced by de 'down from', 'out of'.", "labels": [], "entities": []}, {"text": "This semantic profile was created from the following fillers for the verbs contained in the constructions for ascendo and its synonyms: abyssus 'abyss', fumus 'smoke', lacus 'lake', machina 'machine', manus 'hand', negotiatio 'business', mare 'sea', os 'mouth', templum 'temple', terra 'land'.", "labels": [], "entities": []}, {"text": "These nouns are well represented by the semantic properties related to water and physical places.", "labels": [], "entities": []}, {"text": "Note also the high rank of general properties like actio 'act', which are associated to a large number of fillers and thus generally get a high probability.", "labels": [], "entities": []}, {"text": "Regarding evaluation, we are interested in testing two properties of our model: calibration and discrimination.", "labels": [], "entities": []}, {"text": "Calibration is related to the model's ability to distinguish between high and low probabilities.", "labels": [], "entities": []}, {"text": "We verify that our model is adequately calibrated, since its SP distribution is always very skewed (cf..", "labels": [], "entities": []}, {"text": "Therefore, the model is able to assign a high probability to a small set of nouns (preferred nouns) and a low probability to a large set of nouns (the rest), thus performing better than the baseline model, defined as the model that assigns the uniform distribution overall nouns.", "labels": [], "entities": []}, {"text": "Moreover, our model's entropy is always lower than the baseline: 12.2 vs. the 6.9-11.3 range; by the maximum entropy principle, this confirms that the system uses some information for estimating the probabilities: LWN structure, co-occurrence frequency, syntactic patterns.", "labels": [], "entities": []}, {"text": "However, we have no guarantee that the model uses this information sensibly.", "labels": [], "entities": []}, {"text": "For this, we test the system's discrimination potential, i. e. its ability to correctly estimate the SP probability of each single LWN node.", "labels": [], "entities": [{"text": "SP probability", "start_pos": 101, "end_pos": 115, "type": "METRIC", "confidence": 0.8861632347106934}]}, {"text": "-we see that the model assigns a high probability to most seen fillers for dico in the corpus: anima 'soul For what concerns evaluating the SP probability assigned to nouns unseen in the training set, Alishahi (2008) follows the approach suggested by, using human plausibility judgements on verb-noun pairs.", "labels": [], "entities": [{"text": "SP probability assigned", "start_pos": 140, "end_pos": 163, "type": "METRIC", "confidence": 0.9323278069496155}]}, {"text": "Given the absence of native speakers of Latin, we used random occurrences in corpora, considered as positive examples of plausible argument fillers; on the other hand, we cannot extract non-plausible fillers from a corpus unless we use a frequency-based criterion.", "labels": [], "entities": []}, {"text": "However, we can measure how well our system predicts the probability of these unseen events.", "labels": [], "entities": []}, {"text": "As a preliminary evaluation experiment, we randomly selected from our corpora a list of 19 high-frequency verbs (freq.>51) and 7 mediumfrequency verbs (11<freq.<50), for each of which we chose an interesting argument slot.", "labels": [], "entities": []}, {"text": "Then we randomly extracted one filler for each such pair from two collections of Latin texts (Perseus Digital Library and Corpus Thomisticum), provided that it was not in the training set.", "labels": [], "entities": [{"text": "Perseus Digital Library and Corpus Thomisticum", "start_pos": 94, "end_pos": 140, "type": "DATASET", "confidence": 0.8158087233702341}]}, {"text": "The semantic score in equation 1 on page 3 is then calculated between the set of semantic properties of n and that for f , to obtain the probability of finding the random filler n as an argument fora verb v.", "labels": [], "entities": []}, {"text": "For each of the 26 (verb, slot) pairs, we looked at three measures of central tendency: mean, median and the value of the third quantile, which were compared with the probability assigned by the model to the random filler.", "labels": [], "entities": []}, {"text": "If this probability was higher than the measure, the outcome was considered a success.", "labels": [], "entities": []}, {"text": "The successes were 22 for the mean, 25 for the median and 19 for the third quartile.", "labels": [], "entities": []}, {"text": "For all three measures a binomial test found the success rate to be statistically significant at the 5% level.", "labels": [], "entities": []}, {"text": "For example, table 3 and show that the filler for dico+A Obj in the evaluation set -sententia 'judgement' -is ranked 13th within the verb's semantic profile.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Top 20 semantic properties in the seman- tic profile for ascendo 'ascend' + A (de)Obj", "labels": [], "entities": [{"text": "A (de)Obj", "start_pos": 86, "end_pos": 95, "type": "METRIC", "confidence": 0.7004665255546569}]}, {"text": " Table 3: 15 nouns with the highest probabilities as  accusative objects of dico 'say'.", "labels": [], "entities": []}]}