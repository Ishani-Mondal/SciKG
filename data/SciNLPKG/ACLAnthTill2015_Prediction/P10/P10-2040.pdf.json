{"title": [{"text": "SVD and Clustering for Unsupervised POS Tagging", "labels": [], "entities": [{"text": "POS Tagging", "start_pos": 36, "end_pos": 47, "type": "TASK", "confidence": 0.7685548961162567}]}], "abstractContent": [{"text": "We revisit the algorithm of Sch\u00fctze (1995) for unsupervised part-of-speech tagging.", "labels": [], "entities": [{"text": "part-of-speech tagging", "start_pos": 60, "end_pos": 82, "type": "TASK", "confidence": 0.6691538989543915}]}, {"text": "The algorithm uses reduced-rank singular value decomposition followed by clustering to extract latent features from context distributions.", "labels": [], "entities": []}, {"text": "As implemented here, it achieves state-of-the-art tagging accuracy at considerably less cost than more recent methods.", "labels": [], "entities": [{"text": "tagging", "start_pos": 50, "end_pos": 57, "type": "TASK", "confidence": 0.9651105999946594}, {"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.9533873200416565}]}, {"text": "It can also produce a range of finer-grained tag-gings, with potential applications to various tasks.", "labels": [], "entities": []}], "introductionContent": [{"text": "While supervised approaches are able to solve the part-of-speech (POS) tagging problem with over 97% accuracy), unsupervised algorithms perform considerably less well.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging problem", "start_pos": 50, "end_pos": 86, "type": "TASK", "confidence": 0.6648115366697311}, {"text": "accuracy", "start_pos": 101, "end_pos": 109, "type": "METRIC", "confidence": 0.9975650310516357}]}, {"text": "These models attempt to tag text without resources such as an annotated corpus, a dictionary, etc.", "labels": [], "entities": []}, {"text": "The use of singular value decomposition (SVD) for this problem was introduced in.", "labels": [], "entities": [{"text": "singular value decomposition (SVD)", "start_pos": 11, "end_pos": 45, "type": "TASK", "confidence": 0.6958414912223816}]}, {"text": "Subsequently, a number of methods for POS tagging without a dictionary were examined, e.g., by,,,,,, and.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 38, "end_pos": 49, "type": "TASK", "confidence": 0.9217047393321991}]}, {"text": "The latter two, using Hidden Markov Models (HMMs), exhibit the highest performances to date for fully unsupervised POS tagging.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 115, "end_pos": 126, "type": "TASK", "confidence": 0.7578569650650024}]}, {"text": "The revisited SVD-based approach presented here, which we call \"two-step SVD\" or SVD2, has four important characteristics.", "labels": [], "entities": []}, {"text": "First, it achieves state-of-the-art tagging accuracy.", "labels": [], "entities": [{"text": "tagging", "start_pos": 36, "end_pos": 43, "type": "TASK", "confidence": 0.9307588338851929}, {"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9577696323394775}]}, {"text": "Second, it requires drastically less computational effort than the best currently available models.", "labels": [], "entities": []}, {"text": "Third, it demonstrates that state-of-the-art accuracy can be realized without disambiguation, i.e., without attempting to assign different tags to different tokens of the same type.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 45, "end_pos": 53, "type": "METRIC", "confidence": 0.9942798614501953}]}, {"text": "Finally, with no significant increase in computational cost, SVD2 can create much finer-grained labelings than typically produced by other algorithms.", "labels": [], "entities": []}, {"text": "When combined with some minimal supervision in postprocessing, this makes the approach useful for tagging languages that lack the resources required by fully supervised models.", "labels": [], "entities": [{"text": "tagging languages", "start_pos": 98, "end_pos": 115, "type": "TASK", "confidence": 0.9186244904994965}]}], "datasetContent": [{"text": "We ran the SVD2 algorithm described above on the full Wall Street Journal part of the Penn Treebank (1,173,766 tokens).", "labels": [], "entities": [{"text": "Wall Street Journal part of the Penn Treebank", "start_pos": 54, "end_pos": 99, "type": "DATASET", "confidence": 0.9557714685797691}]}, {"text": "Capitalization was ignored, resulting in N types = 43,766, with only a minor effect on accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9986030459403992}]}, {"text": "Evaluation was done against the POS-tag annotations of the 45-tag PTB tagset (hereafter PTB45), and against the Smith and Eisner (2005) coarse version of the PTB tagset (hereafter PTB17).", "labels": [], "entities": [{"text": "PTB tagset", "start_pos": 66, "end_pos": 76, "type": "DATASET", "confidence": 0.9141429960727692}, {"text": "PTB45", "start_pos": 88, "end_pos": 93, "type": "DATASET", "confidence": 0.7805242538452148}, {"text": "PTB tagset", "start_pos": 158, "end_pos": 168, "type": "DATASET", "confidence": 0.9549941420555115}, {"text": "PTB17", "start_pos": 180, "end_pos": 185, "type": "DATASET", "confidence": 0.6967065334320068}]}, {"text": "We selected the three evaluation criteria of: M-to-1, 1-to-1, and VI.", "labels": [], "entities": []}, {"text": "M-to-1 and 1-to-1 are the tagging accuracies under the best manyto-one map and the greedy one-to-one map respectively; VI is a map-free informationtheoretic criterion-see for details.", "labels": [], "entities": []}, {"text": "Although we find M-to-1 to be the most reliable criterion of the three, we include the other two criteria for completeness.", "labels": [], "entities": []}, {"text": "In addition to the best M-to-1 map, we also employ here, for large values of k 2 , a prototypebased M-to-1 map.", "labels": [], "entities": []}, {"text": "To construct this map, we first find, for each induced tag t, the word type with which it co-occurs most frequently; we call this word type the prototype oft.", "labels": [], "entities": []}, {"text": "We then query the annotated data for the most common gold tag for each prototype, and we map induced tag t to this gold tag.", "labels": [], "entities": []}, {"text": "This prototype-based M-to-1 map produces accuracy scores no greater-typically lower-than the best M-to-1 map.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9993728995323181}]}, {"text": "We discuss the value of this approach as a minimallysupervised post-processing step in Section 5.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Tagging accuracy under the best M-to-1 map, the greedy 1-to-1 map, and  VI, for the full PTB45 tagset and the reduced PTB17 tagset. HMM-EM, HMM-VB  and HMM-GS show the best results from", "labels": [], "entities": [{"text": "Tagging", "start_pos": 10, "end_pos": 17, "type": "TASK", "confidence": 0.95927494764328}, {"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9861333966255188}, {"text": "PTB45 tagset", "start_pos": 99, "end_pos": 111, "type": "DATASET", "confidence": 0.9640181958675385}, {"text": "PTB17 tagset", "start_pos": 128, "end_pos": 140, "type": "DATASET", "confidence": 0.9500927925109863}]}]}