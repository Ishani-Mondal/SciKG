{"title": [], "abstractContent": [{"text": "Information-extraction (IE) systems seek to distill semantic relations from natural-language text, but most systems use supervised learning of relation-specific examples and are thus limited by the availability of training data.", "labels": [], "entities": []}, {"text": "Open IE systems such as TextRunner, on the other hand, aim to handle the unbounded number of relations found on the Web.", "labels": [], "entities": []}, {"text": "But how well can these open systems perform?", "labels": [], "entities": []}, {"text": "This paper presents WOE, an open IE system which improves dramatically on TextRunner's precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9945038557052612}, {"text": "recall", "start_pos": 101, "end_pos": 107, "type": "METRIC", "confidence": 0.9976416826248169}]}, {"text": "The key to WOE's performance is a novel form of self-supervised learning for open extractors-using heuris-tic matches between Wikipedia infobox attribute values and corresponding sentences to construct training data.", "labels": [], "entities": []}, {"text": "Like TextRunner, WOE's extractor eschews lexicalized features and handles an unbounded set of semantic relations.", "labels": [], "entities": []}, {"text": "WOE can operate in two modes: when restricted to POS tag features, it runs as quickly as TextRunner, but when set to use dependency-parse features its precision and recall rise even higher.", "labels": [], "entities": [{"text": "TextRunner", "start_pos": 89, "end_pos": 99, "type": "DATASET", "confidence": 0.8768306374549866}, {"text": "precision", "start_pos": 151, "end_pos": 160, "type": "METRIC", "confidence": 0.9995390176773071}, {"text": "recall", "start_pos": 165, "end_pos": 171, "type": "METRIC", "confidence": 0.9988382458686829}]}], "introductionContent": [{"text": "The problem of information-extraction (IE), generating relational data from natural-language text, has received increasing attention in recent years.", "labels": [], "entities": [{"text": "information-extraction (IE)", "start_pos": 15, "end_pos": 42, "type": "TASK", "confidence": 0.7379935532808304}]}, {"text": "A large, high-quality repository of extracted tuples can potentially benefit a wide range of NLP tasks such as question answering, ontology learning, and summarization.", "labels": [], "entities": [{"text": "question answering", "start_pos": 111, "end_pos": 129, "type": "TASK", "confidence": 0.9007215201854706}, {"text": "ontology learning", "start_pos": 131, "end_pos": 148, "type": "TASK", "confidence": 0.8293175101280212}, {"text": "summarization", "start_pos": 154, "end_pos": 167, "type": "TASK", "confidence": 0.9872740507125854}]}, {"text": "The vast majority of IE work uses supervised learning of relationspecific examples.", "labels": [], "entities": [{"text": "IE", "start_pos": 21, "end_pos": 23, "type": "TASK", "confidence": 0.9908033609390259}]}, {"text": "For example, the WebKB project () used labeled examples of the courses-taught-by relation to induce rules for identifying additional instances of the relation.", "labels": [], "entities": []}, {"text": "While these methods can achieve high precision and recall, they are limited by the availability of training data and are unlikely to scale to the thousands of relations found in text on the Web.", "labels": [], "entities": [{"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9983633160591125}, {"text": "recall", "start_pos": 51, "end_pos": 57, "type": "METRIC", "confidence": 0.9981988072395325}]}, {"text": "An alternative paradigm, Open IE, pioneered by the TextRunner system ( and the \"preemptive IE\" in (), aims to handle an unbounded number of relations and run quickly enough to process Webscale corpora.", "labels": [], "entities": []}, {"text": "Domain independence is achieved by extracting the relation name as well as its two arguments.", "labels": [], "entities": [{"text": "Domain independence", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.7542420923709869}]}, {"text": "Most open IE systems use selfsupervised learning, in which automatic heuristics generate labeled data for training the extractor.", "labels": [], "entities": []}, {"text": "For example, TextRunner uses a small set of handwritten rules to heuristically label training examples from sentences in the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 125, "end_pos": 138, "type": "DATASET", "confidence": 0.9951208233833313}]}, {"text": "This paper presents WOE (Wikipedia-based Open Extractor), the first system that autonomously transfers knowledge from random editors' effort of collaboratively editing Wikipedia to train an open information extractor.", "labels": [], "entities": []}, {"text": "Specifically, WOE generates relation-specific training examples by matching Infobox 1 attribute values to corresponding sentences (as done in and Luchs (), but WOE abstracts these examples to relationindependent training data to learn an unlexicalized extractor, akin to that of TextRunner.", "labels": [], "entities": []}, {"text": "WOE can operate in two modes: when restricted to shallow features like part-of-speech (POS) tags, it runs as quickly as Textrunner, but when set to use dependency-parse features its precision and recall rise even higher.", "labels": [], "entities": [{"text": "Textrunner", "start_pos": 120, "end_pos": 130, "type": "DATASET", "confidence": 0.9023590087890625}, {"text": "precision", "start_pos": 182, "end_pos": 191, "type": "METRIC", "confidence": 0.9995823502540588}, {"text": "recall", "start_pos": 196, "end_pos": 202, "type": "METRIC", "confidence": 0.9988428354263306}]}, {"text": "We present a thorough experimental evaluation, making the following contributions: \u2022 We present WOE, anew approach to open IE that uses Wikipedia for self-supervised learn-ing of unlexicalized extractors.", "labels": [], "entities": [{"text": "WOE", "start_pos": 96, "end_pos": 99, "type": "DATASET", "confidence": 0.7269932627677917}]}, {"text": "Compared with TextRunner (the state of the art) on three corpora, WOE yields between 72% and 91% improved F-measure -generalizing well beyond Wikipedia.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 106, "end_pos": 115, "type": "METRIC", "confidence": 0.8995523452758789}]}, {"text": "\u2022 Using the same learning algorithm and features as TextRunner, we compare four different ways to generate positive and negative training data with TextRunner's method, concluding that our Wikipedia heuristic is responsible for the bulk of WOE's improved accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 255, "end_pos": 263, "type": "METRIC", "confidence": 0.9970158338546753}]}, {"text": "\u2022 The biggest win arises from using parser features.", "labels": [], "entities": []}, {"text": "Previous work concluded that parser-based features are unnecessary for information extraction, but that work assumed the presence of lexical features.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 71, "end_pos": 93, "type": "TASK", "confidence": 0.8153876960277557}]}, {"text": "We show that abstract dependency paths area highly informative feature when performing unlexicalized extraction.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used three corpora for experiments: WSJ from Penn Treebank, Wikipedia, and the general Web.", "labels": [], "entities": [{"text": "WSJ from Penn Treebank", "start_pos": 39, "end_pos": 61, "type": "DATASET", "confidence": 0.760454997420311}, {"text": "Wikipedia", "start_pos": 63, "end_pos": 72, "type": "DATASET", "confidence": 0.9104637503623962}]}, {"text": "For each dataset, we randomly selected 300 sentences.", "labels": [], "entities": []}, {"text": "Each sentence was examined by two people to label all reasonable triples.", "labels": [], "entities": []}, {"text": "These candidate triples are mixed with pseudo-negative ones and submitted to Amazon Mechanical Turk for verification.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 77, "end_pos": 99, "type": "DATASET", "confidence": 0.9687019387880961}]}, {"text": "Each triple was examined by 5 Turkers.", "labels": [], "entities": []}, {"text": "We mark a triple's final label as positive when more than 3 Turkers marked them as positive.", "labels": [], "entities": []}], "tableCaptions": []}