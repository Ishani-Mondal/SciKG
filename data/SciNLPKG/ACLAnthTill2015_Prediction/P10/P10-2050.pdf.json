{"title": [{"text": "Hierarchical Sequential Learning for Extracting Opinions and their Attributes", "labels": [], "entities": [{"text": "Extracting Opinions and their Attributes", "start_pos": 37, "end_pos": 77, "type": "TASK", "confidence": 0.8054059505462646}]}], "abstractContent": [{"text": "Automatic opinion recognition involves a number of related tasks, such as identifying the boundaries of opinion expression , determining their polarity, and determining their intensity.", "labels": [], "entities": [{"text": "Automatic opinion recognition", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6498637596766154}]}, {"text": "Although much progress has been made in this area, existing research typically treats each of the above tasks in isolation.", "labels": [], "entities": []}, {"text": "In this paper, we apply a hierarchical parameter sharing technique using Conditional Random Fields for fine-grained opinion analysis, jointly detecting the boundaries of opinion expressions as well as determining two of their key attributes-polarity and intensity.", "labels": [], "entities": [{"text": "opinion analysis", "start_pos": 116, "end_pos": 132, "type": "TASK", "confidence": 0.7299786806106567}]}, {"text": "Our experimental results show that our proposed approach improves the performance over a baseline that does not exploit hierarchical structure among the classes.", "labels": [], "entities": []}, {"text": "In addition, we find that the joint approach outperforms a baseline that is based on cascading two separate components .", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic opinion recognition involves a number of related tasks, such as identifying expressions of opinion (e.g.,,), determining their polarity (e.g.,, ), and determining their strength, or intensity (e.g.,).", "labels": [], "entities": [{"text": "Automatic opinion recognition", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6402028997739156}]}, {"text": "Most previous work treats each subtask in isolation: opinion expression extraction (i.e. detecting the boundaries of opinion expressions) and opinion attribute classification (e.g. determining values for polarity and intensity) are tackled as separate steps in opinion recognition systems.", "labels": [], "entities": [{"text": "opinion expression extraction", "start_pos": 53, "end_pos": 82, "type": "TASK", "confidence": 0.6454629798730215}, {"text": "detecting the boundaries of opinion expressions", "start_pos": 89, "end_pos": 136, "type": "TASK", "confidence": 0.772703101237615}, {"text": "opinion attribute classification", "start_pos": 142, "end_pos": 174, "type": "TASK", "confidence": 0.6260319252808889}, {"text": "opinion recognition", "start_pos": 261, "end_pos": 280, "type": "TASK", "confidence": 0.8026212155818939}]}, {"text": "Unfortunately, errors from individual components will propagate in systems with cascaded component architectures, causing performance degradation in the end-toend system (e.g.) -in our case, in the end-to-end opinion recognition system.", "labels": [], "entities": [{"text": "opinion recognition", "start_pos": 209, "end_pos": 228, "type": "TASK", "confidence": 0.7232465744018555}]}, {"text": "In this paper, we apply a hierarchical parameter sharing technique (e.g.,,) using Conditional Random Fields (CRFs) () to finegrained opinion analysis.", "labels": [], "entities": [{"text": "finegrained opinion analysis", "start_pos": 121, "end_pos": 149, "type": "TASK", "confidence": 0.6642472346623739}]}, {"text": "In particular, we aim to jointly identify the boundaries of opinion expressions as well as to determine two of their key attributes -polarity and intensity.", "labels": [], "entities": []}, {"text": "Experimental results show that our proposed approach improves the performance over the baseline that does not exploit the hierarchical structure among the classes.", "labels": [], "entities": []}, {"text": "In addition, we find that the joint approach outperforms a baseline that is based on cascading two separate systems.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our system using the MultiPerspective Question Answering (MPQA) corpus     respond to direct subjective expression and expressive subjective element ( ).", "labels": [], "entities": [{"text": "MultiPerspective Question Answering (MPQA)", "start_pos": 33, "end_pos": 75, "type": "TASK", "confidence": 0.7293453216552734}]}, {"text": "Our implementation of hierarchical sequential learning is based on the Mallet) code for CRFs.", "labels": [], "entities": [{"text": "Mallet) code", "start_pos": 71, "end_pos": 83, "type": "DATASET", "confidence": 0.9085977673530579}]}, {"text": "In all experiments, we use a Gaussian prior of 1.0 for regularization.", "labels": [], "entities": []}, {"text": "We use 135 documents for development, and test on a different set of 400 documents using 10-fold crossvalidation.", "labels": [], "entities": []}, {"text": "We investigate three options for jointly extracting opinion expressions with their attributes as follows: [Baseline-1] Polarity-Only \u2229 Intensity-Only: For this baseline, we train two separate sequence tagging CRFs: one that extracts opinion expressions only with the polarity attribute (using common features and polarity extraction features in Section 3), and another that extracts opinion expressions only with the intensity attribute (using common features and intensity extraction features in Section 3).", "labels": [], "entities": [{"text": "sequence tagging CRFs", "start_pos": 192, "end_pos": 213, "type": "TASK", "confidence": 0.7729803919792175}]}, {"text": "We then combine the results from two separate CRFs by collecting all opinion entities extracted by both sequence taggers.", "labels": [], "entities": []}, {"text": "3 This 2 Only 1.5% of the polarity annotations correspond to both; hence, we merge both into the neutral.", "labels": [], "entities": []}, {"text": "Similarly, for gold standard intensity, we merge extremely high into high.", "labels": [], "entities": []}, {"text": "We collect all entities whose portions of text spans are extracted by both models.", "labels": [], "entities": []}, {"text": "baseline effectively represents a cascaded component approach.", "labels": [], "entities": []}, {"text": "[Baseline-2] Joint without Hierarchy: Here we use simple linear-chain CRFs without exploiting the class hierarchy for the opinion recognition task.", "labels": [], "entities": [{"text": "opinion recognition task", "start_pos": 122, "end_pos": 146, "type": "TASK", "confidence": 0.8554198543230692}]}, {"text": "We use the tags shown in.", "labels": [], "entities": []}, {"text": "Joint with Hierarchy: Finally, we test the hierarchical sequential learning approach elaborated in Section 3.", "labels": [], "entities": []}, {"text": "We evaluate all experiments at the opinion entity level, i.e. at the level of each opinion expression rather than at the token level.", "labels": [], "entities": []}, {"text": "We use three evaluation metrics: recall, precision, and F-measure with equally weighted recall and precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.999228835105896}, {"text": "precision", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.996752142906189}, {"text": "F-measure", "start_pos": 56, "end_pos": 65, "type": "METRIC", "confidence": 0.9988365769386292}, {"text": "recall", "start_pos": 88, "end_pos": 94, "type": "METRIC", "confidence": 0.9976658821105957}, {"text": "precision", "start_pos": 99, "end_pos": 108, "type": "METRIC", "confidence": 0.9838760495185852}]}, {"text": "shows the performance of opinion extraction without matching any attribute.", "labels": [], "entities": [{"text": "opinion extraction", "start_pos": 25, "end_pos": 43, "type": "TASK", "confidence": 0.7180409282445908}]}, {"text": "That is, an extracted opinion entity is counted as correct if it overlaps 4 with a gold standard opinion expression, without checking the correctness of its attributes.", "labels": [], "entities": []}, {"text": "show the performance of opinion extraction with the correct polarity and intensity respectively.", "labels": [], "entities": [{"text": "opinion extraction", "start_pos": 24, "end_pos": 42, "type": "TASK", "confidence": 0.7323363572359085}]}, {"text": "From all of these evaluation criteria, JOINT WITH HIERARCHY performs the best, and the least effective one is BASELINE-1, which cascades two separately trained models.", "labels": [], "entities": [{"text": "JOINT WITH", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.8380212783813477}, {"text": "HIERARCHY", "start_pos": 50, "end_pos": 59, "type": "METRIC", "confidence": 0.5413137078285217}, {"text": "BASELINE-1", "start_pos": 110, "end_pos": 120, "type": "METRIC", "confidence": 0.957122802734375}]}, {"text": "It is interesting that the simple sequential tagging approach even without exploiting the hierarchy (BASELINE-2) performs better than the cascaded approach (BASELINE-1).", "labels": [], "entities": [{"text": "sequential tagging", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.5684745162725449}, {"text": "BASELINE-2", "start_pos": 101, "end_pos": 111, "type": "METRIC", "confidence": 0.9282946586608887}]}, {"text": "When evaluating with respect to the polarity attribute, the performance of the negative class is substantially higher than the that of other classes.", "labels": [], "entities": []}, {"text": "This is not surprising as there is approximately twice as much data for the negative class.", "labels": [], "entities": []}, {"text": "When evaluating with respect to the intensity attribute, the performance of the LOW class is substantially lower than that of other classes.", "labels": [], "entities": []}, {"text": "This result reflects the fact that it is inherently harder to distinguish an opinion expression with low intensity from no opinion.", "labels": [], "entities": []}, {"text": "In general, we observe that determining correct intensity attributes is a much harder task than determining correct polarity attributes.", "labels": [], "entities": []}, {"text": "In order to have a sense of upper bound, we also report the individual performance of two separately trained models used for BASELINE-1: for the Polarity-Only model that extracts opinion boundaries only with polarity attribute, the F-scores with respect to the positive, neutral, negative classes are 46.7, 47.5, 57.0, respectively.", "labels": [], "entities": [{"text": "BASELINE-1", "start_pos": 125, "end_pos": 135, "type": "TASK", "confidence": 0.68766188621521}, {"text": "F-scores", "start_pos": 232, "end_pos": 240, "type": "METRIC", "confidence": 0.9728527665138245}]}, {"text": "For the IntensityOnly model, the F-scores with respect to the high, medium, low classes are 37.1, 40.8, 26.6, respectively.", "labels": [], "entities": [{"text": "F-scores", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9974242448806763}]}, {"text": "Remind that neither of these models alone fully solve the joint task of extracting boundaries as well as determining two attributions simultaneously.", "labels": [], "entities": []}, {"text": "As a result, when conjoining the results from the two models (BASELINE-1), the final performance drops substantially.", "labels": [], "entities": [{"text": "BASELINE-1", "start_pos": 62, "end_pos": 72, "type": "METRIC", "confidence": 0.961565375328064}]}, {"text": "We conclude from our experiments that the simple joint sequential tagging approach even without exploiting the hierarchy brings a better performance than combining two separately developed systems.", "labels": [], "entities": [{"text": "joint sequential tagging", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.6054112414518992}]}, {"text": "In addition, our hierarchical joint sequential learning approach brings a further performance gain over the simple joint sequential tagging method.", "labels": [], "entities": [{"text": "joint sequential tagging", "start_pos": 115, "end_pos": 139, "type": "TASK", "confidence": 0.621398131052653}]}], "tableCaptions": [{"text": " Table 1: Labels for Opinion Extraction with Polarity and Intensity", "labels": [], "entities": [{"text": "Opinion Extraction", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.6639213562011719}]}, {"text": " Table 2: Performance of Opinion Extraction with Correct Polarity Attribute", "labels": [], "entities": []}, {"text": " Table 3: Performance of Opinion Extraction with Correct Intensity Attribute", "labels": [], "entities": [{"text": "Performance of Opinion Extraction", "start_pos": 10, "end_pos": 43, "type": "TASK", "confidence": 0.5498684421181679}]}, {"text": " Table 4: Performance of Opinion Extraction", "labels": [], "entities": [{"text": "Performance of Opinion Extraction", "start_pos": 10, "end_pos": 43, "type": "TASK", "confidence": 0.5383976176381111}]}]}