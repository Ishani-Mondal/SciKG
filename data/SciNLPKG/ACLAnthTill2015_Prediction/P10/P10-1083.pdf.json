{"title": [], "abstractContent": [{"text": "We present a system that learns to follow navigational natural language directions.", "labels": [], "entities": [{"text": "navigational natural language directions", "start_pos": 42, "end_pos": 82, "type": "TASK", "confidence": 0.8567162901163101}]}, {"text": "Where traditional models learn from linguistic annotation or word distributions , our approach is grounded in the world, learning by apprenticeship from routes through a map paired with English descriptions.", "labels": [], "entities": []}, {"text": "Lacking an explicit alignment between the text and the reference path makes it difficult to determine what portions of the language describe which aspects of the route.", "labels": [], "entities": []}, {"text": "We learn this correspondence with a reinforcement learning algorithm, using the deviation of the route we follow from the intended path as a reward signal.", "labels": [], "entities": []}, {"text": "We demonstrate that our system successfully grounds the meaning of spatial terms like above and south into geometric properties of paths.", "labels": [], "entities": []}], "introductionContent": [{"text": "Spatial language usage is a vital component for physically grounded language understanding systems.", "labels": [], "entities": [{"text": "Spatial language usage", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8540758490562439}]}, {"text": "Spoken language interfaces to robotic assistants ( and Geographic Information Systems () must cope with the inherent ambiguity in spatial descriptions.", "labels": [], "entities": []}, {"text": "The semantics of imperative and spatial language is heavily dependent on the physical setting it is situated in, motivating automated learning approaches to acquiring meaning.", "labels": [], "entities": []}, {"text": "Traditional accounts of learning typically rely on linguistic annotation or word distributions).", "labels": [], "entities": []}, {"text": "In contrast, we present an apprenticeship learning system which learns to imitate human instruction following, without linguistic annotation.", "labels": [], "entities": []}, {"text": "Solved using a reinforcement learning algorithm, our system acquires the meaning of spatial words through 1.", "labels": [], "entities": []}, {"text": "go vertically down until you're underneath eh diamond mine 2.", "labels": [], "entities": []}, {"text": "then eh go right until you're 3.", "labels": [], "entities": []}, {"text": "you're between springbok and highest viewpoint: A path appears on the instruction giver's map, who describes it to the instruction follower.", "labels": [], "entities": []}, {"text": "grounded interaction with the world.", "labels": [], "entities": []}, {"text": "This draws on the intuition that children learn to use spatial language through a mixture of observing adult language usage and situated interaction in the world, usually without explicit definitions.", "labels": [], "entities": []}, {"text": "Our system learns to follow navigational directions in a route following task.", "labels": [], "entities": []}, {"text": "We evaluate our approach on the HCRC Map Task corpus, a collection of spoken dialogs describing paths to take through a map.", "labels": [], "entities": [{"text": "HCRC Map Task corpus", "start_pos": 32, "end_pos": 52, "type": "DATASET", "confidence": 0.9577228426933289}]}, {"text": "In this setting, two participants, the instruction giver and instruction follower, each have a map composed of named landmarks.", "labels": [], "entities": []}, {"text": "Furthermore, the instruction giver has a route drawn on her map, and it is her task to describe the path to the instruction follower, who cannot seethe reference path.", "labels": [], "entities": []}, {"text": "Our system learns to interpret these navigational directions, without access to explicit linguistic annotation.", "labels": [], "entities": [{"text": "interpret these navigational directions", "start_pos": 21, "end_pos": 60, "type": "TASK", "confidence": 0.7353689298033714}]}, {"text": "We frame direction following as an apprenticeship learning problem and solve it with a reinforcement learning algorithm, extending previous work on interpreting instructions by.", "labels": [], "entities": []}, {"text": "Our task is to learn a policy, or mapping from world state to action, which most closely follows the reference route.", "labels": [], "entities": []}, {"text": "Our state space combines world and linguistic features, representing both our current position on the map and the communicative content of the utterances we are interpreting.", "labels": [], "entities": []}, {"text": "During training we have access to the reference path, which allows us to measure the utility, or reward, for each step of interpretation.", "labels": [], "entities": []}, {"text": "Using this reward signal as a form of supervision, we learn a policy to maximize the expected reward on unseen examples.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluate our system on the Map Task corpus, splitting the corpus into 96 training dialogs and 32 test dialogs.", "labels": [], "entities": []}, {"text": "The whole corpus consists of approximately 105,000 word tokens.", "labels": [], "entities": []}, {"text": "The maps seen attest time do not occur in the training set, but some of the human participants are present in both.", "labels": [], "entities": []}, {"text": "We evaluate how closely the path P generated by our system follows the expert path P e . We measure this with respect to two metrics: the order in which we visit landmarks and the side we pass them on.", "labels": [], "entities": []}, {"text": "To determine the order P e visits landmarks we compute the minimum distance from P e to each landmark, and threshold it at a fixed value.", "labels": [], "entities": []}, {"text": "To score path P , we compare the order it visits landmarks to the expert path.", "labels": [], "entities": []}, {"text": "A transition l \u2192 l which occurs in P counts as correct if the same transition occurs in P e . Let |P | be the number of landmark transitions in a path P , and N the number of correct transitions in P . We define the order precision as N/|P |, and the order recall as N/|P e |.", "labels": [], "entities": [{"text": "order precision", "start_pos": 216, "end_pos": 231, "type": "METRIC", "confidence": 0.6984918117523193}, {"text": "recall", "start_pos": 257, "end_pos": 263, "type": "METRIC", "confidence": 0.5739889144897461}]}, {"text": "We also evaluate how well we are at passing landmarks on the correct side.", "labels": [], "entities": []}, {"text": "We calculate the distance of P e to each side of the landmark, considering the path to visit aside of the landmark if the distance is below a threshold.", "labels": [], "entities": []}, {"text": "This means that a path might be considered to visit multiple sides of a landmark, although in practice it is usu-: This figure shows the relative weights of spatial features organized by spatial word.", "labels": [], "entities": []}, {"text": "The top row shows the weights of allocentric (landmark-centered) features.", "labels": [], "entities": []}, {"text": "For example, the top left figure shows that when the word above occurs, our policy prefers to go to the north of the target landmark.", "labels": [], "entities": []}, {"text": "The bottom row shows the weights of egocentric (absolute) spatial features.", "labels": [], "entities": []}, {"text": "The bottom left figure shows that given the word above, our policy prefers to move in a southerly cardinal direction.", "labels": [], "entities": []}, {"text": "If C is the number of landmarks we pass on the correct side, define the side precision as C/|P |, and the side recall as C/|P e |.", "labels": [], "entities": [{"text": "precision", "start_pos": 77, "end_pos": 86, "type": "METRIC", "confidence": 0.5011218786239624}, {"text": "recall", "start_pos": 111, "end_pos": 117, "type": "METRIC", "confidence": 0.8161709308624268}]}], "tableCaptions": [{"text": " Table 2: Experimental results. Visit order shows  how well we follow the order in which the answer  path visits landmarks. 'Side' shows how success- fully we pass on the correct side of landmarks.", "labels": [], "entities": []}]}