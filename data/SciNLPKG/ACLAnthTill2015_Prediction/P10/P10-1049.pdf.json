{"title": [{"text": "Training Phrase Translation Models with Leaving-One-Out", "labels": [], "entities": [{"text": "Training Phrase Translation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.6206574042638143}]}], "abstractContent": [{"text": "Several attempts have been made to learn phrase translation probabilities for phrase-based statistical machine translation that go beyond pure counting of phrases in word-aligned training data.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.8065825402736664}, {"text": "phrase-based statistical machine translation", "start_pos": 78, "end_pos": 122, "type": "TASK", "confidence": 0.5681577101349831}]}, {"text": "Most approaches report problems with over-fitting.", "labels": [], "entities": []}, {"text": "We describe a novel leaving-one-out approach to prevent over-fitting that allows us to train phrase models that show improved translation performance on the WMT08 Europarl German-English task.", "labels": [], "entities": [{"text": "WMT08 Europarl German-English task", "start_pos": 157, "end_pos": 191, "type": "DATASET", "confidence": 0.9051056951284409}]}, {"text": "In contrast to most previous work where phrase models were trained separately from other models used in translation , we include all components such as single word lexica and reordering models in training.", "labels": [], "entities": []}, {"text": "Using this consistent training of phrase models we are able to achieve improvements of up to 1.4 points in BLEU.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 107, "end_pos": 111, "type": "METRIC", "confidence": 0.990214467048645}]}, {"text": "As aside effect, the phrase table size is reduced by more than 80%.", "labels": [], "entities": []}], "introductionContent": [{"text": "A phrase-based SMT system takes a source sentence and produces a translation by segmenting the sentence into phrases and translating those phrases separately ().", "labels": [], "entities": [{"text": "SMT", "start_pos": 15, "end_pos": 18, "type": "TASK", "confidence": 0.895571231842041}]}, {"text": "The phrase translation table, which contains the bilingual phrase pairs and the corresponding translation probabilities, is one of the main components of an SMT system.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 4, "end_pos": 22, "type": "TASK", "confidence": 0.790850818157196}, {"text": "SMT", "start_pos": 157, "end_pos": 160, "type": "TASK", "confidence": 0.9945862293243408}]}, {"text": "The most common method for obtaining the phrase table is heuristic extraction from automatically word-aligned bilingual training data ().", "labels": [], "entities": [{"text": "heuristic extraction", "start_pos": 57, "end_pos": 77, "type": "TASK", "confidence": 0.699106365442276}]}, {"text": "In this method, all phrases of the sentence pair that match constraints given by the alignment are extracted.", "labels": [], "entities": []}, {"text": "At extraction time it does not matter, whether the phrases are extracted from a highly probable phrase alignment or from an unlikely one.", "labels": [], "entities": []}, {"text": "Phrase model probabilities are typically defined as relative frequencies of phrases extracted from word-aligned parallel training data.", "labels": [], "entities": []}, {"text": "The joint counts C( \u02dc f , \u02dc e) of the source phrase\u02dcfphrase\u02dc phrase\u02dcf and the target phrase\u02dcephrase\u02dc phrase\u02dce in the entire training data are normalized by the marginal counts of source and target phrase to obtain a conditional probability pH ( \u02dc f |\u02dce|\u02dce) = C( \u02dc f , \u02dc e) C(\u02dc e) . The translation process is implemented as a weighted log-linear combination of several models h m (e I 1 , s K 1 , f J 1 ) including the logarithm of the phrase probability in source-to-target as well as in target-to-source direction.", "labels": [], "entities": []}, {"text": "The phrase model is combined with a language model, word lexicon models, word and phrase penalty, and many others.", "labels": [], "entities": []}, {"text": "() The best translation\u00ea\u02c6Itranslation\u02c6translation\u00ea translation\u00ea\u02c6 translation\u00ea\u02c6I 1 as defined by the models then can be written as\u00ea\u02c6I as\u02c6as\u00ea as\u00ea\u02c6 as\u00ea\u02c6I 1 = argmax In this work, we propose to directly train our phrase models by applying a forced alignment procedure where we use the decoder to find a phrase alignment between source and target sentences of the training data and then updating phrase translation probabilities based on this alignment.", "labels": [], "entities": [{"text": "argmax", "start_pos": 155, "end_pos": 161, "type": "METRIC", "confidence": 0.9764259457588196}, {"text": "phrase translation", "start_pos": 391, "end_pos": 409, "type": "TASK", "confidence": 0.6932538151741028}]}, {"text": "In contrast to heuristic extraction, the proposed method provides away of consistently training and using phrase models in translation.", "labels": [], "entities": [{"text": "heuristic extraction", "start_pos": 15, "end_pos": 35, "type": "TASK", "confidence": 0.7696624994277954}]}, {"text": "We use a modified version of a phrase-based decoder to perform the forced alignment.", "labels": [], "entities": []}, {"text": "This way we ensure that all models used in training are identical to the ones used at decoding time.", "labels": [], "entities": []}, {"text": "An illustration of the basic idea can be seen in.", "labels": [], "entities": []}, {"text": "In the literature this method by itself has been shown to be problematic because it suffers from over-fitting (), ().", "labels": [], "entities": []}, {"text": "Since our initial phrases are extracted from the same training data, that we want to align, very long phrases can be found for segmentation.", "labels": [], "entities": []}, {"text": "As these long phrases tend to occur in only a few training sentences, the EM algorithm generally overestimates their probability and neglects shorter phrases, which better generalize to unseen data and thus are more useful for translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 227, "end_pos": 238, "type": "TASK", "confidence": 0.9769173860549927}]}, {"text": "In order to counteract these effects, our training procedure applies leaving-one-out on the sentence level.", "labels": [], "entities": []}, {"text": "Our results show, that this leads to a better translation quality.", "labels": [], "entities": [{"text": "translation", "start_pos": 46, "end_pos": 57, "type": "TASK", "confidence": 0.96624356508255}]}, {"text": "Ideally, we would produce all possible segmentations and alignments during training.", "labels": [], "entities": [{"text": "segmentations and alignments", "start_pos": 39, "end_pos": 67, "type": "TASK", "confidence": 0.7929837107658386}]}, {"text": "However, this has been shown to be infeasible for real-world data . As training uses a modified version of the translation decoder, it is straightforward to apply pruning as in regular decoding.", "labels": [], "entities": []}, {"text": "Additionally, we consider three ways of approximating the full search space: 1.", "labels": [], "entities": []}, {"text": "the single-best Viterbi alignment, 2.", "labels": [], "entities": [{"text": "Viterbi alignment", "start_pos": 16, "end_pos": 33, "type": "DATASET", "confidence": 0.8626633882522583}]}, {"text": "the n-best alignments, 3.", "labels": [], "entities": []}, {"text": "all alignments remaining in the search space after pruning.", "labels": [], "entities": []}, {"text": "The performance of the different approaches is measured and compared on the German-English Europarl task from the ACL 2008 Workshop on Statistical Machine Translation (WMT08).", "labels": [], "entities": [{"text": "German-English Europarl task from the ACL 2008 Workshop on", "start_pos": 76, "end_pos": 134, "type": "DATASET", "confidence": 0.851968550019794}, {"text": "Statistical Machine Translation (WMT08)", "start_pos": 135, "end_pos": 174, "type": "TASK", "confidence": 0.7909022072950999}]}, {"text": "Our results show that the proposed phrase model training improves translation quality on the test set by 0.9 BLEU points over our baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 109, "end_pos": 113, "type": "METRIC", "confidence": 0.9990140199661255}]}, {"text": "We find that by interpolation with the heuristically extracted phrases translation performance can reach up to 1.4 BLEU improvement over the baseline on the test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 115, "end_pos": 119, "type": "METRIC", "confidence": 0.9995399713516235}]}, {"text": "After reviewing the related work in the following section, we give a detailed description of phrasal alignment and leaving-one-out in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 explains the estimation of phrase models.", "labels": [], "entities": [{"text": "estimation", "start_pos": 23, "end_pos": 33, "type": "TASK", "confidence": 0.9600943922996521}]}, {"text": "The empirical evaluation of the different approaches is done in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted our experiments on the GermanEnglish data published for the ACL 2008 Workshop on Statistical Machine Translation (WMT08).", "labels": [], "entities": [{"text": "GermanEnglish data published for the ACL 2008 Workshop on", "start_pos": 36, "end_pos": 93, "type": "DATASET", "confidence": 0.9423298438390096}, {"text": "Statistical Machine Translation (WMT08)", "start_pos": 94, "end_pos": 133, "type": "TASK", "confidence": 0.8413193225860596}]}, {"text": "Statistics for the Europarl data are given in.", "labels": [], "entities": [{"text": "Europarl data", "start_pos": 19, "end_pos": 32, "type": "DATASET", "confidence": 0.9960871636867523}]}, {"text": "We are given the three data sets T RAIN , DEV and T EST . For the heuristic phrase model, we first use GIZA++ to compute the word alignment on T RAIN . Next we obtain a phrase table by extraction of phrases from the word alignment.", "labels": [], "entities": [{"text": "T EST", "start_pos": 50, "end_pos": 55, "type": "METRIC", "confidence": 0.6940911114215851}, {"text": "GIZA", "start_pos": 103, "end_pos": 107, "type": "METRIC", "confidence": 0.8530237078666687}]}, {"text": "The scaling factors of the translation models have been optimized for BLEU on the DEV data.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 70, "end_pos": 74, "type": "METRIC", "confidence": 0.9963409304618835}, {"text": "DEV data", "start_pos": 82, "end_pos": 90, "type": "DATASET", "confidence": 0.9783567488193512}]}, {"text": "The phrase table obtained by heuristic extraction is also used to initialize the training.", "labels": [], "entities": [{"text": "heuristic extraction", "start_pos": 29, "end_pos": 49, "type": "TASK", "confidence": 0.695062980055809}]}, {"text": "The forced alignment is run on the training data T RAIN from which we obtain the phrase alignments.", "labels": [], "entities": [{"text": "T RAIN", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.7378863394260406}]}, {"text": "Those are used to build a phrase table according to the proposed generative phrase models.", "labels": [], "entities": []}, {"text": "Afterward, the scaling factors are trained on DEV for the new phrase table.", "labels": [], "entities": [{"text": "DEV", "start_pos": 46, "end_pos": 49, "type": "DATASET", "confidence": 0.9088435769081116}]}, {"text": "By feeding back the new phrase table into forced alignment we can reiterate the training procedure.", "labels": [], "entities": []}, {"text": "When training is finished the resulting phrase model is evaluated on DEV and T EST . Additionally, we can apply smoothing by interpolation of the new phrase table with the original one estimated heuristically, retrain the scaling factors and evaluate afterwards.", "labels": [], "entities": [{"text": "DEV", "start_pos": 69, "end_pos": 72, "type": "DATASET", "confidence": 0.7914880514144897}, {"text": "T EST", "start_pos": 77, "end_pos": 82, "type": "METRIC", "confidence": 0.853420078754425}]}, {"text": "The baseline system is a standard phrase-based SMT system with eight features: phrase translation and word lexicon probabilities in both translation directions, phrase penalty, word penalty, language model score and a simple distance-based reordering model.", "labels": [], "entities": [{"text": "SMT", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.8877267837524414}, {"text": "phrase translation", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.7518441677093506}]}, {"text": "The features are combined in a log-linear way.", "labels": [], "entities": []}, {"text": "To investigate the generative models, we replace the two phrase translation probabilities and keep the other features identical to the baseline.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 57, "end_pos": 75, "type": "TASK", "confidence": 0.7149779498577118}]}, {"text": "For the feature-wise combination the two generative phrase probabilities are added to the features, resulting in a total of 10 features.", "labels": [], "entities": []}, {"text": "We used a 4-gram language model with modified Kneser-Ney discounting for all experiments.", "labels": [], "entities": []}, {"text": "The metrics used for evaluation are the case-sensitive BLEU () score and the translation edit rate (TER)) with one reference translation.", "labels": [], "entities": [{"text": "BLEU () score", "start_pos": 55, "end_pos": 68, "type": "METRIC", "confidence": 0.9015535712242126}, {"text": "translation edit rate (TER))", "start_pos": 77, "end_pos": 105, "type": "METRIC", "confidence": 0.8454248358805975}]}], "tableCaptions": [{"text": " Table 2: Statistics for the Europarl German- English data", "labels": [], "entities": [{"text": "Europarl German- English data", "start_pos": 29, "end_pos": 58, "type": "DATASET", "confidence": 0.9487025618553162}]}, {"text": " Table 3: Comparison of different training setups  for the count model on DEV .", "labels": [], "entities": [{"text": "DEV", "start_pos": 74, "end_pos": 77, "type": "DATASET", "confidence": 0.9694705009460449}]}, {"text": " Table 4: Phrase table size of the count model for  different n-best list sizes, the full model and for  heuristic phrase extraction.", "labels": [], "entities": [{"text": "Phrase table size", "start_pos": 10, "end_pos": 27, "type": "METRIC", "confidence": 0.8619420131047567}, {"text": "phrase extraction", "start_pos": 115, "end_pos": 132, "type": "TASK", "confidence": 0.7277383804321289}]}]}