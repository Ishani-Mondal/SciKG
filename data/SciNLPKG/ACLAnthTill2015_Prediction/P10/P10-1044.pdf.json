{"title": [{"text": "A Latent Dirichlet Allocation method for Selectional Preferences", "labels": [], "entities": [{"text": "Selectional Preferences", "start_pos": 41, "end_pos": 64, "type": "TASK", "confidence": 0.9537730813026428}]}], "abstractContent": [{"text": "The computation of selectional preferences , the admissible argument values fora relation, is a well-known NLP task with broad applicability.", "labels": [], "entities": []}, {"text": "We present LDA-SP, which utilizes LinkLDA (Erosheva et al., 2004) to model selectional preferences.", "labels": [], "entities": []}, {"text": "By simultaneously inferring latent topics and topic distributions over relations, LDA-SP combines the benefits of previous approaches: like traditional class-based approaches, it produces human-interpretable classes describing each re-lation's preferences, but it is competitive with non-class-based methods in predic-tive power.", "labels": [], "entities": []}, {"text": "We compare LDA-SP to several state-of-the-art methods achieving an 85% increase in recall at 0.9 precision over mutual information (Erk, 2007).", "labels": [], "entities": [{"text": "recall", "start_pos": 83, "end_pos": 89, "type": "METRIC", "confidence": 0.9983041286468506}, {"text": "precision", "start_pos": 97, "end_pos": 106, "type": "METRIC", "confidence": 0.9853396415710449}]}, {"text": "We also evaluate LDA-SP's effectiveness at filtering improper applications of inference rules, where we show substantial improvement over Pantel et al.'s system (Pantel et al., 2007).", "labels": [], "entities": []}], "introductionContent": [{"text": "Selectional Preferences encode the set of admissible argument values fora relation.", "labels": [], "entities": []}, {"text": "For example, locations are likely to appear in the second argument of the relation X is headquartered in Y and companies or organizations in the first.", "labels": [], "entities": []}, {"text": "A large, high-quality database of preferences has the potential to improve the performance of a wide range of NLP tasks including semantic role labeling (), pronoun resolution (, textual inference (, word-sense disambiguation, and many more.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 130, "end_pos": 152, "type": "TASK", "confidence": 0.6681181589762369}, {"text": "pronoun resolution", "start_pos": 157, "end_pos": 175, "type": "TASK", "confidence": 0.777715265750885}, {"text": "word-sense disambiguation", "start_pos": 200, "end_pos": 225, "type": "TASK", "confidence": 0.7450245916843414}]}, {"text": "Therefore, much attention has been focused on automatically computing them based on a corpus of relation instances.", "labels": [], "entities": []}, {"text": "presented the earliest work in this area, describing an information-theoretic approach that inferred selectional preferences based on the WordNet hypernym hierarchy.", "labels": [], "entities": [{"text": "WordNet hypernym hierarchy", "start_pos": 138, "end_pos": 164, "type": "DATASET", "confidence": 0.8981502254803976}]}, {"text": "Recent work) has moved away from generalization to known classes, instead utilizing distributional similarity between nouns to generalize beyond observed relation-argument pairs.", "labels": [], "entities": []}, {"text": "This avoids problems like WordNet's poor coverage of proper nouns and is shown to improve performance.", "labels": [], "entities": []}, {"text": "These methods, however, no longer produce the generalized class for an argument.", "labels": [], "entities": []}, {"text": "In this paper we describe a novel approach to computing selectional preferences by making use of unsupervised topic models.", "labels": [], "entities": []}, {"text": "Our approach is able to combine benefits of both kinds of methods: it retains the generalization and humaninterpretability of class-based approaches and is also competitive with the direct methods on predictive tasks.", "labels": [], "entities": []}, {"text": "Unsupervised topic models, such as latent Dirichlet allocation (LDA) ( and its variants are characterized by a set of hidden topics, which represent the underlying semantic structure of a document collection.", "labels": [], "entities": [{"text": "latent Dirichlet allocation (LDA)", "start_pos": 35, "end_pos": 68, "type": "TASK", "confidence": 0.6631970802942911}]}, {"text": "For our problem these topics offer an intuitive interpretationthey represent the (latent) set of classes that store the preferences for the different relations.", "labels": [], "entities": []}, {"text": "Thus, topic models area natural fit for modeling our relation data.", "labels": [], "entities": []}, {"text": "In particular, our system, called LDA-SP, uses LinkLDA (), an extension of LDA that simultaneously models two sets of distributions for each topic.", "labels": [], "entities": []}, {"text": "These two sets represent the two arguments for the relations.", "labels": [], "entities": []}, {"text": "Thus, LDA-SP is able to capture information about the pairs of topics that commonly co-occur.", "labels": [], "entities": []}, {"text": "This information is very helpful in guiding inference.", "labels": [], "entities": []}, {"text": "We run LDA-SP to compute preferences on a massive dataset of binary relations r(a 1 , a 2 ) ex-tracted from the Web by TEXTRUNNER (.", "labels": [], "entities": [{"text": "TEXTRUNNER", "start_pos": 119, "end_pos": 129, "type": "METRIC", "confidence": 0.6930294632911682}]}, {"text": "Our experiments demonstrate that LDA-SP significantly outperforms state of the art approaches obtaining an 85% increase in recall at precision 0.9 on the standard pseudodisambiguation task.", "labels": [], "entities": [{"text": "LDA-SP", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.7328848838806152}, {"text": "recall", "start_pos": 123, "end_pos": 129, "type": "METRIC", "confidence": 0.9950577020645142}, {"text": "precision", "start_pos": 133, "end_pos": 142, "type": "METRIC", "confidence": 0.9463208317756653}]}, {"text": "Additionally, because LDA-SP is based on a formal probabilistic model, it has the advantage that it can naturally be applied in many scenarios.", "labels": [], "entities": []}, {"text": "For example, we can obtain a better understanding of similar relations, filter out incorrect inferences based on querying our model (Section 4.3), as well as produce a repository of class-based preferences with a little manual effort as demonstrated in Section 4.4.", "labels": [], "entities": []}, {"text": "In all these cases we obtain high quality results, for example, massively outperforming Pantel et al.'s approach in the textual inference task.", "labels": [], "entities": []}], "datasetContent": [{"text": "We perform three main experiments to assess the quality of the preferences obtained using topic models.", "labels": [], "entities": []}, {"text": "The first is a task-independent evaluation using a pseudo-disambiguation experiment (Section 4.2), which is a standard way to evaluate the quality of selectional preferences ().", "labels": [], "entities": []}, {"text": "We use this experiment to compare the various topic models as well as the best model with the known state of the art approaches to selectional preferences.", "labels": [], "entities": []}, {"text": "Secondly, we show significant improvements to performance at an end-task of textual inference in Section 4.3.", "labels": [], "entities": []}, {"text": "Finally, we report on the quality of a large database of Wordnet-based preferences obtained after manually associating our topics with Wordnet classes (Section 4.4).", "labels": [], "entities": []}, {"text": "We first compare the three LDA-based approaches to each other and two state of the art similarity based systems) (using mutual information and Jaccard similarity respectively).", "labels": [], "entities": [{"text": "Jaccard similarity", "start_pos": 143, "end_pos": 161, "type": "METRIC", "confidence": 0.8348666727542877}]}, {"text": "These similarity measures were shown to outperform the generative model of, as well as class-based methods such as Resnik's.", "labels": [], "entities": []}, {"text": "In this pseudo-disambiguation experiment an observed tuple is paired with a pseudo-negative, which has both arguments randomly generated from the whole vocabulary (according to the corpus-wide distribution over arguments).", "labels": [], "entities": []}, {"text": "The task is, for each relation-argument pair, to determine whether it is observed, or a random distractor.", "labels": [], "entities": []}, {"text": "We now evaluate LDA-SP's ability to improve performance at an end-task.", "labels": [], "entities": []}, {"text": "We choose the task of improving textual entailment by learning selectional preferences for inference rules and filtering inferences that do not respect these.", "labels": [], "entities": [{"text": "textual entailment", "start_pos": 32, "end_pos": 50, "type": "TASK", "confidence": 0.7374361753463745}]}, {"text": "This application of selectional preferences was introduced by.", "labels": [], "entities": []}, {"text": "For now we stick to inference rules of the form r 1 (a 1 , a 2 ) \u21d2 r 2 (a 1 , a 2 ), though our ideas are more generally applicable to more complex rules.", "labels": [], "entities": []}, {"text": "As an example, the rule (X defeats Y) \u21d2 (X plays Y) holds when X and Y are both sports teams, however fails to produce a reasonable inference if X and Y are Britain and Nazi Germany respectively.", "labels": [], "entities": []}, {"text": "In order to evaluate LDA-SP's ability to filter inferences based on selectional preferences we need a set of inference rules between the relations in our corpus.", "labels": [], "entities": []}, {"text": "We therefore mapped the DIRT Inference rules), (which consist of pairs of dependency paths) to TEXTRUN-NER relations as follows.", "labels": [], "entities": [{"text": "TEXTRUN-NER", "start_pos": 95, "end_pos": 106, "type": "METRIC", "confidence": 0.8076529502868652}]}, {"text": "We first gathered all instances in the generalization corpus, and for each r(a 1 , a 2 ) created a corresponding simple sentence by concatenating the arguments with the relation string between them.", "labels": [], "entities": []}, {"text": "Each such simple sentence was parsed using Minipar.", "labels": [], "entities": [{"text": "Minipar", "start_pos": 43, "end_pos": 50, "type": "DATASET", "confidence": 0.9542115330696106}]}, {"text": "From the parses we extracted all dependency paths between nouns that contain only words present in the TEXTRUNNER relation string.", "labels": [], "entities": [{"text": "TEXTRUNNER", "start_pos": 103, "end_pos": 113, "type": "METRIC", "confidence": 0.858779788017273}]}, {"text": "These dependency paths were then matched against each pair in the DIRT database, and all pairs of associated relations were collected producing about 26,000 inference rules.", "labels": [], "entities": [{"text": "DIRT database", "start_pos": 66, "end_pos": 79, "type": "DATASET", "confidence": 0.9328630864620209}]}, {"text": "Following we randomly sampled 100 inference rules.", "labels": [], "entities": []}, {"text": "We then automatically filtered out any rules which contained a negation, or for which the antecedent and consequent contained a pair of antonyms found in WordNet (this left us with 85 rules).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 154, "end_pos": 161, "type": "DATASET", "confidence": 0.9650063514709473}]}, {"text": "For each rule we collected 10 random instances of the antecedent, and generated the consequent.", "labels": [], "entities": []}, {"text": "We randomly sampled 300 of these inferences to hand-label.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Top 10 and Bottom 10 ranked inference  rules ranked by LDA-SPafter automatically filter- ing out negations and antonyms (using WordNet).", "labels": [], "entities": [{"text": "WordNet", "start_pos": 137, "end_pos": 144, "type": "DATASET", "confidence": 0.957666277885437}]}]}