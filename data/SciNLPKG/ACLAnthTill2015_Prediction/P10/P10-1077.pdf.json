{"title": [{"text": "Fine-grained Genre Classification using Structural Learning Algorithms", "labels": [], "entities": [{"text": "Genre Classification", "start_pos": 13, "end_pos": 33, "type": "TASK", "confidence": 0.7793641090393066}]}], "abstractContent": [{"text": "Prior use of machine learning in genre classification used a list of labels as classification categories.", "labels": [], "entities": [{"text": "genre classification", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.7708918452262878}]}, {"text": "However, genre classes are often organised into hierarchies , e.g., covering the subgenres of fiction.", "labels": [], "entities": []}, {"text": "In this paper we present a method of using the hierarchy of labels to improve the classification accuracy.", "labels": [], "entities": [{"text": "classification", "start_pos": 82, "end_pos": 96, "type": "TASK", "confidence": 0.9426743984222412}, {"text": "accuracy", "start_pos": 97, "end_pos": 105, "type": "METRIC", "confidence": 0.9639589786529541}]}, {"text": "As a testbed for this approach we use the Brown Corpus as well as a range of other corpora, including the BNC, HGC and Syracuse.", "labels": [], "entities": [{"text": "Brown Corpus", "start_pos": 42, "end_pos": 54, "type": "DATASET", "confidence": 0.9897643625736237}, {"text": "BNC", "start_pos": 106, "end_pos": 109, "type": "DATASET", "confidence": 0.9844931364059448}, {"text": "HGC", "start_pos": 111, "end_pos": 114, "type": "DATASET", "confidence": 0.8611717820167542}, {"text": "Syracuse", "start_pos": 119, "end_pos": 127, "type": "DATASET", "confidence": 0.9516647458076477}]}, {"text": "The results are not encouraging: apart from the Brown corpus, the improvements of our structural classifier over the flat one are not statistically significant.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 48, "end_pos": 60, "type": "DATASET", "confidence": 0.9297568500041962}]}, {"text": "We discuss the relation between structural learning performance and the visual and distributional balance of the label hierarchy, suggesting that only balanced hierarchies might profit from structural learning.", "labels": [], "entities": []}], "introductionContent": [{"text": "Automatic genre identification (AGI) can be traced to the mid-1990s), but this research became much more active in recent years, partly because of the explosive growth of the Web, and partly because of the importance of making genre distinctions in NLP applications.", "labels": [], "entities": [{"text": "Automatic genre identification (AGI)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.8074599355459213}]}, {"text": "In Information Retrieval, given the large number of web pages on any given topic, it is often difficult for the users to find relevant pages that are in the right genre.", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 3, "end_pos": 24, "type": "TASK", "confidence": 0.7507602274417877}]}, {"text": "As for other applications, the accuracy of many tasks, such as machine translation, POS tagging ( or identification of discourse relations relies of defining the language model suitable for the genre of a given text.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9978501796722412}, {"text": "machine translation", "start_pos": 63, "end_pos": 82, "type": "TASK", "confidence": 0.7869484126567841}, {"text": "POS tagging", "start_pos": 84, "end_pos": 95, "type": "TASK", "confidence": 0.8962071537971497}, {"text": "identification of discourse relations", "start_pos": 101, "end_pos": 138, "type": "TASK", "confidence": 0.8662271648645401}]}, {"text": "For example, the accuracy of POS tagging reaching 96.9% on newspaper texts drops down to 85.7% on forums, i.e., every seventh word in forums is tagged incorrectly.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9995929598808289}, {"text": "POS tagging", "start_pos": 29, "end_pos": 40, "type": "TASK", "confidence": 0.7746264636516571}]}, {"text": "This interest in genres resulted in a proliferation of studies on corpus development of web genres and comparison of methods for AGI.", "labels": [], "entities": []}, {"text": "The two corpora commonly used for this task are KI-04 (Meyer zu) and Santinis.", "labels": [], "entities": []}, {"text": "The best results reported for these corpora (with 10-fold cross-validation) reach 84.1% on KI-04 and 96.5% accuracy on Santinis ().", "labels": [], "entities": [{"text": "KI-04", "start_pos": 91, "end_pos": 96, "type": "DATASET", "confidence": 0.8598983883857727}, {"text": "accuracy", "start_pos": 107, "end_pos": 115, "type": "METRIC", "confidence": 0.9993497729301453}]}, {"text": "In our research ( we produced even better results on these two benchmarks (85.8% and 97.1%, respectively).", "labels": [], "entities": []}, {"text": "However, this impressive accuracy is not realistic in vivo, i.e., in classifying web pages retrieved as a result of actual queries.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9990608096122742}, {"text": "classifying web pages retrieved as a result of actual queries", "start_pos": 69, "end_pos": 130, "type": "TASK", "confidence": 0.7904314756393432}]}, {"text": "One reason comes from the limited number of genres present in these two collections (eight genres in KI-04 and seven in Santinis).", "labels": [], "entities": [{"text": "KI-04", "start_pos": 101, "end_pos": 106, "type": "DATASET", "confidence": 0.8694531917572021}]}, {"text": "As an example, only front pages of online newspapers are listed in Santinis, but not actual newspaper articles, so once an article is retrieved, it cannot be assigned to any class at all.", "labels": [], "entities": []}, {"text": "Another reason why the high accuracy is not useful concerns the limited number of sources in each collection, e.g., all FAQs in Santinis come from either a website with FAQs on hurricanes or another one with tax advice.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9989731311798096}]}, {"text": "In the end, a classifier built for FAQs on this training data relies on a high topic-genre correlation in this particular collection and fails to spot any other FAQs.", "labels": [], "entities": []}, {"text": "There are other corpora, which are more diverse in the range of their genres, such as the fifteen genres of the Brown Corpus () or the seventy genres of the BNC, but because of the number of genres in them and the diversity of documents within each genre, the accuracy of prior work on these collections is much less impressive.", "labels": [], "entities": [{"text": "Brown Corpus", "start_pos": 112, "end_pos": 124, "type": "DATASET", "confidence": 0.9878141283988953}, {"text": "BNC", "start_pos": 157, "end_pos": 160, "type": "DATASET", "confidence": 0.9105400443077087}, {"text": "accuracy", "start_pos": 260, "end_pos": 268, "type": "METRIC", "confidence": 0.9972066283226013}]}, {"text": "For example, using linear discriminant analysis achieve an accuracy of 52% without us-ing cross-validation (the entire Brown Corpus was used as both the test set and training set), with the accuracy improving to 65% when the 15 genres are collapsed into 10, and to 73% with only 4 genres ().", "labels": [], "entities": [{"text": "accuracy", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.9992423057556152}, {"text": "Brown Corpus", "start_pos": 119, "end_pos": 131, "type": "DATASET", "confidence": 0.9827836751937866}, {"text": "accuracy", "start_pos": 190, "end_pos": 198, "type": "METRIC", "confidence": 0.9992769360542297}]}, {"text": "This result suggests the importance of the hierarchy of genres.", "labels": [], "entities": []}, {"text": "Firstly, making a decision on higher levels might be easier than on lower levels (fiction or non-fiction rather than science fiction or mystery).", "labels": [], "entities": []}, {"text": "Secondly, we might be able to improve the accuracy on lower levels, by taking into account the relevant position of each node in the hierarchy (distinguishing between reportage or editorial becomes easier when we know they are safely under the category of press).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9992572665214539}]}, {"text": "This paper explores away of using information on the hierarchy of labels for improving fine-grained genre classification.", "labels": [], "entities": [{"text": "fine-grained genre classification", "start_pos": 87, "end_pos": 120, "type": "TASK", "confidence": 0.6361040572325388}]}, {"text": "To the best of our knowledge, this is the first work presenting structural genre classification and distance measures for genres.", "labels": [], "entities": [{"text": "structural genre classification", "start_pos": 64, "end_pos": 95, "type": "TASK", "confidence": 0.6987773577372233}]}, {"text": "In Section 2 we present a structural reformulation of Support Vector Machines (SVMs) that can take similarities between different genres into account.", "labels": [], "entities": []}, {"text": "This formulation necessitates the development of distance measures between different genres in a hierarchy, of which we present three different types in Section 3, along with possible estimation procedures for these distances.", "labels": [], "entities": []}, {"text": "We present experiments with these novel structural SVMs and distance measures on three different corpora in Section 4.", "labels": [], "entities": []}, {"text": "Our experiments show that structural SVMs can outperform the non-structural standard.", "labels": [], "entities": [{"text": "SVMs", "start_pos": 37, "end_pos": 41, "type": "TASK", "confidence": 0.8871484398841858}]}, {"text": "However, the improvement is only statistically significant on the Brown corpus.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 66, "end_pos": 78, "type": "DATASET", "confidence": 0.9819529354572296}]}, {"text": "In Section 5 we investigate potential reasons for this, including the (im)balance of different genre hierarchies and problems with our distance measures.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use four genre-annotated corpora for genre classification: the Brown Corpus (, BNC), HGC (Stubbe and Ringlstetter, 2007) and Syracuse ().", "labels": [], "entities": [{"text": "genre classification", "start_pos": 40, "end_pos": 60, "type": "TASK", "confidence": 0.765433669090271}, {"text": "Brown Corpus (, BNC)", "start_pos": 66, "end_pos": 86, "type": "DATASET", "confidence": 0.8779497146606445}, {"text": "HGC (Stubbe and Ringlstetter, 2007)", "start_pos": 88, "end_pos": 123, "type": "DATASET", "confidence": 0.8279721513390541}, {"text": "Syracuse", "start_pos": 128, "end_pos": 136, "type": "DATASET", "confidence": 0.9305319786071777}]}, {"text": "They have a wide variety of genre labels (from 15 in the Brown corpus to 32 genres in HGC to 70 in the BNC to 292 in Syracuse), and different types of hierarchies.", "labels": [], "entities": [{"text": "Brown corpus", "start_pos": 57, "end_pos": 69, "type": "DATASET", "confidence": 0.9322254061698914}, {"text": "HGC", "start_pos": 86, "end_pos": 89, "type": "DATASET", "confidence": 0.9243768453598022}, {"text": "BNC", "start_pos": 103, "end_pos": 106, "type": "DATASET", "confidence": 0.9497658014297485}, {"text": "Syracuse", "start_pos": 117, "end_pos": 125, "type": "DATASET", "confidence": 0.7069716453552246}]}, {"text": "We use standard classification accuracy (Acc) on the most fine-grained level of target categories in the genre hierarchy.", "labels": [], "entities": [{"text": "accuracy (Acc)", "start_pos": 31, "end_pos": 45, "type": "METRIC", "confidence": 0.8367789089679718}]}, {"text": "In addition, given a structural distance H, misclassifications can be weighted based on the distance measure.", "labels": [], "entities": []}, {"text": "This allows us to penalize incorrect predictions which are further away in the hierarchy (such as between government documents and westerns) more than \"close\" mismatches (such as between science fiction and westerns).", "labels": [], "entities": []}, {"text": "Formally, given the classification confusion matrix M then each M ab fora = b contains the number of class a documents that are misclassified into class b.", "labels": [], "entities": [{"text": "classification confusion", "start_pos": 20, "end_pos": 44, "type": "TASK", "confidence": 0.9104180932044983}]}, {"text": "To achieve proper normalization in giving weights to misclassified entries, we can redistribute a total weight k \u2212 1 to each row of H proportionally to its values, where k is the number of genres.", "labels": [], "entities": []}, {"text": "That is, given g the row summation of H, we define a weight matrix Q by normalizing the rows of H in away given by Q ab = (k \u2212 1)h ab /g a , a = b.", "labels": [], "entities": []}, {"text": "We further assign a unit value to the diagonal of Q.", "labels": [], "entities": []}, {"text": "Then it is possible to construct a structurally-aware measure (S-Acc):  We compare structural SVMs using all path-based and information-content based measures (see also Section 3.3).", "labels": [], "entities": []}, {"text": "As a baseline we use the accuracy achieved by a standard \"flat\" SVM.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9995918869972229}]}, {"text": "We use 10-fold (randomised) cross validation throughout.", "labels": [], "entities": []}, {"text": "In each fold, for each genre class 10% of documents are used for testing.", "labels": [], "entities": []}, {"text": "For the remaining 90%, a portion of 10% are sampled for parameter tuning, leaving 80% for training.", "labels": [], "entities": [{"text": "parameter tuning", "start_pos": 56, "end_pos": 72, "type": "TASK", "confidence": 0.7464830279350281}]}, {"text": "In each round the validation set is used to help determine the best C associated with Equation based on the validation accuracy from the candidate list 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.", "labels": [], "entities": [{"text": "Equation", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.7212836742401123}, {"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.7453765273094177}]}, {"text": "Note via this experiment setup, all methods are tuned to their best performance.", "labels": [], "entities": []}, {"text": "For any algorithm comparison, we use a McNemar test with the significance level of 5% as recommended by).", "labels": [], "entities": [{"text": "significance level", "start_pos": 61, "end_pos": 79, "type": "METRIC", "confidence": 0.9810068905353546}]}], "tableCaptions": [{"text": " Table 1: Brown 10-genre Classification Results.  Method  Accuracy  Karlgren and Cutting, 1994 65 (Training)  Flat SVM  64.40  SSVM(IC-lin-word-bnc)  68.80  SSVM(IC-lin-word-br)  68.60  SSVM(IC-lin-gram-br)  67.80", "labels": [], "entities": []}, {"text": " Table 2: Structural Accuracy on Brown 15-genre Classification.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 21, "end_pos": 29, "type": "METRIC", "confidence": 0.792740523815155}, {"text": "Brown 15-genre Classification", "start_pos": 33, "end_pos": 62, "type": "DATASET", "confidence": 0.9082851409912109}]}, {"text": " Table 3: Tree Balance Scores", "labels": [], "entities": [{"text": "Tree Balance", "start_pos": 10, "end_pos": 22, "type": "TASK", "confidence": 0.6623194068670273}]}]}