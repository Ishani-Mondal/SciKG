{"title": [{"text": "BabelNet: Building a Very Large Multilingual Semantic Network", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper we present BabelNet-a very large, wide-coverage multilingual semantic network.", "labels": [], "entities": []}, {"text": "The resource is automatically constructed by means of a methodology that integrates lexicographic and en-cyclopedic knowledge from WordNet and Wikipedia.", "labels": [], "entities": []}, {"text": "In addition Machine Translation is also applied to enrich the resource with lexical information for all languages.", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.8355058133602142}]}, {"text": "We conduct experiments on new and existing gold-standard datasets to show the high quality and coverage of the resource.", "labels": [], "entities": []}], "introductionContent": [{"text": "In many research areas of Natural Language Processing (NLP) lexical knowledge is exploited to perform tasks effectively.", "labels": [], "entities": [{"text": "Natural Language Processing (NLP) lexical knowledge", "start_pos": 26, "end_pos": 77, "type": "TASK", "confidence": 0.7504019215703011}]}, {"text": "These include, among others, text summarization, Named Entity Recognition (), Question Answering () and text categorization ().", "labels": [], "entities": [{"text": "text summarization", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.762936532497406}, {"text": "Named Entity Recognition", "start_pos": 49, "end_pos": 73, "type": "TASK", "confidence": 0.588164339462916}, {"text": "Question Answering", "start_pos": 78, "end_pos": 96, "type": "TASK", "confidence": 0.8364591896533966}]}, {"text": "Recent studies in the difficult task of Word Sense Disambiguation, WSD) have shown the impact of the amount and quality of lexical knowledge (Cuadros and): richer knowledge sources can be of great benefit to both knowledge-lean systems and supervised classifiers ().", "labels": [], "entities": [{"text": "Word Sense Disambiguation, WSD)", "start_pos": 40, "end_pos": 71, "type": "TASK", "confidence": 0.7483215580383936}]}, {"text": "Various projects have been undertaken to make lexical knowledge available in a machine readable format.", "labels": [], "entities": []}, {"text": "A pioneering endeavor was WordNet, a computational lexicon of English based on psycholinguistic theories.", "labels": [], "entities": []}, {"text": "Subsequent projects have also tackled the significant problem of multilinguality.", "labels": [], "entities": []}, {"text": "These include EuroWordNet,), the Multilingual Central Repository (), and many others.", "labels": [], "entities": [{"text": "EuroWordNet", "start_pos": 14, "end_pos": 25, "type": "DATASET", "confidence": 0.9895079135894775}]}, {"text": "However, manual construction methods inherently suffer from a number of drawbacks.", "labels": [], "entities": []}, {"text": "First, maintaining and updating lexical knowledge resources is expensive and time-consuming.", "labels": [], "entities": []}, {"text": "Second, such resources are typically lexicographic, and thus contain mainly concepts and only a few named entities.", "labels": [], "entities": []}, {"text": "Third, resources for non-English languages often have a much poorer coverage since the construction effort must be repeated for every language of interest.", "labels": [], "entities": [{"text": "coverage", "start_pos": 68, "end_pos": 76, "type": "METRIC", "confidence": 0.9637966156005859}]}, {"text": "As a result, an obvious bias exists towards conducting research in resource-rich languages, such as English.", "labels": [], "entities": []}, {"text": "A solution to these issues is to draw upon a large-scale collaborative resource, namely Wikipedia 1 . Wikipedia represents the perfect complement to WordNet, as it provides multilingual lexical knowledge of a mostly encyclopedic nature.", "labels": [], "entities": []}, {"text": "While the contribution of any individual user might be imprecise or inaccurate, the continual intervention of expert contributors in all domains results in a resource of the highest quality (.", "labels": [], "entities": []}, {"text": "But while a great deal of work has been recently devoted to the automatic extraction of structured information from Wikipedia (, inter alia), the knowledge extracted is organized in a looser way than in a computational lexicon such as WordNet.", "labels": [], "entities": [{"text": "automatic extraction of structured information from Wikipedia", "start_pos": 64, "end_pos": 125, "type": "TASK", "confidence": 0.8228971362113953}, {"text": "WordNet", "start_pos": 235, "end_pos": 242, "type": "DATASET", "confidence": 0.9579617977142334}]}, {"text": "In this paper, we make a major step towards the vision of a wide-coverage multilingual knowledge resource.", "labels": [], "entities": []}, {"text": "We present a novel methodology that produces a very large multilingual semantic network: BabelNet.", "labels": [], "entities": []}, {"text": "This resource is created by linking Wikipedia to WordNet via an automatic mapping and by integrating lexical gaps in resource-", "labels": [], "entities": [{"text": "WordNet", "start_pos": 49, "end_pos": 56, "type": "DATASET", "confidence": 0.8742656707763672}]}], "datasetContent": [{"text": "We first performed an evaluation of the quality of our mapping from Wikipedia to WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 81, "end_pos": 88, "type": "DATASET", "confidence": 0.7953256964683533}]}, {"text": "To create a gold standard for evaluation we considered all lemmas whose senses are contained both in WordNet and Wikipedia: the intersection between the two resources contains 80,295 lemmas which correspond to 105,797 WordNet senses and 199,735 Wikipedia pages.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 101, "end_pos": 108, "type": "DATASET", "confidence": 0.9495018720626831}]}, {"text": "The average polysemy is 1.3 and 2.5 for WordNet senses and Wikipages, respectively (2.8 and 4.7 when excluding monosemous words).", "labels": [], "entities": [{"text": "polysemy", "start_pos": 12, "end_pos": 20, "type": "METRIC", "confidence": 0.9805691242218018}]}, {"text": "We then selected a random sample of 1,000 Wikipages and asked an annotator with previous experience in lexicographic annota- tion to provide the correct WordNet sense for each page (an empty sense label was given, if no correct mapping was possible).", "labels": [], "entities": []}, {"text": "The gold-standard dataset includes 505 non-empty mappings, i.e. Wikipages with a corresponding WordNet sense.", "labels": [], "entities": [{"text": "WordNet sense", "start_pos": 95, "end_pos": 108, "type": "DATASET", "confidence": 0.8997771441936493}]}, {"text": "In order to quantify the quality of the annotations and the difficulty of the task, a second annotator sense tagged a subset of 200 pages from the original sample.", "labels": [], "entities": []}, {"text": "Our annotators achieved a \u03ba inter-annotator agreement) of 0.9, indicating almost perfect agreement.", "labels": [], "entities": [{"text": "\u03ba inter-annotator agreement)", "start_pos": 26, "end_pos": 54, "type": "METRIC", "confidence": 0.6601944267749786}]}, {"text": "summarizes the performance of our mapping algorithm against the manually annotated dataset.", "labels": [], "entities": []}, {"text": "Evaluation is performed in terms of standard measures of precision, recall, and F 1 -measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 57, "end_pos": 66, "type": "METRIC", "confidence": 0.999693751335144}, {"text": "recall", "start_pos": 68, "end_pos": 74, "type": "METRIC", "confidence": 0.9996720552444458}, {"text": "F 1 -measure", "start_pos": 80, "end_pos": 92, "type": "METRIC", "confidence": 0.9872734546661377}]}, {"text": "In addition we calculate accuracy, which also takes into account empty sense labels.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9997121691703796}]}, {"text": "As baselines we use the most frequent WordNet sense (MFS), and a random sense assignment.", "labels": [], "entities": [{"text": "WordNet sense (MFS)", "start_pos": 38, "end_pos": 57, "type": "DATASET", "confidence": 0.8474935054779053}]}, {"text": "The results show that our method achieves almost 80% F 1 and it improves over the baselines by a large margin.", "labels": [], "entities": [{"text": "F 1", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9952555298805237}]}, {"text": "The final mapping contains 81,533 pairs of Wikipages and word senses they map to, covering 55.7% of the noun senses in WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 119, "end_pos": 126, "type": "DATASET", "confidence": 0.9616522789001465}]}, {"text": "As for the baselines, the most frequent sense is just 0.6% and 0.4% above the random baseline in terms of F 1 and accuracy, respectively.", "labels": [], "entities": [{"text": "F 1", "start_pos": 106, "end_pos": 109, "type": "METRIC", "confidence": 0.9956746399402618}, {"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.9980231523513794}]}, {"text": "A \u03c7 2 test reveals in fact no statistical significant difference at p < 0.05.", "labels": [], "entities": []}, {"text": "This is related to the random distribution of senses in our dataset and the Wikipedia unbiased coverage of WordNet senses.", "labels": [], "entities": []}, {"text": "So selecting the first WordNet sense rather than any other sense for each target page represents a choice as arbitrary as picking a sense at random.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 23, "end_pos": 30, "type": "DATASET", "confidence": 0.929453432559967}]}, {"text": "We perform a second set of experiments concerning the quality of the acquired concepts.", "labels": [], "entities": []}, {"text": "This is assessed in terms of coverage against gold-standard resources (Section 5.1) and against a manuallyvalidated dataset of translations (Section 5.2).: Size of the gold-standard wordnets.", "labels": [], "entities": [{"text": "coverage", "start_pos": 29, "end_pos": 37, "type": "METRIC", "confidence": 0.9564197063446045}]}, {"text": "We compare BabelNet against goldstandard resources for 5 languages, namely: the subset of GermaNet () included in EuroWordNet for German, MultiWordNet () for Italian, the Multilingual Central Repository for Spanish and Catalan (), and WOrdnet Libre du Fran\u00e7ais (Beno\u02c6\u0131tBeno\u02c6\u0131t and Fi\u0161er, 2008, WOLF) for French.", "labels": [], "entities": [{"text": "EuroWordNet", "start_pos": 114, "end_pos": 125, "type": "DATASET", "confidence": 0.9749605059623718}, {"text": "WOrdnet Libre du Fran\u00e7ais (Beno\u02c6\u0131tBeno\u02c6\u0131t and Fi\u0161er, 2008, WOLF)", "start_pos": 235, "end_pos": 299, "type": "DATASET", "confidence": 0.8809848657021155}]}, {"text": "In we report the number of synsets and word senses available in the gold-standard resources for the 5 languages.", "labels": [], "entities": []}, {"text": "Let B be BabelNet, F our goldstandard non-English wordnet (e.g. GermaNet), and let E be the English WordNet.", "labels": [], "entities": [{"text": "English WordNet", "start_pos": 92, "end_pos": 107, "type": "DATASET", "confidence": 0.7970857918262482}]}, {"text": "All the goldstandard non-English resources, as well as BabelNet, are linked to the English WordNet: given a synset SF \u2208 F, we denote its corresponding babel synset as S B and its synset in the English WordNet as SE . We assess the coverage of BabelNet against our gold-standard wordnets both in terms of synsets and word senses.", "labels": [], "entities": [{"text": "SE", "start_pos": 212, "end_pos": 214, "type": "METRIC", "confidence": 0.978689968585968}]}, {"text": "For synsets, we calculate coverage as follows: where \u03b4(S B , SF ) = 1 if the two synsets S B and SF have a synonym in common, 0 otherwise.", "labels": [], "entities": [{"text": "coverage", "start_pos": 26, "end_pos": 34, "type": "METRIC", "confidence": 0.9964229464530945}]}, {"text": "That is, synset coverage is determined as the percentage of synsets of F that share a term with the corresponding babel synsets.", "labels": [], "entities": [{"text": "coverage", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.6433169841766357}]}, {"text": "For word senses we calculate a similar measure of coverage: where s F is a word sense in synset SF and \u03b4 (s F , S B ) = 1 if s F \u2208 S B , 0 otherwise.", "labels": [], "entities": [{"text": "coverage", "start_pos": 50, "end_pos": 58, "type": "METRIC", "confidence": 0.990563154220581}]}, {"text": "That is we calculate the ratio of word senses in our gold-standard resource F that also occur in the corresponding synset S B to the overall number of senses in F.", "labels": [], "entities": []}, {"text": "However, our gold-standard resources cover only a portion of the English WordNet, whereas the overall coverage of BabelNet is much higher.", "labels": [], "entities": [{"text": "English WordNet", "start_pos": 65, "end_pos": 80, "type": "DATASET", "confidence": 0.835922509431839}]}, {"text": "We calculate extra coverage for synsets as follows: Similarly, we calculate extra coverage for word senses in BabelNet corresponding to WordNet synsets not covered by the reference resource F.", "labels": [], "entities": []}, {"text": "We evaluate the coverage and extra coverage of word senses and synsets at different stages: (a) using only the interlanguage links from Wikipedia (WIKI Links); (b) and (c) using only the automatic translations of the sentences from Wikipedia (WIKI Transl.) or SemCor (WN Transl.); (d) using all available translations, i.e. BABELNET.", "labels": [], "entities": [{"text": "BABELNET", "start_pos": 324, "end_pos": 332, "type": "METRIC", "confidence": 0.9008699059486389}]}, {"text": "Coverage results are reported in.", "labels": [], "entities": [{"text": "Coverage", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.7690929770469666}]}, {"text": "The percentage of word senses covered by BabelNet ranges from 52.9% (Italian) to 66.4 (Spanish) and 86.0% (French).", "labels": [], "entities": []}, {"text": "Synset coverage ranges from 73.3% (Catalan) to 76.6% (Spanish) and 92.9% (French).", "labels": [], "entities": [{"text": "Synset coverage", "start_pos": 0, "end_pos": 15, "type": "METRIC", "confidence": 0.5868881046772003}]}, {"text": "As expected, synset coverage is higher, because a synset in the reference resource is considered to be covered if it shares at least one word with the corresponding synset in BabelNet.", "labels": [], "entities": [{"text": "coverage", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.7734125256538391}]}, {"text": "Numbers for the extra coverage, which provides information about the percentage of word senses and synsets in BabelNet but not in the goldstandard resources, are given in.", "labels": [], "entities": []}, {"text": "The results show that we provide for all languages a high extra coverage for both word senses -between 340.1% (Catalan) and 2,298% (German) -and synsets -between 102.8% (Spanish) and 902.6% (German). and show that the best results are obtained when combining all available translations, i.e. both from Wikipedia and the machine translation system.", "labels": [], "entities": []}, {"text": "The performance figures suffer from the errors of the mapping phase (see Section 4).", "labels": [], "entities": []}, {"text": "Nonetheless, the results are generally high, with a peak for French, since WOLF has been created semi-automatically by combining several resources, including Wikipedia.", "labels": [], "entities": [{"text": "WOLF", "start_pos": 75, "end_pos": 79, "type": "DATASET", "confidence": 0.8407458066940308}]}, {"text": "The relatively low word sense coverage for Italian (55.4%) is, instead, due to the lack of many common words in the Italian gold-standard synsets.", "labels": [], "entities": [{"text": "word sense coverage", "start_pos": 19, "end_pos": 38, "type": "METRIC", "confidence": 0.4621995687484741}]}, {"text": "Examples include whip EN translated as staffile IT but not as the more common frusta IT , playboy EN translated as vitaiolo IT but not gigo\u00ec o IT , etc.: Coverage against gold-standard wordnets (we report percentages).", "labels": [], "entities": []}, {"text": "The automatic evaluation quantifies how much of the gold-standard resources is covered by BabelNet.", "labels": [], "entities": []}, {"text": "However, it does not say anything about the precision of the additional lexicalizations provided by BabelNet.", "labels": [], "entities": [{"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9989005327224731}]}, {"text": "Given that our resource has displayed a remarkably high extra coverage -ranging from 340% to 2,298% of the national wordnets (see) -we performed a second evaluation to assess its precision.", "labels": [], "entities": [{"text": "coverage", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.5246464610099792}, {"text": "precision", "start_pos": 179, "end_pos": 188, "type": "METRIC", "confidence": 0.9985169768333435}]}, {"text": "For each of our 5 languages, we selected a random set of 600 babel synsets composed as follows: 200 synsets whose senses exist in WordNet only, 200 synsets in the intersection between WordNet and Wikipedia (i.e. those mapped with our method illustrated in Section 3.2), 200 synsets whose lexicalizations exist in Wikipedia only.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 130, "end_pos": 137, "type": "DATASET", "confidence": 0.9588295817375183}]}, {"text": "Therefore, our dataset included 600 \u00d7 5 = 3,000 babel synsets.", "labels": [], "entities": []}, {"text": "None of the synsets was covered by any of the five reference wordnets.", "labels": [], "entities": []}, {"text": "The babel synsets were manually validated by expert annotators who decided which senses (i.e. lexicalizations) were appropriate given the corresponding WordNet gloss and/or Wikipage.", "labels": [], "entities": []}, {"text": "We report the results in.", "labels": [], "entities": []}, {"text": "For each language (rows) and for each of the three regions of BabelNet (columns), we report precision (i.e. the percentage of synonyms deemed correct) and, in parentheses, the overall number of synonyms evaluated.", "labels": [], "entities": [{"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.999294638633728}]}, {"text": "The results show that the different regions of BabelNet contain translations of different quality: while on average translations for WordNet-only synsets have a precision around 72%, when Wikipedia comes into play the performance increases considerably (around 80% in the intersection and 95% with Wikipedia-only translations).", "labels": [], "entities": [{"text": "precision", "start_pos": 161, "end_pos": 170, "type": "METRIC", "confidence": 0.99454665184021}]}, {"text": "As can be seen from the figures in parentheses, the number of translations available in the presence of Wikipedia is higher.", "labels": [], "entities": [{"text": "Wikipedia", "start_pos": 104, "end_pos": 113, "type": "DATASET", "confidence": 0.9578682780265808}]}, {"text": "This quantitative difference is due to our method collecting many translations from the redirections in the Wikipedia of the target language (Section 3.3), as well as to the paucity of examples in SemCor for many synsets.", "labels": [], "entities": []}, {"text": "In addition, some of the synsets in WordNet with no Wikipedia counterpart are very difficult to translate.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 36, "end_pos": 43, "type": "DATASET", "confidence": 0.9602012634277344}]}, {"text": "Examples include terms like stammel, crape fern, baseball clinic, and many others for which we could", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Performance of the mapping algorithm.", "labels": [], "entities": []}, {"text": " Table 2: Size of the gold-standard wordnets.", "labels": [], "entities": []}, {"text": " Table 3: Coverage against gold-standard wordnets  (we report percentages).", "labels": [], "entities": []}]}