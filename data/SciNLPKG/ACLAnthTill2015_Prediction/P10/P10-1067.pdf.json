{"title": [{"text": "Comparable Entity Mining from Comparative Questions", "labels": [], "entities": [{"text": "Comparable Entity Mining", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7486365437507629}]}], "abstractContent": [{"text": "Comparing one thing with another is atypical part of human decision making process.", "labels": [], "entities": [{"text": "decision making process", "start_pos": 59, "end_pos": 82, "type": "TASK", "confidence": 0.7914674580097198}]}, {"text": "However , it is not always easy to know what to compare and what are the alternatives.", "labels": [], "entities": []}, {"text": "To address this difficulty, we present a novel way to automatically mine comparable entities from comparative questions that users posted on-line.", "labels": [], "entities": []}, {"text": "To ensure high precision and high recall, we develop a weakly-supervised bootstrapping method for comparative question identification and comparable entity extraction by leveraging a large online question archive.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9970113039016724}, {"text": "recall", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9991208910942078}, {"text": "comparative question identification", "start_pos": 98, "end_pos": 133, "type": "TASK", "confidence": 0.8091128667195638}, {"text": "comparable entity extraction", "start_pos": 138, "end_pos": 166, "type": "TASK", "confidence": 0.6518911719322205}]}, {"text": "The experimental results show our method achieves F1-measure of 82.5% in comparative question identification and 83.3% in comparable entity extraction.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 50, "end_pos": 60, "type": "METRIC", "confidence": 0.999546468257904}, {"text": "comparative question identification", "start_pos": 73, "end_pos": 108, "type": "TASK", "confidence": 0.769530455271403}, {"text": "entity extraction", "start_pos": 133, "end_pos": 150, "type": "TASK", "confidence": 0.748130202293396}]}, {"text": "Both significantly outperform an existing state-of-the-art method.", "labels": [], "entities": []}], "introductionContent": [{"text": "Comparing alternative options is one essential step in decision-making that we carryout everyday.", "labels": [], "entities": []}, {"text": "For example, if someone is interested in certain products such as digital cameras, he or she would want to know what the alternatives are and compare different cameras before making a purchase.", "labels": [], "entities": []}, {"text": "This type of comparison activity is very common in our daily life but requires high knowledge skill.", "labels": [], "entities": [{"text": "comparison activity", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.8784417510032654}]}, {"text": "Magazines such as Consumer Reports and PC Magazine and online media such as CNet.com strive in providing editorial comparison content and surveys to satisfy this need.", "labels": [], "entities": [{"text": "PC Magazine", "start_pos": 39, "end_pos": 50, "type": "DATASET", "confidence": 0.8031638860702515}]}, {"text": "In the World Wide Web era, a comparison activity typically involves: search for relevant web pages containing information about the targeted products, find competing products, read reviews, and identify pros and cons.", "labels": [], "entities": []}, {"text": "In this paper, we focus on finding a set of comparable entities given a user\"s input entity.", "labels": [], "entities": []}, {"text": "For example, given an entity, Nokia N95 (a cellphone), we want to find comparable entities such as Nokia N82, iPhone and soon.", "labels": [], "entities": []}, {"text": "In general, it is difficult to decide if two entities are comparable or not since people do compare apples and oranges for various reasons.", "labels": [], "entities": []}, {"text": "For example, \"Ford\" and \"BMW\" might be comparable as \"car manufacturers\" or as \"market segments that their products are targeting\", but we rarely see people comparing \"Ford Focus\" (car model) and \"BMW 328i\".", "labels": [], "entities": []}, {"text": "Things also get more complicated when an entity has several functionalities.", "labels": [], "entities": []}, {"text": "For example, one might compare \"iPhone\" and \"PSP\" as \"portable game player\" while compare \"iPhone\" and \"Nokia N95\" as \"mobile phone\".", "labels": [], "entities": []}, {"text": "Fortunately, plenty of comparative questions are posted online, which provide evidences for what people want to compare, e.g. \"Which to buy, iPod or iPhone?\".", "labels": [], "entities": []}, {"text": "We call \"iPod\" and \"iPhone\" in this example as comparators.", "labels": [], "entities": []}, {"text": "In this paper, we define comparative questions and comparators as: \uf0b7 Comparative question: A question that intends to compare two or more entities and it has to mention these entities explicitly in the question.", "labels": [], "entities": []}, {"text": "\uf0b7 Comparator: An entity which is a target of comparison in a comparative question.", "labels": [], "entities": []}, {"text": "According to these definitions, Q1 and Q2 below are not comparative questions while Q3 is.", "labels": [], "entities": []}, {"text": "\"iPod Touch\" and \"Zune HD\" are comparators.", "labels": [], "entities": []}, {"text": "Q1: \"Which one is better?\"", "labels": [], "entities": []}, {"text": "Q2: \"Is Lumix GH-1 the best camera?\"", "labels": [], "entities": [{"text": "Lumix GH-1", "start_pos": 8, "end_pos": 18, "type": "DATASET", "confidence": 0.8506148457527161}]}, {"text": "Q3: \"What\"s the difference between iPod Touch and Zune HD?\"", "labels": [], "entities": []}, {"text": "The goal of this work is mining comparators from comparative questions.", "labels": [], "entities": []}, {"text": "The results would be very useful in helping users\" exploration of alternative choices by suggesting comparable entities based on other users\" prior requests.", "labels": [], "entities": []}, {"text": "To mine comparators from comparative questions, we first have to detect whether a question is comparative or not.", "labels": [], "entities": []}, {"text": "According to our definition, a comparative question has to be a question with intent to compare at least two entities.", "labels": [], "entities": []}, {"text": "Please note that a question containing at least two entities is not a comparative question if it does not have comparison intent.", "labels": [], "entities": []}, {"text": "However, we observe that a question is very likely to be a comparative question if it contains at least two entities.", "labels": [], "entities": []}, {"text": "We leverage this insight and develop a weakly supervised bootstrapping method to identify comparative questions and extract comparators simultaneously.", "labels": [], "entities": []}, {"text": "To our best knowledge, this is the first attempt to specially address the problem on finding good comparators to support users\" comparison activity.", "labels": [], "entities": []}, {"text": "We are also the first to propose using comparative questions posted online that reflect what users truly care about as the medium from which we mine comparable entities.", "labels": [], "entities": []}, {"text": "Our weakly supervised method achieves 82.5% F1-measure in comparative question identification, 83.3% in comparator extraction, and 76.8% in end-to-end comparative question identification and comparator extraction which outperform the most relevant state-of-the-art method by Jindal & Liu (2006b) significantly.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 44, "end_pos": 54, "type": "METRIC", "confidence": 0.9995943903923035}, {"text": "comparative question identification", "start_pos": 58, "end_pos": 93, "type": "TASK", "confidence": 0.7702373067537943}, {"text": "comparator extraction", "start_pos": 104, "end_pos": 125, "type": "TASK", "confidence": 0.6858979910612106}, {"text": "comparative question identification", "start_pos": 151, "end_pos": 186, "type": "TASK", "confidence": 0.6403819620609283}, {"text": "comparator extraction", "start_pos": 191, "end_pos": 212, "type": "TASK", "confidence": 0.709640845656395}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "The next section discusses previous works.", "labels": [], "entities": []}, {"text": "Section 3 presents our weakly-supervised method for comparator mining.", "labels": [], "entities": [{"text": "comparator mining", "start_pos": 52, "end_pos": 69, "type": "TASK", "confidence": 0.7886717617511749}]}, {"text": "Section 4 reports the evaluations of our techniques, and we conclude the paper and discuss future work in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "According to our first assumption, a reliability score \u00ed \u00b5\u00ed\u00b1 \u00ed \u00b5\u00ed\u00b1\u0098 (\u00ed \u00b5\u00ed\u00b1\u009d \u00ed \u00b5\u00ed\u00b1\u0096 ) fora candidate pattern \u00ed \u00b5\u00ed\u00b1\u009d \u00ed \u00b5\u00ed\u00b1\u0096 at iteration k can be defined as follows: , where \u00ed \u00b5\u00ed\u00b1\u009d \u00ed \u00b5\u00ed\u00b1\u0096 can extract known reliable comparator pairs \u00ed \u00b5\u00ed\u00b1\u0090\u00ed \u00b5\u00ed\u00b1\u009d \u00ed \u00b5\u00ed\u00b1\u0097 . \u00ed \u00b5\u00ed\u00b0 \u00b6\u00ed \u00b5\u00ed\u00b1\u0083 \u00ed \u00b5\u00ed\u00b1\u0098\u22121 indicates the reliable comparator pair repository accumulated until the (\u00ed \u00b5\u00ed\u00b1\u0098 \u2212 1)\u00ed \u00b5\u00ed\u00b1\u00a1\u210e iteration.", "labels": [], "entities": []}, {"text": "\u00ed \u00b5\u00ed\u00b1\u0081 \u00ed \u00b5\u00ed\u00b1\u0084 (\u00ed \u00b5\u00ed\u00b1\u00a5) means the number of questions satisfying a condition x.", "labels": [], "entities": [{"text": "\u00ed \u00b5\u00ed\u00b1\u0081 \u00ed \u00b5\u00ed\u00b1\u0084", "start_pos": 0, "end_pos": 13, "type": "METRIC", "confidence": 0.8259854316711426}]}, {"text": "The condition \u00ed \u00b5\u00ed\u00b1\u009d \u00ed \u00b5\u00ed\u00b1\u0096 \u2192 \u00ed \u00b5\u00ed\u00b1\u0090\u00ed \u00b5\u00ed\u00b1\u009d \u00ed \u00b5\u00ed\u00b1\u0097 denotes that \u00ed \u00b5\u00ed\u00b1\u0090\u00ed \u00b5\u00ed\u00b1\u009d \u00ed \u00b5\u00ed\u00b1\u0097 can be extracted from a question by applying pattern \u00ed \u00b5\u00ed\u00b1\u009d \u00ed \u00b5\u00ed\u00b1\u0096 while the condition \u00ed \u00b5\u00ed\u00b1\u009d \u00ed \u00b5\u00ed\u00b1\u0096 \u2192 * denotes any question containing pattern \u00ed \u00b5\u00ed\u00b1\u009d \u00ed \u00b5\u00ed\u00b1\u0096 . However, Equation (1) can suffer from incomplete knowledge about reliable comparator pairs.", "labels": [], "entities": [{"text": "Equation", "start_pos": 253, "end_pos": 261, "type": "METRIC", "confidence": 0.9260818958282471}]}, {"text": "For example, very few reliable pairs are generally discovered in early stage of bootstrapping.", "labels": [], "entities": []}, {"text": "In this case, the value of Equation (1) might be underestimated which could affect the effectiveness of equation on distinguishing IEPs from non-reliable patterns.", "labels": [], "entities": [{"text": "Equation", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.9991330504417419}]}, {"text": "We mitigate this problem by a lookahead procedure.", "labels": [], "entities": []}, {"text": "Let us denote the set of candidate patterns at the iteration k by \u00ed \u00b5\u00ed\u00b1\u0083 \u00ed \u00b5\u00ed\u00b1\u0098 . We define the support \u00ed \u00b5\u00ed\u00b1\u0086 for comparator pair \u00ed \u00b5\u00ed\u00b1\u0090\u00ed \u00b5\u00ed\u00b1\u009d \u00ed \u00b5\u00ed\u00b1\u0096 which can be extracted by \u00ed \u00b5\u00ed\u00b1\u0083 \u00ed \u00b5\u00ed\u00b1\u0098 and does not exist in the current reliable set: \u00ed \u00b5\u00ed\u00b1\u0086 \u00ed \u00b5\u00ed\u00b1\u0090\u00ed \u00b5\u00ed\u00b1\u009d \u00ed \u00b5\u00ed\u00b1\u0096 = \u00ed \u00b5\u00ed\u00b1\u0081 \u00ed \u00b5\u00ed\u00b1\u0084 ( \u00ed \u00b5\u00ed\u00b1\u0083 \u00ed \u00b5\u00ed\u00b1\u0098 \u2192 \u00ed \u00b5\u00ed\u00b1\u0090\u00ed \u00b5\u00ed\u00b1\u009d \u00ed \u00b5\u00ed\u00b1\u0096 ) where \u00ed \u00b5\u00ed\u00b1\u0083 \u00ed \u00b5\u00ed\u00b1\u0098 \u2192 \u00ed \u00b5\u00ed\u00b1\u0090\u00ed \u00b5\u00ed\u00b1\u009d \u00ed \u00b5\u00ed\u00b1\u0096 means that one of the patterns in \u00ed \u00b5\u00ed\u00b1\u0083 \u00ed \u00b5\u00ed\u00b1\u0098 can extract \u00ed \u00b5\u00ed\u00b1\u0090\u00ed \u00b5\u00ed\u00b1\u009d \u00ed \u00b5\u00ed\u00b1\u0096 in certain questions.", "labels": [], "entities": []}, {"text": "Intuitively, if \u00ed \u00b5\u00ed\u00b1\u0090\u00ed \u00b5\u00ed\u00b1\u009d \u00ed \u00b5\u00ed\u00b1\u0096 can be extracted by many candidate patterns in \u00ed \u00b5\u00ed\u00b1\u0083 \u00ed \u00b5\u00ed\u00b1\u0098 , it is likely to be extracted as a reliable one in the next iteration.", "labels": [], "entities": []}, {"text": "Based on this intuition, a pair \u00ed \u00b5\u00ed\u00b1\u0090\u00ed \u00b5\u00ed\u00b1\u009d \u00ed \u00b5\u00ed\u00b1\u0096 whose support S is more than a threshold \u00ed \u00b5\u00ed\u00bb\u00bc is regarded as a likely-reliable pair.", "labels": [], "entities": []}, {"text": "Using likely-reliable pairs, lookahead reliability score \u00ed \u00b5\u00ed\u00b1 \u00ed \u00b5\u00ed\u00b1\u009d \u00ed \u00b5\u00ed\u00b1\u0096 is defined: , where \u00ed \u00b5\u00ed\u00b0 \u00b6\u00ed \u00b5\u00ed\u00b1\u0083 \u00ed \u00b5\u00ed\u00b1\u009f\u00ed \u00b5\u00ed\u00b1\u0092\u00ed \u00b5\u00ed\u00b1\u0099 \u00ed \u00b5\u00ed\u00b1\u0098 indicates a set of likely-reliable pairs based on \u00ed \u00b5\u00ed\u00b1\u0083 \u00ed \u00b5\u00ed\u00b1\u0098 . By interpolating Equation and, the final reliability score \u00ed \u00b5\u00ed\u00b1 (\u00ed \u00b5\u00ed\u00b1\u009d \u00ed \u00b5\u00ed\u00b1\u0096 ) \u00ed \u00b5\u00ed\u00b1\u0093\u00ed \u00b5\u00ed\u00b1\u0096\u00ed \u00b5\u00ed\u00b1\u009b\u00ed \u00b5\u00ed\u00b1\u008e\u00ed \u00b5\u00ed\u00b1\u0099 \u00ed \u00b5\u00ed\u00b1\u0098 fora pattern is defined as follows: Using Equation (4), we evaluate all candidate patterns and select patterns whose score is more than threshold \u00ed \u00b5\u00ed\u00bb\u00be as IEPs.", "labels": [], "entities": [{"text": "lookahead reliability score", "start_pos": 29, "end_pos": 56, "type": "METRIC", "confidence": 0.6711693406105042}, {"text": "IEPs", "start_pos": 479, "end_pos": 483, "type": "METRIC", "confidence": 0.7813699245452881}]}, {"text": "All necessary parameter values are empirically determined.", "labels": [], "entities": []}, {"text": "We will explain how to determine our parameters in section 4.", "labels": [], "entities": []}, {"text": "Two separate data sets were created for evaluation.", "labels": [], "entities": []}, {"text": "First, we collected 5,200 questions by sampling 200 questions from each Yahoo!", "labels": [], "entities": []}, {"text": "Answers category . Two annotators were asked to label each question manually as comparative, noncomparative, or unknown.", "labels": [], "entities": []}, {"text": "Among them, 139 (2.67%) questions were classified as comparative, 4,934 (94.88%) as non-comparative, and 127 (2.44%) as unknown questions which are difficult to assess.", "labels": [], "entities": []}, {"text": "We call this set SET-A.", "labels": [], "entities": [{"text": "SET-A", "start_pos": 17, "end_pos": 22, "type": "TASK", "confidence": 0.591687798500061}]}, {"text": "Because there are only 139 comparative questions in SET-A, we created another set which contains more comparative questions.", "labels": [], "entities": [{"text": "SET-A", "start_pos": 52, "end_pos": 57, "type": "TASK", "confidence": 0.7225860357284546}]}, {"text": "We manually constructed a keyword set consisting of 53 words such as \"or\" and \"prefer\", which are good indicators of comparative questions.", "labels": [], "entities": []}, {"text": "In SET-A, 97.4% of comparative questions contains one or more keywords from the keyword set.", "labels": [], "entities": [{"text": "SET-A", "start_pos": 3, "end_pos": 8, "type": "TASK", "confidence": 0.9389727711677551}]}, {"text": "We then randomly selected another 100 questions from each Yahoo!", "labels": [], "entities": []}, {"text": "Answers category with one extra condition that all questions have to contain at least one keyword.", "labels": [], "entities": []}, {"text": "These questions were labeled in the same way as SET-A except that their comparators were also annotated.", "labels": [], "entities": []}, {"text": "This second set of questions is referred as SET-B.", "labels": [], "entities": [{"text": "SET-B", "start_pos": 44, "end_pos": 49, "type": "TASK", "confidence": 0.7947431802749634}]}, {"text": "It contains 853 comparative questions and 1,747 noncomparative questions.", "labels": [], "entities": []}, {"text": "For comparative question identification experiments, we used all labeled questions in SET-A and SET-B.", "labels": [], "entities": [{"text": "comparative question identification", "start_pos": 4, "end_pos": 39, "type": "TASK", "confidence": 0.7731653650601705}, {"text": "SET-A", "start_pos": 86, "end_pos": 91, "type": "DATASET", "confidence": 0.49978843331336975}, {"text": "SET-B", "start_pos": 96, "end_pos": 101, "type": "DATASET", "confidence": 0.7522864937782288}]}, {"text": "For comparator extraction experiments, we used only SET-B.", "labels": [], "entities": [{"text": "comparator extraction", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.699530154466629}, {"text": "SET-B", "start_pos": 52, "end_pos": 57, "type": "METRIC", "confidence": 0.829974353313446}]}, {"text": "All the remaining unlabeled questions (called as SET-R) were used for training our weakly supervised method.", "labels": [], "entities": [{"text": "SET-R", "start_pos": 49, "end_pos": 54, "type": "TASK", "confidence": 0.48195329308509827}]}, {"text": "As a baseline method, we carefully implemented J&L\"s method.", "labels": [], "entities": []}, {"text": "Specifically, CSRs for comparative question identification were learned from the labeled questions, and then a statistical classifier was built by using CSR rules as features.", "labels": [], "entities": [{"text": "comparative question identification", "start_pos": 23, "end_pos": 58, "type": "TASK", "confidence": 0.8126001358032227}]}, {"text": "We examined both SVM and Na\u00efve Bayes (NB) models as reported in their experiments.", "labels": [], "entities": []}, {"text": "For the comparator extraction, LSRs were learned from SET-B and applied for comparator extraction.", "labels": [], "entities": [{"text": "comparator extraction", "start_pos": 8, "end_pos": 29, "type": "TASK", "confidence": 0.7788477838039398}, {"text": "LSRs", "start_pos": 31, "end_pos": 35, "type": "METRIC", "confidence": 0.9601970911026001}, {"text": "SET-B", "start_pos": 54, "end_pos": 59, "type": "DATASET", "confidence": 0.7828634977340698}, {"text": "comparator extraction", "start_pos": 76, "end_pos": 97, "type": "TASK", "confidence": 0.7586591839790344}]}, {"text": "To start the bootstrapping procedure, we applied the IEP \"<#start nn/$c vs/cc nn/$c ?/.", "labels": [], "entities": [{"text": "IEP", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9266383647918701}]}, {"text": "#end>\" to all the questions in SET-R and gathered 12,194 comparator pairs as the initial seeds.", "labels": [], "entities": [{"text": "SET-R", "start_pos": 31, "end_pos": 36, "type": "TASK", "confidence": 0.5927512645721436}]}, {"text": "For our weakly supervised method, there There are 26 top level categories in Yahoo!", "labels": [], "entities": [{"text": "Yahoo!", "start_pos": 77, "end_pos": 83, "type": "DATASET", "confidence": 0.9194180965423584}]}, {"text": "Answers. are four parameters, i.e. \u03b1, \u03b2, \u03b3, and \u03bb, need to be determined empirically.", "labels": [], "entities": []}, {"text": "We first mined all possible candidate patterns from the suffix tree using the initial seeds.", "labels": [], "entities": []}, {"text": "From these candidate patterns, we applied them to SET-R and got anew set of 59,410 candidate comparator pairs.", "labels": [], "entities": [{"text": "SET-R", "start_pos": 50, "end_pos": 55, "type": "TASK", "confidence": 0.652106761932373}]}, {"text": "Among these new candidate comparator pairs, we randomly selected 100 comparator pairs and manually classified them into reliable or non-reliable comparators.", "labels": [], "entities": []}, {"text": "Then we found \u00ed \u00b5\u00ed\u00bb\u00bc that maximized precision without hurting recall by investigating frequencies of pairs in the labeled set.", "labels": [], "entities": [{"text": "precision", "start_pos": 36, "end_pos": 45, "type": "METRIC", "confidence": 0.9992825388908386}, {"text": "recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.9981927275657654}]}, {"text": "By this method, \u00ed \u00b5\u00ed\u00bb\u00bc was set to 3 in our experiments.", "labels": [], "entities": [{"text": "\u00ed \u00b5\u00ed", "start_pos": 16, "end_pos": 20, "type": "METRIC", "confidence": 0.6442820727825165}]}, {"text": "Similarly, the threshold parameters \u00ed \u00b5\u00ed\u00bb\u00bd and \u00ed \u00b5\u00ed\u00bb\u00be for pattern evaluation were set to 10 and 0.8 respectively.", "labels": [], "entities": [{"text": "pattern evaluation", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.8113007545471191}]}, {"text": "For the interpolation parameter \u00ed \u00b5\u00ed\u00bc\u0086 in Equation, we simply set the value to 0.5 by assuming that two reliability scores are equally important.", "labels": [], "entities": [{"text": "interpolation parameter \u00ed \u00b5\u00ed\u00bc\u0086", "start_pos": 8, "end_pos": 38, "type": "METRIC", "confidence": 0.706728607416153}, {"text": "Equation", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.6218407154083252}, {"text": "reliability", "start_pos": 104, "end_pos": 115, "type": "METRIC", "confidence": 0.979522705078125}]}, {"text": "As evaluation measures for comparative question identification and comparator extraction, we used precision, recall, and F1-measure.", "labels": [], "entities": [{"text": "comparative question identification", "start_pos": 27, "end_pos": 62, "type": "TASK", "confidence": 0.7678582270940145}, {"text": "comparator extraction", "start_pos": 67, "end_pos": 88, "type": "TASK", "confidence": 0.7490691840648651}, {"text": "precision", "start_pos": 98, "end_pos": 107, "type": "METRIC", "confidence": 0.9997096657752991}, {"text": "recall", "start_pos": 109, "end_pos": 115, "type": "METRIC", "confidence": 0.9992275238037109}, {"text": "F1-measure", "start_pos": 121, "end_pos": 131, "type": "METRIC", "confidence": 0.9982692003250122}]}, {"text": "All results were obtained from 5-fold cross validation.", "labels": [], "entities": []}, {"text": "Note that J&L\"s method needs a training data but ours use the unlabeled data (SET-R) with weakly supervised method to find parameter setting.", "labels": [], "entities": [{"text": "SET-R", "start_pos": 78, "end_pos": 83, "type": "METRIC", "confidence": 0.9183496832847595}]}, {"text": "This 5-fold evaluation data is not in the unlabeled data.", "labels": [], "entities": []}, {"text": "Both methods were tested on the same test split in the 5-fold cross validation.", "labels": [], "entities": []}, {"text": "All evaluation scores are averaged across all 5 folds.", "labels": [], "entities": []}, {"text": "For question processing, we used our own statistical POS tagger developed in-house 4 . shows our experimental results.", "labels": [], "entities": [{"text": "question processing", "start_pos": 4, "end_pos": 23, "type": "TASK", "confidence": 0.9268465638160706}, {"text": "POS tagger", "start_pos": 53, "end_pos": 63, "type": "TASK", "confidence": 0.5830384492874146}]}, {"text": "In the table, \"Identification only\" indicates the performances in comparative question identification, \"Extraction only\" denotes the performances of comparator extraction when only comparative questions are used as input, and \"All\" indicates the end-to-end performances when question identification results were used in comparator extraction.", "labels": [], "entities": [{"text": "Identification", "start_pos": 15, "end_pos": 29, "type": "METRIC", "confidence": 0.9597543478012085}, {"text": "comparative question identification", "start_pos": 66, "end_pos": 101, "type": "TASK", "confidence": 0.7462078134218851}, {"text": "comparator extraction", "start_pos": 149, "end_pos": 170, "type": "TASK", "confidence": 0.7015694677829742}, {"text": "comparator extraction", "start_pos": 320, "end_pos": 341, "type": "TASK", "confidence": 0.7182784974575043}]}, {"text": "Note that the results of J&L\"s method on our collections are very comparable to what is reported in their paper.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Effect of pattern specialization and Generali- zation in the end-to-end experiments.", "labels": [], "entities": [{"text": "pattern specialization", "start_pos": 20, "end_pos": 42, "type": "TASK", "confidence": 0.6683793216943741}, {"text": "Generali- zation", "start_pos": 47, "end_pos": 63, "type": "METRIC", "confidence": 0.9442444841066996}]}, {"text": " Table 4: Performance variation over different initial  seed IEPs in the end-to-end experiments", "labels": [], "entities": []}, {"text": " Table 2: Performance comparison between our method and Jindal and Bing\"s Method (denoted as J&L).  The values with * indicate statistically significant improvements over J&L (CSR) SVM or J&L (LSR)  according to t-test at p < 0.01 level.", "labels": [], "entities": []}]}