{"title": [{"text": "Learning Common Grammar from Multilingual Corpus", "labels": [], "entities": []}], "abstractContent": [{"text": "We propose a corpus-based probabilis-tic framework to extract hidden common syntax across languages from non-parallel multilingual corpora in an unsupervised fashion.", "labels": [], "entities": []}, {"text": "For this purpose, we assume a generative model for multilingual corpora, where each sentence is generated from a language dependent probabilistic context-free grammar (PCFG), and these PCFGs are generated from a prior grammar that is common across languages.", "labels": [], "entities": []}, {"text": "We also develop a variational method for efficient inference.", "labels": [], "entities": []}, {"text": "Experiments on a non-parallel multilingual corpus of eleven languages demonstrate the feasibility of the proposed method.", "labels": [], "entities": []}], "introductionContent": [{"text": "Languages share certain common properties.", "labels": [], "entities": []}, {"text": "For example, the word order inmost European languages is subject-verb-object (SVO), and some words with similar forms are used with similar meanings in different languages.", "labels": [], "entities": []}, {"text": "The reasons for these common properties can be attributed to: 1) a common ancestor language, 2) borrowing from nearby languages, and 3) the innate abilities of humans.", "labels": [], "entities": []}, {"text": "We assume hidden commonalities in syntax across languages, and try to extract a common grammar from non-parallel multilingual corpora.", "labels": [], "entities": []}, {"text": "For this purpose, we propose a generative model for multilingual grammars that is learned in an unsupervised fashion.", "labels": [], "entities": []}, {"text": "There are some computational models for capturing commonalities at the phoneme and word level, but, as far as we know, no attempt has been made to extract commonalities in syntax level from non-parallel and non-annotated multilingual corpora.", "labels": [], "entities": []}, {"text": "In our scenario, we use probabilistic contextfree grammars (PCFGs) as our monolingual grammar model.", "labels": [], "entities": []}, {"text": "We assume that a PCFG for each language is generated from a general model that are common across languages, and each sentence in multilingual corpora is generated from the language dependent PCFG.", "labels": [], "entities": []}, {"text": "The inference of the general model as well as the multilingual PCFGs can be performed by using a variational method for efficiency.", "labels": [], "entities": [{"text": "PCFGs", "start_pos": 63, "end_pos": 68, "type": "DATASET", "confidence": 0.8634024262428284}]}, {"text": "Our approach is based on a Bayesian multitask learning framework ().", "labels": [], "entities": []}, {"text": "Hierarchical Bayesian modeling provides a natural way of obtaining a joint regularization for individual models by assuming that the model parameters are drawn from a common prior distribution ().", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated our method by employing the EuroParl corpus).", "labels": [], "entities": [{"text": "EuroParl corpus", "start_pos": 41, "end_pos": 56, "type": "DATASET", "confidence": 0.9957825839519501}]}, {"text": "The corpus consists of the proceedings of the European Parliament in eleven western European languages: Danish (da), German (de), Greek (el), English (en), Spanish (es), Finnish (fi), French (fr), Italian (it), Dutch (nl), Portuguese (pt), and Swedish (sv), and it contains roughly 1,500,000 sentences in each language.", "labels": [], "entities": []}, {"text": "We set the number of nonterminals at |K| = 20, and omitted sentences with more than ten words for tractability.", "labels": [], "entities": []}, {"text": "We randomly sampled 100,000 sentences for each language, and analyzed them using our method.", "labels": [], "entities": []}, {"text": "It should be noted that our random samples are not sentence-aligned.", "labels": [], "entities": []}, {"text": "shows the most probable terminals of emission for each language and nonterminal with a high probability of selecting the emission rule.", "labels": [], "entities": []}, {"text": "We named nonterminals by using grammatical categories after the inference.", "labels": [], "entities": []}, {"text": "We can see that words in the same grammatical category clustered across languages as well as within a language.", "labels": [], "entities": []}, {"text": "shows examples of inferred common grammar rules with high probabilities.", "labels": [], "entities": []}, {"text": "Grammar rules that seem to be common to European languages have been extracted.", "labels": [], "entities": []}], "tableCaptions": []}