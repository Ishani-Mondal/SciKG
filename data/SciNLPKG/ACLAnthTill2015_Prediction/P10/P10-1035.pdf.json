{"title": [{"text": "Accurate Context-Free Parsing with Combinatory Categorial Grammar", "labels": [], "entities": [{"text": "Accurate Context-Free Parsing", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.6907373865445455}]}], "abstractContent": [{"text": "The definition of combinatory categorial grammar (CCG) in the literature varies quite a bit from author to author.", "labels": [], "entities": [{"text": "combinatory categorial grammar (CCG)", "start_pos": 18, "end_pos": 54, "type": "TASK", "confidence": 0.7739125986893972}]}, {"text": "However , the differences between the definitions are important in terms of the language classes of each CCG.", "labels": [], "entities": []}, {"text": "We prove that a wide range of CCGs are strongly context-free, including the CCG of CCG-bank and of the parser of Clark and Cur-ran (2007).", "labels": [], "entities": []}, {"text": "In light of these new results, we train the PCFG parser of Petrov and Klein (2007) on CCGbank and achieve state of the art results in supertagging accuracy , PARSEVAL measures and dependency accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.9706040024757385}, {"text": "PARSEVAL", "start_pos": 158, "end_pos": 166, "type": "METRIC", "confidence": 0.9413120746612549}, {"text": "accuracy", "start_pos": 191, "end_pos": 199, "type": "METRIC", "confidence": 0.9599162340164185}]}], "introductionContent": [{"text": "Combinatory categorial grammar (CCG) is a variant of categorial grammar which has attracted interest for both theoretical and practical reasons.", "labels": [], "entities": [{"text": "Combinatory categorial grammar (CCG)", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.7950475166241328}]}, {"text": "On the theoretical side, we know that it is mildly context-sensitive and that it can elegantly analyze a wide range of linguistic phenomena).", "labels": [], "entities": []}, {"text": "On the practical side, we have corpora with CCG derivations for each sentence), a wide-coverage parser trained on that corpus) and a system for converting CCG derivations into semantic representations ().", "labels": [], "entities": []}, {"text": "However, despite being treated as a single unified grammar formalism, each of these authors use variations of CCG which differ primarily on which combinators are included in the grammar and the restrictions that are put on them.", "labels": [], "entities": []}, {"text": "These differences are important because they affect whether the mild context-sensitivity proof of applies.", "labels": [], "entities": []}, {"text": "We will provide a generalized framework for CCG within which the full variation of CCG seen in the literature can be defined.", "labels": [], "entities": []}, {"text": "Then, we prove that fora wide range of CCGs there is a context-free grammar (CFG) that has exactly the same derivations.", "labels": [], "entities": []}, {"text": "Included in this class of strongly context-free CCGs area grammar including all the derivations in CCGbank and the grammar used in the Clark and Curran parser.", "labels": [], "entities": []}, {"text": "Due to this insight, we investigate the potential of using tools from the probabilistic CFG community to improve CCG parsing results.", "labels": [], "entities": [{"text": "CCG parsing", "start_pos": 113, "end_pos": 124, "type": "TASK", "confidence": 0.8324631750583649}]}, {"text": "The Petrov parser) uses latent variables to refine the grammar extracted from a corpus to improve accuracy, originally used to improve parsing results on the Penn treebank (PTB).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.998343825340271}, {"text": "Penn treebank (PTB)", "start_pos": 158, "end_pos": 177, "type": "DATASET", "confidence": 0.9638031482696533}]}, {"text": "We train the Petrov parser on CCGbank and achieve the best results to date on sentences from section 23 in terms of supertagging accuracy, PARSEVAL measures and dependency accuracy.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 30, "end_pos": 37, "type": "DATASET", "confidence": 0.9806835055351257}, {"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.9065182209014893}, {"text": "PARSEVAL measures", "start_pos": 139, "end_pos": 156, "type": "METRIC", "confidence": 0.9789933860301971}, {"text": "accuracy", "start_pos": 172, "end_pos": 180, "type": "METRIC", "confidence": 0.9371086955070496}]}, {"text": "These results should not be interpreted as proof that grammars extracted from the Penn treebank and from CCGbank are equivalent.", "labels": [], "entities": [{"text": "Penn treebank", "start_pos": 82, "end_pos": 95, "type": "DATASET", "confidence": 0.9922610223293304}, {"text": "CCGbank", "start_pos": 105, "end_pos": 112, "type": "DATASET", "confidence": 0.8689529895782471}]}, {"text": "Bos's system for building semantic representations from CCG derivations is only possible due to the categorial nature of CCG.", "labels": [], "entities": []}, {"text": "Furthermore, the long distance dependencies involved in extraction and coordination phenomena have a more natural representation in CCG.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments use CCGbank as the corpus and we use sections 02-21 for training (39603 sentences), 00 for development (1913 sentences) and 23 for testing (2407 sentences).", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 20, "end_pos": 27, "type": "DATASET", "confidence": 0.9741929769515991}]}, {"text": "CCGbank, in addition to the basic atoms S, N , NP and PP , also differentiates both the Sand NP atoms with features allowing more subtle distinctions.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9554455876350403}]}, {"text": "For example, declarative sentences are S[dcl], wh-questions are S[wq] and sentence fragments are S[f rg] (.", "labels": [], "entities": []}, {"text": "These features allow finer control of the use of combinatory rules in the resulting grammars.", "labels": [], "entities": []}, {"text": "However, this fine-grained control is exactly what the Petrov parser does automatically.", "labels": [], "entities": []}, {"text": "Therefore, we trained the Petrov parser twice, once on the original version of CCGbank (denoted \"Petrov\") and once on aversion of CCGbank without these features (denoted \"Petrov no feats\").", "labels": [], "entities": []}, {"text": "Furthermore, we will evaluate the parsers obtained after 0, 4, 5 and 6 training iterations (denoted I-0, I-4, I-5 and I-6).", "labels": [], "entities": []}, {"text": "When we evaluate on sets of sentences for which not all parsers return an analysis, we report the coverage (denoted \"Cover\").", "labels": [], "entities": [{"text": "coverage", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9816581010818481}, {"text": "Cover", "start_pos": 117, "end_pos": 122, "type": "METRIC", "confidence": 0.9747626781463623}]}, {"text": "We  Curran's evaluate script for dependency evaluation.", "labels": [], "entities": [{"text": "dependency evaluation", "start_pos": 33, "end_pos": 54, "type": "TASK", "confidence": 0.9262045323848724}]}, {"text": "To determine statistical significance, we obtain p-values from Bikel's randomized parsing evaluation comparator 6 , modified for use with tagging accuracy, F-score and dependency accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 146, "end_pos": 154, "type": "METRIC", "confidence": 0.9006690382957458}, {"text": "F-score", "start_pos": 156, "end_pos": 163, "type": "METRIC", "confidence": 0.9980644583702087}, {"text": "accuracy", "start_pos": 179, "end_pos": 187, "type": "METRIC", "confidence": 0.7182446122169495}]}, {"text": "Before evaluating the parse trees as a whole, we evaluate the categories assigned to words.", "labels": [], "entities": []}, {"text": "In the supertagging literature, POS tagging and supertagging are distinguished -POS tags are the traditional Penn treebank tags (e.g. NN, VBZ and DT) and supertags are CCG categories.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 32, "end_pos": 43, "type": "TASK", "confidence": 0.7726686596870422}, {"text": "Penn treebank tags", "start_pos": 109, "end_pos": 127, "type": "DATASET", "confidence": 0.9634819229443868}]}, {"text": "However, because the Petrov parser trained on CCGbank has no notion of Penn treebank POS tags, we can only evaluate the accuracy of the supertags.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 46, "end_pos": 53, "type": "DATASET", "confidence": 0.9689676761627197}, {"text": "Penn treebank POS tags", "start_pos": 71, "end_pos": 93, "type": "DATASET", "confidence": 0.9638713598251343}, {"text": "accuracy", "start_pos": 120, "end_pos": 128, "type": "METRIC", "confidence": 0.9991758465766907}]}, {"text": "The results are shown in figures 3 and 4 where the \"Accuracy\" column shows accuracy of the supertags against the CCGbank categories and the \"No feats\" column shows accuracy when features are ignored.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 52, "end_pos": 60, "type": "METRIC", "confidence": 0.9990122318267822}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9989078044891357}, {"text": "CCGbank categories", "start_pos": 113, "end_pos": 131, "type": "DATASET", "confidence": 0.9461729824542999}, {"text": "accuracy", "start_pos": 164, "end_pos": 172, "type": "METRIC", "confidence": 0.9989421963691711}]}, {"text": "Despite the lack of POS tags in the Petrov parser, we can see that it performs slightly better than the Clark and Curran parser.", "labels": [], "entities": [{"text": "POS", "start_pos": 20, "end_pos": 23, "type": "METRIC", "confidence": 0.9556877017021179}]}, {"text": "The difference inaccuracy is only statistically significant between Clark and Curran's Normal Form model ignoring features and the Petrov parser trained on CCGbank without features (p-value = 0.013).", "labels": [], "entities": []}, {"text": "In this section we evaluate the parsers using the traditional PARSEVAL measures which measure recall, precision and F-score on constituents in http://www.cis.upenn.edu/ dbikel/software.html both labeled and unlabeled versions.", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 62, "end_pos": 70, "type": "METRIC", "confidence": 0.6991124749183655}, {"text": "recall", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.9994574189186096}, {"text": "precision", "start_pos": 102, "end_pos": 111, "type": "METRIC", "confidence": 0.9991533756256104}, {"text": "F-score", "start_pos": 116, "end_pos": 123, "type": "METRIC", "confidence": 0.9990876913070679}]}, {"text": "In addition, we report a variant of the labeled PARSEVAL measures where we ignore the features on the categories.", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.8956971764564514}]}, {"text": "For reasons of brevity, we report the PAR-SEVAL measures for all sentences in sections 00 and 23, rather than for sentences of length is less than 40 or less than 100.", "labels": [], "entities": [{"text": "PAR-SEVAL", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9894281029701233}]}, {"text": "The results are essentially identical for those two sets of sentences.", "labels": [], "entities": []}, {"text": "gives the PARSEVAL measures on section 00 for Clark and Curran's two best models and the Petrov parser trained on the original CCGbank and the version without features after various numbers of training iterations.", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9972520470619202}, {"text": "CCGbank", "start_pos": 127, "end_pos": 134, "type": "DATASET", "confidence": 0.9772521257400513}]}, {"text": "gives the accuracies on section 23.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9939206838607788}]}, {"text": "In the case of Clark and Curran's hybrid model, the poor accuracy relative to the Petrov parsers can be attributed to the fact that this model chooses derivations based on the associated dependencies at the expense of constituent accuracy (see section 3.4).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9990297555923462}, {"text": "accuracy", "start_pos": 230, "end_pos": 238, "type": "METRIC", "confidence": 0.765009880065918}]}, {"text": "In the case of Clark and Curran's normal form model, the large difference between labeled and unlabeled accuracy is primarily due to the mislabeling of a small number of features (specifically, NP and NP).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9661464095115662}]}, {"text": "The labeled accuracies without features gives the results when features are disregarded.", "labels": [], "entities": []}, {"text": "Due to the similarity of the accuracies and the difference in the coverage between I-5 of the Petrov parser on CCGbank and I-6 of the Petrov parser on CCGbank without features, we reevaluate their results on only those sentences for which they both return derivations in figures 6 and 8.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 111, "end_pos": 118, "type": "DATASET", "confidence": 0.9488789439201355}]}, {"text": "These results show that the features in CCGbank actually inhibit accuracy (to a statistically significant degree in the case of unlabeled accuracy on section 00) when used as training data for the Petrov parser.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 40, "end_pos": 47, "type": "DATASET", "confidence": 0.924315333366394}, {"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9984012246131897}, {"text": "accuracy", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.967885434627533}]}, {"text": "gives a comparison between the Petrov parser trained on the Penn treebank and on CCGbank.", "labels": [], "entities": [{"text": "Penn treebank", "start_pos": 60, "end_pos": 73, "type": "DATASET", "confidence": 0.9938591718673706}, {"text": "CCGbank", "start_pos": 81, "end_pos": 88, "type": "DATASET", "confidence": 0.9876852035522461}]}, {"text": "These numbers should not be directly compared, but the similarity of the unlabeled measures indicates that the difference between the structure of the Penn treebank and CCGbank is not large.", "labels": [], "entities": [{"text": "Penn treebank", "start_pos": 151, "end_pos": 164, "type": "DATASET", "confidence": 0.9936716258525848}, {"text": "CCGbank", "start_pos": 169, "end_pos": 176, "type": "DATASET", "confidence": 0.671170175075531}]}, {"text": "The constituent-based PARSEVAL measures are simple to calculate from the output of the Petrov parser but the relationship of the PARSEVAL      scores to the quality of a parse is not entirely clear.", "labels": [], "entities": [{"text": "PARSEVAL", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.8556709885597229}]}, {"text": "For this reason, the word to word dependencies of categorial grammar parsers are often evaluated.", "labels": [], "entities": []}, {"text": "This evaluation is aided by the fact that in addition to the CCG derivation for each sentence, CCGbank also includes a set of dependencies.", "labels": [], "entities": []}, {"text": "Furthermore, extracting dependencies from a CCG derivation is well-established ().", "labels": [], "entities": []}, {"text": "A CCG derivation can be converted into dependencies by, first, determining which arguments go with which functors as specified by the CCG derivation.", "labels": [], "entities": []}, {"text": "This can be represented as in.", "labels": [], "entities": []}, {"text": "Although this is not difficult, some care must betaken with respect to punctuation and the conjunction rules.", "labels": [], "entities": []}, {"text": "Next, we reorient some of the edges according to information in the lexical categories.", "labels": [], "entities": []}, {"text": "A language for specifying these instructions using variables and indices is given in.", "labels": [], "entities": []}, {"text": "This process is shown in figures 1, 10 and 11 with the directions of the dependencies reversed from.", "labels": [], "entities": []}, {"text": "We used the CCG derivation to dependency converter generate included in the C&C tools package to convert the output of the Petrov parser to dependencies.", "labels": [], "entities": []}, {"text": "Other than a CCG derivation, their system requires only the lexicon of edge reorientation instructions and methods for converting the unrestricted rules of CCGbank into the argument-functor relations.", "labels": [], "entities": []}, {"text": "Important for the purpose of comparison, this system does not depend on their parser.", "labels": [], "entities": []}, {"text": "An unlabeled dependency is correct if the ordered pair of words is correct.", "labels": [], "entities": []}, {"text": "A labeled dependency is correct if the ordered pair of words is correct, the headword has the correct category and the position of the category that is the source of that edge is correct.", "labels": [], "entities": []}, {"text": "shows accuracies from the Petrov parser trained on CCGbank along with accuracies for the Clark and Curran parser.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 6, "end_pos": 16, "type": "METRIC", "confidence": 0.9870686531066895}, {"text": "CCGbank", "start_pos": 51, "end_pos": 58, "type": "DATASET", "confidence": 0.9922841191291809}, {"text": "accuracies", "start_pos": 70, "end_pos": 80, "type": "METRIC", "confidence": 0.9708685278892517}]}, {"text": "We only show accuracies for the Petrov parser trained on the original version of CCGbank because the dependency converter cannot currently generate dependencies for featureless derivations.", "labels": [], "entities": [{"text": "CCGbank", "start_pos": 81, "end_pos": 88, "type": "DATASET", "confidence": 0.9373599886894226}]}, {"text": "The relatively poor coverage of the Petrov parser is due to the failure of the dependency converter to output dependencies from valid CCG derivations.", "labels": [], "entities": []}, {"text": "However, the coverage of the dependency converter is actually lower when run on the gold standard derivations indicating that this coverage problem is not indicative of inaccuracies in the Petrov parser.", "labels": [], "entities": [{"text": "coverage", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9676263332366943}]}, {"text": "Due to the difference in coverage, we again evaluate the top two parsers on only those sentences that they both generate dependencies for and report those results in figures 13 and 14.", "labels": [], "entities": [{"text": "coverage", "start_pos": 25, "end_pos": 33, "type": "METRIC", "confidence": 0.9888713955879211}]}, {"text": "The Petrov parser has better results by a statistically significant margin for both labeled and unlabeled recall and unlabeled F-score.", "labels": [], "entities": [{"text": "recall", "start_pos": 106, "end_pos": 112, "type": "METRIC", "confidence": 0.9906631708145142}, {"text": "F-score", "start_pos": 127, "end_pos": 134, "type": "METRIC", "confidence": 0.9751046895980835}]}, {"text": "As a final evaluation, we compare the resources that are required to both train and parse with the Petrov parser on the Penn Treebank, the Petrov parser on the original version of CCGbank, the Petrov parser on CCGbank without features and the Clark and Curran parser using the two models.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 120, "end_pos": 133, "type": "DATASET", "confidence": 0.9951924979686737}, {"text": "CCGbank", "start_pos": 180, "end_pos": 187, "type": "DATASET", "confidence": 0.9625657200813293}]}, {"text": "All training and parsing was done on a 64-bit machine with 8 dual core 2.8 Ghz Opteron 8220 CPUs and 64GB of RAM.", "labels": [], "entities": [{"text": "parsing", "start_pos": 17, "end_pos": 24, "type": "TASK", "confidence": 0.9563514590263367}]}, {"text": "Our training times are much larger than those reported in Clark and Curran (2007) because we report the cumulative time spent on all CPUs rather than the maximum time spent on a CPU.", "labels": [], "entities": []}, {"text": "As can be seen, the Clark and Curran parser has similar training times, although significantly greater RAM requirements than the Petrov parsers.", "labels": [], "entities": [{"text": "RAM", "start_pos": 103, "end_pos": 106, "type": "METRIC", "confidence": 0.9996153116226196}]}, {"text": "In contrast, the Clark and Curran parser is significantly faster than the Petrov parsers, which we hypothesize to be attributed to the degree to which Clark and Curran have optimized their code, their use of C++ as opposed to Java and their use of a supertagger to prune the lexicon.", "labels": [], "entities": []}], "tableCaptions": []}