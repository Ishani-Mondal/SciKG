{"title": [{"text": "Improving Arabic-to-English Statistical Machine Translation by Reordering Post-verbal Subjects for Alignment", "labels": [], "entities": [{"text": "Improving Arabic-to-English Statistical Machine Translation", "start_pos": 0, "end_pos": 59, "type": "TASK", "confidence": 0.8926592588424682}, {"text": "Alignment", "start_pos": 99, "end_pos": 108, "type": "TASK", "confidence": 0.6642871499061584}]}], "abstractContent": [{"text": "We study the challenges raised by Ara-bic verb and subject detection and reordering in Statistical Machine Translation (SMT).", "labels": [], "entities": [{"text": "Ara-bic verb and subject detection", "start_pos": 34, "end_pos": 68, "type": "TASK", "confidence": 0.5781674206256866}, {"text": "Statistical Machine Translation (SMT)", "start_pos": 87, "end_pos": 124, "type": "TASK", "confidence": 0.8231709400812784}]}, {"text": "We show that post-verbal subject (VS) constructions are hard to translate because they have highly ambiguous reordering patterns when translated to En-glish.", "labels": [], "entities": []}, {"text": "In addition, implementing reordering is difficult because the boundaries of VS constructions are hard to detect accurately , even with a state-of-the-art Arabic dependency parser.", "labels": [], "entities": []}, {"text": "We therefore propose to reorder VS constructions into SV order for SMT word alignment only.", "labels": [], "entities": [{"text": "SMT word alignment", "start_pos": 67, "end_pos": 85, "type": "TASK", "confidence": 0.9163841009140015}]}, {"text": "This strategy significantly improves BLEU and TER scores, even on a strong large-scale baseline and despite noisy parses.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 37, "end_pos": 41, "type": "METRIC", "confidence": 0.9984297156333923}, {"text": "TER scores", "start_pos": 46, "end_pos": 56, "type": "METRIC", "confidence": 0.9714645147323608}]}], "introductionContent": [{"text": "Modern Standard Arabic (MSA) is a morphosyntactically complex language, with different phenomena from English, a fact that raises many interesting issues for natural language processing and Arabic-to-English statistical machine translation (SMT).", "labels": [], "entities": [{"text": "Modern Standard Arabic (MSA)", "start_pos": 0, "end_pos": 28, "type": "DATASET", "confidence": 0.8036831716696421}, {"text": "natural language processing", "start_pos": 158, "end_pos": 185, "type": "TASK", "confidence": 0.686510960261027}, {"text": "statistical machine translation (SMT)", "start_pos": 208, "end_pos": 245, "type": "TASK", "confidence": 0.8137248059113821}]}, {"text": "While comprehensive Arabic preprocessing schemes have been widely adopted for handling Arabic morphology in SMT (e.g.,,,), syntactic issues have not received as much attention by comparison (,,).", "labels": [], "entities": [{"text": "SMT", "start_pos": 108, "end_pos": 111, "type": "TASK", "confidence": 0.8739945292472839}]}, {"text": "Arabic verbal constructions are particularly challenging since subjects can occur in pre-verbal (SV), post-verbal (VS) or pro-dropped (\"null subject\") constructions.", "labels": [], "entities": []}, {"text": "As a result, training data for learning verbal construction translations is split between the different constructions and their patterns; and complex reordering schemas are needed in order to translate them into primarily pre-verbal subject languages (SVO) such as English.", "labels": [], "entities": [{"text": "learning verbal construction translations", "start_pos": 31, "end_pos": 72, "type": "TASK", "confidence": 0.6874375715851784}]}, {"text": "These issues are particularly problematic in phrase-based SMT (.", "labels": [], "entities": [{"text": "SMT", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.7783322930335999}]}, {"text": "Standard phrase-based SMT systems memorize phrasal translation of verb and subject constructions as observed in the training bitext.", "labels": [], "entities": [{"text": "SMT", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9340130090713501}, {"text": "phrasal translation of verb and subject constructions", "start_pos": 43, "end_pos": 96, "type": "TASK", "confidence": 0.8048018046787807}]}, {"text": "They do not capture any generalizations between occurrences in VS and SV orders, even for the same verbs.", "labels": [], "entities": []}, {"text": "In addition, their distance-based reordering models are not well suited to handling complex reordering operations which can include long distance dependencies, and may vary by context.", "labels": [], "entities": []}, {"text": "Despite these limitations, phrase-based SMT systems have achieved competitive results in Arabic-to-English benchmark evaluations.", "labels": [], "entities": [{"text": "SMT", "start_pos": 40, "end_pos": 43, "type": "TASK", "confidence": 0.7824172377586365}]}, {"text": "1 However, error analysis shows that verbs are still often dropped or incorrectly translated, and subjects are split or garbled in translation.", "labels": [], "entities": []}, {"text": "This suggests that better syntactic modeling should further improve SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.995111882686615}]}, {"text": "We attempt to get a better understanding of translation patterns for Arabic verb constructions, particularly VS constructions, by studying their occurrence and reordering patterns in a handaligned Arabic-English parallel treebank.", "labels": [], "entities": []}, {"text": "Our analysis shows that VS reordering rules are not straightforward and that SMT should therefore benefit from direct modeling of Arabic verb subject translation.", "labels": [], "entities": [{"text": "VS reordering", "start_pos": 24, "end_pos": 37, "type": "TASK", "confidence": 0.9577186405658722}, {"text": "SMT", "start_pos": 77, "end_pos": 80, "type": "TASK", "confidence": 0.9930464625358582}, {"text": "Arabic verb subject translation", "start_pos": 130, "end_pos": 161, "type": "TASK", "confidence": 0.5667996034026146}]}, {"text": "In order to detect VS constructions, we use our state-of-the-art Arabic dependency parser, which is essentially the CATIBEX baseline in our subsequent parsing work in, and is further described there.", "labels": [], "entities": [{"text": "VS constructions", "start_pos": 19, "end_pos": 35, "type": "TASK", "confidence": 0.8943824768066406}]}, {"text": "We show that VS subjects and their exact boundaries are hard to identify accurately.", "labels": [], "entities": []}, {"text": "Given the noise in VS detection, existing strategies for source-side reordering (e.g.,,,) or using de-: How are Arabic SV and VS translated in the manually word-aligned Arabic-English parallel treebank?", "labels": [], "entities": [{"text": "VS detection", "start_pos": 19, "end_pos": 31, "type": "TASK", "confidence": 0.9845616519451141}]}, {"text": "We check whether V and S are translated in a \"monotone\" or \"inverted\" order for all VS and SV constructions.", "labels": [], "entities": []}, {"text": "\"Overlap\" represents instances where translations of the Arabic verb and subject have some English words in common, and are not monotone nor inverted.", "labels": [], "entities": []}, {"text": "gold) are not effective at this stage.", "labels": [], "entities": []}, {"text": "While these approaches have been successful for language pairs such as German-English for which syntactic parsers are more developed and relevant reordering patterns might be less ambiguous, their impact potential on Arabic-English translation is still unclear.", "labels": [], "entities": []}, {"text": "In this work, we focus on VS constructions only, and propose anew strategy in order to benefit from their noisy detection: for the word alignment stage only, we reorder phrases detected as VS constructions into an SV order.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 131, "end_pos": 145, "type": "TASK", "confidence": 0.730170801281929}]}, {"text": "Then, for phrase extraction, weight optimization and decoding, we use the original (non-reordered) text.", "labels": [], "entities": [{"text": "phrase extraction", "start_pos": 10, "end_pos": 27, "type": "TASK", "confidence": 0.8892461657524109}, {"text": "weight optimization", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.8031653165817261}]}, {"text": "This approach significantly improves both BLEU and TER on top of strong medium and large-scale phrase-based SMT baselines.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 42, "end_pos": 46, "type": "METRIC", "confidence": 0.9958135485649109}, {"text": "TER", "start_pos": 51, "end_pos": 54, "type": "METRIC", "confidence": 0.9713071584701538}]}], "datasetContent": [{"text": "We use the open-source Moses toolkit ( ) to build two phrase-based SMT systems trained on two different data conditions: \u2022 medium-scale the bitext consists of 12M words on the Arabic side (LDC2007E103).", "labels": [], "entities": [{"text": "SMT", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.8510516881942749}]}, {"text": "The language model is trained on the English side of the large bitext.", "labels": [], "entities": []}, {"text": "\u2022 large-scale the bitext consists of several newswire LDC corpora, and has 64M words on the Arabic side.", "labels": [], "entities": []}, {"text": "The language model is trained on the English side of the bitext augmented with Gigaword data.", "labels": [], "entities": [{"text": "Gigaword data", "start_pos": 79, "end_pos": 92, "type": "DATASET", "confidence": 0.8928931653499603}]}, {"text": "Except from this difference in training data, the two systems are identical.", "labels": [], "entities": []}, {"text": "They use a standard phrase-based architecture.", "labels": [], "entities": []}, {"text": "The parallel corpus is word-aligned using the GIZA++ (, which sequentially learns word alignments for the IBM1, HMM, IBM3 and IBM4 models.", "labels": [], "entities": []}, {"text": "The resulting alignments in both translation directions are intersected and augmented using the grow-diag-final-and heuristic . Phrase translations of up to 10 words are extracted in the Moses phrase-table.", "labels": [], "entities": []}, {"text": "We apply statistical significance tests to prune unreliable phrase-pairs and score remaining phrase-table entries).", "labels": [], "entities": []}, {"text": "We use a 5-gram language model with modified Kneser-Ney smoothing.", "labels": [], "entities": []}, {"text": "Feature weights are tuned to maximize BLEU on the NIST MT06 test set.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 38, "end_pos": 42, "type": "METRIC", "confidence": 0.9995560050010681}, {"text": "NIST MT06 test set", "start_pos": 50, "end_pos": 68, "type": "DATASET", "confidence": 0.9036462008953094}]}, {"text": "For all systems, the English data is tokenized using simple punctuation-based rules.", "labels": [], "entities": []}, {"text": "The Arabic side is segmented according to the Arabic Treebank (PATB3) tokenization scheme () using the MADA+TOKAN morphological analyzer and tokenizer).", "labels": [], "entities": [{"text": "Arabic Treebank (PATB3)", "start_pos": 46, "end_pos": 69, "type": "DATASET", "confidence": 0.9133737087249756}]}, {"text": "MADA-produced Arabic lemmas are used for word alignment.", "labels": [], "entities": [{"text": "MADA-produced Arabic lemmas", "start_pos": 0, "end_pos": 27, "type": "DATASET", "confidence": 0.8366814057032267}, {"text": "word alignment", "start_pos": 41, "end_pos": 55, "type": "TASK", "confidence": 0.8108720183372498}]}], "tableCaptions": [{"text": " Table 1: How are Arabic SV and VS translated in  the manually word-aligned Arabic-English paral- lel treebank? We check whether V and S are trans- lated in a \"monotone\" or \"inverted\" order for all  VS and SV constructions. \"Overlap\" represents  instances where translations of the Arabic verb  and subject have some English words in common,  and are not monotone nor inverted.", "labels": [], "entities": []}, {"text": " Table 2: Precision, Recall and F-scores for con- structions of Arabic verbs and their subjects, eval- uated on our development part of PATB3.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9989023208618164}, {"text": "Recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9983792304992676}, {"text": "F-scores", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9977781176567078}, {"text": "PATB3", "start_pos": 136, "end_pos": 141, "type": "DATASET", "confidence": 0.9414463639259338}]}, {"text": " Table 3: Evaluation on all test sets: on the total  of 4432 test sentences, improvements are statisti- cally significant at the 99% level using bootstrap  resampling (Koehn, 2004)", "labels": [], "entities": []}, {"text": " Table 4: VS reordering improves BLEU and TER scores in almost all test conditions on 5 test sets, 2  metrics, and 2 MT systems", "labels": [], "entities": [{"text": "VS", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.6986820101737976}, {"text": "BLEU", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.9990173578262329}, {"text": "TER", "start_pos": 42, "end_pos": 45, "type": "METRIC", "confidence": 0.9959000945091248}]}]}