{"title": [{"text": "Automatic Sanskrit Segmentizer Using Finite State Transducers", "labels": [], "entities": [{"text": "Sanskrit Segmentizer", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.706227034330368}]}], "abstractContent": [{"text": "In this paper, we propose a novel method for automatic segmentation of a Sanskrit string into different words.", "labels": [], "entities": [{"text": "automatic segmentation of a Sanskrit string", "start_pos": 45, "end_pos": 88, "type": "TASK", "confidence": 0.8146474709113439}]}, {"text": "The input for our segmentizer is a Sanskrit string either encoded as a Unicode string or as a Ro-man transliterated string and the output is a set of possible splits with weights associated with each of them.", "labels": [], "entities": []}, {"text": "We followed two different approaches to segment a Sanskrit text using sandhi 1 rules extracted from a parallel corpus of manually sandhi split text.", "labels": [], "entities": []}, {"text": "While the first approach augments the finite state transducer used to analyze Sanskrit morphology and traverse it to segment a word, the second approach generates all possible segmentations and validates each constituent using a morph an-alyzer.", "labels": [], "entities": []}], "introductionContent": [{"text": "Sanskrit has a rich tradition of oral transmission of texts and this process causes the text to undergo euphonic changes at the word boundaries.", "labels": [], "entities": []}, {"text": "In oral transmission, the text is predominantly spoken as a continuous speech.", "labels": [], "entities": []}, {"text": "However, continuous speech makes the text ambiguous.", "labels": [], "entities": []}, {"text": "To overcome this problem, there is also a tradition of reciting the pada-p\u00af at . ha (recitation of words) in addition to the recitation of a sam . hit\u00af a (a continuous sandhied text).", "labels": [], "entities": []}, {"text": "In the written form, because of the dominance of oral transmission, the text is written as a continuous string of letters rather than a sequence of words.", "labels": [], "entities": []}, {"text": "Thus, the Sanskrit texts consist of a very long sequence of phonemes, with the word boundaries having undergone euphonic changes.", "labels": [], "entities": []}, {"text": "This makes it difficult to split a continuous string into words and process the text automatically.", "labels": [], "entities": []}, {"text": "Sanskrit words are mostly analyzed by building a finite state transducer).", "labels": [], "entities": []}, {"text": "In the first approach, this transducer was modified by linking the final states to appropriate intermediate states incorporating the sandhi rules.", "labels": [], "entities": []}, {"text": "This approach then allows one to traverse the string from left to right and generate all and only possible splits that are morphologically valid.", "labels": [], "entities": []}, {"text": "The second approach is very closely based on the Optimality Theory () where we generate all the possible splits fora word and validate each using a morphological analyzer.", "labels": [], "entities": []}, {"text": "We use one of the fastest morphological analyzers available viz.", "labels": [], "entities": []}, {"text": "the one developed by Apertium group 2 . The splits that are not validated are pruned out.", "labels": [], "entities": [{"text": "Apertium group 2", "start_pos": 21, "end_pos": 37, "type": "DATASET", "confidence": 0.9351934591929117}]}, {"text": "Based on the number of times the first answer is correct, we achieved an accuracy of around 92% using the second approach while the first approach performed with around 71% accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.999700665473938}, {"text": "accuracy", "start_pos": 173, "end_pos": 181, "type": "METRIC", "confidence": 0.9973540306091309}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Complete rank-wise Distribution.", "labels": [], "entities": []}]}