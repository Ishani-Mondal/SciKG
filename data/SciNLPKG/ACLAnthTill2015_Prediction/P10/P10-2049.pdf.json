{"title": [{"text": "Using Anaphora Resolution to Improve Opinion Target Identification in Movie Reviews", "labels": [], "entities": [{"text": "Anaphora Resolution", "start_pos": 6, "end_pos": 25, "type": "TASK", "confidence": 0.6326664090156555}, {"text": "Improve Opinion Target Identification in Movie Reviews", "start_pos": 29, "end_pos": 83, "type": "TASK", "confidence": 0.7550332375935146}]}], "abstractContent": [{"text": "Current work on automatic opinion mining has ignored opinion targets expressed by anaphorical pronouns, thereby missing a significant number of opinion targets.", "labels": [], "entities": [{"text": "automatic opinion mining", "start_pos": 16, "end_pos": 40, "type": "TASK", "confidence": 0.6462930142879486}]}, {"text": "In this paper we empirically evaluate whether using an off-the-shelf anaphora resolution algorithm can improve the performance of a baseline opinion mining system.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 141, "end_pos": 155, "type": "TASK", "confidence": 0.679119661450386}]}, {"text": "We present an analysis based on two different anaphora resolution systems.", "labels": [], "entities": []}, {"text": "Our experiments on a movie review corpus demonstrate , that an unsupervised anaphora resolution algorithm significantly improves the opinion target extraction.", "labels": [], "entities": [{"text": "anaphora resolution", "start_pos": 76, "end_pos": 95, "type": "TASK", "confidence": 0.7328188121318817}, {"text": "opinion target extraction", "start_pos": 133, "end_pos": 158, "type": "TASK", "confidence": 0.7347392439842224}]}, {"text": "We furthermore suggest domain and task specific extensions to an off-the-shelf algorithm which in turn yield significant improvements.", "labels": [], "entities": []}], "introductionContent": [{"text": "Over the last years the task of opinion mining (OM) has been the topic of many publications.", "labels": [], "entities": [{"text": "opinion mining (OM)", "start_pos": 32, "end_pos": 51, "type": "TASK", "confidence": 0.8865651607513427}]}, {"text": "It has been approached with different goals in mind: Some research strived to perform subjectivity analysis at the document or sentence level, without focusing on what the individual opinions uttered in the document are about.", "labels": [], "entities": []}, {"text": "Other approaches focused on extracting individual opinion words or phrases and what they are about.", "labels": [], "entities": [{"text": "extracting individual opinion words or phrases", "start_pos": 28, "end_pos": 74, "type": "TASK", "confidence": 0.846918652455012}]}, {"text": "This aboutness has been referred to as the opinion target or opinion topic in the literature from the field.", "labels": [], "entities": []}, {"text": "In this work our goal is to extract opinion target -opinion word pairs from sentences from movie reviews.", "labels": [], "entities": [{"text": "extract opinion target -opinion word pairs from sentences from movie reviews", "start_pos": 28, "end_pos": 104, "type": "TASK", "confidence": 0.6905840610464414}]}, {"text": "A challenge which is frequently encountered in text mining tasks at this level of granularity is, that entities are being referred to by anaphora.", "labels": [], "entities": [{"text": "text mining tasks", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.8264951308568319}]}, {"text": "In the task of OM, it can therefore also be necessary to analyze more than the content of one individual sentence when extracting opinion targets.", "labels": [], "entities": [{"text": "OM", "start_pos": 15, "end_pos": 17, "type": "TASK", "confidence": 0.9879065752029419}]}, {"text": "Consider this example sentence: \"Simply put, it's unfathomable that this movie cracks the Top 250.", "labels": [], "entities": []}, {"text": "It is absolutely awful.\".", "labels": [], "entities": []}, {"text": "If one wants to extract what the opinion in the second sentence is about, an algorithm which resolves the anaphoric reference to the opinion target is required.", "labels": [], "entities": []}, {"text": "The extraction of such anaphoric opinion targets has been noted as an open issue multiple times in the OM context (.", "labels": [], "entities": [{"text": "OM context", "start_pos": 103, "end_pos": 113, "type": "TASK", "confidence": 0.8363088071346283}]}, {"text": "It is not a marginal phenomenon, since report that in their data, 14% of the opinion targets are pronouns.", "labels": [], "entities": []}, {"text": "However, the task of resolving anaphora to mine opinion targets has not been addressed and evaluated yet to the best of our knowledge.", "labels": [], "entities": []}, {"text": "In this work, we investigate whether anaphora resolution (AR) can be successfully integrated into an OM algorithm and whether we can achieve an improvement regarding the OM in doing so.", "labels": [], "entities": [{"text": "anaphora resolution (AR)", "start_pos": 37, "end_pos": 61, "type": "METRIC", "confidence": 0.6689573287963867}]}, {"text": "This paper is structured as follows: Section 2 discusses the related work on opinion target identification and OM on movie reviews.", "labels": [], "entities": [{"text": "opinion target identification", "start_pos": 77, "end_pos": 106, "type": "TASK", "confidence": 0.6901243329048157}, {"text": "OM on movie reviews", "start_pos": 111, "end_pos": 130, "type": "TASK", "confidence": 0.6864635944366455}]}, {"text": "Section 3 outlines the OM algorithm we employed by us, while in Section 4 we discuss two different algorithms for AR which we experiment with.", "labels": [], "entities": []}, {"text": "Finally, in Section 5 we present our experimental work including error analysis and discussion, and we conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "Currently the only freely available dataset annotated with opinions including annotated anaphoric opinion targets is a corpus of movie reviews by. describe a collection of product reviews in which anaphoric opinion targets are also annotated, but it is not available to the public (yet).", "labels": [], "entities": []}, {"text": "used a subset of the dataset they published (1829 documents), namely 1100 documents, however they do not state which documents comprise this subset used in their evaluation.", "labels": [], "entities": []}, {"text": "In our experiments, we therefore use the complete dataset available, detailed in.", "labels": [], "entities": []}, {"text": "As shown, roughly 9.5% of the opinion targets are referred to by pronouns.", "labels": [], "entities": []}, {"text": "outlines detailed statistics on which pronouns occur as opinion targets.", "labels": [], "entities": []}, {"text": "To integrate AR in the OM algorithm, we add the antecedents of the pronouns annotated as opinion targets to the target candidate list.", "labels": [], "entities": [{"text": "AR", "start_pos": 13, "end_pos": 15, "type": "METRIC", "confidence": 0.935599148273468}, {"text": "OM", "start_pos": 23, "end_pos": 25, "type": "TASK", "confidence": 0.8804587125778198}]}, {"text": "Then we extract the dependency paths connecting pronouns and opinion words and add them to the list of valid paths.", "labels": [], "entities": []}, {"text": "When we run the algorithm, we extract anaphora which were resolved, if they occur with a valid dependency path to an opinion word.", "labels": [], "entities": []}, {"text": "In such a case, the anaphor is substituted for its antecedent and thus extracted as part of an opinion target -opinion word pair.", "labels": [], "entities": []}, {"text": "To reproduce the system by, we substitute the cast and crew list employed by them (see Section 3.2), with a NER component ().", "labels": [], "entities": []}, {"text": "One aspect regarding the extraction of opinion target -opinion word pairs remains open in: The dependency paths only identify connections between pairs of single words.", "labels": [], "entities": [{"text": "extraction of opinion target -opinion word pairs", "start_pos": 25, "end_pos": 73, "type": "TASK", "confidence": 0.7394170016050339}]}, {"text": "However, almost 50% of the opinion target candidates are multiword expressions.", "labels": [], "entities": []}, {"text": "do not explain how they extract multiword opinion targets with the dependency paths.", "labels": [], "entities": []}, {"text": "In our experiments, we require a dependency path to be found to each word of a multiword target candidate for it to be extracted.", "labels": [], "entities": []}, {"text": "Furthermore, do not state whether in their evaluation annotated multiword targets are treated as a single unit which needs to be extracted, or whether a partial matching is employed in such cases.", "labels": [], "entities": []}, {"text": "We require all individual words of a multiword expression to be extracted by the algorithm.", "labels": [], "entities": []}, {"text": "As mentioned above, the dependency path based approach will only identify connections between pairs of single words.", "labels": [], "entities": []}, {"text": "We therefore employ a merging step, in which we combine adjacent opinion targets to a multiword expression.", "labels": [], "entities": []}, {"text": "We have compiled two result sets: shows the results of the overall OM in a five-fold cross-validation.", "labels": [], "entities": [{"text": "OM", "start_pos": 67, "end_pos": 69, "type": "TASK", "confidence": 0.9384990930557251}]}, {"text": "gives a detailed overview of the AR for opinion target identification summed up overall folds.", "labels": [], "entities": [{"text": "AR", "start_pos": 33, "end_pos": 35, "type": "METRIC", "confidence": 0.9498600363731384}, {"text": "opinion target identification", "start_pos": 40, "end_pos": 69, "type": "TASK", "confidence": 0.6464723845322927}]}, {"text": "In, a true positive refers to an extracted pronoun which was annotated as an opinion target and is resolved to the correct antecedent.", "labels": [], "entities": []}, {"text": "A false positive subsumes two error classes: A pronoun which was not annotated as an opinion target but extracted as such, or a pronoun which is resolved to an incorrect antecedent.", "labels": [], "entities": []}, {"text": "As shown in, the recall of our reimplementation is slightly higher than the recall reported in.", "labels": [], "entities": [{"text": "recall", "start_pos": 17, "end_pos": 23, "type": "METRIC", "confidence": 0.9996448755264282}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9909150004386902}]}, {"text": "However, our precision and thus f-measure are lower.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.9998612403869629}, {"text": "f-measure", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9549935460090637}]}, {"text": "This can be attributed to the different document sets used in our experiments (see Section 3.1), or our substitution of the list of peoples' names with the NER component, or differences regarding the evaluation strategy as mentioned above.", "labels": [], "entities": []}, {"text": "We observe that the MARS algorithm yields an improvement regarding recall compared to the baseline system.", "labels": [], "entities": [{"text": "MARS", "start_pos": 20, "end_pos": 24, "type": "METRIC", "confidence": 0.6425396203994751}, {"text": "recall", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.9991863369941711}]}, {"text": "However, it also extracts a high number of false positives for both the personal and impersonal / demonstrative pronouns.", "labels": [], "entities": []}, {"text": "This is due to the fact that the MARS algorithm is designed for robustness and always resolves a pronoun to an antecedent.", "labels": [], "entities": []}, {"text": "CogNIAC in its off-the-shelf configuration already yields significant improvements over the baseline regarding f-measure 2 . Our CogNIAC extension improves recall slightly in comparison to the off-the-shelf system.", "labels": [], "entities": [{"text": "recall", "start_pos": 156, "end_pos": 162, "type": "METRIC", "confidence": 0.9995712637901306}]}, {"text": "As shown in, the algorithm extracts impersonal and demonstrative pronouns with lower precision than personal pronouns.", "labels": [], "entities": [{"text": "precision", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.9956132173538208}]}, {"text": "Our error analysis shows that this is mostly due to the Person / Location / Organization classification of the CogNIAC implementation.", "labels": [], "entities": []}, {"text": "The names of actors and movies are thus often misclassified.", "labels": [], "entities": []}, {"text": "Extension mitigates this problem, since it increases precision, while not affecting recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 53, "end_pos": 62, "type": "METRIC", "confidence": 0.9991140961647034}, {"text": "recall", "start_pos": 84, "end_pos": 90, "type": "METRIC", "confidence": 0.9969889521598816}]}, {"text": "The overall improvement of our extensions [id] + is however not statistically significant in comparison to off-the-shelf CogNIAC.", "labels": [], "entities": []}, {"text": "Our extensions and in combination with each increase recall at the expense of precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 53, "end_pos": 59, "type": "METRIC", "confidence": 0.9996678829193115}, {"text": "precision", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9996201992034912}]}, {"text": "The improvement in f-measure of CogNIAC [id] + over the off-the-shelf system is statistically significant.", "labels": [], "entities": [{"text": "f-measure", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9622823596000671}]}, {"text": "The best overall results regarding f-measure are reached if we combine all our extensions of the CogNIAC algorithm.", "labels": [], "entities": []}, {"text": "The results of this configuration show that the positive effects of extensions and are complemen-  tary regarding the extraction of impersonal and demonstrative pronouns.", "labels": [], "entities": []}, {"text": "This configuration yields statistically significant improvements regarding fmeasure over the off-the-shelf CogNIAC configuration, while also having the overall highest recall.", "labels": [], "entities": [{"text": "recall", "start_pos": 168, "end_pos": 174, "type": "METRIC", "confidence": 0.9992498755455017}]}], "tableCaptions": [{"text": " Table 1. As  shown, roughly 9.5% of the opinion targets are re- ferred to by pronouns.", "labels": [], "entities": []}, {"text": " Table 2: Pronouns as Opinion Targets", "labels": [], "entities": []}, {"text": " Table 3: Op. Target -Op. Word Pair Extraction", "labels": [], "entities": [{"text": "Word Pair Extraction", "start_pos": 26, "end_pos": 46, "type": "TASK", "confidence": 0.6429007748762766}]}, {"text": " Table 4: Results of AR for Opinion Targets", "labels": [], "entities": [{"text": "AR", "start_pos": 21, "end_pos": 23, "type": "TASK", "confidence": 0.7863757014274597}]}]}