{"title": [{"text": "Bootstrapping Semantic Analyzers from Non-Contradictory Texts", "labels": [], "entities": []}], "abstractContent": [{"text": "We argue that groups of unannotated texts with overlapping and non-contradictory semantics represent a valuable source of information for learning semantic representations.", "labels": [], "entities": [{"text": "learning semantic representations", "start_pos": 138, "end_pos": 171, "type": "TASK", "confidence": 0.7098182241121928}]}, {"text": "A simple and efficient inference method recursively induces joint semantic representations for each group and discovers correspondence between lexical entries and latent semantic concepts.", "labels": [], "entities": []}, {"text": "We consider the generative semantics-text correspondence model (Liang et al., 2009) and demonstrate that exploiting the non-contradiction relation between texts leads to substantial improvements over natural baselines on a problem of analyzing human-written weather forecasts.", "labels": [], "entities": [{"text": "generative semantics-text correspondence", "start_pos": 16, "end_pos": 56, "type": "TASK", "confidence": 0.9279662569363912}, {"text": "analyzing human-written weather forecasts", "start_pos": 234, "end_pos": 275, "type": "TASK", "confidence": 0.7001286596059799}]}], "introductionContent": [{"text": "In recent years, there has been increasing interest in statistical approaches to semantic parsing.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 81, "end_pos": 97, "type": "TASK", "confidence": 0.871226578950882}]}, {"text": "However, most of this research has focused on supervised methods requiring large amounts of labeled data.", "labels": [], "entities": []}, {"text": "The supervision was either given in the form of meaning representations aligned with sentences or in a somewhat more relaxed form, such as lists of candidate meanings for each sentence or formal representations of the described world state for each text (.", "labels": [], "entities": []}, {"text": "Such annotated resources are scarce and expensive to create, motivating the need for unsupervised or semi-supervised techniques (.", "labels": [], "entities": []}, {"text": "However, unsupervised methods have their own challenges: they are not always able to discover semantic equivalences of lexical entries or logical forms or, on the contrary, cluster semantically different or even opposite expressions).", "labels": [], "entities": []}, {"text": "Unsupervised approaches can only rely on distributional similarity of contexts to decide on semantic relatedness of terms, but this information maybe sparse and not reliable).", "labels": [], "entities": []}, {"text": "For example, when analyzing weather forecasts it is very hard to discover in an unsupervised way which of the expressions among \"south wind\", \"wind from west\" and \"southerly\" denote the same wind direction and which are not, as they all have a very similar distribution of their contexts.", "labels": [], "entities": []}, {"text": "The same challenges affect the problem of identification of argument roles and predicates.", "labels": [], "entities": [{"text": "identification of argument roles and predicates", "start_pos": 42, "end_pos": 89, "type": "TASK", "confidence": 0.8061083257198334}]}, {"text": "In this paper, we show that groups of unannotated texts with overlapping and non-contradictory semantics provide a valuable source of information.", "labels": [], "entities": []}, {"text": "This form of weak supervision helps to discover implicit clustering of lexical entries and predicates, which presents a challenge for purely unsupervised techniques.", "labels": [], "entities": []}, {"text": "We assume that each text in a group is independently generated from a full latent semantic state corresponding to the group.", "labels": [], "entities": []}, {"text": "Importantly, the texts in each group do not have to be paraphrases of each other, as they can verbalize only specific parts (aspects) of the full semantic state, yet statements about the same aspects must not contradict each other.", "labels": [], "entities": []}, {"text": "Simultaneous inference of the semantic state for the noncontradictory and semantically overlapping documents would restrict the space of compatible hypotheses, and, intuitively, 'easier' texts in a group will help to analyze the 'harder' ones.", "labels": [], "entities": []}, {"text": "As an illustration of why this weak supervision maybe valuable, consider a group of two non-contradictory texts, where one text mentions \"2.2 bn GBP decrease in profit\", whereas another one includes a passage \"profit fell by 2.2 billion pounds\".", "labels": [], "entities": []}, {"text": "Even if the model has not observed The sky is heavy.", "labels": [], "entities": []}, {"text": "It is 70 F now, temperature (time = 6-21; min = 64, max = 75, mean = 70) windDir(time=6-21,mode=S) gust(time=6-21, min=0, max=29, mean=25) precipPotential(time=6-21,min=20,max=32,mean=26) thunderChance(time=6-21,mode=chance) freezingRainChance(time=17-30,mode=--) sleetChance(time='6-21',mode=--) skycover(time=6-21,bucket=75-100) rainChance(time=6-21,mode=chance) windChill(time=6-21,min=0,max=0,mean=0) ......", "labels": [], "entities": []}, {"text": "the word \"fell\" before, it is likely to align these phrases to the same semantic form because of similarity of their arguments.", "labels": [], "entities": []}, {"text": "And this alignment would suggest that \"fell\" and \"decrease\" refer to the same process, and should be clustered together.", "labels": [], "entities": []}, {"text": "This would not happen for the pair \"fell\" and \"increase\" as similarity of their arguments would normally entail contradiction.", "labels": [], "entities": [{"text": "similarity", "start_pos": 60, "end_pos": 70, "type": "METRIC", "confidence": 0.958031177520752}]}, {"text": "Similarly, in the example mentioned earlier, when describing a forecast fora day with expected south winds, texts in the group can use either \"south wind\" or \"southerly\" to indicate this fact but no texts would verbalize it as \"wind from west\", and therefore these expressions will be assigned to different semantic clusters.", "labels": [], "entities": []}, {"text": "However, it is important to note that the phrase \"wind from west\" may still appear in the texts, but in reference to other time periods, underlying the need for modeling alignment between grouped texts and their latent meaning representation.", "labels": [], "entities": []}, {"text": "As much of the human knowledge is redescribed multiple times, we believe that noncontradictory and semantically overlapping texts are often easy to obtain.", "labels": [], "entities": []}, {"text": "For example, consider semantic analysis of news articles or biographies.", "labels": [], "entities": [{"text": "semantic analysis of news articles or biographies", "start_pos": 22, "end_pos": 71, "type": "TASK", "confidence": 0.8924997193472726}]}, {"text": "In both cases we can find groups of documents referring to the same events or persons, and though they will probably focus on different aspects and have different subjective passages, they are likely to agree on the core information.", "labels": [], "entities": []}, {"text": "Alternatively, if such groupings are not available, it may still be easier to give each semantic representation (or a state) to multiple annotators and ask each of them to provide a textual description, instead of annotating texts with semantic expressions.", "labels": [], "entities": []}, {"text": "The state can be communicated to them in a visual or audio form (e.g., as a picture or a short video clip) ensuring that their interpretations are consistent.", "labels": [], "entities": []}, {"text": "Unsupervised learning with shared latent semantic representations presents its own challenges, as exact inference requires marginalization over possible assignments of the latent semantic state, consequently, introducing non-local statistical dependencies between the decisions about the semantic structure of each text.", "labels": [], "entities": []}, {"text": "We propose a simple and fairly general approximate inference algorithm for probabilistic models of semantics which is efficient for the considered model, and achieves favorable results in our experiments.", "labels": [], "entities": []}, {"text": "In this paper, we do not consider models which aim to produce complete formal meaning of text, instead focusing on a simpler problem studied in ().", "labels": [], "entities": []}, {"text": "They investigate grounded language acquisition set-up and assume that semantics (world state) can be represented as a set of records each consisting of a set of fields.", "labels": [], "entities": [{"text": "grounded language acquisition", "start_pos": 17, "end_pos": 46, "type": "TASK", "confidence": 0.6527725954850515}]}, {"text": "Their model segments text into utterances and identifies records, fields and field values discussed in each utterance.", "labels": [], "entities": []}, {"text": "Therefore, one can think of this problem as an extension of the semantic role labeling problem, where predicates (i.e. records in our notation) and their arguments should be identified in text, but here arguments are not only assigned to a specific role (field) but also mapped to an underlying equivalence class (field value).", "labels": [], "entities": [{"text": "semantic role labeling problem", "start_pos": 64, "end_pos": 94, "type": "TASK", "confidence": 0.7370600551366806}]}, {"text": "For example, in the weather forecast domain field sky cover should get the same value given expressions \"overcast\" and \"very cloudy\" but a different one if the expres-sions are \"clear\" or \"sunny\".", "labels": [], "entities": []}, {"text": "This model is hard to evaluate directly as text does not provide information about all the fields and does not necessarily provide it at the sufficient granularity level.", "labels": [], "entities": []}, {"text": "Therefore, it is natural to evaluate their model on the database-text alignment problem, i.e. measuring how well the model predicts the alignment between the text and the observable records describing the entire world state.", "labels": [], "entities": [{"text": "database-text alignment", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.7584051191806793}]}, {"text": "We follow their set-up, but assume that instead of having access to the full semantic state for every training example, we have a very small amount of data annotated with semantic states and a larger number of unannotated texts with noncontradictory semantics.", "labels": [], "entities": []}, {"text": "We study our set-up on the weather forecast data () where the original textual weather forecasts were complemented by additional forecasts describing the same weather states (see for an example).", "labels": [], "entities": []}, {"text": "The average overlap between the verbalized fields in each group of noncontradictory forecasts was below 35%, and more than 60% of fields are mentioned only in a single forecast from a group.", "labels": [], "entities": [{"text": "overlap", "start_pos": 12, "end_pos": 19, "type": "METRIC", "confidence": 0.9560964107513428}]}, {"text": "Our model, learned from 100 labeled forecasts and 259 groups of unannotated non-contradictory forecasts (750 texts in total), achieved 73.9% F 1 . This compares favorably with 69.1% shown by a semi-supervised learning approach, though, as expected, does not reach the score of the model which, in training, observed semantics states for all the 750 documents (77.7% F 1 ).", "labels": [], "entities": [{"text": "F 1", "start_pos": 141, "end_pos": 144, "type": "METRIC", "confidence": 0.9965196847915649}, {"text": "F 1 )", "start_pos": 366, "end_pos": 371, "type": "METRIC", "confidence": 0.9712714354197184}]}, {"text": "The rest of the paper is structured as follows.", "labels": [], "entities": []}, {"text": "In section 2 we describe our inference algorithm for groups of non-contradictory documents.", "labels": [], "entities": []}, {"text": "Section 3 redescribes the semantics-text correspondence model () in the context of our learning scenario.", "labels": [], "entities": []}, {"text": "In section 4 we provide an empirical evaluation of the proposed method.", "labels": [], "entities": []}, {"text": "We conclude in section 5 with an examination of additional related work.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we consider the semi-supervised set-up, and present evaluation of our approach on on the problem of aligning weather forecast reports to the formal representation of weather.", "labels": [], "entities": []}, {"text": "To perform the experiments we used a subset of the weather dataset introduced in ().", "labels": [], "entities": []}, {"text": "The original dataset contains 22,146 texts of 28.7 words on average, there are 12 types of records (predicates) and 36.0 records per forecast on average.", "labels": [], "entities": []}, {"text": "We randomly chose 100 texts along with their world states to be used as the labeled data.", "labels": [], "entities": []}, {"text": "To produce groups of noncontradictory texts we have randomly selected a subset of weather states, represented them in a visual form (icons accompanied by numerical and symbolic parameters) and then manually annotated these illustrations.", "labels": [], "entities": []}, {"text": "These newly-produced forecasts, when combined with the original texts, resulted in 259 groups of non-contradictory texts (650 texts, 2.5 texts per group).", "labels": [], "entities": []}, {"text": "An example of such a group is given in.", "labels": [], "entities": []}, {"text": "The dataset is relatively noisy: there are inconsistencies due to annotation mistakes (e.g., number distortions), or due to different perception of the weather by the annotators (e.g., expressions such as 'warm' or 'cold' are subjective).", "labels": [], "entities": []}, {"text": "The overlap between the verbalized fields in each group was estimated to be below 35%.", "labels": [], "entities": [{"text": "overlap", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9610804319381714}]}, {"text": "Around 60% of fields are mentioned only in a single forecast from a group, consequently, the texts cannot be regarded as paraphrases of each other.", "labels": [], "entities": []}, {"text": "The test set consists of 150 texts, each corresponding to a different weather state.", "labels": [], "entities": []}, {"text": "Note that during testing we no longer assume that documents share the state, we treat each document in isolation.", "labels": [], "entities": []}, {"text": "We aimed to preserve approximately the same proportion of new and original examples as we had in the training set, therefore, we combined 50 texts originally present in the weather dataset with additional 100 newly-produced texts.", "labels": [], "entities": []}, {"text": "We annotated these 100 texts by aligning each line to one or more records, 7 whereas for the original texts the alignments were already present.", "labels": [], "entities": []}, {"text": "Following we evaluate the models on how well they predict these alignments.", "labels": [], "entities": []}, {"text": "When estimating the model parameters, we followed the training regime prescribed in (.", "labels": [], "entities": []}, {"text": "Namely, 5 iterations of EM with a basic model (with no segmentation or coherence modeling), followed by 5 iterations of EM with the model which generates fields independently and, at last, 5 iterations with the full model.", "labels": [], "entities": []}, {"text": "Only then, in the semi-supervised learning scenarios, we added unlabeled data and ran 5 additional iterations of EM.", "labels": [], "entities": []}, {"text": "Instead of prohibiting records from crossing punctuation, as suggested by, in our implementation we disregard the words not attached to specific fields (attached to the nullfield, see section 3.1) when computing spans of records.", "labels": [], "entities": []}, {"text": "To speed-up training, only a single record of each type is allowed to be generated when running inference for unlabeled examples on the E-7 The text was automatically tokenized and segmented into lines, with line breaks at punctuation characters.", "labels": [], "entities": []}, {"text": "Information about the line breaks is not used during learning and inference.", "labels": [], "entities": []}], "tableCaptions": []}