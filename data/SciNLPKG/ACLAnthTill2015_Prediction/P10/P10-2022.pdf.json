{"title": [{"text": "Event-based Hyperspace Analogue to Language for Query Expansion", "labels": [], "entities": []}], "abstractContent": [{"text": "Bag-of-words approaches to information retrieval (IR) are effective but assume independence between words.", "labels": [], "entities": [{"text": "information retrieval (IR)", "start_pos": 27, "end_pos": 53, "type": "TASK", "confidence": 0.8641341209411622}]}, {"text": "The Hy-perspace Analogue to Language (HAL) is a cognitively motivated and validated semantic space model that captures statistical dependencies between words by considering their co-occurrences in a surrounding window of text.", "labels": [], "entities": []}, {"text": "HAL has been successfully applied to query expansion in IR, but has several limitations, including high processing cost and use of distribu-tional statistics that do not exploit syntax.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 37, "end_pos": 52, "type": "TASK", "confidence": 0.832118809223175}]}, {"text": "In this paper, we pursue two methods for incorporating syntactic-semantic information from textual 'events' into HAL.", "labels": [], "entities": []}, {"text": "We build the HAL space directly from events to investigate whether processing costs can be reduced through more careful definition of word co-occurrence, and improve the quality of the pseudo-relevance feedback by applying event information as a constraint during HAL construction.", "labels": [], "entities": [{"text": "HAL construction", "start_pos": 264, "end_pos": 280, "type": "TASK", "confidence": 0.9179775416851044}]}, {"text": "Both methods significantly improve performance results in comparison with original HAL, and interpolation of HAL and relevance model expansion outperforms either method alone.", "labels": [], "entities": []}], "introductionContent": [{"text": "Despite its intuitive appeal, the incorporation of linguistic and semantic word dependencies in IR has not been shown to significantly improve over a bigram language modeling approach) that encodes word dependencies assumed from mere syntactic adjacency.", "labels": [], "entities": [{"text": "IR", "start_pos": 96, "end_pos": 98, "type": "TASK", "confidence": 0.9761783480644226}]}, {"text": "Both the dependence language model for IR (), which incorporates linguistic relations between non-adjacent words while limiting the generation of meaningless phrases, and the Markov Random Field (MRF) model, which captures short and long range term dependencies, consistently outperform a unigram language modelling approach but are closely approximated by a bigram language model that uses no linguistic knowledge.", "labels": [], "entities": [{"text": "IR", "start_pos": 39, "end_pos": 41, "type": "TASK", "confidence": 0.9685901999473572}]}, {"text": "Improving retrieval performance through application of semantic and syntactic information beyond proximity and co-occurrence features is a difficult task but remains a tantalising prospect.", "labels": [], "entities": []}, {"text": "Our approach is like that of in that it considers semantic-syntactically determined relationships between words at the sentence level, but allows words to have more than one role, such as predicate and argument for different events, while link grammar dictates that a word can only satisfy one connector in a disjunctive set.", "labels": [], "entities": []}, {"text": "Compared to the MRF model, our approach is unsupervised where MRFs require the training of parameters using relevance judgments that are often unavailable in practical conditions.", "labels": [], "entities": []}, {"text": "Other work incorporating syntactic and linguistic information into IR includes early research by, who employed tree structured analytics (TSAs) resembling dependency trees, the use of syntax to detect paraphrases for question answering (QA), and semantic role labelling in QA.", "labels": [], "entities": [{"text": "IR", "start_pos": 67, "end_pos": 69, "type": "TASK", "confidence": 0.9860115647315979}, {"text": "question answering (QA)", "start_pos": 217, "end_pos": 240, "type": "TASK", "confidence": 0.8419056415557862}]}, {"text": "Independent from IR, Pado and Lapata (2007) proposed a general framework for the construction of a semantic space endowed with syntactic information.", "labels": [], "entities": [{"text": "IR", "start_pos": 17, "end_pos": 19, "type": "TASK", "confidence": 0.828052818775177}]}, {"text": "This was represented by an undirected graph, where nodes stood for words, dependency edges stood for syntactical relations, and sequences of dependency edges formed paths that were weighted for each target word.", "labels": [], "entities": []}, {"text": "Our work is inline within constructing a semantic space with syntactic information, but builds our space from events, states and attributions as defined linguistically by.", "labels": [], "entities": []}, {"text": "We call these simply events, and extract them automatically from predicate-argument structures and a dependency parse.", "labels": [], "entities": []}, {"text": "We will use this space to perform query expansion in IR, a task that aims to find additional words related to original query terms, such that an expanded query including these words better expresses the information need.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 34, "end_pos": 49, "type": "TASK", "confidence": 0.7558996379375458}, {"text": "IR", "start_pos": 53, "end_pos": 55, "type": "TASK", "confidence": 0.7173121571540833}]}, {"text": "To our knowledge, the notion of events has not been applied to query expansion before.", "labels": [], "entities": [{"text": "query expansion", "start_pos": 63, "end_pos": 78, "type": "TASK", "confidence": 0.844226211309433}]}, {"text": "This paper will outline the original HAL algorithm which serves as our baseline, and the event extraction process.", "labels": [], "entities": [{"text": "HAL", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9190036058425903}, {"text": "event extraction", "start_pos": 89, "end_pos": 105, "type": "TASK", "confidence": 0.7877765595912933}]}, {"text": "We then propose two methods to arm HAL with event information: direct construction of HAL from events (eHAL-1), and treating events as constraints on HAL construction from the corpus (eHAL-2).", "labels": [], "entities": [{"text": "HAL", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.9532141089439392}]}, {"text": "Evaluation will compare results using original HAL, eHAL-1 and eHAL-2 with a widely used unigram language model (LM) for IR and a state of the art query expansion method, namely the Relevance Model (RM)).", "labels": [], "entities": [{"text": "IR", "start_pos": 121, "end_pos": 123, "type": "TASK", "confidence": 0.9619650840759277}]}, {"text": "We also explore whether a complementary effect can be achieved by combining HAL-based dependency modelling with the unigram-based RM.", "labels": [], "entities": []}], "datasetContent": [{"text": "We empirically test whether our event-based HALs perform better than the original HAL, and standard LM and RM, using three TREC 2 collections: AP89 with Topics 1-50 (title field), AP8889 with Topics 101-150 (title field) and WSJ9092 with Topics 201-250 (description field).", "labels": [], "entities": [{"text": "TREC 2 collections", "start_pos": 123, "end_pos": 141, "type": "DATASET", "confidence": 0.7282957633336385}, {"text": "AP8889", "start_pos": 180, "end_pos": 186, "type": "DATASET", "confidence": 0.768806517124176}, {"text": "WSJ9092", "start_pos": 225, "end_pos": 232, "type": "DATASET", "confidence": 0.8224411606788635}]}, {"text": "All the collections are stemmed, and stop words are removed, prior to retrieval using the Lemur Toolkit Version 4.11 . Initial retrieval is identical for all models evaluated: KL-divergence based LM smoothed using Dirichlet prior with \u00b5 set to 1000 as appropriate for TREC style title queries).", "labels": [], "entities": []}, {"text": "The top 50 returned documents form the basis for all pseudo-relevance feedback, with other parameters tuned separately for the RM and HAL methods.", "labels": [], "entities": [{"text": "RM", "start_pos": 127, "end_pos": 129, "type": "TASK", "confidence": 0.7143737077713013}]}, {"text": "For each dataset, the number of feedback terms for each method is selected optimally among 20, 40, 60, 80 and the interpolation and smoothing coefficient is set to be optimal in with interval 0.1.", "labels": [], "entities": []}, {"text": "For RM, we choose the first relevance model in with the document model smoothing parameter optimally set at 0.8.", "labels": [], "entities": [{"text": "RM", "start_pos": 4, "end_pos": 6, "type": "TASK", "confidence": 0.986289918422699}]}, {"text": "The number of feedback terms is fixed at 60 (for AP89 and WSJ9092) and 80 (for AP8889), and interpolation between the query and relevance models is set at 0.7 (for WSJ9092) and 0.9 (for AP89 and AP8889).", "labels": [], "entities": [{"text": "WSJ9092", "start_pos": 58, "end_pos": 65, "type": "DATASET", "confidence": 0.8105058073997498}, {"text": "WSJ9092", "start_pos": 164, "end_pos": 171, "type": "DATASET", "confidence": 0.9587206244468689}]}, {"text": "The HAL-based query expansion methods add the top 80 expansion terms to the query with interpolation coefficient 0.9 for WSJ9092 and 1 (that is, no interpolation) for AP89 and AP8889.", "labels": [], "entities": [{"text": "HAL-based query expansion", "start_pos": 4, "end_pos": 29, "type": "TASK", "confidence": 0.5618316829204559}, {"text": "WSJ9092", "start_pos": 121, "end_pos": 128, "type": "DATASET", "confidence": 0.902614951133728}, {"text": "AP89", "start_pos": 167, "end_pos": 171, "type": "DATASET", "confidence": 0.9092792272567749}, {"text": "AP8889", "start_pos": 176, "end_pos": 182, "type": "DATASET", "confidence": 0.9484930038452148}]}, {"text": "The other HAL-based parameters are set as follows: shortest event length M = 5, for eHAL-2 the \"inclusion criterion\" is 75% of words in an event, and for HAL and eHAL-2, window size L = 8.", "labels": [], "entities": [{"text": "shortest event length M", "start_pos": 51, "end_pos": 74, "type": "METRIC", "confidence": 0.8716138452291489}]}, {"text": "Top expansion terms are selected according to the formula: where HAL(t j |\u2295q) is the weight oft j in the combined HAL vector \u2295q () of original query terms.", "labels": [], "entities": [{"text": "HAL", "start_pos": 65, "end_pos": 68, "type": "METRIC", "confidence": 0.9929189085960388}]}, {"text": "Mean Average Precision (MAP) is the performance indicator, and t-test (at the level of 0.05) is performed to measure the statistical significance of results.", "labels": [], "entities": [{"text": "Mean Average Precision (MAP)", "start_pos": 0, "end_pos": 28, "type": "METRIC", "confidence": 0.9594396551450094}, {"text": "t-test", "start_pos": 63, "end_pos": 69, "type": "METRIC", "confidence": 0.9831337332725525}]}, {"text": "lists the experimental results 5 . It can be observed that all the three HAL-based query expansion methods improve performance over the LM and both eHALs achieve better performance than original HAL, indicating that the incorporation of event information is beneficial.", "labels": [], "entities": [{"text": "HAL-based query expansion", "start_pos": 73, "end_pos": 98, "type": "TASK", "confidence": 0.762899657090505}]}, {"text": "In addition, eHAL-2 leads to better performance than eHAL-1, suggesting that use of linguistic information as a constraint on statistical processing, rather than the focus of extraction, is a more effective strategy.", "labels": [], "entities": []}, {"text": "The results are still short of those achieved: Performance (MAP) comparison of query expansion using different HALs with RM, but the gap is significantly reduced by incorporating event information here, suggesting this is a promising line of work.", "labels": [], "entities": [{"text": "Performance (MAP)", "start_pos": 47, "end_pos": 64, "type": "METRIC", "confidence": 0.8895670622587204}, {"text": "query expansion", "start_pos": 79, "end_pos": 94, "type": "TASK", "confidence": 0.7183793038129807}]}, {"text": "In addition, as shown in (), the Information Flow method built upon the original HAL largely outperformed RM.", "labels": [], "entities": []}, {"text": "We expect that eHAL would provide an even better basis for Information Flow, but this possibility is yet to be explored.", "labels": [], "entities": [{"text": "Information Flow", "start_pos": 59, "end_pos": 75, "type": "TASK", "confidence": 0.829194962978363}]}, {"text": "As is known, RM is a pure unigram model while HAL methods are dependency-based.", "labels": [], "entities": [{"text": "RM", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.9122888445854187}]}, {"text": "They capture different information, hence it is natural to consider if their strengths might complement each other in a combined model.", "labels": [], "entities": []}, {"text": "For this purpose, we design the following two schemes: 1.", "labels": [], "entities": []}, {"text": "Apply RM to the feedback documents (original RM), the events extracted from these documents (eRM-1), and the text segments around each event (eRM-2), where the three sources are the same as used to produce HAL, eHAL-1 and eHAL-2 respectively; 2.", "labels": [], "entities": []}, {"text": "Interpolate the expanded query model by RM with the ones generated by each HAL, represented by HAL+RM, eHAL-1+RM and eHAL-2+RM.", "labels": [], "entities": []}, {"text": "The interpolation coefficient is again selected to achieve the optimal MAP.", "labels": [], "entities": [{"text": "MAP", "start_pos": 71, "end_pos": 74, "type": "METRIC", "confidence": 0.4929130971431732}]}, {"text": "The MAP comparison between the original RM and these new models are demonstrated in Table 3 . From the first three lines (Scheme 1), we can observe that inmost cases the performance generally deteriorates when RM is directly run over the events and the text segments.", "labels": [], "entities": [{"text": "MAP", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.6366013288497925}]}, {"text": "The event information is more effective to express the information about the term dependencies while the unigram RM ignores this information and only takes: Performance (MAP) comparison of query expansion using the combination of RM and term dependencies the occurrence frequencies of individual words into account, which is not well-captured by the events.", "labels": [], "entities": []}, {"text": "In contrast, the performance of Scheme 2 is more promising.", "labels": [], "entities": []}, {"text": "The three methods outperform the original RM inmost cases, but the improvement is not significant and it is also observed that there is little difference shown between RM with HAL and eHALs.", "labels": [], "entities": []}, {"text": "The phenomenon implies more effective methods maybe invented to complement the unigram models with the syntactical and statistical dependency information.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. A single word is  represented by a row vector and a column vector  that capture the information before and after the  word, respectively. In some applications, direc- tion sensitivity is ignored to obtain a single vector  representation of a word by adding corresponding  row and column vectors (", "labels": [], "entities": [{"text": "direc- tion sensitivity", "start_pos": 170, "end_pos": 193, "type": "METRIC", "confidence": 0.8092062771320343}]}, {"text": " Table 1: A HAL space for the text \"w 1 w 2 w 3 w 4  w 5 w 6 \" using a 5-word sliding window (L = 5).", "labels": [], "entities": []}, {"text": " Table 2: Performance (MAP) comparison of query  expansion using different HALs", "labels": [], "entities": [{"text": "HALs", "start_pos": 75, "end_pos": 79, "type": "TASK", "confidence": 0.5551603436470032}]}, {"text": " Table 3: Performance (MAP) comparison of query  expansion using the combination of RM and term  dependencies", "labels": [], "entities": []}]}