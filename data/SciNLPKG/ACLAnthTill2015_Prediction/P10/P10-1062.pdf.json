{"title": [{"text": "Error Detection for Statistical Machine Translation Using Linguistic Features", "labels": [], "entities": [{"text": "Error Detection", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.9163061082363129}, {"text": "Statistical Machine Translation", "start_pos": 20, "end_pos": 51, "type": "TASK", "confidence": 0.8596912622451782}]}], "abstractContent": [{"text": "Automatic error detection is desired in the post-processing to improve machine translation quality.", "labels": [], "entities": [{"text": "error detection", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.7531515061855316}, {"text": "machine translation", "start_pos": 71, "end_pos": 90, "type": "TASK", "confidence": 0.7101007103919983}]}, {"text": "The previous work is largely based on confidence estimation using system-based features, such as word posterior probabilities calculated from N-best lists or word lattices.", "labels": [], "entities": []}, {"text": "We propose to incorporate two groups of linguistic features , which convey information from outside machine translation systems, into error detection: lexical and syntactic features.", "labels": [], "entities": [{"text": "error detection", "start_pos": 134, "end_pos": 149, "type": "TASK", "confidence": 0.7179301232099533}]}, {"text": "We use a maximum entropy clas-sifier to predict translation errors by integrating word posterior probability feature and linguistic features.", "labels": [], "entities": []}, {"text": "The experimental results show that 1) linguistic features alone outperform word posterior probability based confidence estimation in error detection; and 2) linguistic features can further provide complementary information when combined with word confidence scores, which collectively reduce the classification error rate by 18.52% and improve the F measure by 16.37%.", "labels": [], "entities": [{"text": "error detection", "start_pos": 133, "end_pos": 148, "type": "TASK", "confidence": 0.7149867117404938}, {"text": "F measure", "start_pos": 348, "end_pos": 357, "type": "METRIC", "confidence": 0.9934856593608856}]}], "introductionContent": [{"text": "Translation hypotheses generated by a statistical machine translation (SMT) system always contain both correct parts (e.g. words, n-grams, phrases matched with reference translations) and incorrect parts.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 38, "end_pos": 75, "type": "TASK", "confidence": 0.7697356094916662}]}, {"text": "Automatically distinguishing incorrect parts from correct parts is therefore very desirable not only for post-editing and interactive machine translation) but also for SMT itself: either by rescoring hypotheses in the N -best list using the probability of correctness calculated for each hypothesis) or by generating new hypotheses using Nbest lists from one SMT system or multiple systems (.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 134, "end_pos": 153, "type": "TASK", "confidence": 0.7545080780982971}, {"text": "SMT", "start_pos": 168, "end_pos": 171, "type": "TASK", "confidence": 0.9961612224578857}, {"text": "SMT", "start_pos": 359, "end_pos": 362, "type": "TASK", "confidence": 0.9291505217552185}]}, {"text": "In this paper we restrict the \"parts\" to words.", "labels": [], "entities": []}, {"text": "That is, we detect errors at the word level for SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.9901121258735657}]}, {"text": "A common approach to SMT error detection at the word level is calculating the confidence at which a word is correct.", "labels": [], "entities": [{"text": "SMT error detection", "start_pos": 21, "end_pos": 40, "type": "TASK", "confidence": 0.9004194339116415}]}, {"text": "The majority of word confidence estimation methods follows three steps: 1) Calculate features that express the correctness of words either based on SMT model (e.g. translation/language model) or based on SMT system output (e.g. N -best lists, word lattices) ().", "labels": [], "entities": [{"text": "word confidence estimation", "start_pos": 16, "end_pos": 42, "type": "TASK", "confidence": 0.6390800674756368}, {"text": "SMT", "start_pos": 148, "end_pos": 151, "type": "TASK", "confidence": 0.9600027799606323}]}, {"text": "2) Combine these features together with a classification model such as multi-layer perceptron (, Naive Bayes (, or loglinear model).", "labels": [], "entities": []}, {"text": "3) Divide words into two groups (correct translations and errors) by using a classification threshold optimized on a development set.", "labels": [], "entities": []}, {"text": "Sometimes the step 2) is not necessary if only one effective feature is used; and sometimes the step 2) and 3) can be merged into a single step if we directly output predicting results from binary classifiers instead of making thresholding decision.", "labels": [], "entities": []}, {"text": "Various features from different SMT models and system outputs are investigated ().", "labels": [], "entities": [{"text": "SMT", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.9894579648971558}]}, {"text": "Experimental results show that they are useful for error detection.", "labels": [], "entities": [{"text": "error detection", "start_pos": 51, "end_pos": 66, "type": "TASK", "confidence": 0.7972510159015656}]}, {"text": "However, it is not adequate to just use these features as discussed in (Shi and) because the information that they carry is either from the inner components of SMT systems or from system outputs.", "labels": [], "entities": [{"text": "SMT", "start_pos": 160, "end_pos": 163, "type": "TASK", "confidence": 0.9810665845870972}]}, {"text": "To some extent, it has already been considered by SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.9920382499694824}]}, {"text": "Hence finding external information sources from outside SMT systems is desired for error detection.", "labels": [], "entities": [{"text": "SMT", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.9855625629425049}, {"text": "error detection", "start_pos": 83, "end_pos": 98, "type": "TASK", "confidence": 0.7121507972478867}]}, {"text": "Linguistic knowledge is exactly such a good choice as an external information source.", "labels": [], "entities": []}, {"text": "It has already been proven effective in error detection for speech recognition).", "labels": [], "entities": [{"text": "error detection", "start_pos": 40, "end_pos": 55, "type": "TASK", "confidence": 0.6861603409051895}, {"text": "speech recognition", "start_pos": 60, "end_pos": 78, "type": "TASK", "confidence": 0.8616927862167358}]}, {"text": "However, it is not widely used in SMT error detection.", "labels": [], "entities": [{"text": "SMT error detection", "start_pos": 34, "end_pos": 53, "type": "TASK", "confidence": 0.9040225148200989}]}, {"text": "The reason is probably that people have yet to find effective linguistic features that outperform nonlinguistic features such as word posterior probability features (.", "labels": [], "entities": []}, {"text": "In this paper, we would like to show an effective use of linguistic features in SMT error detection.", "labels": [], "entities": [{"text": "SMT error detection", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.9324886600176493}]}, {"text": "We integrate two sets of linguistic features into a maximum entropy (MaxEnt) model and develop a MaxEnt-based binary classifier to predict the category (correct or incorrect) for each word in a generated target sentence.", "labels": [], "entities": []}, {"text": "Our experimental results show that linguistic features substantially improve error detection and even outperform word posterior probability features.", "labels": [], "entities": [{"text": "error detection", "start_pos": 77, "end_pos": 92, "type": "TASK", "confidence": 0.7334096133708954}]}, {"text": "Further, they can produce additional improvements when combined with word posterior probability features.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we review the previous work on wordlevel confidence estimation which is used for error detection.", "labels": [], "entities": [{"text": "wordlevel confidence estimation", "start_pos": 45, "end_pos": 76, "type": "TASK", "confidence": 0.5731260081132253}, {"text": "error detection", "start_pos": 95, "end_pos": 110, "type": "TASK", "confidence": 0.6628327369689941}]}, {"text": "In Section 3, we introduce our linguistic features as well as the word posterior probability feature.", "labels": [], "entities": []}, {"text": "In Section 4, we elaborate our MaxEntbased error detection model which combine linguistic features and word posterior probability feature together.", "labels": [], "entities": [{"text": "MaxEntbased error detection", "start_pos": 31, "end_pos": 58, "type": "TASK", "confidence": 0.7200335462888082}, {"text": "word posterior probability feature", "start_pos": 103, "end_pos": 137, "type": "METRIC", "confidence": 0.7735016644001007}]}, {"text": "In Section 5, we describe the SMT system which we use to generate translation hypotheses.", "labels": [], "entities": [{"text": "SMT", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.9940342307090759}]}, {"text": "We report our experimental results in Section 6 and conclude in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We conducted our experiments at several levels.", "labels": [], "entities": []}, {"text": "Starting with MaxEnt models with single linguistic feature or word posterior probability based feature, we incorporated additional features incrementally by combining features together.", "labels": [], "entities": []}, {"text": "In doing so, we would like the experimental results not only to display the effectiveness of linguistic features for error detection but also to identify the additional contribution of each feature to the task.", "labels": [], "entities": [{"text": "error detection", "start_pos": 117, "end_pos": 132, "type": "TASK", "confidence": 0.692923828959465}]}, {"text": "To evaluate the overall performance of the error detection, we use the commonly used metric, classification error rate (CER) to evaluate our classifiers.", "labels": [], "entities": [{"text": "error detection", "start_pos": 43, "end_pos": 58, "type": "TASK", "confidence": 0.692508801817894}, {"text": "classification error rate (CER)", "start_pos": 93, "end_pos": 124, "type": "METRIC", "confidence": 0.8979570766290029}]}, {"text": "CER is defined as the percentage of words that are wrongly tagged as follows CER = # of wrongly tagged words Total # of words The baseline CER is determined by assuming the most frequent class for all words.", "labels": [], "entities": [{"text": "CER", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.7879629135131836}, {"text": "CER", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.9290088415145874}]}, {"text": "Since the ratio of correct words in both the development and test set is lower than 50%, the most frequent class is \"incorrect\".", "labels": [], "entities": []}, {"text": "Hence the baseline CER in our experiments is equal to the ratio of correct words as these words are wrongly tagged as incorrect.", "labels": [], "entities": [{"text": "CER", "start_pos": 19, "end_pos": 22, "type": "METRIC", "confidence": 0.8465067148208618}]}, {"text": "We also use precision and recall on errors to evaluate the performance of error detection.", "labels": [], "entities": [{"text": "precision", "start_pos": 12, "end_pos": 21, "type": "METRIC", "confidence": 0.9995229244232178}, {"text": "recall", "start_pos": 26, "end_pos": 32, "type": "METRIC", "confidence": 0.9988138675689697}, {"text": "error detection", "start_pos": 74, "end_pos": 89, "type": "TASK", "confidence": 0.7177413403987885}]}, {"text": "Let n g be the number of words of which the true class is incorrect, n t be the number of words which are tagged as incorrect by classifiers, and n m be the number of words tagged as incorrect that are indeed translation errors.", "labels": [], "entities": []}, {"text": "The precision P re is the percentage of words correctly tagged as translation errors.", "labels": [], "entities": [{"text": "precision P re", "start_pos": 4, "end_pos": 18, "type": "METRIC", "confidence": 0.9003485441207886}]}, {"text": "P re = n m n t The recall Rec is the proportion of actual translation errors that are found by classifiers.", "labels": [], "entities": [{"text": "recall Rec", "start_pos": 19, "end_pos": 29, "type": "METRIC", "confidence": 0.9565961062908173}]}, {"text": "F measure, the trade-off between precision and recall, is also used.", "labels": [], "entities": [{"text": "F measure", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9850501716136932}, {"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9994351267814636}, {"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.998932421207428}]}, {"text": "shows the performance of our experiments on the error detection task.", "labels": [], "entities": [{"text": "error detection task", "start_pos": 48, "end_pos": 68, "type": "TASK", "confidence": 0.7700511813163757}]}, {"text": "To compare with previous work using word posterior probabilities for confidence estimation, we carried out experiments using wpp estimated from N -best lists with the classification threshold \u03c4 , which was optimized on our development set to minimize CER.", "labels": [], "entities": [{"text": "CER", "start_pos": 251, "end_pos": 254, "type": "METRIC", "confidence": 0.942980170249939}]}, {"text": "A relative improvement of 9.27% is achieved over the baseline CER, which reconfirms the effectiveness of word posterior probabilities for error detection.", "labels": [], "entities": [{"text": "CER", "start_pos": 62, "end_pos": 65, "type": "METRIC", "confidence": 0.810833215713501}, {"text": "error detection", "start_pos": 138, "end_pos": 153, "type": "TASK", "confidence": 0.7082284241914749}]}, {"text": "We conducted three groups of experiments using the MaxEnt based error detection model with various feature combinations.", "labels": [], "entities": [{"text": "MaxEnt based error detection", "start_pos": 51, "end_pos": 79, "type": "TASK", "confidence": 0.7211714833974838}]}, {"text": "\u2022 The first group of experiments uses single feature, such as dwpp, pos.", "labels": [], "entities": []}, {"text": "We find the most effective feature is pos, which achieves a 16.12% relative improvement over the baseline CER and 7.55% relative improvement over the CER of word posterior probability thresholding.", "labels": [], "entities": [{"text": "CER", "start_pos": 106, "end_pos": 109, "type": "METRIC", "confidence": 0.738632321357727}]}, {"text": "Using discrete word posterior probabilities as features in the MaxEnt based error detection model is marginally better than word posterior probability thresholding in terms of CER, but obtains a 13.79% relative improvement in F measure.", "labels": [], "entities": [{"text": "MaxEnt based error detection", "start_pos": 63, "end_pos": 91, "type": "TASK", "confidence": 0.7557352781295776}, {"text": "CER", "start_pos": 176, "end_pos": 179, "type": "METRIC", "confidence": 0.9900366067886353}, {"text": "F measure", "start_pos": 226, "end_pos": 235, "type": "METRIC", "confidence": 0.9886094033718109}]}, {"text": "The syntactic feature link also improves the error detection in terms of CER and particularly recall.", "labels": [], "entities": [{"text": "CER", "start_pos": 73, "end_pos": 76, "type": "METRIC", "confidence": 0.8965688347816467}, {"text": "recall", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.9983909130096436}]}], "tableCaptions": [{"text": " Table 3: Corpus statistics (number of sentences  and words) for the error detection task.", "labels": [], "entities": [{"text": "error detection task", "start_pos": 69, "end_pos": 89, "type": "TASK", "confidence": 0.7588522831598917}]}, {"text": " Table 4: Case-insensitive BLEU score and ratio  of correct words (RCW) on the training, develop- ment and test corpus.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 27, "end_pos": 37, "type": "METRIC", "confidence": 0.9313259720802307}, {"text": "ratio  of correct words (RCW)", "start_pos": 42, "end_pos": 71, "type": "METRIC", "confidence": 0.8576143894876752}]}, {"text": " Table 5: Performance of the error detection task.", "labels": [], "entities": [{"text": "error detection task", "start_pos": 29, "end_pos": 49, "type": "TASK", "confidence": 0.7481491267681122}]}, {"text": " Table 5. Except for the wd feature,", "labels": [], "entities": []}]}