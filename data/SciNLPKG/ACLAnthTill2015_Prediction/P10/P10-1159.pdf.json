{"title": [{"text": "Automated planning for situated natural language generation", "labels": [], "entities": []}], "abstractContent": [{"text": "We present a natural language generation approach which models, exploits, and manipulates the non-linguistic context in situated communication, using techniques from AI planning.", "labels": [], "entities": [{"text": "natural language generation", "start_pos": 13, "end_pos": 40, "type": "TASK", "confidence": 0.760377049446106}]}, {"text": "We show how to generate instructions which deliberately guide the hearer to a location that is convenient for the generation of simple referring expressions , and how to generate referring expressions with context-dependent adjectives.", "labels": [], "entities": []}, {"text": "We implement and evaluate our approach in the framework of the Challenge on Generating Instructions in Virtual Environments, finding that it performs well even under the constraints of real-time generation.", "labels": [], "entities": []}], "introductionContent": [{"text": "The problem of situated natural language generation (NLG)-i.e., of generating natural language in the context of a physical (or virtual) environment-has received increasing attention in the past few years.", "labels": [], "entities": [{"text": "situated natural language generation (NLG)-", "start_pos": 15, "end_pos": 58, "type": "TASK", "confidence": 0.8222578508513314}]}, {"text": "On the one hand, this is because it is the foundation of various emerging applications, including human-robot interaction and mobile navigation systems, and is the focus of a current evaluation effort, the Challenges on Generating Instructions in Virtual Environments (GIVE; ().", "labels": [], "entities": [{"text": "mobile navigation", "start_pos": 126, "end_pos": 143, "type": "TASK", "confidence": 0.7586498558521271}]}, {"text": "On the other hand, situated generation comes with interesting theoretical challenges: Compared to the generation of pure text, the interpretation of expressions in situated communication is sensitive to the non-linguistic context, and this context can change as easily as the user can move around in the environment.", "labels": [], "entities": []}, {"text": "One interesting aspect of situated communication from an NLG perspective is that this nonlinguistic context can be manipulated by the speaker.", "labels": [], "entities": []}, {"text": "Consider the following segment of discourse between an instruction giver (IG) and an instruction follower (IF), which is adapted from the SCARE corpus (): (1) IG: Walk forward and then turn right.", "labels": [], "entities": []}, {"text": "IF: (walks and turns) IG: OK.", "labels": [], "entities": [{"text": "IF", "start_pos": 0, "end_pos": 2, "type": "METRIC", "confidence": 0.9575300812721252}, {"text": "IG", "start_pos": 22, "end_pos": 24, "type": "METRIC", "confidence": 0.9550836086273193}, {"text": "OK", "start_pos": 26, "end_pos": 28, "type": "METRIC", "confidence": 0.5401501655578613}]}, {"text": "Now hit the button in the middle.", "labels": [], "entities": []}, {"text": "In this example, the IG plans to refer to an object (here, a button); and in order to do so, gives a navigation instruction to guide the IF to a convenient location at which she can then use a simple referring expression (RE).", "labels": [], "entities": [{"text": "RE", "start_pos": 222, "end_pos": 224, "type": "METRIC", "confidence": 0.9620078206062317}]}, {"text": "That is, there is an interaction between navigation instructions (intended to manipulate the non-linguistic context in a certain way) and referring expressions (which exploit the non-linguistic context).", "labels": [], "entities": []}, {"text": "Although such subdialogues are common in SCARE, we are not aware of any previous research that can generate them in a computationally feasible manner.", "labels": [], "entities": []}, {"text": "This paper presents an approach to generation which is able to model the effect of an utterance on the non-linguistic context, and to intentionally generate utterances such as the above as part of a process of referring to objects.", "labels": [], "entities": []}, {"text": "Our approach builds upon the CRISP generation system, which translates generation problems into planning problems and solves these with an AI planner.", "labels": [], "entities": []}, {"text": "We extend the CRISP planning operators with the perlocutionary effects that uttering a particular word has on the physical environment if it is understood correctly; more specifically, on the position and orientation of the hearer.", "labels": [], "entities": []}, {"text": "This allows the planner to predict the nonlinguistic context in which a later part of the utterance will be interpreted, and therefore to search for contexts that allow the use of simple REs.", "labels": [], "entities": []}, {"text": "As a result, the work of referring to an object gets distributed over multiple utterances of low cognitive load rather than a single complex noun phrase.", "labels": [], "entities": []}, {"text": "A second contribution of our paper is the generation of REs involving context-dependent adjectives: A button can be described as \"the left blue button\" even if there is a red button to its left.", "labels": [], "entities": [{"text": "REs", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.8318490386009216}]}, {"text": "We model adjectives whose interpretation depends on the nominal phrases they modify, as well as on the non-linguistic context, by keeping track of the distractors that remain after uttering a series of modifiers.", "labels": [], "entities": []}, {"text": "Thus, unlike most other RE generation approaches, we are not restricted to building an RE by simply intersecting lexically specified sets representing the extensions of different attributes, but can correctly generate expressions whose meaning depends on the context in a number of ways.", "labels": [], "entities": [{"text": "RE generation", "start_pos": 24, "end_pos": 37, "type": "TASK", "confidence": 0.9775754809379578}]}, {"text": "In this way we are able to refer to objects earlier and more flexibly.", "labels": [], "entities": []}, {"text": "We implement and evaluate our approach in the context of a GIVE NLG system, by using the GIVE-1 software infrastructure and a GIVE-1 evaluation world.", "labels": [], "entities": [{"text": "GIVE NLG", "start_pos": 59, "end_pos": 67, "type": "DATASET", "confidence": 0.8173843920230865}, {"text": "GIVE-1 software infrastructure", "start_pos": 89, "end_pos": 119, "type": "DATASET", "confidence": 0.8969100515047709}]}, {"text": "This shows that our system generates an instruction-giving discourse as in in about a second.", "labels": [], "entities": []}, {"text": "It outperforms a mostly nonsituated baseline significantly, and compares well against a second baseline based on one of the top-performing systems of the GIVE-1 Challenge.", "labels": [], "entities": [{"text": "GIVE-1 Challenge", "start_pos": 154, "end_pos": 170, "type": "DATASET", "confidence": 0.7700473964214325}]}, {"text": "Next to the practical usefulness this evaluation establishes, we argue that our approach to jointly modeling the grammatical and physical effects of a communicative action can also inform new models of the pragmatics of speech acts.", "labels": [], "entities": []}, {"text": "We discuss related work in Section 2, and review the CRISP system, on which our work is based, in Section 3.", "labels": [], "entities": []}, {"text": "We then show in Section 4 how we extend CRISP to generate navigation-and-reference discourses as in (1), and add context-dependent adjectives in Section 5.", "labels": [], "entities": []}, {"text": "We evaluate our system in Section 6; Section 7 concludes and points to future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "To establish the quality of the generated instructions, we implemented SCRISP as part of a generation system in the GIVE-1 framework, and evaluated it against two baselines.", "labels": [], "entities": [{"text": "GIVE-1 framework", "start_pos": 116, "end_pos": 132, "type": "DATASET", "confidence": 0.8718313872814178}]}, {"text": "GIVE-1 was the First Challenge on Generating Instructions in Virtual Environments, which was completed in 2009 SCRISP  (.", "labels": [], "entities": [{"text": "GIVE-1", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.7543414831161499}, {"text": "SCRISP", "start_pos": 111, "end_pos": 117, "type": "DATASET", "confidence": 0.8601384162902832}]}, {"text": "In this challenge, systems must generate real-time instructions that help users perform a task in a treasure-hunt virtual environment such as the one shown in.", "labels": [], "entities": []}, {"text": "We conducted our evaluation in World 2 from GIVE-1, which was deliberately designed to be challenging for RE generation.", "labels": [], "entities": [{"text": "World 2 from GIVE-1", "start_pos": 31, "end_pos": 50, "type": "DATASET", "confidence": 0.780158743262291}, {"text": "RE generation", "start_pos": 106, "end_pos": 119, "type": "TASK", "confidence": 0.9482724070549011}]}, {"text": "The world consists of one room filled with several objects and buttons, most of which cannot be distinguished by simple descriptions.", "labels": [], "entities": []}, {"text": "Moreover, some of those may activate an alarm and cause the player to lose the game.", "labels": [], "entities": []}, {"text": "The player's moves and turns are discrete and the NLG system has complete and accurate real-time information about the state of the world.", "labels": [], "entities": []}, {"text": "Instructions that each of the three systems under comparison generated in an example scene of the evaluation world are presented in.", "labels": [], "entities": []}, {"text": "The evaluation took place online via the Amazon Mechanical Turk, where we collected 25 games for each system.", "labels": [], "entities": [{"text": "Amazon Mechanical Turk", "start_pos": 41, "end_pos": 63, "type": "DATASET", "confidence": 0.8753054936726888}]}, {"text": "We focus on four measures of evaluation: success rates for solving the task and resolving the generated REs, average task completion time (in seconds) for successful games, and average distance (in steps) between the IF and the referent at the time when the RE was generated.", "labels": [], "entities": []}, {"text": "As in the challenge, the task is considered as solved if the player has correctly been led through manipulating all target objects required to discover and collect the treasure; in World 2, the minimum number of such targets is eight.", "labels": [], "entities": []}, {"text": "An RE is successfully resolved if it results in the manipulation of the referent, whereas manipulation of an alarm-triggering distractor ends the game unsuccessfully.", "labels": [], "entities": [{"text": "RE", "start_pos": 3, "end_pos": 5, "type": "METRIC", "confidence": 0.6563713550567627}]}], "tableCaptions": [{"text": " Table 2: Evaluation results. Differences to  SCRISP are significant at *p < .05, **p < .005  (Pearson's chi-square test for system success rates;  unpaired two-sample t-test for the rest).", "labels": [], "entities": []}]}