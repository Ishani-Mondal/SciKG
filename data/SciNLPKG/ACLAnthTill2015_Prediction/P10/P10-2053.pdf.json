{"title": [], "abstractContent": [{"text": "Classical Information Extraction (IE) systems fill slots in domain-specific frames.", "labels": [], "entities": [{"text": "Classical Information Extraction (IE)", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.7596197028954824}]}, {"text": "This paper reports on SEQ, a novel open IE system that leverages a domain-independent frame to extract ordered sequences such as presidents of the United States or the most common causes of death in the U.S. SEQ leverages regularities about sequences to extract a coherent set of sequences from Web text.", "labels": [], "entities": []}, {"text": "SEQ nearly doubles the area under the precision-recall curve compared to an extractor that does not exploit these regularities.", "labels": [], "entities": [{"text": "SEQ", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.5312334895133972}, {"text": "precision-recall", "start_pos": 38, "end_pos": 54, "type": "METRIC", "confidence": 0.9985666871070862}]}], "introductionContent": [{"text": "Classical IE systems fill slots in domain-specific frames such as the time and location slots in seminar announcements) or the terrorist organization slot in news stories (.", "labels": [], "entities": []}, {"text": "In contrast, open IE systems are domainindependent, but extract \"flat\" sets of assertions that are not organized into frames and slots.", "labels": [], "entities": []}, {"text": "This paper reports on SEQ-an open IE system that leverages a domain-independent frame to extract ordered sequences of objects from Web text.", "labels": [], "entities": [{"text": "SEQ-an open IE", "start_pos": 22, "end_pos": 36, "type": "TASK", "confidence": 0.844015896320343}]}, {"text": "We show that the novel, domain-independent sequence frame in SEQ substantially boosts the precision and recall of the system and yields coherent sequences filtered from low-precision extractions.", "labels": [], "entities": [{"text": "SEQ", "start_pos": 61, "end_pos": 64, "type": "TASK", "confidence": 0.7629038095474243}, {"text": "precision", "start_pos": 90, "end_pos": 99, "type": "METRIC", "confidence": 0.9993849992752075}, {"text": "recall", "start_pos": 104, "end_pos": 110, "type": "METRIC", "confidence": 0.9985961318016052}]}, {"text": "Sequence extraction is distinct from set expansion (; because sequences are ordered and because the extraction process does not require seeds or HTML lists as input.", "labels": [], "entities": [{"text": "Sequence extraction", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9425745010375977}]}, {"text": "The domain-independent sequence frame consists of a sequence name s (e.g., presidents of the United States), and a set of ordered pairs (x, k) where x is a string naming a member of the sequence with name s, and k is an integer indicating  its position (e.g., (Washington, 1) and (JFK, 35)).", "labels": [], "entities": []}, {"text": "The task of sequence extraction is to automatically instantiate sequence frames given a corpus of unstructured text.", "labels": [], "entities": [{"text": "sequence extraction", "start_pos": 12, "end_pos": 31, "type": "TASK", "confidence": 0.860099732875824}]}, {"text": "By definition, sequences have two properties that we can leverage in creating a sequence extractor: functionality and density.", "labels": [], "entities": []}, {"text": "Functionality means position kin a sequence is occupied by a single real-world entity x.", "labels": [], "entities": []}, {"text": "Density means that if a value has been observed at position k then there must exist values for all i < k, and possibly more after it.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section reports on two experiments.", "labels": [], "entities": []}, {"text": "First, we measured how the density and functionality features improve performance on the sequence name classification sub-task ().", "labels": [], "entities": [{"text": "sequence name classification", "start_pos": 89, "end_pos": 117, "type": "TASK", "confidence": 0.6619142591953278}]}, {"text": "Second, we report on SEQ's performance on the sequenceextraction task).", "labels": [], "entities": [{"text": "SEQ", "start_pos": 21, "end_pos": 24, "type": "METRIC", "confidence": 0.5966644287109375}]}, {"text": "To create a test set, we selected all sentences containing ordinal phrases from Banko's 500M Web page corpus.", "labels": [], "entities": [{"text": "Banko's 500M Web page corpus", "start_pos": 80, "end_pos": 108, "type": "DATASET", "confidence": 0.9622591634591421}]}, {"text": "To enrich this set O, we obtained additional sentences from Bing.com as follows.", "labels": [], "entities": []}, {"text": "For each sequence name s satisfying localConf (x, k, s|sentence) \u2265 0.5 for some sentence in O, we queried Bing.com for \"the kth s\" fork = 1, 2, . .", "labels": [], "entities": []}, {"text": "until no more hits were returned.", "labels": [], "entities": []}, {"text": "For each query, we downloaded the search snippets and added them to our corpus.", "labels": [], "entities": []}, {"text": "This procedure resulted in making 95, 611 search engine queries.", "labels": [], "entities": []}, {"text": "The final corpus contained 3, 716, 745 distinct sentences containing an OP.", "labels": [], "entities": []}, {"text": "Generating candidate extractions using the method from Section 2.1 resulted in a set of over 40 million distinct extractions, the vast majority of which are incorrect.", "labels": [], "entities": []}, {"text": "To get a sample with a significant number of correct extractions, we filtered this set to include only extractions with totalConf (x, k, s|C) \u2265 0.8 for some sentence, resulting in a set of 2, 409, 211 extractions.", "labels": [], "entities": []}, {"text": "We then randomly sampled and manually labeled 2, 000 of these extractions for evaluation.", "labels": [], "entities": []}, {"text": "We did a Web search to verify the correctness of the sequence name sand that x is the kth item in the sequence.", "labels": [], "entities": []}, {"text": "In some cases, the ordering relation of the sequence name was ambiguous (e.g., \"largest state in the US\" could refer to land area or population), which could lead to merging two distinct sequences.", "labels": [], "entities": []}, {"text": "In practice, we found that most ordering relations were used in a consistent way (e.g., \"largest city in\" always means largest by population) and only about 5% of the sequence names in our sample have an ambiguous ordering relation.", "labels": [], "entities": []}, {"text": "We compute precision-recall curves relative to this random sample by changing a confidence threshold.", "labels": [], "entities": [{"text": "precision-recall", "start_pos": 11, "end_pos": 27, "type": "METRIC", "confidence": 0.9964901804924011}]}, {"text": "Precision is the percentage of correct extractions above a threshold, while recall is the percentage correct above a threshold divided by the total number of correct extractions.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9903152585029602}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.999572217464447}]}, {"text": "Because SEQ requires training data, we used 15-fold cross validation on the labeled sample.", "labels": [], "entities": [{"text": "SEQ", "start_pos": 8, "end_pos": 11, "type": "TASK", "confidence": 0.9068416357040405}]}, {"text": "The functionality and density features boost SEQ's ability to correctly identify sequence names.", "labels": [], "entities": [{"text": "SEQ", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.8163463473320007}]}, {"text": "shows how well SEQ can identify correct sequence names using only functionality, only density, and using functionality and density in concert.", "labels": [], "entities": []}, {"text": "The baseline used is the maximum value of localConf (x, k, s) overall (x, k).", "labels": [], "entities": []}, {"text": "Both the density features and the functionality features are effective at this task, but using both types of features resulted in a statistically significant improvement over using either type of feature individually (paired t-test of area under the curve, p < 0.05).", "labels": [], "entities": []}, {"text": "We measure SEQ's efficacy on the complete sequence-extraction task by contrasting it with two baseline systems.", "labels": [], "entities": [{"text": "SEQ", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9647645950317383}]}, {"text": "The first is LOCAL, which ranks extractions by localConf . The second is If an extraction arises from multiple sentences, we use REDUND, which ranks extractions by totalConf . shows the precision-recall curves for each system on the test data.", "labels": [], "entities": [{"text": "LOCAL", "start_pos": 13, "end_pos": 18, "type": "METRIC", "confidence": 0.9564200043678284}, {"text": "REDUND", "start_pos": 129, "end_pos": 135, "type": "METRIC", "confidence": 0.9780642986297607}, {"text": "precision-recall", "start_pos": 186, "end_pos": 202, "type": "METRIC", "confidence": 0.9935550093650818}]}, {"text": "The area under the curves for SEQ, REDUND, and LOCAL are 0.59, 0.31, and 0.17, respectively.", "labels": [], "entities": [{"text": "SEQ", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.8423179388046265}, {"text": "REDUND", "start_pos": 35, "end_pos": 41, "type": "METRIC", "confidence": 0.9928421974182129}, {"text": "LOCAL", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.9987971782684326}]}, {"text": "The low precision and flat curve for LOCAL suggests that localConf is not informative for classifying extractions on its own.", "labels": [], "entities": [{"text": "precision", "start_pos": 8, "end_pos": 17, "type": "METRIC", "confidence": 0.9978985786437988}]}, {"text": "REDUND outperformed LOCAL, especially at the high-precision part of the curve.", "labels": [], "entities": [{"text": "REDUND", "start_pos": 0, "end_pos": 6, "type": "METRIC", "confidence": 0.762752890586853}, {"text": "LOCAL", "start_pos": 20, "end_pos": 25, "type": "METRIC", "confidence": 0.6528303623199463}]}, {"text": "On the subset of extractions with correct s, REDUND can identify x as the kth item with precision of 0.85 at recall 0.80.", "labels": [], "entities": [{"text": "REDUND", "start_pos": 45, "end_pos": 51, "type": "METRIC", "confidence": 0.943972647190094}, {"text": "precision", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.9989369511604309}, {"text": "recall", "start_pos": 109, "end_pos": 115, "type": "METRIC", "confidence": 0.9848612546920776}]}, {"text": "This is consistent with previous work on redundancy-based extractors on the Web.", "labels": [], "entities": []}, {"text": "However, REDUND still suffered from the problems of over-specification and over-generalization described in Section 2.", "labels": [], "entities": [{"text": "REDUND", "start_pos": 9, "end_pos": 15, "type": "TASK", "confidence": 0.46003445982933044}]}, {"text": "SEQ reduces the negative effects of these problems by decreasing the scores of sequence names that appear too general or too specific.", "labels": [], "entities": [{"text": "SEQ", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8124806880950928}]}], "tableCaptions": []}