{"title": [{"text": "Adapting Self-training for Semantic Role Labeling", "labels": [], "entities": [{"text": "Adapting", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.9589507579803467}, {"text": "Semantic Role Labeling", "start_pos": 27, "end_pos": 49, "type": "TASK", "confidence": 0.744522492090861}]}], "abstractContent": [{"text": "Supervised semantic role labeling (SRL) systems trained on hand-crafted annotated corpora have recently achieved state-of-the-art performance.", "labels": [], "entities": [{"text": "semantic role labeling (SRL)", "start_pos": 11, "end_pos": 39, "type": "TASK", "confidence": 0.8029425342877706}]}, {"text": "However, creating such corpora is tedious and costly, with the resulting corpora not sufficiently representative of the language.", "labels": [], "entities": []}, {"text": "This paper describes apart of an ongoing work on applying bootstrapping methods to SRL to deal with this problem.", "labels": [], "entities": [{"text": "SRL", "start_pos": 83, "end_pos": 86, "type": "TASK", "confidence": 0.9575645327568054}]}, {"text": "Previous work shows that, due to the complexity of SRL, this task is not straightforward.", "labels": [], "entities": [{"text": "SRL", "start_pos": 51, "end_pos": 54, "type": "TASK", "confidence": 0.9816908240318298}]}, {"text": "One major difficulty is the propagation of classification noise into the successive iterations.", "labels": [], "entities": []}, {"text": "We address this problem by employing balancing and preselection methods for self-training, as a bootstrapping algorithm.", "labels": [], "entities": []}, {"text": "The proposed methods could achieve improvement over the baseline, which do not use these methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "Semantic role labeling has been an active research field of computational linguistics since its introduction by.", "labels": [], "entities": [{"text": "Semantic role labeling", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7370837926864624}]}, {"text": "It reveals the event structure encoded in the sentence, which is useful for other NLP tasks or applications such as information extraction, question answering, and machine translation.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 116, "end_pos": 138, "type": "TASK", "confidence": 0.8215461373329163}, {"text": "question answering", "start_pos": 140, "end_pos": 158, "type": "TASK", "confidence": 0.9105434119701385}, {"text": "machine translation", "start_pos": 164, "end_pos": 183, "type": "TASK", "confidence": 0.8122769296169281}]}, {"text": "Several CoNLL shared tasks) dedicated to semantic role labeling affirm the increasing attention to this field.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 41, "end_pos": 63, "type": "TASK", "confidence": 0.768398106098175}]}, {"text": "One important supportive factor of studying supervised statistical SRL has been the existence of hand-annotated semantic corpora for training SRL systems.", "labels": [], "entities": [{"text": "SRL", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.7909424901008606}, {"text": "SRL", "start_pos": 142, "end_pos": 145, "type": "TASK", "confidence": 0.8959060907363892}]}, {"text": "FrameNet () was the first such resource, which made the emergence of this research field possible by the seminal work of.", "labels": [], "entities": [{"text": "FrameNet", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8259064555168152}]}, {"text": "However, this corpus only exemplifies the semantic role assignment by selecting some illustrative examples for annotation.", "labels": [], "entities": [{"text": "semantic role assignment", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.6383245289325714}]}, {"text": "This questions its suitability for statistical learning.", "labels": [], "entities": [{"text": "statistical learning", "start_pos": 35, "end_pos": 55, "type": "TASK", "confidence": 0.8583681285381317}]}, {"text": "Propbank was started by aiming at developing a more representative resource of English, appropriate for statistical SRL study.", "labels": [], "entities": [{"text": "Propbank", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9676219820976257}, {"text": "SRL study", "start_pos": 116, "end_pos": 125, "type": "TASK", "confidence": 0.8222728073596954}]}, {"text": "Propbank has been used as the learning framework by the majority of SRL work and competitions like CoNLL shared tasks.", "labels": [], "entities": [{"text": "Propbank", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.9342973232269287}, {"text": "SRL work", "start_pos": 68, "end_pos": 76, "type": "TASK", "confidence": 0.9038787484169006}]}, {"text": "However, it only covers the newswire text from a specific genre and also deals only with verb predicates.", "labels": [], "entities": []}, {"text": "All state-of-the-art SRL systems show a dramatic drop in performance when tested on anew text domain.", "labels": [], "entities": [{"text": "SRL", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.9733330011367798}]}, {"text": "This evince the infeasibility of building a comprehensive hand-crafted corpus of natural language useful for training a robust semantic role labeler.", "labels": [], "entities": []}, {"text": "A possible relief for this problem is the utility of semi-supervised learning methods along with the existence of huge amount of natural language text available at a low cost.", "labels": [], "entities": []}, {"text": "Semi-supervised methods compensate the scarcity of labeled data by utilizing an additional and much larger amount of unlabeled data via a variety of algorithms.", "labels": [], "entities": []}, {"text": "Self-training) is a semisupervised algorithm which has been well studied in the NLP area and gained promising result.", "labels": [], "entities": []}, {"text": "It iteratively extend its training set by labeling the unlabeled data using abase classifier trained on the labeled data.", "labels": [], "entities": []}, {"text": "Although the algorithm is theoretically straightforward, it involves a large number of parameters, highly influenced by the specifications of the underlying task.", "labels": [], "entities": []}, {"text": "Thus to achieve the best-performing parameter set or even to investigate the usefulness of these algorithms fora learning task such as SRL, a thorough experiment is required.", "labels": [], "entities": [{"text": "SRL", "start_pos": 135, "end_pos": 138, "type": "TASK", "confidence": 0.9577351808547974}]}, {"text": "This work investigates its application to the SRL problem.", "labels": [], "entities": [{"text": "SRL problem", "start_pos": 46, "end_pos": 57, "type": "TASK", "confidence": 0.9546650052070618}]}], "datasetContent": [{"text": "In these experiments, we target two main problems addressed by semi-supervised methods: the performance of the algorithm in exploiting unlabeled data when labeled data is scarce and the domain-generalizability of the algorithm by using an out-of-domain unlabeled data.", "labels": [], "entities": []}, {"text": "We use the CoNLL 2005 shared task data and setting for testing and evaluation purpose.", "labels": [], "entities": [{"text": "CoNLL 2005 shared task data", "start_pos": 11, "end_pos": 38, "type": "DATASET", "confidence": 0.9575364828109741}]}, {"text": "The evaluation metrics include precision, recall, and their harmonic mean, F1.", "labels": [], "entities": [{"text": "precision", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9997338652610779}, {"text": "recall", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9996825456619263}, {"text": "F1", "start_pos": 75, "end_pos": 77, "type": "METRIC", "confidence": 0.9841291904449463}]}], "tableCaptions": [{"text": " Table 2: Performances of the current system (Cur)  and the state-of-the-art (", "labels": [], "entities": []}]}