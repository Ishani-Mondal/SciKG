{"title": [{"text": "Using Document Level Cross-Event Inference to Improve Event Extraction", "labels": [], "entities": [{"text": "Document Level Cross-Event Inference", "start_pos": 6, "end_pos": 42, "type": "TASK", "confidence": 0.5365419313311577}, {"text": "Improve Event Extraction", "start_pos": 46, "end_pos": 70, "type": "TASK", "confidence": 0.850770095984141}]}], "abstractContent": [{"text": "Event extraction is a particularly challenging type of information extraction (IE).", "labels": [], "entities": [{"text": "Event extraction", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.764589250087738}, {"text": "information extraction (IE)", "start_pos": 55, "end_pos": 82, "type": "TASK", "confidence": 0.8538821995258331}]}, {"text": "Most current event extraction systems rely on local information at the phrase or sentence level.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.7311416566371918}]}, {"text": "However, this local context maybe insufficient to resolve ambiguities in identifying particular types of events; information from a wider scope can serve to resolve some of these ambiguities.", "labels": [], "entities": []}, {"text": "In this paper, we use document level information to improve the performance of ACE event extraction.", "labels": [], "entities": [{"text": "ACE event extraction", "start_pos": 79, "end_pos": 99, "type": "TASK", "confidence": 0.8919768929481506}]}, {"text": "In contrast to previous work, we do not limit ourselves to information about events of the same type, but rather use information about other types of events to make predictions or resolve ambiguities regarding a given event.", "labels": [], "entities": []}, {"text": "We learn such relationships from the training corpus and use them to help predict the occurrence of events and event arguments in a text.", "labels": [], "entities": []}, {"text": "Experiments show that we can get 9.0% (absolute) gain in trigger (event) classification, and more than 8% gain for argument (role) classification in ACE event extraction.", "labels": [], "entities": [{"text": "trigger (event) classification", "start_pos": 57, "end_pos": 87, "type": "TASK", "confidence": 0.5946358561515808}, {"text": "argument (role) classification", "start_pos": 115, "end_pos": 145, "type": "TASK", "confidence": 0.7077401161193848}, {"text": "ACE event extraction", "start_pos": 149, "end_pos": 169, "type": "TASK", "confidence": 0.840764582157135}]}], "introductionContent": [{"text": "The goal of event extraction is to identify instances of a class of events in text.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 12, "end_pos": 28, "type": "TASK", "confidence": 0.7410983443260193}]}, {"text": "The ACE 2005 event extraction task involved a set of 33 generic event types and subtypes appearing frequently in the news.", "labels": [], "entities": [{"text": "ACE 2005 event extraction task", "start_pos": 4, "end_pos": 34, "type": "TASK", "confidence": 0.8580202102661133}]}, {"text": "In addition to identifying the event itself, it also identifies all of the participants and attributes of each event; these are the entities that are involved in that event.", "labels": [], "entities": []}, {"text": "Identifying an event and its participants and attributes is quite difficult because a larger field of view is often needed to understand how facts tie together.", "labels": [], "entities": [{"text": "Identifying an event", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.8755394021670023}]}, {"text": "Sometimes it is difficult even for people to classify events from isolated sentences.", "labels": [], "entities": [{"text": "classify events from isolated sentences", "start_pos": 45, "end_pos": 84, "type": "TASK", "confidence": 0.8360138893127441}]}, {"text": "From the sentence: (1) He left the company.", "labels": [], "entities": []}, {"text": "it is hard to tell whether it is a Transport event in ACE, which means that he left the place; or an End-Position event, which means that he retired from the company.", "labels": [], "entities": [{"text": "ACE", "start_pos": 54, "end_pos": 57, "type": "DATASET", "confidence": 0.8128682971000671}, {"text": "End-Position", "start_pos": 101, "end_pos": 113, "type": "METRIC", "confidence": 0.9585800766944885}]}, {"text": "However, if we read the whole document, a clue like \"he planned to go shopping before he went home\" would give us confidence to tag it as a Transport event, while a clue like \"They held a party for his retirement\" would lead us to tag it as an End-Position event.", "labels": [], "entities": []}, {"text": "Such clues are evidence from the same event type.", "labels": [], "entities": []}, {"text": "However, sometimes another event type is also a good predictor.", "labels": [], "entities": []}, {"text": "For example, if we find a Start-Position event like \"he was named president three years ago\", we are also confident to tag (1) as End-Position event.", "labels": [], "entities": []}, {"text": "Event argument identification also shares this benefit.", "labels": [], "entities": [{"text": "Event argument identification", "start_pos": 0, "end_pos": 29, "type": "TASK", "confidence": 0.7917812863985697}]}, {"text": "Consider the following two sentences: (2) A bomb exploded in Bagdad; seven people died while 11 were injured.", "labels": [], "entities": [{"text": "Bagdad", "start_pos": 61, "end_pos": 67, "type": "DATASET", "confidence": 0.7214689254760742}]}, {"text": "(3) A bomb exploded in Bagdad; the suspect got caught when he tried to escape.", "labels": [], "entities": [{"text": "Bagdad", "start_pos": 23, "end_pos": 29, "type": "DATASET", "confidence": 0.6480240225791931}]}, {"text": "If we only consider the local context of the trigger \"exploded\", it is hard to determine that \"seven people\" is a likely Target of the Attack event in (2), or that the \"suspect\" is the Attacker of the Attack event, because the structures of (2) and (3) are quite similar.", "labels": [], "entities": []}, {"text": "The only clue is from the semantic inference that a person who died may well have been a Target of the Attack event, and the person arrested is probably the Attacker of the Attack event.", "labels": [], "entities": []}, {"text": "These maybe seen as examples of a broader textual inference problem, and in general such knowledge is quite difficult to acquire and apply.", "labels": [], "entities": []}, {"text": "However, in the present case we can take advantage of event extraction to learn these rules in a simpler fashion, which we present below.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 54, "end_pos": 70, "type": "TASK", "confidence": 0.7908636629581451}]}, {"text": "Most current event extraction systems are based on phrase or sentence level extraction.", "labels": [], "entities": [{"text": "event extraction", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.728634774684906}, {"text": "phrase or sentence level extraction", "start_pos": 51, "end_pos": 86, "type": "TASK", "confidence": 0.611299067735672}]}, {"text": "Several recent studies use high-level information to aid local event extraction systems.", "labels": [], "entities": [{"text": "local event extraction", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.633254756530126}]}, {"text": "For example,,,, and tried to use discourse, document, or cross-document information to improve information extraction.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 95, "end_pos": 117, "type": "TASK", "confidence": 0.7738347351551056}]}, {"text": "However, most of this research focuses on single event extraction, or focuses on high-level information within a single event type, and does not consider information acquired from other event types.", "labels": [], "entities": [{"text": "single event extraction", "start_pos": 42, "end_pos": 65, "type": "TASK", "confidence": 0.633231520652771}]}, {"text": "We extend these approaches by introducing cross-event information to enhance the performance of multi-event-type extraction systems.", "labels": [], "entities": [{"text": "multi-event-type extraction", "start_pos": 96, "end_pos": 123, "type": "TASK", "confidence": 0.7411954402923584}]}, {"text": "Cross-event information is quite useful: first, some events co-occur frequently, while other events do not.", "labels": [], "entities": []}, {"text": "For example, Attack, Die, and Injure events very frequently occur together, while Attack and Marry are less likely to co-occur.", "labels": [], "entities": []}, {"text": "Also, typical relations among the arguments of different types of events can be helpful in predicting information to be extracted.", "labels": [], "entities": []}, {"text": "For example, the Victim of a Die event is probably the Target of the Attack event.", "labels": [], "entities": [{"text": "Victim of a Die event", "start_pos": 17, "end_pos": 38, "type": "TASK", "confidence": 0.48026553988456727}]}, {"text": "As a result, we extend the observation that \"a document containing a certain event is likely to contain more events of the same type\", and base our approach on the idea that \"a document containing a certain type of event is likely to contain instances of related events\".", "labels": [], "entities": []}, {"text": "In this paper, automatically extracted within-event and cross-event information is used to aid traditional sentence level event extraction.", "labels": [], "entities": [{"text": "sentence level event extraction", "start_pos": 107, "end_pos": 138, "type": "TASK", "confidence": 0.636246033012867}]}], "datasetContent": [{"text": "We followed's evaluation and randomly select 10 newswire texts from the ACE 2005 training corpora as our development set, which is used for parameter tuning, and then conduct a blind test on a separate set of 40 ACE 2005 newswire texts.", "labels": [], "entities": [{"text": "ACE 2005 training corpora", "start_pos": 72, "end_pos": 97, "type": "DATASET", "confidence": 0.9298240542411804}, {"text": "parameter tuning", "start_pos": 140, "end_pos": 156, "type": "TASK", "confidence": 0.6762939840555191}, {"text": "ACE 2005 newswire texts", "start_pos": 212, "end_pos": 235, "type": "DATASET", "confidence": 0.9389824420213699}]}, {"text": "We use the rest of the ACE training corpus (549 documents) as training data for both the sentence-level baseline event tagger and document-level event tagger.", "labels": [], "entities": [{"text": "ACE training corpus", "start_pos": 23, "end_pos": 42, "type": "DATASET", "confidence": 0.8935136198997498}, {"text": "sentence-level baseline event tagger", "start_pos": 89, "end_pos": 125, "type": "TASK", "confidence": 0.5757402405142784}, {"text": "document-level event tagger", "start_pos": 130, "end_pos": 157, "type": "TASK", "confidence": 0.5748763779799143}]}, {"text": "To compare with previous work on within-event propagation, we reproduced Ji and Grishman (2008)'s approach for cross-sentence, within-event-type inference (see \"within-event-type rules\" in).", "labels": [], "entities": [{"text": "within-event propagation", "start_pos": 33, "end_pos": 57, "type": "TASK", "confidence": 0.7267277091741562}]}, {"text": "We applied their within-document inference rules using the cross-sentence confident-event information.", "labels": [], "entities": []}, {"text": "These rules basically serve to adjust trigger and argument classification to achieve document-wide consistency.", "labels": [], "entities": [{"text": "argument classification", "start_pos": 50, "end_pos": 73, "type": "TASK", "confidence": 0.6985305398702621}]}, {"text": "This process treats each event type separately: information about events of a given type is used to infer information about other events of the same type.", "labels": [], "entities": []}, {"text": "We report the overall Precision (P), Recall (R), and F-Measure (F) on blind test data.", "labels": [], "entities": [{"text": "Precision (P)", "start_pos": 22, "end_pos": 35, "type": "METRIC", "confidence": 0.9678160548210144}, {"text": "Recall (R)", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.9668439775705338}, {"text": "F-Measure (F)", "start_pos": 53, "end_pos": 66, "type": "METRIC", "confidence": 0.9741054177284241}]}, {"text": "In addition, we also report the performance of two human annotators on 28 ACE newswire texts (a subset of the blind test set).", "labels": [], "entities": [{"text": "ACE newswire texts", "start_pos": 74, "end_pos": 92, "type": "DATASET", "confidence": 0.9628812472025553}]}], "tableCaptions": [{"text": " Table 3. Events co-occurring with die events with  conditional probability > 10%", "labels": [], "entities": []}, {"text": " Table 5. Overall performance on blind test data", "labels": [], "entities": []}]}