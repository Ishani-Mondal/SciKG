{"title": [{"text": "Discriminative Modeling of Extraction Sets for Machine Translation", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.7551678121089935}]}], "abstractContent": [{"text": "We present a discriminative model that directly predicts which set of phrasal translation rules should be extracted from a sentence pair.", "labels": [], "entities": []}, {"text": "Our model scores extraction sets: nested collections of all the overlapping phrase pairs consistent with an underlying word alignment.", "labels": [], "entities": []}, {"text": "Extraction set models provide two principle advantages over word-factored alignment models.", "labels": [], "entities": []}, {"text": "First, we can incorporate features on phrase pairs, in addition to word links.", "labels": [], "entities": []}, {"text": "Second, we can optimize for an extraction-based loss function that relates directly to the end task of generating translations.", "labels": [], "entities": []}, {"text": "Our model gives improvements in alignment quality relative to state-of-the-art unsuper-vised and supervised baselines, as well as providing up to a 1.4 improvement in BLEU score in Chinese-to-English translation experiments.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 167, "end_pos": 177, "type": "METRIC", "confidence": 0.9792376160621643}]}], "introductionContent": [{"text": "In the last decade, the field of statistical machine translation has shifted from generating sentences word byword to systems that recycle whole fragments of training examples, expressed as translation rules.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 33, "end_pos": 64, "type": "TASK", "confidence": 0.6626008053620657}]}, {"text": "This general paradigm was first pursued using contiguous phrases (, and has since been generalized to a wide variety of hierarchical and syntactic formalisms.", "labels": [], "entities": []}, {"text": "The training stage of statistical systems focuses primarily on discovering translation rules in parallel corpora.", "labels": [], "entities": []}, {"text": "Most systems discover translation rules via a two-stage pipeline: a parallel corpus is aligned at the word level, and then a second procedure extracts fragment-level rules from word-aligned sentence pairs.", "labels": [], "entities": []}, {"text": "This paper offers a model-based alternative to phrasal rule extraction, which merges this two-stage pipeline into a single step.", "labels": [], "entities": [{"text": "phrasal rule extraction", "start_pos": 47, "end_pos": 70, "type": "TASK", "confidence": 0.7536932031313578}]}, {"text": "We present a discriminative model that directly predicts which set of phrasal translation rules should be extracted from a sentence pair.", "labels": [], "entities": []}, {"text": "Our model predicts extraction sets: combinatorial objects that include the set of all overlapping phrasal translation rules consistent with an underlying word-level alignment.", "labels": [], "entities": []}, {"text": "This approach provides additional discriminative power relative to word aligners because extraction sets are scored based on the phrasal rules they contain in addition to word-to-word alignment links.", "labels": [], "entities": []}, {"text": "Moreover, the structure of our model directly reflects the purpose of alignment models in general, which is to discover translation rules.", "labels": [], "entities": []}, {"text": "We address several challenges to training and applying an extraction set model.", "labels": [], "entities": []}, {"text": "First, we would like to leverage existing word-level alignment resources.", "labels": [], "entities": [{"text": "word-level alignment", "start_pos": 42, "end_pos": 62, "type": "TASK", "confidence": 0.7089490294456482}]}, {"text": "To do so, we define a deterministic mapping from word alignments to extraction sets, inspired by existing extraction procedures.", "labels": [], "entities": []}, {"text": "In our mapping, possible alignment links have a precise interpretation that dictates what phrasal translation rules can be extracted from a sentence pair.", "labels": [], "entities": []}, {"text": "This mapping allows us to train with existing annotated data sets and use the predictions from word-level aligners as features in our extraction set model.", "labels": [], "entities": []}, {"text": "Second, our model solves a structured prediction problem, and the choice of loss function during training affects model performance.", "labels": [], "entities": [{"text": "structured prediction", "start_pos": 27, "end_pos": 48, "type": "TASK", "confidence": 0.7163214385509491}]}, {"text": "We optimize fora phrase-level F-measure in order to focus learning on the task of predicting phrasal rules rather than word alignment links.", "labels": [], "entities": [{"text": "predicting phrasal rules", "start_pos": 82, "end_pos": 106, "type": "TASK", "confidence": 0.8442920247713724}]}, {"text": "Third, our discriminative approach requires that we perform inference in the space of extraction sets.", "labels": [], "entities": []}, {"text": "Our model does not factor over disjoint wordto-word links or minimal phrase pairs, and so existing inference procedures do not directly apply.", "labels": [], "entities": []}, {"text": "However, we show that the dynamic program fora block ITG aligner can be augmented to score extraction sets that are indexed by underlying ITG word alignments.", "labels": [], "entities": []}, {"text": "We also describe a [discover] was discovered Distribution over possible link types [two] [year] [in] Figure 1: A word alignment A (shaded grid cells) defines projections \u03c3(e i ) and \u03c3(f j ), shown as dotted lines for each word in each sentence.", "labels": [], "entities": []}, {"text": "The extraction set R 3 (A) includes all bispans licensed by these projections, shown as rounded rectangles.", "labels": [], "entities": []}, {"text": "coarse-to-fine inference approach that allows us to scale our method to long sentences.", "labels": [], "entities": []}, {"text": "Our extraction set model outperforms both unsupervised and supervised word aligners at predicting word alignments and extraction sets.", "labels": [], "entities": [{"text": "predicting word alignments", "start_pos": 87, "end_pos": 113, "type": "TASK", "confidence": 0.8098349769910177}]}, {"text": "We also demonstrate that extraction sets are useful for end-to-end machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 67, "end_pos": 86, "type": "TASK", "confidence": 0.6992990672588348}]}, {"text": "Our model improves translation quality relative to state-of-theart Chinese-to-English baselines across two publicly available systems, providing total BLEU improvements of 1.2 in Moses, a phrase-based system, and 1.4 in a Joshua, a hierarchical system ( 2 Extraction Set Models The input to our model is an unaligned sentence pair, and the output is an extraction set of phrasal translation rules.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 151, "end_pos": 155, "type": "METRIC", "confidence": 0.9992827773094177}]}, {"text": "Word-level alignments are generated as a byproduct of inference.", "labels": [], "entities": []}, {"text": "We first specify the relationship between word alignments and extraction sets, then define our model.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 42, "end_pos": 57, "type": "TASK", "confidence": 0.701318547129631}]}], "datasetContent": [{"text": "We evaluate our extraction set model by the bispans it predicts, the word alignments it generates, and the translations generated by two end-to-end systems.", "labels": [], "entities": []}, {"text": "compares the five systems described below, including three baselines.", "labels": [], "entities": []}, {"text": "All supervised aligners were optimized for bispan F 5 . Unsupervised Baseline: GIZA++.", "labels": [], "entities": [{"text": "Baseline", "start_pos": 69, "end_pos": 77, "type": "METRIC", "confidence": 0.858059287071228}, {"text": "GIZA", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.8666338920593262}]}, {"text": "We trained GIZA++ () using the default parameters included with the Moses training script (.", "labels": [], "entities": []}, {"text": "The designated regimen concludes by Viterbi aligning under Model 4 in both directions.", "labels": [], "entities": []}, {"text": "We combined these alignments with the grow-diag heuristic (.", "labels": [], "entities": []}, {"text": "Unsupervised Baseline: Joint HMM.", "labels": [], "entities": [{"text": "Joint HMM", "start_pos": 23, "end_pos": 32, "type": "TASK", "confidence": 0.6000869274139404}]}, {"text": "We trained and combined two HMM alignment models) using the Berkeley Aligner.", "labels": [], "entities": [{"text": "HMM alignment", "start_pos": 28, "end_pos": 41, "type": "TASK", "confidence": 0.8465491235256195}, {"text": "Berkeley Aligner", "start_pos": 60, "end_pos": 76, "type": "DATASET", "confidence": 0.9258311688899994}]}, {"text": "We initialized the HMM model parameters with jointly trained Model 1 parameters (), combined word-toword posteriors by averaging (soft union), and decoded with the competitive thresholding heuristic of, yielding a state-ofthe-art unsupervised baseline.", "labels": [], "entities": []}, {"text": "Supervised Baseline: Block ITG.", "labels": [], "entities": [{"text": "Block ITG", "start_pos": 21, "end_pos": 30, "type": "DATASET", "confidence": 0.828215092420578}]}, {"text": "We discriminatively trained a block ITG aligner with only sure links, using block terminal productions up to 3 words by 3 words in size.", "labels": [], "entities": []}, {"text": "This supervised baseline is a reimplementation of the MIRA-trained model of.", "labels": [], "entities": [{"text": "MIRA-trained", "start_pos": 54, "end_pos": 66, "type": "METRIC", "confidence": 0.3490425646305084}]}, {"text": "We use the same features and parser implementation for this model as we do for our extraction set model to ensure a clean comparison.", "labels": [], "entities": []}, {"text": "To remain within the alignment class, MIRA updates this model toward a pseudogold alignment with only sure links.", "labels": [], "entities": [{"text": "MIRA", "start_pos": 38, "end_pos": 42, "type": "DATASET", "confidence": 0.5096209645271301}]}, {"text": "This model does not score any overlapping bispans.", "labels": [], "entities": []}, {"text": "We add possible links to the output of the block ITG model by adding the mixed terminal block productions described in Section 2.3.", "labels": [], "entities": []}, {"text": "This model scores overlapping phrasal rules contained within terminal blocks that result from including or excluding possible links.", "labels": [], "entities": []}, {"text": "However, this model does not score bispans that cross bracketing of ITG derivations.", "labels": [], "entities": []}, {"text": "Our full model includes possible links and features on extraction sets for phrasal bispans with a maximum size of 3.", "labels": [], "entities": []}, {"text": "Model inference is performed using the coarseto-fine scheme described in Section 4.2.", "labels": [], "entities": [{"text": "Model inference", "start_pos": 0, "end_pos": 15, "type": "TASK", "confidence": 0.7476678788661957}]}, {"text": "We evaluate the alignments predicted by our model using two publicly available, open-source, state-of-the-art translation systems.", "labels": [], "entities": []}, {"text": "Moses is a phrase-based system with lexicalized reordering ().", "labels": [], "entities": []}, {"text": "Joshua () is an implementation of Hiero (Chiang, 2007) using a suffix-array-based grammar extraction approach.", "labels": [], "entities": [{"text": "Hiero (Chiang, 2007)", "start_pos": 34, "end_pos": 54, "type": "DATASET", "confidence": 0.8436629871527354}, {"text": "suffix-array-based grammar extraction", "start_pos": 63, "end_pos": 100, "type": "TASK", "confidence": 0.6640845934549967}]}, {"text": "Both of these systems take word alignments as input, and neither of these systems accepts possible links in the alignments they consume.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 27, "end_pos": 42, "type": "TASK", "confidence": 0.6972268968820572}]}, {"text": "To interface with our extraction set models, we produced three sets of sure-only alignments from our model predictions: one that omitted possible links, one that converted all possible links to sure links, and one that includes each possible link with 0.5 probability.", "labels": [], "entities": []}, {"text": "These three sets were aggregated and rules were extracted from all three.", "labels": [], "entities": []}, {"text": "The training set we used for MT experiments is quite heterogenous and noisy compared to our alignment test sets, and the supervised aligners did not handle certain sentence pairs in our parallel corpus well.", "labels": [], "entities": [{"text": "MT", "start_pos": 29, "end_pos": 31, "type": "TASK", "confidence": 0.9945777654647827}]}, {"text": "In some cases, pruning based on consistency with the HMM caused parse failures, which in turn caused training sentences to be skipped.", "labels": [], "entities": []}, {"text": "To account for these issues, we added counts of phrasal rules extracted from the baseline HMM to the counts produced by supervised aligners.", "labels": [], "entities": []}, {"text": "In Moses, our extraction set model predicts the set of phrases extracted by the system, and so the estimation techniques for the alignment model and translation model both share a common underlying representation: extraction sets.", "labels": [], "entities": []}, {"text": "Empirically, we observe a BLEU score improvement of 1.2 over the best unsupervised baseline and 0.8 over the block ITG supervised baseline ().", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 26, "end_pos": 36, "type": "METRIC", "confidence": 0.975764125585556}]}, {"text": "In Joshua, hierarchical rule extraction is based upon phrasal rule extraction, but abstracts away sub-phrases to create a grammar.", "labels": [], "entities": [{"text": "hierarchical rule extraction", "start_pos": 11, "end_pos": 39, "type": "TASK", "confidence": 0.6593156456947327}, {"text": "phrasal rule extraction", "start_pos": 54, "end_pos": 77, "type": "TASK", "confidence": 0.7687265674273173}]}, {"text": "Hence, the extraction sets we predict are closely linked to the representation that this system uses to translate.", "labels": [], "entities": []}, {"text": "The extraction model again outperformed both unsupervised and supervised baselines, by 1.4 BLEU and 1.2 BLEU respectively.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.9989091157913208}, {"text": "BLEU", "start_pos": 104, "end_pos": 108, "type": "METRIC", "confidence": 0.9963634610176086}]}], "tableCaptions": [{"text": " Table 1: Experimental results demonstrate that the full extraction set model outperforms supervised and  unsupervised baselines in evaluations of word alignment quality, extraction set quality, and translation.  In word and bispan evaluations, GIZA++ did not have access to a dictionary while all other methods  did. In the BLEU evaluation, all systems used a bilingual dictionary included in the training corpus. The  BLEU evaluation of supervised systems also included rule counts from the Joint HMM to compensate  for parse failures.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 147, "end_pos": 161, "type": "TASK", "confidence": 0.7035787552595139}, {"text": "translation", "start_pos": 199, "end_pos": 210, "type": "TASK", "confidence": 0.9523561000823975}, {"text": "BLEU", "start_pos": 325, "end_pos": 329, "type": "METRIC", "confidence": 0.8744091987609863}, {"text": "BLEU", "start_pos": 420, "end_pos": 424, "type": "METRIC", "confidence": 0.968665599822998}, {"text": "Joint HMM", "start_pos": 493, "end_pos": 502, "type": "DATASET", "confidence": 0.8581038415431976}]}]}