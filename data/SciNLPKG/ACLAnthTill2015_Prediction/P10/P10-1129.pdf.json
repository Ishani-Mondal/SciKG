{"title": [{"text": "Reading Between the Lines: Learning to Map High-level Instructions to Commands", "labels": [], "entities": [{"text": "Learning to Map High-level Instructions to Commands", "start_pos": 27, "end_pos": 78, "type": "TASK", "confidence": 0.693858231816973}]}], "abstractContent": [{"text": "In this paper, we address the task of mapping high-level instructions to sequences of commands in an external environment.", "labels": [], "entities": []}, {"text": "Processing these instructions is challenging-they posit goals to be achieved without specifying the steps required to complete them.", "labels": [], "entities": []}, {"text": "We describe a method that fills in missing information using an automatically derived environment model that encodes states, transitions , and commands that cause these transitions to happen.", "labels": [], "entities": []}, {"text": "We present an efficient approximate approach for learning this environment model as part of a policy-gradient reinforcement learning algorithm for text interpretation.", "labels": [], "entities": [{"text": "text interpretation", "start_pos": 147, "end_pos": 166, "type": "TASK", "confidence": 0.8116941750049591}]}, {"text": "This design enables learning for mapping high-level instructions , which previous statistical methods cannot handle.", "labels": [], "entities": []}], "introductionContent": [{"text": "In this paper, we introduce a novel method for mapping high-level instructions to commands in an external environment.", "labels": [], "entities": []}, {"text": "These instructions specify goals to be achieved without explicitly stating all the required steps.", "labels": [], "entities": []}, {"text": "For example, consider the first instruction in -\"open control panel.\"", "labels": [], "entities": []}, {"text": "The three GUI commands required for its successful execution are not explicitly described in the text, and need to be inferred by the user.", "labels": [], "entities": []}, {"text": "This dependence on domain knowledge makes the automatic interpretation of high-level instructions particularly challenging.", "labels": [], "entities": [{"text": "automatic interpretation of high-level instructions", "start_pos": 46, "end_pos": 97, "type": "TASK", "confidence": 0.7222769260406494}]}, {"text": "The standard approach to this task is to start with both a manually-developed model of the environment, and rules for interpreting high-level instructions in the context of this model.", "labels": [], "entities": []}, {"text": "Given both the model and the rules, logic-based inference is used to automatically fill in the intermediate steps missing from the original instructions.", "labels": [], "entities": []}, {"text": "Our approach, in contrast, operates directly on the textual instructions in the context of the interactive environment, while requiring no additional information.", "labels": [], "entities": []}, {"text": "By interacting with the environment and observing the resulting feedback, our method automatically learns both the mapping between the text and the commands, and the underlying model of the environment.", "labels": [], "entities": []}, {"text": "One particularly noteworthy aspect of our solution is the interplay between the evolving mapping and the progressively acquired environment model as the system learns how to interpret the text.", "labels": [], "entities": []}, {"text": "Recording the state transitions observed during interpretation allows the algorithm to construct a relevant model of the environment.", "labels": [], "entities": []}, {"text": "At the same time, the environment model enables the algorithm to consider the consequences of commands before they are executed, thereby improving the accuracy of interpretation.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 151, "end_pos": 159, "type": "METRIC", "confidence": 0.998310923576355}]}, {"text": "Our method efficiently achieves both of these goals as part of a policy-gradient reinforcement learning algorithm.", "labels": [], "entities": []}, {"text": "We apply our method to the task of mapping software troubleshooting guides to GUI actions in the Windows environment).", "labels": [], "entities": []}, {"text": "The key findings of our experiments are threefold.", "labels": [], "entities": []}, {"text": "First, the algorithm can accurately interpret 61.5% of high-level instructions, which cannot be handled by previous statistical systems.", "labels": [], "entities": []}, {"text": "Second, we demonstrate that explicitly modeling the environment also greatly improves the accuracy of processing low-level instructions, yielding a 14% absolute increase in performance over a competitive baseline).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9979382157325745}]}, {"text": "Finally, we show the importance of constructing an environment model relevant to the language interpretation task -using textual \"open control panel, double click system, then go to the advanced tab\" Document (input): \"go to the advanced tab\" : :: An example mapping of a document containing high-level instructions into a candidate sequence of five commands.", "labels": [], "entities": [{"text": "language interpretation task", "start_pos": 85, "end_pos": 113, "type": "TASK", "confidence": 0.7835103770097097}]}, {"text": "The mapping process involves segmenting the document into individual instruction word spans W a , and translating each instruction into the sequence c of one or more commands it describes.", "labels": [], "entities": []}, {"text": "During learning, the correct output command sequence is not provided to the algorithm.", "labels": [], "entities": []}, {"text": "instructions enables us to bias exploration toward transitions relevant for language learning.", "labels": [], "entities": []}, {"text": "This approach yields superior performance compared to a policy that relies on an environment model constructed via random exploration.", "labels": [], "entities": []}], "datasetContent": [{"text": "Datasets Our model is trained on the same dataset used by . For testing we use two datasets: the first one was used in prior work and contains only low-level instructions, while the second dataset is comprised of documents with high-level instructions.", "labels": [], "entities": []}, {"text": "This new dataset was collected from the Microsoft Help and Support website, and has on average 1.03 high-level instructions per document.", "labels": [], "entities": [{"text": "Microsoft Help and Support website", "start_pos": 40, "end_pos": 74, "type": "DATASET", "confidence": 0.7777197360992432}]}, {"text": "The second dataset contains 60 test documents, while the first is split into 70, 18 and 40 document for training, development and testing respectively.", "labels": [], "entities": []}, {"text": "The combined statistics for these datasets is shown below:, with set to 0.1.", "labels": [], "entities": []}, {"text": "We also identify dead-end states, i.e. states with the lowest possible immediate reward, and use the induced environment model to encourage additional exploration by lowering the likelihood of actions that lead to such dead-end states.", "labels": [], "entities": []}, {"text": "During the early stages of learning, experience gathered in the environment model is extremely sparse, causing the look-ahead features to provide poor estimates.", "labels": [], "entities": []}, {"text": "To speed convergence, we ignore these estimates by disabling the look-ahead features fora fixed number of initial training iterations.", "labels": [], "entities": []}, {"text": "Finally, to guarantee convergence, stochastic gradient ascent algorithms require a learning rate schedule.", "labels": [], "entities": [{"text": "stochastic gradient ascent", "start_pos": 35, "end_pos": 61, "type": "TASK", "confidence": 0.7271718382835388}]}, {"text": "We use a modified search-thenconverge algorithm, and tie the learning rate to the ratio of training documents that received a positive reward in the current iteration.", "labels": [], "entities": []}, {"text": "Baselines As a baseline, we compare our method against the results reported by , denoted here as BCZB09.", "labels": [], "entities": [{"text": "BCZB09", "start_pos": 97, "end_pos": 103, "type": "DATASET", "confidence": 0.8071268200874329}]}, {"text": "As an upper bound for model performance, we also evaluate our method using a reward signal that simulates a fully-supervised training regime.", "labels": [], "entities": []}, {"text": "We define a reward function that returns positive one for histories that match the annotations, and zero otherwise.", "labels": [], "entities": []}, {"text": "Performing policy-gradient with this function is equivalent to training a fullysupervised, stochastic gradient algorithm that optimizes conditional likelihood ( . Evaluation Metrics We evaluate the accuracy of the generated mapping by comparing it against manual annotations of the correct action sequences.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 198, "end_pos": 206, "type": "METRIC", "confidence": 0.9983874559402466}]}, {"text": "We measure the percentage of correct actions and the percentage of documents where every action is correct.", "labels": [], "entities": []}, {"text": "In general, the sequential nature of the interpretation task makes it difficult to achieve high action accuracy.", "labels": [], "entities": [{"text": "interpretation task", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.9033898115158081}, {"text": "accuracy", "start_pos": 103, "end_pos": 111, "type": "METRIC", "confidence": 0.9795666337013245}]}, {"text": "For example, executing an incorrect action early on, often leads to an environment state from which the remaining instructions cannot be completed.", "labels": [], "entities": []}, {"text": "When this happens, it is not possible to recover the remaining actions, causing cascading errors that significantly reduce performance.: Accuracy of the mapping produced by our model, its variants, and the baseline.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 137, "end_pos": 145, "type": "METRIC", "confidence": 0.9923174381256104}]}, {"text": "Values marked with * are statistically significant at p < 0.01 compared to the value immediately above it.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy of the mapping produced by our model, its variants, and the baseline. Values marked  with  *  are statistically significant at p < 0.01 compared to the value immediately above it.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9758428931236267}]}]}