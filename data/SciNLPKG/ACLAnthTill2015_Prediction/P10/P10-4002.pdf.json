{"title": [{"text": "cdec: A Decoder, Alignment, and Learning Framework for Finite-State and Context-Free Translation Models", "labels": [], "entities": []}], "abstractContent": [{"text": "We present cdec, an open source framework for decoding, aligning with, and training a number of statistical machine translation models, including word-based models, phrase-based models, and models based on synchronous context-free grammars.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 96, "end_pos": 127, "type": "TASK", "confidence": 0.655787855386734}]}, {"text": "Using a single unified internal representation for translation forests, the decoder strictly separates model-specific translation logic from general rescoring, pruning, and inference algorithms.", "labels": [], "entities": [{"text": "translation forests", "start_pos": 51, "end_pos": 70, "type": "TASK", "confidence": 0.9091466963291168}]}, {"text": "From this unified representation, the decoder can extract not only the 1-or k-best translations , but also alignments to a reference, or the quantities necessary to drive dis-criminative training using gradient-based or gradient-free optimization techniques.", "labels": [], "entities": []}, {"text": "Its efficient C++ implementation means that memory use and runtime performance are significantly better than comparable decoders.", "labels": [], "entities": []}], "introductionContent": [{"text": "The dominant models used in machine translation and sequence tagging are formally based on either weighted finite-state transducers (FSTs) or weighted synchronous context-free grammars (SCFGs).", "labels": [], "entities": [{"text": "machine translation", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.8126522600650787}, {"text": "sequence tagging", "start_pos": 52, "end_pos": 68, "type": "TASK", "confidence": 0.6535145789384842}]}, {"text": "Phrase-based models (, lexical translation models (, and finite-state conditional random fields) exemplify the former, and hierarchical phrase-based models the latter.", "labels": [], "entities": []}, {"text": "We introduce a software package called cdec that manipulates both classes in a unified way.", "labels": [], "entities": []}, {"text": "Although open source decoders for both phrasebased and hierarchical translation models have been available for several years (, their extensibility to new models and algorithms is limited by two significant design flaws that we have avoided with cdec.", "labels": [], "entities": []}, {"text": "First, their implementations tightly couple the translation, language model integration (which we call rescoring), and pruning algorithms.", "labels": [], "entities": [{"text": "translation", "start_pos": 48, "end_pos": 59, "type": "TASK", "confidence": 0.9612575173377991}, {"text": "language model integration", "start_pos": 61, "end_pos": 87, "type": "TASK", "confidence": 0.6555907825628916}]}, {"text": "This makes it difficult to explore alternative translation models without also re-implementing rescoring and pruning logic.", "labels": [], "entities": []}, {"text": "In cdec, model-specific code is only required to construct a translation forest ( \u00a73).", "labels": [], "entities": []}, {"text": "General rescoring (with language models or other models), pruning, inference, and alignment algorithms then apply to the unified data structure ( \u00a74).", "labels": [], "entities": []}, {"text": "Hence all model types benefit immediately from new algorithms (for rescoring, inference, etc.); new models can be more easily prototyped; and controlled comparison of models is made easier.", "labels": [], "entities": []}, {"text": "Second, existing open source decoders were designed with the traditional phrase-based parameterization using a very small number of dense features (typically less than 10).", "labels": [], "entities": []}, {"text": "cdec has been designed from the ground up to support any parameterization, from those with a handful of dense features up to models with millions of sparse features.", "labels": [], "entities": [{"text": "cdec", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8709688186645508}]}, {"text": "Since the inference algorithms necessary to compute a training objective (e.g. conditional likelihood or expected BLEU) and its gradient operate on the unified data structure ( \u00a75), any model type can be trained using with any of the supported training criteria.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 114, "end_pos": 118, "type": "METRIC", "confidence": 0.9631395936012268}]}, {"text": "The software package includes general function optimization utilities that can be used for discriminative training ( \u00a76).", "labels": [], "entities": []}, {"text": "These features are implemented without compromising on performance.", "labels": [], "entities": []}, {"text": "We show experimentally that cdec uses less memory and time than comparable decoders on a controlled translation task ( \u00a77).", "labels": [], "entities": []}], "datasetContent": [{"text": "The workstation used has two 2GHz quad-core Intel Xenon processors, 32GB RAM, is running Linux kernel version 2.6.18 and gcc version 4.1.2.", "labels": [], "entities": []}, {"text": "All decoders use SRI's language model toolkit, version 1.5.9.", "labels": [], "entities": []}, {"text": "Joshua was run on the Sun HotSpot JVM, version 1.6.0 12.", "labels": [], "entities": [{"text": "Sun HotSpot JVM", "start_pos": 22, "end_pos": 37, "type": "DATASET", "confidence": 0.9042906562487284}]}, {"text": "A hierarchical phrase-based translation grammar was extracted for the NIST MT03 Chinese-English translation using a suffix array rule extractor.", "labels": [], "entities": [{"text": "NIST MT03 Chinese-English translation", "start_pos": 70, "end_pos": 107, "type": "DATASET", "confidence": 0.8842501640319824}]}, {"text": "A non-terminal span limit of 15 was used, and all decoders were configured to use cube pruning with a limit of 30 candidates at each node and no further pruning.", "labels": [], "entities": []}, {"text": "All decoders produced a BLEU score between 31.4 and 31.6 (small differences are accounted for by different tie-breaking behavior and OOV handling).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 24, "end_pos": 34, "type": "METRIC", "confidence": 0.9787090718746185}, {"text": "OOV handling", "start_pos": 133, "end_pos": 145, "type": "METRIC", "confidence": 0.913464218378067}]}, {"text": "Figure 4: Configuration file (above) and feature weights file (below) used for the decoding test described in \u00a77.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Memory usage and average per-sentence  running time, in seconds, for decoding a Chinese- English test set.", "labels": [], "entities": []}]}