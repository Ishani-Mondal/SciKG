{"title": [{"text": "Improving Statistical Machine Translation with Monolingual Collocation", "labels": [], "entities": [{"text": "Improving Statistical Machine Translation", "start_pos": 0, "end_pos": 41, "type": "TASK", "confidence": 0.8772497922182083}]}], "abstractContent": [{"text": "\uf020 This paper proposes to use monolingual collocations to improve Statistical Machine Translation (SMT).", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 65, "end_pos": 102, "type": "TASK", "confidence": 0.8729764918486277}]}, {"text": "We make use of the collocation probabilities, which are estimated from monolingual corpora, in two aspects, namely improving word alignment for various kinds of SMT systems and improving phrase table for phrase-based SMT.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 125, "end_pos": 139, "type": "TASK", "confidence": 0.7156743556261063}, {"text": "SMT", "start_pos": 161, "end_pos": 164, "type": "TASK", "confidence": 0.9887121915817261}, {"text": "SMT", "start_pos": 217, "end_pos": 220, "type": "TASK", "confidence": 0.6851735711097717}]}, {"text": "The experimental results show that our method improves the performance of both word alignment and translation quality significantly.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 79, "end_pos": 93, "type": "TASK", "confidence": 0.8057162165641785}, {"text": "translation quality", "start_pos": 98, "end_pos": 117, "type": "TASK", "confidence": 0.8047268092632294}]}, {"text": "As compared to baseline systems, we achieve absolute improvements of 2.40 BLEU score on a phrase-based SMT system and 1.76 BLEU score on a parsing-based SMT system.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 74, "end_pos": 84, "type": "METRIC", "confidence": 0.9772571325302124}, {"text": "SMT", "start_pos": 103, "end_pos": 106, "type": "TASK", "confidence": 0.787785530090332}, {"text": "BLEU score", "start_pos": 123, "end_pos": 133, "type": "METRIC", "confidence": 0.9772197604179382}, {"text": "parsing-based SMT", "start_pos": 139, "end_pos": 156, "type": "TASK", "confidence": 0.6358160078525543}]}], "introductionContent": [{"text": "Statistical bilingual word alignment () is the base of most SMT systems.", "labels": [], "entities": [{"text": "Statistical bilingual word alignment", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.634907141327858}, {"text": "SMT", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.9957356452941895}]}, {"text": "As compared to single-word alignment, multi-word alignment is more difficult to be identified.", "labels": [], "entities": [{"text": "multi-word alignment", "start_pos": 38, "end_pos": 58, "type": "TASK", "confidence": 0.683660238981247}]}, {"text": "Although many methods were proposed to improve the quality of word alignments, the correlation of the words in multi-word alignments is not fully considered.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 62, "end_pos": 77, "type": "TASK", "confidence": 0.6920051723718643}]}, {"text": "In phrase-based SMT (, the phrase boundary is usually determined based on the bi-directional word alignments.", "labels": [], "entities": [{"text": "SMT", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.7700024843215942}]}, {"text": "But as far as we know, few previous studies exploit the collocation relations of the words in a phrase.", "labels": [], "entities": []}, {"text": "Some This work was partially done at Toshiba (China) researches used soft syntactic constraints to predict whether source phrase can be translated together (.", "labels": [], "entities": []}, {"text": "However, the constraints were learned from the parsed corpus, which is not available for many languages.", "labels": [], "entities": []}, {"text": "In this paper, we propose to use monolingual collocations to improve SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.9953384399414062}]}, {"text": "We first identify potentially collocated words and estimate collocation probabilities from monolingual corpora using a Monolingual Word Alignment (MWA) method (), which does not need any additional resource or linguistic preprocessing, and which outperforms previous methods on the same experimental data.", "labels": [], "entities": [{"text": "Monolingual Word Alignment (MWA)", "start_pos": 119, "end_pos": 151, "type": "TASK", "confidence": 0.7353683412075043}]}, {"text": "Then the collocation information is employed to improve Bilingual Word Alignment (BWA) for various kinds of SMT systems and to improve phrase table for phrase-based SMT.", "labels": [], "entities": [{"text": "Bilingual Word Alignment (BWA)", "start_pos": 56, "end_pos": 86, "type": "METRIC", "confidence": 0.6649766614039739}, {"text": "SMT", "start_pos": 108, "end_pos": 111, "type": "TASK", "confidence": 0.9911826848983765}, {"text": "SMT", "start_pos": 165, "end_pos": 168, "type": "TASK", "confidence": 0.681312084197998}]}, {"text": "To improve BWA, we re-estimate the alignment probabilities by using the collocation probabilities of words in the same cept.", "labels": [], "entities": [{"text": "BWA", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.5812028646469116}]}, {"text": "A cept is the set of source words that are connected to the same target word ().", "labels": [], "entities": []}, {"text": "An alignment between a source multi-word cept and a target word is a many-to-one multi-word alignment.", "labels": [], "entities": []}, {"text": "To improve phrase table, we calculate phrase collocation probabilities based on word collocation probabilities.", "labels": [], "entities": []}, {"text": "Then the phrase collocation probabilities are used as additional features in phrase-based SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 90, "end_pos": 93, "type": "TASK", "confidence": 0.8817915916442871}]}, {"text": "The evaluation results show that the proposed method in this paper significantly improves multi-word alignment, achieving an absolute error rate reduction of 29%.", "labels": [], "entities": [{"text": "multi-word alignment", "start_pos": 90, "end_pos": 110, "type": "TASK", "confidence": 0.7473026514053345}, {"text": "absolute error rate reduction", "start_pos": 125, "end_pos": 154, "type": "METRIC", "confidence": 0.8881096243858337}]}, {"text": "The alignment improvement results in an improvement of 2.16 BLEU score on phrase-based SMT system and an improvement of 1.76 BLEU score on parsing-based SMT system.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 60, "end_pos": 70, "type": "METRIC", "confidence": 0.9754178822040558}, {"text": "SMT", "start_pos": 87, "end_pos": 90, "type": "TASK", "confidence": 0.7921270728111267}, {"text": "BLEU", "start_pos": 125, "end_pos": 129, "type": "METRIC", "confidence": 0.9977074861526489}, {"text": "parsing-based SMT", "start_pos": 139, "end_pos": 156, "type": "TASK", "confidence": 0.6507295668125153}]}, {"text": "If we use phrase collocation probabilities as additional features, the phrase-based SMT performance is further improved by 0.24 BLEU score.", "labels": [], "entities": [{"text": "SMT", "start_pos": 84, "end_pos": 87, "type": "TASK", "confidence": 0.8558310866355896}, {"text": "BLEU", "start_pos": 128, "end_pos": 132, "type": "METRIC", "confidence": 0.9994537234306335}]}, {"text": "The paper is organized as follows: In section 2, we introduce the collocation model based on the MWA method.", "labels": [], "entities": []}, {"text": "In section 3 and 4, we show how to improve the BWA method and the phrase table using collocation models respectively.", "labels": [], "entities": [{"text": "BWA", "start_pos": 47, "end_pos": 50, "type": "METRIC", "confidence": 0.8623494505882263}]}, {"text": "We describe the experimental results in section 5, 6 and 7.", "labels": [], "entities": []}, {"text": "Lastly, we conclude in section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use FBIS corpus to train the Chinese-toEnglish SMT systems.", "labels": [], "entities": [{"text": "FBIS corpus", "start_pos": 7, "end_pos": 18, "type": "DATASET", "confidence": 0.8641131818294525}, {"text": "SMT", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.813112199306488}]}, {"text": "Moses () is used as the baseline phrase-based SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9207686185836792}]}, {"text": "We use SRI language modeling toolkit) to train a 5-gram language model on the English sentences of FBIS corpus.", "labels": [], "entities": [{"text": "FBIS corpus", "start_pos": 99, "end_pos": 110, "type": "DATASET", "confidence": 0.8829245567321777}]}, {"text": "We used the NIST MT-2002 set as the development set and the NIST MT-2004 test set as the test set.", "labels": [], "entities": [{"text": "NIST MT-2002 set", "start_pos": 12, "end_pos": 28, "type": "DATASET", "confidence": 0.869739810625712}, {"text": "NIST MT-2004 test set", "start_pos": 60, "end_pos": 81, "type": "DATASET", "confidence": 0.9187759906053543}]}, {"text": "And Koehn's implementation of minimum error rate training) is used to tune the feature weights on the development set.", "labels": [], "entities": []}, {"text": "We use BLEU () as evaluation metrics.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 7, "end_pos": 11, "type": "METRIC", "confidence": 0.9986518025398254}]}, {"text": "We also calculate the statistical significance differences between our methods and the baseline method by using paired bootstrap re-sample method).", "labels": [], "entities": []}, {"text": "We also investigate the effectiveness of the improved word alignments on the parsing-based SMT system, Joshua ( . In this system, the Hiero-style SCFG model is used We must adopt effective measures in order to avoid problems . We must adopt effective measures can we avoid out of the question .", "labels": [], "entities": [{"text": "word alignments", "start_pos": 54, "end_pos": 69, "type": "TASK", "confidence": 0.7217532843351364}, {"text": "parsing-based SMT", "start_pos": 77, "end_pos": 94, "type": "TASK", "confidence": 0.7232896685600281}]}], "tableCaptions": [{"text": " Table 1. Statistics of training data", "labels": [], "entities": []}, {"text": " Table 2. English-to-Chinese word alignment results", "labels": [], "entities": [{"text": "English-to-Chinese word alignment", "start_pos": 10, "end_pos": 43, "type": "TASK", "confidence": 0.5715795954068502}]}, {"text": " Table 4. Performances of Moses using the dif- ferent bi-directional word alignments (Signifi- cantly better than baseline with p < 0.01)", "labels": [], "entities": []}]}