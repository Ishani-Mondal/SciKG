{"title": [{"text": "Importance-Driven Turn-Bidding for Spoken Dialogue Systems", "labels": [], "entities": [{"text": "Importance-Driven Turn-Bidding", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7933159470558167}]}], "abstractContent": [{"text": "Current turn-taking approaches for spoken dialogue systems rely on the speaker releasing the turn before the other can take it.", "labels": [], "entities": []}, {"text": "This reliance results in restricted interactions that can lead to inefficient dialogues.", "labels": [], "entities": []}, {"text": "In this paper we present a model we refer to as Importance-Driven Turn-Bidding that treats turn-taking as a negotiative process.", "labels": [], "entities": []}, {"text": "Each conversant bids for the turn based on the importance of the intended utterance, and Reinforcement Learning is used to indirectly learn this parameter.", "labels": [], "entities": []}, {"text": "We find that Importance-Driven Turn-Bidding performs better than two current turn-taking approaches in an artificial collabo-rative slot-filling domain.", "labels": [], "entities": []}, {"text": "The negotiative nature of this model creates efficient dialogues , and supports the improvement of mixed-initiative interaction.", "labels": [], "entities": []}], "introductionContent": [{"text": "As spoken dialogue systems are designed to perform evermore elaborate tasks, the need for mixed-initiative interaction necessarily grows.", "labels": [], "entities": []}, {"text": "Mixed-initiative interaction, where agents (both artificial and human) may freely contribute to reach a solution efficiently, has long been a focus of dialogue systems research (.", "labels": [], "entities": []}, {"text": "Simple slot-filling tasks might not require the flexible environment that mixedinitiative interaction brings but those of greater complexity, such as collaborative task completion or long-term planning, certainly do.", "labels": [], "entities": []}, {"text": "However, translating this interaction into working systems has proved problematic (, in part to issues surrounding turn-taking: the transition from one speaker to another.", "labels": [], "entities": []}, {"text": "Many computational turn-taking approaches seek to minimize silence and utterance overlap during transitions.", "labels": [], "entities": []}, {"text": "This leads to the speaker controlling the turn transition.", "labels": [], "entities": []}, {"text": "For example, systems using the Keep-Or-Release approach will not attempt to take the turn unless it is sure the user has released it.", "labels": [], "entities": []}, {"text": "One problem with this approach is that the system might have important information to give but will be unable to get the turn.", "labels": [], "entities": []}, {"text": "The speaker-centric nature of current approaches does not enable mixed-initiative interaction and results in inefficient dialogues.", "labels": [], "entities": []}, {"text": "Primarily, these approaches have been motivated by smooth transitions reported in the human turn-taking studies of among others.", "labels": [], "entities": []}, {"text": "Sacks et al. also acknowledge the negotiative nature of turn-taking, stating that the \"the turn as unit is interactively determined\"(p. 727).", "labels": [], "entities": []}, {"text": "Other studies have supported this, suggesting that humans negotiate the turn assignment through the use of cues and that these cues are motivated by the importance of what the conversant wishes to contribute.", "labels": [], "entities": [{"text": "turn assignment", "start_pos": 72, "end_pos": 87, "type": "TASK", "confidence": 0.7378768622875214}]}, {"text": "Given this, any dialogue system hoping to interact with humans efficiently and naturally should have a negotiative and importance-driven quality to its turn-taking protocol.", "labels": [], "entities": []}, {"text": "We believe that, by focusing on the rationale of human turn-taking behavior, a more effective turn-taking system maybe achieved.", "labels": [], "entities": []}, {"text": "We propose the Importance-Driven Turn-Bidding (IDTB) model where conversants bid for the turn based on the importance of their utterance.", "labels": [], "entities": []}, {"text": "We use Reinforcement Learning to map a given situation to the optimal utterance and bidding behavior.", "labels": [], "entities": []}, {"text": "By allowing conversants to bid for the turn, the IDTB model enables negotiative turntaking and supports true mixed-initiative interaction, and with it, greater dialogue efficiency.", "labels": [], "entities": [{"text": "IDTB", "start_pos": 49, "end_pos": 53, "type": "DATASET", "confidence": 0.8690351843833923}]}, {"text": "We compare the IDTB model to current turntaking approaches.", "labels": [], "entities": [{"text": "IDTB", "start_pos": 15, "end_pos": 19, "type": "DATASET", "confidence": 0.8792375922203064}]}, {"text": "Using an artificial collaborative dialogue task, we show that the IDTB model enables the system and user to complete the task more efficiently than the other approaches.", "labels": [], "entities": []}, {"text": "Though artificial dialogues are not ideal, they allow us to test the validity of the IDTB model before embarking on costly and time-consuming human studies.", "labels": [], "entities": []}, {"text": "Since our primary evaluation criteria is model comparison, consistent user simulations provide a constant needed for such measures and increase the external validity of our results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We now evaluate the IDTB approach by comparing it against the two competing models: SingleUtterance and Keep-Or-Release.", "labels": [], "entities": [{"text": "Keep-Or-Release", "start_pos": 104, "end_pos": 119, "type": "METRIC", "confidence": 0.9184209704399109}]}, {"text": "The three turntaking approaches are trained and tested in four user conditions: novice, intermediate, expert, and combined.", "labels": [], "entities": []}, {"text": "In the combined condition, one of the three user types is randomly selected for each dialogue.", "labels": [], "entities": []}, {"text": "We train ten policies for each condition and turn-taking approach.", "labels": [], "entities": []}, {"text": "Policies are trained using Qlearning, and \u2212greedy search for 10000 epochs (1 epoch = 100 dialogues, after which the Q-scores are updated) with = 0.2.", "labels": [], "entities": []}, {"text": "Each policy is then ran over 10000 test dialogues with no exploration ( = 0), and the mean dialogue cost for that policy is determined.", "labels": [], "entities": []}, {"text": "The 10 separate policy values are then averaged to create the mean policy cost.", "labels": [], "entities": []}, {"text": "The mean policy cost between the turn-taking approaches and user conditions are shown in.", "labels": [], "entities": []}, {"text": "Lower numbers are indicative of shorter dialogues, since the system learns to successfully complete the task in all cases.", "labels": [], "entities": []}, {"text": "Single User Conditions: Single user conditions show how well each turn-taking approach can optimize its behavior for specific user populations and handle slight differences found in those populations.", "labels": [], "entities": []}, {"text": "shows that the mean policy cost of the SU model is higher than the other two models which indicates longer dialogues on average.", "labels": [], "entities": [{"text": "SU", "start_pos": 39, "end_pos": 41, "type": "TASK", "confidence": 0.8915984034538269}]}, {"text": "Since the SU system must respond to every user utterance and cannot learn a turn-taking strategy to utilize user knowledge, the dialogues are necessarily longer.", "labels": [], "entities": []}, {"text": "For example, in the expert condition the best possible dialogue fora SU interaction will have a cost of five (three user utterances for each slot, two system utterances in response).", "labels": [], "entities": []}, {"text": "This cost is in contrast to the best expert dialogue cost of three (three user utterances) for KR and IDTB interactions.", "labels": [], "entities": [{"text": "KR and IDTB interactions", "start_pos": 95, "end_pos": 119, "type": "TASK", "confidence": 0.5942098051309586}]}, {"text": "The IDTB turn-taking approach outperforms the KR design in all single user conditions ex-cept for novice (6.09 vs. 6.00).", "labels": [], "entities": [{"text": "IDTB", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.712348222732544}]}, {"text": "In this condition, the KR system takes the turn first, informs the available fillers for each slot, and then releases the turn.", "labels": [], "entities": []}, {"text": "The user can then inform its filler easily.", "labels": [], "entities": []}, {"text": "The IDTB system attempts a similar dialogue strategy by using highest bids but sometimes loses the turn when users also bid highest.", "labels": [], "entities": [{"text": "IDTB", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.9236997365951538}]}, {"text": "If the user uses the turn to query or inform an unavailable filler the dialogue grows longer.", "labels": [], "entities": []}, {"text": "However, this is quite rare as shown by small difference in performance between the two models.", "labels": [], "entities": []}, {"text": "In all other single user conditions, the IDTB approach has shorter dialogues than the KR approach (5.77 and 4.35 vs. 6.35 and 4.46).", "labels": [], "entities": []}, {"text": "A detailed explanation of IDTB's performance will be given in Section 6.1.", "labels": [], "entities": [{"text": "IDTB", "start_pos": 26, "end_pos": 30, "type": "DATASET", "confidence": 0.5991032719612122}, {"text": "Section 6.1", "start_pos": 62, "end_pos": 73, "type": "DATASET", "confidence": 0.8969465494155884}]}, {"text": "Combined User Condition: We next measure performance on the combined condition that mixes all three user types.", "labels": [], "entities": []}, {"text": "This condition is more realistic than the other three, as it better mimics how a system will be used in actual practice.", "labels": [], "entities": []}, {"text": "The IDTB approach (mean policy cost = 5.52) outperforms the KR (mean policy cost = 6.01) and SU (mean policy cost = 7.05) approaches.", "labels": [], "entities": []}, {"text": "We also observe that KR outperforms SU.", "labels": [], "entities": []}, {"text": "These results suggest that the more a turn-taking design can be flexible and negotiative, the more efficient the dialogues can be.", "labels": [], "entities": []}, {"text": "Exploiting User bidding differences: It follows that IDTB's performance stems from its negotiative turn transitions.", "labels": [], "entities": []}, {"text": "These transitions are distinctly different than KR transitions in that there is information inherent in the users bids.", "labels": [], "entities": []}, {"text": "A user that has a stronger belief strength is more likely to behave a higher bid and inform an available filler.", "labels": [], "entities": []}, {"text": "Policy analysis shows that the IDTB system takes advantage of this information by using moderate bids -neither highest nor lowest bids-to filter users based on their turn behavior.", "labels": [], "entities": [{"text": "IDTB", "start_pos": 31, "end_pos": 35, "type": "DATASET", "confidence": 0.8477330803871155}]}, {"text": "The distribution of bids used over the ten learned policies is shown in.", "labels": [], "entities": []}, {"text": "The initial position refers to the first bid of the dialogue; final position, the last bid of the dialogue; and medial position, all other bids.", "labels": [], "entities": []}, {"text": "Notice that the system uses either the low or mid bids as its initial policy and that 67.2% of dialogue medial bids are moderate.", "labels": [], "entities": []}, {"text": "These distributions show that the system has learned to use the entire bid range to filter the users, and is not seeking to win or lose the turn outright.", "labels": [], "entities": []}, {"text": "This behavior is impossible in the KR approach.", "labels": [], "entities": []}, {"text": "In our domain, performance is measured by dialogue length and solution quality.", "labels": [], "entities": []}, {"text": "However, since solution quality never affects the dialogue cost fora trained system, dialogue length is the only component influencing the mean policy cost.", "labels": [], "entities": []}, {"text": "The primary cause of longer dialogues are unavailable filler inform and query (UFI-Q) utterances by the user, which are easily identified.", "labels": [], "entities": []}, {"text": "These utterances lengthen the dialogue since the system must inform the user of the available fillers (the user would otherwise not know that the filler was unavailable) and then the user must then inform the system of its second choice.", "labels": [], "entities": []}, {"text": "The mean number of UFI-Q utterance for each dialogue over the ten learned policies are shown for all user conditions in.", "labels": [], "entities": []}, {"text": "Notice that these numbers are inversely related to performance: the more UFI-Q utterances, the worse the performance.", "labels": [], "entities": []}, {"text": "For example, in the combined condition the IDTB users perform 0.38 UFI-Q utterances per dialogue (u/d) compared to the 0.94 UFI-Q u/d for KR users.", "labels": [], "entities": [{"text": "IDTB", "start_pos": 43, "end_pos": 47, "type": "DATASET", "confidence": 0.9011757373809814}]}, {"text": "While a KR user will release the turn if its planned utterance has a weak belief, it may select that weak utterance when first getting the turn (either after a system utterance or at the start of the dialogue).", "labels": [], "entities": []}, {"text": "This may lead to a UFI-Q utterance.", "labels": [], "entities": [{"text": "UFI-Q utterance", "start_pos": 19, "end_pos": 34, "type": "TASK", "confidence": 0.6778876036405563}]}, {"text": "The IDTB system, however, will outbid the same user, resulting in a shorter dialogue.", "labels": [], "entities": [{"text": "IDTB", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.8841719627380371}]}, {"text": "This situation is shown in.", "labels": [], "entities": []}, {"text": "The dialogue is the same until utterance 3, where the IDTB system wins the turn with amid bid over the user's low bid.", "labels": [], "entities": [{"text": "IDTB", "start_pos": 54, "end_pos": 58, "type": "DATASET", "confidence": 0.8162360191345215}]}, {"text": "In the KR environment however, the user gets the turn and performs an unavailable filler inform, which the system must react to.", "labels": [], "entities": []}, {"text": "This is an instance of the second deficiency of the KR approach, where inform burger b3 5 mid high U: inform drink d1 6 l-est h-est U: inform side s1 7 high mid S: bye inform side s2 Release 8 S: bye the speaking system should not have released the turn.", "labels": [], "entities": []}, {"text": "The user has the same belief in both scenarios, but the negotiative nature of IDTB enables a shorter dialogues.", "labels": [], "entities": [{"text": "IDTB", "start_pos": 78, "end_pos": 82, "type": "DATASET", "confidence": 0.923194408416748}]}, {"text": "In short, the IDTB system can win the turn when it should have it, but the KR system cannot.", "labels": [], "entities": []}, {"text": "A lesser cause of longer dialogues is an instance of the first deficiency of the KR systems; the listening user cannot get the turn when it should have it.", "labels": [], "entities": []}, {"text": "Usually, this situation presents itself when the user releases the turn, having randomly chosen the weaker of the two unfilled slots.", "labels": [], "entities": []}, {"text": "The system then has the turn for more than one utterance, informing the available fillers for two slots.", "labels": [], "entities": []}, {"text": "However, the user already had a strong belief and available top filler for one of those slots, and the system has increased the dialogue length unnecessarily.", "labels": [], "entities": []}, {"text": "In the combined condition, the KR system produces 0.06 unnecessary informs per dialogue, whereas the IDTB system produces 0.045 per dialogue.", "labels": [], "entities": [{"text": "IDTB", "start_pos": 101, "end_pos": 105, "type": "DATASET", "confidence": 0.8632874488830566}]}, {"text": "The novice and intermediate conditions mirror this (IDTB: 0.009, 0.076 ; KR: 0.019, 0.096 respectfully), but the expert condition does not (IDTB: 0.011, KR: 0.0014).", "labels": [], "entities": [{"text": "IDTB", "start_pos": 52, "end_pos": 56, "type": "DATASET", "confidence": 0.6977537274360657}, {"text": "KR: 0.019", "start_pos": 73, "end_pos": 82, "type": "METRIC", "confidence": 0.8759186267852783}, {"text": "IDTB", "start_pos": 140, "end_pos": 144, "type": "DATASET", "confidence": 0.8541415929794312}]}, {"text": "In this case, the IDTB system wins the turn initially using a low bid and informs one of the strong slots, whereas the expert user initiates the dialogue for the KR environment and unnecessary informs are rarer.", "labels": [], "entities": []}, {"text": "In general, however, the KR approach has more unnecessary informs since the KR system can only infer that one of the user's beliefs was probably weak, otherwise the user would not have released the turn.", "labels": [], "entities": []}, {"text": "The IDTB system handles this situation by using a high bid, allowing the user to outbid the system as its contribution is more important.", "labels": [], "entities": [{"text": "IDTB", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.9216780066490173}]}, {"text": "In other words, the IDTB user can win the turn when it should have it, but the KR user cannot.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Notice  that in Line 3 the system informs the user that  their first filler, d1, is unavailable. The user then  asks asks about the availability of its second drink  choice, d2 (Line 4), and upon receiving an affirma- tive response (Line 5), informs the system of that  filler preference (Line 6).", "labels": [], "entities": []}, {"text": " Table 2: Single-Utterance dialogue  Spkr Speech Action  Utterance  1 S:  q. slot  q. drink  2 U: i. slot filler  i. drink d1  3 S:  i. filler not avail  i. not have d1  4 U: q. filler avail  q. drink have d2  5 S:  i. slot  i. yes  6 U: i. slot filler  i. drink d2  7 S:  i. avail slot fillers i. burger have b1", "labels": [], "entities": []}, {"text": " Table 3.  Lower numbers are indicative of shorter dialogues,  since the system learns to successfully complete  the task in all cases.", "labels": [], "entities": []}, {"text": " Table 3: Mean Policy Cost for Model and User  condition 7  Model Novice Int. Expert Combined  SU  7.61  7.09 6.43  7.05  KR  6.00  6.35 4.46  6.01  IDTB  6.09  5.77 4.35  5.52", "labels": [], "entities": [{"text": "Mean", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9550685882568359}, {"text": "Model Novice Int. Expert Combined  SU  7.61  7.09 6.43  7.05  KR  6.00  6.35 4.46  6.01  IDTB  6.09  5.77 4.35  5.52", "start_pos": 60, "end_pos": 176, "type": "DATASET", "confidence": 0.9090009416852679}]}, {"text": " Table 4: Bid percentages over ten policies in the  Combined User condition for IDTB  Position H-est High Mid Low L-est  Initial  0.0  0.0  70.0 30.0 0.0  Medial  20.5  19.4 24.5 23.3 12.3  Final  49.5  41.0 9.5  0.0  0.0", "labels": [], "entities": [{"text": "Bid percentages", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.9641510844230652}, {"text": "Mid Low L-est  Initial  0.0  0.0  70.0", "start_pos": 106, "end_pos": 144, "type": "METRIC", "confidence": 0.7586607166699001}]}, {"text": " Table 5. Notice that these numbers are  inversely related to performance: the more UFI- Q utterances, the worse the performance. For ex- ample, in the combined condition the IDTB users  perform 0.38 UFI-Q utterances per dialogue (u/d)  compared to the 0.94 UFI-Q u/d for KR users.  While a KR user will release the turn if its planned", "labels": [], "entities": []}, {"text": " Table 5: Mean number of UFI-Q utterances over  policies  Model Novice Int. Expert Combined  KR  0.0  1.15 0.53  0.94  IDTB  0.1  0.33 0.39  0.38", "labels": [], "entities": [{"text": "Mean number of", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9256020983060201}, {"text": "UFI-Q utterances", "start_pos": 25, "end_pos": 41, "type": "TASK", "confidence": 0.5436406284570694}, {"text": "Novice Int. Expert Combined  KR  0.0  1.15 0.53  0.94  IDTB  0.1  0.33 0.39  0.38", "start_pos": 64, "end_pos": 145, "type": "DATASET", "confidence": 0.7089841584364573}]}, {"text": " Table 6: Sample IDTB dialogue in Combined User  condition; Cost=6  Sys  Usr  Spkr Utt  1 low  mid  U:  inform burger b1  2 h-est low  S:  inform burger have b3  3 mid low  S:  inform side have s1  4 mid h-est U:", "labels": [], "entities": [{"text": "Sample IDTB", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.7244232892990112}, {"text": "Cost", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.9739252328872681}, {"text": "Sys  Usr  Spkr Utt  1 low  mid  U", "start_pos": 68, "end_pos": 101, "type": "METRIC", "confidence": 0.8246453925967216}]}]}