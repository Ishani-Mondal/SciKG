{"title": [], "abstractContent": [{"text": "Letter-phoneme alignment is usually generated by a straightforward application of the EM algorithm.", "labels": [], "entities": [{"text": "Letter-phoneme alignment", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7170465439558029}]}, {"text": "We explore several alternative alignment methods that employ phonetics, integer programming, and sets of constraints, and propose a novel approach of refining the EM alignment by aggregation of best alignments.", "labels": [], "entities": []}, {"text": "We perform both intrinsic and extrinsic evaluation of the assortment of methods.", "labels": [], "entities": []}, {"text": "We show that our proposed EM-Aggregation algorithm leads to the improvement of the state of the art in letter-to-phoneme conversion on several different data sets.", "labels": [], "entities": [{"text": "letter-to-phoneme conversion", "start_pos": 103, "end_pos": 131, "type": "TASK", "confidence": 0.6946976482868195}]}], "introductionContent": [{"text": "Letter-to-phoneme (L2P) conversion (also called grapheme-to-phoneme conversion) is the task of predicting the pronunciation of a word given its orthographic form by converting a sequence of letters into a sequence of phonemes.", "labels": [], "entities": [{"text": "Letter-to-phoneme (L2P) conversion", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.64080610871315}, {"text": "grapheme-to-phoneme conversion)", "start_pos": 48, "end_pos": 79, "type": "TASK", "confidence": 0.8493963877360026}, {"text": "predicting the pronunciation of a word", "start_pos": 95, "end_pos": 133, "type": "TASK", "confidence": 0.8605802754561106}]}, {"text": "The L2P task plays a crucial role in speech synthesis systems (), and is an important part of other applications, including spelling correction) and speechto-speech machine translation (Engelbrecht and).", "labels": [], "entities": [{"text": "speech synthesis", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.7601911425590515}, {"text": "spelling correction", "start_pos": 124, "end_pos": 143, "type": "TASK", "confidence": 0.8946636021137238}, {"text": "speechto-speech machine translation", "start_pos": 149, "end_pos": 184, "type": "TASK", "confidence": 0.6696208516756693}]}, {"text": "Many data-driven techniques have been proposed for letter-to-phoneme conversion systems, including neural networks, decision trees (), pronunciation by analogy), Hidden Markov Models (, and constraint satisfaction).", "labels": [], "entities": [{"text": "letter-to-phoneme conversion", "start_pos": 51, "end_pos": 79, "type": "TASK", "confidence": 0.7582827210426331}]}, {"text": "Letter-phoneme alignment is an important step in the L2P task.", "labels": [], "entities": [{"text": "Letter-phoneme alignment", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7056892961263657}]}, {"text": "The training data usually consists of pairs of letter and phoneme sequences, which are not aligned.", "labels": [], "entities": []}, {"text": "Since there is no explicit information indicating the relationships between individual letter and phonemes, these must be inferred by a letter-phoneme alignment algorithm before a prediction model can be trained.", "labels": [], "entities": []}, {"text": "The quality of the alignment affects the accuracy of L2P conversion.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 41, "end_pos": 49, "type": "METRIC", "confidence": 0.9996788501739502}, {"text": "L2P conversion", "start_pos": 53, "end_pos": 67, "type": "TASK", "confidence": 0.6310459524393082}]}, {"text": "Letter-phoneme alignment is closely related to transliteration alignment (), which involves graphemes representing different writing scripts.", "labels": [], "entities": [{"text": "Letter-phoneme alignment", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.683292418718338}, {"text": "transliteration alignment", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.784278005361557}]}, {"text": "Letter-phoneme alignment may also be considered as a task in itself; for example, in the alignment of speech transcription with text in spoken corpora.", "labels": [], "entities": [{"text": "Letter-phoneme alignment", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.6824444830417633}, {"text": "alignment of speech transcription", "start_pos": 89, "end_pos": 122, "type": "TASK", "confidence": 0.8020325750112534}]}, {"text": "Most previous L2P approaches induce the alignment between letters and phonemes with the expectation maximization (EM) algorithm.", "labels": [], "entities": [{"text": "expectation maximization (EM)", "start_pos": 88, "end_pos": 117, "type": "METRIC", "confidence": 0.8377012848854065}]}, {"text": "In this paper, we propose a number of alternative alignment methods, and compare them to the EMbased algorithms using both intrinsic and extrinsic evaluations.", "labels": [], "entities": []}, {"text": "The intrinsic evaluation is conducted by comparing the generated alignments to a manually-constructed gold standard.", "labels": [], "entities": []}, {"text": "The extrinsic evaluation uses two different generation techniques to perform letter-to-phoneme conversion on several different data sets.", "labels": [], "entities": [{"text": "letter-to-phoneme conversion", "start_pos": 77, "end_pos": 105, "type": "TASK", "confidence": 0.7219904065132141}]}, {"text": "We discuss the advantages and disadvantages of various methods, and show that better alignments tend to improve the accuracy of the L2P systems regardless of the actual technique.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.999096155166626}]}, {"text": "In particular, one of our proposed methods advances the state of the art in L2P conversion.", "labels": [], "entities": [{"text": "L2P conversion", "start_pos": 76, "end_pos": 90, "type": "TASK", "confidence": 0.6864115744829178}]}, {"text": "We also examine the relationship between alignment entropy and alignment quality.", "labels": [], "entities": []}, {"text": "This paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we enumerate the assumptions that the alignment methods commonly adopt.", "labels": [], "entities": []}, {"text": "In Section 3, we review previous work that employs the EM approach.", "labels": [], "entities": []}, {"text": "In Sections 4, 5 and 6, we describe alternative approaches based on phonetics, manuallyconstructed constraints, and Integer Programming, respectively.", "labels": [], "entities": []}, {"text": "In Section 7, we propose an algorithm to refine the alignments produced by EM.", "labels": [], "entities": []}, {"text": "Sections 8 and 9 are devoted to the intrinsic and extrinsic evaluation of various approaches.", "labels": [], "entities": []}, {"text": "Section 10 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "For the intrinsic evaluation, we compared the generated alignments to gold standard alignments extracted from the the core vocabulary of the Combilex data set ().", "labels": [], "entities": [{"text": "Combilex data set", "start_pos": 141, "end_pos": 158, "type": "DATASET", "confidence": 0.9554126858711243}]}, {"text": "Combilex is a high quality pronunciation lexicon with explicit expert manual alignments.", "labels": [], "entities": []}, {"text": "We used a subset of the lexicon composed of the core vocabulary containing 18,145 word-phoneme pairs.", "labels": [], "entities": []}, {"text": "The alignments contain 550 mappings, which include complex 4-1 and 2-3 types.", "labels": [], "entities": []}, {"text": "Each alignment approach creates alignments from unaligned word-phoneme pairs in an unsupervised fashion.", "labels": [], "entities": []}, {"text": "We distinguish between the 1-1 and M-M approaches.", "labels": [], "entities": []}, {"text": "We report the alignment quality in terms of precision, recall and Fscore.", "labels": [], "entities": [{"text": "alignment", "start_pos": 14, "end_pos": 23, "type": "TASK", "confidence": 0.892257034778595}, {"text": "precision", "start_pos": 44, "end_pos": 53, "type": "METRIC", "confidence": 0.9997968077659607}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9998311996459961}, {"text": "Fscore", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.999578058719635}]}, {"text": "Since the gold standard includes many links that involve multiple letters, the theoretical upper bound for recall achieved by a one-to-one approach is 90.02%.", "labels": [], "entities": [{"text": "recall", "start_pos": 107, "end_pos": 113, "type": "METRIC", "confidence": 0.9985161423683167}]}, {"text": "However, it is possible to obtain the perfect precision because we count as correct all 1-1 links that are consistent with the M-M links in the gold standard.", "labels": [], "entities": [{"text": "precision", "start_pos": 46, "end_pos": 55, "type": "METRIC", "confidence": 0.9798986911773682}]}, {"text": "The F-score corresponding to perfect precision and the upper-bound recall is 94.75%.", "labels": [], "entities": [{"text": "F-score", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.9995352029800415}, {"text": "perfect", "start_pos": 29, "end_pos": 36, "type": "METRIC", "confidence": 0.9859134554862976}, {"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.916976273059845}, {"text": "recall", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.9756591320037842}]}, {"text": "Alignment entropy is a measure of alignment quality proposed by in the context of transliteration.", "labels": [], "entities": [{"text": "Alignment entropy", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.9325324296951294}]}, {"text": "The entropy indicates the uncertainty of mapping between letter land phoneme p resulting from the alignment: We compute the alignment entropy for each of the methods using the following formula: includes the results of the intrinsic evaluation.", "labels": [], "entities": []}, {"text": "(the two rightmost columns are discussed in Section 9).", "labels": [], "entities": []}, {"text": "The baseline BaseEM is an implementation of the one-to-one alignment method of) without the allowable list.", "labels": [], "entities": []}, {"text": "ALINE is the phonetic method described in Section 4.", "labels": [], "entities": [{"text": "ALINE", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.9530404806137085}]}, {"text": "SeedMap is the hand-seeded method described in Section 5.", "labels": [], "entities": []}, {"text": "M-M-EM is the M2M-aligner approach of.", "labels": [], "entities": []}, {"text": "1-M-EM is equivalent to M-M-EM but with the restriction that each link contains exactly one letter.", "labels": [], "entities": []}, {"text": "IP-align is the alignment generated by the IP formulation from Section 6.", "labels": [], "entities": [{"text": "IP-align", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.8425419330596924}, {"text": "IP formulation from Section 6", "start_pos": 43, "end_pos": 72, "type": "DATASET", "confidence": 0.7074258863925934}]}, {"text": "IP-EM is the method that combines IP with EM described in Section 6.1.", "labels": [], "entities": []}, {"text": "EM-Aggr is our final many-to-many alignment method described in Section 7.", "labels": [], "entities": [{"text": "EM-Aggr", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.7565497159957886}]}, {"text": "Oracle corresponds to the gold-standard alignments from Combilex.", "labels": [], "entities": []}, {"text": "Overall, the M-M models obtain lower precision but higher recall and F-score than 1-1 models, which is to be expected as the gold standard is defined in terms of M-M links.", "labels": [], "entities": [{"text": "precision", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9992522597312927}, {"text": "recall", "start_pos": 58, "end_pos": 64, "type": "METRIC", "confidence": 0.9996625185012817}, {"text": "F-score", "start_pos": 69, "end_pos": 76, "type": "METRIC", "confidence": 0.9983795881271362}]}, {"text": "ALINE produces the most accurate alignments among the 1-1 methods, with the precision and recall values that are very close to the theoretical upper bounds.", "labels": [], "entities": [{"text": "precision", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9995383024215698}, {"text": "recall", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.998984158039093}]}, {"text": "Its precision is particularly impressive: on average, only one link in a thousand is not consistent with the gold standard.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9992153644561768}]}, {"text": "In terms of word accuracy, 98.97% words have no incorrect links.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 17, "end_pos": 25, "type": "METRIC", "confidence": 0.9549927115440369}]}, {"text": "Out of 18,145 words, only 112 words contain incorrect links, and further 75 words could not be aligned.", "labels": [], "entities": []}, {"text": "The ranking of the 1-1 methods is quite clear: ALINE followed by IP-EM, 1-M-EM, IP-align, and BaseEM.", "labels": [], "entities": [{"text": "ALINE", "start_pos": 47, "end_pos": 52, "type": "METRIC", "confidence": 0.995142936706543}]}, {"text": "Among the M-M methods, EM-Aggr has slightly better precision than M-M-EM, but its recall is much worse.", "labels": [], "entities": [{"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9990488886833191}, {"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.9997199177742004}]}, {"text": "This is probably caused by the aggregation strategy causing EM-Aggr to \"lose\" a significant number of correct links.", "labels": [], "entities": []}, {"text": "In general, the entropy measure does not mirror the quality of the alignment.: L2P word accuracy using the TiMBL-based generation system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 88, "end_pos": 96, "type": "METRIC", "confidence": 0.9703691005706787}]}, {"text": "In order to investigate the relationship between the alignment quality and L2P performance, we feed the alignments to two different L2P systems.", "labels": [], "entities": []}, {"text": "The first one is a classification-based learning system employing TiMBL (, which can utilize either 1-1 or 1-M alignments.", "labels": [], "entities": []}, {"text": "The second system is the state-of-the-art online discriminative training for letter-to-phoneme conversion (, which accepts both 1-1 and M-M types of alignment.", "labels": [], "entities": [{"text": "letter-to-phoneme conversion", "start_pos": 77, "end_pos": 105, "type": "TASK", "confidence": 0.7122604846954346}]}, {"text": "show that the online discriminative training system outperforms a number of competitive approaches, including joint ngrams (, constraint satisfaction inference), pronunciation by analogy), and decision trees ().", "labels": [], "entities": []}, {"text": "The decoder module uses standard Viterbi for the 1-1 case, and a phrasal decoder () for the M-M case.", "labels": [], "entities": []}, {"text": "We report the L2P performance in terms of word accuracy, which rewards only the completely correct output phoneme sequences.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9598872065544128}]}, {"text": "The data set is randomly split into 90% for training and 10% for testing.", "labels": [], "entities": []}, {"text": "For all experiments, we holdout 5% of our training data to determine when to stop the online training process.", "labels": [], "entities": []}, {"text": "includes the results on the Combilex data set.", "labels": [], "entities": [{"text": "Combilex data set", "start_pos": 28, "end_pos": 45, "type": "DATASET", "confidence": 0.9751048485438029}]}, {"text": "The two rightmost columns correspond to our two test L2P systems.", "labels": [], "entities": []}, {"text": "We observe that although better alignment quality does not always translate into better L2P accuracy, there is nevertheless a strong correlation between the two, especially for the weaker phoneme generation system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 92, "end_pos": 100, "type": "METRIC", "confidence": 0.9770426750183105}]}, {"text": "Interestingly, EM-Aggr matches the L2P accuracy obtained with the gold standard alignments.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 39, "end_pos": 47, "type": "METRIC", "confidence": 0.9574726223945618}]}, {"text": "However, there is no reason to claim that the gold standard alignments are optimal for the L2P generation task, so that result should not be considered as an upper bound.", "labels": [], "entities": [{"text": "L2P generation task", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.7903404434521993}]}, {"text": "Finally, we note that alignment entropy seems to match the L2P accuracy better than it matches alignment quality.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9202207326889038}]}, {"text": "show the L2P results on several evaluation sets: English Celex, CMUDict, NETTalk, OALD, and French Brulex.", "labels": [], "entities": [{"text": "English Celex", "start_pos": 49, "end_pos": 62, "type": "DATASET", "confidence": 0.914365291595459}, {"text": "OALD", "start_pos": 82, "end_pos": 86, "type": "METRIC", "confidence": 0.7890879511833191}, {"text": "French", "start_pos": 92, "end_pos": 98, "type": "DATASET", "confidence": 0.8878004550933838}, {"text": "Brulex", "start_pos": 99, "end_pos": 105, "type": "METRIC", "confidence": 0.5156201720237732}]}, {"text": "The training sizes range from 19K to 106K words.", "labels": [], "entities": []}, {"text": "We follow exactly the same data splits as in.", "labels": [], "entities": []}, {"text": "The TiMBL L2P generation method) is applicable only to the 1-1 alignment models.", "labels": [], "entities": [{"text": "TiMBL L2P generation", "start_pos": 4, "end_pos": 24, "type": "TASK", "confidence": 0.5081483324368795}]}, {"text": "ALINE produces the highest accuracy on four out of six datasets (including Combilex).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 27, "end_pos": 35, "type": "METRIC", "confidence": 0.999049723148346}]}, {"text": "The performance of IP-EM is comparable to 1-M-EM, but not consistently better.", "labels": [], "entities": []}, {"text": "IP-align does not seem to measure up to the other algorithms.", "labels": [], "entities": [{"text": "IP-align", "start_pos": 0, "end_pos": 8, "type": "DATASET", "confidence": 0.854944109916687}]}, {"text": "The discriminative approach is flexible enough to utilize all kinds of alignments.", "labels": [], "entities": []}, {"text": "However, the M-M models perform clearly better than 1-1 models.: L2P word accuracy using the online discriminative system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9742879867553711}]}, {"text": "can be attributed to the fact that NetTalk already includes double-phonemes in its original formulation.", "labels": [], "entities": []}, {"text": "In general, the 1-M-EM method achieves the best results among the 1-1 alignment methods, Overall, EM-Aggr achieves the best word accuracy in comparison to other alignment methods including the joint n-gram results, which are taken directly from the original paper of.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 129, "end_pos": 137, "type": "METRIC", "confidence": 0.8730127811431885}]}, {"text": "Except the Brulex and CMUDict data sets, the differences between EM-Aggr and M-M-EM are statistically significant according to McNemar's test at 90% confidence level.", "labels": [], "entities": [{"text": "Brulex", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.8616018295288086}, {"text": "CMUDict data sets", "start_pos": 22, "end_pos": 39, "type": "DATASET", "confidence": 0.9621047774950663}]}, {"text": "contains a plot of alignment entropy values vs. L2P word accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9067656993865967}]}, {"text": "Each point represent an application of a particular alignment method to a different data sets.", "labels": [], "entities": []}, {"text": "It appears that there is only weak correlation between alignment entropy and L2P accuracy.", "labels": [], "entities": [{"text": "alignment entropy", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.9322017431259155}, {"text": "accuracy", "start_pos": 81, "end_pos": 89, "type": "METRIC", "confidence": 0.9757635593414307}]}, {"text": "So far, we have been unable to find either director indirect evidence that alignment entropy is a reliable measure of letterphoneme alignment quality.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Alignment quality, entropy, and L2P conversion accuracy on the Combilex data set.", "labels": [], "entities": [{"text": "Alignment quality", "start_pos": 10, "end_pos": 27, "type": "METRIC", "confidence": 0.8025433719158173}, {"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9284099340438843}, {"text": "Combilex data set", "start_pos": 73, "end_pos": 90, "type": "DATASET", "confidence": 0.9644567966461182}]}, {"text": " Table 2: L2P word accuracy using the TiMBL-based generation system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9790123701095581}]}, {"text": " Table 3: L2P word accuracy using the online discriminative system.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9590342044830322}]}]}