{"title": [{"text": "On Jointly Recognizing and Aligning Bilingual Named Entities", "labels": [], "entities": [{"text": "Jointly Recognizing and Aligning Bilingual Named Entities", "start_pos": 3, "end_pos": 60, "type": "TASK", "confidence": 0.8188331723213196}]}], "abstractContent": [{"text": "We observe that (1) how a given named entity (NE) is translated (i.e., either semantically or phonetically) depends greatly on its associated entity type, and (2) entities within an aligned pair should share the same type.", "labels": [], "entities": []}, {"text": "Also, (3) those initially detected NEs are anchors , whose information should be used to give certainty scores when selecting candidates.", "labels": [], "entities": [{"text": "certainty", "start_pos": 94, "end_pos": 103, "type": "METRIC", "confidence": 0.9861465096473694}]}, {"text": "From this basis, an integrated model is thus proposed in this paper to jointly identify and align bilingual named entities between Chinese and English.", "labels": [], "entities": []}, {"text": "It adopts anew mapping type ratio feature (which is the proportion of NE internal tokens that are semantically translated), enforces an entity type consistency constraint, and utilizes additional monolingual candidate certainty factors (based on those NE anchors).", "labels": [], "entities": []}, {"text": "The experiments show that this novel approach has substantially raised the type-sensitive F-score of identified NE-pairs from 68.4% to 81.7% (42.1% F-score imperfection reduction) in our Chinese-English NE alignment task.", "labels": [], "entities": [{"text": "F-score", "start_pos": 90, "end_pos": 97, "type": "METRIC", "confidence": 0.9080261588096619}, {"text": "F-score imperfection reduction", "start_pos": 148, "end_pos": 178, "type": "METRIC", "confidence": 0.9278146028518677}, {"text": "NE alignment task", "start_pos": 203, "end_pos": 220, "type": "TASK", "confidence": 0.754708727200826}]}], "introductionContent": [{"text": "In trans-lingual language processing tasks, such as machine translation and cross-lingual information retrieval, named entity (NE) translation is essential.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 52, "end_pos": 71, "type": "TASK", "confidence": 0.8179716765880585}, {"text": "cross-lingual information retrieval", "start_pos": 76, "end_pos": 111, "type": "TASK", "confidence": 0.6753248473008474}, {"text": "named entity (NE) translation", "start_pos": 113, "end_pos": 142, "type": "TASK", "confidence": 0.6716681917508444}]}, {"text": "Bilingual NE alignment, which links source NEs and target NEs, is the first step to train the NE translation model.", "labels": [], "entities": [{"text": "Bilingual NE alignment", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7014655073483785}, {"text": "NE translation", "start_pos": 94, "end_pos": 108, "type": "TASK", "confidence": 0.9019184112548828}]}, {"text": "Since NE alignment can only be conducted after its associated NEs have first been identified, the including-rate of the first recognition stage significantly limits the final alignment performance.", "labels": [], "entities": [{"text": "NE alignment", "start_pos": 6, "end_pos": 18, "type": "TASK", "confidence": 0.9608783423900604}]}, {"text": "To alleviate the above error accumulation problem, two strategies have been proposed in the literature.", "labels": [], "entities": [{"text": "error accumulation", "start_pos": 23, "end_pos": 41, "type": "TASK", "confidence": 0.7201768755912781}]}, {"text": "The first strategy) identifies NEs only on the source side and then finds their corresponding NEs on the target side.", "labels": [], "entities": []}, {"text": "In this way, it avoids the NE recognition errors which would otherwise be brought into the alignment stage from the target side; however, the NE errors from the source side still remain.", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 27, "end_pos": 41, "type": "TASK", "confidence": 0.8543033599853516}]}, {"text": "To further reduce the errors from the source side, the second strategy ( expands the NE candidate-sets in both languages before conducting the alignment, which is done by treating the original results as anchors, and then re-generating further candidates by enlarging or shrinking those anchors' boundaries.", "labels": [], "entities": []}, {"text": "Of course, this strategy will be in vain if the NE anchor is missed in the initial detection stage.", "labels": [], "entities": []}, {"text": "In our data-set, this strategy significantly raises the NE-pair type-insensitive including-rate 1 from 83.9% to 96.1%, and is thus adopted in this paper.", "labels": [], "entities": [{"text": "including-rate 1", "start_pos": 81, "end_pos": 97, "type": "METRIC", "confidence": 0.832560271024704}]}, {"text": "Although the above expansion strategy has substantially alleviated the error accumulation problem, the final alignment accuracy is still not good (type-sensitive F-score only 68.4%, as indicated in in Section 4.2).", "labels": [], "entities": [{"text": "alignment", "start_pos": 109, "end_pos": 118, "type": "METRIC", "confidence": 0.8188091516494751}, {"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.798244297504425}, {"text": "F-score", "start_pos": 162, "end_pos": 169, "type": "METRIC", "confidence": 0.9145976305007935}]}, {"text": "After having examined the data, we found that: (1) How a given NE is translated, either semantically (called translation) or phonetically (called transliteration), depends greatly on its associated entity type 2 . The mapping type ratio, which is the percentage of NE internal tokens which are translated semantically, can help with the recognition of the associated NE type; (2) Entities within an aligned pair should share the same type, and this restriction should be integrated into NE alignment as a constraint; (3) Those initially identified monolingual NEs can act as anchors to give monolingual candidate certainty scores (preference weightings) for the re-generated candidates.", "labels": [], "entities": []}, {"text": "Based on the above observation, anew joint model which adopts the mapping type ratio, enforces the entity type consistency constraint, and also utilizes the monolingual candidate certainty factors is proposed in this paper to jointly identify and align bilingual NEs under an integrated framework.", "labels": [], "entities": []}, {"text": "This framework is decomposed into three subtasks: Initial Detection, Expansion, and Alignment&Re-identification.", "labels": [], "entities": [{"text": "Expansion", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9278839230537415}, {"text": "Alignment&Re-identification", "start_pos": 84, "end_pos": 111, "type": "TASK", "confidence": 0.8277721802393595}]}, {"text": "The Initial Detection subtask first locates the initial NEs and their associated NE types inside both the Chinese and English sides.", "labels": [], "entities": [{"text": "Initial Detection", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7108413577079773}]}, {"text": "Afterwards, the Expansion subtask re-generates the candidate-sets in both languages to recover those initial NE recognition errors.", "labels": [], "entities": []}, {"text": "Finally, the Alignment&Re-identification subtask jointly recognizes and aligns bilingual NEs via the proposed joint model presented in Section 3.", "labels": [], "entities": [{"text": "Alignment&Re-identification", "start_pos": 13, "end_pos": 40, "type": "TASK", "confidence": 0.8158436417579651}]}, {"text": "With this new approach, 41.8% imperfection reduction in type-sensitive F-score, from 68.4% to 81.6%, has been observed in our ChineseEnglish NE alignment task.", "labels": [], "entities": [{"text": "imperfection reduction", "start_pos": 30, "end_pos": 52, "type": "METRIC", "confidence": 0.7557109296321869}, {"text": "F-score", "start_pos": 71, "end_pos": 78, "type": "METRIC", "confidence": 0.9113345146179199}, {"text": "ChineseEnglish NE alignment task", "start_pos": 126, "end_pos": 158, "type": "DATASET", "confidence": 0.8646519333124161}]}], "datasetContent": [{"text": "To evaluate the proposed joint approach, a prior work () is re-implemented in our environment as the baseline, in which the translation cost, transliteration cost and tagging cost are used.", "labels": [], "entities": []}, {"text": "This model is selected for comparison because it not only adopts the same candidate-set expansion strategy as mentioned above, but also utilizes the monolingual information when selecting NE-pairs (however, only a simple bi-gram model is used as the tagging cost in their paper).", "labels": [], "entities": [{"text": "tagging", "start_pos": 250, "end_pos": 257, "type": "TASK", "confidence": 0.9612305164337158}]}, {"text": "Note that it enforces the same NE type only when the tagging cost is evaluated: To give a fairer comparison, the same training-set and testing-set are adopted.", "labels": [], "entities": []}, {"text": "The trainingset includes two parts.", "labels": [], "entities": []}, {"text": "The first part consists of 90,412 aligned sentence-pairs newswire data from the Foreign Broadcast Information Service (FBIS), which is denoted as Training-Set-I. The second Part of the training set is the LDC2005T34 bilingual NE dictionary 3 , which is denoted as Training-Set-II.", "labels": [], "entities": [{"text": "Foreign Broadcast Information Service (FBIS)", "start_pos": 80, "end_pos": 124, "type": "DATASET", "confidence": 0.7601522633007595}, {"text": "LDC2005T34 bilingual NE dictionary 3", "start_pos": 205, "end_pos": 241, "type": "DATASET", "confidence": 0.8512348532676697}]}, {"text": "The required feature information is then manually labeled throughout the two training sets.", "labels": [], "entities": []}, {"text": "In our experiments, for the baseline system, the translation cost and the transliteration cost are trained on Training-Set-II, while the tagging cost is trained on Training-Set-I. For the proposed approach, the monolingual candidate certainty factors are trained on Training-Set-I, and Training-Set-II is used to train the parameters relating to bilingual alignment factors.", "labels": [], "entities": []}, {"text": "For the testing-set, 300 sentence pairs are randomly selected from the LDC Chinese-English News Text (LDC2005T06).", "labels": [], "entities": [{"text": "LDC Chinese-English News Text (LDC2005T06)", "start_pos": 71, "end_pos": 113, "type": "DATASET", "confidence": 0.9520719732557025}]}, {"text": "The average length of the Chinese sentences is 59.4 characters, while the average length of the English sentences is 24.8 words.", "labels": [], "entities": []}, {"text": "Afterwards, the answer keys for NE recognition and alignment were annotated manually, and used as the gold standard to calculate metrics of precision (P), recall (R), and F-score (F) for both NE recognition (NER) and NE alignment (NEA).", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.9520645439624786}, {"text": "precision (P)", "start_pos": 140, "end_pos": 153, "type": "METRIC", "confidence": 0.9604161530733109}, {"text": "recall (R)", "start_pos": 155, "end_pos": 165, "type": "METRIC", "confidence": 0.96200230717659}, {"text": "F-score (F)", "start_pos": 171, "end_pos": 182, "type": "METRIC", "confidence": 0.9672218710184097}, {"text": "NE recognition (NER)", "start_pos": 192, "end_pos": 212, "type": "TASK", "confidence": 0.8712090611457824}, {"text": "NE alignment (NEA)", "start_pos": 217, "end_pos": 235, "type": "TASK", "confidence": 0.7903274059295654}]}, {"text": "In Total 765 Chinese NEs and 747 English NEs were manually labeled in the testing-set, within which there are only 718 NE pairs, including 214 PER, 371 LOC and 133 ORG NE-pairs.", "labels": [], "entities": [{"text": "PER", "start_pos": 143, "end_pos": 146, "type": "METRIC", "confidence": 0.9555599689483643}]}, {"text": "The number of NE pairs is less than that of NEs, because not all those recognized NEs can be aligned.", "labels": [], "entities": []}, {"text": "Besides, the development-set for MERT weight training is composed of 200 sentence pairs selected from the LDC2005T06 corpus, which includes 482 manually tagged NE pairs.", "labels": [], "entities": [{"text": "MERT weight training", "start_pos": 33, "end_pos": 53, "type": "TASK", "confidence": 0.9195729692776998}, {"text": "LDC2005T06 corpus", "start_pos": 106, "end_pos": 123, "type": "DATASET", "confidence": 0.9577664732933044}]}, {"text": "There is no overlap between the training-sets, the development-set and the testing-set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. Initial Chinese/English NER", "labels": [], "entities": [{"text": "Initial Chinese/English NER", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.4371890306472778}]}, {"text": " Table 3. Comparison between ME Framework  and Derived Model on the Testing-Set", "labels": [], "entities": []}, {"text": " Table 5. Testing-Set Performance for Semi- Supervised Learning of English NE Recognition", "labels": [], "entities": [{"text": "Semi- Supervised Learning of English NE Recognition", "start_pos": 38, "end_pos": 89, "type": "TASK", "confidence": 0.636642724275589}]}]}