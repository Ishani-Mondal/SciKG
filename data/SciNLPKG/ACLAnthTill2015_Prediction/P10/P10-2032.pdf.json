{"title": [{"text": "Balancing User Effort and Translation Error in Interactive Machine Translation Via Confidence Measures", "labels": [], "entities": [{"text": "Balancing User Effort", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.7911795576413473}, {"text": "Interactive Machine Translation Via Confidence Measures", "start_pos": 47, "end_pos": 102, "type": "TASK", "confidence": 0.6943324108918508}]}], "abstractContent": [{"text": "This work deals with the application of confidence measures within an interactive-predictive machine translation system in order to reduce human effort.", "labels": [], "entities": [{"text": "interactive-predictive machine translation", "start_pos": 70, "end_pos": 112, "type": "TASK", "confidence": 0.6970647176106771}]}, {"text": "If a small loss in translation quality can be tolerated for the sake of efficiency, user effort can be saved by interactively translating only those initial translations which the confidence measure classifies as incorrect.", "labels": [], "entities": []}, {"text": "We apply confidence estimation as away to achieve a balance between user effort savings and final translation error.", "labels": [], "entities": []}, {"text": "Empirical results show that our proposal allows to obtain almost perfect translations while significantly reducing user effort.", "labels": [], "entities": []}], "introductionContent": [{"text": "In Statistical Machine Translation (SMT), the translation is modelled as a decission process.", "labels": [], "entities": [{"text": "Statistical Machine Translation (SMT)", "start_pos": 3, "end_pos": 40, "type": "TASK", "confidence": 0.8846384088198344}]}, {"text": "For a given source string f J 1 = f 1 . .", "labels": [], "entities": []}, {"text": "f J , we seek for the target string e I 1 = e 1 . .", "labels": [], "entities": []}, {"text": "e I which maximises posterior probability: Within the Interactive-predictive Machine Translation (IMT) framework, a state-of-the-art SMT system is employed in the following way: For a given source sentence, the SMT system fully automatically generates an initial translation.", "labels": [], "entities": [{"text": "Interactive-predictive Machine Translation (IMT)", "start_pos": 54, "end_pos": 102, "type": "TASK", "confidence": 0.7815340658028921}, {"text": "SMT", "start_pos": 133, "end_pos": 136, "type": "TASK", "confidence": 0.984478771686554}]}, {"text": "A human translator checks this translation from left to right, correcting the first error.", "labels": [], "entities": [{"text": "correcting the first error", "start_pos": 63, "end_pos": 89, "type": "METRIC", "confidence": 0.8242253065109253}]}, {"text": "The SMT system then proposes anew extension, taking the correct prefix e i 1 = e 1 . .", "labels": [], "entities": [{"text": "SMT", "start_pos": 4, "end_pos": 7, "type": "TASK", "confidence": 0.9536834359169006}]}, {"text": "These steps are repeated until the whole input sentence has been correctly translated.", "labels": [], "entities": []}, {"text": "In the resulting decision rule, we maximise overall possible extensions e I i+1 of e i 1 : \u02c6 e \u02c6 I i+1 = argmax I,e I i+1 P r(e I i+1 |e i 1 , f J 1 ) . An implementation of the IMT famework was performed in the TransType project () and further improved within the TransType2 project (.", "labels": [], "entities": [{"text": "argmax I,e I i+1 P r", "start_pos": 105, "end_pos": 125, "type": "METRIC", "confidence": 0.9017210155725479}, {"text": "IMT famework", "start_pos": 178, "end_pos": 190, "type": "DATASET", "confidence": 0.8641178607940674}]}, {"text": "IMT aims at reducing the effort and increasing the productivity of translators, while preserving high-quality translation.", "labels": [], "entities": [{"text": "IMT", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8331806063652039}]}, {"text": "In this work, we integrate Confidence Measures (CMs) within the IMT framework to further reduce the user effort.", "labels": [], "entities": []}, {"text": "As will be shown, our proposal allows to balance the ratio between user effort and final translation error.", "labels": [], "entities": []}], "datasetContent": [{"text": "The aim of the experimentation was to study the possibly trade-off between saved user effort and translation error obtained when using sentence CMs within the IMT framework.", "labels": [], "entities": []}, {"text": "In this paper, we report our results as measured by Word Stroke Ratio (WSR) (.", "labels": [], "entities": [{"text": "Word Stroke Ratio (WSR)", "start_pos": 52, "end_pos": 75, "type": "METRIC", "confidence": 0.7618230283260345}]}, {"text": "WSR is used in the context of IMT to measure the effort required by the user to generate her translations.", "labels": [], "entities": [{"text": "WSR", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.5221092104911804}, {"text": "IMT", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.8229532241821289}]}, {"text": "WSR is computed as the ratio between the number of word-strokes a user would need to achieve the translation she has in mind and the total number of words in the sentence.", "labels": [], "entities": [{"text": "WSR", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.8132003545761108}]}, {"text": "In this context, a word-stroke is interpreted as a single action, in which the user types a complete word, and is assumed to have constant cost.", "labels": [], "entities": []}, {"text": "Additionally, and because our proposal allows differences between its output and the reference translation, we will also present translation quality results in terms of BiLingual Evaluation Understudy (BLEU) ().", "labels": [], "entities": [{"text": "BiLingual Evaluation Understudy (BLEU)", "start_pos": 169, "end_pos": 207, "type": "METRIC", "confidence": 0.7401539434989294}]}, {"text": "BLEU computes a geometric mean of the precision of ngrams multiplied by a factor to penalise short sentences.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.9718208312988281}, {"text": "precision", "start_pos": 38, "end_pos": 47, "type": "METRIC", "confidence": 0.9967917799949646}]}, {"text": "Our experiments were carried out on the EU corpora ().", "labels": [], "entities": [{"text": "EU corpora", "start_pos": 40, "end_pos": 50, "type": "DATASET", "confidence": 0.9506166279315948}]}, {"text": "The EU corpora were extracted from the Bulletin of the European Union.", "labels": [], "entities": [{"text": "the Bulletin of the European Union", "start_pos": 35, "end_pos": 69, "type": "DATASET", "confidence": 0.823589876294136}]}, {"text": "The EU corpora is composed of sentences given in three different language pairs.", "labels": [], "entities": []}, {"text": "Here, we will focus on the Spanish-English part of the EU corpora.", "labels": [], "entities": []}, {"text": "The corpus is divided into training, development and test sets.", "labels": [], "entities": []}, {"text": "The main figures of the corpus can be seen in.", "labels": [], "entities": []}, {"text": "As a first step, be built a SMT system to translate from Spanish into English.", "labels": [], "entities": [{"text": "SMT", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9894598722457886}]}, {"text": "This was done by means of the Thot toolkit (), which is a complete system for building phrasebased SMT models.", "labels": [], "entities": [{"text": "SMT", "start_pos": 99, "end_pos": 102, "type": "TASK", "confidence": 0.850061297416687}]}, {"text": "This toolkit involves the estimation, from the training set, of different statistical models, which are in turn combined in a loglinear fashion by adjusting a weight for each of them by means of the MERT) proce- dure, optimising the BLEU score on the development set.", "labels": [], "entities": [{"text": "MERT) proce- dure", "start_pos": 199, "end_pos": 216, "type": "METRIC", "confidence": 0.9342781186103821}, {"text": "BLEU score", "start_pos": 233, "end_pos": 243, "type": "METRIC", "confidence": 0.9792093932628632}]}, {"text": "The IMT system which we have implemented relies on the use of word graphs () to efficiently compute the suffix fora given prefix.", "labels": [], "entities": []}, {"text": "A word graph has to be generated for each sentence to be interactively translated.", "labels": [], "entities": []}, {"text": "For this purpose, we used a multi-stack phrase-based decoder which will be distributed in the near future together with the Thot toolkit.", "labels": [], "entities": []}, {"text": "We discarded to use the state-of-the-art Moses toolkit ( because preliminary experiments performed with it revealed that the decoder by performs better in terms of WSR when used to generate word graphs for their use in IMT.", "labels": [], "entities": []}, {"text": "Moreover, the performance difference in regular SMT is negligible.", "labels": [], "entities": [{"text": "SMT", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.9722487330436707}]}, {"text": "The decoder was set to only consider monotonic translation, since in real IMT scenarios considering non-monotonic translation leads to excessive response time for the user.", "labels": [], "entities": []}, {"text": "Finally, the obtained word graphs were used within the IMT procedure to produce the reference translations in the test set, measuring WSR and BLEU.", "labels": [], "entities": [{"text": "IMT", "start_pos": 55, "end_pos": 58, "type": "TASK", "confidence": 0.6018562316894531}, {"text": "WSR", "start_pos": 134, "end_pos": 137, "type": "METRIC", "confidence": 0.9904987215995789}, {"text": "BLEU", "start_pos": 142, "end_pos": 146, "type": "METRIC", "confidence": 0.9965620636940002}]}], "tableCaptions": [{"text": " Table 1: Statistics of the Spanish-English EU cor- pora. K and M denote thousands and millions of  elements respectively.", "labels": [], "entities": [{"text": "Spanish-English EU cor- pora", "start_pos": 28, "end_pos": 56, "type": "DATASET", "confidence": 0.7409840643405914}]}]}