{"title": [{"text": "Learning to Adapt to Unknown Users: Referring Expression Generation in Spoken Dialogue Systems", "labels": [], "entities": [{"text": "Referring Expression Generation", "start_pos": 36, "end_pos": 67, "type": "TASK", "confidence": 0.9069666663805643}]}], "abstractContent": [{"text": "We present a data-driven approach to learn user-adaptive referring expression generation (REG) policies for spoken dialogue systems.", "labels": [], "entities": [{"text": "user-adaptive referring expression generation (REG)", "start_pos": 43, "end_pos": 94, "type": "TASK", "confidence": 0.7610747856753213}]}, {"text": "Referring expressions can be difficult to understand in technical domains where users may not know the technical 'jargon' names of the domain entities.", "labels": [], "entities": [{"text": "Referring expressions", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.91013103723526}]}, {"text": "In such cases, dialogue systems must be able to model the user's (lexical) domain knowledge and use appropriate referring expressions.", "labels": [], "entities": []}, {"text": "We present a reinforcement learning (RL) framework in which the system learns REG policies which can adapt to unknown users online.", "labels": [], "entities": [{"text": "reinforcement learning (RL)", "start_pos": 13, "end_pos": 40, "type": "TASK", "confidence": 0.6715009689331055}]}, {"text": "Furthermore, unlike supervised learning methods which require a large corpus of expert adaptive behaviour to train on, we show that effective adaptive policies can be learned from a small dialogue corpus of non-adaptive human-machine interaction, by using a RL framework and a statistical user simulation.", "labels": [], "entities": []}, {"text": "We show that in comparison to adaptive hand-coded baseline policies, the learned policy performs significantly better , with an 18.6% average increase in adaptation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 165, "end_pos": 173, "type": "METRIC", "confidence": 0.950481116771698}]}, {"text": "The best learned policy also takes less dialogue time (average 1.07 min less) than the best hand-coded policy.", "labels": [], "entities": []}, {"text": "This is because the learned policies can adapt online to changing evidence about the user's domain expertise.", "labels": [], "entities": []}], "introductionContent": [{"text": "We present a reinforcement learning) framework to learn user-adaptive referring expression generation policies from datadriven user simulations.", "labels": [], "entities": [{"text": "user-adaptive referring expression generation", "start_pos": 56, "end_pos": 101, "type": "TASK", "confidence": 0.5744256749749184}]}, {"text": "A user-adaptive REG policy allows the system to choose appropriate expressions to refer to domain entities in a dialogue Jargon: Please plug one end of the broadband cable into the broadband filter.", "labels": [], "entities": []}, {"text": "Descriptive: Please plug one end of the thin white cable with grey ends into the small white box. setting.", "labels": [], "entities": []}, {"text": "For instance, in a technical support conversation, the system could choose to use more technical terms with an expert user, or to use more descriptive and general expressions with novice users, and a mix of the two with intermediate users of various sorts (see examples in).", "labels": [], "entities": []}, {"text": "In natural human-human conversations, dialogue partners learn about each other and adapt their language to suit their domain expertise.", "labels": [], "entities": []}, {"text": "This kind of adaptation is called Alignment through Audience Design.", "labels": [], "entities": [{"text": "Alignment", "start_pos": 34, "end_pos": 43, "type": "TASK", "confidence": 0.9857989549636841}]}, {"text": "We assume that users are mostly unknown to the system and therefore that a spoken dialogue system (SDS) must be capable of observing the user's dialogue behaviour, modelling his/her domain knowledge, and adapting accordingly, just like human interlocutors.", "labels": [], "entities": []}, {"text": "Rule-based and supervised learning approaches to user adaptation in SDS have been proposed earlier.", "labels": [], "entities": [{"text": "user adaptation", "start_pos": 49, "end_pos": 64, "type": "TASK", "confidence": 0.7880712449550629}, {"text": "SDS", "start_pos": 68, "end_pos": 71, "type": "TASK", "confidence": 0.830277144908905}]}, {"text": "However, such methods require expensive resources such as domain experts to hand-code the rules, or a corpus of expertlayperson interactions to train on.", "labels": [], "entities": []}, {"text": "In contrast, we present a corpus-driven framework using which a user-adaptive REG policy can be learned using RL from a small corpus of non-adaptive humanmachine interaction.", "labels": [], "entities": []}, {"text": "We show that these learned policies perform better than simple hand-coded adaptive policies in terms of accuracy of adaptation and dialogue time.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 104, "end_pos": 112, "type": "METRIC", "confidence": 0.9992474317550659}]}, {"text": "We also compared the performance of policies learned using a hand-coded rule-based simulation and a data-driven statistical simulation and show that data-driven simulations produce better policies than rule-based ones.", "labels": [], "entities": []}, {"text": "In section 2, we present some of the related work.", "labels": [], "entities": []}, {"text": "Section 3 presents the dialogue data that we used to train the user simulation.", "labels": [], "entities": []}, {"text": "Section 4 and section 5 describe the dialogue system framework and the user simulation models.", "labels": [], "entities": []}, {"text": "In section 6, we present the training and in section 7, we present the evaluation for different REG policies.", "labels": [], "entities": [{"text": "REG", "start_pos": 96, "end_pos": 99, "type": "TASK", "confidence": 0.7528896927833557}]}], "datasetContent": [{"text": "In this section, we present the evaluation metrics used, the baseline policies that were hand-coded for comparison, and the results of evaluation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Evaluation on 5 user types", "labels": [], "entities": []}]}