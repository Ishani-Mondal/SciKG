{"title": [{"text": "WSD as a Distributed Constraint Optimization Problem", "labels": [], "entities": [{"text": "WSD", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8514783382415771}]}], "abstractContent": [{"text": "This work models Word Sense Disam-biguation (WSD) problem as a Distributed Constraint Optimization Problem (DCOP).", "labels": [], "entities": [{"text": "Word Sense Disam-biguation (WSD) problem", "start_pos": 17, "end_pos": 57, "type": "TASK", "confidence": 0.7167340772492545}]}, {"text": "To model WSD as a DCOP, we view information from various knowledge sources as constraints.", "labels": [], "entities": [{"text": "WSD", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.9595566391944885}]}, {"text": "DCOP algorithms have the remarkable property to jointly maximize over a wide range of utility functions associated with these constraints.", "labels": [], "entities": []}, {"text": "We show how utility functions can be designed for various knowledge sources.", "labels": [], "entities": []}, {"text": "For the purpose of evaluation, we modelled all words WSD as a simple DCOP problem.", "labels": [], "entities": []}, {"text": "The results are competitive with state-of-art knowledge based systems .", "labels": [], "entities": []}], "introductionContent": [{"text": "Words in a language may carry more than one sense.", "labels": [], "entities": []}, {"text": "The correct sense of a word can be identified based on the context in which it occurs.", "labels": [], "entities": []}, {"text": "In the sentence, He took all his money from the bank, bank refers to a financial institution sense instead of other possibilities like the edge of river sense.", "labels": [], "entities": []}, {"text": "Given a word and its possible senses, as defined by a dictionary, the problem of Word Sense Disambiguation (WSD) can be defined as the task of assigning the most appropriate sense to the word within a given context.", "labels": [], "entities": [{"text": "Word Sense Disambiguation (WSD)", "start_pos": 81, "end_pos": 112, "type": "TASK", "confidence": 0.7800784409046173}]}, {"text": "WSD is one of the oldest problems in computational linguistics which dates back to early 1950's.", "labels": [], "entities": [{"text": "WSD", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.7969090342521667}, {"text": "computational linguistics", "start_pos": 37, "end_pos": 62, "type": "TASK", "confidence": 0.7541878521442413}]}, {"text": "A range of knowledge sources have been found to be useful for WSD.; highlight the importance of various knowledge sources like part of speech, morphology, collocations, lexical knowledge base (sense taxonomy, gloss), sub-categorization, semantic word associations, selectional preferences, semantic roles, domain, topical word associations, frequency of senses, collocations, domain knowledge. etc.", "labels": [], "entities": [{"text": "WSD.", "start_pos": 62, "end_pos": 66, "type": "TASK", "confidence": 0.9907355904579163}]}, {"text": "Methods for WSD exploit information from one or more of these knowledge sources.", "labels": [], "entities": [{"text": "WSD", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9929116368293762}]}, {"text": "Supervised approaches like;) used collective information from various knowledge sources to perform disambiguation.", "labels": [], "entities": []}, {"text": "Information from various knowledge sources is encoded in the form of a feature vector and models were built by training on sense-tagged corpora.", "labels": [], "entities": []}, {"text": "These approaches pose WSD as a classification problem.", "labels": [], "entities": [{"text": "WSD", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9802886247634888}]}, {"text": "They crucially rely on hand-tagged sense corpora which is hard to obtain.", "labels": [], "entities": []}, {"text": "Systems that do not need hand-tagging have also been proposed.) evaluated the contribution of each knowledge source separately.", "labels": [], "entities": []}, {"text": "However, this does not combine information from more than one knowledge source.", "labels": [], "entities": []}, {"text": "In any case, little effort has been made in formalizing the way in which information from various knowledge sources can be collectively used within a single framework: a framework that allows interaction of evidence from various knowledge sources to arrive at a global optimal solution.", "labels": [], "entities": []}, {"text": "Here we present away for modelling information from various knowledge sources in a multi agent setting called distributed constraint optimization problem (DCOP).", "labels": [], "entities": [{"text": "distributed constraint optimization problem (DCOP)", "start_pos": 110, "end_pos": 160, "type": "TASK", "confidence": 0.7925346706594739}]}, {"text": "In DCOP, agents have constraints on their values and each constraint has a utility associated with it.", "labels": [], "entities": []}, {"text": "The agents communicate with each other and choose values such that a global optimum solution (maximum utility) is attained.", "labels": [], "entities": []}, {"text": "We aim to solve WSD by modelling it as a DCOP.", "labels": [], "entities": [{"text": "WSD", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.8794890642166138}]}, {"text": "To the best of our knowledge, ours is the first attempt to model WSD as a DCOP.", "labels": [], "entities": [{"text": "WSD", "start_pos": 65, "end_pos": 68, "type": "TASK", "confidence": 0.9356117844581604}]}, {"text": "In DCOP framework, information from various knowledge sources can be used combinedly to perform WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 96, "end_pos": 99, "type": "TASK", "confidence": 0.941100537776947}]}, {"text": "In section 2, we give a brief introduction of DCOP.", "labels": [], "entities": [{"text": "DCOP", "start_pos": 46, "end_pos": 50, "type": "TASK", "confidence": 0.6719374060630798}]}, {"text": "Section 3 describes modelling WSD as a DCOP.", "labels": [], "entities": [{"text": "WSD", "start_pos": 30, "end_pos": 33, "type": "TASK", "confidence": 0.9146715402603149}]}, {"text": "Utility functions for various knowledge sources are described in section 4.", "labels": [], "entities": []}, {"text": "In section 5, we conduct a simple experiment by modelling allwords WSD problem as a DCOP and perform disambiguation on Senseval-2 ( and) data-set of all-words task.", "labels": [], "entities": []}, {"text": "Next follow the sections on related work, discussion, future work and conclusion.", "labels": [], "entities": []}, {"text": "\u2022 A = {a 1 , a 2 , . .", "labels": [], "entities": [{"text": "A", "start_pos": 2, "end_pos": 3, "type": "METRIC", "confidence": 0.9815126657485962}]}, {"text": "an } is a set of n agents,", "labels": [], "entities": []}], "datasetContent": [{"text": "We carried out a simple experiment to test the effectiveness of DCOP algorithm.", "labels": [], "entities": []}, {"text": "We conducted our experiment in an all words setting and used only WordNet) based relatedness measures as knowledge source so that results can be compared with earlier state-of-art knowledgebased WSD systems like which used similar knowledge sources as ours.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 66, "end_pos": 73, "type": "DATASET", "confidence": 0.9324339032173157}]}, {"text": "Our method performs disambiguation on sentence by sentence basis.", "labels": [], "entities": []}, {"text": "A utility function based on semantic relatedness is defined for every pair of words falling in a particular window size.", "labels": [], "entities": []}, {"text": "Restricting utility functions to a window size reduces the number of constraints.", "labels": [], "entities": []}, {"text": "An objective function is defined as sum of these restricted utility functions over the entire sentence and thus allowing information flow across all the words.", "labels": [], "entities": []}, {"text": "Hence, a DCOP algorithm which aims to maximize this objective function leads to a globally optimal solution.", "labels": [], "entities": []}, {"text": "In our experiments, we used the best similarity measure settings of which is a sum of normalized similarity measures jcn, lch and lesk.", "labels": [], "entities": []}, {"text": "We used used Distributed Pseudotree Optimization Procedure (DPOP) algorithm (), which solves DCOP using linear number of messages among agents.", "labels": [], "entities": [{"text": "Distributed Pseudotree Optimization Procedure (DPOP)", "start_pos": 13, "end_pos": 65, "type": "TASK", "confidence": 0.7346190512180328}]}, {"text": "The implementation provided with the open source toolkit FRODO) is used.", "labels": [], "entities": [{"text": "FRODO", "start_pos": 57, "end_pos": 62, "type": "DATASET", "confidence": 0.5141887068748474}]}], "tableCaptions": [{"text": " Table 1: Evaluation results on Senseval-2 and  Senseval-3 data-set of all words task.", "labels": [], "entities": []}]}