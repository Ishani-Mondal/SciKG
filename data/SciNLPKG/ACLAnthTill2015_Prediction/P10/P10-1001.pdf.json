{"title": [], "abstractContent": [{"text": "We present algorithms for higher-order dependency parsing that are \"third-order\" in the sense that they can evaluate sub-structures containing three dependencies, and \"efficient\" in the sense that they require only O(n 4) time.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 39, "end_pos": 57, "type": "TASK", "confidence": 0.7149865925312042}]}, {"text": "Importantly, our new parsers can utilize both sibling-style and grandchild-style interactions.", "labels": [], "entities": []}, {"text": "We evaluate our parsers on the Penn Tree-bank and Prague Dependency Treebank, achieving unlabeled attachment scores of 93.04% and 87.38%, respectively.", "labels": [], "entities": [{"text": "Penn Tree-bank", "start_pos": 31, "end_pos": 45, "type": "DATASET", "confidence": 0.9934554100036621}, {"text": "Prague Dependency Treebank", "start_pos": 50, "end_pos": 76, "type": "DATASET", "confidence": 0.977501372496287}, {"text": "attachment", "start_pos": 98, "end_pos": 108, "type": "METRIC", "confidence": 0.7627472877502441}]}], "introductionContent": [{"text": "Dependency grammar has proven to be a very useful syntactic formalism, due in no small part to the development of efficient parsing algorithms, which can be leveraged fora wide variety of learning methods, such as feature-rich discriminative models.", "labels": [], "entities": [{"text": "Dependency grammar", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.823637843132019}]}, {"text": "These parsing algorithms share an important characteristic: they factor dependency trees into sets of parts that have limited interactions.", "labels": [], "entities": [{"text": "parsing", "start_pos": 6, "end_pos": 13, "type": "TASK", "confidence": 0.9671803712844849}]}, {"text": "By exploiting the additional constraints arising from the factorization, maximizations or summations over the set of possible dependency trees can be performed efficiently and exactly.", "labels": [], "entities": []}, {"text": "A crucial limitation of factored parsing algorithms is that the associated parts are typically quite small, losing much of the contextual information within the dependency tree.", "labels": [], "entities": [{"text": "factored parsing", "start_pos": 24, "end_pos": 40, "type": "TASK", "confidence": 0.5132090747356415}]}, {"text": "For the purposes of improving parsing performance, it is desirable to increase the size and variety of the parts used by the factorization.", "labels": [], "entities": [{"text": "parsing", "start_pos": 30, "end_pos": 37, "type": "TASK", "confidence": 0.9866478443145752}]}, {"text": "At the same time, the need for more expressive factorizations For examples of how performance varies with the degree of the parser's factorization see, e.g., must be balanced against any resulting increase in the computational cost of the parsing algorithm.", "labels": [], "entities": []}, {"text": "Consequently, recent work in dependency parsing has been restricted to applications of secondorder parsers, the most powerful of which) requires O(n 4 ) time and O(n 3 ) space, while being limited to second-order parts.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.8413838148117065}]}, {"text": "In this paper, we present new third-order parsing algorithms that increase both the size and variety of the parts participating in the factorization, while simultaneously maintaining computational requirements of O(n 4 ) time and O(n 3 ) space.", "labels": [], "entities": []}, {"text": "We evaluate our parsers on the Penn WSJ Treebank ( and Prague Dependency Treebank (), achieving unlabeled attachment scores of 93.04% and 87.38%.", "labels": [], "entities": [{"text": "Penn WSJ Treebank", "start_pos": 31, "end_pos": 48, "type": "DATASET", "confidence": 0.9184728860855103}, {"text": "Prague Dependency Treebank", "start_pos": 55, "end_pos": 81, "type": "DATASET", "confidence": 0.9452914595603943}, {"text": "attachment", "start_pos": 106, "end_pos": 116, "type": "METRIC", "confidence": 0.6792632341384888}]}, {"text": "In summary, we make three main contributions: 1.", "labels": [], "entities": []}, {"text": "Efficient new third-order parsing algorithms.", "labels": [], "entities": []}, {"text": "2. Empirical evaluations of these parsers.", "labels": [], "entities": []}, {"text": "3. A free distribution of our implementation.", "labels": [], "entities": []}, {"text": "The remainder of this paper is divided as follows: Sections 2 and 3 give background, Sections 4 and 5 describe our new parsing algorithms, Section 6 discusses related work, Section 7 presents our experimental results, and Section 8 concludes.", "labels": [], "entities": [{"text": "parsing", "start_pos": 119, "end_pos": 126, "type": "TASK", "confidence": 0.9608809351921082}]}], "datasetContent": [{"text": "In order to evaluate the effectiveness of our parsers in practice, we apply them to the Penn WSJ Treebank () and the Prague Dependency.", "labels": [], "entities": [{"text": "Penn WSJ Treebank", "start_pos": 88, "end_pos": 105, "type": "DATASET", "confidence": 0.9339579542477926}, {"text": "Prague Dependency", "start_pos": 117, "end_pos": 134, "type": "DATASET", "confidence": 0.9933243691921234}]}, {"text": "We use standard training, validation, and test splits 7 to facilitate comparisons.", "labels": [], "entities": []}, {"text": "Accuracy is For English, we extracted dependencies using Joakim Nivre's Penn2Malt tool with standard head rules; for Czech, we \"projectivized\" the training data by finding best-match projective trees.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9944283962249756}, {"text": "Penn2Malt", "start_pos": 72, "end_pos": 81, "type": "DATASET", "confidence": 0.9293118119239807}]}, {"text": "For Czech, the PDT has a predefined split; for English, we split the Sections as: 2-21 training, measured with unlabeled attachment score (UAS): the percentage of words with the correct head.", "labels": [], "entities": [{"text": "unlabeled attachment score (UAS)", "start_pos": 111, "end_pos": 143, "type": "METRIC", "confidence": 0.8107180098692576}]}], "tableCaptions": [{"text": " Table 1: Effect of the marginal-probability beam  on English parsing. For each beam value, parsers  were trained on the English training set and evalu- ated on the English validation set; the same beam  value was applied to both training and validation  data. Pass = %dependencies surviving the beam in  training data, Orac = maximum achievable UAS  on validation data, Acc1/Acc2 = UAS of Models  1/2 on validation data, and Time1/Time2 = min- utes per perceptron training iteration for Models  1/2, averaged over all 10 iterations. For perspec- tive, the English training set has a total of 39,832  sentences and 950,028 words. A beam of 0.0001  was used in all experiments outside this table.", "labels": [], "entities": [{"text": "English parsing", "start_pos": 54, "end_pos": 69, "type": "TASK", "confidence": 0.5840886831283569}, {"text": "English training set", "start_pos": 121, "end_pos": 141, "type": "DATASET", "confidence": 0.7064802249272665}, {"text": "Pass", "start_pos": 261, "end_pos": 265, "type": "METRIC", "confidence": 0.9965105652809143}, {"text": "Orac", "start_pos": 320, "end_pos": 324, "type": "METRIC", "confidence": 0.9826363325119019}, {"text": "UAS", "start_pos": 346, "end_pos": 349, "type": "METRIC", "confidence": 0.7454757690429688}, {"text": "Acc1/Acc2", "start_pos": 371, "end_pos": 380, "type": "METRIC", "confidence": 0.7462881406148275}, {"text": "UAS", "start_pos": 383, "end_pos": 386, "type": "METRIC", "confidence": 0.9139074087142944}, {"text": "Time1", "start_pos": 426, "end_pos": 431, "type": "METRIC", "confidence": 0.8966992497444153}]}, {"text": " Table 2: UAS of Models 1 and 2 on test data, with  relevant results from related work. Note that Koo  et al. (2008) is listed with standard features and  semi-supervised features.  \u2020: see main text.", "labels": [], "entities": [{"text": "UAS", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.6438860893249512}]}, {"text": " Table 3: UAS for modified versions of our parsers  on validation data. The term no-3 rd indicates a  parser that was trained and tested with the third- order feature mappings f gsib and f tsib deactivated,  though lower-order features were retained; note  that \"Model 2, no-3 rd \" is not identical to the Car- reras (2007) parser as it defines grandchild parts  for the pair of grandchildren. The term no-G indi- cates a parser that was trained and tested with the  grandchild-based feature mappings f gch and f gsib  deactivated; note that \"Model 2, no-G\" emulates  the third-order sibling parser proposed by", "labels": [], "entities": [{"text": "UAS", "start_pos": 10, "end_pos": 13, "type": "DATASET", "confidence": 0.7696226239204407}, {"text": "Car- reras (2007) parser", "start_pos": 306, "end_pos": 330, "type": "DATASET", "confidence": 0.8153731737818036}]}]}