{"title": [{"text": "All Words Domain Adapted WSD: Finding a Middle Ground between Supervision and Unsupervision", "labels": [], "entities": []}], "abstractContent": [{"text": "In spite of decades of research on word sense disambiguation (WSD), all-words general purpose WSD has remained a distant goal.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 35, "end_pos": 66, "type": "TASK", "confidence": 0.8125222126642863}, {"text": "all-words general purpose WSD", "start_pos": 68, "end_pos": 97, "type": "TASK", "confidence": 0.6064665019512177}]}, {"text": "Many supervised WSD systems have been built, but the effort of creating the training corpus-annotated sense marked corpora-has always been a matter of concern.", "labels": [], "entities": [{"text": "WSD", "start_pos": 16, "end_pos": 19, "type": "TASK", "confidence": 0.9665575623512268}]}, {"text": "Therefore, attempts have been made to develop unsupervised and knowledge based techniques for WSD which do not need sense marked corpora.", "labels": [], "entities": [{"text": "WSD", "start_pos": 94, "end_pos": 97, "type": "TASK", "confidence": 0.9902357459068298}]}, {"text": "However such approaches have not proved effective, since they typically do not better Word-net first sense baseline accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 116, "end_pos": 124, "type": "METRIC", "confidence": 0.7976798415184021}]}, {"text": "Our research reported here proposes to stick to the supervised approach, but with far less demand on annotation.", "labels": [], "entities": []}, {"text": "We show that if we have ANY sense marked corpora, be it from mixed domain or a specific domain, a small amount of annotation in ANY other domain can deliver the goods almost as if exhaustive sense marking were available in that domain.", "labels": [], "entities": []}, {"text": "We have tested our approach across Tourism and Health domain corpora, using also the well known mixed domain SemCor corpus.", "labels": [], "entities": [{"text": "SemCor corpus", "start_pos": 109, "end_pos": 122, "type": "DATASET", "confidence": 0.7249024361371994}]}, {"text": "Accuracy figures close to self domain training lend credence to the viability of our approach.", "labels": [], "entities": []}, {"text": "Our contribution thus lies in finding a convenient middle ground between pure supervised and pure unsupervised WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 111, "end_pos": 114, "type": "TASK", "confidence": 0.7324614524841309}]}, {"text": "Finally , our approach is not restricted to any specific set of target words, a departure from a commonly observed practice in domain specific WSD.", "labels": [], "entities": []}], "introductionContent": [{"text": "Amongst annotation tasks, sense marking surely takes the cake, demanding as it does high level of language competence, topic comprehension and domain sensitivity.", "labels": [], "entities": [{"text": "sense marking", "start_pos": 26, "end_pos": 39, "type": "TASK", "confidence": 0.8937307894229889}]}, {"text": "This makes supervised approaches to WSD a difficult proposition ().", "labels": [], "entities": [{"text": "WSD", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9842425584793091}]}, {"text": "Unsupervised and knowledge based approaches have been tried with the hope of creating WSD systems with no need for sense marked corpora ().", "labels": [], "entities": [{"text": "WSD", "start_pos": 86, "end_pos": 89, "type": "TASK", "confidence": 0.9708774089813232}]}, {"text": "However, the accuracy figures of such systems are low.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 13, "end_pos": 21, "type": "METRIC", "confidence": 0.9996669292449951}]}, {"text": "Our work here is motivated by the desire to develop annotation-lean all-words domain adapted techniques for supervised WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 119, "end_pos": 122, "type": "TASK", "confidence": 0.9026573896408081}]}, {"text": "It is a common observation that domain specific WSD exhibits high level of accuracy even for the all-words scenario () -provided training and testing are on the same domain.", "labels": [], "entities": [{"text": "WSD", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.784931480884552}, {"text": "accuracy", "start_pos": 75, "end_pos": 83, "type": "METRIC", "confidence": 0.9987993240356445}]}, {"text": "Also domain adaptation -in which training happens in one domain and testing in another -often is able to attain good levels of performance, albeit on a specific set of target words.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 5, "end_pos": 22, "type": "TASK", "confidence": 0.7753020226955414}]}, {"text": "To the best of our knowledge there does not exist a system that solves the combined problem of all words domain adapted WSD.", "labels": [], "entities": []}, {"text": "We thus propose the following: a.", "labels": [], "entities": []}, {"text": "For any target domain, create a small amount of sense annotated corpus. b. Mix it with an existing sense annotated corpus -from a mixed domain or specific domain -to train the WSD engine.", "labels": [], "entities": []}, {"text": "This procedure tested on four adaptation scenarios, viz., (i) SemCor ( to Tourism, (ii) SemCor to Health, (iii) Tourism to Health and (iv) Health to Tourism has consistently yielded good performance (to be explained in sections 6 and 7).", "labels": [], "entities": []}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2 we discuss previous work in the area of domain adaptation for WSD.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 53, "end_pos": 70, "type": "TASK", "confidence": 0.7461266219615936}, {"text": "WSD", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.8222614526748657}]}, {"text": "In section 3 we discuss three state of art supervised, unsupervised and knowledge based algorithms for WSD.", "labels": [], "entities": [{"text": "WSD", "start_pos": 103, "end_pos": 106, "type": "TASK", "confidence": 0.9669516086578369}]}, {"text": "Section 4 discusses the injection strategy for domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 47, "end_pos": 64, "type": "TASK", "confidence": 0.7953652441501617}]}, {"text": "In section 5 we describe the dataset used for our experiments.", "labels": [], "entities": []}, {"text": "We then present the results in section 6 followed by discussions in section 7.", "labels": [], "entities": []}, {"text": "Section 8 examines whether there is any need for intelligent choice of injections.", "labels": [], "entities": []}, {"text": "Section 9 concludes the paper highlighting possible future directions.", "labels": [], "entities": []}], "datasetContent": [{"text": "Due to the lack of any publicly available all-words domain specific sense marked corpora we set upon the task of collecting data from two domains, viz., Tourism and Health.", "labels": [], "entities": []}, {"text": "The data for Tourism domain was downloaded from Indian Tourism websites whereas the data for Health domain was obtained from two doctors.", "labels": [], "entities": []}, {"text": "This data was manually sense annotated by two lexicographers adept in English.", "labels": [], "entities": []}, {"text": "Princeton Wordnet 2.1 3  Note that we do not use the monosemous words while calculating precision and recall of our algorithms.", "labels": [], "entities": [{"text": "Princeton Wordnet 2.1", "start_pos": 0, "end_pos": 21, "type": "DATASET", "confidence": 0.9220677415529887}, {"text": "precision", "start_pos": 88, "end_pos": 97, "type": "METRIC", "confidence": 0.9990788698196411}, {"text": "recall", "start_pos": 102, "end_pos": 108, "type": "METRIC", "confidence": 0.9982136487960815}]}, {"text": "shows the average number of instances per polysemous word in the 3 corpora.", "labels": [], "entities": []}, {"text": "We note that the number of instances per word in the Tourism domain is comparable to that in the SemCor corpus whereas the number of instances per word in the Health corpus is smaller due to the overall smaller size of the Health corpus.", "labels": [], "entities": [{"text": "SemCor corpus", "start_pos": 97, "end_pos": 110, "type": "DATASET", "confidence": 0.8652984499931335}, {"text": "Health corpus", "start_pos": 159, "end_pos": 172, "type": "DATASET", "confidence": 0.881078839302063}, {"text": "Health corpus", "start_pos": 223, "end_pos": 236, "type": "DATASET", "confidence": 0.9072040319442749}]}, {"text": "summarize the average degree of Wordnet polysemy and corpus polysemy of the polysemous words in the corpus.", "labels": [], "entities": []}, {"text": "Wordnet polysemy is the number of senses of a word as listed in the Wordnet, whereas corpus polysemy is the number of senses of a word actually appearing in the corpus.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 68, "end_pos": 75, "type": "DATASET", "confidence": 0.9821747541427612}]}, {"text": "As expected, the average degree of corpus polysemy is much less than the average degree of Wordnet polysemy.", "labels": [], "entities": [{"text": "Wordnet", "start_pos": 91, "end_pos": 98, "type": "DATASET", "confidence": 0.9147324562072754}]}, {"text": "Further, the average degree of corpus polysemy) in the two domains is less than that in the mixed-domain SemCor corpus, which is expected due to the domain specific nature of the corpora.", "labels": [], "entities": [{"text": "SemCor corpus", "start_pos": 105, "end_pos": 118, "type": "DATASET", "confidence": 0.829337865114212}]}, {"text": "Finally,   The data is currently being enhanced by manually sense marking more words from each domain and will be soon freely available 4 for research purposes.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Polysemous and Monosemous words per  category in each domain", "labels": [], "entities": []}, {"text": " Table 2: Average number of instances per polyse- mous word per category in the 3 domains", "labels": [], "entities": []}, {"text": " Table 3: Average degree of Wordnet polysemy of  polysemous words per category in the 3 domains", "labels": [], "entities": []}, {"text": " Table 5: Number of unique polysemous words per category  in each domain.", "labels": [], "entities": []}, {"text": " Table 6. We also report  the Wordnet first sense baseline (WFS).", "labels": [], "entities": [{"text": "Wordnet first sense baseline (WFS)", "start_pos": 30, "end_pos": 64, "type": "METRIC", "confidence": 0.6506856424467904}]}, {"text": " Table 6: Comparing the performance of Person- alized PageRank (PPR) with Wordnet First Sense  Baseline (WFS)", "labels": [], "entities": [{"text": "Wordnet First Sense  Baseline (WFS)", "start_pos": 74, "end_pos": 109, "type": "DATASET", "confidence": 0.7373274905341012}]}, {"text": " Table 8: Percentage of Words belonging to each  category in the three settings.", "labels": [], "entities": []}]}