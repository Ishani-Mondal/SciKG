{"title": [{"text": "The impact of interpretation problems on tutorial dialogue", "labels": [], "entities": []}], "abstractContent": [{"text": "Supporting natural language input may improve learning in intelligent tutoring systems.", "labels": [], "entities": []}, {"text": "However, interpretation errors are unavoidable and require an effective recovery policy.", "labels": [], "entities": [{"text": "interpretation", "start_pos": 9, "end_pos": 23, "type": "TASK", "confidence": 0.9648504853248596}]}, {"text": "We describe an evaluation of an error recovery policy in the BEETLE II tutorial dialogue system and discuss how different types of interpretation problems affect learning gain and user satisfaction.", "labels": [], "entities": [{"text": "error recovery", "start_pos": 32, "end_pos": 46, "type": "TASK", "confidence": 0.7037200629711151}, {"text": "BEETLE II tutorial dialogue system", "start_pos": 61, "end_pos": 95, "type": "DATASET", "confidence": 0.8692571520805359}]}, {"text": "In particular, the problems arising from student use of non-standard terminology appear to have negative consequences.", "labels": [], "entities": []}, {"text": "We argue that existing strategies for dealing with terminology problems are insufficient and that improving such strategies is important in future ITS research.", "labels": [], "entities": []}], "introductionContent": [{"text": "There is a mounting body of evidence that student self-explanation and contentful talk in humanhuman tutorial dialogue are correlated with increased learning gain ().", "labels": [], "entities": []}, {"text": "Thus, computer tutors that understand student explanations have the potential to improve student learning (.", "labels": [], "entities": []}, {"text": "However, understanding and correctly assessing the student's contributions is a difficult problem due to the wide range of variation observed in student input, and especially due to students' sometimes vague and incorrect use of domain terminology.", "labels": [], "entities": []}, {"text": "Many tutorial dialogue systems limit the range of student input by asking short-answer questions.", "labels": [], "entities": []}, {"text": "This provides a measure of robustness, and previous evaluations of ASR in spoken tutorial dialogue systems indicate that neither word error rate nor concept error rate in such systems affect learning gain).", "labels": [], "entities": [{"text": "ASR", "start_pos": 67, "end_pos": 70, "type": "TASK", "confidence": 0.9553737640380859}, {"text": "word error rate", "start_pos": 129, "end_pos": 144, "type": "METRIC", "confidence": 0.730904092391332}]}, {"text": "However, limiting the range of possible input limits the contentful talk that the students are expected to produce, and therefore may limit the overall effectiveness of the system.", "labels": [], "entities": []}, {"text": "Most of the existing tutoring systems that accept unrestricted language input use classifiers based on statistical text similarity measures to match student answers to open-ended questions with pre-authored anticipated answers (.", "labels": [], "entities": []}, {"text": "While such systems are robust to unexpected terminology, they provide only a very coarse-grained assessment of student answers.", "labels": [], "entities": []}, {"text": "Recent research aims to develop methods that produce detailed analyses of student input, including correct, incorrect and missing parts, because the more detailed assessments can help tailor tutoring to the needs of individual students.", "labels": [], "entities": []}, {"text": "While the detailed assessments of answers to open-ended questions are intended to improve potential learning, they also increase the probability of misunderstandings, which negatively impact tutoring and therefore negatively impact student learning ().", "labels": [], "entities": []}, {"text": "Thus, appropriate error recovery strategies are crucially important for tutorial dialogue applications.", "labels": [], "entities": [{"text": "error recovery", "start_pos": 18, "end_pos": 32, "type": "TASK", "confidence": 0.6764828413724899}, {"text": "tutorial dialogue", "start_pos": 72, "end_pos": 89, "type": "TASK", "confidence": 0.845935195684433}]}, {"text": "We describe an evaluation of an implemented tutorial dialogue system which aims to accept unrestricted student input and limit misunderstandings by rejecting low confidence interpretations and employing a range of error recovery strategies depending on the cause of interpretation failure.", "labels": [], "entities": []}, {"text": "By comparing two different system policies, we demonstrate that with less restricted language input the rate of non-understanding errors impacts both learning gain and user satisfaction, and that problems arising from incorrect use of terminology have a particularly negative impact.", "labels": [], "entities": []}, {"text": "A more detailed analysis of the results indicates that, even though we based our policy on an approach ef-fective in task-oriented dialogue), many of our strategies were not successful in improving learning gain.", "labels": [], "entities": []}, {"text": "At the same time, students appear to be aware that the system does not fully understand them even if it accepts their input without indicating that it is having interpretation problems, and this is reflected in decreased user satisfaction.", "labels": [], "entities": []}, {"text": "We argue that this indicates that we need better strategies for dealing with terminology problems, and that accepting non-standard terminology without explicitly addressing the difference in acceptable phrasing may not be sufficient for effective tutoring.", "labels": [], "entities": []}, {"text": "In Section 2 we describe our tutoring system, and the two tutoring policies implemented for the experiment.", "labels": [], "entities": []}, {"text": "In Section 3 we present experimental results and an analysis of correlations between different types of interpretation problems, learning gain and user satisfaction.", "labels": [], "entities": []}, {"text": "Finally, in Section 4 we discuss the implications of our results for error recovery policies in tutorial dialogue systems.", "labels": [], "entities": [{"text": "error recovery", "start_pos": 69, "end_pos": 83, "type": "TASK", "confidence": 0.6735753118991852}]}], "datasetContent": [{"text": "We collected data from 76 subjects interacting with the system.", "labels": [], "entities": []}, {"text": "The subjects were randomly assigned to either the baseline (BASE) or the full (FULL) policy condition.", "labels": [], "entities": [{"text": "BASE", "start_pos": 60, "end_pos": 64, "type": "METRIC", "confidence": 0.7930964231491089}, {"text": "FULL", "start_pos": 79, "end_pos": 83, "type": "METRIC", "confidence": 0.9452906250953674}]}, {"text": "Each subject took a pretest, then worked through a lesson with the system, and then took a post-test and filled in a user satisfaction survey.", "labels": [], "entities": []}, {"text": "Each session lasted approximately 4 hours, with 232 student language turns in FULL (SD = 25.6) and 156 in BASE (SD = 2.02).", "labels": [], "entities": [{"text": "FULL", "start_pos": 78, "end_pos": 82, "type": "METRIC", "confidence": 0.993516206741333}, {"text": "BASE (SD = 2.02)", "start_pos": 106, "end_pos": 122, "type": "METRIC", "confidence": 0.9071562588214874}]}, {"text": "Additional time was taken by reading and interacting with the simulation environment.", "labels": [], "entities": []}, {"text": "The students had little prior knowledge of the domain.", "labels": [], "entities": []}, {"text": "The survey consisted of 63 questions on the 5-point Likert scale covering the lesson content, the graphical user interface, and tutor's understanding and feedback.", "labels": [], "entities": []}, {"text": "For purposes of this study, we are using an averaged tutor score.", "labels": [], "entities": []}, {"text": "The average learning gain was 0.57 (SD = 0.23) in FULL, and 0.63 (SD = 0.26) in BASE.", "labels": [], "entities": [{"text": "learning gain", "start_pos": 12, "end_pos": 25, "type": "METRIC", "confidence": 0.9298164546489716}, {"text": "FULL", "start_pos": 50, "end_pos": 54, "type": "DATASET", "confidence": 0.5865796208381653}, {"text": "BASE", "start_pos": 80, "end_pos": 84, "type": "DATASET", "confidence": 0.794756293296814}]}, {"text": "There was no significant difference in learning gain between conditions.", "labels": [], "entities": []}, {"text": "Students liked BASE better: the average tutor evaluation score for FULL was 2.56 out of 5 (SD = 0.65), compared to 3.32 (SD = 0.65) in BASE.", "labels": [], "entities": [{"text": "BASE", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.3552345931529999}, {"text": "FULL", "start_pos": 67, "end_pos": 71, "type": "DATASET", "confidence": 0.591029703617096}, {"text": "BASE", "start_pos": 135, "end_pos": 139, "type": "DATASET", "confidence": 0.6805671453475952}]}, {"text": "These results are significantly different (t-test, p < 0.05).", "labels": [], "entities": []}, {"text": "In informal comments after the session many students said that they were frustrated when the system said that it did not understand them.", "labels": [], "entities": []}, {"text": "However, some students in BASE also mentioned that they sometimes were not sure if the system's answer was correcting a problem with their answer, or simply phrasing it in a different way.", "labels": [], "entities": [{"text": "BASE", "start_pos": 26, "end_pos": 30, "type": "DATASET", "confidence": 0.7474439144134521}]}, {"text": "We used mean frequency of non-interpretable utterances (out of all student utterances in each session) to evaluate the effectiveness of the two different policies.", "labels": [], "entities": []}, {"text": "On average, 14% of utterances in both conditions resulted in non-understandings.", "labels": [], "entities": []}, {"text": "The frequency of nonunderstandings was negatively correlated with learning gain in FULL: r = \u22120.47, p < 0.005, but not significantly correlated with learning gain in BASE: r = \u22120.09, p = 0.59.", "labels": [], "entities": [{"text": "FULL", "start_pos": 83, "end_pos": 87, "type": "DATASET", "confidence": 0.6075172424316406}, {"text": "BASE", "start_pos": 166, "end_pos": 170, "type": "DATASET", "confidence": 0.7104223966598511}]}, {"text": "However, in both conditions the frequency of non-understandings was negatively correlated with user satisfaction: FULL r = \u22120.36, p = 0.03, BASE r = \u22120.4, p = 0.01.", "labels": [], "entities": [{"text": "FULL r", "start_pos": 114, "end_pos": 120, "type": "METRIC", "confidence": 0.9878653287887573}, {"text": "BASE r", "start_pos": 140, "end_pos": 146, "type": "METRIC", "confidence": 0.9871141612529755}]}, {"text": "Thus, even though in BASE the system did not indicate non-understanding, students were negatively affected.", "labels": [], "entities": [{"text": "BASE", "start_pos": 21, "end_pos": 25, "type": "DATASET", "confidence": 0.5149937272071838}]}, {"text": "That is, they were not satisfied with the policy that did not directly address the interpretation problems.", "labels": [], "entities": [{"text": "interpretation", "start_pos": 83, "end_pos": 97, "type": "TASK", "confidence": 0.9635174870491028}]}, {"text": "We discuss possible reasons for this below.", "labels": [], "entities": []}, {"text": "We investigated the effect of different types of interpretation errors using two criteria.", "labels": [], "entities": []}, {"text": "First, we checked whether the mean frequency of errors was reduced between BASE and FULL for each individual strategy.", "labels": [], "entities": [{"text": "mean frequency of errors", "start_pos": 30, "end_pos": 54, "type": "METRIC", "confidence": 0.8859391659498215}, {"text": "BASE", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.9792099595069885}, {"text": "FULL", "start_pos": 84, "end_pos": 88, "type": "METRIC", "confidence": 0.9824712872505188}]}, {"text": "The reduced frequency means that the recovery strategy for this particular error type is effective in reducing the error frequency.", "labels": [], "entities": [{"text": "error frequency", "start_pos": 115, "end_pos": 130, "type": "METRIC", "confidence": 0.9294419884681702}]}, {"text": "Second, we looked for the cases where the frequency of a given error type is negatively correlated with either learning gain or user satisfaction.", "labels": [], "entities": []}, {"text": "This is provides evidence that such errors are negatively impacting the learning process, and therefore improving recovery strategies for those error types is likely to improve overall system effectiveness, The results, shown in, indicate that the majority of interpretation problems are not significantly correlated with learning gain.", "labels": [], "entities": []}, {"text": "However, several types of problems appear to be particularly significant, and are all related to improper use of domain terminology.", "labels": [], "entities": []}, {"text": "These were irrelevant answer, no appr terms, selectional restriction failure and program error.", "labels": [], "entities": []}, {"text": "An irrelevant answer error occurs when the student makes a statement that uses domain termi-: Correlations between frequency of different error types and student learning gain and satisfaction.", "labels": [], "entities": []}, {"text": "** -correlation is significant with p < 0.05, * -with p <= 0.1.", "labels": [], "entities": [{"text": "correlation", "start_pos": 4, "end_pos": 15, "type": "METRIC", "confidence": 0.9978843331336975}]}, {"text": "nology but does not appear to answer the system's question directly.", "labels": [], "entities": []}, {"text": "For example, the expected answer to \"In circuit 1, which components are in a closed path?\" is \"the bulb\".", "labels": [], "entities": []}, {"text": "Some students misread the question and say \"Circuit 1 is closed.\"", "labels": [], "entities": []}, {"text": "If that happens, in FULL the system says \"Sorry, this isn't the form of answer that I expected.", "labels": [], "entities": [{"text": "FULL", "start_pos": 20, "end_pos": 24, "type": "METRIC", "confidence": 0.5076266527175903}]}, {"text": "I am looking fora component\", pointing out to the student the kind of information it is looking for.", "labels": [], "entities": []}, {"text": "The BASE system for this error, and for all other errors discussed below, gives away the correct answer without indicating that there was a problem with interpreting the student's utterance, e.g., \"OK, the correct answer is the bulb.\"", "labels": [], "entities": [{"text": "BASE", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.9968749284744263}]}, {"text": "The no appr terms error happens when the student is using terminology inappropriate for the lesson in general.", "labels": [], "entities": [{"text": "no appr terms error", "start_pos": 4, "end_pos": 23, "type": "METRIC", "confidence": 0.6945090666413307}]}, {"text": "Students are expected to learn to explain everything in terms of connections and terminal states.", "labels": [], "entities": []}, {"text": "For example, the expected answer to \"What is voltage?\" is \"the difference in states between two terminals\".", "labels": [], "entities": []}, {"text": "If instead the student says \"Voltage is electricity\", FULL responds with \"I am sorry, I am having trouble understanding.", "labels": [], "entities": [{"text": "FULL", "start_pos": 54, "end_pos": 58, "type": "METRIC", "confidence": 0.9627606868743896}]}, {"text": "I see no domain concepts in your answer.", "labels": [], "entities": []}, {"text": "Here's a hint: your answer should mention a terminal.\"", "labels": [], "entities": []}, {"text": "The motivation behind this strategy is that in general, it is very difficult to reason about vaguely used domain terminology.", "labels": [], "entities": []}, {"text": "We had hoped that by telling the student that the content of their utterance is outside the domain as understood by the system, and hinting at the correct terms to use, the system would guide students towards a better answer.", "labels": [], "entities": []}, {"text": "Selectional restr failure errors are typically due to incorrect terminology, when the students phrased answers in away that contradicted the system's domain knowledge.", "labels": [], "entities": []}, {"text": "For example, the system can reason about damaged bulbs and batteries, and open and closed paths.", "labels": [], "entities": []}, {"text": "So if the student says \"The path is damaged\", the FULL system would respond with \"I am sorry, I am having trouble understanding.", "labels": [], "entities": [{"text": "FULL", "start_pos": 50, "end_pos": 54, "type": "METRIC", "confidence": 0.8503246903419495}]}, {"text": "Only bulbs and batteries can be damaged.\"", "labels": [], "entities": []}, {"text": "Program error were caused by faults in the underlying network software, but usually occurred when the student was using extremely long and complicated utterances.", "labels": [], "entities": []}, {"text": "Out of the four important error types described above, only the strategy for irrelevant answer was effective: the frequency of irrelevant answer errors is significantly higher in BASE (t-test, p < 0.05), and it is negatively correlated with learning gain in BASE.", "labels": [], "entities": [{"text": "BASE", "start_pos": 179, "end_pos": 183, "type": "METRIC", "confidence": 0.8974727988243103}, {"text": "BASE", "start_pos": 258, "end_pos": 262, "type": "DATASET", "confidence": 0.6789060235023499}]}, {"text": "The frequencies of other error types did not significantly differ between conditions.", "labels": [], "entities": []}, {"text": "However, one other finding is particularly interesting: the frequency of no appr terms errors is negatively correlated with user satisfaction in BASE.", "labels": [], "entities": [{"text": "frequency of no appr terms errors", "start_pos": 60, "end_pos": 93, "type": "METRIC", "confidence": 0.7120150129000345}, {"text": "BASE", "start_pos": 145, "end_pos": 149, "type": "DATASET", "confidence": 0.6106533408164978}]}, {"text": "This indicates that simply accepting the student's answer when they are using incorrect terminology and exposing them to the correct answer is not the best strategy, possibly because the students are noticing the unexplained lack of alignment between their utterance and the system's answer.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Correlations between frequency of different error types and student learning gain and satisfac- tion. ** -correlation is significant with p < 0.05, * -with p <= 0.1.", "labels": [], "entities": [{"text": "satisfac- tion", "start_pos": 96, "end_pos": 110, "type": "METRIC", "confidence": 0.9350487192471822}, {"text": "correlation", "start_pos": 116, "end_pos": 127, "type": "METRIC", "confidence": 0.7951226234436035}]}]}