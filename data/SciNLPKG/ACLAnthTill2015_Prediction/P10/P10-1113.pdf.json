{"title": [{"text": "Joint Syntactic and Semantic Parsing of Chinese", "labels": [], "entities": [{"text": "Syntactic and Semantic Parsing of Chinese", "start_pos": 6, "end_pos": 47, "type": "TASK", "confidence": 0.6994511435429255}]}], "abstractContent": [{"text": "This paper explores joint syntactic and semantic parsing of Chinese to further improve the performance of both syntactic and semantic parsing, in particular the performance of semantic parsing (in this paper, semantic role labeling).", "labels": [], "entities": [{"text": "semantic parsing of Chinese", "start_pos": 40, "end_pos": 67, "type": "TASK", "confidence": 0.8330409079790115}, {"text": "syntactic and semantic parsing", "start_pos": 111, "end_pos": 141, "type": "TASK", "confidence": 0.7249514758586884}, {"text": "semantic parsing", "start_pos": 176, "end_pos": 192, "type": "TASK", "confidence": 0.720443919301033}, {"text": "semantic role labeling", "start_pos": 209, "end_pos": 231, "type": "TASK", "confidence": 0.6361330350240072}]}, {"text": "This is done from two levels.", "labels": [], "entities": []}, {"text": "Firstly, an integrated parsing approach is proposed to integrate semantic parsing into the syntactic parsing process.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 65, "end_pos": 81, "type": "TASK", "confidence": 0.714380756020546}, {"text": "syntactic parsing", "start_pos": 91, "end_pos": 108, "type": "TASK", "confidence": 0.7187981009483337}]}, {"text": "Secondly, semantic information generated by semantic parsing is incorporated into the syntactic parsing model to better capture semantic information in syntactic parsing.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 44, "end_pos": 60, "type": "TASK", "confidence": 0.7278575897216797}, {"text": "syntactic parsing", "start_pos": 86, "end_pos": 103, "type": "TASK", "confidence": 0.7145601063966751}, {"text": "syntactic parsing", "start_pos": 152, "end_pos": 169, "type": "TASK", "confidence": 0.748248964548111}]}, {"text": "Evaluation on Chinese TreeBank, Chinese PropBank, and Chinese NomBank shows that our integrated parsing approach outperforms the pipeline parsing approach on n-best parse trees, a natural extension of the widely used pipeline parsing approach on the top-best parse tree.", "labels": [], "entities": [{"text": "Chinese TreeBank", "start_pos": 14, "end_pos": 30, "type": "DATASET", "confidence": 0.944185346364975}, {"text": "Chinese PropBank", "start_pos": 32, "end_pos": 48, "type": "DATASET", "confidence": 0.8841158151626587}, {"text": "Chinese NomBank", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.9048755168914795}, {"text": "pipeline parsing", "start_pos": 129, "end_pos": 145, "type": "TASK", "confidence": 0.6869006752967834}]}, {"text": "Moreover, it shows that incorporating semantic role-related information into the syntactic parsing model significantly improves the performance of both syntactic parsing and semantic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 81, "end_pos": 98, "type": "TASK", "confidence": 0.7457385361194611}, {"text": "syntactic parsing", "start_pos": 152, "end_pos": 169, "type": "TASK", "confidence": 0.7614365220069885}, {"text": "semantic parsing", "start_pos": 174, "end_pos": 190, "type": "TASK", "confidence": 0.7140681445598602}]}, {"text": "To our best knowledge, this is the first research on exploring syntactic parsing and semantic role labeling for both verbal and nominal predicates in an integrated way.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 63, "end_pos": 80, "type": "TASK", "confidence": 0.7404078841209412}, {"text": "semantic role labeling", "start_pos": 85, "end_pos": 107, "type": "TASK", "confidence": 0.6881281137466431}]}], "introductionContent": [{"text": "Semantic parsing maps a natural language sentence into a formal representation of its meaning.", "labels": [], "entities": [{"text": "Semantic parsing", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.812703549861908}]}, {"text": "Due to the difficulty in deep semantic parsing, most previous work focuses on shallow semantic parsing, which assigns a simple structure (such as WHO did WHAT to WHOM, WHEN, WHERE, WHY, HOW) to each predicate in a sentence.", "labels": [], "entities": [{"text": "deep semantic parsing", "start_pos": 25, "end_pos": 46, "type": "TASK", "confidence": 0.7083117763201395}, {"text": "shallow semantic parsing", "start_pos": 78, "end_pos": 102, "type": "TASK", "confidence": 0.6787321964899699}, {"text": "WHOM", "start_pos": 162, "end_pos": 166, "type": "METRIC", "confidence": 0.7134897112846375}]}, {"text": "In particular, the well-defined semantic role labeling (SRL) task has been drawing increasing attention in recent years due to its importance in natural language processing (NLP) applications, such as question answering), information extraction (, and co-reference resolution (.", "labels": [], "entities": [{"text": "semantic role labeling (SRL) task", "start_pos": 32, "end_pos": 65, "type": "TASK", "confidence": 0.8426903060504368}, {"text": "question answering", "start_pos": 201, "end_pos": 219, "type": "TASK", "confidence": 0.9024275243282318}, {"text": "information extraction", "start_pos": 222, "end_pos": 244, "type": "TASK", "confidence": 0.9063572287559509}, {"text": "co-reference resolution", "start_pos": 252, "end_pos": 275, "type": "TASK", "confidence": 0.729411169886589}]}, {"text": "Given a sentence and a predicate (either a verb or a noun) in the sentence, SRL recognizes and maps all the constituents in the sentence into their corresponding semantic arguments (roles) of the predicate.", "labels": [], "entities": [{"text": "SRL", "start_pos": 76, "end_pos": 79, "type": "TASK", "confidence": 0.9718433618545532}]}, {"text": "In both English and Chinese PropBank (, and English and Chinese NomBank (), these semantic arguments include core arguments (e.g., Arg0 for agent and Arg1 for recipient) and adjunct arguments (e.g., ArgM-LOC for locative argument and ArgM-TMP for temporal argument).", "labels": [], "entities": [{"text": "Arg0", "start_pos": 131, "end_pos": 135, "type": "METRIC", "confidence": 0.9589428901672363}, {"text": "ArgM-LOC", "start_pos": 199, "end_pos": 207, "type": "METRIC", "confidence": 0.9355303645133972}, {"text": "ArgM-TMP", "start_pos": 234, "end_pos": 242, "type": "METRIC", "confidence": 0.9503293037414551}]}, {"text": "According to predicate type, SRL can be divided into SRL for verbal predicates (verbal SRL, in short) and SRL for nominal predicates (nominal SRL, in short).", "labels": [], "entities": [{"text": "SRL", "start_pos": 29, "end_pos": 32, "type": "TASK", "confidence": 0.9357688426971436}, {"text": "SRL", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.8607344031333923}, {"text": "SRL", "start_pos": 106, "end_pos": 109, "type": "METRIC", "confidence": 0.6679555177688599}]}, {"text": "With the availability of large annotated corpora such as FrameNet (), PropBank, and NomBank in English, data-driven techniques, including both feature-based and kernel-based methods, have been extensively studied for SRL (;.", "labels": [], "entities": [{"text": "PropBank", "start_pos": 70, "end_pos": 78, "type": "DATASET", "confidence": 0.9171853065490723}, {"text": "SRL", "start_pos": 217, "end_pos": 220, "type": "TASK", "confidence": 0.9930522441864014}]}, {"text": "Nevertheless, for both verbal and nominal SRL, state-of-the-art systems depend heavily on the top-best parse tree and there exists a large performance gap between SRL based on the gold parse tree and the top-best parse tree.", "labels": [], "entities": [{"text": "SRL", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.8664831519126892}, {"text": "SRL", "start_pos": 163, "end_pos": 166, "type": "TASK", "confidence": 0.9550166130065918}]}, {"text": "For example, suffered a performance drop of 7.3 in F1-measure on English PropBank when using the top-best parse tree returned from Charniak's parser.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 51, "end_pos": 61, "type": "METRIC", "confidence": 0.9978975057601929}, {"text": "English PropBank", "start_pos": 65, "end_pos": 81, "type": "DATASET", "confidence": 0.8808244466781616}]}, {"text": "reported a performance drop of 4.21 in F1-measure on English NomBank.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 39, "end_pos": 49, "type": "METRIC", "confidence": 0.9986904263496399}, {"text": "English NomBank", "start_pos": 53, "end_pos": 68, "type": "DATASET", "confidence": 0.9016513526439667}]}, {"text": "Compared with English SRL, Chinese SRL suffers more seriously from syntactic parsing.", "labels": [], "entities": [{"text": "SRL", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.7904415726661682}, {"text": "SRL", "start_pos": 35, "end_pos": 38, "type": "TASK", "confidence": 0.6013237237930298}, {"text": "syntactic parsing", "start_pos": 67, "end_pos": 84, "type": "TASK", "confidence": 0.7134646475315094}]}, {"text": "Xue (2008) evaluated on Chinese PropBank and showed that the performance of Chinese verbal SRL drops by about 25 in F1-measure when replacing gold parse trees with automatic ones.", "labels": [], "entities": [{"text": "Chinese PropBank", "start_pos": 24, "end_pos": 40, "type": "DATASET", "confidence": 0.8651808202266693}, {"text": "F1-measure", "start_pos": 116, "end_pos": 126, "type": "METRIC", "confidence": 0.9988831877708435}]}, {"text": "Likewise, and reported a performance drop of about 12 in F1-measure in Chinese NomBank SRL.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 57, "end_pos": 67, "type": "METRIC", "confidence": 0.9989890456199646}, {"text": "Chinese NomBank SRL", "start_pos": 71, "end_pos": 90, "type": "DATASET", "confidence": 0.7997288902600607}]}, {"text": "While it maybe difficult to further improve syntactic parsing, a promising alternative is to perform both syntactic and semantic parsing in an integrated way.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 44, "end_pos": 61, "type": "TASK", "confidence": 0.8022906482219696}, {"text": "syntactic and semantic parsing", "start_pos": 106, "end_pos": 136, "type": "TASK", "confidence": 0.6636277362704277}]}, {"text": "Given the close interaction between the two tasks, joint learning not only allows uncertainty about syntactic parsing to be carried forward to semantic parsing but also allows useful information from semantic parsing to be carried backward to syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 100, "end_pos": 117, "type": "TASK", "confidence": 0.7037937641143799}, {"text": "semantic parsing", "start_pos": 143, "end_pos": 159, "type": "TASK", "confidence": 0.7209720462560654}, {"text": "semantic parsing", "start_pos": 200, "end_pos": 216, "type": "TASK", "confidence": 0.7475768327713013}, {"text": "syntactic parsing", "start_pos": 243, "end_pos": 260, "type": "TASK", "confidence": 0.7706562876701355}]}, {"text": "This paper explores joint learning of syntactic and semantic parsing for Chinese texts from two levels.", "labels": [], "entities": [{"text": "syntactic and semantic parsing", "start_pos": 38, "end_pos": 68, "type": "TASK", "confidence": 0.6490898802876472}]}, {"text": "Firstly, an integrated parsing approach is proposed to benefit from the close interaction between syntactic and semantic parsing.", "labels": [], "entities": [{"text": "syntactic and semantic parsing", "start_pos": 98, "end_pos": 128, "type": "TASK", "confidence": 0.6942744478583336}]}, {"text": "This is done by integrating semantic parsing into the syntactic parsing process.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 28, "end_pos": 44, "type": "TASK", "confidence": 0.7352679371833801}, {"text": "syntactic parsing", "start_pos": 54, "end_pos": 71, "type": "TASK", "confidence": 0.7473336458206177}]}, {"text": "Secondly, various semantic role-related features are directly incorporated into the syntactic parsing model to better capture semantic role-related information in syntactic parsing.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 84, "end_pos": 101, "type": "TASK", "confidence": 0.7631642520427704}, {"text": "syntactic parsing", "start_pos": 163, "end_pos": 180, "type": "TASK", "confidence": 0.7700850963592529}]}, {"text": "Evaluation on Chinese TreeBank, Chinese PropBank, and Chinese NomBank shows that our method significantly improves the performance of both syntactic and semantic parsing.", "labels": [], "entities": [{"text": "Chinese TreeBank", "start_pos": 14, "end_pos": 30, "type": "DATASET", "confidence": 0.9282957017421722}, {"text": "Chinese PropBank", "start_pos": 32, "end_pos": 48, "type": "DATASET", "confidence": 0.8576888144016266}, {"text": "Chinese NomBank", "start_pos": 54, "end_pos": 69, "type": "DATASET", "confidence": 0.8569725155830383}, {"text": "semantic parsing", "start_pos": 153, "end_pos": 169, "type": "TASK", "confidence": 0.7110627740621567}]}, {"text": "This is promising and encouraging.", "labels": [], "entities": []}, {"text": "To our best knowledge, this is the first research on exploring syntactic parsing and SRL for verbal and nominal predicates in an integrated way.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 63, "end_pos": 80, "type": "TASK", "confidence": 0.7344272136688232}, {"text": "SRL", "start_pos": 85, "end_pos": 88, "type": "TASK", "confidence": 0.9680343270301819}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 reviews related work.", "labels": [], "entities": []}, {"text": "Section 3 presents our baseline systems for syntactic and semantic parsing.", "labels": [], "entities": [{"text": "syntactic and semantic parsing", "start_pos": 44, "end_pos": 74, "type": "TASK", "confidence": 0.6322842910885811}]}, {"text": "Section 4 presents our proposed method of joint syntactic and semantic parsing for Chinese texts.", "labels": [], "entities": [{"text": "joint syntactic and semantic parsing", "start_pos": 42, "end_pos": 78, "type": "TASK", "confidence": 0.6459594607353211}]}, {"text": "Section 5 presents the experimental results.", "labels": [], "entities": []}, {"text": "Finally, Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have evaluated our integrated parsing approach on Chinese TreeBank 5.1 and corresponding Chinese PropBank and NomBank.", "labels": [], "entities": [{"text": "Chinese TreeBank 5.1", "start_pos": 53, "end_pos": 73, "type": "DATASET", "confidence": 0.9831923047701517}, {"text": "Chinese PropBank", "start_pos": 92, "end_pos": 108, "type": "DATASET", "confidence": 0.8843090236186981}, {"text": "NomBank", "start_pos": 113, "end_pos": 120, "type": "DATASET", "confidence": 0.8579950928688049}]}, {"text": "This version of Chinese PropBank and Chinese NomBank consists of standoff annotations on the file (chtb 001 to 1151.fid) of Chinese Penn TreeBank 5.1.", "labels": [], "entities": [{"text": "Chinese PropBank", "start_pos": 16, "end_pos": 32, "type": "DATASET", "confidence": 0.8897433578968048}, {"text": "Chinese NomBank", "start_pos": 37, "end_pos": 52, "type": "DATASET", "confidence": 0.8257916867733002}, {"text": "Chinese Penn TreeBank 5.1", "start_pos": 124, "end_pos": 149, "type": "DATASET", "confidence": 0.9073838293552399}]}, {"text": "Following the experimental settings in Xue (2008) and, 648 files (chtb 081 to 899.fid) are selected as the training data, 72 files (chtb 001 to 040.fid and chtb 900 to 931.fid) are held out as the test data, and 40 files (chtb 041 to 080.fid) are selected as the development data.", "labels": [], "entities": []}, {"text": "In particular, the training, test, and development data contain 31,361 (8,642), 3,599 (1,124), and 2,060 (731) verbal (nominal) propositions, respectively.", "labels": [], "entities": []}, {"text": "For the evaluation measurement on syntactic parsing, we report labeled recall, labeled precision, and their F1-measure.", "labels": [], "entities": [{"text": "syntactic parsing", "start_pos": 34, "end_pos": 51, "type": "TASK", "confidence": 0.7594663798809052}, {"text": "recall", "start_pos": 71, "end_pos": 77, "type": "METRIC", "confidence": 0.9296152591705322}, {"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.8802337050437927}, {"text": "F1-measure", "start_pos": 108, "end_pos": 118, "type": "METRIC", "confidence": 0.9914895296096802}]}, {"text": "Also, we report recall, precision, and their F1-measure for evaluation of SRL on automatic predicates, combining verbal SRL and nominal SRL.", "labels": [], "entities": [{"text": "recall", "start_pos": 16, "end_pos": 22, "type": "METRIC", "confidence": 0.999264657497406}, {"text": "precision", "start_pos": 24, "end_pos": 33, "type": "METRIC", "confidence": 0.9993896484375}, {"text": "F1-measure", "start_pos": 45, "end_pos": 55, "type": "METRIC", "confidence": 0.9942784309387207}, {"text": "SRL", "start_pos": 74, "end_pos": 77, "type": "TASK", "confidence": 0.5582975149154663}]}, {"text": "An argument is correctly labeled if there is an argument in manual annotation with the same semantic label that spans the same words.", "labels": [], "entities": []}, {"text": "Moreover, we also report the performance of predicate recognition.", "labels": [], "entities": [{"text": "predicate recognition", "start_pos": 44, "end_pos": 65, "type": "TASK", "confidence": 0.8513129949569702}]}, {"text": "To see whether an improvement in F1-measure is statistically significant, we also conduct significance tests using a type of stratified shuffling which in turn is a type of compute-intensive randomized tests.", "labels": [], "entities": [{"text": "F1-measure", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.9961122870445251}]}, {"text": "In this paper, '>>>', '>>', and '>' denote p-values less than or equal to 0.01, in-between (0.01, 0.05], and bigger than 0.05, respectively.", "labels": [], "entities": []}, {"text": "We are not aware of any SRL system combing automatic predicate recognition, verbal SRL and nominal SRL on Chinese PropBank and NomBank.", "labels": [], "entities": [{"text": "SRL", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9698342084884644}, {"text": "combing automatic predicate recognition", "start_pos": 35, "end_pos": 74, "type": "TASK", "confidence": 0.7467204481363297}, {"text": "Chinese PropBank", "start_pos": 106, "end_pos": 122, "type": "DATASET", "confidence": 0.903537780046463}, {"text": "NomBank", "start_pos": 127, "end_pos": 134, "type": "DATASET", "confidence": 0.6144977807998657}]}], "tableCaptions": [{"text": " Table 3: Syntactic and semantic parsing performance  on test data (using gold standard word boundaries).  \"V-\" denotes \"verbal\" while \"N-\"denotes \"nominal\".", "labels": [], "entities": [{"text": "Syntactic and semantic parsing", "start_pos": 10, "end_pos": 40, "type": "TASK", "confidence": 0.6940421089529991}]}, {"text": " Table 4: Performance with the character-based pars- er 1 (using automatically recognized word bounda- ries).", "labels": [], "entities": []}]}