{"title": [], "abstractContent": [{"text": "This paper presents a supervised approach for identifying generic noun phrases in context.", "labels": [], "entities": [{"text": "identifying generic noun phrases in context", "start_pos": 46, "end_pos": 89, "type": "TASK", "confidence": 0.8305087387561798}]}, {"text": "Generic statements express rule-like knowledge about kinds or events.", "labels": [], "entities": []}, {"text": "Therefore, their identification is important for the automatic construction of knowledge bases.", "labels": [], "entities": []}, {"text": "In particular, the distinction between generic and non-generic statements is crucial for the correct encoding of generic and instance-level information.", "labels": [], "entities": []}, {"text": "Generic expressions have been studied extensively informal semantics.", "labels": [], "entities": []}, {"text": "Building on this work, we explore a corpus-based learning approach for identifying generic NPs, using selections of linguistically motivated features.", "labels": [], "entities": []}, {"text": "Our results perform well above the baseline and existing prior work.", "labels": [], "entities": []}], "introductionContent": [{"text": "Generic expressions come in two basic forms: generic noun phrases and generic sentences.", "labels": [], "entities": []}, {"text": "Both express rule-like knowledge, but in different ways.", "labels": [], "entities": []}, {"text": "A generic noun phrase is a noun phrase that does not refer to a specific (set of) individual(s), but rather to a kind or class of individuals.", "labels": [], "entities": []}, {"text": "Thus, the NP The lion in (1.a) 1 is understood as a reference to the class \"lion\" instead of a specific individual.", "labels": [], "entities": []}, {"text": "Generic NPs are not restricted to occur with kind-related predicates as in (1.a).", "labels": [], "entities": []}, {"text": "As seen in (1.b), they may equally well be combined with predicates that denote specific actions.", "labels": [], "entities": []}, {"text": "In contrast to (1.a), the property defined by the verb phrase in (1.b) may hold of individual lions.", "labels": [], "entities": []}, {"text": "The lion was the most widespread mammal. b. Lions eat up to 30 kg in one sitting.", "labels": [], "entities": []}, {"text": "Generic sentences are characterising sentences that quantify over situations or events, expressing rule-like knowledge about habitual actions or situations (2.a).", "labels": [], "entities": []}, {"text": "This is in contrast with sentences that refer to specific events and individuals, as in (2.b).", "labels": [], "entities": []}, {"text": "The genericity of an expression may arise from the generic (kind-referring, class-denoting) interpretation of the NP or the characterising interpretation of the sentence predicate.", "labels": [], "entities": []}, {"text": "Both sources may concur in a single sentence, as illustrated in, where we have cross-classified the examples above according to the genericity of the NP and the sentence.", "labels": [], "entities": []}, {"text": "This classification is extremely difficult, because (i) the criteria for generic interpretation are far from being clear-cut and (ii) both sources of genericity may freely interact.", "labels": [], "entities": [{"text": "generic interpretation", "start_pos": 73, "end_pos": 95, "type": "TASK", "confidence": 0.9740508794784546}]}], "datasetContent": [{"text": "As data set we are using the ACE-2 () corpus, a collection of newspaper texts annotated with entities marked for their genericity.", "labels": [], "entities": [{"text": "ACE-2 () corpus", "start_pos": 29, "end_pos": 44, "type": "DATASET", "confidence": 0.8663313786188761}]}, {"text": "In this version of the corpus, the classification of entities is a binary one.", "labels": [], "entities": []}, {"text": "Annotation guidelines The ACE-2 annotation guidelines describe generic NPs as referring to an arbitrary member of the set in question, rather than to a particular individual.", "labels": [], "entities": []}, {"text": "Thus, a property attributed to a generic NP is in principle applicable to arbitrary members of the set (although not to all of them).", "labels": [], "entities": []}, {"text": "The guidelines list several tests that are either local syntactic tests involving determiners or tests that cannot be operationalised as they involve world knowledge and context information.", "labels": [], "entities": []}, {"text": "The guidelines give a number of criteria to identify generic NPs referring to specific properties.", "labels": [], "entities": []}, {"text": "These are (i) types of entities (lions in 3.a), (ii) suggested attributes of entities (mammals in 3.a), (iii) hypothetical entities (7) and (iv) generalisations across sets of entities (5.d).", "labels": [], "entities": []}, {"text": "(7) If a person steps over the line, they must be punished.", "labels": [], "entities": []}, {"text": "The general description of generic NPs as denoting arbitrary members of sets obviously does not capture kind-referring readings.", "labels": [], "entities": []}, {"text": "However, the properties characterised (i) can be understood to admit kinds.", "labels": [], "entities": []}, {"text": "Also, some illustrations in the guidelines explicitly characterise kind-referring NPs as generic.", "labels": [], "entities": []}, {"text": "Thus, while at first sight the guidelines do not fully correspond to the characterisation of generics we find in the formal semantics literature, we argue that both characterisations have similar extensions, i.e., include largely overlapping sets of noun phrases.", "labels": [], "entities": []}, {"text": "In fact, all of the examples for generic noun phrases presented in this paper would also be classified as generic according to the ACE-2 guidelines.", "labels": [], "entities": [{"text": "ACE-2", "start_pos": 131, "end_pos": 136, "type": "DATASET", "confidence": 0.911375880241394}]}, {"text": "We also find annotated examples of generic NPs that are not discussed in the formal semantics literature (8.a), but that are well captured by the ACE-2 guidelines.", "labels": [], "entities": []}, {"text": "However, there are also cases that are questionable. b. Even more remarkable is the Internet, where information of all kinds is available about the government and the economy.", "labels": [], "entities": []}, {"text": "This shows that the annotation of generics is difficult, but also highlights the potential benefit of a corpus-driven approach that allows us to gather a wider range of realisations.", "labels": [], "entities": []}, {"text": "This in turn can contribute to novel insights and discussion.", "labels": [], "entities": []}, {"text": "Data analysis A first investigation of the corpus shows that generic NPs are much less common than non-generic ones, at least in the newspaper genre at hand.", "labels": [], "entities": []}, {"text": "Of the 40,106 annotated entities, only 5,303 (13.2%) are marked as generic.", "labels": [], "entities": []}, {"text": "In order to control for bias effects in our classifier, we will experiment with two different training sets, a balanced and an unbalanced one.", "labels": [], "entities": []}, {"text": "Given the unclear dependencies of features, we chose to use a Bayesian network.", "labels": [], "entities": []}, {"text": "A Bayesian network represents the dependencies of random variables in a directed acyclic graph, where each node represents a random variable and each edge a dependency between variables.", "labels": [], "entities": []}, {"text": "In fact, a number of feature selection tests uncovered feature dependencies (see below).", "labels": [], "entities": []}, {"text": "We used the Weka () implementation BayesNet in all our experiments.", "labels": [], "entities": [{"text": "Weka () implementation BayesNet", "start_pos": 12, "end_pos": 43, "type": "DATASET", "confidence": 0.8500193208456039}]}, {"text": "To control for bias effects, we created balanced data sets by oversampling the number of generic entities and simultaneously undersampling nongeneric entities.", "labels": [], "entities": []}, {"text": "This results in a dataset of 20,053 entities with approx. 10,000 entities for each class.", "labels": [], "entities": []}, {"text": "All experiments are performed on balanced and unbalanced data sets using 10-fold crossvalidation, where balancing has been performed for each training fold separately (if any).", "labels": [], "entities": []}, {"text": "Feature classes We performed evaluation runs for different combinations of feature sets: NP-vs. S-level features (with further distinction between syntactic and semantic NP-/S-level features), as well as overall syntactic vs. semantic features.", "labels": [], "entities": []}, {"text": "This was done in order to determine the effect of different types of linguistic factors for the detection of genericity (cf.).", "labels": [], "entities": [{"text": "detection of genericity", "start_pos": 96, "end_pos": 119, "type": "TASK", "confidence": 0.6820818781852722}]}, {"text": "Feature selection We experimented with two methods for feature selection.", "labels": [], "entities": [{"text": "Feature selection", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.803897500038147}, {"text": "feature selection", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.8316308259963989}]}, {"text": "shows the resulting feature sets.", "labels": [], "entities": []}, {"text": "In ablation testing, a single feature in turn is temporarily omitted from the feature set.", "labels": [], "entities": []}, {"text": "The feature whose omission causes the biggest drop in fmeasure is set aside as a strong feature.", "labels": [], "entities": [{"text": "fmeasure", "start_pos": 54, "end_pos": 62, "type": "DATASET", "confidence": 0.9138652682304382}]}, {"text": "This process is repeated until we are left with an empty feature set.", "labels": [], "entities": []}, {"text": "From the ranked list of features f 1 to f n we evaluate increasingly extended feature sets f 1 ..f i for i = 2..n.", "labels": [], "entities": []}, {"text": "We select the feature set that yields the best balanced performance, at 45.7% precision and 53.6% f-measure.", "labels": [], "entities": [{"text": "precision", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9987720847129822}, {"text": "f-measure", "start_pos": 98, "end_pos": 107, "type": "METRIC", "confidence": 0.9818102121353149}]}, {"text": "The features are given as Set 5 in.", "labels": [], "entities": []}, {"text": "As ablation testing does not uncover feature dependencies, we also experimented with single, tuple and triple feature combinations to determine features that perform well in combination.", "labels": [], "entities": []}, {"text": "We ran evaluations using features in isolation and each possible pair and triple of features.", "labels": [], "entities": []}, {"text": "We select the resulting five best features, tuples and triples of features.", "labels": [], "entities": []}, {"text": "The respective feature sets are given as Set 1 to Set 3 in.", "labels": [], "entities": []}, {"text": "The features that appear most often in Set 1 to Set 3 are grouped in Set 4.", "labels": [], "entities": []}, {"text": "Baseline Our results are evaluated against three baselines.", "labels": [], "entities": []}, {"text": "Since the class distribution is unequal, a majority baseline consists in classifying each entity as non-generic.", "labels": [], "entities": []}, {"text": "As a second baseline we chose the performance of the feature Person, as this feature gave the best performance in precision among those that are similarly easy to extract.", "labels": [], "entities": [{"text": "precision", "start_pos": 114, "end_pos": 123, "type": "METRIC", "confidence": 0.9992345571517944}]}, {"text": "Finally, we compare our results to).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 6: Results of the classification, using different feature and training sets", "labels": [], "entities": []}]}