{"title": [{"text": "Cross-Language Text Classification using Structural Correspondence Learning", "labels": [], "entities": [{"text": "Cross-Language Text Classification", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7804567615191141}]}], "abstractContent": [{"text": "We present anew approach to cross-language text classification that builds on structural correspondence learning, a recently proposed theory for domain adaptation.", "labels": [], "entities": [{"text": "cross-language text classification", "start_pos": 28, "end_pos": 62, "type": "TASK", "confidence": 0.7152839104334513}, {"text": "domain adaptation", "start_pos": 145, "end_pos": 162, "type": "TASK", "confidence": 0.7283882200717926}]}, {"text": "The approach uses unlabeled documents , along with a simple word translation oracle, in order to induce task-specific, cross-lingual word correspondences.", "labels": [], "entities": [{"text": "word translation oracle", "start_pos": 60, "end_pos": 83, "type": "TASK", "confidence": 0.8007773160934448}]}, {"text": "We report on analyses that reveal quantitative insights about the use of un-labeled data and the complexity of inter-language correspondence modeling.", "labels": [], "entities": [{"text": "inter-language correspondence modeling", "start_pos": 111, "end_pos": 149, "type": "TASK", "confidence": 0.7813570300738016}]}, {"text": "We conduct experiments in the field of cross-language sentiment classification, employing English as source language, and German, French, and Japanese as target languages.", "labels": [], "entities": [{"text": "cross-language sentiment classification", "start_pos": 39, "end_pos": 78, "type": "TASK", "confidence": 0.8644827405611674}]}, {"text": "The results are convincing; they demonstrate both the robustness and the competitiveness of the presented ideas.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper deals with cross-language text classification problems.", "labels": [], "entities": [{"text": "cross-language text classification", "start_pos": 22, "end_pos": 56, "type": "TASK", "confidence": 0.7743439277013143}]}, {"text": "The solution of such problems requires the transfer of classification knowledge between two languages.", "labels": [], "entities": []}, {"text": "Stated precisely: We are given a text classification task \u03b3 in a target language T for which no labeled documents are available.", "labels": [], "entities": [{"text": "text classification task", "start_pos": 33, "end_pos": 57, "type": "TASK", "confidence": 0.79923548301061}]}, {"text": "\u03b3 maybe a spam filtering task, a topic categorization task, or a sentiment classification task.", "labels": [], "entities": [{"text": "spam filtering task", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.8727993170420328}, {"text": "topic categorization task", "start_pos": 33, "end_pos": 58, "type": "TASK", "confidence": 0.793787439664205}, {"text": "sentiment classification task", "start_pos": 65, "end_pos": 94, "type": "TASK", "confidence": 0.9120061198870341}]}, {"text": "In addition, we are given labeled documents for the identical task in a different source language S.", "labels": [], "entities": []}, {"text": "Such type of cross-language text classification problems are addressed by constructing a classifier f S with training documents written in Sand by applying f S to unlabeled documents written in T . For the application off S under language T different approaches are current practice: machine translation of unlabeled documents from T to S, dictionary-based translation of unlabeled documents from T to S, or language-independent concept modeling by means of comparable corpora.", "labels": [], "entities": [{"text": "cross-language text classification", "start_pos": 13, "end_pos": 47, "type": "TASK", "confidence": 0.6743136644363403}, {"text": "machine translation of unlabeled documents from T to S", "start_pos": 284, "end_pos": 338, "type": "TASK", "confidence": 0.8422619269953834}, {"text": "dictionary-based translation of unlabeled documents from T to S", "start_pos": 340, "end_pos": 403, "type": "TASK", "confidence": 0.8303373456001282}, {"text": "language-independent concept modeling", "start_pos": 408, "end_pos": 445, "type": "TASK", "confidence": 0.6106955707073212}]}, {"text": "The mentioned approaches have their pros and cons, some of which are discussed below.", "labels": [], "entities": []}, {"text": "Here we propose a different approach to crosslanguage text classification which adopts ideas from the field of multi-task learning.", "labels": [], "entities": [{"text": "crosslanguage text classification", "start_pos": 40, "end_pos": 73, "type": "TASK", "confidence": 0.7689603567123413}]}, {"text": "Our approach builds upon structural correspondence learning, SCL, a recently proposed theory for domain adaptation in the field of natural language processing ().", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 97, "end_pos": 114, "type": "TASK", "confidence": 0.7428880035877228}]}, {"text": "Similar to SCL, our approach induces correspondences among the words from both languages by means of a small number of so-called pivots.", "labels": [], "entities": []}, {"text": "In our context a pivot is a pair of words, {w S , w T }, from the source language Sand the target language T , which possess a similar semantics.", "labels": [], "entities": []}, {"text": "Testing the occurrence of w S or w T in a set of unlabeled documents from Sand T yields two equivalence classes across these languages: one class contains the documents where either w S or w T occur, the other class contains the documents where neither w S nor w T occur.", "labels": [], "entities": []}, {"text": "Ideally, a pivot splits the set of unlabeled documents with respect to the semantics that is associated with {w S , w T }.", "labels": [], "entities": []}, {"text": "The correlation between w S or w T and other words w, w \u2208 {w S , w T } is modeled by a linear classifier, which then is used as a language-independent predictor for the two equivalence classes.", "labels": [], "entities": []}, {"text": "As we will see, a small number of pivots can capture a sufficiently large part of the correspondences between Sand T in order to (1) construct a cross-lingual representation and (2) learn a classifier f ST for the task \u03b3 that operates on this representation.", "labels": [], "entities": []}, {"text": "Several advantages follow from our approach: \u2022 Task specificity.", "labels": [], "entities": [{"text": "Task specificity", "start_pos": 47, "end_pos": 63, "type": "TASK", "confidence": 0.7584474086761475}]}, {"text": "The approach exploits the words' pragmatics since it considers-during the pivot selection step-task-specific characteristics of language use.", "labels": [], "entities": []}, {"text": "\u2022 Efficiency in terms of linguistic resources.", "labels": [], "entities": [{"text": "Efficiency", "start_pos": 2, "end_pos": 12, "type": "METRIC", "confidence": 0.9755609035491943}]}, {"text": "The approach uses unlabeled documents from both languages along with a small number (100 -500) of translated words, instead of employing a parallel corpus or an extensive bilingual dictionary.", "labels": [], "entities": []}, {"text": "\u2022 Efficiency in terms of computing resources.", "labels": [], "entities": [{"text": "Efficiency", "start_pos": 2, "end_pos": 12, "type": "METRIC", "confidence": 0.9368352293968201}]}, {"text": "The approach solves the classification problem directly, instead of resorting to a more general and potentially much harder problem such as machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 140, "end_pos": 159, "type": "TASK", "confidence": 0.756682276725769}]}, {"text": "Note that the use of such technology is prohibited in certain situations (market competitors) or restricted by environmental constraints (offline situations, high latency, bandwidth capacity).", "labels": [], "entities": []}, {"text": "Contributions Our contributions to the outlined field are threefold: First, the identification and utilization of the theory of SCL to cross-language text classification, which has, to the best of our knowledge, not been investigated before.", "labels": [], "entities": [{"text": "SCL", "start_pos": 128, "end_pos": 131, "type": "TASK", "confidence": 0.9506350159645081}, {"text": "cross-language text classification", "start_pos": 135, "end_pos": 169, "type": "TASK", "confidence": 0.7141597668329874}]}, {"text": "Second, the further development and adaptation of SCL towards a technology that is competitive with the state-of-the-art in cross-language text classification.", "labels": [], "entities": [{"text": "SCL", "start_pos": 50, "end_pos": 53, "type": "TASK", "confidence": 0.9393845200538635}, {"text": "cross-language text classification", "start_pos": 124, "end_pos": 158, "type": "TASK", "confidence": 0.7067137757937113}]}, {"text": "Third, an in-depth analysis with respect to important hyperparameters such as the ratio of labeled and unlabeled documents, the number of pivots, and the optimum dimensionality of the cross-lingual representation.", "labels": [], "entities": []}, {"text": "In this connection we compile extensive corpora in the languages English, German, French, and Japanese, and for different sentiment classification tasks.", "labels": [], "entities": [{"text": "sentiment classification", "start_pos": 122, "end_pos": 146, "type": "TASK", "confidence": 0.9530837535858154}]}, {"text": "The paper is organized as follows: Section 2 surveys related work.", "labels": [], "entities": []}, {"text": "Section 3 states the terminology for cross-language text classification.", "labels": [], "entities": [{"text": "cross-language text classification", "start_pos": 37, "end_pos": 71, "type": "TASK", "confidence": 0.780849556128184}]}, {"text": "Section 4 describes our main contribution, anew approach to cross-language text classification based on structural correspondence learning.", "labels": [], "entities": [{"text": "cross-language text classification", "start_pos": 60, "end_pos": 94, "type": "TASK", "confidence": 0.7491745154062907}]}, {"text": "Section 5 presents experimental results in the context of cross-language sentiment classification.", "labels": [], "entities": [{"text": "cross-language sentiment classification", "start_pos": 58, "end_pos": 97, "type": "TASK", "confidence": 0.8879527449607849}]}], "datasetContent": [{"text": "We evaluate CL-SCL for the task of crosslanguage sentiment classification using English as source language and German, French, and Japanese as target languages.", "labels": [], "entities": [{"text": "crosslanguage sentiment classification", "start_pos": 35, "end_pos": 73, "type": "TASK", "confidence": 0.887543777624766}]}, {"text": "Special emphasis is put on corpus construction, determination of upper bounds and baselines, and a sensitivity analysis of important hyperparameters.", "labels": [], "entities": [{"text": "corpus construction", "start_pos": 27, "end_pos": 46, "type": "TASK", "confidence": 0.828143447637558}]}, {"text": "All data described in the following is publicly available from our project website.", "labels": [], "entities": []}, {"text": "We compiled anew dataset for cross-language sentiment classification by crawling product reviews from Amazon.{de | fr | co.jp}.", "labels": [], "entities": [{"text": "cross-language sentiment classification", "start_pos": 29, "end_pos": 68, "type": "TASK", "confidence": 0.8323228160540262}]}, {"text": "The crawled part of the corpus contains more than 4 million reviews in the three languages German, French, and Japanese.", "labels": [], "entities": []}, {"text": "The corpus is extended with English product reviews provided by.", "labels": [], "entities": []}, {"text": "Each review contains a category label, a title, the review text, and a rating of 1-5 stars.", "labels": [], "entities": []}, {"text": "Following a review with >3 (<3) stars is labeled as positive (negative); other reviews are discarded.", "labels": [], "entities": []}, {"text": "For each language the labeled reviews are grouped according to their category label, whereas we restrict our experiments to three categories: books, dvds, and music.", "labels": [], "entities": []}, {"text": "Since most of the crawled reviews are positive (80%), we decide to balance the number of positive and negative reviews.", "labels": [], "entities": []}, {"text": "In this study, we are interested in whether the cross-lingual representation induced by CL-SCL captures the difference between positive and negative reviews; by balancing the reviews we ensure that the imbalance does not affect the learned model.", "labels": [], "entities": []}, {"text": "Balancing is achieved by deleting reviews from the majority class uniformly at random for each languagespecific category.", "labels": [], "entities": [{"text": "Balancing", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9643246531486511}]}, {"text": "The resulting sets are split into three disjoint, balanced sets, containing training documents, test documents, and unlabeled documents; the respective set sizes are 2,000, 2,000, and 9,000-50,000.", "labels": [], "entities": []}, {"text": "For each of the nine target-language-categorycombinations a text classification task is created by taking the training set of the product category in Sand the test set of the same product category in T . A document dis described as normalized feature vector x under a unigram bag-of-words document representation.", "labels": [], "entities": [{"text": "text classification", "start_pos": 60, "end_pos": 79, "type": "TASK", "confidence": 0.7308632433414459}]}, {"text": "The morphological analyzer MeCab is used for Japanese word segmentation.", "labels": [], "entities": [{"text": "MeCab", "start_pos": 27, "end_pos": 32, "type": "DATASET", "confidence": 0.7445476651191711}, {"text": "Japanese word segmentation", "start_pos": 45, "end_pos": 71, "type": "TASK", "confidence": 0.6563582221666971}]}], "tableCaptions": [{"text": " Table 1: Cross-language sentiment classification results. For each task, the number of unlabeled docu- ments from S and T is given. Accuracy scores (mean \u00b5 and standard deviation \u03c3 of 10 repetitions of  SGD) on the test set of the target language T are reported. \u2206 gives the difference in accuracy to the  upper bound. CL-SCL uses m = 450, k = 100, and \u03c6 = 30.", "labels": [], "entities": [{"text": "Cross-language sentiment classification", "start_pos": 10, "end_pos": 49, "type": "TASK", "confidence": 0.877969761689504}, {"text": "Accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.9855930209159851}, {"text": "accuracy", "start_pos": 290, "end_pos": 298, "type": "METRIC", "confidence": 0.9992095232009888}, {"text": "\u03c6", "start_pos": 354, "end_pos": 355, "type": "METRIC", "confidence": 0.9768921136856079}]}]}