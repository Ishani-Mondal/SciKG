{"title": [], "abstractContent": [{"text": "We propose a novel method to automatically acquire a term-frequency-based tax-onomy from a corpus using an unsuper-vised method.", "labels": [], "entities": []}, {"text": "A term-frequency-based taxonomy is useful for application domains where the frequency with which terms occur on their own and in combination with other terms imposes a natural term hierarchy.", "labels": [], "entities": []}, {"text": "We highlight an application for our approach and demonstrate its effectiveness and robustness in extracting knowledge from real-world data.", "labels": [], "entities": []}], "introductionContent": [{"text": "Taxonomy deduction is an important task to understand and manage information.", "labels": [], "entities": [{"text": "Taxonomy deduction", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8891012966632843}]}, {"text": "However, building taxonomies manually for specific domains or data sources is time consuming and expensive.", "labels": [], "entities": []}, {"text": "Techniques to automatically deduce a taxonomy in an unsupervised manner are thus indispensable.", "labels": [], "entities": []}, {"text": "Automatic deduction of taxonomies consist of two tasks: extracting relevant terms to represent concepts of the taxonomy and discovering relationships between concepts.", "labels": [], "entities": [{"text": "Automatic deduction of taxonomies", "start_pos": 0, "end_pos": 33, "type": "TASK", "confidence": 0.7107134610414505}]}, {"text": "For unstructured text, the extraction of relevant terms relies on information extraction methods ().", "labels": [], "entities": [{"text": "information extraction", "start_pos": 66, "end_pos": 88, "type": "TASK", "confidence": 0.6900610625743866}]}, {"text": "The relationship extraction task can be classified into two categories.", "labels": [], "entities": [{"text": "relationship extraction task", "start_pos": 4, "end_pos": 32, "type": "TASK", "confidence": 0.8466342488924662}]}, {"text": "Approaches in the first category use lexical-syntactic formulation to define patterns, either manually () or automatically (), and apply those patterns to mine instances of the patterns.", "labels": [], "entities": []}, {"text": "Though producing accurate results, these approaches usually have low coverage for many domains and suffer from the problem of inconsistency between terms when connecting the instances as chains to form a taxonomy.", "labels": [], "entities": []}, {"text": "The second category of approaches uses clustering to discover terms and the relationships between them), even if those relationships do not explicitly appear in the text.", "labels": [], "entities": []}, {"text": "Though these methods tackle inconsistency by addressing taxonomy deduction globally, the relationships extracted are often difficult to interpret by humans.", "labels": [], "entities": [{"text": "taxonomy deduction", "start_pos": 56, "end_pos": 74, "type": "TASK", "confidence": 0.8369821012020111}]}, {"text": "We show that for certain domains, the frequency with which terms appear in a corpus on their own and in conjunction with other terms induces a natural taxonomy.", "labels": [], "entities": []}, {"text": "We formally define the concept of a term-frequency-based taxonomy and show its applicability for an example application.", "labels": [], "entities": []}, {"text": "We present an unsupervised method to generate such a taxonomy from scratch and outline how domainspecific constraints can easily be integrated into the generation process.", "labels": [], "entities": []}, {"text": "An advantage of the new method is that it can also be used to extend an existing taxonomy.", "labels": [], "entities": []}, {"text": "We evaluated our method on a large corpus of real-life addresses.", "labels": [], "entities": []}, {"text": "For addresses from emerging geographies no standard postal address scheme exists and our objective was to produce a postal taxonomy that is useful in standardizing addresses (.", "labels": [], "entities": []}, {"text": "Specifically, the experiments were designed to investigate the effectiveness of our approach on noisy terms with lots of variations.", "labels": [], "entities": []}, {"text": "The results show that our method is able to induce a taxonomy without using any kind of lexical-semantic patterns.", "labels": [], "entities": []}], "datasetContent": [{"text": "We present an evaluation of our approach for address data from an emerging economy.", "labels": [], "entities": []}, {"text": "We implemented our algorithm in Java and store the records in a DB2 database.", "labels": [], "entities": []}, {"text": "We rely on the DB2 optimizer to efficiently retrieve the next frequent term.", "labels": [], "entities": []}, {"text": "The results are based on 40 Million Indian addresses.", "labels": [], "entities": []}, {"text": "Each address record was given to us as a single string and was first tokenized into a sequence of terms as shown in.", "labels": [], "entities": []}, {"text": "Ina second step, we addressed spelling variations.", "labels": [], "entities": []}, {"text": "There is no fixed way of transliterating Indian alphabets to English and most Indian proper nouns have various spellings in English.", "labels": [], "entities": []}, {"text": "We used tools to detect synonyms with the same context to generate a list of rules to map terms to a standard form.", "labels": [], "entities": []}, {"text": "For example, in 'Maharashtra' can also be spelled 'Maharastra'.", "labels": [], "entities": []}, {"text": "We also used a list of keywords to classify some terms as markers such as 'Road' and 'Nagar' shown in.", "labels": [], "entities": []}, {"text": "Our evaluation consists of two parts.", "labels": [], "entities": []}, {"text": "First, we show results for constructing a TFIT from scratch.", "labels": [], "entities": []}, {"text": "To evaluate the precision and recall we also retrieved post office addresses from India Post 1 , cleaned them, and organized them in a tree.", "labels": [], "entities": [{"text": "precision", "start_pos": 16, "end_pos": 25, "type": "METRIC", "confidence": 0.9996789693832397}, {"text": "recall", "start_pos": 30, "end_pos": 36, "type": "METRIC", "confidence": 0.9996232986450195}, {"text": "India Post 1", "start_pos": 82, "end_pos": 94, "type": "DATASET", "confidence": 0.919994076093038}]}, {"text": "Second, we use our approach to enrich the existing hierarchy created from post office addresses with additional area terms.", "labels": [], "entities": []}, {"text": "To validate the result, we also retrieved data about which area names appear within a ZIP code.", "labels": [], "entities": []}, {"text": "We also verified whether Google Maps shows an area on its map.", "labels": [], "entities": [{"text": "Google Maps", "start_pos": 25, "end_pos": 36, "type": "DATASET", "confidence": 0.8816179037094116}]}], "tableCaptions": [{"text": " Table 1: Example of a tokenized address", "labels": [], "entities": []}, {"text": " Table 2: Precision and recall for categorizing  terms belonging to the state Maharashtra", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9922405481338501}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9993576407432556}]}]}