{"title": [{"text": "SystemT: An Algebraic Approach to Declarative Information Extraction", "labels": [], "entities": [{"text": "SystemT", "start_pos": 0, "end_pos": 7, "type": "TASK", "confidence": 0.7789832353591919}, {"text": "Declarative Information Extraction", "start_pos": 34, "end_pos": 68, "type": "TASK", "confidence": 0.763125459353129}]}], "abstractContent": [{"text": "As information extraction (IE) becomes more central to enterprise applications, rule-based IE engines have become increasingly important.", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 3, "end_pos": 30, "type": "TASK", "confidence": 0.8668973267078399}]}, {"text": "In this paper, we describe SystemT, a rule-based IE system whose basic design removes the ex-pressivity and performance limitations of current systems based on cascading grammars.", "labels": [], "entities": []}, {"text": "SystemT uses a declarative rule language, AQL, and an optimizer that generates high-performance algebraic execution plans for AQL rules.", "labels": [], "entities": [{"text": "SystemT", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.8589306473731995}]}, {"text": "We compare SystemT's approach against cascading grammars, both theoretically and with a thorough experimental evaluation.", "labels": [], "entities": []}, {"text": "Our results show that SystemT can deliver result quality comparable to the state-of-the-art and an order of magnitude higher annotation throughput.", "labels": [], "entities": []}], "introductionContent": [{"text": "In recent years, enterprises have seen the emergence of important text analytics applications like compliance and data redaction.", "labels": [], "entities": [{"text": "data redaction", "start_pos": 114, "end_pos": 128, "type": "TASK", "confidence": 0.7563010454177856}]}, {"text": "This increase, combined with the inclusion of text into traditional applications like Business Intelligence, has dramatically increased the use of information extraction (IE) within the enterprise.", "labels": [], "entities": [{"text": "information extraction (IE)", "start_pos": 147, "end_pos": 174, "type": "TASK", "confidence": 0.8570783138275146}]}, {"text": "While the traditional requirement of extraction quality remains critical, enterprise applications also demand efficiency, transparency, customizability and maintainability.", "labels": [], "entities": []}, {"text": "In recent years, these systemic requirements have led to renewed interest in rule-based IE systems (.", "labels": [], "entities": [{"text": "IE", "start_pos": 88, "end_pos": 90, "type": "TASK", "confidence": 0.8784028887748718}]}, {"text": "Until recently, rule-based IE systems) were predominantly based on the cascading grammar formalism exemplified by the Common Pattern Specification Language (CPSL) specification).", "labels": [], "entities": [{"text": "IE", "start_pos": 27, "end_pos": 29, "type": "TASK", "confidence": 0.8310316801071167}]}, {"text": "In CPSL, the input text is viewed as a sequence of annotations, and extraction rules are written as pattern/action rules over the lexical features of these annotations.", "labels": [], "entities": []}, {"text": "Ina single phase of the grammar, a set of rules are evaluated in a left-to-right fashion over the input annotations.", "labels": [], "entities": []}, {"text": "Multiple grammar phases are cascaded together, with the evaluation proceeding in a bottom-up fashion.", "labels": [], "entities": []}, {"text": "As demonstrated by prior work, grammar-based IE systems can be effective in many scenarios.", "labels": [], "entities": [{"text": "IE", "start_pos": 45, "end_pos": 47, "type": "TASK", "confidence": 0.8615108728408813}]}, {"text": "However, these systems suffer from two severe drawbacks.", "labels": [], "entities": []}, {"text": "First, the expressivity of CPSL falls short when used for complex IE tasks over increasingly pervasive informal text (emails, blogs, discussion forums etc.).", "labels": [], "entities": [{"text": "IE tasks", "start_pos": 66, "end_pos": 74, "type": "TASK", "confidence": 0.9246489107608795}]}, {"text": "To address this limitation, grammar-based IE systems resort to significant amounts of userdefined code in the rules, combined with preand post-processing stages beyond the scope of CPSL (.", "labels": [], "entities": []}, {"text": "Second, the rigid evaluation order imposed in these systems has significant performance implications.", "labels": [], "entities": []}, {"text": "Three decades ago, the database community faced similar expressivity and efficiency challenges in accessing structured information.", "labels": [], "entities": []}, {"text": "The community addressed these problems by introducing a relational algebra formalism and an associated declarative query language SQL.", "labels": [], "entities": []}, {"text": "The groundbreaking work on System R () demonstrated how the expressivity of SQL can be efficiently realized in practice by means of a query optimizer that translates an SQL query into an optimized query execution plan.", "labels": [], "entities": []}, {"text": "Borrowing ideas from the database community, we have developed SystemT, a declarative IE system based on an algebraic framework, to address both expressivity and performance issues.", "labels": [], "entities": []}, {"text": "In SystemT, extraction rules are expressed in a declarative language called AQL.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section we present an extensive comparison study between SystemT and implementations of expanded CPSL grammar in terms of quality, runtime performance and resource requirements.", "labels": [], "entities": []}, {"text": "Tasks We chose two tasks for our evaluation: \u2022 NER : named-entity recognition for Person, Organization, Location, Address, PhoneNumber, EmailAddress, URL and DateTime.", "labels": [], "entities": []}, {"text": "\u2022 BandReview : identify informal reviews in blogs.", "labels": [], "entities": []}, {"text": "We chose NER primarily because named-entity recognition is a well-studied problem and standard datasets are available for evaluation.", "labels": [], "entities": [{"text": "NER", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.8501986265182495}, {"text": "named-entity recognition", "start_pos": 31, "end_pos": 55, "type": "TASK", "confidence": 0.7707885205745697}]}, {"text": "For this task we use GATE and ANNIE for comparison . We chose BandReview to conduct performance evaluation fora more complex extraction task.", "labels": [], "entities": [{"text": "ANNIE", "start_pos": 30, "end_pos": 35, "type": "METRIC", "confidence": 0.988341748714447}, {"text": "BandReview", "start_pos": 62, "end_pos": 72, "type": "DATASET", "confidence": 0.9532111287117004}]}, {"text": "lists the datasets used for performance evaluation.", "labels": [], "entities": []}, {"text": "The size of Finance L is purposely small because GATE takes a significant amount of time processing large documents (see Sec. 5.2).", "labels": [], "entities": [{"text": "GATE", "start_pos": 49, "end_pos": 53, "type": "TASK", "confidence": 0.828486979007721}]}, {"text": "The experiments were run on a server with two 2.4 GHz 4-core Intel Xeon CPUs and 64GB of memory.", "labels": [], "entities": []}, {"text": "We use GATE 5.1 (build 3431) and two configurations for ANNIE: 1) the default configuration, and 2) an optimized configuration where the Ontotext Japec Transducer 6 replaces the default NE transducer for optimized performance.", "labels": [], "entities": [{"text": "GATE 5.1", "start_pos": 7, "end_pos": 15, "type": "DATASET", "confidence": 0.8487750291824341}]}, {"text": "We refer to these configurations as ANNIE and ANNIE-Optimized, respectively.", "labels": [], "entities": [{"text": "ANNIE", "start_pos": 36, "end_pos": 41, "type": "METRIC", "confidence": 0.7706776857376099}]}, {"text": "The goal of our quality evaluation is two-fold: to validate that annotators can be builtin SystemT with quality comparable to those builtin a grammar-based system; and to ensure a fair performance comparison between SystemT and GATE by verifying that the annotators used in the study are comparable.", "labels": [], "entities": []}, {"text": "shows results of our comparison study for Person annotators.", "labels": [], "entities": []}, {"text": "We report the classical (exact) precision, recall, and F 1 measures that credit only exact matches, and corresponding partial measures that credit partial matches in a fashion similar to).", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9024314284324646}, {"text": "recall", "start_pos": 43, "end_pos": 49, "type": "METRIC", "confidence": 0.998779833316803}, {"text": "F 1", "start_pos": 55, "end_pos": 58, "type": "METRIC", "confidence": 0.9953877627849579}]}, {"text": "As can be seen, T-NE produced results of significantly higher quality than ANNIE on both datasets, for the same Person extraction task.", "labels": [], "entities": [{"text": "ANNIE", "start_pos": 75, "end_pos": 80, "type": "METRIC", "confidence": 0.837531328201294}, {"text": "Person extraction task", "start_pos": 112, "end_pos": 134, "type": "TASK", "confidence": 0.8033780058224996}]}, {"text": "In fact, on EnronMeetings, the F 1 measure of T-NE is 7.4% higher than the best published result).", "labels": [], "entities": [{"text": "EnronMeetings", "start_pos": 12, "end_pos": 25, "type": "DATASET", "confidence": 0.9433748722076416}, {"text": "F 1 measure", "start_pos": 31, "end_pos": 42, "type": "METRIC", "confidence": 0.9882160226504008}, {"text": "T-NE", "start_pos": 46, "end_pos": 50, "type": "METRIC", "confidence": 0.8426305651664734}]}, {"text": "Similar results can be observed for Organization and Location on ACE (exact numbers omitted in interest of space).", "labels": [], "entities": [{"text": "Organization and Location", "start_pos": 36, "end_pos": 61, "type": "TASK", "confidence": 0.7267988522847494}]}, {"text": "Clearly, considering the large gap between ANNIE's F 1 and partial F 1 measures on both datasets, ANNIE's quality can be improved via dataset-specific tuning as demonstrated in.", "labels": [], "entities": [{"text": "F 1 and partial F 1", "start_pos": 51, "end_pos": 70, "type": "METRIC", "confidence": 0.7254775563875834}]}, {"text": "However, dataset-specific tuning for ANNIE is beyond the scope of this paper.", "labels": [], "entities": [{"text": "ANNIE", "start_pos": 37, "end_pos": 42, "type": "TASK", "confidence": 0.6607397198677063}]}, {"text": "Based on the experimental results above and our previous formal comparison in Sec.", "labels": [], "entities": []}, {"text": "4, we believe it is reasonable to conclude that annotators can be builtin SystemT of quality at least comparable to those builtin a grammar-based system.", "labels": [], "entities": []}, {"text": "We now focus our attention on the throughput and memory behavior of SystemT, and draw a comparison with GATE.", "labels": [], "entities": [{"text": "GATE", "start_pos": 104, "end_pos": 108, "type": "DATASET", "confidence": 0.7784061431884766}]}, {"text": "For this purpose, we have configured both ANNIE and T-NE to identify only the same eight types of entities listed for NER task.", "labels": [], "entities": [{"text": "ANNIE", "start_pos": 42, "end_pos": 47, "type": "METRIC", "confidence": 0.819701611995697}, {"text": "NER task", "start_pos": 118, "end_pos": 126, "type": "TASK", "confidence": 0.8654693365097046}]}, {"text": "plots the throughput of the two systems on multiple Enron x datasets with average document sizes of between 0.5KB and 100KB.", "labels": [], "entities": [{"text": "Enron x datasets", "start_pos": 52, "end_pos": 68, "type": "DATASET", "confidence": 0.9119313359260559}]}, {"text": "For this experiment, both systems ran with a maximum Java heap size of 1GB.", "labels": [], "entities": []}, {"text": "As shown in, even though the throughput of ANNIE-Optimized (using the optimized transducer) increases two-fold compared to ANNIE under default configuration, T-NE is between 8 and 24 times faster compared to ANNIE-Optimized.", "labels": [], "entities": []}, {"text": "For both systems, throughput varied with document size.", "labels": [], "entities": []}, {"text": "For T-NE, the relatively low throughput on very small document sizes (less than 1KB) is due to fixed overhead insetting up operators to process a document.", "labels": [], "entities": []}, {"text": "As document size increases, the overhead becomes less noticeable.", "labels": [], "entities": [{"text": "overhead", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9779289364814758}]}, {"text": "We have observed similar trends on the rest of the test collections.", "labels": [], "entities": []}, {"text": "shows that T-NE is at least an order of magnitude faster than ANNIE-Optimized across all datasets.", "labels": [], "entities": [{"text": "T-NE", "start_pos": 11, "end_pos": 15, "type": "METRIC", "confidence": 0.6608057022094727}]}, {"text": "In particular, on Finance L T-NE's throughput remains high, whereas the performance of both ANNIE and ANNIE-Optimized degraded significantly.", "labels": [], "entities": [{"text": "ANNIE", "start_pos": 92, "end_pos": 97, "type": "DATASET", "confidence": 0.47455713152885437}]}, {"text": "To ascertain whether the difference in performance in the two systems is due to low-level components such as dictionary evaluation, we performed detailed profiling of the systems.", "labels": [], "entities": [{"text": "dictionary evaluation", "start_pos": 109, "end_pos": 130, "type": "TASK", "confidence": 0.6938609927892685}]}, {"text": "The profiling revealed that 8.2%, 16.2% and respectively 14.2% of the execution time was spent on average on low-level components in the case of ANNIE, ANNIE-Optimized and T-NE, respectively, thus leading us to conclude that the observed differences are due to SystemT's efficient use of resources at a macroscopic level.", "labels": [], "entities": []}, {"text": "In theory, grammar based systems can stream tuples through each stage for minimal memory consumption, whereas SystemT operator graphs may need to materialize intermediate results for the full document at certain points to evaluate the constraints in the original AQL.", "labels": [], "entities": []}, {"text": "The goal of this study is to evaluate whether this potential problem does occur in practice.", "labels": [], "entities": []}, {"text": "In this experiment we ran both systems with a maximum heap size of 2GB, and used the Java garbage collector's built-in telemetry to measure the total quantity of live objects in the heap overtime while annotating the different test corpora.", "labels": [], "entities": []}, {"text": "plots the minimum, maximum, and mean heap sizes with the Enron x datasets.", "labels": [], "entities": [{"text": "Enron x datasets", "start_pos": 57, "end_pos": 73, "type": "DATASET", "confidence": 0.867084801197052}]}, {"text": "On small documents of size up to 15KB, memory consumption is dominated by the fixed size of the data structures used (e.g., dictionaries, FST/operator graph), and is comparable for both systems.", "labels": [], "entities": []}, {"text": "As documents get larger, memory consumption increases for both systems.", "labels": [], "entities": []}, {"text": "However, the increase is much smaller for T-NE compared to that for both AN-NIE and ANNIE-Optimized.", "labels": [], "entities": []}, {"text": "A similar trend can be observed on the other datasets as shown in Table 3.", "labels": [], "entities": []}, {"text": "In particular, for Finance L , both ANNIE and ANNIE-Optimized required 8GB of Java heap size to achieve reasonable throughput 7 , in contrast to T-NE which utilized at most 300MB out of the 2GB of maximum Java heap size allocation.", "labels": [], "entities": []}, {"text": "SystemT requires much less memory than GATE in general due to its runtime, which monitors data dependencies between operators and clears out low-level results when they are no longer needed.", "labels": [], "entities": [{"text": "SystemT", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.847990095615387}]}, {"text": "Although a streaming CPSL implementation is theoretically possible, in practice mechanisms that allow an escape to custom code make it difficult to decide when an intermediate result will no longer be used, hence GATE keeps most intermediate data in memory until it is done analyzing the current document.", "labels": [], "entities": []}, {"text": "We conclude by briefly discussing our experience with the BandReview task from.", "labels": [], "entities": [{"text": "BandReview task", "start_pos": 58, "end_pos": 73, "type": "DATASET", "confidence": 0.9047462642192841}]}, {"text": "We built two versions of this annotator, one in AQL, and the other using expanded CPSL grammar.", "labels": [], "entities": []}, {"text": "The grammar implementation processed a 4.5GB collection of 1.05 million blogs in 5.6 hours and output 280 reviews.", "labels": [], "entities": []}, {"text": "In contrast, the SystemT version (85 AQL statements) extracted 323 reviews in only 10 minutes!", "labels": [], "entities": [{"text": "SystemT", "start_pos": 17, "end_pos": 24, "type": "DATASET", "confidence": 0.7713446021080017}]}], "tableCaptions": [{"text": " Table 1: Datasets for performance evaluation.", "labels": [], "entities": []}, {"text": " Table 2: Quality of Person on test datasets.", "labels": [], "entities": [{"text": "Quality", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9567914605140686}]}, {"text": " Table 3: Throughput and mean heap size.", "labels": [], "entities": []}]}