{"title": [{"text": "Correcting Errors in a Treebank Based on Synchronous Tree Substitution Grammar", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper proposes a method of correcting annotation errors in a treebank.", "labels": [], "entities": []}, {"text": "By using asynchronous grammar, the method transforms parse trees containing annotation errors into the ones whose errors are corrected.", "labels": [], "entities": []}, {"text": "The synchronous grammar is automatically induced from the treebank.", "labels": [], "entities": []}, {"text": "We report an experimental result of applying our method to the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 63, "end_pos": 76, "type": "DATASET", "confidence": 0.994966983795166}]}, {"text": "The result demonstrates that our method corrects syntactic annotation errors with high precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 87, "end_pos": 96, "type": "METRIC", "confidence": 0.9974371194839478}]}], "introductionContent": [{"text": "Annotated corpora play an important role in the fields such as theoretical linguistic researches or the development of NLP systems.", "labels": [], "entities": []}, {"text": "However, they often contain annotation errors which are caused by a manual or semi-manual mark-up process.", "labels": [], "entities": []}, {"text": "These errors are problematic for corpus-based researches.", "labels": [], "entities": []}, {"text": "To solve this problem, several error detection and correction methods have been proposed so far).", "labels": [], "entities": [{"text": "error detection and correction", "start_pos": 31, "end_pos": 61, "type": "TASK", "confidence": 0.7468919232487679}]}, {"text": "These methods detect corpus positions which are marked up incorrectly, and find the correct labels (e.g. pos-tags) for those positions.", "labels": [], "entities": []}, {"text": "However, the methods cannot correct errors in structural annotation.", "labels": [], "entities": []}, {"text": "This means that they are insufficient to correct annotation errors in a treebank.", "labels": [], "entities": []}, {"text": "This paper proposes a method of correcting errors in structural annotation.", "labels": [], "entities": []}, {"text": "Our method is based on asynchronous grammar formalism, called synchronous tree substitution grammar (STSG), which defines a tree-to-tree transformation.", "labels": [], "entities": [{"text": "synchronous tree substitution grammar (STSG)", "start_pos": 62, "end_pos": 106, "type": "TASK", "confidence": 0.7570149217333112}]}, {"text": "By using an STSG, our method transforms parse trees containing errors into the ones whose errors are corrected.", "labels": [], "entities": []}, {"text": "The grammar is automatically induced from the treebank.", "labels": [], "entities": []}, {"text": "To select STSG rules which are useful for error correction, we define a score function based on the occurrence frequencies of the rules.", "labels": [], "entities": [{"text": "error correction", "start_pos": 42, "end_pos": 58, "type": "TASK", "confidence": 0.6683616489171982}]}, {"text": "An experimental result shows that the selected rules archive high precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9985307455062866}]}, {"text": "This paper is organized as follows: Section 2 gives an overview of previous work.", "labels": [], "entities": []}, {"text": "Section 3 explains our method of correcting errors in a treebank.", "labels": [], "entities": [{"text": "correcting errors", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.8435601890087128}]}, {"text": "Section 4 reports an experimental result using the Penn Treebank.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 51, "end_pos": 64, "type": "DATASET", "confidence": 0.9947930872440338}]}], "datasetContent": [{"text": "To evaluate the effectiveness of our method, we conducted an experiment using the Penn Treebank (.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 82, "end_pos": 95, "type": "DATASET", "confidence": 0.995587021112442}]}, {"text": "We used 49208 sentences in Wall Street Journal sections.", "labels": [], "entities": [{"text": "Wall Street Journal sections", "start_pos": 27, "end_pos": 55, "type": "DATASET", "confidence": 0.9708526879549026}]}, {"text": "We induced STSG rules by applying our method to the corpus.", "labels": [], "entities": []}, {"text": "We We manually checked whether each rule application corrected an error, because the corrected treebank does not exist 2 . Furthermore, we only evaluated the first 100 rules which are ordered by the score function described in Section 3.3, since it is time-consuming and expensive to evaluate all of the rules.", "labels": [], "entities": []}, {"text": "These 100 rules were applied at 331 positions.", "labels": [], "entities": []}, {"text": "The precision of the rules is 71.9%.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9996287822723389}]}, {"text": "For each rule, we measured the precision of it.", "labels": [], "entities": [{"text": "precision", "start_pos": 31, "end_pos": 40, "type": "METRIC", "confidence": 0.9996596574783325}]}, {"text": "70 rules achieved 100% precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9994168281555176}]}, {"text": "These results demonstrate that our method can correct syntactic annotation errors with high precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 92, "end_pos": 101, "type": "METRIC", "confidence": 0.9964770674705505}]}, {"text": "Moreover, 30 rules of the 70 rules transformed bracketed structures.", "labels": [], "entities": []}, {"text": "This fact shows that the treebank contains structural errors which cannot be dealt with by the previous methods.", "labels": [], "entities": []}, {"text": "depicts examples of error correction rules which achieved 100% precision.", "labels": [], "entities": [{"text": "error correction", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.6866969764232635}, {"text": "precision", "start_pos": 63, "end_pos": 72, "type": "METRIC", "confidence": 0.9983596205711365}]}, {"text": "Rule (1), (2) and (3) are rules which transform bracketed structures.", "labels": [], "entities": []}, {"text": "Rule (4) simply replaces anode label.", "labels": [], "entities": []}, {"text": "Rule (1) corrects an erroneous position of a comma (see (a)).", "labels": [], "entities": []}, {"text": "Rule (2) deletes a useless node NP in a subject position (see (b)).", "labels": [], "entities": []}, {"text": "Rule (3) inserts anode NP (see (c)).", "labels": [], "entities": []}, {"text": "Rule (4) replaces anode label NP with the correct label PP (see).", "labels": [], "entities": []}, {"text": "These examples demonstrate that our method can correct syntactic annotation errors.", "labels": [], "entities": []}, {"text": "depicts an example where our method detected an annotation error but could not correct it.", "labels": [], "entities": []}, {"text": "To correct the error, we need to attach the node  SBAR under the node NP.", "labels": [], "entities": []}, {"text": "We found that 22 of the rule applications were of this type.", "labels": [], "entities": []}, {"text": "depicts a false positive example where our method mistakenly transformed a correct syntactic structure.", "labels": [], "entities": []}, {"text": "The score of the rule is very high, since the source elementary tree (TOP (NP NP VP .)) is less frequent.", "labels": [], "entities": [{"text": "TOP", "start_pos": 70, "end_pos": 73, "type": "METRIC", "confidence": 0.8788227438926697}]}, {"text": "This example shows that our method has a risk of changing correct annotations of less frequent syntactic structures.", "labels": [], "entities": []}], "tableCaptions": []}