{"title": [{"text": "A Generalized-Zero-Preserving Method for Compact Encoding of Concept Lattices", "labels": [], "entities": [{"text": "Compact Encoding of Concept Lattices", "start_pos": 41, "end_pos": 77, "type": "TASK", "confidence": 0.7868541121482849}]}], "abstractContent": [{"text": "Constructing an encoding of a concept lattice using short bit vectors allows for efficient computation of join operations on the lattice.", "labels": [], "entities": []}, {"text": "Join is the central operation any unification-based parser must support.", "labels": [], "entities": []}, {"text": "We extend the traditional bit vector encoding , which represents join failure using the zero vector, to count any vector with less than a fixed number of one bits as failure.", "labels": [], "entities": []}, {"text": "This allows non-joinable elements to share bits, resulting in a smaller vector size.", "labels": [], "entities": []}, {"text": "A constraint solver is used to construct the encoding, and a variety of techniques are employed to find near-optimal solutions and handle timeouts.", "labels": [], "entities": []}, {"text": "An evaluation is provided comparing the extended representation of failure with traditional bit vector techniques.", "labels": [], "entities": []}], "introductionContent": [{"text": "The use of bit vectors is almost as old as HPSG parsing itself.", "labels": [], "entities": [{"text": "HPSG parsing", "start_pos": 43, "end_pos": 55, "type": "TASK", "confidence": 0.8026555776596069}]}, {"text": "Since they were first suggested in the programming languages literature) as a method for computing the unification of two types without table lookup, bit vectors have been attractive because of three speed advantages: \u2022 The classical bit vector encoding uses bitwise AND to calculate type unification.", "labels": [], "entities": [{"text": "type unification", "start_pos": 284, "end_pos": 300, "type": "TASK", "confidence": 0.7165872752666473}]}, {"text": "This is hard to beat.", "labels": [], "entities": []}, {"text": "\u2022 Hash tables, the most common alternative, involve computing the Dedekind-MacNeille completion (DMC) at compile time if the input type hierarchy is not a bounded-complete partial order.", "labels": [], "entities": []}, {"text": "That is exponential time in the worst case; most bit vector methods avoid explicitly computing it.", "labels": [], "entities": []}, {"text": "\u2022 With large type signatures, the table that indexes unifiable pairs of types maybe so large that it pushes working parsing memory into swap.", "labels": [], "entities": []}, {"text": "This loss of locality of reference costs time.", "labels": [], "entities": []}, {"text": "Why isn't everyone using bit vectors?", "labels": [], "entities": []}, {"text": "For the most part, the reason is their size.", "labels": [], "entities": []}, {"text": "The classical encoding given by A\u00a8\u0131tA\u00a8\u0131t- is at least as large as the number of meet-irreducible types, which in the parlance of HPSG type signatures is the number of unary-branching types plus the number of maximally specific types.", "labels": [], "entities": [{"text": "A\u00a8\u0131tA\u00a8\u0131t-", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9430050154527029}]}, {"text": "For the English Resource Grammar (ERG)), these are 314 and 2474 respectively.", "labels": [], "entities": [{"text": "English Resource Grammar (ERG))", "start_pos": 8, "end_pos": 39, "type": "DATASET", "confidence": 0.8750781615575155}]}, {"text": "While some systems use them nonetheless) does, as a very notable exception), it is clear that the size of these codes is a source of concern.", "labels": [], "entities": []}, {"text": "Again, it has been so since the very beginning: A\u00a8\u0131tA\u00a8\u0131t- devoted several pages to a discussion of how to \"modularize\" type codes, which typically achieves a smaller code in exchange fora larger-time operation than bitwise AND as the implementation of type unification.", "labels": [], "entities": [{"text": "A\u00a8\u0131tA\u00a8\u0131t-", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.9170049925645193}, {"text": "modularize\" type codes", "start_pos": 107, "end_pos": 129, "type": "TASK", "confidence": 0.8222101032733917}, {"text": "type unification", "start_pos": 252, "end_pos": 268, "type": "TASK", "confidence": 0.8352821469306946}]}, {"text": "However, in this and later work on the subject (e.g.), one constant has been that we know our unification has failed when the implementation returns the zero vector.", "labels": [], "entities": []}, {"text": "Zero preservation, i.e., detecting a type unification failure, is just as important as obtaining the right answer quickly when it succeeds.", "labels": [], "entities": [{"text": "type unification", "start_pos": 37, "end_pos": 53, "type": "TASK", "confidence": 0.7186174541711807}]}, {"text": "The approach of the present paper borrows from recent statistical machine translation research, which addresses the problem of efficiently representing large-scale language models using a mathematical construction called a Bloom filter.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 54, "end_pos": 85, "type": "TASK", "confidence": 0.6234773000081381}]}, {"text": "The approach is best combined with modularization in order to further reduce the size of the codes, but its novelty lies in the observation that counting the number of one bits in an integer is implemented in the basic instruction sets of many CPUs.", "labels": [], "entities": []}, {"text": "The question then arises whether smaller codes would be obtained by relaxing zero preservation so that any resulting vector with at most \u03bb bits is interpreted as failure, with \u03bb \u2265 1.", "labels": [], "entities": []}, {"text": "Penn generalized join-preserving encodings of partial orders to the case where more than one code can be used to represent the same object, but the focus there was on codes arising from successful unifications; there was still only one representative for failure.", "labels": [], "entities": []}, {"text": "To our knowledge, the present paper is the first generalization of zero preservation in CL or any other application domain of partial order encodings.", "labels": [], "entities": []}, {"text": "We note at the outset that we are not using Bloom filters as such, but rather a derandomized encoding scheme that shares with Bloom filters the essential insight that \u03bb can be greater than zero without adverse consequences for the required algebraic properties of the encoding.", "labels": [], "entities": []}, {"text": "Deterministic variants of Bloom filters may in turn prove to be of some value in language modelling.", "labels": [], "entities": [{"text": "language modelling", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.7633980214595795}]}], "datasetContent": [{"text": "The non-modular encoding with \u03bb = 0 is the basic encoding of A\u00a8\u0131tA\u00a8\u0131t-.", "labels": [], "entities": [{"text": "A\u00a8\u0131tA\u00a8\u0131t-", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9257261554400126}]}, {"text": "As Table 3 shows, we achieved more than a factor of two improvement from that, in both time and vector length, just by setting \u03bb = 1.", "labels": [], "entities": []}, {"text": "Larger values offered further small improvements in length up to \u03bb = 140, which gave the minimum vector length of 985.", "labels": [], "entities": [{"text": "length", "start_pos": 52, "end_pos": 58, "type": "METRIC", "confidence": 0.9775731563568115}]}, {"text": "That is a shallow minimum; both \u03bb = 120 and \u03bb = 160 gave vector lengths of 986, and the length slowly increased with greater \u03bb.", "labels": [], "entities": [{"text": "length", "start_pos": 88, "end_pos": 94, "type": "METRIC", "confidence": 0.9531994462013245}]}, {"text": "However, the fastest bit-count on this architec- ture, using a technique first published by, requires time increasing with the number of nonzero bits it counts; and a similar effect would appear on a word-by-word basis even if we used a constant-time per-word count.", "labels": [], "entities": []}, {"text": "As a result, there is a time cost associated with using larger \u03bb, so that the fastest value is not necessarily the one that gives the shortest vectors.", "labels": [], "entities": []}, {"text": "In our experiments, \u03bb = 9 gave the fastest joins for the non-modular encoding of the ERG.", "labels": [], "entities": []}, {"text": "As shown in, all small nonzero \u03bb gave very similar times.", "labels": [], "entities": []}, {"text": "Modularization helps a lot, both with \u03bb = 0, and when we choose the optimal \u03bb per module.", "labels": [], "entities": []}, {"text": "Here, too, the use of optimal \u03bb improves both time and space by more than a factor of two.", "labels": [], "entities": []}, {"text": "Our best bit-vector encoding, the modularized one with permodule optimal \u03bb, is only a little less than half the speed of the lookup table; and this test favours the lookup table by giving it a full word for every entry (no time spent shifting and masking bits) and testing the pairs in a simple two-level loop (almost purely sequential access).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Rules for solving an instance in the ERG", "labels": [], "entities": [{"text": "ERG", "start_pos": 47, "end_pos": 50, "type": "TASK", "confidence": 0.3758082687854767}]}, {"text": " Table 2: Best encodings of the ERG and its mod- ules: n is number of types, b 0 is vector length with  \u03bb = 0, and \u03bb is parameter that gives the shortest  vector length b \u03bb .", "labels": [], "entities": []}, {"text": " Table 3: Query performance. Vector length in bits,  time in milliseconds, space in Kbytes.", "labels": [], "entities": []}]}