{"title": [{"text": "Bridging SMT and TM with Translation Recommendation", "labels": [], "entities": [{"text": "Bridging SMT", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.526373416185379}, {"text": "Translation Recommendation", "start_pos": 25, "end_pos": 51, "type": "TASK", "confidence": 0.7507518827915192}]}], "abstractContent": [{"text": "We propose a translation recommendation framework to integrate Statistical Machine Translation (SMT) output with Translation Memory (TM) systems.", "labels": [], "entities": [{"text": "translation recommendation", "start_pos": 13, "end_pos": 39, "type": "TASK", "confidence": 0.9316453039646149}, {"text": "Statistical Machine Translation (SMT) output", "start_pos": 63, "end_pos": 107, "type": "TASK", "confidence": 0.8266390987804958}]}, {"text": "The framework recommends SMT outputs to a TM user when it predicts that SMT outputs are more suitable for post-editing than the hits provided by the TM.", "labels": [], "entities": [{"text": "SMT outputs", "start_pos": 25, "end_pos": 36, "type": "TASK", "confidence": 0.921038419008255}, {"text": "SMT outputs", "start_pos": 72, "end_pos": 83, "type": "TASK", "confidence": 0.8753423392772675}]}, {"text": "We describe an implementation of this framework using an SVM binary classifier.", "labels": [], "entities": []}, {"text": "We exploit methods to fine-tune the classifier and investigate a variety of features of different types.", "labels": [], "entities": []}, {"text": "We rely on automatic MT evaluation metrics to approximate human judgements in our experiments.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.9217928647994995}]}, {"text": "Experimental results show that our system can achieve 0.85 precision at 0.89 recall, excluding exact matches.", "labels": [], "entities": [{"text": "precision", "start_pos": 59, "end_pos": 68, "type": "METRIC", "confidence": 0.9932528138160706}, {"text": "recall", "start_pos": 77, "end_pos": 83, "type": "METRIC", "confidence": 0.9958523511886597}]}, {"text": "Furthermore, it is possible for the end-user to achieve a desired balance between precision and recall by adjusting confidence levels.", "labels": [], "entities": [{"text": "precision", "start_pos": 82, "end_pos": 91, "type": "METRIC", "confidence": 0.9994009733200073}, {"text": "recall", "start_pos": 96, "end_pos": 102, "type": "METRIC", "confidence": 0.997933030128479}]}], "introductionContent": [{"text": "Recent years have witnessed rapid developments in statistical machine translation (SMT), with considerable improvements in translation quality.", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 50, "end_pos": 87, "type": "TASK", "confidence": 0.8461790184179941}]}, {"text": "For certain language pairs and applications, automated translations are now beginning to be considered acceptable, especially in domains where abundant parallel corpora exist.", "labels": [], "entities": []}, {"text": "However, these advances are being adopted only slowly and somewhat reluctantly in professional localization and post-editing environments.", "labels": [], "entities": []}, {"text": "Post-editors have long relied on translation memories (TMs) as the main technology assisting translation, and are understandably reluctant to give them up.", "labels": [], "entities": [{"text": "translation memories (TMs)", "start_pos": 33, "end_pos": 59, "type": "TASK", "confidence": 0.8619502425193787}, {"text": "translation", "start_pos": 93, "end_pos": 104, "type": "TASK", "confidence": 0.9758679866790771}]}, {"text": "There are several simple reasons for this: 1) TMs are useful; 2) TMs represent considerable effort and investment by a company or (even more so) an individual translator; 3) the fuzzy match score used in TMs offers a good approximation of post-editing effort, which is useful both for translators and translation cost estimation and, 4) current SMT translation confidence estimation measures are not as robust as TM fuzzy match scores and professional translators are thus not ready to replace fuzzy match scores with SMT internal quality measures.", "labels": [], "entities": [{"text": "translation cost estimation", "start_pos": 301, "end_pos": 328, "type": "TASK", "confidence": 0.7057323455810547}, {"text": "SMT translation confidence estimation", "start_pos": 345, "end_pos": 382, "type": "TASK", "confidence": 0.7968042641878128}, {"text": "SMT internal", "start_pos": 518, "end_pos": 530, "type": "TASK", "confidence": 0.9048303365707397}]}, {"text": "There has been some research to address this issue, see e.g. ( and).", "labels": [], "entities": []}, {"text": "However, to date most of the research has focused on better confidence measures for MT, e.g. based on training regression models to perform confidence estimation on scores assigned by post-editors (cf. Section 2).", "labels": [], "entities": [{"text": "MT", "start_pos": 84, "end_pos": 86, "type": "TASK", "confidence": 0.9958445429801941}]}, {"text": "In this paper, we try to address the problem from a different perspective.", "labels": [], "entities": []}, {"text": "Given that most postediting work is (still) based on TM output, we propose to recommend MT outputs which are better than TM hits to post-editors.", "labels": [], "entities": [{"text": "MT", "start_pos": 88, "end_pos": 90, "type": "TASK", "confidence": 0.9536385536193848}]}, {"text": "In this framework, post-editors still work with the TM while benefiting from (better) SMT outputs; the assets in TMs are not wasted and TM fuzzy match scores can still be used to estimate (the upper bound of) postediting labor.", "labels": [], "entities": [{"text": "SMT", "start_pos": 86, "end_pos": 89, "type": "TASK", "confidence": 0.9833409190177917}]}, {"text": "There are three specific goals we need to achieve within this framework.", "labels": [], "entities": []}, {"text": "Firstly, the recommendation should have high precision, otherwise it would be confusing for post-editors and may negatively affect the lower bound of the postediting effort.", "labels": [], "entities": [{"text": "precision", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9988201260566711}]}, {"text": "Secondly, although we have full access to the SMT system used in this paper, our method should be able to generalize to cases where SMT is treated as a black-box, which is of-ten the casein the translation industry.", "labels": [], "entities": [{"text": "SMT", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9835973381996155}, {"text": "SMT", "start_pos": 132, "end_pos": 135, "type": "TASK", "confidence": 0.9591524004936218}]}, {"text": "Finally, post-editors should be able to easily adjust the recommendation threshold to particular requirements without having to retrain the model.", "labels": [], "entities": []}, {"text": "In our framework, we recast translation recommendation as a binary classification (rather than regression) problem using SVMs, perform RBF kernel parameter optimization, employ posterior probability-based confidence estimation to support user-based tuning for precision and recall, experiment with feature sets involving MT-, TM-and system-independent features, and use automatic MT evaluation metrics to simulate post-editing effort.", "labels": [], "entities": [{"text": "translation recommendation", "start_pos": 28, "end_pos": 54, "type": "TASK", "confidence": 0.9078344106674194}, {"text": "RBF kernel parameter optimization", "start_pos": 135, "end_pos": 168, "type": "TASK", "confidence": 0.6289523839950562}, {"text": "posterior probability-based confidence estimation", "start_pos": 177, "end_pos": 226, "type": "METRIC", "confidence": 0.7480955719947815}, {"text": "precision", "start_pos": 260, "end_pos": 269, "type": "METRIC", "confidence": 0.9959755539894104}, {"text": "recall", "start_pos": 274, "end_pos": 280, "type": "METRIC", "confidence": 0.986806333065033}, {"text": "MT evaluation", "start_pos": 380, "end_pos": 393, "type": "TASK", "confidence": 0.8727162480354309}]}, {"text": "The rest of the paper is organized as follows: we first briefly introduce related research in Section 2, and review the classification SVMs in Section 3.", "labels": [], "entities": []}, {"text": "We formulate the classification model in Section 4 and present experiments in Section 5.", "labels": [], "entities": []}, {"text": "In Section 6, we analyze the post-editing effort approximated by the TER metric ().", "labels": [], "entities": [{"text": "TER metric", "start_pos": 69, "end_pos": 79, "type": "METRIC", "confidence": 0.9696495831012726}]}, {"text": "Section 7 concludes the paper and points out avenues for future research.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our raw data set is an English-French translation memory with technical translation from Symantec, consisting of 51K sentence pairs.", "labels": [], "entities": []}, {"text": "We randomly selected 43K to train an SMT system and translated the English side of the remaining 8K sentence pairs.", "labels": [], "entities": [{"text": "SMT", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9917902946472168}]}, {"text": "The average sentence length of the training set is 13.5 words and the size of the training set is comparable to the (larger) TMs used in the industry.", "labels": [], "entities": []}, {"text": "Note that we remove the exact matches in the TM from our dataset, because exact matches will be reused and not presented to the post-editor in atypical TM setting.", "labels": [], "entities": []}, {"text": "As for the SMT system, we use a standard log-linear PB-SMT model): GIZA++ implementation of IBM word alignment model 4, 1 the refinement and phraseextraction heuristics described in (, minimum-error-rate training, a 5-gram language model with Kneser-Ney smoothing) trained with SRILM) on the English side of the training data, and Moses () to decode.", "labels": [], "entities": [{"text": "SMT", "start_pos": 11, "end_pos": 14, "type": "TASK", "confidence": 0.9932085871696472}, {"text": "IBM word alignment", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.6046044627825419}]}, {"text": "We train a system in the opposite direction using the same data to produce the pseudosource sentences.", "labels": [], "entities": []}, {"text": "We train the SVM classifier using the lib-SVM () toolkit.", "labels": [], "entities": [{"text": "SVM classifier", "start_pos": 13, "end_pos": 27, "type": "TASK", "confidence": 0.607046902179718}]}, {"text": "The SVMtraining and testing is performed on the remaining 8K sentences with 4-fold cross validation.", "labels": [], "entities": []}, {"text": "We also report 95% confidence intervals.", "labels": [], "entities": [{"text": "confidence intervals", "start_pos": 19, "end_pos": 39, "type": "METRIC", "confidence": 0.9390961527824402}]}, {"text": "The SVM hyper-parameters are tuned using the training data of the first fold in the 4-fold cross validation via a brute force grid search.", "labels": [], "entities": []}, {"text": "More specifically, for parameter C in (1) we search in the range [2 \u22125 , 2 15 ], and for parameter \u03b3 (2) we search in the range [2 \u221215 , 2 3 ].", "labels": [], "entities": []}, {"text": "The step size is 2 on the exponent.", "labels": [], "entities": []}, {"text": "We measure the quality of the classification by precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 48, "end_pos": 57, "type": "METRIC", "confidence": 0.999677300453186}, {"text": "recall", "start_pos": 62, "end_pos": 68, "type": "METRIC", "confidence": 0.999121367931366}]}, {"text": "Let Abe the set of recommended MT outputs, and B be the set of MT outputs that have lower TER than TM hits.", "labels": [], "entities": [{"text": "MT", "start_pos": 31, "end_pos": 33, "type": "TASK", "confidence": 0.9728156924247742}, {"text": "TER", "start_pos": 90, "end_pos": 93, "type": "METRIC", "confidence": 0.9978172779083252}]}, {"text": "We standardly define precision P , recall Rand F-value as in:  Evaluation with human post-editors is crucial to validate and improve translation recommendation.", "labels": [], "entities": [{"text": "precision P", "start_pos": 21, "end_pos": 32, "type": "METRIC", "confidence": 0.9379307627677917}, {"text": "recall Rand F-value", "start_pos": 35, "end_pos": 54, "type": "METRIC", "confidence": 0.8378894329071045}, {"text": "translation recommendation", "start_pos": 133, "end_pos": 159, "type": "TASK", "confidence": 0.9571372866630554}]}, {"text": "There are two possible avenues to pursue: \u2022 Test our system on professional post-editors.", "labels": [], "entities": []}, {"text": "By providing them with the TM output, the MT output and the one recommended to edit, we can measure the true accuracy of our recommendation, as well as the post-editing time we save for the post-editors; \u2022 Apply the presented method on open domain data and evaluate it using crowdsourcing.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 109, "end_pos": 117, "type": "METRIC", "confidence": 0.9966291785240173}]}, {"text": "It has been shown that crowdsourcing tools, such as the Amazon Mechanical Turk), can help developers to obtain good human judgements on MT output quality both cheaply and quickly.", "labels": [], "entities": [{"text": "MT output", "start_pos": 136, "end_pos": 145, "type": "TASK", "confidence": 0.890434056520462}]}, {"text": "Given that our problem is related to MT quality estimation in nature, it can potentially benefit from such tools as well.", "labels": [], "entities": [{"text": "MT quality estimation", "start_pos": 37, "end_pos": 58, "type": "TASK", "confidence": 0.8843508362770081}]}], "tableCaptions": [{"text": " Table 1: Recommendation Results  Precision  Recall  F-Score  SYS 82.53\u00b11.17 96.44\u00b10.68 88.95\u00b1.56  SI  82.56\u00b11.46 95.83\u00b10.52 88.70\u00b1.65  ALL 83.45\u00b11.33 95.56\u00b11.33 89.09\u00b1.24", "labels": [], "entities": [{"text": "Recommendation", "start_pos": 10, "end_pos": 24, "type": "METRIC", "confidence": 0.9054893255233765}, {"text": "Precision  Recall  F-Score  SYS 82.53\u00b11.17", "start_pos": 34, "end_pos": 76, "type": "METRIC", "confidence": 0.5730181421552386}, {"text": "ALL", "start_pos": 136, "end_pos": 139, "type": "METRIC", "confidence": 0.8311988711357117}]}, {"text": " Table 2: Classifier margins  Precision  Recall  TER+0  83.45\u00b11.33 95.56\u00b11.33  TER+0.05 82.41\u00b11.23 94.41\u00b11.01  TER+0.10 84.53\u00b10.98 88.81\u00b10.89  TER+0.15 85.24\u00b10.91 87.08\u00b12.38  TER+0.20 87.59\u00b10.57 75.86\u00b12.70  TER+0.25 89.29\u00b10.93 66.67\u00b12.53", "labels": [], "entities": [{"text": "Precision  Recall  TER+0  83.45\u00b11.33 95.56\u00b11.33  TER+0.05 82.41\u00b11.23 94.41\u00b11.01  TER+0.10 84.53\u00b10.98 88.81\u00b10.89  TER+0.15", "start_pos": 30, "end_pos": 151, "type": "METRIC", "confidence": 0.8553325179964304}]}, {"text": " Table 4: Contribution of Features  Precision  Recall  F Score  SYS  82.53\u00b11.17 96.44\u00b10.68 88.95\u00b1.56  +M1 82.87\u00b11.26 96.23\u00b10.53 89.05\u00b1.52  +LM 82.82\u00b11.16 96.20\u00b11.14 89.01\u00b1.23  +PS  83.21\u00b11.33 96.61\u00b10.44 89.41\u00b1.84", "labels": [], "entities": [{"text": "Contribution", "start_pos": 10, "end_pos": 22, "type": "METRIC", "confidence": 0.9208744168281555}, {"text": "Precision  Recall  F Score", "start_pos": 36, "end_pos": 62, "type": "METRIC", "confidence": 0.7187346816062927}, {"text": "SYS", "start_pos": 64, "end_pos": 67, "type": "DATASET", "confidence": 0.4973376393318176}]}, {"text": " Table 5: Edit Statistics when Recommending MT Outputs in Classification, confidence=0.5  Insertion  Substitution  Deletion  Shift  MT 0.9849 \u00b1 0.0408 2.2881 \u00b1 0.0672 0.8686 \u00b1 0.0370 1.2500 \u00b1 0.0598  TM 0.7762 \u00b1 0.0408 4.5841 \u00b1 0.1036 3.1567 \u00b1 0.1120 1.2096 \u00b1 0.0554", "labels": [], "entities": [{"text": "MT", "start_pos": 44, "end_pos": 46, "type": "TASK", "confidence": 0.9648791551589966}, {"text": "confidence", "start_pos": 74, "end_pos": 84, "type": "METRIC", "confidence": 0.9603604078292847}]}, {"text": " Table 6: Edit Statistics when NOT Recommending MT Outputs in Classification, confidence=0.5  Insertion  Substitution  Deletion  Shift  MT 1.0830 \u00b1 0.1167 2.2885 \u00b1 0.1376 1.0964 \u00b1 0.1137 1.5381 \u00b1 0.1962  TM 0.7554 \u00b1 0.0376 1.5527 \u00b1 0.1584 1.0090 \u00b1 0.1850 0.4731 \u00b1 0.1083", "labels": [], "entities": [{"text": "MT", "start_pos": 48, "end_pos": 50, "type": "TASK", "confidence": 0.9564067125320435}, {"text": "confidence", "start_pos": 78, "end_pos": 88, "type": "METRIC", "confidence": 0.9770897626876831}]}, {"text": " Table 7: Edit Statistics when Recommending MT Outputs in Classification, confidence=0.85  Insertion  Substitution  Deletion  Shift  MT 1.1665 \u00b1 0.0615 2.7334 \u00b1 0.0969 1.0277 \u00b1 0.0544 1.5549 \u00b1 0.0899  TM 0.8894 \u00b1 0.0594 6.0085 \u00b1 0.1501 4.1770 \u00b1 0.1719 1.6727 \u00b1 0.0846", "labels": [], "entities": [{"text": "Edit", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9451983571052551}, {"text": "MT", "start_pos": 44, "end_pos": 46, "type": "TASK", "confidence": 0.973473846912384}, {"text": "confidence", "start_pos": 74, "end_pos": 84, "type": "METRIC", "confidence": 0.9682254195213318}]}]}