{"title": [{"text": "A study of Information Retrieval weighting schemes for sentiment analysis", "labels": [], "entities": [{"text": "Information Retrieval weighting", "start_pos": 11, "end_pos": 42, "type": "TASK", "confidence": 0.8672864238421122}, {"text": "sentiment analysis", "start_pos": 55, "end_pos": 73, "type": "TASK", "confidence": 0.975123792886734}]}], "abstractContent": [{"text": "Most sentiment analysis approaches use as baseline a support vector machines (SVM) classifier with binary unigram weights.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 5, "end_pos": 23, "type": "TASK", "confidence": 0.9455592632293701}]}, {"text": "In this paper, we explore whether more sophisticated feature weighting schemes from Information Retrieval can enhance classification accuracy.", "labels": [], "entities": [{"text": "classification", "start_pos": 118, "end_pos": 132, "type": "TASK", "confidence": 0.9627996683120728}, {"text": "accuracy", "start_pos": 133, "end_pos": 141, "type": "METRIC", "confidence": 0.7278094291687012}]}, {"text": "We show that variants of the classic tf.idf scheme adapted to sentiment analysis provide significant increases inaccuracy, especially when using a sublinear function for term frequency weights and document frequency smoothing.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 62, "end_pos": 80, "type": "TASK", "confidence": 0.9484087526798248}, {"text": "document frequency smoothing", "start_pos": 197, "end_pos": 225, "type": "TASK", "confidence": 0.5688986877600352}]}, {"text": "The techniques are tested on a wide selection of data sets and produce the best accuracy to our knowledge.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9991279244422913}]}], "introductionContent": [{"text": "The increase of user-generated content on the web in the form of reviews, blogs, social networks, tweets, fora, etc. has resulted in an environment where everyone can publicly express their opinion about events, products or people.", "labels": [], "entities": []}, {"text": "This wealth of information is potentially of vital importance to institutions and companies, providing them with ways to research their consumers, manage their reputations and identify new opportunities.", "labels": [], "entities": []}, {"text": "claims that \"for many businesses, online opinion has turned into a kind of virtual currency that can make or break a product in the marketplace\".", "labels": [], "entities": []}, {"text": "Sentiment analysis, also known as opinion mining, provides mechanisms and techniques through which this vast amount of information can be processed and harnessed.", "labels": [], "entities": [{"text": "Sentiment analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.9467849135398865}, {"text": "opinion mining", "start_pos": 34, "end_pos": 48, "type": "TASK", "confidence": 0.8349281251430511}]}, {"text": "Research in the field has mainly, but not exclusively, focused in two subproblems: detecting whether a segment of text, either a whole document or a sentence, is subjective or objective, i.e. contains an expression of opinion, and detecting the overall polarity of the text, i.e. positive or negative.", "labels": [], "entities": [{"text": "detecting whether a segment of text, either a whole document or a sentence", "start_pos": 83, "end_pos": 157, "type": "TASK", "confidence": 0.6280137896537781}]}, {"text": "Most of the work in sentiment analysis has focused on supervised learning techniques), although there are some notable exceptions.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 20, "end_pos": 38, "type": "TASK", "confidence": 0.9773812592029572}]}, {"text": "Previous research has shown that in general the performance of the former tend to be superior to that of the latter (.", "labels": [], "entities": []}, {"text": "One of the main issues for supervised approaches has been the representation of documents.", "labels": [], "entities": [{"text": "representation of documents", "start_pos": 62, "end_pos": 89, "type": "TASK", "confidence": 0.8534924785296122}]}, {"text": "Usually a bag of words representation is adopted, according to which a document is modeled as an unordered collection of the words that it contains.", "labels": [], "entities": []}, {"text": "Early research by in sentiment analysis showed that a binary unigrambased representation of documents, according to which a document is modeled only by the presence or absence of words, provides the best baseline classification accuracy in sentiment analysis in comparison to other more intricate representations using bigrams, adjectives, etc.", "labels": [], "entities": [{"text": "in sentiment analysis", "start_pos": 18, "end_pos": 39, "type": "TASK", "confidence": 0.6820853352546692}, {"text": "accuracy", "start_pos": 228, "end_pos": 236, "type": "METRIC", "confidence": 0.9766415953636169}, {"text": "sentiment analysis", "start_pos": 240, "end_pos": 258, "type": "TASK", "confidence": 0.8973698019981384}]}, {"text": "Later research has focused on extending the document representation with more complex features such as structural or syntactic information (), favorability measures from diverse sources (), implicit syntactic indicators (), stylistic and syntactic feature selection (, \"annotator rationales\" () and others, but no systematic study has been presented exploring the benefits of employing more sophisticated models for assigning weights to word features.", "labels": [], "entities": [{"text": "syntactic feature selection", "start_pos": 238, "end_pos": 265, "type": "TASK", "confidence": 0.619052936633428}]}, {"text": "In this paper, we examine whether term weighting functions adopted from Information Retrieval (IR) based on the standard tf.idf formula and adapted to the particular setting of sentiment analysis can help classification accuracy.", "labels": [], "entities": [{"text": "Information Retrieval (IR)", "start_pos": 72, "end_pos": 98, "type": "TASK", "confidence": 0.7802578568458557}, {"text": "sentiment analysis", "start_pos": 177, "end_pos": 195, "type": "TASK", "confidence": 0.9247789978981018}, {"text": "classification", "start_pos": 205, "end_pos": 219, "type": "TASK", "confidence": 0.9570549726486206}, {"text": "accuracy", "start_pos": 220, "end_pos": 228, "type": "METRIC", "confidence": 0.8254369497299194}]}, {"text": "We demonstrate that variants of the original tf.idf weighting scheme provide significant increases in classification performance.", "labels": [], "entities": []}, {"text": "The advantages of the approach are that it is intuitive, computationally efficient and doesn't require additional human annotation or external sources.", "labels": [], "entities": []}, {"text": "Experiments conducted on a number of publicly available data sets improve on the previous state-of-the art.", "labels": [], "entities": []}, {"text": "The next section provides an overview of relevant work in sentiment analysis.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 58, "end_pos": 76, "type": "TASK", "confidence": 0.9669877290725708}]}, {"text": "In section 3 we provide a brief overview of the original tf.idf weighting scheme along with a number of variants and show how they can be applied to a classification scenario.", "labels": [], "entities": []}, {"text": "Section 4 describes the corpora that were used to test the proposed weighting schemes and section 5 discusses the results.", "labels": [], "entities": []}, {"text": "Finally, we conclude and propose future work in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have experimented with a number of publicly available data sets.", "labels": [], "entities": []}, {"text": "The movie review dataset by has been used extensively in the past by a number of researchers (see), presenting the opportunity to compare the produced results with previous approaches.", "labels": [], "entities": [{"text": "movie review dataset", "start_pos": 4, "end_pos": 24, "type": "DATASET", "confidence": 0.72727898756663}]}, {"text": "The dataset comprises 2,000 movie reviews, equally divided between positive and negative, extracted from the Internet Movie Database 3 archive of the rec.arts.movies.reviews newsgroup.", "labels": [], "entities": [{"text": "Internet Movie Database 3 archive of the rec.arts.movies.reviews newsgroup", "start_pos": 109, "end_pos": 183, "type": "DATASET", "confidence": 0.844747006893158}]}, {"text": "In order to avoid reviewer bias, only 20 reviews per author were kept, resulting in a total of 312 reviewers . The best attained accuracies by previous research on the specific data are presented in table 4.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 129, "end_pos": 139, "type": "METRIC", "confidence": 0.9760420322418213}]}, {"text": "We do not claim that those results are directly comparable to ours, because of potential subtle differences in tokenization, classifier implementations etc, but we present them here for reference.", "labels": [], "entities": []}, {"text": "The Multi-Domain Sentiment data set (MDSD) by contains Amazon reviews for four different product types: books, electronics, DVDs and kitchen appliances.", "labels": [], "entities": [{"text": "Multi-Domain Sentiment data set (MDSD)", "start_pos": 4, "end_pos": 42, "type": "DATASET", "confidence": 0.7619722017220089}]}, {"text": "Reviews with ratings of 3 or higher, on a 5-scale system, were labeled as positive and reviews with a rating less than 3 as negative.", "labels": [], "entities": []}, {"text": "The data set contains 1,000 positive and 1,000 negative reviews for each product category fora total of 8,000 reviews.", "labels": [], "entities": []}, {"text": "Typically, the data set is used for domain adaptation applications but in our setting we only split the reviews between positive and negative 5 . Lastly, we present results from the BLOGS06 () collection that is comprised of an uncompressed 148GB crawl of approximately 100,000 blogs and their respective RSS feeds.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 36, "end_pos": 53, "type": "TASK", "confidence": 0.783756822347641}, {"text": "BLOGS06 () collection", "start_pos": 182, "end_pos": 203, "type": "DATASET", "confidence": 0.6860167980194092}]}, {"text": "The collection has been used for 3 consecutive years by the Text REtrieval Conferences (TREC) . Participants of the conference are provided with the task of finding documents (i.e. web pages) expressing an opinion about specific enti-ties X, which maybe people, companies, films etc.", "labels": [], "entities": [{"text": "Text REtrieval Conferences (TREC)", "start_pos": 60, "end_pos": 93, "type": "TASK", "confidence": 0.7900076806545258}]}, {"text": "The results are given to human assessors who then judge the content of the webpages (i.e. blog post and comments) and assign each webpage a score: \"1\" if the document contains relevant, factual information about the entity but no expression of opinion, \"2\" if the document contains an explicit negative opinion towards the entity and \"4\" is the document contains an explicit positive opinion towards the entity.", "labels": [], "entities": []}, {"text": "We used the produced assessments from all 3 years of the conference in our data set, resulting in 150 different entity searches and, after duplicate removal, 7,930 negative documents (i.e. having an assessment of \"2\") and 9,968 positive documents (i.e. having an assessment of \"4\"), which were used as the \"gold standard\" 7 . Documents are annotated at the document-level, rather than at the post level, making this data set somewhat noisy.", "labels": [], "entities": []}, {"text": "Additionally, the data set is particularly large compared to the other ones, making classification especially challenging and interesting.", "labels": [], "entities": [{"text": "classification", "start_pos": 84, "end_pos": 98, "type": "TASK", "confidence": 0.9664293527603149}]}, {"text": "More information about all data sets can be found at table 5.", "labels": [], "entities": []}, {"text": "We have kept the pre-processing of the documents to a minimum.", "labels": [], "entities": []}, {"text": "Thus, we have lower-cased all words and removed all punctuation but we have not removed stop words or applied stemming.", "labels": [], "entities": []}, {"text": "We have also refrained from removing words with low or high occurrence.", "labels": [], "entities": [{"text": "occurrence", "start_pos": 60, "end_pos": 70, "type": "METRIC", "confidence": 0.9741544723510742}]}, {"text": "Additionally, for the BLOGS06 data set, we have removed all html formatting.", "labels": [], "entities": [{"text": "BLOGS06 data set", "start_pos": 22, "end_pos": 38, "type": "DATASET", "confidence": 0.9820156097412109}]}, {"text": "We utilize the implementation of a support vector classifier from the LIBLINEAR library.", "labels": [], "entities": [{"text": "LIBLINEAR library", "start_pos": 70, "end_pos": 87, "type": "DATASET", "confidence": 0.8138958811759949}]}, {"text": "We use a linear kernel and default parameters.", "labels": [], "entities": []}, {"text": "All results are based on leave-one out cross validation accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 56, "end_pos": 64, "type": "METRIC", "confidence": 0.9800452589988708}]}, {"text": "The reason for this choice of cross-validation setting, instead of the most standard ten-fold, is that all of the proposed approaches that use some form of idf utilize the training documents for extracting document frequency statistics, therefore more information is available to them in this experimental setting.", "labels": [], "entities": []}, {"text": "Because of the high number of possible combinations between tf and idf variants (6\u00b79\u00b72 = 108) and due to space constraints we only present results from a subset of the most representative combinations.", "labels": [], "entities": []}, {"text": "Generally, we'll use the cosine normalized variants of unsmoothed delta weighting schemes, since they perform better than their un-  normalized counterparts.", "labels": [], "entities": []}, {"text": "We'll avoid using normalization for the smoothed versions, in order to focus our attention on the results of smoothing, rather than normalization.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: SMART normalization.  Notation  Normalization  n (none)  1  c (cosine)", "labels": [], "entities": [{"text": "SMART normalization", "start_pos": 10, "end_pos": 29, "type": "TASK", "confidence": 0.8873753845691681}]}, {"text": " Table 5: Statistics about the data sets used.  Data set  #Documents #Terms  #Unique  Terms", "labels": [], "entities": []}]}