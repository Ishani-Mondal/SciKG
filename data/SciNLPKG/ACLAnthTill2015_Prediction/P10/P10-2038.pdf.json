{"title": [{"text": "Simple semi-supervised training of part-of-speech taggers", "labels": [], "entities": [{"text": "part-of-speech taggers", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.7483498454093933}]}], "abstractContent": [{"text": "Most attempts to train part-of-speech tag-gers on a mixture of labeled and unlabeled data have failed.", "labels": [], "entities": []}, {"text": "In this work stacked learning is used to reduce tagging to a classification task.", "labels": [], "entities": []}, {"text": "This simplifies semi-supervised training considerably.", "labels": [], "entities": []}, {"text": "Our prefered semi-supervised method combines tri-training (Li and Zhou, 2005) and disagreement-based co-training.", "labels": [], "entities": []}, {"text": "On the Wall Street Journal, we obtain an error reduction of 4.2% with SVMTool (Gimenez and Marquez, 2004).", "labels": [], "entities": [{"text": "Wall Street Journal", "start_pos": 7, "end_pos": 26, "type": "DATASET", "confidence": 0.9756548206011454}, {"text": "error reduction", "start_pos": 41, "end_pos": 56, "type": "METRIC", "confidence": 0.9800725281238556}]}], "introductionContent": [{"text": "Semi-supervised part-of-speech (POS) tagging is relatively rare, and the main reason seems to be that results have mostly been negative., in a now famous negative result, attempted to improve HMM POS tagging by expectation maximization with unlabeled data.", "labels": [], "entities": [{"text": "Semi-supervised part-of-speech (POS) tagging", "start_pos": 0, "end_pos": 44, "type": "TASK", "confidence": 0.5797275503476461}, {"text": "HMM POS tagging", "start_pos": 192, "end_pos": 207, "type": "TASK", "confidence": 0.7852214376131693}]}, {"text": "reported positive results with little labeled training data but negative results when the amount of labeled training data increased; the same seems to be the casein who use co-training of two diverse POS taggers.", "labels": [], "entities": [{"text": "POS taggers", "start_pos": 200, "end_pos": 211, "type": "TASK", "confidence": 0.7551780045032501}]}, {"text": "present positive results for self-training a simple bigram POS tagger, but results are considerably below state-of-the-art.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 59, "end_pos": 69, "type": "TASK", "confidence": 0.6670339107513428}]}, {"text": "Recently researchers have explored alternative methods.", "labels": [], "entities": []}, {"text": "introduce a semi-supervised extension of conditional random fields that combines supervised and unsupervised probability models by so-called MDF parameter estimation, which reduces error on Wall Street Journal (WSJ) standard splits by about 7% relative to their supervised baseline.", "labels": [], "entities": [{"text": "error", "start_pos": 181, "end_pos": 186, "type": "METRIC", "confidence": 0.9732679128646851}, {"text": "Wall Street Journal (WSJ) standard splits", "start_pos": 190, "end_pos": 231, "type": "DATASET", "confidence": 0.9387529566884041}]}, {"text": "use anew pool of unlabeled data tagged by an ensemble of state-of-the-art taggers in every training step of an averaged perceptron POS tagger with 4-5% error reduction.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 152, "end_pos": 167, "type": "METRIC", "confidence": 0.9417416155338287}]}, {"text": "Finally, S\u00f8gaard (2009) stacks a POS tagger on an unsupervised clustering algorithm trained on large amounts of unlabeled data with mixed results.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 33, "end_pos": 43, "type": "TASK", "confidence": 0.7133808434009552}]}, {"text": "This work combines anew semi-supervised learning method to POS tagging, namely tritraining (, with stacking on unsupervised clustering.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 59, "end_pos": 70, "type": "TASK", "confidence": 0.6874937117099762}]}, {"text": "It is shown that this method can be used to improve a state-of-the-art POS tagger, SVMTool ().", "labels": [], "entities": []}, {"text": "Finally, we introduce a variant of tri-training called tri-training with disagreement, which seems to perform equally well, but which imports much less unlabeled data and is therefore more efficient.", "labels": [], "entities": []}], "datasetContent": [{"text": "SVMTool is one of the most accurate POS taggers available.", "labels": [], "entities": [{"text": "SVMTool", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9520899057388306}, {"text": "POS taggers", "start_pos": 36, "end_pos": 47, "type": "TASK", "confidence": 0.7491650879383087}]}, {"text": "This means that the predictions that are added to the labeled data are of very high quality.", "labels": [], "entities": []}, {"text": "To test if our semi-supervised learning methods were sensitive to the quality of the input taggers we repeated the self-training and tri-training experiments with a less competitive POS tagger, namely the maximum entropy-based POS tagger first described in that comes with the maximum entropy library in).", "labels": [], "entities": []}, {"text": "Results are presented as the second line in.", "labels": [], "entities": []}, {"text": "Note that error reduction is much lower in this case.", "labels": [], "entities": [{"text": "error reduction", "start_pos": 10, "end_pos": 25, "type": "METRIC", "confidence": 0.8992904126644135}]}], "tableCaptions": []}