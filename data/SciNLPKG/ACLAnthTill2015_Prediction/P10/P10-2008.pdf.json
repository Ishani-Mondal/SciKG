{"title": [{"text": "Authorship Attribution Using Probabilistic Context-Free Grammars", "labels": [], "entities": [{"text": "Authorship Attribution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6860362738370895}]}], "abstractContent": [{"text": "In this paper, we present a novel approach for authorship attribution, the task of identifying the author of a document, using probabilistic context-free grammars.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 47, "end_pos": 69, "type": "TASK", "confidence": 0.8011471331119537}]}, {"text": "Our approach involves building a probabilistic context-free grammar for each author and using this grammar as a language model for classification.", "labels": [], "entities": []}, {"text": "We evaluate the performance of our method on a wide range of datasets to demonstrate its efficacy.", "labels": [], "entities": []}], "introductionContent": [{"text": "Natural language processing allows us to build language models, and these models can be used to distinguish between languages.", "labels": [], "entities": []}, {"text": "In the context of written text, such as newspaper articles or short stories, the author's style could be considered a distinct \"language.\"", "labels": [], "entities": []}, {"text": "Authorship attribution, also referred to as authorship identification or prediction, studies strategies for discriminating between the styles of different authors.", "labels": [], "entities": [{"text": "Authorship attribution", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.7546748220920563}, {"text": "authorship identification or prediction", "start_pos": 44, "end_pos": 83, "type": "TASK", "confidence": 0.8128567412495613}]}, {"text": "These strategies have numerous applications, including settling disputes regarding the authorship of old and historically important documents, automatic plagiarism detection, determination of document authenticity in court (), cyber crime investigation (, and forensics.", "labels": [], "entities": [{"text": "automatic plagiarism detection", "start_pos": 143, "end_pos": 173, "type": "TASK", "confidence": 0.5698901613553365}, {"text": "determination of document authenticity in court", "start_pos": 175, "end_pos": 222, "type": "TASK", "confidence": 0.8102549910545349}, {"text": "cyber crime investigation", "start_pos": 227, "end_pos": 252, "type": "TASK", "confidence": 0.7145363291104635}]}, {"text": "The general approach to authorship attribution is to extract a number of style markers from the text and use these style markers as features to train a classifier.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.7155427634716034}]}, {"text": "These style markers could include the frequencies of certain characters, function words, phrases or sentences.", "labels": [], "entities": []}, {"text": "build a character-level n-gram model for each author. and use a combination of word-level statistics and part-of-speech counts or n-grams.", "labels": [], "entities": []}, {"text": "demonstrate that the use of syntactic features from parse trees can improve the accuracy of authorship attribution.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 80, "end_pos": 88, "type": "METRIC", "confidence": 0.9984489679336548}]}, {"text": "While there have been several approaches proposed for authorship attribution, it is not clear if the performance of one is better than the other.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 54, "end_pos": 76, "type": "TASK", "confidence": 0.931679904460907}]}, {"text": "Further, it is difficult to compare the performance of these algorithms because they were primarily evaluated on different datasets.", "labels": [], "entities": []}, {"text": "For more information on the current state of the art for authorship attribution, we refer the reader to a detailed survey by.", "labels": [], "entities": [{"text": "authorship attribution", "start_pos": 57, "end_pos": 79, "type": "TASK", "confidence": 0.8511818945407867}]}, {"text": "We further investigate the use of syntactic information by building complete models of each author's syntax to distinguish between authors.", "labels": [], "entities": []}, {"text": "Our approach involves building a probabilistic contextfree grammar (PCFG) for each author and using this grammar as a language model for classification.", "labels": [], "entities": []}, {"text": "Experiments on a variety of corpora including poetry and newspaper articles on a number of topics demonstrate that our PCFG approach performs fairly well, but it only outperforms a bigram language model on a couple of datasets (e.g. poetry).", "labels": [], "entities": []}, {"text": "However, combining our approach with other methods results in an ensemble that performs the best on most datasets.", "labels": [], "entities": []}], "datasetContent": [{"text": "This section describes experiments evaluating our approach on several real-world datasets.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Statistics for the training datasets used in  our experiments. The numbers in columns 3, 4 and  5 are averages.", "labels": [], "entities": []}, {"text": " Table 2: Accuracy in % for authorship prediction on different datasets. Bigram-I refers to the bigram  language model with smoothing. PCFG-E refers to the ensemble based on MaxEnt, Bigram-I, and  PCFG-I. MaxEnt+Bigram-I refers to the ensemble based on MaxEnt and Bigram-I.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9914757013320923}, {"text": "authorship prediction", "start_pos": 28, "end_pos": 49, "type": "TASK", "confidence": 0.9016976952552795}, {"text": "PCFG-I", "start_pos": 197, "end_pos": 203, "type": "DATASET", "confidence": 0.9391530752182007}]}]}