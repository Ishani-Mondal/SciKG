{"title": [{"text": "Efficient Optimization of an MDL-Inspired Objective Function for Unsupervised Part-of-Speech Tagging", "labels": [], "entities": [{"text": "Part-of-Speech Tagging", "start_pos": 78, "end_pos": 100, "type": "TASK", "confidence": 0.699466198682785}]}], "abstractContent": [{"text": "The Minimum Description Length (MDL) principle is a method for model selection that trades off between the explanation of the data by the model and the complexity of the model itself.", "labels": [], "entities": [{"text": "Minimum Description Length (MDL)", "start_pos": 4, "end_pos": 36, "type": "TASK", "confidence": 0.7024087111155192}, {"text": "model selection", "start_pos": 63, "end_pos": 78, "type": "TASK", "confidence": 0.7284846305847168}]}, {"text": "Inspired by the MDL principle, we develop an objective function for generative models that captures the description of the data by the model (log-likelihood) and the description of the model (model size).", "labels": [], "entities": []}, {"text": "We also develop a efficient general search algorithm based on the MAP-EM framework to optimize this function.", "labels": [], "entities": [{"text": "MAP-EM framework", "start_pos": 66, "end_pos": 82, "type": "DATASET", "confidence": 0.8728444874286652}]}, {"text": "Since recent work has shown that minimizing the model size in a Hidden Markov Model for part-of-speech (POS) tagging leads to higher accuracies, we test our approach by applying it to this problem.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging", "start_pos": 88, "end_pos": 116, "type": "TASK", "confidence": 0.6575279593467712}]}, {"text": "The search algorithm involves a simple change to EM and achieves high POS tagging accuracies on both English and Italian data sets.", "labels": [], "entities": [{"text": "EM", "start_pos": 49, "end_pos": 51, "type": "METRIC", "confidence": 0.6766867637634277}, {"text": "POS tagging accuracies", "start_pos": 70, "end_pos": 92, "type": "METRIC", "confidence": 0.7878089348475138}]}], "introductionContent": [{"text": "The Minimum Description Length (MDL) principle is a method for model selection that provides a generic solution to the overfitting problem (.", "labels": [], "entities": [{"text": "model selection", "start_pos": 63, "end_pos": 78, "type": "TASK", "confidence": 0.7069572806358337}]}, {"text": "A formalization of Ockham's Razor, it says that the parameters are to be chosen that minimize the description length of the data given the model plus the description length of the model itself.", "labels": [], "entities": [{"text": "Ockham's Razor", "start_pos": 19, "end_pos": 33, "type": "TASK", "confidence": 0.59665447473526}]}, {"text": "It has been successfully shown that minimizing the model size in a Hidden Markov Model (HMM) for part-of-speech (POS) tagging leads to higher accuracies than simply running the ExpectationMaximization (EM) algorithm.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging", "start_pos": 97, "end_pos": 125, "type": "TASK", "confidence": 0.6512749552726745}]}, {"text": "employ a Bayesian approach to POS tagging and use sparse Dirichlet priors to minimize model size.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 30, "end_pos": 41, "type": "TASK", "confidence": 0.9011768698692322}]}, {"text": "More recently, alternately minimize the model using an integer linear program and maximize likelihood using EM to achieve the highest accuracies on the task so far.", "labels": [], "entities": [{"text": "likelihood", "start_pos": 91, "end_pos": 101, "type": "METRIC", "confidence": 0.9512490630149841}, {"text": "EM", "start_pos": 108, "end_pos": 110, "type": "METRIC", "confidence": 0.825729489326477}, {"text": "accuracies", "start_pos": 134, "end_pos": 144, "type": "METRIC", "confidence": 0.9780314564704895}]}, {"text": "However, in the latter approach, because there is no single objective function to optimize, it is not entirely clear how to generalize this technique to other problems.", "labels": [], "entities": []}, {"text": "In this paper, inspired by the MDL principle, we develop an objective function for generative models that captures both the description of the data by the model (log-likelihood) and the description of the model (model size).", "labels": [], "entities": []}, {"text": "By using a simple prior that encourages sparsity, we cast our problem as a search for the maximum a posteriori (MAP) hypothesis and present a variant of EM to approximately search for the minimumdescription-length model.", "labels": [], "entities": []}, {"text": "Applying our approach to the POS tagging problem, we obtain higher accuracies than both EM and Bayesian inference as reported by.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 29, "end_pos": 40, "type": "TASK", "confidence": 0.8468480408191681}, {"text": "accuracies", "start_pos": 67, "end_pos": 77, "type": "METRIC", "confidence": 0.9622113704681396}]}, {"text": "On a Italian POS tagging task, we obtain even larger improvements.", "labels": [], "entities": [{"text": "POS tagging task", "start_pos": 13, "end_pos": 29, "type": "TASK", "confidence": 0.8109415173530579}]}, {"text": "We find that our objective function correlates well with accuracy, suggesting that this technique might be useful for other problems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9993817806243896}]}], "datasetContent": [{"text": "We carried out POS tagging experiments on English and Italian.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.9104911684989929}]}], "tableCaptions": [{"text": " Table 2: Average accuracies over three held-out sets for English.", "labels": [], "entities": [{"text": "Average", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9905751943588257}, {"text": "accuracies", "start_pos": 18, "end_pos": 28, "type": "METRIC", "confidence": 0.6883959174156189}, {"text": "English", "start_pos": 58, "end_pos": 65, "type": "DATASET", "confidence": 0.8823992609977722}]}, {"text": " Table 1: MAP-EM with a L0 norm achieves higher  tagging accuracy on English than (2007) and much  higher than standard EM.", "labels": [], "entities": [{"text": "tagging", "start_pos": 49, "end_pos": 56, "type": "TASK", "confidence": 0.9417569637298584}, {"text": "accuracy", "start_pos": 57, "end_pos": 65, "type": "METRIC", "confidence": 0.9614284038543701}]}, {"text": " Table 3: MAP-EM with a smoothed L0 norm  yields much smaller models than standard EM.", "labels": [], "entities": []}]}