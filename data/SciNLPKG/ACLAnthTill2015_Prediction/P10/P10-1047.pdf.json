{"title": [{"text": "Syntax-to-Morphology Mapping in Factored Phrase-Based Statistical Machine Translation from English to Turkish", "labels": [], "entities": [{"text": "Syntax-to-Morphology Mapping", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.8288553953170776}]}], "abstractContent": [{"text": "We present a novel scheme to apply fac-tored phrase-based SMT to a language pair with very disparate morphological structures.", "labels": [], "entities": [{"text": "SMT", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.8575639128684998}]}, {"text": "Our approach relies on syntactic analysis on the source side (English) and then encodes a wide variety of local and non-local syntactic structures as complex structural tags which appear as additional factors in the training data.", "labels": [], "entities": []}, {"text": "On the target side (Turkish), we only perform morphological analysis and disam-biguation but treat the complete complex morphological tag as a factor, instead of separating morphemes.", "labels": [], "entities": []}, {"text": "We incrementally explore capturing various syntactic sub-structures as complex tags on the En-glish side, and evaluate how our translations improve in BLEU scores.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 151, "end_pos": 155, "type": "METRIC", "confidence": 0.9980329871177673}]}, {"text": "Our maximal set of source and target side transformations , coupled with some additional techniques, provide an 39% relative improvement from a baseline 17.08 to 23.78 BLEU, all averaged over 10 training and test sets.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 168, "end_pos": 172, "type": "METRIC", "confidence": 0.9990136623382568}]}, {"text": "Now that the syntactic analysis on the English side is available, we also experiment with more long distance constituent reordering to bring the English constituent order close to Turkish, but find that these transformations do not provide any additional consistent tangible gains when averaged over the 10 sets.", "labels": [], "entities": []}], "introductionContent": [{"text": "Statistical machine translation into a morphologically complex language such as Turkish, Finnish or Arabic, involves the generation of target words with the proper morphology, in addition to properly ordering the target words.", "labels": [], "entities": [{"text": "Statistical machine translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7194507022698721}]}, {"text": "Earlier work on translation from English to Turkish has used an approach which relied on identifying the contextually correct parts-of-speech, roots and any morphemes on the English side, and the complete sequence of roots and overt derivational and inflectional morphemes for each word on the Turkish side.", "labels": [], "entities": [{"text": "translation from English to Turkish", "start_pos": 16, "end_pos": 51, "type": "TASK", "confidence": 0.8878005266189575}]}, {"text": "Once these were identified as separate tokens, they were then used as \"words\" in a standard phrase-based framework ().", "labels": [], "entities": []}, {"text": "They have reported that, given the typical complexity of Turkish words, there was a substantial percentage of words whose morphological structure was incorrect: either the morphemes were not applicable for the part-of-speech category of the root word selected, or the morphemes were in the wrong order.", "labels": [], "entities": []}, {"text": "The main reason given for these problems was that the same statistical translation, reordering and language modeling mechanisms were being employed to both determine the morphological structure of the words and, at the same time, get the global order of the words correct.", "labels": [], "entities": [{"text": "language modeling", "start_pos": 99, "end_pos": 116, "type": "TASK", "confidence": 0.7183602601289749}]}, {"text": "Even though a significant improvement of a standard word-based baseline was achieved, further analysis hinted at a direction where morphology and syntax on the Turkish side had to be dealt with using separate mechanisms.", "labels": [], "entities": []}, {"text": "Motivated by the observation that many local and some nonlocal syntactic structures in English essentially map to morphologically complex words in Turkish, we present a radically different approach which does not segment Turkish words into morphemes, but uses a representation equivalent to the full word form.", "labels": [], "entities": []}, {"text": "On the English side, we rely on a full syntactic analysis using a dependency parser.", "labels": [], "entities": []}, {"text": "This analysis then lets us abstract and encode many local and some nonlocal syntactic structures as complex tags (dynamically, as opposed to the static complex tags as proposed by  and).", "labels": [], "entities": []}, {"text": "Thus we can bring the representation of English syntax closer to the Turkish morphosyntax.", "labels": [], "entities": []}, {"text": "Such an approach enables the following: (i) Driven by the pattern of morphological structures of full word forms on the Turkish side represented as root words and complex tags, we can identify and reorganize phrases on the English side, to \"align\" English syntax to Turkish morphology wherever possible.", "labels": [], "entities": []}, {"text": "(ii) Continuous and discontinuous variants of certain (syntactic) phrases can be conflated during the SMT phrase extraction process.", "labels": [], "entities": [{"text": "SMT phrase extraction", "start_pos": 102, "end_pos": 123, "type": "TASK", "confidence": 0.9220539927482605}]}, {"text": "(iii) The length of the English sentences can be dramatically reduced, as most function words encoding syntax are now abstracted into complex tags.", "labels": [], "entities": []}, {"text": "(iv) The representation of both the source and the target sides of the parallel corpus can now be mostly normalized.", "labels": [], "entities": []}, {"text": "This facilitates the use of factored phrase-based translation that was not previously applicable due to the morphological complexity on the target side and mismatch between source and target morphologies.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 37, "end_pos": 61, "type": "TASK", "confidence": 0.7079215198755264}]}, {"text": "We find that with the full set of syntax-tomorphology transformations and some additional techniques we can get about 39% relative improvement in BLEU scores over a word-based baseline and about 28% improvement of a factored baseline, all experiments being done over 10 training and test sets.", "labels": [], "entities": [{"text": "BLEU scores", "start_pos": 146, "end_pos": 157, "type": "METRIC", "confidence": 0.9761959612369537}]}, {"text": "We also find that further constituent reordering taking advantage of the syntactic analysis of the source side, does not provide tangible improvements when averaged over the 10 data sets.", "labels": [], "entities": []}, {"text": "This paper is organized as follows: Section 2 presents the basic idea behind syntaxto-morphology alignment.", "labels": [], "entities": [{"text": "syntaxto-morphology alignment", "start_pos": 77, "end_pos": 106, "type": "TASK", "confidence": 0.7857675552368164}]}, {"text": "Section 3 describes our experimental set-up and presents results from a sequence of incremental syntax-to-morphology transformations, and additional techniques.", "labels": [], "entities": []}, {"text": "Section 4 summarizes our constituent reordering experiments and their results.", "labels": [], "entities": []}, {"text": "Section 5 presents a review of related work and situates our approach.", "labels": [], "entities": []}, {"text": "We assume that the reader is familiar with the basics of phrase-based statistical machine translation ( and factored statistical machine translation ( ).", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 57, "end_pos": 101, "type": "TASK", "confidence": 0.613635390996933}, {"text": "factored statistical machine translation", "start_pos": 108, "end_pos": 148, "type": "TASK", "confidence": 0.6276460289955139}]}], "datasetContent": [{"text": "We evaluated the impact of the transformations in factored phrase-based SMT with an EnglishTurkish data set which consists of 52712 parallel sentences.", "labels": [], "entities": [{"text": "SMT", "start_pos": 72, "end_pos": 75, "type": "TASK", "confidence": 0.7924711108207703}, {"text": "EnglishTurkish data set", "start_pos": 84, "end_pos": 107, "type": "DATASET", "confidence": 0.9430143237113953}]}, {"text": "In order to have more confidence in the impact of our transformations, we randomly generated 10 training, test and tune set combinations.", "labels": [], "entities": []}, {"text": "For each combination, the latter two were 1000 sentences each and the remaining 50712 sentences were used as training sets.", "labels": [], "entities": []}, {"text": "We performed our experiments with the Moses toolkit ( . In order to encourage long distance reordering in the decoder, we used a distortion limit of -1 and a distortion weight of -shows surface morpheme boundaries.", "labels": [], "entities": []}, {"text": "We could give two more examples of rules to process the if-clause in the example in.", "labels": [], "entities": []}, {"text": "These rules would be applied sequentially: The first rule recognizes the passive construction mediated by be+VB<AGR> forming a verb complex (VC) with <Y>+VB_VBN and appends the former to the complex tag on the latter and then deletes the former token.", "labels": [], "entities": []}, {"text": "The second rule then recognizes <X>+IN relating to <Y>+VB<TAGS>with VMOD and appends the former to the complex tag on the latter and then deletes the former token.", "labels": [], "entities": [{"text": "IN", "start_pos": 36, "end_pos": 38, "type": "METRIC", "confidence": 0.913460373878479}]}, {"text": "The tune set was not used in this work but reserved for future work so that meaningful comparisons could be made.", "labels": [], "entities": []}, {"text": "We did not use MERT to further optimize our model.", "labels": [], "entities": [{"text": "MERT", "start_pos": 15, "end_pos": 19, "type": "METRIC", "confidence": 0.5663972496986389}]}, {"text": "For evaluation, we used the BLEU metric).", "labels": [], "entities": [{"text": "BLEU metric", "start_pos": 28, "end_pos": 39, "type": "METRIC", "confidence": 0.9751809239387512}]}, {"text": "Each experiment was repeated over the 10 data sets.", "labels": [], "entities": []}, {"text": "Wherever meaningful, we report the average BLEU scores over 10 data sets along with the maximum and minimum values and the standard deviation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 43, "end_pos": 47, "type": "METRIC", "confidence": 0.9988709092140198}]}, {"text": "These allow and do not penalize unlimited distortions.", "labels": [], "entities": []}, {"text": "The experience with MERT for this language pair has not been very positive.", "labels": [], "entities": []}, {"text": "Earlier work on Turkish indicates that starting with default Moses parameters and applying MERT to the resulting model does not even come close to the performance of the model with those two specific parameters set as such (distortion limit -1 and distortion weight 0.1), most likely because the default parameters do not encourage the range of distortions that are needed to deal with the constituent order differences.", "labels": [], "entities": [{"text": "MERT", "start_pos": 91, "end_pos": 95, "type": "METRIC", "confidence": 0.958693265914917}, {"text": "distortion limit -1", "start_pos": 224, "end_pos": 243, "type": "METRIC", "confidence": 0.9565769731998444}, {"text": "distortion weight 0.1", "start_pos": 248, "end_pos": 269, "type": "METRIC", "confidence": 0.8905023137728373}]}, {"text": "Earlier work on Turkish also shows that even when the weight-d parameter is initialized with this specific value, the space explored for distortion weight and other parameters do not produce any improvements on the test set, even though MERT claims there are improvements on the tune set.", "labels": [], "entities": [{"text": "Turkish", "start_pos": 16, "end_pos": 23, "type": "DATASET", "confidence": 0.7623584270477295}, {"text": "MERT", "start_pos": 237, "end_pos": 241, "type": "DATASET", "confidence": 0.7577589750289917}]}, {"text": "The other practical reasons for not using MERT were the following: at the time we performed this work, the discussion thread at http://www.mail-archive.", "labels": [], "entities": [{"text": "MERT", "start_pos": 42, "end_pos": 46, "type": "TASK", "confidence": 0.582037091255188}]}, {"text": "com/moses-support@mit.edu/msg01012.html indicated that MERT was not tested on multiple factors.", "labels": [], "entities": [{"text": "MERT", "start_pos": 55, "end_pos": 59, "type": "TASK", "confidence": 0.8954704999923706}]}, {"text": "The discussion thread at http://www.mail-archive.", "labels": [], "entities": []}, {"text": "com/moses-support@mit.edu/msg00262.html claimed that MERT does not help very much with factored models.", "labels": [], "entities": [{"text": "MERT", "start_pos": 53, "end_pos": 57, "type": "TASK", "confidence": 0.7103198170661926}]}, {"text": "With these observations, we opted not to experiment with MERT with the multiple factor approach we employed, given that it would be risky and time consuming to run MERT needed for 10 different models and then not necessarily see any (consistent) improvements.", "labels": [], "entities": [{"text": "MERT", "start_pos": 57, "end_pos": 61, "type": "TASK", "confidence": 0.9216538667678833}]}, {"text": "MERT however is orthogonal to the improvements we achieve here and can always be applied on top of the best model we get.", "labels": [], "entities": [{"text": "MERT", "start_pos": 0, "end_pos": 4, "type": "METRIC", "confidence": 0.7652553915977478}]}, {"text": "Ave: BLEU scores of after reordering transformations  Factored phrase-based SMT allows the use of multiple language models for the target side, for different factors during decoding.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 5, "end_pos": 9, "type": "METRIC", "confidence": 0.997593104839325}, {"text": "SMT", "start_pos": 76, "end_pos": 79, "type": "TASK", "confidence": 0.8162375688552856}]}, {"text": "Since the number of possible distinct morphological tags (the morphological tag vocabulary size) in our training data (about 3700) is small compared to distinct number of surface forms (about 52K) and distinct roots (about 15K including numbers), it makes sense to investigate the contribution of higher order n-gram language models for the morphological tag factor on the target side, to see if we can address the observation in the previous section.", "labels": [], "entities": []}, {"text": "Using the data transformed with Noun+Adj-+Verb+Adv+PostP transformations which previously gave us the best results overall, we experimented with using higher order models (4-grams to 9-grams) during decoding, for the morphological tag factor models, keeping the surface and root models at 3-gram.", "labels": [], "entities": []}, {"text": "We observed that for all the 10 data sets, the improvements were consistent for up to 8-gram.", "labels": [], "entities": []}, {"text": "The BLEU with the 8-gram for only the morphological tag factor averaged over the 10 data sets was 22.61 (max: 23.66, min: 21.37, std: 0.72) compared to the 21.96 in.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 4, "end_pos": 8, "type": "METRIC", "confidence": 0.998026430606842}]}, {"text": "Using a 4-gram root LM, considerably less sparse than word forms but more sparse that tags, we get a BLEU score of 22.80 (max: 24.07, min: 21.57, std: 0.85).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 101, "end_pos": 111, "type": "METRIC", "confidence": 0.9828221499919891}]}, {"text": "The details of the various BLEU scores are shown in the two halves of.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 27, "end_pos": 31, "type": "METRIC", "confidence": 0.9947431087493896}]}, {"text": "It seems that larger n-gram LMs contribute to the larger n-gram precisions contributing to the BLEU but not to the unigram precision.", "labels": [], "entities": [{"text": "precisions", "start_pos": 64, "end_pos": 74, "type": "METRIC", "confidence": 0.8689144849777222}, {"text": "BLEU", "start_pos": 95, "end_pos": 99, "type": "METRIC", "confidence": 0.998320996761322}, {"text": "precision", "start_pos": 123, "end_pos": 132, "type": "METRIC", "confidence": 0.5472308993339539}]}, {"text": "The transformations in the previous section do not perform any constituent level reordering, but rather eliminate certain English function words as tokens in the text and fold them into complex syntactic tags.", "labels": [], "entities": []}, {"text": "That is, no transformations reorder the English SVO order to Turkish SOV, 17 for instance, or move postnominal prepositional phrase modifiers in English, to prenominal phrasal modifiers in Turkish.", "labels": [], "entities": []}, {"text": "Now that we have the parses of the English side, we have also investigated a more comprehensive set of reordering transformations which perform the following constituent reorderings to bring English constituent order more inline with the Turkish constitent order at the top and embedded phrase levels: \u2022 Object reordering (ObjR), in which the objects and their dependents are moved in front of the verb.", "labels": [], "entities": []}, {"text": "\u2022 Adverbial phrase reordering (AdvR), which involve moving post-verbal adverbial phrases in front of the verb.", "labels": [], "entities": [{"text": "Adverbial phrase reordering (AdvR)", "start_pos": 2, "end_pos": 36, "type": "TASK", "confidence": 0.810671349366506}]}, {"text": "\u2022 Passive sentence agent reordering (PassAgR), in which any post-verbal agents marked by by, are moved in front of the verb.", "labels": [], "entities": [{"text": "Passive sentence agent reordering (PassAgR)", "start_pos": 2, "end_pos": 45, "type": "TASK", "confidence": 0.6524489223957062}]}, {"text": "\u2022 Subordinate clause reordering (SubCR) which involve moving postnominal relative clauses or prepositional phrase modifers in front of any modifiers of the head noun.", "labels": [], "entities": [{"text": "Subordinate clause reordering (SubCR)", "start_pos": 2, "end_pos": 39, "type": "TASK", "confidence": 0.8329942226409912}]}, {"text": "Similarly any prepositional phrases attached to verbs are moved to in front of the verb.", "labels": [], "entities": []}, {"text": "We performed these reorderings on top of the data obtained with the Noun+Adj+Verb+Adv+PostP transformations earlier in Section 3.2.2 and used the same decoder parameters.", "labels": [], "entities": []}, {"text": "shows the performance obtained after various combination of reordering operations over the 10 data sets.", "labels": [], "entities": []}, {"text": "Although there were some improvements for certain cases, none of reordering gave consistent improvements for all the data sets.", "labels": [], "entities": []}, {"text": "A cursory examinations of the alignments produced after these reordering transformations indicated that the resulting root alignments were not necessarily that close to being monotonic as we would have expected.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1. We can observe that the com- bined syntax-to-morphology transformations on  the source side provide a substantial improvement  by themselves and a simple target side transfor- mation on top of those provides a further boost  to 21.96 BLEU which represents a 28.57% rel- ative improvement over the word-based baseline  and a 18.00% relative improvement over the fac- tored baseline.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 244, "end_pos": 248, "type": "METRIC", "confidence": 0.9988294243812561}]}, {"text": " Table 1: BLEU scores for a variety of transforma- tion combinations", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9988794922828674}]}, {"text": " Table 2: Details of Word, Root and Morphology  BLEU Scores", "labels": [], "entities": [{"text": "BLEU Scores", "start_pos": 48, "end_pos": 59, "type": "METRIC", "confidence": 0.9578043818473816}]}, {"text": " Table 3: Details of Word, Root and Morphology  BLEU Scores, with 8-gram tag LM and 3/4-gram  root LMs", "labels": [], "entities": [{"text": "BLEU Scores", "start_pos": 48, "end_pos": 59, "type": "METRIC", "confidence": 0.9526183009147644}]}, {"text": " Table 4: BLEU scores of after reordering transfor- mations", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9993324875831604}]}]}