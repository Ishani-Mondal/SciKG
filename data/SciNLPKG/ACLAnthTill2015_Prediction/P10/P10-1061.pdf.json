{"title": [{"text": "Evaluating Multilanguage-Comparability of Subjectivity Analysis Systems", "labels": [], "entities": [{"text": "Evaluating Multilanguage-Comparability of Subjectivity Analysis", "start_pos": 0, "end_pos": 63, "type": "TASK", "confidence": 0.5949309587478637}]}], "abstractContent": [{"text": "Subjectivity analysis is a rapidly growing field of study.", "labels": [], "entities": [{"text": "Subjectivity analysis", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.9714273512363434}]}, {"text": "Along with its applications to various NLP tasks, much work have put efforts into multilingual subjectivity learning from existing resources.", "labels": [], "entities": []}, {"text": "Multilingual subjectivity analysis requires language-independent criteria for comparable outcomes across languages.", "labels": [], "entities": [{"text": "Multilingual subjectivity analysis", "start_pos": 0, "end_pos": 34, "type": "TASK", "confidence": 0.7107705473899841}]}, {"text": "This paper proposes to measure the multilanguage-comparability of subjectivity analysis tools, and provides meaningful comparisons of multilingual subjectivity analysis from various points of view.", "labels": [], "entities": []}], "introductionContent": [{"text": "The field of NLP has seen a recent surge in the amount of research on subjectivity analysis.", "labels": [], "entities": [{"text": "subjectivity analysis", "start_pos": 70, "end_pos": 91, "type": "TASK", "confidence": 0.7378673106431961}]}, {"text": "Along with its applications to various NLP tasks, there have been efforts made to extend the resources and tools created for the English language to other languages.", "labels": [], "entities": []}, {"text": "These endeavors have been successful in constructing lexicons, annotated corpora, and tools for subjectivity analysis in multiple languages.", "labels": [], "entities": [{"text": "subjectivity analysis", "start_pos": 96, "end_pos": 117, "type": "TASK", "confidence": 0.724742978811264}]}, {"text": "There are multilingual subjectivity analysis systems available that have been built to monitor and analyze various concerns and opinions on the Internet; among the better known are OASYS from the University of Maryland that analyzes opinions on topics from news article searches in multiple languages ( and TextMap, an entity search engine developed by Stony Brook University for sentiment analysis along with other functionalities ().", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 380, "end_pos": 398, "type": "TASK", "confidence": 0.9313005208969116}]}, {"text": "Though these systems currently rely on English analysis tools and a machine translation (MT) technology to translate other languages into English, up-to-date research provides various ways to analyze subjectivity in multilingual environments.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 68, "end_pos": 92, "type": "TASK", "confidence": 0.8434438467025757}]}, {"text": "Given sentiment analysis systems in different languages, there are many situations when the analysis outcomes need to be multilanguagecomparable.", "labels": [], "entities": [{"text": "sentiment analysis", "start_pos": 6, "end_pos": 24, "type": "TASK", "confidence": 0.9179433584213257}]}, {"text": "For example, it has been common these days for the Internet users across the world to share their views and opinions on various topics including music, books, movies, and global affairs and incidents, and also multinational companies such as Apple and Samsung need to analyze customer feedbacks for their products and services from many countries in different languages.", "labels": [], "entities": []}, {"text": "Governments may also be interested in monitoring terrorist web forums or its global reputation.", "labels": [], "entities": []}, {"text": "Surveying these opinions and sentiments in various languages involves merging the analysis outcomes into a single database, thereby objectively comparing the result across languages.", "labels": [], "entities": []}, {"text": "If there exists an ideal subjectivity analysis system for each language, evaluating the multilanguage-comparability would be unnecessary because the analysis in each language would correctly identify the exact meanings of all input texts regardless of the language.", "labels": [], "entities": []}, {"text": "However, this requirement is not fulfilled with current technology, thus the need for defining and measuring the multilanguage-comparability of subjectivity analysis systems is evident.", "labels": [], "entities": []}, {"text": "This paper proposes to evaluate the multilanguage-comparability of multilingual subjectivity analysis systems.", "labels": [], "entities": []}, {"text": "We build a number of subjectivity classifiers that distinguishes subjective texts from objective ones, and measure the multilanguage-comparability according to our proposed evaluation method.", "labels": [], "entities": []}, {"text": "Since subjectivity analysis tools in languages other than English are not readily available, we focus our experiments on comparing different methods to build multilingual analysis systems from the resources and systems created for English.", "labels": [], "entities": []}, {"text": "These approaches enable us to extend a monolingual system to many languages with a number of freely available NLP resources and tools.", "labels": [], "entities": []}], "datasetContent": [{"text": "An evaluation of multilanguage-comparability maybe done in two ways: measuring agreements in the outcomes of a pair of multilingual texts with an identical subjective meaning, or measuring the consistencies in the label and/or accordance in the order of intensity of a pair of texts with different subjectivities.", "labels": [], "entities": []}, {"text": "There are advantages and disadvantages to each approaches.", "labels": [], "entities": []}, {"text": "The first approach requires multilingual texts aligned at the level of specificity, for instance, document, sentence and phrase, that the subjectivity analysis system works.", "labels": [], "entities": []}, {"text": "Text corpora for MT evaluation such as newspapers, books, technical manuals, and government official records provide a wide variety of parallel texts, typically at the sentence level.", "labels": [], "entities": [{"text": "MT evaluation", "start_pos": 17, "end_pos": 30, "type": "TASK", "confidence": 0.9685308933258057}]}, {"text": "Annotating these types of corpus can be efficient; as parallel texts must have identical semantic meanings, subjectivity-related annotations for one language can be projected into other languages without much loss of accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 217, "end_pos": 225, "type": "METRIC", "confidence": 0.9654619097709656}]}, {"text": "The latter approach accepts any pair of multilingual texts as long as they are annotated with labels and/or intensity.", "labels": [], "entities": []}, {"text": "In this case, evaluating the label consistency of a multilingual system is only as difficult as evaluating that of a monolingual system; we can produce all possible pairs of texts from test corpora annotated with labels for each language.", "labels": [], "entities": []}, {"text": "Evaluating with intensity is not easy for the latter approach; if test corpora already exist with intensity annotations for both languages, normalizing the intensity scores to a comparable scale is necessary (yet is uncertain unless every pair is checked manually), otherwise every pair of multilingual texts needs a manual annotation with its relative order of intensity.", "labels": [], "entities": []}, {"text": "In this paper, we utilize the first approach because it provides a more rational means; we can reasonably hypothesize that text translated into another language by a skilled translator carries an identical semantic meaning and thereby conveys identical subjectivity.", "labels": [], "entities": []}, {"text": "Therefore the required resource is more easily attained in relatively inexpensive ways.", "labels": [], "entities": []}, {"text": "For evaluation, we measure the consistency in the subjectivity labels and the correlation of subjectivity intensity scores of parallel texts.", "labels": [], "entities": [{"text": "consistency", "start_pos": 31, "end_pos": 42, "type": "METRIC", "confidence": 0.983453094959259}]}, {"text": "Section 5.1 describes the details of evaluation metrics.", "labels": [], "entities": []}, {"text": "To evaluate the multilanguage-comparability of subjectivity analysis systems, we measure 1) how consistently the system assigns subjectivity labels and 2) how closely numeric scores for systems' confidences correlate with regard to parallel texts in different languages.", "labels": [], "entities": []}, {"text": "In particular, we use Cohen's kappa coefficient for the first and Pearson's correlation coefficient for the latter.", "labels": [], "entities": [{"text": "Pearson's correlation coefficient", "start_pos": 66, "end_pos": 99, "type": "METRIC", "confidence": 0.9357012510299683}]}, {"text": "These widely used metrics provide useful comparability measures for categorical and quantitative data.", "labels": [], "entities": []}, {"text": "Both coefficients are scaled from \u22121 to +1, indicating negative to positive correlations.", "labels": [], "entities": []}, {"text": "Kappa measures are corrected for chance, thereby yielding better measurements than agreement by proportion.", "labels": [], "entities": [{"text": "Kappa", "start_pos": 0, "end_pos": 5, "type": "METRIC", "confidence": 0.8593742251396179}, {"text": "chance", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.978563129901886}]}, {"text": "The characteristics of Pearson's correlation coefficient that it measures linear relationships and is independent of change in origin, scale, and unit comply with our experiments.", "labels": [], "entities": [{"text": "Pearson's correlation coefficient", "start_pos": 23, "end_pos": 56, "type": "METRIC", "confidence": 0.7141315117478371}]}], "tableCaptions": [{"text": " Table 1: Agreement on subjectivity (S for subjec- tive, O objective) of 859 sentence chunks in Ko- rean between two annotators (An. 1 and An. 2).", "labels": [], "entities": []}, {"text": " Table 2: Agreement on projection of subjectivity  (S for subjective, O objective) from Korean (KR)  to English (EN) by one annotator.  EN  S  O Total", "labels": [], "entities": []}, {"text": " Table 3: Performance of subjectivity analysis with precision (P), recall (R), and F-measure (F). S-SA,- CB,-LB systems in Korean, Chinese, Japanese indicate English analysis systems inputted with transla- tions of the target languages into English.", "labels": [], "entities": [{"text": "precision (P)", "start_pos": 52, "end_pos": 65, "type": "METRIC", "confidence": 0.9271720945835114}, {"text": "recall (R)", "start_pos": 67, "end_pos": 77, "type": "METRIC", "confidence": 0.9507903605699539}, {"text": "F-measure (F)", "start_pos": 83, "end_pos": 96, "type": "METRIC", "confidence": 0.9584056735038757}]}, {"text": " Table 4: Performance of multilanguage-comparability: kappa coefficient (\u03ba) for measuring comparability  of classification labels and Pearson's correlation coefficient (\u03c1) for classification scores for English (EN),  Korean (KR), Chinese (CH), and Japanese (JP). Evaluations of T-CB,-LB for language pairs including  English are carried out with results from S-CB,-LB for English and T-CB,-LB for target languages.", "labels": [], "entities": [{"text": "kappa coefficient (\u03ba)", "start_pos": 54, "end_pos": 75, "type": "METRIC", "confidence": 0.9363404154777527}, {"text": "Pearson's correlation coefficient (\u03c1)", "start_pos": 134, "end_pos": 171, "type": "METRIC", "confidence": 0.9775277546473912}]}]}