{"title": [{"text": "Learning Script Knowledge with Web Experiments", "labels": [], "entities": []}], "abstractContent": [{"text": "We describe a novel approach to unsuper-vised learning of the events that makeup a script, along with constraints on their temporal ordering.", "labels": [], "entities": []}, {"text": "We collect natural-language descriptions of script-specific event sequences from volunteers over the Internet.", "labels": [], "entities": []}, {"text": "Then we compute a graph representation of the script's temporal structure using a multiple sequence alignment algorithm.", "labels": [], "entities": [{"text": "multiple sequence alignment", "start_pos": 82, "end_pos": 109, "type": "TASK", "confidence": 0.6967242757479349}]}, {"text": "The evaluation of our system shows that we outperform two informed baselines.", "labels": [], "entities": []}], "introductionContent": [{"text": "A script is \"a standardized sequence of events that describes some stereotypical human activity such as going to a restaurant or visiting a doctor\" (.", "labels": [], "entities": []}, {"text": "Scripts are fundamental pieces of commonsense knowledge that are shared between the different members of the same culture, and thus a speaker assumes them to be tacitly understood by a hearer when a scenario related to a script is evoked: When one person says \"I'm going shopping\", it is an acceptable reply to say \"did you bring enough money?\", because the SHOPPING script involves a 'payment' event, which again involves the transfer of money.", "labels": [], "entities": []}, {"text": "It has long been recognized that text understanding systems would benefit from the implicit information represented by a script.", "labels": [], "entities": [{"text": "text understanding", "start_pos": 33, "end_pos": 51, "type": "TASK", "confidence": 0.8494446277618408}]}, {"text": "There are many other potential applications, including automated storytelling , anaphora resolution, and information extraction (.", "labels": [], "entities": [{"text": "automated storytelling", "start_pos": 55, "end_pos": 77, "type": "TASK", "confidence": 0.6894082725048065}, {"text": "anaphora resolution", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.7708776295185089}, {"text": "information extraction", "start_pos": 105, "end_pos": 127, "type": "TASK", "confidence": 0.8659437596797943}]}, {"text": "However, it is also commonly accepted that the large-scale manual formalization of scripts is infeasible.", "labels": [], "entities": []}, {"text": "While there have been a few attempts at doing this), efforts in which expert annotators create script knowledge bases clearly don't scale.", "labels": [], "entities": []}, {"text": "The same holds true of the script-like structures called \"scenario frames\" in FrameNet ().", "labels": [], "entities": []}, {"text": "There has recently been a surge of interest in automatically learning script-like knowledge resources from corpora (; but while these efforts have achieved impressive results, they are limited by the very fact that a lot of scripts -such as SHOPPING -are shared implicit knowledge, and their events are therefore rarely elaborated in text.", "labels": [], "entities": []}, {"text": "In this paper, we propose a different approach to the unsupervised learning of script-like knowledge.", "labels": [], "entities": []}, {"text": "We focus on the temporal event structure of scripts; that is, we aim to learn what phrases can describe the same event in a script, and what constraints must hold on the temporal order in which these events occur.", "labels": [], "entities": []}, {"text": "We approach this problem by asking non-experts to describe typical event sequences in a given scenario over the Internet.", "labels": [], "entities": []}, {"text": "This allows us to assemble large and varied collections of event sequence descriptions (ESDs), which are focused on a single scenario.", "labels": [], "entities": []}, {"text": "We then compute a temporal script graph for the scenario by identifying corresponding event descriptions using a Multiple Sequence Alignment algorithm from bioinformatics, and converting the alignment into a graph.", "labels": [], "entities": [{"text": "Multiple Sequence Alignment", "start_pos": 113, "end_pos": 140, "type": "TASK", "confidence": 0.6410293579101562}]}, {"text": "This graph makes statements about what phrases can describe the same event of a scenario, and in what order these events can take place.", "labels": [], "entities": []}, {"text": "Crucially, our algorithm exploits the sequential structure of the ESDs to distinguish event descriptions that occur at different points in the script storyline, even when they are semantically similar.", "labels": [], "entities": []}, {"text": "We evaluate our script graph algorithm on ten unseen scenarios, and show that it significantly outperforms a clustering-based baseline.", "labels": [], "entities": []}, {"text": "The paper is structured as follows.", "labels": [], "entities": []}, {"text": "We will first position our research in the landscape of related work in Section 2.", "labels": [], "entities": []}, {"text": "We will then define how we understand scripts, and what aspect of scripts we model here, in Section 3.", "labels": [], "entities": []}, {"text": "Section 4 describes our data collection method, and Section 5 explains how we use Multiple Sequence Alignment to compute a temporal script graph.", "labels": [], "entities": [{"text": "Multiple Sequence Alignment", "start_pos": 82, "end_pos": 109, "type": "TASK", "confidence": 0.6098642945289612}]}, {"text": "We evaluate our system in Section 6 and conclude in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the two core aspects of our system: its ability to recognize descriptions of the same event (paraphrases) and the resulting temporal constraints it defines on the event descriptions (happens-before relation).", "labels": [], "entities": []}, {"text": "We compare our approach to two baseline systems and show that our system outperforms both baselines and sometimes even comes close to our upper bound.", "labels": [], "entities": []}], "tableCaptions": []}