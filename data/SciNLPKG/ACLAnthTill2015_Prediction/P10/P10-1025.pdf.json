{"title": [], "abstractContent": [{"text": "Current Semantic Role Labeling technologies are based on inductive algorithms trained overlarge scale repositories of annotated examples.", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 8, "end_pos": 30, "type": "TASK", "confidence": 0.7908353408177694}]}, {"text": "Frame-based systems currently make use of the FrameNet database but fail to show suitable generalization capabilities in out-of-domain scenarios.", "labels": [], "entities": [{"text": "FrameNet database", "start_pos": 46, "end_pos": 63, "type": "DATASET", "confidence": 0.9222604334354401}]}, {"text": "In this paper, a state-of-art system for frame-based SRL is extended through the encapsulation of a distributional model of semantic similarity.", "labels": [], "entities": [{"text": "SRL", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.8083443641662598}]}, {"text": "The resulting argument classification model promotes a simpler feature space that limits the potential overfitting effects.", "labels": [], "entities": [{"text": "argument classification", "start_pos": 14, "end_pos": 37, "type": "TASK", "confidence": 0.7204831391572952}]}, {"text": "The large scale empirical study here discussed confirms that state-of-art accuracy can be obtained for out-of-domain evaluations.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 74, "end_pos": 82, "type": "METRIC", "confidence": 0.9978991746902466}]}], "introductionContent": [{"text": "The availability of large scale semantic lexicons, such as FrameNet (, allowed the adoption of a wide family of learning paradigms in the automation of semantic parsing.", "labels": [], "entities": [{"text": "semantic parsing", "start_pos": 152, "end_pos": 168, "type": "TASK", "confidence": 0.7184374332427979}]}, {"text": "Building upon the so called frame semantic model, the Berkeley FrameNet project has developed a semantic lexicon for the core vocabulary of English, since 1997.", "labels": [], "entities": []}, {"text": "A frame is evoked in texts through the occurrence of its lexical units (LU ), i.e. predicate words such verbs, nouns, or adjectives, and specifies the participants and properties of the situation it describes, the so called frame elements (F Es).", "labels": [], "entities": []}, {"text": "Semantic Role Labeling (SRL) is the task of automatic recognition of individual predicates together with their major roles (e.g. frame elements) as they are grammatically realized in input sentences.", "labels": [], "entities": [{"text": "Semantic Role Labeling (SRL) is the task of automatic recognition of individual predicates together with their major roles (e.g. frame elements) as they are grammatically realized in input sentences", "start_pos": 0, "end_pos": 198, "type": "Description", "confidence": 0.7634391631140853}]}, {"text": "It has been a popular task since the availability of the PropBank and FrameNet annotated corpora), the seminal work of () and the successful CoNLL evaluation campaigns).", "labels": [], "entities": [{"text": "PropBank", "start_pos": 57, "end_pos": 65, "type": "DATASET", "confidence": 0.9573118686676025}]}, {"text": "Statistical machine learning methods, ranging from joint probabilistic models to support vector machines, have been successfully adopted to provide very accurate semantic labeling, e.g. (. SRL based on FrameNet is thus not a novel task, although very few systems are known capable of completing a general frame-based annotation process over raw texts, noticeable exceptions being discussed for example in), and.", "labels": [], "entities": []}, {"text": "Some critical limitations have been outlined in literature, some of them independent from the underlying semantic paradigm.", "labels": [], "entities": []}, {"text": "Most of the employed learning algorithms are based on complex sets of syntagmatic features, as deeply investigated in).", "labels": [], "entities": []}, {"text": "The resulting recognition is thus highly dependent on the accuracy of the underlying parser, whereas wrong structures returned by the parser usually imply large misclassification errors.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 58, "end_pos": 66, "type": "METRIC", "confidence": 0.998322069644928}]}, {"text": "Statistical learning approaches applied to SRL are very demanding with respect to the amount and quality of the training material.", "labels": [], "entities": [{"text": "SRL", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.9906249642372131}]}, {"text": "The complex SRL architectures proposed (usually combining local and global, i.e. joint, models of argument classification, e.g. () require a large number of annotated examples.", "labels": [], "entities": [{"text": "SRL", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.982475996017456}, {"text": "argument classification", "start_pos": 98, "end_pos": 121, "type": "TASK", "confidence": 0.7239669859409332}]}, {"text": "The amount and quality of the training data required to reach a significant accuracy is a serious limitation to the exploitation of SRL in many NLP applications.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 76, "end_pos": 84, "type": "METRIC", "confidence": 0.9942544102668762}, {"text": "SRL", "start_pos": 132, "end_pos": 135, "type": "TASK", "confidence": 0.9882136583328247}]}, {"text": "Several studies showed that even when large training sets exist the corresponding learning exhibits poor generalization power.", "labels": [], "entities": []}, {"text": "Most of the CoNLL 2005 systems show a significant performance drop when the tested corpus, i.e. Brown, differs from the training one (i.e. Wall Street Journal), e.g. (. More recently, the stateof-art frame-based semantic role labeling system discussed in) reports a 19% drop inaccuracy for the argument classification task when a different test domain is targeted (i.e. NTI corpus).", "labels": [], "entities": [{"text": "CoNLL 2005", "start_pos": 12, "end_pos": 22, "type": "DATASET", "confidence": 0.8484708666801453}, {"text": "Wall Street Journal", "start_pos": 139, "end_pos": 158, "type": "DATASET", "confidence": 0.9573274453481039}, {"text": "stateof-art frame-based semantic role labeling", "start_pos": 188, "end_pos": 234, "type": "TASK", "confidence": 0.5807622730731964}, {"text": "argument classification task", "start_pos": 294, "end_pos": 322, "type": "TASK", "confidence": 0.7942589720090231}]}, {"text": "Out-of-domain tests seem to suggest the models trained on BNC do not generalize well to novel grammatical and lexical phenomena.", "labels": [], "entities": []}, {"text": "As also suggested in (, the major drawback is the poor generalization power affecting lexical features.", "labels": [], "entities": []}, {"text": "Notice how this is also a general problem of statistical learning processes, as large fine grain feature sets are more exposed to the risks of overfitting.", "labels": [], "entities": []}, {"text": "The above problems are particularly critical for frame-based shallow semantic parsing where, as opposed to more syntactic-oriented semantic labeling schemes), a significant mismatch exists between the semantic descriptors and the underlying syntactic annotation level.", "labels": [], "entities": [{"text": "frame-based shallow semantic parsing", "start_pos": 49, "end_pos": 85, "type": "TASK", "confidence": 0.5968499109148979}]}, {"text": "In () an upper bound of about 83.9% for the accuracy of the argument identification task is reported, it is due to the complexity in projecting frame element boundaries out from the dependency graph: more than 16% of the roles in the annotated material lack of a clear grammatical status.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 44, "end_pos": 52, "type": "METRIC", "confidence": 0.9991618394851685}, {"text": "argument identification task", "start_pos": 60, "end_pos": 88, "type": "TASK", "confidence": 0.7799296577771505}]}, {"text": "The limited level of linguistic generalization outlined above is still an open research problem.", "labels": [], "entities": [{"text": "linguistic generalization", "start_pos": 21, "end_pos": 46, "type": "TASK", "confidence": 0.6988304257392883}]}, {"text": "Existing solutions have been proposed in literature along different lines.", "labels": [], "entities": []}, {"text": "Learning from richer linguistic descriptions of more complex structures is proposed in (.", "labels": [], "entities": []}, {"text": "Limiting the cost required for developing large domainspecific training data sets has been also studied, e.g.,.", "labels": [], "entities": []}, {"text": "Finally, the application of semi-supervised learning is attempted to increase the lexical expressiveness of the model, e.g. (. In this paper, this last direction is pursued.", "labels": [], "entities": []}, {"text": "A semi-supervised statistical model exploiting useful lexical information from unlabeled corpora is proposed.", "labels": [], "entities": []}, {"text": "The model adopts a simple feature space by relying on a limited set of grammatical properties, thus reducing its learning capacity.", "labels": [], "entities": []}, {"text": "Moreover, it generalizes lexical information about the annotated examples by applying a geometrical model, in a Latent Semantic Analysis style, inspired by a distributional paradigm.", "labels": [], "entities": []}, {"text": "As we will see, the accuracy reachable through a restricted feature space is still quite close to the state-of-art, but interestingly the performance drops in out-of-domain tests are avoided.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 20, "end_pos": 28, "type": "METRIC", "confidence": 0.9990578293800354}]}, {"text": "In the following, after discussing existing approaches to SRL (Section 2), a distributional approach is defined in Section 3.", "labels": [], "entities": [{"text": "SRL", "start_pos": 58, "end_pos": 61, "type": "TASK", "confidence": 0.9771758317947388}]}, {"text": "Section 3.2 discusses the proposed HMM-based treatment of joint inferences in argument classification.", "labels": [], "entities": [{"text": "argument classification", "start_pos": 78, "end_pos": 101, "type": "TASK", "confidence": 0.773439884185791}]}, {"text": "The large scale experiments described in Section 4 will allow to draw the conclusions of Section 5.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Training and Testing data sets", "labels": [], "entities": []}, {"text": " Table 3: Accuracy on Arg classification tasks wrt  different clustering policies", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9973692893981934}, {"text": "Arg classification", "start_pos": 22, "end_pos": 40, "type": "TASK", "confidence": 0.7695882618427277}]}, {"text": " Table 4: Accuracy of the Argument Classification task over the different corpora. In parenthesis the  relative increment with respect to the immediately simpler model, previous row", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.990017831325531}, {"text": "Argument Classification task", "start_pos": 26, "end_pos": 54, "type": "TASK", "confidence": 0.7697371939818064}]}, {"text": " Table 5: Accuracy of the full cascade of the SRL  system over three domain", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9968820810317993}, {"text": "SRL", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.955595076084137}]}]}