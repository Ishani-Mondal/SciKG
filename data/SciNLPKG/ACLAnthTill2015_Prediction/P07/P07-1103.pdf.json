{"title": [{"text": "Resolving It, This, and That in Unrestricted Multi-Party Dialog", "labels": [], "entities": [{"text": "Resolving It", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.9019719362258911}]}], "abstractContent": [{"text": "We present an implemented system for the resolution of it, this, and that in transcribed multi-party dialog.", "labels": [], "entities": [{"text": "resolution", "start_pos": 41, "end_pos": 51, "type": "TASK", "confidence": 0.9729397892951965}]}, {"text": "The system handles NP-anaphoric as well as discourse-deictic anaphors, i.e. pronouns with VP antecedents.", "labels": [], "entities": []}, {"text": "Selectional preferences for NP or VP antecedents are determined on the basis of corpus counts.", "labels": [], "entities": []}, {"text": "Our results show that the system performs significantly better than a recency-based baseline.", "labels": [], "entities": []}], "introductionContent": [{"text": "This paper describes a fully automatic system for resolving the pronouns it, this, and that in unrestricted multi-party dialog.", "labels": [], "entities": []}, {"text": "The system processes manual transcriptions from the ICSI Meeting Corpus (.", "labels": [], "entities": [{"text": "ICSI Meeting Corpus", "start_pos": 52, "end_pos": 71, "type": "DATASET", "confidence": 0.973599910736084}]}, {"text": "The following is a short fragment from one of these transcripts.", "labels": [], "entities": []}, {"text": "The letters FN in the speaker tag mean that the speaker is a female non-native speaker of English.", "labels": [], "entities": [{"text": "FN", "start_pos": 12, "end_pos": 14, "type": "METRIC", "confidence": 0.9868926405906677}]}, {"text": "The brackets and subscript numbers are not part of the original transcript.", "labels": [], "entities": []}, {"text": "For each of the six 3rd-person pronouns in the example, the task is to automatically identify its referent, i.e. the entity (if any) to which the speaker makes reference.", "labels": [], "entities": []}, {"text": "Once a referent has been identified, the pronoun is resolved by linking it to one of its antecedents, i.e. one of the referent's earlier mentions.", "labels": [], "entities": []}, {"text": "For humans, identification of a pronoun's referent is often easy: it 1 , it 2 , and it 6 are probably used to refer to the text on the web pages, while it 4 is probably used to refer to reading this text.", "labels": [], "entities": [{"text": "identification of a pronoun's referent", "start_pos": 12, "end_pos": 50, "type": "TASK", "confidence": 0.8783297340075175}]}, {"text": "Humans also have no problem determining that it is not a normal pronoun at all.", "labels": [], "entities": []}, {"text": "In other cases, resolving a pronoun is difficult even for humans: this 3 could be used to refer to either reading or changing the text on the web pages.", "labels": [], "entities": []}, {"text": "The pronoun is ambiguous because evidence for more than one interpretation can be found.", "labels": [], "entities": []}, {"text": "Ambiguous pronouns are common in spoken dialog), a fact that has to betaken into account when building a spoken dialog pronoun resolution system.", "labels": [], "entities": [{"text": "spoken dialog pronoun resolution", "start_pos": 105, "end_pos": 137, "type": "TASK", "confidence": 0.6479220986366272}]}, {"text": "Our system is intended as a component in an extractive dialog summarization system.", "labels": [], "entities": [{"text": "extractive dialog summarization", "start_pos": 44, "end_pos": 75, "type": "TASK", "confidence": 0.6714858512083689}]}, {"text": "There are several ways in which coreference information can be integrated into extractive summarization.", "labels": [], "entities": [{"text": "extractive summarization", "start_pos": 79, "end_pos": 103, "type": "TASK", "confidence": 0.5755182504653931}]}, {"text": "e.g. obtained their best extraction results by specifying for each sentence whether it contained a mention of a particular anaphoric chain.", "labels": [], "entities": []}, {"text": "Apart from improving the extraction itself, coreference information can also be used to substitute anaphors with their antecedents, thus improving the readability of a summary by minimizing the number of dangling anaphors, i.e. anaphors whose antecedents occur in utterances that are not part of the summary.", "labels": [], "entities": []}, {"text": "The paper is structured as follows: Section 2 outlines the most important challenges and the state of the art in spoken dialog pronoun resolution.", "labels": [], "entities": [{"text": "spoken dialog pronoun resolution", "start_pos": 113, "end_pos": 145, "type": "TASK", "confidence": 0.5866211354732513}]}, {"text": "Section 3 describes our annotation experiments, and Section 4 describes the automatic dialog preprocessing.", "labels": [], "entities": []}, {"text": "Resolution experiments and results can be found in Section 5.", "labels": [], "entities": [{"text": "Resolution", "start_pos": 0, "end_pos": 10, "type": "TASK", "confidence": 0.7804805636405945}, {"text": "Section 5", "start_pos": 51, "end_pos": 60, "type": "DATASET", "confidence": 0.9180820882320404}]}], "datasetContent": [{"text": "As point out, in an application-oriented setting, not all anaphoric links are equally important: If a pronoun is resolved to an anaphoric chain that contains only pronouns, this resolution can be treated as neutral because it has no application-level effect.", "labels": [], "entities": []}, {"text": "The common coreference evaluation measure described in is inappropriate in this setting.", "labels": [], "entities": []}, {"text": "We calculate precision, recall and F-measure on the basis of the following definitions: A pronoun is resolved correctly resp.", "labels": [], "entities": [{"text": "precision", "start_pos": 13, "end_pos": 22, "type": "METRIC", "confidence": 0.999653697013855}, {"text": "recall", "start_pos": 24, "end_pos": 30, "type": "METRIC", "confidence": 0.9997078776359558}, {"text": "F-measure", "start_pos": 35, "end_pos": 44, "type": "METRIC", "confidence": 0.9993915557861328}]}, {"text": "incorrectly only if it is linked (directly or transitively) to the correct resp.", "labels": [], "entities": []}, {"text": "Likewise, the number of maximally resolvable pronouns in the core data set (i.e. the evaluation key) is determined by considering only pronouns in those chains that do not begin with a pronoun.", "labels": [], "entities": []}, {"text": "Note that our definition of precision is stricter (and yields lower figures) than that applied in the ACE context, as the latter ignores incorrect links between two expressions in the response if these expressions happen to be unannotated in the key, while we treat them as precision errors unless the antecedent is a pronoun.", "labels": [], "entities": [{"text": "precision", "start_pos": 28, "end_pos": 37, "type": "METRIC", "confidence": 0.9992367029190063}, {"text": "precision", "start_pos": 274, "end_pos": 283, "type": "METRIC", "confidence": 0.9879141449928284}]}, {"text": "The same is true for links in the response that were identified by less than three annotators in the key.", "labels": [], "entities": []}, {"text": "While it is practical to treat those links as wrong, it is also simplistic because it does not do justice to ambiguous pronouns (cf. Section 6).", "labels": [], "entities": []}, {"text": "Our best machine learning results were obtained with the Weka 9 Logistic Regression classifier.", "labels": [], "entities": [{"text": "Weka 9 Logistic Regression classifier", "start_pos": 57, "end_pos": 94, "type": "DATASET", "confidence": 0.9019388318061828}]}, {"text": "All experiments were performed with dialog-wise crossvalidation.", "labels": [], "entities": []}, {"text": "For each run, training data was created from the manually annotated markables in four dialogs from the core data set, while testing was performed on the automatically detected chunks in the remaining fifth dialog.", "labels": [], "entities": []}, {"text": "For training and testing, the person, number , gender, and (co-)argument constraints were used.", "labels": [], "entities": []}, {"text": "If an anaphor gave rise to a positive instance, no negative training instances were created beyond that instance.", "labels": [], "entities": []}, {"text": "If a referential anaphor did not give rise to a positive training instance (because its antecedent fell outside the search scope or because it was removed by a constraint), no instances were created for that anaphor.", "labels": [], "entities": []}, {"text": "Instances for nonreferential pronouns were added to the training data as described in Section 5.2.", "labels": [], "entities": []}, {"text": "During testing, we select for each potential anaphor the positive antecedent with the highest overall confidence.", "labels": [], "entities": []}, {"text": "Testing parameters include it-filter, which switches on and off the module for the detection of nonreferential it described in.", "labels": [], "entities": []}, {"text": "When evaluated alone, this module yields a precision of 80.0 and a recall of 60.9 for the detection of pleonastic and discarded it in the five ICSI dialogs.", "labels": [], "entities": [{"text": "precision", "start_pos": 43, "end_pos": 52, "type": "METRIC", "confidence": 0.9987395405769348}, {"text": "recall", "start_pos": 67, "end_pos": 73, "type": "METRIC", "confidence": 0.9994899034500122}, {"text": "ICSI dialogs", "start_pos": 143, "end_pos": 155, "type": "DATASET", "confidence": 0.9287666976451874}]}, {"text": "For training, this module was always on.", "labels": [], "entities": []}, {"text": "We also vary the parameter tipster, which controls whether or not the corpus frequency features are used.", "labels": [], "entities": []}, {"text": "If tipster is off, we ignore the corpus frequency features both during training and testing.", "labels": [], "entities": []}, {"text": "We first ran a simple baseline system which resolved pronouns to their most recent compatible antecedent, applying the same settings and constraints 9 http://www.cs.waikato.ac.nz/ml/weka/ The full set of experiments is described in M \u00a8 uller.", "labels": [], "entities": [{"text": "M \u00a8 uller", "start_pos": 232, "end_pos": 241, "type": "METRIC", "confidence": 0.7063432931900024}]}, {"text": "The number constraint applies to it only, as this and that can have both singular and plural antecedents as for testing (cf. above).", "labels": [], "entities": []}, {"text": "The results can be found in the first part of.", "labels": [], "entities": []}, {"text": "Precision, recall and Fmeasure are provided for ALL and for NP and VP antecedents individually.", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9965510368347168}, {"text": "recall", "start_pos": 11, "end_pos": 17, "type": "METRIC", "confidence": 0.9993128776550293}, {"text": "Fmeasure", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.9988800883293152}, {"text": "ALL", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.8734307289123535}]}, {"text": "The parameter tipster is not available for the baseline system.", "labels": [], "entities": []}, {"text": "The best baseline performance is precision 4.88, recall 20.06 and F-measure 7.85 in the setting with it-filter on.", "labels": [], "entities": [{"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9995391368865967}, {"text": "recall", "start_pos": 49, "end_pos": 55, "type": "METRIC", "confidence": 0.9995555281639099}, {"text": "F-measure", "start_pos": 66, "end_pos": 75, "type": "METRIC", "confidence": 0.9990811347961426}]}, {"text": "As expected, this filter yields an increase in precision and a decrease in recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 47, "end_pos": 56, "type": "METRIC", "confidence": 0.9996169805526733}, {"text": "recall", "start_pos": 75, "end_pos": 81, "type": "METRIC", "confidence": 0.9992495179176331}]}, {"text": "The negative effect is outweighed by the positive effect, leading to a small but insignificant   The second part of shows the results of the Logistic Regression classifier.", "labels": [], "entities": []}, {"text": "When compared to the best baseline, the F-measures are consistently better for NP, VP, and ALL.", "labels": [], "entities": [{"text": "F-measures", "start_pos": 40, "end_pos": 50, "type": "METRIC", "confidence": 0.992277979850769}, {"text": "VP", "start_pos": 83, "end_pos": 85, "type": "METRIC", "confidence": 0.9128202199935913}]}, {"text": "The improvement is (sometimes highly) significant for NP and ALL, but never for VP.", "labels": [], "entities": [{"text": "VP", "start_pos": 80, "end_pos": 82, "type": "TASK", "confidence": 0.9035320281982422}]}, {"text": "The best F-measure for ALL is 18.63, yielded by the setting with it-filter off and tipster on.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 9, "end_pos": 18, "type": "METRIC", "confidence": 0.9981020092964172}, {"text": "ALL", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.9165902137756348}]}, {"text": "This setting also yields the best Fmeasure for VP and the second best for NP.", "labels": [], "entities": [{"text": "Fmeasure", "start_pos": 34, "end_pos": 42, "type": "METRIC", "confidence": 0.9892504215240479}]}, {"text": "The contribution of the it-filter is disappointing: In both tipster settings, the it-filter causes F-measure for ALL to go down.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 99, "end_pos": 108, "type": "METRIC", "confidence": 0.99735426902771}, {"text": "ALL", "start_pos": 113, "end_pos": 116, "type": "METRIC", "confidence": 0.9365655779838562}]}, {"text": "The contribution of the corpus features, on the other hand, is somewhat inconclusive: In both it-filter settings, they cause an increase in F-measure for ALL.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 140, "end_pos": 149, "type": "METRIC", "confidence": 0.9978173971176147}]}, {"text": "In the first setting, this increase is accompanied by an increase in F-measure for VP, while in the second setting, F-measure for VP goes down.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 69, "end_pos": 78, "type": "METRIC", "confidence": 0.9981517195701599}, {"text": "F-measure", "start_pos": 116, "end_pos": 125, "type": "METRIC", "confidence": 0.9934439659118652}]}, {"text": "It has to be noted, however, that none of the improvements brought about by the itfilter or the tipster corpus features is statistically significant.", "labels": [], "entities": []}, {"text": "This also confirms some of the findings of, who found features similar to", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Krippendorff's \u03b1 for four annotators.", "labels": [], "entities": []}, {"text": " Table 2: Anaphoric chains in core data set.", "labels": [], "entities": []}, {"text": " Table 3. Precision, recall and F- measure are provided for ALL and for NP and VP  antecedents individually. The parameter tipster  is not available for the baseline system. The best  baseline performance is precision 4.88, recall 20.06  and F-measure 7.85 in the setting with it-filter  on. As expected, this filter yields an increase in pre- cision and a decrease in recall. The negative effect  is outweighed by the positive effect, leading to a  small but insignificant", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9988138675689697}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9980022311210632}, {"text": "F- measure", "start_pos": 32, "end_pos": 42, "type": "METRIC", "confidence": 0.9933186173439026}, {"text": "ALL", "start_pos": 60, "end_pos": 63, "type": "TASK", "confidence": 0.8932642340660095}, {"text": "precision", "start_pos": 208, "end_pos": 217, "type": "METRIC", "confidence": 0.9962427616119385}, {"text": "recall", "start_pos": 224, "end_pos": 230, "type": "METRIC", "confidence": 0.9960883855819702}, {"text": "F-measure", "start_pos": 242, "end_pos": 251, "type": "METRIC", "confidence": 0.9728124141693115}, {"text": "recall", "start_pos": 369, "end_pos": 375, "type": "METRIC", "confidence": 0.999154806137085}]}]}