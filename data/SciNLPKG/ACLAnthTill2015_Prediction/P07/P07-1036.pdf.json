{"title": [], "abstractContent": [{"text": "Over the last few years, two of the main research directions in machine learning of natural language processing have been the study of semi-supervised learning algorithms as away to train classifiers when the labeled data is scarce, and the study of ways to exploit knowledge and global information in structured learning tasks.", "labels": [], "entities": []}, {"text": "In this paper, we suggest a method for incorporating domain knowledge in semi-supervised learning algorithms.", "labels": [], "entities": []}, {"text": "Our novel framework unifies and can exploit several kinds of task specific constraints.", "labels": [], "entities": []}, {"text": "The experimental results presented in the information extraction domain demonstrate that applying constraints helps the model to generate better feedback during learning, and hence the framework allows for high performance learning with significantly less training data than was possible before on these tasks.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 42, "end_pos": 64, "type": "TASK", "confidence": 0.7903808951377869}]}], "introductionContent": [{"text": "Natural Language Processing (NLP) systems typically require large amounts of knowledge to achieve good performance.", "labels": [], "entities": []}, {"text": "Acquiring labeled data is a difficult and expensive task.", "labels": [], "entities": []}, {"text": "Therefore, an increasing attention has been recently given to semi-supervised learning, where large amounts of unlabeled data are used to improve the models learned from a small training set ().", "labels": [], "entities": []}, {"text": "The hope is that semi-supervised or even unsupervised approaches, when given enough knowledge about the structure of the problem, will be competitive with the supervised models trained on large training sets.", "labels": [], "entities": []}, {"text": "However, in the general case, semi-supervised approaches give mixed results, and sometimes even degrade the model performance ().", "labels": [], "entities": []}, {"text": "In many cases, improving semi-supervised models was done by seeding these models with domain information taken from dictionaries or ontology ().", "labels": [], "entities": []}, {"text": "On the other hand, in the supervised setting, it has been shown that incorporating domain and problem specific structured information can result in substantial improvements ().", "labels": [], "entities": []}, {"text": "This paper proposes a novel constraints-based learning protocol for guiding semi-supervised learning.", "labels": [], "entities": []}, {"text": "We develop a formalism for constraints-based learning that unifies several kinds of constraints: unary, dictionary based and n-ary constraints, which encode structural information and interdependencies among possible labels.", "labels": [], "entities": []}, {"text": "One advantage of our formalism is that it allows capturing different levels of constraint violation.", "labels": [], "entities": []}, {"text": "Our protocol can be used in the presence of any learning model, including those that acquire additional statistical constraints from observed data while learning (see Section 5.", "labels": [], "entities": []}, {"text": "In the experimental part of this paper we use HMMs as the underlying model, and exhibit significant reduction in the number of training examples required in two information extraction problems.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 161, "end_pos": 183, "type": "TASK", "confidence": 0.8276199102401733}]}, {"text": "As is often the casein semi-supervised learning, the algorithm can be viewed as a process that improves the model by generating feedback through labeling unlabeled examples.", "labels": [], "entities": []}, {"text": "Our algorithm pushes this intuition further, in that the use of constraints allows us to better exploit domain information as away to label, along with the current learned model, unlabeled examples.", "labels": [], "entities": []}, {"text": "Given a small amount of labeled data and a large unlabeled pool, our framework initializes the model with the labeled data and then repeatedly: (1) Uses constraints and the learned model to label the instances in the pool.", "labels": [], "entities": []}, {"text": "(2) Updates the model by newly labeled data.", "labels": [], "entities": []}, {"text": "This way, we can generate better \"training\" examples during the semi-supervised learning process.", "labels": [], "entities": []}, {"text": "The core of our approach, (1), is described in Section 5.", "labels": [], "entities": []}, {"text": "The task is described in Section 3 and the Experimental study in Section 6.", "labels": [], "entities": []}, {"text": "It is shown there that the improvement on the training examples via the constraints indeed boosts the learned model and the proposed method significantly outperforms the traditional semi-supervised framework.", "labels": [], "entities": []}], "datasetContent": [{"text": "In Section 4 we will develop a general framework for semi-supervised learning with constraints.", "labels": [], "entities": []}, {"text": "However, it is useful to illustrate the ideas on concrete problems.", "labels": [], "entities": []}, {"text": "Therefore, in this section, we give a brief introduction to the two domains on which we tested our algorithms.", "labels": [], "entities": []}, {"text": "We study two information extraction problems in each of which, given text, a set of pre-defined fields is to be identified.", "labels": [], "entities": [{"text": "information extraction", "start_pos": 13, "end_pos": 35, "type": "TASK", "confidence": 0.8065538704395294}]}, {"text": "Since the fields are typically related and interdependent, these kinds of applications provide a good test case for an approach like ours.", "labels": [], "entities": []}, {"text": "The first task is to identify fields from citations ( ) . The data originally included 500 labeled references, and was later extended with 5,000 unannotated citations collected from papers found on the Internet ().", "labels": [], "entities": []}, {"text": "Given a citation, the task is to extract the  fields that appear in the given reference.", "labels": [], "entities": []}, {"text": "There are 13 possible fields including author, title, location, etc.", "labels": [], "entities": []}, {"text": "To gain an insight to how the constraints can guide semi-supervised learning, assume that the sentence shown in appears in the unlabeled data pool.", "labels": [], "entities": []}, {"text": "Part (a) of the figure shows the correct labeled assignment and part (b) shows the assignment labeled by a HMM trained on 30 labels.", "labels": [], "entities": []}, {"text": "However, if we apply the constraint that state transition can occur only on punctuation marks, the same HMM model parameters will result in the correct labeling (a).", "labels": [], "entities": []}, {"text": "Therefore, by adding the improved labeled assignment we can generate better training samples during semi-supervised learning.", "labels": [], "entities": []}, {"text": "In fact, the punctuation marks are only some of the constraints that can be applied to this problem.", "labels": [], "entities": []}, {"text": "The set of constraints we used in our experiments appears in.", "labels": [], "entities": []}, {"text": "Note that some of the constraints are non-local and are very intuitive for people, yet it is very difficult to inject this knowledge into most models.", "labels": [], "entities": []}, {"text": "The second problem we consider is extracting fields from advertisements ().", "labels": [], "entities": []}, {"text": "The dataset consists of 8,767 advertisements for apartment rentals in the San Francisco Bay Area downloaded in June 2004 from the Craigslist website.", "labels": [], "entities": []}, {"text": "In the dataset, only 302 entries have been labeled with 12 fields, including size, rent, neighborhood, features, and soon.", "labels": [], "entities": [{"text": "soon", "start_pos": 117, "end_pos": 121, "type": "METRIC", "confidence": 0.9617763161659241}]}, {"text": "The data was preprocessed using regular expressions for phone numbers, email addresses and URLs.", "labels": [], "entities": []}, {"text": "The list of the constraints for this domain is given in.", "labels": [], "entities": []}, {"text": "We implement some global constraints and include unary constraints which were largely imported from the list of seed words used in ().", "labels": [], "entities": []}, {"text": "We slightly modified the seedwords due to difference in preprocessing.", "labels": [], "entities": []}, {"text": "In this section, we present empirical results of our algorithms on two domains: citations and advertisements.", "labels": [], "entities": []}, {"text": "Both problems are modeled with a simple token-based HMM.", "labels": [], "entities": []}, {"text": "We stress that token-based HMM cannot represent many of our constraints.", "labels": [], "entities": []}, {"text": "The function d ) used is an approximation of a Hamming distance function, discussed in Section 7.", "labels": [], "entities": []}, {"text": "For both domains, and all the experiments, \u03b3 was set to 0.1.", "labels": [], "entities": []}, {"text": "The constraints violation penalty \u03c1 is set to \u2212 log 10 \u22124 and \u2212 log 10 \u22121 for citations and advertisements, resp.", "labels": [], "entities": [{"text": "constraints violation penalty \u03c1", "start_pos": 4, "end_pos": 35, "type": "METRIC", "confidence": 0.6971880421042442}]}, {"text": "2 Note that all constraints share the same penalty.", "labels": [], "entities": []}, {"text": "The number of semi-supervised training cycles (line 3 of) was set to 5.", "labels": [], "entities": []}, {"text": "The constraints for the two domains are listed in.", "labels": [], "entities": []}, {"text": "We trained models on training sets of size varying from 5 to 300 for the citations and from 5 to 100 for the advertisements.", "labels": [], "entities": []}, {"text": "Additionally, in all the semi-supervised experiments, 1000 unlabeled examples are used.", "labels": [], "entities": []}, {"text": "We report token-based 3 accuracy on 100 held-out examples (which do not overlap neither with the training nor with the unlabeled data).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 24, "end_pos": 32, "type": "METRIC", "confidence": 0.9325003623962402}]}, {"text": "We ran 5 experiments in each setting, randomly choosing the training set.", "labels": [], "entities": []}, {"text": "The results reported below are the averages over these 5 runs.", "labels": [], "entities": []}, {"text": "To verify our claims we implemented several baselines.", "labels": [], "entities": []}, {"text": "The first baseline is the supervised learning protocol denoted by sup.", "labels": [], "entities": []}, {"text": "The second baseline was a traditional top-1 Hard EM also known as truncated EM 4 (denoted by H for Hard).", "labels": [], "entities": []}, {"text": "In the third baseline, denoted H&W, we balanced the weight of the supervised and unsupervised models as described inline 9 of.", "labels": [], "entities": []}, {"text": "We compare these baselines to our proposed protocol, H&W&C, where we added the constraints to guide the H&W protocol.", "labels": [], "entities": [{"text": "H&W&C", "start_pos": 53, "end_pos": 58, "type": "DATASET", "confidence": 0.8646551370620728}]}, {"text": "We experimented with two flavors of the algorithm: the top-1 and the top-K version.", "labels": [], "entities": []}, {"text": "In the top-K version, the algorithm uses K-best predictions (K=50) for each instance in order to update the model as described in.", "labels": [], "entities": []}, {"text": "The experimental results for both domains are in given The guiding intuition is that \u03bbF (x, y) corresponds to a loglikelihood of a HMM model and \u03c1 to a crude estimation of the log probability that a constraint does not hold.", "labels": [], "entities": []}, {"text": "\u03c1 was tuned on a development set and kept fixed in all experiments.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Experimental results for extracting fields  from citations and advertisements. N is the number  of labeled samples. H is the traditional hard-EM and  H&W weighs labeled and unlabeled data as men- tioned in Sec. 5. Our proposed model is H&W&C,  which uses constraints in the learning procedure. I  refers to using constraints during inference at eval- uation time. Note that adding constraints improves  the accuracy during both learning and inference.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 417, "end_pos": 425, "type": "METRIC", "confidence": 0.9988908171653748}]}]}