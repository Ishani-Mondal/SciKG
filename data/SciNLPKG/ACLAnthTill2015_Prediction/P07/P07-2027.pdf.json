{"title": [{"text": "Disambiguating Between Generic and Referential \"You\" in Dialog *", "labels": [], "entities": [{"text": "Disambiguating", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.9382268190383911}]}], "abstractContent": [{"text": "We describe an algorithm fora novel task: disam-biguating the pronoun you in conversation.", "labels": [], "entities": []}, {"text": "You can be generic or referential; finding referential you is important for tasks such as addressee identification or extracting 'owners' of action items.", "labels": [], "entities": [{"text": "addressee identification", "start_pos": 90, "end_pos": 114, "type": "TASK", "confidence": 0.7019306719303131}, {"text": "extracting 'owners' of action items", "start_pos": 118, "end_pos": 153, "type": "TASK", "confidence": 0.7619799574216207}]}, {"text": "Our classifier achieves 84% accuracy in two-person conversations; an initial study shows promising performance even on more complex multi-party meetings.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 28, "end_pos": 36, "type": "METRIC", "confidence": 0.9987157583236694}]}], "introductionContent": [], "datasetContent": [{"text": "As shows, there are very few occurrences of the referential plural, reported referential and ambiguous classes.", "labels": [], "entities": []}, {"text": "We therefore decided to model our problem as a two way classification task, predicting generic versus referential (collapsing referential singular and plural as one category).", "labels": [], "entities": []}, {"text": "Note that we expect this to be the major useful distinction for our overall action-item detection task.", "labels": [], "entities": [{"text": "action-item detection task", "start_pos": 76, "end_pos": 102, "type": "TASK", "confidence": 0.7787723243236542}]}, {"text": "Baseline A simple baseline involves predicting the dominant class (in the test set, referential).", "labels": [], "entities": []}, {"text": "This gives 54.59% accuracy (see).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 18, "end_pos": 26, "type": "METRIC", "confidence": 0.9996647834777832}]}, {"text": "The experiments above used two-person dialog data: we expect that multi-party data is more complex.", "labels": [], "entities": []}, {"text": "We performed an initial exploratory study, applying the same classes and features to multi-party meetings.", "labels": [], "entities": []}, {"text": "Two annotators labeled one meeting from the AMI corpus), giving a total of 52 utterances containing \"you\" on which to assess agreement: kappa was 87.18% for two way classification of generic versus referential.", "labels": [], "entities": [{"text": "AMI corpus", "start_pos": 44, "end_pos": 54, "type": "DATASET", "confidence": 0.9199379086494446}]}, {"text": "One of the authors then labeled a testing set of 203 utterances; 104 are generic and 99 referential, giving a baseline accuracy of 51.23% (and F-score of 67.65%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 119, "end_pos": 127, "type": "METRIC", "confidence": 0.9923481941223145}, {"text": "F-score", "start_pos": 143, "end_pos": 150, "type": "METRIC", "confidence": 0.999637246131897}]}, {"text": "We performed experiments for the same task: detecting generic versus referential uses.", "labels": [], "entities": [{"text": "detecting generic versus referential uses", "start_pos": 44, "end_pos": 85, "type": "TASK", "confidence": 0.8347716927528381}]}, {"text": "Due to the small amount of data, we trained the classifier on the Switchboard training set from section 3 (i.e. on twoparty rather than multi-party data).", "labels": [], "entities": [{"text": "Switchboard training set", "start_pos": 66, "end_pos": 90, "type": "DATASET", "confidence": 0.9015230933825175}]}, {"text": "Lacking part-ofspeech or dialog act features (since the dialog act tagset differs from the Switchboard tagset), we used only the sentential, context and question mark features described in.", "labels": [], "entities": [{"text": "Switchboard tagset", "start_pos": 91, "end_pos": 109, "type": "DATASET", "confidence": 0.8471108376979828}]}, {"text": "However, the classifier still achieves an accuracy of 73.89% and F-score of 74.15%, comparable to the results on Switchboard without dialog act features (accuracy 76.30%).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 42, "end_pos": 50, "type": "METRIC", "confidence": 0.9995982050895691}, {"text": "F-score", "start_pos": 65, "end_pos": 72, "type": "METRIC", "confidence": 0.9997387528419495}, {"text": "accuracy", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.9975709319114685}]}, {"text": "Precision is lower, though (both precision and recall are 73-75%).", "labels": [], "entities": [{"text": "Precision", "start_pos": 0, "end_pos": 9, "type": "METRIC", "confidence": 0.9948747754096985}, {"text": "precision", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9998061060905457}, {"text": "recall", "start_pos": 47, "end_pos": 53, "type": "METRIC", "confidence": 0.9995794892311096}]}], "tableCaptions": [{"text": " Table 1: Number of cases found.", "labels": [], "entities": [{"text": "Number", "start_pos": 10, "end_pos": 16, "type": "METRIC", "confidence": 0.9789766073226929}]}, {"text": " Table 2: Features investigated. N indicates the num- ber of possible values (there are 46 DA tags; context  features can be generic, referential or N/A).", "labels": [], "entities": []}, {"text": " Table 3: SVM results: generic versus referential", "labels": [], "entities": []}, {"text": " Table 4: SVM results: prosodic features", "labels": [], "entities": []}, {"text": " Table 5: Prosodic feature analysis", "labels": [], "entities": [{"text": "Prosodic feature analysis", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.8114939530690511}]}]}