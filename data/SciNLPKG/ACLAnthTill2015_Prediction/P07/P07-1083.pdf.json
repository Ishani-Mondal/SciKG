{"title": [], "abstractContent": [{"text": "A character-based measure of similarity is an important component of many natural language processing systems, including approaches to transliteration, coreference, word alignment, spelling correction, and the identification of cognates in related vocabularies.", "labels": [], "entities": [{"text": "coreference", "start_pos": 152, "end_pos": 163, "type": "TASK", "confidence": 0.9650618433952332}, {"text": "word alignment", "start_pos": 165, "end_pos": 179, "type": "TASK", "confidence": 0.7683267593383789}, {"text": "spelling correction", "start_pos": 181, "end_pos": 200, "type": "TASK", "confidence": 0.856141984462738}]}, {"text": "We propose an alignment-based dis-criminative framework for string similarity.", "labels": [], "entities": [{"text": "string similarity", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.6875708997249603}]}, {"text": "We gather features from substring pairs consistent with a character-based alignment of the two strings.", "labels": [], "entities": []}, {"text": "This approach achieves exceptional performance; on nine separate cognate identification experiments using six language pairs, we more than double the precision of traditional orthographic measures like Longest Common Subsequence Ratio and Dice's Coefficient.", "labels": [], "entities": [{"text": "precision", "start_pos": 150, "end_pos": 159, "type": "METRIC", "confidence": 0.9989044666290283}]}, {"text": "We also show strong improvements over other recent discrimina-tive and heuristic similarity functions.", "labels": [], "entities": []}], "introductionContent": [{"text": "String similarity is often used as a means of quantifying the likelihood that two pairs of strings have the same underlying meaning, based purely on the character composition of the two words.", "labels": [], "entities": []}, {"text": "use Edit Distance as a feature for determining if two words are coreferent.", "labels": [], "entities": [{"text": "Edit Distance", "start_pos": 4, "end_pos": 17, "type": "METRIC", "confidence": 0.7554309070110321}]}, {"text": "use French-English common letter sequences as a feature for discriminative word alignment in bilingual texts.", "labels": [], "entities": [{"text": "discriminative word alignment", "start_pos": 60, "end_pos": 89, "type": "TASK", "confidence": 0.6794180572032928}]}, {"text": "learn misspelled-word to correctly-spelled-word similarities for spelling correction.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 65, "end_pos": 84, "type": "TASK", "confidence": 0.8634356260299683}]}, {"text": "In each of these examples, a similarity measure can make use of the recurrent substring pairings that reliably occur between words having the same meaning.", "labels": [], "entities": []}, {"text": "Across natural languages, these recurrent substring correspondences are found in word pairs known as cognates: words with a common form and meaning across languages.", "labels": [], "entities": []}, {"text": "Cognates arise either from words in a common ancestor language (e.g. light/Licht, night/Nacht in English/German) or from foreign word borrowings (e.g. trampoline/toranporin in English/Japanese).", "labels": [], "entities": []}, {"text": "Knowledge of cognates is useful fora number of applications, including sentence alignment) and learning translation lexicons ().", "labels": [], "entities": [{"text": "sentence alignment", "start_pos": 71, "end_pos": 89, "type": "TASK", "confidence": 0.7930936515331268}, {"text": "learning translation lexicons", "start_pos": 95, "end_pos": 124, "type": "TASK", "confidence": 0.8263473510742188}]}, {"text": "We propose an alignment-based, discriminative approach to string similarity and evaluate this approach on cognate identification.", "labels": [], "entities": [{"text": "cognate identification", "start_pos": 106, "end_pos": 128, "type": "TASK", "confidence": 0.7487387359142303}]}, {"text": "Section 2 describes previous approaches and their limitations.", "labels": [], "entities": []}, {"text": "In Section 3, we explain our technique for automatically creating a cognate-identification training set.", "labels": [], "entities": []}, {"text": "A novel aspect of this set is the inclusion of competitive counter-examples for learning.", "labels": [], "entities": []}, {"text": "Section 4 shows how discriminative features are created from a characterbased, minimum-edit-distance alignment of a pair of strings.", "labels": [], "entities": []}, {"text": "In Section 5, we describe our bitext and dictionary-based experiments on six language pairs, including three based on non-Roman alphabets.", "labels": [], "entities": []}, {"text": "In Section 6, we show significant improvements over traditional approaches, as well as significant gains over more recent techniques by,,, and.", "labels": [], "entities": []}], "datasetContent": [{"text": "Section 3 introduced two high-precision methods for generating labelled cognate pairs: using the word alignments from a bilingual corpus or using the entries in a translation lexicon.", "labels": [], "entities": []}, {"text": "We investigate both of these methods in our experiments.", "labels": [], "entities": []}, {"text": "In each case, we generate sets of labelled word pairs for training, testing, and development.", "labels": [], "entities": []}, {"text": "The proportion of positive examples in the bitext-labelled test sets range between 1.4% and 1.8%, while ranging between 1.0% and 1.6% for the dictionary data.", "labels": [], "entities": [{"text": "bitext-labelled test sets", "start_pos": 43, "end_pos": 68, "type": "DATASET", "confidence": 0.7856083412965139}]}, {"text": "For the discriminative methods, we use a popular Support Vector Machine (SVM) learning package called SVM light (Joachims, 1999).", "labels": [], "entities": []}, {"text": "SVMs are maximum-margin classifiers that achieve good performance on a range of tasks.", "labels": [], "entities": []}, {"text": "In each case, we learn a linear kernel on the training set pairs and tune the parameter that trades-off training error and margin on the development set.", "labels": [], "entities": [{"text": "margin", "start_pos": 123, "end_pos": 129, "type": "METRIC", "confidence": 0.9477699995040894}]}, {"text": "We apply our classifier to the test set and score the pairs by their positive distance from the SVM classification hyperplane (also done by with their token-based SVM similarity measure).", "labels": [], "entities": []}, {"text": "We also score the test sets using traditional orthographic similarity measures PREFIX, DICE, LCSR, and NED, an average of these four, and's LCSF.", "labels": [], "entities": [{"text": "PREFIX", "start_pos": 79, "end_pos": 85, "type": "METRIC", "confidence": 0.8721470832824707}, {"text": "DICE", "start_pos": 87, "end_pos": 91, "type": "METRIC", "confidence": 0.8061705827713013}, {"text": "LCSR", "start_pos": 93, "end_pos": 97, "type": "METRIC", "confidence": 0.8976229429244995}, {"text": "LCSF", "start_pos": 140, "end_pos": 144, "type": "METRIC", "confidence": 0.8804246783256531}]}, {"text": "We also use the log of the edit probability from the stochastic decoder of (normalized by the length of the longer word) and Tiedemann (1999)'s highest performing system (Approach #3).", "labels": [], "entities": [{"text": "Approach", "start_pos": 171, "end_pos": 179, "type": "METRIC", "confidence": 0.7370861768722534}]}, {"text": "Both use only the positive examples in our training set.", "labels": [], "entities": []}, {"text": "Our evaluation metric is 11-pt average precision on the score-sorted pair lists (also used by).", "labels": [], "entities": [{"text": "precision", "start_pos": 39, "end_pos": 48, "type": "METRIC", "confidence": 0.8843058347702026}]}, {"text": "For the bitext-based annotation, we use publiclyavailable word alignments from the Europarl corpus, automatically generated by GIZA++ for FrenchEnglish (Fr), Spanish-English (Es) and GermanEnglish (De) ().", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 83, "end_pos": 98, "type": "DATASET", "confidence": 0.990060567855835}]}, {"text": "Initial cleaning of these noisy word pairs is necessary.", "labels": [], "entities": []}, {"text": "We thus remove all pairs with numbers, punctuation, a capitalized English word, and all words that occur fewer than ten times.", "labels": [], "entities": []}, {"text": "We also remove many incorrectly aligned words by filtering pairs where the pairwise Mutual Information between the words is less than 7.5.", "labels": [], "entities": [{"text": "pairwise Mutual Information", "start_pos": 75, "end_pos": 102, "type": "METRIC", "confidence": 0.7290280858675638}]}, {"text": "This processing leaves vocabulary sizes of 39K for French, 31K for Spanish, and 60K for German.", "labels": [], "entities": []}, {"text": "Our labelled set is then generated from pairs with LCSR \u2265 0.58 (using the cutoff from Melamed (1999)).", "labels": [], "entities": [{"text": "LCSR", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.9903620481491089}]}, {"text": "Each labelled set entry is a triple of a) the foreign word f , b) the cognates E f + and c) the false friends E f \u2212 . For each language pair, we randomly take 20K triples for training, 5K for development and 5K for testing.", "labels": [], "entities": []}, {"text": "Each triple is converted to a set of pairwise examples for learning and classification.", "labels": [], "entities": []}, {"text": "For the dictionary-based cognate identification, we use French, Spanish, German, Greek (Gr), Japanese (Jp), and Russian (Rs) to English translation pairs from the Freelang program.", "labels": [], "entities": [{"text": "dictionary-based cognate identification", "start_pos": 8, "end_pos": 47, "type": "TASK", "confidence": 0.5531160334746043}, {"text": "Freelang program", "start_pos": 163, "end_pos": 179, "type": "DATASET", "confidence": 0.9436040818691254}]}, {"text": "The latter three pairs were chosen so that we can evaluate on more distant languages that use non-Roman alphabets (although the R\u00f4maji Japanese is Romanized by definition).", "labels": [], "entities": []}, {"text": "We take 10K labelled-set triples for training, 2K for testing and 2K for development.", "labels": [], "entities": []}, {"text": "The baseline approaches and our definition of cognation require comparison in a common alphabet.", "labels": [], "entities": []}, {"text": "Thus we use a simple context-free mapping to convert every Russian and Greek character in the word pairs to their nearest Roman equivalent.", "labels": [], "entities": []}, {"text": "We then label a translation pair as cognate if the LCSR between the words' Romanized representations is greater than 0.58.", "labels": [], "entities": [{"text": "LCSR", "start_pos": 51, "end_pos": 55, "type": "METRIC", "confidence": 0.8900557160377502}]}, {"text": "We also operate all of our comparison systems on these Romanized pairs.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: Bitext, Dictionary Foreign-to-English cognate identification 11-pt average precision (%).", "labels": [], "entities": [{"text": "Foreign-to-English cognate identification 11-pt average", "start_pos": 29, "end_pos": 84, "type": "TASK", "confidence": 0.5310053825378418}, {"text": "precision", "start_pos": 85, "end_pos": 94, "type": "METRIC", "confidence": 0.5030484199523926}]}]}