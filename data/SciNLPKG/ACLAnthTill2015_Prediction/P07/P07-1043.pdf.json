{"title": [{"text": "Sentence generation as a planning problem", "labels": [], "entities": [{"text": "Sentence generation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9775635898113251}]}], "abstractContent": [{"text": "We translate sentence generation from TAG grammars with semantic and pragmatic information into a planning problem by encoding the contribution of each word declaratively and explicitly.", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 13, "end_pos": 32, "type": "TASK", "confidence": 0.7455967962741852}]}, {"text": "This allows us to exploit the performance of off-the-shelf planners.", "labels": [], "entities": []}, {"text": "It also opens up new perspectives on referring expression generation and the relationship between language and action.", "labels": [], "entities": [{"text": "referring expression generation", "start_pos": 37, "end_pos": 68, "type": "TASK", "confidence": 0.8331561088562012}]}], "introductionContent": [{"text": "Systems that produce natural language must synthesize the primitives of linguistic structure into wellformed utterances that make desired contributions to discourse.", "labels": [], "entities": []}, {"text": "This is fundamentally a planning problem: Each linguistic primitive makes certain contributions while potentially introducing new goals.", "labels": [], "entities": []}, {"text": "In this paper, we make this perspective explicit by translating the sentence generation problem of TAG grammars with semantic and pragmatic information into a planning problem stated in the widely used Planning Domain Definition Language (PDDL,).", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.7414994239807129}]}, {"text": "The encoding provides a clean separation between computation and linguistic modelling and is open to future extensions.", "labels": [], "entities": [{"text": "linguistic modelling", "start_pos": 65, "end_pos": 85, "type": "TASK", "confidence": 0.7169159501791}]}, {"text": "It also allows us to benefit from the past and ongoing advances in the performance of off-the-shelf planners).", "labels": [], "entities": []}, {"text": "While there have been previous systems that encode generation as planning, our approach is distinguished from these systems by its focus on the grammatically specified contributions of each individual word (and the TAG tree it anchors) to syntax, semantics, and local pragmatics (.", "labels": [], "entities": []}, {"text": "For example, words directly achieve content goals by adding a corresponding semantic primitive to the conversational record.", "labels": [], "entities": []}, {"text": "We deliberately avoid reasoning about utterances as coordinated rational behavior, as earlier systems did; this allows us to get by with a much simpler logic.", "labels": [], "entities": []}, {"text": "The problem we solve encompasses the generation of referring expressions (REs) as a special case.", "labels": [], "entities": [{"text": "generation of referring expressions (REs)", "start_pos": 37, "end_pos": 78, "type": "TASK", "confidence": 0.6467932122094291}]}, {"text": "Unlike some approaches, we do not have to distinguish between generating NPs and expressions of other syntactic categories.", "labels": [], "entities": []}, {"text": "We develop anew perspective on the lifecycle of a distractor, which allows us to generate more succinct REs by taking the rest of the utterance into account.", "labels": [], "entities": []}, {"text": "More generally, we do not split the process of sentence generation into two separate steps of sentence planning and realization, as most other systems do, but solve the joint problem in a single integrated step.", "labels": [], "entities": [{"text": "sentence generation", "start_pos": 47, "end_pos": 66, "type": "TASK", "confidence": 0.7325137108564377}, {"text": "sentence planning and realization", "start_pos": 94, "end_pos": 127, "type": "TASK", "confidence": 0.7381388694047928}]}, {"text": "This can potentially allow us to generate higher-quality sentences.", "labels": [], "entities": []}, {"text": "We share these advantages with systems such as SPUD (.", "labels": [], "entities": []}, {"text": "Crucially, however, our approach describes the dynamics of interpretation explicitly and declaratively.", "labels": [], "entities": []}, {"text": "We do not need to assume extra machinery beyond the encoding of words as PDDL planning operators; for example, our planning operators give a self-contained description of how each individual word contributes to resolving references.", "labels": [], "entities": []}, {"text": "This makes our encoding more direct and transparent than those in work like and.", "labels": [], "entities": []}, {"text": "We present our encoding in a sequence of steps, each of which adds more linguistic information to 336 the planning operators.", "labels": [], "entities": []}, {"text": "After a brief review of LTAG and PDDL, we first focus on syntax alone and show how to cast the problem of generating grammatically well-formed LTAG trees as a planning problem in Section 2.", "labels": [], "entities": []}, {"text": "In Section 3, we add semantics to the elementary trees and add goals to communicate specific content (this corresponds to surface realization).", "labels": [], "entities": []}, {"text": "We complete the account by modeling referring expressions and go through an example.", "labels": [], "entities": []}, {"text": "Finally, we assess the practical efficiency of our approach and discuss future work in Section 4.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}