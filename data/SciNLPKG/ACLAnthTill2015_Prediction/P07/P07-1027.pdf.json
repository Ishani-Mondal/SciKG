{"title": [{"text": "Learning Predictive Structures for Semantic Role Labeling of NomBank", "labels": [], "entities": [{"text": "Semantic Role Labeling", "start_pos": 35, "end_pos": 57, "type": "TASK", "confidence": 0.6421977082888285}, {"text": "NomBank", "start_pos": 61, "end_pos": 68, "type": "DATASET", "confidence": 0.442288339138031}]}], "abstractContent": [{"text": "This paper presents a novel application of Alternating Structure Optimization (ASO) to the task of Semantic Role Labeling (SRL) of noun predicates in NomBank.", "labels": [], "entities": [{"text": "Alternating Structure Optimization (ASO)", "start_pos": 43, "end_pos": 83, "type": "TASK", "confidence": 0.7036645710468292}, {"text": "Semantic Role Labeling (SRL) of noun predicates", "start_pos": 99, "end_pos": 146, "type": "TASK", "confidence": 0.8111778630150689}]}, {"text": "ASO is a recently proposed linear multi-task learning algorithm, which extracts the common structures of multiple tasks to improve accuracy , via the use of auxiliary problems.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 131, "end_pos": 139, "type": "METRIC", "confidence": 0.9973607659339905}]}, {"text": "In this paper, we explore a number of different auxiliary problems, and we are able to significantly improve the accuracy of the Nom-Bank SRL task using this approach.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9993152618408203}, {"text": "Nom-Bank SRL task", "start_pos": 129, "end_pos": 146, "type": "TASK", "confidence": 0.5681288838386536}]}, {"text": "To our knowledge, our proposed approach achieves the highest accuracy published to date on the English NomBank SRL task.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 61, "end_pos": 69, "type": "METRIC", "confidence": 0.9988375306129456}, {"text": "English NomBank SRL task", "start_pos": 95, "end_pos": 119, "type": "DATASET", "confidence": 0.8484974950551987}]}], "introductionContent": [{"text": "The task of Semantic Role Labeling (SRL) is to identify predicate-argument relationships in natural language texts in a domain-independent fashion.", "labels": [], "entities": [{"text": "Semantic Role Labeling (SRL)", "start_pos": 12, "end_pos": 40, "type": "TASK", "confidence": 0.8374098738034567}]}, {"text": "In recent years, the availability of large human-labeled corpora such as PropBank () and FrameNet () has made possible a statistical approach of identifying and classifying the arguments of verbs in natural language texts.", "labels": [], "entities": [{"text": "classifying the arguments of verbs in natural language texts", "start_pos": 161, "end_pos": 221, "type": "TASK", "confidence": 0.7730919851197137}]}, {"text": "A large number of SRL systems have been evaluated and compared on the standard data set in the CoNLL shared tasks (, and many systems have performed reasonably well.", "labels": [], "entities": [{"text": "SRL", "start_pos": 18, "end_pos": 21, "type": "TASK", "confidence": 0.9566546678543091}, {"text": "CoNLL shared tasks", "start_pos": 95, "end_pos": 113, "type": "DATASET", "confidence": 0.772642453511556}]}, {"text": "Compared to the previous CoNLL shared tasks (noun phrase bracketing, chunking, clause identification, and named entity recognition), SRL represents a significant step towards processing the semantic content of natural language texts.", "labels": [], "entities": [{"text": "noun phrase bracketing", "start_pos": 45, "end_pos": 67, "type": "TASK", "confidence": 0.6268766423066457}, {"text": "clause identification", "start_pos": 79, "end_pos": 100, "type": "TASK", "confidence": 0.7597047090530396}, {"text": "named entity recognition", "start_pos": 106, "end_pos": 130, "type": "TASK", "confidence": 0.6966118415196737}, {"text": "SRL", "start_pos": 133, "end_pos": 136, "type": "TASK", "confidence": 0.9762614965438843}, {"text": "processing the semantic content of natural language texts", "start_pos": 175, "end_pos": 232, "type": "TASK", "confidence": 0.6815617680549622}]}, {"text": "Although verbs are probably the most obvious predicates in a sentence, many nouns are also capable of having complex argument structures, often with much more flexibility than its verb counterpart.", "labels": [], "entities": []}, {"text": "For example, compare affect and effect: With the recent release of NomBank (), it becomes possible to apply machine learning techniques to the task.", "labels": [], "entities": [{"text": "NomBank", "start_pos": 67, "end_pos": 74, "type": "DATASET", "confidence": 0.9204187393188477}]}, {"text": "So far we are aware of only one English NomBank-based SRL system (), which uses the maximum entropy classifier, although similar efforts are reported on the Chinese NomBank by) 208 and on FrameNet by) using a small set of hand-selected nominalizations.", "labels": [], "entities": [{"text": "Chinese NomBank by) 208", "start_pos": 157, "end_pos": 180, "type": "DATASET", "confidence": 0.803147554397583}, {"text": "FrameNet", "start_pos": 188, "end_pos": 196, "type": "DATASET", "confidence": 0.8906431198120117}]}, {"text": "Noun predicates also appear in FrameNet semantic role labeling (, and many FrameNet SRL systems are evaluated in.", "labels": [], "entities": [{"text": "FrameNet semantic role labeling", "start_pos": 31, "end_pos": 62, "type": "TASK", "confidence": 0.7272922545671463}]}, {"text": "Semantic role labeling of NomBank is a multiclass classification problem by nature.", "labels": [], "entities": [{"text": "Semantic role labeling", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.6778117914994558}]}, {"text": "Using the one-vs-all arrangement, that is, one binary classifier for each possible outcome, the SRL task can be treated as multiple binary classification problems.", "labels": [], "entities": [{"text": "SRL task", "start_pos": 96, "end_pos": 104, "type": "TASK", "confidence": 0.9344653189182281}]}, {"text": "In the latter view, we are presented with the opportunity to exploit the common structures of these related problems.", "labels": [], "entities": []}, {"text": "This is known as multi-task learning in the machine learning literature.", "labels": [], "entities": [{"text": "multi-task learning", "start_pos": 17, "end_pos": 36, "type": "TASK", "confidence": 0.7187429815530777}]}, {"text": "In this paper, we apply Alternating Structure Optimization (ASO) () to the semantic role labeling task on NomBank.", "labels": [], "entities": [{"text": "semantic role labeling task", "start_pos": 75, "end_pos": 102, "type": "TASK", "confidence": 0.6868654415011406}, {"text": "NomBank", "start_pos": 106, "end_pos": 113, "type": "DATASET", "confidence": 0.9000330567359924}]}, {"text": "ASO is a recently proposed linear multi-task learning algorithm based on empirical risk minimization.", "labels": [], "entities": []}, {"text": "The method requires the use of multiple auxiliary problems, and its effectiveness may vary depending on the specific auxiliary problems used.", "labels": [], "entities": []}, {"text": "ASO has been shown to be effective on the following natural language processing tasks: text categorization, named entity recognition, part-of-speech tagging, and word sense disambiguation ().", "labels": [], "entities": [{"text": "text categorization", "start_pos": 87, "end_pos": 106, "type": "TASK", "confidence": 0.7617643177509308}, {"text": "named entity recognition", "start_pos": 108, "end_pos": 132, "type": "TASK", "confidence": 0.6038133800029755}, {"text": "part-of-speech tagging", "start_pos": 134, "end_pos": 156, "type": "TASK", "confidence": 0.7063559293746948}, {"text": "word sense disambiguation", "start_pos": 162, "end_pos": 187, "type": "TASK", "confidence": 0.6728544235229492}]}, {"text": "This paper makes two significant contributions.", "labels": [], "entities": []}, {"text": "First, we present a novel application of ASO to the SRL task on NomBank.", "labels": [], "entities": [{"text": "SRL task", "start_pos": 52, "end_pos": 60, "type": "TASK", "confidence": 0.9243539273738861}, {"text": "NomBank", "start_pos": 64, "end_pos": 71, "type": "DATASET", "confidence": 0.911249577999115}]}, {"text": "We explore the effect of different auxiliary problems, and show that learning predictive structures with ASO results in significantly improved SRL accuracy.", "labels": [], "entities": [{"text": "SRL", "start_pos": 143, "end_pos": 146, "type": "TASK", "confidence": 0.9050869941711426}, {"text": "accuracy", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.9022464156150818}]}, {"text": "Second, we achieve accuracy higher than that reported in) and advance the state of the art in SRL research.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 19, "end_pos": 27, "type": "METRIC", "confidence": 0.9993975162506104}, {"text": "SRL research", "start_pos": 94, "end_pos": 106, "type": "TASK", "confidence": 0.9109449088573456}]}, {"text": "The rest of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "We give an overview of NomBank and ASO in Sections 2 and 3 respectively.", "labels": [], "entities": [{"text": "NomBank", "start_pos": 23, "end_pos": 30, "type": "DATASET", "confidence": 0.8555486798286438}]}, {"text": "The baseline linear classifier is described in detail in Section 4, followed by the description of the ASO classifier in Section 5, where we focus on exploring different auxiliary problems.", "labels": [], "entities": []}, {"text": "We provide discussions in Section 6, present related work in Section 7, and conclude in Section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the combined task, we run the identification task with gold parse trees, and then the classification task with the output of the identification task.", "labels": [], "entities": []}, {"text": "This way the combined effect of errors from both stages on the final classification output can be assessed.", "labels": [], "entities": []}, {"text": "The scores of this complete SRL system are presented in the third row of.", "labels": [], "entities": [{"text": "SRL", "start_pos": 28, "end_pos": 31, "type": "TASK", "confidence": 0.9771411418914795}]}, {"text": "To test the performance of the combined task on automatic parse trees, we employ two different configurations.", "labels": [], "entities": []}, {"text": "First, we train the various classifiers on sections 2 to 21 using gold argument labels and automatic parse trees produced by Charniak's reranking parser), and test them on section 23 with automatic parse trees.", "labels": [], "entities": []}, {"text": "This is the same configuration as reported in).", "labels": [], "entities": []}, {"text": "The scores are presented in the fourth row auto parse (t&t) in.", "labels": [], "entities": []}, {"text": "Next, we train the various classifiers on sections 2 to 21 using gold argument labels and gold parse trees.", "labels": [], "entities": []}, {"text": "To minimize the discrepancy between gold and automatic parse trees, we remove all the nodes in the gold trees whose POS are -NONE-, as they do not span any word and are thus never generated by the automatic parser.", "labels": [], "entities": [{"text": "NONE", "start_pos": 125, "end_pos": 129, "type": "METRIC", "confidence": 0.861325740814209}]}, {"text": "The resulting classifiers are then tested on section 23 using automatic parse trees.", "labels": [], "entities": []}, {"text": "The scores are presented in the last row auto parse (test) of.", "labels": [], "entities": []}, {"text": "We note that auto parse (test) consistently outperforms auto parse (t&t).", "labels": [], "entities": []}, {"text": "We believe that auto parse (test) is a more realistic setting in which to test the performance of SRL on automatic parse trees.", "labels": [], "entities": [{"text": "SRL", "start_pos": 98, "end_pos": 101, "type": "TASK", "confidence": 0.9141047596931458}]}, {"text": "When presented with some previously unseen test data, we are forced to rely on its automatic parse trees.", "labels": [], "entities": []}, {"text": "However, for the best results we should take advantage of gold parse trees whenever possible, including those of the labeled training data.", "labels": [], "entities": []}, {"text": "Our maximum entropy classifier consistently outperforms (), which also uses a maximum entropy classifier.", "labels": [], "entities": []}, {"text": "The primary difference is that we use a later version of NomBank (September 2006 release vs. September 2005 release).", "labels": [], "entities": [{"text": "NomBank", "start_pos": 57, "end_pos": 64, "type": "DATASET", "confidence": 0.9501065015792847}]}, {"text": "In addition, we use somewhat different features and treat overlapping arguments differently.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 3: F1 scores of various classifiers on Nom- Bank SRL", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.9988563060760498}, {"text": "Nom- Bank SRL", "start_pos": 46, "end_pos": 59, "type": "DATASET", "confidence": 0.9273129403591156}]}, {"text": " Table 4: F1 scores of ASO with observable auxiliary  problems on argument identification. All h = 20.", "labels": [], "entities": [{"text": "F1", "start_pos": 10, "end_pos": 12, "type": "METRIC", "confidence": 0.999526858329773}, {"text": "ASO", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.6802700161933899}, {"text": "argument identification", "start_pos": 66, "end_pos": 89, "type": "TASK", "confidence": 0.7321385592222214}]}]}