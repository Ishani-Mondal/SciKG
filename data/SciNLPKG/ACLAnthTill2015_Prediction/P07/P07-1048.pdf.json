{"title": [{"text": "A Multimodal Interface for Access to Content in the Home", "labels": [], "entities": []}], "abstractContent": [{"text": "In order to effectively access the rapidly increasing range of media content available in the home, new kinds of more natural interfaces are needed.", "labels": [], "entities": []}, {"text": "In this paper, we explore the application of multimodal interface technologies to searching and browsing a database of movies.", "labels": [], "entities": []}, {"text": "The resulting system allows users to access movies using speech, pen, remote control, and dynamic combinations of these modalities.", "labels": [], "entities": []}, {"text": "An experimental evaluation, with more than 40 users, is presented contrasting two variants of the system: one combining speech with traditional remote control input and a second where the user has a tablet display supporting speech and pen input.", "labels": [], "entities": []}], "introductionContent": [{"text": "As traditional entertainment channels and the internet converge through the advent of technologies such as broadband access, movies-on-demand, and streaming video, an increasingly large range of content is available to consumers in the home.", "labels": [], "entities": []}, {"text": "However, to benefit from this new wealth of content, users need to be able to rapidly and easily find what they are actually interested in, and do so effortlessly while relaxing on the couch in their living room -a location where they typically do not have easy access to the keyboard, mouse, and close-up screen display typical of desktop web browsing.", "labels": [], "entities": []}, {"text": "Current interfaces to cable and satellite television services typically use direct manipulation of a graphical user interface using a remote control.", "labels": [], "entities": []}, {"text": "In order to find content, users generally have to either navigate a complex, pre-defined, and often deeply embedded menu structure or type in titles or other key phrases using an onscreen keyboard or triple tap input on a remote control keypad.", "labels": [], "entities": []}, {"text": "These interfaces are cumbersome and do not scale well as the range of content available increases).", "labels": [], "entities": []}], "datasetContent": [{"text": "After designing and implementing our initial prototype system, we conducted an extensive multimodal data collection and usability study with the two different interaction scenarios: tablet versus remote control.", "labels": [], "entities": []}, {"text": "Our main goals for the data collection and statistical analysis were three-fold: collect a large corpus of natural multimodal dialogue for this media selection task, investigate whether future systems should be paired with a remote control or tablet-like device, and determine which types of search and input modalities are more or less desirable.", "labels": [], "entities": [{"text": "data collection", "start_pos": 23, "end_pos": 38, "type": "TASK", "confidence": 0.8346428871154785}, {"text": "statistical analysis", "start_pos": 43, "end_pos": 63, "type": "TASK", "confidence": 0.8713361918926239}]}, {"text": "The system evaluation took place in a conference room setup to resemble a living room ().", "labels": [], "entities": []}, {"text": "The system was projected on a large screen across the room from a couch.", "labels": [], "entities": []}, {"text": "An adjacent conference room was used for data collection.", "labels": [], "entities": [{"text": "data collection", "start_pos": 41, "end_pos": 56, "type": "TASK", "confidence": 0.7680220007896423}]}, {"text": "Data was collected in sound files, videotapes, and text logs.", "labels": [], "entities": []}, {"text": "Each subject's spoken utterances were recorded by three microphones: wireless, array and standalone.", "labels": [], "entities": []}, {"text": "The wireless microphone was connected to the system while the array and standalone microphones were around 10 feet away.", "labels": [], "entities": []}, {"text": "1 Test sessions were recorded with two video cameras -one captured the system's screen using a scan converter while the other recorded the user and couch area.", "labels": [], "entities": []}, {"text": "Lastly, the user's interactions and the state of the system were captured by the system's logger.", "labels": [], "entities": []}, {"text": "The logger is an additional agent added to the system architecture for the purposes of the evaluation.", "labels": [], "entities": []}, {"text": "It receives log messages from different system components as interaction unfolds and stores them in a detailed XML log file.", "labels": [], "entities": []}, {"text": "For the specific purposes of this evaluation, each log file contains: general information about the system's components, a description and timestamp for each system event and user event, names and timestamps for the system-recorded sound files, and timestamps for the start and end of each scenario.", "labels": [], "entities": []}], "tableCaptions": []}