{"title": [{"text": "On the role of context and prosody in the interpretation of 'okay'", "labels": [], "entities": [{"text": "interpretation of 'okay'", "start_pos": 42, "end_pos": 66, "type": "TASK", "confidence": 0.9009070992469788}]}], "abstractContent": [{"text": "We examine the effect of contextual and acoustic cues in the disambiguation of three discourse-pragmatic functions of the word okay.", "labels": [], "entities": []}, {"text": "Results of a perception study show that contextual cues are stronger predictors of discourse function than acoustic cues.", "labels": [], "entities": []}, {"text": "However, acoustic features capturing the pitch excursion at the right edge of okay feature prominently in disambiguation, whether other contextual cues are present or not.", "labels": [], "entities": []}], "introductionContent": [{"text": "CUE PHRASES (also known as DISCOURSE MARK-ERS) are linguistic expressions that can be used to convey explicit information about the structure of a discourse or to convey a semantic contribution (.", "labels": [], "entities": [{"text": "PHRASES", "start_pos": 4, "end_pos": 11, "type": "METRIC", "confidence": 0.7880955934524536}]}, {"text": "For example, the word okay can be used to convey a 'satisfactory' evaluation of some entity in the discourse (the movie was okay); as a backchannel in a dialogue to indicate that one interlocutor is still attending to another; to convey acknowledgment or agreement; or, in its 'cue' use, to start or finish a discourse segment).", "labels": [], "entities": []}, {"text": "A major question is how speakers indicate and listeners interpret such variation in meaning.", "labels": [], "entities": []}, {"text": "From a practical perspective, understanding how speakers and listeners disambiguate cue phrases is important to spoken dialogue systems, so that systems can convey potentially ambiguous terms with their intended meaning and can interpret user input correctly.", "labels": [], "entities": []}, {"text": "There is considerable evidence that the different uses of individual cue phrases can be distinguished by variation in the prosody with which they are realized.", "labels": [], "entities": []}, {"text": "For example, found that cue phrases in general could be disambiguated between their 'semantic' and their 'discourse marker' uses in terms of the type of pitch accent borne by the cue phrase, the position of the phrase in the intonational phrase, and the amount of additional information in the phrase.", "labels": [], "entities": []}, {"text": "Despite the frequence of the word okay in natural dialogues, relatively little attention has been paid to the relationship between its use and its prosodic realization.", "labels": [], "entities": []}, {"text": "did find that okay differs in terms of the pitch contour speakers use in uttering it, suggesting that a final rising pitch contour \"categorically marks a turn change,\" while a downstepped falling pitch contour usually indicates a discourse segment boundary.", "labels": [], "entities": []}, {"text": "However, it is not clear which, if any, of the prosodic differences identified in this study are actually used by listeners in interpreting these potentially ambiguous items.", "labels": [], "entities": []}, {"text": "In this study, we address the question of how hearers disambiguate the interpretation of okay.", "labels": [], "entities": [{"text": "hearers disambiguate the interpretation of okay", "start_pos": 46, "end_pos": 93, "type": "TASK", "confidence": 0.720360686381658}]}, {"text": "Our goal is to identify the acoustic, prosodic and phonetic features of okay tokens for which listeners assign different meanings.", "labels": [], "entities": []}, {"text": "Additionally, we want to determine the role that discourse context plays in this classification: i.e., can subjects classify okay tokens reliably from the word alone or do they require additional context?", "labels": [], "entities": []}, {"text": "Below we describe a perception study in which listeners were presented with a number of spoken productions of okay, taken from a corpus of dialogues between subjects playing a computer game.", "labels": [], "entities": []}, {"text": "The tokens were presented both in isolation and in context.", "labels": [], "entities": []}, {"text": "Users were asked to select the meaning of each token from three of the meanings that okay can take on: ACKNOWLEDGEMENT/AGREEMENT, BACKCHANNEL, and CUE OF AN INITIAL DIS-COURSE SEGMENT.", "labels": [], "entities": [{"text": "AGREEMENT", "start_pos": 119, "end_pos": 128, "type": "METRIC", "confidence": 0.9624332785606384}, {"text": "BACKCHANNEL", "start_pos": 130, "end_pos": 141, "type": "METRIC", "confidence": 0.9951896667480469}, {"text": "CUE OF AN INITIAL DIS-COURSE SEGMENT", "start_pos": 147, "end_pos": 183, "type": "METRIC", "confidence": 0.8108205497264862}]}, {"text": "Subsequently, we examined the acoustic, prosodic and phonetic correlates of these classifications to try to infer what cues listeners used to interpret the tokens, and how these varied by context condition.", "labels": [], "entities": []}, {"text": "Section 2 describes our corpus.", "labels": [], "entities": []}, {"text": "Section 3 describes the perception experiment.", "labels": [], "entities": []}, {"text": "In Section 4 we analyze inter-subject agreement, introduce a novel representation of subject judgments, and examine the acoustic, prosodic, phonetic and contextual correlates of subject classification of okays.", "labels": [], "entities": []}, {"text": "In Section 5 we discuss our results and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "We next designed a perception experiment to examine naive subjects' perception of these tokens of okay.", "labels": [], "entities": []}, {"text": "To obtain good coverage both of the (labeled) A, B, and C classes, as well as the degrees of potential ambiguity among these classes, we identified 9 categories of okay tokens to include in the experiment: 3 classes (A, B, C) \u00d7 3 levels of labeler agreement (UNANIMOUS, MAJORITY, NO-AGREEMENT).", "labels": [], "entities": [{"text": "UNANIMOUS", "start_pos": 259, "end_pos": 268, "type": "METRIC", "confidence": 0.8222553730010986}, {"text": "MAJORITY", "start_pos": 270, "end_pos": 278, "type": "METRIC", "confidence": 0.8433876633644104}, {"text": "NO-AGREEMENT", "start_pos": 280, "end_pos": 292, "type": "METRIC", "confidence": 0.969346821308136}]}, {"text": "'Unanimous' refers to tokens assigned to a particular class label by all 3 labelers, 'majority' to tokens assigned to this class by 2 of the 3 labelers, and 'noagreement' to tokens assigned to this class by only 1 labeler.", "labels": [], "entities": []}, {"text": "To decrease variability in the stimuli, we selected tokens only from speakers who produced at least one token for each of the 9 conditions.", "labels": [], "entities": []}, {"text": "There were 6 such speakers (3 female, 3 male), which gave us a total of 54 tokens.", "labels": [], "entities": []}, {"text": "To see whether subjects' classifications of okay were dependent upon contextual information or not, we prepared two versions of each token.", "labels": [], "entities": []}, {"text": "The isolated versions consisted of only the word okay extracted from the waveform.", "labels": [], "entities": []}, {"text": "For the contextualized versions, we extracted two full speaker turns for each okay including the full turn 1 containing the target okay plus the full turn of the previous speaker.", "labels": [], "entities": []}, {"text": "In the following three sample contexts, pauses are indicated with '#', and the target okays are underlined: The isolated okay tokens were single channel audio files; the contextualized okay tokens were formatted so that each speaker was presented to subjects on a different channel, with the speaker uttering the target okay consistently on the same channel.", "labels": [], "entities": []}, {"text": "The perception study was divided into two parts.", "labels": [], "entities": []}, {"text": "In the first part, each subject was presented with the 54 isolated okay tokens, in a different random ordering for each subject.", "labels": [], "entities": []}, {"text": "They were given a forced choice task to classify them as A, B, or C, with the corresponding labels (Acknowledgement/agreement, Backchannel, and Cue beginning) also presented in a random order for each token.", "labels": [], "entities": [{"text": "Backchannel", "start_pos": 127, "end_pos": 138, "type": "METRIC", "confidence": 0.8645234704017639}]}, {"text": "In the second part, the same subject was given 54 contextualized tokens, presented in a different random order, and asked to make the same choice.", "labels": [], "entities": []}, {"text": "We recruited 20 (paid) subjects for the study, 10 female, and 10 male, all between the ages of 20 and 60.", "labels": [], "entities": []}, {"text": "All subjects were native speakers of Standard American English, except for one subject who was born in Jamaica but a native speaker of English.", "labels": [], "entities": []}, {"text": "All subjects reported no hearing problems.", "labels": [], "entities": []}, {"text": "Subjects performed the study in a quiet lab using headphones to listen to the tokens and indicating their classification decisions in a GUI interface on a lab workstation.", "labels": [], "entities": []}, {"text": "They were given instructions on how to use the interface before each of the two sections of the study.", "labels": [], "entities": []}, {"text": "For the study itself, for each token in the isolated condition, subjects were shown a screen with the three randomly ordered classes and a link to the token's sound file.", "labels": [], "entities": []}, {"text": "They could listen to the sound files as many times as they wished but were instructed not to be concerned with answering the questions We define a TURN as a maximal sequence of words spoken by the same speaker during which the speaker holds the floor.", "labels": [], "entities": []}, {"text": "\"correctly\", but to answer with their immediate response if possible.", "labels": [], "entities": [{"text": "correctly", "start_pos": 1, "end_pos": 10, "type": "METRIC", "confidence": 0.9852026104927063}]}, {"text": "However, they were allowed to change their selection as many times as they liked before moving to the next screen.", "labels": [], "entities": []}, {"text": "In the contextualized condition, they were also shown an orthographic transcription of part of the contextualized token, to help them identify the target okay.", "labels": [], "entities": []}, {"text": "The mean duration of the first part of the study was 25 minutes, and of the second part, 27 minutes.", "labels": [], "entities": [{"text": "duration", "start_pos": 9, "end_pos": 17, "type": "METRIC", "confidence": 0.66275554895401}]}], "tableCaptions": [{"text": " Table 2: Fleiss' \u03ba for each label class  in each study condition.", "labels": [], "entities": []}, {"text": " Table 3: Fleiss' \u03ba in each study condition, grouped  by agreement of the three original labelers ('OL').", "labels": [], "entities": [{"text": "Fleiss' \u03ba", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.8527020215988159}]}, {"text": " Table 6: Features correlated to the proportion of  votes for each label. Contextualized condition.", "labels": [], "entities": []}, {"text": " Table 7: Realization of the /oU/ phoneme, grouped  by subject plurality label. Isolated condition only.", "labels": [], "entities": []}, {"text": " Table 8: Phrase accent and boundary tone, grouped  by subject plurality label.", "labels": [], "entities": [{"text": "Phrase accent", "start_pos": 10, "end_pos": 23, "type": "TASK", "confidence": 0.8443665206432343}]}]}