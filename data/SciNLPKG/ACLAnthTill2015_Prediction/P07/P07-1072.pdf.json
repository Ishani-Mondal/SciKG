{"title": [{"text": "Improving the Interpretation of Noun Phrases with Cross-linguistic Information", "labels": [], "entities": [{"text": "Improving", "start_pos": 0, "end_pos": 9, "type": "TASK", "confidence": 0.9697712659835815}, {"text": "Interpretation of Noun Phrases", "start_pos": 14, "end_pos": 44, "type": "TASK", "confidence": 0.6131484881043434}]}], "abstractContent": [{"text": "This paper addresses the automatic classification of semantic relations in noun phrases based on cross-linguistic evidence from a set of five Romance languages.", "labels": [], "entities": [{"text": "automatic classification of semantic relations in noun phrases", "start_pos": 25, "end_pos": 87, "type": "TASK", "confidence": 0.8362210616469383}]}, {"text": "A set of novel semantic and contextual English-Romance NP features is derived based on empirical observations on the distribution of the syntax and meaning of noun phrases on two corpora of different genre (Europarl and CLUVI).", "labels": [], "entities": [{"text": "Europarl", "start_pos": 207, "end_pos": 215, "type": "DATASET", "confidence": 0.981715202331543}]}, {"text": "The features were employed in a Support Vector Machines algorithm which achieved an accuracy of 77.9% (Eu-roparl) and 74.31% (CLUVI), an improvement compared with two state-of-the-art models reported in the literature.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.9994534850120544}, {"text": "CLUVI)", "start_pos": 126, "end_pos": 132, "type": "METRIC", "confidence": 0.9160131812095642}]}], "introductionContent": [{"text": "Semantic knowledge is very important for any application that requires a deep understanding of natural language.", "labels": [], "entities": []}, {"text": "The automatic acquisition of semantic information in text has become increasingly important in ontology development, information extraction, question answering, and other advanced natural language processing applications.", "labels": [], "entities": [{"text": "automatic acquisition of semantic information in text", "start_pos": 4, "end_pos": 57, "type": "TASK", "confidence": 0.8059038264410836}, {"text": "ontology development", "start_pos": 95, "end_pos": 115, "type": "TASK", "confidence": 0.9280049502849579}, {"text": "information extraction", "start_pos": 117, "end_pos": 139, "type": "TASK", "confidence": 0.8269442021846771}, {"text": "question answering", "start_pos": 141, "end_pos": 159, "type": "TASK", "confidence": 0.9137023389339447}]}, {"text": "In this paper we present a model for the automatic semantic interpretation of noun phrases (NPs), which is the task of determining the semantic relation among the noun constituents.", "labels": [], "entities": [{"text": "automatic semantic interpretation of noun phrases (NPs)", "start_pos": 41, "end_pos": 96, "type": "TASK", "confidence": 0.8284201323986053}]}, {"text": "For example, family estate encodes a POSSESSION relation, while dress of silk refers to PART-WHOLE.", "labels": [], "entities": [{"text": "POSSESSION", "start_pos": 37, "end_pos": 47, "type": "METRIC", "confidence": 0.9870317578315735}, {"text": "PART-WHOLE", "start_pos": 88, "end_pos": 98, "type": "METRIC", "confidence": 0.8658000826835632}]}, {"text": "The problem, while simple to state is hard to solve.", "labels": [], "entities": []}, {"text": "The reason is that the meaning of these constructions is most of the time ambiguous or implicit.", "labels": [], "entities": []}, {"text": "Interpreting NPs correctly requires various types of information from world knowledge to complex context features.", "labels": [], "entities": []}, {"text": "Moreover, the extension of this task to other natural languages brings forward new issues and problems.", "labels": [], "entities": []}, {"text": "For instance, beer glass translates into tarro de cerveza in Spanish, bicchiere da birra in Italian, verr\u00e8 ab\u00ec ere in French, and pahar de bere in Romanian.", "labels": [], "entities": []}, {"text": "Thus, an important research question is how do the syntactic constructions in the target language contribute to the preservation of meaning in context.", "labels": [], "entities": []}, {"text": "In this paper we investigate noun phrases based on cross-linguistic evidence and present a domain independent model for their semantic interpretation.", "labels": [], "entities": [{"text": "semantic interpretation", "start_pos": 126, "end_pos": 149, "type": "TASK", "confidence": 0.7448508441448212}]}, {"text": "We aim at uncovering the general aspects that govern the semantics of NPs in English based on a set of five Romance languages: Spanish, Italian, French, Portuguese, and Romanian.", "labels": [], "entities": []}, {"text": "The focus on Romance languages is well motivated.", "labels": [], "entities": []}, {"text": "It is mostly true that English noun phrases translate into constructions of the form NP N in Romance languages where, as we will show below, the P (preposition) varies in ways that correlate with the semantics.", "labels": [], "entities": []}, {"text": "Thus Romance languages will give us another source of evidence for disambiguating the semantic relations in English NPs.", "labels": [], "entities": []}, {"text": "We also present empirical observations on the distribution of the syntax and meaning of noun phrases on two different corpora based on two state-of-the-art classification tag sets: Lauer's set of 8 prepositions and our list of 22 semantic relations.", "labels": [], "entities": []}, {"text": "We show that various crosslingual cues can help in the NP interpretation task when employed in an SVM model.", "labels": [], "entities": [{"text": "NP interpretation task", "start_pos": 55, "end_pos": 77, "type": "TASK", "confidence": 0.9156570633252462}]}, {"text": "The results are compared against two state of the art approaches: a su-568 pervised machine learning model, Semantic Scattering (Moldovan and, and a webbased probabilistic model ().", "labels": [], "entities": []}, {"text": "The paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2 we present a summary of the previous work.", "labels": [], "entities": []}, {"text": "Section 3 lists the syntactic and semantic interpretation categories used along with observations regarding their distribution on the two different cross-lingual corpora.", "labels": [], "entities": []}, {"text": "Sections 4 and 5 present a learning model and results for the interpretation of English noun phrases.", "labels": [], "entities": [{"text": "interpretation of English noun phrases", "start_pos": 62, "end_pos": 100, "type": "TASK", "confidence": 0.8636269092559814}]}, {"text": "Finally, in Section 6 we offer some discussion and conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "The table shows that, overall the performance is better for the Europarl corpus than for CLUVI.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 64, "end_pos": 79, "type": "DATASET", "confidence": 0.9936662316322327}, {"text": "CLUVI", "start_pos": 89, "end_pos": 94, "type": "DATASET", "confidence": 0.9145027995109558}]}, {"text": "For the Baseline and SV M 1 , SS [F1 + F2] gives better results than SVM.", "labels": [], "entities": [{"text": "F1", "start_pos": 34, "end_pos": 36, "type": "METRIC", "confidence": 0.965016782283783}, {"text": "SVM", "start_pos": 69, "end_pos": 72, "type": "DATASET", "confidence": 0.8410794734954834}]}, {"text": "The inclusion of other English features (SVM [F1-F7]) adds more than 15% (with a higher increase in Europarl) for SV M 1 .", "labels": [], "entities": [{"text": "F1-F7", "start_pos": 46, "end_pos": 51, "type": "METRIC", "confidence": 0.4159194529056549}, {"text": "Europarl", "start_pos": 100, "end_pos": 108, "type": "DATASET", "confidence": 0.8854572772979736}, {"text": "SV M 1", "start_pos": 114, "end_pos": 120, "type": "DATASET", "confidence": 0.6338193019231161}]}], "tableCaptions": [{"text": " Table 2: The performance of the cross-linguistic SVM models compared against one baseline, SS model and  Lapata & Keller's unsupervised model. Accuracy (number of correctly labeled instances over the number of  instances in the test set).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 144, "end_pos": 152, "type": "METRIC", "confidence": 0.9988738894462585}]}]}