{"title": [{"text": "A Joint Statistical Model for Simultaneous Word Spacing and Spelling Error Correction for Korean", "labels": [], "entities": [{"text": "Simultaneous Word Spacing and Spelling Error Correction", "start_pos": 30, "end_pos": 85, "type": "TASK", "confidence": 0.7670941693442208}]}], "abstractContent": [{"text": "This paper presents noisy-channel based Korean preprocessor system, which corrects word spacing and typographical errors.", "labels": [], "entities": []}, {"text": "The proposed algorithm corrects both errors simultaneously.", "labels": [], "entities": []}, {"text": "Using Eojeol transition pattern dictionary and statistical data such as Eumjeol n-gram and Jaso transition probabilities, the algorithm minimizes the usage of huge word dictionaries.", "labels": [], "entities": []}], "introductionContent": [{"text": "With increasing usages of messenger and SMS, we need an efficient text normalizer that processes colloquial style sentences.", "labels": [], "entities": [{"text": "text normalizer", "start_pos": 66, "end_pos": 81, "type": "TASK", "confidence": 0.744818240404129}]}, {"text": "As in the case of general literary sentences, correcting word spacing error and spelling error is the very essential problem with colloquial style sentences.", "labels": [], "entities": [{"text": "correcting word spacing", "start_pos": 46, "end_pos": 69, "type": "TASK", "confidence": 0.8412957191467285}, {"text": "spelling error", "start_pos": 80, "end_pos": 94, "type": "METRIC", "confidence": 0.9086722731590271}]}, {"text": "In order to correct word spacing errors, many algorithms were used, which can be divided into statistical algorithms and rule-based algorithms.", "labels": [], "entities": [{"text": "word spacing", "start_pos": 20, "end_pos": 32, "type": "TASK", "confidence": 0.645742803812027}]}, {"text": "Statistical algorithms generally use character ngram (Eojeol 1 or Eumjeol 2 n-gram in Korean) or noisychannel model.", "labels": [], "entities": []}, {"text": "Rule-based algorithms are mostly heuristic algorithms that reflect linguistic knowledge () to solve word spacing problem.", "labels": [], "entities": [{"text": "word spacing problem", "start_pos": 100, "end_pos": 120, "type": "TASK", "confidence": 0.7841433882713318}]}, {"text": "Word spacing problem is treated especially in Japanese or Chinese, which does not use word boundary, or Korean, which is normally segmented into Eojeols, not into words or morphemes.", "labels": [], "entities": [{"text": "Word spacing", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.6741575002670288}]}, {"text": "The previous algorithms for spelling error correction basically use a word dictionary.", "labels": [], "entities": [{"text": "spelling error correction", "start_pos": 28, "end_pos": 53, "type": "TASK", "confidence": 0.8755061626434326}]}, {"text": "Each word in a sentence is compared to word dictionary entries, and if the word is not in the dictionary, then the system assumes that the word has spelling errors.", "labels": [], "entities": []}, {"text": "Then corrected candidate words are suggested by the system from the word dictionary, according to some metric to measure the similarity between the target word and its candidate word, such as edit-distance (.", "labels": [], "entities": []}, {"text": "But these previous algorithms have a critical limitation: They all corrected word spacing errors and spelling errors separately.", "labels": [], "entities": [{"text": "word spacing", "start_pos": 77, "end_pos": 89, "type": "TASK", "confidence": 0.6539684534072876}]}, {"text": "Word spacing algorithms define the problem as a task for determining whether to insert the delimiter between characters or not.", "labels": [], "entities": [{"text": "Word spacing", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.6979857385158539}]}, {"text": "Since the determination is made according to the characters, the algorithms cannot work if the characters have spelling errors.", "labels": [], "entities": []}, {"text": "Likewise, algorithms for solving spelling error problem cannot work well with word spacing errors.", "labels": [], "entities": [{"text": "spelling error problem", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.6542246143023173}, {"text": "word spacing", "start_pos": 78, "end_pos": 90, "type": "TASK", "confidence": 0.7317479848861694}]}, {"text": "To cope with the limitation, there is an algorithm proposed for Japanese.", "labels": [], "entities": []}, {"text": "Japanese sentence cannot be divided into words, but into chunks (bunsetsu in Japanese), like Eojeol in Korean.", "labels": [], "entities": []}, {"text": "The proposed system is for sentences recognized by OCR, and it uses character transition probabilities and POS (part of speech) tag n-gram.", "labels": [], "entities": []}, {"text": "However it needs a word dictionary and takes longtime for searching many character combinations.", "labels": [], "entities": []}, {"text": "We propose anew algorithm which can correct both word spacing error and spelling error simultaneously for Korean.", "labels": [], "entities": [{"text": "word spacing", "start_pos": 49, "end_pos": 61, "type": "TASK", "confidence": 0.6648006737232208}, {"text": "spelling error", "start_pos": 72, "end_pos": 86, "type": "METRIC", "confidence": 0.8406932353973389}]}, {"text": "This algorithm is based on noisy-channel model, which uses Jaso 3 transition probabilities and Eojeol transition probabilities to create spelling correction candidates.", "labels": [], "entities": [{"text": "spelling correction", "start_pos": 137, "end_pos": 156, "type": "TASK", "confidence": 0.8481117784976959}]}, {"text": "Candidates are increased in number by inserting the blank characters on the created candidates, which cover the spacing error correction candidates.", "labels": [], "entities": [{"text": "spacing error correction", "start_pos": 112, "end_pos": 136, "type": "TASK", "confidence": 0.5399886171023051}]}, {"text": "We find the best candidate sentence from the networks of Jaso/Eojeol candidates.", "labels": [], "entities": []}, {"text": "This method decreases the size of Eojeol transition pattern dictionary and corrects the patterns which are not in the dictionary.", "labels": [], "entities": [{"text": "Eojeol transition pattern dictionary", "start_pos": 34, "end_pos": 70, "type": "DATASET", "confidence": 0.7920776754617691}]}, {"text": "The remainder of this paper is as follows: Section 2 describes why we use Jaso transition probability for Korean.", "labels": [], "entities": []}, {"text": "Section 3 describes the proposed model in detail.", "labels": [], "entities": []}, {"text": "Section 4 provides the experiment results and analyses.", "labels": [], "entities": []}, {"text": "Finally, section 5 presents our conclusion.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used two separate Eumjeol n-grams as language models for experiments.", "labels": [], "entities": []}, {"text": "N-gram A is obtained from only training corpus and n-gram B is obtained from all training and test corpora.", "labels": [], "entities": []}, {"text": "All accuracies are measured based on Eojeol unit.", "labels": [], "entities": [{"text": "accuracies", "start_pos": 4, "end_pos": 14, "type": "METRIC", "confidence": 0.9954532384872437}, {"text": "Eojeol unit", "start_pos": 37, "end_pos": 48, "type": "DATASET", "confidence": 0.6822747886180878}]}, {"text": "shows the results of word spacing error correction only for the test corpus.", "labels": [], "entities": [{"text": "word spacing error correction", "start_pos": 21, "end_pos": 50, "type": "TASK", "confidence": 0.7046567276120186}]}], "tableCaptions": []}