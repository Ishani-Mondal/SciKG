{"title": [{"text": "Vocabulary Decomposition for Estonian Open Vocabulary Speech Recognition", "labels": [], "entities": [{"text": "Vocabulary Decomposition", "start_pos": 0, "end_pos": 24, "type": "TASK", "confidence": 0.7792966365814209}, {"text": "Estonian Open Vocabulary Speech Recognition", "start_pos": 29, "end_pos": 72, "type": "TASK", "confidence": 0.6142208099365234}]}], "abstractContent": [{"text": "Speech recognition in many morphologically rich languages suffers from a very high out-of-vocabulary (OOV) ratio.", "labels": [], "entities": [{"text": "Speech recognition", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7569682598114014}, {"text": "out-of-vocabulary (OOV) ratio", "start_pos": 83, "end_pos": 112, "type": "METRIC", "confidence": 0.8165082216262818}]}, {"text": "Earlier work has shown that vocabulary decomposition methods can practically solve this problem fora subset of these languages.", "labels": [], "entities": [{"text": "vocabulary decomposition", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.8270938992500305}]}, {"text": "This paper compares various vocabulary decomposition approaches to open vocabulary speech recognition, using Estonian speech recognition as a benchmark.", "labels": [], "entities": [{"text": "vocabulary decomposition", "start_pos": 28, "end_pos": 52, "type": "TASK", "confidence": 0.7174212634563446}, {"text": "open vocabulary speech recognition", "start_pos": 67, "end_pos": 101, "type": "TASK", "confidence": 0.648784302175045}, {"text": "Estonian speech recognition", "start_pos": 109, "end_pos": 136, "type": "TASK", "confidence": 0.6171063383420309}]}, {"text": "Comparisons are performed utilizing large models of 60000 lexical items and smaller vocabularies of 5000 items.", "labels": [], "entities": []}, {"text": "A large vocabulary model based on a manually constructed morphological tag-ger is shown to give the lowest word error rate, while the unsupervised morphology discovery method Morfessor Baseline gives marginally weaker results.", "labels": [], "entities": [{"text": "word error rate", "start_pos": 107, "end_pos": 122, "type": "METRIC", "confidence": 0.749206523100535}]}, {"text": "Only the Morfessor-based approach is shown to adequately scale to smaller vocabulary sizes.", "labels": [], "entities": []}], "introductionContent": [], "datasetContent": [{"text": "Acoustic models for Estonian ASR were trained on the Estonian Speechdat-like corpus).", "labels": [], "entities": [{"text": "Estonian ASR", "start_pos": 20, "end_pos": 32, "type": "TASK", "confidence": 0.5718348920345306}, {"text": "Estonian Speechdat-like corpus", "start_pos": 53, "end_pos": 83, "type": "DATASET", "confidence": 0.9167423645655314}]}, {"text": "This consists of spoken newspaper sentences and shorter utterances, read over a telephone by 1332 different speakers.", "labels": [], "entities": []}, {"text": "The data therefore was quite clearly articulated, but suffered from 8kHz sample rate, different microphones, channel noises and occasional background noises.", "labels": [], "entities": []}, {"text": "On top of this the speakers were selected to give a very broad coverage of different dialectal varieties of Estonian and were of different age groups.", "labels": [], "entities": []}, {"text": "For these reasons, in spite of consisting of relatively common word forms from newspaper sentences, the database can be considered challenging for ASR.", "labels": [], "entities": [{"text": "ASR", "start_pos": 147, "end_pos": 150, "type": "TASK", "confidence": 0.9832872152328491}]}, {"text": "Held-out sentences were from the same corpus used as development and evaluation set.", "labels": [], "entities": []}, {"text": "8 different sentences from 50 speakers each were used for evaluation, while sentences from 15 speakers were used for development.", "labels": [], "entities": []}, {"text": "LM scaling factor was optimized for each model separately on the development set.", "labels": [], "entities": []}, {"text": "On total over 200 hours of data from the database was used for acoustic model training, of which less than half was speech.", "labels": [], "entities": [{"text": "acoustic model training", "start_pos": 63, "end_pos": 86, "type": "TASK", "confidence": 0.7803910772005717}]}], "tableCaptions": [{"text": " Table 2. Word error rates for the models (WER %).", "labels": [], "entities": [{"text": "Word error rates", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.8638635476430258}, {"text": "WER", "start_pos": 43, "end_pos": 46, "type": "METRIC", "confidence": 0.997864305973053}]}, {"text": " Table 3. Letter error rates for the models (LER %).", "labels": [], "entities": [{"text": "Letter error rates", "start_pos": 10, "end_pos": 28, "type": "METRIC", "confidence": 0.8222466508547465}, {"text": "LER", "start_pos": 45, "end_pos": 48, "type": "METRIC", "confidence": 0.9966200590133667}]}]}