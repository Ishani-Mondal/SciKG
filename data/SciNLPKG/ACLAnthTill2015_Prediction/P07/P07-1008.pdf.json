{"title": [{"text": "Making Lexical Ontologies Functional and Context-Sensitive", "labels": [], "entities": []}], "abstractContent": [{"text": "Human categorization is neither a binary nor a context-free process.", "labels": [], "entities": []}, {"text": "Rather, some concepts are better examples of a category than others, while the criteria for category membership maybe satisfied to different degrees by different concepts in different contexts.", "labels": [], "entities": []}, {"text": "In light of these empirical facts, WordNet's static category structure appears both excessively rigid and unduly fragile for processing real texts.", "labels": [], "entities": []}, {"text": "In this paper we describe a syntagmatic, corpus-based approach to redefining WordNet's categories in a functional , gradable and context-sensitive fashion.", "labels": [], "entities": []}, {"text": "We describe how the diagnostic properties for these definitions are automatically acquired from the web, and how the increased flexibility in categorization that arises from these redefinitions offers a robust account of metaphor comprehension in the mold of Glucksberg's (2001) theory of category-inclusion.", "labels": [], "entities": []}, {"text": "Furthermore, we demonstrate how this competence with figurative categorization can effectively be governed by automatically-generated ontological constraints, also acquired from the web.", "labels": [], "entities": []}], "introductionContent": [{"text": "Linguistic variation across contexts is often symptomatic of ontological differences between contexts.", "labels": [], "entities": []}, {"text": "These observable variations can serve as valuable clues not just to the specific senses of words in context (e.g., see Pustejovsky,) but to the underlying ontological structure itself (see).", "labels": [], "entities": []}, {"text": "The most revealing variations are syntagmatic in nature, which is to say, they look beyond individual word forms to larger patterns of contiguous usage).", "labels": [], "entities": []}, {"text": "In most contexts, the similarity between chocolate, say, and a narcotic like heroin will meagerly reflect the simple ontological fact that both are kinds of substances; certainly, taxonomic measures of similarity as discussed in will capture little more than this commonality.", "labels": [], "entities": []}, {"text": "However, in a context in which the addictive properties of chocolate are very salient (e.g., an online dieting forum), chocolate is more likely to be categorized as a drug and thus be considered more similar to heroin.", "labels": [], "entities": []}, {"text": "Look, for instance, at the similar ways in which these words can be used: one can be \"chocolate-crazed\" or \"chocolate-addicted\" and suffer \"chocolate-induced\" symptoms (e.g., each of these uses can be found in the pages of Wikipedia).", "labels": [], "entities": []}, {"text": "Ina context that gives rise to these expressions, it is unsurprising that chocolate should appear altogether more similar to a harmful narcotic.", "labels": [], "entities": []}, {"text": "In this paper we computationally model this idea that language use reflects category structure.", "labels": [], "entities": []}, {"text": "As noted by De Leenheer and de, ontologies are lexical representations of concepts, so we can expect the effects of context on language use to closely reflect the effects of context on ontological structure.", "labels": [], "entities": []}, {"text": "An understanding of the linguistic effects of context, as expressed through syntagmatic patterns of word usage, should lead therefore to the design of more flexible lexical ontologies that naturally adapt to their contexts of use.", "labels": [], "entities": []}, {"text": "WordNet) is just one such lexical ontology that can benefit greatly from the added flexibility that context-sensitivity can bring.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 0, "end_pos": 7, "type": "DATASET", "confidence": 0.9500069618225098}]}, {"text": "Though comprehensive in scale and widely used, WordNet suffers from an obvious structural rigidity in which concepts are either entirely within a category or entirely outside a category: no gradation of category membership is allowed, and no contextual factors are brought to bear on criteria for membership.", "labels": [], "entities": []}, {"text": "Thus, a gun is always a weapon in WordNet while an axe is never so, despite the uses (sporting or murderous) to which each can be put.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 34, "end_pos": 41, "type": "DATASET", "confidence": 0.9721155762672424}]}, {"text": "In section two we describe a computational framework forgiving WordNet senses a functional, context-sensitive form.", "labels": [], "entities": []}, {"text": "These functional forms simultaneously represent i) an intensional definition for each word sense; ii) a structured query capable of retrieving instances of the corresponding category from a context-specific corpus; and iii) a membership function that assigns gradated scores to these instances based on available syntagmatic evidence.", "labels": [], "entities": []}, {"text": "In section three we describe how the knowledge required to automate this functional re-definition is acquired from the web and linked to WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 137, "end_pos": 144, "type": "DATASET", "confidence": 0.9745481014251709}]}, {"text": "In section four we describe how these re-definitions can produce a robust model of metaphor, before we evaluate the descriptive sufficiency of this approach in section five, comparing it to the knowledge already available within WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 229, "end_pos": 236, "type": "DATASET", "confidence": 0.9532406330108643}]}, {"text": "We conclude with some final remarks in section six.", "labels": [], "entities": []}], "datasetContent": [{"text": "The simile gathering process of section 3, abetted by Google's practice of ranking pages according to popularity, should reveal the most frequently-used comparative nouns, and thus, the most useful categories to capture in a general-purpose ontology like WordNet.", "labels": [], "entities": [{"text": "simile gathering", "start_pos": 4, "end_pos": 20, "type": "TASK", "confidence": 0.7703750431537628}, {"text": "WordNet", "start_pos": 255, "end_pos": 262, "type": "DATASET", "confidence": 0.94411700963974}]}, {"text": "But the descriptive sufficiency of these categories is not guaranteed unless the defining properties ascribed to each can be shown to be collectively rich enough, and individually salient enough, to predict how each category is perceived and applied by a language user.", "labels": [], "entities": []}, {"text": "If similes are indeed a good basis for mining the most salient and diagnostic properties of categories, we should expect the set of properties for each category to accurately predict how the category is perceived as a whole.", "labels": [], "entities": []}, {"text": "For instance, humans -unlike computers -do not generally adopt a dispassionate view of ideas, but rather tend to associate certain positive or negative feelings, or affective values, with particular ideas.", "labels": [], "entities": []}, {"text": "Unsavoury activities, people and substances generally possess a negative affect, while pleasant activities and people possess a positive affect.", "labels": [], "entities": []}, {"text": "reduces the notion of affect to a single numeric dimension, to produce a dictionary of affect that associates a numeric value in the range 1.0 (most unpleasant) to 3.0 (most pleasant) with over 8000 words in a range of syntactic categories (including adjectives, verbs and nouns).", "labels": [], "entities": []}, {"text": "Soto the extent that the adjectival properties yielded by processing similes paint an accurate picture of each category / noun-sense, we should be able to predict the affective rating of each vehicle via a weighted average of the affective ratings of the adjectival properties ascribed to these nouns (i.e., where the affect rating of each adjective contributes to the estimated rating of a noun in proportion to its frequency of co-occurrence with that noun in our simile data).", "labels": [], "entities": []}, {"text": "More specifically, we should expect that ratings estimated via these simile-derived properties should correlate well with the independent ratings contained in Whissell's dictionary.", "labels": [], "entities": [{"text": "Whissell's dictionary", "start_pos": 159, "end_pos": 180, "type": "DATASET", "confidence": 0.9087713162104288}]}, {"text": "To determine whether similes do offer the clearest perspective on a category's most salient properties, we calculate and compare this correlation using the following data sets: A.", "labels": [], "entities": []}, {"text": "Adjectives derived from annotated bona-fide (non-ironic) similes only.", "labels": [], "entities": []}, {"text": "B. Adjectives derived from all annotated similes (both ironic and non-ironic).", "labels": [], "entities": []}, {"text": "C. Adjectives derived from ironic similes only.", "labels": [], "entities": []}, {"text": "D. All adjectives used to modify a given noun in a large corpus.", "labels": [], "entities": []}, {"text": "We use over 2-gigabytes of text from the online encyclopaedia Wikipedia as our corpus.", "labels": [], "entities": []}, {"text": "E. The set of 63,935 unique property-of-noun pairings extracted via shallow-parsing from WordNet glosses in section 2, e.g., strong and black for Espresso.", "labels": [], "entities": []}, {"text": "Predictions of affective rating were made from each of these data sources and then correlated with the ratings reported in Whissell's dictionary of affect using a two-tailed Pearson test (p < 0.01).", "labels": [], "entities": []}, {"text": "As expected, property sets derived from bona-fide similes only (A) yielded the best correlation (+0.514) while properties derived from ironic similes only (C) yielded the worst (-0.243); a middling correlation coefficient of 0.347 was found for all similes together, demonstrating the fact that bona-fide similes outnumber ironic similes by a ratio of 4 to 1.", "labels": [], "entities": [{"text": "middling correlation coefficient", "start_pos": 189, "end_pos": 221, "type": "METRIC", "confidence": 0.8645785450935364}]}, {"text": "A weaker correlation of 0.15 was found using the corpus-derived adjectival modifiers for each noun (D); while this data provides quite large property sets for each noun, these properties merely reflect potential rather than intrinsic properties of each noun and so do not reveal what is most diagnostic about a category.", "labels": [], "entities": []}, {"text": "More surprisingly, property sets derived from WordNet glosses (E) are also poorly predictive, yielding a correlation with Whissell's affect ratings of just 0.278.", "labels": [], "entities": []}, {"text": "This suggests that the properties used to define categories in hand-crafted resources like WordNet are not always those that actually reflect how humans think of these categories.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 91, "end_pos": 98, "type": "DATASET", "confidence": 0.9588841199874878}]}], "tableCaptions": [{"text": " Table 1. The Likelihood of a category X accommo- dating a category Y.", "labels": [], "entities": []}]}