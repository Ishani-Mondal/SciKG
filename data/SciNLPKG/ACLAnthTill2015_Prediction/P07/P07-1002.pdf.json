{"title": [{"text": "A Discriminative Syntactic Word Order Model for Machine Translation", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 48, "end_pos": 67, "type": "TASK", "confidence": 0.7549477219581604}]}], "abstractContent": [{"text": "We present a global discriminative statistical word order model for machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 68, "end_pos": 87, "type": "TASK", "confidence": 0.8104174435138702}]}, {"text": "Our model combines syntactic movement and surface movement information, and is discriminatively trained to choose among possible word orders.", "labels": [], "entities": []}, {"text": "We show that combining discriminative training with features to detect these two different kinds of movement phenomena leads to substantial improvements in word ordering performance over strong baselines.", "labels": [], "entities": [{"text": "word ordering", "start_pos": 156, "end_pos": 169, "type": "TASK", "confidence": 0.7639278173446655}]}, {"text": "Integrating this word order model in a baseline MT system results in a 2.4 points improvement in BLEU for English to Japanese translation.", "labels": [], "entities": [{"text": "MT", "start_pos": 48, "end_pos": 50, "type": "TASK", "confidence": 0.9760621190071106}, {"text": "BLEU", "start_pos": 97, "end_pos": 101, "type": "METRIC", "confidence": 0.9992916584014893}, {"text": "English to Japanese translation", "start_pos": 106, "end_pos": 137, "type": "TASK", "confidence": 0.6919171214103699}]}], "introductionContent": [{"text": "The machine translation task can be viewed as consisting of two subtasks: predicting the collection of words in a translation, and deciding the order of the predicted words.", "labels": [], "entities": [{"text": "machine translation task", "start_pos": 4, "end_pos": 28, "type": "TASK", "confidence": 0.8076619307200114}, {"text": "predicting the collection of words in a translation", "start_pos": 74, "end_pos": 125, "type": "TASK", "confidence": 0.8175059482455254}]}, {"text": "For some language pairs, such as English and Japanese, the ordering problem is especially hard, because the target word order differs significantly from the source word order.", "labels": [], "entities": []}, {"text": "Previous work has shown that it is useful to model target language order in terms of movement of syntactic constituents in constituency trees) or dependency trees), which are obtained using a parser trained to determine linguistic constituency.", "labels": [], "entities": []}, {"text": "Alternatively, order is modelled in terms of movement of automatically induced hierarchical structure of sentences).", "labels": [], "entities": []}, {"text": "The advantages of modeling how a target language syntax tree moves with respect to a source language syntax tree are that (i) we can capture the fact that constituents move as a whole and generally respect the phrasal cohesion constraints, and (ii) we can model broad syntactic reordering phenomena, such as subject-verb-object constructions translating into subject-object-verb ones, as is generally the case for English and Japanese.", "labels": [], "entities": []}, {"text": "On the other hand, there is also significant amount of information in the surface strings of the source and target and their alignment.", "labels": [], "entities": []}, {"text": "Many state-of-the-art SMT systems do not use trees and base the ordering decisions on surface phrases ().", "labels": [], "entities": [{"text": "SMT", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.9864562749862671}]}, {"text": "In this paper we develop an order model for machine translation which makes use of both syntactic and surface information.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 44, "end_pos": 63, "type": "TASK", "confidence": 0.8120049238204956}]}, {"text": "The framework for our statistical model is as follows.", "labels": [], "entities": []}, {"text": "We assume the existence of a dependency tree for the source sentence, an unordered dependency tree for the target sentence, and a word alignment between the target and source sentences.", "labels": [], "entities": []}, {"text": "(a) shows an example of aligned source and target dependency trees.", "labels": [], "entities": []}, {"text": "Our task is to order the target dependency tree.", "labels": [], "entities": []}, {"text": "We train a statistical model to select the best order of the unordered target dependency tree.", "labels": [], "entities": []}, {"text": "An important advantage of our model is that it is global, and does not decompose the task of ordering a target sentence into a series of local decisions, as in the recently proposed order models for Machine Transition;).", "labels": [], "entities": []}, {"text": "Thus we are able to define features over complete target sentence orders, and avoid the independence assumptions made by these 9 all constraints are satisfied \"restriction\"\"condition\" TOPIC \"all\" \"satisfy\" PASSIVE-PRES: (a) A sentence pair with source dependency tree, projected target dependency tree, and word alignments.", "labels": [], "entities": [{"text": "TOPIC", "start_pos": 184, "end_pos": 189, "type": "METRIC", "confidence": 0.9873036742210388}, {"text": "word alignments", "start_pos": 307, "end_pos": 322, "type": "TASK", "confidence": 0.6959728747606277}]}, {"text": "(b) Example orders violating the target tree projectivity constraints. models.", "labels": [], "entities": []}, {"text": "Our model is discriminatively trained to select the best order (according to the BLEU measure) () of an unordered target dependency tree from the space of possible orders.", "labels": [], "entities": [{"text": "BLEU measure)", "start_pos": 81, "end_pos": 94, "type": "METRIC", "confidence": 0.9698152740796407}]}, {"text": "Since the space of all possible orders of an unordered dependency tree is factorially large, we train our model on N-best lists of possible orders.", "labels": [], "entities": []}, {"text": "These N-best lists are generated using approximate search and simpler models, as in the re-ranking approach of).", "labels": [], "entities": []}, {"text": "We first evaluate our model on the task of ordering target sentences, given correct (reference) unordered target dependency trees.", "labels": [], "entities": []}, {"text": "Our results show that combining features derived from the source and target dependency trees, distortion surface order-based features (like the distortion used in Pharaoh) and language model-like features results in a model which significantly outperforms models using only some of the information sources.", "labels": [], "entities": []}, {"text": "We also evaluate the contribution of our model to the performance of an MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 72, "end_pos": 74, "type": "TASK", "confidence": 0.9881088137626648}]}, {"text": "We integrate our order model in the MT system, by simply re-ordering the target translation sentences output by the system.", "labels": [], "entities": [{"text": "MT", "start_pos": 36, "end_pos": 38, "type": "TASK", "confidence": 0.9325084090232849}]}, {"text": "The model resulted in an improvement from 33.6 to 35.4 BLEU points in English-toJapanese translation on a computer domain.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 55, "end_pos": 59, "type": "METRIC", "confidence": 0.9988090991973877}]}], "datasetContent": [{"text": "Our experiments on ordering reference sentences use a set of 445K English sentences with their reference Japanese translations.", "labels": [], "entities": []}, {"text": "This is a subset of the  set MT-train in.", "labels": [], "entities": [{"text": "MT-train", "start_pos": 29, "end_pos": 37, "type": "DATASET", "confidence": 0.7229344248771667}]}, {"text": "The sentences were annotated with alignment (using GIZA++ () and syntactic dependency structures of the source and target, obtained as described in Section 2.", "labels": [], "entities": []}, {"text": "Japanese POS tags were assigned by an automatic POS tagger, which is a local classifier not using tag sequence information.", "labels": [], "entities": [{"text": "POS tagger", "start_pos": 48, "end_pos": 58, "type": "TASK", "confidence": 0.5950187295675278}]}, {"text": "We used 400K sentence pairs from the complete set to train the first pass models: the language model was trained on 400K sentences, and the local tree order model was trained on 100K of them.", "labels": [], "entities": []}, {"text": "We generated N-best target tree orders for the rest of the data (45K sentence pairs), and used it for training and evaluating the re-ranking model.", "labels": [], "entities": []}, {"text": "The re-ranking model was trained on 44K sentence pairs.", "labels": [], "entities": []}, {"text": "All models were evaluated on the remaining 1,000 sentence pairs set, which is the set Ref-test in.", "labels": [], "entities": [{"text": "Ref-test", "start_pos": 86, "end_pos": 94, "type": "METRIC", "confidence": 0.742462694644928}]}, {"text": "The top part of presents the 1-best BLEU scores (actual performance) and 30-best oracle BLEU scores of the first-pass models and their log-linear combination, described in Section 4.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 36, "end_pos": 40, "type": "METRIC", "confidence": 0.9891552329063416}, {"text": "BLEU", "start_pos": 88, "end_pos": 92, "type": "METRIC", "confidence": 0.9840508103370667}]}, {"text": "We can see that the combination of the language model and the local tree order model outperformed either model by a large margin.", "labels": [], "entities": []}, {"text": "This indicates that combining syntactic (from the LTOM model) and surfacebased (from the language model) information is very effective even at this stage of selecting N-best orders for re-ranking.", "labels": [], "entities": []}, {"text": "According to the 30-best oracle performance of the combined model LTOM+LM, 98.0 BLEU is the upper bound on performance of our reranking approach.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 80, "end_pos": 84, "type": "METRIC", "confidence": 0.9884294271469116}]}, {"text": "The bottom part of the table shows the performance of the global log-linear model, when features in addition to the scores from the two first-pass models are added to the model.", "labels": [], "entities": []}, {"text": "Adding: Performance of the first-pass order models and 30-best oracle performance, followed by performance of re-ranking model for different feature sets.", "labels": [], "entities": []}, {"text": "Results are on reference sentences.", "labels": [], "entities": []}, {"text": "the Pharaoh displacement feature to the displacement feature we illustrated in.", "labels": [], "entities": []}, {"text": "We can see that the Pharaoh displacement feature improves performance of the baseline by .34 points, whereas our displacement feature improves performance by nearly 1 BLEU point.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 167, "end_pos": 171, "type": "METRIC", "confidence": 0.9991820454597473}]}, {"text": "Concatenating the DISP feature with the POS tag of the source word aligned to the current word improved performance slightly.", "labels": [], "entities": []}, {"text": "The results show that surface movement features (i.e. the DISP feature) improve the performance of a model using syntactic-movement features (i.e. the LTOM model).", "labels": [], "entities": []}, {"text": "Additionally, adding part-ofspeech information from both languages in combination with displacement, and using a higher order on the displacement features was useful.", "labels": [], "entities": []}, {"text": "The performance of our best model, which included all information sources, is 94.5 BLEU points, which is a 35% improvement over the fist-pass models, relative to the upper bound.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 83, "end_pos": 87, "type": "METRIC", "confidence": 0.9990252256393433}]}, {"text": "We apply our model to machine translation by reordering the translation produced by a baseline MT system.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.7909144461154938}, {"text": "MT", "start_pos": 95, "end_pos": 97, "type": "TASK", "confidence": 0.953926682472229}]}, {"text": "Our baseline MT system constructs, for each target translation hypothesis, a target dependency tree.", "labels": [], "entities": [{"text": "MT", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.9719104766845703}]}, {"text": "Thus we can apply our model to MT output in exactly the same way as for reference sentences, but using much noisier input: a source sentence with a dependency tree, word alignment and an unordered target dependency tree as the example shown in  target words and/or will not be projective with respect to the best possible order.", "labels": [], "entities": [{"text": "MT output", "start_pos": 31, "end_pos": 40, "type": "TASK", "confidence": 0.8965337574481964}, {"text": "word alignment", "start_pos": 165, "end_pos": 179, "type": "TASK", "confidence": 0.6835554242134094}]}, {"text": "The baseline MT system was trained on the MT-train dataset described in.", "labels": [], "entities": [{"text": "MT", "start_pos": 13, "end_pos": 15, "type": "TASK", "confidence": 0.973016619682312}, {"text": "MT-train dataset", "start_pos": 42, "end_pos": 58, "type": "DATASET", "confidence": 0.8251620829105377}]}, {"text": "The test set for the MT experiment is a 1K sentences set from the same domain (shown as MT-test in the table).", "labels": [], "entities": [{"text": "MT experiment", "start_pos": 21, "end_pos": 34, "type": "TASK", "confidence": 0.8995949923992157}, {"text": "MT-test", "start_pos": 88, "end_pos": 95, "type": "DATASET", "confidence": 0.8334714770317078}]}, {"text": "The weights in the linear model used by the baseline SMT system were tuned on a separate development set.", "labels": [], "entities": [{"text": "SMT", "start_pos": 53, "end_pos": 56, "type": "TASK", "confidence": 0.9819031953811646}]}, {"text": "shows the performance of the first-pass models in the top part, and the performance of our 15: Performance of the first pass order models and 30-best oracle performance, followed by performance of re-ranking model for different feature sets.", "labels": [], "entities": []}, {"text": "re-ranking model in the bottom part.", "labels": [], "entities": []}, {"text": "The first row of the table shows the performance of the baselinelect from the space of orders projective with respect to a target dependency tree.", "labels": [], "entities": []}, {"text": "We investigated a combination of features modeling surface movement and syntactic movement phenomena and showed that these two information sources are complementary and their combination is powerful.", "labels": [], "entities": []}, {"text": "Our results on ordering MT output and reference sentences were very encouraging.", "labels": [], "entities": [{"text": "MT output", "start_pos": 24, "end_pos": 33, "type": "TASK", "confidence": 0.8206841349601746}]}, {"text": "We obtained substantial improvement by the simple method of post-processing the 1-best MT output to re-order the proposed translation.", "labels": [], "entities": []}, {"text": "In the future, we would like to explore tighter integration of our order model with the SMT system and to develop more accurate algorithms for constructing projective target dependency trees in translation.", "labels": [], "entities": [{"text": "SMT", "start_pos": 88, "end_pos": 91, "type": "TASK", "confidence": 0.9761978983879089}]}], "tableCaptions": [{"text": " Table 1: Performance of a tri-gram language model  on ordering reference and MT output sentences: un- constrained or subject to target tree projectivity con- straints.", "labels": [], "entities": [{"text": "MT output sentences", "start_pos": 78, "end_pos": 97, "type": "TASK", "confidence": 0.8944582939147949}]}, {"text": " Table 2: Performance of the first-pass order models  and 30-best oracle performance, followed by perfor- mance of re-ranking model for different feature sets.  Results are on reference sentences.", "labels": [], "entities": []}, {"text": " Table 4: Performance of the first pass order models  and 30-best oracle performance, followed by perfor- mance of re-ranking model for different feature sets.  Results are in MT.", "labels": [], "entities": [{"text": "MT", "start_pos": 176, "end_pos": 178, "type": "DATASET", "confidence": 0.5528554320335388}]}]}