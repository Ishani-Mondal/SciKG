{"title": [{"text": "Machine Translation by Triangulation: Making Effective Use of Multi-Parallel Corpora", "labels": [], "entities": [{"text": "Machine Translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8041558861732483}]}], "abstractContent": [{"text": "Current phrase-based SMT systems perform poorly when using small training sets.", "labels": [], "entities": [{"text": "SMT", "start_pos": 21, "end_pos": 24, "type": "TASK", "confidence": 0.8426232933998108}]}, {"text": "This is a consequence of unreliable translation estimates and low coverage over source and target phrases.", "labels": [], "entities": []}, {"text": "This paper presents a method which alleviates this problem by exploiting multiple translations of the same source phrase.", "labels": [], "entities": []}, {"text": "Central to our approach is triangula-tion, the process of translating from a source to a target language via an intermediate third language.", "labels": [], "entities": []}, {"text": "This allows the use of a much wider range of parallel corpora for training , and can be combined with a standard phrase-table using conventional smoothing methods.", "labels": [], "entities": []}, {"text": "Experimental results demonstrate BLEU improvements for triangulated models over a standard phrase-based system.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 33, "end_pos": 37, "type": "METRIC", "confidence": 0.9977205395698547}]}], "introductionContent": [{"text": "Statistical machine translation ( has seen many improvements in recent years, most notably the transition from word-to phrase-based models ( . Modern SMT systems are capable of producing high quality translations when provided with large quantities of training data.", "labels": [], "entities": [{"text": "Statistical machine translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.7040862441062927}, {"text": "SMT", "start_pos": 150, "end_pos": 153, "type": "TASK", "confidence": 0.9838035106658936}]}, {"text": "With only a small training sample, the translation output is often inferior to the output from using larger corpora because the translation algorithm must rely on more sparse estimates of phrase frequencies and must also 'back-off' to smaller sized phrases.", "labels": [], "entities": []}, {"text": "This often leads to poor choices of target phrases and reduces the coherence of the output.", "labels": [], "entities": []}, {"text": "Unfortunately, parallel corpora are not readily available in large quantities, except fora small subset of the world's languages (see for discussion), therefore limiting the potential use of current SMT systems.", "labels": [], "entities": [{"text": "SMT", "start_pos": 199, "end_pos": 202, "type": "TASK", "confidence": 0.9920171499252319}]}, {"text": "In this paper we provide a means for obtaining more reliable translation frequency estimates from small datasets.", "labels": [], "entities": []}, {"text": "We make use of multi-parallel corpora (sentence aligned parallel texts over three or more languages).", "labels": [], "entities": []}, {"text": "Such corpora are often created by international organisations, the United Nations (UN) being a prime example.", "labels": [], "entities": []}, {"text": "They present a challenge for current SMT systems due to their relatively moderate size and domain variability (examples of UN texts include policy documents, proceedings of meetings, letters, etc.).", "labels": [], "entities": [{"text": "SMT", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9941889047622681}]}, {"text": "Our method translates each target phrase, t, first to an intermediate language, i, and then into the source language, s.", "labels": [], "entities": []}, {"text": "We call this two-stage translation process triangulation).", "labels": [], "entities": []}, {"text": "We present a probabilistic formulation through which we can estimate the desired phrase translation distribution (phrase-table) by marginalisation, p(s|t) = i p(s, i|t).", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 81, "end_pos": 99, "type": "TASK", "confidence": 0.7208156287670135}]}, {"text": "As with conventional smoothing methods (), triangulation increases the robustness of phrase translation estimates.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 85, "end_pos": 103, "type": "TASK", "confidence": 0.7655830681324005}]}, {"text": "In contrast to smoothing, our method alleviates data sparseness by exploring additional multiparallel data rather than adjusting the probabilities of existing data.", "labels": [], "entities": []}, {"text": "Importantly, triangulation provides us with separately estimated phrase-tables which could be further smoothed to provide more reliable distributions.", "labels": [], "entities": []}, {"text": "Moreover, the triangulated phrase-tables can be easily combined with the standard sourcetarget phrase-table, thereby improving the coverage over unseen source phrases.", "labels": [], "entities": []}, {"text": "As an example, consider which shows the coverage of unigrams and larger n-gram phrases when using a standard source target phrase-table, a triangulated phrase-table with one (it) and nine languages (all), and a combination of standard and triangulated phrase-tables (all+standard).", "labels": [], "entities": []}, {"text": "The phrases were harvested from a small French-English bitext 728 and evaluated against a test set.", "labels": [], "entities": [{"text": "French-English bitext 728", "start_pos": 40, "end_pos": 65, "type": "DATASET", "confidence": 0.7741425037384033}]}, {"text": "Although very few small phrases are unknown, the majority of larger phrases are unseen.", "labels": [], "entities": []}, {"text": "The Italian and all results show that triangulation alone can provide similar or improved coverage compared to the standard sourcetarget model; further improvement is achieved by combining the triangulated and standard models (all+standard).", "labels": [], "entities": [{"text": "coverage", "start_pos": 90, "end_pos": 98, "type": "METRIC", "confidence": 0.9582688808441162}]}, {"text": "These models and datasets will be described in detail in Section 3.", "labels": [], "entities": []}, {"text": "We also demonstrate that triangulation can be used on its own, that is without a source-target distribution, and still yield acceptable translation output.", "labels": [], "entities": []}, {"text": "This is particularly heartening, as it provides a means of translating between the many \"low density\" language pairs for which we don't yet have a source-target bitext.", "labels": [], "entities": [{"text": "translating", "start_pos": 59, "end_pos": 70, "type": "TASK", "confidence": 0.9724538922309875}]}, {"text": "This allows SMT to be applied to a much larger set of language pairs than was previously possible.", "labels": [], "entities": [{"text": "SMT", "start_pos": 12, "end_pos": 15, "type": "TASK", "confidence": 0.9957703948020935}]}, {"text": "In the following section we provide an overview of related work.", "labels": [], "entities": []}, {"text": "Section 3 introduces a generative formulation of triangulation.", "labels": [], "entities": [{"text": "generative", "start_pos": 23, "end_pos": 33, "type": "TASK", "confidence": 0.9694920778274536}]}, {"text": "We present our evaluation framework in Section 4 and results in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used the Europarl corpus () for experimentation.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 12, "end_pos": 27, "type": "DATASET", "confidence": 0.9921462833881378}]}, {"text": "This corpus consists of about 700,000 sentences of parliamentary proceedings from the European Union in eleven European languages.", "labels": [], "entities": []}, {"text": "We present results on the full corpus fora range of language pairs.", "labels": [], "entities": []}, {"text": "In addition, we have created smaller parallel corpora by sub-sampling 10,000 sentence bitexts for each language pair.", "labels": [], "entities": []}, {"text": "These corpora are likely to have minimal overlap -about 1.5% of the sentences will be shared between each pair.", "labels": [], "entities": []}, {"text": "However, the phrasal overlap is much greater (10 to 20%), which allows for triangulation using these common phrases.", "labels": [], "entities": [{"text": "phrasal overlap", "start_pos": 13, "end_pos": 28, "type": "METRIC", "confidence": 0.8297031223773956}]}, {"text": "This training setting was chosen to simulate translating to or from a \"low density\" language, where only a few small independently sourced parallel corpora are available.", "labels": [], "entities": []}, {"text": "These bitexts were used for direct translation and triangulation.", "labels": [], "entities": [{"text": "direct translation", "start_pos": 28, "end_pos": 46, "type": "TASK", "confidence": 0.6019418388605118}]}, {"text": "All experimental results were evaluated on the ACL/WMT 2005 3 set of 2,000 sentences, and are reported in BLEU percentage-points.", "labels": [], "entities": [{"text": "ACL/WMT 2005 3 set of 2,000 sentences", "start_pos": 47, "end_pos": 84, "type": "DATASET", "confidence": 0.9463608198695712}, {"text": "BLEU", "start_pos": 106, "end_pos": 110, "type": "METRIC", "confidence": 0.9951518774032593}]}, {"text": "The evaluation of our method was motivated by three questions: (1) How do different training requirements affect the performance of the triangulated models presented in this paper?", "labels": [], "entities": []}, {"text": "We expect performance gains with triangulation on small and moderate datasets.", "labels": [], "entities": []}, {"text": "triangulated phrase-table with the standard sourcetarget one.", "labels": [], "entities": []}, {"text": "This is desired in order to compensate for the noise incurred by the triangulation process.", "labels": [], "entities": []}, {"text": "We used two combination methods, namely linear interpolation (see) and a weighted geometric mean (see).", "labels": [], "entities": []}, {"text": "reports the results for two translation tasks when triangulating with a single language (es) using three different feature sets, each with different translation features.", "labels": [], "entities": []}, {"text": "The interpolation model uses uniform linear interpolation to merge the standard and triangulated phrase-tables.", "labels": [], "entities": []}, {"text": "Non-uniform mixtures did not provide consistent gains, although, as expected, biasing towards the standard phrasetable was more effective than against.", "labels": [], "entities": []}, {"text": "The indicator model uses the same interpolated distribution along with a series of 0-1 indicator features to identify the source of each event, i.e., if each (s, t) pair is present in phrase-table j.", "labels": [], "entities": []}, {"text": "We also tried per-context features with similar results.", "labels": [], "entities": []}, {"text": "The separate model has a separate feature for each phrase-table.", "labels": [], "entities": []}, {"text": "All three feature sets improve over the standard source-target system, while the interpolated features provided the best overall performance.", "labels": [], "entities": []}, {"text": "The relatively poorer performance of the separate model is perhaps surprising, as it is able to differentially weight the component distributions; this is probably due to MERT not properly handling the larger feature sets.", "labels": [], "entities": [{"text": "MERT", "start_pos": 171, "end_pos": 175, "type": "DATASET", "confidence": 0.6763759255409241}]}, {"text": "In all subsequent experiments we report results using linear interpolation.", "labels": [], "entities": []}, {"text": "As a proof of concept, we first assessed the effect of triangulation on corpora consisting of 10,000 sentence bitexts.", "labels": [], "entities": []}, {"text": "We expect triangulation to deliver performance gains on small corpora, since a large number of phrase-table entries will be unseen.", "labels": [], "entities": []}, {"text": "In each entry shows the BLEU score when using the standard phrase-table and the absolute improvement when using triangulation.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 24, "end_pos": 34, "type": "METRIC", "confidence": 0.9807494580745697}]}, {"text": "Here we have used three languages for triangulation (it \u222a {de, en, es, fr}\\{s, t}).", "labels": [], "entities": []}, {"text": "The source-target languages were chosen so as to mirror the evaluation setup of NAACL/WMT.", "labels": [], "entities": [{"text": "NAACL/WMT", "start_pos": 80, "end_pos": 89, "type": "DATASET", "confidence": 0.8286479115486145}]}, {"text": "The translation tasks range 732  from easy (es \u2192 fr) to very hard (de \u2192 en).", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9710081219673157}]}, {"text": "In all cases triangulation resulted in an improvement in translation quality, with the highest gains observed for the most difficult tasks (to and from German).", "labels": [], "entities": []}, {"text": "For these tasks the standard systems have poor coverage (due in part to the sizeable vocabulary of German phrases) and therefore the gain can be largely explained by the additional coverage afforded by the triangulated phrase-tables.", "labels": [], "entities": [{"text": "coverage", "start_pos": 47, "end_pos": 55, "type": "METRIC", "confidence": 0.9721673130989075}]}, {"text": "To test whether triangulation can also improve performance of larger corpora we ran six separate translation tasks on the full Europarl corpus.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 127, "end_pos": 142, "type": "DATASET", "confidence": 0.9897560477256775}]}, {"text": "The results are presented in, fora single triangulation language used alone (triang) or uniformly interpolated with the standard phrase-table (interp).", "labels": [], "entities": []}, {"text": "These results show that triangulation can produce high quality translations on its own, which is noteworthy, as it allows for SMT between a much larger set of language pairs.", "labels": [], "entities": [{"text": "SMT", "start_pos": 126, "end_pos": 129, "type": "TASK", "confidence": 0.996274471282959}]}, {"text": "Using triangulation in conjunction with the standard phrase-table improved over the standard system inmost instances, and only degraded performance once.", "labels": [], "entities": []}, {"text": "The improvement is largest for the German tasks which can be explained by triangulation providing better robustness to noisy alignments (which are often quite poor for German) and better estimates of low-count events.", "labels": [], "entities": []}, {"text": "The difficulty of aligning German with the other languages is apparent from the Giza++ perplexity: the final Model 4 perplexities for German are quite high, as much as double the perplexity for more easily aligned language pairs (e.g., Spanish-French).", "labels": [], "entities": []}, {"text": "shows the effect of triangulation on different sized corpora for the language pair fr \u2192 en.", "labels": [], "entities": []}, {"text": "It presents learning curves for the standard system and a triangulated system using one language (es).", "labels": [], "entities": []}, {"text": "As can be seen, gains from triangulation only diminish slightly for larger training corpora, and that task standard interm triang interp    the purely triangulated models have very competitive performance.", "labels": [], "entities": []}, {"text": "The gain from interpolation with a triangulated model is roughly equivalent to having twice as much training data.", "labels": [], "entities": []}, {"text": "Finally, notice that triangulation may benefit when the sentences in each bitext are drawn from the same source, in that there are no unseen 'intermediate' phrases, and therefore (1) can be easily evaluated.", "labels": [], "entities": []}, {"text": "We investigate this by examining the robustness of our method in the face of disjoint bitexts.", "labels": [], "entities": []}, {"text": "The concepts contained in each bitext will be more varied, potentially leading to better coverage of the target language.", "labels": [], "entities": []}, {"text": "In lieu of a study on different domain bitexts which we plan for the future, we bisected the Europarl corpus for fr \u2192 en, triangulating with Spanish.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 93, "end_pos": 108, "type": "DATASET", "confidence": 0.9904095530509949}]}, {"text": "The triangulated models were presented with fr-es and es-en bitexts drawn from either the same half of the corpus or from different halves, resulting in scores of 28.37 and 28.13, respectively.", "labels": [], "entities": []}, {"text": "These results indicate that triangulation is effective for disjoint bitexts, although ideally we would test this with independently sourced parallel texts.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Different feature sets used with the 10K training  corpora, using a single language (es) for triangulation. The  columns refer to standard, uniform interpolation, interpolation  with 0-1 indicator features, and separate phrase-tables, respec- tively.", "labels": [], "entities": []}, {"text": " Table 2: BLEU improvements over the standard phrase-table  (top) when interpolating with three triangulated phrase-tables  (bottom) on the small training sample.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.9989757537841797}]}, {"text": " Table 3: Results on the full training set showing triangulation  with a single language, both alone (triang) and alongside a stan- dard model (interp).", "labels": [], "entities": []}, {"text": " Table 4. The coverage over  source and target phrases is much higher in the stan- dard table than the triangulated tables, which reflects  the reduced ability of triangulation to extract large  phrases -despite the large increase in the num- ber of events. The table also shows the overlapping  probability mass which measures the sum of prob- ability in one", "labels": [], "entities": [{"text": "coverage", "start_pos": 14, "end_pos": 22, "type": "METRIC", "confidence": 0.9725359678268433}]}, {"text": " Table 4: Comparative statistics of the standard triangulated table  on fr \u2192 en using the full training set and Spanish as an inter- mediate language.", "labels": [], "entities": []}]}