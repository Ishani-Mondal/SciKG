{"title": [{"text": "Coordinate Noun Phrase Disambiguation in a Generative Parsing Model", "labels": [], "entities": [{"text": "Coordinate Noun Phrase Disambiguation", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.5664218664169312}]}], "abstractContent": [{"text": "In this paper we present methods for improving the disambiguation of noun phrase (NP) coordination within the framework of a lexicalised history-based parsing model.", "labels": [], "entities": [{"text": "disambiguation of noun phrase (NP) coordination", "start_pos": 51, "end_pos": 98, "type": "TASK", "confidence": 0.68363481387496}]}, {"text": "As well as reducing noise in the data, we look at modelling two main sources of information for disambiguation: symmetry in conjunct structure, and the dependency between con-junct lexical heads.", "labels": [], "entities": [{"text": "symmetry", "start_pos": 112, "end_pos": 120, "type": "METRIC", "confidence": 0.9744014143943787}]}, {"text": "Our changes to the base-line model result in an increase in NP coordination dependency f-score from 69.9% to 73.8%, which represents a relative reduction in f-score error of 13%.", "labels": [], "entities": [{"text": "NP coordination dependency f-score", "start_pos": 60, "end_pos": 94, "type": "METRIC", "confidence": 0.6457719802856445}, {"text": "f-score error", "start_pos": 157, "end_pos": 170, "type": "METRIC", "confidence": 0.8482434153556824}]}], "introductionContent": [{"text": "Coordination disambiguation is a relatively little studied area, yet the correct bracketing of coordination constructions is one of the most difficult problems for natural language parsers.", "labels": [], "entities": [{"text": "Coordination disambiguation", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8703592121601105}]}, {"text": "In the Collins parser, for example, dependencies involving coordination achieve an f-score as low as 61.8%, by far the worst performance of all dependency types.", "labels": [], "entities": [{"text": "Collins", "start_pos": 7, "end_pos": 14, "type": "DATASET", "confidence": 0.9562479853630066}, {"text": "f-score", "start_pos": 83, "end_pos": 90, "type": "METRIC", "confidence": 0.9685145020484924}]}, {"text": "Take the phrase busloads of executives and their wives (taken from the WSJ treebank).", "labels": [], "entities": [{"text": "WSJ treebank", "start_pos": 71, "end_pos": 83, "type": "DATASET", "confidence": 0.9860109984874725}]}, {"text": "The coordinating conjunction (CC) and and the noun phrase their wives could attach to the noun phrase executives, as illustrated in Tree 1,.", "labels": [], "entities": []}, {"text": "Alternatively, their wives could be incorrectly conjoined to the noun phrase busloads of executives as in Tree 2,.", "labels": [], "entities": []}, {"text": "* Now at the National Centre for Language Technology, Dublin City University, Ireland.", "labels": [], "entities": [{"text": "National Centre", "start_pos": 13, "end_pos": 28, "type": "DATASET", "confidence": 0.9303141236305237}, {"text": "Dublin City University", "start_pos": 54, "end_pos": 76, "type": "DATASET", "confidence": 0.8803501129150391}]}, {"text": "As with PP attachment, most previous attempts at tackling coordination as a subproblem of parsing have treated it as a separate task to parsing and it is not always obvious how to integrate the methods proposed for disambiguation into existing parsing models.", "labels": [], "entities": [{"text": "PP attachment", "start_pos": 8, "end_pos": 21, "type": "TASK", "confidence": 0.9132093787193298}]}, {"text": "We therefore approach coordination disambiguation, not as a separate task, but from within the framework of a generative parsing model.", "labels": [], "entities": [{"text": "coordination disambiguation", "start_pos": 22, "end_pos": 49, "type": "TASK", "confidence": 0.769045352935791}, {"text": "generative parsing", "start_pos": 110, "end_pos": 128, "type": "TASK", "confidence": 0.892804890871048}]}, {"text": "As noun phrase coordination accounts for over 50% of coordination dependency error in our baseline model we focus on NP coordination.", "labels": [], "entities": [{"text": "noun phrase coordination", "start_pos": 3, "end_pos": 27, "type": "TASK", "confidence": 0.6078498065471649}, {"text": "NP coordination", "start_pos": 117, "end_pos": 132, "type": "TASK", "confidence": 0.837267130613327}]}, {"text": "Using a model based on the generative parsing model of) Model 1, we attempt to improve the ability of the parsing model to make the correct coordination decisions.", "labels": [], "entities": [{"text": "generative parsing", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.9269771873950958}]}, {"text": "This is done in the context of parse reranking, where the n-best parses output from Bikel's parser) are reranked according to a generative history-based model.", "labels": [], "entities": [{"text": "parse reranking", "start_pos": 31, "end_pos": 46, "type": "TASK", "confidence": 0.935701459646225}]}, {"text": "In Section 2 we summarise previous work on coordination disambiguation.", "labels": [], "entities": [{"text": "coordination disambiguation", "start_pos": 43, "end_pos": 70, "type": "TASK", "confidence": 0.9120056927204132}]}, {"text": "There is often a considerable bias toward symmetry in the syntactic structure of two conjuncts and in Section 3 we introduce new parameter classes to allow the model to prefer symmetry in conjunct structure.", "labels": [], "entities": []}, {"text": "Section 4 is concerned with modelling the dependency between conjunct head words and begins by looking at how the different handling of coordination in noun phrases and base noun phrases (NPB) affects coordination disambiguation.", "labels": [], "entities": []}, {"text": "We look at how we might improve the model's handling of coordinate head-head dependencies by altering the model so that a common parameter class is used for coordinate word probability estimation in both NPs and NPBs.", "labels": [], "entities": [{"text": "coordinate word probability estimation", "start_pos": 157, "end_pos": 195, "type": "TASK", "confidence": 0.573770672082901}]}, {"text": "In Section 4.2 we focus on improving the estimation of this parameter class by incorporating BNC data, and a measure of word similarity based on vector cosine similarity, to reduce data sparseness.", "labels": [], "entities": [{"text": "BNC data", "start_pos": 93, "end_pos": 101, "type": "DATASET", "confidence": 0.667589470744133}]}, {"text": "In Section 5 we suggest anew head-finding rule for NPBs so that the lexicalisation process for coordinate NPBs is more similar to that of other NPs.", "labels": [], "entities": []}, {"text": "Section 6 examines inconsistencies in the annotation of coordinate NPs in the Penn Treebank which can lead to errors in coordination disambiguation.", "labels": [], "entities": [{"text": "Penn Treebank", "start_pos": 78, "end_pos": 91, "type": "DATASET", "confidence": 0.9952287673950195}]}, {"text": "We show how some coordinate noun phrase inconsistencies can be automatically detected and cleaned from the data sets.", "labels": [], "entities": []}, {"text": "Section 7 details how the model is evaluated, presents the experiments made and gives a breakdown of results.", "labels": [], "entities": []}], "datasetContent": [{"text": "We use a parsing model similar to that described in which is based on) Model 1 and uses k-NN for parameter estimation.", "labels": [], "entities": []}, {"text": "The n-best output from Bikel's parser is reranked according to this k-NN parsing model, which achieves an f-score of 89.4% on section 23.", "labels": [], "entities": []}, {"text": "For the coordination experiments, sections 02 to 21 are used for training, section 23 for testing and the remaining sections for validation.", "labels": [], "entities": []}, {"text": "Results are for sentences containing 40 words or less.", "labels": [], "entities": []}, {"text": "As outlined in Section 6, the treebank guidelines are somewhat ambiguous as to the appropriate bracketing for coordinate NPs which consist entirely of proper nouns.", "labels": [], "entities": []}, {"text": "We therefore do not include, in the coordination test and validation sets, coordinate NPs wherein the gold standard NP the leaf nodes consist entirely of proper nouns (or CCs or commas).", "labels": [], "entities": []}, {"text": "In do-ing so we hope to avoid a situation whereby the success of the model is measured in part by how well it can predict the often inconsistent bracketing decisions made fora particular portion of the treebank.", "labels": [], "entities": []}, {"text": "In addition, and for the same reasons, if a gold standard tree is inconsistent with the guidelines in either of the following two ways the tree is not used when calculating coordinate precision and recall of the model: the gold tree is a noun phrase which ends with the sequence CC/non-nominal modifier/noun; the gold tree is a structured coordinate noun phrase where each word in the noun phrase is a noun.", "labels": [], "entities": [{"text": "precision", "start_pos": 184, "end_pos": 193, "type": "METRIC", "confidence": 0.7960861325263977}, {"text": "recall", "start_pos": 198, "end_pos": 204, "type": "METRIC", "confidence": 0.9978725910186768}]}, {"text": "Call these inconsistencies type a and type b respectively.", "labels": [], "entities": []}, {"text": "This left us with a coordination validation set consisting of 1064 coordinate noun phrases and a test set of 416 coordinate NPs from section 23.", "labels": [], "entities": []}, {"text": "A coordinate phrase was deemed correct if the parent constituent label, and the two conjunct node labels (at level 0) match those in the gold subtree and if, in addition, each of the conjunct head words are the same in both test and gold tree.", "labels": [], "entities": []}, {"text": "This follows the definition of a coordinate dependency in).", "labels": [], "entities": []}, {"text": "Based on these criteria, the baseline f-scores for test and validation set were 69.1% and 67.1% respectively.", "labels": [], "entities": []}, {"text": "The coordination f-score for the oracle trees on section 23 is 83.56%.", "labels": [], "entities": [{"text": "coordination f-score", "start_pos": 4, "end_pos": 24, "type": "METRIC", "confidence": 0.9648706316947937}]}, {"text": "In other words: if an 'oracle' were to choose from each set of n-best trees the tree that maximised constituent precision and recall, then the resulting set of oracle trees would have a NP coordination dependency f-score of 83.56%.", "labels": [], "entities": [{"text": "precision", "start_pos": 112, "end_pos": 121, "type": "METRIC", "confidence": 0.9651567935943604}, {"text": "recall", "start_pos": 126, "end_pos": 132, "type": "METRIC", "confidence": 0.9948952794075012}, {"text": "NP coordination dependency f-score", "start_pos": 186, "end_pos": 220, "type": "METRIC", "confidence": 0.5802904218435287}]}, {"text": "For the validation set the oracle trees coordination dependency f-score is 82.47%.", "labels": [], "entities": [{"text": "coordination dependency f-score", "start_pos": 40, "end_pos": 71, "type": "METRIC", "confidence": 0.8602829376856486}]}, {"text": "We first eliminated from the training set all coordinate noun phrase subtrees, of type a and type b described in Section 7.", "labels": [], "entities": []}, {"text": "The effect of this on the validation set is outlined in, step 2.", "labels": [], "entities": [{"text": "validation", "start_pos": 26, "end_pos": 36, "type": "TASK", "confidence": 0.960791289806366}]}, {"text": "For the new parameter class in (1) we found that the best results occurred when it was used only in conjuncts of depth 1 and 2, although the case base for this parameter class contained head events from all post-CC conjunct depths.", "labels": [], "entities": []}, {"text": "Parameter class (2) was used for predicting POS tags at level 1 in right-ofhead conjuncts, although again the sample contained  events from all depths.", "labels": [], "entities": [{"text": "Parameter class (", "start_pos": 0, "end_pos": 17, "type": "METRIC", "confidence": 0.9550837278366089}, {"text": "predicting POS tags", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.7567258278528849}]}, {"text": "For the P coordW ord parameter class we extracted 9961 coordinate noun pairs from the WSJ training set and 815,323 pairs from the BNC.", "labels": [], "entities": [{"text": "WSJ training set", "start_pos": 86, "end_pos": 102, "type": "DATASET", "confidence": 0.9503482381502787}, {"text": "BNC", "start_pos": 130, "end_pos": 133, "type": "DATASET", "confidence": 0.9635608792304993}]}, {"text": "As pairs are considered symmetric this resulted in a total of 1,650,568 coordinate noun events.", "labels": [], "entities": []}, {"text": "The term weights for the word vectors were dampened co-occurrence counts, of the form: 1 + log(count).", "labels": [], "entities": []}, {"text": "For the estimation of P sim (n i |n j ) we found it too computationally expensive to calculate similarity measures between n j and each word token collected.", "labels": [], "entities": []}, {"text": "The best results were obtained when the neighbourhood of n j was taken to be the k-nearest neighbours of n j from among the set of word that had previously occurred in a coordination pattern with n j , where k is 1000.", "labels": [], "entities": []}, {"text": "shows the effect of the P coordW ord parameter class estimated from WSJ data only (step 5), with the addition of BNC data (step 6) and finally with the word similarity measure (step 7).", "labels": [], "entities": [{"text": "WSJ data", "start_pos": 68, "end_pos": 76, "type": "DATASET", "confidence": 0.9392971098423004}, {"text": "BNC", "start_pos": 113, "end_pos": 116, "type": "METRIC", "confidence": 0.8453613519668579}]}, {"text": "The result of these experiments, as well as that involving the change in the head-finding heuristics, outlined in Section 5, was an increase in coordinate noun phrase f-score from 69.9% to 73.8% on the test set.", "labels": [], "entities": []}, {"text": "This represents a 13% relative reduction in coordinate f-score error over the baseline, and, using McNemar's test for significance, is significant at the 0.05 level (p = 0.034).", "labels": [], "entities": [{"text": "coordinate f-score error", "start_pos": 44, "end_pos": 68, "type": "METRIC", "confidence": 0.8415579199790955}, {"text": "McNemar's test", "start_pos": 99, "end_pos": 113, "type": "DATASET", "confidence": 0.7818047404289246}, {"text": "significance", "start_pos": 118, "end_pos": 130, "type": "METRIC", "confidence": 0.9848116636276245}]}, {"text": "The reranker f-score for all constituents (not excluding any coordinate NPs) for section 23 rose slightly from 89.4% to 89.6%, a small but significant increase in f-score.", "labels": [], "entities": [{"text": "f-score", "start_pos": 13, "end_pos": 20, "type": "METRIC", "confidence": 0.47281724214553833}, {"text": "f-score", "start_pos": 163, "end_pos": 170, "type": "METRIC", "confidence": 0.9829119443893433}]}, {"text": "Finally, we report results on an unaltered coordination test set, that is, a test set from which no noisy events were eliminated.", "labels": [], "entities": []}, {"text": "The baseline coordination dependency f-score for all NP coordination dependencies (550 dependencies) from section 23 is 69.27%.", "labels": [], "entities": []}, {"text": "This rises to 72.74% when all experiments described in Section 7 are applied, which is also a statistically significant increase (p = 0.042).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Results on the Validation Set. 1064 coordi- nate noun phrase dependencies. In the significance  column > means at level .05 and \ud97b\udf59 means at level  .005, for McNemar's test of significance. Results are  cumulative.", "labels": [], "entities": [{"text": "McNemar's test of significance", "start_pos": 166, "end_pos": 196, "type": "DATASET", "confidence": 0.6796850502490998}]}]}