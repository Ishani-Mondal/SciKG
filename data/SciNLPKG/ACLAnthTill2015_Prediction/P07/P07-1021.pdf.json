{"title": [], "abstractContent": [{"text": "Dependency-based representations of natural language syntax require a fine balance between structural flexibility and computational complexity.", "labels": [], "entities": []}, {"text": "In previous work, several constraints have been proposed to identify classes of dependency structures that are well-balanced in this sense; the best-known but also most restrictive of these is projectivity.", "labels": [], "entities": []}, {"text": "Most constraints are formulated on fully specified structures, which makes them hard to integrate into models where structures are composed from lexical information.", "labels": [], "entities": []}, {"text": "In this paper, we show how two empirically relevant relax-ations of projectivity can be lexicalized, and how combining the resulting lexicons with a regular means of syntactic composition gives rise to a hierarchy of mildly context-sensitive dependency languages.", "labels": [], "entities": []}], "introductionContent": [{"text": "Syntactic representations based on word-to-word dependencies have along tradition in descriptive linguistics.", "labels": [], "entities": [{"text": "descriptive linguistics", "start_pos": 85, "end_pos": 108, "type": "TASK", "confidence": 0.906592845916748}]}, {"text": "Lately, they have also been used in many computational tasks, such as relation extraction), parsing), and machine translation ().", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 70, "end_pos": 89, "type": "TASK", "confidence": 0.8444611132144928}, {"text": "parsing", "start_pos": 92, "end_pos": 99, "type": "TASK", "confidence": 0.9802373051643372}, {"text": "machine translation", "start_pos": 106, "end_pos": 125, "type": "TASK", "confidence": 0.8319776952266693}]}, {"text": "Especially in recent work on parsing, there is a particular interest in non-projective dependency structures, in which a word and its dependents maybe spread out over a discontinuous region of the sentence.", "labels": [], "entities": [{"text": "parsing", "start_pos": 29, "end_pos": 36, "type": "TASK", "confidence": 0.9704424142837524}]}, {"text": "These structures naturally arise in the syntactic analysis of languages with flexible word order, such as Czech ().", "labels": [], "entities": []}, {"text": "Unfortunately, most formal results on non-projectivity are discouraging: While grammar-driven dependency parsers that are restricted to projective structures can be as efficient as parsers for lexicalized context-free grammar), parsing is prohibitively expensive when unrestricted forms of non-projectivity are permitted).", "labels": [], "entities": []}, {"text": "Data-driven dependency parsing with non-projective structures is quadratic when all attachment decisions are assumed to be independent of one another), but becomes intractable when this assumption is abandoned).", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.6659886538982391}]}, {"text": "In search of a balance between structural flexibility and computational complexity, several authors have proposed constraints to identify classes of non-projective dependency structures that are computationally well-behaved (.", "labels": [], "entities": []}, {"text": "In this paper, we focus on two of these proposals: the gap-degree restriction, which puts abound on the number of discontinuities in the region of a sentence covered by a word and its dependents, and the well-nestedness condition, which constrains the arrangement of dependency subtrees.", "labels": [], "entities": []}, {"text": "Both constraints have been shown to be in very good fit with data from dependency treebanks ().", "labels": [], "entities": []}, {"text": "However, like all other such proposals, they are formulated on fully specified structures, which makes it hard to integrate them into a generative model, where dependency structures are composed from elementary units of lexicalized information.", "labels": [], "entities": []}, {"text": "Consequently, little is known about the generative capacity and computational complexity of languages over restricted non-projective dependency structures.", "labels": [], "entities": [{"text": "generative capacity", "start_pos": 40, "end_pos": 59, "type": "TASK", "confidence": 0.8850474953651428}]}, {"text": "Contents of the paper In this paper, we show how the gap-degree restriction and the well-nestedness condition can be captured in dependency lexicons, and how combining such lexicons with a regular means of syntactic composition gives rise to an infinite hierarchy of mildly context-sensitive languages.", "labels": [], "entities": []}, {"text": "The technical key to these results is a procedure to encode arbitrary, even non-projective dependency structures into trees (terms) over a signature of local order-annotations.", "labels": [], "entities": []}, {"text": "The constructors of these trees can be read as lexical entries, and both the gap-degree restriction and the well-nestedness condition can be couched as syntactic properties of these entries.", "labels": [], "entities": []}, {"text": "Sets of gap-restricted dependency structures can be described using regular tree grammars.", "labels": [], "entities": []}, {"text": "This gives rise to a notion of regular dependency languages, and allows us to establish a formal relation between the structural constraints and mildly context-sensitive grammar formalisms: We show that regular dependency languages correspond to the sets of derivations of lexicalized Linear Context-Free Rewriting Systems (lcfrs), and that the gap-degree measure is the structural correspondent of the concept of 'fan-out' in this formalism.", "labels": [], "entities": []}, {"text": "We also show that adding the well-nestedness condition corresponds to the restriction of lcfrs to Coupled Context-Free Grammars (, and that regular sets of well-nested structures with a gap-degree of at most 1 are exactly the class of sets of derivations of Lexicalized Tree Adjoining Grammar (ltag).", "labels": [], "entities": []}, {"text": "This result generalizes previous work on the relation between ltag and dependency representations).", "labels": [], "entities": []}, {"text": "Structure of the paper The remainder of this paper is structured as follows.", "labels": [], "entities": []}, {"text": "Section 2 contains some basic notions related to trees and dependency structures.", "labels": [], "entities": []}, {"text": "In Section 3 we present the encoding of dependency structures as order-annotated trees, and show how this encoding allows us to give a lexicalized reformulation of both the gap-degree restriction and the well-nestedness condition.", "labels": [], "entities": []}, {"text": "Section 4 introduces the notion of regular dependency languages.", "labels": [], "entities": []}, {"text": "In Section 5 we show how different combinations of restrictions on non-projectivity in these languages correspond to different mildly context-sensitive grammar formalisms.", "labels": [], "entities": []}, {"text": "Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}