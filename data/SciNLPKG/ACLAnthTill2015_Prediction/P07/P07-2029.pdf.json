{"title": [], "abstractContent": [{"text": "Live closed-captions for deaf and hard of hearing audiences are currently produced by stenographers, or by voice writers using speech recognition.", "labels": [], "entities": []}, {"text": "Both techniques can produce captions with errors.", "labels": [], "entities": []}, {"text": "We are currently developing a correction module that allows a user to intercept the real-time caption stream and correct it before it is broadcast.", "labels": [], "entities": []}, {"text": "We report results of preliminary experiments on correction rate and actual user performance using a prototype correction module connected to the output of a speech recognition captioning system.", "labels": [], "entities": [{"text": "speech recognition captioning", "start_pos": 157, "end_pos": 186, "type": "TASK", "confidence": 0.6679206291834513}]}], "introductionContent": [{"text": "CRIM's automatic speech recognition system has been applied to live closed-captioning of frenchcanadian television programs ().", "labels": [], "entities": [{"text": "CRIM", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9526375532150269}, {"text": "speech recognition", "start_pos": 17, "end_pos": 35, "type": "TASK", "confidence": 0.663140669465065}]}, {"text": "The low error rate of our approach depends notably on the integration of the re-speak method) fora controlled acoustic environment, automatic speaker adaptation and dynamic updates of language models and vocabularies, and was deemed acceptable by several Canadian broadcasters (RDS,CPAC,GTVA and TQS) who have adopted it over the past few years for captioning sports, public affairs and newscasts.", "labels": [], "entities": [{"text": "error rate", "start_pos": 8, "end_pos": 18, "type": "METRIC", "confidence": 0.9672344028949738}, {"text": "captioning sports, public affairs and newscasts", "start_pos": 349, "end_pos": 396, "type": "TASK", "confidence": 0.8387006946972438}]}, {"text": "However, for sensitive applications where error rates must practically be zero, or other situations where speech recognition error rates are too high, we are currently developing a real-time correction interface.", "labels": [], "entities": []}, {"text": "In essence, this interface allows a user to correct the word stream from speech recognition before it arrives at the closed-caption encoder.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 2: Error rate for perfect correction.", "labels": [], "entities": [{"text": "Error rate", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9879449307918549}, {"text": "perfect", "start_pos": 25, "end_pos": 32, "type": "METRIC", "confidence": 0.961641252040863}]}, {"text": " Table 3: Error rate after user correction.", "labels": [], "entities": [{"text": "Error rate", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9857287108898163}]}]}