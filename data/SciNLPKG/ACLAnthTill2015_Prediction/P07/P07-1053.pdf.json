{"title": [{"text": "Opinion Mining Using Econometrics: A Case Study on Reputation Systems", "labels": [], "entities": [{"text": "Opinion Mining", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.8518218100070953}]}], "abstractContent": [{"text": "Deriving the polarity and strength of opinions is an important research topic, attracting significant attention over the last few years.", "labels": [], "entities": [{"text": "Deriving the polarity", "start_pos": 0, "end_pos": 21, "type": "TASK", "confidence": 0.8764655987421671}]}, {"text": "In this work, to measure the strength and polarity of an opinion, we consider the economic context in which the opinion is evaluated , instead of using human annotators or linguistic resources.", "labels": [], "entities": []}, {"text": "We rely on the fact that text in on-line systems influences the behavior of humans and this effect can be observed using some easy-to-measure economic variables , such as revenues or product prices.", "labels": [], "entities": []}, {"text": "By reversing the logic, we infer the semantic orientation and strength of an opinion by tracing the changes in the associated economic variable.", "labels": [], "entities": []}, {"text": "In effect, we use econometrics to identify the \"economic value of text\" and assign a \"dollar value\" to each opinion phrase, measuring sentiment effectively and without the need for manual labeling.", "labels": [], "entities": []}, {"text": "We argue that by interpreting opinions using econometrics, we have the first objective, quantifiable, and context-sensitive evaluation of opinions.", "labels": [], "entities": []}, {"text": "We make the discussion concrete by presenting results on the reputation system of Amazon.com.", "labels": [], "entities": []}, {"text": "We show that user feedback affects the pricing power of merchants and by measuring their pricing power we can infer the polarity and strength of the underlying feedback postings.", "labels": [], "entities": []}], "introductionContent": [{"text": "A significant number of websites today allow users to post articles where they express opinions about products, firms, people, and soon.", "labels": [], "entities": []}, {"text": "For example, users on Amazom.com post reviews about products they bought and users on eBay.com post feedback describing their experiences with sellers.", "labels": [], "entities": []}, {"text": "The goal of opinion mining systems is to identify such pieces of the text that express opinions) and then measure the polarity and strength of the expressed opinions.", "labels": [], "entities": [{"text": "opinion mining", "start_pos": 12, "end_pos": 26, "type": "TASK", "confidence": 0.7863174378871918}]}, {"text": "While intuitively the task seems straightforward, there are multiple challenges involved.", "labels": [], "entities": []}, {"text": "\u2022 What makes an opinion positive or negative?", "labels": [], "entities": []}, {"text": "Is there an objective measure for this task?", "labels": [], "entities": []}, {"text": "\u2022 How can we rank opinions according to their strength?", "labels": [], "entities": []}, {"text": "Can we define an objective measure for ranking opinions?", "labels": [], "entities": []}, {"text": "\u2022 How does the context change the polarity and strength of an opinion and how can we take the context into consideration?", "labels": [], "entities": []}, {"text": "To evaluate the polarity and strength of opinions, most of the existing approaches rely either on training from human-annotated data, or use linguistic resources () like WordNet, or rely on co-occurrence statistics) between words that are unambiguously positive (e.g., \"excellent\") and unambiguously negative (e.g., \"horrible\").", "labels": [], "entities": [{"text": "WordNet", "start_pos": 170, "end_pos": 177, "type": "DATASET", "confidence": 0.9722522497177124}]}, {"text": "Finally, other approaches rely on reviews with numeric ratings from websites () and train (semi-)supervised learning algorithms to classify reviews as positive or negative, or in more fine-grained scales).", "labels": [], "entities": []}, {"text": "Implicitly, the supervised learning techniques assume that numeric ratings fully encapsulate the sentiment of the review.", "labels": [], "entities": []}, {"text": "416 In this paper, we take a different approach and instead consider the economic context in which an opinion is evaluated.", "labels": [], "entities": []}, {"text": "We observe that the text in on-line systems influence the behavior of the readers.", "labels": [], "entities": []}, {"text": "This effect can be measured by observing some easy-tomeasure economic variable, such as product prices.", "labels": [], "entities": []}, {"text": "For instance, online merchants on eBay with \"positive\" feedback can sell products for higher prices than competitors with \"negative\" evaluations.", "labels": [], "entities": []}, {"text": "Therefore, each of these (positive or negative) evaluations has a (positive or negative) effect on the prices that the merchant can charge.", "labels": [], "entities": []}, {"text": "For example, everything else being equal, a seller with \"speedy\" delivery maybe able to charge $10 more than a seller with \"slow\" delivery.", "labels": [], "entities": []}, {"text": "Using this information, we can conclude that \"speedy\" is better than \"slow\" when applied to \"delivery\" and their difference is $10.", "labels": [], "entities": [{"text": "speedy", "start_pos": 46, "end_pos": 52, "type": "METRIC", "confidence": 0.9950527548789978}]}, {"text": "Thus, we can infer the semantic orientation and the strength of an evaluation from the changes in the observed economic variable.", "labels": [], "entities": []}, {"text": "Following this idea, we use techniques from econometrics to identify the \"economic value of text\" and assign a \"dollar value\" to each text snippet, measuring sentiment strength and polarity effectively and without the need for labeling or any other resource.", "labels": [], "entities": []}, {"text": "We argue that by interpreting opinions within an econometric framework, we have the first objective and context-sensitive evaluation of opinions.", "labels": [], "entities": []}, {"text": "For example, consider the comment \"good packaging,\" posted by a buyer to evaluate a merchant.", "labels": [], "entities": []}, {"text": "This comment would have been considered unambiguously positive by the existing opinion mining systems.", "labels": [], "entities": []}, {"text": "We observed, though, that within electronic markets, such as eBay, a posting that contains the words \"good packaging\" has actually negative effect on the power of a merchant to charge higher prices.", "labels": [], "entities": []}, {"text": "This surprising effect reflects the nature of the comments in online marketplaces: buyers tend to use superlatives and highly enthusiastic language to praise a good merchant, and a lukewarm \"good packaging\" is interpreted as negative.", "labels": [], "entities": []}, {"text": "By introducing the econometric interpretation of opinions we can effortlessly capture such challenging scenarios, something that is impossible to achieve with the existing approaches.", "labels": [], "entities": []}, {"text": "We focus our paper on reputation systems in electronic markets and we examine the effect of opinions on the pricing power of merchants in the marketplace of Amazon.com.", "labels": [], "entities": []}, {"text": "(We discuss more applications in Section 7.)", "labels": [], "entities": []}, {"text": "We demonstrate the value of our technique using a dataset with 9,500 transactions that took place over 180 days.", "labels": [], "entities": []}, {"text": "We show that textual feedback affects the power of merchants to charge higher prices than the competition, for the same product, and still make a sale.", "labels": [], "entities": []}, {"text": "We then reverse the logic and determine the contribution of each comment in the pricing power of a merchant.", "labels": [], "entities": []}, {"text": "Thus, we discover the polarity and strength of each evaluation without the need for human annotation or any other form of linguistic resource.", "labels": [], "entities": []}, {"text": "The structure of the rest of the paper is as follows.", "labels": [], "entities": []}, {"text": "Section 2 gives the basic background on reputation systems.", "labels": [], "entities": []}, {"text": "Section 3 describes our methodology for constructing the data set that we use in our experiments.", "labels": [], "entities": []}, {"text": "Section 4 shows how we combine established techniques from econometrics with text mining techniques to identify the strength and polarity of the posted feedback evaluations.", "labels": [], "entities": []}, {"text": "Section 5 presents the experimental evaluations of our techniques.", "labels": [], "entities": []}, {"text": "Finally, Section 6 discusses related work and Section 7 discusses further applications and concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we first present the experimental settings (Section 5.1), and then we describe the results of our experimental evaluation (Section 5.2).", "labels": [], "entities": []}, {"text": "Recall of Extraction: The first step of our experimental evaluation is to examine whether the opinion extraction technique of Section 4.1 indeed captures all the reputation characteristics expressed in the feed-420: The recall of our technique compared to the recall of the human annotators back (recall) and whether the dimensions that we capture are accurate (precision).", "labels": [], "entities": [{"text": "Recall of Extraction", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.6542207400004069}, {"text": "opinion extraction", "start_pos": 94, "end_pos": 112, "type": "TASK", "confidence": 0.7490561306476593}, {"text": "recall", "start_pos": 220, "end_pos": 226, "type": "METRIC", "confidence": 0.9979053735733032}, {"text": "recall", "start_pos": 297, "end_pos": 303, "type": "METRIC", "confidence": 0.988114058971405}, {"text": "precision", "start_pos": 362, "end_pos": 371, "type": "METRIC", "confidence": 0.9947133660316467}]}, {"text": "To examine the recall question, we used two human annotators.", "labels": [], "entities": [{"text": "recall", "start_pos": 15, "end_pos": 21, "type": "METRIC", "confidence": 0.9883195161819458}]}, {"text": "The annotators read a random sample of 1,000 feedback postings, and identified the reputation dimensions mentioned in the text.", "labels": [], "entities": []}, {"text": "Then, they examined the extracted modifierdimension pairs for each posting and marked whether the modifier-dimension pairs captured the identified real reputation dimensions mentioned in the posting and which pairs were spurious, non-opinion phrases.", "labels": [], "entities": []}, {"text": "Both annotators identified nine reputation dimensions (see).", "labels": [], "entities": []}, {"text": "Since the annotators did not agree in all annotations, we computed the average human recall for each dimension d, where agreed dis the number of postings for which both annotators identified the reputation dimension d, and all dis the number of postings in which at least one annotator identified the dimension d.", "labels": [], "entities": [{"text": "recall", "start_pos": 85, "end_pos": 91, "type": "METRIC", "confidence": 0.986396074295044}]}, {"text": "Based on the annotations, we computed the recall of our algorithm against each annotator.", "labels": [], "entities": [{"text": "recall", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9994692206382751}]}, {"text": "We report the average recall for each dimension, together with the human recall in.", "labels": [], "entities": [{"text": "recall", "start_pos": 22, "end_pos": 28, "type": "METRIC", "confidence": 0.9787945747375488}, {"text": "recall", "start_pos": 73, "end_pos": 79, "type": "METRIC", "confidence": 0.9788918495178223}]}, {"text": "The recall of our technique is only slightly inferior to the performance of humans, indicating that the technique of Section 4.1 extracts the majority of the posted evaluations.", "labels": [], "entities": [{"text": "recall", "start_pos": 4, "end_pos": 10, "type": "METRIC", "confidence": 0.9995813965797424}]}, {"text": "Interestingly, precision is not an issue in our setting.", "labels": [], "entities": [{"text": "precision", "start_pos": 15, "end_pos": 24, "type": "METRIC", "confidence": 0.9972368478775024}]}, {"text": "In our framework, if an particular modifier-dimension pair is just noise, then it is almost impossible to have a statistically significant correlation with the price premiums.", "labels": [], "entities": []}, {"text": "The noisy opinion phrases are statistically guaranteed to be filtered out by the regression.", "labels": [], "entities": []}, {"text": "Estimating Polarity and Strength: In we present the modifier-dimension pairs (positive and negative) that had the strongest \"dollar value\" and were statistically significant across all regressions.", "labels": [], "entities": []}, {"text": "(Due to space issues, we cannot list the values for all pairs.)", "labels": [], "entities": []}, {"text": "These values reflect changes in the merchants's pricing power after taking their average numerical score and level of experience into account, and also highlight the additional the value contained in textbased reputation.", "labels": [], "entities": []}, {"text": "The examples that we list here illustrate that our technique generates a natural ranking of the opinion phrases, inferring the strength of each modifier within the context in which this opinion is evaluated.", "labels": [], "entities": []}, {"text": "This holds true even for misspelled evaluations that would break existing techniques based on annotation or on resources like WordNet.", "labels": [], "entities": [{"text": "WordNet", "start_pos": 126, "end_pos": 133, "type": "DATASET", "confidence": 0.9718238711357117}]}, {"text": "Furthermore, these values reflect the context in which the opinion is evaluated.", "labels": [], "entities": []}, {"text": "For example, the pair good packaging has a dollar value of -$0.58.", "labels": [], "entities": []}, {"text": "Even though this seems counterintuitive, it actually reflects the nature of an online marketplace where most of the positive evaluations contain superlatives, and a mere \"good\" is actually interpreted by the buyers as a lukewarm, slightly negative evaluation.", "labels": [], "entities": []}, {"text": "Existing techniques cannot capture such phenomena.", "labels": [], "entities": []}, {"text": "Price Premiums vs. Ratings: One of the natural comparisons is to examine whether we could reach similar results by just using the average star rating associated with each feedback posting to infer the score of each opinion phrase.", "labels": [], "entities": []}, {"text": "The underlying assumption behind using the ratings is that the review is perfectly summarized by the star rating, and hence the text plays mainly an explanatory role and carries no extra information, given the star rating.", "labels": [], "entities": []}, {"text": "For this, we examined the R 2 fit of the regression, with and without the use of the text variables.", "labels": [], "entities": [{"text": "R 2 fit", "start_pos": 26, "end_pos": 33, "type": "METRIC", "confidence": 0.8371181885401408}]}, {"text": "Without the use of text variables, the R 2 was 0.35, while when using only the text-based regressors, the R 2 fit increased to 0.63.", "labels": [], "entities": [{"text": "R 2", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.9402281045913696}]}, {"text": "This result clearly indicates that the actual text contains significantly more information than the ratings.", "labels": [], "entities": []}, {"text": "We also experimented with predicting which merchant will make a sale, if they simultaneously sell the same product, based on their listed prices and on their numeric and text reputation.", "labels": [], "entities": []}, {"text": "Our C4.5 classifier (Quinlan, 1992) takes a pair of merchants and decides which of the two will make a sale.", "labels": [], "entities": []}, {"text": "We used as training set the transactions that took place in the first four months and as test set the transactions in the last two months of our data set.", "labels": [], "entities": []}, {"text": "accuracy when using only prices as features indicates that customers rarely choose a product based solely on price.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 0, "end_pos": 8, "type": "METRIC", "confidence": 0.9948146939277649}]}, {"text": "Rather, as indicated by the 74% accuracy, they also consider the reputation of the merchants.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9901095628738403}]}, {"text": "However, the real value of the postings relies on the text and not on the numeric ratings: the accuracy is 87%-89% when using the textual reputation variables.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 95, "end_pos": 103, "type": "METRIC", "confidence": 0.9994447827339172}]}, {"text": "In fact, text subsumes the numeric variables but not vice versa, as indicated by the results in.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: The recall of our technique compared to the  recall of the human annotators", "labels": [], "entities": [{"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9991233944892883}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.9699329733848572}]}, {"text": " Table 3: Predicting the merchant who makes the sale.", "labels": [], "entities": [{"text": "Predicting", "start_pos": 10, "end_pos": 20, "type": "METRIC", "confidence": 0.9548912644386292}]}]}