{"title": [], "abstractContent": [{"text": "This paper presents a Function Word centered , Syntax-based (FWS) solution to address phrase ordering in the context of statistical machine translation (SMT).", "labels": [], "entities": [{"text": "phrase ordering", "start_pos": 86, "end_pos": 101, "type": "TASK", "confidence": 0.6918137967586517}, {"text": "statistical machine translation (SMT)", "start_pos": 120, "end_pos": 157, "type": "TASK", "confidence": 0.7682447185118993}]}, {"text": "Motivated by the observation that function words often encode grammatical relationship among phrases within a sentence, we propose a probabilistic synchronous grammar to model the ordering of function words and their left and right arguments.", "labels": [], "entities": []}, {"text": "We improve phrase ordering performance by lexi-calizing the resulting rules in a small number of cases corresponding to function words.", "labels": [], "entities": [{"text": "phrase ordering", "start_pos": 11, "end_pos": 26, "type": "TASK", "confidence": 0.8230656981468201}]}, {"text": "The experiments show that the FWS approach consistently outperforms the base-line system in ordering function words' arguments and improving translation quality in both perfect and noisy word alignment scenarios.", "labels": [], "entities": [{"text": "FWS", "start_pos": 30, "end_pos": 33, "type": "METRIC", "confidence": 0.4055842161178589}]}], "introductionContent": [{"text": "The focus of this paper is on function words, a class of words with little intrinsic meaning but is vital in expressing grammatical relationships among words within a sentence.", "labels": [], "entities": []}, {"text": "Such encoded grammatical information, often implicit, makes function words pivotal in modeling structural divergences, as projecting them in different languages often result in longrange structural changes to the realized sentences.", "labels": [], "entities": []}, {"text": "Just as a foreign language learner often makes mistakes in using function words, we observe that current machine translation (MT) systems often perform poorly in ordering function words' arguments; lexically correct translations often end up reordered incorrectly.", "labels": [], "entities": [{"text": "machine translation (MT)", "start_pos": 105, "end_pos": 129, "type": "TASK", "confidence": 0.8477189421653748}]}, {"text": "Thus, we are interested in modeling the structural divergence encoded by such function words.", "labels": [], "entities": []}, {"text": "A key finding of our work is that modeling the ordering of the dependent arguments of function words results in better translation quality.", "labels": [], "entities": []}, {"text": "Most current systems use statistical knowledge obtained from corpora in favor of rich natural language knowledge.", "labels": [], "entities": []}, {"text": "Instead of using syntactic knowledge to determine function words, we approximate this by equating the most frequent words as function words.", "labels": [], "entities": []}, {"text": "By explicitly modeling phrase ordering around these frequent words, we aim to capture the most important and prevalent ordering productions.", "labels": [], "entities": [{"text": "phrase ordering", "start_pos": 23, "end_pos": 38, "type": "TASK", "confidence": 0.7318712174892426}]}], "datasetContent": [{"text": "We would like to study how the FWS model affects 1) the ordering of phrases around function words; 2) the overall translation quality.", "labels": [], "entities": [{"text": "FWS", "start_pos": 31, "end_pos": 34, "type": "DATASET", "confidence": 0.5569621324539185}]}, {"text": "We achieve this by evaluating the FWS model against a baseline system using two metrics, namely, orientation accuracy and BLEU respectively.", "labels": [], "entities": [{"text": "FWS", "start_pos": 34, "end_pos": 37, "type": "DATASET", "confidence": 0.610813558101654}, {"text": "orientation accuracy", "start_pos": 97, "end_pos": 117, "type": "METRIC", "confidence": 0.7026090025901794}, {"text": "BLEU", "start_pos": 122, "end_pos": 126, "type": "METRIC", "confidence": 0.9990012049674988}]}, {"text": "We define the orientation accuracy of a (function) word as the accuracy of assigning correct orientation values to both its left and right arguments.", "labels": [], "entities": [{"text": "orientation accuracy", "start_pos": 14, "end_pos": 34, "type": "METRIC", "confidence": 0.5905916094779968}, {"text": "accuracy", "start_pos": 63, "end_pos": 71, "type": "METRIC", "confidence": 0.9987941980361938}]}, {"text": "We report the aggregate for the top 1024 most frequent words; these words cover 90% of the test set.", "labels": [], "entities": []}, {"text": "We devise a series of experiments and run it in two scenarios -manual and automatic alignment -to assess the effects of using perfect or real-world input.", "labels": [], "entities": []}, {"text": "We utilize the HIT bilingual computer manual corpus, which has been manually aligned, to perform Chinese-to-English translation (see).", "labels": [], "entities": [{"text": "HIT bilingual computer manual corpus", "start_pos": 15, "end_pos": 51, "type": "DATASET", "confidence": 0.8756636023521424}, {"text": "Chinese-to-English translation", "start_pos": 97, "end_pos": 127, "type": "TASK", "confidence": 0.5678970217704773}]}, {"text": "Manual alignment is essential as we need to measure orientation accuracy with respect to a gold standard.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9617975950241089}]}, {"text": "A language model is trained using the SRILMToolkit, and a text chunker) is applied to the Chinese sentences in the test and dev sets to extract the constituent boundaries necessary for the phrase boundary model.", "labels": [], "entities": [{"text": "SRILMToolkit", "start_pos": 38, "end_pos": 50, "type": "DATASET", "confidence": 0.7789641618728638}]}, {"text": "We run minimum error rate training on dev set using Chiang's toolkit to find a set of parameters that optimizes BLEU score.", "labels": [], "entities": [{"text": "Chiang's toolkit", "start_pos": 52, "end_pos": 68, "type": "DATASET", "confidence": 0.9128202199935913}, {"text": "BLEU score", "start_pos": 112, "end_pos": 122, "type": "METRIC", "confidence": 0.9783783853054047}]}, {"text": "Here, all knowledge is automatically trained on the train set, and as a result, the input word alignment is noisy.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 90, "end_pos": 104, "type": "TASK", "confidence": 0.7367814481258392}]}, {"text": "As a baseline, we use the state-of-the-art phrase-based Pharaoh decoder.", "labels": [], "entities": []}, {"text": "For a fair comparison, we run minimum error rate training for different distortion limits from 0 to 10 and report the best parameter (dl=5) as the baseline.", "labels": [], "entities": [{"text": "minimum error rate", "start_pos": 30, "end_pos": 48, "type": "METRIC", "confidence": 0.7617970705032349}]}, {"text": "We use the phrase translation table from the baseline and perform an identical set of experiments as the perfect lexical choice scenario, except that we only report the result for N =128, due to space constraint.", "labels": [], "entities": [{"text": "phrase translation", "start_pos": 11, "end_pos": 29, "type": "TASK", "confidence": 0.6785320192575455}]}, {"text": "reports the resulting BLEU scores.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.9986304044723511}]}, {"text": "As shown, the FWS model improves BLEU score significantly over the baseline.", "labels": [], "entities": [{"text": "FWS", "start_pos": 14, "end_pos": 17, "type": "METRIC", "confidence": 0.9373385310173035}, {"text": "BLEU score", "start_pos": 33, "end_pos": 43, "type": "METRIC", "confidence": 0.9699110388755798}]}, {"text": "We observe the same trend as the one in perfect lexical choice scenario where top 128 most frequent words provides the majority of improvement.", "labels": [], "entities": []}, {"text": "However, the pb features yields no noticeable improvement unlike in prefect lexical choice scenario; this is similar to the findings in (.", "labels": [], "entities": []}, {"text": "718: Results using perfect aligned input.", "labels": [], "entities": []}, {"text": "Here, (lm+d) is the baseline; (+ori), (+ori+pref) and (+ori+pref+pb) are different FWS configurations.", "labels": [], "entities": [{"text": "FWS", "start_pos": 83, "end_pos": 86, "type": "DATASET", "confidence": 0.8218168020248413}]}, {"text": "The results of the model (where N is varied) that features the largest gain are bold, whereas the highest score is italicized.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Orientation statistics and unigram probability of selected frequent Chinese words in the HIT corpus.  Subscripts L/R refers to lexical unit's orientation with respect to its left/right neighbor. U is the universal  token used in back-off for N = 128. Dominant orientations of each word are in bold.", "labels": [], "entities": [{"text": "HIT corpus", "start_pos": 99, "end_pos": 109, "type": "DATASET", "confidence": 0.9415296912193298}]}, {"text": " Table 2: Statistics for the HIT corpus.", "labels": [], "entities": [{"text": "HIT corpus", "start_pos": 29, "end_pos": 39, "type": "DATASET", "confidence": 0.8891167640686035}]}, {"text": " Table 4: Results using perfect aligned input. Here, (lm+d) is the baseline; (+ori), (+ori+pref) and  (+ori+pref+pb) are different FWS configurations. The results of the model (where N is varied) that fea- tures the largest gain are bold, whereas the highest score is italicized.", "labels": [], "entities": [{"text": "FWS", "start_pos": 131, "end_pos": 134, "type": "DATASET", "confidence": 0.7510696053504944}]}]}