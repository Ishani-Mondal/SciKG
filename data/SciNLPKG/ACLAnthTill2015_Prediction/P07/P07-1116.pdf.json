{"title": [{"text": "A Language-Independent Unsupervised Model for Morphological Segmentation", "labels": [], "entities": [{"text": "Morphological Segmentation", "start_pos": 46, "end_pos": 72, "type": "TASK", "confidence": 0.8136554062366486}]}], "abstractContent": [{"text": "Morphological segmentation has been shown to be beneficial to a range of NLP tasks such as machine translation, speech recognition, speech synthesis and information retrieval.", "labels": [], "entities": [{"text": "Morphological segmentation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8584394752979279}, {"text": "machine translation", "start_pos": 91, "end_pos": 110, "type": "TASK", "confidence": 0.7954663038253784}, {"text": "speech recognition", "start_pos": 112, "end_pos": 130, "type": "TASK", "confidence": 0.798622190952301}, {"text": "speech synthesis", "start_pos": 132, "end_pos": 148, "type": "TASK", "confidence": 0.789175808429718}, {"text": "information retrieval", "start_pos": 153, "end_pos": 174, "type": "TASK", "confidence": 0.8126763999462128}]}, {"text": "Recently, a number of approaches to unsupervised morphological segmentation have been proposed.", "labels": [], "entities": [{"text": "morphological segmentation", "start_pos": 49, "end_pos": 75, "type": "TASK", "confidence": 0.7531282305717468}]}, {"text": "This paper describes an algorithm that draws from previous approaches and combines them into a simple model for morphological segmentation that outperforms other approaches on English and German, and also yields good results on agglutinative languages such as Finnish and Turkish.", "labels": [], "entities": [{"text": "morphological segmentation", "start_pos": 112, "end_pos": 138, "type": "TASK", "confidence": 0.7131778746843338}]}, {"text": "We also propose a method for detecting variation within stems in an unsupervised fashion.", "labels": [], "entities": [{"text": "detecting variation within stems", "start_pos": 29, "end_pos": 61, "type": "TASK", "confidence": 0.8719726502895355}]}, {"text": "The segmentation quality reached with the new algorithm is good enough to improve grapheme-to-phoneme conversion.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 4, "end_pos": 16, "type": "TASK", "confidence": 0.9538882970809937}, {"text": "grapheme-to-phoneme conversion", "start_pos": 82, "end_pos": 112, "type": "TASK", "confidence": 0.6990925967693329}]}], "introductionContent": [{"text": "Morphological segmentation has been shown to be beneficial to a number of NLP tasks such as machine translation), speech recognition (), information retrieval (Monz and de) and question answering.", "labels": [], "entities": [{"text": "Morphological segmentation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8498664796352386}, {"text": "machine translation", "start_pos": 92, "end_pos": 111, "type": "TASK", "confidence": 0.7882572710514069}, {"text": "speech recognition", "start_pos": 114, "end_pos": 132, "type": "TASK", "confidence": 0.8019298911094666}, {"text": "information retrieval", "start_pos": 137, "end_pos": 158, "type": "TASK", "confidence": 0.7931042611598969}, {"text": "question answering", "start_pos": 177, "end_pos": 195, "type": "TASK", "confidence": 0.9121011793613434}]}, {"text": "Segmenting a word into meaningbearing units is particularly interesting for morphologically complex languages where words can be composed of several morphemes through inflection, derivation and composition.", "labels": [], "entities": []}, {"text": "Data sparseness for such languages can be significantly decreased when words are decomposed morphologically.", "labels": [], "entities": []}, {"text": "There exist a number of rule-based morphological segmentation systems fora range of languages.", "labels": [], "entities": [{"text": "rule-based morphological segmentation", "start_pos": 24, "end_pos": 61, "type": "TASK", "confidence": 0.6985611120859782}]}, {"text": "However, expert knowledge and labour are expensive, and the analyzers must be updated on a regular basis in order to cope with language change (the emergence of new words and their inflections).", "labels": [], "entities": []}, {"text": "One might argue that unsupervised algorithms are not an interesting option from the engineering point of view, because rule-based systems usually lead to better results.", "labels": [], "entities": []}, {"text": "However, segmentations from an unsupervised algorithm that is language-independent are \"cheap\", because the only resource needed is unannotated text.", "labels": [], "entities": []}, {"text": "If such an unsupervised system reaches a performance level that is good enough to help another task, it can constitute an attractive additional component.", "labels": [], "entities": []}, {"text": "Recently, a number of approaches to unsupervised morphological segmentation have been proposed.", "labels": [], "entities": [{"text": "morphological segmentation", "start_pos": 49, "end_pos": 75, "type": "TASK", "confidence": 0.7531282305717468}]}, {"text": "These algorithms autonomously discover morpheme segmentations in unannotated text corpora.", "labels": [], "entities": []}, {"text": "Here we describe a modification of one such unsupervised algorithm, RePortS ().", "labels": [], "entities": []}, {"text": "The RePortS algorithm performed best on English in a recent competition on unsupervised morphological segmentation (), but had very low recall on morphologically more complex languages like German, Finnish or Turkish.", "labels": [], "entities": [{"text": "recall", "start_pos": 136, "end_pos": 142, "type": "METRIC", "confidence": 0.9991355538368225}]}, {"text": "We add anew step designed to achieve higher recall on morphologically complex languages and propose a method for identifying related stems that underwent regular non-concatenative morphological processes such as umlauting or ablauting, as well as morphological alternations along morpheme boundaries.", "labels": [], "entities": [{"text": "recall", "start_pos": 44, "end_pos": 50, "type": "METRIC", "confidence": 0.9985209107398987}]}, {"text": "2 discusses the relationship between languagedependency and the level of supervision of a learning algorithm.", "labels": [], "entities": []}, {"text": "We then give an outline of the main steps of the RePortS algorithm in section 3 and explain the modifications to the original algorithm in section 4.", "labels": [], "entities": []}, {"text": "Section 5 compares results for different languages, quantifies the gains from the modifications on the algorithm and evaluates the algorithm on a grapheme-to-phoneme conversion task.", "labels": [], "entities": [{"text": "grapheme-to-phoneme conversion", "start_pos": 146, "end_pos": 176, "type": "TASK", "confidence": 0.7426082491874695}]}, {"text": "We finally summarize our results in section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "For evaluating the different versions of the algorithm on English, Turkish and Finnish, we used the training and test sets from MorphoChallenge to enable comparison with other systems.", "labels": [], "entities": [{"text": "MorphoChallenge", "start_pos": 128, "end_pos": 143, "type": "DATASET", "confidence": 0.9339768886566162}]}, {"text": "Performance of the algorithm on German was evaluated on 244k manually annotated words from CELEX because German was not included in the MorphoChallenge data.", "labels": [], "entities": [{"text": "CELEX", "start_pos": 91, "end_pos": 96, "type": "DATASET", "confidence": 0.9469383955001831}, {"text": "MorphoChallenge data", "start_pos": 136, "end_pos": 156, "type": "DATASET", "confidence": 0.9516786932945251}]}, {"text": "shows that the introduction of the stem candidate acquisition step led to much higher recall on German, Finnish and Turkish, but caused some losses in precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 86, "end_pos": 92, "type": "METRIC", "confidence": 0.9996131062507629}, {"text": "precision", "start_pos": 151, "end_pos": 160, "type": "METRIC", "confidence": 0.998738706111908}]}, {"text": "For English, adding both components did not have a large effect on either precision or recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 74, "end_pos": 83, "type": "METRIC", "confidence": 0.9994851350784302}, {"text": "recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9965476393699646}]}, {"text": "This means that this component is well behaved, i.e. it improves performance on languages where the intermediate stem-acquisition step.", "labels": [], "entities": []}, {"text": "The algorithm is very efficient: When trained on the 240m tokens of the German TAZ corpus, it takes up less than 1 GB of memory.", "labels": [], "entities": [{"text": "German TAZ corpus", "start_pos": 72, "end_pos": 89, "type": "DATASET", "confidence": 0.8312299052874247}]}, {"text": "The training phase takes approx. 5 min on a 2.4GHz machine, and the segmentation of the 250k test words takes 3 min for the version that does the simple segmentation and about 8 min for the version that generates all possible segmentations and uses the language model.", "labels": [], "entities": []}, {"text": "Morphological segmentation is not of value in itself -the question is whether it can help improve results on an application.", "labels": [], "entities": [{"text": "Morphological segmentation", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.9238492250442505}]}, {"text": "Performance improvements due to morphological information have been reported for example in MT, information retrieval, and speech recognition.", "labels": [], "entities": [{"text": "MT", "start_pos": 92, "end_pos": 94, "type": "TASK", "confidence": 0.9973775148391724}, {"text": "information retrieval", "start_pos": 96, "end_pos": 117, "type": "TASK", "confidence": 0.849418431520462}, {"text": "speech recognition", "start_pos": 123, "end_pos": 141, "type": "TASK", "confidence": 0.8356302678585052}]}, {"text": "For the latter task, morphological segmentations from the unsupervised systems presented here have been shown to improve accuracy ().", "labels": [], "entities": [{"text": "morphological segmentations", "start_pos": 21, "end_pos": 48, "type": "TASK", "confidence": 0.7597687244415283}, {"text": "accuracy", "start_pos": 121, "end_pos": 129, "type": "METRIC", "confidence": 0.9989473223686218}]}, {"text": "Another motivation for evaluating the system on a task rather than on manually annotated data is that linguistically motivated morphological segmentation is not necessarily the best possible segmentation fora certain task.", "labels": [], "entities": [{"text": "linguistically motivated morphological segmentation", "start_pos": 102, "end_pos": 153, "type": "TASK", "confidence": 0.695544570684433}]}, {"text": "Evaluation against a manually annotated corpus prefers segmentations that are closest to linguistically motivated analyses.", "labels": [], "entities": []}, {"text": "Furthermore, it might be important fora certain task to find a particular type of morpheme boundaries (e.g. boundaries between stems), but for another task it: F-measure for evaluation on manually annotated CELEX and phoneme error rate (PER) from g2p conversion using a decision tree (dt).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 160, "end_pos": 169, "type": "METRIC", "confidence": 0.9981638789176941}, {"text": "phoneme error rate (PER)", "start_pos": 217, "end_pos": 241, "type": "METRIC", "confidence": 0.7973624567190806}]}, {"text": "might be very important to find boundaries between stems and suffixes.", "labels": [], "entities": []}, {"text": "The standard evaluation procedure does not differentiate between the types of mistakes made.", "labels": [], "entities": []}, {"text": "Finally, only evaluation on a task can provide information as to whether high precision or high recall is more important, therefore, the decision as to which version of the algorithm should be chosen can only betaken given a specific task.", "labels": [], "entities": [{"text": "precision", "start_pos": 78, "end_pos": 87, "type": "METRIC", "confidence": 0.9643025994300842}, {"text": "recall", "start_pos": 96, "end_pos": 102, "type": "METRIC", "confidence": 0.9801102876663208}]}, {"text": "For these reasons we decided to evaluate the segmentation from the new versions of the RePortS algorithm on a German grapheme-to-phoneme (g2p) conversion task.", "labels": [], "entities": [{"text": "segmentation", "start_pos": 45, "end_pos": 57, "type": "TASK", "confidence": 0.9614233374595642}, {"text": "German grapheme-to-phoneme (g2p) conversion task", "start_pos": 110, "end_pos": 158, "type": "TASK", "confidence": 0.5864388048648834}]}, {"text": "The evaluation on this task is motivated by the fact that showed that good-quality morphological preprocessing can improve g2p conversion results.", "labels": [], "entities": []}, {"text": "We here compare the effect of using our system's segmentations to a range of different morphological segmentations from other systems.", "labels": [], "entities": []}, {"text": "We ran each of the rule-based systems (ETI, SMOR-disamb1, SMOR-disamb2) and the unsupervised algorithms (original RePortS, Bernhard, Morfessor 1.0, Bordag) on the CELEX data set and retrained our decision tree (an implementation based on) on the different morphological segmentations.", "labels": [], "entities": [{"text": "RePortS", "start_pos": 114, "end_pos": 121, "type": "DATASET", "confidence": 0.9091273546218872}, {"text": "CELEX data set", "start_pos": 163, "end_pos": 177, "type": "DATASET", "confidence": 0.9847530921300253}]}, {"text": "shows the F-score of the different systems when evaluated on the manually annotated CELEX data (full data set) and the phoneme error rate (PER) for the g2p conversion algorithm when annotated with morphological boundaries (smaller test set, since the decision tree is a supervised method and needs training data).", "labels": [], "entities": [{"text": "F-score", "start_pos": 10, "end_pos": 17, "type": "METRIC", "confidence": 0.9984347224235535}, {"text": "CELEX data (full data set", "start_pos": 84, "end_pos": 109, "type": "DATASET", "confidence": 0.8299011985460917}, {"text": "phoneme error rate (PER)", "start_pos": 119, "end_pos": 143, "type": "METRIC", "confidence": 0.86203533411026}]}, {"text": "As we can see from the results, the distribution of precision and recall (see) has an important impact on the conversion quality: the RePortS version with higher precision signifi-926 cantly outperforms the other version on the task, although their F-measures are almost identical.", "labels": [], "entities": [{"text": "precision", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9993879795074463}, {"text": "recall", "start_pos": 66, "end_pos": 72, "type": "METRIC", "confidence": 0.9990693926811218}, {"text": "F-measures", "start_pos": 249, "end_pos": 259, "type": "METRIC", "confidence": 0.9866849780082703}]}, {"text": "Remarkably, the RePortS version that uses the filtering step is the only unsupervised system that beats the no-morphology baseline (p < 0.0001).", "labels": [], "entities": []}, {"text": "While all other unsupervised systems tested here make the system perform worse than it would without morphological information, this new version improves accuracy on g2p conversion.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 154, "end_pos": 162, "type": "METRIC", "confidence": 0.9994787573814392}]}], "tableCaptions": [{"text": " Table 2: Performance of the algorithm with the mod- ifications on different languages.  1 MorphoChallenge Data, 2 German CELEX", "labels": [], "entities": [{"text": "MorphoChallenge Data, 2 German CELEX", "start_pos": 91, "end_pos": 127, "type": "DATASET", "confidence": 0.8154868682225546}]}, {"text": " Table 3: Evaluating rule-based and data-based sys- tems for morphological segmentation with respect to  CELEX manual morphological annotation.", "labels": [], "entities": [{"text": "morphological segmentation", "start_pos": 61, "end_pos": 87, "type": "TASK", "confidence": 0.8581551611423492}, {"text": "CELEX", "start_pos": 105, "end_pos": 110, "type": "DATASET", "confidence": 0.9171679615974426}]}, {"text": " Table 4: F-measure for evaluation on manually an- notated CELEX and phoneme error rate (PER) from  g2p conversion using a decision tree (dt).", "labels": [], "entities": [{"text": "F-measure", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9968252182006836}, {"text": "phoneme error rate (PER)", "start_pos": 69, "end_pos": 93, "type": "METRIC", "confidence": 0.8185668339331945}]}]}