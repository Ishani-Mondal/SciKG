{"title": [], "abstractContent": [{"text": "Transliteration is the task of converting a word from one alphabetic script to another.", "labels": [], "entities": []}, {"text": "We present a novel, substring-based approach to transliteration, inspired by phrase-based models of machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 100, "end_pos": 119, "type": "TASK", "confidence": 0.7761912047863007}]}, {"text": "We investigate two implementations of substring-based transliteration: a dynamic programming algorithm, and a finite-state transducer.", "labels": [], "entities": []}, {"text": "We show that our substring-based transducer not only outperforms a state-of-the-art letter-based approach by a significant margin, but is also orders of magnitude faster.", "labels": [], "entities": []}], "introductionContent": [{"text": "A significant proportion of out-of-vocabulary words in machine translation models or cross language information retrieval systems are named entities.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 55, "end_pos": 74, "type": "TASK", "confidence": 0.7033198177814484}, {"text": "cross language information retrieval", "start_pos": 85, "end_pos": 121, "type": "TASK", "confidence": 0.5925700515508652}]}, {"text": "If the languages are written in different scripts, these names must be transliterated.", "labels": [], "entities": []}, {"text": "Transliteration is the task of converting a word from one writing script to another, usually based on the phonetics of the original word.", "labels": [], "entities": [{"text": "Transliteration is the task of converting a word from one writing script to another, usually based on the phonetics of the original word", "start_pos": 0, "end_pos": 136, "type": "Description", "confidence": 0.8015140642722448}]}, {"text": "If the target language contains all the phonemes used in the source language, the transliteration is straightforward.", "labels": [], "entities": []}, {"text": "For example, the Arabic transliteration of Amanda is \u00a9 \u00c3 \u00ad , which is essentially pronounced in the same way.", "labels": [], "entities": [{"text": "\u00a9 \u00c3", "start_pos": 53, "end_pos": 56, "type": "METRIC", "confidence": 0.9487890005111694}]}, {"text": "However, if some of the sounds are missing in the target language, they are generally mapped to the most phonetically similar letter.", "labels": [], "entities": []}, {"text": "For example, the sound in the name Paul, does not exist in Arabic, and the phonotactic constraints of Arabic disallow the sound in this context, so the word is transliterated as , pronounced.", "labels": [], "entities": []}, {"text": "The information loss inherent in the process of transliteration makes back-transliteration, which is the restoration of a previously transliterated word, a particularly difficult task.", "labels": [], "entities": []}, {"text": "Any phonetically reasonable forward transliteration is essentially correct, although occasionally there is a standard transliteration (e.g. Omar Sharif ).", "labels": [], "entities": []}, {"text": "In the original script, however, there is usually only a single correct form.", "labels": [], "entities": []}, {"text": "Ina statistical approach to machine transliteration, given a foreign word F , we are interested in finding the English word\u02c6Eword\u02c6 word\u02c6E that maximizes P (E|F ).", "labels": [], "entities": [{"text": "machine transliteration", "start_pos": 28, "end_pos": 51, "type": "TASK", "confidence": 0.7031052112579346}]}, {"text": "Using Bayes' rule, and keeping in mind that F is constant, we can formulate the task as follows: This is known as the noisy channel approach to machine transliteration, which splits the task into two parts.", "labels": [], "entities": [{"text": "machine transliteration", "start_pos": 144, "end_pos": 167, "type": "TASK", "confidence": 0.735242486000061}]}, {"text": "The language model provides an estimate of the probability P (E) of an English word, while the transliteration model provides an estimate of the probability P (F |E) of a foreign word being a transliteration of an English word.", "labels": [], "entities": []}, {"text": "The probabilities assigned by the transliteration and language models counterbalance each other.", "labels": [], "entities": []}, {"text": "For example, simply concatenating the most common mapping for each letter in the Arabic string \ud97b\udf59\u00fa\u00c3 \u00aa \ud97b\udf59\ud97b\udf59, produces the string maykl, which is barely pronounceable.", "labels": [], "entities": []}, {"text": "In order to generate the correct Michael, a model needs 944 to know the relatively rare letter relationships ch/\u00f8 and ae/\u01eb, and to balance their unlikelihood against the probability of the correct transliteration being an actual English name.", "labels": [], "entities": []}, {"text": "The search for the optimal English transliteration\u02c6E transliteration\u02c6 transliteration\u02c6E fora given foreign name F is referred to as decoding.", "labels": [], "entities": []}, {"text": "An efficient approach to decoding is dynamic programming, in which solutions to subproblems are maintained in a table and used to buildup the global solution in a bottom-up approach.", "labels": [], "entities": []}, {"text": "Dynamic programming approaches are optimal as long as the dynamic programming invariant assumption holds.", "labels": [], "entities": []}, {"text": "This assumption states that if the optimal path through a graph happens to go through state q, then this optimal path must include the best path up to and including q.", "labels": [], "entities": []}, {"text": "Thus, once an optimal path to state q is found, all other paths to q can be eliminated from the search.", "labels": [], "entities": []}, {"text": "The validity of this assumption depends on the state space used to define the model.", "labels": [], "entities": []}, {"text": "Typically, for problems related to word comparison, a dynamic programming approach will define states as positions in the source and target words.", "labels": [], "entities": [{"text": "word comparison", "start_pos": 35, "end_pos": 50, "type": "TASK", "confidence": 0.7287576794624329}]}, {"text": "As will be shown later, however, not all models can be represented with such a state space.", "labels": [], "entities": []}, {"text": "The phrase-based approach developed for statistical machine translation () is designed to overcome the restrictions on many-tomany mappings in word-based translation models.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 40, "end_pos": 71, "type": "TASK", "confidence": 0.6741434633731842}]}, {"text": "This approach is based on learning correspondences between phrases, rather than words.", "labels": [], "entities": []}, {"text": "Phrases are generated on the basis of a word-to-word alignment, with the constraint that no words within the phrase pair are linked to words outside the phrase pair.", "labels": [], "entities": []}, {"text": "In this paper, we propose to apply phrase-based translation methods to the task of machine transliteration, in an approach we refer to as substringbased transliteration.", "labels": [], "entities": [{"text": "phrase-based translation", "start_pos": 35, "end_pos": 59, "type": "TASK", "confidence": 0.7250309884548187}]}, {"text": "We consider two implementations of these models.", "labels": [], "entities": []}, {"text": "The first is an adaptation of the monotone search algorithm outlined in ().The second encodes the substringbased transliteration model as a transducer.", "labels": [], "entities": []}, {"text": "The results of experiments on Arabic-to-English transliteration show that the substring-based transducer outperforms a state-of-the-art letter-based transducer, while at the same time being orders of magnitude smaller and faster.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses previous approaches to machine transliteration.", "labels": [], "entities": [{"text": "machine transliteration", "start_pos": 43, "end_pos": 66, "type": "TASK", "confidence": 0.7313416004180908}]}, {"text": "Section 3 presents the letter-based transducer approach to Arabic-English transliteration proposed in), which we use as the main point of comparison for our substring-based models.", "labels": [], "entities": []}, {"text": "Section 4 presents our substring-based approaches to transliteration.", "labels": [], "entities": []}, {"text": "In Section 5, we outline the experiments used to evaluate the models and present their results.", "labels": [], "entities": []}, {"text": "Finally, Section 6 contains our overall impressions and conclusions.", "labels": [], "entities": []}, {"text": "propose to model forward transliteration through a combination of neural net and expert systems.", "labels": [], "entities": [{"text": "forward transliteration", "start_pos": 17, "end_pos": 40, "type": "TASK", "confidence": 0.6304388642311096}]}, {"text": "Their main task was to vowelize the Arabic names as a preprocessing step for transliteration.", "labels": [], "entities": [{"text": "vowelize the Arabic names", "start_pos": 23, "end_pos": 48, "type": "TASK", "confidence": 0.8697015047073364}]}, {"text": "Their method is Arabic-specific and requires that the Arabic names have a regular pattern of vowelization.", "labels": [], "entities": []}, {"text": "model the transliteration of Japanese syllabic katakana script into English with a sequence of finite-state transducers.", "labels": [], "entities": [{"text": "transliteration of Japanese syllabic katakana script", "start_pos": 10, "end_pos": 62, "type": "TASK", "confidence": 0.8246338466803232}]}, {"text": "After performing a conversion of the English and katakana sequences to their phonetic representations, the correspondences between the English and Japanese phonemes are learned with the expectation maximization (EM) algorithm.", "labels": [], "entities": []}, {"text": "adapt this approach to Arabic, with the modification that the English phonemes are mapped directly to Arabic letters.", "labels": [], "entities": []}, {"text": "find that a model mapping directly from English to Arabic letters outperforms the phoneme-toletter model.", "labels": [], "entities": []}, {"text": "model forward transliteration from Arabic to English by treating the words as sentences and using a statistical word alignment model to align the letters.", "labels": [], "entities": [{"text": "forward transliteration from Arabic to English", "start_pos": 6, "end_pos": 52, "type": "TASK", "confidence": 0.9050727089246114}]}, {"text": "They select common English n-grams based on cases when the alignment links an Arabic letter to several English letters, and consider these n-grams as single letters for the purpose of training.", "labels": [], "entities": []}, {"text": "The English transliterations are produced using probabilities, learned from the training data, for the mappings between Arabic letters and English letters/n-grams.", "labels": [], "entities": []}, {"text": "propose a letter-to-letter n-gram transliteration model for Chinese-English transliteration in an attempt to allow for the encoding of more 945 contextual information.", "labels": [], "entities": []}, {"text": "The model isolates individual mapping operations between training pairs, and then learns n-gram probabilities for sequences of these mapping operations.", "labels": [], "entities": []}, {"text": "adapt this model to the transliteration of names from Bengali to English.", "labels": [], "entities": [{"text": "transliteration of names from Bengali to English", "start_pos": 24, "end_pos": 72, "type": "TASK", "confidence": 0.8455888628959656}]}], "datasetContent": [{"text": "In this section, we describe the evaluation of our models on the task of Arabic-to-English transliteration.", "labels": [], "entities": []}, {"text": "For each of the 300 transliteration pairs in the test set, the name written in Arabic served as input to the models, while its English counterpart was considered a gold standard transliteration for the purpose of evaluation.", "labels": [], "entities": []}, {"text": "Two separate tests were performed on the test set.", "labels": [], "entities": []}, {"text": "In the first, the 300 English words in the test set were added to the training data for the language models (the seen test), while in the second, all English words in the test set were removed from the language model's training data (the unseen test).", "labels": [], "entities": []}, {"text": "Both tests were run on the same set of words to ensure that variations in performance for seen and unseen words were solely due to whether or not they appear in the language model (and not, for example, their language of origin).", "labels": [], "entities": []}, {"text": "The seen testis similar to tests run in and) where the models could not produce any words not included in the language model training data.", "labels": [], "entities": []}, {"text": "The models were evaluated on the seen test set in terms of exact matches to the gold standard.", "labels": [], "entities": [{"text": "seen test set", "start_pos": 33, "end_pos": 46, "type": "DATASET", "confidence": 0.8375955820083618}]}, {"text": "Because the task of generating transliterations for the unseen test set is much more difficult, exact match accuracy will not provide a meaningful metric for comparison.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 108, "end_pos": 116, "type": "METRIC", "confidence": 0.6177107691764832}]}, {"text": "Thus, a softer measure of performance was required to indicate how close the generated transliterations are to the gold standard.", "labels": [], "entities": []}, {"text": "We used Levenshtein distance: the number of insertions, deletions and substitutions required to convert one string into another.", "labels": [], "entities": [{"text": "Levenshtein distance", "start_pos": 8, "end_pos": 28, "type": "METRIC", "confidence": 0.6224658042192459}]}, {"text": "We present the results separately for names of Arabic origin and for those of non-Arabic origin.", "labels": [], "entities": []}, {"text": "We also performed a third test on words that appear in both the transliteration and language model training data.", "labels": [], "entities": []}, {"text": "This test was not indicative of the overall strength of the models but was meant to give a sense of how much each model depends on its language model versus its transliteration model.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Exact match accuracy percentage on the  seen test set for various methods.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 22, "end_pos": 30, "type": "METRIC", "confidence": 0.8817687034606934}, {"text": "seen test set", "start_pos": 50, "end_pos": 63, "type": "DATASET", "confidence": 0.740123838186264}]}, {"text": " Table 3: Average Levenshtein distance on the un- seen test set for various methods.", "labels": [], "entities": [{"text": "Average Levenshtein distance", "start_pos": 10, "end_pos": 38, "type": "METRIC", "confidence": 0.7779204448064169}, {"text": "un- seen test set", "start_pos": 46, "end_pos": 63, "type": "DATASET", "confidence": 0.8084716916084289}]}, {"text": " Table 5: Results for testing on the transliteration  training set.", "labels": [], "entities": []}]}