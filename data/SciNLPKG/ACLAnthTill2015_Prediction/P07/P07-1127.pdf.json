{"title": [{"text": "User Requirements Analysis for Meeting Information Retrieval Based on Query Elicitation", "labels": [], "entities": [{"text": "User Requirements Analysis", "start_pos": 0, "end_pos": 26, "type": "TASK", "confidence": 0.8231772184371948}, {"text": "Meeting Information Retrieval", "start_pos": 31, "end_pos": 60, "type": "TASK", "confidence": 0.7714775005976359}, {"text": "Query Elicitation", "start_pos": 70, "end_pos": 87, "type": "TASK", "confidence": 0.7058561593294144}]}], "abstractContent": [{"text": "We present a user requirements study for Question Answering on meeting records that assesses the difficulty of users questions in terms of what type of knowledge is required in order to provide the correct answer.", "labels": [], "entities": [{"text": "Question Answering", "start_pos": 41, "end_pos": 59, "type": "TASK", "confidence": 0.8107212483882904}]}, {"text": "We grounded our work on the empirical analysis of elicited user queries.", "labels": [], "entities": []}, {"text": "We found that the majority of elicited queries (around 60%) pertain to argumentative processes and outcomes.", "labels": [], "entities": []}, {"text": "Our analysis also suggests that standard keyword-based Information Retrieval can only deal successfully with less than 20% of the queries, and that it must be complemented with other types of metadata and inference.", "labels": [], "entities": [{"text": "Information Retrieval", "start_pos": 55, "end_pos": 76, "type": "TASK", "confidence": 0.6644131690263748}]}], "introductionContent": [{"text": "Meeting records constitute a particularly important and rich source of information.", "labels": [], "entities": []}, {"text": "Meetings area frequent and sustained activity, in which multiparty dialogues take place that are goal-oriented and where participants perform a series of actions, usually aimed at reaching a common goal: they exchange information, raise issues, express opinions, make suggestions, propose solutions, provide arguments (pro or con), negotiate alternatives, and make decisions.", "labels": [], "entities": [{"text": "participants perform a series of actions, usually aimed at reaching a common goal: they exchange information, raise issues, express opinions, make suggestions, propose solutions, provide arguments (pro or con), negotiate alternatives, and make decisions", "start_pos": 121, "end_pos": 374, "type": "Description", "confidence": 0.870276724629932}]}, {"text": "As outcomes of the meeting, agreements on future action items are reached, tasks are assigned, conflicts are solved, etc.", "labels": [], "entities": []}, {"text": "Meeting outcomes have a direct impact on the efficiency of organization and team performance, and the stored and indexed meeting records serve as reference for further processing).", "labels": [], "entities": []}, {"text": "They can also be used in future meetings in order to facilitate the decision-making process by accessing relevant information from previous meetings), or in order to make the discussion more focused).", "labels": [], "entities": []}, {"text": "Meetings constitute a substantial and important source of information that improves corporate organization and performance).", "labels": [], "entities": []}, {"text": "Novel multimedia techniques have been dedicated to meeting recording, structuring and content analysis according to the metadata schema, and finally, to accessing the analyzed content via browsing, querying or filtering (.", "labels": [], "entities": []}, {"text": "This paper focuses on debate meetings () because of their particular richness in information concerning the decision-making process.", "labels": [], "entities": []}, {"text": "We consider that the meeting content can be organized on three levels: (i) factual level (what happens: events, timeline, actions, dynamics); (ii) thematic level (what is said: topics discussed and details); (iii) argumentative level (which/how common goals are reached).", "labels": [], "entities": []}, {"text": "The information on the first two levels is explicit information that can be usually retrieved directly by searching the meeting records with appropriate IR techniques (i.e., TF-IDF).", "labels": [], "entities": []}, {"text": "The third level, on the contrary, contains more abstract and tacit information pertaining to how the explicit information contributes to the rationale of the meeting, and it is not present as such in raw meeting data: whether or not the meeting goal was reached, what issues were debated, what proposals were made, what alternatives were discussed, what arguments were brought, what decisions were made, what task were assigned, etc.", "labels": [], "entities": []}, {"text": "The motivating scenario is the following: A user needs information about a past meeting, either in quality of a participant who wants to recollect a discussion (since the memories of co-participants are often inconsistent, cf.), or as a non-participant who missed that meeting.", "labels": [], "entities": []}, {"text": "Instead of consulting the entire meeting-related information, which is usually heterogeneous and scaterred (audio-video recordings, notes, minutes, e-mails, handouts, etc.), the user asks natural language questions to a query engine which retrieves relevant information from the meeting records.", "labels": [], "entities": []}, {"text": "In this paper we assess the users' interest in retrieving argumentative information from meetings and what kind of knowledge is required for answering users' queries.", "labels": [], "entities": []}, {"text": "Section 2 reviews previous user requirements studies for the meeting domain.", "labels": [], "entities": []}, {"text": "Section 3 describes our user requirements study based on the analysis of elicited user queries, presents its main findings, and discusses the implications of these findings for the design of meeting retrieval systems.", "labels": [], "entities": []}, {"text": "Section 4 concludes the paper and outlines some directions for future work.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Query classification according to the  meeting content type.", "labels": [], "entities": [{"text": "Query classification", "start_pos": 10, "end_pos": 30, "type": "TASK", "confidence": 0.8789818286895752}]}, {"text": " Table 1. In both sets, the  information most sought was argumentative: about  55% of the IM2-set queries are argumentative  (process or outcome). This invalidates the initial  estimation of", "labels": [], "entities": []}, {"text": " Table 2. Inter-annotator agreement for query-type  classification.", "labels": [], "entities": [{"text": "query-type  classification", "start_pos": 40, "end_pos": 66, "type": "TASK", "confidence": 0.7670024037361145}]}, {"text": " Table 3: IR is sufficient for  answering 14.4% of the IM2 queries, and 20% of  the MS-set queries. In 50% and 25.7% of the cases,  respectively, it simply cannot be applied (irrele- vant). Finally, IR alone is not enough in 35.6% of  the queries from the IM2-set, and in 54.3% of the  MS-set; it has to be complemented with other  techniques.", "labels": [], "entities": [{"text": "IR", "start_pos": 10, "end_pos": 12, "type": "TASK", "confidence": 0.9456886053085327}, {"text": "irrele- vant)", "start_pos": 175, "end_pos": 188, "type": "METRIC", "confidence": 0.9270475506782532}, {"text": "IR", "start_pos": 199, "end_pos": 201, "type": "TASK", "confidence": 0.8864210844039917}]}, {"text": " Table 3. The role of IR (and topic extraction) in  answering users' queries.", "labels": [], "entities": [{"text": "IR", "start_pos": 22, "end_pos": 24, "type": "TASK", "confidence": 0.9497664570808411}, {"text": "topic extraction", "start_pos": 30, "end_pos": 46, "type": "TASK", "confidence": 0.6917406022548676}, {"text": "answering users' queries", "start_pos": 52, "end_pos": 76, "type": "TASK", "confidence": 0.875367005666097}]}, {"text": " Table 4. Queries requiring argumentative informa- tion.", "labels": [], "entities": []}, {"text": " Table 5. Some of the most frequent combinations of information required for answering the queries in the  IM2-Set and in the MS-set when IR alone fails.", "labels": [], "entities": []}]}