{"title": [{"text": "Exploiting Syntactic and Shallow Semantic Kernels for Question/Answer Classification", "labels": [], "entities": [{"text": "Question/Answer Classification", "start_pos": 54, "end_pos": 84, "type": "TASK", "confidence": 0.7472447603940964}]}], "abstractContent": [{"text": "We study the impact of syntactic and shallow semantic information in automatic classification of questions and answers and answer re-ranking.", "labels": [], "entities": [{"text": "automatic classification of questions and answers", "start_pos": 69, "end_pos": 118, "type": "TASK", "confidence": 0.8385142882664999}]}, {"text": "We define (a) new tree structures based on shallow semantics encoded in Predicate Argument Structures (PASs) and (b) new kernel functions to exploit the representational power of such structures with Support Vector Machines.", "labels": [], "entities": []}, {"text": "Our experiments suggest that syntactic information helps tasks such as question/answer classification and that shallow semantics gives remarkable contribution when a reliable set of PASs can be extracted, e.g. from answers.", "labels": [], "entities": [{"text": "question/answer classification", "start_pos": 71, "end_pos": 101, "type": "TASK", "confidence": 0.705617681145668}]}], "introductionContent": [{"text": "Question answering (QA) is as a form of information retrieval where one or more answers are returned to a question in natural language in the form of sentences or phrases.", "labels": [], "entities": [{"text": "Question answering (QA)", "start_pos": 0, "end_pos": 23, "type": "TASK", "confidence": 0.9321111679077149}, {"text": "information retrieval where one or more answers are returned to a question in natural language in the form of sentences or phrases", "start_pos": 40, "end_pos": 170, "type": "Description", "confidence": 0.7578155926682733}]}, {"text": "The typical QA system architecture consists of three phases: question processing, document retrieval and answer extraction ().", "labels": [], "entities": [{"text": "question processing", "start_pos": 61, "end_pos": 80, "type": "TASK", "confidence": 0.8379047214984894}, {"text": "document retrieval", "start_pos": 82, "end_pos": 100, "type": "TASK", "confidence": 0.7327777594327927}, {"text": "answer extraction", "start_pos": 105, "end_pos": 122, "type": "TASK", "confidence": 0.7522271871566772}]}, {"text": "Question processing is often centered on question classification, which selects one of k expected answer classes.", "labels": [], "entities": [{"text": "Question processing", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8655936121940613}, {"text": "question classification", "start_pos": 41, "end_pos": 64, "type": "TASK", "confidence": 0.7827511429786682}]}, {"text": "Most accurate models apply supervised machine learning techniques, e.g. SNoW (), where questions are encoded using various lexical, syntactic and semantic features.", "labels": [], "entities": []}, {"text": "The retrieval and answer extraction phases consist in retrieving relevant documents) and selecting candidate answer passages from them.", "labels": [], "entities": [{"text": "answer extraction", "start_pos": 18, "end_pos": 35, "type": "TASK", "confidence": 0.8265949785709381}]}, {"text": "A further answer re-ranking phase is optionally applied.", "labels": [], "entities": []}, {"text": "Here, too, the syntactic structure of a sentence appears to provide more useful information than a bag of words (), although the correct way to exploit it is still an open problem.", "labels": [], "entities": []}, {"text": "An effective way to integrate syntactic structures in machine learning algorithms is the use of tree kernel (TK) functions), which have been successfully applied to question classification () and other tasks, e.g. relation extraction ().", "labels": [], "entities": [{"text": "question classification", "start_pos": 165, "end_pos": 188, "type": "TASK", "confidence": 0.8478519916534424}, {"text": "relation extraction", "start_pos": 214, "end_pos": 233, "type": "TASK", "confidence": 0.8811279833316803}]}, {"text": "In more complex tasks such as computing the relatedness between questions and answers in answer re-ranking, to our knowledge no study uses kernel functions to encode syntactic information.", "labels": [], "entities": [{"text": "answer re-ranking", "start_pos": 89, "end_pos": 106, "type": "TASK", "confidence": 0.6375133544206619}]}, {"text": "Moreover, the study of shallow semantic information such as predicate argument structures annotated in the PropBank (PB) project) (www.cis.upenn.edu/ \u223c ace) is a promising research direction.", "labels": [], "entities": [{"text": "PropBank (PB) project", "start_pos": 107, "end_pos": 128, "type": "DATASET", "confidence": 0.8280885100364686}]}, {"text": "We argue that semantic structures can be used to characterize the relation between a question and a candidate answer.", "labels": [], "entities": []}, {"text": "In this paper, we extensively study new structural representations, encoding parse trees, bag-of-words, POS tags and predicate argument structures (PASs) for question classification and answer re-ranking.", "labels": [], "entities": [{"text": "question classification", "start_pos": 158, "end_pos": 181, "type": "TASK", "confidence": 0.8341355919837952}, {"text": "answer re-ranking", "start_pos": 186, "end_pos": 203, "type": "TASK", "confidence": 0.7945370078086853}]}, {"text": "We define new tree representations for both simple and nested PASs, i.e. PASs whose arguments are other predicates (Section 2).", "labels": [], "entities": []}, {"text": "Moreover, we define new kernel functions to exploit PASs, which we automatically derive with our SRL system () (Section 3).", "labels": [], "entities": []}, {"text": "Our experiments using SVMs and the above ker-776 nels and data (Section 4) shows the following: (a) our approach reaches state-of-the-art accuracy on question classification.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 138, "end_pos": 146, "type": "METRIC", "confidence": 0.9991021156311035}, {"text": "question classification", "start_pos": 150, "end_pos": 173, "type": "TASK", "confidence": 0.7829013168811798}]}, {"text": "(b) PB predicative structures are not effective for question classification but show promising results for answer classification on a corpus of answers to TREC-QA 2001 description questions.", "labels": [], "entities": [{"text": "question classification", "start_pos": 52, "end_pos": 75, "type": "TASK", "confidence": 0.7938601076602936}, {"text": "answer classification", "start_pos": 107, "end_pos": 128, "type": "TASK", "confidence": 0.790955126285553}, {"text": "TREC-QA 2001 description questions", "start_pos": 155, "end_pos": 189, "type": "DATASET", "confidence": 0.8320919871330261}]}, {"text": "We created such dataset by using YourQA), our basic Webbased QA system 1 . (c) The answer classifier increases the ranking accuracy of our QA system by about 25%.", "labels": [], "entities": [{"text": "YourQA", "start_pos": 33, "end_pos": 39, "type": "DATASET", "confidence": 0.9123609662055969}, {"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9541122317314148}]}, {"text": "Our results show that PAS and syntactic parsing are promising methods to address tasks affected by data sparseness like question/answer categorization.", "labels": [], "entities": [{"text": "PAS", "start_pos": 22, "end_pos": 25, "type": "TASK", "confidence": 0.8570804595947266}, {"text": "syntactic parsing", "start_pos": 30, "end_pos": 47, "type": "TASK", "confidence": 0.7051104009151459}, {"text": "question/answer categorization", "start_pos": 120, "end_pos": 150, "type": "TASK", "confidence": 0.636608861386776}]}], "datasetContent": [{"text": "The purpose of our experiments is to study the impact of the new representations introduced earlier for QA tasks.", "labels": [], "entities": []}, {"text": "In particular, we focus on question classification and answer re-ranking for Web-based QA systems.", "labels": [], "entities": [{"text": "question classification", "start_pos": 27, "end_pos": 50, "type": "TASK", "confidence": 0.8348346948623657}, {"text": "answer re-ranking", "start_pos": 55, "end_pos": 72, "type": "TASK", "confidence": 0.736466646194458}]}, {"text": "In the question classification task, we extend previous studies, e.g. (), by testing a set of previously designed kernels and their combination with our new Shallow Semantic Tree Kernel.", "labels": [], "entities": [{"text": "question classification", "start_pos": 7, "end_pos": 30, "type": "TASK", "confidence": 0.8282954692840576}]}, {"text": "In the answer re-ranking task, we approach the problem of detecting description answers, among the most complex in the literature ().", "labels": [], "entities": [{"text": "answer re-ranking task", "start_pos": 7, "end_pos": 29, "type": "TASK", "confidence": 0.8291090528170267}]}, {"text": "The representations that we adopt are: bag-ofwords (BOW), bag-of-POS tags (POS), parse tree (PT), predicate argument structure (PAS) and nested PAS (PASN).", "labels": [], "entities": []}, {"text": "BOW and POS are processed by means of a linear kernel, PT is processed with TK, PAS and PASN are processed by SSTK.", "labels": [], "entities": [{"text": "BOW", "start_pos": 0, "end_pos": 3, "type": "METRIC", "confidence": 0.9639523029327393}, {"text": "PT", "start_pos": 55, "end_pos": 57, "type": "METRIC", "confidence": 0.9832711815834045}, {"text": "PAS", "start_pos": 80, "end_pos": 83, "type": "METRIC", "confidence": 0.9792136549949646}, {"text": "PASN", "start_pos": 88, "end_pos": 92, "type": "METRIC", "confidence": 0.8575809597969055}]}, {"text": "We implemented the proposed kernels in the SVM-light-TK software available at ai-nlp.info.uniroma2.it/ moschitti/ which encodes tree kernel functions in SVM-light (Joachims, 1999).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Accuracy of the question classifier with dif- ferent feature combinations", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9964191913604736}]}, {"text": " Table 2: Baseline classifiers accuracy and MRR of  YourQA (QA), Google (Gg) and the best re-ranker", "labels": [], "entities": [{"text": "accuracy", "start_pos": 31, "end_pos": 39, "type": "METRIC", "confidence": 0.9978975057601929}, {"text": "MRR", "start_pos": 44, "end_pos": 47, "type": "METRIC", "confidence": 0.9994563460350037}, {"text": "YourQA", "start_pos": 52, "end_pos": 58, "type": "DATASET", "confidence": 0.9666137099266052}]}]}