{"title": [{"text": "HPSG Parsing with Shallow Dependency Constraints", "labels": [], "entities": [{"text": "HPSG Parsing", "start_pos": 0, "end_pos": 12, "type": "TASK", "confidence": 0.6119953393936157}]}], "abstractContent": [{"text": "We present a novel framework that combines strengths from surface syntactic parsing and deep syntactic parsing to increase deep parsing accuracy, specifically by combining dependency and HPSG parsing.", "labels": [], "entities": [{"text": "surface syntactic parsing", "start_pos": 58, "end_pos": 83, "type": "TASK", "confidence": 0.6486567755540212}, {"text": "deep syntactic parsing", "start_pos": 88, "end_pos": 110, "type": "TASK", "confidence": 0.7141043146451315}, {"text": "accuracy", "start_pos": 136, "end_pos": 144, "type": "METRIC", "confidence": 0.969816267490387}, {"text": "HPSG parsing", "start_pos": 187, "end_pos": 199, "type": "TASK", "confidence": 0.7221407890319824}]}, {"text": "We show that by using surface dependencies to constrain the application of wide-coverage HPSG rules, we can benefit from a number of parsing techniques designed for high-accuracy dependency parsing, while actually performing deep syntactic analysis.", "labels": [], "entities": []}, {"text": "Our framework results in a 1.4% absolute improvement over a state-of-the-art approach for wide coverage HPSG parsing.", "labels": [], "entities": [{"text": "absolute", "start_pos": 32, "end_pos": 40, "type": "METRIC", "confidence": 0.9650945067405701}, {"text": "wide coverage HPSG parsing", "start_pos": 90, "end_pos": 116, "type": "TASK", "confidence": 0.5699783489108086}]}], "introductionContent": [{"text": "Several efficient, accurate and robust approaches to data-driven dependency parsing have been proposed recently () for syntactic analysis of natural language using bilexical dependency relations.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 65, "end_pos": 83, "type": "TASK", "confidence": 0.6929946690797806}, {"text": "syntactic analysis of natural language", "start_pos": 119, "end_pos": 157, "type": "TASK", "confidence": 0.8377732753753662}]}, {"text": "Much of the appeal of these approaches is tied to the use of a simple formalism, which allows for the use of efficient parsing algorithms, as well as straightforward ways to train discriminative models to perform disambiguation.", "labels": [], "entities": []}, {"text": "At the same time, there is growing interest in parsing with more sophisticated lexicalized grammar formalisms, such as Lexical Functional Grammar (LFG), Lexicalized Tree Adjoining Grammar (LTAG) (, Headdriven Phrase Structure Grammar (HPSG) and Combinatory Categorial Grammar (CCG), which represent deep syntactic structures that cannot be expressed in a shallower formalism designed to represent only aspects of surface syntax, such as the dependency formalism used in current mainstream dependency parsing.", "labels": [], "entities": [{"text": "parsing", "start_pos": 47, "end_pos": 54, "type": "TASK", "confidence": 0.980426549911499}, {"text": "dependency parsing", "start_pos": 489, "end_pos": 507, "type": "TASK", "confidence": 0.7280941605567932}]}, {"text": "We present a novel framework that combines strengths from surface syntactic parsing and deep syntactic parsing, specifically by combining dependency and HPSG parsing.", "labels": [], "entities": [{"text": "surface syntactic parsing", "start_pos": 58, "end_pos": 83, "type": "TASK", "confidence": 0.653778205315272}, {"text": "deep syntactic parsing", "start_pos": 88, "end_pos": 110, "type": "TASK", "confidence": 0.7430199980735779}, {"text": "HPSG parsing", "start_pos": 153, "end_pos": 165, "type": "TASK", "confidence": 0.7701181173324585}]}, {"text": "We show that, by using surface dependencies to constrain the application of wide-coverage HPSG rules, we can benefit from a number of parsing techniques designed for high-accuracy dependency parsing, while actually performing deep syntactic analysis.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 180, "end_pos": 198, "type": "TASK", "confidence": 0.685716450214386}]}, {"text": "From the point of view of HPSG parsing, accuracy can be improved significantly through the use of highly accurate discriminative dependency models, without the difficulties involved in adapting these models to a more complex and linguistically sophisticated formalism.", "labels": [], "entities": [{"text": "HPSG parsing", "start_pos": 26, "end_pos": 38, "type": "TASK", "confidence": 0.7259706258773804}, {"text": "accuracy", "start_pos": 40, "end_pos": 48, "type": "METRIC", "confidence": 0.9987402558326721}]}, {"text": "In addition, improvements in dependency parsing accuracy are converted directly into improvements in HPSG parsing accuracy.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.6703320443630219}, {"text": "accuracy", "start_pos": 48, "end_pos": 56, "type": "METRIC", "confidence": 0.9364054799079895}, {"text": "HPSG parsing", "start_pos": 101, "end_pos": 113, "type": "TASK", "confidence": 0.6002568602561951}, {"text": "accuracy", "start_pos": 114, "end_pos": 122, "type": "METRIC", "confidence": 0.8012157082557678}]}, {"text": "From the point of view of dependency parsing, the application of HPSG rules to structures generated by a surface dependency model provides a principled and linguistically motivated way to identify deep syntactic phenomena, such as long-distance dependencies, raising and control.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7589637637138367}]}, {"text": "We begin by describing our dependency and HPSG parsing approaches in section 2.", "labels": [], "entities": [{"text": "HPSG parsing", "start_pos": 42, "end_pos": 54, "type": "TASK", "confidence": 0.7296604216098785}]}, {"text": "In section 3, we present our framework for HPSG parsing with shallow dependency constraints, and in section 4 we 2 Fast dependency parsing and wide-coverage HPSG parsing", "labels": [], "entities": [{"text": "HPSG parsing", "start_pos": 43, "end_pos": 55, "type": "TASK", "confidence": 0.7170986235141754}, {"text": "dependency parsing", "start_pos": 120, "end_pos": 138, "type": "TASK", "confidence": 0.6695888042449951}, {"text": "HPSG parsing", "start_pos": 157, "end_pos": 169, "type": "TASK", "confidence": 0.6673237830400467}]}], "datasetContent": [{"text": "We evaluate the accuracy of HPSG parsing with dependency constraints on the HPSG Treebank (, which is extracted from the Wall Street Journal portion of the Penn Treebank (Marcus et al., 1993) . Sections 02-21 were used for training (for HPSG and dependency parsers), section 22 was used as development data, and final testing was performed on section 23.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 16, "end_pos": 24, "type": "METRIC", "confidence": 0.9992770552635193}, {"text": "HPSG parsing", "start_pos": 28, "end_pos": 40, "type": "TASK", "confidence": 0.6914868354797363}, {"text": "HPSG Treebank", "start_pos": 76, "end_pos": 89, "type": "DATASET", "confidence": 0.9800758957862854}, {"text": "Wall Street Journal portion of the Penn Treebank", "start_pos": 121, "end_pos": 169, "type": "DATASET", "confidence": 0.9445713758468628}, {"text": "dependency parsers", "start_pos": 246, "end_pos": 264, "type": "TASK", "confidence": 0.7240935266017914}]}, {"text": "Following previous work on wide-coverage parsing with lexicalized grammars using the Penn Treebank, we evaluate the parser by measuring the accuracy of predicate-argument relations in the parser's output.", "labels": [], "entities": [{"text": "wide-coverage parsing", "start_pos": 27, "end_pos": 48, "type": "TASK", "confidence": 0.732710987329483}, {"text": "Penn Treebank", "start_pos": 85, "end_pos": 98, "type": "DATASET", "confidence": 0.9934086501598358}, {"text": "accuracy", "start_pos": 140, "end_pos": 148, "type": "METRIC", "confidence": 0.9984194040298462}]}, {"text": "A predicate-argument relation is defined as a tuple \u03c3, w h , a, w a , where \u03c3 is the predicate type (e.g. adjective, intransitive verb), w h is the headword of the predicate, a is the argument label (MODARG, ARG1, ... , ARG4), and w a is the headword of the argument.", "labels": [], "entities": [{"text": "MODARG", "start_pos": 200, "end_pos": 206, "type": "DATASET", "confidence": 0.8859416842460632}, {"text": "ARG1", "start_pos": 208, "end_pos": 212, "type": "DATASET", "confidence": 0.6592371463775635}, {"text": "ARG4", "start_pos": 220, "end_pos": 224, "type": "DATASET", "confidence": 0.887803852558136}]}, {"text": "Labeled precision (LP)/labeled recall (LR) is the ratio of tuples correctly identified by the parser.", "labels": [], "entities": [{"text": "Labeled precision (LP)/labeled recall (LR)", "start_pos": 0, "end_pos": 42, "type": "METRIC", "confidence": 0.8552091658115387}]}, {"text": "These predicateargument relations cover the full range of syntactic dependencies produced by the HPSG parser (including, long-distance dependencies, raising and control, in addition to surface dependencies).", "labels": [], "entities": []}, {"text": "In the experiments presented in this section, input sentences were automatically tagged with partsof-speech with about 97% accuracy, using a maximum entropy POS tagger.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 123, "end_pos": 131, "type": "METRIC", "confidence": 0.9980586171150208}]}, {"text": "We also report results on parsing text with gold standard POS tags, where explicitly noted.", "labels": [], "entities": []}, {"text": "This provides an upper-bound on what can be expected if a more sophisticated multitagging scheme (James R.) is used, instead of hard assignment of single tags in a preprocessing step as done here.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Summary of results on development data.  * The shallow accuracy of combination C1 corre- sponds to the dependency precision (no dependen- cies were reported for 8% of all words in the devel- opment set).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 65, "end_pos": 73, "type": "METRIC", "confidence": 0.9994246959686279}, {"text": "dependency precision", "start_pos": 113, "end_pos": 133, "type": "METRIC", "confidence": 0.601724773645401}]}, {"text": " Table 2: Final results on test set. The first set of  results show our HPSG baseline and HPSG with soft  dependency constraints using three different sources  of dependency constraints. The second set of results  show the accuracy of the same parsers when gold  part-of-speech tags are used. The third set of results  is from existing published models on the same data.", "labels": [], "entities": [{"text": "HPSG baseline", "start_pos": 72, "end_pos": 85, "type": "DATASET", "confidence": 0.9376547634601593}, {"text": "HPSG", "start_pos": 90, "end_pos": 94, "type": "DATASET", "confidence": 0.9267376065254211}, {"text": "accuracy", "start_pos": 223, "end_pos": 231, "type": "METRIC", "confidence": 0.9990968704223633}]}]}