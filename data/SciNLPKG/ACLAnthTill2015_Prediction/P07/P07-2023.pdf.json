{"title": [{"text": "Test Collection Selection and Gold Standard Generation fora Multiply-Annotated Opinion Corpus", "labels": [], "entities": []}], "abstractContent": [{"text": "Opinion analysis is an important research topic in recent years.", "labels": [], "entities": [{"text": "Opinion analysis", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.9671821594238281}]}, {"text": "However, there are no common methods to create evaluation corpora.", "labels": [], "entities": []}, {"text": "This paper introduces a method for developing opinion corpora involving multiple annotators.", "labels": [], "entities": []}, {"text": "The characteristics of the created corpus are discussed, and the methodologies to select more consistent testing collections and their corresponding gold standards are proposed.", "labels": [], "entities": []}, {"text": "Under the gold standards, an opinion extraction system is evaluated.", "labels": [], "entities": [{"text": "opinion extraction", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.7768921852111816}]}, {"text": "The experiment results show some interesting phenomena.", "labels": [], "entities": []}], "introductionContent": [{"text": "Opinion information processing has been studied for several years.", "labels": [], "entities": [{"text": "Opinion information processing", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.8994723757108053}]}, {"text": "Researchers extracted opinions from words, sentences, and documents, and both rule-based and statistical models are investigated).", "labels": [], "entities": []}, {"text": "The evaluation metrics precision, recall and f-measure are usually adopted.", "labels": [], "entities": [{"text": "precision", "start_pos": 23, "end_pos": 32, "type": "METRIC", "confidence": 0.9996517896652222}, {"text": "recall", "start_pos": 34, "end_pos": 40, "type": "METRIC", "confidence": 0.9997238516807556}, {"text": "f-measure", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9887031316757202}]}, {"text": "A reliable corpus is very important for the opinion information processing because the annotations of opinions concern human perspectives.", "labels": [], "entities": [{"text": "opinion information processing", "start_pos": 44, "end_pos": 74, "type": "TASK", "confidence": 0.8488528331120809}]}, {"text": "Though the corpora created by researchers were analyzed), the methods to increase the reliability of them were seldom touched.", "labels": [], "entities": [{"text": "reliability", "start_pos": 86, "end_pos": 97, "type": "METRIC", "confidence": 0.9739251136779785}]}, {"text": "The strict and lenient metrics for opinions were mentioned, but not discussed in details together with the corpora and their annotations.", "labels": [], "entities": []}, {"text": "This paper discusses the selection of testing collections and the generation of the corresponding gold standards under multiple annotations.", "labels": [], "entities": []}, {"text": "These testing collections are further used in an opinion extraction system and the system is evaluated with the corresponding gold standards.", "labels": [], "entities": [{"text": "opinion extraction", "start_pos": 49, "end_pos": 67, "type": "TASK", "confidence": 0.7350463718175888}]}, {"text": "The analysis of human annotations makes the improvements of opinion analysis systems feasible.", "labels": [], "entities": [{"text": "opinion analysis", "start_pos": 60, "end_pos": 76, "type": "TASK", "confidence": 0.8311169445514679}]}], "datasetContent": [{"text": "Experiment results of CopeOpi using four designed testing collections are shown in.", "labels": [], "entities": [{"text": "CopeOpi", "start_pos": 22, "end_pos": 29, "type": "DATASET", "confidence": 0.9647101163864136}]}, {"text": "Under the lenient metric with the lenient test collection, fmeasure scores 0.761 and 0.383 are achieved by CopeOpi.", "labels": [], "entities": [{"text": "fmeasure", "start_pos": 59, "end_pos": 67, "type": "METRIC", "confidence": 0.8535963296890259}, {"text": "CopeOpi", "start_pos": 107, "end_pos": 114, "type": "DATASET", "confidence": 0.9633831977844238}]}, {"text": "The strict metric is the most severe, and the performance drops a lot under it.", "labels": [], "entities": [{"text": "strict metric", "start_pos": 4, "end_pos": 17, "type": "METRIC", "confidence": 0.7628862857818604}]}, {"text": "Moreover, when using high agreement (H-A) and substantial consistency (S-C) test collections, the performance of the system does not increase in portion to the increase of agreement.", "labels": [], "entities": []}, {"text": "According to the agreement of annotators, people should perform best in the strict collection, and both high agreement and substantial consistency testing collections are easier than the lenient one.", "labels": [], "entities": [{"text": "agreement", "start_pos": 109, "end_pos": 118, "type": "METRIC", "confidence": 0.9460578560829163}]}, {"text": "This phenomenon shows that though this system's performance is satisfactory, its behavior is not like human beings.", "labels": [], "entities": []}, {"text": "For a computer system, the lenient testing collection is fuzzier and contains more information for judgment.", "labels": [], "entities": []}, {"text": "However, this also shows that the system may only take advantage of the surface information.", "labels": [], "entities": []}, {"text": "If we want our systems really judge like human beings, we should enhance the performance on strict, high agreement, and substantial consistency testing collections.", "labels": [], "entities": []}, {"text": "This analysis gives us, or other researchers who use this corpus for experiments, a direction to improve their own systems.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Statistics of cases A-E", "labels": [], "entities": []}, {"text": " Table 5. Kappa values for polarity judgment", "labels": [], "entities": []}, {"text": " Table 6. Under the  lenient metric with the lenient test collection, f- measure scores 0.761 and 0.383 are achieved by  CopeOpi. The strict metric is the most severe, and  the performance drops a lot under it. Moreover,", "labels": [], "entities": [{"text": "f- measure scores 0.761", "start_pos": 70, "end_pos": 93, "type": "METRIC", "confidence": 0.9156673669815063}, {"text": "CopeOpi", "start_pos": 121, "end_pos": 128, "type": "DATASET", "confidence": 0.9559404850006104}]}]}