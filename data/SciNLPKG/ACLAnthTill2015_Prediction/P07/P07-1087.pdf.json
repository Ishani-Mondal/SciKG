{"title": [{"text": "A Unified Tagging Approach to Text Normalization", "labels": [], "entities": [{"text": "Unified Tagging Approach", "start_pos": 2, "end_pos": 26, "type": "TASK", "confidence": 0.7098220984141032}, {"text": "Text Normalization", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.7338614612817764}]}], "abstractContent": [{"text": "This paper addresses the issue of text nor-malization, an important yet often overlooked problem in natural language processing.", "labels": [], "entities": []}, {"text": "By text normalization, we mean converting 'informally inputted' text into the canonical form, by eliminating 'noises' in the text and detecting paragraph and sentence boundaries in the text.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 3, "end_pos": 21, "type": "TASK", "confidence": 0.7122711092233658}]}, {"text": "Previously, text normalization issues were often under-taken in an ad-hoc fashion or studied separately.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 12, "end_pos": 30, "type": "TASK", "confidence": 0.8378779888153076}]}, {"text": "This paper first gives a formaliza-tion of the entire problem.", "labels": [], "entities": []}, {"text": "It then proposes a unified tagging approach to perform the task using Conditional Random Fields (CRF).", "labels": [], "entities": []}, {"text": "The paper shows that with the introduction of a small set of tags, most of the text normalization tasks can be performed within the approach.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 79, "end_pos": 97, "type": "TASK", "confidence": 0.7815563380718231}]}, {"text": "The accuracy of the proposed method is high, because the subtasks of normalization are interdependent and should be performed together.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.9997009038925171}]}, {"text": "Experimental results on email data cleaning show that the proposed method significantly outperforms the approach of using cascaded models and that of employing independent models.", "labels": [], "entities": [{"text": "email data cleaning", "start_pos": 24, "end_pos": 43, "type": "TASK", "confidence": 0.6078689396381378}]}], "introductionContent": [{"text": "More and more 'informally inputted' text data becomes available to natural language processing, such as raw text data in emails, newsgroups, forums, and blogs.", "labels": [], "entities": []}, {"text": "Consequently, how to effectively process the data and make it suitable for natural language processing becomes a challenging issue.", "labels": [], "entities": []}, {"text": "This is because informally inputted text data is usually very noisy and is not properly segmented.", "labels": [], "entities": []}, {"text": "For example, it may contain extra line breaks, extra spaces, and extra punctuation marks; and it may contain words badly cased.", "labels": [], "entities": []}, {"text": "Moreover, the boundaries between paragraphs and the boundaries between sentences are not clear.", "labels": [], "entities": []}, {"text": "We have examined 5,000 randomly collected emails and found that 98.4% of the emails contain noises (based on the definition in Section 5.1).", "labels": [], "entities": []}, {"text": "In order to perform high quality natural language processing, it is necessary to perform 'normalization' on informally inputted data first, specifically, to remove extra line breaks, segment the text into paragraphs, add missing spaces and missing punctuation marks, eliminate extra spaces and extra punctuation marks, delete unnecessary tokens, correct misused punctuation marks, restore badly cased words, correct misspelled words, and identify sentence boundaries.", "labels": [], "entities": []}, {"text": "Traditionally, text normalization is viewed as an engineering issue and is conducted in a more or less ad-hoc manner.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 15, "end_pos": 33, "type": "TASK", "confidence": 0.8457786738872528}]}, {"text": "For example, it is done by using rules or machine learning models at different levels.", "labels": [], "entities": []}, {"text": "In natural language processing, several issues of text normalization were studied, but were only done separately.", "labels": [], "entities": [{"text": "natural language processing", "start_pos": 3, "end_pos": 30, "type": "TASK", "confidence": 0.6588827768961588}, {"text": "text normalization", "start_pos": 50, "end_pos": 68, "type": "TASK", "confidence": 0.7692009508609772}]}, {"text": "This paper aims to conduct a thorough investigation on the issue.", "labels": [], "entities": []}, {"text": "First, it gives a formalization of the problem; specifically, it defines the subtasks of the problem.", "labels": [], "entities": []}, {"text": "Next, it proposes a unified approach to the whole task on the basis of tagging.", "labels": [], "entities": []}, {"text": "Specifically, it takes the problem as that of assigning tags to the input texts, with a tag representing deletion, preservation, or replacement of a token.", "labels": [], "entities": []}, {"text": "As the tagging model, it employs Conditional Random Fields (CRF).", "labels": [], "entities": [{"text": "tagging", "start_pos": 7, "end_pos": 14, "type": "TASK", "confidence": 0.9619702100753784}]}, {"text": "The unified model can achieve better performances in text normalization, because the subtasks of text normalization are often interdependent.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 53, "end_pos": 71, "type": "TASK", "confidence": 0.8350902199745178}, {"text": "text normalization", "start_pos": 97, "end_pos": 115, "type": "TASK", "confidence": 0.6968663483858109}]}, {"text": "Furthermore, there is no need to define specialized models and features to conduct different types of cleaning; all the cleaning processes have been formalized and conducted as assignments of the three types of tags.", "labels": [], "entities": []}, {"text": "Experimental results indicate that our method significantly outperforms the methods using cascaded models or independent models on normalization.", "labels": [], "entities": []}, {"text": "Our experiments also indicate that with the use of the tags defined, we can conduct most of the text normalization in the unified framework.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 96, "end_pos": 114, "type": "TASK", "confidence": 0.7847141623497009}]}, {"text": "Our contributions in this paper include: (a) formalization of the text normalization problem, (b) proposal of a unified tagging approach, and (c) empirical verification of the effectiveness of the proposed approach.", "labels": [], "entities": [{"text": "text normalization problem", "start_pos": 66, "end_pos": 92, "type": "TASK", "confidence": 0.8178343772888184}]}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we introduce related work.", "labels": [], "entities": []}, {"text": "In Section 3, we formalize the text normalization problem.", "labels": [], "entities": [{"text": "text normalization", "start_pos": 31, "end_pos": 49, "type": "TASK", "confidence": 0.8001947402954102}]}, {"text": "In Section 4, we explain our approach to the problem and in Section 5 we give the experimental results.", "labels": [], "entities": []}, {"text": "We conclude the paper in Section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. Unnecessary token deletion refers to dele- tion of tokens like '-----' and '====', which are  not needed in natural language processing. Note  that most of the subtasks conduct 'cleaning' of  noises, except paragraph boundary detection and  sentence boundary detection.", "labels": [], "entities": [{"text": "paragraph boundary detection", "start_pos": 217, "end_pos": 245, "type": "TASK", "confidence": 0.7456629276275635}, {"text": "sentence boundary detection", "start_pos": 251, "end_pos": 278, "type": "TASK", "confidence": 0.7395633260409037}]}, {"text": " Table 1. Text Normalization Subtasks", "labels": [], "entities": [{"text": "Text Normalization Subtasks", "start_pos": 10, "end_pos": 37, "type": "TASK", "confidence": 0.7435738841692606}]}, {"text": " Table 4. Statistics on data sets", "labels": [], "entities": []}, {"text": " Table 5. Performances of text normalization (%)", "labels": [], "entities": [{"text": "text normalization", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7833230197429657}]}, {"text": " Table 6. Performances of text normalization (%)", "labels": [], "entities": [{"text": "text normalization", "start_pos": 26, "end_pos": 44, "type": "TASK", "confidence": 0.7798129618167877}]}]}