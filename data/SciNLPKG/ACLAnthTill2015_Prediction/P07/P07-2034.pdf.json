{"title": [{"text": "Building Emotion Lexicon from Weblog Corpora", "labels": [], "entities": []}], "abstractContent": [{"text": "An emotion lexicon is an indispensable resource for emotion analysis.", "labels": [], "entities": [{"text": "emotion analysis", "start_pos": 52, "end_pos": 68, "type": "TASK", "confidence": 0.7192998379468918}]}, {"text": "This paper aims to mine the relationships between words and emotions using weblog corpora.", "labels": [], "entities": []}, {"text": "A collocation model is proposed to learn emotion lexicons from weblog articles.", "labels": [], "entities": []}, {"text": "Emotion classification at sentence level is experimented by using the mined lexicons to demonstrate their usefulness.", "labels": [], "entities": [{"text": "Emotion classification", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.9170962572097778}]}], "introductionContent": [{"text": "Weblog (blog) is one of the most widely used cybermedia in our internet lives that captures and shares moments of our day-to-day experiences, anytime and anywhere.", "labels": [], "entities": []}, {"text": "Blogs are web sites that timestamp posts from an individual or a group of people, called bloggers.", "labels": [], "entities": []}, {"text": "Bloggers may not follow formal writing styles to express emotional states.", "labels": [], "entities": []}, {"text": "In some cases, they must post in pure text, so they add printable characters, such as \":-)\" (happy) and \":-(\" (sad), to express their feelings.", "labels": [], "entities": []}, {"text": "In other cases, they type sentences with an internet messengerstyle interface, where they can attach a special set of graphic icons, or emoticons.", "labels": [], "entities": []}, {"text": "Different kinds of emoticons are introduced into text expressions to convey bloggers' emotions.", "labels": [], "entities": []}, {"text": "Since thousands of blog articles are created everyday, emotional expressions can be collected to form a large-scale corpus which guides us to build vocabularies that are more emotionally expressive.", "labels": [], "entities": []}, {"text": "Our approach can create an emotion lexicon free of laborious efforts of the experts who must be familiar with both linguistic and psychological knowledge.", "labels": [], "entities": []}], "datasetContent": [{"text": "Experiment results show that all methods utilizing Lexicon A have performance figures lower than the baseline, so Lexicon A is not useful.", "labels": [], "entities": []}, {"text": "In contrast, Lexicon B, which provides a larger collection of vocabularies and emotion senses, outperforms Lexicon A and the baseline.", "labels": [], "entities": []}, {"text": "Although Method 3 has the smallest candidate answer set and thus has the smallest upper bound recall, it outperforms the other two methods inmost cases.", "labels": [], "entities": [{"text": "recall", "start_pos": 94, "end_pos": 100, "type": "METRIC", "confidence": 0.938468337059021}]}, {"text": "Method 2 achieves better precisions when using Thayer's emotion categories.", "labels": [], "entities": [{"text": "precisions", "start_pos": 25, "end_pos": 35, "type": "METRIC", "confidence": 0.998671293258667}]}, {"text": "Method 1 treats the vote to every sense equally.", "labels": [], "entities": []}, {"text": "Hence, it loses some differentiation abilities.", "labels": [], "entities": []}, {"text": "Method 1 performs the best in the first case (Lexicon A, 40 classes).", "labels": [], "entities": []}, {"text": "We can also apply machine learning to the dataset to train a high-precision classification model.", "labels": [], "entities": []}, {"text": "To experiment with this idea, we adopt LIBSVM) as the SVM kernel to deal with the binary polarity classification problem.", "labels": [], "entities": [{"text": "binary polarity classification", "start_pos": 82, "end_pos": 112, "type": "TASK", "confidence": 0.6335663398106893}]}, {"text": "The SVM classifier chooses top k (k = 25, 50, 75, and 100) emotion words as features.", "labels": [], "entities": []}, {"text": "Since the SVM classifier uses a small feature set, there are testing instances which do not contain any features seen previously by the SVM classifier.", "labels": [], "entities": []}, {"text": "To deal with this problem, we use the class prediction from Method 3 for any testing instances without any features that the SVM classifier can recognize.", "labels": [], "entities": []}, {"text": "In, the SVM classifier employing 25 features has the highest precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 61, "end_pos": 70, "type": "METRIC", "confidence": 0.9985446929931641}]}, {"text": "On the other hand, the SVM classifier employing 50 features has the highest F measure when used in conjunction with Method 3.", "labels": [], "entities": [{"text": "F measure", "start_pos": 76, "end_pos": 85, "type": "METRIC", "confidence": 0.9940427839756012}]}], "tableCaptions": [{"text": " Table 1. Yahoo! Kimo Blog Emoticon Set.", "labels": [], "entities": [{"text": "Yahoo! Kimo Blog Emoticon Set", "start_pos": 10, "end_pos": 39, "type": "DATASET", "confidence": 0.9204452137152354}]}, {"text": " Table 2. Statistics of the Weblog Dataset.", "labels": [], "entities": [{"text": "Weblog Dataset", "start_pos": 28, "end_pos": 42, "type": "DATASET", "confidence": 0.9406119883060455}]}]}