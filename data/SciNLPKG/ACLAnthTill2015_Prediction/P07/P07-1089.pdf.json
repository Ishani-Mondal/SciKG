{"title": [], "abstractContent": [{"text": "In this paper, we propose forest-to-string rules to enhance the expressive power of tree-to-string translation models.", "labels": [], "entities": []}, {"text": "A forest-to-string rule is capable of capturing non-syntactic phrase pairs by describing the correspondence between multiple parse trees and one string.", "labels": [], "entities": []}, {"text": "To integrate these rules into tree-to-string translation models, auxiliary rules are introduced to provide a generalization level.", "labels": [], "entities": []}, {"text": "Experimental results show that, on the NIST 2005 Chinese-English test set, the tree-to-string model augmented with forest-to-string rules achieves a relative improvement of 4.3% in terms of BLEU score over the original model which allows tree-to-string rules only.", "labels": [], "entities": [{"text": "NIST 2005 Chinese-English test set", "start_pos": 39, "end_pos": 73, "type": "DATASET", "confidence": 0.9772773623466492}, {"text": "BLEU score", "start_pos": 190, "end_pos": 200, "type": "METRIC", "confidence": 0.9843584597110748}]}], "introductionContent": [{"text": "The past two years have witnessed the rapid development of linguistically syntax-based translation models (; ;), which induce tree-to-string translation rules from parallel texts with linguistic annotations.", "labels": [], "entities": []}, {"text": "They demonstrated very promising results when compared with the state of the art phrase-based system () in the NIST 2006 machine translation evaluation . While and  put emphasis on target language analysis, and show benefits from modeling the syntax of source language.", "labels": [], "entities": [{"text": "NIST 2006 machine translation evaluation", "start_pos": 111, "end_pos": 151, "type": "TASK", "confidence": 0.8359894514083862}, {"text": "target language analysis", "start_pos": 181, "end_pos": 205, "type": "TASK", "confidence": 0.6356798311074575}]}, {"text": "See http://www.nist.gov/speech/tests/mt/ One major problem with linguistically syntaxbased models, however, is that tree-to-string rules fail to syntactify non-syntactic phrase pairs because they require a syntax tree fragment over the phrase to be syntactified.", "labels": [], "entities": []}, {"text": "Here, we distinguish between syntactic and non-syntactic phrase pairs.", "labels": [], "entities": []}, {"text": "By \"syntactic\" we mean that the phrase pair is subsumed by some syntax tree fragment.", "labels": [], "entities": []}, {"text": "The phrase pairs without trees over them are non-syntactic.", "labels": [], "entities": []}, {"text": "report that approximately 28% of bilingual phrases are non-syntactic on their English-Chinese corpus.", "labels": [], "entities": []}, {"text": "We believe that it is important to make available to syntax-based models all the bilingual phrases that are typically available to phrase-based models.", "labels": [], "entities": []}, {"text": "On one hand, phrases have been proven to be a simple and powerful mechanism for machine translation.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 80, "end_pos": 99, "type": "TASK", "confidence": 0.7780952453613281}]}, {"text": "They excel at capturing translations of short idioms, providing local re-ordering decisions, and incorporating context information straightforwardly.", "labels": [], "entities": [{"text": "capturing translations of short idioms", "start_pos": 14, "end_pos": 52, "type": "TASK", "confidence": 0.7971392393112182}]}, {"text": "shows significant improvement by keeping the strengths of phrases while incorporating syntax into statistical translation.", "labels": [], "entities": []}, {"text": "On the other hand, the performance of linguistically syntax-based models can be hindered by making use of only syntactic phrase pairs.", "labels": [], "entities": []}, {"text": "Studies reveal that linguistically syntax-based models are sensitive to syntactic analysis), which is still not reliable enough to handle real-world texts due to limited size and domain of training data.", "labels": [], "entities": []}, {"text": "Various solutions are proposed to tackle the problem.", "labels": [], "entities": []}, {"text": "handle non-constituent phrasal translation by traversing the tree upwards until reaches anode that subsumes the phrase.", "labels": [], "entities": []}, {"text": "argue that this choice is inap-704 propriate because large applicability contexts are required.", "labels": [], "entities": []}, {"text": "For a non-syntactic phrase pair,  create a xRS rule headed by a pseudo, nonsyntactic nonterminal symbol that subsumes the phrase and corresponding multi-headed syntactic structure; and one sibling xRS rule that explains how the non-syntactic nonterminal symbol can be combined with other genuine nonterminals so as to obtain genuine parse trees.", "labels": [], "entities": []}, {"text": "The name of the pseudo nonterminal is designed to reflect how the corresponding rule can be fully realized.", "labels": [], "entities": []}, {"text": "However, they neglect alignment consistency when creating sibling rules.", "labels": [], "entities": []}, {"text": "In addition, it is hard for the naming mechanism to deal with more complex phenomena.", "labels": [], "entities": [{"text": "naming", "start_pos": 32, "end_pos": 38, "type": "TASK", "confidence": 0.9623244404792786}]}, {"text": "treat bilingual phrases as lexicalized TATs (Tree-to-string Alignment Template).", "labels": [], "entities": []}, {"text": "A bilingual phrase can be used in decoding if the source phrase is subsumed by the input parse tree.", "labels": [], "entities": []}, {"text": "Although this solution does help, only syntactic bilingual phrases are available to the TAT-based model.", "labels": [], "entities": []}, {"text": "Moreover, it is problematic to combine the translation probabilities of bilingual phrases and TATs, which are estimated independently.", "labels": [], "entities": []}, {"text": "In this paper, we propose forest-to-string rules which describe the correspondence between multiple parse trees and a string.", "labels": [], "entities": []}, {"text": "They cannot only capture non-syntactic phrase pairs but also have the capability of generalization.", "labels": [], "entities": []}, {"text": "To integrate these rules into tree-to-string translation models, auxiliary rules are introduced to provide a generalization level.", "labels": [], "entities": []}, {"text": "As there is no pseudo node or naming mechanism, the integration of forest-to-string rules is flexible, relying only on their root nodes.", "labels": [], "entities": []}, {"text": "The forest-to-string and auxiliary rules enable tree-to-string models to derive in a more general way, while the strengths of conventional tree-to-string rules still remain.", "labels": [], "entities": []}], "datasetContent": [{"text": "In this section, we report on experiments with Chinese-to-English translation.", "labels": [], "entities": [{"text": "Chinese-to-English translation", "start_pos": 47, "end_pos": 77, "type": "TASK", "confidence": 0.6699273884296417}]}, {"text": "The training corpus consists of 31, 149 sentence pairs with 843, 256 Chinese words and 949, 583 English words.", "labels": [], "entities": []}, {"text": "For the language model, we used SRI Language Modeling Toolkit to train a trigram model with modified Kneser-Ney smoothing) on the 31, 149 English sentences.", "labels": [], "entities": [{"text": "SRI Language Modeling Toolkit", "start_pos": 32, "end_pos": 61, "type": "DATASET", "confidence": 0.7784744054079056}]}, {"text": "We selected 571 short sentences from the 2002 NIST MT Evaluation test set as our development corpus, and used the 2005 NIST MT Evaluation test set as our test corpus.", "labels": [], "entities": [{"text": "NIST MT Evaluation test set", "start_pos": 46, "end_pos": 73, "type": "DATASET", "confidence": 0.9236536502838135}, {"text": "NIST MT Evaluation test set", "start_pos": 119, "end_pos": 146, "type": "DATASET", "confidence": 0.9344581723213196}]}, {"text": "Our evaluation metric is BLEU-4 (, as calculated by the script mteval-v11b.pl with its default setting except that we used case-sensitive matching of n-grams.", "labels": [], "entities": [{"text": "BLEU-4", "start_pos": 25, "end_pos": 31, "type": "METRIC", "confidence": 0.9979044198989868}]}, {"text": "To perform minimum error rate training to tune the feature weights to maximize the system's BLEU score on development set, we used the script optimizeV5IBMBLEU.m).", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 92, "end_pos": 102, "type": "METRIC", "confidence": 0.9787538945674896}]}, {"text": "We ran GIZA++) on the training corpus in both directions using its default setting, and then applied the refinement rule \"diagand\" described in ( to obtain a single many-to-many word alignment for each sentence pair.", "labels": [], "entities": []}, {"text": "Next, we employed a Chinese parser written by Deyi Xiong () to parse all the 31, 149 Chinese sentences.", "labels": [], "entities": []}, {"text": "The parser was trained on articles 1-270 of Penn Chinese Treebank version 1.0 and achieved 79.4% in terms of F1 measure.", "labels": [], "entities": [{"text": "Penn Chinese Treebank version 1.0", "start_pos": 44, "end_pos": 77, "type": "DATASET", "confidence": 0.972018587589264}, {"text": "F1 measure", "start_pos": 109, "end_pos": 119, "type": "METRIC", "confidence": 0.9804520308971405}]}, {"text": "Given the word-aligned, source side parsed bilingual corpus, we obtained bilingual phrases using the training toolkits publicly released by Philipp Koehn with its default setting.", "labels": [], "entities": []}, {"text": "Then, we applied extraction algorithm described in to extract both tree-to-string and forest-to-string rules by restricting h = 3, c = 5, and l = 7.", "labels": [], "entities": []}, {"text": "All the rules, including bilingual phrases, tree-to-string rules, and forest-tostring rules, are filtered for the development and test sets.", "labels": [], "entities": []}, {"text": "According to different levels of lexicalization, we divide translation rules into three categories: 709 shows the statistics of rules used in our experiments.", "labels": [], "entities": []}, {"text": "We find that even though forest-to-string rules are introduced the total number (i.e. 73, 592) of lexicalized tree-to-string and forest-to-string rules is still far less than that (i.e. 251, 173) of bilingual phrases.", "labels": [], "entities": []}, {"text": "This difference results from the restriction we impose in training that both the first and last symbols in the target string must be aligned to some source symbols.", "labels": [], "entities": []}, {"text": "For the forest-to-string rules, partial lexicalized ones are in the majority.", "labels": [], "entities": []}, {"text": "We compared our system Lynx against a freely available phrase-based decoder Pharaoh ().", "labels": [], "entities": []}, {"text": "For Pharaoh, we set a = 20, \u03b1 = 0, b = 100, \u03b2 = 10 \u22125 , and distortion limit dl = 4.", "labels": [], "entities": [{"text": "distortion limit dl", "start_pos": 60, "end_pos": 79, "type": "METRIC", "confidence": 0.9769103129704794}]}, {"text": "For Lynx, we set a = 20, \u03b1 = 0, b = 100, and \u03b2 = 0.", "labels": [], "entities": [{"text": "Lynx", "start_pos": 4, "end_pos": 8, "type": "DATASET", "confidence": 0.9206843972206116}]}, {"text": "Two postprocessing procedures ran to improve the outputs of both systems: OOVs removal and recapitalization.: Effect of lexicalized, partial lexicalized, and unlexicalized forest-to-string rules.", "labels": [], "entities": [{"text": "OOVs removal", "start_pos": 74, "end_pos": 86, "type": "TASK", "confidence": 0.7601826786994934}]}], "tableCaptions": [{"text": " Table 1: A derivation composed of only tree-to-string rules for", "labels": [], "entities": []}, {"text": " Table 2: A derivation composed of tree-to-string, forest-to-string, and auxiliary rules for", "labels": [], "entities": []}, {"text": " Table 3: Subcell divisions and corresponding auxiliary rules for the source tree in", "labels": [], "entities": []}, {"text": " Table 4: Number of rules used in experiments (BP:  bilingual phrase, TR: tree-to-string rule, FR: forest- to-string rule; L: lexicalized, P: partial lexicalized,  U: unlexicalized).", "labels": [], "entities": [{"text": "FR", "start_pos": 95, "end_pos": 97, "type": "METRIC", "confidence": 0.9781468510627747}]}]}