{"title": [{"text": "Instance Weighting for Domain Adaptation in NLP", "labels": [], "entities": [{"text": "Instance Weighting", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.8986428081989288}, {"text": "Domain Adaptation", "start_pos": 23, "end_pos": 40, "type": "TASK", "confidence": 0.7334485352039337}]}], "abstractContent": [{"text": "Domain adaptation is an important problem in natural language processing (NLP) due to the lack of labeled data in novel domains.", "labels": [], "entities": [{"text": "Domain adaptation", "start_pos": 0, "end_pos": 17, "type": "TASK", "confidence": 0.7876408696174622}, {"text": "natural language processing (NLP)", "start_pos": 45, "end_pos": 78, "type": "TASK", "confidence": 0.8159480889638265}]}, {"text": "In this paper, we study the domain adaptation problem from the instance weighting perspective.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.7432011961936951}]}, {"text": "We formally analyze and characterize the domain adaptation problem from a distributional view, and show that there are two distinct needs for adaptation, corresponding to the different distributions of instances and classification functions in the source and the target domains.", "labels": [], "entities": [{"text": "domain adaptation problem", "start_pos": 41, "end_pos": 66, "type": "TASK", "confidence": 0.7885709007581075}]}, {"text": "We then propose a general instance weighting framework for domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 59, "end_pos": 76, "type": "TASK", "confidence": 0.7351006865501404}]}, {"text": "Our empirical results on three NLP tasks show that incorporating and exploiting more information from the target domain through instance weighting is effective.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many natural language processing (NLP) problems such as part-of-speech (POS) tagging, named entity (NE) recognition, relation extraction, and semantic role labeling, are currently solved by supervised learning from manually labeled data.", "labels": [], "entities": [{"text": "part-of-speech (POS) tagging", "start_pos": 56, "end_pos": 84, "type": "TASK", "confidence": 0.687470805644989}, {"text": "named entity (NE) recognition", "start_pos": 86, "end_pos": 115, "type": "TASK", "confidence": 0.659964049855868}, {"text": "relation extraction", "start_pos": 117, "end_pos": 136, "type": "TASK", "confidence": 0.845118910074234}, {"text": "semantic role labeling", "start_pos": 142, "end_pos": 164, "type": "TASK", "confidence": 0.6123053828875223}]}, {"text": "A bottleneck problem with this supervised learning approach is the lack of annotated data.", "labels": [], "entities": []}, {"text": "As a special case, we often face the situation where we have a sufficient amount of labeled data in one domain, but have little or no labeled data in another related domain which we are interested in.", "labels": [], "entities": []}, {"text": "We thus face the domain adaptation problem.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.7534945607185364}]}, {"text": "Following), we call the first the source domain, and the second the target domain.", "labels": [], "entities": []}, {"text": "The domain adaptation problem is commonly encountered in NLP.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7591008841991425}]}, {"text": "For example, in POS tagging, the source domain maybe tagged WSJ articles, and the target domain maybe scientific literature that contains scientific terminology.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 16, "end_pos": 27, "type": "TASK", "confidence": 0.7251922786235809}]}, {"text": "In NE recognition, the source domain maybe annotated news articles, and the target domain maybe personal blogs.", "labels": [], "entities": [{"text": "NE recognition", "start_pos": 3, "end_pos": 17, "type": "TASK", "confidence": 0.9005061388015747}]}, {"text": "Another example is personalized spam filtering, where we may have many labeled spam and ham emails from publicly available sources, but we need to adapt the learned spam filter to an individual user's inbox because the user has her own, and presumably very different, distribution of emails and notion of spams.", "labels": [], "entities": [{"text": "personalized spam filtering", "start_pos": 19, "end_pos": 46, "type": "TASK", "confidence": 0.6717543601989746}]}, {"text": "Despite the importance of domain adaptation in NLP, currently there are no standard methods for solving this problem.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 26, "end_pos": 43, "type": "TASK", "confidence": 0.7406450659036636}]}, {"text": "An immediate possible solution is semi-supervised learning, where we simply treat the target instances as unlabeled data but do not distinguish the two domains.", "labels": [], "entities": []}, {"text": "However, given that the source data and the target data are from different distributions, we should expect to do better by exploiting the domain difference.", "labels": [], "entities": []}, {"text": "Recently there have been some studies addressing domain adaptation from different perspectives).", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 49, "end_pos": 66, "type": "TASK", "confidence": 0.7366138398647308}]}, {"text": "However, there have not been many studies that focus on the difference between the instance distributions in the two domains.", "labels": [], "entities": []}, {"text": "A detailed discussion on related work is given in Section 5.", "labels": [], "entities": [{"text": "Section 5", "start_pos": 50, "end_pos": 59, "type": "DATASET", "confidence": 0.83792644739151}]}, {"text": "In this paper, we study the domain adaptation problem from the instance weighting perspective.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 28, "end_pos": 45, "type": "TASK", "confidence": 0.7432011961936951}]}, {"text": "In general, the domain adaptation problem arises when the source instances and the target instances are from two different, but related distributions.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 16, "end_pos": 33, "type": "TASK", "confidence": 0.7793503999710083}]}, {"text": "We formally analyze and characterize the domain adaptation problem from this distributional view.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 41, "end_pos": 58, "type": "TASK", "confidence": 0.71462482213974}]}, {"text": "Such an analysis reveals that there are two distinct needs for adaptation, corresponding to the different distributions of instances and the different classification functions in the source and the target domains.", "labels": [], "entities": []}, {"text": "Based on this analysis, we propose a general instance weighting method for domain adaptation, which can be regarded as a generalization of an existing approach to semi-supervised learning.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 75, "end_pos": 92, "type": "TASK", "confidence": 0.7228915244340897}]}, {"text": "The proposed method implements several adaptation heuristics with a unified objective function: (1) removing misleading training instances in the source domain; (2) assigning more weights to labeled target instances than labeled source instances; (3) augmenting training instances with target instances with predicted labels.", "labels": [], "entities": []}, {"text": "We evaluated the proposed method with three adaptation problems in NLP, including POS tagging, NE type classification, and spam filtering.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 82, "end_pos": 93, "type": "TASK", "confidence": 0.7590955197811127}, {"text": "NE type classification", "start_pos": 95, "end_pos": 117, "type": "TASK", "confidence": 0.7765214443206787}, {"text": "spam filtering", "start_pos": 123, "end_pos": 137, "type": "TASK", "confidence": 0.8864879608154297}]}, {"text": "The results show that regular semi-supervised and supervised learning methods do not perform as well as our new method, which explicitly captures domain difference.", "labels": [], "entities": []}, {"text": "Our results also show that incorporating and exploiting more information from the target domain is much more useful for improving performance than excluding misleading training examples from the source domain.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "In Section 2, we formally analyze the domain adaptation problem and distinguish two types of adaptation.", "labels": [], "entities": [{"text": "domain adaptation problem", "start_pos": 38, "end_pos": 63, "type": "TASK", "confidence": 0.7852504750092825}]}, {"text": "In Section 3, we then propose a general instance weighting framework for domain adaptation.", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 73, "end_pos": 90, "type": "TASK", "confidence": 0.7397203892469406}]}, {"text": "In Section 4, we present the experiment results.", "labels": [], "entities": []}, {"text": "Finally, we compare our framework with related work in Section 5 before we conclude in Section 6.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Accuracy on the target domain after removing \"misleading\" source domain instances.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9931118488311768}]}, {"text": " Table 2: Accuracy on the unlabeled target instances after adding the labeled target instances.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9966417551040649}]}, {"text": " Table 3: Accuracy on the target domain without using labeled target instances. In balanced bootstrapping,  more weights are put on the target instances in the objective function than in standard bootstrapping.", "labels": [], "entities": []}]}