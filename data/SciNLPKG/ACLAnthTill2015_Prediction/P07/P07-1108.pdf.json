{"title": [{"text": "Pivot Language Approach for Phrase-Based Statistical Machine Translation", "labels": [], "entities": [{"text": "Phrase-Based Statistical Machine Translation", "start_pos": 28, "end_pos": 72, "type": "TASK", "confidence": 0.7835646271705627}]}], "abstractContent": [{"text": "This paper proposes a novel method for phrase-based statistical machine translation by using pivot language.", "labels": [], "entities": [{"text": "phrase-based statistical machine translation", "start_pos": 39, "end_pos": 83, "type": "TASK", "confidence": 0.6279325485229492}]}, {"text": "To conduct translation between languages L f and Le with a small bilingual corpus, we bring in a third", "labels": [], "entities": [{"text": "translation between languages L f", "start_pos": 11, "end_pos": 44, "type": "TASK", "confidence": 0.820282232761383}]}], "introductionContent": [{"text": "For statistical machine translation (SMT), phrasebased methods () and syntax-based methods) outperform word-based methods).", "labels": [], "entities": [{"text": "statistical machine translation (SMT)", "start_pos": 4, "end_pos": 41, "type": "TASK", "confidence": 0.8193961878617605}]}, {"text": "These methods need large bilingual corpora.", "labels": [], "entities": []}, {"text": "However, for some languages pairs, only a small bilingual corpus is available, which will degrade the performance of statistical translation systems.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 117, "end_pos": 140, "type": "TASK", "confidence": 0.6409294009208679}]}, {"text": "To solve this problem, this paper proposes a novel method for phrase-based SMT by using a pivot language.", "labels": [], "entities": [{"text": "SMT", "start_pos": 75, "end_pos": 78, "type": "TASK", "confidence": 0.7309160828590393}]}, {"text": "To perform translation between languages L f and Le , we bring in a pivot language L p , for which there exist large bilingual corpora for language pairs L f -L p and L p -L e . With the L f -L p and L p -L e bilingual corpora, we can build a translation model for L f -L e by using L p as the pivot language.", "labels": [], "entities": []}, {"text": "We name the translation model pivot model.", "labels": [], "entities": []}, {"text": "The advantage of this method lies in that we can conduct translation between L f and Le even if there is no bilingual corpus available for this language pair.", "labels": [], "entities": []}, {"text": "Moreover, if a small corpus is available for L f -L e , we build another translation model, which is named standard model.", "labels": [], "entities": []}, {"text": "Then, we build an interpolated model by performing linear interpolation on the standard model and the pivot model.", "labels": [], "entities": []}, {"text": "Thus, the interpolated model can employ both the small L f -L e corpus and the large L f -L p and L p -L e corpora.", "labels": [], "entities": []}, {"text": "We perform experiments on the Europarl corpus ().", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 30, "end_pos": 45, "type": "DATASET", "confidence": 0.9914520382881165}]}, {"text": "Using BLEU () as a metric, our method achieves an absolute improvement of 0.06 (22.13% relative) as compared with the standard model trained with 5,000 L f -L e sentence pairs for French-Spanish translation.", "labels": [], "entities": [{"text": "BLEU", "start_pos": 6, "end_pos": 10, "type": "METRIC", "confidence": 0.9986646175384521}]}, {"text": "The translation quality is comparable with that of the model trained with a bilingual corpus of 30,000 L f -L e sentence pairs.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9461183547973633}]}, {"text": "Moreover, translation quality is further boosted by using both the small L f -L e bilingual corpus and the large L f -L p and L p -L e corpora.", "labels": [], "entities": [{"text": "translation", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.9731643795967102}]}, {"text": "Experimental results on Chinese-Japanese translation also indicate that our method achieves satisfactory results using English as the pivot language.", "labels": [], "entities": [{"text": "Chinese-Japanese translation", "start_pos": 24, "end_pos": 52, "type": "TASK", "confidence": 0.6612455248832703}]}, {"text": "The remainder of this paper is organized as follows.", "labels": [], "entities": []}, {"text": "In section 2, we describe the related work.", "labels": [], "entities": []}, {"text": "Section 3 briefly introduces phrase-based SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 42, "end_pos": 45, "type": "TASK", "confidence": 0.6969436407089233}]}, {"text": "Section 4 and Section 5 describes our method for phrase-based SMT using pivot language.", "labels": [], "entities": [{"text": "SMT", "start_pos": 62, "end_pos": 65, "type": "TASK", "confidence": 0.8241347670555115}]}, {"text": "We describe the experimental results in sections 6 and 7.", "labels": [], "entities": []}, {"text": "Lastly, we conclude in section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "To perform phrase-based SMT, we use Koehn's training scripts 1 and the Pharaoh decoder).", "labels": [], "entities": [{"text": "phrase-based SMT", "start_pos": 11, "end_pos": 27, "type": "TASK", "confidence": 0.6423746645450592}]}, {"text": "We run the decoder with its default settings and then use Koehn's implementation of minimum error rate training to tune the feature weights on the development set.", "labels": [], "entities": [{"text": "minimum error rate", "start_pos": 84, "end_pos": 102, "type": "METRIC", "confidence": 0.7185832858085632}]}, {"text": "The translation quality was evaluated using a well-established automatic measure: BLEU score ().", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.9563384652137756}, {"text": "BLEU score", "start_pos": 82, "end_pos": 92, "type": "METRIC", "confidence": 0.9816997945308685}]}, {"text": "And we also use the tool provided in the NAACL/HLT 2006 shared task on SMT to calculate the BLEU scores.", "labels": [], "entities": [{"text": "NAACL/HLT 2006 shared task on SMT", "start_pos": 41, "end_pos": 74, "type": "DATASET", "confidence": 0.8719886764883995}, {"text": "BLEU", "start_pos": 92, "end_pos": 96, "type": "METRIC", "confidence": 0.9978249073028564}]}, {"text": "In section 6, translation results on the Europarl multilingual corpus indicate the effectiveness of our method.", "labels": [], "entities": [{"text": "translation", "start_pos": 14, "end_pos": 25, "type": "TASK", "confidence": 0.9653101563453674}, {"text": "Europarl multilingual corpus", "start_pos": 41, "end_pos": 69, "type": "DATASET", "confidence": 0.93415367603302}]}, {"text": "To investigate the effectiveness of our method by using independently sourced parallel corpora, we conduct Chinese-Japanese translation using English as a pivot language in this section, where the training data are not limited to a specific domain.", "labels": [], "entities": [{"text": "Chinese-Japanese translation", "start_pos": 107, "end_pos": 135, "type": "TASK", "confidence": 0.6036842167377472}]}, {"text": "The data used for this experiment is the same as those used in ().", "labels": [], "entities": []}, {"text": "There are, and 160,535 sentence pairs for the language pairs Chinese-Japanese, Chinese-English, and English-Japanese, respectively.", "labels": [], "entities": []}, {"text": "The development data and testing data include 500 and 1,000 Chinese sentences respectively, with one reference for each sentence.", "labels": [], "entities": []}, {"text": "For Japanese language model training, we use about 100M bytes Japanese corpus.", "labels": [], "entities": [{"text": "Japanese language model training", "start_pos": 4, "end_pos": 36, "type": "TASK", "confidence": 0.7660159319639206}]}, {"text": "The translation result is shown in.", "labels": [], "entities": []}, {"text": "The pivot model only outperforms the standard model trained with 2,500 sentence pairs.", "labels": [], "entities": []}, {"text": "This is because (1) the corpora used to train the pivot model are smaller as compared with the Europarl corpus; (2) the training data and the testing data are not limited to a specific domain; (3) The languages are not closely related.", "labels": [], "entities": [{"text": "Europarl corpus", "start_pos": 95, "end_pos": 110, "type": "DATASET", "confidence": 0.9910617172718048}]}, {"text": "The interpolated models significantly outperform the other models.", "labels": [], "entities": []}, {"text": "When only 5,000 sentence pairs are available, the BLEU score increases relatively by 20.53%.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 50, "end_pos": 60, "type": "METRIC", "confidence": 0.9798179268836975}]}, {"text": "With the entire (21,977 pairs) Chinese-Japanese available, the interpolated model relatively increases the BLEU score by 5.62%, from 0.1708 to 0.1804.", "labels": [], "entities": [{"text": "BLEU score", "start_pos": 107, "end_pos": 117, "type": "METRIC", "confidence": 0.9810128509998322}]}], "tableCaptions": [{"text": " Table 1. Training Corpus for European Languages", "labels": [], "entities": []}, {"text": " Table 2. Results with Different Lexical Weights", "labels": [], "entities": []}]}