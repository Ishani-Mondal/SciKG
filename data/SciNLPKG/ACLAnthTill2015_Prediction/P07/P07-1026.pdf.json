{"title": [{"text": "A Grammar-driven Convolution Tree Kernel for Se- mantic Role Classification", "labels": [], "entities": [{"text": "Se- mantic Role Classification", "start_pos": 45, "end_pos": 75, "type": "TASK", "confidence": 0.6868489503860473}]}], "abstractContent": [{"text": "Convolution tree kernel has shown promising results in semantic role classification.", "labels": [], "entities": [{"text": "semantic role classification", "start_pos": 55, "end_pos": 83, "type": "TASK", "confidence": 0.856216569741567}]}, {"text": "However, it only carries out hard matching, which may lead to over-fitting and less accurate similarity measure.", "labels": [], "entities": [{"text": "accurate similarity measure", "start_pos": 84, "end_pos": 111, "type": "METRIC", "confidence": 0.7945845524470011}]}, {"text": "To remove the constraint, this paper proposes a grammar-driven convolution tree kernel for semantic role classification by introducing more linguistic knowledge into the standard tree kernel.", "labels": [], "entities": [{"text": "semantic role classification", "start_pos": 91, "end_pos": 119, "type": "TASK", "confidence": 0.7744993170102438}]}, {"text": "The proposed grammar-driven tree kernel displays two advantages over the previous one: 1) grammar-driven approximate substructure matching and 2) grammar-driven approximate tree node matching.", "labels": [], "entities": [{"text": "grammar-driven approximate substructure matching", "start_pos": 90, "end_pos": 138, "type": "TASK", "confidence": 0.556229829788208}, {"text": "grammar-driven approximate tree node matching", "start_pos": 146, "end_pos": 191, "type": "TASK", "confidence": 0.5805157661437989}]}, {"text": "The two improvements enable the grammar-driven tree kernel explore more linguistically motivated structure features than the previous one.", "labels": [], "entities": []}, {"text": "Experiments on the CoNLL-2005 SRL shared task show that the grammar-driven tree kernel significantly outperforms the previous non-grammar-driven one in SRL.", "labels": [], "entities": [{"text": "CoNLL-2005 SRL shared task", "start_pos": 19, "end_pos": 45, "type": "DATASET", "confidence": 0.8395819813013077}]}, {"text": "Moreover, we present a composite kernel to integrate feature-based and tree kernel-based methods.", "labels": [], "entities": []}, {"text": "Experimental results show that the composite kernel outperforms the previously best-reported methods.", "labels": [], "entities": []}], "introductionContent": [{"text": "Given a sentence, the task of Semantic Role Labeling (SRL) consists of analyzing the logical forms expressed by some target verbs or nouns and some constituents of the sentence.", "labels": [], "entities": [{"text": "Semantic Role Labeling (SRL)", "start_pos": 30, "end_pos": 58, "type": "TASK", "confidence": 0.8398735622564951}]}, {"text": "In particular, for each predicate (target verb or noun) all the constituents in the sentence which fill semantic arguments (roles) of the predicate have to be recognized.", "labels": [], "entities": []}, {"text": "Typical semantic roles include Agent, Patient, Instrument, etc. and also adjuncts such as Locative, Temporal, Manner, and Cause, etc.", "labels": [], "entities": [{"text": "Manner", "start_pos": 110, "end_pos": 116, "type": "METRIC", "confidence": 0.8933420777320862}]}, {"text": "Generally, semantic role identification and classification are regarded as two key steps in semantic role labeling.", "labels": [], "entities": [{"text": "semantic role identification", "start_pos": 11, "end_pos": 39, "type": "TASK", "confidence": 0.7352930307388306}, {"text": "semantic role labeling", "start_pos": 92, "end_pos": 114, "type": "TASK", "confidence": 0.681610623995463}]}, {"text": "Semantic role identification involves classifying each syntactic element in a sentence into either a semantic argument or a non-argument while semantic role classification involves classifying each semantic argument identified into a specific semantic role.", "labels": [], "entities": [{"text": "Semantic role identification", "start_pos": 0, "end_pos": 28, "type": "TASK", "confidence": 0.7382882436116537}, {"text": "semantic role classification", "start_pos": 143, "end_pos": 171, "type": "TASK", "confidence": 0.6561102867126465}]}, {"text": "This paper focuses on semantic role classification task with the assumption that the semantic arguments have been identified correctly.", "labels": [], "entities": [{"text": "semantic role classification", "start_pos": 22, "end_pos": 50, "type": "TASK", "confidence": 0.8204395969708761}]}, {"text": "Both feature-based and kernel-based learning methods have been studied for semantic role classification ().", "labels": [], "entities": [{"text": "semantic role classification", "start_pos": 75, "end_pos": 103, "type": "TASK", "confidence": 0.8331765333811442}]}, {"text": "In feature-based methods, a flat feature vector is used to represent a predicateargument structure while, in kernel-based methods, a kernel function is used to measure directly the similarity between two predicate-argument structures.", "labels": [], "entities": []}, {"text": "As we know, kernel methods are more effective in capturing structured features. and used a convolution tree kernel) for semantic role classification.", "labels": [], "entities": [{"text": "semantic role classification", "start_pos": 120, "end_pos": 148, "type": "TASK", "confidence": 0.7485213677088419}]}, {"text": "The convolution tree kernel takes sub-tree as its feature and counts the number of common sub-trees as the similarity between two predicate-arguments.", "labels": [], "entities": []}, {"text": "This kernel has shown very promising results in SRL.", "labels": [], "entities": [{"text": "SRL", "start_pos": 48, "end_pos": 51, "type": "TASK", "confidence": 0.9885440468788147}]}, {"text": "However, as a general learning algorithm, the tree kernel only carries out hard matching between any two sub-trees without considering any linguistic knowledge in kernel design.", "labels": [], "entities": []}, {"text": "This makes the kernel fail to handle similar phrase structures (e.g., \"buy a car\" vs. \"buy a red car\") and near-synonymic grammar tags (e.g., the POS variations between \"high/JJ degree/NN\" 1 and \"higher/JJR degree/NN\") 2 . To some degree, it may lead to over-fitting and compromise performance.", "labels": [], "entities": []}, {"text": "This paper reports our preliminary study in addressing the above issue by introducing more linguistic knowledge into the convolution tree kernel.", "labels": [], "entities": []}, {"text": "To our knowledge, this is the first attempt in this research direction.", "labels": [], "entities": []}, {"text": "In detail, we propose a grammar-driven convolution tree kernel for semantic role classification that can carryout more linguistically motivated substructure matching.", "labels": [], "entities": [{"text": "semantic role classification", "start_pos": 67, "end_pos": 95, "type": "TASK", "confidence": 0.7466514706611633}, {"text": "substructure matching", "start_pos": 144, "end_pos": 165, "type": "TASK", "confidence": 0.7217300236225128}]}, {"text": "Experimental results show that the proposed method significantly outperforms the standard convolution tree kernel on the data set of the CoNLL-2005 SRL shared task.", "labels": [], "entities": [{"text": "CoNLL-2005 SRL shared task", "start_pos": 137, "end_pos": 163, "type": "DATASET", "confidence": 0.8725049048662186}]}, {"text": "The remainder of the paper is organized as follows: Section 2 reviews the previous work and Section 3 discusses our grammar-driven convolution tree kernel.", "labels": [], "entities": []}, {"text": "Section 4 shows the experimental results.", "labels": [], "entities": []}, {"text": "We conclude our work in Section 5.", "labels": [], "entities": []}], "datasetContent": [{"text": "Data: We use the CoNLL-2005 SRL shared task data) as our experimental corpus.", "labels": [], "entities": [{"text": "CoNLL-2005 SRL shared task data", "start_pos": 17, "end_pos": 48, "type": "DATASET", "confidence": 0.9341737270355225}]}, {"text": "The data consists of sections of the Wall Street Journal part of the Penn TreeBank (, with information on predicate-argument structures extracted from the PropBank corpus.", "labels": [], "entities": [{"text": "Wall Street Journal part", "start_pos": 37, "end_pos": 61, "type": "DATASET", "confidence": 0.9647733867168427}, {"text": "Penn TreeBank", "start_pos": 69, "end_pos": 82, "type": "DATASET", "confidence": 0.8385944962501526}, {"text": "PropBank corpus", "start_pos": 155, "end_pos": 170, "type": "DATASET", "confidence": 0.9629873037338257}]}, {"text": "As defined by the shared task, we use sections 02-21 for training, section 24 for development and section 23 for test.", "labels": [], "entities": []}, {"text": "There are 35 roles in the data including 7 Core (A0-A5, AA), 14 Adjunct (AM-) and 14 Reference (R-) arguments.", "labels": [], "entities": [{"text": "AA", "start_pos": 56, "end_pos": 58, "type": "METRIC", "confidence": 0.9908607006072998}]}, {"text": "We assume that the semantic role identification has been done correctly.", "labels": [], "entities": [{"text": "semantic role identification", "start_pos": 19, "end_pos": 47, "type": "TASK", "confidence": 0.7015435894330343}]}, {"text": "In this way, we can focus on the classification task and evaluate it more accurately.", "labels": [], "entities": [{"text": "classification task", "start_pos": 33, "end_pos": 52, "type": "TASK", "confidence": 0.8855777382850647}]}, {"text": "We evaluate the performance with Accuracy.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 33, "end_pos": 41, "type": "METRIC", "confidence": 0.9995902180671692}]}, {"text": "SVM) is selected as our classifier and the one vs. others strategy is adopted and the one with the largest margin is selected as the final answer.", "labels": [], "entities": []}, {"text": "In our implementation, we use the binary SVMLight and modify the Tree Kernel Tools) to a grammardriven one.", "labels": [], "entities": []}, {"text": "We use a greedy strategy to fine-tune parameters.", "labels": [], "entities": []}, {"text": "Evaluation on the development set shows that our kernel yields the best performance when \u03bb (decay factor of tree kernel), 1 \u03bb and 2 \u03bb (two penalty factors for the grammar-driven kernel), \u03b8 (hybrid kernel parameter) and c (a SVM training parameter to balance training error and margin) are set to 0.4, 0.6, 0.3, 0.6 and 2.4, respectively.", "labels": [], "entities": [{"text": "margin", "start_pos": 277, "end_pos": 283, "type": "METRIC", "confidence": 0.9083095192909241}]}, {"text": "For other parameters, we use default setting.", "labels": [], "entities": []}, {"text": "In the CoNLL 2005 benchmark data, we get 647 rules with optional nodes out of the total 6,534 grammar rules and define three equivalent node feature sets as below: \u2022 JJ, JJR, JJS \u2022 RB, RBR, RBS \u2022 NN, NNS, NNP, NNPS, NAC, NX Here, the verb feature set \"VB, VBD, VBG, VBN, VBP, VBZ\" is removed since the voice information is very indicative to the arguments of ARG0 (Agent, operator) and ARG1 (Thing operated).", "labels": [], "entities": [{"text": "CoNLL 2005 benchmark data", "start_pos": 7, "end_pos": 32, "type": "DATASET", "confidence": 0.9391070604324341}]}, {"text": "In order to make full use of the syntactic structure information and the other useful diverse flat features, we present a composite kernel to combine the grammar-driven hybrid kernel and feature-based method with polynomial kernel: (1 ) (0 1) Evaluation on the development set shows that the composite kernel yields the best performance when \u03b3 is set to 0.3.", "labels": [], "entities": []}, {"text": "Using the same setting, the system achieves the performance of 91.02% in Accuracy in the same test set.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 73, "end_pos": 81, "type": "METRIC", "confidence": 0.9995189905166626}]}, {"text": "It shows statistically significant improvement (\u03c7 2 test with p= 0.10) over using the standard features with the polynomial kernel (\u03b3 = 0, Accuracy = 89.92%) and using the grammar-driven hybrid convolution tree kernel (\u03b3 = 1, Accuracy = 87.96%).", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 139, "end_pos": 147, "type": "METRIC", "confidence": 0.9986556768417358}, {"text": "Accuracy", "start_pos": 226, "end_pos": 234, "type": "METRIC", "confidence": 0.9990150928497314}]}, {"text": "The main reason is that the tree kernel can capture effectively more structure features while the standard flat features can cover some other useful features, such as Voice, SubCat, which are hard to be covered by the tree kernel.", "labels": [], "entities": []}, {"text": "The experimental results suggest that these two kinds of methods are complementary to each other.", "labels": [], "entities": []}, {"text": "In order to further compare with other methods, we also do experiments on the dataset of English PropBank I (LDC2004T14).", "labels": [], "entities": [{"text": "English PropBank I (LDC2004T14)", "start_pos": 89, "end_pos": 120, "type": "DATASET", "confidence": 0.9253446161746979}]}, {"text": "The training, development and test sets follow the conventional split of Sections 02-21, 00 and 23.", "labels": [], "entities": []}, {"text": "compares our method with other previously best-reported methods with the same setting as discussed previously.", "labels": [], "entities": []}, {"text": "It shows that our method outperforms the previous best-reported one with a relative error rate reduction of 10.8% (0.97/(100-91)).", "labels": [], "entities": [{"text": "error rate", "start_pos": 84, "end_pos": 94, "type": "METRIC", "confidence": 0.931721031665802}]}, {"text": "This further verifies the effectiveness of the grammar-driven kernel method for semantic role classification.", "labels": [], "entities": [{"text": "semantic role classification", "start_pos": 80, "end_pos": 108, "type": "TASK", "confidence": 0.8091280659039816}]}], "tableCaptions": [{"text": " Table 1 lists counts of sentences  and arguments in the three data sets.", "labels": [], "entities": []}, {"text": " Table 3: Performance comparison between our  method and previous work", "labels": [], "entities": []}]}