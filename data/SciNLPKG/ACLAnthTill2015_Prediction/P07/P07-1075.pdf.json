{"title": [{"text": "A Multi-resolution Framework for Information Extraction from Free Text", "labels": [], "entities": [{"text": "Information Extraction from Free Text", "start_pos": 33, "end_pos": 70, "type": "TASK", "confidence": 0.8307260274887085}]}], "abstractContent": [{"text": "Extraction of relations between entities is an important part of Information Extraction on free text.", "labels": [], "entities": [{"text": "Extraction of relations between entities", "start_pos": 0, "end_pos": 40, "type": "TASK", "confidence": 0.8992063522338867}, {"text": "Information Extraction", "start_pos": 65, "end_pos": 87, "type": "TASK", "confidence": 0.6637244522571564}]}, {"text": "Previous methods are mostly based on statistical correlation and dependency relations between entities.", "labels": [], "entities": []}, {"text": "This paper reexamines the problem at the multi-resolution layers of phrase, clause and sentence using dependency and discourse relations.", "labels": [], "entities": []}, {"text": "Our multi-resolution framework ARE (Anchor and Relation) uses clausal relations in 2 ways: 1) to filter noisy dependency paths; and 2) to increase reliability of dependency path extraction.", "labels": [], "entities": [{"text": "ARE", "start_pos": 31, "end_pos": 34, "type": "METRIC", "confidence": 0.993598461151123}, {"text": "dependency path extraction", "start_pos": 162, "end_pos": 188, "type": "TASK", "confidence": 0.6662734945615133}]}, {"text": "The resulting system outperforms the previous approaches by 3%, 7%, 4% on MUC4, MUC6 and ACE RDC domains respectively .", "labels": [], "entities": [{"text": "MUC4", "start_pos": 74, "end_pos": 78, "type": "DATASET", "confidence": 0.8648967742919922}, {"text": "MUC6", "start_pos": 80, "end_pos": 84, "type": "DATASET", "confidence": 0.7020623087882996}, {"text": "ACE RDC domains", "start_pos": 89, "end_pos": 104, "type": "DATASET", "confidence": 0.7923499941825867}]}], "introductionContent": [{"text": "Information Extraction (IE) is the task of identifying information in texts and converting it into a predefined format.", "labels": [], "entities": [{"text": "Information Extraction (IE)", "start_pos": 0, "end_pos": 27, "type": "TASK", "confidence": 0.8383245885372161}]}, {"text": "The possible types of information include entities, relations or events.", "labels": [], "entities": []}, {"text": "In this paper, we follow the IE tasks as defined by the conferences MUC4, MUC6 and ACE RDC: slotbased extraction, template filling and relation extraction, respectively.", "labels": [], "entities": [{"text": "IE", "start_pos": 29, "end_pos": 31, "type": "TASK", "confidence": 0.9655829668045044}, {"text": "MUC4", "start_pos": 68, "end_pos": 72, "type": "DATASET", "confidence": 0.9457666873931885}, {"text": "MUC6", "start_pos": 74, "end_pos": 78, "type": "DATASET", "confidence": 0.8386584520339966}, {"text": "ACE RDC", "start_pos": 83, "end_pos": 90, "type": "DATASET", "confidence": 0.8604690134525299}, {"text": "slotbased extraction", "start_pos": 92, "end_pos": 112, "type": "TASK", "confidence": 0.7319764792919159}, {"text": "template filling", "start_pos": 114, "end_pos": 130, "type": "TASK", "confidence": 0.8066823184490204}, {"text": "relation extraction", "start_pos": 135, "end_pos": 154, "type": "TASK", "confidence": 0.8257140219211578}]}, {"text": "Previous approaches to IE relied on cooccurrence () and dependency ( ) relations between entities.", "labels": [], "entities": [{"text": "IE", "start_pos": 23, "end_pos": 25, "type": "TASK", "confidence": 0.9937230944633484}]}, {"text": "These relations enable us to make reliable extraction of correct entities/relations at the level of a single clause.", "labels": [], "entities": []}, {"text": "However, reported that the increase of relation path length will lead to considerable decrease in performance.", "labels": [], "entities": []}, {"text": "In most cases, this decrease in performance occurs because entities may belong to different clauses.", "labels": [], "entities": []}, {"text": "Since clauses in a sentence are connected by clausal relations, it is thus important to perform discourse analysis of a sentence.", "labels": [], "entities": []}, {"text": "Discourse analysis may contribute to IE in several ways.", "labels": [], "entities": [{"text": "Discourse analysis", "start_pos": 0, "end_pos": 18, "type": "TASK", "confidence": 0.7969728410243988}, {"text": "IE", "start_pos": 37, "end_pos": 39, "type": "TASK", "confidence": 0.9951841235160828}]}, {"text": "First, reported that discourse analysis helps to decompose long sentences into clauses.", "labels": [], "entities": [{"text": "discourse analysis", "start_pos": 21, "end_pos": 39, "type": "TASK", "confidence": 0.7039572298526764}]}, {"text": "Therefore, it helps to distinguish relevant clauses from non-relevant ones.", "labels": [], "entities": []}, {"text": "Second, stated that entities insubordinate clauses are less salient.", "labels": [], "entities": []}, {"text": "Third, the knowledge of textual structure helps to interpret the meaning of entities in a text (.", "labels": [], "entities": []}, {"text": "As an example, consider the sentences \"ABC Co. appointed anew chairman.", "labels": [], "entities": [{"text": "ABC Co.", "start_pos": 39, "end_pos": 46, "type": "DATASET", "confidence": 0.9726854264736176}]}, {"text": "Additionally, the current CEO was retired\".", "labels": [], "entities": []}, {"text": "The word 'additionally' connects the event in the second sentence to the entity 'ABC Co.'", "labels": [], "entities": [{"text": "ABC Co.", "start_pos": 81, "end_pos": 88, "type": "DATASET", "confidence": 0.9190701047579447}]}, {"text": "Fourth, reported that discourse segments tend to be in a fixed order for structured texts such as court decisions or news.", "labels": [], "entities": []}, {"text": "Hence, analysis of discourse order may reduce the variability of possible relations between entities.", "labels": [], "entities": []}, {"text": "To model these factors, we propose a multiresolution framework ARE that integrates both discourse and dependency relations at 2 levels.", "labels": [], "entities": [{"text": "ARE", "start_pos": 63, "end_pos": 66, "type": "METRIC", "confidence": 0.9931527376174927}]}, {"text": "ARE aims to filter noisy dependency relations from training and support their evaluation with discourse relations between entities.", "labels": [], "entities": []}, {"text": "Additionally, we encode semantic roles of entities in order to utilize semantic relations.", "labels": [], "entities": []}, {"text": "Evaluations on MUC4, MUC6 and ACE RDC 2003 corpora demonstrates that our approach outperforms the state-of-art systems mainly due to modeling of discourse relations.", "labels": [], "entities": [{"text": "MUC4", "start_pos": 15, "end_pos": 19, "type": "DATASET", "confidence": 0.8421582579612732}, {"text": "ACE RDC 2003 corpora", "start_pos": 30, "end_pos": 50, "type": "DATASET", "confidence": 0.9520091712474823}]}, {"text": "The contribution of this paper is in applying discourse relations to supplement dependency relations in a multi-resolution framework for IE.", "labels": [], "entities": [{"text": "IE", "start_pos": 137, "end_pos": 139, "type": "TASK", "confidence": 0.9851515889167786}]}, {"text": "The framework enables us to connect entities in different clauses and thus improve the performance on long-distance dependency paths.", "labels": [], "entities": []}, {"text": "Section 2 describes related work, while Section 3 presents our proposed framework, including the extraction of anchor cues and various types of relations, integration of extracted relations, and complexity classification.", "labels": [], "entities": [{"text": "complexity classification", "start_pos": 195, "end_pos": 220, "type": "TASK", "confidence": 0.7049057334661484}]}, {"text": "Section 4 describes our experimental results, with the analysis of results in Section 5.", "labels": [], "entities": []}, {"text": "Section 6 concludes the paper.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the first stage, we evaluate from training data the relevance of relation path Path l = [A i , Rel 1 ,\u2026, Rel n , A j ] between candidate anchors A i and A j of types Ci and C j . We divide this task into 2 steps.", "labels": [], "entities": []}, {"text": "The first step ranks each single relation Rel k \u2208 Path l ; while the second step combines the evaluations of Rel k to rank the whole relation path Path l .  At this stage, we have a set of accepted integral relation paths between any anchor pair A i and A j . The next task is to merge appropriate set of anchors into candidate templates.", "labels": [], "entities": []}, {"text": "Here we follow the methodology of.", "labels": [], "entities": []}, {"text": "For each sentence, we compose a set of candidate templates T using the extracted relation paths between each A i and A j . To evaluate each template Ti \u2208T, we combine the integral scores from relation paths between its anchors A i and A j into the overall Relation_Score T : where K is the number of extracted slots, M is the number of extracted relation paths between anchors A i and A j , and Score I (A i , A j ) is obtained from Equation (9).", "labels": [], "entities": [{"text": "Relation", "start_pos": 256, "end_pos": 264, "type": "METRIC", "confidence": 0.9615513682365417}, {"text": "Equation", "start_pos": 433, "end_pos": 441, "type": "METRIC", "confidence": 0.809043824672699}]}, {"text": "Next, we calculate the extracted entity score based on the scores of all the anchors in Ti : where Entity_Score(A i ) is taken from Equation (1).", "labels": [], "entities": [{"text": "Entity_Score(A i )", "start_pos": 99, "end_pos": 117, "type": "METRIC", "confidence": 0.9406907899039132}]}, {"text": "Finally, we obtain the combined evaluation fora template: where \u03bb is a predefined constant.", "labels": [], "entities": []}, {"text": "In order to decide whether the template Ti should be accepted or rejected, we need to determine a threshold Score T O from the training data.", "labels": [], "entities": [{"text": "threshold Score T O", "start_pos": 98, "end_pos": 117, "type": "METRIC", "confidence": 0.8300710916519165}]}, {"text": "If anchors of a candidate template match slots in a correct template, we consider the candidate template as correct.", "labels": [], "entities": []}, {"text": "Let TrainT = { Ti } be the set of candidate templates extracted from the training data, TrainT + \u2282 TrainT be the subset of correct candidate templates, and TotalT + be the total set of correct templates in the training data.", "labels": [], "entities": []}, {"text": "Also, let TrainT(X) = { Ti | Score T (T i ) \u2265 X, Ti \u2208 TrainT } be the set of candidate templates with score above X and TrainT + (X) \u2282 TrainT(X) be the subset of correct candidate templates.", "labels": [], "entities": []}, {"text": "We define the measures of precision, recall and F 1 as follows: Since the performance in IE is measured in F 1 -measure, an appropriate threshold to be used for the most prominent candidate templates is: The value Score T O is used as a training model.", "labels": [], "entities": [{"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9995394945144653}, {"text": "recall", "start_pos": 37, "end_pos": 43, "type": "METRIC", "confidence": 0.9995985627174377}, {"text": "F 1", "start_pos": 48, "end_pos": 51, "type": "METRIC", "confidence": 0.9936342835426331}, {"text": "IE", "start_pos": 89, "end_pos": 91, "type": "TASK", "confidence": 0.9421846270561218}, {"text": "F 1 -measure", "start_pos": 107, "end_pos": 119, "type": "METRIC", "confidence": 0.9540658742189407}, {"text": "value Score T O", "start_pos": 208, "end_pos": 223, "type": "METRIC", "confidence": 0.6877481192350388}]}, {"text": "During testing, we accept a candidate template InputT i if Score T (InputT i ) > Sco Ore .  We carryout our experiments on 3 domains: MUC4 (Terrorism), MUC6 (Management Succession), and ACE-Relation Detection and Characterization.", "labels": [], "entities": [{"text": "MUC4 (Terrorism)", "start_pos": 134, "end_pos": 150, "type": "TASK", "confidence": 0.6125581711530685}, {"text": "MUC6", "start_pos": 152, "end_pos": 156, "type": "DATASET", "confidence": 0.6939097046852112}, {"text": "ACE-Relation Detection and Characterization", "start_pos": 186, "end_pos": 229, "type": "TASK", "confidence": 0.8077865019440651}]}, {"text": "The MUC4 corpus contains 1,300 documents as training set and 200 documents (TST3 and TST4) as official testing set.", "labels": [], "entities": [{"text": "MUC4 corpus", "start_pos": 4, "end_pos": 15, "type": "DATASET", "confidence": 0.9607045352458954}]}, {"text": "We used a modified version of the MUC6 corpus described by  To compare the results on the terrorism domain in MUC4, we choose the recent state-of-art systems GRID by, and ARE (2006) by which does not utilize discourse and semantic relations.", "labels": [], "entities": [{"text": "MUC6 corpus", "start_pos": 34, "end_pos": 45, "type": "DATASET", "confidence": 0.9522522389888763}, {"text": "GRID", "start_pos": 158, "end_pos": 162, "type": "DATASET", "confidence": 0.6546345353126526}, {"text": "ARE", "start_pos": 171, "end_pos": 174, "type": "METRIC", "confidence": 0.9716213941574097}]}, {"text": "The comparative results are given in.", "labels": [], "entities": []}, {"text": "It shows that our enhanced ARE results in 3% improvement in F 1 measure over ARE (2006) that does not use clausal relations.", "labels": [], "entities": [{"text": "ARE", "start_pos": 27, "end_pos": 30, "type": "METRIC", "confidence": 0.9782162308692932}, {"text": "F 1 measure", "start_pos": 60, "end_pos": 71, "type": "METRIC", "confidence": 0.9779136180877686}, {"text": "ARE", "start_pos": 77, "end_pos": 80, "type": "METRIC", "confidence": 0.863324761390686}]}, {"text": "The improvement was due to the use of discourse relations on long paths, such as \"X distributed leaflets claiming responsibility for murder of Y\".", "labels": [], "entities": []}, {"text": "At the same time, for many instances, it would be useful to store the extracted anchors for another round of learning.", "labels": [], "entities": []}, {"text": "For example, the extracted features of discourse pattern \"murder -same_clause-> HUM_PERSON\" may boost the score for patterns that correspond to relation path \"X <-span-_ -Elaboration-> murder\".", "labels": [], "entities": [{"text": "HUM_PERSON", "start_pos": 80, "end_pos": 90, "type": "METRIC", "confidence": 0.6708608269691467}]}, {"text": "In this way, high-precision patterns will support the refinement of patterns with average recall and low precision.", "labels": [], "entities": [{"text": "recall", "start_pos": 90, "end_pos": 96, "type": "METRIC", "confidence": 0.9988580942153931}, {"text": "precision", "start_pos": 105, "end_pos": 114, "type": "METRIC", "confidence": 0.9928749799728394}]}, {"text": "This observation is similar to that described in Ciravegna's work on (LP) 2  Next, we present the performance of our system on MUC6 corpus (Management Succession) as shown in.", "labels": [], "entities": [{"text": "MUC6 corpus", "start_pos": 127, "end_pos": 138, "type": "DATASET", "confidence": 0.9297154545783997}]}, {"text": "The improvement of 7% in F 1 is mainly due to the filtering of irrelevant dependency relations.", "labels": [], "entities": [{"text": "F 1", "start_pos": 25, "end_pos": 28, "type": "METRIC", "confidence": 0.9354290068149567}]}, {"text": "Additionally, we noticed that 22% of testing sentences contain 2 answer templates, and entities in many of such templates are intertwined.", "labels": [], "entities": []}, {"text": "One example is the sentence \"Mr. Bronczek who is 39 years old succeeds Kenneth Newell 55 who was named to the new post of senior vice president\", which refers to 2 positions.", "labels": [], "entities": []}, {"text": "We therefore we need to extract 2 templates \"PersonIn: Bronczek, PersonOut: Newell\" and \"PersonIn: Newell, Post: senior vice president\".", "labels": [], "entities": []}, {"text": "The discourse analysis is useful to extract the second template, while rejecting another long-distance template \"PersonIn: Bronczek, PersonOut: Newell, Post: seniour vice president\".", "labels": [], "entities": []}, {"text": "Another remark is that it is important to assign 2 anchors of 'Cand_PersonIn' and 'Cand_PersonOut' for the phrase \"Kenneth Newell\".", "labels": [], "entities": []}, {"text": "The characteristic of the ACE corpus is that it contains a large amount of variations, while only 2% of possible dependency paths are correct.", "labels": [], "entities": [{"text": "ACE corpus", "start_pos": 26, "end_pos": 36, "type": "DATASET", "confidence": 0.7975632548332214}]}, {"text": "Since many of the relations occur only at the level of single clause (for example, most instances of relation At), the discourse analysis is used to eliminate long-distance dependency paths.", "labels": [], "entities": []}, {"text": "It allows us to significantly decrease the dimensionality of the problem.", "labels": [], "entities": []}, {"text": "We noticed that 38% of relation paths in ACE contain a single relation, 28% contain 2 relations and 34% contain \u2265 3 relations.", "labels": [], "entities": []}, {"text": "For the case of \u2265 3 relations, the analysis of dependency paths alone is not sufficient to eliminate the unreliable paths.", "labels": [], "entities": []}, {"text": "Our results for general types and specific subtypes are presented in  Based on our results in, discourse and dependency relations support each other in different situations.", "labels": [], "entities": []}, {"text": "We also notice that multiple instances require modeling of entities in the path.", "labels": [], "entities": []}, {"text": "Thus, in our future work we need to enrich the search space for relation patterns.", "labels": [], "entities": []}, {"text": "This observation corresponds to that reported in . Discourse parsing is very important to reduce the amount of variations for specific types on ACE RDC'03, as there are 48 possible anchor types.", "labels": [], "entities": [{"text": "Discourse parsing", "start_pos": 51, "end_pos": 68, "type": "TASK", "confidence": 0.7515052855014801}, {"text": "ACE RDC'03", "start_pos": 144, "end_pos": 154, "type": "DATASET", "confidence": 0.9223906397819519}]}, {"text": "The relatively small improvement of results in maybe attributed to the following reasons: 1) it is important to model the commonality relations, as was done by ; and 2) our relation paths do not encode entities.", "labels": [], "entities": []}, {"text": "This is different from , who were using entities in their subtrees.", "labels": [], "entities": []}, {"text": "Overall, the results indicate that the use of discourse relations leads to improvement over the state-of-art systems.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2. Results on MUC4", "labels": [], "entities": [{"text": "MUC4", "start_pos": 21, "end_pos": 25, "type": "TASK", "confidence": 0.6788434982299805}]}, {"text": " Table 2. It shows that our enhanced ARE results in  3% improvement in F 1 measure over ARE (2006)  that does not use clausal relations. The improve- ment was due to the use of discourse relations on  long paths, such as \"X distributed leaflets claiming  responsibility for murder of Y\". At the same time,  for many instances, it would be useful to store the  extracted anchors for another round of learning.  For example, the extracted features of discourse  pattern \"murder -same_clause-> HUM_PERSON\"  may boost the score for patterns that correspond to  relation path \"X <-span-_ -Elaboration-> mur- der\". In this way, high-precision patterns will sup- port the refinement of patterns with average recall  and low precision. This observation is similar to  that described in Ciravegna's work on (LP) 2", "labels": [], "entities": [{"text": "ARE", "start_pos": 37, "end_pos": 40, "type": "METRIC", "confidence": 0.7933080792427063}, {"text": "F 1 measure", "start_pos": 71, "end_pos": 82, "type": "METRIC", "confidence": 0.9356911579767863}, {"text": "recall", "start_pos": 701, "end_pos": 707, "type": "METRIC", "confidence": 0.998497724533081}, {"text": "precision", "start_pos": 717, "end_pos": 726, "type": "METRIC", "confidence": 0.9858476519584656}]}, {"text": " Table 3. Results on MUC6", "labels": [], "entities": [{"text": "MUC6", "start_pos": 21, "end_pos": 25, "type": "TASK", "confidence": 0.6308919191360474}]}, {"text": " Table 4. Results on ACE RDC'03, general types", "labels": [], "entities": [{"text": "ACE RDC'03", "start_pos": 21, "end_pos": 31, "type": "DATASET", "confidence": 0.8255176544189453}]}, {"text": " Table 5. Results on ACE RDC'03, specific types", "labels": [], "entities": [{"text": "ACE RDC'03", "start_pos": 21, "end_pos": 31, "type": "DATASET", "confidence": 0.7691300213336945}]}]}