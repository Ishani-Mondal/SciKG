{"title": [{"text": "Learning to Extract Relations from the Web using Minimal Supervision", "labels": [], "entities": [{"text": "Learning to Extract Relations from the Web", "start_pos": 0, "end_pos": 42, "type": "TASK", "confidence": 0.7708662067140851}]}], "abstractContent": [{"text": "We present anew approach to relation extraction that requires only a handful of training examples.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 28, "end_pos": 47, "type": "TASK", "confidence": 0.9741824269294739}]}, {"text": "Given a few pairs of named entities known to exhibitor not exhibit a particular relation, bags of sentences containing the pairs are extracted from the web.", "labels": [], "entities": []}, {"text": "We extend an existing relation extraction method to handle this weaker form of supervision , and present experimental results demonstrating that our approach can reliably extract relations from web documents.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.7665735185146332}]}], "introductionContent": [{"text": "A growing body of recent work in information extraction has addressed the problem of relation extraction (RE), identifying relationships between entities stated in text, such as or EmployedBy(Person, Company).", "labels": [], "entities": [{"text": "information extraction", "start_pos": 33, "end_pos": 55, "type": "TASK", "confidence": 0.752850204706192}, {"text": "relation extraction (RE)", "start_pos": 85, "end_pos": 109, "type": "TASK", "confidence": 0.8472204983234406}]}, {"text": "Supervised learning has been shown to be effective for RE (); however, annotating large corpora with examples of the relations to be extracted is expensive and tedious.", "labels": [], "entities": [{"text": "RE", "start_pos": 55, "end_pos": 57, "type": "TASK", "confidence": 0.7273993492126465}]}, {"text": "In this paper, we introduce a supervised learning approach to RE that requires only a handful of training examples and uses the web as a corpus.", "labels": [], "entities": [{"text": "RE", "start_pos": 62, "end_pos": 64, "type": "TASK", "confidence": 0.9928552508354187}]}, {"text": "Given a few pairs of well-known entities that clearly exhibitor do not exhibit a particular relation, such as CorpAcquired(Google, YouTube) and not(CorpAcquired(Yahoo, Microsoft)), a search engine is used to find sentences on the web that mention both of the entities in each of the pairs.", "labels": [], "entities": []}, {"text": "Although not all of the sentences for positive pairs will state the desired relationship, many of them will.", "labels": [], "entities": []}, {"text": "Presumably, none of the sentences for negative pairs state the targeted relation.", "labels": [], "entities": []}, {"text": "Multiple instance learning (MIL) is a machine learning framework that exploits this sort of weak supervision, in which a positive bag is a set of instances which is guaranteed to contain at least one positive example, and a negative bag is a set of instances all of which are negative.", "labels": [], "entities": [{"text": "Multiple instance learning (MIL)", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.7902882347504298}]}, {"text": "MIL was originally introduced to solve a problem in biochemistry (); however, it has since been applied to problems in other areas such as classifying image regions in computer vision (), and text categorization ().", "labels": [], "entities": [{"text": "MIL", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.9385365843772888}, {"text": "text categorization", "start_pos": 192, "end_pos": 211, "type": "TASK", "confidence": 0.804410457611084}]}, {"text": "We have extended an existing approach to relation extraction using support vector machines and string kernels () to handle this weaker form of MIL supervision.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 41, "end_pos": 60, "type": "TASK", "confidence": 0.9432855248451233}, {"text": "MIL supervision", "start_pos": 143, "end_pos": 158, "type": "TASK", "confidence": 0.8966946601867676}]}, {"text": "This approach can sometimes be misled by textual features correlated with the specific entities in the few training pairs provided.", "labels": [], "entities": []}, {"text": "Therefore, we also describe a method for weighting features in order to focus on those correlated with the target relation rather than with the individual entities.", "labels": [], "entities": []}, {"text": "We present experimental results demonstrating that our approach is able to accurately extract relations from the web by learning from such weak supervision.", "labels": [], "entities": []}], "datasetContent": [{"text": "For the purpose of evaluation, we created two datasets: one for corporate acquisitions, as shown in, and one for the person-birthplace relation, with the example pairs from   Given a pair of arguments (a 1 , a 2 ), the corresponding bag of sentences is created as follows: A query string \"a 1 * * * * * * * a 2 \" containing seven wildcard symbols between the two arguments is submitted to Google.", "labels": [], "entities": []}, {"text": "The preferences are set to search only for pages written in English, with Safesearch turned on.", "labels": [], "entities": []}, {"text": "This type of query will match documents where an occurrence of a 1 is separated from an occurrence of a 2 by at most seven content words.", "labels": [], "entities": []}, {"text": "This is an approximation of our actual information 580 need: \"return all documents containing a 1 and a 2 in the same sentence\".", "labels": [], "entities": []}, {"text": "The returned documents (limited by Google to the first 1000) are downloaded, and then the text is extracted using the HTML parser from the Java Swing package.", "labels": [], "entities": []}, {"text": "Whenever possible, the appropriate HTML tags (e.g. BR, DD, P, etc.) are used as hard end-of-sentence indicators.", "labels": [], "entities": [{"text": "BR", "start_pos": 51, "end_pos": 53, "type": "METRIC", "confidence": 0.9827685952186584}]}, {"text": "The text is further segmented into sentences with the OpenNLP 1 package.", "labels": [], "entities": [{"text": "OpenNLP 1 package", "start_pos": 54, "end_pos": 71, "type": "DATASET", "confidence": 0.9477893312772115}]}, {"text": "Sentences that do not contain both arguments a 1 and a 2 are discarded.", "labels": [], "entities": []}, {"text": "For every remaining sentence, we find the occurrences of a 1 and a 2 that are closest to each other, and create a relation example by replacing a 1 withe 1 and a 2 withe 2 . All other occurrences of a 1 and a 2 are replaced with a null token ignored by the subsequence kernel.", "labels": [], "entities": []}, {"text": "The number of sentences in every bag is shown in the last column of.", "labels": [], "entities": []}, {"text": "Because Google also counts pages that are deemed too similar in the first 1000, some of the bags can be relatively small.", "labels": [], "entities": []}, {"text": "As described in Section 5.1, the word-argument correlations are modeled through the quantity P (w|a) = C(w, a)/C(a), estimated as the ratio between the number of sentences containing wand a, and the number of sentences containing a.", "labels": [], "entities": []}, {"text": "These counts are computed over a bag of sentences containing a, which is created by querying Google for the argument a, and then by processing the results as described above.", "labels": [], "entities": []}, {"text": "Each dataset is split into two sets of bags: one for training and one for testing.", "labels": [], "entities": []}, {"text": "The test dataset was purposefully made difficult by including negative bags with arguments that during training were used in positive bags, and vice-versa.", "labels": [], "entities": []}, {"text": "In order to evaluate the relation extraction performance at the sentence level, we manually annotated all instances from the positive test bags.", "labels": [], "entities": [{"text": "relation extraction", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.832354724407196}]}, {"text": "The last column in Tables 2 & 3 shows, between parentheses, how many instances from the positive test bags are real positive instances.", "labels": [], "entities": []}, {"text": "The corporate acquisition test set has a total of 995 instances, out of which 156 are positive.", "labels": [], "entities": [{"text": "corporate acquisition test set", "start_pos": 4, "end_pos": 34, "type": "DATASET", "confidence": 0.7843180075287819}]}, {"text": "The person-birthplace test set has a total of 601 instances, and only 45 of them are positive.", "labels": [], "entities": [{"text": "person-birthplace test set", "start_pos": 4, "end_pos": 30, "type": "DATASET", "confidence": 0.6258547107378641}]}, {"text": "Extrapolating from the test set distribution, the pos-1 http://opennlp.sourceforge.net itive bags in the person-birthplace dataset are significantly sparser in real positive instances than the positive bags in the corporate acquisition dataset.", "labels": [], "entities": [{"text": "corporate acquisition dataset", "start_pos": 214, "end_pos": 243, "type": "DATASET", "confidence": 0.6298733949661255}]}, {"text": "The subsequence kernel described in Section 4 was used as a custom kernel for the LibSVM 2 Java package.", "labels": [], "entities": [{"text": "LibSVM 2 Java package", "start_pos": 82, "end_pos": 103, "type": "DATASET", "confidence": 0.8870743662118912}]}, {"text": "When run with the default parameters, the results were extremely poor -too much weight was given to the slack term in the objective function.", "labels": [], "entities": []}, {"text": "Minimizing the regularization term is essential in order to capture subsequence patterns shared among positive bags.", "labels": [], "entities": []}, {"text": "Therefore LibSVM was modified to solve the optimization problem from, where the capacity parameter C is normalized by the size of the transformed dataset.", "labels": [], "entities": [{"text": "LibSVM", "start_pos": 10, "end_pos": 16, "type": "DATASET", "confidence": 0.9389395713806152}]}, {"text": "In this new formulation, C is set to its default value of 1.0 -changing it to other values did not result in significant improvement.", "labels": [], "entities": []}, {"text": "The trade-off between false positive and false negative errors is controlled by the parameter c p . When set to its default value of 0.5, false-negative errors and false positive errors have the same impact on the objective function.", "labels": [], "entities": []}, {"text": "As expected, setting c p to a smaller value (0.1) resulted in better performance.", "labels": [], "entities": []}, {"text": "Tests with even lower values did not improve the results.", "labels": [], "entities": []}, {"text": "We compare the following four systems: SSK-MIL: This corresponds to the MIL formulation from Section 3, with the original subsequence kernel described in Section 4.", "labels": [], "entities": []}, {"text": "SSK-T1: This is the SSK-MIL system augmented with word weights, so that the Type I bias is reduced, as described in Section 5.1.", "labels": [], "entities": [{"text": "SSK-T1", "start_pos": 0, "end_pos": 6, "type": "DATASET", "confidence": 0.8126815557479858}]}], "tableCaptions": [{"text": " Table 4: Area Under Precision-Recall Curve.", "labels": [], "entities": []}]}