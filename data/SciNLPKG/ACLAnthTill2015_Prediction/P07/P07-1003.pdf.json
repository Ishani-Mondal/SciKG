{"title": [{"text": "Tailoring Word Alignments to Syntactic Machine Translation", "labels": [], "entities": [{"text": "Word Alignments", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.7044567316770554}, {"text": "Syntactic Machine Translation", "start_pos": 29, "end_pos": 58, "type": "TASK", "confidence": 0.777105470498403}]}], "abstractContent": [{"text": "Extracting tree transducer rules for syntactic MT systems can be hindered byword alignment errors that violate syntactic correspondences.", "labels": [], "entities": [{"text": "MT", "start_pos": 47, "end_pos": 49, "type": "TASK", "confidence": 0.7101876735687256}]}, {"text": "We propose a novel model for unsupervised word alignment which explicitly takes into account target language constituent structure, while retaining the robust-ness and efficiency of the HMM alignment model.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 42, "end_pos": 56, "type": "TASK", "confidence": 0.7068792581558228}, {"text": "HMM alignment", "start_pos": 186, "end_pos": 199, "type": "TASK", "confidence": 0.8114445507526398}]}, {"text": "Our model's predictions improve the yield of a tree transducer extraction system, without sacrificing alignment quality.", "labels": [], "entities": [{"text": "tree transducer extraction", "start_pos": 47, "end_pos": 73, "type": "TASK", "confidence": 0.6659079293409983}]}, {"text": "We also discuss the impact of various posterior-based methods of reconciling bidirectional alignments.", "labels": [], "entities": []}], "introductionContent": [{"text": "Syntactic methods are an increasingly promising approach to statistical machine translation, being both algorithmically appealing and empirically successful).", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 60, "end_pos": 91, "type": "TASK", "confidence": 0.7703218261400858}]}, {"text": "However, despite recent progress, almost all syntactic MT systems, indeed statistical MT systems in general, build upon crude legacy models of word alignment.", "labels": [], "entities": [{"text": "MT", "start_pos": 55, "end_pos": 57, "type": "TASK", "confidence": 0.8124938607215881}, {"text": "word alignment", "start_pos": 143, "end_pos": 157, "type": "TASK", "confidence": 0.7480234801769257}]}, {"text": "This dependence runs deep; for example, requires word alignments to project trees from the target language to the source, while requires alignments to induce grammar rules.", "labels": [], "entities": []}, {"text": "Word alignment models have not stood still in recent years.", "labels": [], "entities": [{"text": "Word alignment", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.6808753162622452}]}, {"text": "Unsupervised methods have seen substantial reductions in alignment error () as measured by the now much-maligned AER metric.", "labels": [], "entities": [{"text": "alignment error", "start_pos": 57, "end_pos": 72, "type": "METRIC", "confidence": 0.7155466079711914}, {"text": "AER", "start_pos": 113, "end_pos": 116, "type": "METRIC", "confidence": 0.9780327081680298}]}, {"text": "A host of discriminative methods have been introduced).", "labels": [], "entities": []}, {"text": "However, few of these methods have explicitly addressed the tension between word alignments and the syntactic processes that employ them).", "labels": [], "entities": [{"text": "word alignments", "start_pos": 76, "end_pos": 91, "type": "TASK", "confidence": 0.7192290723323822}]}, {"text": "We are particularly motivated by systems like the one described in, which constructs translations using tree-to-string transducer rules.", "labels": [], "entities": []}, {"text": "These rules are extracted from a bitext annotated with both English (target side) parses and word alignments.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 93, "end_pos": 108, "type": "TASK", "confidence": 0.6672600954771042}]}, {"text": "Rules are extracted from target side constituents that can be projected onto contiguous spans of the source sentence via the word alignment.", "labels": [], "entities": []}, {"text": "Constituents that project onto non-contiguous spans of the source sentence do not yield transducer rules themselves, and can only be incorporated into larger transducer rules.", "labels": [], "entities": []}, {"text": "Thus, if the word alignment of a sentence pair does not respect the constituent structure of the target sentence, then the minimal translation units must span large tree fragments, which do not generalize well.", "labels": [], "entities": []}, {"text": "We present and evaluate an unsupervised word alignment model similar in character and computation to the HMM model, but which incorporates a novel, syntax-aware distortion component which conditions on target language parse trees.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 40, "end_pos": 54, "type": "TASK", "confidence": 0.7089131772518158}]}, {"text": "These trees, while automatically generated and therefore imperfect, are nonetheless (1) a useful source of structural bias and (2) the same trees which constrain future stages of processing anyway.", "labels": [], "entities": []}, {"text": "In our model, the trees do not rule out any alignments, but rather softly influence the probability of transitioning between alignment positions.", "labels": [], "entities": []}, {"text": "In particular, transition probabilities condition upon paths through the target parse tree, allowing the model to prefer distortions which respect the tree structure.", "labels": [], "entities": []}, {"text": "17 Our model generates word alignments that better respect the parse trees upon which they are conditioned, without sacrificing alignment quality.", "labels": [], "entities": [{"text": "word alignments", "start_pos": 23, "end_pos": 38, "type": "TASK", "confidence": 0.7022438049316406}]}, {"text": "Using the joint training technique of to initialize the model parameters, we achieve an AER superior to the GIZA++ implementation of IBM model 4 ( and a reduction of 56.3% in aligned interior nodes, a measure of agreement between alignments and parses.", "labels": [], "entities": [{"text": "AER", "start_pos": 88, "end_pos": 91, "type": "METRIC", "confidence": 0.9995206594467163}]}, {"text": "As a result, our alignments yield more rules, which better match those we would extract had we used manual alignments.", "labels": [], "entities": []}], "datasetContent": [{"text": "To understand the behavior of this model, we computed the standard alignment error rate (AER) performance metric.", "labels": [], "entities": [{"text": "standard alignment error rate (AER) performance metric", "start_pos": 58, "end_pos": 112, "type": "METRIC", "confidence": 0.8934537106090121}]}, {"text": "We also investigated extractionspecific metrics: the frequency of interior nodes -a measure of how often the alignments violate the constituent structure of English parses -and a variant of the CPER metric of.", "labels": [], "entities": []}, {"text": "We evaluated the performance of our model on both French-English and Chinese-English manually aligned data sets.", "labels": [], "entities": [{"text": "French-English and Chinese-English manually aligned data sets", "start_pos": 50, "end_pos": 111, "type": "DATASET", "confidence": 0.6789306913103376}]}, {"text": "For Chinese, we trained on the FBIS corpus and the LDC bilingual dictionary, then tested on 491 hand-aligned sentences from the 2002 We trained on 100k sentences for each language.", "labels": [], "entities": [{"text": "FBIS corpus", "start_pos": 31, "end_pos": 42, "type": "DATASET", "confidence": 0.9663156867027283}, {"text": "LDC bilingual dictionary", "start_pos": 51, "end_pos": 75, "type": "DATASET", "confidence": 0.8942438960075378}]}], "tableCaptions": [{"text": " Table 1: Alignment error rates (AER) for 100k train- ing sentences. The evaluated alignments are a soft  union for French and a hard union for Chinese, both  using competitive thresholding decoding.  *  From  Ayan and Dorr (2006), grow-diag-final heuristic.", "labels": [], "entities": [{"text": "Alignment error rates (AER)", "start_pos": 10, "end_pos": 37, "type": "METRIC", "confidence": 0.8904738128185272}]}]}