{"title": [{"text": "Automated Vocabulary Acquisition and Interpretation in Multimodal Conversational Systems", "labels": [], "entities": [{"text": "Automated Vocabulary Acquisition", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.6378778020540873}]}], "abstractContent": [{"text": "Motivated by psycholinguistic findings that eye gaze is tightly linked to human language production, we developed an unsuper-vised approach based on translation models to automatically learn the mappings between words and objects on a graphic display during human machine conversation.", "labels": [], "entities": []}, {"text": "The experimental results indicate that user eye gaze can provide useful information to establish such mappings, which have important implications in automatically acquiring and interpreting user vocabularies for conversational systems.", "labels": [], "entities": []}], "introductionContent": [{"text": "To facilitate effective human machine conversation, it is important fora conversational system to have knowledge about user vocabularies and understand how these vocabularies are mapped to the internal entities for which the system has representations.", "labels": [], "entities": []}, {"text": "For example, in a multimodal conversational system that allows users to converse with a graphic interface, the system needs to know what vocabularies users tend to use to describe objects on the graphic display and what (type of) object(s) a user is attending to when a particular word is expressed.", "labels": [], "entities": [{"text": "know what vocabularies users tend to use to describe objects on the graphic display and what (type of) object(s) a user is attending to when a particular word is expressed", "start_pos": 127, "end_pos": 298, "type": "Description", "confidence": 0.8115771063736507}]}, {"text": "Here, we use acquisition to refer to the process of acquiring relevant vocabularies describing internal entities, and interpretation to refer to the process of automatically identifying internal entities given a particular word.", "labels": [], "entities": []}, {"text": "Both acquisition and interpretation have been traditionally approached by either knowledge engineering (e.g., manually created lexicons) or supervised learning from annotated data.", "labels": [], "entities": [{"text": "acquisition and interpretation", "start_pos": 5, "end_pos": 35, "type": "TASK", "confidence": 0.6847839256127676}]}, {"text": "In this paper, we describe an unsupervised approach that relies on naturally co-occurred eye gaze and spoken utterances during human machine conversation to automatically acquire and interpret vocabularies.", "labels": [], "entities": []}, {"text": "Motivated by psycholinguistic studies and recent investigations on computational models for language acquisition and grounding), we are particularly interested in two unique questions related to multimodal conversational systems: (1) Ina multimodal conversation that involves more complex tasks (e.g., both user initiated tasks and system initiated tasks), is there a reliable temporal alignment between eye gaze and spoken references so that the coupled inputs can be used for automated vocabulary acquisition and interpretation?", "labels": [], "entities": [{"text": "language acquisition", "start_pos": 92, "end_pos": 112, "type": "TASK", "confidence": 0.7149676978588104}, {"text": "vocabulary acquisition and interpretation", "start_pos": 488, "end_pos": 529, "type": "TASK", "confidence": 0.7355916947126389}]}, {"text": "(2) If such an alignment exists, how can we model this alignment and automatically acquire and interpret the vocabularies?", "labels": [], "entities": []}, {"text": "To address the first question, we conducted an empirical study to examine the temporal relationships between eye fixations and their corresponding spoken references.", "labels": [], "entities": []}, {"text": "As shown later in section 4, although a larger variance (compared to the findings from psycholinguistic studies) exists in terms of how eye gaze is linked to speech production during human machine conversation, eye fixations and the corresponding spoken references still occur in a very close vicinity to each other.", "labels": [], "entities": []}, {"text": "This natural coupling between eye gaze and speech provides an opportunity to automatically learn the mappings between 368 words and objects without any human supervision.", "labels": [], "entities": []}, {"text": "Because of the larger variance, it is difficult to apply rule-based approaches to quantify this alignment.", "labels": [], "entities": []}, {"text": "Therefore, to address the second question, we developed an approach based on statistical translation models to explore the co-occurrence patterns between eye fixated objects and spoken references.", "labels": [], "entities": []}, {"text": "Our preliminary experiment results indicate that the translation model can reliably capture the mappings between the eye fixated objects and the corresponding spoken references.", "labels": [], "entities": []}, {"text": "Given an object, this model can provide possible words describing this object, which represents the acquisition process; given a word, this model can also provide possible objects that are likely to be described, which represents the interpretation process.", "labels": [], "entities": []}, {"text": "In the following sections, we first review some related work and introduce the procedures used to collect eye gaze and speech data during human machine conversation.", "labels": [], "entities": []}, {"text": "We then describe our empirical study and the unsupervised approach based on translation models.", "labels": [], "entities": []}, {"text": "Finally, we present experiment results and discuss their implications in natural language processing applications.", "labels": [], "entities": []}], "datasetContent": [{"text": "We experimented our proposed statistical translation model on the collected data mentioned in Section 3.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 29, "end_pos": 52, "type": "TASK", "confidence": 0.6798923313617706}]}, {"text": "As described in Section 5, by using a statistical translation model we can get a set of translation probabilities, either from any given spoken word to all the objects, or from any given object to all the spoken words.", "labels": [], "entities": []}, {"text": "To evaluate the two sets of translation probabilities, we use precision and recall as   evaluation metrics.", "labels": [], "entities": [{"text": "precision", "start_pos": 62, "end_pos": 71, "type": "METRIC", "confidence": 0.9994295239448547}, {"text": "recall", "start_pos": 76, "end_pos": 82, "type": "METRIC", "confidence": 0.9983558058738708}]}, {"text": "Specifically, fora given object o k the translation model will yield a set of probabilities {Pr(w j |o k ), \u2200j}.", "labels": [], "entities": [{"text": "Pr", "start_pos": 93, "end_pos": 95, "type": "METRIC", "confidence": 0.9805898666381836}]}, {"text": "We can sort the probabilities and get a ranked list.", "labels": [], "entities": []}, {"text": "Let us assume that we have the ground truth about all the spoken words to which the given object should be mapped.", "labels": [], "entities": []}, {"text": "Then, at a given number n of top ranked words, the precision of mapping the given object o k to words is defined as # words that o k is correctly mapped to # words that o k is mapped to and the recall is defined as # words that o k is correctly mapped to # words that o k should be mapped to All the counting above is done within the top n rank.", "labels": [], "entities": [{"text": "precision", "start_pos": 51, "end_pos": 60, "type": "METRIC", "confidence": 0.9993236064910889}, {"text": "recall", "start_pos": 194, "end_pos": 200, "type": "METRIC", "confidence": 0.9989694356918335}]}, {"text": "Therefore, we can get different precision/recall at different ranks.", "labels": [], "entities": [{"text": "precision", "start_pos": 32, "end_pos": 41, "type": "METRIC", "confidence": 0.9995110034942627}, {"text": "recall", "start_pos": 42, "end_pos": 48, "type": "METRIC", "confidence": 0.9801430106163025}]}, {"text": "At each rank, the overall performance can be evaluated by averaging the precision/recall for all the given objects.", "labels": [], "entities": [{"text": "precision", "start_pos": 72, "end_pos": 81, "type": "METRIC", "confidence": 0.9992928504943848}, {"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.9187304377555847}]}, {"text": "Human judgment is used to decide whether an object-word mapping is corrector not, as ground truth for evaluation.", "labels": [], "entities": []}, {"text": "Similarly, based on the set of probabilities of mapping a given object with spoken words, we can find a ranked list of objects fora given word, i.e. {Pr(o k |w j ), \u2200k}.", "labels": [], "entities": []}, {"text": "Thus, at a given rank the precision and recall of mapping a given word w j to objects can be measured.", "labels": [], "entities": [{"text": "precision", "start_pos": 26, "end_pos": 35, "type": "METRIC", "confidence": 0.9995786547660828}, {"text": "recall", "start_pos": 40, "end_pos": 46, "type": "METRIC", "confidence": 0.9986066222190857}]}, {"text": "Vocabulary acquisition is the process of finding the appropriate word(s) for any given object.", "labels": [], "entities": [{"text": "Vocabulary acquisition", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.8735118508338928}]}, {"text": "For the sake of statistical significance, our evaluation is done on 21 objects that were mentioned at least 3 times by the users.", "labels": [], "entities": []}, {"text": "gives the average precision/recall evaluated at the top 10 ranks.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9990573525428772}, {"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9618514776229858}]}, {"text": "As we can see, if we use the most probable word acquired for each object, about 66.67% of them are appropriate.", "labels": [], "entities": []}, {"text": "With the rank increasing, more and more appropriate words can be acquired.", "labels": [], "entities": []}, {"text": "About 62.96% of all the appropriate words are included within the top 10 probable words found.", "labels": [], "entities": []}, {"text": "The results indicate that by using a translation model, we can obtain the words that are used by the users to describe the objects with reasonable accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 147, "end_pos": 155, "type": "METRIC", "confidence": 0.9924367070198059}]}, {"text": "presents the top 3 most probable words found for each object.", "labels": [], "entities": []}, {"text": "It shows that although there maybe more than one word appropriate to describe a given object, those words with highest probabilities always suggest the most popular way of describing the corresponding object among the users.", "labels": [], "entities": []}, {"text": "For example, for the object with ID 26, the word candle gets a higher probability than the word candlestick, which is in accordance with our observation that in our user study, on most occasions users tend to use the word candle rather than the word candlestick.", "labels": [], "entities": []}, {"text": "Vocabulary interpretation is the process of finding the appropriate object(s) for any given spoken word.", "labels": [], "entities": [{"text": "Vocabulary interpretation", "start_pos": 0, "end_pos": 25, "type": "TASK", "confidence": 0.8471934199333191}]}, {"text": "Out of 176 nouns in the user vocabulary, we only evaluate those used at least three times for statistical significance concerns.", "labels": [], "entities": []}, {"text": "Further, abstract words (such as reason, position) and general words (such as room, furniture) are not evaluated since they do not refer to any particular objects in the scene.", "labels": [], "entities": []}, {"text": "Finally, 23 nouns remain for evaluation.", "labels": [], "entities": []}, {"text": "We manually enumerated all the object(s) that those 23 nouns refer to as the ground truth in our evaluation.", "labels": [], "entities": []}, {"text": "Note that a given noun can possibly be used to refer to multiple objects, such as lamp, since we have several lamps (with object ID 3, 8, 17, and 23) in the experiment setting, and bed, since bed frame, bedspread, and pillows (with object ID 19, 21, and 20 respectively) are all part of a bed.", "labels": [], "entities": []}, {"text": "Also, an object can be referred to by multiple nouns.", "labels": [], "entities": []}, {"text": "For example, the words painting, picture, or waterfall can all be used to refer to the object with ID 15.: Words found forgiven objects.", "labels": [], "entities": []}, {"text": "Each row lists the top 3 most probable spoken words (being stemmed) for the corresponding given object, with the mapping probabilities in parentheses.", "labels": [], "entities": []}, {"text": "Asterisks indicate correctly identified spoken words.", "labels": [], "entities": []}, {"text": "Note that some objects are heavily overlapped, so the corresponding words are considered correct for all the overlapping objects, such as bed being considered correct for objects with ID 19, 20, and 21.: Objects found forgiven words.", "labels": [], "entities": []}, {"text": "Each row lists the 4 most probable object IDs for the corresponding given words (being stemmed), with the mapping probabilities in parentheses.", "labels": [], "entities": []}, {"text": "Asterisks indicate correctly identified objects.", "labels": [], "entities": []}, {"text": "Note that some objects are heavily overlapped, such as the candle (with object ID 26) and the chair (with object ID 25), and both were considered correct for the respective spoken words.", "labels": [], "entities": []}, {"text": "gives the average precision/recall evaluated at the top 10 ranks.", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9990573525428772}, {"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9618514776229858}]}, {"text": "As we can see, if we use the most probable object found for each speech word, about 78.26% of them are appropriate.", "labels": [], "entities": []}, {"text": "With the rank increasing, more and more appropriate objects can be found.", "labels": [], "entities": []}, {"text": "About 85.71% of all the appropriate objects are included within the top 10 probable objects found.", "labels": [], "entities": []}, {"text": "The results indicate that by using a translation model, we can predict the objects from user spoken words with reasonable accuracy.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 122, "end_pos": 130, "type": "METRIC", "confidence": 0.9954641461372375}]}, {"text": "lists the top 4 probable objects found for each spoken word being evaluated.", "labels": [], "entities": []}, {"text": "A close look reveals that in general, the top ranked objects tend to gather around the correct object fora given spoken word.", "labels": [], "entities": []}, {"text": "This is consistent with the fact that eye gaze tends to move back and forth.", "labels": [], "entities": []}, {"text": "It also indicates that the mappings established by the translation model can effectively find the approximate area of the corresponding fixated object, even if it cannot find the object due to the noisy and jerky nature of eye gaze.", "labels": [], "entities": []}, {"text": "The precision/recall in vocabulary acquisition is not as high as that in vocabulary interpretation, partially due to the relatively small scale of our experiment data.", "labels": [], "entities": [{"text": "precision", "start_pos": 4, "end_pos": 13, "type": "METRIC", "confidence": 0.9996178150177002}, {"text": "recall", "start_pos": 14, "end_pos": 20, "type": "METRIC", "confidence": 0.9729602932929993}, {"text": "vocabulary acquisition", "start_pos": 24, "end_pos": 46, "type": "TASK", "confidence": 0.7817682921886444}, {"text": "vocabulary interpretation", "start_pos": 73, "end_pos": 98, "type": "TASK", "confidence": 0.7581591904163361}]}, {"text": "For example, with only 7 users' speech data on 14 conversational tasks, some words were only spoken a few times to refer to an object, which prevented them from getting a significant portion of probability mass among all the words in the vocabulary.", "labels": [], "entities": []}, {"text": "This degrades both precision and recall.", "labels": [], "entities": [{"text": "precision", "start_pos": 19, "end_pos": 28, "type": "METRIC", "confidence": 0.9996306896209717}, {"text": "recall", "start_pos": 33, "end_pos": 39, "type": "METRIC", "confidence": 0.9990069270133972}]}, {"text": "We believe that in large scale experiments or real-world applications, the performance will be improved.", "labels": [], "entities": []}, {"text": "acquire different words related to different objects without any human supervision.", "labels": [], "entities": []}, {"text": "To further explore this idea, we developed a novel unsupervised approach using statistical translation models.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 79, "end_pos": 102, "type": "TASK", "confidence": 0.6319205462932587}]}, {"text": "Our experimental results have shown that this approach can reasonably uncover the mappings between words and objects on the graphical display.", "labels": [], "entities": []}, {"text": "The main advantages of this approach include: 1) It is an unsupervised approach with minimum human inference; 2) It does not need any prior knowledge to train a statistical translation model; 3) It yields probabilities that indicate the reliability of the mappings.", "labels": [], "entities": [{"text": "statistical translation", "start_pos": 161, "end_pos": 184, "type": "TASK", "confidence": 0.6403457820415497}]}, {"text": "Certainly, our current approach is built upon simplified assumptions.", "labels": [], "entities": []}, {"text": "It is quite challenging to incorporate eye gaze information since it is extremely noisy with large variances.", "labels": [], "entities": []}, {"text": "Recent work has shown that the effect of eye gaze in facilitating spoken language processing varies among different users (.", "labels": [], "entities": [{"text": "spoken language processing", "start_pos": 66, "end_pos": 92, "type": "TASK", "confidence": 0.7035809357961019}]}, {"text": "In addition, visual properties of the interface also affect user gaze behavior and thus influence the predication of attention () based on eye gaze.", "labels": [], "entities": []}, {"text": "Our future work will develop models to address these variations.", "labels": [], "entities": []}, {"text": "Nevertheless, the results from our current work have several important implications in building robust conversational interfaces.", "labels": [], "entities": []}, {"text": "First of all, most conversational systems are built with static knowledge space (e.g., vocabularies) and can only be updated by the system developers.", "labels": [], "entities": []}, {"text": "Our approach can potentially allow the system to automatically acquire knowledge and vocabularies based on the natural interactions with the users without human intervention.", "labels": [], "entities": []}, {"text": "Furthermore, the automatically acquired mappings between words and objects can also help language interpretation tasks such as reference resolution.", "labels": [], "entities": [{"text": "language interpretation", "start_pos": 89, "end_pos": 112, "type": "TASK", "confidence": 0.7053994238376617}, {"text": "reference resolution", "start_pos": 127, "end_pos": 147, "type": "TASK", "confidence": 0.8230291604995728}]}, {"text": "Given the recent advances in eye tracking technology), integrating nonintrusive and high performance eye trackers with conversational interfaces becomes feasible.", "labels": [], "entities": [{"text": "eye tracking", "start_pos": 29, "end_pos": 41, "type": "TASK", "confidence": 0.7700513303279877}]}, {"text": "The work reported here can potentially be integrated in practical systems to improve the overall robustness of human machine conversation.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Average precision/recall of mapping given  objects to words (i.e., acquisition)", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.9454665184020996}, {"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9490789771080017}]}, {"text": " Table 3: Average precision/recall of mapping given  words to objects.(i.e., interpretation)", "labels": [], "entities": [{"text": "precision", "start_pos": 18, "end_pos": 27, "type": "METRIC", "confidence": 0.959276556968689}, {"text": "recall", "start_pos": 28, "end_pos": 34, "type": "METRIC", "confidence": 0.9252510070800781}]}, {"text": " Table 4: Words found for given objects. Each row  lists the top 3 most probable spoken words (being  stemmed) for the corresponding given object, with  the mapping probabilities in parentheses. Asterisks  indicate correctly identified spoken words. Note  that some objects are heavily overlapped, so the cor- responding words are considered correct for all the  overlapping objects, such as bed being considered  correct for objects with ID 19, 20, and 21.", "labels": [], "entities": []}]}