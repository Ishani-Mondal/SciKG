{"title": [{"text": "Learning Multilingual Subjective Language via Cross-Lingual Projections", "labels": [], "entities": []}], "abstractContent": [{"text": "This paper explores methods for generating subjectivity analysis resources in anew language by leveraging on the tools and resources available in English.", "labels": [], "entities": []}, {"text": "Given abridge between English and the selected target language (e.g., a bilingual dictionary or a parallel corpus), the methods can be used to rapidly create tools for subjectivity analysis in the new language.", "labels": [], "entities": [{"text": "subjectivity analysis", "start_pos": 168, "end_pos": 189, "type": "TASK", "confidence": 0.6929011046886444}]}], "introductionContent": [{"text": "There is growing interest in the automatic extraction of opinions, emotions, and sentiments in text (subjectivity), to provide tools and support for various natural language processing applications.", "labels": [], "entities": [{"text": "automatic extraction of opinions, emotions, and sentiments in text (subjectivity)", "start_pos": 33, "end_pos": 114, "type": "TASK", "confidence": 0.8392621917384011}]}, {"text": "Most of the research to date has focused on English, which is mainly explained by the availability of resources for subjectivity analysis, such as lexicons and manually labeled corpora.", "labels": [], "entities": []}, {"text": "In this paper, we investigate methods to automatically generate resources for subjectivity analysis fora new target language by leveraging on the resources and tools available for English, which in many cases took years of work to complete.", "labels": [], "entities": [{"text": "subjectivity analysis", "start_pos": 78, "end_pos": 99, "type": "TASK", "confidence": 0.6886947453022003}]}, {"text": "Specifically, through experiments with cross-lingual projection of subjectivity, we seek answers to the following questions.", "labels": [], "entities": []}, {"text": "First, can we derive a subjectivity lexicon fora new language using an existing English subjectivity lexicon and a bilingual dictionary?", "labels": [], "entities": []}, {"text": "Second, can we derive subjectivity-annotated corpora in anew language using existing subjectivity analysis tools for English and a parallel corpus?", "labels": [], "entities": []}, {"text": "Finally, third, can we build tools for subjectivity analysis fora new target language by relying on these automatically generated resources?", "labels": [], "entities": [{"text": "subjectivity analysis", "start_pos": 39, "end_pos": 60, "type": "TASK", "confidence": 0.7336468994617462}]}, {"text": "We focus our experiments on Romanian, selected as a representative of the large number of languages that have only limited text processing resources developed to date.", "labels": [], "entities": []}, {"text": "Note that, although we work with Romanian, the methods described are applicable to any other language, as in these experiments we (purposely) do not use any language-specific knowledge of the target language.", "labels": [], "entities": []}, {"text": "Given abridge between English and the selected target language (e.g., a bilingual dictionary or a parallel corpus), the methods can be applied to other languages as well.", "labels": [], "entities": []}, {"text": "After providing motivations, we present two approaches to developing sentence-level subjectivity classifiers fora new target language.", "labels": [], "entities": []}, {"text": "The first uses a subjectivity lexicon translated from an English one.", "labels": [], "entities": []}, {"text": "The second uses an English subjectivity classifier and a parallel corpus to create target-language training data for developing a statistical classifier.", "labels": [], "entities": []}], "datasetContent": [{"text": "We want to assess the quality of the translated lexicon, and compare it to the quality of the original English lexicon.", "labels": [], "entities": []}, {"text": "The English subjectivity lexicon was evaluated in (Wiebe and) against a corpus of English-language news articles manually annotated for subjectivity (the MPQA corpus ( ).", "labels": [], "entities": [{"text": "MPQA corpus", "start_pos": 154, "end_pos": 165, "type": "DATASET", "confidence": 0.9664680063724518}]}, {"text": "According to this evaluation, 85% of the instances of the clues marked as strong and 71.5% of the clues marked as weak are in subjective sentences in the MPQA corpus.", "labels": [], "entities": [{"text": "MPQA corpus", "start_pos": 154, "end_pos": 165, "type": "DATASET", "confidence": 0.9620196521282196}]}, {"text": "Since there is no comparable Romanian corpus, an alternate way to judge the subjectivity of a Romanian lexicon entry is needed.", "labels": [], "entities": []}, {"text": "Two native speakers of Romanian annotated the subjectivity of 150 randomly selected entries.", "labels": [], "entities": []}, {"text": "Each annotator independently read approximately 100 examples of each drawn from the Web, including a large number from news sources.", "labels": [], "entities": []}, {"text": "The subjectivity of a word was consequently judged in the contexts where it most frequently appears, accounting for its most frequent meanings on the Web.", "labels": [], "entities": []}, {"text": "The tagset used for the annotations consists of S(ubjective), O(bjective), and B(oth).", "labels": [], "entities": []}, {"text": "A W(rong) label is also used to indicate a wrong translation.", "labels": [], "entities": [{"text": "W", "start_pos": 2, "end_pos": 3, "type": "METRIC", "confidence": 0.9493591785430908}]}, {"text": "Without counting the wrong translations, the agreement is measured at 0.80, with a Kappa \u03ba = 0.70, which indicates consistent agreement.", "labels": [], "entities": [{"text": "agreement", "start_pos": 45, "end_pos": 54, "type": "METRIC", "confidence": 0.9968476891517639}]}, {"text": "After the disagreements were reconciled through discussions, the final set of 123 correctly translated entries does include 49.6% (61) subjective entries, but fully 23.6% were found in the study to have primarily objective uses (the other 26.8% are mixed).", "labels": [], "entities": []}, {"text": "Thus, this study suggests that the Romanian subjectivity clues derived through translation are less reliable than the original set of English clues.", "labels": [], "entities": []}, {"text": "In several cases, the subjectivity is lost in the translation, mainly due to word ambiguity in either the source or target language, or both.", "labels": [], "entities": []}, {"text": "For instance, the word fragile correctly translates into Romanian as fragil, yet this word is frequently used to refer to breakable objects, and it loses its subjective meaning of delicate.", "labels": [], "entities": []}, {"text": "Other words, such as one-sided, completely lose subjectivity once translated, as it becomes in Romanian cu o singura latur\u02d8 a, meaning with only one side (as of objects).", "labels": [], "entities": []}, {"text": "Interestingly, the reliability of clues in the English lexicon seems to help preserve subjectivity.", "labels": [], "entities": [{"text": "reliability", "start_pos": 19, "end_pos": 30, "type": "METRIC", "confidence": 0.9791299700737}]}, {"text": "Out of the 77 entries marked as strong, 11 were judged to be objective in Romanian (14.3%), compared to 14 objective Romanian entries obtained from the 36 weak English clues (39.0%).", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Agreement on 150 entries in the Romanian  lexicon", "labels": [], "entities": []}, {"text": " Table 3: Evaluation of the rule-based classifier", "labels": [], "entities": []}, {"text": " Table 4: Agreement on the data set of 173 sentences.  Annotations performed by three annotators: one na- tive English speaker (En) and two native Romanian  speakers (Ro 1 and Ro 2 )", "labels": [], "entities": []}, {"text": " Table 5: Precision, recall, and F-measure for the  two OpinionFinder classifiers, as measured on the  MPQA corpus.", "labels": [], "entities": [{"text": "Precision", "start_pos": 10, "end_pos": 19, "type": "METRIC", "confidence": 0.9989733695983887}, {"text": "recall", "start_pos": 21, "end_pos": 27, "type": "METRIC", "confidence": 0.9991551637649536}, {"text": "F-measure", "start_pos": 33, "end_pos": 42, "type": "METRIC", "confidence": 0.9993628859519958}, {"text": "MPQA corpus", "start_pos": 103, "end_pos": 114, "type": "DATASET", "confidence": 0.9794961214065552}]}, {"text": " Table 6: Subjective and objective training sentences  automatically annotated with OpinionFinder.", "labels": [], "entities": []}, {"text": " Table 7: Evaluation of the machine learning classi- fier using training data obtained via projections from  data automatically labeled by OpinionFinder (OF).", "labels": [], "entities": []}]}