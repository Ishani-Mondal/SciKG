{"title": [{"text": "Statistical Machine Translation through Global Lexical Selection and Sentence Reconstruction", "labels": [], "entities": [{"text": "Statistical Machine Translation", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8266615072886149}]}], "abstractContent": [{"text": "Machine translation of a source language sentence involves selecting appropriate target language words and ordering the selected words to form a well-formed target language sentence.", "labels": [], "entities": [{"text": "Machine translation of a source language sentence", "start_pos": 0, "end_pos": 49, "type": "TASK", "confidence": 0.841415456363133}]}, {"text": "Most of the previous work on statistical machine translation relies on (local) associations of target words/phrases with source words/phrases for lexical selection.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 29, "end_pos": 60, "type": "TASK", "confidence": 0.6424178580443064}]}, {"text": "In contrast, in this paper , we present a novel approach to lexical selection where the target words are associated with the entire source sentence (global) without the need to compute local associations.", "labels": [], "entities": [{"text": "lexical selection", "start_pos": 60, "end_pos": 77, "type": "TASK", "confidence": 0.7132017016410828}]}, {"text": "Further, we present a technique for reconstructing the target language sentence from the selected words.", "labels": [], "entities": []}, {"text": "We compare the results of this approach against those obtained from a finite-state based statistical machine translation system which relies on local lexical associations.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 89, "end_pos": 120, "type": "TASK", "confidence": 0.6872283816337585}]}], "introductionContent": [{"text": "Machine translation can be viewed as consisting of two subproblems: (a) lexical selection, where appropriate target language lexical items are chosen for each source language lexical item and (b) lexical reordering, where the chosen target language lexical items are rearranged to produce a meaningful target language string.", "labels": [], "entities": [{"text": "Machine translation", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.8344561457633972}]}, {"text": "Most of the previous work on statistical machine translation, as exemplified in (, employs word-alignment algorithm (such as GIZA++ () that provides local associations between source and target words.", "labels": [], "entities": [{"text": "statistical machine translation", "start_pos": 29, "end_pos": 60, "type": "TASK", "confidence": 0.6782625317573547}]}, {"text": "The source-to-target word alignments are sometimes augmented with target-to-source word alignments in order to improve precision.", "labels": [], "entities": [{"text": "precision", "start_pos": 119, "end_pos": 128, "type": "METRIC", "confidence": 0.9967306852340698}]}, {"text": "Further, the word-level alignments are extended to phraselevel alignments in order to increase the extent of local associations.", "labels": [], "entities": []}, {"text": "The phrasal associations compile some amount of (local) lexical reordering of the target words -those permitted by the size of the phrase.", "labels": [], "entities": []}, {"text": "Most of the state-of-the-art machine translation systems use phrase-level associations in conjunction with a target language model to produce sentences.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7343509197235107}]}, {"text": "There is relatively little emphasis on (global) lexical reordering other than the local reorderings permitted within the phrasal alignments.", "labels": [], "entities": []}, {"text": "A few exceptions are the hierarchical (possibly syntax-based) transduction models) and the string transduction models ().", "labels": [], "entities": []}, {"text": "In this paper, we present an alternate approach to lexical selection and lexical reordering.", "labels": [], "entities": []}, {"text": "For lexical selection, in contrast to the local approaches of associating target to source words, we associate target words to the entire source sentence.", "labels": [], "entities": [{"text": "lexical selection", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.8209094405174255}]}, {"text": "The intuition is that there maybe lexico-syntactic features of the source sentence (not necessarily a single source word) that might trigger the presence of a target word in the target sentence.", "labels": [], "entities": []}, {"text": "Furthermore, it might be difficult to exactly associate a target word to a source word in many situations -(a) when the translations are not exact but paraphrases (b) when the target language does not have one lexical item to express the same concept that is expressed by a source word.", "labels": [], "entities": []}, {"text": "Extending word to phrase alignments attempts to address some of these situations while alleviating the noise in word-level alignments.", "labels": [], "entities": [{"text": "word to phrase alignments", "start_pos": 10, "end_pos": 35, "type": "TASK", "confidence": 0.6945017576217651}]}, {"text": "As a consequence of this global lexical selection approach, we no longer have a tight association between source and target language words.", "labels": [], "entities": []}, {"text": "The result of lexical selection is simply a bag of words in the target language and the sentence has to be reconstructed using this bag of words.", "labels": [], "entities": []}, {"text": "The words in the bag, however, might be enhanced with rich syntactic information that could aid in reconstructing the target sentence.", "labels": [], "entities": []}, {"text": "This approach to lexical selection and: Decoding phases for our system sentence reconstruction has the potential to circumvent limitations of word-alignment based methods for translation between languages with significantly different word order (e.g. English-Japanese).", "labels": [], "entities": [{"text": "lexical selection", "start_pos": 17, "end_pos": 34, "type": "TASK", "confidence": 0.7051822692155838}, {"text": "system sentence reconstruction", "start_pos": 64, "end_pos": 94, "type": "TASK", "confidence": 0.6972367862860361}]}, {"text": "In this paper, we present the details of training a global lexical selection model using classification techniques and sentence reconstruction models using permutation automata.", "labels": [], "entities": [{"text": "sentence reconstruction", "start_pos": 119, "end_pos": 142, "type": "TASK", "confidence": 0.7485669851303101}]}, {"text": "We also present a stochastic finite-state transducer (SFST) as an example of an approach that relies on local associations and use it to compare and contrast our approach.", "labels": [], "entities": []}], "datasetContent": [{"text": "We have performed experiments on the IWSLT06 Chinese-English training and development sets from We used the implementation available at http://homepages.inf.ed.ac.uk/s0450736/maxent toolkit.html 2005 and 2006.", "labels": [], "entities": [{"text": "IWSLT06 Chinese-English training and development sets", "start_pos": 37, "end_pos": 90, "type": "DATASET", "confidence": 0.8668201963106791}]}, {"text": "The data are traveler task expressions such as seeking directions, expressions in restaurants and travel reservations.", "labels": [], "entities": []}, {"text": "presents some statistics on the data sets.", "labels": [], "entities": []}, {"text": "It must be noted that while the 2005 development set matches the training data closely, the 2006 development set has been collected separately and shows slightly different statistics for average sentence length, vocabulary size and out-of-vocabulary words.", "labels": [], "entities": []}, {"text": "Also the 2006 development set contains no punctuation marks in Chinese, but the corresponding English translations have punctuation marks.", "labels": [], "entities": []}, {"text": "We also evaluated our models on the Chinese speech recognition output and we report results using 1-best with a word error rate of 25.2%.", "labels": [], "entities": [{"text": "Chinese speech recognition", "start_pos": 36, "end_pos": 62, "type": "TASK", "confidence": 0.564702163139979}, {"text": "1-best", "start_pos": 98, "end_pos": 104, "type": "METRIC", "confidence": 0.9806368947029114}, {"text": "word error rate", "start_pos": 112, "end_pos": 127, "type": "METRIC", "confidence": 0.8510907888412476}]}, {"text": "For the experiments, we tokenized the Chinese sentences into character strings and trained the models discussed in the previous sections.", "labels": [], "entities": []}, {"text": "Also, we trained a punctuation prediction model using Maxent framework on the Chinese character strings in order to insert punctuation marks into the 2006 development data set.", "labels": [], "entities": [{"text": "punctuation prediction", "start_pos": 19, "end_pos": 41, "type": "TASK", "confidence": 0.696371391415596}, {"text": "2006 development data set", "start_pos": 150, "end_pos": 175, "type": "DATASET", "confidence": 0.7914581894874573}]}, {"text": "The resulting character string with punctuation marks is used as input to the translation decoder.", "labels": [], "entities": []}, {"text": "For the 2005 development set, punctuation insertion was not needed since the Chinese sentences already had the true punctuation marks.", "labels": [], "entities": [{"text": "punctuation insertion", "start_pos": 30, "end_pos": 51, "type": "TASK", "confidence": 0.6666873097419739}]}, {"text": "In we present the results of the three different translation models -FST, Sequential Maxent and BOW Maxent.", "labels": [], "entities": [{"text": "FST", "start_pos": 69, "end_pos": 72, "type": "METRIC", "confidence": 0.6153612732887268}, {"text": "BOW", "start_pos": 96, "end_pos": 99, "type": "METRIC", "confidence": 0.982166588306427}]}, {"text": "There area few interesting observations that can be made based on these results.", "labels": [], "entities": []}, {"text": "First, on the 2005 development set, the sequential Maxent model outperforms the FST model, even though the two models were trained starting from the same GIZA++ alignment.", "labels": [], "entities": [{"text": "FST", "start_pos": 80, "end_pos": 83, "type": "DATASET", "confidence": 0.753487229347229}]}, {"text": "The difference, however, is due to the fact that Maxent models can cope with increased lexical context 2 and the parameters of the model are discriminatively trained.", "labels": [], "entities": []}, {"text": "The more surprising result is that the BOW Maxent model significantly outperforms the sequential Maxent model.", "labels": [], "entities": [{"text": "BOW", "start_pos": 39, "end_pos": 42, "type": "METRIC", "confidence": 0.7838193774223328}]}, {"text": "The reason is that the sequential Maxent model relies on the word alignment, which, if erroneous, results in incorrect predictions by the sequential Maxent model.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 61, "end_pos": 75, "type": "TASK", "confidence": 0.6283090561628342}]}, {"text": "The BOW model does not rely on the word-level alignment and can be interpreted as a discriminatively trained model of dictionary lookup fora target word in the context of a source sentence.", "labels": [], "entities": [{"text": "BOW", "start_pos": 4, "end_pos": 7, "type": "METRIC", "confidence": 0.7336987853050232}]}, {"text": "As indicated in the data release document, the 2006 development set was collected differently compared to the one from 2005.", "labels": [], "entities": []}, {"text": "Due to this mismatch, the performance of the Maxent models are not very different from the FST model, indicating the lack of good generalization across different genres.", "labels": [], "entities": [{"text": "FST", "start_pos": 91, "end_pos": 94, "type": "DATASET", "confidence": 0.7121608257293701}]}, {"text": "However, we believe that the Maxent framework allows for incorporation of linguistic features that could potentially help in generalization across genres.", "labels": [], "entities": []}, {"text": "For translation of ASR 1-best, we see a systematic degradation of about 3% in mBLEU score compared to translating the transcription.", "labels": [], "entities": [{"text": "translation", "start_pos": 4, "end_pos": 15, "type": "TASK", "confidence": 0.965735912322998}, {"text": "ASR", "start_pos": 19, "end_pos": 22, "type": "TASK", "confidence": 0.693635106086731}, {"text": "mBLEU score", "start_pos": 78, "end_pos": 89, "type": "METRIC", "confidence": 0.9508977830410004}]}, {"text": "In order to compensate for the mismatch between the 2005 and 2006 data sets, we computed a 10-fold average mBLEU score by including 90% of the 2006 development set into the training set and using 10% of the 2006 development set for testing, each time.", "labels": [], "entities": [{"text": "mBLEU score", "start_pos": 107, "end_pos": 118, "type": "METRIC", "confidence": 0.7689406871795654}]}, {"text": "The average mBLEU score across these 10 runs increased to 22.8.", "labels": [], "entities": [{"text": "mBLEU score", "start_pos": 12, "end_pos": 23, "type": "METRIC", "confidence": 0.8304011821746826}]}, {"text": "In we show the improvement of mBLEU scores with the increase in permutation window size.", "labels": [], "entities": [{"text": "permutation window size", "start_pos": 64, "end_pos": 87, "type": "METRIC", "confidence": 0.7806493639945984}]}, {"text": "We had to limit to a permutation window size of 10 due to memory limitations, even though the curve has not plateaued.", "labels": [], "entities": []}, {"text": "We anticipate using pruning techniques we can increase the window size further.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Statistics of training and development data from 2005/2006 (  *  = first of multiple translations only).", "labels": [], "entities": []}, {"text": " Table 3: Results (mBLEU) scores for the three dif- ferent models on the transcriptions for development  set 2005 and 2006 and ASR 1-best for development  set 2006.", "labels": [], "entities": [{"text": "ASR 1-best", "start_pos": 127, "end_pos": 137, "type": "METRIC", "confidence": 0.8093370199203491}]}, {"text": " Table 4: Lexical Selection results (F-measure) on  the Arabic-English UN Corpus and the French- English Hansard Corpus. In parenthesis are F- measures for open and closed class lexical items.", "labels": [], "entities": [{"text": "F-measure", "start_pos": 37, "end_pos": 46, "type": "METRIC", "confidence": 0.9593026041984558}, {"text": "UN Corpus", "start_pos": 71, "end_pos": 80, "type": "DATASET", "confidence": 0.8878762722015381}, {"text": "French- English Hansard Corpus", "start_pos": 89, "end_pos": 119, "type": "DATASET", "confidence": 0.6411759614944458}, {"text": "F- measures", "start_pos": 140, "end_pos": 151, "type": "METRIC", "confidence": 0.9514321883519491}]}]}