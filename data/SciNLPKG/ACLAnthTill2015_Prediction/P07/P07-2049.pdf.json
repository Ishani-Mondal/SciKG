{"title": [{"text": "Measuring Importance and Query Relevance in Topic-focused Multi-document Summarization", "labels": [], "entities": [{"text": "Summarization", "start_pos": 73, "end_pos": 86, "type": "TASK", "confidence": 0.8139421343803406}]}], "abstractContent": [{"text": "The increasing complexity of summarization systems makes it difficult to analyze exactly which modules make a difference in performance.", "labels": [], "entities": [{"text": "summarization", "start_pos": 29, "end_pos": 42, "type": "TASK", "confidence": 0.9816970229148865}]}, {"text": "We carried out a principled comparison between the two most commonly used schemes for assigning importance to words in the context of query focused multi-document summarization: raw frequency (word probability) and log-likelihood ratio.", "labels": [], "entities": [{"text": "query focused multi-document summarization", "start_pos": 134, "end_pos": 176, "type": "TASK", "confidence": 0.47744065523147583}]}, {"text": "We demonstrate that the advantages of log-likelihood ratio come from its known dis-tributional properties which allow for the identification of a set of words that in its entirety defines the aboutness of the input.", "labels": [], "entities": []}, {"text": "We also find that LLR is more suitable for query-focused summarization since, unlike raw frequency, it is more sensitive to the integration of the information need defined by the user.", "labels": [], "entities": [{"text": "query-focused summarization", "start_pos": 43, "end_pos": 70, "type": "TASK", "confidence": 0.5545051544904709}]}], "introductionContent": [{"text": "Recently the task of multi-document summarization in response to a complex user query has received considerable attention.", "labels": [], "entities": [{"text": "multi-document summarization", "start_pos": 21, "end_pos": 49, "type": "TASK", "confidence": 0.6210629045963287}]}, {"text": "In generic summarization, the summary is meant to give an overview of the information in the documents.", "labels": [], "entities": [{"text": "generic summarization", "start_pos": 3, "end_pos": 24, "type": "TASK", "confidence": 0.680524468421936}]}, {"text": "By contrast, when the summary is produced in response to a user query or topic (query-focused, topic-focused, or generally focused summary), the topic/query determines what information is appropriate for inclusion in the summary, making the task potentially more challenging.", "labels": [], "entities": []}, {"text": "In this paper we present an analytical study of two questions regarding aspects of the topic-focused scenario.", "labels": [], "entities": []}, {"text": "First, two estimates of importance on words have been used very successfully both in generic and query-focused summarization: frequency) and loglikelihood ratio;).", "labels": [], "entities": []}, {"text": "While both schemes have proved to be suitable for summarization, with generally better results from loglikelihood ratio, no study has investigated in what respects and by how much they differ.", "labels": [], "entities": [{"text": "summarization", "start_pos": 50, "end_pos": 63, "type": "TASK", "confidence": 0.9899157881736755}]}, {"text": "Second, there are many little-understood aspects of the differences between generic and query-focused summarization.", "labels": [], "entities": []}, {"text": "For example, we'd like to know if a particular word weighting scheme is more suitable for focused summarization than others.", "labels": [], "entities": [{"text": "word weighting", "start_pos": 47, "end_pos": 61, "type": "TASK", "confidence": 0.7275340855121613}, {"text": "focused summarization", "start_pos": 90, "end_pos": 111, "type": "TASK", "confidence": 0.741710752248764}]}, {"text": "More significantly, previous studies show that generic and focused systems perform very similarly to each other in query-focused summarization ( and it is of interest to find out why.", "labels": [], "entities": []}, {"text": "To address these questions we examine the two weighting schemes: raw frequency (or word probability estimated from the input), and log-likelihood ratio (LLR) and two of its variants.", "labels": [], "entities": [{"text": "log-likelihood ratio (LLR)", "start_pos": 131, "end_pos": 157, "type": "METRIC", "confidence": 0.8581524848937988}]}, {"text": "These metrics are used to assign importance to individual content words in the input, as we discuss below.", "labels": [], "entities": []}, {"text": "Word probability R(w) = n N , where n is the number of times the word w appeared in the input and N is the total number of words in the input.", "labels": [], "entities": [{"text": "Word probability R(w)", "start_pos": 0, "end_pos": 21, "type": "METRIC", "confidence": 0.8540304551521937}]}, {"text": "Log-likelihood ratio (LLR) The likelihood ratio \u03bb () uses a background corpus to estimate the importance of a word and it is proportional to the mutual information between a word wand the input to be summarized; \u03bb(w) is defined as the ratio between the probability (under a binomial distribution) of observing win the input and the background corpus assuming equal probability of occurrence of win both and the probability of the data assuming different probabilities for win the input and the background corpus.", "labels": [], "entities": []}, {"text": "LLR with cut-off (LLR(C)) A useful property of the log-likelihood ratio is that the quantity 193 \u22122 log(\u03bb) is asymptotically well approximated by \u03c7 2 distribution.", "labels": [], "entities": []}, {"text": "A word appears in the input significantly more often than in the background corpus when \u22122 log(\u03bb) > 10.", "labels": [], "entities": []}, {"text": "Such words are called signature terms in who were the first to introduce the log-likelihood weighting scheme for summarization.", "labels": [], "entities": [{"text": "summarization", "start_pos": 113, "end_pos": 126, "type": "TASK", "confidence": 0.9823682904243469}]}, {"text": "Each descriptive word is assigned an equal weight and the rest of the words have a weight of zero: R(w) = 1 if (\u22122 log(\u03bb(w)) > 10), 0 otherwise.", "labels": [], "entities": []}, {"text": "This weighting scheme has been adopted in several recent generic and topic-focused summarizers).", "labels": [], "entities": []}, {"text": "LLR(CQ) The above three weighting schemes assign a weight to words regardless of the user query and are most appropriate for generic summarization.", "labels": [], "entities": [{"text": "generic summarization", "start_pos": 125, "end_pos": 146, "type": "TASK", "confidence": 0.6381251364946365}]}, {"text": "When a user query is available, it should inform the summarizer to make the summary more focused.", "labels": [], "entities": []}, {"text": "In such query sensititivity is achieved by augmenting LLR(C) with all content words from the user query, each assigned a weight of 1 equal to the weight of words defined by LLR(C) as topic words from the input to the summarizer.", "labels": [], "entities": []}], "datasetContent": [{"text": "In the summarizers we compare here, the various weighting methods we describe above are used to assign importance to individual content words in the input.", "labels": [], "entities": []}, {"text": "The weight or importance of a sentence S in: SU4 ROUGE recall (and 95% confidence intervals) for runs on the entire input (GENERIC) and on relevant sentences (FOCUSED).", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 49, "end_pos": 54, "type": "METRIC", "confidence": 0.9321340322494507}, {"text": "recall", "start_pos": 55, "end_pos": 61, "type": "METRIC", "confidence": 0.8154109120368958}, {"text": "FOCUSED", "start_pos": 159, "end_pos": 166, "type": "METRIC", "confidence": 0.9435340166091919}]}, {"text": "the input is defined as where R(w) assigns a weight for each word w.", "labels": [], "entities": []}, {"text": "For GENERIC summarization, the top scoring sentences in the input are taken to form a generic extractive summary.", "labels": [], "entities": [{"text": "GENERIC summarization", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.6144970059394836}]}, {"text": "In the computation of sentence importance, only nouns, verbs, adjectives and adverbs are considered and a shortlist of light verbs are excluded: \"has, was, have, are, will, were, do, been, say, said, says\".", "labels": [], "entities": [{"text": "sentence importance", "start_pos": 22, "end_pos": 41, "type": "TASK", "confidence": 0.7123563438653946}]}, {"text": "For FOCUSED summarization, we modify this algorithm merely by running the sentence selection algorithm on only those sentences in the input that are relevent to the user query.", "labels": [], "entities": [{"text": "FOCUSED summarization", "start_pos": 4, "end_pos": 25, "type": "TASK", "confidence": 0.7810337543487549}]}, {"text": "In some previous DUC evaluations, relevant sentences are explicitly marked by annotators and given to systems.", "labels": [], "entities": []}, {"text": "In our version here, a sentence in the input is considered relevant if it contains at least one word from the user query.", "labels": [], "entities": []}, {"text": "For evaluation we use ROUGE) SU4 recall metric 1 , which was among the official automatic evaluation metrics for DUC.", "labels": [], "entities": [{"text": "ROUGE) SU4 recall metric 1", "start_pos": 22, "end_pos": 48, "type": "METRIC", "confidence": 0.7786541134119034}, {"text": "DUC", "start_pos": 113, "end_pos": 116, "type": "DATASET", "confidence": 0.839562177658081}]}], "tableCaptions": [{"text": " Table 1: SU4 ROUGE recall (and 95% confidence  intervals) for runs on the entire input (GENERIC) and  on relevant sentences (FOCUSED).", "labels": [], "entities": [{"text": "ROUGE", "start_pos": 14, "end_pos": 19, "type": "METRIC", "confidence": 0.9376201629638672}, {"text": "recall", "start_pos": 20, "end_pos": 26, "type": "METRIC", "confidence": 0.8914476633071899}, {"text": "GENERIC", "start_pos": 89, "end_pos": 96, "type": "METRIC", "confidence": 0.796869695186615}, {"text": "FOCUSED", "start_pos": 126, "end_pos": 133, "type": "METRIC", "confidence": 0.950745701789856}]}]}