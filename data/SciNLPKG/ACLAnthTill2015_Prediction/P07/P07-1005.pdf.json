{"title": [{"text": "Word Sense Disambiguation Improves Statistical Machine Translation", "labels": [], "entities": [{"text": "Word Sense Disambiguation Improves Statistical Machine Translation", "start_pos": 0, "end_pos": 66, "type": "TASK", "confidence": 0.8512085505894252}]}], "abstractContent": [{"text": "Recent research presents conflicting evidence on whether word sense disambigua-tion (WSD) systems can help to improve the performance of statistical machine translation (MT) systems.", "labels": [], "entities": [{"text": "word sense disambigua-tion (WSD)", "start_pos": 57, "end_pos": 89, "type": "TASK", "confidence": 0.7150387813647588}, {"text": "statistical machine translation (MT)", "start_pos": 137, "end_pos": 173, "type": "TASK", "confidence": 0.7749186158180237}]}, {"text": "In this paper, we successfully integrate a state-of-the-art WSD system into a state-of-the-art hierarchical phrase-based MT system, Hiero.", "labels": [], "entities": [{"text": "MT", "start_pos": 121, "end_pos": 123, "type": "TASK", "confidence": 0.9021725654602051}, {"text": "Hiero", "start_pos": 132, "end_pos": 137, "type": "DATASET", "confidence": 0.8484805226325989}]}, {"text": "We show for the first time that integrating a WSD system improves the performance of a state-of-the-art statistical MT system on an actual translation task.", "labels": [], "entities": [{"text": "WSD", "start_pos": 46, "end_pos": 49, "type": "TASK", "confidence": 0.9186839461326599}, {"text": "MT", "start_pos": 116, "end_pos": 118, "type": "TASK", "confidence": 0.9038158059120178}, {"text": "translation task", "start_pos": 139, "end_pos": 155, "type": "TASK", "confidence": 0.8776881098747253}]}, {"text": "Furthermore, the improvement is statistically significant.", "labels": [], "entities": []}], "introductionContent": [{"text": "Many words have multiple meanings, depending on the context in which they are used.", "labels": [], "entities": []}, {"text": "Word sense disambiguation (WSD) is the task of determining the correct meaning or sense of a word in context.", "labels": [], "entities": [{"text": "Word sense disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8356685439745585}, {"text": "determining the correct meaning or sense of a word in context", "start_pos": 47, "end_pos": 108, "type": "TASK", "confidence": 0.5950920337980444}]}, {"text": "WSD is regarded as an important research problem and is assumed to be helpful for applications such as machine translation (MT) and information retrieval.", "labels": [], "entities": [{"text": "WSD", "start_pos": 0, "end_pos": 3, "type": "TASK", "confidence": 0.8982442617416382}, {"text": "machine translation (MT)", "start_pos": 103, "end_pos": 127, "type": "TASK", "confidence": 0.860391092300415}, {"text": "information retrieval", "start_pos": 132, "end_pos": 153, "type": "TASK", "confidence": 0.8521709740161896}]}, {"text": "In translation, different senses of a word win a source language may have different translations in a target language, depending on the particular meaning of win context.", "labels": [], "entities": []}, {"text": "Hence, the assumption is that in resolving sense ambiguity, a WSD system will be able to help an MT system to determine the correct translation for an ambiguous word.", "labels": [], "entities": [{"text": "MT", "start_pos": 97, "end_pos": 99, "type": "TASK", "confidence": 0.9622977375984192}]}, {"text": "To determine the correct sense of a word, WSD systems typically use a wide array of features that are not limited to the local context of w, and some of these features may not be used by state-of-the-art statistical MT systems.", "labels": [], "entities": [{"text": "MT", "start_pos": 216, "end_pos": 218, "type": "TASK", "confidence": 0.8492279052734375}]}, {"text": "To perform translation, state-of-the-art MT systems use a statistical phrase-based approach () by treating phrases as the basic units of translation.", "labels": [], "entities": [{"text": "translation", "start_pos": 11, "end_pos": 22, "type": "TASK", "confidence": 0.9815568923950195}, {"text": "MT", "start_pos": 41, "end_pos": 43, "type": "TASK", "confidence": 0.9819489121437073}]}, {"text": "In this approach, a phrase can be any sequence of consecutive words and is not necessarily linguistically meaningful.", "labels": [], "entities": []}, {"text": "Capitalizing on the strength of the phrase-based approach, introduced a hierarchical phrase-based statistical MT system, Hiero, which achieves significantly better translation performance than Pharaoh, which is a state-of-the-art phrasebased statistical MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 110, "end_pos": 112, "type": "TASK", "confidence": 0.7698314785957336}, {"text": "Hiero", "start_pos": 121, "end_pos": 126, "type": "DATASET", "confidence": 0.8076173663139343}]}, {"text": "Recently, some researchers investigated whether performing WSD will help to improve the performance of an MT system.", "labels": [], "entities": [{"text": "WSD", "start_pos": 59, "end_pos": 62, "type": "TASK", "confidence": 0.9491146206855774}, {"text": "MT", "start_pos": 106, "end_pos": 108, "type": "TASK", "confidence": 0.9863684773445129}]}, {"text": "Carpuat and integrated the translation predictions from a Chinese WSD system) into a ChineseEnglish word-based statistical MT system using the ISI ReWrite decoder.", "labels": [], "entities": [{"text": "MT", "start_pos": 123, "end_pos": 125, "type": "TASK", "confidence": 0.4990357458591461}, {"text": "ISI ReWrite decoder", "start_pos": 143, "end_pos": 162, "type": "DATASET", "confidence": 0.8897182941436768}]}, {"text": "Though they acknowledged that directly using English translations as word senses would be ideal, they instead predicted the HowNet sense of a word and then used the English gloss of the HowNet sense as the WSD model's predicted translation.", "labels": [], "entities": [{"text": "HowNet", "start_pos": 124, "end_pos": 130, "type": "DATASET", "confidence": 0.9142274260520935}, {"text": "HowNet sense", "start_pos": 186, "end_pos": 198, "type": "DATASET", "confidence": 0.9119591116905212}]}, {"text": "They did not incorporate their WSD model or its predictions into their translation model; rather, they used the WSD predictions either to constrain the options available to their decoder, or to postedit the output of their decoder.", "labels": [], "entities": []}, {"text": "They reported the negative result that WSD decreased the performance of MT based on their experiments.", "labels": [], "entities": [{"text": "WSD", "start_pos": 39, "end_pos": 42, "type": "TASK", "confidence": 0.8587324619293213}, {"text": "MT", "start_pos": 72, "end_pos": 74, "type": "TASK", "confidence": 0.9910366535186768}]}, {"text": "In another work (), the WSD problem was recast as a word translation task.", "labels": [], "entities": [{"text": "WSD problem", "start_pos": 24, "end_pos": 35, "type": "TASK", "confidence": 0.9260718524456024}, {"text": "word translation task", "start_pos": 52, "end_pos": 73, "type": "TASK", "confidence": 0.8131284316380819}]}, {"text": "Thetranslation choices fora word w were defined as the set of words or phrases aligned tow, as gathered from a word-aligned parallel corpus.", "labels": [], "entities": []}, {"text": "The authors showed that they were able to improve their model's accuracy on two simplified translation tasks: word translation and blank-filling.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 64, "end_pos": 72, "type": "METRIC", "confidence": 0.9984645843505859}, {"text": "word translation", "start_pos": 110, "end_pos": 126, "type": "TASK", "confidence": 0.8036453127861023}]}, {"text": "Recently, experimented with incorporating WSD translations into Pharaoh, a state-of-the-art phrase-based MT system ( ).", "labels": [], "entities": [{"text": "WSD translations", "start_pos": 42, "end_pos": 58, "type": "TASK", "confidence": 0.9539406299591064}, {"text": "MT", "start_pos": 105, "end_pos": 107, "type": "TASK", "confidence": 0.7654343843460083}]}, {"text": "Their WSD system provided additional translations to the phrase table of Pharaoh, which fired anew model feature, so that the decoder could weigh the additional alternative translations against its own.", "labels": [], "entities": []}, {"text": "However, they could not automatically tune the weight of this feature in the same way as the others.", "labels": [], "entities": []}, {"text": "They obtained a relatively small improvement, and no statistical significance test was reported to determine if the improvement was statistically significant.", "labels": [], "entities": []}, {"text": "Note that the experiments in) did not use a state-of-the-art MT system, while the experiments in ( were not done using a full-fledged MT system and the evaluation was not on how well each source sentence was translated as a whole.", "labels": [], "entities": []}, {"text": "The relatively small improvement reported by without a statistical significance test appears to be inconclusive.", "labels": [], "entities": []}, {"text": "Considering the conflicting results reported by prior work, it is not clear whether a WSD system can help to improve the performance of a state-of-the-art statistical MT system.", "labels": [], "entities": [{"text": "MT", "start_pos": 167, "end_pos": 169, "type": "TASK", "confidence": 0.9305248260498047}]}, {"text": "In this paper, we successfully integrate a stateof-the-art WSD system into the state-of-the-art hierarchical phrase-based MT system, Hiero).", "labels": [], "entities": [{"text": "Hiero", "start_pos": 133, "end_pos": 138, "type": "DATASET", "confidence": 0.8417224287986755}]}, {"text": "The integration is accomplished by introducing two additional features into the MT model which operate on the existing rules of the grammar, without introducing competing rules.", "labels": [], "entities": [{"text": "MT", "start_pos": 80, "end_pos": 82, "type": "TASK", "confidence": 0.8949037194252014}]}, {"text": "These features are treated, both in feature-weight tuning and in decoding, on the same footing as the rest of the model, allowing it to weigh the WSD model predictions against other pieces of evidence so as to optimize translation accuracy (as measured by BLEU).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 231, "end_pos": 239, "type": "METRIC", "confidence": 0.838291585445404}, {"text": "BLEU", "start_pos": 256, "end_pos": 260, "type": "METRIC", "confidence": 0.9981788396835327}]}, {"text": "The contribution of our work lies in showing for the first time that integrating a WSD system significantly improves the performance of a state-of-the-art statistical MT system on an actual translation task.", "labels": [], "entities": [{"text": "MT", "start_pos": 167, "end_pos": 169, "type": "TASK", "confidence": 0.9144019484519958}, {"text": "translation task", "start_pos": 190, "end_pos": 206, "type": "TASK", "confidence": 0.8395106792449951}]}, {"text": "In the next section, we describe our WSD system.", "labels": [], "entities": [{"text": "WSD", "start_pos": 37, "end_pos": 40, "type": "TASK", "confidence": 0.9613441228866577}]}, {"text": "Then, in Section 3, we describe the Hiero MT system and introduce the two new features used to integrate the WSD system into Hiero.", "labels": [], "entities": [{"text": "Hiero MT system", "start_pos": 36, "end_pos": 51, "type": "DATASET", "confidence": 0.8342141310373942}, {"text": "Hiero", "start_pos": 125, "end_pos": 130, "type": "DATASET", "confidence": 0.9262939691543579}]}, {"text": "In Section 4, we describe the training data used by the WSD system.", "labels": [], "entities": [{"text": "WSD", "start_pos": 56, "end_pos": 59, "type": "TASK", "confidence": 0.8685745596885681}]}, {"text": "In Section 5, we describe how the WSD translations provided are used by the decoder of the MT system.", "labels": [], "entities": [{"text": "WSD translations", "start_pos": 34, "end_pos": 50, "type": "TASK", "confidence": 0.6802982091903687}, {"text": "MT", "start_pos": 91, "end_pos": 93, "type": "TASK", "confidence": 0.7761045694351196}]}, {"text": "In Section 6 and 7, we present and analyze our experimental results, before concluding in Section 8.", "labels": [], "entities": []}], "datasetContent": [{"text": "As mentioned, our experiments were on Chinese to English translation.", "labels": [], "entities": [{"text": "Chinese to English translation", "start_pos": 38, "end_pos": 68, "type": "TASK", "confidence": 0.5812614038586617}]}, {"text": "Similar to. the English portion of the FBIS corpus and the Xinhua portion of the Gigaword corpus, we trained a trigram language model using the SRI Language Modelling Toolkit.", "labels": [], "entities": [{"text": "FBIS corpus", "start_pos": 39, "end_pos": 50, "type": "DATASET", "confidence": 0.8887837827205658}, {"text": "Gigaword corpus", "start_pos": 81, "end_pos": 96, "type": "DATASET", "confidence": 0.9188959896564484}, {"text": "SRI Language Modelling Toolkit", "start_pos": 144, "end_pos": 174, "type": "DATASET", "confidence": 0.7390978634357452}]}, {"text": "Following, we used the version 11a NIST BLEU script with its default settings to calculate the BLEU scores () based on case-insensitive ngram matching, where n is up to 4.", "labels": [], "entities": [{"text": "NIST", "start_pos": 35, "end_pos": 39, "type": "DATASET", "confidence": 0.7263603806495667}, {"text": "BLEU", "start_pos": 40, "end_pos": 44, "type": "METRIC", "confidence": 0.9052152633666992}, {"text": "BLEU scores", "start_pos": 95, "end_pos": 106, "type": "METRIC", "confidence": 0.9739855229854584}]}, {"text": "First, we performed word alignment on the FBIS parallel corpus using GIZA++) in both directions.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 20, "end_pos": 34, "type": "TASK", "confidence": 0.7938053011894226}, {"text": "FBIS parallel corpus", "start_pos": 42, "end_pos": 62, "type": "DATASET", "confidence": 0.7892632484436035}]}, {"text": "The word alignments of both directions are then combined into a single set of alignments using the \"diag-and\" method of . Based on these alignments, synchronous CFG rules are then extracted from the corpus.", "labels": [], "entities": []}, {"text": "While Hiero is extracting grammar rules, we gathered WSD training data by following the procedure described in section 4.", "labels": [], "entities": [{"text": "WSD training", "start_pos": 53, "end_pos": 65, "type": "TASK", "confidence": 0.7809106111526489}]}], "tableCaptions": [{"text": " Table 2: Weights for each feature obtained by MERT training. The first eight features are those used by  Hiero in", "labels": [], "entities": [{"text": "MERT", "start_pos": 47, "end_pos": 51, "type": "TASK", "confidence": 0.6344488859176636}, {"text": "Hiero", "start_pos": 106, "end_pos": 111, "type": "DATASET", "confidence": 0.905384361743927}]}, {"text": " Table 3: Number of WSD translations used and proportion that matches against respective reference sen- tences. WSD translations longer than 4 words are very sparse (less than 10 occurrences) and thus they are  not shown.", "labels": [], "entities": [{"text": "WSD translations", "start_pos": 20, "end_pos": 36, "type": "TASK", "confidence": 0.7919609546661377}]}]}