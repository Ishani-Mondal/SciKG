{"title": [{"text": "A Feature Based Approach to Leveraging Context for Classifying Newsgroup Style Discussion Segments", "labels": [], "entities": [{"text": "Classifying Newsgroup Style Discussion Segments", "start_pos": 51, "end_pos": 98, "type": "TASK", "confidence": 0.797773277759552}]}], "abstractContent": [{"text": "On a multi-dimensional text categorization task, we compare the effectiveness of a feature based approach with the use of a state-of-the-art sequential learning technique that has proven successful for tasks such as \"email act classification\".", "labels": [], "entities": [{"text": "text categorization task", "start_pos": 23, "end_pos": 47, "type": "TASK", "confidence": 0.7466598947842916}, {"text": "email act classification", "start_pos": 217, "end_pos": 241, "type": "TASK", "confidence": 0.6910617351531982}]}, {"text": "Our evaluation demonstrates for the three separate dimensions of a well established annotation scheme that novel thread based features have a greater and more consistent impact on classification performance.", "labels": [], "entities": []}], "introductionContent": [{"text": "The problem of information overload in personal communication media such as email, instant messaging, and on-line discussion boards is a well documented phenomenon.", "labels": [], "entities": []}, {"text": "Because of this, conversation summarization is an area with a great potential impact.", "labels": [], "entities": [{"text": "conversation summarization", "start_pos": 17, "end_pos": 43, "type": "TASK", "confidence": 0.8236736357212067}]}, {"text": "What is strikingly different about this form of summarization from summarization of expository text is that the summary may include more than just the content, such as the style and structure of the conversation).", "labels": [], "entities": [{"text": "summarization", "start_pos": 48, "end_pos": 61, "type": "TASK", "confidence": 0.9822714328765869}]}, {"text": "In this paper we focus on a classification task that will eventually be used to enable this form of conversation summarization by providing indicators of the quality of group functioning and argumentation.", "labels": [], "entities": [{"text": "conversation summarization", "start_pos": 100, "end_pos": 126, "type": "TASK", "confidence": 0.6378439366817474}]}, {"text": "Lacson and colleagues (2006) describe a form of conversation summarization where a classification approach is first applied to segments of a conversation in order to identify regions of the conversation related to different types of information.", "labels": [], "entities": [{"text": "conversation summarization", "start_pos": 48, "end_pos": 74, "type": "TASK", "confidence": 0.6440218091011047}]}, {"text": "This aids in structuring a useful summary.", "labels": [], "entities": []}, {"text": "In this paper, we describe work in progress towards a different form of conversation summarization that similarly leverages a text classification approach.", "labels": [], "entities": [{"text": "conversation summarization", "start_pos": 72, "end_pos": 98, "type": "TASK", "confidence": 0.7072922587394714}, {"text": "text classification", "start_pos": 126, "end_pos": 145, "type": "TASK", "confidence": 0.7243031859397888}]}, {"text": "We focus on newsgroup style interactions.", "labels": [], "entities": []}, {"text": "The goal of assessing the quality of interactions in that context is to enable the quality and nature of discussions that occur within an on-line discussion board to be communicated in a summary to a potential newcomer or group moderators.", "labels": [], "entities": []}, {"text": "We propose to adopt an approach developed in the computer supported collaborative learning (CSCL) community for measuring the quality of interactions in a threaded, online discussion forum using a multi-dimensional annotation scheme).", "labels": [], "entities": []}, {"text": "Using this annotation scheme, messages are segmented into idea units and then coded with several independent dimensions, three of which are relevant for our work, namely micro-argumentation, macroargumentation, and social modes of coconstruction, which categorizes spans of text as belonging to one of five consensus building categories.", "labels": [], "entities": []}, {"text": "By coding segments with this annotation scheme, it is possible to measure the extent to which group members' arguments are well formed or the extent to which they are engaging in functional or dysfunctional consensus building behavior.", "labels": [], "entities": []}, {"text": "This work can be seen as analogous to work on \"email act classification\").", "labels": [], "entities": [{"text": "email act classification", "start_pos": 47, "end_pos": 71, "type": "TASK", "confidence": 0.6421339710553488}]}, {"text": "However, while in some ways the structure of newsgroup style interaction is more straightforward than email based interaction because of the unambiguous thread structure), what makes this particularly challenging from a technical standpoint is that the structure of this type of conversation is multi-leveled, as we describe in greater depth below.", "labels": [], "entities": []}, {"text": "We investigate the use of state-of-the-art sequential learning techniques that have proven successful for email act classification in comparison with a feature based approach.", "labels": [], "entities": [{"text": "email act classification", "start_pos": 106, "end_pos": 130, "type": "TASK", "confidence": 0.7505503098169962}]}, {"text": "Our evaluation demonstrates for the three separate dimensions of a context oriented annotation scheme that novel thread based features have a greater and more consistent impact on classification performance.", "labels": [], "entities": []}], "datasetContent": [{"text": "The purpose of our evaluation is to contrast our proposed feature based approach with a state-ofthe-art sequential learning technique.", "labels": [], "entities": []}, {"text": "Both approaches are designed to leverage context for the purpose of increasing classification accuracy on a classification task where the codes refer to the role a span of text plays in context.", "labels": [], "entities": [{"text": "classification", "start_pos": 79, "end_pos": 93, "type": "TASK", "confidence": 0.9528875946998596}, {"text": "accuracy", "start_pos": 94, "end_pos": 102, "type": "METRIC", "confidence": 0.8875695466995239}]}, {"text": "We evaluate these two approaches alone and in combination over the same data but with three different sets of codes, namely the three relevant dimensions of the Weinberger and Fischer annotation scheme.", "labels": [], "entities": []}, {"text": "In all cases, we employ a 10-fold cross-validation methodology, where we apply a feature selection wrapper in such as way as to select the 100 best features over the training set on each fold, and then to apply this feature space and the trained model to the test set.", "labels": [], "entities": []}, {"text": "The complete corpus comprises about 250 discussions of the participants.", "labels": [], "entities": []}, {"text": "From this we have run our experiments with a subset of this data, using altogether 1250 annotated text segments.", "labels": [], "entities": []}, {"text": "Trained coders categorized each segment using this multi-dimensional annotation scheme, in each case achieving a level of agreement exceeding .7 Kappa both for segmentation and coding of all dimensions as previously published).", "labels": [], "entities": []}, {"text": "For each dimension, we first evaluate alternative combinations of features using SMO, Weka's implementation of Support Vector Machines).", "labels": [], "entities": []}, {"text": "For a sequential learning algorithm, we make use of the Collins Perceptron Learner).", "labels": [], "entities": [{"text": "Collins Perceptron Learner", "start_pos": 56, "end_pos": 82, "type": "DATASET", "confidence": 0.9114486376444498}]}, {"text": "When using the Collins Perceptron Learner, in all cases we evaluate combinations of alternative history sizes (0 and 1) and alternative feature sets (base and base+AllContext).", "labels": [], "entities": [{"text": "Collins Perceptron Learner", "start_pos": 15, "end_pos": 41, "type": "DATASET", "confidence": 0.9240772525469462}, {"text": "AllContext", "start_pos": 164, "end_pos": 174, "type": "METRIC", "confidence": 0.8750170469284058}]}, {"text": "In our experimentation we have evaluated larger history sizes as well, but the performance was consistently worse as the history size grew larger than 1.", "labels": [], "entities": []}, {"text": "Thus, we only report results for history sizes of 0 and 1.", "labels": [], "entities": []}, {"text": "Our evaluation demonstrates that we achieve a much greater impact on performance with carefully designed, automatically extractable context oriented features.", "labels": [], "entities": []}, {"text": "In all cases we are able to achieve a statistically significant improvement by adding context oriented features, and only achieve a statistically significant improvement using sequential learning for one dimension, and only in the absence of context oriented features.", "labels": [], "entities": []}], "tableCaptions": []}