{"title": [{"text": "A Comparison between Dialog Corpora Acquired with Real and Simulated Users", "labels": [], "entities": []}], "abstractContent": [{"text": "In this paper, we test the applicability of a stochastic user simulation technique to generate dialogs which are similar to real human-machine spoken interactions.", "labels": [], "entities": []}, {"text": "To do so, we present a comparison between two corpora employing a comprehensive set of evaluation measures.", "labels": [], "entities": []}, {"text": "The first corpus was acquired from real interactions of users with a spoken dialog system , whereas the second was generated by means of the simulation technique, which decides the next user answer taking into account the previous user turns, the last system answer and the objective of the dialog .", "labels": [], "entities": []}], "introductionContent": [{"text": "During the last decade, there has been a growing interest in learning corpus-based approaches for the different components of spoken dialog systems,,,,,),.", "labels": [], "entities": []}, {"text": "One of the most relevant areas of study has been the automatic generation of dialogs between the dialog manager and an additional module, called the user simulator, which generates automatic interactions with the dialog system.", "labels": [], "entities": []}, {"text": "A considerable effort is necessary to acquire and label a corpus with the data necessary to train good models.", "labels": [], "entities": []}, {"text": "User simulators make it possible to generate a large number of dialogs in a very simple way, reducing the time and effort needed for the evaluation of a dialog system each time the system is modified.", "labels": [], "entities": []}, {"text": "The construction of user models based on statistical methods has provided interesting and wellfounded results in recent years and is currently a growing research area.", "labels": [], "entities": []}, {"text": "A probabilistic user model can be trained from a corpus of human-computer dialogs to simulate user answers.", "labels": [], "entities": []}, {"text": "Therefore, it can be used to learn a dialog strategy by means of its interaction with the dialog manager.", "labels": [], "entities": []}, {"text": "In the literature, there are several corpus-based approaches for developing user simulators, learning optimal management strategies, and evaluating the dialog system ()) ()) ().", "labels": [], "entities": []}, {"text": "A summary of user simulation techniques for reinforcement learning of the dialog strategy can be found in ().", "labels": [], "entities": []}, {"text": "In this paper, we propose a statistical approach to acquire a labeled dialog corpus from the interaction of a user simulator and a dialog manager.", "labels": [], "entities": []}, {"text": "In our methodology, the new user turn is selected using the probability distribution provided by a neural network.", "labels": [], "entities": []}, {"text": "By means of the interaction of the dialog manager and the user simulator, an initial dialog corpus can be extended by increasing its variability and detecting dialog situations in which the dialog manager does not provide an appropriate answer.", "labels": [], "entities": []}, {"text": "We propose the use of this corpus for evaluating both our user simulation technique and our dialog system performance.", "labels": [], "entities": []}, {"text": "Different studies have been carried out to compare corpora acquired by means of different techniques and to define the most suitable measures to carryout this evaluation (), (), (,),,.", "labels": [], "entities": []}, {"text": "In this work, we have applied our dialog simulation technique to acquire a corpus in the academic domain, and compared it with a corpus recorded from real users interactions with a spo-ken dialog system The results of this comparison show that the simulated corpus obtained is very similar to the corpus recorded from real user interactions in terms of number of turns, confirmations and dialog acts among other evaluation measures.", "labels": [], "entities": []}, {"text": "The rest of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 summarizes the main characteristics of the UAH system.", "labels": [], "entities": []}, {"text": "Section 3 describes our statistical methodology for user simulation.", "labels": [], "entities": []}, {"text": "Section 4 describes the set of measures used to compare the corpus acquired with real users and the simulated corpus.", "labels": [], "entities": []}, {"text": "Section 5 presents the results of this evaluation, and finally, the conclusions are presented in Section 6.", "labels": [], "entities": []}], "datasetContent": [{"text": "We used a set of measures to carryout the evaluation of the acquired corpora based on prior work in the dialog literature.", "labels": [], "entities": []}, {"text": "( proposed a comprehensive set of quantitative evaluation measures to compare two dialog corpora.", "labels": [], "entities": []}, {"text": "These measures were adapted for our purpose and can be divided into three types:  \u2022 Dialog style/cooperativeness measures: These measures analyze the frequency of the different speech acts and study, for example, the proportion of actions which are goal-directed vs. dialog formalities.", "labels": [], "entities": []}, {"text": "\u2022 Task success/efficiency measures: These are computations of the goal achievement rates and goal completion times.", "labels": [], "entities": []}, {"text": "We have defined six high-level dialog features for the evaluation of the dialogs: the average number of turns per dialog, the percentage of different dialogs without considering the attribute values, the number of repetitions of the most seen dialog, the number of turns of the most seen dialog, the number of turns of the shortest dialog, and the number of turns of the longest dialog.", "labels": [], "entities": []}, {"text": "Using these measures, we tried to evaluate the success of the simulated dialogs as well as their efficiency and variability with regard to the different objectives.", "labels": [], "entities": []}, {"text": "For dialog style features, we have defined a set of system/user dialog acts.", "labels": [], "entities": []}, {"text": "On the system side, we have measured the frequency of confirmations, questions that require information, and system answers generated after a database query.", "labels": [], "entities": []}, {"text": "We have not taken into account the opening and closing system turns.", "labels": [], "entities": []}, {"text": "On the user side, we have measured the percentage of turns in which the user carries out a request to the system, provide information, confirms a concept or attribute, Yes/No answers, and other answers not included in the previous categories.", "labels": [], "entities": []}, {"text": "We have not considered task success/efficiency measures in our evaluation, since only the dialogs that fulfill the objectives predefined in the scenarios have been incorporated into our corpora.", "labels": [], "entities": []}, {"text": "We have considered successful dialogs those that fulfill the complete list of objectives defined in the corresponding scenario.", "labels": [], "entities": []}, {"text": "summarizes the complete set of measures used in the evaluation.", "labels": [], "entities": []}, {"text": "To compare the two corpora, we have computed the mean value for each corpus with respect to each of the evaluation measures shown in the previous section.", "labels": [], "entities": []}, {"text": "Then two-tailed t-tests have been employed to compare the means across the two corpora as described in).", "labels": [], "entities": []}, {"text": "All differences reported as statistically significant have p-values less than 0.05 after Bonferroni corrections.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: Results of the high-level dialog features defined for the comparison of the three corpora", "labels": [], "entities": []}, {"text": " Table 3: Percentages of the different types of system dialog acts in both corpora", "labels": [], "entities": []}]}