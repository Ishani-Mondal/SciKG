{"title": [{"text": "Transliteration of Name Entity via Improved Statistical Translation on Character Sequences", "labels": [], "entities": [{"text": "Transliteration of Name Entity", "start_pos": 0, "end_pos": 30, "type": "TASK", "confidence": 0.7899405509233475}, {"text": "Statistical Translation on Character Sequences", "start_pos": 44, "end_pos": 90, "type": "TASK", "confidence": 0.6496723771095276}]}], "abstractContent": [{"text": "Transliteration of given parallel name entities can be formulated as a phrase-based statistical machine translation (SMT) process , via its routine procedure comprising training, optimization and decoding.", "labels": [], "entities": [{"text": "Transliteration of given parallel name entities", "start_pos": 0, "end_pos": 47, "type": "TASK", "confidence": 0.8546927869319916}, {"text": "statistical machine translation (SMT)", "start_pos": 84, "end_pos": 121, "type": "TASK", "confidence": 0.7888720979293188}]}, {"text": "In this paper, we present our approach to transliterating name entities using the log-linear phrase-based SMT on character sequences.", "labels": [], "entities": [{"text": "SMT", "start_pos": 106, "end_pos": 109, "type": "TASK", "confidence": 0.8624638319015503}]}, {"text": "Our proposed work improves the translation by using bidirectional models, plus some heuristic guidance integrated in the decoding process.", "labels": [], "entities": [{"text": "translation", "start_pos": 31, "end_pos": 42, "type": "TASK", "confidence": 0.9842064380645752}]}, {"text": "Our evaluated results indicate that this approach performs well in all standard runs in the NEWS2009 Machine Transliteration Shared Task.", "labels": [], "entities": [{"text": "NEWS2009 Machine Transliteration Shared Task", "start_pos": 92, "end_pos": 136, "type": "TASK", "confidence": 0.5971985220909118}]}], "introductionContent": [{"text": "To transliterate a foreign name into a target language, a direct instrument is to make use of existing rules for converting text to syllabus, or at least a phoneme base to support such transformation.", "labels": [], "entities": [{"text": "transliterate a foreign name into a target language", "start_pos": 3, "end_pos": 54, "type": "TASK", "confidence": 0.7905622348189354}]}, {"text": "Following this path, the well developed noisy channel model used for transliteration usually set an intermediate layer to represent the source and target names by phonemes or phonetic tags).", "labels": [], "entities": []}, {"text": "Having been studied extensively though, the phonemes-based approaches cannot break its performance ceiling for two reasons (): (1) Languagedependent phoneme representation is not easy to obtain; (2) The phonemic representation to source and target names usually causes error spread.", "labels": [], "entities": [{"text": "Languagedependent phoneme representation", "start_pos": 131, "end_pos": 171, "type": "TASK", "confidence": 0.5667352477709452}]}, {"text": "Several approaches have been proposed for direct use of parallel texts for performance enhancement (.", "labels": [], "entities": []}, {"text": "There is no straightforward mean for grouping characters or letters in the source or target language into better transliteration units fora better correspondence.", "labels": [], "entities": []}, {"text": "There is no consistent deterministic mapping between two languages either, especially when they belong to different language families, such as English and Chinese.", "labels": [], "entities": []}, {"text": "Usually, a single character in a source name is not enough to form a phonetic pattern in a target name.", "labels": [], "entities": []}, {"text": "Thus a better way to model transliteration is to map character sequences between source and target name entities.", "labels": [], "entities": []}, {"text": "The mapping is actually an alignment process.", "labels": [], "entities": []}, {"text": "If a certain quantity of bilingual transliterated entities are available for training, it is a straight-forward idea to tackle this transliteration problem with a mature framework such as phrase-based SMT.", "labels": [], "entities": [{"text": "SMT", "start_pos": 201, "end_pos": 204, "type": "TASK", "confidence": 0.7333605885505676}]}, {"text": "It can be considered a general statistical translation task if the character sequences involved are treated like phrases.", "labels": [], "entities": [{"text": "statistical translation task", "start_pos": 31, "end_pos": 59, "type": "TASK", "confidence": 0.722211500008901}]}, {"text": "In so doing, however, a few points need to be highlighted.", "labels": [], "entities": []}, {"text": "Firstly, only parallel data are required for generating transliteration outputs via SMT, and this SMT translation process can be easily integrated as a component into a general-purpose SMT system.", "labels": [], "entities": [{"text": "SMT", "start_pos": 84, "end_pos": 87, "type": "TASK", "confidence": 0.9663592576980591}, {"text": "SMT translation", "start_pos": 98, "end_pos": 113, "type": "TASK", "confidence": 0.9833116829395294}, {"text": "SMT", "start_pos": 185, "end_pos": 188, "type": "TASK", "confidence": 0.9771382808685303}]}, {"text": "Secondly, on character sequences, the mapping between source and target name entities can be performed on even larger units.", "labels": [], "entities": []}, {"text": "Consequently, contextual information can be exploited to facilitate the alignment, fora string can be used as a context for everyone of its own characters.", "labels": [], "entities": []}, {"text": "It is reasonable to expect such relevant information to produce more precisely statistical results for finding corresponding transliterations.", "labels": [], "entities": []}, {"text": "Thirdly, transliteration as a monotonic word ordering transformation problem allows the alignment to be performed monotonously from the beginning to the end of a text.", "labels": [], "entities": [{"text": "word ordering transformation", "start_pos": 40, "end_pos": 68, "type": "TASK", "confidence": 0.811060388882955}]}, {"text": "Thus its decoding is easy to perform as its search space shrinks this way, for re-ordering is considered not to be involved, in contrast to the general SMT process.", "labels": [], "entities": [{"text": "SMT", "start_pos": 152, "end_pos": 155, "type": "TASK", "confidence": 0.9922858476638794}]}, {"text": "This paper is intended to present our work on applying phrased-based SMT technologies to tackle transliteration.", "labels": [], "entities": [{"text": "SMT", "start_pos": 69, "end_pos": 72, "type": "TASK", "confidence": 0.8057633638381958}]}, {"text": "The following sections will report how we have carried out our experiments for the NEWS2009 task ( and present the experimented results.", "labels": [], "entities": [{"text": "NEWS2009 task", "start_pos": 83, "end_pos": 96, "type": "DATASET", "confidence": 0.7541036307811737}]}], "datasetContent": [{"text": "For NEWS2009, we participated in all 8 standard runs of transliteration task, namely, EnCh (), EnJa, EnKo, JnJk 3 , EnHi, EnTa, EnKa and EnRu (.", "labels": [], "entities": [{"text": "NEWS2009", "start_pos": 4, "end_pos": 12, "type": "DATASET", "confidence": 0.8170264363288879}, {"text": "EnKa", "start_pos": 128, "end_pos": 132, "type": "DATASET", "confidence": 0.9014360308647156}, {"text": "EnRu", "start_pos": 137, "end_pos": 141, "type": "DATASET", "confidence": 0.8440970778465271}]}, {"text": "Ten best candidates generated for each source name are submitted for each run.", "labels": [], "entities": []}, {"text": "The transliteration performance is evaluated by the official script 4 , using six metrics 5 . The official evaluation results for our system are presented in.", "labels": [], "entities": []}, {"text": "The effectiveness of our approach is revealed by the fact that many of our Mean F-scores are above 0.8 for various tasks.", "labels": [], "entities": [{"text": "Mean F-scores", "start_pos": 75, "end_pos": 88, "type": "METRIC", "confidence": 0.7937221229076385}]}, {"text": "These high scores suggest that our top candidates are close to the given references.", "labels": [], "entities": []}, {"text": "Besides, it is also interesting to look into how well the desired targets are generated under a certain recall rate, by examining if the best answers are among the ten candidates produced for each source name.", "labels": [], "entities": [{"text": "recall rate", "start_pos": 104, "end_pos": 115, "type": "METRIC", "confidence": 0.9761360585689545}]}, {"text": "If the recall rate goes far beyond MRR, it can be a reliable indication that the desired targets are found for most source names, but just not put at the top of the ten-best.", "labels": [], "entities": [{"text": "recall rate", "start_pos": 7, "end_pos": 18, "type": "METRIC", "confidence": 0.9862289428710938}, {"text": "MRR", "start_pos": 35, "end_pos": 38, "type": "METRIC", "confidence": 0.9391707181930542}]}, {"text": "From the last column in, we can see a great chance to improve our performance, especially for EnCh, JnJk and EnRu runs.", "labels": [], "entities": [{"text": "EnCh", "start_pos": 94, "end_pos": 98, "type": "DATASET", "confidence": 0.9812643527984619}, {"text": "JnJk", "start_pos": 100, "end_pos": 104, "type": "DATASET", "confidence": 0.7648942470550537}, {"text": "EnRu", "start_pos": 109, "end_pos": 113, "type": "DATASET", "confidence": 0.8685347437858582}]}, {"text": "But still, since SMT is a data-driven approach, the amount of training data could affect the transliteration results significantly.", "labels": [], "entities": [{"text": "SMT", "start_pos": 17, "end_pos": 20, "type": "TASK", "confidence": 0.9927700161933899}]}, {"text": "shows the training data size in our task.", "labels": [], "entities": []}, {"text": "It gives a hint on the connections between the performance, especially Mean F-score, and the data size.", "labels": [], "entities": [{"text": "Mean", "start_pos": 71, "end_pos": 75, "type": "METRIC", "confidence": 0.9824835658073425}, {"text": "F-score", "start_pos": 76, "end_pos": 83, "type": "METRIC", "confidence": 0.5836948156356812}]}, {"text": "In spite of the low ACC, EnKa test has a Mean F-score close to other two runs, namely EnHi and EnTa, of similar data size.", "labels": [], "entities": [{"text": "ACC", "start_pos": 20, "end_pos": 23, "type": "METRIC", "confidence": 0.9954901337623596}, {"text": "EnKa test", "start_pos": 25, "end_pos": 34, "type": "DATASET", "confidence": 0.8948916494846344}, {"text": "Mean", "start_pos": 41, "end_pos": 45, "type": "METRIC", "confidence": 0.995512068271637}, {"text": "F-score", "start_pos": 46, "end_pos": 53, "type": "METRIC", "confidence": 0.7311288118362427}, {"text": "EnHi", "start_pos": 86, "end_pos": 90, "type": "DATASET", "confidence": 0.9626626968383789}, {"text": "EnTa", "start_pos": 95, "end_pos": 99, "type": "DATASET", "confidence": 0.8747166395187378}]}, {"text": "For EnRu test, although the training data is limited, the highest Mean F-score is achieved thanks to the nice correspondence between English and Russian characters.", "labels": [], "entities": [{"text": "EnRu test", "start_pos": 4, "end_pos": 13, "type": "DATASET", "confidence": 0.8366608321666718}, {"text": "Mean", "start_pos": 66, "end_pos": 70, "type": "METRIC", "confidence": 0.9985176920890808}, {"text": "F-score", "start_pos": 71, "end_pos": 78, "type": "METRIC", "confidence": 0.7789575457572937}]}], "tableCaptions": [{"text": " Table 1: Comparison: baseline v.s. optimized  performance on EnCh and EnRu development  sets.", "labels": [], "entities": [{"text": "EnCh", "start_pos": 62, "end_pos": 66, "type": "DATASET", "confidence": 0.9611787796020508}, {"text": "EnRu development  sets", "start_pos": 71, "end_pos": 93, "type": "DATASET", "confidence": 0.8350487152735392}]}, {"text": " Table 3: Numbers of name entities in NEWS2009  training data 6 .", "labels": [], "entities": [{"text": "NEWS2009  training data", "start_pos": 38, "end_pos": 61, "type": "DATASET", "confidence": 0.9112025101979574}]}, {"text": " Table 2: Evaluation result of NEWS2009 task.", "labels": [], "entities": [{"text": "NEWS2009", "start_pos": 31, "end_pos": 39, "type": "DATASET", "confidence": 0.6963780522346497}]}]}