{"title": [{"text": "Refining the most frequent sense baseline", "labels": [], "entities": [{"text": "Refining", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.9698508977890015}]}], "abstractContent": [{"text": "We refine the most frequent sense baseline for word sense disambiguation using a number of novel word sense disambiguation techniques.", "labels": [], "entities": [{"text": "word sense disambiguation", "start_pos": 47, "end_pos": 72, "type": "TASK", "confidence": 0.7351625164349874}, {"text": "word sense disambiguation", "start_pos": 97, "end_pos": 122, "type": "TASK", "confidence": 0.6586014231046041}]}, {"text": "Evaluating on the S\uf765\uf76e\uf773\uf765\uf776\uf761\uf76c-3 English all words task, our combined system focuses on improving every stage of word sense dis-ambiguation: starting with the lemmatization and part of speech tags used, through the accuracy of the most frequent sense baseline, to highly targeted individual systems.", "labels": [], "entities": [{"text": "S\uf765\uf76e\uf773\uf765\uf776\uf761\uf76c-3 English all words task", "start_pos": 18, "end_pos": 51, "type": "TASK", "confidence": 0.7448598487036568}, {"text": "word sense dis-ambiguation", "start_pos": 109, "end_pos": 135, "type": "TASK", "confidence": 0.6586049397786459}, {"text": "accuracy", "start_pos": 211, "end_pos": 219, "type": "METRIC", "confidence": 0.9962008595466614}]}, {"text": "Our supervised systems include a ranking algorithm and a Wikipedia similarity measure.", "labels": [], "entities": [{"text": "Wikipedia similarity measure", "start_pos": 57, "end_pos": 85, "type": "METRIC", "confidence": 0.588482548793157}]}], "introductionContent": [{"text": "The difficulty of outperforming the most frequent sense baseline, the assignment of the sense which appears most often in a given annotated corpus, in word sense disambiguation (WSD) has been brought to light by the recent S\uf765\uf76e\uf773\uf765\uf776\uf761\uf76c WSD system evaluation exercises.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 151, "end_pos": 182, "type": "TASK", "confidence": 0.7498886237541834}, {"text": "S\uf765\uf76e\uf773\uf765\uf776\uf761\uf76c WSD system evaluation", "start_pos": 223, "end_pos": 253, "type": "TASK", "confidence": 0.7258547067642211}]}, {"text": "In this work, we present a combination system, which, rather than designing a single approach to all words, enriches the most frequent sense baseline when there is high confidence for an alternative sense to be chosen.", "labels": [], "entities": []}, {"text": "WSD, the task of assigning a sense to a given word from a sense inventory is clearly necessary for other natural language processing tasks.", "labels": [], "entities": []}, {"text": "For example, when performing machine translation, it is necessary to distinguish between word senses in the original language if the different senses have different possible translations in the target language.", "labels": [], "entities": [{"text": "machine translation", "start_pos": 29, "end_pos": 48, "type": "TASK", "confidence": 0.7580199837684631}]}, {"text": "A number of different approaches to WSD have been explored in recent years, with two distinct approaches: techniques which require annotated training data (supervised techniques) and techniques which do not (unsupervised methods).", "labels": [], "entities": [{"text": "WSD", "start_pos": 36, "end_pos": 39, "type": "TASK", "confidence": 0.9922084212303162}]}, {"text": "It has long been believed that supervised systems, which can be tuned to a word's context, greatly outperform unsupervised systems.", "labels": [], "entities": []}, {"text": "This theory was supported in the S\uf765\uf76e\uf773\uf765\uf776\uf761\uf76c WSD system evaluation exercises, where the performance gap between the best supervised system and the best unsupervised system is large.", "labels": [], "entities": [{"text": "S\uf765\uf76e\uf773\uf765\uf776\uf761\uf76c WSD system evaluation", "start_pos": 33, "end_pos": 63, "type": "TASK", "confidence": 0.8246013998985291}]}, {"text": "Unsupervised systems were found to never outperform the most frequent sense (MFS) baseline (a sense assignment made on the basis of the most frequent sense in an annotated corpus), while supervised systems occasionally perform better than the MFS baseline, though rarely by more than 5%.", "labels": [], "entities": []}, {"text": "However, recent work by shows that acquiring a predominant sense from an unannotated corpus can outperform many supervised systems, and under certain conditions will also outperform the MFS baseline.", "labels": [], "entities": []}, {"text": "Rather than proposing anew algorithm which will tackle all words, we focus on improving upon the MFS baseline system when an alternative system proposes a high confidence answer.", "labels": [], "entities": [{"text": "MFS baseline", "start_pos": 97, "end_pos": 109, "type": "DATASET", "confidence": 0.7442806661128998}]}, {"text": "An MFS refining system can therefore benefit from answers suggested by a very low recall (but high precision) WSD system.", "labels": [], "entities": [{"text": "MFS refining", "start_pos": 3, "end_pos": 15, "type": "TASK", "confidence": 0.8328476250171661}, {"text": "recall", "start_pos": 82, "end_pos": 88, "type": "METRIC", "confidence": 0.9979625940322876}, {"text": "precision", "start_pos": 99, "end_pos": 108, "type": "METRIC", "confidence": 0.9571366906166077}]}, {"text": "We propose a number of novel approaches to WSD, but also demonstrate the importance of a highly accurate lemmatizer and part of speech tagger to the English all words task of S\uf765\uf76e\uf773\uf765\uf776\uf761\uf76c-3.", "labels": [], "entities": [{"text": "WSD", "start_pos": 43, "end_pos": 46, "type": "TASK", "confidence": 0.9901158213615417}]}, {"text": "We present our enriched most frequent sense 1 Unless specified otherwise, we use WordNet 1.7.1) and the associated sense annotated SemCor corpus () (translated to WordNet 1.7.1 by Rada Mihalcea).", "labels": [], "entities": [{"text": "WordNet 1.7.1", "start_pos": 81, "end_pos": 94, "type": "DATASET", "confidence": 0.9553117752075195}, {"text": "SemCor corpus", "start_pos": 131, "end_pos": 144, "type": "DATASET", "confidence": 0.7190439403057098}, {"text": "WordNet 1.7.1", "start_pos": 163, "end_pos": 176, "type": "DATASET", "confidence": 0.9252743422985077}]}, {"text": "baseline in Section 2, which motivates the lemmatizer and part of speech tagger refinements presented in Section 3.", "labels": [], "entities": [{"text": "speech tagger refinements", "start_pos": 66, "end_pos": 91, "type": "TASK", "confidence": 0.7848069369792938}]}, {"text": "Our novel high precision WSD algorithms include a reranking algorithm (Section 4), and a Wikipedia-based similarity measure (Section 5).", "labels": [], "entities": [{"text": "WSD", "start_pos": 25, "end_pos": 28, "type": "TASK", "confidence": 0.957726001739502}, {"text": "similarity measure", "start_pos": 105, "end_pos": 123, "type": "METRIC", "confidence": 0.8566343188285828}]}, {"text": "The individual systems are combined in Section 6, and we close with our conclusions in Section 7.", "labels": [], "entities": []}], "datasetContent": [{"text": "We evaluated the lemmatizers against the lemmas found in the S\uf765\uf76e\uf773\uf765\uf776\uf761\uf76c-3 gold standard.", "labels": [], "entities": [{"text": "S\uf765\uf76e\uf773\uf765\uf776\uf761\uf76c-3 gold standard", "start_pos": 61, "end_pos": 85, "type": "DATASET", "confidence": 0.6620531201362609}]}, {"text": "Even the lowest performing system improved accuracy by 31.74% over the baseline, which baseline simply equates the given token with the lemma.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 43, "end_pos": 51, "type": "METRIC", "confidence": 0.9994316697120667}]}, {"text": "Table 2 shows the results of evaluating the lemmatizers against the EAW key.", "labels": [], "entities": [{"text": "EAW key", "start_pos": 68, "end_pos": 75, "type": "DATASET", "confidence": 0.8563647270202637}]}, {"text": "While the simple voting system performed better than any of the individual lemmatizers, hyphenated words proved problematic for all of the systems.", "labels": [], "entities": []}, {"text": "Some hyphenated words in the test set remained hyphenated in the gold standard, and some others were separated.", "labels": [], "entities": [{"text": "gold standard", "start_pos": 65, "end_pos": 78, "type": "DATASET", "confidence": 0.8330408036708832}]}, {"text": "However, evaluation results show that splitting hyphenated words increases lemmatizing accuracy by 0.9% .", "labels": [], "entities": [{"text": "accuracy", "start_pos": 87, "end_pos": 95, "type": "METRIC", "confidence": 0.9724550247192383}]}], "tableCaptions": [{"text": " Table 1: Refining the MFS baseline with predominant  sense", "labels": [], "entities": [{"text": "Refining", "start_pos": 10, "end_pos": 18, "type": "TASK", "confidence": 0.9809772372245789}, {"text": "MFS", "start_pos": 23, "end_pos": 26, "type": "TASK", "confidence": 0.7695594429969788}]}, {"text": " Table 2: Accuracy of several lemmatizers on <head>  words of EAW task.", "labels": [], "entities": [{"text": "Accuracy", "start_pos": 10, "end_pos": 18, "type": "METRIC", "confidence": 0.9946666955947876}]}]}