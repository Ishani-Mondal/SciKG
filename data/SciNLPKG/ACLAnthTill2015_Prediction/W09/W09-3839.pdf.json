{"title": [{"text": "A generative re-ranking model for dependency parsing", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 34, "end_pos": 52, "type": "TASK", "confidence": 0.8235630393028259}]}], "abstractContent": [{"text": "We propose a framework for dependency parsing based on a combination of dis-criminative and generative models.", "labels": [], "entities": [{"text": "dependency parsing", "start_pos": 27, "end_pos": 45, "type": "TASK", "confidence": 0.8892077207565308}]}, {"text": "We use a discriminative model to obtain a k-best list of candidate parses, and subsequently rerank those candidates using a generative model.", "labels": [], "entities": []}, {"text": "We show how this approach allows us to evaluate a variety of generative models, without needing different parser implementations.", "labels": [], "entities": []}, {"text": "Moreover, we present empirical results that show a small improvement over state-of-the-art dependency parsing of English sentences.", "labels": [], "entities": []}], "introductionContent": [{"text": "Probabilistic generative dependency models define probability distributions overall valid dependency structures, and thus provide a useful intermediate representation that can be used for many NLP tasks including parsing and language modeling.", "labels": [], "entities": [{"text": "parsing", "start_pos": 213, "end_pos": 220, "type": "TASK", "confidence": 0.9631138443946838}, {"text": "language modeling", "start_pos": 225, "end_pos": 242, "type": "TASK", "confidence": 0.7069692611694336}]}, {"text": "In recent evaluations of supervised dependency parsing, however, generative approaches are consistently outperformed by discriminative models (), which treat the task of assigning the correct structure to a given sentence as a classification task.", "labels": [], "entities": [{"text": "supervised dependency parsing", "start_pos": 25, "end_pos": 54, "type": "TASK", "confidence": 0.6287408570448557}]}, {"text": "In this category we include both transition based) and graph based parsers.", "labels": [], "entities": []}, {"text": "In this paper, we explore a reranking approach that combines a generative and a discrimative model and tries to retain the strengths of both.", "labels": [], "entities": []}, {"text": "The idea of combining these two types of models through re-ranking is not new, although it has been mostly explored in constituency parsing).", "labels": [], "entities": [{"text": "constituency parsing", "start_pos": 119, "end_pos": 139, "type": "TASK", "confidence": 0.8234245479106903}]}, {"text": "This earlier work, however, used the generative model in the first step, and trained the discriminative model over its k-best candidates.", "labels": [], "entities": [{"text": "generative", "start_pos": 37, "end_pos": 47, "type": "TASK", "confidence": 0.9698291420936584}]}, {"text": "In this paper we reverse the usual order of the two models, by employing a generative model to rescore the k-best candidates provided by a discriminative model.", "labels": [], "entities": []}, {"text": "Moreover, the generative model of the second phase uses frequency counts from the training set but is not trained on the k-best parses of the discriminative model.", "labels": [], "entities": []}, {"text": "The main motivation for our approach is that it allows for efficiently evaluating many generative models, differing from one another on (i) the choice of the linguistic units that are generated (words, pairs of words, word graphs), (ii) the generation process (Markov process, top-down, bottom-up), and (iii) the features that are considered to build the event space (postags/words, distance).", "labels": [], "entities": []}, {"text": "Although efficient algorithms exist to calculate parse forests, each choice gives rise to different parser instantiations.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": []}