{"title": [{"text": "Speech Retrieval in Unknown Languages: a Pilot Study *", "labels": [], "entities": [{"text": "Speech Retrieval in Unknown Languages", "start_pos": 0, "end_pos": 37, "type": "TASK", "confidence": 0.8630336284637451}]}], "abstractContent": [{"text": "Most cross-lingual speech retrieval assumes intensive knowledge about all involved languages.", "labels": [], "entities": [{"text": "cross-lingual speech retrieval", "start_pos": 5, "end_pos": 35, "type": "TASK", "confidence": 0.7186042269070944}]}, {"text": "However, such resource may not exist for some less popular languages.", "labels": [], "entities": []}, {"text": "Some applications call for speech retrieval in unknown languages.", "labels": [], "entities": [{"text": "speech retrieval", "start_pos": 27, "end_pos": 43, "type": "TASK", "confidence": 0.778886616230011}]}, {"text": "In this work, we leverage on a quasi-language-independent subword recognizer trained on multiple languages, to obtain an abstracted representation of speech data in an unknown language.", "labels": [], "entities": []}, {"text": "Language-independent query expansion is achieved either by allowing a wide lattice output for an audio query, or by taking advantage of distinctive features in speech articulation to propose subwords most similar to the given sub-words in a query.", "labels": [], "entities": [{"text": "Language-independent query expansion", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.5645255148410797}]}, {"text": "We propose using a retrieval model based on finite state machines for fuzzy matching of speech sound patterns, and further for speech retrieval.", "labels": [], "entities": [{"text": "speech retrieval", "start_pos": 127, "end_pos": 143, "type": "TASK", "confidence": 0.8167797923088074}]}, {"text": "A pilot study of speech retrieval in unknown languages is presented, using English, Spanish and Russian as training languages, and Croatian as the unknown target language.", "labels": [], "entities": [{"text": "speech retrieval", "start_pos": 17, "end_pos": 33, "type": "TASK", "confidence": 0.7557338178157806}]}], "introductionContent": [{"text": "Dramatic increase in recorded speech media calls for efficient retrieval of audio files.", "labels": [], "entities": []}, {"text": "Accessing speech media of a foreign language is a particularly important and challenging task, often referred to as crosslingual speech retrieval or cross-lingual spoken document retrieval.", "labels": [], "entities": [{"text": "crosslingual speech retrieval", "start_pos": 116, "end_pos": 145, "type": "TASK", "confidence": 0.6527766684691111}, {"text": "cross-lingual spoken document retrieval", "start_pos": 149, "end_pos": 188, "type": "TASK", "confidence": 0.6319696754217148}]}, {"text": "* This research is funded by NSF grants 0534106 and 0703624.", "labels": [], "entities": []}, {"text": "The authors would like to thank Su-Youn Yoon for inspiring discussion.", "labels": [], "entities": []}, {"text": "# The student authors contribute equally.", "labels": [], "entities": []}, {"text": "Previous work on cross-lingual speech retrieval mostly leverages on intensive knowledge about all the languages involved.", "labels": [], "entities": [{"text": "cross-lingual speech retrieval", "start_pos": 17, "end_pos": 47, "type": "TASK", "confidence": 0.7319629788398743}]}, {"text": "Most reported work investigates retrieval in a target language, in response to audio or text queries given in a different source language (.", "labels": [], "entities": []}, {"text": "Usually, the speech media in the target language, and the audio queries in the source language, are converted to speech recognition transcripts using large-vocabulary automatic speech recognizers (LVASR) trained for the target language and the source language respectively.", "labels": [], "entities": []}, {"text": "The text queries, or transcribed audio queries, are translated to the target language.", "labels": [], "entities": []}, {"text": "Text retrieval techniques are applied to retrieve speech, by retrieving the corresponding LVASR transcription in the target language.", "labels": [], "entities": [{"text": "Text retrieval", "start_pos": 0, "end_pos": 14, "type": "TASK", "confidence": 0.7381890565156937}]}, {"text": "In such systems, a large-vocabulary speech recognizer trained on the target language is essential, which requires the existence of a dictionary and labeled acoustic training data in that language.", "labels": [], "entities": []}, {"text": "LVASR currently do not exist for most of the 6000 languages on Earth.", "labels": [], "entities": [{"text": "LVASR", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.7145112156867981}]}, {"text": "In some situations, knowledge about the target language is limited, and definitely not sufficient to enable training LVASR.", "labels": [], "entities": []}, {"text": "Imagine an audio database in a target language unknown to a user, who needs to retrieve spoken content relevant to some audible query in this unknown language.", "labels": [], "entities": []}, {"text": "For example, the user knows how the name \"Obama\" is pronounced in the target language, and wants to retrieve all spoken documents that contain the query word, from a database in this unknown language.", "labels": [], "entities": []}, {"text": "A linguist might find himself/herself in this scenario when he or she tries to collect a large number of utterances containing some particular phrases in an unknown language.", "labels": [], "entities": []}, {"text": "Similarly, an information analyst might wish to leverage on speech retrieval in unknown languages to organize critical information before engaging linguistic experts for finer analysis.", "labels": [], "entities": []}, {"text": "We refer to such retrieval tasks as speech retrieval in unknown languages, in which little knowledge about the target language is assumed.", "labels": [], "entities": [{"text": "speech retrieval", "start_pos": 36, "end_pos": 52, "type": "TASK", "confidence": 0.7288994491100311}]}, {"text": "A human linguist attempting to manually perform speech retrieval in an unknown language would necessarily map the perceived speech (both database and query) into some cognitive abstraction or schema, representing, perhaps, the phonetic distinctions that he or she has been trained to hear.", "labels": [], "entities": [{"text": "speech retrieval in an unknown language", "start_pos": 48, "end_pos": 87, "type": "TASK", "confidence": 0.8230707148710886}]}, {"text": "Matching and retrieval of speech would then be performed based on such an abstraction.", "labels": [], "entities": [{"text": "Matching", "start_pos": 0, "end_pos": 8, "type": "TASK", "confidence": 0.9430857300758362}]}, {"text": "Two cognitive processes, assimilation and accommodation, take place when human brains are to process new information (, such as speech in an unknown language.", "labels": [], "entities": []}, {"text": "In accommodation, the internal stored knowledge adapts to new information with which it is confronted.", "labels": [], "entities": []}, {"text": "In assimilation, the new information, e.g., speech in an unknown language, is mapped to previously stored information, e.g., subwords (phones) as defined by knowledge about the languages known to the listener.", "labels": [], "entities": []}, {"text": "This paper models speech retrieval in unknown languages using a machine learning model of phonetic assimilation.", "labels": [], "entities": [{"text": "speech retrieval", "start_pos": 18, "end_pos": 34, "type": "TASK", "confidence": 0.7227234989404678}]}, {"text": "A quasi-language-independent subword recognizer is trained to capture salient subwords and their acoustic distribution in multiple languages.", "labels": [], "entities": [{"text": "subword recognizer", "start_pos": 29, "end_pos": 47, "type": "TASK", "confidence": 0.7103964686393738}]}, {"text": "This recognizer is applied on an unknown language, therefore mapping segments of the unknown speech to subwords in the known languages.", "labels": [], "entities": []}, {"text": "Through this machine cognitive process, the database and queries in the unknown language are represented as sequences of quasi-languageindependent subwords.", "labels": [], "entities": []}, {"text": "Speech retrieval is performed based on such representation.", "labels": [], "entities": [{"text": "Speech retrieval", "start_pos": 0, "end_pos": 16, "type": "TASK", "confidence": 0.7853088676929474}]}, {"text": "illustrates that speech retrieval in an unknown language can be modeled as a special case of assimilation.", "labels": [], "entities": [{"text": "speech retrieval", "start_pos": 17, "end_pos": 33, "type": "TASK", "confidence": 0.7120878547430038}]}, {"text": "This task differs from the more widely studied known-language speech retrieval task, in that no linguistic knowledge of the target language is assumed.", "labels": [], "entities": [{"text": "known-language speech retrieval task", "start_pos": 47, "end_pos": 83, "type": "TASK", "confidence": 0.7042921334505081}]}, {"text": "We can only leverage on knowledge that can be applied by assimilation to the multiple known languages.", "labels": [], "entities": []}, {"text": "Therefore, this task is more like a crosslingual sound pattern retrieval task, leveraged on quasi-language-independent subwords, rather than a translated spoken word/phrase retrieval task using target language LVASR transcripts, as inmost cross-lingual speech retrieval systems.", "labels": [], "entities": [{"text": "crosslingual sound pattern retrieval", "start_pos": 36, "end_pos": 72, "type": "TASK", "confidence": 0.6126981228590012}, {"text": "translated spoken word/phrase retrieval", "start_pos": 143, "end_pos": 182, "type": "TASK", "confidence": 0.7739429175853729}, {"text": "cross-lingual speech retrieval", "start_pos": 239, "end_pos": 269, "type": "TASK", "confidence": 0.6946616371472677}]}, {"text": "The quasilanguage-independent subword recognizer is trained on speech data other than the target language, and therefore generates much noisier recognition results, owing to potential mismatch between acoustic distributions, lack of dictionary and lack of a word-level language model.", "labels": [], "entities": [{"text": "subword recognizer", "start_pos": 30, "end_pos": 48, "type": "TASK", "confidence": 0.7168578803539276}]}, {"text": "To manage the extra difficulty, we adopt a subword lattice representation to encode a wide hypothesis space of recognized speech in the target language.", "labels": [], "entities": []}, {"text": "Language-independent query expansion is achieved either by allowing a wide lattice output for an audio query, or by taking advantage of distinctive features in speech articulation to propose quasi-language-independent subwords most similar to the given subwords in a query.", "labels": [], "entities": [{"text": "Language-independent query expansion", "start_pos": 0, "end_pos": 36, "type": "TASK", "confidence": 0.5549527208010355}]}, {"text": "Finite state machines (FSM) constructed from the speech lattices are used to allow for fuzzy matching of speech sound patterns, and further for retrieval in unknown languages.", "labels": [], "entities": []}, {"text": "We carryout a pilot study of speech retrieval in unknown languages, using English, Spanish and Russian as training languages, and Croatian as the unknown target language.", "labels": [], "entities": [{"text": "speech retrieval", "start_pos": 29, "end_pos": 45, "type": "TASK", "confidence": 0.7861641943454742}]}, {"text": "To explain the effect of additional knowledge about the target language, we demonstrate the improvements in retrieval performance that result by incrementally making available subword sequence models and acoustic models for the target language.", "labels": [], "entities": []}], "datasetContent": [{"text": "The known language pool should cover as many language families as possible so that the derived subwords could better approximate language independence.", "labels": [], "entities": []}, {"text": "However, as a pilot study, this paper reports experiments using only languages within the IndoEuropean family.", "labels": [], "entities": []}, {"text": "summarizes the size of speech data from each language.", "labels": [], "entities": []}, {"text": "Croatian is used as the unknown target language, and the other three languages are the known languages used for deriving and training the quasi-language-independent subword models.", "labels": [], "entities": []}, {"text": "We extracted 80% of all speakers per language for training, and 10% as a development set.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Summary for data: language ID, total length,  number of speakers and speaking style for each language.", "labels": [], "entities": []}, {"text": " Table 2: Examples of quasi-language-independent sub- words, as clusters of source language IPAs.", "labels": [], "entities": []}, {"text": " Table 3: Performance of quasi-languange-independent  subword and IPA.", "labels": [], "entities": []}, {"text": " Table 4: Performance of subword recognition and speech  retrieval.", "labels": [], "entities": [{"text": "subword recognition", "start_pos": 25, "end_pos": 44, "type": "TASK", "confidence": 0.8343523740768433}, {"text": "speech  retrieval", "start_pos": 49, "end_pos": 66, "type": "TASK", "confidence": 0.7934431731700897}]}]}