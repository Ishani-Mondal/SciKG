{"title": [{"text": "Incremental Reference Resolution: The Task, Metrics for Evaluation, and a Bayesian Filtering Model that is Sensitive to Disfluencies", "labels": [], "entities": [{"text": "Incremental Reference Resolution", "start_pos": 0, "end_pos": 32, "type": "TASK", "confidence": 0.8905776143074036}]}], "abstractContent": [{"text": "In this paper we do two things: a) we discuss in general terms the task of incre-mental reference resolution (IRR), in particular resolution of exophoric reference, and specify metrics for measuring the performance of dialogue system components tackling this task, and b) we present a simple Bayesian filtering model of IRR that performs reasonably well just using words directly (no structure information and no hand-coded semantics): it picks the right referent out of 12 for around 50 % of real-world dialogue utterances in our test corpus.", "labels": [], "entities": [{"text": "incre-mental reference resolution (IRR)", "start_pos": 75, "end_pos": 114, "type": "TASK", "confidence": 0.8277025719483694}]}, {"text": "It is also able to learn to interpret not only words but also hesitations, just as humans have shown to do in similar situations , namely as markers of references to hard-to-describe entities.", "labels": [], "entities": []}], "introductionContent": [{"text": "Like other tasks involved in language comprehension, reference resolution-that is, the linking of natural language expressions to contextually given entities-is performed incrementally by human listeners.", "labels": [], "entities": [{"text": "reference resolution-that", "start_pos": 53, "end_pos": 78, "type": "TASK", "confidence": 0.7277963757514954}]}, {"text": "This was shown for example by in a famous experiment where addressees of utterances containing referring expressions made eye movements towards target objects very shortly after the end of the first word that unambiguously specified the referent, even if that wasn't the final word of the phrase.", "labels": [], "entities": []}, {"text": "In fact, as has been shown in later experiments, such disambiguating material doesn't even have to be lexical: under certain circumstances, a speaker's hesitating already seems to be understood as increasing the likelihood of subsequent reference to hard-to-describe entities.", "labels": [], "entities": []}, {"text": "Recently, efforts have begun to build dialogue systems that make use of incremental processing as well.", "labels": [], "entities": []}, {"text": "These efforts have so far focused on aspects other than resolution of references (() deals with the interaction of reference and parsing).", "labels": [], "entities": [{"text": "resolution of references", "start_pos": 56, "end_pos": 80, "type": "TASK", "confidence": 0.8676601052284241}]}, {"text": "In this paper, we discuss in general terms the task of incremental reference resolution (IRR) and specify metrics for evaluating incremental components for this task.", "labels": [], "entities": [{"text": "incremental reference resolution (IRR)", "start_pos": 55, "end_pos": 93, "type": "TASK", "confidence": 0.7989296714464823}]}, {"text": "To make the discussion more concrete, we also describe a simple Bayesian filtering model of IRR in a domain with a small number of possible referents, and show that it performs better wrt.", "labels": [], "entities": []}, {"text": "our metrics if given information about hesitations-thus providing computational support for the rationality of including observables other than words into models of dialogue meaning.", "labels": [], "entities": []}, {"text": "The remainder of the paper is structured as follows: We discuss the IRR task in Section 2, and suitable evaluation metrics in Section 3.", "labels": [], "entities": [{"text": "IRR task", "start_pos": 68, "end_pos": 76, "type": "TASK", "confidence": 0.8732418715953827}]}, {"text": "In Section 4 we describe and analyse the data for which we present results with our Bayesian model for IRR in Section 5.", "labels": [], "entities": [{"text": "IRR", "start_pos": 103, "end_pos": 106, "type": "TASK", "confidence": 0.8884125351905823}]}], "datasetContent": [{"text": "In previous work, we have discussed metrics for evaluating the performance of incremental speech recognition (.", "labels": [], "entities": [{"text": "speech recognition", "start_pos": 90, "end_pos": 108, "type": "TASK", "confidence": 0.7118978053331375}]}, {"text": "There, our metrics could rely on time-aligned gold-standard information against which the incremental results could be measured.", "labels": [], "entities": []}, {"text": "For the reasons discussed in the previous section, we do not assume that we have such temporally-aligned information for evaluating IRR.", "labels": [], "entities": [{"text": "IRR", "start_pos": 132, "end_pos": 135, "type": "TASK", "confidence": 0.9055776000022888}]}, {"text": "Our measures described here simply assume that there is one intention behind the referring utterances (namely to identify a certain entity), and that this intention is therefrom the beginning of the utterance and stays constant.", "labels": [], "entities": []}, {"text": "2 This is not to be understood as the claim that it is reasonable to expect an IRR component to pick out a referent even if the only part of the utterance that has already been processed for example is \"now take the\"-it just facilitates the \"earlier is better\" ranking discussed above.", "labels": [], "entities": []}, {"text": "We use two kinds of metrics for IRR: positional metrics, which measure when (which percentage into the utterance) a certain event happens, and edit metrics which capture the \"jumpiness\" of the decision process (how often the component changes its mind during an utterance).", "labels": [], "entities": [{"text": "IRR", "start_pos": 32, "end_pos": 35, "type": "TASK", "confidence": 0.9878231287002563}]}, {"text": "shows a constructed example that il- We leave open here what \"as early as possible\" meansa well-trained model might be able to resolve a reference before the speaker even deems that possible, and hence appear to do unnatural (or supernatural?)", "labels": [], "entities": []}, {"text": "Conversely, frequent changes of opinion might be something that human listeners would exhibit as well (e. g. in their gaze direction).", "labels": [], "entities": []}, {"text": "We abstract away from these finer details in our heuristic.", "labels": [], "entities": []}, {"text": "2 Note that our metrics would also work for corpora where the correct point-of-identification is annotated; this would simply move the reference point from the beginning of the utterance to that point.", "labels": [], "entities": []}, {"text": "describe an annotation effort in a simpler domain where entities can easily be described which would make such information available.", "labels": [], "entities": []}, {"text": "We assume that reference is to an object that is internally represented by the letter F.", "labels": [], "entities": []}, {"text": "The example shows two models, no-sil and sil (what exactly they are doesn't matter for now).", "labels": [], "entities": []}, {"text": "The former model guesses that reference is to object X already after the first word, and stays with this opinion until it encounters the final word, when it chooses F as most likely referent.", "labels": [], "entities": []}, {"text": "(Why the decision for the items sil is \"-\" will be explained below; here this can be read as \"repetition of previous decision\".)", "labels": [], "entities": [{"text": "repetition", "start_pos": 94, "end_pos": 104, "type": "METRIC", "confidence": 0.9467943906784058}]}, {"text": "The other model changes its mind more often, but also is correct for the first time earlier and stays correct earlier.", "labels": [], "entities": []}, {"text": "Our metrics make this observation more precise: \u2022 average fc (first correct): how deep into the utterance do we make the first correct guess?", "labels": [], "entities": [{"text": "average fc (first correct)", "start_pos": 50, "end_pos": 76, "type": "METRIC", "confidence": 0.8547432919343313}]}, {"text": "(If the decision component delivers n-best lists instead of single guesses, \"correct\" means here and below \"is member of n-best list\".)", "labels": [], "entities": []}, {"text": "E. g., if the referent is recognised only after the final word of the expression, the score for this metric would be 1.", "labels": [], "entities": []}, {"text": "In our example it is 2/5 for the sil-model and 1 for the non-sil model.", "labels": [], "entities": []}, {"text": "\u2022 fc applicable: since the previous measure can only be specified for cases where the correct referent has been found, we also specify for how many utterances this is the case.", "labels": [], "entities": []}, {"text": "\u2022 average ff (first final): how deep into the utterance do we make the correct guess and don't subsequently change our mind?", "labels": [], "entities": []}, {"text": "This would be 4/5 for the sil-model in our example and 1 for the no-silmodel.", "labels": [], "entities": []}, {"text": "\u2022 ff applicable: again, the previous measure can only be given where the final guess of the component is correct, so we also need to specify how often this is the case.", "labels": [], "entities": []}, {"text": "Note that whenever ff is applicable, fc is applicable as well, so ff applicable\u2264fc applicable.", "labels": [], "entities": []}, {"text": "\u2022 ed-utt (mean edits per utterance): an IRR module may still change its mind even after it has already made a correct guess.", "labels": [], "entities": []}, {"text": "This metric measures how often the module changes its mind before it comes back to the right guess (if at all).", "labels": [], "entities": []}, {"text": "Since such decision-revisions (edits) maybe costly for later modules, which possibly need to retract their own hypotheses that they've built based on the output of this module, ideally this number should below.", "labels": [], "entities": []}, {"text": "In our example the number of edits between fc and ff is 2 for the sil-model and 0 for the non-sil model (because here fc and ff are at the same position).", "labels": [], "entities": []}, {"text": "\u2022 eo (edit overhead): ratio unnecessary edits / necessary edits.", "labels": [], "entities": [{"text": "edit overhead)", "start_pos": 6, "end_pos": 20, "type": "METRIC", "confidence": 0.8473116358121237}]}, {"text": "(In the ideal case, there is exactly one edit, from \"no decision\" to the correct guess.)", "labels": [], "entities": []}, {"text": "\u2022 correctness: how often the model guesses correctly.", "labels": [], "entities": [{"text": "correctness", "start_pos": 2, "end_pos": 13, "type": "METRIC", "confidence": 0.9871756434440613}]}, {"text": "This is 3/5 for the sil-model in the example and 1/5 for the non-sil-model.", "labels": [], "entities": []}, {"text": "\u2022 sil-correctness: how often the model guesses correctly during hesitations.", "labels": [], "entities": []}, {"text": "The correctness measure applied only to certain data-points; we use this to investigate whether informing the model about hesitations is helpful.", "labels": [], "entities": []}, {"text": "\u2022 adjusted error: some of our IRR models can return \"undecided\" as reply.", "labels": [], "entities": [{"text": "adjusted error", "start_pos": 2, "end_pos": 16, "type": "METRIC", "confidence": 0.9377778172492981}]}, {"text": "The correctness measures defined above would punish this in the same way as a wrong guess.", "labels": [], "entities": []}, {"text": "The adjusted error measure implements the idea that undecidedness is better than a wrong guess, at least early in the utterance.", "labels": [], "entities": [{"text": "adjusted error measure", "start_pos": 4, "end_pos": 26, "type": "METRIC", "confidence": 0.7459912896156311}]}, {"text": "More precisely, it's defined to be 0 if the guess is correct, pos / pos max if the reply is \"undecided\" (with pos denoting the position in the utterance), and 1 if the guess is incorrect.", "labels": [], "entities": []}, {"text": "That way uncertainty is not punished in the beginning of the utterance and counted like an error towards its end.", "labels": [], "entities": []}, {"text": "Note that these metrics characterise different aspects of the performance of a model.", "labels": [], "entities": []}, {"text": "In practical cases, they may not be independent from each other, and a system designer will have to decide which one to optimize.", "labels": [], "entities": []}, {"text": "If it is helpful to be informed about a likely referent early, for example to prepare a reaction, and is not terribly costly to later have to revise hypotheses, then a low first correct maybe the target.", "labels": [], "entities": []}, {"text": "If hypothesis revisions are costly, then a low edit overhead maybe preferred over a low first correct.", "labels": [], "entities": [{"text": "hypothesis revisions", "start_pos": 3, "end_pos": 23, "type": "TASK", "confidence": 0.6997268497943878}]}, {"text": "(first final and ff applicable, however, are parameters that are useful for global optimisation.): The Twelve Pentomino Pieces with their canonical names (which were not known to the dialogue participants).", "labels": [], "entities": []}, {"text": "The pieces used in the dialogues all had the same colour.", "labels": [], "entities": []}, {"text": "In the remaining sections, we describe a probabilistic model of IRR that we have implemented, and evaluate it in terms of these metrics.", "labels": [], "entities": [{"text": "IRR", "start_pos": 64, "end_pos": 67, "type": "TASK", "confidence": 0.9458954930305481}]}, {"text": "We begin with describing the data from which we learnt our model.", "labels": [], "entities": []}, {"text": "All experiments were performed with 10-fold cross-validation.", "labels": [], "entities": []}, {"text": "We always ran both versions, the one that showed silences to the model and the one that didn't.", "labels": [], "entities": []}, {"text": "We tested various combinations of language model parameters and deciders, of which the best-performing ones are discussed in the next section.", "labels": [], "entities": []}, {"text": "shows the results for the different decision methods and for models where silences are included as observations and where they aren't, and, as a baseline, the result fora resolver that makes a random decision after each observation.", "labels": [], "entities": []}], "tableCaptions": []}