{"title": [{"text": "Proceedings of CLIAWS3, Third International", "labels": [], "entities": [{"text": "CLIAWS3", "start_pos": 15, "end_pos": 22, "type": "DATASET", "confidence": 0.8626824617385864}]}], "abstractContent": [{"text": "Part of Speech (POS) tagging and Named Entity (NE) tagging have become important components of effective text analysis.", "labels": [], "entities": [{"text": "Speech (POS) tagging", "start_pos": 8, "end_pos": 28, "type": "TASK", "confidence": 0.7565186858177185}, {"text": "Named Entity (NE) tagging", "start_pos": 33, "end_pos": 58, "type": "TASK", "confidence": 0.6702009638150533}, {"text": "text analysis", "start_pos": 105, "end_pos": 118, "type": "TASK", "confidence": 0.7366560995578766}]}, {"text": "In this paper, we propose a bootstrapped model that involves four levels of text processing for Ur-du.", "labels": [], "entities": []}, {"text": "We show that increasing the training data for POS learning by applying bootstrapping techniques improves NE tagging results.", "labels": [], "entities": [{"text": "POS learning", "start_pos": 46, "end_pos": 58, "type": "TASK", "confidence": 0.926188588142395}, {"text": "NE tagging", "start_pos": 105, "end_pos": 115, "type": "TASK", "confidence": 0.9630917608737946}]}, {"text": "Our model overcomes the limitation imposed by the availability of limited ground truth data required for training a learning model.", "labels": [], "entities": []}, {"text": "Both our POS tagging and NE tagging models are based on the Conditional Random Field (CRF) learning approach.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 9, "end_pos": 20, "type": "TASK", "confidence": 0.6990139782428741}, {"text": "NE tagging", "start_pos": 25, "end_pos": 35, "type": "TASK", "confidence": 0.8129083812236786}]}, {"text": "To further enhance the performance, grammar rules and lexicon lookups are applied on the final output to correct any spurious tag assignments.", "labels": [], "entities": []}, {"text": "We also propose a model for word boundary segmen-tation where a bigram HMM model is trained for character transitions among all positions in each word.", "labels": [], "entities": []}, {"text": "The generated words are further processed using a probabilistic language model.", "labels": [], "entities": []}, {"text": "All models use a hybrid approach that combines statistical models with hand crafted grammar rules.", "labels": [], "entities": []}], "introductionContent": [{"text": "The work here is motivated by a desire to understand human sentiment and social behavior through analysis of verbal communication.", "labels": [], "entities": []}, {"text": "Newspapers reflect the collective sentiments and emotions of the people and in turn the society to which they cater to.", "labels": [], "entities": []}, {"text": "Not only do they portray an event that has taken place as is, but they also reveal details about the intensity of fear, imagination, happiness and other emotions that people express in relation to that event.", "labels": [], "entities": []}, {"text": "Newspaper write ups, when analyzed over these factors -emotions, reactions and behavior -can give a broader perspective on the culture, beliefs and the extent to which the people in the region are tolerant towards other religions.", "labels": [], "entities": []}, {"text": "Our final goal is to automate this kind of behavioral analysis on newspaper articles for the Urdu language.", "labels": [], "entities": []}, {"text": "Annotated corpus that tag six basic human emotions, \"happy\", \"fear\", \"sad\", \"surprise\", \"anger\" and \"disgust\", based on the code book developed using the MPQA standards as guideline, is currently being developed.", "labels": [], "entities": [{"text": "MPQA standards", "start_pos": 154, "end_pos": 168, "type": "DATASET", "confidence": 0.9494786560535431}]}, {"text": "Articles from two leading Urdu newswires, BBC Urdu 1 and Jung Daily 2 form our corpus.", "labels": [], "entities": [{"text": "BBC Urdu 1", "start_pos": 42, "end_pos": 52, "type": "DATASET", "confidence": 0.9564633766810099}, {"text": "Jung Daily 2", "start_pos": 57, "end_pos": 69, "type": "DATASET", "confidence": 0.9487933119138082}]}, {"text": "In order to achieve our goal, it was required to generate the basic tools needed for efficient text analysis.", "labels": [], "entities": [{"text": "text analysis", "start_pos": 95, "end_pos": 108, "type": "TASK", "confidence": 0.8013714551925659}]}, {"text": "This includes NE tagging and its precursor, POS tagging.", "labels": [], "entities": [{"text": "NE tagging", "start_pos": 14, "end_pos": 24, "type": "TASK", "confidence": 0.8265546262264252}, {"text": "POS tagging", "start_pos": 44, "end_pos": 55, "type": "TASK", "confidence": 0.7063407897949219}]}, {"text": "However, Urdu, despite being spoken by over 100 million people,) is still a less privileged language when it comes to the availability of resources on the internet.", "labels": [], "entities": []}, {"text": "Developing tools fora language with limited resources is a challenge, but necessary, as the volume of Urdu text on the internet is rising.", "labels": [], "entities": []}, {"text": "shows that Urdu has now gained importance on the web, making it the right time to tackle these issues.", "labels": [], "entities": []}, {"text": "It is useful to first examine some basic properties of Urdu and how they affect the cascade of NLP steps in text analysis.", "labels": [], "entities": [{"text": "text analysis", "start_pos": 108, "end_pos": 121, "type": "TASK", "confidence": 0.7443426549434662}]}, {"text": "Urdu has the nastaleeq and nasq style of writing that is similar to Arabic and flows from right to left).", "labels": [], "entities": []}, {"text": "It also adopts some of its vocabulary from Arabic.", "labels": [], "entities": []}, {"text": "However, the grammar and semantics of the language is similar to Hindi and this makes it very different from Arabic.", "labels": [], "entities": []}, {"text": "For effective text analysis, a thorough syntactic and semantic understanding of the language is required.", "labels": [], "entities": [{"text": "text analysis", "start_pos": 14, "end_pos": 27, "type": "TASK", "confidence": 0.7236655652523041}]}, {"text": "Detailed grammatical analysis provided by and can be used for this purpose.", "labels": [], "entities": []}, {"text": "The first step in the information retrieval pipeline is tokenization.", "labels": [], "entities": [{"text": "information retrieval pipeline", "start_pos": 22, "end_pos": 52, "type": "TASK", "confidence": 0.8808364868164062}, {"text": "tokenization", "start_pos": 56, "end_pos": 68, "type": "TASK", "confidence": 0.9715975522994995}]}, {"text": "Unlike English, where the word delimiter is mostly a space, Urdu is more complex.", "labels": [], "entities": []}, {"text": "There are space insertion as well as space deletion problems.", "labels": [], "entities": [{"text": "space insertion", "start_pos": 10, "end_pos": 25, "type": "TASK", "confidence": 0.7250504195690155}]}, {"text": "This makes tokenization a difficult task.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 11, "end_pos": 23, "type": "TASK", "confidence": 0.9855443835258484}]}, {"text": "The word segmentation model that we propose here combines the statistical approach that considers bigram transition of characters based on their positions in a word and morphological rules with lexicon lookups.", "labels": [], "entities": [{"text": "word segmentation", "start_pos": 4, "end_pos": 21, "type": "TASK", "confidence": 0.7652884721755981}]}, {"text": "POS tagging comes next in the NLP text analysis pipeline.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 0, "end_pos": 11, "type": "TASK", "confidence": 0.697187528014183}, {"text": "NLP text analysis pipeline", "start_pos": 30, "end_pos": 56, "type": "TASK", "confidence": 0.7295979559421539}]}, {"text": "The accuracy of the tagging model varies, depending on the tagsets used and the domain of the ground truth data.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 4, "end_pos": 12, "type": "METRIC", "confidence": 0.999500036239624}]}, {"text": "There are two main tagsets designed for Urdu, the CRULP tagset 3 and the U1-tagset).", "labels": [], "entities": [{"text": "CRULP tagset 3", "start_pos": 50, "end_pos": 64, "type": "DATASET", "confidence": 0.9044414560000101}]}, {"text": "The U1-tagset, released as apart of EMILLE 4 corpus, is based on the EAGLES standards (.", "labels": [], "entities": [{"text": "EMILLE 4 corpus", "start_pos": 36, "end_pos": 51, "type": "DATASET", "confidence": 0.9469352761904398}, {"text": "EAGLES standards", "start_pos": 69, "end_pos": 85, "type": "DATASET", "confidence": 0.7260401099920273}]}, {"text": "We decided to use the standards proposed by CRULP for the following reasons.", "labels": [], "entities": [{"text": "CRULP", "start_pos": 44, "end_pos": 49, "type": "DATASET", "confidence": 0.9763929843902588}]}, {"text": "1. The tagset, though not as detailed as the one proposed in U1-tagset, covers all the basic requirements needed to achieve our final goal.", "labels": [], "entities": []}, {"text": "2. The tagged corpus provided by CRULP is newswire material, similar to our final corpus.", "labels": [], "entities": [{"text": "CRULP", "start_pos": 33, "end_pos": 38, "type": "DATASET", "confidence": 0.9322202205657959}]}, {"text": "A person, when asked to identify an NE tagged word in a sentence would typically try to first find the word associated with a proper noun or a noun, and then assign a suitable NE tag based on the context.", "labels": [], "entities": []}, {"text": "A similar approach is used in our model, where the learning happens on the data that is POS tagged as well as NE tagged.", "labels": [], "entities": []}, {"text": "Features are learnt from the POS tags as well as the NE tags.", "labels": [], "entities": [{"text": "POS tags", "start_pos": 29, "end_pos": 37, "type": "DATASET", "confidence": 0.9071270227432251}, {"text": "NE tags", "start_pos": 53, "end_pos": 60, "type": "DATASET", "confidence": 0.8126373291015625}]}, {"text": "The final output of our complete model returns the POS tags and NE tags associated with each word.", "labels": [], "entities": []}, {"text": "Since we have limited data for training both the POS as well as the NE models, we propose a technique called bootstrapping that helps in maximizing the learning for efficient tagging.", "labels": [], "entities": []}, {"text": "The remainder of the paper is organized as follows.", "labels": [], "entities": []}, {"text": "Section 2 discusses the resources assimilated for the work followed by tokenization and word segmentation in Section 3.", "labels": [], "entities": [{"text": "tokenization", "start_pos": 71, "end_pos": 83, "type": "TASK", "confidence": 0.961542010307312}, {"text": "word segmentation", "start_pos": 88, "end_pos": 105, "type": "TASK", "confidence": 0.6965443342924118}]}, {"text": "Section 4 gives a detailed explanation of our model starting with a brief introduction of the learning approach used.", "labels": [], "entities": []}, {"text": "Rules used for POS tagging and NE tagging are mentioned in subsections of Section 4.", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 15, "end_pos": 26, "type": "TASK", "confidence": 0.7927729785442352}, {"text": "NE tagging", "start_pos": 31, "end_pos": 41, "type": "TASK", "confidence": 0.927310436964035}]}, {"text": "Section 5 presents the results and Section 6 concludes the paper.", "labels": [], "entities": []}, {"text": "In each section, wherever relevant, previous work and drawbacks are presented.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1. NE tagging results for the two stage and four  stage models", "labels": [], "entities": [{"text": "NE tagging", "start_pos": 10, "end_pos": 20, "type": "TASK", "confidence": 0.6810415238142014}]}, {"text": " Table 2. POS tagging results for the two stage (POS A )  and four stage (POS B ) models", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.784848153591156}]}, {"text": " Table 3. POS tagging results for stages POS A and POS B", "labels": [], "entities": [{"text": "POS tagging", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.8011544048786163}]}, {"text": " Table 4. NE tagging results after applying rules for test  results in Table 1", "labels": [], "entities": [{"text": "NE tagging", "start_pos": 10, "end_pos": 20, "type": "TASK", "confidence": 0.8062582314014435}]}]}