{"title": [], "abstractContent": [{"text": "This paper introduces a formal framework that presents a novel Interactive Predic-tive Parsing schema which can be operated by a user, tightly integrated into the system, to obtain error free trees.", "labels": [], "entities": []}, {"text": "This compares to the classical two-step schema of manually post-editing the erroneus constituents produced by the parsing system.", "labels": [], "entities": []}, {"text": "We have simulated interaction and calculated evalaution metrics, which established that an IPP system results in a high amount of effort reduction fora manual annotator compared to a two-step system.", "labels": [], "entities": []}], "introductionContent": [{"text": "The aim of parsing is to obtain the linguistic interpretation of sentences, that is, their underlying syntactic structure.", "labels": [], "entities": [{"text": "parsing", "start_pos": 11, "end_pos": 18, "type": "TASK", "confidence": 0.9730101823806763}]}, {"text": "This task is one of the fundamental pieces needed by a computer to unsderstand language as used by humans, and has many applications in Natural Language Processing ().", "labels": [], "entities": []}, {"text": "A wide array of parsing methods exist, including those based on Probabilistic Context-Free Grammars (PCFGs)..", "labels": [], "entities": []}, {"text": "The most impressive results are achieved by subtree reranking systems, as shown in the semisupervised method of (), or the forest reranking approximation of) in which packed parse forests (compact structures that contain many possible tree derivations) are used.", "labels": [], "entities": []}, {"text": "These state-of-the-art parsers provide trees of excelent quality.", "labels": [], "entities": []}, {"text": "However, perfect results are vir-tually never achieved.", "labels": [], "entities": []}, {"text": "If the need of one-hundredpercent error free trees arises, the supervision of a user that post-edits and corrects the errors is unavoidable.", "labels": [], "entities": []}, {"text": "Error free trees are needed in many tasks such as handwritten mathematical expressions recognition (), or creation of new gold standard treebanks).", "labels": [], "entities": [{"text": "mathematical expressions recognition", "start_pos": 62, "end_pos": 98, "type": "TASK", "confidence": 0.5925702353318533}]}, {"text": "For example, in the creation of the Penn Treebank grammar, a basic two-stage setup was employed: a rudimentary parsing system providad a skeletal syntactic representation, which then was manually corrected by human annotators.", "labels": [], "entities": [{"text": "Penn Treebank grammar", "start_pos": 36, "end_pos": 57, "type": "DATASET", "confidence": 0.9905957579612732}]}, {"text": "In this paper, we introduce anew formal framework that tightly integrates the user within the parsing system itself, rather than keeping him isolated from the automatic tools used in a classical two-step approach.", "labels": [], "entities": []}, {"text": "This approach introduces the user into the parsing system, and we will call it \"interactive predictive parsing\", or simply IPP.", "labels": [], "entities": [{"text": "predictive parsing", "start_pos": 92, "end_pos": 110, "type": "TASK", "confidence": 0.692577674984932}]}, {"text": "An IPP system is interactive because the user is in continuous contact with the parsing process, sending and receiving feedback.", "labels": [], "entities": [{"text": "parsing process", "start_pos": 80, "end_pos": 95, "type": "TASK", "confidence": 0.9006683230400085}]}, {"text": "An IPP system is also predictive because it reacts to the user corrections: it predicts and suggest new parse trees taking into account the new gold knowledge received from the user.", "labels": [], "entities": []}, {"text": "Interactive predictive methods have been studied and successfully used in fields like Automatic Text Recognition ( and Statistical Machine Translation () to ease the work of transcriptor and translators.", "labels": [], "entities": [{"text": "Interactive predictive", "start_pos": 0, "end_pos": 22, "type": "TASK", "confidence": 0.5754551589488983}, {"text": "Automatic Text Recognition", "start_pos": 86, "end_pos": 112, "type": "TASK", "confidence": 0.6153130829334259}, {"text": "Statistical Machine Translation", "start_pos": 119, "end_pos": 150, "type": "TASK", "confidence": 0.6986866593360901}]}, {"text": "Assessment of the amount of effort saved by the IPP system will be measured by automatically calculated metrics.", "labels": [], "entities": []}], "datasetContent": [{"text": "The objective of the experimentation presented here is to evaluate the amount of effort saved for the user using the IPP system, compared to the effort required to manually correct the trees without the use of an interactive system.", "labels": [], "entities": []}, {"text": "In this section, we define a standard automatic evaluation protocol, akin to the ones used in Computer-Aided Translation and Computer Aided Text Recognition.", "labels": [], "entities": [{"text": "Computer-Aided Translation", "start_pos": 94, "end_pos": 120, "type": "TASK", "confidence": 0.6690155267715454}, {"text": "Computer Aided Text Recognition", "start_pos": 125, "end_pos": 156, "type": "TASK", "confidence": 0.6175648421049118}]}, {"text": "In the absence of testing of an interactive system with real users, the gold reference trees were used to simulate system interaction by a human corrector.", "labels": [], "entities": []}, {"text": "In order to do this, the constituents in the proposed tree were automatically reviewed in a preorder manner 2 . In each step, the constituent in the proposed tree was compared to the corresponding one in the reference tree: if the constituent was equivalent no action was taken.", "labels": [], "entities": []}, {"text": "When one incorrect constituent was found in the proposed tree, it was replaced by the correct one from the reference tree.", "labels": [], "entities": []}, {"text": "This precise step simulated what a human supervisor would do, that is, to type the correct constituent in place of the erroneus one.", "labels": [], "entities": []}, {"text": "The system then performed the predictive step (i.e. recalculation of subtrees related to the corrected constituent).", "labels": [], "entities": []}, {"text": "We kept a correction count, which was incremented by one after each predictive step.", "labels": [], "entities": [{"text": "correction count", "start_pos": 10, "end_pos": 26, "type": "METRIC", "confidence": 0.982403576374054}]}, {"text": "For evaluation, first we report a metric representing the amount of human correcting work needed to obtain the gold tree in a classical two-step process (i.e. the number of operations needed to postedit the proposed tree in orther to obtain the gold 2 Interaction in this ordered manner guaranteed that the evaluation protocol only needed to modify the label A and the endpoint j of a given edge c A ij , while i remained valid given the modifications of previous constituents. one).", "labels": [], "entities": []}, {"text": "We then compare this value to a metric that measures the amount of effort needed to obtain the gold tree with the human interacting within the presented IPP system.", "labels": [], "entities": []}, {"text": "Parsing quality is generally assessed by the classical evaluation metrics, precission, recall and Fmeasure.", "labels": [], "entities": [{"text": "recall", "start_pos": 87, "end_pos": 93, "type": "METRIC", "confidence": 0.9995263814926147}, {"text": "Fmeasure", "start_pos": 98, "end_pos": 106, "type": "METRIC", "confidence": 0.9938493371009827}]}, {"text": "Finally, the relevant evaluation metric that assessed the IPP system performance represents the amount effort that the operator would have to spend using the system in order to obtain the gold tree, and is directly comparable to the TCER: \u2022 Tree Constituent Action Rate (TCAC): Number of constituent corrections performed using the IPP system to obtain the reference tree, divided by the total number of constituents in the reference tree.", "labels": [], "entities": [{"text": "TCER", "start_pos": 233, "end_pos": 237, "type": "METRIC", "confidence": 0.6093128323554993}, {"text": "Tree Constituent Action Rate (TCAC)", "start_pos": 241, "end_pos": 276, "type": "METRIC", "confidence": 0.7743765967232841}]}, {"text": "An IPP system was implemented over the classical CYK-Viterbi algorithm.", "labels": [], "entities": []}, {"text": "Experimentation was run over the Penn Tree bank: sections 2 to 21 were used to obtain a vanilla Penn Treebank Grammar; test set was the whole section 23.", "labels": [], "entities": [{"text": "Penn Tree bank", "start_pos": 33, "end_pos": 47, "type": "DATASET", "confidence": 0.9976425369580587}, {"text": "Penn Treebank Grammar", "start_pos": 96, "end_pos": 117, "type": "DATASET", "confidence": 0.9922681053479513}]}, {"text": "We obtained several binarized versions of the train grammar for use with the CYK.", "labels": [], "entities": [{"text": "CYK", "start_pos": 77, "end_pos": 80, "type": "DATASET", "confidence": 0.984000563621521}]}, {"text": "The Chomsky Normal Form (CNF) transformation method from the NLTK 4 was used to obtain several rightfactored binary grammars of different sizes . A basic schema was introduced for parsing sentences with out-of-vocabulary words: when an input word could not be derived by any of the preterminals in the vanilla treebank grammar, a very small probability for that word was uniformly added to all of the preterminals.", "labels": [], "entities": []}, {"text": "Results for the metrics discussed on section 3.1 for different markovizations of the train grammar can be seen in.", "labels": [], "entities": []}, {"text": "We observe that the percetage of corrections needed using the IPP system is much lower than the rate of needed corrections just post-editing the proposed trees: from 42% to 46% in effort reduction by the human supervisor.", "labels": [], "entities": []}, {"text": "These results clearly show that an interactive predictive system can relieve manual annotators of a lot of burden in their task.", "labels": [], "entities": []}, {"text": "Note that the presented experiments were done using parsing models that perform far from the latest F 1 results; their intention was to assess the utility of the IPP schema.", "labels": [], "entities": []}, {"text": "Expected relative reductions with IPP systems incorporating state-of-theart parsers would not be so large.: Results for the test set: F 1 and TCER for the baseline system; TCAC for the IPP system; relative reduction beteween TCER and TCAC.", "labels": [], "entities": [{"text": "F 1", "start_pos": 134, "end_pos": 137, "type": "METRIC", "confidence": 0.9889141321182251}, {"text": "TCER", "start_pos": 142, "end_pos": 146, "type": "METRIC", "confidence": 0.9125454425811768}, {"text": "TCAC", "start_pos": 172, "end_pos": 176, "type": "METRIC", "confidence": 0.9399000406265259}, {"text": "TCER", "start_pos": 225, "end_pos": 229, "type": "METRIC", "confidence": 0.8630107641220093}, {"text": "TCAC", "start_pos": 234, "end_pos": 238, "type": "METRIC", "confidence": 0.750270426273346}]}], "tableCaptions": [{"text": " Table 1: Results for the test set: F 1 and TCER  for the baseline system; TCAC for the IPP system;  relative reduction beteween TCER and TCAC.", "labels": [], "entities": [{"text": "F 1", "start_pos": 36, "end_pos": 39, "type": "METRIC", "confidence": 0.991396963596344}, {"text": "TCER", "start_pos": 44, "end_pos": 48, "type": "METRIC", "confidence": 0.9551941752433777}, {"text": "TCAC", "start_pos": 75, "end_pos": 79, "type": "METRIC", "confidence": 0.9900110363960266}, {"text": "TCER", "start_pos": 129, "end_pos": 133, "type": "METRIC", "confidence": 0.8722867369651794}, {"text": "TCAC", "start_pos": 138, "end_pos": 142, "type": "METRIC", "confidence": 0.7121857404708862}]}]}