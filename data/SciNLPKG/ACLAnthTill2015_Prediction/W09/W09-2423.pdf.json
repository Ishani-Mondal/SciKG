{"title": [{"text": "Automatic Recognition of Logical Relations for English, Chinese and Japanese in the GLARF Framework", "labels": [], "entities": [{"text": "GLARF Framework", "start_pos": 84, "end_pos": 99, "type": "DATASET", "confidence": 0.945081353187561}]}], "abstractContent": [{"text": "We present GLARF, a framework for representing three linguistic levels and systems for generating this representation.", "labels": [], "entities": []}, {"text": "We focus on a logical level, like LFG's F-structure, but compatible with Penn Treebanks.", "labels": [], "entities": [{"text": "LFG's F-structure", "start_pos": 34, "end_pos": 51, "type": "DATASET", "confidence": 0.8995170593261719}, {"text": "Penn Treebanks", "start_pos": 73, "end_pos": 87, "type": "DATASET", "confidence": 0.9945622384548187}]}, {"text": "While less fine-grained than typical semantic role labeling approaches , our logical structure has several advantages: (1) it includes all words in all sentences , regardless of part of speech or semantic domain; and (2) it is easier to produce accurately.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 37, "end_pos": 59, "type": "TASK", "confidence": 0.6864861845970154}]}, {"text": "Our systems achieve 90% for En-glish/Japanese News and 74.5% for Chinese News-these F-scores are nearly the same as those achieved for treebank-based parsing.", "labels": [], "entities": [{"text": "Chinese News-these", "start_pos": 65, "end_pos": 83, "type": "DATASET", "confidence": 0.8406543731689453}, {"text": "F-scores", "start_pos": 84, "end_pos": 92, "type": "METRIC", "confidence": 0.7880523800849915}]}], "introductionContent": [{"text": "For decades, computational linguists have paired a surface syntactic analysis with an analysis representing something \"deeper\".", "labels": [], "entities": []}, {"text": "The work of, and many others showed that one could use these deeper analyses to regularize differences between ways of expressing the same idea.", "labels": [], "entities": []}, {"text": "For statistical methods, these regularizations, in effect, reduce the number of significant differences between observable patterns in data and raise the frequency of each difference.", "labels": [], "entities": []}, {"text": "Patterns are thus easier to learn from training data and easier to recognize in test data, thus somewhat compensating for the spareness of data.", "labels": [], "entities": []}, {"text": "In addition, deeper analyses are often considered semantic in nature because conceptually, two expressions that share the same regularized form also share some aspects of meaning.", "labels": [], "entities": []}, {"text": "The specific details of this \"deep\" analysis have varied quite a bit, perhaps more than surface syntax.", "labels": [], "entities": []}, {"text": "In the 1970s and 1980s, Lexical Function Grammar's (LFG) way of dividing C-structure (surface) and F-structure (deep) led to parsers such as which produced these two levels, typically in two stages.", "labels": [], "entities": [{"text": "Lexical Function Grammar", "start_pos": 24, "end_pos": 48, "type": "TASK", "confidence": 0.7047032515207926}]}, {"text": "However, enthusiasm for these two-stage parsers was eclipsed by the advent of one stage parsers with much higher accuracy (about 90% vs about 60%), the now-popular treebank-based parsers including) and many others.", "labels": [], "entities": [{"text": "accuracy", "start_pos": 113, "end_pos": 121, "type": "METRIC", "confidence": 0.9982001781463623}]}, {"text": "Currently, many different \"deeper\" levels are being manually annotated and automatically transduced, typically using surface parsing and other processors as input.", "labels": [], "entities": []}, {"text": "One of the most popular, semantic role labels (annotation and transducers based on the annotation) characterize relations anchored by select predicate types like verbs ), nouns), discourse connectives () or those predicates that are part of particular semantic frames ().", "labels": [], "entities": []}, {"text": "The CONLL tasks for) has focused on unifying many of these individual efforts to produce a logical structure for multiple parts of speech and multiple languages.", "labels": [], "entities": []}, {"text": "Like the CONLL shared task, we link surface levels to logical levels for multiple languages.", "labels": [], "entities": []}, {"text": "However, there are several differences: (1) The logical structures produced automatically by our system can be expected to be more accurate than the comparable CONLL systems because our task involves predicting semantic roles with less fine-grained distinctions.", "labels": [], "entities": []}, {"text": "Our English and Japanese results were higher than the CONLL 2009 SRL systems.", "labels": [], "entities": [{"text": "CONLL 2009 SRL", "start_pos": 54, "end_pos": 68, "type": "DATASET", "confidence": 0.9031708836555481}]}, {"text": "Our English Fscores range from 76.3% (spoken) to 89.9% (News): the best CONLL 2009 English scores were 73.31% (Brown) and 85.63% (WSJ).", "labels": [], "entities": [{"text": "Fscores", "start_pos": 12, "end_pos": 19, "type": "METRIC", "confidence": 0.7912799715995789}, {"text": "News", "start_pos": 56, "end_pos": 60, "type": "DATASET", "confidence": 0.953603208065033}, {"text": "CONLL 2009 English scores", "start_pos": 72, "end_pos": 97, "type": "DATASET", "confidence": 0.8785629719495773}, {"text": "WSJ", "start_pos": 130, "end_pos": 133, "type": "DATASET", "confidence": 0.899389922618866}]}, {"text": "Our Japanese system scored 90.6%: the best CONLL 2009 Japanese score was 78.35%.", "labels": [], "entities": [{"text": "CONLL 2009 Japanese score", "start_pos": 43, "end_pos": 68, "type": "DATASET", "confidence": 0.8709644079208374}]}, {"text": "Our Chinese system 74.5%, 4 points lower than the best CONLL 2009 system (78.6%), probably due to our system's failings, rather than the complexity of the task; (2) Each of the languages in our system uses the same linguistic framework, using the same types of relations, same analyses of comparable constructions, etc.", "labels": [], "entities": [{"text": "CONLL 2009 system", "start_pos": 55, "end_pos": 72, "type": "DATASET", "confidence": 0.885421872138977}]}, {"text": "In one case, this required a conversion from a different framework to our own.", "labels": [], "entities": []}, {"text": "In contrast, the 2009 CONLL task puts several different frameworks into one compatible input format.", "labels": [], "entities": []}, {"text": "(3) The logical structures produced by our system typically connect all the words in the sentence.", "labels": [], "entities": []}, {"text": "While this is true for some of the CONLL 2009 languages, e.g., Czech, it is not true about all the languages.", "labels": [], "entities": [{"text": "CONLL 2009 languages", "start_pos": 35, "end_pos": 55, "type": "DATASET", "confidence": 0.9333486159642538}]}, {"text": "In particular, the CONLL 2009 English and Chinese logical structures only include noun and verb predicates.", "labels": [], "entities": [{"text": "CONLL 2009 English and Chinese logical structures", "start_pos": 19, "end_pos": 68, "type": "DATASET", "confidence": 0.9298471978732518}]}, {"text": "In this paper, we will describe the GLARF framework (Grammatical and Logical Representation Framework) and a system for producing GLARF output (.", "labels": [], "entities": []}, {"text": "GLARF provides a logical structure for English, Chinese and Japanese with an F-score that is within a few percentage points of the best parsing results for that language.", "labels": [], "entities": [{"text": "GLARF", "start_pos": 0, "end_pos": 5, "type": "DATASET", "confidence": 0.6632631421089172}, {"text": "F-score", "start_pos": 77, "end_pos": 84, "type": "METRIC", "confidence": 0.9985600113868713}]}, {"text": "Like LFG's (LFG) F-structure, our logical structure is less fine-grained than many of the popular semantic role labeling schemes, but also has two main advantages over these schemes: it is more reliable and it is more comprehensive in the sense that it covers all parts of speech and the resulting logical structure is a connected graph.", "labels": [], "entities": [{"text": "semantic role labeling", "start_pos": 98, "end_pos": 120, "type": "TASK", "confidence": 0.7169857819875082}]}, {"text": "Our approach has proved adequate for three genetically unrelated natural languages: English, Chinese and Japanese.", "labels": [], "entities": []}, {"text": "It is thus a good candidate for additional languages with accurate parsers.", "labels": [], "entities": []}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: English Aggregate Scores", "labels": [], "entities": [{"text": "English", "start_pos": 10, "end_pos": 17, "type": "DATASET", "confidence": 0.8536036610603333}, {"text": "Aggregate Scores", "start_pos": 18, "end_pos": 34, "type": "METRIC", "confidence": 0.915172278881073}]}, {"text": " Table 2: English Score per Sentence", "labels": [], "entities": [{"text": "English Score", "start_pos": 10, "end_pos": 23, "type": "DATASET", "confidence": 0.6527572274208069}, {"text": "Sentence", "start_pos": 28, "end_pos": 36, "type": "TASK", "confidence": 0.4410305321216583}]}, {"text": " Table 3: 53 Chinese Newswire Sentences: Aggregate and  Average Sentence Scores", "labels": [], "entities": [{"text": "Chinese Newswire", "start_pos": 13, "end_pos": 29, "type": "DATASET", "confidence": 0.8818728923797607}, {"text": "Aggregate", "start_pos": 41, "end_pos": 50, "type": "METRIC", "confidence": 0.9513702392578125}, {"text": "Average Sentence Scores", "start_pos": 56, "end_pos": 79, "type": "METRIC", "confidence": 0.8765408595403036}]}, {"text": " Table 4: 40 Japanese Sentences from JENAA Corpus:  Aggregate and Average Sentence Scores", "labels": [], "entities": [{"text": "Japanese Sentences", "start_pos": 13, "end_pos": 31, "type": "TASK", "confidence": 0.4780268669128418}, {"text": "JENAA Corpus", "start_pos": 37, "end_pos": 49, "type": "DATASET", "confidence": 0.7473002672195435}, {"text": "Aggregate", "start_pos": 52, "end_pos": 61, "type": "METRIC", "confidence": 0.9852516651153564}, {"text": "Average Sentence Scores", "start_pos": 66, "end_pos": 89, "type": "METRIC", "confidence": 0.8556594649950663}]}]}