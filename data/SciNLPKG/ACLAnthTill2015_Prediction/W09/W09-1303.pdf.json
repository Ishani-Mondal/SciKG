{"title": [{"text": "ONYX: A System for the Semantic Analysis of Clinical Text", "labels": [], "entities": [{"text": "ONYX", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8294757604598999}, {"text": "Semantic Analysis of Clinical Text", "start_pos": 23, "end_pos": 57, "type": "TASK", "confidence": 0.8503250002861023}]}], "abstractContent": [{"text": "This paper introduces ONYX, a sentence-level text analyzer that implements a number of innovative ideas in syntactic and semantic analysis.", "labels": [], "entities": [{"text": "ONYX", "start_pos": 22, "end_pos": 26, "type": "METRIC", "confidence": 0.4755488336086273}, {"text": "sentence-level text analyzer", "start_pos": 30, "end_pos": 58, "type": "TASK", "confidence": 0.6048202812671661}, {"text": "syntactic and semantic analysis", "start_pos": 107, "end_pos": 138, "type": "TASK", "confidence": 0.6394172087311745}]}, {"text": "ONYX is being developed as part of a project that seeks to translate spoken dental examinations directly into chartable findings.", "labels": [], "entities": [{"text": "ONYX", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9714038968086243}]}, {"text": "ONYX integrates syntax and semantics to a high degree.", "labels": [], "entities": [{"text": "ONYX", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.887984573841095}]}, {"text": "It interprets sentences using a combination of probabilistic classifiers, graphical unification, and semantically annotated grammar rules.", "labels": [], "entities": [{"text": "graphical unification", "start_pos": 74, "end_pos": 95, "type": "TASK", "confidence": 0.7500370442867279}]}, {"text": "In this preliminary evaluation, ONYX shows inter-annotator agreement scores with humans of 86% for assigning semantic types to relevant words, 80% for inferring relevant concepts from words, and 76% for identifying relations between concepts.", "labels": [], "entities": [{"text": "ONYX", "start_pos": 32, "end_pos": 36, "type": "DATASET", "confidence": 0.8007209300994873}]}], "introductionContent": [{"text": "This paper describes ONYX, a sentence-level medical language analyzer currently underdevelopment at the University of Pittsburgh.", "labels": [], "entities": [{"text": "ONYX", "start_pos": 21, "end_pos": 25, "type": "METRIC", "confidence": 0.6056065559387207}, {"text": "sentence-level medical language analyzer", "start_pos": 29, "end_pos": 69, "type": "TASK", "confidence": 0.5646120384335518}]}, {"text": "Since ONYX contains a number of innovative ideas at an early stage of development, the objective of this paper is to paint abroad picture of ONYX and to present preliminary evaluation results rather than analyzing any single aspect in detail.", "labels": [], "entities": [{"text": "ONYX", "start_pos": 6, "end_pos": 10, "type": "DATASET", "confidence": 0.9395022392272949}, {"text": "ONYX", "start_pos": 141, "end_pos": 145, "type": "DATASET", "confidence": 0.9542604684829712}]}, {"text": "ONYX is being developed as part of a project aimed at extracting information from spoken dental examinations.", "labels": [], "entities": [{"text": "ONYX", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9705979228019714}, {"text": "extracting information from spoken dental examinations", "start_pos": 54, "end_pos": 108, "type": "TASK", "confidence": 0.8593804637591044}]}, {"text": "Currently, dental findings must be charted after an exam is completed or maybe charted by an assistant who acts as a transcriptionist during the exam.", "labels": [], "entities": []}, {"text": "Our goal is to design a system capable of automatically extracting chartable findings directly from spoken exams, potentially also supporting automated decision support and quality control.", "labels": [], "entities": []}, {"text": "We are also developing tools to enable the system to be ported to other clinical domains and settings.", "labels": [], "entities": []}, {"text": "Extracting information from unedited speech transcriptions presents a number of challenges.", "labels": [], "entities": [{"text": "Extracting information from unedited speech transcriptions", "start_pos": 0, "end_pos": 58, "type": "TASK", "confidence": 0.8902514179547628}]}, {"text": "Sentences maybe fragmented or telegraphic, and much of the speech maybe irrelevant for our purposes.", "labels": [], "entities": []}, {"text": "The following example illustrates some of these difficulties: The relevant findings in this example are that tooth number one is missing and tooth number two has amalgam fillings on the occlusal and palatal surfaces.", "labels": [], "entities": []}, {"text": "Our ultimate challenge is to create a system that can recognize relevant sentences and perform competently in the face of the inherent ambiguity and noise commonly found in conversational speech.", "labels": [], "entities": []}, {"text": "ONYX does not yet address all of these challenges, although we have clear directions we are pursuing as described in the Future Work section of this paper.", "labels": [], "entities": [{"text": "ONYX", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.9702911972999573}]}, {"text": "Our goal in this paper is to describe the current state of ONYX and the innovations we feel will enable it to be adapted to complex NLP tasks in the future.", "labels": [], "entities": [{"text": "ONYX", "start_pos": 59, "end_pos": 63, "type": "DATASET", "confidence": 0.8583597540855408}]}], "datasetContent": [{"text": "We performed a preliminary evaluation of ONYX for the extraction of relevant dental concepts and relations on a set of twelve documents in our current training corpus.", "labels": [], "entities": [{"text": "ONYX", "start_pos": 41, "end_pos": 45, "type": "DATASET", "confidence": 0.4982832074165344}, {"text": "extraction of relevant dental concepts and relations", "start_pos": 54, "end_pos": 106, "type": "TASK", "confidence": 0.7703201345035008}]}, {"text": "Each document was independently annotated by three human annotators (authors LC, JI and HH), who used the ONYX training tool to fill in templates representing dental conditions, tooth locations and other relevant concepts, as well as to select the semantic relations linking those templates.", "labels": [], "entities": []}, {"text": "The annotators then reviewed disagreements and by consensus created a reference standard set of templates and relations.", "labels": [], "entities": []}, {"text": "Where the annotators did not have sufficient dental knowledge to reach an agreement they consulted dental clinicians.", "labels": [], "entities": []}, {"text": "To evaluate ONYX on the relatively small corpus of documents, we applied a leave-one-out approach: for each sentence in the reference standard, ONYX was trained using the templates from the remaining reference standard sentences.", "labels": [], "entities": [{"text": "ONYX", "start_pos": 12, "end_pos": 16, "type": "DATASET", "confidence": 0.7729901075363159}, {"text": "ONYX", "start_pos": 144, "end_pos": 148, "type": "DATASET", "confidence": 0.8888865113258362}]}, {"text": "ONYX was then applied to the target sentence, and the resulting templates and relations were compared to the reference standard.", "labels": [], "entities": [{"text": "ONYX", "start_pos": 0, "end_pos": 4, "type": "DATASET", "confidence": 0.8617749810218811}]}, {"text": "We measured inter-annotator agreement (IAA) between ONYX and the reference standard using the formula described in Roberts et al: We calculated IAA separately for CM words, concepts, and semantic relations.", "labels": [], "entities": [{"text": "inter-annotator agreement (IAA)", "start_pos": 12, "end_pos": 43, "type": "METRIC", "confidence": 0.9015938758850097}, {"text": "ONYX", "start_pos": 52, "end_pos": 56, "type": "DATASET", "confidence": 0.9580872058868408}, {"text": "IAA", "start_pos": 144, "end_pos": 147, "type": "METRIC", "confidence": 0.9919092059135437}]}, {"text": "A correct match is a word, concept or relation generated by both the reference standard and ONYX; a spurious item is one ONYX generated that did not exist in the reference standard; and a missing item is one that existed in the reference standard but was not generated by ONYX.", "labels": [], "entities": [{"text": "ONYX", "start_pos": 92, "end_pos": 96, "type": "DATASET", "confidence": 0.9712730050086975}, {"text": "ONYX", "start_pos": 272, "end_pos": 276, "type": "DATASET", "confidence": 0.9818726181983948}]}, {"text": "In addition to IAA we identified the concepts and relations most commonly in error and calculated percentages for those errors.", "labels": [], "entities": [{"text": "IAA", "start_pos": 15, "end_pos": 18, "type": "METRIC", "confidence": 0.5437330007553101}]}, {"text": "We compared ONYX's performance on the target documents with that of a simple baseline parser we created for this purpose.", "labels": [], "entities": [{"text": "ONYX", "start_pos": 12, "end_pos": 16, "type": "DATASET", "confidence": 0.6672934889793396}]}, {"text": "The baseline parser processes the words of a sentence from left to right, creating phrases for sets of juxtaposed words that can be interpreted together using the semantic network.", "labels": [], "entities": []}, {"text": "No grammar rules are employed, there is no analysis of conjunctive phrases, and goodness scores are not calculated.", "labels": [], "entities": [{"text": "goodness scores", "start_pos": 80, "end_pos": 95, "type": "METRIC", "confidence": 0.9688780307769775}]}, {"text": "Our goal was to get a feel for how much these factors contribute to generating correct interpretations.", "labels": [], "entities": []}, {"text": "There is no precedence for this particular approach as far as we are aware, so we regard this comparison as informative but not definitive.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 2: IAA for assignment of words, concepts, and  relations.  IAA  ONYX  86%  Words (n = 904)  Baseline  57%  ONYX  80%  Concepts (n = 1186)  Baseline  53%  ONYX  76%  Relations (n = 297)  Baseline  41%", "labels": [], "entities": [{"text": "IAA", "start_pos": 10, "end_pos": 13, "type": "METRIC", "confidence": 0.8928958177566528}, {"text": "IAA  ONYX  86%  Words", "start_pos": 66, "end_pos": 87, "type": "METRIC", "confidence": 0.7431313812732696}]}, {"text": " Table 3: Per-concept error percentages  Dental Condition Summary Concept  18%  Tooth Location Summary Concept  17%  Dental Condition Intermediate Concept  16%  Surface Summary Concept  15%  Total  66%", "labels": [], "entities": [{"text": "Per-concept error percentages", "start_pos": 10, "end_pos": 39, "type": "METRIC", "confidence": 0.6885095437367758}, {"text": "Dental Condition Summary Concept", "start_pos": 41, "end_pos": 73, "type": "TASK", "confidence": 0.6925699338316917}, {"text": "Tooth Location Summary Concept", "start_pos": 80, "end_pos": 110, "type": "TASK", "confidence": 0.7880483493208885}]}, {"text": " Table 4: Per-relation error percentages.  Surface of Part  47%  Location of Condition  23%  Total  70%", "labels": [], "entities": [{"text": "Per-relation error percentages", "start_pos": 10, "end_pos": 40, "type": "METRIC", "confidence": 0.7181726098060608}]}]}