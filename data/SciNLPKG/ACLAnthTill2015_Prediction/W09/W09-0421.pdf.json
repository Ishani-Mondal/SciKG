{"title": [{"text": "Improving alignment for SMT by reordering and augmenting the training corpus", "labels": [], "entities": [{"text": "Improving alignment", "start_pos": 0, "end_pos": 19, "type": "TASK", "confidence": 0.9157080948352814}, {"text": "SMT", "start_pos": 24, "end_pos": 27, "type": "TASK", "confidence": 0.9895113110542297}]}], "abstractContent": [{"text": "We describe the LIU systems for English-German and German-English translation in the WMT09 shared task.", "labels": [], "entities": [{"text": "WMT09 shared task", "start_pos": 85, "end_pos": 102, "type": "DATASET", "confidence": 0.7953059871991476}]}, {"text": "We focus on two methods to improve the word alignment: (i) by applying Giza++ in a second phase to a reordered training corpus , where reordering is based on the alignments from the first phase, and (ii) by adding lexical data obtained as high-precision alignments from a different word aligner.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 39, "end_pos": 53, "type": "TASK", "confidence": 0.7411023080348969}]}, {"text": "These methods were studied in the context of a system that uses compound processing, a morphological sequence model for German, and a part-of-speech sequence model for English.", "labels": [], "entities": []}, {"text": "Both methods gave some improvements to translation quality as measured by Bleu and Meteor scores, though not consistently.", "labels": [], "entities": [{"text": "translation", "start_pos": 39, "end_pos": 50, "type": "TASK", "confidence": 0.9703487753868103}, {"text": "Bleu", "start_pos": 74, "end_pos": 78, "type": "METRIC", "confidence": 0.9125246405601501}]}, {"text": "All systems used both out-of-domain and in-domain data as the mixed corpus had better scores in the baseline configuration.", "labels": [], "entities": []}], "introductionContent": [{"text": "It is an open question whether improved word alignment actually improves statistical MT.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 40, "end_pos": 54, "type": "TASK", "confidence": 0.7411727607250214}, {"text": "MT", "start_pos": 85, "end_pos": 87, "type": "TASK", "confidence": 0.8828151226043701}]}, {"text": "found that improved alignments as measured by AER will not necessarily improve translation quality, whereas did improve translation quality on several language pairs by extending the alignment algorithm.", "labels": [], "entities": [{"text": "AER", "start_pos": 46, "end_pos": 49, "type": "METRIC", "confidence": 0.9329702854156494}]}, {"text": "For this year's shared task we therefore studied the effects of improving word alignment in the context of our system for the WMT09 shared task.", "labels": [], "entities": [{"text": "word alignment", "start_pos": 74, "end_pos": 88, "type": "TASK", "confidence": 0.7546021640300751}, {"text": "WMT09 shared task", "start_pos": 126, "end_pos": 143, "type": "TASK", "confidence": 0.5786754290262858}]}, {"text": "Two methods were tried: (i) applying Giza++ in a second phase to a reordered training corpus, where reordering is based on the alignments from the first phase, and (ii) adding lexical data obtained as high-precision alignments from a different word aligner.", "labels": [], "entities": []}, {"text": "The submitted system includes the first method in addition to the processing of compounds and additional sequence models used by . Heuristics were used to generate true-cased versions of the translations that were submitted, as reported in section 6.", "labels": [], "entities": []}, {"text": "In this paper we report case-insensitive Bleu scores (), unless otherwise stated, calculated with the NIST tool, and caseinsensitive Meteor-ranking scores, without WordNet ().", "labels": [], "entities": [{"text": "Bleu scores", "start_pos": 41, "end_pos": 52, "type": "METRIC", "confidence": 0.846373051404953}, {"text": "NIST tool", "start_pos": 102, "end_pos": 111, "type": "DATASET", "confidence": 0.9486527442932129}, {"text": "WordNet", "start_pos": 164, "end_pos": 171, "type": "DATASET", "confidence": 0.9709840416908264}]}], "datasetContent": [], "tableCaptions": [{"text": " Table 1: Number of sentences in the corpora (after  filtering)", "labels": [], "entities": []}, {"text": " Table 2: Results of domain adaptation", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.839123010635376}]}, {"text": " Table 3: Results of reordering experiments", "labels": [], "entities": []}, {"text": " Table 4: Results of domain adaptation", "labels": [], "entities": [{"text": "domain adaptation", "start_pos": 21, "end_pos": 38, "type": "TASK", "confidence": 0.8381781876087189}]}, {"text": " Table 5: Case-sensitive Bleu scores", "labels": [], "entities": [{"text": "Bleu", "start_pos": 25, "end_pos": 29, "type": "METRIC", "confidence": 0.6129900217056274}]}, {"text": " Table 6: Bleu scores for the reordered systems on  two sections of development set news-dev2009b.  NIST scores show the same distribution.", "labels": [], "entities": [{"text": "Bleu", "start_pos": 10, "end_pos": 14, "type": "METRIC", "confidence": 0.969912588596344}, {"text": "NIST scores", "start_pos": 100, "end_pos": 111, "type": "DATASET", "confidence": 0.9339383542537689}]}]}