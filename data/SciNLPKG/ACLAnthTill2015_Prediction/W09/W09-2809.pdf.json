{"title": [{"text": "A Parse-and-Trim Approach with Information Significance for Chinese Sentence Compression", "labels": [], "entities": [{"text": "Chinese Sentence Compression", "start_pos": 60, "end_pos": 88, "type": "TASK", "confidence": 0.6624469856421152}]}], "abstractContent": [{"text": "In this paper, we propose an event-based approach for Chinese sentence compression without using any training corpus.", "labels": [], "entities": [{"text": "Chinese sentence compression", "start_pos": 54, "end_pos": 82, "type": "TASK", "confidence": 0.6676886876424154}]}, {"text": "We enhance the linguistically-motivated heuristics by exploiting event word significance and event information density.", "labels": [], "entities": []}, {"text": "This is shown to improve the preservation of important information and the tolerance of POS and parsing errors, which are more common in Chinese than English.", "labels": [], "entities": [{"text": "parsing", "start_pos": 96, "end_pos": 103, "type": "TASK", "confidence": 0.7887173891067505}]}, {"text": "The heuristics are only required to determine possibly removable constituents instead of selecting specific constituents for removal, and thus are easier to develop and port to other languages and domains.", "labels": [], "entities": []}, {"text": "The experimental results show that around 72% of our automatic compressions are grammatically and semantically correct, preserving around 69% of the most important information on average .", "labels": [], "entities": []}], "introductionContent": [{"text": "The goal of sentence compression is to shorten sentences while preserving their grammaticality and important information.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 12, "end_pos": 32, "type": "TASK", "confidence": 0.7282988429069519}]}, {"text": "It has recently attracted much attention because of its wide range of applications, especially in summarization and headline generation (which can be viewed as summarization with very short length requirement).", "labels": [], "entities": [{"text": "summarization", "start_pos": 98, "end_pos": 111, "type": "TASK", "confidence": 0.9914513230323792}, {"text": "headline generation", "start_pos": 116, "end_pos": 135, "type": "TASK", "confidence": 0.8447927236557007}, {"text": "summarization", "start_pos": 160, "end_pos": 173, "type": "TASK", "confidence": 0.9597663283348083}]}, {"text": "Sentence compression can improve extractive summarization in coherence and amount of information expressed within a fixed length.", "labels": [], "entities": [{"text": "Sentence compression", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9229540228843689}, {"text": "summarization", "start_pos": 44, "end_pos": 57, "type": "TASK", "confidence": 0.7103005051612854}]}, {"text": "An ideal sentence compression will include complex paraphrasing operations, such as word deletion, substitution, insertion, and reordering.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 9, "end_pos": 29, "type": "TASK", "confidence": 0.7301041632890701}]}, {"text": "In this paper, we focus on the simpler instantiation of sentence simplification, namely word deletion, which has been proved a success in the literature (.", "labels": [], "entities": [{"text": "sentence simplification", "start_pos": 56, "end_pos": 79, "type": "TASK", "confidence": 0.7138381004333496}, {"text": "word deletion", "start_pos": 88, "end_pos": 101, "type": "TASK", "confidence": 0.6962957382202148}]}, {"text": "In this paper, we present our technique for Chinese sentence compression without the need fora sentence/compression parallel corpus.", "labels": [], "entities": [{"text": "Chinese sentence compression", "start_pos": 44, "end_pos": 72, "type": "TASK", "confidence": 0.6187193691730499}]}, {"text": "We combine linguistically-motivated heuristics and word significance scoring together to trim the parse tree, and rank candidate compressions according to event information density.", "labels": [], "entities": [{"text": "word significance scoring", "start_pos": 51, "end_pos": 76, "type": "TASK", "confidence": 0.7279121180375417}]}, {"text": "In contrast to probabilistic methods, the heuristics are more likely to produce grammatical and fluent compressed sentences.", "labels": [], "entities": []}, {"text": "We reduce the difficulty and linguistic skills required for composing heuristics by only requiring these heuristics to identify possibly removable constituents instead of selecting specific constituents for removal.", "labels": [], "entities": []}, {"text": "The word significance helps to preserve informative constituents and overcome some POS and parsing errors.", "labels": [], "entities": [{"text": "POS and parsing", "start_pos": 83, "end_pos": 98, "type": "TASK", "confidence": 0.608680933713913}]}, {"text": "In particular, we seek to assess the event information during the compression process, according to the previous successes in event-based summarization () and anew eventoriented 5W summarization task ().", "labels": [], "entities": []}, {"text": "The next section presents previous approaches to sentence compression.", "labels": [], "entities": [{"text": "sentence compression", "start_pos": 49, "end_pos": 69, "type": "TASK", "confidence": 0.8150569796562195}]}, {"text": "In section 3, we describe our system with three modules, viz.", "labels": [], "entities": []}, {"text": "linguistically-motivated heuristics, word significance scoring and candidate compression selection.", "labels": [], "entities": [{"text": "word significance scoring", "start_pos": 37, "end_pos": 62, "type": "TASK", "confidence": 0.8056337634722391}, {"text": "candidate compression selection", "start_pos": 67, "end_pos": 98, "type": "TASK", "confidence": 0.8248873353004456}]}, {"text": "We also develop a heuristics-only approach for comparison.", "labels": [], "entities": []}, {"text": "In section 4, we evaluate the compressions in terms of grammaticality, infor-mativeness and compression rate.", "labels": [], "entities": [{"text": "infor-mativeness", "start_pos": 71, "end_pos": 87, "type": "METRIC", "confidence": 0.92194002866745}, {"text": "compression rate", "start_pos": 92, "end_pos": 108, "type": "METRIC", "confidence": 0.9043239951133728}]}, {"text": "Finally, Section 5 concludes this paper and discusses directions of future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "Our experiments were designed to evaluate the quality of automatic compression.", "labels": [], "entities": [{"text": "automatic compression", "start_pos": 57, "end_pos": 78, "type": "TASK", "confidence": 0.7306448221206665}]}, {"text": "The evaluation corpus is 79 documents from Chinese newswires, and the first sentence of each news article is compressed.", "labels": [], "entities": []}, {"text": "The compression of the first sentences in the Chinese news articles is a comparatively challenging task.", "labels": [], "entities": [{"text": "compression of the first sentences in the Chinese news articles", "start_pos": 4, "end_pos": 67, "type": "TASK", "confidence": 0.8016974687576294}]}, {"text": "Unlike English, Chinese often connects two or more self-complete sentences together without any indicating word or punctuation; this is extremely frequent for the first sentence of news text.", "labels": [], "entities": []}, {"text": "The average length of the first sentences in the 79 documents is 61.5 characters, compared to 46.8 characters for the sentences in the body of these news articles.", "labels": [], "entities": []}, {"text": "We compare the compressions generated by four different methods: \uf0b7 are set roughly to be 10 and 20 characters based on our experience.", "labels": [], "entities": []}, {"text": "Sentence compression is commonly evaluated by human judgment.", "labels": [], "entities": [{"text": "Sentence compression", "start_pos": 0, "end_pos": 20, "type": "TASK", "confidence": 0.9482600390911102}]}, {"text": "Following the literature (, we asked three native Chinese speakers to rate the grammaticality of compressions using the 1 to 5 scale.", "labels": [], "entities": []}, {"text": "We find that all three nonlinguist human judges tend to take semantic correctness into consideration when scoring grammaticality.", "labels": [], "entities": []}, {"text": "We also asked these three judges to give a list of keywords from the original sentence before seeing compressions, which they would preserve if asked to create a headline based on the sentence.", "labels": [], "entities": []}, {"text": "Instead of a subjective score, the informativeness is evaluated by measuring the keyword coverage of the target compression on a percentage scale.", "labels": [], "entities": []}, {"text": "The three judges give different numbers of keywords varying from 3.33 to 6.51 on average over the 79 sentences.", "labels": [], "entities": []}, {"text": "The compression rate is the ratio of the number of Chinese characters in a compressed sentence to that in its original sentence.", "labels": [], "entities": [{"text": "compression rate", "start_pos": 4, "end_pos": 20, "type": "METRIC", "confidence": 0.9431643187999725}]}, {"text": "The experimental results in show that our automatically generated compressions preserve grammaticality, with an average score of about 4 out of 5, because of the use of linguistically-motivated heuristics..", "labels": [], "entities": []}, {"text": "Mean rating from human evaluation on first sentence compression Event-based word significance and information density increase the amount of important information by 6% with similar sentence length, but decreases the average grammaticality score by 6.5%.", "labels": [], "entities": [{"text": "first sentence compression Event-based word significance", "start_pos": 37, "end_pos": 93, "type": "TASK", "confidence": 0.7502122869094213}]}, {"text": "This is because the method using word significance sacrifices grammaticality to reduce the linguistic complexity of the heuristics.", "labels": [], "entities": [{"text": "word significance", "start_pos": 33, "end_pos": 50, "type": "TASK", "confidence": 0.6894253045320511}]}, {"text": "Nonetheless, this method does improve grammaticality for 16 of the 79 compressed sentences, typically for those with POS or parsing errors.", "labels": [], "entities": [{"text": "POS", "start_pos": 117, "end_pos": 120, "type": "METRIC", "confidence": 0.8456135988235474}]}], "tableCaptions": [{"text": " Table 2. Mean rating from human evaluation on  first sentence compression", "labels": [], "entities": [{"text": "Mean rating", "start_pos": 10, "end_pos": 21, "type": "METRIC", "confidence": 0.9787083864212036}]}, {"text": " Table 3. Compressions with good grammar", "labels": [], "entities": []}]}