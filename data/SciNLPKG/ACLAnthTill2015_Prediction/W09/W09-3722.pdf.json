{"title": [{"text": "A Multiclassifier based Approach for Word Sense Disambiguation using Singular Value Decomposition", "labels": [], "entities": [{"text": "Word Sense Disambiguation", "start_pos": 37, "end_pos": 62, "type": "TASK", "confidence": 0.788018544514974}]}], "abstractContent": [{"text": "In this paper a multiclassifier based approach is presented fora word sense disambiguation (WSD) problem.", "labels": [], "entities": [{"text": "word sense disambiguation (WSD)", "start_pos": 65, "end_pos": 96, "type": "TASK", "confidence": 0.7977693031231562}]}, {"text": "A vector representation is used for training and testing cases and the Singular Value Decomposition (SVD) technique is applied to reduce the dimension of the representation.", "labels": [], "entities": []}, {"text": "The approach we present consists in creating a set of k-NN classifiers and combining the predictions generated in order to give a final word sense prediction for each case to be classified.", "labels": [], "entities": []}, {"text": "The combination is done by applying a Bayesian voting scheme.", "labels": [], "entities": []}, {"text": "The approach has been applied to a database of 100 words made available by the lexical sample WSD subtask of SemEval-2007 (task 17) organizers.", "labels": [], "entities": [{"text": "WSD subtask of SemEval-2007 (task 17) organizers", "start_pos": 94, "end_pos": 142, "type": "DATASET", "confidence": 0.8492692112922668}]}, {"text": "Each of the words was considered an independent classification problem.", "labels": [], "entities": []}, {"text": "A methodological parameter tuning phase was applied in order to optimize parameter setting for each word.", "labels": [], "entities": []}, {"text": "Results achieved are among the best and make the approach encouraging to apply to other WSD tasks.", "labels": [], "entities": [{"text": "WSD tasks", "start_pos": 88, "end_pos": 97, "type": "TASK", "confidence": 0.9287599623203278}]}], "introductionContent": [{"text": "Word sense disambiguation (WSD) is the problem of determining which sense of a word is used when a word appears in a particular context.", "labels": [], "entities": [{"text": "Word sense disambiguation (WSD)", "start_pos": 0, "end_pos": 31, "type": "TASK", "confidence": 0.8389701346556345}]}, {"text": "In fact, WSD is an important component in many information organization tasks, and fundamentally consists in a classification problem: given some word-contexts corresponding to some possible senses, the WSD system has to classify an occurrence of the word into one of its possible senses.", "labels": [], "entities": [{"text": "WSD", "start_pos": 9, "end_pos": 12, "type": "TASK", "confidence": 0.9413419961929321}]}, {"text": "In the approach presented in this paper, a vector representation is used for training and testing word cases and the Singular Value Decomposition of matrices is applied in order to reduce the dimension of the representation.", "labels": [], "entities": []}, {"text": "In particular, Latent Semantic Indexing (LSI) is used to make the dimension reduction.", "labels": [], "entities": [{"text": "Latent Semantic Indexing (LSI)", "start_pos": 15, "end_pos": 45, "type": "METRIC", "confidence": 0.6117847363154093}, {"text": "dimension reduction", "start_pos": 66, "end_pos": 85, "type": "TASK", "confidence": 0.7665554285049438}]}, {"text": "This technique compresses vectors representing word related contexts into vectors of a lower-dimensional space and has shown to have the ability to extract the relations among features representing words by means of their context of use.", "labels": [], "entities": []}, {"text": "We present a multiclassifier based approach which uses different training databases.", "labels": [], "entities": []}, {"text": "These databases are obtained from the original training dataset by random subsampling.", "labels": [], "entities": []}, {"text": "The implementation of this approach is made by a model inspired in bagging, and the k-NN classification algorithm is used to make sense predictions for testing words.", "labels": [], "entities": []}, {"text": "For experimentation, a previous tuning phase was performed to training data in order to automatically set some system parameters to their optimal values.", "labels": [], "entities": []}, {"text": "Four are the parameters to be optimized, and the combination of all of them gives the possibility to perform the complete disambiguation process by 1440 different ways for each of the 100 words to be disambiguated.", "labels": [], "entities": []}, {"text": "The tuning phase has been performed in a sound manner with the aim to improve our previous work.", "labels": [], "entities": []}, {"text": "Although the computational payload is high, it is a systematic way to fix the optimal values for parameters.", "labels": [], "entities": []}, {"text": "The aim of this article is to give a brief description of our approach to deal with the WSD task and to show the results achieved.", "labels": [], "entities": [{"text": "WSD task", "start_pos": 88, "end_pos": 96, "type": "TASK", "confidence": 0.8914864957332611}]}, {"text": "In Section 2, our approach is presented.", "labels": [], "entities": []}, {"text": "In Section 3, the experimental setup is introduced.", "labels": [], "entities": []}, {"text": "The experimental results are presented and discussed in Section 4, and finally, Section 5 contains some conclusions and future work.", "labels": [], "entities": []}], "datasetContent": [{"text": "The dataset we use in the experiments was obtained from the 4th International Workshop on Semantic Evaluations (SemEval-2007) web page 1 , task 17, subtask 1: Coarse-grained English Lexical Sample WSD.", "labels": [], "entities": [{"text": "International Workshop on Semantic Evaluations (SemEval-2007) web page 1", "start_pos": 64, "end_pos": 136, "type": "DATASET", "confidence": 0.5278822671283375}, {"text": "Coarse-grained English Lexical Sample WSD", "start_pos": 159, "end_pos": 200, "type": "TASK", "confidence": 0.5365994989871978}]}, {"text": "This task consists of lexical sample style training and testing data for 100 lemmas (35 nouns and 65 verbs) of different degree of polysemy (ranging from 1 to 13) and number of instances annotated (ranging from 19 instances in training for the word grant to 2536 instances at share).", "labels": [], "entities": []}, {"text": "The average inter-annotator agreement for these lemmas is over 90%.", "labels": [], "entities": []}, {"text": "In task organizers describe the results achieved by the participating systems.", "labels": [], "entities": []}, {"text": "They define a baseline for the task based on giving the most frequent sense in training (F-score: 78.0%).", "labels": [], "entities": [{"text": "F-score", "start_pos": 89, "end_pos": 96, "type": "METRIC", "confidence": 0.9994742274284363}]}, {"text": "The best system performance (89.1%) was closely approaching the inter-annotator agreement but still below it.", "labels": [], "entities": []}, {"text": "The experiments were carried out in two phases.", "labels": [], "entities": []}, {"text": "First, a parameter tuning phase was performed in order to set the following parameters to their optimal values: \u2022 The dimension p of the reduced dimensional vector space R p to which word-case vectors are projected for each word.", "labels": [], "entities": []}, {"text": "\u2022 The number of classifiers, training databases TD i , to create for each word.", "labels": [], "entities": []}, {"text": "\u2022 The number k of nearest neighbors to be considered by the k-NN classifier for each word.", "labels": [], "entities": []}, {"text": "\u2022 The number n 1 of cases to select from the TD of each word in order to create each one of the TD i , that is, the size of each TD i . All the four parameters were adjusted independently for each word, because of the different characteristics of words with respect to the number of training and testing cases present in the dataset and the number of wordsenses associated to each of them.", "labels": [], "entities": []}, {"text": "Validation and testing data subsets used in the tuning phase were extracted form the original training database TD for each word.", "labels": [], "entities": []}, {"text": "Both subsets were constructed by random selection of cases, where 75% of the cases were selected for the validation subset and the rest for the tuning purposed made testing subset.", "labels": [], "entities": []}, {"text": "In the following the optimization of parameters is explained.", "labels": [], "entities": []}, {"text": "Parameters were optimized in the same order as presented in this subsection, that is, the dimension reduction first, the number of classifiers second, the number k of nearest neighbors third and the size of each TD i last.", "labels": [], "entities": [{"text": "dimension reduction", "start_pos": 90, "end_pos": 109, "type": "METRIC", "confidence": 0.96480792760849}]}, {"text": "When the first parameter was being optimized, all possibilities for the other three parameters were taken into account, and the optimization of the parameter was made based on the average of the 10% best results.", "labels": [], "entities": []}, {"text": "Once a parameter was fixed, the same method was applied in order to optimize the rest of the parameters.", "labels": [], "entities": []}, {"text": "This optimization method implies that the experiment was performed for all the combinations of the four parameters.", "labels": [], "entities": []}, {"text": "This implies a high computational cost during the tuning phase.", "labels": [], "entities": []}, {"text": "For testing phase, the experiments are performed using the optimal values for parameters.", "labels": [], "entities": []}, {"text": "The experiment was conducted by considering the optimal values for parameters tuned.", "labels": [], "entities": []}, {"text": "Original training and testing datasets were used for the final experiment, and results achieved were compared to the ones made available by task organizers.", "labels": [], "entities": []}, {"text": "Our system achieved an F-score of 85.65%, which compared to the baseline defined (78.0%) is a very good result, although still below the best published by task organizers (89.1%).", "labels": [], "entities": [{"text": "F-score", "start_pos": 23, "end_pos": 30, "type": "METRIC", "confidence": 0.9996625185012817}]}, {"text": "In the performance of the top-8 systems on individual verbs and nouns is shown; 73 of the 100 lemmas are included in a table in two separated groups.", "labels": [], "entities": []}, {"text": "Lemmas that have perfect or almost perfect accuracies have been removed.", "labels": [], "entities": []}, {"text": "In TABLE 1 the average results achieved by our system for the two groups of lemmas are compared to the ones published in the cited paper.", "labels": [], "entities": [{"text": "TABLE", "start_pos": 3, "end_pos": 8, "type": "METRIC", "confidence": 0.8165462017059326}]}, {"text": "We can observe that our system performs better than the average of the top-8 systems disambiguating nouns, but slightly worse for verbs.", "labels": [], "entities": []}, {"text": "In the overall, our system is very near to the average performance of the top-8 systems.", "labels": [], "entities": []}, {"text": "Top- We want to remark that our system uses only the official training and testing data, without including background knowledge of any type.", "labels": [], "entities": []}, {"text": "Some of the top-8 systems used background knowledge in order to assist in resolving ambiguities.", "labels": [], "entities": []}, {"text": "An analysis of the parameter optimization performed in the tuning phase lead us to observe that there is a relation between the dimensionality reduction level applied by SVD and the accuracy achieved fora word disambiguation (see).", "labels": [], "entities": [{"text": "accuracy", "start_pos": 182, "end_pos": 190, "type": "METRIC", "confidence": 0.999245285987854}, {"text": "word disambiguation", "start_pos": 205, "end_pos": 224, "type": "TASK", "confidence": 0.6969449371099472}]}, {"text": "Words with more than 500 cases in the training dataset were not depicted in the figure because an additional dimension reduction was applied to them (see section 3.1).", "labels": [], "entities": []}, {"text": "The graphic in suggests that In order to analyze the adequacy of the parameter tuning performed, we created anew variable dividing the case number n of the training database by the number of senses for each word.", "labels": [], "entities": []}, {"text": "This calculus is meant to represent the complexity of each word.", "labels": [], "entities": []}, {"text": "In the interquartile relationships found among the parameter \u03bb and the complexity of the words is presented.", "labels": [], "entities": []}, {"text": "For each value of \u03bb the segments represent the minimum and the maximum value of the complexity, while the bold line shows the median and the rectangular area represents the density of the second and third quartiles.", "labels": [], "entities": []}, {"text": "As it can be seen, the evolution of the median value, as well as the minimum values, are similar to the observed in the accuracies.", "labels": [], "entities": []}, {"text": "This allows to say that the \u03bb value was properly selected by the automatic selection used, and also that higher values of \u03bb would not ensure better solutions for the most complex words.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Average performance compared to the top-8 in [9]", "labels": [], "entities": []}]}