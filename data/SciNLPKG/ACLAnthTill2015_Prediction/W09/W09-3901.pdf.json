{"title": [{"text": "Evaluating the Effectiveness of Information Presentation in a Full End-To-End Dialogue System", "labels": [], "entities": []}], "abstractContent": [{"text": "Recent work on information presentation in dialogue systems combines user modelling (UM) and stepwise refinement through clustering and summarisa-tion (SR) in the UMSR approach.", "labels": [], "entities": [{"text": "information presentation", "start_pos": 15, "end_pos": 39, "type": "TASK", "confidence": 0.7161552459001541}]}, {"text": "An evaluation in which participants rated dialogue transcripts showed that UMSR presents complex trade-offs understandably, provides users with a good overview of their options, and increases users' confidence that all relevant options have been presented (Demberg and Moore, 2006).", "labels": [], "entities": []}, {"text": "In this paper, we evaluate the effectiveness of the UMSR approach in a more realistic setting, by incorporating this information presentation technique into a full end-to-end dialogue system in the city information domain, and comparing it with the traditional approach of presenting information sequentially.", "labels": [], "entities": []}, {"text": "Our results suggest that despite complications associated with areal dialogue system setting, the UMSR model retains its advantages.", "labels": [], "entities": [{"text": "areal dialogue system setting", "start_pos": 63, "end_pos": 92, "type": "TASK", "confidence": 0.5910830646753311}]}], "introductionContent": [{"text": "Spoken dialogue systems (SDS) that help users find a desired option (e.g., flight, restaurant, movie) from the set of options satisfying their constraints typically present options sequentially, ordered along a default dimension (e.g., by price or departure time).", "labels": [], "entities": []}, {"text": "An example is shown in.", "labels": [], "entities": []}, {"text": "The user can then navigate through the options and refine them by offering new constraints until a suitable option has been found.", "labels": [], "entities": []}, {"text": "However, when the number of available options is large, this process can be painstaking, leading to long dialogues There are six restaurant options matching your query.). and reduced user satisfaction.", "labels": [], "entities": []}, {"text": "Thus a major challenge in the development of SDS is to improve information presentation algorithms.", "labels": [], "entities": [{"text": "SDS", "start_pos": 45, "end_pos": 48, "type": "TASK", "confidence": 0.9812554717063904}, {"text": "information presentation algorithms", "start_pos": 63, "end_pos": 98, "type": "TASK", "confidence": 0.8231294552485148}]}, {"text": "This is important for several reasons: (1) to avoid overburdening the user's memory by presenting too many options; to ensure that the user is given an overview of the available option space so that the optimal option can be found; and (3) to minimise the number of dialogue turns (hence dialogue duration) required for the user to find an acceptable option.", "labels": [], "entities": []}, {"text": "As showed, failing to meet this third goal may reduce overall user satisfaction.", "labels": [], "entities": []}, {"text": "Recently several approaches have been proposed to overcome the shortcomings of the sequential enumeration strategy (.", "labels": [], "entities": []}, {"text": "Because of the complexity of building a complete end-to-end SDS, these approaches have been evaluated using an \"overhearer\" methodology in which dialogues are either hand-crafted or simulated and then presented to subjects, either as textual transcripts or audio recordings (), for rating.", "labels": [], "entities": []}, {"text": "The general consensus from these studies is that users significantly prefer approaches that take their preferences into account.", "labels": [], "entities": []}, {"text": "However, because users were not interacting with these SDS, the evaluation criteria were limited to users' perceptions (e.g., informativeness, good overview of options, confidence in choice, etc.), and metrics such as effectiveness (i.e., actual or perceived task completion) and efficiency (i.e., length of dialogue) could not be assessed.", "labels": [], "entities": []}, {"text": "To address this issue, carried out a Wizard-of-Oz (WOz) study in which users participated in dialogues controlled by two different information presentation algorithms.", "labels": [], "entities": []}, {"text": "They found that not only did users prefer presentations based on a user model, dialogues employing the \"usermodel based summarise and refine\" (UMSR) approach led to greater task success and dialogue efficiency.", "labels": [], "entities": []}, {"text": "In this paper, we take this one step further, and evaluate the effectiveness of the UMSR approach in a more realistic setting, incorporating this content selection and presentation strategy into a full end-to-end dialogue system, and comparing it to the traditional sequential enumeration approach.", "labels": [], "entities": []}, {"text": "Our results suggest that despite complications associated with areal dialogue system setting, the UMSR model retains its advantages.", "labels": [], "entities": [{"text": "areal dialogue system setting", "start_pos": 63, "end_pos": 92, "type": "TASK", "confidence": 0.5910830646753311}]}, {"text": "Our results also verify the hypothesis that the UMSR model presents complex trade-offs in a concise, yet understandable way.", "labels": [], "entities": []}, {"text": "Furthermore, as in the WOz study, the UMSR approach leads to a significant reduction in the number of dialogue turns.", "labels": [], "entities": [{"text": "WOz study", "start_pos": 23, "end_pos": 32, "type": "DATASET", "confidence": 0.8548541367053986}]}, {"text": "The structure of the paper is as follows: In Sec.", "labels": [], "entities": []}, {"text": "2, we discuss related work.", "labels": [], "entities": []}, {"text": "3 we present the full end-to-end SDS used for comparison between the standard sequential enumeration approach and the UMSR approach.", "labels": [], "entities": []}, {"text": "4 we describe how we implemented the UMSR approach.", "labels": [], "entities": [{"text": "UMSR", "start_pos": 37, "end_pos": 41, "type": "TASK", "confidence": 0.8488990068435669}]}, {"text": "5 we provide an example.", "labels": [], "entities": []}, {"text": "6 we describe our experimental design and in Sec.", "labels": [], "entities": []}, {"text": "8, we present our conclusions.", "labels": [], "entities": []}], "datasetContent": [{"text": "In total 18 subjects interacted with our two systems.", "labels": [], "entities": []}, {"text": "Each participant interacted three times with the modified TownInfo system, and another three times with the system that supported our implementation of the UMSR model (108 dialogues in: A sample option tree structure for the student user of.", "labels": [], "entities": [{"text": "TownInfo", "start_pos": 58, "end_pos": 66, "type": "DATASET", "confidence": 0.9584580659866333}]}, {"text": "Pruned nodes are shown as shaded.", "labels": [], "entities": []}, {"text": "The order of the dialogues was randomised among the subjects.", "labels": [], "entities": []}, {"text": "Each experiment took between 40 and 50 minutes on average.", "labels": [], "entities": []}, {"text": "For each task, subjects were provided with the user profile and the actual scenario for the specific task in hand.", "labels": [], "entities": []}, {"text": "The tasks were carefully constructed so that half of them could be solved without making any trade-offs and the other half required a trade-off to be made.", "labels": [], "entities": []}, {"text": "At the end of each task the subjects had to fill out a questionnaire with 10 questions on a 7-point Likert scale.", "labels": [], "entities": []}, {"text": "They were also asked if they had been able to accomplish the given task (perceived task completion), i.e., to find a suitable restaurant for the scenario and user profile in hand.", "labels": [], "entities": []}, {"text": "Finally, after each task they had to provide the name(s) of the restaurants they chose for the task.", "labels": [], "entities": []}, {"text": "The name(s) stated for this task were then used to compare perceived task completion with actual task completion.", "labels": [], "entities": []}, {"text": "At the end of each task with the UMSR system, the profiles were reset to the default attribute values and ranks.", "labels": [], "entities": []}, {"text": "Both systems had identical software configurations, i.e., they only differed in the information presentation component.", "labels": [], "entities": [{"text": "information presentation", "start_pos": 84, "end_pos": 108, "type": "TASK", "confidence": 0.8210285604000092}]}, {"text": "Yet another important feature was that the UMSR based model did not accept multiple attributes in a single query.", "labels": [], "entities": []}, {"text": "So for instance the user could not ask \"I am looking fora moderately priced restaurant near the city centre that serves Italian food\".", "labels": [], "entities": []}, {"text": "This seemed to be a major shortcoming of the UMSR based system compared to the TownInfo system with sequential information presentation.", "labels": [], "entities": [{"text": "TownInfo", "start_pos": 79, "end_pos": 87, "type": "DATASET", "confidence": 0.9443923830986023}]}, {"text": "However, as we will see in the following, even with this shortcom-: Average scores of the questionnaires for all dialogues, dialogues with tradeoffs (with TO) and dialogues without trade-offs (no TO) (U=understandability, CC=conciseness, CF=confidence, A=accessibility, E=efficiency).", "labels": [], "entities": [{"text": "TO", "start_pos": 155, "end_pos": 157, "type": "METRIC", "confidence": 0.977233350276947}]}, {"text": "ing the UMSR approach retained its advantages and proved more successful than the traditional sequential enumeration approach.", "labels": [], "entities": []}], "tableCaptions": [{"text": " Table 1: Sample user model for a student.", "labels": [], "entities": [{"text": "Sample user", "start_pos": 10, "end_pos": 21, "type": "TASK", "confidence": 0.8375712335109711}]}, {"text": " Table 2: Average scores of the question- naires for all dialogues, dialogues with trade- offs (with TO) and dialogues without trade-offs  (no TO) (U=understandability, CC=conciseness,  CF=confidence, A=accessibility, E=efficiency).", "labels": [], "entities": [{"text": "TO", "start_pos": 101, "end_pos": 103, "type": "METRIC", "confidence": 0.9881229996681213}]}, {"text": " Table 3: Sample user model for a business person (User Model A).", "labels": [], "entities": []}]}